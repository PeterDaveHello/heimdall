[
  {
    "id": 37461449,
    "title": "Microsoft has not stopped forcing Edge on Windows 11 users",
    "originLink": "https://www.ctrl.blog/entry/windows-system-components-default-edge.html",
    "originBody": "Ctrl.blog Skip to main content Daniel Aleksandersen Latest Newsletter Topics Patrons About Microsoft has not stopped forcing Edge on Windows 11 users 2023-09-11 5-minute read Share Microsoft published a blog post on the Windows Insider Blog in late August with a vague statement saying that “Windows system components“ were to begin respecting the default web browser setting. Windows 10 and 11 regularly bypass this setting and force-open links in Microsoft Edge instead. In my extensive testing, I haven’t found any changes in the new Windows Insider version. You may have read stories in the tech media celebrating that Windows will finally respect the default browser setting. This reporting seems to have been done completely without verification and based entirely on a misunderstanding. The source of the confusion is this one highlighted but vague entry in the changelog for a recent Windows 11 Insider preview build: In the European Economic Area (EEA), Windows system components use the default browser to open links. Announcing Windows 11 Insider Preview Build 23531 (Dev Channel), Amanda Langowski Brandon LeBlanc The highlight makes it sound like Microsoft has finally caved to regulatory pressure from the European Union (EU). The software powerhouse has abused the dominant market position of its Windows operating system to promote its Edge web browser and services for too long. I’ve followed this developing story closely over the years. I even developed the popular open-source EdgeDeflector program that hijacked web links destined for Microsoft Edge and directed them back to your default web browser. Microsoft finally reacted and blocked EdgeDeflector from working once the Mozilla Firefox and Brave browsers began building the functionality into their web browsers. Excitedly, I installed the new Windows Insider build and began testing the changes to see them in action. At first, I didn’t believe my findings. Nothing had changed from the current version of Windows 11. The new Windows version still strongly discourages changing the default browser away from Microsoft Edge. After system updates, the new version still aggressively prompts you with a captive full-screen experience on start-up to reset your default web browser to Microsoft Edge. Web links in primary surfaces still force-open Microsoft Edge — including links in the new Copilot, Start menu, Search on the taskbar and desktop, Windows Spotlight, first-party apps (Outlook, Teams, News, Weather, and more), and Widgets on the taskbar (formerly called News and Weather). I’ve verified my findings in the Home and Professional editions of Windows and even the EU-specific “N” variants of each edition. I’ve tested in two configurations for Norway (EEA member) and Germany (EEA and EU member). For both tests, I installed devices with region and locale settings matching the desired country with IP addresses and geolocation sensor data to match. I’ve checked, double-, and triple-checked my findings. Nothing has changed. Web links still force-open in Microsoft Edge instead of your default web browser. Microsoft first announced the changes for Windows Insider build 23531 (Developer channel). I waited for two more releases and retested with builds 23536 and 23541, both from the Developer channel. I also retested with the Canary channel, which is even further ahead on the development tree than the Developer channel. Microsoft sometimes gradually rolls out changes in the Windows Insider program to a limited set of users. It does not document publicly which new changes are gradually rolled out. However, there were only two new experiments in build 23531. None of them are related to default browser settings or Microsoft Edge. The new changes to default browser handling may be a gradual rollout, though. Microsoft was vague about the change, and neither its customers nor the tech media verified their assumptions before running with the story. Despite not having implemented the changes everyone assumed it had, it has received lots of positive press attention for doing the right thing. I have not found anyone commenting on whether this change worked for them in the many and extensive discussions on Hacker News, Reddit, and other social media. I’ve also not found any traces of confirmation or checks in the hundreds of news sites that ran the story nor in their comment sections. There has also been no mention of it in the Insider Feedback Hub or any subsequent Windows Insider build announcements or changelogs. I have not reached out to Microsoft for a comment on this story. Frankly, at this point, I rather assume they hate me personally more than they hate their average customers. Microsoft has also refused to make statements to The Register and The Verge for their stories on the vague changes. Disclaimer: I am an employee of Vivaldi Technologies, a competitor to Microsoft Edge. This website is my personal blog, and the views and findings expressed here do not represent my employer. I’m also the developer of EdgeDeflector, the circumvention program described in the article. Buy Me A Coffee Read 274 comments Microsoft Windows Web Browsers Sources Announcing Windows 11 Insider Preview Build 23531 (Dev Channel), 2023-08-25, Amanda Langowski and Brandon LeBlanc, Windows Insider Blog, Microsoft Abbreviations EEA European Economic Area EU European Union IP Internet Protocol Follow Ctrl blog on Feedly About Privacy Policy Colophon Licensing The image “Microsoft Edge” by © 2020 Daniel Aleksandersen is licensed under a CC0 1.0 License. Ctrl blog by © 2023 Daniel Aleksandersen. Hosting by Hetzner and Linode. CDN by Bunny.",
    "commentLink": "https://news.ycombinator.com/item?id=37461449",
    "commentBody": "Microsoft has not stopped forcing Edge on Windows 11 usersHacker NewspastloginMicrosoft has not stopped forcing Edge on Windows 11 users (ctrl.blog) 487 points by extr0pian 9 hours ago| hidepastfavorite272 comments oefrha 25 minutes agoLast time I tested an extension of mine on Edge, I counted four or five distinct ways Windows and Edge tried to convince or coax me into setting Edge as default. (Coaxing includes but isn’t limited to full-screen one-click “finish setting up your computer” on boot which includes adopting “Microsoft-recommended” browser security settings which of course means resetting the default browser. It appeared on every reboot until someone told me about a setting to disable it.) Mind you, the four or five ways I encountered were from using Windows 11 Pro normally or opening Edge briefly; I’m not even counting additional conditional shenanigans like special banner on chrome.com, or asking you to use Microsoft everything (including on mobile devices) to bump up your position in Bing Chat waitlist.The brazenness and shamelessness is really appalling. reply withinrafael 5 hours agoprevGlad to see someone else chasing this down, and not surprised this is still not yet reproducible.Paul Thurrott and I were also scratching our heads with this one on August 25. After failing to reproduce the behavior, he wrote up our collective experience [1] the next day. We chalked it up to yet another Windows Insider screw up, marked it as an unsolved case, and moved on.I certainly hope the change eventually makes it into the OS before the Windows 11 \"23H2\" release is finalized (imminent).[1] https:&#x2F;&#x2F;www.thurrott.com&#x2F;paul&#x2F;287711&#x2F;scaling-back-the-terrib... (pay-walled) reply eganist 5 hours agoparentI remember when we first found out that IE could be \"uninstalled\" from Windows 7 (it was a checkbox in an early build&#x27;s programs list that let you have it removed, basically).Interesting seeing the about-face over a decade later.---for those not aware, Rafael&#x27;s almost a two decade long authority on the topic of smashing Windows internals to bits to see how it all works. reply hnlmorg 3 hours agorootparentI remember when we first found out that IE could be uninstalled from Windows 98 and thus what eventually lead the EU to mandate Microsoft give Windows users a choice of 3rd party browsers.Back then businesses were a lot more scared of the repercussions of anti-competitive behaviour than they are now. reply rjbwork 1 hour agorootparent>Back then businesses were a lot more scared of the repercussions of anti-competitive behaviour than they are now.Reasonably, too. Governments seem reluctant to actually regulate anti-competitive behavior these days, especially from tech giants. I think it must be a kind of technological \"too big to fail\". reply FirmwareBurner 41 minutes agorootparent>I think it must be a kind of technological \"too big to fail\".Microsoft was still big even back then, and yet they got regulated. Bell&#x2F;AT&T was also a giant monopoly and it also got broken up. It seems that size wasn&#x27;t the problem. reply midasuni 1 hour agorootparentprevBig businesses have more resource and more ability to manipulate the public than democratic governments reply isanjay 56 minutes agorootparentBig businesses buy politicians too... replysandworm101 16 minutes agoprevEvery day of bad new for Microsoft and Windows is another great day for Linux. You all have a choice. Make it. reply ryzvonusef 2 hours agoprevI use Edge on my laptop (because of Bing Chat, easy to use on Edge, without faffing around on OpenAI), and Microsoft still won&#x27;t stop trying to push it on me every once in a while.(on windows 10, because of TPM1.2, small blessings)Like chill, you already got me. I am not going to remove Chrome and Firefox, but you are the default browser already and I use Bing too, now go away. reply fhd2 1 hour agoparentA: \"Edge conversations are up 4%! What else can we do to increase them?\"B: \"Users that already have Edge as their default browser also see these, shouldn&#x27;t we first fix that?\"A: \"That wouldn&#x27;t increase Edge conversions, would it?\"B: \"No, but...\"A: \"Then we don&#x27;t have time for that. What can we do to increase them?\"Been there - not at Microsoft, but it&#x27;s not particularly unique to them. reply prmoustache 11 minutes agoparentprevI uninstall edge from my laptop when bing search started to open a chatGPT prompt instead of showing me related links. reply mlazos 15 minutes agoprevThis stems from modern companies’ obsession with measurable impact. If it can’t be measured it might as well not exist. Unfortunately UX has to become very very bad before the effect is measurable (losing users) and by then it is much too late, especially when the company has near monopoly power. I hope they figure out that they need to make feedback easier to gather so that they can get back to making good products. reply doyouevensunbro 7 hours agoprevI’m using Windows 11 and nothing forces open Edge on my machine. Every link opens in Brave like I told it to. reply antiframe 6 hours agoparentWhat happens when you press Win, type a query, then press enter, quickly? In Win 10 that opens a Bing search in Edge for me, no matter what settings I try. Very annoying when I type \"(Win)chr(enter)\" to open Chrome and get a search instead. If I do it slow it will sometimes work.I haven&#x27;t tried it on Win 11 because that was what caused me to drop Windows altogether. (Everyone has their straw). reply yard2010 23 minutes agorootparentA while ago I uninstalled IE from my pc. I&#x27;m not sure how, but now when I do what you say nothing happens. It says \"search the web\" but I guess it can&#x27;t find IE so it just fails silently. It took me a while to recall that I uninstalled IE in a tantrum in the past so that puzzled me for a while reply valzam 5 hours agorootparentprevI have the same issue but even worse: If I do it too fast it works! Somehow it takes longer to find the app than it does to suggest a websearch, so I need to wait 1-2 seconds after typing not to open edge... reply stevage 3 hours agorootparentprevI use Windows 10. I&#x27;m not sure what settings I applied (I did do quite a few), but I don&#x27;t get that.If I do Win+aoeuaoeu+enter, nothing at all happens. It just sits with a search box open showing \"No results for aoeuaoeu\". I can&#x27;t actually see any way of getting to a browser search window from there (whether my preferred browser or not). So I must have found some way to disable that behaviour completely. Keep trying?(FWIW yes that is the way I open my browser: win+fire+enter. Nothing bad happens if I do it too fast.) reply 0dayz 2 hours agorootparentI believe you&#x27;ve disabled Cortana or \"search the web for result\". reply magicalhippo 1 hour agorootparentprev> What happens when you press Win, type a query, then press enter, quickly?Also on Win 10. I get, in the start menu, \"no results for \". I know I turned of web searching when installing, but it&#x27;s been so long I might have used registry keys[1].[1]: https:&#x2F;&#x2F;answers.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;forum&#x2F;all&#x2F;how-to... reply LilBytes 6 hours agorootparentprevThe last time I checked, you can&#x27;t change this to use anything but Edge either. reply doyouevensunbro 5 hours agorootparentprevI launch apps from the Win key all the time, never ending up in Edge. The worst for me is ending up in “Internet Options” when I want to launch IntelliJ. reply kbrosnan 6 hours agoparentprevTry opening help or press F1 with the desktop in focus. This normally opens Edge. reply doyouevensunbro 5 hours agorootparentDon’t ever hit the help menu. So the problem is that MS opens help in it’s own browser? That complaint seems disingenuous at best. reply aarong11 4 hours agorootparentExcept edge then opens and presents you with some message about setting it to the default browser (which a lot of people will just click ok to make it go away) reply alkonaut 3 hours agorootparentThat an internal OS system (help) opens in the OS browser I&#x27;m willing to accept. That every browser says \"please please make us the default browser\" is annoying but hardly unique for Edge. This is just the combination of the two.I don&#x27;t think enough people use Win+Type+Enter queries, nor F1 help in Windows to make the discussion very interesting compared to the really interesting ones like which browsers will open a hyperlink in a non-browser app. reply cedilla 3 hours agorootparentEdge is the only browser that periodically captures you in a full screen multiple pages nag screen when it&#x27;s not default. It&#x27;s also the only browser able to set itself as default without further interaction.It&#x27;s not behaving the same as any other browser. reply vladvasiliu 1 hour agorootparentIt does that when it&#x27;s the default, too. I only occasionally use Windows, so couldn&#x27;t be bothered to install something else. Yet, I feel that every other time I start it, I&#x27;m presented with some \"use edge! it&#x27;s so cool!\" screen I have to sit through. It also insists on changing the search engine to bing. I&#x27;m usually pretty cautious and try not to press \"ok\" just so it leaves me alone, yet it managed to change it. For my needs, pretty much every search engine is good enough. I prefer google since I can convince it to use dark mode and use English instead of my local language (even though windows is set to use English as its display language). reply ben0x539 1 hour agorootparentprevHow is it more acceptable because it&#x27;s a combination of two things? Lots of objectionable outcomes are a combination of multiple factors! reply tentacleuno 4 hours agorootparentprevExcept the same is applied to the start menu, help pages, system links, just to name a few. reply kbutler 6 hours agoparentprevThe windows spotlight links from the landscape photos on my windows lock screen always open edge. I haven&#x27;t dug in enough to find if there is a way to change that. reply yathaid 5 hours agorootparentI dug through a bit (in mid 2022) and there isn&#x27;t a native way to do this. You will have to use edge deflector or something like that. I am not sure if the brave&#x2F;firefox intercepts added more recently work.This drove me so mad I bought a Mac mini to replace my surface pro (which I wasn&#x27;t using as a tablet anyway). Good job MS! reply lacrimacida 2 hours agoprevMy wife’s laptop just upgraded itself to windows 11 pro form 10 pro unasked & unsolicited and all prefs were changed to microsoft traps including edge being the default. Dark patterns galore. Luckily I could revert back to the previous version. reply hackerlight 1 hour agoparentI spent 2 hours trying to uninstall Edge unsuccessfully then decided to live with it. reply rekoil 1 hour agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;rcmaehl&#x2F;MSEdgeRedirect is a decent band-aid on the problem. reply dustedcodes 2 hours agoparentprevGood husbands don&#x27;t let their wives use Windows. reply lacrimacida 1 hour agorootparentShe needs it for some software at work so I decrapified as much as I could and decided to go along but it’s a never ending battle with Microsoft’s agressive force. I wouldn’t force her with Linux and Mac is not something I am familiar with. reply ClassyJacket 1 hour agorootparentprevGood husbands don&#x27;t force their wives to wrestle with random daily problems like screen brightness not working on Linux because of their personal tech politics. reply dustedcodes 56 minutes agorootparentMacBook Air M2 should be the choice for any normal person who just needs to get normal work done. No politics, but clearly I&#x27;ve touched an insecurity here :&#x2F; reply stevemk14ebr 40 minutes agorootparentinsecurity lol. You made an unbased claim and retort with &#x27;insecurity&#x27; when challenged. All operating systems have pros and cons, and people have preferences. replytheusus 5 hours agoprevI want the Chrome to stop being the majority shareholder of the market. But not like this. reply no_wizard 5 hours agoparentEdge is effectively chrome under the hood. It’s not doing much for browser diversity reply theusus 1 hour agorootparentChrome does its own stuff. Lately, they added a tracking different from cookies, something that Brave has said they won&#x27;t be adding. I want the market to segregate at every level. reply martinsnow 5 hours agorootparentprevExactly. If anything Edge, Brave and other Chromium browsers gives a false sense of healthy competition. reply mherrmann 1 hour agorootparentI view Brave as very healthy competition to Chrome and Edge. Yes, it&#x27;s based on Chromium. But it disables the many egregious privacy violations, as well as other bad things. reply mythhabit 1 hour agorootparentAnd whatever Google decides they want to implement or support in Chromium will be the web default, even just how they interpret ambiguities or undefined behaviours - standards be damned. We have tried this before and it was not pretty.That is why we need competing browser implementations. reply yard2010 12 minutes agorootparentI&#x27;d argue for the opposite - we need strong standards and some methods to strictly enforce them. Governments could do that but the level of incompetency and politics are huge roadblocks replybrucethemoose2 5 hours agoprevI used to be ambivalent about Edge. It actually has some nice integrated features I would normally need (slow) addons for, and better integration in Windows features (like better DRM for video streaming).I even used it in linux some....But I just recently tested it on a brand new Windows desktop, and I can&#x27;t believe how slow and spammy it feels out-of-the-box compared to Thorium&#x2F;Chromite now. reply biogene 7 hours agoprevI don&#x27;t care for edge for the most part, but there is actually one integration with edge that I have come to like. When I click on an email link inside outlook, edge opens the link, and also displays a sidebar which displays the email. Super handy IMO.Somehow we need to find a balance that allows vendors to tightly integrate their apps but prevent abusing this.MS is everyone&#x27;s favorite whipping boy, but I fear what kind of ads Google while shove through if they ever get a dominant market share in desktop OSs. Apple seems to be the only sensible alternative. reply saghm 7 hours agoparent> Somehow we need to find a balance that allows vendors to tightly integrate their apps but prevent abusing thisA vendor of a web browser and email client, sure. A vendor of an operating system and one (or both) of a web browser and an email client, hell no. If anything, an operating system should be forced _not_ to tightly integrate to vendor-specific apps and instead should provide integration loosely and in a way a user can plug in their choice of app (or disable entirely). reply Spivak 5 hours agorootparentI do think people like Dolby Atmos, Android Auto, Airdrop, SMB, systemd, the whole of SteamOS and I think when you get down to it \"tight integration but I don&#x27;t like it\" is the only definition you&#x27;ll get that actually will encompass what people mean. Because what makes Springboard on iOS okay when on Android you can have Nova? What makes NFS okay to build in the kernel but not Airdrop? What makes Steam&#x27;s overlay browser okay to tightly integrate but not Edge?The whole OS is a mess of tightly coupled software with messy boundaries. I don&#x27;t think the coupling is the thing that matters. reply clhodapp 5 hours agorootparentDolby Atmos, at least, sounds good but it&#x27;s pretty annoying because it&#x27;s had the practical effect of making height channels proprietary in most systems.Springboard definitely isn&#x27;t OK.There&#x27;s no good reason that Airdrop shouldn&#x27;t be in the Linux kernel and it probably would be if the protocol were well documented.You can use game overlays other than the Steam one, so there&#x27;s nothing stopping Microsoft from creating an overlay that provides the Edge browser.Rich integrations are great but when the boundary is perceived by the user as being two different programs or systems, both sides of the integration should have well-documented public interfaces that support swapping out the other side (no \"private API\" funny business). reply BuckRogers 3 hours agorootparentprevAt a certain point, you’re pretty much asking for socialism. No one should be obligated to build an entire operating system that works on billion combination of potential parts, and then cater to everyone else so that they get the native experience in every way integrating with the OS.Obviously, I want the best experience as an end-user. But I think it’s ridiculous, at a certain point you should have to invest the billions of dollars to build your own equivalent operating system. You really can’t expect all of that. Microsoft already has a pretty flexible system.Maybe there is a business model for that massive investment. I don’t think that 100% native integration for third party applications is a big draw to most people. It’s mostly something people complain about on this forum.Proof of that is Apple. It’s relatively inflexible, and people seem to like it quite a bit. They are doing very well. Then there’s also Linux but then people complain things aren’t tightly integrated enough.Basically people want to have their cake and eat it too on someone else’s 1 billion dollar investment. reply FireInsight 3 hours agorootparentYour comment is ridiculous to me. We have Linux, probably supported on billion combinations, not too closely integrated with \"vendor-specific\" things. It&#x27;s also free to use and free software, constantly being improved and extended by people around the world.I don&#x27;t much care about Windows, but as someone who has to use it for certain work I feel like I have the right to complain about Microsoft trying to force it&#x27;s other products on me. And they probably could survive by having their OS be a bit more end-user friendly,, and if they couldn&#x27;t, we would use some other OS. reply makapuf 3 hours agorootparentprevI think you should be able to embed a browser with your os (the browser is almost part of an os now, and there can be links between those integration), but not prevent 3rd party browsers or tie services to your browser. There is no technical reason for bing. reply foxylad 7 hours agoparentprevSad you didn&#x27;t see Linux as a better alternative to OSX. I credit it with making me at least 10% more productive over the twenty years I&#x27;ve used it, partly because it is stable and fast, but mostly because it isn&#x27;t trying to sell me stuff while I work. reply smt88 6 hours agorootparentMy experience is the opposite. I spent 15 years on Linux desktops until finally switching to Windows for the sake of my producivity.I&#x27;ve seen promoted links in Win10&#x2F;11, but never anything that harmed my productivity. Most importantly, the OS just fades into the background. I never think about it.Linux required almost-daily googling and opening up a terminal to fix or change something. It became maddening eventually. reply bachmeier 6 hours agorootparent> Linux required almost-daily googling and opening up a terminal to fix or change something.I usually try to avoid discussions of the OS, since it&#x27;s such a terribly boring topic. However, this is quite an extraordinary claim that is made without any details. Perhaps you could elaborate. As someone that has used various Linux distros for nearly twenty years, I don&#x27;t think I could construct a scenario in which someone doing the usual things has to open a terminal to \"fix or change something\" on a daily basis. It&#x27;s probably less than once a year that I have to fix anything on my Linux desktop computers.Did you build your own Linux distribution? Were you running IT at a company with 50,000 Linux desktops? Were you testing the development version of a desktop environment? reply squeaky-clean 4 hours agorootparentIt&#x27;s 2023 and I still can&#x27;t get a Dell laptop with Linux pre-installed to sleep properly without crashing without editing things in the terminal and mucking about in the bios.Even giving up on that and disabling sleep on lid close requires using the terminal. Sure the Gnome Tweaks tool has a setting for that but it&#x27;s not installed by default and check the comments here, it doesn&#x27;t actually work.https:&#x2F;&#x2F;askubuntu.com&#x2F;questions&#x2F;15520&#x2F;how-can-i-tell-ubuntu-...https:&#x2F;&#x2F;www.dell.com&#x2F;support&#x2F;kbdoc&#x2F;en-nz&#x2F;000179566&#x2F;how-to-di... reply dspillett 48 minutes agorootparentIt is 2023, and they seem to have completely broken hibernate on Windows. Didn&#x27;t work reliably for a while, intermittently failing to wake up correctly in various ways, one of those ways being a black screen with no choice but to reboot¹, and it seems to have vanished as an option on most (maybe all) laptops I&#x27;ve used recently².And sleep doesn&#x27;t always stay slept. We&#x27;ve had machines wake up in bags so when later needed they have near flat batteries and are nice & toasty³.So sleep&#x2F;hibernate not working right is hardly a significant difference when comparing Linux to Windows. In fact one of the laptops I had trouble with did sleep and hibernate properly when Linux went on it for a while, so at least sometimes the difference is not in favour of Windows.----[1] the couple of times that happened to me, the machine would still work via RDC and other such so an orderly restart could be arranged if I had another machine on the same network, but if I had no such machine available like when travelling a hard-reset had to be forced[2] I&#x27;m told you can force it to be available again, but I assume the removal is an admission that is doesn&#x27;t work properly so enabling it is risky[3] being in a bag isn&#x27;t great for cooling airflow! reply gokhan 3 hours agorootparentprevMy son got a Lenovo T16 AMD for school, wanted to go with Kubuntu and spent one week setting up hibernate. Only solution that works is still hacky, he runs a script that disables then enables some things after returning from hibernation to make networking work.This, on a machine that you can buy with Linux. reply sam345 6 hours agorootparentprevI believe it. I&#x27;ve used linux desktops for 20 years also and command line is definitely a must on a daily basis. Ive also used Windows and agree that it just fades into background. Windows 10&#x2F;11 definitely less paiinful on the desktop. These days with better integration with and tools for Linux cli, Windows is definitely my preferred gui productivity environment. Many Linux fans don&#x27;t know better or won&#x27;t admit it because hate tends to blind. reply modo_mario 1 hour agorootparent>I&#x27;ve used linux desktops for 20 years also and command line is definitely a must on a daily basis.What were you using if I may ask? I use manjaro with plasma and.... idk I really don&#x27;t have to use the commandline much if at all when i&#x27;m not coding. Last time I was forced to was a few months ago in fact with an old niche wifi dongle that didn&#x27;t work without some tinkering but this now works out of the box as well. reply bergon 4 hours agorootparentprevCould it be because you&#x27;re more comfortable with the CLI than any GUI alternative? E.g. I wouldn&#x27;t go clicking about for installing packages when it&#x27;s just one line away.I know many power users of Windows that bring up their terminal frequently as well. reply mixmastamyk 5 hours agorootparentprevI just set up Windows and spent an entire week googling how to tame it. Turns out dism.exe at the CLI is required to make it free up 20 to 30GB! of disk space it was wasting.Many, many hours and late nights figuring out how to turn off telemetry, Edge and more. Multiple Group policy editor settings to force it to do what is asked and no more. For some reason updates and uninstalls take forever and uninstalls can’t be batched. (A powsh I found didn’t work) I could go on…“Fades in the background” my ass. :-P reply mrweasel 4 hours agorootparent> spent an entire week googling how to tame itPart of the reason Windows doesn&#x27;t fade into the background for you is that you insist on fighting it, you&#x27;re tweaking stuff you should just leave alone... according to Microsoft.Physically it&#x27;s not possible for me to use Windows, my hand cramps up, not completely sure why that happens, but it provides a constant physical reminder that I&#x27;m using Windows. reply anothernewdude 5 hours agorootparentprevNonsense. They&#x27;ve moved so much stuff about all my windows knowledge from 7 is useless. You&#x27;ll be in the same spot when 12 comes out. reply kuboble 3 hours agorootparentprevI think when you are such a proficient user of some technology you don&#x27;t even realize how many mistakes you can make along the way. And some small annoyance that you don&#x27;t even notice might be a burden and a day-long struggle for someone less experienced.As an example of such a behavior on Windows. My customers (too often) complain that my console-based program suddenly stopped and they tried everything and can&#x27;t make it to restart.The problem is that they don&#x27;t realize that selecting some text in the window blocks the stdout and the program won&#x27;t continue until they remove the selection.So for a more experienced user it&#x27;s nothing, but for someone new to terminal behavior it&#x27;s a huge obstacle.On Linux you have much more traps like that. reply rendaw 2 hours agorootparentGP said 15 years though, not exactly someone less experienced. reply dspillett 1 hour agorootparentI know people who seem to have managed to have the same year of experience 15 times over, learning nothing along the way…Time spent is not necessarily experience, especially if you are trying to do something else at the time. In this case trying to do DayJob so not having time&#x2F;care to commit much operating system management knowledge to memory, which is more understandable than the people mentioned in my first sentence who were failing to learn what was their job. reply topaz0 5 hours agorootparentprev> [Windows 10&#x2F;11] fades into the backgroundI strongly disagree with this. When I am forced to use windows, I am constantly fighting with it to not be obnoxious. It takes many seconds to do something as simple as bring up an explorer window. I can&#x27;t count the number of times I have had to dig into menus to disable this or that ad panel or other bloatware. In linux, I occasionally have to figure out how something works and fix it, but there are generally many months between those events, when everything just works and gets out of my way. reply Thlom 3 hours agorootparentJust took me 0.5 seconds to bring up an explorer window.I&#x27;ve mostly used OS X and Linux the last 25 years, but have been forced to use Windows at work and recently on my gaming computer, so I&#x27;m not really defending Windows here. But honestly, I don&#x27;t have any big problems with it. It works OK for the most part. reply Novosell 3 hours agorootparentprevWindows key+E opens explorer. Or do you mean that it&#x27;s so slow that it takes several seconds? reply dspillett 1 hour agorootparentOn my work machine (approx 4 years old, Win10) and home machine (mostly 2 years old, graphics card, a 1060&#x2F;6GB is more elderly, Win10) both take most of a second to bring up a fresh Explorer window, timing by eye from Win+E to the whole UI being present. It seems far more variable (sometimes feeling quicker, sometimes taking a couple of seconds) on my laptop ( Linux required almost-daily googling and opening up a terminal to fix or change something. It became maddening eventually.Really? What kind of things do you have to google for Linux to work these days? The opposite is true for me in Windows, I am not about to relearn how to use the Windows terminal. reply jwells89 5 hours agorootparentIn my personal experience it&#x27;s usually random little things that technically work but not quite right, and occasionally it&#x27;s stuff that&#x27;s just outright broken.There&#x27;s also been a fair amount of googling for how to set up X in Linux to do Y only to find a trail of half-functional or abandoned packages. Getting global menus set up in your DE of choice for example takes a surprising amount of twiddling and even at its best doesn&#x27;t work with a lot of software. Getting everything functioning as expected with a minimal WM setup is also a surprising amount of work (e.g. laptop volume keys not working if some daemon isn&#x27;t running). Admittedly it&#x27;s not as bad if all your want is a Win9x-type or iPad-type desktop. reply bergon 4 hours agorootparentIt&#x27;s frustrating that you can&#x27;t change DE in Windows though, and that it changes from version to version. reply anticensor 2 hours agorootparentYou actually can, but there is no viable alternative DE. If only KDE had a Win32-free build for Windows. reply bergon 1 hour agorootparentI didn&#x27;t know that, thanks for mentioning. It&#x27;s apparently called shells in Windows lingo: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;List_of_alternative_shells_f... reply simion314 4 hours agorootparentprev>Getting global menus set up in your DE of choice for example takes a surprising amount of twiddling and even at its best doesn&#x27;t work with a lot of software.And is one click and works with all apps in Windows ? reply brian-armstrong 6 hours agorootparentprevI don&#x27;t think I agree with this. I left Macos for Linux a few years ago and the first month was pretty frustrating, but it got much easier after that. I think it does help to invest time in making it work though. On the upside, I&#x27;ve had many fewer instances where an update suddenly breaks things and causes me to stop working unexpectedly to fix them. reply deafpolygon 4 hours agorootparentprevI&#x27;ve had the same experience. Linux just requires too much babysitting for me, while Windows 11 just works. I haven&#x27;t had any major problems nor any issues with my productivity. reply codebolt 3 hours agorootparentprevMy 8 year old son inherited an old laptop this week, that was too slow to consider installing Win 11, so I ended up loading it with XUbuntu. The first thing I did was actually to install Edge, because that makes it possible to monitor his web browsing using MS Parental Controls. I actually think it&#x27;s a good browser, certainly better than Chrome (too bloated) or Firefox (too buggy). I&#x27;ll never understand HNs relentless hatred for all things MS. reply makapuf 3 hours agorootparentWhen a company uses dirty tactics against your project, forcing its (at the time) inferior product by strong arming pc vendors, call your project a Cancer and tries to undermine java and the Web and has been found guilty on court, some animosity is in order. Yeah its been a long time. Seeing current practices, not so much it seems. reply devsda 3 hours agorootparentprevWhat are these bugs that people encounter that often in Firefox?I&#x27;ve been using using Firefox on Linux and Mac for a long time now and I&#x27;m yet to see any bug(a rare occurrence) that is a show stopper(for me atleast). reply Zetobal 1 hour agorootparentI guess the \"best viewed with\" and \"please use the last version of chrome\" banners preventing you from logging in some services could be seen as a bug from normal users. reply S201 3 hours agoparentprev> Apple seems to be the only sensible alternative.My Arch box has never once tried to display an ad to me, or coerce me to use any particular piece of software for that matter. reply lionkor 2 hours agorootparentI have to +1 very loudly for Arch. It has an absolute dream of a documentation. Any configuration or cache paths are default, the distro doesnt try to fuck with it like Ubuntu and others do - you do `man mytool` or look at the official docs for that tool, and if that says the config is at &#x2F;etc&#x2F;monkey&#x2F;mytool.conf, it is.The package manager works well.The installer is very solid by now.It comes with absolutely nothing preinstalled, perfect for techie people. reply hutzlibu 1 hour agorootparentAnd if one likes the Arch way, but a graphical installer and some things taken care of for you, I recommend EndeavourOS. reply zik 5 hours agoparentprev> I fear what kind of ads Google while shove through if they ever get a dominant market share in desktop OSsMicrosoft already forces ads on Windows users so I guess it&#x27;d be something like the current situation. reply herdcall 5 hours agoparentprevYeah, I&#x27;ve been using all kinds of browsers (Chrome, Brave, Edge, now Firefox) on Windows old and new (now on 11), never had any real issues. I don&#x27;t even remember nudges to use Edge, to be honest, may be there was one after an OS update. Edge is actually really good now, with tight Bing chat integration, but the last dev version has been sluggish on occasion. reply l33t7332273 7 hours agoparentprevUbuntu is very usable for a desktop OS. reply mackrevinack 2 hours agorootparentpersonally i would recommend zorin os before ubuntu since it has a similar desktop layout to windows or if someone doesnt care about that then pop os is decent as well reply petre 5 hours agorootparentprevExcept they too pushed ads (ubuntu advantage) and snap and other annoying stuff. reply diffeomorphism 5 hours agorootparentWindows: ads in the start menu, candy crush, hey you are trying to install chrome and I don&#x27;t like that.Ubuntu: one line message in the terminal about we releasedthing, feel free to try it.Yeah, basically the same thing. reply c0nducktr 4 hours agorootparentIt&#x27;s the same thing, just one company has taken it further. I realize this is a slippery slope argument, but when there are countless examples of how this slopes is slippery, I think it&#x27;s a valid point of contention. replypiyh 8 hours agoprevI gave my old parents the latest hand-me-up laptop and installed ubutntu on it because of windows 11. The install process and default configuration is so user hostile to someone that \"just needs to use chrome\". My niece & nephew have only known ChromeOS&#x2F;iOS&#x2F;Android. They will never use windows until a college course requires some specific software, or they get a desk job. I think they will for sure eventually \"learn windows\", but I don&#x27;t think the generation behind them will.I get the feeling more and more that peak Windows is upon us. reply nyanpasu64 7 hours agoparentUbuntu is now bundling advertisements for their paid services in apt upgrade output and the GUI software sources manager, in packages which cannot be uninstalled because they&#x27;re hard dependencies of the `ubuntu-desktop` metapackage. Plus they&#x27;ve replaced Firefox with a package which installs a Snap, which loads so slowly they added a \"snap opened\" notification. reply severino 1 hour agorootparentDo you mean you should just stick with Windows because Ubuntu now prints a line in your console when you apt-get upgrade telling you that Ubuntu Pro exists? reply ploxiln 5 hours agorootparentprevFWIW there&#x27;s really nothing wrong with uninstalling this kind of metapackage. I&#x27;ve been uninstalling the \"ubuntu-desktop\" metapackage as I trim my ubuntu systems, for over a decade. I use a combination of \"debfoster -n\" and aptitude for the trimming ... it is a bit annoying but it&#x27;s just once per install.That said, for the past couple years I&#x27;ve just run Debian and Arch. But I&#x27;ll probably use ubuntu again for a while when I get a new framework laptop later this month, the hardware is too new, some special&#x2F;custom kernel package provided for the latest ubuntu will probably be the most convenient solution initially, and I find trimming back ubuntu isn&#x27;t too bad. Yes, you have to remove the \"desktop\" meta-package. It&#x27;s fine. reply hutzlibu 1 hour agorootparent\"It&#x27;s fine.\"No, it is not fine, that I have to fight my OS. It is managable if one has some skills with computer like we do, but it is not fine in general. I would like to trust the operating system I use. reply physicles 7 hours agorootparentprevThis is one of the reasons why I stopped using Ubuntu and switched to pop os. Is there something keeping you from switching to another Debian derivative? reply k12sosse 7 hours agorootparentHonest question, why not just Debian and use a derivative instead? I took a 20 year sabbatical on Linux in the home. But with windows 11, I decided to go back. Stopped on debian, and chose Debian when I came back. I am super impressed with how it has matured and it seems to be built in a way that really does a fair job on looking out for you as a user, and as an administrator. reply p1necone 7 hours agorootparentThe main problem with Debian is outdated software. For servers the fixed release cycle is great, everything is properly tested and it should be rock solid without really needing to touch it.But for a regular desktop&#x2F;workstation system I want more frequent software updates even if it comes at the cost of a little stability.(Of course there&#x27;s Debian unstable, but I&#x27;d rather go with a distro where the rolling release is the main product, and they maybe do a little more testing before making changes) reply Jedd 49 minutes agorootparent> The main problem with Debian is outdated software.I&#x27;m a Debian user. I see this a lot. Often in contrast with Ubuntu.Yet Debian&#x27;s cycle is roughly on par with Ubuntu&#x27;s LTS - every ~2 years.[0]Perhaps they mean there are interim releases in Ubuntu? It&#x27;s hard to say for sure, as the phrase &#x27;outdated software&#x27; can mean different things (more than 6 months old, more than 2 years old, in need of a security patch for > 1 week, etc).> But for a regular desktop&#x2F;workstation system I want more frequent software updates even if it comes at the cost of a little stability.This sounds like you want Debian Testing (currently Trixie).Much more frequent software updates, with an extremely small risk of less &#x27;stability&#x27;.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Debian_version_history reply jwells89 6 hours agorootparentprevThis point is particularly pertinent if Debian isn&#x27;t the only OS you&#x27;re using. It can be problematic if the software on your Linux machine is more than slightly behind whatever is on your Win&#x2F;Mac machines. reply senknvd 6 hours agorootparentprevI find that Flatpaks[1] work really well for getting the latest version of GUI-only apps. For CLI tools and libraries I haven&#x27;t found a great solution but I make do with an Arch Linux distrobox[2] container.[1]: https:&#x2F;&#x2F;flathub.org&#x2F;setup&#x2F;Debian [2]: https:&#x2F;&#x2F;packages.debian.org&#x2F;bookworm&#x2F;distrobox reply andrewaylett 46 minutes agorootparentFlatpak is great, and Homebrew works nicely on Linux for other bits and pieces. Linux support made it upstream to https:&#x2F;&#x2F;brew.sh, so you get all the same things you&#x27;d get on a Mac. reply HKH2 3 hours agorootparentprevWell there are backports for some packages that require updates due to API changes etc. reply retrocryptid 7 hours agorootparentprevStock Debian has been pretty decent recently. I was surprised to find it either didn&#x27;t require proprietary blobs or installed them when I wasn&#x27;t paying attention.I&#x27;ve also been playing around with BSD and it&#x27;s like hanging out with a friend from elementary school: they&#x27;re a little wonky, but you remember some good times together.PopOS isn&#x27;t my favorite, but it is pretty straight-forward. If it&#x27;s working for you then it&#x27;s a total win. (Which is my way of saying \"though I like Stock Debian and BSD, there is absolutely nothing wrong with PopOS.\") reply 29athrowaway 7 hours agorootparentprevIf they keep messing it up, you can try Arch Linux. reply taftster 7 hours agoparentprev> I get the feeling more and more that peak Windows is upon us.Probably. But I don&#x27;t think Microsoft cares. Just look at where Windows is in their org hierarchy; it&#x27;s definitely not top dog anymore and it&#x27;s not a \"strategy\" like it once was.The days of Microsoft needing Windows to make money are behind us, that&#x27;s for sure. Peak Windows is probably correct, but that fact is not going to usher in Microsoft&#x27;s demise. reply richiebful1 6 hours agoparentprevI&#x27;m a &#x27;non-traditional&#x27; student (25) and my fellow students are normal undergraduate age (19).Half are having a hard time with learning some of the CAD software because they lack the experience with full featured Desktop OS&#x27;s like Windows&#x2F;Linux&#x2F;Mac. It&#x27;s surprising how fast generational change occurs reply Thlom 3 hours agorootparentI&#x27;ve heard the same from university staff. The last few years many new students are having problems with the simplest stuff like uploading their course work into whatever educational platform the university is using because they have no grasp of the concept of a file. reply cmcaleer 33 minutes agorootparentDirectory structures is the ‘skill’ I’ve been hearing a lot of complaints about students not understanding. Particularly annoying for those teaching first year undergrad SWEng, since the gap between those self starters who have some idea of what’s going on and those who don’t really care and we’re pressured into it by parents is larger than ever.It’s pretty unfair on those who have done the bare minimum amount of experience with computers that they have to sit through (and pay for!) being taught ‘this is what a file structure is and how it works’ for a not-trivial amount of time. reply brian-armstrong 6 hours agorootparentprevWhat, you mean CAD software didn&#x27;t fully migrate to iPads? ;) reply fh973 5 hours agoparentprevWindows is effectively also the reason for the modular PC platform to exist. If peak Windows also means peak modular hardware, it&#x27;s a dim future with closed Apple and Android-style hardware. Nothing&#x27;s composable, OS is bound to the specific piece of hardware. reply Zetobal 2 hours agorootparentIntel just announced that they will be putting ram on the package with their next gen CPUs... reply p1necone 7 hours agoparentprevUbuntu kinda sucks now too. \"Sign up for an account\" is part of the install flow just like Windows.Fedora is my default \"easy\" Linux install nowadays, the excessively corporate vibes I get from Ubuntu feel very wrong for a Linux distro. reply The_Colonel 3 hours agorootparent> \"Sign up for an account\" is part of the install flow just like Windows.There&#x27;s nothing wrong with providing an easily skippable option to do that (ubuntu), a completely different thing to make it a mandatory part of the installation (windows). reply backendanon 7 hours agorootparentprevFirst, there&#x27;s nothing overbearing about the Ubuntu install.Second, Fedora uses rpm management, rpm repositories sooner or later corrupt themselves, happened to me and others I know on Red Hat, on Fedora and on SuSE.I&#x27;d use Debian but I&#x27;ve found Ubuntu&#x27;s driver management to be far more stable and reliable, especially for WiFi. reply tkuraku 7 hours agorootparentExact opposite experience here. RHEL and friends have been much more stable reliable for me than Ubuntu. reply doubled112 7 hours agorootparentprevDebian started shipping firmware in the main ISO this release. It mostly just works except Nvidia now, and even that&#x27;s just an apt install away.Does that make it any easier? You can download a live version and test instead of needing to find that firmware included release. reply RankingMember 7 hours agoparentprev> I get the feeling more and more that peak Windows is upon us.If only. I remember people saying the same when Vista came out. reply userbinator 7 hours agoparentprevI recommend to switch them to Firefox instead. reply alexfromapex 6 hours agoparentprevI hope so, Microsoft is a terrible monopolistic company and the PC landscape would be better off without them. reply ZoomerCretin 6 hours agoprevI&#x27;m surprised no one has brought up United States v. Microsoft yet. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_v._Microsoft_Cor....They were successfully sued for favoring their browser over others, and faced being broken up. Though their actions now are not as egregious as those actions 25 years ago, it&#x27;s obvious that no lesson has been learned. reply yard2010 6 minutes agoparent> On June 28, 2001, the Circuit Court overturned Judge Jackson&#x27;s rulings against Microsoft. This was partly because Jackson had improperly discussed the case with the news media while it was still in progress, violating the Code of Conduct for American judges.[24] The Circuit Court judges accused Jackson of unethical conduct and determined that he should have recused himself from the case.Lol. reply dns_snek 22 minutes agoparentprev> Though their actions now are not as egregious as those actions 25 years agoHow so? They still bundle a browser, but now they go a step further and actively ignore user-selected preferences for the default browser. reply perihelions 3 hours agoparentprev- \"their actions now are not as egregious as those actions 25 years ago\"Which part of the other case do you view as more egregious? They seem similar to me. reply zeusk 4 hours agoparentprevThey did learn a lesson; from Google and Apple. reply charcircuit 5 hours agoparentprevMicrosoft successfully appealed it. reply RektBoy 1 hour agoprevWin10 in professional use turned me into Linux user. Sorry but I always lol&#x27;d people, when their box stopped working because of pending win update, ridiculous.I&#x27;m running a lot of Win builds on VMs for debugging etc. and it&#x27;s enough for me. reply fortran77 8 hours agoprevHorrible! At least Apple doesn&#x27;t force Safari on iOS users. reply koito17 7 hours agoparentThey indeed don&#x27;t; they force browsers to use the WebKit engine instead. And comparing iOS to Windows is a bit unfair: one is a mobile operating system whereas another is a desktop operating system. You should compare what Windows forces on its users with what Mac OS forces on its users.With that said, Mac OS isn&#x27;t entirely innocent either, such as giving users a \"Try The New Safari\" notification when they run a non-Safari web browser on their machine.[1][1] https:&#x2F;&#x2F;lapcatsoftware.com&#x2F;articles&#x2F;TRYTHENEWSAFARI.html reply izacus 6 hours agoparentprevDid you.... forget the &#x2F;s sign? These days it&#x27;s hard to figure out whether people are serious or satirizing on this website. reply freeAgent 7 hours agoparentprevThey force the engine, which is bad, but much less bad (IMO, at least) than forcing a full-blown browser full of insanely privacy-invasive defaults on users. reply voxelghost 7 hours agorootparentAnd they only force the engine on iOS, not Mac OS, as far as I know. reply freeAgent 7 hours agorootparentYes, on MacOS you can use whatever browser you like, engine and all, while being unmolested for favoring something not-Safari. That’s why, after a lifetime of being a Windows user, my most recent PC purchase was a MacBook Air. I would prefer to use Linux, but where I’m at in my life, I just want something that works relatively well out of the box, and I use some software that won’t run on Linux. reply kbrosnan 6 hours agorootparentThere are still ads for Safari if you use something else. MacOS will pop up a notification recommending Safari for battery savings. reply freeAgent 5 hours agorootparentYeah, they do ask you to stay, but compared to what MS does, it’s nothing. They could be better, of course, but they aren’t in the same league with MS&#x2F;Edge nags and abuse. reply6510 1 hour agoprevThey finally convinced me to try bing chat. Made a shortcut like so:microsoft-edge:https:&#x2F;&#x2F;www.bing.com&#x2F;search?showconv=1&sendquery=1&form=MY02...Can also use it to create your own bing chat links on your home page.They&#x27;ve promised not to do it anymore in the EU apparently. reply daft_pink 7 hours agoprevI like windows, but really considering jumping to NixOs. Edge really feels like spyware. reply nxpnsv 4 hours agoprevHow’s this making ms any money? reply reilly3000 4 hours agoparentMore edge usage tends to translate to more Bing queries and clicks, more data, more targeting, more cross selling their services. Google as default search in Chrome, Safari, and Firefox is a major problem for #2 search engine. reply clove 4 hours agoprevI deleted Edge from my new laptop installation. Yet I now have problems opening certain apps because they rely on Edge. reply dc3k 8 hours agoprevGlad I switched to ReviOS and don’t have to deal with these shenanigans.https:&#x2F;&#x2F;revi.cc&#x2F; reply blakes 6 hours agoparentJust so everyone is aware, ReviOS disables the Spectre and Meltdown mitigations, virtualized based security, Windows Defender, turns off and hides the ability to use Windows Update (no future security updates), disables Bitlocker, etc. Many of the performance improvements come from disabling security mitigations&#x2F;processes. Just something to be aware of. I think all of these settings can be re-enabled through their Revision Tool https:&#x2F;&#x2F;github.com&#x2F;meetrevision&#x2F;revision-tool. reply dietr1ch 7 hours agoparentprevI understood more about it by reading the legal notice than the About section,About,> As a group of friends and tech enthusiasts from all over the world, we have dedicated ourselves to the idea of sharing insights and ideas freely among us. Our picture of the internet is that of a country without borders and we cherish cultural diversity without exception. We embrace the concept of open source, open knowledge and collaboration, sharing the belief among us that information should be free and never have a price tag. Where others hoard knowledge to gain an advantage, we share it and where people sell information, we give it away for free.Still I know nothing.Legal Notice,> By downloading any of these images (ISOs), you agree to Microsoft&#x27;s Terms of Service regarding (5.) Authorized Software and Activation. None of these pre-tweaked image files are pre-activated.That&#x27;s it, ReviOS must be a trimmed down Windows reply brirec 7 hours agoparentprevHuh, I thought people around these parts knew better than to trust some hacked up Windows “distribution.”At that point you might as well just use an illegitimately-activated copy of LTSC — at least you can be sure it wasn’t tampered with.Especially since installing Windows using customized install media is explicitly prohibited by the EULA of almost all Windows editions. You have to have the same sort of enterprise support contract with Microsoft that would get you access to LTSC to legally use this thing anyway. reply heywoodlh 7 hours agorootparentInterestingly, they seem to address this on their legal page[0].Despite this, it does seem like just installing Windows and then attemting to debloat post-install is the least risky option than just trusting a third party Windows installer.[0] https:&#x2F;&#x2F;revi.cc&#x2F;legal reply seanp2k2 5 hours agorootparentI used to like Blackbird for this, but after breaking updates and the Store enough times I’ve learned my lesson. O&O ShutUp10++ is all I used to debloat now, in addition to MassGrave activation. NTLite is the nuclear option if you’re prepared to invest a few hours crafting your “perfect” image. reply userbinator 6 hours agorootparentprevI thought people around these parts knew better than to trust some hacked up Windows “distribution.”That&#x27;s what the corporate propaganda wants you to think --- that you are to trust Big Tech unconditionally, including all their user-hostilities, because they are supposed to be \"good for you\" somehow.While I have no doubt that some customised ISOs may contain malware, in my experience the \"official\" malware is really no better, and I can&#x27;t think of any well-documented instances of trimmed Windows distros actually containing third-party malware, so I suspect the campaign against them, much like the similar one against cracks&#x2F;patches&#x2F;keygens, is mostly FUD to advance the interests of Big Tech. reply heywoodlh 7 hours agoparentprevAs a person who only uses Windows for gaming (I use Linux or MacOS everywhere else), I worry about these custom Windows ISOs being merely reskins of Windows. I would love to hear what you like about it -- I think I may try it out, as the sales pitch looks compelling:> It aspires to re-create what Windows as an operating system should have been - easy and simple> ReviOS [is] a capable, efficient yet private operating system reply LilBytes 6 hours agorootparentYeah I&#x27;ll do the same and report back. Might make a Show HN to talk about it.I need to better understand how updates work however, turning off auto updates is a concern. So I&#x27;ll mostly be focusing on usability and how updates are managed as part of their tooling.1st edit: Noticed a few broken links on their site regarding updates, I&#x27;ve created an issue on GH: https:&#x2F;&#x2F;github.com&#x2F;meetrevision&#x2F;revision-tool&#x2F;issues&#x2F;382nd edit: I&#x27;m not sure how I feel about disabling Windows Defender. https:&#x2F;&#x2F;revi.cc&#x2F;docs&#x2F;faq&#x2F;after&#x2F;defender&#x2F;If you&#x27;re not using Windows Defender, you&#x27;d want to use something else and I don&#x27;t know what to recommend except Malware Bytes. I do have Malware Bytes running too so perhaps it&#x27;s redundant, but as far as AVs (antivirus&#x27;) go, Defender is the best of a very broad, bad bunch. reply keyle 6 hours agoparentprevI&#x27;ve been out of the Windows world for years, but seeing a lot of games are now available on Linux, and drivers, why not build a Linux gaming PC?I mean what else would you need a PC with Windows for?This ReviOS stuff has all the smoke signals of too good to be true. reply dc3k 6 hours agorootparentI want less hassle, not more.Linux still has a very long way to go in gaming - some things still require a bunch of tweaking, some games suffer from poor frame rates or just plain don’t work at all. Also I vastly prefer the windows desktop experience to any Linux distribution I’ve tried over the years. reply TwentyPosts 3 hours agorootparentI don&#x27;t know, works on my machine. Basically any game I play works immediately out of the box. Last bigger issues I remember is Elden Ring crashing when opening sometimes.Otherwise it all just works immediately, no issues at all. reply yonatan8070 4 hours agorootparentprevIf you need to run MS Office, 3D CAD or animation software, the Adobe suite, and other things, you need Windows. As much as I&#x27;d like it if Linux became the default, WINE just doesn&#x27;t cut it for every program yet reply catlover76 6 hours agoparentprevSo what is this, exactly? I download this, pay for Windows, use the Windows activation key with ReviOS, and I can get Windows 11 without spy-and-bloat ware?And everything works? All my hardware, all my apps? reply keyle 6 hours agorootparentBasically it reads that way. Be sure to read the doco and the FAQ before jumping in. reply dc3k 6 hours agorootparentprevYes to all of your questions, at least in my experience. reply cout 5 hours agoparentprevInteresting, reminds me a bit of 98lite which did something similar for windows 98. reply perryizgr8 6 hours agoprevThis is such a non issue. Might as well complain about ios shipping with safari as default. reply pacifika 6 hours agoparentBut it’s not about it shipping edge by default. reply perryizgr8 6 hours agorootparentYeah, it&#x27;s not. That&#x27;s why I said it is \"like\" complaining about shipping safari as default. Because it is not exactly the same thing, but comparable. reply yathaid 5 hours agorootparentNo it isn&#x27;t. Its like you ordering sushi and the restaurant gives you shoes because they know better. reply FireBeyond 3 hours agorootparentYou mean like how the first time you use Chrome on macOS (which you obviously had to manually install), it checks with you to see if you&#x27;d really rather just use Safari instead (and Safari is the default answer, not Chrome)? reply jay_kyburz 4 hours agorootparentprevMore like, they bring the sushi, but also a pair of shoes. And when you throw the shoes on the floor because they are not what you ordered, they come back over and put them back on the table.On iOS they only sell shoes, you don&#x27;t go there if you want sushi. (and too bad if you find yourself locked into the apple ecosystem &#x2F; restaurant, because shoes is all they have.) replylionkor 2 hours agoprevOn my work computer there is Windows 11, and what we build can only be built on windows.So naturally, I just accept almost all defaults. If you just go along with their (sometimes mindbendingly horrible) choices, you get to actually get work done.Of course it&#x27;s a wonderful moment to boot up my machine at home, which has ArchLinux on it, with KDE and all the things I chose because I like them, and I&#x27;m at least 2x more productive. Reading code is much easier without distractions, with the right font, with the right colorscheme that I&#x27;m used to. Writing code is much easier when the IDE doesn&#x27;t hijack Tab to insert AI autosuggestions (which as I said, I leave on, because I dont want to fight MS as its a waste of time). I can use bash without 194728 incantations of setting up path variables and installing all the tools I want.Yeah this is a rant, but man, Windows does a lot of work to force its defaults on you, and man, theyre horrible. reply lacrimacida 2 hours agoparentI go along with whatever our employer policies are and don’t even have much say in for example when windows defender agressively scans and scans and scans slowing my machine to a crawl when Im building a Visual Studio project. It’s infuriating at times but it ain’t on my dime, I try to go along with the program, go for a coffee or walk when building. From minutes it went to 1&#x2F;4 or 1&#x2F;3 hours. Good job Microsoft, you’re burning my company’s money on fire.At work I eventually stopped caring whether I use chrome or edge, since Edge sets itself as default link everytime after a machine restart.At home too I’m mostly on Linux. reply olavgg 2 hours agorootparentFor 10 years ago I was in the position of both of you. I hate being ineffective, but because of company policies I just had to go along. Anyway, the madness inside made me quit and after that I&#x27;ve booted several successful startups. Quitting was the best descision I&#x27;ve ever made. It is a big leap for sure, but heck. If you&#x27;re not happy with current work, you shouldn&#x27;t continue. reply lacrimacida 1 hour agorootparentGreat for you. Im still trapped for now and not ready for much risk as I have a young child to raise. But hope one day I’ll make a move unless I get neutralized and stop caring for good. reply Madmallard 2 hours agorootparentprevW11 forces Edge as default after every restart? How is that at all tolerated? reply lacrimacida 1 hour agorootparentThey do not give a damn about the user but justify themelves to the user with a corporate slogan: “we care about your experience …” but it’s mostly to a hostage or ignorant userbase. reply 1vuio0pswjnm7 2 hours agoprev\"Freedom of choice for customers!Microsoft edge is bringing me inconvenience. Just because a product is good doesn&#x27;t mean I&#x27;m obligated to use it. I as a customer do not like this browser. I like another one and I want to have the options very clear to download the browser you want. Your browser edge is almost like a virus does not let me download another browser and we know clearly that all this is not to benefit customers and to direct us to the microsoft download store. I can&#x27;t download another product other than microsoft this seems to me like monopoly syndrome,I request a change to a list teaching me the steps to have other free browser options, I don&#x27;t want to remove the edge any more than other options.This thread is locked. You can follow the question or vote as helpful, but you cannot reply to this thread.\"Source: https:&#x2F;&#x2F;answers.microsoft.com&#x2F;en-us&#x2F;microsoftedge&#x2F;forum&#x2F;all&#x2F;... reply userbinator 8 hours agoprevthe new version still aggressively prompts you with a captive full-screen experience on start-upIMHO that is the peak of user-hostile behaviour. The urge to pull the power cord or hit the reset button when I encounter things like that is very hard to resist because of how insulting it feels, but I do wonder if most of the user population have already been beaten into submission and consider it only a minor annoyance and almost trivial. reply foxylad 7 hours agoparentDoctorow&#x27;s enshitification is everywhere. I use Debian so haven&#x27;t experienced Windows for twenty years, but I recently travelled for three months away from the Pihole that blocks ads on my home network.The web was practically unusable. I guess it&#x27;s the boiling frog and most people have just got used to having to scroll past three pages of ads to see what they want, but suddenly experiencing \"normal\" ad loads literally stopped me browsing the web. reply 8note 7 hours agoparentprevThe big problem is the prompt, and the options.Most commonly browsers just open full screen as a captive experience nowadays. There&#x27;s no need to force me to click buttons before getting it.The android experience does it pretty well. If you want a second view on the screen, you work for it reply teawrecks 7 hours agoparentprevNot ever experiencing this stuff anymore on linux is the best feeling. reply taftster 8 hours agoprevEdge is insidious too, from a privacy stand point. There are literally dozens of settings that effectively send \"tracking\" data to Microsoft from Edge. All of the sync, shopping, points, url protection, etc. settings all effectively send data to Microsoft for evaluation. And they automatically sign you into your Edge profile (from your Windows profile). Ugh.I get that HTML has taken over the world and that most of Office now is effectively a web app. So Edge is definitely a required piece of library software on any Windows install. But the inability to just open simple hyperlinks in an alternative browser combined with Edge&#x27;s insistence that every \"feature\" is basically Microsoft profiling you... I guess it just boggles my mind how they get away with this. reply EMM_386 7 hours agoparentEdge was even automatically sending every image URL you viewed to their servers to \"enhance\" the images via the \"Enhance images in Microsoft Edge\" setting, which was on by default.It seems like this has since been removed, but what kind of crazy decision is that? reply bandergirl 7 hours agorootparentA literal MITM attack on by default. How that made it past legal we’ll never know. reply heyoni 6 hours agorootparentprevHave they reversed that yet? reply Gud 5 hours agoprevWasn’t this breaking the law the last time?I remember it was calls to split Microsoft into separate companies, one for the operating system and one for the internet divisions. Looks like it’s time now.Last time Microsoft had the default web browser they were horrible stewards of the web. I’ll never forget them delaying supporting PNG. reply mrweasel 4 hours agoprevMicrosoft is weird. People where pretty happy about Edge initially and Microsoft fail to capitalize on that.Why not just create a good browser, bundle it Windows, ensure it has excellent privacy features and if people use it then great, if not, to bad. I really fail to see Microsofts end goal here. They don&#x27;t need people to use Edge, they don&#x27;t need to spy on people... So why do they feel like they must? reply seanp2k2 5 hours agoprevLooks like they really learned a lot from that $613M EU fine. I hope they double it next time. How much exactly do they make from forcing IE down users throats? Apparently enough to justify this behavior given the past penalties, just mind blowing that they’re able to continue to do this and just pay fines. You’d think there’d be more backlash at the board level to this type of behavior. reply hackernewds 4 hours agoparentBrowser domination is the Holy Grail. They will persist as long as the EXPECTED VALUE of the fine is less than the projected benefit - which is existential for the company. reply heavyset_go 8 hours agoprevLooks like nothing much has changed on Microsoft&#x27;s end.I posted this 2 years ago on HN[1] about how Microsoft goes out of its way to manipulate users when they search for \"Firefox\" on Bing using Edge:> Tangentially related, but I recently spun up a Windows VM and used Edge to search Bing for \"Firefox\" and this is result I got[2].> It&#x27;s a giant banner that says, \"You&#x27;re already browsing in Microsoft Edge. Keep using to get world class performance with more privacy, more productivity, and more value.\"> That banner is followed by another giant banner image telling me to get \"Get Robux using Microsoft Edge. Join Microsoft Rewards and use Microsoft Edge. Get a 100 Robux eGift Card on us when you search with Microsoft Bing on Microsoft Edge for 5 days after you join.\"> I had to scroll to even see the relevant search results for my search term. I&#x27;m assuming most non-power users won&#x27;t scroll because they were just assured that they were \"already browsing in Microsoft Edge\", which is apparently more private, productive and valuable than what they intended to search for.[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=28517187[2] https:&#x2F;&#x2F;i.imgur.com&#x2F;blHGMgX.png reply pxmpxm 7 hours agoparentThey really need to fire whoever keeps ramming non-sequitur rewards stuff into the windows product.I have still don&#x27;t understand what the rewards are for, despite having spent inordinate amount of time removing them from my windows machines, but it&#x27;s bizarre that some product manager gets to piss a convoluted frequent flier miles scheme all over microsoft&#x27;s premier product. That&#x27;s akin to Ferrari covering their very exclusive cars with promo stickers hawking those ferrari licensed asus laptops. reply chongli 7 hours agorootparentThey really need to fire whoever keeps ramming non-sequitur rewards stuff into the windows product.How do we know this wouldn’t lead to firing the CEO? Frankly, I’m inclined to believe that enshittification [1] is the primary strategy of the company right now. They’ve had decades to build Windows market share and now they realize that growth in software license sales has all but dried up. On the other hand, they’ve seen how hard the wind is blowing in the services and adtech direction.So they’re determined to monetize their Windows install case right up to the hilt. They know they won’t be able to sell these folks expensive software licenses anymore, so they’re selling their users to advertisers instead.[1] https:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;tiktok-platforms-cory-doctorow&#x2F; reply p-e-w 7 hours agorootparentprev> That&#x27;s akin to Ferrari covering their very exclusive cars with promo stickers hawking those ferrari licensed asus laptops.No it&#x27;s not, because Windows is not a \"premium\" or \"exclusive\" product, at all. It&#x27;s the textbook example of a mass market product. There are (far) more Windows installations than there are cars in the world. The average Windows user is almost indistinguishable from the average human. And the monetization strategies reflect that. reply staplers 7 hours agorootparentprevMost \"rewards\" programs (including for grocery stores) are to allow payment method-based tracking.Right now it&#x27;s illegal to track users&#x2F;customers based on payment method. This is more than just an upsell. reply SoftTalker 7 hours agoparentprevAs with any person or business, you have to judge them not on what they say but on what they do.You can assume that about 50% of whatever anyone says is either a straight-up lie, misleading, or bullshit. reply jmkni 7 hours agoparentprevIronically I think non-power users will begin every browsing session by typing \"www.google.com\" into the address bar, avoiding this issue entirely. reply monero-xmr 8 hours agoparentprevI installed Windows on a media PC (all other laptops are macOS or Linux) and it was like the entire OS is a web browser without ad block installed. Just endless nags, pop ups, notifications, ads in my start menu, ads in the login screen, holy shit. Who actually likes this? It’s insane! reply sshine 7 hours agorootparentThat’s what get when you don’t pay for... oh, wait. reply Nition 7 hours agorootparentprev> Who actually likes this?Microsoft. reply Ygg2 7 hours agorootparentI don&#x27;t think they like it. But their customers - advertisers - sure do. reply PaulHoule 7 hours agorootparentYou can turn all of that crap off with some effort.Contrast that to the Linux desktop where you can&#x27;t turn off the \"it just doesn&#x27;t work\" (unless you mean just disable the GUI completely and only use the CLI), and the enthusiast who says they have it working just the way they want probably has \"just not working\" more thoroughly than the defaults.The thing is that those ads are: (1) almost always for other Microsoft products, (2) frequently are for MSN articles aimed at Trump Voters, (3) probably destroy Microsoft products more than they promote them.As an example of (3), consider how Microsoft launched a product called SkyDrive without doing a Trademark check, had to rename it OneDrive (just like they had to call the third XBOX the XBOX ONE, contrast that to Sony where even Mom can tell a PS5 is better than a PS4) then made Office save to OneDrive by default and leave you not being able to save at all if it couldn&#x27;t connect to OneDrive.That&#x27;s like killing your product with 900 cyanide laced bullets, if they ever want me to use OneDrive again there is no amount of heavy handed marketing tactics that will work, even if I have to click 500 times and edit 30 registry entries to disable OneDrive I&#x27;ll do that. reply 15457345234 6 hours agorootparent> Contrast that to the Linux desktop where you can&#x27;t turn off the \"it just doesn&#x27;t work\"The modern Linux desktop is pretty damn usable, especially if you go with something like PopOS. It&#x27;s got to be covering 99% of non-workstation-type of use cases out of the box. reply midoridensha 4 hours agorootparentprev>Who actually likes this? It’s insane!It&#x27;s not insane at all, it&#x27;s good for business. Who likes it? Microsoft shareholders of course. All these annoyances help to increase Microsoft&#x27;s profits, so they&#x27;re good by definition.If you don&#x27;t like the modern Windows experience, it&#x27;s simple: don&#x27;t use Windows. reply nologic01 4 hours agoprevWindows continuously monitors what browsers users have installed. If you uninstall Chrome, it immediately tries to make Edge the default browser.And it never respects my wishes for a default browser. Any OS embedded help link will open Edge, wasting me time, memory and screen space. reply jay_kyburz 4 hours agoparentOne thing I really hate is that, I like to hit the windows key and start typing the name of an app I want to open, but if I mistype the app name, it searches the web for the misspelling... in Edge! reply mackrevinack 1 hour agorootparentthey have to get those bing numbers up somehow! reply baz00 3 hours agoprevI&#x27;ve stopped forcing myself on Microsoft. Works wonders. Moved my workflow off the platform over the last 6 months entirely. reply TonyStr 5 hours agoprevI used a debloater on my windows 11 laptop which also removed edge. No big deal since Firefox is my browser if choice, but I&#x27;m a Web developer and need to test my apps in different browsers. I&#x27;ve tried to install edge multiple times, but I can never get it to work. reply toastal 4 hours agoparentEdge is still Blink+V8. Just test Chromium or Brave & forget about Edge. reply robin_reala 3 hours agorootparentThat’s not exactly true, there’s a bunch of ancillary code too. For example, image handling, where Edge doesn’t support AVIF: https:&#x2F;&#x2F;caniuse.com&#x2F;avif reply leshenka 1 hour agorootparentBut that&#x27;s (+ AV1) about it. I wouldn&#x27;t install edge just to test whether there are any files encoded with these codecs. (unless there are a LOT of media encoded in different ways e.g. youtube)Just test on chrome and keep in mind to avoid AVIF reply toastal 1 hour agorootparent…Which you should be using the picture element or image() to fall all the way back to PNG or JPEG in most scenarios anyhow. New & improved formats like JPEG-XL should be considered ‘enhancements’ rather than relied on. reply DrSiemer 3 hours agorootparentprevDon&#x27;t remember what it was exactly, but I did run into some obscure scenario (something with tab focus I believe) where Edge had a bug that prevented my code from working.Just spin up a VM for testing Edge, the differences are small. reply laserbeam 2 hours agoparentprevHonestly, as much as I avoid it as a primary browser, I think all OSes should have a default browser that one could use as a preinstalled webview. Some way to avoid having to ship a 100 MB electron with simple web apps.I don&#x27;t think web apps are ideal, but having edge installed and available as a native webview is relevant.I don&#x27;t think this dream works yet, I don&#x27;t think one can actually make THESE kinds of apps without shipping electron yet, but that should definitely be an option. I have no problem with edge used as a random weview in random apps. I only hate it when edge is opened as a dedicated browser.I don&#x27;t think an OS API to use Firefox as a webview is a reasonable ask :(. reply seanp2k2 4 hours agoparentprevTry the second set of instructions here https:&#x2F;&#x2F;www.intowindows.com&#x2F;how-to-reinstall-microsoft-edge-... reply HenryBemis 2 hours agoparentprevHow about you get VMware and install in there a vanilla Win10&#x2F;11 just for the testing of Edge? Yes, it is heavy. Yes you will only fire it up when you need it. And this won&#x27;t contaminate your machine. reply kristofferg 4 hours agoparentprevYou can’t remove plankton and expect the whale to survive. reply radium3d 4 hours agoprevMicrosoft Edge is a privacy nightmare. They have buried dozens of data-collection settings in so many menus under so many different names and categories it&#x27;s insane. You literally need a book to know which settings to turn off, and even then they keep adding new settings at a very high rate hidden in \"security updates\" reply dietr1ch 5 hours agoprevWhat made you think they&#x27;d stop?I just want them to use clippy to force you into going from google sheets back to excel just for the memes. (and don&#x27;t tell me to stop giving them bad ideas, I know the higher-ups love them) reply cebert 7 hours agoprevI used to be a huge Windows fan, but shoving Edge upon me so aggressively has made me decide it’s time to move on. Moving forward, I’m only buying Apple or Linux devices. reply dismalpedigree 4 hours agoparentI bought my pre-teen a prebuilt pc for gaming recently. Figured windows 11 would be easier due to compatibility with games and it being pre installed. After screwing with it for several hours to remove as much crap as possible, What I found was that every time it restarted there was a new prompt to reenable something, surreptitiously start using a ms service, etc. I gave up and installed Ubuntu. Not every game works perfectly, but most do, and its no longer a confusing experience for my kid.I mean what the hell. My kid just wants to play minecraft for Christ&#x27;s sake. reply FireInsight 3 hours agorootparentOnce Ubuntu breaks: https:&#x2F;&#x2F;github.com&#x2F;ublue-os&#x2F;bazzite&#x2F;It&#x27;s a gaming distro built on top of Fedora Silverblue, making it stable as heck while having up-to-date official steam, and other goodies. Works on Deck too, if you want that. reply 0dayz 2 hours agorootparentI am happy that my teenage dream of an actual sub-genre of desktop PC usage is finally getting distros designed that particularly purpose. reply adammarples 2 hours agorootparentprevOnly works with steam deck or amd GPUs? reply jpnc 2 hours agorootparentNo, there&#x27;s also the bazzite-nvidia variant if that&#x27;s the GPU you got. It&#x27;s fairly easy to setup. Once you start bazizte ISO you&#x27;re given a choice of the variant you want&#x2F;need.I myself run the nvidia variant on my new desktop and the OOB experience has been amazing. reply peteri 2 hours agorootparentprevMight be worth having a look under Settings &#x2F; System &#x2F; Notifications and the check boxes at the bottom of the screen which are:Show me the Windows welcome experienceOffer suggestions on how I can setup my deviceGet Tips and suggestions when I use Windows(I&#x27;ve posted this in the past, but it does seem to help) reply jay_kyburz 4 hours agorootparentprevI would love to see my kids using KDE on some flavor of Linux, but the two biggest games they play have issues. Roblox and Fortnite. reply lionkor 3 hours agorootparentIts such a shame, because from what I can tell, the only reason Roblox doesn&#x27;t work is because they do some very goofy stuff to launch the game reply dustedcodes 2 hours agoprev\"Hey friends :wave:, I call everyone my friend because I am a creepy old Influenza(tm) on TikTok trying to advertise snake poison to young folks. Don&#x27;t be afraid, I&#x27;m just an innocent friendly neighbour hood virtue signalling Microsoft advocate. Look, here I use Edge, here I use Windows 11 with some bullshit hack to run Linux in my terminal and then I use (innocently) a bunch of other toxic Microsoft software to advertise this spyware to you in an unsuspecting way.\"Yawn... I think people are slowly waking up to Microsoft and their antics and fake people. reply AraceliHarker 6 hours agoprevMost of the people who participate in Windows Insider are amateurs, they don&#x27;t have several PCs for functional verification, they don&#x27;t have in-depth knowledge of software testing, and there is no point in blaming them. On the contrary, Windows 11 is entrusted to these amateurs for functional verification instead of QA, so it is not surprising that Windows 11 has bugs in every update. reply midoridensha 4 hours agoparentWhy should Microsoft spend any money on maintaining a QA team and doing functional verification? What&#x27;s the business benefit?Leaving QA to a bunch of amateurs is a good thing: it saves MS lots of money, and so increases profitability, and increases shareholder value. Windows users aren&#x27;t going to stop using Windows because of a bunch of bugs that a dedicated QA department would have caught, so there&#x27;s no reason to avoid bugginess. reply post_break 7 hours agoprevMicrosoft is also forcing office 365 support to end on windows servers in 2025&#x2F;2026. It&#x27;s going to be a blood bath if you run on prem. reply catlover76 6 hours agoparentThey aren&#x27;t going to support on-prem Office 365? reply retrocryptid 7 hours agoparentprevMeh. I just use text files and emacs. And I hacked sc to use emacs key bindings for spreadsheets. It&#x27;s far from an ideal system, but it works for me. Simplicity can be nice. reply post_break 7 hours agorootparentIt&#x27;s like saying I&#x27;m having engine trouble on my big rig, and you telling me about how you upgraded your tennis shoes. reply retrocryptid 6 hours agorootparentDon&#x27;t ask the question if you don&#x27;t want the answer. And sheesh, dude, how many alts do you have? reply o1y32 5 hours agorootparentprevHow is your personal preference relevant at all under a comment of enterprise-level setup? You are going to ask everyone in the company to use emacs? reply dingosity 5 hours agorootparentEveryone in my company uses emacs, except the few who use vi. There is one guy who uses VSCode. I have no idea what he uses to type text documents for human consumption. So, sure. Use whatever tool works for you. Kind of bizarre you&#x27;re wanting everyone to use Word and Edge (and Win 11). I mean... you should use what works for you. But you shouldn&#x27;t freak out when people use different things. I hear some people use Macs, for instance.I mean... most of my daily effort goes into supporting a bank. There&#x27;s A LOT of mainframe stuff. Some COBOL. Some guys using AIX (actually, a surprising number of guys using AIX) and (as mentioned previously, xterms and emacs or vi.) On the dev side there&#x27;s more focus on file format standards than tools. So use whatever tool that generates files in the appropriate format. We probably could use Win11, but they started using AIX in the 90s and just never got around to moving to Windows. reply khobragade 5 hours agoprevI ended up blocking Edge in the firewall so it would at least close quickly without loading any useless stuff. Even then the firewall rule would reset periodically so I made a new one that points to the Edge binary. reply hackernewds 4 hours agoparenthow can one do this? reply khobragade 3 hours agorootparentHere&#x27;s how...1. Find out where the Edge executable is; copy its path.2. Open &#x27;Windows Defender Firewall with Advanced Security&#x27;3. Select Inbound Rules (Left pane).3.1 Click on &#x27;New Rule&#x27; (Right pane)3.2 Set the type of rule to Program, click Next and paste the exe path and delete the quotation marks. Click Next.3.3 Set the Action to &#x27;Block the connection&#x27; and then select where this rules applies (select all three options). Click Next.3.4 Specify a name (and an optional description) for the rule.Done!I also made a blocking outbound rule, but I don&#x27;t think it&#x27;s necessary for this purpose. reply 0dayz 2 hours agoprevI am shocked a company with a very sketchy history with repeated violation with anti trust related to internet browsers.But to be serious, I wonder what sketchy nonsense Microsoft would do if they could only compete on Linux or MacOS.On steam and other stores they force you to login into Xbox services. reply gotschi_ 2 hours agoprevI refuse to use browsers that come tied deeply with the os. Last one I used was IE6Thats all I have to say about these tactics over the last decades reply charles_f 7 hours agoprevSmells like typical knee jerk reaction for a product that doesn&#x27;t perform to a vp&#x27;s expectations. PM&#x27;s asked to do something about it, and between making the product better to attract users, or implementing defaults and such to force it on them, they choose the expedient. reply netfl0 7 hours agoprevWho forced you to use Microsoft (at home). reply CameronNemo 7 hours agoparentCan you actually switch the default browser with group policy? What if your team only has the bandwidth to support a couple browsers, and your users say they want Chrome and Firefox? reply hug 5 hours agorootparentIf this is an honest question, then Microsoft&#x27;s answer is that you use Intune to push the Chrome & Edge settings (via the same policy node, since they&#x27;re the same engine, they just report their spying to different corporations) and import an ADMX for Firefox policy. That&#x27;s two browsers worth of policy that you&#x27;re supporting, but it actually handles three bits of software. reply CameronNemo 5 hours agorootparentThis doesn&#x27;t answer my question... If an admin does not want their users using Edge, is there an actual way to configure the default browser that doesn&#x27;t end up opening links and such in Edge? reply hug 4 hours agorootparentDidn&#x27;t realise that was what you were getting at. In short, no, you cannot stop deep-links for Edge from opening in Edge. reply22 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The default web browser settings in Windows 11 remain unchanged, despite claims in a blog post that Microsoft would consider users' browser preferences.",
      "Misunderstanding stemmed from a recent Windows 11 Insider preview build changelog, leading many to believe Microsoft had conceded to regulatory pressures.",
      "In-depth testing reveals that Windows 11 persistently proposes Microsoft Edge as the default browser, overriding the user's chosen browser. Initial reports of changes were misinterpreted and widely circulated in the media, with no official confirmation from Microsoft."
    ],
    "commentSummary": [
      "The main discussions revolve around user dissatisfaction with Microsoft Edge's intrusive attempts to be the default browser, and limitations with the Windows operating system.",
      "There is a notable desire for more browser diversity with users expressing concern over Google's dominance, and some prefer alternative browsers like Chromium or Brave.",
      "Users mention alternative operating systems like Ubuntu, Arch Linux, and custom Windows distributions, meanwhile, discussing different tools such as Emacs and VSCode."
    ],
    "points": 487,
    "commentCount": 272,
    "retryCount": 0,
    "time": 1694391904
  },
  {
    "id": 37459495,
    "title": "Knightmare: A DevOps Cautionary Tale (2014)",
    "originLink": "https://dougseven.com/2014/04/17/knightmare-a-devops-cautionary-tale/",
    "originBody": "Skip to content Doug Seven Something can be learned in the course of observing things Home Knightmare Product Management Guitars dseven@twitter About Knightmare: A DevOps Cautionary Tale D7 DevOps April 17, 2014 6 Minutes I was speaking at a conference last year on the topics of DevOps, Configuration as Code, and Continuous Delivery and used the following story to demonstrate the importance making deployments fully automated and repeatable as part of a DevOps/Continuous Delivery initiative. Since that conference I have been asked by several people to share the story through my blog. This story is true – this really happened. This is my telling of the story based on what I have read (I was not involved in this). This is the story of how a company with nearly $400 million in assets went bankrupt in 45-minutes because of a failed deployment. Background Knight Capital Group is an American global financial services firm engaging in market making, electronic execution, and institutional sales and trading. In 2012 Knight was the largest trader in US equities with market share of around 17% on each the NYSE and NASDAQ. Knight’s Electronic Trading Group (ETG) managed an average daily trading volume of more than 3.3 billion trades daily, trading over 21 billion dollars…daily. That’s no joke! On July 31, 2012 Knight had approximately $365 million in cash and equivalents. The NYSE was planning to launch a new Retail Liquidity Program (a program meant to provide improved pricing to retail investors through retail brokers, like Knight) on August 1, 2012. In preparation for this event Knight updated their automated, high-speed, algorithmic router that send orders into the market for execution known as SMARS. One of the core functions of SMARS is to receive orders from other components of Knights trading platform (“parent” orders) and then send one or more “child” orders out for execution. In other words, SMARS would receive large orders from the trading platform and break them up into multiple smaller orders in order to find a buyer/seller match for the volume of shares. The larger the parent order, the more child orders would be generated. The update to SMARS was intended to replace old, unused code referred to as “Power Peg” – functionality that Knight hadn’t used in 8-years (why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the point). The code that that was updated repurposed an old flag that was used to activate the Power Peg functionality. The code was thoroughly tested and proven to work correctly and reliably. What could possibly go wrong? What Could Possibly Go Wrong? Indeed! Between July 27, 2012 and July 31, 2012 Knight manually deployed the new software to a limited number of servers per day – eight (8) servers in all. This is what the SEC filing says about the manual deployment process (BTW – if there is an SEC filing about your deployment something may have gone terribly wrong). “During the deployment of the new code, however, one of Knight’s technicians did not copy the new code to one of the eight SMARS computer servers. Knight did not have a second technician review this deployment and no one at Knight realized that the Power Peg code had not been removed from the eighth server, nor the new RLP code added. Knight had no written procedures that required such a review. SEC FilingRelease No. 70694October 16, 2013 At 9:30 AM Eastern Time on August 1, 2012 the markets opened and Knight began processing orders from broker-dealers on behalf of their customers for the new Retail Liquidity Program. The seven (7) servers that had the correct SMARS deployment began processing these orders correctly. Orders sent to the eighth server triggered the supposable repurposed flag and brought back from the dead the old Power Peg code. Attack of the Killer Code Zombies Its important to understand what the “dead” Power Peg code was meant to do. This functionality was meant to count the shares bought/sold against a parent order as child orders were executed. Power Peg would instruct the the system to stop routing child orders once the parent order was fulfilled. Basically, Power Peg would keep track of the child orders and stop them once the parent order was completed. In 2005 Knight moved this cumulative tracking functionality to an earlier stage in the code execution (thus removing the count tracking from the Power Peg functionality). When the Power Peg flag on the eighth server was activated the Power Peg functionality began routing child orders for execution, but wasn’t tracking the amount of shares against the parent order – somewhat like an endless loop. 45 Minutes of Hell Imagine what would happen if you had a system capable of sending automated, high-speed orders into the market without any tracking to see if enough orders had been executed. Yes, it was that bad. When the market opened at 9:30 AM people quickly knew something was wrong. By 9:31 AM it was evident to many people on Wall Street that something serious was happening. The market was being flooded with orders out of the ordinary for regular trading volumes on certain stocks. By 9:32 AM many people on Wall Street were wondering why it hadn’t stopped. This was an eternity in high-speed trading terms. Why hadn’t someone hit the kill-switch on whatever system was doing this? As it turns out there was no kill switch. During the first 45-minutes of trading Knight’s executions constituted more than 50% of the trading volume, driving certain stocks up over 10% of their value. As a result other stocks decreased in value in response to the erroneous trades. To make things worse, Knight’s system began sending automated email messages earlier in the day – as early as 8:01 AM (when SMARS had processed orders eligible for pre-market trading). The email messages references SMARS and identified an error as “Power Peg disabled.” Between 8:01 AM and 9:30 AM there were 97 of these emails sent to Knight personnel. Of course these emails were not designed as system alerts and therefore no one looked at them right away. Oops. During the 45-minutes of Hell that Knight experienced they attempted several counter measures to try and stop the erroneous trades. There was no kill-switch (and no documented procedures for how to react) so they were left trying to diagnose the issue in a live trading environment where 8 million shares were being traded every minute . Since they were unable to determine what was causing the erroneous orders they reacted by uninstalling the new code from the servers it was deployed to correctly. In other words, they removed the working code and left the broken code. This only amplified the issues causing additional parent orders to activate the Power Peg code on all servers, not just the one that wasn’t deployed to correctly. Eventually they were able to stop the system – after 45 minutes of trading. In the first 45-minutes the market was open the Power Peg code received and processed 212 parent orders. As a result SMARS sent millions of child orders into the market resulting in 4 million transactions against 154 stocks for more than 397 million shares. For you stock market junkies this meant the Knight assumed approximately $3.5 billion net long positions in 80 stocks and $3.15 billion net short positions in 74 stocks. In laymen’s terms, Knight Capital Group realized a $460 million loss in 45-minutes. Remember, Knight only has $365 million in cash and equivalents. In 45-minutes Knight went from being the largest trader in US equities and a major market maker in the NYSE and NASDAQ to bankrupt. They had 48-hours to raise the capital necessary to cover their losses (which they managed to do with a $400 million investment from around a half-dozen investors). Knight Capital Group was eventually acquired by Getco LLC (December 2012) and the merged company is now called KCG Holdings. A Lesson to Learn The events of August 1, 2012 should be a lesson to all development and operations teams. It is not enough to build great software and test it; you also have to ensure it is delivered to market correctly so that your customers get the value you are delivering (and so you don’t bankrupt your company). The engineer(s) who deployed SMARS are not solely to blame here – the process Knight had set up was not appropriate for the risk they were exposed to. Additionally their process (or lack thereof) was inherently prone to error. Any time your deployment process relies on humans reading and following instructions you are exposing yourself to risk. Humans make mistakes. The mistakes could be in the instructions, in the interpretation of the instructions, or in the execution of the instructions. Deployments need to be automated and repeatable and as free from potential human error as possible. Had Knight implemented an automated deployment system – complete with configuration, deployment and test automation – the error that cause the Knightmare would have been avoided. A couple of the principles for Continuous Delivery apply here (even if you are not implementing a full Continuous Delivery process): Releasing software should be a repeatable, reliable process. Automate as much as is reasonable. Share this: TwitterFacebookLinkedInRedditPinterest2EmailPrint Loading... Tagged Continuous Delivery DevOps Release Management Published by D7 View all posts by D7 Published April 17, 2014 Post navigation Previous Post Strategy: The Art of the Product Manager Next Post Scaling Agile Across the Enterprise 106 thoughts on “Knightmare: A DevOps Cautionary Tale” Craig April 27, 2014 at 5:46 AM 82 6 Rate This Yes, DevOps would have helped here, but sound coding practices would have prevented it entirely. Never re-purpose a variable. Reply Marc Seiler (@digitalfiz) February 4, 2015 at 9:40 AM 29 3 Rate This I was thinking the same thing the entire time i was reading this. Its simple to create a new flag and it would have prevented something like this from happening. It doesn’t change the message this post is supposed to convey because it was mainly about bad deployments and the problems it causes but there is another message here: DON’T REPURPOSE FLAGS/VARIABLES! Reply yesthattom April 27, 2014 at 7:52 AM 4 3 Rate This I can’t believe they didn’t deploy the code with the flag off, then wait a bit before flipping it on. Reply Martin Barry April 30, 2014 at 1:14 AM 17 1 Rate This Tom, I believe their use of the term “flag” is not in line with what we would normally think of in deployments (i.e. “feature flag” http://en.wikipedia.org/wiki/Feature_toggle) but instead it’s a variable in the data format of the orders being sent to the system. This means that “turning it off” was probably not so easy as you would need to change the order format being generated by the upstream system. Nor is it clear what would have happened to orders submitted without the RLP bit on. Reply Shyam S August 10, 2019 at 6:28 PM 1 12 Rate This Let’s take a step back. What makes someone want to repurpose a variable? Laziness. Moral of the story: don’t be lazy. Nav Marwaha May 5, 2014 at 4:54 AM 4 3 Rate This Good post, regardless of development practices, level of experience or the number of quality gates, automation is a requirement for reliability. Reply Pingback: Feature Toggles from a Continuous Delivery Perspective » Programming Bytes Pingback: Knightmare: A DevOps Cautionary TaleAndymatic Pingback: 4p – How a ~$400M company went bankrupt in 45m because of a failed deployment – blog.offeryour.com Vj February 3, 2015 at 5:59 PM 8 5 Rate This A scenario : Lets assume they had very good DevOps. So all servers would be in sync. But – assume that the new code had a bug. So all servers are in synch, but have the same buggy code. What if two versions of the code, i.e. the last 2 deployments had this bug. So once they realize that something is wrong, they’d roll back the code, the bug still stays… Precious minutes have gone by. Maybe 20 minutes instead of the 45 minutes in your article. So in short – their disaster / kill-switch is a code rollback + deployment in a live environment. That would still be a defective design. What they’d need would be a big red switch (almost literally, somewhere in their dashboard) to immediately stop. Where is the business rule that says “first do no harm”. Reply Eric Minick February 4, 2015 at 10:48 AM 9 2 Rate This VJ if the deployment to all servers had worked, they would have been ok. But in this case, 7 of 8 for one subsystem were deployed to correctly. Because the bad behavior, they rolled back the other 7 thinking the new code in that subsystem was the problem. That multiplied the problem until the eventual kill switch. Disasters are almost always complex. In this case it was poor coding practices, plus questionable testing / code inspection practices, plus an error in deployment, plus a rollback at the granularity of the subsystem rather than the whole system. If you resolve any of those issues, you don’t get a disaster. Reply Jay Conrad July 26, 2016 at 11:12 AM 28 1 Rate This One of the things I’ve seen in companies who don’t recognize the true importance and impact of their IT systems is that they don’t provide budget for legacy code updates. For example: I’ve seen situations where IT has no budget. It has to justify everything it does against a business expense. Which means constantly scrambling to line up new projects. Business rarely sees the need to update old software that is currently working, so they refuse to pay for it. The result is constant new code, made by the cheapest coders possible, while not investing in the technologies that would ultimately improve performance and mitigate risk. Why? Because these are seen as “IT problems” and not the purview of whatever project the IT people are working on, so nobody will pay for it. A great read regarding this practice is The Phoenix Project by Gene Kim, Kevin Behr, and George Spafford. darkfader March 16, 2015 at 12:51 PM 2 1 Rate This Thank you for applying brain to the hype. Probably one should ask why the techs involved did get to take the blame but didn’t get authority to kill switch on their own. Oh right, that’s why you put Ops/SRE in place anyway. “R” is for responsible, aka flame bait. Reply allspaw February 3, 2015 at 6:11 PM 12 3 Rate This I have written a bit about this event, and I would caution anyone to use the SEC report as anything at all other than for what the SEC needed it for. http://www.kitchensoap.com/2013/10/29/counterfactuals-knight-capital/ Reply Marcus February 3, 2015 at 7:34 PM 3 1 Rate This Fascinating read. I worked at a large auction house for fruits and vegetables once where an new software version was installed and failed, leading to large losses to the traders (although not as massive as these). This too was a case of improper deployment and no fall-back. Reply vlad ill February 3, 2015 at 7:37 PM 6 13 Rate This The lesson to be learned is that there are domains where computer should not take any decision without human validation. What about the people who lost their jobs because, oops, there was a bug? What about the other companies that maybe got into trubble because of sudden change of the stock value? Automation of “high level decisions” is to be handled carefully… Nice and educational post Btw. Reply joskid February 3, 2015 at 7:52 PM 0 6 Rate This Reblogged this on josephdung. Reply Mark A Hart, NPDP (@OpLaunch) February 3, 2015 at 9:48 PM 6 5 Rate This Using the #Cynefin framework provides a better characterization of this ‘#DevOps’ failure This post seems to have been written from a DevOps perspective. The suggested solutions are consistent with a DevOps perspective – examine the release process, automate more, and craft a kill switch with rollback capabilities. Someone may read the post and put too much emphasis on the Knight technician that did not copy the old code to one of the eight servers. Someone may oversimplify a cause and effect relationship. Someone may insisit on new rules to ‘prevent this from ever happening again.’ A more powerful approach may invest to: – Increase diversity to analyze the situation and synthesize better options – Improve communication between specialties – Improve implicit coordination between specialties – Recruit individuals with more expertise to write and review code A major factor that limited improving the capability of the team from nine years prior to the significant failure event was mis-characterizing the system. In a Cynefin framework, confining this failure to a DevOps problem is associating the system with the “Obvious” domain where there are simple cause and effect relationships that are recognizable by ‘professionals.’ The failure should not be associated with the Cynefin “Complicated” domain where a significant analysis by ‘specialists’ would have prevented the failure. The system should be associated with the Cynefin “Complex” domain – a complex adaptive system. The system is dispositional. The same initial conditions will not produce the same failure (except by accident). For more information about Cynefin, visit http://en.wikipedia.org/wiki/Cynefin and @CognitiveEdge. Reply Scott Mann February 4, 2015 at 5:02 AM 2 1 Rate This I appreciate your highlighting the tacit factors in such a catastrophe. Like the author, I also work in operations, and it’s easy to fall into the same old thought patterns on causes and solutions. I particularly enjoy your point relating to diversity (Which comes in all forms: experience levels, cultural and educational backgrounds, skillsets, age, etc.), as I think this is a strong driver behind the success of DevOps itself. Having a variety of perspectives, both within and without your team, looking at your project has strong, demonstrable potential and can help curb oversights such as the one brought up in this article. Reply sushil10018 February 4, 2015 at 2:07 AM 2 4 Rate This Reblogged this on sushil10018. Reply malikest February 4, 2015 at 2:17 AM 2 2 Rate This Reblogged this on malikesaint and commented: Deep Reply Pingback: HACKERNYTT.se - dagliga nyheter för dig som bygger framtiden m50d February 4, 2015 at 6:15 AM 11 2 Rate This > why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the point On the contrary, that’s exactly the point. Code with unused, and therefore untested, configuration possibilities is a disaster waiting to happen. This is why I’m very sceptical about feature-flag-based approaches generally. Configuration is as much a part of your program as code is, and configuration changes should go through the same lifecycle – pull request, code review, release, deploy to staging – as any other change. If your release process is too heavy and you need to make fast config changes to production, fix your release process. Reply CFC February 4, 2015 at 7:26 AM 5 1 Rate This There were too many mistakes to attribute the epic failure to just DevOps (though I do fully agree that automation and testing is the only way): – No teamwork and checklists while doing an update on *production* servers. Any update on production should require a team watching over each other, and going through a checklist. – 8 years of unused old code in production. That tells you a lot about the lack of understanding about the risks of dangling “unused” code. – Insufficient logging [from the code], and insufficient real-time log monitoring, correlation and analysis. That would have triggered enough clues early one to the engineers and ops folks. – No hot-hot failover to a cluster with the previous version. That would have stopped all issues after 1 or 2 minutes. (That’s the bug red button that the article mentions) If you also have been architecting software, systems and enterprises for a long time, you know disaster happens, you know some bugs are only caught in the wild and not during simulations, just like you know machines will go down. You need to prepare for the worst case in both scenarios. Murphy’s Law is so true in our world… Reply dwntwn1973 February 4, 2015 at 9:03 AM 19 1 Rate This I’ve been in what is now called the “DevOps” space for nearly 20 years, over half of that in the financial world. Knight was both a vendor to and a competitor of the company I currently work for. Deployment automation *might* have helped. Maybe. But few companies can afford exactly duplicate environments, and this was essentially caused by environmental differences. Even automated validation of deployment might not have helped in this case if the automation didn’t know about the environmental difference. Automation is only as good as the knowledge of the people setting it up. If a manual install wasn’t aware of the old system, then there’s a good chance the automated system wouldn’t have known to check for it either. Automation of a rollback is also only as good as the decision-making on whether to make the roll-back. And if the automation inadventently started the old system, there’s also no guarantee that switching the contemporary system back would have stopped the old system – you could have ended up with the same problem even after an automated rollback of the contemporary system. Which brings me to a final point: Automation is a requirement in large, modern, environments. But over-reliance on it can lead to the people operating the system being unaware of what it’s doing. Automation is most useful for validations, because validating things are done correctly is tedious and easy to skimp on when done manually. Even when automating, having human-involved breakpoints or human-driven steps helps insure that those operating the system know the system and how it operates, greatly improving their ability to troubleshoot issues, diagnose problems, and make appropriate suggestions on what steps to take to stop or mitigate a problem. Automation is a tool, but it is only one tool and it still requires a craftsman to wield it appropriately. Expertise is what makes and keeps great systems great. Reply GarrettHampton February 4, 2015 at 9:06 AM 0 3 Rate This Reblogged this on Garrett S. Y. Hampton and commented: Incredible. DevOps always watch, document, and review your deployments! Reply Satan February 4, 2015 at 1:48 PM 6 1 Rate This The exact same thing could have happened with an automated deployment. What they should have done is kill Power Peg with fire, deploy, verify, and THEN deploy the new functionality. Reply Bobby February 4, 2015 at 2:50 PM 3 1 Rate This There were a few problems… the First problem was they had no Disaster Recovery Plan, i.e. a kill switch. Leaving the whole system running and while a problem was apparent was a bad idea. Included in the lack of a Disaster Recovery Plan was knowing the disaster was going on. There were no indicators showing that they were making trades without the parent order, nor something showing how much money was payable and how much was received. They also didn’t have a plan to implement a kill switch. The Second problem was a function of being incomplete and not keeping code clean, as the “Power Peg” code was still in the original code and never removed after going unused. Along with that, they didn’t test the prior code against the new order format, so they didn’t have a reliable rollback plan. Lastly, they deployed without a mechanism for ensuring that all installed code was identical on on servers, and they didn’t have a monitor on each node so they could find the problem node faster. Reply Pingback: Readings: Knightmare, Ulbricht Convicted, Franklin on VaccinationsNeurovagrant asdf February 5, 2015 at 12:53 AM 3 3 Rate This I don’t see any DEV in the OPS story here, but thanks, it was very interesting to read technical details about the incindent. Reply Pingback: 1p – Knightmare: A DevOps Cautionary Tale – Exploding Ads thenrio February 5, 2015 at 1:18 PM 3 1 Rate This Looks more like a product failure… Failure to understand what your you are really doing I know of a quite similar tale, and only similar because it was only a deployment issue SG warrant market making in HK, approx 15 years ago ( as a dis, I CAN be wrong on some figures as it was a tale related by SG mates, still I deeply trust them because we worked together on this market making for more than 2 years, and I left before it happened ) Bad refill and limit configuration, bad underlying for one instrument => bad price, arbitrated by automaton of doetsche boerse Loss was 4M€ in 4 minutes And the operator stopped the market making . 4 minutes, not 45 Could and should have been less My point is that the operator had a deep understanding of how market making worked…and how to stop it Electronic trading that you can not halt is a failure to understand electronic trading It is not a deployment issue per se Reply AirFrank February 5, 2015 at 2:19 PM 4 1 Rate This Never leave old code behind and don’t reuse old flags. Had this happen on International Space Station. Guy overloaded a flag and in a future upgrade forgot that it was overloaded. I asked why he did that and he replied that he didn’t want yet another flag in the system. Reply fubar February 5, 2015 at 8:56 PM 10 4 Rate This Shouldn’t the real lesson learned here be why stockmarkets can allow something like this to happen in the first place? Reply glass February 6, 2015 at 12:46 AM 3 1 Rate This must be hell of a release engineer, took Knight to leading trader just by doing manual deployment. Reply Pingback: Highlights KW 06/15drikkes.com/ Pingback: Developer Catchup: New Node, Profanity, Oh-My-Git, Knightmares, Bad Docs and Go TracingCodescaling mrpjscott February 17, 2015 at 10:51 PM 0 2 Rate This Reblogged this on refresh.me and commented: This article is an awesome example of why automation is so important for businesses. I know that I personally will do my best to introduce more automation and configuration management tools into the environments I work on. This article is a reminder that without it, terrible things can happen! Until next time! Reply Pingback: QCon London 2015–Takeaways from “Small is Beautiful”theburningmonk.com Pingback: Knight Capital Group - Seite 4 Pingback: Why Driverless Cars?Survival of the Craziest Pingback: CodeMotion 15–Takeaways from “Measuring micro-services”theburningmonk.com Pingback: What I've been reading - June - Tyler Crammond Pingback: Professional Release EngineeringJust Digital People PieceDigital June 19, 2015 at 7:04 PM 1 1 Rate This How do you reactivate old code that’s laid dormant for ages? Reusing a variable or route? Reply Pingback: Devops - what is it and why should you care? - Steiniche Pingback: Extended Goals for DevelopingAOD Coding Pingback: Se7en Deadly Sins to Do in Python codeA Techie's Journey Through Life … Ron Barak August 17, 2015 at 7:57 AM 0 1 Rate This Excellent headup for new ({?}) DevOps. Errata: an average daily trading volume of more than 3.3 billion trades [daily] The code that [that] was updated Power Peg would instruct the [the] system Reply Pingback: Confluence: Engineering Pingback: The Power Equation and the Financial Rise of the UKRamen IR Pingback: The Power Equation and the Financial Rise of the UKRamen IR Pingback: Feature Toggles Revisited – Feature Flags, Toggles, Controls Pingback: The Tao of MicroservicesRichard Rodger Pingback: The secret step to save your software from the subtle death of inmaintainabilityThe Coding Flow Pingback: A Buggy Release – Voice of the DBA Joseph Kamal July 26, 2016 at 2:46 PM 0 2 Rate This Awesome writeup, that was a great read and an excellent cautionary tale. Thanks!! Reply quiquedcode July 27, 2016 at 12:54 PM 1 4 Rate This Did the IT office commit massive suicide when daily loss report arrived? Reply Pingback: Node.js Module Replacements, HTTPS Adoption, and Much More - Intertech Blog discreetsecuritysolutions July 31, 2016 at 4:48 AM 1 1 Rate This No killswitch? That’s foolish. Reply Pingback: A computer tech forgot to install some new code… – Crazy Facts Pingback: Quick Fact: A computer tech forgot to install some new code in... - Quick Facts Pingback: Knightmare – Where were the testing and development practices? – Recurring Theme Pingback: Automatizar cambios con la ayuda de Fibonacci – EACHANG Pingback: Powershell: Backup & Copy – Cultivating Software David November 27, 2016 at 9:54 AM 4 0 Rate This Odd how disasters in different industries mimic one another. Look at Deepwater Horizon. Different industry, same mistakes. Only high pressure hydrocarbons unfortunately tend to ignite. The proverbial “Swiss cheese” of barriers with holes in is just the same. $40 billion and still counting… checks and balances and humility are key to eliminating failure. Not cost saving and arrogance. Reply Pingback: Day 1 – Why You Need a Postmortem ProcessDigital Roadies como fazer seu comercio vender mais January 4, 2017 at 6:16 PM 0 0 Rate This A sigla significa Content Management System, trocando em miúdos, Sistema de Governo de Teor. http://pension-gutshof-mihla.de/index.php?mod=users&action=view&id=1597789 Reply Pingback: Martin Fowler and feature branches revisited – james mckay dot net Pingback: Constant Vigilance in Continuous Delivery – How to do DevOps rightOnPage Pingback: Six essential software deployment tools for error-free applications Pingback: Win Your DevOps Conversation with Business LeadersSandeep Joshi Pingback: My Darwin Award for Epic-Failed Startups – Startupon.net Pingback: 5 DevOps Horror Stories That Will Scare Your Pants Off - Typemock Pingback: Feature Flags with FeatureToggleAnton Kalcik Pingback: Challenges from machines – Site Title Pingback: This is why high assurance is key when money is involved. - The HODL Life Pingback: DevOps on business — 4Geeks.io Pingback: Updates uitvoeren, waarom je het beter niet zelf doet ... - Made I.T. Pingback: Data-driven grocery shopping - Data Science Central Pingback: Software Reality – Grumpy Developer Pingback: Reads: Crashing Bond Market Bubbles, Essar Steel Resolution, Riots on Real Estate Fall - Forex Brokers India Pingback: Top 4 DevOps stories from hellDm4r Pingback: Festive week well spent in learning – Wisdom Seeker Pingback: Continuous Delivery: Feature Toggles – Made Tech Blog Pingback: Valuable News – 2019/01/11𝚟𝚎𝚛𝚖𝚊𝚍𝚎𝚗 Pingback: Expertise takes time – Grumpy Developer Pingback: If you were to start React all over again what would you do? [NSFW] – Creative Tech Blog Pingback: IDG Contributor Network: Moving operations to ‘Simple’ with CynefinRadical End Prophesies Before the Rapture Pingback: Collection of Software Bugs - TechBits Pingback: Collection of Software Bugs – News94 Pingback: Collection of Software BugsSTMIK Samarinda Akshat Gupta December 18, 2019 at 11:43 PM 1 0 Rate This Actual problem here is 1. Rollback was incorrect If they rolled back to code to previous working version, how could this dead code’s flag is activated. 2. Missing Prepare and Activate. Blue Green deployments should be compatible. For breaking changes, dead code removal, 2 step deployment process should be followed. 1st deployment should prepare system for this change(logging to see no trace of dead code usage). 2nd deployment should activate this change(removing dead code). Things like this can’t be solved by automated deployment solution alone. How can flag for dead code be activated somehow, with new changes. This is a logical bug, which could not have been prevented by automated deployment. Reply Pingback: 3 Lessons from big software failures Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (From ~$400 Mil to Bankrupt in 45 Minutes) – Hckr News Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (From ~$400 Mil to Bankrupt in 45 Minutes) – Ultimate News Pingback: Knightmare: A DevOps Cautionary Tale (2014) – INDIA NEWS Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (2014) – Outside The Know Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (2014) – The Pakistani News Corner Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (2014) – News about world Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (2014) – protipsss Pingback: New top story on Hacker News: Knightmare: A DevOps Cautionary Tale (2014) – Latest news Pingback: A DevOps Cautionary Tale – Doug Seven - Dhruba's Blog & Online News Pingback: Futureseek Daily Link Review; 6 February 2020Futureseek Link Digest Pingback: Knightmare: A DevOps Cautionary Tale (2014) – Hacker News Robot Pingback: Top story HACKER NEWS: Knightmare: A DevOps Cautionary Tale (2014) - Nate's Blog Leave a Reply TAG CLOUD .NET 4.5 90-days Agile Android Apache Cordova Arduino Azure IoT Build Cloud CSS Device DevOps Google HTML5 Hybrid Icenium Intel Edison iOS IoT IoT Workshop iPad iPhone JavaScript Johnny Five LiveSync MacOS X Marketing Metro style Microsoft Mobile Native Node.js PaaS PhoneGap Positioning Random Raspberry Pi 2 Release Silverlight SW8DPD Telerik ThingLabs UI Visual Studio Visual Studio LightSwitch 2011 Windows 8 Windows 10 IoT Windows Phone WinRT XAML Blog at WordPress.com. Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37459495",
    "commentBody": "Knightmare: A DevOps Cautionary Tale (2014)Hacker NewspastloginKnightmare: A DevOps Cautionary Tale (2014) (dougseven.com) 397 points by sathishmanohar 13 hours ago| hidepastfavorite230 comments lopkeny12ko 13 hours agoI&#x27;m not sure how automated deployments would have solved this problem. In fact, if anything, it would have magnified the impact and fallout of the problem.Substitute \"a developer forgot to upload the code to one of the servers\" for \"the deployment agent errored while downloading the new binary&#x2F;code onto the server and a bug in the agent prevented the error from being surfaced.\" Now you have the same failure mode, and the impact happens even faster.The blame here lies squarely with the developers--the code was written in a non-backwards-compatible way. reply dmurray 13 hours agoparent> The blame here lies squarely with the developers--the code was written in a non-backwards-compatible way.The blame completely lies with the risk management team.The market knew there was a terrible problem, Knight knew there was a problem, yet it took 45 minutes of trying various hotfixes before they ceased trading. Either because they didn&#x27;t have a kill switch, or because no one was empowered to pull the kill switch because of the opportunity cost (perhaps pulling the switch at the wrong time costs $500k in opportunity).I worked for a competitor to Knight at the time, and we deployed terrible bugs to production all the time, and during post mortems we couldn&#x27;t fathom the same thing happening to us. A dozen automated systems would have kicked in to stop individual trades, and any senior trader or operations person could have got a kill switch pulled with 60 seconds of dialogue, and not feared the repercussions. Actually, we made way less of Knight&#x27;s $400m than we could have because our risk systems kept shutting strategies down because what was happening was \"too good to be true\". reply mpeg 12 hours agorootparentIt’s nice to see your perspective as someone familiar with better systems.I have always found this story fascinating; in my junior days I worked at a relatively big adtech platform (ie billions of impressions per day) and as cowboy as we were about lots of things, all our systems always had kill switches that could stop spending money and I could have pulled them with minimal red tape if I suspected something was wrong.And this was for a platform where our max loss for an hour would have hurt but not killed the business (maybe a six figure loss), I can’t imagine not having layers of risk management systems in HFT software. reply blitzar 2 hours agorootparentprevI messed around with the idea of a physical big red button kill switch to shut down market making; the IT people thought I was joking - the trading desk just assumed that it was in the design from day 1. reply pxmpxm 8 hours agorootparentprevThey were asleep at the wheel, not unlike all the random brokerages that blew up when swiss central bank pulled the CHF peg in 2015.This is a culture problem - as soon as you load up your trading firm with a bunch of software industry hires, you end up with jiras and change management workflows instead of people on deck that have context for what they&#x27;re doing. That&#x27;s the only way to explain reverse scalping for 45 mins straight. reply jwestbury 1 hour agorootparent> as soon as you load up your trading firm with a bunch of software industry hiresAs a software industry hire at a hedge fund right now... I&#x27;d love to see more cross-pollination, because there are so many good things happening on both sides, and so many terrible things happening through just a sheer lack of knowledge.Change management workflows are great and should be used more in finance. But software companies should implement andon cord systems more often (Amazon does; nowhere else I&#x27;ve worked gives that power to anybody at the company). reply ycombobreaker 6 hours agorootparentprevThe CHF de-peg wasn&#x27;t really technology risk. Brokers lost money because they undervalued CHF&#x2F;EUR risk, undervalued liquidity risk (stop orders were executing FAR worse than expected, or simply failing to execute at all), and didn&#x27;t pay attention to the legal protections afforded to their customers (customer balances went negative but there was no way to recover that money from the customers). These brokers would have had the same problems even if using pen & paper, they failed to plan (or alternatively, made a conscious bet and lost). reply throwaway2037 3 hours agorootparentI think it is worth saying that no one saw that de-peg coming. Absolutely no one. Sure there are some crazies who saw it coming, but that same camp is still taking for the HKD-USD de-peg. It was a shock to everyone on Wall Street. I am a bit surprised that the Swiss National Bank didn&#x27;t tip off their own banks before doing it. Both UBS and Credit Suisse were seriously caught off guard when it happened. replyeru 4 hours agorootparentprev> Actually, we made way less of Knight&#x27;s $400m than we could have because our risk systems kept shutting strategies down because what was happening was \"too good to be true\".Aren&#x27;t a lot of trades undone anyway by the authorities after such severe market hiccups? reply throwaway2037 3 hours agorootparentThis is a good question. In my experience, I have only see exchange trades reversed when there was a major bug in exchange software. If the bug is on the client side, tough luck. And reversing trades done on an exchange is usually a decision for the exchange regulator. It is a major event that only happens every few years -- at most -- for highly developed exchanges. reply dmurray 2 hours agorootparentReversing or amending a single \"fat finger\" trade happens all the time and the exchange generally has procedures for this that don&#x27;t involve a regulator.Even in the most controversial recent example - LME cancelling a day&#x27;s worth of nickel trades [0]- I understand it was their call and not any external regulator. That said, while I&#x27;d count LME as a \"highly developed exchange\", it&#x27;s the Wild West compared to the US NMS.[0] https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2022-03-14&#x2F;inside-ni... reply eru 1 hour agorootparent> [...] the exchange generally has procedures for this that don&#x27;t involve a regulator.That&#x27;s part of why I vaguely referred to &#x27;the authorities&#x27; in my original comment. I wasn&#x27;t quite sure who&#x27;s doing the amending and reversing, and it wasn&#x27;t too important. reply dmurray 2 hours agorootparentprevNormally trades are undone or amended in price if they are executed far away (say 10%+) from what is determined to be reasonable market prices. And when amended, they get amended to a price that&#x27;s still in the same direction, so the market taker still loses a little bit compared to the fair price.KCG traded in such liquid instruments and in such a way that it didn&#x27;t move the market that much. They lost a hundred dollars a trade on 4 million trades.The article says some stocks were moved by more than 10%, but as I recall that was a small fraction of them. reply movedx 11 hours agoparentprevCI&#x2F;CD would have have solved this 100%:> ... one of Knight’s technicians did not copy the new code to one of the eight SMARS computer servers. Knight did not have a second technician review this deployment and no one at Knight realized that the Power Peg code had not been removed from the eighth server, nor the new RLP code added.Read this part again:> ... one of Knight’s technicians did not *copy the new code to one of the eight SMARS computer servers*.Yes, of course a CI&#x2F;CD pipeline can fail midway through and only partially deploy the code to a partial number of servers, but I doubt it. And even if that were the case, just off the top of my head I can guarantee an Ansible Playbook would have not only stopped the moment that particular transfer failed, the whole Playbook would have therefore failed, and none of the services would have been restarted (because that would be a final step that wouldn&#x27;t be reached.)This was due to human error and is the very reason CI&#x2F;CD&#x2F;automation is a thing.> Knight did not have a second technician review this deployment and no one at Knight realized that the Power Peg code had not been removed from the eighth serverCI&#x2F;CD would have have solved this 100%. A \"Pull Request\" made against a repository of Ansible code (or whatever you flavour is) would have *PREVENTED* the first technician from ever being able to merge the code into master&#x2F;main (because you have master&#x2F;main protected right... right?), completely preventing the entire process from ever rolling out without a review, which would have hopefully caught the misaligned configuration.DevOps, which is mostly underpinned by CI&#x2F;CD, would have solved this 100%. I&#x27;m very certain of this. reply SoftTalker 9 hours agorootparentAnsible in my experience will stop trying to run subsequent tasks on a server once one of them fails, but it will go ahead with other servers that match the inventory pattern. So it very well could have successfully updated 7 out of 8 hosts.Maybe there is a switch that will stop everything if any task on any host fails but it&#x27;s not the default behavior.At least it would have logged an error that hopefully would have been looked at. reply dfinninger 4 hours agorootparentYeah, it’s a runbook config: https:&#x2F;&#x2F;docs.ansible.com&#x2F;ansible&#x2F;2.8&#x2F;user_guide&#x2F;playbooks_er... reply dtech 2 hours agorootparentprev> So it very well could have successfully updated 7 out of 8 hosts.The problem was that the feature flag was manually enabled on the host with old code. Presumably with automated deployment the feature flag would never have been toggled if the deployment failed, either because the deployment didn&#x27;t get that far or because the human spotted the failed deployment. reply BoorishBears 9 hours agorootparentprevI think this is an example of hindsight not always being 20&#x2F;20If you replace each step of the post mortem with a CI&#x2F;CD based alternative, you miss out on the fact CI&#x2F;CD trivializes designs where this wouldn&#x27;t have happened.The \"easy default\" wouldn&#x27;t be to run a play against 8 hosts manually in your terminal, it&#x27;d be run a playbook with them all baked in, and that would fail correctly by default: https:&#x2F;&#x2F;docs.ansible.com&#x2F;ansible&#x2F;latest&#x2F;playbook_guide&#x2F;playb...The key here is CI&#x2F;CD makes it so its actually less work to run that one play than it is to shoot yourself in the foot with 8 separate invocations.Even in the fact of incompetence&#x2F;laziness&#x2F;oversight, the general framework makes the right choice reply dfinninger 4 hours agorootparentThe easy default here would be to have a runbook that executed on a particular inventory group.The “linear” execution strategy is the default (which you linked to). By default, if there is an error on one host it will continue executing on all other hosts. You need to set a flag to stop executing on all hosts[1].The parent process would not be notified of any failures until the end of the run, unless you supplied a custom callback plugin[2].[1] https:&#x2F;&#x2F;docs.ansible.com&#x2F;ansible&#x2F;2.8&#x2F;user_guide&#x2F;playbooks_er...[2] https:&#x2F;&#x2F;docs.ansible.com&#x2F;ansible&#x2F;latest&#x2F;plugins&#x2F;callback.htm... reply BoorishBears 2 hours agorootparentThe problem was a human forgot to run a step and no one noticed: The playbook would have failed and the server wouldn&#x27;t have been online to make orders.If you read the article, the other servers were fine and did not contribute to the issue. reply piyh 7 hours agorootparentprevTree, meet forest. reply ledauphin 13 hours agoparentprevThe blame here may indeed lie with whoever decided that reusing an old flag was a good idea. As anyone who has been in software development for any time can attest, this decision was not necessarily - and perhaps not even likely - made by a \"developer.\" reply manicennui 12 hours agorootparent9 times out of 10, I see developers making the mistakes that everyone seems to want to blame on non-technical people. There is a massive amount of software being written by people with a wide range of capabilities, and a large number of developers never master the basics. It doesn&#x27;t help that some of the worst tools \"win\" and offer little protection against many basic mistakes. reply xupybd 10 hours agorootparentYou have to assume people will make mistakes.A great book on that is this https:&#x2F;&#x2F;www.thenile.co.nz&#x2F;books&#x2F;sidney-dekker&#x2F;the-field-guid... reply hinkley 11 hours agorootparentprevFor a group who so thoroughly despises bosses that operate on &#x27;blame allocation&#x27;, we spend a lot of time shopping around for permission to engage in reckless behavior. Most people would call that being a hypocrite.Whereas I would call it... no, hypocrite works just fine. reply SoftTalker 13 hours agorootparentprevOr at least not by a developer who has made that sort of mistake in the past.I don&#x27;t know what software engineering programs teach these days, but in the 1980s there was very little inclusion of case studies of things that went wrong. This was unlike the courses in the business school (my undergrad was CS major + business minor) nor I would presume what real engineering disciplines teach.My first exposure to a fuckup in production was a fuckup in production on my first job. reply andersa 13 hours agorootparentprevI wonder if this code was written in c++ or similar, the flags were actually a bitfield, and they repurposed it because they ran out of bits.Need a space here? Oh, let&#x27;s throw out this junk nobody used in 8 years and there we go... reply CraigRo 11 hours agorootparentIt is very hard to change the overall size of the messages, and there&#x27;s a lot of pressure to keep them short. So it could have been a bitfield or several similar things... e.g a value in a char field reply bluelightning2k 10 hours agorootparentprevThis sounds particularly plausible with it being high frequency trading. Those presumably have optimisations few other applications have reply paradox242 5 hours agorootparentprevThis is the first thing I thought of because otherwise this story doesn&#x27;t make a lot of sense. reply mijoharas 12 hours agorootparentprevAt the very least have a two deploys - actually removing the old code that relies on it and then repurposing it. Giant foot gun to do it all in one especially without any automated deploys. reply bluelightning2k 10 hours agorootparentGood point. Actually I think I&#x27;ll treat this as a best practice in general when there&#x27;s a transition reply Nekhrimah 12 hours agorootparentprev>whoever decided that reusing an old flag was a good idea.My understanding is that in high frequency trading, minimizing the size of the transmission is paramount. Hence re-purposing an existing flag, rather than adding size to the packet makes some sense. reply lopkeny12ko 13 hours agorootparentprevI doubt any manager or VP cares or knows enough about the technical details of the code to dictate the name that should be used for a feature flag, of all things. reply hinkley 11 hours agorootparentprevFlag recycling is a task that should be measured in months to quarters, and from what I recall of the postmortem they tried to achieve it in weeks, which is just criminally stupid.It&#x27;s this detail of the story which flips me from sympathy to schadenfreude. You dumb motherfuckers fucked around and found out. reply aiunboxed 30 minutes agoparentprevI think the blame is not on either the devops or the developers, it is on the process. If a bug occurs than there should be atleast 5-6 different metrics &#x2F; alerts that should be able to catch the bug. reply schneems 12 hours agoparentprevI see this as a problem of not investing enough in the deploy process. (Disclosure: I maintain an open source deploy tool for a living).Charity Majors gave a talk in Euruko that talked a lot about this. Deploy tooling shouldn’t be a bunch of bash scripts in a trench coat, it should be fully staffed, fully tested, and automated within an inch of its life.If you have a deploy process that has some king of immutable architecture, tooling to monitor (failed&#x2F;stuck&#x2F;incomplete) rollouts, and the ability to quickly rollback to a prior known good stage then you have layers of protection and an easy course of action for when things do go sideways. It might not have made this problem impossible, but it would have made it harder to happen. reply hinkley 11 hours agorootparentI wrote a tool to automate our hotfix process, and people were somewhat surprised that you could kill the process at any step and start over and it would almost always do the right thing. Like how did you expect it to work? Why replace an error prone process with an error prone and opaque one that you can&#x27;t restart? reply bluelightning2k 10 hours agorootparentprevGreat reply.Counterpoint though: that automation in and of itself is more failure area.I can imagine a similar story where the deployment pipeline incorrectly rolled back due to some change in metric format and caused the infinite loss, for example.The thing with these being a 1 in a million chance is that there&#x27;s thousands of different hypothetical causes. The more parts the harder to predict an interaction and we&#x27;ve all been blindsided by something.I would personally hate the stress of working on such high stakes releases. reply schneems 9 hours agorootparentTest test test. If that’s not enough, pick better tools. I’m rewriting bash scripts in rust at work because it gives me the ability to make many invalid states impossible to represent in code. Is it overkill? Maybe, but it is such a huge quality of life improvement.Automated things can fail. Sure. But consider that playbooks are just crappy automation run by unreliable meat computers.Also you can take an iterative approach to automation:- manual playbook only- automate one step of the playbook- if it goes well, move to another. If not, run a retro to figure out out how you can improve it and try again.Stress of failure at a job responsible for deployment architecture is manageable if you have a team and culture built around respecting that stress. There are some areas of code people are more careful around, but largely we make safety a product of our tools and processes and not some heroic “try harder not to screw up” attitude.I find the impact of helping so many developers and their companies rewarding. reply BoorishBears 9 hours agorootparentPart of the solution is at the level of attitude, just one more productive than \"don&#x27;t fuck up\"To create a contrived example, say someone reads your note on replacing bash scripts and decides they agree with the principle.They go into work tomorrow, their fellow engineer agrees on the technical merit, and they reimplement a bunch of bash scripts in Rust with a suite of tests bigger than anyone imagined, and life is great.... fast forward a few months from now and suddenly a state the bash scripts were hiding flares up and everyone is lost, and type safety didn&#x27;t help.A shared culture of \"conservation of value\" can help in a lot of ways there. That&#x27;s the attitude that creation of value is always uncertain, so you prioritize potential future value lower than currently provided value:- instead of looking at technical merit of the new, we prioritize asking: What specific shortcomings the old way have? What can we improve downstream so that the value those systems provide is protected from invalid states we&#x27;re worried about this tool generating?- does switching the language reduce the number of people who can work on it? Do we reduce the effect surface area of the team providing value to it? When hair is on fire do we know the sysops guy won&#x27;t balk?- when it goes down, with a culture of \"conservation of value\", your plan A is always rolling back, there&#x27;s no back and forth on if we can just roll this one fix. If you cause the company to lose a million dollar trade, it&#x27;s already codified that you made the right decisionObviously these are all extensions of a contrived example, but to me culture is heavily utilized as a way to guide better engineering.I think these days people tend to think in terms of culture that affirms, as a reaction to cultures that block anyone from accomplishing anything: to me a good engineering culture is one that clashes with what people want to do just enough to be mildly annoying. reply hooverd 12 hours agorootparentprev> bash scripts in a trench coat That&#x27;s an amazing turn of phrase. reply hinkley 11 hours agoparentprevThe goal with automation is that the number of unidentified corner cases reduces over time.A manual runbook is a game of, \"I did step 12, I think I did step 13, so the next step is 14.\" that plays out every single time you do server work. The thing with the human brain is that when you interrupt a task you&#x27;ve done a million times in the middle, most people can&#x27;t reliably discern between this iteration and false memories from the last time they did it.So unless there are interlocks that prevent skipping a step, it&#x27;s a gamble every single time. And the effort involved in creating interlocks is a large fraction of the cost of automating. reply WJW 1 hour agorootparent1. Print the checklist&#x2F;runbook out on paper with actual empty boxes next to the steps.2. Laminate the printed checklist and put it in a big folder.3. Every time you run the checklist, use a sharpie to mark the checkbox after you&#x27;ve done the step.4. When you are done with the entire process, use whiteboard cleaner to wipe out the checks again and put the checklist back in the big folder with all the other checklists.This is how every safety critical profession (aviation, shipping, medical, power generation, etc) has worked for decades and unless people are willingly being obtuse it is extremely hard to do it wrong. You just need people to turn off their ego and follow the process instead of trying to show off by doing it from memory. This last part might be more difficult in software settings. reply emmelaich 8 hours agoparentprevTechnically, a flag re-use was the most impactful error, code wise.A flag of such importance should not be just on&#x2F;off; the ON should require a positive response &#x2F; receipt containing the name and version of the code being turned on.[edit - don&#x27;t mean for each trade, I mean validation on startup] reply devjab 4 hours agoparentprev> the deployment agent errored while downloading the new binary&#x2F;code onto the serverIn that case the build would never be pushed to production. The worst it would accomplish, and this is if your systems fail, is that it will break your staging area.Sure this is in the the ideal world where people actually know how to set up their deployment pipelines correctly, so you’re likely still right in many cases, but you shouldn’t be. reply thrashh 11 hours agoparentprevI agree. It doesn’t matter if you give an inexperienced person a hammer or a saw — they’ll still screw it up.My biggest pet peeve is they NO ONE ever does failure modeling.I swear everyone builds things assuming it will work perfectly. Then when you mention if one part fails, it will completely bring down everything, they’ll say that it’s a 1 in a million chance. Yeah, the problem isn’t that it’s unlikely, it’s that when it does happen, you’ve perfectly designed your system to destroy itself. reply TheAlchemist 8 hours agorootparentNo one, is quite a bold assumption !It&#x27;s actually quite routine stuff now in finance at least - to perform some kind of &#x27;fire test&#x27; on a regular basis - you shut down some components during the day, and switch to backups solutions, to test everything works smoothly. reply stusmall 12 hours agoparentprevI think the big improvement would be consistency. Either all servers would be correct or all servers would be incorrect. The step where \"Since they were unable to determine what was causing the erroneous orders they reacted by uninstalling the new code from the servers it was deployed to correctly\" wouldn&#x27;t have had a negative impact. They could have even instantly rolled back. Also if they were using the same automated deployment processes for their test environment they might have even caught this in QA. reply moeris 12 hours agoparentprevAutomated deployments would have allowed you to review the deployment before it happened. A failed deployment could be configured to allow automatic rollbacks. Automated deployments should also handle experiment flags, which could have been toggled to reduce impact. There are a bunch of places where it could have intervened and mitigated&#x2F;prevented this whole situation. reply Waterluvian 12 hours agoparentprevWhich really means is a failure of leadership for being so incompetent as to allow such an intensely risky situation to exist. reply lwhi 12 hours agoparentprevAutomated deployments require planning before the time they&#x27;re executed.If code is involved, someone likely reviews and approves it.There are naturally far more safeguards in place than there would be for a manual deployment. reply justinclift 12 hours agorootparentIn an ideal world, sure.In the current one, we have Facebook&#x27;s \"Move fast and break things\" being applied to many things where it has no business being.Banking and communications infrastructure comes to my mind, but there are definitely others. :) reply lwhi 12 hours agorootparentI think the benefits from automated deployments are things that are just par for the course to be honest.Sure, you can mess these things up .. but doing so would involve willful negligence rather than someone&#x27;s absent mindedness.Basically, I think the takeaway from the article is probably worth taking. reply rcpt 11 hours agoparentprevIt seems like the kind of thing that would be canaried which is the kind of thing that you&#x27;d typically build alongside automated deployment reply itsthecourier 10 hours agoparentprevAlso, api versioning. They weren&#x27;t running api versioning on it, they called an old method with a new set of parameters, that shouldn&#x27;t have been possible in first place reply lolinder 8 hours agoprev> why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the pointThis seems to be exactly the point! For 8 years they left unused code in place, seemingly only bothering to remove it because they wanted to repurpose a flag. If they&#x27;d done the right thing 8 years prior and removed code they weren&#x27;t using, this story plays out very differently. No ancient routines get resurrected, no rogue server.Maybe Knight Capital wasn&#x27;t using version control and held onto this code \"just in case\", but I&#x27;ve seen this same resistance to deleting code in programmers working in repos that are completely under VCS, and it&#x27;s flabbergasting. If you need it again, you can always bring it back from version control. If you need it again but forget it&#x27;s there, you&#x27;d do the same with the dead code path. Leaving it in the source tree is pure liability.EDIT: Kevlin Henney gave an excellent talk at GOTO about software reliability and he touches on this, using Knight Capital as the example—he actually cites this very blog post [0]. The whole talk is excellent, but I&#x27;ve linked the three minutes where he talks about Knight Capital.> The problem is there is no code that is truly dead. It turns out all you need to do is make a small assumption, a change of an assumption and then suddenly it&#x27;s no longer dead, it&#x27;s zombie code. It has come back to life and the zombie apocalypse costs money.[0] https:&#x2F;&#x2F;youtu.be&#x2F;IiGXq3yY70o?si=hZ9HB2dlfj0vHvNK&t=463 reply TheDong 6 hours agoparent> I&#x27;ve seen this same resistance to deleting code in programmers working in repos that are completely under VCS, and it&#x27;s flabbergastingI think a lot of developers only know the basics of git. They can check in changes, they can look at history with git log, and maybe they know how to use git blame.They often don&#x27;t know how to filter git history. They often don&#x27;t know about the git pickaxe, or about exclude patterns, and don&#x27;t even think to question if you can do something like \"git log -G&#x27;int.*foo\\(&#x27; -- &#x27;:(exclude)directory&#x27;\" to search for &#x27;foo&#x27; in the git log, excluding some directory.They know how to \"grep\" within the existing code tree though, so they know if it&#x27;s not deleted they can find it again with the right grep. If it&#x27;s deleted, they might not know how to find it in git history.I sympathize with this to a degree actually. Code in the git log is invisible to a lot of tooling, so for example it won&#x27;t show up in autocomplete if your text editor might have otherwise suggested it, it won&#x27;t show up in your library documentation, etc.If you truly think the code will be used again, I think it&#x27;s at least defensible to leave it in the tree so that it comes along for refactors, and ends up being found when it&#x27;s needed.For cases like Knight capital, where it&#x27;s obviously never going to be useful again, it&#x27;s not defensible of course. reply jve 2 hours agorootparent> and don&#x27;t even think to question if you can do something like \"git log -G&#x27;int.*foo\\(&#x27; -- &#x27;:(exclude)directory&#x27;\"I do question it, but I know the answer is hard (as you demonstrated), so I don&#x27;t bother. And I&#x27;m now looking at git log docs - I fail to parse how the exclude works even looking at the docs - I don&#x27;t find anything about `:(` contstruct which houses exclude keyword. But thanks for -G - that will be useful.> Code in the git log is invisible to a lot of toolingThis is the issue. I expect when searching code to have a way to search older commits. But azure devops won&#x27;t do it. There is no checkbox \"Include all commits\" reply lolinder 5 hours agorootparentprevI can understand that argument for small, standalone functions. Where it really gets at me is when people insist on leaving whole use cases or subsystems in place, which seems to be what happened here.You don&#x27;t want these to be visible to autocomplete, because they&#x27;re outdated and would need major modification to be correct again. If you do need to resurrect them, they&#x27;re trivial to find in the git history—just search for the commit named \"remove foo\"—and they should pass through code review as if they were brand new code, because a lot of stuff will have changed around them in the intervening time. reply bhasi 3 hours agorootparentprev> git pickaxe, or about exclude patterns, and don&#x27;t even think to question if you can do something like \"git log -G&#x27;int.*foo\\(&#x27; -- &#x27;:(exclude)directory&#x27;\" to search for &#x27;foo&#x27; in the git log, excluding some directoryLearned something new today, thank you! Will find ways to use these in my daily workflow. reply SoftTalker 6 hours agoparentprev\"If it works, don&#x27;t touch it\" is something I&#x27;ve heard a lot, especially said by managers who don&#x27;t understand what they are talking about.An update to simply \"remove old code\" might be difficult if someone sees any change as creating a risk of something going wrong. And to be fair, any change is a risk, but so is leaving old code around.At least now we have this case to point to as a clear example of the risk. reply asalahli 6 hours agoparentprevI&#x27;m less surprised by them leaving dead code around, honestly. I&#x27;ve seen that happen at virtually every company I&#x27;ve worked for.What completely baffles me everytime I come across their story is that they repurposed an existing flag instead of making a new one! Why? reply SamuelAdams 8 hours agoparentprevVersion control isn’t bulletproof either. All your code history is one git rebase away from being abolished forever.I hope most orgs have processes around their main branches so this does not occur, but I’ve also been in smaller orgs and accidentally screwed up prod database tables, so the accidental git rebase isn’t impossible to consider… reply lolinder 7 hours agorootparentYes, you should definitely have branch protection turned on on main, I kind of assumed that went without saying. But to actually lose your entire git history would require both having no branch protection and having every single developer on your staff be in the regular habit of force rebasing their own branches on main. If a single developer does a double take when they&#x27;re told that their branch has a different history than origin&#x2F;main, then you probably didn&#x27;t lose more than a week of work.Also, it&#x27;s worth noting that this dead code will almost certainly not get reused wherever you decide to store it, so it&#x27;s best to keep it as far away from zombification as possible, even if it&#x27;s not the safest place. reply chii 8 hours agorootparentprev> All your code history is one git rebase away from being abolished foreverunless you also GC right away, it&#x27;s not gone. reply Terr_ 7 hours agorootparentYep, and also:1. You shouldn&#x27;t be allowing anybody to force-push rebased stuff onto major branches in your main repo (the one builds come from) anyway. This is especially important to support auditing and trace-ability.2. Just because the folder is a git-repo isn&#x27;t an excuse not to have it part of your regular offsite backup set. reply gorgoiler 5 hours agorootparentThere are reasons to want branch protection but audit isn’t one of them. An auditable system would be keeping an immutable log of the git repo actions in a separate, append-only location. It wouldn’t rely on the thing being written to all the time, by users, to never get broken. In your model, your audit history only needs one bug in the branch-protection tool for it to be destroyed.Think of it like syslog. It’s good to keep a log of events but it’s bad to rely on the &#x2F;var&#x2F;log&#x2F;syslog on your web server. You should be logging to a remote, append-only system.(However I would concede that if we are talking about lawyer-proof-audit — SOC2, ISO etc — rather than actual security auditing, then branch protection is probably just fine.) reply IshKebab 4 hours agorootparentprevYou&#x27;re very unlikely to lose your version history like that.Everywhere I&#x27;ve worked has branch protection turned on, and backups. Even if those both fail somehow it&#x27;s very likely the complete history is on lots of engineers&#x27; laptops. reply philjohn 3 hours agoparentprevI always remember the Codeless Code on comments when I read about this: http:&#x2F;&#x2F;thecodelesscode.com&#x2F;case&#x2F;41?topic=comments reply pnt12 1 hour agoparentprevnitpick: git is enough to keep the history of old code, but it&#x27;s not great at letting you find it. reply mirekrusin 4 hours agoparentprevThe morale should be \"don&#x27;t reuse feature flags kids\". reply TheAlchemist 8 hours agoprevWild west times ! It&#x27;s worth noting, that things changed a lot in trading systems since then.When I started working in this domain (2009), it was pretty crazy how unreliable those systems were, on all sides - banks, brokers, exchanges. Frequently you needed to make sure over the phone, what quantities got executed etc.I remember when the Italian exchange was rolling out their systems, at some point we did \"tests\" on a mix of production and UAT - if my memory is correct, we were just changing IPs to which to connect for order passing to test for the upcoming release, after the market closed. We couldn&#x27;t just test in their UAT environment, since it was so bugged and half down most of the time.And let&#x27;s not even talk about Excel spreadsheets with some VBA code that would make chatGPT swear, that were pricing instruments with volumes traded with a lot of zeros.It&#x27;s very different nowadays, in part thanks to stories like this one. Most things are automated, and there is much less cowboy&#x27;s attitude.There are mandatory kill switches, a lot of layers of risk &#x2F; trading activity monitorings (on your side, on exchange side), and really a lot of hard learned lessons incorporated into the systems. That&#x27;s also part of the reason why people sometime tend to be naive about how hard it is to build a good trading system - the strategies are sometimes now really smart - it&#x27;s mostly about how to avoid getting killed by something that&#x27;s outside of usual conditions. reply hedora 13 hours agoprevNo continuous deployment system I have worked with would have blocked this particular bug.They were in a situation where they were incrementally rolling out, but the code had a logic bug where the failure of one install within an incremental rollout step bankrupted the company.I’d guard against this with runtime checks that the software version (e.g. git sha) matches, and also add fault injection into tests that invoke the software rollout infrastructure. reply kccqzy 8 hours agoparentNo continuous deployment system worth its salt would allow configuration and code to be out of sync. They had a configuration change to turn on a flag that used to enable Power Peg but now enabled something else, plus a code change to reinterpret that flag differently. reply chii 7 hours agorootparentthe situation is caused by a confluence of multiple issues.The biggest red-flag is that they chose to repurpose a flag! Why? Is it really difficult to add a new flag for a new feature?Even if the technician was careful not to let prod be out of sync, it is possible that the deployment isn&#x27;t instantaneous, and that the old code could&#x27;ve ran when the repurposed flag was turned on. reply atomicnumber3 5 hours agorootparentSome of the trickiness that comes from HFT and adjacent things like this is you can be working on tremendously powerful hardware but still be miserly about bits because every extra byte you have to cram into a packet is extra latency. The HFT firm I worked for would \"re-use flags\" in the sense that each packet literally had an 8-bit section called \"flags\" (and further down in the message, another 8 bit section called flags2 because of course) and each bit in there was a Boolean that could be on or off - a flag. So we weren&#x27;t reusing flags as much as we were re-allocating what a high bit at that index in flags meant.We were very conscious of this kind of error though and we managed them like Scrooge counting his farthings. reply valdiorn 13 hours agoprevLiterally everyone in quant finance knows about knight capital. It even has its own phrase; \"pulling a knight capital\" (meaning; cutting corners on mission critical systems, even ones that can bankrupt the company in an instant, and experiencing the consequences) reply shric 12 hours agoparentIndeed, it&#x27;s used in onboarding material at my employer. reply mxz3000 11 hours agorootparentYeap, it&#x27;s used as a case study for us as to the worst case scenario in trading incidents. Definitely humbling. reply atomicnumber3 5 hours agorootparentprevSame, we knew of it as the Knightmare too. reply pavas 13 hours agoprevMy team&#x27;s systems play a critical role for several $100M of sales per day, such that if our systems go down for long enough, these sales will be lost. Long enough means at least several hours and in this time frame we can get things back to a good state, often without much external impact.We too have manual processes in place, but for any manual process we document the rollback steps (before starting) and monitor the deployment. We also separate deployment of code with deployment of features (which is done gradually behind feature flags). We insist that any new features (or modification of code) requires a new feature flag; while this is painful and slow, it has helped us avoid risky situations and panic and alleviated our ops and on-call burden considerably.For something to go horribly wrong, it would have to fail many \"filters\" of defects: 1. code review--accidentally introducing a behavioral change without a feature flag (this can happen, e.g. updating dependencies), 2. manual and devo testing (which is hit or miss), 3. something in our deployment fails (luckily this is mostly automated, though as with all distributed systems there are edge cases), 4. Rollback fails or is done incorrectly 5. Missing monitoring to alert us that issue still hasn&#x27;t been fixed. 5. Fail to escalate the issue in time to higher-levels. 6. Enough time passes that we miss out on ability to meet our SLA, etc.For any riskier manual changes we can also require two people to make the change (one points out what&#x27;s being changed over a video call, the other verifies).If you&#x27;re dealing with a system where your SLA is in minutes, and changes are irreversible, you need to know how to practically monitor and rollback within minutes, and if you&#x27;re doing something new and manually, you need to quadruple check everything and have someone else watching you make the change, or its only a matter of time before enough things go wrong in a row and you can&#x27;t fix it. It doesn&#x27;t matter how good or smart you are, mistakes will always happen when people have to manually make or initiate a change, and that chance of making mistakes needs to be built into your change management process. reply coldtea 12 hours agoparent>My team&#x27;s systems play a critical role for several $100M of sales per day, such that if our systems go down for long enough, these sales will be lost.Would they? Or would they just happen later? In a lot of cases in regular commerce, or even B2B, the same sales can often be attempted again by the client for a little later, it&#x27;s not \"now or never\". As a user I have retried things I wanted to buy when a vendor was down (usually because of a new announcement and big demand breaking their servers) or when my bank had some maintainance issue, and so on. reply pavas 12 hours agorootparentIt&#x27;s both (though I would lean towards lost for a majority of them). It&#x27;s also true that the longer the outage, the greater the impact, and you have to take into account knock-on effects such as loss of customer trust. Since these are elastic customer-goods, and ours isn&#x27;t the only marketplace, customers have choice. Customers will typically compare price, then speed.It&#x27;s also probably true that a one-day outage would have a negative net present value (taking into account all future sales) far exceeding the daily loss in sales, due to loss of customer goodwill. reply yardstick 12 hours agorootparentprevIt would be a serious issue for in person transactions like shops, supermarkets, gas stations, etcImagine Walmart or Costco or Chevron centralised payment services went down for 30+ mins. You would get a lot of lost sales from those who don’t carry enough cash to cover it otherwise. Maybe a retailer might have a zapzap machine but lots of cards aren’t imprinted these days so that’s a non starter too. reply squeaky-clean 10 hours agorootparentNot just lost sales. I&#x27;ve seen a Walmart lose all ability to do credit card sales and after about 5 minutes maybe 10% of people waiting just started leaving with their groceries in their cart and a middle finger raised to the security telling them to stop. reply kaashif 11 hours agorootparentprev> Maybe a retailer might have a zapzap machine but lots of cards aren’t imprinted these days so that’s a non starter too.When I Google \"zapzap machine\" this comment is the only result, but after looking around on Wikipedia, I see this is a typo for \"zipzap\".Is this really the only time in history someone has typoed zipzap as zapzap? I guess so. reply HellsMaddy 10 hours agorootparentFor anyone who is still confused: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Credit_card_imprinter reply yardstick 10 hours agorootparentprevHaha yeah I guess so! Last time I used one was in the previous millennium. replyjammycakes 1 hour agoprevThis incident highlights a problem that is often overlooked in the debate about feature branches versus feature toggles.I&#x27;ve worked with both feature branches and feature toggles, and while long lived feature branches can be painful to work with what with all the conflicts, they do have the advantage that problems tend to be uncovered and resolved in development before they hit production.When feature toggles go wrong, on the other hand, they go wrong in production -- sometimes, as was the case here, with catastrophic results. I&#x27;ve always been nervous about the fact that feature toggles and trunk based development means merging code into main that you know for a fact to be buggy, immature, insufficiently tested and in some cases knowingly broken. If the feature toggles themselves are buggy and don&#x27;t cleanly separate out your production code from your development code, you&#x27;re asking for trouble.This particular case had an additional problem: they were repurposing an existing feature toggle for something else. That&#x27;s just asking for trouble. reply foota 12 hours agoprevThe real issue here (sorry for true Scotsman-ing) is that they were using an untested combination of configuration and binary release. Configuration and binaries can be rolled out in lockstep, preventing this class of issues.Of course there were other mistakes here etc., but the issue wouldn&#x27;t have been possible if this weren&#x27;t the case. reply skizm 10 hours agoprevI feel like the first thing I would build into any automated trading system is a kill switch? then every single diff or pull request I add would have some sort of automated testing to ensure the kill switch still works. Also I&#x27;d manually flip it on&#x2F;off once a day to make sure it works for real. That seems like the single most important thing to build and make sure works. Or is the system too complex for something like this and I don&#x27;t understand the domain well enough? reply slavboj 6 hours agoparentDepending on what you&#x27;re doing, a straight \"pull the plug and stop trading\" could leave you with eg unhedged positions that blow through your risk limits. But when your ability to actually execute those trades sensibly is broken regardless, yeah, you&#x27;re still going to want to hit that button. reply atomicnumber3 5 hours agoparentprevMost systems do. At pastjob we had a few different levels:- halt - just stop trading- exit-only - only exit positions (but do so according to our alphas, no hurry)- flatten - exit in a hurry but obey certain limits (often if liquidity was thin we would just \"journal\" the shares - move them to a long-term-hold (meaning more than the current day) account to exit in the opening auction the next day- market exit - get the fuck out, now, no matter what the cost.I never saw us use that last one. reply dang 11 hours agoprevRelated:Knightmare: A DevOps Cautionary Tale (2014) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22250847 - Feb 2020 (33 comments)Knightmare: A DevOps Cautionary Tale (2014) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8994701 - Feb 2015 (85 comments)Knightmare: A DevOps Cautionary Tale - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=7652036 - April 2014 (60 comments)Also:The $440M software error at Knight Capital (2019) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31239033 - May 2022 (172 comments)Bugs in trading software cost Knight Capital $440M - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4329495 - Aug 2012 (1 comment)Knight Capital Says Trading Glitch Cost It $440 Million - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4329101 - Aug 2012 (90 comments)Others? reply SoftTalker 8 hours agoparentEarly theory about the cause (incorrect, as it turns out):Nanex ~ 03-Aug-2012 ~ The Knightmare Explaned - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=4337359 (no comments) reply dkarl 12 hours agoprev> why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the pointIt&#x27;s not the worst mistake in the story, but it&#x27;s not \"not the point.\" A proactive approach to pruning dead functionality would have resulted in a less complex, better-understood piece of software with less potential to go haywire. Driving relentlessly forward without doing this kind of maintenance work is a risk, calculated or otherwise. reply stevage 4 hours agoprev>They had 48-hours to raise the capital necessary to cover their losses (which they managed to do with a $400 million investment from around a half-dozen investors).I&#x27;m very curious about this bit. How exactly do you raise $400m of \"investment\" to cover such a massive footgun, in 48 hours, when you haven&#x27;t even had time to understand what happened or whether it would happen again?Why are people stumping up hundreds of millions of cash here? reply quickthrower2 9 hours agoprevHold on. Are we blaming the plane crash on the pilot here? It seems there is so much other stuff wrong with this company first that such a deployment would tank it.No kill switch. Literally needs to be a power switch and a trader who runs to the room and flips it. Ridiculously small amount of cash for the trading volume, and no way to borrow more to stay in business (but that borrowing requiring manual intervention no accessible to the trading system). Obviously the decision to leave that code in there, and for there to be config setting to bring it back.Then the devops stuff - rollback plans, approvals, pairing on deployments, etc. reply daft_pink 13 hours agoprevI&#x27;m so glad I don&#x27;t write code that automatically routes millions of dollars with no human intervention.It&#x27;s like writing code that flies a jumbo jet.Who wants that kind of responsibility. reply Waterluvian 12 hours agoparentIt’s not scary when it’s done properly. And done properly can look like an incredibly tedious job. I think it’s for a certain kind of person who loves the process and the tests and the simulators and the redundancy. Where only 1% of the engineering is the code that flies the plane. reply callalex 12 hours agoparentprevIt’s fine to have that kind of responsibility, but it has to actually be your responsibility. Which means you have to be empowered to say “no, we aren’t shipping this until XYZ is fixed” even if XYZ will take another two years to build and the boss wants to ship tomorrow. reply salawat 11 hours agorootparentYep. Until the capacity to say unoverridably \"No\" materializes, there&#x27;s a lot of code I refuse to have responsibility for delegated to me. reply wruza 11 hours agorootparentAs a profit non-taker, which responsibility a worker can even have? Realistically it lies in range of their monthly paycheck and pending bonuses and in a moral obligation to operate a failing system until it lands somewhere. Everything above it is a systemic risk for a profit taker which if left unaddressed is absolutely on them. There’s no way you can take responsibility for $400M unless you have that money. reply wruza 11 hours agoparentprevIt feels anxiety inducing at first, but if you have good controls and monitoring in place, it becomes daily routine. You basically address the points you naturally have and the more reasonably anxious you are, the better for the business. From my experience with finance, I’d wager that problem at Knight was 10% tech issues, 90% CTO-ish person feeling ballsy. In general, not exactly that day or week. reply shric 8 hours agoparentprevI don&#x27;t know if it&#x27;s like this at every company, but typically there are plenty of humans keeping a close eye on what&#x27;s going on whenever the software is placing orders on an exchange.I suspect we can thank this incident in part. reply hgomersall 13 hours agoparentprevI&#x27;m so glad I&#x27;m not wasting my life working in finance. reply shric 12 hours agorootparentI&#x27;ve worked in various small to medium IT companies, a FAANG and another fortune 500 tech company. 6 months ago I moved to a proprietary trading company&#x2F;market maker and it&#x27;s the most interesting and satisfying place I&#x27;ve worked so far.I hope to continue to \"waste my life\" for many years to come. reply hammeiam 11 hours agorootparentMay I ask which one, and what your process was that led you to them? reply pxmpxm 8 hours agorootparentprevActually it&#x27;s one of the few truly intellectually-pure endeavors. Everything else is the same pursuit with extra steps:Make a trading strategy to make moneyvsMake a cutting edge machine learning classifier to back out latent meaning in search queries to produce better search results to drive more traffic to google to sell ads to make money reply hgomersall 3 hours agorootparentYou&#x27;re not wrong, but the problem is those steps are also the steps that produce food, or improve health, or solve climate change or solve any of the innumerable problems we face as a society. As you identify, there are plenty of pursuits other than finance that are not particularly socially useful - it&#x27;s not a very exclusive club. reply TheAlchemist 9 hours agorootparentprevOut of curiosity - in what domain do you work ?I find the work in finance &#x2F; tech very interesting. Societally useful ? Almost certainly not. But probably still more than most good-paying tech jobs. reply m463 12 hours agoparentprev> It&#x27;s like writing code that flies a jumbo jet.and upgrading it from a coach seat reply Galanwe 4 hours agoparentprevThings are somewhat different now than 5, 10, 20 years ago.There has been a wave of \"individual accountability regimes\" released by pretty much every regulator.I have worked with the SFC the most, so that&#x27;s what I will describe here, but all these regulations are pretty much copy&#x2F;paste of each other anyway.I was MIC under the SFC (HK) for various operational and financial resps for approx 8 years responsible for close to $3B exposure across equities, IRS & FX, and am now licensed with the FCA (UK) since approx 1 year.Basically, on top of the usual regulatory framework defining a top level Operating Officer (MOO) and subordinate Responsible Officers (RO), the new individual accountability regime creates the notion of Managers In Charge (MIC).The MICs fill the gap that, increasingly, a considerable amount of operational responsibility lie in the hands of non licensed individuals (i. e. tech people).The SFC defines a number of responsabilites (e.g. DRP&#x2F;BCP, kill switches, backups, fail overs, rollbacks, load testing, etc) and these responsibilites need to be allocated to one or more of the allocated MIC.The SFC has a right to reject an appointment of MIC if the individual is not seen as fit and proper (that is assessed generally on an annual basis by a compliance officer, but can be re-assessed on the spot if you end up displaying unfit traits). The SFC also mandates a track record of experience and expertise on the assigned responsibilities, as well as a direct capability by the MIC to have control on his responsibilities. In clear terms, that means you need to have the actual power of saying \"no\", you need to have the power to hire someone if that is necessary for the safety of the operations, etc.Once you get appointed as MIC, most of your responsibilities are based on _means_, not _end results_:If Karen breaks production, that&#x27;s not much of your problem (regulatorily speaking) as long as you can demonstrate that you had Karen attend 6h of training this year on how not to break production.In terms of actual developer experience, the _means_ often take the form of trainings, code review, pre prod impact assessment, incident reporting procedures, etc.So on one hand you have a very heavy personal and professional responsibility. But on the other end you are at fault only if you did not setup a proper framework for things to work.In terms of the professional responsibility, there is not much to do if you are deemed guilty. You will most likely be temporarily or permanently barred from having a licensed position. Nobody will hire you anyway.For the personal responsibility, it is usually limited to single digit millions, and most big asset managers have an insurance to protect you (otherwise noone would accept the role).If you are interested in the actual additional responsibilities that were added after KC, then I suggest you have a look at MiFID II (the European régulation, well written and understandable), especially segment RTS 6 \"Technical standards specifying the organisational requirements of investment firms engaged in algorithmic trading\":https:&#x2F;&#x2F;ec.europa.eu&#x2F;finance&#x2F;securities&#x2F;docs&#x2F;isd&#x2F;mifid&#x2F;rts&#x2F;1... reply hyperhopper 13 hours agoprevYes, the deployment practices were bad, but they still would have had an issue even with proper practices.The real issue was re-using an old flag. That should have never been thought of or approved. reply amluto 13 hours agoparentI would argue the real issue was the lack of an automated system (or multiple automated systems) that would hit the kill switch if the trading activity didn’t look right. reply leaflets2 4 hours agorootparentYes definitely, one has to assume that from time to time, bugs will reach the prod servers, no amount of tests and code review can completely prevent that.Hopefully the kill switch system is reasonably easy to code review and test :-) reply distortionfield 12 hours agorootparentprevBut how would you even start to define something as stochastic as trading activity as “not looking right”? reply Jorge1o1 11 hours agorootparentI’ve had to fill out forms for new algorithms &#x2F; quant strategies with questions like:- how many orders per minute do you expect to create?- how many orders per minute do you expect to cancel&#x2F;amend?- what’s your max per-ticker position?- what’s your max strategy-level GMV&#x2F;NMV?Etc.Any one of those questions can be used to set up killswitches.[edited for formatting] reply distortionfield 10 hours agorootparentSure, but there is always the possibility that then you shut down trading when things _arent_ broken.There are always two error rates.Defining behavior is great for retrospective analysis but would you really feel comfortable putting hard cuts into production based on the answers to those questions? I’m genuinely asking, because IME I wouldn’t be. reply amluto 8 hours agorootparentThat last nine in a trading system uptime has exponentially low value unless you have customers who care quite a lot.Seriously, suppose you have a truly awesome system making $100B per year of revenue. If you unnecessarily shut down 0.1% of the time, that’s only $100M per year lost, and an 0.1% unnecessary shutdown rate seems pretty high. reply distortionfield 8 hours agorootparent> That last nine in a trading system uptime has exponentially low valueIME that last 9 is where all the action happens> unless you have customers who care quite a lotAll customers care about their trades. I’ve worked with these systems. You can’t treat smaller traders as less-than.> only $100MHow far removed from the problem do you have to be to think one hundred million dollars is not going to effect anyone? reply Narkov 5 hours agorootparent> How far removed from the problem do you have to be to think one hundred million dollars is not going to effect anyone?If $10b is at risk, $100m is not a lot for an insurance policy. reply amluto 5 hours agorootparentprevNot all automated trading systems have customers. reply leaflets2 4 hours agorootparentprevA way to add limits when being clueless:Estimate what a real human can do in a day, and use that as the limits. Verify that the system behaves ok for some time, then scale up the desired trading volume and limits, observe, scale, repeat.But you don&#x27;t do it by making a (bad) guess up front and then just leaving it at that. reply piyh 7 hours agorootparentprev\"If we lose 100 million dollars in 20 minutes\" seems like a good one. reply mxz3000 12 hours agorootparentprevspamming the market with orders for one reply distortionfield 10 hours agorootparentDefine “spamming”, then? High frequency traders would probably look a lot like spammers.There are always two error rates. reply matkoniecz 1 hour agoparentprevThere are multiple real root issues here. Missing manual kill switch is also one of them. reply rwmj 12 hours agoparentprevThere&#x27;s definitely more to this story. Why was there a fixed number of \"flags\" so that they needed to be reused? I wish there was a true technical explanation. reply Neil44 13 hours agoparentprevI can only think that it was some kind of fixed binary blob of 1&#x2F;0 flags where all the positions had been used umpteen times over the years and nobody wanted to mess with the system to replace it with something better. reply notnmeyer 13 hours agoparentprevthis is what stood out to me reading the story. i wonder if there was a reason why they opted for this, however half-baked.it reads less to me like a case for devops as it does a case for better practices at every stage of development. how arrogant or willfully ignorant do you have to be to operate like this considering what’s at stake? reply SoftTalker 13 hours agorootparentThey probably already had a bitfield of feature flags, maybe it was a 16-bit integer and full, and someone notices \"hey this one is old, we can reuse it and not have to change the datatype\" reply notnmeyer 13 hours agorootparentah, yeah—hadn’t considered that! reply xyst 12 hours agoprevHaving worked in some Fortune 500 financial firms and low rent “fintech” upstarts, I am not surprised this happened. Decades of bandaid fixes, years of rotating out different consultants&#x2F;contractors, and software rot. Plus years of emphasizing mid level management over software quality.As other have mentioned, I don’t think “automation of deployment” would have prevented this company’s inevitable downfall. If it wasn’t this one incident in 2014, then it would have been another incident later on. reply jonplackett 12 hours agoparentThe thing I was surprised about is that they survived!After all that they still got a $400 million cash bailout! reply xcv123 12 hours agorootparentThey were probably worth much more than $400M before the failure so it was a good investment opportunity. They would have been a money printing machine aside from this one major fuckup. reply nly 11 hours agorootparentTheir IP (proprietary trading algos) etc were probably worth a lot at the time.These days probably not so. I wouldn&#x27;t imagine there are any market makers left in NYSE and NASDAQ who aren&#x27;t deploying FPGAs to gain a speed edge. reply m_0x 12 hours agorootparentprevIt wasn&#x27;t a bailout, it was investment money.Bailout could imply government throwing a lifeguard reply kaashif 12 hours agorootparent> It wasn&#x27;t a bailout, it was investment money.Almost all bailouts are investments, whether it&#x27;s a government or private bailout.The investments are questionable sometimes, but they&#x27;re still investments. reply leoqa 12 hours agorootparentThe nuance is a) what happens to existing equity stakeholders and b) does the bailout have to be repaid.If the answer is nothing and no, then it’s a bailout philosophically. If the existing investors get diluted then they’re in part paying for the new capital injection. reply ben-gy 12 hours agorootparentprevIt wasn’t a bail out, it was an opportunity for investors to get great terms on equity at a crucial juncture for the company. reply swores 12 hours agorootparentA government bail out isn&#x27;t the exclusive use of the phrase \"bail out\", it was both a bail out and an opportunity for investors to get great terms on equity. reply hinkley 12 hours agoparentprevIt&#x27;s an entire industry built on adrenaline, bravado, and let&#x27;s be honest: testosterone. How could their IT discipline be described as anything other than \"YOLO\"?Trading is mostly based on a book that, like the waterfall model, was meant to be a cautionary tale on how not to do things. Liars&#x27; Poker had the exact opposite effect of Silent Spring. Imagine if Rachel Carson&#x27;s book came out and people decided that a career in pesticides was more glamorous than being a doctor or a laywer, we made movies glorifying spraying pesticides everywhere and on everything, and telling anyone who thought you were crazy that they&#x27;re a jealous loser and to fuck off. reply gumballindie 13 hours agoprev> Had Knight implemented an automated deployment system – complete with configuration, deployment and test automation – the error that cause the Knightmare would have been avoided.Would it have been avoided though? Configuration, deployment and test automation mean nothing if they don&#x27;t do what they are supposed to do. Regardless of how many tests you have, if you don&#x27;t test for the right stuff it&#x27;s all useless. reply bluelightning2k 10 hours agoparentYes. It would have.The specific part is configuration as code. So the config change (flag activation) and code change (flag calling) would have been synchronized.And there wouldn&#x27;t have been one server of 8 with a different build for a meaningful time and also if it did fail to deploy on that one server it would have been obvious. reply brundolf 9 hours agoprevMuch as I enjoy articles that reinforce my existing beliefs, high-frequency trading is a pretty extreme example when it comes to how how badly things can go in a short time reply dilyevsky 10 hours agoprevTheir issue was neglecting an automated SCRAM system that would halt all the trading or any alerting with manual intervention. The article touches on that. There was no excuse why the system wasn’t halted by 9:32 which would’ve avoided most of the kerfuffle reply mariusmg 1 hour agoprevFirst problem was repurposing flags used in the past for different functionality. Just dont do that. reply civilized 10 hours agoprevI see a lot of criticism of the deployment, but why did the developers \"repurpose an old flag\" that activates 8 years dead code that you haven&#x27;t deleted and that has completely unknown current functionality? That seems like the strangest decision made in this debacle. reply leaflets2 4 hours agoparentTo save time, I guess. They deleted the inactive code, so, why not, they thought. But then they forgot to deploy that change (to one server).Bugs and configuration errors will happen from time to time, and might look silly in retrospect. But the real problem was, I think, that there was no kill switch (managers and tech leads should have decided to add long ago) reply supportengineer 13 hours agoprevThey were missing any kind of risk mitigation steps, in their deployment practice. reply hyperhello 13 hours agoparentThere’s no money for that. reply earnesti 13 hours agorootparentIt is funny, but in one company I was working for, the more people they added the more they neglected all basics, such as backups. There were heavy processes for many things and they were followed very well, but for whatever reasons some really basic things went unnoticed for many years. reply Gibbon1 12 hours agoparentprevI think Goldman Sachs or someone big like that had a similar oopsie. And what happened was the exchange reversed all their bad trades. reply zsoltkacsandi 5 hours agoprevThis has nothing to do with “DevOps”, and I am getting tired of this word. This mistake could have been prevented on multiple levels, and in my experience, deployments that involves major architectural changes rarely repeatable or can be fully automated. reply motoboi 11 hours agoprevChanges we make to software and hardware infrastructure are essentially hypotheses. They&#x27;re backed by evidence suggesting that these modifications will achieve our intended objectives.What&#x27;s crucial is to assess how accurately your hypothesis reflects the reality once it&#x27;s been implemented. Above all, it&#x27;s important to establish an instance that would definitively disprove your hypothesis - an event that wouldn&#x27;t occur if your hypothesis holds true.Harnessing this viewpoint can help you sidestep a multitude of issues. reply KnuthIsGod 5 hours agoprevNot so simple. The company was then used as a building block to to create another entity, which was then acquired for over a billion dollars.\"The company agreed to be acquired by Getco LLC in December 2012 after an August 2012 trading error lost $460 million. The merger was completed in July 2013, forming KCG Holdings....On April 20, 2017, KCG announced that it had agreed to be acquired by Virtu Financial for $20 per share in cash in a deal valued at approximately $1.4 billion.\" reply nickdothutton 13 hours agoprev“The code that that was updated repurposed an old flag…” Was as far as I needed to read. Never do this. reply taspeotis 13 hours agoprevNeeds (2014) in the title. reply danielvaughn 8 hours agoprevI worked in fintech for a few years. I&#x27;ll never again work on software that&#x27;s responsible for trading, you could offer $1M&#x2F;year and I wouldn&#x27;t take it. By far the most stress I&#x27;ve ever experienced at a job. reply CraigRo 5 hours agoparentWe used to tell each other what stall we were going to. It is fun, like playing video games, but also super stressful. reply 0xFEE1DEAD 10 hours agoprevI don&#x27;t exactly understand what this has to do with continuous delivery, but maybe I just don&#x27;t know enough about this topic.Wouldn&#x27;t it have been best to set up a &#x27;shadow infrastructure&#x27; and route every trade into it for several weeks&#x2F;months to verify the correctness of the system? reply siliconc0w 9 hours agoprevWhile nice automated deployment is the wrong lesson here, it&#x27;s really not anticipating backwards incompatibility and poor altering and incident training.Flags should never be reused and should be retired after they&#x27;re no longer useful. reply ChrisMarshallNY 8 hours agoparent> Flags should never be reused and should be retired after they&#x27;re no longer useful.That&#x27;s such a \"no-brainer,\" that I don&#x27;t think it&#x27;s even written down, anywhere.When I read that, I was like, \"Whut?\"In the Days of Yore, when we hammered programs directly into the iron as Machine Code, we would do stuff like that, but I can&#x27;t even imagine doing that with any halfway modern language. They don&#x27;t say, but it&#x27;s probably C++. I know that&#x27;s popular for HFT. reply SoftTalker 5 hours agorootparentPossibly Fortran. reply gumby 12 hours agoprev> (why code that had been dead for 8-years was still present in the code base is a mystery, but that’s not the point).Actually it&#x27;s a big part of the point: they have a system that works with dead code in it. If you remove that dead code perhaps it unwittingly breaks something else.That kinds of chesterson&#x27;s fence is a good practice. reply rkuykendall-com 12 hours agoparentLeaving dead code in is not good practice?? I would love more explanation here because that sounds like crazy talk to me. reply OtherShrezzing 12 hours agorootparentChesterton&#x27;s Fence states that you shouldn&#x27;t make a change until you understand something&#x27;s current state. Removing code because it&#x27;s dead is folly, if you don&#x27;t understand 1) why it&#x27;s there, and 2) why nobody else removed it yet. reply meiraleal 12 hours agorootparentAs this is a postmortem, it was proven dead code. There is nothing in the text that mentions that they didn&#x27;t know what the code did (which then wouldn&#x27;t be dead code). reply lionkor 12 hours agorootparentprevIt may not be obvious that it&#x27;s dead code - in a lot of popular interpreted languages, it&#x27;s impossible to tell if a given function can be called or not reply gumby 12 hours agorootparentprevYou&#x27;ll have to ask the author of the article. reply fphhotchips 12 hours agorootparentYour original comment is somewhat unclear. Are you advocating for leaving old code in because the system works and it&#x27;s more stable that way, or taking it out to force the necessary refactoring steps and understanding that will bring? reply gumby 12 hours agorootparentI&#x27;m sorry I wasn&#x27;t clear: I re-read my comment and couldn&#x27;t think of a decent edit.It was the author whom I was quoting as saying \"why would someone have old code lying around.\" It seems obvious why that&#x27;s a good idea and it seems commenters in this thread (including you) agree with me and not the author.Sorry again if I was unclear. reply_boffin_ 7 hours agoprevIf you want to see how it looked like from the tick scale, take a look here: http:&#x2F;&#x2F;www.nanex.net&#x2F;aqck2&#x2F;3522.htmlPs. Anyone know of any other sites &#x2F; places that does comparable level of research that&#x27;s open to the public? reply codegeek 12 hours agoprevI refuse to believe that failed deployment can bring a company down. That is just a symptom. The root cause has to be a whole big collection of decisions and processes&#x2F;systems built over years. reply roughly 8 hours agoprevThis is the Ur “devops fuckup” tale - I’ve told this to junior engineers who’ve bodged a deploy to make them feel better. I’ve been in this field for 20 years, and I can’t imagine I’ll ever have a day as bad as the engineers who got bit by this fuckup. reply markus_zhang 10 hours agoprevSometimes I think whether these events are more sinister than they appear to be. But then I heard that another MM is using Access applications to make markets for options and I think it&#x27;s just incompetent. reply firesteelrain 11 hours agoprevAutomation is not a silver bullet. Automation is still designed by humans. Peer reviews, acceptance test procedures, promotion procedures, etc all would have helped. And yes some of those things are manual. Sandbox environments, etc reply hinkley 12 hours agoprev> $400M in assets to bankruptWas this Knight Capital?> Knight Capital GroupYep. Practically the canonical case study in deployment errors. reply thorum 13 hours agoprevHonestly seems like the market itself should have safeguards against this kind of thing. reply SoftTalker 13 hours agoparentThe safeguard is \"you go bankrupt if you fuck up\"Imagine there was some way for a trading company to execute billions of dollars of trades and they say \"ooops, sorry, that was all a mistake\" can you not see how that would be abused?Now, the story also says that within a minute of the market opening, the experienced traders knew something was wrong. Do they bear any culpability for jumping on those trades, making their money off of something they knew couldn&#x27;t be intentional? reply harerazer 8 hours agorootparentThis isn’t really correct. Typically exchanges have safety parameters which market makers can set according to how they wish to trade, and if you exceed those your orders will no longer be accepted and existing orders may also be pulled.Obviously there are false positives occasionally and there is typically communication between the exchange and the market maker to ensure those don’t reoccur. reply bluelightning2k 10 hours agorootparentprevA safeguard doesn&#x27;t have to be a revert.A safeguard could be rate limiting. And or the ability to disable an API key or whatever the equivalent is.This actually seems pretty reasonable to me. reply alpark3 12 hours agoparentprevIt&#x27;s interesting to note that exchanges are adding \"obvious error\" rules that can slash trades under certain circumstances. reply piyh 7 hours agoprevThis can be summarized as \"terminally inadequate technical controls\" reply codeulike 12 hours agoprevWhen I got to the memorable words \"Power Peg\" I remembered I&#x27;d heard all about this before. reply cdchn 8 hours agoprevGood example of a blameless port mortem. reply reedf1 13 hours agoprevGotta imagine the sinking feeling that guy felt. reply cratermoon 5 hours agoprevNot removing old code is akin to never throwing away food, even after it reaches its expiration date. Sure, you&#x27;ll have it around next time you need it, but putting year-old yeast into your baguettes is, well, a recipe for disaster. reply hollerith 5 hours agoparentAlso on the tiny chance you really need the old code, you can dredge it up from your version-control system. reply m3kw9 12 hours agoprevSomeone missed a blind spot reply jokoon 11 hours agoprevOh noAnyways reply tomp 13 hours agoprevAh, Knight Capital. The warning story for every quant trader &#x2F; engineer.This is what people don&#x27;t realize when they say HFT (high frequency trading) is risk-free, leeching off people, etc.You make a million every day with very little volatility (the traditional way of quantifying \"risk\" in finance) but one little mistake, and you&#x27;re gone. The technical term is \"picking up pennies in front of a steamroller (train)\". Selling options is also like that. reply loa_in_ 13 hours agoparentI don&#x27;t see how anything here goes against it leeching off people reply Nevermark 13 hours agorootparentLeeching implies someone has found a way to skim value from you without providing value.Someone taking on loads of risk to carry out your commands efficiently is providing value.You can argue whether they are doing so competently or not, or whether they are pricing optimally or not, but they are not just ”takers” or “leeches”. reply UncleMeat 13 hours agorootparentHow are they taking on loads of risk? Risk has a particular meaning in investment and \"well, a bug can blow up my company\" isn&#x27;t part of that meaning.Simply creating risky (in the colloquial meaning) things is not itself a reason to deserve money. reply pxmpxm 8 hours agorootparent> How are they taking on loads of risk?This entire story is about a trading firm that lost 400m trying to provide market liquidity. Which part of the loads of risk isn&#x27;t clear in this context? reply siftrics 12 hours agorootparentprevWhen you make markets you are literally paid the spread to assume the risk of holding the position. reply piyh 7 hours agorootparentCan you break this down a bit more? I&#x27;ve heard about making markets in relation to FTX but didn&#x27;t really get the full picture. reply envsubst 12 hours agorootparentprev> Risk has a particular meaning in investmentRisk in finance definitely takes on more meaning than the narrow definition in modern portfolio theory (stddev of price). reply erik_seaberg 13 hours agorootparentprevIf a seller and a buyer are in market within seconds of each other, they would have traded successfully without a third party taking some of their money. As I understand it, HFTs are trying to avoid taking meaningful long-term positions (which is why latency matters to only them). reply Guvante 13 hours agorootparentprevWhat risk are they taking exactly? Bugs ruining the business isn&#x27;t meaningful risk for the customer. It isn&#x27;t like day traders are at risk of going bankrupt due to that after all.They claim liquidity is their value but given how they act they don&#x27;t seem to be providing measurable liquidity, either in terms of price or volume. (Yes they increase volume by getting in the middle of trades but that isn&#x27;t useful volume...) reply hackerlight 12 hours agorootparentMarket risk isn&#x27;t the only type of risk. Many businesses in other industries don&#x27;t have market risk, that isn&#x27;t abnormal. Even businesses that you would expect to be exposed to market risk aren&#x27;t, since they hedge most or all of it.There&#x27;s operational risk, like what brought down Knight Capital, that&#x27;s a type of risk. Or the risk that you will be put out of business by competition because you were too slow to innovate while burning through all your cash runway. HFT firms face the same risks that other types of businesses face. Smaller HFT firms fail often, and larger firms tend to stay around (although sometimes they also fail and often they shrink), which is similar to many mature competitive industries.> given how they act they don&#x27;t seem to be providing measurable liquidityI&#x27;m not sure \"How they act\" should inform one&#x27;s perspective on the empirical question of whether or not they are adding to liquidity. There is a lot of serious debate and research that has gone into that question. reply jraph 13 hours agorootparentprevWhat value do they provide? reply callalex 13 hours agorootparentThey claim to provide liquidity, even though they are just front-running trades that are already happening anyway. reply dasil003 13 hours agorootparentprevDepends on whether they truly take on the risk. Interestingly I can’t clearly tell from a quick google who exactly ended up holding the bag here, and what became of upper management. reply alpark3 12 hours agoparentprevMost people confuse market making&#x2F;risk holding with high frequency statistical arbitrage strategies. I&#x27;m not totally sure exactly what Knight Capital was running, but generally the only \"little\" mistakes that would cause HFT market takers such as Jump(for the most part) would blow up is some type of egregious technical error like this, or some type of assumption violations outside of market conditions(legal, structural, etc.). Compare this to market makers like Jane Street who hold market risk in exchange for EV, and thus could lose money just based off of market swings (not to blowup levels if they know what they&#x27;re doing), and you can see the difference between the styles.I&#x27;m a proponent of both. But generally I hold more respect for actual market makers who hold positions and can warehouse risk. reply qeternity 10 hours agoparentprev> Selling options is also like that.There are plenty of bad options traders, particularly retail...but this is an oversimplification. You can buy an index fund, and it can go to zero (however unlikely). You&#x27;re not guaranteed any return, whereas at least selling an option has some guaranteed fixed premium.Professional options traders are incredibly sophisticated, and most of the tail risk is offloaded to people who are always long biased. Options as a whole massively improve price discovery in markets. reply 40yearoldman 13 hours agoprevlol. No. Deployments were not the issue. At any given time an automated deployment system could have had a mistake introduced that resulted in bad code being sent to the system. It does not matter if it was old or new code. Any code could have had this bug.What the issue was, and it’s one that I see often. Firstly no vision into the system. Not even a dash board showing the softwares running version. How often i see people ship software without a banner posting its version and or an endpoint that simply reports the version.Secondly no god damn kill switch. You are working with money!! Shutting down has to be an option. reply 40yearoldman 13 hours agoparentOh god. I just realized this is a PM. A plight on software engineering. People who play technical, and “take the requirements from the customer to the engineer”. What’s worse is when they play engineer too. reply INTPenis 13 hours agoparentprevI mean it makes no sense, without even reading the article, just by working in IT I can tell you that if you&#x27;re one deployment away from being bankrupt then you&#x27;re either doing it wrong, or in the wrong business. reply rvz 12 hours agoprevBut ChatGPT would have fixed the issue faster in 45 mins than a human would. &#x2F;sA high risk situation like this would make the idea of using LLMs for this as not an option; before someone puts out a &#x27;use-case&#x27; for a LLM to fix this issue.I&#x27;m sorry to preempt the thought of this in advance, but it would not. reply uxp8u61q 12 hours agoparentWho are you replying to? Nobody but you talked about chatbots in this thread. Are you talking to yourself? reply bsagdiyev 12 hours agorootparentNo they&#x27;re preempting someone coming along and claiming this. Haven&#x27;t seen it in the replies yet but there&#x27;s typically one (or a lot in some cases) person(s) claiming ChatGPT will bring Jesus back from the dead sort of thing. reply cwkoss 10 hours agoparentprevThat&#x27;s an odd nonsequitor strawman you constructed to knock down. Did someone suggest LLMs as the solution or are you just asserting superiority over an imaginary guy? reply rvz 8 hours agorootparentAs expected it seems many here, even you couldn&#x27;t figure out what the &#x27;&#x2F;s&#x27; means even as I preempted it in advance before anyone comes and tries to claim it anyway.So even putting the &#x27;&#x2F;s&#x27; to denote sarcastic intent doesn&#x27;t work on HN. Can&#x27;t even take a joke here. reply realreality 13 hours agoprev [–] The moral of the story is: don’t engage in dubious practices like high speed trading. reply eddtests 13 hours agoparentAnd remove easy&#x2F;quick liquidity for the rest of the market?Edit: downvotes, any reason why? Or just HFT == Bad? reply realreality 11 hours agorootparent“The market” shouldn’t even exist. reply eddtests 4 hours agorootparentWhat should replace it? reply TheAlchemist 9 hours agorootparentprevAnd how would you invest in companies ? reply dexwiz 13 hours agoparentprevThey were market makers, which is different. They help so when you push sell on E*trade you actually get a price somewhat close to your order in relatively short time. No need to call up a broker who will route the order so a guy shouting on the floor. reply pxmpxm 8 hours agoparentprevTell me you learned about finance from youtube without telling me .. reply tacker2000 13 hours agoparentprevHow is high speed trading any more dubious than long term holding, or shorting, etc? reply realreality 11 hours agorootparentIt’s all dubious. reply alphanullmeric 13 hours agoparentprev [–] good to know that you don’t consent to what other people do with their money. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The piece recounts the fall of Knight Capital Group, a financial services firm that went under in less than an hour due to unsuccessful deployment of their automated trading system.",
      "It highlights the imperative nature of fully automated and repeatable deployments in the DevOps realm.",
      "The importance of correct configuration management and testing in software deployment is also stressed."
    ],
    "commentSummary": [
      "The conversation is focused on the 2014 Knightmare incident where a DevOps failure caused significant financial losses for Knight Capital due to non-backwards-compatible code writing and lack of a kill switch.",
      "Participants underscore the necessity of automated systems, kill switches, and risk management to prevent such issues, indicating the importance of cross-collaboration between software and finance sectors.",
      "The dialogue also addresses the risks associated with high-frequency trading, the aftermath of deployment errors, and the importance of correct frameworks, automation, and accountability within the finance industry."
    ],
    "points": 397,
    "commentCount": 230,
    "retryCount": 0,
    "time": 1694376432
  },
  {
    "id": 37455534,
    "title": "Earth had hottest 3-months on record; unprecedented sea temps & extreme weather",
    "originLink": "https://public.wmo.int/en/media/press-release/earth-had-hottest-three-month-period-record-unprecedented-sea-surface",
    "originBody": "Skip to main content WORLD METEOROLOGICAL ORGANIZATION Weather · Climate · Water English Our mandate Programmes Projects Resources Media Events About us Community Platform Reform Search form Search Home Media Press Releases Earth had hottest three-month period on record, with unprecedented sea surface temperatures and much extreme weather Main News Press Release News from Members Multimedia Contact us fa5aecb7-de24-4861-a780-e3c9986329a8.png Earth had hottest three-month period on record, with unprecedented sea surface temperatures and much extreme weather Tags: Climate change 6 Published 6 September 2023 Bonn and Geneva, 6 September 2023 (ECMWF and WMO) - Earth just had its hottest three months on record, according to the European Union-funded Copernicus Climate Change Service (C3S) implemented by ECMWF. Global sea surface temperatures are at unprecedented highs for the third consecutive month and Antarctic sea ice extent remains at a record low for the time of year. It was the hottest August on record – by a large margin – and the second hottest ever month after July 2023, according to the Copernicus Climate Change Service ERA 5 dataset. August as a whole is estimated to have been around 1.5°C warmer than the preindustrial average for 1850-1900, according to the C3S monthly climate bulletin. The year so far (January to August) is the second warmest on record behind 2016, when there was a powerful warming El Niño event. August as a whole saw the highest global monthly average sea surface temperatures on record across all months, at 20.98°C. Temperatures exceeded the previous record (March 2016) every single day in August. Antarctic sea ice extent remained at a record low level for the time of year, with a monthly value 12% below average, by far the largest negative anomaly for August since satellite observations began in the late 1970s. Arctic sea ice extent was 10% below average, but well above the record minimum of August 2012. WMO consolidates data from C3S and five other international datasets for its climate monitoring activities and its State of the Climate reports. A report in May from WMO and the UK's Met Office predicted that there is a 98% likelihood that at least one of the next five years will be the warmest on record and a 66% chance of temporarily exceeding 1.5°C above the 1850-1900 average for at least one of the five years. This does not mean that we will permanently exceed the 1.5°C level specified in the Paris Agreement which refers to long-term warming over many years. Commentary “Our planet has just endured a season of simmering -- the hottest summer on record. Climate breakdown has begun. Scientists have long warned what our fossil fuel addiction will unleash. Surging temperatures demand a surge in action. Leaders must turn up the heat now for climate solutions. We can still avoid the worst of climate chaos – and we don’t have a moment to lose, “ said UN Secretary-General António Guterres. “The northern hemisphere just had a summer of extremes – with repeated heatwaves fuelling devastating wildfires, harming health, disrupting daily lives and wreaking a lasting toll on the environment. In the southern hemisphere Antarctic sea ice extent was literally off the charts, and the global sea surface temperature was once again at a new record. It is worth noting that this is happening BEFORE we see the full warming impact of the El Niño event, which typically plays out in the second year after it develops” says World Meteorological Organization Secretary-General Prof. Petteri Taalas. “Eight months into 2023, so far we are experiencing the second warmest year to date, only fractionally cooler than 2016, and August was estimated to be around 1.5°C warmer than pre-industrial levels. What we are observing, not only new extremes but the persistence of these record-breaking conditions, and the impacts these have on both people and planet, are a clear consequence of the warming of the climate system,” comments Carlo Buontempo, Director of the Copernicus Climate Change Service, ECMWF. Notes for Editors The World Meteorological Organization is the UN system's authoritative voice on weather climate and water. C3S, implemented by the European Centre for Medium-Range Weather Forecasts (ECMWF) on behalf of the European Commission, routinely monitors climate and has also been closely following recent development of global air and sea surface temperatures. The monthly report and associated assets is here. More information on the sea surface temperatures in August 2023 can be found here. More information about climate variables in August and climate updates of previous months as well as high-resolution graphics and the video can be downloaded here. Answers to frequently asked questions regarding temperature monitoring can be found here. Share this page Latest WMO News American Meteorological Society honors Celeste Saulo 8 September 2023 WMO Bulletin: heatwaves worsen air quality and pollution 6 September 2023 Scientists assess the impacts of a warming ocean 5 September 2023 Early Warnings For All Action Plan for Africa is launched 4 September 2023 Africa suffers disproportionately from climate change 4 September 2023 What is trending Climate change Climate Disaster risk reduction Weather WMO Environment Elsewhere on the WMO website IMO-WMO 150th Anniversary Global GHG Monitoring Infrastructure Early Warnings for All State of the Global Climate 2022 Follow WMO Discover Events News Bookstore Projects Bulletin MeteoWorld Learn Visit the Library Youth Corner WMO Governance Partnerships Contact us Procurement Privacy policy Report fraud, corruption or abuse About us Disclaimer Copyright Sitemap © 2022 World Meteorological Organization (WMO) ShareThis Copy and Paste",
    "commentLink": "https://news.ycombinator.com/item?id=37455534",
    "commentBody": "Earth had hottest 3-months on record; unprecedented sea temps & extreme weatherHacker NewspastloginEarth had hottest 3-months on record; unprecedented sea temps & extreme weather (wmo.int) 352 points by myshpa 20 hours ago| hidepastfavorite476 comments badtension 20 hours ago> It was the hottest August on record – by a large margin – and the second hottest ever month after July 2023, according to the Copernicus Climate Change Service ERA 5 dataset. August as a whole is estimated to have been around 1.5°C warmer than the preindustrial average for 1850-1900, according to the C3S monthly climate bulletin.Thinking about getting to 1.5 C averaged over the planet is surreal and we are still 30 years out from the promised \"net zero\". We have some tough times ahead of us. reply melling 19 hours agoparentYes, and there’s a lag effect so the temperature will still increase for years after that.However, to be clear, it’s unlikely we get to net zero in 27 years. We haven’t reached any of our goals so far and the goals only get more difficult reply GartzenDeHaes 19 hours agorootparentI seem to recall that the first and second IPCC reports (I haven&#x27;t read the newer ones) indicated that increases would continue for about 200 years, even if emissions went to zero. reply wcoenen 18 hours agorootparentThe earth is indeed not in thermal equilibrium due to the speed of the recent CO2 increase, so warming would continue if atmospheric CO2 concentration would be held constant.However, atmospheric CO2 concentration would not stay constant after emissions stop. It would go down slowly, mainly because it would continue to dissolve into the oceans. This effect cancels out the above point. Which is why the IPCC says that \"The global temperature will stabilise when carbon dioxide emissions reach net zero.\"[1]Unfortunately, stabilizing temperature does not mean that nothing else changes. The stable higher temperature will still mean that glaciers will continue to melt. Sea levels will continue to rise. Oceans will still acidify further.[1] https:&#x2F;&#x2F;www.ipcc.ch&#x2F;2022&#x2F;04&#x2F;04&#x2F;ipcc-ar6-wgiii-pressrelease&#x2F; reply jules-jules 14 hours agorootparentMethane tipping points are already met, especially from tropical wetlands and the polar regions. Add to that the conversion of past carbon sinks to carbon emitters, such as the boreal forests and the Amazon and we are looking at a continued rise of both emissions and temps for a long time. reply badtension 14 hours agorootparentI know about the \"flipped s-curve\" that is methane emissions (inflection point in 2007) is it really considered a tipping point though? Do you have some good papers on that? reply jules-jules 13 hours agorootparentHere&#x27;s a paper from July https:&#x2F;&#x2F;agupubs.onlinelibrary.wiley.com&#x2F;doi&#x2F;10.1029&#x2F;2023GB00...Key Points >The rapid growth in the atmospheric methane burden that began in late 2006 is very different from methane&#x27;s past observational record >Recent studies point to strongly increased emissions from wetlands, especially in the tropics >This increase is comparable in scale and speed to glacial&#x2F;interglacial terminations when the global climate system suddenly reorganizedOverall, there is a growing research output although much is still unknown. See for example:https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;d41586-023-00616-xhttps:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41558-023-01629-0#Sec1https:&#x2F;&#x2F;agupubs.onlinelibrary.wiley.com&#x2F;doi&#x2F;full&#x2F;10.1029&#x2F;201...> Rising methane could be a sign that Earth’s climate is part-way through a ‘termination-level transition’https:&#x2F;&#x2F;theconversation.com&#x2F;rising-methane-could-be-a-sign-t...>‘Exceptional’ surge in methane emissions from wetlands worries scientistshttps:&#x2F;&#x2F;www.carbonbrief.org&#x2F;exceptional-surge-in-methane-emi...Dr Peter Carter has a good run down of the rapid rise in methane emissions:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2oQNrO0fqOA reply badtension 13 hours agorootparentThank you so much, I think I might have seen the first paper, will plow through the rest later, it will take me some time! reply badtension 18 hours agorootparentprevThank you for the details, I have read similar reports about temperatures not changing that much later on.One thing to keep in mind though are aerosols, which can bump the temperature up by a 0.5-1 C (afaik) if we stop emitting them. reply jules-jules 13 hours agorootparentYes. IPCC AR6 estimates about 0.4-0.5C of warming is masked due to anthropogenic aerosol emissions. Given the conservative nature of IPCC estimates, it is probably more. reply calvinmorrison 19 hours agorootparentprevMaybe Greenland will finally get populated and maybe people will stop living in hurricane zones reply ethanbond 18 hours agorootparentYes yes the solution here is to physically move hundreds or thousands of years of capital investment, especially forms of capital investment that cannot be moved and are just abandoned&#x2F;destroyed.That way we can emit a bunch more to rebuild that already-built infrastructure in a different locale! reply eastof 16 hours agorootparentYou&#x27;re forgetting that the rebuild is only for survivors so it&#x27;s a smaller scale. reply tempaccount420 15 hours agorootparentprevTo be honest, we could use a hard reset like that every once in a while. reply glial 14 hours agorootparentMaybe the new cities could be built to be walkable. reply berniedurfee 14 hours agorootparentUnfortunately, humanity repeats itself. reply Aerbil313 13 hours agorootparentThis time it won’t because there aint any fuel left. reply badtension 12 hours agorootparentThat would be a cool story plot: starting civilization again with all the knowledge but none of the fossil fuel power. Solarpunk? reply Aerbil313 1 hour agorootparentI think you overestimate how much knowledge there will be left. reply badtension 36 minutes agorootparentOf course not all the knowledge will be left but enough to easily build basic engines using Stirling or Carnot cycles or even pressurized steam. Solar panels don&#x27;t have to be 25% efficient, 5% amorphous silicon cells would also be very useful. replyrc_mob 19 hours agorootparentprevYes. Humanity we are not in good shape. reply markwkw 18 hours agoparentprevOn the other hand, looking at lived experience the story is quite tricky.From the perspective of an individual it is very hard to detect this level of climate change. I can&#x27;t tell how much warmer any given month was compared to even 20 years ago. We&#x27;re talking about 28 vs 28.5°C average for a month. (and July and August made news because of pronounced anomalies, other months were probably even murkier stories due to natural monthly variability). This is not perceptible. And no one has an experiential reference point of Average Global Temperature of the 20th Century.How hot was May of 2003 compared to May of 2023? I could attempt a guess but have zero confidence in it. Do you remember the average temperature of your teenage years summers? \"It was hot\", \"between 25-30...\" is all I can give without looking at data.This is something we should keep in mind when advocating for climate measures, otherwise sceptics have another easy attack - \"it feels basically the same, what are you talking about\" reply yashap 18 hours agorootparentDepends where you live. I live in Vancouver, BC, and the effects here are very, very significant. It used to be that wildfire smoke in the city was super rare, but for the past ~10 years there’s been massive amounts of smoke in the city almost every summer. Weeks each summer where the air is filled with smoke, your throat itches non-stop, and it’s not healthy to be outside for extended periods. Virtually everyone agrees this is due to climate change, and it’s a pretty major negative impact on quality of living here, and pretty much everywhere along the west coast of North America.Or another example, that I don’t have personal experience with - island nations dealing with a big increase in hurricane severity and&#x2F;or frequency also have very visceral experiences of climate change. reply Gareth321 17 hours agorootparentGlobal warming is a potential factor, but decades of poor logging practises are also to blame (https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S259006171...). reply input_sh 18 hours agorootparentprevIt depends on your location I guess? I for one can definitely tell from my own experience, and I&#x27;m not even 30 yet.Proper winter starts much later and is milder than before, it was 10+ degrees Celsius for the past five or so NYE (didn&#x27;t even need a winter jacket), summer heat waves are more unbearable and last longer, we went from no serious issues with floods in the spring to a number of entire-towns-are-underwater levels of flooding...Now some of these did happen before, but as an anomaly, definitely not something that happens multiple years in a row. reply vel0city 17 hours agorootparentprevI can experience it here in North Texas. We&#x27;ve had a lot more snow events in the past few years than the over a decade preceding. It used to be an every few years kind of thing, now there&#x27;s a couple big ice storms every year. Massive difference.And it swings the other way in the summer too. Yeah, it&#x27;s Texas, its hot. Upper 90s most days in the peak summer time. Every now a bad summer with a lot of 100F days. Now every summer has streaks of well over 100F days. This summer alone has been the hardest one for me to experience here in my over thirty years in Texas. reply sn9 14 hours agorootparentThis summer has seen weeks or months where the lows haven&#x27;t dropped below the high 70s F.And that&#x27;s only for a brief window of time before sunrise. It&#x27;s still in the 90s F at midnight most nights. reply rootusrootus 16 hours agorootparentprevThis is a fair point. Out of curiosity, I went back and looked at the temperatures in my area the year I was born. Our highest temperature of the year was 96F ... on September 24! Let me tell you, if we hit 96F two weeks from now, it&#x27;ll be front page news and evidence of climate catastrophe.I think everyone has now fallen into the trap of mixing up weather with climate. We used to deride the deniers who said a cold snap meant global warming was fake, by pointing out that climate and weather are two different things. But more recently we point to every heat wave as evidence of climate change, every cold snap as well -- because &#x27;more energy means more extremes!&#x27; Which may be entirely true, but it&#x27;s hard to deny it looks like trying to have your cake and eat it too.FWIW, back in 1974, the coldest day of that year was 12F. That would also be considered quite cold today. So that year hit some temperatures in both directions that would be noteworthy today, almost 50 years later. reply amrocha 16 hours agorootparentYou can&#x27;t take the number outside of its context. We know the earth is warming, that&#x27;s not up for contention anymore. When you hit a 50 year record high temperature, the implication is that it&#x27;s only going to get hotter.It&#x27;s not \"doom and gloom because it hit 96F\"It&#x27;s \"doom and gloom because it hit 96F and it&#x27;s only gonna get hotter\" reply wolverine876 5 hours agorootparentprevWe now have the knowledge to connect weather events to climate. reply badtension 18 hours agorootparentprevYou are right, the changes are small and usually hard to see directly.But we also have to remember that warming is not uniform across the planet, where I live the Berkeley Earth site [1] shows an average 2.5 C warming since the 1850s.It is especially visible if your regular winter temperatures go below 0 C, but not much. Even 1-2 C warming may be seen as a much smaller snow coverage than before.[1] https:&#x2F;&#x2F;berkeleyearth.org reply wolverine876 5 hours agorootparentprev> From the perspective of an individual it is very hard to detect this level of climate change.That used to be a common claim, but it&#x27;s past its expiration date. Extreme weather events are happening all over. reply truculent 16 hours agorootparentprevI might be fooling myself but I think I can intuit the changes in extreme temperature events (not the averages though, as you say) reply WinLychee 18 hours agoparentprevWhat&#x27;s even better is that net zero isn&#x27;t doing anything for _already emitted carbon_, or the already accumulated heat energy. We can get to net zero and average temperature is still going to keep rising. reply pier25 18 hours agoparentprevEven if a miracle happens and we get to net zero, warming will continue for decades due to climate lag and feedbacks. reply Moldoteck 18 hours agorootparentI think there are solutions, question is when these will be implemented. I&#x27;m referring to planting more trees to cool down cities so that avg temp will decrease, routing rivers&#x2F;water through city to increase even more the cooling effect (like city of Bishkek) reply moffkalast 19 hours agoparentprevThe more you think about it the more it becomes plainly obvious how unfathomably screwed we genuinely are. reply datameta 18 hours agorootparentIf policies don&#x27;t drastically change. Just imagine norwegian electric car subsidies but happening everywhere decades straight - for solar, wind, tidal, battery, pumped water stations, sand batteries. Perhaps a Sahara -> Europe solar megaproject (I remember a good discussion on HN about that).Separately, I wonder if a geoengineering megaproject is more likely to be funded than small incremental changes due to politicians perceiving more immediate ROI, peer clout, and poll ratings. reply badtension 18 hours agorootparent> If policies don&#x27;t drastically change. Just imagine norwegian electric car subsidies but happening everywhere decades straight - for solar, wind, tidal, battery, pumped water stations, sand batteries. Perhaps a Sahara -> Europe solar megaproject (I remember a good discussion on HN about that).Do you honestly see them changing in the following years? We had Paris 8 years ago and the only thing that caused a small, one-year dip in our emissions was a deadly pandemic... reply datameta 16 hours agorootparentI do, because there is an entire generation steeped in understanding of climate change already taking up policital roles. Minds may be changing (but not fast enough) so intead the politicians changing will be what saves us. reply wahnfrieden 17 hours agorootparentprevIt wasn’t deadly pandemic that did that; it was biz owners complying with orders to let workers stay at home and not commute in and work their jobs that depend on it. Society didn’t collapse either. It’s a decision. reply badtension 17 hours agorootparentYes but deadly pandemic was the threat that did it, otherwise it would be business as usual.In other words: we can&#x27;t seem to make a change unless given a direct and immediate threat on a global scale. reply lossolo 17 hours agorootparentprevAnd how much did it cost? It didn&#x27;t collapse because we printed trillions of dollars, but now we have a huge debt and inflation, which has made poor people even poorer, especially in poorer countries where food insecurity has resurfaced. If it were a sustainable solution, we would have already implemented it. reply rootusrootus 16 hours agorootparentprev> Just imagine norwegian electric car subsidies but happening everywhereThat&#x27;s hard to imagine, because Norway exported a huge amount of pollution to the rest of the world in order to finance their current policy of green technology adoption. Not everyone has that nice ratio of oil and tiny population. reply sn9 14 hours agorootparentprevIf solar and batteries are cheaper, you won&#x27;t have to wait for political action.Though obviously subsidizing those technologies would hasten their takeover. reply Aerbil313 12 hours agorootparentprevTake a genuine look at the science. Scientists themselves are freaking out. There’s no way out of the famine and heat and just the general Collapse that will kill billions. reply cmews 19 hours agoprevMy prediction is that geo-engineering will be done when a certain death&#x2F;disturbance threshold will have been reached (too many climate refugees for example and western world can&#x27;t achieve a closed border, or too many weather disasters that hit the western world and populations are convinced it is because of global warming). However I don&#x27;t think we will reach it in the next 5-10 years, but maybe after that period.Also curious if the earth maybe has some tricks (last one I can recall was more clouds were causing more cooling than expected in the climate models) that will invalidate the current climate change models. reply biztos 16 hours agoparentI&#x27;m not ready to predict, but based on what I saw in Europe in 2015[0] and how things[1] are developing[2] lately[3], I see this as a very plausible outcome.The US and EU countries get more migrants than they can handle; resentment grows; attempts to solve the problem with bureaucracy and policing fail spectacularly; calls for outright violence grow louder; and the well-meaning citizenry agrees that Something Must Be Done!Geo-engineering is something, and it will be done.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2015_European_migrant_crisis[1]: https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;09&#x2F;10&#x2F;us&#x2F;migrant-crisis-massach...[2]: https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;immigration-us-mexico-border-cr...[3]: https:&#x2F;&#x2F;www.consilium.europa.eu&#x2F;en&#x2F;policies&#x2F;eu-migration-pol... reply ethanbond 18 hours agoparentprevWhy would you think we have tricks up our sleeves? What’s that mean “geo-engineering will be done when…”The whole problem is we aren’t capable of doing what we know needs to be done. reply cmews 18 hours agorootparentWhen we can burn fossil fuels to impact the atmosphere that cause climate change then we can also pump other gasses that will have a cooling effect. We aren’t doing much at the moment because there aren’t economic incentives to do so, but that can change if we have policy changes. reply jfengel 17 hours agorootparentWe aren&#x27;t doing it because pumping gases into the atmosphere does more than just reduce temperature. Sulfur compounds, for example, dissolve in the clouds and make them acidic.So does the CO2 itself. The oceans are getting more acidic already, killing shellfish and throwing off food webs.Throwing additional geoengineering on top of the geoengineering we&#x27;re already doing will almost certainly cause as many problems as it solves. It would be so much simpler, cheaper, and more effective to just stop digging carbon out of the ground and putting it in the sky. reply dharma1 17 hours agorootparentI read somewhere that fine water mist sprayed into the atmosphere may have the same reflective effect as sulphur from the shipping industry without the negatives.I’m fairly certain we will resort to this type of geo engineering soon - cutting down energy consumption is not a viable path, it’s just not going to happen. Quite the contrary, humanity’s energy consumption is likely to grow a lot.I agree with you about keeping carbon in the ground - but it will only happen for economic reasons in reality (ie. solar being cheaper than oil and gas) and the transition will take decades.I hope we don’t hit irreversible feedback effects in the next couple of decades!I know every generation feels special - the pinnacle of humanity, a special time - but this time around it really feels like what happens in the next 20-30 years can have make it or break it consequences for later generations (not just climate, also chemical pollution, risk of nuclear&#x2F;biological weapons use and possibly AI - though that could also solve a lot of our problems) reply ethanbond 17 hours agorootparentNo one knows what fine water mist sprayed into the atmosphere would do. Good god let&#x27;s not bank on these ridiculous massive-scale hail Marys that may just as well cause more damage than good. reply dharma1 17 hours agorootparentI agree with you - but I have a feeling it will be done anyway by one state actor or another reply warning26 15 hours agorootparentprevThis was basically the plot of that movie Snowpiercer; we accidentally geoengineer a second ice age. reply jmerz 17 hours agorootparentprevWe&#x27;re far more likely to pump a bunch of sulfates into the air than we are to stop driving pickup trucks everywhere. Humans aren&#x27;t rational, and this is the kind of irrationality that democracy in particular cannot solve. reply japhyr 17 hours agorootparentprevClimate change is an unintended effect of roughly two centuries of growth and development.It seems much easier to have unintended effects, than to get exactly the effects you want with from a global geoengineering campaign on the first try. reply reducesuffering 14 hours agorootparent> global geoengineering campaignYou&#x27;re still being quite optimistic...This plays out with a country like Bangladesh or India, under duress, ignoring everyone else and attempting to do it themselves reply thomasahle 6 hours agoparentprev> My prediction is that geo-engineering will be done when a certain death&#x2F;disturbance threshold will have been reachedPeople seem to be accepting \"the new normal\" very fast. I&#x27;m not sure geo-engineering will be popular, since the status quo bias that&#x27;s currently preventing us from reducing fossil fuels, will also stop any \"artificial weather manipulation\". reply Timon3 2 hours agorootparentBut let&#x27;s be fair - \"reducing fossil fuel consumption\" and \"artificial weather manipulation\" are on completely different levels in regards to dangers. Nothing bad will happen if we suddenly stopped all fossil fuel consumption and replaced it with renewable energy. We don&#x27;t know what kind of bad things can happen with artificial weather manipulation, because we haven&#x27;t really done that before, and you can&#x27;t really test the impacts in a closed experiment. reply pier25 18 hours agoparentprevThe 2030s is when I think things are going to start getting serious. reply netsharc 18 hours agorootparentI think 2-3 years, tbh.. it&#x27;s a doom spiral. reply LispSporks22 17 hours agoprev> red meatI&#x27;ve been vegan for decades, and I would love to see humanity move on from meat, but the idea is so incredibly offensive to people that I find it far easier to imagine the the Amazon razed and replaced with cattle feeding lots before that will happen. reply wolverine876 5 hours agoparentIt&#x27;s not incredibly offensive; those are rhetorical tactics and you are falling for them: Act crazy and the other side will give up; it&#x27;s a simple as that.They don&#x27;t care about meat; they care about defeating liberalism. They will shift their belief in a moment. reply renegade-otter 17 hours agoparentprevWe are supposed to stop eating meat while our governments cut taxes for corporations as their management buys that third infinity pool.Corporations are \"people\", my friend - while being absolved from any social responsibility. reply mort96 17 hours agorootparentYes. We can do a good thing even if other people are doing a bad thing. reply mvkel 4 hours agoparentprevThis would address less than a tenth of 1% of the problem, but sure. reply Timon3 2 hours agorootparentStudies seem to indicate that the cattle industry produces somewhere between 11% and 17% of global greenhouse emissions: https:&#x2F;&#x2F;thebreakthrough.org&#x2F;issues&#x2F;food-agriculture-environm...How do you get from that to less than 0.1%? reply thunkle 18 hours agoprevI&#x27;m discouraged that politics ever even comes into this. It makes as much sense as the left likes masks and the right doesn&#x27;t like masks. I wish everyone could admit this is an issue and move forward. reply acdha 17 hours agoparentI’d remember that this didn’t happen by accident. The fossil fuel companies knew this was coming in the 1970s and poured billions of dollars into delaying action and securing their political power. You used to be able to find Republicans opposed to pollution and Democrats who were in the pocket of fossil fuel companies - Manchin is a relic of that era – but the fossil fuel companies managed to get enough control of the Republican Party to make it difficult for anyone opposed to pollution to remain a member. By the time Bush ran against Gore the contrast was stark: someone saying urgent action was needed and an oilman saying the scientists were all wrong and we needed more cheap oil.What really sealed our fate was electing Obama. I know a Republican lobbyist who used to work on various environmental issues, which wasn’t as oxymoronic as it sounds: he used to get the coalitions of hunting and fishing groups and sometimes farmers who were in favor of things like clean water and air, and ecosystems which were healthy enough to support game. As he describes it, once Obama was elected the Republican leadership were bitterly determined not to give him any wins and told their members that those old deals were off-limits. Their successors don’t even have a tradition of collaborating like that. reply mort96 17 hours agoparentprevOf course it&#x27;s a political issue. Politics is fundamentally about a struggle for which interests should be given priority over other interests. There are lots of people with a whooooole lot of power who have a lot to lose from taking climate change seriously, how could it not become political? reply mikewarot 17 hours agoprevClearly we need to solve this problem, climate change is real, and it&#x27;s here.However, we can&#x27;t just stop using oil. It would lead to the death (by starvation) of most of humanity, mostly in the poorer parts of the world.We need a well managed transition away from fossil fuel inputs. One of the first things that should be shifted, as much as is possible, is from Industrial Farming which uses massive chemical inputs, and burns up the soil.Regenerative agriculture can eliminate the need for tilling, capture carbon into the soil, which both then improve water retention, and decrease soil temperatures. These reduce the need for irrigation, increase the ability to absorb rainfall without run-off.The addition of ruminants to the mix produces fertilizer and meat at the same time.About 20% of the carbon we&#x27;ve dumped into the atmosphere could be recaptured if widespread adoption of regenerative farming were to happen. It&#x27;s not a perfect solution, but it&#x27;s a lot cheaper than trying to use machines to do it. reply acdha 17 hours agoparent> However, we can&#x27;t just stop using oilThe single best move we could make would be progressively taxing it: tell everyone that today is the cheapest a gallon of gas will ever be, with guaranteed 20% annual price increases with the tax revenue devoted to assisting low-income households decarbonize. That would tell every business to start investing in alternatives or efficiency improvements, homeowners would shift towards things like heat pumps to save money, and you wouldn’t have as many auto buyers locking in 15-20 years of pollution buying a heavy industrial truck so they can cosplay as a rancher on the way into cubicle land. Toss in credits for carbon sinks and you’d have a good way to support the kind of farming you mention without constantly being underpriced by farmers relying on subsidized cheap oil.Around the turn of the century, that was a Republican idea but since the fossil fuel industry successfully managed an ideological purge that’s now too politically incorrect to even mention in those circles. reply mikewarot 12 hours agorootparentGasoline use is just a small fraction of the demand for oil, most of it has other uses, and those aren&#x27;t as flexible on demand as fuel for cars. I&#x27;d be willing to bet that they&#x27;d start flaring it off if demand collapsed, just to keep the refineries going.Fertilizer is a major sink of petrochemicals, and there really aren&#x27;t any substitutes available on a large enough scale. reply acdha 12 hours agorootparentYes, I’m aware - you’ll note I also mentioned home heating, which is usually oil or gas. That doesn’t in any way change the fact that raising the price would both give people the right economic incentives to use less and provide funds to assist with capital outlays that might require.That would among other things be great for letting us conserve usage for things which are hard to make from other sources. That’s a much better use of a limited resource than someone insecure driving a multi-ton vehicle to pick up a hamburger because it’s been subsidized to seem cheaper. reply jeffbee 14 hours agoparentprevSuburban middle class guy switching from driving an F150 to the Safeway to using an e-bike to get his groceries will not cause anyone to starve, but it will make a measurable dent in CO2 emissions. Do not frame this as an irreconcilable tension between starvation and plenty. The question is whether the average American consumer-bot can be coerced into not squandering the atmosphere at a rate 100x faster than the average human. reply seanmcdirmid 14 hours agorootparentThe guy is living in the suburbs, which means they aren’t going to the store very often as they probably live far away from it. That means they are getting more than a few bags of groceries, they don’t need an F150 for sure, but they probably aren’t getting to carry this with an e-bike.Better for the suburban guy to become a city guy and walk or bike to the grocery store a few times a week. They get better veggies that way as well. reply jeffbee 14 hours agorootparentEither way. I don&#x27;t give a flip how it happens, but that guy&#x27;s F150 needs to get crushed. reply seanmcdirmid 14 hours agorootparentIf they are a contractor that works in construction or some other similar field, the F150 can make sense. But otherwise I agree. reply cmxch 14 hours agorootparentprevNot as long as there are policymakers who aren’t making an equal or greater sacrifice.You want to have an impact on the suburban middle class guy&#x2F;consumer, start with less jet set Davos&#x2F;Aspen environmentalists.Coercion or deception by any means will only make them (and others) dig in deeper. reply sumek83 13 hours agoprevAnd tech carries out churning out artificial intelligence systems that consumes way more energy than genuine human intelligence while being worse off at the same tasks most of the time reply bufferoverflow 7 hours agoparentI&#x27;d like to see that energy calculation. AI could write a whole book in hours or a beautiful image in seconds consuming a few hundred watts of the TPU.It would take a human weeks&#x2F;months to write a book and days&#x2F;week to paint a beautiful images. Also consuming at least ~100 watts idle. reply gremlinsinc 5 hours agorootparentalso ai agent scientists in a simulated lab could solve big problems like climate change. AI might be the only thing that can save us, if it don&#x27;t kill us. reply markus_zhang 19 hours agoprevHow is the metric measured? I read https:&#x2F;&#x2F;climate.copernicus.eu&#x2F;summer-2023-hottest-record but didn&#x27;t get a good idea. Maybe I missed something.Reason I ask is because strangely we got a very cool summer for the previous 3 months in Eastern Canada. But that&#x27;s part of earth so I&#x27;m asking about the method, how the weight is distributed, etc. reply Projectiboga 18 hours agoparentOur region still has cooling from Greenland glacial melting. The catches are that the reflectiveness is going down and worse ice takes lots of heat to melt but way way less for that melted water to heat further. The previous climate shifts including 5 major extinction event major climate shifts happened over maybe a dozen years. El Nino is just starting now in September the records of the last three months were just when the cool phase La Nina was over before the coming few super heated years. And the civilization collapse tipping point from massive Arctic methane release may happen in the next few years. This climate scientist has been warning of mass human extinction by about the year 2026 for awhile now! https:&#x2F;&#x2F;arctic-news.blogspot.com reply zetsurin 18 hours agoparentprevI&#x27;m in eastern Canada, with the exception of August, it was unseasonably hot in Ontario and Nova Scotia. reply markus_zhang 13 hours agorootparentInteresting, guess it&#x27;s just a southern Quebec thing then. August is particularly...cold. reply gmuslera 19 hours agoprevSeasons, global climate related cycles like El Niño, unpredictable weather and so on push temperatures up and down, eventually it will get colder next winter.But the complex system that is the planet have a lot of tipping points, that once reached things will go increasingly worse with no turning back.I&#x27;m not sure if we didn&#x27;t reach that stage already, or if this kind of events will give us the extra push to cross the border. That is why is dangerous to keep emitting even if they are not predicted to reach some milestone for some years still, the system becomes fragile and ready to break down with small changes. reply highwaylights 19 hours agoparentThis is the part of the problem it’s almost impossible to get people to accept and understand.The wilful ignorance, even among some of my own relatives, is legitimately terrifying. I tried to explain the concept of a tipping point and got chastised for buying into fake news.For a while I thought maybe a lot of people just think it’s exaggerated or something. Nope. They fully think the entire concept is a work of fiction, despite the overwhelming (and increasing) mountain of evidence.It’s legitimately crazy out there.Climate tipping points are poorly understood and are cumulative. We really don’t know if melting the glaciers is going to be enough by itself to raise the temperature enough to trigger the next domino to fall without further emissions which are also still increasing.It’s not been over-dramatised. If anything, I believe the consensus view is too reserved in how it views the limits of impacts at 1.5 degrees. reply irrational 19 hours agorootparentYes, I have relatives that are medical doctors, physic professors, have doctorates in statistics, are engineers (real engineers and not software engineers), etc. and yet, because of the lies of conservative politics, are convinced that at best there is climate change, but it is from natural fluctuations and not human caused, and at worst that it is a hoax. Either way, there is nothing we can or should do. reply badtension 16 hours agorootparent> real engineers and not software engineersThank you, as a software engineer I have to say this made me laugh lol. We make a lot of money yet are usually far behind real world engineering. reply gmuslera 19 hours agorootparentprevSo, lets bet really everything that all the climate scientists are wrong so we can keep making profits. I get it. reply bandyaboot 19 hours agoprevI can’t wait for 5-10 years from now when the climate change deniers have a resurgence armed with graphs using now as the starting point. &#x2F;s reply perihelions 19 hours agoprevOne more example occurred in the four days since this post was published:- \"By 06:00 UTC on September 8, Lee&#x27;s maximum sustained winds reached 165 mph (270 km&#x2F;h), an increase of 85 mph (140 km&#x2F;h) in 24 hours, making it the third‑fastest intensifying Atlantic hurricane on record, behind only Felix and Wilma.[12]\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hurricane_Lee_(2023) reply renegade-otter 17 hours agoprevIt seems to me that the \"alarmist\" scientists have been erring on the side of caution so much that the events have been unfolding faster than even some of their most conservative predictions. reply jlnho 17 hours agoparentWell, yeah, otherwise those predictions likely wouldn&#x27;t have been labelled conservative. reply someonehere 14 hours agoprevNobody wants to talk about the elephant in the room? China and India causing the dramatic increase in CO2 levels?https:&#x2F;&#x2F;ourworldindata.org&#x2F;co2-emissions reply SpacePortKnight 11 hours agoparentOnly emissions per capita counts. Just because those countries have more population than entire continents of Africa and Europe, does not mean it&#x27;s their fault.USA emits almost 8 times more emission per capita when compared to India. Rather India is so poor, that it must increase it&#x27;s energy generation by any means possible.So an Indian on average consumes just 1&#x2F;8 of a USA citizen.https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;co-emissions-per-capita reply notacoward 10 hours agorootparentThis is, unfortunately, a case where fairness and feasibility don&#x27;t align well. Is it fair to expect Indians to rein in their emissions when those are already lower (per capita) than the US? Hell no. Asked and answered. Is it feasible? That&#x27;s a trickier question, and it won&#x27;t be possible to answer it without addressing loss aversion.\"we feel the pain from losses about twice as much as we feel the joy of equivalent gains\" https:&#x2F;&#x2F;insidebe.com&#x2F;articles&#x2F;loss-aversion&#x2F; (link to original \"prospect theory\" paper - the most cited in economics by some measures - where that text appears)Loss aversion is usually discussed as part of behavioral economics, but it appears all over the place. For example, many casual games have a \"start paying real money or you&#x27;ll start losing\" dark pattern that&#x27;s based on loss aversion.With respect to the current question, it&#x27;s clearly very hard to make people give up a high-emissions lifestyle once they&#x27;ve experienced it. Getting people to maintain a lower-emissions lifestyle is much easier. Again, it&#x27;s not fair. Absolutely not, and I&#x27;m not really suggesting it as The Solution. However, understanding loss aversion might help to understand why people keep bringing it up. reply FrankyHollywood 17 hours agoprevAll these comments mentioning cutting down on energy. It will help a bit, but the real problem is there are just to many people on earth.A world wide one-child policy like it used to exist in China [1] would be a real solution in keeping earth a pleasant place to live.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;One-child_policy reply SpacePortKnight 11 hours agoparentA better solution would be if most people turn vegetarian [1]https:&#x2F;&#x2F;news.berkeley.edu&#x2F;2022&#x2F;02&#x2F;01&#x2F;global-elimination-of-m... reply Sargos 17 hours agoparentprevFirst world countries already have 1 child per family with the rest of the world also moving that direction as they grow wealthier. This policy wouldn&#x27;t actually do much to help and would likely cause massive unintended consequences like China is dealing with right now. reply FrankyHollywood 16 hours agorootparentYes I know putting it into practice by law is not practical or even wanted. I just don&#x27;t believe climate changes significantly improves by having electric cars and replacing old light bulbs with led. We need more deepcutting measures.Either have less kids or power the world nuclear and all eat vegan (no methane producing animals), or accept the new climate reality and deal with the heat or whatever. Just don&#x27;t pretend we are doing a good job at the moment because we don&#x27;t. reply seanmcdirmid 17 hours agoparentprevObviously putting humanity below replacement reproduction eventually causes it to disappear, then the planet will recover from whatever we did after a few million years.But I don’t see how that will make it a better place to live for us. We know that birth rates already fall with higher standards of living, so if you want fewer kids just develop those countries where the birth rate is still high. reply rootusrootus 16 hours agoparentprevJudging by the demographic changes caused by China&#x27;s one-child policy, I think your &#x27;solution&#x27; looks a lot like a recipe for World War III. reply __pache__ 17 hours agoparentprevWhat % of this warming is due to humans? Aren&#x27;t we exiting an ice age...? reply rc_mob 19 hours agoprevApparently still not hot enough that anyone is power is doing any large changes reply SketchySeaBeast 19 hours agoparentElections are every roughly every half decade in most of the world, right? I think the leaders know that we won&#x27;t panic about our climate changing over that time span. What do we call the climate change equivalent of an Overton window? reply brucethemoose2 19 hours agorootparentI posit that the Overton Window is increasingly less relevant in highly polarized political environments.Taking climate change as an example, a large fraction of the population in some countries is growing more skeptical of aggressive climate change policy, not less. Thats not going to shift policy acceptability even if the public&#x27;s opinion shifts the opposite direction on average. reply randomdata 19 hours agorootparentprevIn most of the world we are the leaders. reply wolverine876 5 hours agoparentprevWe are in power. What are you doing? reply mgfist 19 hours agoparentprevThat&#x27;s not true, it just takes a lot of time and money. reply Spk--17 7 hours agoprevOne solution is easy, it is to reduce deforestation. These can grow faster with more CO2 and store them in their wood. But humanity&#x27;s real problem is not carbon dioxide and methane. The worst are the industrial chemicals and toxic agents that are impregnated in our bodies and brains. reply whazor 7 hours agoparentI recently learnt that chopping trees is not particularly a bad thing. The CO2 is already stored inside the tree. The most important thing is to ensure new trees will be growing. reply sktrdie 13 hours agoprevSince it&#x27;s a race with time do you guys think burning more energy irresponsibly could lead us to faster innovation in geoengineering advances that would help us fix the problem before it&#x27;s too late? reply lsh123 16 hours agoprevAnd this is a good thing! For the most of its history, Earth was much (>5F) warmer than today:http:&#x2F;&#x2F;www.climate.gov&#x2F;media&#x2F;11332https:&#x2F;&#x2F;www.climate.gov&#x2F;news-features&#x2F;climate-qa&#x2F;whats-hotte...We are still technically getting out of the last ice age.Warmer climates mean more places are warm enough to grow food. More CO2 means plants grow faster (also more food). Yea, some low lands might get flooded - either build protections or don’t buy &#x2F; build houses there. But overall for humanity warmer Earth temperatures are good thing. Much better than another ice age. reply wolverine876 5 hours agoparentSo how do you think we should avoid all the costs and realize the benefits? The costs are enormous. How do we handle massive food production loss, migrations, flooding, etc.?Our civilization was built for the climate as it has been for 10,000 years. Do we just toss out much of that capital? Who will pay for it? reply acdha 16 hours agoparentprevThis is like saying losing weight is good so you should contract cholera. The times where the climate was warmer in the past took much longer to get that way, giving ecosystems time to adapt. reply ska123 6 hours agoprevDear diary, against my better judgement, I went into a comment section on the internet today… no surprises tho…sheeple still arguing about latest nonsense they heard on the tv somewhere… had a good laugh, as usual. reply gls2ro 18 hours agoprevWhat a great coincidence: today Youtube recommended me to watch The Problem with Jon Steward: The World is ending ... So Recyle?I strongly recommend it to watch and then think about what solutions we can have. reply aov22 16 hours agoprevI&#x27;m wondering, what&#x27;s the projected circuit breaker that causes the system to collapse and people to change something if we don&#x27;t do anything before? Crop yields falling? Starvation? Extreme events? Mass migration? reply notacoward 9 hours agoparentCould be starvation. Even though we&#x27;re capable of producing more than enough food for everyone, the combination of sub-optimal eating habits, sub-optimal farming techniques, and comically inefficient&#x2F;unfair distribution means that we don&#x27;t. Between those factors and increasing population, even a small decrease in crop yields could cause unprecedented levels of famine.Could be war. War over food, war over water, war over water for growing food, war over living space as coasts get flooded or obliterated by storms, etc.Could be disease. There&#x27;s plenty of evidence that climate change is causing diseases to spread (along with their animal hosts) where they hadn&#x27;t before. If anyone thinks COVID was the last or worst pandemic we&#x27;ll have to endure this century, they&#x27;re fooling themselves. The true worst might not cause civilization to collapse entirely, but it sure will increase a lot of the tension already present.Most likely, it will be a combination of all of these. The four horsemen are all enjoying the race. reply bioinformatics 9 hours agoprevWhen are you shutting down this high brow Reddit clone to help save the planet? That would be a great start for the planet. reply echelon 20 hours agoprevWe&#x27;re technically still in an ice age [1]. How far does this need to go to reach the end of that ice age [2]?The Cretaceous period was over ten degrees warmer than our current period [3,4,5]. It supported a lot (though much different) biodiversity. How long would it take us to push into these temperature ranges? And how long to exceed them?How much species diversity will we lose at each half degree increment from this point forward? Will we see some species better equipped (increased as opposed to decreased fitness) by temperature increases? Will we see any quick evolution to support climage changes?When will temperatures be incompatible with ranges necessary to sustain society? When will they be incompatible with human life? And all terrestrial and aquatic animal life? Will runaway heating (clatrate gun [6], etc.) be capable of achieving any of these?--[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ice_age \"Earth is currently in the ice age called Quaternary glaciation.\"[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Quaternary_glaciation \"To geologists, an ice age is defined by the presence of large amounts of land-based ice.\" (So my question in terms of heating and time - how long until we exit the ice age?)[3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cretaceous \"Mean annual temperatures at the poles during the MKH exceeded 14 °C.\", \"deep ocean temperatures were as much as 15 to 20 °C (27 to 36 °F) warmer than today&#x27;s\"[4] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cretaceous_Thermal_Maximum \"Late Cenomanian sea surface temperatures (SSTs) in the equatorial Atlantic Ocean were substantially warmer than today (~27-29°C). Turonian equatorial SSTs are conservatively estimated based on δ18O and high pCO2 estimates to have been ~32°C, but may have been as high as 36°C.\"[5] https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;ngeo1081 \"During this period, we find sea-surface temperatures exceeding 32 °C at 15°–20° N and averaging 26 °C at ∼53° S. These temperatures substantially exceed modern temperatures at equivalent latitudes,\"[6] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clathrate_gun_hypothesis (truly horrifying) reply mindcandy 20 hours agoparentClimate change deniers tell each other we are coming out of The Little Ice Age that started in 1200AD. Which is technically correct.What they don’t tell each other is that “Little” is an understatement and we shot way past the prior “Medieval Warm Period” long ago and are only accelerating.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Little_Ice_Age#&#x2F;media&#x2F;File%3... reply wredue 19 hours agorootparentI just checked on them a few days ago.Their current messaging is back to:“Climate change is a hoax for science grants and political power” reply rc_mob 19 hours agorootparentMany issues over humanity it has been the case that someone lied for power.Insane that these idiots picked the one time a problem is actually really real as the time they decided to call out the tactic. reply SketchySeaBeast 12 hours agorootparent> Insane that these idiots picked the one time a problem is actually really real as the time they decided to call out the tactic.If you take every shot you&#x27;re probably going to miss a lot. reply johnchristopher 18 hours agorootparentprevLatest trend is \"warming (which is normal) is increasing co2, but the other way around\". From the same people who think co2 levels are too low to be significant and that water vapor is more problematic. reply peoplefromibiza 18 hours agorootparentprevno, scientists do too.https:&#x2F;&#x2F;www.space.com&#x2F;climate-change-termination-event-end-i... reply Etrnl_President 19 hours agorootparentprevPeople believe we are coming out of an ice age?This means they deny climate is changing.The more you know… reply piuantiderp 18 hours agorootparentIt&#x27;s not belief...This is a pretty accepted fact, the debate amongst the educated is about the speed and causes of the change (man-made vs not) reply leereeves 19 hours agorootparentprevThat chart covers a very short duration. Here&#x27;s a more complete chart of Earth&#x27;s temperature:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Geologic_temperature_record#&#x2F;m...As you can see, we are indeed coming out of one of the coldest periods ever in Earth&#x27;s history. reply kurthr 19 hours agorootparent... and based on that chart are now hotter than any time in the last 100k years, heading into the last few million. A few 10s (of million) years at +25c are going to be the \"new normal\"? I&#x27;m trying to understand the point. The rate of change is quite dramatic, and the last time (Eemian) there was anything like this there were \"rapid\" 12c oscillations.Humans didn&#x27;t exist. I suspect most current plant&#x2F;animal species are \"devolved\" by such swings. reply IAmGraydon 17 hours agorootparent>and based on that chart are now hotter than any time in the last 100k years, heading into the last few million. A few 10s (of million) years at +25c are going to be the \"new normal\"?No, the chart does not say that. The 2050 and 2100 dots are projections from the IPOC RCP8.5 “high emissions” scenario. Also, absolutely nothing on that says we’re going to +25c. That part of the chart (that goes to 25) is in F, and it still doesn’t say we’re going to 25f either.Lots of people wonder why we have so many climate deniers. A lot of the reason is because of guys like this ^ on the opposite end of the spectrum, spewing their fears into a hyperbolic, warped reality. What we need more of is a balanced, realistic, objective view. That will allow us to get to work on a solution. reply kurthr 15 hours agorootparentThank you for pointing out that the right side of the graph is labeled in F and the left label is in C. reply bsaul 18 hours agorootparentprevDon&#x27;t know about op&#x27;s point, but seeing those kinds of graphs makes you really think twice about the hypothesis that stopping any kind of human activity will have any effect on a phenomenon that&#x27;s been naturally occuring for hundreds of millions of years, on one order of magnitude greater than what we&#x27;re observing (talking about degrees variation, not taking speed into account). reply SketchySeaBeast 12 hours agorootparent> talking about degrees variation, not taking speed into accountIf you discount this of course we aren&#x27;t effecting anything unprecedented. We were once a ball of magma. But, as has been pointed out here, rate and cause of change is incredibly important. A swing set and an explosion will both launch you into the air. reply leereeves 16 hours agorootparentprev> Humans didn&#x27;t exist. I suspect most current plant&#x2F;animal species are \"devolved\" by such swings.The first apes evolved about 20 million years ago, when the world was much hotter. I suspect we can survive those conditions again.And regardless of climate change, most current plant&#x2F;animal species will go extinct (or already have) due to habitat destruction and mass exploitation. As a cause of mass extinction, that&#x27;s a much bigger problem than climate change. reply mindcandy 19 hours agorootparentprevLooks to me more like we were in a very long, very cool period and are suddenly popping out of it and are only accelerating. That’s fine for the planet. But, sucks pretty hard for any life forms that evolved to fit the Earth in the last 10 million years according to that chart. reply leereeves 16 hours agorootparentIt looks very long because of the scale of the chart. But everything on the right half of the chart would fit in a few pixels on the left side. reply IG_Semmelweiss 19 hours agorootparentprevI read what you wrote several times and I still don&#x27;t understand what your point is.Can you please elaborate? reply mindcandy 19 hours agorootparenteschelon said that we are in an ice age and multiple people asked “how can you call this an ice age?” I either didn’t see the linked reference or it wasn’t there when I read eschelon’s comment.Either way, I’ve seen the Little Ice Age come up enough lately to be extremely irritating. So, I knee-jerked the rebuttal.Now I think eschelon was actually asking if we are overriding the https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Quaternary_glaciation which would normally take millions of years to happen. reply Jtsummers 19 hours agorootparent> I either didn&#x27;t see the linked reference or it wasn&#x27;t there when I read eschelon&#x27;s comment.It wasn&#x27;t there. echelon added the references later, presumably en lieu of responding to everyone. Everything below the -- is new. reply IG_Semmelweiss 19 hours agorootparentprevThank you for the honesty reply echelon 19 hours agorootparentprevI&#x27;m not a climate change denier. I&#x27;m very interested in climate science, I&#x27;m just not informed as I&#x27;d like to be.I edited my comment to include sources for things I knew off-hand. I left the core comment largely intact, just changing a few words to better flow with the sources.I want more information and reading around the questions I asked.From my understanding, it looks like we&#x27;re about to enter a period that is actually slightly more sustainable for humans on average (increases in arable land, easier to access hydrocarbons - yikes) [1].But from there, we may quickly slip into ranges that kill everything. Especially if the Clathrate gun hypothesis [2] or similar runaway mechanisms turn out correct.And obviously even if slightly warmer temperatures are better for people on average, every temperature increment results in enormous and permanent erasure of species diversity. That&#x27;s an incalculable loss that we cannot recover.---[1] https:&#x2F;&#x2F;www.nytimes.com&#x2F;interactive&#x2F;2020&#x2F;12&#x2F;16&#x2F;magazine&#x2F;russ... \"And no country may be better positioned to capitalize on climate change than Russia. Russia has the largest land mass by far of any northern nation. It is positioned farther north than all of its South Asian neighbors, which collectively are home to the largest global population fending off displacement from rising seas, drought and an overheating climate. Like Canada, Russia is rich in resources and land, with room to grow. Its crop production is expected to be boosted by warming temperatures over the coming decades even as farm yields in the United States, Europe and India are all forecast to decrease. And whether by accident or cunning strategy or, most likely, some combination of the two, the steps its leaders have steadily taken — planting flags in the Arctic and propping up domestic grain production among them — have increasingly positioned Russia to regain its superpower mantle in a warmer world.\" (There are lots of other geopolitical takes on climate change that cite similar outcomes for a host of other countries.)[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Clathrate_gun_hypothesis reply swader999 18 hours agorootparentConsidering that the tropics only contain a third of the land mass it makes sense for humanity to not fight this warming. reply IG_Semmelweiss 17 hours agorootparentIts possible to think that, but at the aame time the cost of adjustment would be trememndous.I would think food costs would skyrocket before canada and siberia are pumping out grain in massive quantity.Adjustment at that scale can also carry other risk such as disease and civil war.Or nothing at all may happenIt really does depend on the rate of change. reply swader999 8 hours agorootparentIt&#x27;s going to happen slowly enough. Right now we enjoy a few extra days growing season. replyjanosdebugs 20 hours agoparentprevEven if that is the case, the agriculture needed to feed the amount of people on the planet doesn&#x27;t seem like it will survive and be efficient if this keeps on going. It doesn&#x27;t matter if it&#x27;s human-made or not, if we don&#x27;t get it under control, a whole lot of people will die and the current amount of refugees will seem quaint in comparison.The planet will probably be fine in a few hundred thousand years, it&#x27;s just us humans that are not going to be here. reply willcipriano 20 hours agorootparent> agriculture needed to feed the amount of people doesn&#x27;t seem like it will survive and be efficient if this keeps on goingThe earth is getting greener, rapidly. The maximum human carrying capacity is probably higher than ever and populations are shrinking at the same time.https:&#x2F;&#x2F;www.nasa.gov&#x2F;feature&#x2F;goddard&#x2F;2016&#x2F;carbon-dioxide-fer... reply myshpa 19 hours agorootparent> The earth is getting greener, rapidlyhttps:&#x2F;&#x2F;skepticalscience.com&#x2F;co2-plant-food-basic.htmhttps:&#x2F;&#x2F;skepticalscience.com&#x2F;co2-plant-food-advanced.htm> The maximum human carrying capacity is probably higher than everhttps:&#x2F;&#x2F;www.mdpi.com&#x2F;2673-4060&#x2F;4&#x2F;3&#x2F;32The Human Ecology of Overshoot: Why a Major ‘Population Correction’ Is Inevitable reply willcipriano 19 hours agorootparent> Plants cannot live on CO2 aloneNot my claim. We also have plenty of fossil fuels to put into the Haber process until we transition into fusion, even if that&#x27;s in the distant future.> The Human Ecology of Overshoot: Why a Major ‘Population Correction’ Is Inevitable> Homo sapiens has evolved to reproduce exponentiallySure, humans do that until they industrialize, then they slow down. reply myshpa 19 hours agorootparent>> (OP) the agriculture needed to feed the amount of people on the planet doesn&#x27;t seem like it will survive> (you) The earth is getting greener, rapidly. The maximum human carrying capacity is probably higherThe actual myth (read beyond the title):\"CO2 is actually the \"food\" that sustains essentially all plants on the face of the earth, as well as those in the sea. And the more CO2 they \"eat\" (absorb from the air or water), the bigger and better they grow\"As I understand this exchange, you&#x27;ve challenged the claim that climate change will negatively impact agriculture by pointing out that Earth is getting greener, supported by yours> Hint: The green stuff is food, for either humans or animals humans can eat.The page I&#x27;ve linked debunks exactly this.> A specific plant’s response to excess CO2 is sensitive to a variety of factors, including but not limited to: age, genetic variations, functional types, time of year, atmospheric composition, competing plants, disease and pest opportunities, moisture content, nutrient availability, temperature, and sunlight availability. The continued increase of CO2 will represent a powerful forcing agent for a wide variety of changes critical to the success of many plants, affecting natural ecosystems and with large implications for global food production. The global increase of CO2 is thus a grand biological experiment, with countless complications that make the net effect of this increase very difficult to predict with any appreciable level of detail.> Sure, humans do that until they industrialize, then they slow down.Overshoot is not only about population, but also about consumption and pollution. reply jncfhnb 19 hours agorootparentprevThat is irrelevant to the quote you cited. reply willcipriano 19 hours agorootparentHint: The green stuff is food, for either humans or animals humans can eat. reply jncfhnb 19 hours agorootparentYes, good job. Let’s dig a little deeper though.In terms of useful agricultural output, how many acres of “greening” do you think we might need to offset the loss of one well maintained acre of arable farmland? replylayer8 19 hours agoparentprevCommenters seem to be taking these questions as rhetorical (which they may well be, I can’t really tell), but I’d actually be intellectually interested in genuine answers to them. reply jug 18 hours agoparentprevIt’s pretty useless to debate biodiversity and keeping it intact because the real killer is not the temperature increase by a degree or two but the speed. reply Projectiboga 18 hours agoparentprevHere is a climate professor&#x27;s site he and his associates are warning of imminent mass human extinction. https:&#x2F;&#x2F;arctic-news.blogspot.com&#x2F; Dig back through his posts they are horrifying. reply tigen 15 hours agorootparentAs far as I can tell this site is run by an amateur, not a \"climate professor\". reply mattnewton 18 hours agoparentprev> The Cretaceous period was over ten degrees warmer than our current period [3,4,5]. It supported a lot (though much different) biodiversity.Humans don’t evolve very fast, it’s going to be very very uncomfortable to be part of that “much different” biodiversity and kill a lot of people reply taneq 20 hours agoparentprevI think it’s an ice age while any point on earth (not counting mountains etc.) has year-round ice. We’ll be in serious trouble long before that changes. reply echelon 20 hours agorootparentAs I understand it, there was no glacial ice on earth during the Cretaceous. Water covered much more of the earth&#x27;s surface. There were lots of dinosaurs, insects, and other biodiversity that thrived during this time.Our current biodiversity evolved to fit cooler temperatures, obviously, so the quick change is a huge fitness gradient challenge that many species will not overcome. And in certain food webs, it may result in much larger scale collapse. reply Retric 19 hours agorootparent> no glacial ice on earth during the CretaceousThat’s not quite what the evidence shows. The Cretaceous shows evidence for forest near the poles and it’s missing evidence for multiple mile thick ice sheets such as those that recently covered Manhattan Island etc. However currently there’s a glacier 170 km from the equator as altitude drops the temperature, such glaciers likely existed in the Cretaceous. reply zzzeek 19 hours agorootparentprevI think humans are one of those species, as they cannot survive wet bulb over 95f nor can current populations survive across the collapse of agriculture, hence the problem reply galangalalgol 19 hours agorootparentYeah, it is a mistake to worry about the earth in regards to climate change. It will be fine. Biodiversity may in fact increase after the bottleneck. Humans though, or at least human civilization... reply echelon 19 hours agorootparentThat&#x27;s what I&#x27;d really like to read an abundance of information on. Timelines, milestones, etc.At what stages do fishing and agriculture end? When do our brains overheat? Etc.In the short term, we&#x27;re possibly going to have an even better time of sustaining human life and society (see my other comments&#x27; sources). Until things progress even further and we severely damage our civilization and possibly kill ourselves off.What are the things we can do to cope, what are the things we can do to slow or reverse the temperature trend, and what ranges do these things happen?Can we stop? How? Where should we stop? Should we return back to where we were? Or should we keep going further and then stop? At some point this becomes a biogeoengineering problem.I have so many questions. reply kQq9oHeAz6wLLS 19 hours agorootparentprevThat doesn&#x27;t take technology into account, though. Not arguing one way or the other, but humans are well advanced beyond any species, and are ingenious and inventive to boot. I don&#x27;t think humans are so easy to wipe out, not on the timeline predicted. reply zzzeek 14 hours agorootparentNot at all. Many humans are definitely surviving this no matter what. It&#x27;s just the extra 2 billion or so that won&#x27;t have access to whatever new \"technology\" is needed to survive. replysurume 20 hours agoparentprevWhat is your source for saying that we&#x27;re in an ice age? And do you mean ten degrees C or F? reply moffkalast 20 hours agoprevHomer telling Bart: 3 hottest months on record so far reply totetsu 20 hours agoparentDont let global warming get you down, civilizations die all the time, just like that, why ours could wake up dead tomorrow. reply jfengel 17 hours agorootparentI just wish we didn&#x27;t go down so stupidly. I could understand mere greed. I could even understand ordinary ignorance.Instead, we chose stupidity. The answers were right there. It wasn&#x27;t a secret and it wasn&#x27;t all that difficult. Instead people pretended it was a vast conspiracy against them, denying both basic physics and the data.We still debate why and how Rome fell, but they&#x27;ll look back at us and say, \"yeah, they were just a bunch of dumbfucks.\" reply enraged_camel 19 hours agorootparentprevPart of me feels sad, part of me feels dread, and part of me says, \"well, we&#x27;re just reaping what we have been (and still are) sowing, and we collectively deserve all that is coming.\" All the suffering sucks though. reply wolverine876 5 hours agorootparentHow about another response: Do something about it. You&#x27;re not a spectator; it&#x27;s in your hands. reply scioto 19 hours agorootparentprevThis is natural progression. The apex predator takes over and over-grazes the land, so to speak, to the point where it no longer supports the apex, so eventually the apex predator dies off, and the other species that are left can flourish. reply moffkalast 19 hours agorootparentThe trick is to brake just early enough to hit the apex of the proverbial civilizational corner and come out accelerating until we straighten ourselves out. reply nprateem 19 hours agorootparentprevOnly some are more culpable than others. The climate crisis represents the single biggest failure of humanity. How stupid do our leaders need to be to know about an extinction level event (or at least one that threatens the breakdown of civilisation) with > 50 years notice and take no substantive action? They should be charged for crimes against humanity. reply totetsu 18 hours agorootparentSome people just want power and ego and status, some people just want things to be simple and not change from what they know, and a significantly smaller number of people just want to be chill and sensible. reply enraged_camel 16 hours agorootparentprevThe blame doesn’t lie just with leaders though. It comes all the way from the bottom. Everyone wants their standard of life to improve, they want conveniences, luxuries, socioeconomic status… and they vote for policies that’ll give them those things. It’s a collective problem at a global scale. reply mistermann 18 hours agorootparentprevSome conspiracy theorists warned people about the design of your political systems but no one seemed to think it&#x27;s a legitimate concern. Time will tell I suppose. replyvixen99 17 hours agoprev\"China, the United States and India — contribute 42.6% total emissions, while the bottom 100 countries only account for only 2.9%.\". Asia is the largest emitter with China at 27%\". While selling renewables to the rest of the world, China seems reluctant to reduce its reliance on coal-fired power stations.&#x27;Global Energy Monitor and the Centre for Research on Energy and Clean Air finds the country quadrupled the amount of new coal power approvals in 2022 compared to 2021.&#x27;Chinese scientists are hardly backward in understanding climate science. So what&#x27;s the logic here? Presumably if they could maintain energy supplies without coal, they would.https:&#x2F;&#x2F;ourworldindata.org&#x2F;annual-co2-emissions https:&#x2F;&#x2F;energyandcleanair.org&#x2F;publication&#x2F;china-permits-two-... reply tock 17 hours agoparentChina, the United States and India also make up 40% of the world population. reply wolverine876 5 hours agorootparentDo you believe that the US, at least, doesn&#x27;t emit more per capita than most less-developed countries? reply tock 4 hours agorootparentDeveloped countries definitely emit more per capita than less developed countries. reply ryan93 18 hours agoprevFor a fraction of the US federal debt we could have gone full nuclear. reply wolverine876 5 hours agoparentWe have a very hard time building nuclear power stations. This claim, which seems to absolve energy consumption, is easy to say but very hard to do in practice. reply thatwasunusual 20 hours agoprevI&#x27;m getting 503, so: https:&#x2F;&#x2F;archive.ph&#x2F;FdOZJ reply more_corn 18 hours agoprevHottest so far. reply jfengel 17 hours agoparentCoolest for the rest of your life.(Alas, that&#x27;s not true. Next summer will likely be cooler, and the usual suspects will claim that proves climate change is a hoax.) reply 29athrowaway 17 hours agoprevIt&#x27;s the arctic methane that is now melting.We need a constellation of methane tracking satellites. reply gonzo41 18 hours agoprevJust for fun everyone. This year there were like 2000 private jet flights to get rich people to burning man.Apologize to your children. They will be rightly angry. reply refurb 19 hours agoprevThe chart is from 1991 to 2023 by the looks of the article? reply pc86 19 hours agoparentThere are three charts in the article. Two are 1979-2023 and the other appears to just be the top 30 hottest months from the same time period. reply swader999 18 hours agorootparentThis is a ridiculously short period for these sorts of claims. reply pc86 18 hours agorootparentI mean they are pretty solidly up and to the right. Are there charts with data from the 60s&#x2F;50s&#x2F;40s that drastically change the trend? reply swader999 18 hours agorootparent30s were significantly hotter. replyNotYourLawyer 20 hours agoprev>If the C3S dataset only currently starts in 1979, how can you then provide temperatures relating to the pre-industrial era?>In order to relate global mean temperature derived from the C3S dataset (ERA5) to the pre-industrial era, we use the estimate that the 1981-2010 reference period is approximately 0.69°C and that the 1991-2020 reference period is approximately 0.88°C warmer than the period 1850-1900, the time period typically referred to as the pre-industrial level for temperatures by the Intergovernmental Panel on Climate Change (IPCC).>Note that these estimates were updated during Autumn 2021, due to new findings published in AR6 WGI report “Climate Change 2021: The Physical Science Basis”. See more here under “Reference periods and anomalies”.I’m sure this is all fine and valid, but they really need to work on their messaging. To a skeptic, this is gonna sound a lot like “oh yeah we pretty much just made the numbers up.” reply hn_throwaway_99 20 hours agoparentHonestly, at this point I&#x27;m beyond caring much what stuff sounds like \"to a skeptic\". The past 15 or so years have proven to me that \"skeptics\" can believe whatever TF they want, all logic and and reason be damned, as long as there is a snazzy YouTube video pointing out how it&#x27;s all a CoNSp1RacY by the Secret Global Elite.I&#x27;m done with trying to convince people who have made it extremely adamant that they aren&#x27;t willing to be convinced. reply NotYourLawyer 19 hours agorootparentSure, there are some people who are not persuadable no matter what. But there are other people who are not crazy but who see stuff like this and have legitimate doubts. reply moritz 18 hours agorootparentSure, we only built gigantonormous infrastructures to measure about everything on every cm of this planet, 10s of thousands of highly qualified experts from all over the world work on this full time and have been saying the same thing for decades, but “there are people” who have “““legitimate doubts”””. Sure. reply NotYourLawyer 18 hours agorootparentI’m talking specifically about the data from before that infrastructure existed. reply afpx 19 hours agorootparentprevI’d like to know more about the legitimate doubts. I haven’t heard a solid argument yet. Of the arguments I’ve heard though, the speaker had had low scientific literacy and misunderstandings of the scientific process and the data. They were perturbed by media, mainly. So, I’d like to hear someone serious address the issue. reply pc86 18 hours agorootparentYou don&#x27;t need a solid argument to have doubts, you need to hear a solid argument (or more accurately, several of them over some period of time) not to have doubts, and even then you should be checking and doubting your own assumptions.Not everyone is a scientist or an engineer. You don&#x27;t have to be an idiot to read the above statements and have your main takeaway be \"they don&#x27;t know for sure so they guessed\" and it&#x27;s completely reasonable to still have doubts based on that. reply afpx 18 hours agorootparentSo, you’re saying the models that have been used and refined over decades have been wildly inaccurate? It’d be interesting to me to see that analysis. Maybe it’ll change my mind. reply pc86 18 hours agorootparentI didn&#x27;t say that at all, clearly you&#x27;re the one operating in bad faith now. reply afpx 17 hours agorootparentThis is the stuff I&#x27;m talking about. I make a deduction, and you respond with a defensive statement and change the subject. I&#x27;m just looking for evidence of what you&#x27;re implicitly claiming. Are the models accurate or not?Anyway, probably just the inherent difficulty of trying to have a conversation online. replyeuroderf 14 hours agorootparentprevThis is a cop-out. reply flooow 20 hours agoparentprevObviously clearer is better, but do you think a scientific body should be expected to go out of its way to convey information in a way that would be difficult for bad-faith actors to willfully misinterpret? Because I don&#x27;t. reply pc86 18 hours agorootparent\"Bad faith actor\" is different from someone who is simply unfamiliar with the material, uneducated, or skeptical for good faith reasons.Bad faith actors will act in bad faith, we all know that. But yes, you should go out of your way as a scientific body to explain your conclusions to good faith skeptics and people who want to understand your material. And I think that bar goes higher the more bad faith actors you have in your field. reply driverdan 17 hours agoparentprev> To a skepticYou mean denier. We&#x27;re way past skepticism, the overwhelming evidence shows climate change is real. reply euroderf 14 hours agorootparentWe are at the \"well duh cigarettes do in fact harm your health\" stage of climate debate. reply moritz 14 hours agorootparentfunny you should mention that https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Merchants_of_Doubt reply 28304283409234 19 hours agoparentprevDoing perfect is the enemy of doing good. reply ForestCritter 20 hours agoparentprevI can&#x27;t back it up because it was a televised congressional committee hearing and I don&#x27;t remember the name of the scientist but he said that his data he had been studying and working with that was published in the 1940&#x27;s was different from the data that is now published for that same time period. He made no accusations he just said his data showed no signs of global warming. So, I guess as a skeptic, yes this does make me think they are making it all up. reply polotics 19 hours agorootparentWhat are you skeptic of? There is so much misleading denialism of what is now ao blindingly obvious to any casual reasonable observer, that I propose you apply you skepticism with a bit a cui bono. reply giardini 19 hours agorootparentpolotics says \"...what is now ao(sic) blindingly obvious to any casual reasonable observer...\"Hmmm, \"any casual reasonable observer\" - that would be a scientist perhaps, and \"casual reasonable observation\" would be \"science\"? reply multiplegeorges 19 hours agorootparentprevYou don&#x27;t think techniques have improved since the 1940s?Of course the data would be different with 60-70 years of improved collection techniques, analysis tools, and theoretical knowledge about the climate. reply IG_Semmelweiss 19 hours agorootparentThis does not sound at all like good fortune will shine on current data, though? reply hn_throwaway_99 18 hours agorootparentI&#x27;d expect that our current temperature measurements are much, much more accurate than in the early 1900s, so while I&#x27;d expect them to be tweaked, not by much.But this whole debate is pretty much a smokescreen. Sure, there are definitely error bars around temperature records of the past and estimates for the future. But one thing I have never seen be in question is the sheer amount of CO2 we have put into the atmosphere: https:&#x2F;&#x2F;www.climate.gov&#x2F;news-features&#x2F;understanding-climate&#x2F;... .The atmosphere now contains 50% more CO2 than pre-industrial times. The oceans are now 30% more acidic. These are gargantuan amounts. Sure, the global climate is incredibly complex, and how the climate reacts in different places in the world (e.g. ocean currents, ice cover, sea levels, temperatures, atmospheric humidity, storm intensity, etc.) is the hard work of some very smart people in climate science. But it&#x27;s preposterous to me that we think we could raise the main global greenhouse gas by 50% and increase ocean acidity by 30% and not see some major impacts.So while I think it&#x27;s important to \"worry about the details\", only if done in good faith. Nitpicking around whether temperatures have rising 1.1 vs. 1.2 degrees, and using that as \"evidence\" that global warming isn&#x27;t a problem or isn&#x27;t worth doing something about, is what is so ridiculous in the face of avalanches of other data that we are seriously affecting the global climate. reply consp 19 hours agorootparentprevOnly if you assume the same mistakes are being made for the current data and the lessons from the past are not used. reply hotpotamus 19 hours agorootparentprevAs someone who has lived in South Texas my whole life and seen summers go from uncomfortably hot when I was a child to now dangerous to life, I have to say that my data leads me to believe that we&#x27;re doomed. I do wish I could believe what you believe though; much like I wish there was a god in heaven who loves and protects me - it seems to really help people get through the day, but I seem to be incapable of believing it myself. reply jokoon 19 hours agoprevIt&#x27;s odd how everytime somebody mentions slashing oil production by 50 or 75%, people are immediately up in arms. Same for red meat or cheap air travel.Western rich countries have too many really spoiled consumers.It&#x27;s weird to say, but we should crash the economy if it can slow down climate change. I mean there are plenty people in other parts of the world who don&#x27;t have such a high standard of living, and it&#x27;s not that big of a problem.And yes, I don&#x27;t believe it&#x27;s only rich people, it&#x27;s also middle class people who generate a lot of emissions, and I&#x27;m a leftist. reply pentae 17 hours agoparentI&#x27;m going to guess you&#x27;ve never spent much time outside the bubble of the first world.After living extensively overseas in Latin America & South-east Asia and seeing how its part of everyday life for most people in the rest of the world to openly burn trash, plastics, car tyres.. litter everywhere, cutting the cat converters off their trucks, dumping construction waste straight into rivers.. it&#x27;s been eye opening. Nobody in Asia is dropping plastic bags or single use plastic straws unless its a cafe for hippy white tourists.Meanwhile, educated people in western countries are incredibly eco-conscious, have excellent modern waste management, have amazing huge national parks and conservation areas, clean waterways or have nets to prevent plastics entering the oceans.. are &#x27;banning&#x27; gasoline cars by 2030.. and the air quality! Amazing.The truth is 85% of the worlds population just doesn&#x27;t care enough at all about the environment and no amount of western policy making will fix the problem. And only an ignorant college educated person from the first would assume that their &#x27;solutions&#x27; will be exported globally. sorry to break it to you but the rest of the world doesn’t have any interest in that.The middle&#x2F;upper class whites you seem to deride so much are actually participating in one of the most eco friendly societies on earth reply 21echoes 17 hours agorootparentYou can wax poetic all you want about anecdotal values differences between the first and third worlds, but speaking in terms of actual practical impact: what you are saying is simply not true. Greenhouse gas emissions scale super-linearly with income: https:&#x2F;&#x2F;www.iea.org&#x2F;commentaries&#x2F;the-world-s-top-1-of-emitte...There are dozens and dozens of studies all reaching this same conclusion, if the International Energy Agency isn&#x27;t good enough for you: https:&#x2F;&#x2F;www.google.com&#x2F;search?q=greenhouse+gas+emissions+by+...OP&#x27;s point was that the global rich (most US citizens included) have lifestyles and patterns of consumption which produce an outsized amount of greenhouse gasses, and any attempts to alter those behaviors are routinely met with anger and political backlash reply pentae 17 hours agorootparentYeah and my point is that these studies look at energy consumption they don’t take into account things like burning yard waste or plastic garbage into their co2 consumption which is often done daily to keep mosquitoes away and from laziness. Nor does it look at air pollution nor waterways pollution. So it’s a useless metric that doesn’t even have accurate data or tell the real story.What will we do when these societies who give no fucks about the environment (compared to the west) get wealthier?White guilt is not going to save anyone reply refulgentis 16 hours agorootparentI don&#x27;t think proposing cutting CO2 emissions is \"white guilt\" -- I probably missed something, I&#x27;m not sure how race entered it. (and I don&#x27;t mean that snarky! I probably missed it :) )I&#x27;m also unsure if \"White guilt\" is a good descriptor for the West enforcing emission cuts by force on not-West: that sounds like aggression as opposed to an expression of guilt.The fun&#x2F;exciting part: a total mind-bender on this is not-West countries are installing renewables at scale without incentives or \"[any color] guilt\", solar is cheaper than any other supply you can think of.Then we can start talking about \"solar isn&#x27;t enough because unreliable\", true.Then maybe we start talking about how it&#x27;s racist to prevent people from having unreliable electricity, true, but rest-assured, the idea of enforcing cuts on other nations isn&#x27;t on the table.To avoid the tarpit of moralizing, I try to stay focused on saying \"they&#x27;re installing solar panels and it&#x27;s cool if they gotta do coal&#x2F;tires&#x2F;etc. while we 10x batteries again like we did last decade\" --- this also has the benefit of matching the uncoordinated reality as it stands reply concordDance 16 hours agorootparentprevYour link has the Chinese top decile with higher emissions than the EU top decile, so your \"what you are saying is simply not true\" seems incorrect, their central point of value differences and higher pollution in third world countries seems to stand up well. reply onetimeusename 16 hours agorootparentprevThis doesn&#x27;t take into account that countries like the US have already cut emissions and emissions have been declining for years. Meanwhile, China has much greater total emissions than the US does and emissions in China are increasing per year continuously as they are in India. Total global emissions are what matters for the climate. Although reducing waste and being more efficient are always helpful, fixating on lifestyles of people like US citizens is not particularly useful. reply refulgentis 16 hours agorootparentSource? (AFAIK it does, and it&#x27;d be very unexpected for it not to. The rest of the comment is unclear to me. I may be reading it as a strawman instead of a steelman -- would a reply like: &#x27;just because our derivative is negative doesn&#x27;t mean on a per-capita basis we&#x27;re less&#x27; be accurate? I&#x27;m sure I missed something) reply onetimeusename 16 hours agorootparentSource for what? That emissions are declining in the US?You can find some details here https:&#x2F;&#x2F;www.epa.gov&#x2F;climate-indicators&#x2F;climate-change-indica... I am surprised you didn&#x27;t know this already.Here is China https:&#x2F;&#x2F;data.worldbank.org&#x2F;indicator&#x2F;EN.ATM.CO2E.KT?location...It doesn&#x27;t take into account trends that already exist. In the next decade small reductions to emissions in US transportation per year will be meaningless. Also reducing agricultural emissions which are only 10% of CO2 emissions in the US will have little affect on total global emissions. I&#x27;m not sure why there is so much hand waving about the CO2 emissions of China alone. reply refulgentis 16 hours agorootparent> Source for what?\"This doesn&#x27;t take into account that countries like the US have already cut emissions and emissions have been declining for years.\"> You can find some details here https:&#x2F;&#x2F;www.epa.gov&#x2F;climate-indicators&#x2F;climate-change-indica... I am surprised you didn&#x27;t know this already.This being US &#x2F; 1st world emissions are decreasing? Thank you for looking that up etc., I appreciate it -- I did know that, and seriously, thank you for taking the time to source it: I&#x27;m only saying I knew so you can rest assured at least one other person is up on data. These are strange times and it&#x27;s hard to get a read on if facts are common knowledge or not, and our estimate of that can cause intense feelings.Putting my comment more simply and extending it so it doesn&#x27;t feel like I&#x27;m passive-aggressively quoting my comment back at you:I&#x27;m curious why we think the per-capita emissions data \"isn&#x27;t accounting for it decreasing\" reply onetimeusename 16 hours agorootparentWhat I am taking issue with is the assertion from the other poster that \"Greenhouse gasses scales super-linearly with income\" which links to a page. That page looks at one year, 2021, and makes assertions that don&#x27;t account for annual trends like the decrease in emissions the US has been experiencing for years and will continue to experience. The US _IS_ reducing emissions. It also doesn&#x27;t take into account the large expected increases over just say the next decade in countries like China.Total global emissions are an important factor to consider for the global climate and focusing only on reducing emissions of the US will be meaningless because total global emissions will still continue to go up.edit: thanks for clarifying btw and here is trends in total global emissions found on the page https:&#x2F;&#x2F;www.epa.gov&#x2F;ghgemissions&#x2F;global-greenhouse-gas-emiss... replythomasahle 17 hours agorootparentprev\"But it&#x27;s you reduce the economy, think of what it will do to the poor!\" it&#x27;s incredible how ritch people will happily push the poor in front of them when it&#x27;s beneficial.The fact is \"emmisions per capita\" is heavily correlated with \"gdp per capita\": https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;co2-emissions-vs-gdpThe \"educated people in western countries [who] are incredibly eco-conscious\" emit way more co2 than \"85% of the worlds population\". reply rayiner 17 hours agorootparentWhat does “per capita” emissions have to do with the physics of climate change? reply thomasahle 16 hours agorootparentIt&#x27;s related to the comment I was replying to:> Meanwhile, educated people in western countries are incredibly eco-conscious, have excellent modern waste management, have amazing huge national parks and conservation areas, clean waterways or have nets to prevent plastics entering the oceans.. are &#x27;banning&#x27; gasoline cars by 2030.. and the air quality! Amazing.The commenter appears to say that people in western countries are already doing a good job on climate. Even though those people emit way more than people from other countries. reply hollerith 16 hours agorootparentAccording to this next page, in 2021 the \"EU27\" emitted 2774.93 megatons of co2 whereas China emitted 12466.32. Also, European emissions are falling whereas China&#x27;s is rising.https:&#x2F;&#x2F;edgar.jrc.ec.europa.eu&#x2F;report_2022#emissions_tablePer capita, EU27 is at 6.25 whereas China is at 8.73 whereas the US is at 14.24:https:&#x2F;&#x2F;edgar.jrc.ec.europa.eu&#x2F;report_2022?vis=pop#emissions... reply concordDance 16 hours agorootparentprevThe Chinese emit more per capita than the Europeans. reply seasox 16 hours agorootparentYes, if you count the emissions for the stuff manufactured in China for (not only) european customers.If you look at consumption-based emissions[0], China is at 7 t per capita, which is 8 t less than the US, 2 t less than Germany and about par with Denmark, Slovakia, and England.0: https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;consumption-co2-per-capit... reply tptacek 16 hours agorootparentThis is per capita data again, which makes the argument circular. In absolute terms, China emits more than twice as much CO2 as the next producer, and only a small fraction of that is exported. reply waffleiron 16 hours agorootparentPer capita data makes sense. CO2 emissions don’t change if we cut giants countries into many smaller ones. If China was 25 different countries you wouldn’t be pointing the finger to them.Why shouldn’t the highest emitters not be the ones to reduce most? reply tptacek 16 hours agorootparentBecause we&#x27;re not having a moral argument but rather a practical one. The fact is that China emits much more CO2 than other countries, even after you account for exports (ie, CO2 emissions \"offshored\" from Europe and North America). Moreover: while emissions in the west are falling, the are rising in China and India and the developing world, as they must, because they track rising standards of living.I don&#x27;t understand the \"25 smaller Chinas\" argument. China sets statewide emissions policies. That&#x27;s a reason we pay attention to country borders here, rather than considering an undifferentiated mass of humanity as a map scatterplot.Ultimately, the reason to point out the gap between China and Europe or North America is that if you concentrate climate mitigation strategies on the west, you won&#x27;t actually do much to solve the crisis. Fair&#x27;s got nothing to do with it. reply thomasahle 12 hours agorootparentThere&#x27;s no reason to argue about this. Everyone agrees that1) China needs to cut more emissions in total.2) The US&#x2F;West needs to cut more emissions per capita. reply tptacek 11 hours agorootparentOnly in the most abstract sense, because the real debate is over prioritization; if you suggest that equal effort be put into both of these projects, reasonable people will argue that you&#x27;re misallocating effort. reply thomasahle 10 hours agorootparentDifferent people have to do (1) and (2), so it&#x27;s not really a prioritization question.But if both groups argue that the other group has to do their part first, or they won&#x27;t act, then nothing will get done. replydanbolt 16 hours agorootparentprevI think the world would benefit if western nations had a carbon levy on imports as well as a carbon tax on domestically-produced goods. Or, with the added costs, market forces would encourage people to find more efficient lifestyles. If someone wanted a more environmentally-taxing lifestyle, they could play the fair cost. reply baq 16 hours agorootparentprevNothing.But it doesn’t matter. What matters is that nobody is prepared to willingly let go of their conveniences. They may say they are but they haven’t seen the real cost to their lifestyle.The transition is politically impossible. You’ll see some kind of populist revolution happen in Germany, which on paper seems to be the leader in green policies. reply EatingWithForks 17 hours agorootparentprevI think it&#x27;s actually more complicated, because a lot of the construction, etc. is caused by demand from the western countries. Also, western countries consume proportionately more flights, cars, electronics... pretty much all the actual major industry-sized consumption is disproportionately consumed by the west, even if a portion of individual westerners (certainly not all) are eco-conscious, no-waste, plastic-free vegans. reply rambojohnson 17 hours agorootparentprevthe point is that if it&#x27;s that vs. the oceans consuming continents, it&#x27;s probably not that big a deal BY COMPARISON. stop virtue signaling. reply freen 17 hours agorootparentprevPersonal responsibility for environmental issues is a fiction peddled by the biggest polluters.The moment you think an individual is going to make any sort of a difference through minor changes in behavior, you have already lost the plot. reply zpeti 17 hours agorootparentprevThank you. Climate change is a diplomacy issue, nothing the west is going to do in the next 50 years will make a difference with what’s going on in china and elsewhere.So either you are a realist about this problem, and you admit that either it’s war with many countries to solve this issue, or it won’t be solved (because they won’t stop economic growth for carbon emissions). Possible alternatives are technology.But guilt tripping the west and stopping people eating steak will. Not. Make. A. Difference. reply SpacePortKnight 11 hours agorootparentUSA emits almost 8 times more C02 when compared to India per capita. https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;co-emissions-per-capitaIn that sense India would need to be 10B+ people to poluate as much as US &#x2F; west does. reply pentae 7 hours agorootparentAgain these studies don&#x27;t take into account things like burning, air pollution, waterways pollution, nor trees per capita in India vs North America.If you&#x27;ve got enough trees per person to offset their carbon use, then it doesn&#x27;t matter how much co2 they emit. reply zpeti 1 hour agorootparentprevExcept per capita co2 emissions AND total emissions have been falling in the USA.China now emits more co2 than europe and USA combined. And this is NOT because of exports to the west, those are now also falling yet co2 emissions are still climbing.https:&#x2F;&#x2F;ourworldindata.org&#x2F;grapher&#x2F;annual-co2-emissions-per-...This is what I mean. Just these two countries like india and china are emitting so much CO2, that any reduction in emissions by the west by not eating steak just won&#x27;t matter. Either you stop china doing this (good luck!) or think of another solution. reply lr4444lr 18 hours agoparentprev> there are plenty people in other parts of the world who don&#x27;t have such a high standard of living, and it&#x27;s not that big of a problem.Go live like that for 6 months and get back to us: food insecurity, inadequate healthcare, and few civil services or safety net.Those other countries are not net zero pollution either. You wanna crash the economy? How then will we develop the innovations to fix this problem?Can&#x27;t believe this comment is top rated. reply moritzwarhier 18 hours agorootparentI upvoted you, but IMO:- private cars and their usage are too cheap- air travel is too cheap- producing garbage is to cheap- politics is top centered around providing infinte fuel for \"growth\" instead of distributing resources rationallyYes, this is a political opinion.The stunt many people do is pretending that climate denialism and politics centered on fueling growth are not a political opinion but \"rational\" and sustainable. reply lr4444lr 18 hours agorootparentAgreed, both on the whole and in the details. But if I&#x27;m forced into the \"either&#x2F;or\" mindset of the OP of a hypothetical choice to shrink GDP by 1% by stopping all vacation car travel or deficit spend 1% GDP as a \"Manhattan Project\" to get lab grown beef commercially viable, I&#x27;m voting for the latter. reply moritzwarhier 17 hours agorootparentThe latter sounds like fantasy though, and it&#x27;s not the lab-grown meat per se I&#x27;m talking about.Also I wasn&#x27;t talking about car usage exclusively during vacations, I was explicitly talking about private car usage.People literally get governmental subsidies for building homes in the suburbs, then commute by car and pollute the planet in order to avoid car traffic.Anyone who fails to see the absurdity of this has drank too much Kool-aid for my taste. reply concordDance 16 hours agorootparentprevIf your issue is global warming you should be campaigning for electric cars rather than against private cars. But I suspect you actually dislike cars in and of themselves, even if they could be grown on trees and powered by banana skins. reply moritzwarhier 13 hours agorootparentI like driving cars or being a passenger in them. I also acknowledge their importance for society as a whole.But since you ask:Cars are not a subject but an object, a tool to me.\"Suspecting\" that I \"dislike\" this tool does not sound like a coherent argument to me.Yes, I hate cars when being outside them, because they are a major obstruction and source of pollution, noise and overshooting environmental damage.I hate their artifical abundance, for which I am forced to pay.I&#x27;m not sure what you are talking about with the hypothetical banana car and why you care about my feelings.Seems like an ideological argument to me.Do EVs grow on trees?I agree that global warming is only the tip of the iceberg of the damage we do.And yes, EVs are marginally better for the nearby environment compared to CEVs. They don&#x27;t solve the larger problem though and they still impose huge resource costs.Subsidizing EVs (again) is putting more fuel into the fire.In my country, there are and were already so many subsidies and benefits for buying a new car, it isn&#x27;t funny anymore.It&#x27;s always being justified by the newer cars ostensively being better for the environment.Even before there were affordable EVs, the government paid people bonuses to buy a new car and trash&#x2F;sell the previous one with this justification.As a person with a license, but without a car: this is disgusting and reminds me of 1984. One of the many subsidies for buying cars in Germany was called \"Umweltprämie\" (environment bonus). As early as 2009.It was basically a tax-funded bonus for trashing and buying cars to fund the industry.That being said, cars of course are only one particularly obvious example of insane policies. reply nroets 18 hours agorootparentprevEurope doesn&#x27;t have food insecurity. Health is pretty good and there&#x27;s a safety net. Even China scores pretty well on those points. Yet their per capita emissions are much lower than the US. reply throwaway290 16 hours a",
    "originSummary": [
      "The past three months have been the hottest on record for Earth, replicating a climate change pattern that's caused extreme weather events and unprecedented sea surface temperatures.",
      "August 2023 emerged as the warmest August ever recorded, contributing to this year becoming the second warmest on record, trailing only 2016.",
      "Scientists attribute these record-breaking climatic conditions to climate change and call for urgent action to prevent dire environmental consequences."
    ],
    "commentSummary": [
      "The discussions cover the urgency and need for action against climate change, discussing potential solutions and its various implications including extreme weather events, human related global warming, and the potential consequences of climate change.",
      "Significant topics include geo-engineering, political implications, effects on agriculture and food production, and the responsibility of different nations in managing climate change.",
      "There are debates around denial of climate change, emissions reduction efforts, with an overall sense of concerned urgency about the future impacts of climate change, suggesting diverse opinions and perspectives."
    ],
    "points": 352,
    "commentCount": 476,
    "retryCount": 0,
    "time": 1694351685
  },
  {
    "id": 37456471,
    "title": "Peredvizhnikov Engine: Lock-free game engine written in C++20",
    "originLink": "https://github.com/eduard-permyakov/peredvizhnikov-engine",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up eduard-permyakov / peredvizhnikov-engine Public Notifications Fork 12 Star 469 Code Issues Pull requests Actions Projects Security Insights eduard-permyakov/peredvizhnikov-engine master 1 branch 0 tags Go to file Code Latest commit eduard-permyakov Minor fixes to tests f2026d1 Git stats 261 commits Files Type Name Latest commit message Commit time deps/SDL2 Add SDL2 to project docs Add logo, README src scheduler: Fix being able to dequeue an awaiter more than once during… test Minor fixes to tests .gitignore Makefile: Add option to dump annotated assembly LICENSE.txt Add license Makefile Makefile: fix incorrect module dependency README.md Fix build for latest clang++-16 module.modulemap Fix build for latest clang++-16 README.md Peredvizhnikov Engine is a fully lock-free game engine written in C++20. It implements the actor model of concurrent computation on top of the language's coroutine primitives. Using the actor model abstraction, it is possible to develop complex, parallel logic while being wholly isolated from the details of inter-thread synchronization. A completely lock-free implementation of the model brings with it many advantages, namely guaranteed progress even in the presence of arbitrary thread termination, deadlock-freedom, predictable latency in reacting to critical events, and fault-tolerance. In fact, the degree of fault-tolerance in Peredvizhnikov Engine is so great, that the engine is guaranteed to continue running even when any of the worker threads is asynchronously killed. You may verify this yourself. The implementation is founded upon a mix of classical and novel ideas in lock-free programming. It includes a novel implementation of Software Transactional Memory, a new kind of lock-free queue, an original lock-free serialization primitive, a lock-free std::atomic_shared_ptr, a lock-free scheduler, a lock-free memory allocator and plenty more! For a detailed breakdown of all the lock-free algorithms that went into realizing the engine, rationale for the design, benchmarks, and more, please take a look at the accompanying document: Peredvizhnikov Engine: Design and Implementation of a Completely Lock-Free Scheduler. Building Peredvizhnikov Engine At the moment, the only supported platform is Linux. Clang++ 16 is required to build the sources. git clone https://github.com/eduard-permyakov/peredvizhnikov-engine.git cd peredvizhnikov-engine make -j16 DEBUG=0 License The source code of Peredvizhnikov Engine is freely available under the GPLv3 license. However, I may grant permission to use parts or all of the code under a different license on a case-by-case basis. Please inquire by e-mail. Contact You may contact me with any questions, comments, or concerns pertaining to the source code or the underlying algorithms. In addition, I am currently actively seeking employment. Please don't hesitate to reach out regarding any suitable opportunities. My e-mail is: edward.permyakov@gmail.com About A fully lock-free game engine written in C++20 Resources Readme License GPL-3.0 license Activity Stars 469 stars Watchers 6 watching Forks 12 forks Report repository Releases No releases published Packages No packages published Languages C++ 98.8% Makefile 1.2% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37456471",
    "commentBody": "Peredvizhnikov Engine: Lock-free game engine written in C++20Hacker NewspastloginPeredvizhnikov Engine: Lock-free game engine written in C++20 (github.com/eduard-permyakov) 337 points by gjvc 19 hours ago| hidepastfavorite153 comments smallstepforman 17 hours agoI have an Actor framework which uses a vanilla std::deque for method pointers, and to add messages to the queue, the locking technique is a Benaphore (the original Futex, which uses an atomic and a locking primitive, with the twist that my locking primitive is a combo of spinlock&#x2F;mutex based on retry count). Nothing special. Benchmarks show that very rarely does the message push function block, and the chance of an OS context switch is also very low, so even though occasionally we get a locked thread swapping out, it is so infrequent that it doesn&#x27;t justify the lock-free algorithm cost.In a nutshell, non lock free queues are much faster than lock free queues, however you must be prepared to accept the very infrequent longer delay due to a context switch (where the lock is not available to anyone). My benchmarks show that the price is acceptable since so much more performance is available with non lock free queues. 10 million messages per second per work thread can be queued on modern hardware. reply tialaramex 12 hours agoparent> the original FutexThe \"Benaphore\" was a pretty old idea, but the Futex isn&#x27;t just \"Oh it&#x27;s a Benaphore but Linux\" the essential trick is that you don&#x27;t actually need a kernel object - your \"locking primitive\" at all, and that idea is where this goes from \"Yeah, everybody knows that\" to OK, our OS should add this feature ASAP.Instead of an OS synchronisation object which is used to handle conflicts, with the futex design the OS carries a list of address -> thread mappings. If a thread T is asleep on a futex at address X, the address X goes in the list pointing to thread T. When the OS is asked to wake the X futex, it walks the list and wakes T.The give away is the limits. For something like Benaphores you&#x27;re constrained, these are a costly OS wide resource, I think BeOS only allowed 65536 per machine or something. But a Futex is just memory, so there&#x27;s no reason to have any limit at all. reply Y_Y 17 hours agoparentprevWith a post like this, however interesting, you really should link the code. Not only will it prove your claim, but others like me will find the idea intriguing and immediately want to see how it&#x27;s done. reply smallstepforman 16 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;smallstepforman&#x2F;Medo&#x2F;tree&#x2F;main&#x2F;Actor reply YZF 7 hours agoparentprevIt really depends on the specifics. If there&#x27;s a lot of contention then performance will drop off a cliff. Even atomic instructions can become a bottleneck ( https:&#x2F;&#x2F;stackoverflow.com&#x2F;q&#x2F;2538070 ).I think what you&#x27;re observing, i.e. that in many cases just use a lock and don&#x27;t worry about it (or your variation) is true. But there are certain applications&#x2F;situations where you can do better. Having a consumer pull out everything from the queue with one locking operation and being careful with how you signal the consumer from the producer(s), assuming there&#x27;s a signal, can also make the queue more efficient&#x2F;have higher throughput (e.g. you shouldn&#x27;t signal for every item you put in the queue, only when it becomes non-empty). reply foota 15 hours agoparentprevAren&#x27;t lock free data structures more about reducing the impact of contention than throughput under low contention? reply tialaramex 11 hours agorootparentUnder a lock free algorithm, we promise that across our entire system, eventually some progress is made. I can&#x27;t necessarily point at any specific thread of execution and say \"This thread makes progress\" but I can say that forward progress is made for the system as a whole.Under a wait free algorithm, we promise that every individual thread eventually makes progress.Suppose I have one really dumb thread which just goes to sleep for 10 seconds in a loop, as well as other threads which do some actual work. If we&#x27;re a lock free algorithm, it is OK if the 10-second-sleep thread is always chosen to make progress, its \"progress\" consists of sleeping for 10 seconds, too bad, try again next time.With a wait free algorithm, the threads which actually do useful work will also make at least some progress, eventually despite the 10 second sleeper.Generally we can&#x27;t say for sure that we e.g. \"reduce impact of contention\" only that we definitely make some forward progress, on at least one thread eventually. reply loeg 12 hours agorootparentprevLock free is kind of an overloaded term that can mean a variety of things depending on what the user is thinking. Usually the goal is being able to make forward progress even if one thread is context switched out by the OS scheduler, which might be called wait-free or non-blocking. Using mutexes (unless you can prevent OS scheduling, interrupts, etc) makes this property impossible to achieve. In general, MPSC queues are super fast and there&#x27;s no real reason to prefer a locked queue. reply adwn 3 hours agorootparent> In general, MPSC queues are super fast and there&#x27;s no real reason to prefer a locked queue.There&#x27;s one significant advantage that a locked vector or deque has over MPSC&#x2F;MPMC queues: the consumers can dequeue all messages in a single operation by locking the vector, swapping it with an empty vector (typically, that&#x27;s just 3 words), and locking it again. That&#x27;s such a simple operation that it will typically be as fast or even faster than a single pop-one-message operation in an MPSC&#x2F;MPMP. Similarly, if the vector is empty, a producer can push any number of messages in a single, constant-time operation. reply klodolph 12 hours agorootparentprevDepends what you mean by “the impact of contention”. It is possible, if you build a lock-free system, to end up with threads that keep churning and never make forward progress. reply EliRivers 17 hours agoparentprevMy benchmarks show that the price is acceptableWell, except to people who have a hard requirement that there never be this unpredictable, infrequent longer delay you mention. reply Groxx 16 hours agorootparentIt&#x27;s probably fair to claim that zero* game developers have this hard requirement. At best they have a strong desire which might be partially backed up by benchmarks and squinting hard enough.*: ignoring deliberately esoteric cases, like Doom on a hard real-time system. reply EarthLaunch 16 hours agorootparentIt&#x27;s a requirement for any game that needs a reliable frame rate. Unpredictable delays during frame rendering cause jank.(This is not to say the OP has any such issues in its context.) reply electroly 16 hours agorootparentThis is usually called \"soft realtime\" -- you want it to be fast but it&#x27;s not wrong if it misses deadlines. It doesn&#x27;t violate correctness of the system to miss a deadline. In a \"hard realtime\" system, it is a fatal error if the system misses a deadline because correctness is violated. I presume this difference is what OP is talking about. Games are never hard realtime; missing frame deadlines reduces user experience but it doesn&#x27;t break the game. Hard realtime is things like industrial motion control, automotive and aviation electronics, pacemakers, etc. reply djmips 14 hours agorootparentI would say that an exception could be made for VR games where any frame rate &#x27;jank&#x27; causes an uncomfortable experience and can lead to increased simulator sickness. reply forrestthewoods 13 hours agorootparentVR games almost all use Unity and Unreal. They drop frames left and right. VR platforms use extremely complex time warp algorithms to hide the jank.So you&#x27;re not wrong. VR games are much more susceptible to dropped frames causing problems. But it both happens and is hidden remarkably well. reply jefftk 16 hours agorootparentprev> Games are never hard realtimeDepends how high your standards are! One of the things that makes playing old games on the original hardware really satisfying is how consistent they are. reply brokencode 15 hours agorootparentThose old games could be so consistent because the software and hardware were both so incredibly simple compared to today.Today, a PC game has to work on a large range of hardware that has come out over the past 5+ years. And there are GPU features that are only available on certain cards, like hardware ray tracing and things like DLSS and FSR for upscaling.And the game engines are incredibly more complex today to handle modern expectations, with dynamic lighting and shadows, huge maps, etc.It doesn’t matter what your standards are. Hard realtime just isn’t realistic or even possible any more, except maybe in a game that would be considered truly primitive by today’s standards. reply EliRivers 14 hours agorootparentI am sure I have memories of how hard it was to support a range of hardware when I had to write specifically for each piece. When I had to write separately for a Soundblaster card and an Adlib and a Disney SoundSource and a Roland and a Gravis.And that was just the sound cards. Writing for different hardware became so much easier when OpenGl and DirectX came into being. Suddenly I just had to write to these APIs.I think I&#x27;m disagreeing with you. Supporting multiple hardware configuration way back when was so much harder than doing it today. reply gamacodre 10 hours agorootparentYeah, and Tandy graphics were different from EGA or VGA, just enough that you needed to write different display code for them. And you had to get the user to tell you which ports&#x2F;IRQ numbers half of their hardware was configured at.We have way better hardware abstractions in the OS today, which I would agree makes modern development easier overall. reply EliRivers 1 hour agorootparentOh yes, that brings it all back. Having the user tell me the IRQ and also DMAs and... I&#x27;m sure there was more. Sometimes the user would end up having to open up the PC and reseat physical jumpers on hardware cards to have the cards use values that were both offered by the software and not clashing with anything else.Different world. So much easier now. reply Yoric 13 hours agorootparentprevOh gosh, the many different variants of SVGA that existed back in the days...&#x2F;me shivers at the recollection reply munificent 15 hours agorootparentprev> Games are never hard realtime; missing frame deadlines reduces user experience but it doesn&#x27;t break the game.It depends on whether the game is multi-player and, if so, how it keeps the different players in sync with each other.Games that rely on deterministic gameplay can desync (two players don&#x27;t see the same world state) and abort if one player&#x27;s simulation drops a frame while the other doesn&#x27;t. reply Groxx 15 hours agorootparentIf you have multiplayer like this, you absolutely do not have a hard requirement on frame latency.You don&#x27;t control network latency spikes. Latency tolerance is a hard requirement, or you will have constant problems and likely be unplayable. Or custom networking and hardware stacks, which is deep into esoteric territory. reply electroly 15 hours agorootparentprevThat&#x27;s still just a degradation of user experience and not a fatal fault. Indeed, support for running in desynced mode is written is because they know deadlines can be missed. In hard realtime, deadlines can&#x27;t be missed. There&#x27;s no recovery; it&#x27;s a critical fault and you have to halt or failover to a backup. reply munificent 15 hours agorootparent> That&#x27;s still just a degradation of user experience and not a fatal fault.I don&#x27;t know how you&#x27;d describe a game spontaneously aborting not a \"fatal fault\". Yes, it&#x27;s not turning off someone&#x27;s pacemaker, but within the scope of what a game is able to do, kicking the player back to the matchmaking screen in the middle of a game is about as fatal as it gets. reply fluoridation 15 hours agorootparentThat&#x27;s only going to happen if the client has such a massive network latency spike that the server thinks it&#x27;s disconnected. At least half a second, possibly more. You&#x27;re never going to get that kind of delay from synchronizing threads, unless the process totally deadlocks.EDIT: Well, there is one situation where you might get delays like that: if the computer is so woefully inadequate to run the game that it consistently misses frame deadlines by several hundred milliseconds. Of course, in such a situation a different concurrent algorithm wouldn&#x27;t have solved anything anyway. reply caconym_ 14 hours agorootparentprevLiterally any multiplayer game will have a \"fatal fault\" if its connection to the other players and&#x2F;or server is interrupted for long enough, but it seems disingenuous to describe a system tolerant of delays variable across several orders of magnitude, up to hundreds of milliseconds or even full seconds, as \"hard real time\" in the sense in which the term is generally understood. reply fiddlerwoaroof 15 hours agorootparentprevWhat I don’t understand here is how missing a frame deadline in this situation ( Games that rely on deterministic gameplay can desync (two players don&#x27;t see the same world state) and abort if one player&#x27;s simulation drops a frame while the other doesn&#x27;t.Right. This is why lockstep deterministic (LSD) games are bound to the SLOWEST player&#x27;s machine.No LSD game in existence crashes the game if one player&#x27;s machine falls behind. Instead you either pause the simulation for all players until they catch up or you slow down time itself.Source: shipped RTS games that were lockstep deterministic. reply djmips 14 hours agorootparentprev\"Unpredictable delays during frame rendering cause jank\"This is usually not serious inflicted and the presentation threads will be higher priority than the simulation in order to minimize visual &#x27;jank&#x27;Lockfree game code ain&#x27;t fixing jank from the OS. reply snvzz 7 hours agorootparent>Lockfree game code ain&#x27;t fixing jank from the OS.Latency is like a chain. Every link matters.A game engine programmer can&#x27;t do a thing about the OS, but can still keep latency bounded in the code under their control. reply moonchrome 15 hours agorootparentprevThese people are probably not game developers because frame dips are all over the place on console and PC gaming. reply rcme 14 hours agorootparentprevWell do we have a benchmark where the price of locking is unacceptable? I think the linked project is a fun theoretical exercise, but I personally don’t accept the assertion that locking is unacceptable without seeing evidence. reply Phelinofist 15 hours agoparentprevI agree, lock free is cool and all, but often times it is more complex and not every case justifies the increased complexity. reply samsquire 12 hours agoparentprevThank you for sharing this.Could you tell me if your 10 million figure includes batching or are they a loop that tries to enqueue as many items as possible? reply hoseja 3 hours agoparentprevThe problem with vanilla std::deque is that the only acceptable implementation is in clang libc++. On MSVC it&#x27;s basically an overcomplicated linked list. reply rowanG077 12 hours agoparentprevI gather from your comment that lock-free is actually the best choice for videogames. Where consistent frame timing should be paramount. reply enqk 17 hours agoparentprevhow do you deal with msvc&#x27;s `std::deque`? (or maybe you&#x27;re not using literal std::dequeue) reply OnionBlender 16 hours agorootparentWhat is special about msvc&#x27;s `std::deque`? reply josefx 15 hours agorootparentThe memory chunks it allocates to store entries are so small that it ends up allocating one chunk for every element for almost every type. The result is a lot of allocation overhead, pointer indirection and various other things that are bad for performance. reply nly 14 hours agorootparentprevIt&#x27;s block size is something stupid like 16 bytes, so it effectively becomes a slower linked list. reply dwattttt 1 hour agorootparentSee https:&#x2F;&#x2F;devblogs.microsoft.com&#x2F;oldnewthing&#x2F;20230810-00&#x2F;?p=10... which includes confirmation & a brief commentary of the tiny block size. reply HelloNurse 16 hours agorootparentprevWhatever the issue is, they support Clang on linux, i.e. no MSVC standard library. reply snaury 3 hours agoprevThe lockfree scheduler certainly looks interesting (especially linearizability of event broadcasts), but I was surprised to see benchmark results in the paper with a peak of 43500 messages&#x2F;s for 12 pairs of actors (and 12 cores?), with a graph showing ~5000 messages&#x2F;s for a single core, which is surprisingly low for that kind of benchmark. Unfortunately the engine requires linux and more importantly x86 (due to asm intructions) so I wasn&#x27;t able to replicate them yet, but I would expect at least ~1 million requests&#x2F;s per a pair of actors (e.g. with Erlang), otherwise the overhead is prohibilitely low.The engine also focuses on message passing, but from experience it&#x27;s very difficult to work with (state machines are hard, especially when working with multiple downstream actors), and at the core actors are more about isolating state without locks than message passing. Swift actors did it right in my opinion, method calls instead of messages are not only easier to reason about, they give additional hints to the runtime when context may switch without involving a scheduler at all (any shared state is slow and inhibits scalability).I actually wrote a header-only library recently (search for \"coroactors\" if you&#x27;re interested) that implements something similar to Swift actors with C++20 coroutines, and I thought ~10 million requests&#x2F;s (when uncontended) or ~1-3 million&#x2F;s (when contended and depending on a scheduler) was a way too high of an overhead, especially when compared to normal method calls with shared state protected with mutexes. Coroutines tend to go viral (with more and more functions becoming \"async\" coroutines), and any non-trivial code base would have a lot of coroutine calls (or messages passed), and that overhead needs to be as low as possible, otherwise you&#x27;d spend more time task switching than doing useful work. reply devit 16 hours agoprevIt says that it&#x27;s actor-based, and sending messages to an actor is equivalent to running the actor function under a mutex, and thus reduces parallelism (in other words, you have N threads sending messages, but only 1 thread running the actor code, so it&#x27;s just as serialized as a mutex), so while it may technically be \"fully lock-free\", using actors means that there is no parallelization improvement. reply jstimpfle 14 hours agoparent> sending messages to an actor is equivalent to running the actor function under a mutexWhere does it say that? In my understanding actor model means message-passing with asynchronous execution. So quite the contrary, actor model allows N threads executing in parallel given N actors. reply mrkeen 12 hours agorootparentWhenever I read any press about actors or goroutines, they say the same thing about preventing races (and the need for explicit locking) through share-nothing concurrency.It&#x27;s easy to scatter the computations, but they never go on to explain how to gather them back up.You&#x27;re going to render one frame to the screen. Did multiple actors have a write-handle into the frame buffer? What about collisions, does each entity collide with itself, without sharing position information with other actors? reply jstimpfle 9 hours agorootparentHow to gather them up, I guess messages again? It depends on the situation how easy it is, and yes I would assume typically not very. reply hot_gril 12 hours agorootparentprevOne way or another, there has to be a master thread that gathers things back. So instead of a mutex, you have a supervisor. reply onjectic 14 hours agoparentprevYour right that there is no parallelization improvement, but it does not reduce parallelism either, its just a different(imo easier) way to think about concurrency.Because it is easier for me to think about it is easier for me to see where things will contend the same resource and actually helps me improve potential parallelism. Once you recognize a particular opportunity where SMP can speed things up, you can stray a way from the actor-model a bit and have multiple threads receiving on your message queue, or if that isn&#x27;t possible, you can just add more actors and split up the data better. reply lelandbatey 14 hours agoparentprevNot quite; with mutex based actors an interruption of the actor thread would cause that mutex (and thus that actor code) to remain locked until the original thread resumes. No additional parallelism will allow that actor code to be \"restarted\" or \"resumed\" as the mutex owned by the interrupted thread is locked.This implementation relies heavily on restartable functions in order to allow another parallel thread to pick up and continue the work of an already in progress but otherwise interrupted actor. See page three of the (excellent) design document: https:&#x2F;&#x2F;github.com&#x2F;eduard-permyakov&#x2F;peredvizhnikov-engine&#x2F;bl...Thus while it might not strictly be \"more parallel\" (same number of actors), it does seem to be able to make better use of more parallelism for completing the same set of work. reply schmichael 17 hours agoprevDoes anyone have experience debugging&#x2F;profiling highly contended critical sections of STM vs a more traditional mutex implementation? At the end of the day something has to mediate concurrent access to shared memory, there’s no free lunches, and mutexes are so well optimized, profiled, and understood. I’m unclear if the same applies to STM where a transaction may need to be retried an unbounded(?!) number of times. reply pramalhe 3 hours agoparentActually, for starvation-free STMs, transactions will retried a _bounded_ number of times. One example is 2PLSF, but there are several others https:&#x2F;&#x2F;zenodo.org&#x2F;record&#x2F;7886718 reply gabereiser 17 hours agoparentprevYes. The mediator in this case is the scheduler. The one that actually calls the asynchronous block. Potentially retrying it if it fails. In the OP’s code, there’s atomic blocks, sequential execution of blocks, stateful blocks, etc for ensuring singular access at a time.The meat here is scheduler.cpp. It uses std::coroutines.This is like async&#x2F;await in other languages. The scheduler has a queue of work(coroutines) and a pool of threads(N>0) to execute those on.In this case, messages are passed between work that contains the data. No locks are required at the expense of memory footprint. reply schmichael 16 hours agorootparentThanks!So the scheduler serializes execution of critical sections?> In this case, messages are passed between work that contains the data. No locks are required at the expense of memory footprint.Are messages copied or moved? If moved is there compile time checking for ownership or runtime debugging tools? reply gabereiser 15 hours agorootparenthttps:&#x2F;&#x2F;en.cppreference.com&#x2F;w&#x2F;cpp&#x2F;language&#x2F;coroutines reply jeffreygoesto 18 hours agoprevLooks BEAMish to me?https:&#x2F;&#x2F;youtu.be&#x2F;bo5WL5IQAd0?feature=shared reply pjmlp 1 hour agoprevI wonder why it is using clang modules instead of proper C++20 modules.Except for header units, the support is already mostly there. reply Voultapher 3 hours agoprevAs cool as lock free sounds, in my opinion any amount of non-trivial atomics usage should be accompanied by a formal, ideally machine checked, proof. Non sequential consistent atomic ordering usage is so difficult to get right. I&#x27;ve repeatedly seen code that gets it wrong, and the bugs that creates are the worst. reply djmips 17 hours agoprevI didn&#x27;t see mention of how hard it is to debug such an engine. reply hot_gril 18 hours agoprevI don&#x27;t have time to read through the impl, but the readme makes it sound like a classic distributed system between game threads, where patterns like retry-backoff will be common. reply jacoblambda 17 hours agoparentThe paper goes into more detail without forcing you to go into the impl but it does seem to be a decent bit more advanced than that.https:&#x2F;&#x2F;github.com&#x2F;eduard-permyakov&#x2F;peredvizhnikov-engine&#x2F;bl... reply kovacs_x 2 hours agoprevI&#x27;m 99% sure, the author has never done any completed &#x2F; published non trivial game..... because doing lock-free programming is least of problems when creating games. reply malkia 10 hours agoprevWhere is the game demo? Also to be considered gaming engine nowadays, you need actual tools, exporters (Maya, 3DSMax, etc.) + who knows what else (collaboration tooling, metrics, alerts) reply adamrezich 10 hours agoparentI disagree—\"game engine\" does not necessarily mean \"thing I can replace Unity or Unreal with\". reply xwdv 9 hours agorootparentNot even asking for that much. Any game demo would be appreciated. reply charcircuit 11 hours agoprev>Lock-free export std::mutex iolock{}; export std::mutex errlock{}; SDL_PollEventNot yet at least. reply xwdv 18 hours agoprevAny games built with this reply minitoar 17 hours agoparentYes, it’s called C++20 Game Engine Developer. reply mdaniel 18 hours agoprevAll those people who complain about project names squatting on existing words have finally been heard :-D reply pekka22 18 hours agoparentPeredvizhniki [0] were a group of Russian realist painters from the 19th century. Among other things, they organized \"traveling\" art exhibitions to promote Russian art in the provinces. The name roughly translates as \"The travelers\".- [0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Peredvizhniki reply rhelz 17 hours agorootparentNot all who wander are lost. reply forty 17 hours agoparentprevI tried in it a zxcvbn simulator, and it qualified as a strong password ;) reply segfaultbuserr 10 hours agorootparentMy experience is that zxcvbn lacks many non-English dictionaries, it often gives false-positives for foreign languages... reply datameta 18 hours agoprevThe painting used is Barge Haulers on the Volga - https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Barge_Haulers_on_the_VolgaCan someone please expand on the significance of this achievement to someone used to shooting their foot off in C++ in a predominantly single threaded manner? reply mhd 18 hours agoparentNever mind that a lot of Volga boats were very single-threaded.https:&#x2F;&#x2F;www.amusingplanet.com&#x2F;2021&#x2F;12&#x2F;belyana-russias-giant-... reply perihelions 17 hours agorootparentIt&#x27;s a logging framework! :D reply aldanor 1 hour agorootparentStreaming logging framework reply 3seashells 18 hours agorootparentprevYou can even see the steam ships that replaced the slave in the background. reply beatcracker 17 hours agorootparentThey were not the slaves, but unionized workers:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Burlak reply mananaysiempre 17 hours agorootparentAFAIU an артель artelʼ usually did not engage in collective bargaining as such, so calling it a union is not really accurate; you might compare it to a guild but I think there’s no implicaton of a monopoly on a particular trade either. The most accurate description I can think of is perhaps a cooperative combined with a mutual insurance fund. reply beatcracker 16 hours agorootparentAgree, I might&#x27;ve stretched It a bit. Your descriptions is more accurate. reply Iwan-Zotow 7 hours agorootparentprevYEp, somewhat resemblance to Teamsters reply datameta 16 hours agorootparentprevFun fact - this was painted about 8 to 10 years after the abolition of serfdom in the Russian Empire. Coincidentally, it happened two years prior to the US Emancipation Proclamation. I&#x27;ve wondered from time to time how linked the two events were, if at all. reply Iwan-Zotow 7 hours agorootparentprevthey were not slaves, but something like Russian Teamsters reply datameta 9 hours agoparentprevAs an addendum - a fair portion here should be in one way or another familiar with Ilya Repin&#x27;s Reply of the Zaporozhian Cossacks (aka Zaporozhian Cossacks are Writing a Letter to the Turkish Sultan) https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Reply_of_the_Zaporozhian_Cos... reply hathym 16 hours agoparentprevI hope the author is not picturing developers using his engine. reply drums8787 15 hours agoparentprevBarge hauler 4th from the back appears to be checking his messages. reply tetris11 15 hours agorootparent\"Tut tut, those poor Canadian renters...\" reply hesdeadjim 18 hours agoprevIt’s quite the stretch to call this a game engine, rather than a tech demo for clever locking strategies. reply Salgat 16 hours agoparentI wouldn&#x27;t even call it clever. The Actor model trivializes avoiding locks, since you&#x27;re letting everything act on stale information (if the actors process concurrently) and then just iterating through their intended actions against a singleton state and resolving those conflicts with sequential code. reply sigg3 15 hours agorootparentThanks for the summary, mate. reply DennisP 18 hours agoparentprevMaybe it&#x27;s not done yet. reply rhelz 16 hours agoparentprevSay you are in the middle of building a house. The foundation has been built and they are framing it up.Is it a house? reply squeaky-clean 10 hours agorootparentNo, because otherwise you wouldn&#x27;t say \"the foundation has been built\". You&#x27;d say the \"the house has been built\".Does a house need a foundation? Yes. Is the foundation the same as the house? No. reply rhelz 1 hour agorootparentBut you do say, “I am building a house.” reply nitwit005 16 hours agorootparentprevNo reply xwdv 16 hours agorootparentprevNo, and if you accept it as a house then this is a recipe for developing a bad habit of leaving a trail of half finished projects in your wake. reply rhelz 1 hour agorootparentCan you point at a house and say “I designed this house?” If the house didn’t have some kind of existence while you were even designing it, how could it be that you designed that, particular house? reply Reticularas 10 hours agoparentprevThis model isn&#x27;t novel, there&#x27;s been experimental engines using this technique for years now. They&#x27;re just not practical at scale reply forrestthewoods 18 hours agoparentprevThis. There’s no demonstration of any game made with this “game engine”. The benchmarks are some matrix multiplication and unimpressive message passing.There might be some cool data container ideas or primitives. Those could have useful applications. But it isn’t really a “game engine”. Nor does it seem like an interesting way to build one. reply erwincoumans 18 hours agorootparentIndeed. The project has no renderer or game physics code it seems? If so, it is too premature to be a game engine. reply edfletcher_t137 16 hours agoprev> At the moment, the only supported platform is Linux.Regardless of your feelings on the status quo, there is one thing you must do when building a game engine if you want it to succeed: support Windows. reply StevenXC 16 hours agoparentI&#x27;d love to see the Steam Deck \"console\" change this status quo. reply tmccrary55 16 hours agorootparentMost of the SteamDeck games are just running windows games through photon, wine and other compatibility layers.While that works amazingly well, I tend to prefer games with native Linux and SteamOS builds, even though they&#x27;re rare. reply NavinF 16 hours agorootparentprevwin32 is the stable ABI for SteamOS, same as any other Linux distro reply WhereIsTheTruth 15 hours agoparentprevbullshit, consoles&#x2F;mobile are bigger markets than PC&#x2F;WindowsPC is just less than 1&#x2F;3 of the whole picturehttps:&#x2F;&#x2F;www.data.ai&#x2F;en&#x2F;insights&#x2F;mobile-gaming&#x2F;2022-gaming-sp... reply p1necone 8 hours agorootparentI feel like it&#x27;s a mistake to consider mobile games as being part of the same market as PC&#x2F;console games.Sure they&#x27;re both \"games\" but I don&#x27;t know that they&#x27;re competing for the same set of users - either people play one or the other, or the people that do crossover in both markets are probably playing PC&#x2F;console games at home and mobile games on the bus or train. reply 5e92cb50239222b 15 hours agorootparentprevA bit more than that since Xbox runs Windows too. reply WhereIsTheTruth 15 hours agorootparentJuly console sales:PS5: 1.2mSwitch: 950kXbox: 370kXbox accounts for just 17% of total console sales in JulyBoth Switch and PS5 are FreeBSD basedIf we count the whole period of the current gen of each vendors, it only accounts for 13%, it&#x27;s not bighttps:&#x2F;&#x2F;www.vgchartz.com&#x2F; reply squeaky-clean 10 hours agorootparentAnd what about actual game sales and revenue through things like GamePass. It doesn&#x27;t help your game if a million people bought a Nintendo Switch if 80% of them only buy Pokémon, Mario Kart and Zelda. reply rstat1 13 hours agorootparentprevActually its only the PS5 that&#x27;s FreeBSD based. Switch runs a completely proprietary Nintendo OS that borrows a lot from Android. reply WhereIsTheTruth 12 hours agorootparentA mix of the two\"partially Unix-like via certain components which are based on FreeBSD and Android\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nintendo_Switch_system_softwar... reply rstat1 8 hours agorootparentfrom the same article\"it is based on a proprietary microkernel\"\"....Despite popular misconceptions to the contrary, Horizon (the Switch&#x27;s OS) is not largely derived from FreeBSD code, nor from Android...\" reply GranPC 13 hours agorootparentprevIt borrows very little from Android - I think it mostly draws some parts from stagefright. reply rstat1 8 hours agorootparentAlso borrows the whole of its compositor \"nvnflinger\" from Android&#x27;s \"SurfaceFlinger\".I&#x27;d call that a pretty significant piece. replyhot_gril 11 hours agorootparentprevRude way of putting it, but yeah, mobile dwarfs everything. reply kevingadd 13 hours agorootparentprevGot bad news for you about what the console SDKs run on(Also, the consoles don&#x27;t run Linux) reply corethree 14 hours agorootparentprevHe&#x27;s probably referring to the Desktop&#x2F;laptop market. In which case windows controls like 90%. reply WhereIsTheTruth 12 hours agorootparentTitle is: \"Peredvizhnikov Engine is a fully lock-free game engine written in C++20 \"A Game Engine targets various platformsA \"video-game\" is not something exclusive to desktop&#x2F;laptop windows market reply corethree 9 hours agorootparentRight but a toolchain that targets anything else other then a desktop is not straightforward to find or setup.Toy game engines like this are in the majority of cases used on desktop. replyhankman86 12 hours agoprevIt’s licensed under GPL3, where the developer suggests individually negotiating a license for commercial projects. I am not sure this is a good approach given the early stage of this project. Video game development is already commercially and technically risky enough.I cannot see game developers lining up to even try out this unproven technology when they have no sense of what the eventual fees will be. reply gjvc 12 hours agoparentquoting https:&#x2F;&#x2F;github.com&#x2F;eduard-permyakov&#x2F;peredvizhnikov-engineThe source code of Peredvizhnikov Engine is freely available under the GPLv3 license. However, I may grant permission to use parts or all of the code under a different license on a case-by-case basis. Please inquire by e-mail. reply pshirshov 12 hours agoprevActors is one of the worst programming models possible. It&#x27;s hard to observe actor-based systems and debug them. The protocol complexity (and complete protocol informality) usually brings much more trouble than any kind of locking&#x2F;synchronization. reply lll-o-lll 12 hours agoparentI’ve had good success with actor based models. When you say “protocol complexity”, I don’t understand what you mean.Observation requires good logging, but this isn’t out of line for any complex system. Debugging (as in actual breakpoints in an IDE or post-mortem analysis) can be facilitated with stack tracking (this same problem occurs with async await patterns and is solved in a similar way).The advantages and disadvantages exist, but I think it’s an extremely effective programming model for many use cases. Formal state-machine programming, that’s the worst model, unless you need it. reply hot_gril 11 hours agoparentprevFor game dev or in general? I hate using actors for general backend stuff, but for game dev maybe it makes more sense. reply legosexmagic 9 hours agorootparentActors tend to lead to bloated incomprehensible code. Even when you do want game objects to look like independent message passing actors. Faking it is always easier.Actors are self defeating because they turn everything into a distributed system. reply hot_gril 5 hours agorootparentThat&#x27;s what I was thinking. I&#x27;m trying not to write Actors off because I&#x27;m not an expert on game dev and can imagine the possibility of an unusually large-scaled game. But yeah, if you&#x27;re writing a typical game, I imagine you&#x27;re best off doing it the typical way that&#x27;s been optimized for. reply gabereiser 17 hours agoprev [11 more] [flagged] rychco 17 hours agoparent [–] Forgive me if it’s common knowledge, but what’s wrong with SDL2 in this case? Broadly speaking, I feel as though there is largely positive sentiment around the SDL project, no? reply gabereiser 17 hours agorootparent [–] I have nothing against the SDL project. I have everything against the DirectMedia style api of 1997. I get that people are actively developing with it and that roadmap towards 3.0 is getting close but my experience is it’s designed for legacy games, legacy rendering styles, legacy ABI’s. No one is shipping games for Dreamcast or PS2.2&#x2F;3rds of the library is dead code when working with Vulkan. reply rstat1 13 hours agorootparentTIL Unreal 5 based games were \"legacy\" reply gabereiser 8 hours agorootparentThey really only use it for Linux window and audio because there’s so many ways to skin a disto. reply rstat1 4 hours agorootparentThey definitely use it for more than that, because I&#x27;m sure I&#x27;ve seen it ship with Windows games as well.Also there&#x27;s exactly 2 ways to get a window on Linux, and those 2 ways are common to pretty much every modern distro. Same as audio. reply OnionBlender 16 hours agorootparentprev [–] What is a better alternative? reply gabereiser 14 hours agorootparent [–] For what? Working with Vulkan? Or a windowing library? Personally I use a mix of glfw and native windowing on mobile, which is surprisingly simple for a gfx context window and this gets me to triangle.SDL2 is about the same amount of boilerplate code only in SDL_Thing form.Now, if I was writing a game that needed to be shipped on everything possible and I can’t afford Unity or Unreal, SDL is a viable choice. MonoGame, mine, and others have used it, it’s battle tested.I just can’t look at SDL code anymore and say “this is the cleanest api” for anything outside of C99. reply nickelpro 14 hours agorootparent [–] As with most SDL usage, it merely provides a rendering context and an input abstraction.That&#x27;s almost nothing, its boilerplate you don&#x27;t want to write. Which particular lib you grab that boilerplate from, SDL, GLFW, fucking GLEW, whatever, it doesn&#x27;t matter. SDL is a widely accepted library for doing so and it&#x27;s fine. If you want more complete input handling you&#x27;ll be using the platform APIs directly. reply gabereiser 8 hours agorootparent [–] And surfaces, and audio… yeah I know. For tinkering and learning, sure. If you’re going to build an engine, pull that boilerplate code within. reply nickelpro 7 hours agorootparent [–] Many, arguably most, custom game engines never internalize that boilerplate. Most engine codebases are much smaller and more specialized than the AAA players, and gain nothing from splitting their build into platform-specific layers when they could just link SDL. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Peredvizhnikov Engine is a lock-free game engine written in C++20, designed on the actor model of concurrent computation, allowing parallel logic development and inter-thread synchronization isolation.",
      "The engine is fault-tolerant, guaranteed to persist even if worker threads are killed, includes lock-free algorithms, and is GPLV3 licensed but can be licensed differently if permitted by the creator.",
      "Currently, the engine only supports Linux, and requires Clang++ 16 for building."
    ],
    "commentSummary": [
      "The Peredvizhnikov Engine, a lock-free game engine written in C++20, uses a unique Benaphore technique for message queueing that improves performance levels.",
      "Key debate points in game development are consistent performance, synchronization among multiple players, the intricacy of current hardware and software, and the Peredvizhnikov Engine's limitations including debugging challenges and no Windows support.",
      "A substantial discussion is also devoted to the distinction between mobile games and PC/console games, emphasizing the advantage of utilizing a library like SDL versus platform-specific layers for constructing a game engine."
    ],
    "points": 337,
    "commentCount": 153,
    "retryCount": 0,
    "time": 1694358233
  },
  {
    "id": 37455621,
    "title": "How does Linux NAT a ping?",
    "originLink": "https://devnonsense.com/posts/how-does-linux-nat-a-ping/",
    "originBody": "[posts][tags][about][github] how does linux nat a ping? 2023-09-08 #linux #networking A few months ago, I found myself wondering how a command like ping 1.1.1.1 works from within a private network. In most private networks, multiple hosts connect to the Internet through a router. For IPv4, the router performs network address translation (NAT) by rewriting the original host’s source address to the router’s public IP address. The router can lookup the correct host for a reply packet based on the packet’s port field, at least for protocols like TCP and UDP. But a command like ping doesn’t use TCP or UDP; it uses ICMP, and those packets do not have a port field. So how does NAT work for ICMP packets? This led me down a deep rabbit hole: running experiments in network namespaces, capturing packets, reading RFCs, and tracing through the Linux source code. This post summarizes what I did and learned along the way.1 Before these experiments, I hadn’t spent much time in the Linux networking code – this is something new I’m learning. If I’ve made any mistakes please let me know so I can correct them. Table of contents Experiment setup Step 1: Connect two clients to a bridge Step 2: Connect natbox and server Step 3: Configure routing and NAT Packet capture RFC 792 Ping source code ID conflict Netfilter, conntrack, and NAT bpftrace Conclusion Experiment setup One of the best ways to understand Linux networking is through experimentation. These days, it’s easy to run experiments using network namespaces to simulate multiple devices on a single Linux machine. This is the setup I wanted to test: There are two clients (client1 and client2) connected to a router (natbox) performing NAT from private network 192.168.99.0/24 to public network 10.0.100.0/24. The clients, natbox, and server are each separate network namespaces. Once everything is ready, a ping from either client to the server at 10.0.100.2 should get a reply! For these experiments, I used a Fedora 38 Server VM running version 6.2.9 of the Linux kernel. Most of the below commands (ip, iptables, tcpdump, etc.) were run as the root user.2 Step 1: Connect two clients to a bridge The first step is to create two clients connected to a bridge, like this: To set it up: # Create a network namespace for each client. ip netns add \"client1\" ip netns add \"client2\" # Create a virtual bridge. ip link add name \"br0\" type bridge ip link set dev \"br0\" up # Disable iptables processing for bridges so rules don't block traffic over br0. sysctl -w net.bridge.bridge-nf-call-iptables=0 # Connect client1 to the bridge with a veth pair and assign IP address 192.168.99.1 ip link add dev \"vethclient1\" type veth peer name \"eth0\" netns \"client1\" ip link set \"vethclient1\" master \"br0\" ip link set \"vethclient1\" up ip -n \"client1\" addr add dev \"eth0\" \"192.168.99.1/24\" ip -n \"client1\" link set dev \"eth0\" up # Same for client2, with IP address 192.168.99.2 ip link add dev \"vethclient2\" type veth peer name \"eth0\" netns \"client2\" ip link set \"vethclient2\" master \"br0\" ip link set \"vethclient2\" up ip -n \"client2\" addr add dev \"eth0\" \"192.168.99.2/24\" ip -n \"client2\" link set dev \"eth0\" up If this worked, then: ip netns should show client1 and client2. ip -n client1 addr and ip -n client2 addr should show 192.168.99.1 and 192.168.99.2 respectively, and the eth0 interface should show “state UP”. Now the two clients can ping each other over the bridge: # ping client1 -> client2 ip netns exec client1 ping 192.168.99.2 # ping client2 -> client1 ip netns exec client2 ping 192.168.99.1 Step 2: Connect natbox and server Next, create network namespaces for the natbox and server: ip netns add \"natbox\" ip netns add \"server\" Then connect the natbox to the bridge: ip link add dev \"vethnatbox\" type veth peer name \"eth0\" netns \"natbox\" ip link set \"vethnatbox\" master \"br0\" ip link set \"vethnatbox\" up ip -n \"natbox\" addr add dev \"eth0\" \"192.168.99.3/24\" ip -n \"natbox\" link set dev \"eth0\" up The natbox needs a second interface in the 10.0.100.0/24 network, so add that and call it “eth1”. Since there’s only one server, there’s no need for a bridge – just connect the natbox and server directly with a veth pair: ip -n \"natbox\" link add \"eth1\" type veth peer name \"eth1\" netns \"server\" ip -n \"natbox\" addr add dev \"eth1\" \"10.0.100.1/24\" ip -n \"natbox\" link set dev \"eth1\" up ip -n \"server\" addr add dev \"eth1\" \"10.0.100.2/24\" ip -n \"server\" link set dev \"eth1\" up Now the natbox can reach both clients and the server. Test it with ping: # ping natbox -> client1 ip netns exec natbox ping 192.168.99.1 # ping natbox -> client2 ip netns exec natbox ping 192.168.99.2 # ping natbox -> server ip netns exec natbox ping 10.0.100.2 At this point, every network namespace, interface, and veth pair has been created: However, the client cannot yet ping the server because the natbox isn’t forwarding traffic between its interfaces or performing NAT. Step 3: Configure routing and NAT Add a default route in each client to send traffic to the natbox: ip -n client1 route add 0.0.0.0/0 via 192.168.99.3 ip -n client2 route add 0.0.0.0/0 via 192.168.99.3 For security reasons, Linux does not forward packets between interfaces unless specifically enabled. So configure the natbox to forward traffic by setting net.ipv4.ip_forward: ip netns exec natbox sysctl \"net.ipv4.ip_forward=1\" At this point, packets from a client will reach the server. However, these packets will retain the original source IP in the 192.168.99.0/24 network, so replies from the server back to this IP will go… nowhere. Fix it by configuring the natbox to NAT the traffic from a client IP (in network 192.168.99.0/24) to the natbox’s public IP (10.0.100.1/24). The easiest way to do this is to add a MASQUERADE rule to the iptables “nat” chain: ip netns exec natbox iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE At last, clients can reach the server through the natbox! Test it with ping: # ping client1 -> server via natbox ip netns exec natbox ping 10.0.100.2 # ping client2 -> server via natbox ip netns exec natbox ping 10.0.100.2 Packet capture Now capture ICMP packets from both client and server network namespaces. ip netns exec client1 tcpdump -n icmp ip netns exec server tcpdump -n icmp This is the tcpdump for client1: 08:01:33.549598 IP 192.168.99.1 > 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64 08:01:33.549661 IP 10.0.100.2 > 192.168.99.1: ICMP echo reply, id 31428, seq 1, length 64 08:01:34.610605 IP 192.168.99.1 > 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64 08:01:34.610654 IP 10.0.100.2 > 192.168.99.1: ICMP echo reply, id 31428, seq 2, length 64 … and the corresponding tcpdump for the server: 08:01:33.549643 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 31428, seq 1, length 64 08:01:33.549654 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 31428, seq 1, length 64 08:01:34.446611 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 33391, seq 1, length 64 08:01:34.446619 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 33391, seq 1, length 64 08:01:34.610635 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 31428, seq 2, length 64 08:01:34.610646 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 31428, seq 2, length 64 08:01:35.506411 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 33391, seq 2, length 64 08:01:35.506423 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 33391, seq 2, length 64 These captures show that: Traffic is being NAT’d. By the time an ICMP echo request reaches the server (10.0.100.2), its source IP has been rewritten to the IP of the natbox (10.0.100.1). Each client has a different “id” field (in the capture above, client1 has ID 31428 and client2 has ID 33391). The “id” field seemed like it might allow the natbox to distinguish reply packets destined for each client. But what does the “id” field mean, and how is it chosen? RFC 792 ICMP is a very, very old protocol. It is defined in RFC 792, which was published in 1981. The RFC specifies the exact structure of an ICMP echo and echo reply message: 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+TypeCodeChecksum+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+IdentifierSequence Number+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+Data ... +-+-+-+-+- The “type” field distinguishes an echo request (8) from an echo reply (1). Code is always 0 (I guess it isn’t used for anything?). What about “sequence number” and “identifier”? If code = 0, an identifier to aid in matching echos and replies, may be zero… If code = 0, a sequence number to aid in matching echos and replies, may be zero… The identifier and sequence number may be used by the echo sender to aid in matching the replies with the echo requests. For example, the identifier might be used like a port in TCP or UDP to identify a session, and the sequence number might be incremented on each echo request sent. The echoer returns these same values in the echo reply. The RFC doesn’t say anything about how the IDs are actually chosen. That’s not part of the protocol specification, so the next step is to look at an implementation – in this case, the source code for the ping command. Ping source code The ping command is part of the “iputils” package, with source code available at github.com/iputils/iputils. There is a comment just before ping4_send_probe: /* * pinger -- *Compose and transmit an ICMP ECHO REQUEST packet. The IP packet * will be added on by the kernel. The ID field is a random number, * and the sequence number is an ascending integer. The first several bytes * of the data portion are used to hold a UNIX \"timeval\" struct in VAX * byte-order, to compute the round-trip time. */ So ping chooses the identifier randomly. It’s a bit difficult to see where this actually happens in the code, but from what I understand: There is a struct ping_rts that has a field ident. The ident field defaults to -1, but can be overridden by the CLI flag “-e” to any value between zero and IDENTIFIER_MAX (0xFFFF). When rts->ident == -1, ping binds to a socket with type SOCK_DGRAM and protocol IPPROTO_ICMP. In this configuration, it does not modify source.sin_port, so the source port is zero. I didn’t find much documentation for how Linux implements SOCK_DGRAM sockets with IPPROTO_ICMP, except for this description from the mailing list “net: ipv4: add IPPROTO_ICMP socket kind”: ICMP headers given to send() are checked and sanitized. The type must be ICMP_ECHO and the code must be zero (future extensions might relax this, see below). The id is set to the number (local port) of the socket, the checksum is always recomputed. I suspect that when ping doesn’t specify a source port (source.sin_port == 0), then the Linux kernel chooses a free port at random. This port then gets used as the ID for ICMP packets. ID conflict What happens if two ping processes on different hosts both choose the exact same ID? Test it using ping -e to explicitly set the ICMP ID to the same value for both clients: # ping from client1 -> server with ICMP ID 999 ip netns exec client1 ping 10.0.100.2 -e 999 # ping from client2 -> server with ICMP ID 999 ip netns exec client2 ping 10.0.100.2 -e 999 This time, the packet capture from the server shows something different: 10:22:18.807289 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 999, seq 1, length 64 10:22:18.807300 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 999, seq 1, length 64 10:22:19.838650 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 999, seq 2, length 64 10:22:19.838661 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 999, seq 2, length 64 10:22:20.011677 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 30218, seq 1, length 64 10:22:20.011687 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 30218, seq 1, length 64 10:22:20.862591 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 999, seq 3, length 64 10:22:20.862603 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 999, seq 3, length 64 10:22:21.054598 IP 10.0.100.1 > 10.0.100.2: ICMP echo request, id 30218, seq 2, length 64 10:22:21.054614 IP 10.0.100.2 > 10.0.100.1: ICMP echo reply, id 30218, seq 2, length 64 One of the clients is using ID 999, but the other one is using ID 30218. Where did that second ID come from? Time to go to the Linux source code. Netfilter, conntrack, and NAT The kernel subsystem responsible for implementing iptables rules is called “netfilter.” The iptables MASQUERADE rule is responsible for NAT’ing packets, so the NAT implementation for ICMP must be in netfilter. Grep’ing through the net/netfilter directory in the Linux repository, I found a few places where the ICMP “id” field is used: In “nf_nat_core.c” the function nf_nat_setup_info calls get_unique_tuple, which calls nf_nat_l4proto_unique_tuple. There is a switch statement with a case for IPPROTO_ICMP, and a reference to &tuple->src.u.icmp.id. In “nf_nat_proto.c” the function nf_nat_manip_pkt calls nf_nat_ipv4_manip_pkt, which calls l4proto_manip_pkt. When the protocol is IPPROTO_ICMP this calls icmp_manip_pkt, which has a line hdr->un.echo.id = tuple->src.u.icmp.id. In order to NAT packets, netfilter needs to store something called a connection. For TCP, not surprisingly, this represents the TCP connection, uniquely identified by the 5-tuple (src IP, src port, dst IP, dst port, L4 protocol). However, in netfilter the term “connection” has a broader meaning: it can correlate outgoing and incoming packets even for connectionless protocols like UDP and ICMP. Examining the nf_conn data structure: nf_conn has a field struct nf_conntrack_tuple_hash tuplehash[IP_CT_DIR_MAX]. There are two tuple hashes, one for outgoing packets and one for incoming packets (IP_CT_DIR_ORIGINAL and IP_CT_DIR_REPLY respectively). Each nf_conntrack_tuple_hash has a field nf_conntrack_tuple tuple with the tuple uniquely identifying the connection. Each tuple is split into a part that can be manipulated, called src, and a part that is immutable called dst. src has type struct nf_conntrack_man, which has an IP address (union nf_inet_addr u3) and protocol-specific fields (union nf_conntrack_man_proto u). For ICMP, the protocol-specific field is __be16 id. dst has the unmodified IP address as well as the ICMP type and code fields. Connection tracking and NAT are closely related. To NAT a packet, netfilter needs to “remember” how it modified the outgoing packet so it can reverse those modifications on the reply packet. It does so by representing the modifications in a connection. For ICMP, I believe netfilter works like this: When natbox receives an ICMP echo, nf_nat_setup_info creates a new connection. This is where it chooses whether it needs to rewrite the source IP address and/or the ICMP id field on the outgoing packet. For each incoming and outgoing ICMP packet, the function nf_nat_manip_pkt sets the source IP and ICMP id field to whatever is set in the connection. The argument ip_conntrack_dir dir determines whether the packet is treated as an outgoing echo (rewrite the source IP) or incoming reply (rewrite the destination IP). nf_nat_setup_info is responsible for choosing the ICMP ID for the NAT’d packets. The NAT rewrites happen in get_unique_tuple. Here are the key steps: On line 541, find_best_ips_proto(zone, tuple, range, ct, maniptype) rewrites the source IP address. On lines 548-560, nf_nat_used_tuple(tuple, ct) checks whether the tuple is already being used; if not, the current tuple is returned. This explains why when two clients use different ICMP IDs, those IDs are preserved in the NAT’d packets. On line 563, nf_nat_l4proto_unique_tuple is called to perform protocol-specific NAT (in this case manipulating the ICMP ID field). In nf_nat_l4proto_unique_tuple lines 393-403 set keyptr = &tuple->src.u.icmp.id to choose the ICMP ID field as the “key” to NAT, then jumps to find_free_id at the end of the function. find_free_id on line 471 calls get_random_u16() to generate a random ID, adjusts the value into the range3 of valid ICMP IDs (on line 485), then checks if it’s used (another call to nf_nat_used_tuple on line 486). If a tuple with the random ID not yet used, then it gets returned. Otherwise, netfilter searches for an unused ID from progressively smaller ranges starting at random offsets (lines 483-494). If an unused tuple cannot be found within a maximum number of attempts, then nf_nat_l4_proto_unique_tuple returns, leaving the duplicate ID in the connection. Later, __nf_conntrack_confirm will detect the duplicate and drop the packet. bpftrace To verify my understanding of the netfilter code, I used a tool called bpftrace.4 After much tinkering, I ended up with this program to trace the kernel functions nf_nat_setup_info and nf_nat_manip_pkt: // from linux/socket.h #define AF_INET2 /* Internet IP Protocol*/ // from net/netfilter/nf_nat.h enum nf_nat_manip_type {NF_NAT_MANIP_SRC,NF_NAT_MANIP_DST }; // from include/uapi/linux/netfilter/nf_conntrack_tuple_common.h // Use #define instead of enum so we can use these in bpftrace array indices. #define IP_CT_DIR_ORIGINAL 0 #define IP_CT_DIR_REPLY 1 kprobe:nf_nat_setup_info {// nf_nat_setup_info gets called twice, once in the prerouting chain// to modify the destination (actually a no-op), and once in the output// chain to modify the source (which is what we care about).$mtype = arg2;if ($mtype != NF_NAT_MANIP_SRC) { return;}$conn = (struct nf_conn *)arg0;if ($conn->tuplehash[IP_CT_DIR_ORIGINAL].tuple.dst.protonum == IPPROTO_ICMP) { @setupConn[tid] = $conn;} } kretprobe:nf_nat_setup_info {if (@setupConn[tid] == none) { return;}$conn = (struct nf_conn *)@setupConn[tid];$origTuple = $conn->tuplehash[IP_CT_DIR_ORIGINAL].tuple;$replyTuple = $conn->tuplehash[IP_CT_DIR_REPLY].tuple;printf(\"nf_nat_setup_info: origTuple.addr=%s, origTuple.id=%d, replyTuple.addr=%s, replyTuple.id=%d\\n\", ntop(AF_INET, $origTuple.src.u3.ip), bswap($origTuple.src.u.icmp.id), ntop(AF_INET, $replyTuple.src.u3.ip), bswap($replyTuple.src.u.icmp.id));delete(@setupConn[tid]); } kprobe:nf_nat_manip_pkt {$mtype = arg2;$skb = (struct sk_buff *)arg0;$iphdr = (struct iphdr *)$skb->data;$icmphdr = (struct icmphdr *)($skb->data + $iphdr->ihl * 4);printf(\"nf_nat_manip_pkt before: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\\n\", $mtype, ntop(AF_INET, $iphdr->saddr), ntop(AF_INET, $iphdr->daddr), bswap($icmphdr->type), bswap($icmphdr->un.echo.id));@manipType[tid] = $mtype;@manipSkb[tid] = $skb } kretprobe:nf_nat_manip_pkt {$mtype = @manipType[tid];$skb = @manipSkb[tid];$iphdr = (struct iphdr *)$skb->data;$icmphdr = (struct icmphdr *)($skb->data + $iphdr->ihl * 4);printf(\"nf_nat_manip_pkt after: mtype=%d, saddr=%s, daddr=%s, icmp.type=%d, icmp.id=%d\\n\", $mtype, ntop(AF_INET, $iphdr->saddr), ntop(AF_INET, $iphdr->daddr), bswap($icmphdr->type), bswap($icmphdr->un.echo.id));delete(@manipType[tid]);delete(@manipSkb[tid]); } The important parts are: kprobe traces when a kernel function is called, and kretprobe traces when the function returns. kretprobe cannot access function arguments directly, so store the arguments in a BPF map on entry and retrieve them on exit. For example, kprobe:nf_nat_setup_info writes the netfilter connection argument to @setupConn[tid] (a BPF map keyed by thread ID). Then kretprobe:nf_nat_setup_info reads the connection from the map and deletes the entry. struct sk_buff is how the Linux kernel represents a packet. bswap reverses byte order, which is used to convert from big endian (network byte order) to little endian. ntop returns the string representation of an IP address. The BPF program can reference kernel data structures like sk_buff and nf_conn without including any headers. This is the magic of BPF Type Format (BTF) available in recent versions of the Linux kernel. I tested this program on Linux kernel version 6.2.9. It may or may not work on other kernel versions. To execute the program, I saved the above code to a file called trace.bt then ran bpftrace trace.bt as root. This is what the output looks like with two clients pinging the server using the same ICMP ID (999): $ bpftrace trace.bt Attaching 4 probes... nf_nat_setup_info: origTuple.addr=192.168.99.1, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=999 nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999 nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=999 nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=999 nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.1, icmp.type=0, icmp.id=999 nf_nat_setup_info: origTuple.addr=192.168.99.2, origTuple.id=999, replyTuple.addr=10.0.100.2, replyTuple.id=32809 nf_nat_manip_pkt before: mtype=0, saddr=192.168.99.2, daddr=10.0.100.2, icmp.type=8, icmp.id=999 nf_nat_manip_pkt after: mtype=0, saddr=10.0.100.1, daddr=10.0.100.2, icmp.type=8, icmp.id=32809 nf_nat_manip_pkt before: mtype=1, saddr=10.0.100.2, daddr=10.0.100.1, icmp.type=0, icmp.id=32809 nf_nat_manip_pkt after: mtype=1, saddr=10.0.100.2, daddr=192.168.99.2, icmp.type=0, icmp.id=999 The output shows that nf_nat_setup_info gets called twice, once for each client.5 For the first client (IP 192.168.99.1), both the original and reply tuple have the ICMP ID sent by the client (999). For the second client (IP 192.168.99.2), however, the reply tuple has been rewritten to ID 32809. For both clients, the source IP address has been rewritten to the IP of the natbox (10.0.100.2). Once nf_nat_setup_info has created the connection, nf_nat_manip_pkt modifies the echo and echo reply ICMP packets. For the echo packet, mtype=0 (NF_NAT_MANIP_SRC) because the source IP is rewritten. Likewise, the reply packet has mtype=1 (NF_NAT_MANIP_DST) to rewrite the destination IP of the incoming reply back to the original client IP. Conclusion So that is how Linux NATs a ping! In the end, maybe the answer isn’t very surprising – and, in fact, I discovered much later that most of this behavior is documented in the Netfilter Hacking HOWTO. But it was a fun journey, and it’s nice to know exactly where this magic happens in the code. There’s a superuser question that explains how NAT works for ICMP. I guess I could have read that and moved on with my life, but I wanted to take the opportunity to dive deeper into Linux networking. ↩︎ None of these commands are persistent: rebooting the machine will clear any network namespaces, iptables rules, and interfaces. ↩︎ By default, this is the full range of IDs (0 to 65536), but it’s possible to constrain this by specifying --to-ports in the iptables MASQUERADE rule like this: iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE -p icmp --to-ports 100-200. ↩︎ For more details about bpftrace, see Brendan Gregg’s 2019 article from LWN ↩︎ I observed that if the client stops sending packets for more than 30 seconds (the default timeout: check cat /proc/sys/net/netfilter/nf_conntrack_icmp_timeout), then nf_nat_setup_info gets called again the next time the client pings, presumably because netfilter garbage collects connections after the timeout. I wasn’t able to trace exactly where the garbage collection happens, but I’d guess it’s part of gc_worker in nf_conntrack_core.c. ↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=37455621",
    "commentBody": "How does Linux NAT a ping?Hacker NewspastloginHow does Linux NAT a ping? (devnonsense.com) 295 points by willdaly 20 hours ago| hidepastfavorite82 comments voxic11 15 hours agoYou might be interested in https:&#x2F;&#x2F;samy.pl&#x2F;pwnat&#x2F; Specifically, when the server starts up, it begins sending fixed ICMP echo request packets to the fixed address 3.3.3.3. We expect that these packets won&#x27;t be returned. Now, 3.3.3.3 is *not* a host we have any access to, nor will we end up spoofing it. Instead, when a client wants to connect, the client (which knows the server IP address) sends an ICMP Time Exceeded packet to the server. The ICMP packet includes the \"original\" fixed packet that the server was sending to 3.3.3.3. The packet is INSIDE the computer. This harcoded packet is built into pwnat and acts as an identifier for pwnat. Why? Well, the client is pretending to be a hop on the Internet, politely telling the server that its original \"ICMP echo request\" packet couldn&#x27;t be delivered. Your NAT, being the gapingly open device it is, is nice enough to notice that the packet *inside* the ICMP time exceeded packet matches the packet the server sent out. Your NAT then forwards the ICMP time exceeded back to the server behind the NAT, *including* the full IP header from the client, thus allowing the server to know what the client IP address is! reply tambourine_man 7 hours agoparentpwnat seems really interesting and potentially easier than my SSH tunnels. Thanks for the link reply Beinglis23 17 hours agoprevWhen a ping is sent from a device on a local network to a device on the internet, the router performing NAT rewrites the source address of the ping to its public IP address and rewrites the ID field of the ICMP packet to a unique value. When the response is received, the router uses the unique ID value to forward the response to the correct device on the local network. reply baq 17 hours agoparentTaking this thought just a tiny bit further, this is changing a stateless protocol to a stateful one. reply slt2021 14 hours agorootparentNAT stands for Network Address Translation, which means a NAT device maintains a translation table of internal IPs to external, so that it can return response packets coming from Internet to a proper destination on the internal network.By definition NAT will maintain state which is translation table. Now that table can be dynamic or static, but it doesn&#x27;t change the fact that there will be some state to maintain. reply sgjohnson 8 hours agorootparent> By definition NAT will maintain state which is translation table.Stateless NAT is also possible, but then it has to be 1:1. Which has it&#x27;s purpose, but is rarely used.A practical example would be with IPv6 if your ISP doesn&#x27;t allocate you a static prefix. Stateless NAT would allow you to use a &#x2F;64 from the private range of fd00::&#x2F;8 in your local network which the router would translate to your globally unique &#x2F;64. No state needed, because there would be as many IPs available in your LAN prefix as in your GUA prefix. All it would do would be translating fdxx:xxxx:xxxx:xxxx:1234:1234:1234:1234 to 2yyy:yyyy:yyyy:yyyy:1234:1234:1234:1234 and vice versa.I&#x27;ve also done stateless NAT on IPv4. When you request more IPs from some cloud providers, they assign you a bunch of &#x2F;32s, not a proper subnet, virtually requiring you to run a cloud router. reply littlecranky67 16 hours agorootparentprevIs or was a thing with NAT. Linux also comes with stateful modules (ip_conntrack*) to track and rewrite higher level protocols, such as FTP control connections. reply mannyv 11 hours agorootparentprevYou&#x27;re confusing tracking the packets with protocol. It&#x27;s not changing ICMP, it&#x27;s tracking ICMP packets. That&#x27;s a totally different thing. reply starfallg 15 hours agorootparentprevAny NAT that is not statically mapping IP addresses or ports 1-to-1 will require connections to be tracked and hence makes it stateful on the side after the translation (usually outside).Hence you do need state syncing between firewalls in order for NAT connections to failover correctly, unless it&#x27;s a statically mapped, one-on-one, one range onto another range, for example. reply devman0 15 hours agorootparentThis isn&#x27;t really specific to NAT either, connection tracking is required for most firewalls as well even if NAT isn&#x27;t in play just to implement the most basic ALLOW related,estabalished rule even, and especially, what would normally be connectionless protocols. reply starfallg 13 hours agorootparentYes, tracking the state of connections (e.g. TCP) is needed enforce rules on OSI layers 4 - 7. That&#x27;s kinda the typically scenario when we think of connection tracking and stateful enforcement of rules.I was just pointing out when NAT also requires connection tracking (i.e. when the NAT table needs to be built dynamically, as opposed to statically mapped). reply lokar 10 hours agoparentprevPing needs that bit if state itself anyway to match replies to requests. reply justsomehnguy 13 hours agoparentprevOr thinking about the proper way: how an operating system distinguish between two different ICMP &#x27;talks&#x27; to the same destination.Bam, you only need one computer and wireshark&#x2F;tcpdump.Sure, the article is nice and probably is enlightening for someone who never even thought about and doesn&#x27;t have any networking understanding... honestly it&#x27;s more about how to make a proper network lab and dig the sources but without thinking. reply p1esk 13 hours agoparentprevWhy not use the source private IP instead of the “unique value”? reply accrual 10 hours agorootparentOne reason would be to not expose details about your private network to every hop the ICMP packet traverses. Even if knowing you have some 192.168.1.x host is not on its own very useful to an attacker, it&#x27;d be preferable to not expose that.It&#x27;s another reason WebRTC&#x2F;STUN was a big issue when it first became widely available, it made it easy to leak details about your LAN to outside servers. reply rfmoz 12 hours agoparentprevBut the ID is on the ICMP header or it belongs to the IP part? reply nanmu42 18 hours agoprevGood post.Coincidently, I was struggling with Netfilter this weekend to enable transparent proxy on my OpenWRT router.For the curious, the go-to resources for Netfilter are:1. https:&#x2F;&#x2F;wiki.nftables.org&#x2F;wiki-nftables&#x2F;index.php&#x2F;Main_Page2. https:&#x2F;&#x2F;www.netfilter.org&#x2F;projects&#x2F;nftables&#x2F;manpage.html reply viopq 18 hours agoprevIt&#x27;s refreshing to see a \"how does\" which actually drills down through layers of abstraction all the way to the source code. Nicely explained and very informative! reply peter_l_downs 17 hours agoparentI came here to write this. Routing and networking is still confusing for me and all the writing about it is usually very \"abstract\" to me. A hands-on example like this one is really appreciated. Nice work, OP. I&#x27;ll try to do it myself and follow along.EDIT: one of the only other posts about this stuff that has made much sense to me is this one from Tailscale. It contains lots of \"worked out examples\" that really make it clear how everything fits together.https:&#x2F;&#x2F;tailscale.com&#x2F;blog&#x2F;how-nat-traversal-works&#x2F; reply mindslight 17 hours agorootparentIME if you&#x27;re digging into the finer points of netfilter, you eventually run up against the limits of published documentation and have to dig into the source code to figure some things out. reply kazinator 18 hours agoprevSince there is no port in ICMP, NAT doesn&#x27;t have to deal with the problem of sending the ICMP echo reply back to the correct port.ICMP echo requests have an ID, and that&#x27;s effectively the same as a source port number.Correct NAT handling of ICMP echo has to remap the ID in both directions, the same way that correct handling of UDP remaps the source port.Reason being, if the machine behind NAT is being pinged at the same time by two different hosts, and they happen to use the same request numbers, then it is ambiguous.Another possibility is not to rewrite the identifiers, but keep a list of remote machines associated with each ID. When there is a clashing ID, the list contains two or more entries (remote IP addresses). So then, when a reply is received from the machine behind the NAT gateway, the NAT chooses one of the entries in the list (say, the least recently added one) and sends the reply to that machine. Then removes the entry. reply jjoonathan 18 hours agoprevNAT is such a trashy abstraction. IPv4 needs to die. reply midasuni 18 hours agoparentI have a few devices on my home internet, on a handful of 192.168 subnetsThe other week I moved my ISP. The AS my house belonged to obviously changed to the new ISP, and I got a new v4 IPAll I had to do was update my Wan router to forward trafffic from the new Ip.Instead with ipv6 I would have to change every node on my network, update my internal DNS.Now in theory I could have my own &#x2F;48 which I take with me. That relies on my new ISP being willing to advertise it (which my current one does) but it’s not particularly common.However a week ago my phone line was cut. I got a 5g mifi out and moved my wan connectivity through that until the cable was fixed. Again a nice simple masquerade on that interface and all was good (well not that good - very poor signal where I live)But the elephant in the room is of course all that ipv6 stuff aside, I still need to run a dual stack (or use trashy nat abstractions). It increases my work for no benefit.But taking about work, how about there?I have a fleet of vehicles on internal 172.16&#x2F;12 subnets, they plug together and route to each other, and route from where they are via a variety of vpn connectivity (hoping that at least one method will work, as there’s rarely a signal in the basements these park)If I moved them to ipv6 then again I’m back to having to move my &#x2F;48s. Except these vehicles get internet from various sporting venues - most of which struggle to turn off MITM&#x2F;443 or unblock UDP, that’s just not going to work in a world where they turn up at 10am Saturday morning and need to be working 2 hours later.What business benefit is there for me to double the workload and double the risk by moving to dual stack? reply jandrese 15 hours agorootparentWith IPv6 you would do stateless autoconfigurarion, so there would be no manually setting of your addresses. The router would advertise the new prefix and everything would just use it.There would be no DNS configuration at all, all local machines would use anycast DNS for the services and a well known server for Internet addresses.One of the primary goals of IPv6 was to avoid needing manual configuration if anything on the network. It is supposed to be as automated as possible. reply 3np 14 hours agorootparent> There would be no DNS configuration at all, all local machines would use anycast DNS for the services and a well known server for Internet addresses.Assumptions and dragons be here. reply midasuni 11 hours agorootparentMDNS, specifically designed for use on a single vlan, so useless reply dfox 10 hours agorootparentThe solution there is DDNS, which is one of the things behind MS AD and just works, and configuring that on pure Unix infrastructure is surprisingly easy. reply midasuni 11 hours agorootparentprevAnd now I can’t find anything because mdns doesn’t work, half my kit won’t take dns entries, more fragility from systems which don’t exist, or and of course all my open sessions on local networks break as ip addresses change, not to mention all my WireGuard sessions. reply noinsight 16 hours agorootparentprevYou could be using IPv6 ULA addresses internally on your home network to have static addressing. The real solution is moving to DNS names though with your router maintaining them based on DHCP leases or just using multicast DNS (Zeroconf).In the future you can probably go \"IPv6-mostly\" with a CLAT engine to ditch dual-stack: https:&#x2F;&#x2F;blog.apnic.net&#x2F;2022&#x2F;11&#x2F;21&#x2F;deploying-ipv6-mostly-acce... reply dmatech 16 hours agorootparentYou could, but now you have three addresses per node instead of one. Plus, the mechanisms for assigning those addresses are weird compared to DHCP and static assignment. I get that it facilitates packets being routed reliably, but some of us want maintainable firewall rules that don&#x27;t have to deal with IP addresses changing out of the blue. reply qhwudbebd 15 hours agorootparentprev> In the future you can probably go \"IPv6-mostly\" with a CLAT engine...although there still isn&#x27;t any kernel support for the necessary SIIT v4v6 translation, so to implement CLAT you end up using unmaintained (and unmergeably bad) out-of-tree kernel modules or unmaintained (and slow) userspace daemons hanging off a tuntap interface. reply dgl 9 hours agorootparentpf on OpenBSD does it fine. reply qalmakka 8 hours agorootparentprevIn IPv6 you&#x27;d do exactly like you&#x27;d do with IPv4, by assigning ULAs (private, local addresses) to your machines from fc00::&#x2F;7.With the (IMHO) big advantage that unless some madman has configured NAT66, the traffic over ULA will *never* get out into the internet.The fact you have GUAs allocated doesn&#x27;t mean you have to necessarily use them for your internal traffic. Most of the time link local addresses (on small scale, with auto discovery via LLMNR or mDNS) or ULAs are way more convenient than GUAs or IPv4 local addresses. reply pixl97 17 hours agorootparentprevI do believe there is some kind of 1:1 NAT with IPv6 these days, which is way better than 1:Many of IPv4. There are so many potentially useful applications that are DOA because of v4 NAT being everywhere. reply midasuni 11 hours agorootparentThose applications are DOA because of firewall administrators that barely allow tcp&#x2F;443 through. reply littlecranky67 15 hours agoparentprevNot sure IPv6 will fix this. Technically, yes it does. But major providers only assigning a &#x2F;64 to a home user (and charging hefty fees for \"buisness use\" &#x2F;48) already leads to IPv6 NAT or segmenting the &#x2F;64 further - which shoulnt be done. reply mike_hock 49 minutes agorootparentWhy would anyone need &#x2F;64 if not to segment it further. reply lazide 11 hours agorootparentprevMost seem to have stopped and are handing out &#x2F;48’s in my experience. Do you know any not doing that still? reply trustingtrust 18 hours agoparentprevYou&#x27;ll hate CG-NAT even more then. reply i80and 18 hours agorootparentThe first time I encountered CGNAT was such a rude shock. I don&#x27;t think it should be legal to market it as \"internet\" to consumers reply sgt 3 hours agorootparentIf your ISP gives you CGNAT, then the best thing you can do is to request a static public IP address. Will probably cost a little bit more but well worth it. reply lorenzo95 18 hours agorootparentprevheh ... It&#x27;s all IPv6 ULA here with Nat66 reply commandersaki 5 hours agoparentprevYou mean the unsung hero of the Internet. reply riffic 16 hours agoparentprevbe mindful of the Lindy effect, an observation on the future longevity of non-perishable things like technology or an idea being proportional to their current age, ipv4 due to its age will likely be around for quite some time to come.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lindy_effect reply backendanon 7 hours agoparentprevIPv6 needs to die. IPv4 using NAT ensures a moderately high level of privacy. IPv6 with privacy extensions does not. reply kazinator 18 hours agoparentprevYou need NAT (or something else that is worse in some respects, like port forwarding) in any situation in which your subnet is given only one address upstream, even if it is an IPv6 address. reply xxpor 18 hours agorootparentIf your ISP doesn&#x27;t do PD with v6, their implementation sucks. Even my crappy 6rd setup from CenturyLink gives me iirc an entire &#x2F;48. reply midasuni 17 hours agorootparentMany ISPs suck. That’s not controversial.We have to deal with the world we live in, not the world we’d like. reply pantalaimon 17 hours agorootparentThat&#x27;s why variable length SLAAC has been proposedhttps:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;draft-mishra-6man-variable-... reply growse 17 hours agorootparentprev> Many ISPs suck. That’s not controversial.> We have to deal with the world we live in, not the world we’d like.No we don&#x27;t. Some choose to just put up with shittiness, others enact change. reply toast0 16 hours agorootparentPriorities. I don&#x27;t have to put up with PPPoE in 2023, but it&#x27;s a hell of a lot less expensive than pulling munifiber to my garage (and the monthly fees for munifiber are higher too, so there&#x27;s no point in time where it makes economic sense), and consistency and stable addressing is currently winning over the promise of 5g&#x2F;leo satellite. reply growse 15 hours agorootparentSure, but you&#x27;re choosing that prioritisation. It&#x27;s not being forced on you. reply taway1237 8 hours agorootparentI&#x27;m not even sure if you and GP agree or disagree.As for me, I want IPv4 to stay forever. It works for me and I don&#x27;t see any reason to spend time and migrate to something else. reply kazinator 17 hours agorootparentprevOP here.Your \"ISP\" is a sysadmin at work who gives you one address to your cube.You otherwise like the work and the team, and the compensation is fine.Now what? reply growse 15 hours agorootparent> Now what?You advocate for change. You make the case.You might not win the battle, but you&#x27;re by no means forced to accept the status quo. The more who fight the battle, the more win. The more win, the faster progress, which benefits us all. reply kazinator 13 hours agorootparentI set up NAT, I move on.If you can solve a problem technically, without involving people, that is best. replypaulddraper 15 hours agorootparentprevYeah, but there&#x27;s no reason to do that with IPv6 reply jaimex2 11 hours agoparentprevIPv6 needs to die also. It had more than enough time to become dominant and has just floundered. reply sgjohnson 8 hours agorootparenthttps:&#x2F;&#x2F;www.google.com&#x2F;intl&#x2F;en&#x2F;ipv6&#x2F;statistics.html 45% (and growing) of all traffic to Google is IPv6. Hardly \"floundered\". It&#x27;s just that most major ISPs in the developed world have so many IPv4 addresses they don&#x27;t care that much about IPv6 yet.Now, try starting a new ISP without CGNAT (which will lead to a garbage experience for everyone) or IPv6. You&#x27;ll have to spend literal tens (if not hundreds) of millions just on IP addresses alone. reply commandersaki 5 hours agorootparent25 years and we&#x27;ve only got 45% We should&#x27;ve been at 95% decades earlier if they came up with an actual transition plan. reply mindslight 17 hours agoparentprevIs there a better way to not unnecessarily leak addressing metadata to adversarial remote nodes and middle boxes?IPv6 with assigning end users a whole &#x2F;64 and end-devices continually churning through privacy addresses is a start. But even then some form of NAT is still required to nimbly use source prefixes from different horizon providers - eg to avoid spilling your geographic location or opening yourself up to low-effort legal shakedowns.An example: on my local network I&#x27;ve got an everyday web browsing VM and a torrent VM. They each have static 192.168.x.x addresses, both so I can ssh in for administration and also to control their view of network services. They each see a completely different Internet horizon through the router - the web browsing goes out from a rotating datacenter IP, and the torrent one goes out from a consumer VPN. Each of those outgoing horizons uses NAT - any of my hosts using that rotating data center IP appears the same, and any of my host using the consumer VPN appears the same as every other customer using that same VPN node.What is the no-NAT equivalent of this? Make that rotating data center IP and VPN external IP into subnet allocations, somehow feed that addressing information back to the hosts that are using it, and dual-home each VM with two routable addresses? For equivalent mixing on the consumer VPN there would also need to be some ARP-like protocol that let me continually rotate the address. reply 3np 14 hours agorootparent> What is the no-NAT equivalent of this?At least for web-browsing and other HTTP&#x2F;TCP use-cases: Cut off internet from your hosts and use centralized local proxies for all outgoing connections. Presumably you already have reverse proxies in place for the incoming. There is no need for NAT if all the traffic is taken care of in higher layers. This reduces your consideration to the internet-facing forward- and reverse-proxies only.Sounds like you already have bittorrent figured out via VPN (Wireguard I guess? Well there we have one more UDP exit-point to consider).BTW, I largely agree with your sentiment: Benefit of (especially migrating to) IPv6&#x2F;DS for individual networks is often unclear or questionable and metadata privacy is a valid consideration where I believe correct solutions are not readily available and understood even by your well-intentioned and seasoned senior admins. Maybe globally the number of people who will get this right ranges in the 1000s? 10,000s if we&#x27;re lucky? How many networks do we need to migrate again for \"IPv4 to die\"?I guess the only way forward is for more people to do that migration and share their findings and solutions, though ;) reply mindslight 12 hours agorootparentThe general ignorance of the privacy benefits of NAT are what I&#x27;m reacting against too. It&#x27;s certainly regrettable that end users are forced into NAT [0], but since then a shameless surveillance industry has cropped up, looking to exploit every bit of identifying information that it can. And it seems that calls for native IPv6 with everything having its own distinct address generally just ignore the practical privacy implications.It certainly seems possible to get a NAT-equivalent privacy from properly set up SLAAC. Although a sibling comment says that the proposal for variable length prefixes was just submitted this year?!? Equivalent privacy would also require things like consumer VPN providers allowing you to request a few new addresses every few minutes, whereas NAT makes a shared uniform distribution the default.Using a proxy instead of NAT is a good point, although there are certainly reasons I moved towards managing egress flows at the packet level with VMs rather than configuring software to play nice with proxies. And spiritually I would say that a proxy is an even more heavyweight version of NAT one layer up.[0] Although I don&#x27;t personally think the web would have developed any less centralized without NAT as many people like to imagine reply jandrese 15 hours agorootparentprevWhy not just use a VPN in both cases? That’s more or less what your NAT solution is doing, except without the encryption to the data center. reply mindslight 15 hours agorootparentIt is a wireguard tunnel to the data center, but my comment was focused on the addressing. reply cobertos 10 hours agoprevIt annoys me when I write blog posts like this, it&#x27;s so hard to link to a specific line of code and have that link stay alive and useful&#x2F;fresh over time.I guess if it&#x27;s GitHub, you can tie it to a specific commit hash, file name, line number tuple, but if the codebase ever changes a lot its not super useful. I&#x27;ve also not had luck with other, less used git webviews (git.blender.org) reply xxpor 10 hours agoparentFor linux kernel code, you can use elixir, so it&#x27;ll at least be linked to a specific version. You can use an LTS version if you want the code to have at least some staying power.https:&#x2F;&#x2F;elixir.bootlin.com&#x2F;linux&#x2F;latest&#x2F;source reply zackmorris 16 hours agoprevI wonder if ping could be abused to send short messages for p2p networking over UDP without a central server to handle NAT busting. Looks like someone figured the message part out:https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;31857419&#x2F;how-to-send-a-m...Unfortunately ping is handled by the OS so apps on the peer IPs wouldn&#x27;t be able to read the messages.I wonder if it&#x27;s time to provide hooks to some of these services in user space to make true p2p under double-ended NAT possible. At least a readonly event stream or something. It just feels like the barriers preventing that are entirely artificial now. reply freedomben 16 hours agoparentMinor technical correction, but ping is ICMP rather than UDP.But I have seen data exfiltration strategies and other communication that uses ping! Nowadays I think it would be nearly impossible for p2p because most firewall default configs will silently drop all ICMP, including pings. reply jandrese 15 hours agorootparentNote that blanket dropping of ICMP will break Path MTU Discovery (PMTUD) so you had better not be tunneling or encapsulating TCP traffic. reply zinekeller 15 hours agorootparentActually, ICMP-based PMTUD is almost dead in IPv4 due to this exact problem (since ICMP isn&#x27;t a \"protected\" protocol which is required for IPv4 connectivity), most actual services tend to do the MTU discovery purely using UDP or even using TCP (https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc4821) reply dfox 11 hours agorootparentThat is essentially an reaction to random middleboxes just plainly droping ICMP traffic. If you want to stuff to work you do not want to just drop ICMP. The sane policy is to just pass it through or maybe rate limit it. reply lazide 15 hours agorootparentprevNod, I remember it not being as effective&#x2F;easy to hide as exfiltration over UDP&#x2F;DNS too, as there was always less background noise to hide in. That said, I found this with a quick search - https:&#x2F;&#x2F;github.com&#x2F;utoni&#x2F;ptunnel-ng for those who still want to do it. A number of hotels and captive portals still let pings through relatively unmolested even if they play tricks with UDP&#x2F;TCP.Any significant data over ICMP will always stick out though if anyone is doing analysis. Which isn’t often, frankly, in situations like I described, but… reply oasisaimlessly 12 hours agoparentprevIt exists: https:&#x2F;&#x2F;samy.pl&#x2F;pwnat&#x2F;(from top comment) reply Bluecobra 16 hours agoparentprevAs IPv6 gains more and more adoption this should become less as an issue if everyone has a publicly routable IP and can avoid NAT altogether. reply mindslight 15 hours agoparentprevInteresting idea. It would seem that &#x27;id&#x27; is effectively equivalent of (sport, dport), but 16 bits is a much smaller space than 32.But isn&#x27;t the main problem with NAT punching that it requires activity on both ends to create a connection? Thus it always requires a coordination server to let node T (target) that node S (source) is trying to talk to it.You&#x27;ve got me thinking though. I wonder if there is a way to do this with ICMP routing messages - unreachable, TTL expired, etc. You can traceroute to some IP address, and get back packets from other arbitrary IP addresses, and this generally works through NAT. I&#x27;m envisioning a host T that wanted incoming connections to pick a random \"dummy\" IP address , publish (router IP, dummy IP) as its identity, and periodically send packets to the dummy IP address. Now a host S that wants to talk to T might be able to send an ICMP TTL-expired to T&#x27;s router, pertaining to the dummy address. The router should see this and forward the packet to T.Of course this is contingent upon if IP addresses in ICMP fields are ingress policed the way the addresses in the IP header have become.(edit: hah. There is now a top-level comment pointing to an implementation of this idea) reply riffic 16 hours agoparentprevping is icmp not udp reply throwawaymaths 16 hours agorootparentIt&#x27;s super confusing because you can use udp to read icmp packets (but not send, iirc), and i might be wrong, but i remember seeing tuts that did this!! reply throwawaymaths 15 hours agorootparentGetting downvoted, so:https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;13087097&#x2F;how-to-get-icmp...Using a udp socket is the \"classic\" way of implementing ping on low privilege syystems reply dgl 11 hours agorootparent“udp” in this context means unprivileged data gram, not UDP the protocol. For some reason go uses the confusing “udp” name in parts of its API. The docs for this kind of socket seem to only exist on the kernel commit: https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;420800&#x2F; reply yencabulator 13 hours agorootparentprevYou can kindly ask the kernel networking stack to inform you of errors, but that is not the same as \"using udp to read icmp packets\". replythrowawaymaths 17 hours agoprev [–] Tl;Dr (but do read it, it&#x27;s very good): there&#x27;s an id field in the icmp packet and netfilter is aware of icmp packets? Frames? as a \"special case\". replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The writer has undertaken experiments to understand how Network Address Translation (NAT) functions with regards to ICMP packets in a Linux environment.",
      "They've delved into the structure and mechanics of ICMP echo and echo reply messages, along with the implementation of the 'ping' command and the randomness of its ICMP identifier selection.",
      "Utilizing a tool called 'bpftrace' for tracing kernel functions, the author observed and confirmed modification in the source and destination IP addresses in ICMP packets due to the NAT process."
    ],
    "commentSummary": [
      "The articles explore a range of topics related to Network Address Translation (NAT), IPv6, and the use of ping for peer-to-peer networking, including how Linux deals with NAT and pinging.",
      "The advantages, challenges, and restrictions of existing NAT and IPv6 configurations, as well as potential solutions for improving peer-to-peer communication, are discussed.",
      "While there seems to be a variety of viewpoints and concerns regarding these technologies and their implementation, the articles aim to provide a comprehensive view of the topic."
    ],
    "points": 295,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1694352505
  },
  {
    "id": 37454766,
    "title": "I wired up my bike's GPS to order me pizza during a gravel race",
    "originLink": "https://steele.blue/geofence-pizza-ordering/",
    "originBody": "Matt Steele I wired up my bike's GPS to order me pizza during a gravel race 🍕 10 Sep 2023 As harvest season begins here in the Midwest, I once again celebrate by grinding Nebraska gravel at the Gravel Worlds Long Voyage bike race. As in previous years (2021) (2022), I spent more time writing code for a marginally-useful project than I did training. But hey, I finished! Fueled by Pizza My goal this year involved optimizing my food choices during the race: pizza from Casey's General Store. These convenience stores are S-Tier options when out in the middle of nowhere. In addition to snacks and drinks, most Casey's have a kitchen, and have pretty decent grab 'n go slices of pizza. My problem: last year, there were so many faster riders ahead of me, that all the pizza was taken by the time I made it to the stops. This is an outrage! This year, I knew I had to do better. But with time winding down on improving my fitness, I had to resort to the latent superpower of software hackery. My thought: why not have a fresh pizza ordered ahead of time, scheduled precisely for when I arrived? More precisely, I could write a script that ordered a pizza for me, GPS-triggered by my bike leaving a geofence about an hour from the stop. Building this on top of the serverless GPS tracker I made last year should fit into the architecture pretty well. Casey's Pizza API When The overall design: I setup a geofence within the AWS Location service, which was monitoring my GPS tracker. When my tracker exited the geofence, it would trigger a Lambda function that calculates an ETA for my next stop, and orders the pizza. The problem: Casey's doesn't have a public API for online ordering. So I had to resort to alternate approaches. More specifically, I fell back to screen scraping the website, everyone's favorite hack. I've had to screen-scrape for other projects (such as updating privacy on Strava activities), but since Casey's website was a complex React app that rendered everything on the client, I had to use a more powerful scraper; this time powered by Playwright. Getting Playwright to run in a Lambda was An Experience. Full writeup here. To keep track of the status, I also setup a push notification to be delivered to my phone (and watch) on a success or failure. Configuring Web Push to work on iOS devices is probably worthy of its own post. Pizza False Positive I had the triggering geofence configured around mile 180 of the race, with the pizza setup to be delivered at mile 200. As I left the geofence, I got a push notification on my watch saying that the pizza had been successfully ordered. But when I made it to the stop, there was nothing at the counter, and they had no record of an order. And sure enough, I checked my account, and no order had been placed. False positive. There were a few pre-made slices available, so I picked those up. They left a bitter taste in my mouth, not just because they weren't especially fresh. Through the rest of the 300-mile race, all I could think about was what might have went wrong with my function. After finishing the race, I made it to a computer and quickly checked the logs to see what had gone wrong. But to my chagrin, there was nothing in the logs indicating what caused the failure; it was just a silent success. I had nothing to go on to try and debug. A few days later, I enhanced the Lambda to capture a video of the browser in action and upload it to an S3 bucket for analysis. Running a test of the updated behavior, it finally worked. I picked up a fresh Hawaiian pizza, and we enjoyed the pie from the comfort of our home. I'm still not entirely sure why it worked. My going theory is that the Lambda had terminated processing as soon as the final form.submit() went through in the embedded Playwright browser. It's quite possible that the online ordering website saw that the browser never received a Success response, and didn't fully process the order. My guess is that the additional time spent processing and uploading the video gave the browser sufficient time to clean up properly, with serendipity in timing. Pizza Lessons While I was bummed the pizza ordering functionality didn't run, I think it's in a good spot to try again in upcoming races. I also learned a lot while building this out: Consistently screen-scraping a React client-side app with a browser running in the cloud: possible, but boy howdy is it finicky. If I were to redo project, I may opt for reverse engineering one of their native apps, focusing on triggering their APIs directly Having a good workflow to simulate geospatial behavior is necessary. At first, I setup a geofence around my house for testing, but having to leave for a walk at 11pm gets pretty old, pretty fast That said, don't skimp on real-world testing. Prior to the race, I was mostly testing the function by running it on my local workstation, not in a Lambda. The successes of the local functions gave me false confidence that everything was working as expected If you're worried about running out of Casey's pizza during a gravel race, another option is to just let the groups ahead of you get more than 30 minutes ahead, so they have plenty of time to make more slices The code is available on GitHub: https://github.com/mattdsteele/spot-tracker-tracker/tree/main/pizza-function",
    "commentLink": "https://news.ycombinator.com/item?id=37454766",
    "commentBody": "I wired up my bike&#x27;s GPS to order me pizza during a gravel raceHacker NewspastloginI wired up my bike&#x27;s GPS to order me pizza during a gravel race (steele.blue) 291 points by nxten 22 hours ago| hidepastfavorite89 comments mhb 21 hours agoColin will make you a pizza while he&#x27;s delivering it: https:&#x2F;&#x2F;youtu.be&#x2F;YjyJRTM0knE?si=fes2lbRntUlciPSH reply rafram 19 hours agoparentYou laugh, but the concept of this funny YouTube video was the actual business model of a SoftBank-backed startup that raised half a billion dollars [1]. The crucial flaw in their otherwise ironclad plan was that the pizza had a tendency to fly around and lose all its toppings when the truck went over a bump in the road.[1]: https:&#x2F;&#x2F;gizmodo.com&#x2F;zume-softbank-ai-pizza-delivery-stellar-... reply siva7 17 hours agorootparentI&#x27;m pretty sure that was a money-laundering scheme disguised as some silicon valley-esque startup to not trigger alarm bells with institutions reply cultofmetatron 15 hours agorootparent> I&#x27;m pretty sure that was a money-laundering scheme disguised as some silicon valley-esque startupconsidering some of the half baked shenanigans I&#x27;ve seen conducted in SF that actually raised funding back when I was there. this would explain a LOT... reply smabie 15 hours agorootparentprevI&#x27;m pretty sure it was not: there&#x27;s much more effective ways to launder money than a high profile startup reply siva7 15 hours agorootparentThat would be a perfect cover up considering it’s not that unheard of with their investor: https:&#x2F;&#x2F;www.theinformation.com&#x2F;briefings&#x2F;c4d82a reply notatoad 8 hours agorootparentprevisn&#x27;t all of softbank a money-laundering scheme? it&#x27;s just kingdom of saud buying influence in the west. reply sneak 7 hours agorootparentYour second sentence contradicts your first. reply ParanoidShroom 15 hours agorootparentprevI don&#x27;t see how one would do that. Mind expanding? You won&#x27;t turn out dividends and salary sounds highly taxed reply FanaHOVA 15 hours agorootparentprevIt&#x27;s really not that deep reply arlort 15 hours agorootparentprevThat&#x27;s fun, this was also the premise of a Donald Duck story in the italian mickey mouse weeklyhttps:&#x2F;&#x2F;inducks.org&#x2F;story.php?c=I+TL+2629-3&search=paperino%... reply asimpleusecase 15 hours agorootparentprevShould have pivoted to calzones. reply lostlogin 15 hours agorootparentprevThey need that tech tanks use to keep their gun level, that multi axis gyroscope thing. This is the sort of tech crossover that could make military spending more acceptable. reply mschuster91 10 hours agorootparentTo illustrate just how capable that tech was even back in 1986, look at 1:45 of this Bundeswehr video demonstrating a Leopard tank carry a keg of beer and not lose a drop: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=K2mcO6l-0cY reply dronodeath 7 hours agorootparentIt’s actually a stein of beer, carried on the end of the barrel of the tank’s main gun, for others that like me did not understand. It’s cool. reply HWR_14 11 hours agorootparentprevHis cellphone uses GPS and connects to other computers over the internet using TCP&#x2F;IP, but I guess you&#x27;re waiting on pizza gyroscopes to see any valuable tech crossover relative to this project. reply gregoryl 11 hours agorootparentImagine the things achieved if the money being spent wasn&#x27;t focused on military applications. reply HWR_14 6 hours agorootparentI imagine military applications for \"know where something is in world\" and \"have network of computers communicate in a damage resistant way\" are no more costly to develop than non-military applications. reply bipop5000 17 hours agorootparentprevSeems like it would have been a better option to do the final cooking which is around 7-8 min in the oven at the delivery doorstep. reply p1necone 8 hours agorootparentNeapolitan pizza needs to cook for like 3 minutes tops, but getting an oven hot enough for that on the back of a truck would probably be a challenge. reply kbutler 16 hours agorootparentprevSeems like you could install pretty good motion isolation systems in the trucks with that kind of money... reply heavyset_go 12 hours agorootparentprevHere&#x27;s the thread that debuted this on HN in 2016 titled \"Zume, a new startup trying to make a more profitable pizza through robotics\"[1].[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=11980694 reply mortureb 15 hours agorootparentprevShould have had the oven on shock absorbers. reply heavenlyblue 19 hours agorootparentprevThey didn&#x27;t raise half a billion dollars, they were valued at half a billion. reply d3vmax 18 hours agorootparentFrom the article:&#x2F;&#x2F;&#x2F;Most notably, the company enjoyed a generous infusion from Japanese investment firm SoftBank, which injected a whopping $375 million into the startup in 2018. By the end of its lifespan, Zume had raised as much as $445 million.&#x2F;&#x2F;&#x2F;They actually nearly raised half a bil. reply rafram 18 hours agorootparentYeah, the headline’s wording implies valuation, but that’s actually the amount they raised. Who knows how they managed to spend it. That’s a lot of Bali offsites and kombucha on tap. reply franky47 21 hours agoparentprevThat&#x27;s what happens when you remove the GIL.Edit: the video was the best laugh I had on YouTube this year, thanks! reply oxguy3 6 hours agoparentprevOmg my entire Sunday evening gone. Just watched this man build a tunnel from his house to his shed for 2.5 hours. What a fun channel. reply Waterluvian 17 hours agoparentprevIs Colin’s recklessness a fake act, like Electroboom, or is he really as reckless as it seems? I’m not sure I’ve ever really figured it out, and for some reason it makes it hard for me to watch. I guess obviously they wouldn’t publish a video where something goes horribly wrong, though. reply sureglymop 15 hours agorootparentAnother one if you want to see some real recklessness is \"I did a thing\". reply gibolt 13 hours agorootparentSeconded! Here&#x27;s the channel linkhttps:&#x2F;&#x2F;youtube.com&#x2F;@Ididathing reply sublinear 17 hours agorootparentprevIt&#x27;s an act, but I wouldn&#x27;t call it fake. He has more in common with photonicinduction than electroboom. reply OrsonSmelles 14 hours agorootparentI think I&#x27;m slightly more worried that photonicinduction has actually died when he goes silent for a while, though. I know it&#x27;s mostly down to career&#x2F;relationship ups-and-downs, but there&#x27;s always a chance it&#x27;s \"got turned inside out by a flying washing machine drum\". reply wayfinder 11 hours agorootparentprevWhat’s something that Colin did that was reckless? Everything he does looks pretty run of the mill for a workshop, but cool. reply mhb 5 hours agorootparentMaybe:https:&#x2F;&#x2F;youtu.be&#x2F;soxxPyaAT1k?si=-LPT22_aPrOx9xyThttps:&#x2F;&#x2F;youtu.be&#x2F;fzMi6yf1Roc?si=v6s9QcCX5ughgnlk reply LegitShady 15 hours agorootparentprevthey&#x27;re just playing characters reply CalChris 19 hours agoprevVery nice. A 21st century take on pizzatool.https:&#x2F;&#x2F;donhopkins.medium.com&#x2F;the-story-of-sun-microsystems-...FWIW, there&#x27;s a pizza restaurant, Waypoint Pizza in Tiburon, which if you ask nicely will deliver on the water in the San Francisco Bay. This comes in handy during weird less serious sailing races like Three Bridge Fiasco. reply MuffinFlavored 10 hours agoparent> if you ask nicelyhow much does that cost if a normal pizza delivery can cost $5-$10 extra? reply CalChris 8 hours agorootparentYou&#x27;d have to call+ask. It was a thing circa 2012. It&#x27;s been awhile but the woman who ran Waypoint was a racer on the America3 team. It was more of a courtesy to other racers than an Uber Eats thing. Dunno if she&#x27;s still there or if they still do it. reply rcarr 18 hours agoprevDean Karnazes did this in an ultra running race minus the tech. He rolled the pizza up like a burrito and ran with it:https:&#x2F;&#x2F;gffmag.com&#x2F;the-raw-endurance-of-ultramarathon-man-de... reply nathancahill 14 hours agoparentEndurance running is really just eating. reply cjmcqueen 14 hours agorootparentIt&#x27;s literally the second hardest thing to do after the biking&#x2F;running&#x2F;swimming&#x2F;skiing itself. Fueling is the operational excellence challenge of endurance sports. reply MuffinFlavored 10 hours agorootparentprevhow does your body not have a hard time processing cheese&#x2F;sauce&#x2F;butter&#x2F;fat&#x2F;grease while running? reply grayclhn 9 hours agorootparentIt does. Getting your stomach good at that (and figuring out what food you can personally tolerate best) is a nontrivial part of training for longer ultramarathons. reply nhance 20 hours agoprevIf it is a react website that would imply it has an api you could just use directly. Might still need to login to get a token but that&#x27;s a lot more robust reply internetter 15 hours agoparentAgreed! I always am confused when people screen scrape instead of just monitoring and replaying network requests. Much cheaper and much more robust. Is there anything I&#x27;m missing? reply rendall 15 hours agorootparentI was curious about this myself. Perhaps the pizza request is arcane or buried in lots of other requests? reply avg_dev 21 hours agoprevi cannot tell you how much i enjoyed this article. it was very funny. it had so many great elements. a fun tech problem, pizza, getting me to look up what “s-tier” meant, a dash of humor (as if the premise wasn’t already hilarious), the mea culpa at the end and the ideas as to what the bug was (his theory sounds plausible to me, but idk). reply tesin 10 hours agoparentHm. I thoroughly disliked it - 100 layers of abstraction, glue and duct tape in the cloud to construct a rube Goldberg machine that doesn&#x27;t work. It felt like everything wrong with modern tech. reply fullspectrumdev 21 hours agoprevThis is pretty neat not gonna lie. I wonder now if something similar can be done with Deliveroo or similar - on day X if certain conditions are met (eg: working late), have preprogrammed order Y submitted when approximately Z distance from house. reply willcipriano 21 hours agoparentWire it up to a fitness tracker and only have enough pizza delivered to keep you at a calorie deficit so that you lose weight. reply netrus 16 hours agorootparentAdd enough pizza alternatives to make it a somewhat plausible diet and that&#x27;s an actually great idea - for the crowd that can afford a fully delivery-based diet. reply whywhywouldyou 18 hours agoparentprevWhy would you lie about this being pretty neat? Seems like a weird thing to clarify. reply tbrownaw 17 hours agorootparentIt&#x27;s usually spelled \"ngl\" and seems to be a stock phrase that&#x27;s used more-or-less as an opposite of \"&#x2F;s\". reply Loocid 10 hours agorootparentprevIts just an expression, dont overthink it. reply wanderingstan 20 hours agoparentprevYes, it’s seems like food ordering services should have good APIs for this—why not make it easy for people to integrate food ordering (and paying!) into IFTTT-style hacks?! reply gdprrrr 20 hours agorootparentThey might fear abuse or trolls reply tough 16 hours agorootparentAlso not being able to put ads down your throat via API reply zschuessler 21 hours agoprevI have fond memories of growing up with Casey&#x27;s pizza. I pick it up any time I am back in the Midwest.I can&#x27;t place it, but it has its own distinct charm. reply ecommerceguy 21 hours agoparentExtra grease? The breakfast pizza is the best err, usually after a night of drinking busch lights. reply weekay 19 hours agorootparenthttps:&#x2F;&#x2F;investor.caseys.com&#x2F;press-releases&#x2F;press-release-det...This might surprise some people . Pizza for breakfast . Not left over pizza from previous night reply bilekas 3 hours agoprevThere&#x27;s a great way to get motivated for the last leg of the race! reply loeg 19 hours agoprevOof, and it didn&#x27;t work. That&#x27;s pretty rough to find out at mile 200! reply stevage 11 hours agoprevI think I would either:- just call up using hands free - have a friend do the call, and message them to trigger itAlso he keeps referring to \"delivery\" but it&#x27;s actually pickup, no? reply hardware2win 21 hours agoprev>My going theory is that the Lambda had terminated processing as soon as the final form.submit()Kinda odd behaviour reply devit 17 hours agoparentThat&#x27;s because the author apparently neglected to parse the resulting page to ensure that the submission succeeded.If you terminate the system right after sending a form there is no guarantee that the data even left the local buffers for the network. reply frankthedog 16 hours agorootparentThis is the right answer. He’s immediately closing the browser after clicking the button. He should wait for a success UI or at least that the resulting network call finishes with success or a failure to retry on. Not lambdas fault, it’s performing as coded. reply _joel 19 hours agoparentprevIsn&#x27;t that the point of serverless though? reply isbvhodnvemrwvn 17 hours agorootparentIt wouldn&#x27;t have worked regardless of what they ran it on, it&#x27;s the runtime that terminates. reply marvin 11 hours agorootparentThis wasn&#x27;t obvious to me just looking at the problem from a distance, but thankfully testing reduces the level of skill required to get something right :) reply Gelob 19 hours agoprevIf they take phone orders you could just play a pre recorded messages and call them using twillo. I&#x27;ve done this in the past to call many stores and check inventory of an item reply tqkxzugoaupvwqr 17 hours agoparentHow does this work with a conversation? Did you ask them to press 1 if the item is in stock, or send you an email to a provided address? reply sahkopoyta 16 hours agorootparentYou could start the message by explaining your situation. But yeah still lots of edge cases this doesn&#x27;t catch. reply callalex 16 hours agorootparentprevTwilio has different verbs you can use to quickly and easily throw together a small voice controlled phone tree with basic conversational understanding. reply sambalbadjak 19 hours agoprevthat was a fun read! hope you get your fresh pizza next race reply perebas 14 hours agoprevLOL this guy is amazing and does amazing things. I would never think of something like that. reply throwaway413 19 hours agoprevSoftware, cycling and pizza. Some of my favorite things in life. This project and write-up was thoroughly enjoyed, and has inspired some of my own similar ideas now! Cheers reply tomglynch 12 hours agoparentHi, these are also my favourite things. OP, yourself and myself should start a club. reply weirdkid 17 hours agoprevBut… Hawaiian pizza? reply cultofmetatron 15 hours agoparentmakes sense in a weird way. if you&#x27;re running. pineapple got plenty of sugar in em which is exactly what you need when you&#x27;re running and eating at the same time. reply fullstackchris 14 hours agoprevGreat stuff! Thanks for the Playwright link and detailed Lambda blog posts, I had a similar project I was working on trying to convert text into animated (typed) code videos (on visual studio code) - trying to get anything non trivial in lambda to run is indeed an interesting endeavour to say the least! reply terminous 16 hours agoprevThe lengths people these days will go to in order to not make a phone call... reply Theodores 45 minutes agoparentExactly. Personally I like making calls whilst riding my bicycle, in part to make motorists go mad because we all know that texts, calls and such phone activity causes accidents. But, on a bike you are not going to kill anyone. reply dools 13 hours agoprev> In other words, after having wasted an ungodly amount of money trying to make pizza in the most complicated way possible, Zume decided that the best course of action was to just try selling boxes insteadStarted off as a Futurama episode, finished off as a Simpsons episode. reply thrdbndndn 20 hours agoprev [–] Sorry for being kinda off-topic, but what&#x27;s going on with these small(-ish) businesses configuring their websites to block users randomly through Cloudflare nowadays? I&#x27;ve seen this happened at least 5 times this week clicking random links, they are all local business websites.I&#x27;m talking about https:&#x2F;&#x2F;www.caseys.com in this article, which gives me Access denied Error code 1020 You do not have access to www.caseys.com. The site owner may have set restrictions that prevent you from accessing the site.\"Is this a GDPR measure (but My IP is in Japan, not EU), anti-proxy measure (I do use one), or cost-saving measure? reply foooobaba 20 hours agoparentWell, Casey’s is not actually smallish, it’s a fortune 500 company publicly traded on NASDAQ (CASY) and has a market cap of over 9 billion. reply thrdbndndn 19 hours agorootparentI guess that makes it even worse. Large companies surely want people around the world to visit their websites for brand recognition even if they don&#x27;t operate in their regions. reply weekay 20 hours agoparentprevThis really is a hard stop being applied on Cloudflare WAF rules to stop any traffic from geo locations a sys admin believes would stop threats and also reduce their bandwidth utilisation. If companies don’t have business interest outside or their territory&#x2F; country the new trend seems to be just geo block that domain. While https:&#x2F;&#x2F;investor.caseys.com&#x2F; is accessible from Europe for eg., the main site isn’t . This isn’t a GDPR thing just a playbook some of the cyber security and ops team seem to be applying across various retail companies now a days . reply evrimoztamur 20 hours agoparentprev [–] This, I believe, is the free DDoS guard that people opt into because it&#x27;s free. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Matt Steele connected his bicycle's GPS to make advance pizza orders from Casey's General Store while participating in a gravel race using a script activated when his bike exited a geofence.",
      "On his first attempt, there was a false positive failing to order the pizza. However, after enhancing the script, Matt successfully ordered a pizza after the race.",
      "Despite the challenges faced, Matt gained valuable lessons and aims to use the pizza ordering functionality in future races. The project's source code is publicly available on GitHub, an online hosting platform for software development."
    ],
    "commentSummary": [
      "The text focuses on a story about a cyclist who wired their bike's GPS to allow pizza ordering during a race, which sparked a debate about potential misuse of food ordering service APIs, such as a money-laundering scheme.",
      "It discusses the difficulties of endurance racing, particularly about fueling the body, and the IFTTT-style hacks developed by users to integrate food ordering.",
      "The article also mentions a trend of random user blocking by websites, possibly to comply with GDPR or to cut costs, with the adoption of geo-blocking by retail companies to prevent threats and reduce bandwidth usage. Cloudflare's free DDoS guard is identified as a possible reason for this trend."
    ],
    "points": 291,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1694344333
  },
  {
    "id": 37454853,
    "title": "“Make” as a static site generator (2022)",
    "originLink": "https://www.karl.berlin/static-site.html",
    "originBody": "Karl Bartel Home Projects make as a Static Site Generator Static site generators are in fashion for good reasons. The resulting pages are easy to host, fast and extremely low on maintenance while being sufficient for many use cases. As I learned when setting up my blog, writing a simple script myself is faster and more satisfying than learning one of the other site builders and customizing it to my needs. This time, I only need a plain site without automatically updated timestamps or an RSS-feed, so I can go even simpler than by blog script. Basic setup To get the site into a working state, I require the following functionality: All input files reside in the source directory, in the same layout as I want them in the output. During processing, add a header to all HTML files. Copy all other files to the build directory as they are. Each of these points results in one rule in the Makefile: # The `build` target depends on all output files in the `build` directory. It # does not do anything by itself, but causes one of the following rules to be # applied for each file. build: $(patsubst source/%,build/%,$(shell find source -type f)) # For each .html file do `cat header.html $input > $output`. build/%.html: source/%.html header.html Makefile@mkdir -p $(dir $@)cat header.html $ $@ # Copy all other files without changes. build/%: source/%cp $ $@ Generate Page From Markdown If you dislike writing HTML or if you have existing content in markdown format, you can pipe your markdown content through a markdown-to-HTML converter of you choice (I like smu). build/%.html: source/%.html header.html Makefile@mkdir -p $(dir $@)smu $ $@ Since we still assume that build/foo.html is built from source/foo.html, you should keep the .html suffix for the markdown files or modify the rules to look for .md files as input. Little Helpers You can not only modify the site generation itself. Convenience features can also be added as additional make targets. Serve Site Locally Not all sites can be accurately previewed by opening the local files in your browser. The most common reason for this is using absolute links instead of relative ones. In those cases, you will want to run a small test web server locally to preview your site. Python is already installed on many systems and comes with a web server this is suitable for the task. serve:python -m http.server -d build Rebuild on Change If you work a lot on your site, manually rebuilding after each change is a hassle. Just use entr (or inotifywait if you want to avoid the dependency) to rebuild automatically when a file in the source directory changes. watch:find source header.html Makefileentr make build Upload to GitHub Pages I store my repositories on GitHub, so using GitHub Pages to host the resulting HTML is a natural choice. Getting the commands just right so that you don't have to care about git details when publishing is a bit tricky, but easy enough in the end. The approach is based on Sangsoo Nam's post. deploy:git worktree add public_html gh-pagescp -rf build/* public_htmlcd public_html && \\ git add --all && \\ git commit -m \"Deploy to github pages\" && \\ git push origin gh-pagesgit worktree remove public_html Summary Having your own static site generator in only six simple lines in a Makefile is great! There are no exotic dependencies, nothing to maintain and you can quickly adapt it to your needs. A page I built using this approach is available at https://github.com/karlb/astridbartel.de and can serve as a real world example. Written on 2022-06-14.",
    "commentLink": "https://news.ycombinator.com/item?id=37454853",
    "commentBody": "“Make” as a static site generator (2022)Hacker Newspastlogin“Make” as a static site generator (2022) (karl.berlin) 256 points by bundie 22 hours ago| hidepastfavorite144 comments p4bl0 21 hours agoMy personal website (https:&#x2F;&#x2F;pablo.rauzy.name&#x2F;) used to be generated using a simple Makefile.Then I added features like news and an RSS feed, a way to automatically list my research publications and course materials, a list of books filterable with tags, etc. So now it still is a Makefile but the Makefile itself is a bit simpler than it used to be, but it calls a few Bash scripts that in particular make use of the awesome xml2 and 2xml utilities to be able to manipulate HTML in a line-oriented manner using the core utils (grep and sed mostly).On top of that I have a few git hooks that call make automatically when needed, in particular on the remote server where the website is hosted so that the public version is rebuilt when I push updates the repository there.It&#x27;s been working like a charm for years! My git history goes back to 2009.EDIT: I just had a look at the first commits… beccad7 (FIRST_VERSION) Initial commit d1cc6d7 adding link to Google Reader shared items 6ccfd0c fix typo d337959 adding link to Identi.ca account… 15 years have passed indeed. reply e12e 17 hours agoparent> xml2 and 2xml utilitiesSeems somewhat abandoned?https:&#x2F;&#x2F;github.com&#x2F;cryptorick&#x2F;xml2https:&#x2F;&#x2F;manpages.debian.org&#x2F;unstable&#x2F;xml2&#x2F;2xml.1.en.html reply naniwaduni 11 hours agorootparentOne of the nifty parts about having a static site generated offline from trusted inputs is that it doesn&#x27;t matter whether the generator components are \"abandoned\" or complete. reply Groxx 10 hours agorootparentEhhh... assuming their dependencies and your operating system maintain compatibility with it on the order of decades, yes. Which do exist, but they&#x27;re understandably rare.And it&#x27;s complicated by this only being knowable in retrospect, as you can&#x27;t predict the future. \"Not abandoned\" is a positive sign for \"if we failed to predict the future correctly, it&#x27;ll be fixed\", rather than mostly relying on luck.(Thankfully full-blown simulation is often an option nowadays too) reply phaer 15 minutes agorootparent> (Thankfully full-blown simulation is often an option nowadays too)Yes, and I think its fair to assume that some backend to execute the x86-64 Linux ABI will out-live most readers.Projects like https:&#x2F;&#x2F;justine.lol&#x2F;ape.html, https:&#x2F;&#x2F;guix.gnu.org&#x2F;manual&#x2F;en&#x2F;html_node&#x2F;Invoking-guix-pack.... or https:&#x2F;&#x2F;github.com&#x2F;matthewbauer&#x2F;nix-bundle do make it approachable to \"bundle\" a lot of software down to libc. reply nickstinemates 10 hours agorootparentprevTake a rootfs snapshot, have it available as a container. reply enriquto 17 hours agorootparentprevs&#x2F;abandoned&#x2F;crystalized&#x2F;g reply account42 1 hour agorootparentprevFFS not everything needs constant churn. reply tannhaeuser 16 hours agorootparentprevIf converting markup to&#x2F;from line format is your thing to put awk, perl, and other line-oriented tools to use, there&#x27;s also the ESIS format understood by traditional SGML tools and used by SGML formal test suites even. reply jez 19 hours agoprevA problem with this approach is that deleting a file from source&#x2F; does not delete it from build&#x2F;.In my own projects, simply rebuilding the whole site is fast enough, so I opt to remove the whole build folder before a rebuild:https:&#x2F;&#x2F;github.com&#x2F;jez&#x2F;jez.github.io&#x2F;blob&#x2F;source&#x2F;Makefile#L1...This defeats a big part of why you’d want a build system in the first place (incremental builds), but at least if you know the page you want to regenerate you can still `make` that file directly.If there’s a common workaround for this pattern in makefiles I’d love to learn it. reply dredmorbius 8 hours agoparentFile deletions and renames are common problems with many revision control &#x2F; build systems.Other than the nuclear option (\"make clean\"), another is to have a specific rename &#x2F; remove make target, so: make rm sourcefileor make mv sourcefile newsourcefile... which will handle the deletion and renaming of both the original and generated targets.In practice for even fairly large blog and online projects, a make clean &#x2F; make all cycle is reasonably quick (seconds, perhaps minutes), and is often called for when revising templates or other elements of the site design. If you&#x27;re operating at a scale where rebuild time is a concern, you probably want to be using an actual CMS (content management system) in which source is managed in a database and generated dynamically on client access. reply schemescape 19 hours agoparentprevNot sure if it’s a common pattern, but my solution to this was to always run a command that deletes all “unexpected” files, using GNU Make’s “shell” function to enumerate files and the “filter-out” function to filter out “expected” outputs. Edit: I ensure this runs every time using an ugly hack: running the command as part of variable expansion via the “shell” function.Edit to link my Makefile: https:&#x2F;&#x2F;github.com&#x2F;jaredkrinke&#x2F;make-blog&#x2F;blob&#x2F;main&#x2F;Makefile reply rustybolt 19 hours agoparentprev> If there’s a common workaround for this pattern in makefiles I’d love to learn it.\"make clean\"? reply dmd 19 hours agorootparentHow does that solve the problem? That forces a total rebuild, which is exactly what he said he didn&#x27;t want. reply rustybolt 18 hours agorootparentYes, I didn&#x27;t read properly.I guess you could do some magic to delete \"unexpected\" files, but are there tools which do solve this problem? reply IshKebab 18 hours agorootparentThe cleanest way to do it is essentially \"make install\". You do all the heavy build steps into a build directory, and then the final stage is to delete the \"output\" directory and copy all the files you need there. Incremental builds should still be pretty fast since the only repeated action is copying files (and you could link them if you want instead). reply Karellen 15 hours agorootparentThis is the way, because intermediate build artefacts also end up in `build&#x2F;`. You don&#x27;t want those in your `output&#x2F;` directory, but you also don&#x27;t want to delete them because they help speed up the incremental builds.Edit: `make install` also protects you against broken builds breaking your live site. reply cratermoon 18 hours agorootparentprevConventionally, install puts the outputs in their where they will live for use. It does so in a way that &#x27;make uninstall&#x27; will leave things as they were before install. The install target should also run any pre- and post-install commands. There&#x27;s also a &#x27;make dist&#x27; convention, to build a release tarball. replylinkdd 19 hours agoparentprevSomething like this should do the trick: rm&#x2F;%.html: @rm -f source&#x2F;%.html build&#x2F;%.htmlRun with: $ make rm&#x2F;page.html reply throwaway858 16 hours agoparentprevThe shake build system (a general-purpose build system similar-to&#x2F;better-than make) has a \"prune\" feature for exactly this purpose:http:&#x2F;&#x2F;neilmitchell.blogspot.com&#x2F;2015&#x2F;04&#x2F;cleaning-stale-file...But I think the best solution (that also works with make) is to have a \"make dist\" target that creates a final .tar.gz archive of the result. If the rule is written properly then it won&#x27;t contain any stale files. The disadvantage is for large project it may be slow, but you are not supposed to use this rule during development (where it is useless anyway), only for releases (which still can be built incrementally -- only the final .tar.gz needs to be created from scratch) reply bogwog 14 hours agoparentprevI think the best solution is to use something like webpack or vite or whatever. These usually have their own dev server and can watch directories for changes.My personal site is also using a custom make-like ssg, but after spending a disproportionate amount of time writing the bundling&#x2F;packaging code, I decided to just switch over to one of these tools. It’s a solved problem, and it greatly reduced the complexity of my site. reply Jhsto 19 hours agoparentprevI use Nix, so I get incremental builds and your problem goes away. reply schemescape 19 hours agorootparentYou’re using Nix to drive your static site generation? If so, please share more details because that sounds intriguing! reply Jhsto 17 hours agorootparentHere you go: https:&#x2F;&#x2F;juuso.dev&#x2F;blogPosts&#x2F;nix-as-a-static-site-generator&#x2F;n... reply schemescape 13 hours agorootparentWow, I ask and a blog post just appears!My initial reaction is: I should probably get around to learning about Flakes. I’m not sure I’d want each blog post to pin its templates, but it’s nice to have that choice. reply __MatrixMan__ 17 hours agorootparentprevI was just reading this and thinking that `nix build` would do the same trick even more nicely. reply Jhsto 17 hours agorootparentI posted a link to the other comment, but here it is for you as well: https:&#x2F;&#x2F;juuso.dev&#x2F;blogPosts&#x2F;nix-as-a-static-site-generator&#x2F;n... reply __MatrixMan__ 16 hours agorootparentI admire how nimble you are. I aspire to write blog posts at the drop of a hat like this, but I rarely do.I also like the use of flake inputs for content.It reminds me of a world that I&#x27;ve been imagining where the conclusions in scientific papers are generated as a flake outputs (an adjacent output would be the human readable thing, a PDF or whatever).In this world, you can just run `nix flake update && nix build`, and if a paper that you cite published an update which invalidates your conclusion, you know right away because their output is your input, so your build fails.We think about repeatable builds being for executable binaries, but they could equally well be for conclusions and assumptions.Perhaps nix is too big of a hammer for the job, but it seems like the best shot we have at achieving this without also constraining the scientist re: tooling.I realize that you don&#x27;t want to be storing mountains of data in the nix store, but it would work just as well if the output in question is an IPFS CID, to be resolved during the build instead. The publisher can then be in charge of keeping that CID pinned and of notifying scientists when they&#x27;re \"build\" starts failing. reply Jhsto 16 hours agorootparent> I admire how nimble you are. I aspire to write blog posts at the drop of a hat like this, but I rarely do.Thanks! I took up blogging more often as of recent, and for me, having a manageable system is a large part of that. The last thing I want to happen on a Sunday evening is breaking some page of my website. That being said, I hope to one day make the workflow easier.> It reminds me of a world that I&#x27;ve been imagining where the conclusions in scientific papers are generated as a flake outputs (and adjacent output would be the human readable thing, a PDF or whatever).I happen to be a reviewer for software artifacts in a scientific journal, and I often use Nix here. Not that many projects do use it, but if I&#x27;m able to reproduce it with Nix, then I know the author has not missed any implicit dependencies. I like to imagine it&#x27;s also useful for the authors as a feedback, whether they use Nix or not.> I realize that you don&#x27;t want to be storing mountains of data in the nix store, but it would work just as well if the output in question is an IPFS CID, to be resolved during the build instead.I maintain separate build serves of my own using Nix integrations and the Nix cache is quite large already (so called remote builders) sitting at around 500GB. I host these at Hetzner.I have also thought adding IPFS integration for my website, but haven&#x27;t got around to it. reply __MatrixMan__ 13 hours agorootparent> I happen to be a reviewer for software artifacts in a scientific journalThat&#x27;s very cool. I have a question for you.I&#x27;m taking a bioinformatics class, despite not having the chemistry prerequisites. I&#x27;m getting a crash course in biochem, and the rest of the class benefits from having an expert in what-kind-of-quotes-to-use.I&#x27;ve been thinking: would it be helpful if the care and maintenance of these compute environments wasn&#x27;t left to each scientist but was instead aggregated (perhaps per-class or per-university)?We&#x27;re setting these chemists up with conda in Ubuntu in WSL in a terminal whose startup command activates the conda environment. Not exactly a recipe for reproducibility after they get a new laptop.What if certain compute-heavy classes published flakes which the students could...a) use while taking the class so we stop wasting time on troubleshooting ssl deps via condab) reference in publications after the fact. They could say:> Here&#x27;s a Jupyter notebook, download it and run it in the UCCS biochem environment like so: `nix run github:UCCS&#x2F;CHEM4573?rev=16afd67`, its output lets us make the following conclusions...I know it would be helpful for the students in the class. Do you think it would be helpful to them later on when they were publishing things?I&#x27;m thinking about packaging the dependencies for this class, giving it to the teacher, and pitching it to the university:> Set up a technical fellowes program. Waive tuition for us nerds and in exchange we&#x27;ll support your students and faculty through the maintenance of these environments.I don&#x27;t mind paying tuition so much, but I&#x27;d like to do something to get a bit more cross pollination going between scientists in need of tech support and techies in need of something meaningful to work on.Am I dreaming here, or would it solve some problems? Do you think I have a shot at convincing anybody? reply NGRhodes 11 hours agorootparentNot sure on your issue with reproducibility using conda is. We (team of RSE working with many researchers) have had good success with storing conda environment files in git along side the code, only a few commands to get a working environment. We provide class room training to researchers and provide the training material and environments this way. reply __MatrixMan__ 10 hours agorootparentI don&#x27;t have the link to the github issue handy, but I remember that the key was to ask for a lower version of python and then supply the `--force-reinstall` param. The fact that it only happened to some students was evidence that conda wasn&#x27;t as hermetically sealed as nix.My real gripe is that in that issue, the app developer couldn&#x27;t really help--since it was a packaging problem--and the conda folks were unaware because the users had gone straight to the app developer. If there must be a third party doing curation, it seems to me that they should be more narrowly focused on whatever particular suite of tools enables whatever particular group of people--not on individual packages.I know that conda lets users do this too, but I don&#x27;t think that the environments compose as well as they do with nix. If you want Jim&#x27;s envioronment, but with Susie&#x27;s custom build of foo-tool, you can just take both as inputs, overwrite foo-tool as desired, and output composition. Your maintenance burden remains small. If conda handles environments with this kind of compositional attitude, I&#x27;m unaware of it. reply NGRhodes 2 hours agorootparent> I don&#x27;t have the link to the github issue handy, but I remember that the key was to ask for a lower version of python and then supply the `--force-reinstall` param. The fact that it only happened to some students was evidence that conda wasn&#x27;t as hermetically sealed as nix.Conda can be a bit fiddly, it makes life much easier if you specify the required version of python when you create a new environment.>I know that conda lets users do this too, but I don&#x27;t think that the environments compose as well as they do with nix.Yes, though we find Conda great for most of our use cases, we still have to resort to creating containers. reply Jhsto 12 hours agorootparentprevCouple of thoughts:> I&#x27;ve been thinking: would it be helpful if the care and maintenance of these compute environments wasn&#x27;t left to each scientist but was instead aggregated (perhaps per-class or per-university)?This is definitely something that Nix can abstract quite well. In my company we have [an infrastructure of computers](https:&#x2F;&#x2F;github.com&#x2F;ponkila&#x2F;homestaking-infra) that we manage with NixOS. We have gone over the system such that `cd` into a directory \"conjures\" the environment using devenv or direnv. We don&#x27;t do anything too fancy yet, but we have a project commencing next month in which we start to also manage routers this way. We speculate that this will help us to do things such as follows: register new node, and it gets automatically imported by the router which establishes DNS entries and SSH keys for each user. The idea is that we could have different \"views\" of the infrastructure depending on the user which the router could control. For administrators, we have a separate UI created with React that pulls NixOS configuration declarations from a git repository (note: these don&#x27;t have to be public) and shows how the nodes connect with each other. The UI is still under construction, but imagine this but now with more nodes: https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;obBfRk0. We have this set up at https:&#x2F;&#x2F;homestakeros.com.Depending on a project you are working on, you could then have a subset of the infrastructure be shown to the user and have things such as SSH aliases and other niceties set up on `cd` in. When you `cd` out, then your view is destroyed.We have quite overengineered this approach -- we run the nodes from RAM. NixOS has the idea of \"delete your darlings\" which is having a temporary rootfs. We have gone the extra mile that we don&#x27;t even store the OS on the computer, the computers boot via PXE and load the latest image from the router (though any HTTP server will do, I boot some from CloudFlare). We do this because it also forces the administrators to document changes that they do -- there is nothing worse than starting to call up people when theres is downtime and try to figure your way back up from what the mutations are. PXE booting establishes a working initial state for each node -- you just reboot the computer, and you are guaranteed to get into a working initial state. I&#x27;m personally big on this -- all my servers and even my laptop works like this. We upgrade servers by using kexec -- the NixOS configurations produce self-contained kexec scripts and ISO images for hypervisors (some stakeholders insist on running on Proxmox). I&#x27;ve suggested some kernel changes to NixOS which would allow boostrapping arbitrary size initial ramdisks, because otherwise you are limited to 2GB file size.> We&#x27;re setting these chemists up with conda in Ubuntu in WSL in a terminal whose startup command activates the conda environment. Not exactly setting them up for reproducibility if they ever move to a different laptop.Python in specific is a PITA to setup with Nix, dream2nix etc., might help but it&#x27;s definitely the hardest environment to set up of all languages I&#x27;ve tried -- even GPGPU environments are easier. Oftentimes, the only problem is not the packaging, but also the infrastructure used. For that, you could also publish the NixOS configurations and maybe distribute the kexec or ISO images.A notable thing is that devenv also allows creation of containers from the devShell environment, which may further help your case. Researchers could reference docker images instead of insisting on everyone to use Nix.In any case, I put some emails on my HN profile so we can also take the discussion off platform -- we are looking for test users for the holistic approach using PXE, and we are currently funded until Q3 next year. reply theK 16 hours agorootparentprevReading through your link I caught myself thinking if I would put up with all those boilerplate nix steps just to add a new page to the site.Don&#x27;t get me wrong, I get that you gain big amounts of flexibility out of it the way you do it but if we think about the tasksat hand, adding a page to a predefined blog, it seems a bit involved. reply Jhsto 15 hours agorootparentA fair comment, I do not disagree. I do plan to one day do an `ls` command on the root Nix file so that the manual update to the root flake for both the inputs and the RSS feed would be redundant. replymftrhu 18 hours agoparentprevNot sure if anyone actually uses it, but I would approach the problem with find, comm, and a sprinkle of sed: comm -23 1&#x27; \"$DSTDIR&#x2F;build-info\") (gen_index)xargs -n1 \"$0\" \"$SRCDIR\" \"$DSTDIR\"sorttee -a \"$DSTDIR&#x2F;build-info.new\")(cd \"$DSTDIR\" && xargs rm)Full source here: https:&#x2F;&#x2F;gist.github.com&#x2F;hadrianw&#x2F;060944011acfcadd889d937b960... reply m000 21 hours agoprevAdding a pinch of m4 [1] can give you a bit more of flexibility while sticking with the same barebones approach.I used to maintain a small website built like that some 20 years back. But I can&#x27;t see the model working today, personal websites excluded. The problem is that the approach essentially enforces Web 1.0 roles: You either need every contributing user to be html-proficient, or someone willing to assume the drudgery of being the \"webmaster\".[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;M4_(computer_language) reply gizmo686 19 hours agoparentThere is no such thing as a \"pinch of m4\". You start a clean project promising that you won&#x27;t touch m4 this time. Then you add a small m4 invocation to save yourself from some boilerplate.A year later, when you are trying to figure out why all instances of the word \"cat\" are silently disapearing from your website, you dig through 5 layers of macro expansions to discover that a junior dev tried implementing a for loop instead of copying it from the manual and messed up the quotation marks.Having solved the immediate issue, you decide that debbuging your DSL is too hard, so you import M4 macro file you have been copying between projects. You then spend a day replacinf all usages of &#x27;define&#x27; with your macro-creating-macro that adds comments to the output enabling your stacktrace generation script to work.Next project, I am putting down a hard rule: no m4! (Except for maybe that one instance) reply JoelMcCracken 19 hours agorootparentPlease write more to this story reply gizmo686 18 hours agorootparentNot \"this\" story. Everything above has happened on several projects. The cat thing comes up because it is tricky to expand two macros next to each other without whitespace. So if you do: define(`foo&#x27;,`hello&#x27;) define(`bar&#x27;,`world&#x27;) foo bar foobarYou will get: hello world foobarWorking around this gets tricky, so someone inevitably ends up writing a cat-like macro such that you can do cat(foo,bar)To get helloworld.A side effect of this is that now \"cat\" is really \"cat()\" which expands to \"\". You can work around this by doing `cat&#x27;. However, if `cat&#x27; is used as an argument to another macro (such as a for loop), the quotation only prevents escaping the first time. When the for macro is expanded, the quotation marks are stripped, giving you just \"cat\", which gets expanded again. A correctly written for macro would add new quotes as needed, but I have never seen someone correctly write such a macro without just copying it.Not sure if I have seen this interaction specifically with for and cat, but I have seen an interaction like it on almost every project that used m4. reply mhitza 18 hours agorootparentYou can place an empty \"expansion\" in that line to get the behavior you want without an additional cat-like function foo`&#x27;barI only know of this feature because recently read the manual page for m4, and it&#x27;s mentioned rather early in there, but might have been not as well emphasized in past iterations of the manual. reply gnubison 18 hours agorootparentprevFor completions sake, though, the easy way to do it is: foo`&#x27;barThe empty quotes make foo and bar separate words. reply js2 18 hours agorootparentprevI&#x27;ve only ever used m4 via autoconf and sendmail configuration files, so I don&#x27;t know if it&#x27;s m4 that has the bizarre syntax or whether it&#x27;s autoconf&#x27;s and sendmail&#x27;s use of it. I&#x27;m not sure I&#x27;ve ever tried to use m4 directly for anything. reply _ache_ 18 hours agorootparentprevI know that story too well. Finally, I thought that if I have to code, I should just use a programming language.Now, I use nodeJS to replace every m4 file with mustache.js and some JS logic and I don&#x27;t feel limited anymore. The complexity doesn&#x27;t increase much. reply tkb 25 minutes agoparentprevI too had a small web site with M4 around 1999&#x2F;2000. Why M4? Because I&#x27;d learned enough of it to be useful&#x2F;dangerous when wrestling with Sendmail, and it seemed to do the trick (at least when the trick was simply \"be easier than manually editing lots of HTML files every time there&#x27;s a site-wide change\").I suspect I was never doing anything complicated enough to encounter the gotchas mentioned by other commenters... reply tannhaeuser 19 hours agoparentprevRather than relying on generic text substitution using m4 or perl or whatever, I suggest using SGML, the basis and common superset of HTML and XML, which comes with easy type checked text macro (entity) expansion for free or even type-aware parametric macro expansion. Where \"type\" refers to the regular content type of a markup element (ie. its allowed child elements and their expected order) but also considers expansion and escaping into attributes or other context such CDATA or RCDATA. Only SGML can extend to the case of properly expanding&#x2F;escaping potentially malicious user comments with custom rules such as eg. allowing span-level markup but disallowing script elements, does markdown or other Wiki syntax expansion into HTML, can import external&#x2F;syndicated HTML content, produce RSS and outlines for navigation, etc. Works well for nontrivial static site preparation tasks on the command-line; cf. linked tutorial and command line reference.[1]: https:&#x2F;&#x2F;sgmljs.net&#x2F;docs&#x2F;producing-html-tutorial&#x2F;producing-ht...[2]: https:&#x2F;&#x2F;sgmljs.net&#x2F;docs&#x2F;sgmlproc-manual.html reply layer8 19 hours agorootparentWhat is sgmljs? There doesn’t seem to be any explanation on the site. reply tannhaeuser 18 hours agorootparentA comprehensive package for processing, converting, and serving SGML on the command line, on the server side, or in the browser; see [1]. Also features SGML DTDs (grammars) for W3C HTML 5, 5.1, 5.2, and Review Drafts January 2020 and 2023, which are the latest non-volatile W3C and WHATWG HTML recommendations&#x2F;spec versions.[1]: https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;sgmlEdit: your comment is a welcome reminder to improve the site, which isn&#x27;t an easy thing to do however due to sheer volume of the material, even though it&#x27;s using SGML for shared boilerplate inclusion, ToC&#x2F;site nav and page nav generation, etc. (in fact, by calling sgmlproc from a Makefile) reply q3k 21 hours agoparentprev> a pinch of m4nononononononononono for the love of everything please nom4 isn&#x27;t even a good esolang! reply PaulHoule 21 hours agorootparentAt the dawn of the age of PHP, I created a user management system (registration, verification, admin interface, …) that was based on well-established ideas (how login worked at Yahoo, Amazon, and every other process major site) but got no traction at all as a open source project. In any language that wasn’t PHP it would be necessary to write an “authentication module” which as about 50lines of cookie handling code. Multiple times I managed to out several existing apps together and make an advanced web site.About 10 years ago the idea suddenly got traction once it was legitimized by the SAAS fad, I would tell people “don’t you know they’re going to end the free tier or go out of business or both?” and sure enough they did.Anyhow, I bring it up because the system used M4 to interpolate variables into PHP, other languages, shell scripts, SQL scripts, etc. reply gabereiser 19 hours agorootparentUgh, I know exactly how this feels. You resist the urge so hard to say “I told you so” and instead relish in the fact that you saw it. “The Way”, so to speak.I remember having to write cgi cookie handling code. I remember having to write session-cookie sync code. PHP was a small slice of heaven in the cgi world. Until it wasn’t. Still, being able to import libraries of script functions without having to recompile was wizardry. The problem with php now is they let a certain product somewhat dictate their direction. Class namespaces with slashes is the ugliest design choice.What was your oss project that couldn’t get traction? reply PaulHoule 9 hours agorootparentIt was called Tapir User Manager but the web site was down for some time. It was an open source failure but a career success because I used it around 8 projects including the arXiv preprint service, a voice chat service that got 400,000+ users, and the web site for our county green party (which had national impact.) reply Tomte 21 hours agorootparentprevYou need to combine it with Perl and a collection of other special passes, of course: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180309134414&#x2F;http:&#x2F;&#x2F;thewml.org... reply envsubst 20 hours agoparentprevInstead of `m4` or `sed` find and replace, the author should try `envsubst`. It&#x27;s a program that replaces bash style variable references (for example `$TITLE`) with their value in the environment. export CURRENT=\"...\" cat page.htmlenvsubt reply karl42 1 hour agorootparentI agree that `envsubst` is a good choice for this. Unfortunately, it is not part of posix, so you can&#x27;t rely on it being present everywhere. But as part of gettext, it is still very common. reply teo_zero 19 hours agorootparentprevThe problem is that the $SOMETHING syntax is just too common if your site is a technical one, and you&#x27;ll end up substituting too much. reply envsubst 17 hours agorootparentYou can specify which variable names are valid, reducing the likelihood of a collision. reply gjvc 19 hours agoparentprevI did that once. Never again.Just because it worked for sendmail is not sufficient justification for anything. reply SoftTalker 12 hours agorootparentA lot of older unix software config is complicated and cryptic.sendmail, bind, apache, older X11, sudo are examples that come to mind. reply bradley_taunt 21 hours agoprevI was instantly inspired by Karl&#x27;s work on his \"blog.sh\" shell script[0] that he mentions in this article. I took it and tweaked it to create my own minimalist SSG called \"barf\"[1]. That wouldn&#x27;t exist if Karl didn&#x27;t share his wonderful work publicly![0]: https:&#x2F;&#x2F;github.com&#x2F;karlb&#x2F;karl.berlin&#x2F;blob&#x2F;master&#x2F;blog.sh [1]: https:&#x2F;&#x2F;barf.bt.ht reply adityaathalye 21 hours agoparentAh, a fellow person of culture. Mine is called shite [1], which makes my site [2]. The name alludes to the software quality :)What I like most about it is I haven&#x27;t had to upgrade anything, and don&#x27;t expect to forever. And a close second; it \"hot reloads\" without javascript.[1] https:&#x2F;&#x2F;github.com&#x2F;adityaathalye&#x2F;shite[2] https:&#x2F;&#x2F;evalapply.org reply gnyman 14 hours agorootparentHaha I sense a trend for these home grown static site generators :-)Yours are much more advanced, but a few years back I made a minimal PHP static page generator and named it...PHP keep It Stupid Simple, or in short P.I.S.S.https:&#x2F;&#x2F;blog.nyman.re&#x2F;2020&#x2F;10&#x2F;11&#x2F;introducing-piss-a.html reply adityaathalye 14 hours agorootparentWell, if you see my templating code, I&#x27;ve basically written PHP, but in Bash :D reply rambambram 17 hours agoprevI like it that (almost) every dev blog I come across on HN has an RSS feed.For every interesting article that I read here I follow the feed. Whether you have a Wordpress site, a Bear Blog, a Micro blog, a blog on Havenweb, or a feed on your self-built site, I add them to the &#x27;Really Social Sites&#x27; module of Hey Homepage.Ultimately, I would like to publish this list of blogs, just like Kagi now does with their Small Web initiative. But I guess curating is key to adding quality. And when I think about curating, starting some kind of online magazine seems only natural. reply qudat 9 hours agoparentThere’s also https:&#x2F;&#x2F;prose.sh which is similar to bear blog. reply rambambram 3 hours agorootparentSounds familiar, I might have seen it here on HN. I like their &#x27;Discover&#x27; page with an overview of interesting posts from others! reply MuffinFlavored 16 hours agoparentprevI&#x27;m trying to understand (as a dev) if there is something \"wrong with me\" for not wanting to have my own blog. Where do people get the \"entitlement\" (I mean that in the best way possible) to share with other people&#x2F;assume other people care what they are working on? It feels like a competition sometimes. \"I need to work on something as cool as possible so I&#x27;ll get some likes&#x2F;impressions on my blog\".Collaboration is obviously cool and only works with making it all public, I just don&#x27;t know where \"I&#x27;m doing this because I think it&#x27;s cool\" and \"I&#x27;m going to put effort in to share it with others to get reactions\" reply jaw 15 hours agorootparentI have a blog, but I mostly assume people _don&#x27;t_ care what I&#x27;m doing or thinking. Some of my posts have probably never been read by anybody. I still personally find it worthwhile for a few reasons:- The mere possibility that someone will see it pushes me to put more thought and effort into what I write. Sometimes this reveals weaknesses in my ideas that I would have glossed over if I were just writing private notes for myself; sometimes it leads me to actually change my opinions. It also means the blog posts are easier for me to understand &#x2F; get value out of than notes are if I come back and reread them years later.- It creates opportunities for people to connect with me which can pay off at unexpected times. Occasionally people have reached out to me to say a post helped them or resonated with them, or to give a thoughtful reply or ask a question. Those sorts of interactions are really satisfying even if they&#x27;re rare. (One time, I was interviewing for a dev job and the interviewer asked a question about a post I&#x27;d written on the philosophy of John Rawls, and how it could connect to software engineering. I found that absolutely delightful.)- It&#x27;s just nice to have an outlet when I feel like writing about something. reply rambambram 16 hours agorootparentprevI don&#x27;t think there&#x27;s something wrong with you. I also think there&#x27;s nothing wrong with people sharing _interesting_ stuff, whether they do it ultimately for shallow likes or for ... you know... just sharing _interesting_ stuff.On a side note, I get the \"entitlement\" from nobody. I take it. I also mean that in the best way possible. Nobody&#x27;s asking for my software, my (future) articles, my point of view, etc. Still, I make stuff and sometimes share stuff. I think it can be a net value for some people (definitely not for everyone). This is only the reasoning behind it, the main motivator was me realizing I matter as a human being and I have only one life to live. I learned that because of experiencing a &#x27;dark night of the soul&#x27; a couple of years back. Luckily I got through. And to be honest, if it wasn&#x27;t for the internet - made up of personal websites and real people sharing their own experience on forums - that taught me everything there is to know about Cluster B disordered personalities (just an example, cough nothing personal cough), I don&#x27;t think I would be sitting here typing this lengthy response.I realized I can not sit back, enjoy the decline of the internet, and only complain about it. I would love to see the web have a lot of personal websites and blogs about every kind of subject, so I started to build a website software. The web&#x2F;internet, and all the information shared and made easily accessible, made me able to save myself. I was probably helped more by some random dude who put up a website fifteen years ago with everything he knew about certain stuff than I was helped by anything else. reply calderknight 3 hours agorootparentprev\"WWW - let&#x27;s share what we know\" reply rambambram 3 hours agorootparentUnd die gedanken sind frei! reply eep_social 16 hours agorootparentprevI think the bloggers are a classic vocal minority, nothing to feel weird about. reply rambambram 15 hours agorootparent> a classic vocal minorityNot saying you&#x27;re right or wrong, but I myself don&#x27;t want to look at it like it&#x27;s a competition of the loudest people.I&#x27;ve read so many blogs through HN over the last years, and every one of &#x27;em had something interesting to say while also portraying something personal from the author. Whether that&#x27;s a nice layout, nice color scheme, or even some nice jokes in their bio text.To me, it can not get any more human than this. Pure individuals connecting on a world wide web. By links, by email, by RSS feeds. All without big tech. reply eep_social 14 hours agorootparentI agree with everything you wrote — what I was trying to communicate is that there’s no shame in not feeling the urge to share as it happens to be that the vast majority of us, like the gp post, don’t but that’s not easy to see or quantify.Aside, I almost wrote “silent majority” but that seemed like it was veering towards politics so I went with vocal minority; I suspect there is a better term out there but I didn’t find it quickly. reply rambambram 14 hours agorootparentI admit I interpreted more in your short post than was there. People definitely should not feel shame for not feeling an urge to share!I still encourage people to share though, because I think a lot of people would like to read personal stuff about topics that interest them. Doesn&#x27;t even have to be with your name and all next to it, anonymous&#x2F;pseudonymous homepages are usually possible.Therefor I offer free websites (on a subdomain though) for people that would like to write or post photos about their hobbies. And know that there are way more possibilities to go online, just look at the OP of this thread with a nice SSG. reply eep_social 14 hours agorootparent> I offer free websitesAnd I am so glad you do!Writing my longer reply I realized that early social media is a strong counterpoint — people absolutely loved to share when the barrier to doing so was low, the platforms hadn’t been given over to commercialization, and it was less obvious that those details were going to be ingested into an advertising profile. It sounds like you offer a bit of that without the motive or intent that turned mainstream social media into what it is and I think that’s great! reply rambambram 13 hours agorootparentThanks!Yeah, somewhere between the homepages and webrings of the nineties and the added social functionality of the early social media platforms. Ideally without the platforms and their incentives. The web itself is already a social platform, a social medium. No need for more layers, especially if they ultimately are against my interests. I think RSS still holds the potential to connect individual websites&#x2F;people, albeit in a slightly (or maybe even fundamental?) different way than the social media platforms do.Question: what would be your number one topic&#x2F;subject to blog about, other than anything tech related? replymixmastamyk 6 hours agorootparentprevOdd take. If you spend several hours figuring something out, it’s quite neighborly to write it up for the next person. “Shoulders of giants” and all that.I’m certainly grateful for their help, and even written up a few of my own. reply marcodiego 17 hours agoprevA friend of mine described using make to generate scientific papers. He explained that if he changed a single test file, the entire paper could be regenerated including running tests and generating graphs the changed test with a single command. reply danielvaughn 21 hours agoprevIt&#x27;s a neat idea, though I have to point out that if you&#x27;re already pushing to Github, you could just push the source and Github will publish your markdown as a hosted page: https:&#x2F;&#x2F;pages.github.com&#x2F; reply account42 1 hour agoparentBut that makes you dependent on GitHub for more than just dumb hosting - better make sure you can run the site generation locally from the start. reply Kiuhrly 20 hours agoprevWow, this is almost exactly what I was planning to do for my site. For another small project, I wrote a tiny shell script as a makeshift \"bundler\" (just embeds the CSS and JS inside the HTML) with the goal of also being able to serve the unbuilt files locally: sed \\ -e &#x27;&#x2F;[&#x2F;][&#x2F;]script&#x2F;r index.js&#x27; -e &#x27;&#x2F;[&#x2F;][&#x2F;]script&#x2F;d&#x27; \\ -e &#x27;&#x2F; &#x2F;d&#x27; \\ -e &#x27;&#x2F;[&#x2F;][*]style[*][&#x2F;]&#x2F;r styles.css&#x27; -e &#x27;&#x2F;[&#x2F;][*]style[*][&#x2F;]&#x2F;d&#x27; \\ -e &#x27;&#x2F; &#x2F;d&#x27; \\ index.htmlThe HTML contains something like this: &#x2F;*style*&#x2F; and the script just deletes thetag and replaces the &#x2F;style&#x2F; comment with the contents of styles.css. Definitely not my finest work but it worked well enough. reply kazinator 17 hours agoprevThe benefit of make is that large programs that are built by slow compilers can be incrementally rebuilt much faster in the face of small changes. Something that would take 40 minutes to do a full rebuild can build in three seconds or whatever.If your static site can be generated from scratch in under a second by just catting a few hundred HTML files with a common header, there is no benefit to using make over a script. You only risk performing an incomplete build due to a bug in the dependencies. reply toast0 16 hours agoparentIf the file dependencies don&#x27;t actually matter, you can mark the build targets as .phonyAnd still get to have things like make build vs make push, etc. reply kazinator 13 hours agorootparentIf dependencies don&#x27;t matter, make isn&#x27;t the right tool.Your scripted actions can be .&#x2F;build and .&#x2F;push.If you feel you need to type the name of a tool before your command, you can do that: sh build, sh push. reply mixmastamyk 6 hours agorootparentFilling your project namespace with a half dozen 2 -3 line scripts is not a big win.One script with a switch case might be better. reply jrm4 21 hours agoprevInteresting. So I&#x27;m a weird sort, I imagine, in that I&#x27;m the type that has been using Linux and shell scripts for 20+ years, but never actually done any big-time coding, and thus I really don&#x27;t know \"make.\"Point being, I do something very similar to this; except I first simply write&#x2F;create my website in Zim-wiki, but then I have a bunch of little tasks to \"clean up,\" i.e. fix&#x2F;modify some links and then use the Canvas API to update my main course page (which, because I hate Canvas that much, simply links out to my own site).Why make instead of shell scripts? reply aquova 21 hours agoparentMakefiles honestly are just glorified shell scripts. Some of the syntax is a little odd, but you trade that for a more standarized format and the ability to add different build options without mucking around with argparse yourself. reply thaumasiotes 20 hours agorootparent> Makefiles honestly are just glorified shell scripts.Not really. The concept of a script is \"do these things in this order\".The concept of a makefile is \"here are a bunch of things that might or might not need to be done, you figure it out\". reply dahart 18 hours agoparentprevAs someone who also writes a lot of shell scripts and has for decades, I’d guess that if you learn just a little make, you’ll find lots of non-coding uses for it and wish you’d learned it earlier. ;) It’s just another great unix tool that is sometimes very handy to augment shell scripts when you need it, not unlike find+grep+sort, cut+join, awk+sed, gnu parallel, etc.. I think make is under-appreciated for its uses outside of code compilation. I use it anytime I’m making gnuplots, or doing image processing on the command line, for example. Whenever you have a batch of files to process, and the batch might need to re-run, and it transforms into other files or a single big file, then make may be the right toolMake has at its core one thing that would be pretty tedious to do in shell scripts: update the target (output) file only if it’s older than the prerequisite (dependency&#x2F;input) file(s). This applies transitively to files that depend on other files that might change during the run of make, which is the part that really separates make from a shell script.The thing you do when the target needs updating is run a little snippet of shell script, so that part you already know.After learning how a rule works, you can combine it with ‘pattern rules’ to abstract a rule over all files that share a common prefix or common extension. Suddenly you have a loop but without any loop syntax, and can process a thousand files on demand with 2 lines of make - and without modification you can change a single input file, have it process only a single output file, and not waste your time re-running the 999 other files.Also pro-tip: make will run in parallel if you use -j, and it will do it without breaking any dependency chains. If you have a process that turns text files into sql files and then turns this sql files into html files (possibly nonsensical example), make running in parallel will not blindly update html files first, it will run parallel jobs in the correct dependency order. You can use make to build something like gnu parallel, but is able to resume a batch job that was interrupted in the middle! reply 0cf8612b2e1e 16 hours agoparentprevMy number one reason to use make is to have a single centralized location for project commands. If I see a Makefile at the root, I can quickly scan it and have an overview of what high level actions I might execute.Note that I have recently switched to Just (https:&#x2F;&#x2F;github.com&#x2F;casey&#x2F;just). While not technically the exact feature set as make, it covers all of the ground for what I typically do. It gets the benefit of history and discards a lot of make cruft to make a more predictable experience. reply defanor 19 hours agoprevI used a shell script for that, but vaguely thought of changing to a Makefile for a while, and finally did now, thanks to the article reminding of that; it is more appropriate. Though the shell script still invokes make, and then rsync, since rsync seems less appropriate for a Makefile. But now it synchronizes fewer files.As a side note, I am quite happy with XSLT templates to produce the pages (instead of attaching a static header, as in the article), as well as to generate indexes and an Atom feed. reply jasonm23 4 hours agoprevBash&#x2F;Zsh as a static site generator would be less steps.Or Github actions workflow as static site generator would only include one shell wrapper, instead of 2. reply adityaathalye 21 hours agoprevI love the code [1]. Mine [2] is a bit over engineered because I wanted hot-reloading (without JS), and it was a delightful yak shave.But the basic idea is the same --- heredocs for templating, using a plaintext -> html compiler (pandoc in my case), an intermediate CSV for index generation. Also some handy sed-fu [3] to lift out front matter. Classic :)Very nice![1] https:&#x2F;&#x2F;github.com&#x2F;karlb&#x2F;karl.berlin&#x2F;blob&#x2F;master&#x2F;blog.sh[2] https:&#x2F;&#x2F;github.com&#x2F;adityaathalye&#x2F;shite[3] I&#x27;m doing this: https:&#x2F;&#x2F;github.com&#x2F;adityaathalye&#x2F;shite&#x2F;blob&#x2F;master&#x2F;bin&#x2F;templ... case ${file_type} in org ) # Multiline processing of org-style header&#x2F;preamble syntax, boxed # between begin&#x2F;end markers we have defined. We use org-mode&#x27;s own # comment line syntax to write the begin&#x2F;end markers. # cf. https:&#x2F;&#x2F;orgmode.org&#x2F;guide&#x2F;Comment-Lines.html sed -n -E \\ -e &#x27;&#x2F;^\\#\\s+shite_meta&#x2F;I,&#x2F;^\\#\\s+shite_meta&#x2F;I{&#x2F;\\#\\s+shite_meta.*&#x2F;Id; s&#x2F;^\\#\\+(\\w+)\\:\\s+(.*)&#x2F;\\L\\1\\E,\\2&#x2F;Ip}&#x27; ;; md ) # Multiline processing of Jekyll-style YAML front matter, boxed # between `---` separators. sed -n -E \\ -e &#x27;&#x2F;^\\-{3,}&#x2F;,&#x2F;^\\-{3,}&#x2F;{&#x2F;^\\-{3,}.*&#x2F;d; s&#x2F;^(\\w+)\\:\\s+(.*)&#x2F;\\L\\1\\E,\\2&#x2F;Ip}&#x27; ;; html ) # Use HTML meta tags and parse them, according to this convention: ## cf. https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Learn&#x2F;HTML&#x2F;Introduction_to_HTML&#x2F;The_head_metadata_in_HTML sed -n -E \\ -e &#x27;s;^\\s?;\\L\\1\\E,\\2;Ip&#x27; ;; esac reply rcarmo 20 hours agoparentI found his GEMINI approach quite funny - it strips out most of the formatting with a regexp.There is a bit of a limitation, though - I organize posts by namespace and with the date in the URL, and make can’t really handle that directly. reply karl42 17 hours agorootparent> I found his GEMINI approach quite funny - it strips out most of the formatting with a regexp.Do you mean the regexp in https:&#x2F;&#x2F;github.com&#x2F;karlb&#x2F;karl.berlin&#x2F;blob&#x2F;master&#x2F;blog.sh#L4 ? It doesn&#x27;t remove the formatting, just HTML comments (because they would show up on the page, otherwise) and rel=\"me\" attributes (because they don&#x27;t work with md2gemini). Feel free to read the blog post about adding Gemini support for more details: https:&#x2F;&#x2F;www.karl.berlin&#x2F;gemini-blog.html reply adityaathalye 20 hours agorootparentprevHuh, I previously skim-read the code and didn&#x27;t notice the GEMINI regex detail. I wonder why they&#x27;re doing that.Re: namespace organisation. I thought about that a lot, and decided to adopt namespace-only convention for symmetry between text file layout, html file layout, and url scheme.I&#x27;ve treated Date&#x2F;time as metadata, which I can use to organise index pages. If I get to years worth of posts, then I&#x27;ll group them by year&#x2F;month or something reasonable. Likewise tags. I debated tags _and_ categories. But I decided on \"everything is a post with tags, and categories will emerge based on topical coverage + post format\". reply maccard 20 hours agoparentprevSeeing these sorts of scripts is exactly why we don&#x27;t write our own, and use something like esbuild and vite. reply adityaathalye 20 hours agorootparentWell, I have my reasons and you have yours!For example,A) Most importantly, I wanted to tinker and have fun!B) I already use Bash at work and stuff, so it&#x27;s easy for me.C) I am generally averse to fast-changing dependencies, and giant dependency trees, so that rules out most scripting languages.Besides, if you peruse the README, you will see that my code guarantee is \"works on my machine\". Your mileage will vary tremendously :) reply maccard 19 hours agorootparentIf it&#x27;s just for fun then write your bundler in assembly for all I care! reply adityaathalye 19 hours agorootparentYou never know :) replydenvaar 20 hours agoprevIt’s fun to make your own SSG tool, and this is a great example of keeping it simple.It’s also interesting to read so many comments of people doing similar things.For my own site, I find that I want an SSG tool that is simple, intuitive, and stays out of the way. With these goals in mind, I have been able to slowly improve my tool over and over. It’s been awesome to be able to do more using less. reply nonethewiser 20 hours agoparentIt also makes you realize what they actually are. reply adityaathalye 19 hours agorootparentAbsolutely! What mental model did you arrive at?Mine is \"an SSG is just a source to HTML compiler and compositor, plus file organiser\".I reviewed a few tools (jekyll, emacs.love&#x2F;weblorg, hugo), and ended up making mine in big part because I went down the rabbit hole of \"well, why is this part here? why is it like this? why can&#x27;t we do this other thing? wow this bit is cool, how do I make it myself?\". reply bundie 5 minutes agorootparentHmm, is this SSG tool public? like, on GitHub or something? reply ivanstojic 19 hours agoprevTossing mine in the pot too: make + pandoc: https:&#x2F;&#x2F;ordecon.com&#x2F;2020&#x2F;07&#x2F;pandoc-as-a-site-generator&#x2F;index... reply tyingq 21 hours agoprevThe syntax takes a little trial and error and usually finding real-world examples, but I like \"make\".I had one project that involved downloading a jdk, using it to build a project specific jre, patching some class files with local java sources, bundling it, etc.Without being a make expert, it took me a couple of hours of reading, finding examples, etc...but now I have the dependency stuff working perfectly. Where it now only re-downloads or re-builds things if something upstream from it changed, handles errors well and points out what broke, etc.All that to say, for some things, it&#x27;s worth looking into for it&#x27;s built-in dependency chain stuff. When you need to run arbitrary outside scripts&#x2F;tools, it sometimes does things that other build tools can&#x27;t (gradle in my case, couldn&#x27;t easily do this, or at least I couldn&#x27;t figure out how). reply dijit 21 hours agoparentMake is excellent for tasks where you have a file that needs to exist and steps that reliably cause it to exist.Excellent too for building a tree of things that depend on prior stages; in your example needing java to run a java applet which generates a file.the syntax takes some getting used to, but in those cases there is little better.But I do find people using it as a glorified task runner and it works but it’s quite possibly the least ergonomic tool available. - especially for things like making docker images, which I see extremely often reply maccard 20 hours agorootparentThere&#x27;s not really any better option though. Once you start setting environment variables, customising tagging, adding file prerequisites, handling building from a different directory (monorepo requiring access to shared resources), you need some sort of wrapper, with options, argparsinc and some rudimentary dependency checking. Make is a super low barrier to entry solution that with a small workaround (phony targets) gives you all of the above. reply w4rh4wk5 21 hours agoprevI did some similar experiments some time ago. It includes Makefiles, Rakefiles, SASS, Ruby erb, Jade, m4, and a few other tools.https:&#x2F;&#x2F;github.com&#x2F;W4RH4WK&#x2F;static-page-generatorsOver all, I quite like Ruby since it comes with rake and erb. reply maccard 20 hours agoparentRake is probably my favourite of them all, but it adds a dependency on ruby. We&#x27;ve settled with using make and accepting the limitations reply askiiart 18 hours agoprevI did something similar for mine, I do markdown-to-html using pandoc, then replace the language labels using find (so that prism.js works). I&#x27;ve got it all running via a little Python script (I would&#x27;ve done bash but I&#x27;m terrible at it) to generate all the the files easily, rather than going through one-by-one: https:&#x2F;&#x2F;git.askiiart.net&#x2F;askiiart&#x2F;askiiart-net&#x2F;src&#x2F;branch&#x2F;ma...I might move to something make-based like this, looks interesting. reply mjburgess 18 hours agoparentjust use (gnu) parallel reply donatj 21 hours agoprevJust a couple days ago I set up a site with GitHub Pages and used a very similar setup.I learned about envsubst in the process which let me fill in values here and there. This is the rough way the homepage works. public&#x2F;index.html: index.md template&#x2F;header.html template&#x2F;footer.html cat template&#x2F;header.html > public&#x2F;index.html DATE=$(shell date +%Y-%m-%d) envsubst > public&#x2F;index.html cat template&#x2F;footer.html >> public&#x2F;index.htmlGitHub’s newer version of pages that lets you deploy via GitHub Actions rather than being forced into using Jekyll is just so amazing. I have converted a bunch of static sites to using it as hosting. reply hnarayanan 21 hours agoparentJust as straightforward as this is another method that has worked for me for years (decades?).Server Side Includes.Have a separate files for the header, content and footer and only edit the content files. reply donatj 21 hours agorootparentI was there 3,000 years ago… I used SSI’s in the late 90s&#x2F;early 2000’s before replacing all that with PHP which was a huge step up at the time. I am more than familiar.The convenience here is largely in being able to use GitHub Pages to host the page while being able to do almost anything you want for a build process. It’s really neat. reply girishso 17 hours agoprevMost Static Site Generators generate blog from markdown, which is not feasible for projects like company websites etc. For such projects I like Middleman (https:&#x2F;&#x2F;middlemanapp.com) which provides layouts&#x2F;partials and things like haml templates. reply petepete 11 hours agoparentNanoc is great in cases like this too. It does less out of the box than Middleman but is easier to extend.https:&#x2F;&#x2F;nanoc.app&#x2F; reply karl42 17 hours agoprevAuthor here. Nice to see people appreciate simplicity. If you have any questions, feel free to ask! reply mosselman 20 hours agoprevThis amazing course by Avdi Grimm on make and rake for the same purpose has completely changed my understanding of rake and I recommend anyone checking it out:https:&#x2F;&#x2F;graceful.dev&#x2F;courses&#x2F;acapa&#x2F; reply smarnach 14 hours agoprevIsn&#x27;t this \"cat\" as a static site generator target than \"make\"? Make is just the build system invoking the static site generator. reply gigatexal 21 hours agoprevI do this too! But my make-fu isn’t as good. I’ll use what I learned from here to make it better. reply tiehuis 21 hours agoprevI as well moved to this sort of approach a few years ago [1]. Definitely like the simple approach and it just stays out of the way.[1] https:&#x2F;&#x2F;tiehu.is&#x2F;blog&#x2F;blog1 reply adriangrigore 20 hours agoprevShameless plug for my shell based static site generator https:&#x2F;&#x2F;mkws.sh. You can replace the bin&#x2F;mkws script with a Plan9 mk file anytime. reply prabal97 20 hours agoparentVery cool! How long did it take you to make something like this? reply adriangrigore 20 hours agorootparentWell, I implemented the main idea in a day or two. That being the pp preprocessor. The rest, I really can&#x27;t remember, it was mainly grunt work to see what are the minimum things a web site is required to have. I still have some stuff to remove. reply mkoryak 21 hours agoprev> There are no exotic dependencies, nothing to maintain and you can quickly adapt it to your needs.Yeah kinda, except that most people making static sites aren&#x27;t the people who know Make. reply jetrink 21 hours agoparentI regularly see people on HN who have a static site for their personal site or blog. There&#x27;s a niche for this kind of thing. reply rcarmo 21 hours agorootparentUp until a certain point, yes. Then you start wanting back links, navigation, etc., and doing that with make alone doesn’t quite work, especially if you have a deep tree of files - single folder sites don’t typically have a lot of content in them.(My site is generated by a Python commit webhook that indexes new files, diffs an Azure storage container and uploads updated files only). reply envsubst 20 hours agoparentprevit&#x27;s a crazy concept, but people are willing to learn to use a new tool for their hobby project. reply dwheeler 21 hours agoprevI&#x27;ve been doing this for decades. It works very well, it can handle complex cases, and it ports trivially between different hosting systems. reply sureglymop 17 hours agoprevI use make and pandoc as my static site generator! Generates a good website from my markdown notes. reply TekMol 21 hours agoprevWhat does make bring to the table here compared to a shellscript which loops over the files in the source dir? reply oftenwrong 20 hours agoparentMake provides incremental execution of the build graph. It is aware of the dependency graph, and the state of inputs and outputs. It will (ideally) only execute the minimal build rules necessary.A shell script that checks file mtimes to determine what has already been built, and therefore what can be skipped, is close in spirit.Make variants like GNU Make have additional functionality, like automatic concurrent execution of parts of the build graph. reply lacrosse_tannin 16 hours agoprevI&#x27;m gonna use bazel reply bachmeier 15 hours agoprevAs long as we&#x27;re sharing our own projects...One of the things I did during the pandemic lockdown was work on the simplest possible blog in a single html file. Something that requires essentially no technical knowledge beyond typing text into a file. I recently dusted it off and yesterday I posted the most recent iteration.Demo: https:&#x2F;&#x2F;bachmeil.github.io&#x2F;minblog&#x2F;blog.htmlSource: https:&#x2F;&#x2F;github.com&#x2F;bachmeil&#x2F;minblog&#x2F;blob&#x2F;main&#x2F;blog.htmlThere&#x27;s very little styling, but that&#x27;s not the objective (and it&#x27;d be trivial to add). reply PaulHoule 21 hours agoprevFunny I am setting up a blog with Pelican which uses “make” for executive control. reply superlopuh 20 hours agoprevIs there a GitHub workflow available for this or similar tool? reply liveoneggs 21 hours agoprevhey I wrote almost this exact blog post 15(ish?) years ago except mine used m4 as an \"exotic dependency\" ;) reply jameshart 16 hours agoprev\"No exotic dependencies and nothing to maintain\"Oh really?: sed -E &#x27;s|(href=\"$(subst source,,$ $@a sed script that modifies HTML fragments isn&#x27;t nothing. And this just does one thing that you might want to customize in the header for each page. It doesn&#x27;t do things like handle pages having differenttags. Every feature like this that you come up with becomes another thing to maintain, and another thing that can catch you out later. When you come back to fix this later, will you even remember what it&#x27;s supposed to do?From a web publishing point of view, make and sed are exotic dependencies. There&#x27;s not going to be a bunch of helpful pointers online to help you debug issues with using them for this purpose. When you google how to fix your sed regex to match specific HTML attributes and not match others, you&#x27;re going to find stack overflow posts about Zalgo, not quick answers. reply superkuh 20 hours agoprev [–] Or maybe don&#x27;t make a site generator and just make a website using HTML files? You&#x27;ll spend a lot less time painting the shed and a lot more time actually putting your ideas&#x2F;content on the website.If you want templating then use server side includes. It&#x27;s much less attack surface than say, PHP or some complex CMS, but you can still just make a footer.html and stick in at the bottom of every other .html page easily and avoid the one problem with file based sites: updating shared bits. reply ttfkam 20 hours agoparent [–] If only there were a way to make consistent structure in an online document (such as hypertext) and separate the styling into distinct files. Even better, what if we could make separate styling for mobile, desktop, and printing, all with the same content?If only it were possible using existing standard web technology. Sadly it was never designed with such goals in mind.&#x2F;s replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their positive experiences using the static site generator, Karl Bartel Home Projects, for creating and hosting websites, highlighting its speed, simplicity, and flexibility.",
      "They discuss various functionalities such as adding headers to HTML files, copying unchanged files, and the possibility of converting markdown content into HTML.",
      "They propose convenience features like serving the site locally, automatically rebuilding on file changes, and uploading directly to GitHub Pages."
    ],
    "commentSummary": [
      "The article delves into methods and tools for creating and managing static websites, including the use of Makefiles, shell scripts, and static site generators, discussing their advantages and disadvantages.",
      "It touches on using Nix, Conda, and Docker for compute environment management, discussing the challenges and strengths associated with these tools.",
      "Personal blogging value, the use of heredocs and plaintext to HTML compilers for website generation, and limitations of current web technology regarding consistent styling across platforms are also discussed."
    ],
    "points": 256,
    "commentCount": 143,
    "retryCount": 0,
    "time": 1694345429
  },
  {
    "id": 37454707,
    "title": "New JFK assassination revelation could upend the lone gunman theory",
    "originLink": "https://www.vanityfair.com/news/2023/09/new-jfk-assassination-revelation-upend-lone-gunman",
    "originBody": "Skip to main content OPEN NAVIGATION MENU SIGN IN Subscribe SEARCH Politics Business Hollywood Style Culture Royals Celebrity Video Podcasts Archive VF Shop What Is Cinema? Newsletters Archive VF Shop VF London Magazine Limited Time Offer - Get 1 year for $29.99 $8 + a free tote. Subscribe This one's on us. You are reading your first free article. Limited Time Offer - 1 year for $29.99 $8, plus a free tote. Join Now Already a subscriber? Sign in. HISTORY A New JFK Assassination Revelation Could Upend the Long-Held “Lone Gunman” Theory In a new book, former Secret Service agent Paul Landis, largely silent for 60 years, says he found a bullet in Kennedy’s limo. A sometime presidential historian explains why that’s so significant, if true. BY JAMES ROBENALT SEPTEMBER 9, 2023 Paul Landis leads President Kennedy and Jackie Kennedy through a crowd of supporters at the Dallas airport; November 22, 1963BETTMANN/GETTY IMAGES. He has kept his secret for 60 years. Paul Landis was one of two Secret Service agents tasked with guarding first lady Jacqueline Kennedy on November 22, 1963—the day President John F. Kennedy was assassinated. In a new book, The Final Witness, to be published in October, Landis claims to have seen something that afternoon that he had never publicly admitted before. His secret, coming to light only now, will certainly reorient how historians and laymen perceive that grave and harrowing event. His account also raises questions about whether there might have been a second gunman in Dallas that day. Hive Where Wall Street, Washington, and Silicon Valley meet. Your email SUBMIT BY SIGNING UP YOU AGREE TO OUR USER AGREEMENT AND PRIVACY POLICY & COOKIE STATEMENT. THIS SITE IS PROTECTED BY RECAPTCHA AND THE GOOGLE PRIVACY POLICY AND TERMS OF SERVICE APPLY. After much prodding and reflection, Landis, now 88, made the decision to begin laying out his recollections for publication. Because I have written three books on presidential history, and because Landis’s publisher, Chicago Review Press, happens to be my publisher, an editor there asked me to read a copy of the galley and offer my comments, which I did quite eagerly. In fact, I was so taken with Landis’s backstory and, upon spending time with him, so drawn to the facets of his tale that are not answered in the book (whose details were first reported in The New York Times), that I probed further, maintaining a healthy dose of skepticism. And yet, as I got to know him during more than a dozen meetings this past year, I was won over by his integrity and by the way his account of what he witnessed in Dallas—and in the grave months of American mourning that followed—remained consistent and unwavering. Over time, Landis and I became close. As a result, I am writing this assessment of his narrative (and of his motives for coming out with his story) not only as a historian and armchair investigator but as Landis’s confidant. Twenty-three-year-old Paul Landis applied to become a Secret Service agent in 1958. He came from Worthington, Ohio, a suburb of Columbus, and had graduated from Ohio Wesleyan University 15 months earlier. A neighborhood boy, Bob Foster, who was friends with Landis’s sister, had joined the Secret Service two years before. After speaking with Foster, Landis thought being in the Secret Service sounded like the “coolest job in the universe.” WATCH NOW: Troye Sivan Takes a Lie Detector Test Landis was intrigued. But because he has always been slight of build, his immediate concern was whether he could meet the minimum height requirement (five feet, eight inches). During the physical exam, he stretched himself like a rubber band and, as he recalls, barely made it. 1 year for just $29.99 $8 + a free tote. Subscribe Now He started work in October 1959, at the time the youngest special agent, at 24. Just over a year later, John Kennedy was elected president; soon the young recruit was assigned the job of guarding the Kennedy children and, eventually, along with Special Agent Clint Hill, Mrs. Kennedy herself. Not all agents were given code names, but as a result of Landis’s new assignment, and because of his youth and boyish looks, he was eventually christened “Debut.” Landis found himself deep in the inner workings of Camelot, coinciding with the apex of Jackie’s popularity. As an international superstar, she was the Princess Di of her era, and Landis was on hand as the media followed her every move. Landis traveled with the first lady and her daughter, Caroline, to Italy in 1962. (John Jr., her young son, remained back home.) Landis was the agent who helped speed and accompany Jackie to the Otis Air Force Base emergency facilities when she went into premature labor with son Patrick, who died two days after his birth in August 1963. That October, at the suggestion of Jackie’s sister, Lee Radziwill, a trip to Greece followed for an excursion aboard the luxury yacht of the shipping magnate Aristotle Onassis. First lady Jackie Kennedy and Landis (second from left) in Italy; August 30, 1962FROM AP. Jackie Kennedy, her sister, Lee Radziwill, and Landis (far right) at a museum in Greece; October 8, 1963RAOUL FORNEZZA/AP. Then came November 22, 1963. A month after returning from Greece, Landis stood on the right rear running board of the Secret Service follow-up car, code-named “Halfback,” in the president’s motorcade as the vehicle headed from Dallas’s Love Field airport to a luncheon at the city’s Trade Mart. Landis was approximately 15 feet away when Kennedy was mortally wounded, a close witness to unspeakable horror. That horror was compounded when the president’s limo reached Parkland Memorial Hospital, where Landis and Clint Hill tried to coax Jackie to release the president, whom, by that point, she had cradled in her lap. Climbing into the back seat area, which had been spattered with blood and brains and bullet fragments, both agents, according to their subsequent accounts, gently encouraged the first lady to let go. As she did—standing up to follow Hill and another agent, Roy Kellerman, who lifted her husband’s body onto a gurney and raced into the hospital—Landis saw and did something that he has kept secret for six decades, he says now. He claims he spotted a bullet resting on the top of the back of the seat. He says he picked it up, put it in his pocket, and brought it into the hospital. Then, upon entering Trauma Room No. 1 (at that stage, he was the only nonmedical person in the room besides Mrs. Kennedy, and both stayed for only a short period), he insists, he placed the bullet on a white cotton blanket on the president’s stretcher. This secret, as it turns out, may upend key conclusions of the Warren Commission, the body created by President Lyndon Johnson to investigate the assassination. The sad fact is that Landis—though required to provide his version of events to the Secret Service (and, in a second report, to what would become the Warren Commission)—never sat for an interview before the FBI and never testified before the commission itself. He left the Secret Service months after the assassination and before the panel had finished its work and issued its report. Landis, to this day, attests that in the first few years following the assassination, he was simply unable to overcome his PTSD from witnessing the murder firsthand. He says that the mental image of the president’s head, exploding, had become a recurring flashback. He maintains that he desperately tried to push down the memories. He also says he felt unable to read anything in detail about the assassination until some 50 years later, starting in 2014, when he began to come to grips with all that he had witnessed, suppressed, and finally processed. Landis holding up John F. Kennedy Jr. on the South Lawn of the White House; 1962BY CECIL STOUGHTON/WHITE HOUSE PHOTOGRAPHS/JOHN F. KENNEDY PRESIDENTIAL LIBRARY AND MUSEUM, BOSTON. Landis, two years shy of his 90th birthday, remains vigorous. He exercises daily and plays golf once a week. He works a steady job as a security guard and a kind of welcome ambassador at the Cleveland History Center. But still, the JFK conspiracy hounds are legion, and with his new book’s publication, Landis can expect intense scrutiny. I made myself available to him as a way of helping to prepare him for what was to come. In writing this analysis of his account, I have tried to determine if his story was possible, seen against the mountains of evidence, not to mention newly released documents collected over the years by the Warren Commission, congressional probes, countless individual authors, and a kind of industry that has evolved, in which dozens upon dozens of “researchers” trade information and, inevitably, misinformation. Over the decades, there have been endless theories surrounding the assassination, but not one of them considered that a Secret Service agent might have brought a fully intact bullet, found on top of the rear seat of the limousine, into Parkland Memorial Hospital and placed it on the president’s stretcher. Not one. So there is virtue in looking anew at the evidence that was collected in 1963 and attempting to draw some tentative conclusions. Read the Book Here All products featured on Vanity Fair are independently selected by our editors. However, when you buy something through our retail links, we may earn an affiliate commission. PREORDER ON AMAZON My own conclusion is that Landis’s story, for several reasons, is not just possible; it in fact makes more sense than the core finding of the Warren Commission, known as the “single bullet” theory. That theory posits that a single bullet caused all of the wounds in Kennedy’s neck as well as all of the serious injuries to Texas governor John Connally—who was sitting in front of the president at the time—including the shattering of four inches of Connolly’s fifth rib and the fracturing of a major bone in his right wrist. Yet the bullet that Landis now claims to have discovered that morning emerged largely intact and only moderately damaged, its base having been squeezed in. By possibly placing the “magic bullet” theory in doubt, Landis’s disclosure raises as many questions as it answers. I will try to address some of them here. First, it makes sense to retrace the main tenets of the Warren Commission’s official version of the assassination. According to the panel’s final report, issued in September 1964, three gunshots rang out as the president’s limousine passed by the Texas School Book Depository building in Dallas. Witnesses’ auditory memory differed, their testimony ranging from two to six shots. Most, however, recalled hearing a trio of blasts. Three spent shells, in fact, were found under a window on the sixth floor of the book depository. Nearby, partially hidden by some cartons, a rifle with a scope was discovered, a cheap Mannlicher-Carcano. Lee Harvey Oswald, the man history identifies as the lone assassin, worked in that building. The commission determined that the three shots all came from the sixth floor of the book depository. The commission concluded that two of the three shots had hit the occupants of the limousine: One bullet had transited Kennedy’s neck and then, most probably, hit Governor Connally, and one had fatally wounded Kennedy, striking his head. (Connally survived the attack, later becoming President Richard Nixon’s Treasury secretary.) In the view of the task force, one of the shots had likely missed the limo and, though the conjecture was inconclusive, possibly struck a nearby cement curb, sending a fragment that hit a spectator some distance away, near an overpass, slightly grazing his face. But what of the ammunition itself? Two large bullet fragments were found in the front seat of the limo, and slivers of lead fragments were recovered from an area below the jump seat where the governor’s wife, Nellie Connally, had been sitting. President Kennedy and the first lady with Texas governor John Connally; November 22, 1963BETTMANN/GETTY IMAGES. At Parkland Memorial Hospital, on the day of the assassination, an additional intact bullet was discovered on a stretcher. Through testing, commission investigators determined that the copper-jacketed, 6.5-millimeter bullet matched the rifling of the Mannlicher-Carcano that had been abandoned on the sixth floor of the depository. Testing on the bullet fragments resulted in a similar finding. One key point to raise here concerns a fundamental underpinning of the Warren Commission report: the supposition that the retrieved intact bullet had been discovered on Governor Connally’s stretcher, not on Kennedy’s. It was from this assumption, in part, that the commission reached its pivotal conclusion: The available evidence indicated that “the bullet found on the Governor’s stretcher”—the single bullet—“could have caused all his wounds.” Over time, critics have referred to it as the “pristine” or “magic” bullet. Moreover, if that single bullet did not cause the damage, then ballistics tests performed at the time suggest it would have been almost impossible for Oswald to have fired all three shots within the tight, multi-second time frame derived from the other main piece of evidence of the assassination: the Zapruder film, a 26.6-second home movie recorded in color by bystander Abraham Zapruder, a local clothing manufacturer who happened to have brought along his Bell & Howell 8mm camera that day and, by happenstance, captured the entire sequence of the assassination. In his book, Paul Landis now says that when Jackie Kennedy stood up to enter Parkland, he looked over and saw that a bullet was improbably sitting on top of the rear seat of the limo, right around the spot where the limo’s detachable roof, which had been removed that day, would have otherwise been affixed to the trunk. Also, amid the blood and gore, Landis remembers, were two bullet fragments on the back seat, next to where Jackie had been sitting. Landis contends that he reached over, picked up the lone bullet nestled in the crevice, and decided to place it in his pocket, mindful that if it were left there, precariously, it might be overlooked, pilfered by an unauthorized passerby, or misplaced once the president’s body was removed. Accompanying the first lady into Parkland, he says, he brought the bullet with him and, without conferring with Mrs. Kennedy, his fellow agents, or hospital staffers, placed it on JFK’s stretcher, thinking it needed to be with the body for the autopsy. As such, he contradicts a key linchpin underlying the findings of the Warren Commission. The bullet—as Landis tells it—was not from Connally’s stretcher. From Landis’s description, three lines of inquiry emerge. First, how did a largely intact bullet wind up on the ledge of the back seat, where JFK had been riding when he was shot? Second, if Landis’s account is accurate, could Lee Harvey Oswald—who shot the president from a vantage point behind the motorcade—have acted alone, as the Warren Commission theorized? And finally, why did Landis decide to keep this information to himself for six decades? A view of the Kennedys’ motorcade CORBIS/GETTY IMAGES. There is no way to know for sure how the undamaged bullet ended up on top of the rear seat. But there seem to be only two real possibilities, both of which can be inferred from the Zapruder film. One way is that an undercharged bullet, having already been lodged in the president’s back from an initial gunshot, was jolted out of his body after a subsequent shot to the head caused his upper body to be thrown violently back against the seat, bouncing off of it with great force. A second possibility is that at some point in those hectic moments, the bullet fell out of the president’s back and onto the first lady’s clothing (her white-gloved hand did brush hard against his back, around where the bullet could have been embedded at the moment of the final shot). As one can see in the Zapruder film, Jackie, at this stage, climbed onto the trunk of the speeding car, possibly to look for or retrieve a portion of her husband’s skull—or out of sheer panic to take cover from further gunshots. In fact, the section of the back seat over which she stretched corresponds to the spot where Landis says he found the bullet. The autopsy evidence, as developed the night of the assassination, supports either one of these results. A short recap is in order. Initially, President Kennedy was declared dead at Parkland—his body lying face-up on the table after the surgical team had performed a tracheotomy, hoping to provide needed oxygen through a ventilator to keep him breathing (which by that time was described as gasping or agonal respiration). These emergency room doctors used what they believed was an entry bullet wound in the front of the president’s neck to create the tracheotomy. They were apparently unaware of a bullet hole in the president’s back. But later that night, an autopsy began at Bethesda Naval Hospital, near Washington, DC. During the procedure, doctors examined the president’s remains, only to discover a small bullet hole in the right shoulder, about five inches down from the top of the collar. This injury had gone unnoticed at Parkland since the president was declared dead before his body could be surveyed in its entirety. The Bethesda pathologists were puzzled when they probed the wound because it clearly was an entrance puncture, but it did not seem to have an exit wound, even though X-rays showed no bullet in the body. In fact, the shoulder wound was shallow. Two doctors found that they could not pass more than half a pinky finger into the opening. Metal probes likewise uncovered no path of the bullet through the body. Standing in proximity to the doctors were two FBI agents, Frank O’Neill and Jim Sibert, who had been dispatched by the bureau’s director, J. Edgar Hoover, to witness the autopsy and recover bullets or bullet fragments for the FBI lab. In their written statement, the agents discussed the frustration of the Bethesda doctors when they could not locate a bullet or exit wound for the projectile that had entered the president’s shoulder. That night, according to the agents’ account, one of them placed a call to the FBI lab and found out that a “stretcher bullet” had been discovered at Parkland. Doctors used this information to theorize that “this accounted for no bullet being located which had entered the back region and that since external cardiac massage had been performed at Parkland Hospital, it was entirely possible that through such movement the bullet had worked its way back out of the point of entry and had fallen on the stretcher.” The next morning, the Bethesda pathologists, as stated in their Warren Commission testimony, were told by Parkland doctors that the wound in the front of Kennedy’s neck was more than just the result of the tracheotomy they had performed. In fact, the Parkland team stated, there had been a bullet hole in the anterior (front) of the neck, and the ER staff had used that wound to create the tracheotomy. No one at the autopsy, according to FBI agents Sibert and O’Neill, had suspected there was a hole in the front of the president’s neck. With this new information, the Bethesda doctors revised their findings and assumed that the front wound was an exit for the bullet that had entered the president’s body from the back. Warren Commission members Hale Boggs, John Cooper, and Richard Russell leave the Texas School Book Depository after inspecting President Kennedy’s assassination sceneBETTMANN/GETTY IMAGES. There were problems with this inference. The neck and shoulder had not been sectioned by those performing the autopsy to establish a bullet path. And by the time of the revelation of the front-neck injury, the president’s body had been brought to the White House to lay in repose in the East Room. (The next day, it lay in state in the Capitol rotunda.) Further, the wound in the back, according to Silbert and O’Neill, did not align with the location of the front-neck wound; such a pathway would have required a bullet traveling from the book depository, behind the motorcade, to have changed course inside the president’s body so as to exit higher up, through the neck, without hitting any bone to alter its course. Agents O’Neill and Sibert didn’t buy it. “I do not see how the bullet that entered below the shoulder in the back could have come out the front of the throat,” O’Neill told the House Select Committee on Assassinations in 1978. Landis’s discovery of the bullet on top of the rear seat, if true, comports with the initial finding: that the bullet had lodged superficially in the president’s back before being dislodged by the final blast to his head. It also explains the “pristine” nature of the bullet. The genesis of the “single bullet” theory was twofold. First, the Zapruder footage showed Kennedy reacting to the bullet that hit him in the back—and then, apparently, exited through the front of his neck (his arms spasmodically began to rise, elbows out, fists shielding his throat)—about a second or so before Connally seemed to react to his own wounding. To the Warren Commission staff, that double reaction on the part of the two men was puzzling. Given the type of weapon Oswald was using, there would have been no way for him to have gotten off two firings in such a short span of time. Secondly, when the panel attempted to recreate the shooting in a manner consistent with the Zapruder film, FBI marksmen found that it took about 2.3 seconds to shoot, reload the bolt-action rifle, aim, and shoot again. Given Governor Connally’s reaction time, there did not appear to have been enough time for Oswald to have taken a second shot so quickly, let alone with any accuracy. Howard Willens, an assistant counsel to the Warren Commission, and the author of the 2013 book History Will Prove Us Right, wrote about this dilemma: “If the interval between the first and second shots covered a span of less than 2.25 seconds, the time estimated to be necessary for the assassin to fire two shots, it might suggest that a second rifle was involved.” The commission’s solution, however, championed by staff attorney Arlen Specter (who would become a US senator from Pennsylvania), was that the same bullet that hit Kennedy must have gone on to hit Connally on his right side. Connally’s second-later response was explained by the commission as a “delayed reaction” to an earlier wounding. But, as noted, that theory depended on the single bullet having been found on Connally’s stretcher at Parkland Memorial Hospital, not on Kennedy’s stretcher. The panel’s members speculated that the bullet, after causing Kennedy’s and Connally’s wounds, ended up superficially stuck in Connally’s left leg and must have dropped onto his stretcher once inside the hospital. That said, the original evidence from 1963 is far from clear on this point. President Kennedy stands on the Texas airstrip with Jackie Kennedy and Governor John ConnallyBETTMANN/GETTY IMAGES. Governor Connally recovering in his hospital room with his wife, NellieBETTMANN/GETTY IMAGES. The provenance of the bullet is also important in supporting or refuting Paul Landis’s purported memory. How was that bullet found? And how did it make its way to the FBI lab in Washington, DC, on the night of the assassination? Landis’s recollection, as stated above, is that he found the undeformed bullet on top of the back seat of the limousine. “It was resting in a seam where the tufted leather padding ended against the car’s metal body,” he writes. When Jackie Kennedy stood up to follow her husband into the hospital, he saw it. He picked up the bullet, worried that souvenir seekers or others might take it or move it. Upon arriving inside the emergency room, as stated above, he was jammed in with the first lady and a gathering horde of doctors and nurses. Standing near the feet of the president’s body, Landis left the bullet on his stretcher, as he believed it was crucial evidence and needed for the autopsy, which, under Texas law, should have taken place in Dallas. But then a new chain of events overtook the gruesome sequence surrounding the assassination. A decision was made to transfer the president’s body, along with the first lady, Vice President Johnson, and others, back to Air Force One at Love Field. And with new tasks taking precedence for Landis—and the overwhelming national shock of the first assassination of an American president in 62 years (since the death of William McKinley in 1901)—the special agent simply never gave the bullet a second thought, he says. He had left it where someone would find it. Landis didn’t make reference to the bullet in either of the two reports he submitted, hastily written in the turbulent days following the assassination. One short file, written two days after the funeral, didn’t even mention Parkland Memorial Hospital. A second, typed three days later—a day after Life magazine journalist Theodore White interviewed Jackie at the Kennedy compound in Hyannis Port, in what became known, famously, as the “Camelot” interview—was drafted during a time of deep shock and trauma. That Thanksgiving, November 28—three days after the state funeral at which world leaders marched behind Mrs. Kennedy in the streets of Washington, DC—Landis and Hill traveled to Hyannis Port in a security capacity, protecting Jackie and her children. The agents had no time off to regroup or get their bearings. Sleep had eluded them. Landis had been up for practically four days straight. In the months after Lyndon Johnson was sworn in and assumed the presidential reins, Landis’s role switched from being part of the overall White House protection group to working full time for the former first lady. (Congress passed an act to authorize this service.) With this change of responsibilities, he found it hard to think of much beyond the weeks ahead. And if his thoughts did migrate back to November 22, he dwelled on the horrific scenes of the assassination, and rarely on what he says he considered a minor detail: the fact that he had picked up a bullet and placed it next to the president’s body. The evidence from 1963 makes it fully plausible that the stretcher on which the bullet was found could have been President Kennedy’s. How so? A Parkland Memorial Hospital engineer, Darrell Tomlinson, was asked on November 22, before the president’s remains had been taken from the hospital to travel back north, to set the controls of the elevator in the emergency area—the one that had taken the wounded Governor Connally up to the second floor for surgery—so that the elevator would only be operable manually. The security team had determined that only people with official clearance would be allowed access; Tomlinson was instructed to control who got on the elevator and where they would go. When he pushed the button to open the elevator, he later recalled, there was a stretcher in the elevator—one that the Warren Commission presumed was Governor Connally’s stretcher, returned from the surgery floor. Tomlinson testified that the stretcher had some sheets on it and a white covering on the pad, but no bullet. He moved the stretcher out of the elevator and placed it against a wall. However, Tomlinson testified that there was another stretcher already in the hall, which had been placed in front of a men’s restroom in the corner. That stretcher had bloody sheets and some used medical paraphernalia on it. Tomlinson said that sometime later, “an intern or doctor,” in order to use the bathroom, pushed the stretcher out of the way but failed to return it to its spot against the wall after leaving. Tomlinson roughly pushed it back against the wall, and when he did so, he claimed, a bullet rolled out from under the mat. This was clearly not Connally’s stretcher. Jackie Kennedy looking into the ambulance, November 22, 1963. Landis stands just behind her (third from right).BETTMANN/GETTY IMAGES. Arlen Specter, who had traveled to Dallas to take Tomlinson’s deposition in March 1964, was thunderstruck when Tomlinson relayed this scenario. To judge from a transcript of that conversation, Specter spent much of the remainder of his time with Tomlinson essentially trying to talk him out of his recollection, causing a distressed Tomlinson to say he just was not sure about his memory. But the Q&A itself clearly suggests that Tomlinson, unprompted and unbadgered, had a cogent recollection that a bullet, wherever else it ultimately ended up, had come from the stretcher that had already been left in the hall in front of the men’s room. In its final report, the Warren Commission mentioned nothing about this detail from Tomlinson’s account. Instead, the panel largely dismissed Tomlinson’s testimony, writing that even though he was “not certain whether the bullet came from the Connally stretcher or the adjacent one,” the commission “has concluded that the bullet came from the Governor’s stretcher.” And what of the contemporaneous evidence from the witnesses who provided care to the governor in the emergency room and on the surgery floor? When Connally was brought in from the limo, he was in great distress. He was taken to Trauma Room No. 2, where his clothes were immediately cut off. No one saw a bullet sticking out of his leg when his pants were removed. Neither was a bullet seen on the stretcher nor found in his clothing. Once stabilized, he was wheeled to the emergency room elevator and taken to surgery on the second floor. Connally was then transported from the emergency room stretcher and placed on an operating table. No one testified to having seen a bullet on that stretcher. All of the medical paraphernalia on Connally’s stretcher was removed by a nurse before the stretcher was put back in the elevator. And the attendant who placed that stretcher onto the elevator did not recall having seen a bullet. Darrell Tomlinson, however, went further. He said that as soon as he found the bullet, he alerted O.P. Wright, the chief of security at the hospital. Wright, in turn, gave the bullet to Secret Service agent Dick Johnsen, who was in the process of leaving the hospital with the president’s casket and Mrs. Kennedy. Johnsen wrapped the bullet in a handkerchief and placed it in his pocket. He then rode on Air Force One back to Washington. Johnsen was assigned to sit with the casket and near Mrs. Kennedy in the back of Air Force One on the return journey to the nation’s capital. The body, the widow, and the bullet all returned to Washington on the same plane, in close proximity. When Johnsen got back to the White House, he typed a short note to describe the bullet and how he ended up with it. “The attached expended bullet was received by me about 5 min., prior to Mrs. Kennedy’s departure from the hospital,” he wrote. “It was found on one of the stretchers located in the emergency ward of the hospital. Also on this same stretcher were rubber gloves, a stethoscope and other doctor’s paraphernalia.” Johnsen dated his note: “7:30 p.m., Nov. 22, 1963.” Johnsen then handed over the bullet to the director of the Secret Service, James Rowley. Rowley, finally, gave the bullet to the FBI that very night; it was signed in as the first piece of evidence in the assassination investigation, labeled with the designation “Q1.” That evening, the initial supposition was that the bullet had come from JFK’s stretcher because the autopsy doctors at Bethesda, attempting to understand the whereabouts of the bullet that had entered Kennedy’s back, thought it might have been lodged in his back and then fallen out when rigorous chest massages were performed at Parkland. It was only after the autopsy (and after the president’s body had been moved to the White House) that Parkland doctors told the pathologists that they had used a bullet wound in the front of Kennedy’s neck to make a tracheotomy. Upon hearing this, the autopsy doctors tentatively revised their thesis and surmised that the bullet that entered Kennedy’s back must have exited through the front of his neck. And so the problem started: The Warren Commission could not explain what happened to the bullet if it exited through the front of Kennedy’s neck. Howard Willens described the Warren Commission staff’s internal debate: “There was one basic question that now seems very simple,” he wrote. “Where did the bullet go after it exited the president’s neck?” Paul Landis, in effect, answers that question: It ended up in a crevice on top of the back seat. It seems unlikely that the bullet traversed the president’s body and exited through the front of his neck. Maybe the bullet entered the president’s back only superficially; these WW II–vintage bullets, after all, were notoriously undercharged with gunpowder. If this were the case, it might have indeed fallen out when he was violently struck with the final shot; when Mrs. Kennedy, at one point, pushed him down onto the seat; or when she clambered onto the trunk, the bullet falling off of her and onto the top of the back seat. To be fair to the record, the Warren Commission’s findings suggested that Kennedy’s stretcher was not the stretcher in the elevator lobby because the nurses who had treated the president testified that once they’d been informed that a casket had arrived at Parkland, they had removed bloody sheets from his stretcher before moving it across the hall to Trauma Room No. 2. But given the blood-soaked scene described by all of the medical personnel in Trauma Room No. 1, it is not unreasonable to assume that an orderly in Trauma Room No. 2 preemptively moved the president’s stretcher into the hall, stained sheets, medical paraphernalia, and all, to be further cleaned up by other attendants. Attorney General Robert Kennedy, Senator Edward Kennedy, the first lady, and Landis (far right) walking during the funeral procession on November 25, 1963BETTMANN/GETTY IMAGES. What does all this mean when considering whether Lee Harvey Oswald, as proposed by the Warren Commission, was the lone assassin? It certainly raises the stakes that another shooter might have been involved. First, if the “pristine” bullet did not travel through both Kennedy and Connally, somehow ending up on Connally’s stretcher, then it stands to reason that Connally might have actually been hit by a separate bullet, coming from above and to the rear. The FBI recreation suggests that Oswald would not have had enough time to get off two separate shots so quickly as to hit Connally after wounding the president in the back. A second shooter must be considered. And what about the bullet wound in the front of Kennedy’s neck? In one of the earliest critiques of the Warren Commission report, Josiah Thompson, author of Six Seconds in Dallas, proposed, not unreasonably, that the front-neck wound might have come from a bullet or bone fragment that was driven down and exited through the president’s throat from the final blast to his skull. But there are other, darker explanations arising from the secrecy surrounding the X-rays and photographs taken at the autopsy and then not made public for decades. Jerrol F. Custer, the principal X-ray technician at the autopsy, testified in 1997 that there were several small metallic fragments in the cervical spine (the spinal region directly below the skull), which were visible in an X-ray, and that this was one of three X-ray exposures he took that night that went missing from the collection in the National Archives. This might have contained evidence of a shot from the front of the motorcade—a frangible bullet that disintegrated into tiny pieces after entry into the body. A heavy lift, for sure, but medical staffers who saw the front-of-the-neck wound before the tracheotomy believed it was an entrance wound because of its neatness. Though some observers, down through the years, have mentioned the possibility of a second shooter, perhaps positioned on the so-called “grassy knoll” area along the route of the motorcade, neither this article nor Landis’s book has the insight or forensic expertise to hazard any new conclusions in this area. Others will have to analyze the evidence in full to see where it now leads. But, without question, this revelation will spark major debates. And that should not be surprising. The Warren Commission report, though lauded right after it was issued, has had its share of credibility detractors as time has passed. In 2013, a week before the 50th anniversary of the assassination, public opinion polls found that more than 60% of Americans believed the president’s murder had not been the work of one man, as the commission contended, but part of some kind of conspiracy. There are many reasons for this skepticism, including a growing public distrust toward governmental pronouncements. And yet a chronic source of questioning has been the commission’s claim that a single bullet wounded both Kennedy and Connally, emerging mostly undamaged after having done so much damage. Perhaps Landis’s revelations will offer a critical mass of additional conjecture to prompt a reassessment of the “magic bullet” theory. The more confounding question, in my view, is a simple, human one: Why did Paul Landis decide to keep this information to himself for 60 years? The answer is complicated. But it is in many ways understandable if one considers his predicament at the time and in the years that followed. Upon leaving the bullet on Kennedy’s stretcher, Landis explains today, he felt that he had done the right thing, expecting an autopsy and mindful of the need for the bullet to remain with the body. Like all of the Secret Service members on hand that day—and, indeed, the entire nation—he was also racked with grief and loss (to say nothing of PTSD, which was an unrecognized condition at the time). For Landis, however, a man who had been a constant presence in his life had been slain right in front of him—a man whose wife’s safety had been, in part, his own responsibility. But soon the intensity of the moment enveloped him. Landis’s focus turned to responding to Mrs. Kennedy at Parkland; attending to the needs of the family upon the return of the remains to the capital; accompanying Jackie and the president’s brother Robert F. Kennedy during the nine-hour wait at Bethesda as the autopsy proceeded; remaining on protective duty during one of the riskiest state funerals in history; and then staying on in Jackie’s peripatetic orbit for the next several months—unable to find the time to properly attempt to cope with the raw trauma he had experienced. In May, nearly six months after the assassination, Landis realized that the ordeal had taken its toll; concerned about his own mental health, he decided he couldn’t take it anymore. By August, at age 29, he had left the Secret Service. At the time, the Warren Commission had not issued its report, nor had Landis been interviewed for it; the public had not yet heard of the “single bullet” theory. From that point onward, Landis now says, he withdrew from his more public-facing life, adamantly refusing to read more about the assassination. He avoided most requests for interviews by the media. He assumed, without looking at the final report, that the Warren Commission must have gotten it right. Then, around 2010, things began to thaw. A project by Secret Service agent Gerald Blaine brought Landis out of his shell. Blaine was writing a book, The Kennedy Detail, with Lisa McCubbin, and Landis agreed to participate, mainly, he says, because his friend Clint Hill had also signed on. The agents met in Dallas to film an accompanying documentary, and Landis discovered he was not alone in feeling guilty and isolated following the assassination. But even then, Landis was not yet prepared to tell his own story. Jackie Kennedy mourns at the funeral with children Caroline and John, brothers-in-law Ted and Robert, and LandisFROM GETTY IMAGES. That all changed in 2014 when Landis finally read a 1967 book on the assassination—a gift from a friend. When he began to page through Six Seconds in Dallas, by Josiah Thompson, he first saw that CE 399—the “pristine” bullet—was believed to have come from Governor Connally’s stretcher. Landis claims today that he immediately reached out to Clint Hill to tell him that he brought the bullet into Parkland and left it on the president’s stretcher, not the governor’s. He needed to correct this record. One issue at the time was that the Secret Service was struggling with very public scandals, ranging from breaches of the White House grounds by intruders to accusations of liaisons with prostitutes in South America. And so, in deference to the troubles roiling the agency, Landis decided to remain mum. In late 2015, however, Landis had a change of heart, he insists. He spoke with former Secret Service director Lewis Merletti, who had lived nearby, in Beachwood, Ohio, as the former head of security for the Cleveland Browns. Landis told Merletti of his secret; soon thereafter, Landis began the odyssey of carefully writing his book. In the intervening seven years, he struggled with his conscience. His guilt, in my estimation, stemmed in part from a creeping concern that others might accuse him of having done something wrong by moving the bullet. Moreover, he must have worried, to some degree, about not having spoken out about finding the bullet in the first place—and not having sought to clarify the record more speedily once it became apparent to him that many historians and the public at large had cast doubt on the findings of the Warren Commission. Another factor amplifying his angst, I would imagine, was that the longer he remained silent, the harder it became to speak out. Adding to his concerns, I’m sure, was the fact that Landis had been criticized—unfairly, in my view—for having stayed out most of the night before the assassination. Over the years, journalists and others have written sporadically about how “nine members” of the Kennedy Secret Service contingent went out drinking into the wee hours of November 22. A detailed report, with statements by the agents, was gathered following the assassination, and those comments are included as part of the record in the Warren Commission report volumes. That investigation showed that around midnight on November 21, the Secret Service agents arrived in Fort Worth at the Hotel Texas with the president and first lady. Kennedy had barnstormed the state that day with events and motorcades in San Antonio and Houston. Though exhausted and famished, the agents were nonetheless used to putting in long hours in service to a youthful, hard-charging—and sometimes hard-partying—president. Double shifts were not uncommon. Some members of the group, seeking food, were encouraged by Merriman Smith, a respected wire service reporter with United Press International, to visit a complimentary room set up by the Fort Worth Press Club in a nearby hotel. By that late hour, however, the food was gone. Several agents had a beer or two. Some had mixed drinks. Landis, for his part, professed to having had a scotch and soda. Still hungry, the agents were told of a late-night coffeehouse, The Cellar, that might have something to eat. The Cellar was known for its “beatnik” performers—poetry-reading and guitar-playing—and a female waitstaff that wore skimpy outfits. Landis was among the agents who went to The Cellar, where, as he mentioned in one of his 1963 statements to authorities, he had two “Salty Dicks”—a local concoction that might or might not have had alcohol. Landis attested that he drank grapefruit juice, which he says today had no alcohol. At 4 a.m. CT, he says, he left to retire to his hotel. By 8 a.m., Landis had breakfast and was asked by Roy Kellerman, the man in charge of the entire unit, to assist in protection for the president, who had decided to give an impromptu speech in front of the Hotel Texas. He later helped escort Mrs. Kennedy to a breakfast sponsored by the Fort Worth Chamber of Commerce at the hotel. He contends that he and his fellow agents that day were amped up by the heightened alertness involved with a presidential motorcade. They were likely stoked, as well, by the adrenaline of the crowds and the excitement and pomp. To a man, everyone involved who was interviewed for the Warren Commission said that all of the agents, including those who had gone out the night before, showed up on time for work, exhibiting no effects of excess drinking. Photos from that morning and day, in fact, show Landis bright-eyed and working diligently in his protective capacity. Columnist Drew Pearson, however, got wind of the late-night excursion and in the week following the assassination published an exposé about the agents’ behavior. It caused an uproar. The incident, in fact, has continued to attract attention: In 2014, author Susan Cheever, finishing up a book called Drinking in America, reconstructed her own narrative of the evening for Vanity Fair, quoting both Paul Landis and Clint Hill. I believe there is little reason to think that late-night alcohol consumption contributed to the agents’ response times or decision-making that day. Hill, who had been out with the others, reacted quickly in trying to get to the limo. In a six-second incident, he did not make it in time. The agent on the running board in front of Landis, Jack Ready, started to jump off himself but was called back by the agent in charge of that car, Emory Roberts, who feared that Ready might be run over and realized that Hill was already on his way toward the vehicle. Roberts had not been out the night before, drinking or otherwise. The same is true of the only agent who really had a chance to avert disaster, driver Bill Greer, who might have taken evasive action with the president’s limo once the shooting started. The agent next to Greer in the front passenger seat of the presidential limo, Roy Kellerman, likewise didn’t react in time. Kellerman had not been out drinking; he had gone straight to bed once they checked into the Hotel Texas. Landis recognized that, despite any accusations to the contrary, there was nothing he could have done to prevent the tragedy. He also knew that he risked being criticized for having stayed out most of the night and having violated Secret Service policy by drinking any alcohol that might possibly impair him “if called upon to perform an official duty.” This no doubt contributed to his overall reluctance to come forward. More to the point, I sense that he had an underlying guilt about what he might have done. He had found a bullet—the first piece of evidence logged into the record of the assassination of a US president—and then he went on his way, alone, in private. He understands today how history might have changed had he told the pathologists at Bethesda that night where the “stretcher bullet” had come from—but he was not the one in the autopsy room (Kellerman and Greer were), and he had his hands full with the stream of family and mourners who arrived on the hospital’s 17th floor to console Jackie. Landis is an upright, respected, private man. His moral authority and personal credibility have always been two hallmarks of his persona. My gut tells me that in his own way, he didn’t want to be the guy who had done a good deed under intense pressure, and then, forevermore, was raked over the coals for it. Which is how society often treats people these days. That anxiety might well have led to a sense of regret—even though his initial actions had been completely laudable. In addition, he was in his late 20s at the time, a man whose values were grounded in those of the 1950s and ’60s. Silence and discretion, to him, had always been virtues. And he didn’t feel that it was appropriate to change his stripes and “go public”—drawing attention to his own behavior—when conspiracy theorists ran rampant, when other agents had been in the press over the years, and when President Kennedy had been killed, in effect, on his watch. All of this, I contend, contributed to his years of silence. But nothing, as I see it—and as Landis himself sees it—should detract from the fact that he has now come forward with his version of what happened on that dreadful day. And history will be the better for it. James David Robenalt is an attorney and Washington Post contributor. He is the author of four nonfiction books: The Harding Affair; Linking Rings; Ballots and Bullets; and January 1973: Watergate, Roe v. Wade, Vietnam, and the Month That Changed America Forever. More Great Stories From Vanity Fair How Four Billionaire Techno-Oligarchs Are Creating an Alternate Reality Exclusive New Details About Meghan Markle’s Wedding Dress A Bird’s-Eye View of Everything Happening at This Fall’s Film Festivals—Without the Stars A Serious Setback for Trump’s Plan to Get Reelected and Pardon Himself Meet Kyle Deschanel, the Pretend Playboy Who Seems to Have Fooled Half of Manhattan The Ultimate Guide to Fall Movies From the Archive: A Father’s Account of the Trial of His Daughter’s Killer End-of-summer sale! Take 25% off at the VF Shop James Robenalt SEE MORE BY JAMES ROBENALT » READ MORE POLITICS Former President Donald Trump (Finally) Gets Invite To Queen Elizabeth II’s Memorial Service Former U.S. presidents Obama, Clinton, Bush and Carter also received invitations to Washington, D.C. ceremony. BY KELLY RISSMAN POLITICS “Fuck Biden,” “Don’t Tread on Me,” and a Wisconsin Death Trip for Our Times The author knocks on the doors bearing the darkest symbols, behind which lie guns, ammo, antisemitism, antiabortion dogma—and a belief in the coming civil war. BY JEFF SHARLET POLITICS Exclusive: Inside the S--tshow That Was the Trump-Biden Transition New revelations about how one Trump staffer helped preserve the transfer of power—from the forthcoming book on the Biden White House, The Fight of His Life. BY CHRIS WHIPPLE HOLLYWOOD Paul Newman and Joanne Woodward’s Daughters Appreciated the “Fuck Hut” Detail Too “I have to admit I read that and I was like, Go mom,” laughs Clea Newman Soderlund, speaking about her father’s posthumous memoir, The Extraordinary Life of an Ordinary Man. BY JULIE MILLER Get 1 year for $29.99 $8. Plus, a free tote. Join now MORE FROM VANITY FAIR Newsletters Subscribe Digital Edition Inside the Issue FAQ CONTACT Advertising Careers Contact VF Customer Service Condé Nast Store VF Media Kit Accessibility Help MANAGE PREFERENCES © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights. Vanity Fair may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices CN Entertainment Select international site United States We and our partners store and/or access information on a device, such as unique IDs in cookies to process personal data. You may accept or manage your choices by clicking below or at any time in the privacy policy page. These choices will be signaled to our partners and will not affect browsing data.More Information We and our partners process data to provide: Use precise geolocation data. Actively scan device characteristics for identification. Store and/or access information on a device. Personalised ads and content, ad and content measurement, audience insights and product development. List of Partners (vendors) I Accept Show Purposes",
    "commentLink": "https://news.ycombinator.com/item?id=37454707",
    "commentBody": "New JFK assassination revelation could upend the lone gunman theoryHacker NewspastloginNew JFK assassination revelation could upend the lone gunman theory (vanityfair.com) 254 points by morby 22 hours ago| hidepastfavorite350 comments neonate 15 hours agohttp:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230910120240&#x2F;https:&#x2F;&#x2F;www.vanity...https:&#x2F;&#x2F;archive.ph&#x2F;W6A0z a2tech 12 hours agoprevI used to be passingly interested in the conspiracy part of the JFK assassination until I watched this EXTENSIVE in length and sourced video on the assassination: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DC8tO16xdrYIt&#x27;s all very logical and straightforward. reply pliesfan97 11 hours agoparentI personally believe it&#x27;s somewhat possible that there was some CIA involvement in JFK&#x27;s assassination. I did not watch the entire video, but the part that addresses potential CIA involvement seems to have 2 main flaws IMO:1. It only addresses the Vietnam War as a potential motive and \"debunks\" this motive. Geopolitics is complicated, and there are countless other potential motives, especially surrounding Cuba and the CIA&#x27;s involvement there (Bay of Pigs, etc). The parts of the video I watched (including part 2) did not seem to address this at all. Eliminating one motive does not by any means eliminate the possibility of CIA involvement.2. The video&#x27;s creator seems to assume that CIA&#x27;s involvement would consist of \"hiring\" Oswald to perform the assassination and that Oswald would have full awareness of the plans, etc. This is not the only scheme in which a conspiracy may have taken place, and in fact seems like a highly unlikely and unsophisticated scheme. It seems much more likely that Oswald was \"used\" rather than \"hired\" and that he was either convinced or coerced to shoot Kennedy. This is how murderous intelligence organizations do their dirty work (the CIA is known to have killed people) - via coercion, power, politics, propaganda, and not via direct orders or contracts. Assuming my theory is correct (of which I do not have certainty), Oswald likely had his own motives to wanting to shoot Kennedy, but it required a conspiracy to actually get him to carry through with it. This model of the relationships and dynamics involved seems entirely foreign to the video&#x27;s creator and is completely unaddressed.In general, discourse around the JFK assassination and potential conspiracies focuses way too much on the shooting itself - ballistic physics, positions of possible shooters, analysis of film. This is a complete distraction from the more important question which is around Lee Harvey Oswald&#x27;s incredibly suspicious relationships and contacts with known CIA people. reply mulmen 9 hours agorootparentThis is what’s fascinating and terrifying about conspiracy theories. You’re clearly an intelligent person who can articulate their thoughts. But none of this is well reasoned. In the face of compelling evidence you propose vague, unsubstantiated alternative theories. This is a bottomless pit. It’s not hard to make up a fantasy to explain reality. But that way lies madness. Reasonable people can disagree and arrive at the truth. But constantly inventing unsubstantiated counter arguments simply delays the inevitable conclusion to the detriment of everyone. reply harry8 8 hours agorootparent>But none of this is well reasoned.Conjecture: A is not the culprit because motive xyz does not check out.Reasoning: That doesn&#x27;t exonerate A, who could have other motives.Without agreeing with it, that looks perfectly well reasoned to me.Compelling evidence exonerating the CIA you say? Well ok, I&#x27;ll believe that when I see it, just like any other evidence from gravity onward. The CIA&#x27;s docs haven&#x27;t been declassified and released. reply mulmen 5 hours agorootparentThe meta argument is the one which is unreasonable. Forming reasonable small arguments is easy. People engage them easily. But because so many can be created so cheaply it’s possible for people’s minds to cloud. reply harry8 3 hours agorootparentOk so you acknowledge it was well reasoned and you are apologising to op for saying it wasn&#x27;t. And moving forward you&#x27;ve come to:So many well reasoned arguments can be created so it is possible for people&#x27;s minds to cloud.I have no idea what you are trying to say here but it seems like it&#x27;s not contributing anything much to the discussion. Perhaps your mind clouded before you wrote it?edit: did you edit your original post &#x2F;after&#x2F; I replied? reply speleding 1 hour agorootparentprevI would say that a compelling argument against the CIA being involved is that they would have done a way better job of covering their tracks if it really was them. Think about it: Professional spooks who know they would probably receive a death sentence for treason if caught planning an assassination attempt on the president.And think about the number of people involved in an organisation like that who pledged allegiance to serve their country and now have to go along with killing the president. Just so incredibly unlikely. People watch too many cloak and dagger movies. reply shrimpx 1 hour agorootparentprevA lot of it is fueled by the govt continuing to refuse to release the JFK papers. reply nerdponx 8 hours agorootparentprevSeems well-reasoned enough to me. That doesn&#x27;t make it true, but given that the official story has some practical problems, it doesn&#x27;t seem like something we can dismiss out of hand. reply jasonm23 4 hours agorootparentprev> Reasonable people can disagree and arrive at the truth.This seems untrue in the current media landscape. It is more likely people will disagree and then drift back to their echo chamber. reply irrational 8 hours agorootparentprevThis seems to presuppose the “inevitable conclusion” is true. reply unethical_ban 7 hours agorootparentprevConspiracies have several variables, from feasibility in general, to number of collaborators, to motives, to methods of discovery.Assassinating a popular, progressive president in the 1960s was very doable and didn&#x27;t take a lot of people to pull off. It will never be settled as to the true motive of the killing.Compare this to \"the moon landing was faked\" or \"9&#x2F;11 towers were not only an inside job, but imploded\" and they are much less plausible. reply flagrant_taco 7 hours agorootparentprev> It’s not hard to make up a fantasy to explain reality.Unfortunately this isn&#x27;t limited to conspiracy theories. We spent the better part of the years with leaders and scientists forcing similarly baseless explanations down or throat rather than taking the time to collect the data that actually supported the politically favorable talking points. There were countless fantasies made up to explain the risks of the specific virus, efficacy of masks, net benefit of vaccination, etc. reply jasonm23 4 hours agorootparentprev> This is a complete distraction from the more important question which is around Lee Harvey Oswald&#x27;s incredibly suspicious relationships and contacts with known CIA people.Distraction is the point.Distraction from several key points which beg a series of questions.- Dulles formed the CIA from the OSS.- Dulles hated Castro and thought he&#x27;d trigger a full scale invasion by launching the Bay of Pigs \"raid\"- Dulles was not all that happy when that plan, not only failed, but triggered his dismissal from the agency he formed and headed up, by JFK.- Dulles, may not have been a psychopath, but he calmly watched his sister almost drown in the ocean, before their finally mother rushed to save her. reply mc32 7 hours agorootparentprevJFK was forced to go along with the bay of pigs (he was against it) on the other hand he got us too close to the brink of annihilation --one can imagine these two things would displease some people --whether that rises to assassination by an internal faction is unknown --though maybe if they released all material that was supposed to be released we&#x27;d maybe have a better idea. reply dave_sullivan 9 hours agoparentprevI suppose it&#x27;s impossible to prove the specifics of the conspiracy, but that Jack Ruby, a guy running strip clubs for the mafia, takes it upon himself to publically shoot Lee Harvey Oswald kind of proves to me that there was some kind of conspiracy. What other explanation could there possibly be? What Oswald might have said if we were kept alive... no one will ever know. But if there was nothing there, why did Jack Ruby kill him? Temporary insanity, deeply patriotic fan of JFK, or tying up loose ends on orders -- what makes more sense? reply hilbert42 7 hours agorootparent\"But if there was nothing there, why did Jack Ruby kill him?\"I was a teenager living outside the US when I learned about JFK&#x27;s assassination. It was a Saturday morning where I was and I remember it vividly more from the shock reaction of my parents than from the radio news report (I heard the news first and told them about it).From that moment onwards the news coverage was intense. When Ruby shot Oswald we were struck with a sense of disbelief—even with my naïve sense of US politics, law enforcement, etc. the first things that came to mind were why would the seemingly sleazy Ruby want to shoot Oswald at all, second, how did US law enforcement let it actually happen. Either the US was in more chaos than the news was reporting and it was a free-for-all over there, or that Ruby&#x27;s ulterior motive was more than just loyalty to the US&#x2F;JFK.I wasn&#x27;t alone in thinking this, many were of this opinion and it was the first thing that came to our minds. I&#x27;d stress we&#x27;d formed that opinion within days if not hours of the news—that&#x27;s well before any of the conspiracy theories or &#x27;grassy knoll&#x27; stories emerged. reply thephyber 2 hours agorootparentprev> But if there was nothing there, why did Jack Ruby kill him?That line of thinking can power any conspiracy theory.Do you really think there are only 3 options for his motives? Why not “an impulsive criminal businessman with a gun filled with rage in the hours after a presidential assassination in his town during a Cold War looks for a way he can personally feel some modicum of control in a world that is mostly chaotic”. reply UberFly 9 hours agorootparentprevSome who knew Ruby theorized that he wanted to be a national hero by killing JFK&#x27;s killer. Those who knew him said he was fairly emotional and hot-headed too. reply a2tech 9 hours agorootparentThat is essentially what they say in the video. reply Tmpod 11 hours agoparentprevRecently watched this detailed and well sourced video by LEMMiNO on a particular prespective, might be of interesting for you: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5u7euN1HTuU reply bni 2 hours agorootparentThe production value in this one is amazing reply sireat 2 hours agoparentprevFascinating video and indeed pretty straightforward.However, the bank robber analogy starting at 26mins https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DC8tO16xdrY&t=1601s does not sit quite right.You can&#x27;t just stick with one theory and keep fitting other facts to that theory forever - there is going to be a breaking point.To keep going with that particular bank robber story - Jake.In the example barring other facts, it is 99.9% probable that Jake indeed is the bank robber.What if instead of finding $9k out of $10k, police only find $5k out of $100k on Jake?What if not only talking to his girlfriend about robbing the bank he also talked about robbing the bank at the bar the previous week?What if there was an amateur theatre troupe at that bar that night?What if one of those actors was also an accomplished make up artist and high speed driver?Okay, the story keeps getting sillier.Even with these new facts the prosecution would still win.Let&#x27;s add a new fact security cameras at a bar also show Jake, with similar timestamps to the bank&#x27;s cameras. There are 3 more patrons that are willing to swear it was Jake.An old lady reports that she saw a car drive up at a high speed to Jake&#x27;s car and leave a package.At that point we have a problem with being so sure on Jake being the guilty one. There is some reasonable doubt now.My point is you can never be 100% sure. All you can do is adjust priors.With JFK as it currently stands we might say 95% chance that Oswald was the lone gunman and 80% that he acted completely alone.We can also say there is a 40% probability there was a conspiracy to assassinate JFK, there might have been even more than one, but those might have had nothing to do with Oswald. reply fsckboy 7 hours agoparentprevOswald Acted Alone... you mean lone gunman acted alone? or do you mean nobody else with prior knowledge? reply koolba 21 hours agoprev> Landis saw and did something that he has kept secret for six decades, he says now. He claims he spotted a bullet resting on the top of the back of the seat. He says he picked it up, put it in his pocket, and brought it into the hospital. Then, upon entering Trauma Room No. 1 (at that stage, he was the only nonmedical person in the room besides Mrs. Kennedy, and both stayed for only a short period), he insists, he placed the bullet on a white cotton blanket on the president’s stretcher.The revelation is that the bullet was not lodged in JFK and did not fall out while shaking about on the gurney. reply morby 21 hours agoparentI would probably add some major points to this synopsis. The bullet was believed to have been on Connally’s stretcher. It is the “magic bullet”. The pristine bullet that was supposed to have hit JFK and Connally both. The assumption here is that it did not penetrate through JFK. That it came from the wound in his back. This would upend the investigative findings that the bullet in this back was responsible for the neck wound and the injury to the governor. It’s a rather drastic change to the record. reply morby 21 hours agorootparentTo add to that. The author details how this new detail subsequently alters the version of events. Namely it suggests that the bullet that hit JFK in the back and hit Connally were two different bullets and that they could not have been fired at that rate (the rate suggested by the video evidence) with the weapon used by Oswald reply lucas_membrane 6 hours agorootparent> could not have been fired at that rateThe stories all say that the FBI reported the minimum time to fire that rifle was 2.25 seconds. How was that determined? How can a supposedly experimental result like that have no error bars? Was it determined by repeated firings of the gun found in the sniper&#x27;s nest, or by another similar gun presumed to be an exact duplicate (of a 20-year old mail order gun?) for purposes of that measurement? It is known that Oswald spent some considerable time (maybe and hour or several, I don&#x27;t remember) &#x27;dry firing&#x27; the rifle the night before. Could he perhaps have developed speed superior to that of whomever the FBI asked to do that experiment? Has the 2.25 second minimum ever been replicated? How could the person trying to fire the gun as fast as possible for the FBI ever have as much adrenaline flowing as Oswald, the man who had previously tried and failed to kill General Walker must have had. reply TedDoesntTalk 14 hours agorootparentprevIn other words, there can only have been more than one shooter. Not just Oswald. reply Obscurity4340 2 hours agorootparentDidn&#x27;t the same thing happen to one of his relatives&#x2F;descendants at a hotel in California? One guy went down for it but there were multiple firings from seperate angles and placements and witnesses reported hearing multiple shots from different orientations? reply Eisenstein 11 hours agorootparentprevSo the shooter was working with Oswald, or it was a coincidence? I&#x27;d like to know who would sign up for anything with Oswald -- probably the most unreliable and untethered person you would have been able to find in the SW USA at the time.All of these conspiracy theories would die if those taking them seriously would just sit down and read the Warren report. If you can then find something specific in the evidence or conclusions that is wrong or illogical or seems like it was covered up in the report, please point it out. reply TedDoesntTalk 10 hours agorootparentThis very article points out Arlen Specter heavily influenced people on the ground during the day of the assassination. This behavior is well-documented. Why do you take the Warren Report as gospel?“ Arlen Specter, who had traveled to Dallas to take Tomlinson’s deposition in March 1964, was thunderstruck when Tomlinson relayed this scenario. To judge from a transcript of that conversation, Specter spent much of the remainder of his time with Tomlinson essentially trying to talk him out of his recollection, causing a distressed Tomlinson to say he just was not sure about his memory.But the Q&A itself clearly suggests that Tomlinson, unprompted and unbadgered, had a cogent recollection that a bullet, wherever else it ultimately ended up, had come from the stretcher that had already been left in the hall in front of the men’s room.In its final report, the Warren Commission mentioned nothing about this detail from Tomlinson’s account. Instead, the panel largely dismissed Tomlinson’s testimony, writing that even though he was “not certain whether the bullet came from the Connally stretcher or the adjacent one,” the commission “has concluded that the bullet came from the Governor’s stretcher.”As sibling points out, Oswald may have been a scapegoat or patsy. reply Eisenstein 2 hours agorootparentSo you haven&#x27;t read it. reply cool_dude85 11 hours agorootparentprevOne potential conclusion is Oswald as the patsy for the real assassin. So nobody was \"working with him\" except in the sense of wanting him to take the fall. reply Eisenstein 1 hour agorootparentI guess you can be provided all the evidence you want but if you want to believe something else you are going to no matter what. replyJohnBooty 20 hours agoparentprevnext [–]The revelation is that the bullet was not lodged in JFK and did not fall out while shaking about on the gurney.I&#x27;m sorry, this is not correct.This pristine bullet was previously thought to have been found on Connally&#x27;s stretcher, not JFK&#x27;s stretcher.It was thought that this bullet traveled into JFK from the rear, exited his throat, and then wounded Connally.If Landis&#x27; claim is true, that would upend entirely the Warren commission&#x27;s findings. Of course, we probably can&#x27;t really know the truth at this point. But the article makes a solid case for it being quite likely true. reply lucas_membrane 6 hours agorootparent> If Landis&#x27; claim is true, that would upend entirely the Warren commission&#x27;s findings.Not so. Three shots were fired according to about 85% of the witnesses. Previously, we had a missing bullet. The bullet Landis found might be that missing bullet, previously explained as having vanished someplace in Dealey Plaza. Oswald may have fired it while his view of the limo was partially obscured by the tree. If it made some slight contact with the tree, it might have caused the small bit of flying debris that nicked one of the spectators, then continuing its flight at a lesser speed, hit Kennedy&#x27;s back, popped out of his back, and been found by Landis. The other magic bullet the Warren Commission may have figured out pretty accurately. Which bullet was the one found at Parkland? Given all the unanticipated mayhem that day, it could have been either one, but one would not expect that both of two wandering bullets would have been found. Many&#x27;s the detective who has been baffled by red-headed identical twins. reply ndsipa_pomu 14 hours agoparentprevLandis&#x27; behaviour strikes me as being very peculiar. Shouldn&#x27;t he have attempted to preserve evidence on the bullet rather than simply putting it into his pocket? reply alanbernstein 10 hours agorootparent> he said he grabbed it to thwart souvenir hunters. Then, for reasons that still seem fuzzy even to him, he said he entered the hospital and placed it next to Kennedy on the president’s stretcher, assuming it could somehow help doctors figure out what happened.From the NYT article. It also mentions that crime scene integrity wasn&#x27;t as much of a thing at the time, which seems questionable at best. But still, if you believe the choice is between keeping or losing the bullet, you definitely take it. reply Aeolun 11 hours agorootparentprevHe was also a 24 year old that had just seen the head of someone very familiar to him explode in front of him.I’m kind of inclined to expect peculiar behavior from him. reply ndsipa_pomu 10 hours agorootparentShock is the only explanation that makes any sense to me. However, remaining \"largely silent\" for 60 years about it implies that there&#x27;s other factors at play. reply another_story 9 hours agorootparentThe silence could have come from embarrassment at later recognition of what he&#x27;d done. reply Aeolun 3 hours agorootparentprevDepends. If you realize after they’ve gone through a whole investigation and produced a report, do you want to go up to them and tell them all their conclusions are pointless because of something you did? reply hyperhopper 12 hours agorootparentprevI am also skeptical of Landis, but what do you mean about preserving evidence?It&#x27;s a bullet. It just was next to an explosion that cleared it most most evidence. Then the barrel rifling altered the metal. That would not be harmed by picking it up. Then it went through jfk. Okay, we already know his DNA is on it.The real question is why are you picking up random things from a crime scene and then putting them down in a hospital stretcher. reply Tao3300 11 hours agorootparent> The real question is why are you picking up random thingsProbably seemed like a good idea at the time. My wife was in car accident once where the airbag deployed. For some reason her immediate reaction was to roll down the window. People in stressful and perilous situations sometimes do things that make no sense. reply KennyBlanken 11 hours agorootparentThe gasses generated by an airbag are quite toxic and don&#x27;t smell very good.Why wouldn&#x27;t she open a window? reply jcpham2 10 hours agorootparentI’ve been in a wreck and burned by the hot explosive gases filling those harsh burlap sacks known as air bags; I am opening a window or door ASAP too.It’s funny how advertising depicts air bags as these soft pillows when they are anything but inviting during the moment of deployment. reply ndsipa_pomu 10 hours agorootparentprev> I am also skeptical of Landis, but what do you mean about preserving evidence?I don&#x27;t really know, but it hardly seems like good practise to pick up a bullet. Don&#x27;t crime scene investigators usually take calibrated pictures of important items such as bullets and often try to determine the trajectory?There&#x27;s also the chain of custody to think about - the bullet could easily have been swapped with a different bullet after he left it on the stretcher. reply Someone 11 hours agorootparentprevPicking up the bullet destroys the evidence of the exact location it ended up in. reply grotorea 10 hours agorootparentWould he be expected to know we would spend decades doing ballistic studies on that bullet trajectory in the heat of the moment? reply Aeolun 11 hours agorootparentprevSo would the car accellerating after the bullet landed there. Picking it up and putting it on the stretcher seems plausible? reply ianburrell 11 hours agorootparentprevAre you from some other timeline where there was explosion at Kennedy assassination?The bullet they are talking about is the \"magic bullet\" that hit Kennedy and Connally. The bullet that hit Kennedy&#x27;s head distinegrated and they found fragments. reply checkyoursudo 9 hours agorootparent> Are you from some other timeline where there was explosion at Kennedy assassination?> The bullet they are talking about is the \"magic bullet\" that hit Kennedy and Connally. The bullet that hit Kennedy&#x27;s head distinegrated and they found fragments.The explosion they are referring to is the one inside the firearm when the firing pin strikes the cartridge.No need to be unkind. reply drusepth 9 hours agorootparentprevBullets, in general, are next to an \"explosion\" when fired from any gun that propels bullets via explosion. reply ufmace 6 hours agorootparentprevNote that he was pretty young and his only \"law enforcement\" experience was from working in the Secret Service. Presumably all of his training and experience was for things involving VIP protection activities. It shouldn&#x27;t be surprising that he didn&#x27;t know much at all about crime scene investigation. reply Nevermark 5 hours agorootparentI would personally expect an eight year old could figure out the importance of crime scene evidence in that situation.And his “only law enforcement experience was being in the Secret Service? That isn’t a low bar. reply becquerel 21 hours agoparentprevCrazy that he chose to keep this secret for six decades. I wonder what possible reason he could have to bring it up now. Hmm, hmm, hmm. reply lapcat 21 hours agorootparent> Crazy that he chose to keep this secret for six decades. I wonder what possible reason he could have to bring it up now. Hmm, hmm, hmm.Maybe because he&#x27;s 88 years old and likely to die soon? More or less a deathbed confession.Consider that Watergate&#x27;s \"Deep Throat\" Mark Felt only came forward at age 91. reply emmelaich 7 hours agorootparentSpeaking of Mark Felt, this article is fascinating.https:&#x2F;&#x2F;www.politico.com&#x2F;magazine&#x2F;story&#x2F;2017&#x2F;09&#x2F;10&#x2F;watergate... reply Simulacra 19 hours agorootparentprevMark Felt had more to lose, this guy might just be looking for a payday reply Apocryphon 21 hours agorootparentprevWell, JFK’s nephew is running for president. reply dylan604 13 hours agorootparentI thought maybe it had to do with all of the people believing JFK is coming back to Dallas reply Sunhold 13 hours agorootparentprevThe article discusses this in detail. reply chrisdhoover 10 hours agorootparentprevHe is at the end of his life and has nothing to lose? Imagine knowing the murder was a planned Dulles op. Then imagine, they killed Jack, Bobby, Martin, and Lennon. They tried to kill George Wallace and Regan. Might be good to keep quiet reply stevage 11 hours agorootparentprevSame reason Carly Simon revealed who was so vain. reply adrr 11 hours agorootparentprevHe’s trying to sell a book. reply Trombone12 21 hours agoparentprevAnd how does that upend anything? That it fell out already in the car does not seem dramatically different from it falling out after shaking Kennedy a bit. reply ttctciyf 14 hours agorootparent> how does that upend anything?If the story in the article is true, the bullet Landis found - i.e. the famous \"magic bullet\" - could not have wounded both Kennedy and Governor Connally and have been shot from the Book Depository (to Kennedy&#x27;s rear) as the so-called single-bullet theory[0] requires, so it upends the Warren Commission&#x27;s version of the assassination completely.0: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Single-bullet_theory reply Eisenstein 11 hours agorootparentThere is nothing magical about the bullet. The governor was sitting in front and to the right of Kennedy as you can see here:* https:&#x2F;&#x2F;spacecoastdaily.com&#x2F;wp-content&#x2F;uploads&#x2F;2017&#x2F;11&#x2F;JFK-A...look at the arms. Kennedy is resting his arm on the car frame and Connally cannot. The seat he is in is not lined up with where Kennedy is. The bullet needs no magic to go in a straight line. reply ttctciyf 10 hours agorootparent\"Magic bullet\" is just the most recognisable name for CE399[0], nothing supernatural implied by my use of it.0: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Single-bullet_theory reply JohnBooty 20 hours agorootparentprevAccording to the Warren Commission, the bullet was on Connally&#x27;s stretcher and presumably fell out of Connally.So if true (not that we can really know at this point) if the pristine bullet was retrieved from Kennedy&#x27;s car then yes, that would upend everything. reply thinkharderdev 13 hours agorootparentThey were in the same car reply JohnBooty 13 hours agorootparentAh, thanks. Sorry. I meant \"Kennedy&#x27;s car seat\" and not, \"Kennedy&#x27;s car.\" reply jgalt212 21 hours agorootparentprevI don&#x27;t know about that, but I do know that Vanity Fair seems to have an entire department devoted to the The Kennedy&#x27;s. reply thinkharderdev 13 hours agoprevI didn&#x27;t read the article but a few months ago I randomly came across https:&#x2F;&#x2F;www.posner.com&#x2F;case-closed and gave it a read. I haven&#x27;t really read much else about the Kennedy assassination and the various conspiracy theories (certainly no other 400p books on the subject) but came away from the reading pretty impressed with the thoroughness of the argument. Spoiler alert, the argument is that the official story that Oswald acted alone is almost certainly correct and evidence to the contrary is entirely unconvincing when examined in detail. reply PaulRobinson 13 hours agoparentHow does this book account for the magic bullet, an exit wound to the back of the head, gun smoke seem from another location, eyewitness reports of Oswald that make it impossible for him to make the shots in those timeframes, or the eyewitness reports of a \"police officer\" near the grassy knoll that was never accounted for or found?The magic bullet and exit wound - as seen on film kept from Americans for years - were enough to convince me the lone gunman theory was nonsense, but the rest of it also needs some accounting for. reply ianburrell 12 hours agorootparentThe magic bullet took a straight trajectory through Kennedy and Connolly. Modern theory is that they weren&#x27;t seated in a straight line and Connolly was turned.Oswald could definitely have made the shots. He was a trained Marine marksman. There have been multiple tests showing that it is possible to make the shots.Kennedy had a small entry in back of the head. The explosion on top and side of head was not the entry wound. There isn&#x27;t an exit wound because it was probably in damaged area so could say explosion was the exit wound. Remember that he was hit with rifle bullet that causes lots more damage than handgun. reply PaulRobinson 12 hours agorootparentBut you can see from video evidence that they were sat aligned and Connolly was not turned.If you are in the room, you might be able to make the shots - although the FBI failed to, and Oswald was a lousy shot - but my main problem is that he could not have moved through the building as needed without being seen by some people, and not by others who did.The photos of Kennedy do not show a small wound in the back of the head. They are distressing for a number of reasons, not least they clearly show the back of the head has exploded out. reply sparky_z 11 hours agorootparentOn the contrary, what you can see in the Zapruder film is comletely consistent with the bullet trajectories lining up. [0]This documentary I watched recently is long, but it puts all the eyewitness testimony of Oswald in the depository building into one big spacial timeline [1]. There are some inconsistencies (like you would expect when aggregating a bunch of eyewitness testimony from fallible humans) but there&#x27;s nothing there that made me think there was something nefarious going on. Anything specific you had in mind?As far as the autopsy photos go, I know the photo you&#x27;re referring to, and you&#x27;re misinterpreting it.Here are some medical illustrations [still kinda graphic, but not photographs] of the part that \"exploded out\" [2] and what the actual hole in the back of his head looked like when you held that part back in place [3]:[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8AlKUJHXYxQ&t=260s [1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=8AlKUJHXYxQ&t=260s [2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;File:HSCA-JFK-head-7-125.jpg [3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;File:JFK_posterior_head_wound.... reply sparky_z 9 hours agorootparentToo late to edit, but the [1] link should be:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5u7euN1HTuU reply jcranmer 11 hours agorootparentprev> But you can see from video evidence that they were sat aligned and Connolly was not turned.I just looked up the Zapruder film right now [1]. In the seconds before the fatal shot, you can clearly see Connolly turn around to face JFK (you can see the rotation of the shoulder pretty clearly as the car passes the road sign). At the moment of the fatal shot, he appears to be in the middle of turning back to his original position. Now I can&#x27;t tell from the Zapruder film whether or not they were aligned or instead offset by several inches, but it is very clear that Connolly was not facing forward at the time of fatal shot.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HBJFT-OyDEc is the source I used. reply ianburrell 11 hours agorootparentprevThe autopsy of Kennedy shows small wound in the back of head, top and side blown off, and no wound in the front. The bullet fragments were in his head, which makes a forward shot impossible. The video is deceptive because it is from behind and doesn&#x27;t see full explosion.Oswald was a good shot, he was rated sharpshooter and marksman in the Marines. Lots of people left to watch the motorcade. Memories are always unreliable. Oswald was supposed to be working.It is possible that FBI was working from bad info or incompetent. It was thought that the last two shots were rapid fire. But there is better info now that the shots were spaced out with plenty of time for bolt action rifle, and the \"rapid fire\" was echos. Lots of people have recreated the shots, some not that good shots. reply Eisenstein 11 hours agorootparentprevWhat you are saying is that most people are able to deduce proper bullet trajectories through soft targets by watching a single section of film shot from a distance -- and that this ability is so good as to render all of the other evidence moot. reply bunabhucan 11 hours agorootparent>What you are saying is thatsome HN>people are able toopine outside their circle of competence. reply thinkharderdev 12 hours agorootparentprev> gun smoke seem from another location, eyewitness reports of Oswald that make it impossible for him to make the shots in those timeframes, or the eyewitness reports of a \"police officer\" near the grassy knoll that was never accounted for or foundNot sure what specifically you are referring to with all of them, but in general it covers the various eyewitness reports used to establish multiple shooters. In short (and would really recommend reading the book if you are interested in the subject) they are not credible. Often inconsistent (both internally as the stories are told on different occasions) and also mutually inconsistent. There were a lot of people there that day and it was quite chaotic after the assassination. It doesn&#x27;t seem that implausible to me that there would be a lot of conflicting information from eyewitnesses. But the eyewitness testimony taken as a whole is completely consistent with Oswald firing all three shots from the Book Depository.> magic bulletFrom memory, there was nothing \"magical\" about the magic bullet. The injuries on both Kennedy and Connelly and the video evidence are completely consistent with the official story that a bullet hit Kennedy in the back of the neck, exited through his throat and then hit Connelly in the the thigh.> exit woundI assume you mean the story that there was an exit wound on the back of Kennedy&#x27;s head. But according to the actual autopsy that was not the case. He had an entry wound on the back of his head and exit wound on the side&#x2F;front (again consistent with the official story). The story of a rear exit wound is from two doctors who treated Kennedy at the hospital in Dallas. They were not doing an autopsy. They were administering emergency medicine to a man whose head was covered in blood and brain fragments. And there accounts have been directly contradicted by other doctors who were there. reply pseingatl 14 hours agoprevThe article suggests that Landis&#x27; come to Jesus moment came after reading Josih Thompson&#x27;s Six Seconds in Dallas. Three years ago Thompson wrote another book, Last Seconds in Dallas in which he and an audio expert examined recently released magnetophone recordings. The inescapable conclusion is that there were two gunmen. reply philistine 8 hours agoparentThe second gunmen doesn&#x27;t require a conspiracy to explain. Oswald fired two shots: one in Kennedy&#x27;s back which did not fully penetrate, and one through his neck which hit Connally.Then, in the ensuing confusion, a Secret Service agent following the motorcade accidentally discharged his AR-15 in the back of Kennedy&#x27;s head, killing him.The agent who pulled the trigger on the ground doesn&#x27;t even need to realize he had done it; it&#x27;s possible to accidentally discharge without realizing it. reply defen 7 hours agorootparentHow would that agent eventually account for the missing round? reply distortionfield 13 hours agoparentprevThat would line up with Landis’ statements now: he claims to have heard a louder, different shot, which was ultimately the fatal blow. reply raylad 11 hours agoprevIt was the conclusion of the House Select Committee on Assassinations that there was a high probability there were two gunmen.This was based on acoustical analysis of Dallas police radio recordings:https:&#x2F;&#x2F;www.archives.gov&#x2F;research&#x2F;jfk&#x2F;select-committee-repor... reply lostNFound 10 hours agoparentAnother commenter linked a video which I’ll re-link[0]. Essentially the conclusion of the HSCA was, as you say, literally entirely based on that recording. If the recording hadn’t been there, the HSCA actually was on the verge of concluding the same as Warren. (In other words, if the recording evidence wasn’t there they would’ve concluded Oswald lone).The recording was, indeed, later found to not even be from the time of the shots but from an entirely different point in time, after police already noticed Kennedy shot. In that very recording, police officers say things in reaction to the shooting. After those voices, the “shots” from which the conclusion was drawn appear. Painfully obviously, that doesn’t make any sense.Also the recording was in an entirely different point in space too, as it wasn’t even from a bike in the motorcade, as the HSCA thought but it from a different 3-wheeled-motorcycle stationed where Kennedy would’ve been arriving.Drawing conclusions from that recording about the Kennedy shooting is probably less reliable than drawing them from the Live Aid concert version recording of Bohemian Rhapsody by Queen.In summary, after adjusting for that lone error in HSCA, Warren and HSCA concluded the same.[0]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=DC8tO16xdrY reply jwally 1 hour agoprevIf I&#x27;m the CIA and I have exclusive access to the President&#x27;s food, transportation, calendar, etc...this isn&#x27;t how I take him out. Plane malfunction, opiate overdose in bathtub, food poisoning.Plenty of other options with way higher probability for success. reply fatfingerd 40 minutes agoparentYou mean if you are in the Secret Service? reply EMM_386 14 hours agoprevWhat I find most intriguing about the JFK assassination is the fact that parts of it still can&#x27;t be declassified.In 1992, Congress passed a law saying everything was to be declassified in 25 years. October 2017 came and went, and the FBI blocked around 7,500 documents from release. The DEA didn&#x27;t want CI names related to organized crime in them. The State Department blocked some due to \"national security and foreign affairs concerns\".Trump claimed while running for President that he was now going to release everything, yet the FBI and CIA stepped in again and those plans changed.Trump finally said he couldn&#x27;t release them due to some being \"of such gravity that it outweighs the public interest in immediate disclosure\".So they remain secret, 60 years later. reply ip26 14 hours agoparentWhat’s the anti-conspiratorial explanation for that? I can imagine a million different things they’d love to hide, but what would the legitimate, honest&#x2F;harmless reason? reply h2odragon 14 hours agorootparentHypothetical: They checked with an agent who is deep &#x2F; high up in some foreign agency and he said \"wasnt us.\" that agent retired but helped recruit others. those may have retired and helped recruit others.Just that one connection in a file, \"we asked agent $name and he said $agency knew nothing\" might be justifiable to keep secret if theres a connection to someone still active. reply throw_m239339 13 hours agorootparent> Hypothetical: They checked with an agent who is deep &#x2F; high up in some foreign agency and he said \"wasnt us.\" that agent retired but helped recruit others. those may have retired and helped recruit others.> Just that one connection in a file, \"we asked agent $name and he said $agency knew nothing\" might be justifiable to keep secret if theres a connection to someone still active.The names of the agents would be redacted at first place on declassified material. reply acdha 13 hours agorootparentIt’s not just names but also things like places, times, methods of communication, etc. which could be use to narrow things down. If there was a high-level KGB officer whose cooperation hadn’t previously been recognized they don’t want to inspire new investigation into what else that person or their handlers did. replyoconnor663 14 hours agorootparentprevThe anti-conspiratorial explanation would be that the government flagrantly broke tons of laws over the years, both in the US and abroad, and that they don&#x27;t want to publish details about that (even though none of those details actually involve trying to kill Kennedy). reply theultdev 12 hours agorootparentWell that&#x27;s still a conspiratorial explanation, just a different conspiracy.Though we do know these agencies have broken laws and done some pretty nasty stuff like MKUltra over the years.So they really have no stock and should have been broken up a long time ago. No conspiracy theories needed really. reply chrisdhoover 10 hours agorootparentprevPerhaps some of the programs are still running, new generation, same playbook reply kwhitefoot 1 hour agoparentprevWith this kind of secrecy it&#x27;s no wonder that conspiracy theories are so popular. reply xyzelement 14 hours agoprevNot directly related to this article, but I found the lone gunman theory much easier to accept after visiting the museum in the former book depository in Dallas. You can look down onto the plaza from the exact spot Oswald shot from, and you can easily imagine how the bullet fired from there would go through JFK and into the governor sitting in front of him.Not that this proves anything, it was just a \"oh, I can tangibly see it\" feeling that I didn&#x27;t get from reading about it. For some reason the view from Oswald&#x27;s window isn&#x27;t in popular knowledge although you can find plenty of pictures. reply whartung 13 hours agoparentYears ago, on Discovery or History channel, I watched a show where they replicated the “magic bullet” shot. The magic bullet was the one that hit the President and the Governor, that apparently went all zig zag, and left a pristine bullet.For the experiment they had all the measurements and distances, detailed ballistic dummies (with bones and whatnot), positioned properly (the Governor was on a smaller, lower jump seat, and sitting below the President), and they shot from a tower.They had the same rifle, though not the actual rifle, and they had period ammunition from the same lot that Oswald used. Who knows where they dug that up. I also can’t speak to the atmospheric conditions but those would affect accuracy, not impact.Only thing hey didn’t mimic was the actual motion. It was a stationary shot.Sorry to be graphic here, but as I recall this was the shot that hit The President in the throat, passed through him and continued on to hit the Governor, twice, I believe. Through his arm and into his leg.And you know what?They did it. They replicated the shot. Was it 100%? No. But I’d call it 90+%.The damage to the dummies was very similar, including deflection off the bones. They recovered the bullet and it was not perfect, but it was in very good shape. It was simple ball ammunition and did not expand like modern bullets can.It was, to me, a very convincing demonstration about how little magic was in the original bullet. reply SCAQTony 13 hours agorootparentHere is the video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PZRUNYZY71g&t=23s reply kanzenryu2 2 hours agorootparentprevRecently it was revealed that the car had been modified and the back seat was quite a bit higher than is normal for that model, and the original bullet trajectory analysis was therefore inaccurate. reply fatbird 8 hours agorootparentprevA few years after the Warren Commission, Dan Rather and CBS News recreated the shooting with marksmen on a tower, and did use a moving target. Several hit with two shots; one with all three.Here&#x27;s the video: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ghmY6HmR4fs reply superposeur 11 hours agoparentprevI think what drives much conspiracy-theorizing are two facts: 1) people have terrible intuition about physics outside a very narrow range of everyday conditions, 2) people are viscerally unaware of fact 1).For instance, I recall sitting next to a table of 9&#x2F;11-truthers meeting up at a coffee shop. Their discussions kept circling back to the sheer implausibility of a fire causing structural beams to buckle. People don&#x27;t have intuition for jet-fuel-hot fires; nor skyscraper-high gravitational potential energy. Similarly, the dynamics of a high-speed bullet is so far outside people&#x27;s intuitions that they derisively call its behavior \"magic.\"I&#x27;d like to hope that at least problem 2) could be ameliorated if good laboratory-based educational experiences were widespread enough; the terribleness of everyday intuitions smacks you in the face quickly when you try to do even a basic experiment. On the other hand, maybe the old dictum holds true that education benefits those most who need it least. reply philwelch 9 hours agorootparent> For instance, I recall sitting next to a table of 9&#x2F;11-truthers meeting up at a coffee shop. Their discussions kept circling back to the sheer implausibility of a fire causing structural beams to buckle. People don&#x27;t have intuition for jet-fuel-hot fires; nor skyscraper-high gravitational potential energy.They might, if they think for a few minutes about how metalworking works.> I&#x27;d like to hope that at least problem 2) could be ameliorated if good laboratory-based educational experiences were widespread enoughI think a lot of this comes from people being alienated from working with the physical world. Blacksmiths probably have extremely accurate everyday intuitions about how metal behaves under extreme heat. reply jjoonathan 14 hours agoparentprevSimilar: recent PR photos made it \"click\" for me that modern stealthy aircraft look exactly like \"flying saucer\" UFOs from the front.https:&#x2F;&#x2F;www.cnn.com&#x2F;2022&#x2F;12&#x2F;02&#x2F;politics&#x2F;b-21-stealth-bomber-... reply dizhn 13 hours agorootparentThat&#x27;s exactly why they make them look like flying saucers. Plausible deniability. reply The_Colonel 12 hours agorootparentprevYou can get this view only when the aircraft is flying directly towards you, any change in direction will reveal its true shape. For me this isn&#x27;t very convincing. reply whimsicalism 13 hours agorootparentprevEveryone knows that modern stealth aircraft looks like that, but that is not what has been causing the recent furor. reply tomrod 13 hours agorootparentFuror which may well have been caused by unacknowledged aircraft like the above.But who knows, maybe an intelligence or sapience from another world just wants to confuse people, or something similar in the long probability tail of life experience in this universe. reply sekh60 13 hours agorootparentAliens are doing for the lulz. reply akira2501 13 hours agoparentprevThe problem is, the Secret Service could see that too, and Dallas wasn&#x27;t exactly a \"friendly\" city. The decision to take such a route in a vehicle without cover or without securing the building remains unexplained.So, yea, the depository is a perfect location to shoot onto that route. This in and of itself is a massive problem. reply kevinmchugh 12 hours agorootparentThe featured article is about a 23 year old secret service agent hired directly from college and quickly assigned to protect the first lady - what if the secret service before 1963 was just not that competent? How much does that explain for us? reply ianburrell 12 hours agorootparentprevOswald was temporary employee at the Book Depository. He carried a long package into the building in the morning. I don&#x27;t think there was security since would have likely searched the package. But his employee status would have gotten him in and given him reason to be there in any search. reply jmyeet 9 hours agorootparentprevYou, like many people, fall into the trap of seeing the events of 1963 through a modern lens, a lens that itself was greatly influenced by these events.Presidential security in 1963 wasn&#x27;t what it is today. For example, JFK would stop his car to go mingle with the crowd. There&#x27;s a photo on this audio recording from Miami in 1963 [1].There are parallels with 9&#x2F;11. Prior to 9-11, people would generally go along peacefully with hijackers. Why? Because they knew the \"routine\". The hijackers would fly the plane somewhere, land it, make demands, make noise for their political cause and, more often than not, people would get to go home. Harrowing for sure. But the general public didn&#x27;t conceive of planes being used as cruise missiles. We all know post-9&#x2F;11 was so much security theater but it was also largely unnecessary because people were now aware they could be used as a missile so were less likely to simply go along with demands.JFK&#x27;s assassination changed the threat modelling and protection by the Secret Service of the president. In spite of that, Ronald Reagan was shot by an assailant [2] without any great planning or mass conspiracy.Now it&#x27;s all bulletproof motorcades with armor plating to survive running over a land mine. It&#x27;s Secret Service vetting every audience member at a live event. It&#x27;s mapping out and securing any potential sniper positions. None of that was true to the same degree in 1963.[1]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ep_NiYKrcC0[2]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Attempted_assassination_of_Ron... reply kanzenryu2 2 hours agoparentprevOr you can play the game https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=C5U5iu85oUM reply ALittleLight 13 hours agoparentprevI think the suspicious stuff about the JFK assassination is not the shot itself, but the fact that Oswald had a friend and mentor who was a CIA handler and Oswald himself was inexplicably murdered by Ruby before any real investigation could happen. Ruby&#x27;s offered explanation - that he wanted to save Jackie a trial, doesn&#x27;t seem plausible. reply wheelerof4te 13 hours agorootparent\"I think the suspicious stuff about the JFK assassination is not the shot itself, but...\"...who ordered the murder. Shooter is the least important factor considering how many enemies JFK had in the establishment. It is too easy to blackmail someone in performing the murder.Especially if you have friends in the CIA. reply drexlspivey 12 hours agorootparentThe hit was ordered by Sam Giancana, the Chicago mafia boss. Jack Ruby was his lackey.From wikipedia: Ruby was known to have been acquainted with both the police and the Mafia. The HSCA said that Ruby had known Chicago mobster Sam Giancana (1908–1975) and Joseph Campisi (1918–1990) since 1947, and had been seen with them on many occasions. reply wheelerof4te 12 hours agorootparentIt&#x27;s so good that you mentioned him, because this is from the first article of the top of Google&#x27;s search:\"In July 1974, however, he was seized by police in Mexico City and shipped back to Chicago. One year later he was bullet-riddled in his home in Oak Park, Ill., by unknown assailants. He had been scheduled to appear before the U.S. Senate Intelligence Committee to discuss his alleged involvement in a Central Intelligence Agency plot to assassinate Fidel Castro in the early 1960s.\"Source: https:&#x2F;&#x2F;www.britannica.com&#x2F;biography&#x2F;Sam-GiancanaSo, the guy was involved and worked with the CIA. Meaning, CIA could have been involved, too.And they conveniently offed him to prevent him to talk. Such class. reply kevinmchugh 11 hours agorootparentprevRuby&#x27;s mob associations are probably exactly normal for someone in his line of work, but also they tell us they he wasn&#x27;t committed to the rule of law. That&#x27;s consistent with his statement about saving Jackie from a trial - he thought retribution was owed, not justice. reply cafard 8 hours agorootparentprevWhy should JFK have enemies in the establishment? He was the establishment. reply JPws_Prntr_Fngr 9 hours agorootparentprevAnd Ruby&#x27;s psychiatrist: Louis Jolyon West, extremely nefarious CIA MKUltra mind control contractor. https:&#x2F;&#x2F;www.nytimes.com&#x2F;1964&#x2F;04&#x2F;29&#x2F;archives&#x2F;coast-psychiatri... reply philwelch 10 hours agoparentprevI had the exact same reaction. There are X’s on the road where Kennedy was hit, and standing at the window next to Oswald’s position, two things were immediately obvious to me: that both X’s were in line with his position (so he wouldn’t have needed to shift his point of aim unlike a shooter from the grassy knoll) and that I could have probably made the same shots. reply pseingatl 14 hours agoparentprevI had the opposite feeling. Looking from the window, to your left, a winding road. To your right, the freeway entrance. With a bolt action rifle, Oswald had to shoot, eject the casing, reload, acquire the target of an accelerating vehicle, shoot, eject the casing, reload, acquire the target of an accelerating vehicle and fire again. One of the Marine Corps&#x27; top snipers said, \"I can&#x27;t do it.\" If he can&#x27;t, how could Oswald? reply dharmab 14 hours agorootparentThe Carcano M91&#x2F;38 is a magazine fed rifle, it isn&#x27;t manually reloaded. You can work the bolt while remaining on target. That&#x27;s not a particularly hard thing to do, either- I was able to learn that skill the first afternoon I shot a magzine fed bolt action.EDIT: Here&#x27;s a video of someone replicating the shots with that rifle. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ghmY6HmR4fs The comments also point out other factors that could have made the shot easier. reply kbrisso 13 hours agorootparentOne of the cable networks had a guy make the shot from the exact same height and distance. After I watch that episode I&#x27;m convinced it happened that way. What really makes it a conspiracy is how RFK covered up the political on goings in the White House. JFK was doing thing politically not popular in America, in an effort to cover this up RFK rushed the funeral, medical exam and burial to put those things to rest. reply xyzelement 11 hours agorootparentprevThank you for sharing this context and the video. It is also interesting anachronism to see Americans casually handling firearms with competence on a TV broadcast reply codenesium 13 hours agorootparentprevThe distance was like 75 yards. I visited the book depository as a child and even then thought I could make that shot. reply nativeit 10 hours agorootparentprevThey weren’t exactly bullseye hits. He got the bullets in the right vicinity, which is admittedly an impressive feat, but it was pure chance that they managed to strike in a way that caused a lethal blow. If one was going through the effort of conspiring with 1-2 other gunmen, then it should have featured better and more intentional targeting, from spaces anywhere along the motorcade route that wouldn’t be so difficult to enter&#x2F;exit. Or, if we’re talking about a broader planned conspiracy, use a blunter instrument like an IED or another vehicle, or both. Why opt for a sniper at all? The chances of success seem too little for a professional hit, but about right for an unstable radicalized former soldier looking for revolutionary glory.Also, the car only started accelerating after the hit was made, and it was fairly axial to the bullet trajectory. I dunno know about you, but I can reload a bolt action rifle without dropping aim in under a second. It’s using the rifle as it was designed to be used.It wasn’t a good shot. It was a lucky shot. One he clearly didn’t fully prepare to land, otherwise he probably wouldn’t have been arrested shortly after in a nearby movie theater. It was hardly sophisticated, and its success hinged almost entirely on blind luck and circumstance, which is the most difficult scenario to protect against. reply neaden 14 hours agorootparentprevWho was the marine Corp top sniper who said they couldn&#x27;t do it? reply klyrs 11 hours agorootparentNone other than Captain John Patrick Francis Mulcahy, I&#x27;m sure. reply robswc 9 hours agoprevI honestly don&#x27;t think there was a conspiracy... but I wouldn&#x27;t be surprised to learn there was more to it, at the same time. I never gave it much thought but one day I saw a documentary and its like \"damn, there&#x27;s a lot of weird stuff to this.\" However, I think it also shows just how bad people&#x27;s memory is _or_ how bad people are at extracting details from witnesses. reply dahdum 9 hours agoprevWhat a convenient revelation to have when it comes time to sell some books. reply rendall 5 hours agoprev\"As an international superstar, [Jackie Kennedy] was the Princess Di of her era...\"Interesting turn of phrase. Princess Di was far closer a contemporary of Jackie Kennedy than either are today. I can&#x27;t imagine there is a large audience of people who would understand the reference to Princess Di but not Jackie Kennedy. Like saying \"Will Rogers was the Red Skelton of his era\". Iykyk. reply circumlocution 20 hours agoprevTo those who haven&#x27;t seen it, I&#x27;d really recommend Lemmino&#x27;s video on the assassination https:&#x2F;&#x2F;youtu.be&#x2F;5u7euN1HTuU?feature=shared He dives pretty deep into the details, and it helped me form my own opinion of what probably happened reply tgv 13 hours agoparentSo, in the beginning, they play recordings. But the recordings, in particular that of Oswald&#x27;s wife, sound pretty unnatural, including the interviewer. On the website linked, there are sources, but they are text only. Were those interviews \"recreated\" for the video, as far as you know?Edit: it is mentioned (not very clearly) at the end that the recordings were \"voiced\" by other people. So that answers my question. reply Ylpertnodi 15 hours agoparentprevWhat is your own opinion of what probably happened? reply ufmace 5 hours agorootparentI watched it as well. I don&#x27;t have a strong opinion on what actually happened, but the details in the video of how LHO came to be employed at the book depository and his movements in the days preceding the assassination make it seem pretty improbable that his position there and the assassination were part of some carefully coordinated plan.For example, if there were actually multiple gunmen in different locations, who all fired within a few seconds, they would have to have had some way to coordinate not only the fact that they would shoot at the motorcade that day, but to precisely synchronize exactly when they all fired. How would they do that? Did LHO even have a watch? Were there other gunmen sitting around somewhere with their guns ready and on target and fingers on triggers, ready to fire within a split second of when some other shooter fired?I would also note, I&#x27;ve watched training videos on how to respond to mass shooter situations. One of the main points is to discount any claims of additional shooters in other locations until you hear shots yourself. It seems it&#x27;s quite common in mass shooter situations for witnesses to falsely report additional shooters in other locations. reply circumlocution 12 hours agorootparentprevI didn&#x27;t read all the source material researched for the video myself, so I&#x27;d take all this with a grain of salt, but I personally consider Lemmino reliable. Based on his presentation of the evidence I think it was just Lee Harvey Oswald taking an attack of opportunity. It seems likely he was working at the building by happenstance, heard&#x2F;read that the motercade would pass by, and hasily planned the assassination in secret. He had a motive that doesn&#x27;t require any conspiracy as he was self admittedly a marxist and was described as \"unstable\". To me, his murder of a police officer immediately following the assassination is indicative of mental instability rather than a carefully planned conspiracy. I also consider the reports of multiple gunshots unreliable; I remember being nearby Parliment in Ottawa during the 2014 shootings at Parliment Hill. There was incredible confusion when it started, and rumours and miscommunications travelled at lightning speed since everyone feared for their lives. At first there were reports of multiple gunman in several different locations near the actual shooting because of echoes off of nearby buildings and return fire from police. Really it was a lone gunman, and despite those inital reports I&#x27;m not aware of any conspiracies about the whole event. I think the true conspiracy, if any, was that any of the people involved who failed in their role to prevent the assassination of the president by a lone unstable man, or to conduct a flawless investigation following it, were incentivized to bend evidence and testimoney in their favour (whether unconsciously or intentionally). I don&#x27;t think this was done out of malice, rather, who would want to admit to any actions that could conceivably invite criticism? In the article itself he provides several (perhaps reasonable) reasons for why he moved the bullet at all, probably to defend against criticism that leaving all evidence in place (seems to me) would have been the best course of action. As for the article itself, human memory is notoriously unreliable (even shortly after shocking events like this), so even if he beleives he is telling the truth, and isn&#x27;t interested in the profit motive, I don&#x27;t think it&#x27;s compelling enough evidence to believe in a conspiracy beyond human fallacy. reply tharmas 14 hours agoparentprevThanks for this link. I&#x27;ve never seen nor heard of this film before. reply circumlocution 12 hours agorootparentYou&#x27;re very welcome, he gives a similar video rundown on Jack the Ripper; in both cases I find it fascinating how messy real life investigations are. reply kelnos 15 hours agoprevEven if Landis is being honest to the best of his ability, this account seems suspect for one simple reason: human memory is incredibly unreliable even in routine cases. Considering the stress and trauma around witnessing and being so close to an awful event like that, as well as the amount of time that has passed, I don&#x27;t see how we can consider this story to be even remotely reliable.He may truly remember these events as he is describing them, even if what he&#x27;s described never actually happened. That&#x27;s unfortunately how (poorly) human memory works. reply jl6 13 hours agoparentI am reminded of an incident relayed to me by an office worker in the early 2000s. A colleague had left the building at lunchtime and had been witness to some kind of shooting incident where robbers or gang members on motorcycles had opened fire on someone or something else - I don’t think it was ever discovered what the target or cause was. This was in South America, so not a wholly unusual scenario. But the debrief of the employee was eye-opening. He described everything that had happened from his perspective: he heard gunshots, hid behind a bin, and waited until it was over. He said there were dozens of gunshots and he had stayed in hiding for about ten minutes, until he heard the bikes speed away.However, upon reviewing the CCTV footage, it became clear that the whole incident, from bike arrival to employee emerging from behind the bin, lasted about 11 seconds.The colleague was astounded to see the footage and couldn’t explain why he had felt it was so much longer.I think there’s a good chance that stressful situations play havoc with human memory formation. reply tmnvix 12 hours agorootparentA really interesting example here in a PBS doco of someone&#x27;s experience of time &#x27;stretching out&#x27; in a dangerous situation. It includes footage of the entire event, the individual&#x27;s recollection, and a possible explanation:https:&#x2F;&#x2F;youtu.be&#x2F;7eCniXtM__g?si=26Gbd2w8PEozKL0i&t=2768 reply Waterluvian 11 hours agorootparentprevIs it an issue with forming memory, or did the person experience ten minutes worth of 11 seconds? reply moritzwarhier 11 hours agorootparentThere&#x27;s an interesting dialog about this in Catch-22, the novel, but it intentionally revolves around boredom, not fear (which of course also is a primary subject of the novel)I assume you were also aiming at a point of absurdity, because I don&#x27;t want to imagine that you&#x27;d like to lenghten your perceived lifespan i.e. by being tortured... reply nradov 12 hours agorootparentprevTime dilation is well known to occur in dangerous situations.https:&#x2F;&#x2F;doi.org&#x2F;10.1111%2Fpsyp.12836 reply jonplackett 11 hours agorootparentTime dilation is pretty amazing.I experienced it one time when I accidentally put the car into a a skid at 70mph. I remember calmly realising the car was moving sideways. Having time to ponder that for a few moments. Then deciding to start steering into the skid. Then think about that for a while. Release the break a bit. Finally we did a full 360 and ended up in the middle of the road again.It seemed like it took a minute or more but was probably a few seconds if that.Brains are awesome! (My younger self driving ability, much less so) reply alasdair_ 9 hours agorootparentMy understanding of time dilation is that at the time the event is actually happening, things occur at normal speed, it&#x27;s just that our memory of the event is time-dilated and so we remember everything slowing down and taking a long time. reply tasogare 12 hours agorootparentprevMy theory is that in a really stressful situation the mind hyperfocuses and \"processes more frames per second\" to react quicker. Just like with movies this mean that replayed at normal speed the movie serms very slow, hence the long timespan memory. reply pfannkuchen 12 hours agorootparentI believe this is also responsible for so called dad reflexes. reply WalterBright 13 hours agoparentprevMy dad kept a diary during his WW2 duty. In his 80&#x27;s, he read it and was shocked to discover it did not line up with his memories. reply paint 13 hours agorootparentInteresting! Without going into personal details, can you explain what sort of incongruence he found between his diary and his memory?I sometimes keep a diary, for example when I go on long trips that are different from my day-to-day life. I try to be as accurate as possible, but sometimes i notice what i write isn&#x27;t fully representative of my state of mind at the time, simply because when you&#x27;re writing stuff down (especially when you&#x27;re writing with a pen and paper (slow!)), you can never fully capture all the concurrent thoughts and emotions you&#x27;re experiencing, so its impossible for a diary to be fully accurate. Undoubtedly, e.g. Elizabeth Loftus has done a lot of prominent research in that field, our memories tend to be fallible, but maybe that&#x27;s part of the reason? reply WalterBright 13 hours agorootparentIt was about what transpired on the missions.When I was writing a paper on the history of D, I had kept a lot of records, such as emails. I was often surprised when the details didn&#x27;t quite line up with my memories.This is one reason why one cannot get a fair trial 40 years after the fact, if any of it relies on eyewitness testimony. reply fsckboy 13 hours agorootparentmaybe your memory of being surprised or the one that the details didn&#x27;t line up is the false memory! reply jimhefferon 13 hours agorootparentprevI remember with 100 percent clarity doing great in sophomore high school math. I loved it and I went on to get a PhD. Then my mom passed and I got a box of stuff with my name on it from her house. It included my report card. C. reply 7thaccount 11 hours agorootparentThat&#x27;s because you remember correctly...the simulation just messed up the report card object and accidentally decremented the counter twice.In all seriousness it&#x27;s crazy how bad memory is. Like we all have a false version of the truth. reply wolverine876 9 hours agorootparentConversation is throwing fictional worlds at each other. reply philistine 8 hours agorootparentprevYou had low standards when you were a kid. You thought a C was great. reply lost_tourist 3 hours agorootparentyep possibly \"oh shit I&#x27;m gonna fail, I better study like crazy\" gets 100 on the final and brings a D up to C, and realizes he can do math pretty well when he tries. reply agumonkey 14 hours agoparentprevI agree. Having gone through stuff I know how my mind can distort &#x2F; hallucinate stuff in confusing &#x2F; high stress situations. Even without questioning the person&#x27;s honesty.. your brain is not a high quality source of information. reply cjbgkagh 13 hours agorootparentTotally, that&#x27;s why I don&#x27;t trust anything anyone says, ever. I can&#x27;t trust that my fallible brain is hearing what people are saying correctly, so even if they&#x27;re right my understanding of what they&#x27;re saying may still be wrong. reply bbor 12 hours agorootparentThere is no such thing as knowledge, just justified beliefs ;) reply EliRivers 13 hours agoparentprevThe JFK assassination has been such a recurrent theme for so long that I reckon I might have memories of it, even though it happened decades before I was born. reply interestica 12 hours agorootparentAs time goes by I&#x27;m less and less sure that I saw the second plane hit the tower on 9&#x2F;11 live.I think there&#x27;s a similar \"induced memory\" surrounding who watched the challenger disaster live.(Fwiw, I&#x27;m still pretty sure I watched it live) reply simonh 11 hours agorootparentI didn’t see it live, it was on a news replay minutes after it happened. I remember thinking I have to tell my brother and my dad, but what will I say? It felt a bit like when you stub your toe and it doesn’t hurt yet, you know something bad has happened and this is the pause before the impact hits when you tell everyone. I seem to remember them asking what exactly had happened, and I struggled to explain what I’d seen on the few seconds of replay I’d seen, and couldn’t really describe it.Years later we discussed it and they were both adamant we all watched it live on TV. Am I misremembering, or them, or all of us? Tough one.With 9&#x2F;11 I seem to remember one of the impacts only being seen from the explosion, but you couldn’t see the plane itself. Maybe that was the second one? reply jcranmer 11 hours agorootparent> With 9&#x2F;11 I seem to remember one of the impacts only being seen from the explosion, but you couldn’t see the plane itself. Maybe that was the second one?There is an archive of several news channel and their coverage of 9&#x2F;11 at https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;911&#x2F;day&#x2F;20010911#&#x2F;. Some of the news channels had better viewpoints and saw the second plane hit on live footage [1]. The NEWSNW channel has a very solid view of the second plane as it hits, which causes the reporter there to react mid-sentence. Note that&#x27;s the live coverage; since there&#x27;s so many cameras pointed out the towers by that time, there&#x27;s several different angles of the actual moment of impact (although most news channels were focusing on the views that best showed the damage at the first tower when it happened live).There&#x27;s only three known recordings of the first tower being hit (the best quality one being from someone shooting a documentary film who heard the plane, looked up with the camera, and recorded it as it hit). The hit of the Pentagon is only recorded by a security camera, where there is but one frame with part of the plane being just barely in the view before the impact.[1] This takes place in the first or second clip of the second row of the 9:00-9:10 segment, depending on how bad the delay is. reply Tao3300 11 hours agorootparentprevThere probably even a conspiracy theory that you did it! reply wolverine876 9 hours agoparentprevLandis also said different things in his report at the time. reply dangus 13 hours agoparentprevJust to reiterate and point it out, this was 60 years ago. reply colordrops 10 hours agoparentprevThis seems like a pretty arbitrary criticism. Do you have any reason to believe that he didn&#x27;t remember things correctly? reply empath-nirvana 21 hours agoprevThe problem with conversations about this topic and similar topics (9&#x2F;11) is that almost no-one who cares about the topic deeply enough to have an argument about it online is interested because they&#x27;re just super into ballistics and forensics and don&#x27;t care about the political implications. It&#x27;s all motivated reasoning because they don&#x27;t like the _implications_ of the official story for whatever reason (or, alternatively, the conspiratorial reading), or they&#x27;re selling something to the people who don&#x27;t like the official story (or the conspiracy).You think you&#x27;re having an argument with someone about the facts and what you&#x27;re actually doing is having a conversation with someone who is deeply invested in defending their _entire world view_ which means they just can&#x27;t accept whatever argument you&#x27;re trying to make. You can go after each argument they make and dispense with them in turn, and they&#x27;ll continue to invent new ones -- for decades if they have to. It&#x27;s like trying to argue with a christian fundamentalist about the logical impossibilities of noah&#x27;s ark. And it really doesn&#x27;t matter _who is right_. Nobody is going to be arguing in good faith about it. Probably if you&#x27;re about to comment on this post, you&#x27;ve got some motivated reasoning behind it that has nothing to do with finding out what really happened. reply lapcat 20 hours agoparent> Probably if you&#x27;re about to comment on this post, you&#x27;ve got some motivated reasoning behind it that has nothing to do with finding out what really happened.I&#x27;m not sure that&#x27;s true in this case. I remember 9&#x2F;11, but I wasn&#x27;t even born yet when the Kennedy assassination happened. I doubt that many people under age 70 remember that personally. It doesn&#x27;t really have emotional salience for most people now. For me, it&#x27;s merely a curiosity, and I can&#x27;t say that the truth of the matter is important to me either way.Even if there was a conspiracy to kill JFK, I don&#x27;t see how it&#x27;s relevant to current politics, and the possible players involved are no longer relevant either. Joe Biden himself, old as he is, was only 21 at the time and still in college. reply ryandrake 18 hours agorootparent> I doubt that many people under age 70 remember that personally.I think OP&#x27;s point is that personal remembrance, direct knowledge&#x2F;witness, or subject matter expertise is not a requirement when it comes to defending one&#x27;s strongly invested world view. Instead of looking at evidence, people start with a vague belief about the world and then draw the lines between everything that happens and that world view.For example: \"There are inscrutable elites that operate in secret to control the world.\" This is a vague and close to impossible-to-prove assertion, but people believe it strongly, and they use this world view to explain everything they have questions about. JFK was obviously assassinated for going against the Shadowy Elite! If you take your belief as a given, many wild explanations simply follow logically. 9&#x2F;11 was orchestrated by this Elite to [do whatever The Elite does, there are a wide range of speculation even among the \"shadowy elite\" believers]. COVID was planned by The Elite. It goes on and on, and everything makes sense when you&#x27;re working from that one assumption.If you argue with someone against any of these particular things, you&#x27;re not going to get anywhere because disproving even one of these calls into question the world view that all his other beliefs are pinned to.EDIT: Parent commenter I see what you&#x27;re saying now and yea I totally agree! reply toast0 13 hours agorootparentThe thing about the shadowy elite is that it&#x27;s non-falsifiable.We can certainly have a discussion, but it&#x27;s outside the realm of logic, because there&#x27;s no possible evidence that could disprove it. That doesn&#x27;t make it true or false, but it does make it useless to discuss in the terms of logic, and trying will just lead to frustration.What would we do differently if the shadowy elite was behind JFK&#x27;s death? What would we do differently if the shadowy elite wasn&#x27;t behind it? What ends were gotten by the shadowy elite through the means of mysterious assasinations to help the Rolling Stones sell records?These are all reasonable questions to ask, but the philosophy of logic won&#x27;t help us come to answers. reply Kamq 11 hours agorootparentMinor quibble, logic is generally perfectly fine with things that are non-falsifiable, so long as a truth value can be hypothesized, we can use logic just fine.It&#x27;s science that doesn&#x27;t have anything to say about unfalsifiable situations (metaphysics, negative statements, etc).We&#x27;ve really left the realm of empiricism, not logic. reply lapcat 18 hours agorootparentprev> If you argue with someone against any of these particular things, you&#x27;re not going to get anywhere because disproving even one of these calls into question the world view that all his other beliefs are pinned to.I don&#x27;t dispute that there are people like this. What I was disputing, specifically, was the overgeneralization, applying this characterization to everyone: \"Nobody is going to be arguing in good faith about it. Probably if you&#x27;re about to comment on this post, you&#x27;ve got some motivated reasoning behind it that has nothing to do with finding out what really happened.\"Even among those who are into a \"Shadowy Elite\" conspiracy theory, I don&#x27;t see a lot of emotional investment remaining nowadays in the JFK conspiracy specifically. Of course they&#x27;re obsessed now with Covid, for example. JFK is old news, not salient. reply somenameforme 13 hours agorootparentprevI think the issue is not one of expertise, but that many people are arguing without being aware of facts contrary to their own view. For instance a critical component to the conspiratorial view is Operation Northwoods [1]. And it tends to paint a far different than picture than you are claiming. Operation Northwoods was a planned CIA operation where they were going to carry out terrorist attacks against both civilian and military US targets (notably they even proposed the use of remote controlled civilian aircraft) and blame it on Cuba, so we could start a war with them. This plan successfully made its way all the way up the chain of the command and was one signature away from being executed. The problem is that JFK rejected it, vigorously.The CIA and the military wanted global escalation and military conflict. Kennedy, by contrast, was working more towards reconciliation and global peace through good faith. Just prior to Operation Northwoods, he had recently removed the head of the CIA (following the Bay of Pigs catastrophe), and following the Joint Chief of Staffs presentation of Operation Northwoods to him, JFK also removed him from power as well. JFK would then go to on to pass a unilateral nuclear test ban as a show of good faith to the USSR, and was reportedly not only looking to withdraw from Vietnam, but also to completely dismantle the CIA. Less than 6 months later, he would be assassinated.That&#x27;s hardly a tale of some &#x27;shadowy elite trying to control the world.&#x27; In fact the assassination becomes so utterly predictable in this context that one has to consider that if it was a simple lone-wolf then the CIA and military effectively won some sort of one in a quadrillion type lottery (at least from their rather sociopathic worldviews). For that assassin to then to be assassinated, after initially claiming he was a \"patsy\", and all the other weirdness around it all, I think Occam&#x27;s Razor starts pointing in a pretty clear direction.[1] - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Operation_Northwoods reply logicchains 13 hours agorootparentprev>the possible players involved are no longer relevant either.If the conspiracy was on the part of the spy agencies, as claimed, then the agencies involved are absolutely still relevant. If the CIA or whatever back then was willing to kill someone because he threatened to reduce their power, given the intelligence agencies have even more power now than they did back then there&#x27;s no reason to think they wouldn&#x27;t do it again if threatened. reply frenchy 12 hours agorootparentprev> I doubt that many people under age 70 remember that personally.Jesus of Nazarath was reportedly crucified in Judea almost 2000 years ago, and people have all sorts of opinions on that event.Events like these just have a way of getting out of hand. Honestly, I think my grandma, who was a JFK fan-girl, would probably be incredibly confused by the ideology of modern JFK conspiracy theorists. reply roenxi 20 hours agorootparentprev> Even if there was a conspiracy to kill JFK, I don&#x27;t see how it&#x27;s relevant to current politics...A group with that much power - to kill a president then get it covered up - is not going to just fade away quietly. It&#x27;d have to be a powerful group and powerful groups have a habit of lasting beyond the lives of the members.If it turned out that there was a conspiracy it is actually quite likely that the group that organised it are still active. Picking on one from https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;John_F._Kennedy_assassination_... that would make a good story ... if it was the Israelis there&#x27;d be no reason to believe they stopped. It&#x27;d put Jeff Epstein&#x27;s kompromat operation in a new light if they were trying to manage US politics. reply lapcat 19 hours agorootparent> A group with that much power - to kill a president then get it covered up - is not going to just fade away quietly. It&#x27;d have to be a powerful group and powerful groups have a habit of lasting beyond the lives of the members.> If it turned out that there was a conspiracy it is actually quite likely that the group that organised it are still active.I don&#x27;t think these are correct assumptions. Sixty years is a long time, and the world has changed a lot. The Soviet Union is a shell of its former self (hence the current Ukraine conflict), Fidel Castro is dead, etc.> if it was the IsraelisIMO this is one of the dumber and least plausible of the conspiracy theories.What are we even to conclude from this, though? Of course Israel still exists, but what exactly are you trying to imply about the current situation? Netanyahu, by the way, was 14 years old in 1963 and was actually living in Pennsylvania, US at the time.> there&#x27;d be no reason to believe they stoppedStopped what? reply knowingowl 18 hours agorootparentIf the JFK and RFK assassinations were done by secret services it seems to make a lot of sense (psychologically) that they&#x27;d use people that were the \"opposite\" of themselves as patsies.So some right-wing CIA people (and their Mafia&#x2F;Anti-Castro helpers) used a left-wing communist Oswald as the patsy for JFK. There was a lot of motive for these people to kill JFKAnd then some Jewish Israel Mossad people copycatted for the RFK assassination, using a Muslim Palestinian as their patsy. There was a lot of motive for these people to kill RFK. (And I shouldn&#x27;t have to say this, but I&#x27;m Jewish, so this isn&#x27;t an antisemitic thing.)But I agree with the point that it mostly doesn&#x27;t have much impact on the modern world. Whoever was involved in these assassinations doesn&#x27;t hold power any more. They&#x27;re dead.No kind of reconciliation process is truly required to prevent this kind of thing in the future. The world has changed and that&#x27;s why these kind of political assassinations aren&#x27;t used in the west today.Not because there aren&#x27;t people that wouldn&#x27;t love to have this tool. It&#x27;s just not as viable as it was in the time before mass surveillance and uncontrollable information flows.Try to imagine pulling off the RFK or JFK assassinations with a large number of uncontrolled smartphones posting and even live streaming to the internet. reply barrysteve 13 hours agorootparentShinzo Abe was killed last year.It&#x27;s not some grand conspiracy, just some guy with a gun.I can imagine pulling off JFK 2.0... but I don&#x27;t want to.Surveillance cements consequences.If it was Israel, then who cares? Are we doing diplomacy by assassination now? The reality of politically motivated, err, unpleasantness, has existed forever.Let&#x27;s not forget the 20yr war that happened straight after 9&#x2F;11. Less killing the better, and a death in cabinet doesn&#x27;t always get the change &#x27;the powerful group&#x27; may want.I&#x27;d be more worried about getting on a submarine with a console controller now. reply knowingowl 12 hours agorootparentOf course actual unhinged will try to assassinate people. That&#x27;s to be expected in a world with so many people.What has changed is that covert political assassinations by the secret services of nation states is no longer a viable strategy the way it was when JFK and RFK were killed.Not even the Mossad is good enough to pull it off these days, and they&#x27;re probably the best in the world: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Assassination_of_Mahmoud_Al-Ma... replyDANmode 14 hours agorootparentprev> Even if there was a conspiracy to kill JFKHe&#x27;s dead, so...what? reply DANmode 11 hours agorootparentRewriting: \"He&#x27;s dead so: what?\"because obviously(?) there was someone conspiring to kill him. reply Apocryphon 19 hours agoparentprevEh, at this point with all of the myths and legends surrounding the JFK assassination, it would be novel if even something as banal as the friendly fire theory turned out to be true.https:&#x2F;&#x2F;www.nbcnews.com&#x2F;news&#x2F;us-news&#x2F;accidental-assassin-jfk... reply knowingowl 18 hours agoparentprev\"Nobody is going to be arguing in good faith about it.\"Saying that \"nobody\" is willing to discuss this in good faith is going way too far. Just because I don&#x27;t expect anyone to be able to convince me that it wasn&#x27;t a conspiracy doesn&#x27;t mean I&#x27;m not open to the possibility.All good faith means, in this context, is that one is willing to maintain intellectual honesty. That may be hard for many but far from all. reply jddj 20 hours agoparentprevAnd sadly the list of topics for which this is an excellent description of human behaviour seems to grow steadily. reply dontlaugh 20 hours agoparentprevExactly. How a CIA faction used Cuban exiles to assassinate him is far less interesting than why. reply knowingowl 18 hours agorootparentThe \"why\" (motive) is the most clear part: JFK was not willing to invade Cuba and depose Castro. To say this this really pissed off the DoD, CIA, Mafia, and Cuban rebels is putting it extremely mildly. They hated JFK with a murderous passion. reply lost_tourist 3 hours agoparentprevThis seems like one outlook but either case wouldn&#x27;t drastically change my skepticism of government. That it happened exactly as the official report says or it turns out that the CIA lied and there was a second shooter. I&#x27;ve seen an attempted coup (and the GOP attempt to minimize that and continued support of the dictator-in-waiting) which I thought would never happen in my lifetime despite noticing the polarization we&#x27;re all seeing. Nothing really surprises me much any longer when it comes to politics and how dirty it can be or if they didn&#x27;t lie at all. reply JPws_Prntr_Fngr 9 hours agoparentprevNot one word of what you just wrote is accurate. Source: [0][0] I pulled it out of my ass, same as you did. reply colordrops 10 hours agoparentprevThat&#x27;s true of most topics. This one is just more heated because of the historical significance and lack of direct evidence. reply adolph 14 hours agoparentprev> Probably if you&#x27;re about to comment on this post, you&#x27;ve got some motivated reasoning behind it that has nothing to do with finding out what really happened.Is that a recursive statement or are you somehow the only one with clean hands? reply Octokiddie 13 hours agoprevCutting to the chase:> He claims he spotted a bullet resting on the top of the back of the seat. He says he picked it up, put it in his pocket, and brought it into the hospital. Then, upon entering Trauma Room No. 1 (at that stage, he was the only nonmedical person in the room besides Mrs. Kennedy, and both stayed for only a short period), he insists, he placed the bullet on a white cotton blanket on the president’s stretcher.> ...> Yet the bullet that Landis now claims to have discovered that morning emerged largely intact and only moderately damaged, its base having been squeezed in. reply fsh 19 hours agoprevThe recollections of an 88 year old person about an event 60 years ago are simply not credible. He may truly remember picking up the bullet, but that doesn&#x27;t mean it actually happened. Since he didn&#x27;t mention it in his memos at the time, it probably didn&#x27;t. reply indymike 13 hours agoparent> The recollections of an 88 year old person about an event 60 years ago are simply not credible.My experience with aging family members is that their memory of old events tends to improve as their short-term memory seems to get worse. I&#x27;ve had family memebers not remember where an object is, and from their nursing home bed, when asked about \"what happened to ___?\" reply with remarkable accuracy - to the point we were able to find several family heirlooms (photos from WWII that were lost in the 1960s, an old service rifle, old writings, paintings) right where they said it was. I wonder if perhaps that is the case here. reply fsh 13 hours agorootparentI have had aging family members who remembered things that cannot possibly have happened. Going beyond anecdotes, false memories are a well known and empirically studied effect: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;False_memory reply gordian-not 21 hours agoprevA man in a prime position to write a book and make millions, writes a book reply lapcat 21 hours agoparentHe&#x27;s 88 years old and has been sitting on this information not cashing in for 60 years. reply arrowsmith 20 hours agorootparentMaybe his grandkids need money for college. reply Apocryphon 19 hours agorootparentGreat-grandkids even reply dylan604 13 hours agorootparentor just trying to pay off the existing student debt for the grandkids reply ManuelKiessling 12 hours agorootparentWait, now it all makes sense: Biden‘s student loan relief program existed only to prevent this book from being written, but the plan failed!Man, conspiracy theories are so easy — fun even! reply kasey_junk 20 hours agorootparentprevBut he does have a book coming out now… reply Apocryphon 21 hours agoparentprevMaybe he should’ve done it earlier in his life reply eurticket 9 hours agoprevWasn&#x27;t there a documented operation that JFK didn&#x27;t want to sign&#x2F;rejected, that pertained to the CIA wanting to set up false flags to justify war against Cuba?Found it: Operation Northwoods https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Operation_Northwoods reply missedthecue 8 hours agoparentSo the CIA killed JFK and then decided not to invade Cuba anyway? reply harry8 8 hours agorootparentKnowing nothing much about this there are still some obvious points to make.The CIA will not be one singular entity of one mind and focus. There will be factions in that organisation, there will be rogue elements. There does not have to be a grand master plan but there could be. There does not have to be uniform competence and there will not be. Operations go wrong all the time. Pieces will be moved into position at vast expense then not used for so many possible reasons. Further if it were a cia operation (and I have no idea about that) it may not have been intended to actually kill anyone and Oswald surprised people by his effectiveness.All sorts of wild stuff is plausible and you need evidence to assess it. Every huckster will trade on the doubt, there will be wishful thinking and genuine, directed official misinformation. Treating the CIA as an entity all marching in lock-step of one mind and purpose is an assumption that stretches plausibility and certainly requires evidence. Chaos is almost certainly a major factor in any explanation and indeed counts as the entirety of the official version of what happened and its aftermath. reply voisin 8 hours agoprevI seem to recall the bullet on the gurney story to figure fairly prominently in the latest JFK documentary by Oliver Stone. Am I mistaken? When I read this accounting it didn’t strike me as totally new but rather a vindication of a story that had been relegated to being a conspiracy? reply damontal 10 hours agoprevThe movement of his head has led some to suggest there was a shooter in the sewer that the car passed. reply WalterBright 13 hours agoprevPeople just can&#x27;t stand the idea that a lone nut could bring down Camelot. reply soderfoo 12 hours agoprevA great and semi related book is The Devil&#x27;s Chessboard: Allen Dulles, the CIA, and the Rise of America&#x27;s Secret Government reply JPws_Prntr_Fngr 9 hours agoparent+1. The Brothers: John Foster Dulles, Allen Dulles, and Their Secret World War is a great complimentary biopic. reply pella 21 hours agoprevNYT version: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37451699 reply mcpackieh 9 hours agoprevJFK was trying to stop Israel&#x27;s nuclear weapons program: https:&#x2F;&#x2F;www.jewishvirtuallibrary.org&#x2F;kennedy-administration-... reply kahirsch 9 hours agoparentAnd Johnson continued those policies. reply JPws_Prntr_Fngr 9 hours agoparentprevWow, yep. That&#x27;ll do it. reply AndyMcConachie 12 hours agoprevIt&#x27;s wild that people still talk about the Warren Commission as having any relevance. The House Select Committee on Assassinations is the last thing the government &#x27;officially&#x27; said on the case and they concluded there was a conspiracy and most likely not a lone gunman. reply chaostheory 14 hours agoprevHe should have spoken up 2-3 decades earlier for better credibility.Internally, the KGB considered the JFK assassination as a coup reply paulryanrogers 13 hours agoparentBy whom? And did they consider it successful? reply chaostheory 11 hours agorootparenthttps:&#x2F;&#x2F;www.npr.org&#x2F;sections&#x2F;thetwo-way&#x2F;2017&#x2F;10&#x2F;27&#x2F;560345132... reply shrimpx 14 hours agoprevBill Hicks was right. reply Simulacra 19 hours agoprevSuch a statement about the \"magic bullet\" leaves me with tremendous doubt. This idea that he put a pristine bullet that he found in the limousine, which later became the magic bullet, but somehow it got switched, just seems too far-fetched for me.All these years he never told anyone? It is completely different from his written statement at the time. After all these years, I call BS. reply jjtheblunt 11 hours agoprevif there were a way to set user-level filters on HN, i&#x27;d set one which drops all titles with subjunctive verbs (like the \"could\" here), everything about Elon Musk, etc.It would be interesting to analyze a collection of user-defined user-level customization filters, as some sort of zeitgeist. reply jmyeet 11 hours agoprevI highly suggest people go watch \"inside the book Depository\" [1]. It&#x27;s long but it gives a good overview of the sequence of events and the discrepancies.Thing is, it&#x27;s not a conspiracy theorist video. The best part of the video is the last segment where the creator uses all the examples to show just how unreliable eyewitness testimony is, even when fresh let alone decades later. They go on to say that pretty much any conspiracy theory relies on cherry-picking certain details as irrefutable while ignoring others and this is esentially an arbitrary decision based on whatever narrative someone is pushing.Additionally, the details supposedly changed never make sense for a conspiracy that is supposedly powerful enough to arrange all this.Lastly, people often see things through a modern lens. Presidential security is a big one. JFK used to stop his motorcade and go into the crowd. Anyone with a handgun could&#x27;ve ended him. These people weren&#x27;t all frisked and vetted. It was a different time. JFK&#x27;s assassination is probably a big part of why presidential security changed. So the idea that you needed to have or be a sniper (or a team of snipers) is a silly one and based on modern assumptions.Myths in this area persist too despite them being debunked. One that springs to mind is that you couldn&#x27;t fire Oswald&#x27;s rifle fast enough. CBS and the FBI tested and debunked this in the 1960s [2].When this happens you&#x27;ll often find the conspiracy theory moves the goalposts from it being \"impossible\" to \"very hard\". I&#x27;m sure it was hard but Oswald was also irrefutably a Marine-trained shooter.Personally my theory is that any mystery surrounding JFK is much like that of 9-11: intelligence agencies caught with their pants down, not wanting to upset allies and&#x2F;or not wanting to expose intelligence assets.The last point I&#x27;ll make is a study was recently done on the link between narcissism and conspiracy theories [3]. Now this has a lot of relevance to why who gets sucked into QAnon and their political leanings. But it&#x27;s relevant beyond that.A lot of people are uncomfortable with the idea that random things happen. They&#x27;d rather believe it&#x27;s all part of a plan. It&#x27;s almost preferable if it&#x27;s a nefarious force as some people love to LARP as being oppressed or even just being brave warriors standing up for what&#x27;s righteous. But this shares a lot of the psychology with those for a predilection for religion. And narcissim is the definition of main character syndrome.[1]: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5u7euN1HTuU[2]:",
    "originSummary": [
      "Former Secret Service agent Paul Landis alleges the discovery of a bullet in President Kennedy's limousine on the day of his assassination, potentially opposing the Warren Commission's \"Lone Gunman\" theory.",
      "The possible presence of an additional bullet raises doubts about the official account of the incident and could demand a reconsideration of established conclusions.",
      "Another key claim comes from Special Agent Richard Landis, who suggests a bullet was left on a stretcher at the hospital, contradicting the commission's assertion that the bullet originated from Governor Connally's stretcher."
    ],
    "commentSummary": [
      "The discussion overviews online debates about JFK's assassination and associated conspiracy theories, with topics ranging from CIA involvement to Warren Commission's report credibility.",
      "The single-bullet theory's validity, classified document withholding, and human memory fallibility serve as key debating points in the evaluation of witness testimonies.",
      "The discourse also highlights the role of individuals' behavior, availability of video evidence, and how these theories' relevance in today's politics."
    ],
    "points": 254,
    "commentCount": 350,
    "retryCount": 0,
    "time": 1694343589
  },
  {
    "id": 37458283,
    "title": "A Senior Engineer's Check-List (2019)",
    "originLink": "https://littleblah.com/post/2019-09-01-senior-engineer-checklist/",
    "originBody": "This website uses cookies to ensure you get the best experience on our website. Learn more Got it! Little Blah Subscribe ArchivesTagsCategoriesPagesHabit Tracker A Senior Engineer's CheckList Sunday, September 1, 2019 general articles in software development 3280 words 16 mins read Controls (click to expand) CheckList This is a simple checklist, and while it is useful to any software engineer, it is especially useful to senior engineers. # Task Effort Category Impacthigh low medium growth hiring leadership managers mentor network one-on-one politics technology Career high low medium Company high low medium 1 Understand the business aspect of your work, and what makes money. Eventually, only that matters. high leadership high high 2 Get involved with hiring for your team and company, and maintain a high bar for hiring quality candidates. medium hiring low high 3 Design and develop systems appropriate to scale, extensibility, and scope of the problem. Avoid over-engineering. high technology medium medium 4 Question everything and ask \"why\" repetitively until you get to the root of problems and situations. high technology medium low 5 Demand accountability and ownership from others. high leadership low medium 6 Once you understand the company's needs, lead at least one high-impact project with a clear definition and target of successful delivery. high leadership high high 7 Work towards disambiguating ambiguous problem statements. high leadership medium medium 8 Cultivate relationships with other teams and develop trust. high network medium medium 9 Do not be adamant about your views. Listen to others and accept that there is more than one way to look at a problem statement, and multiple valid solutions to a problem. medium network medium low 10 Be involved with multiple projects as a consultant, a reviewer and/or a mentor. medium network medium medium 11 Follow the principles of extreme ownership. high leadership high medium 12 Have strong mentors to help you navigate and grow in the company. high mentor high low 13 Take projects with high risk and high rewards. high growth high high 14 Strive for deep technical expertise in technologies used in your team. high growth high medium 15 Ask for stretch projects from your manager, or help her identify one for you. medium growth high high 16 Discuss the goals of your manager, and how you align your work with it. medium managers high low 17 Invest time in networking effectively with seniors, peers, and juniors. medium network high low 18 Be a mentor to a couple of junior engineers. medium mentor low medium 19 Increase your breadth of knowledge in the domain of your team/company. high growth high high 20 Drive your one-on-ones. Maintain a list of topics for the next one-on-one discussion. medium one-on-one high low 21 Discuss problems with your manager, but have some solutions beforehand. medium managers high low 22 Increase your breadth of knowledge in technology. high growth high low 23 Explore emerging technologies by building small prototypes. high growth medium low 24 Read a few technical books every year. high growth high low 25 Before suggesting the next big shiny technology for your production stack, understand its pros and cons thoroughly. high technology medium high 26 Schedule a regular one-on-one with your manager low one-on-one high low 27 Schedule a regular one-on-one with your skip level manager low one-on-one high low 28 [Reminder] One-on-one usually is not a status meeting medium one-on-one high low 29 Involve the manager in your personal life (just a little though) low managers low low 30 Actively seek feedback from your manager low managers high low 31 Keep your manager up-to-date in things you are involved with, but don't get bogged down in unnecessary detail low managers high medium 32 Keep your manager up-to-date in things you are blocked on low managers high medium 33 Keep your manager up-to-date on people you have difficulty working with medium managers high medium 34 Give constructive feedback to your manager medium managers high low 35 If you are overworked, let your manager know low managers high medium 36 If you are under-utilized, ask your manager for areas to explore medium managers high medium 37 If you have an ineffective or neglectful manager, talk to your manager about your expectations low managers high medium 38 If you have a micromanager, talk to your manager about your expectations low managers high medium 39 If you have an abusive manager, talk to your skip manager or HR with data points low managers high medium 40 If you have an ineffective skip manager and ineffective manager, switch the team or company high managers high medium 41 If you do not have a cordial relationship with your manager, switch the team or company high managers high medium 42 [Reminder] Leverage = impact produced/time invested. Use leverage as a yardstick for effectiveness high growth high low 43 Measure what you want to improve. Make efforts measurable medium growth high low 44 Maintain high visibility of projects which have a high risk high growth high medium 45 To deal with difficult folks, discuss with your managers and mentors low network low low 46 To deal with difficult folks, fall back to first principles low network low low 47 Be reachable to other engineers low network low low 48 Have a huge bias for action and delivery, but do not over-compromise on quality. Push back if required high leadership medium medium 49 Simplify code, systems, and architectures relentlessly high technology low high 50 Demand high-quality work from others, but be pragmatic medium technology low high 51 Prioritize fixing tech-debt in code, systems, and architecture when the incremental cost to develop keeps rising high technology low medium 52 Document extensively, and demand it from others. Document \"why\" more than \"how\" high technology low medium 53 Avoid politics, but have right folks vouch for your work high politics medium low 54 When dealing with politics, fall back to first principles high politics low low 55 If politics thrives due to team or company culture, switch high politics high low 56 Try not to get involved in office gossip low politics medium low 57 Avoid stretching yourself too thin to be effective medium leadership medium low 58 Respect code and systems that came before you. There are reasons for every code and every guard that exists in production low technology low medium 59 Before you suggest major refactors, ensure you understand the system deeply medium technology medium high 60 Resist the urge to refactor major systems to achieve simplification, because there's a risk you will end up with a similarly complex system after some time medium technology medium high Showing 1 to 60 of 60 entries Select all Deselect all Download selected Resources click to expand Subscribe * indicates required Email Address * This information will only be used to send you updates and is stored in Mailchimp. If you liked this post, please share with others! If you have any feedback, drop me a mail. My email address is listed here. Curated checklist for your travels",
    "commentLink": "https://news.ycombinator.com/item?id=37458283",
    "commentBody": "A Senior Engineer&#x27;s Check-List (2019)Hacker NewspastloginA Senior Engineer&#x27;s Check-List (2019) (littleblah.com) 221 points by gautamsomani 16 hours ago| hidepastfavorite77 comments a_square_peg 15 hours agoAssuming technical competency is given, I think senior engineer really needs to do two things well:1. Be able to make a design decision - among multiple options and with incomplete data and uncertainties, a senior engineer needs to be able to make a decision and be accountable for it in order to move the project forward. I think a good interview question would be to ask about their difficult design decisions.2. Be able to identify wrong solution (most of the time) - maybe this comes with technical competency but a lot of resource is wasted chasing solutions that with the benefit of experience, should have been evident early on. reply beebmam 15 hours agoparentDisagree. A senior engineer should make evidence based decisions, as should any engineer. If there&#x27;s missing evidence for a conclusion, then a senior engineer should be able to design experiments which gather more evidence to derive a conclusion.Senior engineers should not be con-men. reply CapitalistCartr 14 hours agorootparentThat sounds great, but hard decisions are hard because there isn&#x27;t time, money, other resources to have all the facts, yet a decision must be made. There might not even be any way to know for sure without taking one path. Experience is all we have to guide us. Progress is full of such decisions, made in a gray fog. Fear of being wrong is paralyzing. reply galaxyLogic 14 hours agorootparentExactly. My favorite metaphor for SW-development is playing chess. When you make a move, a decision, new choices, new decisions to make, open up and other ones may no longer be practical.What you decide and do now, affects what you can and must decide next.Except unlike in chess we don&#x27;t really have the exact rules of the game anywhere. Still we must make choices which affect what moves can be chosen later.It is also like building a house, once you decide how to build the ground-floor and what it stands on, that greatly affects how the floors above that can be built (not too heavy, not too light etc.).It is often difficult to understand all the consequences of a design decision, what can be done and chosen after that, until you actually implement that design. reply aYsY4dDQ2NrcNzA 13 hours agorootparentPath dependence. reply jldugger 14 hours agorootparentprev> That sounds great, but hard decisions are hard because there isn&#x27;t time, money, other resources to have all the facts, yet a decision must be made.While I am sympathetic to the concept of reasoning under uncertainty, the way you&#x27;ve framed it is hardly engineering anymore.Design projects come with a spectrum of data requirements, and each has its own cost function for improved accuracy. For example, knowing exactly how long the bridge you need to build matters greatly, and the cost of surveying should be pretty low. In contrast, measuring the soil at the site you build on top of has a variety[1] of options with varying costs. You can&#x27;t ever be 100 percent certain that your sampling was good enough, but the samples more you have the more confident you can be. Depending on the project and design, you may not need the most expensive and most accurate option, but you probably don&#x27;t want to just rely on priors built through \"experience.\"Translating this to the world of software, we have a variety of data collection strategies. A&#x2F;B tests, canaries, software instrumentation, tracing, offsite monitoring, f-scores, beta tests, market surveys, and more. The best thing you can do as an engineer making an uninformed choice is to design the system to collect the data you are missing and to make it easy to change your design later. Amazon calls these \"two way doors\" versus \"one way doors\"; if your decision was wrong you can go back and make a different choice. As an example, if you are designing a caching system, spending a bit of time to generalize the API will allow you to swap between policies as you collect data about cache hit rates. If you don&#x27;t, the cost of changing your mind goes up as more things depend on the nuances of your API.Rather valorize making uninformed decisions, I&#x27;d prefer to valorize flexibility and continuous data collection. Seen this way, the old adage \"There&#x27;s never enough time to do it right, but always plenty of time to do it over\" is a coherent philosophy.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Geotechnical_investigation#Soi... reply f1shy 14 hours agorootparentprevIf you have to make decision, and lack information, time and money to even try something to understand the best decision, you are having problems bigger than technical ones; and even the best engineer in the world will probably not do better than a dice reply MAGZine 14 hours agorootparentprev> A senior engineer should make evidence based decisions, as should any engineer.... sooo there is no distinction between a senior engineer and a non-senior engineer? you&#x27;ve really said nothing in this comment.senior engineers have seen enough things to know what the right solution is in many cases, without having to take a bunch of time to collect evidence. that&#x27;s what makes them senior, not just &#x27;good&#x27;. reply lowercased 13 hours agorootparent> seen enough things to know what the right solution is in many casesWhen dealing with uncertainty (nearly always) it&#x27;s generally easier to identify and rule out what &#x27;wrong&#x27; solutions are. There are often multiple obviously &#x27;wrong&#x27; options (no, we should not keep a user&#x27;s password in plaintext, even if the goal is to make it easy to recover a lost password), but picking a &#x27;right&#x27; one... from a whittled down list, it may often come down to familiarity or convention rather than an arbitrary \"this is the only 100% correct solution\". reply f1shy 14 hours agorootparentprevThen the problem is not missing information, as stated. There is enough information, if you have enough experience. reply beebmam 14 hours agorootparentprevDisagree, profoundly. reply Nevermark 14 hours agorootparentprevAn important series of skills would be:1. Identify every project dimension with risks. The big one: project -> use -> user -> reward -> costumer fit? (Where user and customer may, or may not be the same.)Price cost economics? Technical complexity? Technical experience shortfalls? Project resource availability? Solution resource efficiency? Safety? Third party dependencies?2. Identify each significant risk in each risk dimension.3. Identify the simplest question (or two) whose answer will reduce or eliminate each risk.4. If a risk can’t be mitigated by answering a single question (or two), maybe it is really a combination of risks, or risk dimensions. If so break them out, repeat.4. Craft the simplest research task to resolve each risk question.—This sequence is a special case of focusing energy on upstream tasks, before investing in downstream tasks.Or as I like to say: move slow to move fast.—A meta risk is loops in risk&#x2F;work dependencies.Classic example: Stakeholder wants to see something working before you resolve risks of getting something working.Identify the simplest, sparsest form of a loop is one way forward.Alternatively, break the loop. Identify alternate ways to satisfy the stakeholder. Find a way to remove dependency on the stake holder (constructively). reply delusional 13 hours agorootparentprevI can kind of agree with your sentiment. We should run experiments, regardless of our skill level. We should, in fact, regard anything we do as an experiment. Very few decisions in the real world are irreversible. Doing experiments doesn&#x27;t mean there&#x27;s no skill to it. The Senior engineer will know what hypothesis is most likely to prove true, and will start with a system design that will work out well assuming that hypothesis to be true.This is what the previous commenter referred to as \"making a decision without all the evidence\". If the senior engineer turns out to be right, and the hypothesis proves true, the experiment becomes the system. If the hypothesis turns out false, the system might still be workable, otherwise it&#x27;s refactored into some new experiment.The senior engineer is better at making that initial guess as the correctness of a hypothesis. Just like a senior scientist. reply stinkbutt 14 hours agorootparentprevA senior engineer should work in an organization that actually enables this type of engineering reply paulcole 13 hours agorootparentprevThere’s always going to be missing evidence. Almost all business decisions can be made without 100% certainty. Make your conclusion with what you have available and find out if that’s good enough. Don’t dawdle trying to get more info that’s probably not needed. reply bsder 10 hours agorootparentprevSometimes a decision needs to be made today. That&#x27;s just life.Engineering is all about what you do when you don&#x27;t have perfect information.This is why real engineers have things called \"safety margins\". reply shortrounddev2 14 hours agoparentprevMentoring is as important as the technical output. You cannot be a senior engineer without being able to mentor reply f1shy 14 hours agorootparentI think this is the most important: make the team grow. reply f1shy 14 hours agoparentprevThis HR idea of doing questions abput the past to “know” how good somebody will be in the future, is doomed to fail reply noitpmeder 5 hours agorootparentCompared to what? Leetcode questions? I&#x27;d say an in depth discussion about past projects is the only way to know if someone will be a valuable future member of any team. reply kqr 14 hours agorootparentprevSource?From what I can tell, that is the only good predictor we have. See Tversky&#x27;s work with the IDF or the available CTA methods for studying expertise, e.g. CDM. reply karol 15 hours agoprevIt&#x27;s the same as the problem of finding a good cleaner. If someone is responsible, thorough, turns up on time, has attention to detail, can handle delicate objects, is trustworthy around children and has good manners - then that person is already too good to be an ordinary cleaner and will get hired elsewhere, become a manager or a business owner. reply medstrom 14 hours agoparentI don&#x27;t think the world permits so easy mobility. I have worked with cleaners who ticked all those boxes, they were still stuck in their job. Meanwhile not all managers tick those boxes. reply Horffupolde 14 hours agoparentprevIt’s the eternal paradox of life. reply Aurornis 15 hours agoprevI’ve had the good fortune to hire and work with a lot of ambitious engineers.One trap with lists like this is that it can be easy to lose sight of your core workload. On more than one occasion I’ve had to ask senior engineers to pump the brakes on all of their mentoring, leading, organizing, example-setting, and helping activities because their own work was not getting done.You only have so many hours in a work week. Get your priority work done first, then layer in additional activities selectively. Don’t think you need to be doing all of these things on the list all of the time. reply fifilura 14 hours agoparentThen maybe that person has implicitly become a manager.And to mentor and help others may very well be the best spent time for the company as a whole. But then his biggest tasks should be done by one of his more junior team-members. reply proc0 13 hours agorootparentThis is why most software companies tend to ship buggy messes that need to be constantly patched and updated. Software engineers never get to fully focus on optimizing software for the long term because as they gain experience within the org. they are moved away from engineering into management of other engineers.I think I get the motivation, an engineer managing a team of engineers can achieve \"more\" in less time. However I put \"more\" in quotes because a single expert engineer can build better, faster, and more reliable than an entire team, once they have mastered the systems and tools. That will never happen if they rarely touch code and instead attend meetings to talk about planning and scheduling. reply za3faran 8 hours agorootparentThe promotion incentives at least in the bigger companies generally do not favor becoming a domain expert in the product. Everyone wants to become \"staff+\" and rake in the big bucks, and it&#x27;s a race to build an empire at the cost of getting things done many times. reply Longhanks 13 hours agorootparentprevIf someone disregards his or her tasks without communication to his or her superior, and fails to get the tasks he or she was hired for done, a promotion is hardly the right answer in my opinion. reply kbutler 14 hours agoparentprevIt can be hard to accurately measure the value of those activities.You may be getting a short-term benefit at a huge long-term cost. reply TensorTinkerer 15 hours agoprevReally digging the list, especially the emphasis on simplicity in systems. Reminds me of that age-old principle: \"What is the simplest thing that could possibly work?\" I&#x27;ve been on teams where we battled convoluted systems. Sometimes a refactor, even a daunting one, clears so much technical debt and revitalizes the team.The &#x27;ask \"why\"&#x27; bit? Gold. It&#x27;s not just about coding but understanding the bigger picture. Feedback loops in software? Amazing. Feedback in career growth? Equally crucial.It&#x27;s a solid reminder that our game isn&#x27;t just code; it&#x27;s the soft skills too. They can seriously make or break your trajectory. But as always, while guides are great, everyone&#x27;s path in tech is unique. It&#x27;s like code; it evolves, iterates, and adapts. reply playingalong 15 hours agoprevI agree with the list and there is nothing wrong with it.Though, I would like to emphasize this is clearly an Individual Contributor kind of a perspective. There are hardly any bullet points encouraging building and maintaining work culture, growing other people, serving as an example to follow. Maybe a handful out of the 60 fall into this bucket.Thus don&#x27;t consider this list anywhere near complete if your career path envisions being a manager (of different kinds). reply Aurornis 15 hours agoparent> There are hardly any bullet points encouraging building and maintaining work culture, growing other people, serving as an example to follow.Well the title is literally about being a “Senior Engineer”, not a manager. That said, there are numerous bullet points about mentoring others, leading by example, and setting work culture. Number 18 is “Be a mentor to a couple of junior engineers.”> Thus don&#x27;t consider this list anywhere near complete if your career path envisions being a manager (of different kinds).While you’re not wrong, I don&#x27;t think anyone should expect a checklist titled “Senior Engineer’s Checklist” to cater to management items. A manager’s checklist would subtract a lot of the IC items from this list.Management isn’t a superset of IC work. It’s a different job. reply jameshart 15 hours agoparentprevThere&#x27;s also some questionable stuff on here for ICs:> Keep your manager up-to-date on people you have difficulty working withIf one of my directs came to a one on one and shared their updated enemy-list with me, I&#x27;d be pretty concerned. reply fragmede 14 hours agorootparentI... what do you you see as your job as a manager? Your entire job as a manager is to manage your direct reports. Knowing who they&#x27;re working with, and who they&#x27;re having difficulty working with (and then to smooth it over so they can continue to work together, or move people around so they don&#x27;t have to) is core to the job of managing y&#x27;know, people. reply cratermoon 15 hours agorootparentprevIf one of my directs didn&#x27;t tell me about difficult-to-work-with people, I&#x27;d be concerned. I want to know if there are people everyone finds difficult work with, and the best way to know is to hear from all ICs. reply alex_lav 14 hours agorootparentprevThe fact that you equate “difficulty working with” as an enemy list suggests to me you’re probably not equipped to be managing people. Respectfully. reply jameshart 14 hours agorootparentThere&#x27;s a difference between having some awareness of interpersonal challenges my team have, versus one of them having, among the list of 61 principles by which they govern themselves, &#x27;keeping me up to date on who they are having difficulty working with&#x27;. I mean, I note that there isn&#x27;t a corresponding advice to &#x27;keep your manager up to date on people you enjoy working with&#x27;.Overall, it just sounds like they plan on making problems and then bringing them to me to resolve. Which, sure, would require &#x27;managing&#x27;. reply alex_lav 14 hours agorootparent> Overall, it just sounds like they plan on making problems and then bringing them to me to resolve. Which, sure, would require &#x27;managing&#x27;.Yeah…again, I’m trying to communicate respectfully, but I really think these perspectives aren’t fit for being responsible for others’ employment. reply jameshart 13 hours agorootparentYou&#x27;re clearly a very serious person. It might help you to be aware that some other people take things, in general, a little lightly.Out of context guidance consisting of little faux-wise aphorisms like that of the OP is just kind of inherently amusing, especially when offered earnestly, precisely because it is open to misinterpretation - and my suggestion that it could be interpreted as advice to keep your manager apprised of who&#x27;s currently on your enemies list was meant to illustrate that risk.As putative advice to senior engineers for how to conduct themselves, it struck me as something which some toxic engineers might take as endorsing their superior attitude. That makes it bad advice, and that&#x27;s why I&#x27;m mocking it.But how I react to the idea of this sort of thing being offered as career advice, respectfully, tells you absolutely nothing about how I conduct myself in my professional role. reply alex_lav 13 hours agorootparent> and my suggestion that it could be interpreted as advice to keep your manager apprised of who&#x27;s currently on your enemies list was meant to illustrate that risk.Yeah....again....not an enemies list.> As putative advice to senior engineers for how to conduct themselves, it struck me as something which some toxic engineers might take as endorsing their superior attitude. That makes it bad advice, and that&#x27;s why I&#x27;m mocking it.Yeah...again...this perception is a toxic _manager_ trait.> But how I react to the idea of this sort of thing being offered as career advice, respectfully, tells you absolutely nothing about how I conduct myself in my professional role.We can disagree, that&#x27;s fine. Thankfully you don&#x27;t work in my organization, so your opinion is of 0 value to me. I had (obviously incorrectly) hoped some sane feedback might make you reevaluate your behavior, but alas stubbornness prevails. Hopefully your reports can manage working with you effectively. replyjameshart 15 hours agoprevNot really a &#x27;checklist&#x27;. Can anyone honestly go down this list and mark any of the items affirmatively as &#x27;complete&#x27;? reply helpfulContrib 15 hours agoparentYou can certainly use the form that way, as your own instance of a checklist, and it seems the site has the purpose of providing such mini &#x27;applications&#x27; in a local-store friendly manner - see the Travel checklist on the same site, for example.Pretty nifty, if you think about it. Storage stays local, it looks like .. but I am not an expert. I just like the form of this.3-digit slashdot ID&#x27;s notwithstanding, I hope we see a revival of cute little cottage-&#x2F;hobby sites like this, or a kind of perpetually simple cache of folks who just render their genius to static files, in cute ways, and leave it at that... over and over for a few years. reply dbalatero 15 hours agoparentprevNo, but you could keep checking in on them and seeing how you&#x27;re doing on a semi recurring basis. reply donutshop 12 hours agoparentprevI agree with this. This is more of a list of reminders to keep in mind IMO. reply ChrisMarshallNY 15 hours agoprev> Resist the urge to refactor major systems to achieve simplification, because there&#x27;s a risk you will end up with a similarly complex system after some timeWord reply shikshake 14 hours agoprev“Strive for deep technical expertise in technologies used”In general, how would someone go about this? Is it just something that should happen over time or is there a method&#x2F;goal to strive for? reply renegade-otter 14 hours agoparentIt&#x27;s possible if you keep things simple, but it&#x27;s a rather naive goal in most places which have already grown in size and complexity. Just knowing what&#x27;s happening with the other teams and how your work fits into it is already a full-time job. I&#x27;ve spent DAYS on Slack without getting anything done - I had to get up early in the morning.I wrote about something related recently.\"I am not your Cloud person\": https:&#x2F;&#x2F;renegadeotter.com&#x2F;2023&#x2F;07&#x2F;26&#x2F;i-am-not-your-cloud-per... reply Agingcoder 13 hours agoparentprevRead books, on a variety of topics, including the ones you don’t know about. A book will give you a much broader and deeper understanding of most topics than random blog posts on the internet. Make sure you read one or two a year, and think about how you’d apply what you’re learning at work. Even better, find an actual application at work.I’ve found that solving tricky problems ( horrible network related issue, performance bugs, strange behaviour of program&#x2F;framework&#x2F;os, someone you know deciding to use new tech you don’t know about etc ) is usually a good way of finding a topic to explore.Find someone who’s interested in actively learning things, it makes things a lot more pleasant, and it’s easier to remain motivated. You don’t have to learn the same things - just share the fun stuff you’re learning.Finally, and most importantly : it’s ok if you’re not learning as quickly as when you were at university. It’s not a competition. You have a full time job, don’t have a lot of time, so just make sure that you enjoy learning, so that you keep doing it ! reply alex_lav 14 hours agoparentprevDon’t stop learning at the end of your use-case for a piece of tech. If your team uses a tool, understand approaches you didn’t take, trade offs and ultimately why you chose the path you chose. Understand even other pieces of tech and their approaches. Also, deeply understand failure scenarios and how to mitigate them.Basically just dig in beyond “it works”. You’d be surprised how many devs never read a tool’s docs if they don’t absolutely have to. reply kbutler 14 hours agoparentprevContinuing study and investigation after achieving functional competence.Learn more apis, dig in to implementation, read other people&#x27;s code, ...There&#x27;s a big difference between engineers who consistently, proactively study and learn vs those who just leverage previous knowledge.And I&#x27;ve experienced both sides of that in myself. reply trav4225 15 hours agoprevI always find advice like this a little confusing. A lot of these things seem (to me) to be none of the engineers&#x27; business.To me, engineers receive specs from management and implement solutions that meet those specs. And that&#x27;s it.I suppose my personal experience must not be how things work elsewhere! Kind of fascinating, and it makes me wonder if people enjoy all this extra responsibility and how things go when engineers disagree with management. reply iteria 14 hours agoparentWhat you&#x27;re talking about to me is mid-level work. Seniors deal with ambiguity and feasibility analysis. Non-technical people often don&#x27;t understand the level of tech necessary. They&#x27;ll say, \"I want a bridge about this long\" very nice, but but did you consider the about wind that whistles through this area ? Also, how many lanes? Yeah that many is too few because once this bridge goes up we&#x27;re not gonna be reasonably able to close it even for maintenance. We need at least 4 lanes. Isn&#x27;t there a cement shortage? Hm.. maybe we can use this material instead? No. I don&#x27;t think building with wood for this length is a great idea.You get the picture. Yes lead developers exist, but they only have so much time to do little battles and they&#x27;re busy making sure the big things are arguing correctly. Senior engineers should be able to talk to design about a redesign necessary because iOS just isn&#x27;t capable of this it turns out or the cool effect you saw is only available on a version we don&#x27;t use and can&#x27;t update to right because complex reason.If you&#x27;re just taking your requirements and working without having to negotiate with another person, you&#x27;re probably not doing senior work.Some of it I the site I don&#x27;t think is senior work really unless you&#x27;re a tiny shop, but they&#x27;re not weird since these are all skills a for senior adjacent roles that any senior might be called on to take randomly. It&#x27;s not uncommon in many shops for leads to be a spontaneous and temporary role for some project that disappears on major release. reply cratermoon 5 hours agorootparentI&#x27;m not even sure that a mid-level engineer would be just taking specs and implementing them. Maybe early-mid, the sort who are moving up from building easy things to building bigger things, but even at mid level an engineer should be able to take ownership of some small set of related features for a system. reply noitpmeder 4 hours agorootparentEveryone is building to spec. As you get more senior the specs just get more vague ;) reply jkaptur 14 hours agoparentprevIt&#x27;s definitely interesting how people with the same title can have such different experiences. I&#x27;ll try to give the other perspective, but please understand that it&#x27;s a huge topic and this is a simplification.My experience has been an issue is raised - usually by management or \"the business\", but sometimes by engineering. \"Our website is too slow!\". Now someone has to step up and clarify things. Like: * what does \"fast\" even mean for our website? It would be great to have an objective metric. * Is there such a thing as \"fast enough\"? * How much time &#x2F; effort &#x2F; money is a given improvement worth? * How do we prioritize this vs. everything else we could be working on?A project spec comes out of those discussions, but the discussions themselves have significant technical and business inputs.I don&#x27;t view taking part in these discussions as \"extra\" responsibility, I view it as a core part of the job. I&#x27;ve also seen what happens when specs are written without technical input: it makes implementing them a lot less pleasant. reply proc0 13 hours agorootparent> A project spec comes out of those discussions, but the discussions themselves have significant technical and business inputs.Then managers should learn whatever it takes to be able to make these types of decisions. There seems to be a double standard where engineers have to do all of these non-engineering tasks, meanwhile non-engineers never have to learn the systems in depth.I think programming is a hard enough job that warrants 90% of focus, at least to be able to reap the benefits of computer science. At the dawn of generative AI, we can clearly see software has no limits, yet limits are implicitly imposed by re-prioritizing an engineer&#x27;s time with \"soft skill\" tasks and having them spend a huge amount of time thinking about things that have little to do with computer science.If a business needs that specific intersection of skillset, perhaps it should be a new role, instead of stretching the role of engineering and missing the opportunity to innovate at the software level, which in the end would help the business anyway. reply nuancebydefault 15 hours agoparentprevSometimes (often) you feel like following the requirements is not the correct way, because they look fine at first sight but not so bright when doing a first analysis or design. Then you tend to get involved with the \"none of my business\" business. reply danwee 12 hours agoprev> Strive for deep technical expertise in technologies usedAnd that alone occupies most of my (working&#x2F;free) time. Not sure how I&#x27;m supposed to keep up with the rest of the list. To know technologies is one thing, to have deep tech expertise in many technologies is a completely different one. reply lr4444lr 15 hours agoprevWow, 60 items and I don&#x27;t disagree with any of them. reply sacnoradhq 13 hours agoprev> 8. Do not be adamant about your views.I worked at a MAANG where this was not the case. The pecking order of \"seniority\" was who was the most \"right\" and who could poke the most holes in everyone else&#x27;s ideas while denying others&#x27; contributions while bragging about how essential and important their work was in a semi-agro manner that discouraged dissent and curiosity.In my view, marks of intelligence include lacking strong biases, comfort with ambiguity, be willing to propose hypotheses, experiment, gather data, and be proven wrong. reply nuancebydefault 15 hours agoprevZooming in on check 4, ask &#x27;why&#x27; until you find the root. For some reason I tend to do this almost naturally, with mixed results though.Especially when reviewing code, you often see how things can be done more simply, and asking \"why\" to the reviewee can sometimes backfire because of touching a sore point.Thinking about it, not only when reviewing code. Also, when you question the used processes you often bump into \"we found out from experience this works best\" or \"why change a working process\". So always using the \"why\" tactic can be frustrating at times. reply arkoinad 7 hours agoprevSome of the points are very company&#x2F;team specific dependent. And also dependent on culture of the company. reply dang 14 hours agoprevDiscussed at the time:A Senior Engineer&#x27;s CheckList - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=20914236 - Sept 2019 (143 comments)(that shouldn&#x27;t have been a Show HN! too late now) reply donutshop 11 hours agoprevRelevant discussion from the past https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=16367997 reply mellosouls 11 hours agoprev\"Understand the business aspect of your work, and what makes money. Eventually, only that matters.\"Applies only to commercial organisations (and no, even with those money is not the be-all and end-all) so not impressive as a number one, at least with that wording. Understanding business is clearly key though.TBH that and the rather self-satisfied \"it is useful to any software engineer, it is especially useful to senior engineers.\" on a rather enigmatic website lacking in other interesting writing put me off considering it further. reply karol 15 hours agoprevFlip prio to high, the list shrinks to 11. Tick all and congratulate yourself. reply cratermoon 15 hours agoparentYou mean Company impact? I see \"effort\" and two categories for impact - Career and Company. Also I notice that there&#x27;s nothing in the \"managers\" category that has high company impact. Seems about right. reply crtified 13 hours agoprevPoint 1 (\"Understand the business aspect of your work, and what makes money. Eventually, only that matters.\") is depressing to me. reply GreedClarifies 12 hours agoprevA lot of Amazon in that list, that&#x27;s not a bad thing, one of Amazon&#x27;s greatest strengths is its principles.Did the author spend time at Amazon? reply johnea 15 hours agoprev#61: Shorten the checklist... reply tennisflyi 12 hours agoprevGlad number one was explicit. It might not be what you consider but for most others it is. reply quantum_state 15 hours agoprevGreat list … thanks for sharing reply 29athrowaway 13 hours agoprevThere is nothing about engineering in that list. reply cratermoon 15 hours agoprevThe only part of this I disagree with is \"Couple of years of Relevant Practical Experience\" is senior. Intermediate, sure. Senior should be at least five years AND at least two projects. reply zer8k 8 hours agoprev [3 more] [flagged] lolinder 7 hours agoparent> Be amazing at bullshitting. Small project? Make the mole hill into mount everest. Big project? Act like you just saved the company. Study people. Your manager and their manager have exploitable weaknesses. ... Fuck people who think honesty is how you get ahead. ... Exploit every weakness. Don&#x27;t be an asshole of course. That won&#x27;t get you ahead.Following the advice in this paragraph—bullshitting and exploiting people to get ahead—makes you into an asshole. There&#x27;s no way around it.For myself, I&#x27;d rather not \"get ahead\" if \"getting ahead\" requires turning myself into that which I despise. I&#x27;ve had to work with people like this, and I will not bring that hell on anyone else. reply mannyv 7 hours agoparentprev [–] Sounds like the former staff from Twitter! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The website offers a comprehensive checklist designed to assist senior engineers in their career progression and success, containing key tasks and principles.",
      "It covers diverse topics such as leadership, hiring practices, technology, networking, and the cultivation of professional relations, recognising the business facets of their roles.",
      "They are guided on handling challenging situations, work prioritization, continuous learning, maintaining open-mindedness, enforcing accountability, and discouraging system over-complication."
    ],
    "commentSummary": [
      "The conversations involve various aspects of a senior engineer's role, responsibilities, and hurdles, such as decision-making, mentorship, people management, ambiguity, communication, problem-solving, understanding business nuances, and diverse skill requirements.",
      "There exists a disagreement over the importance of experience versus evidence-based decision-making, showing that different perspectives exist within the field.",
      "The discussions underscore the multi-dimensional nature of senior engineering positions and the necessity for a mix of technical expertise, experience, and effective leadership skills."
    ],
    "points": 221,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1694368662
  },
  {
    "id": 37457796,
    "title": "Goodbye to Thien-Thi Nguyen",
    "originLink": "https://lists.gnu.org/archive/html/emacs-devel/2023-09/msg00713.html",
    "originBody": "emacs-devel [Top][All Lists] Advanced [Date Prev][Date Next][Thread Prev][Thread Next][Date Index][Thread Index] Goodbye to Thien-Thi Nguyen From: Amin Bandali Subject: Goodbye to Thien-Thi Nguyen Date: Sat, 09 Sep 2023 23:55:05 -0400 User-agent: Gnus/5.13 (Gnus v5.13) Emacs/30.0.50 (gnu/linux) We have learned with deep sadness that Thien-Thi Nguyen (ttn) died in October 2022. Thien-Thi was a hacker, artist, writer, and long-time maintainer and contributor to many GNU programs as well as other free software packages. He was the GNU maintainer of the rcs, guile-sdl, alive, and superopt packages, and he was working on GNU Go as well. Thien-Thi especially loved GNU Emacs, GNU Taler, and GNU Go: he was the author and maintainer of the xpm, gnugo, ascii-art-to-unicode, and hideshow GNU Emacs packages and made substantial contributions to many others such as vc, as well as to GNU Taler and its documentation. We greatly miss Thien-Thi in the free software community - his death is a great loss to the Free World. reply via email to [Prev in Thread] Current Thread [Next in Thread] Goodbye to Thien-Thi Nguyen, Amin Bandali <= Re: Goodbye to Thien-Thi Nguyen, Emanuel Berg, 2023/09/10 Re: Goodbye to Thien-Thi Nguyen, lux, 2023/09/11 Re: Goodbye to Thien-Thi Nguyen, Dr. Arne Babenhauserheide, 2023/09/11 Prev by Date: Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084 Next by Date: Re: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084 Previous by thread: Treesit Regression In ec4d29c4494f32acf0ff7c5632a1d951d957f084 Next by thread: Re: Goodbye to Thien-Thi Nguyen Index(es): Date Thread",
    "commentLink": "https://news.ycombinator.com/item?id=37457796",
    "commentBody": "Goodbye to Thien-Thi NguyenHacker NewspastloginGoodbye to Thien-Thi Nguyen (lists.gnu.org) 205 points by signa11 17 hours ago| hidepastfavorite12 comments toomuchtodo 16 hours ago\"Emacs is the ground. We run around and act silly on top of it, and when we die, may our remnants grace its ongoing incrementation.\" -- Thien-Thi Nguyen.https:&#x2F;&#x2F;savannah.gnu.org&#x2F;users&#x2F;ttnhttps:&#x2F;&#x2F;www.emacswiki.org&#x2F;emacs&#x2F;ThienThiNguyenhttps:&#x2F;&#x2F;en.wikiquote.org&#x2F;wiki&#x2F;Emacs reply jdblair 16 hours agoprevOh no, this is sad to read.I worked with ttn a long time ago, 1999 to 2001, and lost touch with him a few years later. The last time I saw him in person was in my kitchen in Oakland in 2001.He was one of the good ones. reply qorrect 15 hours agoparentWhat were y&#x27;all working on back then? reply jdblair 15 hours agorootparentWe worked at Cobalt Networks at the same time, then a smaller software company in Berkeley for a short time. reply eduction 8 hours agorootparentI love Cobalt Cube. Were you there after it sold to Sun? Did you know Thomas Oh? reply em-bee 15 hours agorootparentprevoh, i have one of those cobalt cubes (no longer in use, don&#x27;t know if it still works). i loved that machine. it served as a home server for many years. reply linuxlizard 12 hours agorootparentprevI loved the Cobalt Cube! Such an awesome bit of hardware and software. reply raybb 14 hours agoprevRest in peace. Also looks like his site is gone already (but on IA) https:&#x2F;&#x2F;www.gnuvola.org&#x2F;If you know some links to his works or projects maybe add it to his wikidata: https:&#x2F;&#x2F;www.wikidata.org&#x2F;wiki&#x2F;Q110168816 reply notorandit 15 hours agoprevDid it take 1 year to know he was passed away? reply kelnos 14 hours agoparentI thought this was notable too. I guess sometimes people&#x27;s online lives are separate enough from their in-person lives that a long online absence can be attributed to the person just taking some time away, without anyone digging in to find out what&#x27;s going on. reply zelphirkalt 12 hours agoprevI saw some of his projects in the GNU Guile ecosystem. Always wondered who that might be. reply bitwize 16 hours agoprev [–] He was also a Guile hacker back in the day. I will miss him. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Thien-Thi Nguyen, a renowned hacker, artist, and writer who made substantial contributions to GNU programs and free software packages, has unfortunately passed away.",
      "Nguyen was recognized for his work on GNU Emacs, GNU Taler, and GNU Go. He was also the author and maintainer of various Emacs packages.",
      "His departure signifies a considerable loss to the free software community as his contributions were invaluable."
    ],
    "commentSummary": [
      "Thien-Thi Nguyen, a well-regarded member in the Emacs and GNU Guile communities, has sadly passed away.",
      "Individuals from these communities are expressing their grief and sharing memories associated with him.",
      "Discussions are ongoing about the contributions he made through his projects and the significant impact he had on the community."
    ],
    "points": 205,
    "commentCount": 12,
    "retryCount": 0,
    "time": 1694365704
  },
  {
    "id": 37459371,
    "title": "Why is the ocean salty? (2022)",
    "originLink": "https://www.usgs.gov/faqs/why-ocean-salty",
    "originBody": "Skip to main content An official website of the United States government Here's how you know U.S. Geological Survey SCIENCE PRODUCTS NEWS CONNECT ABOUT Latest EarthquakesLive WebChat Share Social Media Label Breadcrumb FREQUENTLY ASKED QUESTIONS OCEAN Why is the ocean salty? Oceans cover about 70 percent of the Earth's surface and about 97 percent of all water on and in the Earth is saline—there's a lot of salty water on our planet. By some estimates, if the salt in the ocean could be removed and spread evenly over the Earth’s land surface it would form a layer more than 500 feet (166 meters) thick, about the height of a 40-story office building. But, where did all this salt come from? Salt in the ocean comes from rocks on land. Here's how it works: From precipitation to the land to the rivers to the sea.... The rain that falls on the land contains some dissolved carbon dioxide from the surrounding air. This causes the rainwater to be slightly acidic due to carbonic acid. The rain physically erodes the rock and the acids chemically break down the rocks and carries salts and minerals along in a dissolved state as ions. The ions in the runoff are carried to the streams and rivers and then to the ocean. Many of the dissolved ions are used by organisms in the ocean and are removed from the water. Others are not used up and are left for long periods of time where their concentrations increase over time. The two ions that are present most often in seawater are chloride and sodium. These two make up over 90% of all dissolved ions in seawater. The concentration of salt in seawater (its salinity) is about 35 parts per thousand; in other words, about 3.5% of the weight of seawater comes from the dissolved salts. In a cubic mile of seawater, the weight of the salt (as sodium chloride) would be about 120 million tons. A cubic mile of seawater can also contain up to 25 pounds of gold and up to 45 pounds of silver! But before you go out and try alchemy on seawater, just think about how big a cubic mile is: 1 cubic mile contains 1,101,117,147,000 gallons of water! Learn more: USGS Water Science School - Why is the Ocean Salty? NOAA - Why is the ocean salty? Related Content FAQ Multimedia Publications News link What is marine geology? Geology is the study of the Earth. This includes how the Earth was formed, how the Earth has changed since it was formed, the materials that make up the Earth, and the processes that act on it. Marine Geology focuses on areas affected by our oceans including the deep ocean floor, the shallower slopes and shelves that surround the continents, and coastal areas like beaches and estuaries. USGS... link Where can I find bathymetric data? The USGS has made bathymetric surveys for many coastal areas and for a few selected rivers and lakes in the U.S., including Yellowstone Lake, Crater Lake, and Lake Tahoe. Information and data for some of those studies is on the USGS Maps of America's Submerged Lands website. NOAA (National Oceanic and Atmospheric Administration) is the primary source of bathymetric data for the world's oceans. See... link How is the salinity of Great Salt Lake measured? The salinity of Great Salt Lake is measured by taking specific gravity and temperature measurements and comparing them to standardized values reported in a table. Specific gravity is measured in the field by testing a water sample with a device very similar to a battery or antifreeze tester. Learn more: Great Salt Lake, Utah link Where can I get current sea-surface temperature data? The USGS has studied sea-surface temperature in many areas around the globe; you can find publications from these studies in the USGS Publications Warehouse and by searching on the Internet. World maps and data are available from other agencies, particularly at the NOAA's Sea Surface Temperature , and at the JPL Physical Oceanography Distributed Active Archive Center. For specific data covering... link What is the difference between a tsunami and a tidal wave? Although both are sea waves, a tsunami and a tidal wave are two different and unrelated phenomena. A tidal wave is a shallow water wave caused by the gravitational interactions between the Sun, Moon, and Earth (\"tidal wave\" was used in earlier times to describe what we now call a tsunami.) A tsunami is an ocean wave triggered by large earthquakes that occur near or under the ocean, volcanic... Explore Search Ocean Ocean Back to Top SCIENCE Science Explorer Mission Areas Programs Regions Science Centers Observatories Laboratories Frequently Asked Questions Educational Resources Special Topics PRODUCTS Data Maps Publications Multimedia Gallery Web Tools Software U.S. Board on Geographic Names The National Map USGS Library USGS Store Park Passes NEWS Featured Stories News Releases Science Snippets Technical Announcements Employees in the News Get Our News Media Contacts I'm a Reporter Newsletters CONNECT Headquarters Locations Staff Profiles Social Media Careers Contact Us ABOUT About Us Survey Manual Organization Key Officials Congressional Budget Careers and Employees Doing Business Emergency Management LEGAL Accessibility FOIA Site Policies Privacy Policy Site Map DOI and USGS link policies apply No FEAR Act USA.gov U.S. Geological Survey U.S. Department of the Interior Facebook Twitter YouTube Instagram RSS Contact USGS 1-888-392-8545 answers.usgs.gov",
    "commentLink": "https://news.ycombinator.com/item?id=37459371",
    "commentBody": "Why is the ocean salty? (2022)Hacker NewspastloginWhy is the ocean salty? (2022) (usgs.gov) 190 points by thunderbong 14 hours ago| hidepastfavorite145 comments mcv 2 hours ago> Many of the dissolved ions are used by organisms in the ocean and are removed from the water. Others are not used up and are left for long periods of time where their concentrations increase over time.> The two ions that are present most often in seawater are chloride and sodium.This makes it sound like sodium and chloride are the most common ions because they&#x27;re not used by the organisms in the ocean, unlike all the other dissolved ions. But that&#x27;s not correct, is it? The ocean is salty because we don&#x27;t need salt? But we do.So why is there so much salt in the ocean? Do sodium and chloride simply happen to be the most common elements on Earth that are able to dissolve in water? reply hoseja 1 hour agoparentThey are used by organisms but they are not removed from circulation. Other ions, calcium etc. are used and incorporated into insoluble minerals. reply mcv 1 hour agorootparentThanks. That sounds like the real explanation.Although this graph of the abundance of elements[0] puts sodium with the rock-forming elements (and chloride just inside, but on the edge). So doesn&#x27;t that mean they should also form insoluble minerals?[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;File:Elemental_abundances.svg reply pjc50 1 hour agorootparentChemistry stackexchange says yes, they do: https:&#x2F;&#x2F;chemistry.stackexchange.com&#x2F;questions&#x2F;82328&#x2F;are-ther...(wow, there are a lot of different minerals https:&#x2F;&#x2F;www.mindat.org&#x2F;element&#x2F;Sodium .. ah, 50% of the earth&#x27;s rocks are feldspars which contain some sodium. https:&#x2F;&#x2F;www.imerys.com&#x2F;minerals&#x2F;feldspar ) reply DoreenMichele 11 hours agoprevMany of the dissolved ions are used by organisms in the ocean and are removed from the water...The two ions that are present most often in seawater are chloride and sodium. These two make up over 90% of all dissolved ions in seawater.The other ten percent are micronutrients that are also essential to life.Most land animals have a skeleton not just to provide physical scaffolding to hang tissue on but because we need a store of calcium to mediate blood pH, something sea life doesn&#x27;t require thanks to those minerals in the water. That&#x27;s why you can have sharks which are mostly supported by cartilage with one set of bones: Their jaws. reply gwerbret 10 hours agoparent> we need a store of calcium to mediate blood pHBlood pH is regulated mainly by dissolved carbon dioxide and bicarbonate [1]. There&#x27;s an order of magnitude less calcium in the blood, usually in the form of calcium phosphate, than either of those, and the amount is extremely tightly regulated within a very narrow concentration range -- far too narrow to have a notable effect on pH.[1]: https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;books&#x2F;NBK482291 reply DoreenMichele 10 hours agorootparentThe majority of calcium ions within the cell are bound to intracellular proteins, leaving a minority freely dissociated. When calcium is added to or removed from the cytoplasm by transport across the cell membrane or sarcoplasmic reticulum, calcium buffers minimise the effect on changes in cytoplasmic free calcium concentration by binding calcium to or releasing calcium from intracellular proteins. As a result, 99% of the calcium added to the cytosol of a cardiomyocyte during each cardiac cycle becomes bound to calcium buffers, creating a relatively small change in free calcium.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Calcium_bufferingI raised and homeschooled two kids and watched a lot of when dinosaurs ruled the earth type stuff. That&#x27;s my source for the idea that a store of calcium was critical for allowing life to leave the ocean and I&#x27;ve tried repeatedly to search for additional info on this and can never find it.I have no problem imagining that calcium is essential for buffering pH in land mammals and that free calcium ions simultaneously are tightly regulated and not directly used to move that number for the blood in short time frames. That actually fits perfectly well with my mental models that cellular acidosis is a more fundamental problem that fuels acidosis of bodily fluids.If anyone has any good sources that might clarify this relationship for me, that would be cool. reply Retric 10 hours agorootparent> calcium is essential for buffering pHExcept that’s not what’s going on.The Wikipedia article lays it out. The amount of hydrogen ions someplace is what PH means, so controlling PH is controlling the number of hydrogen ions.The same thing happens with calcium, but rather than doing the buffering it’s the number of calcium ions being controlled. Calcium buffering is controlling the number of calcium ions.> Calcium buffering describes the processes which help stabilise the concentration of free calcium ions within cells, in a similar manner to how pH buffers maintain a stable concentration of hydrogen ions.[1] The majority of calcium ions within the cell are bound to intracellular proteins, leaving a minority freely dissociated.[2] When calcium is added to or removed from the cytoplasm by transport across the cell membrane or sarcoplasmic reticulum, calcium buffers minimise the effect on changes in cytoplasmic free calcium concentration by binding calcium to or releasing calcium from intracellular proteins. As a result, 99% of the calcium added to the cytosol of a cardiomyocyte during each cardiac cycle becomes bound to calcium buffers, creating a relatively small change in free calcium.[2] reply DoreenMichele 9 hours agorootparentThank you.In layman&#x27;s terms, pH is a scale for measuring alkalinity vs acidity. Calcium is supposedly alkaline and high levels of intracellular calcium is associated with cell death (apoptosis).So, for example, some people with CF avoid calcium because they think excess calcium causes cell death. But I think most likely excess calcium -- along with high levels of intracellular glutathione -- are a desperate attempt to buffer against something, including but not limited to excess acid.So that&#x27;s really what I&#x27;m interested in understanding. And also would love to see confirmation that calcium stores helped life leave the ocean and that wasn&#x27;t something stupid and stated in error.Though people with CF also likely misprocess sodium bicarbonate, in addition to being prone to very early onset osteoporosis (as early as their teens). reply hansvm 5 hours agorootparent> Calcium is supposedly alkalineMost reliable sources of information describing calcium as alkaline stem from PRAL (potential renal acid load) and other kidney literature. Combined with the right chemicals (as you find in the kidneys), calcium does reduce acidity (contrasted with a buffering agent, the formulae are more linear, and a linear amount of other shit requires a linear amount of calcium or other alkalizing compounds to compensate) in the kidneys.As something of a fun aside, most \"alkaline diets\" recommend a diet of weakly to strongly acidic foods which have an alkalizing effect on the kidneys and nearly no pH impact anywhere else in the body.No comment on the rest. I just want to reiterate that acid&#x2F;alkaline in one context (most commonly a description of the hydrogen concentration or other related ions) absolutely does not translate without extra effort and math and chemistry to other contexts (like anything describing calcium as alkaline). When those two ideas are mixed in presentation, a correct interpretation absolutely requires you to understand the details of what&#x2F;where&#x2F;why an author means when they refer to pH as something other than hydrogen&#x2F;hydroxide concentration. reply pdonis 7 hours agorootparentprev> Calcium is supposedly alkalineMore precisely, calcium is an alkali earth metal (second column from the left in the periodic table), and those metals are so named because the compounds in which they were first discovered were alkalis. But that does not mean all calcium compounds are alkalis. For example, calcium citrate, which is a common way to convey calcium in supplements, can be weakly acidic in water solution (because of the citrate ion). reply eru 3 hours agorootparentprev> I raised and homeschooled two kids and watched a lot of when dinosaurs ruled the earth type stuff. That&#x27;s my source for the idea that a store of calcium was critical for allowing life to leave the ocean and I&#x27;ve tried repeatedly to search for additional info on this and can never find it.Insects and friends manage to live on land just fine without any calcium bones. reply DoreenMichele 3 hours agorootparentDragonflies used to get to a two-foot wingspan. They don&#x27;t anymore. The atmosphere was thicker and contained more oxygen.What works once life is established on land can be different from what it took to transition to land and that&#x27;s what I&#x27;m asking about. reply eru 3 hours agorootparentThere was more oxygen in the air when the dinosaurs roamed, but not when insects (and other critters) first came on land.https:&#x2F;&#x2F;forces.si.edu&#x2F;atmosphere&#x2F;02_02_06.html says> As plants became firmly established on land, life once again had a major effect on Earth’s atmosphere during the Carboniferous Period. Oxygen made up 20 percent of the atmosphere—about today’s level—around 350 million years ago, and it rose to as much as 35 percent over the next 50 million years. reply DoreenMichele 2 hours agorootparentIrrelevant. reply eru 2 hours agorootparentHuh?The high oxygen levels you mentioned occurred long after life had successfully made its way on land. replyleplen 7 hours agorootparentprevIt looks like there is a theory that dermal bone in early tetrapods was used this way, but it&#x27;s still fairly speculative. https:&#x2F;&#x2F;www.nbcnews.com&#x2F;id&#x2F;wbna47176272 reply DoreenMichele 7 hours agorootparentThank you:Breathing air came with challenges, though. A major one was getting rid of the air&#x27;s carbon dioxide, which, when it builds up, reacts with water in the body and forms an acid. reply mykowebhn 2 hours agorootparentprevThe Wikipedia article you linked as a reference makes no mention about bones, but it does mention intracellular proteins as the location of where the majority of calcium ions are found.I&#x27;ll take wikipedia as a reference (with reservations), but children&#x27;s television shows? reply levischoen 9 hours agorootparentprevHow refreshing. A non defensive critically thoughtful reply to feedback during a public discourse reply DoreenMichele 9 hours agorootparentIt used to be somewhat common on HN. Then it got bigger and covid introduced the entire internet to Eternal September on steroids. reply eru 3 hours agorootparentEven early Reddit used to be like this. Back when HN wasn&#x27;t even opened yet. reply DoreenMichele 3 hours agorootparentYC was founded in March 2005 and Reddit in June 2005. Reddit is a YC company. reply eru 3 hours agorootparentI know. And HN is younger than Reddit.HN != YC. reply DoreenMichele 2 hours agorootparentPaul Graham substantially shaped both cultures from what I gather. So hardly shocking if something once common here was also common there. reply eru 2 hours agorootparentIt&#x27;s possible, but I suspect demographics are more likely to be the main reason here. &#x27;Eternal September on steroids&#x27; as you say. replyBlahah 11 hours agoparentprevI have long known sharks have cartilaginous skeletons but only just wondered whether that means shark bodies are squishy like human ears? Like if you hugged a shark would it deform? reply DoreenMichele 11 hours agorootparentI don&#x27;t know but I wouldn&#x27;t recommend trying it, at least not without wearing chain mail. Their skin is abrasive if you hug them and call them George and rub their skin backwards. reply Moto7451 6 hours agorootparentprevWhile you can’t hug them, see if your nearest aquarium has a touch tank experience. Usually they do those with rays&#x2F;skates but you can also find them with Nurse sharks. Either way, you’ll literally get a feel for their composition.From memory it’s more like the stiff parts of your nose running near&#x2F;along the bone and unlike your ears in any way. reply hn_throwaway_99 11 hours agorootparentprevNo. The human nose is mostly cartilage and it&#x27;s hard. reply Calavar 11 hours agorootparentThe lower half of the nose is cartilage and is pretty soft. The upper half of the nose hard and is bone. reply BuildTheRobots 11 hours agorootparentThis is probably a stupid question, but if the upper half of the nose is bone, why does a human skull seem to always have a hole where the nose is? reply Retric 9 hours agorootparentAnatomically correct skulls have an hole where the bottom of your nose is and the eyes are both smaller and higher up than you probably think.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Orbit_(anatomy)#&#x2F;media&#x2F;File:Ey...Looking at yourself in a mirror, if you hold your finger over the top of your nose your eyes will see under your finger. Move your finger just low enough so you’re seeing over it and you should be touching the bottom of your nasal bone. At that point your nose should be more than a finger width froward from the bottom of your orbital socket which is where the hole in skulls starts in those skulls. reply AlotOfReading 10 hours agorootparentprevThat&#x27;s where the cartilage was. You can find that hole in your own skull easily enough. There should be a small bump midway up your nasal ridge. That point is called the rhinion. Everything above it is laying on your skull. The parts of the nose below it cover your nasal cavity. reply thfuran 11 hours agorootparentprevBecause the bottom half isn&#x27;t bone and the whole thing is hollow. reply colordrops 3 hours agorootparentprevYeah you (well, I) can feel a distinct line between the bone and cartilage. reply edgyquant 11 hours agorootparentprevIt’s pretty soft compared to bone. I can push mine half way down to the skin. replyeru 3 hours agoparentprev> Most land animals have a skeleton [...]Most land animals don&#x27;t have a skeleton. Most land animals are insects and similar critters. reply medstrom 3 hours agorootparentThey have exoskeletons, which still serve the stated purposes. reply eru 3 hours agorootparentThose exoskeletons are made of chitin. Chitin is a carbohydrate. It doesn&#x27;t really have much to do with calcium. reply quickthrower2 5 hours agoparentprevThanks, that is fascinating. The amount of gold&#x2F;silver is too. Even just the amount of salt. Measure in parts per 1000! I like having a wow moment about something we take for granted. reply thaumasiotes 2 hours agoparentprev> Most land animals have a skeleton not just to provide physical scaffolding to hang tissue on but because we need a store of calcium to mediate blood pH, something sea life doesn&#x27;t require thanks to those minerals in the water. That&#x27;s why you can have sharks which are mostly supported by cartilageWell, the other reason sea life doesn&#x27;t require rigid bones is that water provides a lot more buoyancy than air. Jellyfish work fine in the water; on land they&#x27;re immobile puddles of glop. reply barrkel 12 hours agoprevThe answer that springs to mind from general knowledge is that rainwater picks up minerals in solution on the way to the sea, where it gets concentrated by evaporation.The real question is why the sea isn&#x27;t saltier. Why is the Dead Sea so salty? (Because the Dead Sea is enclosed and in a hot location, so evaporation happens faster.) Why aren&#x27;t the oceans as salty as the Dead Sea? What is cause of equilibrium? The article briefly mentions (a) \"organisms\" using the salts, and (b) concentrations continuing to rise (!). So is the ocean on its way to being as dead as the Dead Sea, just really slowly, or what? reply actionfromafar 11 hours agoparentIt was less salty in the past, so I always assumed it will get saltier and saltier.Edit: Our blood has the same salt concentration the ocean had when our ancestors formed or split off or something. Someone with actual knowledge will surely come along and enlighten us with a comment. reply __alexs 1 hour agoparentprevDon&#x27;t worry, the melting glaciers are not at all salty so that should keep the concentration down for a while. reply fransje26 32 minutes agorootparentThis is fine. I&#x27;m fine. reply marricks 9 hours agoparentprevExactly. It&#x27;s been around for billion(s?) of years having rain water dissolve land and run into it. Shouldn&#x27;t it be as salty as it can be?Perhaps it&#x27;s deep sea flour shenanigans keeping it at some stable level. reply eru 3 hours agorootparentWell, there are also salt mines where we get the salt for eating and putting on the road from. They are dried up sea bed.So whatever process produces the mineable deposits will necessarily remove salt from the wider oceans.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Salt_mining reply qup 2 hours agorootparentprevThese gluten-free artisinal flours are getting out of hand. reply leetharris 13 hours agoprevThis is a great perspective check.Water is truly a near-infinite resource. If we can master desalination then humanity is in a great spot in regards to fresh water.It also frames the challenge well. Desalinating a cubic mile gives you 120 million tons of leftovers. Another extremely difficult challenge. reply anon____ 12 hours agoparentThe volume of the Pacific Ocean is 1.583x10^8 cubic miles. (https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=volume+of+pacific+ocean...)The world&#x27;s freshwater need is about 950 cubic miles a year. (https:&#x2F;&#x2F;www.wolframalpha.com&#x2F;input?i=worldwide+water+use+in+...)You can just put the leftovers back without worrying much about it. reply libraryofbabel 10 hours agorootparentFor some reason this topic of desalinization waste keeps coming up on hacker news! The dilution principle here is correct but it’s not as easy as you think to dispose of the waste in the ocean, because if you just pipe it out to sea you’ll create a nasty big marine dead zone around the outlet of your pipe. reply ninkendo 10 hours agorootparentprev> You can just put the leftovers back without worrying much about it.Yes, just not all in one place&#x2F;time. Separating seawater into pure water in one place and pure brine in another, you don’t want to let that brine out all at once in one spot, it’ll kill a lot of ocean life. Most desal plants that are attempting to do this right, will pump the brine into pipes that diffuse it over a wide area to avoid oversalinating. And it still kills a lot of ocean life. reply fiddlerwoaroof 5 hours agorootparentIt might be better just to sacrifice specific spots rather than to try to spread it evenly. reply chongli 3 hours agorootparentOr another solution would be just to take a hit on efficiency and not produce highly concentrated brine as a water product. If instead we extract just a bit of fresh water out and return saltwater with slightly elevated salt concentration then it wouldn’t be so lethal to marine life.Or we could have a premix station where we pump in sea water and mix it with brine at a certain ratio and then return that to the sea. reply SargeDebian 5 hours agorootparentprevIt will still need to spread from that spot. reply fiddlerwoaroof 4 hours agorootparentYeah, but depending on the details and design of the sacrificed area, it might be less environmental impact overall. replybmitc 40 minutes agoparentprevFurther destroying the ocean&#x27;s balance doesn&#x27;t seem like the best idea. It literally drives life on Earth. reply eru 3 hours agoparentprevDesalination has become a lot better in the last decade or so.Israel even turned into a water exported thanks to the technology.See eg https:&#x2F;&#x2F;www.timesofisrael.com&#x2F;how-israel-became-a-water-supe... and https:&#x2F;&#x2F;blogs.worldbank.org&#x2F;water&#x2F;israel-how-meeting-water-c... reply fallat 7 hours agoparentprevLike others have said, there will always be a cost X to desalinate water.I think the best way to pay for X, is to use energy from an external source. External from the Earth. I&#x27;m obviously talking about the Sun.We could use the removed material as a general filler. I&#x27;m sure we can get creative about it. I think the problem is lack of incentives and misalignment of goals amongst people.I truly think if we can figure out how to how to use the most out of the Sun&#x27;s rays - i.e. as most directly as possible - we will solve all our needs. The energy is truly free to the Earth. reply eru 3 hours agorootparentYou can also work on making that &#x27;X&#x27; as small as possible.There&#x27;s a thermodynamic fundamental lower limit on the amount of energy needed to desalinate water, but it&#x27;s absurdly small. Much smaller than the amount of energy we use in practice with current technologies.(Just like there&#x27;s a thermodynamic lower limit on how much energy a computer needs. But it&#x27;s also extremely low. See https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Landauer%27s_principle ) reply csomar 4 hours agoparentprevThere is enough fresh water out there. The problem is that most countries are not building infrastructure to take advantage of it. reply CapitalistCartr 13 hours agoparentprevI wonder if we could use that as a building material. reply zdragnar 13 hours agorootparentAnything that is water soluble is going to be a pretty poor building material, unfortunately. The organics floating about (protozoa, algae, fish) also generally decompose, another undesirable property. The remainder- very very fine silt and microplastics- might be useful.With all the chemical processing that would be needed to stabilize the salts, mechanical filtering and such, I think we&#x27;re better off continuing to use bricks and ground sourced gravel and cement. At least the holes we dig can be repurposed into sanitary landfills. reply Blahah 11 hours agorootparentCorals manage it quite effectively reply zdragnar 10 hours agorootparentBut not efficiently. Scientists think the polyps absorb bicarbonate and calcium ions and deposit calcium carbonate, but they&#x27;re not really sure of the bio&#x2F;chemical process involved.Regardless, a polyp adds about 1mm to 1cm to the reef a year. You can get that right now just by throwing a shovel at the ground where I live. reply A_D_E_P_T 12 hours agorootparentprevEven if we split NaCl into its constituent parts -- sodium metal and chlorine gas -- there&#x27;s not a whole lot that can be done with them.Sodium is potentially useful towards two applications, off the top of my head. (1) Na2O is used in glassmaking, and it&#x27;s possible that there are -- or that there can be discovered -- Na2O-enriched glasses that can be used in construction and as a filler substance, i.e. reduced to powder and added to cement. (2) Sodium-based zeolites can potentially be useful for carbon capture. Production of zeolites, however, also requires lots of alumina and silica.I struggle to think of any large-scale application for all of that chlorine, though. Maybe vinyl chloride production? But the world doesn&#x27;t need that much PVC... reply tonymillion 7 hours agorootparentAlso in the production of Sodium batteries, which while significantly lower in energy density compared to Lithium, they have bigger cycle counts (and as such are&#x2F;can be used to buffer grid based wind&#x2F;solar generation) reply thombat 13 hours agorootparentprevThose leftovers are water soluble, so either you perform some interesting chemistry to convert them into something more durable or your buildings have to be in arid places (condominium in an old salt mine?) reply acidburnNSA 12 hours agorootparentprevProbably more practical to use more chemistry and find good uses for sodium and chlorine individually. reply phkahler 12 hours agoparentprev>> if we can master desalination then humanity is in a great spot in regards to fresh water.Don&#x27;t forget that we actually mine salt, a lot of which ends up in the sea. A million years from now we might regret that ;-) reply Obscurity4340 13 hours agoparentprevI&#x27;ve read that Israel has basically already solved this problem with their desalination tech. reply tpmx 3 hours agorootparentDesalination is [responsible for] around 10% of the electricity consumed in Israel. [...] more than 90% of the country’s electricity comes from fossil fuels.https:&#x2F;&#x2F;www.energymonitor.ai&#x2F;tech&#x2F;can-desalination-save-a-dr... reply gsich 12 hours agoparentprevDesalination is \"solved\". Main problem is the huge energy requiered. reply iancmceachern 11 hours agorootparentSo, not solved? reply Avshalom 10 hours agorootparentI&#x27;m not a physical chemist but there&#x27;s probably a computable minimum energy necessary.A quick search popped up https:&#x2F;&#x2F;pubs.acs.org&#x2F;doi&#x2F;10.1021&#x2F;acs.jchemed.0c01194 For example, desalinating seawater with a typical seawater salt concentration of 35 g L–1 (corresponding osmotic pressure of 29.7 bar) and 50% water recovery (i.e., 50% of the feed stream becomes purified water and 50% becomes brine) requires at least 1.1 kWh per cubic meter of purified water. Regardless of the desalination technology, it is impossible to desalinate water using less energy than that determined by eq 12.which a couple other searches seems to be within order unity of the current energy use reply iancmceachern 10 hours agorootparentWith current membrane technology, yes.There are so many examples in our collective technical history of overcoming these types of limitations not with brute force, but with finesse.In this case, I expect it will be a combination of improved pumps, improved RO membrane technology, and finding synergies like making sea salt from the brine, collecting other useful minerals front the brine,etc. All of these things help to pay for the energy and development costs.It&#x27;s not a hard physics limit like the rule if squares or the speed of light. It&#x27;s a complex engineering system that has may different dynamics and interactions between those dynamics, all opportunity for improvement. reply kergonath 4 hours agorootparent> With current membrane technology, yes.Equation 12 is the energy you need to counteract the effect of the entropy of the ions in solution and separate the initial solution into one that does not have the ions. It’s pretty much a thermodynamic limit and does not depend on process or technology.They explicitly assume that they have a perfect membrane when they introduce the equation. The floor will never be zero, it is a physical limit. reply Avshalom 10 hours agorootparentprevGibbs Free Energy is pretty much a hard physics limit.Trying to pull gold out of the ocean to pay for pulling salt out of the ocean is --again not a chemist but-- probably thermodynamically worse. reply iancmceachern 9 hours agorootparentThat&#x27;s my point. It&#x27;s not a single thing, it&#x27;s not about making it add up trying to do one thing, but if you batch them together and say, use thr waste heat from one process to power the next, etc. One can find new efficiencies.Of course I&#x27;m not saying we need to break the laws of thermodynamics, in my house we obey the laws of thermodynamics.In this case, the work needed is defined by the features of the RO membrane. It&#x27;s conceivable that we could develop a RO membrane that requires less pressure or energy to operate. In fact they have been.In that case, we would gain a more efficient process, while still obeying the laws of thermodynamics reply daedrdev 5 hours agorootparentI see this view a lot on HN, but this kind of wish for great new development can be unrealistic simple because there are no more low hanging fruit for these very physical processes.It could easily be the case that RO is going to see only marginal improvements for the next decade or two (except perhaps some test membranes that are too expensive), and modern RO already uses energy recovery in the process. reply iancmceachern 3 hours agorootparentThis seems highly speculative replyriffic 12 hours agoparentprevnear infinite? there is literally a finite amount of water in this planet and it can be quantified objectively.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Water_distribution_on_Earth reply bee_rider 12 hours agorootparentIf we must do pedantry, technically the original comment didn’t specify “on Earth.” reply bedobi 11 hours agorootparentApplause nitpicking the nitpickers, love it reply riffic 12 hours agorootparentprevwords have meaning reply jamiek88 9 hours agorootparentAs does punctuation, or one may accidentally eat Grandma. reply knodi123 6 hours agorootparentprevdictionaries don&#x27;t speak. replyk__ 2 hours agoprevThis doesn&#x27;t explain why the water in springs, creeks, and rivers isn&#x27;t salty.There is much more water in an ocean for the salt to disperse than in a creek, somehow I can drink from it, but not from the ocean. reply mcv 2 hours agoparentI suspect it&#x27;s because the erosion of the elements from land happens extremely slowly and barely detectable trace amounts, but the oceans is where they accumulate over the course of billions of years.I think the real answer is that these elements (sodium and chloride) easily dissolve in water, and there&#x27;s no process that removes them from the ocean, so they linger and accumulate. reply chakintosh 41 minutes agoparentprevWater from springs (then creeks) comes out of the ground pre-filtered, some springs are salty, others are red from high concentrations of iron and so on. Second reason is because it&#x27;s running water, so it doesn&#x27;t stay in one place accumulating minerals. reply onethought 2 hours agoparentprevBecause the water is flowing, in only one direction, with no feedback. So any salt is taken out and put into the ocean&#x2F;sea it connects to. reply ColinWright 12 hours agoprevSomething I heard a while ago: The sea is salty because it remembers the taste of the land. reply pcurve 13 hours agoprevI wish more scientific explanation were this concise and to the point. Basically in just one short paragraph. reply asimpleusecase 13 hours agoprevTwo questions come to mind. 1) what would our world be like if the oceans were not salty? We could pump fresh water all over the globe, but are there other things that would happen at scale without the salt? 2) by the article it seems like the oceans will always increase in salinity. What is that rate of increase? Then run that model backwards was there a time when salt content was low enough for ocean water to be potable ? reply gumby 13 hours agoparentAnimals, and perhaps all life, would not exist. We carry the ocean around with us in our circulatory system, from a long ago bootstrap in which some creature needed to drag part of its \"home\" with it when it left home.Why? Well fresh water is pretty boring. Seawater, with all those polar ions in it, enables and facilitates all sorts of interesting (i.e. useful) chemistry.One of the reasons we can&#x27;t drink seawater is that our body needs to maintain homeostasis on the blood so the chemistry continues to work properly. If you drink a lot of seawater the kidneys can&#x27;t excrete the salt fast enough. For that matter, if you drink too much fresh water the opposite happens and you die too. reply iancmceachern 11 hours agorootparentExactly. We die if we don&#x27;t get enough salt. There are all sorts of mechanisms in our body that rely on it. As an engineer, I like to think it&#x27;s as simple as electricity not being nearly as conductive through pure water, various osmosis processes like happens in dialysis, etc. reply eru 3 hours agorootparentIf the ocean&#x27;s hadn&#x27;t been salty, we would likely have biochemistry that doesn&#x27;t rely on salt so much.. instead of just keeling over. reply rsa4046 13 hours agoparentprevThe chemical composition of the world ocean reflects the balance of inputs from the continents (as described, from riverine input as well groundwater), atmospheric cycling, and outputs: extraction via evaporite minerals in marginal environments, weathering at the seafloor, exchange over a range of temperatures with mid-ocean ridge basalt, and precipitation of minerals (mostly in the form of biogenic carbonates such as CaCO3, biogenic silica, etc.), as well as their subsequent dissolution, and lastly the biological processes of CO2 fixation and respiration of organic carbon (including electron acceptors other than O2, such as iron, sulfate, etc.).It is the solubility of sparingly soluble phases such as CaCO3 that controls much of the seawater composition: surface seawater is close to saturation with respect to CaCO3 (calcite, aragonite). Because halite (rock salt, NaCl) is highly soluble, seawater is, conversely, fairly concentrated with respect to these ions. Seawater must be extensively evaporated to remove the far more soluble (evaporite) minerals. Over geologic time, the composition of seawater has changed, reflecting the relative pace of the various processes listed above that deliver and remove components from solution. reply perihelions 13 hours agoparentprevGlobal climate would be pretty different without ocean currents driven by salinity gradients.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Thermohaline_circulation reply emodendroket 13 hours agoparentprevIt would surely affect settlement not just in the positive sense (more potable water) but also in the negative (people need salt to live and it wasn’t always as abundant as it is now) reply eep_social 13 hours agoparentprevI guess that at the time when ocean water would have been potable it would have had to wait millions of years for an animal to come along and drink. We don’t talk about air being potable ;) reply Gibbon1 12 hours agoparentprevJust offhand thought is the earths geology over time tends to remove salt from the ocean. An example is the Messinian Salinity Crisis when the Mediterranean sea closed off and then mostly evaporated. The result was a huge layer of salt deposited under the seabed. And the rest of the earths oceans became much less salty. Would not surprise me if plate subduction doesn&#x27;t sequester salts as well.https:&#x2F;&#x2F;www2.atmos.umd.edu&#x2F;~dankd&#x2F;MessinianWeb&#x2F;_private&#x2F;HOME... reply Gare 2 hours agorootparent> And the rest of the earths oceans became much less salty.Source for that claim?Mediterranian is still more salty than oceans because of the high evaporation rate. reply amelius 1 hour agoprevAnd how does sea life filter out the ions? And can we acquire that gene, as it would solve a growing problem? reply aquafox 13 hours agoprevSince salination is essentially driven by the CO2 in the air, does this imply the CO2 we add to the air increases the rate of salination (f&#x27; > 0, where f(t) is the salt content of the oceans)? If so, does this affect ocean currents? reply phkahler 12 hours agoparentYes, increased CO2 probably contributes. I&#x27;m guessing it&#x27;s a drop in the bucket for ocean currents though. Mining salt and dumping it on roads is probably an issue to, as it runs off and goes down rivers. Again, not doing much because the oceans are so big. But over a million years maybe not so great to do. reply tiler2915072 5 hours agoprevMakes you wonder how big the mountains were that dissolved into all that salt and other minerals… reply johncole 13 hours agoprevTIL USGS has an FAQ reply Davidzheng 4 hours agoprevBut why are the ions primarily Sodium and Chloride, why not like Lithium, Flouride, Magnesium, iron, etc? reply pvg 4 hours agoparentLikely some combination of abundance and electronegativity. For instance, from your example - Sodium is about a zillion times more abundant than Lithiumhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Abundance_of_elements_in_Earth... reply mcv 1 hour agorootparentNice graph. But if I understand it correctly, Chloride is about as abundant as Lithium, and less abundant than its neighbours Sulfide, Phospor, Fluoride etc. So why is chloride so abundant in the ocean? Sodium makes sense, but chloride does not.I&#x27;m also surprised to see that Nitrogen is relatively rare compared to its neighbours Carbon and Oxygen, despite making up 80% of the atmosphere. Or maybe that&#x27;s why? Are we losing nitrogen to space? reply dang 11 hours agoprevRelated:Why is the ocean salty? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=16129786 - Jan 2018 (90 comments) reply kbrisso 13 hours agoprevI love facts like this, thanks! reply cbovis 3 hours agoprevBecause cod made it that way. reply Mistletoe 3 hours agoprevI’ve googled this before and gotten a different answer- that it is the water going in and out of the seabed floor and dissolving all the salts in the rock. reply pcthrowaway 12 hours agoprev... because the shore never waves back. reply supportengineer 13 hours agoprevNa CLue reply politelemon 13 hours agoparentThe variants I&#x27;ve heard on this joke are:Because the land didn&#x27;t wave backBecause it&#x27;s full of seamenBecause it&#x27;s full ofplayers reply ThePowerOfFuet 13 hours agoprev>In a cubic mile of seawater, the weight of the salt (as sodium chloride) would be about 120 million tons. A cubic mile of seawater can also contain up to 25 pounds of gold and up to 45 pounds of silver! But before you go out and try alchemy on seawater, just think about how big a cubic mile is: 1 cubic mile contains 1,101,117,147,000 gallons of water!This is one of the best sales pitches for the metric system that I&#x27;ve ever seen. reply crazygringo 12 hours agoparentTo be honest, such numbers in the millions and trillions are totally incomprehensible to human experience regardless of which units are used.It&#x27;s equally silly to try to convey the size of a cubic mile of water in gallons, just as much as it is to convey the size of a cubic kilometer in liters. The numbers are just round in the latter case.In other words, both: 1,101,117,147,000and liters in 1 km^3: 1,000,000,000,000are equally meaninglessly large to any lay reader. reply avar 11 hours agorootparentnext [–]> are equally meaninglessly > large to any lay reader.No, because a cubic kilometer of ocean does not contain a nice round number of liters of water.It contains however many liters of water are in that cubic kilometer after you subtract everything else in the ocean, it&#x27;ll be close to a trillion liters, but not quite.Of course the article may be using \"water\" in the loose sense.But if it&#x27;s not the metric version would implicitly provide you with an easily inferred percentage of how much of a cubic kilometer of ocean is made up of other stuff.Whereas in imperial units you won&#x27;t know that at a glance, you&#x27;ll need to either repeat the calculation, or memorize various conversions. reply HPsquared 12 hours agorootparentprevYou can have an idea of orders of magnitude though, say a billion is a cube 1000 units on each side. That is, a meter cubed with units of 1mm. Actually you could have such a thing on the kitchen table.Edit: now a trillion, that&#x27;s getting beyond comprehension. Just multiply each side by 10.Edit edit: that \"1 billion\" would make for a good conversation piece. Or, easier, a container with 1 billion small grains in it. reply verve_rat 12 hours agorootparentprevA cubic km of sea water would weigh a bit north of a billion tonnes.You&#x27;re right that large numbers are hard to comprehend, but being able to summarise them and convert to other measures easily helps convey meaningful information.Saying you want to process a billion tonnes of something is immediately grokable as vastly different to wanting to process a million tonnes.Being able to immediately convert that into a conversation about processing a trillion litres vs a billion litres is similarly valuable.If I can process 1 tonne of water per unit time, then I know that the cubic km will take 1000 times longer than a billion litres &#x2F; million tonnes. reply swampthinker 12 hours agoparentprevHard to understand unless it’s converted to football fields. reply mchaver 4 hours agorootparentAmerican or metric football fields? reply b3nji 1 hour agoprev [–] Fun fact, Blue Whales ejaculate 20 litres each time. Maybe, this is why the ocean is salty? reply bozhark 1 hour agoparent [–] does the whale sperm turn into salt? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The ocean's salinity, approximately 3.5% of the seawater's weight, is due to rain eroding land rocks, thus transferring salts and minerals into rivers and eventually into the ocean.",
      "The most prevalent ions in seawater are chloride and sodium.",
      "Both the USGS (United States Geological Survey) and NOAA (National Oceanic and Atmospheric Administration) provide further resources for understanding the ocean's salinity and related subjects."
    ],
    "commentSummary": [
      "The discussions examine various aspects of the ocean's high salt content, such as the accumulation of sodium and chloride ions.",
      "Topics include the function of calcium in sustaining life, potential consequences of desalination, and the applications of sodium and chlorine.",
      "Additional points of discussion cover the chemical composition of seawater and the implications of ocean salinity on climate and marine life."
    ],
    "points": 190,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1694375792
  },
  {
    "id": 37460815,
    "title": "The Awk book’s 60-line version of Make",
    "originLink": "https://benhoyt.com/writings/awk-make/",
    "originBody": "BEN HOYT Home Resume/CV Projects Tech Writing Non-Tech Email The AWK book’s 60-line version of Make September 2023 Go to: AWK MakeHow it worksPython MakeConclusion In the wonderful book The AWK Programming Language by Aho, Weinberger, and Kernighan, there are a few pages at the end of chapter 7 that present a simplified version of the Make utility – written in a single page of AWK code. Before we look at that, I want to mention that the second edition of the AWK book is coming out next month. Brian Kernighan’s done a great job of updating it, most notably with a new chapter on exploratory data analysis, and adding proper CSV support to AWK to enable this. I was honoured to be asked to review a draft of the second edition. AWK still shines for exploring data in 2023, especially with the new --csv option. CSV mode has also been added to Gawk (GNU AWK), the most widely-installed version of AWK. My own GoAWK implementation has had proper CSV support for some time, and I’ve added the --csv option to match the others. The second edition of the book still includes the Make program, though it’s been made more readable with the addition of some “spacing and bracing” – this took it from 50 lines to 62 lines. This article presents the Make program, to show how AWK is not just great for one-liners, but can be used as a scripting language too – though whether you should or not is another question. I’m then going to compare what the same program would look like in Python, and briefly discuss when you’d choose AWK or Python for this kind of thing. It should go without saying, but I intend this purely as a learning exercise (for me and my readers), not a program I’d recommend you use to build your projects! Original AWK version The second edition of the book introduces the Make program as follows. (For what it’s worth, I find the term “target” confusing here – I think “source” or “dependency” would fit better.) This section develops a rudimentary updating program, patterned after the Unix make command, that is based on the depth-first search technique of the previous section. To use the updater, one must explicitly describe what the components of the system are, how they depend upon one another, and what commands are needed to construct them. We’ll assume these dependencies and commands are stored in a file, called a makefile, that contains a sequence of rules of the form name: t1 t2 ... tn commands The first line of a rule is a dependency relation that states that the program or file name depends on the targets t1, t2, …, tn where each ti is a filename or another name. Following each dependency relation may be one or more lines of commands that list the commands necessary to generate name. Here is an example of a makefile for a small program with two C files called a.c and b.c, and a yacc grammar file c.y, a typical program-development application. prog: a.o b.o c.o gcc a.o b.o c.o -ly -o prog a.o: prog.h a.c gcc -c prog.h a.c b.o: prog.h b.c gcc -c prog.h b.c c.o: c.c gcc -c c.c c.c: c.y yacc c.y mv y.tab.c c.c print: pr prog.h a.c b.c c.y The first line states that prog depends on the target files a.o, b.o, and c.o. The second line says that prog is generated by using the C compiler command gcc to link a.o, b.o, c.o, and a yacc library y into the file prog. The next rule (third line) states that a.o depends on the targets prog.h and a.c and is created by compiling these targets; b.o is the same. The file c.o depends on c.c, which in turn depends on c.y, which has to be processed by the yacc parser generator. Finally, the name print does not depend on any target; by convention, for targetless names make will always perform the associated action, in this case printing all the source files with the command pr. The dependency relations in the makefile can be represented by a graph in which there is an edge from node x to node y whenever there is a dependency rule with x on the left side and y one of the targets on the right. For a rule with no targets, a successorless node with the name on the left is created. For the makefile above, we have the following dependency graph: prog print /\\ /\\ a.o b.o c.o / \\ / \\ \\ / \\/ \\ \\ a.c prog.h b.c c.c| c.y It’s a highly-simplified version of Make, of course, but still has the core concepts of outputs, dependencies, and build commands. Before we look at how it works, I’ve included the full source code below, as it appears in the second edition of the AWK book. Click on the bold text to expand it, or skip down to “How it works” to see the code explained in detail. The AWK book’s Make program (full source code). How it works There’s an explanation of how the program works in the book, but I’ll explain it in my own words here, focussing on the aspects I find interesting. The BEGIN block is the main entry point for a program like this. Unlike most AWK programs which implicitly read lines from standard input, this one uses an explicit loop with getline to read the makefile: BEGIN { while (getline0) { if ($0 ~ /^[A-Za-z]/) { # $1: $2 $3 ... sub(/:/, \"\") if (++names[nm = $1] > 1) error(nm \" is multiply defined\") for (i = 2; i0) { error(\"illegal line in makefile: \" $0) } } ... } The getline0), it’s a makefile error. Finally, after reading the makefile in the while loop, we uses ages() to compute the ages of all files in the current directory, and then call update(ARGV[1]) to update the rule passed on the command line: BEGIN { ... ages() # compute initial ages if (ARGV[1] in names) { if (update(ARGV[1]) == 0) print ARGV[1] \" is up to date\" } else { error(ARGV[1] \" is not in makefile\") } } The ages function is where things start to get interesting: function ages( f,n,t) { for (t = 1; (\"ls -t\"getline f) > 0; t++) age[f] = t # all existing files get an age close(\"ls -t\") for (n in names) if (!(n in age)) # if n has not been created age[n] = 9999 # make n really old } The parameter names f, n, and t are prefixed with a bunch of spaces to show they’re actually local variables, and not expected as arguments. This is an AWK quirk (which Kernighan regrets): the only way to define local variables is as function parameters, and if a function is called with fewer arguments than it has parameters, the extras take on the default value (0 for numbers, \"\" for strings). So you’ll see these extra spaces a lot in AWK function definitions. The next thing is quite neat: AWK supports shell-likesyntax to pipe the output of a program, one getline at a time, to a variable (in this case f). The ls -t command lists files in the current directory ordered by modification time, newest first. After the loop that’s assigned each file’s age to age[f], we call close to close the ls -t pipe and avoid too many open file handles. Finally, we loop through the rule names and assign an arbitrary large number to age[n] to pretend that files that haven’t been created are really old and need to be updated. Next is the recursive update function, where the meat of the algorithm lives: function update(n, changed,i,s) { if (!(n in age)) error(n \" does not exist\") if (!(n in names)) return 0 changed = 0 visited[n] = 1 for (i = 1; i <= scnt[n]; i++) { if (visited[s = slist[n, i]] == 0) update(s) else if (visited[s] == 1) error(s \" and \" n \" are circularly defined\") if (age[s] <= age[n]) changed++ } visited[n] = 2 if (changed || scnt[n] == 0) { printf(\"%s\", cmd[n]) system(cmd[n]) # execute cmd associated with n ages() # recompute all ages age[n] = 0 # make n very new return 1 } return 0 } Once again you’ll note the parameter list: n is an expected argument (the name to update), and changed,i,s are the locals. After initial checks, we loop through the list of dependencies by iterating from slist[n, 1] to slist[n, scnt[n]]. If we haven’t visited this dependency yet, we perform a depth-first traversal of the dependency graph by recursively calling update to see if we need to update that dependency first: if (visited[s = slist[n, i]] == 0) update(s) The recursion is terminated by the if (!(n in names)) return 0 block near the top. We stop when the file being updated isn’t in the list of rule names – which is a leaf node in the dependency graph. The block if (age[s] <= age[n]) changed++ increments the changed count if any dependency is newer than the age of the current file being updated. After the traversal loop, if any of the dependencies or sub-dependencies had changed, we run the associated command using system(), recompute the ages of all files, and return 1 to the caller to indicate we did make an update. The scnt[n] == 0 clause handles the case where the rule being updated doesn’t have any dependencies specified, like the print rule in the example. In that case, always re-run its command. And there you have it! A minimalist Make in one page of AWK. Python version For interest, I ported the book’s AWK Make to Python, and have included it below. Once again, click the bold text to expand the program. My Python port of the Make program (full source code). It’s very similar in structure to the original AWK version, though I made two simplifications which I think make it somewhat easier to understand: Simpler data structures to avoid the slist / scnt quirkiness – in Python we can just use a dictionary of lists. (See diff.) Determine ages more directly using os.stat() to fetch file modification times (mtimes), rather than using the ls -t trick. This also removes the need for the age map and the ages function. (See diff.) I didn’t plan for this, but even if you include the import line and the if __name__ == '__main__' dance, it’s 58 lines of code – basically the same length as the AWK program. When making the Python version, I realized we could simplify the AWK version in a similar way: It’s conceptually simpler to store the slist directly as an AWK array: a key-value map where the key is the rule name and the value is the list of dependencies as a space-separated string (just like in the makefile). We can use split as needed to turn the dependencies string into a list (an array from 1 to the number of dependencies). This avoids the need for scnt and names altogether. (See diff.) Similar to the Python version, we can get the mtime directly by shelling out to stat, instead of listing all files in age order with ls -t. I’ve used stat --format %y to do this. I believe this is a GNU extension, so it’s not as portable as ls -t, but it’s simpler and avoids the need for recomputing the age array. (See diff.) For what it’s worth, the modified version is four lines shorter than the original. I think the simpler slist is clearer, and I like the more direct approach to fetching mtimes, though I realize the lack of portability of stat --format is a downside (macOS’s stat looks quite different). Conclusion The AWK Make program is a neat little piece of code that shows how useful a language AWK is, even for medium-sized scripts. However, Python is definitely a nicer language for this kind of thing: it has much richer data types, better tools like os.stat, and local variables without quirky syntax. I consider AWK amazing, but I think it should remain where it excels: for exploratory data analysis and for one-liner data extraction scripts. As the author of GoAWK, which has had native CSV support for a while, I’m especially pleased to see both Kernighan’s “one true AWK” and Gawk gain proper CSV support in the form of the --csv option. Kernighan’s AWK updates will be merged soon, and Gawk will include this feature in version 5.3.0, which is coming out soon. You can also view my awkmake repo on GitHub, which contains the full source for both the AWK book’s Make program and my Python version, as well as a runnable example project based on the example in the AWK book. I’d love it if you sponsored me on GitHub – it will motivate me to work on my open source projects and write more good content. Thanks!",
    "commentLink": "https://news.ycombinator.com/item?id=37460815",
    "commentBody": "The Awk book’s 60-line version of MakeHacker NewspastloginThe Awk book’s 60-line version of Make (benhoyt.com) 178 points by nalgeon 11 hours ago| hidepastfavorite39 comments kazinator 9 hours agoBen notes that Kernighan regrets the way local variables are handled in Awk.I patched GNU Awk to have a @let extension that gives you scoped locals (usable in functions as well as in BEGIN&#x2F;END blocks): $ egawk &#x27;BEGIN { x = 3; print x; @let (x = 4, y) { print x } print x }&#x27; 3 4 3@ is used because there is at least one other existing extension which is like that: @include.https:&#x2F;&#x2F;www.kylheku.com&#x2F;cgit&#x2F;egawk&#x2F;about&#x2F;This was rejected by the GNU Awk project, though. I was encouraged to make a fork and give it some kind of different name, so I did that. reply Brian_K_White 7 hours agoparentDid they cite a reason that sounded reasonable? Like the particular implementation breaks some design principle they want to stick to or something? Did they suggest it might be acceptable some other way or in some other form?It&#x27;s curious because gawk cannot for one second claim something like needing to stick to some legacy standard, not with a straight face. reply Joeri 4 hours agorootparentIf I were the gawk maintainer I would be unwilling to take on features by default. It is widely used infrastructure and keeping out bugs is far more important than taking on features. If the userbase keeps asking for the same feature over and over, at that point it would be up for consideration, but no sooner. reply im3w1l 26 minutes agorootparentprevProgramming languages try very hard to be backward compatible so every feature you add is an eternal commitment. reply jph00 1 hour agoprevawk and sed are cool, but whenever someone tells me they&#x27;re interested in learning them, I always redirect them to learn perl&#x27;s `-n` and `-p` flags instead, particularly with `-la` added. This gives you, basically, a superset of sed and awk, which makes many things easier to express, often resulting in clearer and more concise code.For those who have taken this advice, they&#x27;ve always told me later they&#x27;re really glad they did so, and generally express surprise that this isn&#x27;t more widely known.(If you already know awk and sed well, then you mightn&#x27;t view learning perl in addition worth the effort -- I&#x27;m not sure either way. This advice is for people that currently are not strong users of either.) reply mattrighetti 9 minutes agoparentIs perl as widespread as sed and awk in linux distros and other OSes? If I want to make a script that works across the board I feel like the latter are much more adopted, is that correct? reply version_five 10 hours agoprevI&#x27;m a big awk fan but I&#x27;m not sold on this. The awk program is not very readable- I think that&#x27;s fine for a dense one-liner, I&#x27;m not really sure it carries over to a 60 line script. I think for something like this I&#x27;d prefer a bash script, maybe with awk invoked somewhere, that would be much easier to understand at a glance.Is there something in the awk script that makes it advantageous over a shell script?Edit: I hadn&#x27;t read the author&#x27;s conclusion yet when I posted, he agrees I consider AWK amazing, but I think it should remain where it excels: for exploratory data analysis and for one-liner data extraction scripts reply tyingq 14 minutes agoparent> Is there something in the awk script that makes it advantageous over a shell script?Pseudo multi-dimensional associative arrays for representing the dependency graph of make. This part: for (i = 2; iThe awk program is not very readableWhat do you find hard to read about it? If you know what make does, I think it is fairly easy to read, even for those who don’t know awk at all, but do know the Unix shell (to recognize ‘ls -t’) and C (both of which, probably the audience for this book knew, given that the book is from 1988)> I think for something like this I&#x27;d prefer a bash scriptBut would it be easier to read? I doubt see why it would. reply mauvehaus 8 hours agorootparentBash also would have been an unlikely choice for a book published in 1988, considering it wasn&#x27;t released until 1989 (Per Wikipedia). reply Brian_K_White 5 hours agorootparentIt would have been ksh, which was the bash of the day, as in, the more featureful sh-compatible sh-superset.But a bash or ksh script would have been less readable than awk.bash (or ksh88 or ksh93) is powrful and useful but not readable if you&#x27;re actually using the powerful useful features.In bash, a lot of functionality comes in the form of brace expansions and word splitting, basically abusing the command parser to get results there is no actual function for. In awk and any other more normal programming language, those same features come in the form of an explicit function to do that thing. reply fuzztester 3 hours agorootparent>In bash, a lot of functionality comes in the form of brace expansions and word splitting, basically abusing the command parser to get results there is no actual function for. In awk and any other more normal programming language, those same features come in the form of an explicit function to do that thing.Right. That&#x27;s one of the reasons why the man page for bash is so long. IIRC, going way back, even the page for plain sh was long, for the same reason. reply falcor84 1 hour agorootparentIndeed. But at least it acknowledges it, with the iconic \"It&#x27;s too big and too slow.\" replymbivert 9 hours agoparentprevI think it should be appreciated in context: it&#x27;s a good way to teach both awk(1) and make(1) to someone new to UNIX. It also demonstrates how to use awk(1) for prototyping, which IMO is a good programming habit to \"develop\": it forces to focus on the essential, and not to unnecessarily overthink. reply rottc0dd 5 hours agoparentprevBash would really be bad idea if it is going to use bash stitching so many gnu utils for this kind of job.I once had to rewrite a bash script into awk[1] that is big enough and it made the program more readable and the total time execution came down from 12 mins to less than 1 second.I think maybe the original bash script would have written badly, (each util command will invoke it&#x27;s own process and it has to piped to others instead of using awk which will be running in a single process).[1] - https:&#x2F;&#x2F;github.com&#x2F;berry-thawson&#x2F;diff2html&#x2F;blob&#x2F;master&#x2F;diff2... reply pushedx 8 hours agoparentprevWriting this make program in bash would invovle even more difficult to read hacks, as bash also does not support multidimensional arrays. reply Spivak 10 hours agoparentprev> for exploratory data analysis and for one-liner data extraction scriptsI think both you and the author just don&#x27;t like AWK if that&#x27;s the takeaway. What you&#x27;re describing is literally 1% of the AWK language -- like you don&#x27;t have to like it, it&#x27;s weird in many respects but you&#x27;re treating AWK like it&#x27;s jq when it&#x27;s actually closer to like a Perl-Lite&#x2F;Bash mix. An AWK focused on just those use-cases would look very different.One of my favorite resources on AWK: https:&#x2F;&#x2F;www.grymoire.com&#x2F;Unix&#x2F;Awk.html reply whartung 7 hours agoprevFunny, I would have approached this by removing the while loop and the if else parts of the BEGIN clause, leveraging the stock file reading and line iteration along with AWK pattern matching (terminated with a next statement to skip to the next row), and then shoved the rest in the END clause.It’s always been a “thing” with me of not liking to put everything into BEGIN. Kind of a “if I’m doing that, why am I using awk” thing.Just how I approach problems with awk. reply eequah9L 52 minutes agoparentI&#x27;m with you on this, but is there a way to force input file to read in AWK? That would be a reason to choose the while loop over AWK&#x27;s implicit iteration. In particular, overriding FILENAME in BEGIN does not do anything. reply mtillman 6 hours agoprevI wan’t aware that an updated book was on the way. Pre-ordered it immediately. It&#x27;s wonderful to see that, even after 40+ years, the people who created a scripting language are still providing new, well-documented features. reply teo_zero 52 minutes agoprev> return 1 to the caller to indicate we did make an update.This (both in awk and python code) seems useless, as the return value from update() is not used anyhere. Am I missing something obvious? reply greyman 1 hour agoprevI must admit that I use awk only via GPT-4, which will write me the one-liner I need and I just run it. I somewhat cannot remember the syntax, provided I use the tool only occasionally. reply 1vuio0pswjnm7 9 hours agoprev [–] These blog posts and discussion usually pit one language against others and often attempt to restrict a language to some specific context, ignoring that each user&#x27;s experience, needs and preferences may be different. A more interesting debate would be language-agnostic, such as writing one-liners versus writing lengthy programs.In short, the debate might be something like: What does the computer user prefer more: (a) writing one-liners or (b) writing lengthy programs. Not everyone will have the same answer. Knuth might prefer (b). McIllroy might prefer (a).Assuming one reading this blog post knew nothing about programming languages, it seems to imply Python is not well-suited for one-liners, or at least not comparable to AWK in that context. Perhaps the interpreter startup time might have something to do with the failure to consider Python for one-liners. reply benhoyt 8 hours agoparent [–] I don&#x27;t think Python is very well suited to one-liners, but it&#x27;s not due to interpreter startup time (20ms on my machine). Rather, it&#x27;s due to all the scaffolding needed, which AWK provides implicitly: AWK automatically reads input lines and splits them into fields, automatically initializes variables to the type&#x27;s default value, and has terser syntax for things like regex matching.Consider the following AWK one-liner which, for every input line that starts with a letter, prints the line number and the line&#x27;s second field: awk &#x27;&#x2F;^[A-Za-z]&#x2F; { print NR, $2 }&#x27;The equivalent Python program has a ton more boilerplate: import statements, explicit input reading and field splitting, and more verbose regex matching: import re import fileinput inp = fileinput.input(encoding=&#x27;utf-8&#x27;) for line in inp: if re.match(r&#x27;[A-Za-z]&#x27;, line): fields = line.split() print(inp.lineno(), fields[1]) reply fuzztester 6 hours agorootparent>The equivalent Python program has a ton more boilerplate: import statements, explicit input reading and field splitting, and more verbose regex matching:\"awks and pythons\" reply make3 6 hours agorootparentprev [–] I always thought we should make a short of Python for one liners inspired from awk, where the loop over the lines would be implied.the line, lineno and fields would be predifined, and I guess re, os, shutil, pathlib and sys are pre imported. maybe the whole stdlib acts as if it&#x27;s preimported, while only being imported lazylyhere it would be something like```if re.match(r&#x27;[A-Za-z]&#x27;, line): fields = line.split() print(inp.lineno(), fields[1])```so```cat makefilepyawk &#x27;if re.match(r\"[A-Za-z]\", line): print(lineno, fields[1])&#x27;```I don&#x27;t see a way out of multiple if statements requiring multiple lines though, otherwise you would have to introduce brackets to Python lol reply cb321 38 minutes agorootparentOften whole program generation in a prog.lang (& ecosystem!) that you already know can substitute for a new prog.lang. Python even has eval. You may be interested in: https:&#x2F;&#x2F;github.com&#x2F;c-blake&#x2F;bu&#x2F;blob&#x2F;main&#x2F;doc&#x2F;rp.mdYou can actually get pretty far depending upon boundaries with the always implicit command-option language (when launched from the shell language, anyway). For example, Ben&#x27;s example can be adapted to: rp -m^\\[A-Za-z\\] &#x27;echo nr,\" \",s[1]&#x27;which is only 5 more characters and only 3 more key downs (less SHIFT-ing) than the space-optimized version of his `awk`. { key downs are, of course, just a start to a deep rabbit hole on HCI ergonometrics ending in heatmaps, finger reach&#x2F;strain&#x2F;keyboard layouts, left-right hand switching dynamics, etc., but they seem the most portable idea. }Nim is not Python - it is actually a bit more concise while also being statically typed and can be compiled to code which runs as fast as the best C&#x2F;C++ (at more expense than one usually wants for 1-liner interactive iteration, though unless you need to test on very large data). That said, I find it roughly \"as easy\" to enter `rp` commands as `awk`.If doing this in Python tickles your fancy, Ben actually has an interesting on these ideas: https:&#x2F;&#x2F;benhoyt.com&#x2F;writings&#x2F;prig&#x2F; you might also find interesting.EDIT: and while I was typing in a sibling @networked mentions a bunch more examples, but I think my comment here remains non-redundant. I&#x27;m not sure even one of those examples has some simple `-m` for auto-match mode (although many would say a grep pre-filter is enough for this). reply benhoyt 5 hours agorootparentprevAlec Thomas wrote a script like this called pawk.py (https:&#x2F;&#x2F;github.com&#x2F;alecthomas&#x2F;pawk). It reads input automatically, and for each line, defines \"n\" and \"f\" to the line number and fields list (among other things). It even supports &#x2F;regex&#x2F; patterns. Even the print is implicit. So the example above would be: pawk &#x27;&#x2F;^[A-Za-z]&#x2F; (n, f[1])&#x27;By the way, triple backticks don&#x27;t work on HN. You have to indent by 2 spaces to get a code block. reply networked 59 minutes agorootparentprev [–] A sibling comment already mentions PAWK. You can do cat makefilepyawk &#x27;if re.match(r\"[A-Za-z]\", line): print(lineno, fields[1])&#x27;in a Python one-liner without PAWK by abusing list comprehensions: python -c &#x27;import fileinput, re; [print(re.split(r\"\\s+\", line)[0], fileinput.lineno()) for line in fileinput.input() if re.match(r\"[A-Za-z]\", line)]&#x27; makefileEdit: Removed a list of other awk replacements to post it as a separate comment. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author details the utility of the Make program, a tool for building software projects, specifically discussing a simplified version created using the AWK programming language.",
      "Emphasized is the forthcoming second edition of the AWK book, featuring CSV support and an amended Make program version.",
      "While recognizing AWK's usefulness in specific tasks, the author argues that Python is a more appropriate language for this type of program and provides a link to their GitHub repository hosting the source code."
    ],
    "commentSummary": [
      "The author shares their journey creating a variant of Make utility with Awk, a scripting language, and a failed attempt to modify GNU Awk.",
      "Readers engage in debates over the use of Awk in comparison to other scripting languages, discussing its strengths and weaknesses.",
      "Alternatives like pawk.py and rp receive mentions as possible tools, along with the concept of writing one-liners in Awk or creating a more streamlined Python version influenced by Awk."
    ],
    "points": 178,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1694385384
  },
  {
    "id": 37457051,
    "title": "New Bézier curves for vector graphics",
    "originLink": "https://ad8e.pages.dev/curve",
    "originBody": "Remodeling Béziers This article is about how math creates an easier-to-use version of Béziers. We'll show examples of issues with Béziers, then discuss the issues academically, then derive a curve that fixes the problems (and can draw circles!). This is a Bézier. You can drag the handles. The green lines represent curvature. Béziers are a little unintuitive to use, because it's not always clear where to put the control points, or how long the handles should be. This leads to a lot of trial and error. To see for yourself, use the handles below to align the black and pink curves. Show answer Click \"Show answer\" when done. You probably got the curve right, but you had to go back and forth between the two handles, iterating the curve. You couldn't set each handle to the correct position on the first try. (I can't do it either.) Here's another one: Show answer You probably got the curve close, but your handles are way off. Adjust the middle node: Show answer I don't know of a reasonable way to guess the right location. These illustrate the following problems with Béziers: It's hard to guess the correct handle length on the first try; you have to see the result and adjust iteratively. The correct value of a handle depends on too many other things. If you move a node or handle, then you have to adjust its handles, then re-adjust the neighboring handles, then re-adjust the first handles, then re-adjust the neighboring handles, etc. You can't set each handle to the correct value on its own. In mathematics, this means they are \"non-orthogonal\". Widely different inputs can lead to similar outputs, and then you have to adjust neighboring handles a lot. In mathematics, this means the output-to-input map is \"poorly conditioned\". This becomes an issue when it is not axis-aligned, like the second example. There's no obvious way to figure out where to put nodes. And there are three more problems: Béziers can't represent circles. If you try to approximate one by hand, it'll look lopsided. Deleting existing nodes from a curve creates a mess. It's hard to keep curvature continuous across a node; you'd have to stare at curvature combs and fiddle a lot. Mathematics resolves these issues. Local and global The words \"local\" and \"global\" appear in disparate domains in mathematics, like parallel evolution. These concepts are broadly useful. Small and simple objects are \"local\". Large and complex objects are \"global\". For example, your house is a global object, and each room is a local object. If you want to know whether the whole house is painted white (a global property), you can check whether each individual room is painted white (a local property). This splits the global task into smaller local tasks. The key insight is: Local properties are easy, and global properties are hard. Whenever global objects can be decomposed into local objects, it's more convenient to work with the local objects. This is the backbone of the local to global principle. A curve is determined by a finite number of points on the screen - those points are the artist's interface. These points should control the curve locally, determining the curve in a small region. In geometry, the standard local description of a curve is its derivatives, like a Taylor series. (We can safely ignore analyticity, thanks to Stone-Weierstrass.) The zeroth derivative is position - where the curve is. The first derivative is direction - which way the curve points. The second derivative is curvature - how curvy the curve is. These three parameters are easy for humans to understand, and artists don't use higher derivatives. So the points should control position, direction, and curvature. These three parameters produce a circular arc. Local control is easy to draw with, because you just need to match behavior at points: You understand what an input point does - it chooses a circular arc for the nearby curve. It's easy to position input points - put them where you want to change the curve. This explains the underlying issue with Béziers. Bézier controls are local for position and direction, but not local for curvature. Local position and local direction coincide with the easy tasks - placing the node on the curve and setting the handle direction. Non-local curvature coincides with the hard task - setting handle length. So it's failure of locality causing the issues. Given local behavior, how do we create a global curve? The user only inputs a finite number of points. It's best if the correct curve extends naturally between these points, requiring as few correction points as possible. Because of locality, a curve between two points is determined solely by these two points, and ignores any points farther away. Each point specifies either 0, 1, or 2 derivatives. Remember that the 0th derivative is position, the 1st derivative is direction, and the 2nd derivative is curvature. If you specify a higher derivative (like curvature), you specify all its lower derivatives as well (like position and direction). So given two points and a number of derivatives for each point (0 1 2), we have to come up with a curve. If each point specifies only its position (the derivative numbers are 0 0), the curve is a line. If one point specifies direction and the other specifies position (derivatives are 1 0), then the curve is a circle. That's the easy cases. For the rest, we need math. We specify some possible axioms, then choose which ones to satisfy. Primacy of lines and circles. The desired curves are disproportionately lines and circles. If the points express a line or circle, then the curve is a line or circle. Affirmation invariance. Adding extra derivatives that agree with the existing curve should keep the curve the same. Affine transformation. Affine transformation of the points causes affine transformation of the curve. This is important for drawing 3D objects (which most things are). For example, ellipses are circles on a 3D plane, projected down to your 2D surface. They are an affine transformation of a circle. Subdivision (strong). If we truncate a curve specified by points with N and M derivatives, then the two endpoints of the snipped curve have N and M derivatives. Subdivision (weak). If we truncate a curve specified by points with N and M derivatives, then the two endpoints of the snipped curve have at most max(N, M) derivatives. Finite length. Curves don't travel to infinity. (For example, a parabola does.) Non-singularity. When the input varies smoothly, the output also varies smoothly. Unfortunately, not all these axioms can be satisfied simultaneously. So we have to make some tradeoffs, just like Arrow's impossibility theorem. An example is that axioms 1 + 3 together create the conic sections - whose paths travel to infinity, and hence cannot satisfy axioms 6 or 7. If both points specify direction (1 1), then a parabola satisfies axioms 3, 4, and 5. It's equivalent to a quadratic Bézier. The best UI control is the intersection of the handles, which satisfies axiom 7. An alternative is to choose sin(angle/2) as the weight for a rational quadratic Bézier. This satisfies axioms 1, 2, and 6 (and 7 with the right UI). The curve is always an ellipse. If the directions are perpendicular, then the points are the maximum and minimum curvature points of an ellipse. If one point specifies direction and curvature, and the other point specifies only position (2 0), then the previous choices are still available: ellipses and parabolas. There's an additional alternative, where the direction and curvature are mirrored to the other point across the line between them. This satisfies axioms 1, 2, 3, and symmetry. If one point specifies direction and curvature, and the other point specifies direction (2 1), then we get a uniquely determined conic section, and axioms 1, 2, 3, 4, and 5 are satisfied. These are ellipses, parabolas, and hyperbolas. Curves which travel to infinity should have their handles flipped. If both points specify direction and curvature (2 2), then the curve is overspecified for a conic, so we have choices to make. Here's one possible solution. Blue circles control curvature. Now blue circular handles control radius: The handles determine the radius of a circular arc near the point. The in-between is interpolated. There are better curves; I didn't look too hard. This one respects axioms 1, 2, 3, and 6. 4 and 5 are probably achievable with a week of work. This one happens to be computationally efficient. It flips when the handles cross parallel, but this flip can be adjusted with more work (letting you represent a whole circle with one point). This curve is a rational cubic Bézier. You can read it in final3() in the source code, or follow these steps: Affine transform the two input points so that the intersection of their directions creates an isosceles right triangle, with the two points forming the hypotenuse. (Like the first of the two diagrams above.) Let the curvatures of the points be c and k. Draw a rational cubic Bézier. Let r = √(8c)/3/(c + k), s = √(8k)/3/(c + k). The second control point has weight w = 3krr/2 + s and is proportion r/w between the first and second control points. The third control point is calculated symmetrically by exchanging the input points. Affine transform the curve back to the original position. The old list of problems with Béziers is fixed: The handle length can be set on the first or second try; just match a small arc around the point. The correct handle length only depends on a small region around the point, not anything else. After it's set, moving nodes and other handles won't interfere; it'll still be correct. High condition numbers for the inverse map are axis-aligned. Placing nodes is simple. (Put them at the largest deviations, and on inflection points.) Circles are easy to draw. Deleting existing nodes from a curve leaves the curve in good shape. The curvature is well behaved (the green lines). At a smooth node, the curvature is equal on both sides - no jump discontinuities. Here's a trick that turns curve-finding from a boring math problem into an interesting geometry problem. The subdivision axiom is secretly reversible: Extension axiom: Any curve has a unique curve that extends it, which produces the original curve when subdivided. This extension continues forever, so the curve must either loop back to itself or approach a singularity. This infinitely-continuing curve is called a \"parent curve\". Finding a set of parent curves is a very intuitive process. Each parent curve extends infinitely, ending in loops or singularities, and every curve is just a short snippet of a parent curve. For example, the parent curves for conics are the parabolas and hyperbolas (which extend forever) and the ellipses (which loop). You can try to construct your own parent curves, using these constraints as a guide: Any pair of points, containing the information {position, direction, curvature}, must belong to exactly one parent curve. Since conics create every valid symmetric tuple, your parent curves can have no axis of symmetry unless they are conics. Parent curves should be useful curves to draw with. So singularities should generally be points at infinity. Spirals aren't useful, so they are disallowed. The curves should behave well with inflection points; this is necessary to cover the lack of inflection points with conic sections. So the curve should be non-degenerate when one point has curvature 0. Which curves do you think are elegant or useful? Is there an optimal set of parent curves? Here are some possible approaches: Try existing classes of curves with nice properties, like cardioids, conic generalizations, or other geometric shapes. See if any of them form parametrized families. Here's a list. Create parametrized families of curves directly. The interesting case is with singularities at infinity, where curvatures approach 0. Some promising classes are complex rational Béziers, rational Béziers, and curves on the complex plane. For example, conic sections have a nice polar form. Eyeball the loop case, where one curvature is zero and the other is not. Future work These control systems can be extended to curves and surfaces in 3D. And to curves on 3D surfaces. With a suitable UI, animations should be convenient. Conics express the sine wave, which is the physically natural \"ease-in-out\", a spring force. They also express the parabola, the physically natural \"ease-in\", a constant force (like gravity). 2 2's curve can be improved. There's also alternative UIs for the node handles that allow inflection points away from input points. If you develop drawing software, you can implement these curves. They are easier to learn than Béziers, and are easier to be accurate with. No more staring at curvature combs needed. Discussion: Hacker News Author: Kevin Yin Visualizations are thanks to G9 and took minimal effort.",
    "commentLink": "https://news.ycombinator.com/item?id=37457051",
    "commentBody": "New Bézier curves for vector graphicsHacker NewspastloginNew Bézier curves for vector graphics (ad8e.pages.dev) 167 points by ad8e 17 hours ago| hidepastfavorite52 comments egypturnash 13 hours ago\"I don&#x27;t know of a reasonable way to guess the right location.\"1. Drag curve handles out to 1&#x2F;3 of the length of the curve segment they control.2. Eschew s-curves between two control points.3. Don&#x27;t turn more than about 90º between two control points.I learnt this about a year into what is now a 23-year career as an Illustrator artist. It has served me well. You will note that the first interactive example on this page is asking you to violate rule 2.\"Béziers can&#x27;t represent circles. If you try to approximate one by hand, it&#x27;ll look lopsided.\"If you try to draw a circle by hand, it&#x27;ll look lopsided too. Any pro traditional artist will have a compass and a few circle templates in their kit. In Illustrator there&#x27;s an ellipse tool one keypress away. I&#x27;ve been drawing at a pro level for about thirty years and while I can probably pick up a pencil and draw a better circle in a couple quick arm motions than you can in a bunch of little sketchy attempts, they&#x27;re still nowhere near perfect, and they don&#x27;t need to be.I also draw about 90% of my paths with the Pencil tool, which just abstracts worrying all of this way. Unless you are doing very geometric work, or require the absolute minimum possible number of points, I feel that using the Pen tool to draw everything is about as sensible as writing a program entirely in assembly language. And if I do need to work under a tight point count constraint, then I will still draw it with the Pencil, then pull out Astute&#x27;s Smart Point Removal tool, which does a great job of optimizing the heck out of my paths, much better than Adobe&#x27;s tools for this. reply spoiler 13 hours agoparent> I feel that using the Pen tool to draw everything is about as sensible as writing a program entirely in assembly language.As someone who&#x27;s only ever used the pen tool, I feel mildly attacked!Jokes aside, I think I agree with you if you have a tablet. I used to draw with a mouse back then, so I&#x27;d basically sketch on paper, take a picture or scan it, then use my mouse to pen over it. Sometimes I&#x27;d skip the sketching&#x2F;importing steps, depending on what I&#x27;d work on.Later when I could afford a tablet, I mostly left Illustrator&#x2F;Inkskape behind in favour of just using Krita for most things. However, if I&#x27;m making a vector illustration today, I still use the pen tool... and the mouse, even if I have the tablet. If I were to work on something complex enough, I&#x27;d probably sketch it in Krita though, and then use the good&#x27;ol pen and mouse...I&#x27;m by no means a professional artist, just do this as a hobby though. So, if my workflows outlined here have mortified you; apologies for that. reply egypturnash 12 hours agorootparentThe workflow you outline is where I started! It&#x27;s not one I&#x27;d want to use any more, now that I can casually make Illustrator automatically do a lot of work for me, then come back in and refine a few places manually. But it was a good place to begin.https:&#x2F;&#x2F;egypt.urnash.com&#x2F;illustratorbook&#x2F; reply raphlinus 11 hours agoparentprevI can perhaps refine (1) and provide some insight in support of (2).It does make intuitive sense for handles to be 1&#x2F;3 of the length of the curve, as that makes the \"speed\" close to constant, but this is not the smoothest possible choice in general. In particular, it&#x27;s not the best approximation to a circular arc, which by most reasonable definitions is the smoothest possible curve. I did the math[1] and found that there&#x27;s a parabola around each endpoint that does result in an accurate arc approximation, and in fact may be easier to apply as it doesn&#x27;t move around as the length of the curve changes. Rather, each of the parabolas can be applied independently.Evidence in favor of this is O(n^5) accuracy scaling to approximate Euler spirals (which are also a good candidate for \"smoothest possible curve\" depending on the way you define that). I suspect, but haven&#x27;t yet demonstrated, that there&#x27;s some variational sense in which this choice is optimum, or at least to a first order approximation.You can think of cubic Béziers as forming a four-dimensional parameter space (the parameters can be accounted as the lengths and angles of the control handles; in this scheme, the positions of the endpoints are not counted). By applying a rule such as 1&#x2F;3 arc length, or falling on a parabola, that reduces it to a two-dimensional space (same dimensionality as quadratic Beziers, Euler spirals, and sections of rectangular elastica). I think two dimensions is too few, as it doesn&#x27;t give you the ability to easily form superellipse shapes, a particular strength of cubic Béziers and quite handy for font design, as superellipse is extremely common in fonts. I think there may be some value in exploring a three-dimensional parameter space (which, among other things, is the count for general elastica) and have some ideas.As for (2), the problem is that for s-shaped curves, cubic Béziers tend to put curvature maxima near but not exactly on endpoints. Since the curvature maximum is visually salient, you do better subdividing your curves so you can place them at joins. Other curve families, notably those based on elastica and Euler spirals, don&#x27;t have this problem.[1]: https:&#x2F;&#x2F;raphlinus.github.io&#x2F;curves&#x2F;2021&#x2F;02&#x2F;19&#x2F;parallel-curve... reply ad8e 10 hours agorootparentThe ideal dimensionality of the parameter space depends on the jaggedness of the curve. Derivatives are useful when they stay constant over a stretch of time; when derivatives vary too much, it becomes more efficient to use more points of lower degree. This is the same calculation in other domains of approximation: numerical integration, DiffEq, and Taylor series.For example, to draw rough surfaces, point-to-point lines are the most efficient way, with a ton of points. For industrial geometric shapes, lines and ellipses become efficient. As the smoothness of the curve goes up, more derivatives become valid. But sometimes those higher derivatives are not useful.This is why the parent comment likes the Pencil tool; it&#x27;s optimal for high variation, because it is a local (smoothed) control of position, the zeroth derivative. The cost is some loss of smoothness, which likely doesn&#x27;t matter for her domain, since her hands move smoothly enough.I think the Pen tool would be a more competitive alternative with a better control scheme. For example, a Pen tool with local control would unify the Pencil and Pen: letting you draw jagged curves by holding your mouse down, and letting you draw straight lines and smooth curves by clicking. There would be no interruption of flow, as you can use either method freely to continue a curve. They should inherently be the same tool anyway, just with different numbers of derivatives. reply karaterobot 13 hours agoparentprevI think what you&#x27;ve done is mastered an unintuitive (or even counterintuitive) system. That&#x27;s well and good, but it doesn&#x27;t mean the system shouldn&#x27;t be improved. It would make life no worse for you, and better for people with less experience, less time to experiment. reply cush 13 hours agorootparentI don’t think they’re implying it takes 21 years to learn. I’m inexperienced and learned how to accurately follow paths with bezier curves using the same technique after watching a 10 minute Burt Munroy tutorial. reply egypturnash 12 hours agorootparentCorrect. I have certainly learnt a ton more about how to manipulate vector art in the intervening years, and the set of tools I have available has expanded a lot - Adobe&#x27;s added a lot of tools to Illustrator, and so has the Illustrator plugin ecosystem. But those three simple rules did a lot to make my Illustrator practice a lot faster. reply bobbylarrybobby 12 hours agoprevAre Bézier curves with handles “worth it”? I&#x27;ve always found the easiest method for drawing curves to be, simply, “give me the (cubic) spline curve that goes through these points”. You place your points and continuity conditions determine the cubic, as described in https:&#x2F;&#x2F;mathworld.wolfram.com&#x2F;CubicSpline.html . reply dahart 3 hours agoparentIt of course depends on what you need, what you’re doing. The cubic Bézier curves with handles are probably the best thing for animation curves, specifically because having handles allow you to break the continuity of the curve, and change direction suddenly. Animators need this when tweaking motion curves on a timeline. Think of abrupt changes in speed, like with collisions.Splines with tangent handles are much better for font design as well, than splines without handles.Splines defined by points and not tangents are useful for different reasons, and they’re not great if you want to have sharp changes of angle. You can do it by duplicating control points, but that causes some math mayhem in some situations.In computer graphics people use the “Catmull-Rom” spline a lot, which is a type of interpolating spline that goes through the control points. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Centripetal_Catmull–Rom_splinePeople also use the B-spline as well, which is smoother and nicer than the Catmull-Rom spline, but it’s an approximating spline that doesn’t usually go exactly through the control points. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;B-splineBoth of these get used in CG for hair and fur - which is a good example of an application of curves that doesn’t require sharp angles along the splines. reply crazygringo 11 hours agoparentprevThat&#x27;s exactly what I&#x27;ve always been curious about!It seems vastly more intuitive to place points rather than adjust handles. (And set directions for endpoints if the curve is open.)And obviously a practical tool will provide the capability to join separate cubic splines at sharp angles.Does anyone know of a GUI drawing tool based on this? I&#x27;ve always wanted to experiment with it. Because I&#x27;ve always wanted to either confirm that it&#x27;s a great idea that we should all be using instead of beziers, or else discover if there&#x27;s an immediately obvious reason once you try it out that it&#x27;s a terrible idea. reply ad8e 10 hours agorootparentI have used this in some commercial software before (maybe Illustrator?); my experience was not positive. When you move a node, some not-so-close curves start wiggling, and you think, \"I already set that part correctly, stop moving please\". It behaves very poorly around rounded corners. Adding points causes the curves to shift, usually not how you want, and then you try to add more points, which causes more shifts, etc. Arc length-based interpolation might do better in this respect, as opposed to the (# of points)-based interpolation which I expect it used.The alternative, which obeys similar principles, is the Pencil tool. This simply spams out a ton of points to match what you draw. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37460009 mentions that these points can be capably reduced, which could serve your purpose. reply slimsag 16 hours agoprevCool to see others working on this problem. I hope more people do.Funnily I&#x27;ve seen a lot of programmers and math folks who express how truly, genuinely beautiful Beziers and the math behind them are. But I&#x27;ve never met an artist or graphic designer who didn&#x27;t express some deep frustration at Bezier controls and how hard they are to work with.There are even games[0] which make a mockery out of how hard Bezier controls are to use, where the game is purely using the controls.Controls are just one side of the problem, in my view; the other side is that cubics are terrible for GPUs, they don&#x27;t understand them - and I believe many of the best 2D graphics libraries today are not even fully GPU accelerated, e.g. Skia. There are folks working on compute shader-based approaches, where we try to shoe-horn this CPU-focused algorithm into GPUs and pray - but it still isn&#x27;t really suitable.The controls suck for artists, and the math sucks for GPUs. This is only true of cubics, if you restrict yourself to quadratics (although that brings other challenges), both the control issue goes away (you can just click+drag the curve!) and the performance issue goes away (quadratics are triangles, GPUs love them)That&#x27;s the summary of the talk[1] I gave at SYCL&#x27;22. In that talk, I didn&#x27;t have time to present the downsides of my solution (which are real!) so if you watch it please keep that in mind - the talk is about the problem statement, not a solution. We are exploring a different solution today than what was presented in that talk. My overall point in there, though, is a solid one: vector graphics as they exist today suck for artists and GPUs alike.The only reason we stick with vector graphics in their current form is because of SVG & compatibility with existing tooling. But isn&#x27;t it crazy? We have new bitmap image formats all the time, and so few vector graphics formats.In Mach engine[2] we&#x27;re continuing to explore this space, end-to-end, from author tooling -> format -> rendering. I&#x27;m not claiming we have a perfect solution, we don&#x27;t, but we&#x27;re at least thinking about this problem. Kudos to the authors of this article for thinking about this space as well.[0] https:&#x2F;&#x2F;bezier.method.ac&#x2F;[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=QTybQ-5MlrE[2] https:&#x2F;&#x2F;machengine.org reply pavlov 16 hours agoparentPostscript used cubic Béziers, but TrueType, specified some ten years later by Apple with the learnings from practical use of Postscript on Macs, opted to only support quadratics instead.Donald E. Knuth seems to think pretty highly of this decision:“The quadratic has the great advantage that there&#x27;s a real cheap way to render them. You can make hardware to draw a quadratic spline lickety-split. It&#x27;s all Greek mathematics, the conic sections. You can describe a quadratic spline by a quadratic equation (x, y) so that the value of f(x, y) is positive on one side of the curve and negative on the other side. And then you can just follow along pixel by pixel, and when x changes by one and y changes by one, you can see which way to move to draw the curve in the optimal way. And the mathematics is really simple for a quadratic. The corresponding thing for a cubic is six times as complicated, and it has extra very strange effects in it because cubic curves can have cusps in them that are hidden. They can have places where the function will be plus on both sides of the cubic, instead of plus on one side and minus on the other.“The algorithm that&#x27;s like the quadratic one, but for cubics, turns out that you can be in something that looks like a very innocuous curve, but mathematically you&#x27;re passing a singular point. That&#x27;s sort of like a dividing by zero even though it doesn&#x27;t look like there&#x27;s any reason to do so. The bottom line is that the quadratic curves that TrueType uses allow extremely fast hardware implementations, in parallel.”https:&#x2F;&#x2F;lists.nongnu.org&#x2F;archive&#x2F;html&#x2F;freetype-devel&#x2F;2000-01... reply vidarh 14 hours agorootparentAnd then OpenType added cubic bezier back in.... by embedding postscript font definitions.... Before they went one better and added support for embedding SVG for emojis.(I ported a tiny TrueType renderer from C to Ruby, and looked at what it&#x27;d take to add OpenType support, since OpenType uses the same container format; font file formats look like they were designed by a drunk student as a prank) reply slimsag 15 hours agorootparentprevWow, I didn&#x27;t know Knuth said that. I would&#x27;ve been 7 years old at the time - wild. reply pmcjones 15 hours agorootparentKnuth has been saying interesting things for a very long time. He began _The Art of Computer Programming_ project in 1962. reply dhosek 7 hours agorootparentYeah, I’m thinking that I met DEK before the parent poster was born (he told me that I would be able to be his student because I wasn’t taller than him. Spoiler: I was never his student). reply TheRealPomax 12 hours agorootparentprevthose are both Bezier curves. They&#x27;re just second vs. first order Bezier curves, but all the same math applies, and polybeziers are so much harder to work with when they&#x27;re quadratic instead of cubic, it&#x27;s not even funny. reply CharlesW 13 hours agoparentprev> But I&#x27;ve never met an artist or graphic designer who didn&#x27;t express some deep frustration at Bezier controls and how hard they are to work with.That surprises me, because Illustrator (especially earlier versions) is all about Bezier curves, and in my experience it doesn&#x27;t take long before you start to \"think\" like the Pen tool. I don&#x27;t recall working with an artist who couldn&#x27;t intuit how they worked after creating with them for a few weeks. reply crazygringo 11 hours agorootparentYou can easily learn how to use them.That doesn&#x27;t mean they don&#x27;t stop being frustrating.I will commonly wish there was a method to change a curve in a single drag in some particular situation, rather than 20 drags of fiddling with beziers, trying to figure out if adding another control point is necessary or redundant.Just because you figure out the intuition behind them doesn&#x27;t turn them into an efficient way of achieving results. Because the intuition of beziers translates poorly to our innate human&#x2F;artistic intuitions of curves. reply CharlesW 9 hours agorootparent> I will commonly wish there was a method to change a curve in a single drag in some particular situation…If I understand what you want, you&#x27;d probably really dig the Curvature tool. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xzilL2zvldo reply slimsag 5 hours agorootparentThat is exactly the type of user interface I am advocating for, I love that.Give me that + fast&#x2F;efficient GPU-animated keyframes of those curves, and I&#x27;m 100% sold. replyTheRealPomax 12 hours agoprevIt looks like the conclusion is \"let&#x27;s use rational Bezier curves instead of plain Bezier curves\", in which case: you can, you just have more parameters to tweak now. Also calling this \"new\" is a bit disingenous given that rational Beziers have been around half a century now. They&#x27;re useful, but if you only look at Bezier curves from the tooling side of things, you&#x27;re going to miss the reason why we use them so much. And the biggest mistake in design software is having tools that actually let you work with the datatypes that your final product is going to end up using. Need a circle? Draw a circle based on a center point and a radius. Good tooling won&#x27;t surface that fact that it&#x27;s going to end up being a Bezier curve, it just lets you design with the primitives you need, and will take care of the conversion as needed when you export it to whatever format your deliverable needs to be.Making people draw Bezier curves just because \"the file format uses those\" is by far the bigger problem here. reply ad8e 10 hours agoparentThere are a few misunderstandings here. Rational Bézier curves are incidental in this article, and the conclusion is not that they are correct. They were just a convenient curve I used to express the main message of local control, and the article endorses looking for other curves that fit the properties.The parameter count has not gone up; it&#x27;s equal to or less than usual Bézier control handles, because I forced the parameters to take specific values.The part that is \"new\" about the Béziers is the new formula that selects one specific Bézier out of all the possible choices. I think this linguistic accusation is silly; for example, if someone discovers a new rock, it would be fair to call it a \"new rock\" even though rocks have been discovered thousands of years ago.These curves are also unrelated to the file format; the curves are designed to fit how the user thinks about curves rather than be computer-efficient. For the tooling point, I think you are agreeing with me while arguing; I agree that there&#x27;s no reason the curve should match what is used in the final product, and some of the other curve choices I considered require a complex conversion step. reply bsder 11 hours agoparentprevThis article is really stretching when the conclusion is smacking him in the face: \"Use quadratic Beziers.\"The original article points out that quadratic Beziers have most of the desirable properties with very few of the downsides.It used to be that the issue was that you would have to use significantly more quadratic Beziers to approximate something that a much smaller number of cubic Bezier&#x27;s could do. This was a big deal when a font file might clog up a floppy disk.Now that we&#x27;re slinging around gigabyte patch files. Do we really care? reply PaulHoule 10 hours agoprevThere are these civilized curveshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Non-uniform_rational_B-splinewhich you never saw because patents kept them off the markets until Beziers were completely entrenched. reply raphlinus 13 hours agoprevThe goals look quite similar to my hyperbezier explorations. There&#x27;s an online demo of the first draft[1], and a Zulip thread on some progress toward a second draft[2]. The tl;dr is that I think I have the mathematics of the curve family, but I haven&#x27;t finished the mapping between control points and the parameters of the curve family.Both drafts have (exact) Euler spirals inside their parameter space, and thus circular arcs as well. I think that&#x27;s a good criterion for a Bézier successor.It&#x27;s on the back burner for now, but I hope to get back to it, and am open to collaboration.[1]: https:&#x2F;&#x2F;www.cmyr.net&#x2F;blog&#x2F;hyperbezier.html[2]: https:&#x2F;&#x2F;xi.zulipchat.com&#x2F;#narrow&#x2F;stream&#x2F;260979-kurbo&#x2F;topic&#x2F;H... reply dang 15 hours agoprevThis is a nice post but not a valid Show HN - please see https:&#x2F;&#x2F;news.ycombinator.com&#x2F;showhn.html.I&#x27;ve taken \"Show HN\" out of the title now. reply delta_p_delta_x 16 hours agoprev> Béziers can&#x27;t represent circles. If you try to approximate one by hand, it&#x27;ll look lopsided.Many graphics algorithms (vector operations: scale, translate, rotate; raster operations like rasterisation and interpolation) specialise for straight lines (and hence also triangles), Bézier curves, circles, etc separately, rather than forcing everything to be a Bézier curve. reply slimsag 16 hours agoparent\"Béziers can&#x27;t represent circles\" is not exactly wrong, but is not really the full picture.Often you don&#x27;t need to _represent_ a circle. TrueType fonts (quadratics) and OpenType fonts (cubics) can&#x27;t mathmatically _represent_ a circle, either, but does that mean no font has circles in it? Sometimes an approximation is pretty damn good.Also conics (rational quadratic Beziers), which Microsoft has a surprisingly good article on[0], can represent circles.[0] https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;xamarin&#x2F;xamarin-forms&#x2F;user... reply cormullion 14 hours agorootparentFortunately fonts usually don&#x27;t contain perfect circles anyway, because the designer will optically correct any circles so that they don&#x27;t appear to bulge. Kabel is the closest font I found with circular formas; LineTo&#x27;s Circular is also quite close but slightly taller than wider. reply mkl 12 hours agorootparentFonts are supposed to contain perfect circles; try searching for \"circle\" in a Unicode character map. They only don&#x27;t in practice because quadratic and cubic Bezier splines can&#x27;t do them. reply TheRealPomax 12 hours agorootparentAnd they don&#x27;t have to. The approximation of a circle with a bunch of cubic curves is so accurate [1] that you&#x27;d need to print a huge circle and then sit there with a measuring tape to be able to even tell it&#x27;s not a perfect circle. Which is why \"you can&#x27;t draw a circle with Bezier curves\" is only a mathematical \"problem\", it&#x27;s not an actual problem.[1] https:&#x2F;&#x2F;pomax.github.io&#x2F;bezierinfo&#x2F;#circles_cubic reply ad8e 11 hours agorootparentIt&#x27;s a UI problem, not a mathematical problem. No set of curves can represent everything exactly, but they all can get close. The goal is just to make it easy to get close.The computer can produce a near-perfect circle with Béziers for each 1&#x2F;4 arc, and near-perfect circles are usually good enough. It&#x27;s just inconvenient. It&#x27;s also hard to manipulate the generated circle; the user might have a clear image of his head of the changed circle he wants, but pushing the control points to get there is not easy.The mathematical \"axioms\" in the article are only attempting to provide a clean interface, so that the user can easily translate what is in his head to what the program creates. The circle axiom says, \"The user often wants a circle, and also expects a circle, so let&#x27;s produce the expected circle.\" There&#x27;s no other mathematical purity involved. replybobajeff 16 hours agoprevThe guy from the mach engine has also talked about issues dealing with Bézier curves and came up with a interesting set a primitives: Triangles, quadratic curves and semi-circles.Mostly this is make it easier to do vector graphics on a gpu, which is why I&#x27;m interested in it, but I think it might be easier to understand. reply IAmGraydon 8 hours agoprevI found the examples extremely easy to align with the target, but I&#x27;ve also been using Adobe Illustrator for over 20 years. reply butz 15 hours agoprevJust trying to align curves to targets was fun. Someone should build a whole game on this idea. reply slimsag 15 hours agoparenthttps:&#x2F;&#x2F;bezier.method.ac&#x2F; reply Nycto 16 hours agoprevObligatory links for anyone that is interested in learning more about Bézier curves:https:&#x2F;&#x2F;pomax.github.io&#x2F;bezierinfo&#x2F;https:&#x2F;&#x2F;pomax.github.io&#x2F;bezierjs&#x2F;https:&#x2F;&#x2F;github.com&#x2F;Pomax&#x2F;bezierjs reply anon____ 11 hours agoparentThese, too:https:&#x2F;&#x2F;ciechanow.ski&#x2F;drawing-bezier-curves&#x2F;https:&#x2F;&#x2F;ciechanow.ski&#x2F;curves-and-surfaces&#x2F; reply AlphaCerium 14 hours agoparentprevMight I also add: https:&#x2F;&#x2F;youtu.be&#x2F;aVwxzDHniEw?feature=shared Which works through them from first principles with beautiful animations. reply atan2 11 hours agorootparentI personally really like this video, but it&#x27;s interesting how when I showed it to a group of CS undergrad students, they all loved the animations but performed poorly on a post-video quiz about the topic. I knew the content already, but I wonder if this video is really as educational as it appears to be. reply bombdailer 7 hours agorootparentHer other video on the subject https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=jvPPXbo87ds&t is far more interesting and informative imo. reply CrimsonCape 16 hours agoprevDo you have any publicly available code on github? reply ad8e 15 hours agoparentThe source code is visible with Ctrl+U, I didn&#x27;t minimize anything. The g9 use is pretty neat. It definitely deserves the shout-out I gave it.I just now uploaded a worse C++ desktop version with saving and loading: https:&#x2F;&#x2F;github.com&#x2F;ad8e&#x2F;local-curves This desktop version is 5 years old. I think the web version is better. This github repo is only interesting if you want to copy code from it; it&#x27;s not practical as a drawing tool. reply CrimsonCape 15 hours agorootparentOk thanks. I will possibly try to port to SkiaSharp in the future to learn how your code works. reply jheriko 15 hours agoprevgood work. i&#x27;ve always found bezier curves impractical and overrated, using standard polynomial interpolations or more easily understood variants. reply javajosh 16 hours agoprev [–] beautifully made. However I think one&#x27;s intuition for where the control points go and what they do are very clear if you&#x27;ve ever taken calculus. The line segments control the direction and magnitude of the tangent to the curve at that position. If you understand that, then it makes the motivating problem go away, and all the challenge problems are easy to solve. reply ad8e 16 hours agoparentIt&#x27;s not as easy to visualize the tangent magnitude as you are suggesting, because the time parametrization makes the calculation fail - the curve doesn&#x27;t travel forward at a constant rate. This is best seen with the second example: If the left handle is fully extended and the right handle is 0, the Bézier curve looks almost exactly the same as when the handles are reversed. Here&#x27;s a picture: https:&#x2F;&#x2F;i.imgur.com&#x2F;WkanN1G.pngThe handle varies from 0 to full-strength, but the magnitude of the tangent vector stays constant. This means the handle doesn&#x27;t decide the magnitude. Tracing the path in your head to visualize the changing tangent vectors would mean visualizing a competition between t^2, (1-t)^2t, and (1-t)^3, which I find difficult, even with some calculus knowledge. reply pavlov 16 hours agoparentprevInteractive curves are primarily meant to be used by designers. They are a tool. When the tool is not intuitive, it’s not really a solution to say “designers should just take calculus and it makes the problem go away.” reply unconed 16 hours agoparentprev [–] This isn&#x27;t true, and is obvious when you try to split a bezier without distorting its shape.As a bezier is just repeated interpolations, the tangents and their lengths can be derived from the intermediate interpolations [1]. This means that if you split a bezier near an existing control point, the new point will have wildly unbalanced tangents on both sides, and yet, connect into the exact same cubic curve.So both your intuition and your confidence in it are... wrong.[1] https:&#x2F;&#x2F;i.stack.imgur.com&#x2F;I9wKC.png replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the difficulties of using Bézier curves, highlighting issues such as determining the proper placement and length of control points.",
      "A mathematical solution is proposed that uses the local properties of curves - position, direction, and curvature - to manage the curve's shape, permitting easier drawing and alignment; it also solves inherent issues, like representing circles and maintaining curvature continuity.",
      "The piece additionally touches on the limitations and tradeoffs of this proposed solution, hinting at potential future developments in the field."
    ],
    "commentSummary": [
      "The article explores the use, advantages, and challenges of Bézier curves in graphic design and animation.",
      "It proposes alternative curves like quadratic Beziers, hinting at potential limitations of Bézier curves, notably their inefficiency in accurately representing circles.",
      "There's a spotlight on the ongoing discourse and investigation of different methodologies pertaining to vector graphics."
    ],
    "points": 167,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1694361367
  },
  {
    "id": 37455382,
    "title": "Is air conditioning making cities hotter?",
    "originLink": "https://www.euronews.com/green/2023/08/30/fact-check-is-air-conditioning-making-cities-hotter",
    "originBody": "Continue without agreeing → We and our partners store and access non-sensitive information from your device, like cookies, and process personal data like IP addresses, for data processing like displaying personalized ads, measuring preferences of our visitors... You can change your preferences at any time in our Cookie Policy. Some partners do not ask for your consent to process your data and rely on their legitimate interest. You can object to it by clicking on “Learn More”. We and our partners do the following data processing: Measure audience, Personalised ads and content, ad and content measurement, audience insights and product development, Precise geolocation data, and identification through device scanning, Storage and access to geolocation information for targeted advertising purposes, Storage and access to geolocation information to carry out marketing studies, Store and/or access information on a device View our partners Learn More → Agree and close NEWS CLIMATE NATURE LIVING ECO-INNOVATION OPINION SERIES Climate Now The Road to Green Ocean GreenClimate Fact-check: Is air conditioning making cities hotter? By Sophia Khatsenkova Published on 30/08/2023 - 07:00•Updated 16:29 Share this article A study found that waste heat generated by a city’s worth of air conditioners during a heatwave can raise the outside temperature by more than 2 degrees Celsius. As Europe faces more frequent and more intense heatwaves, you might have considered taking the plunge and buying an air conditioning unit. But while you'd be forgiven for thinking it’s cooling things down, it’s actually doing the exact opposite, it’s heating things up. In France, the use of air conditioning has become the subject of debate after left-wing MP Mathilde Panot said during an interview, “the temperature of a city can be increased by up to 2 degrees Celsius due to the use of AC [air conditioning].” Was she right? Where did the French MP get this statistic from? It comes from a study published in 2020 that was based on a scenario in which air conditioners are used in all buildings of a city like Paris to maintain an interior temperature of 23 degrees Celsius during a heatwave. Temperature increases due to air conditioning (AC) use \"depend on the time of day and the characteristics of the heatwave, mainly its intensity\", according to the study. The scientists used the deadly 2003 heatwave which killed more than 14,000 people in France to model their predictions. They found that, after \"Nine days of a heat wave similar to the one of 2003,\" the systematic use of AC during that time would increase air temperature \"by up to 2.4°C\". Europeans reluctantly turn to air conditioning as heatwaves bite 'Absolutely disastrous': Air conditioners take horror toll on the environment, campaigners warn Why does air conditioning increase the temperature? How is that possible? Because air conditioners work like a heat pump, cooling a room by releasing hot air outside. Air conditioners use more electricity than any other appliance in the home. They consume 10% of global electricity and leak harmful planet-warming gases into the atmosphere. The link between AC use and increasing temperatures in cities has already been documented. According to research published in 2014 in the Journal of Geophysical Research: Atmospheres, excess heat generated by a city’s worth of air conditioners can increase the outside temperature by 1 to 1.5 degrees Celsius at night. And as cities are only likely to grow hotter as a result of climate change, that means that citizens are likely to demand more indoor air conditioning. Heatwaves that would have been a once-in-a-decade event in the 1800s iare now more intense and happen nearly three times as often, according to the latest IPCC report. Ranked: These are the best and worst cities in Europe for eco-friendly transport links What is an urban heat island? Here's why cities are so much hotter than the countryside Air conditioner use is set to triple worldwide by 2050 In 2019, 20% of EU households owned an AC unit, according to the European Environment Agency. The number of air conditioners worldwide is predicted to rise from 1.6 billion units today to 5.6 billion units by the middle of this century, according to a 2018 report issued by the International Energy Agency. By 2050 all the air conditioners in the world would use as much electricity as China does for all activities today, according to the report's predictions. What are some alternatives to air conditioners? The scientists behind the 2020 study suggest other options to help cool down cities: including creating more green spaces, insulating buildings, and better advising the population on how to keep cool during a heatwave. If all of these measures are taken, the study claims these actions could significantly \"cool outdoor air temperatures up to 4.2°C at night\". Share this article You might also like CLIMATE Europe heatwave: Was it this hot in Rome back in 1841? CLIMATE Fact-check: Are droughts in EU man-made and are airplanes responsible? CLIMATE Is the EU the only place on Earth that has reduced its emissions? Technology Air conditioner Thecube Science Climate change Heatwave ADVERTISEMENT ADVERTISEMENT Most viewed World’s biggest wind turbine breaks record for power produced in a day In data: How much has Europe warmed up over the past 40 years? Greta’s school strikes led 30% of Swiss citizens to change habits Fact-check: Is air conditioning making cities hotter? UK heatwave: Why is it so hot in September? ADVERTISEMENT NEWS CLIMATE NATURE LIVING ECO-INNOVATION OPINION SERIES Terms and Conditions Cookie Policy - English Visit Euronews",
    "commentLink": "https://news.ycombinator.com/item?id=37455382",
    "commentBody": "Is air conditioning making cities hotter?Hacker NewspastloginIs air conditioning making cities hotter? (euronews.com) 147 points by elorant 21 hours ago| hidepastfavorite250 comments a_square_peg 11 hours agoI really hope people don&#x27;t take this result at its face value - the model used and the approach is extremely simplistic, which is essentially a pseudo 2-D simplification of urban canyon geometry, a street with buildings on either sides. I worked with the referenced model as part of my master&#x27;s thesis.The bulk of urban heat island effect is driven by the radiative absorption of non-porous materials of the built-environment. Other heat waste put into the area accounts for less than something like 5% of the additional heat added when compared to rural areas. reply darkclouds 6 hours agoparentI&#x27;ve got F&#x27;all qualifications, but I can read and remember which means I also know Ozone (O3) levels can trap heat[1], and heat is Infra-Red (IR), a large part of the electromagnetic light spectrum [2] and ozone happens to be considerably higher in built up in areas[3], also contributing to the Heat Island Effect seen in towns and cities.So whilst I cant find a copy of the study, and I recognise your comment on the modelling and approach being simplistic, the above also demonstrates that other factors like increased number of vehicles on the road, can be a factor as they contribute to ground level ozone and many also come with an air conditioning unit built into the car as standard today.[1] https:&#x2F;&#x2F;uk-air.defra.gov.uk&#x2F;research&#x2F;ozone-uv&#x2F;moreinfo?view=...[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Light#&#x2F;media&#x2F;File:EM_spectrum....[3] https:&#x2F;&#x2F;www.gov.uk&#x2F;government&#x2F;statistics&#x2F;air-quality-statist.... reply pembrook 4 hours agorootparentOn a hot sunny day, the blacktop beneath the traffic jam is radiating more heat than all the cars on top of it are creating.And a car engine is producing far more direct heat than the increase in ground-level ozone from exhaust pollution is increasing heat (from that same car).Also the fact that cars have air conditioners is a total non-sequitur. The air conditioner in the car requires negligible energy compared to the force required to move 4000 pounds and 1-5 people at 70mph. reply darkclouds 1 hour agorootparentThis maybe true, but I&#x27;d argue the air con still takes about 5mpg off the range of the fuel, but their existence and heat isnt magically disappearing, it spreads out helping to raise temperatures.This link [1] suggests traffic jams can increase temperatures by 7 degrees Celcius.[1] https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC9678727&#x2F; reply tasogare 11 hours agoparentprev> the model used and the approach is extremely simplisticSeems like a constant in doomsday \"science\": making a model that bear ressemblance to reality as much as SimCity does, run it to get the expected conclusion, then extrapolate and conclude with newsworthy title that X or Y is true in reality. reply thfuran 10 hours agorootparent>then extrapolate and conclude with newsworthy title that X or Y is true in reality.It&#x27;s worth noting that this portion is generally done by science reporters rather than the scientists. It&#x27;s quite often the case that alarmist articles refer to research with much more measured and less sweeping claims. reply ChainOfFools 6 hours agorootparentextremely relevanthttps:&#x2F;&#x2F;phdcomics.com&#x2F;comics&#x2F;archive.php?comicid=1174 reply blackbear_ 6 hours agorootparentprevSimplification and abstraction are, in fact, basic tenets of all scientific and philosophical disciplines.https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;simplicity&#x2F;https:&#x2F;&#x2F;iep.utm.edu&#x2F;simplici&#x2F;Of course, you are more than welcome to voice concrete concerns about this specific study, if you have any (beyond what the GP already said). reply chipsa 52 minutes agorootparentThere&#x27;s simplification, and there&#x27;s \"Spherical cow on a frictionless plane in a vacuum\". reply heisenzombie 42 minutes agorootparentprevYup, the only word a physics professor likes more than “negligible” is “trivial”. reply edgyquant 6 hours agorootparentprevNo they aren’t in this sense. I’m really not sure what you are attempting to convey here, maybe you’re being defensive for reasons unrelated to this topic, but your links aren’t talking about doing ultrasimplistic studies that don’t properly model the problem and treating results as fact. They mean simplicity in the Occams Razor meaning. Occams Razor is about the simplest solution being the most likely (e.g. don’t invent a ton of conclusions) and in fact is a philosophical argument for the existence of god.Please don’t condescend people and definitely don’t go around arguing that science holds unrealistic simplicity as a core tenant. reply reportingsjr 20 hours agoprevThis is one reason I heavily push for roof top solar, even if it is a bit more expensive than utility scale. In many areas air conditioning is pretty much a given at this point.A typical solar panel absorbs ~20% of the sun&#x27;s energy blasted on to a city rooftop. If that&#x27;s used to power air conditioning it&#x27;s doubly effective. You&#x27;re reducing the heat urban heat island effect from the sun&#x27;s energy, and you&#x27;re also not adding additional heat from external power sources in to the city.On a large scale this would really help make cities more livable. On a hot summer day here in northern Kentucky I noticed a massive difference (I&#x27;ve roughly measured it at a 5-7F difference) going from less developed areas to the more urban areas. reply slt2021 14 hours agoparentTrees are a much better solution to urban heating. Proven with millennia, eco friendly, and makes cities beautiful and desirable to livehttps:&#x2F;&#x2F;creativelyunited.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;02&#x2F;temp... reply jeffchien 11 hours agorootparentWith regards to temperature, there are more levers to pull, like the aspect ratio of the street (narrower = cooler). Architects in Taiwan and southern China have been studying arcaded streets (qilou&#x2F;騎樓), which seem to be as good as trees for shielding pedestrians [1], except in situations where the sun might shine through the sides or ends.Of course, trees are great for many other reasons like air quality, but for temperature fundamentally they&#x27;re just big evaporative coolers. I wish cities in more water-stressed areas would consider arcades + rooftop solar.[2] https:&#x2F;&#x2F;www.mdpi.com&#x2F;2071-1050&#x2F;11&#x2F;5&#x2F;1355&#x2F;htm reply AlDante2 7 hours agorootparentThe big advantage trees have ove most man-made shade is that heat can convect through them. If you’ve ever sat underneath an umbrella at a café versus a beer garden under trees you’ll notice the difference. The umbrella shades, but traps reflected heat, re-radiating it below. reply agsnu 2 hours agorootparentTrees also provide a significant cooling effect by releasing water vapour into the air from the soil (evapotranspiration), which you won&#x27;t get under an umbrella. reply samcheng 5 hours agorootparentprevQilou seem much more oriented around shelter from the rain than for shelter from the sun, though. I agree that they&#x27;re a great addition to urban streets for pedestrians! reply jjoonathan 11 hours agorootparentprevTrees are swamp coolers. Consuming freshwater for outdoor air conditioning isn&#x27;t necessarily a bad idea, but you aren&#x27;t cheating thermodynamics. reply kgermino 11 hours agorootparentTrees are so much more than swamp coolers.Leaves block the Sun relatively high off the ground, meaning people are in the shade during the hottest part of the day and feeling as much radiation off buildings and streets in the evening.Beyond cooling they’re also good for water management. Most street trees don’t need any watering (at least in the Midwest) they live off rainwater. When it rains, water pools on the leaves and evaporates from there, reducing the amount of run off and keeping the street drier and less humid on days with light rain.In cooler months (and places where this is relevant) the leaves fall and you can still get the warming benefit of sunlight. reply jjoonathan 10 hours agorootparentI love trees and want more of them in our cities, my only point is that they are not usually a substitute for HVAC unless your climate is in a precise sweet spot of plentiful water, dry air, and not too much heat. Rather than letting wishful thinking snowball into bad policy and disappointment, let&#x27;s promote trees by focusing on what they do well (what you&#x27;ve mentioned plus aesthetics and sound damping) rather than by ignoring the limitations of evaporative cooling. reply AlDante2 7 hours agorootparentIn which climate zones do trees not make their surroundings more temperate? Trees live from Alaska to the equator, and from the coast to near-desert. They are not de-humidifiers, but they certainly regulate temperature. reply Spooky23 7 hours agorootparentprevThey reduce the load. I live in a place with hot humid summers. My block is shaded with mature oak, nut and maple trees. There’s always a breeze, and less solar energy is absorbed by blacktop. reply kgermino 10 hours agorootparentprevI guess we disagree on what trees do well. I’m in the Midwest with warm semi humid summers. Trees keep the area around them massively cooler, not by evaporation but by shading.Maybe it’s a disagreement of terms? I guess they aren’t technically “cooling” the area in an active sense, but they absolutely keep it cooler even when it’s 95 and the dew points over 70 reply freddie_mercury 9 hours agorootparentDew point over 70 doesn&#x27;t sound that high?I live in Vietnam. It is 8am right now and the dew point is 80. It only 80 at the moment but is supposed to get up to 90 later in the day. I assume the dew point will also go up to around 90.AccuWeather says the \"RealFeel\" will be 97 and \"RealFeel Shade\" will also be 97, so being in the shade does almost nothing, since it is overcast and raining very slightly at the moment.We&#x27;re not in a heat wave or anything, this is just normal weather basically year round. If anything it&#x27;s been especially rainy and cool the past few weeks.Trees are nice but are not remotely a substitute for air conditioning. Trees do not lower humidity enough to stop the average European&#x2F;American from sweating constantly just sitting still here. reply glitchc 6 hours agorootparentVietnam is sub-tropical, not directly comparable. Better to compare Vietnam to itself, with and without trees. How much hotter is it in the city compared to the jungle? reply spongebobstoes 8 hours agorootparentprevof course trees are not a substitute for air conditioning. but, on a sunny day a street heavily shaded by trees is significantly cooler than the same street with no trees. this is true no matter how hot out it isthat&#x27;s not to say that the heat under a trees&#x27; shade cannot still be oppressive. merely that shade matters, as the existence of two \"RealFeel\" measurements you shared indicates reply freddie_mercury 8 hours agorootparent> of course trees are not a substitute for air conditioningWell the whole thread was something arguing they are.First post: \"I love trees and want more of them in our cities, my only point is that they are not usually a substitute for HVAC\"Reply: \"I guess we disagree on what trees do well\" reply kgermino 7 hours agorootparentGoing back to the beginning what started this is a debate about whether trees cool cities.I don’t think anyone (certainly not me) has intended to argue that trees can replace AC, just that they make the city around them (including indoors in many cases) much cooler than they would be without the trees reply jrockway 9 hours agorootparentprevThe shade is the important effect. Air conditioners have to use energy to remove heat from the indoors. That means that if the indoors are less hot, then you need to move less energy out of the room. Trees are great here, because the trees stand in the way of our solar system&#x27;s largest energy source and the indoors.To be fair, things like insulation are also good here. You want something outside to get hot when the sun shines on it instead of whatever space you&#x27;re cooling.(There are, of course, many heat sources inside that are annoying. I was running some fuzz tests yesterday and was annoyed to watch my air conditioner scale up in power to remove the heat that was wasting. I guess that&#x27;s why people use The Cloud for everything. You can heat up someone else&#x27;s city while enjoying the comforts of home!) reply ComputerGuru 11 hours agorootparentprevNative, grown trees need no watering, even in a (one- or two-off) drought. reply jjoonathan 11 hours agorootparentSure, but less evapotranspiration = less cooling. You aren&#x27;t cheating thermodynamics. reply ComputerGuru 9 hours agorootparentApparently a good part of the reason (parts of) the Midwest can get uncomfortably humid some summers despite being so far from large bodies of water is the evapotranspiration from the crops (mostly the corn). So too much evapotranspiration is not always a great thing!(Of course those are being watered regularly.) reply uoaei 11 hours agorootparentprevWith enough trees the microclimate changes enough that precipitation is more likely in that immediate area, which compounds the cooling effects on average. reply lucidguppy 8 hours agorootparentprevhttps:&#x2F;&#x2F;www.energy.gov&#x2F;energysaver&#x2F;cool-roofsPaint roofs white - and then go plant some trees. reply brentis 6 hours agorootparentOddly houses in Dallas are going with white brick and pure black rooftops. Looks hideous to me and not solving our plight.Some modern neighborhoods are trying living roofs with grass. Haven&#x27;t taken off and the grass hasn&#x27;t survived either.Lastly, other day saw post about leaving grass uncut reduced surface temps notable amount. reply andsoitis 14 hours agorootparentprevWe can do both. reply zdragnar 13 hours agorootparentI can&#x27;t- the solar company I talked to said there&#x27;s too much shade on my roof for too much of the day, there&#x27;s no way to place the panels to make financial sense before the panels need to be replaced.It seemed a bit odd, because my roof is fully lit up, but only for a few hours a day- one half is covered most of the morning, and the other half most of the evening.Sadly, it&#x27;s not even really nice trees, just gigantic cottonwoods that litter leaves and twigs and sticky leaf pods like crazy. reply hinkley 12 hours agorootparentWait a couple years and check again. With micro inverters you can deal better with partial shade. They&#x27;re probably right that it makes no financial sense now, but that changes over time.The problem with solar is that unlit panels behave like a diode and no current flows. Chain together a lit and unlit panel and you get nothing. Put the inverter ahead of the interconnects and that&#x27;s not a problem. reply briHass 11 hours agorootparentThe problem with rooftop solar in the US is that the install cost is so high. Even if the panels were free, there are many areas where you&#x27;d be looking at 15+ year payback, which is a bad investment.I&#x27;d love to do solar, but the only way I can make the numbers work is if I DIY&#x27;d the full install. reply prawn 8 hours agorootparentWhat makes the install cost high? Where I live in Australia, 44% of houses have rooftop solar and installations seem to be done in a fraction of a day. Seems like a pretty efficient process where they bolt racks to the roofing iron and then attach panels to the racks, wire it up, etc. reply zdragnar 5 hours agorootparentHere&#x27;s a decent breakdown for US installs: https:&#x2F;&#x2F;solaractionalliance.org&#x2F;residential-solar-panel-cost...Your 5-10k range installs will be $10-20,000 AFTER the tax credit, which might be a little higher now than when that graphic was put together.Of course, this doesn&#x27;t account for things like needing to re-do existing electrical work to get affected areas up to code, or if you need to replace the shingles on your roof while you&#x27;re at it because it&#x27;s typically recommended to do both at the same time if you&#x27;re going to add solar.Then again, you may also have the problem of ensuring your roof will withstand the extra weight, depending on the system. Most people are probably fine here, but for older houses in snowy climates it&#x27;s worth thinking about as well.I&#x27;ve looked into solar for my house. Aside from not getting enough sun throughout the day due to tree shade, there&#x27;s also the problem that every solar calculator available wants to pretend that energy prices are going to go up 5% a year. Well, I&#x27;ve lived at my current house for 5 years and they haven&#x27;t gone up once. The real payback for me is 20 years, if I&#x27;m lucky, even without the trees in the way. reply prawn 4 hours agorootparentWow. That&#x27;s quite remarkable. 7kW here was under US$4,000 including inverter, panels, installation and accounting for government rebates (some sort of credit system that the energy company handles by buying your credits off you, AFAIK). That was installed onto typical industrial metal roofing sheets - not sure of the name of it. Similar price at home installed onto corrugated iron which is very common in Australia. reply mcny 8 hours agorootparentprevAssuming you want net metering, you’d need controls in place for grid safety and such and all the permits and inspections which take time and cost money. reply prawn 7 hours agorootparentI imagine all that is pretty standard here also - South Australia isn&#x27;t exactly without regulation or seemingly high labour costs. I used the same company at the office building and then at home, and each was painless. Approve an easy quote and then everything is later installed on a particular day. Both were in the 5-10kW range.At the office building, the estimated payback was all of two years. reply Spooky23 6 hours agorootparentprevIt’s not. You may have to retrofit parts of your electrical system.People also stuff like leasing that adds overhead. reply midoridensha 8 hours agorootparentprev>What makes the install cost high?US skilled labor costs are insane. It makes all construction costs ridiculously high. reply 10u152 11 hours agorootparentprevMicro inverters don&#x27;t solve everything. Installing panels where they&#x27;ll be in full sun for an hour a day isn&#x27;t a good use of resources. reply hamandcheese 10 hours agorootparentprevWouldn&#x27;t a much simpler and cheaper approach be bypass switches for each panel instead of microinverters?For that matter, can solar panels be wired in parallel instead of in series? reply zdragnar 10 hours agorootparentThey can, but you need a suitable equipment- thicker wires, at a minimum. Wiring in parallel means the voltage is the same regardless of the number of panels, but the current sums up- so your inverter and&#x2F; or controller will need to be rated appropriately. reply cassepipe 13 hours agorootparentprevDon&#x27;t worry, a sizeable part of the tree population we are used to live by are going to die because of climate change. Problem (soon to be) solved. reply parineum 9 hours agorootparentIf you want to play that game, a sizeable part of the tree population is just going to migrate north&#x2F;south.The more immediate problem with climate change isn&#x27;t that there won&#x27;t be enough places to live&#x2F;farm, it&#x27;s that it&#x27;s all going to move causing destabilization of societies.The long term effects of running out of arable land are a considerable distance in the future. reply midoridensha 4 hours agorootparentMaybe I&#x27;m missing something, but I don&#x27;t see how we&#x27;ll ever run out of arable land. The Earth has been warmer than now, in the distant past: there were times when the poles were not frozen over. Of course, this means the sea level was higher than now, so melting all the glaciers means a lot of our cities (and probably most of Florida) will be underwater, and it isn&#x27;t so easy to pick up a city and move it to higher ground. A warmer Earth probably means more deserts, but there should still be arable land, in places that are currently cold tundra perhaps. reply distant_hat 13 hours agorootparentprevMy neighbors cut down trees around their house so that the solar panels could have unobstructed Sun. reply hinkley 12 hours agorootparentThis is why we can&#x27;t have nice things. reply ProfessorLayton 12 hours agorootparentI have mixed feelings about this. My neighbor cut down their tree, and now my living room enjoys a lot more sun throughout the day, and my yard has a lot less trash to cleanup. reply BeetleB 11 hours agorootparentAnd your house is hotter.My neighbor shields much of my house from the sun. We had issues when his branches started touching my roof, but we made sure it was trimmed in a way to still give us the shade it has all these years. reply hinkley 12 hours agorootparentprevThere&#x27;s an art to growing and tending trees that leave visibility and air at ground level. reply psunavy03 11 hours agorootparentGrinds my gears when people just hack down something that took 20-100 years to grow without even thinking of consulting an arborist. reply lotsoweiners 10 hours agorootparentThe problem in my neighborhood is the arborist probably needed to be consulted before the tree was planted in the first place. reply parineum 9 hours agorootparentprevSolar panels are nice things. reply m463 12 hours agorootparentprevI think an interesting way of doing this would be to have tree-like solar panels. they would be somewhat wasteful in some ways, but would organically gather solar energy at a variety of times from a variety of directions. They could also provide a % of light through in all directions to give partial shade and coexist with trees. reply ehnto 6 hours agorootparentprevYou will still want airconditioning in a great many cities. It gets to 45c in the forest here, no amount of trees will help the city, although of course they are still part of a good solution.As always it&#x27;s likely a combination of solutions, and rooftop solar is a good idea for more reasons than just heat. reply crazygringo 7 hours agorootparentprevSorry, do you mean trees on roofs?Since the person you&#x27;re responding to is talking about solar panels on roofs and you&#x27;re suggesting trees instead? reply BurningFrog 10 hours agorootparentprevTrees can shade one story houses, but hardly any multiple floor apartment buildings.Which makes it a good solution only to suburban heating. reply another_story 9 hours agorootparentIt&#x27;s a huge benefit to the crowds at street level, and keeps the city cooler overall because all that concrete is not being turned into a heated surface. They&#x27;re not generally there to shade the buildings, but the people and roads. reply throw3823423 7 hours agorootparentI think of the cities in Spain with the hottest climates, and I don&#x27;t see a lot of crowds being protected by tree shade: Instead, the traditional design is narrower streets which aren&#x27;t straight for very long, and even white cloth hanging across the street to provide the shade directly.It&#x27;s not that there&#x27;s no trees, but you&#x27;ll see them in parks and boulevards that might as well be narrow parks.If anything, I see far more trees in the American midwest. Here the streets are very wide, with basically no foot traffic to speak of, and too much road for the number of cars that use the street in urban areas. You can definitely fit trees here, but that&#x27;s because so much of that concrete is waste. The extra trees just mean more distances, and more distances means more parking lots and more concrete. reply rowanG077 12 hours agorootparentprevI disagree. No amount of trees will take my 30 degree indoor temp down to 22. reply lionkor 11 hours agorootparentHave you lived in a house covered entirely in tree shade? reply jjoonathan 11 hours agorootparentI can look at the wet-bulb temperature and see exactly how far trees will get me. This time of year, it isn&#x27;t far -- which checks out, because I have plenty of trees and they don&#x27;t stop the heat. Swamp coolers (trees are swamp coolers, thermodynamically speaking) are brilliant if humidity is low and freshwater is plentiful, but if either of those wheels come off no amount of wishful thinking will make evaporation work comparably to a refrigeration cycle. Where I live, it&#x27;s the humidity. Fortunately, I do have real AC, and even better, my power mix is predominantly nuclear so I can crank that AC and get real cooling without pumping legions of dead dinosaurs into the sky. Damn it&#x27;s nice to live in the 21st century. Or the 20th. reply BeetleB 11 hours agorootparentI don&#x27;t know exactly how many degrees the shade will bring the temperature down, but just today my portable temperature sensor reported an 8F degree difference compared to one in the shade - both were in the same area of the house, but one happened to be where sunlight was coming in from a narrow window. And the sensor was in the sunlight for under an hour when I recorded the difference.Of course, this is spot heating, and over a whole house the effect will be diminished, but it tells you how quickly things can get hot. reply jjoonathan 10 hours agorootparentNo, I did not forget that shade exists. It&#x27;s still uncomfortable in the summer. Once RH hits 100%, evaporation stops cooling and your options are to go without or to use a different thermodynamic cycle.We&#x27;ve got plenty of freshwater in these parts, but in other places freshwater availability will be the limiting factor. Famously, swamp cooling works great in the desert if you can spare the water.Trees are great, let&#x27;s just be real about what they can and can&#x27;t do. reply rowanG077 10 hours agorootparentprevNo. I don&#x27;t have to. The wet bulb temperature will tell you enough. No amount of trees will lower the wet bulb temperature. I live in an area with humid summers so trees help but are no solution. reply uoaei 10 hours agorootparentA tree growing is itself an endothermic process, in addition to the passive shade and quasi-active evapotranspiration it exhibits. They will help in multiple ways, but of course only up to a point. reply_Algernon_ 20 hours agoparentprevConsidering that solar panels are close to perfectly black, they will also close to perfectly absorb the remaining 80%. The 20% of solar electricity that is then used for AC, will be released as heat as well.You&#x27;ve just made a ~100% efficient heat capturing machine. The 98.1% reflecting paint will be much more efficient, with the added bonus of not being dependent on the grid. reply pfdietz 19 hours agorootparentAre PV cells really that black for photon energies below their bandgap?It would be nice if the cells were highly reflective at a range of wavelengths between the range they can actually use and the range where they radiate waste heat. reply MichaelZuo 15 hours agorootparentYes they are very black in the visible spectrum. Like the parent said a highly reflecting white paint for rooftops would certainly be the smarter choice. reply chris_va 14 hours agorootparentThey are usually reflective out of band, for unifacial (ito on semiconductor on a metallic backing), so ~40% of the radiation is heading back to space, vs 10-20% for a typical roof.However... that means they don&#x27;t radiate well at night (they have low emissivity and are not well thermally coupled to the roof). Painting the roof white is ideal. reply pfdietz 12 hours agorootparentHmm. I wonder if the glass can have a coating that would make them more emissive in the atmospheric transparent bands of the mid- and far-IR. reply jstanley 6 hours agorootparentprevIt is easy to tell that they are black in the visible spectrum because they look black. reply pfdietz 15 hours agorootparentprevI wasn&#x27;t talking about the visible spectrum, I was talking about near IR below the bandgap (which is just below visible for Si cells.) This light does not contribute to the output of the cells, so reflecting it back into space would reduce heat generation at no loss of efficiency. If anything, by keeping the cells cooler it would slightly boost efficiency. reply perihelions 14 hours agorootparentThere were HN threads about this (?)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27782370 (\"Passive radiative cooling below ambient airtemperature under direct sun\") reply aeternum 15 hours agorootparentprevYou can do both, typical rooftop solar installations typically don&#x27;t cover the majority of the roof. Make the rest reflective and&#x2F;or make it a space for people. Rooftop area has some of the greatest views in any city. Kinda crazy that we don&#x27;t use it as space for humans and greenery in most cases. reply pfdietz 14 hours agorootparentI want to point out that to optimize for temperature reduction, you want to minimize absorption while maximizing thermal radiation. This says you want the surface to be reflective at wavelengths below some cutoff, but perfectly emissive (that is, black) above that wavelength. (Actually it&#x27;s a bit more complex, because the atmosphere emits IR in some bands.)Some work on surfaces of this kind have shown promising results, being able to fall below ambient temperature even in full sunlight.Do it yourself: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KDRnEm-B3AI reply esel2k 13 hours agorootparentprevRooftops are great, we have a 100m2 rooftop terrace and kids love it. But I had no idea how hot it gets. To the point where I don’t even step outside during those heatwaves. When the offical temperature was 36C we had in fullsun above 46C and the concrete panel was too hut to wall barefoot. So my take is that in dry&#x2F;hot areas rooftops are just unliveable. reply crtified 13 hours agorootparentprevI wonder, would that make for some interesting (or potentially problematic) visual side effects in an urban environment? With the variety of roof angles and sun angles, suddenly all manner of observation points (e.g. on roads) would potentially be subject to blinding reflections at different times of day and year. reply sethhochberg 12 hours agorootparentThese concerns already come up with things like glass and metal clad buildings - plenty of urban zoning codes already account for the light that reflects off new or modified structures (or at least try to).It tends to be newsworthy when it goes wrong, because the results can be things like buildings cooking nearby objects at certain times of day. Spicy stuff.https:&#x2F;&#x2F;www.upi.com&#x2F;Odd_News&#x2F;2013&#x2F;09&#x2F;03&#x2F;Skyscraper-melting-c... reply crtified 9 hours agorootparentFair point. In hindsight, my mind had wandered off unsupervised, and was picturing the unadulterated chaos of an instant universal conversion of all existing rooftops to super-reflective.\"All will be simultaneously unveiled at 12 Midday tomorrow, citizens, so, ...take care out there!\". reply zbrozek 12 hours agorootparentprevRoof reflectivity higher than 40% is illegal by zoning code in my city. reply pfdietz 11 hours agorootparentWhite roofs are being pushed in NY City.(shared link, readable even without a sub)https:&#x2F;&#x2F;www.nytimes.com&#x2F;2021&#x2F;11&#x2F;10&#x2F;realestate&#x2F;cool-roofs-cli... reply neRok 9 hours agorootparentprevI wondered this a long time ago too (if solar panels cause more heating by absorbing more), but actually they still reflect a fair portion of the suns energy. [This article](https:&#x2F;&#x2F;www.treehugger.com&#x2F;ask-pablo-do-solar-panels-contrib...) says earths average reflection coefficient is ~0.35, and that cities are more in the range of ~0.1. Solar panels are ~0.3, so much better than many existing roof materials and of cities in general. reply hinkley 12 hours agorootparentprevThe solar panels are not quite in contact with the roof though, and that air gap does reduce absorption. reply contravariant 12 hours agorootparentFor the heat island effect the distinction is immaterial. The city itself is still absorbing more heat, this heat must go somewhere.Your reasoning is a bit like assuming solar panels stop flooding because they prevent the roof from getting wet. reply hinkley 12 hours agorootparentMy point was that a carbon black shingle would result in a much higher amount of work required to cool the inside of the house because you&#x27;d be baking yourself alive. The standoffs for solar prevent that. Which at 20% efficiency panels, back of the envelope says that could end up cancelling out the benefit of the panels entirely, for more than half the year. reply sidewndr46 13 hours agoparentprevIt can&#x27;t be \"doubly effective\". The energy cannot simply disappear into the void. If it is used to run something electrical in the house, that energy is still there. If you ship it into the grid and across the country, less of the heating is localized. But it is still heating as it travels through the wires.As it turns out, solar panels are often more reflective than the typical roof of a house in North America. So solar panels can actually reduce the heat island effect. But it is mostly independent of whether they are hooked up at all. reply wolverine876 9 hours agorootparent> solar panels are often more reflective than the typical roof of a house in North AmericaReflective of what wavelengths? Isn&#x27;t that an odd characteristic of something designed to absorb electromagnetic energy? reply y42 18 hours agoparentprevWait what? An AC does not simply turn hot air into cold air. It \"moves energy\" from one place to another.Indeed it would be nice to power the AC with solar power, but how does this help the city to cool down? You would cool down the houses, but the heat from the houses would remain in the city, it would even get hotter. reply robotresearcher 15 hours agorootparentThe argument is that you aren’t moving additional energy into the city from power stations to run the AC, which ends up as heat. Instead you’re using energy that’s already radiated into the city from the sky.As others have pointed out, you might do better bouncing the incoming radiation back out of the city with white roofs. And still others say you can do a bit of both. reply reportingsjr 15 hours agorootparentExactly correct!Also, you could definitely do well to reduce your roof albedo by switching to white&#x2F;reflective roofs. This point has been made endlessly over the last 30-40 years. No one actually does it. People are actually installing solar panels. reply crazygringo 14 hours agorootparent> No one actually does it.To the contrary -- at least in NYC it&#x27;s extremely common. The vast majority of \"tenement\" apartment buildings have silver roofs, for this reason.Just fire up Google Maps in satellite view over Manhattan and see for yourself. White-looking roofs everywhere (but silver in reality).New construction with roof decks tends to use things like white-ish floor squares as well. They&#x27;re obviously much cooler to walk on in the summer.(While, sadly, contrary to your assertion, virtually nobody is installing solar panels in NYC. Landlords don&#x27;t seem very interested so far.) reply wolverine876 9 hours agorootparentWhy silver and not white? reply crazygringo 7 hours agorootparentGood question. I can&#x27;t easily find an answer, but this page at least seems to describes the type of silver roof common on old NYC buildings:https:&#x2F;&#x2F;flatroofdoc.com&#x2F;silver-coating-protecting-a-rubber-r...Elsewhere I find a claim that the aluminum paint used was a 20th century thing, but now white paint is preferred as being more reflective. reply andsoitis 14 hours agorootparentprev> No one actually does it.Los Angeles has building codes for cool roofs:https:&#x2F;&#x2F;www.ladbs.org&#x2F;docs&#x2F;default-source&#x2F;publications&#x2F;ordin... reply Ekaros 20 hours agoparentprevWouldn&#x27;t it be more effective to surface the roof tops with some reflective material? reply gamerDude 20 hours agorootparentYes! In fact there is a new paint that was developed with exactly this in mind. https:&#x2F;&#x2F;www.purdue.edu&#x2F;newsroom&#x2F;releases&#x2F;2021&#x2F;Q2&#x2F;the-whitest...Reflects 98.1% of the suns rays. reply artursapek 20 hours agorootparentis that dangerous to aircraft? reply mitthrowaway2 20 hours agorootparentAircraft can safely fly over snow, which has albedo if 90%, so it&#x27;s probably ok. reply hinkley 12 hours agorootparentprevIf the roof scatters the light, probably not.However if an entire downtown or subdivision does it? Possibly. reply ars 15 hours agorootparentprevOnly if the roof has a lens shape, otherwise it&#x27;s the same light as what&#x27;s coming from above which isn&#x27;t harmful. reply dylan604 14 hours agorootparentwell, it&#x27;s 98.1% of the same light, so technically, less harmful reply slt2021 14 hours agorootparentprevTrees, trees are a much better solution. Very simple yet effective solution to urban heating problemhttps:&#x2F;&#x2F;creativelyunited.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;02&#x2F;temp... reply throw3823423 7 hours agorootparentThat street&#x27;s sin is not the lack of trees, but having 6 entire lanes for cars, which apparently all go in one direction. An uncrossable nightmare that only even has stores at one side!Those nice trees take a few decades to grow, need serious pruning, will cause foundation problems next door, and increase building setbacks anyway. We also waste two entire lanes for street parking, have basically no businesses on either side anyway, and the street is still too wide. It might be urban, but it&#x27;s still a car centric hellscape, just with some shade. reply Dylan16807 13 hours agorootparentprevYes but not on roofs. They&#x27;re so heavy. reply sgu999 13 hours agorootparentAren&#x27;t grass-like plants working reasonably well? It&#x27;s quite common on new build where I am reply Dylan16807 13 hours agorootparentprev\"white\" and \"mirror\" are equally good at bouncing light, and the exact effectiveness is based on the specific design. reply wolverine876 9 hours agorootparentPlease explain? Mirrors seem to reflect much more, but maybe that&#x27;s another effect. reply Dylan16807 9 hours agorootparentThat&#x27;s an illusion because from certain angles the mirror is much brighter, and you don&#x27;t pay as much attention to all the angles where the mirror is darker.An ideal mirror reflects 100% of the light, and so does an ideal white surface. The white surface just spreads out the light.If you light a mirror evenly from all angles, it will be indistinguishable from a white surface. reply wolverine876 6 hours agorootparentThanks. That was my first guess, that it was directional. reply _vertigo 20 hours agorootparentprevNot if you want to use the sun’s energy for power reply stephen_g 20 hours agorootparentYou can do both - having solar panels over a reflective white roof (like the fancy newly discovered passive radiative cooling paints) helps increase PV output by cooling the panel.The solar panels will still absorb and radiate heat back so you won&#x27;t get as much cooling as you would have just with passive radiative cooling paint, but it&#x27;d be better than just solar on a regular roof in both ways (solar output and thermally). reply amelius 20 hours agorootparentprevThermal radiation is just EM waves, which you can reflect.So just put the PV panels on top, and a reflective layer below. reply vbezhenar 14 hours agoparentprevYou can also insulate roof and it&#x27;ll just heat air and radiate energy in cosmos. Heating air is not a problem because it&#x27;s already somewhat high and will only move higher. reply TylerE 10 hours agoparentprevHonestly you&#x27;d get a much more effective reduction in AC needed, for much less money, by putting a decent ceramic tint on all the glass. There are quality tints these days that have minimal effect on visible light while blocking 90%+ of IR. reply neRok 9 hours agorootparentI have roller shutters on my east and west facing windows, and my north facing windows (this is in Australia) get no direct sunlight because they are shaded by my patio. So no direct sunlight is coming into my house through the windows. Still in summer after ~2pm the house heats up. I think overall my house is decently insulated from the sun because in winter my house is extremely cold (what little heat the sun could give doesn&#x27;t get in to my house). Recently in early spring there were days when the outside air temp was hotter than in my house.I think reducing the absorption of the roof and the walls would help, but even then you have still have a house sitting in 34C+ air temps for at least 10 hours per day, so it gets hot. But when I consider my dads house, which has 2m eaves all around, high ceilings, and massive roof space - it still gets hot. His house might feel nicer without a&#x2F;c during early summer, but by mid+late summer it is hot too.Maybe better insulated doors+windows would help? My house is double brick walls. Maybe the \"outer layer\" needs to be able to get hot, and then the \"inner layer\" insulated from the outer as much as possible. That&#x27;s a lot of change though. Instead I just run the a&#x2F;c all day \"for free\" off my solar panels. reply raverbashing 20 hours agoparentprevThere&#x27;s one other minor factor that helps even if the solar panel did nothing:By making the sun hit at a layer above the ceiling (and assuming you have proper air circulation below), your attic area will heat less, hence your house will get less hot.(This is similar to the effect you get by staying under a tree shadow)As per the article, yes, if everybody had air conditioners city wide that would increase the city temperature. But that would require everyone to blast it at the same time reply 7e 17 hours agoparentprevWhat is the effect of this approach in winter? The opposite? Losing heat from the sun that would otherwise help heat the building? reply hinkley 12 hours agorootparentYou&#x27;ve heard of blackbody radiation?Black is hotter in the day and colder at night. In the desert you want light colors, which do the opposite. reply zdragnar 13 hours agorootparentprevDepends on how much snow you get. reply ck2 6 hours agoparentprevDo Solar Panels themselves not get glowing hot from hours of direct sunlight?Do they behave like heat pumps in some fashion where that energy is converted?Oh I see now you say 20% so okay, some but definitely not even half.Still, we&#x27;re going to need every bit of help and I guess that 20% might be 30 or even 40% decades down the road. reply chiefalchemist 14 hours agoparentprevTrees also \"capture\" heat. Whether urban or suburban, we&#x27;d be wise to plant more anywhere we can. reply slt2021 14 hours agorootparentjust wanted to add illustration https:&#x2F;&#x2F;creativelyunited.org&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;02&#x2F;temp... reply mlindner 8 hours agoparentprev> A typical solar panel absorbs ~20% of the sun&#x27;s energy blasted on to a city rooftop. If that&#x27;s used to power air conditioning it&#x27;s doubly effective. You&#x27;re reducing the heat urban heat island effect from the sun&#x27;s energy, and you&#x27;re also not adding additional heat from external power sources in to the city.You’re not reducing energy here. If you gather and then release the energy again (make it do work) it’s simply being re-released. reply guerrilla 20 hours agoparentprevWhat % do trees and other plants absorb? reply reportingsjr 19 hours agorootparentBelow 10%. The most efficient plants are food crops we&#x27;ve genetically modified. I believe corn absorbs around 10%.However, plants also reflect a lot of energy, unlike black&#x2F;asphalt roofs that most people in the US install. reply ars 15 hours agorootparentPlants also evaporate water from the extra light energy, which further cools things. reply wolverine876 9 hours agorootparentprevBut they reflect green energy. reply guerrilla 19 hours agorootparentprevWhen you say efficient it makes me suspicious. Just because a plant doesn&#x27;t absorb the energy for conversion doesn&#x27;t mean it doesn&#x27;t absorb it as heat. Remember, they&#x27;re quite connected to the ground so they could be good heat dissipation (I have no idea, just speculating.) reply tonfa 18 hours agorootparentOne thing trees&#x2F;plant help with (instead of concrete&#x2F;asphalt in cities) is with the added impact of evapotranspiration (besides providing shade). replyArn_Thor 19 hours agoprevBy coincidence I was walking around Paris today in 30+ degree heat. It was only really bearable in the shade, which the city has a lot of thanks to a good amount of trees lining the sidewalks. It was quite pleasant until we passed a convenience store and the heat and humidity of that part of the street immediately rose to oppressive levels. This was because an air conditioner for the store was venting into the street.The effect is stark and incontrovertible. There is the heat being removed plus some heat from the compressor and fan. Everyone in public and private spaces will be better off if we reduce AC usage as much as possible in favor of other solutions reply mikhailfranco 18 hours agoparentIt&#x27;s not (just) the a&#x2F;c in the store, it also has huge refrigeration units.In Asia, 7-Eleven is famous for its chilled air, but also has the walls covered with refrigerators for cool drinks, and there may be freezers for meat, seafood and ice cream. reply phendrenad2 52 minutes agoparentprevIn Paris small shops like that typically don&#x27;t have a vent on the roof, so they need to vent heat to the street at pedestrian level. Easily solved, if people cared. reply 6502nerdface 15 hours agoparentprevIn Las Vegas they solve this by blowing cold air onto the sidewalk through an always-open door, thereby cooling passersby, and perhaps enticing a few to enter for a game of slots. reply alistairSH 15 hours agorootparentThat doesn’t really solve the problem. They’re just dumping the waste heat on the back of the building where tourists aren’t walking. And producing more of that waste heat because they’re trying to condition a leakier building. reply mertd 14 hours agorootparent99% sure the parent post is sarcastic reply wavemode 13 hours agorootparentNo, I&#x27;ve personally witnessed this practice. Wide open doors pouring out cold air on a sweltering day really gets people to stop and shop. reply tnel77 10 hours agorootparentThey meant that the person acting like that was the solution was the sarcastic part. Everyone is in agreement that that’s what they do in Vegas. replybaud147258 13 hours agoparentprevLiving near Paris, it annoys me whenever I look through my window and see the exit pipes of mobile AC units (like this one https:&#x2F;&#x2F;www.emoqui.fr&#x2F;wp-content&#x2F;uploads&#x2F;2019&#x2F;06&#x2F;climatiseur...) running through the open windows of the opposite flat. reply SirMaster 12 hours agorootparentIt annoys me whenever I see a single hose AC unit period.It just makes no sense to me.First, you are now pumping air from inside the building to outside. You aren&#x27;t creating a vacuum inside, so all that means is somewhere else in the building the air is being replaced from the only place it can... from outside...Second, the air you are pumping outside contains some of the air from the inside space that you just spent electricity cooling...I use a mobile AC unit like this because it&#x27;s really the only type of unit that will work in my apartment, but I use a dual hose unit. The unit has 2 air loops. Air from the room is drawn in from the back of the unit, heat is absorbed by the heatsink, and then cool air is blown out the front of the unit into the room.Then to dissipate the absorbed heat as well as the heat from the electricity being consumed, air from outside is sucked in through 1 hose, runs through the other heatsink, and then is expelled back outside again from the other hose.It just makes so much more sense, and if you can stick 1 hose in your window, it&#x27;s really not that hard to stick 2. reply TylerE 10 hours agorootparentYou want air changeover. Low changes&#x2F;hr leads to high indoor co2 and is just in general bad for you.\"ASHRAE empirical research determined that \"acceptability\" was a function of outdoor (fresh air) ventilation rate and used carbon dioxide as an accurate measurement of occupant presence and activity. Building odors and contaminants would be suitably controlled by this dilution methodology. ASHRAE codified a level of 1,000 ppm of carbon dioxide and specified the use of widely available sense-and-control equipment to assure compliance. The 1989 issue of ASHRAE 62.1-1989 published the whys and wherefores and overrode the 1981 requirements that were aimed at a ventilation level of 5,000 ppm of carbon dioxide (the OSHA workplace limit), federally set to minimize HVAC system energy consumption. This apparently ended the SBS epidemic.\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sick_building_syndrome reply tormeh 10 hours agorootparentprevUnfortunately dual-hose ACs are not widely available. I just couldn’t find any when I was in the market. It’s single-hose only in my experience. Why this is I don’t understand. Had to buy one and try it to finally conclude that I was sane and society was crazy. reply kiririn 9 hours agorootparentprevIf the outside temperature is lower than inside then single hose is at least as good, as long as you open a window somewhere else so outside air rather than some other apartment’s air is sucked inSingle hose portables are bad in countries where air con is practically essential, but are fine or even desirable for countries where only a handful of % of people have AC - the purchases will be for use cases like attics and top floor apartments where inside can be easily hotter than outside reply londons_explore 11 hours agorootparentprevWorthwhile noting that most single hose AC units can usually be converted into double-hose with some cardboard, hose, and a lot of duct tape.It&#x27;s worth doing too - you&#x27;ll normally get almost the double the cooling effect from a double hose unit of the same wattage as a single hose one, just due to the fact you aren&#x27;t wasting coolness out of the window.If you do this, note that it&#x27;s important to use extra large and short (insulated) hoses, simply because the blower fans in your unit aren&#x27;t designed for so many yards of hose. reply midasz 2 hours agorootparentprevSome people aren&#x27;t allowed (rental) or cannot afford built-in AC units. I&#x27;ve got a mobile one in my attic where I WFH because otherwise it gets to 30c+ and that&#x27;s just unbearable. reply jefftk 12 hours agorootparentprevWhy does this annoy you? reply londons_explore 10 hours agorootparentI can see why seeing someone else making poor choices wasting their own money, making their quality of life worse, and destroying our shared environment, could be upsetting.In a way it&#x27;s worse than seeing strip mining, or those people who fish with dynamite, or people who litter. At least all those people are benefiting from their environmental destruction. reply emtel 19 hours agoprevAll electricity used in a city ends up as waste heat - AC is no different. If AC is using (as claimed in the article) 10% of a city&#x27;s electricity, then it is responsible for 10% of the waste heat in that city.There could be a short term spike as the AC rejects interior heat from buildings to the outside, but that will be balanced out later as outside heat is absorbed by the cooler buildings, or as cool air leaks to the outside. reply hinkley 12 hours agoparentHeat pumps don&#x27;t work that way. If it&#x27;s using 10% of the electricity it could be 25-35% of the waste heat in the city. reply contravariant 12 hours agorootparentHeat that is moved from a dwelling onto the street shouldn&#x27;t really count as &#x27;waste&#x27; heat. reply hinkley 12 hours agorootparentIf you&#x27;re talking about the heat island effect? The hotter it is outside compared to the desired inside temperature, the less efficient heat pumps get. Also the hotter you make it outside the harder it is for your neighbors to eschew AC in the first place. In a part of town where some critical mass of people have AC, the remainder will be forced to flip. And when that happens, there goes your 10% of all power is used for air conditioning. reply pjerem 19 hours agoparentprevThe issue IS the short term span. Nobody is complaining about ACs making cities hotter in winter. The issues comes from the fact that AC rejects heat from buildings when it’s already hot outside. It renders the city unbreathable in summer. reply _3u10 9 hours agorootparentSo summer is caused by AC rather than AC being turned on in summer? reply emtel 17 hours agorootparentprevTime of year is not the issue. As soon as the system is in equilibrium, the contribution of AC is just the waste heat of the energy consumed. This is just thermodynamics &#x2F; conservation of energy reply adammarples 13 hours agoparentprevThis sounds wrong, lots of electricity does useful work that doesn&#x27;t turn into heat (moving an electric vehicle, making plastic items) or escapes as other waste (light, sound, etc) reply dgacmu 12 hours agorootparentIn the case of the car: when you accelerate, it turns most of that electric energy into kinetic energy (and turns some of it into heat). As you cruise along at a constant velocity, it&#x27;s turning most of that electricity into heat: It&#x27;s overcoming air and road friction, aka, rubbing against things and producing heat. Etc.Waste light and sound get absorbed by surfaces, thus, turned into heat (unless the waste light is in the right IR band to pass out through the atmosphere). reply rcme 7 hours agorootparentWhat about flipping bits in a processor? Current processors do produce waste heat, but I don&#x27;t think all of the energy in a processor gets converted to heat and it&#x27;s not a requirement for computation that heat be generated, e.g. if we had superconducting processors. reply wardedVibe 7 hours agorootparentActually, it is a physical requirement that erasing information generates waste heat. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Landauer%27s_principleWe&#x27;re still pretty far from that limit, but unless your plan is to never erase bits, you&#x27;re going to waste energy. reply rcme 6 hours agorootparent> On the other hand, recent advances in non-equilibrium statistical physics have established that there is no a priori relationship between logical and thermodynamic reversibility.[19] It is possible that a physical process is logically reversible but thermodynamically irreversible. It is also possible that a physical process is logically irreversible but thermodynamically reversible. At best, the benefits of implementing a computation with a logically reversible system are nuanced.[20] reply BytesAndGears 12 hours agorootparentprevThose are actually all converted to heat eventually, just with more steps.Moving an electric vehicle causes motion, but that motion is absorbed by the air and ground via friction with both, aka heat.Light is just energy in a photon — when it hits a surface that absorbs it, it becomes heat. And it can be quite a lot actually! If you put your hand in front of a really bright flashlight, you’ll notice a warm feeling. If you turn off the flashlight, it goes away immediately, proving that is the light itself causing the heat.Approximately all of the energy we use as electricity is just changing something into heat with some useful work in between reply SirMaster 12 hours agorootparentprevSound and light are heat. Heat is movement of atmos. When the sound or light physically hit a surface, they cause the surface to heat up a bit.It&#x27;s all heat in the end. reply hinkley 12 hours agorootparentprevMoving an electric vehicle turns into heat. Because routes are cyclical all of the potential energy turns into heat in the end. You buy a book case and haul it to the top of a hill, eventually that book case is going to the dump, which will be downhill.Manufacturing products via endothermic processes does not turn all of the energy into heat, but then again exothermic processes can exceed the energy used. reply _3u10 6 hours agorootparentprevThink of heat as like nature&#x27;s income tax, every energy transaction you do is subject to a heat tax. Eventually almost all energy is converted into heat. Even the sun converts every chemical into its lowest energy state and releases all that energy in the atoms as heat. The primary thing the universe currently does is turn matter into heat, and tries to distribute that heat evenly.Eventually most of the energy for earth either becomes heat in the earth, gets radiated into space, or slows the earths rotation around the sun, or spin. Of all of these things the dominant two are heat radiating into space (this is by far the largest), and heating the earth, with a few things like the tides slowing the rotation of the earth.A little bit of it gets stored as chemical energy through plants and animals, but eventually those get burned either through fire, or chemical decomposition.To give you an idea of how much heat escapes, if the sun stopped, and we used our nuclear arsenal to replace it, we&#x27;d have about 30 minutes of sunlight.The idea that AC causes heat in cities to any real extent is laughable, if AC was capable of changing the temperature of the earth to any meaningful degree we&#x27;d just water cool the heat exchanger and solve global warming by dumping the heat into the ocean. reply kraig911 19 hours agoprevA lot of things are making everything including cities hotter. Here in Texas it was 110 at my house yesterday in September. I live way way way outside of a large city. I personally think concrete&#x2F;asphalt absorbs and retains a lot of heat keeping things hotter. If we could just reflect more back I think it&#x27;d help much more. I have solar on my house and it practically pays for my AC Bill. reply stephen_g 19 hours agoparentConcrete and asphalt definitely do absorb huge amounts of heat - it’s well studied and called the urban heat island effect. reply xeromal 7 hours agorootparentI had to leave vegas at 4am this summer. The city was 72 or so degrees but as soon as I was out maybe 5-10 minutes of driving, it was 50-60. Unbelievable. reply uoaei 10 hours agorootparentprevHotter air results from the hot concrete. Then the air has more capacity for holding water instead of precipitating it out as clouds or rain. This increases the likelihood of 100%RH conditions, in direct sunlight, on top of a huge thermal mass heated to way above body temps, making heat waves deadlier because evaporative cooling becomes moot at that humidity and you&#x27;re essentially in desert conditions surrounded by hot rocks. reply zo1 15 hours agorootparentprevDo we know how much of that is causing global warming? reply stephen_g 6 hours agorootparentGood link posted by s0rce in another reply, the authors&#x27; research seems to indicate the global effect is quite small, which tracks with what we might expect - it&#x27;s a really big problem localised in cities because so much of the area around us is paved, but on a global scale the surface area of paved urban areas is not huge as a percentage of the surface of the earth. reply s0rce 14 hours agorootparentprevhttps:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41467-022-31558-z reply Solvency 13 hours agorootparentprevYeah. Read a book.https:&#x2F;&#x2F;www.amazon.com&#x2F;Kiss-Ground-Reverse-Climate-Ultimatel... reply SavageBeast 19 hours agoparentprevGreetings Fellow Texan - I live in the downtown Austin area and I can second your conjecture that concrete and asphalt absorb heat.Here is a downtown weather station: https:&#x2F;&#x2F;www.wunderground.com&#x2F;weather&#x2F;us&#x2F;tx&#x2F;austin&#x2F;KTXAUSTI18...This site allows you to check various weather stations and see temps as recorded at the location.You can compare your location to others less or more urban and see this while its happening. Next time you&#x27;re awake at 3AM with nothing to do check it out! Compare downtown Austin to the suburban area of your choice. I saw a 2-3 degree difference pretty regularly last I looked. reply Aeolun 11 hours agoprevKinda weird. Of course air conditioning makes cities hotter, but the point is kinda to cool down the insides of the house, not the outsides. Small enclosed areas are a lot easier to cool.Heating up the 40 square kilometers of city outside by 2.4 degrees reduces 1 sqkm of inside temperature from a sweltering 30 to 23 degrees (note, made up numbers). reply gandalfian 1 hour agoprevI wonder more about heating than cooling. Luddite paranoia perhaps but hot air rises up into space and away. Cold air sinks, where does it go? Outside air is a big heat sink but if entire urban areasn start pumping out MW of cold air in the future will the bottom of hills turn into ice rinks? reply grey-area 21 hours agoprevFor the curious, the answer is yes, by 2.4 degrees C. reply alexfromapex 7 hours agoprevYes, it’s very simple and undeniable. Instead of AC systems dumping heat into the air outside, they should be dumping it underground or to a hot water heater or something. reply arnaudsm 20 hours agoprevGreat example that systemic problems require systemic solutions.AC is an individual solution to global warming, and actually making things worse. And deincentivizes us from fixing the actual problem. reply megaman821 14 hours agoparentWell if AC is your cutoff line for the amount of energy use and carbon intensity making things worse, I have really bad news for everyone using heating. reply whynotmaybe 19 hours agoparentprevLike this?https:&#x2F;&#x2F;www.theonion.com&#x2F;addressing-climate-crisis-bush-call... reply baobabKoodaa 10 hours agoparentprevMaking things worse? What? AC saves lives. reply p0w3n3d 5 hours agoprevJust plant trees in the cities. Go and Chech what is the difference of temperature in cities with trees and without. Of course sometimes it&#x27;s too late: in my hometown they cut away 40 huge trees and made a market square, \"because that&#x27;s what they do in Netherlands\" (exact explanation of local ministry), and now you cannot pass the market square in a hot day. Installation of some sort of irrigators doesn&#x27;t make difference and is not hygienic (see Legionella). They took away trees and grass and made everything concrete.Meanwhile my parent&#x27;s home is much cooler, no AC needed because they have trees between the blocks reply ajb 19 hours agoprevI&#x27;ve been looking at getting shutters on my windows; They&#x27;re not common in the UK but are common in more southern European countries. Unfortunately UK windows are designed without the expectation that shutters might be installed. Also it seems to require planning permission to install them on street facing windows too, as they are not currently one of the exceptions. But installing air conditioning (and heat pumps) does have an exception. This needs to be fixed. reply tonfa 20 hours agoprev> Air conditioners [...] leak harmful planet-warming gases into the atmosphere.Anyone has a reference about that? Last time I tried to research it, it seems like it was mostly fixed at least in Europe with the most harmful gases being banned for new sales. reply housemusicfan 19 hours agoparentSounds like FUD. A properly installed AC leaks nothing because it is by design a sealed system. I wonder if they feel the same about refrigerators.These same smooth-brains are probably extolling the benefits of heat pump water heaters not realizing they have the equivalent of an AC attached to them. reply aa_is_op 19 hours agorootparentThey do leak. That&#x27;s why you have to replenish their gas reserves every 2-3-4 years (based on brand). Had to do mine two years ago. reply housemusicfan 19 hours agorootparentThis is false. They&#x27;re not supposed to leak. \"Replenish gas reserves\" is not a regularly scheduled maintenance item. In fact it&#x27;s illegal for a technician to add refrigerant more than once without identifying and repairing the source of the leak. Unless you did something stupid like tried to install a split system yourself.If your unit leaks refrigerant it needs to be repaired. This is not normal. reply Finnucane 19 hours agorootparent“Not supposed to” is a very weak condition in manufacturing these days. reply housemusicfan 19 hours agorootparentICE cars aren&#x27;t supposed to explode nor are EVs supposed to burst into flames via inextinguishable battery fires.But sometimes they do.We don&#x27;t use this outlier data to refer to them as conflagrations-on-wheels and assert it&#x27;s a normal function of the device just to strengthen our biased case. reply Finnucane 18 hours agorootparentSure but battery fires are still a problem that needs to be fixed and not ignored. Also, even though it doesn’t happen often, when it does the results can be catastrophic. So it is a reasonable concern. reply Dylan16807 10 hours agorootparentYou have to deal with battery fires but they&#x27;re not a climate issue. replystephen_g 19 hours agorootparentprevWhat? I’ve never heard of a system that (with proper installation etc.) needs to be replenished anything like that often! Where are these brands you’re talking about from?!Car air conditioners maybe, but it seems unbelievable for fixed systems of any reasonable quality… reply callalex 14 hours agorootparentprevYou are being fleeced by some shady repair business. Can you point me to the user manual of your machine where it calls for such frequent recharging? reply userbinator 12 hours agorootparentprevFind the leak and fix it. They&#x27;re not supposed to leak.AC should be as sealed as a fridge, and you don&#x27;t hear people having to recharge their fridges every few years.Even ignoring the environmental concerns of refrigerant leaks, it&#x27;s wasteful of your money too. reply SirMaster 12 hours agorootparentprevI&#x27;ve been using my window AC unit for 10 years now. Have not had to replenish any gas...They definitely aren&#x27;t supposed to leak. reply WheatMillington 14 hours agorootparentprevIf you&#x27;re replacing your gas every 2-4 years, something is terribly wrong. reply moritz 19 hours agoparentprevThe phase-out under the Montreal protocol is an ongoing process, but we are far from there. The HFCs that replaced (H)CFCs in the 90s quickly turned out to be fastes growing category of short-term climate pollutants in many countries in the world [1]. The Kigali Amendment to the Montreal protocol from 2019 now covers HFCs too, and the EU limits them since 2015, but these things take time…R-410A, commonly used in Europe, has a GWP of 2088. Worldwide, R-22 still is the most common refrigerant. That’s a HCFC, so stratospheric ozone depleting, and with a GWP of 1960.[1]: https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;science.1216414 reply stephen_g 19 hours agorootparentR-410A is being phased out in major markets including the US too over the next few years (R-22 has been banned for new equipment most places for more than a decade, and is banned entirely in the EU since 2015 for recharging existing units). My Mitsubishi air to air heat pumps (one from 2015 and one from 2018) were already R-32 (GWP 675, Ozone depletion potential 0) and my air to water (Sanden, installed 2022) is R-744 (which is CO2 - obviously GWP 1) reply tonfa 18 hours agorootparentThanks both for the pointers (it&#x27;s easier to google if you know what to search for).https:&#x2F;&#x2F;climate.ec.europa.eu&#x2F;eu-action&#x2F;fluorinated-greenhous... is the list of alternatives with corresponding GWP for EU. reply moritz 18 hours agorootparentprevIn so-called developing countries, the full ban of R-22 will be 2030, which is a full ban with an asterisk to 2040.Not saying the phase-out isn’t happening, but there are, and there will be for quite some time, millions of units leaking climate pollutants (which was the question). reply nraynaud 9 hours agoparentprevI installed a brand new unit last month, I’m now the proud owner of 900kg equivalent CO2 on my roof. It’s 20 times less than before, but not nothing. reply crazygringo 14 hours agoprevQuestion: is there a huge difference based on whether units are placed in windows vs. on roofs?Obviously for a window unit or split where the compressor is on the building&#x27;s wall -- those are going to heat the air in the street. Ground level units most of all.But a lot of buildings place all their compressors on the roofs. And since hot air rises, does that produce any noticeable effect at ground level? reply rapnie 21 hours agoprev14 trackers after \"reject all\" is also making me hotter. reply merth 20 hours agoparentinstall \"ublock origin\" and enable \"annoyances\" from settings. reply SoftTalker 15 hours agorootparentDidn&#x27;t know about \"Annoyances\" thanks -- giving that a try now (these are under the \"Filter lists\" tab in settings, for anyone looking for them). reply GLjEI4YbnGD27LB 3 hours agorootparentprevThanks, also didn&#x27;t know about annoyances! reply MaKey 13 hours agorootparentprevThanks for the hint! reply guerrilla 21 hours agoprevThat would seem inevitable, so the only real question was how much (+2C.) So, how much cooler does the city with many heat pumps get in the winter then? reply Ozzie_osman 20 hours agoparentEffect must be less. For AC, you&#x27;re transferring indoor heat outdoor AND generating excess heat from running the AC itself. For heating, the excess heat generation presumably works counter to the heat transfer. reply stephen_g 20 hours agoparentprevThe opposite effect I expect should be less for heating, since the heat is constantly leaking out of buildings at some rate back into the environment (insulation, double glazing etc. reduces this but all the added heat eventually leaks out), and additional energy is being put in which turns into heat too (e.g. COP 4 means 1 unit heat from electricity and 3 units shifted from the outside environment).So whether there is temporary localised cooling depends on the quality of the insulation but overall and over time there is no cooling due to the additional input. reply guerrilla 20 hours agorootparentThe heat is constantly leaking into the buildings too. I&#x27;d be more concerned with differences in efficiency with direction that you mention at the end. In any case, the net result is still negative, so how much negative is still the question that stands. reply raverbashing 20 hours agoparentprevGood question, some aspects make it different:- you&#x27;re always getting some \"free warmth\" through the sun, so on average you need to pump less energy to heat than to cool (for same temp difference)- Hot air rises, cold air sinks, not sure how that works in a city environment, probably concentrates the cold more reply superq 19 hours agorootparentTemp differentials are still differentials, though, so sun warmth would be already accounted for. reply raverbashing 19 hours agorootparentKind of, because your house will always be warmer than the outside at thermal equilibrium, both in summer and winter (with heating&#x2F;ac off)So, yes if you consider the differential in-house current-target temperature yes, but difference of outside&#x2F;inside temperature no. reply SavageBeast 19 hours agoprevSo lets look at how the refrigeration cycle works here and make some conjectures. If I understand correctly, this kind of system removes heat from one side and moves that heat out the other side. An AC unit with a structure as a barrier is a machine that removes heat from the confined structure and vents it to the outside. So, with enough AC units removing heat from sealed structures and outputting it into the atmosphere, seems plausible that getting enough of them together would behave like a kind of heater.Now, how did the air inside these structures get warmed up in the first place? Under normal conditions, is the air inside the structures WARMER than the ambient air? Does the structure itself somehow more efficiently harness the suns energy to warm the structure more than the ambient outside air?If the same energy source is heating the ambient air and the air inside the structures - and it is - its the sun here, don&#x27;t we have a constant amount of energy warming the area? Some of that energy warms outside, some of it warms inside, but the amount is constant.So how could a device that removes heat from structures to vent it outside be responsible for a warming of the outside air? Unless the AC itself added some extra heat energy in the process OR the structures somehow more efficiently turned solar energy into heat, how could moving heat around cause a temperature increase?For example - on a warm day in a little European village, everyone lights a gigantic fire and adds non-solar heat to their homes. The devices that remove the heat would then be adding new energy to constant solar energy heating the town. Ambient temperatures would likely rise. But did the AC cause the temperature increase? Didn&#x27;t the AC unit just move heat from structure to ambient? The AC added no heat in this case. reply coda_ 18 hours agoparentAs someone said in a another comment:\"There is the heat being removed plus some heat from the compressor and fan.\" reply anticrymactic 18 hours agoparentprev> Now, how did the air inside these structures get warmed up in the first place? Under normal conditions, is the air inside the structures WARMER than the ambient air?Greenhouse effect + no wind.The infrared emitted by heated objects are reflected by the glass, heating the room even more reply labster 15 hours agoparentprevJust look at inputs and outputs. Electrical energy goes in; heat, noise (heat), and moving air (heat) come out. Nearly 100% of the energy going into an air conditioner produces heat. reply AlDante2 7 hours agoprevBasic physics says yes. reply lucb1e 14 hours agoprevWould it help to have an IR-reflective dish below hot AC units, to reflect more of the heat they put out back into space? reply contravariant 12 hours agoparentMost of the heat is probably spreading by convecting hot air, not as thermal radiation. A good chimney seems like it should be more effective, though it fundamentally still can&#x27;t stop the fact that you&#x27;re converting quite a bit of electricity into heat. reply lucb1e 11 hours agorootparentThere will be some loss, but the heat trapped in houses wasn&#x27;t going anywhere anyway. By putting it outside the home, there is a more direct pathway for it to be leaving the city. Though I wouldn&#x27;t know how to quantify this by any sort of approximation, I assume it&#x27;s less than the heat added from inefficiencies yeah reply soultrees 10 hours agorootparentI wonder if it means that during the daytime, the cities are hotter but at night, the average temperature is cooler than before? Since all the heat trapped indoors has been pushed out into the world. reply agumonkey 19 hours agoprevWhere&#x27;s research on passive thermal management (materials acting as heat phasors kinda) ? reply pazimzadeh 6 hours agoparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Windcatcher reply aaomidi 14 hours agoprevCity wide geothermal cooling pls thanksYou can use huge water mains to transfer the heat reply Etrnl_President 13 hours agoprevCities are made of houses. Houses are made of rooms. If rooms are hot, aren&#x27;t cities hot? If room heat is pumped outside, did the city temperature really change? What is the heat-island effect? reply kkfx 14 hours agoprevHonestly? That&#x27;s just bullshit to try pushing people against A&#x2F;C.Cities are hotter than outside because:- they absorb more heat :: concrete, asphalt absorb much more than grass or trees and disperse far more slowly. Just go walking in a bush, measure temperature at 1.5 m from soil, do the same in grass covered area and the same over a road. You&#x27;ll see and feel the difference;- in cities there are MANY ICE vehicles whose engine produce much heat, much more than any electrical motor;- in cities there is less air circulation than in the open nature due to the high and heat-absorbing buildings;- in many cities glass coated skyscraper works like any other glass keeping much of Sun IR radiation inside.These are the reason why cities are hotter. Another proof? They are ALSO hotter in winter, not just in summer. In winter you can count extra heat from badly insulated heated buildings, little cold pushed outside by the so far limited percentage of people heating with some heat pumps that have air on their exterior side, but look at the numbers and you&#x27;ll see they are more hotter than mere heats spread outside by badly insulated heated buildings.People should learn two things:- cities WAS a necessity to evolve in the past, but with the &#x27;80 logistic revolution they lost one of their last reasons to exists, manufacturing became cheaper to do far from customers, so far from cities. With the remote work the last remaining reasons vanish as well. As a result dense cities and high rise buildings have NO REASONS TO EXISTS anymore. Try to keep them and sell them as green, good for the future etc is just a push toward intensive human farming to keep people dependent on service they don&#x27;t own, living to operate them so they can pay them. Since in the modern era cities can&#x27;t be sustained the push needs to makes people accept bad living condition as a new normal;- we need to switch from a high density model, too dense for today state of tech and society, climate etc to a new less dense one, that&#x27;s hard and that&#x27;s means MANY will be simply \"overflowing humans\" to be put somewhere, since no one like that role, if told in such a crude way, some try to advertise such role with various \"bells and whistles\" but that&#x27;s simply BULLSHIT.If you try reasoning about the above you&#x27;ll understand a thing: such move to put aside a significant percentage of humans can&#x27;t really work, never worked in history. It does work if the set aside cohort is very limited, the poorest, very isolated and very dependent, but at modern scale can&#x27;t work. reply crooked-v 13 hours agoparent> we need to switch from a high density model, too dense for today state of tech and society, climate etcThe populations of dense cities use fewer resources than the same population spread out in low-density settlements, especially when those cities are laid out to be properly walkable. It&#x27;s just basic economy of scale.> in cities there are MANY ICE vehicles whose engine produce much heat, much more than any electrical motor;In cities, not having a vehicle is an option. Outside of them, it&#x27;s basically required in most places. reply mschuster91 11 hours agorootparent> It&#x27;s just basic economy of scale.Economies of scale aren&#x27;t a goal on their own. Scaling something up will always have side effects... in the case of too dense urban areas, it&#x27;s for example the sheer amount of traffic. For example, a quarter full of high-rises, no way you can get away without expensive high-capacity subterranian trains to handle commuters, and surface traffic is going to be a hot mess even with just shuttling the basic supplies for supermarkets, restaurants and the likes in one direction and waste on the other direction. In contrast, even a standard European mid-sized city can get away with cheap bus and tram lines. And it&#x27;s harder to provide other essentials to meaningful life in a city as well, particularly where children are involved - land is too valuable to leave it as a park, and children can&#x27;t have outdoor places to play either in kindergarten because it&#x27;s too expensive, so you have even more traffic just from parents bringing their kids to kindergarten&#x2F;school&#x2F;playgrounds&#x2F;whatnot.Another effect of urban over-density that&#x27;s often neglected is human health, both physical (we&#x27;ve seen that with COVID, just how fast pathogens can spread in urban areas) and mental. I mean, even here in Munich or Berlin we&#x27;re not at the US levels of mental health and housing issues with people defecating on the sidewalk, but still it&#x27;s noticeable how cities tend to have more anti-social behavior, as poverty and boredom are definitely contagious especially when not backed by the implicit social control that life even in smaller cities brings. reply lmm 11 hours agorootparent> Economies of scale aren&#x27;t a goal on their own. Scaling something up will always have side effects... in the case of too dense urban areas, it&#x27;s for example the sheer amount of traffic. For example, a quarter full of high-rises, no way you can get away without expensive high-capacity subterranian trains to handle commuters, and surface traffic is going to be a hot mess even with just shuttling the basic supplies for supermarkets, restaurants and the likes in one direction and waste on the other direction. In contrast, even a standard European mid-sized city can get away with cheap bus and tram lines.But that high-capacity transit more than pays for itself (just the land value increase alone is more than the cost of building it). Yes there are costs to building densely (obviously to build a skyscraper at all costs more per square metre of floor space than building on the flat), but the end result is that more people can live (and more productively) for less total cost.> Another effect of urban over-density that&#x27;s often neglected is human health, both physical (we&#x27;ve seen that with COVID, just how fast pathogens can spread in urban areas) and mental. I mean, even here in Munich or Berlin we&#x27;re not at the US levels of mental health and housing issues with people defecating on the sidewalk, but still it&#x27;s noticeable how cities tend to have more anti-social behavior, as poverty and boredom are definitely contagious especially when not backed by the implicit social control that life even in smaller cities brings.Do you have any evidence for that? The last results I&#x27;ve seen are that suburban living is significantly worse for mental health than dense urban cores (and I wouldn&#x27;t be surprised if that was true for physical health as well), and frankly that fits with my experiences. reply kkfx 3 hours agorootparent> but the end result is that more people can live (and more productively) for less total cost.Another classic scam: metros are very energy efficient in travel time, when loaded enough. But you need to move at any time of the day, differently by many others needs and desire, as a result OR you make the service run 24&#x2F;7 nearly empty most of the time or you can&#x27;t satisfy personal traveling needs most of the time. Beside that the mere cost of a metro respect of \"glorified electric golf cart\" for a less dense are is ENORMOUS and no, it does not pay up. Not only why keep moving in a city? Most activities there are doable from remote, just cutting such commuting to move only for pleasure and the reaming needs is FAR cheaper.> Do you have any evidence for that?In most of the world life expectancy in cities is LESS than outside by few years, gut microbes are far less in people living in dense area not to count pollution effects. reply lmm 24 minutes agorootparent> Beside that the mere cost of a metro respect of \"glorified electric golf cart\" for a less dense are is ENORMOUS and no, it does not pay up.I think you missed or added some words there, so it&#x27;s not very clear what you were trying to say. The cost&#x2F;benefit of metros stacks up, that&#x27;s why cities build them - not necessarily in terms of value that can be captured by charging fares, but certainly in terms of overall benefit.> Not only why keep moving in a city?Because the agglomeration effect still works; the more people within a 30 minute commute range, the more useful stuff they can do in less time. Again people wouldn&#x27;t pay what it costs to live in a megacity if it wasn&#x27;t worth it.> Most activities there are doable from remote, just cutting such commuting to move only for pleasure and the reaming needs is FAR cheaper.If there&#x27;s less need for commuting then surely by your own argument that makes the case for living in a big city stronger, since there&#x27;ll be less need for underground metros.> In most of the world life expectancy in cities is LESS than outside by few yearsIs that after controlling for wealth?> gut microbes are far less in people living in dense areaIs that good or bad?> not to count pollution effects.Pollution is important though. The more you can walk or cycle, and more generally the lower the per capita energy use, the less pollution and the better for human health. reply msm_ 8 hours agorootparentprev>For example, a quarter full of high-rises, no way you can get away without expensive high-capacity subterranian trains to handle commutersAren&#x27;t trains much, much more efficient than individual transport? Compare the average urban train with everyone driving their own car and it starts to look pretty good. reply mschuster91 3 hours agorootparentThey are. The problem is they are vastly more expensive (to the tune of billions of euros) than building on-surface light rail&#x2F;tram due to the cost and difficulty of boring tunnels. reply kkfx 2 hours agorootparentprev> Aren&#x27;t trains much, much more efficient than individual transport?Only if well loaded and running most of the time well loaded. Meaning in practice they can&#x27;t be more efficient than personal transports.OR you make a service 24&#x2F;7&#x2F;365 (untenable, running nearly empty most of the time) or you can&#x27;t satisfy personal moving needs most of the time. Beside that just look at single stations costs compared to people moving in less dense areas in glorified electric golf carts mostly recharged via local p.v.It&#x27;s an ancient scam to sell collective transportation as positive, actually it&#x27;s positive only for the public-funded business owner. reply kkfx 3 hours agorootparentprev> The populations of dense cities use fewer resources than the same population spread out in low-density settlements, especially when those cities are laid out to be properly walkable. It&#x27;s just basic economy of scale.No, that&#x27;s just marketing try to convince people of that...> In cities, not having a vehicle is an option. Outside of them, it&#x27;s basically required in most places.Again that&#x27;s marketingDid you try to think hoe many resources are needed just to build high rise buildings compared to an equivalent set of single family homes? Hint: their own structure need to be supported, just that and foundations impose MUCH MORE resources than light homes. Similarly for any implant inside, including elevators.Sewage network? Metros and so on?A city if you try to count raw material use MUCH more than an equivalent spread area.Not only: single family homes can evolve, they can be wood based and rebuild every let&#x27;s say 50 years. Meaning they remain aligned to contemporary needs and tech, while rebuild a high rise building is a nightmare.If you have modern homes with EV in most part of inhabited world, WFH for eligible jobs, not suburb USA style but mixed spread are where your dentist is just a small building few km away, there is a small supermarket few km away and so on you can have small-battery EV mostly recharge via domestic p.v. in cities you can walk, sure, unfortunately groceries are not made there, they came from far away, as far as more dense is the area because anybody eat, but in dense area there is no local food production. As a result you consume less, comfortably ignoring the logistic behind anything you use locally.Now enlarge yourself talking about soil sealing who kill humus, water cycle alteration due to the big impact of such large and concentrated usage and discharge and so on.If you REALLY try to dimension a city you&#x27;ll easy see that anything you believe is false, marketing pushed because dense cities means dependency on services, witch means big business for very few on the shoulders of many. Try just to imaging ready-to-eat food delivery in a spread are: there is no chance Uber Eat, Just Eat and so one model keep up. People have kitchen, stockpile of food and time to do whatever they like, far less waste, far less packaging. Oh BTW this was an ancient known scam in Europe: in the past schools have internal kitchen, then they was told to externalize to make anything more efficient. As a result food quality have dropped, costs ans waste and packaging use skyrocketed. reply jimnotgym 19 hours agoprevTLDR; YES reply thatwasunusual 18 hours agoprevIsn&#x27;t this well known, and not limited to AC, based on the Urban heat island effect?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Urban_heat_island reply lowbloodsugar 15 hours agoprev [–] The asphalt and concrete is doing far more than the AC. But the city would have to pay for that and the poor need roads, so not as useful for lefties to incite riots against the “rich”. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A recent study suggests that air conditioning units amplify city temperatures, with waste heat during heatwaves significantly increasing outdoor temperatures by over 2 degrees Celsius.",
      "Air conditioners are under debate due to their contribution to the heatwaves issue, as they emit hot air outside and consume substantial electricity, releasing planet-warming gases.",
      "As global air conditioner usage is predicted to triple by 2050, the study recommends alternatives like cultivating green spaces, enhancing building insulation, and educating people on maintaining cool during heatwaves."
    ],
    "commentSummary": [
      "The conversation touches on a variety of topics including the influence of air conditioning, the advantages of trees and solar panels in managing temperature, and the effectiveness of swamp coolers and reflective rooftops.",
      "Emphasized is the necessity for alternative solutions, taking into account multiple factors, to attain effective temperature control and environmental sustainability in urban contexts.",
      "Discussions range from the benefits and costs of solar installations, the impact of such technologies on urban heat islands, to the challenges of urban overpopulation, and the environmental implications of food production and transportation in cities."
    ],
    "points": 145,
    "commentCount": 250,
    "retryCount": 0,
    "time": 1694350284
  },
  {
    "id": 37462125,
    "title": "RestGPT",
    "originLink": "https://github.com/Yifan-Song793/RestGPT",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up Yifan-Song793 / RestGPT Public Notifications Fork 13 Star 357 Code Issues Pull requests Actions Projects Security Insights Yifan-Song793/RestGPT main 1 branch 0 tags Go to file Code Latest commit Yifan-Song793 fix typos 25535bf Git stats 11 commits Files Type Name Latest commit message Commit time datasets first commit imgs fix bugs in readme model first commit specs first commit utils first commit README.md fix typos config.yaml first commit init_spotify.py first commit run.py add a quick start script run_spotify.py first commit run_tmdb.py first commit README.md RestGPT This is the code for the paper RestGPT: Connecting Large Language Models with Real-World RESTful APIs. This work aims to construct a large language model based autonomous agent, RestGPT, to control real-world applications, such as movie database and music player. To achieve this, we connect LLMs with RESTful APIs and tackle the practical challenges of planning, API calling, and response parsing. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality test set which consists of two real-world scenarios and human-annotated instructions with gold solution paths. What's New [Next] The demo is under-construction. [2023/8/29] Code for RestGPT is released. [2023/8/28] The second version of our paper is released. [2023/6/13] Our paper is released. RestGPT RestGPT adopts an iterative coarse-to-fine online planning framework and uses an executor to call RESTful APIs. Here is an overview of RestGPT. Modules: Planner: generating natural language sub-task for current step. API selector: mapping the coarse high-level sub-task to finer API calling plan. Executor: executing the API calling plan. Caller: organizing API parameters based on the API plan and API documentation. Parser: generating Python code to parse the API response based on the response schema. Here is an example of using TMDB movie database to search for the number of movies directed by Sofia Coppola. Data We also introduce RestBench to evaluate the performance of RestGPT. RestBench is a high-quality test set consisting of TMDB movie database and Spotify music player scenarios. We collect realistic user instructions with human-annotated gold solution paths. Here are examples of RestBench: TMDB example: Instruction: Who is the director of today's most trending movie? Gold solution path GET /trending/{media_type}/{time_window} GET /movie/{movie_id}/credits Spotify example: Instruction: Make me a playlist containing three songs of Mariah Carey and name it 'Love Mariah'. Gold solution path GET /search GET /me POST /usres/{user_id}/playlists POST /playlists/{playlist_id}/tracks Below is the statistics of the data. We report the number of instructions with different lengths of solution path: Scenario #APIs Len-1 Len-2 Len-3 Len-4 Avg. Len. Total TMDB 54 5 66 27 2 2.3 100 Spotify 40 8 18 22 9 2.6 57 Setup pip install langchain colorama tiktoken spotipy openai create logs folder Get OpenAI key from OpenAI, TMDB key from https://developer.themoviedb.org/docs/getting-started, and Spotify key from https://developer.spotify.com/documentation/web-api Fill in your own key in config.yaml (Optional) Initialize the Spotify Environment WARNING: this will remove all your data from spotify! python init_spotify.py Run The code can be run using the following command: python run.py Then Input the scenario (TMDB/Spotify) and instruction. We also provide two scripts to run RestGPT on RestBench: # TMDB python run_tmdb.py # Spotify, please open Spotify on your device python run_spotify.py run_tmdb.py will sequentially execute all instructions of RestBench-TMDB. Regarding RestBench-Spotify, you should manually modify the query_idx before executing the instructions. Citation If you find this repo useful, please cite us. @misc{song2023restgpt, title={RestGPT: Connecting Large Language Models with Real-World RESTful APIs}, author={Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li}, year={2023}, eprint={2306.06624}, archivePrefix={arXiv}, primaryClass={cs.CL} } About An LLM-based autonomous agent controlling real-world applications via RESTful APIs Resources Readme Activity Stars 357 stars Watchers 9 watching Forks 13 forks Report repository Releases No releases published Packages No packages published Languages Python 100.0% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37462125",
    "commentBody": "RestGPTHacker NewspastloginRestGPT (github.com/yifan-song793) 147 points by omarfarooq 8 hours ago| hidepastfavorite48 comments pplonski86 2 hours agoHow RestGPT differs from ToolLLM or Gorilla?papers:1. ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2307.167892. Gorilla: Large Language Model Connected with Massive APIs https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.15334 reply westurner 36 minutes agoprev\"Gorilla: Large Language Model Connected with Massive APIs\" (2023) https:&#x2F;&#x2F;gorilla.cs.berkeley.edu&#x2F; :> Gorilla enables LLMs to use tools by invoking APIs. Given a natural language query, Gorilla comes up with the semantically- and syntactically- correct API to invoke. With Gorilla, we are the first to demonstrate how to use LLMs to invoke 1,600+ (and growing) API calls accurately while reducing hallucination. We also release APIBench, the largest collection of APIs, curated and easy to be trained on! Join us, as we try to expand the largest API store and teach LLMs how to write them!eval&#x2F;: https:&#x2F;&#x2F;github.com&#x2F;ShishirPatil&#x2F;gorilla&#x2F;tree&#x2F;main&#x2F;eval- \"Gorilla: Large Language Model connected with massive APIs\" (2023-05) https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36073241- \"Gorilla: Large Language Model Connected with APIs\" (2023-06) https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36333290- \"Gorilla-CLI: LLMs for CLI including K8s&#x2F;AWS&#x2F;GCP&#x2F;Azure&#x2F;sed and 1500 APIs (github.com&#x2F;gorilla-llm)\" (2023-06) https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36524078 reply two_in_one 4 hours agoprevThe problem here is where these actions come from. Generic LLM cannot generate correct actions in many (if not most) real life cases. So, it will have to learn, and LLMs aren&#x27;t good at learning. For example: \"I&#x27;m tired, play my favorite\". The action depends on _who_ is saying and on what&#x27;s going on right now. There may be someone sleeping, or watching TV. I&#x27;m afraid that acceptable solution is much more complicated. reply liampulles 21 minutes agoparentI have investigated use of agents for real support agent type work and the rate of failure made it unacceptable for my use case. This is even after giving it very explicit and finely tuned context.I suspect that if engineering of LLM solutions utilizes unseen testing data more, it&#x27;s going to become apparent that it really does not have sufficiently reliable \"cognitive\" ability to do any practical agent type work. reply pplonski86 2 hours agoparentprevI think this can be easily fixed, if LLM can do notes on what&#x27;s going on. If it will have additional context before the prompt:```You are home assistant. Here is information what&#x27;s going on in the house:It&#x27;s 4PM. Bob likes Chopin Fantaisie-Impromptu. Alice likes Mozart Rondo in D. Bob is in the house. Alice will be back from office at 5PM.You get a prompt: I&#x27;m tired, play my favorite```For the above input any LLM will play Chopin. reply troupo 1 hour agorootparentWhere is that input coming from? reply pplonski86 23 minutes agorootparentIt&#x27;s just example, I&#x27;ve manually created it. But I think LLM can do such memory notes for itself and include as context. reply regularfry 58 minutes agoparentprevI&#x27;m genuinely not seeing a problem there that the Planner part of the paper couldn&#x27;t cover. \"Who said that\" and \"what&#x27;s going on right now\" are just API calls. Besides which, if one person says \"play my favourite\" while another person is watching TV, that&#x27;s not the LLM&#x27;s job to unpack.The point is that the ability to call APIs gives them the ability to learn so that the actions that are eventually taken are correct in context. It&#x27;s like a more generic version of https:&#x2F;&#x2F;code-as-policies.github.io&#x2F;. reply pmx 3 hours agoparentprevDO we have to expect _that_ level of understanding from the agent, though? If my wife said that to me, I may have a good chance of queuing up the song she has in mind, but anyone else? No chance. I don&#x27;t expect tools like this to be able to understand cryptic requests and always come to the right answer. I&#x27;m happy if I can request a song or an action, or anything else in the same way i might ask another human who doesn&#x27;t know me intimately. reply swexbe 3 hours agorootparentIf not, how is this more useful than something like Siri? reply og_kalu 3 hours agorootparentNatural language understanding. Siri doesn&#x27;t get context at all. You can twist unstructed data or requests however you like and the LLM will deal with it just fine.\"Play my favorite\" is just a knowledge problem. If GPT fails there, it&#x27;s because it doesn&#x27;t know your favorite, not because it can&#x27;t parse the request or understand what you need it to do.You have to speak certain ways to Siri to get it to do things.Unless specifically hard-coded, Siri will never receive \"damn I&#x27;m finding it hard to read\" as input as decide to turn on the lights. GPT will. reply troupo 2 hours agorootparent\"Siri doesn&#x27;t get context at all.\" and yet immediately \"GPT fails there, it&#x27;s because it doesn&#x27;t know your favorite\"\"Knowing your favorite\" is the context.> Unless specifically hard-coded, Siri will never receive \"damn I&#x27;m finding it hard to read\" as input as decide to turn on the lights. GPT will.Of course it won&#x27;t. You have to very specifically fine tune it to understand what light conditions are, where you are in the house, and what it is you need to turn on. reply regularfry 1 hour agorootparent> You have to very specifically fine tune it to understand what light conditions are, where you are in the house, and what it is you need to turn on.Where you are in the house and what needs to turn on, at least, is an API query job, not a fine-tuning job.As far as whether it can understand the relevance of lighting to the situation, I just asked ChatGPT 3.5 the question &#x27;Acting as an AI home assistant, if you hear me say \"I&#x27;m finding it hard to read\", what actions would you take?&#x27; and &#x27;Adjust the lighting&#x27; was the second option it gave back (after &#x27;ask for clarification&#x27;). I think we&#x27;re there, honestly, we just don&#x27;t have the different parts connected yet. reply troupo 1 hour agorootparent> Where you are in the house and what needs to turn on, at least, is an API query job, not a fine-tuning job.And that API magically comes form where?> I just asked ChatGPT 3.5 the question &#x27;Acting as an AI home assistant, if you hear me say \"I&#x27;m finding it hard to read\", what actions would you take?&#x27;So, basically:- you had to pre-program Chat GPT to act as a home assistant- you had to provide it with specific context and specific phrasing for it- it still failed, asked for clarification, and only then respondedAnd now you have to this song and dance every time you want to coax GPT into doing what you need (and that&#x27;s what RestGPT does). reply selalipop 26 minutes agorootparentWhat you&#x27;re describing as pre-programming is a little misleading if the \"pre-programming\" doesn&#x27;t need to change for each specific request: a real product would provide that \"pre-programming\" for the user.Prompting for task performance is fine as long as you&#x27;re not expecting the end user to have to replicate your prompting. Your goal is to change model activations for a given input, the end user is similarly affected regardless of if you used a prompt or fine-tuned.-This task doesn&#x27;t require fine-tuning though, zero-shot performance is enough:I generated a mock schema from Home Assistant&#x27;s API (https:&#x2F;&#x2F;data.home-assistant.io&#x2F;docs&#x2F;states&#x2F;) and explicitly gave the model the option to ask for clarification, but it has no problem translating non-obvious commands into actions without asking for details:https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;fc5b972f-4641-47a1-9842-2e0d69...Note those objects mirror Home Automation, you could hook that up today without any song and dance. Combine that with RAG and you&#x27;d have something that&#x27;s a lot more useful than Siri and capable of improving performance over time. reply regularfry 45 minutes agorootparentprev> And that API magically comes form where?HomeAssistant, or any number of other providers. Do you think this part is somehow difficult?> you had to pre-program Chat GPT to act as a home assistantThat is what we call \"a prompt\". It is a well-known technique. I am surprised that this should look strange to you.> you had to provide it with specific context and specific phrasing for itThat is what we call \"a prompt\". It is a well-known technique. I am surprised that this should look strange to you.> it still failed, asked for clarification, and only then respondedYou have misunderstood. In its list of actions to take, the first and only response it gave, the first thing it said it would do in context is ask for clarification as to why I was finding it hard to read. That seems entirely reasonable to me. Does it not to you?> And now you have to this song and dance every time you want to coax GPT into doing what you need (and that&#x27;s what RestGPT does).So what? It&#x27;s not something the person sat in the dark ever has to care about. reply troupo 41 minutes agorootparent> That is what we call \"a prompt\". It is a well-known technique. I am surprised that this should look strange to you.> That is what we call \"a prompt\". It is a well-known technique. I am surprised that this should look strange to you.Funny how we&#x27;re in the discussion about context, and you decided to ignore and discard the entire context of the discussion :) reply circuit10 2 hours agorootparentprevThey mean context in the sentence or that or that be inferred from “common sense” and without any specific knowledge, I think reply troupo 1 hour agorootparentI hate Siri as much as anyone, but Chat GPT has no context in the \"common sense\" either.The sibling comment literally says \"I had to provide a long-ish sentence as a context&#x2F;programming instructions before it could do anything\". https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37464563 replyjsemrau 31 minutes agoparentprevThe whole notion of \"memory\" in LLM research solves this problem. reply selalipop 1 hour agoparentprev> So, it will have to learn, and LLMs aren&#x27;t good at learningLLMs are bad at human-like learning, but their zero-shot performance + semantic search more than make up for it.If you give an LLM access to your Spotify account via an API, it has access to your playlists and access to details about each song like `BPM`, `vocality`, even `energy` :https:&#x2F;&#x2F;developer.spotify.com&#x2F;documentation&#x2F;web-api&#x2F;referenc... https:&#x2F;&#x2F;developer.spotify.com&#x2F;documentation&#x2F;web-api&#x2F;referenc...An LLM with no prior explanation of either endpoint, can figure out that it should look at your favorites playlists, and find which songs in your favorite list are most suitable for a tired person.-But it can go even further and identify its own sorting criteria for different situations with chain of thought:Bedroom at night: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;6b1787ef-cd84-4834-b582-5024f8... Kitchen at 5pm: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;7ddaa047-0855-48c1-bcea-308083...Rather than blindly selecting the most relaxing songs it understands nuance like:> Room State: \"lights on\" and \"garage door open\" can imply either returning home from work or engaging in some evening activity. The environment is probably not yet set for relaxation completely.And genuinely comes up with an intelligently adapted strategy based on the situation -And say it gets your favorite wrong, and you correct it: an LLM with no specialized training can classify your follow up as a correction vs an unrelated command. It can even use chain-of-thought to posit why it may have been wrong.You can then store all messages it classified as corrections and fetch those using semantic similarity.That addresses both the customization and determinism issues: You don&#x27;t need to rely on the zero-shot performance getting it right every time, the model can use the same chain of thought to translate past corrections into future guidance without further training.For example, if your last correction was from classical music to hard metal when you got back from work, it&#x27;s able to understand that you prefer higher energy songs, but still able to understand that doesn&#x27;t mean every time in perpetuity it should play hard metalKitchen w&#x2F; memory: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;43635427-55d5-4394-b282-46acae... Bedroom w&#x2F; memory: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;8c146dd5-2233-4aba-8f6a-b97b7a...-I experimented heavily with things like this when GPT came out; part of me wants to go back to it since I&#x27;ve seen shockingly few projects do what I assumed everyone would do.LLMs + well thought out memory access can do some incredible things as general assistants right now, but that seemed so obvious I moved on from the idea almost immediately.In retrospect, there&#x27;s an interesting irony at play: LLMs make simple products very attractive. But if you embed them in more thoroughly engineered solutions, you can do some incredible things that are far above what they otherwise seem capable of.Yet a large number of the people most experienced in creating thoroughly engineered solutions view LLMs very cynically because of the simple (and shallow) solutions that are being churned out.Eventually LLMs may just advanced far enough that they bridge the gap in implementation, but I think there&#x27;s a lot of opportunity left on the table because of that catch-22 reply behnamoh 6 hours agoprevIt seems after 1-2 years that the true power of LLMs is in DevOps. I got pretty excited when I tried GPT-3 (completion model), but as time went by and OpenAI shifted to chat models, we lost control over the LLM part and found new meaning in taking whatever model OpenAI made available as a blackbox and \"chained\" it to other tools we already had, like data bases, APIs, function calls&#x2F;tools, etc. I&#x27;d say DevOps is exactly where open source is seriously behind; there are decent open source models but it costs so much to self host them, despite the full power and control we have on them (via text generation webui and the like).OpenAI is playing the DevOps game (starting maybe with introduction of ChatML). Open source community plays the LLM and benchmarks game. Ironically, the two are converging, meaning that OpenAI&#x27;s models are getting dumber (not the API) thanks to censorship and RLHF, to the point that open source models are even better than some OpenAI models in some aspects. On the other hand, open source models are getting better tooling and DevOps thanks to oobabooga, llama.cpp, etc.I&#x27;m seriously waiting for competitors to change nVidia&#x27;s monopoly in this space. Maybe Apple? reply antupis 5 hours agoparentI think currently M2 max is best bang for buck running interface in open source model. But use case is so niche that Apple probably doesn&#x27;t actively start supporting open source models. In the long run I hope some smaller company gets shit together and starts competing with NVIDIA. reply rankun203 4 hours agorootparentThe GPU support in ML frameworks however is really not impressive. I have a Macbook with M1 Max 64G RAM, I can load a 7b model for fine-tuning (Huggingface Trainer, Pytorch, MPS), but the speed is just too slow, can only reach to 50% the speed of an i5-12500 CPU in my tests. reply behnamoh 4 hours agorootparentprevAt $6,000, how is M2 Max the best bang for the buck?!One could get two used 3090s and setup a decent PC at lower prices. reply kiratp 4 hours agorootparentTwo 3090s don’t have 96GB of VRAM reply behnamoh 4 hours agorootparentThat&#x27;s true. But OTOH, one can&#x27;t easily upgrade Macs. reply aarong11 3 hours agorootparentWith 96gb of VRAM, will you really need to? Personally I think apple servers might be adopted for AI and LLM workloads soon. reply antupis 3 hours agorootparentprevM2 max studio is 2000$. reply sam_goody 1 hour agoparentprev> I&#x27;m seriously waiting for competitors to change nVidia&#x27;s monopoly in this space. Maybe Apple?I would have thought AMD is the obvious contender. They are #2 in GPU&#x27;s, they have formidable programming talent (based on their advances with Ryzen vs Intel) and they have targeted AI as their goal.Am I missing something? reply stevage 4 hours agoprev> WARNING: this will remove all your data from spotify!That is quite the caveat. reply seanthemon 4 hours agoparentI feel like that script needs a few &#x27;are you completely sure?&#x27; Prompts reply Towaway69 1 hour agoparentprevthanks for pointing that out! reply salamo 7 hours agoprevIt&#x27;s actually really interesting to see GOFAI techniques like planning used in conjunction with LLMs. reply cscurmudgeon 7 hours agoparentI see a GOFAI resurgence thanks to LLMs. reply impulser_ 6 hours agoprevThe examples are pretty lame since you can do what the examples do way faster without using a LLM and paying OpenAI. reply albert_e 7 hours agoprevChatGPT + Noteable is already powerful to get some work done via API calls (after installing and importing the libraries, writing Python code, managing secrets for authentication etc)There is surely scope to streamline this much furtherI am very intently watching this space reply pplonski86 2 hours agoparentI&#x27;ve seen Noteable+ChatGPT demo, where user can chat with ChatGPT and responses where executed in the Noteable-hosted Python notebook. It was cool!It would be also cool to have such plugin for Google Colab.I hope someone will come with a new way to interact with LLM models other than chat UI. It would make code writing even more faster. reply thelittleone 5 hours agoparentprevInterested to learn more (big fan of data stories). Do you have any particular use cases you would recommend to look into? reply amelius 1 hour agoprevWaiting for BashGPT.It could use curl to do REST calls too, and a lot more. reply pplonski86 1 hour agoparenthttps:&#x2F;&#x2F;github.com&#x2F;KillianLucas&#x2F;open-interpreter reply cosbgn 5 hours agoprevThis is interesting, I do something similar with unfetch.com - I have some examples on unfetch.com&#x2F;directory - There are a lot of potential use cases for LLm & APIs reply pplonski86 2 hours agoparentThe service unfetch.com looks cool. Can I run it locally on my machine, not in the cloud? Is it open-source? reply cosbgn 1 hour agorootparentIt&#x27;s not opensouce, even though it&#x27;s something I would like to be able to do soon. We offer enterprise plans, which use LLAMA2 instead of openai and can run on your own cloud (or even locally if you have enough RAM). If you are interested send me an email at c@unfetch.com reply venky180 6 hours agoprevHow does this compare to agentGPT? reply airstrike 5 hours agoprevFinally a use for my IRC bot reply transcriptase 6 hours agoprevPaging the Google Home team… reply Obscurity4340 6 hours agoprev [–] Is there any local GPT model available, even if its a bit older? I had heard maybe 3.5 leaked but perhaps I&#x27;m mixing up StableDiffusion? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The RestGPT project is a sizeable language model that interacts with RESTful APIs in order to manipulate real-world applications like film databases and music players.",
      "RestGPT uses a planning and executing framework to call APIs and analyze the responses.",
      "The project presents RestBench, a test set for measuring the performance of RestGPT, and the code, data, and instructions for setting up and operating the system are accessible under an open-source license."
    ],
    "commentSummary": [
      "The central discussion is about the distinction between RestGPT and other language models, with considerations about their understanding and capacity to handle real-life situations.",
      "The conversation covers the potential of language models like ChatGPT in home automation, personal assistants, and in DevOps, contrasting them with the limitations of virtual assistants like Siri regarding natural language understanding and context.",
      "There is a focus on the need to challenge NVIDIA's monopoly in GPU support, suggesting a necessity for competition in the field. The use of ChatGPT, Noteable, and GOFAI techniques with language models are also discussed."
    ],
    "points": 142,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1694398965
  },
  {
    "id": 37455574,
    "title": "Google no longer offers new domain registrations",
    "originLink": "https://domains.google/",
    "originBody": "Home Support Manage domains An update on domains Google no longer offers new domain registrations, but try Squarespace Get a new domain from Squarespace On September 7, 2023 Squarespace acquired all domain registrations and related customer accounts from Google Domains. Customers and domains will be transitioned over the next few months. Learn more. Already a Google Domains customer? Manage your current domains This is an affiliate link. If you make a purchase from Squarespace, we may earn a commission. Google About Google Privacy Terms Deutsch (Österreich) Deutsch (Schweiz) Deutsch (Deutschland) English (Australia) English (Canada) English (United Kingdom) English (India) English (Mexico) English (Malaysia) English (New Zealand) English (Philippines) English (United States) English (Singapore) English (South Africa) español (Colombia) español (México) español (España) français (Belgique) français (Canada) français (Suisse) français (France) हिन्दी (भारत) Indonesia (Indonesia) italiano (Svizzera) italiano (Italia) 日本語 (日本) Nederlands (België) Nederlands (Nederland) polski (Polska) português (Brasil) svenska (Sverige) ไทย (ไทย) Türkçe (Türkiye) Tiếng Việt (Việt Nam) 中文 (台湾) arrow_drop_down",
    "commentLink": "https://news.ycombinator.com/item?id=37455574",
    "commentBody": "Google no longer offers new domain registrationsHacker NewspastloginGoogle no longer offers new domain registrations (domains.google) 142 points by sparshrestha 21 hours ago| hidepastfavorite176 comments skilled 20 hours agoGoogle Domains assets (existing domains) was sold to Squarespace which has been discussed on HN at the time of the announcement,Alphabet selling Google Domains assets to Squarespace (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36346454) (548 points86 days ago606 comments)Also relevant,About the Squarespace purchase of Google Domains registrations (https:&#x2F;&#x2F;support.google.com&#x2F;domains&#x2F;answer&#x2F;13689670?hl=en) reply dang 15 hours agoparentThanks! Macroexpanded:Google Deprecates Google Domains, Sells It to Squarespace - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37140806 - Aug 2023 (47 comments)Who should I use for Domain Names since Google Domains has been sold? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36868082 - July 2023 (11 comments)Google Domains to Shut Down - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36437962 - June 2023 (12 comments)Google is selling all my personal information in Google Domains to Squarespace? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36423465 - June 2023 (124 comments)Google Cloud Domains is to be fully deprecated as part of Google Domains sale - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36369701 - June 2023 (45 comments)Where are you moving your Google domains to? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36364519 - June 2023 (16 comments)Why would Google sell Google domains to Squarespace? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36352347 - June 2023 (72 comments)Alphabet selling Google Domains assets to Squarespace - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36346454 - June 2023 (606 comments) reply PartiallyTyped 20 hours agoparentprevI looked up some domains I was interested in the `.dev` TLD and they go for 7-8 times the price that google offered them for a year. reply makestuff 19 hours agorootparentYeah I have a .RSVP domain for an event website. Google charged $12&#x2F;yr and Squarespace charges $20. It was a TLD created by Google so there aren’t too many places that support it yet. reply drexlspivey 19 hours agorootparentprevcloudflare added the .dev TLD among others a few weeks ago reply juvenn 7 hours agorootparentYes, and its cheaper even than google&#x27;s price. I&#x27;ve just transferred to cloudflare a weeks ago. reply tikkun 20 hours agoprevThere was a thread about alternatives on HN [1]. The top mentioned ones were: Porkbun, Namecheap, Dynadot, Cloudflare, Nearlyfreespeech, Gandi.I&#x27;ve used Porkbun, Namecheap, and Gandi. Namecheap is my preferred. Porkbun is fine, Gandi I would prefer to not use again. I haven&#x27;t tried Dynadot or Cloudflare&#x27;s domains (but I love Cloudflare&#x27;s DNS).[1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37099102 reply pdw 20 hours agoparentGandi was sold earlier this year. The new owners do not have a good reputation. reply rapind 19 hours agorootparentWasn’t Gandi’s whole schtick an ethical thing? Then they sold out? reply mypetocean 18 hours agorootparentNot saying this is what happened necessarily, but sometimes as a startup, you find yourself in a position where you must either sell to someone&#x2F;anyone or the business must shut down (and you&#x27;re left with the debt and with long-loyal early employees&#x2F;friends whose equity you were never able to pay off).I was a founding member of a social enterprise startup which ended up in a position very similar to that.In our case, we were lucky that we had two options to sell: (A) to an investor who wanted to pervert our mission, vision, and values for profit; or, (B) to a nonprofit who didn&#x27;t have the money to give us more than a single paycheck or two worth of payoff for our equity.If we had sold to Option A, a dozen of us would be wealthy right now. But the company we built would have been perverted into something unrecognizable.In our case, to our founder&#x27;s credit, we sold to Option B to keep the dream alive, but none of us became wealthy... and the nonprofit just shut down the company we founded only 2 years after the purchase (partly because the nonprofit didn&#x27;t have the business savvy to make it sustainable). _Everyone_ was just laid off.That means, our noble sacrifice only extended the lifetime of our noble vision by 2 years, and we&#x27;re certainly feeling less good about it.Because the alternative would have meant that a bunch of us bleeding hearts would have the economic freedom right now to do all sorts of good for untold decades to come.So I&#x27;m just saying, sometimes you don&#x27;t get to have good options and everything sucks, no matter how well-intentioned you are. reply TedDoesntTalk 19 hours agorootparentprevGandi’s VPS offerings have always been a nightmare reply hairofadog 19 hours agorootparentprevAh, I knew about the price increases but not the sale of the company.One thing I really liked about Gandi was that they had a concept of Organizations, and users within those orgs, so we didn’t have to share a login within the org.I’ve been moving my personal domains to Porkbun and Cloudflare, just to see which I like better. For domains at the company where I work I’d rather move them to Cloudflare, but they require that you use their DNS, and I haven’t yet felt like untangling how that will work with our AWS setup — we’re currently using Route53 and features there, including their certificate management and routing to specific ARNs.Anyway, It’s a shame, because I was a big advocate for Gandi for a decade, and any time I could I always transferred domains there, for myself and the companies I worked for. In my digital life so far, Apple is the only one I’ve been able to stick with long-term. If they ever get broken up or if I get inexplicably banned, that one’s gonna hurt. reply florbo 18 hours agorootparent> Cloudflare, but they require that you use their DNSThis has been my only issue with them so far. Realistically it&#x27;s not likely to cause any problems for either my personal or professional situations since I prefer to use CF DNS. It&#x27;s simply a missing feature.If something happens that makes me reconsider their DNS product I&#x27;d likely transfer the domains, even if I could change nameservers. reply sylware 19 hours agorootparentprevOh god.I am a gandi domain user.I could up my account balance with a check and use their simple noscript http API to perform my domain operations (with curl).Does it mean I will have to go raw IP email server? Aka, myname@[x.x.x.x] and myname@[IPv6:...], at least SPF is free here :)Why I cannot find who did buy gandi??? what is happening??? reply franckl 19 hours agorootparenthttps:&#x2F;&#x2F;www.nextinpact.com&#x2F;article&#x2F;71103&#x2F;gandi-fusionne-avec... Google translate it from french. Basically the new owners are known for not caring about customer service. Gandhi email service will probably go or increase a lot in price reply hairofadog 19 hours agorootparentprevIt’s on their Wikipedia page:> In February 2023, Gandi was acquired by Total Webhosting Solutions, forming a new brand, Your.Online. In June, the company announced drastic price increases, including a new monthly fee for mailboxes previously included for free.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gandi reply beowa 20 hours agoparentprevI can vouch for Cloudflare — definitely the cleanest registrar I’ve ever used reply Nereuxofficial 19 hours agorootparentAlso the price after 1 year is really cheap reply temp0826 19 hours agoparentprevI really wanted to move everything to Porkbun from Gandi after their announcements, but they don&#x27;t support .st names and I&#x27;m not interested in having multiple providers. So I&#x27;ll be sticking with them until further notice. The price changes seemed to only(&#x2F;mostly?) affect their email hosting offerings that I don&#x27;t use...but the change of hands in general makes me nervous. reply k8sToGo 18 hours agoparentprevI transferred all my domains to cloudflare. The downside is that you must use Cloudflare DNS servers. reply robtaylor 19 hours agoparentprevJust a shout for Porkbun.Not directly domain related but they replied to me direct on something and great - humans there. reply sodality2 13 hours agorootparent+1. I’ll never forget when I had an account with them, set up FIDO 2FA, and lost my password + email access for the account. I emailed customer support asking if there was something that could be done, and if not, I was fine making a new account (I had no domains at the time, and if I had, payment method confirmation would’ve probably let me get it back). Within days, their engineers added that feature, tested it, and rolled it out… reply radicality 19 hours agoparentprevI’ve been using internet.bs for a few domains for many years and haven’t had any issues, anyone else use it? I remember the control panel looks kinda old and sketchy, but it’s been working fine for me for probably at least a decade now. reply iRomain 16 hours agoparentprevI have 200 domains at Dynadot and keep my personal&#x2F;most valuable ones at Cloudflare. Dynadot has improved a lot in the past few years. reply chias 19 hours agoparentprevI saw the writing on the wall with Google Domains a couple years ago, and moved to Moniker. Their platform is a little bit slow, but other than that, it&#x27;s excellent. reply numbasys 17 hours agorootparentOut of interest, how did you see that coming? The discussions I remember here on HN were full of people wondering why, and being generally blindsided by the news... reply chias 15 hours agorootparentI didn&#x27;t see the writing on the wall for them shutting it down, rather that I could not rely on it.I have (or rather had) two Google Domains accounts, one for my own projects, and one with my work email address for work purposes. My work Google Domains account got banned for some imagined rules infraction. I sent an appeal with evidence, which was immediately denied. In case you are curious, the effect of being banned from Google Domains is: you are no longer able to use Google Domains at all, which means you are both unable to change your DNS settings, and unable to transfer your domains out. For all of the domains, I had to wait until they expired, wait for the grace period to expire, and re-register them on a new registrar, hoping nobody else got to them first.After this experience, I decided it was not worth the risk to keep my personal domains on my personal Google account, so I transferred them out a few days later. I assume this was a bug, but as soon as I initiated the domain transfers, Google deleted all DNS records, which meant I had some non-trivial downtime on all of my websites while I got it all sorted out on a new registrar.After both of these experiences, there is no way I would ever trust another domain to Google Domains. reply nextaccountic 20 hours agoparentprevWhy Namecheap rather than Porkbun? reply unmole 20 hours agorootparentPorkbun has trouble process my credit card for some reason. reply Karunamon 20 hours agoparentprevI have had very good luck with Cloudflare, but their domain registration comes with an annoying limitation: you are not allowed to modify the glue records, you are stuck with their DNS reply malfist 19 hours agorootparentThat&#x27;s because it&#x27;s a loss leader to get you into their system reply moonchrome 19 hours agorootparentBut their DNS is free ? reply hairofadog 19 hours agorootparent(Not the person you’re replying to)It’s free, but there are times when it’s more convenient to point to someone else’s nameservers, and some people like to keep their DNS separate from their registrations as a “separation of powers” thing, but I’ve never seen the utility in that. reply nytesky 18 hours agorootparentI hear this complaint often. Why do people want particular DNS? I thought it was synced around the world? reply buro9 17 hours agorootparentTry using Cloudflare and having a wildcard subdomain and then letting others CNAME to it.You cannot do this on Cloudflare without purchasing an Enterprise offering with SaaS features.It&#x27;s a very basic thing, allow CNAME to your subdomains... but nope.So if you want to do this, you cannot use their DNS or Registrar. reply rmkrmk 6 hours agorootparentThis implies you&#x27;re using their reverse proxy feature, not just plain DNS records. reply hairofadog 18 hours agorootparentprevBecause sometimes it’s more convenient to point to someone else’s nameservers (I commented elsewhere in this thread about our AWS setup), and some people don’t want to give a single company control over their entire domain-to-web-server pipeline, though like I said I’ve never seen how that matters in practice. reply numpad0 16 hours agorootparentprevCould be particular registrar && DNS not run by that registrar replynytesky 19 hours agoparentprevAnyone know if Hover is any good, a friend recommended them? reply tildef 18 hours agorootparentI used Hover for personal domains and email for a while. It was fairly priced and reliable, and I also got decent chat support when I was migrating off it (to AWS for domains and purelymail for email--just for convenience reasons since I&#x27;d already started using those services for other stuff). They have some cute novelty TLDs too, which is nice. reply rendall 20 hours agoparentprevWould you mind saying more about your experience with Gandi? reply moron4hire 19 hours agoparentprevI had tried NameCheap for a little while, but I&#x27;ve been using NameSilo for everything for the past 5 years. For the most part it stays out of my way.I&#x27;ve never found a registrar that really felt like it was overall a good experience. It&#x27;s definitely a \"least bad\" kind of market. The thing that bothers me the most about registrars is that they all have their own interfaces for stuff and it takes time to learn how to navigate to everything. So it makes it hard to try new ones. reply shmde 18 hours agoparentprevI love porkbun. Bought 2 cheap domains and the UI is super duper friendly. Love it. Had used Gandi previously and liked it too. reply tlogan 19 hours agoprevI&#x27;ve raised this question several times, but it bears repeating: What&#x27;s Google&#x27;s rationale behind this decision?Domain management appears to be a crucial component of a comprehensive cloud solution. It may serve as a loss leader, but it&#x27;s undeniably an effective entry point for both Google Workspace and Google Cloud. After all, competitors like AWS and Cloudflare offer this service. reply thomasrognon 19 hours agoparentGCP still has domain management via Cloud DNS. That isn&#x27;t going away. This is just domain registration. I say this as someone who uses Google Domains and GCP and is upset at this decision. reply surajrmal 18 hours agorootparentGCP is still retaining domain registration as well. The backing registrar is changing, but the Google Cloud Domains product is unaffected otherwise. reply bananapub 1 hour agoparentprevI would wager \"focus\" and symbolic headcount reduction. reply prepend 19 hours agoparentprevI think it’s because GCP isn’t profitable and so they don’t want a loss leader for a product line that isn’t competitive with their other internal products.Typically you don’t want loss leaders for things that aren’t strategic or very profitable.Google is not a cloud company. So this is probably just reallocating resources toward more important things.I bet if domains was a loss leader to AdWords it would stick around. reply jsnell 15 hours agorootparentGoogle Cloud reported profits in the last two quarters, and seems to be the thing they have been reallocating resources to this year, not from.I think the reality is just that Google Domains was not (and never had been) a product of the Cloud organization and was not subject to their decision making process. But obviously that&#x27;s not how anybody outside the company would have viewed it; they don&#x27;t know the internal org charts nor care about them. reply tlogan 12 hours agorootparentI think this is the best and the most logical explanation. reply paganel 18 hours agorootparentprev> Typically you don’t want loss leaders for things that aren’t strategic or very profitable.So does that mean that GCP itself is on the chopping block? I seem to remember a similar discussion regarding its future was in the air about 2-3 years ago. reply prepend 16 hours agorootparentI thought they would cut it years ago, but it’s sticking around.It’s still a distant 3rd place, but it used to be fourth and seems to have doubled from 5-10% in the last 5 years. [0][0] https:&#x2F;&#x2F;techcrunch.com&#x2F;2023&#x2F;02&#x2F;06&#x2F;even-as-cloud-infrastructu... reply buro9 18 hours agoprevI think the most shocking thing is that the link to Squarespace is an affiliate link.Google have sold Google Domains to Squarespace... but apparently, not for enough as they really really want to just make a few hundred bucks more from affiliate revenue.Is Google really in that much trouble? reply ttymck 18 hours agoparentPerhaps they were obligated to do this under the terms of the sale?Maybe it&#x27;s not for affiliate revenue, but just because some product manager at squarespace needed another metric to track? reply fakedang 8 hours agoparentprevMore likely, Squarespace just wants to track the number of users searching from Google Domains, before the brand is completely sunset. reply hartator 20 hours agoprevI remember not so long ago Google Domains was considered a safe long-term way to register domains. reply ipnon 20 hours agoparentIsn’t the joke on HN generally that no product lasts at Google unless it’s search? reply RedNifre 19 hours agorootparentWhat makes you think that search will last? They could easily sunset it as soon as the majority of users switch to some AI chat for getting answers. reply ip_addr 20 hours agorootparentprevhttps:&#x2F;&#x2F;killedbygoogle.com&#x2F; reply acdha 17 hours agoprevThe most Google-y thing about this is that their FAQ links point to a page which is blocked behind a login form which requires a Google.com corporate account.https:&#x2F;&#x2F;support.google.com&#x2F;domains&#x2F;answer&#x2F;13689670?hl=en reply zarzavat 19 hours agoprevCloud services are sold on the basis of an exchange. I build my product, or my entire business, on your cloud platform, submitting to a huge amount of risk by doing so. In return, you promise to minimize my risk by being a trustworthy and reliable steward of that platform.Cloud platforms are a lot like banks. The value proposition of a bank is not that they store your money: my mattress can do that. No, the value proposition of a bank is that it’s a safe and trustworthy place.There is some second-order thinking involved. If I believe that other businesses are questioning the future of a given cloud platform, then I might decide that I need to start migrating to another provider sooner rather than later. If everybody decides that they need to migrate then it could make the platform actually unprofitable. Like a bank run. Only there’s no FDIC protection for cloud platforms.Google clearly just doesn’t give a shit what people think of their cloud platform. That’s scary. It means they don’t understand that they’re in the trust business. They truly believe that they’re just selling computing services. reply tourmalinetaco 18 hours agoparentThey haven’t understood trust as a selling point for at least a decade. At the end of the day Google is an ad company that dabbles in technology, all of their core services (Search, Gmail, YouTube, Android, Chrome) are all about reinforcing&#x2F;showing off their advertising network and any possible benefit consumers derive from that are secondary to selling&#x2F;displaying ads. reply ttfkam 18 hours agorootparentYep, they screwed the pooch with Google Reader and forced Google+ registration. Rather than learn their lessons, they just keep doing the same things over and over, eroding trust, and wondering why they can&#x27;t get more marketshare in new endeavors.They just can&#x27;t see why folks have such loyalty to search, gmail, docs, and Chrome: they are consistent. Folks aren&#x27;t loyal to Google Cloud, chat, etc. precisely because of their inconsistency and likelihood of getting the rug pulled out at any moment. reply surajrmal 18 hours agoparentprevGoogle domains is not a cloud product. Google cloud domains is. The latter is unaffected other than the fact the registrar backing the product is going to change to be square space. I&#x27;m not sure if any other major cloud vendor is the registrar backing their equivalent product. reply zinekeller 18 hours agorootparent> I&#x27;m not sure if any other major cloud vendor is the registrar backing their equivalent product.How to shoot down your argument 101: Amazon (https:&#x2F;&#x2F;www.icann.org&#x2F;en&#x2F;accredited-registrars?iana-number=4..., https:&#x2F;&#x2F;aws.amazon.com&#x2F;route53&#x2F;amazon-registrar-policies&#x2F;, note that the third-party links are the registries itself like Verisign), Cloudflare (https:&#x2F;&#x2F;www.icann.org&#x2F;en&#x2F;accredited-registrars?iana-number=1..., https:&#x2F;&#x2F;www.cloudflare.com&#x2F;products&#x2F;registrar&#x2F;), and Microsoft (https:&#x2F;&#x2F;www.icann.org&#x2F;en&#x2F;accredited-registrars?iana-number=1..., https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;app-service&#x2F;manage-c...) are operating their own registrars. reply tyingq 18 hours agorootparentprevMaking them one product seems possible&#x2F;reasonable. Cloudflare does it. reply traceroute66 18 hours agoparentprev> Cloud platforms are a lot like banks.I would argue that your comparison is incorrect.The correct comparison to a bank is dedicated hosting or own-hardware colocation.Cloud providers are selling you an abstraction over that base.Therefore the correct thing to compare cloud providers to are NBFIs (Non-Bank Financial Institutions).NBFIs know they are not a bank, they know they can&#x27;t sell you the trust-model of a bank. Instead they try to incentivise you with attractive sounding interest rates in the hope that you will conveniently disregard the fact that you will not benefit from the government-backed deposit safety scheme that you would gain with a bank. reply paulgb 18 hours agorootparentI think you&#x27;re taking the analogy too literally. Of course there are certain dimensions where they differ; that&#x27;s true of any analogy. OP&#x27;s point is that in both cloud computing and banks, trust is the product. reply traceroute66 18 hours agorootparent> you&#x27;re taking the analogy too literallyThe OP was the one who said \"there&#x27;s no FDIC protection for cloud\", so..... ;-)> trust is the productWell, to be fair, too many people put too much trust in the cloud.\"upload all your data to us, we promise we won&#x27;t look at it\" \"trust our key-management service where we too have access to the private-key&#x2F;API\" etc. etc.I wouldn&#x27;t \"trust\" any of them further than I can throw a 1U server. reply schemescape 20 hours agoprevThat was quick. I just had a renewal coming up, so I took the opportunity to transfer out.Originally, I was going to try Cloudflare, due to their at-cost pricing, but they didn’t allow transferring domains without first moving DNS (and maybe more? I couldn’t tell) to Cloudflare. I didn’t really understand the implications (would I have to use their CDN?), so I bailed out part way through. Edit: sounds like it’s just DNS: https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;registrar&#x2F;faq&#x2F;I ended up going with Porkbun, based on recommendations here. Their interface is a blast from the past, but their documentation is pretty good. The only issue I encountered is that they don’t support wildcard email forwarding like Google Domains, so I had to inventory the email addresses I’d been using and setup manual forwards for each.Overall, I wish Google Domains was still a thing. It was easy to use and cheap, and I thought it would stand the test of time.Edit to add: Google Domains’s UI&#x2F;instructions for transferring out were great. What a shame the service is going away! reply peddling-brink 19 hours agoparentMy only dislike about porkbun is their domain search. Google domains had amazing search, as might be expected. reply _joel 19 hours agoparentprevJust keep the NS set to the original DNS? I&#x27;ve done that with cloudflare before and not needed to transfer in the whole DNS. reply schemescape 19 hours agorootparentThe Cloudflare FAQ says you have to set the authoritative name servers to Cloudflare’s: https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;registrar&#x2F;faq&#x2F;#what-happen...If that’s not the case, then I’m definitely misunderstanding something about DNS! reply bandergirl 19 hours agorootparentThat&#x27;s correct, you cannot change the name servers of a domain purchased on Cloudflare, but you don&#x27;t have to use their proxy.I have yet to see a DNS zone manager as good as CloudFlare, so I&#x27;ve been using it anyway for the past 10 years for all of my domains. reply schemescape 19 hours agorootparentThanks! In retrospect, that doesn’t seem like a big deal. I guess I’m effectively paying $1&#x2F;year for the option of being able to change authoritative name servers to whatever I want (and the privilege of using Porkbun’s presumably worse interface).I’ll admit I was already a little biased against Cloudflare because one time I got caught by their infinite captcha (maybe due to my OS not being up to date because it was an old computer? I’ll never know…). reply Eisenstein 19 hours agoparentprevYou just reminded me about wildcard email forwarding. If squarespace turns that off I am screwed. Do you know any providers which will keep it? reply josephb 12 hours agorootparenthttps:&#x2F;&#x2F;purelymail.com&#x2F; https:&#x2F;&#x2F;mxroute.com&#x2F;Are two providers that I&#x27;ve used to catch-all and forward to an external mailbox. reply kstrauser 19 hours agorootparentprevNamecheap has it for free on domains registered there. reply peddling-brink 19 hours agorootparentprevCloudflare supports it. reply yafbum 19 hours agoprevThis is what I think about when I see people wiring a bunch of Google assistant devices and compatible widgetry in their homes. Home tech is supposed to last 20 years+, so why be okay with putting things in the walls from a company that has a pretty thick-faced history of leaving markets that it finds itself unable to milk for advertising? reply pluc 20 hours agoprevSeriously does anyone trust Google to run a product? Even if they came out tomorrow with a teleportation service I&#x27;d be too worried they&#x27;d cancel it mid-flight to try it out. reply zarzavat 19 hours agoparentThis decision has trashed Google’s brand and whoever made it should be fired. It’s not that Google domains is particularly important, but Google’s reputation for untrustworthiness in the consumer space has now metastasized to their cloud business. People were willing to give Google the benefit of the doubt before, that they would not treat business customers the same as consumers. Now they aren’t. reply dcow 19 hours agorootparentI mean I’d even argue that Google domains is important in terms of making the product a seamless experience when using GCP (and generally just carving out Google as being part fundamental internet infrastructure). I wouldn’t underestimate how much a small QoL thing like having one company as both your registrar and cloud service provider can impact the choice of which otherwise commodity service to use. Not having to do a bunch of domain verification BS for every new piece of infrastructure is (was) a pretty awesome experience.Sure you can have an MBA look at the situation and ask “Do we really need a registrar? The other cloud providers don’t have one and look at their margins”. So what this really signals to me is that Google has lost all capacity to be forward thinking, trendy and innovative. And without that (and thus a general relevance as a tech company), what is Google? reply CharlieDigital 19 hours agorootparentI&#x27;m a big time proponent of Google Cloud because I believe that they&#x27;ve done a few things particularly well in their overall architecture that others have gotten wrong.But this decision rubs me the wrong way because there&#x27;s a deep integration with several of the services that allow connecting an external domain. The verification of domain ownership with Google purchased domains was effectively seamless and aligned with this overall architecture principle of Stuff That Just Makes Sense.I still think that GCP is a great platform to build on, but the problem now is that they&#x27;ve further tarnished their image to other stakeholders who have a say in the platform decision making process. reply dtech 19 hours agorootparentprevAWS definitely has a domain registrar, although I believe they subcontract. Azure subcontracts to GoDaddy. Both still provide the service. reply explaininjs 18 hours agorootparentAre you sure? This (sourced) comment claimed the opposite: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37456916 reply the88doctor 18 hours agorootparentprev\"I wouldn&#x27;t underestimate how... having one company as both your registrar and cloud service provider can impact the choice of which otherwise commodity service to use.\" THIS. Even if I&#x27;m just spinning up a simple blog, unless I&#x27;m buying a premium domain name, I&#x27;m gonna buy it on Bluehost instead of a cheaper registrar like Namecheap just to avoid the few minutes of work and few hours of wait time to link that domain with another hosting service. reply joezydeco 19 hours agorootparentprevI&#x27;m a paying Workspace customer, running a domain for my family. I reallllly don&#x27;t want to migrate off but with each passing month I&#x27;m growing more and more nervous.What are my alternatives besides Office365? reply ccakes 19 hours agorootparenthttps:&#x2F;&#x2F;www.fastmail.com&#x2F;Have been a customer for years, great service run by humans. reply angrygoat 18 hours agorootparent+1 on fastmail, I&#x27;ve been nothing but happy with their service. reply kstrauser 19 hours agorootparentprevApple’s iCloud+ plans (starting at $1&#x2F;mo) include email hosting with custom domains. I moved my family to that a couple years ago and it’s been fine. See https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT212514Everyone in my immediate family has 1 or more email addresses in our family domain, and I have a couple of fun&#x2F;project domains their too, for $0.00 above what I was already paying for iCloud. reply politelemon 19 hours agorootparentprevOffice 365 is decent overall, good value for money so it&#x27;s still worth considering. With rough edges.Zoho is an alternative, can do custom domains, website hosting, email, productivity suite. reply nytesky 19 hours agorootparentI thought O365 no longer offered custom domains? reply connordoner 17 hours agorootparentThe personal and family service doesn’t, but the business service does. reply newscracker 16 hours agorootparentprevIf you only need email, then there are a bunch of providers in Europe that are cheaper (especially compared to something like Fastmail if you need one mailbox for each person in the family), have been around for several years and support custom domains. In no particular order, they are mailfence, mailbox.org, runbox.com and migadu. All of them support IMAP directly (unlike ProtonMail that needs a bridge application and Tutanota that does not support IMAP). reply Intralexical 18 hours agorootparentprevIf it&#x27;s just for your family, then depending on what you need, you could try OnlyOffice— Either self-hosted, or SAAS. They use MS formats as their first-class native format, IIRC, so compatibility is pretty great.Nextcloud also advertises an office suite, though I haven&#x27;t tried it. Nextcloud also apparently integrates with OnlyOffice, though I haven&#x27;t tried that either— Apparently Nextcloud&#x27;s own office suite is a rebranding of LibreOffice.I&#x27;d probably go with OnlyOffice, either on its own or integrated into Nextcloud. reply numpad0 19 hours agorootparentprevYour domains should not be tied to your main Gmail and GDrive anyway. Too many horror stories of wrongful ban leading to a chicken and egg situation around account lockouts. reply joezydeco 12 hours agorootparentOh, they&#x27;re not. I knew of that trap a long time ago. reply snuxoll 19 hours agorootparentprevBeen using Zoho services for my family after I got tired of fighting with spam reputation when self-hosting. reply charrondev 18 hours agorootparentprevAre you just using it for email? For my family that already had a few Apple devices I switched to using custom domains with iCloud (which is included with any iCloud subscription, even the $1 one).You can have up to 3 domains configured per family. reply joezydeco 12 hours agorootparentMostly email, but we do take advantage of gDrive for file sharing.And I really really don&#x27;t like iCloud&#x27;s file system. reply traceroute66 18 hours agorootparentprev> What are my alternatives besides Office365?Protonmail ? If its email you&#x27;re after you can point your MX at them. reply ocdtrekkie 18 hours agorootparentprevFastmail is really well set up to be a family account provider. You can add multiple domains, aliases to various accounts, and you can mix and match account levels now (kids accounts can be cheaper ones than your own, but still share your domain). Their spam filter works better than Google or Microsoft&#x27;s, and I set up aliases that deliver to say, my wife and I, so we can both be notified of updates for particular accounts and such.If you have any issues, a real person will answer your support ticket. reply paulgb 20 hours agoparentprevUntil Domains, I mostly trusted google to keep running a paid b2b product with lots of users. Most of the famous products they&#x27;ve killed have been ones that either didn&#x27;t bring in revenue, or never became popular.After the Domains announcement, I can&#x27;t in good conscience bring myself to spin up any new GCP services, and have started leaning more heavily on AWS. Part of me thinks that Domains is a signal that Google is planning a larger exit from the cloud business, given the GCP &#x2F; Domains integration, and the absolutely atrocious comms from Google around Domains has not reassured me at all. reply TedDoesntTalk 19 hours agorootparent> that either didn&#x27;t bring in revenueDomain registration is famously difficult to profit from unless the registrar is able to upsell reply paulgb 19 hours agorootparentThey used it to upsell Google Workspace, as well as their own TLDs (.dev, .app). And although they didn&#x27;t upsell GCP through it, the integration between the two was a nice (small) incentive to use GCP. reply andrewpolidori 18 hours agorootparentprevWhat makes it so difficult to profit from? A yearly subscription to maintain some text entries doesn&#x27;t seem that crazy to me. reply loopdoend 18 hours agorootparentThe costs are known, the competition is high, the margins are low. You still have to deal with support&#x2F;abuse. There is no real “high volume customer”. reply thiht 17 hours agorootparentprevThere’s a lot of contractual obligations and edge cases in domain names, and a lot of potential for fraud and disputes. It’s a business with high legal fees.Also how domains should be managed evolves with time. For example GDPR has a huge impact on WHOIS, especially since the ICANN took so much time to acknowledge that in their specs, so there was a time where it was impossible for a registrar to be compliant with GDPR and ICANN rules. It’s still not 100% clear how it’ll be handled by RDAP (future successor of WHOIS)And last but not least, some registries for ccTLDs are real pains in the ass to work with, and won’t hesitate to slap you with big fines if you make any mistake. reply redman25 18 hours agorootparentprevThey killed GCP IOT core as well. Forced us to find another vendor. reply 23B1 19 hours agorootparentprevWe&#x27;ve had multiple multi-cloud customers signal a desire to move away from GCP for years now because savvy CXOs are just fed up with the unreliability. When you&#x27;re looking to resolve a ton of tech debt that you have because of the ground constantly shifting beneath your feet for 1-2 decades... well, you just get fed up and want the reliability of serious enterprise vendors.It makes innovation much harder due to the downstream effects, but at least I&#x27;m not carrying more and more risk forward thanks to Google&#x2F;Alphabet&#x27;s ADHD approach to product, brand, and support. reply dividedbyzero 19 hours agorootparentWhat exactly do you mean by unreliability? reply js4ever 18 hours agorootparentProbably the constant deprecation of API &#x2F; SDK from Google, you have to keep up with their crazy deprecation policy. On the other side I still have some APPS calling AWS API since 10y without any issues. reply chias 19 hours agorootparentprevNot having to ask \"will the product I rely on today exist tomorrow?\" reply 23B1 17 hours agorootparentprev\"When will Alphabet opaquely and unilaterally depreciate this product upon which we&#x27;ve come to rely, as they do with many other products all the time?\"Alphabet is a hopelessly disorganized bureaucracy whose leadership appears, at best indifferent to customer needs, at worst hostile to customers that don&#x27;t toe their line.It&#x27;s just a risk calculation you have to make when you&#x27;re spending millions to build systems of record upon which your enterprise will depend for years to come.I don&#x27;t know if its fair or even accurate – but it&#x27;s the feedback I get from client CTOs and CIOs at sizable companies. reply late25 20 hours agoparentprevNo, I do not. Google needs new leadership. There’s something to be said about trying things, but this continued uncertainty is killing their brand. reply mbesto 19 hours agorootparent> but this continued uncertainty is killing their brand.There stock price would say otherwise: https:&#x2F;&#x2F;finance.yahoo.com&#x2F;quote&#x2F;GOOG&#x2F;?guccounter=1Until people stop using their service(s) then, no, their brand is not dying. reply scarface_74 18 hours agorootparentBlackBerry’s stock price was at its peak in 2010. 3 years after the iPhone came out and a year or so after Android started becoming popular.I’m not saying Google is going to fail. But GCP seems like a dead man limping reply mbesto 12 hours agorootparent> But GCP seems like a dead man limpingSure is... https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;478176&#x2F;google-public-clo... reply scarface_74 10 hours agorootparentWell GCPs profit was a meager $191 million last quarterhttps:&#x2F;&#x2F;www.datacenterdynamics.com&#x2F;en&#x2F;news&#x2F;q1-2023-cloud-res...And even that is only because of GSuite reply dimitrios1 19 hours agorootparentprevTheir stock price reflects their ad moat, and nothing more.In my opinion, their stock price is the least interesting. They are coming around on the other side of an upswing and seem poised to be headed back down towards their pre-COVID normalization of around 90 dollars. Compared to Amazon, it&#x27;s disappointing, and Microsoft is in another galaxy in comarison. With no real option for growth, considering they simply cannot be trusted to launch a new product, it seems like the early feedback is this will also hurt their cloud business as customers simply cannot trust them to maintain new offerings.They&#x27;ll do what they always have done: survive off ads and YouTube. But I am not sure how many more percentage points they can squeeze out of those two. People are already starting to catch whiff that their search engine results are not what they used to be. What will happen then?If history is doomed to repeat itself, they&#x27;ll do what their predecessors have done: get some Harvard-style MBA types in the building to \"optimize\", jettison all the excess baggage, and keep the cash flowing into their investors pockets, while they slowly lose whats left of their reputation and ability to innovate.I suppose they have enough patents to troll on for the next 25+ years or so. Just like some other 3 letter company we may know about that once was a tech giant. reply _jal 19 hours agorootparentprev> this continued uncertainty is their brandFIFY.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Category:Discontinued_Google_s...If it doesn&#x27;t shove an ad in someone&#x27;s face, Google is structurally incapable of caring about it. reply numpad0 18 hours agorootparentI remember reading about dream workplace called Google where devs can join or leave any team for credits to count towards promotions, with a catch that helping others and&#x2F;or bothering yourself with low-impact maintenance tasks could risk your employment.If that&#x27;s actually how Google works, it does sound structural. reply appplication 19 hours agorootparentprevList is missing Google Play Music reply javier2 19 hours agorootparentprevThis. The Ads priiiint money, anything else looks unimportant. reply dcow 19 hours agorootparentSure, if you want to fade into history as an ultimately irrelevant ad network that simply had the novel ideal of tying ads into internet search early on in the internet’s youth and became popular and rich for a decade, then take this stance. reply JadeNB 19 hours agorootparent> Sure, if you want to fade into history as an ultimately irrelevant ad network that simply had the novel ideal of tying ads into internet search early on in the internet’s youth and became popular and rich for a decade, then take this stance.The problem with any current leader is that they do want to do this. Or, rather, they don&#x27;t care if they do. Who cares what Google will look like in the long run? They&#x27;ll be gone. Right now, they presided over the appearance of continued growth, and that&#x27;s what matters.(I have no internal knowledge about Google, of course, but I am at a university, whose plan is (1) attract more students, (2) more students, (3) more, (4) start thinking about what to do with all these students.) reply scarface_74 18 hours agorootparentFounder run companies care and even hand picked successors to founders who are “company men”. The Google CEO is just a suit.If you look at all of the Big Tech companies - Facebook, Apple, Amazon, Microsoft and Google, (yes I left off Netflix, it’s a nothingburger compared to those five), Google is the only one that seems to be rudderless without a long term plan or vision. reply culturestate 18 hours agorootparent> Founder run companies care and even hand picked successors to founders who are “company men”. The Google CEO is just a suit.Sundar has been at Google since 2004 and Larry Page hand-picked him. reply scarface_74 17 hours agorootparentSo in other words. He is just incompetent. That throws that thesis out of the window. replyslacka 19 hours agoparentprevCounter point, I&#x27;ve been using a VoIP service called GrandCentral since college. Google purchased them. Nearly 20 years later, I&#x27;m still using that same number with far more feature. In this case, Squarespace acquired Google Domains. Assuming the transition as seamless as GrandCentral was for me, what&#x27;s the issue here? From what I&#x27;ve heard of Squarespace and their support, they will be just as good a custodian as Google. reply joecool1029 19 hours agorootparentBandwidth.com mostly runs that service and they have proven themselves a competant business that Google built other products like GOOG-411 off of. Google Voice is just a frontend to it.I think if it ran entirely on Google&#x27;s infra and the service itself could be killed like the registrar was it would have been killed years ago (notably it stagnated from like 2012-2018 or so and there was a period of time they had a half-assed panel redesign and the product blog for it wasn&#x27;t updated for years) reply nytesky 19 hours agorootparentCan you get a number from bandwidth.com directly? Google Voice is invaluable. reply joecool1029 15 hours agorootparentYou can but they don&#x27;t really do B2C, their B2B has come down for small businesses but still requires a larger commitment then makes sense for a phone number or two.Unrelated, but I&#x27;ve found it bizarre Google Voice doesn&#x27;t do RCS but they made a big push otherwise to enable it for their Messages app. reply 1-6 19 hours agoparentprevThe problem is, organizationally, it&#x27;s a mesh network. If no one is kept on a single product for long, how can a product survive turnover rates when the next shiny object appears? It&#x27;s a game of musical chairs. reply xnx 16 hours agoparentprevGoogle is about ads and AI. Everything else is a distraction. reply gcanyon 19 hours agoparentprevgmail? docs?If google cancelled either of those I&#x27;d be very surprised and equally disappointed. reply lopatin 20 hours agoprevI just transferred mine over to AWS. For some reason I never knew they even did domains, and always bothered with Namecheap and Google. reply bandergirl 19 hours agoparentAWS has a few issues:- domains are relatively expensive ($13 vs $9.15 on CloudFlare for a .com, others even more expensive)- you have to pay DNS on top of that- you have to deal with AWS reply pnpnp 18 hours agorootparent> - you have to pay DNS on top of thatI’m starting to see this as a feature. AWS makes you pay per-request for a lot of things, but in my mind it makes those services sustainable.Maybe I’ve just been bitten by the promise of “free” or really cheap services either imploding or suddenly changing their billing model over the years. reply justhw 19 hours agoprevI wrote this 9 years go > The last thing I trust Google with is my domains. They can outright ban or disable you just like with any of their products and not offer support or explanation.Google will eventually kill all products that do not help them sell ads. Keep that in mind.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=8882243 reply ahnick 19 hours agoparentWho do you trust currently? reply traceroute66 18 hours agorootparent> Who do you trust currently?Depending on the extent of trust you want, the ultimate (whilst being \"reasonably\" affordable) option is becoming a Nominet member.Nominet are the registry for .uk. Anybody (person or business) can become a member and the core benefit of membership is you effectively become your own registrar. As long as you pay the membership fee, Nominet don&#x27;t care.You therefore cut out the middlemen.Sure, Nominet could theoretically cut off your domain (e.g. if you don&#x27;t pay your membership fees). But the bar is much, much higher than $Mega_Corp.Unless you&#x27;ve got money to burn, probably a bit extravagant for only one domain name. But if you&#x27;ll be needing a few it might be worth considering. reply DarkCrusader2 19 hours agoprevHow does this affect the .dev domains? I don&#x27;t understand the governance around TLDs very deeply, but can SquareSpace jack up the prices? Can they disable&#x2F;discontinue existing domains? reply Sytten 20 hours agoprevGoogle Cloud Domain seems unaffected? Unsure it that is expected to change, never know with google these days. reply alphalima 19 hours agoparentUnfortunately cloud domains domains are going to managed by Squarespace.> Since Google Domains is the underlying domains registrar for Cloud Domains, there are some important changes that we want to share with you.> What do you need to know? Upon closing of the Squarespace-Google Domains transaction, Squarespace Domains will become the registrar for your domains managed by Cloud Domains. reply lima 19 hours agorootparentThat&#x27;s fine, though. AWS Route53 uses a number of third-party registrars like Gandi. reply oldtownroad 19 hours agoparentprevGoogle Cloud Domains as a product will continue to function but it’ll be an interface to Squarespace: Squarespace will be the registrar.“Yes, you can continue to search and register for new domains using Cloud Domains. After migration, Google Cloud becomes a reseller of Squarespace Domains. When you buy new domains using Cloud Domains after migration, the registrar of record is Squarespace.”The least bad outcome.https:&#x2F;&#x2F;cloud.google.com&#x2F;domains&#x2F;docs&#x2F;faq reply krmboya 18 hours agoprevI heard something like this a while ago. Paraphrasing: A company is first run by engineers (becomes a well made product that people love), then it is run by MBAs (so that it looks good on the balance sheet), then it is run by lawyers (to extract every bit of value created), then it dies (i.e sustained only by inertia).But I find it hard to figure out what stage Google is at in this (maybe simplictic) progression. reply vagab0nd 18 hours agoparenthttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lmFlOd0MGZg reply wavemode 17 hours agoparentprevThe engineer-MBA-lawyer progression is commonly referred to as the enshittification cycle. reply xtracto 18 hours agoprevSo nowadays I use google domain&#x27;s feature of easy email forwarding (forward some xxyyy@mydomain.com to a personal email). Is there an alternative provider that can do that? reply rglullis 18 hours agoparentNamecheap does it. njalla does it. Virtually every domain registrar can offer this. reply xtracto 5 hours agorootparentCool, i normally ger domains through name.com and I think they dont do it. reply quickco 17 hours agoprevAdding a mention of Hover.com which has a very simple user interface. So ads or other junk. I’ve been a happy customer for years without any issues. reply colinbartlett 20 hours agoprevRelated discussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36352347 reply tjpnz 19 hours agoprevWhat&#x27;s the name of that art style? It&#x27;s like 90s clip art and I hate it. reply r721 19 hours agoparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Corporate_Memphis ? reply shmde 18 hours agoparentprevyou have a whole subreddit dunking on the artstyle. corporate memphis aka Alegria Art. The artstyle is fucking stupid and outright pathetic. Looking at it makes me want to puke on it.https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;fuckalegriaart&#x2F; reply keep_reading 17 hours agoprevHighly recommend dnsimple.comSmall company, great service, fastest DNS replication I&#x27;ve ever experienced, and a solid clean API reply economist420 10 hours agoprevNever again will I trust google. I&#x27;m so sick of this. reply chanar 19 hours agoprev“This is an affiliate link. If you make a purchase from Squarespace, we may earn a commission.”What’s the reason to earn commission from Squarespace? reply dizhn 18 hours agoparentIt would be funny if it was some google engineer&#x27;s personal affiliate link. reply potency 19 hours agoparentprevBecause Google&#x27;s shareholders demand it. reply lijok 18 hours agoprevAnd on this day a couple thousand more people learn that doing business with Google is a liability. reply carbocation 18 hours agoprevStill blows my mind that they did this about a year after announcing that Domains was out of Beta. reply totetsu 20 hours agoprevThat was quicker than expected. reply LightBug1 19 hours agoprevMission Statement: Google no longer offers. As soon as possible. reply kstrauser 19 hours agoparentCancellation as a Service. reply hankchinaski 18 hours agoprevMoved all my domain registration to cloudflare reply rvz 19 hours agoprevLet&#x27;s now predict the next product that Google is going to kill. I&#x27;ll start:I pick Google Fi. reply LikeBeans 11 hours agoparentPlease don&#x27;t give them any ideas. \"Unfortunately\" I rely on Fi for travel. So convenient. Come on Google, please leave this one alone. reply idolofdust 17 hours agoparentprevmost likely Google Podcasts next reply schemescape 18 hours agoparentprevGoogle Voice reply politelemon 19 hours agoparentprevGKE reply JOnAgain 20 hours agoprev [–] Another one bites the dustAnother one bites the dustAnd another one gone, and another one goneAnother one bites the dust (yeah)Hey, I&#x27;m gonna get you tooAnother one bites the dust replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "As of September 7, 2023, Google Domains has stopped providing new domain registrations.",
      "Squarespace has acquired all domain registrations and customer accounts from Google Domains.",
      "Existing Google Domains customers are required to transition their domains to Squarespace."
    ],
    "commentSummary": [
      "Google has transferred its domain registration service, Google Domains, to Squarespace. This development sparked discussions and raised concerns about Google's strategies and the future allocation of its resources.",
      "Other domain registrar options like Porkbun, Namecheap, Dynadot, Cloudflare, Nearlyfreespeech, and Gandi are suggested. Concerns exist about the new management of Gandi, while Google Cloud's domain management service, Cloud DNS, remains unaffected. Conversely, concerns about the future of Google Cloud Platform (GCP) are noted.",
      "This transition highlights the issues of trust, reliability, and risks in relying on single companies for various services. Attention is drawn to the need for considering alternative providers and Google's comparative domain management."
    ],
    "points": 142,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1694352013
  },
  {
    "id": 37459341,
    "title": "A design system for the federal government",
    "originLink": "https://designsystem.digital.gov/",
    "originBody": "Skip to main content An official website of the United States government Here’s how you know U.S. Web Design System (USWDS) How to use USWDS Design principles Components Patterns Design tokens Utilities Templates About Search Read website standards Download v3.6.0 View on GitHub A design system for the federal government. We make it easier to build accessible, mobile-friendly government websites. Introducing USWDS 3.0 Migrating to USWDS 3.0 Components Browse all USWDS components, and get UX, accessibility, and implementation guidance. Browse components Patterns Use our guidance to craft effective and inclusive user experiences. Explore pattern guidance Design tokens Learn how to get started using design tokens, the building blocks of USWDS component design. View design tokens Utilities Adapt your designs and deliver prototypes quickly and consistently without touching a line of CSS. Build with utilities Showcase vote.gov U.S. Department of Veterans Affairs NASA Glenn Research Center PubMed LabsU.S. National Library of Medicine America’s Seed Fund Plain Language Become part of the community USWDS is an active open source community of government engineers, content specialists, and designers. Our contributors both in and out of government support dozens of agencies and nearly 200 sites. Have an idea or an issue? Reach out in GitHub Engage with the community Find a channel that works for you Subscribe to our newsletter Sign up for USWDS updates Get support Email the USWDS team Looking for USWDS v1 documentation? Visit v1.designsystem.digital.gov designsystem.digital.gov An official website of the General Services Administration About GSA Accessibility support FOIA requests No FEAR Act data Office of the Inspector General Performance reports Privacy policy Looking for U.S. government information and services? Visit USA.gov",
    "commentLink": "https://news.ycombinator.com/item?id=37459341",
    "commentBody": "A design system for the federal governmentHacker NewspastloginA design system for the federal government (digital.gov) 138 points by galaxyLogic 14 hours ago| hidepastfavorite60 comments raylus 4 hours agoIn our foundational setup for the new https:&#x2F;&#x2F;beta.nasa.gov and https:&#x2F;&#x2F;beta.science.nasa.gov websites, we&#x27;ve adopted the US Web Design System (USWDS). While our other core products primarily rely on Tailwind, we are quite familiar with this toolkit. In my opinion, comparing the two is not entirely straightforward, but the USWDS toolkit has been implemented effectively, despite some of its \"America First\" usa-* class names.The decision to use the same toolkit across our projects is largely influenced by the 21st Century Integrated Digital Experience Act (IDEA), which mandates federal agencies to modernize their websites and digital services. You can find more information about IDEA here: https:&#x2F;&#x2F;www.hhs.gov&#x2F;web&#x2F;governance&#x2F;21st-century-idea.html#:~.... reply thaumasiotes 1 hour agoparent> despite some of its \"America First\" usa-* class namesIt&#x27;s the American government... isn&#x27;t it?What namespace would you expect them to use? reply amatecha 5 hours agoprevThe Canadian government has a design system[0] for government services too, that I think is quite decent. It&#x27;s almost primitive, but it&#x27;s clean, consistent and follows good accessibility principles. It&#x27;s downright boring, but I think that&#x27;s great. I am not interested in a flashy, only-compatible-with-latest-Chrome design for a government website. :)Oh, they even include a content style guide[1] which goes so far as to recommend things like writing with \"plain language\" to ensure content is easily understood. Really cool!Even further, they outline some good practice around how to actually create and maintain a good website[2], including suggestions like \"build in accessibility from the start\" and \"use open standards and solutions\".. How cool is that?For real though, I need to reiterate how impressed I am with their design system. Check out Canada.ca[3], the country&#x27;s official website. It&#x27;s \"plain jane\", right? I can&#x27;t believe how readable it is. It&#x27;s just plainly-worded links to topics of information you may be seeking. The chosen standard font is extremely legible, compared to so many websites. And it loads SO fast! :D I notice UK Govt&#x27;s website[4] is quite similar, which is great (though the cookie banner covering 2&#x2F;3 of the screen isn&#x27;t so nice haha)[0] https:&#x2F;&#x2F;design.canada.ca&#x2F;[1] https:&#x2F;&#x2F;design.canada.ca&#x2F;style-guide&#x2F;[2] https:&#x2F;&#x2F;www.canada.ca&#x2F;en&#x2F;government&#x2F;system&#x2F;digital-governmen...[3] https:&#x2F;&#x2F;www.canada.ca&#x2F;en.html[4] https:&#x2F;&#x2F;www.gov.uk&#x2F; reply ricardobeat 3 hours agoparentDutch government websites also have a no-frills design and well-written content in a similar style:https:&#x2F;&#x2F;business.gov.nl&#x2F;https:&#x2F;&#x2F;duo.nlhttps:&#x2F;&#x2F;belastingdienst.nl reply skavi 2 hours agorootparentUK’s got a very clean system as well.https:&#x2F;&#x2F;design-system.service.gov.uk&#x2F; reply michelb 38 minutes agorootparentprevThis is the NL design system: https:&#x2F;&#x2F;nldesignsystem.nl Open for public participation. reply AndrewKemendo 6 hours agoprevAs a user of the department of VA website I can say with confidence it is absolutely unnecessarily terrible.The login process alone is kafkaesque with literally 6 methods of login offered and a Byzantine routing process between nameservers, root DNS bouncers and processes that can’t maintain login state.What a joke reply encomiast 4 hours agoparentHow is the login experience, DNS, and routing related to the US Web Design System? reply salil999 4 hours agoparentprevYeah this reply doesn&#x27;t make sense. This is talking about design. You&#x27;re talking about login. You can stretch it and say UX can be improved but even then it&#x27;s not as relevant. reply binarysneaker 8 hours agoprevNot a patch on the UK government design system IMO. Used by the UK gov and 3rd parties to produce consistent, accessible and aesthetically pleasing public service front-ends. More: https:&#x2F;&#x2F;design-system.service.gov.uk&#x2F; reply ceedaxp 2 hours agoparentHaving seen a number of different gov websites, I think that gov.uk are the most aesthetically pleasant and UX-focused. I would only say that at times they are excessively verbose, but that is less of a design system fault and more from the \"let&#x27;s protect us from any liabilities and people making totally silly assumptions about what, when, and how we do things\" department. reply nicbou 2 hours agorootparentMy favourite part is the NHS website. Pages like this one [0] are an excellent example of clear, effective writing. They heavily influence how I write similar content.[0] https:&#x2F;&#x2F;www.nhs.uk&#x2F;conditions&#x2F;cough&#x2F; reply bobbylarrybobby 5 hours agoparentprevI love the UK government site design, in particular their font (Transport something or other?). Sadly the font may not be used anywhere but .gov.uk sites. reply melx 36 minutes agorootparentIt&#x27;s called GDS Transport[0] and it&#x27;s custom version of New Transport (for digital use) that&#x27;s based on the original Transport font designed in the 1950s.[0] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Transport_(typeface) reply throwmeout123 3 hours agoprevThe design system, where once productive FE devs go to die thinking everyone should use it reply brutusborn 9 hours agoprevI don’t know much about web design so I ask from a place of ignorance: has this been done well?Standardising components sounds like a good way to improve efficiency and safety but I imagine if it is done badly it could do the opposite.I’m always skeptical of big government initiatives, so I am interested to hear how those in the know grade the gov in this example. reply nicbou 8 hours agoparentIn this case a design system standardises forms and form components and that&#x27;s very valuable. This means that every government website taps gets to learn the same little design lessons at once, from browser compatibility to keyboard navigation and accessibility.gov.uk nailed this, and it makes their website very pleasant to use. They share a lot of their UX research so it benefits a lot of other people including myself.I&#x27;m also a big fan of writing guides that teach people to write simply and clearly. It&#x27;s sorely missing where I live. reply SoftTalker 8 hours agoparentprevAny site design will look stale after five years, no matter what standards you follow. It&#x27;s just an unfortunate reality, there is no way off of the wheel unless you are like Craigslist and deliberately reject all convention. reply ics 7 hours agorootparentI wish this wasn&#x27;t such a commonly shared opinion. Too defeatist, in my view. Craigslist is spartan, sure, but there are less extreme examples such as McMaster-Carr. They&#x27;ve had the same design more or less since 2010 at least and it is usually considered both functional and tastefully current. I think in the early 2000s they had a different design which was fine, and they obviously skipped the whole \"web 2.0\" era of design. reply SoftTalker 7 hours agorootparentYou&#x27;re right, there are a few exceptional sites that manage to have a \"timeless\" look and I&#x27;d probably put McMaster in that category. reply nextaccountic 5 hours agorootparentprev> there are less extreme examples such as McMaster-Carr. They&#x27;ve had the same design more or less since 2010 at least and it is usually considered both functional and tastefully current.This? https:&#x2F;&#x2F;www.mcmaster.com&#x2F;On desktop, sure. But they don&#x27;t work in mobile. And that&#x27;s easily 80% of the troubles of modern design: to avoid building everything twice, today people write \"responsive\", \"mobile first\" websites that, on desktop, tend to have an excessive amount of whitespace and other issues (see for example the old vs new reddit layout)What&#x27;s being demanded of websites in 2023 is just much more difficult to do well than what people wanted in 2010. reply sverhagen 4 hours agorootparentIt isn&#x27;t immediately clear to me what about that website isn&#x27;t working on Mobile, as it seems to look pretty decent for me? (Firefox on a Galaxy phone.) reply domh 3 hours agorootparentprevIt is my first time going on mcmaster.com and it&#x27;s working great on mobile for me (Android, Firefox). It feels snappy, good button sizes, great filtering options, no dead ends in flow until login to purchase. Top marks from me! reply bryanrasmussen 2 hours agorootparentprevthirding the mobile experience for me looks great on first try. I mean really really good. reply high_5 1 hour agorootparentprevThis is a discussion about governmental sites. I don&#x27;t use them because I want to but because I have to. So, current fashion and appeal are second to usability. There are some fundamental laws and limitations on how people process the presented information and that SHOULD be taken into account in designing a public service. Ideally, there is an interest in both parties (state and citizen) that their interaction is correct in order to fulfill their obligations and ensure their rights.Also many of the interactions with governmental digital services happen only once a year. I&#x27;ve been in helpdesk supporting people on a webapp with an obnoxious interface that they had to use 3 to 4 times a year to fulfill their project report in order to get paid for their project work. The UX was so out of the conventions that people hated it with passion and I had to help the laggards to use the application. reply pjc50 1 hour agorootparentprev\"Stale\" is good for government websites. If you&#x27;ve got to interact with a form regularly as part of a legal requirement it is good that it never changes and looks exactly the same time every time you load it across a decade. reply asoneth 6 hours agorootparentprevI am disappointed any time \"modernize\" comes up as one of the priorities on a redesign, especially for enterprise products. Most enterprise software does not gain much from looking \"modern\" and like all fashions the more modern the UI the more quickly it becomes dated.In extreme cases of very large products whose owners want them to look exceedingly modern it can be like painting the Golden Gate Bridge: by the time they finish implementing the last components and icons, the ones that were implemented at the beginning of the project are already due for an update.The job security simply isn&#x27;t worth the maddening repetition. reply amatecha 5 hours agorootparentprevYeah, you should see the Canada.ca design system[0]. It&#x27;s ultra-boring, but it works, and has been the same for a very long time (and I&#x27;d be happy if it doesn&#x27;t change much at all). Having such a simple design standard makes it so I can hit the website of any government service and understand how to \"parse\" the site and find my way around. I never have to relearn a totally new design language and information architecture, which is huge for me, as I cannot stand having to \"re-learn\" sites every couple years![0] https:&#x2F;&#x2F;design.canada.ca&#x2F; reply blitzar 2 hours agorootparentprevIf you write html properly - in 5 years do a minor tweak to the css and you have a new fresh look. reply bryanrasmussen 2 hours agorootparenthow will that help you keep employed though, better to have the css as part of your JS so any redesign is months of tiring work to earn those big consulting bucks!&#x2F;you may get the impression I&#x27;m bitter. reply blitzar 2 hours agorootparentMe too my friend, me too.(btw your solution is needlessly complicated and way too much hard work - easier to sit with the client, exhale deeply then say \"A full redesign? Thats quite a big project and its a lot of work, are you sure?\" offer a fixed rate contract assuming 100&#x27;s or even 1000&#x27;s of person-hours and deliver (after a polite overrun of a few weeks) the updated css.)&#x2F;you may get the impression I&#x27;m bitter and cynical. reply nine_k 8 hours agoparentprevI&#x27;d say that a good design should not look modern. It should look timeless. reply tacitusarc 8 hours agorootparentThat’s a pretty nice quip but not necessarily meaningful. reply high_5 1 hour agorootparentBut it is meaningful. The websites are being interfaced with pretty much timeless clients - people. We interact with the world with our body and process it with our brain. The world has the same physics laws all around the world, so it&#x27;s consistent. The virtual world is becoming anything but that. At least public services should become more consistent and change more slowly upon the most necessary changes. reply xyst 1 hour agorootparentprevWhich site is considered “timeless” to you? reply UberFly 8 hours agorootparentprevIt should lack both space and time to reach web 6.0 perfection. reply encomiast 4 hours agoparentprevIt does quite a few things well especially around helping website developers comply with section 508 accessibility requirements. They also do a lot of user testing a research which is reflected in the guidance for the various components. For example something as simple as asking someone to enter their name can be nuanced when dealing with a large diverse population: https:&#x2F;&#x2F;designsystem.digital.gov&#x2F;patterns&#x2F;create-a-user-prof... reply code_witch_sam 6 hours agoparentprevi&#x27;m not sure i would call this a \"big government initiative.\" this is pretty cheap, obvious stuff.you might pull an off-the-shelf component library for a demo app or even a startup, but the value of building in-house&#x2F;from-scratch in government, especially military, cannot be understated. the web ui ecosystem is rife with security risks and accessibility footguns.it looks fine to me. it&#x27;s a design system, not rocket science. reply the_mar 8 hours agoparentprevgov.uk til.gov reply euroderf 3 hours agoprevTables, but no treeviews. reply candiddevmike 10 hours agoprevInteresting LICENSE: https:&#x2F;&#x2F;github.com&#x2F;uswds&#x2F;uswds&#x2F;blob&#x2F;develop&#x2F;LICENSE.mdWonder why they decided to go with Material Icons vs building out their own icon library? US seems to have various glyphs all over the place, would be neat to see them consolidated in a standard icon library. reply pcurve 10 hours agoparentCreating icon set from scratch is rather difficult and time consuming. It also requires a lot of research to ensure usability. What ends up happening is designers will just start from existing icon set anyway to stay close to existing convention and mental model.I guess they felt it’s not the best use of their limited resources? reply moritzwarhier 10 hours agoparentprevIt also mentions Font Awesome. Probably better to build on ubuquitous icon sets instead of wasting taxpayers money on redesigning exclamation mark icons.This would cost a lot of money.They can still augment with custom icons where it actually matters. reply asoneth 5 hours agoparentprevProducing a bespoke icon library for a large organization can be shockingly expensive depending on how the organization is structured.I&#x27;ve worked on projects where dozens of different stakeholders needed to sign off on the icon library resulting in thousands of person-hours of design review meetings alone. If I could save millions of dollars by picking an existing icon library and adding only what is needed that seems like a smart move to me. reply rswerve 7 hours agoparentprevThere is a standard set. https:&#x2F;&#x2F;designsystem.digital.gov&#x2F;components&#x2F;icon&#x2F; reply candiddevmike 6 hours agorootparentThose are material icons reply azemetre 8 hours agoparentprevHow does public domain license compare to something like GPL? Isn&#x27;t public domain better? reply dhosek 7 hours agorootparentPublic domain allows you to do whatever you want with the work. GPL requires derivative works to also be GPL’d.As a matter of law, all copyrightable work done by Federal employees as part of their job is public domain. This is yet another loss to society in the trend towards privatizing government operations. reply vxNsr 6 hours agorootparentCan’t tell what you’re lamenting. reply wlesieutre 5 hours agorootparentIf the federal government designed their own icon set it would be available for anyone to use without license restrictions. Since they’ve decided to use someone else’s icon system, they aren’t making a public domain set of icons. reply encomiast 4 hours agorootparentBut also, since they’ve decided to use someone else’s icon system, taxpayers are not paying for yet another icon system, when an existing one under an Apache license is available. replydclowd9901 9 hours agoparentprevReally unfortunate. It’s not like we don’t have the will or capability. I’m hoping this is just while they iron out licensing agreements. reply glompers 9 hours agorootparentCould you or someone please help explain why a new icon library or license would be really fortunate compared to this choice? reply quickthrower2 8 hours agoprevI want this to be good. I would happily use something like this for my \"bootstrap\" knowing that a lot of thought has been put into it. reply mock-possum 7 hours agoprevIs it weird to anyone else how completely they avoid talking about the actual technologies involved? It just keeps saying “design system.”So… is it just a bunch of SASS files and icons? Or is it web components? Or is it react&#x2F;vue&#x2F;angular components? Are there tests? Is there a storybook?It seems like all that stuff should be front and center on the landing page reply Uehreka 6 hours agoparentIt’s not weird. When you’re dealing with an organization as big as the US government, you’re not going to be able to standardize on a single technology for front end engineering. So you say “Make all your stuff look like this” as an opening statement, and then secondarily work with certain large departments to implement the visual stuff (1em padding on modals, 5px rounded edges on cards, tooltips on icon buttons etc) in the technology that each is using.You won’t be able to get to everyone, but the people you don’t get to (say, the DEA weirdos using MooTools and Stylus) will at least have some guidelines they can follow instead of just coming up with styles on their own. reply petepete 6 hours agoparentprevIt&#x27;s a set of styles and guidance on how to use them in a universally accessible manner.You&#x27;re unlikely to build anything that&#x27;s usable by everyone using React&#x2F;Vue&#x2F;Angular. I mean, it is possible, but it&#x27;s hard enough to get right with plain HTML and CSS - adding a load of JavaScript to the mix just confuses matters. reply chevman 8 hours agoprev [–] It doesn&#x27;t look like anything in the github repo or change logs on the actual site itself have been updated in over a year.Is anyone still actively maintaining this effort? reply encomiast 4 hours agoparentIt’s quite active: https:&#x2F;&#x2F;github.com&#x2F;uswds&#x2F;uswds&#x2F;commits&#x2F;develop reply rswerve 7 hours agoparentprev [–] Latest release was three weeks ago. https:&#x2F;&#x2F;github.com&#x2F;uswds&#x2F;uswds replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The US Web Design System (USWDS) is a tool for the federal government that aids in creating accessible and mobile-friendly government websites.",
      "It offers components, patterns, design tokens, and utilities for designing and implementing user experiences.",
      "USWDS is an active open source community offering support to various government agencies and websites."
    ],
    "commentSummary": [
      "The US government has enacted the US Web Design System (USWDS) in an effort to modernize government websites and enhance digital services, mirroring similar initiatives in other countries.",
      "The discussion remains divided on the success of these projects, with core areas of contention involving usability, minimalist design, and the worth of standard systems and icon libraries.",
      "Debates surface around the use of public domain and GPL licenses in government operations, upon which concern and speculation are raised about employing existing icon systems and the expected technology maintenance."
    ],
    "points": 133,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1694375594
  },
  {
    "id": 37463662,
    "title": "A group of open source Android apps without ads and unnecessary permissions",
    "originLink": "https://www.simplemobiletools.com",
    "originBody": "Simple Mobile Tools Support this project Blog A group of simple, open source Android apps without ads and unnecessary permissions, with customizable colors. Simple Gallery Pro 110,470 Simple Calendar Pro 12,397 Simple Contacts Pro 2,921 Simple Notes Pro 2,813 Simple File Manager Pro 4,275 Other App From Our Hands Previous Keyboard Clock Launcher Camera Draw Music Player Dialer SMS Messenger Voice Recorder Flashlight App Launcher Calculator Keyboard Clock Launcher Camera Draw Music Player Dialer SMS Messenger Voice Recorder Flashlight App Launcher Calculator Keyboard Clock Launcher Camera Next 70M+ Downloads 24 Apps 4.6 Average Rating Discover the difference. Read our mission Support this project Let’s stay in touch! Your email address… Submit Replacing your Android apps one by one since 2016. Copyright © 2023, All Rights Reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=37463662",
    "commentBody": "A group of open source Android apps without ads and unnecessary permissionsHacker NewspastloginA group of open source Android apps without ads and unnecessary permissions (simplemobiletools.com) 147 points by laktak 3 hours ago| hidepastfavorite67 comments deng 1 hour agoOK, instead of answering in every Thread here:These apps have existed for many years now and the \"business model\" behind them has changed over the times. These apps are available on Google Play and F-Droid. Originally, the apps were completely free, and there was a \"Thank You\" app which you could purchase on Google Play. This \"Thank You\" app does almost nothing, it only allows you to change the color theme of the apps and is more meant as a \"donation app\" for the project.Then, in 2018, the author decided to develop \"Pro\" versions of the most popular apps: Gallery, Calendar, Contacts, File Manager, etc. They can be bought on Google Play. These apps are still fully open source, you can build them yourself if you want, but much easier: they are still published on F-Droid, including the \"Thank You\" app.Understandably, the author does not really advertise that everything he does is available completely for free on F-Droid. If you install it from there, please consider to donate. I find these apps to be usually excellent and have used them for years. reply brucethemoose2 32 minutes agoparentNothing wrong with that.Mindustry (a tower defense factorio supcom-ish game) follows a similar model. Its paid on Steam, its free and GPLv3 on GitHub (and Android), and there don&#x27;t seem to be many complaints about it.IMO more closed source devs need to follow this model, or the \"open source but proprietary\" model that&#x27;s working for Barotrauma. reply thijser 56 minutes agoparentprevIt seems the apps starting to enforce upgrades to pro in ~February of this year.On the AppBrain page you can see the rating nosedive from 4.6 stars (out of 5) to less than 2: https:&#x2F;&#x2F;www.appbrain.com&#x2F;app&#x2F;simple-gallery&#x2F;com.simplemobile... reply prmoustache 47 minutes agorootparent> It seems the apps starting to enforce upgrades to pro in ~February of this year.Only when installed from Google playstore. reply p0w3n3d 30 minutes agorootparentYeah but the price is symbolic... and maintaining app on Android, even without adding any features, requires some work to catch up on the changes made to the system reply pmontra 2 hours agoprevI used the file manager and the gallery apps but I stopped using them since they started to reduce functionality to nudge people to the paid versions. Of course there is nothing wrong in working for money, I do, but I replaced them with other open source and free as beer apps from F-Droid. Selling open source is hard. To put it mildly, there is lot of competition on price. Selling closed source is hard too, because of competition from open source.I&#x27;m using Material Files and Aves Libre now. Aves doesn&#x27;t have an editor and I&#x27;m using either the one from Samsung&#x27;s Gallery, which I can&#x27;t remove anyway, or Google&#x27;s Snapseed. Google can snoop on me with the OS and the other apps of them I&#x27;m using (almost only Maps) so I&#x27;m not worsening my privacy level too much. reply deng 1 hour agoparent> they started to reduce functionality to nudge people to the paid versionsYou get the \"Pro\" apps from F-Droid as well. reply dskrepps 1 hour agoprevI&#x27;m very discouraged when I click their Blog page and see headlines like \"Our best apps are now paid\" and \"Trial period.\" These apps have popups asking for support, which 100% are advertisements contrary to the thread title. Their apps which previously were free and received updates no longer get those updates and have been replaced with paid ones. This is a warning sign of enshittification and degradation of reliability. There are a multitude of ways they could someday stop updates to these apps too to replace them with another monetization scheme. reply j1elo 1 minute agoparentHaving to eat and the shitty business model (or lack thereof) of open source means that it is probably either that, or not having the apps at all. The author has written code and released it under liberal licenses for years, and now they want (or worse, need because their life conditions changed) some income from the effort.> they could someday stop updates to these apps too to replace them with another monetization schemeThe code is still being written and kindly released under the terms of an open source license, so if that happens, I&#x27;d expect that sufficiently motivated people moved by strong needs or ideals would be able to fork it and keep using (and possibly even improving) them without issue, as the license explicitly allows for it. reply deng 1 hour agoparentprevYou get the \"Pro\" apps from F-Droid, including the \"ThankYou\" App. I never got any nagging from them (and yes, I donated, but that did not have any technical consequences and is not necessary). reply dskrepps 1 hour agorootparentI want to recommend things everyone benefits from, not myself. Consequently, I don&#x27;t want to support anything that doesn&#x27;t trend the community toward my ideals.For instance, the Mastodon project and mastodon.social are run by a non-profit. They have their own mastodon account which discusses updates, advertises merchandise to support them, and could ask for sponsors or donations if needed. Users can subscribe to their feed if they want, and support them should they need help, while users who don&#x27;t want advertisements won&#x27;t be affected. I&#x27;m confident in the stability of this model for them so I chose to make my Mastodon account on their instance so I can trust I won&#x27;t have to transfer to another someday should one shut down.I&#x27;m hoping the digital space evolves in this direction and that we approach a post-advertisement economy.Otherwise, enshittification keeps ruining things and we can&#x27;t rely on the long-term stability of anything. Just look at Google. reply Animats 3 hours agoprevI use some of those via F-Droid, but I&#x27;ve stopped installing updates because the nagging to \"upgrade\" to a \"monetized\" version is getting worse.[1] I&#x27;m worried that they will start breaking the free versions, and thus can no longer trust their updates.[1] https:&#x2F;&#x2F;www.simplemobiletools.com&#x2F;blog&#x2F;our-best-apps-are-now... reply BLKNSLVR 1 hour agoparentIt sounds as if you&#x27;re actually using the apps installed from the playstore. If they&#x27;re from F-Droid you shouldn&#x27;t get any nagging or ads.I use gallery, contacts, and file manager from F-Droid, up to date, and no ads or nags at all, ever. reply figmert 2 hours agoparentprevIf you&#x27;re so inclined, the unlock is also pushed to F-Droid under Simple Thank You app. It&#x27;s by the same Dev. reply Rygian 3 hours agoparentprevSo it&#x27;s not \"apps without ads,\" but rather \"apps without third-party ads.\" reply thaumasiotes 2 hours agoparentprev> I use some of those via F-Droid, but I&#x27;ve stopped installing updates because the nagging to \"upgrade\" to a \"monetized\" version is getting worse.[1]Huh? The versions in F-Droid are the monetized versions. They don&#x27;t include any nagging. I&#x27;ve been using them for years. reply btzs 1 hour agoprevThis is a similar project from Karlsruhe University:Summary: All Privacy Friendly Apps:- are Open Source (GPLv3) and their source code can be viewed an Github by anybody- used minimal permissions- do not neither tracking mechanisms nor advertisementhttps:&#x2F;&#x2F;secuso.aifb.kit.edu&#x2F;english&#x2F;105.php reply m0shen 1 hour agoparentThe fitness apps looked exactly like what I need, but when going to the play store says they were made for an older version of Android. Visiting Github seems like they aren&#x27;t actively maintained either. reply mcv 58 minutes agorootparentFork them, I guess. That remains the main big advantage of open source.I&#x27;ve had closed source apps, even paid ones, disappear without a trace from my phone and tablets, presumably after an OS update. I find that an incredibly shitty thing to be subjected to. If an OS update is going break any apps, I&#x27;d like to be warned about that. reply weinzierl 2 hours agoprevIt&#x27;s sad that \"without ads and unnecessary permissions\" is so rare that it makes it to the HN front page. It really should be the other way around: \"A blacklist of apps with ads and unnecessary permissions\" should be newsworthy. reply visarga 2 hours agoparentApp stores are a wasteland. The vast majority of apps have \"in-app-purchases\" and try to nag users into paying a never ending stream of extras, or are filled with ads. Where are those simple apps that cost $1-$10, pay once, can use forever and have no ads?For example I am trying to put a game on my child&#x27;s iPad. The game is free but you only got one level open. If you want to play the other levels you got to pay. But it won&#x27;t simply unlock the game, no, only a small part. If you want more, pay more, there is no end to the \"buying\" phase. This is a no-go situation with children. They can be tricked into clicking these in-app sales and getting stuck there. And that&#x27;s what the developers want.I want once I pay for a game, to know that 1. it will never advertise upsells or anything else 2. it will never block access for any feature 3. there are no trick links, buttons or UI flows to get children into the buying side of the app. On AppStore I can only find the Apple Arcade games to be clean, and those are subscription based.The moral - I want to buy and have no choice of decent apps. How did we get into this mess after 15 years of App store evolution? reply akyuu 51 minutes agorootparentNintendo consoles seem to provide the experience you&#x27;re looking for. Clean and curated games with no ads or subscriptions. And the games tend to be of higher quality, focused on actual gameplay as opposed to the dark patterns common on phone apps (e.g. time-limited \"stamina\" and other psychological manipulation tricks to encourage addictive behavior). reply KronisLV 34 minutes agorootparent> Nintendo consoles seem to provide the experience you&#x27;re looking for. Clean and curated games with no ads or subscriptions.This mostly matches my experience, for example Nintendo Switch occasionally gets some critique for being a bit dated (apparently a new version is in the works), but it feels like a step up from mobile gaming and has all sorts of great games, from Legend of Zelda to Animal Crossing and even well made ports from other platforms.That said, there are also free games that do have aspects of monetization, but I think it&#x27;s easy enough not to save card details or anything like that.Honestly, I kind of wish the first Switch generation would hang around for longer and developers would keep making well optimized games for it. reply mcv 1 hour agorootparentprevI would really love to see a curated version of the Play Store that only lists the good apps and not the legion of shitty ones. reply NoZebra120vClip 6 minutes agorootparentprevI have found high-quality pay-once apps with no advertising, and I&#x27;ve done it with minimal effort.Unfortunately, it won&#x27;t do any good to recommend them to you, or their developers, because none of them are games, and the apps are so niche that nearly nobody on HN will want to purchase them anyway.But they do exist; they&#x27;re on the Play Store, hidden in plain sight. reply zem 16 minutes agoparentprevI have long wanted an app store that only carried ad- and unnecessary-permission-free apps, both free and paid. no one seems inclined to set one up though. reply q87b 2 hours agoprevWarning, the reaction to massive security issues in a bundled PDF reader of the file manager made me uninstall all of these apps. Safety of my device and data is paramount.https:&#x2F;&#x2F;github.com&#x2F;SimpleMobileTools&#x2F;Simple-File-Manager&#x2F;iss...https:&#x2F;&#x2F;github.com&#x2F;SimpleMobileTools&#x2F;Simple-File-Manager&#x2F;iss... where the developer shows no grasp of security \"what can happen to an app without internet access?\"A \"simple\" file manager should not come with a PDF reader. reply WithinReason 2 hours agoparentHe did remove the PDF functionality as a result reply lotophage 39 minutes agoprevI&#x27;m surprised at the amount of negativity in the comments. I use several of the tools and they are great. They do one thing well and don&#x27;t have the feature bloat that a lot of apps suffer from. reply crop_rotation 10 minutes agoparentHN is full of negativity against anything that is paid and is a consumer product. reply randunel 1 hour agoprevI recommend all of my friends and family to use this when searching for Android apps https:&#x2F;&#x2F;playsearch.kaki87.net&#x2F; and simply tick the 3 checkboxes at the bottom. reply zem 13 minutes agoparentthanks, that looks like an awesome resource! reply account-5 2 hours agoprevI use these apps from fdroid. Google, whilst not removed, is pretty much disabled on my device. Never had an issue.I think they are also moving into the device business too: https:&#x2F;&#x2F;simplephone.tech&#x2F;eu&#x2F;product&#x2F;simple-phone&#x2F; reply NGRhodes 2 hours agoparentSimplephone got abandoned. reply zootboy 3 hours agoprevI would be wary of using their calendar app. It has had a long-standing bug in basic timezone &#x2F; DST handling:https:&#x2F;&#x2F;github.com&#x2F;SimpleMobileTools&#x2F;Simple-Calendar&#x2F;issues&#x2F;... https:&#x2F;&#x2F;github.com&#x2F;SimpleMobileTools&#x2F;Simple-Calendar&#x2F;issues&#x2F;... reply prmoustache 44 minutes agoparentYour issues links point to bugs that have been closed. reply majewsky 27 minutes agorootparentOnly the first one has been closed, apparently because it is a duplicate of the second one which is still open. reply patwoz 2 hours agoprevI installed these apps on my mother&#x27;s smartphone (Motorola) after the existing apps became unusable because they slowed down or displayed large banner ads.Thank you for these great apps. I just donated to you :) reply zecg 1 hour agoprevYou can get their apps off f-droid, and their Gallery is the best one I&#x27;ve tried on Android. reply yCloser 3 hours agoprevI used to lovehttps:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.simplemobi...but now it is a \"14days free trial, then pay\" reply deng 2 hours agoparentInstall the version from F-Droid instead. reply friend_and_foe 53 minutes agoprevI use a his calendar and notes app. They&#x27;re great. Others I haven&#x27;t tried but I assume they&#x27;re pretty good too. reply UberFly 3 hours agoprevDo really like using many of their offerings. On f-Droid as well. reply throwaway-jim 2 hours agoprevI have had bad experience with their apps, I don&#x27;t particularly remember what it was as it was a few years ago but it was their notes app. They limit some basic features and push you to buy their premium versions. reply ktzar 2 hours agoprevPushing to buy premium version, so without ads is misleading. reply stoicfungi 1 hour agopreva while ago, I created this https:&#x2F;&#x2F;appswithcode.org&#x2F;?q=android to search apps with code. reply Woshiwuja 3 hours agoprevimagine having to pay 1 euro for no ads in your file browser lmao reply collaborative 3 hours agoparentimagine having to pay 0 euros for an ecosystem that monetizes your privacy and attention reply 77pt77 2 hours agoparentprevTotal commander is pretty good with no funny business.It&#x27;s \"ugly\" though.https:&#x2F;&#x2F;www.ghisler.com&#x2F;It even has plugins for ftp and I believe sftp. reply thot_experiment 2 hours agorootparentI didn&#x27;t realize there was an android version, I&#x27;ll have to take a look. I am incapable of using a windows computer without Total Commander, I&#x27;ve used it more than any other program, full stop. Probably since I was 4 or 5 years old. Life without it is unimaginable. reply 77pt77 1 hour agorootparentI didn&#x27;t know there was a Windows version.The Android version works great. I don&#x27;t know of a better alternative. reply lodovic 49 minutes agorootparentfun fact: Total Commander is inspired by Midnight Commander, which in its turn is a clone of Norton Commander, which was first released in 1986. reply komali2 3 hours agoparentprevWhat free file browser do you use that you&#x27;re sure isn&#x27;t snooping on your files? reply prirai 1 hour agorootparentMiXplorer, Material Files reply idle_zealot 2 hours agorootparentprevDolphin. Sometimes dired. reply prirai 1 hour agorootparentprevMaterial files, MiXplorer reply Rygian 3 hours agorootparentprevtermux ? reply komali2 3 hours agorootparentIs that a terminal emulator on android? That sounds... really obnoxious to use with my 2 thumbs lol. reply la_fayette 2 hours agoprevI cannot think of any open source endeavour, without finding monetization, to be sustainable... reply nologic01 2 hours agoparentWe live in monetary societies, you cannot live without money. What matters is the type of monetization. reply 2Gkashmiri 1 hour agoprevThe only simplemobiltools app I use on a Daly basis is gallery.No other app works reliably while this app is rock solid for what it does.I have attempted to give others a try but they had reduced functionality or bugs like dialer.Calendar works kinda but gallery is rock solid. reply aaws11 3 hours agoprevprevious discussion:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31490250 reply komali2 3 hours agoprev [–] Wait, people are upset that the compiled versions have free trials and then paid versions? I&#x27;m looking at the code for all these apps right now, you can compile your own apks and never pay a dime if you want, are people really upset about this monetization strategy? reply collaborative 2 hours agoparentUnfortunately, the vast majority of users don&#x27;t want to spend a dime on any digital good ever. In fact, they are very offended when asked to pay and will gladly leave 1 star reviews thinking that they are defending their interests. They won&#x27;t admit to it but they are instead paying with their privacy and attention. This is the reason we have tech monopolies financed by marketing and user data for sale on the dark net. And the worst bit of it all is that the current state of affairs is hopelessly irreversible reply crop_rotation 5 minutes agorootparentYou are absolutely right. Every HN thread about a consumer product that is paid is full of why it is bad, or why people would gladly pay if it had 10 more orthogonal features, or they have a better way to support the creator, or the product doesn&#x27;t deserve payment for some random reason but it is OK to use it without compensating the creator.The irony is a good % of HN is well paid due to information related jobs. And their work is valued only due to artificial scarcity of information. reply dskrepps 2 hours agoparentprevI personally don&#x27;t consider what my direct experience will be, but instead the total sum of the collective experience all users will have. I want to support something everyone benefits from, not myself. Consequently, I don&#x27;t want to support anything that doesn&#x27;t trend the community toward my ideals.As an example, the Mastodon project and mastodon.social are run by a non-profit. They have their own mastodon account which discusses updates, advertises merchandise to support them, and could ask for sponsors or donations if needed. Users can subscribe to their feed if they want, and support them should they need help, while users who don&#x27;t want advertisements won&#x27;t be affected. I&#x27;m confident in the stability of this model for them so I chose to make my Mastodon account on their instance so I can trust I won&#x27;t have to transfer to another someday should one shut down.I&#x27;m hoping the digital space evolves in this direction and we approach a post-advertisement economy.Otherwise, enshittification keeps ruining things and we can&#x27;t rely on the long-term stability of anything. Just look at Google. reply mohmans 2 hours agoparentprev [–] and I believe that the versions on F-Droid are the paid versions, so you can just install it from there for free instead of Google Play replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Simple Mobile Tools is a project featuring a range of basic open-source, ad-free Android apps with customizable colors offering alternatives to existing Android apps.",
      "The project includes apps like Simple Gallery Pro, Simple Calendar Pro, Simple Contacts Pro, Simple Notes Pro, and Simple File Manager Pro.",
      "The apps have collectively garnered over 70 million downloads and maintain an average rating of 4.6, indicating high user satisfaction."
    ],
    "commentSummary": [
      "Users are expressing discontent with app stores that offer apps with ads and in-app purchases, advocating for ad-free applications available at a fixed price.",
      "They are sharing experiences and features of various file browsing apps, and consider alternatives like Nintendo consoles or curated app stores for a cleaner user experience.",
      "The debate also covers challenges and strategies of monetization for digital products with a stated desire for more transparency and better options to support software creators sans advertisements."
    ],
    "points": 130,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1694413995
  },
  {
    "id": 37457208,
    "title": "What I have changed my mind about in software development",
    "originLink": "https://henrikwarne.com/2023/09/10/what-i-have-changed-my-mind-about-in-software-development/",
    "originBody": "Henrik Warne's blog Thoughts on programming… Skip to content HOME ABOUT ← Well-maintained Software What I Have Changed My Mind About in Software Development Posted on September 10, 20232 Comments I really like this quote from Jeff Bezos: “Anybody who doesn’t change their mind a lot is dramatically underestimating the complexity of the world we live in.” Lately I have been thinking about what I have changed my mind about in software development. Here are the things I came up with: Self-documenting code. I used to think that the names of the classes, methods and variables should be enough to understand what the program does. No comments should be needed. Over the years I have realized that some comments are needed and useful. These days I add comments when there is something particularly tricky, either with the implementation, or in the domain. Every time I came back to code where I wrote a comment, I am happy that I took the time to do it. I have written more about this in On Comments in Code. Unit testing private methods. I wrote a blog post called Unit Testing Private Methods, where I argued that you might as well make them package private, so you can easily write tests for them. However, several people commented and argued that you can test the private methods through the public interface. After a bit of thinking, I ended up agreeing with them, and changed my approach. Using an IDE. Many years ago, I was using Emacs when writing code. I was quite happy with that, and didn’t particularly feel that anything was lacking. However, one day my colleague Johan showed me what IntelliJ IDEA could do. I was sold, and never looked back. The biggest difference is navigation – it is so much easier to move around in a code base with one. Nowadays, I can’t imagine not using an IDE. I have written more on this in Programmer Productivity: Emacs versus IntelliJ IDEA. Using a debugger. I like trouble shooting using log statements and printf. It is simple and effective, and works in many situations. However, when I started writing Go code several years ago, my colleague Erik showed me how nice it is to explore the state of the program when a test case fails. I had used debuggers before, but he showed me a great use case for them. Working remotely. Even during the pandemic, when I was working from home full time, I was skeptical of working remotely. However, I have changed my mind, and I now think working from home is great. The downside is still that I miss the face-to-face interactions. But working remotely allows me to work for companies I previously could not work for. Not having to commute is a another big plus. On balance, I think the advantages outweigh the disadvantages. Using ChatGPT. When ChatGPT came out, I was impressed with what it could do. However, I was a bit skeptical of exactly how it would work in software development. But my colleague Filip kept telling me of all the cases where he used ChatGPT to help with development. So I decided to put some more effort into seeing how I could use it. For me, the main use has been for minor stand-alone tasks. For example, to generate a first draft of a Python script, to write a SQL INSERT/UPDATE trigger, or giving me a sed regular expression that removes the initial time stamp (when present) from log lines. In all these cases, it has been a great time saver. Conclusion Am I changing my mind about enough things? I don’t know. But it is definitely worthwhile to once in a while examine your beliefs about how to develop software. In many of the above cases, it took somebody else to show me, or convince me, of other ways of working. My conclusion is that collaboration and pair programming is important for spreading good ideas. What have you changed your mind about when it comes to software development? Let me know in the comments. SHARE THIS: TwitterFacebookLinkedIn RELATED Well-maintained Software April 23, 2023 In \"Programming\" Working as a Software Developer December 12, 2012 In \"Learning\" 20.5 Years of XP and Agile April 27, 2020 In \"Programming\" This entry was posted in Learning, Programming and tagged learning, programming. Bookmark the permalink. 2 RESPONSES TO “WHAT I HAVE CHANGED MY MIND ABOUT IN SOFTWARE DEVELOPMENT” Henrik WarneSeptember 11, 2023 at 8:05 amReply Hacker News discussion: https://news.ycombinator.com/item?id=37457208 Henrik WarneSeptember 11, 2023 at 8:07 amReply https://www.reddit.com/r/programming/comments/16fmgl6/ LEAVE A REPLY MOST POPULAR Lessons Learned in Software Development Top 5 Surprises When Starting Out as a Software Developer Working as a Software Developer Great Programmers Write Debuggable Code What Makes a Good Programmer RECENT POSTS What I Have Changed My Mind About in Software Development Well-maintained Software Algorithmic Trading: A Practitioner’s Guide There Is No Software Maintenance Switching to Go – First Impressions Effective Software Testing – A Developer’s Guide On Code Reviews Book Review: A Philosophy of Software Design On Comments in Code 4 Things I Like About Microservices Recruiting Software Developers – Coding Tests More Good Programming Quotes, Part 5 6 Small Unit Testing Tips Mathematical Modelling of Football Deployed To Production Is Not Enough Good Logging Working From Home – Cons and Pros Artificial Intelligence – A Guide for Thinking Humans 20.5 Years of XP and Agile Secure by Design More Good Programming Quotes, Part 4 Grokking Deep Learning EuroSTAR Testing Conference Prague 2019 Classic Computer Science Problems in Python When TDD Is Not a Good Fit Recruiting Software Developers – Checking Out a Company Book Review: Designing Data-Intensive Applications Nordic Testing Days Tallinn 2019 Book review: Accelerate More Good Programming Quotes, Part 3 Programming: Math or Writing? Developer On Call My Favorite Command-Line Shortcuts 6 Git Aha Moments Is Manual Testing Needed? Exercises in Programming Style Programming for Grade 8 6 Years of Thoughts on Programming Benefits of Continuous Delivery More Good Programming Quotes, Part 2 Developer Testing Programming Conference – QCon New York 2017 Developers – Talk To People Code Rot Programmer Career Planning Software Development and the Gig Economy Book Review: The Effective Engineer Things Programmers Say Developer Book Club Book Review: Release It! 18 Lessons From 13 Years of Tricky Bugs Learning From Your Bugs More Good Programming Quotes The Wisdom of Programming Quotes Ph.D. or Professional Programmer? Social Engineering from Kevin Mitnick Recruiting Software Developers – Initial Contact Coursera Course Review: Software Security Lessons Learned in Software Development Book Review: Clean Code Coursera Course Review: Computational Investing Part 1 Programmer Knowledge 5 Reasons Why Software Developer is a Great Career Choice A Response to “Why Most Unit Testing is Waste” What Makes a Good Programmer? Switching from Java to Python – First Impressions Antifragility and Software Development 5 Unit Testing Mistakes Unit Testing Private Methods A Bug, a Trace, a Test, a Twist Session-based Logging Finding Bugs: Debugger versus Logging TDD, Unit Tests and the Passage of Time Automatically Include Revision in Log Statement 7 Ways More Methods Can Improve Your Program LinkedIn – Good or Bad? Great Programmers Write Debuggable Code SET Card Game Variation – Complementary Pairs Programmer Productivity – Interruptions, Meetings and Working Remotely What Do Programmers Want? Coursera course review: Algorithms: Design and Analysis, Part 2 Blog stats for 2012 (by WordPress) Working as a Software Developer 4 Reasons Why Bugs Are Good For You Book Review: How Google Tests Software Top 5 Surprises When Starting Out as a Software Developer Programmer Productivity: Emacs versus IntelliJ IDEA Why I Love Coding Coursera course review: Design and Analysis of Algorithms I Mac OS X Break Programs Review Favorite Programming Quotes How I Beat Repetitive Stress Injury Introduction to Databases – On-line Learning Done Well 10 million SET games simulated using “Random among ‘most similar’ Sets” 10 million SET games simulated using “Random among available Sets” 10 million SET games simulated using “First found Set” SET® Probabilities Revisited TAG CLOUD algorithms book book review break program bugs career code coding conference coursera creativity databases debugging developer testing DevOps emacs ergonomics face to face Google hiring ide idea integration testing intellij interruption job knowledge learning linkedin logging love machine learning Mac OS X meeting meta methods office on-line course probabilities production software productivity professional software development programmer programming programming course programming job python quotes recruiting refactoring Repetitive Stress Injury review revision RSI security SET game simulation software development statistics stats stretches subversion surprises svn tdd test-driven development testing time trouble-shooting unit-test unit testing university version work working RSS RSS - Posts RSS - Comments FOLLOW BLOG VIA EMAIL Enter your email address to follow this blog and receive notifications of new posts by email. Email Address: Follow Join 368 other subscribers Create a free website or blog at WordPress.com. Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37457208",
    "commentBody": "Hacker NewsHacker NewsWe're having some trouble serving your request. Sorry!",
    "originSummary": [
      "The author shares his evolving views on topics in software development such as commenting in code, unit testing of private methods, and the use of Integrated Development Environments (IDEs) and debuggers.",
      "The author also discusses the advantages of remote work and utilizing ChatGPT, an AI language model developed by OpenAI, for certain tasks.",
      "The importance of collaboration and openness to new ideas in software development is underscored in the post."
    ],
    "commentSummary": [],
    "points": 120,
    "commentCount": 186,
    "retryCount": 0,
    "time": 1694362331
  },
  {
    "id": 37455106,
    "title": "The molecule DIM reduces biofilms causing dental plaque: study",
    "originLink": "https://scitechdaily.com/90-reduction-scientists-discover-natural-molecule-that-eradicates-plaques-and-cavities/",
    "originBody": "HOME ABOUT CONTACT NEWSLETTER TRENDING NEWS Facebook Twitter YouTube Pinterest Newsletter RSS BIOLOGY CHEMISTRY EARTH HEALTH PHYSICS SCIENCE SPACE TECHNOLOGY HOT TOPICS SEPTEMBER 10, 2023NEW STUDY: WE ARE WASTING UP TO 20 PERCENT OF OUR TIME ON COMPUTER PROBLEMS SEPTEMBER 10, 2023HUMANITY ON THE BRINK: GENOMIC RESEARCH UNEARTHS STARTLING DECLINE IN HUMAN ANCESTOR POPULATIONS SEPTEMBER 10, 2023A “DOUBLE SHOT” OF STRENGTH: HOW USED COFFEE GROUNDS REINFORCE CONCRETE SEPTEMBER 10, 2023GROUNDBREAKING QUANTUM LEAP: PHYSICISTS TURN SCHRÖDINGER’S CAT ON ITS HEAD SEPTEMBER 10, 2023REDEFINING EARTH’S CORE: SYNCHROTRON REVEALS HIDDEN LIGHT MATERIAL SEARCH FOR: HOMEHEALTH NEWS 90% Reduction: Scientists Discover Natural Molecule That Eradicates Plaques and Cavities TOPICS:BacteriaBen-Gurion University Of The NegevDentistryNational University Of SingaporePopularTeeth By BEN-GURION UNIVERSITY OF THE NEGEV SEPTEMBER 8, 2023 Scientists have discovered that the molecule DIM reduces biofilms causing dental plaque by 90%. Its addition to toothpaste and mouthwash could revolutionize dental hygiene. The 3 Most Secretive Zodiac Signs #astrology #zodiac 3,3′-Diindolylmethane (DIM) decreased the Streptococcus mutans biofilm, a leading contributor to plaque and cavities, by 90%. A significant portion of the global population experiences persistent issues with dental plaque and cavities or will face them at some time. While toothpaste, mouthwash, and routine dental visits help in prevention, there’s always room for improvement. Researchers from Ben-Gurion University of the Negev, in collaboration with teams from Sichuan University and the National University of Singapore, have identified that 3,3′-Diindolylmethane (DIM) – a naturally occurring molecule also referred to as bisindole – can reduce biofilms responsible for plaque and cavities by a remarkable 90%. The molecule is also found to have anti-carcinogenic properties. Their findings were recently published in the journal Antibiotics. Your mouth is a great reservoir for bacteria such as S. mutans, which is believed to be one of the primary actors in dental cavities. S. mutans grows in the moist and sugary atmosphere of your mouth after food in a biofilm that coats your teeth. Biofilm generates plaque, attacks enamel, and causes cavities. The scientists found that the bisindole (DIM) disrupted that biofilm by 90% and therefore the bacterium was not given a chance to grow. “The molecule, which was found to have low toxicity, could be added to toothpastes and mouthwashes to greatly improve dental hygiene,” says lead author Prof. Ariel Kushmaro of the Avram and Stella Goldstein-Goren Department of Biotechnology Engineering. He is also a member of the Ilse Katz Institute for Nanoscale Science and Technology and the Goldman Sonnenfeldt School of Sustainability and Climate Change. Reference: “3,3′-Diindolylmethane (DIM): A Potential Therapeutic Agent against Cariogenic Streptococcus mutans Biofilm” by Yifat Baruch, Karina Golberg, Qun Sun, Karina Yew-Hoong Gin, Robert S. Marks and Ariel Kushmaro, 6 June 2023, Antibiotics. DOI: 10.3390/antibiotics12061017 The study was conducted with his student Yifat Baruch, and Dr. Karina Golberg, as well as Prof. Robert S. Marks of the same department and Qun Sun of Sichuan University, and Karina Yew-Hoong Gin of the National University of Singapore. The research was supported by the International Research and Development Program of Sichuan (2019YFH0113) and SMART innovation grant ING-000398 (Singapore). SHARE TWEET REDDIT EMAIL SHARE Previous postNext post MORE ON SCITECHDAILY HEALTH Tooth Decay Surprise: New Bacterial Culprit Discovered SCIENCE New Fluoride-Free Toothpaste Is Just As Effective at Cavity Prevention HEALTH 6 Ingredients in Toothpaste to Avoid BIOLOGY Evolution Discovery: No Social Distancing at the Beginning of Life BIOLOGY “Simple” Bacteria Found To Organize in Surprisingly Elaborate Patterns HEALTH Plaque Identifying Toothpaste May Prevent Heart Attacks and Strokes SPACE Biofilms in Space and the Risks to Equipment and Astronauts BIOLOGY New Imaging Technique Reveals Possible Plan of Attack for Bacterial Diseases 30 COMMENTS ON \"90% REDUCTION: SCIENTISTS DISCOVER NATURAL MOLECULE THAT ERADICATES PLAQUES AND CAVITIES\" skabSeptember 8, 2023 at 7:48 amReply It’s a useful achievement in dental hygiene & care. Can’t wait to have it as an ingredient of daily dental care products like toothpaste, mouthwash, etc. JSSeptember 8, 2023 at 11:14 amReply I’m curious what it does with the good and critical bacteria in your mouth you dont want to get rid of. Esther ASeptember 10, 2023 at 12:09 pmReply Thats what I was thinking plus the gut bacteria. JohnSeptember 8, 2023 at 5:53 pmReply Parodontax seems to work well. Would this do a better job? WinnaSeptember 8, 2023 at 6:07 pmReply For anyone unaware, DIM is a compound found in broccoli. JojoSeptember 9, 2023 at 12:57 amReply I eat broccoli almost every evening. Didn’t prevent cavities for me. LeighSeptember 9, 2023 at 9:28 amReply IKR? I guess we’re brushing away the DIM with fluoride toothpaste. Would have to be in a form that is intended to stay on the teeth. Antonio Bragança MartinsSeptember 8, 2023 at 6:32 pmReply The natural molecule is called baking soda! I have used it for 20 years and I haven’t plaques or cavities! But your dentist don’t want you know it! PraksSeptember 8, 2023 at 10:40 pmReply Does not it spoils tooth enamel Dr DSeptember 9, 2023 at 5:13 pmReply You don’t have plaques because you’ve never achieved anything, especially, an understanding of oral health. It’s plaque (singular). I’m a dentist and do want to prevent plaque and dental Carie’s in my patients. JojoSeptember 9, 2023 at 12:58 amReply It will take 10-15 years to get this in toothpaste. How about re-growing teeth? They have been working on that for decades. If Sharks can do, we should be able to do it. Memory LaneSeptember 9, 2023 at 6:36 amReply I totally agree, & have in fact had that very same thought as well! Plus we lose one set of teeth already, so we must somewhat have the capability already! BatgirlSeptember 9, 2023 at 1:39 amReply They won’t want us to have it. These guys have made tons of money off of us for years… you think they are just gonna give it up?? Highly unlikely. RyanSeptember 9, 2023 at 2:37 amReply I’m guessing the DIM in broccoli and other cruciferous veggies isn’t really broken down in your mouth as you’re chewing. It’s sold in Capsules so one could easily just open the capsules and dip your brush in it. Another question is if it disrupts biofilm, could it be used to help stop surgical site infections? MimiSeptember 9, 2023 at 4:51 amReply Dental floss and brushing teeth with nothing on it is doing best job. Adding a flavour of a toothpaste is just changing your morning taste and smell. That is all a toothpaste doing. All what is in it, going to your stomach so be aware of its content. Keep simple and clean will bring you health and cavity free. Adding “stuff” growing pockets only. Dr K N THOMASSeptember 9, 2023 at 2:55 amReply Great Findings ESeptember 9, 2023 at 6:52 amReply I have a cousin who had 3 sets of teeth. RyanSeptember 10, 2023 at 4:27 pmReply People have the buds to grow a 3rd set, and scientists are researching how to jumpstart the growth. Very recent discovery. George AndersonSeptember 9, 2023 at 9:03 amReply I have found the same results and possibl, but much more economical the controls Staphylococcus A.bacteria that causes tooth decay, heart plaque, boils on the skin, atopic dermatitis, eczema, hemroids and several other Staph. A. infections. The natural product does not cause erosion of enamel on the teeth. BradySeptember 10, 2023 at 5:13 amReply Would you be willing to share what this natural product you found to be this beneficial is? And the method on how to use it for the best desired results? Thanks so much!, if you can share that information, you would be helpful to so many people perhaps. Your wrongSeptember 9, 2023 at 9:24 amReply Your taking it at face value put some thought into it they are obviously increasing the DIM up to levels where it takes effect hence them saying it’s low in toxins so this is an Optimal choice RichardSeptember 9, 2023 at 11:29 amReply The folks deep in some small villages in Ugandan,seem to have naively been aware of the benefits of certain plants thus the strong healthy white teeth they posses. MarkSeptember 9, 2023 at 2:05 pmReply Don’t hold your (bad) breath. They often come up with these findings in Israel and they’re almost never implemented. DavidSeptember 9, 2023 at 2:45 pmReply So I went tobthe dentist a year ago (I’m aged 45) and had zero issues with my teeth. Now, I had gone for years with brushing maybe 2 to 3 times per month. Never had had breath, never in my life had cavities or any other issues. Dentist said they “hate” people like me and chalked it up to genetics. Makes me wonder what my body does differently thanb5he other 90% of the population. Stephen mucciniSeptember 9, 2023 at 3:56 pmReply Dentists wouldn’t like this to go public….. CholoSeptember 9, 2023 at 5:31 pmReply Okay but what happens if you swallow it? Any studies on that? RyanSeptember 10, 2023 at 4:30 pmReply Umm… DIM is a common Supplement take to to help with estrogen control. Do people ever bother to research something before they post. DanielSeptember 9, 2023 at 6:12 pmReply Ah, great! Another Fluoride to slowly poison the children… RyanSeptember 10, 2023 at 4:34 pmReply Did you even bother to Google dim? What it comes from (cruciferous veggies) and what it does? My guess is no. SimplySeptember 10, 2023 at 1:20 pmReply LIFE IS COMPLEX LETS NOT MAKE IT COMPLICATED AND HARD GO BACK TO THE BASICS. WHERE ITS EASY TO GAIN THE NEED WHICH IS IN UNDERSTANDING THAT IT TAKES TWO TO GAIN ANY AND EVERYTHING! GIVEN TO TAKE GIVES MOTION I had a nasty cut on my schin that became infected and 8 months RX’d a variety of antibiotics yet to no avail. In my own research I FINALLY tried putting white table sugar on the wound. Which kept a white film on top not giving way to scab over; the morning after I put the table sugar on top, miraculously the white film was GONE! I SPRINKLED MORE SUGAR ON TO IT FOLLOWED WITH MANUKA HONEY and later SAME afternoon it grew a scab. Repeated that the following day at which the 1″ diameter wound that was almost to my bone, was as a fraction a size. In a matter of 4 days the cut was HEALED! HEALED it’s been a little over a year and there is minimal scar. I have never before this wound took a “full course” of antibiotics either, EXCEPT during this time of attempting to heal this wound. Wherein antibiotics did not help. I have come to conclusion that the antibiotics gave more harm than help. When either my child or I feel like we are coming down with an illness, we take in combination extra ZINC & L-LYSINE. My child is now 16 1/2 and has only taken an antibiotic 2 times in life. At which NEVER had a “full” course of either. Once the “symptoms” are gone it is immediately stopped. Never have we had a “recourse”. Knock on wood neither of us have had Co-vid and we have been around others who have had it. Neither of us get the flu or co-vid Vaccines either. We also are not fanatics in with washing our hands after everything we touch or in using hand sanitizers. My child was born with congenital differences where we had genetic tests done was told we both have a gene variant that aids in prevention of the flu; idk I’m not a scientist. Only I do know we humans are all different where I believe the proper term is just UNIQUE. In summary I think the issue came from a problem where the solution stemmed gave to the change where it became problematic. Due to the lack of respect was not given the equally. Where all give differently we give to the same where in the combination of us together gives the one fact where the problem holds to the value called the EQUAL. WHERE THE SOLUTION DID NOT GIVE TO ALL EQUALLY FOR ONE TOOK THE GREATER VALUE SOLVING THE PROBLEM FOR SELF LEAVING OTHERS WITH LESS OF THE GAIN.THE GIVEN PROBLEM WAS NOT RESOLVED. WHERE THE SOLUTION GAVE WAY TO ONE CAME BY ANOTHER WHO SAW MANY HAD A SIMILAR NEED HE FOR TOOK THE OPPORTUNITY TO TAKE FOR HIMSELF SO HE TOOK THE LEAD. WHERE THOSE IN NEED HAD SEEN THE WAY HE SOLVED PROBLEM FOR ONE THEY GAVE THEIR TRUST TO HIM NOT THINKING TO FIRST GAIN THE TRUTH IN UNDERSTANDING WHERE THE DRIVING FORCES STEMS. SO THIS ONE GAVE THE SAME AS HE GAVE TO THE OTHER WHICH BECAUSE WE ARE ALL DIFFERENT THE SOLUTION DID NOT SOLVE THE PROBLEM DUE TO OUR DIFFERENCES. WHICH LED TO THE WAYS OF CHANGE THAT IS GIVEN FROM TIME. FOR THE TRUTH IS OUR ABILITY TO CHANGE COMES BY TIME. WHERE THE MOTION THAT GIVES COMES FROM TWO FIELDS THAT CAME WITH NEED WHERE EACH HOLD EQUAL TO THE SAME WHERE BY GIVING SERVES THE ONE PURPOSE. EQUALLY GAIN THE INTEREST WHERE YOU HAVE BEEN GIVEN THE CHOICE TO GIVE YOUR ATTRIBUTE TO ONE SIDE OR THE OTHER. AND SINCE WE ARE HUMANS WE DO MAKE MISTAKES. THE WAYS OF THE FOOL HAS THE SAME POWER AS THE WISE OF THE WISE. ITS ALL IN THE MANNER OF COMMUNICATION. SEE WE SIMPLY ARE ALL REACTING TO THE FACT WHERE BY TWO WE HAVE BECOME ALIVE. AT OUR OWN START OF OUR OWN JOURNEY IS THE BEGINING TO WHERE IN ANY GIVEN MOMENT OUR ABILITY TO CHOOSE WILL CHANGE SIMPLY BT THE GIFT FROM TIME. WHERE ALL LIVING WILL COME TO THE END BY DEATH. LIFE BELONGS NO ONE IT IS SHARED. No One’s Journey has the ability to “survive” Life living! We have the ability to give all that we are given towards the betterment of all. Accepting the facts that in the given lies the the truth no matter if you like it or not it’s just the reality where we are different we get just the same equally. Their are many many factors in play that change the value in the same given that makes a world of difference! Where in reality when one does not share the all they know in sharing the full details in the given fact creates the way where in the given truth leads to a false understanding where the the true value becomes where the given perception is not true in the truth lies in reality time gives the changes. The wolf in sheeps clothing speaks in a manner that gives the deception controlled by the negative who takes for their self. While they taunt I EARNED IT MYSELF BY GIVING MORE EFFORT, IS SIMPLY A ILL MANNERED FOOLISH INDIVIDUAL WHO HAS BEEN FOOLED BY THE FOOL! ITS THE NEGATIVE THAT TAKES AWAY FROM THE WHERE THE FORCE OF POSITIVE IS HURTING & STRUGGLING NOT HEALED OR HELPED. ITS A LACK OF RESPECT DUE TO THE GREATER of RESPECT IS GIVEN TO THE LOVE OF SELF. Where one will eventually take it all for self. ONE SELF will eventually become starved, weakened and weary. There will be no reason of purpose. NO driving force for will to change. There is nothing that gives to receive. Alone and lonely, no joy in giving no joy to receive. No respect to earn No respect to gain. Love the love of life is gone. The fooled fooled you to act foolishly taking for self not giving the respect to others who you did not see them as equal value. AND so no one is left Life has left and to hell with the ways of wicked! Change give back all you got it’s the way to gain anyways. Life is complex learn to accept the interesting ways of the wise where the interest is gives to best where in better is just that it’s BETTER!! There is no less nor more in the FACT THAT GIVES THE EQUAL. THE VALUE IS EITHER MORE OR LESS.PERIOD. ITS THE DESIGN OF NATURE GREED is the root of evil wherein the given perception of Life has not been thought about in the PROPER ORDER OF PERSPECTIVE. WHERE ALL EQUALLY ALL GIVE TO VALUE WHERE IN LIFE GIVES TO ALL A DIFFERENT VALUE IT IS IN THE SAME WHERE ALL RECIEVE EQUALLY. NONETHELESS YOUR CHOICE MAKES A DIFFERENCE EITHER IT GIVES THAT ENABLES OR TAKES WHICH DISABLES. Leave a comment Email address is optional. If provided, your email will not be published or shared. Comment Name Email Save my name, email, and website in this browser for the next time I comment. SUBSCRIBE SciTechDaily: Home of the best science and technology news since 1998. Keep up with the latest scitech news via email or social media. > Subscribe Free to Email Digest report this ad POPULAR ARTICLES SEPTEMBER 8, 2023 A Sense of Order – The Unique Trait That Sets Us Apart From Other Animals Remembering the order of information is crucial when engaging in dialogues, organizing daily activities, or pursuing education. A recent study in the scientific journal PLOS… READ MORE SEPTEMBER 8, 2023 Scientists Discover Simple Way to Boost the Effectiveness of Popular Emergency Contraceptive Pill SEPTEMBER 8, 2023 Uncharted Solar Realms: Camera “Hack” Lets Solar Orbiter Peer Deeper Into Sun’s Atmosphere SEPTEMBER 8, 2023 Fundamental Biology Overturned: New Discovery Challenges Long-Held Views on “The Second Brain” SEPTEMBER 8, 2023 Fact vs. Fiction – Scientists Debunk 6 Popular Hypnosis Myths SEPTEMBER 8, 2023 90% Reduction: Scientists Discover Natural Molecule That Eradicates Plaques and Cavities SEPTEMBER 8, 2023 Scientists Discover Unexpected Pathway to Batteries With High Energy, Low Cost, and Long Life SEPTEMBER 8, 2023 New Study Uncovers Unexpected Side Effect of Daily Aspirin Usage in Older Adults TAGS Artificial Intelligence Astronaut Astronomy Astrophysics Behavioral Science Biochemistry Biotechnology Black Hole Brain Cancer Cell Biology Climate Change Cosmology COVID-19 Disease DOE Ecology Energy European Space Agency Evolution Exoplanet Genetics Harvard-Smithsonian Center for Astrophysics Hubble Space Telescope Infectious Diseases International Space Station JPL Mars Materials Science Max Planck Institute MIT Nanotechnology NASA NASA Goddard Space Flight Center Neuroscience Nutrition Paleontology Particle Physics Planetary Science Planets Popular Public Health Quantum Physics Virology Yale University report this ad report this ad FOLLOW SCITECHDAILY Facebook Twitter YouTube Pinterest Newsletter RSS SCITECH NEWS Biology News Chemistry News Earth News Health News Physics News Science News Space News Technology News LATEST NEWS New Study: We Are Wasting Up to 20 Percent of Our Time on Computer Problems Humanity on the Brink: Genomic Research Unearths Startling Decline in Human Ancestor Populations A “Double Shot” of Strength: How Used Coffee Grounds Reinforce Concrete Groundbreaking Quantum Leap: Physicists Turn Schrödinger’s Cat on Its Head Redefining Earth’s Core: Synchrotron Reveals Hidden Light Material SCIENCE NEWS CONTACT EDITORIAL BOARD PRIVACY POLICY TERMS OF USE COPYRIGHT © 1998 - 2023 SCITECHDAILY. ALL RIGHTS RESERVED. × We and our partners share information on your use of this website to help improve your experience. Do not sell my info: Okay",
    "commentLink": "https://news.ycombinator.com/item?id=37455106",
    "commentBody": "The molecule DIM reduces biofilms causing dental plaque: studyHacker NewspastloginThe molecule DIM reduces biofilms causing dental plaque: study (scitechdaily.com) 112 points by hanniabu 22 hours ago| hidepastfavorite90 comments dlg 20 hours agoThere was a version of streptococcus mutans developed that didn’t produce tons of lactic acid and would have pretty much ended tooth decay back in 2000. Iirc, it was built to outcompete the regular bacteria too. As far as I can tell there’s been no progress in commercializing this-—I assume because of the cost and complexity of FDA approval.E.g., https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;12369203&#x2F; reply tyre 17 hours agoparentLooks like that research led the lead author to found a company[0] and develop a probiotic tablet[1]. Seems like it could be worth trying.[0]: https:&#x2F;&#x2F;www.dentistryiq.com&#x2F;dentistry&#x2F;oral-systemic-health&#x2F;a...[1]: https:&#x2F;&#x2F;probiorahealth.com&#x2F; reply Obscurity4340 17 hours agorootparentNo way?! Great find, dude. I wonder if anyone can comment about it specifically or if it might be worthwhile to start a thread soliciting users experience... reply lisper 16 hours agorootparentI&#x27;ve never tried it but I see cause for skepticism: the claim is that these beneficial bacteria will out-compete the harmful ones. But if that&#x27;s true, why would it take 30 days for them to get established? One shot of Listerine to kill what&#x27;s there now, then one batch of the good critters to get them started, and, if the claims are true, you should be set for life, right? So something doesn&#x27;t add up. reply Obscurity4340 16 hours agorootparentDoesn&#x27;t your body have a reservoir of your microbiome throughout your body (like in the appendix or whatever)? Is it that far-out that some of the mouth stuff makes it there as well? Keep in mind, these bacteria have probably adapted and co-evolved over our development as a species, they must be fairly hardy and well-positionedNot qualified to argue with your very logical position here but I feel like it might be a longer-term transition and there might still be hold-outs if its only a one-and-done deal like you&#x27;ve described.Mea culpa tho, I definitely want to believe reply lisper 16 hours agorootparent> I definitely want to believeMe too. Nothing would make me happier than for someone to show me why I&#x27;m wrong here. reply Obscurity4340 16 hours agorootparentIt totally makes sense as a real-life conspiracy theory too, although I&#x27;m not super familiar with the ADA&#x27;s exploits. Obviously, dentists have an enormous amount to lose if something like this ever escaped the laboratory, so to speak. reply lisper 15 hours agorootparentThat&#x27;s true, but if it really were the case that you could stop cavities and gum disease by popping a pill that was already on the market I don&#x27;t see any way they could stop it. I also think that there are a few ADA members who actually care about people&#x27;s dental health, and if they thought that there was a conspiracy to suppress such a thing, they would have said so.Like I said, nothing would make me happier than to be proven wrong about this. But right now my money is on the things-that-sound-too-good-to-be-true-usually-are theory. reply rdedev 16 hours agorootparentprevIt could be the case that these specific strain of good bacteria does not last long enough in the mouth for some reason. For example they could mutate or they might not have the capability to attach itself to the tooth surface for long enough.In their website they claim that within 30 days the good bacteria will outcompetes the bad one. I don&#x27;t think you can stop taking the tablets after those 30 days completely to keep tits benefits. Those bacteria might die down over a course of a few months for various reasons. reply lisper 16 hours agorootparentWhat do you think \"outcompete\" means in the context of evolutionary biology? Something is going to set up shop in your mouth; it&#x27;s just too attractive an environment to be left fallow. Whatever that ends up being without intervention has by definition outcompeted all the other contenders. So if the good bacteria don&#x27;t persist, then by definition they have not \"outcompeted\" the competition. reply rdedev 11 hours agorootparentGuess the main point is the environment itself changes depending on what you do and what you eat. So you need to constantly resupply the initial good bacteria for them to keep holding on reply lisper 10 hours agorootparent> you need to constantly resupply the initial good bacteria for them to keep holding onThen unless your mouth ends up bacteria-free, the good bacteria are by definition not out-competing the bad ones. reply darkclouds 13 hours agorootparentprevZinc starves bacteria via a variety of means, and a high zinc intake will see high levels of zinc in the saliva and in the teeth, helping to keep bacterial levels down, but RDA&#x27;s are highly conservative amounts for young healthy people, not old or ill people, which then makes some RDA&#x27;s woefully inadequate.Very few products kill 100% of bacteria, even deionised water will still have less than 25 colony forming bacteria per litre in it, although by virtue of being deionised has less in it to help bacteria get established. Acidifying water will make it harder for pseudomonas to get established. But when scientists say they are searching for life on mars or an asteroid, they are referring to bacteria, mainly the bacillus aka rod shaped bacteria as it can survive in radiation 100,000 times more than humans can survive in, and extreme cold like space, so global warming and melting ice at the poles presents new viral and bacterial risks.Diet can also reduce the body&#x27;s own immune response, for example calcium disodium ethylene diamine tetra-acetate aka Calcium disodium EDTA found in a variety of products from makeup to food like Mayonnaise chelates zinc reducing zinc&#x27;s ability to activate GPR39.Zinc&#x27;s inability from deficiency or chemicals like the one mentioned above, from being able to activate GPR39, creates a myriad of problems in human health, including reducing saliva production. [1]There isnt anything wrong with using bacteria to out compete other bacteria, but adaptions occur.Phages are viruses that kill bacteria, something the Russians developed decades ago as the West when with antibiotics[2]. I would also consider Georgia as a medical destination for some conditions as they are superior to Western options. Some of their doctors do scoff at the Western doctors!You can find millions if not billions of phages in just 1ml of seawater [3]. The problem with phages is they take time to develop, so you could be dead before the bacterial strain is identified and a phage is developed, so antibiotics are the fastest immediate response, but the gold standard is antibiotics until the phages have been developed and then used as a part of a treatment program, but you&#x27;ll only get this from very expensive private healthcare.Of course drinking seawater when one goes surfing is a bit of pot luck, or lucky dip with regards to consuming phages. It makes me wonder if Surfers Against Sewage know about phages. [4]So lots of different ways to tackle health problems, but medical experts cant always use them due to cost or simply lack of knowledge.[1] https:&#x2F;&#x2F;www.mdpi.com&#x2F;1422-0067&#x2F;22&#x2F;8&#x2F;3872[2] https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC6203130&#x2F;[3] https:&#x2F;&#x2F;www.bbc.com&#x2F;future&#x2F;article&#x2F;20210115-the-viruses-that....[4] https:&#x2F;&#x2F;www.sas.org.uk&#x2F; reply darkclouds 13 hours agorootparentprev[1]: https:&#x2F;&#x2F;probiorahealth.com&#x2F; resolves to google, yet it shows in google results, so dont know if the HN hug of death has forced this change.Last scan by the wayback machine.https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230628125533&#x2F;https:&#x2F;&#x2F;probiorah... reply clumsysmurf 14 hours agorootparentprevThere are a few of these kinds of products, I wonder how they comparehttps:&#x2F;&#x2F;www.lifeextension.com&#x2F;vitamins-supplements&#x2F;item02120... reply TheHumanist 20 hours agoparentprevI wonder if there is anything more to the reason that it has never gained any real traction? A lot of groups would stand to lose a lot of money if something like this become used by even half the population. This would mean a massive reduction in purchases of many dental products, visits to dentists, procedures needed by dentists, etc. reply isoprophlex 19 hours agorootparentHow&#x27;d you call this lactic acid promoting cartel? Big Toothpaste? Big Plaque? Big Teeth? reply maximinus_thrax 18 hours agorootparentYou&#x27;re trying to make a joke here, but please do some reasearch about the dental lobbying groups. The ADA is no joke.What OP is implying is not really tinfoil hat material. As one example, one of the reasons parroted (by democrats, actually) that we won&#x27;t have universal healthcare ever, is that it&#x27;s going to cause thousands of health insurance jobs to dissapear. reply beebmam 17 hours agorootparentThen why doesn&#x27;t a country with a nationalized health care system do it? There are incentives in other countries that would encourage this, if it were possible. reply maximinus_thrax 15 hours agorootparentMy nationalized healthcare comment is unlreated to the existence of the dental industry in its current form. It was just an example to point out that protecting jobs is something our elected leaders are worried about when lobbyists are paying up (they&#x27;re not really that worried about jobs dissapearing due to automation or mergers or monolopies, etc..)Regardless of the type of healthcare (nationalized, private, etc..) the dental health industry is still getting paid, the only diffference is who is doing it. The original statement was that a breakthrough in preventive medicine will destroy a large portion of the bread and butter of the dental health industry, which will lead to it being only a fraction of what it is today. Industries fight tooth and nail to keep growing. Guess what they do when their existence is threatened. reply zaat 14 hours agorootparent> Regardless of the type of healthcare (nationalized, private, etc..) the dental health industry is still getting paid, the only diffference is who is doing it.No, one difference is who is doing it, another one is the sums being payed. That&#x27;s why the dental industry in countries with national health care fight to stay out of the general health system. The lucrative compensation of the practitioners lead people to want to go specifically for that. If it were part of national health care it would cease to be sure path to accumulating loads of money, the incentive to become a dentist as well as the power of current practitioner will be similar to that of family doctors or orthopedic specialist. Spoiler alert: in countries with national health care their status is higher then the status of teachers in national school systems, but not by much. reply zaat 17 hours agorootparentprevI&#x27;m not saying there isn&#x27;t such a country, but the countries with national health care that I know about don&#x27;t or don&#x27;t fully cover dental health (presumably because one can live in perfect health with a rotting mouth and not due to a strong dental healthcare lobby &#x2F;s). reply peteradio 16 hours agorootparentHow oh how did our ancestors survive without the dental lobby!? How did the children with their rotten ass teeth consume all their goodies and sodie pops with such poorly functioning teeth!? Its a complete mystery, one I&#x27;m sure is lost to the sands of the 1950s. reply zaat 16 hours agorootparentThey died at young age, miserably? reply klipt 13 hours agorootparentMost of our ancestors just ate much less refined sugar, so probably had less need for dental care in the first place. reply zaat 13 hours agorootparent> ...there was never yet philosopher that could endure the toothache patiently (shakespeare)Why defer to a baseless \"probably\" when you can easily check what is known about the past? Wikipedia doesn&#x27;t put the blame on refined sugar but rather point to farming as to what correlated with dental issues. Are you familiar with the barber&#x27;s pole? that&#x27;s the sign for the location where our ancestors went to be relived from owning teeth.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Barber%27s_pole replyFinnucane 14 hours agorootparentprevWhat&#x27;s more likely, vast cabal conspiring against competing product, or competing product just doesn&#x27;t work as well as claimed? There aren&#x27;t nearly as many grand conspiracies out there as there should be. reply bsder 11 hours agorootparentprevYou think that the governments of the world with much poorer people wouldn&#x27;t jump on something like this? Improving dental health dramatically improves outcomes all across the board.If something works, someone, somewhere in the world would start using it. Hell, people are willing to use stuff that is flat out harmful simply because some people on the internet said so.The big issue with bio things is that the human organism has a lot of variation and a lot of cures sorta work for some people some of the time. Consequently, a high enough bar to get FDA clearance has to be significantly strong.(Two good recent examples: A woman died from oxalate overload from drinking green smoothies and Vitamin C and anti-oxidants can spur cancer growth. Does that mean that everybody should stop drinking green smoothies and taking Vitamin C? Obviously no. But it shows that humans vary and that things aren&#x27;t always straightforward.) reply amelius 19 hours agoparentprev> it was built to outcompete the regular bacteria tooWhat if it invades the gut? reply piuantiderp 19 hours agorootparentVery different conditions reply 0cf8612b2e1e 15 hours agoparentprevMy naïve thought, assuming it was effective, could outcompete acid spewing species, and you had dosed a handful of the population: why would it not have been able to spread through the population?Inoculated person X kisses two people, they go on to kiss two people, etc. Probably too simple a model, but I assume that kissing spreads all manner of microorganisms. How much do you need for the bacteria to take hold? reply ravenstine 16 hours agoprevThis molecule, DIM, supposedly breaks up the biofilms of S. mutans. But there are other substances known to break up biofilms, including xylitol. There&#x27;s been research around this, and it suggests that it can work but only under the condition that sucrose (and possibly other sugars) not be present.https:&#x2F;&#x2F;pubmed.ncbi.nlm.nih.gov&#x2F;32932149&#x2F;https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;342535934_Xylitol_a... reply klipt 13 hours agoparentWe already have a reliable way to break up biofilm, it&#x27;s called brushing ... unfortunately you have to repeat the process twice daily. reply Mayzie 7 hours agorootparentReally only needs to be done once daily. Twice daily is recommended because people tend to not brush their teeth properly and miss things. Doing it twice tends to hit the areas missed in the first pass. reply xk_id 20 hours agoprevthere is something odd about their results. the compound was found not to be effective at either 0.1x or 10x of the effective dose. and they don&#x27;t really explain why. this kind of dose-response curve makes it impractical to use. reply kens 19 hours agoparentWow, you&#x27;re right; the results are very strange. Concentrations of 50, 5, and .05 have no effect at all, while .5 almost completely eliminated biofilm. That kind of looks like experimental error.Figure 1 at https:&#x2F;&#x2F;www.mdpi.com&#x2F;2079-6382&#x2F;12&#x2F;6&#x2F;1017 reply arcticfox 18 hours agorootparentWowwwww. I desperately want this approach to hold up but who in their right mind puts that in a paper with only the caveat “interestingly, only one dose worked.” when they tested three others with literally zero effect and there’s no known mechanistic reason listed.I hope I’m missing something but that looks like a ridiculous blunder perhaps made to get forward to publishing. reply ta988 13 hours agoparentprevUnfortunately typical of compounds that have promiscuous activities. Lets wait for this to be replicated or applied before getting excited. reply briHass 15 hours agoprevI&#x27;d like to see more research on bleach (sodium hypochlorite) for this purpose. The limited studies out there are very promising for bleach as a mouthwash, where it compares favorably to chlorhexidine, another bacteria killer available as prescription mouthwash. Unlike chlorhexidine, however, it doesn&#x27;t stain teeth as significantly, and it&#x27;s obviously much cheaper. (Note: the concentration is 0.1% typically, so diluted from the 6% common in the jug)One interesting point I saw was that bleach is unlikely to promote oral cancers, unlike alcohol mouthwash or oxygenating compounds like hydrogen peroxide. reply klipt 13 hours agoparentI&#x27;ve had several hygienists and dentists tell me Closys (sodium fluoride) is great for killing the bad bacteria without staining. reply vidarh 13 hours agoparentprevWhere is chlorhexidine prescription only? Here (UK) there are several brands sold everywhere as daily mouthwash.Staining w&#x2F;chlorhexidine appears to be very individual. reply smeej 17 hours agoprev> A significant portion of the global population experiences persistent issues with dental plaque and cavities or will face them at some time.How significant a percentage are we talking about?Pretty much every dentist I&#x27;ve seen throughout my life has told me that I&#x27;m somehow immune to cavities. I don&#x27;t know how they&#x27;re figuring this out just from looking in my mouth (I&#x27;m not aware of having had any saliva tests or anything like that), but they&#x27;ve all agreed about it.I wonder if I&#x27;m in some less significant percentage of people who foster this bacteria (or something like it) on our own somehow? reply tremon 15 hours agoparentPretty much every dentist I&#x27;ve seen throughout my life has told me that I&#x27;m somehow immune to cavitiesMy dentist told me there&#x27;s two types of mouth flora: one that causes cavities, and one that causes calculus. My mouth seems to be of the latter. reply HWR_14 16 hours agoparentprevThey can see the beginning stages of cavity development long before they need to be dealt with. I would take it as \"my teeth are abnormally healthy\" reply micromacrofoot 16 hours agoparentprevstop brushing and find out reply smeej 12 minutes agorootparentI&#x27;ve only ever been a once-a-day brusher and \"only if something is stuck\" flosser, to no ill effects so far. That&#x27;s as far as I&#x27;m willing to push it though. reply impish9208 19 hours agoprev9 out of 10 dentists hate this molecule. reply nikolay 10 hours agoprevWhen I read this, I ordered powdered DIM, and xylitol to make my own mouthwash. But there was an old study about stevia extract, which was also found to be extremely effective against biofilms, so, maybe I may add add more to the cocktail. Best would be to chew also mastic cum before swashing as that was found also highly effective against cavity-causing bacteria. reply ironborn123 16 hours agoprevSo any salad that contains chopped cabbage&#x2F;broccoli and eaten daily should do the trick? reply beefman 17 hours agoprevConveniently doesn&#x27;t mention that DIM smells horrible! reply ipnon 17 hours agoprevInterestingly enough, it&#x27;s a cannabinoid receptor agonist.https:&#x2F;&#x2F;onlinelibrary.wiley.com&#x2F;doi&#x2F;10.1002&#x2F;ardp.202200493 reply TheAceOfHearts 20 hours agoprevI can&#x27;t wait for daily teeth brushing to be a thing of the past. It amazes me we&#x27;ve had so many technological advances while still having such primitive mouth cleaning solutions.There&#x27;s people that basically never have to brush their teeth, why can&#x27;t their magical bacteria be used by everyone? I recently asked a dentist in training and they told me the bacteria would die after eating the plaque. Even if you have to regularly re-add the bacteria, it doesn&#x27;t seem like that big of a deal. You could make a lozenge which you suck on once a week, and it&#x27;s still less effort than brushing daily. reply anonym29 20 hours agoparentTechnically, teeth brushing can become a thing of the past for you at any time, if you&#x27;re not in love with your teeth. reply WhereIsTheTruth 20 hours agorootparentIf you are referring to implants, you still have to brush them daily reply pdimitar 15 hours agorootparentDo you really have to do it daily with them? I have two zirconium-based implanted teeth and they&#x27;re always smooth. Zero biological film or gunk on them, and I had some periods this year during which I didn&#x27;t brush teeth for 4-5 days. All other teeth were nasty but the zirconium implants looked and felt pristine. (Sadly still prone to food bits getting stuck in-between though, but oral shower and interdental brushes take care of that.)Though I agree that even if you replace all your teeth you still have to brush somewhat because the gums need the cleanup as well and you can&#x27;t replace those. Though I&#x27;d think I can get away with a much shorter procedure than what I do for several years now (powerful oral shower, interdental brushes, brushing teeth and gums, and Listerine). reply WhereIsTheTruth 12 hours agorootparentIf I remember correctly, it&#x27;s mostly inter-dental brushing&#x2F;flushing to avoid gum related problems or food getting stuck (infections) reply pdimitar 12 hours agorootparentThat&#x27;s what I thought, thanks. Interdental brushing is the one and only unavoidable cleaning procedure even if all your teeth are artificial, it seems.Gums and inter-teeth space are still prone to pollution that can easily grow to infections and ultimately nasty stuff like periodontitis (I got operated to be cured of it several years ago). reply agumonkey 19 hours agorootparentprevI think he had soup and straws in mind reply tsss 17 hours agoparentprevI would still brush my teeth after every meal if I can. Not only to prevent smells. I find it also reduces the frequency of snacking and thus helps to keep the weight down. reply bigbillheck 19 hours agoparentprevNever brushing your teeth is a great way for nobody to ever want to smooch you. reply amelius 19 hours agorootparentBut note that more brushing != more smooching. reply lijok 17 hours agorootparentSpeak for yourself - my wife is a dentist reply xorbax 17 hours agorootparentprevIt depends on what range of the x-axis you select, and what units you use for y reply dghughes 18 hours agorootparentprevOnly if you brush up against somone. reply bigbillheck 17 hours agorootparentprevIt&#x27;s necessary but not sufficient. reply happytoexplain 13 hours agorootparentprevI can attest that this is not a rule. Some people simply do not develop bad breath despite never brushing (I am not one of them). I assume it is a lucky minority. reply tycho-newman 19 hours agoprevY&#x27;all will do anything to avoid some mouthwash. reply justinclift 19 hours agoparentWell, it&#x27;s pricing is kind of extraordinary.Like soft drinks, it&#x27;s pretty much water + additives.Yet it makes brand name soft drinks look extremely cheap. ;) reply retSava 17 hours agorootparentYou could call my child, or me, water + additives, yet she is priceless :). reply justinclift 5 hours agorootparentWhile that&#x27;s technically true, I&#x27;m pretty sure you understand the point I was making. :) reply doubled112 14 hours agorootparentprevInteresting. My children seem to be incredibly expensive. reply Obscurity4340 17 hours agoparentprevIs that really all it takes? reply klipt 13 hours agorootparentNo, you need mechanical stimulation to break up biofilm, aka brushing.Most effective are those Oral B electric brushes that alternately rotate back and forth. reply kej 17 hours agoprevI feel like I&#x27;ve read some variation of \"new thing will make tooth brushing obsolete\" every few years for the last two decades at least, but they never seem to come to fruition. reply lifty 20 hours agoprevIs there a DIY version of this molecule? reply stereo 19 hours agoparentBroccoli contains loads of it. You can also buy a bag for $19: https:&#x2F;&#x2F;www.amazon.com&#x2F;PURE-ORIGINAL-INGREDIENTS-Diindolylme... reply amelius 19 hours agorootparentFrom:https:&#x2F;&#x2F;www.webmd.com&#x2F;vitamins&#x2F;ai&#x2F;ingredientmono-1049&#x2F;diindo...> Diindolylmethane might act like estrogen in the body, but might also block estrogen effects.Right, so don&#x27;t swallow it?> People commonly use diindolylmethane for breast cancer, prostate cancer, and many other conditions, but there is no good scientific evidence to support these uses.Or perhaps do swallow it? reply LinuxBender 12 hours agorootparentI take it in capsule form. It may be worth noting should anyone decide to take this to remember in advance how it will color the urine. The first time can be rather disturbing. It makes the urine kindof a splotchy red&#x2F;bronze color if it has not been consumed in a while. I totally forgot about that the first time and though I was experiencing renal failure at first.I personally only take small amounts as it seems to up-regulate some repair pathways that can cause pain in some joints. No pain no gain but I&#x27;m just lazy enough to stick with broccoli sprouts for DIM and sulforaphane most of the time. I also don&#x27;t measure serum estrogen and guess as with most things. reply tourmalinetaco 18 hours agorootparentprevAs is common in food sciences, “we have no idea what this actually does but SOME small studies have SOME big conclusions so here you go”. reply Projectiboga 16 hours agorootparentThis molecule is safe to eat, it helps the body fight the stomach ulcer bacteria. This cuts the slime that these bacteria use but aren&#x27;t indiscriminate at killing microbes. You&#x27;re immune system still does the actual work this just prevents evasive measures resistant bugs use. reply typingonmyphone 19 hours agoparentprevCareful, if this molecule is basically an antibiotic (and at that, with poor effectiveness outside of a specific dose range), you could produce resistant bacteria or hard-to-predict side effects reply 1letterunixname 9 hours agoprevMy DDS alleged that the bacteria strain(s) that promote plaque tend to out-compete the one(s) that leads to cavities. Can anyone confirm? reply m3kw9 18 hours agoprev [–] Whatever dental society that is gets paid for giving dentists licences is not gonna approve this if it means it will lower cavities by a lot, a big portion of dentists fees is from patching up cavities and it’s sideffects. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers have discovered a naturally occurring molecule, DIM, capable of reducing dental plaque and cavities by up to 90%.",
      "DIM works by disrupting the biofilm of bacteria that cause cavities, and it could be used to enhance oral hygiene products like toothpaste and mouthwash.",
      "In addition to this breakthrough in dental health, the article also discusses various other scientific advancements and studies."
    ],
    "commentSummary": [
      "Researchers found a molecule, DIM, which can reduce dental plaque, leading to the creation of a probiotic tablet to compete with detrimental mouth bacteria.",
      "Commercialization of such products has been hindered due to uncertainty about their effectiveness and concerns over their long-term persistence.",
      "The article discusses reasons for the limited traction of this innovation, skepticism on its effectiveness, pros and cons of oral hygiene practices and products and the potential influence of dental societies on approval and promotion of new treatments."
    ],
    "points": 112,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1694347908
  }
]
