[
  {
    "id": 39856413,
    "title": "Boeing's Toxic Work Culture: Prioritizing Profits Over Quality",
    "originLink": "https://prospect.org/infrastructure/transportation/2024-03-28-suicide-mission-boeing/",
    "originBody": "Suicide Mission What Boeing did to all the guys who remember how to build a plane by Maureen Tkacik March 28, 2024 5:15 AM RSS Print × Expand Gavin McIntyre/The Post And Courier via AP A Boeing Dreamlifter sits on the tarmac at their campus in North Charleston, South Carolina, May 30, 2023. John Barnett had one of those bosses who seemed to spend most of his waking hours scheming to inflict humiliation upon him. He mocked him in weekly meetings whenever he dared contribute a thought, assigned a fellow manager to spy on him and spread rumors that he did not play nicely with others, and disciplined him for things like “using email to communicate” and pushing for flaws he found on planes to be fixed. “John is very knowledgeable almost to a fault, as it gets in the way at times when issues arise,” the boss wrote in one of his withering performance reviews, downgrading Barnett’s rating from a 40 all the way to a 15 in an assessment that cast the 26-year quality manager, who was known as “Swampy” for his easy Louisiana drawl, as an anal-retentive prick whose pedantry was antagonizing his colleagues. The truth, by contrast, was self-evident to anyone who spent five minutes in his presence: John Barnett, who raced cars in his spare time and seemed “high on life” according to one former colleague, was a “great, fun boss that loved Boeing and was willing to share his knowledge with everyone,” as one of his former quality technicians would later recall. More from Maureen Tkacik But Swampy was mired in an institution that was in a perpetual state of unlearning all the lessons it had absorbed over a 90-year ascent to the pinnacle of global manufacturing. Like most neoliberal institutions, Boeing had come under the spell of a seductive new theory of “knowledge” that essentially reduced the whole concept to a combination of intellectual property, trade secrets, and data, discarding “thought” and “understanding” and “complex reasoning” possessed by a skilled and experienced workforce as essentially not worth the increased health care costs. CEO Jim McNerney, who joined Boeing in 2005, had last helmed 3M, where management as he saw it had “overvalued experience and undervalued leadership” before he purged the veterans into early retirement. “Prince Jim”—as some long-timers used to call him—repeatedly invoked a slur for longtime engineers and skilled machinists in the obligatory vanity “leadership” book he co-wrote. Those who cared too much about the integrity of the planes and not enough about the stock price were “phenomenally talented assholes,” and he encouraged his deputies to ostracize them into leaving the company. He initially refused to let nearly any of these talented assholes work on the 787 Dreamliner, instead outsourcing the vast majority of the development and engineering design of the brand-new, revolutionary wide-body jet to suppliers, many of which lacked engineering departments. The plan would save money while busting unions, a win-win, he promised investors. Instead, McNerney’s plan burned some $50 billion in excess of its budget and went three and a half years behind schedule. Swampy belonged to one of the cleanup crews that Boeing detailed to McNerney’s disaster area. The supplier to which Boeing had outsourced part of the 787 fuselage had in turn outsourced the design to an Israeli firm that had botched the job, leaving the supplier strapped for cash in the midst of a global credit crunch. Boeing would have to bail out—and buy out—the private equity firm that controlled the supplier. In 2009, Boeing began recruiting managers from Washington state to move east to the supplier’s non-union plant in Charleston, South Carolina, to train the workforce to properly put together a plane. Boeing was in a perpetual state of unlearning all the lessons it had absorbed over a 90-year ascent to the pinnacle of global manufacturing. But after the FAA cleared Boeing to deliver its first 787s to customers around the end of 2011, one of Swampy’s old co-workers says that McNerney’s henchmen began targeting anyone with experience and knowledge for torment and termination. One of Swampy’s closest colleagues, Bill Seitz, took a demotion to go back west. A quality control engineer named John Woods was terminated for insisting inspectors thoroughly document damage and repair performed on composite materials, which were far less resilient than steel. Good machinists and inspectors who wore wristbands in support of a union drive were framed with dubious infractions. “Everyone from Everett started dropping like flies,” remembers a former manager at the plant. “There’s a form we all had to sign that says you take responsibility for anything that goes wrong, and it states pretty clearly that if something happens to a plane because of something you did wrong, you can face a major fine or jail time for that,” the manager recalled. “The Everett managers took that seriously. Charleston leadership did not.” The bosses hit Swampy with a new initiative called “Multi-Function Process Performer,” through which quality inspectors were directed to outsource 90 percent of their duties to the mechanics they were supposed to be supervising. This was supposed to speed up production and save Boeing millions once it successfully shed the thousands of inspectors it intended to axe. Swampy believed relying on mechanics to self-inspect their work was not only insane but illegal under the Federal Aviation Administration charter, which explicitly required quality inspectors to document all defects detected, work performed, and parts installed on a commercial airplane in one centralized database. Swampy knew he was caught in a prisoner’s dilemma. If he went along, he was breaking the law; if he didn’t, whistleblowers who complained about unsafe practices were routinely terminated on grounds of violating the same safety protocols they had opposed violating. Swampy calculated that it would be a bigger pain for Boeing to fire him for doing the right thing than following orders, so he kept his head down and continued managing his inspectors as though he were back in Everett, taking special care to meticulously record every episode of noncompliance (and nonconformance, which is similar but not identical) he encountered. He documented his discovery that machinists installing floor panels had been littering long titanium slivers into wire bundles and electrical boxes between the floorboards and the cargo compartment ceiling panels, where they risked causing an electrical short. A series of mysterious battery fires had already caused the FAA to ground the 787 for a few months just over a year after the first plane had been delivered. He wrote that 75 out of a package of 300 oxygen masks slated for installation on a plane did not actually pump oxygen. His team compiled a list of 300 defects on a fuselage scheduled for delivery, and he discovered that more than 400 nonconforming aircraft parts had gone missing from the defective parts cage and likely been installed on planes illegally and without documentation, by managers and mechanics desperate to get them out the door. × Expand Courtesy Barnett Family John Barnett worked for Boeing for more than 30 years as a quality inspector and manager. Few quality managers were as stubborn as Swampy. A Seattle Times story detailed an internal Boeing document boasting that the incidence of manufacturing defects on the 787 had plunged 20 percent in a single year, which inspectors anonymously attributed to the “bullying environment” in which defects had systematically “stopped being documented” by inspectors. They weren’t fooling customers: Qatar Airways had become so disgusted with the state of the planes it received from Charleston that it refused to accept them, and even inspired the Qatar-owned Al Jazeera to produce a withering documentary called Broken Dreams, in which an employee outfitted with a hidden camera chitchatted with mechanics and inspectors about the planes they were producing. “They hire these people off the street, dude … fucking flipping burgers for a living, making sandwiches at Subway,” one mechanic marveled of his colleagues; another regaled the narrator with tales of co-workers who came to work high on “coke and painkillers and weed” because no one had ever had a urine test. Asked if they would fly the 787 Dreamliner; just five of 15 answered yes, and even the positive responses did Boeing no favors: “I probably would, but I have kind of a death wish, too.” The day after Broken Dreams premiered, Swampy got an email informing him that he’d been put on a 60-day corrective action plan four weeks earlier. His alleged offense constituted using email to communicate about process violations; the HR file noted, fictitiously, that his boss had discussed his “infraction” with him earlier. Swampy was no fool. “Leadership wants nothing in email so they maintain plausible deniability,” he wrote in the “comments” space on his corrective action plan paperwork. “It is obvious leadership is just looking for items to criticize me on so I stop identifying issues. I will conform!” He immediately applied for a job on the graveyard shift, whose supervisor promised the gig would go to the manager with the most seniority on the Final Assembly team. But the job went to a manager who had transferred to Final Assembly all of a week earlier, which is when Swampy began to realize he’d been institutionally blackballed from the only company he’d ever worked for. He got two more internal job offers rescinded after that, including one from a group that was literally desperate for someone with Barnett’s breadth of experience. “They didn’t care how bad I wanted him,” the senior manager told one of Swampy’s friends. “They said John Barnett is not going anywhere.” Finally, in early 2017 Swampy happened upon a printout of a list of 49 “Quality Managers to Fire.” The name John Barnett was number one. Swampy decided to go on a medical leave of absence, which turned into early retirement on March 1. He called a labor lawyer he knew from a colleague’s case, and together they began the seemingly unending process of filing an aviation whistleblower complaint detailing his seven years at the Charleston plant. It made him sick to think that the value of his Boeing shares had tripled over the same period during which he’d watched the company get so comprehensively dismantled. But it was downright surreal to watch the stock price nearly triple once more during the two years after he left the company. Nine days after the stock reached its high of $440, a brand-new 737 MAX dove into the ground near Addis Ababa, Ethiopia, at nearly 800 miles per hour, killing 157 people on board, thanks to a shockingly dumb software program that had programmed the jets to nose-dive in response to the input from a single angle-of-attack sensor. The software had already killed 189 people on a separate 737 MAX in Indonesia, but Boeing had largely deflected blame for that crash by exploiting the island nation’s reputation for aviation laxity. Now it was clear Boeing was responsible for all the deaths. Swampy had no firsthand experience with the 737 MAX, but it was obvious that the ethos that drove the 787 plant had poisoned that program as well. He began sharing his story in media interviews, and soon the Department of Justice, which had opened a criminal investigation into the MCAS flight control system crashes that quickly widened to encompass the Dreamliner program, came calling as well. While the criminal probe ultimately shriveled into one of the most pathetic plea bargains in the history of American justice, something shifted within the FAA. Boeing had quietly assumed many of the roles traditionally played by its primary regulator, an arrangement that was ethically absurd, though in practice it probably worked better than being regulated by an agency full of underpaid bureaucrats desperate to ingratiate themselves to Boeing. (Swampy’s best friend and later wife Diane Johnson worked at Boeing as an FAA liaison.) Most of the Boeing employees who worked in quasi-regulatory roles were like Swampy, terrified of anything going wrong on a plane they had inspected and deeply skeptical of their bosses, who seemed unconcerned about the consequences. Amid the MAX grounding, the FAA began to take a closer look at the 787 program that was the subject of so many complaints from workers and airlines. The company had campaigned the FAA heavily to approve a “random sampling” method of inspecting the precision of the shims it cut to connect various pieces of the plane together; a closer look revealed the shims were not as precisely sized as the company had boasted. Eight planes were immediately grounded, and the agency forced Boeing to halt deliveries pending further investigation. Weeks stretched into years as nonconformances and noncompliances piled up; “Boeing Looked for Flaws in Its Dreamliner and Couldn’t Stop Finding Them,” one headline summarized. Boeing had quietly assumed many of the roles traditionally played by its primary regulator, an arrangement that was ethically absurd. In December 2022, Aviation Week produced a helpful diagram mapping what sections of the plane had caused auditors the biggest headaches. Every single section, from the tip of the nose to the horizontal stabilizers, was marked up with red arrows. In 2023, deliveries were halted in January, February, and again in August over problems with the shimming, the horizontal stabilizer, and God knows what else. Swampy, and hundreds of others who had blown the whistle on Boeing’s managerial nihilism, had been thoroughly vindicated. But it was too late. There were no more cleanup crews left at Boeing; too much knowledge had been drained from the company. “For every new plane you put up into the sky there are about 20,000 problems you need to solve, and for a long time we used to say Boeing’s core competency was piling people and money on top of a problem until they crushed it,” says Stan Sorscher, a longtime Boeing physicist and former officer of the Society of Professional Engineering Employees in Aerospace (SPEEA), the labor union representing Boeing engineers. But those people are gone. Sorscher has warned Boeing management for decades now of the catastrophic effects of the brain drain inflicted by its war on “brilliance.” He says McDonnell Douglas managers published a statistical analysis in 1997 gauging productivity against the average seniority of managers across various programs that found that greener workforces were substantially less productive, which he found to be a “mirror image” of a kind of “rule of thumb” within Boeing that held that every Boeing employee takes four years to become “fully productive.” But the average employee assigned to the 737 program has been at Boeing just five years, according to a longtime Boeing executive who is involved in various efforts to save the company; for comparison’s sake, he says the average employee assigned to the 777 program had between 15 and 20 years under their belt. The typical engineer or machinist assigned to the task of fixing Boeing’s 20,000 problems has never known a Boeing that wasn’t a five-alarm dumpster fire. There’s a terrifying visual representation of this: the satellite view of the Moses Lake Municipal Airport in an arid stretch of Washington east of Seattle, or the Southern California Logistics Airport in Victorville, California, where hundreds of Boeing 737 MAXes sit in abandoned parking lots waiting for someone to fix them so they can finally be delivered. Meanwhile, pieces are flying off the Boeing planes actually in use at an alarming rate, criminal investigations are under way, and another in a long line of stock-conscious CEOs is stepping down. Boeing’s largest union, the Machinists, is trying to snag a board seat because, in the words of its local president, “we have to save this company from itself.” SPEEA has demanded, understandably, that the board choose an aerospace engineer as its next CEO. But there are few signs that will happen: None of the names floated thus far for the spot have been aerospace engineers, and the shoo-in for the position, GE’s Larry Culp, is not an engineer at all. By now you know what became of Swampy: He was found dead a few weeks ago with a gunshot wound to his right temple, “apparently” self-inflicted, on what was meant to be the third day of a three-day deposition in his whistleblower case against his former employer; his amended complaint, which his lawyer released last week, is the basis for much of this story. It is worth noting here that Swampy’s former co-workers universally refuse to believe that their old colleague killed himself. One former co-worker who was terrified of speaking publicly went out of their way to tell me that they weren’t suicidal. “If I show up dead anytime soon, even if it’s a car accident or something, I’m a safe driver, please be on the lookout for foul play.” Swampy’s wife Diane, who worked at Boeing for 28 years, died of brain cancer at age 60 in late 2022. Discussing Swampy’s death and the whistleblower lawsuit he left behind, the longtime former Boeing executive told me, “I don’t think one can be cynical enough when it comes to these guys.” Did that mean he thought Boeing assassinated Swampy? “It’s a top-secret military contractor, remember; there are spies everywhere,” he replied. More importantly, he added, “there is a principle in American law that there is no such thing as an accidental death during the commission of a felony. Let’s say you rob a bank and while traveling at high speed in the getaway you run down a pedestrian and kill them. That’s second-degree murder at the very least.” Tags Transportation airlines Boeing whistleblowers corporate power CEOs Justice Department Maureen Tkacik Maureen Tkacik is investigations editor at the Prospect and a senior fellow at the American Economic Liberties Project. Read more by Maureen Tkacik March 28, 2024 5:15 AM You can count on the Prospect, can we count on you? There's no paywall here. Your donations power our newsroom as we report on ideas, politics and power — and what’s really at stake as we navigate another presidential election year. Please, become a member, or make a one-time donation, today. Thank you! RELATED Gavin McIntyre/The Post And Courier via AP The Strange Death of a Boeing Whistleblower There’s no way America’s last great manufacturer murdered a prominent critic … is there? Mar 14, 2024 Lindsey Wasson/AP Photo Blowing the Door Off Boeing’s ‘Epstein Deal’ The lawyer who busted open Jeffrey Epstein’s sweetheart deal sues DOJ for the goods on Trump’s slimy deferred prosecution agreement with the 737 manufacturer. Feb 9, 2024 National Transportation Safety Board via AP Boeing 737 MAX Incident a By-Product of Its Financial Mindset The door plug that ripped off an Alaska Airlines plane only exists because of cost-cutting production techniques to facilitate cramming more passengers into the cabin. Jan 9, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39856413",
    "commentBody": "What Boeing did to all the guys who remember how to build a plane (prospect.org)725 points by doom2 14 hours agohidepastfavorite438 comments class3shock 10 hours ago\"But the average employee assigned to the 737 program has been at Boeing just five years, according to a longtime Boeing executive who is involved in various efforts to save the company; for comparison’s sake, he says the average employee assigned to the 777 program had between 15 and 20 years under their belt.\" It don't think it's possible to overstate how bad, and sad, of a state of affairs that is. I've never seen a group at any organization that was composed predominantly of early career engineers that did not have issues (in the aerospace/defense industry). Those mid / late career engineers are irreplaceable and yet they were actively trying to get rid of them... There are no words. reply mrjin 1 hour agoparentEngineering is not only about know what to do, but also what not to do, and imho, knowing what not to do is way more important. Those C*O without an engineering background probably could not recognize that, but even they do, they probably don't care neither. Early career staffs are not only more energetic but also much cheaper comparing to those veterans in the field. Replacing those know what not to do with younger stuffs will definitely make numbers looking much better, but the consequences are not immediate, and most likely someone-else's problem when it indeed pops, as the one made the decisions would have pocketed a big fat bonus and walked away... reply lukan 53 minutes agorootparent\"when it indeed pops, as the one made the decisions would have pocketed a big fat bonus and walked away\" And this is exactly what happened here and criminal investigations are happening, but I kind of doubt, whether they will lead to much. Much in the article is based on hearsay, so it will depend on whether there are more people willing to testify. But one main witness already suicided, despite telling others he won't do that. Either way, that is already a strong deterrent. reply weinzierl 20 minutes agoparentprevI'd also blame flat hierarchy and lean management. When I started as a young engineer in aerospace in the late-nineties[1] this trend had already started, but we still had young people that tried to build a career and reputation. This culture is completely gone and replaced by move fast, break things and when you screw up start afresh somewhere else with minimal repercussions. I don't say the old world was necessarily better and most certainly I don't want the 80s back, but something important has been lost and we yet have to find a replacement. [1] I left aerospace after six years, got a computer science degree and built a career in IT. Never looked back. reply amtamt 5 hours agoparentprevSomething very similar is happening, at a very rapid pace, in software development. reply AtlasBarfed 1 hour agorootparentAre you (ironically) new? Software has been like that for st least three decades. reply dbg31415 5 hours agorootparentprevhttps://www.wired.com/story/ageism-haunts-tech-workers-layof... reply holografix 2 hours agorootparentprevJust look at Google reply xen0 36 minutes agorootparentAnecdotally, the average member of the team I'm in (in Europe) is probably mid-30s with at least 10 years of experience. Less than 5 years of experience at Google is, to be fair, common. But the company doubled in size over that time, so it's inevitable. And higher turn over in tech is common (and I don't think that is necessarily reflective of anything other than the fact it's easy to get another job as a software engineer). I can't state much on the layoffs because my team was not heavily affected. reply einpoklum 15 minutes agorootparentprevTBH I try not to look at Google. reply reissbaker 13 hours agoprevFWIW, \"Prince Jim\" McNerney, who most of the article's ire is understandably directed towards, is no longer the CEO. He directed the 737 MAX's development, but retired before the scandals; his successor, Dennis Muilenburg (a 30+ year Boeing employee who started out in engineering), was fired for the poor quality of the 737 MAX despite it being developed under Prince Jim. That being said, the current CEO — Dave Calhoun — is an old exec from from GE, where McNerney started out; I hope he's different from Jim, but I wouldn't bank on it. Unlike Muilenberg and pre-merger Boeing CEOs, he doesn't have a direct background in aviation. He's retiring at the end of the year, and I hope his replacement is more like the pre-merger CEOs than the accounting-focused recent ones. reply donmcronald 3 hours agoparent> the current CEO — Dave Calhoun — is an old exec from from GE, where McNerney started out From the article. > None of the names floated thus far for the spot have been aerospace engineers, and the shoo-in for the position, GE’s Larry Culp, is not an engineer at all. Maybe they should start bundling life insurance with flights on Boeing planes. reply teleforce 2 hours agorootparentIt's a strange anomaly when most of the current top Fortune 500 (US) companies have engineers as their CEO [1]. You would have expected that Boeing to be led by engineers due to the scale of engineering involved in the plane constructions but apparently it's not always the case. [1] Top CEOs have this degree: https://news.ycombinator.com/item?id=39680613 reply masklinn 2 hours agorootparentBoeing stopped considering engineering and manufacturing to be their core competency after the MDD merger, that is expressly why they moved the HQ away from Seattle and closer to financial markets. reply mrjin 1 hour agorootparentWas about to say the same. I guess the most of recent engineering in Boeing is just scaling, I mean, making it bigger without changing anything else, if you can call that engineering by any chance... reply peteradio 8 hours agoparentprev> I hope his replacement is more like the pre-merger CEOs than the accounting-focused recent ones. ... womp womp reply benreesman 7 hours agoprevI know that this is about Boeing, but it is just such a perfect epitaph for the end of the current decaying Valley elite. What took Boeing 20 years FAANG did in one: “CEO Jim McNerney, who joined Boeing in 2005, had last helmed 3M, where management as he saw it had ‘overvalued experience and undervalued leadership’ before he purged the veterans into early retirement.” reply mikewarot 11 hours agoprev>Boeing had come under the spell of a seductive new theory of “knowledge” that essentially reduced the whole concept to a combination of intellectual property, trade secrets, and data, discarding “thought” and “understanding” and “complex reasoning” possessed by a skilled and experienced workforce as essentially not worth the increased health care costs. So they devalued Wisdom, and Elders... and things fell apart. This seems to be a pattern repeated all over the modern world. reply gostsamo 2 hours agoparentPurging elder employees is the logical result of making the employer pay for the health care of their employees. reply ignoramous 15 minutes agorootparent> Purging elder employees is the logical result of making the employer pay for the health care of their employees. The now-elder employee gave their best and healthy years to the company and its mission. reply Jensson 0 minutes agorootparentWhich is why healthcare and pension shouldn't be paid by the employer, employers shouldn't be punished for keeping old people around. sooheon 2 hours agorootparentprevNo, it's only one incentive. Counterbalancing it is the value of expertise. reply gostsamo 2 hours agorootparentThis is, politely said, wishful thinking. The incentive is for good enough, not for the best possible product. reply sooheon 1 hour agorootparent> for the best possible product When did I say this? reply rdtsc 11 hours agoprev> The day after Broken Dreams premiered, Swampy got an email informing him that he’d been put on a 60-day corrective action plan four weeks earlier. His alleged offense constituted using email to communicate about process violations That is pretty shady. They didn't want to discuss violations in emails so it doesn't end up in a court case or found by the FAA during an investigation. > the longtime former Boeing executive told me, “I don’t think one can be cynical enough when it comes to these guys.” Did that mean he thought Boeing assassinated Swampy? “It’s a top-secret military contractor, remember; there are spies everywhere,” he replied. I am kind of surprised various executives don't order hits on each other more often. Or maybe they do but the assassinations are too subtle and they look like heart attacks and accidents? With billions on the line, what's a few millions in crypto found in a usb stick somewhere in the bushes for a \"job well done\". There is also the idea that sometimes it should look more an assassination to send a clear message to others: \"you don't want to fall on the knife backwards, three times in as row, like so and so, now do you?\" reply donmcronald 3 hours agoparent> They didn't want to discuss violations in emails so it doesn't end up in a court case or found by the FAA during an investigation. Thankfully big tech is able to provide these companies with retention policies that allow the pesky paper trail to be auto-purged on a schedule. reply Tabular-Iceberg 42 minutes agoprevI wonder if Boeing’s institutional investors have had the foresight to get controlling stakes in business jet manufacturers to prevent them from going down the same path, just so that they can still get places by plane in reasonable safety. reply lucianbr 37 minutes agoparentMoney trumps even the personal safety of the person getting the money. Look at the guy with the carbon fibre submarine. He literally sacrificed his life in the pursuit of profit. reply margalabargala 13 hours agoprevIf you read this article looking for new or surprising insight, you won't find it. It is not new information that Boeing started a rapid decline shortly after the McDonnell Douglas merger, and it will be unsurprising to you to hear that shortly afterwards, Boeing began abusing its most senior employees into leaving. What this article offers is new detail into exactly how Boeing has gone about cannibalizing itself. The specific things done to specific employees, the specific quality incidents that were swept under the rug, the lengths to which they went to ensure all prior institutional knowledge regarding how to properly build a plane was systematically destroyed. It's worth reading, perhaps unless you're going to be flying on a Boeing plane anytime soon. reply iaoat2d 13 hours agoparent\"the lengths to which they went to ensure all prior institutional knowledge regarding how to properly build a plane was systematically destroyed.\" why do this intentionally? reply margalabargala 13 hours agorootparentStock price gains. Fire all the longest-tenured, highest-salaried employees. Now you have a company that appears to look similar but with millions of dollars fewer per year in headcount expenses. Boeing's stock price went up 10x in the time frame covered by the article. The people responsible for gutting the company have cashed out. reply Rinzler89 13 hours agorootparent>Boeing's stock price went up 10x in the time frame covered by the article. The people responsible for gutting the company have cashed out. Why does the stock market reward idiot shit like this? I've seen the same whit a a large US semiconductor company. In the 2008 crunch, the fired the most tenured employees and offshored the work abroad. Granted, the company didn't fail, their stock went up and now it's 5-7x that amount. reply TaylorAlexander 13 hours agorootparent> Why does the stock market reward idiot shit like this? Well at a first order, the answer is that the stock market as a system for promoting value creation is an imperfect approximation of an ideal value creator, and more and more we are beginning to see the myriad of ways this concept produces antisocial results. (See for example the state of hospitals and schools, and the rising rate of individuals with crippling medical and college debt.) More directly there has been some criticism of the stock market for rewarding short term gain over long term value, which among other things has led to the creation of the Long Term Stock Exchange: https://en.wikipedia.org/wiki/Long-Term_Stock_Exchange reply TaylorAlexander 12 hours agorootparentI should add that our short term market-based approach to economic activity fails to produce appropriate housing outcomes, and that the approaches in Vienna or Singapore could end our homelessness crisis and make everyone happier. I recently read a doctor’s account of the homeless people who use the ER as a community space by complaining of minor illnesses, and it seems so clear to me it would be cheaper to give them small private subsidized housing (not the awful and alienating “shelters” that offer no privacy or storage and have strict rules, making the street more appealing). Fixing housing could be cheaper than them using the ER or paying for their prison space, and it would also make the streets of San Francisco smell a LOOOT better (and BART), but our short term market based system just chops up everything good, sells it for parts, and speculates on all the land and buildings. https://www.shareable.net/public-housing-works-lessons-from-... reply gretch 7 hours agorootparent>I should add that our short term market-based approach to economic activity fails to produce appropriate housing outcomes >Fixing housing could be cheaper than them using the ER or paying for their prison space, and it would also make the streets of San Francisco smell a LOOOT better (and BART) It's extremely unfair to blame \"market based solutions\" for failing to fix SF housing problems when it's pretty clear the largest hurdle is NIMBYism politically blocking new housing developments. For example here: https://www.sfchronicle.com/sf/article/s-f-housing-clash-yim... The locals won't even LET other people build new housing. They definitely aren't going to start footing the bill and building the housing themselves reply ClumsyPilot 8 hours agorootparentprev> streets of San Francisco smell a LOOOT better What happened to all the public toilets in US/UK? I remember there being many more, am I hallucinating this? Many 2nd world countries still have them, for good reason! reply gosub100 41 minutes agorootparentPeople defile them, use them for shelters, or drug ingestion stations. There's no innovative way to solve homelessness. It's an insidious problem that defies any method to redress. Any angle you try to approach it from will be abused or defeated in some way. reply Rinzler89 12 hours agorootparentprev>and that the approaches in Vienna Vienna's approach worked because it happened after WW2 when the country was bombed and broken, land, construction materials and labor were dirt cheap, so the state built over half the city's homes and turned them into public housing cheaply no problem. But fast forward to today where most of the land and buildings in a city are privately owned, how to you expect a city, any city, to buy up over half the buildings in the city at today's market and turn them into public housing? The city would probably have to go broke or into huge amounts of debt and everyone would be screaming communism. Even in the rest of Austria, this approach today would not be feasible due to how insane the cost of urban housing ahs reached no city could afford to buy up over half of it. The monetary appreciation of housing prices and and turning it into an speculative asset is the west's biggest policy failure. You'd have to undo this first before you can think of implementing Vienna's policies. reply awiesenhofer 2 hours agorootparent> Vienna's approach worked because it happened after WW2 It didn't though, they already started in the 1920ies! The most famous builing, Karl-Marx-Hof, started construction in 1927. And they are building new public housing to this day, making use of inner city land that comes available from old factories, storage facilities, rail yards or alongside private construction projects etc. Other austrian cities do this too. Agreed on the policy failure though. reply Rinzler89 59 minutes agorootparent>And they are building new public housing to this day, Sure, a bit yes, but the bulk was acquired/made back when property was dirt cheap, not at today's prices. Vienna couldn't replicate the same move from scratch today. >Other austrian cities do this too. Not even remotely as much as Viena. Graz has next to no public housing, it's mostly private. reply TaylorAlexander 11 hours agorootparentprevRight so you’re saying Vienna’s approached worked but we would have to change things to make it work for us. That is exactly what I am saying too. I’m also saying that it could be worth considerable effort to try to make those changes, because the reward is a much better system. For example we might introduce bills now that help stabilize (reduce) housing prices by limiting large scale corporate speculation on housing, such as these two bills [below] introduced into congress. With cheaper housing available, the need for social housing goes down and so does the cost to build it, dramatically lowering the total cost to implement. https://projects.propublica.org/represent/bills/117/hr9246 https://projects.propublica.org/represent/bills/117/s5151 > everyone would be screaming communism Yes and part of what I’m saying is that we might want to stop doing that and think about what is actually going to fix our problems, even if gasp the government is involved. Nobody can afford housing and our planes are falling out of the sky and we’re having a cold-war political debate while every other major country offers cheaper medical care and education. reply Eisenstein 11 hours agorootparentThat would require actually listening to each other and experts, and not using demagoguery to villainize people who disagree with us on minor culture issues. Again, the financial incentives align for the anti-social aspect, since yelling at each other draws in more engagement and viewers and sells more ad-space. reply massysett 10 hours agorootparentprevHospitals and schools don’t support this thesis: in the USA, the bulk of the operators in both segments are either governments or non-profits. reply CWuestefeld 12 hours agorootparentprev> the stock market as a system for promoting value creation is an imperfect approximation of an ideal value creator yet > See for example the state of hospitals and schools, and the rising rate of individuals with crippling medical and college debt. Ummmm. State hospitals and schools are not traded on our stock exchanges. If there's a failure here, it's not with equities markets. There's an obvious common denominator between the examples you give, and that these are the most highly-regulated industries in America. My first guess as to where to lay blame would be on those regulations - although we'd really need to dig into whatever the specific failures you're thinking of, if we want to be sure. reply TaylorAlexander 12 hours agorootparent“See the state of hospitals” meaning the situation with hospitals, many of which it seems are private. Our schools are a mixture of state and publicly owned (I’m including college) but even state funded schools suffer due to their reliance on stock market driven suppliers such as textbook companies and the housing the teachers live in. > My first guess as to where to lay blame would be on those regulations Considering medical and educational costs (total system costs including government expense) are much higher here than they are for example in Germany which has State run institutions for both, I would see this as a poor assumption. However I’m not actually advocating for State-run institutions, as I would rather see locally owned cooperatives for housing and schools, and larger federations of cooperatives for medical research. My point is that short term market-based winner-take-all approaches are hurting us. I should add that the broad topic of discussion here is Boeing, which degraded in critical safety metrics after moving to a relaxed regulation environment and focusing on market based short term optimization. reply justwool 11 hours agorootparentprevBecause state hospitals aren’t publicly listened they aren’t broken by this? Yes I forgot every aspect of state run hospitals are the same… But except wait.. almost every aspect of what makes that hospital is on the stock market. reply Tabular-Iceberg 15 minutes agorootparentprev> Why does the stock market reward idiot shit like this? I don’t think the market rewards it, at least not by itself. The problem is that the real money isn’t in the market, the institutional investors make most of their money on commissions. So while short term gains are a nice bonus, it’s only secondary to driving volatility and with it trade volume. So the incentive is to just stir shit up, because that’s what makes them money, both as stock prices go up and down. Also institutional investors have disproportionate voting power that lets them put their own shit stirrers on the board and subsequently in the C-suite. reply afavour 12 hours agorootparentprevBecause, depressingly, the stock market is correct. Boeing is one of two manufacturers for planes of this size. The other is totally backlogged with orders. The stock market has assessed, correctly, that Boeing can withstand this loss of knowledge and keep generating profit. Does it result in shit equipment that literally kills people? Sure. But how many people are going to stop flying because of it? Not many. Throw in the lucrative military connections and you’ve got yourself a sure bet. reply JackFr 12 hours agorootparentI think that many of the managers honestly didn’t understand where the quality and safety came from. They probably thought that they could just coast and the quality would continue. As a counterpoint, I work at very large financial firm in technology and in general, the 20+ year veterans who’ve been here forever are terrible. They are hidebound in their actions, years behind in industry best practices and they maintain little fiefdoms simply because of their intimate knowledge of the banks arcane and idiosyncratic policies. The place would be better of without the bulk of them. That is to say we are the complete opposite of what Boeing was. But the most charitable interpretation you could offer the Boeing management is that they thought they were in the situation of my company rather than the situation they actually had. reply soraminazuki 12 hours agorootparentYou're being too generous. Boeing actively retaliated against people raising safety concerns. That's not the action of people who didn't know any better. reply GolfPopper 4 hours agorootparentprevPeople won't stop flying until they do - or at least stop flying on Boeing aircraft. And if airlines can't make a profit on a Boeing aircraft flight, there won't be any more Boeing aircraft flights. I don't know whether the point where the market for Boeing aircraft travel is one disaster away or ten disasters away, but it is out there. When it comes, people won't stop flying, but they will fly less, and it will cost more. It can happen. reply swader999 12 hours agorootparentprevI'm not getting on a Boeing plane again. More on principle than fear of my life. And yeah, I'm probably in a group that is not statistically important. reply fcatalan 12 hours agorootparentI flew this week. There were two 737 flights at about 130€ then one with an A320 at 220€. I took the Airbus. Same reason as you. reply eptcyka 13 hours agorootparentprevBecause if you look at it by the numbers, expenses went down whilst output remained. If you’re an investor that investigates annual reports on finances, this would pique your interest. There is no way to price the talent and knowledge of your workforce until after they have left. reply tcmart14 12 hours agorootparentI really like that last sentence. 'There is no way to price the talent and knowledge of your workforce until after they have left.' I think that captures so much in such a simple to understand way. reply polygamous_bat 13 hours agorootparentprev> Why does the stock market reward idiot shit like this? Goodhart’s law, unfortunately. Whatever metric the stock market rewards gets gamed like there is no tomorrow (or next quarter, here.) reply constantcrying 10 hours agorootparentprev>Why does the stock market reward idiot shit like this? Because Boeing is in an absolutely unique position where they are part of a duopoly in a market where demand for airplanes massively outstrips supply. Boeing's customers have no alternative and Boeing will be selling them planes and the market knows that. Additionally the stock market can only look a tangible results. There is no measure of \"engineering competency\" which you could track year over year, which makes these mistakes hard to realize unless you are inside the system. reply HumblyTossed 13 hours agorootparentprevBecause the market is barely better than a ponzi scheme. There's ___just___ enough laws around it to keep people somewhat okay with it. reply JackFr 12 hours agorootparentThat’s nonsense. Markets are the best way we’ve come up with to allocate capital. Committees and commissars do not do a better job. reply z3phyr 3 hours agorootparentThe potential for benevolence of a market is lesser than an enlightened individual. reply sooheon 2 hours agorootparentYes, but the likelihood of an individual being enlightened is less than either. reply vkou 2 hours agorootparentprev> Committees and commissars do not do a better job. Then why is internal governance and resource allocation inside companies done by committees and commissars and dictators, instead of by an unplanned free market? reply JackFr 2 hours agorootparentThat’s actually a really good question. I would direct you to Ronald Coase and other writing on the theory of the firm. https://en.m.wikipedia.org/wiki/The_Nature_of_the_Firm https://en.m.wikipedia.org/wiki/Theory_of_the_firm reply Eisenstein 10 hours agorootparentprev> Markets are the best way we’ve come up with to allocate capital. Properly regulated, competitive markets. Aerospace regulation is based on a lot of trust, which Boeing seems to have exploited, causing this problem. The market is not competitive; there are only two players and the output of only one of them cannot meet demand. > Committees and commissars do not do a better job. Dichotomies are good for making punctual arguments online, but you do yourself a huge disservice by using them to frame the options in your own mind. Do you honestly think that the options are 1. Antisocial free market allowed to do whatever it wants for capital gain, or 2. Despotic communism? You are smarter than that. reply JackFr 7 hours agorootparentI could have been clearer, but I honestly meant my point to be limited to the stock market as a means for allocating capital. I do favor markets in general and I understand their limitations. And with respect to allocating capital, stock markets have proven to be better than the varying degrees of state economies. > You are smarter than that. True. :-) reply Rury 6 hours agorootparentprevQuite simply because investors are often chasing after money only (ie profitability), not necessarily a company's productivity or product quality. And the quicker the profits the better (meaning short term is valued over long term). Additionally, not all investors are savvy on what's going on with companies, so they decide to invest in ETFs (which mind you, is now the lion's share of investment activity). Now not all ETFs are the same basket of stocks. Some may have 15 stocks, whereas others may consist of 50. This is done so people can \"choose their risk tolerance\", which is calculated based on various things such as how diversified the fund is (50 stocks is more diversified than 15), what the market caps of the companies are, etc. Anyhow, the point is, choosing to invest in said investment vehicles, has little to do with investing based upon fundamentals, or rewarding productive companies, and more to do with managing a person's personal investment risk. The result? Companies are detached from fundamentals because, quite literally, the majority of investors are not investing based on fundamentals, but based on risk. reply JohnFen 13 hours agorootparentprevThe stock market is all about near-term gains, and as a result it is often irrational and rewards destructive behavior. reply dboreham 12 hours agorootparentprev> Why does the stock market reward idiot shit like this? Wall St geniuses are not engineers. That said, I bought Boeing stock and held over that time frame. I did so because I could see that humans were going to need more planes over the long term, and there are only two vendors. Also I visited the Everett plant with my family on vacation. It didn't occur to me that it would be worthwhile introducing KPI BS and McDonald's management style when constructing things worth 100 million and safety-critical. reply throwway120385 13 hours agorootparentprevBecause the MBAs and financiers have taken everything over and are working their way through our government now. reply toss1 11 hours agorootparentprevBecause the entire rewards system is built around short-medium term financial gains. It is a very old story. People build a company with deep knowledge and caring about what actually makes great products. Financial managers get involved to manage the money aspects of the business. Financial types want a lot more control to make the company more profitable. The financial management has no actual clue what makes the company valuable. They only know what makes more or less cash flow in this or that direction. But, credit where due, they DO know how to make that work. They start financially 'engineering' the company for near-term profits and higher stock prices. This works. This works fantastically well. Everything looks leaner, teams of younger workers are sometimes orders of magnitude cheaper than the highly experienced teams, and no one can tell the difference from outside. Profits are higher, stock prices hit record high after record high. Cash is spent on stock buybacks and not R&D or retaining institutional knowledge. Warning flags start showing up in product and service quality indicators, but are ignored and even suppressed. The problems start multiplying at increasing rates, then exponentially increasing rates. Eventually, it starts to get serious. But by then, the \"financial geniuses\" have long since cashed out and the core of the company's workforce, ethos, and institutional knowledge has been so gutted that there is no recovery. The death spiral starts in earnest. The only questions are whether for Boeing, being a critical keystone in the US aerospace and defense industry can or will be allowed to fail, and, if not, if there will be an actual engineering-based turnaround, or if it will be a Soviet-like zombie company for how many years? Forkin' MBAs, they'll kill it every time. reply api 12 hours agorootparentprevFew stock market investors bother to look beneath top line numbers like profits, revenue growth, etc. Number go up, so stock goes up. They're exploiting the uninformed, which in this case are retail investors. reply listenallyall 11 hours agorootparentprev> Why does the stock market reward idiot shit like this? Because Boeing boosted revenue from $60 to 101 billion during the time frame. And had just a single competitor. The current stock price is less than half of its 2019 peak. reply vkou 12 hours agorootparentprev> Why does the stock market reward idiot shit like this? Because as someone buying stock, I have no idea whether these kinds of things are right and necessary to reduce bloat and redundancies in the firm, or idiotic and self-destructive. All I know is that I probably want to be buying stock in firms that are more profitable, as opposed to less profitable. Or, at least, firms that other people think are going to be more profitable. reply hughesjj 13 hours agorootparentprevI blame index funds. Pump the % gain, index funds buy it up because it looks like a better ROI. Abuse that by doing short term shit and ride the wave of self fulfilling prophecy by the index funds buying into it (amplifying noise into a signal) and leave retail/workers holding the bags. I get that statistically DIY'ing your portfolio will almost always lead to worse returns but I really do wish I could exclude certain stocks from my index funds. reply scarmig 13 hours agorootparent1) That's not how index funds work: they attempt to track a target market index. At most, it happens indirectly: get your company into the major indices by a short-sighted depletion of capital, and you can get some level of lift from index funds blindly purchasing your stock (though IIRC it's not a huge effect). 2) You can effectively remove certain companies from an index using derivatives in addition to the index fund. Alternatively, look into direct indexing, where you attempt to track an index by directly owning an appropriately weighted basket of stocks, though it tends to be more complicated, have greater tracking errors, and have higher fees. reply lotsofpulp 13 hours agorootparentprevIndex funds do not buy shares because shares “look like a better ROI”. Index funds buy because non index funds buy (and same with selling). reply Analemma_ 12 hours agorootparentprevI don't think the timing adds up for this explanation. Friedman introduced the shareholder value doctrine in 1970, and Jack Welch's Pierre Hotel speech that kicked off the era of slash-and-burn management was in 1981. Meanwhile, index funds were a tiny fraction of assets under management until well into the 2000s. reply rqtwteye 10 hours agorootparentI am starting to believe more and more that the shareholder value movement has done enormous damage to the social fabric. It basically declares that the only stakeholders of an economy are owners. Anybody else doesn’t count. If this doesn’t change, then progress in AI and robotics will lead to a very dystopian society with a few haves and many have nots. reply yowzadave 12 hours agorootparentprevIt seems like this is the same pattern that we've seen happen more broadly in the tech industry over the past year--the big tech companies think they can juice the bottom line by reducing headcount, and the increased profitability will outweigh any negative impact on their engineering performance. It's a perverse incentive that seems very difficult to turn around once it starts happening. reply makerdiety 10 hours agorootparentprevHow about eliminate your employees to pump up the stock selling price or whatever and instead of removing the best subordinates, keep them, give them automation capabilities, and remove the unintelligent dross? That's much better than basically destroying your own company because you don't know how to progress forward and upward. This privilege is reserved for the few who can I guess. reply sitkack 9 hours agorootparentprevThis is what Google is actively doing. The layoffs continue and they are culling the most senior employees. reply listenallyall 11 hours agorootparentprev> millions of dollars fewer per year in headcount expenses. I don't know how much they saved by forcing out highly-paid employees, but it was a tiny amount compared to the 40 billion in additional revenue earned between 2008 and 2018 (60 to 101 billion). The stock market rewarded the company primarily because of the revenue gains. reply unsui 13 hours agorootparentprevThe only thing that seems to work nowadays is name-and-shame (unless you run for president, apparently). Who are these folks that deserve to be outted for gutting an American institution? I'm sure they're still around, practicing their strain of vulture capitalism. UPDATE: Looks like the article points out the following main culprits: * Jim McNerney * Dave Calhoun reply forgotmyinfo 13 hours agorootparentprevY'all're gonna hate this, but financialization and the relentless pursuit of profits. Every time this stuff happens, people ask why, and it's because of greed. When you focus on making money above all else, this is what happens. It's not a mystery. reply vundercind 12 hours agorootparentIt’s this, absolutely. Professional managers trained in finance who either don’t know or don’t care about the actual business they’re managing. Work = moving money around a spreadsheet and all else is incidental at best and something to be avoided at worst, doubly so if it can’t be captured in a spreadsheet with a dollar value attached. reply constantcrying 10 hours agorootparentprevNo. Under nearly any other circumstance a company like Boeing would simply go under. If a car manufacturer pulled something like this they either have to fix it really fast or have to face severe financial consequences. You have to realize that Boeing's customers have no alternative. They will be buying planes from Boeing. reply pseingatl 8 hours agorootparentUnless the DoJ splits up Boeing, which is what they should do. If Apple's iPhone is a monopoly with dozens of Android alternatives, what does that say about Boeing? reply trilobyte 12 hours agorootparentprevThis is where regulation steps in. A regulatory body should make the cost of certain failure scenarios so painful that companies are incentivized to make better choices. We probably don't need regulations about the color choices of t-shirts, but safety & testing for mass-transit vehicles might be warranted. reply jandrese 12 hours agorootparentThat's the future guy's problem. So long as it is possible to cash out before the consequences happen that sort of regulation won't move the needle much. Making it illegal to be a bad CEO is one of those things that sounds intriguing on paper, but would be a nightmare to implement in real life. Prosecutor: \"You inflated investor returns by sabotaging the future survival of the company and made shoddy products that killed people.\" Former CEO: \"So what?\" The worst part is that this is a real problem. So many formerly strong companies have been brought down by this behavior that it is becoming notable when it doesn't happen. We are allowing these guys to destroy the American economy slowly just because it makes them and their close buddies ridiculous money. And of course the government is largely captured by these same people, so Washington isn't going to help. Just so frustrating. reply rybosworld 11 hours agorootparentThis phenomenon also explains some others that may or may not be surprising: 1. Founder led companies have higher returns. And it's by A LOT. Hard to quantify exactly but, I've seen quoted numbers as high as 20% outperformance for founder led companies. 2. The biggest corporations never remain the biggest. Where is the Dutch East India company today? More recent examples: IBM was overtaken by Nippon Telephone, was overtaken by Exxon Mobil, was overtaken by GE, was overtaken by Microsoft etc. 3. It's not very common that a company stays in the S&P 500 for more than 30 years. The average lifespan is 21 years. The common thread is that as soon as the sociopath MBA's take over, they Boeing the whole business. reply malermeister 12 hours agorootparentprevIt's almost as if an economic system based on maximizing greed instead of reigning it in was not sustainable or desirable. reply therealdrag0 8 hours agorootparent*for some domains. reply nyolfen 12 hours agorootparentprevnext [5 more] [flagged] vundercind 12 hours agorootparentI grow less and less tolerant of “stuff just is, you can’t, like, judge it, man” the older I get. reply rybosworld 11 hours agorootparentA lot of people (sizeable majority?) seem to go the opposite way when they get older, so that's pretty interesting. reply vundercind 10 hours agorootparentI’m less interested in judging most things. Started actively jettisoning that impulse in my 20s. It’s the “pft, but that’s just morality and like that’s relative and stuff therefore we should disregard it” sort of thing that I increasingly have less patience for. I’m less quick to dismiss terms like “greed”. reply truckerbill 12 hours agorootparentprevEven most economists these days would agree that this is a really bad take (invisible hand). You should read more than the punchline of that Adam Smith book and you would find that even he would agree reply Cheer2171 13 hours agorootparentprevThe intention wasn't to destroy institutional knowledge. The intention was to cut costs in the short term, largely through outsourcing and turnover. Why pay a senior engineer a huge salary when you could replace them with a consultant in their twenties? They just didn't think or care about the consequences. reply margalabargala 13 hours agorootparentThey adopted a philosophy of management that explicitly assigned no value to institutional knowledge, and thus eliminated anyone who had it as they were not considered worth their salary. From the article: > Boeing had come under the spell of a seductive new theory of “knowledge” that essentially reduced the whole concept to a combination of intellectual property, trade secrets, and data, discarding “thought” and “understanding” and “complex reasoning” possessed by a skilled and experienced workforce as essentially not worth the increased health care costs. reply bfrog 12 hours agorootparentThis has been done so many times at this point, shouldn't MBAs have case studies covering the \"how companies have rotted from shit decisions made by bean counters\" 101 course? reply mook 10 hours agorootparentDoes it matter to the MBAs? The effect is on long enough terms that they'll be gone by the time everything falls over. They're not there to maximize long-term value, just to get good enough to get promoted and then maybe switch companies. reply swader999 13 hours agorootparentprevThis is true, they also cut costs by 'finding' less defects in QA, deferring them to production deployment several quarters out. reply bumby 12 hours agorootparentThis is the irony of good QA. 1) Company starts to notice a lot of quality problems. 2) Company institutes a good QA program. 3) Company notices less quality problems. 4) Company cuts QA program because there seems to be less need for it. Wash. Rinse. Repeat. (The same can be said for safety when dealing with low probability events). reply FrustratedMonky 12 hours agorootparentYes. It is raining. I use an Umbrella. Still raining, but I am no longer getting wet. I must not need the umbrella. Close the Umbrella Get wet again. reply bumby 11 hours agorootparentIn that case, the causality is easy to determine. But that’s not the case with more complex systems, so it’s easier to rationalize a bias (I don’t need this expensive QA) reply ChrisMarshallNY 9 hours agorootparentprevIn my experience, the term \"tribal knowledge\" is a pejorative, and has been disparaged by many authors (some, that I respect). Also, in my experience, \"tribal knowledge\" is an essential ingredient in classical Maximum Quality engineering. I'm not saying that it's the only way, but I have seen many, many other ways fail. It's something that -no exaggeration- humans have been doing for thousands of years. It's just that we have a crew at the top that sincerely believe they know better. Every now and then, one hits it out of the park. The rest ... not so much. reply downrightmike 13 hours agorootparentprevRather: Money > consequences. And so far, they've been right. How likely will old managers that have long left, but fully participated, be held accountable? reply Simulacra 13 hours agorootparentYou may be right.. your comment reminded me of the formula from Fight Club. Maybe the airlines made that calculus, reasoning that, after all this time their planes were safe enough, and the chance of an accident were low. Even still, it was cheaper to settle lawsuits. \"A new car built by my company leaves somewhere traveling at 60 mph. The rear differential locks up. The car crashes and burns with everyone trapped inside. Now, should we initiate a recall? Take the number of vehicles in the field, A, multiply by the probable rate of failure, B, multiply by the average out-of-court settlement, C. A times B times C equals X. If X is less than the cost of a recall, we don't do one.\" reply david422 12 hours agorootparentThe Ford Pinto: https://en.wikipedia.org/wiki/Ford_Pinto#Cost%E2%80%93benefi... reply marcosdumay 12 hours agorootparentprevThe airlines brought a high-quality aircraft. Up to the first failures of the Max, there was no reason at all to expect Boeings to be badly done. reply djbusby 13 hours agorootparentprevThose old engineers cost too much! And we already know how to build planes. So, we can ditch them, my quarterly KPIs look good and with the money freed up from pushing them out it can land in my bonus check! reply pseingatl 8 hours agorootparentOr 20 billion in stock buy-backs, juicing the price. reply hwbunny 13 hours agorootparentprevThat's the million dollar question. Why talented people are forced out? Like managers/other key members have a mission and if you somehow not fit in their \"world view\", you get hell. reply Tagbert 13 hours agorootparentprevPerhaps because the senior people were at a higher pay grade? If you bump off the expensive employees, your overhead goes down. Better numbers next quarter so you get a bonus. reply alistairSH 13 hours agorootparentIt's in the article. Not just senior = higher pay. Senior = more likely to stick to existing (known good) safety/QC processes. Boeing didn't want QC at all - they wanted the guys assembling the planes to do their own QC (which is likely illegal per FAA regulations). Toss in a side of union busting. And a dessert serving of outsourcing to the lowest bidder, regardless of that bidders history in the space. reply labster 12 hours agorootparentprevSenior people also cost more because their health care costs more. Of course discriminating against older people is illegal, so they cut down on senior staff which just happens to have the same cost reduction. Funny that. reply vpribish 12 hours agorootparentprevthey did not. this article and many people are sensationalizing it to get attention and push whatever their angle is. it was short-sighted, stupid, greedy, and wrong, but not intentionally suicidal (let alone homicidal!). reply Brian_K_White 1 hour agorootparentprevMost of the article is spent describing exactly why. reply autokad 13 hours agorootparentpreva lot of people say things like 'stock price', but that's missing the point. the lesson is in the nuance. its many factors, effecting all aspects of our lives now honestly. - young people's disregard for the knowledge of people older than them. This can be an essay in itself, but there's the idea that the reasons why people are doing things the way they are is because they are stupid, something like: \"you are young and you knows how to do everything right if only these dumb old people would get out of my way.\" I had a friend do a start up to make bourbon in 3 months. He thought all those alcohol producers that take 5-30 years making them were doing it wrong. I am like, definitely give it a go but understand that \"I am sure they thought about this'. - management focuses on nonsensical metrics. In recent history, you have to be data driven, focus on metrics, ignore everything else, its the new religion. An example is how technical support teams focus on having 0 tickets open, so support engineers just close tickets even if the customer isn't helped. but hey, that red line is pointing down and to the left right? win! And as with boeing, they made their metrics look really good, look, no more defects! all you have to do is stop reporting them. - companies willing to outsource critical components of their business. I never understood this one, I don't care how 'cheap' it is, you don't outsource critical parts of your business. at best, they don't have the same stakes as you do on the matter, at worst they steal your IP and/or become your competitors. reply tomthehero 13 hours agorootparentDon't blame this on young people, it's probably mostly post-40 dudes who run the board of these large companies reply autokad 12 hours agorootparentyoung dudes of the time, that are now hitting their 40s. Dont get me wrong, the new young are doubling down on that world view. reply samatman 10 hours agorootparentprev> I had a friend do a start up to make bourbon in 3 months. He thought all those alcohol producers that take 5-30 years making them were doing it wrong. I am like, definitely give it a go but understand that \"I am sure they thought about this'. I realize this is focusing on the example, but no, established bourbon distillers aren't going to stop barrel aging. It's part of the brand, it's part of what people pay for, and they have no reason to. Your friend might have been overconfident, I don't know, but macerating oak chips at high temperature, getting the process right, adding flavorants: if he succeeds in making a high-quality product, great! Am I skeptical? Yes. But again, the established distillers didn't consider and reject the idea of making liquor this way because it's a bad idea, they wouldn't do it because that's not bourbon. If he's successful, they still won't do it, because it's not bourbon. He can sell to people who don't care, though. If it's good, I'd get a bottle. reply jbreckmckye 10 hours agorootparentprevIt's a lot easier to make your outsourcing strategy stick, if you no longer have an alternative. reply tanseydavid 13 hours agorootparentprev>> why do this intentionally? Myopia + greed is a hell of a drug. reply kwhitefoot 13 hours agorootparentprevIt's a side effect of reducing the power of those awkward people who want to spend money on well designed aeroplanes. reply bsder 12 hours agorootparentprevAre any of the executives who did this in jail? No? Well, carry on, then. None of the executives responsible for this have paid any price. None of the investors or board members who allowed this paid any price. And the worst part: it's not clear you can fix it, now. Even if you completely busted out every executive and wiped out the investors, there is no path forward since those executives pushed out all the engineering knowledge. reply FrustratedMonky 12 hours agorootparentprev\"intentionally\" is too strong a word here. More -> intentionally cut cost by eliminating experienced people. Not -> intentionally getting rid of knowledge. even the worst managers wouldn't admit to wanting to loose knowledge. reply pyrale 12 hours agorootparentprevSome people in organizations can't take no for an answer. They want to see their orders followed, and if they see you as a roadblock, you will be marginalized, sometimes with harm. That's not always bad, sometimes employees drag their feet when they shouldn't. But in some situations (for instance, one arm of the company gaining the upper hand), the people in power are so convinced that their own perspective and goals are right, that they think they don't need to listen or understand the big picture. Ad to this that sometimes an exec has sociopathic tendencies, and you have an explosive cocktail of harassment and destruction of valuable knowledge. The more resilient the company, the more entrenched this behaviour can get, and the more irreversible it will become. reply stephenhuey 13 hours agoparentprevI learned some things reading this article from 2 days ago: Boeing’s Dead Whistleblower Spoke the Truth https://www.thefp.com/p/boeings-dead-whistleblower-spoke-the... The Free Press reply zer00eyz 13 hours agorootparentThe entire first half of this (tfp directly above this comment) article blindly supports the spin that there is some conspiracy where someone killed him. HIs own family goes into great detail all over the press about how he had anxiety and ptsd. That he quit his job on DR orders or the stress was going to give him a heart attack. The shit Boeing did to him was awful (stress, anxiety and ptsd) and Boeing should be blamed for that. They should be held accountable for that. Making his sucicide \"Fishy\" discredits the pressure he was under and its cause. Playing at the edges of conspiracy theory also serves to discredit the author of the article and the validity of everything else they are saying. The man killed himself. The actions of Boeing played a part in that. reply smsm42 11 hours agorootparentYou say it like \"anxiety\" and \"stress\" are synonymous to suicidal. I am a pretty anxious person, and sometimes have a lot of stress at work, and experienced burnout in the past too. That doesn't mean I am about to shoot myself in a motel parking lot - or anywhere else, for that matter. This binary view of mental health - either a person is \"healthy\" which means 100% perfect, or he's not - and then anything can be expected, including a suicide at any arbitrary time - is nonsense. It's completely legit to ask how comes the person who wasn't suicidal, and actually told people that he's not - suddenly turns to commit suicide in the middle of court testimony, without any warning signs or explanation. Saying \"oh, he was anxious and stressed about work\" is not a good explanation to this. Maybe there was an explanation, maybe there wasn't, but pretending \"anxiety\" explains it is nonsense. reply zer00eyz 11 hours agorootparentHis whole lawsuit was about being forced to retire 10 years early because Boeing forced him out for whistleblowing. Thats whistleblowing as in past tense. He complained to the FAA and the FAA said 'yes John you're right'. Not to diminish your mental heath but the whole argument here is that what Boeing around \"stress\", \"pressure\" and \"anxiety\" was far worse. Its not like is anti whistleblower retaliation case (AIR21) was going to be some massive blemish for Boeing. It's not like it was going to be a 100 million dollar write down. It is basically \"wrongful termination\" that they are fighting. And it would be round 2 on this case (the first was \"dismissed\"). https://archive.is/iUzxR#selection-995.134-995.139 does a bit better job of surfacing more of the details. Ones that paint boeing in a far worse light without the sensationalism of a tv script murder plot. reply smsm42 4 hours agorootparentBeing forced as whistle-blower and being suicidal are again very different things. Especially when he was in the middle of proving he's right. And right in the middle of the fight, between the testimonies, after he spent so much effort to prove he's right, he decides \"fuck it all\" and quits abruptly? Doesn't add up. Maybe something else happened but I just am astonished how easily people dismiss it. Ah, he was anxious and stressed? We'll, it's only natural then. No it's not. reply makerdiety 10 hours agorootparentprevStress and anxiety make you more vulnerable to bad decisions like suicide. Stop trying to turn stress and anxiety into an aesthetic personality trait and fashionable dress. Mental illness is not a dress that you can wear. It's toxic stuff to get rid of or at least mitigate. reply singleshot_ 10 hours agorootparentStress and anxiety are foundational to high performance. Imagining that stressed anxious people are mentally ill is ridiculous. reply segasaturn 13 hours agorootparentprevThere's more than enough circumstantial evidence to support the allegations of foul play here. When people kill themselves, they usually do it somewhere private and personal to them, like inside their home, or their car. Not in the parking lot outside a courthouse. reply isleyaardvark 12 hours agorootparentAnd they generally don’t tell a friend “if anything happens to me, it's not suicide”. reply layer8 11 hours agorootparentFrom TFA, it seems that it was someone else (still alive) who said that. reply metabagel 11 hours agorootparentFrom \"the f..ing article\"? reply layer8 11 hours agorootparentSee https://news.ycombinator.com/context?id=39488667 . It’s commonly used on HN. reply kjkjadksj 12 hours agorootparentprevUnless its one last troll against boeing on the way out. Why go quietly if you are going to go when you have a shot to majorly embarrass the company one last time? reply dash2 29 minutes agorootparentprevThis is clearly false. \"He did it in the parking lot\" is nothing like enough evidence to convict anyone. It isn't remotely enough even on the balance of probabilities. I have seen zero evidence for the conspiracy theory, and strong evidence against it, including the fact that his own family think his death was suicide. Please do not casually spread conspiracy theories. They poison democratic debate, make us all stupider, and distract attention from important, evidenced realities, like the others mentioned in the article. reply dralley 12 hours agorootparentprev>or their car That's where he killed himself. Inside his truck, in the parking lot. reply kjkjadksj 12 hours agorootparentprevOn the other hand, he might have wanted to go out leaving exactly this sort of mess of optics for boeing PR to deal with. Most people who commit suicide probably aren’t in the national spotlight against the very thing that brought them this point beforehand. reply lstamour 13 hours agorootparentprevThe article above and every other article I've read says, \"he was found in his truck\". That's a personal vehicle, and assuming it was locked, enough to suggest that it was self-inflicted. reply Supermancho 12 hours agorootparentI can close a locked door after shooting someone in the head. I'm not sure how this follows that \"it's enough\". After years of criticizing Boeing, he kills himself during his deposition? I don't think so. reply singleshot_ 10 hours agorootparentprevPrime Boeing juror material reply zer00eyz 12 hours agorootparentprev>>> or their car. Not in the parking lot outside a courthouse. NO: Barnett's body was found in a vehicle in a Holiday Inn parking lot in Charleston on Saturday, police said. Or you know this The family says Barnett's health declined because of the stresses of taking a stand against his longtime employer. \"He was suffering from PTSD and anxiety attacks as a result of being subjected to the hostile work environment at Boeing,\" they said, \"which we believe led to his death.\" FROM: https://www.npr.org/2024/03/12/1238033573/boeing-whistleblow... The man was found dead, with a sucide note (hand written) and his own gun in his hand. You know what happens when gun owners get the urge to kill themselves. They kill themselves. Guns make suicide less of a cry for help and more or less \"effective\". Any article that doesn't mention what his family had to say about the matter is not only creating a narrative, but they are openly disrespecting the family of a dead man to grab attention and headlines. How about todays interview with his OWN FAMILY: FROM HIS MOTHER: If this hadn't gone on so long, I'd still have my son, and my sons would have their brother and we wouldn't be sitting here. So in that respect, I do,\" Vicky Stokes said when asked if she places some of the blame for her son's death on Boeing. OR THIS: Stokes and her son Rodney Barnett said they do not want to comment on whether they believe he died by suicide until the investigation by the Charleston police department concludes. source: https://www.cbsnews.com/news/john-barnett-boeing-whistleblow... reply lyu07282 11 hours agorootparentIt's not like we know or will ever know the details of and the extend of the investigation, the note was actually reported as a \"white piece of paper that closely resembled a note,\", what was on the note? Were his fingerprints on the note? Was handwriting analysis done? Did the gun belong to him? That wasn't reported either. Was it registered to him/ when/where did he buy it? Was there gunpowder residue on his hand? Does the trajectory and blood splatter analysis all match? Was there surveillance footage of the car? What was his last cellphone usage? Part of the reason why people jump to conclusions is because of a distinct lack of rationalist reporting by police and media. They don't tell us the empirical evidence because we are supposed to just believe them, and trust in their competent investigation, but that doesn't really work, at least not everyone is going to be satisfied by that demand. That's not to say it wasn't a suicide, it just means we don't know either way and will likely never know. But it crucially also doesn't mean sufficient evidence couldn't be presented to convince a reasonable observer. reply zer00eyz 11 hours agorootparentSure: What we do know: this was an AR21 case. It was him suing boeing for forcing him to retire early and not promoting him because he was \"whistle blowing\". This is a case that had already been dismissed once. On the matter of that, the FAA already got his reports and agreed with him. The harm to Boeing from his wistle blowing was finished. They were probably paying more for lawyers to fight this than it was going to cost to settle. So this wasnt about Boeing loosing anything other than cash at this point. If we're going to speculate we should be asking if Boeing was fighting this out of spite rather than making a good business decision. The family themselves have spoken up: that he was troubled, and they firmly blame Boeing for his death. The way they are going about it says \"we know he killed himself\" ... they just think Boeing drove him to do it. They are coy with the conspiracy theory angle cause it just make boeing look bad... There is a really interesting narrative here about stress, mental heath, and suicide for gun owners. Topics that the press wants to touch less than the ones your suggesting they ignore.... reply lyu07282 11 hours agorootparentI care infinitely more about the questions I asked than whatever the family had to say. Because questions about fingerprints and gunpowder residue are concerning the physical evidence that could prove suicide to a reasonable degree. I don't really care about talking about circumstantial evidence when the physical is right there. The reason why people aren't convinced by the “this wasn't even about his whistleblowing, he already disclosed everything, so Boeing has no motive“ argument is because it isn't just about stopping whistleblowers, it's about the chilling effect for other potential, current employees. We can brush it all aside as crazy conspiracy theories, but I think that's actually very harmful to society. Conspiracy thinking is very damaging, our response shouldn't be “shut up and trust authority“ when somebody asks about forensic evidence. reply zer00eyz 11 hours agorootparent>>> it's about the chilling effect for other potential, current employees. We agree on this 1000% \"If this hadn't gone on so long, I'd still have my son, and my sons would have their brother and we wouldn't be sitting here. So in that respect, I do,\" Vicky Stokes said when asked if she places some of the blame for her son's death on Boeing. FROM: https://www.cbsnews.com/news/john-barnett-boeing-whistleblow... Let me restate that: THE MANS OWN MOTHER SAYS BOEING DROVE HIM TO KILL HIMSELF They didn't need to hold a gun to his head and pull the trigger. The just needed to fuck him over badly enough for long enough for this to be the inevitable outcome. Blow the whistle all you want kids, Pappa Boeing gonna take your job and fuck you over and there aint nothing you can do about it... Thats the chilling narrative if there ever was one. reply sitkack 9 hours agorootparentShe should sue Boeing for wrongful death. If they really continued this behavior, and she doesn't sue, they got exactly what they wanted. reply michaelmrose 10 hours agorootparentprevHandwriting analysis and blood spatter is mostly garbage. If he was shot with a gun inside the car from a reasonable angle its not going to be immediately obvious whether he did it or not unless they left bloody fingerprints on the door handle after shooting him twice. reply darkerside 7 hours agorootparentprevFirst I've heard of a handwritten note. Any details? reply Cornbilly 10 hours agorootparentprevIt appeals to the \"free thinkers\"/\"heterodox\" (empty-headed contrarian) crowd that TFP caters to and that infests every tech website on the net. reply euroderf 12 hours agorootparentprevA billion dollars here, a billion dollars there, pretty soon someone needs to be taken out of the picture. reply zer00eyz 11 hours agorootparentWhat billions of dollars. The man had already been on film. He already has written statements everywhere. The FAA already agreed that what he said had happened. He was in court for AIR21 case... to get money out of boeing for himself, for 10 years of early retirement. Candidly Boeing was probably paying more for the lawyers they were using to fight him than they would have paid just settling. There weren't billons on the line with this. reply cjbgkagh 11 hours agorootparentThe reason you don’t settle is to discourage others from doing the same thing. It would also be the reason to ‘suicide’ someone even if they were not costing you much money. reply sitkack 9 hours agorootparentExactly, they weren't stopping him, they were stopping every other future whistleblower. Imagine if even 3 more people stepped forward. reply stephenhuey 13 hours agorootparentprevOn a previous HN discussion, plenty of people here believed it was fully possible that someone at Boeing essentially pulled the trigger and gave plenty of examples, even from a huge successful Silicon Valley company, of corporate folks doing stranger nefarious things than would be believable in film. As someone who has known multiple people who committed suicide, I'm not sure I can feel as certain as you that this was a suicide without more evidence. reply thatguy0900 12 hours agorootparentAfter reading the story of ebay execs harassing a random completely unimportant couple, to the point of repeatedly mailing them threatening or disgusting packages, I can't discredit killing a witness for a real tangible reason. reply mateus1 12 hours agorootparentMonsanto also did some pretty awful persecution to scientists… there are plenty of examples in American contemporary businesses reply mschuster91 12 hours agorootparentprevOh yeah, I remember that one [1]. One of the bastards got five years in prison - one of the very very few exceptions to my general line of calling for prison abolishment. [1] https://www.theguardian.com/technology/2022/sep/29/ebay-exec... reply araes 11 hours agorootparentPrefaced with, while horrifying, that may also have been one of the funnier corporate stories I've read in the last several years. Note, horrifying from the Steiner's perspective. People with private jets who can fly across America to leave bloody masks on your porch. Yet, it's cartooonishly preposterous. Seven people charged, seven guilty pleas, and the heads of Security and \"Resiliency\"? They flew across the country to do the equivalent of college harassment and B&E ... in a residential garage? Baugh worked for the CIA? His wife works for the CIA? Running Charlie's Angels as the security team (sorry, Jim's Angels)? Mandatory pop culture videos? What did I just read? Unfortunately, it always has a Nelson response, no matter how funny. \"Aww, those are the people who run corporate America...\" They run my economy. NYT Archive: https://web.archive.org/web/20201213125301/https://www.nytim... WP: https://en.wikipedia.org/wiki/EBay_stalking_scandal reply whythre 12 hours agorootparentprevSeems pretty convenient to the people in power that he had the courtesy to off himself before he could hurt them in court. reply dralley 12 hours agorootparentIt. was. a. defamation. lawsuit. The second of two, because he lost the first one. People act like this was a criminal proceeding. It was not. He'd already been testifying and speaking publicly about Boeing for more than 5 years. He sued them because of Boeing's attempts to defame his character to downplay the allegations which have been public for a long time. reply ladzoppelin 12 hours agorootparentI am not saying your wrong but who were the faulty suppliers for all these claims? Is it possible things would start unraveling for something much bigger than it already has? The other motive would also be to send a message which it definitely did. I find it weird that he would ruin the chance of future whistle blowers coming forward by doing this the day after the court appearance, its strange. reply zer00eyz 11 hours agorootparentRight... defamation is a good analog for this. Its under AIR21... This case was him suing Boeing for money. The claim was that his whistleblowing was the reason he didn't get promoted and was forced to retire early. Thats whistleblowing past tense, the FAA already said the things he was whistleblowing on were in fact true, and Boeing was at fault. He had lost this case once, but his lawyers felt that he could win this 2nd time around as there was a preponderance of evidence. The table stakes for this were in the 10's of millions at best, a trivial sum of money. >>> I am not saying your wrong but who were the faulty suppliers for all these claims? It was all, already, long ago, unraveled: https://archive.is/iUzxR#selection-1111.393-1111.775 reply ladzoppelin 10 hours agorootparentIts not opening but I appreciate you adding other info to the conversation. Do you think as the trial proceeds we will gain new information? reply dralley 11 hours agorootparentprevWhat was his testimony in a civil (not criminal) lawsuit which had already been given many times before both in public and in other lawsuits going to unravel? Especially given the number of additional investigations going on? Why would I just assume that it exists? And why would it ruin the chance of future whistle blowers coming forwards? Was he supposed to imagine that everyone was going to start believing conspiracy theories about his death? reply ladzoppelin 11 hours agorootparentI mean, do you really think this will not deter future whistle blowers lol? \"conspiracy theories about his death\" You mean like that 30 year coordinated Epstein situation? reply ClumsyPilot 8 hours agorootparentprev> They should be held accountable for that. In what way, exactly? Because from where I am sitting, it appears Boeing would enjoy unconditional support of US government no matter what they do. reply partiallypro 11 hours agorootparentprevI don't really even get the conspiracy theory that he was murdered, if Boeing etc are all so knowing and powerful why didn't they kill him years ago, well before he could tell his tale? Now they kill him because he already spoke out and they want to put the spotlight on themselves? The whole thing doesn't really make a lot of logical sense. reply ClumsyPilot 8 hours agorootparent> Boeing etc are all so knowing and powerful It sounds like you have some unrealistic overestimate of your safety against a determined criminal. This just an older gentleman, far away from home, alone, with no security. One method is to hire a junky, or a homeless person, or some other desperate person to commit a crime. Affordable to the middle class! And even if they are caught, they would not know your identity. Kadyrov regularly assassinates his critics in EU for example, and that's not even his 'territory' so to speak, https://warsawinstitute.org/kadyrovs-hitmen/ reply ladzoppelin 10 hours agorootparentprev\"Boeing etc are all so knowing and powerful\" Wait Boeing makes most of its money through military contracts, downplaying its \"power\" and importance is slightly disingenuous . reply partiallypro 7 hours agorootparentYou completely missed the point that...if Boeing knew he was going to blow the whistle, and they are so powerful...they'd have killed him beforehand. Not very smart of them to kill someone AFTER they blew the whistle and then make everyone think you did it. That just puts you even more into the spotlight and his testimony is already publicly available. Doesn't sound like a great conspiracy, much less a theory. reply throw7 11 hours agorootparentprevOn the other hand... I can imagine after testifying, the feeling that one had done all one could do. That it was finished and it was his time. reply pdonis 10 hours agorootparentBut he wasn't finished testifying. He was found dead on the morning of what was supposed to be his final day of deposition. reply m463 11 hours agoparentprevIt's really hard to recover from a downgrade in culture. I hear the same kinds of things about IBM. I'm pretty sure there are other examples. The tough part is - it is sad. Read about boeing and Tex Johnston: https://en.wikipedia.org/wiki/Alvin_M._Johnston#Boeing_Compa... and IBM invented the PC: https://en.wikipedia.org/wiki/IBM_Personal_Computer reply margalabargala 9 hours agorootparentOther examples include Xerox and Kodak. I also wonder if it has happened in the past, with a subsequent recovery, to some American car companies? GM pre-2008 perhaps? reply markbnj 9 hours agoparentprev>> It's worth reading, perhaps unless you're going to be flying on a Boeing plane anytime soon. Just returned from Miami yesterday aboard a B757-200. I was intrigued because it has been so long since I've flown on one. The trip down was a 737-Max8 (or 9 I'm not sure). So I wondered if this was a plane that they had dragged out of retirement. Not like Newark-Miami is a backwater route. reply jrs235 11 hours agoparentprevNorminalization of Deviance: https://youtu.be/GN80sx3s4LA?si=de_4xxo1YhFVy0lD reply ryukoposting 4 hours agoparentprevI'll be on two 737 MAX planes going back and forth to Vegas in a couple weeks. Yay! reply atmosx 6 hours agoparentprevIMO the FAA’s approach and handling was the most shocking aspect. Not sure what purpose the FAA serves anymore. reply deburo 6 hours agoparentprevHm, i smell a google here. What a shame tbh. reply caycep 13 hours agoparentprevI am silently grateful to JetBlue for ordering Airbuses from the get go... reply BiteCode_dev 13 hours agorootparentAirbus has a limited production capacity, and they are maxed out with this scandal. So Boing is still getting orders, because the world need planes. reply stcredzero 12 hours agoparentprevit will be unsurprising to you to hear that shortly afterwards, Boeing began abusing its most senior employees into leaving. Sounds a bit like what happened in newsrooms and at newspapers in the past decade and a half. (Except in that case, it was bottom-up, not top-down.) reply justrealist 12 hours agoparentprev> It's worth reading, perhaps unless you're going to be flying on a Boeing plane anytime soon. This is all bad for Boeing, but at the end of the day, nobody has died on an American carrier in a Boeing plane in a very long time. Aircraft safety is layers on layers on layers. Let's not FUD people into thinking that flying on the worst plane Boeing has ever put out is anywhere comparable to the daily risks of driving. reply margalabargala 9 hours agorootparent> but at the end of the day, nobody has died on an American carrier in a Boeing plane in a very long time. This is coincidental. When the plug ripped out of the plane over Portland, it was pure luck that no one was sitting in that row. The seats were shredded. If someone had been sitting there, they also would have been shredded. Boeing and their deteriorated quality culture is directly at fault for that one, and the only thing that prevented a fatality is a coincidence of seating arrangement. As far as I'm concerned, that resets their safety clock. If a new 737 were to literally disintegrate in midair, but by pure happenstance it was entirely staffed and occupied by skydivers wearing parachutes and as a result no one dies, that also shouldn't be handwaved off as \"oh nobody has died in a long time\" just because luck prevented an otherwise sure death in that specific scenario. reply justrealist 8 hours agorootparentEven if, worst case, 3 people had been sitting there and died (and people are tougher than seats), it would only move needle trivially vs cars. reply fargle 4 hours agorootparentand while the fact related to the risk of flying vs. driving are probably true, they are off-topic and irrelevant. the reason that large airline safety in the US is so overwhelmingly good is the preceding 20, 30, 40, 50? years of continuous improvements. until the last 5-10 years that is. we haven't even seen the tip of the iceberg yet. when these 2010's and 2020 planes are 15-30 years old, it's going to be a shit-show. so if you believe that the airlines are too safe, that there is too much margin, they are over-engineered, over-regulated, etc. then that wouldn't be at all irrational. you could trade some gold-plated engineering for profit. you could trade bureaucracy for faster production, maintenance, etc. you could reduce the cost of travel (by how much? it's already cheap). this would be an interesting argument to make. but these decisions should be made in the light of day by the NTSB/FAA, congress, the public, and the shareholders, etc. even then, it's likely that theory would have negative consequences (remember the better-faster-cheaper NASA theory of operation). the problem is that, instead of an honest choice made in public by the appropriate stakeholders and the flying public, these choices and short-cuts were made in secret, illegally, with extreme dishonestly, repeatedly, for at least a decade, for extremely selfish gains, by FAA and boeing executives. that's what's not ok. we're told and we expect the nearly perfect safety to continue. what we got was back to the 1950's-1970's era shit-show. reply mrbadguy 2 hours agorootparentprevI’m sorry, why does it matter that no one has died on an American carrier for a while? Not so long ago, Boeing sent over 300 people to their deaths with their shoddy MCAS scheme. It’s pure chance that this didn’t happen in the USA so I’m not sure I understand the relevance of the nationalities of the deceased. reply theragra 12 hours agorootparentprevThanks reply bsder 12 hours agorootparentprev> Aircraft safety is layers on layers on layers. This is true, but disasters occur because those layers and layers get eroded until there is only one layer left which then fails. The problem is that Boeing has eroded layers and layers and layers of that safety. The question is \"How many of those layers are left?\" reply deviantbit 12 hours agoparentprevWhat do you mean by \"down hill\"? Boeing has developed incredible technologies since the MD merger. They have been profitable w/ these technologies. You make a claim they were going down hill, what do you mean? I have a number of family members that work for Boeing, that have been in executive management, engineering and research. None of them ever mentioned MD as being the beginning of a decline. All of them tell a different story. The problems began with James McNerney. Harry Stonecipher came from MD, and was one of the best CEO's to ever touch that company. The 787 wouldn't have been a thing if it were not for McNerney. If you make a claim, back it up. reply margalabargala 9 hours agorootparentThis is a discussion of an article. You'll find a link to it at the top of the page. If you read the article, I am sure someone as intelligent as yourself will be able to use context clues to figure out what I mean by \"down hill\". That article is what I am backing up my claim with. reply bullfightonmars 7 hours agorootparentprevHa. That’s not the story I have heard from greybeard engineers there before and after the merger. I got the story that Stonecipher wrecked the engineering culture and valued/promoted management at the expense of engineering. Management becoming the only path to promotion and career advancement leaving important engineering groups hollowed out. reply proc0 13 hours agoprev> Swampy believed relying on mechanics to self-inspect their work was not only insane but illegal This sounds like the changes that have taken place in the software industry in the past 10-20 years. Engineers are meant to do much more than engineering, including testing their own software, managing project timelines, etc., however with software nobody dies, you just get crappy software that constantly breaks and needs an update every other day. There's an overall theme here of underestimating how hard engineering is, and as a result expecting a lot more from engineers which then of course causes bad engineering. Not surprisingly this is caused by non-technical people with power. Perhaps the fix is a cultural shift and a renewed respect for people who want to spend all their time specializing in technical skills. reply mattgreenrocks 13 hours agoparentThe real fix is popularizing the notion that management is just as commoditizatable than those they seek to commoditize. Note that in the recent dialogue about AI eating jobs, there's zero mention of whether it could come for management positions. Nothing. Curious, isn't it? Why wouldn't an LLM be good enough at this? I mean, it's really data-driven, right? reply joe_the_user 11 hours agorootparentThe real fix is popularizing the notion that management is just as commoditizatable than those they seek to commoditize. What's described here is exactly what happens when you have \"generic\" management. Generic management finds unneeded expenses and eliminates them. The only way a senior expert isn't a cost to be eliminated is if you have managers focused on and understanding the enterprise they are managing (and no promises with that, however). reply seb1204 5 hours agorootparentWhen the AI has QA/QC as part of the over all requirements should this not solve it? A question of ensuring all requirements are internalized. reply crotchfire 1 hour agorootparentprev> AI eating jobs, there's zero mention of whether it could come for management positions. Nothing. Curious, isn't it? Why wouldn't an LLM be good enough at this? There's a whole book about this, called Rainbows End. Highly recommended. reply passwordoops 12 hours agorootparentprevFrankly I think ChatGPT 3.5 was already good enough to replace the majority of CxO positions reply lrem 12 hours agorootparentWhy not a Markov chain generator? reply paradox460 6 hours agorootparentOr an 8 ball reply margalabargala 13 hours agoparentprev> however with software nobody dies The MCAS issue which crashed two Boeing planes was a software hack. reply SahAssar 13 hours agorootparentWell, yes, but also no. It was a hardware design change that necessitated a software hack (to escape mandatory retraining of pilots) that relied on unreliable hardware, right? Sure, software played a big part in it, but I think it seems like it was more a management and communication failure. If it was just software it'd probably be much easier to diagnose and fix. reply margalabargala 13 hours agorootparentI disagree. The hardware design of the cockpit is intended to be such that any computer inputs also move the pilot's controls, so that the pilots can countermand computer inputs if necessary. In this case, software was written such that this was not possible. The software that operates MCAS operates on a garbage-in-garbage-out model, like most software. There was no software written to determine if the incoming data was garbage, thus the software decided to crash two planes. Here's an article that goes into detail on the software: https://spectrum.ieee.org/how-the-boeing-737-max-disaster-lo... > When the flight computer trims the airplane to descend, because the MCAS system thinks it’s about to stall, a set of motors and jacks push the pilot’s control columns forward. It turns out that the Elevator Feel Computer can put a lot of force into that column—indeed, so much force that a human pilot can quickly become exhausted trying to pull the column back, trying to tell the computer that this really, really should not be happening. > Indeed, not letting the pilot regain control by pulling back on the column was an explicit design decision. Because if the pilots could pull up the nose when MCAS said it should go down, why have MCAS at all? > MCAS is implemented in the flight management computer, even at times when the autopilot is turned off, when the pilots think they are flying the plane. In a fight between the flight management computer and human pilots over who is in charge, the computer will bite humans until they give up and (literally) die. At the end of the day, if the person who wrote that software had written it differently, then those planes would not have crashed and hundreds of people would not have died. reply error503 12 hours agorootparent> At the end of the day, if the person who wrote that software had written it differently, then those planes would not have crashed and hundreds of people would not have died. You can't really blame the software engineers. This was all thought out and tightly specified by Boeing to their avionics subcontractor (Collins, IIRC). This is how it was designed and engineered to work at a systems level - it is a design hack. As far as I know there weren't any software bugs or 'hacks' involved, and the avionics operated as designed (aside from the AoA DISAGREE alert, which was due to a requirements miscommunication, not a bug). It was broken by design, which happened long before implementation, at Boeing. > When the flight computer trims the airplane to descend, because the MCAS system thinks it’s about to stall, a set of motors and jacks push the pilot’s control columns forward. It turns out that the Elevator Feel Computer can put a lot of force into that column—indeed, so much force that a human pilot can quickly become exhausted trying to pull the column back, trying to tell the computer that this really, really should not be happening. The Elevator Feel Computer is a part of the 737NG as well, and would behave the same way in those airplanes when receiving such erroneous AoA data; it's nothing new in the MAX. It certainly did not help the crews during the fatal MAX incidents, and is clearly not an ideal design, but it's also barely a footnote in the root cause analysis, along with the stick shaker and stall warnings blaring at them constantly. The pilots would easily be able to overcome it long enough to get safely on the ground. What was a bigger problem for those crews was that the MCAS has enough trim authority to make it impossible, with any amount of elevator input, to restore level flight - limiting its trim authority was part of the 'fixes' required to get them airborne again. I don't think it's reasonable to blame the implementation of MCAS for the accidents, its existence is to blame, and really highlights how nothing about the 737 platform has been designed holistically - it is a patchwork of hacks on hacks dating from the 1970s, which is difficult to reason about as a whole, and has dark corners. To truly 'fix' MCAS, you need to consider AoA as critical air data (which the 737 does not), and you need to integrate it holistically with the rest of the flight controls (which the 737 cannot, since it is not fly-by-wire), and you need to consider it critical equipment (it's an 'augmentation' and not considered critical on the 737, 'justifying' the lack of redundancy). Once you've done those things, you've basically got the bones of a proper envelope protection system in place, and you've obviated the need for MCAS in the first place. Of course the 737 team couldn't do this, because the business decided that it was more important to avoid (and hide) any differences than to bring the aircraft in line with modern standards. Realistically, this should have been trapped by the safety analysis of the flawed design, which should have considered its effect on the whole flight control system when evaluating it, but Boeing again only considered MCAS to be an 'augmentation' and it got an abbreviated safety review as a result. Some engineers did express concern about some of these factors, but given the environment outlined in TFA, those concerns did not go anywhere, because they would have basically scuttled the idea and sent everyone back to the drawing board, which Boeing was desperate to avoid having already been caught flat-footed with the launch of the A320neo. The 737 airframe needs to be put to rest, it is simply not safe or sane to keep stacking more hacks onto it. But there's no indication Boeing's working on a successor so it's probably going to be on the market for another 20+ years. Hard to imagine folks will probably be flying on an airframe with a 100 year old design (2024 + 20 years before a new revision + 20 years life span = 2064, around 100 years from the 737 launch before they start retiring)! reply canucker2016 11 hours agorootparentBuying an airplane is not the same as buying a consumer item from a big box retailer. It's more like buying an expensive car/enterprise software. There are options. Options cost extra.... excerpts from https://www.nytimes.com/2019/03/21/business/boeing-safety-fe...: As the pilots of the doomed Boeing jets in Ethiopia and Indonesia fought to control their planes, they lacked two notable safety features in their cockpits. One reason: Boeing charged extra for them. For Boeing and other aircraft manufacturers, the practice of charging to upgrade a standard plane can be lucrative. Top airlines around the world must pay handsomely to have the jets they order fitted with customized add-ons. Boeing’s optional safety features, in part, could have helped the pilots detect any erroneous readings. One of the optional upgrades, the angle of attack indicator, displays the readings of the two sensors. The other, called a disagree light, is activated if those sensors are at odds with one another. Boeing will soon update the MCAS software, and will also make the disagree light standard on all new 737 Max planes, according to a person familiar with the changes, who spoke on condition of anonymity because they have not been made public. Boeing started moving on the software fix and the equipment change before the crash in Ethiopia. The angle of attack indicator will remain an option that airlines can buy. Neither feature was mandated by the Federal Aviation Administration. All 737 Max jets have been grounded. “They’re critical, and cost almost nothing for the airlines to install,” said Bjorn Fehrm, an analyst at the aviation consultancy Leeham. “Boeing charges for them because it can. But they’re vital for safety.” “There are so many things that should not be optional, and many airlines want the cheapest airplane you can get,” said Mark H. Goodrich, an aviation lawyer and former engineering test pilot. “And Boeing is able to say, ‘Hey, it was available.’” But what Boeing doesn’t say, he added, is that it has become “a great profit center” for the manufacturer. The three American airlines that bought the 737 Max each took a different approach to outfitting the cockpits. American Airlines, which ordered 100 of the planes and has 24 in its fleet, bought both the angle of attack indicator and the disagree light, the company said. Southwest Airlines, which ordered 280 of the planes and counts 36 in its fleet so far, had already purchased the disagree alert option, and it also installed an angle of attack indicator in a display mounted above the pilots’ heads. After the Lion Air crash, Southwest said it would modify its 737 Max fleet to place the angle of attack indicator on the pilots’ main computer screens. United Airlines, which ordered 137 of the planes and has received 14, did not select the indicators or the disagree light. A United spokesman said the airline does not include the features because its pilots use other data to fly the plane. When it was rolled out, MCAS took readings from only one sensor on any given flight, leaving the system vulnerable to a single point of failure. One theory in the Lion Air crash is that MCAS was receiving faulty data from one of the sensors, prompting an unrecoverable nose dive. In the software update that Boeing says is coming soon, MCAS will be modified to take readings from both sensors. If there is a meaningful disagreement between the readings, MCAS will be disabled. reply proc0 10 hours agorootparentprevI meant software only products like websites, apps, games, etc., but it should be clarified, good point. reply rjbwork 13 hours agoparentprevGreat idea but how will the bean counters and schmoozers get their multi-million dollar bonuses if they can't force engineers to do 5 jobs while paying them for 1? Will never work. reply pfortuny 13 hours agorootparentquality control is most of the times unmeasurable in the short term… reply necheffa 10 hours agoparentprev> however with software nobody dies Well...no actually. This may be the case for _some_ software. I happen to work on (software) products where public safety is a concern. reply seb1204 5 hours agorootparentWell in the story is the point of an software error leading to the plane crash right... reply ccakes 11 hours agoparentprev> however with software nobody dies Software that runs systems which can directly kill people does tend to get a lot of scrutiny, but there is also a lot of software which can indirectly kill someone that doesn’t get the same level of attention https://www.technologydecisions.com.au/content/convergence/a... reply JohnFen 11 hours agoparentprev> however with software nobody dies Unless that software is running a life-critical or potentially life-threatening piece of equipment. People have died from software bugs in such things. reply Terr_ 13 hours agoparentprevThe difference is whether organizations are willing--or forced--to invest in it. That's not automatically a wrong though, since different objects or processes merit different levels of quality. reply oglop 10 hours agoparentprev100% agree. Had a manager that does this try and tell the Challenger story once. He had the lessons of the report exactly backwards. Instead of the managers creating an environment of risk by not understanding the engineering and overriding the engineers, he claimed it was engineers not listening to or informing managers properly. It was wild to me to sit there and hear this manager say the exact wrong lesson of that tragedy. reply lozenge 12 hours agoparentprev> however with software nobody dies Eh, not a good hard-and-fast rule. Fujitsu's Horizon software drove some of its users to suicide. reply ordu 12 hours agoprev> Swampy knew he was caught in a prisoner’s dilemma. If he went along, he was breaking the law; if he didn’t, whistleblowers who complained about unsafe practices were routinely terminated on grounds of violating the same safety protocols they had opposed violating. How is it a prisoner's dilemma? Is it about cooperating with whisleblowers or defecting them? It seems to me to be a mere dilemma, two choices, both bad. There was no interplay of cooperate/defect strategies. reply ChrisArchitect 13 hours agoprevRelated: Boeing's Dead Whistleblower Spoke the Truth https://www.thefp.com/p/boeings-dead-whistleblower-spoke-the... (https://news.ycombinator.com/item?id=39838580) reply patrickhogan1 10 hours agoprevThis situation highlights why startups can outperform established companies. It's not only about innovation or asymmetric motivation but also due to the internal decay of incumbents like Boeing and General Electric. This presents an opportunity for an aeronautics startup to emerge - mission focused on building the best airplanes. reply ZoomerCretin 6 hours agoparentOf course, all you have to do is get several billion dollars in funding and hope Boeing doesn't use its vast resources to poach your engineers. Boeing is not going to be disrupted any more than TSMC or ASML will be disrupted. Planes are too complex and too expensive to manufacture correctly. reply patrickhogan1 4 hours agorootparentThe best engineers wont work for companies that don’t ship great product. Funding and complexity are obstacles, but there are many examples of overcoming the obstacles with innovation and conviction. Rockets - Lockheed -> SpaceX AI - Google -> OpenAI Electric Cars - Toyota -> Tesla Shipping - Maersk -> Flexport CPUs - Intel -> ARM reply slim 2 hours agorootparentFlexport has it's own ships ? reply YeBanKo 12 hours agoprev> “Prince Jim”—as some long-timers used to call him—repeatedly invoked a slur for longtime engineers and skilled machinists in the obligatory vanity “leadership” book he co-wrote. Those who cared too much about the integrity of the planes and not enough about the stock price were “phenomenally talented assholes,” Decline in attention to quality at Boeing is a known thing. But this attitude towards engineering and specially to machinist is just utterly f*king stupid. Especially to machinists, because experienced one are hard to find, not even talking about toolmakers. It seems that the starting salary for machinists isn't that great and many shops lost to outsource. And experienced folks retire leaving a wide gap behind. Of course, this does not excuse such an attitude toward engineers either. reply spking 13 hours agoprevhttps://archive.ph/Oub0v reply rybosworld 11 hours agoprevU.S. companies have a management problem. I specifically mean that the terminal career path for most professions is \"management\". Depending where you work, management can mean: - giving orders - delegating work (usually this is work the manager specifically doesn't want to do themselves) - clearing blockers in front of your employees That the third one is the rarest is a problem. American corporate culture has devolved into: get promoted into management and coast. There are obviously exceptions. But a lot of people will agree they've had their fair share of terrible managers. I dare say that's the norm. Boeing is just the most current example of what happens when a company fetishizes management. That is, there comes a time when the leeches have sucked the body dry. reply twojobsoneboss 6 hours agoparentHave you been in upper management? It is stressful and if things don’t go well it’s quite likely that you’ll get canned, vs an IC Grass is always greener reply bondolo 10 hours agoprevNot just planes and fairly recently too. I was working at a Boeing subsidiary when the 737 Max MCAS happened. They dumped everyone they could on loathsome “$9000 USB cable” type time and materials defense work. I was a senior Java architect and they quickly “retrained” me to do HIL component testing in plain old C. It might have been seen as a move to improve cash flow but realistically it had the effect causing almost all of the software staff to leave in short order which I guess also improved cash flow. The subsidiary is still struggling several years later to rebuild their software team. reply type_Ben_struct 13 hours agoprevIt baffles me how this happens time and time again in companies as they grow (albeit rarely with this level of human life consequence), and nobody ever seems to learn from it. reply 015UUZn8aEvW 13 hours agoparentPournelle's Iron Law of Bureaucracy. Every hour that a Boeing employee spends trying to design or build a good airplane is one less hour that he can spend angling for power within the organization. So the people who care the most about the original purpose of the organization will be systematically outcompeted by the people who care the most about obtaining power within the organization. A widespread and profound problem. When companies are small, the machinations of political types and their inadequate contributions to the core product are too obvious, and they get weeded out. But when the company grows large and successful (due to the efforts of the people who cared about the original mission), it has a brand and long-term customers. At that point, the political type",
    "originSummary": [
      "Boeing under CEO Jim McNerney fostered a toxic work environment, undervaluing experienced employees for cost-cutting measures, which impacted manufacturing standards and aircraft projects.",
      "The case of ex-Boeing employee \"Swampy,\" who raised safety concerns and encountered retaliation, sheds light on the ongoing criminal probes and calls for leadership reforms within the company.",
      "The article touches on Swampy's suspicious death, a whistleblower lawsuit, and the broader skepticism surrounding Boeing as a military contractor, prompting questions about potential foul play."
    ],
    "commentSummary": [
      "Boeing's decision to replace experienced engineers with younger staff to cut costs raises safety concerns regarding their planes.",
      "The discussion extends to tech industry trends, addressing ageism and lack of leadership diversity.",
      "The focus includes stock market valuations, corporate competition, housing, financialization's impact, and profit prioritization over quality and safety, as seen in the Boeing 737 Max crashes."
    ],
    "points": 728,
    "commentCount": 438,
    "retryCount": 0,
    "time": 1711654941
  },
  {
    "id": 39858144,
    "title": "The Redis Licensing Controversy and the Emergence of KeyDB and Valkey",
    "originLink": "https://lwn.net/SubscriberLink/966631/6bf2063136effa1e/",
    "originBody": "LWN .net News from the source Content Weekly Edition Archives Search Kernel Security Events calendar Unread comments LWN FAQ Write for us User: Password:| Subscribe / Log in / New account The race to replace Redis [LWN subscriber-only content] Welcome to LWN.net The following subscription-only content has been made available to you by an LWN subscriber. Thousands of subscribers depend on LWN for the best news from the Linux and free software communities. If you enjoy this article, please consider accepting the trial offer on the right. Thank you for visiting LWN.net! Free trial subscription Try LWN for free for 1 month: no payment or credit card required. Activate your trial subscription now and see why thousands of readers subscribe to LWN.net. By Joe Brockmeier March 28, 2024 On March 21, Redis Ltd. announced that the Redis \"in-memory data store\" project would now be released under non-free, source-available licenses, starting with Redis 7.4. The news is unwelcome, but not entirely unexpected. What is unusual with this situation is the number of Redis alternatives to choose from; there are at least four options to choose as a replacement for those who wish to stay with free software, including a pre-existing fork called KeyDB and the Linux Foundation's newly-announced Valkey project. The question now is which one(s) Linux distributions, users, and providers will choose to take its place. A short history of Redis Redis has a complicated backstory. Salvatore Sanfilippo (also known as \"antirez\") started the project to use as \"a different kind of database\" with a realtime log-analyzer application called LLOOGG, because MySQL was not meeting his needs. Instead of creating a relational database, he designed the project as a simple dictionary database that stored a key-value pair in memory—its name is a contraction of \"remote dictionary server\". It has, of course, matured and accrued many more features over the years. Redis quickly became popular as part of the NoSQL movement, and he was hired by VMware to work on Redis development in 2010. He moved to VMware's spin-off, Pivotal, in 2013 and continued to work on the project. Around that time, Redis was growing in popularity, with high-profile use by Twitter and Pinterest, among others, and started to appear in Linux distributions. It was packaged for Ubuntu in the 12.04 (April 2012) release, Fedora 18 (January 2013), and others. Support for Redis was added to Amazon Web Service's (AWS) ElastiCache service in September 2013, which took advantage of, and helped bolster, Redis's popularity. In early 2013, a startup called Garantia Data started offering Redis services and positioning itself as a better alternative to \"open source Redis\". Garantia took a first round of funding in November 2013 and floated changing its corporate name to RedisDB. After some pushback from Sanfilippo, the company renamed itself Redis Labs, instead, in early 2014. Sanfilippo joined Redis Labs as the lead for open-source development in 2015. He remained with Redis Labs until stepping down in 2020. In 2018, Redis Labs adopted a new license for its add-on modules that provide features on top of the core database. The company chose to use a modified version of the Apache License, Version 2.0, with an addition called the Commons Clause. This clause restricted selling the software or charging for services. The rationale given for the switch was that cloud providers were \"taking advantage of the open source community\" by selling services based on open-source code they didn't develop. At the time, the company pledged that Redis \"is BSD and will always remain BSD\". It was not the only company to start experimenting with use-restrictive licenses. Venture-backed database companies, in particular, were starting to run toward new licenses to try to ensure they could exclusively sell services using the software. MariaDB had created the Business Source License (BSL) for a product called MaxScale in 2016, and MongoDB launched the Server Side Public License (SSPL) in late 2018. Eventually, Redis Labs settled on a dual-license scheme of SSPL and its own Redis Source Available License (RSAL) for its modules. The company dropped \"Labs\" from its name in mid-2021. In announcing the name change, Redis again committed to open source, and said that the company renaming \"will not affect the licensing of open source Redis, which has always been and will continue to be BSD licensed\". The company also put in place a governance model that would place major decisions about Redis's \"architecture, design, or philosophy\" with a community \"core team\". One would expect that team's mandate to include the license for Redis itself. The governance page is no longer on Redis's web site, but is available on the Internet Archive's Wayback Machine. It listed a core team of five members, three from Redis (Yossi Gotlieb, Oran Agra, and Itamar Haber) as well as Zhao Zhao from Alibaba and Madelyn Olson from AWS. On March 20, Redis announced that \"all future versions of Redis will be released with source-available licenses\", specifically the SSPL and RSAL. Rowan Trollope, Redis CEO, wrote that maintaining the BSD license was now \"at odds with our ability to drive Redis successfully into the future\". Future versions, in this case, means Redis 7.4 and later. The announcement's FAQ says that, following the company's security policy, security patches will be backported to previous versions under the original three-clause BSD license. Cloud versus open source Proponents of use-restrictive licenses like the SSPL and Redis's RSAL have tried to position this solely as a battle between giant cloud providers like AWS and open source, where use restrictions are the only logical alternative and cloud providers are the only losers. In 2019, Redis Labs then-CEO Ofer Bengal was quoted as saying that there were \"many different views\" after Redis adopted its source-available licenses for Redis modules, but that it was necessary to compete with cloud providers: Some people condemned that [license change]. But after the initial noise calmed down — and especially after some other companies came out with a similar concept — the community now understands that the original concept of open source has to be fixed because it isn't suitable anymore to the modern era where cloud companies use their monopoly power to adopt any successful open source project without contributing anything to it. In the March 20 announcement, Trollope wrote that \"cloud service providers will be able to deliver Redis 7.4 only after agreeing to licensing terms with Redis, the maintainers of the Redis code\" but, that \"nothing changes for the Redis developer community who will continue to enjoy permissive licensing under the dual license\". The choice of the phrase \"permissive licensing\" is misleading. Redis is able to adopt a non-free license scheme for 7.4 and later versions because external developers had granted their contributions under the permissive BSD license. The terms of the SSPL and RSAL are incompatible with common usage of the term \"permissive\" in the open source community. It is also hard to reconcile the claims that cloud providers do not contribute with the actual commits to the Redis repository. A quick examination of the commits since the 7.0.0 release using gitdm shows 967 commits over that time period: Top changeset contributions by employer (Unknown) 331 34.2% Tencent 240 24.8% Redis 189 19.5% Alibaba 65 6.7% Huawei 50 5.2% Amazon.com 50 5.2% Bytedance 19 2.0% NetEase 13 1.3% BinBin Wang, of Tencent, is responsible for nearly 25% of the commits to the project. Some of the contributors without a readily identifiable employer surely are Redis employees, but it's clear that the company has not been working alone. (Note that some single-digit contributors were omitted.) Changing distribution model So it should be apparent that code contribution is beside the point. Redis is a venture-backed company that has taken more than $350 million in funding over many rounds since 2011. The company, and its investors, seem to have calculated that they can safely move away from open source to try to capture more revenue. They have some reason to believe this is the case, if MongoDB's results are any guide. The company went public in 2017 and moved to the SSPL a little more than a year later. Shortly afterward, major Linux distributions stopped packaging the database because it no longer met their licensing standards. But, by that time, the company had set its sights on a platform model that would encourage developers (and their employers) to use and pay for MongoDB and ancillary offerings with the as-a-service model. Distributing a source-available version of MongoDB could be seen as a loss-leader strategy to reach developers that the company wagered did not care about open-source. As Redmonk founder Stephen O'Grady wrote in 2017: As developers began to assert control over technical selection and direction in increasing numbers, even in situations where a proprietary alternative is technically superior, the sheer accessibility of open source software gave it an enormous market advantage. Choosing between adequate option A that could be downloaded instantly and theoretically superior option B gated by a salesperson was not in fact a choice. But open source, noted Grady, \"is typically less convenient than service-based alternatives\" and if convenience is the most important factor then open source has a problem. Especially when vendors like MongoDB have learned from proprietary vendors that \"locking in customers is good for business\". Is it good for business? MongoDB has kept growing, adding customers, and brought in $1.68 billion its last fiscal year. That's more than a 30% increase, and its Atlas database service revenue also increased more than 30%, demonstrating that a lot of companies would rather pay to use the service than try to host it themselves. Despite all that, the company is still losing money—more than $345 million in the same time period. But, investors may be more interested in stock price than actual profit. The company's stock started around $33 a share when it went public, but is now more than $350 a share. Redis's investors would likely be happy if it can produce similar results. Forks and alternatives Venture-backed vendors seem to have, as O'Grady wrote last year, reached a consensus that they can move away from open source. Especially if they are not \"actively opposed by other commercial interests, foundations and other interested industry participants\". Here, Redis may have miscalculated the industry mood. When Hashicorp adopted BSL for its projects last year, a fork of its Terraform project appeared within days and was embraced by the Linux Foundation under the name OpenTofu. On March 28, the foundation announced that it was supporting Valkey, a direct fork of Redis 7.2.4, with Amazon Web Services (AWS), Google Cloud, Oracle, Ericsson, and Snap named as backers of the effort. The Valkey fork got its life just a few days after the Redis license change. Olson wrote that she and \"various former Redis contributors\" had started working on a fork, using the original three-clause BSD license, with \"placeholderkv\" as a temporary name. Olson, Zhao, Viktor Söderqvist, and Ping Xie were listed as maintainers. According to Olson this was not an AWS fork of Redis, but \"just me trying to keep the continuity with the community\". KeyDB was considered, but it has diverged to the point that it \"is missing a lot of stuff the community is used to\". The KeyDB fork was created in 2019 for technical, rather than licensing, reasons. The project, which billed itself as \"a faster drop in alternative to Redis\" was created by John Sully and Ben Schermel, who wanted a multithreaded version and were not able to persuade Redis maintainers to go in that direction. Sully and Schermel started a company, also called KeyDB, that offered a proprietary enterprise version. The entire codebase became fully open source under the three-clause BSD license when KeyDB was acquired by Snap in 2022. The problem with KeyDB as a direct alternative is that it hasn't kept up with Redis since it forked. It still lacks many features found in Redis 7, and Sully indicated that there's little time for him to work on issues \"not directly affecting Snap\", though the project \"would of course welcome outside help and we can certainly name additional maintainers if there is community interest in helping\". On March 22, Sully updated another issue and said he was in discussions to \"potentially\" add maintainers to bring KeyDB closer to Redis 7. It's not clear yet whether Valkey will supplant KeyDB, but Snap's involvement makes that seem likely over the long term. Drew DeVault, founder and CEO of SourceHut, has also created a fork named Redict based on Redis 7.2.4, but chose to use the LGPLv3. In his announcement post, he said that the choice of license was \"a deliberate one which balances a number of concerns\". DeVault wanted a license that was copyleft but \"as easy as possible for users to comply\" with the license and to ease integrations with Redis-compatible modules or Lua plugins that can be used to perform operations within Redis. He also noted that Redict will have no contributor license agreement (CLA), but contributors would be asked to verify contributions with a developer certificate of origin. Despite his connection to SourceHut, DeVault chose to host Redict on Codeberg to \"provide a comfortable and familiar user experience for anyone comfortable with the GitHub-based community\" of Redis. Another kind-of contender is Microsoft's Garnet, announced on March 18. According to the announcement, it has been in development by Microsoft Research since 2021. It is a remote cache-store that can cache and manage the same types of data as Redis and is designed to be compatible with the Redis serialization protocol. Garnet is MIT-licensed, written in .NET C#, and is not meant to be a direct drop-in replacement. However, its API compatibility page claims that it can be \"regarded as a close-enough starting point\" that works \"unmodified with many Redis clients\". Many, but not all. For example, one user attempted to switch a NodeJS application to Garnet, but found that Redis's FLUSHALL command is not currently supported. Adding support for missing APIs on is on the project's roadmap. Scramble for alternatives Once again, Linux distributions are left with a mess to clean up. Neal Gompa opened a discussion on the Fedora development list, noting the license change and the need to remove Redis from Fedora. Jonathan Wright replied that KeyDB might be a replacement; he had been \"loosely working on packaging\" before the license change. He later said that KeyDB would be \"a step backwards and cause headaches\" for those looking to replace later versions of Redis. Nevertheless, he wrote on March 23 that he had pushed builds that were ready for testing for Fedora and EPEL 8 and 9. Shortly after the Valkey announcement, Wright wrote that he would be packaging it as soon as there is a tagged release. Wright also said that he is \"anticipating valkey becoming the [de facto] replacement for redis in most places.\" Gompa also raised the issue on openSUSE's Factory discussion list. Dominique Leuenberger replied with a list of 18 packages with dependencies on the redis package in Tumbleweed. The initial discussion mentioned Redict and KeyDB as possible replacements, but Valkey had not been announced yet. Having to find a replacement to ship in place of Redis is not the only problem for community distributions. Jacob Michalskie called out several services in use by the openSUSE project that will need a Redis replacement, including the Pagure code-hosting software (created and used by Fedora as well) used for code.opensuse.org, and the Discourse forum software. Debian contributor Guillem Jover filed a Request for Package (RFP) for KeyDB as a potential replacement for Redis. Jover said he was not sure if he was up for sole maintainership, but was happy to give a hand. In an email exchange with Jover, he told me that his company had migrated from Redis 6 to KeyDB and it was a \"smooth transition\". According to Jover, \"KeyDB might be lacking some features compared to Redis 7, but we have neither noticed we miss any or felt we were missing out on anything.\" Jover said that it was too early to tell whether the newer forks would continue to be maintained, and that Redict's LGPLv3 licensing \"might also be problematic for the ecosystem\". In a follow-up email after the Valkey announcement, he said \"I think we'll probably go further with packaging KeyDB for Debian at least, if it dies out it can always be removed or transitioned out from there.\" Path forward It is, of course, too soon to predict whether one or more of the forks will gain significant traction—but it seems likely that Valkey will be a credible alternative. The possibility of a swift fork with widespread community and industry backing should give pause to vendors who expect a smooth path after abandoning open source. Did you like this article? Please accept our trial subscription offer to be able to see more content like it and to participate in the discussion. (Log in to post comments) The race to replace Redis Posted Mar 28, 2024 22:58 UTC (Thu) by carlosrodfern (subscriber, #166486) [Link] Excellent article. Thank you for the analysis. The race to replace Redis Posted Mar 29, 2024 2:25 UTC (Fri) by immibis (subscriber, #105511) [Link] SSPL is a copyleft license based on broadening AGPL. The logic by which SSPL is considered nonfree also makes AGPL and GPL nonfree, which is actually insane. I think the OSI is completely in the wrong on this point. I note that the OSI is mostly a consortium of cloud service vendors. The race to replace Redis Posted Mar 29, 2024 3:12 UTC (Fri) by jhoblitt (subscriber, #77733) [Link] If the SSPL and the AGPL are equivalent (hint: they aren't), then only one of them needs to exist. There is a line in terms of impingements upon freedoms every open source developers is willing to tolerate. For many, AGPL is close to that line and the SSPL is on the wrong side of it. There are of course also concerns that SSPL requires legal authorities outside of copyright law. The race to replace Redis Posted Mar 29, 2024 3:32 UTC (Fri) by willy (subscriber, #9762) [Link] The FSF, Debian and Red Hat have all concluded that the SSPL doesn't meet their definitions of Free Software. Harder to make those groups out as shills for Big Cloud. The race to replace Redis Posted Mar 29, 2024 5:54 UTC (Fri) by immibis (subscriber, #105511) [Link] The last I saw was that the FSF hadn't made a determination and the others were just following the OSI determination. The race to replace Redis Posted Mar 29, 2024 7:06 UTC (Fri) by pbonzini (subscriber, #60935) [Link] The difference is that the SSPL breaks the \"License Must Not Restrict Other Software\" clause of the open source definition. In contrast the GPL and LGPL have an explicit text saying that they don't extend to other software even if distributed on the same medium, if that constitutes \"mere aggregation\"). (In addition it's debatable whether it's possible at all to distribute all the required components under the SSPL, which would constitute a restriction on making use of the program in a specific field of endeavor; but that's not necessary given the previous point). The race to replace Redis Posted Mar 29, 2024 8:50 UTC (Fri) by fw (subscriber, #26023) [Link] The AGPL does not create any additional obligations over the GPL if one does not modify the software. The SSPL obligations apply even if one runs unmodified versions, as distributed by upstream. Certainly this is a major difference. s/BSL/BuSL/g Posted Mar 29, 2024 6:22 UTC (Fri) by mirabilos (subscriber, #84359) [Link] BSL is Boost’s (and not a nōn-free licence), the newcomer does not get to occupy the same name, which is also listed in SPDX. s/BSL/BuSL/g Posted Mar 29, 2024 9:46 UTC (Fri) by aragilar (subscriber, #122569) [Link] The relevant SPDX pages for reference: https://spdx.org/licenses/BUSL-1.1.html and https://spdx.org/licenses/BSL-1.0.html Copyright © 2024, Eklektix, Inc. Comments and public postings are copyrighted by their creators. Linux is a registered trademark of Linus Torvalds",
    "commentLink": "https://news.ycombinator.com/item?id=39858144",
    "commentBody": "The race to replace Redis (lwn.net)466 points by chmaynard 11 hours agohidepastfavorite296 comments brody_hamer 7 hours agoIt wasn’t clear to me until I read their blog, that redis will remain free to use in their “community edition”, which will continue to be supported and maintained (and improved!) So we as developers don’t have to scramble to replace redis in our SAAS apps and web based software. This is more about preventing AWS from eating their lunch by providing redis-as-a-service, without paying any sort of compensation to the redis developers. Redis’ blog post: https://redis.com/blog/redis-adopts-dual-source-available-li... reply dkuntz2 7 hours agoparentWell, except for the fact that \"redis\" the organization didn't create redis and isn't even the main developer of redis. The origin of Redis the company is literally as a hosting provider for the open source redis that they didn't create. reply simonebrunozzi 3 hours agorootparentI believe that Redis has an agreement of sorts with Salvatore Sanfilippo / Antirez, the creator of Redis. reply radicalbyte 1 hour agorootparentAmazon / Google / Microsoft made a massive mistake by not hiring Antirez, it's chump change for them to throw him $1-2M a year at him so he can work on Redis for them full time. reply evanharwin 1 hour agorootparentThis makes me think - is it actually bad for Amazon/Google/Microsoft, that they now have to pay a licensing fee to Redis? I feel like there’s an argument that these kind of licensing terms are almost beneficial to ‘big cloud’ because the cost/effort of all of these arrangements might dissuade smaller companies from trying to compete in the hosting and managed-services business. reply jbverschoor 1 hour agorootparentprevSame with many open source creators. Plus some great projects don’t even get (monetary) contributions from large corporations. I think because it could weaken their legal position. reply BartjeD 48 minutes agorootparentprevMicrosoft has its own redis alternative: https://github.com/microsoft/garnet reply mariusor 1 hour agorootparentprevHas anyone asked Filippo if he still wants to work on Redis \"for them\" though? The fact that he stepped down suggests he doesn't. reply radicalbyte 1 hour agorootparentHe sold the trademark to some random company. Amazon / Google / Microsoft could have thrown him $30M for that and put Redis in an OSS Foundation. Again, it's chump change, these companies drop that kinda money all the time in aquihires.. reply alex_duf 28 minutes agorootparentprevI mean I love redis, but Amazon Google and Microsoft all probably have readily available in memory key/value stores at hand. Throw a little money and they can make it redis compatible, so we wouldn't have to re-write any code. Redis is great as an off-the shelf component, but it's not exactly rocket science to re-implement for a big corporation. So redis doesn't really have any leverage in my opinion. reply objektif 6 hours agorootparentprevThis is what I am confused about so what right do they have to enforce AWS from selling Redis when they do not own it? reply tapoxi 5 hours agorootparentTrademark, and it's licensed under BSD. Basically Redis Inc is the one making the fork, which retains the Redis name since they purchased it from antirez. reply nebulous1 6 hours agorootparentprevFrom what I understand they acquired the rights to redis from antirez sometime after employing him. I assume he received money for this. reply mythz 6 hours agorootparentprevThe licensing change only applies to their future versions which they own all contributions of which AWS won't be allowed to leech off anymore. reply happymellon 2 hours agorootparent> AWS won't be allowed to leech off anymore. Doesn't AWS employ Madelyn Olson? I mean, AWS have paid for Redis development. Not exactly a leech. reply lukaszwojtow 1 hour agorootparentYes, they paid. And they can use the code they paid for. But it doesn't give them right to leech of any future code written by someone else IN THE FUTURE. reply chii 1 hour agorootparentCalling it leech isn't right, because what makes aws any different from another user? Just because they're selling the hosting, doesnt make it any different to a regular user. Code contributions from amazon would've been leeched by other parties using redis as well - something which amazon is accepting (and probably encouraging). reply happymellon 1 hour agorootparentprevAnd considering Redis Inc hasn't contributed the majority of the code, they won't be able to leech off other people's code because why on earth would anyone contribute to this trainwreck! It's lose/lose! reply jamespo 51 minutes agorootparentNot for redis the company if they follow mongodb’s trajectory reply mythz 1 hour agorootparentprevYep still the biggest leachers. Token hires and flowery PR campaigns doesn't entitle them to most of the profits of other vendors products or absolve them of their predatory behavior. But they wont be able to leech Redis's future contributions. Knowing AWS they'll most likely create a fork to continue raking in most of the profits in the short-term. reply happymellon 1 hour agorootparentErr, after this license change Redis Inc will be the biggest leechers considering they didn't contribute the majority of the code. > Yep still the biggest leachers Redis was literally licensed for people to do whatever they want. That's not leeching. reply mythz 1 hour agorootparentRedis Labs was a long time sponsor for the full-time development of Redis then later compensated the creator of Redis for their rights to Redis Technology and branding who was ended up retiring from technology to write Sci-Fi books. By contrast AWS takes most of the profits whilst contributing relatively nothing back, making them the biggest leacher and the primary motivation for the relicensing to prevent mega corps with unfettered access to their future contributions that AWS repackages to compete against them. So whilst their previous license allowed AWS to leech off them, it's now been relicensed to prevent them from profiting off their future investments without compensating anything back. reply nindalf 56 minutes agorootparentprevAWS, along with Google and others have created a fork already. It’s very rude of you to call someone a token hire when they’re high up in the contributors list (#7 all time). Denigrating their work for no reason other than to “win” an internet argument. We’ll see what happens though. If redis Inc (that never created redis) wins over AWS, GCP and others (who also never created redis). Both contributed to its maintenance, as GitHub clearly shows. We’ll see which fork wins out. reply mythz 40 minutes agorootparent> It’s very rude of you to call someone a token hire when they’re high up in the contributors list (#7 all time). I've called AWS's hiring of a single developer a token hire that they then go on to write flowery PR posts about to camouflage their predatory relationship with OSS vendors. For concrete numbers they contributed 165/12111 commits for a total of a 1.36% of the commits. Whilst that qualifies as a valuable contribution to any project, it's also dwarfed by the 350M investment in Redis Labs and doesn't absolve AWS from being a called a \"leacher\" by helping themselves to the majority of the profits whilst contributing relatively nothing back. reply nindalf 25 minutes agorootparent> dwarfed by the 350M investment in Redis Labs It’s funny that you would use commits to quantify investment from AWS, but you’d use $ to buy shares in future profits to quantify investment from redis labs. Why not use the same yardstick for both? Either way, it doesn’t matter. Not one bit. Everyone who put in effort into redis did it knowing the license. There’s nothing wrong in relicensing future commits. There’s nothing wrong with forking. There’s nothing wrong in using whichever fork works better for you. You’re insisting up and down that AWS and others were leeching because they didn’t own the copyright to redis. I’ve never heard this interpretation of OSS before, but sure maybe you’re right. But we’ll see which fork comes out on top a year from now. reply vasco 4 hours agorootparentprevAWS leeches as much as Garantia Data no? reply mythz 3 hours agorootparentAWS are the largest leeches of OSS, syphoning off most the profits and contribute relatively nothing back towards the OSS projects they rent seek from. The \"Free for all except mega cloud corps\" license changes are to disrupt this status quo which currently sees the mega cloud corps with impenetrable moats from capturing most of the value of OSS products others spend their resources into building, AWS are then able to use their war chest profits to out resource, and out compete them, using their own code-bases against them. It's unfortunate organizations need to resort to relicensing stop this predatory behavior, but its clear in AWSs 20+ year history they're not going to change their behavior on their own. reply ricardobeat 4 minutes agorootparentExcept Redis was never meant to be “owned” by this company. They are both predatory. mirekrusin 4 hours agorootparentprevIf you own copyrights you’re not the leech. reply Thorrez 3 hours agorootparentWho owns the copyrights? According to the article, since 7.0.0, 24.8% of commits are from Tencent, 19.5% from Redis, 6.7% from Alibaba, 5.2% from Huawei, 5.2% from Amazon. reply firstSpeaker 1 hour agorootparentI wonder if there is a qualitative analysis of the commits. Aka, it changed a line of comment vs it introduced a new feature or refactored and increased long term viability, etc. reply vasco 3 hours agorootparentprevIf you own the copyrights you had money to spend at some point. Other than that unless you are one of the contributors you are leeching, just different flavors of leeching. reply exe34 2 hours agorootparentIs buying the same as leaching now? Words really do get diluted to the point of meaningless... reply vasco 1 hour agorootparentHow does buying a copyright to a name, literally just being able to call it \"Redis\" equate to purchasing the code contributions that individual contributors make? They bought the rights to the name, not the project, the project was open-source until the license change and belongs to society as a whole. reply exe34 1 hour agorootparentThe project still belongs to society as a whole! You can fork it too! You just can't profit off their future work. reply vasco 33 minutes agorootparentI agree, I didn't make any argument against that, I just don't see the difference between whatis different from . My only argument here is that there's not much difference between AWS and Garantia Data from my limited understanding of the situation. reply gkbrk 1 hour agorootparentprevIt is if the thing they bought had contributions from many other people but pretty much all of them got nothing for it. reply mattmanser 1 hour agorootparentprevOften, as that's what rentiers are. Generally bad for society. And have captured many regulatory processes and got tons of tax breaks for producing nothing. One of the well known flaws of capitalism, in the 'bad, but everything else is worse' sense. reply x3n0ph3n3 4 hours agorootparentprevNot only that, AWS has been offering redis-as-a-service longer than the \"Redis\" organization has been. reply hsbauauvhabzb 3 hours agorootparentBut if the shoe were on the other foot, AWS wouldn’t hesitate to rip the carpet from under anyone. reply chii 1 hour agorootparentIt doesnt matter if they would've or not. Presumed innocent until proven guilty (via action). Using this as an argument doesn't work to justify redis inc's actions. reply coredog64 5 hours agoparentprev> without paying any sort of compensation to the redis developers. AWS employee Madelyn Olson was a committer on Redis since 2019. Since 2020, she was on the core team of maintainers. reply andrelaszlo 2 hours agorootparentHere's what she wrote about the above article: > If you're looking for a primer on what is going on with Redis and why its license change matters, this is the article to read. As someone close to the situation, this is the best summary I've seen. reply a2800276 1 hour agorootparentWhere? reply andrelaszlo 1 hour agorootparentLinkedIn reply ensignavenger 4 hours agoparentprevAWS was directly funding Redis development, from the article, they are one of the top contributors, they even employed one of the core redis maintainers full time to work on Redis. reply esquire_900 4 hours agorootparentWhich is peanuts compared to the 350 million that the VCs invested. You're totally right, but I think the internal financial pressure is higher. reply gklitz 2 hours agorootparentAh, so it’s not about open source and moral responsibilities. It’s about the responsibility we all owe to VCs to ensure they make money. Gotcha. reply Tabular-Iceberg 2 hours agorootparentIsn’t that the deal we sign up for when we take VC money? I like free money as much as the next guy, but VC isn’t it. reply Macha 43 minutes agorootparentWho's we though? The former Garantia data did, but redis users didn't. (And also I'd argue most of redis' value to users was already in place before the VC backed company got involved) reply crasshit 5 hours agoparentprev> without paying any sort of compensation to the redis developers. Redis organization doesn't pay any sort of compensation to developers who contribute to redis source code. I do not see any difference here. reply ajmurmann 4 hours agorootparentDoesn't Redis Labs employ paid contributors? Does Amazon donate their contributions back to the community? reply x3n0ph3n3 4 hours agorootparentAccording to the linked article, Amazon has contributed 5% of the contributions to Redis, while Redis, the company, has contributed 20%. reply cloudboogie 1 hour agorootparentRight, now count in contributions from other cloud providers: tensent, huawei, alibaba and you'll find out that they contributed much more, than actual redis-employed developers reply jpc0 2 hours agorootparentprevI'm not for or against in this case. I'm anti what Redis the company is doing but I don't give a crap otherwise. Are we really counting contribution based on LoC? Haven't we over the decades decided that isn't valid? Guess every person that makes this claim should once again have their performance based on LoC... Some simple examples, I'm not saying this is the case though. What if most of Amazon's contributions are high impact contributions where most of Redis orgs are simply maintenance or feature pushes. What if the same is true for a 1% contributor? By your own statement doesn't Tencent then have a larger claim to redis that Amazon or Redis does? reply sverhagen 1 hour agorootparent> Are we really counting contribution based on LoC? I think they didn't include the LoC in the article as anything other than a broad estimate of contributions, perhaps for lack of any better measurements. reply ufocia 4 hours agoparentprev> This is more about preventing AWS from eating their lunch by providing redis-as-a-service, without paying any sort of compensation to the redis developers. But the developers licensed the software at no charge. What kind of compensation are they entitled to then? Sounds like a case of sellers remorse/take-backsies one of the problems that open source was aiming to solve. reply bramblerose 3 hours agorootparentThey are not entitled to compensation over their previous work, but you/me/AWS are also not entitled to their _future_ work. reply mahkeiro 1 hour agorootparentBut when you see that currently Redis is mainly developed by Chinese companies or AWS all of this is rather ironic. reply jamespo 46 minutes agorootparent5% of contributions is not “mainly” from AWS reply mort96 21 minutes agoparentprevWhether it's gratis or not isn't the issue. Some people used Redis not only because it's free of cost, but also because it's open source. It's not anymore. reply kyriakos 18 minutes agoparentprevIsn't this the same with Elastic? Or that was a different situation? reply VWWHFSfQ 6 hours agoparentprevI continue to have mixed feelings about this kind of thing. A (very) long time ago the Apache developers could have gone down this route. > You can only run Apache under very specific circumstances! Or memcached: > You are only allowed to run a memcached server if you're only caching your own website! We see how nonsensical this is reply wmf 5 hours agorootparentMore like you can run Apache except in specific circumstances. People will put up with a lot if there's no alternative. reply stephenr 45 minutes agoparentprev> that redis will remain free to use in their “community edition”, I mean, they've already changed licensing for parts of the project twice in 6 years. I have zero faith that they pull a Vader and change the terms of the agreement again. > continue to be supported and maintained (and improved!) I'd guess that > 99% of any \"improvements\" Redis the company make, will affectpreventing AWS from eating their lunch by providing redis-as-a-service, without paying any sort of compensation to the redis developers Look I hate AWS more than most people would find reasonable, and even I'll admit they're not the \"bad guys\" in this scenario. The project was released as BSD licensed, so AWS could if they wanted, fork it, and offer a service based on that, and make any fixes/improvements just in their service offering. They didn't. They had paid staff contributing back to the redis project, for a number of years. This was literally the goldilocks project of the OSS world: Numerous massive tech companies who all have the financial ability to simply run their own fork, and the legal right to do so (due to BSD-3), willingly contributing to the maintenance of the project. As I've said before, the story of what's happened to Redis (and HashiCorp stuff) is likely to become a warning to the tech community in general: if an OSS project you rely on transfers control from it's founder(s) to a company, you probably need to consider continuing with a fork from the last open version, because apparently \"(try to) monetise popular open source\" is the newest way to win the douchebag villain award given to MBAs at VC funded companies. reply lukaszwojtow 1 hour agoprevAll this outcry about license switch coming from \"community\" feels funny. After all, if there is the \"community\" then they can take the last open-source version and keep developing it themselves, right? But most \"communities\" are about \"take, take, take\", not \"work, work, work\". They often upset only because someone declared they aren't going to work for free any more. reply pjmlp 1 hour agoparentYeah, it is incredible how the whole free software movement turned into a bunch of entitled folks that want to be paid for their work, while refusing to put down any penny for the folks that make their tooling possible in first place. At the same time big corps use it as carte blanche to basically pirate software in a legal way, while following the letter of the licence. Going back to the open core/demo versions (aka Shareware/Public Domain/Trials) is the only sustainable way to make a living. reply chii 54 minutes agorootparent> Going back to the open core/demo versions aka, just sell software, rather than make it open source. What is being balked at is the idea that you can use open-source as a foot-in-the-door marketing and growth hack, which you then reap after some level of popularity/network effect is reached. Some call it bait and switch. Blaming big corps for \"leeching\" is just self-serving. They are doing exactly what the license allows them to do - a license for which was chosen at the start to allow for it! If you expected to be paid to make this software, don't opensource it. reply AnonymousPlanet 1 hour agoparentprevIn this case the community is the biggest contributor to Redis. The ones that \"take, take, take\" is Redis the company. Your comment seems way out of place in this light. reply lukaszwojtow 1 hour agorootparentGood. So now Redis Inc is in trouble because they have to replace community work with their own. If community does most of the work, then what's the problem? reply oefrha 31 minutes agorootparentThe problem is too many people are announcing OSS forks so it’s hard to align development efforts and users are confused. No one’s begging Redis Labs (which didn’t create Redis in the first place and only took over the brand with VC money when it was already popular) or whatever they’re called now to keep the bug fixes rolling. They only account for 20-50% of recent development anyway (50% if you attribute all “unknown” contributors to them), with the other 50% from (predominantly Chinese) cloud companies allegedly “pirating” their software, according to some. I don’t typically ask people to RTFA because that’s against the rules, but you would have known all of the above if you bothered to read the article. reply endisneigh 27 minutes agorootparentWhat you’re describing isn’t a problem. Why does it matter if there are too many forks? Development also doesn’t need to be aligned to begin with. It’s like complaining that there are too many implementations of GitHub of the same thing. reply lazyasciiart 1 hour agoparentprevThat doesn't seem like a very reasonable takeaway from an article which describes almost too many people announcing that they will take the last open-source version and keep developing it themselves for everyone else to use. reply palata 1 hour agoparentprevIf you only take, obviously there is no reason to complain. Now the problem is rather when contributors (those who \"give\", not those who \"take\") have to sign a CLA. Then the company who gets their copyright takes their work for free, to later use it in a non open-source project (assuming they changed the license, like Redis did). I think it is valid to find this immoral. The solution is pretty simple though: do not contribute to open source projects that require you to sign a CLA. reply lukaszwojtow 37 minutes agorootparentUsing the code later in a non open-source project can happen also with MIT/Apache licensed code. Even without CLA. Does it mean that company that does it is immoral? reply endisneigh 42 minutes agorootparentprevNo? They create a fork that maintains the existing terms. No cla required. reply xandrius 1 hour agoparentprevYep, that's exactly it. Of course it makes sense: making requires several orders of magnitude more effort than using. But if a project changes/goes down, the community often just moves elsewhere, nothing major lost from their perspective. And I think Open Source is based on the very few who decide to take it upon themselves to be the ones spearheading a specific project/task and share it with everyone else. Maybe it's not every single time me, sometimes it's you, sometimes it's Lucy or Mark, and that's how the roll keeps rolling for everyone. So if a project goes down and nobody comes up to replace it, either it wasn't worth much or this is the time nobody took it upon themselves to do it (yet). reply jychang 1 hour agoparentprevThat's a dumb take. That completely ignores opportunity cost of such actions. You can't just spin up a fork like that; there's barriers to entry, network effects, etc which prevent that from being a simple solution. reply endisneigh 42 minutes agorootparentYou really can just spin up a fork reply CyanLite2 2 hours agoprevMicrosoft's Garnet has the best chance of replacing Redis, the OSS project and the hosting company. Article doesn't mention it, but supposedly Microsoft uses novel algorithms and multi threading to achieve an order of magnitude improvement in throughput. Now if they can commercialize it with Azure, it should be a credible alternative to Redis Enterprise hosting. reply rmbyrro 1 hour agoparentArticle does mention it reply ddorian43 1 hour agoparentprevProbably not, because it's new and incompatible with many Redis use cases (lua scripts, etc). reply alternatex 34 minutes agorootparentMost Redis users don't really do scripting though. If Microsoft manages to replace Redis for most use cases they will succeed. reply bcye 1 hour agoparentprevLet's replace a project that failed because of a CLA with another project that requires a CLA reply BartjeD 46 minutes agorootparentGarnet is MIT licensed. See: https://github.com/microsoft/garnet reply bcye 43 minutes agorootparentAnd requires a CLA, see the same link reply dindresto 39 minutes agorootparentI think the point BartjeD wants to make is that due to the nature of MIT licensing, they could run away with your contributions anyway, even without a CLA. Furthermore, Redis didn't have a CLA if I remember correctly and the relicensing is solely based on the what the previously used BSD license allows. reply bcye 21 minutes agorootparentInteresting, I thought the point of not wanting CLAs was not giving them the ability to relicense your code under a more restrictive license (i.e. SSPL), not to keep them from running away with it. reply west0n 7 hours agoprevNeal Gompa opened a discussion on the Fedora development list, noting the license change and the need to remove Redis from Fedora. Gompa also raised the issue on openSUSE's Factory discussion list. After Docker was phased out, various distributions have adopted the compatible Podman as a replacement for Docker. It seems that a similar story is unfolding with Redis. reply cpach 2 hours agoparentNB: Docker Engine is open source. (Docker Desktop is not.) reply fweimer 1 hour agorootparentMoby is open source. The licensing situation for Docker Engine is unclear. reply jacooper 7 hours agoparentprevDocker was only phased out in red hat distros because they don't like it and want to push Podman. Others still have docker packaged in their repos. reply dralley 5 hours agorootparentA bit reductionist. IIRC the main reason Docker was phased out because Red Hat wanted to push rootless, daemonless containers, which required CGroups v2, which Docker didn't want to support for the longest time. Since both versions of CGroups can't be enabled simultaneously, and no distro wanted to go without Docker (or at least Docker-like) functionality, CGroups v2 was left in permanent stasis, and so Red Hat started Podman to break the deadlock. There were a laundry list of other technical disagreements (mostly around security) but that was the primary one. And then once Red Hat distros switched over to CGroups v2, which Podman enabled them to do, it meant that Docker wouldn't really work all that well anymore until they eventually switched to CGroups v2 also (which they eventually did a few years later). So that's why it got removed from the repos, at least originally. reply jillesvangurp 3 hours agorootparentprevdocker-cli is still open source (Apache 2.0) and being distributed in most flavors of Linux. Docker the company does not own all the source code. But like redis they are free to build their own non open source products around this code base. reply tick_tock_tick 5 hours agorootparentprevIt's not in Debian and their wiki straight up directs you to podman with a nice big scary warning about dockers root issue. https://wiki.debian.org/Docker Docker is dyeing on linux podman will be the only one that remains. reply noirscape 1 hour agorootparentNo? Sorry if that's a bit cynical, but Docker is only dying in the opinion of distro maintainers. By this metric, it's been dying for the past 8 years, but everyone is still talking about Docker, not podman. A related problem I've seen from other complaints made elsewhere is that podman does things just slightly different enough than Docker that it's not a true drop-in replacement. We've seen that before; where distro maintainers declared software too dangerous/prematurely dead for a while. All it resulted in was community hosted repositories for the old software. (Read: this is why avconv failed.) reply Kwpolska 1 hour agorootparentprevThe page suggests podman in a small info box (one that people might skip, because it feels like the Wikipedian \"this article has issues\" box), but it also tells you how to install real Docker. Docker has name brand recognition, and even if it wasn't in Debian's official repos, it would be installed from Docker's own repos. This wiki isn't popular enough for this to matter anyway, people are likely googling for \"docker debian\" and are finding instructions for real Docker. I don't feel like Docker is dying. And besides, that issue with root feels overblown in the era of single-user systems and servers as cattle. reply aragilar 5 hours agorootparentprevIt's in Debian: https://packages.debian.org/sid/docker.io reply francislavoie 4 hours agorootparentThat version is so old. I just use Docker's own apt repo to not fall behind. reply tick_tock_tick 5 hours agorootparentprevhuh well I'll be damn I thought this had already been resolved back to the mailing list it seems. reply tison 10 hours agoprevFor the first time, I know our (Apache Kvrocks, an alternative to Redis on Flash) committer Binbin Wang committed nearly 25% of the commits to the newer Redis version. You can find his contributor for both at: * https://github.com/apache/kvrocks/graphs/contributors * https://github.com/redis/redis/graphs/contributors reply tison 9 hours agoparentAnd here is an interesting conversation when Binbin came to the Kvrocks community: https://github.com/apache/kvrocks/pull/1581#issuecomment-163... * Me: @enjoy-binbin Out of curiosity, do you have a fuzzer to test out Kvrocks? Your recent great fixes seem like a combo rather than random findings :D * Binbin: They were actually random findings.I may be sensitive to this, doing code review and found them (also based on my familiarity with redis) reply masklinn 3 hours agorootparentYeah some folks are built different. I’ve a colleague who once every few weeks opens random files and notices weird patterns, I’ve no idea how his mind works but boy does it work. reply kqr 3 hours agoprevI liked Andrew Kelleys perspective on this: let's treat Redict as a rename of the Redis project, and the project now called \"Redis\" a weird commercial fork of Redict. https://andrewkelley.me/post/redis-renamed-to-redict.html reply Kwpolska 1 hour agoparentThis article lists the other contenders for the title of new Redis, and I think Redict is going to be the least successful thanks to its founder, niche hosting site, and the hostile AGPL licence. reply c0l0 1 hour agorootparentIt's not AGPL, but LGPL-3.0-only. Neither of these licenses is \"hostile\". And ftr, in my eyes, a project being created/initiated by ddevault is an asset, certainly not a liability. reply rmbyrro 1 hour agorootparentYou are correct. The issue is that any [X]GPL license has bad reputation in business environments. They see it as a big legal risk that will require constant legal supervision over the technical usage of GPL-licensed code. reply palata 1 hour agorootparentAnd they should learn. LGPL is really not that hard to use. If more open source projects adopted it, then business environments would have to adapt. reply c0l0 45 minutes agorootparentprev¯\\_(\")_/¯ I pity the fool(s). reply nerdponx 7 hours agoprevIsn't this the reason why AGPL has started to get more popular? Everyone has to play by the very strict rules except the copyright holder, who can do whatever they want, but the community still benefits from the core software being open source. The BSD license in particular seems like a particularly bad way to run a business. reply tsimionescu 5 hours agoparentThe whole move to new \"open-core\" licenses started with the most famous (infamous?) AGPL project - MongoDB. The AGPL is not what companies like this want (Mongo, Elastic, Redis etc). They don't want AWS's code: AWS is already providing that. They want AWS to pay them royalties or stop competing. reply thayne 3 hours agorootparent> They want AWS to pay them royalties or stop competing. But the switch from AGPL to SSPL didn't do either of those things. AWS still built DocumentDB to compete with Mongodb, and didn't use any SSPL OR AGPL code in the implementation (at least according to their FAQ[1]). And AFAIK AWS isn't paying mongo any royalties. [1]: https://aws.amazon.com/documentdb/faqs/ reply dragonwriter 2 hours agorootparent> But the switch from AGPL to SSPL didn’t do either of those things. Well, yeah, its mostly a bad plan, because while it can block competition with your code, it doesn’t block substitution with other code that provides the same function, and if you aren’t one of the big cloud providers, competing in the same function market with bundled services from the big cloud providers, whether or not it is the same underlying code, is the actual problem you face when your monetization is based around “sell a hosted service”. reply tsimionescu 3 hours agorootparentprevWell, I was using AWS more as a catch-all term for cloud. They never actually offered a managed MongoDB service, but other like IBM and Oracle did (or still do?). I'm not sure what impact this had exactly, whether those services were discontinued or if they are now paying Mongo for them - but surely they had a significant impact one way or the other. reply chii 1 hour agorootparentprev> They want AWS to pay them royalties or stop competing. but at the same time, they want people to be able to use the software for free (esp. at the start), to kick-start the network effect. In other words, open-core business models want to have their cake and eat it. If you are able to make lots of money off said software, we want a piece of it after the fact. But we dont want to take on the risk of actually looking to build a business and compete on the same. reply rmbyrro 1 hour agorootparentprevThey dont't want AWS royalties. They wanna be able to command higher margins. Since AWS has lower costs and prices, Redis can't compete with good margins. The royalties are just a way to increase AWS costs, so that they raise their prices and give Redis the ability to keep high prices and margins, while still remaining attractive to customers (which don't have a cheaper choice anymore). reply konschubert 1 hour agorootparentThey want to make money with the software they built. reply jeltz 26 minutes agorootparentNo,they want to make money with software they did not build. The Redis company did not build Redis nor are they the biggest contributor. reply throwaway5959 3 hours agorootparentprevThen they shouldn’t have open sourced it in the first place. reply leoedin 1 hour agorootparentYeah, it feels like this pattern of “ship an open source product, get popular, try to backtrack” ignores the fact that the only reason you got popular in the first place was the open source aspect. Would anyone have given mongo a look if it was a fully proprietary technology? They would have gone bust years ago. reply verdverm 6 hours agoparentprevI see more of a shift to open core. Many large orgs just say no to viral licenses, and in choosing AGPL, you put blockers to adoption. Open core releases some of the project under permissive license, and keeps some private or under a permissions license. We are all still trying to figure out how we can have sustainable open source where people can be paid to work on it full time reply sakjur 1 hour agorootparentIf you’re happy with paying a few maintainers, a support staff, and some salespeople the cash flow necessary for being a successful endeavor is a whole lot different than if you’ve raised $350 million. Maybe the problem lies more with overreaching and trying to cash out? reply verdverm 1 hour agorootparentFor sure, there is a problem in startup culture that looks down upon lifestyle companies. Devtools and developer focused products often get caught up in this. At the same time, founders take money to build their idea into something more than they could do with a small team. An big companies are risk averse, having a small staff or being susceptible to \"hit by a bus\" failure is often a deal breaker reply wmf 5 hours agorootparentprevThe shift to open core was ten years ago. Open core failed and is being replaced with pseudo open source. reply verdverm 5 hours agorootparentOpen core only became a word people said 10 years ago, it's on the rise as a business model from what I can tell. Do you have suggestions for alternative funding/support models? What is open core being replaced by from your perspective? reply wmf 5 hours agorootparentOpen core is being replaced by \"selling exceptions\" to AGPL/SSPL/BUSL/FSL. See MongoDB, Elastic, Hashicorp, Redis, etc. Personally I prefer the Adam Jacob trademark business model but it's not that proven and it can't be retrofitted. reply verdverm 4 hours agorootparentOP, OpenSearch, OpenTofu all seem to indicate the jury is still out on this one. I still see many smaller projects using open core. Three I started using recently ( llama-index, langfuse, qdrant ) are in this category. There is certainly a difference between AGPL and BUSL style licenses. One of the new projects I'm using as some of their code with a BUSL style, but still open core primarily reply pininja 4 hours agorootparentprevhttps://medium.com/@adamhjk/introducing-the-community-compac... for folks wondering what Adam’s buisness model is about reply lukaszwojtow 2 hours agorootparentprevIf AGPL blocks adoption then \"large orgs\" can buy commercial license (assuming software is dual-licensed). reply verdverm 1 hour agorootparentThey can, but the issue is how much effort does that require for a random dev in the org to go through to try out a project? It's not a technical blocker, it's a psychological blocker reply lukaszwojtow 1 hour agorootparentI get it. If there are alternatives that overall would be better (including their technical merits and how easy it is to introduce them to a commercial company) then use them. No one is forced to buy dual-license. reply orthoxerox 2 hours agoparentprevsome kind of GPL + no CLA = good. If you contribute to GPL Redis, the Redis company cannot relicense your work, because they own it as much as you do. GPL + CLA = bad. If you contribute to GPL Redis and transfer the copyright to your contributions to the Redis company, they can switch to whatever license they want. SSPL + no CLA = interesting, I would love to see the Redis company open source their hosting stack because they are accepting external contributions. reply IshKebab 2 hours agorootparentIt's too simplistic to call these \"good\" or \"bad\". reply jhoechtl 6 hours agoparentprevAbsolutely! And the haters of that license either do not understand it or have their user-hostile intentions. Or plan to make money with other people's love and free-time. reply somat 20 minutes agoprevIt reminds me of the berkely db situation, where they(sleepycat software at the time, but now I think it is owned by oracle) changed the license to try and sell it, and everyone just kept using the last bsd licensed version. reply gymbeaux 6 hours agoprevAWS also forked ElasticSearch into their “OpenSearch” DBaaS. It caused some issues at my last job because OpenSearch limited us to a particular version of the NEST .NET library that was missing some newer functionality. Real bummer and feels like a step in the wrong direction given all we’ve accomplished in tech over the last 20 years. reply BoorishBears 6 hours agoparentOpenSearch infuriates me to no end. It lacks so many improvements and advancements since the ancient version it was forked at, but because AWS already has an org's payments details, teams often refuse to look at Elasticsearch. Even basic things like autocompleting queries have been WIP for half a decade now: https://github.com/opendistro-for-elasticsearch/sample-code/... https://github.com/opensearch-project/OpenSearch-Dashboards/... The superiority AWS was slinging when they \"bravely\" took the mantle looks terrible in retrospect reply xenago 2 hours agorootparentOpensearch has been great so far, no issues ever since deploying the very initial forked version. Neither of those links seem like dealbreakers, am I missing something? Is the idea that opensearch is not usable in production because of missing autocomplete? reply BoorishBears 1 hour agorootparentDon't put words in my mouth out of desperation. > Is the idea that opensearch is not usable in production No one said it's not usable in production. > because of missing autocomplete? We have an operations team that wants to do searches across 200+ fields for an embedded device's logs. The engine supports it just fine, but what kind of UX is it to expect them to do manual lookups of the fields available? People with simple use cases of course can't imagine how important discovery features are. Of course those aren't all the parity gaps, a random sampling of the ones I banged my head against: - No Log Stream view, also critical for observability operations with any semblance of a reasonable UX - No wildcard type, critical for machine generated logs having sane searchability. Searches are literally broken otherwise by false negatives. - No nested fields in visualizations, can't visualize properly structured logs. - Can't change indexes on visualizations, need to recreate the entire visualization. - Can't use underscores at the start of a field name. - Doesn't support auto refreshing fields which again, is terrible for embedding device logging Elastic moved past basic search since the days OS forked it at, and now it's a genuinely nice choice for observability. There's a literal report I wrote on the gaps there to justify going to Elastic before giving up on our slow RFP process. Every gap no matter how small is representative of what's wrong with OpenSearch: they don't have 1/10th the incentive to actually put comparable resources to Elastic behind it. Especially when you have people lining up to make excuses based on the fact they're clueless about the gaps between them. Literal droves of people using it to provide a middling search experience to their users just don't see anything wrong with it. reply busterarm 4 hours agorootparentprevTeams should refuse to look at Elasticsearch. It's license is SSPL and they ship free and non-free features in the same binary. It's a ticking time bomb to run it in your company. Also you can just keep your data in postgres and use paradedb and stop having to deal with dramatically more expensive infrastructure and the JVM. reply BoorishBears 3 hours agorootparentAh yes, battle-tested Elasticsearch is a ticking time bomb for not wanting to get their lunch eaten by Jeff Bezos. Just use this pre-V1 public beta software I stumbled upon instead. reply wokwokwok 41 minutes agorootparentThe reality is that open search will be (if it is not already) more widely deployed and “battle tested” with bugs that production use raise resolved in it. The narrative that opensearch is some kind of unsafe abandonware is clearly nonsense when you read the commit log: https://github.com/opensearch-project/OpenSearch/commits/mai... All I can say is, sure, if you want elastic use elastic. …but opensearch is fine. I use it and have no problem with it. reply BoorishBears 36 minutes agorootparentHow did you go from \"It lacks so many improvements and advancements since the ancient version it was forked at\" to \"opensearch is some kind of unsafe abandonware\"? Would love to learn the thought process here. reply duskwuff 1 hour agorootparentprevQuery autocomplete is a feature of the Kibana web interface, not of the ElasticSearch database itself. Which isn't to say that it isn't useful, but it's more of a niche utility than a core feature of the stack. reply BoorishBears 46 minutes agorootparentMaybe you're unaware OpenSearch covers Kibana's functionality via OpenSearch-Dashboards? Just like the rest of X-Pack under OpenDistro pre-name change It's not exactly a niche utility for observability unless you plan on hand searching hundreds of fields. But of course see my other comment for a list of the other observability fumbles they've made. Elastic chose a pretty great time to start to give observability attention, and OS didn't keep up there. Meanwhile search is becoming more and more focused on integrating semantic search (which Lucene isn't particularly excellent at) reply gkbrk 1 hour agorootparentprev> OpenSearch infuriates me to no end. > Even basic things like autocompleting queries have been WIP for half a decade now. It's an open-source project. If this bothered you for half a decade, you could always submit a patch. Apparently it didn't bother enough other people that no one cared to send a patch. reply rmbyrro 1 hour agorootparentprevLinux distros also infuriate me sometimes, but: 1. I'm not using Mac-jail-OS 2. I'm not insane to even remotely consider the possibility of using Windows So, yea, I'm using OpenSearch. reply fractalb 4 hours agoprevI feel copyleft licenses look more favourable at this point of time. What’s the value of more free/business friendly licenses if you can’t guarantee that the same license will apply for all the future releases? Looks more like a bait and switch policy. reply paulryanrogers 4 hours agoparentThe future is never guaranteed. Much less if you have no paid contract with the people building and maintaining the floor underneath your feet. reply fractalb 4 hours agorootparentAWS, GCP have assurance that they won't need to pay for their Linux infrastructure. What is it if it wasn't for copyleft licenses(GPL)? reply endisneigh 28 minutes agorootparentWhat assurance is that? reply crabmusket 3 hours agoparentprevAm I right in understanding that the relicensing was possible because of the CLA, not just because of the BSD license? Would a permissively licensed project that didn't use a CLA be vulnerable in the same way? reply 8organicbits 3 hours agorootparentA key concern is that BSD isn't viral, so anyone can take BSD Redis and fork it into a commercial offering. If you want to, you can. The Redis trademark prevents anyone but Redis the company from calling their fork \"Redis\". A CLA may impact relicencing, it depends on the terms. A simple CLA may only say \"I am the owner of the code and I release it under $LICENSE\". The current Redis CLA also has a copyright grant, which gives Redis the company greater rights. reply Tabular-Iceberg 1 hour agorootparent“Viral” just means that the license has a “no additional restrictions” clause, not that you can’t make a commercial offering out of it. That’s why GPL and AGPL don’t really solve the problem. And the problem with the trademark model is that AWS, and especially Microsoft, already have established brand recognition with the people who sign the big SaaS and support contracts. The people who know what a Redis is are just nerds with no money, the real big shots do everything in Microsoft Excel. reply lmm 2 hours agorootparentprevA permissively licensed project without a CLA would be similarly vulnerable, because the BSD license allows them to make releases that include your code under a stricter license. To prevent them relicensing you would need both a strong copyleft in the license and no CLA/copyright assignment (like e.g. Linux - which can't even move to GPLv3 even if they wanted to, because it would be simply impossible to get all contributors' permission). reply orthoxerox 2 hours agorootparentprevNo, since you can include BSD-licensed code in non-free software with just an attribution. The only difference between relicensing Redis from BSD+CLA to SSPL and BSD to SSPL is that the former would've had a more detailed REDISCONTRIBUTIONS.txt. reply fractalb 3 hours agorootparentprevGPL mandates that all derived software must carry the same license. No need for CLA, as I understand it. reply pmontra 3 hours agorootparentThe copyright owners of a GPL software can do whatever they want with future versions, even going proprietary. The problem is that all the owners must agree on that. That's why some GPL software only accepts contributions by people that give copyright to a single maintainer entity. An example is FSF's copyright transfer, which to be fair is more nuanced than that and has also other purposes. https://www.fsf.org/bulletin/2022/fall/copyright-assignment-... reply fractalb 3 hours agorootparentprevI misunderstood your comment. Yes, CLA's make it possible to change the license. I guess CLA's won't work for GPL'd software. reply punnerud 3 hours agoprevInteresting that around 40% of the commits to Reddit is from Chinese companies (Tencent 24.8%, Alibaba 6.8, Huawei 5.2, Bytedance 2) reply rs_rs_rs_rs_rs 3 hours agoparentWhy is that interesting? reply jpgvm 2 hours agorootparentNot so much interesting as it is normal these days. Chinese big tech is much more OSS focussed than US big tech in my experience. reply ayakang31415 4 hours agoprevThere is an easy solution not just for this, but for other potential masses: Just go with MIT license and make money with support reply sa-code 2 hours agoparentHow does this stop you from \"getting Jeff'd\", i.e. when AWS takes your own source code and competes with you? reply IshKebab 2 hours agoparentprevYou're vastly overestimating how much companies want to pay for support. reply renegade-otter 1 hour agorootparentAnd if they do pay for support - it will be to Jeff Bezos and not some raggy startup of five. Support is usually for big corporate clients, and the Cover Your Ass principle works in full force there. \"No one ever got fired for choosing IBM\". reply blitzar 1 hour agorootparentThey wont get totally cut out though - Jeff Bezos will send the bugs they find while servicing their $10mil a year service contract to the raggy startup of five to fix over a weekend between their 3 jobs while sustaining themselves on the most expensive food they can afford - a bowl of discount ramen. reply akho 1 hour agorootparentprevAbout as much as it's worth, but not enough to give your VCs their x100 profit. reply esafak 9 hours agoprevThere's also DragonflyDB reply hipadev23 8 hours agoparentYeah but if you’re going to the trouble of switching, probably pick something that actually outperforms Redis/Redis Cluster. Which basically leaves you with Garnet. Redict is a pointless endeavor. Just stick with Redis 7.2 before the licensing change. Maybe change the binary name if it makes folks feel better. reply lll-o-lll 8 hours agorootparentIsn’t this exactly what Redict is? Plus a license change to prevent what happened to Redis from happening again. reply dralley 7 hours agoparentprevDragonflyDB doesn't have a better licensing situation. reply wallmountedtv 2 hours agoparentprevDragonfly isn't open source nor free software. Rather a pointless switch if you ask me. reply worldsoup 1 hour agorootparentit is free and source available...it's BSL which is slightly more permissive than SSPL that Redis adopted reply harryf 2 hours agoprevTo me Redis has always seemed like a Trojan Horse for developers. The first impression is its this simple key-value database, so easy to use. Oh wait... it's also a cache, nice! Let's cache all the things too! And look... all the cool kids are are using it too, so it must be cool, meanwhile the old Unix mantra of make each program do one thing well. To do a new job, build afresh rather than complicate old programs by adding new features. ( http://www.catb.org/~esr/writings/taoup/html/ch01s06.html ). Fast forward 10 years and you need to download it's Enterprise Whitepaper ( https://redis.com/solutions/use-cases/caching/ ) to make the right caching decisions. Where this is coming from is having worked on a project where Redis was being used as a database and a cache, on different ports. And of course most of the dev team hadn't read the the manual because Redis \"is simple and just works\". And of course someone forgot to actually configure the Redis instance that was supposed to be a cache to actually _be_ a cache. And someone else thought the instance that was supposed to be a cache but wasn't was actually a database. And yet another had used TTL caching to solve all their performance issues. And pretty soon mystery bugs start showing up but sadly no one can actually REASON about what the whole thing is doing any more, but there's no time to actually clean up the mess because it's a startup struggling to stay afloat. And I remember asking \"why didn't you memcached for caching?\" and the response was \"Dude! No one is using memcached any more\". So the technical decision for Redis was based on \"what's cool right now\". Anyway... I feel a bigger rant brewing so I'll stop here. reply cmacleod4 2 hours agoparentRedis is a very useful tool. You shouldn't blame the tool if people can't be bothered to use it properly! reply kunley 52 minutes agoparentprevI think it's rather features were added to Redis out of the experience and craft, not just to \"lure future users into a pit\", I doubt antirez would have that in mind. But I think you described right the social behaviors of certain/common types of users. reply rnts08 1 hour agoparentprevhear hear. reply kazinator 4 hours agoprevWhy don't the distros just take the last free version and fork from there. reply kqr 3 hours agoparentIsn't that what redict is? reply kazinator 3 hours agorootparentI see that it is. So then I don't see what the hoopla is about at all. The software is all there. Some dickheads forked a proprietary version. They got the name, which will be their consolation prize in their voyage to irrelevance; nice knowing you. Meanwhile, what everyone uses marches on. reply palata 1 hour agorootparentI believe that the hoopla is about the CLA. It feels immoral for an open source project to accept contributions but require a CLA, and later change the license for all those contributions that were never compensated. reply dtjohnnymonkey 7 hours agoprevI always wanted to try Pelikan Cache, but it’s hard to take a risk when there is Redis. Maybe now it’s more palatable. reply rokkitmensch 6 hours agoprevI so very much wish that Datomic had been licensed this way. reply umanwizard 5 hours agoparentWhy? reply FrustratedMonky 7 hours agoprevEngineers have to eat too. Nothing wrong with charging for support. I love passion projects as much as anyone, but there is a reason they are hobbies, and people need to keep a day job. Eventually it does get tiring to do support for free. Edit: Ok. I was talking OSS generally. I guess Redis is being bad actor if they are taking OSS work and running away with it to get the money, and not compensating the contributors. That is very wrong. I don't know history on Redis and assumed it was the contributors that founded the company. reply blackoil 7 hours agoparentI think the main issue is bait and switch. You start with a license, get lots of external contributors who are working for free, get ecosystem built around it for free and then change because you want to be paid. reply FrustratedMonky 7 hours agorootparentI agree. I'm not sure how nefarious this Redis move was. I guess I was assuming any move from 'free', to 'paid', will be met with some outcry regardless of how seamless they can pull it off. Or in other words, it is always a messy transition? reply cjbgkagh 6 hours agorootparentThe issue is they took the name with them. If they forked it with a new name no one would have cared. reply itake 7 hours agoparentprevMy issue is the OSS contributors that were not paid for their work, but their work will be monetized now. reply wmf 5 hours agorootparentThat's been going on for 30 years with proprietary BSD forks. That's what they signed up for. reply danielrhodes 7 hours agoparentprevI'd love to be corrected here, but my understanding is that the enterprise support and pro features model can be a pretty good business. Big deployments generally need really good support and help to overcome scaling challenges. Who better than the library maintainers to offer that, and your customers have deep pockets. Then on top of that, you run a business which basically creates proprietary Pro and Enterprise versions of a product which has tooling to operate the project at scale or in high uptime environments. Then you offer your own cloud versions of the product as well (which I think Redis has been doing). But in none of these cases are you creating a disincentive for anybody to use/adopt your product. You're simply creating value around the pain points. reply tick_tock_tick 5 hours agoparentprevThen don't make an open source hobby if you want to pay the bills with it. Or accept you're going to have to be a consultant for the project to make $$. I don't expect jack shit back for my open source contributions nor do I care if Amazon uses it. reply aurareturn 7 hours agoparentprevI agree. People here always seem to react badly to companies that provide something for free and now want to make a bit of money. It’s weird because they themselves work in tech and have to earn a living to put food on the table. Having no way of making money isn’t sustainable. reply smt88 7 hours agorootparentThe problem here is that this isn't putting food on the table for the people who actually built the software. It's a company surprising everyone by pocketing the money from other people's hard, unpaid work. reply ralusek 8 hours agoprevAm I insane or can't a company just fork it from before the license change? I mean, what even needs to change in it? I assume 95% of people were just using it for the features it's had since the beginning anyway. reply tredre3 8 hours agoparent> Am I insane or can't a company just fork it from before the license change? The article mentions half a dozen such forks. So not insane, maybe just a bit lazy ;). reply MenhirMike 8 hours agoparentprevThe question - just like always in cases like this - is which forks will get long-term support. So just like with Terraform, it's probably a good option to stay on the last open source Redis version and wait to see how things shake out, assuming that there are no critical security vulnerabilities in that version of Redis. Alternatively, be prepared to jump around between a few forks if one turns into a dead end. Or move to something else altogether, but that's a much bigger undertaking. reply klabb3 6 hours agoprevWhy don’t we try to fix the “cannot be used for bezos yacht”-licenses instead of shunning the numerous companies of especially databases who want to do good in a meaningful way? Source available is good, better than proprietary which is what we get with aws, but still not enough. People are legitimately afraid of rug pulls, like sneaking in essential features into paid offerings. I think a lot of the skepticism comes from those unknowns. Afaik the non-discriminatory use is the only ideological hard line. I guess people can debate that forever, like with GPL and copyleft and such. But my edgy take is that most people don’t really care about deep ideology yet want something that promotes a healthy hacker- and small-business friendly open source ecosystem. Ideally, a simple, well-understood license that restricts “re-selling your product” and not much more, that you can slap on a project without a legal team, just like with the MIT license. reply lolinder 4 hours agoparent> that you can slap on a project without a legal team The thing is, this kind of license is only really relevant to the kinds of projects that do have legal teams. If you're writing a hobby project you probably shouldn't waste time worrying about feeding the AWS machine, because the odds that you'll get noticed and used are tiny. Just pick GPL or MIT and be done with it. If you're participating in a large decentralized project like Postgres, then having a big player like Amazon providing managed hosting is actually a huge plus because you get lots of contributions from the big players [0]. There's very little downside for a project like this, and lots of upside. The only type of FOSS project that needs an \"AWS can't use this\" license is a project that is driven by a single for-profit company which decided to make their business model \"provide a managed solution layered on top of AWS\". Unsurprisingly, it's hard to compete with AWS on price when you're using AWS itself as your vendor, so these companies tend to be the ones that switch licenses to tell AWS they're not allowed to compete. These companies almost certainly have their own legal counsel and they represent a tiny minority of FOSS projects, so it's not obvious to me that we need a new standardized anti-AWS license. Maybe we should instead acknowledge that \"managed-hosting-supported FOSS database\" is an impossible business model and try something different next time. [0] https://www.postgresql.org/community/contributors/ reply photonthug 3 hours agorootparent> The thing is, this kind of license is only really relevant to the kinds of projects that do have legal teams So you want to advocate that every future database / infrastructure company needs to burn part of their runway to hire lawyers to do the repetitive work of making sure they can both try to be open and try to continue to exist? Plus we, the users, get to try to decode reams of legalese instead of using a convenient three-letter handle for an industry standard, like GPL or MIT? This does not seem ideal.. reply meowface 3 hours agorootparentprevPeople need to make money somehow. Developers who spend years creating, maintaining, and continually improving an open source database (or other project) used by millions deserve compensation. This doesn't apply as much to Redis Labs since they swooped in much later, but the general principle of trying to monetize your project with source-available licenses doesn't feel unethical to me. You're right that it's probably not a great business model most of the time, but what is a good business model to collect some of the value you've produced from dedicating years of your life to something loved by millions of people? It's certainly less sketchy than monetizing a free service with ads, or something. reply dragonwriter 3 hours agorootparent> This doesn't apply as much to Redis Labs since they swooped in much later, but the general principle of trying to monetize your project with source-available licenses doesn't feel unethical to me. Yes, monetizing with a proprietary license, whether source available or not, doesn't seem unethical to most people outside of Free Software ideologues. “The licensing model isn't unethical but competing ones are” isn’t why open source licenses became popular over proprietary (including source available) licenses, the fact that they commoditized the underlying software, enabled competing orojects evolved from the same codebase on essentially equal terms (which also allowed a competing project to fully replace the original if the original at some point failed the community) and, as hosted offerings became more common, the zero licensing friction for hosted solutions, that's what did it. It does mean charging monopoly rents for a hosted service isn't a viable way to recover development costs and pay returns to VCs, but until fairly recently, no one was trying to do VC-backed startups around single open-source products with that as their whole business plan, and the arguments as to why that would be a bad idea were well developed by the mid-1990s reply orthoxerox 2 hours agorootparentprev> Developers who spend years creating, maintaining, and continually improving an open source database (or other project) used by millions deserve compensation. Redis Labs can start by compensating its external contributors (Tencent, Amazon, Alibaba among them) if they care about fairness this much. reply Macha 35 minutes agorootparentDon't forget it's dependencies like the Linux kernel developers or GCC etc. reply diego_sandoval 4 hours agoparentprevThere's many things that I don't like about how open source works, but non-discriminatory licensing is not one of them. In fact, the concept of the four freedoms as necessary parts of a more fundamental freedom is one of the things that I value the most about the free software/open source world. In hindsight, I think that the probability that things turned out the way they did in this regard was relatively low, but the ideological drive of GNU and RMS made the world see the problem from a philosophical perspective rather than a practical one (even among people that don't fully agree with RMS/GNU/FSF). reply noirscape 1 hour agoparentprevThe problem is that in the minds of FOSS people, you might as well try to argue that you want more proprietary software. The \"major platform hijacks our code for the web\" is a valid concern, but the FOSS people have always kinda gone \"well fuck you for having these concerns\". That's... I guess fine enough when the majority of FOSS wasn't part of a SaaS stack, but now that the majority of big name libraries and tools are, it's becoming clearer and clearer that the OSD is just too lacking for those concerns. To be clear, this isn't a defense of SSPL or similar anti-Bezos licenses (the best one I've seen is the BSL, which transforms into a traditional OSS license after X years if you want my opinion), moreso an observation that there's a clear need here that can't be met by OSD. Paying developers on top of the FOSS model is hard; doing support favors entrenched suppliers because of the CYA problem (this is why AWS has the advantage they do) and I'm pretty sure that even if you do the support model, it usually just doesn't pan out. The main reason 90% of these licenses suck is far moreso because lawyers will draft contracts and licenses in such a way for you that they'll always give you the advantage. The SSPL being borderline impossible to comply with is by design for example. reply llm_trw 5 hours agoparentprevThe best idea I've come up with is a license which only grants the rights to a natural person to use the software otherwise it is identical to the MIT, GPL or AGPL, whatever your cup of tea is. If you're a corporation then you need to buy a license. reply 1vuio0pswjnm7 4 hours agorootparentCertainly not a new idea. As recently as early 1990s I licensed shareware that had terms requiring corporations to pay for a license with different fees and/or restrictions as those for individual, non-commercial users. Somehow this ideal was lost. Today, software authors seems allegiant to so-called \"tech\" companies, not to individual, non-commercial end users. As a non-commercial end user, I would prefer to use versions of open source software that are _not_ receiving contributions from so-called \"tech\" companies. But I never see software licenses that say, in so many words, \"If you are Amazon, Google, etc., then you need to contact the author for a commercial license.\" I used to think back in the 1990s that open source software was aimed at least in part at giving individuals an option to use software outside the control or influence of large corporations. This type of software does not feel as if it has the same goal today. It feels like it is literally _made for_ those large companies, not individual, non-commercial end users. Software authors seem delighted to engage with the companies, but generally prefer to avoid engagement with non-commercial end users. reply llm_trw 3 hours agorootparentNo, a non-commercial license is not a natural born person only license. If you're a human you get to use the GPL to your hearts content. If you're a corporation you do not. It's not a hard concept to understand, but it does mean people can't steal from the commons so they spend a lot of time trying to not understand it. reply 1vuio0pswjnm7 3 hours agorootparentI would have to look at the terms to understand. Your comment just reminded me of those sharware-era non-commercial licenses. That's all. Did not intend to suggest the license you mentioned is similar or the same in any other respect than having different license terms for commercial entities versus other users. reply akoboldfrying 5 hours agorootparentprevThis could be an interesting idea, but how would this constrain incorporating the licensed software in a larger piece of software? Either as a library, or a component like a Docker image? Would it be \"viral\" in the sense that, if I want to publish software that internally uses a Docker container running software with such a license, my own software can be used only by natural persons? reply llm_trw 3 hours agorootparentYes, you will have to publish under a license with the same clauses. Not because you are distributing it, but because only natural persons can run the software. reply bawolff 5 hours agorootparentprevThis is not a new idea... i mean its so old it was called out as being \"not free\" back in the 80s by the gnu project. reply llm_trw 3 hours agorootparentThe GNU project has failed at getting source code to users so badly that despite owning a half dozen GPL based devises I have no access to the source code of any of them. At this point listening to them is at best pointless and at worst actively harmful. This is what happens when the last time you worked at a real job was some time in the 1980s. reply aragilar 5 hours agorootparentprevThere exist shared-source licences which do this (https://prosperitylicense.com/ is almost what you describe, but it's the one I can recall of the top of my head), but you can't (by definition) have a open source license like this. reply dehrmann 5 hours agoparentprev> re-selling your product” and not much more That's not what AWS is doing. AWS is selling management services. The fact that managed DBs are as popular as they are says this is a significant value add. reply klabb3 2 hours agorootparent> That's not what AWS is doing. Well yeah technically the product is free but the value comes largely from unpaid labor. That needs to change if we want a healthy small business sector around larger open source products. It’s not based in opinion or ideological conviction on my end, but rather watching this frictionous and awkward transformation to BSL-style licenses happen over and over with small-mid-size companies who are building valuable products and want to be as open as possible while running a business. > The fact that managed DBs are as popular as they are says this is a significant value add. Indeed, and that’s a good thing, because it means a path to a sustainable business model is feasible! However, if you subsidize the product (make it free and open) in order to make it back in management fees, then you need legal rights to it. It could be “you have to use $PROJECTs own management product” but that’s quite narrow thinking. It’s a win-win for everyone else if mega-players like aws can provide their own management but they will have to rev-share with the project owner, on their terms. That’s a battle-tested model that works in all kinds of sectors, with much smaller actors. reply ajmurmann 4 hours agorootparentprevAnd that's also how DB companies try to monetize. So a hyperscaler offering this directly really undermines your entire business. In the past you could offer a Enterprise version with support, but with the move to the cloud that market is shrinking and Amazon is eating the new market themselves reply dragonwriter 3 hours agorootparent> And that’s also how DB companies try to monetize Open source DBs have been around a while, though. A minority of them trying to pay the bills with monopoly rents on hosted services is… much newer. Its how VC-backed DB-as-central-tech startups try to monetize, and, yeah, if you are going to do that, you need a proprietary license. But don’t expect people to treat your DB like an open source DB, then, either. You can be Oracle instead of Postgres, but you can’t also expect to get treated like Postgres, instead of Oracle. reply thayne 3 hours agorootparentprevPerhaps we need a different way to fund database development (not necessarily a single company monetizing it). If the service you provide is hosting DBs, you are are at an inherent disadvantage competing with hosted db offerings form your potential customers' cloud provider. Even if your product is technically superior in every way, you are another entity they have to do business with (billing, support, contracts, security evaluations, etc.), which adds friction, and either you host on your own infrastructure, which means higher network latency, and network costs to get data to and from your customer's cloud, or you have hosting options that run inside all the major cloud providers, in any regions your customers use, which means you (or your customer) ends up paying the hyperscaler for the infrastructure, and you have the added complexity of having to know how to manage it on multiple cloud platforms. And there there is also the fact that it is much more difficult for you to build integration with the cloud's IAM or other services. Basically, most cloud customers would rather use a service that is part of the cloud platform than from another provider. Ideally, instead of competing with the hyperscalers, they would sell some service to the hyperscalers that have the ir own hosted services. But I don't know how to get there. As a brief sidenote, AFAICT this isn't what happened with the hashicorp license change, for them it seems like the pressure largely came from startups, not the big cloud companies. reply dragonwriter 1 hour agorootparent> Perhaps we need a different way to fund database development (not necessarily a single company monetizing it). We have several in use by long-running open source database projects that have not felt a need to jump on proprietary source-available licensing, even though firms like AWS are indeed using their code and selling services. AWS (and other big firms with hosted services) are also sponsoring those DBs with code and/or money, but in many cases the basic model predates the big push to the cloud, and other downstream businesses were doing that before AWS and other cloud hosts. reply dragonwriter 3 hours agoparentprev> Source available is good, better than proprietary “Source available” is a subcategory of proprietary, not “better than proprietary”. > But my edgy take is that most people don’t really care about deep ideology I think most people that orefer open source to proprietary software either care about the business benefits open-source provides over proprietary (including source-available) software or have an ideological affinity for Free Software, occasionally both. reply aragilar 5 hours agoparentprevDefine \"fix\". By definition you cannot have an open source licence which says \"cannot be used for bezos yacht\". Either you accept that, and don't rely on exclusivity for income (which really what the whole relicensing thing is about), or you don't open source your code (and accept that not being open source is a problem for some people). Open source + exclusivity for income is an unstable state, and really only works if no-one else competes with you (e.g. a specific niche), or you have some other means to enforce it (e.g. Red Hat limiting access to source to its customers, and not renewing contracts if they share the code). reply klabb3 4 hours agorootparent> Define \"fix\". It’s early. Everyone is confused. If I could define it, I would have provided a defintion. At this stage, it’s about acquiring requirements and looking at prior art. And being humble about the solution space. No? If you don’t think there’s any problem today, then argue that point. > By definition you cannot have an open source licence which says \"cannot be used for bezos yacht\". By definition by what definition? There are already disagreements about what open source is, long before these business models. The problem solving comes first, and then there may or not be a debate whether about whether the solution fits better into an existing definition or a new one. > Either you accept that […] or you don't open source your code But why? Is this an intrinsic duality or an anccidental/historical one? Or is it about preventing scope creep of the open source term? The latter is easy to solve - don’t call it open source. Or at least defer the debate. reply dragonwriter 1 hour agorootparent> It’s early. Everyone is confused. No, it is not, it is decades in, in a well-understood area. Some VC-backed firms (and the VC’s backing them, who see this as critical beyond the immediate firms) want to trade on the idea and popularity of open source without its substance because open source as has has been known for decades is not a viable foundation for the kind of business model that they would like, but has at the same time secured the kind of mindshare in the market that makes it difficult for proprietary software to achieve the kind of rapid ramp-up that provides the timing and combination of returns they want. So they’ve decided to spend a lot of effort making everyone feel confused at some ginned up new threat to open-source, which is not a threat to open source, not something that open source community hasn’t known about for decades, but just a problem for a bait-and-switch business model in which software gains traction trading on the cachet of open source and then rakes in monopoly rents that avoiding is one of the benefits to users of open source licensing. They want users to see them like Postgres, but they want to milk users like Oracle. That’s the problem – a marketing problem for proprietary software vendors. The attempt to sell confusion is an attempt to conceal that that is all the problem is. reply klabb3 53 minutes agorootparentDislike of VCs as much as the next guy, but is this a representative picture? Many companies I’ve seen have been genuinely interesting, like SurrealDB, CockroachDB and Hashicorp. Are you saying it’s all a long bait and switch game? reply pabs3 3 hours agorootparentprev> By definition by what definition? By the \"Open Source Definition\": https://opensource.org/osd/ reply klabb3 1 hour agorootparentRight. It’s a public benefit org based in CA. I very much appreciate what they do, but I don’t think they own or should own the term. In either case, it’s a moot point because it’s just a term definition. The important thing is to find a good model that promotes the same or very similar benefits we get from traditional OSS but in an evolving world. reply tick_tock_tick 5 hours agoparentprevI think you'll find that the vast vast majority of us don't care about the whole \"cannot be used for bezos yacht\" problem when we contribute to free software. I contribute with no expectation of monitory gain and absolutely zero desire for some random foundation or company that's part or almost always created later to make any money. If some contributors want to make money become consultants the \"amazon problem\" isn't a real one. I love when Amazon or Google or whoever starts working with a project I'm touching it means it will normally get high quality contributions. reply eindiran 5 hours agorootparentOP's \"cannot be used for bezos yacht\" problem is about discriminatory licenses. If you don't care that eg Amazon can use your software, there is nothing at odds with what OP sees as a problem (discrimiatory licenses that violate points 5 or 6 of the OSD[0]). [0] https://opensource.org/osd reply Temporary_31337 5 hours agorootparentprevHow do you make money? reply tick_tock_tick 5 hours agorootparentI work a normal job.... Open source is a couple of hours a week at most. It's a hobby for me some months I do nothing other I crush bugs like it was my job. reply ajmurmann 5 hours agorootparentThe problem is that big OSS database projects have teams of paid developers working on them and they want to make their money back. You can do this by offering paid support or a hosted offering. Having someone like Amazon take your product and build their own hosted version really cuts into that revenue. Now, Redis was AFAIK pretty much just written by antirez and maybe it could have stayed that way, but even exceptional individuals clearly want to move on eventually and you'll likely need a team of maintainers. Distributed data products are complex and need people who contribute more than nights and weekends. reply vasco 4 hours agorootparentThe best open source software is developed by unpaid people. Even the ones with companies around them, the best work is done in the first phase when everyone is still unpaid. The \"cuts into their revenues\" part usually mostly affects their ability to keep developing the non open source parts anyway, their SaaS dashboard, their billing, etc. Take redis, you could never change it again and it's fine. There's no need to support anyone, it's complete software that stands on its own. reply lazyasciiart 53 minutes agorootparentUntil the discovery of a log4j-equivalent, then suddenly it's not fine. reply thayne 4 hours agoparentprevI'm much more sympathetic to a company that starts out with this kind of license than one who changes the license after accepting contributions under a more permissive license, which is basically a bait and switch on those developers. It's even worse when the company previously promised not to do such a thing, as is the case with redis. And this is especially bad because the company that is now called Redis didn't even create the database, they took over an existing project. reply rnts08 1 hour agoparentprevSo you're suggesting the game engine model, you're free to use this software for whatever until you make $x from it? Unity was like that before they screwed it up, I have heard of other systems as well but not sure since it's not my cup of tea. reply wmf 5 hours agoparentprevA bunch of people are working on this from different angles. It's in a chaotic phase right now but it will probably consolidate later. reply jumploops 5 hours agoparentprevI believe this is the goal of https://faircode.io ? reply ocdtrekkie 2 hours agoparentprevThe reason these licenses \"can't\" be fixed is because the OSI approves open source licenses and Amazon is their second biggest corporate sponsor. If they approved SSPL they'd probably have to lay off a staff member or two. reply jsmeaton 7 hours agoprevI’m usually pretty ambivalent when a company decides to move to a license like BUSL. Sure it’s not “free” - but practically it only affects the likes of AWS from freeloading while making extraordinary profits. Especially true when a given company started the project. I understand why some hold strong feelings on the principles of OSS. My perspective is we’ll have fewer nice things if we allow the likes of AWS to cannibalise successful services. But I feel no such sympathy for Redis nee Labs. It was never their project. They took over stewardship and then effectively stole the project for themselves. They’re not even the dominant contributor to the core product. reply anonthrow 7 hours agoparentI agree with your points min general but want to share my experience and maybe some counterpoint. Being a customer of the redis labs' hosted solution, we noticed several issues: - RLs solution is way more cost effective than AWS's - RLs solution is not even close to elasticache in its ability to scale - when issues occur the organization internally moves incredibly slowly so simple issues can turn into prolonged outages Moving to this licensing model will make it possible for them to better invest in these things. That said, given the quality of their offering and lack of investment in the actual redis platform, why would anyone continue to use redis after the license change? The cloud providers can fork off their own version and never look back! I think they're shooting themselves in the foot here. reply pm90 4 hours agorootparent> RLs solution is way more cost effective than AWS's Its not cost effective if the service causes extended outages as you mentioned later. reply YeBanKo 6 hours agoparentprevSeems similar to what Elastic did few years ago [1]. I kinda understand their motivation. It's not theirs originally, but they had antirez working on it for 5 years as their employee. They are making some contributions [2], I wish GH had a way to see such an insight by company affiliation. On the other hand, AWS and likes can easily fork pre-license-change version and spin it into its own product. However, I am fairly certain that AWS Elasticache is already such a thing – their own fork that diverged enough from the upstream and they are not eager to share. So I view it as every major cloud provider with redis offering has its own fork. Except that Redis Labs also owns the original name. But it can go on as a stand alone project, like MariDB was spawn off after MySQL acquisition by Oracle. [1] https://news.ycombinator.com/item?id=25776657 [2] https://github.com/redis/redis/graphs/contributors?from=2019... reply AntonyGarand 6 hours agorootparentAWS did not launch their own spinoff alone, but instead joined the Valkey project by the Linux Foundation[0], alongside many other major contributors: > Industry participants, including Amazon Web Services (AWS), Google Cloud, Oracle, Ericsson, and Snap Inc. are supporting Valkey. They are focused on making contributions that support the long-term health and viability of the project so that everyone can benefit from it. Seems like a good alternative to a single company's spinoff: Many major providers working on this same project should result in everyone benefiting from it. https://www.linuxfoundation.org/press/linux-foundation-launc... reply YeBanKo 6 hours agorootparentI don't have any inside knowledge, but I can't believe that they don't have an internal fork of Redis for Elasticache. reply tsimionescu 5 hours agoparentprevWasn't AWS a major contributor to Redis? How are they \"freeloading\"? reply jsmeaton 11 minutes agorootparentIn this case that’s true and why I said I don’t think it applies here. Typically it does though. Open source services are in a weird spot. They spend tonnes of money developing it and big providers are able to cannibalise as soon as something becomes popular at very little cost to themselves. I think we do need something between fully free and fully closed where cloud providers pay some kind of licensing. It’s a problem worth solving. reply 420698008 4 hours agorootparentprevI'm pretty sure ElastiCache has been around longer than Redis Labs too, so it's not like AWS undercut them, plus RL got a ton of free market research from it reply 46 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Redis Ltd. moved to non-free licenses for its \"in-memory data store\" project, sparking worry in the open-source community.",
      "The shift led to the rise of alternatives like KeyDB and Valkey, impacting major Linux distributions and stirring controversy.",
      "New licensing models like SSPL and BSL are explored, hinting at potential shifts in the open-source ecosystem."
    ],
    "commentSummary": [
      "The article covers the dispute over Redis licensing changes, as AWS introduces Redis-as-a-service, sparking discussions on developer compensation, major cloud providers' roles, and the open-source community impact.",
      "Predatory practices, licensing issues, and alternatives like Garnet are mentioned, along with debates on ethics, licensing models, business longevity, and the struggles of open-source firms in tech.",
      "Concerns include the transition of open source from empowering users to favoring tech corporations, obstacles in cloud service integration, and the repercussions of biased licenses."
    ],
    "points": 466,
    "commentCount": 296,
    "retryCount": 0,
    "time": 1711664849
  },
  {
    "id": 39854182,
    "title": "NotepadNext: Cross-Platform Reimplementation with Bugs and Half-Working Features",
    "originLink": "https://github.com/dail8859/NotepadNext",
    "originBody": "Notepad Next A cross-platform, reimplementation of Notepad++. Though the application overall is stable and usable, it should not be considered safe for critically important work. There are numerous bugs and half working implementations. Pull requests are greatly appreciated. Installation Packages are available for Windows, Linux, and MacOS. Windows packages are available as an installer or a stand-alone zip file on the release page. The installer provides additional components such as an auto-updater and Windows context menu integration. You can easily install it with Winget: winget install dail8859.NotepadNext Linux packages can be obtained by downloading the stand-alone AppImage on the release page or by installing the flatpak by executing: flatpak install flathub com.github.dail8859.NotepadNext MacOS disk images can be downloaded from the release page. MacOS Tweaks By default, MacOS enables font smoothing which causes text to appear quite differently from the Windows version. This can be disabled system-wide using the following command: defaults -currentHost write -g AppleFontSmoothing -int 0 A restart is required for this to take effect. Development Current development is done using Visual Studio 2022 and Qt v6.2+ on Windows. This is also known to build successfully on various Linux distributions and macOS. Other platforms/compilers should be usable with minor modifications. If you are familiar with building C++ Qt desktop applications with Qt Creator, then this should be as simple as opening src/NotepadNext.pro and build/run the project. If you are new to building C++ Qt desktop applications, there is a more detailed guide here. License This code is released under the GNU General Public License version 3.",
    "commentLink": "https://news.ycombinator.com/item?id=39854182",
    "commentBody": "NotepadNext – a cross-platform reimplementation of Notepad++ (github.com/dail8859)432 points by Brajeshwar 17 hours agohidepastfavorite266 comments qwertox 16 hours agoNotepad++ (and this one here) are based on Scintilla [0]. It's worth pointing it out because it is a high-quality open source code editor component. SciTE [1] is the \"official\" demo-editor for Scintilla and was last updated on March 9th 2024. The history reaches back to 1999. [0] https://www.scintilla.org/ [1] https://www.scintilla.org/SciTE.html reply speps 16 hours agoparentI wrote a custom mod more than 15 years ago for SciTE that exposed its plugin API to Ruby and wrote some of my own plugins. It didn't support multiple cursors and I instantly switched to Sublime as soon as I discovered that feature, never looked back. reply jmole 15 hours agorootparentWhat are multiple cursors used for? reply rezonant 13 hours agorootparentAny time you need to make the same edits in multiple places. I use it to mass edit array items for example by using the highlight / add cursor to identical text feature in VS Code (Ctrl+D). I even use it to copy data out of the browser and mass edit it into data structures-- often there will be some pattern to the pasted data even if it's garbage, so being able to quickly set up multicursors around the patterns in the text makes this sort of task much easier, if you are luckily on how the data pastes out. Multicursors are the number one editor innovation of the last ten years that developers should get comfortable with-- once you start to use them you won't want to use an editor without them. reply innocenat 6 hours agorootparentPersonally while there are some task that's easier with multiple cursors, I have personally yet to find any use case where regexp replace in selections doesn't work as well. reply germandiago 6 hours agorootparentI find Emacs Macros and rectangular editing as more useful in lore situations than multiple cursors. As for regexps, the syntax in Emacs is hell, but I do know Emcacs has very powerful edit/replace tools. reply overtomanu 33 minutes agorootparentMulti-cursor is more flexible than rectangular selection. You can skip or delete words of varying length etc. It is certainly less powerful than vim macro and regex, but it's easy to use because 1) there are less shortcuts to remember 2) no need to think too much like figuring out regex for simple tasks 3) it gives instant feedback Video showing this https://youtu.be/lhFNWTAIzOI?t=28 reply cylinder714 4 hours agorootparentprev\"Emcacs\"...I like it. reply edflsafoiewq 4 hours agorootparentprevThere's a reason people use visual editors and not ed. reply treflop 3 hours agorootparentWouldn’t remotely compare regex to ed. I also haven’t found a use for multiple cursors. Writing a regex is quick and easy. reply lenkite 3 hours agorootparentprevI guess with rectangular selection and macros, VIM folks don't find much use for multiple cursors. reply twodave 14 hours agorootparentprevI use it to: * transform a list of field names into different formats (class properties, sql select list, etc.) * quick and dirty convert delimited text into insert statements or graphql queries or json objects * really anything I need to change in column mode but with better tracking of words via mod+arrow keys reply nolongerthere 14 hours agorootparentprevI use it daily in vscode to clean up small data sets where wrangling regex will take more time, and the data set isn’t something that I’m gonna see again so it’s not worth generalizing a solution. reply input_sh 15 hours agorootparentprevIf you're using the same variable name across the file, but want to change only a couple of references to something else, it fills that \"I need to do this more than once, but in a bit of an easier to reach, fancier way than with find and replace\" niche. reply AeroNotix 13 hours agorootparentMost editors these days should have \"rename\" functionality which is very aware of how that symbol is used across a codebase. M-x lsp-rename in emacs, for example works great, if you're using lsp. reply rezonant 13 hours agorootparentYes but this is more general, allowing you to use it in more cases. For instance, I use it heavily when converting old JavaScript to modern ES/TS. Using \"var\" everywhere? Replace them all with let. Using anonymous functions instead of lambdas, easy to change those all over (provided there's no \"this\" dependencies) Have two thousand strings which all need the same edits? No need to do a find/replace operation, you can do it directly in the editor. reply lelanthran 1 hour agorootparent> Have two thousand strings which all need the same edits? No need to do a find/replace operation, you can do it directly in the editor. I might be missing something here, but how is making 2000 individual selections better than `:%s/oldstring/newstring/g`? I'm guessing that you have a rule for setting up those 2000 selection, or something? I mean, even for like 5 identical edits, the regex is going to be faster, so you must have a short way of performing the multi-selection. reply layer8 12 hours agorootparentprevHow do you select those two thousand strings? reply zimmund 9 hours agorootparentUsing VS Code: select whatever you want to match, then Ctrl+Shift+L reply layer8 7 hours agorootparentSo it has to be two thousand identical strings? Then I don’t understand the benefit over search & replace. reply rezonant 7 hours agorootparentIt goes further than just that -- for instance, lets say your data looks like this: [ \"foo bar/2322\", \"foo baz/4223\", \"foo blah/2232\", ... ] And you need to reformat that into: [ \"bar 2322: foo\", \"baz 4223: foo\", \"blah 2232: foo\", ... ] You can absolutely use a regular expression find/replace to solve this. But using multicursors, you can just highlight the first \"foo \", then hold Ctrl+D to select all instances, then hit right arrow key so that your cursors are at \"foo |bar/2322\" (and nothing is selected) et al, then use shift+right arrow key to select bar, baz, blah, and all other substrings, then use ctrl+X to cut that list to your clipboard. Hit delete key to get rid of the /s and add a space so you can keep the fields separated. Then, use ctrl+arrow to move your cursors to just before foo (\"|foo /2322\"), paste, hit space. Now you have \"bar foo 2322\". Repeat the same action to cut all the \"foo\" substrings, then move your cursor to the end, now type \": \" and then paste. You get the idea. It sounds complex, but these are all just comprised of the same fundamental editing patterns-- all of the cursors act as if you had just that one cursor when you press the keys. You have to play with multicursors to really appreciate their power. Most of the time, someone who is well versed with multicursors and their editor's cursor shortcuts (arrow keys, page up/down, shift/ctrl arrow keys, etc) will be able to complete these sort of textual manipulations much faster than using find/replace. reply kemayo 6 hours agorootparentprevIt doesn't have to be identical. For the method they're describing you just have to get search results -- so you can use regex in that. You can also just command-click anywhere you want to leave a new selection-point. (Or use various other find commands that search for things and add them to your selection pool.) The benefit of it is that you're left with a cursor in each location, and you can then do absolutely anything that you'd normally do with a single cursor in every place at once. This includes things like copy/paste, which will maintain a separate buffer in each selection. This also includes things that're actually tough to do with normal find/replace -- I could select the bit after a search result and switch it to title-case, for instance. You can do most things you'd use it for with find/replace. But sometimes it's easier to watch it happen as you type, rather than construct a fairly complex regex with groups and suchlike. reply neoromantique 13 hours agorootparentprevIt helps when it is a bit more interactive, i.e when I only need to replace some of the occurrences versus everything. Also when working with lists it is useful, you spawn cursors on , orI want something super lightweight and fast that can be run as close to standalone as possible. Unfortunately, I don’t really see how you could make a standalone GUI app of meaningful scope on Linux, given the platform that “standalone” is usually defined with respect to doesn’t include a widget toolkit or even a font handling library (it does on Windows). I guess going it alone with an OpenGL viewport would work, but that’s also just setting yourself up for pain the minute accessibility, font shaping, or input methods come into the picture. I won’t begrudge anyone writing their own toolkit or shaper, it’s just, that’s far too much work to do for the sake of being “standalone”. For the ideal of doing everything yourself, yes, I can definitely sympathize, but just getting rid of DT_NEEDED records isn’t much of an ideal. reply DEADMINCE 8 hours agorootparent> Unfortunately, I don’t really see how you could make a standalone GUI app of meaningful scope on Linux, given the platform that “standalone” is usually defined with respect to doesn’t include a widget toolkit or even a font handling library (it does on Windows). Fair point. I meant able to run without needing any special libraries above those that can be assumed to be installed on a standard linux desktop. reply soco 13 hours agorootparentprevAnd formatting! Don't forget language-aware formatting and maybe even syntax coloring. reply DEADMINCE 8 hours agorootparentVery true, very important! reply anonnon 12 hours agoparentprevwxWidget's wxStyledTextCtrl is based on Scintilla, too: https://wiki.wxwidgets.org/WxStyledTextCtrl reply dajt 10 hours agoparentprevI used Scintilla as the editing component for a JavaScript IDE about 20 years ago, was good. reply tentacleuno 16 hours agoprevI very much miss Notepad++ for making quick notes, and then being able to close the window without being asked whether I'd like to save the document. This, and auto-save (so not losing documents if you forget to save) is one of the main reasons I replaced Notepad with ++. Rather quickly, I found that I had to completely remove Notepad so muscle memory would stop guiding me to it. Good times (and sad ones; I lost a lot of lecture notes) -- nevertheless, Notepad++ is an excellent piece of software. I'm curious if the same \"write and close the window\" workflow is achievable with Kate, as I haven't been able to find the option; and, of course, the obvious question: what about this one? reply publius_0xf3 15 hours agoparentOccasionally, someone will submit their new text editor to Hacker News and the first thing I do is check if it quietly saves sessions upon closure. It's amazing how many people don't bother implementing this indispensable feature. reply mikae1 10 hours agorootparent> It's amazing how many people don't bother implementing this indispensable feature. BBEdit is almost bizarrely bulletproof in this regard. I never, in a decade, lost a single note. To me, this is probably the most overlooked and important feature in a text editor. I switched to Plasma/Linux a few years ago and have since learned that Kate is not as robust. Must try Notepad Next. reply jraph 15 hours agorootparentprevKate can restore sessions, not sure it can auto save on close. Ctrl+L saves all but Kate will ask for still unnamed files. reply tentacleuno 14 hours agorootparentI haven't been able to get it to act like Notepad++, wherein it doesn't ask you to save on quit. Perhaps there's a configuration option I've missed? reply jraph 14 hours agorootparentI'll look for it but I'm not sure I've ever seen it despite having seen the settings countless times. If it doesn't exist it could be an easy and useful contribution :-) reply tentacleuno 15 hours agorootparentprevI'm very glad others have come to expect this feature, too; I assumed it was another of my weird, niche workflows :-) reply kzrdude 10 hours agorootparentprevVim had this feature for years. But it took until I tested lazyvim (neovim distribution of plugins) that makes session restore so easily accessible, that I now rely on it. reply mxuribe 14 hours agoparentprevI don't think the core/default Kate editor does the same \"write and close the window\" like Notepad++. Kate does have pretty cool options for session handling - which helps keep files open that you had been working on, etc...which i understand is not the same thing. But, now that you asked, i wonder if there is a plugin or extenson for Kate that might provide such a feature? I myself am a fan of Notepad++, and install it on any corporate-issued Windows machine that i am given by dayjobs...but at home, its all linux all the time, so Kate comes closest for me. I did see someone else mentioned that there is something named NotepadQQ or something which is like Notepad++ but works cross-platform...so that sounds interesting if true. And, i wonder if NotepaddQQ has that auto \"write and close the window\" workflow? reply EMM_386 12 hours agoparentprev> being able to close the window without being asked whether I'd like to save the document Notepad on Windows now has this behavior. Finally. After having used it for more than three decades, it now has the one feature that prevented me from using it to take scratch notes. It will autosave without prompting on close. And it has a dark mode, so now I use it daily. reply nullindividual 15 hours agoparentprevNotepad will now restore open files, like Notepad++ does. TextEdit on macOS does the same. reply MBCook 14 hours agorootparentIt has been a suggested/encouraged default behavior on the Mac for many years at this point. reply adamomada 14 hours agorootparentIt’s just yet another thing Apple gets right: why would the default be to NOT keep what you just put into the computer? reply card_zero 14 hours agorootparentIt seems to be the modern way, and normal on mobile apps, and I can't stand it. Why would I want the computer to save what I wrote without asking? I like being asked. I dislike computers trying to be clever. reply jacurtis 11 hours agorootparentThis happened to me yesterday: I had to complete a resiliency test on our infrastructure and submit it to auditors for compliance reasons. I ran the tests, got the results, and I have to put it into a report. The report is like 30 pages long or more, but very little changes between each test (we do them quarterly). So I only usually change a few tables with the new report results, and freeflow some commentary in the discussion section that is unique for that run, so that the auditor feels special. Anyway, I open up the previous quarter's report. I edit a bunch of data, write a bunch of useless commentary and go to \"Save As\" with the Q1-2024 suffix, and I realize the Word document had been autosaving my work the whole time on top of the Q4-2023 report. Urgh, very annoying. I didn't save intentionally because I knew I would save a copy later. I was able to restore the old version through revision history, but still annoying nonetheless. reply dmonitor 9 hours agorootparentThat's really annoying, but not quite the same as what Notepad++ (and presumably others) do. Notepad++ just saves a cached version of the file without touching the original until you explicitly hit \"Save\". If you close the file in Notepad++ (not exit Notepad++, but tell Notepad++ to close the file thus deleting the cache), it will ask whether you want to save your work. reply Dalewyn 11 hours agorootparentprevI'm inclined to agree with Microsoft Word's autosave, here. If you are making edits to a file, the implication (which could be wrong) is you're intending to overwrite at the end. And indeed, autosave came around because way too many people were losing document modifications to freak power outages and computer crashes. If the intent is to not overwrite an existing file, I personally learned to make a copy first either via Save As in the program or by copying in whatever file manager I'm using. That way I make my intention clear to both myself and the computer. I've actually burned myself numerous times because occasionally I would forget to copy first, instinctively hit CTRL+S frequently because I hail from before autosaving became widespread, and then realize I just overwrote something I wanted to keep as-is. reply gradstudent 10 hours agorootparentAs I read it, the GP complains about Word auto-saving on top of the OG document. I think intermediate changes should go to an auto-save buffer until you tell the editor to save over the top. For that reason I'm inclined to agree with the GP. Word's behaviour is wrong and the process you describe sounds like a workaround. reply NekkoDroid 13 hours agorootparentprev> why would the default be to NOT keep what you just put into the computer? Because you didn't ask it to save and closed the app? reply thereisnospork 11 hours agorootparentAnd if you misclick? Or there's a power outage? Or crash? Guardrails are nice and since I usually want to save what I've entered I appreciate it being the default behavior. Or in other words, I asked. To address another commenter's point about word overwriting: auto saves should only go into a temp/separate file so as to never supersede manual saves. reply kayodelycaon 14 hours agoparentprevYou probably already know this. VSCode has both autosave and hot exit features. If you quit the application when hot exit is enabled, it will restore all windows the next time you start it. I don't see any way to close individual windows without prompting but you can do command+w and then command+d to \"Don't Save\". reply tentacleuno 14 hours agorootparentOh yeah, VSCode's autosave has saved me hours in otherwise-lost code. I do make frequent use of its hot-exit functionality, too. While that's great, I wish the same thing existed for a lightweight Notepad-esque app, too: I used ++ a lot for quickly jotting down information while it was being read to me (so, on the phone); having to start a full-blown IDE for this seems wasteful, and not the right tool for the job. Perhaps the solution is just to leave VSCode open all the time, but that wouldn't work either: whenever I switch workspaces, I'm asked whether I'd like to save the unsaved files (so, just like Kate), and it can be quite resource intensive. Grr. reply SV_BubbleTime 10 hours agorootparentNot just the auto save, but that it is using GIT on the backend for the timeline. Such a helpful feature! reply teekert 14 hours agoparentprevFwiw, I do this in Obsidian (it just saves every keystroke), really enjoying it. reply izoow 11 hours agoparentprevI've been using Sublime Text to do this. I use VS Code/Neovim for my programming, but Sublime Text is still way too convenient as a notepad to keep around, one of the main reasons being this feature. reply aftbit 12 hours agoparentprevI never noticed this. I just hit Ctrl-S obsessively in every application. I heard that once upon a time, vanilla Notepad ignored Ctrl-S. Horror! reply thrdbndndn 15 hours agoparentprevit's achievable with default notepad.exe in Win11. reply dailykoder 13 hours agoparentprevHave you tried neovim? It just works and is blazing fast (respectively plain vim, if you don't need plugins) reply abgiva 12 hours agoparentprevTry CudaText. reply noisy_boy 2 hours agorootparentIts a pain to install due to dependencies on libqt5pas1 (which doesn't work with the version provided on Ubuntu 22.04). I was able to install via snap but it takes way too long to start up (even vscode starts faster). reply fngjdflmdflg 15 hours agoprevThe startup speed for this app is really good. From my quick testing it seems like it is as fast or slightly faster than npp. I am surprised that QT can be that fast. I recall this line from the Sumatra PDF developer on why he chose win32 only: >The only way for one person to even attempt cross-platform app is to use a UI abstraction layer like Qt, WxWidgets or Gtk. >The problem is that Gtk is ugly, Qt is extremely bloated and WxWidgets barely works.[0] To be fair, a PDF reader and a notepad editor are two different things, and startup speed is only one metric which is the only one I tested. But I always assumed npp was also using win32 APIs only for similar reasons. (I don't actualy know what GUI toolkit npp uses.) And \"bloated\" could perhaps mean a lot of things. Perhaps QT takes more memory or something. But I always assumed npp's unbeatable speed was due to native APIs. [0] https://blog.kowalczyk.info/article/2f72237a4230410a888acbfc... reply chrystalkey 14 hours agoparentSumatra is such an awesome piece of software, small, fast, almost entirely bug-free, incredible load speeds for large pdfs... my Linux alternative is Evince, which does about the same reply xcv123 14 hours agoparentprevPerformance is not an issue with Qt. He probably means the framework is too large and complicated from a developer perspective. The compiled code is fast. reply pavon 10 hours agorootparentI think Krzysztof's objection was mainly about size (memory/disk). He set pretty high standards for SumatraPDF in that regard. The full statically linked executable is only 8MB, while the Qt Core and UI libraries by themselves are larger than that, and that is before you start talking about dependencies like the 20MB ICU data. reply umpalumpaaa 13 hours agorootparentprevCame here to say the same thing. Qt is a C++ library and is widely used (for example in KDE) and is also used in embedded environments a lot. And its pretty mature. reply zozbot234 14 hours agoparentprevGTK+ 3 and 4 are quite visually ugly, but you can get Windows classic-styled themes for both (from Chicago95 and B00merang project respectively) that will make them far more usable. reply criddell 13 hours agorootparentDo those themes mimic the Windows look or do they ask Win32 to draw butons, windows, menus, etc...? reply user3939382 16 hours agoprevJust to provide a diversity of opinion: I've heard basically nothing but positive feedback about Notepad++ over the years. However, I tried it out for about 10 seconds before closing it and never looked back. The, what I call \"millions of tiny buttons\" interface is ugly and distracting. I've never liked IDEs or other apps with this UI style. I use a JetBrains IDE now that has just as many features but the UI is not cluttered with millions of tiny buttons and tool ribbons. reply gamepsys 16 hours agoparentI greatly miss those tool bars. I think it's ironic that modern UI strives to be less cluttered than ever before while computer monitors are larger than ever before. * They encourage curiosity about previously undiscovered functionality. It improves feature discoverability. * It's way easier to find the correct tool bar icon than trying to hunt for a feature inside the menus. * If some toolbars are highlighted or disabled can tell you information about the state of the document you are editing. reply nine_k 16 hours agorootparentThere is no \"One size fits all\" UI, sadly. Absolute beginners should be shown a basic interface front and center, with a clear way to access more advanced features. More advanced users may benefit from a plethora of rich controls, all shown together. Experts may want to remove the visual clutter because they access features from keyboard without looking. Good software offers a way to achieve all of these, and often more customization. reply jvanderbot 15 hours agorootparentJust give me a view->toolbars-> checklist and I'll sort it out. FreeCAD does this well. reply giancarlostoro 16 hours agorootparentprevVisual Studio (not Code) lets you move it all around, remove pieces, and add things. It's one of the reasons I love Visual Studio. I otherwise use JetBrains for other languages, or when on other OS' it was a shame VS for Mac went away, but I assume adoption was not very high. reply jwells89 15 hours agorootparentprevI think an argument can be made for toolbars if they’re customizable with no holes barred on customizability (looking at you, Firefox, with your non-optional hamburger menu) and can be hidden entirely, should the user choose to do so. For me, toolbars as they were commonly implemented in Cocoa apps for the first half of OS X’s history are the model example here, which offer all the above. It’s when they’re not fully customizable and aren’t optional when they grate on me. reply funnybeam 15 hours agorootparentprev“less cluttered than ever before while computer monitors are larger than ever before.” Less cluttered but with more white space, especially in the vertical direction which is particularly cramped since the change in monitor aspect ratios so the toolbars have less functionality but take up more of the usable screen space. Progress is great… reply j_maffe 10 hours agorootparentYeah but vertical toolbars are a thing. I love the vertical tabs option in Edge. reply funnybeam 4 hours agorootparentTrue,me too. But now that copilot keeps popping up on the other side, that’s starting to feel cramped too. I used to put the task bar vertically down the side of the monitor as well for the same reason but Microsoft won’t let me do that anymore. reply darby_eight 16 hours agorootparentprev> It's way easier to find the correct tool bar icon than trying to hunt for a feature inside the menus. What? I am just completely confused by this—menu items are labeled in clear textual language, sorted roughly by functionality. icons greatly depend on cultural context. Looking at a screenshot of notepad++ I could would understand maybe a third of the icons and could guess at another third at best. That said, it's not that big of a deal—I'd probably just disable the toolbar rather than figure it out. I don't really use the mouse outside of selecting regions of text anyway. reply jwells89 15 hours agorootparentI find it depends on how many things are in the toolbar, and if the icons are actually icons or monochromatic glyphs. A toolbar that’s populated only with the most frequently used functions and employs full color, uniquely shaped icons can be visually grokked in an instant, whereas a densely packed toolbar full of glyphs is inscrutable at a glance. reply Dalewyn 15 hours agorootparentprevOnce you learn a toolbar, it just becomes visual and muscle memory. Not unlike using hotkeys to access something hidden under a couple layers of menus. reply darby_eight 15 hours agorootparentSure, but that's very different from \"feature discovery\". I totally get this with the floppy-disk icon (which is, ironically enough, now a terrible visual metaphor for persisting to local storage outside of cultural context), but I have no clue what \"up arrow on top of down arrow\" means, nor what the ¶ icon would do—start a new paragraph? Select the current paragraph? Open some kind of paragraph outline? Granted, I don't use windows so it's entirely possible I'm just showing my ass here. reply Dalewyn 15 hours agorootparentThe toolbar buttons all have hover text to ease the learning, ¶ is \"Show All Characters\" where \"characters\" mean stuff like Carriage Return and whitespace. Microsoft Word users are probably familiar with this meaning. I have no idea what \"up arrow on top of down arrow\" is though, because I don't have that button. reply codedokode 15 hours agorootparentprevThe problem with tool bars is that usually you cannot guess what 80% of the icons mean. reply jprd 15 hours agorootparentIf you hover over the icon, a tooltip pops up to help remind/train you on what the icons represent. reply soupbowl 15 hours agoparentprevTakes one second to disable all that. I've used notepad++ forever and not once have I used those buttons, indeed they are useless. Your opinion is valid but I never understand using a tool with options and acting like the defaults are the only option. reply lukan 14 hours agorootparentThat is true, but it takes more than 1 second to find out about it. reply j_maffe 10 hours agorootparentI think the users a software like NP++ is aimed for are willing to spend more than 1 second to find out about this option. It appears that you're not one of those users ¯\\_(ツ)_/¯ reply lukan 4 hours agorootparentYeah, and it also appears that the things how they appear to you, might be wrong. I know about that option as I use npp since well over a decade. But I can still say the general interface is bad and I only use npp via key shortcuts. And if there are other options that provide a clearer initial experience, I can see why newcomers choose those instead. reply CraigJPerry 16 hours agoparentprevThe new Jetbrains ui is hard to like. It’s form over function. The old ui (thankfully still available). Having to hover over a hamburger button just to cause it to draw the menu bar options then slide the mouse across to what you want is annoying. The new commit window alt+0 is better, the old modal always felt tacked on when everything else is a docked panel. reply potamic 9 minutes agorootparentThe old ui was much more compact (even compared to compact mode on new ui) and maximised real estate for code over ui elements, which is what you want from a coding editor. It's definitely form over function here and yet another regressive move in the steps Jetbrains seems to be taking of late. reply hyperman1 16 hours agorootparentprevI tried it. The first week I shared your opinion. But then something flipped. I configured and learned hotkeys to hide the file/services/... pane and ended up with something I can only describe as 'calm'. Only 1 or 2 panes of code visible, and all functions hidden but available. The main detractor is indeed the hamburger menu. Vscode had ctrl-p, emacs has alt-x, and both provide a way to search for some function to execude. I hope Jetbrains is hiding something similar in its innnards, but haven't found it yet. Ctrl ctrl isn't it, at least for me. I went all-in on Jetbrains Ultimate last year without regrets. The thing is great and powerfull, but it is hard to find what you need in there, and hard to find out what is the purpose of some functionality. I've actually lost usefull functionality: Something usefull but I don't remember the name and can't find it in the menus. I should spend some time spellunking in there. Even so, I hope they find something better than the hamburger or the zillion hotkeys. reply abhinavk 16 hours agorootparentJetbrains has Double Shift and Ctrl+Shift+A. reply hyperman1 13 hours agorootparentThanks, all of you. reply ydant 15 hours agorootparentprevI like the new UI as well. There's always a learning curve, but after using it for months I haven't found any reason to switch back. ctrl+ctrl is \"run anything\" (I tend to use ctrl+alt+r for the different but similar run menu instead). I think what you want is \"Actions\" - which is default to \"shift shift\" and then click on a tab, or (ctrl/cmd)+shift+a to jump directly to that tab. reply michaelcampbell 14 hours agorootparentprevInterestingly in the JetBrains emacs keybindings set, alt-x does exactly what you want. So, it's bindable, and you can use it in ANY keybinding, emacs or not. reply Tutitk 12 hours agorootparentprevCtrl-Shift-A, or something. There is a dialog with universal search for actions, files, classes.... reply indymike 16 hours agorootparentprev> The new Jetbrains ui is hard to like. It’s form over function. I'd like my JetBrains IDEs better with a 10x speedup. The new redesign isn't bad if you memorize keyboard shortcuts :-) reply bboygravity 16 hours agorootparent> The new redesign isn't bad if you memorize keyboard shortcuts :-) Contradictio in terminis reply j16sdiz 4 hours agorootparentprevYou can use the keyboard shortcut with old UI. I still like at the old UI. When you do overlapping windows, those non standard chrome are great distraction. reply nine_k 16 hours agorootparentprevWith time, you start using the menu very rarely, because keyboard shortcuts are so much faster. No menu bar means more screen space when working on a laptop. I usually switch off the menu bar in Emacs, and I don't even know if it can be turned on in Vim. reply CraigJPerry 2 hours agorootparentAhh I’d disagree with that, I’ve been solely IntelliJ since around 2011/2012[1] and all the alt+N tool windows, the ctrl+shift+a (besides being the original feature, it’s faster than shift+shift and I never have confusion about whether I’m looking for an action or a file or … that shift+shift view just never made sense to me). Basically all the core shortcuts are memory muscle at this point but the menu is useful for browsing lesser used features. Ctrl+shift+a is slow enough at redrawing that you don’t want to be using it to search / try to remember the name of a feature. [1] well except for a brief 2 year VSCode spell but i came back a year or so ago and have restored my all products subscription reply smusamashah 5 hours agorootparentprevFYI you can configure old UI to not show modal dialog for commit. Took me too long to learn this and this is how I use it now. I despise the new UI. Every tool don't have to become another popular tool (vscode). I find the new UI harder to use. I like all the buttons and menus etc visible right there without needing extra clicks. When working with colleagues I can see them struggling to find features that I have been using with old UI for my advantage because it's all out there in front of you and they don't even it's possible. reply SlackingOff123 15 hours agorootparentprevFYI, it's possible to make the menu bar always visible in settings. reply CraigJPerry 2 hours agorootparentAha, I’ve just turned this on, I’m going to give new ui a whirl again. reply mysterydip 16 hours agoparentprevWhat you find ugly and distracting I find essential to functioning in the app. I can't stand it when I'm trying to find some feature that was hidden so the UI would look cleaner. reply Grazester 16 hours agoparentprevI have used Notepad++ for more than 10 years and I don't think I have ever tried replacing my IDE with it. I don't think it should be use as an IDE replacement but a file editor. reply AdrianB1 12 hours agorootparentIt is the other way around: 10 yeas ago I was using Notepad++ for writing small apps and I replaced it with IDE (VS Code). It makes no sense to replace a decent IDE with Notepad++. reply porphyra 16 hours agoparentprevTiny buttons toolbars were the norm for decades in, say, Windows Explorer and Microsoft Word, before Microsoft transitioned to the \"Ribbon\" style in 2007. Personally I think that people who enjoy those buttons do so for nostalgia reasons, but they are not the worst to use once you remember where each tool is and what each tool's icon looks like. reply j1elo 16 hours agorootparent> Tiny buttons toolbars were the norm for decades (...) before Microsoft transitioned to the \"Ribbon\" style in 2007. The Ribbon still feels to me like that \"new thing\" Microsoft did since some version of Office... and you're telling me it was 2007?!! Oh my... A bit before that time I already moved to Open/LibreOffice, and never really used any Windows past 7, so I've missed a whole UI paradigm transition that now makes Windows feel like a complete stranger to me. reply StuffMaster 15 hours agorootparentPull-down menus are so obtrusive! You SHOULD prefer to hunt and hunt and hunt for the button you want. The future is now and it sucks. reply porphyra 15 hours agorootparentprevThere's now a whole generation of 20 year old programmers who have never used the toolbars of the 1990s and early 2000s. reply yndoendo 16 hours agoparentprevTo me it is a tool for select jobs. Mainly use it for parsing log files. Handles gigabyte files ease unlike Windows notepad. It also is great with regex searching to filter useful log content with cascading results. Temporary scratch pad, for constructing SQL statements, that retains unsaved files upon OS or user closing. Not my go-to for coding and project maintenance. Still a great tool. reply roland35 16 hours agorootparentNotepad++ is what I have for any random file format I need to right click and open quickly! reply delfinom 12 hours agorootparentprevThere's Emedit as a commercial notepad like tool. It's even better than notepad++ for large files because it'll stream in the data as you scroll rather than trying to load all of it at once. reply AdamH12113 16 hours agoparentprevMy advice is to just turn the toolbar off (Settings -> Preferences -> General -> Toolbar -> Hide). I find it easier to skim through menus. You can turn off almost all of the extra UI elements if you want, which makes the interface very clean. reply j1elo 16 hours agorootparentFunny that something as simple as hiding a toolbar requires diving through 5 steps. Doesn't it just offer that option upon right-click? It sounds natural and expected to me for a toolbar to do so. reply AdamH12113 15 hours agorootparentIt's really two or three steps -- select menu item, dialogue box page is already selected by default, click on checkbox. I was giving the full navigation. Personally, I find that making every part of the UI an active control makes it easy to do things by mistake, especially hiding elements, which often doesn't have an obvious way to reverse the process. For one-time UI setup, I don't mind going through a dialogue box. reply wolpoli 15 hours agorootparentprevI just tried it and was surprised that it doesn't offer Right-Click option to customize/turn off the toolbar. There was a period in Windows software when that level of customizability was expected. reply Topgamer7 16 hours agoparentprevnotepad++ was really great for simple syntax highlighting on windows, when good clients were either slow or costed money. It supported a lot of languages. reply nine_k 16 hours agorootparentAlso, the original Notepad++ is unabashedly native to Windows, with none of the limitations or expense of cross-platform toolkits like Qt. So it's lightweight and responsive even on lowest-specced boxes. reply circusfly 16 hours agorootparentI use Notepad++ on Linux, ran the installer, works, it auto updates just like it did on Windows, WINE enables it to run just fine. I use it every day for small files like my TODO, Notes and Scrap files. reply lukan 14 hours agorootparentBut that is a recent developement? Some years ago the experience under WINE with npp was not great. (might be also 10 years, since I tried it the last time) reply circusfly 6 hours agorootparentCould be, I can't remember when it didn't run well but WINE has improved greatly the past 5 years especially. reply HumblyTossed 15 hours agoparentprevI hate cluttered flat surfaces as much as the next guy, but I don't put my toaster away when I'm not using it. It's stays right on the counter because it's convenient for it to be there. reply user3939382 13 hours agorootparent> I don't put my toaster away when I'm not using it I actually do lol reply exodust 6 hours agorootparentAren't you just generating crumbs at two locations now? The kitchen bench and cupboard? Possibly the floor too due to moving the toaster? reply EMM_386 12 hours agoparentprev> The, what I call \"millions of tiny buttons\" interface is ugly and distracting. I agree. I used to use N++ when that sort of interface was common everywhere. It didn't look as out of place. These days I find it too jarring and either use Sublime Text 3 or just regular Windows Notepad for scratch notes (now that it doesn't prompt to save on close anymore). No buttons. reply codexb 13 hours agoparentprevNotepad++ originated at a time when there weren't many code editors for most of the new, growing languages (perl, python, js), or for editing xml and json, especially on windows. Many of the \"good\" code editors were expensive and enterprisey, or they were limited to linux, or they had an extremely steep learning curve (vim, emacs). Notepad++ worked on everything, was free, installed quickly, and it was fast. I've used it to replace hardcoded values in binary files before. I think most of the people who are praising it are remembering how valuable it was 20 years ago. I don't know anyone that still uses Notepad++. reply themadturk 10 hours agorootparentIt's been the \"standard\" editor at my place of employment, but no one objects to other editors or IDEs being used instead. Our workstations are all Windows, so it's a decent default to install for everyone. reply AdrianB1 12 hours agorootparentprevI have it on a few thousand servers in my department, mostly as a Notepad that can do more, like comment color or editing small config files of all sorts. It is far from the days I used to write entire small apps in Notepad ++, but we still use it and there is no plan to replace it unless they do something that puts us in danger (ex: stop fixing bugs/security issues). reply aveao 16 hours agoparentprevNpp is a code editor, and you're comparing it to an IDE. Apples and oranges. reply jraph 15 hours agorootparentBoth are fruits. The comparison applies here I think :-) reply jccalhoun 16 hours agoparentprevIt depends on what you use it for, I guess. I'm not a programmer so I use it as a replacement for windows notepad. I don't know what most of the buttons do and I just ignore them. reply publius_0xf3 15 hours agoparentprevAs a longtime Notepad++ user, I hate those buttons as well. Fortunately, the settings contain the option to hide the menu, the icons, the buttons on the tabs, the status bar, etc. resulting in a very minimalistic experience, which is how I use it. I recommend giving it another look. reply circusfly 16 hours agoparentprevRe-training propaganda: [only the JetBrains products should be used, repeat after me...]. reply Dalewyn 16 hours agoparentprev>The, what I call \"millions of tiny buttons\" interface is ugly and distracting. That's a feature. It's a GUI harkening back to Windows Explorer Classic, aka the interface style used from Windows 95 through Windows XP. reply simion314 16 hours agoparentprevMaybe you can customize it. I am not a user but you will avoid good programs because of this instant reaction. IMO, I would check if the toolbar and key shortcuts can be customized. reply SpartanJ 14 hours agoprevShameless plug: I'm working on a multi-platform code editor similar to NP++ and some new editors like Zed called ecode, that tries to be a fresh take on code editors using some modern tools and technologies like LSPs. I started working on it after using Geany for many years but finding Geany lacking some essential features for my needs. ecode is developed with speed in mind and has a very fast startup time. [1] https://github.com/SpartanJ/ecode/ reply hoyd 13 hours agoparentNice work. Does it have auto-save, like npp? reply SpartanJ 12 hours agorootparentThanks! Currently it does not but it's not something particularly complex to implement so I can add it if there's interest! I haven't used NP++ in some time so I don't remember exactly how it behaves but I'll take a look. reply mdekkers 5 hours agorootparentAutosave is table stakes for good editors reply rubymamis 14 hours agoprevDamn this app is so fast. It handles 24x War and Peace without sweating a bit. Much faster than Sublime as well. The only thing with equivalent performance (on macOS) is BBEdit. Does anyone know how they are able to load such large files so fast? I guess they lazy load from disk as well? I'm writing a block editor in Qt C++ (Npp is also written in Qt) and QML[1], so I'm very curious. I load the entire text and then render it using a virtualized list (ListView). My app is currently the fastest block editor that I've tested. But I always want to take it up a notch and even compete in performance with Sublime and BBEdit, and now NotepadNext. [1] https://www.get-plume.com/ EDIT: It's REALLY fast and very efficient (consumes low amount of memory). Seems to be faster than BBEdit (unscientific). If anyone has a clue about the architecture or can share a link, it will be appreciated. reply extragood 13 hours agoparentThanks for the comparison to Sublime. That's been my preferred editor for a decade, but massive files have always been a pain point. reply binary132 13 hours agoparentprevmmap? reply gen3 16 hours agoprevAwesome. When I moved to linux a few years ago notepad++ was one of the harder apps to find a replacement for. I ended up sticking with Kate Edit: Kate is great, give it a shot! reply techmindmaster 16 hours agoparentThere is https://www.geany.org reply mxuribe 14 hours agorootparentLike @fngjdflmdflg noted, years ago when i moved to linux (for personal use), I also had trouble finding a decent/similar replacement to Notepad++. I started down the Geany route, and liked it alot. It is cross-platform, not slow, has lots of themes, customization options, etc. But eventually I stopped using it, and landed on Kate. For the life of me can't recall why i moved away from Geany? I have been a user of KDE Plasma for many years, but that's not the reason why i moved to Kate, because i actually was still a user of Geany for quite a while during my use of KDE Plasma. In any case, Geany is a really solid option. Not sure that Geany is a feature-for-feature, perfect alternative for Notepad++ (but neither is my favorite Kate editor either!)...nevertheless, the rare times when people ask me for recommendation of text editors on linux (or cross-platform with the intent of using the same editor on all their OSes), I often stick to suggesting Geany or Kate. And, then of course, if they're exclusively Windows users i then suggest either Notepad++ or Geany Kate - not necessarily in any order. (For the Windows machines that my dayjobs issue me, I still use Notepad++ since funny enough that is easier to allow then requesting to install Kate! Corporate world be getting all strict on software installations nowadays - yikes!) reply nsteel 16 hours agorootparentprevExactly this. It's already cross platform (windows and Linux, at least), extendable, looks very similar and has many of the same features. I'm not sure what killer feature is missing that would make someone reimplement the whole thing. The readme weirdly doesn't mention it. reply AlienRobot 14 hours agorootparentprevYeah, but Notepad++ is a Windows app, that is a GTK app. As someone coming from Windows, it's crazy how bad GTK apps look for desktop. Crazy. Like I can't comprehend how did it get to this point. Just compare the screenshots https://www.geany.org/media/uploads/screenshots/geany_light_... https://notepad.plus/wp-content/uploads/2023/03/screen.gif Notepad has 16 toolbar buttons in the same amount of width that GTK can only fit 10 toolbar buttons. The height of the tabs and status bars are also MUCH shorter. It's completely ridiculous and makes every GTK app look bad to me. Not just Geany, but Xed, Pluma, Gedit, the image viewers, the file managers, the system settings dialogs, etc. I have a mouse. I can point at things. I'm not using my thumbs or toes to operate a desktop app. Qt's licensing sounded a bit weird. At first I thought your app HAD to be open source to use it. But once it was clear to me that you can sell apps made with Qt so long as you dynamically link without having to pay royalties or anything, the choice was clear. If I have to program an app for Linux, I'm using Qt. And so far the only problem I found in Qt is that it uses the system's \"native\" GUI by default (i.e. it uses Gtk on Linux). This means that the Ok-Cancel buttons are Cancel-Ok instead of the correct order. Who puts Ok buttons at the right side? Now if I want to quickly close something, I'm clicking at the corner of the window which is the easiest point to click at, and on the top right I have close (which cancels) and at the bottom right I don't have cancel but Ok which COMMITS which is the opposite of what a thoughtless rash speedy click is supposed to do. Ok should be at the left so you can't commit things by accident. The only reason to put it on the right is if you're designing for tablets so the ok button is closer for right-handed users. This isn't how a decision for a desktop-oriented design. reply Aachen 9 hours agoparentprevhttps://kate-editor.org Link for the lazy Looks like an IDE more than a notepad, with the side bar browser, but then I suppose it's a small step up from NP++ (with syntax highlighting and ftp^W git support already built in) to a fully fledged programming environment. Spotted the all-important keyword \"vi bindings\" also. I should give this a try! Bit sad it won't work on remote systems (without inefficient X forwarding at least), but I've been looking to try out a new editor and e.g. not having to deal with things like O timeout (apparently that looks indistinguishable from the start of an escape sequence and so the command line has to wait to see if the rest of the sequence follows) has advantages as well reply snvzz 4 hours agorootparent>Looks like an IDE more than a notepad. AIUI There's the editor embed-able component, kedit. A basic editor based on it, kwrite. Then the more fancy editor program, kate. And the IDE, kdevelop. reply ramon156 16 hours agoparentprevI never needed a replacement but I tried Kate for quick edits and honestly it's a very lovely implementation reply ww520 16 hours agoparentprevI have run Notepad++ with Wine on Linux before and it works well. Kate is awesome. It’s cross platform as well. reply circusfly 16 hours agorootparentI use Notepad++ every day, that WINE runs it is implicit, it's like running any other app. I love KDE but I'm not a fan of the Kate editor. Notepad++ even automatically checks for updates like it did on Windows, downloads it, installs it, etc. Works exactly the same. It's great. reply garyiskidding 4 hours agoparentprevAhh. thanks. Was looking for comparisons for a quick note program on this thread. reply sixthDot 16 hours agoparentprevHave you ever heard of https://cudatext.github.io/. It's certainly faster than Kate. reply jraph 15 hours agorootparentFaster than Kate is a feat. Speed is one aspect, I have been using Kate for more than 10 years. What, in your opinion, should make me check out this editor? reply tvshtr 7 hours agorootparentprevit's much uglier though reply wildzzz 16 hours agoparentprevI used Sublime as my npp replacement on Linux. It's a little more coding focused so it lacks some of the nice editing features but was good enough. Luckily npp is pre installed on my work PC so I don't use anything else now. reply Piraty 16 hours agoparentprevthere is https://notepadqq.com reply summermusic 16 hours agorootparentSadly this project is not actively maintained anymore reply nurettin 16 hours agoparentprevThere is vs code if you like browsers. reply rembicilious 15 hours agoprevNpp (Notepad++) is my go to text editor for windows. It has been actively maintained for 20 years. It’s lightweight with a super responsive UI. I love the text search/replace interface. I keep a copy of the portable version on my keychain thumb drive because I never know when a friend or family member will have me muck around with their pc. Npp Version 7 runs splendidly on wine. I prefer it over the linux desktop text editors like Kate (which is a great editor in its own right). I don’t think NotepadNext appimage or flatpak will be able to match Npp in regards to memory footprint and ui responsiveness. But, I am excited to use it and it may find it’s way onto my thumbdrive because it runs natively on Linux so it doesn’t depend on wine. reply butz 15 hours agoparentI was not expecting much, but AppImage startup time and responsiveness looks promising. Memory usage in GNOME System Monitor looks decent (AppRun.wrapped - 13.9MB, NotepadNext - 876.5 kB). Typing feels much faster than Linux version of VSCode, maybe even reaching levels of SublimeText? Need to test with much bigger documents with complicated syntax highlighting to make sure. Overall, the major Notepad++ selling point - autosave on exit - is not implemented here, so until then I'll be going back to Geany, but will keep my eye on this. And forgot to mention that it decently integrates into GNOME desktop as well, no issues with decorations and missing app in Alt+Tab list. reply jtriangle 15 hours agoparentprevNotepadqq on linux is basically 1:1 with notepad++ reply gverrilla 12 hours agorootparentI'm not a specialist, but having used both I can say Nqq presents a lot of bugs Npp doesn't. reply StuffMaster 15 hours agoparentprevI also love Notepad2. Both are awesome. reply g8oz 11 hours agorootparentI thought the project was dead reply FreeWorld 11 hours agorootparentI believe it's been replaced by notepad3. reply aftbit 12 hours agoprevCool! Notepad++ was one of the apps that I missed the most when I switched to Linux. Besides games, it was the number one reason that I kept rebooting into another OS. After a while, I learned emacs, then vim, and the rest is history. Today, I would probably have switched to Codium. As long as we agree not to use Sublime Text anymore. reply fsloth 12 hours agoparentI transitioned recently to Mac on new job and I was surprised to find the most painful thing was not havig Notepad++ and was super amazed I did not find comparable software on Mac. reply eyegor 7 hours agorootparentSublime is a massive improvement in my opinion, and cross platform. It's not free** but you can use a personal license at work and on multiple machines. It's one of the few text editors with a plug-in system that can reliably open 100mb+ files and auto reload on file updates (without crashing constantly). https://www.sublimetext.com/ ** it's sort of free, the trial period is unlimited. It just gives \"activate me\" popups every dozen file saves or something. reply clnhlzmn 8 hours agorootparentprevTextAdept is a cross platform, minimal, fast, and extensible text editor that might be a good candidate. reply Aachen 9 hours agoparentprev> then vim, and the rest is history. Heh, I'm glad you found the light in the end =) I remember that I first tried out Vim during an internship with a boss that was less than receptive to me trying out things I heard about online, like the way he pronounced \"wtf is dug..dug..go?\" when I did a search query, or the weird look gvim got... I guess I was a bit more prepared for the Linux life by having seen Vim before, but still it was surprising nobody built NP++ for Linux and that there was nothing better than Geany available in terms of NP++-likenesses. It seemed so simple, how can it not exist? Apparently the simplicity is deceptive reply mixmastamyk 7 hours agoparentprevGeany is almost twenty years old. reply paulnpace 11 hours agoparentprevNotepad++ works well for me in wine. reply notRobot 11 hours agorootparentI couldn't get it to work perfectly, it had text and UI rendering bugs that made it unusable. Geany works well as an alternative for me on GNU/Linux. reply constantcrying 16 hours agoprevA colleague of mine, who certainly was an extremely experienced and knowledgeable programmer, used Notepad++ for everything. Certainly was interesting to see how good you can be even with relatively simple tools. reply AdrianB1 12 hours agoparentI did the same 10 years ago, but now VS Code is a much more productive tool for me; for example, extensions, Git integration and markdown preview. reply goblin89 2 hours agoprevIf someone is looking for a Notepad++ equivalent on macOS, I can wholeheartedly recommend CotEditor. Native, too. reply bregma 16 hours agoprevWhy would I choose notepad++ over something like vim or emacs? Is there a compelling differentiator? reply tredre3 16 hours agoparentThe compelling differentiator is that all the features are easily discoverable, you don't need to read a manual before you know how to save/quit/search/replace/use tabs/undo/redo/macros/etc. reply aveao 16 hours agoparentprevIs there a point in comparing CLI-based, primarily-*nix-userbase editors with a GUI-based primarily-windows-userbase editor? reply bongodongobob 15 hours agorootparentOf course, to signal your leetness. reply chanux 7 hours agoparentprevHere's why I like it: For a considerable time in my professional life I was forced to use Windows. I would still have access to Linux VMs, in which I spent most of my time, using vim as the editor but whenever I wanted to take quick notes, sanitize text, stash away some info I need in work etc., I'd just use the notepad on Windows. Then I found Notepad++. The UX is just so great (though I never figured out how to delete all the line ending spaces and it's sometimes nagging me). So I love both Vim and Notepad++, different use cases. Different reasons. reply orthoxerox 16 hours agoparentprevStandard Windows hotkeys, fast, buttons. reply ivanjermakov 16 hours agoparentprevNotepad++ is literally a better version of notepad.exe. I would not consider using it for anything serious though. reply sgc 15 hours agorootparentIt depends what your \"serious\" work is. I have used it to edit well over 300 million words of text, reformatting scripts to add tagging etc, large scripts of complex regex to data clean (although nothing I know of beats TextCrawler for that task), even writing code in several languages - though of course a proper ide is more useful for many coding tasks. VS Code for example absolutely chokes on large files. Sublime does an ok job - but not one I can rely on for larger batch jobs. NPP excels, and I can quickly do thousands of changes on thousands of large files quickly. NPP also has many plugins (like Sublime etc), and its utility depends on them as much as the other text editors do. reply Brian_K_White 14 hours agoparentprevI use vim and geany and code::blocks and np++ for different things at different times. geany, codeblocks, and np++ are all scintilla, so what I am really saying is I use both \"something like vim or emacs\" AND scintilla, and there is no dichotomy. And what is \"something like vim or emacs\"? The two are nothing like each other. Anyone who used either vim or emacs already knows why they do so, and already knows that none of the reasons anyone will say they like any normal editor will apply. Everything anyone says will either be something vim or emacs already has their own answer for, or will be things they actively don't want. Question seems somewhere between disingenuous to inexplicable. I would say rather than an actual request for information, it was just to say \"I like vim or emacs\", except \"I like vim or emacs\" makes no sense because they are not substitutions for each other. reply bregma 14 hours agorootparentUnless you're looking for a compelling reason to switch. For example, I use VS Code sometimes because of its markdown preview pane. That's not available in emacs or vim (to my knowledge). reply nurettin 16 hours agoparentprevDoes emacs work as well as notepad++ on windows? reply rbancroft 16 hours agorootparentemacs works great on windows. I'm not sure if there are things notepad++ does that emacs can't but I've never had any windows-specific issues with emacs. reply michaelcampbell 14 hours agoparentprevNot really, if you already know vim or emacs well enough. You don't need to worry about modes or plugins for language syntax highlighting for most file types as it's built in. reply mardifoufs 15 hours agoparentprevFrom what I've seen it's mostly baby duck syndrome and that's totally ok. I am also fully \"baby ducked\" into vscode, so I get it reply kstrauser 14 hours agorootparent> baby duck syndrome Today I learned something new. reply shnkr 16 hours agoprevhonest question - why was there a need to start a new repo? Would you be ok to merge yours with notepad++'s official repo[0] (both are in c++). Did this cross your mind before and what happened? Not saying that they would allow but it'd help the community as a whole with less duplication of work and deliver more features. https://github.com/notepad-plus-plus/notepad-plus-plus reply tredre3 16 hours agoparentI can't answer for the author, but keep in mind that Notepad++ is good because it uses the win32 API directly. I don't see any future where they'd just accept to replace everything with Qt. reply circusfly 16 hours agorootparentThere's no need to. It installs, updates and runs exactly as it did on Windows, I use it every day. reply nicolas_17 16 hours agoparentprevIt's a complete re-implementation from scratch, they don't share code, using the same programming language is not particularly relevant. reply Aachen 9 hours agoparentprevWas wondering the same. Of course a lot of code is going to need to be new, moving away from Windows-specific APIs, but that's only a lower layer (or so it seems to me). Everything from the versatile search and replace (e.g. regex engine), the macros system, the syntax highlighting, the session management... all that code needn't have been rewritten, people clearly like it working the way it is reply pyrophane 15 hours agoprevI love that this is a made with C++/Qt and isn't an electron app. reply fuzztester 7 hours agoprevI used to use Metapad at times, apart from (mainly) gVim, on Windows. https://liquidninja.com/metapad/ Development on it has stopped, IIRC, but it is still available for download. I had used many other text editors earlier, such as TextPad, NPP, SciTE, PFE,etc., over the years . reply tombert 15 hours agoprevNotepad++, as the name suggests for me, was actually the next editor I learned how to use after Windows Notepad. I saw all this pretty syntax highlighting, and the ability to use tabs, and I decided to use it. I got pretty good with it, even making custom macros and the like, and as I was learning C and C++ on Windows it was still the text editor I used. The reason I stopped using it really did just come down to the fact that it didn't work on Linux. I had already been dual-booting Windows by 2011, and when Windows 8 got announced I utterly hated it so much that I decided to just do Linux full-time. While I was aware that Notepad++ worked on Wine, I didn't really want to muck with anything emulator or emulator-adjacent, so I just picked up Emacs and Vim (went back and forth for multiple years until finally settling on Vim). I will need to look at NotepadNext. NeoVim is great, but sometimes I want a simple, non-IDE, GUI text editor as a place to just dump notes down. reply gradstudent 10 hours agoparentI do all my simple note-taking with vim. Curious why it does not the fit the criteria for you? reply tombert 9 hours agorootparentFor reasons I don't really understand, I've never liked any of the GUI versions of Vim. I use Vim for coding and even writing Markdown docs, the thing I like using GUI text editors for a place to dump copy/paste stuff, writing down phone numbers real quick, quick stuff I can click and copy-paste from. The console version of Vim is fine, but getting stuff to and from the system copy buffer is a bit cumbersome. reply jhwhite 16 hours agoprevNotepad++ has a place in my heart. When I was learning HTML back in the late 90s early 00s I was using MS Frontpage or Adobe Dreamweaver GUI. I read that those would spit out sub-optimal HTML and you should use a text editor. So I downloaded Notepad++ and I learned real HTML using it. reply KingOfCoders 3 hours agoprevNotepad++ has the best feature ever: Autosave without a filename. Just close and open and everything is the way you've left it. reply aAaaArrRgH 3 hours agoparentVSCode and Sublime Text do that too. And recently Microsoft even added it to Notepad. reply dang 14 hours agoprevRelated: NotepadNext: A cross-platform reimplementation of Notepad++ - https://news.ycombinator.com/item?id=30959025 - April 2022 (273 comments) reply knighthack 15 hours agoprevWhile I love the plethora of text editors, I'm sticking to Sublime Text for pure text editing work, and Vim / Vim-mode with Jetbrains' IDE for code-related work. Power and love be to all the alternative text editors out there though. reply thehias 16 hours agoprevNotepad++ for Linux & MacOS?? Very awesome!! :) reply account-5 16 hours agoprevI hope this is better than other offerings on Linux. I've tried a few and none of them come close. Fingers crossed. I hope this will be compatible with np++ plugins which makes np++ even better. reply RunSet 12 hours agoparent:*( > Plugin compatibility between NN and N++ is not possible. https://github.com/dail8859/NotepadNext/issues/422 Shame, since N++'s plugin ecosystem holds quite the treasure trove of functionality. https://github.com/notepad-plus-plus/nppPluginList/blob/mast... reply account-5 10 hours agorootparentThat is a shame. I use a small set daily. reply account-5 12 hours agoparentprevCertainly the windows release fails on my laptop. reply NetOpWibby 16 hours agoprevMan, what a throwback. I absolutely LOVED Notepad++. Then I transitioned to macOS and Brackets, then Atom, then Sublime Text. Thanks for the trip down Memory Lane. reply osigurdson 11 hours agoprevDo they mention why they are re-writing it? It seems neither bad nor very popular. reply snvzz 4 hours agoparentnotepad++ is windows-only. reply israrkhan 15 hours agoprevI am primarily a nevim users. Occasionally I use vs code and dislike it for its slowness. Recently discovered `Zed`[1] on Mac. it is quite fast and really good GUI editor (vs code replacement in some ways). I think NotePadNext will still remain primarily a choice for windows users. [1] https://zed.dev/ reply bluenose69 15 hours agoprevFor the macOS version, the docs suggest turning off font smoothing. This might not be something users want to do. reply g8oz 11 hours agoprevDoes this reimplementation allow for defining projects consisting of files from all over the file system? Rather than just all the files in a directory? That is a killer feature of Notepad++ for me. reply throwaway918274 13 hours agoprevI worked with a guy who used Ubuntu and his main editor was Notepad++ running in Wine. reply binary132 13 hours agoprevI think I missed what was wrong with npp that needed superseding. Is it just that it’s not portable? Perhaps a portability layer could be contributed? reply SuperNinKenDo 13 hours agoparentBased off looks and speed, I've always assumed Npp was pure win32. So the only portability layer is Wine. That said, from memory, it actually works well in Wine, but plugins can be iffy. reply yuz 12 hours agoprevFinally! Every you are so I go online and look up if someone did it, and finally I won't have use vscode reply mixmastamyk 7 hours agoparentGeany is mature. reply slig 16 hours agoprevI really loved TextMate for quick, simple and ultra-fast note taking / quick pasting stuff on macOS. Is there anything like that for Windows (except Notepad++)? reply ahdsr 16 hours agoparentNotepadNext reply slig 16 hours agorootparentWill try, thanks! reply ed_elliott_asc 16 hours agoprevI used to love notepad++’s macros but that is pretty much been replaced with vscode multi caret and copilot. I’d still use it for more complicated things but very rarely.. reply throwaway290 2 hours agoprevAnyone knows who is the author? reply rodneyzeng 10 hours agoprevNo, many features are not implemented yet. I cannot use it now. reply mig39 16 hours agoprevIs there a homebrew package for macOS ? reply Tagbert 14 hours agoparentIt looks like they are supplying a DMG so you would just drag the executable to Applications reply indigodaddy 15 hours agoparentpreva brew search for notepad only returns \"notedup\" so I don't think so currently reply indigodaddy 15 hours agoprevI like this a LOT. Any plugins eg diff type things or vim mode etc on the roadmap? reply rightbyte 13 hours agoprevNice I'll try it. About the only app I miss on Linux is Notepad++. reply Sweepi 16 hours agoprevsometimes I am still sad that I switched to VS Code 6 years ago. The multi-language-spell check feature (plugin) is still better implemented than in any other editor or smartphone I have seen. Same for multi-line editing (native to npp). reply RDaneel0livaw 16 hours agoprevHOLY CRAP!!! This is wonderful news. This is probably my most missed app on Linux/Macos. Installing immediately! edit: flatpak support is just chefs kiss. reply VHRanger 16 hours agoparentWhy do you prefer it to sublime text in particular? I also like Micro a lot - it uses the command line as a GUI reply margalabargala 16 hours agorootparentSublime is not FOSS, for one. I use Geany on Linux, it is the closest replacement I have found. Until now. reply RDaneel0livaw 16 hours agorootparentprevSublime text for me takes too long to load. It's also too heavy for what my use case is. I just want a simple text editor, not an entire development app. reply wewtyflakes 15 hours agorootparentI've always known Sublime text to load and run instantaneously unless working with enormous files that do not have newline characters. reply wildzzz 16 hours agorootparentprevNpp is great for editing text, no matter what kind of text file it is. It has a bunch of crazy plugins that are just mean for editing and converting text in files. For example, you can edit a column of text (rather than just a row). It's great for working on log files or anything computer generated that needs reformatting. Works ok as a code editor too but it's not an IDE (although it does come in handy when an IDE is not available). It's just another tool to have in your quiver. reply 15 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Notepad Next is a cross-platform version of Notepad++ but has bugs and incomplete features, making it not ideal for critical tasks.",
      "Available for Windows, Linux, and macOS, it offers installation packages, with macOS users having the option to disable font smoothing for a Windows-like look.",
      "Developed using Visual Studio 2022 and Qt v6.2+ on Windows, the code is under the GNU General Public License version 3."
    ],
    "commentSummary": [
      "Users are discussing popular text editors like Notepad++ and alternatives such as Emacs, Sublime Text, and VS Code, sharing preferences, experiences, and opinions on features, performance, and usability.",
      "NotepadNext is highlighted as a cross-platform option, featuring multi-cursor editing, auto-save, GUI customization, and toolbar preferences, sparking discussions on its implementation.",
      "The conversation covers comparisons with other text editors, task-specific recommendations, and upcoming code editor releases, indicating users' diverse preferences based on needs and operating systems."
    ],
    "points": 432,
    "commentCount": 266,
    "retryCount": 0,
    "time": 1711644659
  },
  {
    "id": 39858850,
    "title": "Meta Ends Streaming to Please Netflix: Courts Reveal User DM Access",
    "originLink": "https://arstechnica.com/gadgets/2024/03/netflix-ad-spend-led-to-facebook-dm-access-end-of-facebook-streaming-biz-lawsuit/",
    "originBody": "What happened to Facebook Watch? — Facebook let Netflix see user DMs, quit streaming to keep Netflix happy: Lawsuit Facebook Watch, Netflix were allegedly bigger competitors than they let on. Scharon Harding - 3/28/2024, 8:40 PM Enlarge / A promotional image for Sorry for Your Loss, which was a Facebook Watch original scripted series. Facebook reader comments 65 Last April, Meta revealed that it would no longer support original shows, like Jada Pinkett Smith's Red Table Talk talk show, on Facebook Watch. Meta's streaming business that was once viewed as competition for the likes of YouTube and Netflix is effectively dead now; Facebook doesn't produce original series, and Facebook Watch is no longer available as a video-streaming app. The streaming business' demise has seemed related to cost cuts at Meta that have also included layoffs. However, recently unsealed court documents in an antitrust suit against Meta [PDF] claim that Meta has squashed its streaming dreams in order to appease one of its biggest ad customers: Netflix. Facebook allegedly gave Netflix creepy privileges As spotted via Gizmodo, a letter was filed on April 14 in relation to a class-action antitrust suit that was filed by Meta customers, accusing Meta of anti-competitive practices that harm social media competition and consumers. The letter, made public Saturday, asks a court to have Reed Hastings, Netflix's founder and former CEO, respond to a subpoena for documents that plaintiffs claim are relevant to the case. The original complaint filed in December 2020 [PDF] doesn’t mention Netflix beyond stating that Facebook “secretly signed Whitelist and Data sharing agreements” with Netflix, along with “dozens” of other third-party app developers. The case is still ongoing. Advertisement The letter alleges that Netflix's relationship with Facebook was remarkably strong due to the former's ad spend with the latter and that Hastings directed \"negotiations to end competition in streaming video\" from Facebook. One of the first questions that may come to mind is why a company like Facebook would allow Netflix to influence such a major business decision. The litigation claims the companies formed a lucrative business relationship that included Facebook allegedly giving Netflix access to Facebook users' private messages: By 2013, Netflix had begun entering into a series of “Facebook Extended API” agreements, including a so-called “Inbox API” agreement that allowed Netflix programmatic access to Facebook’s users' private message inboxes, in exchange for which Netflix would “provide to FB a written report every two weeks that shows daily counts of recommendation sends and recipient clicks by interface, initiation surface, and/or implementation variant (e.g., Facebook vs. non-Facebook recommendation recipients). ... In August 2013, Facebook provided Netflix with access to its so-called “Titan API,” a private API that allowed a whitelisted partner to access, among other things, Facebook users' “messaging app and non-app friends.\" Meta said it rolled out end-to-end encryption \"for all personal chats and calls on Messenger and Facebook\" in December. And in 2018, Facebook told Vox that it doesn't use private messages for ad targeting. But a few months later, The New York Times, citing \"hundreds of pages of Facebook documents,\" reported that Facebook \"gave Netflix and Spotify the ability to read Facebook users’ private messages.\" Meta didn't respond to Ars Technica's request for comment. The company told Gizmodo that it has standard agreements with Netflix currently but didn't answer the publication's specific questions. Page: 1 2 Next → reader comments 65 Scharon Harding Scharon is Ars Technica’s Senior Product Reviewer writing news, reviews, and analysis on consumer technology, including laptops, mechanical keyboards, and monitors. She’s based in Brooklyn. Advertisement Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 Steve Burke of GamersNexus Reacts To Their Top 1000 Comments On YouTube Scott Manley Reacts To His Top 1000 YouTube Comments LGR's Clint Basinger Reacts To His Top 1000 YouTube Comments How Forza's Racing AI Uses Neural Networks To Evolve The F-35's next tech upgrade Fighter Pilot Breaks Down Every Button in an F-15 Cockpit Linus \"Tech Tips\" Sebastian Reacts to His Top 1000 YouTube Comments Customizing Mini 4WD Racers For High Speeds On A Small Scale MegaBots: Born to Smash Anything in Their Path First Look: Xbox Adaptive Controller Quantum Computing Expert Explains One Concept in 5 Levels of Difficulty Kids versus 80s tech: Game Boy, Vectrex and a stereo system Expert Explains One Concept in 5 Levels of Difficulty - Blockchain Best wearable tech of 2017 The Moov HR Sweat - heart rate monitor in a headbandArs Technica More videos ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39858850",
    "commentBody": "Facebook let Netflix see user DMs, quit streaming to keep Netflix happy (arstechnica.com)398 points by edsimpson 10 hours agohidepastfavorite157 comments tsunamihippo 9 hours agoThe article skips a lot of context to make it sound significantly worse than reality. Facebook didn't just randomly give Netflix access to everyone's messages. Specific user would need to purposefully log in to the Netflix app with their Facebook account in order to grant Netflix access to the chat functionality (intended to send movie recommendations to Facebook friends inside the Netflix app). https://about.fb.com/news/2018/12/facebooks-messaging-partne... Disclaimer: I work at Facebook but not on messaging or anything related to this article. reply aihkas 1 minute agoparentYou're a Facebook criminal, no one will take you seriously, so please shut up. You have to be a sociopath to work for such a criminal gang aka Meta. reply lupire 8 hours agoparentprevAnd if a user consented to Netflix-based chat, Facebook overshared all chat data, instead of only the Netflix chat data, because they couldn't be bothered to build a properly isolated API? That's like asking permission to read and write your entire phone, just to provide the ability to write and read back a file. reply rezonant 6 hours agorootparentThis isn't how permissions work in most OAuth APIs. When you request permissions on apps like this, you request an \"action\" on a \"subject\". The \"action\" can be read/write/delete, the subject can be \"DMs\". How does Facebook determine whether a specific DM is a Netflix DM? In the database it's just a message from one user to another, with a certain text content. By the way I'm not suggesting that it cant work this way, just that it doesn't. Facebook could have added a specific scope to allow an app to only read back messages related to itself. But that would have required anticipating the use case before these companies implemented it, or at least having better review policies to try to reduce the permissions apps are asking for. But if the app wants to allow the user to have a back and forth with the other user, then that implies that Facebook Chat needs to have the ability to have app-specific conversation threads. It doesn't have that, though. Netflix and Spotify requested read permission for DMs. Did they need it? Most assuredly they did not. But requesting read permissions for DMs in general has valid use cases, even if it should be treated sensitively by Facebook's authentication flow. If there's any problem here, its that Facebook didn't seem to recognize that the apps (Netflix and Spotify) should not have been requesting read privileges at all, and should have revoked their ability to request that permission in a timely manner. reply slowmovintarget 6 hours agorootparentThis is why OAuth is insufficient for privilege management, especially for multi-tenant systems, or what should be segregated data sets. You want to grant access to dataset abc123, but not dataset abc124 belonging to the same user. This leads to an explosion of scopes, or an explosion of API keys, unless you have a policy engine, or resource-based access control. A company as big as Meta should be able to (is able to) do better than they did, but they probably didn't think this was worth prioritizing because money lie in attention farming, not in mending the fences. reply rezonant 5 hours agorootparentIt's not just RBAC, the actual feature needs to be designed with this sort of use in mind. When it is, OAuth is perfectly capable of handling it. The ideal way to implement something like this is to expose the message in the Facebook Chat app as a \"Netflix Chat\", separate from your normal one on one conversation with a user. Then, any message in the Netflix chat is shared with Netflix so they can render it in their UI, but nothing else. Put a message under the Netflix logo in Facebook Chat that says \"Netflix will be able to read messages in this chat\" The OAuth consent screen details for an app (\"Netflix\" and the Netflix logo, etc) could be used to present this to the user. However this presupposes that this was ever a good idea. On desktop you have a Facebook tab you can chat from, and on mobile, you want to chat on the Facebook (or whatever) app so you have all of its normal features, instead of a gimped version stuck inside a third party app. The third party app only needs to be able to ask the user if its OK to send a message with specific content, and possibly be able to enumerate who it might send to, but even that we've weeded out into the OS' own Share dialog nowadays. reply abalone 32 minutes agorootparentprevOAuth 2.0 is perfectly fine for privilege management. The problem is they granted read access when all Netflix needed here was write access. An analogy would be granting full access to a Gmail inbox in order to merely send an email. It would not require “scope explosion” to isolate the email sending permission. That’s just one OAuth scope. They just didn’t isolate it. The more interesting question here is how this interacts with supposed end-to-end encryption. Clearly the messages Netflix sends cannot be E2EE (right?). The whole point of E2EE is the service provider doesn’t have your keys. If Facebook is letting 3P send messages on your behalf, they must be unencrypted. Normally, ideally, in an E2EE system this should set off alarm bells. If you get a message from someone that’s not actually signed/encrypted by them, this should be very clearly alerted. Otherwise it’s a privacy attack vector. You could be downgraded to an unencrypted channel without your awareness. So, what’s the Facebook messenger user experience here? reply michaelt 22 minutes agorootparent> The problem is they granted read access when all Netflix needed here was write access. At that point, why not just have an URL that opens facebook with a message pre-populated and skip all the oauth? reply sebasvisser 1 hour agorootparentprevSo when it comes to adding value for advertising fb is able to separate every object and data piece into sickening degrees of detail… but when it’s about privacy and authentication it’s “not the way things are done around here”… As you’ve mentioned as well it’s a choice by fb. Just as we have a choice to call fb out on making immoral choices. Better yet, the developer(s) that coded this part, and the developers that make a daily choice to maintain it in its current form. And yes, it’s a choice. Just because people don’t take responsibility to make a deliberate choice, doesn’t mean it’s not a choice. reply krisoft 39 minutes agorootparentprevI don’t know. If there is a “Facebook Messenger” feature on some Netflix interface then I would be surprised if it only worked with some chats and not others. (That being said I have no clue why there would be such a thing, and why a user would prefer it? Maybe if Netflix were making set-top boxes) reply toofy 8 hours agorootparentprevi’d question the “…couldn’t be bothered to build…” i’d be more likely to believe they knew exactly what they were sharing and wanted it that way. reply Euphorbium 4 hours agorootparentprevThat is how permissions work on android. I hate it. reply amelius 44 minutes agorootparentThat's why I moved to GrapheneOS. reply vlan0 7 hours agorootparentprevWhat incentive does FB have to limit that access? Feels like MBAs would just see that as a cost/burden? We know FB does give a fuck about privacy, so that’s never gonna be a reason. reply yen223 4 hours agorootparentIf you believe FB is in the business of selling user data, then giving out user data for free is not an optimal move. reply captn3m0 7 hours agorootparentprevCourts across the world fining them. reply pooper 6 hours agorootparentThe fines have to be more than 100% of global annual revenue if they are going to matter. The other option is long prison sentences for the board and CEO. reply exe34 2 hours agorootparentWe often act as if corporations are unalignable super intelligences, but you're right, if there are consequences for the board/executive/shareholders, they would start caring. reply Wowfunhappy 6 hours agorootparentprev> That's like asking permission to read and write your entire phone, just to provide the ability to write and read back a file. ...it occurs to me that this is in fact how most desktop apps work, and I do prefer it that way. reply ornornor 6 hours agorootparentOn windows idk but Unix has permissions for that reason. reply Dylan16807 5 hours agorootparentNormal Unix permissions do nothing here in a desktop context because the program is running under your account. reply Wowfunhappy 3 hours agorootparentprevThere are permissions, but I think https://xkcd.com/1200/ is relevant here. reply YeBanKo 7 hours agoparentprevThanks for the context, it's important. But from the link you posted: > In order for you to write a message to a Facebook friend from within Spotify, for instance, we needed to give Spotify “write access.” For you to be able to read messages back, we needed Spotify to have “read access.” “Delete access” meant that if you deleted a message from within Spotify, it would also delete from Facebook. No third party was reading your private messages, or writing messages to your friends without your permission. So here Facebook acknowledges that an app that sends messages needs write permission, not read. I would assume that sending a recommendation is a write only thing, especially with something private as direct messages. And it is pretty well understand pattern. When you share something through iMessages, Signal or WhatsApp from the a different app, the app does not get an access to you chat history. The allegation that Arstechnica are pretty sever: > By 2013, Netflix had begun entering into a series of “Facebook Extended API” agreements, including a so-called “Inbox API” agreement that allowed Netflix programmatic access to Facebook’s users' private message inboxes Strange naming \"Inbox\" for sharing API. > in exchange for which Netflix would “provide to FB a written report every two weeks that shows daily counts of recommendation sends and recipient clicks by interface, initiation surface, and/or implementation variant (e.g., Facebook vs. non-Facebook recommendation recipients). This is something that Netflix could do even without special access to the messages, since links originate from them. But so could Facebook, since they see the traffic in messages and can identify referral links. Looks like Titan API, whatever it is, gave even more access? NYTimes article from 2018 [1] has more details, but it is still unclear if user consent was explicitly obtained for Netflix to read messages. But an interesting quote from Steve Satterfield, Facebook’s director of privacy and public policy: > With most of the partnerships, Mr. Satterfield said, the F.T.C. agreement did not require the social network to secure users’ consent before sharing data because Facebook considered the partners extensions of itself — service providers that allowed users to interact with their Facebook friends. A rather conspicuous statement by someone who have properly collected consent from users. [1] https://archive.is/DH17k reply rezonant 6 hours agorootparent> So here Facebook acknowledges that an app that sends messages needs write permission, not read. I guess the feature at issue here is that you could actually hold a conversation with a Facebook friend inside of Netflix or Spotify which does indeed necessitate the ability to read back messages from the other user. Whether it was wise to allow that instead of the kind of sharing systems we use today in 2024 is another question. reply YeBanKo 5 hours agorootparentDepending on the OS architecture it might be possible to have an SDK render messages without handing any data to the parent app. Or of it's not possible at least the question is where any of the messages even hit Netflix servers. reply some1else 2 hours agoparentprevNote that everyone had access to the Inbox API at the time. We made an art project highlighting the invasiveness of such broad access: \"E-dentity is a project that asks a participant to login to its Facebook account, then takes his/ her private data from their profile and automatically prints them in an understandable booklet that is handed to the user. This booklet seeks to raise awareness of the hidden data we are sharing which we are often not aware of.\" https://github.com/some1else/Edentity reply ionwake 6 hours agoparentprevI only read the headline and this reply gave me even greater concern. wtf they shared ALL msg data for logging into Netflix chat?!? I dunno I’m surprised I’m still surprised these days reply choppaface 1 hour agoparentprev> Disclaimer: I work at Facebook but not on messaging or anything related to this article Same as \"Hey, Googler here. Let me tell you how I'm right and why you should think this way.\" > Facebook didn't just randomly give Netflix access to everyone's messages. That's not at all what the title alleges, nor what the article says. The article (1) provides evidence that Facebook monetized user private messages in a data-sharing project with Netflix and (2) cites court documents that litigate Facebook having Jedi-Blue-like monopoly-preserving interaction with Netflix. It doesn't matter what the Facebook TOS says or how the tech works. Human users never provided informed consent that their private comms would be monetized as well as used for anti-competitive un-American purposes (un-American as in the Sherman Act, altho creating a monopoly is perhaps very American indeed). And Facebook has done that time and time again. reply notnmeyer 9 hours agoparentprevso you agree then that “private” messages aren’t private on fb? i don’t know how to interpret this in a way that isn’t terrible for fb users… reply scarface_74 9 hours agorootparentIf you give access to your chat as the parent poster claims, why are you surprised that Netflix has access? reply hipadev23 8 hours agorootparentBecause it’s not a reasonable expectation that your private messages would be shared with an advertising partner when you link your account to it, and “give access” is rarely a step that your average user actually reads, much like agreeing to TOS’s upon signup. And catering to the average user’s expectation is what should dictate policy, not a “technically we have permission” caveat. reply vel0city 5 hours agorootparent> would be shared with an advertising partner In this case Netflix was not an advertising partner. You were signing into Facebook Chat inside the Netflix chat, and participating in Facebook chat messages inside the Netflix app. You were opting in and using the Netflix app as a Facebook Chat client. Its like being surprised the Pidgin executable could see your Jabber messages. reply rezonant 6 hours agorootparentprevIn the sense that some users may not have realized what they were allowing, that's fair. But that just implies that the permission dialog for this sort of thing should be pretty onerous while being very easy to understand. There are details that aren't clear here too: Did Netflix request read permissions when you signed in via Facebook? If so, that's shitty and is worthy of condemnation, but the onus falls more on Netflix than Facebook there. You should be able to sign in with Facebook without expecting your DMs to be sent to Netflix. It's still on Facebook, but to a much lesser extent: They should make what's being shared super clear when you sign in with Facebook, and that includes making the sign in super onerous and scary if its something like reading DMs, so the user doesn't miss these details. And they should be reviewing third party apps and what permissions they request, and making sure its inline with the functionality the app is presenting. However, if the normal Facebook authentication flow did not grant this permission, and the permission was only granted when the user accessed the \"Netflix Chat\" or whatever feature which obviously did, in actuality, require the read permission to function, then this isn't that big a deal. reply bluefirebrand 8 hours agorootparentprevYou would expect that giving permission to send specific pre-approved messages does not imply permission to read everything you've ever said to anyone or they've said to you.. Right? reply reissbaker 8 hours agorootparentThat's not what the feature was. The feature was that you could use Messenger inside Netflix and Spotify to chat with your friends without leaving those apps. If you opted into using Messenger to chat with your friends inside Spotify, I'm confused why you think Spotify couldn't access your messages, given that Messenger was unencrypted at the time and you were running it inside Spotify. How else would the feature work? It's Messenger running inside Spotify; just like how iOS has access to the unencrypted files and network traffic of any app on your iPhone, Spotify could access any of the unencrypted files or network traffic in Spotify. It's a dumb feature and I'm glad they killed it, but the \"gotcha\" here isn't much of a gotcha IMO. It was an opt-in feature to use Messenger inside these other apps; of course the other apps could see your messages if you opted into that. It's like complaining that GMail \"shares your private email\" with Apple Mail if you use Apple Mail as your mail client. reply chatmasta 8 hours agorootparentThe web was rampant with these patterns in the early 2010s when OAuth didn't exist, and HTTPS the exception rather than the rule. The most egregious example was probably LinkedIn's GMail \"integration,\" ostensibly used to invite your GMail contacts to LinkedIn. Back then, that sort of thing felt innocuous. But the implementation was even worse. Due to lack of OAuth and MFA, you literally entered your GMail password into LinkedIn. Then LinkedIn logged into your GMail account where they could do anything. Even if they limited it to scraping your contacts, they still got every email address you'd ever sent or received an email to or from, over the lifetime of the account. In any other context this would be called phishing. And by the way, this pattern still exists. For example, apps that force you to log into a third party site in their embedded WebView can read the entire DOM (including your password). .. reply reissbaker 7 hours agorootparentYeah definitely. There are still some pretty bad patterns out there; for example, if you try to add an event from Facebook Events to your Google Calendar, instead of generating a normal ICS file or event link, they... ask for read/write access to your entire Google Calendar account. No thanks! Similar to apps that ask for access to your entire Contacts list to \"find your existing friends\"... You can bet they're uploading that entire thing to their servers and trying to growth hack with it. reply jdminhbg 6 hours agorootparentWould be nice if APIs offered more granular permissions. Almost every one of these is global read/write so it’s impossible to distinguish between good and bad actors. reply lupire 8 hours agorootparentprevThink about the difference between accessing these specific messages, and accessing all messages. reply reissbaker 8 hours agorootparentIf I give Apple Mail my credentials for my GMail account, I would expect Apple Mail to be able to access my email in my GMail account. Switching the word \"email\" to \"DM\" doesn't feel like a meaningful difference: if I'm using a third-party client to access and send messages, of course the third-party has access to my messages. Would I expect Tweetbot to be unable to access any tweets other than the ones sent from Tweetbot? That's... not a very useful third-party client. These were third-party Messenger clients; they had access to your Messenger DMs if you opted into using them. reply notnmeyer 8 hours agorootparentprevit’s disingenuous to think that users read and fully understand the various permission scopes of a service. “private” has an unambiguous meaning—playing the “well, technically” card falls pretty flat imo. reply scarface_74 8 hours agorootparentWhen you give your mail client credentials to read your email , would you not expect your client to be able to read your mail? On Android, when you give a third party client permission to receive SMS, you don’t expect it to have access to your SMS? reply SoDmbIHadToRply 7 hours agorootparentSo when I give thunderbird my email details, someone at thunderbird gets access to all my emails ? reply rezonant 6 hours agorootparentIf Thunderbird had a hosted web version, yes. Are you arguing that data portability and interoperability should never be possible if the receiving app is an online service? Of course Thunderbird could send an automatic update that starts shipping your emails to Thunderbird's servers. You dont expect that, but only because you trust them. reply sashank_1509 6 hours agorootparentprevunless I’m wrong thunderbird software has complete access to all your emails when you give thunderbird your email details. Of course, that does not imply that a specific thunderbird employee can read your emails, it is probably encrypted on that end but if they pull a switcheroo and download all your emails into an AWS instance, yes that might be possible (and probably wildly illegal too) reply airtonix 9 hours agorootparentprevnot if you log in to enable and agree to share such messages. no. reply k8svet 8 hours agoparentprevSo... this sounds like OAuth, with a nice consent scene that says I'm giving Netflix this access to my FB DNs. That's what you mean, right? Otherwise, what the fuck is the difference?. And really, as if this makes anything better, wow. Imagine having the feeling of obligation that you have to stick your neck out over this. Just take your over-sized salary and be happy knowing you work for one of the worst companies of our time. (despite my tone, at this point, I honestly say that without judgement, just ... own it.) reply aardvarkr 7 hours agorootparentWhen you give your mail client credentials to read your email , would you not expect your client to be able to read your mail? On Android, when you give a third party client permission to receive SMS, you don’t expect it to have access to your SMS? reply k8svet 6 hours agorootparentJesus Christ, do you also work for Facebook? An LLM could generate a more coherent, logical defense than that. Is Netflix a secret Facebook client that I don't know about? Lmao, is this a serious comment I'm replying to? reply rezonant 6 hours agorootparent> Is Netflix a secret Facebook client that I don't know about? Lmao, is this a serious comment I'm replying to? Yes, in fact, that's what the feature was. You could send a movie recommendation via Facebook within Netflix, and then continue the conversation with that friend, still in the Netflix app. It's a dumb idea for all of the obvious reasons that its in Netfix' best interest to hoover up the data, but that's why it doesn't exist anymore and hasn't existed for years. reply navigate8310 6 hours agorootparentprevTotally agree with the sentiment here. The comment by the employee make it sound like it's the user's fault. Something akin to dark pattern and malicious compliance by giving the user an OAuth consent for their DM. reply rezonant 6 hours agorootparentIt's only a dark pattern if this was the permission Netflix asked for when you hit \"Sign in with Facebook\" or some other unrelated feature. If the permission was granted when you tried to use Netflix Chat, a bidirectional in-app chat powered by Facebook, then its not a dark pattern at all, its just the usual way things are done. reply k8svet 6 hours agorootparentprevLmao, love seeing what HN decides is controversial these days. God give me the power of some of y'all's utterly depraved self-serving self-delusion. I at least acknowledge the moral compromise of how my labor accrues in the system instead of burying my god damn head in the sand about it and offering poor incoherent defenses of my employee in public. And I make a third of what I could make at FB, and still probably don't contribute as negatively to the world. reply lesuorac 7 hours agoparentprev> Disclaimer: I work at Facebook but not on messaging or anything related to this article. So, it could work exactly as it sounds and you'd have no idea? --- Although I'm not sure the complaint [1] (linked from articled) actually says that messages were given. [1]: https://cdn.arstechnica.net/wp-content/uploads/2024/03/compl... reply trolan 7 hours agorootparentYes I think they're giving their general nerd opinion while also being transparent about possible conflicts. Their comment reads like an analysis of the article not the technology. reply cm2012 7 hours agoparentprevIf this wasn't Facebook it wouldn't even be news. reply soraminazuki 6 hours agorootparentI hope you’re being sarcastic? Or is that actually your stance on people’s privacy rights? reply AnotherGoodName 5 hours agorootparentGoogle docs literally has the exact same feature and we're not even talking about it. Using the exact same OAuth framework as here you can grant Netflix and Spotify the right to read everything and all comments in your Google Docs. You can even grant them the right to read all your emails in Gmail! In all seriousness i believe anyone providing oauth should just shut it down at this point, Cambridge Analytica was entirely users granting a third party oauth access to read their friends lists with an explicit permission dialog and all and it was a scandal that led to massive fines. The world decided that oauth access is not ok even with the dialogs prompting to allow third party access and at this point we as developers should listen and take it away. Google currently flys under the radar with the exact same access that led to cambridge analytica but they should probably just shut it down unless they want to run the risk of similar court cases. reply rezonant 6 hours agorootparentprevBoiling it down here... some users hit the \"Yes\" button when Facebook asked them if it was OK to allow Netflix to access their DMs for a feature that allowed you to chat (bidirectionally) with your friends inside the Netflix app. That's a privacy violation? reply kazinator 6 hours agorootparentprevRather, it seems like cynicism about the media, than a stance on rights. reply rvba 6 hours agorootparentprevLots of comments here look like some sort of astroturfing made by a PR agency reply robocat 5 hours agorootparent\"Please don't post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you're worried about abuse, email hn@ycombinator.com and we'll look at the data.\" - https://news.ycombinator.com/newsguidelines.html reply choppaface 1 hour agorootparentThe root comment is literally a Facebook employee who is intentionally trying to change the narrative. An employee of a company that has been fined billions for privacy breaches, that was responsible for literal voter suppression https://www.opendemocracy.net/en/dark-money-investigations/t... etc etc HN \"guidelines\" say \"Please don't post shallow dismissals\" -- Don't allow FANG to astroturf these forums. reply 1vuio0pswjnm7 5 hours agoprev\"Meta said it rolled out end-to-end encryption \"for all personal chats and calls on Messenger and Facebook\" in December. And in 2018, Facebook told Vox that it doesn't use private messages for ad targeting.1 But a few months later, The New York Times, citing \"hundreds of pages of Facebook documents,\" reported that Facebook \"gave Netflix and Spotify the ability to read Facebook users' private messages.\"\" 1. \"Does Facebook use info from your private messages to target you with ads? No. Facebook says it might look at your private messages to determine if they violate the company's policies, but it doesn't use that information for ad targeting. Facebook won't use the contents of your private messages to target you with ads on Facebook Messenger, WhatsApp or Instagram either, according to a spokesperson.\" https://www.vox.com/2018/4/11/17177842/facebook-advertising-... If the messages are encrypted \"end-to-end\" or whatever the chosen marketing buzzwords, so that Facebook cannot read them, then how is FB able to \"use\" messages for anything. One accustomed to normal communications services might think FB is storing and delivering messages and that's all. But in truth, it's \"using\" them. (For purposes other than complying with any request from a court of comptent jurisdiction.) Exactly what they might be doing is of course highly confidential. You are free to take guesses. FB may answer yes or no. Answers cannot be verified, so their value outside of marketing is dubious. NB. Meta _is_ a third party. It feels as if some people believe they can redefine terms like \"end-to-end\", \"third party\", etc. As if they know many readers will happily go along for the ride. reply leidenfrost 5 hours agoparentMy guess is that FB stores the keys to reverse the encryption. The point of e2e is to block any third party to to see your conversations by sniffing packets. Not to stop Meta themselves. reply pushedx 5 hours agorootparentThe OpenWhisper protocol, which is supposedly implemented by Messages and WhatsApp, was designed specifically to enable anonymous key agreement between the two or more parties sending messages, and no one else, including the service provider. Whether or not Facebook actually implements it this way is a great question. reply appplication 5 hours agorootparent> two or more parties When you’re having a 1:1 conversation with someone at a party, and then crack a joke and some weird dude 10 feet away laughs at you and says “good one”. The obvious answer here would be for meta to consider itself party to your conversation. reply AdamJacobMuller 5 hours agorootparentprevPacket sniffing is mitigated by TLS/HTTPS. The point of end to end is to to ensure that only me and the person I'm sending a message to can read it and that none of the systems in-between us can read the plain text of it. reply roncesvalles 5 hours agorootparentprevAlthough the frank meaning of \"E2E encryption\" is that a message is encrypted on the sender's device and only decrypted on the intended recipient's device, that is never ever what big tech companies mean when they use this term. For one, this would remove companies' ability to support lawful interception, which puts them afoul of American law. reply Thorrez 3 hours agorootparentIs lawful interception possible with Whatsapp? I thought it had actual E2E encryption. reply aftbit 5 hours agorootparentprevUh nope, that's a huge move of the goal posts. The point of E2E is to ensure that nobody besides the two endpoints can read the messages, including all hops along the way, notably including the service provider themselves. The problem is that this requires users to do things like use one device to authenticate another or restart key exchange with all of their peers. If a user loses their phone, then they will need to redo their security exchange process, which nobody wants to do or even understands. Thus companies often store key material in an insecure way to allow new devices to be silently added to the account. Plus, even if E2E is well implemented, there are still problems when the endpoint software can be remotely updated to a version that exfiltrates keys or messages. reply bawolff 5 hours agorootparentprev> The point of e2e is to block any third party to to see your conversations by sniffing packets. Not to stop Meta themselves. No... the point of end to end encryption is to be encrypted end to end. Its literally the name. If meta can read your encrypted messages, that is just normal encryption not end to end encryption. reply mcherm 9 hours agoprevI'm not clear whether I understood what the article is claiming. It's clear they claim that Meta shared customer's direct messages with a business partner without notifying the individuals who sent and received the messages. It also SOUNDED to me like the article was claiming they did so AFTER Meta introduced \"end-to-end encryption\" (which would ALSO mean that they were lying about offering end-to-end encryption). Am I reading that correctly? reply benreesman 9 hours agoparentThe cluster of allegations is that the Onavo acquisition put FB-designed and built rootkits underneath TLS on a significant fraction of all smartphones in the United States and that FB/IG (now Meta) used clear text access to ostensibly secure HTTPS sessions to extract arbitrary data from both competitors and partner companies to play poker with X-Ray glasses on as concerned all competition in an ostensibly free and fair and competitive marketplace while simultaneously creating scope for arbitrary other advanced actors to exploit the same intentionally crippled OS-level security at the cost of weakening the entire world’s digital security infrastructure for pure financial profit without so much as a FISA court order to justify such actions. If substantiated, such accusations would be among the most damning in the history of technology. reply nemothekid 7 hours agorootparent>If substantiated, such accusations would be among the most damning in the history of technology. If substantiated? Just search Onavo on HN search - I thought this was widely known for years. reply benreesman 7 hours agorootparentAs a former employee until 2018, I heard the words “Project Ghostbusters” two days ago. I was peripherally aware of something called Onavo but I had no notion that anyone was talking about “kits”, we all thought it was some kind of metrics thing that was sort of iffy sounding but lots of iffy ideas got proposed by some PM looking to make a name and shot down by the grownups, what is alleged would have provoked a riot at the weekly all hands. If any of this is true they didn’t tell people like me about it, and at one point there were three people on the org chart between myself and the CEO. I’m very skeptical of the allegations, but I’d be lying if I said I found them to be flat impossible. I tread very lightly on this sort of thing and I didn’t even acknowledge I’d ever heard the word Onavo until I read it on TechCrunch. I certainly hope they’re false: FAIR seems to be the last real hope for an Open future on AI short of a complete housecleaning of the whole Valley. reply nemothekid 6 hours agorootparentI had a friend tell me about Onavo in ~2015. I wont delve into what he told me, but at the time I had the \"move fast and break things\" spirit and thought it was a pretty cool tool that they had figured out to get competitive information. He never showed me anything, but allegedly they could even see what features were being used in other apps. But I don't think this is something he made up, it's been discussed on HN. https://news.ycombinator.com/item?id=16381812 >I wonder if it's be possible to make a social networking startup, optimise solely for Onavo metrics, and get bought out by Facebook. https://news.ycombinator.com/item?id=16373339 >The Onavo VPN service from Facebook is disguised as a protection mechanism but tracks the user for the benefit of Facebook. https://news.ycombinator.com/item?id=14971839 >The database stems from Facebook’s 2013 acquisition of a Tel Aviv-based startup, Onavo, which had built an app that secures users’ privacy by routing their traffic through private servers. The app gives Facebook an unusually detailed look at what users collectively do on their phones, these people say. I am surprised that this accusation is at all controversial. reply sunshowers 7 hours agorootparentprevEx-FB here -- I do feel like I knew about the general scope of what Onavo did, which was to incentivize people so FB could snoop on TLS traffic and grab data about competitor usage. reply benreesman 6 hours agorootparentCould be a question of what we worked on. I did Ads ML Infrastructure, Abuse Detection Systems (spam basically), and then more ML Infrastructure on IG Feed/Stories. I was deep enough in the engine room it was all more or less feature embeddings. So it’s probably fair to say I would have known less about strategic maneuvering than plenty of less tenured folks closer to the surface. I knew it sounded vaguely sketchy but you remember how many vaguely sketchy things some frisky new PM tried to get pushed through a launch card meeting only to have someone on Sheryl’s radar detonate it on the launch pad. The timeframe is the main reason I’m skeptical: Sheryl didn’t put up with crap like that she knew what was at stake. reply sunshowers 4 hours agorootparentI was on devinfra/source control (worked 2012-2018 in that area before switching to Libra) so we weren't making decisions, but we got to saw a bunch of what happened as it happened. Onavo was always treated as pretty sus among the people I worked with, who were largely linux/free software/security types. As Pedro said in the email described in [1], no sufficiently well-informed, security-minded person could ever be comfortable with Onavo. [1]: https://techcrunch.com/2024/03/26/facebook-secret-project-sn... reply ajdude 8 hours agorootparentprevIf this is true that sounds really, really, bad. reply ahahahahah 5 hours agorootparentprevThis article has nothing to do with onavo. reply loeg 7 hours agorootparentprev> such accusations would be among the most damning in the history of technology. You're putting this up there with IBM in the holocaust? reply tobias2014 9 hours agoparentprevI find the article quite confusing and unclear to be honest. Are there any other sources? This is the original NYT article from 2018 https://www.nytimes.com/2018/12/18/technology/facebook-priva... \"Internal documents show that the social network gave Microsoft, Amazon, Spotify and others far greater access to people’s data than it has disclosed.\" Facebook promised E2E at the end of 2023. reply tssge 8 hours agorootparentHere's the source media is probably using: https://www.courtlistener.com/docket/18714274/klein-v-meta-p... To be honest I found I got much better grasp on the whole debacle by just reading the court papers themselves. reply dylan604 8 hours agorootparentprev> Facebook promised E2E at the end of 2023. Wait, seriously? Like 4-6 months ago? Like, yesterday in terms of how long they haven't had it? Sheesh, a day doesn't go by that I'm not reminded of how happy I am to have dropped FB so long ago. reply ahahahahah 5 hours agorootparentThey've had it for years, it was just opt-in. More recently they've applied it to everything. reply rgbrenner 9 hours agoparentprevFB has supported e2e messaging since 2016, but it wasn't the default until 4 months ago (Dec 2023). So likely very few users had it enabled (much less on both ends needed to protect a message from FB). The netflix deal starts in 2013. Even after 2016, e2e would just mean netflix would get slightly fewer messages. So I don't see anything that would necessarily indicate FB is lying about e2e. reply petesergeant 8 hours agorootparentI wonder if there’s a timing connection here with FB Messenger “upgraded the security of this chat” messages I’ve had on a couple of long-running conversations recently reply Jerrrry 8 hours agorootparentsheer coincidence, not to google-slide. reply bastawhiz 9 hours agoparentprevIt sounds like it, and if true, is pretty damning. reply mgoetzke 6 minutes agoprevWhat is Facebook Watch ? reply kylecazar 8 hours agoprevWhat is being claimed here? 'granted programmatic access to FB user's inboxes' could mean a lot of things. What privileges? I read the article and still can't tell. I don't believe that Meta allowed Netflix to read messages that a user sent or received, but that seems to be what they're implying. reply chatmasta 8 hours agoparentAgreed. I would like to read more details about the \"access to the Titan API\" that Facebook gave to Netflix. Has anyone read the lawsuit PDFs? Maybe more details are in there somewhere. reply bicepjai 8 hours agoparentprevAn exec can interpret different meaning rather than a technical person. I assume that as full access to read the messages reply rvba 6 hours agoparentprevFor me it sounds that they read the messages to measure sentiment (what people are watching / what they like and dislike / what they recommend / generic information about competition from other rv shows, movies and video games), but probably the system was \"bugged\" (plausible deniablity) so those with access could read everything they wanted - be it messages made by employees from some competitor startup, or perhaps partners and sweethearts. Creepy stuff. reply neilv 9 hours agoprevI don't recall this potential bombshell (maybe because it was shortly before a Christmas, and the NYT headline looked like just more of the same ol'): > And in 2018, Facebook told Vox that it doesn't use private messages for ad targeting. But a few months later, The New York Times, citing \"hundreds of pages of Facebook documents,\" reported that Facebook \"gave Netflix and Spotify the ability to read Facebook users’ private messages.\" 2018-12-18 https://arstechnica.com/tech-policy/2018/12/report-facebook-... 2018-12-18 https://www.nytimes.com/2018/12/18/technology/facebook-priva... reply _heimdall 8 hours agoparentThe problem isn't whether Facebook used private messages for ad targeting (the claim they denied), its whether Facebook used private messages at all. Who cares if it was for ads, giving third party companies access should be a huge problem with or without ads. reply margorczynski 7 hours agorootparentThis should make it a no-go for any sane person that is aware of that, unfortunately not many are. I always try to convince people I know to ditch Messanger/WA/etc. in favor of Signal, and in many cases I've succeeded. reply _heimdall 7 hours agorootparentFor better or worse, I found that the people willing to keep Signal installed and up to date largely just to get in touch with me was a good proxy for the list of people that really matter most to me. I didn't win many over on the importance of privacy or Signal, but the willingness of some to put up with it because it matters to me says a lot about my relationship with them. reply rvba 6 hours agorootparentprevWhat is good about signal? It does not allow unique account names (!), but uses telephone numbers - what is just absurdly bad security. The state can make a duplicate of your sim at any time. Not to mention linking phones to people is relatively easy. reply qilo 3 hours agorootparentSignal introduced usernames about a month ago. https://signal.org/blog/phone-number-privacy-usernames/ reply jgalt212 7 hours agoparentprevthat's the money quote, for sure. reply throwaway2990 9 hours agoparentprevnext [18 more] [flagged] zer0zzz 8 hours agorootparentCare to back that up with any citations, or should everyone just take it on faith that what a throwaway says isn’t made up? reply onlyrealcuzzo 7 hours agorootparentFacebook is on both ends of the e2e. e2e encryption means no from client to client can read your messages. Your client certainly can - and Facebook is the client. It would have no problem sending back signals on your messages (or the full message) to Facebook servers. Doesn't mean it's happening. But it's interesting that e2e encryption alone makes you positive it isn't. reply zer0zzz 5 hours agorootparentAgreed, and that’s how it would work. I was more highlighting the throwaway with comment that had no context or link to sources. reply Veserv 8 hours agorootparentprevCan you point out where in their contracts or privacy policy they have legally binding terms that irrevocably dismiss their right to give your messages to advertisers? If they have no intention to sell, then they have nothing to fear by putting it in writing with a appropriate liquidated damages clause. Otherwise it is quite suspicious why they reserve the right to do that in the contracts that they wrote. reply cute_boi 7 hours agorootparentprevWell, how can anyone trust facebook and whatsapp? How can we be so sure that e2e is done properly without looking into source code. reply zer0zzz 5 hours agorootparentThese are all a fair questions, but they’re still questions and not some confident assertion with absolutely no sources from a total throwaway account. That was my point. reply 2Gkashmiri 7 hours agorootparentprevDownload a naughty gif/video from reddit and send it to someone on messenger. It will report you and say you are sending a naughty video and that multiple attempts will ban you. Fine for unencrypted chat. Send same on e2e chat. The video will say \"not sent\". Why is Facebook processing anything before being encrypted? The understanding is e2ee means content gets encrypted on device, sent to server in encrypted state and decrypted at other side. There is NO way Facebook should be able to analyze the contents of message, photo, video. .if they are doing this for csam/nudity, what stops them from using same tech for ad targeting and more seriously, for letting governments to spy on people? reply gloryjulio 8 hours agorootparentprevIt's both true and false. They don't do advertising with msg, and it's e2e encrypted. But they can use the metadata reply tempest_ 7 hours agorootparentIt is end to end encrypted but facebook controls both ends so... ? reply gloryjulio 4 hours agorootparentThat's not how it works. They won't be able to see the messages themselves if it's e2e encrypted. You can say they are lying of course reply addandsubtract 8 hours agorootparentprevYes... meta data reply _heimdall 8 hours agorootparentIs metadata useful for ad targeting? If the claim is that they use the content of messages that's be one thing, but what kind of ad value is really pulled out of timestamps and phone numbers of who you messaged? That said, collection of metadata can still be a problem, I just don't see the ad value. reply dingnuts 8 hours agorootparentYes it is useful. Knowing who you contacted and when tells advertisers demographic information and probably more that I can't think of reply _heimdall 7 hours agorootparentWhat demographics can be gleamed from who and I contact and when? This is one of those times where I feel like I'm annoyingly peppering someone with questions, hopefully it doesn't come across that away. I really am curious what ad-related use case I may have missed with regards to metadata. reply dylan604 8 hours agorootparentprevOMG, that's such an obvious word play that has such dire ramifications. FARK!!! I have to hand it to theZuck, this totally changes how I look at the name change reply fnordpiglet 8 hours agorootparentprevFacebook is organized as a for profit company. reply deprecative 8 hours agorootparentAnyone expecting capitalism to not capitalism is going to have a bad time. reply stephenm00 9 hours agoprevBuried in the article, but not just Netflix, Spotify as well. The New York Times, citing \"hundreds of pages of Facebook documents,\" reported that Facebook \"gave Netflix and Spotify the ability to read Facebook users’ private messages.\" reply crmd 9 hours agoprevThis is one of the litany of bad things that happens when antitrust precident is ignored and we allow a small number of companies to become large enough to dominate the economy. reply izacus 1 hour agoparentBut commenters here want that right? They're rilling up against an API that allows data export and user ownership and demand that they're removed and all interoperability to be killed because \"users are too stupid\". This cements and entrenches monopolies because noone is allowed to compete or interoperate. In sense, things like Apple Mail is a problem for them because it uses full access to GMail account to extract private data over API. reply scarface_74 8 hours agoparentprevSo are you claiming Netflix is a “monopoly” and if so, how would you break them up? The same question for Facebook. This is a case of possible “collusion” not anti trust reply lupire 8 hours agorootparentCollision is part of antitrust. https://www.law.cornell.edu/wex/collusion#:~:text=Collusion%.... reply scarface_74 8 hours agorootparentYou can have collusion without being a monopoly. Your two neighborhood grocery stores can illegally collude even if there are 100 in your city reply loa_in_ 7 hours agorootparentThat's true but also very irrelevant reply petesergeant 8 hours agorootparentprev> Collision is part of antitrust Would make for some fascinating lawsuits, but I suspect you meant collusion reply waveBidder 8 hours agorootparentprevopen protocols in the case of Facebook and banning studios from owning/exclusivity with distributors in the case of Netflix. reply scarface_74 8 hours agorootparentSo you are saying that no one can distribute their own work on thier own website? Where do you draw the line? Can I not create my own video and put it on my website? Can I not work with friends and we all post our own video on our own website that we jointly own? How do we stop foreign studios from distribution over the internet? Do we block them too? Why stop at films? Should book authors also not be slowed to self publish? Software developers? reply thisgoesnowhere 6 hours agorootparentThis slippery slope/where do you draw the line argument is very weak. It's like saying me accidentally spilling a bit while doing a oil change in my garage is the same as BP spilling hundreds of thousands of gallons of crude. Scale matters. And \"where you draw the line\" can be defined loosely to be left up to interpretation at the time. reply JustExAWS 6 hours agorootparentSo you are going to pass a law That says depending on size, American companies can’t create content and distribute it? And then foreign companies are still allowed to distribute thier own content? Are you going to block them from transmitting to the US? If Netflix decides to incorporate in Canada, are you going to stop them from distributing thier own content to US citizens? You really don’t see a problem with the government prohibiting companies from distributing thier own content over the internet? Does that count for newspapers? Video content created by large newspapers? reply waveBidder 7 hours agorootparentprevit's about scale, obviously. the sorts of ventures you make a limited liability corporation for. you want to protect yourself from the potential risks? Then participate in the market in a fair and non-abusive manner. Same thing for publishing companies. individual authors can do whatever they like. reply JustExAWS 6 hours agorootparentI ask the same question, if Netflix decides to incorporate in Canada are you going to make a law that forces ISPs to block them? Are large newspapers not allowed to produce their own content? Do you draw the line at newspapers and news organizations because of freedom of the press and the do you allow Netflix to produce thier own documentaries but not fictional shows? reply ozfive 48 minutes agoprevThis is wiretap level. reply timetraveller26 9 hours agoprevSo it's true that just talking to anybody about anything automatically triggers a flag in some server somewhere. reply pc86 7 hours agoprevThis is literally the first time in my life I've heard of Facebook Watch. reply _heimdall 8 hours agoprevThe encryption concerns here are a bit confusing IMO. Facebook owns the UI that show you the text of the messages. There doesn't have to be a backdoor into E2E encryption at all per say, a simple UI property check would give full access to message contents directly in the frontend code. Throw that into a private API and Bob's your uncle, decrypted messages that were transmitted with 100% secure E2E encryption. reply lxgr 7 hours agoparentIs that different for any other encrypted instant messenger, though? reply _heimdall 7 hours agorootparentNo not at all, its a universal risk since you have to trust the UI. I should have been more clear there. Its interesting to me that I often see concerns over whether Facebook has encryption backdoors when the UI can do all the work. reply bhouston 8 hours agoprevThere is a lot of confidential information in Facebook private messages, probably people cheating, plans to leave one's job, political organizing, brides, illegal activities, etc. If Netflix gets access to this information, it is likely that other companies and 3rd parties got access either directly or indirectly. Very scary what can be done with that information. reply rezonant 6 hours agoprevFor important context on my post here, please read tsunamihippo's post first: https://news.ycombinator.com/item?id=39859319. This story seems very overblown. Are we arguing that Facebook should not ever allow any third party app to ask permission to read the user's Facebook DMs? There are valid use cases for this permission, and every case where an app asks for it is not a \"privacy violation\". Sure, did Netflix or Spotify actually need the ability to read back DMs instead of just write them so that they could send recommendations? No, they shouldn't have needed that. If Facebook's API required that they have read access just to send a message, then that's crap design. But is it nefarious? No. As long as the user is appropriately briefed on what they are granting (and it appears that they were), and as long as Facebook addresses over-scoped permissions requested by third party apps in a timely manner, then this should not be an issue. I for one believe that we need to mandate that FAANG companies have these sorts of permission-driven systems to avoid the vendor lock in we're all too commonly stuck with today. Because these things are needed for competition to thrive and to avoid the big companies from creating moats that prevent us, the startups out there, trying to dethrone them, its all the more important that these companies invest in better UIs that help a user understand the implications of what they are doing, and better review processes to stop bad actors from exploiting users' ignorance on an ongoing basis. I despise Meta, but come on. Don't throw the baby (interoperability) out with the bathwater (interoperability can enable exploitation). reply izacus 1 hour agoparentRemember that this site is full of people outeight supporting monopolies and walled gardens when it comes to companies they like. So yes, they're absolutely defending removal of APIs that allow data sharing with explicit user consent. reply treme 9 hours agoprevhow much effort did meta put into building a legit competition vs netflix/youtube? it's hard to imagine they couldn't put up a decent competition with max user reach and $ just how great of a moat do yt/netflix have? is Disney the only one mounting a decent fight? reply cherioo 9 hours agoparentThere’s plenty of competition to netflix. Tiktok is probably the biggest competitor to YT. But it had to come in from short form video angle, because the moat of YT in long form video is probably insurmountable. Its fate remains to be seen. reply Mindwipe 1 hour agoparentprevWha? Hacker News is literally constantly claiming that there are too many competitors to Netflix and there needs to be some kind of compulsory licensing to reduce competition. Like there are hundreds of posts on the front page every week to that effect. Meta never took Watch very seriously, just because it requires literally billions of dollars of investment and they clearly never wanted to spend that much. They licensed Buffy the Vampire Slayer for the US, clearly saw it didn't move the needle much and they'd need to spend $5 billion+ to get there, and scrapped the whole idea. reply 2muchcoffeeman 6 hours agoprevFacebook had a streaming service? This is the first I’ve heard about it. reply dbg31415 6 hours agoprevFacebook is always going to pull stunts like this. They don't do creepy things on occasion by accident, they do them intentionally by default. Same old story for the last 20 years. Zuck is creepy AF, everything he touches is creepy AF. https://www.businessinsider.com/well-these-new-zuckerberg-im... reply drexlspivey 6 hours agoprevFacebook also installed root certificates through Onavo to spy on their competition. Some email exchanges from this court doc https://storage.courtlistener.com/recap/gov.uscourts.cand.36... From Zuck: Whenever someone asks a question about Snapchat, the answer is usually that because their traffic is encrypted we have no analytics about them. . . . Given how quickly they’re growing, it seems important to figure out a new way to get reliable analytics about them. Perhaps we need to do panels or write custom software. You should figure out how to do this. From Danny Ferrante (FB Data Scientist): - We developed \"kits\" that can be installed on iOS and Android that intercept traffic for specific sub-domains, allowing us to read what would otherwise be encrypted traffic so we can measure in-app usage (i.e., specific actions that people are performing in the app, rather than just overall app visitation). This is a \"man-in-the-middle\" approach. - Our plan is to work with a third party—like GFK, SSI, YouGov, uTest, etc.—who will recruit panelists and distribute the kits under their own branding. We already have proposals from several of these providers. - The panelist won't see Onavo in the NUX or in the phone settings. They could see Onavo using specialized tools (like Wireshark). reply advael 9 hours agoprevGonna give it like two weeks before tech bosses posit that users don't have a reasonable expectation of privacy in their private messages reply cyost 9 hours agoparentIsn't that why they got renamed to \"direct\" messages basically industry-wide? reply cherioo 9 hours agorootparentWow I never made that connection. reply noobface 8 hours agorootparentprevBleak and rings true. The worst origin for speculation turned fact. reply lupire 8 hours agorootparentprevSorry but that's ridiculous. The terms are synonyms, and usage varies by platform. Neither one gives you more privacy. reply _tk_ 9 hours agoprevTwo things are truly horrifying if this is true. 1. Just how normalized this behavior has become in Silicon Valley upper management circles. 2. That this has not gotten out earlier. Hundreds or thousands of employees at both companies could have reported this to the FTC or elsewhere. reply rrr_oh_man 9 hours agoparentVesting period reply staticautomatic 9 hours agoprev [–] Cue the FCC for yet another toothless Meta consent decree. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Meta (formerly Facebook) has discontinued original series on Facebook Watch, leading to the demise of its streaming business.",
      "An antitrust lawsuit alleges that Meta made this move to satisfy Netflix, a significant advertising client, by granting access to Facebook users' private messages for business benefits.",
      "The situation underscores worries about privacy and the impact of large corporations on critical business choices."
    ],
    "commentSummary": [
      "Concerns arise over user privacy and data access with third-party apps like Netflix accessing private messages on Facebook, sparking discussions on OAuth permissions and end-to-end encryption.",
      "Skepticism surrounds the security of encrypted messages and allegations of Facebook potentially misusing user data for competitive reasons, stressing the significance of transparency and protecting user data in the tech sector.",
      "Emphasis is placed on the importance of clear permissions and maintaining user data integrity amidst ongoing conversations in the tech industry regarding privacy issues."
    ],
    "points": 398,
    "commentCount": 158,
    "retryCount": 0,
    "time": 1711669497
  },
  {
    "id": 39857433,
    "title": "Embracing Privacy: A Journey from Faculty to VP of Technology",
    "originLink": "https://seancoates.com/blogs/matter-and-privacy",
    "originBody": "Matter and Privacy 2024-Mar-28 When I was still working at Faculty, we took on a new client that was not yet named Matter. We eventually transitioned from an agency-client relationship to a startup relationship, where I became the VP of Technology. This is what I've been doing for the past two-ish years. Chris wrote some good background on founding Matter, so I won't repeat all of those details, but I've been wanting to write a bit about the origin story from my perspective. When we were trying to figure out how to turn some of the neuroscience, existing material, and lots of our CEO Axel's ideas into a product, we started discussing the idea of building an app around the concept of allowing users to log memories that they could later recall to improve their happiness. As a natural skeptic, it took me a little while to come around to believing that this was even possible and wasn't just hand-wavy wellness stuff. I've since been convinced that we have technology that—when employed correctly—can actually improve happiness by having our users recall positive experiences. And we have actual science (which I will link in the future) that proves that their brains will create/release neurotransmitters (\"happiness chemicals\" in the context of what we're working on) in line with their original positive experience, making them feel happier. For real. So, as a very bare concept, we landed on the idea of allowing users to store photos of these positive experiences, as well as logging ratings of the emotions they experienced so they could recall them later to stimulate these neurotransmitters. At one point Axel asked me \"what do you think of that?\" I said \"To be honest, I have to ask: why would I ever send you a private photo and a positive rating for a sexual desire emotion? I would never send something like that to another party like Facebook, so why would I do it for us?\" This led us down an interesting—and mostly unique—path to how we handle private user content, and how we model threats against this private data. We adopted user privacy as a core value, and how we think about this informs many other decisions we make with the app and the whole ecosystem handling our users' data. This became so important to us that we knew it needed to be one of the foundational aspects of how we work and this decision informed the product, not the inverse. We knew it was not something we could bolt on later—that trying to add this once we'd already exposed user data (to even ourselves) would be error-prone at best, and impossible at worst. Early on, we set out some core principles: we need to build trust with our users so they can believe what we say when it comes to how we handle their data (advanced users can audit traffic over the network to help build this trust, if they desire) we need to protect our users from mistakes we might make (we shouldn't be able to suffer a data leak of our users' data if we have a weak password or our code has a bug) even if we are competent enough to prevent a leak from ever happening, and even if our users trust us to do what we say, we must be resilient to being strong-armed by a future controlling power (e.g. if someone we don't trust buys us) We also had some extremely unusual conversations related to parameters around how far we can go with this: \"should we build our own datacentre for this?\" \"no, probably not. We can use an existing host if we're careful about what data we collect and how we collect it.\" \"but would our things be safer if we did?\" \"honestly, someone much larger than us will do a much better job with the physical layer… I don't think we want to spend our funding on hollowing out a mountain and hiring a militia.\" \"we can have the best intentions, but we can't always rely on those intentions. If one of our users' data became valuable to an evil nation state and they kidnapped my family, I'll be honest, I'd probably have to hand over the data.\" Given these criteria and extremes, we decided that our best course of action is to just never have our users' private data. This means that when you rate something high \"pride\" in Matter, we can't tell you've done that. We've intentionally set up our metrics system to refuse to collect this kind of personal data, and we (the people and systems at Matter) simply never get it (only the app running on your device gets this data). We don't store the data on our servers (outside of analytics—and even then never the data we consider private like emotion ratings); it always stays on your device and within your device's datastore. (Matter is an iPhone app, so we store data on your phone with Core Data, and in a private database that syncs within your iCloud account, but is set up in a way that even we can't access it. The app code that runs within our developer credentials, on your device, can read and write this data, but it is never sent to us and we have no way of accessing it through Apple's tooling. It's truly private to you.) We (again, the people and systems at Matter) do get the product of some of those inputs, but never in a way that we can reverse it. A very simple version of this is if we were to collect the product of an a multiplication operation with the value \"600\", we don't know if the inputs were \"1 × 600\", \"100 × 6\", \"30 × 20\", \"12 × 50\", etc. We don't know what went into a Matter Score for a memory but we do know the score. We know the \"600\" but not the \"8\" or the \"75\". We don't even know how you described a memory or what's in a photo you attached. All we know is that there is a memory, it has a score of 600, and it belongs to a numbered account. Numbered account? Well, we also don't know who—specifically—our users are, and this is maybe the most controversial of our decisions. We don't have accounts; we don't even currently have email addresses, outside of our mailing list. There is no forced association between our mailing list users and our app users. In the future, we may allow users to opt in to self-identifying, but even then we'll continue to be careful about never collecting private data. When users add memories to the app, they'll usually add content such as images. We don't want to (and we don't) hold these, either—at least not in a way we can see them. We primarily store these images on your device, but because the size of this storage is limited, we do have a system for storing assets such as images that have been encrypted on-device, and the actual photo contents or the decryption keys are never sent to us. We store data for users, here, but to us it looks like random noise (the binary ciphertext), never like a photo of whatever it is you're storing a photo of. I intend to write more about this in the future, since we expect to publish some open source tooling related to this. So, we don't have your data in a database that we can access in any way (again, beyond collecting metrics on user-driven events that we don't consider private, so that we can know number of active users, performance in the system, etc.). This poses a couple serious problems. The main problem is: if I lose my data, how can I recover it? Well, the short answer here is: we can't. We can't identify you by email to reset your password. We don't have your email address (associated with your data, at least), and you don't have a password. Even if we did have those things, we don't have your data so we can't restore it. Right now the app has backup/restore functionality and we expect users to use that to protect themselves from data loss. We've put a lot of thought into storing these backups for a user, but having that user identify themselves is a difficult problem. Storing that data on behalf of the user, in a way that we can't get to it is also a problem. But a very interesting problem. I think we have good solutions to these problems that we expect to build into the app before we're out of beta, and I also hope to post about this in the future. There's a bit more info in our Privacy Policy, which we're bound by. I've been working on lots of technology things at Matter, but overseeing our privacy implementation has been one of the most rewarding. One time, almost a year into working on this stuff, Axel said to me \"I love that you're thinking about this stuff and coming up with these kinds of solutions\" to which I barely held back a tear and replied \"I've been thinking about this stuff very seriously for over a decade, and I love that you're the first person who's really let me implement it.\"",
    "commentLink": "https://news.ycombinator.com/item?id=39857433",
    "commentBody": "You can't leak users' data if you don't hold it (seancoates.com)377 points by todsacerdoti 12 hours agohidepastfavorite129 comments jmward01 11 hours agoI agree with the core idea, avoid saving info so you can't ever leak it. I personally think our legal framework should be based on consequences to encourage this mentality more. If you are hacked I don't care even a little that you did everything right, I just care that my information got taken. You should be held liable even if you did what the industry thought was right. reply mooreds 10 hours agoparent> avoid saving info so you can't ever leak it I think that this is a good idea. It's similar to the principle of least privilege: keep only what you need to offer the service you are providing. Less risk for the provider, less risk for the consumer. However, at least in the USA, I've noticed an increasing number of companies who have determined that personal data is worth good money. This is why most stores have rewards programs, where they capture what you've bought and when you have bought it. If it was just about repeat business, they'd still be using punch cards, like they did a decade ago. I don't have any insight into how they use the data, but why would they offer free things (restaurants offer appetizers, grocery stores offer discounts, etc) unless the value they received was more than the cost of the incentive? reply jghn 6 hours agorootparentEven before the Great Sell Off, there was a growing notion of \"we may need this some day so let's store and/or log it\". And it makes sense. If you store it and don't need it, it's relatively cheap, at least in the last couple decades. But if you *don't* store it and need it, you're screwed. reply Affric 10 hours agorootparentprevI am still waiting for digital identity. Not sure why I can’t authenticate myself with these companies based on a private key and any details they want be disclosed to them for whatever reason don’t just come ephemerally from my server. Obviously, you could also have a third party acting in this space for the non-tech savvy. Right now all my data is held by corporate types who don’t give a shit. reply mooreds 10 hours agorootparentPasskeys are a start. They have their issues (I wrote about some here: https://ciamweekly.substack.com/p/on-webauthn-and-passkeys ) but at least it is widespread, well supported, standardized, (possibly) anonymous public private key cryptography. reply __MatrixMan__ 9 hours agorootparentIt seems likely that you know passkeys better than I do (you wrote a blog about them after all), so I've got a question. My impression is that there's a server side component. It's not just a key in your device, it's a key in your device that's blessed by someone who maintains a server. My further impression is that the people who manage the servers (either the authenticating-you server or the supporting-auth-for-you server) will be able to configure allow/deny lists for each other. They can say: > sorry passkeys.jimbobsmomsbasement.com, you're not on the list of servers that I trust, so I'm not going to accept this key Quoting GP here: > Right now all my data is held by corporate types who don’t give a shit. Is it true that passkey providers will be able to use this feature band together and prevent passkey providers that they don't like from being useful? It was something about attestations--I didn't fully get it the first time it was explained to me. If so, doesn't that make the \"corporate types who don't give a shit\" problem worse? At least with a password the corporate types couldn't deny you the right to authenticate because in their estimation your password provider isn't corporate enough. reply hirsin 6 hours agorootparentIt's not a server-side component but something integral to the passkey itself. Everything is on the key and there's no third party - just the key, and the site you're authing to. So when you auth with a passkey, it includes some details around \"this came from a Feitian model x or yubico model y or bitwarden or...\". That's blank, IIRC, if it's Apple. And then if a corporate type has said \"well we only gave our employees Yubikey 3s\", they can instruct their idp to only accept passkeys for Yubikey 3s. This is a tradeoff - their employees can't register legitimate, useful personal passkeys like their phone, but an arbitrary (not dedicated nationstate) attacker is a bit less likely to somehow takeover the account and add a Feitian key. That mismatch is a nice signal to block the user. But in general, outside of corporate identities, no one has any interest in caring what kind of passkey you use. GitHub doesn't, certainly, outside of resident key requirements, a different bundle of fish. (and yes, Dan is definitely great at this stuff, read his blog on this stuff). reply __MatrixMan__ 5 hours agorootparentI see, thank you. I suppose it also lets you reject keys from hardware platforms that are later determined to be insecure. The tinfoilhattery which I heard (and regret tangentially supporting on occasion) was that it was a slippery slope towards something like SSO, where some company (1Password, say) is your identity provider. And then other companies might reject your identity because hypothetically 1Password only collects a retinal scan, not also DNA, or somesuch, and now we're in a race to the bottom re: just how authenticated one can be. reply juped 3 hours agorootparentIt's hardly tinfoil hattery. If it isn't that (and I'm still not convinced by all the above that it isn't) then it needs to explain exactly how it isn't loudly, repeatedly, clearly, and very prominently. reply __MatrixMan__ 3 hours agorootparentThe messaging around it sure has been heavy on the \"you should do this it's better\" and light on the \"and here are the implications\". reply mooreds 5 hours agorootparentprevThere's a server side component--a public key tied to the private key on a device you control. That public key is also tied to the website that you register the passkey too. > My further impression is that the people who manage the servers (either the authenticating-you server or the supporting-auth-for-you server) will be able to configure allow/deny lists for each other. I haven't seen that in the specification. Every host is assigned one or more public keys (again, corresponding to private keys kept in the device), and I don't think there is a common identifier that could be shared between different hosts. Attestation is not required and seems atypical outside of enterprise use cases. I haven't seen it used at all for consumer use cases. reply yau8edq12i 4 hours agorootparentprevPasskeys simply authenticate a device + maybe a PIN. Not a person. reply shicholas 9 hours agorootparentprevThe Schluss project out of the Netherlands is trying to do just that, really cool stuff! (Schluss.org) reply canadiantim 8 hours agorootparentprevFor a third party acting in this space who could provide a server for the non-tech savvy, what do you think the ideal setup is, infrastructure and architecture wise? reply UniverseHacker 9 hours agorootparentprevYep... I think already companies have a profit incentive to not keep data they don't think will provide them value. They are keeping the data not because they are not thinking about security, but because the data is valuable to them, either to sell to a 3rd party or to better target/market to specific customers. reply alpaca128 1 hour agorootparentReal hacks and leaks have shown that even if there is an incentive to not keep data and minimize damage, it is negligible. If the consequences don't go beyond slightly higher DB sizes nobody cares. The potential cost needs to be much higher than potential profits from selling the data. reply RajT88 9 hours agorootparentprevA lot of companies seem to pay to keep data they are not using. Some because they forgot, some because they have not figured out how to monetize it yet. reply m-p-3 10 hours agorootparentprev> personal data is worth good money Then let's make the penalties substantially higher with the risk it incurs. reply mooreds 10 hours agorootparentIsn't that what the CCPA and other laws are trying to do? https://www.burr.com/newsroom/articles/summary-and-compariso... is an outline of some of the US efforts. reply eddd-ddde 10 hours agorootparentprevEven without reward programs, couldn't they just associate purchases with a given credit card or similar? reply jmward01 9 hours agorootparentThis has been my thinking too. When I make any purchase I am giving everything about myself away now. A long time ago I had the idea to create an 'accountability' e-mail server/credential generator that generated emails/credentials with unique ids along with a note about what it was used for so that you could see exactly who sold your info when you saw junk mail come in. There are now ways to do this but it is still a bit manual. It would be great to have this tied in with auto opt-out and auto reporting of abusers. Of course creating a personal e-mail server now is almost impossible. reply mooreds 10 hours agorootparentprevAbsolutely. And I am sure they do. But rewards programs might make matching easier (across different credit cards and household members). They also are owned by the service provider and don't reveal anything to credit card companies. Again, I'm speculating here. reply jethro_tell 8 hours agorootparentprevI that no you usually give convent as part of the sign up for the rewards program. They can track your cards and if they want to track those back to an address and match them all up, not a big deal, but they can sell it if you agree to their turns. reply NegativeK 9 hours agorootparentprevThey control the registers; they can identify or at least bin users by the selection and quantity of products they buy. reply trimethylpurine 9 hours agorootparentprevWe don't actually care. We're interested in how the product is doing so we know how little we can get away with ordering (to the warehouse). I think the rewards are for sharing with other brands or stores that are owned by the same parent. I doubt they would sell to a competitor. That would directly reduce their own sales. Selling to another industry doesn't make sense either. No one wants more liability for retaining irrelevant data. reply ryan_lane 8 hours agorootparentprev> I don't have any insight into how they use the data, but why would they offer free things (restaurants offer appetizers, grocery stores offer discounts, etc) unless the value they received was more than the cost of the incentive? Ignoring selling the data to brokers, it's not hard to think of some ways to use the data that's beneficial to both you and them: - Inventory management: You buy something low demand, but you do it consistently. If they can match up all the purchases of that item to specific folks, and they know the general frequency at which people buy that item, they can ensure it's stocked when you need it, without the need to greatly overstock it. If you stop coming, they also know they may be able to reduce that stock safely. - Price sensitivity: They do a price increase. Which customers have stopped purchasing the product? Do they need to do a sale on the item for you to purchase it again? Do they need to drop the price? This is more of a benefit on their side than yours, but knowing the most frequent purchasers stopped purchasing it due to an increase could lead to a decrease, where this is harder to determine without good data. - How effective are their sales? Are they targeting them correctly? The discount they offer isn't really a discount. It's a price hike for folks without the loyalty program. reply Terr_ 11 hours agoparentprevDisclosure liability insurance, low premiums if there was nothing to leak. Of course, that assumes a different world where companies actually pay for screwing up in the first place. reply _heimdall 8 hours agoparentprevI agree with the sentiment here, but I'm not sure how that could ever really be implemented. Our laws shouldn't punish people for honestly doing the best they know how to, especially with a caveat that it doesn't matter if it was industry standard. Not only is that confusing and at serious risk of punishing all the wrong people, it creates incentives to help hack your competition and throw them to the legal wolves. reply cuu508 3 hours agorootparent> Our laws shouldn't punish people for honestly doing the best they know how to Sure, but holding on to data you do not strictly need is not doing the best reply Nextgrid 11 hours agoparentprevThe root cause behind the proliferation of privacy breaches is that the legal framework against spying/hacking turns out to have a massive vulnerability. Developing & spreading spyware that collects people's personal data without permission is illegal (you don't even need to leak the collected data for it to be illegal), but wrap it in some flashy marketing, dozens of pages of unscrutable ToS and \"privacy\" policy, and suddenly not only your spyware operation became legal but you can even leak or sell the data in total impunity. This is valid in Europe as much as the US. Keep in mind that even before the GDPR, most countries had some sort of legislation around personal data processing, use and storage, but none of it was enforced. The GDPR is no better in terms of enforcement, which is why you see tons of (non-compliant) \"consent\" flows and spying continues as usual for the most part since businesses entirely based on non-consensual data processing are still alive and kicking. reply andoando 9 hours agoparentprevI disagree. I dont see any reason users wouldn't equally share the risk if neither party did anything wrong. I suppose if the company makes a claim like \"We wont share your data with anyone\" then you could make that point reply teeray 6 hours agorootparentThat assumes users fully understood what they were consenting to. Agreements and Privacy Policies are written to exhaust and bamboozle the users so they just hit “accept.” reply fvdessen 8 hours agoparentprevThis is exactly what the GDPR is all about btw. reply 1vuio0pswjnm7 9 hours agoparentprevData centers could be closed, removing their negative environmental impacts. reply A4ET8a8uTh0 11 hours agoparentprevObviously, IANAL In a sense, that gradation is present for other offenses. You kill a man by accident? It may end up being involuntary manslaughter. You kill that same man with malice and planning? It charge will move to aggravated and premeditated murder. At the end of the day, a life was taken and some level of judicial review should take place. That does not appear to happen for 'hack' events. reply gretch 10 hours agorootparentThe difference between this situation is that you still committed an action, compared to simply being acted on. A better analogy would be like if you were a bank holding peoples' money. Armed assailants break into the money and take it. Is the bank liable because it did not have adequate defenses for the attack? But the bank situation is easy to solve because it's money and money is fungible, so you solve it with insurance. Leaked data can't be revoked and it's hard to quantify. If you make the policy wrong, you essentially end up punishing a victim party (the end users are victims, but the firm that was attacked is also a victim). reply ribosometronome 10 hours agorootparentprevAre involuntary manslaughter cases not usually predicated on some sort of negligence or other criminal activity on the part of the manslaughter? I don't think I've ever heard of anyone being punished for being the person in the wrong place when someone else decides to commit suicide by train or vehicle, for example. If we take the comparison down a step (and into what I think is maybe a more comparable situation), I routinely see warnings in parking lots that they are not liable for stolen property or damage and imagine those are generally probably pretty accurate outside of, again, some negligence on the side of the business. reply Nursie 5 hours agoparentprevThat’s basically what the GDPR tried to do, and a great plan. Instead of making the retention of data a good thing, make it toxic, make it risky. You don’t want PII in your logs, on anyone’s workstation or anywhere else it’s not absolutely necessary. Make it radioactive. reply aeternum 9 hours agoparentprevThe problem is the core idea is flawed. The same concept (don't store the data) was applied to creditcard account data 10 years ago in many point-of-sale systems. Malware simply evolved to logs the data itself. Not collecting user data in the first place might be a solve, but don't let simply not storing it create a false sense of security. Your user's data is still very much at risk. reply dj_mc_merlin 7 hours agorootparentThat's an improvement. It changes the risk profile from \"company whose security practices you have no clue about getting hacked\" to \"one of my personal devices getting infected with malware\", which you can at least do something about. reply montereynack 11 hours agoprevI sympathize a lot with the headline statement; it boggles my mind on a lot of the data residency/integrity/confidentiality measures taken around massive data silos (as well as the infra teams companies bring to bear to manage, scale and then inevitably publish gospel articles on the web about) when companies could just opt… NOT to collect that data? I really like the model of “It stays on your device, we never see it. At most we get bare-minimum location statistics.” Although I question the assertion that their metrics system won’t be turned against them; seems obvious that anything programmed can be reprogrammed or updated, especially in the modern update-focused age. I don’t think they addressed that beyond a general statement that they took pains to assure that their users won’t ever be spied on. Would be interested in a technical article on that. Side note, we at Sentinel Devices are taking exactly this “we don’t hold your data” approach for industrial machinery. Think automated AI pipelines that are air-gapped. And we’re hiring! If you’re interested, reach out to hello@sentineldevices.com reply ChrisMarshallNY 11 hours agoprevThis aligns pretty well, with my own PoV. I can tell you that it has not made me popular with my coworkers. This whole blasted industry has become completely drenched in PID harvesting, and incredibly casual treatment of said PID. My solitaire apps are constantly trying to get me to sign up for leaderboards and challenges. I have been denying pig-butchering (most likely) signups for our new app, at about a 30% rate. It's pretty damn sobering (each signup is manually vetted. We don't really care about quantity). We are restricted to US, Canada, and India, and have barely made any efforts to promote the app, but the scammers jumped all over it. Right now, they are primitive (we have a specific demographic that is hard to fake), but I expect that to change. I have just come to accept that baddies will get in, so it's important that the liquor cabinet be empty, if they try raiding it. reply Terretta 11 hours agoprevThis is why B2B SaaS should stop charging enterprise price for SSO, and just REQUIRE an IdP or the Oauth/OIDC/whatever flow: https://vaultvision.com/blog/what-is-oidc The user experience is these \"continue with\" buttons: - https://id.atlassian.com/login - https://www.xsplit.com/user/auth Then you don't have their account creds to lose. Personal data, PII, etc. is risk debt. reply mhuffman 9 hours agoparentBut then how can I make billions with targeted advertising using their metadata? reply 3pm 11 hours agoprevRelated concept is Datensparsamkeit: https://martinfowler.com/bliki/Datensparsamkeit.html reply nedt 50 minutes agoparentThe even better term is Datenenthaltsamkeit - data abstinence. Not just storing less, but really only storing something if there is no other option. reply internetter 10 hours agoparentprevAlso tangentially related: https://www.w3.org/2001/tag/doc/leastPower.html reply Animats 5 hours agoprevAre they willing to contractually commit to not holding the user's data, with penalties? If not, they're not serious. Remember \"Facebook - It's free and always will be.\" reply SecurityLagoon 7 hours agoprevExactly. I work in cyber security and I am more convinced by the day that the answer is not having the data to steal rather than attempting to mitigate every possible threat. This combined with zero trust and 2fa/passkeys will go much further than many other snake oil solutions the industry loves. reply wolverine876 9 hours agoprevFrom their privacy policy: https://matter.xyz/privacy > If we make changes to this privacy policy, we will update it here and update the effective date at the top. (We can’t email you about changes because we don’t collect everyone’s email addresses.) Changes to this policy will not apply retroactively. Effectively they can change it any time and you probably won't know. If they violate it, what power do you have to enforce it? Pay an attorney six figures? For what damages under what law? Also, I'm not sure what 'retroactively' means here, legally: They have my data and change the policy; can they tomorrow use my data according to the new policy? (Not that it matters much, because I won't know about the changes anyway.) reply andrewnicolalde 9 hours agoparentPerhaps it means that a change to the policy can’t be used to justify actions taken that would have broken a prior version of the policy but which don’t violate the new one. Granted, I don’t have a complete understanding of the legal enforceability of a company’s privacy policy. reply refulgentis 9 hours agoparentprevThis is exactly as good as it gets as a privacy extremist - if they don't have your email, they won't send it, if they change it, the changes won't apply to you. They explicitly ruled out using your data according the new policy - retroactively means, if they update it, the updated version doesn't apply to you. reply kelnos 8 hours agorootparentMy read there is that it won't apply retroactively to data you've already given them, but will apply to data you give them in the future, regardless of they are able to notify you of the change or not. reply wolverine876 9 hours agorootparentprev> if they don't have your email, they won't send it They could post a notice in their app, for example. > They explicitly ruled out using your data according the new policy - retroactively means, if they update it, the updated version doesn't apply to you. I think it's much more vague than that. Maybe it's not retroactive to prior actions of theirs or to prior data they had. You're assuming it's not to prior users. reply arkh 1 hour agoprevThat's one of the principles highlighted by the GDPR: data minimization. Once you can be fined for losing data, it suddenly is not free. No more \"let's store everything and see what we can do with it later\". reply numbers 12 hours agoprevI am more interested in the author's blog navigation, so cool! reply scoates 12 hours agoparentHello. Thanks! This old blog design is showing its age, certainly, but I appreciate the nod to URL Sentences: https://shiflett.org/blog/2010/url-sentences reply krebsonsecurity 8 hours agoprevThis is the way. You don't have to protect what you don't collect. Mullvad is an excellent example of this. They don't even want you to pick a password, and they're fine if you just mail them cash as payment. reply mcdonje 6 hours agoprevSemi-related: The point of GDPR opt-outs is it's something that's offensive to the user, which should give the site owners pause. \"Is it really worth it to jump through these hoops and give the users annoying popups so we can set trackers?\" Instead, the industry rallied around popups and tried to shift the blame to the GDPR. reply tppiotrowski 7 hours agoprevI try to follow this mantra on my website. I don't want user accounts so if you pay for something I email you a unique link to access it. No login and password and you can use a burner email address if you'd like. I don't care. I don't worry what happens with my user data if I get acquired because no one will ever want to buy a business with 0 registered users. :) reply cheema33 6 hours agoprev> If one of our users' data became valuable to an evil nation state and they kidnapped my family, I'll be honest, I'd probably have to hand over the data. How is this prevented, when the evil nation asks you to modify the code to your app to do what you said you wouldn't do? i.e. Steal the data. reply gnicholas 6 hours agoparentEasy: have a livestream of his family and if they’re ever unexpectedly absent then assume that a backdoor was just installed. reply masterrr 10 hours agoprevIt's a very sensitive topic for the health data! Too many apps sending data left and right, 23andme scandal.. very few apps (e.g. Carrot Care on iOS) adopt such great philosophy. reply rangestransform 7 hours agoprevGood principle but the godforsaken states of America will never allow it, KYC and AML laws force financial service providers to keep pictures of your ID for eternity reply SV_BubbleTime 10 hours agoprevThe best infosec advice I ever received was “data is toxic”. reply Fnoord 8 hours agoparentCame here to comment on that: see the essay 'Data Is a Toxic Asset, So Why Not Throw It Out?' by Bruce Schneier [1] [1] https://www.schneier.com/essays/archives/2016/03/data_is_a_t... reply petesergeant 8 hours agoprevDon’t see this yet in the comments so: https://idlewords.com/talks/haunted_by_data.htm reply RaoulP 4 hours agoparentInteresting, thanks. See also Fnoord's comment elsewhere in this thread. reply erehweb 11 hours agoprevThe thing I wonder is - how will Matter make money? Is the plan to just get this via subscriptions? reply Almondsetat 11 hours agoparent>how will Matter make money? it won't, Matter reply indymike 9 hours agoprev> You can't leak users' data if you don't hold it False. You can't leak a user's data if you never have it to begin with. If you process it, you are at risk of leaking it. reply kerkeslager 9 hours agoparentFalse. In order to process a user's data, you must inherently hold it while processing it. Alternatively, stop being pedantic. reply indymike 6 hours agorootparentFalse != True. reply stpn 11 hours agoprevI really love this sentiment. Unfortunately, it also seems really hard to build many kinds of applications in a way that follows this line of thinking. I've been building a personal finance app with privacy in mind, but there are some places where you might begrudgingly \"hold\" a users' data that are just unavoidable. For instance, if we want to be a serious competitor and have bank integrations, then plaid etc. will require you to run a server that can see the data, even if you don't want it. We also don't collect names in our app, just an email, but good luck collecting payments, avoiding fraud or reporting taxes without collecting name and address. We've built our system to be as minimally invasive (e.g. in the above, financial data is only proxied to the user's device, never stored on the server), but that's only the \"intention\" part - there's just not a way to take the full measure. reply MichaelZuo 10 hours agoparentYou can always make an app that is not competitive with those which do store user data… reply stephenr 3 hours agoparentprev> good luck collecting payments, avoiding fraud or reporting taxes without collecting name and address A client of mine collected just shy of $2M last calendar year (2023), and we only store an email address, and a password. The trick is, let the organisations that (apparently) need that extra data, collect the extra data themselves. Payments are offered via PayPal, Stripe and Amazon Pay, using their hosted payment pages. It works amazingly well. The Stripe and PayPal options can even be achieved without JS, if you wish. I believe you could also achieve a similar lack of PII using a JS-heavy 'embedded' solution for Stripe and maybe PayPal, but don't quote me on that. reply stpn 3 hours agorootparentOh yes, to be clear we’re not collecting any of that data ourselves, but it is in our stripe account. I suppose that data isn’t in _our system_ per se, but the arrangement is still relying on our privacy intentions over any systematic guarantee (“we simply don’t have this data”) we could give. reply cvalka 5 hours agoprevDon't request it Don't store it Don't keep it. reply aksss 10 hours agoprevFor a SaaS app I built, I am using a third-party IDP/IDaaS, and thought about holding all user data as metadata in that directory so the only thing my app database stored was a foreign key for user, and I'd be able to really leverage the warrantied security of the provider. In the end I needed faster access to the user metadata so now am storing in database. Meh. Not sure if first idea was a good one or not - I know that depending on the type of breach, that user info stored in the directory could still be accessed, but was really attracted to the idea of not having a damn bit of it in my own db for purpose of getting just a bit closer to the idea of not leaking it if it's not there. reply okeuro49 12 hours agoprev> Our first product is an iOS app designed to help you capture the best moments in your life I have increasingly come to the belief that mediating our life experiences and social interactions through apps isn't good for us. Your website \"Matter\" [1], to be honest, seems completely dystopian to me and an indication of all that's wrong with the relationship between technology and society. [1] https://matter.xyz/ reply YeBanKo 10 hours agoparentTheir website is an epitome of idiocy of modern web product design. They want my email, because we are all \"stardust\". There is no clear explanation of what their product is or how it's different from a photo app and a notebook. Instead of a proper description of their business, they send to the Business Insider article about the founder who wants to prevent unhappiness. reply alistairw 10 hours agorootparentI was reading your comments as a classic overly negative hn comment but then went straight to that website and wow, yep that's bad. I can't tell if they're trying to sell me groundbreaking new brain scan technology or very dodgy supplements. Possibly one of the most vague product sites I've seen and there are a lot that come up on here. I'm surprised this happens in tech so much. I feel I'm always very aware of people in the real world having no idea what I work on, so I always need to give background and context. I have noticed people in other industries haven't experienced that their whole life so often rattle off jargon that means nothing to me. Looks like all the founders are US based, maybe it's a cultural thing. reply YeBanKo 9 hours agorootparentThis is definitely a thing. Few years ago I was at a cloud conference and met who worked for a failure large and known security company in a tech position. They have all kinds of offerings. While he was talking to someone, I decided to speak to one of their sales guys. I shared a bit about what my company did and what kind of infra we were using and then asked him what they offered and specifically what they could offer to us. This was one of dumbest conversation I had ever had. The guys had no f*cking clue what his company was selling beyond \"we sell turn key enterprise security solution\", it was so painful. I even tried to steer him into trying to sell us some vulnerability scans or traffic analysis for threat detection. Yeah, I get it, it maybe niche, he is in a non technical, they have many offerings, he hadn't been there too long (iirc about a year, which is long enough for sales), but it was still unacceptable. To me it's the same phenomenon – lack of clarity in communication – not exactly sure what the root cause. reply hn_throwaway_99 11 hours agoparentprevWhile I actually liked the primary point of the author regarding privacy controls, and I feel some of the commenters here are being a bit harsh regarding tangential issues or missing some of the crux of what he wrote, I also so strongly agree with your point that I couldn't let it go. Apps aren't going to make you happier. If you want to be happier, go for a walk outside and go hang out with your friends, in person. reply Retric 11 hours agorootparentThat assumes quite a bit of freedom that may not exist for many people. An Uber driver waiting for their next passenger isn’t able to go hang out with friends, but they can play on their phone, or read a book. reply dylan604 11 hours agorootparentBefore devices, people were able to find ways to kill time at work just fine. As a human, we're perfectly capable of surviving without the device. I know that seems antithetical to zillenials, but it will be more than okay to look away from the screen for an extended period of time. Personally, having a driver sit their counting the number of red cars or counting the number of different state license plates is equally purpose serving as doom scrolling. In fact, it's probably much less detrimental to their mental health. It saddens me a wee bit that people think that the devices much be attended to to this extent. reply throwawaysleep 11 hours agorootparentUsers didn’t consider them just fine, as they immediately abandoned them when given the chance. reply albumen 10 hours agorootparentThat doesn't mean it's not harming them. Have addicts made the right choice by indulging their weakness? reply Retric 8 hours agorootparentNew and fun isn't the same as addictive. We don't consider people watching TV, listing to the radio, or reading books as addicts yet people decried each of them as they became ever more popular for ruining the youth etc. People like stimulation and seem to indulge when it's new, but most people also get used to it relatively quickly. reply dylan604 7 hours agorootparentI think you're trying to move the goal posts. The apps on the new are absolutely without a shadow of doubt trying to make their users addicted. To even suggest they are not addictive is beyond pale, and makes you look like a not serious attempt at the discussion, or worse. Your second sentence is null after your first. reply Retric 6 hours agorootparentPay to win apps aiming for addiction get a tiny number of whales out of millions of people. So yes apps try very hard, but the vast majority of people just don’t get addicted long term just obsessed for a short period. Compare retention numbers between smoking and clash of clans, a clearly successful pay to win game, and it’s not even close. We could talk about various other apps, but nobody has actually nailed addiction for the general population just the people highly susceptible to such behaviors. reply dylan604 6 hours agorootparentare you willfully being obtuse to the behaviors of the social apps FB, Tiktok, Twit...er,X and the ilk? Games of course are trying to be addictive to get you to buy more IAP/lootbox/otherHandInPocket concepts. it's like you think a device is only able to play games which is clearly ludicrous. reply Retric 6 hours agorootparentI simply used gaming to make it clear attempting to be addictive wasn’t the same as actually being addictive. Social Apps rise and fall in popularity just like everything else. Meta has billions of users but that’s split across 4 platforms FB, WhatsApp, Instagram, and Messenger. So clearly popularity isn’t the same as addiction otherwise their FB app would be all they need. Go back a few years and Netflix seem addictive as people binged shows, but I doubt anyone is seriously suggesting they are addictive today. Q.E.D. New and fun isn't the same as addictive. reply dylan604 5 hours agorootparentThe only QED is your circular logic reply josephg 11 hours agorootparentprevSure; but it’s probably true for most of us most of the time. I’m on HN right now instead of playing piano or going for a walk. I think I need the reminder sometimes. reply djbusby 11 hours agorootparentGo for a walk right now! reply gremlinunderway 11 hours agorootparentprevYeah but saying \"you ought to go outside / relax / rest / spend time with family\" and then saying \"not everyone can because shit sucks\" is missing the point. Shit does suck, for a lot of people, in a lot of ways. Acknowledging that is good, but then saying the alternative for that is people to play on their phones? How about advocating for people to be able to make a wage or living and have time to hang out with friends? reply gumby 10 hours agoparentprevBack when my kid was born I bought a video cam. I upgraded the videocam a couple of times, but I realized I didn't use it much because when I did I was videoing not being part of what was going on. As a result there isn't much video of the kid, but I don't regret it. By the timewe switched to video cams in our pockets, I had pretty much given up, and apart from a few few-second captures, I haven't shot any video in years. And TBH I don't miss it at all. Apps like this are simply more of the same. reply forgotmyinfo 12 hours agoprevWhat happens when Matter gets acquired? I'm sorry, but all this self back-patting is a bit too little too late for this jaded guy, especially because a thousand other companies have made the same promises in cheery blog posts, before something happens and my social security number winds up on a sticky note on some hacker's monitor in Belarus. Hell, I've worked for companies where I was forced to break users' trust because some executive critter told me to when it was clear the profit faucet wasn't opened nearly enough. So thanks, but this isn't enough anymore. We need laws that will guarantee that every company that handles our data will do it thoughtfully and safely. In the meantime, I'm not expecting much. reply jacurtis 11 hours agoparent> before something happens and my social security number winds up on a sticky note on some hacker's monitor in Belarus Isn't the point of the article that they can't leak something they don't have? So if I never get your social security number from you, then I have zero risk of leaking it or exposing it to hackers. I can't give them (intentionally or unintentionally) something that I don't possess. The author says: > Given these criteria and extremes, we decided that our best course of action is to just never have our users' private data. --- To your next question on what happens if Matter is acquired. Well the app might stop working or change how it works or have new logo in the corner, but your data never left your device, so you don't really have to worry about it being leaked to Belarus. reply ndr 11 hours agorootparent> Well the app might [...] change how it works [...] but your data never left your device, so you don't really have to worry about it being leaked to Belarus. You're one update away from having an app that has access to all its data and can ship it anywhere. Do you keep updates off? reply AlienRobot 10 hours agorootparentI wish I could keep my updates off. Every time I turn on my computer dnfdragora is like \"there are 35 new updates!\" Oh yeah? But my computer is working. Those updates could fix problems that I don't have but could break stuff I have as well. I'm not updating until they release Fedora 40. (my nvidia driver stopped working when I upgraded to 39, again...) To begin with who thought these notifications were a good idea? Just appear meekly on the system tray when you have something to say. The only time a popup is acceptable is if it says \"yo, your computer is on fire.\" Anything less is unnecessary distraction. I want my software as-is, changing only when I want it to change. The other day a Windows update removed my \"show desktop\" button from the task bar to insert a copilot button. Who asked for this? The taskbar changes when I say it changes! I started using the program because I liked the way it was. If it wasn't the way it was I wouldn't have started using it, so why change? To make matters worse, I don't think there has ever been a time a software updated that I said \"they finally added X!\" It just never happens. It's insane. Things really only get worse with time. Ten years ago GIMP didn't have nondestructive editing. It still doesn't. I'm still waiting for it. They said it will come in GIMP 3, for years. I feel like that update is just never coming. We're at GIMP 2.99.18 now. Can you believe it? 2.99.18. Who even reaches minor version .99?! reply albumen 10 hours agorootparentI can do anecdata too. Photoshop added content-aware fill, and then generative fill. These have been useful additions for me, saving time that was previously tedious stamp-tool work. reply photonthug 10 hours agorootparentYou missed the point. It’s not about whether updates are good or bad, because yes anecdotally it could be either. It’s about whether they are consensual. And whether constant harassment that you can’t opt out of counts as consent when you give up or misclick reply ndr 10 hours agorootparentprevThis is viable when your app works completely offline. As soon as it has a server to talk to things changes. It becomes rather expensive to maintain a server that has to support any previous client, or to support all the users who don't know how to update. In practice auto-update is the best default. Android lets you turn it off. On iOS I don't know. reply tschwimmer 12 hours agoparentprevHey, no need to cast aspersions on the infosec practices of Belorussian hackers, I bet they store their stolen credentials in an encrypted SQLite database as per industry best practice. reply scoates 12 hours agoparentprevHello. Agreed that we need comprehensive privacy reform. You should probably read the article, though. (-; I have access to everything (on the tech side) at Matter, and if you put your social security number into the app, I wouldn't be able to access it to write it on a sticky note. That's the whole point. PS I'm also old and jaded. (-; reply travisjungroth 11 hours agorootparentI don’t think the article really answers this. All these decisions you’ve made to not store data are decisions that you could unmake. To put it concretely: if everyone at Matter tomorrow became malevolent and wanted user data, what happens? For example, if you push an app that sends home my private text, how would I know? Could you? reply defen 10 hours agorootparentIsn't this an argument against putting any personal information into any app? Signal could turn malevolent tomorrow and start sending all your chats to their servers, which could have life-threatening implications for people vs just potentially being embarrassing. reply travisjungroth 5 hours agorootparentI put data into Google Docs knowing it lives on their servers. So there’s no problem there. Signal has an open source client. Big difference for these claims. reply bamnet 9 hours agoparentprevThis isn't just a theoretical point. Chrome extensions are the canonical example of products which start off with the best intentions, get acquired, and then ... reply defen 12 hours agoparentprev> What happens when Matter gets acquired That's a major point that's addressed in the blog post, did you read it? reply abound 11 hours agorootparentNot sure about GP, but I did read the post. If they get acquired, I don't see anything stopping the acquirer from pushing an update that decrypts stuff and sends the plaintext to the servers. reply filleduchaos 10 hours agorootparentI'm rather baffled at this level of nitpicking. Yes, if the software was being written by completely different people with completely different goals they might then start to acquire user data but what does that have to do with the point (that data this team and this management don't have cannot be leaked)? reply travisjungroth 10 hours agorootparentBecause their current solution doesn’t meet their own stated goals. > even if we are competent enough to prevent a leak from ever happening, and even if our users trust us to do what we say, we must be resilient to being strong-armed by a future controlling power (e.g. if someone we don't trust buys us) They could be strong armed into collecting data and then handing it over. reply filleduchaos 8 hours agorootparentAnd you as a customer can simply stop using their services if you no longer trust their intentions and (and this is a very clear and straightforward point) the company and the new controlling power would have nothing on you. Because it did not exist in the first place. Why are so many of you so keen for them to be \"wrong\"? Like what even is the alternative approach here supposed to be? Don't build a product in the first place? reply travisjungroth 5 hours agorootparent> And you as a customer can simply stop using their services if you no longer trust their intentions The original premise of the article is we don’t have to be concerned with their intentions. This is false. > Why are so many of you so keen for them to be \"wrong\"? I’d rather they were right. But they are wrong. > Like what even is the alternative approach here supposed to be? Don't build a product in the first place? Don’t say you can do things you can’t. I don’t have to offer a solution to point out they’re not offering one either. reply lebean 7 hours agorootparentprevNo you see, at any moment this company can get acquired and can start pushing malware as updates. It's quite an elementary mistake to not account for this possibility, and the author of this post should hang their head in shame for even pretending to have a solution. /s reply photonthug 10 hours agorootparentprevIs there any kind of legal promise that could be made and not rescinded by the board, not swept away by mergers and acquisitions? I assume not but that’s almost what is needed here more than a software architecture fix which, no matter how well designed, is only as stable as the whims of internal stakeholders. reply travisjungroth 8 hours agorootparentI think you could make the alerting louder. Hire an independent auditing firm and create some contract around what to do if they fail. A closed source client is fundamentally incompatible with the claims they want to make. reply filleduchaos 8 hours agorootparentprevLegal promises don't enforce themselves. reply stvltvs 10 hours agorootparentprevI don't track management changes for the apps I use because who has the time? How can we protect ourselves against a malicious company changing their tech behind the scenes? reply abound 6 hours agorootparentMy personal solution is just to self-host anything important or sensitive (password manager, file storage, photo storage, etc). Audit the code as desired, pin to specific versions, run on a private network. reply ndr 11 hours agorootparentprevThis. And how likely is it that if their users value their app's data then there's an acquirer willing to wipe out all the users' data from the phones before they take over? reply hn_throwaway_99 11 hours agoparentprevWhile I agree with your sentiment, after re-reading the post and looking at some of the blog posts, I think you missed a major point, that being: 1. You can't leak what you don't have. That is, even if the company gets bought out or is hacked, if they don't have the data, there is nothing to leak. This point is also at least partially enforced by another point from the post: 2. Advanced app users can audit their network traffic from the app Now, granted, I wouldn't expect many users to do this, but highlighting it at least serves as a warning that it should be harder for the app to surreptitiously change what is sent to the server (and to emphasize, I know this can be worked/hacked around, but I don't think working around this could ever be done with plausible deniability). Given the fact that companies and products jettison their high-minded policies as soon as it becomes economically inconvenient, the only other thing I'd recommend for the author is to have a good, simple export tool, e.g. something that dumps all the \"memories\" to a directory or PDF file. The post talks about backup and restore, but if I were a potential user I'd like to know that if the company does kick their privacy policy to the curb at some point that I could get all of the investment and data out of the app without needing to continue to rely on the app for at least the base data I put into it. reply nicksloan 11 hours agorootparentHi, I also work at Matter. Our current backup/restore implementation exports a zip file of complete JSON data. We will improve backups in the future, but no pull request will be merged to remove the existing implementation for at least as long as I’m leading the app team. reply jazdw 10 hours agoprev [–] Except you can leak data even if you don't hold it. You are focusing on data at rest. Not storing the data obviously helps massively, but a bug or maliciously inserted code could lead to user data becoming compromised. reply xu_ituairo 10 hours agoparent [–] We shouldn’t let perfect be the enemy of good reply jazdw 9 hours agorootparent [–] We shouldn't make blanket statements reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author shares their transition from working in academia to achieving the role of VP of Technology at the startup Matter, which centers on enhancing user happiness through the storage of positive memories.",
      "Matter prioritizes user privacy by abstaining from gathering personal data, employing security protocols to safeguard user information, and avoiding the use of user accounts or email addresses for data association.",
      "Backing up data is encouraged by the app to mitigate the risk of data loss, and the author takes pride in supervising Matter's privacy initiatives."
    ],
    "commentSummary": [
      "The discussion emphasizes data privacy and security, particularly user data storage, addressing data breaches, passkeys for authentication, GDPR impact, and strategies to reduce data collection.",
      "It highlights concerns like data sharing, privacy policies, software update challenges, and risks from companies like Matter affecting data practices.",
      "Proposed solutions include hiring auditors, legal commitments, and user-friendly data export tools to tackle privacy issues effectively."
    ],
    "points": 377,
    "commentCount": 129,
    "retryCount": 0,
    "time": 1711660750
  },
  {
    "id": 39852118,
    "title": "AI Chatbots Enhanced Through LLMs' Simple Knowledge Retrieval",
    "originLink": "https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325",
    "originBody": "Researchers demonstrate a technique that can be used to probe a model to see what it knows about new subjects. Adam ZeweMIT News Publication Date: March 25, 2024 Press Inquiries Caption: Researchers from MIT and elsewhere found that complex large language machine-learning models use a simple mechanism to retrieve stored knowledge when they respond to a user prompt. The researchers can leverage these simple mechanisms to see what the model knows about different subjects, and also possibly correct false information that it has stored. Credits: Image: iStock Large language models, such as those that power popular artificial intelligence chatbots like ChatGPT, are incredibly complex. Even though these models are being used as tools in many areas, such as customer support, code generation, and language translation, scientists still don’t fully grasp how they work. In an effort to better understand what is going on under the hood, researchers at MIT and elsewhere studied the mechanisms at work when these enormous machine-learning models retrieve stored knowledge. They found a surprising result: Large language models (LLMs) often use a very simple linear function to recover and decode stored facts. Moreover, the model uses the same decoding function for similar types of facts. Linear functions, equations with only two variables and no exponents, capture the straightforward, straight-line relationship between two variables. The researchers showed that, by identifying linear functions for different facts, they can probe the model to see what it knows about new subjects, and where within the model that knowledge is stored. Using a technique they developed to estimate these simple functions, the researchers found that even when a model answers a prompt incorrectly, it has often stored the correct information. In the future, scientists could use such an approach to find and correct falsehoods inside the model, which could reduce a model’s tendency to sometimes give incorrect or nonsensical answers. “Even though these models are really complicated, nonlinear functions that are trained on lots of data and are very hard to understand, there are sometimes really simple mechanisms working inside them. This is one instance of that,” says Evan Hernandez, an electrical engineering and computer science (EECS) graduate student and co-lead author of a paper detailing these findings. Hernandez wrote the paper with co-lead author Arnab Sharma, a computer science graduate student at Northeastern University; his advisor, Jacob Andreas, an associate professor in EECS and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL); senior author David Bau, an assistant professor of computer science at Northeastern; and others at MIT, Harvard University, and the Israeli Institute of Technology. The research will be presented at the International Conference on Learning Representations. Finding facts Most large language models, also called transformer models, are neural networks. Loosely based on the human brain, neural networks contain billions of interconnected nodes, or neurons, that are grouped into many layers, and which encode and process data. Much of the knowledge stored in a transformer can be represented as relations that connect subjects and objects. For instance, “Miles Davis plays the trumpet” is a relation that connects the subject, Miles Davis, to the object, trumpet. As a transformer gains more knowledge, it stores additional facts about a certain subject across multiple layers. If a user asks about that subject, the model must decode the most relevant fact to respond to the query. If someone prompts a transformer by saying “Miles Davis plays the. . .” the model should respond with “trumpet” and not “Illinois” (the state where Miles Davis was born). “Somewhere in the network’s computation, there has to be a mechanism that goes and looks for the fact that Miles Davis plays the trumpet, and then pulls that information out and helps generate the next word. We wanted to understand what that mechanism was,” Hernandez says. The researchers set up a series of experiments to probe LLMs, and found that, even though they are extremely complex, the models decode relational information using a simple linear function. Each function is specific to the type of fact being retrieved. For example, the transformer would use one decoding function any time it wants to output the instrument a person plays and a different function each time it wants to output the state where a person was born. The researchers developed a method to estimate these simple functions, and then computed functions for 47 different relations, such as “capital city of a country” and “lead singer of a band.” While there could be an infinite number of possible relations, the researchers chose to study this specific subset because they are representative of the kinds of facts that can be written in this way. They tested each function by changing the subject to see if it could recover the correct object information. For instance, the function for “capital city of a country” should retrieve Oslo if the subject is Norway and London if the subject is England. Functions retrieved the correct information more than 60 percent of the time, showing that some information in a transformer is encoded and retrieved in this way. “But not everything is linearly encoded. For some facts, even though the model knows them and will predict text that is consistent with these facts, we can’t find linear functions for them. This suggests that the model is doing something more intricate to store that information,” he says. Visualizing a model’s knowledge They also used the functions to determine what a model believes is true about different subjects. In one experiment, they started with the prompt “Bill Bradley was a” and used the decoding functions for “plays sports” and “attended university” to see if the model knows that Sen. Bradley was a basketball player who attended Princeton. “We can show that, even though the model may choose to focus on different information when it produces text, it does encode all that information,” Hernandez says. They used this probing technique to produce what they call an “attribute lens,” a grid that visualizes where specific information about a particular relation is stored within the transformer’s many layers. Attribute lenses can be generated automatically, providing a streamlined method to help researchers understand more about a model. This visualization tool could enable scientists and engineers to correct stored knowledge and help prevent an AI chatbot from giving false information. In the future, Hernandez and his collaborators want to better understand what happens in cases where facts are not stored linearly. They would also like to run experiments with larger models, as well as study the precision of linear decoding functions. “This is an exciting work that reveals a missing piece in our understanding of how large language models recall factual knowledge during inference. Previous work showed that LLMs build information-rich representations of given subjects, from which specific attributes are being extracted during inference. This work shows that the complex nonlinear computation of LLMs for attribute extraction can be well-approximated with a simple linear function,” says Mor Geva Pipek, an assistant professor in the School of Computer Science at Tel Aviv University, who was not involved with this work. This research was supported, in part, by Open Philanthropy, the Israeli Science Foundation, and an Azrieli Foundation Early Career Faculty Fellowship. Share this news article on: X Facebook LinkedIn Reddit Print Paper Paper: “Linearity of Relation Decoding in Transformer Language Models” Related Links Evan Hernandez Jacob Andreas Language and Intelligence Group Computer Science and Artificial Intelligence Laboratory Department of Electrical Engineering and Computer Science School of Engineering MIT Schwarzman College of Computing Related Topics Research Computer science and technology Artificial intelligence Machine learning Algorithms Human-computer interaction Computer Science and Artificial Intelligence Laboratory (CSAIL) Electrical Engineering & Computer Science (eecs) School of Engineering MIT Schwarzman College of Computing Related Articles Demystifying machine-learning systems AI agents help explain other AI systems 3 Questions: Jacob Andreas on large language models Solving a machine-learning mystery Previous item Next item",
    "commentLink": "https://news.ycombinator.com/item?id=39852118",
    "commentBody": "LLMs use a surprisingly simple mechanism to retrieve some stored knowledge (news.mit.edu)347 points by CharlesW 19 hours agohidepastfavorite124 comments retrofrost 16 hours agoThis is amazing work, but to me it highlights some of the biggest problems in the current AI zeitgeist, we are not really trying to work on any neuron or ruleset that isnt much different from the perceptron thats just a sumnation function. Is it really that suprising that we just see this same structure repeated in the models. Just because feedforward topologies with single neuron steps are the easiest to train and run on graphics cards does that really make them the actual best at accomplishing tasks? We have all sorts of unique training methods and encoding schemes that don't ever get used because the big libraries don't support them. Until, we start seeing real varation in the fundamental rulesets of neuralnets we are always just going to be fighting against the fact these are just perceptrons with extra steps. reply visarga 16 hours agoparent> Just because feedforward topologies with single neuron steps are the easiest to train and run on graphics cards does that really make them the actual best at accomplishing tasks? You are ignoring a mountain of papers trying all conceivable approaches to create models. It is evolution by selection, in the end transformers won. reply nicklecompte 15 hours agorootparentHis point is that \"evolution by selection\" also includes that transformers are easy to implement with modern linear algebra libraries and cheap to scale on current silicon, both of which are engineering details with no direct relationship to their innate efficacy at learning (though indirectly it means you scale up the training data for more inefficient learning). reply wanderingbort 14 hours agorootparentI think it is correct to include practical implementation costs in the selection. Theoretical efficacy doesn’t guarantee real world efficacy. I accept that this is self reinforcing but I favor real gains today over potentially larger gains in a potentially achievable future. I also think we are learning practical lessons on the periphery of any application of AI that will apply if a mold-breaking solution becomes compelling. reply retrofrost 15 hours agorootparentprevJust because papers are getting published doesn't mean its actually gaining any traction. I mean we have known that time series of signals recieves plays a huge role in how bio neurons functionally operate and yet we have nearly no examples of spiking networks being pushed beyond basic academic exploration. We have known glial cells play a critical role in biological neural and yet you can probably count the number of papers that examine using an abstraction of that activity in neural net, on both your hands and toes. Neuroevolution using genetic algorithms has been basically looking for a big break since NEAT. Its the height of hubris to say that we have peaked with transformers when the entire field is based on not getting trapped in local maxima's. Sorry to be snippy, but there is so much uncovered ground its not even funny. reply gwervc 15 hours agorootparent\"We\" are not forbidding you to open a computer, start experimenting and publishing some new method. If you're so convinced that \"we\" are stuck in a local maxima, you can do some of the work you are advocating instead of asking other to do it for you. reply Kerb_ 15 hours agorootparentYou can think chemotherapy is a local maxima for cancer treatment and hope medical research seeks out other options without having the resources to do it yourself. Not all of us have access to the tools and resources to start experimenting as casually as we wish we could. reply erisinger 14 hours agorootparentNot a single one of you bigbrains used the word \"maxima\" correctly and it's driving me crazy. reply antonvs 9 hours agorootparent“Maxima” sounds fancy, making it catnip for people trying to sound smart. reply tschwimmer 12 hours agorootparentprevyeah, not a Nissan in sight reply vlovich123 14 hours agorootparentprevAs I understand it a local maxima means you’re at a local peak but there may be higher maximums elsewhere. As I read it, transformers are a local maximum in the sense of outperforming all other ML techniques as the AI technique that gets the closest to human intelligence. Can you help my little brain understand the problem by elaborating? Also you may want to chill with the personal attacks. reply erisinger 14 hours agorootparentNot a personal attack. These posters are smarter than I am, just ribbing them about misusing the terminology. \"Maxima\" is plural, \"maximum\" is singular. So you would say \"a local maximum,\" or \"several local maxima.\" Not \"a local maxima\" or, the one that really got me, \"getting trapped in local maxima's.\" As for the rest of it, carry on. Good discussion. reply FeepingCreature 14 hours agorootparentA local maxima, that is, /usr/bin/wxmaxima... reply erisinger 13 hours agorootparentTouché... reply gyrovagueGeist 12 hours agorootparentprevWhile \"local maximas\" is wrong, I think \"a local maxima\" is a valid way to say \"a member of the set of local maxima\" regardless of the number of elements in the set. It could even be a singleton. reply dragonwriter 5 hours agorootparentNo, a member of the set of local maxima is a a local maximum, just like a member of the set of people is a person, because it is a definite singular. The plural is also used for indefinite number, so “the set of local maxima” remains correct even if the set has cardinality 1, but a member of the set has definite singular number irrespective of the cardinality of the set. reply Tijdreiziger 12 hours agorootparentprevYou can't have one maxima in the same way you can't have one pencils. That's just how English works. reply pixl97 11 hours agorootparentYou can't have one local maxima, it would be the global maxima. So by saying local maxima you're assuming the local is just a piece of a larger whole, even if that global state is otherwise undefined. reply reverius42 6 hours agorootparentNo, you can’t have one local maxima, or one global maxima, because it’s plural. You can have one local or global maximum, or two (or more) local or global maxima. reply folli 5 hours agorootparentprev\"You can't have one local pencils, it would be the global pencils\" reply mikewarot 14 hours agorootparentprevMNIST and other small and easy to train against datasets are widely available. You can try out anything you like even with a cheap laptop these days thanks to a few decades of Moore's law. It is definitely NOT out of your reach to try any ideas you have. Kaggle and other sites exist to make it easy. Good luck! 8) reply retrofrost 13 hours agorootparentMy pet project has been trying to use elixir with NEAT or HyperNEAT to try and make a spiking network, then when thats working decently drop some glial interactions I saw in a paper. It would be kinda bad at purely functional stuff, but idk seems fun. The biggest problems are time and having to do a lot of both the evolutionary stuff and the network stuff. But yeah the ubiquity of free datasets does make it easy to train. reply haltIncomplete 14 hours agorootparentprevAll we’re doing is engineering new data compression and retrieval techniques: https://arxiv.org/abs/2309.10668 Are we sure there’s anything “net new” to find within the same old x86 machines, within the same old axiomatic systems of the past? Math is a few operations applied to carving up stuff and we believe we can do that infinitely in theory. So “all math that abides our axiomatic underpinnings” is valid regardless if we “prove it” or not. Physical space we can exist in, a middle ground of reality we evolved just so to exist in, seems to be finite; I can’t just up and move to Titan or Mars. So our computers are coupled to the same constraints of observation and understanding as us. What about daily life will be upended reconfirming decades old experiment? How is this not living in sunk cost fallacy? When all you have is a hammer… I’m reminded of Einstein’s quote about insanity. reply aldousd666 7 hours agorootparentEinstein didn't say that about insanity, but... systems exist and are consistently described by particular equations at particular scales. Sure we can say everything is quantum mechanics, even classical physics can technically be translated as a series of wave functions that explain the same behaviors we observe, if we could measure it... But it's impractical, and some of the concepts we think of as fundamental to certain scales, like nucleons, didn't exist at others, like equations that describe the energy of empty space. So, it's maybe not quite a fallacy to point out that not every concept we find to be useful, like deep learning inference, encapsulate every rule at every scale that we know about down to the electrons, cogently. Because none of our theories do that, and even if they did, we couldn't measure or process all the things needed to check and see if we're even right. So we use models that differ from each other, but that emerge from each other, but only when we cross certain scale thresholds. reply samus 10 hours agorootparentprevIf you abstract far enough then yes, everything what we are doing is somehow akin to what we have done before. But that then also applies to what Einstein has done. reply leoc 14 hours agorootparentprev(The singulars are ‘maximum’ and ‘minimum’, ‘maxima’ and ‘minima’ are the plurals.) reply samus 10 hours agorootparentprevWho said that we peaked with transformers? I sure hope we did not. The current focus on them is just institutional inertia. Worst case another AI winter comes, at the end of which a newer, more promising technology would manage to attract funding anew. reply typon 15 hours agorootparentprevDo you really think that transformers came to us from God? They're built on the corpses of millions of models that never went anywhere. I spent an entire year trying to scale up a stupid RNN back in 2014. Never went anywhere, because it didn't work. I am sure we are stuck in a local minima now - but it's able to solve problems that were previously impossible. So we will use it until we are impossibly stuck again. Currently, however, we have barely begun to scratch the surface of what's possible with these models. reply foobiekr 14 hours agorootparentprev\"won\" They barely work for a lot of cases (i.e., anything where accuracy matters, despite the bubble's wishful thinking). It's likely that something will sunset them in the next few years. reply victorbjorklund 14 hours agorootparentThat is how evolution works. Something wins until something else comes along and win. And so on forever. reply Retric 10 hours agorootparentEvolution generally favors multiple winners in different roles over a single dominate strategy. People tend to favor single winners. reply advael 7 hours agorootparentI both think this is a really astute and important observation and also think it's an observation that's more true locally than of people broadly. Modern neoliberal business culture generally and the consolidated current incarnation of the tech industry in particular have strong \"tunnel vision\" and belief in chasing optimality compared to many other cultures, both extant and past reply imtringued 2 hours agorootparentIn neoclassical economics, there are no local maxima, because it would make the math intractable and expose how much of a load of bullshit most of it is. reply refulgentis 11 hours agorootparentprevIt seems cloyingly performative grumpy old man once you're at \"it barely works and it's a bubble and blah blah\" in response to a discussion about their comparative advantage (yeah, they won, and absolutely convincingly so) reply wizzwizz4 9 hours agorootparentThat's like saying Bitcoin won cryptography. reply jjtheblunt 3 hours agorootparentprev> in the end transformers won we're at the end? reply antonvs 9 hours agorootparentprevI’d say it’s more that transformers are in the lead at the moment, for general applications. There’s no rigorous reason afaik that it should stay that way. reply dartos 16 hours agorootparentprevI mean RWKV seems promising and isn’t a transformer model. Transformers have first mover advantage. They were the first models that scaled to large parameter counts. That doesn’t mean they’re the best or that they’ve won, just that they were the first to get big (literally and metaphorically) reply tkellogg 15 hours agorootparentYeah, I'd argue that transformers created such capital saturation that there's a ton of opportunity for alternative approaches to emerge. reply dartos 14 hours agorootparentSpeak of the devil. Jamba just hit the front page. reply refulgentis 11 hours agorootparentprevIt doesn't seem promising, a one man band has been doing a quixotic quest based on intuition and it's gotten ~nowhere, and it's not for lack of interest in alternatives. There's never been a better time to have a different approach - is your metric \"times I've seen it on HN with a convincing argument for it being promising?\" -- I'm not embarrassed to admit that is/was mine, but alternatively, you're aware of recent breakthroughs I haven't seen. reply szundi 9 hours agorootparentprev“end” reply ikkiew 14 hours agoparentprev> the perceptron thats just a sumnation[sic] function What would you suggest? My understanding of part of the whole NP-Complete thing is that any algorithm in the complexity class can be reduced to, among other things, a 'summation function'. reply posix86 13 hours agoparentprevI don't understand enough about the subject to say, but to me it seemed like yes, other models have better metrics with equal model size i.t.o. number of neurons or asymptotic runtime, but the most important metric will always be accuracy/precision/etc for money spent... or in other words, if GPT requires 10x number of neurons to reach the same performance, but buying compute & memory for these neuros is cheaper, then GPT is a better means to an end. reply ldjkfkdsjnv 15 hours agoparentprevCannot understand people claiming we are in a local maxima, when we literally had an ai scientific breakthrough only in the last two years. reply xanderlewis 13 hours agorootparentWhich breakthrough in the last two years are you referring to? reply 6gvONxR4sf7o 10 hours agorootparentIf you had to reduce it to one thing, it's probably that language models are capable few shot and zero shot learners. In other words, training a model to simply predict the next word on naturally occurring text, you end up with an tool you can use for generic tasks, roughly speaking. reply xyzzy_plugh 7 hours agorootparentIt turns out a lot of tasks are predictable. Go figure. reply ldjkfkdsjnv 13 hours agorootparentprevthe LLM scaling law reply blueboo 14 hours agoparentprevThe bitter lesson, my dude. http://www.incompleteideas.net/IncIdeas/BitterLesson.html If you find a simpler, trainable structure you might be onto something Attempts to get fancy tried and died reply derefr 18 hours agoprevHelp me understand: when they say that the facts are stored as a linear function… are they saying that the LLM has a sort of N-dimensional “fact space” encoded into the model in some manner, where facts are embedded into the space as (points / hyperspheres / Voronoi manifolds / etc); and where recalling a fact is — at least in an abstract sense — the NN computing / remembering a key to use, and then doing a key-value lookup in this space? If so: how do you embed a KV-store into an edge-propagated graphical model? Are there even any well-known techniques for doing that “by hand” right now? (Also, fun tangent: isn't the \"memory palace\" memory technique, an example of human brains embedding facts into a linear function for easier retrieval?) reply jacobn 18 hours agoparentThe fundamental operation done by the transformer, softmax(Q.K^T).V, is essentially a KV-store lookup. The Query is dotted with the Key, then you take the softmax to pick mostly one winning Key (the Key closest to the Query basically), and then use the corresponding Value. That is really, really close to a KV lookup, except it's a little soft (i.e. can hit multiple Keys), and it can be optimized using gradient descent style methods to find the suitable QKV mappings. reply naveen99 17 hours agorootparentNot sure there is any real lookup happening. Q,K are the same and sometimes even v is the same… reply toxik 15 hours agorootparentQ, K, V are not the same. In self-attention, they are all computed by separate linear transformation of the same input (ie the previous layer’s output). In cross-attention even this is not true, then K and V are computed by linear transformation of whatever is cross-attended, and Q is computed by linear transformation of the input as before. reply ewild 15 hours agorootparentyeah a common misconception people think because the input is the same they forget that their is a pre attention linear transofrmation for q k and v (using the decoder only version obv v is diff with encoder decoder bert style) reply bionhoward 18 hours agoparentprev[Layer] Normalization constrains huge vectors representing tokens (input fragments) to positions on a unit ball (I think), and the attention mechanism operates by rotating the unconstrained ones based on the sum of their angles relative to all the others. I only skimmed the paper but believe the point here is that there are relatively simple functions hiding in or recoverable from the bigger network which specifically address certain categories of relationships between concepts. Since it would, in theory, be possible to optimize such functions more directly if they are possible to isolate, could this enable advances in the way such models are trained? Absolutely. After all, one of the best criticisms of “modern” AI is the notion we’re just mixing around a soup of linear algebra. Allowing some sense of modularity (reductionism) could make them less of a black box and more of a component driven approach (in the lagging concept space and not just the leading layer space) reply samus 10 hours agoparentprevThe memory palace is a hack that works because in an evolutionary sense our brain's purpose is to help us navigate our world and be effective in it. To do that, it has to be really good at remembering locations, to plot paths through and between them, and to translate that into speech or motion. reply thfuran 18 hours agoparentprev>isn't the \"memory palace\" memory technique, an example of human brains embedding facts into a linear function for easier retrieval? I'm not sure I see how that's a linear function. reply mikewarot 14 hours agoprevI wonder if this relation still holds with newer models that have have even more compute thrown at them? My intuition is that the structure inherent to language makes Word2Vec possible. Then training on terabytes of human text encoded with Word2Vec + Positional Encoding makes it possible to then have the ability to predict the next encoding at superhuman levels of cognition (while training!). It's my sense that the bag of words (as input/output method) combined with limited context windows (to make Positional Encoding work) is a huge impedance mismatch to the internal cognitive structure. Thus I think that given the orders of magnitude more compute thrown at GPT-4 et al, it's entirely possible new forms of representation evolved and remain to be discovered by humans probing through all the weights. I also think that MemGPT could, eventually, become an AGI because of the unlimited long term memory. More likely, though, I think it would be like the protagonist in Memento[1]. [1] https://en.wikipedia.org/wiki/Memento_(film) [edit - revise to address question] reply autokad 13 hours agoparentsorry if I misread your comment, but you seem to be indicating that LLMs such as chat gpt (which use gpt 3+) are bag of words models? they are sequence models. reply mikewarot 12 hours agorootparentI edited my response... I hope it helps... my understanding is that the output gives probabilities for all the words, then one is chosen with some random thrown in (via the #temperature) then fed back in... which to me seems to equate to bag of words. Perhaps I mis-understood the term. reply smaddox 12 hours agorootparentBag of words models use a context that is a \"bag\" (i.e. an unorder map from elements to their counts) of words/tokens. GPT's use a context that is a sequence (i.e. an ordered list) of words/tokens. reply mike_hearn 17 hours agoprevThis is really cool. My mind goes immediately to what sort of functions are being used to encode programming knowledge, and if they are also simple linear functions whether the standard library or other libraries can be directly uploaded into an LLMs brain as it evolves, without needing to go through a costly training or performance-destroying fine-tune. That's still a sci-fi ability today but it seems to be getting closer. reply Animats 17 hours agoparentThat's a good point. It may be possible to directly upload predicate-type info into a LLM. This could be especially useful if you need to encode tabular data. Somewhere, someone probably read this and is thinking about how to export Excel or databases to an LLM. It's encouraging to see people looking inside the black box successfully. The other big result in this area was that paper which found a representation of a game board inside a LLM after the LLM had trained to play a game. Any other good results in that area? The authors point out that LLMs are doing more than encoding predicate-type info. That's just part of what they are doing. reply wongarsu 16 hours agorootparentThe opposite is also exciting: build a loss function that punishes models for storing knowledge. One of the issues of current models is that they seem to favor lookup over reasoning. If we can punish models (during training) for remembering that might cause them to become better at inference and logic instead. reply qlk1123 9 hours agorootparentI believe it will add some spice to the model, but you shouldn't go too far at that direction. Any social system has a rule set, which has to be learnt and remembered, not infered. Two exmaples. (1) grammars in natural languages. You can just see in another commenter here uses \"a local maxima\", and then how people react to that. I didn't even notice becuase English grammar has never been native to me. (2) Mostly, prepositions between two languages, no matter how close they are, don't have a direct mapping. The learner just has to remember it. reply azinman2 8 hours agorootparentprevBut how to do when pre training is basically predict the next token? reply kossTKR 13 hours agorootparentprevInteresting. Reminds me of a sci-fi short i read years ago where AI's \"went insane\" when they had too much knowledge because they'd spent too much time looking through data and get a buffer overflow. I know some of the smaller models like PHI-2 are training for reasoning specifically before by training on question answer sets, though this seems like the opposite to me. reply AaronFriel 17 hours agorootparentprevIt indeed is. An attention mechanism's key and value matrices grow linearly with context length. With PagedAttention[1], we could imagine an external service providing context. The hard part is the how, of course. We can't load our entire database in every conversation, and I suspect there are also challenges around training (perhaps addressed via LandmarkAttention[2]) and building a service efficiently retrieve additional key-value matrices. The external service vector database may require tight timings necessary to avoid stalling LLMs. To manage 20-50 tokens/sec, answers must arrive within 50-20ms. And we cannot do this in real-time, pausing the transformer when a layer produces a query vector stalls the batch, so we need a way to predict queries (or embeddings) several tokens ahead of where they'd be useful and inject the context in when it's needed, and to know when to page it out. [1] https://arxiv.org/abs/2309.06180 [2] https://arxiv.org/abs/2305.16300 reply politician 17 hours agoparentprevHah! Maybe Neo was an LLM. \"I know kung-fu.\" reply zyklonix 15 hours agoprevThis reminds me of the famous \"King - Man + Woman = Queen\" embedding example. The fact that embeddings have semantic properties in them explains why simple linear functions would work as well. reply whatever1 18 hours agoprevLlms seem like a good compression mechanism. It blows my mind that I can have a copy of llama locally on my PC and have access to virtually the entire internet reply Culonavirus 17 hours agoparentYea except it's a lossy compression. With the lost part being hallucinated in at inference time. reply AnotherGoodName 7 hours agorootparentLossy and lossless are way more transferable than people give credit. Long winded explanation as best as i can in a HN comment. Essentially for state of the art compression both the encoder and the decoder have the same algorithm. They look at the bits encoded/decoded so far, they both run exactly the same prediction on those bits seen so far using some model that predicts based on past data (AI is fantastic for this). If the prediction was 99% likely that the next bit is a '1' the encoder only writes a fraction of a bit to represent that (assuming the prediction is correct) and on the other side the decoder will have the same prediction at that point and either read the next large number of bits to correct or it will be able to simple write '1' to the output and start on the prediction of the next bit given that now written '1'. Essentially lossy predictions of the next data are great tools to losslessly compress data as those predictions of the next bit/byte/word minimize the data needed to losslessly encode that next bit/byte/word. Likewise you can trivially make a lossy compressor out of a lossless one. Lossy and lossless just aren't that different. The longstanding Hutter prize for AI in fact judges the AI on how well it can compress data. http://prize.hutter1.net/ This is based in the fact that what we think of as AI and compression are quite interchangeable. There's a whole bunch of papers out on this. http://prize.hutter1.net/hfaq.htm#compai I have nothing to do with Hutter but i know all about AI and data compression and their relation. reply Kuinox 16 hours agorootparentprevIf you've read the article, the LLM hallucinations aren't due to the model not knowing the information but a function that choose to remember the wrong thing. reply sinemetu11 15 hours agorootparentFrom the paper: > Finally, we use our dataset and LRE-estimating method to build a visualization tool we call an attribute lens. Instead of showing the next token distribution like Logit Lens (nostalgebraist, 2020) the attribute lens shows the object-token distribution at each layer for a given relation. This lets us visualize where and when the LM finishes retrieving knowledge about a specific relation, and can reveal the presence of knowledge about attributes even when that knowledge does not reach the output. They're just looking at what lights up in the embedding when they feed something in, and whatever lights up is \"knowing\" about that topic. The function is an approximation they added on top of the model. It's important to not conflate this with the actual weights of the model. You can't separate the hallucinations from the model -- they exist precisely because of the lossy compression. reply ewild 15 hours agorootparentpreveven this place has people not reading the articles. we are doomed reply krainboltgreene 16 hours agoparentprev> have access to virtually the entire internet It isn't even close to 1% of the internet, much less virtually the entire internet. According to the latest dump, Common Crawl has 4.3B pages, but Google in 2016 estimated there are 130T pages. The difference between 130T and 4.3B is about 130T. Even if you narrow it down to Google's searchable text index it's \"100's of billions of pages\" and roughly 100P compared to CommonCrawl's 400T. reply whatever1 5 hours agorootparentThe internet to me and to most of the people is the 10 first search results for the various terms we search for. reply fspeech 15 hours agorootparentprev130T unique pages? That seems highly unlikely as that averages to over 10000 pages for each human being alive. If gp merely wants texts of interest to self as opposed to an accurate snapshot it seems LLMs should be quite capable, one day. reply estebarb 18 hours agoprevI find this similar to what relation vectors do in word2vec: you can add a vector of \"X of\" and often get the correct answer. It could be that the principle is still the same, and transformers \"just\" build a better mapping of entities into the embedding space? reply PaulHoule 17 hours agoparentI think so. It’s hard for me to believe that the decision surfaces inside those models are really curved enough (like the folds of your brain) to really take advantage of FP32 numbers inside vectors: that is I just don’t believe it is x = 0 means “fly” x = 0.01 means “drive” x = 0.02 means “purple” but rather more like x1.5 means “hot” which is one reason why quantization (often 1 bit) works. Also it is a reason why you can often get great results feeding text or images through a BERT or CLIP-type model and then applying classical ML models that frequently involve linear decision surfaces. reply taneq 16 hours agorootparentAre you conflating nonlinear embedding spaces with the physical curvature of the cerebellum? I don't think there's a direct mapping. reply PaulHoule 16 hours agorootparentMy mental picture is that violently curved decision surfaces could look like the convolutions of the brain even though they have nothing to do with how the brain actually works. I think of how tSNE and other algorithms sometimes produce projections that sometimes look like that (maybe that’s just what you get when you have to bend something complicated to fit into a 2-d space) and frequently show cusps that to me look like a sign of trouble (took me a while in my PhD work to realize how Poincaré sections from 4 or 6 dimensions can look messed up when a part of the energy surface tilts perpendicularly to the projection surface.) I still find it hard to believe that dense vectors are the right way to deal with text despite the fact that they work so well. For images it is one thing because changing one pixel a little doesn’t change the meaning of an image, but changing a single character of a text can completely change the meaning of the text. Also there’s the reality that if you randomly stick together tokens you get something meaningless, so it seems almost all of the representation space covers ill formed texts and only a low dimensional manifold holds the well formed texts. Now the decision surfaces really have to be nonlinear and crumpled over all but I think there’s a definitely a limit on how crumpled those surfaces can be. reply Y_Y 16 hours agorootparentThis is interesting. It makes me think of an \"immersion\"[0], as in a generalization of the concept of \"embedding\" in differential geometry. I share your uneasiness about mapping words to vectors and agree that it feels as if we're shoehorning some more complex space into a computationally convenient one. [0] https://en.wikipedia.org/wiki/Immersion_(mathematics) reply MuffinFlavored 18 hours agoprevI don't understand how a \"CSV file/database/model\" of 70,000,000,000 (70B) \"parameters\" of 4-bit weights (a 4 bit value can be 1 of 16 unique numbers) gets us an interactive LLM/GPT that is near-all-knowledgable on all topics/subjects. edit: did research, the 4-bit is just a \"compression method\", the model ends up seeing f32? > Quantization is the process of mapping 32-bit floating-point numbers (which are the weights in the neural network) to a much smaller bit representation, like 4-bit values, for storage and memory efficiency. > Dequantization happens when the model is used (during inference or even training, if applicable). The 4-bit quantized weights are converted back into floating-point numbers that the model's computations are actually performed with. This is done using the scale and zero-point determined during the initial quantization, or through more sophisticated mapping functions that aim to preserve as much information as possible despite the reduced precision. so what is the relationship to \"parameters\" and \"# of unique tokens the model knows about (vocabulary size)\"? > At first glance, LLAMa only has a 32,000 vocabulary size and 65B parameters as compared to GPT-3, > The 65 billion parameters in a model like LLAMA (or any large language model) essentially function as a highly intricate mapping system that determines how to respond to a given input based on the learned relationships between tokens in its training data. reply Filligree 18 hours agoparentIt doesn't, is the simple answer. The slightly more complicated one is that a compressed text dump of Wikipedia isn't even 70GB, and this is lossy compression of the internet. reply ramses0 17 hours agorootparentIs there some sort of \"LLM-on-Wikipedia\" competition? ie: given \"just wikipedia\" what's the best score people can get on however these models are evaluated. I know that all the commercial ventures have a voracious data-input set, but it seems like there's room for dictionary.llm + wikipedia.llm + linux-kernel.llm and some sort of judging / bake-off for their different performance capabilities. Or does the training truly _NEED_ every book every written + the entire internet + all knowledge ever known by mankind to have an effective outcome? reply bionhoward 16 hours agorootparentYes, that’s known as the Hutter Prize http://prize.hutter1.net/ reply ramses0 16 hours agorootparentNot exactly, because LLM's seem to be exhibiting value via \"lossy knowledge response\" vs. \"exact reproduction measured in bytes\", but close. reply AnotherGoodName 6 hours agorootparentLossy and lossless are more interchangeable in computer science than people give credit so i wouldn't dwell on that too much. You can optimally convert one into the other with arithmetic coding. In fact the actual best in class algorithms that have won the hutter prize are all lossy behind the scenes. They make a prediction on the next data using a model (often AI based) which is a lossy process and with arithmetic coding they losslessly encode the next data with bits proportional to how correct the prediction was. In fact the reason why the hutter prize is lossless compression is exactly because converting lossy to lossless with arithmetic coding is a way to score how correct a lossy prediction is. reply CraigJPerry 17 hours agorootparentprev>> Or does the training truly _NEED_ every book every written + the entire internet + all knowledge ever known by mankind to have an effective outcome? I have the same question. Peter Norvig’s GOFAI Shakespeare generator example[1] (which is not an LLM) gets impressive results with little input data to go on. Does the leap to LLM preclude that kind of small input approach? [1] link should be here because I assumed as I wrote the above that I would just turn it up with a quick google. Alas t’was not to be. Take my word for it, somewhere on t’internet is an excellent write up by Peter Norvig on LLM vs GOFAI (good old fashioned artificial intelligence) reply MuffinFlavored 18 hours agorootparentprevsay the average LLM these days has a unique token (vocabulary) size of ~32,000 (not its context size, # of unique tokens it can pick between in a response. English words, punctuation, math, code, etc.) the 60-70B parameters of models is basically like... just stored patterns of \"if these 10 tokens in a row input, then these 10 tokens in a row output score the highest\" Is that a good summary? > The model uses its learned statistical patterns to predict the probability of what comes next in a sequence of text. based on what inputs? 1. previous tokens in the sequence from immediate context 2. tokens summarizing the overall topic/subject matter from the extended context 3. scoring of learned patterns from training 4. what else? reply wongarsu 17 hours agorootparentThat would be equivalent to a hidden markov chain. Those have been around for decades, but we have only managed to make them coherent for very short outputs. Even GPT2 beats any Markov chain, so there has to be more going on Modern LLMs are able to transfer knowledge between different languages, so it's fair to assume that some mapping between human language and a more abstract internal representation happens at the input and output, instead of the model \"operating\" on English or Chinese or whatever language you talk with it. And once this exists, an internal \"world model\" (as in: a collection of facts and implications) isn't far, and seems to indeed be something most LLMs do. The reasoning on top of that world model is still very spotty though reply numeri 17 hours agorootparentprevYour suggested scheme (assuming a mapping from 10 tokens to 10 tokens, with each token taking 2 bytes to store) would take (32000 * 20) * 2 bytes = 2.3e78 TiB of storage, or about 250 MiB per atom in the observable universe (1e82), prior to compression. I think it's more likely that LLMs are actually learning and understanding concepts as well as memorizing useful facts, than that LLMs have discovered a compression method with that high of a compression ratio, haha. reply mjburgess 17 hours agorootparentLLMs cannot determine the physical location of any atoms. they cannot plan movement, and so on. LLMs are just completing patterns of text that have been given before, 'everthing ever written' is both a lot for any individual person to read; but also, almost nothing, in that to propertly describe a table requires more information text is itself an extremely compressed medium which lacks almost any information about the world; it succeeds in being useful to generate because we have that information and are able to map it back to it reply numeri 17 hours agorootparentI didn't imply that they know anything about where atoms are, I was just pointing out the sheer absurdity of that volume of data. I should make it clear that my comparison there is unfair and mostly just funny – you don't need to store every possible combination of 10 tokens, because most of them will be nonsense, so you wouldn't actually need that much storage. That being said, it's been fairly solidly proven that LLMs aren't just lookup tables/stochastic parrots. reply mjburgess 16 hours agorootparent> fairly solidly proven that LLMs aren't just lookup tables/stochastic parrots Well i'd strongly disagree. I see no evidence of this; I'm am quite well acquainted with the literature. All empirical statistical AI is just a means of approximating an empirical distribution. The problem with NLP is that there is no empirical function from text tokens to meanings; just as there is no function from sets of 2D images to a 3D structure. We know before we start that the distributions of text tokens are only coincidentally related to the distributions of meanings. The question is just how much value that coincidence has in any given task. (Consider, eg., that if I ask, \"do you like what i'm wearing?\" there is no distribution of responses which is correct. I do not want you to say \"yes\" 99/100, or even 100/100 times. etc. what I want you to say is a word caused a mental state you have: that of (dis)liking what i'm wearing. Since no statistical AI systems generate outputs based on causal features of reality, we know a priori that almost all possible questions that can be asked cannot be answered by LLMs. They are only useful where questions have cannonical answers; and only because \"cannonical\" means that a text->text function is likely to be conidentally indistinguishable from a the meaning->meaning function we're interested in). reply tel 9 hours agorootparentThat suggests that no statistical method could ever recover hidden representations though. And that’s patently untrue. Taken to its greatest extreme you shouldn’t even be able to guess between two mixed distributions even when they have wildly non-overlapping ranges. Or put another way, all of statistical testing in science is flawed. I’m not saying you believe that, but I fail to see how that situation is structurally different from what you claim. If it’s a matter of degree, how do you feel things change as the situation becomes more complex? reply mjburgess 1 hour agorootparentYes, I think most statistical testing in science is flawed. But, to be clear, the reason it could ever work at all has nothing to do with the methods or the data itself, it has to do with the properties of the data generating process (ie., reality, ie., what's being measured). You can never build representations from measurement data, this is called inductivism and it's pretty clearly false: no representation is obtained from just characterising measurement data. Theres no cases where I can think of that this would work -- temperature isnt patterns in thermometers; gravity isnt patterns in the positions of stars; and so on. Rather you can decide between competing representations using stats in a few special cases. Stats never uncovers hidden representations, it can decide between different formal models which include such representations. eg., if you characterise some system as having a power-law data generating process (eg., social network friendships), then you can measure some parameters of that process or, eg., if you arrange all the data to already follow a law you know (eg., F=Gmm/r^2) then you can find G, 'statistically'. This has caused a lot of confusion histroically: it seems G is 'induced over cases', but all the representaiton work has alerady been done. Stats/induction just plays the role of fine-tuning known representatios. it never builds any reply pk-protect-ai 17 hours agorootparentprevThere is something wrong with these arithmetic: \"(32000 * 20) * 2 bytes = 2.3e78 TiB of storage\" ... The factorial is missing somewhere in there ... reply HarHarVeryFunny 15 hours agorootparentprev> the 60-70B parameters of models is basically like... just stored patterns of \"if these 10 tokens in a row input, then these 10 tokens in a row output score the highest\" > Is that a good summary? No - there's a lot more going on. It's not just mapping input patterns to output patterns. A good starting point to understand it are linguist's sentence-structure trees (and these were the inspiration for the \"transformer\" design of these LLMs). https://www.nltk.org/book/ch08.html Note how there are multiple levels of nodes/branches to these trees, from the top node representing the sentence as a whole, to the words themselves which are all the way at the bottom. An LLM like ChatGPT is made out of multiple layers (e.g. 96 layers for GPT-3) of transformer blocks, stacked on top of each other. When you feed an input sentence into an LLM, the sentence will first be turned into a sequence of token embeddings, then passed through each of these 96 layers in turn, each of which changes (\"transforms\") it a little bit, until it comes out the top of the stack as the predicted output sentence (or something that can be decoded into the output sentence). We only use the last word of the output sentence which is the \"next word\" it has predicted. You can think of these 96 transformer layers as a bit like the levels in one of those linguistic sentence-structure trees. At the bottom level/layer are the words themselves, and at each successive higher level/layer are higher-and-higher level representations of the sentence structure. In order to understand this a little better, you need to understand what these token \"embeddings\" are, which is the form in which the sentence is passed through, and transformed by, these stacked transformer layers. To keep it simple, think of a token as a word, and say the model has a vocabulary of 32,000 words. You might perhaps expect that each word is represented by a number in the range 1-32000, but that is not the way it works! Instead, each word is mapped (aka \"embedded\") to a point in a high dimensional space (e.g. 4096-D for LLaMA 7B), meaning that it is represented by a vector of 4096 numbers (cf a point in 3-D space represented as (x,y,z)). These 4096 element \"embeddings\" are what actually pass thru the LLM and get transformed by it. Having so many dimensions gives the LLM a huge space in which it can represent a very rich variety of concepts, not just words. At the first layer of the transformer stack these embeddings do just represent words, the same as the nodes do at the bottom layer of the sentence-structure tree, but more information is gradually added to the embeddings by each layer, augmenting and transforming what they mean. For example, maybe the first transformer layer adds \"part of speech\" information so that each embedded word is now also tagged as a noun or verb, etc. At the next layer up, the words comprising a noun phase or verb phrase may get additionally tagged as such, and so-on as each transformer layer adds more information. This just gives a flavor of what is happening, but basically by the time the sentence has reached the top layer of the transformer it has been able to see the entire tree structure of the sentence, and only then have \"understand\" it well enough to predict a grammatically and semantically \"correct\" continuation from which it is able to predict continuation words. reply MichaelZuo 12 hours agorootparentThanks for the explanation. Since unicode has well over 64000 symbols, does that imply models, trained on a large corpus, must necessarily have at least 64000 ‘branches’ at the bottom layer? reply HarHarVeryFunny 7 hours agorootparentThe size of the character set (unicode) doesn't really factor into this. Input words are broken down into multi-character tokens (some words will be one token, some split into two, etc), then these tokens mapped into the embedding vectors which is what the model is then operating on. The linguistic sentence structure tree for any input sentence is a useful way to think about what is happening as the input sentence is fed into the model and processed through it layer by layer, but doesn't have any direct correspondence to the model. The model has a fixed number of layers of fixed max-tokens width, so nothing changes according to the sentence passing through it. Note that the bottom level of the sentence structure tree is just the words of the sentence, so the number of branches is just the length of the sentence. The model doesn't actually represent these branches though - just the embeddings corresponding to the input, which are transformed from input to output as they are passed through the model and each layer does it's transformer thing. reply Acumen321 17 hours agoparentprevQuantization in this context is the precision of each value in the vector or matrix/tensor. If the model in question has a token embedding length of 1024, even if it was a 1 bit quantization, each token has 2^1024 possible values. If the context length is 32,000 tokens, there are 32,000^2^1024 possible inputs. reply robertclaus 15 hours agoprevI think this paper is cool and I love that they ran these experiments to validate these ideas. However, I'm having trouble reconciling the novelty of the ideas themselves. Isn't this result expected given that LLM's naturally learn simple statistical trends between words? To me it's way cooler that they clearly demonstrated not all LLM behavior can be explained this simply. reply wslh 18 hours agoprevCan we roughly say that LLMs produces (training mode) a lot of IF-THENs in an automatic way from a vast quantity of information (nor techniques) that was not available before? reply vsnf 18 hours agoprev> Linear functions, equations with only two variables and no exponents, capture the straightforward, straight-line relationship between two variables Is this definition considering the output to be included in the set of variables? What a strange way to phrase it. Under this definition, I wonder what an equation with one variable is. Is a single constant an equation? reply hansvm 17 hours agoparentIt's just a change in perspective. Consider a vertical line. To have an \"output\" variable you have to switch the ordinary `y=mx+b` formulation to `x=c`. The generalization `ax+by=c` accommodates any shifted line you can draw. Adding more variables increases the dimension of the space in consideration (`ax+by+cz=d` could potentially define a plane). Adding more equations potentially reduces the size of the space in consideration (e.g., if `x+y=1` then also knowing `2x+2y=2` wouldn't reduce the solution space, but `x-y=0` would, and would imply `x=y=1/2`, and further adding `x+2y=12` would imply a lack of solutions). Mind you, the \"two variable\" statement in this news piece is a red-herring. The paper describes higher-dimension linear relationships, of the form `Mv=c` for some constant matrix `M`, some constant vector `c`, and some variable vector `v`. On some level, the result isn't _that_ surprising. The paper only examines one layer (not the whole network), after the network has done a huge amount of embedding work. In that layer, they find that under half the time they're able to get over 60% of the way there with a linear approximation. Another interpretation is that the single layer does some linear work and shoves it through some nonlinear transformations, and more than half the time that nonlinearity does something very meaningful (and even in that under half the time where the linear approximation is \"okay\", the metrics are still bad). I'm not super impressed, but I don't have time to full parse the thing right now. It is a bit surprising; if memory serves, one of the authors on this paper had a much better result in terms of neural network fact editing in the last year or two. This looks like a solid research idea, solid work, it didn't pan out, and to get it published they heavily overstated the conclusions (and then the university press release obviously bragged as much as it could). reply ksenzee 17 hours agoparentprevI think they're trying to say \"equations in the form y = mx + b\" without getting too technical. reply 01HNNWZ0MV43FF 18 hours agoparentprevYeah I guess they mean one independent variable and one dependent variable It rarely matters because if you had 2 dependent variables, you can just express that as 2 equations, so you might as well assume there's exactly 1 dependent and then only discuss the number of independent variables. reply pb060 17 hours agoparentprevAren’t functions and equations two different things? reply olejorgenb 18 hours agoparentprevI would think `x = 4` is considered an equation, yes? reply pessimizer 17 hours agorootparentAnd linear at that: x = 0y + 4 reply i5heu 17 hours agoprevSo it is entirely possible to decouple the reasoning part from the information part? This is like absolutely mind blowing if this is true. reply learned 16 hours agoparentA big caveat mentioned in the article is that this experiment was done with a small set (N=47) of specific questions that they expected to have relatively simple relational answers: > The researchers developed a method to estimate these simple functions, and then computed functions for 47 different relations, such as “capital city of a country” and “lead singer of a band.” While there could be an infinite number of possible relations, the researchers chose to study this specific subset because they are representative of the kinds of facts that can be written in this way. About 60% of these relations were retrieved using a linear function in the model. The remaining appeared to have nonlinear retrieval and is still a subject of investigation: > Functions retrieved the correct information more than 60 percent of the time, showing that some information in a transformer is encoded and retrieved in this way. “But not everything is linearly encoded. For some facts, even though the model knows them and will predict text that is consistent with these facts, we can’t find linear functions for them. This suggests that the model is doing something more intricate to store that information,” he says. reply seydor 13 hours agoprevDoes this point to a way to compress entire LLMs by selecting a set of relations? reply leobg 18 hours agoprev> In one experiment, they started with the prompt “Bill Bradley was a” and used the decoding functions for “plays sports” and “attended university” to see if the model knows that Sen. Bradley was a basketball player who attended Princeton. Why not just change the prompt? Name, University attended, Sport played Bill Bradley, reply numeri 18 hours agoparentThis is research, trying to understand the fundamentals of how these models work. They weren't actually trying to find out where Bill Bradley went to university. reply leobg 14 hours agorootparentOf course. But weren’t they trying to find out whether or not that fact was represented in the model’s parameters? reply wnoise 13 hours agorootparentNo, they were trying to figure out if they had isolated where facts like that were represented. reply uoaei 14 hours agoprevThis is the \"random linear projections as memorization technique\" perspective on Transformers. It's not a new idea per se, but nice to see it fleshed out. If you dig into this perspective, it does temper any claims of \"cognitive behavior\" quite strongly, if only because Transformers have such a large capacity for these kinds of \"memories\". reply tel 9 hours agoparentDo you have a reference on “random linear projections as memorization”? I know random projections quite well but haven’t seen that connection. reply aia24Q1 18 hours agoprev [–] I thought \"fact\" means truth. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Large language models (LLMs) utilize basic linear functions to access and interpret stored information, allowing researchers to explore their knowledge and rectify inaccuracies.",
      "Understanding these functions could enhance the precision of AI chatbots and offer clarity on how LLMs store and retrieve data.",
      "A joint research effort from MIT and other institutions uncovered this discovery, to be showcased at the International Conference on Learning Representations."
    ],
    "commentSummary": [
      "The article raises concerns about the limited diversity in artificial neural network models, with a focus on the overwhelming use of transformer models in AI.",
      "Participants engage in debates over terminology, delve into mathematical concepts, evaluate AI advancements, and analyze the complexities of statistical AI systems.",
      "Discussions encompass the functionality and impact of language models such as ChatGPT, transformer models, the role of linear relationships in neural networks, and the management of data in extensive language models."
    ],
    "points": 347,
    "commentCount": 124,
    "retryCount": 0,
    "time": 1711636670
  },
  {
    "id": 39853958,
    "title": "Introducing Jamba: AI Model Leveraging Mamba Architecture",
    "originLink": "https://www.maginative.com/article/ai21-labs-unveils-jamba-the-first-production-grade-mamba-based-ai-model/",
    "originBody": "A121 Open Source AI21 Labs Unveils Jamba: The First Production-Grade Mamba-Based AI Model Jamba is a groundbreaking SSM-Transformer model that offers the best of both worlds, addressing the drawbacks of traditional Transformer architectures while maintaining their powerful capabilities. Chris McKay March 28, 2024 • 2 min read AI21 Labs, has just released Jamba, the world's first production-grade AI model based on the innovative Mamba architecture. Most models today (like GPT, Gemini and Llama) are based on the Transformer architecture. Jamba combines the strengths of both the Mamba Structured State Space model (SSM) and the traditional Transformer architecture, delivering impressive performance and efficiency gains. Jamba boasts an extensive context window of 256K tokens, equivalent to around 210 pages of text, while fitting up to 140K tokens on a single 80GB GPU. This remarkable feat is achieved through its hybrid SSM-Transformer architecture, which leverages mixture-of-experts (MoE) layers to draw on just 12B of its available 52B parameters during inference. The result is a model that can handle significantly longer contexts than most of its counterparts, such as Meta's Llama 2 with its 32,000-token context window, while maintaining high throughput and efficiency. Jamba delivers 3x throughput on long contexts, making it a more efficient model than Transformer-based models of comparable size like Mixtral 8x7B. One of the key advantages of Jamba is its ability to deliver 3x throughput on long contexts compared to Transformer-based models of similar size, like Mixtral 8x7B. This is made possible by the model's unique hybrid architecture, which is composed of Transformer, Mamba, and mixture-of-experts (MoE) layers, optimizing for memory, throughput, and performance simultaneously. It features a blocks-and-layers approach, with each Jamba block containing either an attention or a Mamba layer, followed by a multi-layer perceptron (MLP). This results in an overall ratio of one Transformer layer out of every eight total layers. AI21 Labs says this approach allows the model to maximize quality and throughput on a single GPU, leaving ample memory for common inference workloads. Jamba's impressive performance extends beyond efficiency and cost-effectiveness. The model has already demonstrated remarkable results on various benchmarks, matching or outperforming state-of-the-art models in its size class across a wide range of tasks. Jamba outperforms or matches other state-of-the-art models in its size class on a wide range of benchmarks. Jamba is being released with open weights under Apache 2.0 license. It is available on Hugging Face, and will also be accessible from the NVIDIA API catalog as NVIDIA NIM inference microservice, which enterprise applications developers can deploy with the NVIDIA AI Enterprise software platform. For now, Jamba is currently released as a research model without the necessary safeguards for commercial use. However, AI21 Labs plans to release a fine-tuned, safer version in the coming weeks. As the AI community continues to explore and refine new architectures, we can expect to see even more impressive gains in performance, efficiency, and accessibility, paving the way for a new generation of more capable AI models.",
    "commentLink": "https://news.ycombinator.com/item?id=39853958",
    "commentBody": "Jamba: Production-grade Mamba-based AI model (maginative.com)298 points by bubblehack3r 17 hours agohidepastfavorite76 comments smusamashah 15 hours agoThere was a recent thread on explaining Mamba https://news.ycombinator.com/item?id=39501982 (https://www.kolaayonrinde.com/blog/2024/02/11/mamba.html) There was another one on the same thing, probably better https://news.ycombinator.com/item?id=39482428 (https://jackcook.com/2024/02/23/mamba.html) reply dang 14 hours agoparentThanks! Macroexpanded: Mamba Explained: The State Space Model Taking On Transformers - https://news.ycombinator.com/item?id=39501982 - Feb 2024 (93 comments) Mamba: The Easy Way - https://news.ycombinator.com/item?id=39482428 - Feb 2024 (60 comments) Is Mamba Capable of In-Context Learning? - https://news.ycombinator.com/item?id=39286410 - Feb 2024 (1 comment) Vision Mamba: Efficient Visual Representation Learning with Bidirectional SSM - https://news.ycombinator.com/item?id=39214939 - Feb 2024 (16 comments) MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts - https://news.ycombinator.com/item?id=38932350 - Jan 2024 (39 comments) Implementation of Mamba in one file of PyTorch - https://news.ycombinator.com/item?id=38708730 - Dec 2023 (109 comments) Fortran inference code for the Mamba state space language model - https://news.ycombinator.com/item?id=38687342 - Dec 2023 (1 comment) Guide to the Mamba architecture that claims to be a replacement for Transformers - https://news.ycombinator.com/item?id=38659238 - Dec 2023 (2 comments) Mamba outperforms transformers \"everywhere we tried\" - https://news.ycombinator.com/item?id=38606590 - Dec 2023 (25 comments) Mamba: Linear-Time Sequence Modeling with Selective State Spaces - https://news.ycombinator.com/item?id=38522428 - Dec 2023 (37 comments) Mamba: New SSM arch with linear-time scaling that outperforms Transformers - https://news.ycombinator.com/item?id=38520992 - Dec 2023 (2 comments) reply garyiskidding 5 hours agorootparentthank you, these are very helpful. reply eigenvalue 13 hours agoprevHas anyone gotten this to work in linux using 1 or 2 4090s? I get stuck on \"Loading checkpoint shards: 71%\" and then it bails. But weirdly nvidia-smi shows plenty of VRAM available. My machine has 256gb of RAM so I don't think that's the problem either. Really excited to try this one. reply a_wild_dandan 15 hours agoprevTo those curious about the tradeoffs between transformer and state space model layers, I highly recommend Sasha Rush's video on it: https://www.youtube.com/watch?v=dKJEpOtVgXc reply az226 5 hours agoparentThey use less memory for inference but remember the details less well. For instance if you’re implementing code and want edits, it will forget various functions to be part of the script. Even transformers aren’t perfect at this and SSMs are even worse. For many use cases, that ability isn’t needed as much so the memory savings is a bigger lever. reply Reubend 15 hours agoprevIt's great to see a full production level model using Mamba. But when it comes to long context window benchmarks, I'd love to see performance as well as throughput. I was under the impressions that Mamba has huge increases in throughput at the cost of modest losses in accuracy when using long contexts. reply samus 14 hours agoparentThis one should have you covered :-) one out of every eight layers is a traditional Transformer layer, which should ensure precision, at least over short distances. reply swyx 9 hours agorootparent> which should ensure precision, at least over short distances. why? i dont follow. transformers should provide some attention over -all- distances, no? why does layering truncate this to \"short distances\"? reply samus 8 hours agorootparentI mean \"short\" in comparison to the unlimited, but lossy recall that the Mamba blocks provide. Transformers are limited to the context length, while Mamba can carry along state. While it can remember things from a lot farther back, it is limited and must thus eventually drop things and/or lose precision. reply refulgentis 15 hours agoparentprevI would too -- long context has been such a red herring across providers, Claude 3 is the first I've seen that seems to genuinely have some sort of qualitative leap in noticing things. It is worth noting I'm fairly sure there's no inherent theoratical decrease to accuracy in long contexts, the claimed theoratical change is an _increase_ in long-term accuracy in long contexts. reply tempusalaria 13 hours agorootparentEvery long context sucks right now. All the model providers benchmark on fact recall which is very limited. Actual ability to do anything complicated beyond 16k tokens is not present in any current model I have seen. reply ukuina 9 hours agorootparentThis is not current. GPT-4-Turbo (128k) has lossless recall to the first 64k input tokens and produces output indistinguishable from GPT-4 (32k), though both are limited to 4k output tokens. Several downsides: Recall accuracy past the first 64k tokens suffers badly; Cost is astronomical; Response latency is too high for most interactive use-cases. I would point out the astounding leap in input context in just one year. Should we assume effectively-infinite (RAG-free) context in the near-future? reply anoncareer0212 9 hours agorootparentThis is grossly untrue in a way that denotes surface-level familiarity on several fronts You're referring to the needle-in-a-haystack retrieval problem. Which the person you're replying to explicitly mentioned is the only benchmark providers are using, for good reason. Consider the \"translate Moby Dick to comedic zoomer\" problem. This does not even come remotely close to working unless I do it in maximum chunks of 5,000 tokens. Consider the API output limit of 4096 tokens, across all providers. And no, you shouldn't assume effectively infinite (RAG free) context in the near future. This time last year, Anthropic was demonstrating 120,000 token context. It released 200K a few weeks ago. And runtime cost scales with N^2. reply binalpatel 14 hours agorootparentprevGemini 1.5 Pro is really good at long context in my experience. reply Arthur_ODC 14 hours agorootparentprevLong Context is great and all, but it sucks that all of these LLM's have really poor output length. If I feed something an entire book and ask for a comprehensive summary then I'm expecting at least a full 3-page summary. I get that they try to force these things to be \"concise\" to save on compute, but good lord it's so annoying. reply pedrovhb 12 hours agorootparentHave you tried asking it for a specific concrete length, like a number of words? I was also frustrated with concise answers when asking for long ones, but I found that the outputs improved significantly if I asked for e.g. 4000 words specifically. Further than that, have it break it down into sections and write X words per section. reply Arthur_ODC 11 hours agorootparentYes, all the possible length extending custom instructions you can think of. I can get some reasonable length responses out of it, but I've never seen them go over 1 page worth, and multi-shot example prompts using multiple USER and GPT exchanges to define the format. Seems like GPT4 has a hard limit as to how much it will output when you click \"continue\", and Claude Opus never goes over a page either. Another user pointed out using the API, which I have done in the past, but it's been a long while, and I can't really justify the cost of using the advanced models via API for my general use. reply refulgentis 10 hours agorootparentEveryone's coalescing at a max of 4096 tokens/12 \"pages\" via API (page is 250 words, which is 1 8.5\"x11\" double spaced) To your point, doesn't matter anyway, it's nigh impossible to get over 2K of output with every trick and bit of guidance you can think of (I got desperate when 16K/48 pages came out to \"make it work\", even completely deforming tricks like making it number each line and write a reminder on each line that it should write 1000 lines don't work) reply CuriouslyC 14 hours agorootparentprevThat's a chat gpt problem, if you hit the API it's not nearly so hard to get good output. reply refulgentis 14 hours agorootparentI wouldn't say that, my latest big user story for making sure I'm handling huge inputs was \"translate Moby dick to zoomer\". Cant give any service chunks larger than ~5K tokens, over API, without it failing. (Miserably, like, I'd be fine if it gave a paragraph back. But at least on this \"map\" task, there's a critical point where there's so much input that the reward function ends up imitating the input more instead of chatting) reply skybrian 15 hours agoprev> Jamba boasts an extensive context window of 256K tokens, equivalent to around 210 pages of text, while fitting up to 140K tokens on a single 80GB GPU. I realize this is a big improvement, but it’s striking how inefficient LLM’s are, that you need 80GB of GPU memory to analyze less than 1 megabyte of data. That’s a lot of bloat! Hopefully there’s a lot of room for algorithmic improvements. reply pama 6 hours agoparentThe big (huge?) memory requirement is during training. These LLMs work with high dimensional vectors and they calculate gradients with respect to high dimensional vectors and they do updates that require state of the optimizer. If you have 3 particles in 3 dimensions and you need their forces that creates 3 new 3D vectors and once you update their position along the forces then they also carry momenta. Now generalize these simple 3-body physics to the typical 60-layer creatures inside the LLM with vectors of several thousand dimensions, interactions/weights that are scaling like the squares of these vectors, to a total parameter count that adds up to the 10s to 100s of billions of parameters, and then take derivatives and start to keep track of momenta. It is a feat of modern engineering that some groups can train such models efficiently. I hope we will see more of the training stories becoming public in the near future. reply nl 2 hours agorootparentThis is wrong. You need big memory during inference too. The difference there is you can use tricks like quantisation and offloading to CPU to reduce it somewhat at the cost of accuracy and/or speed. reply nl 2 hours agoparentprevThat’s all the world’s knowledge compressed into 80GB. It’s not analysing 1MB data, it’s analysing all of that knowledge plus and additional 1MB. reply nostrowski 12 hours agoparentprevTwo things I'm curious to know: 1. How many tokens can 'traditional' models (e.g. Mistral's 8x7B) fit on a single 80GB GPU? 2. How does quantization affect the single transformer layer in the stack? What are the performance/accuracy trade-offs that happen when so little of the stack depends on this bottleneck? reply patrakov 12 hours agorootparentMixtral 8x7b runs well (i.e., produces the correct output faster than I can read it) on a modern AMD or Intel laptop without any use of a GPU - provided that you have enough RAM and CPU cores. 32 GB of RAM and 16 hyperthreads are enough with 4-bit quantization if you don't ask too much in terms of context. P.S. Dell Inspiron 7415 upgraded to 64 GB of RAM here. reply riku_iki 12 hours agoparentprev> that you need 80GB of GPU memory to analyze less than 1 megabyte of data 80GB is compressed all human knowledge applied on that 1mb.. reply imtringued 2 hours agoparentprevCompared to the human brain they are shockingly efficient. It's the hardware that isn't, but that is just a matter of time. reply electric_mayhem 15 hours agoparentprevIt’s literally simulating a neural network. How much of your 5-sense experiential memories and decades of academic book learning are you bringing to understand my reply to your post? How many gigabytes do you think that’s equivalent to? reply skybrian 15 hours agorootparentJamba seems to be distributed as 21 5-gigabyte files [1] so I guess that’s another way of looking at it. [1] https://huggingface.co/ai21labs/Jamba-v0.1/tree/main reply imtringued 2 hours agorootparentSo what? I have seen models distributed as 26x 10GB files. reply richardw 10 hours agorootparentprevIt’s kinda simulating our brains but not really. When I attempted to dig more into how neurons work I realised that it’s a massive chasm of difference. Very much worth doing if you haven’t (you might know far better then me, this is for people who don’t yet.) In terms of results: Our brains are working with 20w of power and can be trained to compete with LLM’s using a tiny fraction of the world’s data. They also have to keep you breathing and your blood pumping and manage all the dangers of catching a ball near traffic. Or skiing, or poetry, or sunsets. And they remember stuff five minutes later and don’t need a training run that takes months. We have SO many opportunities to improve the AI architecture it’s ridiculous. This is a good thing. reply reissbaker 10 hours agorootparentTo be fair most of the brain is more like a pretrained model — it isn't being trained at any point after conception to keep your blood pumping or your lungs working, it does that out of the box roughly as soon as you sprout those organs (or the minute you're born, in the case of lungs). The training process was billions of years of evolution. And, well, given fairly persistent cross-cultural cognitive biases, I expect the conscious thought parts are starting from a pretrained model, too, and all we're doing in school is finetuning ;) reply imtringued 2 hours agorootparentprevPeople don't understand that to simulate a single neuron, you need an entire neural network. So 70 billion parameters might at best be equivalent to a million neurons but that is assuming that your neural network architecture is akin to the connections between neurons. Considering the physical sparsity, you might need even more parameters to model the connections of a biological neural network. So less than a million neurons in practice. reply _false 15 hours agorootparentprevI love both parent post perspectives on this. reply gautamcgoel 15 hours agoprevWhy include self-attention layers at all? In other words, why not just alternate SSM and MLP layers? reply NLPaep 15 hours agoparentMamba is bad with long context. It doesn't remember phone numbers https://www.harvard.edu/kempner-institute/2024/02/05/repeat-... reply a_wild_dandan 13 hours agorootparentGood! DNNs unlock semantics (parsing, transforming, producing). That's the basis of general intelligence, not encyclopedic random string recall. Models shouldn't burn ungodly quantities of compute emulating DDR5 with their working memory. We need machines that think better, not memorize well. We already have plenty of those. Massive context windows, and their needle tests, are misguided. We won't reach human-level AGI by basically inventing a natural language RDBMS. Our resources should primarily target better reasoning systems for our models, reinforcement learning, etc. If we can build a GPT4-level problem solving system that coincidentally also can't remember telephone numbers, I'll consider it major progress. reply 6gvONxR4sf7o 10 hours agorootparentMemorization usually refers to training data. It's often useful to have something that can utilize instructions losslessly, which is the distinction between these models. reply Rodeoclash 12 hours agorootparentprevI can't remember phone numbers either but I can use a device suited to remembering them to look them up reply orra 12 hours agorootparentHell, it looks like you forgot you already said that (-: reply Rodeoclash 10 hours agorootparentHaha, I blame the Harmonic app :/ reply imtringued 2 hours agorootparentprevWhat if your field of vision was infinite and you are looking at a unrolled telephone book? Would you need a device to remember the phone number? You wouldn't. You would need a method or algorithm to find the number, but there is no reason why that algorithm couldn't be part of the attention mechanism. The attention mechanism is akin to reading the entire phone book for every word you are about to say. It would be unreasonable to expect you to not find the right phone number eventually. reply Rodeoclash 12 hours agorootparentprevI can't remember phone numbers either but I can use a device suited to remembering them to look them up. reply unraveller 12 hours agoprevJamba-v0.1-hybrid-MoE (16x6B?) is like giving a big NOS boost to a mixtral 8x7B tier LLM. If true 256k context, 3x longer, faster & cheaper than anything else, it should mean an end to the One Model To Rule Them All mindset for now. The big boys will have to offer some version of it as separate but close side-kick integration to their hero offering. reply CGamesPlay 5 hours agoprevDoes this mean that I can continue a chat without needing to send a full transcript? This feels like it could make inference a lot cheaper for multi-step dialogs. reply zzzzzzzzzz10 2 hours agoprevWhere can I download and use it? reply ninjahatori 13 hours agoprevOn a side note: working over longer contexts also reminds me of MemGPT(https://github.com/cpacker/MemGPT) I think a similar concept can be applied to Mamba architecture models too. reply zelphirkalt 8 hours agoprevIs there a Sparabo too? It is always funny to see old names associated with totally different new things! reply toddmorey 8 hours agoprevReleased with open weights! reply moneycantbuy 10 hours agoprevwould a 192GB RAM mac studio or even a 7950x with 192GB RAM be practical for running this model for inference and possibly fine tuning? Especially if I don't need very low latency e.g. 1 token per second is fine for inference. i also have two 3090s. reply haddr 14 hours agoprevWill it be possible to run such model family in ollama? reply andy99 14 hours agoparentMamba is supported in llama.cpp so should be (edit - apparently it's not strictly the mamba architecture, it's a mix of mamba and transformers, so it looks like it would have to be ported to llama.cpp) reply google234123 14 hours agoprevI’m pretty sure computational chemists were combining NNs with Kalman Filters for a while now… I recall the issue it was slow due to the N^2 size of the covariance matrix reply uoaei 14 hours agoparentSurprised they hadn't found ways to advance their techniques with e.g. low-rank approximations, etc. reply theGnuMe 7 hours agorootparentThat’s one strategy. Also flash attention. reply kelseyfrog 16 hours agoprevI'm glad we're seeing exploration into scaling post-transformer LLM architectures, but I'm disappointed that it has a context window. That was kind of the selling point of Mamba(and SSM models in general), right linear scaling because state+input=next_state+output? reply spxneo 11 hours agoparent256k is huge dude. that is like 1/2 of the average non fiction novel i think at least 200~300 pages of PDF im not complaining here and it also fits in GPU reply a_wild_dandan 13 hours agoparentprevstate = context The difference between SSMs and GPTs here is how that state/context scales. Per usual in engineering, there are big trade offs! reply kelseyfrog 13 hours agorootparentI'm not following. State is a multi-dimensional vector and context is a list of tokens. State is perturbed by A and Bx(t), while context is appended to by sampling the predicted token distribution. reply refulgentis 15 hours agoparentprevI'm not sure I follow fully, it is also the case for (handwaves) \"traditional\" LLMs that state + input = next state + output. Its just that output increases, so as output becomes input, eventually state + input / next state + output is greater than the context size. Re: linear scaling, that means the runtime cost is O(n) to context size, rather than traditional transformer O(n^2) reply maccam912 14 hours agorootparentI think kelseyfrog meant that the state for a mamba model is supposed to \"remember\" stuff even if it doesn't have the actual tokens to reference any more. It might not be guaranteed to hang on to some information about tokens from a long time ago, but at least in theory it's possible, whereas tokens from before a context window in a tradional llms may as well never have existed. reply kelseyfrog 14 hours agorootparentYes, you said it better than I did :) reply visarga 14 hours agorootparentprevThat is valid for Mamba, this model (Jamba) is a mix of transformer and mamba layers, so it still has a quadratic memory cost, but divided by 8. reply cs702 13 hours agoprevPlease link to the original post: https://www.ai21.com/blog/announcing-jamba Jamba looks fabulous. Good performance for its size and much more efficient than the available open alternatives. The key idea: One of out of every eight transformer blocks in Jamba applies dot-product attention with quadratic cost, but the other seven out of eight apply a Mamba layer with linear cost. And the entire model is a mixture of experts(MoE) so only ~12B parameters are used at once for inference. Thank you to the folks at AI21 for making Jamba available! reply swyx 11 hours agoparenti havent seen anyone mention this yet so i'll be the first - what is the comparison vs StripedHyena? https://www.together.ai/blog/stripedhyena-7b reply cs702 10 hours agorootparentMamba came out of the same research group, Hazy Research, led by Chris Ré. This new \"Jamba\" model incorporating Mamba and dot-product attention layers has ~8x more parameters than the largest open Striped Hyena, and appears to work much better. reply ipsum2 14 hours agoprev@dang this is blogspam for the official post: https://www.ai21.com/blog/announcing-jamba reply krasin 15 hours agoprevThe license is a proper open-source one: Apache 2.0. Thanks, AI21 Labs. reply popalchemist 13 hours agoparentIn addition to the architectural and performance benefits, this is the big deal here, IMO. reply spxneo 11 hours agoparentprevim so used to seeing AGPLv3 apache 2 is a more generous license reply krasin 11 hours agorootparentAGPLv3 is a fine license too. But most of the models nowadays come with bullshit licenses, like Llama 2 with its \"acceptable use policy\" enforced by the license: https://ai.meta.com/llama/use-policy/ reply sleepingreset 12 hours agoprevgod damn reply htrp 16 hours agoprev [–] compute still has cost? reply samus 14 hours agoparent [–] In not sure I understood your question. This model should have much lower computational cost since only one out of eight layers is a traditional transformer layer with masked self-attention. Additionally, half of the Mamba layers are MoEs. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "AI21 Labs introduced Jamba, the inaugural production-ready AI model utilizing the innovative Mamba architecture, merging Mamba Structured State Space and Transformer elements for enhanced performance.",
      "Jamba features a wide context window, providing a 3x increase in throughput for extended contexts compared to conventional Transformer models, showcasing positive outcomes on diverse benchmarks.",
      "The AI model is currently accessible for public use under the Apache 2.0 license, with future intentions of launching a commercial edition."
    ],
    "commentSummary": [
      "The discussion delves into AI models like Mamba and GPT-4, highlighting their performance, limitations, and trade-offs concerning memory usage, accuracy, and response length.",
      "It covers challenges in managing long context scenarios and the prospects for algorithmic enhancements in the future.",
      "Additionally, debates occur on aspects like including self-attention layers, optimizing GPU memory efficiency, and enhancing problem-solving capabilities within AI systems, referencing models like MemGPT, Sparabo, and the Jamba model that merges traditional transformer and Mamba layers for improved runtime efficiency."
    ],
    "points": 298,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1711643816
  },
  {
    "id": 39852167,
    "title": "Dioxus 0.5: Revamped Core, Signal-based API, and Enhanced App Development",
    "originLink": "https://dioxuslabs.com/blog/release-050/",
    "originBody": "Dioxus 0.5: Signal Rewrite, Remove lifetimes, CSS Hotreloading, and more! March 28, 2024 @jkelleyrtp, @ealmloff The story Here at Dioxus Labs, we have an unofficial rule: only one rewrite per year. Our last rewrite brought some amazing features: templates, hotreloading, and insane performance. However, don’t be mistaken, rewrites are scary, time consuming, and a huge gamble. We started this new rewrite on January 1st of 2024, completed it by Feburary 1st, and then spent another month and a half writing tests, squashing bugs, and polishing documentation. Rewrites are absolutely not for the faint of heart. If you’re new here, Dioxus (dye•ox•us) is a library for building GUIs in Rust. Originally, I built Dioxus as a rewrite of Yew with the intention of supporting proper server-side-rendering. Eventually, Dioxus got popular, we got some amazing sponsors, and I went full time. We’ve grown from a team of 1 (me) to a team of 4(!) - pulled entirely from the wonderful dioxus community. Now, Dioxus is something a little different. Real life, actual companies are shipping web apps, desktop apps, and mobile apps with Dioxus. What was once just a fun little side project powers a small fraction of apps out in the wild. We now have lofty goals of simplifying the entire app development ecosystem. Web, Desktop, Mobile, all end-to-end typesafe, blazing fast, living under one codebase. The dream! With 0.5 we took a hard look at how Dioxus would need to change to achieve those goals. The request we got from the community was clear: make it simpler, make it robust, make it polished. What’s new? This is probably the biggest release of Dioxus ever, with so many new features, bug fixes, and improvements that I can’t list them all. We churned over 100,000 lines of code (yes, 100,000+) with over 1,400 commits between 0.4.3 and 0.5.0. Here’s a quick overview: Complete rewrite of dioxus-core, removing all unsafe code Abandoning use_state and use_ref for a clone-free Signal-based API Removal of all lifetimes and the cx: Scope state A single, unified launch function that starts your app for any platform Asset hotreloading that supports Tailwind and Vanilla CSS Rewrite of events, allowing access to the native WebSys event types Extension of components with element properties (IE a Link now takes all ofproperties) Integrated Error Boundaries and Server Futures with Suspense integration 5x faster desktop reconciliation and custom asset handlers for streaming bytes Streaming server functions and fullstack hotreloading Tons of QoL improvements, bug fixes, and more! 💡 If you are updating from DIoxus 0.4, a migration guide is available Lifetime Problems To make Dioxus simpler, we wanted to remove lifetimes entirely. Newcomers to rust are easily scared off by lifetime issues, and even experienced Rustaceans find wading through obtuse error messages exhausting. In dioxus 0.1-0.4, every value in a component lives for a 'bump lifetime. This lifetime lets you easily use hooks, props and the scope within event listeners without cloning anything. It was the chief innovation that made Dioxus so much easier to use than Yew when it was released. // Scope and Element have the lifetime 'bump fn OldDioxusComponent(cx: Scope) -> Element { // hook has the lifetime 'bump let mut state = use_state(cx, || 0); cx.render(rsx! { button { // The closure has the lifetime 'bump which means you don't // need to clone hook before you move it into the closure onclick: move |_event| *state += 1, } }) } Rust Copy This works great for hooks most of the time. The lifetime lets you omit a bunch of manual clones every time you want to use a value inside an EventHandler (onclick, oninput, etc). However, the lifetime doesn’t work for futures. Futures in dioxus need to be 'static which means you always need to clone values before you use them in the future. Since a future might need to run while the component is rendering, it can’t share the component’s lifetime. // Scope and Element have the lifetime 'bump fn OldDioxusComponent(cx: Scope) -> Element { // state has the lifetime 'bump let state = use_state(cx, || 0); cx.spawn({ // Because state has the lifetime 'bump, we need to clone it to make it // 'static before we move it into the 'static future let state = state.clone(); async move { println!(\"{state}\"); } }); // ... } Rust Copy If you don’t clone the value, you will run into an error like this: 4fn OldDioxusComponent(cx: Scope) -> Element {--|`cx` is a reference that is only valid in the function bodyhas type `&'1 Scoped` ... 8/ cx.spawn(async move { 9| println!(\"{state}\"); 10| });| ^|| |______`cx` escapes the function body hereargument requires that `'1` must outlive `'static` Rust Copy The error complains that cx must outlive 'static without mentioning the hook at all which can be very confusing. Dioxus 0.5 fixes this issue by first removing scopes and the 'bump lifetime and then introducing a new Copy state management solution called signals. Here is what the component looks like in dioxus 0.5: // Element has no lifetime, and you don't need a Scope fn NewComponent() -> Element { // state is 'static and Copy, even if the inner value you store is not Copy let mut state = use_signal(|| 0); // State is already 'static and Copy, so it is copied into the future automatically spawn(async move { println!(\"{state}\"); }); rsx! { button { // The closure has the lifetime 'static, but state is copy so you don't need to clone into the closure onclick: move |_event| state += 1, } } } Rust Copy While this might seem like a rather innocuous change, it has an impressively huge impact on how easy it is to write new components. I’d say building a new Dioxus app is about 2-5x easier with this change alone. Goodbye scopes and lifetimes! In the new version of dioxus, scopes and the 'bump lifetime have been removed! This makes declaring a component and using runtime functions within that component much easier: You can now declare a component by just accepting your props directly instead of a scope parameter #[component] fn MyComponent(name: String) -> Element { rsx! { \"Hello {name}!\" } } Rust Copy And inside that component, you can use runtime functions directly spawn(async move { tokio::time::sleep(Duration::from_millis(100)).await; // You can even use runtime functions inside futures and event handlers! let context: i32 = consume_context(); }); Rust Copy Now that lifetimes are gone, Elements are 'static which means you can use them in hooks or even provide them through the context API. This makes some APIs like virtual lists in dioxus significantly easier. We expect more interesting APIs to emerge from the community now that you don’t need to be a Rust wizard to implement things like virtualization and offscreen rendering. Removal of all Unsafe in Core Removing the 'bump lifetime along with the scope gave us a chance to remove a lot of unsafe from dioxus. dioxus-core 0.5 contains no unsafe code 🎉 There’s still a tiny bit of unsafe floating around various dependencies that we plan to remove throughout the 0.5 release cycle, but way less: all quite simple to cut or unfortunately necessary due to FFI. Signals! Dioxus 0.5 introduces Signals as the core state primitive for components. Signals have two key advantages over the existing use_state and use_ref hooks: They are always Copy and they don’t require manual subscriptions. Copy state Signal is Copy, even if the inner T values is not. This is enabled by our new generational-box crate (implemented with zero unsafe). Signals can even optionally be Send+Sync if you need to move them between threads, removing the need for a whole class of specialized state management solutions. The combination of Copy + Send + Sync Signals, and static components makes it incredibly easy to move state to anywhere you need it: fn Parent() -> Element { // We use a sync signal here so that we can use it in other threads, // but you could use a normal signal if you have !Send data let mut state = use_signal_sync(|| 0); spawn(async move { // Signals have a ton of helper methods that make them easy to work with. // You can call a signal like a function to get the current value let value: i32: state(); }); // Because signals can be sync, we can copy them into threads easily std::thread::spawn(move || { loop { std::thread::sleep(Duration::from_millis(100)); println!(\"{state}\"); } }); rsx! { button { // You can easily move it into an event handler just like use_state onclick: move |_| state += 1 } } } Rust Copy With Copy state, we’ve essentially bolted on a light form of garbage collection into Rust that uses component lifecycles as the triggers for dropping state. From a memory perspective, this is basically the same as 0.4, but with the added benefit of not needing to explicitly Clone anything. Smarter subscriptions Signals are smarter about what components rerun when they are changed. A component will only rerun if you read the value of the signal in the component (not in an async task or event handler). In this example, only the child will re-render when the button is clicked because only the child component is reading the signal: fn Parent() -> Element { let mut state = use_signal(|| 0); rsx! { button { onclick: move |_| state += 1, \"increment\" } Child { state } } } #[component] fn Child(state: Signal) -> Element { rsx! { \"{state}\" } } Rust Copy Smarter subscriptions let us merge several different hooks into signals. For example, we were able to remove an entire crate dedicated to state management: Fermi. Fermi provided what was essentially a use_state API where statics were used as keys. This meant you could declare some global state, and then read it in your components: static COUNT: Atom = Atom::new(|| 0); fn Demo(cx: Scope) -> Element { let mut count = use_read_atom(cx, &COUNT); rsx! { \"{count}\" } } Rust Copy Since fermi didn’t support smart subscriptions, you had to explicitly declare use the right use_read/ use_write hooks to subscribe to the value. In Dioxus 0.5, we just use signals, eliminating the need for any sort of external state management solution altogether. // You can use a lazily initialized signal called // GlobalSignal in static instead of special Fermi atoms static COUNT: GlobalSignal = Signal::global(|| 0); // Using the GlobalSignal is just the same as any other signal! // No need for use_read or use_write fn Demo() -> Element { rsx! { \"{COUNT}\" } } Rust Copy Signals even work with the context API, so you can quickly share state between components in your app: fn Parent() -> Element { // Create a new signal and provide it to the context API // without a special use_shared_state hook let mut state = use_context_provider(|| Signal::new(0)); rsx! { button { onclick: move |_| state += 1, \"Increment\" } Child {} } } fn Child() -> Element { // Get the state from the context API let state = use_context::>(); rsx! { \"{state}\" } } Rust Copy Smart subscriptions also apply to hooks. Hooks like use_future and use_memo will now automatically add signals you read inside the hook to the dependencies of the hook: // You can use a lazily initialized signal called GlobalSignal in static instead of special Fermi atoms static COUNT: GlobalSignal = Signal::global(|| 0); fn App() -> Element { // Because we read COUNT inside the memo, it is automatically added to the memo's dependencies // If we change COUNT, then the memo knows it needs to rerun let memo = use_memo(move || COUNT() / 2); rsx! { \"{memo}\" } } Rust Copy CSS Hot Reloading As part of our asset system overhaul, we implemented hotreloading of CSS files in the asset directory. If a CSS file appears in your RSX, the dx CLI will watch that file and immediately stream its updates to the running app. This works for web, desktop, and fullstack, with mobile support coming in a future mobile-centric update. When combined with the Tailwind watcher, we now support hotreloading of Tailwind CSS! On top of that, we also support IDE hinting of Tailwind classes in VSCode with a custom regex extension What’s even niftier is that you can stream these changes to several devices at once, unlocking simultaneous hotreloading across all devices that you target: Event System Rewrite Since it’s release, dioxus has used a synthetic event system to create a cross platform event API. Synthetic events can be incredibly useful to make events work across platforms and even serialize them across the network, but they do have some drawbacks. Dioxus 0.5 finally exposes the underlying event type for each platform along with a trait with a cross platform API. This has two advantages: You can get whatever information you need from the platform event type or pass that type to another library: fn Button() -> Element { rsx! { button { onclick: move |event| { let web_sys_event: web_sys::MouseEvent = event.web_event(); web_sys::console::log_1(&web_sys_event.related_target.into()); } } } } Rust Copy Dioxus can bundle split code for events apps don’t use. For a hello world example, this shrinks the gzipped size ~25%! Again, this seems like a small change on the surface, but opens up dozens of new use cases and possible libraries you can build with dioxus. 💡 The Dioxus optimization guide has tips to help you make the smallest possible bundle Cross platform launch Dioxus 0.5 introduces a new cross platform API to launch your app. This makes it easy to target multiple platforms with the same application. Instead of pulling in a separate renderer package, you can now enable a feature on the dioxus crate and call the launch function from the prelude: [dependencies] dioxus = \"0.5\" [features] default = [] desktop = [\"dioxus/desktop\"] fullstack = [\"dioxus/fullstack\"] server = [\"dioxus/axum\"] web = [\"dioxus/web\"] TOML Copy use dioxus::prelude::*; fn main() { dioxus::launch(|| rsx!{ \"hello world\" }) } Rust Copy With that single application, you can easily target: # Desktop dx serve --platform desktop # SPA web dx serve --platform web # Or a fullstack application dx serve --platform fullstack Bash Copy The CLI is now smart enough to automatically pass in the appropriate build features depending on the platform you’re targeting. Asset System Beta Currently assets in dioxus (and web applications in general) can be difficult to get right. Links to your asset can easily get out of date, the link to your asset can be different between desktop and web applications, and you need to manually add assets you want to use into your bundled application. In addition to all of that, assets can be a huge performance bottleneck. Lets take a look at the dioxus mobile guide in the docsite as an example: The 0.4 mobile guide takes 7 seconds to load and transfers 9 MB of resources. The page has 6 different large image files which slows down the page loading times significantly. We could switch to a more optimized image format like avif , but manually converting every screenshot is tedious and time consuming. Lets take a look at the 0.5 mobile guide with the new asset system: The new mobile guide takes less than 1 second to load and requires only 1/3 of the resources with the exact same images! Dioxus 0.5 introduces a new asset system called manganis. Manganis integrates with the CLI to check, bundle and optimize assets in your application. The API is currently unstable so the asset system is currently published as a separate crate. In the new asset system, you can just wrap your assets in the mg! macro and they will automatically be picked up by the CLI. You can read more about the new asset system in the manganis docs. As we continue to iterate on the 0.5 release, we plan to add hot reloading to manganis assets, so you can interactively add new the features to your app like CSS, images, tailwind classes, and more without forcing a complete reload. 5x Faster Desktop Rendering Dioxus implements several optimizations to make diffing rendering fast. Templates let dioxus skip diffing on any static parts of the rsx macro. However, diffing is only one side of the story. After you create a list of changes you need to make to the DOM, you need to apply them. We developed sledgehammer for dioxus web to make applying those mutations as fast as possible. It makes manipulating the DOM from Rust almost as fast as native JavaScript. In dioxus 0.5, we apply that same technique to apply changes across the network as fast as possible. Instead of using json to communicate changes to the desktop and liveview renderers, dioxus 0.5 uses a binary protocol. For render intensive workloads, the new renderer takes only 1/5 the time to apply the changes in the browser with 1/2 the latency. Here is one of the benchmarks we developed while working on the new binary protocol. In dioxus 0.4, the renderer was constantly freezing. In dioxus 0.5, it runs smoothly: Dioxus 0.4 Dioxus 0.5 Spreading props One common pattern when creating components is providing some additional functionality to a specific element. When you wrap an element, it is often useful to provide some control over what attributes are set in the final element. Instead of manually copying over each attribute from the element, dioxus 0.5 supports extending specific elements and spreading the attributes into an element: #[derive(Props, PartialEq, Clone)] struct Props { // You can extend a specific element or global attributes #[props(extends = img)] attributes: Vec, } fn ImgPlus(props: Props) -> Element { rsx! { // You can spread those attributes into any element img { ..props.attributes } } } fn app() -> Element { rsx! { ImgPlus { // You can use any attributes you would normally use on the img element width: \"10px\", height: \"10px\", src: \"https://example.com/image.png\", } } } Rust Copy Shorthand attributes Another huge quality-of-life feature we added was the ability to use shorthand struct initialization syntax to pass attributes into elements and components. We got tired of passing class: class everywhere and decided to finally implement this long awaited feature, at the expense of some code breakage. Now, it’s super simple to declare attributes from props: #[component] fn ImgPlus(class: String, id: String, src: String) -> Element { rsx! { img { class, id, src } } } Rust Copy This feature works for anything implementing IntoAttribute, meaning signals also benefit from shorthand initialization. While signals as attributes don’t yet skip diffing, we plan to add this as a performance optimization throughout the 0.5 release cycle. Multi-line attribute merging Another amazing feature added this cycle was attribute merging. When working with libraries like tailwind, you’ll occasionally want to make certain attributes conditional. Before, you had to format the attribute using an empty string. Now, you can simply add an extra attribute with a conditional, and the attribute will be merged using a space as a delimiter: #[component] fn Blog(enabled: bool) -> Element { rsx! { div { class: \"bg-gray-200 border rounded shadow\", class: if enabled { \"text-white\" } } } } Rust Copy This is particularly important when using libraries like tailwind where attributes need to be parsed at compile time but also dynamic at runtime. This syntax integrates with the tailwind compiler, removing the runtime overhead for libraries like tailwind-merge. Server function streaming Dioxus 0.5 supports the latest version of the server functions crate which supports streaming data. Server functions can now choose to stream data to or from the client. This makes it easier to do a whole class of tasks on the server. Creating a streaming server function is as easy as defining the output type and returning a TextStream from the server function. Streaming server functions are great for updating the client during any long running task. We built an AI text generation example here: https://github.com/ealmloff/dioxus-streaming-llm that uses Kalosm and local LLMS to serve what is essentially a clone of OpenAI’s ChatGPT endpoint on commodity hardware. #[server(output = StreamingText)] pub async fn mistral(text: String) -> Result { let text_generation_stream = todo!(); Ok(TextStream::new(text_generation_stream)) } Rust Copy Side note, the AI metaframework used here - Kalosm - is maintained by the Dioxus core team member ealmloff, and his AI GUI app Floneum is built with Dioxus! Fullstack CLI platform The CLI now supports a fullstack platform with hot reloading and parallel builds for the client and sever. You can now serve your fullstack app with the dx command: dx serve # Or with an explicit platform dx serve --platform fullstack Bash Copy Liveview router support https://github.com/DioxusLabs/dioxus/pull/1505 @DonAlonzo added liveview support for the router in dioxus 0.5. The router will now work out of the box with your liveview apps! Custom Asset Handlers https://github.com/DioxusLabs/dioxus/pull/1719 @willcrichton added support for custom asset handlers to dioxus desktop. Custom asset handlers let you efficiently stream data from your rust code into the browser without going through javascript. This is great for high bandwidth communication like video streaming: Now, you can do things like work with gstreamer or webrtc and pipe data directly into the webview without needing to encode/decode frames by hand. Native File Handling This is a bit smaller of a tweak, but now we properly support file drops for desktop: Previously we just gave you the option to intercept filedrops but now it’s natively integrated into the event system Error handling Error handling: You can use error boundaries and the throw trait to easily handle errors higher up in your app Dioxus provides a much easier way to handle errors: throwing them. Throwing errors combines the best parts of an error state and early return: you can easily throw an error with ?, but you keep information about the error so that you can handle it in a parent component. You can call throw on any Result type that implements Debug to turn it into an error state and then use ? to return early if you do hit an error. You can capture the error state with an ErrorBoundary component that will render the a different component if an error is thrown in any of its children. fn Parent() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"Oops, we encountered an error. Please report {error} to the developer of this application\" }, ThrowsError {} } } } fn ThrowsError() -> Element { let name: i32 = use_hook(|| \"1.234\").parse().throw()?; todo!() } Rust Copy You can even nest ErrorBoundary components to capture errors at different levels of your app. fn App() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"Hmm, something went wrong. Please report {error} to the developer\" }, Parent {} } } } fn Parent() -> Element { rsx! { ErrorBoundary { handle_error: |error| rsx! { \"The child component encountered an error: {error}\" }, ThrowsError {} } } } fn ThrowsError() -> Element { let name: i32 = use_hook(|| \"1.234\").parse().throw()?; todo!() } Rust Copy This pattern is particularly helpful whenever your code generates a non-recoverable error. You can gracefully capture these \"global\" error states without panicking or handling state for each error yourself. Hotreloading by default and “develop” mode for desktop We shipped hotreloading in 0.3, added it to desktop in 0.4, and now we’re finally enabling it by default in 0.5. By default, when you dx serve your app, hotreloading is enabled in development mode. Additionally, we’ve drastically improved the developer experience of building desktop apps. When we can’t hotreload the app and have to do a full recompile, we now preserve the state of the open windows and resume that state. This means your app won’t block your entire screen on every edit and it will maintain its size and position, leading to a more magical experience. Once you’ve played with it, you can never go back - it’s that good. Updates to the dioxus template With this update, our newest core team member Miles put serious work into overhauling documentation and our templates. We now have templates to create new dioxus apps for web, desktop, mobile, tui, and fullstack under one command. We also updated the default app you get when using dx new to be closer to the traditional create-react-app. The template is now seeded with assets, CSS, and some basic deploy configuration. Plus, it includes links to useful resources like dioxus-std, the VSCode Extension, docs, tutorials, and more. Dioxus-Community and Dioxus-std The Dioxus Community is something special: discord members marc and Doge have been hard at working updating important ecosystem crates for the 0.5 release. With this release, important crates like icons, charts, and the dioxus-specific standard library are ready to use right out the gate. The Dioxus Community project is a new GitHub organization that keeps important crates up-to-date even when the original maintainers step down. If you build a library for Dioxus, we’ll be happy to help maintain it, keeping it at what is essentially “Tier 2” support. Coming soon At a certain point we had to stop adding new features to this release. There’s plenty of cool projects on the horizon: Stabilizing and more deeply integrating the asset system Bundle splitting the outputted .wasm directly - with lazy components Islands and resumable interactivity (serializing signals!) Server components and merging LiveView into fullstack Enhanced Devtools (potentially featuring some AI!) and testing framework Complete mobile overhaul Fullstack overhaul with websockets, SSE, progressive forms, and more Sneak Peek: Dioxus-Blitz revival using Servo We’re not going to say much about this now, but here’s a sneak peek at “Blitz 2.0”… we’re finally integrating servo into blitz so you can render natively with WGPU using the same CSS engine that powers Firefox. To push this effort forward, we’ve brought the extremely talented Nico Burns (the wizard behind our layout library Taffy) on full time. More about this later, but here’s a little demo of google.com being rendered at 900 FPS entirely on the GPU: Admittedly the current iteration is not quite there (google.com is in fact a little wonky) but we’re progressing rapidly here and are quickly approaching something quite usable. The repo is here if you want to take a look and get involved: https://github.com/jkelleyrtp/stylo-dioxus How can you contribute? Well, that’s it for the new features. We might’ve missed a few things (there’s so much new!). If you find Dioxus as exciting as we do, we’d love your help to completely transform app development. We’d love contributions including: Translating docs into your native language Attempting “Good First Issues” Improving our documentation Contributing to the CLI Help answer questions from the discord community That’s it! We’re super grateful for the community support and excited for the rest of 2024. Build cool things! ✌",
    "commentLink": "https://news.ycombinator.com/item?id=39852167",
    "commentBody": "Dioxus 0.5: Web, Desktop, Mobile Apps in Rust (dioxuslabs.com)293 points by jkelleyrtp 19 hours agohidepastfavorite103 comments terhechte 19 hours agoI build a Mastodon client with Dioxus last year [1] and it was in general a good experience, but it was also clear that lots of things were still missing (I mean, it was also at version 0.2 when I started working on it). With these 0.5 changes the Dioxus authors remove almost all the complexities that I ran into when working on Ebou. I haven't played around with it yet, but the removal of lifetimes and constant cloning will make it a much more pleasant experience. I'm looking forward to trying it out, congratulations to the team for such an awesome release! [1]: https://github.com/terhechte/Ebou reply ryukoposting 13 hours agoparent> in general a good experience, but it was also clear that lots of things were still missing I'll second that. I was working on a GUI frontend for sshfs in Dioxus about 9 months ago. My impression was that it's a really, really good GUI framework... until you run into a wall because the developers aren't finished with some feature yet. Sharing state across different contexts can also be a pain sometimes, but that's true of every GUI framework I've ever used, regardless of language or underlying technologies. Dioxus 0.5 looks like a big leap forward in this regard. My blog uses Dioxus to render a sizable portion of its HTML. In that use case, its limits aren't pushed, and it does a wonderful job. reply echelon 18 hours agoparentprevHow did you choose Dioxus? There are about a dozen Rust frameworks [1] that are trying to do the \"native, reactive UI\" you can deploy on desktop, web/wasm, mobile, etc. I'm worried about betting on the wrong horse and being stuck maintaining abandonware or being faced with a painful and pointless migration. In a similar evolutionary race, there were dozens of Rust HTTP server frameworks. Now Axum, Actix, and Rocket appear to have the lead. I'm worried I made the wrong choice as the community momentum appears to be shifting to Axum. Is there any indication Dioxus will win? It looks to have a large community, venture backing [2] (a good sign!), and more momentum than some of the others. I'd like to use one of these frameworks now, but I worry it's too early to place a bet. Are there any good indicators that now is a good time to start using it? Are Leptos and Yew the other top contenders? These are the two names I hear the most, apart from Dioxus. What would make them a better (or worse) choice? My company is heavily invested in Rust, Actix, and Bevy. We're looking at pairing Bevy with Dioxus or a similar framework to deliver native desktop and mobile clients in the future. I just want to make the right choice. Also, stupid question: is Dioxus named after the Pokemon [3]? The logo makes me think there's something to that, but there are no Pokemon references in the codebase. [1] https://github.com/flosse/rust-web-framework-comparison [2] https://www.ycombinator.com/companies/dioxus-labs [3] https://m.bulbapedia.bulbagarden.net/wiki/Deoxys_(Pok%C3%A9m... reply jkelleyrtp 17 hours agorootparentCreator here, so I'm biased... Yew has had about 10 commits in the past 6 months and the original creator has since moved on. Leptos is a good solution for web-app type stuff, but IMO there's a big usability gap. I'll let the community be the judge there, but I wrote up some differences here: https://github.com/dioxusLabs/dioxus/?tab=readme-ov-file#dio... Leptos was fortunate enough to receive a lot of attention from youtubers on its launch. The most important thing here: we raised venture money for Dioxus. We have many years of runway, are pretty lean, and exclusively focused on pouring resources into making the best GUI library for Rust (and potentially branching out to Python/JS). Getting into YC isn't easy, raising money isn't easy, and there's currently no other Rust projects with similar goals, talent, and financial backing. Biased of course. Oh, and we're committed to the bevy integration. bevy_dioxus is already updated for 0.5 and we share corporate sponsors with the bevy folks. Final point, legally, no we're not inspired by any pokemon with a similar sounding name. Even though that pokemon is awesome. reply dorian-graph 17 hours agorootparent> The most important thing here: we raised venture money for Dioxus. Important, but in a _bad_ way? What will the VC expect out of Dioxus? How will you make money? reply jkelleyrtp 17 hours agorootparentVenture doesn't necessarily mean bad. Long term the goal the goal is to dissolve the gates to Apple and Google's walled gardens, which I personally believe is a net good. As much is the idealist in me wants to do that with no venture backing, the realist in me knows we need Dioxus to be self sustaining and providing legitimate value for people to switch. Google spends 76 million dollars a year on catering alone - there's no way you can compete with Android and Flutter without huge resources. Apple and Google capture the value for their platforms via fees and lock-in. Our goal is to capture value by providing really good utilities for building and deploying apps. You can't move heaven and earth without a really big lever, and venture gives us more leverage. reply steveklabnik 17 hours agorootparentIf you don't mind me asking, what's the actual business model here? Are you going to charge for those utilities? reply jkelleyrtp 16 hours agorootparentYes, we're looking at something like a Vercel/Expo model, probably built on Fly, Cloudflare, or AWS, but designed to be self hosted. We've got a decent amount of enterprise adoption and I think there's money to be made by selling something like a self-hosted Vercel. TBD on licensing - I'd want it to be open source but we wouldn't want people reselling our deploy platform. We raised a seed to prove that people want to build with dioxus. If that hypotheses is validated, then we invest in the deploy model. If not, we have OSS grants and corporate sponsors that will keep the project alive for years even if the VC money runs out. I'm not super interested in making money at the hobbyist tier - those developers are our evangelists. Enterprise self hosting is likely harder but I think we can provide a lot of value to teams building apps in large companies. reply anp 9 hours agorootparentAs a former Expo employee and someone who took a run at this space (moxie) before running out of steam, it’s really exciting to hear this is the approach you’re taking! I’ll be keeping an eye out :). reply margorczynski 8 hours agorootparentprevCool stuff man, wishing you and the team all the best as a person who quite often uses Flutter for side projects but isn't a big fan of Dart. Any ETA on it being stable/1.0? reply steveklabnik 16 hours agorootparentprevNeat, thank you! reply SkyMarshal 16 hours agorootparentprevSpeaking of Flutter, that and Electron seem to be the only really mature multi-platform build systems. What is Dioxus's competitive proposition vs those two? The performance and memory efficiency+safety of Rust is one, any others? reply jkelleyrtp 16 hours agorootparentI'd add React-Native / expo to your list. Flutter is written in Dart but renders to a canvas on the web making it a very, very poor choice for web apps. Especially backend/fullstack apps. Plus you can't use tailwind or whatever flavor of css library there is today. Flutter just nailed the \"get up and running\" part which we've got as well: `cargo binstall dioxus-cli`, `dx new`, `dx bundle` is literally less than 30 seconds. Hopefully `dx deploy` coming soon. Electron is... it's electron. A whole chromium instance, an IPC bridge between your frontend and the system, NodeJS, etc. If you compile for size, our desktop apps are 3mb. You can easily deploy them on an embedded/low end device. We're hoping to eat some market share in the embedded-ish land (not true embedded, but like industrial or POS). Dioxus also has mobile and desktop compatible server functions which basically no other projects have. Expo has been kinda exploring this space. One of our examples is deploying your own LLM on your own infrastructure with a dioxus mobile app UI and it fits in a single file and builds in under a minute. reply SkyMarshal 13 hours agorootparentThanks, wasn't aware of Expo, though it seems to only do mobile+web apps but not desktop apps? > If you compile for size, our desktop apps are 3mb. I'm aware of this from familiarity with Tauri, but hearing it again still amazes me. Very cool. I have an app in mind I want to build, and really would like to have standalone versions on Android+iOS+Linux+Mac+Windows, plus a web app. But there's no way I can manage all that as a single developer. And the fact no development tool has really nailed this yet is telling how hard it is. Whoever really gets this right will save a ton of developer hours across the industry, and that's valuable. Good luck, hope you guys pull it off! PS - one feature request: a local/offline-first mode that eases development of apps that work even with poor or no internet connection. Basically I want to build something like Obsidian that is multi-platform, and does all processing and data storage locally first, in an accessible format like SQLLite or flat files, then syncs with the cloud when available, all with as few developer resources as possible. A tool that enables that would be amazing. reply filleduchaos 10 hours agorootparentprev> Flutter is written in Dart but renders to a canvas on the web making it a very, very poor choice for web apps. Flutter has an HTML renderer (https://docs.flutter.dev/platform-integration/web/renderers), but it's lower-performance than CanvasKit. reply azemetre 17 hours agorootparentprevYeah, it's becoming more common in my group of SWEs to specifically opt to NOT use VC backed software. Everyone has stories about companies closing shop and projects failing to continue onward. Why would Dioxus be any different? If VC's cared about tearing down walled gardens of Google and Apple, why not explicitly donate the money instead? Why have strings attached at all? reply nemothekid 16 hours agorootparentFor a GUI based project, I'd actually prefer they were VC and/or corporate backed with clear governance. OSS backend libraries are easily forked, and someone is usually willing to hack on a database library, but GUIs tend to be boring to work on, and designers don't tend to have to the same gumption to work for free that developers do. reply jkelleyrtp 16 hours agorootparentprevWe have grants and corporate sponsors to keep the project alive even if the VC money runs out. This was all a side project for me at first, so I went down the \"donation\" route in the beginning. Donations are great but they're not how the system works, unfortunately. Dioxus could never compete with the two most valuable companies on earth if it wasn't a self-sustaining business. VC just lets me scale the team from 2 people to 10(?) and have some cash to iterate. We were \"profitable\" even before taking venture money. Now we're able to take on more moonshot-type projects like the blitz renderer, a deploy platform, UI fuzz tooling, and more. We're using our seed round exclusively to make dioxus as awesome as possible, so even if it doesn't work out at a venture level, there's still a really cool, polished, end-to-end app framework that you can build and ship with in Rust. reply azemetre 15 hours agorootparentThat's fair and you're welcome to chart your own path, but I like what Tauri does with their governance model: https://dracc.commonsconservancy.org/0035/ https://tauri.app/about/governance Just for me personally, I don't see the financialization of open source software as an intrinsic good thing and I reflect my technology choices to support this when applicable. reply jkelleyrtp 14 hours agorootparentWe'll probably explore that in the future but right now our team is literally just 2.5 fulltime engineers. Tauri is seeking monetization via CrabNebula, but I can see how the governance structure would secure more confidence in the OSS side. http://crabnebula.dev reply riku_iki 16 hours agorootparentprev> it's becoming more common in my group of SWEs to specifically opt to NOT use VC backed software so, what they use instead? Bugged, dead OSS dropped by creators?.. reply azemetre 15 hours agorootparentNo, normal OSS whose existence isn't tied to VC mostly. It's not like a hard/fast rule, just a heuristic. reply riku_iki 14 hours agorootparentThere are very few good quality, stable, active OSS projects which is not fed by VC/corps money. In this case (UI for rust) there is no much choice. reply fabrice_d 13 hours agorootparentFunding by VC and funding by corps sponsors are 2 very different things. Check how linux desktop projects such as Gnome & KDE kept the lights on for >20 years without VC funding. reply riku_iki 12 hours agorootparent> Funding by VC and funding by corps sponsors are 2 very different things Ok, if you find corp which will give you funding for your project without any expectations, then it is a win. But I am not sure how often this happens. reply fabrice_d 10 hours agorootparentThere are expectations of course, but the ones from a corp will be different from a VC. Typically the corp will expect you to build something they need and can use, a VC will only want financial return on investment. reply wpietri 16 hours agorootparentprev\"There are more things in heaven and Earth, Horatio, / Than are dreamt of in your philosophy.\" reply riku_iki 16 hours agorootparentprev> What will the VC expect out of Dioxus? there are several ways to monetize: - consultancy - \"Pro\" extensions on top of OSS core reply yencabulator 14 hours agorootparentConsultancy is unlikely to give VC a 100x return. Enterprise extensions means the cursed land of open core and refusing to have features in the open source version, or a heavy SaaS push combined with a possible license change along the road, and these are the primary reasons to avoid VC-backed \"open source for now\". reply riku_iki 13 hours agorootparent> Enterprise extensions means the cursed land of open core and refusing to have features in the open source version yes, there are risks in exchange of VC money. You can branch your \"Libre\" project any time, and continue building on top of infra developed using VC funds and which you get for free. But what are other choices? reply unshavedyak 16 hours agorootparentprev> Oh, and we're committed to the bevy integration. bevy_dioxus is already updated for 0.5 and we share corporate sponsors with the bevy folks. I checked out the crate and am still a bit confused. If i may, is it a goal of bevy_dioxus to allow standard bevy gamedev but with the UI portion handled by dioxus? reply jkelleyrtp 15 hours agorootparentYes, a big feature bevy is lacking is a decent editor. There's been an ongoing push to get dioxus into bevy to accelerate the editor development. Bevy's ECS model is good for games but hasn't been cleanly mapped into the traditional GUI space yet. Dioxus is composable so you can integrate it at multiple levels. The bevy folks are using our virtualdom plus state management with their own renderer. reply earthling8118 17 hours agorootparentprevAxum is certainly where it is at and where it has been for a while in terms of HTTP server frameworks. I'd say actix is in second place for sure, but it is wholly viable regardless. Rocket is no longer in the running as far as I'm concerned, and it hasn't been for quite some time. Dioxus is certainly taking the head spot in front end. I still have more concern about the venture backing than I have confidence about it, but for better or for worse, it is certainly the best attempt at this so far. I enjoyed yew as a react-style framework, but its development is slow. Dioxus has made a lot of progress, and in my experience, it is currently the best experience that can be had. It's hard to say if now is the correct time, but I'd be watching it closely if I were you. There's been major work to improve the framework with many of the interfaces changing. Now might be a good time because of the progress made here, but I wouldn't be surprised if there were more changes in store. Although I imagine that you're used to that from bevy anyway. reply qchris 9 hours agorootparentNot sure if you've already seen this, but back in November, Rocket 0.5 (stable) was released, and a 501(c)3 dedicated to Rocket was formed that now owns the Github org, etc. As a result, it's been getting much more regular updates, with the original maintainer still involved in development but no longer the only person with push access. I'd certainly agree that it's no longer the de facto top leader, but as a batteries-included HTTP server, it works well (it's been chugging along powering my personal website for years now) and as far as I know still has quite a sizeable userbase. [1] https://rocket.rs/news/2023-11-17-version-0.5/ reply cchance 18 hours agorootparentprevI'd say leptos and dioxus are the bigger ones now i feel like many people moved from ywe to those 2 reply WuxiFingerHold 5 hours agoprevHonest question: I get why React has created the naming convention of \"use*\" for their hooks API. It makes sense to me. But why is in Dioxus creating a new signal called \"use_signal\"? This function call creates a new signal, doesn't it? The signal is not recreated on every rendering (that's the whole point of signals). let mut count = use_signal(|| 0); In SolidJS you create a signal with createSignal, which makes much more sense to me. const [count, setCount] = createSignal(0) The naming of the API matters, because state hooks behave much differently and might have complementing needs like \"useMemo\". Is there a reason Dioxus for the \"use_signal\" naming other than trying to be close to React? reply airstrike 13 hours agoprevI kinda wish instead of RSX we got something closer to SwiftUI than to React/JSX I feel like despite the name and all the good it did for JS and the web, React is not exactly how I would envision \"reactive UI\" code to look like in 2024 if we have the choice of designing a language (or DSL) from a blank state Which is not to say SwiftUI is perfect, but whatever code I write with it feels much more neatly organized / compartmentalized than similar code using React IMHO the only real advantage of using JSX for cross-platform GUIs is... to reuse existing libraries that were built for the web, which means something like RSX has very little \"transferable value\" other than letting the developer transfer their conceptual knowledge of JSX to RSX. I'd argue that's a worse tradeoff than having the developer learn some new paradigm that is (again IMHO) objectively superior to the React/JSX one TL;DR \"SwiftUI but cross-platform\" is the project I wish existed but doesn't. I'm aware of @Tokamak/TokamakUI but that's still very much incomplete and activity seems to have waned reply prabir 13 hours agoparentThere is https://ribir.org/. Currently it only supports native desktop apps on Linux/mac/windows but they have plans for WASM/web/mobile. reply airstrike 12 hours agorootparentThanks for sharing that. It looks very interesting and I had not come across it even after lots of googling. It's still in 0.2 but I will definitely keep track of its development, so thank you reply skybrian 18 hours agoprevI’m not a Rust programmer, but I’m curious, and I’m wondering if someone could explain how their generational-box crate works? [1] I understand that it’s some kind of arena allocation, but I don’t understand how they support copying without copying, or how this is safe: > Internally, generational-box creates an arena of generational RefCell's that are recycled when the owner is dropped. You can think of the cells as something like &'static RefCell> with a generational check to make recycling a cell easier to debug. Then GenerationalBox's are Copy because the &'static pointer is Copy Like okay, you can create a pointer to static data, but what if it’s something that doesn’t have a static lifetime? [1] https://crates.io/crates/generational-box reply Evan-Almloff 17 hours agoparentWe are copying the reference to the data, not the data itself. The reference to the data lasts for the lifetime of the program. Generational box lets you insert data that last for shorter than the lifetime of the program (as long as that data contains no references). Once you drop the data you inserted, we reuse the box for other allocations. It uses a very similar approach to a generational arena but with boxes instead of a centralized arena (to avoid locking issues). If you try to access the Copy reference to the data after it has been dropped, it will fail with a nice error message reply skybrian 17 hours agorootparentThanks. I’m wondering if this allows for non-static data at all? Maybe it has to be either static or copyable? reply Evan-Almloff 16 hours agorootparentAll data you insert into a generational box needs to be allowed to last for the 'static lifetime (have no internal temporary pointers). You cannot insert something like &'a str into a generational box reply steveklabnik 17 hours agoparentprevI am not familiar with this crate, but I am with Rust, here’s my take: Copy is a specific thing in Rust, it means that if a type implements the Copy trait, it can be copied via a memcpy, that is, it’s like a “shallow” copy as opposed to a “deep” copy. So they’re not “copying without copying”, they’re letting you treat a non-Copy type as a Copy type, in my understanding. > what if it’s something that doesn’t have a static lifetime? The read me says it requires static content so the answer is “you can’t do that.” reply skybrian 15 hours agorootparentCould you use position-independent internal references (relative pointers) to make data copyable? Does Rust have good support for that? reply steveklabnik 13 hours agorootparentRust does not have native support for relative pointers, so you'd have to hack that together with unsafe. It's not generally done. reply sanity 15 hours agoprevI just picked Dioxus to build a decentralized homepage for Freenet[1], it will be the first decentralized website people see when they get Freenet set up. It reminds me a bit of my Kotlin web framework called Kweb[2] that I've been working on on-and-off for a few years now, particularly the way it handles state and the DSL that maps from code to HTML. So far I like what I see. [1] https://freenet.org/ [2] https://kweb.io/ reply jkelleyrtp 15 hours agoparentThat's awesome!! I must've ran into kweb when designing the DSL at first - they're so similar. I'm secretly a huge kotlin fan and love the kotlin DSLs and concurrency models. reply sanity 9 hours agorootparentHah, yes - I've been a big fan of Kotlin for the past decade or so, although Rust is growing on me rapidly. In particular, I think Rust's tooling is a lot better - too many headaches with Gradle. I've pondered the idea of doing something like Kweb in Rust but looks like you've already done it with Dioxus so thank you for saving me the time :) reply m0meni 18 hours agoprevBeen following this for a while and super excited to see it out! I love how Dioxus captures a lot of what made React successful, but also while innovating on top of it and shipping at a super fast rate. Congrats to the team. Excited to try out the signals in this release. reply KolmogorovComp 18 hours agoprevI've been following dioxus with interest despite not having a chance to use it yet. However I'm a bit perplexed with the solution to remove lifetimes [0]. Isn't it a poor's-man GC? What was the performance impact? [0]: https://crates.io/crates/generational-box Side-note: `[generational-box](https://crates.io/crates/generational-box)` link is broken reply jkelleyrtp 18 hours agoparentIt is poor man's GC, but the memory semantics are exactly the same as the previous version. Since `use_hook` owns a value for the lifetime of the component, that value is dropped when the component drops. All signals still `use_hook` so their lifetimes are the same. No performance impact whatsoever since we generally discourage calling `GenerationalBox::new()` outside of use_hook. Now if you spammed `GenerationalBox::new()` in a loop or something, yeah, your garbage will exist until the component drops. But most of the time folks will just push/pop from a Map or a Vec and regular memory semantics apply. reply ramesh31 18 hours agoparentprev>However I'm a bit perplexed with the solution to remove lifetimes [0]. Isn't it a poor's-man GC? This is essentially just ARC: https://en.wikipedia.org/wiki/Automatic_Reference_Counting reply sirwhinesalot 14 hours agorootparentRust's Arc is like ARC, this is more like a generational pool of Box. reply CJefferson 10 hours agoprevCongratulations on the new release! How is the support for SVG which I can interact with? I’m thinking of something like drawing a sudoku as an SVG, then letting people click on each cell. reply Evan-Almloff 8 hours agoparentIt is pretty good. I am working on an application that uses SVGs as a way to draw a workflow editor UI with Dioxus: https://github.com/floneum/floneum reply palmfacehn 18 hours agoprevHow does this render native apps? Is it still within a browser instance of some kind? reply jkelleyrtp 18 hours agoparentYou can choose between using the system's webview as your renderer or an experimental WGPU-based engine that pulls in stylo (the piece of servo shared with Firefox). We're hoping to move folks to the WGPU renderer in the long term, but it's still pretty raw and many companies using Dioxus are pragmatic enough to know that a webview is a good enough solution for like 90% of apps. reply ryukoposting 12 hours agorootparentFood for thought: I have started, stopped, rewrote, given up, and restarted development of a visual novel engine over and over again. My vision is something kind of like Ren'Py[1] but with cross-device game saves, cleaner packaging, improved DRM, better support for complex nonlinear plot development, and better tools for developing game mechanics that go beyond clicking through paragraphs of text. A mobile/desktop/web-friendly GUI library that handles both conventional UI elements and 2D graphics elegantly would be a total game-changer for that project, which I'm hoping to get back to eventually. I won't go into deep detail on my last stab at this project, but it involved making my own Ruby DSL compiler, making my own Ruby-to-Nim FFI library, and SDL2. It was pretty cool, and much faster than you'd expect, but also not very portable, and also nowhere close to complete. [1]: https://renpy.org/ reply tvshtr 11 hours agorootparentprevThe only webview I've seen used under Linux is gtk WebKit, which sucks ass. I really really hope that stylo/servo will eventually get there. reply littlestymaar 18 hours agorootparentprevI had a mixed feeling about your idea of writing your own HTML renderer (because making it so it is actually compatible with how browser engine are rendering their stuff is actually very hard, and even browser vendors don't actually agree on how everything should render) but seeing that you are leveraging work from servo, and even hired a former mozillian in that effort makes me much more confident in your ability to actually deliver. I wish you good luck! reply swsieber 17 hours agoprev> There’s still a tiny bit of unsafe floating around various dependencies that we plan to remove throughout the 0.5 release cycle I'd love to see what these usages are, and what motivates this. I understand that sometimes people reach for unsafe too eagerly. But the std is full of unsafe and drawing the line there sometimes seems like a line in the sand. reply jkelleyrtp 17 hours agoparentIt's mostly just needed to interact with FFI and declare some types as Send/Sync. We use it in 3 places: - fixing some FFI on iOS - enabling function-call syntax for signals (took this implementation from dtolnay) - implementing Send/Sync for an ID that uses a pointer as a hash (which honestly could be removed in lieu of a usize, now that I'm looking at it) reply swsieber 16 hours agorootparentOh, OK. That sounds more like stuff you're directly responsible for, and it looks sensible. reply n42 17 hours agoparentprevI agree, people can be a little too afraid of unsafe. but I don't think it's necessarily ill-advised for a crate author to make a goal of removing unsafe from their crate. crate authors that try to remove all unsafe often do it to relieve the burden of trust from the user. _this_, in my opinion, is the power of the `unsafe` keyword (which probably should have been split into `trust_me` blocks and `check_yourself` functions). it constrains the conversations about memory safety into very tightly defined and auditable locations in the code, AND it creates new, manageable conversations about trust. reply dasloop 18 hours agoprev\"Here at Dioxus Labs, we have an unofficial rule: only one rewrite per year.\" If you have to rewrite your code once a year, maybe it helps to plan ahead before coding. But, if you can rewrite your code once a year, you might not have too much code to worry about. reply jkelleyrtp 18 hours agoparentAgreed, but we've been doing a lot of R&D discovering new ways of doing things. Dioxus was the first Rust framework to do template-based hotreloading and we couldn't have predicted that was even possible 2 years ago. The Copy-state stuff also seemed impossible a year ago, so no way to plan ahead. Now, I think things have matured enough that there's hopefully not a major major rewrite for a long time. reply 63stack 17 hours agorootparentDid something happen in rust that made the copy state thing work? Or was it just \"huh nobody thought of this before\"? reply jkelleyrtp 17 hours agorootparentSomeone else figured it out :-) I think we had a prototype of it a long time ago but couldn't figure out how to implement drop. Leptos came out but just leaked the runtime in its initial rev. We figured we could safely recycle the runtimes and voila, problem solved. reply rtp4me 19 hours agoprevCongrats to the team! I know it has been a long process, but kudos for sticking with it! reply jkelleyrtp 18 hours agoparentIt was 3 months of work and you probably saw our alphas kicking around for a while. We had been thinking about this rewrite for like 6 months, but put it off for a while. Glad we dove into it since the finished product is so much better. reply nirvdrum 12 hours agoprevDoes anyone know how well this integrates with web components? I struggled getting Shoelace components to run well with Yew. It was doable, but by the time I had it working I decided I was using the wrong tool for the job. I'd like to revisit that project with another Rust framework though when I can find the time. reply Evan-Almloff 12 hours agoparentWe have a web components example here: https://github.com/DioxusLabs/dioxus/blob/fd21c971038840130f... Everything should work like normal except: attributes are not typed, custom event listeners must be implemented with web-sys reply nirvdrum 11 hours agorootparentOh, that’s great. I suppose it’d be nice if I could supply my own types, but strings aren’t the end of the world. Thank you for pointing me at that example. Also, thank you for linking to a particular commit. I wish GitHub would do that by default. The web is littered with GitHub links that either no longer work or highlight incorrect lines. reply yunohn 19 hours agoprevHow does this compare to Tauri? reply jkelleyrtp 18 hours agoparentWrote about that here in our readme: https://github.com/dioxusLabs/dioxus/?tab=readme-ov-file#dio... Tauri puts your frontend in the webview and you need to communicate with native Rust functions through an IPC boundary (like electron). In Dioxus your Rust code lives on the native side, so you don't need IPC to do things like read from the file system, websockets, etc. Tauri also forces your frontend to compile to WASM, and a lot of interesting rust crates don't compile to wasm. It's a little hard to express how much simpler it is to build when you don't have an IPC boundary. Dioxus' tooling is also dedicated to just Rust, so you can go from zero to bundled `.app` in less than a minute (12 seconds fresh build, 20 seconds fresh bundle). That being said we're huge fans of Tauri and the flexibility it gives you (frontend in whatever web-compatible UI you want) and you can even use Dioxus in your Tauri apps! reply 01HNNWZ0MV43FF 18 hours agorootparentI see what you mean, but to a reader unfamiliar with tauri this makes it sound really bad. Here's how I use tauri: Almost everything is native rust in the \"backend\" process, which is where main is. I don't need any ffi calls to write files, open ports, etc, it's a normal rust program that happens to have a web view. So I've never had a problem with compiling to wasm, the GUI is TypeScript and the business logic is aot rust The ipc boundary is annoying. It'll be faster in tauri 2, but in 1 it uses json or something internally, so you couldn't e.g. write a video player that uses a custom rust codec. Getting uncompressed video frames through ipc would kill perf I'll take a look how dioxus solves this reply jkelleyrtp 18 hours agorootparentOne of this release's features is getting byte streams into the webview using custom protocols. It's not as ideal as say, sharing a GPU texture with the webview, but powerful enough to do video streaming and data viz. reply dceddia 15 hours agorootparentprev> Tauri also forces your frontend to compile to WASM I’ve been using Tauri (1.x) for a couple years shipping a video editor and I don’t think this is true? I went searching to verify and I couldn’t find anything saying it complies to WASM (or at least not that it requires compiling to WASM). Can you point me to where you saw this? reply jkelleyrtp 15 hours agorootparentIf you want to use a Rust frontend framework with Tauri you need to compile to wasm. You typically use svelte/vue/react etc as the frontend, or I guess you could attempt some sort of MPA approach with SSR. Here's a guide for using Yew with Tauri. Notice how you need to install wasm-bindgen and wasm-pack. https://dev.to/stevepryde/create-a-desktop-app-in-rust-using... reply dceddia 14 hours agorootparentOhh sorry, I misunderstood what you were saying there. I'm just using Svelte in TypeScript and running it in the browser so it doesn't need to do the WASM step. reply 01HNNWZ0MV43FF 15 hours agorootparentprevWhoa. Video editor is exactly what I assumed Tauri couldn't reasonably do. (See sibling comment - I also haven't used wasm since my UI is all TS) How'd you get that working? reply dceddia 14 hours agorootparentI initially ran into that issue too (sending frames over IPC was not gonna work!) so I create a native OS-specific overlay and draw on it with wgpu. The IPC layer has been a bit annoying and I'm looking forward to Tauri 2 where that'll get faster. I've worked around it for some stuff in the meantime by using a custom protocol and serializing stuff to binary. reply veidr 4 hours agoparentprevI clicked through to ask this, as well. I appreciated Dioxus directly addressing that in the README, but would also be interested to hear experiences from people with experience using both of them. With Tauri, I built a toy desktop app to see whether the IPC was fast enough that the web frontend could update and do stuff on every keystroke without lagging (yes), and whether it could send a big file roundtrip from the frontend to the Rust layer and back to the frontend on every keystroke (no, not in my naive toy implementation anyway). It seems like there's be many use cases where either Tauri or Dioxus would be fine, and some use cases where Dioxus would be better. Would love to hear comparative experiences, or even \"we chose Dioxus|Tauri for our project because of X and Y\" type stories. Dioxus looks really cool, and I'm excited to try it. reply J_Shelby_J 18 hours agoprevI'm really excited about this project because it means you can build a single app and deploy it easily anywhere. And in a single language. reply orthecreedence 14 hours agoparentAnd a good language. Flutter/Dart promises this, but I really, really hate Dart. reply skybrian 13 hours agorootparentSwitching from Dart to Rust doesn't seem like a usability improvement, though? It's good for other things like performance and safe concurrency, but a language that has GC seems easier for web development. reply orthecreedence 13 hours agorootparentI've tackled UI from both the web end and the rust end, and I honestly can't say which I prefer. Javascript is definitely quicker and easier, I'll give you that, but I hold my nose when writing in it and people have been building interfaces in compiled/typed languages for decades without issue. I'd say it really depends on developer preference. I've grown to appreciate working with typed interfaces, and rust's compiler eliminates so many pains of working in the low-level space that I think it hits a really good mix of usability and performance. Do UIs really need the performance that the nerds on here gripe about every time something like Electron comes up? Probably not, so maybe HTML+Javascript (or WASM) is the winning combo. I don't really care either way, as long as I don't have to learn 5 different languages, platforms, UI frameworks, etc to release an app for desktop and phones as a single developer. And I already know Rust, so another option in that regard is welcome. reply skybrian 9 hours agorootparentI also appreciate static type systems, but they both have one. It seems like what kind of static type system it is matters a lot for programmer convenience. I'm using TypeScript nowadays (via Deno), and it seems quite flexible. (Deno is built using Rust, but that's not visible to the programmer.) I would try Flutter again if I wanted to write a mobile app. I'm not wild about stateful / stateless widgets, though. Signals seem nicer. And maybe this Rust framework will work out? reply mattdmrs 13 hours agorootparentprevHonestly curious: what makes you hate it so much? reply orthecreedence 13 hours agorootparentI found it hit a strange position between trying to be friendly and trying to be powerful. Things felt very inconsistent. After learning a few patterns in the language, other things I would expect to follow the same patterns went off in their own direction. I wish I could conjure up more specific examples but that's about all I remember from it. It felt like a language that was built for the singular purpose of supporting Flutter (which I actually did enjoy learning) instead of something that needed to exist in its own right. I wish they'd just picked something already baked. reply fngjdflmdflg 12 hours agorootparentWell, it was created before Flutter, so it wasn't built for that purpose. They did however steer Dart's direction in a way that would be more suitable for Flutter than as a JS replacement which is what it was created for. I don't think it's fair to criticize Dart in the way you have without giving any examples. I haven't found it to be trying to be powerful at all. For example it uses async-await, defaults to dynamic arrays and doesn't focus on classes as much as eg. Java. So I find it to be simple on all accounts. And the developers have specifically stated that their intention with the language is to be as intuitive as possible with the smallest amount of surprises. And I've found that to be the case. I almost never need to actually look at the documentation. Meanwhile I always find myself in MDN looking at some strange JS API (`Date`, for example) despite using it for much longer. And don't even get me started on Java. reply ashia 15 hours agoprevCongrats on the launch! Really excited to see the move to signals + curious to see how Blitz 2.0 goes. reply zengid 18 hours agoprevHuge release, congrats! I'm most interested in Dioxus-Blitz. Congrats to Nico for joining the team (I think?). reply jkelleyrtp 16 hours agoparentYeah Nico is awesome. Between Evan and Nico, I'm sure I'm the worst programmer on the team! reply zengid 14 hours agorootparentYou're winning because the goal is always to be in a room where you aren't the smartest! reply osener 14 hours agoprevHow does Dioxus fare as a native GUI lib? Last time I checked the focus was on web targets and both the built in wgpu renderer and skia backend were not supported as much. reply airstrike 13 hours agoparentYeah, that was my impression too which is why I passed on it and went with Tauri instead. Which is not to say that Tauri perfectly map to the boxes I wanted checked, but beggars can't be choosers reply macawfish 9 hours agoprevI especially like the blurb at the bottom about the blitz rewrite using servo! reply hotfixguru 17 hours agoprevYesterday there was another really interesting rust library, egui, on the front page of HN. I can tell that this is more like react, but how do they compare in other regards? reply jkelleyrtp 17 hours agoparentWrote about that here: https://github.com/DioxusLabs/dioxus?tab=readme-ov-file#diox... You're probably not going to be building an email client or the next instagram in egui, but it is good for stuff where you're fine with re-rendering every entire frame (data viz, graphics stuff). reply politician 17 hours agoprev [–] Dioxus is framework that compiles Rust to WebAssembly in order to build a webapp that uses the native OS webbrowser for rendering and interaction. reply Evan-Almloff 17 hours agoparent [–] Dioxus web compiles to WASM, but we compile to native code for desktop rendering to make it easier to interact with native APIs like the filesystem. We just use the web browser for rendering reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dioxus 0.5 features a core rewrite, a new Signal-based API, elimination of lifetimes, CSS hotreloading, and enhancements for simpler cross-platform app development.",
      "The update streamlines component creation, enhances state management subscriptions, improves rendering efficiency, and introduces new features such as multi-line attribute merging and server function streaming.",
      "Additionally, Dioxus 0.5 optimizes performance, adds extended elements, shorthand attribute initialization, and lays the foundation for future projects to enhance the Dioxus ecosystem."
    ],
    "commentSummary": [
      "Dioxus 0.5, a Rust framework, introduces enhancements like simplifying complexities and improving features such as lifetimes and cloning for web, desktop, and mobile app development.",
      "Users express eagerness to integrate Dioxus with tools like Bevy for upcoming projects, sparking discussions on funding, governance, and monetization approaches in open-source software.",
      "Excitement surrounds Dioxus for its innovative characteristics, rapid development, and its ability to enhance the Bevy framework, generating comparisons with other languages like Dart."
    ],
    "points": 293,
    "commentCount": 103,
    "retryCount": 0,
    "time": 1711636883
  },
  {
    "id": 39858750,
    "title": "Doom Captcha: email unsubscribe with a twist",
    "originLink": "https://vivirenremoto.github.io/doomcaptcha/",
    "originBody": "😈 Doom Captcha 💻 Demo Your Email Captcha Unsubscribe Restart Disclaimer: Don't take this too seriously, this is a little project for fun, if do you know how to code it's pretty easy to break the security of this. 👨💻 Code Your EmailUnsubscribe Parameters countdown: on / off label: Text before captcha, you can leave it empty enemies: Total enemies to kill to complete the captcha, by default 4 Last update - 30/05/2021 Cheat codes - Easter eggs Only works on desktop mode if you click start and write: iddqd: Complete the captcha. idkfa: Unlock the super shotgun. Source code The code repository is available on GitHub, feel free to contribute with pull requests or fork the project for your own. 🤘 You rock! Thanks for your contributions: Jelle Witteveen: JS optimization Steve: Fix typos Adam Stachowicz: Code formatting & image optimization. Lee Reilly: Fix typos makc: Original Doom game backgrounds Jaap Brasser: idkfa super shotgun cheat code 🥳 We did it! DOOM Captcha become TOP 1 Product of the Day on Product Hunt, thank you! This is Crazy! I had the idea this Friday, developed the first version on Saturday morning, published that night and went live here on Sunday. I think that today there have been much better projects than this one, but somehow DOOM Captcha has brought you some kind of nostalgia and you felt the project as yours. I'd like to continue my career as a creative developer, so you all gave me a little more confidence in me, if you loved this I'd like you to check out my projects as well. Thank you all for your welcome and comments, I hope you enjoyed it, had a few laughs and it made you want to play DOOM again. ❤ Update 2021-05-26: John Carmack (Doom creator) liked it. 🙋♂ Hello My name is Miquel Camps Orteza and you can follow me on Twitter Do you like this? I made the worst captcha ever Squat Captcha, also you can check out my side projects 🟢 I'm available for work ☕ Buy me a coffee",
    "commentLink": "https://news.ycombinator.com/item?id=39858750",
    "commentBody": "Doom Captcha (2021) (vivirenremoto.github.io)291 points by EndXA 10 hours agohidepastfavorite88 comments SmartHypercube 7 hours agoWho else is clicking \"click to start\" like me? It turns out you have to choose one of the buttons. I thought they are there to allow me to enable/disable the sound, but they also both act as start buttons. Didn't know a simple interface with a sound switch and a game start button can be designed this badly. reply notpushkin 6 hours agoparentI think the easiest way to fix would be to add a colon, so that you see you have to pick an option: Click to start: [sound on] [sound off] reply medstrom 2 hours agorootparentEven better: [Start with sound] [Start without sound] reply kqr 3 hours agorootparentprevOr have the \"click to start\" text cliclable and start the game with sound. Anyone who wants it muted will make sure to first click the mute symbol and then the ambiguity resolves itself anyway. reply wruza 2 hours agorootparentMathDoku does that and I hate it, because sometimes cookies expire and it plays loud music in the middle of the night when I start it. What's wrong with [ CLICK TO START ] [x] Allow sound Keep it simple reply kqr 1 hour agorootparentI think most people would agree your solution is preferable, but the spirit of this subthread was \"what's the smallest change that would improve things\" rather than \"how could it be redesigned from scratch?\" I would also argue the MathDoku problem is different. That sounds like a mode confusion type issue, where the user expects a certain level of automation but it has been disabled by the system without adequate feedback. reply nycdatasci 4 hours agoparentprevWho else is missing the forest for the trees? It turns out you have to focus on the merit of the contribution instead of inconsequential UI design optimization. Didn’t know a simple demo (with disclaimers) from someone who is clearly doing something novel could be commented on this badly. reply Arisaka1 2 hours agorootparentI'd argue that if it confuses the user it's not inconsequential. And also, something can be both innovative and at the same time have room for improvement. Companies are literally chasing down user feedback. A user's feedback is one of the best things that can ever happen to your program, the worst is to never ever get used by anyone, and the second worse is to have the users walk away with no idea why. reply Thorrez 4 hours agorootparentprev>inconsequential UI design optimization I certainly was confused and had a hard time starting it. If a significant amount of people can't even figure out how to start the game, the problem isn't inconsequential. reply nycdatasci 3 hours agorootparentI agree with you, but this is distracting from the merits of the demo. Also, this is currently #2 on the front page so clearly many people are able to navigate the demo UI, even if it is suboptimal. reply wruza 2 hours agorootparentI decided to leave only a secondary comment at the bottom of the thread for the same reason as yours and still got 14 ups (i.e. thanks) in a short time before this branch bubbled up. People definitely get confused and that's worth talking about before the merits of the demo, cause you have to run it somehow. I almost left too thinking it's broken, hugged or something. It is distracting and we'll live through it :) reply ikari_pl 3 hours agorootparentprevmaybe the bots won't know either reply ghnws 2 hours agorootparentprevThere is bad ui and then there is such bad ui that you lose focus on the actual thing and just wonder how an ui can be so bad. This is the latter. reply iopq 3 hours agorootparentprevI couldn't get it started for a while because I clicked start to start like it says on the tin reply kfarr 6 hours agoparentprevYeah it doesn't even need the option IMHO, I don't think sound is needed here... reply taneq 1 minute agorootparentE1M1 is absolutely a part of the experience. reply ghnws 2 hours agorootparentprevDoom without sound is not doom. Sound is absolutely needed reply burrish 1 hour agoparentprevskill issue, literally filtered by two buttons on the screen reply TeMPOraL 1 hour agorootparentYou mean the buttons are the real CAPTCHA? reply corysama 8 hours agoprevUnfortunately, just this week someone fine-tuned the Mistral-7B LLM to play DOOM :P https://news.ycombinator.com/item?id=39813174 reply paulryanrogers 6 hours agoparentFor very modest definitions of playing. Perhaps it'd be more impressive if they recorded a demo file and let that play back without the realtime overhead? Even so it can only move in forward, back, turn, and fire. And only knows to face away from the wall it's collided with. This is so far below even basic Doom bots that I'd be afraid to call it playing. The ASCII intermediate interpretation also seems unnecessary and very limiting. But perhaps that's to keep it near realtime, looks like 1 FPS? And why run on a Mac? Why not a beefy PC with a GPU that can do the calculations faster? Still, does seem like a fun challenge. Maybe with further tuning or training it can level up reply wahnfrieden 7 hours agoparentprevany models fine tuned for playing an open src game that is non-GPL so that it can be deployed to the app store for interesting bot play ideas? reply brcmthrowaway 7 hours agoparentprevHow could this possibly be in the training set? reply corysama 7 hours agorootparentIt’s not. The fine tuning taught the LLM how to give single-character responses (move/fire keyboard controls) in response to a sequence of ASCII-art-ized frames of the game being played. reply Zambyte 5 hours agorootparentIs it actually ASCII art or just a textual encoding? The art representation is nice for looking under the hood and seeing something pretty, but I feel like that is a very far from optimal way to textually encode Doom for a language model to process. Especially since there is no pitching the camera, you can encode all of the information you need to represent a frame in a single line of ASCII. It they are actually using an ASCII art representation, I bet they would get way better performance encoding the frame as a single line of text. reply kqr 2 hours agorootparentI never realised you could encode each column of Doom as a single character, but of course you can! I suppose the one thing missing would be distance, but if you get 8 bits per character I you could reserve the upper bits to represent approximate distance. That's weirdly inspiring! What other games can I make where the visuals are conceptually no more than a line of characters, but which can get macroexpanded into immersive graphics? reply corysama 5 hours agorootparentprevIf you just click through the links you’ll see the actual input to the LLM https://twitter.com/SammieAtman/status/1772075251297550457 Nothing you are saying is technically incorrect. But, optimal performance was not the goal. The goal was to see if this crazy stupid concept would actually work. And, it does! reply sugarkjube 9 hours agoprevAbsolutely love it. Unusual captcha's are great. Reminded me of this one: http://random.irb.hr/signup.php reply esaym 9 hours agoparentFunny. I made a captcha challenge of calculus problems for a comment section on my personal blog page. But 5 years after college, I couldn't remember how to even do them myself so I changed it :-/ reply iopq 3 hours agorootparentwolfram alpha can do it for you reply evgpbfhnr 7 hours agoparentprevYou don't actually need much, for a form I used to get spam in I just added a \"write 42 here\" so anyone who actually cares to read would be able to fill it. spam fell to 0. (for a site with a slightly higher profile this wouldn't be enough, but for a minor corner of the internet with no ill intent actually aimed at it that turned out to be enough to block the fuzzing \"fill all the forms\" spam) reply kqr 2 hours agorootparentSimilarly an empty input field that is css'd to be outside the viewport is often filled by spambots but not humans. But I like the edge case UX of your idea more. reply jeffhuys 2 hours agorootparentJust watch out that Chrome’s autofill doesn’t fill it in. Cost us a huge chunk of new signups until we found out. Chrome ignores autofill directives under some circumstances. reply kqr 1 hour agorootparentIt's also visible for users with CSS overrides and/or other browser inpairments. The more I think about it the more strongly I prefer the \"type 42\" explicit input field. reply baud147258 37 minutes agoparentprevI remember an old (and now defunct) fan site who hit you with lore questions as a captcha. Though I'd guess a LLM could answer reply koito17 7 hours agoparentprevThe question I got was surprisingly simple: it asked to find \"the least real root of the polynomial p(x) = (x+5)(x-4)(x+1)\". A determined attacker can quickly hack together something with Tesseract and feed it into even GPT-3.5 to get the correct answer to questions like these. I guess that means the captcha is doing its job, since running LLMs isn't very cheap or scalable. But any harder problem means you start filtering a significant chunk of human users. Based on the other replies to your comment, it seems that the questions at their current difficulty already stop a lot of human users, yet allow a determined attacker with the setup I described pass through easily. reply explaininjs 6 hours agorootparentI'm not sure how you'd determine the least real root to that, given all three have equally zero imaginary component. reply wnoise 4 hours agorootparentThey of course the minimum out of the set of the real roots. reply cwillu 5 hours agorootparentprevI suppose the square root of negative infinity has the property of being unreal in several distinct ways, but yeah, the least real? I dunno /s reply onlyrealcuzzo 8 hours agoparentprevCan I play by an audio call if I'm visually impared? reply Keyframe 3 hours agorootparentYes, when you hear a monster roar you say BANG! reply em-bee 9 hours agoparentprevafter reloading a dozen times i finally got one that i could solve: -3 * 3 + (-3) = ? reply jakderrida 8 hours agorootparentI just got one I think I can solve: 0 + 7 + 0 = ? Where's my calculator? reply defrost 8 hours agorootparentBond, Jim Bond ? reply wanderer2323 5 hours agoprevAbsolute banger. But the auto-aim on vertical axis is missing. You should be able to have the crosshair under an enemy and still hit them. But in any case, nicely done! reply sira04 8 hours agoprevI'm still waiting for someone to make the Mona Lisa Captcha: https://www.youtube.com/watch?v=WqnXp6Saa8Y reply modeless 8 hours agoprevWhy isn't it actually Doom? Surely there are multiple JS Dooms to choose from. reply tiltowait 7 hours agoparent\"Finish UV Hangar in < 13 seconds.\" Easily achievable[0], thoroughly obnoxious[1]. Just like all captchas. [0] God help you if you're on a touchscreen. [1] For most people. Especially after the novelty wears off. reply kadoban 5 hours agoparentprevDoom is still under copyright protection last I knew. The source is GPL, but have the assets ever been liberally licensed? I think they're more abandonware. I'm sure you could still do it, but personally I try to respect copyright strictly for any projects I'm going to share. It just feels annoying to have copyright nonsense hanging over me otherwise. reply modeless 5 hours agorootparentWell certainly we don't need the full game assets for a captcha. The shareware version would do just fine and that's always been free. reply chungy 4 hours agorootparentEven better, Freedoom. reply Solvency 7 hours agoparentprevYeah kind of bummed me out. reply jml7c5 9 hours agoprevYou should try for a full 3D implementation of Doom! I'm sure it's been ported to JavaScript at least a dozen times. reply explaininjs 9 hours agoprevNow I want Men In Black mode, where your job is to identify the threat posed by the popup and shoot accordingly: Alien doing pull ups? Fine. 8 year old girl holding a Quantum Physics book in a dark alley? That's sus... reply girvo 8 hours agoparentHaving re-watched that movie recently, he's not wrong -- that's a deeply odd book for an apparent 8 year old girl to be holding. And with the amount of aliens that look like humans across the movies... reply canjobear 5 hours agorootparentI always thought he passed the test there, and the guys that just mindlessly shot failed. reply explaininjs 2 hours agorootparentWell of course he passed - they immediately after offer him the job and neuralize everyone else. reply cwillu 5 hours agorootparentprevTypical cop assuming any behaviour they can't explain must be malevolent. reply explaininjs 2 hours agorootparentThey call it entrapment - the officials put him in a position where be believes he's required to shoot in order to pass a test, but he sees no reason to. So finally he has to go with his gut and shoot the most probable target, even if he would have if not placed in that situation with those expectations. reply dang 5 hours agoprevRelated: DOOM Captcha - https://news.ycombinator.com/item?id=27264988 - May 2021 (173 comments) reply wmil 5 hours agoprevCan you make one based on the WoW fishing minigame? ie they need to click on the bobber at the right time. I'm not expecting it to last longer, but there really should be some decent fishing bots at this point. reply avsteele 10 hours agoprevThis is fun. I have been having trouble with Google capchas recently, so Ii;d be happy if more where like this. reply sunnybeetroot 8 hours agoprevMissing 2021 tag reply Apreche 10 hours agoprevThis is a fun idea, but it doesn't seem to work in any browser I tried. Maybe adblock is breaking it? reply wruza 10 hours agoparentYou have to click on \"ON\" or \"OFF\" to start. Unintuitive. reply Apreche 8 hours agorootparentThanks. That was the issue. I was clicking on the text that says \"click to start\" reply binary132 8 hours agorootparentI did that a few times myself :) reply nntwozz 10 hours agoparentprevWorks for me iOS Safari with AdGuard. reply pkrefta 8 hours agoprevBest captcha I've ever seen <3 reply pushedx 10 hours agoprevwouldn't do much to prevent bots reply frozenlettuce 8 hours agoparentIf they switch to canvas rendering and include some twist (eg. shoot x but not y, limit input rate, etc), then I think that a considerable computing effort would be necessary to break the lock reply enlyth 8 hours agorootparentI don't think it's that considerable, I made a script to defeat it with vision in only a few minutes: https://gist.github.com/enlyth/a177e4102b0da37a73587e15dbd68... This could be further optimized to not scan the whole screen, and faking some human like mouse movements shouldn't be that hard too reply Reubend 7 hours agorootparentWow, that's pretty impressive to me and I think it's awesome that you were able to put this together quickly. I admit that I don't have a CV background, so maybe this is easier for a programmer who's already experienced in that area. reply lloeki 1 hour agorootparentTo be fair I don't think you need CV in this specific case where the problem space is very limited. 1. There's no lighting, so the enemies have specific, fixed pixel colours that don't appear in any of the backgrounds. Scan and target these. 2. Enemies appear in a specific zone in the canvas. Makes scan faster, combines with below. If there's expected ambiguity one can a. detect a few interesting background properties by looking at pixels where enemies never appear (e.g corners), and/or b. use a couple of other pixels relative to the candidate match (maybe neighbours, maybe not, could just as well be 20px down, 10 left) to discriminate. Side story: one day my team was tasked with doing textual document content recognition for some biz. Everyone was like \"oh it's going to be $$$ to pull out CV+OCR and have the OCR learn the specific font\". Turns out the document in question was: - an extremely standardised gov format - produced only by gov administration - of a known fixed, overall size with clear identifiable boundaries - printing known, standardised list of fields at fixed position - with a known, standard font specifically made for quick automatic recognition - containing only /[A-Za-z0-9]/ chars (plus a few I can't recall, but essentially dash, plus, slash...) - on a known, standardised background - the only variable is the quality of the scan and the size parameters So I put a file upload form, piped the image through some reasonable imagemagick filter sequence to turn it into a no-background monochrome, look for corners/borders, resize+rotate, scan through the image til I hit a black pixel, then look at pixel-lit/unlit patterns (think 7 segment display in reverse). Cobbled the thing in a couple afternoons, with a quick, simple UI to have the user crop/rotate the doc (putting it mostly upright). It was stupidly fast to run and success rate was very high. Interestingly enough the failure mode was very good as it could reliably tell \"ok I can't make any sense out of this\" vs OCR which claimed success but outputted gibberish. You can get surprisingly far with very little when you have known knowns. reply duskwuff 8 hours agorootparentprevAnd if you analyzed the user's cursor movements (on desktop), reaction time, and positional accuracy, it could be a genuinely decent CAPTCHA. reply RockRobotRock 7 hours agorootparentI'm in awe at the late stages of this cat and mouse game. I write a lot of bots and scrapers, and I feel thoroughly out-gunned against a bunch of PhD data scientists. DataDome talk about detection: https://youtu.be/xJGBfSGIsjw reply RockRobotRock 7 hours agorootparentprevI know this is just for fun, but I think this could be a genuinely good solution if it was heavily obfuscated, and the enemy positions were streamed from the server. reply brink 9 hours agoparentprevThe author knows, it's just a bit of fun. Read the page. reply seattle_spring 6 hours agoparentprevThis comment made me vividly think about that \"no silly hats!\" cartoon by Don Hertzfeld from 20 ish years ago. reply darby_eight 9 hours agoparentprev...what are you comparing to? reply deadbabe 4 hours agoprevThere needs to be hostages or barrels that you shouldn’t shoot because you’ll die. reply paulryanrogers 7 hours agoprevNot really Doom, a few years old, and now broken apparently. IIRC it was basically just a mouse only shooting gallery mini-game. EDIT: Not broken, just not obvious one must click the sound options to start. Still just a mouse gallery mini-game. Doubtful you'd even need AI to solve it. reply justinator 5 hours agoparentWell let's be honest, a human (YOU I assume) couldn't even figure out how to start the game, so if AI can solve it, we're in real trouble. reply paulryanrogers 4 hours agorootparentSo a CAPTCHA that keeps humans out? Sadly that is all too common reply diimdeep 2 hours agoprevthis is dumbest this I have seen this week reply jgalt212 7 hours agoprevthis crashed my firefox. anyone else? reply NamTaf 7 hours agoparentNope, worked fine for me on 124.0.1 w/ several extensions reply airtonix 10 hours agoprev [–] just spam click... autowin. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DOOM Captcha is a playful project for email unsubscription, featuring a Doom-themed captcha game with customizable parameters and cheat codes for an easier experience.",
      "It gained popularity on Product Hunt and garnered praise from users for its novelty.",
      "The developer, Miquel Camps Orteza, welcomes contributions and is open to work opportunities, showcasing creativity in the tech community."
    ],
    "commentSummary": [
      "Users are debating improvements for the game \"Doom Captcha,\" with some prioritizing the user interface over the game's merits, while others emphasize clarity.",
      "Despite UI challenges, the game remains popular, with users exploring a demo UI and discussing its limitations and potential.",
      "Suggestions include utilizing ASCII art for text encoding, lore-based captchas, shareware versions to avoid copyright problems, and a 3D Doom game integration for security, raising concerns about captcha effectiveness against bots."
    ],
    "points": 292,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1711668749
  },
  {
    "id": 39852219,
    "title": "Uncovering Insights from OpenAI's Developer Community Forum",
    "originLink": "https://julep-ai.github.io/",
    "originBody": "Anatomy of OpenAI's Developer Community OpenAI has an official developer community hosted by Discourse which is the centre place of people seeking help and conversations about OpenAI's APIs, ChatGPT, Prompting and more. The forum was launched on March 2021 and since then has seen 100,000+ posts by over 20,000 users. Given the size and concentration of topics on the forum, it is a great resource for understanding the general sentiment of developers, identify common problems and rabbit holes users face and gather feedback on OpenAI products. In order to get deeper insights to developer experience and shared sentiment about certain products, we downloaded all the posts from common categories from the forum, namely. The following categories and their relevant sub-categories are included: API API/Bugs API/Deprecations API/Feedback GPT Builders GPT Builders/Chat-Plugins GPT Builders/Plugin-Store Prompting Community Documentation We created a dataset of all posts and discussions in the above categories which took place on the forum till 28th February 2024. 🤗 HuggingFace Link But... why? We believe there's a lot to learn from what people are struggling with, the developer sentiment over experience with using OpenAI's products. This dataset was made so that we could answer these questions. There's a lot potential in learning from OpenAI's mistakes and successes. We at Julep would love to hear what you built from the dataset! Hit us up on X/Twitter or email. Getting data from Discourse Every Discourse Discussion returns data in JSON if you append .json to the URL. Discussion URL: https://community.openai.com/t/{discussion_id} Discussion in JSON: https://community.openai.com/t/{discussion_id}.json Discussion in Markdown: https://community.openai.com/raw/{discussion_id} Raw data was gathered into a single JSONL file by automating a browser using Playwright. Let's walk through how the dataset was made and then showcase some initial trends we noticed. Feature Engineering Brief walkthrough to engineering the features. Since each row had one Discussion and each Discussion had multiple Posts in a thread, the dataset needed to be normalised to the post level; which were features of an individual post and post_discussion level; which were features of the discussion the post belonged to. For eg; Post-level features: post_id; post_author Discussion-level features: post_discussion_id; post_category_id In [ ]:%matplotlib widget In [ ]:import pandas as pd from datasets import Dataset, load_from_disk, load_dataset # hf_dataset = load_from_disk(\"9_dataset_with_topics\") hf_dataset = load_dataset(\"julep-ai/openai-community-posts\") df = hf_dataset.to_pandas() In [ ]:hf_dataset.features Out[ ]:{'post_discussion_id': Value(dtype='int64', id=None), 'post_discussion_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'post_discussion_title': Value(dtype='string', id=None), 'post_discussion_created_at': Value(dtype='timestamp[ns, tz=UTC]', id=None), 'post_category_id': Value(dtype='int64', id=None), 'post_discussion_views': Value(dtype='int64', id=None), 'post_discussion_reply_count': Value(dtype='int64', id=None), 'post_discussion_like_count': Value(dtype='int64', id=None), 'post_discussion_participant_count': Value(dtype='int64', id=None), 'post_discussion_word_count': Value(dtype='float64', id=None), 'post_id': Value(dtype='int64', id=None), 'post_author': Value(dtype='string', id=None), 'post_created_at': Value(dtype='string', id=None), 'post_content': Value(dtype='string', id=None), 'post_read_count': Value(dtype='int64', id=None), 'post_reply_count': Value(dtype='int64', id=None), 'post_author_id': Value(dtype='int64', id=None), 'post_number': Value(dtype='int64', id=None), 'post_discussion_related_topics': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'accepted_answer_post': Value(dtype='float64', id=None), 'post_content_raw': Value(dtype='string', id=None), 'post_category_name': Value(dtype='string', id=None), 'post_sentiment': Value(dtype='string', id=None), 'post_sentiment_score': Value(dtype='float64', id=None), 'post_content_cluster_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'post_content_classification_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'post_content_search_document_embedding': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'tag1': Value(dtype='string', id=None), 'tag2': Value(dtype='string', id=None), 'tag3': Value(dtype='string', id=None), 'tag4': Value(dtype='string', id=None), 'post_discussion_url': Value(dtype='string', id=None), 'post_url': Value(dtype='string', id=None), 'topic_model_medium': Value(dtype='string', id=None), 'topic_model_broad': Value(dtype='string', id=None)} In [ ]:# Total number of posts print(\"Total number of posts: \", len(df)) # Total discussions print(\"Total discussions: \", len(df[\"post_discussion_id\"].unique())) # Total number of users print(\"Total number of users: \", len(df[\"post_author_id\"].unique())) Total number of posts: 97033 Total discussions: 18990 Total number of users: 21419 In [ ]:# Earliest and latest post print(\"Earliest post: \", df[\"post_created_at\"].min()) print(\"Latest post: \", df[\"post_created_at\"].max()) Earliest post: 2021-03-10T20:39:25.848Z Latest post: 2024-02-27T14:03:01.685Z Apart from Post and Discussion level features, the following class features were computed; Sentiment Vector Embeddings Topic Models Twitter-roBERTa-base Sentiment Using Twitter-roBERTa-base for sentiment analysis, we generated a post_sentiment label (negative, positive, neutral) and post_sentiment_score confidence score for each post. On average, most posts are neutral. In [ ]:df[\"post_sentiment\"].value_counts(ascending=True, normalize=True) Out[ ]:post_sentiment negative 0.185277 positive 0.219327 neutral 0.595395 Name: proportion, dtype: float64 However, by looking at the distribution per category, we see that the api category and api/bugs category has the most negative sentiment amongst different categories. On the other hand, community and gpts-builders/plugin-store has the most positive sentiment. which tracks as people often showcase cool projects, news and latest AI development in the community! In [ ]:# Group by 'post_category_name' and then apply normalized value_counts to 'post_sentiment' sentiment_percentages = df.groupby(\"post_category_name\")[\"post_sentiment\"].apply( lambda x: x.value_counts(normalize=True) ) # Convert the Series to a DataFrame and reset the index # sentiment_percentages = sentiment_percentages.mul( # 100 # ) # Convert fractions to percentages sentiment_percentages = sentiment_percentages.reset_index(name=\"percentage\") # Pivot the table for better readability pivot_df = sentiment_percentages.pivot( index=\"post_category_name\", columns=\"level_1\", values=\"percentage\" ) # Fill NaN values with zero if any sentiment labels are missing in a category pivot_df = pivot_df.fillna(0) pivot_df.reset_index() pivot_df.columns.rename(None, inplace=True) # Display the pivoted DataFrame in descending order pivot_df Out[ ]: negative neutral positive post_category_nameapi 0.188675 0.624195 0.187131 api/bugs 0.376378 0.533858 0.089764 api/deprecations 0.161049 0.662921 0.176030 api/feedback 0.261770 0.553672 0.184557 community 0.137866 0.502298 0.359837 documentation 0.137372 0.559727 0.302901 gpts-builders 0.260511 0.597313 0.142176 gpts-builders/chat-plugins 0.232624 0.538543 0.228833 gpts-builders/plugin-store 0.187500 0.506944 0.305556 prompting 0.133054 0.633530 0.233416 Vector Embeddings For calculating vector embeddings, Nomic Embed-Text v1.5 was ran locally with the help of text-embeddings-inference. Because of it's Matryoshka resizable nature, it's possible to use these embeddings in a bunch of future applications. Nomic Embed v1.5 was largely selected due to it's large context length. In [ ]:import matplotlib.pyplot as plt import seaborn as sns df[\"post_content_raw_length\"] = df[\"post_content_raw\"].apply(len) plt.figure(figsize=(12, 6)) sns.histplot( df[\"post_content_raw_length\"], bins=100, kde=False, cumulative=True, stat=\"density\" ) plt.title(\"CDF of Length Distribution of post_content_raw\") plt.xlabel(\"Length of post_content_raw\") plt.ylabel(\"Cumulative Density\") plt.show() /home/glitch/.conda/envs/julep/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and ={np_minversion} and0) ].drop_duplicates(subset=\"post_discussion_id\").sort_values( \"post_discussion_views\", ascending=False )[ [ \"post_discussion_title\", \"post_content_raw\", \"topic_model_medium\", \"post_discussion_views\", \"post_sentiment\", \"post_discussion_url\", ] ] Out[ ]: post_discussion_title post_content_raw topic_model_medium post_discussion_views post_sentiment post_discussion_url 11898 Cheat Sheet: Mastering Temperature and Top_p i... Presence\\_penalty was only mentioned once as a... Logit 113139 negative https://community.openai.com/t/172683 11179 OpenAI API keys in free account I have genertaed openai api keys in the free a... API Usage 89960 negative https://community.openai.com/t/348972 64217 Your account was flagged for potential abuse Same problem. And I can’t write anything in [h... OpenAI 87260 negative https://community.openai.com/t/156597 5484 Getting response data as a fixed & Consistent ... I have such common issue where JSON data is no... JSON Format 78668 negative https://community.openai.com/t/28471 34098 Is chat GPT provided for free I have only $5 What are you jealous of? Pricing 75918 negative https://community.openai.com/t/86249 ... ... ... ... ... ... ... 194 Anyone experiences no message response using a... Hi, I just encountered very strange behavior w... Assistant Tools 53 negative https://community.openai.com/t/656254 1485 Request always fail after the first function c... I am using model gpt3.5-turbo with chat comple... Python3 Packages 53 negative https://community.openai.com/t/647723 839 Help with using openAI Assistants via API in J... I’m trying to create a simple chrome plugin th... Error Handling 53 negative https://community.openai.com/t/652635 223 Assistant API: Empty message is generated with... Hi whung,I think there might me some err... Assistants, API, Platform 52 negative https://community.openai.com/t/656170 77670 OpenAPI spec can have a maximum of 30 operations I am building an action for an API with lots o... Python3 Packages 31 negative https://community.openai.com/t/586484 2146 rows × 6 columns Posts with Most Negative Sentiment by Topic Some topics tends to cause more frustration than other which we can see by sorting the topics based on the number of posts with negative sentiments. In [ ]:# add a column for the length of the post_content_raw topic_df[\"post_content_raw_length\"] = topic_df[\"post_content_raw\"].apply(len) # Filter the dataframe to include only posts with negative sentiment negative_posts = topic_df[topic_df[\"post_sentiment\"] == \"negative\"] # Group the negative posts by topic and count the number of posts in each topic negative_posts_by_topic = ( negative_posts.groupby(\"topic_model_medium\").size().reset_index(name=\"count\") ) # Sort the topics by the count of negative posts in descending order negative_posts_by_topic = negative_posts_by_topic.sort_values(\"count\", ascending=False) # Plot the bar chart plt.figure(figsize=(12, 6)) sns.barplot( x=\"count\", y=\"topic_model_medium\", data=negative_posts_by_topic, color=\"red\" ) plt.title(\"Posts with Most Negative Sentiment by Topic\") plt.xlabel(\"Number of Posts\") plt.ylabel(\"Topic\") plt.tight_layout() plt.show() Figure Percentage of Posts by Sentiment and Topic Surprisingly, the top 15 topics in this graph break the trend of negative posts being 18.5%. Specifically in these topics, the negative sentiment can be upto 50%! In [ ]:sentiment_percentages = df[\"post_sentiment\"].value_counts(normalize=True) * 100 print(sentiment_percentages) post_sentiment neutral 59.539538 positive 21.932745 negative 18.527717 Name: proportion, dtype: float64 In [ ]:# Group the posts by topic and sentiment, and count the number of posts in each group posts_by_topic_and_sentiment = ( topic_df.groupby([\"topic_model_medium\", \"post_sentiment\"]) .size() .reset_index(name=\"count\") ) colors = {\"negative\": \"red\", \"neutral\": \"blue\", \"positive\": \"green\"} # Calculate the total number of posts for each topic total_posts_by_topic = topic_df.groupby(\"topic_model_medium\").size() # Calculate the percentage of posts for each sentiment within each topic posts_by_topic_and_sentiment[\"percentage\"] = posts_by_topic_and_sentiment.apply( lambda row: row[\"count\"] / total_posts_by_topic[row[\"topic_model_medium\"]] * 100, axis=1, ) # Pivot the DataFrame to get the percentage of posts for each sentiment as separate columns pivot_df = posts_by_topic_and_sentiment.pivot( index=\"topic_model_medium\", columns=\"post_sentiment\", values=\"percentage\" ).fillna(0) pivot_df = pivot_df.sort_values(\"negative\", ascending=False) # Plot the stacked bar chart pivot_df.plot( kind=\"bar\", stacked=True, figsize=(12, 6), color=[colors[col] for col in pivot_df.columns], ) plt.title(\"Percentage of Posts by Sentiment and Topic\") plt.xlabel(\"Topic\") plt.ylabel(\"Percentage of Posts\") plt.legend(title=\"Sentiment\") # plt.xticks(rotation=45) plt.tight_layout() plt.show() Figure People really like to complain about performance! Wrapping up We've just began to scratch the surface to useful data that can be analysed about OpenAI's products, launches, tools and the trends surrounding their usage. This post is meant to be an introduction to the dataset and show some threads that can be explored further. We at Julep AI are building an open-source platform for crafting AI Agents. In the spirit of open-source, we decided to make this dataset public in hopes of helping out other people identify the cracks and the gaps that OpenAI cannot fix, doesn't want to fix or is opinionated against. Given the activity of the community and the ease of downloading the data, it made perfect sense to leverage this low-hanging fruit of knowledge. We hope that this dataset helps other people building AI stacks. We'd love to hear more about how you used the dataset or just talk in general! Hit us up at: Twitter/X: https://x.com/julep_ai Email: Ishita (ishita@julep.ai) / Sid (sid@julep.ai)",
    "commentLink": "https://news.ycombinator.com/item?id=39852219",
    "commentBody": "I scraped all of OpenAI's Community Forum (julep-ai.github.io)284 points by alt-glitch 19 hours agohidepastfavorite55 comments xfalcox 17 hours agoThat's super cool, thanks for sharing! I will share this as an easy to follow example of what we can with AI. > Allowing a Q&A interface using these embeddings over the post contents could speed up research over the community posts (if you know the right questions to ask :P). Let's view some posts similar to this one complaining about function calling That's indeed a great thing to surface, and that's exactly how the the OpenAI forum selects the \"Related Topics\" to show at the end of every topic. We use embeddings for this feature, and the entire thing is open-source: https://github.com/discourse/discourse-ai/blob/main/lib/embe... We also embeddings for suggesting tags, categories, HyDE search and more. It's by far my favorite tech of this new AI/ML gen so far in terms of applicability. > Using Twitter-roBERTa-base for sentiment analysis, we generated a post_sentiment label (negative, positive, neutral) and post_sentiment_score confidence score for each post. We do the same, with even the same model, and conveniently show that information on the admin interface of the forum. Again all open source: https://github.com/discourse/discourse-ai/tree/main/lib/sent... Disclaimer: I'm the tech lead on the AI parts of Discourse, the open source software that powers OpenAI's community forum. reply wavyknife 17 hours agoprev(disclaimer: I work for Discourse) Discourse has an AI plugin that admins can run on their community to generate their own sentiment analysis (among other things), though it's not quite as thorough as this write up! https://meta.discourse.org/t/discourse-ai-plugin/259214 We're always interested to see how public data can be used like this. It's something that can be a lot more difficult on closed platforms. reply Aachen 16 hours agoparent> helps you keep tabs on your community by analyzing posts and providing sentiment and emotional scores to give you an overall sense of your community for any period of time [...] > Toxicity can scan both new posts and chat messages and classify them on a toxicity score across a variety of labels Is that within the defined data processing purposes of all Discourse setups? Does the tool warn admins they might need to update their policies before being able to run this tool, perhaps needing to seek consent (depending on their jurisdiction and ethics)? It sounds somewhat objectionable, trying to guess my mental state from what I write without opt-in Edit: and apparently it also tries to flag NSFW chat messages, does Discourse have PM chats where this would flag private messages for admins to read or is it only public chats that this bot runs on? > tagging NSFW image content in posts and chat messages reply eddd-ddde 14 hours agorootparentI don't think there's anything left for you to consent once you decide to post on a public forum. If I can read your post and guess your mental state so can any other bot. reply Aachen 9 hours agorootparentIf you park your car on the side of the road, that also doesn't allow anyone to do with it what they please If you write an article and post it on your blog, people can't just come along and take the text verbatim If you license your blog as public domain, then someone takes the content and does something objectionable with it, you can (in many countries) still make use of moral rights if you'd wish to correct the situation If I post something publicly on a forum, I'm well aware I may have agreed or consented (depending on the forum) to terms that allow this type of processing, but that is not the default. There exist restrictions, both legally and morally (some legal ones are even called moral rights and are inalienable). Hence my question how this plugin handles extending the allowed data processing to cover taking the content and making automated decisions and claims that may or may not be accurate. I would not be comfortable with that being an automated behind-the-scenes process flagging my posts as good or bad towards the moderators, since they likely won't care to read back hundreds of comments and see whether the computer did a good job reply wavyknife 14 hours agorootparentprevDiscourse is not a centralized platform, so it's up to individual sites to ensure they're compliant with data and privacy regulations. reply Aachen 9 hours agorootparentI mention that in the first nonquote sentence reply xfalcox 13 hours agorootparentprev> Is that within the defined data processing purposes of all Discourse setups? It's an optional plugin that can be enabled / disabled by the site admin. Those modules are all disabled by default, and each need to be enabled by the site owner. > Edit: and apparently it also tries to flag NSFW chat messages, does Discourse have PM chats where this would flag private messages for admins to read or is it only public chats that this bot runs on? Discourse PMs can be read by admins, see the definition here: https://meta.discourse.org/t/guidance-and-best-practices-on-... reply Aachen 9 hours agorootparentOf course an admin can always open up the database and read your forum PMs, that's not surprising. The very first line in the link you provided, however, is what I was worried about: > Moderators can read PMs that have an active flag. This system is now setting nsfw flags in an automated fashion, specifically seeking out content that the persons involved wouldn't want others to see. Clearly a forum is the wrong place for that content, but people don't always make good decisions (especially kids; I was a kid on forums too and would be very surprised if nothing ever transpired there). The receiving person can already flag anything they deem inappropriate. A system making automated decisions about messages that were intended to be private creates problems and it is not clear to me who this serves reply BadHumans 16 hours agorootparentprevMore companies and communities than you think already do this without your knowledge let alone consent. reply david_allison 15 hours agorootparentThat doesn't mean we can't do better reply BadHumans 14 hours agorootparentBetter at what though? I don't even think it's a problem to begin with. reply SunlitCat 18 hours agoprevI didn't even knew they have community forums. Looking at the main homepage (openai.com), the only external links I can find are to chatgpt and their docs hosted on platform.openai.com. The other links lead to their socials, github and soundcloud (of all places). Maybe I'm not looking thoroughly enough, so I may be wrong, tho! reply hughesjj 17 hours agoparentI would also love to see these forums both to post and to lurk reply djantje 17 hours agorootparenthttps://community.openai.com/ (when you are logged in on platform.openai.com, there is a link from the menu) reply SunlitCat 15 hours agorootparentThank you! Gone are the days when you simply saw all the important links on the main page, it seems. :) reply miduil 18 hours agoprevThat's an interesting write-up, I wonder how this would look for other big Discourse communities such as NixOS. reply alt-glitch 7 hours agoparentThis is definitely a workflow we can package into something open-source. I wonder how the community moderators would like it. reply dcreater 2 hours agorootparentI for one would love it! reply klooney 8 hours agoprevWhat's the \"Day Knowledge Direction\" cluster in the Atlas view? reply alt-glitch 7 hours agoparentNeat find! That's actually a cluster of all the system messages notifying users about closing and re-opening of the thread. That's why they're so tightly clustered. I believe the naming isn't perfect for this, but this was all automatic topic modelling! Example: [1]: https://community.openai.com/t/read-this-before-posting-a-ne... reply fzysingularity 16 hours agoprevSo epic, thank you for making this dataset available to everyone! reply garyiskidding 1 hour agoprevThis is really amazing. Pretty insightful. Thank you. reply velid0 18 hours agoprevNow train a gpt based on the data :D reply testfrequency 17 hours agoparentBut make sure to call it ClosedData or something so we know it’s not open source (sorry, I think openai and sam are gross) reply davely 15 hours agorootparentMaybe I don’t understand this sentiment, but are people really that hung up on the name? I see this sort of thing posted a lot (i.e., “it should be ClosedAI instead of OpenAI, lol”) What if it just means “Open for Business” instead of “Open Access for All”? Or maybe they should just make it an acronym? I’m sorry for the confusion on my part, but there’s just been a lot of words dedicated toward expressing frustration with the company because they chose to use “open” in their name. Personally, I don’t find it frustrating that Apple doesn’t sell fruit and Intel doesn’t actually give intelligence data. reply phyzome 11 hours agorootparent\"What if it just means\" -- I mean, we don't have to ask \"what if\". We can look at the original press release: https://openai.com/blog/introducing-openai « We’re hoping to grow OpenAI into such an institution. As a non-profit, our aim is to build value for everyone rather than shareholders. Researchers will be strongly encouraged to publish their work, whether as papers, blog posts, or code, and our patents (if any) will be shared with the world. We’ll freely collaborate with others across many institutions and expect to work with companies to research and deploy new technologies. » They never give an explicit explanation for their name, but it's pretty obvious. reply rootusrootus 15 hours agorootparentprevIs the frustration because of the name, or because open [access] was part of their ethos at the beginning, and people think they've abandoned it? reply startupsfail 15 hours agorootparentOpenAI is supposed to be a nonprofit. But, when the nonprofit board tried to exercise control, it became very clear that the nonprofit arm is not, in fact in control any longer. The board was wiped out, nearly everyone in the company seemingly was willing to join Microsoft or Sam Altman or what not. This doesn’t seem to be compatible with continuing loftily call themselves with the same name, as the initial nonprofit mission. reply woopsn 15 hours agorootparentprevIt's a gimmick. When the nonprofit was organized in 2015, the name certainly did not mean open for business. It meant (loftily) undertaking the quasi-religious quasi-humanist mission \"in the spirit of liberty\" to generate a new kind of super wealth as \"broadly and evenly distributed as possible\". As in prepare for the end... THE END OF HIGH PRICES! > to benefit humanity as a whole, unconstrained by a need to generate financial return - https://openai.com/blog/introducing-openai reply xandrius 18 hours agoprevLove it, just for the sole reason of turning something OpenAI made into a dataset for everyone else :D reply codetrotter 16 hours agoparentI don’t think OpenAI are gonna lose any sleep over this. Isn’t a “community forum” like this basically just: “we’re not gonna spend money on providing adequate customer support so instead here is a forum where y’all can talk amongst yourselves and we’ll give you some badges and imaginary points for doing the customer support yourselves”? reply alt-glitch 5 hours agorootparentI believe a community forum is absolutely vital for an \"ecosystem\" company. There needs to be a town square where people can discuss ideas and share feedback about that particular ecosystem. OpenAI has a pretty active forum with moderators replying and helping out all the time. reply solardev 16 hours agorootparentprevThey probably just sic a customer service GPT on it and use it to train the other ones... reply dorkwood 17 hours agoprevI did a bit of data scraping for fun in the past, but I was never quite sure of the legality of what I was doing. What if I was breaking some law in some jurisdiction of some country? Was someone going to track me down and punish me? OpenAI has taught me that no one gives a shit. Scrape the entire internet if you want, and use the data for whatever you feel like. reply alt-glitch 17 hours agoparentWe were really heading someplace with The Semantic Web aka The Real Web 3.0 [1] Alas we have to fight against the machines in order to properly read the internet thru machines. I believe Discourse knowingly keeps its data easy to scrape though, so kudos to them! [1]: https://en.wikipedia.org/wiki/Semantic_Web reply bsuvc 16 hours agoparentprev> OpenAI has taught me that no one gives a shit. Scrape the entire internet if you want, and use the data for whatever you feel like. Cloudflare gives a shit. My household had to use our 5G internet for most things for a week or two until our IP reputation recovered. reply stoorafa 16 hours agorootparentYeah it’s probably worth renting a server if there’s any doubt about whether it’s wholly appropriate to do something reply ifyoubuildit 17 hours agoparentprevDo you think it would be better if someone did track you down and punish you? Which world do you want to live in? reply n0sleep 17 hours agorootparentI think large companies should be punished for stealing from people to make themselves richer. reply EcommerceFlow 17 hours agoparentprevA precursor to this would have been that Linkedin lawsuit Microsoft lost, allowing that one company to scrape all of Linkedin (technically \"public information\"). reply enonimal 18 hours agoprev> Number of Posts with negative sentiment, grouped by Topic > # 1 Result: Python Packaging Checks out reply doctorpangloss 16 hours agoparentThe Python package is really well engineered, and the startup that is making the OpenAPI client based on it, Stainless, is doing a good job. This shows laypeople piling into a hype thing and running immediately into the roadblock of programming. Normal people don't want to like, put in effort to feel like they are a part of something. They are used to \"just\" having to turn on Netflix to feel like they are a part of the biggest TV show, or \"just\" having to click a button to buy a Stanley Cup, or \"just\" having to click a button to buy Bitcoin. The API and performance issues, IMO, they're not noise, but they are meaningless. To me this also signals how badly Grok and Stability are doing it, they are doubling and tripling down on popular opinions that have a strong, objective meaninglessness to them (like how fast the tokens come out and how much porn you're allowed to make). Whereas the Grok people are looking at this analysis and feeling very validated right now. I have no dog in this race, but I would hope that the OpenAI people do not waste any time on Python APIs for dumb people; instead, they should definitely improve their store and have a firmer opinion on how that would look. They almost certainly have a developing opinion on a programming paradigm for chatbots, but I feel like they are hamstrung by needed to quantize their models to meet demand, not decisions about the look and feel of Python APIs or the crappiness of the Python packaging ecosystem. Another POV is that the Apple development experience persists to be notoriously crappy, and yet they are the most valuable platform for most companies in the world right now; and also, JetBrains could not sustain an audience for the AppCode IDE, because everyone uses middlewares anyway; so I really don't think Python APIs matter as much as the community says they do. It's a Nice to Have, but it Does Not Matter. reply enonimal 16 hours agorootparentwe may think more similarly than you seem to think... this was more a slam on python packaging in general, than it is on the OpenAI implementation. I wouldn't be surprised if many of the issues under this topic are more related to Python package version nightmares, than OpenAI's Python implementation itself. reply minimaxir 17 hours agoparentprevA pro-tip for using the OpenAI API is to not use the official Python package for interfacing with it. The REST API documentation is good, and just using it in your HTTP client of choice like requests is roughly the same LOC without unexpected issues, along with more control. reply rattray 8 hours agorootparentHey minimaxir, I help maintain the official OpenAI Python package. Mind sharing what issues you've had with it? (Have you used it since November, when the 1.0 was released?) Keen for your feedback, either here or email: alex@stainlessapi.com reply minimaxir 6 hours agorootparentThere's nothing wrong per se, it works as advertised. But as a result it's a somewhat redundant dependency. reply rattray 6 hours agorootparentAh, gotcha. Thanks, that makes sense. FWIW, here are some things it provides which might be worth having: 1. typesafety (for those using pyright/mypy) and autocomplete/intellisense 2. auto-retry (w/ backoff, intelligently so w/ rate limits) and error handling 3. auto-pagination (can save a lot of code if you make list calls) 4. SSE parsing for streaming 5. (coming soon) richer streaming & function-calling helpers (can save / clean up a lot of code) Not all of these matter to everybody (e.g., I imagine you're not moved by such benefits as \"dot notation over dictionary access\", which some devs might really like). I would argue that auto-retry would benefit a pretty large percentage of users, though, especially since the 429 handling can paper over a lot of rate limits to the point that you never actually \"feel\" them. And spurious/temporary network connections or 500s also ~disappear. For some simple use-cases, none of these would really matter, and I agree with you - especially if it's not production code and you don't use a type-aware editor. reply rockostrich 17 hours agorootparentprevI've found this happens with a lot of first party clients. At work, we use LaunchDarkly for feature flags and use their code references tool to keep track of where flags are being referenced. The tool uses their first party Go client to interact with the API but the client doesn't handle rate limiting at all even though they have rate limiting headers clearly documented for their API. reply klooney 8 hours agorootparentFirst party clients are typically an afterthought, and you can't add features without getting a PM to sign off, which strangles the impulse to polish & sand down rough edges. reply rattray 8 hours agorootparentAgreed. Any in particular come to mind that you'd like to see improved? (my company provides first-party clients with a lot of polish; maybe we could help) reply rattray 8 hours agoparentprevFWIW, here are the only links I could find in the article which were tagged \"Python3 Package\": https://community.openai.com/t/647723 and https://community.openai.com/t/586484 . Note they don't see to have anything to do with the Python package whatsoever. I was pretty disappointed to see this, as I work on the Python package and was hoping for a good place to find feedback (apart from the github issues, which I monitor pretty closely). I'm not a data scientist; maybe someone from the Julep team could comment on the labeling? Or how I could find some more specific themes of problems with the Python package? (Was it just that people who have a problem of some kind just happen to also use the Python library?) reply alt-glitch 7 hours agorootparentHey! Happy to chat over email/X more closely and help you out. Nomic Atlas automatically generates the labels here. There could be different variations of posts involving the Python Packages. But I did some manual digging & here's what I found; Heading over to the map and filtering by posts around \"Python Packages\" leads to around 900 posts. Sharing a few examples which do talk about people's posts related to the python package: - https://community.openai.com/p/701058 - https://community.openai.com/p/652075 - https://community.openai.com/t/32442 - https://community.openai.com/p/143928 Note: My intuition is that most of the posts are very basic, probably user errors like \"No API Key Found\" etc. reply rattray 6 hours agorootparentgotcha, that makes sense - thank you! reply throwaway98797 18 hours agoprev [–] did they have the right to use all thier data? /s reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI established an official developer community on Discourse, amassing 20,000 users and 100,000+ posts since March 2021, offering insights into developer sentiment and feedback.",
      "A dataset was generated from posts across categories, indicating trends and insights on AI technology, with many neutral posts and some categories showcasing negative sentiment.",
      "The dataset encompasses post information and sentiment analysis, aiming to enhance AI technology, with the creators advocating for its use and inviting feedback and discussions."
    ],
    "commentSummary": [
      "OpenAI's tech lead discusses AI applications in Discourse, emphasizing sentiment analysis, post embeddings, and ethical considerations regarding data analysis without explicit consent.",
      "Community members debate OpenAI's practices, forum moderation, and Python APIs, highlighting both benefits and criticisms of Python packages, including common user errors and data usage rights.",
      "The conversation also explores privacy concerns, content moderation challenges, and potential risks associated with automated systems in the context of AI implementation."
    ],
    "points": 284,
    "commentCount": 55,
    "retryCount": 0,
    "time": 1711637073
  },
  {
    "id": 39850972,
    "title": "UV-K5: The Ultimate Hackable Handheld Ham Radio",
    "originLink": "https://spectrum.ieee.org/quansheng-uv-k5-hacking",
    "originBody": "DIY HANDS ON The Most Hackable Handheld Ham Radio Yet The UV-K5 can be modded at the click of a mouse STEPHEN CASS27 MAR 20244 MIN READ You can add new features or upload your own boot screen to the UV-K5 radio with just a few clicks. JAMES PROVOST",
    "commentLink": "https://news.ycombinator.com/item?id=39850972",
    "commentBody": "UV-K5 is the most hackable handheld ham radio yet (ieee.org)256 points by Brajeshwar 20 hours agohidepastfavorite143 comments crims0n 17 hours agoReally impressed with the custom firmware people are developing for this radio. The one I am on now is written by egzumer and even comes with a spectrum analyzer. Unfortunately, the radio itself is about what you would expect from a $30 import. The frontend easily overloads, and the harmonics on transmit are way outside what the FCC permits. Still, as a gateway into ham radio, it is one hell of a value proposition. reply jcrawfordor 15 hours agoparentHave you been able to perform testing? I think the quality of these Chinese radios has actually improved quite a bit over the years, and the reports I see of testing UV-K5s shows them within FCC limits (well within for 2M, closer to the limit for 70cm). The situation is much worse if you transmit outside of those bands, but, well, that's not really what it's designed for anyway. You have to be cautious with harmonics reports on these radios because a lot of people seem to try to evaluate them with an SDR... and they are pretty much guaranteed to overload the SDR's front end and cause all kinds of intermodulation that people mistake for emissions of the radio. I wish ARRL still put more testing pieces in QST because it's hard to know what to make of the testing reports you see online. People end up finding all kinds of different results, and I'm sure there's variation between units, but it also seems like there's a big aspect of... random internet people unsurprisingly having inconsistent test setups. reply transcriptase 12 hours agorootparent> You have to be cautious with harmonics reports on these radios because a lot of people seem to try to evaluate them with an SDR... and they are pretty much guaranteed to overload the SDR's front end and cause all kinds of intermodulation that people mistake for emissions of the radio. This is something more people should know. On the most popular USB SDRs even a local FM radio station will have the appearance of transmitting on harmonics, which I know for certain the serious hams would report within hours. reply windexh8er 9 hours agorootparent> ...which I know for certain the serious hams would report within hours. In reality this is a myth. There are very few people who go to this length. And even the serious Hams will need some serious gear (e.g. KrakenSDR) to pinpoint quickly. Lots of Hams take themselves way too seriously. Folks like NotARubicon on YouTube do a good job of calling it like it is. reply transcriptase 8 hours agorootparentI’m not sure about where you are, but here the scene is littered with retired electrical engineers, former broadcast professionals, and military comms specialists with tens of thousands of dollars worth of high-end transceivers, vnas, and small antenna farms. And my point was that the guys with serious gear would quickly notice if a local fm country station was actually transmitting in the amateur bands like a cheap SDR might incorrectly show. reply windexh8er 9 hours agorootparentprevI own a few UV-K5s and compared to superheterodyne the actual RF capabilities of the radio isn't all that great. I own a few Wouxon (higher end Chinese radio) and they aren't even remotely in the same league. I've tried a number of more quality antenna on the Quansheng and they do help. I've even had one where the RF was clearly broken out of the box, so your mileage will really vary on these. All that being said, for the money and programability, they really are cool radios. Not legal on GMRS, but perform as expected in those bands with a better antenna. Airband on these things is pretty much next to useless though. Hopefully other manufacturers will follow suit. reply topspin 16 hours agoparentprev> way outside what the FCC permits Confirmed. And yet it has an FCC ID from early 2023... https://fcc.report/FCC-ID/XBPUV-K5 reply drmpeg 12 hours agorootparentThe FCC doesn't test the transmitter. The device is only tested to comply with Part 15 unintentional radiation rules (just like any other consumer electronics device). reply geerlingguy 17 hours agoprevAnd... I just bought one. It's under the threshold for impulse buy to fuel the hobby. Hopefully it doesn't sit in the box for too long, I would love to hack away at it and see what else it can do. I would love more manufacturers to open up the firmware on devices like these. Leave default safeguards in place from the factory, but allow tinkering. Cheap, hackable stuff helps get new people interested in radio, especially if it can be managed using tools people might already be familiar with like WebSerial. reply kps 14 hours agoparentI just ordered one too, just because of the hackability. (I will likely never transmit with it, since I already have a radio with a better radio.) reply transcriptase 12 hours agorootparentFor you and anyone else, make sure you order a programming cable. The baofeng one works for the UV-K5. And when you go to use it, be aware that you’re going to have to press it into the radio far harder than you think. It will make a loud click the first time, and save you hours of troubleshooting! reply geerlingguy 11 hours agorootparentHeh, good to know! I guess they're using ports that are just a bit too tight from the factory. reply AnarchismIsCool 16 hours agoparentprevPeople stress about the safeguards too much. If you run around trying to jam gps, airband, or cellular you'll get your pp slapped pretty hard. If you go off and experiment with random other stuff without making too much noise, literally nobody cares. reply _spduchamp 9 hours agoprevThese are listed $24 (Canadian) on aliexpress, with free shipping. How is that possible? I just can't get my head around how these can be so inexpensive. Wouldn't the materials cost more? Like really, can someone help explain the economics of how this works? reply AnarchismIsCool 8 hours agoparentThere are basically two main chips in there, one handles most of the RF chain, the other drives the display and handles button pushes. Both likely cost under a dollar each at volume. The vast majority of the other components are tiny passives that cost less than a cent each and are just for filtering and impedance matching. In terms of development costs, there is definitely skill in component selection and packaging, but generally speaking the main PCB could have been designed by a lot of EE grads. If you spend some time looking at it, in terms of sophistication it's barely a couple steps above a happy meal toy, but since nobody wants to make quality flexible use radios, this is what everyone ends up buying to experiment with. reply bwv848 2 hours agoparentprevIn China, the retail price is 90 yuan, which is 12.5 dollars and 17.2 Canadian dollars according to current exchange rate. Sometimes people can get them cheaper. reply chpatrick 9 hours agoparentprevElectronics are actually really cheap. reply rasz 2 hours agoparentprevYou have been conditioned by US corporations. Apple consumer electronic prices, TI microcontroller prices, Qualcomm/TI radio chip prices, Intel FPGA prices etc. reply jhoechtl 6 hours agoparentprevIs Chinese software required? It might be just a booster rocket for Chinese spyware. reply squarefoot 4 hours agorootparentAccording to the article, the radio can be reflashed using a browser, but if any suspicious software was needed for reflashing, it could anyway be run in a VM after setting the USB/serial port as pass through. To program frequencies and modes then one can use Chirp, which is Open source. https://chirpmyradio.com/projects/chirp/wiki/Home reply eternityforest 5 hours agoprevWhat the community manages to do is amazing... but I still wonder why all these hackable devices use such low power chips. So many things on the market are basically just computers with specialized IO, but most of the firmware and MCUs don't reach the full potential of the rest of the hardware. A few extra dollars could add literally hundreds of features if they wanted. reply amatecha 14 hours agoprevLong before people were modding these I got one for $20 CAD from Aliexpress. The speaker only works intermittently, requiring me to push on the case to get it to work (I guess there's a weak solder joint or something). I contacted the seller and of course just got infinite runaround. Either way, \"buyer beware\", these things are insanely cheap for a reason. Basically a dollar-store HT. :P reply sedatk 12 hours agoparentJust buy it on Amazon for $10 more, and you're good to go. reply amatecha 12 hours agorootparentUh, on Amazon Canada, the Quansheng UV-K5 is being sold for $125.99 heh reply transcriptase 9 hours agorootparentOrder straight from Aliexpress. You can get one for around ~$30 CAD all in depending on the day. And believe it or not the shipping only takes a couple weeks. reply mschuster91 12 hours agorootparentprevAll that adds is fast shipping because someone with an alphabet soup brand name upfronted a bit of money to get a container load of them shipped from China to an Amazon warehouse. reply sedatk 11 hours agorootparentIt adds no-hassle returns. reply mikewarot 14 hours agoprevI had to look around to find a datasheet[1] for the BK4819 which is the heart of this rig, but it appears that there are I/Q outputs on receive, and possibly I/Q inputs on transmit internally, so it's an SDR, and not limited to FM only. The low output power will likely restrict it to line of site, but it's an interesting substrate on which to work. [1] https://touchardinforeseau.servehttp.com/f4kmn/f4kmn/FRANCAI... reply ianburrell 6 hours agoparentI really wish someone would use one of these chips to make computer-controlled SDR radio. Basically, USB-C port on one side and antenna connector on the other. There are lots of interesting things that could do on VHF/UHF bands with computer radio. Good example is APRS repeater. Or packet data. Receive can be done with SDR but transmit requires a radio that use audio that is flaky. I would love full I/Q but FM data would be fine. reply nominatronic 10 hours agoparentprevIt's only I/Q on the receive side. The TX side is FM only. reply lxgr 14 hours agoparentprevIsn't UHF/VHF (edit: pretty much) always line-of-sight? Edit: Can the downvotes please explain where I'm wrong? It's a genuine question! reply rfthrowaway2 14 hours agorootparentTropospheric ducting is a thing... [1] [1] https://en.wikipedia.org/wiki/Tropospheric_propagation reply lxgr 14 hours agorootparentSure, but is that a thing you'd be able to (and want to) do using a small handheld radio? It's not like HF where ionospheric reflections are pretty much the biggest appeal of the band. reply rfthrowaway2 13 hours agorootparentPlenty of use-cases, unsure what you're arguing against. https://www.youtube.com/watch?v=PmNo1TX1E3Q https://www.youtube.com/watch?v=Hn7_CZurV7Y https://www.reddit.com/r/amateurradio/comments/jcvv5g/did_so... reply lxgr 13 hours agorootparentWho's arguing? I was under the impression UHF/VHF is mostly used for line-of-sight communications, unlike HF, and NLOS usually needs much stronger transmitters than would be practicable in a handheld radio. Curious to learn about other applications. reply throw0101c 9 hours agorootparent> […] and NLOS usually needs much stronger transmitters than would be practicable in a handheld radio. While not typically thought of as a \"handheld radio\", Elecraft's KX-line are pretty compact and portable: * https://elecraft.com/collections/kx-line/products/kx2-ssb-cw... * https://elecraft.com/collections/kx-line/products/kx3-all-mo... The KX3 can run on eight AA batteries. reply ianburrell 6 hours agorootparentprevThere are people who use SSB on VHF to talk over long distances. There is always some bending and they can get weak signal. On rare times, troposphere ducting means they can reach hundreds of miles. This wouldn't be useful for that since, like most handhelds, it doesn't have SSB, just FM. reply nullc 5 hours agorootparentprevRadio line of sight also includes repeaters on a mountain 100mi away (radio line of sight is somewhat further than optical) and satellites 250 miles above. Tropo does occasionally get intentionally used by HT users though most weak signal operation is on SSB (and not on HT's, which don't do SSB for frequency stability reasons that no longer apply and amplifier linearity issues that only somewhat apply). reply lormayna 14 hours agoprevLooking forward that someone will port FT8 to this devices. At the moment you need a phone or a PC to tx/rx in FT8. reply ianburrell 6 hours agoparentFT8 would be pointless. FT8 uses SSB which this can't do. Doing FT8 on FM is a waste of bandwidth and low-signal. FT8 is usually done on HF since that has long-distance propagation and it is important to pick out tiny signals. People do FT8 on VHF but they use radios with SSB. The radio probably doesn't have the processing power for FT8. A Raspberry Pi 3 was struggling for me. Also, a big part of FT8 is choosing what to send and who to respond to, need a good display for that. reply lormayna 30 minutes agorootparentIt seems that there is a firmware doing SSB (I don't understand if it's real SSB or something emulated). Anyway, the radio chip of UV-K5 is able to manage distinct I-Q signal, so it just a matter of implementing SSB via software. reply gh02t 12 hours agoparentprevDoes it have the hardware? Per the article the CPU and available flash memory are super limited. reply sitzkrieg 13 hours agoparentprevthis is what im looking forward to, too. ive even started making some hardware around digital modes so this might make a cheaper frontend + filter investment lol reply ubj 16 hours agoprevThis looks interesting. A common complaint about the Baofengs is that they transmit significant unwanted harmonics outside the intended frequency. Do these radios have this issue as well? I'm very excited about the prospect of more radios that can be easily programmed with mainstream languages such as Python / Rust / C++. Hopefully this becomes a stronger trend going forward. reply stavros 16 hours agoprevI was about to buy one of these (of course), when I noticed that the K6 exists. Which one is the best one to buy to hack around with? reply thrtythreeforty 15 hours agoparentThe K6 has a USB-C port for charging. Of course, they bungled it and it doesn't have the CC resistors to trigger PD chargers, so you need an A-to-C cable, or some soldering skillz. Other than that, they are reported to be identical hardware. reply 05 12 hours agorootparentSoldering skillz are always nice to have but the amount of Chinese 'USB C' gear that skimp on the 5.1K resistors is truly enormous, and adding them gets old really fast. Some designers even combine cc1 and cc2 to save 0.01¢ on the second resistor, with predictable results.. reply AnarchismIsCool 8 hours agorootparentThey probably don't know they need them. A lot of stuff is just copy-pasted from old reference designs that used micro usb and then they slapped a USB-C connector on for marketing purposes. reply _JamesA_ 14 hours agorootparentprevAre you sure about that? I just ordered the UV-K5 from Amazon sold by Quansheng and it is labeled as having USB C charging. There's also a third party seller with an item description of \"UV-K6 UV-K5(8)\". That listing seems fishy. I don't see a \"UV-K6\" listed on the Quansheng web site [1]. EDIT: After more research it looks like the UV-K5(8) is also known as the UV-K6 [2]. I'm curious which model I receive. [1]: http://en.qsfj.com/products/?series=3 [2]: https://hagensieker.com/2024/03/12/quansheng-uv-k6-radio-rev... reply smarx007 13 hours agorootparentUV-K5(8) is legit: http://en.qsfj.com/products/3268 reply thesh4d0w 15 hours agorootparentprevMy K5 also has a usb-c port for charging. AFAIK they are identical except for slightly different housing. reply npunt 9 hours agorootparentprevA review from Amazon on UV-K5: \"Warning though, the USB-C port feature is misleading in some way: you can't get it charged with whatever USB-C cable you have, it needs to be a USB-C power-only cable with USB on the other end (like the one provided). If you try USB-C to USB-C from your Mac it won't work. Also, USB-C direct charging can only charge it to max 80%. Other than that, this is quite a nice radio well built.\" Sigh, won't buy any electronics that can't just charge USB-C without bs.. https://www.amazon.com/QUANSHENG-UV-K5-Rechargeable-Emergenc... reply krupan 7 hours agorootparent\"won't buy any electronics that can't just charge USB-C without bs..\" I don't think that leaves too any ham radio to buy then? reply briandw 17 hours agoprevThe website and manual mention \"10 groups of scrambled voice encryption\". They don't specify what this is actually doing. I've always wondered what it would take to make a really good encrypted coms system using one of these. However my understanding is that encrypted transmission on HAM is illegal. reply thereddaikon 17 hours agoparentUsing encryption on ham bands is illegal yes. You can use it on commercial bands if you buy a license from the FCC and ISM (common 2.4ghz/5Ghz) is mostly fair game as well. The practical reality is people are probably getting away with abusing it because the FCC is not omniscient and has limited resources. For an individual to draw the ire of the FCC they need to make a nuisance of themselves. Occasionally you hear of people getting arrested for using illegal cell jammers and the like. I can't recall hearing of someone getting caught using encryption. For something like this to really get a crackdown you would need a watershed event like RC aircraft had with cheap drones. The point where very capable hardware became extremely cheap and accessible to people who know nothing about the hobby. The RC aircraft community effectively self policed for decades because the bar for entry was high enough that anyone getting involved had to engage with the community. Drones changed that. And the FAA had to step in and regulate. I think we are getting close with cheap Chinese radios. But even Baofengs still require programming and educating yourself. Devices like the flipper zero are far more damaging. Even though they are limited in their capabilities, they make it trivial for the user to make a nuisance of themselves in ways that are hard to ignore. Its probably a matter of time until a cheap radio hits Amazon that does everything for you and permits non hobbyists to ruin everything. Imagine something as capable as a HackRF but as easy to use as an iPhone. Then we have problems. reply avidiax 16 hours agorootparentI think there's one more intrinsic safeguard for these radios vs. drones. Handheld radios are mostly not useful in an urban setting (compared with a cell phone), and only other radio users can even be bothered by them. Unlike \"drone spotted in posh neighborhood looking into windows\" as a headline, \"Baofeng user briefly interferes with garage door opener\" just doesn't have any edge. reply thereddaikon 13 hours agorootparentThat's a fair point but I've seen for a few years now Baofeng Ham radios resold as walkie talkies for recreational use. Often advertised as for powersports like ATVs and boating. This is completely illegal but these resellers have been doing it for awhile now without any consequences. Still, the real world impact is limited and mostly contained to annoying Hams. And its a meme in the community that the FCC doesn't care about Hams. I think the flipper zero/hack rf side of things is the bigger problem. Its very useful to whitehats but they also lower the bar for a lot of disruptive attacks. Get a flipper zero and war drive any neighborhood built in the 80's and its prime hunting ground for forcing garage doors. I'm surprised we haven't heard more of that actually. reply ganzuul 51 minutes agorootparent> I'm surprised we haven't heard more of that actually. It’s a bit of an information hazard. E.g. what if someone made sewer pumps run backwards. Meanwhile the level of exploit capabilities is on the level of Spectre. There is such a wide gulf between what is and what should be that we can’t properly discuss it. reply fullspectrumdev 14 hours agorootparentprev> Imagine something as capable as a HackRF but as easy to use as an iPhone. This is literally just a UX overhaul away for the HackRF Portapak system. As-is the UX is slightly too awkward for the casual user, but these things trend towards becoming more user friendly over time. Honestly a Portapak with Bluetooth module and a phone app to control it would be pretty fucking cool, now that I think about it. reply crmd 14 hours agorootparentprevQuestion from a non-ham: how does the fcc define encryption? Is it ok to speak in code, like a numbers station? What about speaking in Navajo, like the Americans did in ww2? What if it was a made-up tonal language with lots of clicks that sounded similar to a modem transmitting a bitstream? reply threeio 14 hours agorootparent\"messages encoded for the purpose of obscuring their meaning\" https://www.ecfr.gov/current/title-47/part-97#p-97.113(a)(4) It's intentionally broad, and gives exceptions for controlling satellites as the only real exception. People try to fight that publishing encryption keys would mean that you are within the intent of the law, I struggled decades ago trying to create a digital voice mode while every OM told me I was trying to encrypt things. sigh. reply crmd 12 hours agorootparentAwesome, thanks reply thereddaikon 13 hours agorootparentprevWhat threeio said is right. Technically, encoding data digitally isn't encryption and is fine, and there are digital modes used by Hams. But if you were to come up with your own scheme I could see some sweaty old timers try to accuse you of encryption just because their $3k Yaesu can't decode it. There's a good reason why a lot of recent innovation in the hacker and maker spaces has been in unlicensed bands. The rules for the Ham bands were written decades ago when just trying to talk to people around the world was considered experimental. Now its trivial to do that with HF with the right equipment and a bit of reading. The FCC tends to neglect the ham space which is both a good and bad thing. Lack of attention means people are probably getting away with doing a lot of harmless things they technically shouldn't be. But it also means we are stuck with rules from the 1930's. reply reaperman 16 hours agorootparentprevAssuming there was aggressive enforcement against it, could someone “get away” with encrypted transmission sent in low-power alongside high-power unencrypted transmissions? Like would a well-encrypted stream look indistinguishable to a bit of noise from a low-quality transceiver? reply thereddaikon 13 hours agorootparentThat depends entirely on what they are listening with. One sub set of ham radio is called fox hunting which is a gameified form of radio direction finding. Some guys are really good at it. If you annoy one of them and they are persistent they can potentially track you down. The Feds of course have very sophisticated tools far and above what's available to you but if you've drawn that kind of attention you are already in deep trouble and looking at jail time. Powerful software defined radios like the RTL-SDR are inexpensive and with a PC can be used to scan broad swathes of spectrum and even decode and store transmissions. People can setup their own DIY listening posts this way. For someone with the right setup and looking at the right time they would notice you are using an encrypted transmission. To figure out where you are would involve repeated detections from multiple points. An adjacent topic is pirate radio stations. The Youtube channel Ringway Manchester has a series of videos about historical UK pirate stations and their stories. You might find it interesting. reply reaperman 12 hours agorootparentI think you maybe answered a different question than what I intended to ask. I meant to ask - if I only transmit encrypted communications while I’m legitimately transmitting legal content … how would anyone differentiate illegal high-entropy encryption from legal high-entropy noise? Obviously anyone can track my transmissions with “fox-hunting”. But my transmissions would superficially be valid and legal. How would they notice the well-encrypted communications which theoretically should look like random noise? reply mmmrtl 14 hours agoparentprevThis project's trying to add 53-bit *scrambling* with an ESP32. Maybe not technically encryption, but the lines are blurry https://github.com/kamilsss655/ESPRI?tab=readme-ov-file reply Lwrless 6 hours agoprevI was surprised to see that it only costs around $14 in China, so I instantly ordered one. It would nicely fill the gap in VHF bands that are not supported by my Tecsun PL-365. reply Rebelgecko 17 hours agoprevIs there a legit way to use these without a Ham license? I sometimes ski in areas with bad cell service and it would be neat to have an alternative. I've seen portable CB radios but they're on the pricier side reply 2four2 17 hours agoparentShort answer: no Nuanced short answer: operate on frs channels or buy a gmrs license and operate on those bands. This is still illegal because your equipment isn't allowed to operate on these bands but not heavily enforced. Use at your own risk. reply neilv 16 hours agorootparentIIRC, the transmit power of all versions of the UV-5R are too high for FRS. Besides being noncompliant in ways that people are more likely to consider harmless technicalities, such as the antenna being removable. reply avidiax 15 hours agorootparentThere are 5W and even 50W GMRS bands. You would need a license in that case, but it's not expensive. The handheld would be non-compliant, but that wouldn't be detectable on-air unless the deviation or power is outside spec for that frequency. https://en.wikipedia.org/wiki/General_Mobile_Radio_Service#F... reply ganzuul 15 hours agoparentprev> legit If you have an emergency you can initiate emergency traffic. Bought an UV-R5 years ago during a short prepping spree as backup if the mobile net is compromised. Took off the antenna and transmitted less than a second to see if an RTL-SDR would pick up the carrier wave. Then it went into storage and I top up the battery once per year. reply teraflop 12 hours agorootparentBut to clarify, for the purposes of amateur radio, \"emergency traffic\" is defined as: > essential communication needs in connection with the immediate safety of human life and immediate protection of property when normal communication systems are not available (47 CFR § 97.403) That is, just because your communications are related to an ongoing emergency doesn't automatically give you the right to transmit without a license. reply Avamander 14 hours agorootparentprevRunning a transmitter without an antenna is a great way to ruin it. reply ganzuul 2 hours agorootparentI thought of that but if it can’t handle that for a second then I can’t rely on it for prepping purposes. reply threemux 11 hours agorootparentprevYou can use any means necessary if life or property are in imminent danger and only if you're already licensed. The section of Part 97 everyone quotes applies to amateur stations only (like the rest of Part 97). So unless there's another part of the FCC rules that allows this I'm unaware of, even emergency communications made by unlicensed users are illegal. reply ganzuul 2 hours agorootparentIn my country if I had the means to avoid an emergency but did not utilize it I can be held liable. reply kQq9oHeAz6wLLS 10 hours agorootparentprevIf life is on the line, worrying about the FCC is pretty low on the priority list. reply cbfrench 16 hours agoparentprevThe better question might be: What is your imagined use case for this radio? A VHF/UHF handheld is more or less limited to LOS transmission, so you would either need to be within reliable range of a repeater or another person with an HT tuned to that frequency. If you’re looking for something you can use in a backcountry emergency, you’d frankly be better off just plunking down the money for a satphone, which is going to be much more reliable. An HT radio is unlikely to be of much use in that scenario, unless you know there’s a repeater nearby that is regularly used and that you can hit from your location. OTOH, if you’re looking for a new hobby and a gadget to play around with, get a license, pick up an UV-K5, and have fun! If you want to get a license just to play on the radio, it is super easy. A Technician license will allow you legally to use any VHF/UHF radio with full access to those bands (plus all of 6m and some access to other HF bands). It’s extremely simple to get licensed. Put the HamStudy app on your phone, run through the question pool/practice exams until the info is in your memory, and then sign up for a remote exam on HamStudy.org. I studied for my Technician license for like a day and a half and aced the Tech exam. I aced my General and Extra exams within a week using the same method. I have no background in tech or EE. So, yeah, it’s easy. reply Rebelgecko 15 hours agorootparentLess for emergency use (in a life or death situation I'm less worried about upsetting the FCC), more for \"hey dude, wanna meet up for lunch\" or \"FYI I'm heading back to the car\". Ideally something that doesn't require everyone to have a license (eg I can just hand a friend a without advance prep) but with a couple miles of range without LOS (maybe I'm underestimating the Toys R Us walkie talkies but I'm assuming they don't reach that far). I've also seen LoRa based solutions like Meshtastic but not sure how practical it is reply FrankoDelMar 13 hours agorootparentThe BC Link is a commonly used GMRS radio for backcountry enthusiasts. https://backcountryaccess.com/en-us/c/bc-link-radios/ Any decently made GMRS radio should be fine for coordinating around the ski resort. I've had mixed results with FRS as the range is quite poor. This is amplified by the fact that the other party could be on a different face of the mountain as well as covered by trees. It's also convenient that many GMRS and FRS frequencies overlap, so if someone in your party only has an FRS radio or doesn't have a license, they can still communicate with GMRS users, assuming they're within range. As another commenter pointed out a satellite communicator would be preferable in an emergency situation, as FRS/GMRS cannot be relied on to request emergency or rescue services. I keep a Garmin inReach Mini for this purpose. https://www.garmin.com/en-US/p/765374 reply cbfrench 15 hours agorootparentprevYeah in that case, you’d probably be better off just picking up some decent GMRS handhelds. Spend a little more on some antenna upgrades, and you should have no issues. If you really want to stay on the right side of the law, you can have everyone in your group (who isn’t related to you) throw $35 at the FCC for some GMRS licenses. But, depending on terrain, you should be able to stay in reasonable contact with everyone with 5W if you’re within a mile or two. reply Steltek 15 hours agorootparentI'm pretty sure you can find the same radio hardware platform but FCC certified for GMRS (or so the label says anyway). Maybe they added filtering to get it to pass? That means a $35 GMRS radio with USB-C charging, swappable antennas, and higher transmit power. He's already seen Meshtastic, which is something I definitely want to play with for his exact use-case: coordinating with friends while skiing. reply unethical_ban 16 hours agorootparentprevI agree in general, that if someone has a short amount of time, a small amount of money, and any kind of ability to memorize some rules, then getting a Tech license is a breeze! And if you're actually enjoying it, getting a General is not difficult, either. In my humble opinion, the rules on antenna and transmit power for FRS are annoying - garbage range and prone to interference. I wouldn't want to risk pissing off the FCC or a ham with too much time on their hands by running hot on FRS constantly... But for occasional backwoods travel with friends or to use in an emergency without clogging up ham frequencies, it's totally possible to reprogram certain Baofengs and these radios to transmit on FRS frequencies with low wattage. In fact, I think FRS was modified to allow higher power now, so the low-end of these radios fits. It's just the antenna reg that they break now. reply cbfrench 15 hours agorootparentYeah, definitely agree 100%. It’s not a popular ham opinion, but the general follow-up to “Is this illegal?” should be “Will anyone care?” Lots of practices in the radio world are, strictly speaking, illegal, but no one cares. See all the guys running multiple kW amps on CB, which is limited (laughably) to 4W AM and 12W PEP on SSB. If you modify a bunch of Fengs to run on FRS/GMRS freqs to talk up and down the mountain out in the middle of nowhere, sure, it’s illegal, but if no one hears your transmissions other that the people on the mountain, it’s not an issue unless you take the FCC regs as moral edicts. But if you’re looking for a way to get a signal out in an emergency, a satphone is still going to be your best bet. reply myself248 15 hours agoparentprevWhat's the reasoning for not getting the license? It's super straightforward, the test questions are about some RF basics and the regulations you'd have to comply with anyway, and it's super cheap and lasts a lifetime. IOW, I think you're solving the wrong problem. reply colelyman 14 hours agorootparent> lasts a lifetime You need to renew the license every 10 years, but as long as you renew you don't need to take a test (which is maybe what you mean by \"lasts a lifetime\"). reply amatecha 14 hours agorootparentYeah depends on the country/jurisdiction - in Canada, an amateur radio certification is valid for life, and doesn't require any sort of re-testing or paid renewal or anything. Pretty nice. One of the few times the government has really done something right, IMO :) reply fullspectrumdev 13 hours agorootparentprevIn a lot of places your name/address is publicly linked to your callsign when you have a HAM licence, in databases anyone can search. Which is absolute shit. reply lhamil64 8 hours agorootparentIf you're in the US, you can use any address you can receive mail at (work, a PO box, mail forwarding service, etc). I used a cheap mail forwarding service (it actually doesn't charge a monthly fee, just shipping and I never get mail there anyway). The important thing is to get this setup before you even get your FRN because the change history of your license is also public, so once your address is there, it's viewable forever. reply transcriptase 12 hours agoparentprevI believe both the FCC and ISED have exceptions for unlicensed individuals to use any amateur frequency in the event of a genuine emergency. For the price it could be worthwhile to program one of these with local comms frequencies. As long as you don't transmit outside of an emergency it's perfectly legal to both have and listen with. Plus it has a flashlight! reply amatecha 14 hours agoparentprevYou can snag one and listen, just can't transmit. Otherwise, no, no way to legally use it without obtaining an amateur radio certification/license. reply webnrrd2k 13 hours agoparentprevI could be wrong, but I believe that anyone, even without a license, can use them to listen to ham bands at anytime. You can not use them to transmit, unless there is some sort of emergency. reply lxgr 14 hours agoparentprevFor that, I'd just get FRS (US) or PMR446 (EU) radios (or your local equivalent). No license needed and very cheaply available but still interoperable across manufacturers. reply yellow_postit 14 hours agoparentprevGetting radios for skiing as a family and group has been a game changer. Rocky Talkies are very accessible. reply mceachen 13 hours agorootparentYou got your kids to pass a ham license test? Kudos. reply _whiteCaps_ 12 hours agorootparentRocky Talkies are FRS. reply ElevenLathe 16 hours agoparentprevI wonder if this could be programmed to operate on CB bands only? If it could, would that be legal to use on the air? reply cbfrench 16 hours agorootparentI don’t think it would. IIRC, CB radios are type-certified, which means that the transmitter itself is licensed, rather than the operator (similar to FRS). That said, these days the FCC gives absolutely zero shits about what happens on 11m, so I wouldn’t expect any knocks at the door if you modify a non-CB radio for use on CB channels. reply MandieD 14 hours agorootparentprevWrong frequency range - these handhelds are designed for 2m and 70cm, and CB is 11m. You'd have to do a lot of tricky hardware modification first, and then hook it up to a rather large antenna for a handheld. reply lormayna 14 hours agorootparentprevYou can, but the problem is that the radio chip is not designed for the 27Mhz, then you will generate an huge amount of spurious that will pollute other bands and wasting lot of power. I advise don't do that, just to avoid to interfere with some critical services. reply avidiax 15 hours agorootparentprevIn addition to it being technically illegal, you probably can't transmit well on CB without an external antenna and amplifier. reply trelane 17 hours agoparentprevYou can always listen. It's transmitting that requires a license. Possibly also the modding as well. reply trelane 17 hours agorootparentIt's probably pretty easy for anyone here to get Technician, and probably General. I'd expect a large number could get Extra, and probably in one sitting. So you're right, you could use ham radio, but it does require a license, but it's probably not hard to get. Also, if you've an emergency, technically whatever you need to do to get help is fine. But it had better be a life and death emergency. Especially if you end up taking over the radio to a government agency, e.g. FAA or DoD. reply kstrauser 15 hours agorootparent> It's probably pretty easy for anyone here to get Technician, and probably General. Yep. If you're reading this, you probably have the technical background to pass the Technician exam pretty easily. A big chunk of the exam is stuff you learned in the physics class you probably had to take along the way. The rest is largely about specific regulations, like the power limit at this frequency is X, and don't build a tower more than Y tall within Z of airport. If you can remember \"frequency * wavelength = speed of light\" and \"watts = volts * amps\", you could probably get a passing score on the technical part of it without studying in advance. reply MandieD 14 hours agorootparentMost of the rest of the Technician exam is what is the absolute minimum you need to know about Part 97 to avoid disrupting your neighbors' radio reception and/or keep the FCC from knocking on your door. reply kstrauser 14 hours agorootparentExactly. They're the training wheels: if you never do these things, you'll be fine. (And if you do the right things and your neighbor still gets annoyed, we won't get mad at you.) General and Extra are more like \"OK, here's how you can get as close as possible to those things we told you not do to without getting in trouble.\" reply justin66 16 hours agoprev> Like Baofeng’s 5R, Quansheng’s K5 as a radio transceiver is fine. In other words, its output is so dirty the FCC would ban it if they were paying attention? reply chriscjcj 15 hours agoparentYour assertions are applicable to early UV-5R models. However, some have demonstrated that more modern iterations have made substantial improvements. https://forums.radioreference.com/threads/baofeng-spectral-p... reply justin66 15 hours agorootparentThat is good news. reply NovemberWhiskey 15 hours agoparentprevFWIW the Baofeng radio I tested, a BF-F8HP circa 2017, was (barely) compliant with Part 97 spurious emission requirements. reply nimbius 15 hours agoparentprev\"for over a decade, Baofeng has been the name in Chinese handhelds.\" well, its certainly A name...as an amateur extra and a VEC, i tried...i really tried to love these radios. - my first baofeng couldnt hit the repeater across the street from me. - my second baofeng arrived with a flashlight i couldnt turn off, and died an hour later. - my final baofeng (a gift) died during a contest and couldnt even hit a reference repeater. thankfully i was only really using it for a flashlight in a camping tent. ...but i cant. these things are hot garbage for preppers and gun nuts. reply xnyan 9 hours agorootparentApparently the newer ones are significantly improved. https://forums.radioreference.com/threads/baofeng-spectral-p... reply sitzkrieg 13 hours agorootparentprevive an bf-f8hp that outperforms kenwood ht everytime i compare, with stock antenna and all. shrug reply noodlesUK 17 hours agoprevOne thing that I picked up on the spec sheet there which you shouldn't really have in a ham radio is a scrambler. I don't know if they really mean something like DTS/CTCSS which isn't actually encryption, but the word encryption shows up in the user manual, though this might just be a troubled translation. I'm curious if anyone who has one of these has any further clarity on what exactly that feature is. reply thrtythreeforty 17 hours agoparentIt's \"voice inversion\" [1] which conceptually is just flipping the baseband signal's spectrum around a mutually-agreed upon frequency, which serves as the key. The resulting audio is difficult to understand. The UV-K5 is only capable of selecting a single key frequency; more clever schemes will have some sort of rolling code/hopping. This is separate from CTCSS/DCS which this radio also supports, and is not a method for obscuring meaning. You are correct that it is illegal to use on ham frequencies (which can't obscure meaning), but I wanna say it's legal to use on FRS. Of course, this radio is not type-certified for FRS, so technically that would also be illegal (although many people don't care so much about type-certification for FRS). You are correct, it has no completely legal use on this particular radio. [1]: https://en.wikipedia.org/wiki/Voice_inversion reply AnarchismIsCool 16 hours agoparentprevPeople should be able to have encryption if they want it. The rules are absolutely unenforceable either way and there isn't actually any drawback. I'm a ham but most hams like to freak out about it because they think it'll cause companies to suddenly start using ham bands with impunity. The reality is, we need to enforce the existing rules about IDing in the clear periodically and then send whatever you want after that. You already can't decode most of the common digital modes without significant effort because they rely on proprietary vocoders so it's not like encryption would change anything. Cue hams being angry: reply threemux 15 hours agorootparentTo be fair there are a large number of people that think the AMBE vocoders should be removed from the ham bands too. Personally I don't think they run afoul of the rules since the intent is not to obscure meaning. I think encryption is a terrible idea for amateur radio not because of companies doing things (they have ample land mobile allocations), but because it would be filled with cryptoshit scams in no time at all. I know of at least one RF-based cryptocurrency already. I'd also be worried about high speed traders on the HF bands since they're already trying to get licenses in the shortwave broadcast bands as it is. Not to mention I've yet to hear of a legit use case for encryption in the amateur bands that isn't served just as well by other licensed (and licensed-by-rule) services. reply AnarchismIsCool 15 hours agorootparentMy belief is that the core purpose of ham radio is experimentation, so playing with modern protocols, modulation schemes and techniques is really important for it to remain relevant in the future. It can't forever exist as an HF/VHF AM/FM service forever. The future is AES/RSA, DSSS/CSS, internet access, and mobile mesh systems. All that said, if we went to allowing it with a cleartext ID, how do you think the crypto scams would defeat that in a scalable way? reply thereddaikon 17 hours agoparentprevIt could be a mistranslation and just refer to DTS/CTCSS. The cpu isn't powerful enough to implement real AES encryption and the datasheet doesn't mention a hardware crypto module. It could be an inversion scrambler, that's not difficult to implement in software and even if it doesn't have that stock someone could implement it. But scramblers have limited utility now. They are really only useful to annoy others, they are trivial to defeat. Undocumented encryption capabilities are also not unheard of with Chinese made ham radios either. Seems the FCC really only cares when people make a menace of themselves and draw their attention. reply ShakataGaNai 16 hours agoparentprevhttps://youtu.be/1dt6ykstvOo?si=itGvWonj4MPQaSrq&t=384 Mentions that it's a basic scrambler. I doubt a $30 radio has a chip powerful enough for real-time (proper) encryption. reply le-mark 13 hours agoprevThis may not fit here but I’m going to ask if anyone knows; has anyone been using starlink phased array antenna s for point to point microwave communication? What would be fruitful search words for google to find out more? Thanks! reply semi-extrinsic 11 hours agoparentNot answering your question directly, but curious why you want to take on the significant endeavour to hack up something like this, when you can just buy e.g. a pair of Ubiquiti airFiber 5 and get 1 Gbps with >100km range? reply raphman 12 hours agoparentprevI don't have any personal knowledge, but you might want to ask Oleg Kutkov - he has been reverse-engineering and repairing Starlink antennas for some time. https://olegkutkov.me/ https://twitter.com/olegkutkov reply sparrish 17 hours agoprevIt's not terribly useful yet but I like where we're headed. Needs a beefier CPU and more memory. I'm going to buy a few more to help signal to manufacturers that this is the right direction. reply topspin 16 hours agoparent> Needs a beefier CPU and more memory The MCU is $0.21 at quantity on Alibaba. Make it a whole $0.50 and they'd really have something. Kind of a shame. reply ericye16 16 hours agoprevJust checking: using a modded handset on ham frequencies with a ham license would still be perfectly legal, as long as you still abide by power/no-encoding rules right? reply gglitch 15 hours agoparentMy understanding is that the purpose of amateur licensing is to facilitate and encourage experimentation and learning, up to and including people building their own hardware; that's why the rules are about how your machine affects the world. reply kstrauser 15 hours agorootparentThat's exactly right. I'm licensed by the FCC to build my own radio from a bucket of spare parts if I want to, and I can do whatever I want with it as long as I stay inside their rules. The RF I generate is what I'm responsible for. How I get there is up to me. reply ShakataGaNai 16 hours agoparentprevProvided you are broadcasting within bands you have license for, under the power limits for that band/license, and it's not encrypted... yea, you're good. Historically the FCC hasn't care about modding radios, until people start doing illegal shit with them... like broadcasting FM on AM Airband freq's reply kloch 16 hours agoprevSomeone told me once that Beofang uses the open source DSD (digital speech decoder) package in their scanners/radios. Can anyone confirm this? reply FourOnTheFloor 13 hours agoprevHow do they make it work on frequencies beyond its range? The diagram puts its range below the aviation band. reply teeray 16 hours agoprevI wonder if DMR, D-Star, or Fusion can get added to this reply tjohns 11 hours agoparentAlmost certainly not. The usual challenges here are: 1. The codec is computationally expensive (at least by embedded-device standards). Often this is handled by a dedicated ASIC. 2. The waveform needed for DMR (TDMA 4-FSK) or D-STAR (narrowband GMSK) isn't something this radio's hardware is built to generate. The RF chip in the UV-K5 is a BK4819, which does have some limited F2D+F1W FSK data capability. Anecdotally it sounds like it's limited to 2-FSK though. You might be able to get APRS text messaging / AX.25 packet radio working. I'm still waiting for somebody to build a truly hackable SDR-based HT that can be programmed with custom waveforms. reply marssaxman 17 hours agoprevSounds excellent! I suppose I'll buy one. reply trelane 17 hours agoparentFor USD28? Oh yeah. :) reply cjk2 17 hours agoprevPretty cool but is the TX / LPF still shitty? The cheaper radios usually are a real miss on this front. reply alexalx666 16 hours agoprev [–] It's kinda sad that the state of art moved to China, Bao what? Give me a Kenwood or something reply CraigJPerry 15 hours agoparent [–] Have you seen the price of the new kenwood th-75? I just sold my th-d74 to a chap in Moldova of all places and that was a really fun handy for all the extra toys on it but I will NOT be getting the 75! reply fourteenfour 15 hours agorootparent~$750 for anyone else who was wondering. reply vbezhenar 11 hours agorootparentprev [–] Is it hackable? reply CraigJPerry 2 hours agorootparent [–] I don’t think so. By default the feature set is pretty comprehensive though: RX coverage from 100khz through 512mhz with native ssb, cw filter, am and of course nfm & wfm. GPS plus various features on top of that like track logging. Dstar. A packet TNC built in. It exposed IF over usb for use with an SDR. I used it for satellite work a lot of the time (since tx was limited to vhf & uhf), it didn’t have full duplex like the 2 generations prior kenwood which I forget the model number of. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The UV-K5 handheld ham radio is highly moddable and hackable, enabling users to add new features and customize the boot screen effortlessly.",
      "Users can modify the UV-K5 radio with ease, enhancing its functionality and personalizing the boot screen with minimal effort."
    ],
    "commentSummary": [
      "The discussion delves into handheld radios, addressing hackability, hardware quality, FCC compliance, and encryption potential.",
      "Participants express worries about legality, licensing, and operating radios on different frequency bands, emphasizing safety and proper licensing during emergency situations.",
      "SDR technology, USB-C charging, and the significance of communication safety in emergencies are also key points raised in the conversation."
    ],
    "points": 256,
    "commentCount": 143,
    "retryCount": 0,
    "time": 1711631887
  },
  {
    "id": 39852879,
    "title": "Reimagining Ethereum: Enhancing Scalability Through Blobs",
    "originLink": "https://vitalik.eth.limo/general/2024/03/28/blobs.html",
    "originBody": "Dark Mode Toggle Ethereum has blobs. Where do we go from here? 2024 Mar 28 See all posts On March 13, the Dencun hard fork activated, enabling one of the long-awaited features of Ethereum: proto-danksharding (aka EIP-4844, aka blobs). Initially, the fork reduced the transaction fees of rollups by a factor of over 100, as blobs were nearly free. In the last day, we finally saw blobs spike up in volume and the fee market activate as the blobscriptions protocol started to use them. Blobs are not free, but they remain much cheaper than calldata. Left: blob usage finally spiking up to the 3-per-block target thanks to Blobscriptions. RIght: blob fees \"entering price discovery mode\" as a result. Source: https://dune.com/0xRob/blobs. This milestone represents a key transition in Ethereum's long-term roadmap: blobs are the moment where Ethereum scaling ceased to be a \"zero-to-one\" problem, and became a \"one-to-N\" problem. From here, important scaling work, both in increasing blob count and in improving rollups' ability to make the best use of each blob, will continue to take place, but it will be more incremental. The scaling-related changes to the fundamental paradigm of how Ethereum as an ecosystem operates are increasingly already behind us. Additionally, emphasis is already slowly shifting, and will continue to slowly shift, from L1 problems such as PoS and scaling, to problems closer to the application layer. The key question that this post will cover is: where does Ethereum go from here? The future of Ethereum scaling Over the last few years, we have seen Ethereum slowly shift over to becoming an L2-centric ecosystem. Major applications have started to move over from L1 to L2, payments are starting to be L2-based by default, and wallets are starting to build their user experience around the new multi-L2 environment. From the very beginning, a key piece of the rollup-centric roadmap was the idea of separate data availability space: a special section of space in a block, which the EVM would not have access to, that could hold data for layer-2 projects such as rollups. Because this data space is not EVM-accessible, it can be broadcasted separately from a block and verified separately from a block. Eventually, it can be verified with a technology called data availability sampling, which allows each node to verify that the data was correctly published by only randomly checking a few small samples. Once this is implemented, the blob space could be greatly expanded; the eventual goal is 16 MB per slot (~1.33 MB per second). Data availability sampling: each node only needs to download a small portion of the data to verify the availability of the whole thing. EIP-4844 (aka \"blobs\") does not give us data availability sampling. But it does set up the basic scaffolding in such a way that from here on, data availability sampling can be introduced and blob count can be increased behind the scenes, all without any involvement from users or applications. In fact, the only \"hard fork\" required is a simple parameter change. There are two strands of development that will need to continue from here: Progressively increasing blob capacity, eventually bringing to life the full vision of data availability sampling with 16 MB per slot of data space Improving L2s to make better use of the data space that we have Bringing DAS to life The next stage is likely to be a simplified version of DAS called PeerDAS. In PeerDAS, each node stores a significant fraction (eg. 1/8) of all blob data, and nodes maintain connections to many peers in the p2p network. When a node needs to sample for a particular piece of data, it asks one of the peers that it knows is responsible for storing that piece. If each node needs to download and store 1/8 of all data, then PeerDAS lets us theoretically scale blobs by 8x (well, actually 4x, because we lose 2x to the redundancy of erasure coding). PeerDAS can be rolled out over time: we can have a stage where professional stakers continue downloading full blobs, and solo stakers only download 1/8 of the data. In addition to this, EIP-7623 (or alternatives such as 2D pricing) can be used to put stricter bounds on the maximum size of an execution block (ie. the \"regular transactions\" in a block), which makes it safer to increase both the blob target and the L1 gas limit. In the longer term, more complicated 2D DAS protocols will let us go all the way and increase blob space further. Improving L2s There are four key places in which layer 2 protocols today can improve. 1. Using bytes more efficiently with data compression My outline-in-a-picture of data compression continues to be available here; Naively, a transaction takes up around 180 bytes of data. However, there are a series of compression techniques that can be used to bring this size down over several stages; with optimal compression we could potentially go all the way down to under 25 bytes per transaction. 2. Optimistic data techniques that secure L2s by only using the L1 in exceptional situations Plasma is a category of techniques that allows you to get rollup-equivalent security for some applications while keeping data on L2 in the normal case. For EVMs, plasma can't protect all coins. But Plasma-inspired constructions can protect most coins. And constructions much simpler than Plasma can improve greatly on the validiums of today. L2s that are not willing to put all of their data on-chain should explore such techniques. 3. Continue improving on execution-related constraints Once the Dencun hard fork activated, making rollups set up to use the blobs that it introduced 100x cheaper. usage on the Base rollup spiked up immediately: This in turn led to Base hitting its own internal gas limit, causing fees to unexpectedly surge. This has led to a more widespread realization that Ethereum data space is not the only thing that needs to be scaled: rollups need to be scaled internally as well. Part of this is parallelization; rollups could implement something like EIP-648. But just as important is storage, and interaction effects between compute and storage. This is an important engineering challenge for rollups. 4. Continue improving security We are still far from a world where rollups are truly protected by code. In fact, according to l2beat only these five, of which only Arbitrum is full-EVM, have even reached what I have called \"stage 1\". This needs to be tackled head-on. While we are not currently at the point where we can be confident enough in the complex code of an optimistic or SNARK-based EVM verifier, we are absolutely at the point where we can go halfway there, and have security councils that can revert the behavior of the code only with a high threshold (eg. I proposed 6-of-8; Arbitrum is doing 9-of-12). The ecosystem's standards need to become stricter: so far, we have been lenient and accepted any project as long as it claims to be \"on a path to decentralization\". By the end of the year, I think our standards should increase and we should only treat a project as a rollup if it has actually reached at least stage 1. After this, we can cautiously move toward stage 2: a world where rollups truly are backed by code, and a security council can only intervene if the code \"provably disagrees with itself\" (eg. accepts two incompatible state roots, or two different implementations give different answers). One path toward doing this safely is to use multiple prover implementations. What does this mean for Ethereum development more broadly? In a presentation at ETHCC in summer 2022, I made a presentation describing the current state of Ethereum development as an S-curve: we are entering a period of very rapid transition, and after that rapid transition, development will once again slow down as the L1 solidifies and development re-focuses on the user and application layer. Today, I would argue that we are decidedly on the decelerating, right side of this S-curve. As of two weeks ago, the two largest changes to the Ethereum blockchain - the switch to proof of stake, and the re-architecting to blobs - are behind us. Further changes are still significant (eg. Verkle trees, single-slot finality, in-protocol account abstraction), but they are not drastic to the same extent that proof of stake and sharding are. In 2022, Ethereum was like a plane replacing its engines mid-flight. In 2023, it was replacing its wings. The Verkle tree transition is the main remaining truly significant one (and we already have testnets for that); the others are more like replacing a tail fin. The goal of EIP-4844 was to make a single large one-time change, in order to set rollups up for long-term stability. Now that blobs are out, a future upgrade to full danksharding with 16 MB blobs, and even switching the cryptography over to STARKs over a 64-bit goldilocks field, can happen without requiring any further action from rollups and users. It also reinforces an important precedent: that the Ethereum development process executes according to a long-existing well-understood roadmap, and applications (including L2s) that are built with \"the new Ethereum\" in mind get an environment that is stable for the long term. What does this mean for applications and users? The first ten years of Ethereum have largely been a training stage: the goal has been to get the Ethereum L1 off the ground, and applications have largely been happening within a small cohort of enthusiasts. Many have argued that the lack of large-scale applications for the past ten years proves that crypto is useless. I have always argued against this: pretty much every crypto application that is not financial speculation depends on low fees - and so while we have high fees, we should not be surprised that we mainly see financial speculation! Now that we have blobs, this key constraint that has been holding us back all this time is starting to melt away. Fees are finally much lower; my statement from seven years ago that the internet of money should not cost more than five cents per transaction is finally coming true. We are not entirely out of the woods: fees may still increase if usage grows too quickly, and we need to continue working hard to scale blobs (and separately scale rollups) further over the next few years. But we are seeing the light at the end of the... err..... dark forest. What this means to developers is simple: we no longer have any excuse. Up until a couple of years ago, we were setting ourselves a low standard, building applications that were clearly not usable at scale, as long as they worked as prototypes and were reasonably decentralized. Today, we have all the tools we'll need, and indeed most of the tools we'll ever have, to build applications that are simultaneously cypherpunk and user-friendly. And so we should go out and do it. Many are rising to the challenge. The Daimo wallet is explicitly describing itself as Venmo on Ethereum, aiming to combine Venmo's convenience with Ethereum's decentralization. In the decentralized social sphere, Farcaster is doing a good job of combining genuine decentralization (eg. see this guide on how to build your own alternative client) with excellent user experience. Unlike the previous hype waves of \"social fi\", the average Farcaster user is not there to gamble - passing the key test for a crypto application to truly be sustainable. This post was sent on the main Farcaster client, Warpcast, and this screenshot was taken from the alternative Farcaster + Lens client Firefly. These are successes that we need to build on, and expand to other application spheres, including identity, reputation and governance. Applications built or maintained today should be designed with 2020s Ethereum in mind The Ethereum ecosystem still has a large number of applications that operate around a fundamentally \"2010s Ethereum\" workflow. Most ENS activity is still on layer 1. Most token issuance happens on layer 1, without serious consideration to making sure that bridged tokens on layer 2s are available (eg. see this fan of the ZELENSKYY memecoin appreciating the coin's ongoing donations to Ukraine but complaining that L1 fees make it too expensive). In addition to scalability, we are also behind on privacy: POAPs are all publicly on-chain, probably the right choice for some use cases but very suboptimal for others. Most DAOs, and Gitcoin Grants, still use fully transparent on-chain voting, making them highly vulnerable to bribery (including retroactive airdrops), and this has been shown to heavily distort contribution patterns. Today, ZK-SNARKs have existed for years, and yet many applications still have not even started to properly use them. These are all hard-working teams that have to handle large existing user bases, and so I do not fault them for not simultaneously upgrading to the latest wave of technology. But soon, this upgrading needs to happen. Here are some key differences between \"a fundamentally 2010s Ethereum workflow\" and \"a fundamentally 2020s Ethereum workflow\":2010s Ethereum 2020s Ethereum Architecture Build everything on L1 Build on a specific L2, or architect the application so that it supports every L2 that follows some standards Privacy Everything public A user's data is private by default, users merkle-prove or ZK-prove specific claims as needed to establish trust Anti-sybil You must have 0.01 ETH Application can require an ETH deposit, but clients should offer wrappers for non-crypto users that provide \"centralized anti-sybil\" (eg. SMS) Wallets EOAs Account abstraction wallets: key recovery, different access control for different security levels, sponsored txs... Proof of community membership (for voting, airdrops...) Based on how much ETH you have ETH + proof of personhood + POAPs + ZuStamps + EAS + third party curated lists (eg. Starknet's solo staker list) Basically, Ethereum is no longer just a financial ecosystem. It's a full-stack replacement for large parts of \"centralized tech\", and even provides some things that centralized tech does not (eg. governance-related applications). And we need to build with this broader ecosystem in mind. Conclusions Ethereum is in the process of a decisive shift from a \"very rapid L1 progress\" era to an era where L1 progress will be still very significant, but somewhat more mellow, and less disruptive to applications. We still need to finish scaling. This work will be more in-the-background, but it remains important. Application developers are no longer building prototypes; we are building tools for many millions of people to use. Across the ecosystem, we need to fully readjust mindsets accordingly. Ethereum has upgraded from being \"just\" a financial ecosystem into a much more thorough independent decentralized tech stack. Across the ecosystem, we need to fully readjust mindsets accordingly to this too.",
    "commentLink": "https://news.ycombinator.com/item?id=39852879",
    "commentBody": "Ethereum has blobs. Where do we go from here? (vitalik.eth.limo)243 points by bpierre 18 hours agohidepastfavorite373 comments Version467 13 hours agoAs far as I can tell, the only cryptocurrency that actually delivers on its name (i.e. being used as a currency) is Monero. Sure, it's all drugs and stolen credit cards, but it does undeniably solve a real world problem for its users instead of just being used as a vehicle for speculative investment. With that said, I think if anyone comes up with a \"killer-app\" for crypto, then it'll be on the Ethereum chain. They seem to be the only ones who consistently work towards adding capabilities to the core technology. Edit: I realize I haven't commented on the article at all. This sentence stood out to me: > Today, we have all the tools we'll need, and indeed most of the tools we'll ever have, to build applications that are simultaneously cypherpunk and user-friendly. And so we should go out and do it. Clearly, this is an important step. But the two examples he provides as a beacon of what's possible (Daimo and Farcaster) don't inspire a lot of enthusiasm. Daimo is just a decentralized version of Venmo and Farcaster is a protocol to build social networks on the blockchain, which is yet another tool and not an application. I do still like reading Vitaliks thoughts. He's a pretty good writer, and it's evident that he spends a lot of time actually thinking about the topics he writes about. reply gehwartzen 12 hours agoparent>As far as I can tell, the only cryptocurrency that actually delivers on its name (i.e. being used as a currency) is Monero. Sure, it's all drugs and stolen credit cards, but it does undeniably solve a real world problem for its users instead of just being used as a vehicle for speculative investment. This is exactly my use case (the former not later) with Monero and it's been amazing. Only marginally more difficult than to shop on amazon and feels a million times less sketchy than trying to find something locally. The speculative nature of crypto is therefore more of an annoyance as it causes the price to fluctuate too much between paying, shipping, and fund-release. reply coffeebeqn 12 hours agorootparentSo you pay with monero but you still need to give them an address to ship to which some probably store somewhere where the police might eventually find it ? I guess depending on the local police the chances of that leading to any trouble are lower than getting stabbed by a tweaker when you go out into the community to purchase your stuff reply numpad0 9 hours agorootparentI've heard that drug abusers exploit legally protected status of snail mail to avoid search, and have substances sent to an innocent third party as a dead drop or a dummy address to be intercepted. I'd assume authorities will get to you anyway, though. reply jen729w 3 hours agorootparent> abusers Excuse me. reply idlewords 5 hours agorootparentprevThe risk is not just 'stabbed by a tweaker' but 'surprise fentanyl'. And police are very unlikely to come after some random online buyer who is not distributing/reselling. reply reaperman 3 hours agorootparenthttps://energycontrol-international.org/drug-testing-service... You can get quantitative GC/MS tests in addition to fentanyl / nitazene test strips. reply dqft 3 hours agorootparentprevIf someone sends any comm without PGP or I heard a vendor they are not using it witb someone else and I'm never interacting again. It really is that simple! reply arandomusername 10 hours agorootparentprevWould probably be a lot harder for police to do anything since you could argue someone else did it in an attempt to get you in trouble or whatever. reply Semionilo 10 hours agorootparentYes you can argue like this and I thought about it when I got a letter. The issue is that if it's too much they will still raid your place even if the evidence might not be that clear and they might ignore politicians. Good luck defending this, it will still be annoying as fuck If your PC is gone for month reply arandomusername 8 hours agorootparentYou got a letter warning you? If they had proof you paid you would probably be in jail. Can still be painful, but way better than if they had proof you bought it. (Also, if any of your drugs dont arrive or were opened, never order any more) reply Semionilo 3 hours agorootparentIt was for 5g and I have no record. It was from the state and it was dropped. reply rglullis 13 hours agoparentprevOne of the things that made me less skeptical of Ethereum was that Vitalik has consistently argued based on his view of \"Ether as digital oil to power the blockchain\", which is to say that the point is not to just hodl, but to create a core technology that can enable different applications. I still think that we should not forget the \"I need a censorship-proof way to send money to someone overseas\" story, but mostly as a hedge against the existing institutions, not as an immediate need. reply wslh 9 hours agorootparentThe problem is that this gospel has been said for almost a decade now and despite, literally, billion dollars of assets that Vitalik has, and others flowing this is not happening. Not saying that this could not happen as an hypotheses but cryptocurrency foundations are far far from business execution basic practices. As an insider I can say that most money flows to a very small group of people and the governance is not really decentralized. For example, very few people can decide on Bitcoin and Ethereum protocol changes, and these people cannot be changed... reply skybrian 8 hours agorootparentIt does seem slow, but they did manage the proof-of-stake transition pretty smoothly despite delays and widespread skepticism, so I give them some credit for that. I have no idea what Vitalik is funding. Do you? reply wslh 8 hours agorootparentHe was talking about proof-of-stake since the beginning and every year was talking about the next year. Not blaming Vitalik himself but the whole thing, it is bad to give false expectations. Another thing, no pun intended, is that the proof-of-stake upgrade maintains prohibitive the network fees for transactions while other technologies have low fees. > I have no idea what Vitalik is funding. Do you? The funding of projects is through the foundation but if I remember well the original people and contributors received the ~50% of the total ethers until now. reply rglullis 7 hours agorootparent> proof-of-stake upgrade maintains prohibitive Consensus algorithms have nothing to do with transaction fees. > while other technologies have low fees. Any \"Ethereum killer\" that showed up turned out to have the same if not worse problems as Ethereum in the moment they started dealing with minimal real-world traction. > contributors received the ~50% of the total ethers until now. First: source? Second: \"50% of total ETH until now\" is doing a lot of work here. How much was during the pre-mine and how much was due to the sale? The pre-mine sale raisedConsensus algorithms have nothing to do with transaction fees. Please don't tell bullshit. Look at Algorand and other protocols, consensus has a relationship with fees because it is linked with the cost of reaching consensus! You can even read that in the Ethereum subreddit [0]. > Source? It is repeated ad nauseam in Internet [1] and you can analyze the blockchain genesis to check it. > Ethereum killer? It is not about the protocol but the community you create. Algorand has solved the PoS before Cardano and Ethereum but they are #58 now and the creator is one of the parents of modern cryptography, Turing Prize, etc. Solana is #5. Beyond comparing the Solana protocol with Algorand it is a matter of \"business\" execution, technology is a smaller part. Probably if Livra from Meta was accepted it would be in the top 10. Even when you think about Solidity as a programming language, it was not well designed (e.g. security) but that doesn't matter. [0] https://www.reddit.com/r/ethereum/comments/ru9dsq/the_proof_... [1] https://www.google.com/search?q=how+much+the+original+contri... reply rglullis 4 hours agorootparentI asked for \"source\" because I know that this is \"repeated ad nauseam in the Internet\" while being provably false. The very first result on your google query is a bitcoin.com page that is 404, but archive.org has this: The Ethereum network started off with a supply of 72 million Ether (ETH). Eighty-three percent of that (60 million) was distributed to people who had purchased ETH in a crowd sale that was conducted in July and August of 2014. (...) Of the remaining 12 million ETH distributed at the launch of the network in 2015, half was split amongst 83 early contributors to the protocol based mostly on time contributed. The other half were set aside for the Ethereum Foundation. So, the \"50% to contributors\" is actually 8.33%. > consensus has a relationship with fees because it is linked with the cost of reaching consensus! Wrong. Fees are determined by network activity and the amount of transactions competing to get into the block being \"mined\". The cost to validate a full block is not really different than the cost to validate a block that is not completely full. If Algorand or Cardano ever got close to the transaction volume from Ethereum, you can bet that their average transaction fees would go up accordingly. reply pcthrowaway 49 minutes agorootparent> If Algorand or Cardano ever got close to the transaction volume from Ethereum, you can bet that their average transaction fees would go up accordingly. I'm not sure what you mean by this. I don't know about Algorand or Cardano transaction volume, but many EVM-based blockchains process a similar number of transactions to ethereum (or more), with lower fees. They do all have different (proof of stake still) consensus models though For comparison: https://etherscan.io/chart/tx Polygon: https://polygonscan.com/chart/tx Polygon is an L2, so arguably not as decentralized. But then there's Avalanche: https://avascan.info/stats/network-activity Or Fantom: https://ftmscan.com/chart/tx reply pavlov 12 hours agorootparentprev> “Ether as digital oil to power the blockchain” This has made you less skeptical of what he’s peddling? That slogan is a series of red flags in only eight words. He could be selling actual snake oil. reply pazimzadeh 12 hours agorootparentActual snake oil has actual benefits. It's fake snake oil you want to avoid. Effect of Erabu Sea Snake (Laticauda semifasciata) Lipids on the Swimming Endurance of Mice https://karger.com/anm/article-abstract/51/3/281/41756/Effec... reply arcticbull 10 hours agorootparentThe origin story of the snake oil trope is kinda cool. Apparently the concept was brought over to the US by Chinese railroad workers. It was made from the oil of the Chinese water snake which is high in omega-3's that actually do reduce inflammation. Unfortunately there were no Chinese water snakes in America, and the American hucksters started juicing rattlesnakes. And then... other even cheaper substitutes like beef tallow, mineral oil and turpentine. [1] I suspect the Erabu sea snake is the Chinese water snake that was originally juiced? I don't think rattlesnake oil would have the same effect :) [1] https://www.npr.org/sections/codeswitch/2013/08/26/215761377... reply bloppe 11 hours agorootparentprevThis is an all-time HN comment reply maxcoder4 12 hours agorootparentprevI'll rephrase a bit for the HN crowd: \"The Ethereum currency (Ether) value proposition is that it is used to pay for decentralized apps on the Ethereum Blockchain. The more application and users are there, the more Ether is needed and hence it's value goes up\". At least that's how I understand it. OPs point is that most cryptocurrency advocates go for \"but my token and hold, it is sure to grow 10x in a few months\" and I (like probably OP) consider it misleading baseless hope at best, fraud usually. reply kemotep 1 hour agorootparentShould you not want the price to be stable? If an arcade game’s price went from 50 cents per play to 5 dollars per play because more people are using a delivery application on the other side of the world that doesn’t make much sense from a consumer perspective. reply pcthrowaway 24 minutes agorootparentThere are definitely bitcoin diehards out there who look at the price of everything relative to bitcoin. From a practical standpoint, I think most people would prefer it if the currency used by their country of residence increased in value relative to other global currencies, rather than just staying stable (though for hyperinflationary countries, even that would be a major improvement). Although stability relative to another currency (see https://en.wikipedia.org/wiki/Fixed_exchange_rate_system) is considered (by many) disadvantageous for countries with strong economies, because you strip away the central bank's power to manage the supply. This is basically the whole Gold Standard debate. For blockchain users who want reduced volatility and stability relative to a fiat currency, there are always stablecoins. reply PKop 12 hours agorootparentprev>the point is not to just hodl, but to create a core technology that can enable different applications This is has been said about every coin since the beginning of crypto. reply rglullis 11 hours agorootparentAbsolutely not. Bitcoin's initial narrative was \"digital cash\", i.e, digital payments and microtransactions. Given that transaction costs became prohibitive, it switched to \"digital gold\", or store of value, meaning that Bitcoiners defend the idea that Bitcoin's reason d'être is just to hold it. I've never seen Vitalik or any of the core Ethereum developers talking about the value of Ether being a fundamental metric of any kind. The incentives are made in a way to maximize utility of the blockchain, not the value of its base currency. reply PKop 9 hours agorootparentYou gave 2 examples supporting exactly what I just said. And there are 1000s of other ones that encompass \"crypto\". reply rglullis 8 hours agorootparentI'm really failing to understand you here. The \"beginning of crypto\" was with Bitcoin, can we agree to that? Can we agree that Bitcoin was not claiming to \"be a general platform to power distributed applications\"? If you disagree, refer to the whitepaper that says \"A Peer-to-Peer Electronic Cash System\". Can we agree that before Ethereum each chain was just a fork of Bitcoin, and that the token (aka \"the currency\") was \"sold\" to others as something that would have its value determined by supply and demand, but that the blockchain had no use that was not connected to transactions related to the token? As in: fundamentally speaking, Bitcoin, Litecoin, Dogecoin, Bitcoin Gold, Bitcoin Cash... are the same? Can we agree that Ethereum (the blockchain) enables distributed applications where people do not care at all about the price of Ether? E.g, I can host files on Storj and pay with credit card, the people hosting data are being paid in Storj's token, and everyone involved in this economy is directly using the Ethereum blockchain, but don't need to hold any Ether at all? reply PKop 8 hours agorootparentEvery coin at one point said it wasn't just for hodling, including as you pointed out BTC and ETH. Saying you have some other use case besides asset appreciation is not a unique proposition. reply rglullis 7 hours agorootparentBTC (and derivatives) were very much \"just for holding\". The fact that they hoped it could be used for day-to-day value transfers does not negate the fact that the system can only work with a continuous influx of capital. \"You should pay something with BTC, but if possible buy back the USD-equivalent amount\" was standard advice already in 2011. > Saying you have some other use case besides asset appreciation is not a unique proposition. Now, it isn't. In 2015, it pretty much was. reply PKop 6 hours agorootparent>they hoped it could be used for day-to-day value transfers And they said this, including Satoshi. Yes they were wrong, but they said it. >Now, it isn't It's never been unique, because every coin has said it including, as you have mentioned in every response so far, Bitcoiners. You've also said Eth guys have said. What are we left with? Every other **coin has obviously said it. I'm not arguing they all mean it, or they've been right. I'm arguing they all said it. reply willmadden 10 hours agorootparentprevThat's what Bitcoin used to be about, before its development team was taken over and it was crippled. reply rglullis 10 hours agorootparentBitcoin original plan was about \"digital cash\", it was fully focused on permissionless payments, but that's about it. reply willmadden 8 hours agorootparentThe whitepaper's plan wasn't, but that's not true at all for Bitcoin itself. Satoshi included OP_RETURN which allowed smart contracts - mastercoin being the first L2 (on Bitcoin). He also wanted to increase the blocksize to allow scaling. Vitalik started Ethereum because the \"core devs\" (bank incumbent funded usurpers) refused to cooperate. This is also the reason the original maintainers like Gavin and Mike Hearn split off to Bitcoin Cash and other alt-coins. reply midmagico 4 hours agorootparentThis is all pretty much boring, tired lies that altcoin profiteers like to trot out apparently assuming nobody is still around who is interested in contradicting them. The purpose of OP_RETURN was to end the script. It was not designed for rando garbage overlays that are worthless; Satoshi's views on scaling were ambiguous—rather than say it \"should\" he was instead correcting people who thought you could break consensus by simply setting the value higher. There was absolutely zero communication between Vitalik and anybody about his \"plans\" to dump an overlay into Bitcoin, and his current story about 80-to-40 bytes is a pure, often debunked lie. There isn't a single communication that Vitalik himself can point to anywhere which shows he was interested in \"cooperating\" and then core turned him down. His typical lie was that he was interested in stuffing data into Bitcoin, but then core devs \"stopped that\" by reducing the amount he could stuff into Bitcoin by half—from 80 to 40 bytes—but when he says that he also never points at any discussion, and in any event the direct history contradicts this—no versions of Bitcoin from back then ever reduced anything. It was only ever an increase: from 0, to 40, to 80 in released versions. There no evidence these people ever give which shows some lack of cooperation with Vitalik is the reason why Hearn and Andresen \"split off\" to make an altcoin, which itself is quite the absurdity, and if true just means they would have been ethereum pumpers anyway.. so.. reply pcthrowaway 19 minutes agorootparentprev> Vitalik started Ethereum because the \"core devs\" (bank incumbent funded usurpers) refused to cooperate I agree with everything about the bastardization of Bitcoin, but I don't think this is why Vitalik created Ethereum reply rglullis 8 hours agorootparentprev> original maintainers like Gavin and Mike Hearn split off to Bitcoin Cash and other alt-coins. So what developments in Bitcoin Cash have been made in that direction? Why is is that all of the \"ideological\" forks of Bitcoin do nothing but tweak some parameter size in the network settings and do not go beyond that? reply shuntress 12 hours agoparentprevThe \"Killer App\" for a cryptocurrency would be the ability to use it as a currency. reply evantbyrne 11 hours agorootparentimo this is less of a technical issue and more of a regulatory one in 2024. Sending and receiving large amounts of btc/eth for instance might take a minute. For lower value point of sale transactions you don't really have to wait. And that's money in your pocket at that point not an IOU like a pending transaction at a US bank. Paying capital gains on transactions and constantly changing value dampens adoption quite a bit though reply threeseed 5 hours agorootparent> And that's money in your pocket at that point not an IOU like a pending transaction at a US bank In Australia, we have instant transfers between bank accounts. I imagine the US will get to that point soon in which case there is no benefit to crypto for this use case. reply govg 4 hours agorootparentIt exists in the US as well (Zelle), except due to the super high number of banks, not all will have feature parity / have it enabled. The major banks like Chase support QR code scanning for instant transfers, smaller ones might require a phone number or email input via keyboard. reply godelski 4 hours agorootparentprevI don't want instant transactions. Clawbacks are very useful. Now the trick is to get that decentralized which means things like smart contracts? But still I haven't seen a good solution. reply shuntress 11 hours agorootparentprevYou could maybe call it a technical issue or an issue of adoption but the fact is that no one is scanning Monero wallet QR codes to buy coffee. reply evantbyrne 10 hours agorootparentCapital gains tax is not a technical issue per se. People also don't buy coffee with wire transfers, but nobody says wire transfers are a failure. btc/eth are better at doing what wire transfers were designed to do. The point is the tech is much better than people who have been sleeping on crypto seem to realize reply hunter-gatherer 8 hours agorootparentThis was my use case for bitcoin years ago when my wife and I had just got married. She is a foreigner and was finishing school, so I'd sometimes send her bitcoin instead of wire. Back then bitcoin was only worth a few hundred, and sending her a 1-3 hundred a month is what she needed. To wire 300 dollars is simply not worth it, at least back then. I'm not sure if it has changed at all now though. reply joshspankit 6 hours agorootparentprevSomething that has likely slowed down adoption: Current payment methods (CC, debit, tap, chip, etc) artificially appear faster than they are. When someone taps, 99% of the time the payment processor is not waiting for the funds. It’s all trust and calculations of acceptable risk (that’s why the tap limit). Crypto can adopt that approach as well. Yes, CCs/debit went through a period (as did cheques) where that trust was wildly abused and it’s likely any trust layer on top of crypto would have to go through the same period of abuse, but solutions [c|w]ould be implemented fairly quickly since it’s all tech. reply lesuorac 7 hours agorootparentprevI'm really surprised sellers aren't trying to use it at all. There was a small push awhile ago ~2015/16 where a bunch of online stores started accepting bitcoin but IIRC they all stopped once the BTC/USD started to decrease. I guess credit card fees areOr is there something unique about monero that makes it fast? The fact people aren't using it. It's just a PoW coin with some special sauce. Same grey goo energy and equipment dynamics. reply maxcoder4 10 hours agorootparentprevI can't walk into a store and pay with USD either. It doesn't mean USD is not a currency, it's just not usually accepted by stores in my country. I use Monero semi-regularly to pay for things online (usually privacy products, because sadly nobody is interested in selling me groceries in exchange for xmr). You can absolutely buy things with it. reply abnercoimbre 10 hours agorootparent> usually privacy products Could you offer examples? Straight-up curious. reply prussia 7 hours agorootparentNjalla (domain names, VPSes, VPN), and Mullvad (VPN) both accept Monero. reply monero-xmr 9 hours agorootparentprevhttps://kycnot.me/ reply 1vuio0pswjnm7 2 hours agoparentprevA \"solution\" looking for a problem. reply grigio 12 hours agoparentprevyep, Monero is the CBDC cure, what Bitcoin wanted to be in the origin reply 486sx33 13 hours agoparentprev+1 for monero reply medellin 12 hours agoparentprevI mean i have been using bitcoin for the past 6 years to send money to people outside the country with little issue. I know it’s hard to imagine for the west but places exist where working around the local financial system is a huge benefit. reply sfjailbird 5 hours agorootparentAnd lots of people pay for lots of things with bitcoin, today. It works fine, even if the confirmation takes 15-20 minutes and it costs five bucks. For some things where you prefer discretion, it's fine. For privacy, just use a coinjoining wallet. It's a solved problem for a long time. Commenters here are sour over bitcoin, for a variety of reasons, and ignorant at the same time. reply kemotep 1 hour agorootparentIn your opinion is it possible for someone to be sour on cryptocurrency without being ignorant about how it works? reply halfcat 6 hours agoparentprevIs running an app on ethereum still over 100x the cost to run it on, say, AWS? I hear CEOs talk about how this will revolutionize the world, but realistically no one needs a cryptographically secure immutable ledger to validate that someone is the true owner of concert tickets or whatever. I do wonder, if the only real-world application that needs a cryptographically secure immutable ledger, is cryptocurrency. reply shermantanktop 6 hours agorootparentAnd the only real-world, non-criminal users of cryptocurrency are cryptocurrency speculators. To an approximation, anyway. reply wslh 9 hours agoparentprevAnd Zcash and others doing the same? reply qweqwe14 5 hours agorootparentThey aren't. Zcash has opt-in privacy, which I think we've established doesn't work. By this logic BTC also has opt-in privacy – just use a mixer. Well, except that your BTC will be tainted if you do it, which effectively makes BTC non-fungible for all intents and purposes. The only way to have a private, fungible cryptocurrency is to make privacy mandatory and not \"something you enable because you are a drug dealer\". Does this mean that everyone using Monero is automatically a drug dealer? Even if it does, it's waaay better to have consistency vs having a cryptocurrency partitioned into \"normal coins\" and \"darknet market coins\" reply __MatrixMan__ 4 hours agorootparentI think it's more useful to think of ZCash's featureset not as privacy defaulting to on or off, but as giving you the option to have pseudonyms. If you were running a non profit and you wanted people to be able to anonymously contribute to it, but you wanted to prove to your anonymous donors that all of their donations were being spent in accordance with the goals of the nonprofit, you might use ZCash transparent vs shielded addresses as a way to create that division between transparent and opaque. As for t-addresses having been default, that's a regulatory hack. Exchanges have a better shot at being compliant if they can use the chain as a source of truth. So t-addresses let them create a space where they can do that, and then you as a user can privately move funds out of the exchange's domain and into a black hole without having to get your hands dirty with some other exchange. Yes I know that monero let's you generate keys for this on a tx by tx basis, but it's not the same. It's just different privacy properties with different use cases. Monero, however, has the objectively superior CLI. It's fantastic. reply godelski 4 hours agorootparentprev> Zcash has opt-in privacy You could just as accurately say Zcash has opt-out privacy too. And the privacy is much more than a mixer since you got ZKPs. Opting out of privacy gives it more plausible deniability, which is why you can find it on coinbase. Not that you should need deniability, since no one has any business knowing what you're doing with your money. reply wslh 5 hours agorootparentprevGrin's Mimblewimble? reply golergka 10 hours agoparentprev> As far as I can tell, the only cryptocurrency that actually delivers on its name (i.e. being used as a currency) is Monero. In the last two weeks I've paid to people who cleaned my air conditioning, my girlfriend's nails, our lawyer, for delivery of some goods from US, for food delivery, for a sightseeing tour, and for exchange to local currency (delivered to my home) — all in USDT. I've also got USDT from a friend for booking Airbnb for him (he couldn't do it on his own account because of reasons). At this point, most of services in local community are advertised with payment in USDT first: via binance and bybit internal transfer, or just on trc-20. reply Solvency 9 hours agorootparentYeah where do you live, Izhevsk Russia or something? reply golergka 8 hours agorootparentBuenos Aires, and yes — community of (mostly political) Russian immigrants. I don't think USDT gets much use in Izhevsk though, Russian local financial services are pretty good, especially compared to Europe or US. reply throw-the-towel 8 hours agorootparentEven the local businesses in Argentina sometimes accept crypto. I've seen a clothes shop in Jujuy that had a sign claiming to accept Bitcoin. reply SergeAx 7 hours agoparentprevDoes moving funds between compartmentalized economies count as \"currency\" use? I know quite a few cases of using it to move money from Russia or China. reply Mahn 15 hours agoprevKey quote from the article: > Many have argued that the lack of large-scale applications for the past ten years proves that crypto is useless. I have always argued against this: pretty much every crypto application that is not financial speculation depends on low fees - and so while we have high fees, we should not be surprised that we mainly see financial speculation! > Now that we have blobs, this key constraint that has been holding us back all this time is starting to melt away. Fees are finally much lower; my statement from seven years ago that the internet of money should not cost more than five cents per transaction is finally coming true. --- All of this depends on so called \"Layer 2s\", which adds a great deal of UX complexity to the end user. I'm skeptical that this is best way to solve the scalability issues that plague cryptocurrency, but I will say that this looks to me like it has a much better shot of succeeding that anything Bitcoin has ever attempted to do on this front. reply danpalmer 14 hours agoparent5 cents per transaction is high for many parts of the world, and exceptionally high if every interaction in normal life is turned into a financial transaction. reply bawolff 13 hours agorootparentIf their vision is \"applications\" it feels like any price is too high. Would you sign up for hn if it cost 5 cents? Even though that is nothing in terms of money (for most of us), the friction of money actually being involved in and of itself probably makes it not worth it. Especially when its just a silly internet thing. reply danpalmer 12 hours agorootparentIt's not just sign up though, it's posting comments, upvoting, etc. Every \"write\" becomes a transaction, many with their own tokens. > the friction of money actually being involved ... makes it not worth it This is it. There are very few people who live for this level of financialisation. reply fbrusch 25 minutes agorootparentFarcaster is doing it (allowing posting, upvoting etc) with a pragmatic architecture with different degrees of decentralization (identity onchain, posts on a p2p storage à la bittorrent), and it's going pretty fine... https://warpcast.com/ reply everfree 10 hours agorootparentprevI think it's helpful to realize that most everything on the internet is already financialized by default. Whenever you post a comment, upvote, or \"write\", it costs some company somewhere an amount of money to maintain the marginal amount of server capacity required to process your request. And if you aren't paying for the product, then you are the product of course (ads). So blockchains don't necessarily financialize things that aren't already financialized, they just tend to make money flow in a more direct way from a group of people using a service to a group of people hosting/providing it. Instead of paying using a micropayment of attention that gets monetized through a complex and often bespoke advertising arrangement, you can pay using a micropayment of a recognizable asset that has actual market value. Personally, if I could click a single Apple-pay-like button in my browser to attach say 0.5 cents of postage to this Hacker News comment to get it to post, I doubt I would think twice about it. In fact, I would probably participate more confidently knowing it's a deterrent for bots (less of a problem for Hacker News, but a huge problem on Reddit and Xitter). reply bawolff 7 hours agorootparent> they just tend to make money flow in a more direct way from a group of people using a service to a group of people hosting/providing I suppose there is a certain sense that transaction fees go to people providing services to the blockchain... but i would mostly describe it as paying rent and not actually paying the person responsible for the service. reply hanniabu 11 hours agorootparentprevThat's not how it works, not every interaction needs to be onchain reply sainez 7 hours agorootparentDon't know why this is downvoted. It is possible (and probably desirable) to build applications where only certain data is stored on chain. reply soulofmischief 11 hours agorootparentprevI'd happily pay a subscription to a closed community if I thought the value of the community was higher than the entry cost. However, I'm glad Hacker News is open and democratic. reply mattdesl 10 hours agorootparentprevIf that was the cost of decentralization I am sure a lot of users and especially content creators would consider it. I would rather pay 5c per year on Twitter and own my social graph, rather than pay 0c and leave the platform in the hands of the highest bidder. reply kinakomochidayo 14 hours agorootparentprevIt'll come down even more as blobs are increased, and PeerDAS is implemented reply chrisco255 8 hours agorootparentprevIt's really not, especially if you want to transact in USD and your native currency is not USD, you regularly will pay a 5-10% or more conversion fee. reply mindcandy 6 hours agorootparentprevPerfect is the enemy of the great. Credit card users pay $1+ fees per transaction all the time. They don’t complain only because vendors usually eat the fees on their behalf to obscure the issue. I have a “2% cash back on everything” card which I know is actually a “we charged your vendor 4% and shared half of that with people like you who clicked the right button” card. I don’t like it. But, that’s the game. People complain about the impossibility of crypto having fees of pennies with settlement times of minutes while constantly using credit cards that have fees of dollars with a settlement time of days. reply akoboldfrying 4 hours agorootparentI totally agree. The perception that, say, credit cards are fast and free is completely wrong, and based on the comfortably ignorant idea that things that only impact other people don't really exist. If there's one useful thing to take from it, it's that I think it does usefully highlight just how critical that perception is for adoption -- specifically, how thoroughly it dominates technical concerns like throughput and latency. Perhaps if shop owners were prepared to eat the bitcoin transaction fee the same way they eat the credit card fee, bitcoin might have a resurgence as a cash alternative. There would still be the transaction speed issue -- I think it would require a third party to step in to provide merchants with guarantees (in exchange for a fee), so that the merchant wouldn't have to wait for the transaction to go through. But that's not a tech problem -- it's the same problem that credit cards already have, and have already solved. reply medo-bear 13 hours agorootparentprevWhat parts of the world? In non developed countries bank fees are actually higher than in the West. In Bosnia a most basic bank account costs about $3 per month, or 60 Ethereum transactions (most people usually have 10 - 20 transaction per month). For paying bills banks usually charge a commission fee of 1%. And if you want to send money to someone 50 kms away but across the border the fee is $20 with few days wait for money to be received. reply searchableguy 12 hours agorootparentMost major developing countries in Asia have p2p instant payments and bank accounts for free or with minimum balance requirement. UPI (Indian market) launched cross border support with a couple countries starting this year. 118 billion transactions happen via UPI annually. I do think there is some niche market where ethereum payments will shine but hard to beat free and instant systems already in place at far bigger scale. reply arandomusername 10 hours agorootparentWhich is great when sending to someone in the same country, but we live in a globalized world. Sending between countries (except within EU) is best done using crypto. reply danpalmer 12 hours agorootparentprevIn many parts of the world people are basically cash-only and don't pay fees for handling money most of the time. The \"unbanked\". This is the market Ethereum wants to serve. Also I'd challenge 10-20 transactions per month. I think in many near cash-less societies it might be closer to 5 per day. reply medo-bear 11 hours agorootparentBosnia and eastern and most of europe in general is certainly not cash-less nor do most people desire that reply SideburnsOfDoom 11 hours agorootparentprev> The \"unbanked\". This is the market Ethereum wants to serve M-Pesa got there first, and without the taint of cryptocurrency. It's a real, deployed, working system at scale, and has been for years. The idea that a \"hope to serve\" after a bit more crypto tech innovation will open an untapped market ... well, I wouldn't take it seriously. It's wishful thinking at both ends of the supply and demand equation. reply thisgoesnowhere 11 hours agorootparentYou can't invest in M-Pesa tho so it's obviously very bad /s reply justwool 10 hours agorootparentprev5 per day? My budget is $20 dollars a day. Lmao people are so out of touch with reality. 5 transactions a day? For what? Honestly can I get off this train. reply dylkil 14 hours agoparentprev> which adds a great deal of UX complexity to the end user Not exactly, L2s are being abstracted away, end users eventually wont even be aware what chain they are interacting with without tracing the tx reply ASinclair 8 hours agorootparentIf you don’t know which chain you’re interacting with how can you trust your transactions are secured by a chain at all? reply sainez 7 hours agorootparentHow does this differ from e.g. online banking? Does every user manually check encryption algorithms and keys? reply AlienRobot 11 hours agoparentprev>adds a great deal of UX complexity to the end user Considering there are people who don't understand the bitcoins aren't INSIDE a physical wallet, that ship has sailed and made a revolution or two already. reply tootie 12 hours agoparentprevIn the many, many years they have spent building a pile of gibberish tech, traditional finance has begun transitioning to T-0 settlement on centralized platforms. FedNow is going to replace ACH and wires and allow 24/7 real-time transactions. reply chrisco255 8 hours agorootparentIt hasn't at all. If you try to transfer money internationally, you will still pay huge fees and it will take sometimes days to settle. Crypto is truly international, and ERC20s like USDC remain fully programmable in a way that cash will never be. It makes things like permissionless 24/7 exchanges (see Uniswap) possible. Which is more than just point to point or account to account transfers. It's an exchange from one asset to another controlled completely by an automated market making algorithm. You cannot find that in trad fi. reply DennisP 9 hours agorootparentprevLet me know when FedNow allows me to deploy a smart contract that moves dollars around according to whatever business rules I like. reply SideburnsOfDoom 12 hours agorootparentprev> FedNow is going to allow 24/7 real-time transactions. Following in the steps of what EU and UK did few years ago. (1) And which always made this cryptocurrency fast settlement stuff sound laughable - like they're describing just what a regular bank account does, and it's supposedly their special magic, so what? People need to look outside of the USA to understand the state of the art. You can even find these systems in Africa already (2) 1) https://www.ecb.europa.eu/paym/integration/retail/instant_pa... https://en.wikipedia.org/wiki/Faster_Payments 2) https://www.mfw4a.org/news/instant-payment-transactions-afri... reply everfree 10 hours agorootparent> People need to look outside of the USA to understand the state of the art. And yet people need only to look down at their smartphone, no matter where in the world they are located, to understand the state of the art in public ledgers. reply SideburnsOfDoom 27 minutes agorootparentRegarding \"unbanked\" people who are \"anywhere in the world\" but have \" their smartphone\": Cryptocurrency is not only the wrong product, but also in this case a future functionality would be the wrong time. The market gap for that has closed already due to better systems including M-PESA As I mentioned here: https://news.ycombinator.com/item?id=39857944 The consistently ignorant rhetoric here on HN about this supposedly unserved market for cryptocurrency is discouraging. Again, people need to look outside of the USA to understand the state of the art. reply EMM_386 15 hours agoprevHmm ... \"proto-danksharding\" which activated the \"blobscriptions protocol\" so that blobs are \"much cheaper than calldata\", all of this helping it to become an \"L2-centric ecosystem\". In the end, this leaves them \"not confident enough in the complex code of an optimistic or SNARK-based EVM verifier\". I'm sold ... just tell me where to transfer the money. reply PufPufPuf 13 hours agoparentI wouldn't be surprised if all that was just a made up jargon and this was a joke article. But again, it's about blockchain, so the line is thin. reply Zetaphor 12 hours agorootparentThere's actually interesting technology being developed here in the areas of distributed computation and zero trust systems. The implementations of Zero Knowledge Proofs and ongoing work on ZK-SNARKS I personally find most fascinating. There's a lot more to this ecosystem than just speculation. At it's core is a distributed world computer but all anyone knows about is money.exe because this stuff is immensely complex. If you look into the researcher rather than paying attention to the soyjack youtube thumbnails you'll find the actual substance. Nobody is going do the work for you. Or you know, just write it all off with a snide joke because \"crypto bad\". reply agumonkey 11 hours agorootparentcoti is also using dags for some reason reply talldayo 11 hours agorootparentprev> At it's core is a distributed world computer but all anyone knows about is money.exe because this stuff is immensely complex. Alternatively, because the only way to use the aforementioned distributed world computer is to engage with money.exe and buy more CoinTokens. Imagine all the kids out there who will be delighted to learn a pay-per-use code interpreter. \"Hey mom, I need your credit card to cover the gas while I debug my smart contract.\" But assuming you have the money to spend, it's a whole universe of possibilities! Just make sure to cash in before actually trying to use any of them. reply arandomusername 10 hours agorootparentHow did you not realize that one can run/evaluate code without actually broadcasting it? All you need is access to a node (plenty of public ones) and you can \"simulate\" any transaction(code) you would like. reply talldayo 10 hours agorootparentTesting a dapp off the mainnet is like ensuring your website works on localhost. It will find some issues, but it's not representative of how it will look in deployment. In any case, for actual usage it should surprise nobody why everyone conflates Ethereum with money. No, your L2 chain does not qualify as an official solution. reply sainez 6 hours agorootparent> Testing a dapp off the mainnet is like ensuring your website works on localhost I would argue the exact opposite. A website will be deployed to different versions of different browsers on different operating systems. A smart contract will exist on a single distributed computer. It sounds like the actual problem is people treating smart contract development as cavalierly as web app development reply arandomusername 8 hours agorootparentprevNo, you can test transactions as they would happen on mainnet (tests with mainnet state). Or if you want you can fork mainnet and do your stuff there. It's absolutely representive of how it looks in deployment. You can test transactions EXACTLY how they would happen on mainnet. I don't get your second point. reply Zetaphor 11 hours agorootparentprevThe problem with this statement is in assuming that any of this is actually ready for the average user, like a minor with their parents credit card. It's really unfortunate that the space received all of the attention it did during the pandemic, as that only managed to bring in misaligned expectations fueled by grifters making impossible claims. There are a number of planned upgrades on the roadmap[1], such as layer 2 blobs, that will eventually drive the cost per transaction closer to zero, however we're still a decade away from that being the case. In the meantime you can debug your smart contracts on a testnet for $0 [1] https://notes.ethereum.org/@domothy/roadmap reply talldayo 10 hours agorootparentLayer 2 blobs aren't even a solution either, arguably. You have to then engineer the layer 2 bridge to have it's own anonymization and escrow handling technology that is disconnected to the Ethereum network entirely. And realistically speaking, \"closer to zero\" does not mean free (or even at negligible cost). L2 chains can only exist when transactions on the mainnet are made impossible due to unbalanced gas prices. It's a catch-22. reply everfree 14 hours agoparentprevThe actual quote is \"we are not *currently* at the point where we can be confident enough in the complex code of an optimistic or SNARK-based EVM verifier\". The article seems to imply that \"in the end\", they will be. reply elcritch 13 hours agorootparentUnlike the parent, the full quote gives me more confidence that they're being serious about the upgrades to the Ethereum protocol. This stuff is all cutting edge distribute systems and zero-knowledge proofs work, so of course it's going to take a while to reach confidence in how it'll work. reply PoignardAzur 13 hours agorootparentprevSomething tells me that even if/when the optimistic or SNARK-based EVM verifier is production-ready, the person you're replying to will still feel somewhat unconvinced. reply pa7x1 12 hours agorootparentVery likely, but if they get it sorted out one day he will be using it without knowing. If you have no interest whatsoever and they start explaining to you all the cryptography behind establishing a secure connection to your bank most people would dismiss it as mumbo-jumbo. But now you can tell your grandma to look out for the little green lock on the web that makes her account secure. reply EMM_386 3 hours agorootparent> he will be using it without knowing. I will know. Not because of the \"little green lock\". I will know in the same way I know this site is secure. In this case, because of PKCS #1 SHA-256 (aka CKM_SHA1_RSA_PKCS_PSS). Cert issued by DigiCert Global Root G2 and valid until one second before midnight UTC on 3/29/31. That's where I guess I'm losing sight of the vision. It's tested, it's proven, it's secure, it works, no \"gas\", no fees ... I don't know. Maybe I'm just missing something. reply microtherion 7 hours agoparentprevYes, reading TFA left me quite unclear as to how many slurp juices per ape all this new technology translates into. reply monero-xmr 9 hours agoparentprevThe only reason it's foreign to you is because you are not familiar with any of the technology. It's no different that having no idea about LLMs or ML or transformers etc., or if you are not a programmer than being confused by arrays and recursion and TCP/IP... reply Salgat 8 hours agorootparentObviously, the whole point is to tease all this serious discussion over something that amounts to a toy with almost no practical application. reply teekert 14 hours agoparentprevnext [9 more] [flagged] d-lisp 13 hours agorootparentWhen setting up my DWS on the chain I performed a fresh implementation of the flex spanning system so that sharded stakes were accordingly modulated when dilution factors are on the rise. Retro validators should never rely on the sole consideration of performative liquidity, and that's why in most use-cases, distributive-non-passing underfitted categorization of assets is preferable. Every DNP-uca implementation has proto-failure systems that allow for better mining experiences, in fact every time assets are minted you obtain by-products of the initial dilution thanks to the false commitment that is produced when pseudo-stakers correct the current derivation according to the relative spike index. That's why the tech interested me at first. reply teekert 12 hours agorootparentLLMs at their finest. reply Zetaphor 12 hours agorootparentprevJust because you're unfamiliar with the technology doesn't mean it's nonsense. The failing is yours in actually looking into these things rather than trying to be funny. If you explain to most people how a TLS handshake works it will sound to them as equally nonsensical. This technology is complicated, this article is targeted at an audience that understands the technology, not one that needs a \"My first introduction to distributed computing\" reply teekert 2 hours agorootparentI agree with you, but I was just trying to be funny. reply earnesti 12 hours agorootparentprevTLS handshake actually makes sense for average programmers who understand basic cryptography. Ethereums problem is that it is a badly designed clusterfuck. The newer blockchains will likely take over. reply everfree 10 hours agorootparentEthereum should also make plenty of sense to an average programmer who understands basic cryptography. The concept of a distributed virtual machine shouldn't be difficult to grasp. You could dive deeper into either of the topics you mentioned and start losing people - for example how QUIC carries a TLS handshake, or why enshrined proposer-builder separation is important to Ethereum. All that means is that both protocols hide complexity under the surface. reply Zetaphor 11 hours agorootparentprevThat's a pretty bombastic claim with no supporting evidence. What exactly makes the design a clusterfuck, and what do newer chains do that is a significant improvement? So far all of the alternative chains have been plagued with downtime and centralization of nodes into supernodes (at least in the ones that weren't centralized from the start). reply AlienRobot 11 hours agorootparentprev/r/vxjunkies Wait, this isn't reddit. reply bawolff 13 hours agoprev> Basically, Ethereum is no longer just a financial ecosystem. It's a full-stack replacement for large parts of \"centralized tech\", and even provides some things that centralized tech does not (eg. governance-related applications). And we need to build with this broader ecosystem in mind. I have respect for ethereum. It seems like one of the few cryptocurrency projects actually trying to push those ideas as far as they'll go, instead of just being endless scams. But still, at the end of the day, this feels like endless complexity and in the end we are just back we started: applications we could already do much better using traditional technologies. What even is the elevator pitch use case of all this? reply smoovb 12 hours agoparentMy (non-crypto) company uses USDC daily on L2 Arbitrum for international settlement, and have seen the fees drop to a few cents per transaction with the release of blobs. We have replaced the need for wires/TransferWise/Revolut on several of our routes. reply anonymousDan 12 hours agorootparentAwesome. Can I ask the name of your company? reply defiamazing 11 hours agorootparentprevThere is absolutely no reason for USDC to be on a blockchain other than to interact with DeFi. Once DeFi hype dies USDC will be outcompeted by a centralized solution. It's multisig controlled anyway so it's the same thing. reply everfree 10 hours agorootparentWhy is it that no other solution has been developed in the 40 years of the internet, but you believe now is a particularly ripe time for one to pop up? reply defiamazing 10 hours agorootparentBecause there's not enough demand to justify the regulatory headache for most types of international payments, unless you have the added benefit of interacting with DeFi protocols during a massive shitcoin bubble. reply everfree 9 hours agorootparentSorry, but I thought you said in your last comment that you believe USDC will be outcompeted by a centralized solution. Do you believe that, or do you believe that there is not enough demand to justify the regulatory headache of launching a centralized solution? Those seem to me to be opposing viewpoints. reply defiamazing 9 hours agorootparentYes, because Circle will either start using whitelists at which point it will shrink to the point where competition is trivial or it'll just shut down completely. If for some reason there's massive demand in the next decade for sub-minute international money transfers then surely CashApp will get back on that. There's just not, existing slower solutions work fine in most cases and not enough people need something better. Also important to emphasize, I know I said it'll be outcompeted by a centralized solution. But actually USDC is centralized because it has a multisig, and all of its contracts are 100% upgradeable. So it's like a very inefficient centralized solution that really doesn't belong on a blockchain or at least not a popular one with high fees. But again, DeFi protocols exist, and people want to swap USDC for crypto hedge funds to frontrun. reply arandomusername 10 hours agorootparentprevSending USD across countries, e.g from EU to US, is a LOT easier and faster with USDC than any other solution out there. reply defiamazing 10 hours agorootparentThat's because it has regulatory approval (for now). It's not because of a blockchain. You can start the thought experiment by asking why USDC is on Ethereum and other popular chains rather than own private blockchain. People could make payments faster. Fees would be lower or more likely zero. reply arandomusername 8 hours agorootparentIf it's not because of a blockchain, how come there is no other good way? It's not on it's own private blockchain because then no one would use it. reply defiamazing 5 hours agorootparentNo one would use it because people don't actually want to send money internationally badly enough to create a profit opportunity. They want to interact with DeFi protocols, that's why USDC exists on eth, once the DeFi protocols die then so will USDC. There's no good other way because people don't actually want to send money internationally badly enough to create a profit opportunity. reply threeseed 4 hours agorootparentprevIf my aim is transfer money internationally cheaply and efficiently why do I care what blockchain it uses. Or whether it uses a blockchain at all. reply Destiner 11 hours agoparentprevHere's an elevator pitch. Your twitter/facebook/github account gets banned, what do you do? With farcaster/lens/radicle, it's impossible. reply threeseed 4 hours agorootparentThe problem you have is that 99.999% of people aren't getting banned. And of those remaining the overwhelming majority deserve it. So you're trying to convince people to adopt Etheruem, Blockchain etc to solve a problem no one has. reply Shawnj2 2 hours agorootparentprevActivityPub solves this problem without using crypto reply defiamazing 10 hours agorootparentprevThe blockchain's security depends on native token value and the native token is a memecoin with no backing and if there's a speculative dump then the network has no security, so no not quite impossible. reply DennisP 9 hours agorootparentETH is not a memecoin and it has a real economic model. It's used to pay transaction fees, which are mostly burned. There's a small amount of issuance but most of the time that's less than the burn, so the supply shrinks. You can model it as a company, where fee burn is revenue, issuance is cost, the net is earnings, and earnings are distributed to ETH holders like a company doing stock buybacks. You can calculate a PE ratio; when I checked sometime last year the PE was around 100. reply defiamazing 8 hours agorootparentHaving an economic model doesn't make it not a memecoin. LINK has an economic model and most would agree that there's no reason for it to exist other than to dump on retail. The burn is there in large part to enshrine ETH so that investors can dump on retail, otherwise fees could be paid in other ways. It provides no liquidation or dividend rights. The closest thing to that is rights to MEV, which the base fee controller actively prevents. Value is speculative and if it went to zero then the network would completely die unless it forked to disable the burn. reply DennisP 7 hours agorootparentYou need ETH to pay transaction fees. As long as there's more demand for blockspace than the space available, ETH will have a non-speculative value. The reason for the burn was the 1559 upgrade, which fixed the horrible user experience of guessing what minimum fee level would get your transaction through in a timely manner, and often either overpaying, or underpaying and suffering long delays. If not for the fee burn, the 1559 protocol would be trivial for validators to exploit. reply defiamazing 6 hours agorootparentBasically you're arguing for chartalism, it has value because validators say it's the only thing they'll accept. That can change at any time, it's not the same as a company's stock's value being backed by liquid revenue. Imagine situations where the network just decides they want to accept other tokens at the expense of ETH. Imagine what happens to network security if there's a huge speculative dump - would network hard fork to avoid other protocols getting owned? What happens to ETH then? reply thisgoesnowhere 11 hours agorootparentprevDirect RSS from the source does this as well. What's the difference? reply mattdesl 10 hours agorootparentRSS isn’t a social media protocol with follows, comments, usernames, etc. reply bawolff 10 hours agorootparentprevJoin mastadon? reply kinakomochidayo 13 hours agoparentprev> What even is the elevator pitch use case of all this? > It's a full-stack replacement for large parts of \"centralized tech\" Anti-censorship, permissionless data that lasts longer than centralized companies..? reply leashless 8 hours agoprev7. The blockchain is now at a stage in its development equivalent to where the internet was in or around 1995. The internet was unstoppable in 1995 and blockchain technology is unstoppable now. It will become ubiquitous in all major industrial and financial sectors, simply because it allows for the immutable recording of data, thereby reducing friction in commercial and consumer transactions and obliterating the scope for dispute as to what has occurred. 8. As the Master of the Rolls and Head of Civil Justice in England and Wales, I hold an office that pre-dates modern trade in derivatives and reinsurance, even steam engines, powered flight, and certainly the internet. I am particularly and obviously concerned about the reputation and development of English law and the jurisdiction of England and Wales. 9. Many people do not realise that English law governs trading in €600 trillion of OTC derivatives annually, in €11.6 trillion in metals trading, in £250 billion in M&A deals, and in £80 billion in insurance contracts every year – just to take a few examples. My hope is that English law will prove to be the law of choice for borderless blockchain technology as its take up grows exponentially in the months and years to come. https://www.judiciary.uk/wp-content/uploads/2022/02/Speech-M... Case closed. reply Shawnj2 2 hours agoparentI still don’t understand what a fully realized crypto ecosystem would allow people to do that isn’t already being done well by standard technology. Like it or not, for most people doing most things, the government or large companies are suitable enough of a store of trust which is the problem crypto solves by being decentralized. I think it’s a neat technology for tech people but I still struggle to see why normal people doing most things would want to pay for things with bitcoin. reply ArtTimeInvestor 15 hours agoprevAll this crpyto technology is fascinating. But is it used for anything? I asked this in an Ask HN today, but got no answer so far: https://news.ycombinator.com/item?id=39852389 It looks like not a single HN reader is using blockchain technology for anything. If nobody is using blockchain technology outside of blockchain projects, what are the reasons we expect that some day we will? What could be a near term use case? reply hot_gril 15 hours agoparentIts main purpose is internet currency. The only serious uses surround that via smart contracts, like decentralized exchanges or provably fair gambling (unsavory as that is). Any time someone says \"the currency aspect is separate from blockchain,\" I'd be wary, seeing how the entire point of blockchain is decentralization via proof of work or stake. NFTs can make sense in theory as an alternative to the already-popular video game collectibles, as silly as that premise is, but they never really got traction, and again that's related to currency. There's been a lot of vaporware around things like corporate blockchains to track assets, which don't even make sense in theory. reply dinobones 15 hours agorootparentThe day a network exists where you can reliably send like $0.001 of value with little/no fees is the day the internet changes forever. So many ideas are infeasible right now because CC fees are high, and making any payment is extremely high friction. reply ArtTimeInvestor 15 hours agorootparentEven if you can send $1. Users dislike paying on the web because it is a security risk. Because of this insane system of credit cards, where you give the other party a \"secret\" which enables them to take the money from you. If you could just send the money, the barrier to pay would be 100x lower. Most websites pay the bills via ads. And make less than $0.001 per visitor. If they could sell a monthly membership for a one-time payment of $1, they would have a way better business model. reply hot_gril 14 hours agorootparentThere are traditional ways to send money without giving out a secret, like Apple Pay. But there's plenty of fraud in the other direction, people accepting charges with stolen payment info that end up being reversed. It's always a little the merchant's job to decide whose \"money is no good here,\" and that's because of laws. reply ArtTimeInvestor 14 hours agorootparentPaying via Apple Pay means you have to pay Apple so that Apple will pay the vendor for you. How do you pay Apple without giving them a secret? reply lxgr 14 hours agorootparentNo, that's not how it works at all. Apple is neither in the authorization nor the transaction clearing/settlement flow. > How do you pay Apple without giving them a secret? Credit cards being effectively unrestricted bearer tokens isn't nearly the only way to do payments. For example you could send a signed message to your bank instructing them to pay Apple (in a world in which you'd be paying them; again, Apple Pay is not that). reply hot_gril 14 hours agorootparentprevI think Apple has some special relationship with banks, so it's not this simple. But yeah, one way or another you're trusting Apple Pay, which presumably is more trustworthy than a gas station sale terminal. And if you were signing your own payments, you'd still have to trust your computing device and the bank. reply ArtTimeInvestor 14 hours agorootparentWith crypto, you would not have to trust your computing device nor your bank. You would send $100 to your computing device every now and then. And use that for day to day spendings. If the device turns out to be malicious, you lost only the $100 and stay away from the brand that made the device. A bank would not be involved at all. reply hot_gril 14 hours agorootparentBut you're sending that $100 from another computing device, and if you're not trusting a bank-like entity to hold the cryptocurrency for you, you're responsible for securing all your money on that device without locking yourself out. On the other hand, having some money outside a bank is nice. I've had them freeze my assets before just cuz they felt like it, until I spent a whole day telling them to fix it. reply vernon99 13 hours agorootparentHaving a couple hardware wallets in different places + a paper backup split in a couple pieces gives you enough redundancy not to worry about this. Source: my own experience of close to 10 years now. reply MadnessASAP 10 hours agorootparentUnfortunately I will never be willing to entrust my financial safety solely to an algorithm. An algorithm cannot be reasoned with, it cannot understand that your house burned down and destroyed your ID. It cannot accept liability for it's actions. If I lose my bank card I go to a branch, verify my ID, and get a replacement. The bank is liable if they allow somebody other then me access to my accounts, regardless of how convincing the fraudster might have been. Source, been using banks for 30 years now. reply DennisP 8 hours agorootparentKey redundancy and social recovery are pretty much solved problems in crypto. reply dewey 1 hour agorootparentOn a technical level, not a human level. reply hot_gril 12 hours agorootparentprevSo where do you store the paper? reply troupo 19 minutes agorootparentprev> Users dislike paying on the web because it is a security risk. I wonder how small independent sites like Amazon and eBay exist then if people dislike paying on the web because of the security risk. The reality is that people have literally no problem paying for stuff on the internet. reply cesarb 13 hours agorootparentprev> If you could just send the money, the barrier to pay would be 100x lower. We can already do that here in Brazil: the web site displays a QR code (plus its contents in text form), the user scans the QR code (or copies the text) into their banking app, and confirms it on the app to send the money. I hasn't AFAIK made any meaningful difference for websites. What people dislike isn't the inconvenience of credit cards, it's the inconvenience of having any paywall at all. reply ArtTimeInvestor 13 hours agorootparentWhat if they had $50 stored in a browser plugin and when a website asks for it, they could pay $1 with a simple click? reply brazzy 11 hours agorootparentThat was possible 30 years ago. There have been probably been a dozen schemes that tried something like that over the decades, starting with DigiCash from before the WWW existed. They all failed not because of fees, not because of security concerns, but because even having to think about whether you want to pay for something and how much incurs a mental cost that people avoid. Free beets cheap by a margin that has nothing to do with how cheap or how easy. reply shuntress 11 hours agorootparentprevThis is something that feels pretty lost in most modern crypto discussion. It's evident in literally the first line of the bitcoin whitepaper: \"A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution\" If paying a random person online was as easy as dropping a quarter in a cup the internet could be a very different place. reply hot_gril 11 hours agorootparentI think the part about not going through a financial institution is brought up pretty often, but that line doesn't mention the payment being especially small or quick. reply lawn 13 hours agorootparentprev> The day a network exists where you can reliably send like $0.001 of value with little/no fees is the day the internet changes forever. Why do you set the bar at $0.001? Even sending $1 reliably and with low fees (which has been doable with crypto since its inception) would be revolutionary in my opinion. reply lottin 13 hours agorootparentprevWhy would the internet change forever when people can reliably send $0.001 with no fees? reply giantrobot 13 hours agorootparentThen it could be way shittier because every GET request will be monetized. Also your whole browsing history will be public if you're ever tied to a wallet address. reply dgellow 14 hours agorootparentprevIn Europe sending money from one bank account to another is generally free and often almost instant reply IncreasePosts 13 hours agorootparentAre you talking about SCT Inst? It seems like there are no fees built into the protocol itself, but your bank can still charge you to use the service, and it seems many banks charge between 1 and 7 euros: (pdf reference) https://www.beuc.eu/sites/default/files/publications/beuc-x-... reply dgellow 13 hours agorootparentI didn’t mean a specific protocol, just based on my experience. But where do you see 7€ in this document? I see lot of banks offering zero or below 1€ fees. The highest I see is Novo Banco at 5.20€ (page 18). reply ArtTimeInvestor 14 hours agorootparentprevThats news to me. Can you link to a page of a bank in Europe where they state that they offer free instant money transfers? reply dgellow 13 hours agorootparentIt’s pretty simple to see. First result I found: https://moneytransfers.com/bank-transfers/sepa-transfers For example from Germany to Austria, sending 1200€, I see multiple providers with no fees for quick transfers. reply ArtTimeInvestor 13 hours agorootparentI dont't see instant transfers on that page. It says \"within 24 hours\" and sometimes even \"within a week\". reply dgellow 12 hours agorootparentYou can change filters… You can also check https://www.europeanpaymentscouncil.eu/news-insights/videos/... reply IanCal 12 hours agorootparentprevThe UK has \"faster payments\" which is usually instant (sometimes held up for fraud checks). I'm not aware of any bank that charges for this. reply troupo 11 hours agorootparentprevBesides SEPA which mandated the upper ceiling and an upcoming regulation which forbids banks from de-prioritising payments to/from other banks (can't remember what it's called now) many European countries have had instant bank transfers locally. For example, Swish in Sweden: https://www.swish.nu/about-swish reply brazzy 11 hours agorootparentprev> The day a network exists where you can reliably send like $0.001 of value with little/no fees is the day the internet changes forever. It will change absolutely nothing whatsoever. > So many ideas are infeasible right now because CC fees are high, and making any payment is extremely high friction. Making payments will always be, is inherently high friction, and reducing the amount does nothing below a threshold that is much, much higher than $0.001. There have been lots and lots of micropayment schemes, and they have all failed because the very fact that there is a payment already introduces mental friction that's effectively higher than current CC fees. Any idea that is infeasible because there is no way to reliably send $0.001 is in fact easily feasible today by monetizing it some other way, usually via ads. Lower fees are only relevant for high-volume fully automated transactions with a substantial financial incentive behind them, and those can already be done basically for zero marginal cost, see HFT. The only micropayments that people are willing to engage in individually is when they involve addiction, and that as well can and is already done in gambling apps masquerading as games. reply root_axis 13 hours agorootparentprevNFTs make absolutely no sense for video games collectables. As it is, video game collectables work just fine, NFTs add nothing except cost and complexity. reply hot_gril 12 hours agorootparentIf you want there to be a marketplace for your collectibles, NFTs are the most open way of doing that, and a lot is prebuilt. reply MichaelZuo 11 hours agorootparentCounter-strike had a market for collectibles well before? reply hot_gril 11 hours agorootparentIt took work by a large parent company. And I don't know how third-party websites can trade those, but it must mean either Valve is managing an API or people are doing something hacky to work around that. reply valzam 11 hours agorootparentThey can't. There are third party websites but there is no way for them to initiate trades. They work around this bysome crazy peer-to-peer trust-me-bro scheme. reply hot_gril 10 hours agorootparentThat's what I was expecting. reply troupo 11 hours agorootparentprevAnd the reason for that is simple: game collectibles literally cannot work in any game on any platform except the one they were designed for. There's a reason you can't bring your Fortnite skin into a Lord of the Rings game, and it has very little to do with \"central companies\" and \"APIs\" reply hot_gril 11 hours agorootparentInterop with other games isn't the issue here. reply MichaelZuo 10 hours agorootparentSo then what is the issue? reply hot_gril 10 hours agorootparentIt's what I said above, it's a lot of work for a new game to create/maintain its own collectibles marketplace that people can trust, and even a well-established game like Counterstrike doesn't properly support third-party trades. Ethereum provides all that out of the box with NFTs. There's also the issue that Valve controls all the assets, but that's mostly a moot point because they control the game anyway. I guess someone could honor NFT skins in a separate game if they really wanted, but that's getting theoretical. reply lern_too_spel 8 hours agorootparentThat's what SAAS is for. Cheaper and easier than building NFTs on a blockchain and integrating them into your game. reply ArtTimeInvestor 15 hours agorootparentprevAre you using it as internet currency? I don't know anyone who paid anything with it in the last 12 months. reply vernon99 13 hours agorootparentI’ve been paying multiple people and teams remotely via btc in the past years. Even if you can send a wire, sometimes it can be cheaper/easier to send crypto. But in many cases it’s not even possible to send large amounts of money without incurring massive fees (international paypal, western union, etc). Moved hundeds of thousands of dollars this way by now for purely legal economical reasons, helping a bunch of people make money they would not make otherwise. Edit: relatedly, not everybody wants to pay their local taxes (and who am I to judge people in various life situations?). This itself is a _massive_ saver for the folks. Send somebody $5k usd a couple times and their bank will start asking complicated questions. reply ArtTimeInvestor 13 hours agorootparentAnd how do you put the crypto payments into your tax reports? reply bawolff 13 hours agorootparentSeems pretty easy. My country's tax forms dont distinguish between how you got paid, just that you got paid. Gov doesn't care if it was through a bank, in gold bars, bitcoin, etc (capital gains they care more about of course) reply doublepg23 15 hours agorootparentprevI’m using the Bitcoin Lightning Network to support podcasts every week or so. https://www.jupiterbroadcasting.com/boost/ reply ArtTimeInvestor 15 hours agorootparentInteresting. Reading through the page, that sounds super complicated though. Couldn't the podcasts simply put a lightning invoice (Which is just a string of text I guess?) on their website with a text like \"Support us via Lightning: 1f73ac220b9...\"? reply lawn 13 hours agorootparentWith a regular cryptocurrency they could just post an address or QR code and anyone can send it using a wallet at any time (no need for them to be online or anything). reply maxcoder4 15 hours agorootparentprevI use it everywhere where it's an option (so not very often, let's say once a month). I also only use privacy services (vpn for example) where you can pay using cryptocurrency, otherwise what's the point reply ArtTimeInvestor 15 hours agorootparentWhat are some other examples, except for a VPN where you use crypto to pay? And how is the situation around the world - are retailers who offer digital goods/services allowed to accept crypto as payments? reply hot_gril 14 hours agorootparentThere are hardly any retailers accepting it in the US. Wonder how it is in El Salvador, since they made BTC legal tender. reply vernon99 13 hours agorootparentprevIn most of the places it’s trivial to exchange crypto for local currency in p2p fashion, often for cash. reply teh_infallible 3 hours agorootparentprevThere was a sketchy looking file sharing website where someone had posted some incredibly hard to find audio tracks that I really wanted, but the website required a subscription. Paying with a cc meant automatically-recurring payments, but I paid with bitcoin, got my files, and knew the website couldn’t get any money from me after that. reply hot_gril 15 hours agorootparentprevYes reply hem777 4 hours agoparentprevMy non-techie brother has been staking his 1 ETH he bought couple of years ago and has earned today, in his words, “slightly more than from my insurance savings account in the past 10 years”. I think that’s a really nice use case. reply orthecreedence 15 hours agoparentprevI think it could be used for some kind of permissioned, collectively crowdsourced database that's (mostly) free from the control of a single group of administrators/gatekeepers. I guess kind of like a decentralized wiki. In my view, blockchains shine where you need auditable global state, bonus points if you don't want central control in your operations (obviously this then kicks the can to the core devs). This use-case is fairly miniscule for most applications, though. As far as currency, I think they also have their use-cases as well but most people don't want a global audit trail of all their purchases. Things like Monero and Zcash shine here. The value fluctuations are obnoxious, though. I'm saying this as a big blockchain skeptic. I think most of the things people use them for are silly. reply coffeebeqn 12 hours agorootparentShared append only, very slow database. It’s a very specific setup but maybe there’s some scenario for it. reply everfree 10 hours agorootparentI think a shared, \"slow\" database could be useful for property deeds. Give the state admin access to override the typical transfer process in case of theft, and then you're left with a 24/7 accessible public database of property deeds, where the current owner and full history of a deed (transfers, liens, easements) can be accessed and verified by any joe with a computer. It could be useful for professional licenses, too. Everyone could have a verifiable history of someone's professional license - when it was issued, when it was revoked, again mathematically verifiable. You could be sure that someone's record was never changed or deleted without leaving an audit trail. Though to be fair, the important part of this is the chain of cryptographically signed and timestamped events. It could work without strictly being a blockchain. You could imagine something that behaves more like a git repository with a flat file database in it. reply pcthrowaway 15 hours agoparentprevWouldn't any company using blockchain technology be a blockchain project? reply stnmtn 15 hours agorootparentSure, but if every blockchain project is just \"building something for the blockchain\" then where is the actual value? reply pcthrowaway 14 hours agorootparentYou seem to be drawing a distinction here between companies that are building something for blockchain vs building something for people. Alright, I'll bite, here are some projects that use blockchain for things besides trading tokens or improving blockchain technology: - https://sarcophagus.io/ - https://www.gitcoin.co/ - https://docs.kleros.io/ There's many more. Many don't have a lot of adoption, and I don't know if they will. But at the very least it's often interesting to see how traditional systems are reimagined in order to enable decentralized, trustless, computer programs (with humans interacting at the perimeter) to fulfill roles which would traditionally be filled by centralized, trusted intermediaries (often humans). If for no other reason than getting a front seat as many of them fall apart spectacularly but also because it's intellectually fascinating to see problems approached in an inverted manner. reply troupo 11 hours agorootparent> But at the very least it's often interesting to see how traditional systems are reimagined in order to enable decentralized, trustless, computer programs They are not re-imagined. It's a combination of a still on-ongoing gold rush (well, the end tail of it) and people pretending there are purely technical solutions to all problems. Almost every single of those \"interesting re-imagining\" projects rather quickly rediscovers why traditional systems are the way they are, and end up being shittier versions of those. reply pcthrowaway 1 hour agorootparent> well, the end tail of it Whatever your feelings on the impact of the technology are, you can't possibly know this > Almost every single of those \"interesting re-imagining\" projects rather quickly rediscovers why traditional systems are the way they are, and end up being shittier versions of those. I pretty much agree with this, though I'd suggest \"most\" rather than \"almost every\". Most scientific studies may fail to support their hypothesis also, that doesn't make them uninteresting. reply troupo 16 minutes agorootparent> I pretty much agree with this, though I'd suggest \"most\" rather than \"almost every\". The absolute vast majority (outside of scams, obviously). > Most scientific studies may fail to support their hypothesis also, that doesn't make them uninteresting. Scientific studies don't pretend to be re-imagining anything. reply hot_gril 15 hours agorootparentprevMost of those are scams. reply tdudhhu 14 hours agoparentprevSome days ago ICP showed it can run ML on a blockchain. While this is nice and does show that distributed computing is a real possibility I also don't think that anyone is going to switch from Amazon/Azure to ICP any time soon. But I must say the idea is really nice. It's very easy to develop Actor model based software and deploy it on ICP. reply ShamelessC 13 hours agorootparent> ML on a blockchain I would actually love it if you had a link with more info on that. Don't take this the wrong way, but my first guess would be that that basically isn't true; either it's not actually machine learning (as is understood today) or it isn't actually a blockchain but rather normal distributed computing being \"verified\" via blockchain somehow? Would love to be proven wrong though. reply dlubarov 12 hours agorootparentThere are basically two approaches to on-chain inference: consensus-based approaches (several parties run inference and give a claimed result), and zkML (one party runs inference and proves the result cryptographically). zkML can be done using general-purpose ZK libraries (since they support arbitrary computations), or there are some specialized tools for proving ML inference, such as https://github.com/ddkang/zkml. It's currently pretty expensive to prove huge models like LLMs, but there's a lot of work being done to make it more practical. reply tdudhhu 12 hours agorootparentprevhttps://internetcomputer.org/ A YT video about this: https://youtu.be/wk3FxuA5DKs I am still very sceptical about this because it looks very slow, but it seems to work. reply scyclow 12 hours agoparentprevPeople love shitting on NFTs, but there's still a really good art scene based on NFTs and smart contracts. And once you have digital objects that you actually care about, all the web3 infrastructure is surprisingly useful. reply akira2501 11 hours agorootparent> there's still a really good art scene based on NFTs Is that a \"good art\" scene, or a \"good\" art scene? reply darby_eight 9 hours agorootparentprev> there's still a really good art scene based on NFTs and smart contracts I'm still not quite getting the idea here—these assets only really \"exist\" in web3 apps, right? reply tdudhhu 2 hours agorootparentYes, they can prove ownership of an art peace but can not prove the art peace even exists. reply hanniabu 10 hours agoparentprevHere's a bunch of usecases I put together a while ago https://gist.github.com/hanniabu/32b0f933618a3229efe3fbc01cb... reply valcron1000 13 hours agoparentprev> It looks like not a single HN reader is using blockchain technology for anything. > If nobody is using blockchain technology outside of blockchain projects HN is very adverse to the blockchain space. This is not the best place to look for people using the technology since 9/10 times you would get downvoted to oblivion reply toenail 12 hours agoparentprev> But is it used for anything? What people like you usually miss.. hodling bitcoin IS one of its uses, store of value. > It looks like not a single HN reader is using blockchain technology for anything. You haven't missed anything, that's why we say bitcoin, not blockchain. reply willmadden 10 hours agoparentprevWe use it every day for cross-border payments. reply yieldcrv 15 hours agoparentpreva better question is to look at how people use it, the frictions they encounter, and who works on solving those frictions just saying “speculation” as if thats not a use case misses that “financial services” are our biggest industry on the planet and thats mirrored in the blockchain space, many people solve frictions and compete with each other. it willfully ignores that all currencies are 99% held as stores of value and the M0 money supply is a tiny fraction used as cash and for merchant transactions, a distribution also mirrored in the blockchain space but ignorantly used to discredit it despite ironically showing how well it works as a parallel economy. additionally due to the structure of blockchains as a pay to write database, most use cases that aren't related to stores of value or trading are intrinsically tied to something financial which makes the standard impossible reply FactKnower69 15 hours agorootparent>just saying “speculation” as if thats not a use case misses that “financial services” are our biggest industry on the planet and thats mirrored in the blockchain space This is such a great comparison! Crypto and \"financial services\" are both a massive waste of labor that produces zero material wealth and mainly exist to facilitate money laundering and further upward siphoning of wealth. This is why Janet Yellen is currently throwing a tantrum that those big meanies in China aren't playing fair by using their labor to actually manufacture things instead of shuffle fake money back and forth between different buckets until more money appears out of thin air: https://www.reuters.com/business/energy/yellen-intends-warn-... reply mand1575 11 hours agorootparentprevGiven that we are now entering another crypto hype cycle and blockchain technology, discussions often veer towards crypto and the allure of embedded tokens. I’m going to stick to the realty and opportunity: utilizing blockchain in fixed income finance. Having spent two decades navigating the complexities of Wall Street, I know the critical problem plaguing the fixed income market: the overwhelming amount of data generated during the origination of debt instruments and the subsequent challenges in reconciliation during clearing and settlement. Night cycles, calling Bloomberg to fix security master. Calling DTCC to settle trades. Blockchain is the best technology to solve this. Only if applied correctly. Otherwise, it’s a waste. We started with a fundamental goal: to debunk the myths and misconceptions surrounding blockchain in the securities space. Despite the pervasive FUD propagated by the media, we have now proved to regulators that securities originated on blockchain are indeed securities – not merely speculative digital assets. At its core, we are looking to address the root cause of friction in fixed income trading: the lack of direct origination and data quality across market participants. By leveraging a permissioned network, we have proved by recording of municipal loans and securities on our blockchain. While it may not be the flashy product that garners headlines, this milestone marks a significant step forward. We also trained all of FINRA’s fixed income examiners…. Our next step is to bring brokered CDs, directly to the investors, giving them access to negotiate with the issuers. From there the goal is to extend to real-time clearing and settlement, streamlining processes and enhancing efficiency across the fixed income ecosystem. Here's how a trade moves through our system in current state…it’s a mental journey. https://www.chicagofed.org/markets/view-lasalle-street/us-re... reply pa7x1 2 hours agorootparentIn case you are curious BlackRock launched last week a money market fund on Ethereum. You can see it onchain here: https://etherscan.io/token/0x7712c34205737192402172409a8f7cc... And here the press release: https://securitize.io/learn/press/blackrock-launches-first-t... reply troupo 11 hours agorootparentprev> the root cause of friction in fixed income trading: the lack of direct origination and data quality across market participants. By leveraging a permissioned network, Blockchain has nothing to do with \"data quality across market participants\". Bad data entered into blockchain remains bad data. reply mand1575 7 hours agorootparenthence origination - bad data can be fixed. try calling 30 different vendors and rely on downloading the file to run the M2M night-cycle reply wredcoll 15 hours agoparentprevLiterally no. No one is using it and no one has come up with a use. reply kinakomochidayo 13 hours agorootparentThat's odd, Blackrock just created the BUIDL tokenized fund on Ethereum. Seems like there's definitely a use for it. https://securitize.io/learn/press/blackrock-launches-first-t... reply imchillyb 15 hours agoparentprevBanks have been using the Ethereum blockchain for behind the scenes bad debt transfers for about seven years now. Banks don’t want to deal with treasury departments nor do the banks want to be beholden to federal governments regarding prime rates. Ethereum allows banks to circumvent these types of issues because rates are dictated by banks not by governments and their treasury departments. Crypto currency is coming soon. It’s only a matter of time and validating processes now. reply ArtTimeInvestor 15 hours agorootparentHow can a bank transfer debt via Ethereum? Isn't \"debt\" a contract between the bank and a user? How do you transfer that and to whom? reply maxcoder4 15 hours agorootparentprevThat sounds suspicious. Maybe a few years back out would work, but now cryptocurrency is pretty regulated. And at the same time it's not battle tested. Any CFO who signs of on something like that risks shareholder fury when anything goes wrong. reply schmichael 12 hours agorootparentprevCitation needed (from a non-crypto-booster source) reply lottin 13 hours agorootparentprevWhat? reply ForHackernews 12 hours agoparentprev> What could be a near term use case? Ransomware, evading currency controls, funding North Korea. reply 110 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Ethereum ecosystem is evolving with proto-danksharding and blob usage reducing transaction fees and activating a fee market.",
      "Emphasis is now on incremental enhancements, layer 2 solutions, and data availability sampling to boost blob capacity for scalability and efficiency.",
      "The transition signifies a move towards user-friendly apps, sustainable and scalable solutions, and advanced tech like ZK-SNARKs, showcasing Ethereum's progress in decentralized governance and innovation."
    ],
    "commentSummary": [
      "The discussion delves into the potential of Ethereum and Monero in the cryptocurrency sphere, with Monero addressing real-world issues and Ethereum showcasing innovative applications.",
      "Various aspects like decentralization, governance, transaction fees, proof-of-stake, and distribution of Ethereum's ethers are covered, along with comparisons between Bitcoin and Ethereum, smart contracts, payment methods, privacy features, USDT, NFTs, blockchain security, digital cash, and NFT application in gaming.",
      "The conversation explores differing viewpoints on the usefulness, effectiveness, and advantages of cryptocurrency and blockchain technology across different sectors, including finance, online payments, and the skepticism towards blockchain technology's reliability."
    ],
    "points": 243,
    "commentCount": 373,
    "retryCount": 0,
    "time": 1711640466
  },
  {
    "id": 39849727,
    "title": "Intel's $152B Stock Buybacks vs. $8B Subsidy",
    "originLink": "https://www.commondreams.org/opinion/intel-subsidy-chips-act-stock-buyback",
    "originBody": "An illustration of INTEL and the US dollar is being displayed in Suqian City, Jiangsu Province, China, on February 17, 2024. The Biden administration is currently negotiating to provide more than $10 billion in subsidies to Intel Corp., which may include loans and direct grants. (Photo Illustration by Costfoto/NurPhoto via Getty Images) Intel Brags of $152 Billion in Stock Buybacks Over Last 35 Years. So Why Does It Need an $8 Billion Subsidy? What’s to stop the chip-making giant from shoveling taxpayer grants into more stock buybacks?",
    "commentLink": "https://news.ycombinator.com/item?id=39849727",
    "commentBody": "Intel Brags of $152B in Stock Buybacks. Why Does It Need an $8B Subsidy? (commondreams.org)229 points by robtherobber 22 hours agohidepastfavorite281 comments sudhirj 21 hours agoIntel didn't get a subsidy because they're poor, the subsidy exists because the US Government wants the company to do something (setup a fab on US soil) that is not necessarily in the shareholders best interest (cheaper to set up a fab elsewhere). The subsidy is the difference in both parties judge to be the cost of doing the expensive thing (that matches US strategic interests) vs the cheaper thing. reply op00to 20 hours agoparentPerhaps the government should simply nationalize Intel if they continue to do stock buybacks. There’s more knobs to turn than the free money faucet. reply ChadNauseam 20 hours agorootparentAre you suggesting the government buy Intel, or that they steal it from its current owners? You might have different opinions than I do about the morality of such a thing, but either way it would be disastrous as it would disincentivize all investment in things the US can steal. reply mattalex 20 hours agorootparentThe US could have required stock in Intel instead of taking nothing: Intel gets money, US gets influence over Intel. Just like it works everywhere else. reply bryanlarsen 19 hours agorootparentThere are 3 good ways to give money to the private sector: as a purchase order, in exchange for equity, or as an interest bearing loan. If the company won't accept money in one of those 3 forms they probably don't need it. reply mdasen 19 hours agorootparentprevWhen giving a company like Intel money, you could give that in exchange for part of the company or for the company to do something for you. For example, the US could give Intel $8B for about 4% of Intel (at today's market price). However, that wouldn't get them the new US chip fab that they want. It would get them 4% ownership of Intel. Another example, the US could give Intel money to build them a supercomputer. The US would get a supercomputer, but it wouldn't get any ownership of Intel. When I buy Intel processors, I get a product, but no ownership of the company. In this case, the US wants to buy a product: a US based fab. You might say \"but the fab benefits Intel.\" You're totally right, but when I buy Intel processors it gives Intel capital they'll use for their benefit as well. The real question is whether the US is overpaying for this fab or if the fab is even worth it. Could the US have gotten the product it wants cheaper? Is having new US based fabs worth paying for? I think the answer to the latter is a resounding \"yes\" for strategic reasons. Tens of billions is a tiny drop in the bucket to help ensure something bad doesn't happen to one of the most important industries to US prosperity. We spend $850B/year on the military to try to ensure continued US security and prosperity. Giving Intel $8B is probably a bargain by comparison. Likewise, if you hate that Intel is being given $8B, you'll really hate how much Boeing, Lockheed, Raytheon, Northrop, and General Dynamics get from the government. Sure, the US could have required Intel stock as part of the deal, but depending on the amount of stock, Intel would have likely rejected it. Should the US have offered $11-12B for 2% of Intel plus a US fab? If that's the case, why doesn't the US government simply buy stock in Intel today? If your argument is that the US should end up with 20% of Intel for that cash, Intel would reject it. That's giving Intel a tiny fraction of what their stock is worth - 20% of Intel is worth $38B. If the government wanted to nationalize Intel, it'd probably cost them $210-250B. The government isn't just allowed to take something without just compensation. While Intel's market price is $188B, usually buying a whole company involves having to pay a premium over that. The US has taken ownership stakes in companies in some scenarios. For example, the bank \"bailouts\" gave the US preferred stock with a dividend rate of 5% that would climb to 9% from 2008-2013. The government also got warrants to purchase common stock at a very low price. Recipients generally repaid what they were given and the government made billions off the stock warrants. In the case of the bank \"bailouts\", the government was giving the banks money to help save the banks and demanded ownership in return. By contrast, Intel doesn't need help. The US government wants to get Intel to do something; the government wants to pay Intel to make them a product. Maybe the government could have gotten a better deal than $8B. However, given that few companies could legitimately create modern fabs and given that even companies like TSMC have been having difficulty at creating fabs in the US, $8B doesn't seem like a crazy amount of money to be offering as a carrot. It looks like the US is also spending $6B on Samsung and $5B on TSMC to get them to build fabs here. If the US wanted ownership and a new fab, it would cost more than $8B. If the US wanted a new fab plus 10% of Intel, it'd likely cost them $25-30B. reply Wytwwww 19 hours agorootparentprev> Just like it works everywhere else. That's certainly not the case, though. reply paulmd 3 hours agorootparentprevThe money isn’t in return for some stake in intel though. The money is in return for doing something sub-optimal to the interests of the shareholder. It’s compensation in return for a taking. If you take without giving something back, that’s an actual taking and that’s illegal outside specific circumstances. reply refurb 18 hours agorootparentprevBuying $8B in equity of a $160B company might get you a board seat (one of 8) but it’s not going to give you control over the company. reply transcriptase 20 hours agorootparentprevThis thread really brought an alarming number of tankies out of the HN woodwork. Not something you typically see on here! reply pjc50 20 hours agorootparentThere's always been people with really Out There political opinions On Here, but usually they're on the more libertarian side. It seems that mentioning China makes people want to beat them by being more Maoist. I don't know whether this is an effect of outflux from Twitter or some other social media phenomenon. reply Arthur_ODC 19 hours agorootparentprevWow, people are now throwing around the term \"tankie\" when simply discussing nationalization? That's crazy. That term is becoming as useless as calling someone a fascist or woke. reply troyvit 18 hours agorootparentDang and I just learned the word too. reply tasuki 19 hours agorootparentprevIf they were to buy Intel for a fair price, why should that disincentivize investment? reply Teever 20 hours agorootparentprevEminent domain is not theft. It is a legally defined practice in most legal systems. reply justinclift 19 hours agorootparentWell, it's still theft of the \"depriving the owners of their belongings\" variety. It's just that the groups that can do eminent domain tend to both have guns and be in charge of the local legal system. Which means they get to define the rules and make up their own name for when its them doing the thieving. ;) reply Teever 17 hours agorootparentBut you understand that as it is an aspect of the legal system, and one that is usually defined higher in the legal hierarchy that it can't be a thing that is defined later, right? You shouldn't misuse words like you're intentionally doing. Why not go all the way and call it rape or something. reply pjc50 20 hours agorootparentprevI'm sure the US taxpayer would be very happy to take one hundred and eighty five billion dollars and give it to the investors instead. reply jsight 20 hours agorootparentImagine Intel running at the full speed and efficiency of the US government. reply Wytwwww 19 hours agorootparentprevBut now there is chance that Intel will at some point overtake TSMC again and most(?)/much of their production capacity would be in the US? That chance would no longer exist if the government nationalized Intel.. so what would be the point? reply fragmede 20 hours agoparentprevBut were there strings attached that make Intel actually do that with this money, unlike last time? reply Workaccount2 20 hours agorootparentThere are a lot of strings. Ironically I am questioning where or not I should sell my shares because of those strings. Some companies didn't take the CHIPS act money because of them too. reply sudhirj 20 hours agorootparentprevNot sure why what would matter. One party (US taxpayers) is paying another party (Intel shareholders) to do something specific. What recipients do with the money is their own problem. EDIT: Sorry, read this as strings attached to what Intel could do with the money. I would assume the subsidy is contingent on Intel actually setting up the fab and some output numbers, seems idiotic to do it any other way. Don't think this was a bailout or handout at all. I haven't seen the agreement though. reply buran77 20 hours agorootparentPeople generally see subsidies given to companies as a contract. Subsidies in general aren't a contract. People don't have to \"do their part\" when they benefit from a subsidy (like vote for a specific party because they subsidized the price of gas), and usually neither do companies. reply javagram 20 hours agorootparent> People don't have to \"do their part\" when they benefit from a subsidy (like vote for a specific party because they subsidized the price of gas), and usually neither do companies. This is typically false, usually the subsidies are in the form of tax credits that are only awarded once you perform the desired action, or at least have to be paid back if you fail to do so. They don’t just cut a check and wash their hands. This is true for individuals as well as corporations. When you do your taxes this year, take a look at credits like the renewable energy credit. You have to actually purchase insulation or solar panels to be eligible for the credit. reply pwillia7 21 hours agoparentprevYeah I was going to say this is the vig for not going with China for money because greed is the only virtue in the gilded age II reply mhb 20 hours agoparentprevIf it's such an important objective for the US government, perhaps they shouldn't muddle it up with DEI bullshit: https://thehill.com/opinion/4517470-dei-killed-the-chips-act... reply aceon48 21 hours agoparentprevGiven the criticality to National security interests, perhaps the US government should have brought the stick with heavy taxes / penalties for not having the US Based plant instead of the carrot of more corporate subsidies. This is still a US based company, with US leadership reply sschueller 21 hours agorootparentThe US Government could pass a new ruling requiring all chips in all military hardware (or even all hardware used by any government agency) down to the smallest IoT shit needs to be made in the US by a US firm. I doubt Intel would need any money or other incentive if the orders start coming in. reply Workaccount2 20 hours agorootparentThis is basically already how it is. This is also why nobody ever wants to cut the DoD budget, it's basically the backbone of American manufacturing for everything. All the stuff our company makes for the military needs to be US made, despite us being able to get the same stuff from China for 1/10 the cost. It's also a kick-your-door-down-and-go-prison offense if you try and skirt this. My company knows that first hand (unintentional, but the DoD doesn't care) reply lumb63 20 hours agorootparentprevThe supply chain for military hardware is already under heavy scrutiny. I don’t think the CHIPS Act is about security; it’s about onshoring production so the US can avoid caring about Taiwan. reply andsoitis 20 hours agorootparentprevIt is highly likely that that was considered but discounted for being suboptimal. reply wakawaka28 20 hours agorootparentprevThe military may not be a large enough customer to make such demands. Or perhaps a handful of companies would do it at 100x the cost of similar civilian products. It would turn into another $10k toilet seat fiasco. reply YetAnotherNick 21 hours agorootparentprevGood way to force Intel/all remaining chipmakers to move its headquarters to other country. reply rob74 21 hours agorootparentprev...and then stop buying military hardware for 5+ years, until these US-made chips are available? reply willcipriano 20 hours agorootparentPurchase orders like this happen years out. Before the deliveries dry up, Intel's cash flow will dip and investors will riot until Intel is ready to do business in the US. reply _giorgio_ 21 hours agorootparentprevHere's the crazy one. Punishing a company just because it's american. reply harimau777 21 hours agorootparentAlternative take: Punishing a company because it's selling out Americans in favor of cheap labor. reply addicted 21 hours agorootparentThis is a myth. Cheap labor is a benefit but not the primary reason companies are manufacturing in the U.S. today. Look at TSMC. It started setting up US operations years ago and is expecting to complete many years from now. OTOH they started setting up in Japan about a year or so ago and are already cranking out chips. reply roody15 20 hours agorootparenthttps://www.bnnbloomberg.ca/tsmc-s-second-fab-in-arizona-del... TSMC is looking to bail completely on the second fab / even intel is now looking at delaying. The problem we are running into is a lot of DEI language was included in the chips act which is making it hard for TSMC (and Intel) to comply. This is not a good PR move to say this outright so they will just give more generic \"labor\" shortages etc as the official reason. reply fancyfredbot 20 hours agorootparentprevThe Japanese plant is less ambitious, using an older process on a smaller scale. The fact the Japanese plant was finished first says little about manufacturing in the US vs Japan. reply api 21 hours agorootparentprevI think you meant “aren’t manufacturing” and you are correct. It’s not cheap labor, except for the lowest end manufacturing. It’s that you can’t build anything in America anymore. The government needs to address that instead of subsidizing one off efforts. reply helsinkiandrew 20 hours agorootparentprev> it's selling out Americans in favor of cheap labor. Perhaps American workers. But an alternate take is that American consumers got cheaper chips and PCs - which resulted in more being sold, more companies and people using them, greater efficiency and new ideas and perhaps a more productive economy. It will be interesting in 5-10 years if the US needs to tax/block possibly cheaper and better components built outside the US being sold reply 34679 20 hours agorootparentIntel, like any other succesful company, prices its goods based on what the market will pay, not what it costs to make. Lower costs does not mean lower prices for customers, it means more profits for Intel. reply helsinkiandrew 19 hours agorootparent> Intel, like any other succesful company, prices its goods based on what the market will pay, not what it costs to make That may be true for Intel's CPUs but when products aren't produced by monopolies, those that have the cheapest costs and are in competition with others, often lower their prices to compete where the competitor can't. For example: AMD, graphics and motherboard parts reply prerok 14 hours agorootparentWell, I take it that it's always true and is a good lesson for anyone trying to set the price for their own product (like a hacked together side project one of us might be working on :) ). My understanding is that the price should never be set based on production cost but on the value it brings to the customer. Thereby, a simple program you or I could hack together in a month, might have a cost of 10k in labor only cost, but if it would save the customer millions each year, they would pay a million for it. So, you set the cost based on how much they are willing to pay, based on how much they would profit/save. If another competitor offers a similar solution, you just undercut them by 10%, or invest another 10k for superior features. reply amarcheschi 19 hours agorootparentprevFurthermore, up until at least a few years ago (i don't know how it is now) intel chips were more expensive than amd's, especially on server side, even accounting on performance/watt and intel adopted practices such as locking mobo to just one chipset and things like that. the situation might be different now tho reply gruez 21 hours agorootparentprevYeah I'm sure that's going to cause investors/other companies to think that the US is a good place to set up shop and/or make further investments. reply belorn 20 hours agorootparentI believe that $77B as a fairly good cause for investors/other companies to set up shop and make investment into the US semiconductors market. According to random market statistic site, it is also currently growing by 10% each year. Is that market so poor that subsidies really is needed on the basis of profitability? reply gruez 19 hours agorootparentA $77B market that's growing by 10% each year doesn't mean much when the government turns against you demands you do a bunch of expensive investments for nationalist reasons. See also: all the investors fleeing china because they were spooked by the tech crackdown/covid lockdowns. \"Punishing a company because it's selling out Americans in favor of cheap labor\" is basically the same thing but with a different coat of paint. reply owisd 21 hours agorootparentprevIntel is a product of Shockley, which was a product of Bell Labs, which was a product of “punishing” AT&T for “being American”. AT&T would have zealously guarded the transistor patent and never have licenced it out to Motorola, TI, etc. if they only cared about maximising shareholder value. reply skywal_l 21 hours agorootparentprevWouldn't be easier for the US government to buy Intel shares rather than subsidies it? It should actually be mandatory for the government to own part of a company that is so critical to national and security interest. reply DonnyV 21 hours agorootparentprevWe're always bending over backwards for a handful of companies instead of promoting a healthy market. We should of created a race with multiple companies to build the best chip factories. reply gruez 21 hours agorootparent> We should of created a race with multiple companies to build the best chip factories. That's insanely expensive. Today the only companies that make leading edge chips are TSMC, Samsung, and Intel. Global Foundries (headquartered in US) dropped out a few years ago because it was too expensive. How on earth are you going to fund \"a race with multiple companies to build the best chip factories\"? It's going to cost multiples of whatever the intel subsidy is. reply sgarland 20 hours agorootparentMultiples of $8 billion? Oh no, where would we find the money? If this is truly a national security issue, perhaps some of the DoD’s ~$150 billion R&D budget could go towards it. reply prerok 13 hours agorootparentTo be fair: to build whole companies would not cost multiples of 8B but multiples of 150B. And if you really wanted to cover all \"critical\" industries, even this would be a drop (or maybe a puddle) in the ocean. reply prerok 13 hours agorootparentprevnit: should of -> should have reply specialist 19 hours agorootparentprevAccelerated consolidation was policy for decades. Clinton Admin's dept of defence pushed it really hard, esp for defense contractors. To reduce costs, make our nat'l champions more competitive internationally, make our hair more luxuriant, and cure rickets. Because reasons. Now the pendullum might finally be swinging back towards pro-competition and healthy open markets. reply willcipriano 21 hours agorootparentprevYour brother's idiot son doesn't get a no show job if you use the stick. reply taneq 21 hours agoparentprevIdeally this kind of subsidy would be paid any time the expected return on investment for the government was better than breaking even. It’s not about making sure only the most deserving get help, it’s about making sure everyone (including the most deserving) gets more. reply nabla9 21 hours agorootparentIt's a strategic investment for national security with net negative value. The government does not want return of investment. The government wants to lose money so that national security gets better. reply kiba 20 hours agorootparentMaybe or maybe not in term of net tax revenue, but it's certainly an investment with an expectation of the preferred outcome of national security, with some portion of the subsidy maybe being returned as taxes of various kinds. reply User23 21 hours agorootparentprevInvesting money is different when you can create it from nothing. Needless to say the intuitions one develops from investing while not being able to create money at will are not entirely applicable. reply taneq 18 hours agorootparentprevI think we're using different definitions. A \"strategic investment for national security\" only has \"net negative value\" is the overall expected outcome is negative. War is pretty expensive so it's worth spending a bit of money to avoid it, or at least sway the outcome. The government doesn't want a dollar ROI in the sense of increased revenues because it defines the dollar. What happens to the local currency is just one factor in the overall considerations. reply pjc50 22 hours agoprev\"Stock buybacks are a form of stock manipulation\" - not really, they're a means of returning money to the shareholders while bypassing taxes on dividends. (Not an expert on the US tax system as I'm a Brit, but it seems that the tax treatment of dividends depends on how long the stock is held, and can be taxed at income tax rates, while stock buybacks result in inflating the stock value which is always CGT. Not sure what the tax treatment is for institutional investors?) NB that \"returning money to the shareholders\" is ultimately what companies are for, and we should completely expect them to do this because without it investors wouldn't invest in the first place. It's infinite zero-dividend growth that's weird (Amazon). reply concinds 22 hours agoparentThey're a means of \"returning money\", but they also pump up the stock price, to which managers' TCs are linked. Hence they are a form of manipulation. Unlike dividends, they don't return money to all shareholders, but to those who sell shares, which are the wealthiest, unnecessarily increasing inequality. Excessive buybacks and underinvestment are a big reason why Intel failed. Gelsinger (CEO) talked about this publicly. It's not just \"returning money to shareholders\", because it leads to perverse incentives and underinvestment. Under Otellini, Intel returned 109% of its profits to shareholders. reply throw0101b 20 hours agorootparent> They're a means of \"returning money\", but they also pump up the stock price […] Stock prices are also effected by dividends: > Dividends can affect the price of their underlying stock in a variety of ways. While the dividend history of a given stock plays a general role in its popularity, the declaration and payment of dividends also have a specific and predictable effect on market prices. After the ex-dividend date, the share price of a stock usually drops by the amount of the dividend. * https://www.investopedia.com/articles/investing/091015/how-d... This has been know since (at least) 1955: * https://www.jstor.org/stable/2976771 reply nabla9 20 hours agorootparentprev>Unlike dividends, they don't return money to all shareholders, That's false reasoning in so many level. Take every of your arguments and do counterfactual and you see. > leads to perverse incentives and underinvestment Investing is not alternative to paying dividends in any well managed company. Companies invest if they see better ROI for the investment than elsewhere. They give money back to shareholders (either dividends or buybacks) when they can't do better than markets. reply yborg 20 hours agorootparentThe positive ROI may accrue primarily to the top executives who are in a position to directly make that decision. Especially in a field like semiconductor processing where risks are high on new investment, it is almost always a lower risk decision to buyback the stock. I don't know the specifics of Otellini's pay package, but I would assume that his tenure resulted in massive wealth for himself, so this is certainly rational economic behavior but severely damaged the company. reply mamonster 19 hours agorootparentWell the other part is that a big part of share buybacks are simply \"sanitizing\" the dilution from stock based comps(which are increasingly the way that most people get paid). Intel SBC was 3.2 billion in 2023, and there haven't been any buybacks I think the last 2-3 years? Quite a bit of dilution which doesn't really make long term investors happy. reply nabla9 20 hours agorootparentprev>it is almost always a lower risk decision to buyback the stock. This is all about buyback versus dividend. How it is that people are thinking wrong counterfactual? reply prepend 21 hours agorootparentprev> Hence they are a form of manipulation. They are a form of manipulation we don’t normally care about. Definitely not illegal. By this definition, productivity is manipulation. Or tax optimization is manipulation. Or IPOs are manipulation. Typically this word is used to indicate unethical and illegal behavior. Not just typical organizational behavior. reply diogofranco 19 hours agorootparentprevBuybacks \"pumping the stock price\" is a common misconception, but not actually true (unless the buyback is executed at prices lower than fair value). There are less shares outstanding afterwards, but there is also less cash, so if executed at fair prices there is no reason for the stock price to move. Just think through an example of a simple company which is a pot of $1000, and can get 10% returns on it. There are 100 shares, so if investors want 10% returns, shares should trade at 10$ (P/B = 1). If the company repurchases half the shares, there will be only 50 shares but the company only has 500$ now, making each share still worth 10$ for 10% hurdle rates. reply positr0n 10 hours agorootparentBut companies are not pots of assets. What you are buying is assets - liabilities + predicted future cashflow * discount rate. So a more realistic example would be a company with 100 shares, $1000 of cash, and $1000/yr stable income. So before a buyback, 1 share grants you the benefits if whatever the company does with $10/yr of income. Whether it be dividends, reinvestment, etc. If the share price is $25 and they spend half their cash on hand to buy 20 shares back, now one share gets you $12.50/year of income. Thus the share is worth more than it was before. Disclaimer: Armchair finance / economics knowledge. Hope the above is correct. reply robertlagrant 21 hours agorootparentprev> They're a means of \"returning money\", but they also pump up the stock price, to which managers' TCs are linked. Hence they are a form of manipulation. Why would you say they're pumping up the stock price, rather than just raising the price? Is it a temporary pumping effect, like an Elon Musk tweet from 2017, or is it actually increasing the value of the remaining shares? reply thehappypm 20 hours agorootparentLet's say corp XYZ has 100 shares out, and they're owned by 50 people. At any point, there are people trading, buying and selling those 100 shares. Buyer 51 comes along and wants to buy a share. He can only buy a share if one of the 50 owners are selling. So, he has to offer a price that'll convince one of the 50 to sell. XYZ Corp decides to do a buyback. They buy 20 of those shares. In that moment, they will certainly create a spike in demand for the 20 shares. But later on, now there are only 80 shares out. When buyer 52 comes along to buy a share, there are fewer shares, and fewer sellers. He might have to offer more than Buyer 51 to actually get a share for that reason. reply tzs 19 hours agorootparent> But later on, now there are only 80 shares out. When buyer 52 comes along to buy a share, there are fewer shares, and fewer sellers. He might have to offer more than Buyer 51 to actually get a share for that reason. By buying that one share buyer 52 gets ownership of 1.25% of the company. Buyer 51 only got 1.00% of the company when they bought their share. You need to take that into account when comparing share prices. reply robertlagrant 20 hours agorootparentprevThat's not pumping stock, though, right? Pumping stock is artificially increasing the number of buyers, for a short period. You're describing reducing the number of sellers. Which may increase the price, or may not. reply thehappypm 19 hours agorootparentYou could argue that the buyback itself, like the moment where the company actually buys the shares back, is a pump moment. they could have the demand far outstrip the typical demand in the moment. But long-term, the price should be higher as they have decreased supply. reply concinds 21 hours agorootparentprevProbably only the latter. My point was that executives (share sellers) benefit and it creates potentially toxic incentives. reply kjreact 20 hours agorootparentExecutives are always incentivized to increase share value; that’s their job. Note: it’s the board of directors that issues new shares not executives. Executives can sit on the board, but the two are not the same. Executives are actually appointed by the board. The reason stock buybacks are viewed somewhat negatively is because it’s a lazy way to increase share value. Preferably executives would use the money to come up with new products/services to increase revenues. But if we’re talking about huge mega corporations, who already spend a lot of money on R&D, capex and/or acquisitions, then using some additional cash flow on buybacks makes sense. In Intel’s case, the buyback merits some discussion because it is implied that government subsidies are being used to buyback shares which is not the intention of the subsidy. Edit: IMO, I don’t think Intel underinvested, I believe they invested in many failed ventures and under their past and current leadership they are not able to grow the company in any meaningful way. reply robertlagrant 20 hours agorootparentprev> My point was that executives (share sellers) benefit and it creates potentially toxic incentives. This seems like a good incentive. Executives of course don't have to have any shares, although they probably will, but that's not \"toxic\". I know that toxic is now the blandest word in the language due to overuse, but even given that this seems distortional. reply gruez 21 hours agorootparentprev>Under Otellini, Intel returned 109% of its profits to shareholders. Seems like everything is working as intended. What do you think that companies are supposed to do with their profits? Why do you think shareholders buy stocks in the first place? reply fancyfredbot 21 hours agorootparent> What do you think that companies are supposed to do with their profits? With hindsight it's clear that it would have been better for shareholders if Otellini had reinvested more profit into R&D rather than returning it to shareholders. Intel has now lost their process node advantage to TSMC. Their CPUs are not competitive on power efficiency with AMD and Apple. This is leading to smaller profits and ultimately a worse outcome for shareholders. reply concinds 21 hours agorootparentRight, more R&D and more CAPEX. The question is not whether shareholders deserve any return on their investment (yes), the question is short term vs. long term focus. Same with Boeing (161% of Boeing profits given to shareholders 2013-2019, underinvestment in talent and safety). reply fiprofessor 21 hours agoparentprevPrior to the Bush era tax cuts, all dividends were taxed at the income rate, which I think explains the biggest motivation in the shift from dividends to buybacks in that era. Nowadays, as you say, there is no difference in tax rates for qualified dividends. However, one big remaining benefit of buybacks is that a dividend forces one to incur a taxable event when the dividend is issued, even if one chooses to immediately re-invest the dividend in the company (as many people still in the accumulation phase of investing do). On the other hand, a buyback does not force those people to sell. On the other hand, a buyback should lower the market cap of a stock, so cap-weighted index funds ought to sell and re-balance when a buyback is issued, so most index investors would seemingly end up selling. However, they end up being able to avoid most of the capital gains taxes by re-balancing through redemptions and heartbeat trades. reply gizmondo 21 hours agorootparent> On the other hand, a buyback should lower the market cap of a stock You got it backwards. If a stock is priced fairly, a buyback is value-neutral. Reduction of the cash on hand is offset by the increase of future cash flow per share. It's dividends that reduce the market cap. reply fiprofessor 21 hours agorootparentNo, because the future cash flow per share is not reflected in the current market cap. Perhaps you are thinking of share price instead: there it is true that dividends reduce share price, while buybacks are share-price neutral at least theoretically, though it is commonly believed by many people that they do affect price. (Hence, under that same theoretical model, market cap must decrease if share price remains the same because market cap is total number of outstanding shares * share price. So if the former decreases while the latter stays the same, market cap must have decreased.) reply gizmondo 21 hours agorootparentYou're right, I need a coffee. reply otteromkram 21 hours agorootparentprev> On the other hand, a buyback should lower the market cap of a stock [...] Uhh...what? Buybacks are a return of value. Share prices adjust accordingly to the updated proportion of outstanding stock. Might want to select a new username, friend. reply pliny 21 hours agorootparentThe price of the share stays the same but there are fewer shares, so the market cap would go down. reply mrkstu 21 hours agorootparentBut EPS rises so equilibrium would suggest the price of the share would almost certainly rise to match the old EPS. reply fiprofessor 20 hours agorootparentThe earnings per share certainly increases. But this is (at least theoretically) offset by the fact that the firm's assets have decreased. For example, if the buyback was paid for with cash, then prior to the buyback, the shares represented a claim of ownership not just on future earnings, but also on that cash reserve. That said, this is all under a theoretical model (as in Miller-Modigliani theorem). In practice/empirically, there is reason to plausibly believe that e.g. the decision to announce a buyback has a signalling effect and so can increase share prices. reply mrkstu 18 hours agorootparentIs there a heuristic for how much of the value of a share is assigned to asset value vs forward looking earnings? Many of the ‘hot’ stocks like Nvidia seem almost all forward looking. reply pliny 18 hours agorootparentFor public companies you don't need a heuristic, as the balance sheet is included in quarterly earnings reports. reply User23 20 hours agorootparentprevWell it certainly makes a market for the lucky duckies who are the counterparties for the buyback. They benefit. reply User23 20 hours agorootparentprevThis isn’t even necessarily true for dividend yield let alone for EPS. reply jenny91 19 hours agorootparentprevBy buying stocks, the company transfers money out of the company and to shareholders. Of course the market cap should go down: the fundamental value of the company has gone down (they have less cash). reply jorvi 21 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for You have absorbed modern market brokenthink. Companies are for creating goods or services to sell to other parties. They existed long before the idea of shareholders. Following your logic, companies pre-VOC had no existing purpose. reply bryanlarsen 21 hours agorootparentBusinesses have always been for putting food on the table of their proprietors. We've got a few more levels of abstraction now, but the fundamental is the same. reply danbruc 18 hours agorootparentWhy does anyone work? Because they need or desire certain goods and services. They entire idea of a business falls flat if it does not produce stuff people want. It is of course true that from the perspective of the business owner running the business is how they work, how they get the stuff they want by making money to buy things, but putting the emphasize on that seems wrong to me, after all you can run a business without trying to make as much profit as possible but you can not run a business that produces nothing. reply ToValueFunfetti 16 hours agorootparent>you can run a business without trying to make as much profit as possible but you can not run a business that produces nothing This is not an even comparison. A business that produces the minimum amount (0) of product/service should be compared against a business that produces the minimum amount (-$assets) of profit, which corresponds to 0 revenue. Neither business can be run, but the former can at least sit on its assets or pivot into actually making something. A business can also produce too much and collapse (see Atari and DeLorean), but it can't collapse from too much profit. It makes more sense to put the emphasis on profit, I think. reply danbruc 12 hours agorootparentThis is not an even comparison. This was not intended to be one or at best in the following sense. Making products and making profits are two features of businesses, the first one is essential, the second one is dispensable. No products, no business. No profits, no problem. Even more, no profits is where every business would ideally be, in a functioning market competition should drive the margins towards zero, the price should be equal to the costs of production. reply jorvi 15 hours agorootparentprevYou can run a business with negative profit (say, to capture market share or using a loss leader), but you can’t run a business with negative production. Production is essential to a business and profit is not, strange as that may seem. reply ToValueFunfetti 15 hours agorootparentWhat does negative production mean to you here? I can run an incineration business or a demolition derby, as long as I get paid to do so. If that doesn't count as negative production (because I'm producing space or entertainment value; potentially at a loss to acquire market share), what does? If negative production is a physical impossibility, the claim that you can't run a business with it doesn't tell us anything about business. reply gtirloni 21 hours agorootparentprev> Companies are for creating goods or services to sell to other parties Out of autruism? If not, it's to make money for owners. Shareholders are sort of owners thus to make money for shareholders. reply ada1981 21 hours agorootparentYes, actually. >> For the first companies, the privilege of incorporation, often via royal charter, was granted selectively to facilitate activities that contributed to the population’s welfare, such as the construction of roads, canals, hospitals and schools. Allowing shareholders to profit was seen as a means to that end. Companies were deeply interwoven within the country’s or town’s social fabric, and were meant to contribute to its collective prosperity.Companies are for creating goods or services to sell to other parties. They existed long before the idea of shareholders. Following your logic, companies pre-VOC had no existing purpose. Sure, but the owners (sole proprietors, shareholders, partners, etc.) of most companies want to make profit selling those services and goods. The more money you make the more you can grow the company or reward yourself (as owner). reply conscion 19 hours agorootparentprevCompanies don't exist for returning money to shareholders, but issuing stock exists to return money to shareholders. 1. Company issues stock in order raise capital 2. Company uses capital to grow business 3. Company returns money to stock purchases as risk-reward for purchasing stock Buy-backs are what a company _should_ do once the capital it raised has had a positive ROI reply carlosjobim 21 hours agorootparentprevCompanies never existed without shareholders. It's in the name: \"company\", ie a group of people. You're thinking about \"ventures\" or \"businesses\". Which would exist by decree of the sovereign, for example. reply delusional 22 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for And here I thought Intel was for producing computer chips. Silly me. I forget the entirety of human history was just an elaborate pyramid scheme. reply aembleton 21 hours agorootparentComputer chips that they sell for a profit that they return to shareholders reply boh 21 hours agoparentprevFrom a basic economics perspective, companies conduct buybacks when they have no other use for the money. Since re-investment supports shareholders on a longer timescale, Intel has essentially let the market know they don't have any other use for the money they have. The point of investing in a company is the funds to be used to generate wealth. If I invest in your company and you just give me back my money, what's the point of the company (especially if its money requiring extra leverage to produce). Buybacks are inefficient use of invested capital (see NVidia's stock price if you need a comparison for a more efficient use of cash and its effect on shareholder value). reply gizmondo 21 hours agorootparentWhether they are efficient or not entirely depends on the company. For every NVidia you can find another company (or ten) that reinvests inefficiently because managers tend to like building empires at the expense of their shareholders. reply boh 17 hours agorootparentOf course. Intel, specifically, does not make a compelling case that they spent their cash efficiently. reply onetimeuse92304 21 hours agoparentprevIt is a silly notion there is anything wrong per se about stock buybacks. Just as you can sell stock when you need cash (and lose some control) it is simply buying stock back when you saved some cash (and regain control). The only reason stock buybacks are thought of in negative light is that they seem to be a way for companies to not pay taxes... but the tax law is not companies' fault! It is our fault for the tax law to be this way! reply harimau777 21 hours agorootparentDon't the companies, their industry organizations, and the people who own them lobby congress to make that tax law? It seems to me that in that case, tax law is their fault. reply bradleyjg 22 hours agoparentprevI have no idea why journalists have such a hate boner for stock buybacks. Dividends can get favorable tax treatment too. Just allows owners to time the tax hit. reply matwood 20 hours agorootparentIt's like I mentioned when this came up yesterday, it's just a favorite boogieman. reply Workaccount2 20 hours agorootparentprevIt gets clicks from people who aren't old enough yet to have any assets. reply supertrope 14 hours agorootparentprevMost people don't own individual stocks. So their audience just pictures top hat wearing capitalists when they hear stock buybacks. It's the same reason why tenants garner sympathy while landlords are quickly called slumlords. reply patrickthebold 22 hours agoparentprevCouple of comments: Usually when people buy shares they are going to try and get the most shares for the least amount of money, but the incentives are a bit different for stock buybacks. I don't know if buybacks are large enough to \"move the market\" but I'd be curious to see details on how exactly orders are placed. I'm a big believer that we need more non-profits that simple exist to employ people and provide goods and services. I realize this is just a charity and depends on the good will of people with capital. reply overstay8930 22 hours agorootparentYou're probably thinking of co-ops, it is much harder to be a non-profit for most types of companies. reply andmarios 22 hours agoparentprevIt can be both at the same time. By buying out your stock, you alter the company's assets, but the price of the stock remains the same since you still have the same number of stocks issued. You just replaced your money assets with stock assets. Once you cancel the stocks you bought back, the rest of the shares will hold a more significant percentage of the company and increase in value. But this is one part of the equation. The other part is that your stock is inside a market, and buyers and sellers combined determine its price. If you keep buying your stock, you create buying pressure, helping keep the price from falling. reply boringg 22 hours agoparentprevStock buy backs functionally work no different them dividends at the end of the day. Your returns instead of getting issued as cash from a dividend are in the form of higher share value. Taxed as short term or long term capital gains vs dividend. Its a form of stock manipulation if you mean that buying stock increases the value of the stock. It doesn't mean its a form of manipulation in some kind of illegal unethical way that i think this comment thread is trying to make it sound. reply jsiepkes 22 hours agoparentprevIt's stock manipulation, we just chose not to see it as such. Just like alcohol is objectively a hard drug but we just chose not to categorize it as such. reply gpderetta 22 hours agorootparentIs a company issuing its own stock (i.e. selling) also market manipulation? It brings the price down. Buyback is the reverse operation. The difference from actual price manipulation, is that the price change in issues and buybacks is a permanent effect of the material change of the number of outstanding shares, not a fledging effect of the change in trade volume, i.e. the intrinsic value of the stock goes up or down. edit: of course buybacks, like dividends, decrease the value of a company, and issuing stock increase it, so it is not clear cut. reply pjc50 22 hours agorootparentprevWhy is company X buying its own stock on the open market \"manipulation\" rather than any other purchaser? reply Drakim 22 hours agorootparentWhy is me buying my own book to bring it to the best seller list any different than any other purchaser? Stocks are supposed to be a share of ownership in a company, and the price goes up and down because being an owner of a company goes up and down in desirability, based on how well the company is doing. Just like with buying your own book, buying your own stock artificially increases the desirability. reply pas 22 hours agorootparentthat's an argument for why best seller lists are stupid. companies can create new stock anytime out of thin air, and that decreases the price. why can't they do the opposite? some owners of the company decide to buy stocks from the others, thus consolidating ownership. that's what stock buyback is. note, the argument for taxing buybacks is completely different, and valid. (and it might make sense, it might not, it depends on the circumstances. externalities tax (pollution, tax on induced traffic, etc), LVT (land value tax) and wealth tax would be much better, than taxing transactions.) reply jmholla 18 hours agorootparent> companies can create new stock anytime out of thin air, and that decreases the price. why can't they do the opposite? So at any point, a company can devalue existing shares that people have already purchased? That also sounds like a problem. reply akvadrako 11 hours agorootparentIf companies couldn't issue stock there wouldn't be a stock market at all. reply pas 15 hours agorootparentprevsure it can be securities fraud, but usually it's done to attract more investors. companies on stock exchanges usually do stock splits, etc. (and based on bylaws majority or 2/3rs or more of existing owners need to approve.) reply robertlagrant 21 hours agorootparentprev> Why is me buying my own book to bring it to the best seller list any different than any other purchaser? What's the best-seller list in this case? reply bvaldivielso 22 hours agorootparentprevThis is a misunderstanding of what stock buybacks are. Companies do not buy their stock from themselves. They buy the stock from participants in the market. Following your example, it'd be like the author of a book buying the book they wrote from someone else. If the author chooses to pay someone else 1000$ for their book, they can, but they will be wasting money. A company doing a stock buyback is trading off their own capital (they have to spend it, it's not an infinite money glitch where they buy it from themselves) to get back shares of the company itself at the then-market-price. The market chooses whether that's a good trade. It may not reply jsiepkes 22 hours agorootparentprevBecause you have inside knowledge and you are altering the stock price. reply koolba 22 hours agorootparentThe company is in charge of itself. Everything it does alters the price. Bought back shares strictly increase the price for existing shareholders as it takes them off the market. The entire concept is mainly due to stupidity in tax law that ends up double taxing direct dividends. reply chongli 22 hours agorootparentprevStock buybacks are heavily regulated. They need to be tracked and publicly reported and the plans for buybacks need to be announced by the company ahead of time. reply jomohke 21 hours agorootparentprevNote that buybacks must be announced beforehand by the company, so everyone selling their shares has the same knowledge. reply Retric 22 hours agorootparentprevBecause it’s independent of other price signaling mechanisms. The company doesn’t buy the stock because it thinks that stock is a good investment, it does so because of how it influences future prices. Ignoring inflation if a company issues the same inflation adjusted dividend forever say 1% at current prices. In theory the stock should stay roughly the same over the next hundred or thousand years. However, with a buyback the stock would increase constantly forever with endless stock splits. The second option is great for long term owners in terms of taxes, but it’s also manipulation of the stock price. reply davrosthedalek 22 hours agorootparentNo, it buys it /because it has money to spare/. Having the money to spare makes it a good investment. reply Retric 22 hours agorootparentCompanies can have net profits and be terrible investments. The exact same company can be a great investment at 10$, and a terrible investment at 10,000$. You can’t separate stock price from if something is a good investment or not. The example I gave was low risk 1% dividend, that’s not a stock I would want to own. Net result the company, which has inside information, should expect the price to correct ie fall at some point and thus be a poor investment until that point. That doesn’t prevent them from buying it because the goal isn’t a positive ROI. reply wmil 22 hours agorootparentprevIf you're going to stretch the difference that much the why not go all out? CEOs are constantly attempting to manipulate the stock price by trying their best to do a good job. reply daft_pink 21 hours agoparentprevJust want to mention since many commentors on this seem to miss this, three important points about stock buybacks missed by the back and forth partisan talking points on this comment: 1. They only make sense when the stock is undervalued and aren’t purely driven by taxes. If the stock is undervalued, then investors benefit by owning more of the company for less. If the stock is overvalued, then investors don’t benefit. The overall value of the price compared to its long term real value is important. There is a basic problem with this, because company executives probably never want to admit that their stock is overvalued. 2. Companies with strong incomes relative to their price can afford to do buybacks or with strong cash positions are the ones that make sense to do buybacks. Companies like this might be overvalued. When you see companies internet companies with zero income doing buybacks it makes very little sense and only established companies. Companies with strong financial positions relative to their stock price are more likely to be undervalued. 3. Because of the discounted cash value of income model for dividends where the value of a stock is based on future income and cash flow, dividends generally have to be stable and regular to ascribe significant value to a stock, which is why companies that have built up large cash balances but don’t expect to regularly pay dividends opt for buybacks, because they don’t want to create the constant pressure to regularly pay dividends. reply nr378 20 hours agorootparent1. Stock buybacks are always anti-dilutive regardless of the value of the stock, and so investors always benefit as future earnings are concentrated amongst fewer shares (all other things being equal). It's true that a lower price/value increases the magnitude of this effect, but the effect is always present. 2. Zero income stocks can still do buybacks when they're returning capital raised from shareholders to shareholders (this is essentially just partially reversing a funding round, which again undoes some of the dilution). 3. Companies can be deemed to be significantly valuable without paying any dividends. Companies that have a long history of paying dividends but then suddenly stop tend to be in distress, which is then reflected in their share price. reply daft_pink 19 hours agorootparentThese statements might be logically true, but I feel the logic ignores the overall strategic factors involved in buying back stock and that management needs to consider whether the stock is over or under valued, whether earnings are strong enough for this to make logical sense and the supply and demand among investors for dividend stocks and the ultimate value of a single lump sum distributed to investors vs the value of increased future earnings to the investor from the anti-dilutive impact of buying back stock. Discussing only the tax strategy as is happening in this thread is really stepping over some really important strategic operational factors. reply throw0101b 20 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for […] That is one theory of corporate governance: * https://en.wikipedia.org/wiki/Shareholder_value * https://en.wikipedia.org/wiki/Friedman_doctrine There are others: * https://en.wikipedia.org/wiki/Stakeholder_theory * https://corpgov.law.harvard.edu/2012/06/26/the-shareholder-v... * https://sloanreview.mit.edu/article/the-shareholders-vs-stak... reply dubcanada 22 hours agoparentprevTax just depends on how long it's held and if it is part of a major index. If you held long enough and it's part of a major index it is taxed the same as a stock buyback would (assuming you sold). Otherwise it's taxed as income. reply tgv 21 hours agoparentprevTrading stock isn't investing. There's no reason for companies to give money to shareholders that simply bought their shares on the stock market. The company doesn't profit from that. reply danbruc 20 hours agoparentprevNB that \"returning money to the shareholders\" is ultimately what companies are for [...] This could not be further from the truth. Companies - and actually the entire economy - only exists for one purpose, to satisfy the needs of the people, to efficiently produce good and service that people need or desire. Profits are just means to the end, a control signal to steer the economy. Not that they are not important, but they are not why we have companies. reply oatmeal1 22 hours agoparentprevAgreed. It is a huge problem though that share buybacks are a way actual production (wages) is taxed at a higher rate than passive income. reply throwaway_ab 22 hours agoparentprevFor them to be effective at returning money to shareholders, the action of buying stock is intended to take stock out of supply thus increasing share price value. Exactly as you say. Yet, this is clearly a form of stock manipulation, as it's an action to manipulate the share price. Whilst it is stock manipulation, it's debatable if it should be legal. I believe it should be legal, it's an efficient way to increase share value without adding to someone's income, thus often carries no immediate taxable obligation. However one could argue that these methods of moving wealth around without taxable events triggering adds to the fuel for calls to tax unrealised gains on all stock. So in the long run we are all worse off. Those laws will likely come regardless, as a way to fight the billionaire class, so stopping stock buybacks at this stage is unlikely to do anything. reply matwood 20 hours agorootparentDividends also change the share price, should those be illegal? What about announcing new products? reply Drakim 22 hours agorootparentprevIt does effectively legalize a form of insider trading though, a company would never do a massive stock buyback right before dropping bad news because the stocks they are now holding goes down in the price. reply andsoitis 21 hours agorootparent> form of insider trading Rule 10b-18 is designed to prevent companies from using buybacks to manipulate the market, stating that share buy backs must meet 4 conditions: 1. all shares must be purchased during a single day and from a single broker or via a single deal 2. larger companies cannot authorize buybacks within the last 10mins of the day and smaller companies can't authorize them within the last 30 mins 3. companies have to buy back their stocks at a price lower than or equal to the highest independent bid 4. companies can't buy back more than 25% of the average daily volume reply miga 17 hours agoparentprevStock buybacks return money to the investors. reply StableAlkyne 21 hours agoparentprev> not really, they're a means of returning money to the shareholders while bypassing taxes on dividends. This is actually a new idea. Prior to a change by the Reagan administration in 1982, they were considered to be an illegal form of market manipulation. Dividends served the purpose of dumping excess funds to shareholders. reply User23 20 hours agoparentprevStock buybacks only pass money to those shareholders whose stock the company buys back. The buyback may raise the overall market price of the stock, but it also might not. reply ClumsyPilot 21 hours agoparentprev> NB that \"returning money to the shareholders\" is ultimately what companies are for And here I thought companies are there to provide me, the consumer, and the customer, with useful products and services. If the purpose is return of money to shareholders, then the best strategy is to over leverage the company, spend every penny on stock buybacks, then default on all obligations to suppliers, pension funds and customers. Because you can fund stock buybacks with debt, but you could not do that with dividends. We have made economic destruction profitable and it’s happening across our economy - water companies in UK are going bankrupt because they have huge debt that they took out just for stock buybacks, and not for anything else, and now interest rates are up. Same thing happened with airlines, and many other firms. reply pjc50 20 hours agorootparentIt's always been \"both\"? (specifically for the PLC-type company). People invest in the expectation of a return, to be achieved by doing business. It's usually phrased as \"maximize shareholder value\", which is ambiguous about the timeframe, but for most cases the value is understood to be over the indefinite future. Not that that stops people from taking short term decisions which can be bad in the long term. > Because you can fund stock buybacks with debt, but you could not do that with dividends. There are plenty of companies with large debs that pay dividends on the US market, such as Ford. The overleveraged self-destruction is bad, but that tends to be a feature of private equity deals where there is a single majority owner doing it on purpose (e.g. Maplin, Jaguar Land Rover). Harder to do with a publicly owned company where the investors can see what you are doing and may sue you. The UK water companies should never have been privatized in the first place. They're dysfunctional because water isn't a normal market and arguably can't be, so they're ripe for this kind of looting of the state by capital depletion. reply scotty79 22 hours agoparentprev> \"returning money to the shareholders\" is ultimately what companies are for That's what shareholders want you to think. But societally and economically companies are mostly for everything else. If no company ever paid a single dividend or never bought back any of its stock nothing bad would happen. There are a lot of companies doing exactly that. But if companies stopped doing everything else they do that they are supposedly not for, the economy would end. reply fiprofessor 21 hours agorootparentWho would invest in or create a company that would never pay a dividend and never bought back its stock? How would shareholders ever yield gains from their investment? Short of some entity buying all stock and taking the company private (to then withdraw profits), there would be no way to return profits to shareholders. The companies currently not doing those things are in a growth phase, with the expectation that in the future they probably will be issuing dividends/buybacks. reply Aspos 21 hours agorootparentThose who benefit from the company exist would invest in it: state, employees, clients. reply scotty79 11 hours agorootparentprevWhen company goes public its shares become tokens in the casino. Shreholders can sell their shares to people who want to gamble with them. And just one reason is sufficient for people to want to take a gamble and purchase them. It's enough that they believe that they'll be able to sell it for more later. And they are not wrong. As long as the name on the token takes a prominent place in public consciousness people will flock to it and early investors will be able to sell it for more. If you want to see what's sufficient for people to invest in something look at shiba inu crypto token or WIF. Who would create a company for 100k if it can sell it to gamblers for millions when it goes public? Plenty of people. There's whole industry of angel investors fuelled by thay dynamic. reply Eisenstein 21 hours agorootparentprev> The companies currently not doing those things are in a growth phase, with the expectation that in the future they probably will be issuing dividends/buybacks. Berkshire-Hathaway has only paid dividends once since Buffet took over, and is the highest priced stock listed on the NYSE. reply fiprofessor 20 hours agorootparentBut Berkshire Hathaway does do stock buybacks. reply mypastself 22 hours agorootparentprevExcept that even then, an investor can sell their shares. If they couldn’t, no company would ever be able to raise money in a public offering. reply paganel 22 hours agoparentprev>NB that \"returning money to the shareholders\" is ultimately what companies are for That's debatable in many instances of the modern economic system. Of course, some instances of capitalism focus on that particular goal you've mentioned, but that wasn't always the case and it still isn't, depending on the socio-economic circumstances. reply bradleyjg 22 hours agoprevNo one needs $8 billion in subsidies. But that’s how we run the United States now. There’s no longer comprehensive legislation trying to solve a particular (perceived) problem. Instead we just drop money from the sky on various people and companies. There’s a pandemic? Quick, cut 80% of the country a check. The childcare industry is structurally understaffed and unprofitable, let’s just cut them all checks! Higher education keeps on growing to larger and larger percentages of GDP? That’s okay we’ll just cut checks blank tuition checks and then forgive all the loans. China is signaling that it might invade Taiwan. That’s a tough one. Hmm. I got it, let’s cut a check to semiconductor manufacturers! reply vasco 22 hours agoparentMy question shouldn't imply I disagree, but what's the alternative to allocating capital to industries or problems where government wants to drive change? reply bradleyjg 21 hours agorootparentRegulation or deregulation. Take loan forgiveness—-the loans themselves are not the underlying root issue. They are a tertiary effect of a credentialism spiral and insane cost growth at institutions that don’t face true market pressures. Just dropping money on borrowers is not even attempting to fix the underlying problem. It’s so unambitious it invites cynicism. reply ethanbond 21 hours agorootparentAnd how do you propose the government try to fix credentialism? For all the talk about how useless degrees are, companies still choose to require them, especially the companies helmed by “college is a scam” zealots. reply bradleyjg 21 hours agorootparentCompanies have to still require them because they are a valuable signal and it’s free to them. Kids have to go because companies require them. This is what a peacock spiral looks like. Government is fundamentally for breaking these kind of incentive failures. Not supercharging them through blank check forgivable loans. reply ethanbond 21 hours agorootparentNo, companies don’t have to require them. Agreed the loan behavior exacerbates the issue rather than mitigates it, but “the current solution is bad” doesn’t necessarily mean the same agent is able to produce a good solution. If you’re certain the government is capable of breaking it: how? reply bradleyjg 20 hours agorootparentI have ideas but if I post them, I’m guessing you are going to pattern match me to some ideological category and try to debate from that point of view. That’s not my point at all. It’s that all our federal politicians and political parties have had their ambitions shrunk down to nothing. No one at all is saying—-hey this credentialism thing is a serious problem, vote for us and here’s how we’ll attack it. Even if someone was proposing an idea I totally hated, I would at least appreciate the effort to actually solve a real problem. If you think credentialism is impossible for the government to make a difference on, pick something else. Anywhere you look for the last 14 years we’ve had few to no ambitious proposals. reply ethanbond 19 hours agorootparentErrmmm... okay. The Biden administration actually has both talked extensively and taken several concrete steps against credentialism. Effective? I personally do not know. But it's blatantly false to say no one is talking about it or attempting to fix it. > The Department of Labor (DOL) is announcing an Advanced Manufacturing Registered Apprenticeship Accelerator Series that will support hundreds of employers to speed the development and launch of Registered Apprenticeship programs in high-demand occupations, such as industrial manufacturing technicians, robotics technicians, and industrial maintenance mechanics. Since the beginning of this Administration, the number of apprentices in advanced manufacturing Registered Apprenticeship programs has increased by 10 percent—and this effort will build on that growth. The administration has backed numerous apprenticeship programs like BioFabUSA that explicitly do not require college degrees. The administration created \"Investing in America Workforce Hubs\" in several cities to attract private investment into programs that, again, prioritize high-quality jobs that do not require college degrees. So it is simply untrue that no one is saying credentialism is a problem and trying to attack it. The current administration talks about this to no end and has attempted dozens and dozens of substantial attacks on it. Again, if you have ideas other than grant funding and tax incentives, I'm truly curious to hear them. reply lossolo 21 hours agorootparentprevYou still do not offer any alternative solutions to problems you presented in your original post. reply vasco 21 hours agorootparentprevThanks for ellaborating! Although de-regulation and regulation have other properties, I'd posit they are in essense are forms of capital allocation. When you regulate an industry you require more capital investment from that industry, either by investing in new processes, implementing compliance mechanisms, maybe hiring extra quality-assurance people or having to dispose of trash in a better way, etc. Regulation mostly implies more investment by the participants in that specific segment of the market, it's like a reverse capital injection, or an added tax. The same way de-regulation is like giving that segment of the market a cash bonus because they can relax processes that require money to run and operate more efficiently. More importantly regulation and deregulation also add or remove rules, so they change the behavior of the participants. If you want to have the same effect of regulation and deregulation but not by driving change in rules of operation (maybe because as the government you don't know yet which rules to create - or the different political factions cannot agree), an easier way is to directly give money, and depending on how you allocate it, I think it can be a fair way to do it. Another way of thinking about this as a system is imagining the case where you want to promote investment in the semi-conductor industry but not at the expense of processes. Said another way, what would you de-regulate in the semiconductor industry to have the same effect as a capital injection to the leading semiconductor companies in your country? Surely you're not proposing them to be able to use more dangerous chemicals and dispose them however they want, or other types of de-regulation? It would reduce the barriers to entry and help semiconductor companies, but with negative externalities. Messing with regulations always has this potential for unpredictable secondary effects. I'm not convinced regulation/deregulation is in principle superior to just allocating money pools with fair rules to access them. I'm obviously against nepotism and influence peddling as part of the money allocation process and I'm not defending the injection into Intel specifically, which probably suffered from a big amount of influence peddling. reply wakawaka28 20 hours agorootparentprevTuition has only exploded because of unlimited government-backed student loans. They created this problem with the \"good intentions\" of providing everyone an opportunity to study any subject at any price regardless of job prospects. The problem isn't credentialism per se, although a large number of people were advised to go to college for the most generic stuff on the theory that \"any\" college degree doubles your lifetime earnings no matter what you study. reply YetAnotherNick 20 hours agorootparentprevRegulations is one of the major reason semiconductor industry shifted overseas. US used to be the undisputed leader in semiconductor manufacturing. If you think Intel will stay regardless of US regulation, you are definitely wrong. China will always allow manufacturing with minimal regulations. reply Drakim 22 hours agorootparentprevThe government as the strongest central power identifying weak or struggling areas of the country that needs help makes sense. That's like primary advantage of central power in the first place. The issue is that things like lobbying ends up shifting that focus over to already strong parts of the country that wants even more. reply vitiral 17 hours agorootparentprevTraditionally I believe tariffs and trade agreements were the typical approach at shoring up domestic production. I have very little knowledge over their current effectiveness or use. reply dgfitz 22 hours agorootparentprevCap tuition costs, raise wages for daycare centers? reply constantcrying 19 hours agoparentprevSure, but what is the alternative? Government subsidies keep the whole thing afloat, there is no removing them. And obviously that is by design. There is a marginal utility to increasing funding, but that isn't the point, the point is that the subsidies guarantee that the receiver is dependent on the sender. reply gtirloni 21 hours agoparentprevAs opposed to doing what in those cases? reply lossolo 20 hours agoparentprev> There’s no longer comprehensive legislation trying to solve a particular (perceived) problem. Of course, there is, but some problems are different and difficult. Why are they difficult? Because it's hard to find an alternative solution that ticks all these boxes: one that is socially acceptable to all parties involved, does not incur additional problems or direct costs to any specific party or group of interest, and does not disrupt the market, among other considerations. You also need to take into account current laws, the social contract, and politics. Sometimes, the most efficient, easiest, least disruptive, and most acceptable solution is simply to allocate funds to address the problem. reply bradleyjg 12 hours agorootparent> Of course, there is, Which law, passed after the ACA, would you say best reflects Congress identifying a serious national problem and attempting to comprehensively deal with it? reply overstay8930 22 hours agoparentprev“Raising children is expensive, let’s make sure we make it even worse for them by removing our strategic autonomy!” You’re free to believe what you want, but you should probably reevaluate your position when it’s parroting 1:1 what Chinese bots are spreading. reply shortsunblack 21 hours agoprevIf Intel is so important to national security, it should be nationalized. If Intel is not willing to willingly invest into U.S. manufacturing, it can be targeted with tariffs. A corporate handout by the taxpayer is not what should happen, though. And yes, stock buybacks are a form of market manipulation. That's why they were banned before Reagan. Funnily enough, SEC unbanned stock buybacks by using the Chevron deference, which is currently being challenged in courts. EPA being unable to regulate climate change might be offsetted by a minor win of making SEC not ignore law anymore by asserting its legitimacy. reply prepend 21 hours agoparentNationalizing is unlikely to increase productivity and innovation. There’s multiple competing goals here and we need to think about how to achieve them. If we think that Intel is fixed and unlikely to need to change, perhaps nationalize and then just operate it as it slowly declines. But that’s also going to make other chip companies less likely to invest in the US as few investors want their investments nationalized. The purpose of these economic investments isn’t primarily moral justice (although I think that should be part of the calculation). The purpose is to increase US chip production. It seems quite silly to think that nationalizing Intel would lead to greater US chip production. reply shortsunblack 20 hours agorootparentChina is banning Intel and AMD chips from their gov't use. When they catch up with tsmc in 7nm, they'll likely make an import ban on all U.S. chips. Who then will AMD and Intel sell to? Aging European population? Africa as it develops? Africans are likely to buy Chinese chips, seeing for all the material infrastructure China invests in. Intel and AMD will only sell to American-alligned countries, which are declining. Seizing the company and milking till it runs dry is the right move. Intel had all the capital it needed to innovate. It did not. The company is unable, despite all the cash it has on hand. It's a lost cause. One hopes AMD continues innovating. reply constantcrying 19 hours agorootparentThis is completely delusional. China isn't the entire world and trashing your own manufacturing because one market might somewhat soon see increased competition is a legitimately insane policy proposal. Also Intel did innovate, very clearly so and they don't compete with AMD when it comes to manufacturing at all. reply shortsunblack 19 hours agorootparentAMD has 1.5x larger market cap than Intel. All in 7 or so years where it was near bankruptcy. During AMD's weakness, Intel had near monopoly position on chips. It racked up all the cash it could. It hasn't innovated ever since. Chiplets came from AMD, 6 cores as minimum standard came from AMD (Intel sold 4 core entry CPUs well into Zen era because that's all you need!). Affordable motherboards (together with partners) and strong commitment to socket longevity came from AMD (AM4 is still supported and new products with 5600x3d are still released). In reference, Intel before AMD's Zen would release a new socket for each yearly release. And in fabs, Intel just isn't nowhere close. How's the 12nm++++++++++++ going? China is 5.2B of AMD's sales (2022). That's 65% of U.S.' with enormous growth potential as Chinese middle class gets richer. Europe is 1.77B of AMD's revenue. How does the capex investment equation play out when your 5.5B of sales just disappears into thin air? reply constantcrying 18 hours agorootparentMarket caps are literally made up by how investors feel. Intel and AMD aren't competitors in manufacturing semiconductors, as in they literally do not compete in that market. AMD isn't manufacturing, they are totally irrelevant when it comes to the discussion. >It hasn't innovated ever since. What are you on about? This is ridiculous. Do you know anything at all about this subject. reply sloowm 20 hours agoparentprevThe main problem of course is that the US government is so dependent on a single company because they allowed the instruction set to be protected IP since forever, allowed imports from countries without demanding they provide the same labor and environmental protections and they didn't invest in a well educated population that would allow for new advancements to be homegrown. If the buybacks are undesirable they should tax them. If Intel is trying to divest they should start working towards alternatives and put the government contracts towards companies that do not create these issues. reply Workaccount2 20 hours agorootparentThe instruction set has nothing to do with semiconductor fabrication... The reason Intel is the only one is because cutting-edge chip making is arguably the most capital intensive and challenging industry in the world. There are literally only three companies on Earth who do it. reply paxys 20 hours agoparentprevIf we ban stock buybacks then should we ban companies from issuing new shares as well? Why is one manipulation but not the other? reply nabla9 21 hours agoparentprev> And yes, stock buybacks are a form of market manipulation. Stock buybacks are not different from dividends, except for tax reasons. reply gmm1990 20 hours agorootparentthey reduce the supply of stock available, that is a difference. If its material is a different question, I'd argue it is but don't have data to back that up. If a company has to buy back 10 billion in stock over a fixed time period market participates should be able to drive up the stock price knowing they will have a buyer (the company) to sell to later. reply nabla9 20 hours agorootparentLets go this trough: Before: I own 100 stocks worth $100 each. =$10000. Option 1: 2% dividend. I have 100 stocks worth $98 each + $200 =$10000. Stock value drops immediately. Option 2: equal sized buyback: I have 100 stocks worth of $100 each = $1000. Buyback does not increase the stock value immediately. Company pays $200 for those who sell, but owns the stocks (or shareholders 'own them') so it's net neutral. This reduces the number of shares outstanding, thereby inflating (positive) future earnings per share. This typically leads to the value increasing. reply maxerickson 18 hours agorootparentprevBeing taxed differently is pretty significant. Kind of weird to impose a tax and then also have an easy way around it. reply nabla9 16 hours agorootparentIt just delays taxation. It's more important for small investors in the US, because in the US even index funds must pay tax for dividends. Here in EU we can buy US index funds not available for US citizens where dividends are reinvested without tax. For us it does not matter that much. reply maxerickson 13 hours agorootparentIn a hand wavy theoretical sense you can maybe say it \"just\" delays taxation, but shareholders aren't going to go out of their way to ensure that they sell at a price that incurs the equivalent taxation. And then a tax that sort of directly relates back to the cashflow of the company is not equivalent to a tax that is based on the capital gains that shareholders end up with. reply wakawaka28 20 hours agoparentprevIt would be unfair to only put tariffs on Intel. Maybe tariffs could be part of the solution to retain essential production capacity in the US though. It should have been done before production left, though. Right now there is very little production left in the US for anything. reply transcriptase 22 hours agoprevBecause without it they will build somewhere cheaper to operate and then U.S. doesn’t have a fab if/when China absorbs Taiwan. It’s not that difficult of a concept. And no, like others will inevitably suggest you can’t just legislate a multinational company to build its facilities onshore because you need them to. If you need something from a company you make it worthwhile, which is what’s happening here. reply justin66 21 hours agoparent> And no, like others will inevitably suggest you can’t just legislate a multinational company to build its facilities onshore because you need them to. It’s weird that people have forgotten this is a thing the government can do. reply transcriptase 21 hours agorootparentEven weirder that people have forgotten about the concept of second order effects. Which would cost the nation more? a) Setting a modern precedent that any company doing business in the U.S. can suddenly be treated as if they’re somehow owned by the U.S. government and forced to make capital expenditures against their will. b) A $8 billion subsidy that will eventually be recouped or at least offset by economic benefits. reply justin66 20 hours agorootparentI was just pointing out the silliness of acting as if a possible thing that’s been done before is impossible. I wasn’t advocating a course of action. Pretty much every time we arrange things to favor or necessitate domestic production in an industry, it’s done in the name of security (defense contracting and agriculture come to mind). Including semiconductors in that category is not crazy, and there is certainly more than one way to bring about those incentives. reply pjc50 20 hours agorootparentprev> Setting a modern precedent that any company doing business in the U.S. can suddenly be treated as if they’re somehow owned by the U.S. government and forced to make capital expenditures against their will. It's amazing how many people on here seem to think that the first response to China should be to turn the US into China and start doing state-directed capitalism. Maybe \"disappear\" a few dissident CEOs. reply transcriptase 20 hours agorootparentNo kidding. I never thought I would see a thread on here polluted with people saying the United States should start behaving like an authoritarian communist apparatus and nationalize or arbitrarily coerce corporations versus coming to a mutually beneficial financial arrangement. reply justin66 20 hours agorootparentI'm just impressed by how people are willing to, out of ignorance or... whatever, write things that obviously not true and then caricature other commentators as communists. I imagine this level of dialog exists on Fox News websites or something, but you should try harder here. reply transcriptase 19 hours agorootparentFor what it’s worth I wasn’t referencing you specifically. There were, at the time of my last reply, people elsewhere in this comment section advocating for exactly what I mentioned. My apologies. reply justin66 18 hours agorootparentThanks. reply eecc 22 hours agoparentprevWell, no? You can always target the company wirh crippling import tariffs unless it gets onto a roadmap to re-shore the strategic production you want them to. Of course, whether it works or not depends on your leverage as a country: the US should easily pull it off, it's the legislator that doesn't want to play that card for political positioning reasons. reply transcriptase 22 hours agorootparentCrippling tariffs on the thing you’re trying to secure access to. And what happens when China says to Intel “here’s 60 billion a year, don’t worry about America just keep doing what you do best”? reply ethanbond 21 hours agorootparentEasy: https://en.wikipedia.org/wiki/Merck_&_Co.?wprov=sfti1#Nation... reply constantcrying 19 hours agoparentprev>And no, like others will inevitably suggest you can’t just legislate a multinational company to build its facilities onshore because you need them to. Of course you can. But if you do, you have to accept the consequences. Again and again people here pretend that just becythe government does it there will be no consequences. reply lancesells 21 hours agoparentprevI'm not advocating or endorsing China invading Taiwan here but would that mean chips stop coming? Or is the fear they get backdoored? Would $8B be better used for a startup instead of IBM? Or is $8B far too low for a new company. reply pjc50 20 hours agorootparentCapturing TSMC intact by force is .. unlikely. Assuming it survives the fighting, there's definitely both Taiwanese and US factions advocating for blowing it up. https://press.armywarcollege.edu/cgi/viewcontent.cgi?article... ; all it would take is one patriotic officer in the retreat to decide to deny it to the enemy by chucking a grenade in the clean room, and the equipment is toast. Russia burnt down Moscow to deny it to Napoleon, and Hitler ordered that the same be done to Paris (but in that case the officers decided not to obey). A more likely scenario is simply that threats and internal political pressure cause Taiwan to \"\"voluntarily\"\" unify with the mainland. $8bn buys you about one (1) fab, but you also need the staff and institutional knowledge to run it, so realistically it has to go to some company that is already operating a similar fab. reply anonymousDan 22 hours agoparentprevI mean, you quite clearly can legislate that. Whether it's a good idea or nonis a separate question. reply transcriptase 22 hours agorootparentTrue. It comes down to whether or not it will cost more than $8 billion to attempt. And what would the enforcement mechanism be? “Sorry Intel, if you’re not going to play along with our attempt to coerce you into making sure we have a supply of chips then we’re not going to allow you to sell chips here.” Seems a bit self-defeating. reply ethanbond 21 hours agorootparentIt has worked just splendidly before: https://en.wikipedia.org/wiki/Merck_&_Co.?wprov=sfti1#Nation... reply ejb999 22 hours agoparentprevtariffs and or new taxes on the chips imported from other countries would have served that same purpose - without the need for more billions of corporate welfare. reply eterevsky 21 hours agoprevStock buybacks are just a form of dividends. It's still subject to taxation via capital gains tax. Subsidy is just a way to create an incentive for Intel to build manufacturing facilities in the US. It's not paid because Intel lacks funds, but to ensure that factories are built in the US and not elsewhere. Intel can do whatever it wants with the money received from subsidies, provided it fulfills its obligations. Jobs aren't particularly important in this schema, but they are a nice talking point for politicians to show that at least part of the money paid via subsidies will return to American workers. reply specialist 19 hours agoparentAs stated elsethread, buybacks defer taxation. It allows the investor to control the timing of the taxable event. reply paol 22 hours agoprevIt doesn't need it, it's simply in a position where it can get it. From their perspective it's free money. It's the same situation with car manufacturers, they do this all the time. They get massive subsidies (usually in the form of permanent tax breaks) by pitting the governments of prospective factory sites against each other. (It's actually a form of the prisoner's dillema: governments would benefit in the net if no-one offered these subisdies, but the prize for defecting is just too great so someone always does.) reply vitiral 22 hours agoprevSomebody correct me if I'm wrong. I always thought of \"stock buybacks\" as a form of \"debt payment\". Stocks are created by companies out of thin air, as a tech worker I am (partially) paid in stocks. Those stocks aren't purchased by my company on the open market, they are manifested -- diluting shareholder stock. Buybacks put a payment on that \"loan\". I doubt people would be so up in arms about companies paying off their debt, even prematurely. The number I'm more interested in is total stock buybacks / total stocks issued, which of course is never reported. Am I wrong here? reply ourmandave 21 hours agoparentNot correcting you, but Investopedia has a f-ckton of articles on the basics of stocks and buy backs. Stock Buybacks: Why Do Companies Buy Back Shares? https://www.investopedia.com/ask/answers/042015/why-would-co... KEY TAKEAWAYS Companies do buybacks for various reasons, including company consolidation, equity value increase, and looking more financially attractive. The downside to buybacks is they are typically financed with debt, which can strain cash flow. Stock buybacks can have a mildly positive effect on the economy overall. Search for 'stock buy back' https://www.investopedia.com/search?q=stock+buy+back reply vitiral 21 hours agorootparentSo the article seems complete, but literally doesn't even mention continuous dilution due to employee compensation or related issues. It only mentions \"issuing stock\" like it's a single event instead of a continuous process. reply pjc50 20 hours agoparentprevEquity is specifically NOT a debt, but you're right that it's just the mirror image of stock issuance. See my other comment about it being a means of returning money to investors like dividends. reply justin66 21 hours agoparentprev> I always thought of \"stock buybacks\" as a form of \"debt payment\". That’s obviously wrong. What follows will be wrong. You’re welcome. reply huntertwo 22 hours agoparentprevYes you’re wrong - it’s literally not paying back debt. It’s an attempt to appease stockholders because their actual financials can’t keep up, thus reducing the price of the stock, thus reducing the compensation packages of the executives and wealth of the board, who is also elected by shareholders. reply vitiral 22 hours agorootparentI mean I get that argument too. But is what I said wrong? Isn't stock being continually issued, diluting the value over time? If buybacks were _never_ done, wouldn't it keep getting diluted forever? Edit: for instance, if Google has 200,000 employees and is granting an average of $50,000 stock per year, that is $10 billion. So id be okay with buybacks of that size. The actual buybacks are much bigger if memory serves, so that seems like manipulation like you're saying reply spicyusername 21 hours agorootparentOne thing that bothers me about the current economy is that most tech workers are are paid in stock and most Americans are required to invest to retire. This is basically a net fiscal transfer from regular Americans to tech workers, since tech stocks are typically the default investment when retirement is more than a decade away, artificially raising the price of tech stocks. Tech workers sell now while the price is artificially high and everyone else is left gambling later after all the tech workers have cashed out. reply lp4vn 22 hours agoprevThat shows the dominance of the financial market and the economic power over the structures of society. We find completely normal hundreds of billions be redirected to the owners of the capital but we would find an anomaly to think of a technological project that could bring real progress and costed that much. reply giantg2 21 hours agoprev$152B in buybacks and the stock is still not trading high. Still not interested. Feels like Intel is basically at the GE stage of impending decline due to over corporatization. reply Workaccount2 20 hours agoprevSites like commondreams (and their conservative counterparts) should just be blacklisted from being posted here. Seriously, it's hyper-partisan ideological brain damage material solely meant to foster clicks and outrage. reply blackoil 22 hours agoprevUS wants me fabs in-house. For company, Korea/Taiwan or Israel may make more sense. So, US is paying up for it. reply BeetleB 17 hours agoprev> Intel CEO Pat Gelsinger hauled in $179 million in 2021, most of it coming from stock-related compensation. When I see statements like this, I know to stop reading. No he didn't make $179M. He was awarded PSUs that will mature only if Intel stock hits a certain price (in a window of N years). Not only did it not hit that price, it has been down considerably. The grants will likely expire before Intel's price hits those goals (I think the lowest target is in the 80 dollars). His actual compensation that year? About $10M - quite a bit of it being a sign on bonus. reply belter 22 hours agoprevBetween 1998 and 2018, Boeing spent more than $61.0 billion in stock buybacks. The budget for the development of the MAX was US$4 billion reply tester756 21 hours agoprevtitle manipulation original title is: \"Intel Brags of $152 Billion in Stock Buybacks Over Last 35 Years.\" Current HN title made me think that they plan to spend $152 b on buyback in the future reply 31 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Biden administration is in talks to offer Intel Corp. more than $10 billion in subsidies, raising concerns due to the company's history of $152 billion in stock buybacks over 35 years.",
      "There is speculation about the necessity of the subsidy for Intel and whether it might end up being utilized for additional stock buybacks, stirring questions among observers.",
      "The substantial subsidy negotiations with Intel prompt discussions regarding the potential use of public funds in light of the company's extensive buyback activity in the past."
    ],
    "commentSummary": [
      "Intel's $152B stock buybacks and $8B government subsidy for a US fab spark debates on the efficacy of subsidies, stock buybacks, and government involvement in industries.",
      "Discussions include differing views on nationalizing Intel for national security, worries about market manipulation, and the significance of semiconductor manufacturing in the US.",
      "Also debated are coercive measures to secure access to critical production and the delicate balance between economic advantages and security considerations."
    ],
    "points": 229,
    "commentCount": 281,
    "retryCount": 0,
    "time": 1711624324
  }
]
