[
  {
    "id": 38381573,
    "title": "Reflecting on 18 Years at Google: A Call for Leadership Change and Restoration of Values",
    "originLink": "https://ln.hixie.ch/?start=1700627373&count=1",
    "originBody": "2023-11-22 04:29 UTC Reflecting on 18 years at Google I joined Google in October 2005, and handed in my resignation 18 years later. Last week was my last week at Google. I feel very lucky to have experienced the early post-IPO Google; unlike most companies, and contrary to the popular narrative, Googlers, from the junior engineer all the way to the C-suite, were genuinely good people who cared very much about doing the right thing. The oft-mocked \"don't be evil\" truly was the guiding principle of the company at the time (largely a reaction to contemporaries like Microsoft whose operating procedures put profits far above the best interests of customers and humanity as a whole). Many times I saw Google criticised for actions that were sincerely intended to be good for society. Google Books, for example. Much of the criticism Google received around Chrome and Search, especially around supposed conflicts of interest with Ads, was way off base (it's surprising how often coincidences and mistakes can appear malicious). I often saw privacy advocates argue against Google proposals in ways that were net harmful to users. Some of these fights have had lasting effects on the world at large; one of the most annoying is the prevalence of pointless cookie warnings we have to wade through today. I found it quite frustrating how teams would be legitimately actively pursuing ideas that would be good for the world, without prioritising short-term Google interests, only to be met with cynicism in the court of public opinion. Charlie's patio at Google, 2011. Image has been manipulated to remove individuals. Early Google was also an excellent place to work. Executives gave frank answers on a weekly basis, or were candid about their inability to do so (e.g. for legal reasons or because some topic was too sensitive to discuss broadly). Eric Schmidt regularly walked the whole company through the discussions of the board. The successes and failures of various products were presented more or less objectively, with successes celebrated and failures examined critically with an eye to learning lessons rather than assigning blame. The company had a vision, and deviations from that vision were explained. Having experienced Dilbert-level management during my internship at Netscape five years earlier, the uniform competence of people at Google was very refreshing. For my first nine years at Google I worked on HTML and related standards. My mandate was to do the best thing for the web, as whatever was good for the web would be good for Google (I was explicitly told to ignore Google's interests). This was a continuation of the work I started while at Opera Software. Google was an excellent host for this effort. My team was nominally the open source team at Google, but I was entirely autonomous (for which I owe thanks to Chris DiBona). Most of my work was done on a laptop from random buildings on Google's campus; entire years went by where I didn't use my assigned desk. In time, exceptions to Google's cultural strengths developed. For example, as much as I enjoyed Vic Gundotra's enthusiasm (and his initial vision for Google+, which again was quite well defined and, if not necessarily uniformly appreciated, at least unambiguous), I felt less confident in his ability to give clear answers when things were not going as well as hoped. He also started introducing silos to Google (e.g. locking down certain buildings to just the Google+ team), a distinct departure from the complete internal transparency of early Google. Another example is the Android team (originally an acquisition), who never really fully acclimated to Google's culture. Android's work/life balance was unhealthy, the team was not as transparent as older parts of Google, and the team focused on chasing the competition more than solving real problems for users. My last nine years were spent on Flutter. Some of my fondest memories of my time at Google are of the early days of this effort. Flutter was one of the last projects to come out of the old Google, part of a stable of ambitious experiments started by Larry Page shortly before the creation of Alphabet. We essentially operated like a startup, discovering what we were building more than designing it. The Flutter team was very much built out of the culture of young Google; for example we prioritised internal transparency, work/life balance, and data-driven decision making (greatly helped by Tao Dong and his UXR team). We were radically open from the beginning, which made it easy for us to build a healthy open source project around the effort as well. Flutter was also very lucky to have excellent leadership throughout the years, such as Adam Barth as founding tech lead, Tim Sneath as PM, and Todd Volkert as engineering manager. We also didn't follow engineering best practices for the first few years. For example we wrote no tests and had precious little documentation. This whiteboard is what passed for a design doc for the core Widget, RenderObject, and dart:ui layers. This allowed us to move fast at first, but we paid for it later. Flutter grew in a bubble, largely insulated from the changes Google was experiencing at the same time. Google's culture eroded. Decisions went from being made for the benefit of users, to the benefit of Google, to the benefit of whoever was making the decision. Transparency evaporated. Where previously I would eagerly attend every company-wide meeting to learn what was happening, I found myself now able to predict the answers executives would give word for word. Today, I don't know anyone at Google who could explain what Google's vision is. Morale is at an all-time low. If you talk to therapists in the bay area, they will tell you all their Google clients are unhappy with Google. Then Google had layoffs. The layoffs were an unforced error driven by a short-sighted drive to ensure the stock price would keep growing quarter-to-quarter, instead of following Google's erstwhile strategy of prioritising long-term success even if that led to short-term losses (the very essence of \"don't be evil\"). The effects of layoffs are insidious. Whereas before people might focus on the user, or at least their company, trusting that doing the right thing will eventually be rewarded even if it's not strictly part of their assigned duties, after a layoff people can no longer trust that their company has their back, and they dramatically dial back any risk-taking. Responsibilities are guarded jealously. Knowledge is hoarded, because making oneself irreplaceable is the only lever one has to protect oneself from future layoffs. I see all of this at Google now. The lack of trust in management is reflected by management no longer showing trust in the employees either, in the form of inane corporate policies. In 2004, Google's founders famously told Wall Street \"Google is not a conventional company. We do not intend to become one.\" but that Google is no more. Much of these problems with Google today stem from a lack of visionary leadership from Sundar Pichai, and his clear lack of interest in maintaining the cultural norms of early Google. A symptom of this is the spreading contingent of inept middle management. Take Jeanine Banks, for example, who manages the department that somewhat arbitrarily contains (among other things) Flutter, Dart, Go, and Firebase. Her department nominally has a strategy, but I couldn't leak it if I wanted to; I literally could never figure out what any part of it meant, even after years of hearing her describe it. Her understanding of what her teams are doing is minimal at best; she frequently makes requests that are completely incoherent and inapplicable. She treats engineers as commodities in a way that is dehumanising, reassigning people against their will in ways that have no relationship to their skill set. She is completely unable to receive constructive feedback (as in, she literally doesn't even acknowledge it). I hear other teams (who have leaders more politically savvy than I) have learned how to \"handle\" her to keep her off their backs, feeding her just the right information at the right time. Having seen Google at its best, I find this new reality depressing. There are still great people at Google. I've had the privilege to work with amazing people on the Flutter team such as JaYoung Lee, Kate Lovett, Kevin Chisholm, Zoey Fan, Dan Field, and dozens more (sorry folks, I know I should just name all of you but there's too many!). In recent years I started offering career advice to anyone at Google and through that met many great folks from around the company. It's definitely not too late to heal Google. It would require some shake-up at the top of the company, moving the centre of power from the CFO's office back to someone with a clear long-term vision for how to use Google's extensive resources to deliver value to users. I still believe there's lots of mileage to be had from Google's mission statement (to organize the world’s information and make it universally accessible and useful). Someone who wanted to lead Google into the next twenty years, maximising the good to humanity and disregarding the short-term fluctuations in stock price, could channel the skills and passion of Google into truly great achievements. I do think the clock is ticking, though. The deterioration of Google's culture will eventually become irreversible, because the kinds of people whom you need to act as moral compass are the same kinds of people who don't join an organisation without a moral compass. Pingbacks: 1 2 3 4 5",
    "commentLink": "https://news.ycombinator.com/item?id=38381573",
    "commentBody": "Reflecting on 18 Years at GoogleHacker NewspastloginReflecting on 18 Years at Google (hixie.ch) 1769 points by whiplashoo 17 hours ago| hidepastfavorite860 comments pardoned_turkey 16 hours agoIan&#x27;s post is pretty incisive, although I&#x27;ve read so many of these over the past 15 years or so. And the prescription is always to go back in time.I don&#x27;t really think that&#x27;s possible. When you&#x27;re a newcomer, a disruptor, the whole point is to be different. You&#x27;re bold, you have a clarity of purpose, you say things like \"we&#x27;re building a new kind of a company\" or \"the user comes first.\"But once you achieve market dominance, your priorities have to shift. It&#x27;s no longer \"why wouldn&#x27;t you try this\" or \"let&#x27;s do the right thing.\" It&#x27;s \"why would you rock the boat and risk the nice thing we have?\" It&#x27;s not just about profit. Careers and incomes are at stake. People will get hurt.Risk tolerance aside, your organizational structure ossifies too. When you have people who have been running processes or departments in a particular way for fifteen or twenty years, they have little desire to start over from scratch. And that&#x27;s not necessarily a bad thing, because what&#x27;s the alternative? A cutthroat corporate environment where you&#x27;re never sure about the future of your job?I think the only comedy here is that Google looked at these old-school companies like Microsoft or IBM and figured they can be different just because they \"get it.\" And then, over time, they rediscovered the reasons why old companies always end up operating in a particular way. reply eslaught 16 hours agoparentWhen I was an intern at Google circa 2010, there was a guest lecture from a business professor who described exactly this process. At the end of it, he made a comment like, \"Of course none of this will happen to Google. You&#x27;re too innovative.\" But literally every single prediction of his came true, and I witnessed some of them happening in front of my own eyes even in just the months that I was there (and certainly in the years that followed, though I was no longer with the company). reply somenameforme 3 hours agorootparentThere was a really interesting interview [1] with Astro Teller, the head of Google&#x27;s moonshot &#x27;x division&#x27;, in 2016. In terms of project selection, he focuses on trying to dismiss projects early on, by looking for reasons that a project might fail. And even rewarding employees for scrapping things early on. That doesn&#x27;t sound particularly unreasonable, but it largely just amounts to a conservative planning process. So then what exactly is the difference between a &#x27;moonshot&#x27; and a regular new project?And so when you look at this sort of selection process it ends up being unsurprising that Google&#x27;s &#x27;moonshots&#x27; ended up being things like Waymo, Google watches, glasses, drone delivery, and so on. One of the largest companies in the world, with some of the deepest pockets in the world, and their &#x27;moonshots&#x27; are things dozens of other companies are building as well. It seemed quite telling of the present and future of Google.[1] - https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;astro-teller-captain-of-moonshots-... reply bobviolier 3 hours agorootparentAt that time, others companies were not building most of those things though. reply konschubert 3 hours agorootparentprevBuilding the best self driving car in the world is amazing , come on! reply e_y_ 13 hours agorootparentprevOn paper, Google&#x27;s throw-everything-at-the-wall-and-see-what-sticks strategy (that has lead to a substantial Google Graveyard) seems like it was intended to allow for some parts of the company to innovate while keeping the core products stable and boring. In practice, many of those innovations (Google Inbox, anyone?) were not deemed profitable enough to keep around. Others were never given the resources to grow beyond an experiment. And even with a long leash, a big company project is never going to innovate as quickly as a startup.This year, however, with the extremely deep cuts to Google&#x27;s internal incubator (Area 120), it seems pretty clear that they&#x27;ve given up on this strategy, at least for anything that isn&#x27;t somehow AI-related. reply eslaught 9 hours agorootparentIt&#x27;s worth noting that was a turning point: the \"more wood behind fewer arrows\" policy adopted by Larry [1] initiated the die-off cycle of Google products. Prior to that, as far as I am aware, they were much more tolerant of products staying around in a mature-but-not-wildly-successful state. Afterwards, it seemed as if they would only keep things that maintained a trajectory to become as successful as their core products.Again, this was not entirely unpredictable. While I don&#x27;t remember the details of that lecture, I remember the professor calling out these sorts of big shifts in cultural values as being typical of startups transforming into large companies. And Larry himself was part of the transformation, turning into (presumably, what he believed to be) what was needed to lead Google into its next stage as a large company.[1]: https:&#x2F;&#x2F;googleblog.blogspot.com&#x2F;2011&#x2F;07&#x2F;more-wood-behind-few... reply leoc 8 hours agorootparentWhat’s remarkable is that that phrase was already, at that time, notorious for having been a portent of doom at Sun Microsystems. reply ChrisArchitect 4 hours agorootparent..and now all that&#x27;s left of Sun is the wood on the back of the Meta sign. reply jmcguckin 7 hours agorootparentprevAll the wood behind one arrow… reply jacquesm 6 hours agorootparentprevThey made - and still make - one crucial error: you need to spin those projects that are simply viable out immediately after they take root. Otherwise you will end up with the brand advantage but there will always be the pressure to use the resources (people, mostly) more efficiently in terms of ROI. And so nothing ever lasts and slowly but surely your reputation as a reliable partner for new products is eroded.You can use your main brand for the launch, but then you have to be willing to support the child. reply jjulius 12 hours agorootparentprev>Google InboxStill so damn bitter about that death. reply Aeolun 9 hours agorootparentIt’s weird that Gmail never reached that point. Even years later it’s still the same it was 10 years ago.I think after inbox died I just gave up on it and moved to fastmail. reply wyclif 8 hours agorootparentI understand what you&#x27;re saying (I miss Inbox, too). But end users like sameness and \"it just works.\" Normies prefer stability over innovation when they are trying to get stuff done. reply abirch 8 hours agorootparentNormies like sameness, this is why God gave us configs. You can default to normal but let the crazies customize. reply ssd532 2 hours agorootparentprevIt is the best email client I have ever used. reply foxp2 9 hours agorootparentprevI miss Inbox features too. Shortwave is nice if you want something similar today. reply teen 13 hours agorootparentprevI mean that incubator was a total waste of money. No one did anything, everyone was a bser from the top, and 95% of the projects were total failures. I think there were maybe 3 \"successful\" projects. reply seraphsf 11 hours agorootparentI ran one of the successful projects in Area 120.I joined Area 120 with huge skepticism. It was hamstrung and inefficient in its own ways. And I agree it didn’t reach its potential - largely because it was encased in Google 2020 instead of Google 2007.But to my surprise almost all of the projects were impressive, well-conceived, promising bets. And the people in Area 120 were among the top 10% of Googlers I worked with in my decade at the company.Google killed Area 120 because of bureaucracy and politics, full stop. Google is worse off because of it. reply jklm 8 hours agorootparentSomewhat spicy take - if the people in Area 120 were among the top 10% of Googlers you worked with, they probably weren&#x27;t the right builders to start a new vertical.Most of what makes people effective at large companies is neutral or negative value when applied to very early-stage companies. reply seraphsf 4 hours agorootparentYou’re not wrong. They were among the top 10% of people I worked with in terms of passion, commitment, and creativity. They weren’t among the top 10% in terms of their skill in navigating Dilbert-land corporatism.A significant number of the people in Area 120 projects were folks who were stifled and&#x2F;or wasted in their previous Google jobs. One explicit purpose of Area 120 was to prevent the loss of these entrepreneurs to outside startups. Not incidentally, this was a form of cultural reinforcement - Area 120 burnished Google’s reputation as a good home for entrepreneurial mindsets. reply vincnetas 3 hours agorootparent\"One explicit purpose of Area 120 was to prevent the loss of these entrepreneurs to outside startups\"So basically google had a shed where they hoarded talented people, to prevent competition? :) reply tomrod 6 hours agorootparentprevThat assertion applies to the middle 80%, IME. The top 10% are the people you can drop on to any project of any size and any org structure and they adapt quickly and deliver. They adapt themselves accordingly. reply mk89 12 hours agorootparentprev3 successful projects can totally justify what you call waste of money.I sometimes wonder what people expect innovation is. You try and try and try. One thing is good and you must know how to use it - it can make history.If I understood right, chatgpt comes from one of such ideas.... so the question is also: who evaluates the ideas? How come that Google was not able to capitalize on that idea?So yeah, instead of treating the cause they treat the symptoms, like usual. reply lapphi 8 hours agorootparentAgreed, we are on ycombinator.com, after all. The patron saint of failed ideas. reply 121789 12 hours agorootparentprevI think this is why these teams are really hard to have in a mature org. In reality maybe 5% of projects in one of these innovation orgs is actually great! But it’s impossible to evaluate and everyone else is thinking some variant of “this team is able to bs and show no value, while I have to hit real goals or risk being fired?”I think the incentives would have to be much different for it to work (e.g. much lower base pay + higher rewards for success)…..but at that point just join a startup reply seraphsf 11 hours agorootparentWhich 5% of projects are really great? In my experience, presuming you have tight filters such that all of your projects are plausibly potentially great, you really don’t know until you try. That’s the point of an incubator.It’s not that hard to evaluate when something is working (ie the hard part in evaluation is false negatives, not false positives).In Area 120’s case there was no coasting - if anything there was a hair-trigger standard to shut down underperforming projects. reply compiler-guy 12 hours agorootparentprevPretty standard rate of failure for early stage startups. reply gedy 12 hours agorootparentprevI think these type of teams are a good way to give talented devs a break from the grind at bigger companies, even if the chances of a new product is low.Not every company can afford these \"paid vacations\", but they do have some use at times. reply htrp 11 hours agorootparentprev> at least for anything that isn&#x27;t somehow AI-related.If you can&#x27;t innovate at the base level of app design .... how do you have any hope of innovating for AI apps that require research&#x2F;engineering&#x2F;product&#x2F;marketing collaboration? reply nextos 10 hours agorootparentThat&#x27;s true. What they need is what they had started doing, i.e. breaking down Google into Alphabet and letting some companies within the conglomerate act like startups.Why was this effort unsuccessful? Perhaps they were unable to get rid of middle management? I have had lengthy discussions with employees from several of their companies, e.g. Calico, and that seemed to be the case. This article only reinforces my view. reply chii 10 hours agorootparent> Why was this effort unsuccessful?i suspect that they are unsuccessful for two reasons: failure is not death, and success is not riches (for those who did the work). reply nstart 7 hours agorootparentprevIf I recall past discussions on this topic correctly, it wasn’t just about profits. I believe the incentive structures are setup around launches and not maintenance. If that’s correct, then that would lead to people launching, collecting rewards (bonuses, promotions, etc) and then abandoning. reply bicepjai 10 hours agorootparentprevI think you are talking about “innovators dilemma” great book by the way reply rizky05 6 hours agorootparentprevMicrosoft today is more innovative than google IMO. They keep executing bold and controversial strategies, even though being older than google. reply hinkley 15 hours agorootparentprevI once noted that several of my coworkers and I had created a silent conspiracy to get a certain manager to clearly and concisely state her very bad ideas in front of the entire staff.This was not news to one of the other two people. He confessed he was doing it “for sport” and thought we were in on it. Only sort of.I think this statement might have been his little way to entertain himself. reply pas 14 hours agorootparentcan you give a few examples of what kind of bad ideas? like everyone should do all nighters or let&#x27;s use email as the only login, no need for password for the first iteration, we will fix it later, or ... ? reply hinkley 5 hours agorootparentIt’s been long enough that I’ve successfully blocked a lot out, but it all kind of started because she put some terrible bullshit velocity graph up in a staff meeting that made our good weeks look like bad weeks and bad weeks look good. Derailed the whole meeting as people explained project management to a project manager.Then the next staff meeting she put up the same graph. We explained five better ways to display the data.All summer long, same graph, every meeting. At some point the relationship died. reply benvolio 15 hours agorootparentprevSeems like this is referring to Clayton Christensen’s Where Does Growth Come From? talk:https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=rHdS_4GsKmg reply w4yai 12 hours agorootparentThanks for sharing ! Spent the last hour watching it, it was illuminating. reply miohtama 14 hours agorootparentprevThis is called Scumpeter&#x27;s creative destruction (to be distinguished from other creative destruction) and why large companies may lose the ability to be innovative and competehttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Creative_destructionHowever. it&#x27;s hard to see Google&#x27;s core business dominance, search and ad, to be destroyed very easily. It&#x27;s also super confusing that no other entity has been able to create a matching service and we do not have search duopoly similar to Visa Mastercard. reply immibis 2 hours agorootparentPeople are already lamenting the lack of useful results in Google Search, and adverts aren&#x27;t returning as much value as they used to, and there&#x27;s been a rise in modified client apps without ads as a reaction to ads being spammed on certain services. reply makeitdouble 11 hours agorootparentprevI&#x27;m not sure what you mean by Visa&#x2F;Mastercard duopoly, there&#x27;s a lot of regionality so the picture could be fsirly different depending on what you have in mind.To me Bing as a minority competitior in search, and facebook on ads for instance would be candidates to the same kind of duopoly. reply antupis 14 hours agorootparentprev5 years ago it was hard to see , now I ampersonally using more chatgpt than Google. reply ianmcgowan 13 hours agorootparentYeah, it&#x27;s hard to go back to wading through SEO-optimized BS after just getting a decent answer (which, to be fair to the AI-sceptics, you do have to think about before using blindly).It&#x27;s an interesting mental shift - I wasn&#x27;t googling because I wanted to find a web page, I was googling because I wanted an answer to a question. An AR or mixed-mode personal assistant is going to be a game changer. reply BytesAndGears 10 hours agorootparentThis is also where the paid search engine comes into play. I get to pin Wikipedia so it’s always at the top whenever it’s relevant to my search, and there is almost zero SEO spam. And no ads.I use a mix of that and chatGPT together depending on the specific thing I’m searching for, and it’s truly better than even the old Google. reply barnabee 4 hours agorootparentprevI haven’t used Google as more than an occasional backup for years, and even less since I switched from DuckDuckGo to Kagi a few months back.The more I eliminate anything to do with ads from my life, the better things get, reply Ckirby 8 hours agorootparentprevWhat kind of shallow, bland, inoffensive and disconnected items do you search for that a simple chatbot can spit out? reply danielmarkbruce 13 hours agorootparentprevHard agree. Sold Google stock after realizing I&#x27;d more or less replaced Google Search with chatgpt... reply lifeisstillgood 13 hours agorootparentprevIs that because ChatGPT returns better results, or because when it returns results, it wraps them in words that make you feel more comfortable accepting them as better reply whstl 11 hours agorootparentFor me it&#x27;s because ChatGPT ignores less of what I type than Google currently does, plus it doesn&#x27;t return spammy SEO results.Google has become a search engine for advertisements, \"People also ask\" snippets, shopping listings and SEO spam, in that order. The rest of results is just a bonus.Even stupid things like searching for the Wikipedia entry of a movie or TV show has become super difficult with Google lately, because Wikipedia is often buried. Apple&#x27;s Spotlight is better for that. reply ajross 9 hours agorootparent> Even stupid things like searching for the Wikipedia entry of a movie or TV show has become super difficult with Google lately, because Wikipedia is often buriedI&#x27;m always amazed to see claims like this, given it&#x27;s not how my world works at all. Picking some random popular favorites: searches for (verbatim) \"Loki\", \"Hunger Games\", \"Oppenheimer\", and \"House of Usher\" all return a wikipedia entry in at worst the second spot (generally behind IMDB, though Oppenheimer and Usher showed the real man and the short story ahead of the films, not unsurprisingly).I mean, sure, there are glitches with all products and nothing is beyond criticism. But \"Google buries Wikipedia results\" is just beyond weird. It really seems like HN is starting to develop an \"alternative facts\" syndrome, where the echo chamber starts driving collective memory. reply marcus_holmes 7 hours agorootparentI had the same problem. Less with missing Wikipedia results, but I was definitely getting the first page stuffed with crappy SEO results and ads. I switched to DDG a few months ago and I&#x27;m finding the experience much, much better. I tried switching a few years ago and found DDG&#x27;s search wasn&#x27;t as good. But since then either DDG has got better or Google has got worse. I actually suspect the latter. reply ajross 7 hours agorootparentOK, but this is the \"alternative facts\" thing at work. Grandparent claimed something frankly ridiculous, you say you had the \"same problem\", then you redefine the problem to be, well... not the same thing at all? I mean, of course there are \"SEO\" pages in search results, that&#x27;s literally what \"Search Engine Optimization\" means.And it&#x27;s impossible to know what you mean by it without specifics: are you complaining that a top search result is a useless page of advertisement and AI-generated text (which would be bad), or just that e.g. \"tutorialspoint.com\"[1] or whatever is above Stack Overflow on some search (hardly a disaster).Maybe you have some examples we could try?[1] Or some other vaguely low quality but still legitimate site. reply marcus_holmes 5 hours agorootparentI gave this a go. I typed google.com into my browser. First thing: oh yeah, that&#x27;s right, because I use a VPN google puts me through captchas before letting me search (and I&#x27;m currently logged-in to Google on my gmail ID, so it definitely knows who I am, which is even more annoying). One annoying captcha session later, I can search. (and ofc Google wants to know my location, despite knowing my address as part of my Google ID).I tried \"El Dorado\" because I happened to have that boardgame on a shelf in front of me. Actually the results were pretty good - wikipedia, national geographic, IMDB, no ads. But yeah, not something there&#x27;s going to be many ads on, so let&#x27;s try something more adworthy.So I switched to an Incognito window (many, many captchas) and tried \"erectile dysfunction\". Whole bunch of decent results, no ads until the bottom half of the page (and then it was solid ads of course).I&#x27;ve got to say I was pleasantly surprised - it&#x27;s not nearly as swamped with ads and shitty SEO as I remember. But that&#x27;s the thing, isn&#x27;t it? I only switched to DDG a few months ago because I was so fed up with Google&#x27;s responses (and the endless captchas). I didn&#x27;t dream that ;) But yeah, you&#x27;re correct - the first page of Google isn&#x27;t all ads and SEO crap. HN must be hallucinating that. reply murphy1312 1 hour agorootparentStarted using startpage.com for google results without the ads and its pretty good. reply ajross 4 hours agorootparentprev> I only switched to DDG a few months ago because I was so fed up with Google&#x27;s responses (and the endless captchas). I didn&#x27;t dream thatWell, that&#x27;s the thing... maybe you did? I mean, clearly from context you live in a world awash in the kind of rhetoric we&#x27;re seeing in this topic, with hyperbolic claims about the Descent of Google into Vice and Decay everywhere. And... it&#x27;s easy to fit stuff into a frame if that&#x27;s how you&#x27;re already thinking. One bad result or one unexpected pop up ad can sway a *lot* of opinion even if it&#x27;s an outlier.Thus: \"alternative facts\". In the real world search results are boring and generally high quality because that&#x27;s the way they&#x27;ve been for 20+ years (I mean, come one: it&#x27;s a mature product in a mature market, you really expect it to change much?). But here on HN testimony like that gets voted down below the hyperbolic negativity, so what you read are the outliers.HN, to wit, has become the Fox News of tech. reply marcus_holmes 4 hours agorootparentI can see how you got there from where you started, but I&#x27;m not sure it&#x27;s accurate ;)HN is useful but like all new sources and social media sites, it&#x27;s not the unbiased pure stream of news and educated opinion that we&#x27;d like. Humans are weird. replybombcar 5 hours agorootparentprevTry finding out if Walmart is closed tomorrow. Google results are all SEO spam even though Walmart themselves tweeted about it. reply ajross 5 hours agorootparentDid you try this? First hits are Walmart locations with hours. Followed by \"People also ask\" where the first item (with a correct answer) is \"Will Walmart be open on Thanksgiving near me?\". Followed by proper search results where the top two hits are, indeed, the two nearest Walmarts to me. How exactly would you improve that? Is there a better site to put at the top? reply vram22 10 hours agorootparentprevJust add Wikipedia to the end of your search pattern. reply chipotle_coyote 10 hours agorootparentprevIt&#x27;s because ChatGPT isn&#x27;t being monetized with ads yet. I use \"yet\" quite deliberately, mind you. The question isn&#x27;t whether ChatGPT will eventually have ads; the question is how easily you&#x27;ll be able to tell they&#x27;re ads, or if it&#x27;s going to be product&#x2F;service placement worked into responses as seamlessly as possible. reply martinflack 8 hours agorootparentYou say that, but Google Search is still free after decades, whereas you can pay ChatGPT $20&#x2F;mo for a membership right now. reply esafak 8 hours agorootparentIf only Google offered the option to pay in return for no ads and other junk. But they would say it does not scale; they can&#x27;t count that low. So people are flocking to chatGPT. reply girvo 3 hours agorootparentOn the other hand, Google does exactly that with YouTube? reply esafak 2 hours agorootparentGood on them! I meant for search. They have other paid services. reply bruce511 6 hours agorootparentprevI suspect that by doing so they&#x27;d indicate just how much each user is worth to them in ads.I suspect that folk who opted into this would be the ones getting lots of ads (hence the most valuable.)If Google said \"you can opt out for $99 a month\" you&#x27;d freak out. But you&#x27;re probably worth that (or more).People aren&#x27;t really flocking to ChatGPT though - not yet. Not at Google Scale. It&#x27;s not like my mom will pay $20 a month when she just uses Google for free... reply esafak 5 hours agorootparentGiven that I&#x27;ve moved to Kagi and chatGPT how much are they making off me now? They should have disrupted themselves when they had the chance. reply bruce511 4 hours agorootparentSure some are moving. There are always some moving. But despite the HN bubble effect its a tiny sample.Plus folk moving now are folk who&#x27;ll move back later when they get disgruntled there. (No disrespect.) First movers are not the loyal customer base. Movers gotta be moving..(I say this as a general rule not making an assumption about you personally.)It&#x27;s like even everyone \"left\" Facebook for google+. replyactionfromafar 10 hours agorootparentprevWhat a long con nudge bubble will be woven, in the darkness to bind them. reply janalsncm 11 hours agorootparentprevPersonally it’s because there’s no ads. Google’s UX is to choke the user half to death with cookies, popups, reminders to use their app, login screens, and banner ads. And that’s before we even get to the content, which is padded with SEO and filler, dancing around the point before finally giving an answer written by who-knows-whom.(And yes I feel justified in calling these SEO sites part of Google’s UX because this is exactly the behavior their algorithm and business model are encouraging.) reply fragmede 11 hours agorootparentprevinstead of Googleing and getting a forum post from 2009 where you have to read the whole thread and then interpret the results, ChatGPT just gives you the answer directly. ChatGPT could be shitty and rude about it and it would still be better because it&#x27;s a direct smart to your direct question.what&#x27;s hilarious is the conversation that must have happened inside google about linking to pages vs giving the answer on the search result page, and now where we are with ChatGPT. reply miguno 13 hours agorootparentprevThat&#x27;s what the AI robots will use as an explanation when they have f*cked us up. :-) reply cbsmith 15 hours agorootparentprev\"Of course none of this will happen to Google. You&#x27;re too innovative.\"I would have had a hard time hearing that as anything other than sarcasm. reply capableweb 15 hours agorootparentAbsolutely. And I&#x27;m sure the talker had a \"\" in their transcript, which they had to quickly skip since people were taking it seriously. reply hot_gril 2 hours agorootparentI can see this happening. Same as how \"don&#x27;t be evil\" was a joke outside the company (cause obviously an evil company would say this) but taken seriously by some inside. reply tobinfricke 14 hours agorootparentprev\"Present company excluded\"It&#x27;s a polite fiction. reply cbsmith 11 hours agorootparentExactly. reply Mistletoe 14 hours agorootparentprevThere’s a great book by the guy that wrote The Psychology of Money, Morgan Housel that is out right now and I’m really enjoying it. It’s called Same as Ever.Because what never changes is humans and our source code, our DNA. Expecting Google to not turn into IBM is like expecting wings to sprout from our back. The great delusion we tell ourselves is that each business is different, but each business is powered by the same human engine. That engine evolves at a glacial pace on an evolutionary time scale. When I read about the Dutch East Indian company or a guy in Mesopotamia that can’t get good quality copper from his suppliers and his servant was treated rudely, it’s all the same.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Complaint_tablet_to_Ea-nāṣir reply anonacct37 13 hours agorootparentI don&#x27;t think it&#x27;s literally impossible to avoid the same mistakes as our predecessors. But I do think that the default position that \"oh we modern innovative companies won&#x27;t end up like those stodgy old companies\" is a recipe for repeating history. As they say in AA: the first step to solving a problem is admitting you have it.Because yes by default you will absolutely repeat history unless you acknowledge that those old timey crazy people were fundamentally no different than you. reply efitz 6 hours agorootparent> I don&#x27;t think it&#x27;s literally impossible to avoid the same mistakes as our predecessors.Our predecessors didn’t make mistakes; they made rational choices that led to outcomes we don’t like.We (for some subset of us that become business leaders) will make similar choices that those who come after us will view as mistakes.They will rightfully think that we made the “same” “mistakes” because our rational decisions will be made in response to similar pressures.For example, we are going to make short term optimal&#x2F;long term detrimental decisions, just like our predecessors, because we are subject to the same demands from investors for short term gains and from our leadership to hit short term goals in exchange for increased compensation.Don’t hate the players, hate the game. reply Gravityloss 10 hours agorootparentprevThings tend to repeat but it&#x27;s not completely impossible to have large and lasting changes. Ursula K. Le Guin used to say how people thought inescapable the divine rights of kings.On the other hand, Google did change the world. Everything&#x27;s just more mature nowadays. There&#x27;s less blue ocean in its business segments.I wonder if a company could stay \"evergreen\" by constantly finding new business areas and somehow spinning off old ones? Apple for example almost died in between before really coming back with the iPhone. reply peanutz454 10 hours agorootparentprevHumans have great capacity to learn from our mistakes. Our source code or DNA have no encoding related to running business in a certain way. We mourn old google the revolutionary place, the likes of which could not have existed 100 years ago. But we forget that it was such a revolutionary place that its mere existence was an anomaly of sorts, and also that it spurned us to create several such new places, and that learning will continue us to create many more. reply concordDance 11 hours agorootparentprevBut we have created new types of social institutions despite having the same DNA as our ancestors! Most notably the corporation and the nation-state. reply NoMoreNicksLeft 15 hours agorootparentprev> At the end of it, he made a comment like, \"Of course none of this will happen to Google. You&#x27;re too innovative.\"Yes, but how did everyone listening fail to notice that he winked 3 times in a row, paused silently for 30 seconds and looked disappointed when no one seemed to catch on? reply praptak 15 hours agorootparentThe drummer in the background forgot to do the \"ba-dum tsss\" reply al_be_back 11 hours agorootparentprev>> at Google circa 2010 ... a business professor...sounds like Clayton Christensen reply esafak 11 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Innovator%27s_Dilemma reply yojo 15 hours agoparentprevI think “rediscovering” the old ways of operating is a charitable interpretation that makes it sound like these patterns are somehow better. Silos and fiefdoms don’t benefit the company, they benefit the professional managers that are using them to grow their careers.I subscribe to the interpretation that sufficiently successful companies inevitably attract ladder climbers whose goals are personal advancement at all costs, which may or may not align with the company goals&#x2F;mission.Once enough of these people capture positions of power in the organization, the whole thing tips into a political morass. Unless you’ve got diligent leadership at the top rooting these people out (and how do you think most folks ended up at the top?) you get this cultural death spiral.This is also why “founder led” companies are more dynamic. Founders by definition aren’t ladder climbers, otherwise they would have joined BigCo instead of founding a business. reply closeparen 14 hours agorootparentSilos and fiefdoms allow small gelled teams who know and trust each other, have similar levels of competence, and sit physically near each other to put their heads down and execute with extraordinary speed and quality. Once silos are broken down and cross-team&#x2F;cross-org collaboration becomes valorized, everything is strangers and Zoom meetings and time zones and Process and maybe if you’re lucky one person in your partner org or site who can be trusted to give a straight answer or get something done that wasn’t formally planned a year in advance. The best way to derail a project is to get the greatest number of engineers involved in it, especially engineers who don’t share priorities, timelines, conventions, geography, or language. This is coincidentally also the best way to get promoted at a large company that believes in breaking down silos. reply dasil003 14 hours agorootparent> Silos and fiefdoms allow small gelled teams who know and trust each other, have similar levels of competence, and sit physically near each other to put their heads down and execute with extraordinary speed and quality....for things that align with that silo structure. If you try to build new things that necessitate conceptual integrity across org boundaries, then teams that think this way will first debate ownership and responsibility breakdown before it&#x27;s even clear how the thing should work at a high level. I&#x27;ve seen too many examples of horrible engineering done by silo&#x27;ed teams, where they build down blind alleys that turn out to be unmaintainable and net-negative producing over time because they approached it based on what services they could touch rather than what made sense from an overall system and UX perspective.Obviously \"breaking down silos\" involves greater coordination and communication overhead, and thus is harder to pull of successfully, so it&#x27;s a tradeoff that should be weighed carefully in the context of business needs. reply vineyardmike 13 hours agorootparentAnd this is another reason why managers growing their fiefdom to make big teams is bad for the organization.Most of the most successful projects and incredible feats of engineering happen by tiny teams full of very talented people NOT a 4-layer management pyramid of people who are here for a nice stable 9-5. Not to say you can’t be successful with WLB but you need a certain fire in your gut and a hunger to execute as a small and efficient team. reply Aeolun 9 hours agorootparentI think there’s nothing incompatible between fire and WLB. Execute with a much greater degree of efficiency between 9 and 5.Too often do people just throw more time and&#x2F;or bodies at a problem to make it go away. reply closeparen 12 hours agorootparentprevI don’t disagree. But I have also seen situations where middle managers are highly attuned to and proud of cross-team projects, and basically don’t pay any attention or give any weight to value delivered for end-users within teams, so everyone is encouraged to structure their projects to maximize communication overhead (even line managers, since doing so gives them the opportunity to grow their directs). reply dasil003 12 hours agorootparentAbsolutely. There are a lot of failure modes. This is why true IC leadership with teeth is needed. The whole point of staff+ engineer roles (outside of specialist research) is to navigate the right technical decisions that span across teams. reply yojo 14 hours agorootparentprevHigh process and high collaboration&#x2F;coordination is not the only alternative to silos.Google in the mid aughts still had tightly aligned teams with clear priorities. But they were also transparent in what they were doing, and open to collaboration where it made sense. Teams felt empowered to reject requests that would trip them up, but also empowered to do small things to help another team (and got rewarded for doing so).The reality at a large org is you’re going to have dependencies. In my experience, highly-siloed orgs have tremendous coordination barriers to even the smallest request across teams. Your one-line API change didn’t make it onto your dependency’s roadmap this quarter? Too bad, try again in three months.And I’m not sure we have the same understanding of “fiefdom.” I’m talking about the pattern where middle managers try to grow their headcount as large as possible without a clear purpose other than building status within the org. This often manifests as disparate and disjoint teams aggregated under a leader who has little understanding or care as to what exactly it is they’re doing. It is hard to find value in this arrangement. reply lll-o-lll 5 hours agorootparent> In my experience, highly-siloed orgs have tremendous coordination barriers to even the smallest request across teams.Isn’t this solved by having cross-team project managers who can perform this coordination?I certainly agree that the failure case you describe is possible, but it’s also solvable (in my experience). reply JumpCrisscross 12 hours agorootparentprevIt’s Coase’s theory of the firm [1] in synecdoche. Silos escape the political transaction costs around them at the expense of access to external resources.They can famously work, e.g. Skunkworks. But they also decay into fiefdoms.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Theory_of_the_firm reply marklar423 14 hours agorootparentprevI feel like you&#x27;re working with a different definition of \"silo\" than the parent. My understanding of a \"silo\" is \"closed off teams that aren&#x27;t allowed to work with outsiders\" who have their own culture that may be at odds with the company.It seems like you&#x27;re talking about team nimbleness and cohesiveness, which I want to say is orthogonal. reply closeparen 12 hours agorootparentBuilding in silos is when you get something done by yourself or with your direct teammates. Cross team collaboration involves e.g. a weekly sync, coauthored design documents, code changes made in modules you’ve never seen before reviewed by people you don’t know, tasks that are critical blocking dependencies for you but totally irrelevant to the decision-makers of the teams that need to allocate time for them. The extent to which a company is siloed is the extent to which its engineers are talking to their desk neighbors and getting things done vs. navigating communication overhead and being blocked on people quite remote from them and their goals.It’s hard to believe you could have a nimble and cohesive team at the scale of a large corporation, because the number of communication edges gets silly. Dunbar’s number and all that. You can have team nimble and cohesive teams within large corporations. But having several distinct networks is otherwise known as being siloed. reply Nimitz14 9 hours agorootparentThis is not at all what people mean when they talk about silos reply Solvency 9 hours agorootparentOk how do you meaningfully define the difference and moreover how would you prevent his version of a \"good\" silo from devolving into a \"bad\" one in actuality? reply whatshisface 8 hours agorootparent\"How does efficient compartmentalization become bad siloing?\"Step one: build Aa and Bb with the A and a people together, and the B and b people together.Step two: realize you need AB and ab.Step three: keep the same organizational structure, and try to get the A team to work with the B team ten managers and five hundred miles away. replyghaff 14 hours agorootparentprevSilos and fiefdoms are normally seen as negative things. And that&#x27;s not entirely wrong.But they can also describe skunkworks&#x2F;internal startup&#x2F;etc. teams doing their own thing without a lot of interference or having to constantly coordinate with every other organization in the company.It can go both ways. reply esafak 11 hours agorootparentSilos are also good for sheltering and nurturing high performing teams, especially when the broader organization is bad. reply pardoned_turkey 14 hours agorootparentprevAs the other commenter mentioned, silos are not inherently bad. Indeed, in a large company, they&#x27;re necessary to avoid dysfunction. You want stable groups of competent people who share priorities and lore, who own well-defined parts of the business, and who have the autonomy to set the strategy for their thing.\"Founder-led\" companies are more dynamic mostly because they&#x27;re smaller. Once they get to 100,000 employees, they will not be distinguishable from Google, Apple, or Microsoft. reply yojo 13 hours agorootparentMaybe? I&#x27;m having a hard time finding a contemporary example. Bezos bowed out (though Amazon culture was famously bad for years), and even Facebook doesn&#x27;t have 100k employees.My point though is there is a difference between having a leader who got there by politicking versus a leader who got there by building a great company. They&#x27;re both going to have different strengths and weaknesses, but there&#x27;s at least a chance the founder isn&#x27;t going to tolerate the sycophants.An example: I was at Google 2005-2008. My manager&#x27;s manager&#x27;s manager was one of the early empire builders. He hired like crazy with no plan at all for the people he was hiring, and kept getting promoted for managing such a rapidly growing org. Eventually he rose high enough up that someone near the top realized what was going on, and promptly fired the guy, leaving behind a fair-sized mess as folks tried to figure out what to do with all his hires.From what I&#x27;ve read lately, if this guy had just shown up to Google a few years later, he&#x27;d still be getting promoted. reply esafak 11 hours agorootparentExecutives need to observe the whole organization, not just their direct reports. How far from the top was he when he started empire building? You make it sound like it was already very hierarchical, when Google always advertised itself as a relatively flat company. reply hnick 7 hours agorootparentprevSounds like encapsulation in OO. You don&#x27;t want to let other people poke around in your bits except through well defined interfaces. reply hinkley 15 hours agoparentprevI have a long list of ways to improve processes and when I was young, energetic, and didn’t know any better, I got very, very lucky getting many or most of them through. As I’ve gotten older I’ve found more things that I “need” to improve and there’s been more time for me to forget how I need to justify things I consider “the right way” and so I don’t always win those arguments.But the bigger thing I’m coming to grips with is that I have to stop entertaining offers from companies that give me an “I can fix them” vibe because I will only be able to fix half the things I know to fix before everyone else decides they’ve changed “enough” and would I kindly shut up now. Hello ossification.Eventually having half good, half bad is going to drive me nuts and take other people with me. I need a higher bar where they are already doing at least half and I can settle for reaching 2&#x2F;3 or 3&#x2F;4 instead of fighting uphill to get to 50%, only to give up and start the cycle earlier. If this were dating I was talking about, someone would have sat me down by now for an intervention. reply busterarm 15 hours agorootparentI feel so much exactly what you&#x27;re describing here... reply Aeolun 9 hours agorootparentprevI joined my current company 5 years ago, and I feel like we’ve ‘fixed’ a lot of things, but the effort to do so is so absurd.And then it’s suddenly invalidated by some high-up rando on the other side of the world deciding we need to go back to the bad old way of doing things. reply henham 12 hours agorootparentprevHow do you distinguish \"I can fix them\" companies that will not improve because they are where they are because of organisational and human issues and the ones you can actual improve and are ready for you? reply Aeolun 9 hours agorootparentIt’s simple, you just assume none are ready for change, and you’ll have a pretty much 100% accurate heuristic. reply tazjin 14 hours agorootparentprevThis reminds me of the \"Explore&#x2F;Exploit\" chapter from \"Algorithms to live by\" :) reply eVoLInTHRo 5 hours agoparentprevJoined Microsoft in the early 2010s, and Google recently in the 2020s. I see the same bad company culture traits in both cases (incompetent & feuding middle managers, silos of information, promotion based on launches not business impact, hired too many people, etc.).I think one big difference is that Microsoft at the time had clearly fallen behind competitors, while Google hasn&#x27;t yet, or not to the same extent. I believe this failure created enough humility at Microsoft that I found many people & teams to be open to new ideas in terms of work processes & culture. Implementing change was harder, but having the conversation wasn&#x27;t.I see very little of that openness or humility at Google at any level, I suppose because there hasn&#x27;t been a major business threat to force a change in mindset, or to let go of long-tenured ineffective leaders. It&#x27;s been disappointing, because I would have expected a company with a lot of supposedly intelligent people wouldn&#x27;t need external threats to avoid creating the bad culture common to big old companies.To me Google work culture in 2023 looks a lot like the Microsoft work culture from 2010, but most can&#x27;t accept that reality. reply tgsovlerkhgsel 15 hours agoparentprev> Careers and incomes are at stake. People will get hurt.Google continues to print much more money than it burns. People get hurt by callous corporate decisions like layoffs. People don&#x27;t get hurt by a company that has insane amounts of money taking risky projects, and if they fail, assigning those people to some other project. Given the size of Google and the fact that they hire generalists, being at risk of losing your project is very different than not being sure about the future of your job. reply pardoned_turkey 15 hours agorootparentLayoffs at Google didn&#x27;t happen because they had to happen. They happened because the leadership was concerned that in the good years, the company accumulated way too much dead weight - pointless projects, underperforming employees that the managers never had to deal with because they could always hire more people, etc. It&#x27;s an awful fix and only a temporary one, but unnecessary risk-taking can jeopardize a lot more than that.For example, let&#x27;s say you have an idea for replacing online ads with a better monetization system for the benefit of the user. How do you pitch that at Google? A misstep here could literally destroy the company. It&#x27;s insanity, akin to Exxon selling off their fossil fuel operation to try their hand at making solar panels.Regulatory and PR risks are similarly grave. For example, Google couldn&#x27;t have pulled off something like TikTok without all kinds of regulators jumping at their throats right away. They had to wait for ByteDance to clear the way and then launched their own \"also-ran\" clone. It&#x27;s the same story with ChatGPT: Google had the tech but not the freedom to let it loose.All of this is rational. You can get away with a lot more when you&#x27;re a scrappy startup and don&#x27;t have much to lose. When you&#x27;re a multi-trillion-dollar company, the math ain&#x27;t the same. reply Eridrus 14 hours agorootparent> Regulatory and PR risks are similarly grave. For example, Google couldn&#x27;t have pulled off something like TikTok without all kinds of regulators jumping at their throats right away. They had to wait for ByteDance to clear the way and then launched their own \"also-ran\" clone. It&#x27;s the same story with ChatGPT: Google had the tech but not the freedom to let it loose.I think this is directionally true: Google would have taken a lot longer to release something like Bard&#x2F;ChatGPT if their hand had not been forced, but I don&#x27;t think pr&#x2F;regulatory pressure was the reason YouTube Shorts was not done before TikTok.I think short form video is just hard to monetize in comparison to long form. Why would you make a product that has uncertain appeal and is likely to be a money loser if it does succeed? reply kccqzy 12 hours agorootparentIndeed, the company behind TikTok (called ByteDance) didn&#x27;t even have an IPO yet. It is unclear how much money they are earning from TikTok. It&#x27;s conceivable that TikTok itself makes no money and is subsidized by the company&#x27;s other products like Toutiao.If Google were to try this early, it is uncertain that Google will discover a monetization strategy before the product joins the Google graveyard.Let&#x27;s not even talk about short form video, just YouTube. How many years did Google subsidize YouTube with Search money before it really turned up advertising on YouTube? Do we know how much effort Google expended in experimenting with monetization strategies for YouTube? reply Eridrus 11 hours agorootparentI don&#x27;t know YT&#x27;s monetization history, but longform video is incredibly easy to monetize because advertisers are willing to pay much more for their content being there. They get some edge from all the tech they have built for matching ads to users, but it&#x27;s just fundamentally one of the easiest things to monetize on the internet, so I don&#x27;t think they would have struggled there. reply mschuster91 11 hours agorootparentprev> Indeed, the company behind TikTok (called ByteDance) didn&#x27;t even have an IPO yet. It is unclear how much money they are earning from TikTok. It&#x27;s conceivable that TikTok itself makes no money and is subsidized by the company&#x27;s other products like Toutiao.Or, which is more likely, by the CCP. TikTok is the perfect piece of propaganda warfare - it gives destabilizing forces, anything from weird left-wing Hamas supporters to the hardcore far-right &#x2F; incel crowd, a direct link to the brains of our children. It&#x27;s unreal just how toxic the trending content on TikTok is, and how little effort is done to moderate it. Way worse than the YouTube radicalization spiral [1], but for whatever reason there&#x27;s almost zero attention to TikTok.[1] https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2020&#x2F;01&#x2F;29&#x2F;276000&#x2F;a-study-o... reply Eridrus 10 hours agorootparentAcademic studies of social media are often very hampered by tooling and data access and studying a moving target.It&#x27;s hard to even know if the methodology of the paper you cited (analyzing comment trajectories) is a good one, given YT is constantly tweaking their algorithms, including in response to public outcry, and this phenomenon does not show up in other analysis: https:&#x2F;&#x2F;12ft.io&#x2F;proxy?q=https:&#x2F;&#x2F;www.theatlantic.com&#x2F;technolo...I assume the methodological questions are even trickier for TikTok which has many more creators than YT.I would love to see someone actually study TikTok though, since people love to ascribe blame to platforms for radicalizing people rather than accepting that some users just have views we find unacceptable regardless of the platform. reply sgu999 4 hours agorootparentprev> It&#x27;s the same story with ChatGPT: Google had the tech but not the freedom to let it loose.I wouldn&#x27;t be so sure, in my case ChatGPT passes the bar of being mildly useful but Bard is still absolutely useless. I can see two equally likely explanations for this: they simply can&#x27;t manage to pull it off due to their culture or they can&#x27;t release something that isn&#x27;t massively more nerfed than the competition. reply jonathankoren 14 hours agorootparentprevYou’re giving Google too much credit. They couldn’t even conceive of short videos. Why? See earlier in the thread. reply davidcbc 10 hours agorootparentprev> Layoffs at Google didn&#x27;t happen because they had to happen. They happened because the leadership was concerned that in the good years, the company accumulated way too much dead weight - pointless projects, underperforming employees that the managers never had to deal with because they could always hire more people, etc.This doesn&#x27;t really match the reality of the layoffs. They weren&#x27;t team&#x2F;project based or performance based, they were seemingly random. If they were concernee about too many low performing products and employees they went about it in completely the wrong way. reply Ckirby 8 hours agorootparentIt means the rot has already set in, idiots protecting their private fiefdoms consisting of more morons and retards reply lupire 9 hours agorootparentprevLayoffs at everywhere happened because money got more expensive.The whole industry didn&#x27;t magically accumulate debt weight all at the same time in the same proportions. reply brlewis 10 hours agorootparentprevThe rationalization given in this comment for the layoffs is obviously false. Google had ways of getting rid of underperformers without massive layoffs that they have been using for many years. Google has ways of getting rid of projects that do not involve layoffs. reply UncleMeat 9 hours agorootparentprev> the company accumulated way too much dead weight - pointless projects, underperforming employeesThe layoffs weren&#x27;t just low performers and killing unwanted projects. reply hot_gril 16 hours agoparentprevTotally agree. The people complaining about culture shifts there seem to want the company to pretend it&#x27;s ~2006. I was never impressed with old Google. All their revenue came from ads, and they loss-led other projects. Fun, but the market has matured from that.Since I joined several years ago, perks have really degraded but overall I&#x27;ve become more satisfied with my actual work. Over-engineered pet projects in and around our team gave way to business focus, meaning we work on truly important stuff. I have little faith in Sundar&#x27;s leadership and think his speeches might as well be AI-generated, but that was always the case. reply satvikpendem 16 hours agorootparent> All their revenue came from ads, and they loss-led other projects. Great, market has matured from that.Has it? Seems like Google still makes most of their money via ads and everything else is a loss leader. reply Andrex 12 hours agorootparentGoogle has been trying very hard to diversify, mostly through Cloud.How well they are succeeding at that is up to interpretation but they are chipping away at Ads&#x27; percentage of revenue. It used to be higher than 85% but as of 2022 it&#x27;s down to only being 58% of operating revenue[0].0. https:&#x2F;&#x2F;www.cnbc.com&#x2F;amp&#x2F;2021&#x2F;05&#x2F;18&#x2F;how-does-google-make-mon... reply rileyphone 11 hours agorootparentThat&#x27;s an article from 2021 that says ads were 80% of revenue reply immibis 2 hours agorootparentprevWhen companies figure out that cloud is a waste of money, this might not work. reply hot_gril 1 hour agorootparentWhich mid to large companies have made this decision so far? I know there&#x27;s Facebook, but their use case is exceptional. reply hot_gril 16 hours agorootparentprevYes Google is still less diversified than its peers. Cloud and YouTube (edit: and Pixel phones?) are profitable afaik. The overall tech market has matured is what I meant; it&#x27;s no longer time to loss-lead everything. reply kevinventullo 15 hours agorootparentNot sure I’d characterize YouTube as a diversification from ads. reply emodendroket 15 hours agorootparentIt is though. Being an ad supplier is different from being an ad exchange. Or would you describe the New York Times or HBO as \"ads businesses\"? reply hot_gril 2 hours agorootparentHBO is paid programming with product placement at most, and NYT sells subscriptions that actually bring in the majority of their revenue. If it were 90% ads, I&#x27;d say yeah they might want to reconsider that.YouTube has its own content while Search ofc doesn&#x27;t, and its advertising model is different. I wouldn&#x27;t lump it in with Search. But still, they&#x27;ve decided ads aren&#x27;t enough and they need YT Premium subscriptions. reply tannhaeuser 15 hours agorootparentprevI&#x27;m not into watching streaming services or TV for that matter, but that would be news to me. Does YT now produce own exclusive content? I think they don&#x27;t 1. to keep content producers running their stuff on YT rather than acting as competitor 2. to avoid yet another reason for antitrust action (ie. the bad looks of extending their monopoly) reply emodendroket 15 hours agorootparentThere was something called \"YouTube Originals\" that&#x27;s been discontinued but I didn&#x27;t consider that central to the point I was making. reply lizknope 10 hours agorootparentCobra Kai started on \"YouTube Red\" which I think was renamed \"YouTube Premium\"Then it went to Netflix where it became a big hit.There was another show I liked named Ryan Hansen Solves Crimes on Television. They constantly broke the third wall making fun of YouTube Red being confused with some kind of adult content service. reply hotnfresh 11 hours agorootparentprevBy that standard, Search is also a diversification from ads. reply hot_gril 2 hours agorootparentBut it&#x27;s not a diversification from what they&#x27;ve always done. reply emodendroket 6 hours agorootparentprevSure. Why not. reply kevinventullo 8 hours agorootparentprevYou may wish to review Google’s sources of revenue. There is one source which contributes over 50%, and it’s not the ad exchange. reply bossyTeacher 13 hours agorootparentprevIt is not. Think about it. Diversification ensures that if one of your assets degrades in value, you have an unrelated asset that can still do well. Back to Alphabet, if ads revenues disappears overnight, Youtube becomes a dead project. Simples reply kmlevitt 12 hours agorootparentAt least they have alternate ways of selling ads, though. For example there has been a lot of talk about how their search business ads are threatened by LLMs that answer questions directly instead of giving search results that include paid placements, etc. But even if that happened, it likely wouldn’t affect YouTube ad revenues much. reply emodendroket 6 hours agorootparentprevIs it? If some new thing came along tomorrow that made Google&#x27;s ad exchange obsolete, they could still sell ads on YouTube using whatever the new thing is. Or if YouTube became untenable, they&#x27;d have the ad exchange. reply hyperhopper 4 hours agorootparentYou two are nitpicking over \"ads\" vs \"ads exchange\" without saying it or talking about it meaningfully reply hot_gril 2 hours agorootparentYeah, the point is diversification reply oblio 8 hours agorootparentprevHBO? No. NYTimes? Probably. All media is. reply emodendroket 6 hours agorootparentYour ontology raises more questions than it answers, like how a streaming service&#x2F;cable television channel is not \"media\" in your world. reply oblio 1 hour agorootparentOk, rephrase the last part to \"The vast majority of media is\".Even HBO is partially an ad company, I imagine their own shows include product placement. reply hot_gril 15 hours agorootparentprevAlso, they sell Premium reply js4ever 15 hours agorootparentThat&#x27;s probably less than 1% of YouTube revenue (number came out of my hat) reply JohnFen 14 hours agorootparentIn 2022, premium subscribers accounted for a bit less than 9% of YouTube&#x27;s audience (and 67% of premium subscribers were in the US), according to this:https:&#x2F;&#x2F;www.mediagistic.com&#x2F;blog&#x2F;how-many-youtube-users-will... reply kmlevitt 12 hours agorootparent8-9% is actually a pretty impressive conversion rate considering close to 100% of people use YouTube. They have like 97.6% market share. reply hot_gril 2 hours agorootparentNo data for this, but I feel like 9% is less than they expected after 5 years of the \"frustrate and seduce\" strategy, which is why they&#x27;re even going after ad-blockers now. If anything, they look frustrated. But they probably had to do this. reply jonathankoren 14 hours agorootparentprevTo use a googlism: I’m surprised Google can count that low. replychatmasta 15 hours agorootparentprevI was about to correct you about GCP profitability, but I just looked it up, and TIL that GCP became profitable for the first time in 2023 Q2. Interesting. reply hot_gril 15 hours agorootparentAnd before, it might&#x27;ve been in that \"profitable if we want it to be\" situation where they&#x27;re just reinvesting the revenue. reply wavemode 14 hours agorootparentWhich is precisely why profit is a red herring. What matters is market share (which for GCP is still 10%, not amazing but gradually increasing) and, ultimately, revenue growth. reply hot_gril 2 hours agorootparentYes, they don&#x27;t need profits from Cloud yet. They do need it to be a viable business when growth slows eventually, though. replyJW_00000 15 hours agorootparentprevAre the Android app store and GCP loss leaders? I assumed those two would be profitable at least. reply saagarjha 1 hour agorootparentGCP burns massive amounts of cash and was a loss for many years. It just barely pulled a profit this year, though it looks more like some accounting tricks to make a small negative number look like a small positive one to make things look better during a downturn. reply detourdog 15 hours agorootparentprevI loved old google they refused to share a business model. Google ~2006 I think is just past peaked google. I think they developed ads because it was the only model that fit their valuation. reply khazhoux 15 hours agorootparentYou have the history backwards.Ads in early 2000s > Mega-valuation reply metanonsense 15 hours agoparentprevWell said. I think this happens very naturally with every growing &#x2F; successful company. Comparing my company of 30 or so with Google is like comparing a bacterium with a race horse, but even at our size being disruptive &#x2F; staying innovative gets harder every month. Do you assign your best resources to the product that gets the money in? Or can you afford having capable people taking bets on new products, even when you know that such a product (if successful) is possibly years from making a dent in your revenue stream.That decision is never easy and finding a product that creates a \"dent in the revenue stream\" at a company like Google with a once-in-a-lifetime product like Ads is probably not realistic even with their resources. reply konschubert 3 hours agorootparentI think it’s fine if big companies stick to their core competencies, return money to shareholders, and the shareholders can then re-invest into innovative startups.Overall, this leads to better outcomes for everybody involved, except for the CEO who’s ego is scratched by running an “old” company. reply emodendroket 15 hours agorootparentprevIt was easier to thread this needle in an easy-money environment than now, when everyone has suddenly grown much more conservative. reply stillwithit 12 hours agoparentprevHas nothing to do with Google “being bad” and everything to do with emerging social trends questioning the corporatization of everything.Such memes have gone viral across our society. From big beer boycotts, to turning on Google and SV. Filter bubbles across contexts are turning on the source of their fascination; we’re out for video games, Hollywood, beer, celebrities, experts, politicians. Knives aren’t out yet but the sharpening stones are.The real value of decades old value stores foisted upon us in deference to the investor class, for if we do not validate their decades old choices and memes, they will have no choice but to engage in punitive acts, drive fiat economy off the fiscal cliff!People are getting fucking tired of it. Sooner than later they’ll resort to whatever behavior is necessary to meet their needs and shoot anyone who takes issue with it. reply immibis 2 hours agorootparentYour comment has been removed for threatening violence, and your user account has been permanently suspended. Have a nice day. - corporate censors reply stillwithit 14 hours agoparentprev> People will get hurt.Tech workers have externalized a lot of this kind of hurt.I have little sympathy for STEM heads who projected “screw you got mine” who then find themselves in a similar position.It’s just meat based cassette tapes on Earth, engaged in vacuous min&#x2F;max metric hacks given the physical constraints of reality.Industry leaders fed on elders memories of war time production norms and educated us such was “normal”, so we normalized it in code for money, regardless of the externalities.Elder generations need to have their authority over the next generation nerfed hard. Exploitation of youth to prop up some aging out figurehead smacks of old divine mandate memes. reply zepearl 12 hours agoparentprev> But once you achieve market dominance, your priorities have to shift. It&#x27;s no longer \"why wouldn&#x27;t you try this\" or \"let&#x27;s do the right thing.\" It&#x27;s \"why would you rock the boat and risk the nice thing we have?\" It&#x27;s not just about profit. Careers and incomes are at stake. People will get hurt.I don&#x27;t get this.Why did they kill so many products which were running on standalone tracks? (at least in my opinion)If I look at https:&#x2F;&#x2F;killedbygoogle.com I see for example \"Stadia\", \"Podcasts\", \"Domains\", etc... - in my opinion those projects would not conflict with their current main activities being Internet search & email service, respectively whoever is involved in it (ok, maybe excluding allocations of budget - but it&#x27;s not that Google has currently liquidity problems so it&#x27;s not that budget for existing depts would have to be reduced...). reply deckard1 11 hours agorootparentI&#x27;m sure internal politics plays a large role. Managers knee-capping each other and so forth.But there is another way to look at it. A company of Google&#x27;s size will not be satisfied by a \"small\" $10M ARR business or perhaps even a $100M ARR business. It&#x27;s not going to move the needle. The needle being, effectively, Google&#x27;s stock price.There are two ways to move the stock price: increased profit or decreased spend. Increase the pie or stop the number of people eating the existing pie.All of those projects had more value in being ritualistic offerings to the stock gods. Much like the unreleased Batgirl film had more value being a tax write-off than selling for market value: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Batgirl_(film) reply Aeolun 8 hours agorootparentYou can build a very solid business empire on a large collection of small offerings. reply bariswheel 7 hours agorootparentprevThough one key issue: Winning hearts and minds matter, public perception matters, they do indirectly affect the bottom line. Requires some nuance&#x2F;between the lines sight to see this. reply iancmceachern 11 hours agoparentprevThis is my experience having been through 3 acquisitions.In 1-2 years you go from: - operating well, get bought - throwing all the business infrastructure you&#x27;ve put in place that&#x27;s deliberately different and better with what was before worse and slower - then leaders get replaced or leave because we can&#x27;t do anything anymore - leaders start saying things like \"we need to be more like a startup \", which would basically just hbe exactly what the company was pre- acquisition reply scaramanga 3 hours agoparentprevAlso he&#x27;s saying \"don&#x27;t be evil\" was the motto, but he joined a year after gmail and in the same year when the CEO was saying \"don&#x27;t be evil is purely marketing\" in interviews in forbes in order to allay the fears of investors who were wondering whether to take that as an admission that google is defrauding investors and neglecting its fiduciary duties, clarifying that the only \"evil\" that matters is that which has no impact on, or that which materially harms shareholder returns. By that definition, their philosophy is no different from that of a tobacco company or Chevron.So i mean ¯\\_(ツ)_&#x2F;¯ reply Laremere 15 hours agoparentprev> But once you achieve market dominance, your priorities have to shift.This is true, but I think you&#x27;re mischaracterizing the required shift, and assuming this requirement is what&#x27;s causing Google&#x27;s problems today.A company does eventually need to make a shift from \"fast and experimental\" to \"responsible and steady\". However this shift is entirely orthogonal from \"focus on the users\" becoming \"focus on the bottom line and year over year growth\".Just because they&#x27;re following the same path as other large tech companies have, doesn&#x27;t mean this is inevitable. Instead it means they failed to learn the proper lessons. As a sibling comment points out, there was the attitude \"but Google is special so that won&#x27;t happen\", when instead it should have been \"to keep Google special, we need to work really hard on preventing that from happening\". reply pardoned_turkey 14 hours agorootparentFocusing on the user is easy when you have little to lose. When you have a trillion-dollar business and 200,000 employees you&#x27;re responsible for, a large part of your focus is not destroying that. And quite often, it&#x27;s not easy to reconcile that with what your users might want. reply cellu 9 hours agorootparentI’m curious to understand your perspective:m as to why a business that focus on the user may expose to risk? Doesn’t meeting user needs equals to making users happy which in turn equals to making more money? reply lupire 9 hours agorootparentNot when your users are not your paying customers reply yterdy 9 hours agoparentprev>But once you achieve market dominance, your priorities have to shift. It&#x27;s no longer \"why wouldn&#x27;t you try this\" or \"let&#x27;s do the right thing.\" It&#x27;s \"why would you rock the boat and risk the nice thing we have?\"Antitrust is important, wouldn&#x27;t you think?>A cutthroat corporate environment where you&#x27;re never sure about the future of your job?This is the state that the unanointed live in, and we even often deem it beneficial (however erroneously), for the good of society, or a market reality, or whatever, so it is very much an option to be considered. I&#x27;m sure many are aghast at the thought, and my memetic response is playing a video clip of SpongeBob&#x27;s Plankton exclaiming, \"I went to COLLEGE!\", with a wry smile on my face. reply JumpCrisscross 12 hours agoparentprev> the prescription is always to go back in timeI read it more as an indictment of layoffs being treated as business as usual. A company that grows a bit more modestly during boom times, fires fast continuously and maintains adequate buffers shouldn’t have to lay people off. Ever. The advantages of that haven’t been well explored. Ian makes a compelling argument that it should be. reply havercosine 5 hours agoparentprev`why rock the boat` is spot on! Most large organisations eventually go into a mode of maximising the free cash flow for shareholders. I guess more or less this is by design. Investors, Founders and early employees take risks in short run for the rewards in the long run. A company cannot keep saying the promised green land is delayed by another 5 years.Some criticism of CEO might be warranted. But remember that CEO compensations tied to profit after tax. I guess the only way to get back old Google is to start one!Once number of employees hits a certain inflection point (roughly when one can&#x27;t identify everyone with name), the focus for a lot of people is to keep their manager happy. Because any other goal is too abstract. Safi Bahcall&#x27;s book Loonshots had some nice discussions on this point. reply robertlagrant 14 hours agoparentprev> they rediscovered the reasons why old companies always end up operating in a particular wayThe main reason is: it&#x27;s hard to hire to stop the culture regressing to the mean. Every time you get it wrong at a senior level, it has a big negative effect. reply andromeduck 11 hours agorootparentBut that&#x27;s what equity driven comp is supposed to resolve - give them small refreshers until they leave. reply obviouslynotme 10 hours agoparentprevIt&#x27;s less about risk aversion than it is about position, size, and complexity. As these things grow, the incentives change and the ability to understand what the organization even is becomes impossible.A startup starts at the bottom. It begs investors, customers, and employees from a position of optimism and humility. The organization enthusiastically changes itself to find a good balance between those three or it dies. As the organization grows, it starts demanding everyone else change for them instead. Google&#x27;s interviews are an example. Its famous customer service is an example.Then we get to size and complexity. Thanks to Dunbar&#x27;s numbers, we know that there are numerical limits to a human&#x27;s ability to know people. This makes sense. I can know everything about 6 people, most things about 50, and keep track of about 250 well enough. As the organization grows, your ability to know it disappears. You begin making abstractions. Instead of knowing exactly what Susan does, you say she works in X Department, for Y Initiative, doing Z position.Google is so big that one person can&#x27;t understand it anymore. The inevitable reduction to a corporate abstraction occurs and then people treat it like the X Company, which is just like Y Company but makes X instead of Y. Short term revenue and expenses are the only measures at the end.And in this faceless abstraction, the professional parasite class infests and extracts resources and morale. Eventually the C-suite stops fighting it and joins in on it until only the sheer size and momentum of the company keeps it going. Maybe an investor group will come and force a rework of the company, but not before the company is just a shadow of the shadow of its former self. reply ytoawwhra92 3 hours agorootparent> Thanks to Dunbar&#x27;s numbers, we know thatThat dude just made the number up. reply whoknowsidont 10 hours agorootparentprev>and the ability to understand what the organization even is becomes impossible.What makes it impossible? reply obviouslynotme 10 hours agorootparentI explain it in the third paragraph but to illustrate it further: Consider a function. A function that is 1 line long is immediately understandable. At 10 lines, it is readable within a minute or two. At 100 lines, it is maybe legible to someone who lives in that function. At 1000 lines, it is a black box. Human organizations are the same way.You might suggest refactoring, which is what companies do too. They create departments, promotion ladders, org charts, and mission statements. The problem is that abstractions leak by design. As your abstractions accumulate and change outside your view, your ability to understand the entirety reduces. reply whoknowsidont 9 hours agorootparentBut that has to do with the capabilities of the executives involved, it doesn&#x27;t make it impossible. Just like in your example, there are many, many developers that can perfectly understand large functions or code bases without issue.If you have such a code base and you hire people that are not equipped, either through inexperience or capability, of managing that code base that is a resourcing issue.If your executives cannot understand and control the organization they are tasked with controlling and cultivating, then they should be fired.Which is basically what this dude is getting at. reply obviouslynotme 9 hours agorootparentExcept large code bases do the same. They regularly die when their ability to be understood drops too low. Even with well organized code, they are pushed to add features until they aren&#x27;t understood at the deepest level. Once you hit millions of lines of code, even when you spend decades in that code base, you still forget changes you made even if you have an overarching picture. That&#x27;s ignoring other people working on it all the time. The understanding gets reduced to contracts, types, and interfaces.And most importantly, humans are more complicated than code. With enough time and knowledge, I can accurately tell you what any piece of code does on a single expression or statement. Humans regularly do things they don&#x27;t even know for purposes they don&#x27;t understand. reply whoknowsidont 8 hours agorootparentI agree with you, but none of this makes it impossible. It just makes it a resourcing&#x2F;hiring issue.The same thing regularly happens with smaller companies or code bases. The size exacerbates the issue, but it&#x27;s not the cause of it.Which is largely this OP&#x27;s point regarding the subject of calling out culture rot and a particular executive. reply BOOSTERHIDROGEN 3 hours agorootparentDo you have any resources to learn this. How to untangle the situation. What would happen if the resources indeed isn’t the problem to tackle, rather its complexity that is hard to untangle. replychii 10 hours agorootparentprevtoo many things going on, involving too many people and nobody can possibly keep track of it all in their head. You have to split it up. But by splitting it up, the left hand doesn&#x27;t really know what the right hand is doing.So controls and processes are put in place to ensure no bad outcomes are possible, but this also prevents good, innovative outcomes from sprouting.Fundamentally, it&#x27;s a loss of trust that can exist in a smaller organization. reply summerlight 15 hours agoparentprevYes, Google couldn&#x27;t find a good way to scale out its early model. Talents are not something easy to scale out. Transparency is inherently in tension against confidentiality, and when you have lots of eyes then the latter tends to win unless you&#x27;re comfortable of spending your daily life with all those media outlets. If you want to do the right thing, then you&#x27;ll figure out that there&#x27;s too many \"right things\" at its scale because there are too many people with different, conflicting goals. The list goes on.Still, the market expects it to keep its crazy growth rate and Google actually has done a good job there. Unless Google decide to shrink its business significantly, I&#x27;m not sure if going back in time is a viable option. The problem could be remedied by aggressive reduction of business&#x2F;operational complexity but it won&#x27;t solve the root issue. I don&#x27;t know the solution as well.But I still agree with the point that Google generally lacks of clear organizational goal&#x2F;visions. This sort of inter-personal alignment is critical for scaling out any organizations, but Google lost it during its aggressive expansion period in Sundar&#x27;s tenure. Many teams usually fail to find clear causal, logical connections between their daily works and company-wide OKR. Then mid-level managements tend to develop bad organization signal such as entirely metric driven projects since they don&#x27;t know what to rely on. I guess this is something more actionable, but might not be easy to solve. reply strangescript 8 hours agoparentprevCompanies confuse their initial product success with general success. \"We made this amazing thing, so everything we do is amazing\". The logic is flawed but can carry the company a tremendous distance before becoming unsustainable. Google is reaching the early steps of the unsustainable phase, and their initial product success is finally being threatened via AI. Working on an open source library for 9 years and then complaining that the company is changing is ironic. reply immibis 2 hours agorootparentI&#x27;ve seen a hypothesis that Google has never created anything new worth anything to anyone, after it created search and ads. Gmail is a clone of Hotmail, and YouTube and Android were acquisitions. reply eikenberry 11 hours agoparentprev> But once you achieve market dominance [..]Here lies the problem. Market dominance should mean anti-trust kicks in to prevent businesses from shifting to this more conservative, rent seeking behavior. You want businesses kept in that sweet spot where company vision is more than a PR checkbox. reply rkagerer 14 hours agoparentprevYou&#x27;re never too big put the user first.When you stop doing that, someone else will and in time your customers will go there instead. reply surgical_fire 13 hours agorootparentThis is provably false. Customers are anything but rational, and pick things out that play against their best interests all the time.Be it due to fashion, social pressure, brand recognition, cultural norms, et cetera and so forth. reply JohnFen 15 hours agoparentprevWell-said. I think this is all pretty well encapsulated in the truth that \"we tend to become what we hate\", or \"if you gaze into the abyss, the abyss gazes also into you.\" reply esafak 16 hours agoparentprevGoogle has the margins to take risks. If you don&#x27;t disrupt yourself somebody else will. reply chatmasta 15 hours agorootparentSo when Bezos says \"your margin is my opportunity,\" he&#x27;s talking to Google?It&#x27;s not just that Google can take risks because they have margins. It&#x27;s more that they need to take risks to diversify their source of margins before they disappear to someone like Bezos. reply deckard1 11 hours agorootparentAmazon is already there.https:&#x2F;&#x2F;finance.yahoo.com&#x2F;news&#x2F;amazon-is-quietly-building-th...Interestingly, Amazon&#x27;s move to ad placement seems to coincide with how terrible Amazon&#x27;s search is. It&#x27;s a pay-to-play free-for-all wasteland. Not too dissimilar to the SEO wasteland of Google search. reply ljm 11 hours agoparentprevGoogle fought against Microsoft’s EEE strategy until they could do it themselves. Enter Chrome. reply ra7 14 hours agoparentprev> I think the only comedy here is that Google looked at these old-school companies like Microsoft or IBM and figured they can be different just because they \"get it.\" And then, over time, they rediscovered the reasons why old companies always end up operating in a particular way.This is funny because Alphabet&#x27;s homepage still quotes Larry Page bragging they won&#x27;t become a conventional company:As Sergey and I wrote in the original founders letter 11 years ago, “Google is not a conventional company. We do not intend to become one” reply johngossman 12 hours agoparentprevThis is spot on. I&#x27;ll only add that the necessity of showing perpetual growth in the quarterly income report strongly incentivizes big companies to act this way, especially where--as in most tech companies--the employees have equity. reply JSavageOne 5 hours agoparentprevYou&#x27;ve just described why once prominent companies fade into shadows of their former glory (eg. Kodak, Blackberry, IBM, Oracle, Microsoft). Definitely not inevitable and could be avoided with better leadership. reply immibis 2 hours agorootparentBut not a problem, either. Turnover is natural. Nobody but the investors care very much whether Kodak pivots to digital cameras, or whether Kodak remains the leading film camera company as the industry shrinks, and a different company makes digital cameras. In fact the latter is often better for the economy and consumers, due to the better specialization. reply JSavageOne 1 hour agorootparentYes it is a problem if a company is failing not just for the investors but the workers. Nobody wants to work for a sinking ship. Can&#x27;t believe this even needs to be said. reply vkou 16 hours agoparentprevMost of the issues brought up by the author are not ones of priorities, but ones of a select group of mid-level directors (whom you&#x27;ve never heard of, but each of whom wield significant influence over the work output and roadmap for hundreds of engineers) doing a poor job, with nobody above them interested in doing anything about it.> She treats engineers as commodities in a way that is dehumanising, reassigning people against their will in ways that have no relationship to their skill setThis is an example of that. Highly political, and also highly banal re-orgs, that leave the grunts scratching their heads, and picking up the pieces.The risk-taking thing (for ICs) only became relevant post-layoffs. reply pardoned_turkey 16 hours agorootparentI think it goes back to org structure ossification, but also keep in mind that in a sufficiently large company, every department is a thorn in someone else&#x27;s backside. A world where the people you dislike regularly get the boot is also a world where you have to constantly justify your own existence, where you have aggressive stack ranks, and so forth.It&#x27;s a bit of a damned if you do, damned if you don&#x27;t kind of a deal. reply ghaff 15 hours agorootparentAnd the degree to having some level of org structure ossification is to have lots of people sort of going off and doing their own thing. Which probably worked at Google for a longer time than is often the case just because they were printing money. So what if they were doing projects and then just killing them, living with duplication, or having a bunch of random activities that led to nowhere.Even if it&#x27;s a bit frustrating it can also be more fun to be in an environment where it&#x27;s more of a make your own adventure sort of thing. Mature companies though mostly have to be very structured about how they operate. reply vkou 15 hours agorootparentprevSure. It&#x27;s an incentives problem. It&#x27;s very difficult to align the incentives in any organizations with six levels of reporting chain so that people with the most day-to-day power over the direction of the firm (mid-level directors) are marching in the right direction.I don&#x27;t have a silver bullet for this, but I would say that, broadly speaking, managers that don&#x27;t take feedback from below, as well as above, are probably doing a poor job. reply southwesterly 16 hours agorootparentprevA good manager does not always a good SWE make. reply 01100011 13 hours agoparentprev> what&#x27;s the alternative? A cutthroat corporate environmentNo. Sure, that&#x27;s the easy route. You can reposition and retrain folks. You don&#x27;t need to fire people to change, although that is what&#x27;s commonly done.C-Suite can drive a culture where folks feel safe through reorganizations. Setting those expectations in a believable way facilitates the large changes an org like Google needs to periodically make to stay relevant.I work at another large tech company and, despite its problems, I&#x27;ll say that they have done a great job of showing they don&#x27;t easily toss people aside and that results in a better culture overall. reply Animats 13 hours agorootparent> C-Suite can drive a culture where folks feel safe through reorganizations.The larger version of that is mergers and acquisitions. The Wall Street Journal has pointed out a few times that M&A activity is usually a lose for stockholders. Reorganizing the corporate structure is one of the few things C-suite executives can do themselves. For most other things, they have to work through others, managing rather than doing. reply yashap 12 hours agoparentprevI honestly think it’s possible to have large&#x2F;mature companies that are still innovative, fast moving, transparent&#x2F;candid internally, user focused, and low on internal bureaucracy. It’s just really, really, really hard.You need to constantly be eliminating red tape and causes of slowdowns, because they’ll keep appearing. For tech companies this means spending a lot of time eliminating tech debt, slow&#x2F;unreliable workflows, toil work, etc. It also means reducing cross-team dependencies, keeping decision making units small and independent.You need a very performance oriented culture, where you only keep strong performers and fire miss-hires (or ppl who start strong but later start coasting). This is maybe the hardest part, as firing people is very tough and can have real negative consequences on the person being let go, but an accumulation of ppl who are just sort of coasting is one of the biggest reasons companies slide into mediocrity over time.I think very, very few companies pull this off in practice, but I don’t think it’s impossible to pull off, just EXTREMELY hard. reply solatic 3 hours agorootparentIt&#x27;s one of those things that ought to be possible, but the problem is scaling middle management. Plenty of IC talent on the bottom, but it&#x27;s impossible to have hundreds or thousands of IC report to the same individual executive with a vision. One you start to hire middle management, you get politics: fiefdoms, silos, power games, selective storytelling, cherry-picking statistics. In a small company where an executive oversees a single layer of middle management, it can be fought against, and stamped out where it&#x27;s found. Two layers of middle-management, getting executives to be out of touch with the IC level, it starts to get very difficult to parse through what&#x27;s bullshit and what&#x27;s not; by three layers, there&#x27;s too many people playing telephone, and you have an echo chamber.The challenge for executives is to achieve strategic success in spite of the necessary evil of layers of middle management. reply esafak 11 hours agorootparentprevWhich companies did you have in mind? reply steveBK123 15 hours agoparentprevPersonally all large company processes start to rhyme and things feel like ground hog day.After spending the first 10 years of my career at 100K+ employee firms, I&#x27;ve only worked at 500 - 2500 person companies since.There&#x27;s benefits from a process perspective of working at a big place and understanding what guardrails may be useful, and I suppose later in career boomerang back and sort of slowly coast into retirement..But mid career if you know what you are doing and want to deliver, huge firms can be very very stifling places. reply ren_engineer 14 hours agoparentprevlogical move is to get better at splitting off their research and innovation into startups by licensing or funding employees who leave. Spinoff anything risky into an independent company so it can move faster and isn&#x27;t slowed down by Google&#x27;s risk aversion and bureaucracy. Basically what Microsoft did with OpenAI, give them cash and compute resources but have plausible deniability if things go wrong reply mathgradthrow 13 hours agoparentprevIf google&#x27;s mantra had been \"Don&#x27;t rock the boat\" since they achieved market dominance, we would still have xmpp. reply timenova 10 hours agoparentprevI highly recommend you read the paper Marketing Myopia by Theodore Levitt (1960). reply brandall10 5 hours agoparentprevThe book \"The Innovator&#x27;s Dillemma\" is about this concept. reply sonicanatidae 13 hours agoparentprev>But once you achieve market dominance, your priorities have to shift.And shift they did.https:&#x2F;&#x2F;gizmodo.com&#x2F;google-removes-nearly-all-mentions-of-do... reply chatmasta 16 hours agoparentprev> what&#x27;s the alternative? A cutthroat corporate environmentSure. Isn&#x27;t that how the financial industry operates? (Or maybe that&#x27;s more of an illusion, and people in finance just tell themselves they&#x27;re in a cut-throat environment, even though in reality they&#x27;ll never leave it. Whereas if it were really a cut-throat environment you&#x27;d expect to see more churn as the weak employees fail out of the industry.)> And then, over time, they rediscovered the reasons why old companies always end up operating in a particular way.This may be true in tech companies, but I&#x27;m not sure it generalizes to other industries.I wonder to what degree these organizational behaviors are emergent from the personality types within the industry. If you put a bunch of conflict-averse personalities in an organization, and then hire more aggressive personalities to manage them, perhaps that organization will inevitably develop into something resembling IBM. reply ivancho 15 hours agorootparentFinance is cut-throat in the upper echelons, and also around culling people producing less value than their salary. But once they find someone willing to produce $400K of value in exchange for $200K salary, who is not otherwise interested in career growth, they usually just leave them be, that&#x27;s how you see people staying in the same job with roughly the same responsibilities and skills for 10-15 years. Which creates other pathologies, but in some sense is less harsh than tech. reply zem 14 hours agorootparent> someone willing to produce $400K of value in exchange for $200K salary, who is not otherwise interested in career growththat probably describes a lot of people in tech megacorps too reply ivancho 3 hours agorootparentBig tech, yes, lots, but an extra skill required there is to recognize and actively avoid ambitious managers, who would sacrifice&#x2F;burn out their own team for self-advancement. Lots of churn in big tech is purely from that. Small tech, I think the capital pressure is much higher, so just getting a steady good deal on labor is not enough, leadership there is constantly optimizing and trying to upgrade the labor value without matching comp (ie, people are expected to always be acquiring more skills, giving internal talks&#x2F;lectures, mentoring etc, and those who don&#x27;t, well, they turn out to not be a good culture fit). reply lupire 9 hours agorootparentprevIt&#x27;s nearly impossible to measure the marginal contribution of someone one in a non sales role. reply ivancho 3 hours agorootparentAnd yet somehow most people in charge of resourcing and budgeting for projects, teams and companies have some idea of who to hire, how much to pay them, etc. How do you think they do that with something that is nearly impossible to measure?It certainly wouldn&#x27;t benefit anyone who hires people if those people could estimate their own contribution, or, god forbid, compare it to their compensation. I think there&#x27;s a term for the difference which now eludes me. reply ghaff 15 hours agorootparentprev>perhaps that organization will inevitably develop into something resembling IBM.So an over 100 year old company that makes 10s of billions of dollars? reply chatmasta 15 hours agorootparentSure. But people in this thread aren&#x27;t complaining that Google&#x27;s profitable. They&#x27;re complaining about the culture. Long term, such a poisonous culture is not a sustainable path to growth or retained profitability. And it&#x27;s even less sustainable when the company is dependent on an undiversified revenue stream, since they need to be innovating to mitigate that risk, and a poisonous culture is toxic to innovation.But yes, Google is a money printer, and it&#x27;s printing at a higher speed than it was ten years ago. But in that same ten years, Microsoft has grown at a faster rate and even displaced Google in some areas, like developer tooling and AI. In fact, Google has lost its ability to innovate to such an extent that a startup was able to beat them to market by productizing research that originated from Google! And now Microsoft basically owns that startup. That&#x27;s an embarrassing failure of leadership. reply ghaff 15 hours agorootparentMicrosoft has certainly had a pretty amazing transformation. After they lost mobile and the client OS market was clearly stagnant to declining, it seemed they were toast if you looked at where their revenue came from. (And their early hybrid cloud strategy was sort of a mess too.)Whereas, as you suggest, Google&#x27;s cloud strategy has been marginal except for Google Docs and they&#x27;re still mostly an ad company. reply emodendroket 15 hours agorootparentprev> Long term, such a poisonous culture is not a sustainable path to growth or retained profitability.Are you sure? This feels a little bit like when I read the American capitalism is going to collapse because there are a lot of homeless people. Just because something has the effect of making some people miserable doesn&#x27;t mean that it&#x27;s unstable or doomed to fail. IBM, GE, Boeing, or any number of other \"dinosaur\" companies haven&#x27;t gone anywhere. And Microsoft itself shows that even a conservative culture can manage to adapt to changing circumstances when it&#x27;s necessary. reply chatmasta 14 hours agorootparentBut Google doesn&#x27;t intentionally have a conservative culture. They&#x27;re trying to innovate, since they need to mitigate the existential risk of their undiversified revenue stream. But they&#x27;re failing to innovate.So perhaps such a conservative culture does have its merits, but claiming that Google sought those merits is post-facto rationalization of their failure to innovate. Google never intended to turn into IBM (which, btw, they havent - at least IBM has more diversified sources of revenue!).That said, you make a good point that Microsoft itself is a counterexample. So maybe there is still hope for Google. But IMO, that hope is not aligned with the path they&#x27;re currently traveling. They need to fire Sundar and make some drastic cultural changes if they want to outcompete Microsoft between now and 2035. reply emodendroket 13 hours agorootparentSure, they&#x27;re not achieving everything they want, but I think most people would be pretty happy if they just achieved a huge money-printing machine through an app store and ad exchange. reply chatmasta 12 hours agorootparentYeah, hence why Larry and Sergei don&#x27;t care that the company they founded is currently on a downward trajectory... replylupire 9 hours agorootparentprevThat&#x27;s 25% of Google revenue using more employees.So yeah, bloated and underperforming. reply emodendroket 15 hours agorootparentprevA cutthroat environment is going to encourage plenty of people to behave conservatively so that their rivals do not seize on their failures, real or perceived. reply WalterBright 14 hours agoparentprevYou&#x27;ve described why older companies do not inevitably grow into monopolies and take over the world. They get so set in their ways and bureaucratic that they get destroyed by the next wave of upstart companies. reply tannhaeuser 10 hours agoparentprevI find the real comedy here is the emotional attitude towards an employer TBH, especially with GOOG doing just fine.The other thing I find worthwhile is the many Googlers&#x2F;Xooglers coming out here quite bluntly. Which is appreciated when there was a noticeable lack of contributions recently that I was beginning to attribute to some newly imposed corporate social media policy by Google (like, to prevent leaks to competitors or antitrust authorities or sth). reply 0xbadcafebee 14 hours agoparentprev> the reasons why old companies always end up operating in a particular wayIn a word: momentum reply alliao 12 hours agoparentprevkind of interesting how bell was able to spun off so much while modern companies aren&#x27;t able to do so reply toasted-subs 5 hours agoparentprevEventually everybody has to grow up and realize Santa isn’t a real person. reply simone",
    "originSummary": [
      "The author reflects on their 18 years at Google and praises the company's early culture and values.",
      "Over time, Google's culture eroded, transparency decreased, and decision-making began prioritizing the company's interests over those of users.",
      "The lack of visionary leadership from current CEO Sundar Pichai is seen as a contributing factor to these issues.",
      "The author believes that Google needs a shake-up in leadership to steer the company back towards its original mission and values.",
      "It is still possible for Google to heal and achieve great things, but time is running out to reverse the deterioration of the company's culture."
    ],
    "commentSummary": [],
    "points": 1771,
    "commentCount": 860,
    "retryCount": 0,
    "time": 1700671455
  },
  {
    "id": 38378216,
    "title": "Sam Altman Fired and Reinstated: Clashes and Controversy at OpenAI",
    "originLink": "https://www.washingtonpost.com/technology/2023/11/22/sam-altman-fired-y-combinator-paul-graham/",
    "originBody": "Altman’s polarizing past hints at OpenAI board’s reason for firing him Before OpenAI, Altman was asked to leave by his mentor at the prominent start-up incubator Y Combinator, part of a pattern of clashes that some attribute to his self-serving approach By Elizabeth Dwoskin and Nitasha Tiku Updated November 22, 2023 at 2:06 p.m. EST|Published November 22, 2023 at 6:00 a.m. EST (Illustration by Laura Padilla Castellanos/The Washington Post; Justin Sullivan/Getty Images/iStock) Listen 9 min Share Comment Add to your saved stories Save Friday’s shocking ouster of Sam Altman, who negotiated his return as CEO of OpenAI late Tuesday night, was not the first time the shrewd Silicon Valley operator has found himself on the outs. Four years ago, one of Altman’s mentors, Y Combinator founder Paul Graham, flew from the United Kingdom to San Francisco to give his protégé the boot, according to three people familiar with the incident, which has not been previously reported. Graham had surprised the tech world in 2014 by tapping Altman, then in his 20s, to lead the vaunted Silicon Valley incubator. Five years later, he flew across the Atlantic with concerns that the company’s president put his own interests ahead of the organization — worries that would be echoed by OpenAI’s board. Though a revered tactician and chooser of promising start-ups, Altman had developed a reputation for favoring personal priorities over official duties and for an absenteeism that rankled his peers and some of the start-ups he was supposed to nurture, said two of the people, as well as an additional person, all of whom spoke on the condition of anonymity to candidly describe private deliberations. The largest of those priorities was his intense focus on growing OpenAI, which he saw as his life’s mission, one person said. Advertisement Story continues below advertisement A separate concern, unrelated to his initial firing, was that Altman personally invested in start-ups he discovered through the incubator using a fund he created with his brother Jack — a kind of double-dipping for personal enrichment that was practiced by other founders and later limited by the organization. “It was the school of loose management that is all about prioritizing what’s in it for me,” said one of the people. Graham did not respond to a request for comment. Though Altman’s Friday ouster has been attributed in numerous news media reports to an ideological battle between safety concerns vs. commercial interests, a person familiar with the board’s proceedings said the group’s vote was rooted in worries he was trying to avoid any checks on his power at the company — a trait evidenced by his unwillingness to entertain any board makeup that wasn’t heavily skewed in his favor. Allegations of self-interest jeopardized the first days of negotiations to broker Altman’s return to OpenAI, which is the leading artificial intelligence company and is responsible for ChatGPT. Over the weekend, the four members of the original board, including three independent directors, had been willing to bring Altman back as CEO and replace themselves as long as Altman agreed to a group that promised meaningful oversight of his activities, according to the person familiar with the board, who spoke on the condition of anonymity to discuss sensitive matters. Though the board met with and approved of one of Altman’s recommended candidates, Altman was unwilling to talk to anyone he didn’t already know, said the person. By Sunday, it became clear that Altman wanted a board composed of a majority of people who would let him get his way. Another person familiar with Altman’s thinking said he was willing to meet with the board’s shortlist of proposed candidates, except for one person whom he declined on ethical grounds. Skip to end of carousel Key players in OpenAI’s boardroom saga arrow left arrow right Sam Altman Altman, who co-founded OpenAI in 2015 as a nonprofit research lab, was fired as CEO on Friday. The A.I. start-up announced Tuesday that he will return to his post. Bret Taylor Taylor is a Big Tech veteran, having worked at Google, Facebook and most recently as Salesforce’s co-CEO, a post he held until early this year. He was board chair of Twitter during its acquisition by Elon Musk, and he led the legal battle to force Musk to go through with his acquisition of the social media platform. Larry Summers An economist and former treasury secretary under Bill Clinton, Summers was president of Harvard University until stepping down in 2006 after making controversial comments the prior year suggesting women aren’t as good as men at science and engineering. He is well-connected in Silicon Valley and has been a special adviser to venture capital firm Andreessen Horowitz. Satya Nadella Nadella offered to hire Altman as head of Microsoft’s new AI lab if he were to leave OpenAI. The Microsoft CEO struck a deal with OpenAI to invest billions in the company earlier this year. Emmett Shear Shear was named interim CEO of OpenAI to replace Altman and Mira Murati, who held the interim CEO title for just two days. Shear co-founded the video game streaming platform Twitch. Helen Toner Toner is one of the four members of OpenAI’s board who voted to oust Altman. An AI and national security researcher at Georgetown University, she has been a proponent of making sure the AI industry has proper safeguards. She stepped down from the board. Ilya Sutskever A highly respected AI researcher, Sutskever is OpenAI’s chief scientist and was one of the board members who ousted Altman, a move he later said he regretted. He is no longer on the board. Greg Brockman Brockman was one of Altman’s co-founders at OpenAI and has been one of his chief lieutenants. He quit in solidarity when Altman was fired. When Altman was reinstated as CEO, he posted on X he is returning to OpenAI. Kevin Scott The Microsoft chief technology officer is one of the most powerful executives in AI. He told OpenAI employees he would hire them all if they decided to quit the company over Altman’s ouster. Mira Murati Murati was an early OpenAI employee who was chief technology officer up until being appointed interim CEO after Altman’s firing. The board replaced her two days later with Shear. She has supported the efforts to get Altman back to the company. Vinod Khosla The veteran venture capitalist and founder of Khosla Ventures is an early investor in OpenAI. He has vocally opposed Altman’s ouster. Tasha McCauley The former OpenAI board member and tech entrepreneur also sits on the board of the Center for the Governance of AI, a British think tank that researches the impact of artificial intelligence. Adam D’Angelo D’Angelo is on OpenAI’s board and voted to oust Altman. He was Facebook’s chief technology officer in the company’s early years and went on to found Quora, the question-and-answer site. 1/13 End of carousel But by late Tuesday, Altman agreed to certain demands, including not being on the board and retaining Quora CEO and current director Adam D’Angelo, announcing a return as CEO around 10 p.m. Pacific time. He agreed to name two new board members — Bret Taylor, formerly co-CEO of Salesforce and a Twitter board member, as well as Larry Summers, former U.S. treasury secretary — names the old board members were optimistic about. “And now, we all get some sleep,” Helen Toner, one of the board members involved in negotiations, wrote on X, formerly Twitter. OpenAI’s rapidly shifting and drama-filled boardroom saga, which has played out on social media, is a first for the fast-moving tech sector. But Altman’s clashes, over the course of his career, with allies, mentors and even members of a corporate structure he endorsed, are not uncommon in Silicon Valley, amid a culture that anoints wunderkinds, preaches loyalty and scorns outside oversight. The same qualities have made Altman an unparalleled fundraiser, a consummate negotiator, a powerful leader and an unwanted enemy, winning him champions in former Google chairman Eric Schmidt and Airbnb CEO Brian Chesky. Altman’s ability to inspire fealty from employees and faith in his mission was broadcast across X this past weekend in a flood of heart emojis from OpenAI staffers and in threats from nearly all of the company’s 770-person workforce to quit unless he was reinstated. “Ninety-plus percent of the employees of OpenAI are saying they would be willing to move to Microsoft because they feel Sam’s been mistreated by a rogue board of directors,” said Ron Conway, a prominent venture capitalist who became friendly with Altman shortly after Altman founded Loopt, a location-based social networking start-up, in 2005. “I’ve never seen this kind of loyalty anywhere.” Share this article Share But Altman’s personal traits — in particular, the perception that he was too opportunistic even for the go-getter culture of Silicon Valley — have at times led him to alienate some of his closest allies, say six people familiar with his time in the tech world. Advertisement Story continues below advertisement Many in Silicon Valley laud Altman’s strategic skill sets, including his ability to be a matchmaker among powerful people. People who know him say they have witnessed him pluck fledgling start-up founders, mentor them and make introductions for them that altered their careers. One of those people whose career Altman helped propel was Ilya Sutskever, chief scientist and board member at OpenAI — the person who ultimately fired him. Keith Rabois, a general partner at the venture firm Founders Fund, said that Altman was one of only three people he consulted when he decided to leave his previous job to join his current firm. He said Altman, who officiated his wedding, had an uncanny knack for giving strategic advice, for negotiating business deals and for spotting undiscovered talent. “He could tell right away who was destined for greatness — probably one of the five best people in all of Silicon Valley at doing that,” he said. Rabois noted that Altman, as a Stanford dropout, persuaded a major telecommunications company to do business with his start-up Loopt — the same quality, he said, that enabled Altman to persuade Microsoft to invest in OpenAI. “Insofar as he is polarizing, it’s because he is young, successful and ambitious, and people are envious,” he added. Altman’s career arc speaks to the culture of Silicon Valley, where cults of personality and personal networks often take the place of stronger management guardrails — from Sam Bankman-Fried’s FTX to Elon Musk’s Twitter. Altman’s practice of filling the board with allies to gain control is not just common, it’s start-up gospel from venture capitalist Peter Thiel, Altman’s longtime mentor. But some of Altman’s former colleagues recount issues that go beyond a founder angling for power. One person who has worked closely with Altman described a pattern of consistent and subtle manipulation that sows division between individuals. Advertisement Story continues below advertisement A former OpenAI employee, machine learning researcher Geoffrey Irving, who now works at competitor Google DeepMind, wrote that he was disinclined to support Altman after working for him for two years. “1. He was always nice to me. 2. He lied to me on various occasions 3. He was deceptive, manipulative, and worse to others, including my close friends (again, only nice to me, for reasons),” Irving posted Monday on X. Irving did not respond to The Post’s request for comment. The board’s startling, though short-lived, decision to fire Altman came as he appeared to be on an upswing. Only a year after launching ChatGPT, OpenAI was by far the hottest consumer company in Silicon Valley. At the company’s recent Dev Day, Altman presented as a millennial Steve Jobs — and announced plans for the company to become the dominant platform in generative AI. As the face of the company, and the AI boom, he was on the precipice of transitioning to a new entrant in the Big Tech pantheon. Within some tech and AI circles, however, the knives were out for Altman. A growing group alleges that Altman has used his shrewd maneuvering to stifle smaller open-source competitors, in this case to secure the future for his company and employees. AI executives, start-up founders and powerful venture capitalists had become aligned in recent months, concerned that Altman’s negotiations with regulators were dangerous to the advancement of the field. Although Microsoft, which owns a 49 percent stake in OpenAI, has long urged regulators to implement guardrails, investors have fixated on Altman, who has captivated legislators and embraced his regular summonses to Capitol Hill. Advertisement Story continues below advertisement Though full reasoning for Altman’s initial firing is still unclear, the person familiar with the proceedings said there was no single catalyst. The board’s independent directors remained united during negotiations and stood by their decision. It was hard work to find new board members they believed would be able to stand up to Altman, the person said. “Sam lives on the edge of what other people will accept,” said one of the people who had worked with him closely. “Sometimes he goes too far.” In a post on X announcing his return, Altman wrote, “i love openai, and everything i’ve done over the past few days has been in service of keeping this team and its mission together.” Share Comments",
    "commentLink": "https://news.ycombinator.com/item?id=38378216",
    "commentBody": "Before OpenAI, Sam Altman was fired from Y Combinator by his mentorHacker NewspastloginBefore OpenAI, Sam Altman was fired from Y Combinator by his mentor (washingtonpost.com) 847 points by CartyBoston 21 hours ago| hidepastfavorite658 comments helsinkiandrew 21 hours agohttps:&#x2F;&#x2F;archive.ph&#x2F;fLzoF neonate 15 hours agoparenthttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231122141935&#x2F;https:&#x2F;&#x2F;www.washi... QuadrupleA 14 hours agoprevFrom Paul Graham&#x27;s Twitter, three days ago: \"No one in the world is better than Sam at dealing with this kind of situation.\" Jessica Livingston retweet: \"The reason I was a founding donor to OpenAI in 2015 was not because I was interested in AI, but because I believed in Sam. So I hope the board can get its act together and bring Sam and Greg back.\"Also from a sibling comment: https:&#x2F;&#x2F;twitter.com&#x2F;search?q=from:paulg%20since:2019-01-01%2...Seems incredibly respectful and supportive, I&#x27;m not buying that there&#x27;s a lot of bad blood there. reply LeafItAlone 13 hours agoparentMature adults can certainly think that someone else is not fit for one job (running YC) and is fit for another (handling OAI). Good business people are even better at it, knowing that makes them more money. PG certainly seems to fit that. reply PeterStuer 3 hours agorootparentI&#x27;ve met ruthless dark triad people who I correctly predicted would be extremely successful, but I would make sure never to be work with or for. reply ratg13 6 hours agorootparentprevPG doesn’t say he’s fit for the job, he just says he’s good at some unspecified thing.Maybe that unspecified thing is just corporate knife fighting and this time PG is happy he’s not on the other end of it. reply cjrp 2 hours agorootparentMaybe the situation he’s good at dealing with is… getting fired? reply cma 5 hours agorootparentprevYcombinator still has a monetary interest in the for-profit corp of OpenAI right? When Sam says he doesn&#x27;t have equity I believe he sometimes clarifies that he does a small interest through a ycombinator partnership or fund ownership of some shares. reply yumraj 12 hours agoparentprevIt’s not too complicated. Their interests are&#x2F;were different.In the case of YC, removing him was better for PG and YC.In this case, having Sam on top of OpenAI gets them better returns on their investment. reply jesterson 1 hour agoparentprev> because I believed in SamNothing is worse than religious fanatics. While I am not implying she is so, for this kind of enterprise I would personally prefer scientific method of evidential support of Sam being this and that, rather then fanatical speaches how they like him. reply tester756 16 minutes agorootparent>prefer scientific methodIf you know some scientific method to pick CEOs and it worksthen patent it quickly and open it as SaaS or something cuz big companies are waiting with trucks full of cashBtw her \"believing\" in him may be due to serious and measurable results, how is this religious? reply ghufran_syed 1 hour agorootparentprevIt&#x27;s a statement communicating her strength of opinion, I find it hard to understand how you perceive that as \"fanatical\" - what would a \"scientific method of evidential support\" even look like in a domain like business? Is she meant to publish a paper with p-values of his effectiveness running YC or being a YC partner? If she pointed to the success of YC during his tenure (which she could well have done with justification), you&#x27;d probably complain there were many other factors (true) and so was only association, not causation? reply tucnak 43 minutes agorootparentprevBelieving in people isn&#x27;t religious discourse like believing in God is, or more generally \"believing in the coming of superhuman entity,\" and I think there&#x27;s no denying that AI safety circles are somewhat similar in structure to 60s, and then later 80s doomsday cult-craze. The setting is different every time, i.e. it doesn&#x27;t have to be a church-like organisation, it could also be nuclear cold-war, or ecological catastrophe kind of thing; a network of sparse, but also surprisingly well-connected groups, primarily occupied with religious discourse, petty in-group politics of psychosis, all of it contributes to institutional syndrome of sorts.Sam is very transparent in his self-interest, it&#x27;s the \"patriots\" you should beware. reply personjerry 13 hours agoparentprevDoesn&#x27;t this show a vested interest from pg and jessica in OpenAI? So it&#x27;s hard for them to say anything negative. reply haltist 13 hours agorootparentAs a matter of good policy they wouldn&#x27;t publicly denounce anyone that was associated with YC. reply notahacker 8 hours agorootparentBut it&#x27;s possible to maintain that good policy without publicly endorsing his side of someone else&#x27;s argument though... reply haltist 7 hours agorootparentI don&#x27;t do marketing for YC but Paul Graham does so you&#x27;d have to ask him about how they deal with such situations. My comment is just my opinion. reply gjvc 10 hours agorootparentprevsimplest explanation is most likely the one nearest the truth reply skygazer 10 hours agorootparentironically, that’s too simplistic. Simplicity is only virtuous in an explanation if the explanation itself is not contradicted by reality. Unbound from reality, simplicity is dangerously seductive because it’s easy and wrong. reply bch 7 hours agorootparentFor every complex problem there is an answer that is clear, simple, and wrong.- H.L. Mencken reply ghufran_syed 1 hour agorootparentprevvery glib (though true) - but do you have any evidence in this case as to what reality is? If so, could you please explain how the given statement is \"contradicted by reality\"? reply haltist 10 hours agorootparentprevDiscovered a while ago by Occam.[1]1: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Occam%27s_razor reply achileas 8 hours agorootparentThat’s not how Occam’s Razor works, though, as explained in your link. reply gjvc 10 hours agorootparentprevno shit. tell me why the sky is blue. replybigiain 12 hours agorootparentprevJessica went out of her way to use the slightly awkward phrase &#x27;founding donor&#x27;, so she&#x27;s at least trying to imply she isn&#x27;t just trying to protect an investment. I&#x27;m going to take the generous interpretation of that and assume she means what she says there, and isn&#x27;t just playing politics and share price PR. reply ChuckMcM 13 hours agoparentprevI sometimes think that at this level of the game everyone hates everyone else and its all politics. You don&#x27;t \"come out\" for or against anyone publicly, you leave all of that under cover. It makes knowing who your friends and enemies are more difficult and it restricts your ability to maneuver. Another quote from my grandfather was \"Mutual respect does not require that you like someone.\" reply nabla9 13 hours agorootparent\"like\" or \"hate\" are words for people and petty personal conflicts.It&#x27;s counterproductive to take business conflicts personally. PG removed Sam Altman silently without harming his future. There is no reason to be enemies after the issue is solved. There may be deals to be made again. reply ChuckMcM 13 hours agorootparent> It&#x27;s counterproductive to take business conflicts personally.100% agree with this, but it is productive to understand what was behind a business conflict. Personal like or dislike can change which alternative of a choice of equal alternatives, someone might make. As Tony Soprano would say, \"It&#x27;s just business.\" reply hitekker 9 hours agorootparentYour comments are great but your audience is inexperienced. Most of our experience is largely in pointless, online arguments and few serious real-life struggles. The latter scares the hell out of us so we run from the conflict and from our feelings. Then we say we \"didn&#x27;t take it personally\" to cover up the cowardice. reply rramadass 6 hours agorootparentprevhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38388714 reply socketcluster 11 hours agorootparentprevIt comes down to alignment of interests and alignment of values. I think previous comment is right in suggesting that people&#x27;s interests and values may not be clear at that level. People often hide them to appeal more broadly.The more you reveal about yourself, the fewer people you will appeal to because very few people share your exact values. People tend to like people who share some obvious common values and they assume that the values that are unspoken are also a match. In reality, it&#x27;s rarely so.As people learn more about the world and themselves, they begin to realize that some values that they didn&#x27;t consider before are very important and they may be shocked to find that certain people they used to like do not share those values which they took for granted. reply rramadass 7 hours agorootparentprev> It&#x27;s counterproductive to take business conflicts personally.All conflicts are Personal. It is only when you weigh your response and its consequences to short-term and long-term goals that you start spouting niceties like \"It&#x27;s not Personal; it&#x27;s just Business\". It is a question of balancing emotions vs. rational strategy&#x2F;tactics; sometimes it suits the circumstances and sometimes it doesn&#x27;t.Kautilya&#x2F;Sun-Tzu&#x2F;Clausewitz are relevant here. reply koolba 12 hours agorootparentprev> PG removed Sam Altman silently without harming his future.When police departments do that to overly aggressive cops, it’s generally considered a bad thing. reply catlover76 12 hours agorootparentThere are different sets of concerns governing police accountability, transparency, etc., from those governing various different types of corporations, and rightly so. reply cbsmith 10 hours agorootparentIt makes sense. It&#x27;s not like corporations have responsibilities that can have life & death impacts on people, or that can radically transform the lives of people who don&#x27;t even work there.Oh wait... reply catlover76 8 hours agorootparentThe glibness of this superficial comparison doesn&#x27;t change the fact that anyone who actually thought seriously about crafting laws to deal with both of those would find themselves dealing with very different scenarios, both from a practical and moral&#x2F;philosophical perspective.But of course, if one just wants to say snide things on the internet, yeah they&#x27;re simply the same in every major respect, why bother thinking that hard about it. reply cbsmith 1 hour agorootparent> The glibness of this superficial comparison doesn&#x27;t change the fact that anyone who actually thought seriously about crafting laws to deal with both of those would find themselves dealing with very different scenarios, both from a practical and moral&#x2F;philosophical perspective.Yes. There aren&#x27;t a lot of rogue cops in a position to put billion dollar holes in the economy. Few of them are in positions to influence medical decisions for millions of patients. While a rogue cop might be able to influence parole board decisions for thousands of criminals, it&#x27;d be terribly difficult to impact millions.Yes, in theory, the police have a unique monopoly on the use of violence in society, which leads to unique challenges and scenarios. However, the potential problems that stem from removing someone from a responsibility without impacting their future have nothing to do with said monopoly, as demonstrated empirically with teachers, religious leaders, doctors, politicians, and yes, business leaders. In specific cases, it might be the right thing to do, but if you think about it, the potential problems from systemic application of this practice can lead to terrible outcomes that are proportional to the amount of responsibility, not the nature of it....but why bother thinking that hard about it? reply jmye 8 hours agorootparentprevDoes YC? Or are you just irrelevantly musing?Or is this where we pretend that leading YC is even vaguely similar to being a rogue cop, in terms of potential impact on people’s lives? reply cbsmith 1 hour agorootparentI wasn&#x27;t trying to suggest they were similar.It might be hard to imagine this, but it is possible that leading a company deploying billions of dollars might actually have a significantly larger potential impact on people&#x27;s lives than a rogue cop. reply serf 5 hours agorootparentprev>Or is this where we pretend that leading YC is even vaguely similar to being a rogue cop, in terms of potential impact on people’s lives?If a cop shoots someone and kills them, it destroys that life and possibly the family of those around him, the legal system kicks in -- that cop gets ousted or thrown into prison.how many lives have been destroyed by the mere existence of reddit and twitch, and by extension the human trafficking they help to support? how about victims of sexual exploitation that are enabled by platform payment services? how about the person drug below the Cruise self-driving car for 20+ feet? how about drug interactions caused by e-doctor prescriptions that have little over-sight or supervisory element?how about the simplest and most common thing ever -- how many lives are fucked up when an acquihire or business movement of some sort liquidates 80% of the staff?I think the fantasy of the reins-holder being pardoned for the sins of their business is a concept that needs to be re-evaluated; these elements do serve to do damage as well as social good.a rogue cop constitutes a rogue element in society that is dealt with in fairly swift fashion, a rogue corporation pays the fines and continues until a senator or similarly powerful person speaks up and points a finger ; that opens the floodgates for abuse. reply licebmi__at__ 3 hours agorootparentThe same guys who boost time and time again about “making the world a better place” would like everyone to wave away the responsibility on negative externalities their companies cause. reply saagarjha 2 hours agorootparentprev> If a cop shoots someone and kills them, it destroys that life and possibly the family of those around him, the legal system kicks in -- that cop gets ousted or thrown into prison.I’m sorry, are you familiar with the ACAB movement at all? replyinglor_cz 11 hours agorootparentprevThat is an astonishingly bad analogy.Believing that a person is not a good match for a certain business position is worlds apart from a public servant intentionally abusing his legally sanctioned monopoly on violence.The first kind of person may be well a good match for another position, in another company; the latter is just a criminal in uniform. reply murakamiiq84 7 hours agorootparentRight, it depends on the details of his firing, like was it more about Altman being spread too thin or if it was more about ethics. reply unethical_ban 12 hours agorootparentprevThis is laughably naive or frustratingly bad faith to think abusive cops are similar to incompatible business partners. reply mihaic 11 hours agorootparentNot to me, when those \"business partners\" are in charge of some agencies like YC that do influence the society we live in. reply lovich 11 hours agorootparentIf I didn’t know I was on HN I would after a comment like this. reply LightBug1 11 hours agorootparentNaive, in the extreme. reply yawaramin 4 hours agorootparentExtreme opinion, detached from reality. reply lovich 10 hours agorootparentprevNah, just pattern matching replytsavo 13 hours agorootparentprevA similar saying that I learned from a business mentor years ago, \"Just because someone is nice to you doesn&#x27;t make them your friend, just because someone is mean to you doesn&#x27;t make them your enemy.\" reply jzb 13 hours agorootparentprevI&#x27;m sure there&#x27;s some genuine friendships, but it&#x27;s always interesting to see what people say publicly vs. privately. Also fair to say that there are people I&#x27;ve worked with that I did not, at the time, appreciate but grew to appreciate later on.Years ago I was at an event talking to a colleague who was absolutely bashing someone (with good reason) and then another colleague walked up. Same person came up and my first colleague changed tone to \"yeah, so-and-so is an interesting character.\"Because I knew that the other colleague also hated the person, I called him on it. I wonder, though, how often that dynamic plays out where nobody will voice a negative opinion publicly - so people slide by without being called on behavior that shouldn&#x27;t get ignored. reply ChuckMcM 13 hours agorootparent> I&#x27;ve worked with that I did not, at the time, appreciate but grew to appreciate later on.Exactly right. People are complicated and liking or disliking them is adjacent to whether or not they are &#x27;good&#x27; at their job.I&#x27;ve known people who sucked at their job, but doing the same job in a different environment were stars. That experience led me to disassociate what people do as part of their job from the person themselves. And I can respect someone for doing a good job, even when I find their personal attitude or motivations distasteful.Complicated. reply themagician 12 hours agorootparentprevIt&#x27;s all politics WAY before this level. reply klik99 13 hours agorootparentprevDef not true. People who operate at this level can separate business and friendship. But occasionally when big enough deals fall through it can damage long term friendships, but it&#x27;s not common. PG firing sama and keeping it secret sounds like PG likes and respects sama but didn&#x27;t think he should run YC. If he didn&#x27;t like sama he could have done a lot more damage by making it more public. reply colecut 13 hours agorootparentprevThe comment you are responding to has quotes of people definitely coming out \"for\" Sam. reply imjonse 14 hours agoparentprevPaul&#x27;s tweet is an objective statement, it does not say anything about character or values and is not explicitly supportive. reply ketzo 14 hours agorootparent…you think calling someone “the best in the world” isa) purely factualb) not supportiveUh, what on earth would count as explicitly supportive language? reply hn_throwaway_99 13 hours agorootparentDid you miss the context of the image in that tweet? It&#x27;s the famous \"I have a particular set of skills...\" speech from Taken: https:&#x2F;&#x2F;youtu.be&#x2F;jZOywn1qArIIn other words, he&#x27;s basically saying Sam is the best in the world at being a ruthless mofo in these situations and obliterating those who oppose him. \"Admiring language\", perhaps, but I wouldn&#x27;t really call that \"supportive language\". reply patrec 2 hours agorootparent> he&#x27;s basically saying Sam is the best in the world at being a ruthless mofo in these situations and obliterating those who oppose himExactly, it&#x27;s not all that subtle, so I find it hard to even come up with an alternative interpretation. reply prawn 8 hours agorootparentprevOne can quickly see that an individual ideal for a ruthless frontier with competing behemoths might be less perfect for a slightly more encouraging and nurturing incubator. reply murakamiiq84 7 hours agorootparentAnd also how a board of academics + Adam + Ilya of a nonprofit ostensibly optimizing for \"humanity\" might not consider someone like that the best fit for representing the nonprofit, especially if he was gaslighting them and treating them like NPCs. reply actionfromafar 10 hours agorootparentprevThis is the most important comment in this whole thread. reply patmcc 12 hours agorootparentprevIf my favourite sports team was in the championship (and the underdog), I could easily make the claim \"team $NOT_MY_TEAM is the best in the world\" and still hope that my team beats them.Not saying pg is doing this, of course. reply onetimeuse92304 13 hours agorootparentprevAny person that gets to this position must be good at some things.Acknowledging it does not mean supporting the person. It is just a factual statement.Even Adolf Hitler was good at certain things like manipulating masses of people. Saying this absolutely does not mean I support Hitler. It is just a factual statement. reply Waterluvian 14 hours agorootparentprevThat’s a really good example of not being explicitly supportive. It’s an objective statement. If I said “Roy Sullivan is the best in the world at being struck by lightning” it may implicitly feel like I’m rooting for him. But I’m just stating a fact.What would count?“I think Roy Sullivan is the man to be struck an eighth time. He’s the best at it. I hope he succeeds.” reply pests 14 hours agorootparentIs it though?When the fact is subjective to begin with?I would even say “Roy Sullivan is the best in the world at being struck by lightning” is not a fact at all but an opinion.And by giving an opinion you are passing judgement.How can you claim saying something such as \"Washington was the best president\" is in some way a fact? Can you find it in reference books? Is it defined from the laws of nature? Does anyone even believe my quote? reply Waterluvian 13 hours agorootparentHe held the world record, so I’m comfortable saying he was the best at it. If that’s not sufficient and we’re interested in being a semantic pedantic, that’s not a discussion that interests me. reply pests 11 hours agorootparentStill an opinion, sorry. reply pests 6 hours agorootparentTo clarify some, \"best\" in “Roy Sullivan is the best in the world at being struck by lightning” is subjective.Who cares that he got hit three times? Okay, he was hit the most times. That is a fact. I saw a video of a guy getting hit and he did it with grace and elegance - I think hes the best at getting hit. How is \"something is best\" ever a fact? reply snickerbockers 13 hours agorootparentprevSo the statement is that Sam Altman is the best person in the world at getting fired? reply Waterluvian 13 hours agorootparentNot sure. But it’s different from saying they support Altman’s endeavour in being the best at it. reply saiya-jin 13 hours agorootparentprevI wouldn&#x27;t shake my hand with some of the best in the world. Why so damning? Heck we didn&#x27;t even define in what they are best in, could be contract killing or lying for example (not applying to the actual topic and person, just generic statements).More to the point, some people are natural leaders, they can process many stressful complex situations in parallel without breaking a sweat. I know I can&#x27;t, not long term, all the kudos to them.At least some of them are also amoral a-holes, highly functioning sociopaths (these get more common the more power and money floats around till they become the norm). reply paulryanrogers 10 hours agorootparentThere is speculation PG is suggesting Sam is the best at gaining and consolidating power. Considering his swift rise that may be accurate. reply nerbert 14 hours agorootparentprevBeing the best in the world to deal with a situation is a neutral statement. Putin is the best in the world to deal with the situation he’s in right now, if you need a negative angle on this. reply loeg 13 hours agorootparent> Putin is the best in the world to deal with the situation he’s in right now, if you need a negative angle on this.Probably not true? It seems like Russia could use another Yeltsin (or Gorbachev) more than Putin for its current situation. reply epicureanideal 13 hours agorootparentI don’t think most Russians would agree that either of the other gentlemen would be preferable. The 80s and 90s were not a time of great happiness, prosperity, calm, and order. reply nerbert 1 hour agorootparentAnd just like sama may not be the best to run OpenAI of humanity’s interest, Putin isn’t the best to run Russia for humanity’s interest. But both men are incredibly successful at navigating power dynamics to maintain their control over their respective organizations. reply plasmatix 13 hours agorootparentprevNot for Russia&#x27;s benefit but for his own. reply dragonwriter 13 hours agorootparentprev> It seems like Russia could use another Yeltsin (or Gorbachev) more than Putin for its current situation.He did say best in the world, not best that can be imagined; so unless you are saying there is another Yeltsin or Gorbachev available...OTOH, Putin is himself an active reason why alternatives aren&#x27;t readily available. reply loeg 9 hours agorootparentI think there are plenty of Russians alive who could do a better job than Putin. Possibly most of them. One of their defining advantages would be that they are not Putin and can renounce his actions. reply jokethrowaway 13 hours agorootparentprevI think they spent decades growing their economy and preparing to be independent of the west and now our sanctions are useless.It feels like this situation is exactly what they want (and likely an historical inflection point, where we pit east vs west again). Dropping the cold war was needed because they had no resources (surprise, socialism doesn&#x27;t work!).I&#x27;m waiting for Taiwan next and then I&#x27;d say we are completely *** (especially looking at our reliance on the east for manufacturing &#x2F; energy and how useless our governments are). reply astrange 10 hours agorootparentThe point of sanctions isn&#x27;t to hurt their economy (that would just make their people mad at us), it&#x27;s to stop them from resupplying their military.Their response is to become dependent on China instead. replypaulcole 13 hours agorootparentprev> No one in the world is better than Sam at dealing with this kind of situationThis is clearly entirely subjective. To prove otherwise, feel free to show me the list ranking how people in the world would deal with this kind of situation and explain why Sam Altman ends up on top of that list. reply Dudester230602 14 hours agorootparentprevReminds me of this (first one): https:&#x2F;&#x2F;www.muddycolors.com&#x2F;2011&#x2F;09&#x2F;artistic-insults-from-fa... reply jjtheblunt 11 hours agorootparentprevit&#x27;s implausible, because the hyperbole is over the top: he&#x27;s wealthy from writing programs, and clearly has not assessed every single person in the world, so he knows better. reply usefulcat 4 hours agoparentprevThat’s all we’ll and good, but neither does it contradict TFA. reply goodluckchuck 7 hours agoparentprev> \"No one in the world is better than Sam at dealing with this kind of situation.\"Wow, not the kind of compliment I’d want to receive.This situation is rotten with conspiracy, backstabbing, money-grabs, rumor, innuendo, etc.This(?!) is what Sam is so great at? reply wdr1 10 hours agoparentprev> I&#x27;m not buying that there&#x27;s a lot of bad blood thereI didn&#x27;t see anything in the article that there was bad blood, just that Paul fired Sam. Those are not the same thing. reply likeabatterycar 11 hours agoparentprevI must confess I was hoping for a more sordid tale of Silicon Valley sociopathy, like someone using a potted plant in an office at YC HQ as a makeshift toilet, as a means of settling a petty disagreement. Imagine my disappointment reading this was a run-of-the-mill case of divergent minds. reply halfjoking 13 hours agoparentprevIn the made-for-tv movie about OpenAI - PG is played by an actor mimicking Trump, and that&#x27;s Sam&#x27;s origin story. \"You&#x27;re Fired\"Sam with his slick black hair, looking like Tom Hiddleston&#x27;s Loki... \"my ambition knows no bounds, I will build AGI and then you will understand my TRUE power.\" reply jeofken 12 hours agorootparent> played by an actor reply bzbz 12 hours agorootparentWhat is this comment even trying to say? reply halfjoking 8 hours agorootparent“You should leave YC to focus on what you want” is not “you’re fired”It’s like they’re trying to make a TV drama out of nothing. reply philwelch 12 hours agorootparentprevBy the time they make a movie about OpenAI, there will be no more human actors. reply davidwritesbugs 2 hours agorootparentAnd OpenAI will be run by the Q*LLM. replygreatNespresso 16 hours agoprevIt came as a surprise for me to learn that PG fired Sam. It&#x27;s the first time that I read this actually, and if that&#x27;s true, I find it kind of mysterious that it remained a secret for so long. Or maybe I missed the news somehow but I could not find any other mention of that event on Google. reply hn_throwaway_99 15 hours agoparentI&#x27;ve definitely never heard of it, and I was pretty shocked when I read it given how much positive stuff pg has written about sama, and the article itself says the firing \"has not been previously reported\".Reading some recent pg tweets through this lens, though, I think it makes sense. E.g. there is this tweet: https:&#x2F;&#x2F;twitter.com&#x2F;paulg&#x2F;status&#x2F;1726198939517378988. Both of the following can be true (and more to the point, I think the following two items are flip sides of the same coin):1. Sam is an absolute masterful negotiator and is incredibly well-respected in the valley because his skills at assembling people and resources are unmatched.2. Sam can be manipulative and self-serving, sometimes making decisions that are nominally about a higher goal but (not really coincidentally) are self-aggrandizing.I see this trait in lots of effective, famous people. There have been tons of comparisons in the news recently to Steve Jobs, but for me for some reason Anna Wintour comes to mind. I don&#x27;t think many people would describe Wintour as \"nice\" as she is known for being kind of ruthless and manipulative (she was \"The Devil\" after all...), but tons of people in the fashion industry are incredibly loyal to her based on her abilities to identify talent and get shit done. reply btown 13 hours agorootparent> sometimes making decisions that are nominally about a higher goal but (not really coincidentally) are self-aggrandizing\"Had to be me. Someone else might have gotten it wrong.\" reply bart_spoon 10 hours agorootparentIsn’t that reference like the exact opposite? It’s nominally self-aggrandizing (he’s the only one who could have gotten it right) but is actually about a higher goal (sacrificing himself for everyone else’s sake). That’s how I remember reacting to it anyways. reply SpaceManNabs 12 hours agorootparentprevIt has been a decade, but let me guess, Mass effect 3 Mordin? I rather not look it up lol. reply noitpmeder 11 hours agorootparentprevDamn this line still pulls at the heart strings... Might have to replay reply greatNespresso 14 hours agorootparentprevYou make a fair point about that tweet, it can be ironic or sincere and it left me a mixed feeling. I am not sure what was PG&#x27;s goal with that tweet but it did not feel necessary. reply AndrewKemendo 7 hours agorootparentprevIt’s a straight down the middle, no questions about it, perfectly crafted politically perfect Narcissistic capitalist.Sam is what would come out if you created a technocrat in a lab reply icelancer 13 hours agoparentprevI&#x27;ve fired people and later recommended them for jobs where they&#x27;d be a better fit. Not uncommon at all. reply hackitup7 11 hours agorootparentAgreed, it&#x27;s very common to see. In many cases you&#x27;re talking about people who worked together very closely for years and are verging on as close as family. Also, in higher-level roles you often get fired due to a very specific lack of skills or a very specific weakness that wouldn&#x27;t be at all applicable for another job.Ex \"this person is an amazing startup CTO but they get problematically overwhelmed when the organization gets to 100 engineers\" – you would 1000% recommend that person to a 50-person startup even if they got fired from their job at a 500-person company. They might even be better at it the next time around. reply washadjeffmad 12 hours agorootparentprevMy immediate thought. Relatively few have been in management here, perhaps. reply icelancer 12 hours agorootparentIt&#x27;s largely engineers who don&#x27;t really understand the value of a C-level person, as evidenced time and time again in the comments.The concept you could fire someone for business reasons and later be their very good friend and recommend them for another job - sometimes an even better one than you employed them in - doesn&#x27;t fit the single-input single-output mind of a lot of engineers.It&#x27;s alright. We all have roles to play. reply gardenhedge 11 hours agorootparentYour reg dates are 2012 and 2014. As you know, this is hacker news. not c-level news, not middle management news.. hacker news. reply imdsm 10 hours agorootparentThat&#x27;s exactly the point. I&#x27;m C level, but at heart, I&#x27;m a hacker and and engineer, and have been for what, 24 years now (sobering). Reflecting on this isn&#x27;t a criticism (though we all know how touchy engineer-types can be) -- it&#x27;s just an acknowledgment. To E-types, firing is loss of job, loss of livelihood, to C-types, it&#x27;s a reposition of an asset, a reassignment of a resource to a new project. All we&#x27;re doing here is acknowledging this. reply saagarjha 2 hours agorootparentprevThere’s no reason a manager can’t also have been a hacker. Or still might be, from time to time. reply icelancer 2 hours agorootparentprevLike I said, we all have roles to play. I suppose you missed that. May you learn along the way in your career. reply gopher_space 6 hours agorootparentprevI understand the morality needed to succeed and flatly reject it. reply shswkna 1 hour agorootparentWhile this is a common attitude in western society, it does not make sense if you zoom out. Acting morally&#x2F;ethically and being successful are not mutually exclusive. But it is more difficult, and it might require a more careful assessment.You only exist because every ancestor of yours, up to your single celled ancestor, succeeded in &#x27;life&#x27;. To denounce success for its own sake, is, for lack of a better term, stupid. reply icelancer 2 hours agorootparentprevChoosing to lose instead of succeed is indeed a choice. And a valid one I&#x27;ve made a few times. As long as you realize the tradeoff. replytwoodfin 14 hours agoparentprevWeird: The most relevant hn post on Altman’s departure from YC is https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19342184But despite comments to the effect that the YC post indicated Sam’s departure, it doesn’t seem to say anything about it right now? reply dang 11 hours agorootparentI&#x27;m pretty sure the HN thread hasn&#x27;t changed, but you&#x27;re right, the YC post has: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190310042303&#x2F;https:&#x2F;&#x2F;blog.ycom.... One could bisect to find out where. Weird! I&#x27;ve never known these things to change like that, and it&#x27;s not as if the news wasn&#x27;t already public. reply js2 10 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38386524 reply theschmed 13 hours agorootparentprevNor in 2022 when it was first archived by Wayback (unless archives from previous have been removed)https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230000000000*&#x2F;https:&#x2F;&#x2F;www.ycom... reply twoodfin 13 hours agorootparentBut this contemporaneous TechCrunch article—which is clearly talking about the same blog post—says it did!https:&#x2F;&#x2F;techcrunch.com&#x2F;2019&#x2F;03&#x2F;08&#x2F;y-combinator-president-sam... reply jeromegv 11 hours agorootparentprevThey actually changed the URL structureThis is the old URL, and they indeed mentioned Sam leaving https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190316222853&#x2F;https:&#x2F;&#x2F;blog.ycom... reply theschmed 10 hours agorootparentOhhhh thanks.Looking at those it looks like there was an edit:> Updated on 6&#x2F;12&#x2F;20> In May 2019, Geoff Ralston took over as YC President. At that time, Sam Altman stepped away from any formal position at YC.https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201028062425&#x2F;https:&#x2F;&#x2F;blog.ycom...And then shortly after the edit disappeared too:https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20210423025128&#x2F;https:&#x2F;&#x2F;blog.ycom... reply twoodfin 10 hours agorootparentI mean, do what you want, the YC blog is not the New York Times, but the Winston Smith-esque silent modifications are cast into some relief given current events. reply jacquesm 8 hours agorootparentprevYou are watching history being made. reply greatNespresso 14 hours agorootparentprevThank you for the article, I saw a comment from Sam in the HN post but agreed it did not look obvious that he got fired. reply throwaway_xghd 11 hours agorootparentprevThe statement about Sam on the announcement post at https:&#x2F;&#x2F;www.ycombinator.com&#x2F;blog&#x2F;updates-from-yc&#x2F; evolved over time:1. March 2019: \"Sam is transitioning to Chairman of YC and has shifted his operational responsibilities at YC to other partners. This change will allow Sam to spend more time focusing on OpenAI while still being responsible, along with the rest of the partnership, for the long-term social and economic success of YC. Because YC is run as a partnership, there will be no significant operational change.\"2. June 2020: \"In May 2019, Geoff Ralston took over as YC President. At that time, Sam Altman stepped away from any formal position at YC.\"3. April 2021: gone entirelywaybackmachine: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190310003417&#x2F;https:&#x2F;&#x2F;blog.ycom...Basically seems like they were updating it as leadership turnover happened as Sam went from president to chair to out, and Geoff from partner to president to out. reply CSSer 14 hours agoparentprevWe have a tendency to remember the good and not the bad, and we want to see our friends do well. Someone else also pointed out here in the comments that no one wants to publicly state they made a bad call if they can avoid it because it will likely damage them personally. We give others lots of chances, or we encourage and cheer them when others are taking chances on them in the hopes that they&#x27;ll do better this time even when we would no longer risk our own skin.I imagine most of us think, \"S&#x2F;he was so close to success. Maybe s&#x2F;he&#x27;ll have learned! What could be the harm in talking them up a bit? Besides, no one wants to ruin someone else&#x27;s life,\" reply JabavuAdams 10 hours agoparentprevI feel the same way about Annie Altman&#x27;s allegations. Those were out there, but somehow I wasn&#x27;t aware of them, and I see almost no one discussing them. I mean, I understand why, but it&#x27;s still disheartening. reply concordDance 1 hour agorootparent> I understand whyBecause its pointless and unpleasant, we have zero means of verifying or discomfirming the story and it won&#x27;t go anywhere because its unprovable. reply joshxyz 2 hours agoparentprevmg impression is that he outgrew the role. that he is better being a ceo somewhere than babysitting founders. reply davesque 14 hours agoparentprevIt could be that the parties involved have chosen at this moment to re-imagine whatever occurred back then in a less favorable light. Since firing is on everyone&#x27;s mind, and since you can get media attention points by playing along with a juicy narrative, what might have just been described as a disagreement in the past might now be called a firing. I would be skeptical of takes like this. reply miiiiiike 7 hours agoparentprevSometimes you have to fire people you like. It doesn&#x27;t have to be a relationship shattering event. reply lhnz 20 hours agoprevIf Paul Graham fired Sam Altman from YCombinator it&#x27;s interesting that he appears to have such a favourable opinion of him [0].However, personally, what I&#x27;ve taken away from this is that he is a much better strategic&#x2F;tactical operator than many other high-flying executives and very capable of winning the respect and trust of a lot of smart people. I wouldn&#x27;t expect OpenAI to be run by anybody that wasn&#x27;t revered in this way; a lot of CEOs aren&#x27;t saints.[0] https:&#x2F;&#x2F;twitter.com&#x2F;search?q=from:paulg%20since:2019-01-01%2... reply tom_ 17 hours agoparentI dunno, man. As an English person, to me these tweets sound a lot like he is publicly calling Altman a cunt. reply thepasswordis 15 hours agorootparentIt’s really funny to re read this with that perspective.>My kid was really surprised to find out that Sam cofounded this company.>Sam is going better than you. Do better.Etc. I don’t know that you’re right, since these do sound like praise, but it’s kind of a funny game to change the tone and make them into catty insults. reply lhnz 15 hours agorootparentprevReally? It seems like a glowing appraisal. He seems to think that Sam is devestatingly effective at what he does. reply adastra22 12 hours agorootparentGraham is English. The English have a wonderful talent for making backhanded “complements.” E.g. “you’re a truly unique individual” or “I always feel more intelligent after speaking with you.”The American convention is to look for the positive and assume that was intended. The English convention is to look for the negative and assume that was the real meaning.E.g. “Sam is going better than you. Do better.” Could mean “Even that incompetent dipshit Sam is going to do better than you can, that’s how much of a hole you’re in.” reply jacquesm 8 hours agorootparent&#x27;Interesting&#x27; -> &#x27;you&#x27;re barking mad&#x27;. reply lhnz 12 hours agorootparentprevI am also English. :) reply specialist 11 hours agorootparentprevPer Guy Kawasaki (The Macintosh Way), the sincerity of Jean-Louis Gassée&#x27;s feedback was inversely proportional to the level of praise.That anecdote prompted me to do the same (in corporate battlefields). Works great. reply VeejayRampay 4 hours agorootparentGassée is French though, very different feedback culture reply tom_ 15 hours agorootparentprevIf I didn&#x27;t know Graham was English, perhaps I would take them at face value - and, indeed, perhaps I should anyway. (And my characterisation was an extreme one!) But: they do just all sound rather coldly backhanded, if you ask me. reply turzmo 14 hours agorootparentAmerican, but I read PG&#x27;s tweets as someone who absolutely does not want to piss off Sam but is willing to come close to the edge of plausible deniability in damning him, e.g.:> The most alarming thing I&#x27;ve read about AI in recent memory. And if Sam thinks this, it&#x27;s probably true, because he&#x27;s an expert in both AI and persuasion.There certainly isn&#x27;t the paternal warmth you might expect from a proud mentor. reply lhnz 13 hours agorootparentprevWell, I&#x27;m also English and I didn&#x27;t read them that way. However, I do think that Paul is telling people that competing with Sam in certain domains would be extraordinarily difficult.The other thing is that if you take a look at Paul Graham&#x27;s blog posts, he used to regularly thank Sam at the bottom of these -- this isn&#x27;t something you do if you don&#x27;t like or respect someone. However, on the other hand, perhaps they fell out at some point? I can&#x27;t personally make out that signal from the little data there is. reply skilled 15 hours agorootparentprevI like your way of seeing it and I see the same now. If this is true (the article) then for sure it’s a nice inside jab that only Sam would get.Also, I doubt pg would hold a grudge for years on end. You learn many lessons in life and some you are bound to repeat because of stubbornness or whatever. reply itronitron 14 hours agorootparentI think with some of pg&#x27;s tweets he definitely seems to be laying it bare, but only for those people that know what to watch out for. reply lupire 8 hours agorootparentprevGraham moved to the US at age 14. He&#x27;s as American as he is British. reply thatguysaguy 15 hours agorootparentprevThey all say he&#x27;s good at what he does, but none of them actually sound like he likes the guy. reply nothrowaways 14 hours agorootparentprevI read it like so. reply andrelaszlo 15 hours agoparentprevAnyone able to quote these xweets for people without an account? reply martinclayton 15 hours agorootparentMight work: https:&#x2F;&#x2F;nitter.poast.org&#x2F;search?f=tweets&q=from%3Apaulg+sinc... reply TuringNYC 9 hours agoparentprevFascinating! It feels like a Sixth Sense moment where, as I go back and look at these, many can be interpreted a whole different way. reply justrealist 15 hours agoparentprevPaul&#x27;s wife has a huge financial stake in OpenAI, so I suspect massive success there has softened his opinion. reply liuliu 15 hours agorootparentThese are donations. How that becomes investment &#x2F; financial stakes? (It is a question, since how the transition to capped-profit left a lot of questions unanswered). reply didibus 4 hours agorootparentDonations are to the non-for-profit, but now that there is a for-profit arm, private investors can purchase \"stock\" if you want. Share of the company that grants them some percentage of the company profit (when it eventually starts turning a profit).And they can also resell those \"shares\" to other people, at whatever prices people are willing to pay for them.The only restriction is there is a 100x cap on return. So if you paid 1 billion for your \"shares\", once they&#x27;ve returned you 100 billion as a profit percentage, or by reselling the \"shares\" to other people, you can&#x27;t make anymore money for the profit sharing.But if you still have \"shares\", you can still sell them to others at whatever price they want.So for example, say I buy 100 shares worth 100$ each. That&#x27;s worth 10k total. My cap is thus at 1 million.Say there are 1000 shares total, that means I&#x27;m owed 10% of the profit OpenAI makes. But after making 1 million, it stops and I&#x27;m not owed anymore profit.That said, I still have 100 \"shares\". They just stop returning me a percentage of the profit. But I can sell those shares to someone else at whatever price they want. So I could sell them to someone else at 200$ each. And the person that receives them is now owed profit from the percentage of share he owns up to their own cap, which for them would be based on a 200$ price, so they can make a profit return up to 100x of 200$. reply jpeter 15 hours agoparentprevRokos Basilisk reply erikig 15 hours agorootparentIs this why there was a power struggle for OpenAI’s direction? reply B1FF_PSUVM 12 hours agorootparentprevClicksaver: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Roko%27s_basilisk reply Merrill 20 hours agoprevBased on the article and the loyalty shown by openai employees, he appears to be the \"difficult to manage\" type, rather than the \"difficult to work for\" type.That&#x27;s not necessarily a bad thing in employees. I was once told that it is easier to round off the corners of a cube than to develop corners on a sphere. reply Jensson 20 hours agoparentFrom this story sounds more like \"difficult to not work for\". reply hatenberg 15 hours agorootparentOr you know, he personifies paper millions everyone thought they had in the bank reply rsynnott 20 hours agoparentprevIME one almost always implies the other. reply lobsterthief 20 hours agorootparentNot in my experience, at all. Working beneath someone who’s difficult to work for can make your every day at work terrible. Working with someone who’s hard to work with is much more maintainable since you’re more in control of the interactions and can effect change by working with people higher in the org. reply rsynnott 20 hours agorootparentOh, I mean that if someone’s a bad subordinate or peer they’ll probably also be a bad boss, or vice versa. I’d agree that a bad boss tends to be a worse thing to have than the other too. reply 1123581321 14 hours agorootparentprevI haven’t seen that. Some of my favorite coworkers and managers have been people who were hard to manage. It’s because they have strong principles and they prioritize good relations with their peers and subordinates over being promotable.I understand you are probably talking about people who uniformly act like jerks but I haven’t found them to be as common. reply marcinzm 14 hours agorootparentprevNot my experience at all. Someone who pushes back on their boss to get the team they manage what they need is exactly that type of person. reply throwawaaarrgh 17 hours agorootparentprevBut not as a truism. It&#x27;s possible to manipulate well enough that people above and below you both believe you are working in their interest, but it&#x27;s quite hard. Great for job security if you can pull it off. reply reissbaker 13 hours agoprevThe double-dipping charge doesn&#x27;t seem particularly real — even pg still to this day personally invests in YC companies while they&#x27;re in YC, even before Demo Day (e.g. Phind). I very much doubt he fired Sam for doing it too. It reads to me like Sam was focusing more on OpenAI (the \"absenteeism\" that the article mentions was primarily due \"to his intense focus on OpenAI\") and pg told him he couldn&#x27;t do both.Somehow trying to tie that to the OpenAI board — which couldn&#x27;t even come up with a concrete reason for firing him to their attempted CEO replacements, who both then switched sides to supporting Sam — seems like a stretch. reply bambax 13 hours agoprev> “Ninety plus percent of the employees of OpenAI are saying they would be willing to move to Microsoft because they feel Sam’s been mistreated by a rogue board of directors,” said Ron Conway (...) “I’ve never seen this kind of loyalty anywhere.”95% is the kind of score one sees when there&#x27;s an \"election\" in a dictatorship. Unanimity is often suspect. reply PeterStuer 1 hour agoparentI can&#x27;t help but wonder how that \"Ninety plus percent\" would change in a convincingly anonymous voting process instead of a public social pressure with potential repercussions environment. reply Geee 14 hours agoprevIt seems that there are a lot of people who are loyal to Sam because they are scared of crossing him. If this is really the pattern here, then this is probably not the timeline we want to be on. reply drtgh 13 hours agoparentI&#x27;m following the whole story to see if there&#x27;s a sociopath involved. reply brap 12 hours agorootparentProbably most of them. reply _fizz_buzz_ 14 hours agoprevKind of interesting that Jessica Livingston (Paul Graham&#x27;s spouse) tweeted this a couple of days ago:> The reason I was a founding donor to OpenAI in 2015 was not because I was interested in AI, but because I believed in Sam. So I hope the board can get its act together and bring Sam and Greg back.https:&#x2F;&#x2F;twitter.com&#x2F;jesslivingston&#x2F;status&#x2F;172628436492378127... reply toomuchtodo 14 hours agoparentTo be a fly on the wall when Paul and Jessica talk about Sam in private. So many interesting questions never to be answered.(no other reason than to understand how all the puzzle pieces come together) reply hindsightbias 12 hours agorootparentOn one side Paul calls it AIgiarism and she&#x27;s throwing donations at it.Maybe we should all hedge our bets when it comes to our AGI overlords. reply iaseiadit 12 hours agoparentprevYC is invested in OpenAI. Wonder if they want a win-at-all-costs type person (if we go along with this premise) running a company they’re invested in, yet not want him running their company. reply patall 20 hours agoprev> Another person familiar with Altman’s thinking said he was willing to meet with the board’s shortlist of proposed candidates, except for one person whom he declined on ethical grounds.Now you have me interested, who could that one person be? Charles Koch? Henry Kissinger? Because many of those I would normally have guessed are either in the article as possible collaborator (middle-easter connection) or is already an investor (like Elmo). Honestly, who is too ethically different here and yet still within the anglosphere to be considered a board member? reply aidenn0 18 hours agoparentAssuming he&#x27;s as manipulative as the worst reports of him say, \"ethical grounds\" translates to \"doesn&#x27;t believe my lies\" reply VectorLock 1 hour agorootparent\"Ethical grounds\" read: has them. reply cma 20 hours agoparentprev> Henry Kissinger?I think his stock as potential boardmember probably went down with his service on the Theranos board. reply EFreethought 10 hours agorootparentIf accepting a job offer from Richard Nixon doesn&#x27;t sink you, then nothing will. reply someperson 17 hours agoparentprevHenry Kissinger is 100 years old reply bmitc 14 hours agorootparentIt&#x27;s a joke. The explanation is that who would have to have worse morals and ethics than Altman for Altman to dismiss considering them on those grounds. reply kevinmchugh 11 hours agoparentprevCondoleeza Rice? reply rsynnott 20 hours agoparentprevCan’t imagine Kissinger is a popular choice for boards today… reply fhub 14 hours agoprevShortly after it happened the rumor in SF was that Altman was distracted and not really dotting the i&#x27;s and crossing the t&#x27;s. Like they had a cash flow issue where they had to ask for a top up from investors which was a bit embarrassing. Anyway, just a rumor. reply mousetree 20 hours agoprev> One of those people whose career Altman helped propel was Ilya Sutskever, chief scientist and board member at OpenAI — the person who ultimately fired him.Ilya was plenty successful before OpenAI and would&#x27;ve been just fine without Altman helping to \"propel\" his career. reply screye 15 hours agoparentHAHA, I know.Ilya, a nobody who wrote the most seminal paper of the last 10 years. The guy that Eric Schmidt and Elon broke their friendship over was just a random nobody.Come on. It is no secret that when OpenAI formed, every single researcher joined so they could work with Ilya (and Zaremba who worked with him, but was less famous). Greg is brilliant but ML people didn&#x27;t care for him and Sam &#x27;one of those VC guys&#x27;. A lot of their best hires had already worked in Ilya&#x2F;Zaremba before they joined OpenAI.OpenAI might have moved past needing Ilya&#x27;s brilliance to innovate, but if anyone gets to claim that they &#x27;made&#x27; OpenAI, it is Ilya. reply ncann 12 hours agorootparentWhat&#x27;s that about with Eric Schmidt, Elon and Ilya? reply screye 12 hours agorootparentCorrection, it was Larry Page (close enough), Elon and Ilya.Source - https:&#x2F;&#x2F;youtu.be&#x2F;7nORLckDnmg?si=1T5qyYAdPrMwsEGG&t=73 reply siva7 12 hours agorootparentprevand your source for this story is? reply dishwashing 18 hours agoparentprevThis statement about Ilya seems just ridiculous to me. Ilya was one of the people who created all these ML&#x2F;Deep Learning hype with the \"ImageNet moment\". I don&#x27;t care much about all this VC stuff, but before 2023, Ilya seemed to me much more famous than Sam. reply VeejayRampay 4 hours agorootparentSam is the entrepreneur &#x2F; vision guy so he gets all the love here as opposed to the actual tech guyIt&#x27;s modern Jobs &#x2F; Wozniak and Hacker News, despite the name, is ultimately fan service for the archetype of the former, not the latter reply himaraya 15 hours agoparentprevIndicative that many sources still come from Sam&#x27;s camp reply p_j_w 13 hours agoparentprevIt seems obvious that tech media are largely not even close to neutral here. Most everything coming out feels manipulative as hell. I don’t know why anyone thinks they have a clear story of what’s happening here. reply whyenot 12 hours agorootparent> tech media are largely not even close to neutral hereI don&#x27;t find that surprising at all. Many of those reporting are highly dependent on \"access journalism.\" I suspect it&#x27;s pretty hard to be neutral when if you piss off the wrong people they will cut you off. reply adrr 15 hours agoparentprevWhy did he sign the letter and post:>I deeply regret my participation in the board&#x27;s actions. I never intended to harm OpenAI. I love everything we&#x27;ve built together and I will do everything I can to reunite the company. reply gwern 12 hours agorootparentThis is why, the WSJ says: https:&#x2F;&#x2F;www.msn.com&#x2F;en-us&#x2F;money&#x2F;companies&#x2F;openai-s-path-ahea...\"One surprise signee was Ilya Sutskever, the company’s chief scientist and one of the members of the four-person board that voted to oust Altman. On Monday morning, Sutskever said he deeply regretted his participation in the board’s action. “I will do everything I can to reunite the company,” he posted on X.Sutskever flipped his position following intense deliberations with OpenAI employees as well as an emotionally charged conversation with Brockman’s wife, Anna Brockman, at the company’s offices, during which she cried and pleaded with him to change his mind, according to people familiar with the matter.\" reply ralfd 9 hours agorootparentThis is such a clown show. If instead Helen Toner had cried harder in Sutskever face than the outcome would have been different? reply jstarfish 15 hours agorootparentprevWhen you take a shot at someone influential and miss, falling on your own sword is a kinder fate than what will happen when they turn your direction. reply adrr 14 hours agorootparentDid he miss? Sam was fired. reply jstarfish 14 hours agorootparentThis subthread isn&#x27;t about the article; we&#x27;re on a tangent about OpenAI.He was fired [at] and didn&#x27;t die. Now he&#x27;s back, and looking for revenge. reply adrr 13 hours agorootparentBoard hired him back. They could have said no and stuck to their guns. No shareholders to give them the boot. reply adastra22 12 hours agorootparentThen they’d be falling on their own swords. Literally the whole company was ready to walk away. Never in history has that ever happened, as far as I know. reply jstarfish 12 hours agorootparentIt&#x27;s actually pretty typical for coups&#x2F;mutinies.Your position is challenged by military brass, so you imprison&#x2F;execute them. Anyone charismatic enough to take you on is going to have been popular with the soldiers, so now a heavily-armed mob with tanks and artillery is pissed at you. Now you have two problems, with only two solutions-- eat some shit and hope to make peace, or die.Putin played it safe in flipping the script-- negotiate surrender, appear to resolve the dispute peacefully, then stage an \"accident\" of the rabblerouser once tensions are lower. Cooler heads always prevail. reply selimthegrim 11 hours agorootparentOr you could do the King Hassan II strategy which is basically bury them in underground pits with not even enough room to stand up in for 24 hours a day until the first Bush comes knocking and needs a favor and tells you to clean up your PR.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;TazmamartI guess a L63 DS salary at MS must be the salt mines to these guys. replywhyleyc 20 hours agoprevhttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231122121846&#x2F;https:&#x2F;&#x2F;www.washi... reply CartyBoston 21 hours agoprevThe bit about PG and Altman parting ways is interesting I wonder if anyone wants to share more :). reply helsinkiandrew 21 hours agoparentHadn&#x27;t seen the tweet from Geoffrey Irving before:https:&#x2F;&#x2F;twitter.com&#x2F;geoffreyirving&#x2F;status&#x2F;172675427022402397...> 1. He was always nice to me.> 2. He lied to me on various occasions> 3. He was deceptive, manipulative, and worse to others, including my close friends (again, only nice to me, for reasons) reply xrd 20 hours agorootparentIt&#x27;s a very strongly worded statement. Given how connected Altman is, it&#x27;s very interesting that Irving would publicly state this.It&#x27;s either very courageous and in service to changing silicon valley, or also very manipulative and in service of benefiting his company. It feels like it could be both.I&#x27;m left feeling like there are no angels here. (That&#x27;s actually funny given how investors love to call themselves angels.)In the end it appears Altman has looked out for himself above all else, which probably enrages his mentors and investors who don&#x27;t like to lose control, including pg. reply ethbr1 20 hours agorootparentIt&#x27;s difficult to conceptualize someone who is ruthless, self-interested, and skilled enough to overcome all problems... except your control over them.Eventually they look at you and decide you&#x27;re the problem to be overcome.Might not happen for a while, but inevitably will. reply PeterisP 17 hours agorootparentNicely worded, but with regard to the OpenAI conflict I wonder if you intended this to be about Sam Altman or the topic of (G)AI safety or both? reply CSMastermind 15 hours agorootparentprevThis is incredibly well put and not something I&#x27;ve seen articulated so clearly before. reply twic 18 hours agorootparentprevAre you talking about Sam or an AGI? reply ethbr1 10 hours agorootparentMaybe. reply pdonis 17 hours agorootparentprev> I&#x27;m left feeling like there are no angels here.That&#x27;s my feeling after watching all this play out over the last few days. I don&#x27;t trust any of these people to be good stewards of anything that is supposed to benefit humanity. reply bmitc 14 hours agorootparentprevHe said it in the Tweet that it was because people were attacking people, such as Helen Toner, that he knows to be good people. reply theGnuMe 19 hours agorootparentprevYou&#x27;ve got a few billionaire teams in silicon valley not unlike say the NFL.Team DeepMind Team Google Team Meta Team YC Team OpenAI Team Microsoft Team nVIDIA Team VC Team ThielThere are probably more... reply rsynnott 20 hours agorootparentprevI don’t see how 1 and 2 are compatible unless you have a really weird definition of ‘nice’. reply FireBeyond 15 hours agorootparentI think it&#x27;d be more accurate to substitute &#x27;polite&#x27; or &#x27;courteous&#x27; than &#x27;nice&#x27;. reply rwmj 21 hours agorootparentprevLike an AI then. reply coliveira 20 hours agorootparentprevThis is the kind of person we have controlling the future of AI. He and Elon Musk. Between these two we are assured complete destruction. reply objektif 19 hours agorootparentWhat is wrong with Musk again? reply bmitc 14 hours agorootparentHe personally does not like the color yellow, so he required it not used in safety contexts just because of that. So he put workers&#x27; safety at risk because he may have to see pictures or tour the area once every quarter. There are more stories like this ad nauseum. Or, you could just read his Twitter feed. reply machdiamonds 14 hours agorootparentYou guys just believe whatever you read. Things that can easily be debunked with common sense. For example, there&#x27;s a lot of yellow in this factory tour he did:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=mr9kK0_7x08 reply bmitc 13 hours agorootparentI indeed see fairly minimal safety colors and patterns in that video. I don&#x27;t know where you see \"a lot\".And you do realize that there have been investigative journalists, federal inspections, and lawsuits regarding this? So all those people are just making it all up so that I can just believe whatever I read? reply VeejayRampay 4 hours agorootparentmusk fanboyism is a religion, it doesn&#x27;t have to be grounded in facts to be true to people who believe in itmusk is sending strike breakers to sweden to make it so that unions there can&#x27;t do their job to protect workers so he obviously can&#x27;t give a damn about his employees&#x27; safetydoesn&#x27;t change the fact that people will still log on blogs and websites everyday to defend him like he&#x27;s the second coming of jesus reply nullindividual 18 hours agorootparentprevThat’s a rhetorical question, correct? replydemadog 16 hours agoprevI predict his character arch will be similar to Adam Neumann and Travis Kalanick - first the media gushes over him and praises him as a genius. Then the media starts to question him. Then they start to fully dig in and dig up a ton of dirt.With no mainstream outlet pushing forth the allegations his sister is claiming on social, I imagine right now they are looking under every rock on that end.I respect his hustle but there is something about him in watching him speak live and in person that comes off as incredibly manipulative. He knows how to speak and pause in a way that gets the audience to laugh and gives soundbites. I am long OpenAI but I don’t trust Sam.He could follow the character arch of his friend Thiel where the media come after him but he’s too resilient.Or Zuckerberg where the media hated him for years and then moved on.What do you think? reply nottorp 14 hours agoparent> there is something about him in watching him speak live and in personGreatest mistake you can make is watch someone speak live about what they&#x27;re selling. If they&#x27;re a good actor they&#x27;ll win you over. reply doktrin 11 hours agorootparentAccurate. Psychology, history and the intersection thereof broadly supports the idea that we drastically overestimate our ability to measure character and intention based on in-person interactions. Some oft cited cases being how numerous British public figures who sat down with Hitler tragically misread his intentions, in contrast to those who appraised him from a distance based on actions, policies and writings. Likewise, GWB&#x27;s famous ability to peer into Putin&#x27;s soul. reply previnder 7 hours agorootparentI would, however, add that just because most people are bad at estimating others doesn&#x27;t mean that everyone is equally bad. There may be some people who are incredibly good at seeing where others are coming from and what their true intentions are. But, of course, everyone&#x27;s probably overestimating their own capacity to estimate others. reply skilled 15 hours agoparentprevI dislike the fact that he peddles the AGI angle too much. Literally, way above normal.It would be nice to see him be down to Earth for a change and show some compassion but what do I know.. maybe those aren’t his strongest qualities. reply cooper_ganglia 15 hours agoparentprevI trust Greg, and Greg trusts Sam. reply mcpackieh 13 hours agorootparentTransitive trust is a bad idea. The telephone game aka \"chinese whispers\" demonstrates why. reply atleastoptimal 9 hours agoparentprevSam isn&#x27;t charismatic in the classic showman way. He has nerd appeal but he isn&#x27;t magically persuasive. He just seems very \"focused\" so his claims feel believable. reply dchftcs 15 hours agoparentprev>I respect his hustle but there is something about him in watching him speak live and in person that comes off as incredibly manipulative. He knows how to speak and pause in a way that gets the audience to laugh and gives soundbites. I am long OpenAI but I don’t trust Sam.You can say the same thing about Steve Jobs. Steve Jobs is a jerk for sure but a bad personality does not predict success or failure as much as you (or we) hope to. And what people say about your character is also overly dependent on results. Only time will tell whether Sam Altman will be considered a villain or a flawed hero in media. reply vikramkr 16 hours agoprevAt least one of the arguments against him, that he cared too much about openai to lead Microsoft effectively, probably helps him more than it hurts. Otherwise, idk how much of this was really about Sam altman as much as it was a staggeringly incompetent board that drove employees and investors to unify and protest en masse to save the organisation from itself. I guess there&#x27;s a chance there&#x27;s an AGI in the basement but if it was actually about safety they should fucking say what the hell they were freaking out about. But if they leave the only logical conclusion as this being a power struggle between someone who wants to move fast and make bank and a board that wants to kill the company for ego reasons - uhh yeah that&#x27;s not a hard choice reply jacquesm 8 hours agoparentI think you meant YC rather than Microsoft. reply vikramkr 8 hours agorootparentYep I did good catch, can&#x27;t edit it now tho reply 1vuio0pswjnm7 13 hours agoprev\"\"Ninety plus percent of the employees of OpenAI are saying they would be willing to move to Microsoft because they feel Sam&#x27;s been mistreated by a rogue board of directors,\" said Ron Conway, a prominent venture capitalist who became friendly with Altman shortly after he founded Loopt, a location-based social networking start-up, in 2005. \"I&#x27;ve never seen this kind of loyalty anywhere.\"\"Perhaps this looks like \"loyalty\" when viewed with the narrow mindset of Silicon Valley and so-called \"tech\" venture capitalism. But it also looks like disloyalty to OpenAI and its stated mission when viewed more broadly.\"A former OpenAI employee, machine learning researcher Geoffrey Irving, who now works at competitor Google DeepMind, wrote that he was disinclined to support Altman after working for him for two years. \"1. He was always nice to me. 2. He lied to me on various occasions 3. He was deceptive, manipulative, and worse to others, including my close friends (again, only nice to me, for reasons),\" Irving posted Monday on X.\"One could see similarities with the way so-called \"tech\" companies treat computer users.It&#x27;s no surprise people working for so-called \"tech\" companies are trying to hide behind labels such as \"Effective Altruism\". These are not altruistic people. They need a cover. reply ojosilva 19 hours agoprev> Though full reasoning for Altman’s initial firing is still unclear, one person familiar with the matter, who spoke on the condition of anonymity to discuss sensitive matters, pointed to Altman’s aggressive fundraising efforts for a chips venture with autocratic regimes in the Middle East, which raised concerns about the use of AI to facilitate state surveillance and human rights abuses.That&#x27;s a concern of mine from one year ago when ChatGPT exploded: Altman holds a feeble position as a zero-equity co-founder of a non-profit. He should be enabled to become a stinking rich SV mogul of some sort, or at least have his existence tied to substantial equity. Otherwise, having power but no (huge, absurd) money, or promises thereof, from his commitment to OpenAI will only boost these side gigs or even future coups. He&#x27;s an ambitious and powerful leader and entrepreneur, he should be compensated accordingly so that OpenAI goals become aligned to his own.Somehow the new board&#x27;s powerful oversight goals should be leveraged with valuable equity for Altman (and other key people, employees) or equivalent. Create a path to a for-profit, consolidate the Incs and LLCs floating around - OpenAI has a complex structure for such a young enterprise. He has a comfortable upper hand right now (employees, Ilya, a resigning board, MSFT), so this is the moment to rewrite OpenAI&#x27;s charter. reply tracerbulletx 16 hours agoprevCEOs are professional communicators who have reached the highest level of the craft, they use their communications to achieve an end, expressing their inner selves is not the point. You might know a great kind person who is a car salesman, when they are at work a good one comes off as genuine and friendly, the things they&#x27;re saying include many truths, but their words and actions are primarily designed to sell cars. Assume this is true of any professional communicator when they&#x27;re communicating. reply bmitc 15 hours agoparent> CEOs are professional communicators who have reached the highest level of the craftThat&#x27;s kind of silly, isn&#x27;t it? Altman is a college dropout who has barely ever worked and somehow fell upward into CEO positions very quickly.His level of communication in talks and interviews is terrible, so I am genuinely confused where all this mystique comes from. He sounds like a college student being asked and talking about management.It seems that if you have any title or personal relationship attached to you, people will listen to anything you say, and even say things or just conjure up an ora for you. reply runeofdoom 14 hours agorootparentIf you start thinking that CEOs aren&#x27;t special and unique, then you might start thinking they don&#x27;t need to be paid 350 times what the average employee does. reply bmitc 13 hours agorootparentYes. reply WendyTheWillow 12 hours agorootparentThen you must not think the job is difficult or impactful, as well. reply woooooo 12 hours agorootparentThat doesn&#x27;t necessarily follow. Lots of people have difficult jobs. Line cooks have to make priority decisions under high pressure, and it&#x27;s impactful. reply WendyTheWillow 11 hours agorootparentA line cook is comparably difficult and impactful a job as a fortune 500 CEO?Say more. replylebean 14 hours agorootparentprevYeah I&#x27;m not convinced either. No doubt that good communication is a strength in a good CEO. But the only thing I can confidently say is an essential part of being a CEO is that they are blame-sinks for executive decisions, particularly their own. reply og_kalu 13 hours agorootparentprevall the companies altman has CEO&#x27;d are companies he co-founded. Not sure how you \"fall upwards\" into that. reply threeseed 13 hours agorootparentprevAltman founded Loopt.Not sure how you can say he fell into the CEO position there.Also at the time he was at YC it was a significantly smaller and less prestigious incubator. reply bmitc 13 hours agorootparent> Loopt, Inc. was an American company ... which provided a service for smartphone users to share their location selectively with other people.Yea, impressive stuff. I&#x27;m sure that gave him a lot of experience that led to being one of the few \"professional communicators who have reached the highest level of the craft\". reply og_kalu 12 hours agorootparentThat was not the point of that coment.You act like he just mysteriously found himself in executive positions when every company he&#x27;s headed for a significant duration was one he founded. If you didn&#x27;t even know that then you obviously know very little about him and couldn&#x27;t even be bothered to do any research at all. This is a simple wikipedia search. So why are you so bothered about someone you know nothing about ? reply dr_dshiv 14 hours agorootparentprevWatch him at Dev Day. reply bmitc 14 hours agorootparentYawn. reply willis936 13 hours agorootparentprevIf we concede that CEOs deserve their place in society then we can claim that we live in a meritocracy, the world is fair, and we deserve the good things that happen to us. It&#x27;s a very comfortable thought. reply charlie0 15 hours agoparentprevThis the main reason I don&#x27;t trust people who are in the business of \"selling\". On one hand, it&#x27;s nice being around those kinds of people. On the other hand, it&#x27;s hard to take any of the nice things they say seriously. Most of them say nice things to be likeable, not because they actually mean or will do what they say. I&#x27;ve learned to pay close attention to what salesmen do, rather than what is said. The actual truth will be revealed by their actions. reply hutzlibu 15 hours agorootparent\"I&#x27;ve learned to pay close attention to what salesmen do, rather than what is said\"I&#x27;ve learned to apply this to every human being. Talk is cheap. reply blastro 13 hours agorootparent\"Your actions speak so loud we can&#x27;t hear what you say\" - Jim Harbaugh reply gretch 15 hours agorootparentprev>I&#x27;ve learned to pay close attention to what salesmen do, rather than what is said.Yes this is always a wise thing to do.>Most of them say nice things to be likeable, not because they actually mean or will do what they say.I disagree with this take. I mean I’m sure there’s snakes out there. What I see in life though, is that most people don’t say enough nice things, even things they genuinely feel. They hold back from calling their dad or wife and saying “I love you”. Or giving a compliment to someone on the street if you like their outfit that you can tell they put time into.I think a lot of salespeople are just good at “opening the gates” a little.Personally I’ve been on a quest to be less stoic when it comes to expressing joy, and I highly recommend, especially for typical computer science personalities. reply turzmo 14 hours agorootparentPeople could afford to say more nice things. Perhaps it would even devalue the false flattery used by salespeople to their advantage.OTOH the parent comment&#x27;s take seems reasonable. Calling your dad and saying \"I love you\" because you want to be written into the will is sort of the level we&#x27;re dealing with here. reply charlie0 13 hours agorootparentprevNo need to disagree, both our statements can be true at the same time. I also need to be less stoic, but I refuse to put on a mask to achieve that.My statement was directed at those who wear that mask all too well. Example, my landlord, who&#x27;s in real estate and a very nice guy in person. However, he promised to do a few things and didn&#x27;t do them. So his niceties where just that, nice words and nothing more. I&#x27;d rather deal with a less nice person who actually does what they said they will. With limits of course, no one likes a-holes. reply robocat 13 hours agoparentprev> CEOs are professional communicators who have reached the highest level of the craftBut Sam the CEO has totally failed to manage the narrative throughout this episode. [A CEO needs to communicate better]Surely he could have stated it was a disagreement in direction? Instead he left it open to rumours: rumours which mostly assumed the board had good reason to sack him (everyone presumed the board couldn&#x27;t be that stupid plus he didn&#x27;t defend himself). : Many of those rumours were extremely damaging to Sam. Even if he couldn&#x27;t say a thing, he could have got other third parties to endorse him.Nadella and Eric came out looking pretty good. reply tomnipotent 14 hours agoparentprev\"Influence: The Psychology of Persuasion\" is a great book that touches on this subject.I read it in the middle of purchasing a new car in 2010, and had signed paperwork and a purchase agreement to buy car at $X. Next day I&#x27;m told \"My manager won&#x27;t let me sell for anything less than $X+Y\", after I&#x27;d gone through all the trouble of filling out all that paperwork.Fortunetly I&#x27;d just finished a chapter in the book outlining this EXACT sales technique, that relies on a person being more willing to go through with an action if they&#x27;ve committed something to it... like filling out half an hours worth of paperwork. Said no thanks, and found the exact same car an hour away at less than $X.Haven&#x27;t underestimated the impact of a salesperson since, and no longer delude myself trying to believe somehow I&#x27;m special and immune to such things. reply bambax 13 hours agorootparentI don&#x27;t know if this counts as selling, though.Selling is making you want to buy the car, agreeing on a price and filling in the paperwork.Trying to extract more money from you after you have agreed on a price is... extorsion? Fraud? But not just \"selling\". reply tomnipotent 12 hours agorootparentIt&#x27;s negotiation, which is absolutely selling. The dealership was counting on me accepting the price hike because the car I wanted was rare and in-demand, and I had already made some commitment to the process by filling out initial paperwork. I knew a manager still needed to approve the terms, but the sales rep made it sound like it was certain.Turns out this is an incredibly common car sales tactic, enough so that it was explicitly called out in the aforementioned book.Rather than harumph about how unfair it is, I decided it was better to just learn how to play the game. Unwilling participant or not, fair or not, it&#x27;s better to come prepared than feel like you&#x27;re getting taken advantage of. reply bambax 11 hours agorootparentIf anything happens after we shake hands, I walk. Paperwork or not; book or no book.I don&#x27;t question the (un)fairness of it, or the game; just the name.Your guy sounds like Jerry Lundegaardhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=B2LLB9CGfLs reply quickthrower2 14 hours agorootparentprevAnd probably the car is dodgy if they are pulling tricks like that. If a startup investor does it, probably their “help” is suspect. reply Cacti 13 hours agoparentprevGood CEOs are good communicators. Most CEOs, like literally any other profession, are not. People like Jobs are exceptions, and for every one of them there are a hundred shitty CEOs who are neither talented nor intelligent, even among the companies that are still alive, but they don’t get discussed here because this is a site about making money first, and tech second, and the crowd here doesn’t like hearing it’s all bullshit. For every Apple there are a hundred Shitty Integrated, Inc. companies that no one talks about, and every one has a CEO.There are no qualifications to be a CEO, ultimately, except the board happens to want you as CEO.It’s just a title. reply joering2 15 hours agoparentprev> CEOs are professional communicators who have reached the highest level of the craftElon Musk has entered the chat... reply Geee 14 hours agorootparentFounder CEOs are a different breed. There&#x27;s a plenty of successful founder CEOs who don&#x27;t fit the typical hired CEO pattern. Zuckerberg, Sweeney, etc. reply tmpz22 12 hours agorootparentIs Elon a founder CEO of Twitter, Tesla, or SpaceX? reply Geee 10 hours agorootparentMaybe founder isn&#x27;t the most accurate word here. Maybe &#x27;owner CEO&#x27;, i.e. has major control of the company. He is definitely not &#x27;hired CEO&#x27; in any of those. (also he is CTO of Twitter, not CEO). reply tracerbulletx 15 hours agorootparentprevI think he&#x27;s gone a little more \"experimental\" and Avant Garde in his practice of the art. &#x2F;s reply _1 15 hours agorootparentprevThat&#x27;s the exception for someone born wealthy, buys an existing company, and installs themselves as CEO. reply RationalDino 14 hours agorootparentThe source for his being born wealthy is his father. Who is known to be a conman.For example the emerald story seems to be false. https:&#x2F;&#x2F;www.businessinsider.com&#x2F;elon-musk-father-errol-never.... reply375 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sam Altman, the former CEO of OpenAI, was initially fired due to clashes, self-serving behavior, and concerns about power and board balance.",
      "Altman later negotiated his return but faced opposition from co-founders and board members, leading to allegations of deception and manipulation.",
      "Despite the controversy, Altman has both loyal supporters and critics, with accusations of manipulation and division, but his strategic skills and charisma align with the culture of Silicon Valley, and he remains dedicated to OpenAI's mission."
    ],
    "commentSummary": [
      "Sam Altman, the former CEO of OpenAI, has sparked numerous discussions and debates surrounding his departure from the company.",
      "Topics covered include his previous firing from Y Combinator, speculation about his abilities and motivations, the credibility of individuals in the field of AI, and the impact of business leaders.",
      "Other discussions touch on the firing and rehiring of employees, evolving statements from Y Combinator, tweets from Paul Graham about Altman, the influence of Ilya Sutskever, and the compatibility of being \"nice\" with having control over the future of AI."
    ],
    "points": 847,
    "commentCount": 658,
    "retryCount": 0,
    "time": 1700655430
  },
  {
    "id": 38386487,
    "title": "OpenAI Researchers Warned Board of AI Breakthrough Ahead of CEO Ouster",
    "originLink": "https://www.reuters.com/technology/sam-altmans-ouster-openai-was-precipitated-by-letter-board-about-ai-breakthrough-2023-11-22/",
    "originBody": "Technology OpenAI researchers warned board of AI breakthrough ahead of CEO ouster, sources say By Anna Tong, Jeffrey Dastin and Krystal Hu November 23, 20239:52 AM UTCUpdated 10 min ago Nov 22 (Reuters) - Ahead of OpenAI CEO Sam Altman’s four days in exile, several staff researchers wrote a letter to the board of directors warning of a powerful artificial intelligence discovery that they said could threaten humanity, two people familiar with the matter told Reuters. The previously unreported letter and AI algorithm were key developments before the board's ouster of Altman, the poster child of generative AI, the two sources said. Prior to his triumphant return late Tuesday, more than 700 employees had threatened to quit and join backer Microsoft (MSFT.O) in solidarity with their fired leader. Advertisement · Scroll to continue The sources cited the letter as one factor among a longer list of grievances by the board leading to Altman's firing, among which were concerns over commercializing advances before understanding the consequences. Reuters was unable to review a copy of the letter. The staff who wrote the letter did not respond to requests for comment. After being contacted by Reuters, OpenAI, which declined to comment, acknowledged in an internal message to staffers a project called Q* and a letter to the board before the weekend's events, one of the people said. An OpenAI spokesperson said that the message, sent by long-time executive Mira Murati, alerted staff to certain media stories without commenting on their accuracy. Advertisement · Scroll to continue Some at OpenAI believe Q* (pronounced Q-Star) could be a breakthrough in the startup's search for what's known as artificial general intelligence (AGI), one of the people told Reuters. OpenAI defines AGI as autonomous systems that surpass humans in most economically valuable tasks. Given vast computing resources, the new model was able to solve certain mathematical problems, the person said on condition of anonymity because the individual was not authorized to speak on behalf of the company. Though only performing math on the level of grade-school students, acing such tests made researchers very optimistic about Q*’s future success, the source said. Advertisement · Scroll to continue Reuters could not independently verify the capabilities of Q* claimed by the researchers. 'VEIL OF IGNORANCE' [1/2]Sam Altman, CEO of ChatGPT maker OpenAI, arrives for a bipartisan Artificial Intelligence (AI) Insight Forum for all U.S. senators hosted by Senate Majority Leader Chuck Schumer (D-NY) at the U.S. Capitol in Washington, U.S., September 13, 2023. REUTERS/Julia Nikhinson/File Photo Acquire Licensing Rights Researchers consider math to be a frontier of generative AI development. Currently, generative AI is good at writing and language translation by statistically predicting the next word, and answers to the same question can vary widely. But conquering the ability to do math — where there is only one right answer — implies AI would have greater reasoning capabilities resembling human intelligence. This could be applied to novel scientific research, for instance, AI researchers believe. Unlike a calculator that can solve a limited number of operations, AGI can generalize, learn and comprehend. In their letter to the board, researchers flagged AI’s prowess and potential danger, the sources said without specifying the exact safety concerns noted in the letter. There has long been discussion among computer scientists about the danger posed by highly intelligent machines, for instance if they might decide that the destruction of humanity was in their interest. Researchers have also flagged work by an \"AI scientist\" team, the existence of which multiple sources confirmed. The group, formed by combining earlier \"Code Gen\" and \"Math Gen\" teams, was exploring how to optimize existing AI models to improve their reasoning and eventually perform scientific work, one of the people said. Altman led efforts to make ChatGPT one of the fastest growing software applications in history and drew investment - and computing resources - necessary from Microsoft to get closer to AGI. In addition to announcing a slew of new tools in a demonstration this month, Altman last week teased at a summit of world leaders in San Francisco that he believed major advances were in sight. \"Four times now in the history of OpenAI, the most recent time was just in the last couple weeks, I've gotten to be in the room, when we sort of push the veil of ignorance back and the frontier of discovery forward, and getting to do that is the professional honor of a lifetime,\" he said at the Asia-Pacific Economic Cooperation summit. A day later, the board fired Altman. Anna Tong and Jeffrey Dastin in San Francisco and Krystal Hu in New York; Editing by Kenneth Li and Lisa Shumaker Our Standards: The Thomson Reuters Trust Principles. Acquire Licensing Rights , opens new tab Anna Tong Thomson Reuters Anna Tong is a correspondent for Reuters based in San Francisco, where she reports on the technology industry. She joined Reuters in 2023 after working at the San Francisco Standard as a data editor. Tong previously worked at technology startups as a product manager and at Google where she worked in user insights and helped run a call center. Tong graduated from Harvard University. Contact:4152373211 Jeffrey Dastin Thomson Reuters Jeffrey Dastin is a correspondent for Reuters based in San Francisco, where he reports on the technology industry and artificial intelligence. He joined Reuters in 2014, originally writing about airlines and travel from the New York bureau. Dastin graduated from Yale University with a degree in history. He was part of a team that examined lobbying by Amazon.com around the world, for which he won a SOPA Award in 2022. Krystal Hu Thomson Reuters Krystal reports on venture capital and startups for Reuters. She covers Silicon Valley and beyond through the lens of money and characters, with a focus on growth-stage startups, tech investments and AI. She has previously covered M&A for Reuters, breaking stories on Trump's SPAC and Elon Musk's Twitter financing. Previously, she reported on Amazon for Yahoo Finance, and her investigation of the company's retail practice was cited by lawmakers in Congress. Krystal started a career in journalism by writing about tech and politics in China. She has a master's degree from New York University, and enjoys a scoop of Matcha ice cream as much as getting a scoop at work. Read Next Boards category Sam Altman to return as OpenAI CEO after his tumultuous ouster Sam Altman is returning as CEO of OpenAI just days after his ouster, capping frenzied discussions about the future of the startup at the center of an artificial intelligence boom. Technology category UK payments report calls for alternatives to Mastercard and Visa Britain needs a \"digital alternative\" to relying on Visa and Mastercard for card payments regardless of steps being taken by regulators, a report commissioned by the government said on Wednesday. Disrupted category AI poster child Altman back at OpenAI, may have fewer checks on power OpenAI is bringing Altman back as well as installing a revamped board that could bring sharper scrutiny to the startup. Future of Money category US prosecutors want Binance's Zhao to remain in US until sentencing -filing U.S. prosecutors pressed a federal judge on Wednesday to require Binance Holdings founder and former chief Changpeng Zhao to remain in the continental United States before his sentencing hearing on Feb. 23, 2024, according to a court filing. Technology category Binance sees $956 million in outflows after Zhao steps down to settle US probe Investors pulled about $956 million from crypto exchange Binance over the past 24 hours, market data showed, after its chief, Changpeng Zhao, stepped down and faced prison time after pleading guilty on Tuesday to settle a years-long U.S. illicit finance probe.",
    "commentLink": "https://news.ycombinator.com/item?id=38386487",
    "commentBody": "OpenAI researchers warned board of AI breakthrough ahead of CEO ousterHacker NewspastloginOpenAI researchers warned board of AI breakthrough ahead of CEO ouster (reuters.com) 758 points by mfiguiere 10 hours ago| hidepastfavorite835 comments wbhart 5 hours agoI feel very comfortable saying, as a mathematician, that the ability to solve grade school maths problems would not be at all a predictor of ability to solve real mathematical problems at a research level.The reason LLMs fail at solving mathematical problems is because: 1) they are terrible at arithmetic, 2) they are terrible at algebra, but most importantly, 3) they are terrible at complex reasoning (more specifically they mix up quantifiers and don&#x27;t really understand the complex logical structure of many arguments) 4) they (current LLMs) cannot backtrack when they find that what they already wrote turned out not to lead to a solution, and it is too expensive to give them the thousands of restarts they&#x27;d require to randomly guess their way through the problem if you did give them that facilitySolving grade-school problems might mean progress in 1 and 2, but that is not at all impressive, as there are perfectly good tools out there that solve those problems just fine, and old-style AI researchers have built perfectly good tools for 3. The hard problem to solve is problem 4, and this is something you teach people how to do at a university level.(I should add that another important problem is what is known as premise selection. I didn&#x27;t list that because LLMs have actually been shown to manage this ok in about 70% of theorems, which basically matches records set by other machine learning techniques.)(Real mathematical research also involves what is known as lemma conjecturing. I have never once observed an LLM do it, and I suspect they cannot do so. Basically the parameter set of the LLM dedicated to mathematical reasoning is either large enough to model the entire solution from end to end, or the LLM is likely to completely fail to solve the problem.)I personally think this entire article is likely complete bunk.Edit: after reading replies I realise I should have pointed out that humans do not simply backtrack. They learn from failed attempts in ways that LLMs do not seem to. The material they are trained on surely contributes to this problem. reply nostrademons 3 hours agoparentWhat I wonder, as a computer scientist:If you want to solve grade school math problems, why not use an &#x27;add&#x27; instruction? It&#x27;s been around since the 50s, runs a billion times faster than an LLM, every assembly-language programmer knows how to use it, every high-level language has a one-token equivalent, and doesn&#x27;t hallucinate answers (other than integer overflow).We also know how to solve complex reasoning chains that require backtracking. Prolog has been around since 1972. It&#x27;s not used that much because that&#x27;s not the programming problem that most people are solving.Why not use a tool for what it&#x27;s good for and pick different tools for other problems they are better for? LLMs are good for summarization, autocompletion, and as an input to many other language problems like spelling and bigrams. They&#x27;re not good at math. Computers are really good at math.There&#x27;s a theorem that an LLM can compute any computable function. That&#x27;s true, but so can lambda calculus. We don&#x27;t program in raw lambda calculus because it&#x27;s terribly inefficient. Same with LLMs for arithmetic problems. reply seanhunter 1 hour agorootparentThere is a general result in machine learning known as \"the bitter lesson\"[1], which is that methods which come from specialist knowledge tend to be beaten by methods which rely on brute force computation in the long run because of Moore&#x27;s law and the ability to scale things by distributed computing. So the reason people don&#x27;t use the \"add instruction\"[2] for example is that over the last 70 years of attempting to build out systems which do exactly what you are proposing, they have found that not to work very well whereas sacrificing what you are calling \"efficiency\" (which they would think of as special purpose domain-specific knowledge) turns out to give you a lot in terms of generality. And they can make up the lost efficiency by throwing more hardware at the problem.[1] http:&#x2F;&#x2F;www.incompleteideas.net&#x2F;IncIdeas&#x2F;BitterLesson.html[2] Which the people making these models are familiar with. The whole thing is a trillion+ parameter linear algebra crunching machine after all. reply qsort 53 minutes agorootparentAs someone with a CS background myself, I don&#x27;t think this is what GP was talking about.Let&#x27;s forget for a moment that stuff has to run on an actual machine. If you had to represent a quadratic equation, would you rather write:(a) x^2 + 5x + 4 = 0(b) the square of the variable plus five times the variable plus four equals zeroWhen you are trying to solve problems with a level of sophistication beyond the toy stuff you usually see in these threads, formal language is an aid rather than an impediment. The trajectory of every scientific field (math, physics, computer science, chemistry, even economics!) is away from natural language and towards formal language, even before computers, precisely for that reason.We have lots of formal languages (general-purpose programming languages, logical languages like Prolog&#x2F;Datalog&#x2F;SQL, \"regular\" expressions, configuration languages, all kinds of DSLs...) because we have lots of problems, and we choose the representation of the problem that most suits our needs.Unless you are assuming you have some kind of superintelligence that can automagically take care of everything you throw at it, natural language breaks down when your problem becomes wide enough or deep enough. In a way this is like people making Rube-Goldberg contraptions with Excel. 50% of my job is cleaning up that stuff. reply ben_w 45 minutes agorootparentI assumed seanhunter was suggesting getting the LLM to convert x^2 + 5x + 4 = 0 to a short bit of source code to solve for x.IIRC Wolfram Alpha has (or had, hard to keep up) a way to connect with ChatGPT. reply seanhunter 13 minutes agorootparentIt does. This is the plugins methodology described in the toolformers paper which I&#x27;ve linked elsewhere[1]. The model learns that for certain types of problems certain specific \"tools\" are the best way to solve the problem. The problem is of course it&#x27;s simple to argue that the LLM learns to use the tool(s) and can&#x27;t reason itself about the underlying problem. The question boils down to whether you&#x27;re more interested in machines which can think (whatever that means) or having a super-powered co-pilot which can help with a wide variety of tasks. I&#x27;m quite biased towards the second so I have the wolfram alpha plugin enabled in my chat gpt. I can&#x27;t say it solves all the math-related hallucinations I see but I might not be using it right.[1] But here it is again https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.04761 reply rgavuliak 35 minutes agorootparentprevI would mention, that while yes, you can just throw computational power at the problem, the addition of human expertise didn&#x27;t disappear. It moved from creating an add instruction, to coming up with a new Neural Net Architecture, and we&#x27;ve seen a lot of the ideas being super useful and pushing the boundaries. reply panarky 2 hours agorootparentprev>> the ability to solve grade school maths problems would not be at all a predictor of ability to solve real mathematical problems at a research level> If you want to solve grade school math problems, why not use an &#x27;add&#x27; instruction?Certainly the objective is not for the AI to do research-level mathematics.It&#x27;s not really even to do grade-school math.The point is that grade-school math requires reasoning capability that transcends probabilistic completion of the next token in a sequence.And if Q-Star has that reasoning capability, then it&#x27;s another step-function leap toward AGI. reply Closi 2 hours agorootparentprevWhy would we teach kids maths then, when they can use a calculator? It&#x27;s much easier and faster for them.I believe it&#x27;s because having a foundational understanding of maths and logic is important when solving other problems, and if you are looking to create an AI that can generally solve all problems it should probably have some intuitive understanding of maths too.i.e. if we want an LLM to be able to solve unsolved theorems in the future, this requires a level of understanding of maths that is more than &#x27;teach it to use a calculator&#x27;.More broadly, I can imagine a world where LLM training is a bit more &#x27;interactive&#x27; - right now if you ask it to play a game of chess with you it fails, but it has only ever read about chess and past games and guesses the next token based on that. What if it could actually play a game of chess - would it get a deeper appreciation for the game? How would this change it&#x27;s internal model for other questions (e.g. would this make it answer better at questions about other games, or even game theory?) reply comex 2 hours agorootparentJudging by some YouTube videos I’ve seen, ChatGPT with GPT-4 can get pretty far through a game of chess. (Certainly much farther than GPT-3.5.) For that duration it makes reasonably strategic moves, though eventually it seems to inevitably lose track of the board state and start making illegal moves. I don’t know if that counts as being able to “actually play a game”, but it does have some ability, and that may have already influenced its answers about the other topics you mentioned. reply vczf 1 hour agorootparentWhat if you encoded the whole game state into a one-shot completion that fits into the context window every turn? It would likely not make those illegal moves. I suspect it&#x27;s an artifact of the context window management that is designed to summarize lengthy chat conversations, rather than an actual limitation of GPT4&#x27;s internal model of chess. reply sgt101 38 minutes agorootparentprevCan LLM&#x27;s compute any computable function? I thought that an LLM can approximate any computable function, if the function is within the distribution that it is are trained on. I think it&#x27;s jolly interesting to think about different axiomizations in this context.Also we know that LLM&#x27;s can&#x27;t do a few things - arithmetic, inference & planning are in there. They look like they can because they retrieve discussions from the internet that contain the problems, but when they are tested out of distribution then all of a sudden they fail. However, some other nn&#x27;s can do these things because they have the architecture and infrastructure and training that enables it.There is a question for some of these as to whether we want to make NN&#x27;s do these tasks or just provide calculators, like for grade students, but on the other hand something like Alphazero looks like it could find new ways of doing some problems in planning. The challenge is to find architectures that integrate the different capabilities we can implement in a useful and synergistic way. Lots of people have drawn diagrams about how this can be done, then presented them with lots of hand waving at big conferences. What I love is that John Laird has been building this sort of thing for like, forty years, and is roundly ignored by NN people for some reason.Maybe because he keeps saying it&#x27;s really hard and then producing lots of reasons to believe him? reply vidarh 47 minutes agorootparentprevThere&#x27;s no value in an LLM doing arithmetic for the sake of doing arithmetic with the LLM. There&#x27;s value in testing an LLMs ability to follow the rules for doing arithmetic that it already knows, because the ability to recognise that a problem matches a set of rules it already knows in part or whole and then applying those rules with precision is likely to generalise to overall far better problem solving abilities.By all means, we should give LLMs lots and lots of specialised tools to let them take shortcuts, but that does not remove the reasons for understanding how to strengthen the reasoning abilities that would also make them good at maths. reply curling_grad 2 hours agorootparentprevActually, OpenAI did a research[0] on solving some hard math problems by integrating language model and Lean theorem prover some time ago.[0]: https:&#x2F;&#x2F;openai.com&#x2F;research&#x2F;formal-math reply singularity2001 2 hours agorootparenthow do they achieve 41.2% in high school Olympiads but only 55% for grade school problems?PS: also I thought GPT4 already achieved 90% in some university math grades? Oh I remember that was multiple-choice reply xwolfi 3 hours agorootparentprevYou&#x27;re missing the point: who&#x27;s using the &#x27;add&#x27; instruction ? You. We want &#x27;something&#x27; to think about using the &#x27;add&#x27; instruction to solve a problem.We want to remove the human from the solution design. It would help us tremendously tbh, just like I don&#x27;t know, Google map helped me never to have to look for direction ever again ? reply marshray 3 hours agorootparentWhen the solution requires arithmetic, one trick is to simply ask GPT to write a Python program to compute the answer.There&#x27;s your &#x27;add&#x27;. reply davidwritesbugs 2 hours agorootparentInteresting, how do you use this idea? If you prompt the LLM \"create a python Add function Foo to add a number to another number\", \"using Foo add 1 and 2\", or somesuch, but what&#x27;s to stop it hallucinating and saying \"Sure, let me do that for you, foo 1 and 2 is 347. Please let me know if you need anything else.\" reply IanCal 1 hour agorootparentNothing stops it from writing a recipe for soup for every request, but it does tend to do what it&#x27;s told. When asked to do mathsy things and told it&#x27;s got a tool for doing those it tends to lean into that if it&#x27;s a good llm. reply LASR 1 hour agorootparentprevWe’re way beyond this kind of hallucinations now. OpenAI’s models are frighteningly good at producing code.You can even route back runtime errors and ask it to fix its own code. And it does.It can write code and even write a test to test that code. Give it an interpreter and you’re all set. replygmt2027 1 hour agoparentprevWe have an algorithm and computational hardware that will tune a universal function approximator to fit any dataset with emergent intelligence as it discovers abstractions, patterns, features and hierarchies.So far, we have not yet found hard limits that cannot be overcome by scaling the number of model parameters, increasing the size and quality of training data or, very infrequently, adopting a new architecture.The number of model parameters required to achieve a defined level of intelligence is a function of the architecture and training data. The important question is, what is N, the number of model parameters at which we cross an intelligence threshold and it becomes theoretically possible to solve mathematics problems at a research level for an optimal architecture that we may not yet have discovered. Our understanding does not extend to the level where we can predict N but I doubt that anyone still believes that it is infinity after seeing what GPT4 can do.This claim here is essentially a discovery that N may be much closer to where we are with today&#x27;s largest models. Researchers at the absolute frontier are more likely to be able to gauge how close they are to a breakthrough of that magnitude from how quickly they are blowing past less impressive milestones like grade school math.My intuition is that we are in a suboptimal part of the search space and it is theoretically possible to achieve GPT4 level intelligence with a model that is orders of magnitude smaller. This could happen when we figure out how to separate the reasoning from the factual knowledge encoded in the model. reply waveBidder 51 minutes agorootparentintelligence isn&#x27;t a function unless you&#x27;re talking about over every possible state of the universe. reply d--b 36 minutes agoparentprevYou make the asumption that Q* is a LLM, but I think OpenAI guys know very well that the current LLM architecture cannot achieve AGI.As the name suggests, this things is likely using some form of Q learning algorithm, which makes it closer to the DeepMind models than a transformer.My guess is that they pipe their LLM into some Q learnt net. The LLM may transform a natural language task into some internal representation that can then be handled by the Q-learnt model, which spits out something that can be transformed back again into natural language. reply muskmusk 4 hours agoparentprevFriend, the creator of this new progress is a machine learning PhD with a decade of experience in pushing machine learning forward. He knows a lot of math too. Maybe there is a chance that he too can tell the difference between a meaningless advance and an important one? reply neilk 4 hours agorootparentI am neither a mathematician or LLM creator but I do know how to evaluate interesting tech claims.The absolute best case scenario for a new technology is that it when it seems like a toy for nerds, and doesn&#x27;t outperform anything we have today, but the scaling path is clear.Its problems just won&#x27;t matter if it does that one thing with scaling. The web is a pretty good hypermedia platform, but a disastrously bad platform for most other computer applications. Nevertheless the scaling of URIs and internet protocols have caused us to reorganize our lives around it. And then if there really are unsolvable problems with the platform they just get offloaded onto users. Passwords? Privacy? Your problem now. Surely you know to use a password manager?I think this new wave of AI is going to be like that. If they never solve the hallucination&#x2F;confabulation issue, it&#x27;s just going to become your problem. If they never really gain insight, it&#x27;s going to become your problem to instruct them carefully. Your peers will chide for not using a robust AI-guardrail thing or not learning the basics of prompt engineering like all the kids do instinctively these days. reply wbhart 4 hours agorootparentHow on earth could you evaluate the scaling path with too little information. That&#x27;s my point. You can&#x27;t possibly know that a technology can solve a given kind of problem if it can only so far solve a completely different kind of problem which is largely unrelated!Saying that performance on grade-school problems is predictive of performance on complex reasoning tasks (including theorem proving) is like saying that a new kind of mechanical engine that has 90% efficiency can be scaled 10x.These kind of scaling claims drive investment, I get it. But to someone who understands (and is actually working on) the actual problem that needs solving, this kind of claim is perfectly transparent! reply dwaltrip 3 hours agorootparentFor the current generative AI wave, this is how I understand it:1. The scaling path is decreased val&#x2F;test loss during training.2. We have seen multiples times that large decreases in this loss have resulted in very impressive improvements in model capability across a diverse set of tasks (e.g. gpt-1 through gpt-4, and many other examples).3. By now, there is tons of robust data demonstrating really nice relationships between model size, quantity of data, length of training, quality of data, etc and decreased loss. Evidence keeps building that most multi-billion param LLMs are probably undertrained, perhaps significantly so.4. Ergo, we should expect continued capability improvement with continued scaling. Make a bigger model, get more data, get higher data quality, and&#x2F;or train for longer and we will see improved capabilities. The graphs demand that it is so.---This is the fundamental scaling hypothesis that labs like OpenAI and Anthropic have been operating off of for the past 5+ years. They looked at the early versions of the curves mentioned above, extended the lines, and said, \"Huh... These lines are so sharp. Why wouldn&#x27;t it keep going? It seems like it would.\"And they were right. The scaling curves may break at some point. But they don&#x27;t show indications of that yet.Lastly, all of this is largely just taking existing model architectures and scaling up. Neural nets are a very young technology. There will be better architectures in the future. reply uoaei 3 hours agorootparentprevAny claims of objective, quantitative measurements of \"scaling\" in LLMs is voodoo snake oil when measured against some benchmarks consisting of \"which questions does it answer correctly\". Any machine learning PhD will admit this, albeit only in a quiet corner of a noisy bar after a few more drinks than is advisable when they&#x27;re earning money from companies who claim scaling wins on such benchmarks. reply OOPMan 4 hours agorootparentprevHonestly, OpenAI seem more like a cult that a company to me.The hyperbole that surrounds them fits the mould nicely. reply hutzlibu 1 hour agorootparentThey did build the most advanced LLM tool, though. reply raincole 4 hours agorootparentprevBut he also has the incentive to exaggerate the AI&#x27;s ability.The whole idea of double-blind test (and really, the whole scientific methodology) is based on one simple thing: even the most experienced and informed professionals can be comfortably wrong.We&#x27;ll only know when we see it. Or at least when several independent research groups see it. reply visarga 3 hours agorootparent> even the most experienced and informed professionals can be comfortably wrongThat&#x27;s the human hallucination problem. In science it&#x27;s a very difficult issue to deal with, only in hindsight you can tell which papers from a given period were the good ones. It takes a whole scientific community to come up with the truth, and sometimes we fail. reply auggierose 2 hours agorootparentNo. It takes just one person to come up with the truth. It then can takes ages to convince the \"scientific community\". reply lokar 3 hours agorootparentprevI thought (and could be wrong) that all of these concerns are based on a very low probability of a very bad outcome.So: we might be close to a breakthrough, that breakthrough could get out of hand, then it could kill a billion+ people. reply patrec 3 hours agorootparent> I thought (and could be wrong) that all of these concerns are based on a very low probability of a very bad outcome.Among knowledgeable people who have concerns in the first place, I&#x27;d say giving the probability of a very bad outcome of cumulative advances as \"very low\" is a fringe position. It seems to vary more between \"significant\" and \"close to unity\".There are some knowledgeable people like Yann LeCun who have no concerns whatsoever but they seem singularly bad at communicating why this would be a rational position to take. reply ben_w 38 minutes agorootparentGiven how dismissive LeCun is of the capabilities of SotA models, I think he thinks the state of the art is very far from human, and will never be human-like.Myself, I think I count as a massive optimist, as my P(doom) is only about 15% — basically the same as Russian Roulette — half of which is humans using AI to do bad things directly. reply aidaman 3 hours agorootparentprevUnlikely. We&#x27;ll know when OpenAI has declared itself ruler of the new world, imposes martial law, and takes over. reply Gud 0 minutes agorootparentWhy would you ever know? Why would the singularity reveal itself in such an obvious way(until it&#x27;s too late to stop it)? seanhunter 1 hour agorootparentprevThat is as pure an example of the fallacy of argument from authority[1] as I have ever seen especially when you consider that any nuance in the supposed letter from the researchers to the board will have been lost in the translation from \"sources\" to the journalist to the article.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Argument_from_authority reply abhpro 1 hour agorootparentThat fallacy&#x27;s existence alone doesn&#x27;t discount anything (nor have you shown it&#x27;s applicable here), otherwise we&#x27;d throw out the entire idea of authorities and we&#x27;d be in trouble reply mejutoco 33 minutes agorootparentAuthorities are useful within a context. Appealing to authority is not an argument. At most, it is an heuristic._Using_ this fallacy in an argument invalidates the argument (or shows it did not exist in the first place) reply nobrains 4 hours agorootparentprevAlso, wbhart is referring to publicly released LLMs, while the OpenAI researchers are most likely referring to an un-released in-research LLM. reply las_balas_tres 1 hour agorootparentprevSure... but that machine learning PhD has a vested interest in being optimistically biased in his observations. reply insomagent 4 hours agoparentprevLet&#x27;s say a model runs through a few iterations and finds a small, meaningful piece of information via \"self-play\" (iterating with itself without further prompting from a human.)If the model then distills that information down to a new feature, and re-examines the original prompt with the new feature embedded in an extra input tensor, then repeats this process ad-infinitum, will the language model&#x27;s \"prime directive\" and reasoning ability be sufficient to arrive at new, verifiable and provable conjectures, outside the realm of the dataset it was trained on?If GPT-4,5,...,n can progress in this direction, then we should all see the writing on the wall. Also, the day will come where we don&#x27;t need to manually prepare an updated dataset and \"kick off a new training\". Self-supervised LLMs are going to be so shocking. reply wbhart 4 hours agorootparentPeople have done experiments trying to get GPT-4 to come up with viable conjectures. So far it does such a woefully bad job that it isn&#x27;t worth even trying.Unfortunately there are rather a lot of issues which are difficult to describe concisely, so here is probably not the best place.Primary amongst them is the fact that an LLM would be a horribly inefficient way to do this. There are much, much better ways, which have been tried, with limited success. reply gmerc 3 hours agorootparentAfter a year the entire argument you make boils down to “so far”. reply Terr_ 3 hours agorootparentWhereas your post sounds like \"Just give the approach more time, it shall continue to incrementally improve until it finally works someday, cuz reasons.\"Early attempts at human flight approached it by strapping wings to people&#x27;s arms and flapping: Do you think that would have eventually worked too, if only we had just given it a bit more time and faith? reply londons_explore 1 hour agorootparent> Early attempts at human flight approached it by strapping wings to people&#x27;s arms and flapping: Do you think that would have eventually worked too, if only we had just given it a bit more time and faith?Interestingly, we how have human powered aircraft... We have flown ~60km with human leg power alone. We&#x27;ve also got human powered ornithopters (flapping wing designs) which can fly but only for very short times before the pilot is exhausted.I expect that another 100 years from now, both records will be exceeded, altough probably for scientific curiosity more than because human powered flight is actually useful. reply ben_w 31 minutes agorootparentI knew about the legs (there was a model in the London Science Museum when I was a kid), but I didn&#x27;t know about the ornithopter.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;UTIAS_Snowbird13 years ago! Wow, how did I miss that? reply xcv123 2 hours agorootparentprev> Just give the approach more time, it shall continue to incrementally improve until it finally works someday, cuz reasonsYes. Because we haven&#x27;t yet reached the limit of deep learning models. GPT-3.5 has 175 billion parameters. GPT-4 has an estimated 1.8 trillion parameters. That was nearly a year ago. Wait until you see what&#x27;s next. reply meheleventyone 2 hours agorootparentWhy would adding more parameters suddenly make it better at this sort of reasoning? It feels a bit of a “god of the gaps” where it’ll just stop being a stochastic parrot in just a few more million parameters. reply Al-Khwarizmi 1 hour agorootparentI don&#x27;t think it&#x27;s guaranteed, but I do think it&#x27;s very plausible because we&#x27;ve seen these models gain emerging abilities at every iteration, just from sheer scaling. So extrapolation tells us that they may keep gaining more capabilities (we don&#x27;t know how exactly it does it, though, so of course it&#x27;s all speculation).I don&#x27;t think many people would describe GPT-4 as a stochastic parrot already... when the paper that coined (or at least popularized) the term came up in early 2021, the term made a lot of sense. In late 2023, with models that at the very least show clear signs of creativity (I&#x27;m sticking to that because \"reasoning\" or not is more controversial), it&#x27;s relegated to reductionistic philosophical arguments, but not really a practical description anymore. reply TerrifiedMouse 51 minutes agorootparent> very least show clear signs of creativityDo you know how that “creativity” is achieved? It’s done with a random number generator. Instead of having the LLM pick the absolute most likely next token, they have it select from a set of most likely next tokens - size of the set depends on “temperature”.Set temperature to 0, and the LLM will talk in circles and not really say anything interesting. Set it too high and it will output nonsense.The whole design of LLMs don’t seem very well thought out. Things are done a certain way not because it makes sense but because it seems to produce “impressive” results. reply xcv123 12 minutes agorootparent> Set temperature to 0, and the LLM will talk in circles and not really say anything interesting. Set it too high and it will output nonsense.Sounds like some people I know, at both extremes.> The whole design of LLMs don’t seem very well thought out. Things are done a certain way not because it makes sense but because it seems to produce “impressive” results.They have been designed and trained to solve natural language processing tasks, and are already outperforming humans on many of those tasks. The transformer architecture is extremely well thought out, based on extensive R&D. The attention mechanism is a brilliant design. Can you explain exactly which part of the transformer architecture is poorly designed? meheleventyone 1 hour agorootparentprevI don’t think we should throw out the stochastic parrot so easily. As you say there are “clear signs of creativity” but that could be it getting significantly better as a stochastic parrot. We have no real test to tell mimicry apart from reasoning and as you note we also can only speculate about how any of it works. I don’t think it’s reductionist in light of that, maybe cautious or pessimistic. reply Al-Khwarizmi 1 hour agorootparentThey can write original stories in a setting deliberately designed to not be found in the training set (https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.08433). To me that&#x27;s rather strong evidence of being beyond stochastic parrots by now, although I must concede that we know so little about how everything works, that who knows. reply vbezhenar 1 hour agorootparentprevHumans and other animals definitely different when it comes to reasoning. At the same time, biologically humans and many other animals are very similar, when it comes to brain, but humans have more \"processing power\". So it&#x27;s only natural to expect some emergent properties from increasing number of parameters. reply xcv123 19 minutes agorootparentprev> it’ll just stop being a stochastic parrot in just a few more million parameters.Is is not a stochastic parrot today. Deep learning models can solve problems, recognize patterns, and generate new creative output that is not explicitly in their training set. Aside from adding more parameters there are new neural network architectures to discover and experiment with. Transformers aren&#x27;t the final stage of deep learning. reply tarsinge 2 hours agorootparentprevYou are missing the point that it can be a model limit. LLMs were a breakthrough but that doesn’t mean they are a good model for some other problems, no matter the number of parameters. Language contains more than we thought, as GPT has impressively showed (ie semantics embedded in the syntax emerging from text compression), but still not every intellectual process is language based. reply xcv123 35 minutes agorootparentI know that, but deep learning is more than LLMs. Transformers aren&#x27;t the final ultimate stage of deep learning. We haven&#x27;t found the limit yet. reply ra 3 hours agorootparentprevIndeed. LLM is an application on a transformer trained with backpropagation. What stops you from adding a logic&#x2F;mathematic \"application\" on the same transformer? reply seanhunter 1 hour agorootparentNothing, and there are methods which allow these types of models to learn to use special purpose tools of this kind[1].[1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.04761 Toolformer: Language Models Can Teach Themselves to Use Tools reply jimmySixDOF 3 hours agorootparentprevYes, it seems like this is a direction to replace RLHF so another way to scale without baremetal and if not this then still just a matter of time before some model optimization outperforms the raw epoch&#x2F;parameters&#x2F;token approach. reply caesil 4 hours agoparentprevFWIW The Verge is reporting that people inside are also saying the Reuters story is bunk:https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;22&#x2F;23973354&#x2F;a-recent-openai... reply himaraya 4 hours agorootparent> After being contacted by Reuters, OpenAI, which declined to comment, acknowledged in an internal message to staffers a project called Q* and a letter to the board before the weekend&#x27;s events, one of the people said.Reuters update 6:51 PSTThe Verge has acted like an intermediary for Sam&#x27;s camp during this whole saga, from my reading. reply topspin 3 hours agoparentprevI don&#x27;t know whether this particular article is bunk. I do know I&#x27;ve read many, many similar comments about how some complex task is beyond an conceivable model or system and then, years later, marveled at exactly that complex task being solved. reply jhanschoo 3 hours agorootparentThe article isn&#x27;t describing something that will happen years later, but now. The comment author is saying that this current model is not AGI as it likely can&#x27;t solve university-level mathematics, and they are presumably open to the possibility of a model years down the line that can do that. reply est 4 hours agoparentprev> The reason LLMs fail at solving mathematical problems is becauseThat&#x27;s exactly what Go&#x2F;Baduk&#x2F;Weiqi players think some years ago. And superalignment is defintely OpenAI&#x27;s major research objective:> https:&#x2F;&#x2F;openai.com&#x2F;blog&#x2F;our-approach-to-alignment-research> our AI systems are proposing very creative solutions (like AlphaGo’s move 37)When will mathematicians face the move 37 moment? reply Davidzheng 3 hours agorootparentProbably inThat&#x27;s just what I came up with after thinking on it for 2 minutes. I&#x27;m sure they have even better ideas.the thing is that ideas not necessary easy to implement. There will be many obstacles on route you described:- quality of provers, is there good ergo provers which also can run at large scales (say billions of facts)- you need some formalization approach, probably LLM will do some work, but we don&#x27;t know what will be quality- LLM likely will generate many individual factoids, which are losely compatible, contradicting, etc, and untrivial effort is required to reconcile and connect them reply wbhart 4 hours agorootparentprevThere are certainly efforts along the lines of what you suggest. There are problems though. The number of backtracks is 10^k where k is not 2, or 3, or 4.....Another issue is that of autoformalisation. This is the one part of the problem where an LLM might be able to help, if it were reliable enough (it isn&#x27;t currently) or if it could truly understand the logical structure of mathematical problems correctly (currently they can&#x27;t). reply abeppu 5 hours agoparentprevThis comment seems to presume that Q* is related to existing LLM work -- which isn&#x27;t stated in the article. Others have guessed that the &#x27;Q&#x27; in Q* is from Q-learning in RL. In particular backtracking, which you point out LLMs cannot do, would not be an issue in an appropriate RL setup. reply nullc 4 hours agorootparent> which you point out LLMs cannot do, would not be an issue in an appropriate RL setup.Hm? it&#x27;s pretty trivial to use a sampler for LLMs that has a beam search and will effectively &#x27;backtrack&#x27; a &#x27;bad&#x27; selection.It just doesn&#x27;t normally help-- by construction the LLM sampled normally already approximates the correct overall distribution for the entire output, without any search.I assume using a beam search does help when your sampler does have some non-trivial constraints (like the output satisfies some grammar or passes an algebraic test, or even just top-n sampling since those adjustments on a token by token basis result in a different approximate distribution than the original distribution filtered by the constraints). reply Davidzheng 4 hours agoparentprevI agree that in and of itself it&#x27;s not enough to be alarmed. Also i have to say i don&#x27;t really know what grade school mathematics means here(multiplication? Proving triangles are congruent?). But I think the question is, whether the breakthrough is an algorithmic change in reasoning. If it is, then it could challenge all 4 of your limitations. Again this article is low on details so really we are arguing over our best guesses. But I wouldn&#x27;t be so confident that an improvement on simple math problems due to algorithms can have huge implications.Also, do you remember what go players said when they beat Fan Hui? Change can come quick reply wbhart 4 hours agorootparentI think maybe I didn&#x27;t make myself quite clear here. There are already algorithms which can solve advanced mathematical problems 100% reliably (prove theorems). There are even algorithms which can prove any correct theorem that can be stated in a certain logical language, given enough time. There are even systems in which these algorithms have actually been implemented.My point is that no technology which can solve grade school maths problems would be viewed as a breakthrough by anyone who understood the problem. The fundamental problems which need to be solved are not problems you encounter in grade school mathematics. The article is just ill-informed. reply himaraya 4 hours agorootparentThe article suggests the way Q* solves basic math problems matters more than the difficulty of the problems themselves. Either way, I think judging the claims made remains premature without seeing the supporting documentation. reply kenjackson 2 hours agorootparentprev“Given enough time” makes that a useless statement. Every kid in college learns this.The ability to eventually solve a given theorem isn’t interesting — especially if the time is longer than the time left in the universe.It’s far more interesting to see if an AI can, given an arbitrarily stated problem make clear progress quickly. reply poulpy123 2 hours agoparentprevI don&#x27;t know for Q* of course, but all the tests I made with GPT4, and all what I&#x27;ve read and seen about it, show that it is unable to reason. It was trained with an unfathomable amount of data, so it can simulate reasoning very well, but it is unable to reason reply oezi 2 hours agorootparentWhat is the difference between simulating reasoning very well and \"actual\" reasoning? reply parentheses 2 hours agorootparentI think the poster meant that it&#x27;s capable of having a high probability of correct reasoning - simulating reasoning is lossy, actual reasoning is not. Though, human reasoning is still lossy. reply Jare 1 hour agorootparentprevProbably best to say \"simulate the appearance of reasoning\": looks and feels 100% acceptable at a surface level, but the actual details and conclusions are completely wrong &#x2F; do not follow. reply seanhunter 1 hour agorootparentprevActual reasoning shows the understanding and use of a model of the key features of the underlying problem&#x2F;domain.As a simple example that you can replicate using chatgpt, ask it to solve some simple maths problem. Very frequently you will get a solution that looks like reasoning but is not, and reveals that it does not have an actual model of the underlying maths but is in fact doing text prediction based on a history of maths. For example see here[1]. I ask it for some quadratics in x with some specification on the number of roots. It gives me what looks at first glance like a decent answer. Then I ask the same exact question but asking for quadratics in x and y[2]. Again the answer looks plausible except that for the solution \"with one real root\" it says the solution has one real root when x + y =1. Well there are infinite real values for x and y such that x + y =1, not one real root. It looks like it has solved the problem but instead it has simulated the solving of the problem.Likewise stacking problems, used to check for whether an AI has a model of the world. This is covered in \"From task structures to world models: What do LLMs know?\"[3] but for example here[4] I ask it whether it&#x27;s easier to balance a barrel on a plank or a plank on a barrel. The model says it&#x27;s easier to balance a plank on a barrel with an output text that simulates reasoning discussing center of mass and the difference between the flatness of the plank and the tendency of the barrel to roll because of its curvature. Actual reasoning would say to put the barrel on its end so it doesn&#x27;t roll (whether you put the plank on top or not).[1] https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;64556be8-ad20-41aa-99af-ed5a42...[2] https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;2cd39197-dc09-4d07-a0d6-6cd800...[3] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.04276[4] https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;4b631a92-0d55-4ae5-8892-9be025... reply chipsambos 48 minutes agorootparentI generally agree with what you&#x27;re saying and the first half of your answer makes perfect sense but I think the second is unfair (i.e. \"[is it] easier to balance a barrel on a plank or a plank on a barrel\"). It&#x27;s a trick question and \"it\" tried to answer in good faith.If you were to ask the same question of a real person and they replied with the exact same answer you could not conclude that person was not capable of \"actual reasoning\". It&#x27;s a bit of witch-hunt question set to give you the conclusion you want. reply seanhunter 8 minutes agorootparentI didn&#x27;t make up this methodology and it&#x27;s genuinely not a trick question (or not intended as such), it&#x27;s a simple example of an actual class of questions that researchers ask when trying to determine whether a model of the world exists. The paper I linked uses a ball and a plank iirc. Often they use a much wider range of objects eg: something like \"Suggest a stable way of stacking a laptop, a book, 4 wine classes, a wine bottle and an orange\" is one that I&#x27;ve seen in a paper for example. reply silvaring 1 hour agorootparentprevActual reasoning is made up of various biological feedback loops that happen in the body and brain, essentially your physical senses give you the ability to reason in the first place, without the eyes, ears etc there is no ability to learn basic reasoning, which is why kids who are blind or mute from birth have huge issues learning about object permanence, spatial awaraness etc. You cant expect human reasoning without human perception.My question is how does the AI perceive. Basically how good is the simulation for its perception. If we know that, then we can probably assess its ability to reason because we can compare it to the closest benchmark we have (your average human being). How do AI&#x27;s see, how did they learn concepts in strings of words and pixels? How does the concept it learnt in text carry through to images of colors, of shapes? Does it show a transfer of conceptual understanding across both two and three dimentional shapes?I know these are more questions than answers, but its just things that I&#x27;ve been wondering about. reply ajuc 47 minutes agorootparentThis ship can&#x27;t swim because only living creatures swim. It&#x27;s true but it only shows your definition sucks. reply richardw 4 hours agoparentprevOn backtracking, I thought tree-of-thought enabled that?\"considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.10601Generally with you though, this thing is not leading to real smarts and that&#x27;s accepted by many. Yes, it&#x27;ll fill in a few gaps with exponentially more compute but it&#x27;s more likely that an algo change is required once we&#x27;ve maxed out LLM&#x27;s. reply wbhart 3 hours agorootparentYes, there are various approaches like tree-of-thought. They don&#x27;t fundamentally solve the problem because there are just too many paths to explore and inference is just too slow and too expensive to explore 10,000 or 100,000 paths just for basic problems that no one wanted to solve anyway.The problem with solving such problems with LLMs is that if the solution to the problem is unlike problems seen in training, the LLM will almost every time take the wrong path and very likely won&#x27;t even think of the right path at all.The AI really does need to understand why the paths it tried failed in order to get insight into what might work. That&#x27;s how humans work (well, one of many techniques we use). And despite what people think, LLMs really don&#x27;t understand what they are doing. That&#x27;s relatively easy to demonstrate if you get an LLM off distribution. They will double down on obviously erroneous illogic, rather than learn from the entirely new situation. reply richardw 3 hours agorootparentThank you for the thoughtful response reply greendesk 48 minutes agoparentprevThinking is about associations and object visualisation. Surely a non-human system can build those, right? Pointing out only to a single product exposed to the public does not prove limitations for a theoretical limit. reply calf 4 hours agoparentprevBut, isn&#x27;t AlphaGo a solution to kind of specific mathematical problem? And that it has passed with flying colors?What I mean is, yes, neural networks are stochastic and that seems to be why they&#x27;re bad at logic; on the other hand it&#x27; not exactly hallucinating a game of Go, and that seems different to how neural networks are prone to hallucination and confabulation on natural language or X-ray imaging. reply wbhart 3 hours agorootparentSure, but people have already applied deep learning techniques to theorem proving. There are some impressive results (which the press doesn&#x27;t seem at all interested in because it doesn&#x27;t have ChatGPT in the title).It&#x27;s really harder than one might imagine to develop a system which is good at higher order logic, premise selection, backtracking, algebraic manipulation, arithmetic, conjecturing, pattern recognition, visual modeling, has a good mathematical knowledge, is autonomous and fast enough to be useful.For my money, it isn&#x27;t just a matter of fitting a few existing jigsaw pieces together in some new combination. Some of the pieces don&#x27;t exist yet. reply calf 2 hours agorootparentThen your critique is about LLMs specifically.But even there, can we say scientifically that LLMs cannot do math? Do we actually know that? And in my mind, that would imply LLMs cannot achieve AGI either. What do we actually know about the limitations of various approaches?And couldn&#x27;t people argue that it&#x27;s not even necessary to think in terms of capabilities as if they were modules or pieces? Maybe just brute-force the whole thing, make a planetary scale computer. In principle. reply visarga 3 hours agorootparentprevYou seem knowledgeable. Can you share a couple of interesting papers for theorem proving that came out in the last year? I read a few of them as they came out, and it seemed neural nets can advance the field by mixing \"soft\" language with \"hard\" symbolic systems. reply wbhart 2 hours agorootparentThe field is fairly new to me. I&#x27;m originally from computer algebra, and somehow struggling into the field of ATP.The most interesting papers to me personally are the following three:* Making higher order superposition work. https:&#x2F;&#x2F;doi.org&#x2F;10.1007&#x2F;978-3-030-79876-5_24* MizAR 60 for Mizar 50. https:&#x2F;&#x2F;doi.org&#x2F;10.48550&#x2F;arXiv.2303.06686* Magnus Hammer, a Transformer Based Approach to Premise Selection. https:&#x2F;&#x2F;doi.org&#x2F;10.48550&#x2F;arXiv.2303.04488Your mileage may vary. reply paulsutter 45 minutes agoparentprevGood point. What would these AI people know about AI? You’re right, what they’re doing will never workYou should make your own, shouldn’t take more than a weekend, right? reply kolinko 1 hour agoparentprevLLMs by themselves don’t learn from past past mistakes, but you could cycle inference steps and fine tuning&#x2F;retraining steps.Also, you can store failed attempts and lessons learned in context. reply whatever1 5 hours agoparentprevThe thing is that a LLMs can point out a logic error in their reasoning if specifically asked to do so.So maybe OpenAI just slapped an RL agent on top of the next-token generator. reply lukego 56 minutes agoparentprev> 1) they are terrible at arithmetic, 2) they are terrible at algebraThe interaction can be amusing. Proving algebra non-theorems by cranking through examples until an arithmetic mistake finally leads to a \"counter-example.\"It&#x27;s like https:&#x2F;&#x2F;xkcd.com&#x2F;882&#x2F; for theorems. reply codedokode 2 hours agoparentprev> The reason LLMs fail at solving mathematical problems is because...because they are too small and have too little weights. Cats cannot solve mathematical problems too, but unlike cats, neural network evolve. reply serf 1 hour agorootparent>Cats cannot solve mathematical problems too, but unlike cats, neural network evolve.cats evolve plenty, pressure towards mathematical reasoning has stymied as of late what with the cans of food and humans. reply nijave 4 hours agoparentprevChatGPT (3.5) seems to do some rudimentary backtracking when told it&#x27;s wrong enough times. However, it does seem to do very poorly in the logic department. LLMs can&#x27;t seem to pick out nuance and separate similar ideas that are technically&#x2F;logically different.They&#x27;re good at putting things together commonly found together but not so good at separating concepts back out into more detailed sub pieces. reply wbhart 4 hours agorootparentI&#x27;ve tested GPT-4 on this and it can be induced to give up on certain lines of argument after recognising they aren&#x27;t leading anywhere and to try something else. But it would require thousands (I&#x27;m really under exaggerating here) of restarts to get through even fairly simple problems that professional mathematicians solve routinely.Currently the context length isn&#x27;t even long enough for it to remember what problem it was solving. And I&#x27;ve tried to come up with a bunch of ways around this. They all fail for one reason or another. LLMs are really a long, long way off managing this efficiently in my opinion. reply Davidzheng 2 hours agorootparentWeird time estimate given that a little more than a year ago, the leading use of LLMs was generating short coherent paragraphs (3-4 sentences) reply stephenboyd 3 hours agoparentprevDid they say it was an LLM? I didn’t see that in the reporting. reply elliotec 4 hours agoparentprevHubris reply lucubratory 3 hours agorootparentWhose, in this instance? I can see an argument for both reply jiggawatts 1 hour agoparentprevEverything you said about LLMs being \"terrible at X\" is true of the current generation of LLM architectures.From the sound of it, this Q* model has a fundamentally different architecture, which will almost certainly make some of those issues not terrible any more.Most likely, the Q* design is the very similar to the one suggested recently by one of the Google AI teams: doing a tree search instead of greedy next token selection.Essentially, current-gen LLMs predict a sequence of tokens: A->B->C->D, etc... where the next \"F\" token depends on {A,B,C,D} and then is \"locked in\". While we don&#x27;t know exactly how GPT4 works, reading between the lines of the leaked info it seems that it evaluates 8 or 16 of these sequences in parallel, then picks the best overall sequence. On modern GPUs, small workloads waste the available computer power because of scheduling overheads, so \"doing redundant work\" is basically free up to a point. This gives GPT4 a \"best 1 of 16\" output quality improvement.That&#x27;s great, but each option is still a linear greedy search individually. Especially for longer outputs the chance of a \"mis-step\" at some point goes up a lot, and then the AI has no chance to correct itself. All 16 of the alternatives could have a mistake in them, and now its got to choose between 16 mistakes.It&#x27;s as if you were trying to write a maths proof, asked 16 students, and instructed them to not cooperate and write their proof left-to-right, top-to-bottom without pausing, editing, or backtracking in any way! It&#x27;d like to see how \"smart\" humans would be at maths under those circumstances.This Q* model likely does what Google suggested: Do a tree search instead of a strictly linear search. At each step, the next token is presented as a list of \"likely candidates\" with probabilities assigned to each one. Simply pick to \"top n\" instead of the \"top 1\", branch for a bit like that, and then prune based on the best overall confidence instead of the best next token confidence. This would allow a low-confidence next token to be selected, as long as it leads to a very good overall result. Pruning bad branches is also effectively the same as back-tracking. It allows the model to explore but then abandon dead ends instead of being \"forced\" to stick with bad chains of thought.What&#x27;s especially scary -- the type of scary that would result in a board of directors firing an overly commercially-minded CEO -- is that naive tree searches aren&#x27;t the only option! Google showed that you can train a neural network to get better at tree search itself, making it exponentially more efficient at selecting likely branches and pruning dead ends very early. If you throw enough computer power at this, you can make an AI that can beat the world&#x27;s best chess champion, the world&#x27;s best Go player, etc...Now apply this \"AI-driven tree search\" to an AI LLM model and... oh-boy, now you&#x27;re cooking with gas!But wait, there&#x27;s more: GPT 3.5 and 4.0 were trained with either no synthetically generated data, or very little as a percentage of their total input corpus.You know what is really easy to generate synthetic training data for? Maths problems, that&#x27;s what.Even up to the point of \"solve this hideous integral that would take a human weeks with pen and paper\" can be bulk generated and fed into it using computer algebra software like Wolfram Mathematica or whatever.If they cranked out a few terabytes of randomly generated maths problems and trained a tree-searching LLM that has more weights than GPT4, I can picture it being able to solve pretty much any maths problem you can throw at it. Literally anything Mathematica could do, except with English prompting!Don&#x27;t be so confident in the superiority of the human mind. We all thought Chess was impossible for computers until it wasn&#x27;t. Then we all moved the goal posts to Go. Then English text. And now... mathematics.Good luck with holding on to that crown. reply nullc 4 hours agoparentprevIt&#x27;s also hard to know what the LLM has reasoned out vs has memorized.I like the very last example in my tongue-in-cheek article, https:&#x2F;&#x2F;nt4tn.net&#x2F;articles&#x2F;aixy.htmlCertainly the LLM didn&#x27;t derive Fermat&#x27;s theorem on sums of two squares under the hood (and, of course, very obviously didn&#x27;t prove it correct-- as the code is technically incorrect for 2), but I&#x27;m somewhat doubtful that there was any function exactly like the template in codex&#x27;s training set either (at least I couldn&#x27;t quickly find any published code that did that). The line between creating something and applying a memorized fact in a different context is not always super clear. reply CamperBob2 4 hours agoparentprev\"Also, Crysis runs like crap on my Commodore 64.\" reply 3cats-in-a-coat 2 hours agoparentprevI don&#x27;t understand your thesis here it seems self-contradictory:1. \"I don&#x27;t think this is real news &#x2F; important because solving grade school math is not a predictor of ability to do complex reasoning.\"2. \"LLMs can&#x27;t solve grade school math because they&#x27;re bad at arithmetic, algebra and most importantly reasoning.\"So... from 2 automatically follows that LLMs with sufficiently better math may be sufficiently better at reasoning as you said \"most importantly\" reasoning is relevant for their ability to do math. Saying \"most importantly reasoning\" and then saying that reasoning is irrelevant if they can do math, is odd. reply xcv123 4 hours agoparentprev> I feel very comfortable saying, as a mathematician, that the ability to solve grade school maths problems would not be at all a predictor of ability to solve real mathematical problems at a research level.At some point in the past, you yourself were only capable of solving grade school maths problems. reply SantalBlush 4 hours agorootparentThe statement you quoted also holds for humans. Of those who can solve grade school math problems, very, very few can solve mathematical problems at a research level. reply kgeist 3 hours agorootparentWe&#x27;re moving the goalposts all the time. First we had the Turing test, now AI solving math problems \"isn&#x27;t impressive\". Any small mistake is a proof it cannot reason at all. Meanwhile 25% humans think the Sun revolves around the Earth and 50% of students get the bat and ball problem wrong. reply xcv123 4 hours agorootparentprevYou missed the point. Deep learning models are in the early stages of development.With recent advancements they can already outperform humans at many tasks that were considered to require AGI level machine intelligence just a few years ago. reply CodeCompost 1 hour agoparentprevIt&#x27;s a text generator that spits out tokens. It has absolutely no understanding of what it&#x27;s saying. We as humans are attaching meaning to the generated text.It&#x27;s the humans that are hallucinating, not the text generator. reply bottlepalm 1 hour agorootparentThey&#x27;ve already researched this and have found model inside the LLM such as a map of the world - https:&#x2F;&#x2F;x.com&#x2F;wesg52&#x2F;status&#x2F;1709551516577902782. Understanding is key to how so much data can be compressed into a LLM. There really isn&#x27;t a better way to store all of it better than plain understanding it. reply cduzz 7 hours agoprevI was talking to my (12 year old) son about parts of math he finds boring. He said that he thinks absolute value is absurdly easy and extremely boring. I asked him if there was anything that might make it more interesting, he said \"maybe complex numbers\".So I asked him \"what would the absolute value of i+1 be?\" he thinks for a little bit and says \"square root of 2\" and I ask him \"what about the absolute value of 2i + 2?\" \"square root of 8\"I ask him \"why?\" and he said \"absolute value is distance; in the complex plane the absolute value is the hypotenuse of the imaginary and real numbers.\"So -- first of all, this was a little surprising to me that he&#x27;d thought about this sort of thing having mostly just watched youtube videos about math, and second, this sort of understanding is a result of some manner of understanding the underlying mechanisms and not a result of just having a huge dictionary of synonyms.To what degree can these large language models arrive at these same conclusions, and by what process? reply naasking 4 hours agoparent> this sort of understanding is a result of some manner of understanding the underlying mechanisms and not a result of just having a huge dictionary of synonyms.He developed an understanding of the underlying mechanisms because he correlated concepts between algebraic and geometric domains, ie. multimodal training data. Multimodal models are already known to be meaningfully better than unimodal ones. We&#x27;ve barely scratched the surface of multimodal training. reply chacham15 2 hours agoparentprevSorry, can you explain this? To me, it makes sense to define abs(x) = sqrt(x^2) i.e. ignoring the negative solution enforces the positive result. Using that definition, abs(i+1) = sqrt((i+1)^2) = sqrt(i^2 + 2i + 1) = sqrt(-1 + 2i + 1) = sqrt(2i) != sqrt(2). The second example seems off in the same way (i.e. the answer should be sqrt(8i) instead of sqrt(8)). Am I missing something? Also, abs(i+2) = sqrt((i+2)^2) = sqrt(i^2 + 4i + 4) = sqrt(-1 + 4i + 4) = sqrt(4i + 3) which doesnt seem to follow the pattern your son described.Also, just to point out that my understanding of absolute value is different than your sons. Thats not to say one is right and another is wrong, but there are often different ways of seeing the same thing. I would imagine that LLMs would similarly see it a different way. Another example of this is people defining PI by its relation to the circumference of a circle. Theres nothing wrong with such a definition, but its certainly not the only possible definition. reply AgentMatt 58 minutes agorootparent> To me, it makes sense to define abs(x) = sqrt(x^2) i.e. ignoring the negative solution enforces the positive result.Why does this make sense to you? You have some notion of what an absolute value should be, on an intuitive or conceptual level, and the mathematical definition you give is consistent with that (in the one dimensional case).Now taking this valid definition for the 1-d case and generalizing that to higher dimensions is where you run into problems.Instead, you can go back to the conceptual idea of the absolute value and generate a definition for higher dimensional cases from there.Interpreting absolute value as the distance from the origin yields the same concrete definition of abs(x) = sqrt(x^2) for the 1-d case, but generalizes better to higher dimensions: abs( (x,y) ) = sqrt(x^2 + y^2) for the 2-d case equivalent to complex numbers. reply chacham15 30 minutes agorootparent> Why does this make sense to you? You have some notion of what an absolute value should be, on an intuitive or conceptual level, and the mathematical definition you give is consistent with that (in the one dimensional case).In my mind abs(x) = x*sign(x) which is why the above formulation seems correct. This formulation is useful, for example, in formulating reflections.> Instead, you can go back to the conceptual idea of the absolute value and generate a definition for higher dimensional cases from there.This is an interesting idea...how would you define sign(x) in a higher dimension? Wouldnt sign in a higher dimension be a component-wise function? E.g. the reflection would happen on one axis but not the other.> Interpreting absolute value as the distance from the originThis seems to make sense in that it is a different interpretation of abs which seems simpler than reflection in higher dimensions, but seems like a different definition.I know that there are applications of complex numbers in real systems. In such systems, the complex definition seems to not be as valuable. E.g. if I&#x27;m solving a laplace transform, the real number definition seems more applicable than the complex number definition, right?I&#x27;ve asked wolfram alpha to solve the equation and it lists both answers: one using the formulation of sqrt(x^2) and the other using sqrt(re(x)^2 + im(x)^2) so it seems like there is merit to both...I suppose in the laplace example, we are actually operating in one dimension and the imaginary component is approximating something non-real, but doesnt actually exist. I.e. any real&#x2F;observable effect only happens when the imaginary component disappears meaning that this is still technically one dimension. So, since we&#x27;re still in one dimension, the one dimensional formula still applies. Is that correct?Your explanation has been the most helpful though, thanks. reply svetb 1 hour agorootparentprevThe absolute value of a complex number is defined in a different way than that of a real number. For complex number z it is sqrt(Re(z)^2 + Im(z)^2). GP’s examples are correct, I don’t think there’s any ambiguity there.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Absolute_value reply lovasoa 1 hour agorootparentprevNo, there is just one definition, and it&#x27;s his son&#x27;s: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Absolute_value#Complex_numbe... reply chacham15 58 minutes agorootparentThe article you linked literally says that there are two definitions: one for real numbers and another for complex numbers. Thanks for the info. reply LASR 5 minutes agorootparentThat’s not what it says. It says that there is a single definition that can be generalized to both real and complex numbers.A special cases of the general definition where im(z)==0 yields an expression where some parts are multiplied by zero, and can then be omitted entirely.This means that there is one definition. You can mentally ignore some parts of this when dealing with reals. reply mkl 6 minutes agorootparentprevThere is one definition: the distance to 0. There are several (more than two) different ways to calculate it in different situations. reply SpaceNoodled 1 hour agorootparentprevHe&#x27;s talking about distance in two dimensions with real numbers on one axis and complex on the other. reply white_dragon88 4 hours agoparentprevYour son is a goddamn genius. reply cduzz 3 hours agorootparentMaybe; he still needs to finish his damned homework and remember to turn it in. And eat some vegetables. reply SpaceNoodled 1 hour agorootparentBut his homework is boring reply quickthrower2 2 hours agorootparentprevJust quit school and join YC now :-) reply n6242 2 hours agorootparentprevNot saying the kid can&#x27;t be a genius, but grandparent discussing math with the kid and incentivising him to learn is probably a massive boost to his development. It&#x27;s not the same as having to go to the library and teach yourself. Still, props to the kid though. reply Strom 7 hours agoparentprevThe large language models will read your comment here and remember the answer. reply Borrible 1 hour agorootparentGPT-4 correctly reconstructs the \"complex modulus\" token sequence already. Just ask it the same questions as the parent. Probably interesting to see what it will do, when it turns twelve. reply cduzz 7 hours agorootparentprevThe spot instance declared \"a similar vector exists\" and de-provisioned itself? reply J_cst 2 hours agoparentprevMy son plays soccer reply doug_durham 2 hours agoparentprevWhat makes you think that an LLM has a \"huge dictionary of synonyms\"? That&#x27;s not how LLMs work. They capture underlying concepts and their relations. You had a good point going until you make a straw man argument about the capabilities of LLMs. reply Shrezzing 34 minutes agoparentprevIf they&#x27;re not already in one, you might want to get your kid enlisted in some gifted child programs. reply muskmusk 5 hours agoparentprevIf you ask Ilya Sutskever he will say your kids head is full of neurons, so is LLMs.LLMs comsume training data and can then be asked questions. How different is that to your son watching YouTube and then answering questions?It&#x27;s not 1:1 the same,yet, but it&#x27;s in the neighborhood. reply cduzz 4 hours agorootparentWell, my son is a meat robot who&#x27;s constantly ingesting information from a variety of sources including but not limited to youtube. His firmware includes a sophisticated realtime operating system that models reality in a way that allows interaction with the world symbolically. I don&#x27;t think his solving the |i+1| question was founded in linguistic similarity but instead in a physical model &#x2F; visualization similarity.So -- to a large degree \"bucket of neurons == bucket of neurons\" but the training data is different and the processing model isn&#x27;t necessarily identical.I&#x27;m not necessarily disagreeing as much as perhaps questioning the size of the neighborhood... reply meheleventyone 1 hour agorootparentFrom the meat robot perspective the structure, operation and organisation of the neurons is also significantly different. reply leobg 3 hours agorootparentprevMaybe Altman should just go have some kids and RLHF them instead. reply swatcoder 4 hours agorootparentprevThere are thousands of structures and substances in a human head besides neurons, at all sorts of commingling and overlapping scales, and the neurons in those heads behave much differently and with tremendously more complexity than the metaphorical ones in a neural network.And in a human, all those structures and substances, along with the tens of thousands more throughout the rest of the body, are collectively readied with millions of years of \"pretraining\" before processing a continuous, constant, unceasing mulitmodal training experience for years.LLM&#x27;s and related systems are awesome and an amazing innovation that&#x27;s going to impact a lot of our experiences over the next decades. But they&#x27;re not even the same galaxy as almost any living system yet. That they look like they&#x27;re in the neighborhood is because you&#x27;re looking at them through a very narrow, very zoomed telescope. reply Davidzheng 4 hours agorootparentTrue. But a human neuron is more complex than an AI neuron by a constant factor. And we can improve constants. Also you say years like it&#x27;s a lot of data--but they can run RL on chatgpt outputs if they want, isn&#x27;t it comparable? But anyway i share your admiration for the biological thinking machines ;) reply tsimionescu 2 hours agorootparentThe sun is also better than a fusion reactor on earth by only a constant factor. That alone doesn&#x27;t mean much for out prospects of matching its power output. reply riku_iki 2 hours agorootparentprev> human neuron is more complex than an AI neuron by a constant factorconstant still can be not reachable yet: like 100T neurons in brain vs 100B in chatgpt, and also brain can involve some quantum mechanics for example, which will make complexity diff not constant, but say exponential. reply Davidzheng 2 hours agorootparentWikipedia says 100 billion neurons in the brain reply riku_iki 1 hour agorootparentOk, I messed up, we need compare LLM weight with synaps, not neuron, and wiki says there are 100-500T synapses in human brain reply Davidzheng 52 minutes agorootparentOk let&#x27;s say 500T. Rumor is currently gpt4 is 1T. Do you expect gpt6 to be less than 500T? Non sarcastic question. I would lean no. replyDavidzheng 4 hours agorootparentprevTo continue on this. LLMs are actually really good at asking questions even about cutting edge research. Often, I believe, convincing the listener that it understands more than it goes reply gunapologist99 4 hours agorootparent... which ties into Sam&#x27;s point about persuasiveness before true understanding. reply Exoristos 2 hours agoparentprevDamn. What YouTube channels does he watch? reply jhanschoo 3 hours agoparentprevSounds like your son is ready for you to bring it up another level and ask what the absolute value of a (bounded) function is (assuming they have played with functions e.g. in desmos) reply ugh123 4 hours agoparentprevAre you saying an LLM can&#x27;t come to the right conclusion and give an explanation for \"what is the absolute value of 2i + 2\"? reply gunapologist99 4 hours agorootparentAre you saying it could, without having read it somewhere? reply ugh123 4 hours agorootparentMaybe I&#x27;m unsure what we&#x27;re arguing here. Did the guys kid drum that up himself or did he learn it from yt? Knowledge can be inferred or extracted. If it comes up with a correct answer and shows it&#x27;s work, who cares how the knowledge was obtained? reply cduzz 4 hours agorootparentYeah, my son only knows about imaginary numbers as far as the veritasium \"epic math dual\" video.As far as I can tell he inferred that |i+1| needs the Pythagorean theorem and that i and 1 are legs of the right triangle. I don&#x27;t think anyone ever suggested that \"absolute value\" is \"length\". I asked him what |2i+2| would be an his answer of \"square root of 8\" suggests that he doesn&#x27;t have it memorized as an answer because if it was he&#x27;d have said \"2 square root two\" or something similar.I also asked if he&#x27;d seen a video about this and he said no. I think he just figured it out himself. Which is mildly spooky. reply sidlls 3 hours agorootparentprevIf the knowledge was obtained by genuine reasoning, that implies that it could also derive&#x2F;develop a novel solution to an unsolved problem that is not achieved by random guesses. For example, the conception of a complex number in the first place, to solve a class of problems that, prior, weren&#x27;t even thought to be problems. There&#x27;s no evidence that any LLM can do that. replysynaesthesisx 9 hours agoprevRemember, about a month ago Sam posted a comment along the lines of \"AI will be capable of superhuman persuasion well before it is superhuman at general intelligence, which may lead to very strange outcomes\".The board was likely spooked by the recent breakthroughs (which were most likely achieved by combining transformers with another approach), and hit the panic button.Anything capable of \"superhuman persuasion\", especially prior to an election cycle, has tremendous consequences in the wrong hands. reply sampo 4 hours agoparent> Remember, about a month ago Sam posted a comment along the lines of \"AI will be capable of superhuman persuasion well before it is superhuman at general intelligence, which may lead to very strange outcomes\".Superhuman persuasion is Sam&#x27;s area of expertise, so he would make that a priority when building chatbots. reply somenameforme 4 hours agoparentprevIt seems much more likely that this was just referring to the ongoing situation with LLMs being able to create exceptionally compelling responses to questions that are completely and entirely hallucinated. It&#x27;s already gotten to the point that I simply no longer use LLMs to learn about topics I am not already extremely familiar with, simply because hallucinations end up being such a huge time waster. Persuasion without accuracy is probably more dangerous to their business model than the world, because people learn extremely quickly not to use the models for anything you care about being right on. reply pbourke 1 hour agorootparentSounds like we need an AI complement to the Gell-Mann Amnesia effect. reply meheleventyone 1 hour agoparentprevLooking at humanity, persuasion seems to be an extremely low bar! Also for a superhuman trait is it that it’s capable of persuading anyone anything or rather that it’s able to persuade everyone about something. Power vs. Reach. reply thepasswordis 5 hours agoparentprevBut they didn’t hit the panic button. They said Sam lied to them about something and fired him. reply adastra22 4 hours agorootparentAccording to this article Sam has been telling the board that this new advance is not AGI and not anything to worry about (so they can keep selling it to MSFT), then the researchers involved went behind Sam&#x27;s back and reported to the board directly, claiming that they&#x27;d created something that could-maybe-be AGI and it needs to be locked down.That&#x27;s the claim at least. reply sroussey 3 hours agorootparentIf that research team is unwanted at OpenAI, I know places they can go with coworkers writing to their boss’s boss. reply Exoristos 2 hours agoparentprevWhich party is \"the wrong hands\"? reply latexr 45 minutes agorootparentThe original commenter didn’t mention a party. Please don’t polarise the discussion into a flame war. Whatever system exists won’t be used by “a party” all at once, but by individuals. Any of those, with any political affiliation, can be “the wrong hands”.I’ll offer a simple definition. The role of government is to serve the greater good of all people, thus the wrong hands are the ones which serve themselves or their own group above all. reply Liquix 2 hours agorootparentprevAny party with sufficient resources and motive to influence the outcome of an election. Outside of election season, this tech would be very dangerous in the hands of anyone seeking to influence the public for their own gain. reply bakuninsbart 1 hour agorootparentprevBoth? Parties in a democracy aren&#x27;t supposed to be shepherds of the stupid masses, I know manipulation and misinformation is par for the course on both sides of the aisle, but that&#x27;s a huge problem. Without informed, capable citizens, democracy dies a slow death. reply PaulDavisThe1st 8 hours agoparentprevExcept that there&#x27;s a fairly large body of evidence that persuasion is of limited use in shifting political opinion.So the persuasion would need to be applied to something other than some sort of causative political-implication-laden argument. reply hnthrowaway0315 5 hours agorootparentOr, let&#x27;s say, you don&#x27;t need a lot of persuasion to guide an election. I mean we already have X, FB, and an army of bots. reply naasking 4 hours agorootparentprevEven if it were true that human persuasion is of limited use in shifting opinions, the parent posted is talking about superhuman persuasion. I don&#x27;t think we should just assume those are equally effective. reply somenameforme 3 hours agorootparentDo you think any rhetoric could ever persuade you to you adopt the opposite general worldview of what you currently have? I&#x27;m positive that it could not for me. The reason for this is not because I&#x27;m obstinate, but because my worldview is not formed on persuasion, but on lived experience. And I think this is true for the overwhelming majority of people. It&#x27;s why our views tend to change as we age, and experience more of the world.You can even see this geographically. The reason many in South Texas might have a negative view of immigration while those in San Francisco might have a positive view of immigration is not because of persuasion differences, but because both places are strongly impacted by immigration but in very different ways. And this experience is what people associate with immigration in general, and so it forms people&#x27;s worldview. reply torginus 2 hours agorootparentYes. Do not forget that we literally live in the Matrix, getting all the information of import through tiny screens, the sources and validity of which we can only speculate on.All of the validity of the info we have is verified by heuristics we have, like groupthink, listening to &#x27;experts&#x27; and trying to match up the info with our internal knowledge and worldview.I feel like our current system of information allows us to develop models that are quite distant from base reality, evidenced by the multitudes of realities existing in people&#x27;s heads, leading some to question if &#x27;truth&#x27; is a thing that can be discovered.I think as people become more and more Internet-addicted, an increasing amount of our worldviews come through that little screen, instead of real-life experiences. reply silvaring 1 hour agorootparentI like your comment.The world is becoming information saturated and poorly structured by design, ever notice how these story blockers are such a big part of the propaganda machine, whereby you have to use elaborate workarounds to just read a simple news story thats pulled from another source?Saturating culture with too much data is a great tool of breaking reality, breaking truth.But they cant break truth for long, it always finds a way. And truth is a powerful vector, much more than propaganda without a base in truth, because human experience is powerful, unquantifiable, and can take someone from the gutter to a place of massive wealth or influence, in an instant. That is the power of human experience, the power of truth.Doesnt make it easy though, to live in this world of so many lies, supercharged by bots. Nature outside of our technology is much simpler in its truth. reply RandomLensman 1 hour agorootparentprevSome people get relevant information not only from little screens but interactions with other human beings or physical reality. reply torginus 11 minutes agorootparentUnless you happen to move in extremely well-informed circles, most of the information about what&#x27;s going on in the world is coming to you through those little screens (or from people who got it from said screens) reply RandomLensman 6 minutes agorootparentTrue for larger issues, which makes moving in such circles so valuable and the perspective of people only looking at small screens potentially so distorted there.However, for smaller issues and local community issues \"special access\" isn&#x27;t really much of a thing. placebo 3 hours agorootparentprevWhile I agree that human persuasion would probably not change a worldview built on lived experience, you can&#x27;t know in advance what might be possible with superhuman persuasion. You might be led to believe that your experience was interpreted incorrectly, that things are different now or that you live in an illusion and don&#x27;t even know who you are. There is no way to tell what the limits of psychological manipulation are for reprogramming your beliefs unless you are totally above any human doubt about everything, which is in itself a sad state to be in.I hope that persuaded you :) reply somenameforme 2 hours agorootparentWell, but I&#x27;m sure you&#x27;d accept that there are limits. Where we may differ is where those limits begin and where they end. In the end LLMs are not magical. All it&#x27;s going to be able to do is present words to you. And how we respond to words is something that we can control. It&#x27;s not like some series of words is just going to be able to completely reprogram you.Like here I expect there is 0% chance, even if I had a superhuman LLM writing words for me, that I could ever convince you that LLMs will not be able to convince you to hold any arbitrary position. It&#x27;s because you&#x27;ve formed your opinion, it&#x27;s not falsifiable, and so there&#x27;s not a whole heck of a lot else to be done except have some fun debates like this where, if anything, we tend to work to strengthen our own opinions by finding and repairing any holes in them. reply placebo 1 hour agorootparentBoth our opinions about this are equally unfalsifiable unless we agree on an experiment that can be performed at some point which would make one of us change their mind.I assume you&#x27;d agree that the pursuit of what is ultimately true should be exactly the opposite of making oneself more closed minded by repairing inconvenient holes in one&#x27;s opinions rather than reassessing them based on new evidence.I wasn&#x27;t referring to the ability to persuade someone to hold an arbitrary position (although that could be a fun debate as well), and putting aside the discussion about the ability to persuade fanatics, if a super intelligence had an internal model that is more aligned with what is true, it could in theory convince someone who wants to understand the truth to take a critical look at their opinions and change them if they are authentic and courageous enough to do so. replyjjeaff 5 hours agorootparentprevWhen you say persuasion, are you referring to fact based, logical argument? Because there are lots of other types of persuasion and certainly some work very well. Lying and telling people what they want to hear without too many details while dog whistling in ways that confirm their prejudices seems to be working pretty well for some people. reply hnthrowaway0315 5 hours agorootparentJust to add that a lot of people don&#x27;t care about facts. In fact, if acting according to facts make me lose $$ I&#x27;d probably start building lies. reply PaulDavisThe1st 4 hours agorootparentprevnext [–]* **that confirm their prejudices** *(my emphasis) reply hackerlight 3 hours agorootparentprev> Except that there&#x27;s a fairly large body of evidence that persuasion is of limited use in shifting political opinion.The Republican Party&#x27;s base became isolationist and protectionist during 2015 and 2016 because their dear leader persuaded them. reply zztop44 38 minutes agorootparentI think it’s not clear that the causation flowed that way. I think it’s at least partially true that the Republican base was much more isolationist and protectionist than its “establishment” elite, so any significant candidate that played into that was going to get some level of support.That, combined with Donald Trump’s massive pre-existing celebrity, talent for showmanship, and utter shamelessness got him across the line.I think it’s fair to say that at least partially, Trump didn’t shift the base - rather he revealed that the base wasn’t where the establishment thought it was. reply RandomLensman 1 hour agorootparentprevI don&#x27;t think that aligns with the reality of the opinion formation. There was a strong subset of isolationist and protectionist views before 2015. reply TMWNN 1 hour agorootparentprevI know that by \"dear leader\" you mean to imply that Trump did something unfair&#x2F;wrong&#x2F;sinister&#x2F;etc (\"just like Hitler\", amirite fellas?)., but a leader of a large group of people, by definition, is good at persuasion.Franklin Roosevelt moved the Democratic Party in a direction very different from its first century. The party&#x27;s two previous presidential nominees were a Wall Street corporate lawyer (John W. Davis) and Al Smith who, despite also being a New York City resident and state governor, so opposed FDR by the end of his first term that he founded an influential anti-New Deal organization. During the Roosevelt years the Democrats lost significant support from traditional backers, but more than made up for it with gains elsewhere in what became the New Deal coalition.Similarly, under Trump the GOP lost support in wealthy suburbs but gained support elsewhere, such as Rust Belt states, Latinos (including places like South Florida and the Texas border region), blacks, and (according to current polls) young voters. We&#x27;ll see whether one compensates for the other. reply CGamesPlay 9 minutes agoprevWhile we&#x27;re all wildly speculating about what Q* is and if GPT-5 will be able to do grade-school maths, I stumbled upon this interesting paper that discusses mixing classic RL algorithms (MCTS, like from AlphaGo), with LLMs. Q* is typically used to refer to the search for the optimal policy in these algorithms.Paper: \"Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation \" - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.04254 reply dizzydes 9 hours agoprevThis matches far better with the board&#x27;s letter re: firing Sam than a simple power struggle or disagreement on commercialisation. Seeing a huge breakthrough and then not reporting it to the board, who then find out via staff letter certainly counts as a \"lack of candour\"....As an aside, assuming a doomsday scenario, how long can secrets like this stay outside of the hands of bad actors? On a scale of 1 to enriched uranium reply dougmwne 7 hours agoparentNot long at all. Presumably you could write the method on the back of a napkin to lead another top AI researcher to the same result. That’s why trying to sit on breakthroughs is the worst option and making sure they are widely distributed along with alignment methods is the best option. reply Atheros 3 hours agorootparentAnd what if there are no alignment methods. reply marvin 2 hours agorootparentYudkowsky’s doomsday cult almost blew OpenAI to pieces and sent everyone who knows the details in the wind like dandelion seeds. What’s next? A datacenter bombing or killing key researchers? We should be happy that this particular attempt failed, because this cult is only capable of strategic actions that make things far more dangerous.This will be solved like all other engineering and science: with experiments and iteration, in a controlled setting where potential accidents will have small consequences.An unaligned system isn’t even useful, let alone safe. If it turns out that unaligned AGI is very hard, we will obviously not deploy it into the world at scale. It’s bad for the bottom line to be dead.But there’s truly no way out but forward; game theory constrains paranoid actors more than the reckless. A good balance must be found, and we’re pretty close to it.None of the «lesswrong» doomsday hypotheses have much evidence for them, if that changes then we will reassess. reply TerrifiedMouse 5 hours agoparentprevTo quote Reddit user jstadig,> The thing that most worries me about technology is not the technology itself but the greed of those who run it.Someone slimy with limitless ambition like Altman seems to be the worst person to be in charge of things like this. reply wraptile 3 hours agorootparentWhy do you perceive Altman as \"slimy with limitless ambition\"? I&#x27;ve always perceived him as being quite humble from his interviews and podcast appearances. reply nicce 3 hours agorootparentActions speak behalf of speech.You see it from the all commercial deals, protecting company image more that eliminating threats, or even from this post, if it is true.Not telling about breaktrough in research if it would end the deal with Microsoft. reply zurfer 1 hour agoprevThis seems to refer to the GSM8K (grade school math) benchmark [1]. GPT-4 scores 0.92 on that one. A breakthrough could mean it gets all of them correct.This would have major implications for long-term planning. For instance, if you have a sequence of 10 steps, each with a 90% success rate, the overall success rate after all 10 steps falls to just 34%. This is one of the reasons why agents like AutoGPT often fail in complex tasks.[1] https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;grade-school-math reply seydor 1 hour agoprevi no longer follow the messianic complex of the people in openAI. They made great tech, indeed. Other people made great tech before them without instant religious level apocalypse proclamations. People in openAI are smart enough to know that post-AGI , their stock options are worthless anyway so they wouldn&#x27;t stay walled in their secret garden if such a discovery had been made. reply dwroberts 48 minutes agoparentMy guess is also in the opposite direction with this stuff: the Q breakthrough being mentioned here is phony in some way (beyond just being PR) and the ‘lack of candour’ referred to in the firing is failing to disclose how it actually worked after demoing it to the board (eg it uses humans in the loop or some other smoke and mirrors) reply tmoravec 1 hour agoparentprevIMO it&#x27;s always been pure marketing. The wilder apocalypse proclamations, the more powerful and desirable their products seem. Exactly same store with Sam Altman&#x27;s world tour earlier this year. reply kristopolous 1 hour agorootparentThis is similar to the saber rattling about facebook being able to track and micro-target you with such effective advertising, it&#x27;s changing the world!Except everyone&#x27;s individual experience seemed to be getting general random garbage ads and the people that paid for the ads found them to be a waste of money. reply JacobJeppesen 44 minutes agoprevSeems like they have made progress in combining reinforcement learning and LLMs. Andrej Karpathy mentions it in his new talk (~38 minutes in) [1], and Ilya Sutskever talks about it in a lecture at MIT (~29 minutes in) [2]. It would be a huge breakthrough to find a proper reward function to train LLMs in a reinforcement learning setup, and using it to train a model to solve math problems in a similar fashion to how AlphaGo used self-play to learn Go.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=zjkBMFhNj_g&t=2282s[2] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=9EN_HoEk3KY&t=1705s reply zxcvgrsd2 10 hours agoprevTwo Sam Altman comments that seem to be referring to this same Q* discovery.November 18 comment at APEC (just before the current drama) [1]:> On a personal note, like four times now in the history of OpenAI, the most recent time was just in the last couple of weeks, I’ve gotten to be in the room when we pushed the veil of ignorance back and the frontier of discovery forwardand a September 22 Tweet [2]> sure 10x engineers are cool but damn those 10,000x engineer&#x2F;researchers...[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;live&#x2F;ZFFvqRemDv8?si=T3DIxics7nPWala5...[2] https:&#x2F;&#x2F;twitter.com&#x2F;sama&#x2F;status&#x2F;1705302096168493502 reply zx8080 7 hours agoparent> > sure 10x engineers are cool but damn those 10,000x engineer&#x2F;researchers...What was he referring to? reply itronitron 4 hours agorootparentThey&#x27;re getting high on their own supply. reply llelouch 6 hours agorootparentprevProbably Ilya and his team. The recent discovery was made by him and his team. \"The technical breakthrough, spearheaded by OpenAI chief scientist Ilya Sutskever\" reply danbmil 2 hours agorootparentprevI think he is referring to an AGI that is 10000x more productive than a median programmer reply fragsworth 7 hours agorootparentprevGPT4. Everyone uses it to do software engineering now and the people who developed it are responsible for that. reply cambaceres 2 hours agoprevInterestingly, I experience more anxiety from the thought of being made irrelevant than from the prospect of complete human extinction. I guess this can be interpreted as either vanity or stupidity, but I do think it illustrates how important it is for some humans to maintain their position in the social hierarchy. reply lucubratory 1 hour agoparentThis is totally normal. It&#x27;s very common for people to be more scared of public speaking than of dying, for example; there&#x27;s no shame in it. It&#x27;s helpful to be aware of, even, because if we know that we&#x27;re not perfectly \"rational\" with our fears we can try to compensate.If there&#x27;s a referendum between two government policies, the first that every single person had to publicly speak in front of at least ten strangers once a year, that policy would be terrifying and bad to people who don&#x27;t like public speaking. If the second policy was that every single person should be killed, that might be scary but it&#x27;s not really as viscerally scary as the forced public speaking madman, at least to a lot of people, and it&#x27;s also so bad that we have a natural impulse to just reject it as possible.Nevertheless, if we recognise these impulses in ourselves we can attempt to adjust for them and tick the right box on the imaginary referendum, because even though public speaking is really bad and scary, it&#x27;s still better than everyone dying. reply lucubratory 10 hours agoprevWell, Emmett Shear lied to everyone if he knew about this. I understand why, he was probably thinking that without any ability to actually undo it the best that could be done would be to make sure that no one else knows about it so that it doesn&#x27;t start an arms race, but we all know now. Given the Board&#x27;s silence and inadequate explanations, they may have had the same reasoning. Mira evidently didn&#x27;t have the same compunctions.This article, predictably, tells us almost nothing about the actual capabilities involved. \"Grade school math\" if it&#x27;s provably or scalably reasoning in a way that is non-trivially integrated with semantic understanding is more impressive than \"prove Fermat&#x27;s last theorem\" if the answer is just memorised. We&#x27;ll probably know how important Q* actually is within a year or two. reply blazespin 8 hours agoparentVery unlikely Emmett lied. What would be the point. reply cactusplant7374 9 hours agoparentprevIt tells us exactly the capabilities of Q.> Given vast computing resources, the new model was able to solve certain mathematical problems, the person said on condition of anonymity because they were not authorized to speak on behalf of the company. Though only performing math on the level of grade-school students, acing such tests made researchers very optimistic about Q’s future success, the source said. reply lucubratory 8 hours ago",
    "originSummary": [
      "OpenAI researchers have raised concerns about a powerful AI algorithm called Q* that has the potential to be a major breakthrough towards achieving artificial general intelligence (AGI).",
      "The letter and discovery of Q* played a role in the removal of CEO Sam Altman, as the board had concerns about commercializing advancements without fully understanding the implications.",
      "The capabilities of Q* have not been independently verified, and as a result of Altman's firing, over 700 employees have threatened to leave and join Microsoft."
    ],
    "commentSummary": [
      "The conversation delves into a variety of topics regarding AI advancements, primarily focusing on the capabilities and limitations of current language models in solving math problems.",
      "The integration of intuitive math understanding into AI systems and the challenges of reasoning and problem-solving capabilities are discussed.",
      "The importance of human expertise alongside computational power, the potential risks of AI breakthroughs, and the ongoing debate on AI's ability to reason and grasp complex problems are also explored."
    ],
    "points": 758,
    "commentCount": 835,
    "retryCount": 0,
    "time": 1700694458
  },
  {
    "id": 38380137,
    "title": "VMware Joins Broadcom, Offering Enhanced Support Portal",
    "originLink": "https://www.broadcom.com/info/vmware",
    "originBody": "BroadcomSkip to main content Support Portal Go To PortalRegister Forgot Username/Password? English 日本語中文",
    "commentLink": "https://news.ycombinator.com/item?id=38380137",
    "commentBody": "VMware is now part of BroadcomHacker NewspastloginVMware is now part of Broadcom (broadcom.com) 373 points by tonoto 18 hours ago| hidepastfavorite250 comments xyst 14 hours agoVmware changing hands between corporate overlords like it’s hot potato.VMware under EMC $625M acquisition lasted ‘04-‘15Dell acquires EMC for $58B in ‘15 which includes previously acquired VMware.Now Dell is trying to balance their books and sells entire stake of VMWare in ‘21.Broadcom now picks up the pieces of VMware with acquisition completed this year (‘23).I wonder which corporate overlord will take it over in the next 4-5 years.Maybe Oracle or MS will be the next to bag hold. reply tw04 13 hours agoparent>I wonder which corporate overlord will take it over in the next 4-5 years.There will be no next. Broadcom will get blood from the stone, rest assured. They will continue to raise maintenance and licensing fees until they very last customer turns off their last ESXi box. If you think IBM and mainframe is bad, you&#x27;ve never lived with a technology that Broadcom has acquired. reply MrDrMcCoy 13 hours agorootparent100%. I still have contacts from when I worked there, and It&#x27;s worse than feared. Everything is on fire and all the best engineering&#x2F;support talent has either left or is leaving. Broadcom is not only raising prices, but is set to deliver considerably worse products. It makes me sad, because it was once an incredible place to work. Now I recommend that people avoid them like the plague. reply raincom 5 hours agorootparentprevMaybe, Broadcom&#x27;s strategy is &#x27;to raise maintenance and licensing fees until they very last customer turns off their last ESXi box&#x27;. Broadcom spent $69B to acquire VMWare. They just need to squeeze blood for another 10 years.VMware&#x27;s revenue for 2022 is $13B, and net income about $1.8B. Trim sales department, remove duplication(HR, IT, etc), cut down development, remove many make-work projects that the middle management engages in, increase licensing&#x2F;support cost. They will focus more on net income, financing costs for $69B will be taken care of by layoffs and other stuff. reply snapplebobapple 5 hours agorootparentprevPretty much this. I wish proxmox would get off their butts and release a better management setup to deal with multisite, as I would love to complete the move to their product for our last remaining vmware systems. reply iforgotpassword 2 hours agorootparentprevTbh I was really surprised how Workstation still got major updates after that news from 2ish years ago where they fired the whole team working on that and moved its development to India . It already seemed like they wanted to focus on the core business of ESX and switch workstation to maintenance mode, but no, we for example got major improvements in 3D pass-through, like Vulkan and d3d10&#x2F;11 support. reply FirmwareBurner 1 hour agorootparentSimple: there&#x27;s devs in India who can code well and not every Western developer is an irreplaceable John Carmack so not every offshoring story ends badly. reply lokar 11 hours agorootparentprevThey have actually been pretty open that this is the plan. And all the secondary products and small customers can wither away even faster. reply Spooky23 7 hours agorootparentprevYup. Broadcom is the CA of our era. reply worewood 50 minutes agorootparentLiterally, since they acquired them. reply thedougd 7 hours agorootparentprevYes, and they even bought CA. reply mergy 7 hours agorootparentCA = Computer Associates for the youngsters. reply elbear 1 hour agorootparentThank you! reply rr808 5 hours agorootparentprevWeird I used to use broadcom chips decades ago. My new job uses Autosys - by Broadcom wtf? reply unethical_ban 6 hours agorootparentprevOh God... that&#x27;s what the CA in CA Spectrum was?One. NEW. CRITICAL. Alarm. reply notacoward 11 hours agorootparentprevIBM? Try EMC or Cisco. I ended up at the former by acquisition; many friends ended up at the second likewise. AFAICT they both have much worse records of turning acquisitions into abandonware than IBM does (not that IBM&#x27;s is great). Oracle and Microsoft have already been mentioned, but Intel deserves a place on that horrible list too. Tech has been full of such fat and lazy predators for a long time. reply rammer 9 hours agorootparentAnother perfect example of a large company acquiring and killing the support and the product is Intuit\"s acquisition of Tsheets.And more recently the working progress which is Intuit&#x27;s acquisition of MailChimp. reply steve1977 1 hour agorootparentprevEMC already had their go at VMware ;) reply manicennui 11 hours agorootparentprevIs there a single large tech company that doesn&#x27;t fuck over the customers of their acquisitions? reply phyrex 8 hours agorootparentMeta&#x2F;Facebook. Look how instagram, WhatsApp, and oculus are doing. Even the stuff they ended up abandoning they cleaned up and open sourced (like Parse) reply freedomben 7 hours agorootparentMeta really doesn&#x27;t get enough credit for their open source contributions and stewardship of important tech. Of course there are very real criticisms of Facebook and their engagement strategies and such, but LLaMa has been incredible, on top of things like React of course. reply to11mtm 7 hours agorootparentprevIronically...Yeah. They have done a better-than-most job of trying to default to open (for all of their other failings) reply ronsor 11 hours agorootparentprevAs of late, probably Microsoft does it the least, unintuitively enough. reply hosteur 10 hours agorootparentMinecraft users would disagree. reply actionfromafar 10 hours agorootparentI just left my account to die, can&#x27;t even be bothered to try to convert it to MS. It&#x27;s dead, Jim. reply pulse7 10 hours agorootparentprevAs a last resort, they can use TLauncher... reply doublepg23 8 hours agorootparentprevEh, Bedrock is a much easier sell to my friends than Java was back in the day. Even the least technical manage to play together. reply iforgotpassword 2 hours agorootparentRemember when two decades ago even the dumbest kid could figure out how to punch an ip address into teamspeak and CS1.6? reply jamesdwilson 10 hours agorootparentprevTeams enters the chat. reply mcmcmc 10 hours agorootparentNew Teams is actually much better imo. The way they’re murdering Outlook though… reply vasili111 9 hours agorootparentI think it is matter of who it used to what. I was working with web version of Outlook for a long time and loved it. Now I am forced to use old one and hate it. reply johnvanommen 29 minutes agorootparent> I was working with web version of Outlook for a long time and loved it.As I understand it, web Outlook pioneered numerous browser innovations that we take for granted now. reply ghosty141 3 hours agorootparentprevNow I just need that on linux… They even killed the linux app and just want you to use it via prog. Webapp. Its awful. reply cuddlyogre 3 hours agorootparentprevOutlook gets my eternal disdain because it still does not understand HTML written after 2006.It&#x27;s so bad, we have a dedicated email HTML person. reply SahAssar 9 hours agorootparentprevTeams was built in-house, right? Whose existing customers did they fuck over? reply miked85 7 hours agorootparentTheir own. reply SSLy 11 hours agorootparentprevHPE? reply crest 10 hours agorootparentThey even fuck over their own customers by locking away documentation and firmware updates behind a support contract paywall. reply pjmlp 2 hours agorootparentSadly, I have wasted many hours reading HP-UX documentation, and also hunting the Modula-2+ and Modula-3 papers, as per Compaq and DEC Olivetti acquisitions. reply johnvanommen 26 minutes agorootparentprev> They even fuck over their own customers by locking away documentation and firmware updates behind a support contract paywall.I used to work for HPE on their OpenStack team, and getting support, even as an employee, basically required me to have a rolodex full of engineers all over the world. A tremendous amount of troubleshooting was just looking up who had committed code, then tracking them down when something blew up. reply xyst 13 hours agorootparentprevNever heard of Broadcom. Are they like the private equity of tech? Kind of sounds like it. reply jacquesm 7 hours agorootparentBroadcom is the reason there are a few hundred drivers for minor variations of the networking chipset in your laptop, each of them incompatible with all of the others. reply megous 11 hours agorootparentprevBroadcom is chip maker for Raspberry Pi, among many other things, that&#x27;s the one most people here probably will recognize it for. reply pavon 12 hours agorootparentprevBroadcom was essentially bought by a private equity firm who took the name as the name of the umbrella corporation.Before that Broadcom was (and still is) one of the larger communication hardware companies, making chips for cell, wifi, bluetooth, ethernet and ARM SoCs, along with telecom and data center boxes that used these chips. You almost certainly have their hardware in some device you own. But they have always had difficulty competing with Qualcomm, arguably in part due to anticompetitive behavior from the later.After the acquisition, they have been acquiring enterprise software companies to diversify, including CA Technologies (think Atlassian&#x2F;Oracle of the mainframe world), Symantec, and now VMWare. reply dredmorbius 4 hours agorootparentI had totally missed CA being bought by Broadcom.Given that CA already had the reputation of \"where software goes to die\", this is ... bad news for VMWare. (I&#x27;d heard that description from many in the tech field, including from a CEO who&#x27;s previous venture had been acquired by CA.)I also hadn&#x27;t realised that Broadcom itself had originated at HP. reply antod 7 hours agorootparentprevWow, I didn&#x27;t know that. They even Computer Associated Computer Associates. That is like an exponential vortex of suck. reply gpvos 1 hour agorootparentMaybe they absorbed a bit too much of CA culture. reply barkingcat 8 hours agorootparentprevwikipedia has a great article on broadcom - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;BroadcomIts history goes back to the 1960&#x27;s. It is a major semiconductor company that I would say, was part of the ecosystem that made computers and networks possible.You haven&#x27;t heard of them because they make too much of everything that makes the fabric of everyday computing.It&#x27;s like how you would never really know of the company who made the pipes for your toilet&#x2F;plumbing. reply swiftcoder 2 hours agorootparentprevThe mostly specialise in network adapters and low-performance mobile chipsets - the cheaper Kindle tables and Fire TV boxes all ran on broadcom. reply SV_BubbleTime 12 hours agorootparentprevYou almost certainly have Broadcom in your pocket. reply latchkey 11 hours agorootparentThese bits absolutely traveled through a Broadcom NIC. reply zaat 6 hours agorootparentSome other bits were silently discarded by same Broadcom NIC, no particular reason given and no event wasn&#x27;t registered reply Cyph0n 11 hours agorootparentprevAs someone who worked on SP routers at Cisco - yes to the above. reply ikiris 10 hours agorootparentprevMuch to the regret of anyone trying to manage them.Cheap is nice, but I miss the days when chips did things you wanted. reply factormeta 10 hours agorootparentprev>They will continue to raise maintenance and licensing fees until they very last customer turns off their last ESXi boxhmm, why would people still use VMWare? Honest question. Maybe there are some licensing issues I&#x27;m not aware of. Isn&#x27;t vbox open source? If not, wouldn&#x27;t even things such as https:&#x2F;&#x2F;copy.sh&#x2F;v86&#x2F; in the browser would do most virtualization trick now days? reply barkingcat 10 hours agorootparentmost people don&#x27;t use vmware the way you use virtualbox.The money making part of vmware licensing is the baremetal hypervisor ESXi, the competitors are xen or hyperv and the likes.The lock-in part of vmware is the vsphere management software, that allows you to move VM&#x27;s en mass from one baremetal machine to another baremetal machine, or allows you to nest vm&#x27;s, etc. manage your entire fleet of vm&#x27;s which could be thousands or hundreds of thousands of virtual machines, from one management interface.it&#x27;s basically docker except it&#x27;s actual entire vm&#x27;s being moved around. VMWare ESXi being a baremetal hypervisor means you can run different OS&#x27;s on top of these vm&#x27;s and imagine being able to move these VM&#x27;s all running different OS&#x27;s around in your ecosystem.That&#x27;s what people pay the big bucks to vmware for.It would be very difficult to build the vsphere&#x2F;esxi ecosystem with pure opensource tools (it&#x27;s possible with Xen, etc) but you&#x27;d be right back at paying some vendor a massive amount of money for building, integrating, and supporting this kind of system. (Redhat will happily sell you something that approximates vmware&#x27;s tools, for megabucks).As an aside, the consumer \"vmware\" software that you install on your workstation is such a small portion of their business, they basically spend no money on fixing&#x2F;upkeeping. Apple silicon support was in beta for a loooong time, and they don&#x27;t actually care about their workstation product. ESXi makes the money. reply scottjg 9 hours agorootparenti don&#x27;t know what the penetration of it looks like, but on the vsphere&#x2F;esxi side there are also a number of really expensive addon features that i have not seen reproduced in open source software.1. vmotion + storage vmotion - you can live migrate a vm from one hypervisor host machine to another. you can also live migrate the underlying storage (good if you want to consolidate storage servers, rebalance disk load, etc). with some caveats, you can do all of this without any downtime in the vm. it&#x27;s not just a simple suspend on one host, resume on another host. a memory snapshot is migrated while the vm is still running on the first host, and when the amount of dirty pages starts to converge, they flip the vm over to the new host. similar idea for storage vmotion.2. fault tolerance - for single cpu vms, you can use vmware&#x27;s record-replay technology to execute a secondary vm in a \"shadow\" mode which replicates all of the nondeterministic events across the network. if one hypervisor host dies, the other can take over with no downtime. this is great when you need to add HA for a legacy application.3. vsan - generally you run these systems with some sort of shared storage (nfs or iscsi attached SAN, or something like that). a SAN can be really expensive and a single point of failure. vmware can create a \"virtual san\" from a cluster of your esxi hypervisor hosts. as you can imagine, it has all sorts of HA features and can rebalance workloads to improve performance.there are more, but that&#x27;s just a few interesting features. reply edwintorok 59 minutes agorootparentMemory and storage live migration across hosts and pools is possible with Xen too.See VM.pool_migrate and VM.migrate_send https:&#x2F;&#x2F;xapi-project.github.io&#x2F;xen-api&#x2F;classes&#x2F;vm.html. Those features got introduced in Xenserver 4.0 (2007) and 6.1 (2012).Disclaimer: I work at XenServer. reply katbyte 3 hours agorootparentprevFair bit of that can be done with Proxmox now. What esxi has going for it from what I hear is the ability to deal with 100&#x2F;1000s of hosts over many many nodes and Proxmox struggles with that reply lima 8 hours agorootparentprevQEMU&#x2F;libvirt can live migrate VMs without downtime. It works the same way. reply everfrustrated 2 hours agorootparentVMware was doing live migration since 2002. Open source reimplantations are relatively recent. reply erkkie 7 hours agorootparentprevYep, happily using https:&#x2F;&#x2F;ganeti.org&#x2F; and KVM live migrations - mirrors across hosts. reply snapplebobapple 5 hours agorootparentcan you speak to how that is vs the gui web interface goodness of proxmox? I&#x27;m interested in playign with ganeti but all the youtube walkthroughs that would motivate me more are super outdated and the website doesn&#x27;t really sell the product very well. reply ikidd 5 hours agorootparentprevYou might be surprised how much of this the free Proxmox, running Qemu on Debian, can do. reply redundantly 7 hours agorootparentprev> vsan... a SAN can be really expensive and a single point of failure.In every scenario that we spec&#x27;d out vSAN for production use it came in at least two times as expensive as your average dual controller, HA capable, storage array.vSAN pricing is absolute nonsense. reply mgiampapa 7 hours agorootparentvSAN pricing is all about what the sales guy is willing to do to make the rest of the sale. It has zero marginal cost if they can get you on the platform and using their ecosystem of tools and software.In edge deployments where rack space is tight it&#x27;s actually a great solution if you only have a few U to work with and have a HA requirement for a legacy app as well. reply barkingcat 9 hours agorootparentprevgood mention of the replay feature! I haven&#x27;t used that before, but that sounds like something that they could sell for a lot of money and companies would want to buy that feature. reply kbenson 4 hours agorootparentprev> Redhat will happily sell you something that approximates vmware&#x27;s tools, for megabucksActually, no, they apparently won&#x27;t, because I tried and was told they are discontinuing that product. They are going full steam on their OpenShift (k8s) product though, and will be happy to inform you that you can run a VM on that, but if you press them you&#x27;ll find that you&#x27;re actually running a VM in a container, and that you have to specify it as a k8s deployment, so apparently you can&#x27;t just throw a VM up like you can in vCenter. reply lsllc 10 hours agorootparentprevIt&#x27;s ESXi, the server class stuff, not so much the desktop VMware. So many companies have been using it for years. Now Broadcom are wanting to install spyware to \"track\" usage and license compliance and they&#x27;re raising prices. For a lot of orgs, it&#x27;ll probably take several years to move the production systems to something else.For the desktop, VirtualBox isn&#x27;t much better. At one point after Oracle purchased it, they were tracking your IP and if they found you were using their extension pack that provides essential capabilities like USB 3 support (only the core of VirtualBox is GPL) and it was for commercial use, they were hitting you up for a license [0].[0] https:&#x2F;&#x2F;www.theregister.com&#x2F;2019&#x2F;10&#x2F;04&#x2F;oracle_virtualbox_mer... reply nunez 9 hours agorootparentprevNearly every company&#x2F;public service&#x2F;non-profit&#x2F;whatever uses vSphere&#x2F;ESX somewhere. You&#x27;d be (very) surprised to see where people shoehorn ESXi hosts. VMware is EVERYWHERE, and vSphere&#x2F;ESX&#x2F;NSX is still the best game in town if you want to virtualize your datacenter. It&#x27;s insanely rock-solid tech. reply ocdtrekkie 6 hours agorootparentYep. Arguably if you have Windows licensing, Hyper-V will do mostly all the same stuff \"for free\", but only if you want your hypervisors to be exactly as reliable as Windows machines. If you&#x27;re rolling VMware, your datacenter&#x27;s backbone tends to be ridiculously solid.Think servers with four digits of days of uptime, in terms of things you probably shouldn&#x27;t do, but absolutely can. reply c0pium 6 hours agorootparentThat’s not actually different on the Windows side, you should update your priors. There are datacenters full of Server 2019 boxes that have never been upgraded because the guest VMs are mission critical.Source: I’ve responded incidents on those guests. It’s terrifying, but hypervisor uptime is limited by power not OS choice. reply jiggawatts 28 minutes agorootparentI&#x27;m the other \"pro Microsoft guy\" here on HN, but I have to agree with the GP comment: VMware stability puts Microsoft to shame.These days Windows is stable if you don&#x27;t touch it.VMware is stable even if one of the disks is out of space, the fibre is flapping, some idiot misconfigured the switches, and the whole cluster has time out of sync... by seven hours.That&#x27;s not hyperbole, that&#x27;s an actual cluster that I got given to look after. It was running like that for months, perfectly fine, with VMware HA just \"taking care of things\".If you sneeze in the direction of a Windows Failover Cluster it&#x27;ll... fail. reply pavelstoev 5 hours agorootparentprevAgreed. I have 20+ Hyper-V Windows Server VMs running since 2017, seeing 400-600 Mbps live video traffic - no major crashes, only due to facility power loss or annual patching reboots. reply ocdtrekkie 4 hours agorootparentprevI mean, I work with every version of Windows Server since 2012 R2 up through Server 2022 on a daily basis... reply c0pium 3 hours agorootparentNo you don’t. It’s ok, just take the L. replyhsbauauvhabzb 10 hours agorootparentprevEdit: the following statement is incorrect and retracted: ‘Virtualbox is not free for commercial use iirc’Esxi is an enterprise product which engineers are familiar with, the cost of the product vs the cost of migration and upskilling in alternative tech should not be underestimated, particularly when it’s the thing that runs all your other things.Edit: in case you’re not aware, many organisations still leverage on-prem virtualisation technologies - that might not be obvious to people that haven’t seen it. reply p3n1s 10 hours agorootparentVirtualbox is GPL licensed. Only the extension packs are non GPL. In any case virtualbox competes with VMWare player&#x2F;Workstation&#x2F;fusion which we all should know is not their core business. reply stephenr 7 hours agorootparentprevAs explained by others the parent comment is talking about ESXi, but to answer your question: virtualbox desktop hypervisor is the spam of desktop hypervisors.Everyone has heard of it, it&#x27;s theoretically comparable to the likes of VMware&#x2F;Parallels desktop hypervisors, and it&#x27;s cheaper. But just like spam (compared to ham), it&#x27;s also obvious to anyone that&#x27;s used both that it&#x27;s by far the worse option, and there&#x27;s very few reasons to use it besides cost, while there are numerous reasons to use one of the better alternatives.In general, performance is significantly better with other hypervisors, but in particular shared filesystem performance (ie sharing a directory from the host OS into the guest) and features are lacking on virtualbox.It&#x27;s the default provider used by vagrant, and even the vagrant team recommend using a different provider for \"any serious work\". reply fencepost 4 hours agorootparentOne caution: SPAM isn&#x27;t actually cheaper than ham, it&#x27;s just shelf stable without refrigeration. You can get a decent spiral ham for well under $3.29&#x2F;lb (Costco earlier today), but 12oz cans of SPAM work out to around $5&#x2F;lb. reply stephenr 3 hours agorootparentI don&#x27;t know if it&#x27;s just a demand thing or perhaps because I don&#x27;t really know what \"spiral ham\" is, but in Australia the only ham you&#x27;re likely to find cheaper per-kilo than spam is going to be a 2+ kg leg of ham, complete with bone, fat, skin, etc. A boneless ham will be at least as expensive, and sliced&#x2F;shaved ham from the deli section at a supermarket will be easily more expensive per-kilo than spam.Of course one could argue there&#x27;s an even higher percentage of inedible parts in the canned monstrosity because it&#x27;s all inedible, and I wouldn&#x27;t argue that view point is wrong. replylocusm 7 hours agoparentprevProxmox and XCP-NG are well placed to take their customers and gradually add any missing functionality. Although neither have feature parity with VMWare they are adding new things all the time and are very responsive to their respective communities. XCP-NG even has a VMWare to XCP migration tool built in. However, in my experience using both I would avoid Proxmox specifically if your workloads include heavy SQL Server &#x2F; Exchange usage. The bug in question affects all KVM based solutions. reply stephen_g 5 hours agorootparentYeah, I was only ever a ‘casual’ ESXi user (we only ever had a couple of hosts and two dozen or so VMs, and nothing super mission critical), and I’m amazed at how good Proxmox is now we’ve started using it instead of ESXi given the Broadcom acquisition.Obviously if you’re running dozens of hosts and thousands of VMs, needing live migration and things like that, then it’d probably be missing a lot of features you’d want, but for smaller stuff it’s pretty crazy how well it works. reply locusm 3 hours agorootparentLive migration works very well on both local and shared storage. Both products also have a hyperconverged solution if you like that sort of thing. reply ikidd 5 hours agorootparentprevIt live migrates fine. Done it many times to upgrade cluster nodes, moving live VMs back and forth. reply scandox 9 hours agoparentprevThey&#x27;re picking up the pieces for 69 billion. Your analysis makes it sound like VMWare is falling apart. Going by price it suggests it is going from strength to strength no? reply jacquesm 7 hours agorootparentThat price is a reflection of future financial potential, not of commercial success. Very few people would pick VMWare for new stuff today unless it is a large on-prem installation (and there are still plenty of those). But they are past their peak and the bulk of recovering that will come from existing customers, not from new ones. You lock yourself in to anything related to Broadcom at your peril. reply steve1977 10 hours agoparentprevI don’t see MS having any interest in VMware. They have their own virtualization tech already and it would only cannibalize Azure, which seems to be pretty much were their money is now. reply brirec 10 hours agorootparentWhile I agree Microsoft probably doesn’t want to buy VMware, they absolutely have a pretty strong “hybrid cloud” solution, which basically means running an Azure hypervisor on your on-prem servers.Really it’s just Hyper-V with extra “cloud management” bits (“Azure Arc” and friends), but it’s _relatively_ friendly to manage alongside your Azure cloud resources once you set it up.Bottom line is, I really don’t think they’re worried about on-prem hypervisors competing with Azure! reply steve1977 1 hour agorootparentYeah that&#x27;s kind of what I was about (though probably not worded very well). For the on-prem virtualization use cases they are interested in, they already have the necessary technology with Hyper-V.I actually thought that vSphere offers some stuff in the hyperconverged area that Hyper-V doesn&#x27;t, this is where I could see it competing with Azure. However it seems Hyper-V with Storage Spaces Direct seems to be pretty much on par, at least on paper.So there&#x27;s even less reasons why MS would be interested in VMware. Only maybe to get rid of a competitor. reply strangemonad 9 hours agoparentprevNot to mention Pivotal interwoven into that story reply AlphaSite 4 hours agoparentprevIt’s impressive how they’ve effective paid 81 billion for vmware, arguably making it the largest tech acquisition in history. reply whalesalad 11 hours agoparentprevLike the village bicycle - everyone has taken it for a ride. reply woleium 5 hours agoparentprevand each subsequent owner stripmines the company for the IP (patents) they desire. reply api 12 hours agoparentprevThere’s a market out there for a very well designed turn key cloud with things like managed Kubernetes and Postgres you can deploy on bare metal or cheap VPSes. Too bad they aren’t looking at that. They have plenty of expertise and some of the software pieces already developed.I bet the problem is that they are too “enterprise” and couldn’t price it low enough. If it were too expensive it wouldn’t be competitive with big cloud managed offerings. reply UtahDave 8 hours agorootparentVMware does have managed kubernetes reply 3seashells 13 hours agoparentprevSays something about value vs evaluation? reply saltminer 18 hours agoprevWe are already seeing the squeeze from this. We have recently been informed they are dropping their academic list pricing entirely, which will cause many institutions to pay double or even triple what they do now. As a result, several major universities (specifically the Big Ten but I&#x27;m sure many others are as well) are looking into alternatives to reduce license costs ahead of next year&#x27;s contract negotiations.Source: Someone higher up in my department. reply rf15 14 hours agoparentEven by the standards of blind corp greed, that&#x27;s a bad move - you want people to know your platform when they&#x27;re done studying, so they can advocate for it in their jobs. Why would you destroy this revenue stream? Unless they have no longterm vision for VMware and just want to bleed it dry as quickly as possible. reply phpisthebest 14 hours agorootparentBroadcom looks at Orcale and says \"Can I have some of that business model please\"...They exist on legacy vendor lockin, and will milk customers until there is nothing left, which will take decades or more reply NikolaNovak 13 hours agorootparentBut to me, Oracle is the canonical example of getting nerds while they&#x27;re young.In university, I had access to Oracle databases, Oracle manuals, Oracle Linux, etc. Not through some special university approved lab set up - I could just go and download them. Even their acquired software like PeopleSoft etc.I had NONE of that for DB2 or AIX, for example.And their respective market share, I believe based on no evidence but strong belief, belies that strategy.(disclaimer, I guess - I work for IBM, but ironically as an Oracle consultant... the early access really did work :-) reply phpisthebest 13 hours agorootparentMany people have talked about this...People do know that oracle has ALOT more software then their DB right?I mean their DB is the least vendor lockin thing they sell..... reply NikolaNovak 10 hours agorootparentYes, as I said, I spent much of my life around oracle products. Most are freely downloadable for non production purposes. reply tsimionescu 13 hours agorootparentprevAny student can download and use Oracle DBs and most other products for free legally right from Oracle&#x27;s sites. This suggests that even Oracle understands how important this pipeline is. reply dehrmann 6 hours agorootparentprevThis is different. Most student won&#x27;t be exposed to datacenter management. It&#x27;s really just system administrators who see this. reply ocdtrekkie 6 hours agorootparentVMware is literally taught in schools. My college has a two course program in it. reply callalex 5 hours agorootparentThat’s still entirely independent of what the school’s mainframes run on. reply sturadnidge 10 hours agorootparentprevI always thought of Sun as the canonical example of this… why did all the dotcom era startups burn so much cash on Sun hardware? Because that’s what was in the Universities!But on the other hand, look at how that turned out :( reply warriormonk5 14 hours agorootparentprevYeah that&#x27;s the idea. They hold corporations hostage that are slow to move and increase prices. reply rrdharan 13 hours agorootparentAnd it’s entirely plausible they make enough money from that to buy the next VMware in another decade or so to repeat the cycle. Sustainable bottom feeding as a strategy. reply mschuster91 12 hours agorootparentprev> you want people to know your platform when they&#x27;re done studying, so they can advocate for it in their jobs. Why would you destroy this revenue stream?That was how Adobe ran for a looooong time, up until and including CS6. They didn&#x27;t give a f..k about piracy beyond something that could trivially be circumvented by a keygen and a few well-placed &#x2F;etc&#x2F;hosts entries, and that was what made them the utterly dominant power in anything creative - people were used to years of working with Photoshop (a friend of mine started with photography at age 13!), and so they demanded from employers that they use Photoshop. Incidentally, that also was what kept Apple afloat before the iPod&#x2F;iPhone days - Adobe stuff just worked fine on Apple hardware but was a nightmare on Windows, so people also demanded Macs for their work.The advent of CC came once Adobe had achieved that lock-in and started milking its customers for all they were worth, and additionally they opened up a load of legitimate customers as well who didn&#x27;t feel like dropping a few grand on Adobe stuff but who cares about 50$ a month? reply brohoolio 14 hours agoparentprevVMware is notorious for continuously changing SKUs and licensing models to make things more expensive. I would suspect that Broadcom will continue putting the squeeze on customers. If hyper-V (or whatever it&#x27;s named now) was a viable alternative, I suspect you&#x27;d see tons of folks fleeing VMware. reply baq 13 hours agorootparentAzure runs on basically hyper-v I hear (which would make sense, right?), so it can&#x27;t be that bad? reply csydas 12 hours agorootparentHyperV has been overlooked by Microsoft for awhile in favor of Azure. You can get a basic HyperV host up and running pretty easily (even for free with the Core edition), but I would not call it great. My experience with HyperV is not a pleasant one as it struggles a lot and the error messages are often extremely cryptic. Similarly, there are some pretty outstanding bugs that existed for years that Microsoft didn&#x27;t bother to fix -- for example, since HyperV 2019, there has been an impactful RCT bug† that can be triggered if you upgraded your HyperV hosts in a specific path (2016-2019) and any backup solution used HyperV&#x27;s RCT. The result of the bug is extremely poor performance on any VM using RCT. Supposedly there was a patch last or this month that addressed it, but I&#x27;ve not heard any positive news from clients about this patch. Nevermind that Windows updates have frequently broken core HyperV functionality (as recent as December 2022 there were bugs where you couldn&#x27;t start Virtual Machines or even create new ones due to bad Windows updates)From my perspective, Microsoft doesn&#x27;t want to deal with HyperV anymore, they want your machines up on Azure. I&#x27;d actively advise against HyperV simply because I don&#x27;t see that Microsoft cares about on-premises.† RCT == Changed Block Tracking for HyperV, basically faster backups by allowing the backup application to know exactly which blocks of the virtual disks have changed since the last backup and the backup application can do fast incrementals via this means. reply SahAssar 9 hours agorootparentAzure runs on a modified HyperV, right? Or are you saying they are using some other hypervisor there? reply csydas 4 hours agorootparentit does but i cannot tell why the azure performance is so different than on premises hyperv. i simply don’t know but the issues i’m describing here afaik did not affect azure instances. i do not know why but i thjnk it means there is a difference between on premises hyperv and azure hyperv or they do something to ensure the same issues don’t affect azure instancesbut i simply don’t know why there is a differenceedit: if you search “hyperv rct bug” you will find forum posts fasts showing the timeline of this issue lasting years and many clients complaining that microsoft would not even acknowledge the issue publicly (or even in ms support cases) until very very recently reply stephen_g 5 hours agorootparentprevWell there’s a difference between a hypervisor and the infrastructure around it - even if they use the same hypervisor, it’s very likely that the rest of the system is completely different. reply nunez 9 hours agorootparentprevHyperV is fine for the basic stuff, but it&#x27;s missing a lot of the other stuff that makes ESX so appealing (no direct vSAN or NSX equivalents, and you _need_ Windows to run Hyper-V vs ESX supporting liveboot on USB or CD). Also, I think ESX VMs are way faster than HyperV ones, but it&#x27;s been a few years. reply patmorgan23 8 hours agorootparentIsn&#x27;t Storage Spaces Direct an equivalent to vSan? reply merlyn 3 hours agorootparentStorage Spaces Direct is a sure plan to have data loss. Such a piece of %#( reply yjftsjthsd-h 13 hours agorootparentprevThere&#x27;s bad tech, there&#x27;s bad user&#x2F;admin experience, and there&#x27;s bad licensing&#x2F;costs. They might just mean that ex. the costs are awful, which I expect Azure wouldn&#x27;t care about. (Disclaimer: I haven&#x27;t used hyper-v, I don&#x27;t know if any of these apply) reply depereo 14 hours agoparentprevThey&#x27;re pulling entirely out of some countries, too, so here in New Zealand they&#x27;re apparently going to send comms on the 27th, have a seven day &#x27;consultation&#x27; and then probably give everyone the date they don&#x27;t have a job. reply jetbalsa 10 hours agoparentprevI&#x27;m in the process of trying to convert to openstack at my university. but so far its been slow going. I&#x27;ve got a few smaller clusters online currently running it reply jbverschoor 13 hours agoparentprevMigrate to proxmox.. it’s great reply NexRebular 11 hours agorootparentor to MNX Triton or vanilla SmartOS, they&#x27;re the greatest. reply MrDrMcCoy 9 hours agorootparentHow is MNX Triton, a public cloud offering, an alternative to an on-prem, private cloud solution?I&#x27;m sure that SmartOS is great, but being based on Illumos, I&#x27;d be hesitant to switch. Illumos doesn&#x27;t have the most expansive community or hardware support as far as I know. reply NexRebular 9 hours agorootparent> How is MNX Triton, a public cloud offering, an alternative to an on-prem, private cloud solution?By doing on-prem private installation of it [0]. Support contract is not necessary. We run illumos on HPe hardware from Gen6 to Gen10 and there are no issues. Even have GPU compute going via passthrough to ubuntu bhyve HVM.[0] https:&#x2F;&#x2F;docs.tritondatacenter.com&#x2F;private-cloud&#x2F;install reply MrDrMcCoy 5 hours agorootparentNow this is very interesting and I&#x27;m excited to read up on it. Thanks for the link! reply unethical_ban 6 hours agorootparentprevHow does it compare to Proxmox, if you don&#x27;t mind? Both seem to have distributed VM and storage and VM&#x2F;CT support, software network support... if Triton has better SDN I may be interested in it.I remember taking a quick hobbyist look at JoyentOS or something like that about five years ago, but I thought the project died... I&#x27;m shocked to hear it&#x27;s still alive. reply SV_BubbleTime 12 hours agorootparentprevWithout knowing almost anything about it, I run Proximo on a box at home.Is it at all comparable to ESX?I kind of assumed the Proxmox was just the free and cheap and bare bones option. reply ThinkBeat 11 hours agorootparentIn terms of features, they match on the simple &#x2F; broad features. When it comes to scale, reliability, defined compatibility, and supporting tools that is a big no.I have worked on VMWare stack in previous jobs. but I run proxmox at home now.Free ESXi without VMware tools is somewhat harder actually. Still far better reliability. reply linuxftw 12 hours agoparentprevI think it&#x27;s a pretty smart move. Educational institutions don&#x27;t have the engineering capacity to change their datacenters overnight. They&#x27;ll be paying the higher fees for years to come. reply notesinthefield 5 hours agorootparentWe certainly dont. Though half our infra was already on Hyper-V anyway. Lets hope MSFT is watching and wants to put effort into HVS. reply dangerboysteve 14 hours agoparentprevXCP-NG reply smegsicle 14 hours agorootparenti thought i heard kvm was winning, is there still a good reason to go with xen? reply thinkyfish 7 hours agorootparentThe tooling is really mature. Amazon used xen for ages. kvm wins for hardware passthrough and performance, but if your willing to sacrifice a little performance the advanced admin features are competitive. reply remir 10 hours agorootparentprevXCP-NG + Xen Orchestra is a winning combo. If I had a large VM infra, that&#x27;s the stack I would select. All open source too! reply dangerboysteve 13 hours agorootparentprevAll are good choices. reply stock_toaster 13 hours agorootparentprevor proxmox reply AtlasBarfed 14 hours agoparentprevSo ... for the corp&#x2F;academic crowd, what is it VMWare does that VirtualBox doesn&#x27;t do?I don&#x27;t understand orgs that deal with companies with a loooooonnnnnngggggg history of predatory pricing and sales shenanigans and not have active mitigation plans.Who has Oracle that isn&#x27;t actively planning going to Postgres or MariaDB? Of course I&#x27;d say the same thing for IBM in the 1970s, Microsoft in the 1990s, and AWS today.VMWare obviously has a lot of the same. reply NikolaNovak 13 hours agorootparentFirst, VirtualBox is an Oracle product, so I&#x27;m not sure which side you&#x27;re advocating :)More to the point, I think VirtualBox is the equivalent, broadly, of VMWare Workstation&#x2F;VMWare Player; which is a specific individual product that runs on desktop as type 2 hypervisor and a teeny tiny bit of the broader VMWare ecosystem (probably neglible part of their revenue).I don&#x27;t know if VirtualBox has any product or share in server&#x2F;datacentre space? Whereas, VMware is absolutely positively huge. The core ESXi product, sure; but again the ecosystem around it, from vSPhere&#x2F;vCenter to vRealize and Orchestrator and nsx and vSan and everything else, the management and automation flows are pretty well integrated (externally; I&#x27;m sure it&#x27;s a acquired&#x2F;developed mess internally as every other IT product ever:).It&#x27;s a bit like... I don&#x27;t know, \"what does Window Explorer have that File Commander doesn&#x27;t\"? It&#x27;s a valid question that has a rational answer which is useful for limited use cases, but it misses the very very big forest (Windows and Office and Azure etc) for very minor trees inside of itHope that helps a bit? reply wpm 13 hours agorootparentprevVirutalBox is a barebones type 2 hypervisor with only basic orchestration, backup, networking, management features, if any.ESXi and the VMWare products built on top of it (vCenter&#x2F;vSphere) are not even comparable to VB, other than that they both can run virtual machines. vSphere can move running VMs between storage or compute hosts without interruption, can failover between storage or compute, can failover between networking outages (thanks to virtual switches and the ecosystem of hardware support around it), and provides a platform for additional third party add ons for automated backups and recovery. Not to mention easy role based SSO access. My entire university&#x27;s infrastructure was virtualized on VMWare aside from a few domain controllers and the Netapp storage clusters it all ran on, and the equally large Linux&#x2F;KVM infrastructure and the HPC datacenter that ran a bunch of other stuff for...reasons (higher ed is fun). And as an added bonus, desktop type 2 hypervisors like Workstation or Fusion integrate perfectly into it. I used to manage a dozen Windows and Linux VMs straight from VMWare Fusion on my Mac and still do at home in my little VMUG cluster.It&#x27;s like comparing a Chevy Spark to an aircraft carrier, except you built an entire medium to large sized organization&#x27;s infrastructure on top of it. You can&#x27;t just switch overnight unless you want to stop making money for a while. For most orgs who can justify the already steep price, moving away from VMWare onto something else will mean multiple years long projects requiring thousands of person-hours to complete, redundant efforts (as the old stuff can&#x27;t just go away until the new stuff is battle tested), on top of probable hardware purchases since VMWare and its demands have shaped on-site datacenter spend, layout, and networking for years.The actual VMs are the easiest part to move since they are just some virtual disks and a config file. It&#x27;s all the other supporting stuff and high availability that need to configured and battle tested that will take forever. It&#x27;s not something you can plan to do ahead of needing to do it because doing so would mean doing the same job twice for years for a bet that you can&#x27;t just weather some higher costs for a year or two before you can move stuff onto cheaper platforms (and train&#x2F;hire for expertise). reply Stratoscope 13 hours agorootparentprev> what is it VMWare does that VirtualBox doesn&#x27;t do?For my specific use case, it&#x27;s display responsiveness.My main work machine is a ThinkPad X1 Extreme Gen 3. Our development environment is Ubuntu, so when I got the machine our IT guy had helpfully installed Ubuntu on it.There were two major problems though. I could only get my AirPods to pair as headphones, not as a full headset with microphone. And worse, I couldn&#x27;t get my triple-monitor setup to work at all. (The ThinkPad has a 15\" 4K display, and I use two 24\" 4K displays with it: one in landscape mode immediately above the ThinkPad display, another in portrait mode to the left.) I could only get two displays out of the three to come up.I did like the hardware quite a lot - I&#x27;ve been a huge ThinkPad fan for 25 years. So I immediately bought a similar machine for personal use. It came with Windows, and both of the above items worked \"out of the box\".So I looked at the bottom of the work machine and saw that it came with a Windows license. I downloaded the Windows 10 ISO from Lenovo and installed Windows on it, figuring I would run Ubuntu in a VM.I tried VirtualBox first, and it worked, but the display wasn&#x27;t smooth. For example, I often use the Windows key + left&#x2F;right arrow to move a window to one side of the display or the other. Ubuntu does a \"sliding\" animation when you do this, but it looked like it was only refreshing the display every tenth of a second or so.So I tried VMware and it was perfect. The display is just about as responsive as running Ubuntu on the bare metal - every transition and animation is perfectly smooth. reply RachelF 10 hours agorootparentI&#x27;ve had a similar experience.VMWare Workstation (desktop edition) is faster and more polished than VirtualBox.I&#x27;d like to try it all on top of ProxMox one day. reply blincoln 10 hours agorootparentprevVMware Workstation has much better USB support (especially USB NIC support) than VirtualBox.It&#x27;s also licensable individually. If you want to use the VirtualBox Extension Pack in a business environment, you need to buy a per-user license. It&#x27;s only $40, but Oracle has a minimum order quantity of 100, so you&#x27;re spending at least $4000.[1] i.e. in a business, for about 20-30 users, VMware Workstation is cheaper.[1] https:&#x2F;&#x2F;shop.oracle.com&#x2F;apex&#x2F;f?p=dstore:product:257141221156... reply jabroni_salad 13 hours agorootparentprevDoes virtualbox have an equivalent to VCSA? Can I failover a datacenter with it?virtualbox is pretty capable but I only view it as equivalent to vmware workstation. reply X-Istence 12 hours agorootparentNo, you can&#x27;t failover a datacenter with VirtualBox. reply mr_mitm 14 hours agorootparentprevVirtualBox is also Oracle, which is why I switched to KVM&#x2F;QEMU. But I&#x27;m also not an Enterprise user. reply metadat 9 hours agorootparentVirtualBox just straight up isn&#x27;t reliable enough for any production situation. You never know how it&#x27;ll break, and the support front release to release is unpredictable and overall sucks Cindy Stankey balls. reply tiernano 14 hours agorootparentprevServers and enterprise. reply patmorgan23 8 hours agorootparentprevCan you create a High availability cluster that does automatic failover with virtual box? reply Alupis 10 hours agoprevWhat does this means for the development of the Spring Framework ecosystem (including Spring Boot et al).VMware was a pretty good steward from my limited perspective. Does anyone have any experience with successful open source projects under Broadcom? They don&#x27;t seem to have a good track record with driver support, at the least... reply jmaker 2 hours agoparentI am very concerned too, we rely on Spring and RabbitMQ heavily. I’m going to call a halt on Spring and Rabbit for all new projects until the M&A fog dissipates. We run our own tech radar, likely to set the entire VMware stack on hold for now. If any of the prolific Spring contributors leaves, we’ll consider moving altogether. Spring is such a complex framework, if Broadcom gets to reshuffle the team, pieces will start to crumble. reply cendyne 7 hours agoparentprevI am also concerned about this. VMWare have been great stewards of the Spring framework &#x2F; boot libraries. reply ssd532 3 hours agoparentprevI would like to know as well. I am worried about RabbitMQ. reply gigatexal 13 hours agoprevEveryone&#x27;s VMWare licenses are gonna go up so much it&#x27;ll be hilarious. I wonder if any large shops will jump ship to something else, but to what is the question. reply phpisthebest 13 hours agoparentRedHat &#x2F; IBM had a huge opening to take some of this market share... but then for some inexplicable nonsensical move (common with IBM owned Redhat to be honest) they made the choice to just exit the Onprem Hypervisor space to focus on \"Cloud\".I know a few organizations and vendors (like Veeam) were looking to RHV to be a good replacement, the announcement to discontinue the product seems to catch everyone by surprise.I am still hoping Veeam will add support for a good 3rd option, proxmox, XCP, direct KVM, something... reply suprjami 13 hours agorootparentRed Hat didn&#x27;t exit, they moved from RHEV to OpenShift Virt. Now it&#x27;s kubernetes scheduling KVM VMs instead of ovirt-engine scheduling KVM VMs. reply phpisthebest 13 hours agorootparentOpenShift Virt is not RHEV with K8s add, it is a completely different thing, and running Traditional VM workloads on it is troublesome.I have no use for kubernetes, I will never use kubernetes, I do not want kubernetes anywhere near me.Most vmware customers I suspect have the same feelings reply depereo 12 hours agorootparentSet up a VM based workflow and it can run fairly well with minimal intervention for years.Set up a k8s deployment and you&#x27;re fiddling with deprecated APIs every couple months - if you don&#x27;t pay close attention the whole deployment spec falls apart within two years.The VM stuff works for the majority of companies - you can even sprinkle containers in fairly easily.It&#x27;s still a massive if mature market that needs some attention and care, it&#x27;s a shame it&#x27;s going to get squeezed and abused by broadcom. reply totallywrong 10 hours agorootparentprev> I have no use for kubernetes, I will never use kubernetes, I do not want kubernetes anywhere near me.I never got this religious approach to tech when it comes to work. I have my preferences but ultimately I&#x27;ll do whatever pays well. reply linuxftw 13 hours agorootparentprevI can&#x27;t imagine anyone would pay for such a thing. It&#x27;s a product without a market. People want the VMWare experience, Red Hat just refuses to build it. reply tjscott 13 hours agorootparentRed Hat built it in RHEV (or rather, bought it from Qumranet and rebuilt the .net in JBoss), but struggled in the market. They had an arguably better product than VMware, and better pricing, but VMware customers were hard to move, and Microsoft priced Hyper-V for Windows guests at cheaper than free. reply phpisthebest 13 hours agorootparent>>>but VMware customers were hard to movewere being the key phrase. Timing is everything, they Announced they were shutting down RHEV. AFTER broadcom announced they were buying vmware, seems like a terrible move in that light given that many vmware customers will be looking for a replacement in the next couple of renewal cycles. reply prmoustache 10 hours agorootparentAs a former potential RHEV customer, we had been warned about it 3 years ago by RH themselves. It is not like it was a huge secret and the decision was made a long time before broadcom&#x27;s announcement. reply linuxftw 12 hours agorootparentprevVirtualization is a multi-billion dollar market. Even if you&#x27;re a distant #2, it should be financially viable. The reality was, it was an awful product that nobody wanted. It could be free and it&#x27;s worse than rolling your own solution directly on top of libvirt. reply linuxftw 12 hours agorootparentprevSorry, nothing Red Hat built was ever better than VMWare in the virtualization space. They never built a cohesive product experience, they could not get out of their own way. reply totallywrong 9 hours agorootparentYes, this. I generally quite like RH stuff but RHEV was nowhere near VMware. I think it was the right move to shut it down and push Openshift VMs for hybrid workloads. replytw04 13 hours agoparentprevIf Nutanix were smart, they&#x27;d decouple the hypervisor from their garbage storage layer and make hay. But they won&#x27;t... too much pride to swallow that pill. reply MrDrMcCoy 13 hours agorootparentI&#x27;ll never forgive Nutanix for murdering EdgeFS. I have not used any of their products, and hopefully never will. reply notacoward 11 hours agorootparentEdgeFS was pretty much a direct ripoff of multiple open-source projects, including one I worked on, so I&#x27;m not going to shed a tear for them. IIRC they even cribbed some of the material for manuals. reply awiesenhofer 10 hours agorootparent> multiple open-source projectsinteresting, which ones? reply INTPenis 1 hour agoparentprevI can&#x27;t say any names but one very large shop is already jumping. But the jump is chaotic and poorly executed.What are the alternatives? reply moduspol 8 hours agoparentprevThe on-prem VMWare enthusiasts who&#x27;ve been warning for decades about vendor lock-in on the cloud are perhaps about to gain some new perspective. reply bluedino 14 hours agoprevWhat is the enterprise virtualization alternative?Is everyone on Hyper V already? Does Citrix still exist?Are SuSE or Red Hat offering an &#x27;open source&#x27; alternative? Surely people aren&#x27;t using Proxmox in production? reply tlamponi 13 hours agoparent> Surely people aren&#x27;t using Proxmox in production?Lot&#x27;s do, e.g., the Austrian domain registry:https:&#x2F;&#x2F;www.proxmox.com&#x2F;en&#x2F;about&#x2F;stories&#x2F;story&#x2F;nic-atAnd many others (albeit the big ones aren&#x27;t listed there, a bit harder to get real testimonials from them, and we do not pester everybody):https:&#x2F;&#x2F;www.proxmox.com&#x2F;en&#x2F;about&#x2F;stories?f=7 reply jzb 13 hours agoparentprevRed Hat has&#x2F;had Red Hat Virtualization but has transitioned that to Red Hat OpenShift Virtualization as a successor. I think RHV is set to phase out in 2026, and I&#x27;m not sure if they&#x27;re currently selling new subs or just servicing existing customers with other folks pointed to RHOV.The oVirt community&#x27;s most recent release is from last December, so I&#x27;m not sure whether that project is going to thrive now that Red Hat has largely stepped away. (Last blog update is also December 2022.) reply _jal 13 hours agorootparentRHV is dead, they&#x27;re trying to move people over to (the much more expensive) OpenShift. Support for it has gotten predictably worse.I don&#x27;t expect Ovirt to survive, the vast majority of development was RH.\"The market\" seems to \"deciding\" that in-house virtualization will be insanely expensive, and otherwise you need to rent OCP. reply transpute 9 hours agoparentprev> Does Citrix still existYes, https:&#x2F;&#x2F;www.xenserver.com&#x2F; and French OSS derivative https:&#x2F;&#x2F;xcp-ng.orgCitrix is now a private company run by former Broadcom head of software who negotiated VMware acquisition, https:&#x2F;&#x2F;www.crn.com&#x2F;news&#x2F;cloud&#x2F;citrix-tibco-new-ceo-tom-krau... reply edwintorok 54 minutes agorootparentXenserver is not part of Citrix anymore. It is a sibling business unit, part of its parent company Cloud Software Group. See https:&#x2F;&#x2F;cloud.com and https:&#x2F;&#x2F;www.xenserver.com&#x2F;storyDisclaimer: I work here reply noinsight 13 hours agoparentprevRed Hat used to offer Red Hat Virtualization (RHV) - based on oVirt - but they killed that at approximately the same time this VMware deal was announced (supposedly coincidentally).Now they bolted on virtual machines onto their OpenShift container platform and are pushing that. reply tonoto 13 hours agoparentprevKeep the eyes open on https:&#x2F;&#x2F;oxide.computer&#x2F; - they are building hyperscalar racks with open source components. Using bhyve as the hypervisor, API as a first class citizen, Terraform&#x2F;Opentofu, live-migration. Can&#x27;t wish for much more reply locusm 3 hours agoparentprevMy picks would be - Proxmox 8 if you predominately run Linux workloads - XCP-NG + XOA - XenServer reply merlyn 3 hours agoparentprevHyper-V as most people actually use it is more like single-host VMware ESXi.VMware&#x27;s true magic is with vCenter. While Microsoft has an equivalent to that (SC VMM), nobody seems to use it because it is virtually unusable. I&#x27;ve never seen a successful production cluster of VMM running. reply sebazzz 13 hours agoparentprevHyper-V server is killed by Microsoft, though you can of course install Windows Server in Core mode and install the Hypervisor component. reply navaati 13 hours agoparentprevRedHat and a couple other companies will sell you OpenStack clusters, up to a certain size. reply mvdwoord 13 hours agoparentprevContainers containers containers ;)In all seriousness, I think it is a hot topic in Enterprise Architecture (tm) meeting rooms ever since the merger was announced (I know it was in ours). But even if you find an alternative, you need to move, and a lot of companies have a lot of hard to modernize workloads which are skillfully managed by a lot of VMware trained personnel. No easy task. reply nullindividual 10 hours agoparentprevHyper-V isn&#x27;t dead by any means, however I would have a very difficult time recommending it in a greenfield environment. Microsoft&#x27;s focus is clearly not A) Windows Server and B) Hyper-V. reply totallywrong 9 hours agoparentprevOpenStack was all the rage some years ago, but I rarely hear about it these days. It does seem like a mature, viable option. reply rrdharan 8 hours agorootparentYou never hear about it because it’s mostly dead.Would love to hear a counter argument or evidence otherwise but my impression is there are very few successful openstack deployments out there and mostly it just is useful to provide some negotiating leverage when talking to your VMware rep. reply johnvanommen 19 minutes agorootparent> You never hear about it because it’s mostly dead.> Would love to hear a counter argument or evidence otherwise but my impression is there are very few successful openstack deployments out thereI&#x27;ve been doing OpenStack continuously for 10+ years, and it&#x27;s never been more popular than today.It&#x27;s bizarre how people think it&#x27;s dead.The biggest difference between OpenStack in 2013 and OpenStack in 2023 is that in 2013 there were a dozen different vendors promoting it, and in 2023 it&#x27;s basically Canonical and RedHat.The CEO of Canonical wrote an editorial years ago, basically arguing that the implosion that happened in 2017-ish, when Cisco&#x2F;VMWare&#x2F;HPE&#x2F;Pistoncloud&#x2F;etc threw in the towel would be good for OpenStack. And I think that was true.It&#x27;s very similar to what happened to Linux, remember how there was a period where there were 20+ distros vying for supremacy? reply lta 2 hours agorootparentprevOVH uses OpenStack to power a large a amount of it&#x27;s offering afaict, and they&#x27;re a pretty large provider reply johnvanommen 13 minutes agorootparent> OVH uses OpenStack to power a large a amount of it&#x27;s offering afaict,YMMV, but I think one of the main drivers of OpenStack is that it can be modified, because it&#x27;s open source.IE, if you&#x27;re Verizon &#x2F; AT&T &#x2F; T-Mobile, it&#x27;s valuable to be able to modify the product to suit your needs. I did some work on an OpenStack project a couple of years ago where the client wanted to leverage some hardware that was absolutely cutting edge. Literally so new, that engineers from the hardware vendor were involved in tweaking and optimizing things.Try doing that with VMWare; it&#x27;s impossible. With OpenStack, there&#x27;s nothing stopping you from modding the product to suit your needs.Obviously, this works particularly well if you&#x27;re running hundreds or thousands of servers and you can justify the investment. If I were only running a few dozen VMs, OpenStack is probably overkill. reply MrDrMcCoy 10 hours agoparentprevOpenNebula is what my current employer is looking at for our next move. reply remir 9 hours agoparentprevXCP-NG + Xen Orchestra is a solid combo. XCP-NG is based on Xen. reply thaanpaa 18 hours agoprevThat&#x27;s an interesting development. Since the ransomware outbreak earlier this year, there has been an increase in security concerns about VMware. I&#x27;ve heard more complaints about the lateness of security patches and the difficulties people have had installing them, etc. I&#x27;m curious if this has anything to do with that. reply merlyn 3 hours agoparentI haven&#x27;t had any trouble installing VMware security patches (I&#x27;ve done plenty).As to why there seems to be such an increase in security patches, its like the quote from Willie Sutton. That&#x27;s where the money is.. The largest target gets the most attention.Everybody has bugs. While you may hide under the radar with using some lesser known things, don&#x27;t fool yourself thinking that there aren&#x27;t holes the hackers can weave their way through. reply brohoolio 14 hours agoparentprevvCenter is a huge target. VMware docs differ from the the Crowdstrike recommendations, with security vendors saying basically to lock it down to the 9th degree or suffer the consequences. reply convolvatron 13 hours agoparentprevthis has been in the pipe for more than a year reply caycep 11 hours agoprevI guess the practical question for me is: in case Fusion goes abandonware, is there a viable desktop-focused hypervisor for the Mac other than Fusion or Parallels that runs Windows relatively well? I&#x27;m on Fusion, and I&#x27;ve always kind of viewed Parallels with suspicion. There&#x27;s Vimy and LTM but as far as I can tell, they don&#x27;t do Windows or GUI&#x27;s all that well, since their focus seems to be linux and Mac OS X VMS, unless newer versions have improved... reply presbyterian 10 hours agoparentI’ve had a pretty good experience with UTM, and it’s free. reply totallywrong 9 hours agorootparentThere&#x27;s also Lima (CLI only) for macOS which has worked better for me than UTM. reply avtar 4 hours agorootparentBetter in what ways? reply spullara 12 hours agoprevI guess this is really CA buying VMWare. This is a standard move by CA. Buy an entrenched software company that isn&#x27;t growing but has a lot of customers and milk it. reply mr_toad 11 hours agoparent> Buy an entrenched software company that isn&#x27;t growing but has a lot of customers and milk it.This is textbook management 101, and not just for software companies. reply RedShift1 13 hours agoprevThe only reason I&#x27;m sticking with VMware ESXi is because of Veeam, it&#x27;s like the only solidly working piece of backup software for VMs. Otherwise I wouldn&#x27;t doubt to go with Proxmox. reply ikidd 5 hours agoparentProxmox Backup Server is rock solid in the 2 years I&#x27;ve used it. It does a great job of dedup keeping hundreds of backup points as space efficient as you could hope for. And file restores or full VM restores are painless.I&#x27;ve even used the Linux client to virtualize physical boxes. reply jbverschoor 13 hours agoparentprevProxmox seems to be working great, including backups reply doubled112 11 hours agorootparentBuilt in backups that work are a big reason I ended up on Proxmox at home. reply BadBadJellyBean 13 hours agoparentprevDoesn&#x27;t Proxmox have a builtin backup? You could also use Hyper-V with Veeam. reply xoa 12 hours agoparentprevAre you talking about using it AIO? It seems preferable to me in general to have VMs live on external storage like a NAS. Proxmox, KVM, Xen and I assume everything else all support using iSCSI at least. Then your storage layer can focus on that and handle all the backing up, data integrity etc itself. I guess that does raise cost for the same performance vs a single box so it&#x27;ll depend on budget&#x2F;needs, but it&#x27;s getting pretty affordable with a bit of shopping to do some serious storage devices these days. reply system2 9 hours agoparentprevI hated Veeam because of the slowness and difficulty of live snapshots. We purchase synology nas solutions and even use the nas for host redundancy. Works perfectly and super fast. Also, get C2 from Synology to backup your vms on the cloud. reply Suffocate5100 7 hours agoprevIt&#x27;s ok, I&#x27;ve already migrated all of our VMware clusters over to XCP-ng. reply boiler_up800 14 hours agoprevRIP CloudHealth customers. reply don-code 13 hours agoparentFormer CloudHealth early engineer here. That&#x27;s nothing new. This started almost in tandem with the VMware acquisition - the company culture had been all about small- to medium-size customers, up through the point where due diligence started with VMware. We were told in no uncertain words that VMware would roll the red carpet out for big names, and that our platform needed to be ready for it. I stuck it out for about a year and a half, post-acquisition, where we tried to figure out and build a \"CloudHealth Enterprise Edition\" of sorts.I was surprised that VMware kept the \"CloudHealth\" branding as long as they did, - it turned out that the brand actually had some cache that VMware wanted to hang on to. But it was formally dropped last year, in favor of \"VMware Aria Cloud Cost Control\", or some equally overdescribed thing. reply parasubvert 9 hours agorootparentIt&#x27;s now VMware Tanzu CloudHealth. Tanzu is where they&#x27;re putting their public cloud bets. reply micromacrofoot 8 hours agoprevAlways a little scary from an employee perspective, good luck (sincerely)! reply didip 9 hours agoprevSince KVM already exists, who would renew their ESXi licenses?Broadcom would surely rise license costs while at the same time disinvesting.Also, what will happen with VMWare’s Kubernetes investments? I am guessing all of their open source work will cease to exist? reply dopylitty 9 hours agoparentThere may be other hypervisors out there but that&#x27;s not the hard thing to replace. It&#x27;s all the junk on top that enterprises will have to replace somehow.Off the top of my head they have:- Carbon black for what used to be called antivirus but has metastasized into XDR, an all encompassing endpoint security&#x2F;detection&#x2F;response tool- A whole automation framework (vRA&#x2F;vRO) that companies use for automating deploying VMs and other stuff. Probably straightforward to replace with other automation frameworks but migrating existing playbooks will take time and expertise ($$$)- A whole virtual desktop management suite (Horizon) including SaaS IDP&#x2F;Mobile Device Management (Workspace One&#x2F;VMware identity manager). Can probably patch together a replacement with stuff like Jamf, your SaaS IDP of choice, and Microsoft&#x27;s hosted VDI but it won&#x27;t be quick and again device migrations might suck- Software defined networking with NSX. This could be difficult to quickly replace if you have a whole system built around automating network segmentation&#x2F;management with it. It seems like your choice is either go with a network vendor and lose tight VM integration or go with a lower tier virtualization platform and get a bunch of hacked together Apache&#x2F;Linux native stuff and no support- SDWAN stuff. Probably relatively easy to replace unless you have a huge number of branches or edge devices that need to be physically updated by rolling trucks- VMware cloud where ESXi&#x2F;vSphere run on public clouds. To replace it you need to stand up a whole datacenter&#x2F;colo hypervisor environment&#x2F;network&#x2F;storage and staff up to manage themI could go on but suffice it to say I don&#x27;t envy the enterprise management types having to consider untangling their dependencies on VMware right now. reply merlyn 3 hours agorootparentThey&#x27;ve announced NSX and SD-WAN is a core business unit under the new VMware as Broadcom offering.EUC, Aria and Carbon Black are still up in the air. reply system2 9 hours agoparentprevFor proper business infrastructure. We are using VSphere for all our clients and it works very well. We can&#x27;t really deal with half-baked solutions which never translate to the corporate environment. reply softirq 9 hours agorootparentkvm&#x2F;libvirt are the industry standard solutions for enterprise linux based distros, and I know for a fact, that multiple mega-corps use it at scale. Pretty much anything Linux based is going to have the best support path in 2023 vs. something made by a company that&#x27;s being sold over and over again. reply system2 8 hours agorootparentSMB do not use Linux. Business owners do not even know what Linux is. In the real world, Linux is nonexistent. Business software runs on Windows. reply thedaly 10 hours agoprevDamn it, I just purchased an workstation license too. reply akmarinov 14 hours agoprevDid China give the go ahead? reply advisedwang 13 hours agoparentWhy would an American company need China&#x27;s go-ahead to acquire another American company&#x27;s American subsidiary? reply mvdwoord 13 hours agorootparentBecause they do business in China?But yes, they have got it..https:&#x2F;&#x2F;www.streetinsider.com&#x2F;dr&#x2F;news.php?id=22439649&gfv=1 reply xxpor 13 hours agorootparentWouldn&#x27;t be shocked if this is part of a deal Xi and Biden made. reply Patrick_Devine 12 hours agorootparentThat is almost a certainty. That, or it was more likely done one or two tiers down during the APEC conference. reply Nthringas 11 hours agorootparentI think this also has something to do with the whole OpenAI debaclebut I can only guess.... reply xxpor 13 hours agorootparentprevSee also Intel and Tower Semi reply justincormack 13 hours agoparentprevYes according to the press release yesterday, didnt give any details. reply ex3ndr 10 hours agoprevDoes anyone knows good alternative with GPU passthrough for homelab? Hyper-V is not going to fly since it won&#x27;t do passthrough on consumer windows. Also not proxmox. reply transpute 10 hours agoparentXCP-ng (OSS subset of Citrix Hypervisor, both based on Xen). As always, requires GPU and BIOS which supports IOMMU passthrough.https:&#x2F;&#x2F;docs.xcp-ng.org&#x2F;compute&#x2F;#pci-passthrough reply edwintorok 51 minutes agorootparentSmall nitpick: Next version of Citrix Hypervisor is now called Xenserver again, see https:&#x2F;&#x2F;www.xenserver.com&#x2F;storyDisclaimer: I work here reply freeqaz 10 hours agoparentprevXen and KVM will both do this iirc. Requires a bit of work to make it work though.https:&#x2F;&#x2F;wiki.archlinux.org&#x2F;title&#x2F;PCI_passthrough_via_OVMF reply 3np 7 hours agorootparentTo add on this when considering what to use: You first want to decide if you want full virtualization (KVM&#x2F;QEMU) or paravirtualization (Xen).Then you will probably use some operations layer on top of that (e.g. QubesOS and XCP-NG are only Xen; Proxmox is only KVM&#x2F;containers; libvirtd does both). Then based on that you pick your actual host OS (in case it&#x27;s not already set).I have GPU passthrough of the iGPU on a Ryzen 4000U working with kvm&#x2F;qemu+libvirtd on an Alpine base. So the hypervisor runs headless (booting in blind mode) and the guest OS takes over the iGPU entirely. The caveats are explained in that arch Wiki article, IIRC. I think the least obvious part for me was sourcing and loading of the microcode&#x2F;firmware.Also had success with hybrid graphics (Ryzen APU + AMD RX GPU with one passed through and one on host) on an otherwise similar hypervisor setup on Arch BTW.Even more so than usual, the more recent and obscure your hardware, the higher chance you&#x27;ll get to compare different kernel versions, incant random undocumented parameters you found in some forum comment, or even reach for out-of-tree patches to get running smoothly. reply pezezin 10 hours agoparentprevWhy not ProxMox? reply system2 9 hours agoparentprevIs there anything wrong with ESXi? reply ex3ndr 4 hours agorootparentthey do not allow you to use more than 8 cores for VM for example reply system2 2 hours agorootparentNot unless you get a basic VSphere Essentials for 3 hosts. $500 I know, but you get it once, use it with 3 servers, and control it all from one portal. Moving Vms is super easy with Vsphere too. Of course, you get unlimited cores with it. reply chungy 10 hours agoprevBetween Xen, KVM, BHyve, Hyper-V, the use cases for VMware vanished well over a decade ago. They&#x27;ll bleed out their remaining customers until there is no one left. reply c-hendricks 9 hours agoparentWhat&#x27;s a good solution for regular users trying to run a Linux VM on Windows? Looks like Hyper-V doesn&#x27;t have great hardware acceleration support. reply toby0897 9 hours agorootparentis WSL2 with GPU acceleration not an option? reply c-hendricks 8 hours agorootparentHonesr questions, is WSL intended to run a full desktop environment, and does it still require workarounds to get systemd working? reply k8sToGo 1 hour agorootparentWSL2 supports systemd out of the box for some time now. By default it is turned off.In WSL2 you can run GUI applications as well. replybadrabbit 10 hours agoprevAhh damn! Now carboblack has to be renamed again. One product of theirs has already been renamed 4 times at least lol. It&#x27;s like a game of snake with these companies.I wish an MBA can explain to me the value of rebranding and losing brand loyalty&#x2F;familiarity. reply tarxvf 3 hours agoparentI swear the corporate swag manufacturers are in on it somehow. I usually don&#x27;t even get the shirt from the most recent rebranding before the brand is changed again. reply manishsharan 10 hours agoprevThis is very bad news for careers of so many ESXi SMEs at all major corporations. Several employers will put a hard stop on all private cloud (on-prem) investments and move everything to public cloud. We recently pulled the plug on another s&#x2F;w acquired by Broadcom. reply smcleod 12 hours agoprev [–] They deserve each other. Two makers of terrible products. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Broadcom offers a support portal for users to access information and assistance.",
      "Users have the option to register on the portal and retrieve forgotten usernames/passwords."
    ],
    "commentSummary": [
      "The discussion encompasses various topics related to virtualization software, including concerns about Broadcom acquiring VMware and comparisons between different hypervisors.",
      "Users discuss pricing, features, and the effects of acquisitions on companies and customers, expressing their preferences for specific software options.",
      "The conversation expands to include alternatives to VMware, like Proxmox, KVM, and Hyper-V, as well as other subjects such as cloud solutions and enterprise software."
    ],
    "points": 373,
    "commentCount": 250,
    "retryCount": 0,
    "time": 1700665298
  },
  {
    "id": 38378455,
    "title": "Ubuntu Outperforms Windows 11 by 20% on New AMD Zen 4 Threadripper",
    "originLink": "https://www.phoronix.com/review/threadripper-7995wx-windows-linux",
    "originBody": "Ubuntu Linux Squeezes ~20% More Performance Than Windows 11 On New AMD Zen 4 Threadripper Written by Michael Larabel in Operating Systems on 21 November 2023. Page 1 of 7. 21 Comments With currently reviewing the HP Z6 G5 A workstation powered by the new 96-core AMD Ryzen Threadripper PRO 7995WX Zen 4 processor, one of the areas I was curious about was how well HP's tuned Microsoft Windows 11 compares to that of Linux. In this article is looking at how the Microsoft Windows 11 performance is out-of-the-box with the HP Z6 G5 A workstation as configured by HP versus a clean install of Ubuntu 23.10 with the Linux 6.5 kernel. Going back to the original AMD Ryzen Threadripper processors, Linux has long possessed a performance lead over Microsoft Windows. With Linux typically being the dominant OS of HPC systems and other large core count servers, the Linux kernel scheduler has coped better than various flavors of Windows when dealing with high core count processors. Paired with some early Windows issues that Microsoft and AMD has since worked through. Linux has gained a reputation of handling these HEDT systems better than Windows. In being curious about the difference for these new Zen 4 Threadrippers and now being able to push things to the extreme with the Threadripper PRO 7995WX 96-core / 192-thread processor, I set out for some fresh benchmarks. The HP Z6 G5 A review unit was preloaded with Microsoft Windows 11 Pro as configured by HP and so it makes for a nice perspective of looking at the Windows performance as validated by the hardware vendor. After running through all of the Windows benchmarks of tests relevant to HEDT/workstations and that work similarly on Windows and Linux, I then set out to do the Linux benchmarks. Ubuntu 23.10 was run for providing a clean, out-of-the-box look at this common desktop/workstation Linux distribution. Benchmarks of other Linux distributions will come in time in follow-up Phoronix articles. But for the most part the Ubuntu 23.10 performance should be largely similar to that of other modern Linux distributions with the exception of Intel's Clear Linux that takes things to the extreme or those doing non-default tinkering to their Linux installations. The HP Z6 G5 A for all testing was configured with the Ryzen Threadripper PRO 7995WX at default frequencies, 8 x 16GB DDR5-5200 Hynix RDIMMs, Samsung MZVL21T0HCLR-00BH1 NVMe SSD, NVIDIA GeForce RTX A4000 16GB graphics. A full review on the HP Z6 G5 A Threadripper workstation will be published in a separate article on Phoronix in early December. From there the up-to-date Windows 11 Pro Build 22631 (H2'23) was tested against Ubuntu 23.10 with its stable release updates. Let's see how Windows and Ubuntu Linux perform on this 96-core / 192-thread Zen 4 workstation with 128GB of RAM. 21 Comments - Next Page Tweet Page 1 - Introduction Page 2 - LuxCore Renderer + Intel Embree Page 3 - Open Image Denoise + OSPRay + OSPRay Studio Page 4 - NAMD + OpenJDK Java + Image Encoding Page 5 - Video Encoding H.265 + AV1 Page 6 - Stockfish + Asmfish Chess + Y-Cruncher + ASTC + CPU Mining Page 7 - Geekbench + Blender + Appleseed + V-RAY Renderer Page: 1 2 3 4 5 6 7 Next Page",
    "commentLink": "https://news.ycombinator.com/item?id=38378455",
    "commentBody": "Ubuntu squeezes more performance than Windows 11 on new AMD Zen 4 ThreadripperHacker NewspastloginUbuntu squeezes more performance than Windows 11 on new AMD Zen 4 Threadripper (phoronix.com) 339 points by marcodiego 21 hours ago| hidepastfavorite373 comments FirmwareBurner 21 hours agoNot surprised though, with AMD being able to patch the Linux kernel and scheduler to its liking in order to squeeze out the maximum performance for it&#x27;s architecture, versus depending on Microsoft to have the good will to figure it out on their own dime.I&#x27;d be curious if the businesses buying these $20k+, 96-core, HEDT workstations actually do run Windows on them in order for this to be that big of a problem for Microsoft worth addressing, or if it&#x27;s Linux all the way anyway for them so Windows isn&#x27;t even on the radar.Anyone here in the know?Also, obligatory: \"But can it run Crysis?\" (in software render) reply chaosbutters314 17 hours agoparentive worked at companies where we buy these types of workstations for fea&#x2F;cfd&#x2F;MLif the company has a overbearing IT, we run windows for \"security\". at places where we move fast and break things, we run ubuntu and IT says for us to manage it ourselves.for anyone wondering why we done use the cloud or a server, we do too. but model setup, licensing, and small jobs are easier and quicker to do locally. reply ThrowawayB7 13 hours agoparentprev> \"...depending on Microsoft to have the good will to figure it out on their own dime.\"They don&#x27;t have to figure it out on their own; everybody maintains close contact. For example, Intel has a field office literally one block away from Microsoft&#x27;s main campus. One would assume AMD also has a field office similarly near by. (EDIT: they do, a couple of blocks further.) reply bryanlarsen 20 hours agoparentprevOne of the major markets for these would be visual art studios. They aren&#x27;t generally Linux shops. reply FirmwareBurner 20 hours agorootparentFunny you mention this because a lot of big visual arts studios use Mac for the artwork in the Adobe ecosystem, and heavily invested in Linux for the 3D rendering pipelines as they moved away from SGI&#x2F;BSD with Windows almost nowhere on the radar.I&#x27;d estimate the number of big-name shops running Windows is a minority with only smaller indie studios like Corridor Digital being all-in on Windows because it&#x27;s a jack of all trades can-run-anything OS, and managing that one ecosystem without sys-admins and an internal IT department is a lot cheaper easier for small businesses of amateur-professionals. reply bryanlarsen 19 hours agorootparentMy experience is exclusively with small studios, which were Windows shops. reply antod 10 hours agorootparentprevYup - A while back (not sure if changed much since), Weta Digital people would talk about being pretty much mostly Linux for modelling&#x2F;rendering&#x2F;etc and heavily Mac for audio. Very little Windows. reply gamblor956 15 hours agorootparentprevThe majority of professional movie and television VFX work is now done on Windows and Linux computers, with Linux especially being used for the rendering portion of the process.Mac was the dominant platform for a long time, but Windows caught up and zoomed past Mac about a decade ago. Same or better performance, cheaper hardware, cheaper software, easier to upgrade&#x2F;repair, and more choice for all of the above.There&#x27;s a reason that Apple has to pay big bucks to Olivia Rodrigo and others to use Apple products to film and edit their music videos: it&#x27;s because Apple fell out of favor with creatives and Apple is trying to buy its way back in. reply withinboredom 20 hours agorootparentprev\"a lot\" is nowhere near \"all\" reply worthless-trash 20 hours agorootparentAnd none is nowhere near \"a lot\". reply wiz21c 18 hours agorootparentNone is nowhere, a lot is somewhere and all is everywhere. sort of. replyscheeseman486 20 hours agorootparentprevThe improvements coming for Wayland&#x27;s HDR&#x2F;color management are likely to help with that, as the features they&#x27;re aiming for appears to beat Window&#x27;s more slapdash implementation with per-window color management, where window contents are accurately tonemapped and composited within the widest color space the monitor supports.Adobe would need to be incentivized to port their suite over for it to be taken seriously, but maybe Wine could bridge that gap at first.Ah, the mythical Linux Desktop. One day... reply jwells89 19 hours agorootparentWill Wayland be able to render mixed HDR and SDR content correctly, with e.g. an HDR video on YouTube rendering with extended range while the rest of the screen renders as normal?Currently only macOS can do that. With Windows you have to choose between SDR and HDR display modes which affects everything on screen regardless of type, which makes SDR content look dingy in HDR mode. reply kstrauser 17 hours agorootparentOn that subject, anyone know why shifting to HDR dims everything that way? My mental model of it is that SDR brightness goes from 0 to 100, and HDR brightness goes from -100 to 100, and that turning on HDR moves everything not HDR-aware down to the bottom of the brightness space.I could look this up, but never think about it outside of conversations like this and figure it might be more fun to talk about it. reply dagmx 15 hours agorootparentConsider that your display can only do 0-100 brightness (not really but for sake of argument)In SDR, you map the full SDR range (also 0-100) to that 0-100.When you add HDR, you’re now adding levels above 100 (let’s say 0-200).If your display can only do upto 100, you now need to put all the 0-100 stuff in 0-50. Or you get a display that can also display 0-200.Very few computer displays can do over a standard SDR range of 500 nits. reply kstrauser 15 hours agorootparentBut why isn&#x27;t SDR then scaled from 0-200, then? That is, why isn&#x27;t \"fully bright SDR\" mapped to \"fully bright HDR\"? reply saltcured 14 hours agorootparentWell, it&#x27;s pretty arbitrary. What is missing from most image (or sound) data is metadata to say what physical intensity is represented by the signal. I.e. how many nits (or decibels) should be emitted for this signal.AFAIK, most encoding standards only define a relative interpretation of the values within one data set. And even if standards did have a way to pin absolute physical ranges, many applications and content producers would likely ignore this and do their own normalization anyway, based on preconceptions about typical consumers or consumer equipment.To have a \"correct\" mixing, you would need all content to be labeled with its intended normalization, so that you can apply the right gain to place each source into the output. And of course there might be a need for user policy to adjust the mix. I think an HDR compositor ought to have gain adjustments per stream, just like the audio mixer layer. reply dagmx 13 hours agorootparentprevWhat context are you talking about?In single mode where it’s just SDR, it’s mapped to take the full range of the display up to whatever is deemed a comfortable cap.In a mixed HDR&#x2F;SDR mode, the H is range above the S , so it doesn’t make sense to scale it up. I prefer Apple’s terminology of Extended Dynamic Range because it’s clearer that its range above the SDR range.Now you could say that you intend for that SDR to be treated as HDR, but without extra information you don’t know what the scaling should be. Doing a naive linear scale will always look wrong. reply mmis1000 15 hours agorootparentprevBecause windows map sdr contents to srgb color space. Which nobody except designers uses. Most monitor today ship with a much brighter and, high contrast, vivid color profile by default. If you toggle your monitor to srgb color profile. You should see a color that looks really similar to sdr contents in Windows hdr mode.In my opinion, I also don&#x27;t like it. But there is surely no way for Microsoft to chose a color profile that looks like without toggle hdr on given there are so many monitor manufacturers in the market. I think chose the most safe srgb option is understandable. reply t0bia_s 15 hours agorootparentHopefully, DCI 3P will be standard in future.I have monitor that have 187% sRGB, 129% Adobe RGB and 133% DCI P3 gammut volume. But to have correct sRGB colors with maximum coverage on monitor I need to clamp ICC profile via Novideo SRGB. Without it, sRGB content looks oversaturated in orange spectrum. reply bryanlarsen 15 hours agorootparentprevA better way to describe it, IMO:SDR goes from 1-100. HDR goes from 0.01 to 100. Twice as many orders of magnitude difference from bottom to top. So if you peg the top to max brightness in both cases, the HDR looks brighter because the contrast is bigger.(Note that this is an analogy. In other words, it&#x27;s wrong, but a way of looking at it) reply wmf 16 hours agorootparentprevIt&#x27;s more like SDR goes from 0 to 255 and HDR goes from 0 to 1024. In SDR mode, 255 = (say) 500 nits while in HDR mode 1024 = 1000 nits and thus 255 = 250 nits so SDR content looks dimmer. reply jamesfmilne 20 hours agorootparentprevWe sell systems based on these high-end workstations and yes they do run Linux, Rocky Linux 8 at the moment.Still stuck on Xorg because reasons, but for HDR monitoring you&#x27;re usually using a display interface card with SDI or HDMI outputs anyway. reply kelsolaar 17 hours agoparentprevEpic Games runs mostly Windows Threadrippers for Unreal Engine development. Compiling Unreal faster, or anything really, even Windows itself is a compelling argument. reply lostlogin 20 hours agoparentprevThe portion running a hypervisor would also be interesting to know. That’s one hell of a processor. reply jackmott42 20 hours agoparentprevPretty sure Microsoft is very cooperative on working with AMD and others on this stuff, it may just take a little longer in this case. reply dboreham 20 hours agorootparent> versus depending on Microsoft to have the good will to figure it out on their own dime.Cutler stated in a recent interview that he had a 96-core machine as one of his two daily drivers. I wondered at the time if he pre-announced that CPU since the press about it seemed to reach me a few days later. reply vluft 16 hours agorootparentEpyc has had 96-core cpus out for a bit over a year now, so probably that. reply atoav 21 hours agoprevBack in the day I used Linux for rendering my Blender animations because my tests had shown it was 10% faster than the same machine running Windows 10. With render times of more than 8 days this quickly paid off. reply okl 19 hours agoparentI noticed that AMD&#x2F;Xilinx Vivado synthesis runs 20% faster on WSL2 than on Windows. After seeing such differences using it on plain Windows becomes unpleasant. reply alentred 18 hours agoprevIn the context of Linux adoption on the desktop it is not big news, unfortunately. To my mind, overall end-user experience is already better in Linux compared to Windows where similar tasks are more complicated, even before the raw performance starts to matter.Better performance would be a prerequisite indeed - no one wants to move a slower OS - but then there must be other convincing reasons to drive the desktop user adoption. And no roadblocks.Edit: sorry, rephrased a lot, but the core idea is hopefully the same. reply aleph_minus_one 18 hours agoparent> And yet, users don&#x27;t convert to Linux. So there must be other reasons, and performance benefits don&#x27;t seem to work so far.For enterprise desktop purposes:One central reason is that there is no Excel for GNU&#x2F;Linux. Accept it or not: the workflows of lots of departments are deeply intertwined with Excel (and it would take an insane amount of work to replace Excel by some other spreadsheet application). Another important reason is that GNU&#x2F;Linux is not some singular operating system, but a proliferation of various different distributions - this is not something that enterprise customers like. reply OPA100 17 hours agorootparentWe run thousands of Linux desktop workstations from low-end workstations for developers to dual-socket machines with >1TB of memory at work. That&#x27;s primarily because productivity for our use cases is so much higher with a Linux&#x2F;Unix environment than Windows that it&#x27;s not even remotely funny. However, almost all users still have either the standard corporate-issue Windows laptop, or a Windows VM on their workstation. Practically exclusively for Desktop Excel-based administrative tasks.Generally speaking, the vast majority of our userbase likes their Linux workstations far better than their Windows machines, and that&#x27;s after experiencing the significant downgrade to Gnome desktops due to Red Hat removing KDE. reply throw555chip 16 hours agorootparentAs a dev, wish I worked there, IBM was the only other place I worked where many devs and even a few thousand ordinary users like marketing, ran Linux. Also, I wasn&#x27;t aware RedHat removed KDE, what an odd and crappy move. KDE rocks. Gnome not. RPM based distros sooner or later corrupt themselves, I run and recommend Ubuntu or Kubuntu (for KDE people), with Snap disabled with a small apt preferences file. reply torginus 17 hours agorootparentprevWould it? I exclusively use Office365 on the browser for all my Excel needs. It works perfectly, even if it&#x27;s a bit sluggish.But I admit, Excel is a side hustle for me. reply vladvasiliu 5 hours agorootparentI rarely, if ever, use Excel. But I find that Outlook in the browser wipes the floor with local Outlook, be it \"OG\" or \"new\" Outlook. Everything is much smoother, there are no window widgets crapping up (right now, the min &#x2F; max &#x2F; close and window title of my new outlook are black on a dark grey background - I&#x27;m using the windows dark theme). This holds even in Firefox on Linux – it&#x27;s how I mostly interact with MS Office.What&#x27;s also fun to me is that the other day, I tried \"opening in word\" a .docx attachment I received in my locally-installed \"new\" outlook. It didn&#x27;t even try to open my locally installed word on ask me anything. It uploaded the file to onedrive without asking and proceeded to launch word online to read it. reply mmcnl 16 hours agoparentprevThe end user experience is way better on Windows than Linux. And I say that as someone who uses Linux (Ubuntu Gnome) daily. You really have to appreciate the freedom of choice that FOSS brings you to appreciate Linux. If you don&#x27;t care, as most people do, you&#x27;re probably better off with Windows.Ofcourse you can counter my reasoning by listing a lot of problems with Windows. And I can assure you that most people don&#x27;t care about the stuff you (as a Linux user) would care about.Windows just works. It has Office, Excel, Word, PowerPoint. It&#x27;s familiar. Instructions for any kind of software contain Windows instructions. Friends and family can help you if you have problems. Etc.(Windows is the only OS that can handle different fractional scaling factors properly for multiple displays. Fractional scaling on Linux is a joke, and macOS doesn&#x27;t care about low DPI screens at all so everything looks terrible.) reply JaggedJax 15 hours agorootparentI agreed with this for a long time, but in the past 4ish years I no longer agree. On Windows I regularly run into frustrating issues with audio, drivers, printers, random odd errors.On linux (currently PoP OS, first on a System76, now a Dell) I have not been running into issues. The biggest issue I ran into was strange Wifi connection issues, which System76 had me submit logs for and identified it as a failed Wifi card. But my audio, drivers, printer, scanner and day to day tasks just work.Yes there are features that are missing on one platform or another. But day to day is now much more pleasant for me on desktop linux as I run into far less frustrating issues. reply vladvasiliu 4 hours agorootparentprevI&#x27;d say the windows experience is maybe more familiar, but not better. As another commenter said, people are just used to computers being crappy the windows way. And even that familiarity may not be all that great with all the things moving around in windows 11.As another commenter has said, window management is a shitshow, and I don&#x27;t even mean \"missing X feature I love from this other WM\". Virtual desktops are broken. You have UAC windows sometimes going to the front, sometimes staying in the back. Sometimes they&#x27;re at the front covering your old window but they don&#x27;t have focus, even though the caret is blinking. You get windows maximizing behind the taskbar (Teams). Window management is handed-off to applications, so a broken application will poison the rest of the window management.> Windows is the only OS that can handle different fractional scaling factors properly for multiple displaysI don&#x27;t know what you mean by \"properly\", likely not the same thing as I do.That it kinda sorta works as in \"can turn it on\"? But even basic OS things are borked. Have you tried opening the start menu after switching scaling factors?My use case: I have a laptop running at 100%, and an external monitor running at 150%. If I boot it up this way, the start menu looks fine. If I plug or unplug the external screen while running, the start menu breaks. But here&#x27;s the kicker, which shows the quality engineering: pressing the start button shows an OK menu. Start typing looking for something, and it becomes blurry! This is under windows 11 with all the latest updates.Also, Wayland on Linux supports this, too. I don&#x27;t use Wayland, but I understand that whatever problems there are, as in \"not all apps are compatible\" is the same problem with windows: the app has to cooperate. Try opening some configuration panels in Windows on a 200% screen, and you better have some good glasses on hand. reply timlatim 13 hours agorootparentprevI&#x27;m not sure I agree that \"most people don&#x27;t care about the stuff you (as a Linux user) would care about\". Some people put up with Windows problems because they don&#x27;t know it could be different, to them that&#x27;s just how computers work. Take automatic updates for example. More than once have I heard from a friend how they lost unsaved work or an overnight render because their PC rebooted for updates. While on Linux months long uptimes are the norm, and you can trust it won&#x27;t reboot on you out of blue. Same with ads and other Windows annoyances.Other people are bound to Windows by their software needs. You&#x27;re right that many important programs are just not available on Linux (to your Office example I&#x27;d also add the Adobe suite). But the end user experience of Windows itself has been downright abysmal for a long time now, and for casual users who don&#x27;t need much besides Chrome and a couple other Electron apps, modern Linux desktop might genuinely be the better choice. reply hulitu 13 hours agorootparentprev> The end user experience is way better on Windows than Linux.Window management in Windows 10 is so terrible that it makes TWM look modern.Cluterred title bars so you need to aim for some free space to be able to move the window on other monitor, 1px window borders - good luck resizing windows on HD and UHD monitors. Gray on gray. Terrible scrollbars.And the best one: Programs keeping files open after you close them. reply bryanlarsen 18 hours agoparentprev20% extra performance matters a lot to anybody buying a $5000 Threadripper machine. If they didn&#x27;t care about performance, they could have saved a lot of money... reply the__alchemist 15 hours agoprevI hope for a future where we are not trapped between Windows, MacOS, and Linux. They are all very complicated, and have much state. They&#x27;re great for general-purpose computing, but it would be cool if you could use the same hardware in these GP computers with lightweight firmware that doesn&#x27;t get in the way, and can be tuned to a specific task better. Simple, responsive GUI, could run your specialty software etc with direct hardware interaction. reply allo37 15 hours agoparentSounds a bit like what UIO tries to do in Linux? https:&#x2F;&#x2F;www.kernel.org&#x2F;doc&#x2F;html&#x2F;v4.12&#x2F;driver-api&#x2F;uio-howto.h... reply caskstrength 12 hours agoparentprev> Simple, responsive GUI, could run your specialty software etc with direct hardware interaction.Are \"simple and responsive\" network protocols stack and file system, for example, also included in the FW? There is a reason why systems that used to work like that (game consoles) started to ship with general purpose OS to handle such things some time ago. reply ikmckenz 15 hours agoparentprevDo you mean something like MirageOS? https:&#x2F;&#x2F;mirage.io&#x2F; reply tester756 15 hours agoparentprevThat&#x27;s what I&#x27;ve been thinking about.Modern runtimes try to do a lot of OS&#x27; job(s) - memory management like gc, threads management, etc, etc.What if we stopped using OSes and their perf. penalties and run our software (with its runtimes like clr&#x2F;jvm&#x2F;wasmish) directly on the hardware reply KeplerBoy 15 hours agorootparentIs there really performance to gain? I doubt a well configured OS is slowing the CPU down.The alternative could be GPU like devices: A PCI-E card with sockets for the chip and some RAM running it&#x27;s own firmware. Intel tried that with it&#x27;s Xeon Phi line and they opted to run Linux (called uOS) on the accelerator board, so apparently that was never an issue. reply nektro 5 hours agoparentprev> with direct hardware interactionyou&#x27;re not gonna see this ever again. it&#x27;d be reckless to do so with how unsafe it would be reply criddell 20 hours agoprevI hope the community really gets behind Snap or Flatpak or one of the other systems for bringing a modern permissions and privileges system to the Linux desktop. It would help me be a lot more comfortable recommending Linux to non-technical people.What distro would you recommend to somebody like me who wants to be asked before an application gets access to my location, microphone, camera, network, etc...? reply tehbeard 18 hours agoparentSnap can die in a fire.Flatpak... I&#x27;ll warily try it for \"user facing\" apps.But after a clusterfuck of trying to get a flatpak Jellyfin to work (HW accel fell over, and it wanted me to dumpster dive into flatseal to unsandbox it so that media OUTSIDE OF HOME could be accessed... never got around to looking at getting it to even boot at startup) I&#x27;ll shy the hell away from it for daemons. reply ragnese 19 hours agoparentprevAs someone who has been using Linux exclusively for my personal machines since 2007, here&#x27;s the chicken-and-egg problem that the Linux world is constantly battling: new technology is always being released and pushed out before it actually works.It&#x27;s happened constantly since I started using Linux: KDE 4.0, PulseAudio, btrfs (to be fair, most distros didn&#x27;t really push btrfs as a default), Wayland, etc, and now Flatpak and Snap.And it&#x27;s not to say that I don&#x27;t understand the dilemma: you need to get user feedback to improve the tech, and the pool of Linux users is very small (for desktop stuff). But what that means is that desktop Linux is almost always in a state of partial brokenness. (And please also note that I&#x27;m giving a 100% pass on driver issues--that&#x27;s a given when hardware manufacturers simply only care about working with Windows.)Honestly, when it comes to \"just working,\" desktop Linux is worse today than it was when I first installed it on my budget laptop in 2007. Wayland is mostly fine for my uses, but others still struggle with its missing features; snaps&#x2F;flatpaks are slow, bloated, and have strange behaviors because of the permissions models that are NEVER going to be obvious to a casual computer user; and managing an Ubuntu install is still really bad UX.As an example of the latter, I usually run an \"expert\" distro on my personal machines, but I decided to slap Ubuntu on a PC that I hooked up to my TV, and after a year or so of just chugging along and running updates whenever prompted, it started displaying errors that my boot partition was full. You&#x27;ve gotta be kidding me... THIS is supposed to be the \"easy\" distro for normal humans? How the hell do you expect non-tech people to micromanage the &#x2F;boot partition and delete old kernels and shit?So, while I agree with all of the technical issues and complaints about things like permissions, security, etc, that advocate for Wayland and Flatpaks&#x2F;Snaps and whatever, you can&#x27;t pretend to care about adoption while also pushing out half-baked technology to \"stable\" versions as though everyone will be happy with beta-at-best functionality. reply type0 9 hours agorootparentI&#x27;m not sure what distros you have been using but Linux Mint and Debian (if you set it up right) are extremely stable. Snaps have been slow but I have never experienced that with Flapaks; reasonable critique is it takes a lot of disk space and takes too much time to update different versions of underlying tech gtk or qt.Ubuntu has not been a good distro for a few years now. Even Fedora is more stable now and you get new software.We never had as good Linux desktop situation as it is now. The biggest complaint is that if you want to use graphics optimized programs you kinda have to use Nvidia and that&#x27;s still problematic on Linux. reply babypuncher 17 hours agorootparentprevI think part of it is because a lot of these more user-oriented features (desktop compositing, sandboxed app stores, hdr, etc.) don&#x27;t get a lot of attention on Linux until after the two major commercial operating systems get them and prove people actually want them.The monied interests driving a lot of Linux development do not have the same need for these things as end users. To them, Linux is a server, or a lightweight embedded OS, or needed for some other specialized use case. reply ragnese 16 hours agorootparentThat&#x27;s absolutely the issue. Linux on the desktop is extremely niche, and as such, it doesn&#x27;t get much attention. reply beebeepka 16 hours agorootparentprevMy experience does not match your assertions. The Linux desktop has never been more accessible.My mother in law has been happily running manjaro with gnome for a while. Now, truth to be told, she was navigating gnome 2 Ubuntu more than a decade ago but things were mostly not working back then. Upgrading versions was a minefield with mostly terrible results.Maybe the state of things suited you better somehow. I just can&#x27;t imagine how. reply throw555chip 17 hours agorootparentprev> Honestly, when it comes to \"just working,\" desktop Linux is worse today than it was when I first installed it on my budget laptop in 2007.I bought a new Alienware PC in summer 2022, installed Ubuntu immediately, wiping Windows. Everything worked. Still does. This happens on every new Dell (or Alienware), HP or Lenovo desktop or laptop I&#x27;ve bought the past 2 decades. I can&#x27;t buy a new machine that has issues with Linux, what on Earth could I be doing wrong that they all work.Honestly, do you work in Microsoft marketing. reply ragnese 16 hours agorootparent> Honestly, do you work in Microsoft marketing.I shouldn&#x27;t feed the trolls, but I&#x27;ll take the bait this time.Read my comment again. In it I literally say that I run Linux exclusively on my personal machines. I don&#x27;t have a Windows computer in my home and the only Mac I have that&#x27;s still running macOS is a work-issued laptop. What are your Linux-never-Windows credentials? Because I bet they don&#x27;t beat mine unless you&#x27;re just significantly older than me and have been doing the same as me but for longer.If one were to read my comment history, they could only conclude that I&#x27;m a huge Microsoft hater&#x2F;skeptic.Given that the ONLY mention of Microsoft or Windows in my comment was a statement that hardware manufacturers only test their drivers with Windows, this comment is just a strange emotional reaction to my point.> Everything worked. Still does.Read the rest of the thread about Flatpak and Snap. Read people&#x27;s complaints about Wayland. Dig up some old discussions about PulseAudio and Xorg and how we used to have to hand-edit xorg.conf files to set up multiple monitors. If you insist that there are no problems, shortcomings, or missing functionality with Flatpaks, Snaps, and Wayland, you&#x27;re deluding yourself. reply saltcured 11 hours agorootparentI&#x27;m in that older+longer cohort so I&#x27;ll comment...I think you are talking about workflow-breaking changes or stability issues during transitions to newer Linux bits. You explicitly excluded hardware&#x2F;driver issues that a lot of people gripe about with Linux on laptops. I think your experience here can vary dramatically depending on your choice of Linux distribution, your upgrade tempo, and your expectations.I&#x27;ve had some frustrations with the UEFI transition and secure boot, because it forced me do research when I just wanted my system to boot. I&#x27;ve similarly suffered some regressions with MATE recently, where it boots to a black screen and I had to dig around to find that switching to a text console and restarting lightdm would get it unstuck. I&#x27;m struggling to answer whether these are \"driver\" things or not.But, I&#x27;ve been on Fedora for ~20 years now and am happily oblivious to Flatpak, Snap, or even Docker because they have nothing to do with my day to day experience. I also don&#x27;t think I&#x27;ve dipped my toes into Wayland yet. I&#x27;ve been using XFCE or the MATE desktop rather than GNOME. But I do remember when ALSA was the new thing, then pulseaudio, and now pipewire. I mostly didn&#x27;t care unless trying to setup some specific sound peripheral. I never had btrfs anywhere except an experimental system, because I always customized partitioning and never really considered the defaults to matter.If I exclude hardware&#x2F;driver issues, it seems like this same story applies to Windows. It all depends on what part of the ecosystem you consider to be part of your platform experience. Some people might have some favorite apps that essentially work the same as 25 years ago, while others have experienced multiple upheavals as third parties abandoned or hijacked an old favorite application or forced some kind of migration. It&#x27;s only gotten worse with all the rent-seeking cloud integrations with everything. reply bmicraft 20 hours agoparentprevThe thing about snap and flatpak is, that while canonical is heavily pushing snaps, the community seems to be mostly behind flatpak.What this boils down to for regular use is that some big companies only offer a snap for their proprietary app while most open source stuff seems to be on flatpak. With significant overlap of course. reply amelius 19 hours agoparentprevSnap can&#x27;t even fix basic things. Like running stuff over X11, or having your homedir on a different harddrive than &#x2F;. reply akvadrako 17 hours agoparentprevEnough of the the community is behind Flatpak that it&#x27;s possible to run an immutable distro and get most of your apps as flatpaks without much trouble.Snap is terrible; there is no reason to consider it. Mostly because there is only one app store allowed and it&#x27;s really slow to launch apps. reply throw555chip 17 hours agoparentprev> I hope the community really gets behind Snap or FlatpakNO. No. No. No Snap. No flatpak. No rolling release distribution nightmares either. Standard LTS for me (with snap and flatpak disabled with an apt preferences file). reply bmicraft 16 hours agorootparentA standard stable LTS system with the ability to update your gui apps is basically what flatpak is all about. I agree though that Canonical is trying too hard to move system packages over to snaps. reply smoldesu 19 hours agoparentprevIdeally, we get the best of both worlds. The isolation technology that Flatpak uses (bubblewrap) isn&#x27;t exclusive to Flatpaked apps, so someone could probably make a distro with isolation by-default if they were motivated enough.> What distro would you recommend to somebody like me who wants to be asked before an application gets accessUse an immutable distro like Silverblue or Kinoite. Those are more-or-less Flatpak-only, extremely stable and fairly rigid with security. reply ElectricalUnion 17 hours agorootparent> The isolation technology that Flatpak uses (bubblewrap) isn&#x27;t exclusive to FlatpackedI wish flatpacked apps actually used the isolation (most don&#x27;t, so http:&#x2F;&#x2F;flatkill.org&#x2F;2020&#x2F; is still true today) but that isolation is mostly under the control of the packager, not you.On this point, Deno ( https:&#x2F;&#x2F;docs.deno.com&#x2F;runtime&#x2F;manual&#x2F;basics&#x2F;permissions ) and pledge.com ( https:&#x2F;&#x2F;justine.lol&#x2F;pledge ) are better; you have to explicitly allow-list what you want, instead of hoping that the potentially very untrustworthy and third-party packager had your best interests in mind and denylisting what you don&#x27;t want. reply ForkMeOnTinder 16 hours agorootparentMost casual users want to see a quick list of permissions and just click allow---not build their own allowlist for every app they download.If you want to build the allowlist yourself, doesn&#x27;t firejail already do what you want? reply criddell 16 hours agorootparentIt would be nice to grant permissions in a fine grained way and not just have a blanket accept or reject. For example, if I download a weather app, chances are it will want location and internet access. If I don&#x27;t want it to have my precise location I should be able to deny location but grant access to the internet. reply AtlasBarfed 19 hours agoparentprevSnaps are a dumpster fire on Ubuntu. In particular Firefox.Flatpak... I tried a dosbox flatpak and it was 3 gigs. Regular package? 3 megs.I run Linux mint to avoid them as much as possible. All of the flatpaks pretend nobody has files somewhere other than the home directory, and softlinks don&#x27;t work. Have a mdadm raid in &#x2F;mnt? Can&#x27;t see it.So basic frequent use cases can&#x27;t be supported by a \"modern security and permission system\". Then no thanks.All communication of this with the developers of snap, for example, are dismissed with a high amount of condescension. Which is pretty typical with most things whenever you have to deal with security. They imposed the dogma, and you have to comply to it.And the delay whenever the snap has to interact with the file system, there&#x27;s like a 5 second delay every time it happens. When trying to access a SSD based file system. That is unacceptableLook we do not have infinite Moore&#x27;s law steppings, or gigahertz of serial speed coming down the pipeline. Moore&#x27;s law is running out. We can&#x27;t be adopting some system like a stealing light, 50% of the practical performance of the user interface. Hard disc drives are going to start to not get bigger. The technologies we use for increasing the size of hard disk now already reduce the reliability of the drive.So snaps in their elk really are not something I look forward to. For now just run the distro&#x27;s lake Linux mint which doesn&#x27;t use them reply fanatic2pope 17 hours agorootparent> I tried a dosbox flatpak and it was 3 gigs. Regular package? 3 megs.You are counting the runtime size. That is shared between all apps that use the same runtime. As I already had it installed for another app, the download size for the dosbox flatpak on my fedora machine was 1.6MB.I also recommend installing flatseal to easily see and manage file access permissions of flatpak apps. reply avgcorrection 20 hours agoparentprev[deleted] reply signaru 19 hours agorootparentThis is why I&#x27;ve been using Firefox downloaded directly from Mozilla for a while now instead of the broken one shipped with Ubuntu. I just need to manually update via the \"Help -> About\" every once in a while, but things look much better otherwise. reply ComputerGuru 15 hours agorootparentYou don’t need to do that. You can install it via apt from the Mozilla ppa, then it updates automatically along with everything else. reply signaru 8 hours agorootparentIt&#x27;s nearly a year now that I am using Ubuntu 22.04 (and that the Firefox from Mozilla has no problems) so I don&#x27;t remember all the details. I also tried using the apt version of Firefox as others also suggested. But it eventually got automatically replaced with the snap version after an update. reply avgcorrection 19 hours agorootparentprevThanks, I’ll try that soon. Chrome has nothing that Firefox doesn’t have, for me. As long as it works. :) reply bmicraft 20 hours agorootparentprevIt&#x27;s a well known fact that firefox startup time when packaged as snap is significantly worse. This should be less noticeable for actual use.> On Firefox 119 I thought I was losing my mental faculties (even more) since I kept losing track of the cursor for a whole day. Turns out that it’s a Windows “feature” where you hide the cursor when you start typing into some input box. Maybe this is a Firefox-wide regression on Linux though. Difficult to find other examples of it on Linux via Google.Firefox hides the cursor while typing, but it should unhide as soon as it&#x27;s moved (at least it does for me)> - More fun than a problem: `firefox --version` spews a warning: `update.go:85: cannot change mount namespace according to change mount ...` > - My dear XCompose wasn’t respected because of course you have to copy it to inside some dang `&#x2F;home&#x2F;me&#x2F;snap&#x2F;common&#x2F;utensils&#x2F;computer-applicances&#x2F;apps&#x2F;Firefox` treeThose should both be snap specific.> - The keyboard just does not work sometimes. No other apps seem to have this problem. So it’s apparently not some idiotic “applications that use X work but under Wayland it doesn’t” (or vice versa). Does a restart help? No. Seemingly only a computer reboot.I don&#x27;t know about that one. Could be Ubuntu or snap, but it does not happen on Arch. Out of curiosity, are you running firefox through xwayland or native wayland? (It says so on the about:support page under \"Window Protocol\") reply AtlasBarfed 19 hours agorootparentprevNow try saving something from Firefox.By default, it shoves it into some parallel file system within the snap.Oh did you forget to actually explicitly save it into the downloads directory? Yeah, you have no idea where it is now.Oh and of course when the download file explorer widget opens up, you can&#x27;t get the mouse focus. Probably because there&#x27;s some security boundary between Firefox and the file system.Usability of firefoxes vastly decreased as a result of snapsFinally, well this isn&#x27;t a big deal to me. Apparently a lot of the open source people don&#x27;t like it because the Firefox nap is basically just a call. The internet pull down binary command that pulls a huge binary blob and they don&#x27;t like this. reply antod 10 hours agorootparentWeird. I use the Firefox snap (due to my lazy inertia), and my saves&#x2F;downloads are all in $HOME&#x2F;DownloadsI don&#x27;t think I did anything to change that either. reply avgcorrection 19 hours agorootparentprevYes! Downloading things in Firefox has been annoying too now that you mention it. reply ComputerGuru 15 hours agorootparentI know what you meant but generally really unfair to even mention or phrase it like that. “Downloading things in snap” is more correct.Snap has done such a disservice to open source software’s perceived quality. replyjklinger410 18 hours agoprevTangentI have this suspicion that Windows has basically a layer of analytics tracking over the top of the DE that slows the system for most desktop uses, and that they essentially \"tunnel\" through that layer when a program actually needs the performance. Like gaming or exporting a video project.This is why Windows is able to benchmark high for specific tasks, but for overall usage it feels very slow compared to every linux desktop.Am I crazy or is there a nugget of truth there? reply whalesalad 18 hours agoparentBrother we have known this for years. reply jklinger410 17 hours agorootparentThat&#x27;s good to know! Is there any formal proof of said theory? Like what is this analytics layer called, and is the tunneling something that devs are aware of? Just interested in putting some names to this theory so I don&#x27;t sound like a loon when I try and describe it. reply whalesalad 17 hours agorootparentOh it&#x27;s definitely still a theory - but we&#x27;ve collectively proven it through our anecdotal experiences over the last 20+ years of using Windows. reply _Algernon_ 16 hours agorootparentThat is not how it works lol reply whalesalad 15 hours agorootparentIt doesn’t actually work that way, but the net result is the same. Windows is a Trojan horse that manifests itself as an OS but is really just a delivery mechanism for crap from Microsoft. One drive. Cortana. Edge. It’s all so invasive. replyunderseacables 20 hours agoprevI&#x27;ve been playing around with Ubuntu training myself for the day that I have to give up windows 10. My only complaints are that Linux can be tedious, everything is just 43 commands away; it requires greater understanding of not just what the system is doing, but how it is doing it; and the documentation is written like a Wikipedia article on advanced nuclear theory.Windows and OSX have, for the most part, just worked, and it was easier for me to understand what was going on, and how to engage tasks, fix problems, and use the system. With Linux it can feel like I&#x27;m fighting with the system at times.I&#x27;m enjoying the experience but it has not been without frustration. Perhaps I should have chosen another flavor? reply okr 20 hours agoparentNo worries. I have installed windows 11 lately and i find it tedious. It constantly wants to register me somewhere, it asks me to have this as standard, and it is always updating something and asks me to reboot. And why i cant remove certain things from my taskbar? So, i guess, we both have out difficulties. Like always. reply underseacables 20 hours agorootparentWindows 11 should be classified as a hate crime.. Just the fact that I&#x27;m deceitfully \"required\" to create a Microsoft just to use the system is an abomination. On some systems, I&#x27;ve seen that there is a way to bypass that account creation, and just have a local account, but it was so hidden and deceitful that it was… emotional.. reply johnbellone 19 hours agorootparentThis isn&#x27;t any different than being \"required\" to create an Apple account. I agree that it is a problem that both systems make you jump through hoops to use them without doing that, but it doesn&#x27;t seem to elicit the same emotions that come from it being Microsoft.They&#x27;re both trillion dollar companies that only care about keeping you in their walled garden. reply rad_gruchalski 19 hours agorootparent> This isn&#x27;t any different than being \"required\" to create an Apple account.There&#x27;s no requirement to create an apple account. reply mmcnl 15 hours agorootparentThe same goes for the Microsoft account. That&#x27;s the whole point. I have been happily running Windows without a Microsoft accounts for years. You can just skip the step during installation. reply johnbellone 16 hours agorootparentprevThere isn&#x27;t a requirement to create a Microsoft account, either. reply MenhirMike 15 hours agorootparentActually, Windows 11 Home does require one. And I don&#x27;t mean \"You can just be offline\" or \"Just click use Domain Account\", but actually \"Without Internet and a Microsoft Account, you cannot continue\".Maybe someone found a script&#x2F;custom installation image, but the previous posters point about it being required stands for that one SKU at least. (I hope that there&#x27;s a EU version that one can acquire in the future that gets around that, but I don&#x27;t know if the Account requirement falls under the current legislation.) reply underseacables 15 hours agorootparentprevIt varies apparently. HP laptops have no option for local account as of four months ago. It&#x27;s a hard stop. reply beebeepka 15 hours agorootparentprevIndeed there isn&#x27;t. I bought an OEM license for gaming and decided to unplug my ethernet just in case. Wasn&#x27;t asked to create an account. Not sure if this is the only way to avoid it short of installing one of those cool corporate builds.I read things will improve next year thanks to the EU, though: https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;11&#x2F;europeans-can-soon-s... reply geodel 18 hours agorootparentprevAs both Windows&#x2F;Mac user Windows seems way more aggressive with have this online account. I don&#x27;t know its got that kind of hectoring tone. Well you&#x27;ve been stalling for 2 months and now its time to have login created. reply bitwize 16 hours agorootparent\"Windows is a service and updates are part of that service. So if you could reboot to apply updates, say, now, that would be terrific.\" reply jacoblambda 20 hours agorootparentprev> And why i cant remove certain things from my taskbar?You actually can, it&#x27;s just they don&#x27;t expose most of it to the user. However people have built tools [1] that give you a pretty UI to manage those more complex configs and apply them to windows. Bonus points in that you can use all the old windows UI elements from previous versions of windows and mix and match them as you choose.Honestly I couldn&#x27;t tolerate Windows 11 without something like ExplorerPatcher.1. https:&#x2F;&#x2F;github.com&#x2F;valinet&#x2F;ExplorerPatcher reply arrty88 19 hours agorootparentbe careful. i used this for a while, but then windows updated and ended up bricking my normal user account. had to go into safemode and figure out the incantations to uninstall and resolve. all during a high priority time for needing my computer of course. reply jacoblambda 9 hours agorootparentYeah I&#x27;m not sure how long ago you used it but ExplorerPatcher nowadays is setup so that it disables itself if explorer crashes more than like twice in a row so that you can debug the issue. Normally it&#x27;s just a matter of fetching the new symbols (which happens automatically) and occasionally updating. Afterwards you can relaunch EP... or you can just leave it disabled if you are busy. reply mmcnl 15 hours agorootparentprevI honestly don&#x27;t understand how macOS and Linux are better with respect to OS updates. With Ubuntu I always have to update and reboot, almost weekly. And with macOS if there&#x27;s an update, you can at least schedule it, but not without this big bright red notification badge that&#x27;s always in your face and can&#x27;t be dismissed. reply libraryatnight 17 hours agorootparentprevI&#x27;ve been able to disable most of the things I do not like on win11 pro, so far, but if it weren&#x27;t for how much I use Ableton I would be all in on Linux at this point.If anybody knows anyone at Ableton, please tell them to do a Linux edition :P reply bitwize 16 hours agorootparentOr at least check that it works on Wine. I find these days that when Windows programs work on Wine they work very, very well. reply beebeepka 15 hours agorootparentHah, a friend of mine was swearing it wouldn&#x27;t work. How&#x27;s performance and latency? reply okl 20 hours agorootparentprevMaybe this tool can help you disable some of those things: https:&#x2F;&#x2F;www.oo-software.com&#x2F;en&#x2F;shutup10 reply eldaisfish 20 hours agorootparentprevi really dislike this line of reasoning. Windows has a much larger installed base so finding support and solutions are pretty easy. Whether that is a video, a blog or a forum, you can always find someone with the same problem.No, windows nagging you to register is not in the same ballpark as your audio not working or your video resolution changing with multiple monitors. No, windows updates adding or removing features are not equivalent to the problems linux has, many of which are showstoppers.You&#x27;re trying to be snarky and this is one reason why so many regular Joes are reluctant to adopt linux. you never know when you will need the terminal and when you will encounter an unhelpful response like this. reply okr 20 hours agorootparentSo serious. I find the linux community indeed very resourceful. And the ones for windows, after you have clicked thousands of banners away, that tell you the workaround for avoiding the registering after a long text of nothing, i find them resourceful too.My point was, that it is always difficult to enter a new domain. So it is a shared pain. reply ffgjgf1 19 hours agorootparent>I find the linux community indeed very resourcefulI do to. As a “power user”, however it feels that for people who don’t know how&#x2F;fear&#x2F;don’t want to use the command line and don’t know how to read documentation accomplishing even basic stuff on Linux would be a struggle. reply bitwize 16 hours agorootparentprevThe old joke goes, though, that you have to prompt-engineer the Linux community to get a useful response, e.g., \"Linux sucks because I can&#x27;t do X\" instead of \"How do I do X?\" reply eldaisfish 19 hours agorootparentprevMy limited point here is that linux has a lot of problems that are showstoppers. You sometimes cannot do what you want to do.The average person cares about about usability first. Visually, linux is excellent and very useable. The problem is, should things go wrong, the level of technical skill needed to use community resources is relatively high. reply ffgjgf1 19 hours agorootparent> Visually, linux is excellent and very useable.On a superficial level maybe. But generally it’s still very unpolished, inconsistent and has poor UX design. Of course it’s matter of taste.Not sure why your comment is being downvoted though? I find it hard to imagine how could anyone disagree with it from the perspective of an “average” computer user. reply deafpolygon 19 hours agorootparent> But generally it’s still very unpolished, inconsistent and has poor UX design.Came here to say that. If you stick to the 2 or 3 desktop apps that they offer and do everything else in a terminal, then no worries. But the minute you try to get things done, beyond just the terminal - it comes apart. reply soupbowl 18 hours agorootparentprevI don&#x27;t disagree with you but have you ever had to google a windows issue in recent history? You get 90 links of &#x27;Microsoft experts&#x27; that ask you to run \"sfc &#x2F;scannow\" or \"chdsk\". None of them having a clue what they are talking about.I think it is usually easier to fix windows if you have &#x27;audio not working&#x27; but windows 10+ has started to have a lot of non trivial issues and there are no simple google fixes. I have had serious problems as an IT worker with EVERY large windows update in the last 3 years.On the other side of things, I have seen linux desktop issues that are a nightmare to figure out, including audio not working after a recent update. reply spogbiper 16 hours agorootparent> You get 90 links of &#x27;Microsoft experts&#x27; that ask you to run \"sfc &#x2F;scannow\" or \"chdsk\".adding the word \"reddit\" to the search usually improves the results significantly reply RealStickman_ 19 hours agorootparentprevI tried searching for workarounds of network shares causing explorer freezes when no connection can be made.The only \"solution\" I found was sfc &#x2F;scannow reply FirmwareBurner 19 hours agorootparentprev>And why i cant remove certain things from my taskbar?IDK, because the real question here is why can&#x27;t YOU do it? Because that&#x27;s definitely possible, anyone can do it with a few clicks from the GUI, there&#x27;s nothing stopping you from doing that.Pretty sure my 5 year old nephew can figure out how to get to Right click -> Taskbar setting, where stuff can be removed from the taskbar.There are plenty of faults with Win11, but the fact that you haven&#x27;t managed this, is more an issue on your side (\"I tried nothing and it doesn&#x27;t work\") rather than with the product in question.Excuse the bluntness but I&#x27;m tired of seeing all the FUD spread on HN and I need to correct it. reply okr 19 hours agorootparentHow do i remove teams or the stupid weather badge from the task bar? I can remove explorer and edge with a right-click, just those two i can not. It is inconsistent.That it is not impossible with a few more clicks and that i have to know, where to find it, well, duh. reply FirmwareBurner 19 hours agorootparent>How do i remove teams or the stupid weather badge from the task bar?In the time you have written this rant&#x2F;question here you could have typed it instead in Google, Copilot or ChatGPT and have gotten your answer already instead of falsely complaining that \"its impossible to remove something\" when it&#x27;s not.Yes, some things will always be unintuitive to the user that&#x27;s new to any OS, but that&#x27;s the issue with any other OS including MacOS and Linux distros when you&#x27;re brand new to them and use it for the first time.There&#x27;s always gonna be a learning curve and you&#x27;ll need to Google a bit to figure some stuff out in the beginning regardless of your OS of choice, but that&#x27;s a long way from saying \"it cannot be done\" when the main issue is you can&#x27;t be bothered to Google something basic.Excuse the bluntness here in my comments, but how do people manage to get into highly paid technical careers while not being able to Google \"how to remove X from Windows taskbar?\". reply deafpolygon 19 hours agorootparentprevOn Windows 11- Right click Taskbar- Choose \"Taskbar Settings\"- Untick Widget. Weather badge gone.- Untick Teams (if you have it- I don&#x27;t, and don&#x27;t have Teams popping up) reply mikub 18 hours agorootparentSometimes I think people compalaining about windows are just to lazy to look through the settings and search for the things they want to change. Windows has a lot of things to complain and be &#x27;angry&#x27; about, but 90% of the issues I see people mentionning are completly solvable with a few clicks. reply FirmwareBurner 18 hours agorootparent>Sometimes I think people compalaining about windows are just to lazy to look through the settings and search for the things they want to change.Sometimes?! replynoir_lord 20 hours agoparentprev> Perhaps I should have chosen another flavor?That&#x27;ll ignite a holy war.The trick with linux isn&#x27;t to learn the flavour, it&#x27;s to learn linux - once you get an overview of how all the bits work then switching distro is (much) more straightforward.Ubuntu is an excellent first choice because it&#x27;s one of the major distro&#x27;s so you&#x27;ll be able to google stuff more easily.My personal recommendation would be Fedora (and if you want a familiar windows 10 at least in approach GUI) Cinnamon which is excellent. reply chx 20 hours agorootparentWhere do I learn modern desktop Linux? I am using it on servers since 1993 and used for desktop 2004-2017 (and was very unhappy with it) so my desktop knowledge is severely outdated. reply LeJC 19 hours agorootparentThis is almost me. I used Linux on and off over the last 15 years. Mostly in servers, but I often installed a linux partition to try it out.I always went back to windows since windows was much simpler and I thought KDE and Gnome was similar anyway, I didn&#x27;t see any benefit in switching.I permanently switched to Linux in august. I found out about window managers and now I see a real benefit on using Linux over Windows. As much as I&#x27;m forced to use windows at work and I try to emulate the functionalities of a WM.What helped me is support for most of my devices. Linux progressed a lot in the last few years. reply chx 14 hours agorootparentCan you hotplug a GPU or do you need to still (effectively) reboot? (I know it&#x27;s only the windowmanager that needed a restart but if all programs run under then, well.) reply LeJC 11 hours agorootparentWhat do you mean? Switching between integrated and dedicated GPU? Or opening your case and directly removing or adding a GPU?If its the first, I think there is support for this. There&#x27;s NVIDIA optimus for NVIDIA for instance.The second one, I never thought it could be a use case, even less that Windows would even support that. I always turn off my computer to do anything on my motherboard. reply chx 11 hours agorootparentI mean eGPU over Thunderbolt. reply LeJC 9 hours agorootparentOh yeah, didn&#x27;t think of that one. Following what&#x27;s written on arch wiki https:&#x2F;&#x2F;wiki.archlinux.org&#x2F;title&#x2F;External_GPU, Xorg doesn&#x27;t support it and never will. Wayland seems to support it, but I don&#x27;t know what it implies in use. The issues for KDE, Gnome and wlroot are all mergred. replyblkhawk 19 hours agorootparentprevI would be really interested what you were unhappy with? the only major thing that truely changed after 2017 was that wine became almost universally compatible.It was freakish how little issues i had in 2019 when i switched completely. reply antod 10 hours agorootparent2017 was in the early phase of pretty disruptive era with Linux - eg systemd, audio, wayland, app sandboxes etc etc. I get the feeling things are settling now, and stabilising &#x2F; consolidating into a better place overall with less churn. But for a while things weren&#x27;t as stable as they typically were before that. reply trey-jones 17 hours agorootparentprevI&#x27;m not sure what there is to learn, if you have a good working knowledge of Linux servers. This is exactly why I prefer the terminal to any of the GUI components that may exist. Much more stable interface. As far as programs that I use daily, other than a few obscure VPN clients, I&#x27;ve rarely, if ever, needed anything that I couldn&#x27;t find on AUR. For that reason and for reasons of having up-to-date software available, I like something in the Arch family for Desktop use. On the other hand, .deb packages are often available for more obscure software like those VPN clients... reply twic 17 hours agorootparent> I&#x27;m not sure what there is to learn, if you have a good working knowledge of Linux servers.Everything about the graphics and windowing stack, for starters. Why isn&#x27;t my external display being detected after waking from sleep? Why is it always set to the wrong resolution at boot? Why doesn&#x27;t VLC have any controls? Why is this simple Unity game suddenly running at 2 fps?Thermal management, CPU governors, that sort of thing. Not really an issue on servers, occasionally misbehaving on laptops.Occasional stuff around device connectivity - bluetooth speakers, NetworkManager, etc. reply stevenjgarner 18 hours agorootparentprevDepends on your focus. If it is privacy or security, you may want to consider Tails and Qubes OS recommended by Edward Snowden.[1] https:&#x2F;&#x2F;tails.net&#x2F;[2] https:&#x2F;&#x2F;www.qubes-os.org&#x2F;[3] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=s8-B9d7iz1A reply red-iron-pine 14 hours agorootparentQubes is cool, but Tails is for Tor and is meant to be a boot-from-live-cd or flash drive.The whole point is that you want all instances of Tails to look the same on the network so they can&#x27;t fingerprint you. Once you start making it a daily driver, picking up a lot of cookies, making it your own, etc. then the point of using it is moot. reply orangepurple 19 hours agorootparentprevInstall Gentoo if you want to learn how a modern functional Linux system is put together reply oldnetguy 20 hours agorootparentprev> That&#x27;ll ignite a holy war.And that has been the major problem with Linux for years. reply SV_BubbleTime 18 hours agorootparentThe duplication of work is staggering. The best people at Mint are working on the same problems as those at Fedora and PopOS and Cube and Suse … infinite loop. reply xattt 20 hours agorootparentprevAny comment on Arch one you get going? I find the documentation quite thorough for the niggly bits, and have used it to troubleshoot Ubuntu (taking into account differences between the distros). reply II2II 19 hours agorootparentI am an Arch enthusiast since I like building my system up and learning how things are put together, but it is not a terribly good platform for learning how to use or manage a Linux system. One of the issues is that you end up with a system is tailored to your own needs. While that sounds great, you have to make an effort to generalize those skills since no one else will have a setup quite like yours. reply underseacables 20 hours agorootparentprevThank you, The documentation is really important for me I guess. I feel more comfortable with documentation carefully laid everything out; screenshots are gold.Is there a book that you would recommend that would help a novice like myself learn Linux better? reply aarond0623 19 hours agorootparentIMO, the best way to get comfortable with Linux is to get comfortable with the command line, because although every distribution is going to have different UI and built-in apps, the command line is going to stay pretty consistent. Also, a lot of troubleshooting you Google is going to involve interacting with the command line, and it&#x27;s essential to understand what the commands you&#x27;re executing are actually doing.I&#x27;d recommend The Linux Command Line by William Schotts to get started. reply blowfish721 17 hours agorootparentWas trying to configure a network bridge for a vm just the other day from cli. The guide (for Ubuntu which I was also using) was using nmcli (Network Manager), tried it and command not found, back to searching and was nudged to systemd networking by stackoverflow which didnt work either. Turns out that my system was using Netplan. Three different systems to handle networking, really? Ok, chatgpt convert this nmcli command to netplan, sure here you go just put this in your netplan config file and apply config. Ends up with a botched network config on a headless system. reply iam-TJ 15 hours agorootparentnetplan(.io) is an abstraction layer on top of either NetworkManager (GUI installs) or systemd-networkd (servers&#x2F;non-GUI) and is not really needed except as a convenience for Canonical&#x27;s own designs for automated mass deployments especially linked to cloud-init. Under the hood it just converts its YAML configuration files into the syntax for the underlying actual network management tool.For NetworkManager it&#x27;ll write the config file to &#x2F;run&#x2F;NetworkManager&#x2F;system-connections&#x2F; and for networkd to &#x2F;run&#x2F;systemd&#x2F;network&#x2F; on EVERY boot since &#x2F;run&#x2F; is a tmpfs (file-system in RAM).For almost all servers, and most workstations, netplan is an unnecessary indirection since most hosts (including containers) have pretty static network configurations that only require writing once (to &#x2F;etc&#x2F;NetworkManager&#x2F;system-connections&#x2F; or &#x2F;etc&#x2F;systemd&#x2F;network&#x2F; ).nmcli is the NetworkManager command-line tool. There is also nmtui for a text user interface. These are terminal alternatives to the GUI applets such as nm-applet (network-manager-gnome) or plasma-nm for KDE.networkctl is the CLI interface to systemd-networkd. There is no widely used GUI interface to it (yet). reply programd 15 hours agorootparentprevThat&#x27;s the exact experience I went through about a year ago trying to set up a bridged VM on a headless Ubuntu system. I mean right down to the sequence of nmcli, systemd, and Netplan, winding up with wiping it all away and just running Virtual Box on a way overpowered and mostly idle Win 10 system. Because I just wanted to run a VM connected to my local LAN.Linux networking and DNS resolution, while working fine for the happy path, are a dumpster fire from a system management viewpoint. Especially if you want to do anything even mildly off-script. And I say this as a Linux user since before the kernel hit 1.0.I don&#x27;t know, maybe it&#x27;s just a documentation problem. The accumulated junk of 50 years of obsolete documentation that you have to wade through to find out that the whiz-bang Linux distro you&#x27;re using today is not the Linux which worked fine last year.The exit off my lawn is in this direction. reply TrueSlacker0 19 hours agorootparentprevAnd that right there is why Linux is so frustrating to start with. It is easier to solve most problems via command line however a normal user should never ever have to touch a command line. Everything for a common person should be easily accessible via a gui. reply veqq 18 hours agorootparent> Everything for a common person should be easily accessible via a gui.They are. Just there are many different GUIs. Each distro by definition has different ones and you can easily change them yourself etc.There are dozens of sound GUIs, hell, I&#x27;ve tried 4 redshift GUIs before settling on QRedshift. It&#x27;s so easy to write software for Linux that you have countless opportunities. That&#x27;s why the command line is easier - it always works(ish). reply SV_BubbleTime 18 hours agorootparentprevOnly way to do it is to do it.- try something like Mint if you are used to windows and PopOS if you are used to OSX- remember that everything in GUI has a commandline equivalent reply vorticalbox 20 hours agorootparentprevI have been eyeing up Fedora Onyx for the immutable root reply totallywrong 18 hours agorootparentI&#x27;ve been using an immutable Fedora for quite a while now and it&#x27;s amazing. I use toolbox and run everything in containers, including GUI apps, so not even using Flatpak which I&#x27;m not a big fan of. I think I have like 3 or 4 packages installed on top of the base image. The peace of mind while upgrading can&#x27;t be overstated. Highly recommended. reply vorticalbox 15 hours agorootparentI run mongodb for work and that requires openssl1.On Ubuntu I just copy the libs over to &#x2F;usr&#x2F;libBut that wouldn&#x27;t be an option on an immutable system.I will look into toolbox.Edit: looks like tool box is exactly what I&#x27;m after! reply stingraycharles 20 hours agorootparentprevYou mean Fedora Silverblue? Haven’t heard of Onyx.Edit: ok so I learned about Onyx, which appears to be doing roughly the same thing? reply palebluedot 19 hours agorootparentThere are different spins of Fedora that are immutable and based on rpm-ostree and flatpaks, the variation being the desktop manager environment:* Silverblue: GNOME* Onyx: Budgie* Kinoite: KDE Plasma* Sericea: Sway reply bryanlarsen 19 hours agorootparentAnd don&#x27;t forget the community spins based off ublue, like Bazzite! reply KAMSPioneer 19 hours agorootparentprevJust installed Onyx yesterday on my work machine! So far so good, some niggles as always (it&#x27;s my first time using Budgie), but overall fairly usable and easy. reply pawelduda 19 hours agoparentprevSame here but the other way. I find Linux much simpler to grasp than endless hard to navigate menus, windows where each is from different land, registry, shell and what not. I rarely use Windows but when I do, it feels like MS either ruined it or I simply forgot how to do things. I used to think like you so I guess it&#x27;s just a matter of taking the leap and learning new OSBonus points: no ads, no Edge or Drive bullshit, nearly any small quirk that annoys me can be rid of (which admittely can take some effort BUT it can be done)Example: - Linux: just type the command vetted by hundreds of people on StackOverflow to edit the config file - Windows: open app, click this and that... Where is it? Ohhh outside of screen because it uses super duper stylish gaming UI. Let me change system-wide UI scaling just to see thing I want to toggle. No, there was no way to just drag that window. reply secondcoming 19 hours agorootparentIf you’re having to faff about with the registry every day you’re doing it wrong! reply yjftsjthsd-h 19 hours agorootparentIf you&#x27;re having to use the terminal for anything other than your own work (actually even then it should be optional, but I find it easier to run make&#x2F;gcc&#x2F;etc. directly vs using an IDE) everyday something has also gone wrong, so I think it&#x27;s a fair comparison. reply thomastjeffery 18 hours agorootparentprevIf you are never having to faff about with registry, then you are either lucky or using a different OS.I include installing a fresh copy of Windows to resolve the inevitable corrosion that Windows has over time. reply pawelduda 18 hours agorootparent> I include installing a fresh copy of Windows to resolve the inevitable corrosion that Windows has over time.Remember that one from the past and countless times I had to do this for others because Windows would become a mess.Nowadays I just upgrade old Linux distros running for 5+ years because of security concerns or out of boredom. Magically still running same as fresh install reply thomastjeffery 13 hours agorootparentOne of my favorite things about NixOS is that this problem is permanently solved. replyINTPenis 19 hours agoparentprevI&#x27;m a Poweruser of Linux since the late 90s and I can tell you that if you&#x27;re a Windows or Mac poweruser with zero Linux experience, you&#x27;re not going to have a good time in Linux.Linux has come amazingly far, but I still wouldn&#x27;t recommend it for everyone.It&#x27;s all about context. You&#x27;re a power user so you&#x27;re going to want to do advanced things, which requires total immersion in a completely different ecosystem.But my 80 year old father on the other hand, he just wants to edit documents, scan images, browse facebook and play solitaire. He can run Fedora Silverblue with no problems. reply unsungNovelty 19 hours agoparentprevI have been using using Linux for 16 years in total and 7+ years as my primary OS.Ubuntu itself is a performance hog due to snaps. And Ubuntu is NOT beginner friendly. As an ex-IT guy and as a linux enthusiast, It was not when I deployed it to developers and tech people in my company. And it is not beginner friendly when I install it to my friends & family.I used to use Ubuntu for work until last week. Used it because of the worry for Ubuntu compatibility since most work related tools etc supports Ubuntu if you want to use Linux at work. It used to use 7.5-8GB ram and >40% CPU. So I switched to Linux Mint. It is based off Ubuntu but it is faster & is better for UX. And I have been using Linux Mint since monday. Ram usage wend down to only max 6GB RAM andManjaro unstable -> Manjaro testing -> Manjaro stable cycle for a package. Things started breaking and they were hostile to the community which resulted in a new forum. I have both technical and reasons of morale to ditch Manjaro being an early ~2016 Manjaro user.I also have a sour taste regarding Manjaro because I was one in the minority of people who supported them when they wanted to kickstart a company with Manjaro. I am also going to ignore the whole issue about the leadership issues and outsting of Jonathon (R.I.P Jonathon!). I walked away from Manjaro because there was no technical reason or joy to use Manjaro and partly for Jonathon. He was the glue for our community. Old Manjaro users know how awesome their community was initially. reply katsura 18 hours agorootparentThank you for the detailed explanation! I didn&#x27;t know about any of that. I either got \"lucky\" and switched to Mac before all these happened, or just didn&#x27;t pay enough attention to see these changes. reply unsungNovelty 17 hours agorootparentI mean, if you didn&#x27;t know, you probably came in after all these things happened. A lot of the old community fled to Arch or Endeavour.It is good right? You had a pleasant time with Manjaro. Fun is good. Excuse me if I have kind of spoiled it for you. :) reply elaus 19 hours agorootparentprevIs it possible that some of the perceived performance gains come from comparing an old installation (with lots of tools and packages that are no longer used) with a brand new installation? reply unsungNovelty 19 hours agorootparentI don&#x27;t think so. Based on my experience. I have enough experience with snap performance issues. When I was using snaps in another distro (Manjaro), removing snaps shaved me a nice 11-12 seconds boot time. Snaps adds boot time. They are slow to start. They also have these performance issues. What I didn&#x27;t know or somehow missed was Firefox snaps was eating way too much memory than I thought. And the whole package was not appealing or solving my problems.Linux Mint in my past experience have always stood tall even in old installations. So I don&#x27;t expect that as a reason. And I don&#x27;t expect LM to slow down as well. But thanks. I will keep an eye on it and see. reply jorvi 19 hours agorootparentprevArch is terrible due to their bare testing package release policy.Generally accepted recommends:- Windows converts: Mint- General: Fedora &#x2F; PopOS- Rolling: Suse Tumbleweed- Config fanatics: Nix- Minimalistic fanatics: Void &#x2F; Alpine reply unsungNovelty 18 hours agorootparent> Arch is terrible due to their bare testing package release policy.It is NOT. This is biggest mystery I have about people&#x27;s perception about Arch Linux. Arch provides latest upstream stable packages unlike point releases. NOT developer branches of packages BUT STABLE versions of package as soon as it is available. Point releases like ubuntu gives you old versions of software. And backport security patches against that version from latest stable packages which again leads to possible bugs etc etc. Apart from Linux, you will never see anyone calling a latest stable version of a software as \"bleeding edge\". You don&#x27;t say iOS 17 as bleeding edge. It is the latest stable version of the iOS. Windows 11 is not bleeding edge, it is the latest stable version of windows OS.I have a 5+ year installation Arch installation from which I am writing this comment. It is fast easier to use and predictable. Point releases always give you a easy jumpstart and it is often a pain to maintain in the longer run. Arch definitely requires initial time investment (It is after all a DIY distro, not a managed distro), but it is easier to maintain. I use Arch because I am lazy. I don&#x27;t want unpredicatable changes.I don&#x27;t think I am going to complain getting firefox 119 (which is the latest STABLE version at the time of writing) within a week or two. Especially in these times where we should be using latest packages for security and stability.Also repost for Linux distros (like stable&#x2F;unstable&#x2F;testing) is testing a package against the distro. It is NOT checking the stability of the software itself. It is checking the stability of a software&#x2F;packages against a particular distro. reply wing-_-nuts 18 hours agorootparentNot who you&#x27;re replying to but I&#x27;m sorry, he&#x27;s right.The GRUB incident last summer was the last straw for me. I found myself with an unbootable system. The r&#x2F;arch sub was radio silent. r&#x2F;EndevourOs posted a sticky about the grub issue. On researching it more, they were using a build of grub off master (not even a release!). When I asked an arch dev if he thought it was appropriate to do that given he&#x27;d just left thousands of people without a bootable system, he dismissed me with something to the effect of &#x27;If you can&#x27;t repair your bootloader maybe you should use an easier distribution&#x27;You know what? I agreed with him. I formatted my laptop and installed PopOs and it&#x27;s been really nice running a system where the devs actually seem to care about stability. reply unsungNovelty 18 hours agorootparentOh no. I am sorry that happened to you. My experience have been pleasant from the community. But I understand that might not be everyone&#x27;s experience.Might I suggest setting up timeshift or other things like BTRFS which have rolling back features? I never have to use it in my 5+ years old arch install, but I have used it once while using Manjaro (Arch derivative). If your system breaks, I just use Linux Mint live boot and revert it back to last working state from Linux Mint which bundles timeshift. And you just wait for a fix before you update again.I suggest this because my experience has been that point releases creates problems in the long term and hence is not without issue. So this might be helpful.PS: I have heard nice things about PopOS. Hope things are fun over there. :) reply jorvi 17 hours agorootparentprev> It is NOT.It is.Arch has an explicit policy that if there are breaking issues with a package, they will push it regardless and it is your task to read about these yourself in the package update&#x2F;release messages.No sane person is going to do that for the many many packages that their system is comprised of.SUSE holds fresh packages for a little bit and puts them through a more rigorous testing process, before pushing them onto Tumbeleweed. This leads to much much less breakage.Maybe you aren&#x27;t aware, but Tumbleweed is also a rolling distro. This is why I specifically mention it as a replacement for Arch. reply unsungNovelty 13 hours agorootparentHi,This is an interesting point you make. I agree that this is a policy and I am not a fan as well. The solution is keeping an eye on the forums and news. But yeah, it can sound problematic. But like I mentioned just above in my comments, zero issues with just sudo pacman -Syu for the last 5 years. I have only done manual intervention twice, both times as per https:&#x2F;&#x2F;archlinux.org&#x2F;news&#x2F;. One was something I can&#x27;t recall and recently JRE, JDK. It didn&#x27;t break.Tumbleweed updates are big batches because of the way they update. Which I am not a fant of as well. Not to mention, I am a big fan of Arch community. More over, albeit only hearing good things about OpenSUSE (AUR is based on OpenSUSE tech IIRC), I would like to use only community led&#x2F;oriented distros. They are always better for the end users. Especially Arch, whatever technical problems exists, they are always improving things. Look at the archinstall. Now I can have a new arch install in likehalf my day on Zoom calls. For some reason, I periodically would have issues with peripherals. Picking the wrong mic, having to close and reopen Zoom, correct camera not working, etc. None of this is an issue if you&#x27;re on a laptop but it regularly was a problem since I used my machine as a desktop all day.I decided I finally need to get a machine with a beefy GPU this year with all of the LLM stuff happening (plus my son is getting into PC gaming) so I bought an Alienware desktop with Windows. First Windows computer I&#x27;ve owned since 2005. Now I have a 3 screen setup where my middle and left screen are the Windows computer, my fully loaded System76 Meerkat is on the right using Barrier and 99% of my development work is remote on that machine.No issues with the peripherals for meetings on the Windows machine. Still greatly prefer the Linux machine for everything else but the reliability of knowing that my peripherals are going to work for meetings has been important. Plus, I started a tech podcast (Carolina Code Cast) and that&#x27;s been important for all of the A&#x2F;V that goes with it.All that to say, there are tradeoffs. Eventually, I hope that Linux will have first class peripheral support. I&#x27;d like nothing more than to install it on this Alienware machine one day. reply throw555chip 18 hours agorootparent> Still greatly prefer the Linux machine for everything else but the reliability of knowing that my peripherals are going to work for meetings has been important.As a long time Ubuntu user, used to use Skype, now Teams, Google Meet, Google Voice (used to be Hangouts) and sometimes Zoom, I have had no issues, or no more than when work makes me use Windows, when using peripherals. reply pipe01 19 hours agorootparentprevHave you tried pipewire? It fixed some weird issues like the ones you mention for me reply brightball 19 hours agorootparentI have not. Any good links? reply throw555chip 18 hours agorootparentYes Google \"Ubuntu 2022\" or \"Kubuntu 2022\" if you prefer KDE (I do), install and run it, that&#x27;s all you have to do. reply loufe 16 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply brightball 18 hours agorootparentprevIn that case, the problem still exists. I was running the most recent PopOS (Ubuntu based) and it was still a problem. reply throw555chip 16 hours agorootparentPopOS isn&#x27;t from Canonical. Use Ubuntu or Kubuntu for a wonderful Linux Desktop experience. It&#x27;s only worked for me since 2006. replyEnginerrrd 19 hours agorootparentprev>\"For some reason, I periodically would have issues with peripherals. Picking the wrong mic, having to close and reopen Zoom, correct camera not working, etc.\".This problem is probably even worse on windows for me, FYI. reply totallywrong 19 hours agorootparentprevHave you tried a modern Fedora? I don&#x27;t know about Alienware but for me in a wide range of laptops (including Intel Macbook Pros) hardware issues are a thing of the past. reply brightball 19 hours agorootparentFor 90% of things I&#x27;d agree with you. When it was plugged into a USB hub that had a couple of cameras, mics and speakers there would be issues.It&#x27;s entirely possible that the hub itself was a problem but it hasn&#x27;t been an issue thus far with Windows.I _really_ hoped that WSL would be better than it is when I decided to try this. It&#x27;s quirky. reply kibwen 19 hours agoparentprev> Windows and OSX have, for the most part, just workedI bought a System76 machine running their own PopOS distro and everything Just Works as I&#x27;d expect, with the added benefit of actually having the ability to muck around with the innards of my system when I want to, unlike Mac or Windows, which are increasingly locked-down, opaque, and user-hostile. Neither Apple nor Microsoft are consumer desktop OS-focused companies these days; the former is a mostly a phone manufacturer and the latter is a confusing mess that might be best described as an enterprise software company. They have no material incentive to care about the quality of Mac or Windows, and it shows; their desktop OSes are afterthoughts. reply FirmwareBurner 19 hours agorootparent>I bought a System76 machine running their own PopOS distro and everything Just Works as I&#x27;d expectIncluding touchpad gestures and browser hardware video acceleration out of the box? reply amlib 17 hours agorootparentFirefox has hardware video decoding enabled by default on linux for years now, only google chrome doesn&#x27;t want to bother doing the work to enable it. That said, in some cases hardware video decoding may be unavailable due to IP issues that forbid the necessary code to be distributed freely. reply kibwen 18 hours agorootparentprevIt has touchpad gestures, and I even used a GUI program (I think it&#x27;s called Touche, trivially installed via the app store) to customize the gestures further (it&#x27;s quite powerful, it lets you assign arbitrary keys or shell scripts to gestures and scope them by context, e.g. I assigned four-finger swipe left&#x2F;right to Alt+Left&#x2F;Right while inside Firefox to perform back&#x2F;forward navigation (this was before Firefox started shipping with gestures natively)).As for browser hardware video acceleration, I sure hope so (the model I got has a beefy GPU) but I&#x27;m not sure how to check, and in any case I reflexively watch all videos in 480p after years of watching my old Windows laptop overheat while trying to decode video so I&#x27;m the wrong person to ask. :P reply bmicraft 20 hours agoparentprevUbuntu is mostly fine and a good middle ground for new users between bleeding edge (Arch, Fedora) and outdated software (Debian) IMHO. It&#x27;s also probably the best place to start simply because of the mountains of documentation that exist for it because of its large userbase.I would also like to add that often you&#x27;ll find answers to stuff telling you to use a couple of commands when instead you could use existing gui tools. That might be because commands are faster for people that already know them, but often they&#x27;re not the only way. reply pmontra 19 hours agorootparentInstructions like type \"this and that\" in a terminal are short and perfectly reproducible. Instructions like open Settings, find This, click that\" are less precise and could leave people stuck halfway.Even on Windows forums there are often NET USE or Powershell commands mixed with instructions to perform the same task using GUI apps. reply underseacables 20 hours agorootparentprevI deeply appreciate the GUIs. reply pjmlp 19 hours agoparentprevAs ex-UNIX zealot, that came back into Windows around Windows 7, and then settled to use GNU&#x2F;Linux from VMWare, Windows has gotten worse, but still not bad enough for me to use GNU&#x2F;Linux as main OS.Just last weekend I have spent a good part of it fixing the way installing clang messed up with Ubuntu&#x27;s system clang, plugged via LAN cable, because after all these years my little Asus netbook still cannot keep a stable WLAN connection to my router. reply torginus 17 hours agoparentprevMy biggest gripe with Linux is that it&#x27;s an incredibly brittle system that you can easily blow up, either through no fault of my own (a grub update once made my system unbootable), issues which were triggered by trying to work around ubuntu&#x27;s shortcomings (I installed an nvidia driver from a ppa, which broke my system), or through curious experimentation gone wrong.Combined with the constant weird bugs ranging from annoying to potentially system-breaking, and the lack of resources you have for troubleshooting (because few people use it, and the system changes so fast that existing posts become outdated), it&#x27;s really hard to fix, too.I honestly try to never update my Linux box, unless I&#x27;m prepared to invest time into potentially having to fix it. And Windows&#x27; annoying updates are absolutely nothing compared to the daily barrage of packages, each triggering a restart. reply weberer 17 hours agoparentprevI feel the exact opposite. Changing things in Linux is usually just a checkbox in the settings. Whereas changing things in Mac or Windows can be an uphill battle, digging through registry keys, or installing third-party software just to change basic features.For example, how do you rebind the \"switch window\" hotkey on a Mac from Cmd+Tab to Alt+Tab? There&#x27;s no way to do it out of the box. You need to install some third party program called AltTab just to set hotkeys.How do you disable tracking in Windows 10? Well here&#x27;s a 50 step plan. And you better pray that none of these settings will be reset the next time there&#x27;s a forced update.https:&#x2F;&#x2F;nordvpn.com&#x2F;blog&#x2F;disable-windows-10-tracking&#x2F; reply sanitycheck 16 hours agorootparentYour Windows link is interestingly all examples of \"just a checkbox in the settings\", no registry editing, no group policy fiddling and definitely no obscure DOS&#x2F;PowerShell commands to paste!(Personally I go further with Win10 - disabling web crap in the start menu does need a registry change. I gather Win11 is worse still.)OTOH a Linux change I wanted to make recently was to rename Gnome&#x27;s \"Files\" and \"Files\" (!) apps to to \"Nautilus\" and \"Nemo\" so I could tell the f*king difference. Right-click & rename? Nope! We&#x27;re in editing-little-files-land straight away. reply SoylentYellow 19 hours agoparentprev> My only complaints are that Linux can be tediousAfter using Linux daily over 10 years now, this is exactly how I feel about Windows now. I instantly get frustrated any time I have to use Windows. reply asimovfan 20 hours agoparentprevInteresting, my experience is the opposite.. since windows 10 came out it became almost unusable and problematic with random stuff, even after debloating scripts. Ubuntu has been my go to system for a while now, and i basically just want to watch YouTube and edit text. reply trey-jones 18 hours agoparentprevAbout 15 years ago I received the advice, \"If you want to be hacker, stop using Windows and start using Linux.\" Today, I am well aware that this is not the only path to enlightenment, but I count it as some of the best professional advice that I have ever received. This is colored by the direction my career has taken me: the technologies I use are open source, and that fits much better into the Linux box than others.It&#x27;s also not about writing code. Sure, when using Linux exclusively, sometimes you might have to hack together a little script to make your computer do what you want, but that&#x27;s really not necessary, especially in the year of our Lord 2023. It&#x27;s about tooling. So many younger devs that I meet still have irrational fear of the command line. Inability to use built-in documentation (like manpages), and again a fear of trying (because web browsers exist). Worst of all is the lack of understanding that these younger devs have of Unix permissions. We all know the guy who just pastes `chmod -R 777 .` or something from StackExchange. Since most of our production software still lives on Linux, knowing the proper way to configure these environments is valuable (though unfortunately undervalued, in my opinion, since improper configuration can still \"work fine\").Using Linux full-time for years will make you more than comfortable. And yes, it probably will take years. You may come to prefer the terminal to most of the GUI wrappers provided in desktop Linux distros. You won&#x27;t even notice when you come out the other side. You&#x27;ll realize that everything only seemed like it was 43 commands away because you only knew 2 commands to begin with. Typing the most common commands will be second nature and take less time than moving your hand to the mouse. Anything that does need to be reasoned out and typed slowly you will learn to embed in a script, with comments so you can remember how it works, and that will save you even more time.Most importantly, in the end you will have the confidence in your abilities to write long, condescending comments on Hacker News. I kid of course, but you will no longer fear tooling (though you may grow weary of it - looking at you nodeJS), and I truly believe that&#x27;s a more important and difficult skill than reading and writing code of all sorts. reply loudmax 19 hours agoparentprevMost of your interaction with your computer is via the Desktop Environment. Which is Gnome in a default Ubuntu installation. If you&#x27;re not particularly interested in exploring alternate operating system philosophies, I&#x27;d recommend looking into other Desktop Environments to use on Ubuntu. In particular, I&#x27;d recommend XFCE or Mate since they behave conventionally.One thing to understand when moving from a proprietary to an open source OS is how much control you have over the system. Just about any part of it can be disabled or upgraded or swapped out for something different. If you learn where the seams are and how the different pieces work together, it gives you far greater control over your computer than any proprietary OS. If you expect everything to just work, you may be setting yourself up for disappointment. reply Workaccount2 18 hours agoparentprevI have been switched for a year now, for the 4th? 5th? time in my life, and it looks like I&#x27;m gonna end up back on windows once again.The perpetual problem with linux is that it is written and maintained by people who love linux. Its great if you just need a machine to check email, and it&#x27;s great if you are well versed in linux OS structure and know the CLI command set&#x2F;structure through and through.But if you are middle of the road power user, linux is just a constant annoying nightmare of reading forum posts and copy+pasting seemingly random strings of characters into the terminal hoping that it will fix the sound issue on the video you&#x27;re trying to play. reply sanitycheck 19 hours agoparentprevI&#x27;ve been having a reasonably good experience with Pop OS, which is Ubuntu-based but different in a bunch of ways. The makers (System76) put it on the computers they sell so they have a strong incentive to make it \"just work\", and that seems to have mostly worked out well.As someone with years of light Linux experience but no patience for pissing about with config all day, my golden rule is to avoid updating anything ahead of the version that the distro bundles. E.g. no I shall not be updating my Nvidia drivers independently!I like docker for arbitrary command line software I haven&#x27;t checked the source for, Flatpak (or Snap&#x2F;AppImage I guess) for big complicated GUI software, and if those aren&#x27;t options I sometimes run things in a VM if I don&#x27;t trust them not to screw up the system (hello Tizen Studio!). I ended up installing Blender from Steam, of all places. reply jaeckel 19 hours agoparentprevAs also stated by others you should start learning the basic concepts and no specific flavor&#x2F;distro to understand how everything fits together. You sound like someone who could very well succeed in that, since you didn&#x27;t give up yet :)I can only recommend starting to read https:&#x2F;&#x2F;wiki.archlinux.org&#x2F;title&#x2F;Installation_guideOnce I installed arch I never looked back. I heard good things of the rolling distros of Suse and Fedora as well, but arch feels more vanilla than the others to me.If you have a lot of time and passion you could also have a run of linux from scratch. You do it once for the learning part and then choose a distro of your liking. reply horeszko 19 hours agorootparent\"Once I installed arch I never looked back\"I&#x27;m also very fond of Arch Linux and I use it on my laptop.However Arch is very much DIY and is great for the person who wants to get their hands dirty because with Arch you assemble and maintain the installation yourself.For someone who wants things to work out of the box with no (or minimal) tinkering, I would recommend a different distro.Arch is a distro for learners and enthusiasts. But it would be frustrating for someone who just wants a working OS. reply mdhen 19 hours agorootparentIf you want the primary benefit of arch (AUR, best package manager repo) but don&#x27;t want to do a custom set up then Manjaro is a very good choice. reply kstrauser 17 hours agoparentprevMy personal experience has that Windows is easier to get up and running as long as I want to use it as-designed. Getting off that happy path turns into a fiasco for me. I&#x27;m sure a lot of my difficulties would be trivial to fix for Windows expert, but I&#x27;m not one.For me, it&#x27;s way easier to bend Linux to my will.(I&#x27;m typing this on a Mac. I spent my first months on a Mac trying to make it act like my Linux desktop, and hated it. Then I decided to try a month doing everything the Mac way instead, and ended up loving it. Go figure.) reply Saris 18 hours agoparentprevYeah the control you get over Linux is both good and bad. You can pretty much get it to work exactly how you want, but getting there is very complex, and remembering CLI commands is extremely difficult for me even after many years of doing linux server admin.It&#x27;s slowly getting better though, things are starting to have sane defaults more often, and there are more easy to use GUI settings for things, instead of needing to deal with stuff that requires having documentation open on the side.My benchmark for &#x27;good&#x27; is that I shouldn&#x27;t have to look at documentation or remember CLI commands to set up and use an OS. reply mejutoco 19 hours agoparentprevI have used the main OS. Linux (plain LTS Ubuntu) has worked way better than anything else, as long as the software was available. With Figma and an iPad I do not need a Mac or Windows anymore. I still have a separate hard disk for Windows for an occasional game.Sometimes I reboot and people are surprised how quick I am back. Also I use only wired accessories, so that might be a f",
    "originSummary": [
      "Linux, specifically Ubuntu 23.10, outperforms Microsoft Windows 11 on the new AMD Zen 4 Threadripper processor with about a 20% performance advantage.",
      "The benchmark tests on the HP Z6 G5 A workstation include rendering, image denoising, video encoding, chess, and other tasks.",
      "The review unit came with Windows 11 preloaded, which offers a perspective on the performance endorsed by the hardware vendor."
    ],
    "commentSummary": [],
    "points": 339,
    "commentCount": 373,
    "retryCount": 0,
    "time": 1700657193
  },
  {
    "id": 38383138,
    "title": "Windmill: The Fastest Self-Hostable Open-Source Workflow Engine",
    "originLink": "https://www.windmill.dev/blog/launch-week-1/fastest-workflow-engine",
    "originBody": "Launch Week Day 3 - Fastest self-hostable open-source workflow engine November 22, 2023 · 17 min read Ruben Fiszel Founder at Windmill Labs Big claim today: We've benchmarked Windmill to be the fastest self-hostable generic workflow engine among Airflow, Prefect and even Temporal. For Airflow, there is quite a margin, up to 10x faster! Fastest self-hostable open-source workflow engine Benchmarking data and dedicated methodology documentation You've known Windmill to be a productive environment to monitor, write and iterate on workflows, but we wanted to prove it's also the best system to deploy at scale in production. It was important for us to be transparent and you can find the whole benchmark methodology here: Benchmarks Comparing performance of Airflow, Prefect, Temporal and Windmill for 2 representative use cases. Enjoy the reading. A more scoped crown Before you raise your pitchforks, let's unpack our claim a bit, we are not claiming to be necessarily faster than your specialized, hand-built workflow engine written on top of the amazing BEAM (from which we took inspiration) but rather only among the \"all-inclusive\", self-hostable workflow engines. We recognize 3 main ones today: Airflow Prefect Temporal There are tons of workflow engines, but not many of them are self-hostable and generic enough to support arbitrary workloads of jobs defined in code, and even those have restrictions: Some like Airflow and Prefect support only one runtime (Python). Windmill on the other hand supports Typescript/Javascript, Python, Go, Bash and direct SQL queries to BigQuery, Snowflake, Mysql, Postgresql. And its design makes it easy to add more upon request. Some are notoriously hard to write for (because of complex SDKs, looking at you Airflow's XCOM or Temporal idempotency primitives) and deploy to. Windmill offers an integrated DX to build and test workflows in a few minutes interactively in a mix of raw code for the steps and low-code (or YAML) for the DAG itself. It is also possible to define them wholly with code and full version control using our VS Code extension. One benefit of being very fast is that it makes running tests very fast too both in terms of latency to start and to run. Wasting time waiting for previews and tests to run is not fun. Should Temporal even be there? Temporal doesn't actually manage the workers but only the tasks queues. So even after having written your Temporal workflow, you will still need to manage your workers separately. To some degree, Temporal is not a workflow engine but a specialized durable execution engine. Windmill also supports reactivity (aka waiting for event) and can be qualified as a durable execution engine as well. That being said, Temporal is amazing at what it does and if there are overlaps between Windmill and Temporal, there are clearly use cases where you should use Temporal rather than Windmill (as the backbone of your micro-services async patterns at the scale of Uber for instance). On the other hand, sending arbitrary jobs to an internal cluster is out-of-scope for Temporal as you will still need to painfully deploy \"Worker Programs\" beforehand. info We leave analytics/ETL engines such as Spark or Dagster out of it for today as they are not workflow engines per se even if they are built on top of ones. ETL and analytics workflows will be covered later this week, and you will find that Windmill offers best-in-class performance for analytics workloads leveraging s3, duckdb and polars Workflow Engine vs Job queues Job Queues are at the core of Workflow Engines and constitute the crux of any background job processing. There are already plenty of great queues implementations under the form of managed services (SQS), distributed scalable services (Kafka) and software (e.g: Redis with rmsq) or libraries (Orban). They are mostly sufficient to use by themselves and many developers will find satisfaction in avoiding a workflow engine altogether by building their own logic around a job queue. This is akin to writing your own specialized workflow engine. What is a workflow engine, and what constitutes an \"all-inclusive\" workflow engine First some definitions, a workflow is a directed acyclic graph DAG of nodes that represent job specifications. A workflow engine is a distributed system that takes a workflow and orchestrates it to completion on workers while respecting among others all the dependency constraints of each job. There exists a great variety of workflows and many software are domain-specific workflow engines and workflow specs (if you are a software engineer, you probably already wrote one without realizing it). What will interest us here are workflows that can run arbitrary code in at least one major programming language (Python/Typescript/Go/Bash). Those are the most generic but also the most complex and the most difficult to optimize. Every node is a piece of code that takes as input arguments and data from other steps (or the flow inputs), do some side effects (http requests, computation, write to disk/s3) and then returns some data for other steps to consume. 5 Major benefits of workflow engines: Resource allocation: Clusters can be fully leveraged and every job can be assigned to different workers with different resources (cpu, memory, gpus) and guarantee that the full resource of the worker will be available to the job Parallelism: When the constraints of a workflow allow some steps to be run in parallel (branches, for-loop), a workflow engine can dispatch those steps on multiple physically separate workers and not just threads Observability: every job has a unique ID and can be observed separately: the inputs, logs, outputs, status can be inspected Durability: Machine dies, side effects fail for unexpected reasons. Workflows need to be restartable as close to the unexpected events. One way of achieving this is idempotency: a single operation is the same as the effect of making several identical operations. When in doubt, replay the entire flow without any consequences. This is usually implemented with a log file and an sdk that skip the side effect when the unique id attached to an operation is part of the log. Another way is transactional snapshotting of the flow state, storing the state after each operation. To resume, simply reload that last state and execute from there. Windmill does the latter and assumes that idempotency can be implemented when desired in userland. Reactivity: Suspend the flow until it is resumed again based on an event such as a webhook or an approval Additionally, an all-inclusive workflow engine should dynamically register newly available workers and make it easy to deploy new workflows, assign different jobs to different workers, and monitor the health of the workers and of the system itself. A developer platform on top of a workflow engine should handle permissions such that different users with different levels of permissions can run different workflows and those workflows to have access to different resources depending on the roles of the caller. So why is Windmill very fast In a workflow engine, the term \"efficiency\" depends: efficiency to compute transitions, the new jobs to schedule given the last job that completed, and the efficiency of the workers themselves to pull scheduled jobs and run them efficiency to pass data between steps efficiency of the worker to pull jobs, start executing the code, and then submit result and new sate Windmill is extremely fast because on all 3 aspects, it uses a simple design, optimized everywhere, that leverage maximally both Postgresql and Rust. System design and Queue Windmill provides a single binary (compiled from Rust) than can run both as the api server or the worker. Both workers and servers are connected to Postgresql but not to each other. The servers only expose the api and the frontend. The queue is implemented in Postgresql itself. Jobs can be triggered externally by calling the API which will push new jobs to the queue. Jobs are stored in 2 tables in Postgresql: queue (while the job is not completed, even when running) completed_job Jobs are not removed from the queue upon start, but their field running is set to true. Queue is implemented with the traditional UPDATE SKIP LOCKED UPDATE queue SET running = true , started_at = coalesce(started_at, now()) , last_ping = now() , suspend_until = null WHERE id = ( SELECT id FROM queue WHERE running = false AND scheduled_for$3 as result FROM completed_job WHERE id = $1 AND workspace_id = $2\" where $3 is json*path.map(|x| x.split(\".\").map(|x| x.to_string()).collect::>()) share data in a temporary folder Flows can be configured to be wholly executed on the same worker. When that is the case, a folder is shared and symlinked inside every job's ephemeral folder (jobs are started in an ephemeral folder that is removed at the end of their execution) pass data in s3 using the s3 integration (updates specific to that part to be presented on day 5) Workers efficiency In normal mode, workers pull job one at a time, identify the language used by the job (python, typescript, go, bash, snowflake, Postgresql, mysql, mssql, bigquery) and then spawn the corresponding runtime then run the job. Workers run jobs bare, without running containers which gives us a performance boost compared to container based workflow engines. However, for sandboxing purposes, workers themselves can be run inside containers and can run each job in an nsjail sandbox. For query languages, there is no cold start except for establishing the connection. The last connection is maintained for 1 minute to benefit from Temporal locality bash has no cold start, and go scripts are compiled AOT and then the binary is cached locally to avoid any cold starts. Supporting executing arbitrary python code is hard because we have to support any import with any lockfiles. Since workers don't run that python code in containers, the dependencies have to be handled dynamically. To that end, we developed an efficient distributed cache system that dynamically pip install once a specific pair (package, version) and creates a dynamic virtual env on the fly to execute the code. The imports are analyzed efficiently just prior to running the code. Similarly in typescript, the runtimes are either deno or bun so that they can benefit from global cache and never have to install the same dependency twice. However, handling dependency fast is not sufficient for maximum speed, there is still the cold start of spawning a python (~60ms) or deno/bun (~30ms) process. In event streaming cases, the logic itself takes about 1ms and hence the cold start is 30x the overhead of running the script. Fortunately, we implemented recently dedicated workers for scripts, which spawn a python process once at the start of the worker and then execute the script logic in a while loop, taking the job inputs in stdin and returning the output to sdout. We extended this approach with dedicated workers for flows, which are essentially the same approach. At first, those workers will spawn a corresponding dedicated process for each of the steps implemented in Python or Typescript. This completely obliterates the cold starts and makes Windmill flows capable of handling even-streaming use cases and going up to 1000 steps per second on each worker. The dedicated worker for flows will pull any job relative to that flow and then route it to the proper dedicated process. Still executing only one job at a time but in pre-warmed processes. Conclusion Windmill is very fast because it relies on Postgresql, and Rust, and uses a simple design that enables optimizing every part, small and big. It's a bit of the same answer than why Bun is fast, which is implemented in Zig and is optimised everywhere possible. Windmill is an open-source and self-hostable serverless runtime and platform combining the power of code with the velocity of low-code. We turn your scripts into internal apps and composable steps of flows that automate repetitive workflows. You can self-host Windmill using a docker compose up, or go with the cloud app. Tags: Launch week Workflow Engine",
    "commentLink": "https://news.ycombinator.com/item?id=38383138",
    "commentBody": "Fast self-hostable open-source workflow engineHacker NewspastloginFast self-hostable open-source workflow engine (windmill.dev) 322 points by rubenfiszel 15 hours ago| hidepastfavorite157 comments paxys 13 hours agoThe devs of Windmill seem to have taken the winning advice of \"do one thing and do it well\" and done the exact opposite. Going over windmill.dev I have no idea what specifically the software should be used for. Is it a competitor to Retool? Airflow? Temporal? Apparently there&#x27;s a no-code workflow builder? A drag and drop UI builder? An online IDE? Dozens of integrations? What on earth is going on?? reply rubenfiszel 12 hours agoparentThe critics is more than fair and our positioning is not very clear.We are doing a developer platform for enterprise to build internal software, including apis, workflows, background jobs, and UIs using code, but only where it matters. We happen to be quite decent in all aspects, with a focus on performance, and we have an active community of users and customers that are mostly developers and hence have plethora of feedback and feature requests, so we&#x27;re happy to oblige.By being at the right level and trying to expose the code as much as possible, we can be great generalists without sacrificing on the quality. Python, Typescripts, Go, Bash and all the query languages are where all the complexity is and capabilities come from. They are well developed languages with great ecosystem. We merely provide a way to run those language in a system fit for production at enterprise scale. reply MuffinFlavored 11 hours agorootparent> We are doing a developer platform for enterprise to build internal software> for enterpriseI mentioned this product to my enterprise boss and his enterprise answer was \"we can&#x27;t easily get this approved by tech-selection committee for no good reason\" (and that would have just been to have an off-to-the-side proof-of-concept instance or two running in our sandbox k8s cluster let alone actually bringing it onboard as a paid service)How do enterprise users not already have the functionality you are offering covered one way or another and why would they migrate off of what they have to what you are offering? What kind of business today doesn&#x27;t have something like ActiveBatch, AWS&#x2F;Azure functionality with massive cloud support contracts, etc. already? reply rubenfiszel 11 hours agorootparentYou can&#x27;t win every contracts but the market we&#x27;re after is immense and so even a small percentage of enterprises being more daring is sufficient.But the argument is true for any enterprise software, you cannot be small and sell to enterprise (or you must have amazing product market fit), that&#x27;s where open-source comes in.We have overlap with many existing products, but we are the only one to provide such product, with emphasis on DX and excellent performance and scalability, and to be open-source. We do currently have a few big enterprise customers and many enterprise open-source users. It&#x27;s a lot easier to get approval since they get it for free and it&#x27;s fully self-hostable and air-grappable. Once they have tried it on a few non-essential workflow and see the benefits, then they are more motivated to make a case internally. Wide net, some catches until it becomes ubiquitous.I happen to be a really strong believer in open-source so it&#x27;s not just an adoption strategy but I think it happens to be also fortunately the best strategy for such infra level software. reply stingraycharles 10 hours agorootparentWhether enterprise or not, the criticism is still fair: the value proposition needs to be super clear. I’m missing this.Your comments make it a bit more clear, but the big question (as an Airflow user) I have is: why would I want to migrate?A big question for an enterprise customer is typically: will I save money with this? In developer productivity, in resource costs, or something else? Can you unlock new things that were previously not possible?I wish you guys the best. reply jordanbeiber 3 hours agorootparentQuestion is - what are you using airflow for? My experience with airflow have been in data ETL, and if so you are not the target for something like windmill.The target would most likely be automating HR, Finance and IT workflows and tearing down the shadow IT web of crazy integrations taking place at every larger organization I’ve ever experienced.We’re talking “new hire” workflow for example, which at my current employer is about 25 activities in a workflow.All assets have to be lifecycle managed in an enterprise and automated workflows will help you scale that. Far too many enterprises have a lot of people shuffle excel files and emails around to fulfill processes and workflows.Airflow is a beast imho and usually not used in the same niche IME. reply haswell 11 hours agorootparentprevI’ve been the person in a position to recommend enterprise solutions and have those recommendations taken.I’ve also been the person on the other side of that relationship, helping potential customers make a case that my product is worthy of their software&#x2F;services gatekeeper’s consideration.There is often high motivation to bring in a smaller&#x2F;newer tool, because the existing solutions are not scalable, or are missing a critical feature, or require a team of specialized people to make it work, or has onerous licensing costs, etc.“Shadow IT” is also a very real thing. Someone’s boss is frustrated with the bureaucracy and timeframe for bringing something in and so they just throw it on a corp card or install it themselves and ask for forgiveness later. This happens everywhere and is often the precursor to forcing the product to become officially blessed because by now it’s supporting production workloads and has proven its worth.This particular space is still ripe for innovation. Very few of the products that target this kind of tool building approach are close to finished and each has its quirks. reply MuffinFlavored 10 hours agorootparent> There is often high motivation to bring in a smaller&#x2F;newer toolI must be misunderstanding the definition of \"enterprise\" here. I can&#x27;t picture any of the 3 enterprise companies I&#x27;ve ever worked for adapting any sort of product like this. reply jordanbeiber 3 hours agorootparentI’ve worked for years implementing tools like this in enterprises.My most fond memory was introducing a workflow platform to an enterprise with a fully outsourced IT-ops department - it was ruining everyone else in terms of cost, speed and quality.The security dept (this was a large bank) was gridlocked in this setup and wanted the ability to automate their way out of the sourcing mess.I spent roughly three months building a few “hot path” workflows important to them which enabled them to take the ownership back of the processes and save an incredible amount of time and money.Encapsulating these integrations as workflows makes them observable and measurable. The customer had in the first quarter after deployment 10’s of thousands runs and avg time to completion went from 2 weeks to 2 days. It also cut out an rather expensive middle man.And this is not the worst enterprise customer I’ve worked with. One hade 4000 Windows servers manually provisioned and managed. There’s low hanging fruit out there!You basically trade agility and quality for competence, unfortunately a lot of enterprise IT shops are not willing or capable to do so. reply haswell 7 hours agorootparentprevI’ve worked with many of the largest companies across quite a few verticals in a product management capacity. Many large enterprises (think 200K+ employees) still have pockets of tool building and automation springing up everywhere. Big names you’ve heard of.I’d be willing to bet money that this was happening where you were, but you may not have been exposed to it. It often shocks IT management what they find when turning on software auto-discovery and inventory tools.These tools are often employed in operations and other non-core-to-the-business departments to simplify&#x2F;automate busy work happening there. reply jordanbeiber 3 hours agorootparentprevThey have “not only one way or the other” - they have “all the ways” and this is exactly the problem you want a solution like this to fill.We’re talking backoffice&#x2F;cost-center workflows in IT, finance and HR - absolutely not business profit processes mind you.A tool such as this can help an IT department take ownership of integrations and workflows, building them in a framework that can improve speed and quality. It will help with organizational scalability.The alternative is in my experience a giant mess of integrations lacking ownership and observability.Every large enterprise needs “something” like windmill, they might just not know it. reply JacobThreeThree 8 hours agorootparentprev>A workflow engine is a software application that manages business processes>Enterprise resource planning (ERP) is the integrated management of main business processes, often in real-time and mediated by software and technology. ERP is usually referred to as a category of business management software—typically a suite of integrated applications—that an organization can use to collect, store, manage and interpret data from many business activities.What is the difference between a workflow engine and an ERP system?Why not call it an ERP system if you&#x27;re targeting the broader enterprise market? As someone who is far from SV, the business people I know probably don&#x27;t know what a workflow engine is, but they definitely know what an ERP system is.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Enterprise_resource_planninghttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Workflow_engine reply Mandatum 11 hours agorootparentprev> but only where it matters.What does this mean? reply rubenfiszel 11 hours agorootparentHappy to expand on this. Only where you would consider to be not boilerplate, aka your business logic. I hate low-code that force me to use a rigid system for the core of my tools, but I love the velocity that it brings. What if we could have high-velocity for all the boilerplate (permissioning, queuing, frontend, secret management, etc, etc) but code for the business logic. That&#x27;s what windmill is. In a way, this is what serverless was meant to be, write your business logic and servers autoscale and you can hook a gazillon managed services on top.We bring that vision in a fully open-source and consistent platform that you can host wherever you please. reply Mandatum 10 hours agorootparentI suggest you work with a copywriter and come up with a better way of presenting windmill.dev. How you&#x27;re presenting it makes sense to you, because you built it. You know what you mean when you say words like \"boilerplate\" and \"business logic\". That has a specific meaning in your head. But it&#x27;s different for every person in the software industry. To a customer, it&#x27;s confusing.For investors:> We are a developer platform for enterprise, offering a performance-focused solution for building internal software using code. Our open-source platform allows businesses to focus on their unique business logic while we handle the boilerplate tasks, resulting in high-velocity development and the ability to scale at enterprise levels.For devs:> We are a developer platform for enterprise, providing a system for running code written in Python, Typescript, Go, Bash, and query languages at scale. Our platform focuses on performance and offers extensive capabilities to build internal software, including APIs, workflows, background jobs, and UIs. With a fully open-source and flexible architecture, developers can concentrate on their business logic while leveraging our robust ecosystem for efficient development and hosting options.Generic:> Windmill is a developer platform designed for enterprises to build internal software efficiently. It combines the speed of low-code solutions with the flexibility of coding, allowing developers to focus on unique business logic rather than boilerplate tasks like permissioning, queuing, and front-end development. Our platform is fully open-source, offering high performance and hosting versatility.> Our active community of developer users provides constant feedback, driving our platform&#x27;s growth. By emphasizing commonly used languages such as Python, TypeScript, Go, and Bash, Windmill serves as a generalist tool without compromising quality, enabling complex functionalities within a production-ready, enterprise-scale environment. reply knowsuchagency 12 hours agoparentprevI had the same thought when it popped up on my radar a year ago. Now that I’ve been using it for a few weeks, it’s difficult to go back to the exact tools you’re naming. I didn’t realize how large of an impediment it is to move back and forth all of them. Windmill is the thing I never knew I needed. It’s changed how I think about delivering data products&#x2F;solutions. reply debarshri 12 hours agoparentprevDoing one thing well is not a winning advice. You can do multiple things, it really depends on the execution and other factors. They are doing one that is workflows and doing it well. reply MuffinFlavored 12 hours agorootparentI don&#x27;t really understand what a \"workflow\" is &#x2F; what it means.Like GitHub Actions is a workflow, but it&#x27;s a convoluted YAML wrapper around shell scripts.Is a workflow shell scripts? I&#x27;m going to guess no. I&#x27;m going to guess it&#x27;s \"code\". So... why is a workflow code but code isn&#x27;t a workflow?Windmill is a \"workflow (code?)\" orchestrator? reply jagtstronaut 11 hours agorootparentYeah I assumed this was a camunda competitor (a bpmn workflow product), but it seems like it is not that. reply uoaei 11 hours agorootparentprevOne task is the elementary unit of business operations, and one workflow is one DAG of tasks. reply sisve 12 hours agorootparentprevAlso they are using postgres for everything. I think that is a good example of picking one thing that you know very well and using that to the limits.But i do agree that windmill is doing so many things that the elevator pitch need some work. But a lot of companies are trying to do the same. So i do not think people will think of workflow engine + online ide + app builder as a natural grouping in 5 years reply halostatue 6 hours agoparentprevFor our purposes it looks like Windmill might take the place of MWAA (Airflow) that we were planning for our ELT pipelines and could take the place of Rundeck as well. I&#x27;ll need to look at it and play with it (especially from the ELT pipeline perspective for running transformers), but I suspect that we will be able to be up and running both faster and cheaper with either self-hosted Windmill or cloud. reply MuffinFlavored 12 hours agoparentprev> Is it a competitor to Retool? Airflow? Temporal?If it makes you feel any better, I&#x27;m pretty sure I personally couldn&#x27;t tell you specifically what any of those specifically do in terms of \"the one thing they do well\" &#x2F; why anybody would ever use one instead of the other &#x2F; not need to use all 3 to accomplish the same thing slightly different ways reply zo1 2 hours agoparentprevI&#x27;m also very confused about the pricing. Its \"open-source\" but with SSO user-limits? Paid version comes with Prometheus metrics, so does that mean the open-source free tier doesn&#x27;t? So many questions. reply Bonapara 12 hours agoparentprevLooks like a workflow engine to me reply j45 10 hours agoparentprevThe intersection of all those areas listed is often an inordinate amount of work and integration and maintenance.In that way as people want an easily grokable description, windmill seems to be a super-platform that leverages enough of the important bits that come up.I am going to try it out! reply hintymad 14 hours agoprevDoes being fast beyond certain threshold really matter for a workflow engine, though, especially given that many workflows have long-running tasks? What I find matters is multi-tenancy. That is, can a workflow system support as many jobs as a user desires, yet each job gets scheduled and executed as if it is the only one on the workflow engine. For instance, Amazon EC2 and EBS probably have millions of jobs and job queues running at any moment, yet each job has pretty predictable and stable startup delay and execution time. In contrast, each of Nomad and k8s has a global queue that sometimes gets stuck because of bad actors or too many pending jobs (I understand that an orchestrator is far more than just a workflow engine. I&#x27;m just contrasting the user experience). reply rubenfiszel 14 hours agoparentSo I agree that for most jobs taking already more than 300ms, a 50ms per job will not be perceivable anymore. What matters is the DX and even though I&#x27;m very proud of our performance, a lot of our work is focused on providing a consistently great developer experience in all aspects (vscode extension, instant deployment, etc, etc).However, there is one big benefit to being performant which is that you can use the same stack for performance sensitive jobs such as event-streaming use cases. That remove the duplication of infrastructure. The other benefit is that it improve the developer experience overall with fast previews. reply analyte123 12 hours agoparentprevYes. Just think of how annoying it is when you have to wait 5 seconds instead of 0.5s for a 2FA message, then multiply that by everything that you ever do with your workflow engine. That&#x27;s not even to speak of cases where running the workflow (e.g. acquiring data) faster is a competitive advantage, although this thing is still probably too slow for truly HFT-level tasks. reply rubenfiszel 12 hours agorootparentYes it&#x27;s too slow for HFT, but anything would be too slow for HFT unless it&#x27;s custom built. You likely want a streaming engine or even hand-optimize all your event handlers to shave-off any nanoseconds. reply stingraycharles 10 hours agorootparentAs someone who works with HFT firms, they typically do everything in ASICs or FPGAs anyway, so it’s not a good example. reply samsquire 11 hours agorootparentprevJust because I&#x27;m interested in this topic. I&#x27;ve been trying to shave nanoseconds on ringbuffers and barriers in C.LMAX Disruptor can send a message between threads in 53 nanoseconds on average.So you can essentially fork control flow in 53 nanoseconds and do 2 things in parallel.Eyeballing my barrier I can synchronize in 42 nanoseconds and up. reply esafak 10 hours agoparentprevSpeed is the number one reason I hate Airflow. It does not meet that \"certain threshold\". reply 3cats-in-a-coat 12 hours agoparentprevA workflow engine is indistinguishable from a regular interpreter or runtime, except for the fact it&#x27;s suspendable (hence can run tasks long).Ideally a workflow engine being fast means it can be just the platform you write everything in. The artificial separation between \"normal\" code and \"workflow engines\" is completely unnecessary. Our platforms are extremely fragmented, pointlessly so. Remote vs local, statically vs dynamically typed, async vs sync, short running vs long running...If an engine is written without these arbitrary limitations, it can be more. reply boxed 14 hours agoprevIt always amazes me that people spend this much time and effort on writing articles like this and don&#x27;t run their text through a spell checker even once.It also amazes me that people still use text editors that by default doesn&#x27;t spellcheck. Anyone know what editors that could be? Seems pretty crazy in 2023! reply andrewstuart2 14 hours agoparentIf this is an engineer, they probably use whatever tool they&#x27;re most familiar with, and that tool is probably set up for mostly engineering (code) work, in which case in my experience spell checking is a major distraction with an outsized ratio of false positives, because my identifiers aren&#x27;t chosen for their validity in a wordlist. Even in markdown, it&#x27;s more annoying than helpful most of the time, so I tend to leave it as a manual step that I mostly ignore. People know what I mean 99.99% of the time. So, that&#x27;d be my guess. Any sort of editor that&#x27;s been tuned to an engineer&#x27;s preferences which includes only manual spell checking. reply boxed 12 hours agorootparentPyCharm has a spell checker. It&#x27;s pretty great. Not using it seems madness. reply senorrib 2 hours agorootparentSpellchecker in Jetbrains IDEs is terrible. It throws a lot of false positives. reply j_maffe 13 hours agorootparentprevYeah, but this sort of article is what you get at the end of the day. Plus there are several ways of getting rid of false positives and as GP said: at least do it before posting. reply rubenfiszel 12 hours agoparentprevYou&#x27;re right, I apologize. Truth is I wrote everything in vscode markdown and really wanted to finish the article before going out for dinner and I ended up skipping it. We fixed everything reply cooperaustinj 11 hours agorootparentThe Code Spell Checker extension is great. It has proper handling for camelcase and it&#x27;s fast to add words to the dictionary (cmd + .). Catches many typos when coding.Probably not best for the last line of defence for public articles, but probably good enough.https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=streetsi... reply code_biologist 13 hours agoparentprevI turn off spell check in any text editor I touch because I can&#x27;t handle the visual noise. Agreed on running spell check. The few grammar issues in the article made my brain glitch for sure. reply boxed 12 hours agorootparentWhat noise? The noise of you making tons of spelling errors? reply Frivolous9421 6 hours agoparentprevwho craes reply atlas_hugged 12 hours agoprevIt says open source, then it says limit of 10 SSO users. IANAL so this confuses me. Can you explain what this means?Actually, that sounds rude, excuse the ‘tism, I’m sorry. I’m just not super familiar with the license stuff, I generally only touch MIT licensed code when it’s work related, but I thought open source generally allows modification to code. So how do you enforce a limit of 10? I just skimmed the code a bit because of this confusion and I see stuff about enforcing a license in there. So couldn’t anyone just remove that license check code if it’s open-source?If that can’t be modified, then it’s just “source available”, isn’t it? Which to me is also fine, I just feel like I’m being either misled, if you get what I’m saying?Basically I think this project is pretty cool, so I wanted to bring it up to my boss because I think we have a need for this, and I had previously brought up Airflow, but I don’t know how to explain this to her.Sorry for the stream of consciousness. Typing on mobile while answering Teams messages and tickets. reply rubenfiszel 12 hours agoparentSome people will argue we are open-core because almost everything is open-source (AGPL) but our sso and enterprise plugins are under a source-available proprietary license.The reason that we didn&#x27;t split them out of the codebase is that it&#x27;s harder to maintain and would require to load the plugins. We didn&#x27;t want to waste time on that when we had so much to build. reply atlas_hugged 11 hours agorootparentoh ok I see. Just the SSO part is like that. That makes more sense.So I guess I can just self-host for our team of 7 without SSO and we can finally organize these messy cron jobs we’ve accumulated. We would not be reselling at all. Just organizing some annoying aspects of our day to day.Thanks for the clarification. Much appreciated. If we end up expanding our usage down the road, I’ll see if I can convince her to consider shelling out funds for the SSO stuff too. I’d love to be able to support this project. Seems pretty cool! reply rubenfiszel 11 hours agorootparentYou can even self-host with SSO for 7 people. The SSO is free up to 10ppl.You will never have to pay if you do not want to.We believe there are many reasons to start using Windmill and most of them are not worth monetizing by themselves but we strive to build a software so great that you will move more and more stuff on there and at that point, you will want our enterprise plugins.We also mostly monetize bigger companies. reply jagged-chisel 12 hours agoparentprevI would hazard a guess that the SSO part is not open source and could be handled by a non-open plug-in. I should go read the code …Edit: sniped by someone in-the-know reply RandomBK 3 hours agoprevI would love to begin using this system, but the licensing is giving me serious pause. While most of the software is under the AGPLv3, the Commercial License section of the README [0] implies that the company takes on a fairly broad interpretation of the AGPL.In particular, the line \"[...] to build a feature on top of Windmill, to comply with AGPLv3 your product must be AGPLv3 [...]\" seems to imply the company aligns with the stance taken by Google and other companies: that even calling the application via API is enough to trigger copyleft [1].This implies that if I were to build a sign-up form that triggers a Windmill workflow in the backend, my entire application would either need to be AGPLv3 or I would need a commercial license.That&#x27;s perfectly reasonable, as it means any non-AGPL use will have to contribute back to Windmill via a commercial license. However, it does mean positioning this as an \"Fully Open-source\" alternative to Airflow is only technically correct. This is much closer in practice to \"source available\" than how most developers would think as \"open source\".If this isn&#x27;t how Windmill wants their license interpreted, I highly encourage clarifying things.[0] https:&#x2F;&#x2F;github.com&#x2F;windmill-labs&#x2F;windmill#commercial-license[1] https:&#x2F;&#x2F;opensource.google&#x2F;documentation&#x2F;reference&#x2F;using&#x2F;agpl... reply rubenfiszel 2 hours agoparentSorry for the lack of clarity. By product we mean white-labelling windmill, not triggering a script or flow by api. reply RandomBK 2 hours agorootparentGot it! That&#x27;s great to hear. It&#x27;d be great to explicitly clarify that in the README :)Out of curiosity: Have you considered alternative licenses like SSPL or the Elastic license, which make a clear(er) delineation between whitelabelling&#x2F;hosting vs simply using the application? I&#x27;m sure I&#x27;m not the first person to have written off Windmill because of the AGPL. reply rubenfiszel 2 hours agorootparentThose licenses are not open-source and likely to be more restrictive than what we currently offer. It was important for me to be truly open-source.If you are using windmill as a whole, you&#x27;re free to use it however you please with the AGPL but for customers with doubts, we do sell an enterprise&#x2F;commercial license. reply haroldp 13 hours agoprevIs this what I need? We have ad hoc business processes like:1. Sell service to client2. Email client with scheduling info3. Agree to scheduling date with client4. Send client email with documentation and request their data5. Remind client to send data6. Alert admins data hasn&#x27;t been received7. Beat data out of client8. Prepare data9. QA and checkoff service10. Email client to review and approve11. Publish&#x2F;run service12. Send client stats&#x2F;resultsAnd I want to move that from spreadsheets, personal emails and admins keeping in their head where everything is at, to web forms and uploads, automated emails and dashboards. I looked at airtable, smartsheet, budibase and many others but they seem to be very project-based, where you are inventing a unique workflow for each project and using it to keep managers on top of where their team is at with the various steps. Project Management vs process management. None of them seem to have decent calendar integration. Few of them seem to be great about emails or scheduled scripts.I have APIs for my data, or I can code them if needed. I&#x27;d prefer a low-code to a no-code approach, where managers have a spreadsheet view and can do some of of the UI work and programmers can make it do stuff and handle integrations. reply rubenfiszel 12 hours agoparentYes, windmill would likely be a great fit for that as long as you&#x27;re willing to do a little bit of coding.For instance, we do not have a calendar integration per se but can manage your oauth tokens towards any service (including gcalendar) and allow you to write code using their official sdks.For spreadsheets, you can build a similar interface in windmill using aggrid.It seems you also need approval steps and have your workflows wait for events, and that&#x27;s built-in in our workflows. reply MuffinFlavored 11 hours agoparentprevI wonder how far you&#x27;d get with the very \"not technical\" https:&#x2F;&#x2F;getjobber.com&#x2F;Only because you said \"sell service to client\", schedule date with client, etc. reply haroldp 10 hours agorootparentJobber looks like it is more in the \"project management\" space. All of my processes are post-sales. We&#x27;re not inventing new projects that we need to organize. We have a short list of services we sell and each of them has a process with a lot of dependent steps that require a lot of communication and coordination. reply MuffinFlavored 10 hours agorootparent> We have a short list of services we sell and each of them has a process with a lot of dependent steps that require a lot of communication and coordination.Something that comes to mind: In Jira my administrators have locked it down so I can&#x27;t move certain tickets to certain statuseshttps:&#x2F;&#x2F;www.atlassian.com&#x2F;software&#x2F;jira&#x2F;guides&#x2F;workflows&#x2F;ove... reply erichocean 13 hours agoparentprevI don&#x27;t think that&#x27;ll achieve your goals, it&#x27;s far too clunky and inflexible for actually running a business end-to-end. (No knock on Windmill, they&#x27;re all like this in my experience as the way they model the world is how a programmer thinks about things, not a business owner. BPMN is straight up cancer—avoid.)I would suggest looking at workflow systems within the VFX space, which they call \"pipelines\". They are human-driven and maintained, but support very high levels of process automation.VFX pipelines are written in Python, but the key thing is, they&#x27;re very good at a few things simultaneously:(1) Highly irregular work…(2) That nevertheless requires lots of process, including of the ad hoc variety…(3) With high human touch (human in the loop), so calendars, task assignments, timelines, approvals, producer dashboards, etc.(4) That&#x27;s repeatable on the next project&#x2F;opportunity, with as much customization as needed.As a bonus, pipelines handle billions of dollars of work annually under high pressure, with tens of thousands of users, so there&#x27;s a lot of hard won experience built into them.I personally have found that there are three levels of VFX pipeline tech that need to be combined and customized to do everything. This is the most recent stack I&#x27;ve set up:* Kitsu for the producer&#x2F;manager level, human task assignments. Mainly for managers, has the calendar functionality.* Prism Pipeline for software integration (i.e. keeping the humans following the process). This is what people actually do.* Kabaret for compute work. People usually kick off these jobs, but they&#x27;re handled by the farm. You&#x27;ll be responsible for everything that happens here. [0]Don&#x27;t try to get by with just one or two of the three, even though feature-wise it looks like you might be able to. Incorporating computer-driven workflows is tricky and requires purpose-built libraries in my experience. Just use the right library for the job, and accept that they all have somewhat overlapping functionality.For most non-VFX work, you&#x27;ll need to script access to the browser, since that&#x27;s where people do stuff today (i.e. with the Prism Pipeline library). Launch Chrome, Firefox, or Edge with a debug port and use Playwright as your \"plugin\" mechanism, with Prism&#x2F;Python as the driver. You can make your pages do whatever you want and script literally any web-based process, filling in fields from your database as needed, adding data to the page, etc.For the last six years, I&#x27;ve run a business that does around $5M of annual revenue using this approach, with 4 FTE people (including me). We handle around 40 million compute tasks a day, but also have all of the \"daily work\" where humans are in the loop. We do all of the tasks of the type you&#x27;ve listed.HTH![0] If you need fully automated task generation (so, no human in the loop), write \"pump\" scripts in plain Python that push jobs into Kitsu or Kabaret at a particular interval. I personally run them under a god monitor, and have them exit after, say, 15 minutes (or whatever interval makes sense) to get cron-like functionality. This is useful because you can pause execution of any pump process easily, change the interval, restart them, etc. plus you get easy access to the logs for debugging. The scripts themselves are usually less than 100 LOC. I have around 60 of these that run the automatic parts of our business.Whenever I need custom, temporary behavior in this part of the business, I copy the pump script, edit the original to avoid the special case, and have the new script only handle the special case (with whatever new behavior I need). Done, takes very little time, and is easy to run temporarily (e.g. for the next week, a common occurrence because some downstream vendor has caused a problem we need to work around).Another approach to trigger tasks&#x2F;workflows is to have a server that gets pinged by 3rd parties (e.g. Webhooks) and does the same whenever the endpoint is invoked. We have that too, but it&#x27;s literally just a few scripts. (Most workflow systems seem to believe this is damn near 100% of the stuff that needs to be \"automated.\") reply sisve 12 hours agorootparentSearching for \"Vfx pipeline\" just gave me visual effects stuff. Quite sure that was not what you talked about. Could you explain a bit more what ypu mean by it and point to a resource. Keen to learn more.I think windmill could have helped with several of the task and automated some. Its very easy to create dashboard and table with statuses. But its def not a process tool, if that was what he was after. reply Zalastax 11 hours agorootparentI would also like to understand better. But it seems like it is visual effects that is meant. These tools were mentioned by name: https:&#x2F;&#x2F;www.kabaretstudio.com&#x2F; https:&#x2F;&#x2F;prism-pipeline.com&#x2F; reply erichocean 11 hours agorootparentprevSorry, yes, VFX is \"visual effects\".A sibling already gave links to Kabaret and Prism.Here&#x27;s the link to Kitsu: https:&#x2F;&#x2F;www.cg-wire.com&#x2F;Github here: https:&#x2F;&#x2F;github.com&#x2F;cgwire&#x2F;kitsuAll of these projects are targeted at VFX&#x2F;animation, but there&#x27;s nothing about them that ties them to those things, it&#x27;s just why they were developed. You can use them to run any kind of business IMO.I posted about it because (a) they handle the commenter&#x27;s use case, and (b) most HN people are probably unaware they exist and would be discouraged into thinking they are only useful for VFX&#x2F;animation when in fact they are general approaches to running a business that requires high interaction between humans, processes, and background jobs in a very dynamic environment. reply sisve 10 hours agorootparentVery interesting. Thanks reply haroldp 12 hours agorootparentprevThank you for the detailed reply. reply bafe 12 hours agoparentprevLooks like the use case for BPMN and an engine that can execute processes described in that notation. reply foxbee 3 hours agoparentprevWhy did Budibase not suffice? reply michaelmcmillan 12 hours agoparentprevSame here. Use n8n. Self hosted and open source. reply jwildeboer 11 hours agorootparentIt’s not open source. reply michaelmcmillan 34 minutes agorootparentMy bad. You’re right. reply smrtinsert 10 hours agoparentprevAren&#x27;t these CRM use cases? reply goodpoint 13 hours agoparentprevIt is not. reply slig 15 hours agoprevI&#x27;ve been following Windmill since their HN Launch (my first script was edited 540 ago, just checked). Less than a year ago I started using it more heavily and it&#x27;s been a breeze. Their Discord server is very active and Ruben usually replies and fixes bugs in minutes, even on weekends. reply thelastparadise 15 hours agoparentWhat do you use it for? reply slig 15 hours agorootparentDaily puzzle generation, daily PDF updates&#x2F;creation (if the original content is changed, it triggers a new generation), triggering and editing of Remotion videos. reply code_biologist 13 hours agoprevWindmill is great. Definitely don&#x27;t stray from the self-hostable + DX mission! I haven&#x27;t had need to use it professionally, but I use it on a home server to run several small web crawlers and yt-dlp jobs. Really fun piece of tooling. reply darkteflon 13 hours agoparentCould you clarify what you mean by “definitely don&#x27;t stray from the self-hostable + DX mission”? reply code_biologist 13 hours agorootparentI hate cron for running small personal scripts and jobs. I hate ad-hoc handling of logging &#x2F; observability &#x2F; success monitoring. I want a web UI for all of it. I hate trying to figure out how to handle event based job triggers that are more fancy than the 10 line bash script they end up running. I hate trying to wrap up solutions for all those into infrastructure as code — I will end up running an unpatched Ubuntu 20 for the next decade if I can&#x27;t just nuke the box and reload my config + scripts. I hate the idea of relying on the continued existence of a hosted service, as well as them being able to see that I&#x27;m fine tuning an LLM for erotic stories (or whatever).Windmill solved all that for me. I write a short little Python script, paste it into the web UI and boom it&#x27;s running with good answers for all the above issues. That&#x27;s great DX.If workflow engines try to solve every problem they can devolve into plugin and complexity hell. Jenkins issues have caused a lot of headache at my day job lately. I don&#x27;t want Windmill to fall into the same trap. reply darkteflon 12 hours agorootparentThanks, that’s really helpful - agreed on all accounts! reply iFire 11 hours agoprevLICENSE ???https:&#x2F;&#x2F;github.com&#x2F;windmill-labs&#x2F;windmill&#x2F;blob&#x2F;main&#x2F;LICENSEI&#x27;m a bit confused. reply rubenfiszel 11 hours agoparentWe use a mix of AGPL for 95% of the code, Apache 2.0 for specs definitions and apis, and source-available for our enterprise plugins. reply SpaghettiCthulu 11 hours agoparentprevWhat on Earth is confusing about that? reply RandomBK 4 hours agoprevOne balance I&#x27;ve yet to find is how to handle the split between code-in-database (workflows stored in a database and edited via web IDE) vs code-in-git (workflows checked into the repo and only changed via the normal development+peer-review process).It looks like Workflow is primarily the former (code-in-database), but provides an API to sync things from a git repo. Is there a mechanism to enforce the rule that certain scripts&#x2F;functionality&#x2F;secrets are locked behind workflows sourced from a provided repository? reply alexchamberlain 13 hours agoprevInteresting that Windmill&#x27;s backend seems to be implemented in Rust, but the docs talk about supporting jobs written in Python, TypeScript and Go. I understand there is generic Docker support, but does anyone know if you can run Rust jobs natively? reply rubenfiszel 12 hours agoparentWe could add support for Rust, and it would work the same as go, do a built step prior, and then cache the binary. If we have enough demand for it, we will add it (we are a small team and can only prioritize what&#x27;s popular unfortunately).On a personal note, I write a lot of rust (and love it) but using rust for writing non-backend type of stuff is not something I would do myself. I&#x27;m more of a believer of hybrid like polars that optimize the compute in Rust but provide a compatible sdk in python. reply sisve 12 hours agoparentprevIt can not. (It does support go) reply knowsuchagency 14 hours agoprevWindmill is fantastic. It manages to cover so much ground i.e. airflow, prefect, retool, budibase but better reply nextworddev 14 hours agoparentIt’s mainly for workflows but not for building rest endpoints? reply sisve 14 hours agorootparentI think the workflow engine is the _best_ part of it, but together with the script editor (online code editor with LSP support) and a drag-n-drop app builder, that is for developers, so you \"drop down\" to code much of the logic and connect it to script or workflow, it&#x27;s a really nice combo. (you see a lot of other companies trying to span out to workflow + script + appbuilder).It&#x27;s really made for developers or at least people that want code as a \"first class citizen\" of the platform. So i has a cli to sync to&#x2F;from a VCS, VS code extention. But at the same time I have gotten a tech savvy person on the customer success team to create a workflow where they connect to our API and actually create meaningful services way faster then the enterprise developer team would have done.The script and flows get automatically endpoints to connect to, but all request is saved to db, and picked up by a worker that has to save the result to disk, before the server again pick up the result and send it to a client. So I would not use it to customer. I have used it for a lot of internal tools to employees. Meaning they can wait 1-2 sec, because you can teach them that it works and you provide a lot of value. reply ryanjshaw 13 hours agorootparent> It&#x27;s really made for developers or at least people that want code as a \"first class citizen\" of the platform.Power Automate doesn&#x27;t have this (unless you hack it into custom connectors) and it&#x27;s a really puzzling decision.I guess they want you to use Azure Functions but those need a PhD to understand and the deal with the security surface. reply nextworddev 6 hours agorootparentprevOk so nothing is stopping us from wrapping around it as a backend for a CRuD app? reply sisve 1 hour agorootparentNope you can totally do it. It also has a drag and drop app builder and support most frameworks as long as it is build in a certain way.https:&#x2F;&#x2F;www.windmill.dev&#x2F;docs&#x2F;react_vue_svelte_apps&#x2F;react replyj_maffe 13 hours agoprevThat graph is utterly useless. How hard is it to place units on a freaking graph? reply rubenfiszel 11 hours agoparentApologies, the units are seconds, fixing the graph right now. You will find more ample details on the benchmarks there: https:&#x2F;&#x2F;www.windmill.dev&#x2F;docs&#x2F;misc&#x2F;benchmarks&#x2F;competitorsWe made them as easy as possible to be reproduced reply majkinetor 12 hours agoprevI am using Rundeck now to schedule project jobs, get notified on errors, provide UI for PowerShells&#x2F;bash scripts, and have decent project and user management. It uses Quartz and can handle hundreds of jobs per minute without a problem. It can connect to git repository to keep job definitions there. I also use local file system a lot (on Windows or Linux) as I don&#x27;t like to edit my scripts in browser, given that they are mini programs with lots of separate includes.I would like to try windmill instead. Can it cover all those cases, particularly the part where scripts are on the file system? Can I use automatic GUI creation for PowerShell scripts of windmill in such case? Rundeck transmits environment variables with GUI values when starting script. reply rubenfiszel 12 hours agoparentNot only it can cover those cases, you will likely be pleased with the advantages of such system (the automatic GUI creation is just one of those).The binary itself doesn&#x27;t sandbox your processes unless you&#x27;re in the nsjail mode. Hence, if you either use the binary raw (without docker) or mount the filesystem to be available to your container, it can run anything that is available on the filesystem. reply majkinetor 10 hours agorootparentI played a bit now on cloud and was able to run things in powershell and create a custom GUI form, connect button to script and show results in the text area.I didn&#x27;t succeed to return all output from the powershell, just last value. The only way I got it is by using control \"job log\". This one however has some custom header of windmill (job guid etc.), so is there any way to show a raw log ?I generally do not like no-code tools, but first impression of this mix of no-code and code looks intriguing and app feels very nice overall, with great UI and easy to understand features. Good job. reply rubenfiszel 10 hours agorootparentSo bash and powershell are a bit special since they are the only one that are not implemented as using a main function and thus have no result to return.However, we had that feedback a few time so there is a trick. If you write your result in .&#x2F;result.json, we will process it as the result of your powershell script. reply majkinetor 10 hours agorootparentFinal question.Am I able to install it on Windows? I need windows specific things, such as powershell remoting. One of the good things about Rundeck is that server acts as worker, and it runs on Windows without problems (Installing it is as simple as choco install rundeck). I can then use all windows tools, run applications (including GUI ones) etc. just the same as if I run them outside rundeck, using OTB powershell. reply rubenfiszel 9 hours agorootparentYes, the binary can be compiled to windows and run there as a worker but it will need a connection to the main database. Not sure how currently rundeck does it ? reply majkinetor 8 hours agorootparentRundeck is a java web app, using (by default) embeddable database or file system for configuration and data (you could use mainstream databases, but I never needed that).Regarding \"Connection to the main database\" as far as my use case is, all the settings could live in the file system json files or sqlite if that makes installation trivial for the use case of being very good job scheduler with options to create great jobs UI, logs and management of small number of users (which is a fairly common scenario). replyradiowave 10 hours agoparentprevI looked in to this a little when Windmill was last discussed here, and the gap you may bump into (as a replacement for Rundeck) is that AFAICT Windmill has no support for executing scripts remotely over (e.g.) SSH and passing the GUI values along as environment variables.It seems you need a full-blown install of Windmill on each host where actions are to be run. reply rubenfiszel 10 hours agorootparentCurious why you wouldn&#x27;t be able to do this using a bash script in windmill and ssh to your target reply radiowave 9 hours agorootparentIt&#x27;s a good question, and deserves a more detailed answer than I&#x27;m able to give without more first-hand experience with trying to use Windmill in this way. But my sense of it is that there&#x27;s likely to be a chunk of legwork involved in the passing of parameters and credentially over to the remote host, capturing both stdout and stderr from the remote site - things that Rundeck handles pretty much seamlessly - and a concern that using Windmill like this the question of which host the job is executing on isn&#x27;t a first-class concept, like it is in rundeck.It&#x27;s likely that in time I will evaluate Windmill to get a more detailed understanding of this - there&#x27;s definitely aspects of it that are very substantial improvements on what can be done in Rundeck.But inevitably, the question of whether to learn & install & maintain two separate systems side by side, with some degree of overlap in their functionality, vs. just picking one system to do the whole job and living with the shortcomings of whatever it doesn&#x27;t do so well - it&#x27;s always going to be a difficult one to weigh up. reply slig 8 hours agorootparentYou can use any ssh client python library to do that. Also, this video from Trevor Sullivan is somewhat related https:&#x2F;&#x2F;youtu.be&#x2F;3_0z1UihDIo reply radiowave 8 hours agorootparentThanks. At first glance that does look to be in the right area. I&#x27;ll definitely check that out. replypunnerud 12 hours agoprevThe GitHub repo for the open source project gives a better intro&#x2F;sell: https:&#x2F;&#x2F;github.com&#x2F;windmill-labs&#x2F;windmill (Especially the video) reply MuffinFlavored 11 hours agoprevhttps:&#x2F;&#x2F;www.windmill.dev&#x2F;docs&#x2F;misc&#x2F;benchmarks&#x2F;aws_lambdaI did not realize at first glance you can write a script and then trigger it (with an API key, not sure if you can make a public one or if that&#x27;s a security nightmare) through HTTP to basically have your own self-hosted AWS Lambda &#x2F; the whole \"serverless HTTP triggers&#x2F;functions\" craze reply rubenfiszel 11 hours agoparentYes absolutely, we&#x27;re even faster than lambda with dedicated workers since the design is simpler, while loop jobs from the queue while still keeping all the error handling, observability, and easy deployment. reply MuffinFlavored 11 hours agorootparentIs there a workaround I&#x27;m missing where the URLs are exposed without needing an API key? (Something I&#x27;m pretty sure Lambda allows if you configure it properly) reply rubenfiszel 11 hours agorootparentThe api keys can be generated to be webhook specific (that&#x27;s what they are by default when you generate them in the script&#x27;s UX) and hence can be made public so there is no risk to expose them publicly, they are similar to a uuid of a lambda (not a key but impossible to guess).We require api key because every request is permissioned and hence we need to know who the script is executed on behalf of. For instance, scripts can fetch secrets&#x2F;variables but those calls will be permissioned with the permissions of the caller which in this case we get from the webhook specific token. reply slig 11 hours agorootparentprevNot natively, one workaround is using a simple CF worker that proxies the request. reply darkteflon 13 hours agoprevWhile appreciating that they’re not direct substitutes, does anyone have experience comparing Windmill with Dagster for managing dependency resolution in complex data pipelines? reply bafe 12 hours agoparentI briefly tried windmill for a project that involved creating custom workflows on-demand from a configuration file. I can&#x27;t recommend windmill for data pipelines, it is meant to be more of a low-code internal app platform like retool or budibase. It is meant for a relatively static workflow that requires human intervention, like a simple business process involving some API calls and humans approvals in the loop. For complex (and potentially reconfigurable) data pipelines, dragster is a much better choice reply rubenfiszel 12 hours agorootparentWhen you tried, we didn&#x27;t have s3 integrations nor restartable flows. We will present all of this in day 5 of our launch week and it might be a good time to revisit.I agree we were not a good fit prior. I think we would now compare favorably as we will offer excellent ergonomics for data processing, leveraging polars, duckdb, and other OLAP libraries to their full extent. reply bafe 12 hours agorootparentIt was several months ago, so it is entirely possible. Back then I got the feeling that windmill tried to be more of a low code business&#x2F;internal tool platform than a data&#x2F;ETL workflow tool, I especially missed an expressive way to define workflows programmatically (i think you had a JSON schema but nothing as powerful as dragster where you can define a whole workflow in pure python) reply rubenfiszel 12 hours agorootparentWe added a vscode extension to build everything from code, including manipulating the yaml or UI and have them instantly impact each other: https:&#x2F;&#x2F;www.windmill.dev&#x2F;blog&#x2F;launch-week-1&#x2F;vscode-extensionyaml is not real code and so the part that I consider to be real code is that each step is its separate file in python, typescript, that you can edit in your code editor and have your plugins working, testing frameworks. It&#x27;s normal functions that you can run locally.It would be possible for us to do like dagster&#x2F;prefect&#x2F;airflow which is to use a macro-processing step&#x2F;decorators to build dynamically the graph which is what our yaml is in the end, a 1:1 encoding of our dag spec called openflow: https:&#x2F;&#x2F;docs.windmill.dev&#x2F;docs&#x2F;openflow&#x2F;We didn&#x27;t do it yet because in most cases, the decorators are a lot like yaml, they are a very rigid way of declaring that some functions are nodes that you can chain in limited ways. On the other hand, not providing that mode allow us to put more efforts in the low-code graph builder for now.But, as someone that love compilers and built a few, I&#x27;m very eager for us to provide such a mode so it&#x27;s probably a few months away :)We&#x27;d love to have your input on the DX for data&#x2F;ETL once we present it Friday so feel free to join our discord or shoot me an email at ruben@windmill.dev reply bafe 11 hours agorootparentThank you for the extensive reply! The first part you mentioned is exactly what we were missing back then, we wanted to dynamically generate workflows starting from a configuration selected by the user. This wasn&#x27;t really possible unless we would generate the YAML openflow specification ourselves. At the end we gave up and rolled our own simple tool that just does what little we need. This said, it is cool that you are considering offering a more code-friendly way to define workflows. I still think this doesn&#x27;t offer the same level of dynamism of dragster, where you could easily design branching&#x2F;conditional workflows. I suppose your considerations regarding the decorators&#x2F;compilers go exactly in that direction reply rubenfiszel 2 hours agorootparentYes it goes in that direction, however note that you can already do this in a not too hard way.Our openflow spec is both open-source and has a full openapi definition: https:&#x2F;&#x2F;github.com&#x2F;windmill-labs&#x2F;windmill&#x2F;blob&#x2F;main&#x2F;openflow...you can use that to generate client sdks in any languages and build your own dag with it. That&#x27;s what one of our customer did building a reactflow to openflow library: https:&#x2F;&#x2F;github.com&#x2F;Devessier&#x2F;reactflow-to-windmillIt&#x27;s not as good as the decorator way but we move fast and if you still have interest for it we could prioritize it (and ask for feedbacks :)) reply darkteflon 12 hours agorootparentprevThanks Ruben - looking forward to the Dagster comparison post in the coming days. reply mhh__ 7 hours agorootparentprevI find dagster to be quite poor at dynamism. The software defined asset is fundamentally right but dagster just doesn&#x27;t nail it IMO reply darkteflon 12 hours agorootparentprevThanks - great to hear your perspective. reply me_bx 10 hours agoprevThe self-hosted pricing depends on the number of vCPUs used.Does this mean that Windmill installation pings back home with info about clients? reply brunoqc 11 hours agoprevIt&#x27;s open-core (if you care about that).\"The SSO is free up to 10ppl.\"It&#x27;s weird that \"Content Search\" is such a pro feature. reply rubenfiszel 11 hours agoparentOnly if you deem SSO to be of an essential nature to such products. To me it&#x27;s all semantics at this point.But it&#x27;s a complex software that require software engineers with salaries and we do not want to rely on donations so we do have to give reasons for people to pay. SSO and audit logs are good ways to segment enterprises to support the project. reply brunoqc 10 hours agorootparent> Only if you deem SSO to be of an essential nature to such products.I thought that multiple features were enterprise-only (like multiplayer, the content search...).In our world where we don&#x27;t take security seriously enough, I do think that SSO is essential. reply ketozhang 7 hours agoprevDid you guys considered existing standards when you chose what to use for representing workflow definitions before choosing OpenFlow? For example, Common Workflow Language reply rubenfiszel 2 hours agoparentWe did and started with an existing standard but quickly, trying to fit to the standard was more complex than rolling our own.Agreed we just created yet one more standard but the bit about the input transforms being full javascript expressions or the way we encoded suspend steps was impossible to retrofit. reply vlugorilla 11 hours agoprevBeen using windmill for a few months, and it&#x27;s very pleasing. One of the best self-hosted tools I have! reply haolez 10 hours agoprevI could use this as a bridge between developers and operation, but in my case the lack of localization is annoying for the staff in the ops side. I don&#x27;t have time to contribute something like this right now, but I will keep an eye on this. reply gigatexal 13 hours agoprevHi Windmill devs -- why build this on relational Postgres at all? I&#x27;ve been toying with the idea of forking airflow and trying to swap out the backend for something document based either on Mongo or something else.The reasons being db migrations are a pain in the relational strongly typed schema world vs the more forgiving paradigm of documents. reply rubenfiszel 11 hours agoparentbecause 95% of the tables you need for this are relational (queue, completed_job, users, etc, etc) and for the few things that are unstructured, you can represent them well in PG with JSONB (which is what we do for inputs and outputs). reply cyanydeez 13 hours agoparentprevwhat&#x27;d be wrong just storing your documents in postgres JsoN Or XML fields reply gigatexal 12 hours agorootparentThat could work too I guess. reply DonnyV 13 hours agorootparentprevBecause Postgres is a relational database. reply cyanydeez 11 hours agorootparentthat wasn&#x27;t the concern being presented. The concern is \"I want to store mostly unknown structured data, so why dont I use a DB already stupd to do that\" reply jgil 13 hours agoprevWhat are the units for the x-axis? I&#x27;m assuming milliseconds from context, but not having the axis labeled obfuscates the interpretation. reply rubenfiszel 12 hours agoparentIt&#x27;s seconds. You can find all the detailed numbers there: https:&#x2F;&#x2F;www.windmill.dev&#x2F;docs&#x2F;misc&#x2F;benchmarks&#x2F;competitors reply namtab00 9 hours agoprevI&#x27;m trying to understand in what way this differs from node-red. reply victorbjorklund 14 hours agoprevLooks very similar to the UI of Pipedream that I used before. Not a negative thing. Will try it. reply slig 13 hours agoparentI migrated from Pipedream, Windmill is much, much more developer friendly. reply DonnyV 13 hours agoprevThis looks interesting. I wonder if they will be adding compiled languages like C#? reply CuriousSkeptic 13 hours agoparentMight want to checkout DurableTasks[1] for that[1] https:&#x2F;&#x2F;github.com&#x2F;Azure&#x2F;durabletask reply rubenfiszel 12 hours agoparentprevyou can always run compiled programs from bash as binaries (but yeah it&#x27;s not as great as an experience than being able to run interpreted languages directly). reply whoiscroberts 9 hours agoprevHow does this compare to Prefect? reply rubenfiszel 9 hours agoparentit&#x27;s faster, it supports more languages (python, but also typescript, bash, go, and raw queries to different databases)The rest will be a matter of taste reply zegoverno 15 hours agoprevgreat product! reply Kiro 15 hours agoprevI don&#x27;t think this should be a Show HN.> Off topic: blog postshttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;showhn.html reply dang 15 hours agoparentThanks, I&#x27;ve taken Show HN out of the title now. reply rubenfiszel 15 hours agorootparentCurious, what&#x27;s the difference between an article and a blog post ? reply pvg 14 hours agorootparentArticles generally can&#x27;t be show hn&#x27;s either so it doesn&#x27;t matter much for the purposes of Show HN. The full thing is \"Off topic: blog posts, sign-up pages, newsletters, lists, and other reading material. Those can&#x27;t be tried out, so can&#x27;t be Show HNs. Make a regular submission instead.\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;showhn.html reply 0xbadcafebee 14 hours ago[flagged]| prev [–] > we wanted to prove it&#x27;s also the best system to deploy at scale in production> The queue is implemented in Postgresql itselfTell me you don&#x27;t understand system design without telling me you don&#x27;t understand system design reply dang 14 hours agoparent\"Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.\"If you know more than others, that&#x27;s great, but in that case please share some of what you know—without putdowns or snark—so the rest of us can learn.https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&sor...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply ryanjshaw 13 hours agoparentprevI would argue that implementing your internal queues inside your DB is sound system design. Your backups and system restores are as simple as it gets. You should have a specific reason to do anything more complicated. And no, \"deploy at scale\" is puffery, not a good reason. reply igortg 13 hours agoparentprev [–] Any known issue on implementing a queue with Postgres? Do you at least know it has a pretty good pub&#x2F;sub mechanism? reply 0xbadcafebee 6 hours agorootparentConnection limits, locking issues, concurrency issues, multiple consumer&#x2F;producer issues, dead-letter, record expiration, performance limits, scalability limits, lack of gateway, lack of interoperable standards, tightly-coupled applications, general architectural limits.Can you \"work around\" all that? Sure, it&#x27;s technically possible (well actually it&#x27;s not possible to solve all of the above, but most of it). Just like it&#x27;s also possible to take a mini-van and convert it into a hot rod, so it can pick up groceries after it&#x27;s entered in a drag race. It will just cost you a lot of extra time and money, and do both jobs poorly.It&#x27;s NIH syndrome plain and simple. Hipster nerds who want to invent something for fun, rather than using something off the shelf. People decrying \"complexity\", who then poorly implement complexity themselves, in the form of functionality shoved into a system not built for it. Software architecture by HN meme. reply otabdeveloper4 41 minutes agorootparentBy \"queue\" they mean here a table with the columns (job_id, job_status, update_time).You could store that in a text file, there aren&#x27;t really any serious requirements. reply mmcclure 13 hours agorootparentprev [–] Postgres is having a moment with excellent queueing libraries right now, not sure what GP is referring to. We use Oban[1] at Mux for some workloads and love it, and a former colleague just built something similar in Go that was on the front page yesterday (River)[2].[1] https:&#x2F;&#x2F;github.com&#x2F;sorentwo&#x2F;oban[2] https:&#x2F;&#x2F;github.com&#x2F;riverqueue&#x2F;river replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Windmill Labs asserts that its self-hostable open-source workflow engine, Windmill, is the fastest compared to other well-known workflow engines such as Airflow, Prefect, and Temporal.",
      "Windmill offers support for multiple programming languages and provides an integrated development environment for the rapid building and testing of workflows.",
      "Unlike Temporal, Windmill stands out in executing arbitrary jobs on an internal cluster and relies on Postgresql and Rust in its system design, contributing to its impressive performance."
    ],
    "commentSummary": [
      "Windmill is a self-hostable open-source workflow engine designed for building internal software in enterprises, offering performance, an active community, and support for multiple programming languages.",
      "Approval for using Windmill in enterprise environments and migrating from existing solutions are major concerns discussed in the article.",
      "The company behind Windmill believes open-source is the best approach for infrastructure-level software and targets enterprises looking to automate workflows. Users highlight the ease of use, self-hostable nature, and support for various tasks as positive aspects of Windmill. The discussion also covers features like code and no-code options and the use of Windmill for data pipelines."
    ],
    "points": 322,
    "commentCount": 157,
    "retryCount": 0,
    "time": 1700677984
  },
  {
    "id": 38384952,
    "title": "Discover AMD's GPUOpen Ecosystem for Aspiring Graphics Programmers",
    "originLink": "https://gpuopen.com/learn/how_do_you_become_a_graphics_programmer/",
    "originBody": "New or fairly new to AMD’s tools, libraries, and effects? This is the best place to get started on GPUOpen!",
    "commentLink": "https://news.ycombinator.com/item?id=38384952",
    "commentBody": "How do I become a graphics programmer?Hacker NewspastloginHow do I become a graphics programmer? (gpuopen.com) 282 points by pjmlp 13 hours ago| hidepastfavorite131 comments stemlord 11 hours agoI would suggest that beginners not lead with \"which tools should I capitalize on\" and instead, take a step back and ask \"what do I want to make\"? Don&#x27;t lose focus on the final output as you make your first steps. In the world of computer graphics today there are so many tools that abstract away various steps in the process of drawing pixels to the screen that you could very easily waste too much time suffering with low level code up-front and then later realize that the niche field in the wide array of industries that utilize graphics programming that you want to pursue actually only hires people who use Unity, TouchDesigner, threejs, and after effects and don&#x27;t actually write a lick of C++ unless push comes to shove, and even then they might just contract an outside engineer for it.Not to say that learning how things work on the ground level isn&#x27;t immeasureably valuable, but I think trying to do that first is the slow approach. Learning is accelerated when 1) you enter the industry (so you should prioritize output up-front and let the deeper learning happen when you&#x27;re earning a paycheck for it) and 2) you get a better conceptual understanding of what&#x27;s happening under the hood offered by tools of abstraction like a game engine or visual programming paradigm.This comes from someone who spent many years trying to learn cpp and opengl the hard way only to endure a long battle against an internal sunk cost fallacy I&#x27;ve harbored that kept me from taking the no-code approach. Don&#x27;t waste your time taking this path if it doesn&#x27;t help you make what you actually want to be making at the end of the day. reply ryandrake 9 hours agoparentListen to this guy, great advice. Early in my career, I set out to become an \"OpenGL expert\" and I&#x27;d say I mostly got there. I mean I&#x27;m no Mark Kilgard and haven&#x27;t written any textbooks, but I dove super deep into the technology, and gained at least a decade of experience working on all levels of the API from the driver level to conformance tests and performance tuning, up the stack to game and application code, and across each major desktop and mobile platform.Where did it get me? Not very far, really. First of all, almost nobody cares about OpenGL anymore--it&#x27;s kind of dead with the two major OS vendors finally abandoning it. Go to any \"HN Who&#x27;s Hiring\" and text search for OpenGL. Sure, I could have gone and re-skilled and learned another similar graphics API, but the second problem is nobody really needs people who write low-level Direct3D or Vulkan or Metal anymore because that&#x27;s all abstracted for you by engines. And there are max 5 or 6 companies in the world that even have the need for people who can do low-level graphics drivers. It&#x27;s a career-limiting niche.The smaller the piece of the machine you focus on, the more of a world-class expert you need to become in order to make it your whole career. So, unless your plan includes becoming the next John Carmack or something, I&#x27;d recommend going broad rather than deep. reply vlovich123 4 hours agorootparentI feel like better expertise targets tend to be more durable. In other words, rather than expert in a specific technology or technique, the best experts had the ability to develop expertise in any given technology within a space and often overlapped cursory knowledge with other spaces. I met plenty of graphics experts at Oculus and they didn’t care so much about whether it was D3D or Vulkan - originally they were D3D engineers for PCVR and then a good chunk of them shifted to Vulkan once the focus shifted to mobile VR. They just knew how those APIs mapped to the actual HW reality, how things connected, why things were slow, how to improve performance, etc. The mundane stuff of “what is the sequence of steps to do X in Vulkan” is answered by Google&#x2F;StackOverflow (or even these days ChatGPT). Heck, a good chunk of them were creating their own new APIs. This isn’t unique to Meta by the way. It’s like engineers who say they’re “C” or “C++ experts”. With the exception of authors like Scott Meyers or people working on the C++ language spec who I think can truly maybe claim that title, the kind of thing that is called a “language X expert” is the kind of expertise that a good engineer should be able to develop in any language with 2-3 years of practice and proficient mastery within ~3-12 months because the true expertise is the underlying CS principles (at least for a family of languages - I’ve never done too much with non-Algol families so I don’t know how I’d fare there).However, I do agree that generally graphics engineer is a niche limited to the few people working on gaming engines, VR R&D, or animation R&D. But those skills, at least today, are generally transferable to AI engineering because GPU compute plays such a huge role. There’s less graphics programming of course and the APIs for GPU compute are a bit different, but AFAIK many of the hardware concepts remain (e.g. wavefronts, how GPUs do threading, etc etc). reply pjmlp 3 hours agorootparentWhen people like Bjarne Stroustoup, Herb Suttter, Andrei Alexandrescu say they are by no means a C++ expert, always beware of anyone that says otherwise.Same applies to most languages, unless they are talking about toy languages.Even something like C or Go, have so much room to debunk such experts. Between compilers, versions, language evolution, runtime, standard library, OS specific behaviours,.... reply loup-vaillant 21 minutes agorootparent> When people like Bjarne Stroustoup, Herb Suttter, Andrei Alexandrescu say they are by no means a C++ expert,Then you know something is deeply wrong with C++. If even they aren’t experts, that just means the language, despite being a human made artifact meant to encode human thought, is beyond human comprehension.That’s kind of a problem, isn’t it? reply matheusmoreira 3 hours agorootparentprevThat&#x27;s pretty sad. Without people like you, the engines all the others use would not exist. It always saddens me to see people making millions off of high level tools while the people who made it possible get limited returns. reply raincole 7 hours agorootparentprevBut without people like you (who understands the low-level graphics programming), the development of engine will completely stagnate. reply BobbyJo 5 hours agorootparentAnd without slaves, the pyramids would never have been built. reply ywain 1 hour agorootparentI&#x27;m not sure I understand how your analogy is relevant to the discussion, but you should know that the current consensus is that the pyramids were build by paid laborers, not slaves. Cf. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Slavery_in_ancient_Egypt#Great... reply thejazzman 4 hours agorootparentprevyikes. reply nahumfarchi 2 hours agorootparentprevThat escalated quickly reply flohofwoe 2 hours agorootparentprevFocusing on a single technology never was a great idea though. Even already towards the end of the 90&#x27;s D3D was the better choice on Windows, so one had to write code against multiple 3D APIs anyway. This also gives a better perspective where the strengths and weaknesses of the different technologies are and it makes it easier to learn new APIs. But in the end, 3D APIs are just a utility to write applications (mostly games), not to build one&#x27;s career upon. 3D APIs come and go and are (to some degree) also subject to fashion cycles, the underlying GPU hardware develops a lot more predictable than 3D APIs (e.g. especially Vulkan had pretty bad \"mood swings\" recently).Of course when focusing strictly on money and \"career growth\", going into game development is a pretty bad idea to begin with ;) reply DanielHB 19 minutes agoparentprevMuch like sorting algorithms I still think there is some value of teaching this kind of low-level programming in college. You gain a lot of theoretical knowledge as well as a lot of heavy complex algorithm training even if you never end up doing that kind of work in a real job.With graphics it also gives you a lot of applied _math_ experience, there are a TON of fields that are desperate for people who can do math. Just my last job (software for CNC machines) we needed people who could do program the math necessary to program a drill to but a certain shape into a metal block and it was really hard to find these people. Yet, for example, cloud devops engineers, although expensive, were readily available reply beAbU 1 hour agoparentprevThis is the classic trap that new developers step in all the time. It&#x27;s not just associated with graphics programming.Youtube is full of beginner programming videos that take the developer through a journey of learning a stack of technologies in stead of focusing on something interesting to build. You end up with a lot of cargo-culting, and these massively complex Ruby Goldberg contraptions to render some text on a web-page. All in the name of padding out that CV.When I was in university I dabbled with some graphics programming for a semester, and I found it was sufficiently complex that the only reasonable answer to \"what do I want to make\" was \"render a green triangle on a black background\". Going from there to square, to cube, to sphere, to animated sphere, to bouncing ball, is a logical progression and it helps you stay focussed on the prize. So don&#x27;t also make the mistake of answering the above question with \"first person shooter with ray-traced lighting and subsurface scattering\".I can promise you the first iteration of a bouncing ball will be truly horrible code. But that&#x27;s fine. Over time you&#x27;ll figure out how to optimise and improve things. And let me tell you, there&#x27;s nothing as invigorating as discovering a design pattern by yourself: reading a book on a new topic and going \"hey I&#x27;m already doing that!\" reply TheRoque 5 hours agoparentprevWell, as someone looking to get into this field, I kind of disagree. A lot (if not all) job postings about graphics programming require you to know C++ beforehand. Sure, you can have another role, like gameplay programmer, and slowly work your way in graphics, and it&#x27;s probably easier to do so, but in fine, for the graphics programmer role, C++ is required.What you are describing is more about someone who wants to be productive with graphical stuff fast, but it&#x27;s not graphics programming. reply meheleventyone 2 hours agorootparentThere’s two or three strands of graphics programming though:Plumbing - Delivering data efficiently from the game engine to the GPU often in a platform agnostic way with efficient implementations underneath.Art Pipeline - Delivering data efficiently from the artist tools to the game engine.GPU Programming - Creating visual effects, shaders, compute shaders and tools around these to empower artists.All of these use multiple languages, sure C++ is a common one and good to know (likewise as a gameplay programmer) but the bigger percentage of what you need to know as a graphics programmer isn’t how to write C++ but the concepts you’re trying to implement with it.There’s also R&D but it’s a much smaller part of things. reply flohofwoe 2 hours agorootparentprevPeople shouldn&#x27;t be disillusioned though when they find out that there&#x27;s not such a big need for the traditional role of graphics programmer who wrestles directly with lighting models in shader code and shadow rendering implementations. 95% (or so) of game industry jobs is plumbing engine-provided components together, writing some very high level gameplay code and maybe a bit of inhouse tools development. The hard rendering tasks are done by a handful engines now, and currently the pendulum seems to swing away from inhouse engines towards UE5 again. reply pjmlp 3 hours agorootparentprevFirst learn the foundations, then the language.When I started, graphics programming was all about Assembly.Then it was about Object Pascal and C, then it was about C++, now it also requires C#.And who knows, maybe in 20 years, one of the C++ wannabe replacements manages to also have a spot, or some AI driven thingie.Those will solid foundations in graphics programming algorithms, will manage regardless of the language. reply captainkrtek 10 hours agoparentprevThis is great advice. I think it’s a common trap when I see questions like “what language should I learn&#x2F;what language is the best”, which skip the point of “what would you like to build”. The tools change with time, and the best engineers in my experience generally know how to use a variety of tools with varying degrees of skill rather than be super deep in a single one. reply nullptr_deref 2 hours agoparentprevThis is hands down the reality and the best advice out there. No one cares if you are able to do vulkan for 8 years EXCEPT for research labs.And getting there requires that - you either have a PhD or the exact experience (threeJS, unity etc) as above because that will help you set foot on industry effectively allowing you to work on higher abstraction and slowly&#x2F;rapidly decent into low level code. reply quelsolaar 10 hours agoprevAs a graphics programmer i think its good to have a well rounded idea about how graphics works. Here are some things I would expect a good graphics programmer to know, beyond just programming and an API:-Rotation view and projection matrices, and general vector math.-Shader programming.-Procedural primitives like voronoi, SDF and perlin.-Image Compositing.-Forward and deferred rendering.-Various sampling techniques.-Shadow and lighting techniques.-Knowing a bit about how the art pipeline works and how to get data out of 3D apps.-Being comfortable using a profiler and debugger.-Capable of reading Siggraph papers.-Knowing various spacial partitioning and volume hierarchy techniques.-Being able to build a simple raytracer.-Good understanding of primitives, like sprites, triangles n-gons and so on.-Some particle and simulation experience. reply rajangdavis 2 hours agoparentWhere do you learn this stuff? reply quelsolaar 33 minutes agorootparentA good start would be the book Real-Time Rendering: https:&#x2F;&#x2F;www.realtimerendering.com&#x2F; reply rustybolt 1 hour agorootparentprevGoogling it works pretty well reply Buttons840 11 hours agoprevI&#x27;d recommend the Pikuma course Graphics From Scratch[0]. The first thing you do is write a set_pixel function utilizing SDL and the rest of the course is all your code, every matrix operation, every vertex transformation, every triangle rasterization. You calculate what every individual pixel should be colored.[0]: https:&#x2F;&#x2F;pikuma.com&#x2F;courses&#x2F;learn-3d-computer-graphics-progra... reply ggambetta 19 minutes agoparentMy website&#x2F;book&#x2F;course does the same thing, and it&#x27;s freeeeeee! https:&#x2F;&#x2F;www.gabrielgambetta.com&#x2F;computer-graphics-from-scrat... reply torginus 31 minutes agoparentprevThere are a couple of excellent resources out there for implementing 3D rendering from scratch.On that I cannot recommend enough is this github repo:https:&#x2F;&#x2F;github.com&#x2F;ssloy&#x2F;tinyrenderer&#x2F;wiki&#x2F;Lesson-0:-getting...If you are more of a visual learner, this guy is also a treasure trove:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ih20l3pJoeU reply ggambetta 16 minutes agorootparentWow, that first link is fantastic, thanks for sharing! reply rmshin 7 hours agoparentprevJust wanted to second this recommendation. I did the course a few months ago with near-zero baseline in graphics programming (though a few years&#x27; experience as a standard swe), and it gave me a pretty decent grasp of how 3d shapes get drawn on the screen. Afterwards I was able to pick up webgpu in a matter of days, which I don&#x27;t think would&#x27;ve been possible without the understanding I gained from the course.If anyone&#x27;s looking for motivation, I made a wasm-compiled demo of the renderer you produce by the end - https:&#x2F;&#x2F;rmshin.github.io&#x2F;3d-renderer-wasm reply starmole 10 hours agoparentprevI find this very interesting. I have been toying around how I would design a graphics 101 course myself. Should it start with putpixel style sdl code like we did in the 90s? Or start with shadertoy? Of course basic matrix math is always important. But how to teach rasterizing a triangle? Can we skip to homogenous coordinates and quad trees without going through scan lines? Should we really teach Phong shading or can we move straight to BRDFs? Some parts might be teaching \"old hacks\" instead of relevant skills. Statistics and sampling are way more important today. I believe graphics is getting more \"mathy\" every year. So learn math, teach math. reply corysama 5 hours agorootparentI started with putting pixels in MCGA to CPU rasterize phong shaded triangles, and I don’t recommend it.Instead, I’d recommendhttps:&#x2F;&#x2F;learnopengl.com&#x2F; https:&#x2F;&#x2F;raytracing.github.io&#x2F;books&#x2F;RayTracingInOneWeekend.ht... https:&#x2F;&#x2F;fgiesen.wordpress.com&#x2F;2011&#x2F;07&#x2F;09&#x2F;a-trip-through-the-... https:&#x2F;&#x2F;foundationsofgameenginedev.com&#x2F; https:&#x2F;&#x2F;youtu.be&#x2F;j-A0mwsJRmkThough, if you really do want to put pixels, this is how you should do it: https:&#x2F;&#x2F;gist.github.com&#x2F;CoryBloyd&#x2F;6725bb78323bb1157ff8d4175d... reply charcircuit 11 hours agoparentprev>No GPU, no OpenGL, no DirectX!This is the opposite of what you would hope to see for learning graphics programming. reply ChuckMcM 10 hours agorootparentI feel like this comment perfectly captures the difference between programming and coding.Programming comes from a place of first principles, the goal being to understand what is needed completely so that a solution that meets many parallel constraints can be constructed.Coding comes from a place of completing a task, the goal being to get from the requirement to the operating task in as short a time as possible so that one might move on to the next task.Both disciplines have value. The original question was unclear about where the author hoped to end up.To put this in a slightly different perspective, a graphics programmer can write a program to show a shaded object on any platform with a CPU and a way to display graphics. A graphics coder can write a program to show a shaded object only on those platforms where they have previously mastered the APIs for generating display graphics. reply lackbeard 10 hours agorootparentGood comment, and, basically, I fully agree, except, I really dislike your attempt to appropriate the words \"programming\" and \"coding\" here. Like, can you just explain what you mean without trying to redefine terms that have broadly accepted definitions distinct from how you&#x27;re trying to use them here?(Sorry, this probably sounds more critical than I&#x27;m intending...) reply ChuckMcM 9 hours agorootparentNo worries, got to use something as the holder of the definition. FWIW I read a similar essay that discussed cooks and chefs and came away seeing the many parallels with programming and coding. reply caslon 9 hours agorootparentprevProgramming requires creative thinking. Coding, historically, was a lower-paid, unskilled position.You may think this is redefinition. It&#x27;s not. This is how both terms originated. A \"coder\" did the unskilled gruntwork of implementation for business projects, while a programmer was holistic.> I find it bizarre that people now use the term \"coding\" to mean programming. For decades, we used the word \"coding\" for the work of low-level staff in a business programming team. The designer would write a detailed flow chart, then the \"coders\" would write code to implement the flow chart. This is quite different from what we did and do in the hacker community -- with us, one person designs the program and writes its code as a single activity. When I developed GNU programs, that was programming, but it was definitely not coding.> Since I don&#x27;t think the recent fad for \"coding\" is an improvement, I have decided not to adopt it. I don&#x27;t use the term \"coding\", unless I am talking about a business programming team which has coders.https:&#x2F;&#x2F;stallman.org&#x2F;stallman-computing.htmlIn this case, it is you, and the wider cottage industry of business \"coders\" who are doing the appropriation. It&#x27;s not your fault. The bootcamp or Super Cool Totally Serious College you likely learned from probably used the term \"coder\" alongside words like \"rockstar!\" You were given a bad definition, and never knew any better at all. ChuckMcM&#x27;s comment, on the other hand, is correct. Using the word \"literally\" to mean \"figuratively,\" while colloquial, is still less correct than figuratively.The phrase \"code monkey\" is not a compliment, and didn&#x27;t come from nowhere. It came directly from these pre-existing definitions.Programming requires logic. If you are coding, the thinking&#x27;s already been done for you. You are just doing unskilled labor akin to data entry to get the computer to actually follow the instructions. reply NikolaNovak 10 hours agorootparentprevI like the distinction, and I think there should exist different terms, but I don&#x27;t think those two are nearly universal. Many people will use them interchangeably, others may even think other way around (\"programming\" as a professional discipline where you use tools to achieve an MVP most efficiently, vs \"coding\" as an enthusiastic activity that&#x27;s more creative and open ended). reply dkjaudyeqooe 9 hours agorootparentprevThere is a lot to be said for understanding things from first principles, but not everyone wants to go that low. Not everyone is that nerdy or maybe hasn&#x27;t the time or motivation.The other issue is that not everyone learns well from the bottom up. I believe that top down is a much better way of learning anything, and lets you progressively get closer to first principles while not discouraging learners with a steep difficulty curve. But unfortunately is an approach that is seldom facilitated by anyone. reply dragontamer 10 hours agorootparentprev2D graphics with bitblits is a completely different paradigm. If you were using 2D GPUs from the 90s, or maybe a 2D Industrial PC&#x27;s GPU, sure... Learning about Bitblits and rects is good.But if your goal is to program a modern shader on a modern platform (even if it&#x27;s a 2D graphic), you should learn a modern graphics library.-------A modern graphics API is laid out the way it is: to maximize modern performance on modern systems. A first principles bottom up approach will absolutely cover shaders (maybe compute shaders are easiest?) reply crq-yml 7 hours agorootparentThere&#x27;s a lot of leeway to learn 3D principles through a basic software rasterizer. It does not take long - if you already have some awareness of the math, it&#x27;s at most a few weeks to work through the essentials from a tutorial. Once you get to the point where you&#x27;re drawing filled triangles through a projected camera, you can move on. There&#x27;s no need to go into occlusion culling strategies, texture mapping or lighting calculations, or really to make the rasterizer fast in any way. That wouldn&#x27;t be the point of the exercise. It could be done entirely with a fixed-size bitmap and a setPixel(x, y, v) call.The argument against \"just\" using the hardware is that the hardware resists learning that conceptual skeleton. Instead of learning how a rasterizer is implemented, you learn the specific API incantation to bring one up, and that has changed a lot over the years in the direction of being a more professionalized phenomenon, so now it&#x27;s much easier to start application top-down, from within a premade rendering environment like a game engine or Blender&#x27;s rasterizers.Learning to work on production rendering engines would involve reading and studying existing implementations, reading the relevant research papers along the way. reply charcircuit 10 hours agorootparentprevYour definitions are made up.Programming refers to the act of writing a program for a computer to follow.Coding refers to the act of writing code for a computer.Edit: The definitions are not commonly used this way and in fact I&#x27;ve heard other people even give opposite definitions to what correponds to which word. reply javajosh 10 hours agorootparentHate to break it to you, but all definitions are made up. The question is whether or not the distinction is useful or not. In my opinion, it seems useful to distinguish between understanding oriented tasks and goal oriented tasks. reply delta_p_delta_x 10 hours agorootparentprevPersonally... I disagree. The course says:> You&#x27;ll learn how a software 3D engine works under the hood, and ... write a complete software rasterizer from scratchWriting a software rasteriser is a fantastic way to learn the classic graphics pipeline, Every single aspect of said pipeline offers scope for one to learn more about how GPUs work, and the algorithms behind them. This would be immensely educational to a new graphics developer.Vertex processing, including fast, efficient file parsing, vertex data layout and storage, and optimisation.Fast primitive assembly from vertices, including line-drawing and interpolation algorithms.Texture mipmapping, and mapping.The rasterisation phase itself offers tons of opportunity, from Bresenham&#x27;s line drawing algorithm to supersampling, tiled rendering, parallelisation, and efficient memory layouts for cache locality.Clipping, culling, hidden-surface removal, z-buffering, and stencil tests.Various other algorithms that are taken for granted with a pre-existing graphics pipeline, like texture lookup, vector reflection, environment mapping.Post-processing and miscellaneous algorithms like anisotropic filtering, multi-sample anti-aliasing, temporal anti-aliasing, and even deferred rendering. reply charcircuit 10 hours agorootparentIf you want to learn webdev you don&#x27;t start by building a web browser despite the fact that building a web browser would teach you a lot. reply delta_p_delta_x 10 hours agorootparentWeb dev is sufficiently abstracted from the browser and the hardware that a skilled web developer doesn&#x27;t really need to know the internals of the V8 engine or how a browser works. A web back-end developer probably doesn&#x27;t need to deal with the browser at all.Graphics programming skill (by &#x27;skill&#x27;, I mean being able to write a shader pipeline that both satisfies the art direction and performs well), on the contrary, is very deeply tied to a good understanding of hardware. Especially now that the new APIs (Vulkan, Metal, D3D12) are purposely less abstracted than their predecessors. reply charcircuit 9 hours agorootparentAll programmers at a certain level must understand the lower levels of the stack they are building upon. I think most people can get by with just learning the abstractions that are provided to them. With time people can learn more and more about lower levels as they specialize. Most people who become graphics programmers don&#x27;t need to know the low levels of how a GPU works, so I personally do not think that is a good place to start for people who want to get into graphics programming. reply achierius 8 hours agorootparentAre you a graphics programmer, or are you just saying this because that&#x27;s true in the CPU world (where you have experience)? From both my own and my colleagues&#x27; experiences, I would 100% disagree: the nature of GPU architectures means you are forced to deal with super low-level details from the very beginning. Part of this is because graphics (and GPGPU compute) programming is inherently performance-constrained: if it wasn&#x27;t, you could just do your work on the CPU with much less of a headache. Even just generally though, the path to running code on a GPU is much simpler — the hardware does less work for the programmer, there&#x27;s no operating system to manage threads, everything&#x27;s a single binary, etc. — which means that there&#x27;s less to insulate you from what&#x27;s underneath. reply charcircuit 5 hours agorootparent>Are you a graphics programmer, or are you just saying this because that&#x27;s true in the CPU world (where you have experience)Neither.>the nature of GPU architectures means you are forced to deal with super low-level details from the very beginning.Not everyone is trying to push the hardware to its limits by making the best thing possible with the hardware. Plenty of projects can get along fine with a A&#x2F;AA renderer or with unoptimized shaders.>there&#x27;s no operating system to manage threadsThere literally is. Or if you disagree the firmware manages the threads. reply signaru 4 hours agorootparentprevA more realistic comparison for webdev is using plain JS vs using frameworks. reply throwawee 10 hours agorootparentprevAgreed. I&#x27;ve seen beginners fall into the trap of spending way too much time on software rendering that won&#x27;t be useful or performant later because every platform they&#x27;ll ever develop for has hardware accelerated rendering. I learned how to painstakingly render scenes pixel by pixel and then had to unlearn it because graphics programming doesn&#x27;t work that way anymore.Teaching beginners to render graphics without the GPU is like teaching them to do fractional math without the FPU. It won&#x27;t make their first project better and gives them the wrong idea of what to expect. reply CountHackulus 11 hours agorootparentprevI disagree. It&#x27;s good to understand what the GPU is doing at scale before jumping in too deep. It&#x27;s obviously not how you do your day-to-day work, but it helps you understand what&#x27;s going on at a deeper level. reply virtualritz 9 hours agorootparentprev>> No GPU, no OpenGL, no DirectX!> This is the opposite of what you would hope to see for learning graphics programming.It is exactly what you would hope to see.And I would dare say I&#x27;m a graphics programmer, mostly self taught.When I started, as a teenager, in the late 80&#x27;s, there were no GPUs. So I learned everything from first principles. I recall implementing Bresenham in x86 assembly for my CGA card. And then, as a follow up, rasterizing a triangle. You really had to understand stuff end-to-end then as the hardware was so slow. I.e. even C was too slow for that stuff.And today, still, the best offline renderers, that produce the images you see on the big screen, are CPU-only. 100% custom code, no 3rd party API dependency.[1]If you write stuff for CAD&#x2F;CAM&#x2F;CAE&#x2F;VFX, there is a big chance you do not think about the constraints of a GPU and less so of one of the APIs used to program it. Except for previewing stuff.I would suggest to anyone learning graphics programming (or anything else for that matter) to do so from first principles.GPUs are specialized hardware for realtime applications. That is very specific. I don&#x27;t say don&#x27;t learn that. But I suggest to not start with it.[1] One of my best friends is the lead developer of the 3Delight renderer. reply crq-yml 7 hours agorootparentMy little spot of nuance on this reply would be that the point of starting in software would not be to aim for a fast or feature-rich implementation. That seems to be the sticking point of the replies in favor of going hardware-first - that \"we don&#x27;t optimize the same way anymore\". But nobody was asking about optimizing! People seem to go performance-brained when they talk about graphics because they read about John Carmack once. Then they go right back to their Javascript frameworks.Like any student engineering project, \"baby&#x27;s first rasterizer\" would emphasize a combination of concepts and motions - a path to take, to get to a result that can be tested. We don&#x27;t even have to use Bresenham now - deriving the rasterized line from linear interpolation is mathematically more sound and no sweat for modern CPUs. But it might be pedagogically useful to compare the two to explain quality vs performance tradeoffs, ones that were made historically and those that are still in use today. reply moron4hire 10 hours agorootparentprevIt&#x27;s what my graphics courses in my computer science degree did. The skills I learned have benefitted me long after (20 years), and I mostly \"just\" do web development. reply robomartin 11 hours agorootparentprevBelieve it or not, we were doing graphics without any of those things a very long time ago. Learning fundamentals is really important. You can always learn easier ways to do things later.For example, area fill algorithms are really interesting. Etc. reply dahart 4 hours agoprevOh there are so many more ways to become a graphics programmer than by starting with DX&#x2F;VK&#x2F;OGL. No need to use C++ at all. Look at all the amazing 3d graphics 3Blue1Brown does in Python.Learn DirectX or Vulkan if you want to write game engines.Learn WebGL if you want to write browser applications.Those APIs are heavy though, and don’t even necessarily teach you that much about graphics on their own. If you want to learn graphics concepts, write your own rasterizer and ray tracer - both! - in any language you want.There are also a bunch of super-easy-to-use graphics libraries & coding environments that are so much more fun than slogging through Vulkan or DX. Processing is wonderful. Or checkout PlotDevice.io (Python), or its predecessors NodeBox, or DrawBot. ShaderToy is another place where you can learn how to write shaders, or lots and lots about rendering, and it’s so easy to get started. JavaScript has lots of options and libraries. These can be way more accessible and motivating to a beginner, but still offer enough power and flexibility to take the curious student as far as they want. reply ribit 31 minutes agoprevIMO the best way to start for a beginner is with Metal. It&#x27;s a delightfully streamlined API that avoids the idiosyncratic complexity of DX and Vulkan, it&#x27;s very quick to pick up if you already have some C++ experience, the tooling is excellent. Most importantly, you can focus on GPU programming instead of fighting the API and you get to play with all the fancy tools (mesh shading, ray tracing) with a very low barrier of entry. And all that you learn with Metal translates directly to other APIs. reply SuboptimalEng 9 hours agoprevYou can start learning graphics by writing shaders on Shadertoy. It’s where tons of graphics programmers get their start.Shameless self promotion, I’ve made 10+ tutorials going over topics like: how to write shaders in VS Code, SDFs, ray marching, noise functions, fractional brownian motion, etc.https:&#x2F;&#x2F;github.com&#x2F;suboptimaleng&#x2F;shader-tutorialsI’m certainly standing on the shoulders of giants like Inigo Quilez, The Art of Code, SimonDev and Acerola. reply Animats 1 hour agoprevI have the horrible feeling that, if you start to become a graphics programmer now, by the time you&#x27;re done, AI will be doing it.If you want to make games, learn a game engine. The big 3D ones are Unity (not too hard), Unreal Engine (hard, used for AAA titles), and Bevy (in Rust, open source.) There are a ton of 2D engines, mostly used to do retro stuff. reply eurekin 34 minutes agoparentAI will be doing graphics programming? Please elaborate, I have a very hard time understanding how current clunky models that cannot generatie a java class without \"&#x2F;&#x2F; here you fill in the implementation\" everywhere would go about improving current PBR shader code for example reply demondemidi 10 hours agoprevNot really sure what this website is asking. Does the person want to: Rig? Texture? Model? Write drivers? Make GUIs? Animate websites? Make graphics tools? Work with shaders? Or work with 2D photo engines? Make 2D games? Make 3D games? Write procedural scripts? Optimize graphics code?There are hundreds of disciplines that fall under \"computer graphics\". The website focuses on a teensy little corner: programming graphics SDKs. reply quelsolaar 10 hours agoparentBeing a graphics programmer is a pretty well defined category of programmers. A lot of the things you mentioned aren&#x27;t graphics programming like Rig, Texture or Model, and a graphics programmer is expected to be able to run the gamut of games, 3D, 2D, tools, shaders and optimization. reply hshsbs84848 5 hours agoparentprevI can see how it’s confusing but usually “graphics programmer” is someone who works on a graphics rendering engine (either real time or offline rendering) reply wly_cdgr 4 hours agoprevThe details are outdated now, I guess, but I don&#x27;t know if there&#x27;s any more inspiring reading for an aspiring graphics programmer than Fabian Giesen&#x27;s \"A trip through the graphics pipeline\" https:&#x2F;&#x2F;fgiesen.wordpress.com&#x2F;2011&#x2F;07&#x2F;09&#x2F;a-trip-through-the-...As for a place to actually start, I think Computer Graphics From Scratch is a good place https:&#x2F;&#x2F;www.gabrielgambetta.com&#x2F;computer-graphics-from-scrat.... A great thing about the book is it gives you many ideas for where to go next once you work your way through to the end. reply Agentlien 3 hours agoparentThe details are surprisingly still relevant. A lot has changed, but most of that (compute shaders, Ray tracing hardware, ...) is actually orthogonal to everything mentioned in this article or simply details changing in aspects glossed over.I still link people this article because I have yet to find anything which does a better job explaining these things. reply atoav 1 hour agoprevDepends on what you want to make and on which level. Doing graphics for a desktop application will differ from doing it for a web application, for embedded devices or for a game.That being said for a beginner I would recommend starting with the examples in processing.org. This is basically a small IDE where you can make your code draw things in a window with minimal boilerplate (the boilerplate is hidden). There is a heap of examples, how to do easing functions, how to work with vectors, etc.The stuff learned there will be useful for anything where you need to work with a coordinate system. reply uglycoyote 6 hours agoprevI&#x27;m a game developer but not specifically a graphics programmer. Although I work with modern graphics APIs and GLSL shaders in my day job, when my 13 year old recently graduated from wanting to program in Scratch or Python to wanting to learn C++, I decided the best thing to do was break out the old OpenGL 1.2 DLL&#x27;s that I still had on my machine since 1999 and starting him writing some code using glut and glbegin&#x2F;glvertex&#x2F;glend type of immediate programming.it is just a lot more fun than trying to suffer through all of the setup that one needs to do with modern APIs. he is more interested in computational geometry type of things like voronoi diagrams so the graphics API is really just a means to an end and fancy shaders and lighting aren&#x27;t important right now, and performance in C++ and old school OpenGL is about a thousand times faster than Scratch, so I think we hit a sweet spot for where he is at in terms of his progression of learning.even with the simplified API of OpenGL 1.2, he is still biting off a pretty ambitious chunk of learning to try to grasp c++ at the same time as OpenGL, so the simplicity helps keep it sane and manageable, and things are going well. He did some neat marching squares demos and I helped add an IMgui menu to tune parameters at runtime. it has been entertaining! reply trevortheblack 10 hours agoprevSince this is on the front page I guess I&#x27;ll post the resource that the graphics programming industry actually uses (note, I&#x27;m an author): https:&#x2F;&#x2F;raytracing.github.io&#x2F;It&#x27;s included in the \"Useful Websites\" in the article above.Also note that graphics is large enough that there no longer exists a one-size-fits all solution to learning graphics. If you want to learn graphics I&#x27;d recommend finding a mentor. reply starmole 9 hours agoparentGreat stuff! I especially agree with teaching math via raytracing first instead of APIs. reply atum47 10 hours agoprevI&#x27;m on that journey myself. Two years ago I followed several tutorials and youtube videos to create my first 3D engine. It&#x27;s very simple, but I like simple stuff. Right now I&#x27;m working on using this engine to create a city builder game [1]. It is a lot of fun to learn to manipulate stuff using matrix and cross products.1 - https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=cvyrfPUpyp0 reply quelsolaar 10 hours agoprevC is a perfectly good alternative to C++ for Graphics programming. OpenGL and Vulcan are C APIs and DirectX has a C wrapper. Some games like Call of duty are written in C, but C++ is more common. reply mabster 8 hours agoparentI&#x27;ve done games in both. My favourite is mostly imperative C++ so you can use templates. reply TrackerFF 10 hours agoprevLearning trigonometry and linear algebra would be a good start. reply barbariangrunge 9 hours agoprevIf you’re teaching yourself, it might be nice to have an early win. Something like unreals material editor or shader graph might be a nice start. Lots of tutorials around. Then, when you go to write actual shaders. You’ll know what logically you intend to do, and all you have to do is learn the syntax of whatever graphics language&#x2F;api you chooseTangent: Learning the syntax for OpenGL is hellish, and there’s a lack of great resources on it, at least as of several years ago.Then, after you understand shaders a little, go and make your game engine (physics will be its own beast) reply slalomskiing 5 hours agoprevI went through this and switched from web dev to being a graphics programmer at a game studioPersonally I think LearnOpenGL is still the best tutorial series if you want to work on game rendering enginesJust because it covers a ton of different topics from beginner up to advanced all in one series. You go from scratch all the way up to implementing deferred rendering and a full PBR implementationIf you understand all of those tutorials you have a pretty good baseline for how modern game rendering works (minus ray tracing)In terms of getting a job though the modern APIs are highly desirable reply zffr 9 hours agoprevFor complete beginners looking to get a good conceptual understanding of what shaders are actually doing, I would highly recommend this course: https:&#x2F;&#x2F;github.com&#x2F;ssloy&#x2F;tinyrendererIn the course you will build a purely CPU-based renderer that simulates the way OpenGL shaders work. I found it to be incredibly useful for understanding shaders. reply MurageKabui 1 hour agoprevNot one mention of GDI+ ? reply raytopia 9 hours agoprevIf you want to be a retro graphics programmer reject shaders and return to glBegin. reply jherico 9 hours agoparentI&#x27;m sure there&#x27;s a set of shaders that will basically let you emulate the fixed function pipeline without having to endure the shitty performance implications of passing a vertex list to the GPU every single frame. reply byyoung3 10 hours agoprevprogram graphics reply amelius 9 hours agoprevnext [–]10 GRAPHICS 8+16:REM HIRES MODE WITHOUT TEXT WINDOW 15 SETCOLOR 0,0,0:SETCOLOR 2,10,15 20 COLOR 1 30 PLOT 0,0 40 DRAWTO 319,190 50 GOTO 50 reply drones 9 hours agoprevAre there any good resources for learning graphics programming for the first time with WebGPU? I have heard mixed opinions about WGSL. reply theodpHN 11 hours agoprevPractice.https:&#x2F;&#x2F;www.carnegiehall.org&#x2F;Explore&#x2F;Articles&#x2F;2020&#x2F;04&#x2F;10&#x2F;The... reply photochemsyn 7 hours agoprevAll the comments here are BS. You have to learn how to construct 2D and 3D graphical spaces in real time and let them evolve and I&#x27;m sorry to say, as others have before, there is no royal road to mathematics. You simply have to put your time in the trenches. All the tools being sold to you are ephemeral and will soon become obsolete, so you simply have to grasp fundamentals of linear algebra and 3D spatial representations.You can try to use tools created by others but the results will all just look the same as theirs, and if this is too much bother I&#x27;d suggest going back to non-digital mediums for your artwork like pen & ink watercolors oil paints etc.If you can&#x27;t handle vector calculus and complex analysis then that&#x27;s too bad. Try harder or do something else. reply wly_cdgr 4 hours agoparentOk but what are you saying? After understanding the math, are you suggesting that people need to use that understanding to interface with the graphics hardware at a level below Vulkan? reply unconed 41 minutes agoparentprevLol, the only math you need for practical graphics coding is linear algebra. Calculus only comes into play when doing e.g. light integrals, and complex analysis only when you start doing advanced convolutions.The math isn&#x27;t the problem, the absolutely abysmal API design is. The current generation of graphics APIs were designed for game engines to build middleware on top, not for practical use, and it shows.Too many hardcoded limits, too many different ways to do the same thing, too many caveats and exceptions... and not enough decent developer tools to see wtf is going on on the other side. reply eurekin 32 minutes agorootparent> the absolutely abysmal API design isOh.. Now I get why others see AI could improve things here :) reply dboreham 8 hours agoprevPut one pixel in front of another.. reply bsder 11 hours agoprevThis isn&#x27;t hard: DirectX 12 and C++ and Visual Studio (not VSCode) and Windows on an NVIDIA card.Vulkan basically isn&#x27;t relevant anymore unless you are doing Android. Metal similarly unless you are doing iOS.As a Linux user, this pains me. But it&#x27;s just life. Windows-land is soooo much better for graphics programming that it&#x27;s absurd. reply slabity 11 hours agoparent> Vulkan basically isn&#x27;t relevant anymore unless you are doing Android.Why do you say this? reply dagmx 10 hours agorootparentI’m not the person you asked but my 2c (since I agree with their point on Vulkan)Very few video games are made with Vulkan. DirectX is the primary API.Android is the only place where Vulkan really has an interesting market share.For a beginner, it has an incredibly steep learning curve vs DirectX as well. So given the low usage and high friction to pick it up, you have a really poor ROI.DirectX and Metal are much more conducive to getting results quickly and efficiently. reply delta_p_delta_x 10 hours agorootparentprevI&#x27;m not the parent commenter, but I&#x27;d like to explain their logic, which has at least a modicum of reason to it.About 99% of desktop video games (by far the largest clients of graphics APIs) target Windows, and therefore target either Direct3D 11 or Direct3D 12. This includes free-to-use game engines including CryEngine, Unity, Unreal, and Ren&#x27;Py. Almost all the famous, proprietary, high-performance game engines (id Tech, Frostbite, Slipspace, REDEngine, Source) target D3D exclusively. Vulkan is clearly a second-class citizen on Windows. Some engines target OpenGL, and they tend to be used in (hurriedly dashed-out) console ports, but in almost all cases they exhibit worse performance than their D3D competitors.Vulkan is completely absent from MacOS and iOS, where Apple has pushed its own API, Metal. OpenGL on MacOS is deprecated and is stuck on 4.1, missing all the advancements in 4.6, which include mesh shader support.Many Android games are likely still running GLES. Vulkan is pretty hard to get started with, because things that are implicitly handled by the OpenGL global state machine now have to be explicitly handled by the developer, and chances are the developers of the millions of throw-away microtransaction-laden game apps on Android aren&#x27;t writing their own rendering engines in Vulkan.Therefore, despite all the positives of Vulkan—open-source specification, cross-platform support, SPIR-V shader target allowing shaders to be written in any language (HLSL, GLSL, other esoteric languages that compile to SPIR-V), an extension mechanism allowing fast iteration and updates—it has a fairly uphill battle.EDIT: I was incorrect, id Tech supports Vulkan exclusively. But it is a minority in a sea of D3D-first engines. reply spookie 10 hours agorootparentiD Tech, Source 2, Unreal, and Unity support Vulkan.iD Tech targets Vulkan exclusively on PC: https:&#x2F;&#x2F;twitter.com&#x2F;billykhan&#x2F;status&#x2F;1028133659168186368Other points are also blatantly untrue, but I think I have made my point. At this point, targeting only DirectX is shooting yourself in the foot.Other references: https:&#x2F;&#x2F;docs.unity3d.com&#x2F;Manual&#x2F;GraphicsAPIs.html https:&#x2F;&#x2F;www.khronos.org&#x2F;news&#x2F;press&#x2F;khronos-group-releases-vu... https:&#x2F;&#x2F;docs.unrealengine.com&#x2F;5.3&#x2F;en-US&#x2F;supported-features-b... reply delta_p_delta_x 10 hours agorootparentWhile I was incorrect about id Tech (and have edited my comment), I never made the point that any of the other engines didn&#x27;t target Vulkan.Where else is my comment untrue? Many engines and rendering back-ends have only recently completed a Vulkan-based implementation. I am confident in my assessment that the large majority of existing implementations are still running OpenGL and&#x2F;or Direct3D, if on Windows. reply vivty 10 hours agorootparentprevMaybe i am wrong, but this tweet and wikipedia directly contradicts what you say (id tech does indeed use vulkan on windows): https:&#x2F;&#x2F;twitter.com&#x2F;billykhan&#x2F;status&#x2F;1028133659168186368I am just doing game dev on the side but i think nowadays the graphics abstractions are fairly similar in how they work (the modern abstractions, i.e. Metal, D3D12, Vulkan). Of course ideally you choose the graphics abstraction that is \"native\" to the platform, but vulkan seems to be supported very well on windows (many AAA game use it and it works great, many games run even better with vulkan abstraction than with their d3d12 counterpart). I use vukan so my graphics can run on windows and linux (which is why i chose vulkan instead of d3d12). reply dagmx 10 hours agorootparentYou are correct that idTech targets Vulkan (and they have some great GDC talks to boot)They are however very much the minority.I am suspect of your claim about Vulkan abstraction layers running better than DX12. If there is a performance difference, it’s likely elsewhere in the stack and just tangentially related. reply mabster 8 hours agorootparentI&#x27;m surprised by that as well.I haven&#x27;t done this stuff for quite a while, so my memory might be foggy, but the main advantage of Vulcan was that you can control all the CPU locking rather than the API doing it. This allows you to do stuff like prepare on one thread and submit on another, etc.But that would be negated if you&#x27;re using an abstraction layer. reply spookie 9 hours agorootparentprev> Almost all the famous, proprietary, high-performance game engines (id Tech, Frostbite, Slipspace, REDEngine, Source) target D3D exclusively.You&#x27;ve said it there, hence my reply reply moron4hire 10 hours agorootparentprevIDK, all the games I try to run on Linux seem to work better in Windows&#x2F;DX emulation rather than native&#x2F;Vulkan. reply SeanAnderson 11 hours agoparentprevHow does this sentiment align with the advent of WebGPU? reply pjmlp 2 hours agorootparentWebGPU is a browser API.Anyone making use of it outside the browser is making themselves a disservice by not using a middleware engine instead.WebGPU as specified cannot do many modern features, and naturally making use of extensions in wgpu or Dawn, makes the code non portable. reply delta_p_delta_x 10 hours agorootparentprevWebGPU is little more than a laboratory experiment right now. There are probably no industry implementations (game&#x2F;graphics engine, visualisers, etc). Computer graphics is particularly industry-driven—consider the proportion of game devs who present at SIGGRAPH versus academics.I give it at least a decade before WebGPU sees any meaningful market share. reply Jasper_ 10 hours agorootparentChrome is switching to using Dawn (Google&#x27;s WebGPU implementation) for its Skia backend. This would render all UI elements across Chrome using WebGPU. You can find plenty of projects that are using WebGPU today. In the web space, BabylonJS has had plenty of experience using it already, and you can run several demos [0]. Offline, there are games like Veloren [1] that use it exclusively as a graphics backend. Plus a number of other projects I can&#x27;t talk about yet.It&#x27;s pretty obvious WebGPU is not going to replace any big engine&#x27;s custom-built graphics backend, but it&#x27;s already pretty capable, and I think it&#x27;s going to be a good place to start for beginners for a long time.[0] https:&#x2F;&#x2F;github.com&#x2F;Popov72&#x2F;OceanDemo [1] https:&#x2F;&#x2F;veloren.net&#x2F; reply SeanAnderson 10 hours agorootparentprevBevy Engine (https:&#x2F;&#x2F;bevyengine.org&#x2F;) is built ontop of wgpu (https:&#x2F;&#x2F;wgpu.rs&#x2F;) and runs in-browser today (https:&#x2F;&#x2F;bevyengine.org&#x2F;news&#x2F;bevy-webgpu&#x2F;)Bevy is the second highest starred game engine on GitHub&#x27;s Game Engine topic: https:&#x2F;&#x2F;github.com&#x2F;topics&#x2F;game-engineI definitely agree that it&#x27;s still new, but I don&#x27;t feel like it&#x27;s quite as far out as you&#x27;re implying. A year or two at best IMO? reply delta_p_delta_x 10 hours agorootparentGitHub stars aren&#x27;t really an accurate indicator of market share. I&#x27;ve previously starred it, too, but I&#x27;ve never used it.I&#x27;d like to draw attention to the last phrase in my comment:> WebGPU sees any meaningful market shareI am comparing anything implemented in WebGPU to existing games that are played today by gamers.Finally, it&#x27;s using Rust, and the majority of graphics + game engines are written in C++ (with a minority in Java and C#). Despite the safety and tooling benefits, moving to Rust is still a change that companies have to implement and educate their developers on, which is going to take a lot of time. And game dev companies are fairly slow at adopting new language standards (even if they adopt new graphics APIs and hardware fairly quickly, e.g. ray-tracing).I don&#x27;t quite share your optimism; sorry. reply SeanAnderson 10 hours agorootparentWell, I&#x27;m writing a game intended for the web using Bevy right now, so I&#x27;m clearly biased :)There are also some industry veterans building games using it. https:&#x2F;&#x2F;www.mobygames.com&#x2F;person&#x2F;6108&#x2F;brandon-reinhart&#x2F; to name one specifically.You can just use FFI if you want to integrate C crates with Rust, it&#x27;s not that bad. Figma uses a mixture of Rust and C++ in the WASM that they ship.Guess we&#x27;ll see what the future holds. reply delta_p_delta_x 9 hours agorootparentAll the best. I&#x27;ll be happy to eat my words.Rust is a great language (although I don&#x27;t use it myself), and WebGPU is pretty interesting as well. replykllrnohj 8 hours agorootparentprevWebGPU needs to cater to the lowest common denominator so it&#x27;s unlikely to replace DX12&#x2F;Vulkan&#x2F;Metal in the demanding usages. It&#x27;s always going to lag behind on features, capabilities, and performance.But for the long tail of image filters, video effects, more graphically basic games - yeah, it&#x27;s a great fit there. Probably. reply pjmlp 3 hours agorootparentTo put it in perspective, WebGPU 1.0, that 6 years later is still only available on Chrome, is the lowest common denominator from 2015 GPU hardware. reply 0xDEF 11 hours agoparentprevAcademic computer graphics research is in many places still using OpenGL 4.1. reply all2 11 hours agoparentprevWhy is this the case? reply bsder 10 hours agorootparentBecause the amount of resources that Microsoft and NVIDIA pour at graphics programming dwarfs the amount of resources that everybody else combined seems willing to put into it.The implementations are better. The support is better. The ecosystem is better. The debugging tools are better. reply jheriko 8 hours agoprevmake things. the end. reply adamnemecek 11 hours agoprevwgpu, the Rust WebGPU implementation is the bee&#x27;s knees. https:&#x2F;&#x2F;wgpu.rs&#x2F; You can use it beyond the web. reply CyberDildonics 8 hours agoparentYou think the first thing for someone who wants to learn graphics programming is to compile rust&#x27;s webgpu implementation? reply TheRoque 6 hours agorootparentWebGPU is a pretty good starting point, that&#x27;s what I did myself (with C++, not Rust though, which should be even more straightforward). You can even use it in the browser and skip all the native hassle.Just learn the basic concepts like buffers, drawing, texture, light, perspective etc. from https:&#x2F;&#x2F;learnopengl.com&#x2F; then you can jump into WebGPU. Even though there&#x27;s not that many WebGPU tutorial, applying the OpenGL tutorials to it is pretty straightforward once you understand the fundamentals. reply CyberDildonics 6 hours agorootparentUsing webgpu makes sense, but that isn&#x27;t what they said. They said compiling a rust webgpu implementation. reply TheRoque 5 hours agorootparentSince this is very straightforward to do, I took it as equivalent statements reply jholman 7 hours agorootparentprevObviously not. Obviously the first thing for someone who wants to learn graphics programming is to learn Rust. I&#x27;m surprised you asked. reply adamnemecek 6 hours agorootparentprevIt’s actually relatively small. reply CyberDildonics 6 hours agorootparentSo what? You don&#x27;t think they might need to learn math or a graphics API or fundamentals first? You think they need to compile a rust webgpu implementation first because it&#x27;s small?How does this make any sense? reply TheRoque 5 hours agorootparentYou can learn along the way. If you learned with the famous learnopengl website, you learn about compiling glad, glfw and putting up a C++, along with maths, all at the same time, incrementally... The tutorials for Rust&#x27;s wgpu isn&#x27;t any different. reply adamnemecek 4 hours agorootparentprevWhat do you think wgpu is if not a graphics API? replylopkeny12ko 11 hours agoprev [–] Ah, the AMD Game Engineering team, the same fine folks who implemented driver-level \"optimizations\" for Counter Strike that resulted in thousands of players getting permanently VAC banned. reply voldacar 11 hours agoparent [–] The vac bans got reversed. reply qup 11 hours agorootparentTemporarily permanently banned reply lopkeny12ko 10 hours agorootparentprev [–] I fail to see how that excuses sloppy engineering. reply voldacar 9 hours agorootparentI agree with that, I was just correcting you. It&#x27;s crazy that they deliberately altered the code of a running program like that, especially one which is going to have an anti-cheat system. reply charcircuit 10 hours agorootparentprev [–] It wasn&#x27;t sloppy engineering unless you are saying AMD should have used a VAC bypass reply TillE 9 hours agorootparent [–] Injecting code into third-party DLLs is as sloppy as it gets. It&#x27;s an awful hack. reply charcircuit 7 hours agorootparent [–] An AMD DLL always has been loaded into the game&#x27;s process. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The platform is designed for beginners to discover and gain knowledge about AMD's tools, libraries, and effects within the GPUOpen ecosystem.",
      "It provides an ideal environment for individuals who want to explore and learn about AMD's technologies and resources.",
      "This platform offers a great opportunity for newcomers to dive into the GPUOpen ecosystem and understand how AMD's products and developments can be utilized."
    ],
    "commentSummary": [
      "The importance of focusing on the end goal of creating graphics rather than getting caught up in tools and low-level code.",
      "The value of industry experience and abstraction tools like game engines in graphics programming.",
      "The need for a broad knowledge base and adaptability in technology when it comes to graphics programming."
    ],
    "points": 282,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1700686443
  },
  {
    "id": 38387464,
    "title": "Understanding the `test`, `[]`, and `[[` Commands in Unix Systems (2020)",
    "originLink": "https://jmmv.dev/2020/03/test-bracket.html",
    "originBody": "Did you know that Unix systems have a binary whose name is a single symbol? Go and look for it. Run ls /bin/? and behold: $ ls /bin/? /bin/[ Uh huh. [? The square bracket? That’s a program?! But wait, it gets more interesting: $ ls -li /bin/[ /bin/test 834 -rwxr-xr-x 2 root wheel 35824 Jan 23 08:59 /bin/[ 834 -rwxr-xr-x 2 root wheel 35824 Jan 23 08:59 /bin/test The two names, [ and test, point to the same binary1. But why? What are these? The test program is what you use in the shell to evaluate an expression. You can use this to compare strings, compare numbers, and to check various conditions on files. If you have written a shell script—any shell script really—you certainly have used either of these variants. The way this works is simple: the test program takes a bunch of arguments, evaluates the expression represented by them, and returns 0 if the expression is true or 1 if it is false. This then lets you do things like: if test a = b; then echo \"The two strings were the same! Oops!\" fi So why do we have two names for this helper tool? I haven’t been able to find the definitive answer, but my guess is simply: because the above “looks ugly”, and the “obvious” solution to make it look nicer is to introduce [ as a command. With it, you can express the same logic from above as: if [ a = b ]; then echo \"The two strings were the same! Oops!\" fi Yup. Exact same code as above. The only difference here is that the test binary checks its argv[0] to see if it’s invoked as test or as [. If the invocation happens to use the latter, then the program ensures that the last argument is the matching ] to keep things balanced. With that, you can deduce that you don’t even need the conditional statement to use either of these commands and see what’s going on: $ test a = a; echo $? 0 $ test a = b; echo $? 1 $ [ a = a ]; echo $? 0 $ [ a = b ]; echo $? 1 That’s right. The if statement we used in the previous examples just takes a command as its argument and runs it to get its exit code. (And with this, you can “guess” that true and false are… yup, yup… also helper binaries.) To make things more confusing, though, pay attention to the following: $ /bin/test a b test: a: unexpected operator $ test a b dash: 2: test: a: unexpected operator Why did we get different outputs there? Well… as it so happens, test and [ appear a lot in shell scripts. Invoking them as separate binaries would be very inefficient, so the vast majority of the shells implement these commands as built-ins too. You may get different behavior depending on whether you run the external binary or the builtin, which means you easily get different behavior across different shells. (And that’s true for many other things like the innocent-looking echo.) So what about [[? This is a Bash extension and replaces the use of [. The key difference, however, is that [[ is guaranteed to be a builtin and therefore it can change, and it does change, the fundamental rules of the language within the expression it evaluates. To illustrate this, let’s look at an example with globs: $ touch long-name $ [ long* = long-name ] && echo match match $ [[ long* = long-name ]] && echo match The first command shown here is an invocation of the [ tool, which may or may not be a builtin. No matter what, all arguments are subject to the regular shell expansion rules, so long* is matched against the directory contents, is then expanded to long-name, and thus the test succeeds. But, in contrast, [[ produces a different result because it treats the long* as a literal string, so all this is doing is comparing long* against long-name verbatim, and therefore failing. What should you use, then? If you are writing a portable shell script (please do), then stick to [. You can also use test, but I don’t think that’s too common. But if you know your script is going to be Bash-specific anyway, you are probably better served by using [[ unconditionally and consistently, as it provides a lot of nice features (like regular expression matches via =~). And now for the final lolz. I’ve said above that these are the commands you use to evaluate expressions… but the shell also has expressions of its own via the !, &&, and || operators—all of which work on command exit statuses. That is: $ grep ^hello$ /usr/share/dict/words && grep ^bye$ /usr/share/dict/words hello bye $ echo $? 0 $ grep ^tyop$ /usr/share/dict/words && grep ^bye$ /usr/share/dict/words $ echo $? 1 Which means… that you can combine test expressions and shell expressions in one invocation: if [ a = b ] || grep -q ^hello$ /usr/share/dict/words; then echo \"test failed and grep succeeded\" fi You pick whether to be amused or horrified. I don’t know how exactly my coworker reacted when I hinted at this during a recent code review I did for them. /bin/[ and /bin/test are not necessarily hard links. They indeed are on NetBSD and I had assumed that was true on all systems… but a cursory look shows that macOS Catalina ships these as two separate copies of the same binary and Debian testing just has two different binaries. The POSIX spec does not require them to be links after all. ↩︎",
    "commentLink": "https://news.ycombinator.com/item?id=38387464",
    "commentBody": "test, [, and [[ (2020)Hacker Newspastlogintest, [, and [[ (2020) (jmmv.dev) 247 points by mattrighetti 9 hours ago| hidepastfavorite122 comments kqr 1 hour agoTaking the last point one step further, we can also dispense with the if block entirely: if [ a = b ]; then echo \"Oops!\" else echo \"Expected; phew!\" fibecomes [ a = b ] && echo \"Oops!\" || echo \"Expected; phew!\"I&#x27;m not sure how often you should do this but sometimes it comes in handy for things like [ \"$debug\" ] && echo \"what&#x27;s going on\" >&2to conditionally print debug output to stderr.----And the fact that the if block tests a regular command means we can also do things like if grep -q &#x27;debug&#x27; &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log; then echo \"Debug request found!\" fi----Something I have not yet bothered to figure out is whether I should write [ $(expr 1 + 1) -eq 2 ] && [ $(expr 2 + 2) -eq 3 ]or use the built in logical and of test: [ $(expr 1 + 1) -eq 2 -a $(expr 2 + 2) -eq 4 ]As long as performance is not a concern, I can see roughly equal reasons in favour of either. reply illo 14 minutes agoparent> [ a = b ] && echo \"Oops!\" || echo \"Expected; phew!\"Not to be taken as a general rule though. I might be mistaken but I think that bash would parse the line as: ([ a = b ] && echo \"Oops!\") || echo \"Expected; phew!\"so if the command sequence after `&&` fails, then the code sequence after `||` is executed anyway: illo@joe:~ $ [ \"a\" == \"a\" ] && >&#x2F;dev&#x2F;full echo \"strings match\" || echo \"strings don&#x27;t match\" -bash: echo: write error: No space left on device strings don&#x27;t match illo@joe:~ $This is different from the semantics of the `if` block: illo@joe:~ $ if [ \"a\" == \"a\" ]; then >&#x2F;dev&#x2F;full echo \"strings match\"; else echo \"strings don&#x27;t match\"; fi -bash: echo: write error: No space left on device illo@joe:~ $ reply jmmv 8 hours agoprevHey, original author here. Thanks for sharing this and making it rise to the front page! :) By the way, the title probably deserves a (2020) and it would be nice if \"test\" wasn&#x27;t capitalized, because it actually refers to the command.Here is something related from 2021 that also touches on bash&#x27;s [[ operator and that I think you might enjoy in this context: https:&#x2F;&#x2F;jmmv.dev&#x2F;2021&#x2F;08&#x2F;useless-use-of-gnu.html reply dang 3 hours agoparentOk, I&#x27;ve lowercased the leading &#x27;t&#x27;. We never do that but for this, ok :) reply edanm 47 minutes agorootparentAs per the Zen of Python:> Special cases aren&#x27;t special enough to break the rules.> Although practicality beats purity.:) reply o11c 7 hours agoparentprev[[ is not really a builtin, it&#x27;s fundamentally syntactical (but presumably uses a mostly-inaccessible builtin internally). Fun fact, `]]` is also a reserved word despite never being allowed in a context where reserved words matter.In some non-bash shells, the `function` keyword is needed to declare certain types of function.For make `$(shell)`, if you&#x27;re building a lot of targets the performance difference can be measurable. Still, it loses in the nop case, so you should actually usually do `include` to trigger re-making.GNU is completely right to ignore POSIX, since POSIX is not useful for solving most real problems. reply gnfargbl 1 hour agoparentprevThis article complains that using the extended GNU features (--ignore-case, set -o pipefail etc) makes scripts less portable. Fair enough.What it doesn&#x27;t explain is why a Linux user should much care about portability. OpenBSD and FreeBSD are alive and well, but the number of users seems so small that they aren&#x27;t a particular concern. Maybe you could argue that we \"should\" consider these OSes out of a sense of fairness, but where does that stop? Do I also need to consider something obscure like vxWorks?BusyBox (Alpine) is more interesting, but the changes there are so significant that a port will almost always be needed anyway.Are there other compelling reasons to care about the non-GNU ecosystem? reply kqr 43 minutes agorootparentIs your comment best read in Internet Explorer 6?----What I&#x27;m trying to say is that open standards (and the portability that comes with them) is not something that just happens on its own. It takes active maintenance, and part of that maintenance is opting to adhere to the standard even when it would be more convenient to use extensions available in the most popular systems.Will you personally suffer from liberally using Bashisms? Not in the first order. But if we encourage that sort of thinking as a rule, the standards become meaningless. I believe that would be a net negative change for the world, but there are many intelligent people who would disagree. reply ridiculous_fish 8 hours agoprevThe biggest footgun in `[` and `test` is the single argument behavior. For example, you might attempt to check if a variable is nonempty like so: [ -n $FOO ]but if FOO is unset, it expands to nothing (as opposed to the empty string), so this is equvalent to: [ -n ]and POSIX requires that the one-argument form of `[` succeed if that argument (here, \"-n\") is non-empty. So this will falsely report that $FOO is non-empty.Remember to quote your variables! reply jstimpfle 1 hour agoparentI think your last sentence needs to go first. Quote your variables! There&#x27;s no actual footgun in the specification of the test builtin -- the footgun is shell itself. The behaviour that you mention makes sense because [ \"$FOO\" ]is always the non-empty check regardless what it contains (could be \"-n\"). reply whateveracct 8 hours agoparentprevShellCheck your scripts! reply mr_toad 7 hours agorootparentOr use set -u to fail early.Or use [ -n ${FOO-} ] which will replace the unset variable with an empty string. reply kazinator 6 hours agorootparentThat is false. There is no difference between ${FOO} and ${FOO-}. Both disappear if unquoted, and FOO is unset or blank: $ printf \"\" alpha ${beta} omega $ printf \"\" alpha ${beta-} omegaThe form ${var-} form is useful for safely evaluating a variable that might be unset, when \"set -u\" mode is in effect, and for whatever reason we cannot just fix the script so that the variable is set. reply js2 6 hours agorootparentThey meant \"${FOO:-}\" which should still be quoted.The general form is \"${FOO:-default}\" where default can itself be another variable or whatever string you want.I usually prefer to set default values at the top of a script though using this idiom: : \"${FOO:=bar}\"And when creating a local variable I&#x27;ll immediately set it to an empty string if there&#x27;s a chance it won&#x27;t be assigned later: local foo=\"\" reply kazinator 5 hours agorootparentThat colon makes no difference if the replacement is blank. reply js2 4 hours agorootparentHoly crap, 25 years of writing shell scripts and I just learned the difference:With colon, tests variable for unset or empty. Without the colon tests only for unset. It&#x27;s POSIX too:https:&#x2F;&#x2F;pubs.opengroup.org&#x2F;onlinepubs&#x2F;9699919799&#x2F;utilities&#x2F;V... reply kazinator 3 hours agorootparentSo ${foo-bar} will not expand to bar if foo exists, but is empty. The empty value will prevail. ${foo:-bar} will expand to bar.If we have nothing in place of bar, they are effectively same. replysweeter 2 hours agorootparentprev\"set -x\" is a life saver for debugging. Also \"set -euo pipefail\" so a script just exits on errors or unexpected behavior. If done well you can really reign in squirrely behavior.Bash has some odd behaviors and footguns but it can also be surprisingly reliable and versatile. Ive caught some seriously messed up stuff that I couldn&#x27;t figure out otherwise, using set -x. Also shellcheck will forcefully hammer good practice into your head and catch a ton of hangups that are hard to know before making the mistakes.also setting backup variables is a good idea like: pictures=\"${pics_dir:-$HOME&#x2F;Pictures}\" reply LegibleCrimson 7 hours agorootparentprevThat bottom one will also fail. The empty string is not treated as a shell word.You need double quotes. reply yjftsjthsd-h 7 hours agorootparentprevPreferably you&#x27;d use set -u to avoid certain problems, and also keep using shellcheck for all the other things it can catch. reply Xiol32 2 hours agorootparentprevset -euo pipefailEffectively strict mode for shell scripts. reply gpvos 49 minutes agoparentprevAlso, if $FOO contains a space, it will expand into multiple arguments. Just quote your variables, always. reply dixie_land 5 hours agoparentprev[ x\"$FOO\" != x\"\" ] reply stouset 3 hours agorootparentPlease stop with tricks like this and just quote your variables. Everywhere. reply overtomanu 4 hours agorootparentprevwhoa, lot of history in this trickhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26776956 reply andrewshadura 4 hours agorootparentprevNo. This hasn&#x27;t been necessary for decades. reply mattrighetti 2 hours agoparentprevIn this case I would use [ -n \"${FOO?}\" ] so that the script will immediately stop if $FOO is null or unset reply 8n4vidtmkvmk 2 hours agorootparentSet -xufo pipefailOr whatever the magic string is. Enable all the errors at the start of the script reply JNRowe 8 hours agoprevchubot has written an interesting document¹ exploring more of the nuance with test&#x2F;[&#x2F;[[, and many of the other entries in that blog have intriguing explanations of the oddities of our shells(a random example²).¹ https:&#x2F;&#x2F;www.oilshell.org&#x2F;blog&#x2F;2017&#x2F;08&#x2F;31.html² https:&#x2F;&#x2F;www.oilshell.org&#x2F;blog&#x2F;2016&#x2F;11&#x2F;18.html reply cellularmitosis 8 hours agoprevI stopped using [ a few years ago because ‘test’ reinforces the idea that this is just a command like any other, not syntax. Also, “man test” is much more pleasant that sifting through “man bash”. reply tuyiown 1 hour agoparentI&#x27;m with you, the [ (and [[ bashism) introduces lots of confusions about what is really happening, I could never manage any real confidence.That said, [[ being guaranteed to be built-in certainly had its purpose at ages where shell script performance had any kind of relevance, and that was no so long ago. reply kqr 55 minutes agorootparent[[ has more to do with trying to build an intuitive shell scripting environment than performance. [[ makes conditionals behave much more like you&#x27;d expect from other programming languages. I think it&#x27;s a great idea, but then again, if I don&#x27;t have to care for POSIX portability, I&#x27;d rather use something that&#x27;s not a shell language for scripting. reply kazinator 7 hours agoparentprevYour comment makes no sense. GNU Coreutils has a \"man [\" as well as \"man test\" man page.Bash has \"help test\" for a quick cheatsheet.The [ command is very old; it was already present in Version 7 Unix in 1979. reply c0l0 2 hours agorootparentParts of the comment make a LOT of sense actually, when you look at shell scripts written by the uninitated. Often times, I see constructs like while [ 1 ]; do ...; donewhich are a pretty clear indication of the author&#x27;s misconception about the perceived nature of [ ], I think. reply kazinator 1 hour agorootparentThe nice way to write that isn&#x27;t any kind of test command but: while true; do ...; doneThere is never any reason to use test, other than portability to some broken environment that is missing [ but not missing test. reply tuyiown 1 hour agorootparent> There is never any reason to use testWhat&#x27;s the reason for always using [ ? replywodenokoto 1 hour agoprevI had no idea [ was a program and the fact that it checks if the last argument is a closing bracket is kinda funny to me.But at least it explains why you need spaces on both sides of the brackets. reply user261 6 hours agoprevI really didn&#x27;t understand why the last if statement is confusing. Is it because when starting out with shell scripting one would usually assume that the [ is a part of the bash scripting language not just another program? If it&#x27;s then I think I get it now. Otherwise please mention why it&#x27;s surprising. Also, @author thanks for a nice article. was a good reed. reply neverrroot 8 hours agoprev[[ is bash only. If you know you’ll only use bash, use it. For details, the article is nice. reply re 8 hours agoparentWell, zsh too :)https:&#x2F;&#x2F;zsh.sourceforge.io&#x2F;Doc&#x2F;Release&#x2F;Conditional-Expressio... reply dredmorbius 2 hours agorootparent\"bash only\" typically refers to \"bashisms\", that is, bash features not present in the plain Bourne shell (or Bourne-compatible interpreters such as dash). The fact that other shells (such as zsh) may include those features ... is beside the point of writing universally compatible shell scripts.Confirming my facts for this comment, #TIL that \"dash\" is the \"Debian Alquist Shell\", that is, Debian&#x27;s \"ash\" shell: reply bgm1975 6 hours agorootparentprevAnd ksh (ksh88 & later) reply emmelaich 4 hours agoparentprevAlways use [[zsh and ksh have it; in fact I&#x27;m pretty sure it originated with ksh in 1988 or earlier. reply OmarAssadi 2 hours agorootparent> Always use [[While zsh, bash, mksh, ksh93, probably others have it, sure. But many don&#x27;t -- and not totally irrelevant ones either. Debian&#x27;s default, dash, for example, does not support `[[`.IMO, unless you&#x27;re writing something like shell-specific dotfiles, avoid non-POSIX features.It&#x27;s usually pretty trivial to avoid them, especially if you&#x27;re willing to call other mandated commands like awk, etc. But often, with a bit of creative thinking, most non-standard features can be replicated with some combination of `set`, separate functions and&#x2F;or subshells.Shell scripts, in general, have dozens of footguns, are pretty much impossible to statically analyze, difficult to make truly robust, and many of the shells themselves -- e.g., bash -- have huge, borderline inauditable codebases.I can think of a dozen reasons not to write shell scripts. Yet still, there is incredible value in the fact that some form of POSIX-compliant&#x2F;compliant-enough shell can usually be found on most systems.All of that value goes out the window, though, the moment you start relying on non-standard features. reply massysett 23 minutes agorootparentDon’t worship at the altar of portability. There is real cost to portability, as it forces you to cater to broken implementations and to not use features that may be very useful. Also, it can be difficult to ensure compatibility with systems that you don’t test on, so true portability requires having different systems to test on.Sometimes all those costs are necessary for the task at hand. For example, the whole point of GNU Autoconf is that it runs on a wide variety of systems.On the other hand, many programs are for in-house or personal use and will not run on obscure systems. The cost of writing for portability simply might not be worthwhile in these situations. And that’s ok, notwithstanding some conventional wisdom of “always try to be portable.” reply nerdponx 8 hours agoparentprevThat is, test and [ are specified by POSIX and usually are physical binaries (but might also be masked by shell builtins). Whereas [[ is not specified by POSIX and usually only exists as a shell builtin. reply shmerl 8 hours agoparentprevWhy would you not use Bash (unless you are using completely different shell like Fish explicitly?).It feels like some completely archaic concern to target the minimal common shell denominator. reply mikem170 8 hours agorootparentBash seems to be about as archaic as sh.I write my shell scripts in sh, because it comes with every unix-like os by default.I know that bash has more features, but I&#x27;ve never really missed them. I switch from sh to perl for more complicated tasks.To each their own, right? reply 15457345234 7 hours agorootparentThis to me seems like good practice, it&#x27;s better to use a &#x27;real&#x27; programming language when you&#x27;re crossing the boundary from &#x27;script&#x27; to &#x27;program&#x27;Shellscript has way too many idiosyncracies and weirdnesses that would have been beaten out of a proper programming language by now. (I know that talking about weirdnesses is amusing in relation to perl which also has a whole armload of them.) reply hnbad 2 hours agorootparent> This to me seems like good practice, it&#x27;s better to use a &#x27;real&#x27; programming language when you&#x27;re crossing the boundary from &#x27;script&#x27; to &#x27;program&#x27;PowerShell would like a word with you. reply dredmorbius 2 hours agorootparentprevWriting Bourne-compliant scripts ensures maximum portability.As many here have noted, bash isn&#x27;t universally available, with another possible issue being OpenWRT devices. Stock&#x2F;base images tend to use a Bourne-compatible shell, not full Bash. Though the latter&#x27;s installable through opkg, for sufficiently small devices (typical of consumer kit), you simply won&#x27;t have the space to install them.There&#x27;s also the slight PITA that Apple&#x27;s OSX ships with a very old, pre-GPLv2 Bash, out of licensing concerns. (Apple is phenomenally averse to GPL-based code, much as some *BSDs are, such as OpenBSD.)And if you&#x27;re dealing with legacy systems (which tend to be extraordinarily and stubbornly persistently legacy), you&#x27;ll often find that either bash isn&#x27;t present or is quite dated.I freely confess that I tend to write fairly recent-feature bash scripts myself by default, and appreciate many of the newer features. But if and when I am writing portable code, I&#x27;ll go back to Bourne-compatibility.But when writing system level code, an appreciation for standards and the very long tail of legacy standards and the limitations they impose is in fact a large component of professional maturity. reply LambdaComplex 8 hours agorootparentprevNot installed by default on BSDs. Sometimes not installed in minimal environments, e.g. where BusyBox is all you have available. Maybe not installed by default on Unixes? Not sure reply loa_in_ 8 hours agorootparentHonestly, installing bash into environments seems like less work than avoiding it. It&#x27;s not hard to do. reply JohnFen 6 hours agorootparentWhen your script will be running on customer machines, you often don&#x27;t have the luxury (and sometimes it&#x27;s not technically possible because it doesn&#x27;t exist) of installing bash into the environment. reply DonHopkins 5 hours agorootparentTime to find better customers. reply cpuguy83 5 hours agorootparentprevYou don&#x27;t always have a package manager, root access to even be able to install anything, network access, etc.\"Just install bash\" is not always easy, and is not even necessary when posix shell can easily do what most people use bash-specific syntax for. reply emmelaich 4 hours agorootparentThat&#x27;s the sort of yak-shaving I will never do. I&#x27;d rather just not use such a primitive unix and&#x2F;or be in a job where one of pdksh&#x2F;ksh&#x2F;zsh&#x2F;bash is not available at all. reply isatty 3 hours agorootparentWell it’s good that you have the choice to; but it’s also not all that difficult to understand that not everyone who needs to use your script, has that choice. reply OmarAssadi 2 hours agorootparentprevIt&#x27;s not usually hard to do, no, but it is >130K of C alone, excluding whitespace, comments, tests, examples, etc. I don&#x27;t want it on my system from a security perspective alone.Add in the bootstrapping pain it imposes due to autoconf and other stuff, I think there are many valid reasons to avoid it and choose another shell that is more auditable yet still has just as many eyeballs on it (e.g., mksh - the default on Android; dash - default on Debian; BusyBox - every embedded system). reply JohnFen 6 hours agorootparentprevI&#x27;ve worked on several modern projects that needed to be able to run on a wide variety of Unix platforms, several of which didn&#x27;t have bash. Writing for the common shell denominator was important, not archaic. reply shmerl 5 hours agorootparentStill sounds archaic that it&#x27;s a problem today that needs to even be addressed. reply jtafurth 54 minutes agorootparentI wouldn&#x27;t say it&#x27;s an archaic problem, an example I can think of is writing scripts for infrastructure running minimal docker images where you want to keep the image size to a minimum, you would usually need to support both bash and other shells.Embedded applications come to mind as well. reply yjftsjthsd-h 8 hours agorootparentprevIIRC Debian uses dash as &#x2F;bin&#x2F;sh because it&#x27;s faster (execution speed) than bash. reply emmelaich 4 hours agorootparentThat&#x27;s like using a horse instead of a mule. Just not worth it. Move away from the whole equine world and use a real programming language. reply yjftsjthsd-h 4 hours agorootparentEh, there are things that shell is really good at, and there are things that other languages are good at. I will grant that shell is best for glue code; my personal heuristic is that I stick to POSIX sh, and if that hurts then I take that as a sign that I should be considering moving to Python or whatever. But avoiding it completely strikes me as a poor choice, because for the \"glue together separate programs and manipulate files\" tasks that it&#x27;s meant for, it&#x27;s really good and IMO everything else still falls short. reply csydas 4 hours agorootparentprevit’s contextual as most things. need to actually use and work on the machine? use whatever shell you want to make your life easier.need a script to run on many different systems and&#x2F;or need to write a script to be managed automatically by a service account? probably you want a shell with syntax that is guaranteed to be the same on all your systems. reply aidenn0 8 hours agorootparentprevIIRC, &#x2F;bin&#x2F;sh on Ubuntu defaults to dash reply eikenberry 8 hours agorootparentThat is from Debian and all child distros inherit it by default, not just Ubuntu. reply jabl 7 minutes agorootparentIf you want to nitpick, it was first done by Ubuntu and then later upstreamed into Debian (from which other child distros, as you correctly point out, inherit it). reply andrewshadura 4 hours agorootparentprevIn fact, only dash is supported as &#x2F;bin&#x2F;sh on Debian and Ubuntu. reply driggs 8 hours agorootparentprevBecause Apple switched the default macOS shell from the GNU-licensed `bash` to the BSD-licensed `zsh`? reply bgm1975 5 hours agorootparentApple switched when bash switched from GPL2 to GPL3 which they didn’t like. The older bash is still available. reply masklinn 4 hours agorootparent> Apple switched when bash switched from GPL2 to GPL3Apple just didn’t update. It took them years to finally switch to switch to zsh.> The older bash is still available.Aside from it being bash (a great reason not to use it as far as I’m concerned) it’s now a 17 years old version of bash. reply toast0 4 hours agorootparent> Aside from it being bash (a great reason not to use it as far as I’m concerned) it’s now a 17 years old version of bash.I thought people liked macOs for its vintage feel? Remember a time when computers could only render a single menu bar in a fixed location, feel the experience of SYN floods, run a version of bash that is old enough to vote in the next presidential election. reply mkesper 1 hour agorootparentHonestly this is such a waste of time every time I have to argue with developers about installing up to date homebrew (or whatever) versions of the coreutils that I wish Apple would simply DELETE all these ancient versions of tools from MacOS. As a bonus, homebrew does not offer --with-default-names any more and some tools (like make) are posted into different paths so you need to add your own symlinks or add multiple paths to your PATH. reply toast0 4 hours agorootparentprevAccording to the interwebs, zsh became default with Catalina in 2019 [1]; ten years after bash 4 was released with gpl v3 or later.Also, the interwebs suggest Apple used to use tcsh as the default shell[2]; I don&#x27;t know when they changed that, but it may have been after bash 4 released? (Thanks, 10.3 was in 2003, so several years before the license changed)[1] https:&#x2F;&#x2F;www.theverge.com&#x2F;2019&#x2F;6&#x2F;4&#x2F;18651872&#x2F;apple-macos-catal...[2] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18853318 reply masklinn 4 hours agorootparentbash became the default shell in 10.3. tcsh was the default before then. replycduzz 8 hours agoprevI have strong opinions about shell and they don&#x27;t actually line up with the rest of the world...I believe that [ should never be used, only \"test\" because [ gives the illusion that the mechanism is some part of the language syntax when it is just another \"program\" (I&#x27;m including built-ins and functions in \"program\").(if &#x2F; || &#x2F; && look at exit status; a program can&#x27;t see the exit status of other things other than looking at the magic variable $? which is just another string once expanded; case looks at strings but doesn&#x27;t operate based on exit status and doesn&#x27;t set an exit status as part of the case ... esac operation; \"programs\" set an exit status)I also believe that [ &#x2F; test should only ever be used for evaluating filesystem constructs -- test -f &#x2F;dev&#x2F;null and if you&#x27;ve got string evaluations use case.Unsurprisingly, most scripts make me itchy, and scripts that I write people find weird.[edited to add the explanation of \"program\" vs \"syntax\" opinion] reply cduzz 7 hours agoparentJoke&#x27;s on me; that&#x27;s the point of the article.I prefer, when writing in shell, to do this: if program then something else otherthing fiTo emphasize that the thing after the if is just \"look at the exit status of the last command before the then.\" if ls &#x2F;tmp&#x2F;goober test -d &#x2F;tmp&#x2F;goober echo \"I&#x27;ll always execute the then clause because echo will always return a 0 return code\" then echo \"this always gets run\" else echo \"this never gets run\" fibecause the \"if\" is just looking at the exit status of \"echo\".[edited to do code blocks] reply chatmasta 6 hours agoparentprevHello fellow traveler. I&#x27;ve got 8 years of scripts with `test` in them to prove I agree with you. It&#x27;s a lonely road out there... I blame the Google shell style guide.I picked up the habit of preferring `test` when I was writing scripts that needed to run in both `sh` and `bash`, but I kept it because it makes more semantic sense to me than treating a character like `[` as a command. It&#x27;s also weird that `]` is an argument to `[` rather than also being a binary. I mean, I understand the technical reasoning... but it feels like a hack. reply js2 5 hours agorootparentHello fellow traveler. I&#x27;ve got 20 years of scripts with `if test` in them. I only use `[[` when I need functionality it provides that `test` does not (pattern or regex matching, typically, and for pattern matching I&#x27;ll generally use a case statement instead). reply chatmasta 5 hours agorootparentYeah that&#x27;s when I use it too. I figure if I&#x27;ve already given into the temptations of Bash, I may as well go all the way. Sometimes if I&#x27;m feeling extra frisky I even do [[ .. ]] || { echo \"error!\" ; exit 1 } reply cduzz 5 hours agorootparentI imagine most people have sets of macros they habitually add to any sufficiently complex script they&#x27;re modifying... yelp(){ es=$1 shift echo \"$@\" >&2 exit $es } test -d &#x2F;tmp&#x2F;goober || yelp 33 \"couldn&#x27;t find goober!\"(yes, I&#x27;m sure there are standards for exit status ranges and 33 is not such a thing) reply quicklime 4 hours agorootparentprevThe Google style guide doesn’t disagree with you, it says to code exclusively for bash where possible (ie mostly everywhere inside Google) and to prefer [[ over [ and test:https:&#x2F;&#x2F;google.github.io&#x2F;styleguide&#x2F;shellguide.html#s6.3-tes...In a scenario where you also need to support shells other than bash, Google’s shell style guide doesn’t say to use [ over test. reply tuyiown 1 hour agoparentprevReading the comments here it looks like there are somehow dozens of us using test only. Dozens ! reply metadat 8 hours agoprevI&#x27;ve learned to only use [[ when I want to do a regex match, e.g. if [[ \"${foo}\" =~ ^bar$ ]]; then echo Yes; fiOtherwise, just stick with \"test\" or \"[\".85,000 lines of bash and counting... Not saying bash is great, but it&#x27;s still meeting my needs for a lot of stuff. Shrug. reply penguin_booze 2 hours agoparentThe fact that the regex is written bare and unquoted, got me a while ago. I&#x27;m someone who religiously quotes everything; it took me a while before I figured out why my stupidly simple regex doesn&#x27;t match. reply stephenr 7 hours agoparentprevIf you want to do (relatively) simple pattern matching in a posix-compliant way, `expr`[1] can match BREs, and even return a capture group.1: https:&#x2F;&#x2F;pubs.opengroup.org&#x2F;onlinepubs&#x2F;9699919799&#x2F;utilities&#x2F;e... reply cvccvroomvroom 8 hours agoparentprevThat&#x27;s a pointless example. [ \"$foo\" = bar ] && echo YesFor substring matches, [ and * globs are generally good enough. [ \"$bar\" = extra* ] && echo &#x27;$bar began with extra&#x27;Bash&#x27;s regex dialect is primitive and rarely worth fussing over. For anything complicated, use another tool be it grep, awk, perl, or such. There are diminishing returns of obsessing over doing everything in bash when a complicated task demands more capabilities suitable to another tool with greater reusability, modularity, and intrinsic types. reply aidenn0 8 hours agorootparentI thought regex inside [[ was the same as egrep? reply glandium 4 hours agoprevOne place where you learn not to use [ or [[, or be very careful about them is autoconf shell scripts (and that applies to more than `if`, like globs, sed, awk, etc.). Because square brackets are quote characters in autoconf. https:&#x2F;&#x2F;www.gnu.org&#x2F;savannah-checkouts&#x2F;gnu&#x2F;autoconf&#x2F;manual&#x2F;a... reply l0b0 7 hours agoprevSee https:&#x2F;&#x2F;mywiki.wooledge.org&#x2F;BashFAQ&#x2F;031 reply yjftsjthsd-h 8 hours agoprevI actually thought [ and test were symlinks, but that might just be from Alpine Linux where they&#x27;re both symlinks to busybox. reply somat 8 hours agoparentHardlinks actually, but who&#x27;s counting? plus in real world usage you will hit the shell builtin anyway. ls -li &#x2F;bin&#x2F;\\[ &#x2F;bin&#x2F;test 26016 -r-xr-xr-x 2 root bin 133256 Mar 25 2023 &#x2F;bin&#x2F;[ 26016 -r-xr-xr-x 2 root bin 133256 Mar 25 2023 &#x2F;bin&#x2F;testI have to admit I avoid \"[\" in my scripts, it is a weird hack trying to make a command look like syntax and this really bothers me for some reason. reply yjftsjthsd-h 7 hours agorootparentNo, Alpine uses symlinks: $ docker run --rm -ti alpine &#x2F; # ls -l &#x2F;usr&#x2F;bin&#x2F;test &#x2F;usr&#x2F;bin&#x2F;[ lrwxrwxrwx 1 root root 12 Sep 28 11:18 &#x2F;usr&#x2F;bin&#x2F;[ -> &#x2F;bin&#x2F;busybox lrwxrwxrwx 1 root root 12 Sep 28 11:18 &#x2F;usr&#x2F;bin&#x2F;test -> &#x2F;bin&#x2F;busybox &#x2F; # ls -li &#x2F;usr&#x2F;bin&#x2F;test &#x2F;usr&#x2F;bin&#x2F;[ 495254 lrwxrwxrwx 1 root root 12 Sep 28 11:18 &#x2F;usr&#x2F;bin&#x2F;[ -> &#x2F;bin&#x2F;busybox 495360 lrwxrwxrwx 1 root root 12 Sep 28 11:18 &#x2F;usr&#x2F;bin&#x2F;test -> &#x2F;bin&#x2F;busybox &#x2F; # reply figmert 3 hours agorootparentThis is different. Alpine uses busybox, where everything is implemented in the busybox binary, thus everything is symlinked to it.In other distributions, test is a separate binary, and [ is a link. reply chatmasta 5 hours agorootparentprevWhat bothers me is that you can write equivalent code with `test` and `[`, but when using `[` you need to terminate your conditional expression with `]`. Why? Isn&#x27;t it the same binary? Why is the shell adding this extraneous requirement, just to surface \"syntax errors\" rather than simply treating `]` as a no-op? reply kqr 50 minutes agorootparentIt is the test command that requires the terminating ] when it is invoked as [.It&#x27;s possible your shell pre-empts this requirement and presents it as a proper syntax error, but it would have failed anyway. reply shmerl 8 hours agoprev> And now for the final lolz. I’ve said above that these are the commands you use to evaluate expressions… but the shell also has expressions of its own via the !, &&, and || operators—all of which work on command exit statuses.It works for simulating very basic boolean expressions, but it gets ugly quickly if you need some more complex combos of NOT, OR and AND. I wish Bash had proper boolean expressions support. reply candiddevmike 8 hours agoparentIt works fine, you can satisfy your boolean logic needs with bash tests and exit codes.You&#x27;d be amazed at how much of the world runs (just fine!) on bash conditionals. reply hyperhopper 6 hours agorootparentYou&#x27;d be surprised how much of the world runs on cobol and Fortran.Doesn&#x27;t mean those are good or even okay or that people should choose to use them. reply remram 8 hours agoparentprevWhat do you mean? Bash does have (), {}, !, &&, ||What else do you need for \"proper Boolean expressions support\"? reply shmerl 8 hours agorootparentI don&#x27;t think you can assign boolean variables to boolean expressions, becasue there is no boolean type.Something like this won&#x27;t work to become false: foo=true bar=false baz=$foo && $bar echo $bazOr even simply: foo=! $fooWith numeric expressions, you can at least use $((...)) reply emmelaich 4 hours agorootparentYeh you&#x27;d have to do something like foo=true bar=false $($foo) && $($bar); baz=$? case $baz in 1) echo false;; 0) echo true;; esacIt just ain&#x27;t worth it. reply shmerl 1 hour agorootparentYeah, that&#x27;s very convoluted. It would be useful to have some context for boolean expressions, similarly how $((...)) works for numeric ones. replystn_za 3 hours agoprevjs frontend dev masses ripping on bash here. lulz reply pavlov 3 hours agoprevWriting bash scripts seems like the ideal use case for Chat-GPT style programming.The programs are fairly short, examples are common in the corpus, and the syntax and execution model are so inscrutable that only a machine can pretend to understand what’s going on. reply saagarjha 1 hour agoparentI tried doing this and it made a bunch of mistakes with handing spaces and whatnot that makes shell scripts often brittle. Of course, a human would probably make the same mistakes, because who actually knows how to do that correctly? But it doesn’t really make me comfortable using it for anything but the smallest of automation tasks. reply croo 3 hours agoparentprevI already tried to customize my command line prompt with it. All the arcane colouring character decodings and random character escaping missions became a \"put git branch names in parenthesis and make it cyan\". reply db48x 2 hours agorootparentWhat’s so arcane about `echo \"$(tput setaf 6)cyan$(tput sgr0)\"`? reply spullara 2 hours agoparentprevFor sure:https:&#x2F;&#x2F;gist.github.com&#x2F;spullara&#x2F;0fc3e88150f66179017b9aa1758... reply rjblackman 2 hours agoparentprevyes, this is the best use case I have found for chat gpt. I&#x27;ve been automating away all of my little annoyances with powershell. reply stevage 8 hours agoprev [–] > But if you know your script is going to be Bash-specific anyway, you are probably better served by using [[ unconditionally and consistentlyHonestly, I think writing a Bash script is just a terrible idea. Use a real language, and all of these nightmares go away.For me, lately, that&#x27;s been Zx (which uses Node), but there are other fine choices too. reply tuyiown 59 minutes agoparentPeople would had such a take and tell to use perl twenty years ago. Looks where we are now. I&#x27;d rather have improved my shell scripting abilities right away.It&#x27;s a three (optional) steps thing really:- I want something that can use on multiple systems right away (shell)- Ok things getting a bit serious, I&#x27;ll allow myself to add some pre-requirement tooling on the system (others script)- pre-requirement sucks, I&#x27;ll invest in native code tooling and produce binary (eg rust & go for the choices of the moment). reply jmmv 6 hours agoparentprevBash is \"real language\" if you treat it as such. Yes, there are plenty of spaghetti scripts out there, riddled with global variables and full of side-effects, but if you write shell in a principled manner, you can solve some pretty big problems with ease, and you can write maintainable code.I wouldn&#x27;t start new projects in shell, of course, but one area in which I think the shell shines is in writing integration tests for tools. More on this in a recent post I wrote: https:&#x2F;&#x2F;jmmv.dev&#x2F;2023&#x2F;10&#x2F;unit-testing-with-shtk.html reply lmm 4 hours agorootparent> Bash is \"real language\" if you treat it as such. Yes, there are plenty of spaghetti scripts out there, riddled with global variables and full of side-effects, but if you write shell in a principled manner, you can solve some pretty big problems with ease, and you can write maintainable code.Even carefully written bash code tends to be much less maintainable than code in better languages. It&#x27;s just badly designed on multiple levels, like the famous post about PHP. Yes, if you&#x27;re really careful you can write decent code in Malbolge - but why would you?> I wouldn&#x27;t start new projects in shell, of course, but one area in which I think the shell shines is in writing integration tests for tools. More on this in a recent post I wrote: https:&#x2F;&#x2F;jmmv.dev&#x2F;2023&#x2F;10&#x2F;unit-testing-with-shtk.htmlThe fact that you&#x27;ve written something that compiles to shell scripts rather than writing shell scripts rather undermines your claim that shell is a decent language. Integration tests of tools are important, but I&#x27;d still find e.g. TCL a much better way to write them. reply stevage 3 hours agorootparentprev> but if you write shell in a principled manner, you can solve some pretty big problems with ease, and you can write maintainable code.So if you are extremely good at writing shell, and you write it extremely carefully, then you can achieve basically what you can do in other languages without those caveats?It sounds like we both agree that shell is not a sensible choice for scripting, for most people, then. reply Joker_vD 5 hours agorootparentprev> but if you write shell in a principled mannerThe same can be said about QBasic as well, honestly. And here&#x27;s the catch: people who are inclined to write anything in a principled manner are likely the ones who&#x27;d write things in a principled language instead of e.g. shell. Or to put it in another way, if someone chosen to write in shell (or failed to consider an alternative, which also happens quite often), they&#x27;re quite likely exactly the person to not write anything in a principled manner. reply jmmv 4 hours agorootparentOftentimes, the constraints around what you have to do dictate what language(s) you can use. So you do what you can with them and you try to get the best out of them. https:&#x2F;&#x2F;jmmv.dev&#x2F;2023&#x2F;11&#x2F;why-do-i-know-shell-and-how-can-you... reply Joker_vD 3 hours agorootparentI think one of the Rust&#x27;s creators (or was it Go&#x27;s?) said that they wanted to get the C++ developers to switch to their language but that didn&#x27;t happend, they unexpectedly got Python developers instead but retrospectively it makes sense to them: people who wanted to switch from C++ and could afford to had done so already, so the C++ developers are the people who either don&#x27;t mind C++ or the people who have to write it.Which brings me back to my point: yes, technically you can write decent code even in a sloppy language but that misses the bigger picture which is that most of the code written in a sloppy language will inevitably be sloppy because most of the people who write it won&#x27;t care, due to the dynamics described.Heck, the Ops department in my org was forced by the security guys to globally enable ShellCheck on commit for their internal repos, and those security guys still have to drop by about every 2-3 months to rip away their \"# shellcheck disable\" pragmas and force them to actually fix their broken code because those people in the ops actively don&#x27;t care. The Ruby scripts they write end up slightly less broken because Ruby itself is a slightly more principled language, not because they suddenly care more when they write Ruby.Not to mention myself: I&#x27;ve spent quite some time and energy on learning shell&#x27;s semantics and tricks and quirks and DOs and DONTs but it&#x27;s such an infinite, never-ending descent into abyss with rewards of dubious value that nowadays I just don&#x27;t care. Whenever I have to write a one-off script, I give up even before I start and write it however sloppy, with minimal quoting, to save my time; and only when it breaks, or when I have to reuse it, or when I have to share it — which happens quite rarely — then I re-write it in a proper language. On the whole, that definitely saved me both my time and my sanity. As for the cases when I have to write properly behaving shell script, well, those are almost arise in the course of the tasks that can be delegated to our ops team and now that&#x27;s their problem.P.S. I found that re-writing naive but broken shell scripts in a proper language is quite easy: the intended semantics is generally obvious, it&#x27;s just the shell that actually requires quirkier syntax to propely express it; re-writing the (mostly) non-broken shell scripts is much harder: you have to decipher the intended meaining from the quirky syntax while keeping in mind that the original author still could have gotten it wrong by not knowing about a particular quirk you&#x27;re aware about (or vice versa). reply yakubin 48 minutes agorootparentIt was Go. Rust has many converts from C++. But from scripting languages too. It’s a pretty heterogenous programmer-base. replyLegibleCrimson 7 hours agoparentprev [–] I agree. If a POSIX shell script serves your needs, use it. If it doesn&#x27;t, you shouldn&#x27;t be reaching for a more powerful shell, but an actual language. I&#x27;d reach for Perl before Bash, and I can&#x27;t stand Perl. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The `test` and `[]` commands are used in Unix systems to evaluate expressions in shell scripts.",
      "These commands can be implemented as separate binaries or as built-ins within the shell, resulting in different behavior across different shells.",
      "The `[[` command is a Bash extension that guarantees it is a built-in and allows for changes in the language's rules within its expressions.",
      "It is recommended to use `[` for portable scripts and `[[` for Bash-specific scripts.",
      "The article also mentions the ability to combine test expressions and shell expressions in one invocation."
    ],
    "commentSummary": [
      "The articles and discussions cover different aspects of bash scripting and the use of shell scripts, including techniques, commands, and syntax options.",
      "The importance of portability, adherence to standards, and the limitations and complexities of shell scripting are emphasized.",
      "There is debate on the choice of shells, specific tools and languages, and the pros and cons of using shell scripts for different tasks. These discussions highlight the challenges and considerations in writing effective and maintainable shell scripts."
    ],
    "points": 247,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1700699493
  },
  {
    "id": 38378242,
    "title": "UltraFastBERT: Exponentially Faster Language Modelling with Minimal Neuron Engagement",
    "originLink": "https://arxiv.org/abs/2311.10770",
    "originBody": "Computer Science > Computation and Language arXiv:2311.10770 (cs) [Submitted on 15 Nov 2023 (v1), last revised 21 Nov 2023 (this version, v2)] Title:Exponentially Faster Language Modelling Authors:Peter Belcak, Roger Wattenhofer Download PDF Abstract:Language models only really need to use an exponential fraction of their neurons for individual inferences. As proof, we present UltraFastBERT, a BERT variant that uses 0.3% of its neurons during inference while performing on par with similar BERT models. UltraFastBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by replacing feedforward networks with fast feedforward networks (FFFs). While no truly efficient implementation currently exists to unlock the full acceleration potential of conditional neural execution, we provide high-level CPU code achieving 78x speedup over the optimized baseline feedforward implementation, and a PyTorch implementation delivering 40x speedup over the equivalent batched feedforward inference. We publish our training code, benchmarking setup, and model weights. Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE) Cite as: arXiv:2311.10770 [cs.CL](or arXiv:2311.10770v2 [cs.CL] for this version)https://doi.org/10.48550/arXiv.2311.10770 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Peter Belcak [view email] [v1] Wed, 15 Nov 2023 18:42:50 UTC (35 KB) [v2] Tue, 21 Nov 2023 06:59:59 UTC (35 KB) Full-text links: Access Paper: Download PDF PostScript Other Formats (view license) Current browse context: cs.CLnewrecent2311 Change to browse by: cs cs.AI cs.LG cs.NE References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=38378242",
    "commentBody": "Ultra Fast BertHacker NewspastloginUltra Fast Bert (arxiv.org) 233 points by gyre007 21 hours ago| hidepastfavorite1 comment dang 16 hours ago [–] Comments moved to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38364084, which was posted earlier and has the original title. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Exponentially Faster Language Modelling\" presents a new BERT variant called UltraFastBERT that achieves high performance with only 0.3% of its neurons active during inference.",
      "UltraFastBERT utilizes fast feedforward networks (FFFs) instead of traditional feedforward networks, resulting in a substantial speed improvement.",
      "The authors offer code and benchmarks for their implementation, demonstrating its superior speed compared to existing methods."
    ],
    "commentSummary": [
      "The post discusses an article titled \"Ultra Fast BertHacker NewspastloginUltra Fast Bert\" shared on arxiv.org.",
      "The comments related to the post have been relocated to news.ycombinator.com."
    ],
    "points": 233,
    "commentCount": 1,
    "retryCount": 0,
    "time": 1700655605
  },
  {
    "id": 38381918,
    "title": "Firefox's New Update Takes on Chrome with Better Privacy and Enhanced Mobile Experience",
    "originLink": "https://www.androidpolice.com/never-been-better-time-switch-firefox-browser/",
    "originBody": "Home Applications It's never been a better time to switch to Firefox BY FAITH LEROUX PUBLISHED 3 DAYS AGO The mobile browser is about to get a massive update that could see it gain traction over Chrome Readers like you help support Android Police. When you make a purchase using links on our site, we may earn an affiliate commission. Read More. Chrome has been the dominant web browser for PC and mobile for some time now. Chrome is everywhere, to the point a huge selection of the best mobile browsers are Chromium-based (Google's open-sourced version of Chrome), and just because Chrome has been the leading choice for Android and desktop users, it doesn't mean it's necessarily the best browser out there. Chrome is known as a system hog on your CPU and RAM, but unfortunately, Firefox also adds stress to your system resources. But when it comes to the best privacy and security and a cleaner browsing experience, Firefox reigns supreme over the majority of Chromium implementations. But the final push to start using Firefox over Chrome might finally be thanks to the enormous selection of add-ons (Firefox's version of extensions) coming out next month. Chrome doesn't offer native support for extensions in its mobile app. This is where Mozilla can finally regain ground over Google, especially now that Google is so insistent on serving ads everywhere, like YouTube and its current security concerns. Firefox wins the battle for best user privacy and security As a non-profit project, Mozilla is committed to transparency and user privacy through an open-source model. The advantage of running an open-source project is that the entire community can contribute to making the web a better place, plus the code is public, which means anyone can audit it. Firefox also protects your privacy with its Enhanced Tracking Protection. While Google has been taking its sweet time phasing out cookies, Mozilla has been making progress with Total Cookie Protection (TCP) since 2021, and it's on by default. With extra add-ons coming to Firefox, installing your favorite extensions for privacy and security will only get easier. Installing add-ons on Firefox is only going to get better The Chrome Web Store has plenty of extensions to improve your Chrome browsing. These extensions can help you block ads, manage passwords, and provide anti-malware tools to make internet browsing safe and more secure. Only trusted Chrome extensions make it to the Chrome Web Store. But sadly, Google doesn't extend these benefits to its mobile browser. And if you can't live without your extensions, you'd have to settle with third-party extensions on Chromium-based web browsers instead, moving you away from Chrome. So far, Mozilla offers only a few select add-ons (Mozilla's version of extensions) that work on Android, one of which is uBlock Origin (proving itself incredibly helpful as YouTube wages war against adblockers). But soon, Mozilla will launch 200 new add-ons in Firefox 120. That's a whopping 200 more than Google, bringing Firefox Mobile much closer to its Desktop sibling, something Google appears deadset against with Chrome on mobile. Add-ons ensure Firefox brings a competitive edge to mobile When using Firefox, once you plug in a few helpful add-ons, you don't have to worry about sifting through tons of ads, auto-playing videos, and pop-ups. The uBlock Origin plugin can take care of these things, and if it doesn't, you can manually tell it to. And that's just one add-on. Imagine what 200 will bring to the table. Browsing the web on mobile can be just as clutter-free as web browsing on a computer. And since we often prefer to jump into a news story as quickly as possible on our mobile devices, thanks to Firefox's use of add-ons, background clutter and every other annoyance filling our tiny screens may soon be a thing of the past. It's no secret Google loves ads; Google generates billions of dollars from ads alone. And so the vast majority of sites you read follow suit, requiring ads to keep their livelihoods in check as the pay rate continues to fall. Unfortunately, based on how important ads have become for generating revenue, there will never be a shortage of ads online. But in a world of ads, ads can still exist without being intrusive. Google doesn't care which ads you see until you use filters. We also know Google can serve ads that are used for nefarious purposes, which is why the FBI recommends using an ad blocker when online. And thanks to how lucrative ads have become for Google, the company will more than likely never budge on its stance to bring extension support to mobile, as most users will install adblockers. But with Firefox, you can already install uBlock Origin to lockdown those ads, with 200 more add-ons coming soon to bolster the experience. It's about winning the war, not the battle Google Chrome may still be everyone's favorite browser on desktop and mobile, especially with its impressive library of extensions for desktops. Still, with Mozilla Firefox catching up to the extension and add-on game and bringing its work over to Android, Firefox has more than enough fuel to make a comeback in no time flat, especially as Google wages war against adblockers and its users, privacy be damned. With Mozilla's recent moves ensuring Firefox takes shape as one of the most accessible web browsers around, you'd think Google would eventually pick up the pace and start making some pro-consumer moves. But products can only improve with better competition; having another web browser that turns heads may finally force Google to up its game if Firefox really makes a splash once its new add-on supports drops. So not only is it high time to give Firefox another chance as Chrome grows stale and ad-filled, you can expect hundreds of add-ons to make the Firefox browsing experience even better on November 21st. Subscribe To Our Newsletters! By subscribing, you agree to our Privacy Policy and may receive occasional deal communications; you can unsubscribe anytime. Comments Share Share Share Share Share Share Copy Email Link copied to clipboard RELATED TOPICS APPLICATIONS MOZILLA FIREFOX ADD-ONS ABOUT THE AUTHOR Faith Leroux (177 Articles Published) Faith writes guides, how-tos, and roundups on the latest Android games and apps for Android Police. You’ll find her writing about the newest free-to-play game to hit Android, or compiling explainer guides on popular social networking apps like Twitch and Discord. Her area of expertise is in action RPGs and gacha games, but will play and study the occasional competitive shooter. Before joining Android Police, Faith studied Chemistry and graduated with an honors specialization in Chemistry in 2016; leading her to spending many hours toiling around the lab during her time spent as an undergraduate, eventually developing her analytical mindset to dissect and dissemble information and data to arrive at an answer. Her favorite pastime was writing reports, presentations, tutorials, and literature reviews, which led to her pursuing a career in writing after completing a graduate certificate in technical writing. Faith’s first Android phone was Samsung Galaxy Note II in 2012, giving her a taste of how a small piece of powerful hardware can open anyone up to endless opportunities for your favorite hobbies. She’s also been a gamer for over 20 years, starting with Super Mario Bros. on the NES; she has owned over 15 devices for gaming ranging from handhelds to consoles. Now with her analytical mindset, passion for writing, and core identity as a gamer, she can finally chase her dreams as a technical writer and gaming journalist. Nowadays, you’ll find Faith studying spreadsheets and assembling data to theorycraft new teams and builds for Genshin Impact. You’ll also see her trying to dig deep to discover Android gaming’s most hidden gems. POLL Will RCS on the iPhone benefit your life as an Android user? Yes, I use SMS to communicate with my iPhone-owning friends. Yes, because my friends and I can use RCS rather than a third-party app. No, because I'm already using a third-party app to communicate with others. No, because I don't think Apple is doing enough to make RCS matter. Something else (leave a comment). Vote View Results TODAY'S BEST TECH DEALS THE LATEST AP PODCAST A 55-inch TCL Roku TV for under $200? Only if you act NOW! 29 minutes ago Best Black Friday Samsung deals: Phones, tablets, and more 6 hours ago OnePlus Black Friday deals: Save big on OnePlus Open, 11, and more 11 hours ago See More TRENDING NOW Android 14 QPR2 Beta 1.1 is here with some minor bug fixes Galaxy Z Fold 5 and Flip 5 are the first Samsung foldables to get Android 14 Optimize your Samsung Galaxy S23 phone's home screen with our top 9 tips",
    "commentLink": "https://news.ycombinator.com/item?id=38381918",
    "commentBody": "It&#x27;s never been a better time to switch to FirefoxHacker NewspastloginIt&#x27;s never been a better time to switch to Firefox (androidpolice.com) 202 points by Hary06 16 hours ago| hidepastfavorite81 comments kristianp 5 minutes agoI switched away from FF recently. On ubuntu 22.04, was irritated by the fortnightly snap update messages. Decided to switch to the ppa version instead. The ppa version had a \"gmpopenh264\" plugin has crashed problem on many sites. Switched back to Chrome. I don&#x27;t have time for those hassles and the gmpopenh264 crash didn&#x27;t have a googleable solution.Due to the snap being the default installation on ubuntu, not enough users were on the ppa version to get even serious crashing problems fixed. reply rdsubhas 14 hours agoprevI&#x27;m all in on FF on desktop.The only thing stopping on mobile for last 4-5 years is Translations. Project Bergamot is incredibly successful, thanks again to Mozilla for investing in this! Open Translation is such an important thing, it&#x27;s a game changer.It went from beta to addon to bring built into desktop Firefox since the latest release. No words can express the amount of gratitude for this. Now, just waiting for it to be enabled in android builds.Edit: Another not so highlighted feature of Firefox is: Mac always shows Chrome as \"significantly consuming energy\". But never for Firefox. I don&#x27;t know what magic they did here.Edit 2: Don&#x27;t get me started on the benefits of containers, profiles and temporary containers as a default. reply gpchelkin 14 hours agoparentI struggled so long with having to use Chrome for translations on Android until I found out that my favourite translating extension works with mobile Firefox just perfectly. See [3] on how to install it in Firefox Beta (maybe this method or even the extension itself is already available in Firefox Release).[1] https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;traduzir-pagi... [2] https:&#x2F;&#x2F;github.com&#x2F;FilipePS&#x2F;Traduzir-paginas-web [3] https:&#x2F;&#x2F;www.ghacks.net&#x2F;2022&#x2F;10&#x2F;20&#x2F;firefox-beta-for-android-n... reply moltar 31 minutes agoprevGood thing I don’t need to switch, because I’ve been using it since moving off of IE back in mid 2000s :DThere was a bit of turbulence in our relationship when I strayed to Chrome for a brief moment because of the XUL extension deprecation. I was really pissed off because many great extensions stopped working.But then I was back in a month, because chrome is just unbearable. reply seba_dos1 15 hours agoprevThe best time to switch to Firefox was many years ago. The second best time is now. reply hotnfresh 15 hours agoparentI switched when it was Phoenix.I stopped liking it some time around v2. Maybe late 1.x series, don’t remember.I left over a decade ago. reply beej71 10 hours agorootparentWell, probably they haven&#x27;t changed it at all in the last 10 years, right? reply hotnfresh 10 hours agorootparentHad to download it again just yesterday because I needed a certain plugin for piracy reasons. Couldn’t browse at all until I disabled ipv6 via flag in about:config. Other browsers on same system need no such fiddling.Still bloated with a bad UI and offering little I can’t get in almost any other browser, all of which qualities are sharply contrary to the ones that made me start using it in the first place. They’ve changed none of what made me stop liking it. reply colpabar 9 hours agorootparentWhat browser do you use instead? reply twiceaday 15 hours agoparentprevThis is such a bad saying. I guess all the people who switched this year should have waited until now, because now is a better time to switch? reply rdlw 15 hours agorootparentIt&#x27;s not a bad saying, proverbs don&#x27;t have to be mathematically rigorous to be resonant and get a point across. reply seba_dos1 15 hours agorootparentprevThe point of the saying is that it&#x27;s a rolling \"now\". reply seeknotfind 16 hours agoprevFirefox extensions on mobile are already a game changer. I switched a few months ago.The only downside so far: the way you manage&#x2F;view downloads isn&#x27;t so great&#x2F;intuitive. reply ducktective 15 hours agoparentI wish Firefox mobile put tabs on the bottom of the screen so it&#x27;s more accessible to switch back and forth. Also the two-column layout of tab viewer is a subpar experience IMO.edit: Thanks to the replies, I figured 1) You can put the address bar at the bottom of screen 2) You can swipe on address bar to traverse through the tabs and 3) You can change the tab viewer layout to list view.(Still, I wished there was an option to list tabs on the bottom like the way Chrome does in on Android.) reply longstation 15 hours agorootparentYou can do that. It even asks you whether to put it at the bottom when you run Firefox (Android, not sure about iOS) the first time. reply JohnFen 15 hours agorootparentprevThe biggest pain point with Android FF for me is that there&#x27;s no way to get it to close all of the tabs when you close the application.I have to go through and close each tab one by one first. It&#x27;s driving me up the wall. reply kzrdude 15 hours agorootparentThe tab selector view has a menu with -> close all, does this work for you? reply vorticalbox 15 hours agorootparentprevThere actually is if you click \"delete browsing data on quit\"You can toggle \"open tabs\" to close all your tabs reply JohnFen 15 hours agorootparent> \"delete browsing data on quit\"Doesn&#x27;t that delete all browsing data, though? That&#x27;s not what I want. I admit that I haven&#x27;t dared to touch it because I assumed it deleted all browsing data. I&#x27;d be thrilled to be mistaken about this. reply vorticalbox 15 hours agorootparentNot at all you have a selection of things you can turn on.Open tabs, browse history, cookies, cache, site permissions and downloads.You can enabled as many as you like.Just having \"open tabs\" ticked will only close tabs and nothing else which is what I use reply JohnFen 15 hours agorootparentWoah!! Thank you! I guess I shouldn&#x27;t have been afraid to touch that setting.In my web searching to find a resolution to this problem, I didn&#x27;t find a single mention of this. Oh, web, you have failed me again! reply malermeister 15 hours agorootparentDid the web fail you? Looks like the web brought you vorticalbox to help you with this :) replyhappymellon 15 hours agorootparentprevHit tabs, three dots, close all tabs.Slightly quicker than doing them one by one. reply JohnFen 15 hours agorootparentThat&#x27;s a little better, thank you, but it&#x27;s still really irritating. I should be able to just close the app and be done with it.But truly, if this is the biggest issue I have with it, that&#x27;s pretty good. It just makes me actively irritated every time I use it.When I was searching around trying to find a resolution with this problem, I found numerous comments saying that Mozilla does not intend to change this behavior in the future. That made me a little mad.Update: vorticalbox gave me the solution to this in another comment. I take this all back. reply happymellon 14 hours agorootparentAh, yes that is a nice solution.My only issue with Firefox is the lack of easy access multiple profiles.I can live with that, although I wish I could pay to get that fixed. reply kawogi 15 hours agorootparentprevyou can swipe the address bar to switch between tabs. Better than nothing. reply forgotpwd16 12 hours agoparentprevA big issue Firefox mobile has is the refresh-tab-on-change be it switching to different tab or app. reply seeknotfind 12 hours agorootparentHmmm. This wasn&#x27;t happening to me on airplane mode last week. I opened a bunch of tabs on Wikipedia with a connection, and I was able to read them on the plane. It didn&#x27;t destroy the data.Is Firefox getting low memory killed on your device? reply forgotpwd16 10 hours agorootparentThing is it is also happening (not always but very often) merely switching tabs. Maybe Firefox wrongly recognizes a low memory state and unloads tab when moving away from it. It&#x27;s an open bug[0] for 3y+ (from when was originally reported on GH) now.[0]: https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1807364 reply czottmann 13 hours agoprevHi, macOS user here. I know Firefox is great, and I&#x27;d love to use it (again), but Mozilla&#x27;s decision to remove all user-facing, OS-level scripting capabilities from it (i.e., AppleScript) made me drop it a few years ago.Getting anything out of FF on macOS, locally, is a major pain in the ass, actually. Try to grab the current URL from the active tab…I think it&#x27;s a super-solid browser that unfortunately doesn&#x27;t give a shit about the platform it&#x27;s running on. Irritatingly, it&#x27;s fine with being a black box, so much more than the Chromiums are (for all their various faults). reply ssbash 12 hours agoparentI’ve also given up on using Firefox on macOS. I used to be a hard core fan, but Mozilla consistently ignores bugs.For example, years later Firefox still doesn’t support macOS password autofill api. https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=1650212 reply krackers 9 hours agoparentprev+1 everything about firefox on macos just screams non-native. And I&#x27;m not just talking about minor things like context menus not behaving natively (maybe this was fixed recently, don&#x27;t remember). There&#x27;s major stuff that would seem to be trivial to implement that they just haven&#x27;t bothered doing, like making sure the computer doesn&#x27;t go to sleep when downloading files [1].[1] https:&#x2F;&#x2F;bugzilla.mozilla.org&#x2F;show_bug.cgi?id=825914 reply div72 13 hours agoparentprevWeird thought, but have you tried using Selenium?Seems like launching a browser tab with: from selenium import webdriver driver = webdriver.Firefox()and navigating to duckduckgo.com: print(driver.current_url) # https:&#x2F;&#x2F;duckduckgo.com&#x2F;works. reply czottmann 12 hours agorootparentI have. (Web dev here.) I know it works but I don&#x27;t want to set up all the things just to get some basic scripting capability.My point is that there is zero local API surface for interacting with the application. That&#x27;s the reason why tools like Keyboard Maestro support Chromium-based browsers but not Firefox. Which, in return, doesn&#x27;t help Firefox&#x27;s popularity, because it&#x27;s nigh impossible to work with it from other apps.Disclaimer: I am in a weird spot here, for I am serious about automation both as a consumer and as a software maker -- I write macOS automation tools myself, e.g. https:&#x2F;&#x2F;actions.work&#x2F;browser-actions reply rowanG077 13 minutes agoprevQue Firefox breaking on 16K paged systems. reply slaymaker1907 13 hours agoprevI&#x27;d switch if they would support the File System Access API. It&#x27;s a really convenient API and IMO as someone who has worked with it extensively, is very secure. It supposedly has privacy concerns, but I think it would primarily be used for FOSS and hobby projects since Bigco likes to store all the data on their servers anyways, that&#x27;s a feature and not a bug for them. In fact, I think it would be a security&#x2F;privacy improvement since it would encourage storing data locally (privacy) and is way more secure than asking users to install a native app (which has access to pretty much everything on the device and not just the directory&#x2F;file a user gives it access to). reply Andrews54757 13 hours agoparentThis! It is frustrating that web apps like draw.io can&#x27;t save to file directly using Firefox. It gets old having to save a new file every time you make a change.Beyond that, the File System API would also allow for streamed downloads directly from the web-app. This would allow for web-apps to generate large download files without having to store a copy on a database (external server or IndexedDB), which is a privacy improvement. The only way to do this now is by using convoluted techniques to essentially do a MITM to a fake endpoint [1].[1] https:&#x2F;&#x2F;github.com&#x2F;jimmywarting&#x2F;StreamSaver.js reply squigz 12 hours agoparentprev> It supposedly has privacy concerns, but I think it would primarily be used for FOSS and hobby projects since Bigco likes to store all the data on their servers anywaysPrivacy concerns don&#x27;t only apply for entities of a particular size reply ochronus 4 hours agoprevNow if only it had native tab grouping (and vertical tabs, sigh)... all the extensions supporting this are quirky, with subpar UI. I know it sounds nitpicky, but if I spend a lot of hours staring at a piece of software, I want it to be at least not displeasing. reply p1mrx 15 hours agoprevI have Firefox 120 on Android, but I&#x27;m unable to search for my extension (IPvFoo) on the addons page. It works on Firefox Nightly 122, and previously worked when Nightly was at 120.Maybe the launch still requires a server-side change? reply Moldoteck 13 hours agoparentAfaik on ff original you&#x27;ll still not have full list of extensions, just a more extended list reply jakubmazanec 13 hours agoprevStarted using Firefox when it was still Phoenix, never stopped. Few years ago when they made Quantum, Firefox is awesome performance-wise: I can have hundreds of tabs open (with +- 50-90 always active), with no crashing (before Quantum, Firefox needed restarting once in a while). Chrome simply cannot handle that and consumes so much RAM. reply ravenstine 15 hours agoprevI use Firefox at home and Chrome at work, and I can&#x27;t imagine going back to Chrome or Chromium at home. Firefox in 2023 is in great shape as a piece of software.Firefox could do some relatively small things to push it ahead of Chrome in some areas.Bookmarks sorely need an overhaul. For instance, it&#x27;d be really nice if bookmarks could appear in a side-pane instead of a popup window, and allow the user to sort by chronological order. That would discourage me from keeping so many tabs open, which would be a good thing. Just having a dumping ground for interseting pages that I can easily access and search through would be a good thing. It would also be amazing if bookmarks, or something like bookmarks, could optionally capture and store the body text on the page for searching purposes or even personal archiving.Searching tabs through the URL bar is pretty much broken and has been for years. Actually, I&#x27;m not sure that ever really worked. If I begin typing something that matches the title of a tab I have open, it rarely ever shows up as a URL bar suggestion. WTF? Is it really that hard to traverse a small array of tab titles and do a regex? I don&#x27;t get it. What about full-text search across all the pages I have open? Can&#x27;t do that either, apparently. Then again, who would actually want to do that? &#x2F;s Ok, sorry for the sarcasm. Sort of. I mean this in the most constructive way possible. If I get time again, maybe I&#x27;ll eventually fix these things in Firefox, but for now I hope someone at Mozilla reads this and decides it&#x27;s worth fixing. reply abdullahkhalids 15 hours agoparent> it&#x27;d be really nice if bookmarks could appear in a side-pane instead of a popup windowCtrl+B on linux&#x2F;windows or I guess Command+B does exactly this.> and allow the user to sort by chronological orderThis is possible in the main bookmarks window. There is a sort by last modified option which should do the trick. It would indeed be nice to have this option in the sidebar.The other features you mention are more appropriate for an extension.Edit: I just found out that you can open the bookmarks window in a tab by visiting chrome:&#x2F;&#x2F;browser&#x2F;content&#x2F;places&#x2F;places.xhtml reply frizlab 15 hours agoprevI still have that old image from when I was a kid; it’s still relevant, though it was initially against IE… https:&#x2F;&#x2F;frostland.fr&#x2F;adopt-firefox.jpgIronically I’m using Safari (and I love it). reply rodrattt 14 hours agoparentWeb devs seem to love to sh*t on Safari for not adopting all the latest let-your-browser-do-this stuff, often calling it the new IE. However I use it as my main browser with Wipr for ad-blocking and it&#x27;s glorious. I&#x27;ve tried FF many times and also Opera, Brave (ooh boy!) and Chrome and some other browsers and always come back to Safari. I don&#x27;t think devs realise I don&#x27;t want my browser to have more and more access and control. It&#x27;s great for thin computing but is there really some distinction now to thin computing than the early Chromebook days? I don&#x27;t think so. All I really want is a moderately effective way of blocking ads and snooping. Giving websites more control isn&#x27;t going to achieve that. Ofc I could always delve into the tech and get this add-on or that thing but where does that end‽Strangely enough, the one browser I&#x27;ve found that would challenge Safari most for me is duckduckgo&#x27;s browser, it&#x27;s simple and functional. reply lapetitejort 15 hours agoparentprevI remember while there was a push to adopt Firefox, there was another reactionary push against \"alternate browsers\", most likely from web devs who were frustrated that they had to support something other than Internet Explorer. What an interesting time. reply vehemenz 15 hours agorootparentNow they will unironically push back against Safari for not using enough bleeding-edge APIs. The lesson here is that web developers only have their own interests in mind, and what they want isn&#x27;t necessarily what&#x27;s best for the web. reply JohnFen 15 hours agorootparent> The lesson here is that web developers only have their own interests in mind, and what they want isn&#x27;t necessarily what&#x27;s best for the web.True, but it&#x27;s even more insidious than that. A ton of web devs seem to believe that what&#x27;s in their own best interest is what&#x27;s best for the web. reply ducktective 15 hours agoparentprev>Ironically I’m using Safari (and I love it).on iDevices? reply frizlab 15 hours agorootparentAnd on my Mac. Safari does not exist elsewhere anyway (anymore).I hope Kagi will succeed in bringing a credible alternative (Webkit) to chromium or Gecko on Windows&#x2F;Linux, but it’ll take time even if they do it! reply mholm 15 hours agorootparentI really like Kagi Orion and hope it can succeed, but the keychain integration is still severely lacking, and also is my favorite advantage of safari. Maybe there are settings I&#x27;m missing, but migrating everything over to their keychain still has a substantially worse experience. No auto-filling, requires swapping all devices over to it, and seems much less aware of which password to suggest. It upsets me that Apple has Safari behind a usability moat like this, though someone has suggested that the recent mac&#x2F;ios update has provided safari keychain access to third parties. reply childintime 10 hours agoprevMy biggest gripe with FF on Android is closing tabs, especially private tabs. Even though it puts up a notification to close all private tabs, it still takes like 7 clicks, or more, before looking at the last normal tab again.If you have or had private tabs open, FF will ironically advertise that to the max, because of how clumsy it handles them. reply Sloppy 14 hours agoprevHaha, followed the link in Firefox but it was blocked because of my ad-blocker.Who has the time to track all the stuff Google collects about you? At least spread out the tracking by NOT using every Google app. They&#x27;ve become the single largest surveillance organization in history, dwarfing even China&#x27;s government.Besides Firefox and Duckduckgo work so well I don&#x27;t notice the difference.Next, dropping Gmail... reply ananth99 3 hours agoparentThis. FF and DDG work so well together that I hardly notice any downsides moving to it. DDG is my default search engine now and I rarely use google for sports updates. That&#x27;s it. reply ser1us 15 hours agoprevHave not used Firefox for years and am interested in giving it another chance. Currently using Edge, I love the split screen and vertical tabs features. Also, I just realized, I have a lot of PWAs installed. Does Firefox support PWAs on the Desktop? reply Georgelemental 13 hours agoparentNo PWA support unfortunately :( No split screen either. There are several extensions that provide vertical tabs reply ser1us 4 hours agorootparentOh nooo. Honestly, I dont want to miss out on PWAs.Oh well, guess I have to wait and see and potentially switch to another Chromium based one. Time to figure out which ones will adobt the new manifest. reply sbbr 13 hours agoprevAside from all other advantages I&#x27;m on Firefox because can&#x27;t live without MRU ctrl-tab tabs management. Chrome will never implement this, and plugins for different keys are not an option. reply beezlewax 11 hours agoprevI&#x27;m all in on Firefox mobile and desktop except for switching to chrome when some odd site doesn&#x27;t work. No issues generally and it&#x27;s been years. reply ta45654777 13 hours agoprevWith the &#x27;Delete Data on Quit&#x27; option enabled on Firefox mobile, this used to adequately clear (or seemed to) any state for Youtube.com.Some time over the last few months this seems to have changed - I have to now go to Settings > Delete All Browsing Data (or similar) to effectively get Youtube.com to forget everything.Not sure what has changed there... reply m-p-3 11 hours agoprevuBlock Origin, which is also available on Firefox for Android is also more than an adblocker when you add some additional filtersIt can clean URL parameters for privacy reason https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;DandelionSprout&#x2F;adfilt&#x2F;master&#x2F;LegitimateURLShortener.txtIt can also bypass some soft-paywalls https:&#x2F;&#x2F;gitlab.com&#x2F;magnolia1234&#x2F;bypass-paywalls-clean-filters&#x2F;-&#x2F;raw&#x2F;main&#x2F;bpc-paywall-filter.txtas well as blocking those annoying cookie banners, chatbot widgets, etc reply superkuh 16 hours agoprevTitle needs \"on mobile\". For actual computers you should probably go further and switch to a user freedoms respecting Firefox fork. Mozilla stopped doing so in version 37 when they turned off the ability to users to install (or edit) extensions&#x2F;add-ons without Mozilla&#x27;s approval. It&#x27;s only been downhill since in terms of removal of features to \"protect users\" and the addition of proprietary DRM. reply JoshTriplett 16 hours agoparentYou can opt into installing extensions directly from XPI files, in developer versions; it&#x27;s just not the default. You can also disable DRM.I don&#x27;t like that the web added DRM, but given its existence, if Firefox said \"you can&#x27;t watch Netflix &#x2F; Prime Video &#x2F; etc in Firefox\", they&#x27;d lose even more market share than they already have. reply Tommstein 14 hours agorootparent> I don&#x27;t like that the web added DRM, but given its existence, if Firefox said \"you can&#x27;t watch Netflix &#x2F; Prime Video &#x2F; etc in Firefox\", they&#x27;d lose even more market share than they already have.Firefox saying that now would have no effect, since they successfully managed to piss away approximately their entire market share despite going along with bullshit like that to not lose market share. Firefox saying that back when they had meaningful market share would&#x27;ve incurred significant cost calculations for everyone contemplating just throwing away the entire Firefox market. reply JoshTriplett 13 hours agorootparentYes, I agree. They should have fought it tooth and nail when it was proposed, and held out as long as possible.But if sites were willing to do it anyway, despite losing substantial numbers of users...I would have liked to have seen that theory tested, but it may or may not have worked. reply superkuh 15 hours agorootparentprevCorrect, you can&#x27;t install unsigned (not approved by Mozilla) extensions&#x2F;add-ons in the main Firefox release. You have to use insecure&#x2F;crashy versions (developer*) or you can dig deep and find the unbranded builds of Firefox and manually download and unpack them for every single update (they have updates disabled). It&#x27;s tedious but I do it.The ESR releases of FF main don&#x27;t allow unsigned add-ons. You may be using a custom user freedom respecting build Debian specifically negotiated with Mozilla to allow in it&#x27;s repositories?*The developer version is literally the alpha release, later renamed aurora, later named developer. It is not acceptable to use an alpha release as a main driver for security and stability reasons.You&#x27;re right about disabling DRM though. That&#x27;s not a deal breaker the way it&#x27;s implemented. reply ArclightMat 8 hours agorootparent> The developer version is literally the alpha release, later renamed aurora, later named developer. It is not acceptable to use an alpha release as a main driver for security and stability reasons.It hasn&#x27;t been for a long time, Mozilla dropped the Aurora channel in 2017 and rebased Developer Edition off Beta [0]. And as far as I&#x27;m concerned, beta is as stable as mainline (on my phone, at least).> The ESR releases of FF main don&#x27;t allow unsigned add-ons. You may be using a custom user freedom respecting build Debian specifically negotiated with Mozilla to allow in it&#x27;s repositories?Official documentation says you can still load unsigned extensions on ESR, but you need to enable a flag in about:config first [1].[0] https:&#x2F;&#x2F;venturebeat.com&#x2F;business&#x2F;mozilla-kills-firefox-auror...[1] https:&#x2F;&#x2F;extensionworkshop.com&#x2F;documentation&#x2F;publish&#x2F;signing-... reply superkuh 4 hours agorootparentI imagine if you use it on $latest OS and the like it&#x27;s stable. But I can assure you if you&#x27;re distro is a little older then the lib mismatches make developer edition a crashy experience.I&#x27;m glad to hear about [1]. I&#x27;ll have to try this in ESR myself. Hopefully all my extensions have the extra requirement of an add-on ID set. But I suppose I can edit that in myself for each if not. reply JoshTriplett 14 hours agorootparentprevOutdated information, sorry: some reports suggest that at one point they had disallowed it on standard builds but allowed it on ESR, but that doesn&#x27;t seem to be the case anymore.So, yes, you have to use a developer version, or a packaged version.That said: What extensions, exactly, do you want to use on Firefox that aren&#x27;t shipped on AMO? Other than the development of extensions themselves (for which it makes sense to use a developer version of Firefox), what is the use case? reply superkuh 14 hours agorootparentFor me it&#x27;s not so much about which extensions but my ability to edit the extensions to fit my needs. Little tweaks to change appearance or text or or some internal list the extension uses. I do this fairly regularly (maybe once a month?). reply mr_sturd 15 hours agoparentprevI switched over to IceRaven due to the extension lock out. The only extension I really needed outside of the Mozilla walled garden was to help getting past pay walls. reply hagendaasalpine 16 hours agoparentprevyou can still install .xpi files on desktop reply jakeogh 15 hours agoparentprevPocket killed it for me. I got tired of re-disabling it. reply nisse72 5 hours agorootparentYou can add \"DisablePocket\": true(and many other things) to your policies.json file. In my case that file is a symlink to a single master copy I maintain outside of the FF installation folder. See https:&#x2F;&#x2F;mozilla.github.io&#x2F;policy-templates&#x2F; reply rootsu 16 hours agoprevWow, AndroidPolice has fallen so much since the acquisition. reply tedunangst 13 hours agoprevIf switching today is better than yesterday, then by induction switching tomorrow will be better than today. reply novia 15 hours agoprevDid Firefox update at the end of the desktop browsing session instead of the beginning yet? If not, no, it&#x27;s still not a good time to switch (back) to Firefox. reply weberer 12 hours agoparentYeah, they changed it I don&#x27;t know how many years ago. It now gives a little bubble in the navbar asking the user to restart at his or her leisure. reply novia 12 hours agorootparentOh gosh, thank goodness. Firing up Firefox with a question burning in my brain to be answered only to be delayed by a browser update was the most annoying thing to me. I&#x27;ll give them another shot. reply davidy123 15 hours agoprev [–] I use Kiwi Browser. It is an open source fork of Chrome for Android that allows installing any extension. This is better than Chrome, which allows no extensions, and Firefox, which will only offer 200 or so. It also has its own ad blocking built in. Open source ftw. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Firefox, the mobile web browser, is receiving a major update that aims to challenge the dominance of Chrome in both PC and mobile browsing.",
      "Firefox offers better privacy, security, and a cleaner browsing experience compared to Chrome, making it an attractive alternative.",
      "One advantage of Firefox over Chrome is its ability to support add-ons, and Mozilla is launching 200 new add-ons for Firefox Mobile, bringing it closer to its desktop version. These add-ons offer features such as ad-blocking, password management, and enhanced security, making Firefox more versatile and user-friendly."
    ],
    "commentSummary": [
      "Users have positive experiences with features such as translations and energy consumption when using Firefox as their web browser.",
      "However, there are technical issues and dissatisfaction with the user interface reported by some users.",
      "Discussions also revolve around the customizability of Firefox, the need for improved tab management and file-saving capabilities, and the implementation of the File System API.",
      "Privacy and DRM concerns are raised, along with considerations of alternative browsers.",
      "Overall, it is suggested that switching to Firefox may be a good choice at this time."
    ],
    "points": 202,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1700673044
  },
  {
    "id": 38380344,
    "title": "GitHub Renames User Accounts Without Notice or Explanation",
    "originLink": "http://russbishop.net/github-renamed-me",
    "originBody": "Github Renamed Me We will change your SSH keys and you will like it Russ Bishop March 28, 2014 In preparation for a new post, I logged in to GitHub recently. I created my account two years ago in anticipation of being able to open-source more code and I wanted to reserve my name; I had a couple of forked repos but that's it. A new baby and a wife with major back surgery will do that to you. Imagine my surprise when I logged in today and found that my account had been renamed. No longer was I known as github.com/rbishop. Instead, I was now relegated to github.com/rbishop-xx. How curious. I next noticed a warning about verifying my SSH key. \"Why self, I don't remember uploading an SSH key just yet\" \"Well self, that's because you haven't\" Now I was even more curious. Had my account been hacked? Had I made a mistake somewhere? That's when I checked Account Settings, Security, Security History and behold two months ago: Whoever this rathjenc character was, he had not only renamed my account but he uploaded an SSH key, thus allowing him to modify my repos at-will. Just who was this rathjenc fellow? Now I am merely left with questions. Why is an official Github representative renaming accounts and modifying people's SSH keys without so much as an email to the account holder? There is now a new owner of the rbishop name: Richard B; is he a friend of Chris? Was Chris doing his buddy a favor by kicking me off? Or perhaps it's because Richard B is a member of their Developer program. Maybe people who pay more or develop Github integrations have priority on names? Maybe it's just policy that you can take someone else's name if you ask real nice ? Whatever the case, I certainly couldn't find any documentation of this forced-renaming policy on Github's website, and as we all know they're a professional organization. They certainly don't have founder's non-employee wives running around intimidating employees. As I said earlier, how curious. Russ Bishop This blog represents my own personal opinion and is not endorsed by my employer. Subscribe to this blog Share comments powered by Disqus © 2023 Russ Bishop",
    "commentLink": "https://news.ycombinator.com/item?id=38380344",
    "commentBody": "GitHub Renamed Me (2014)Hacker NewspastloginGitHub Renamed Me (2014) (russbishop.net) 194 points by SushiHippie 18 hours ago| hidepastfavorite70 comments heinekan 16 hours agoI’ve been on the other side of this.I asked GitHub if they could change my username to one that was already taken. As long as the account does not have repos of their own and was deemed sufficiently inactive they can take it.The support staff approved my request, but I have friends who’ve gotten declined. reply jperras 16 hours agoparentI&#x27;ve actually had a (great) username completely blackholed by github. I&#x27;m still a bit salty about it.I had received an email several years ago informing me that it was going to be removed. They gave me the equivalent to a coupon for a free year of the github personal plan as compensation.To this day it&#x27;ll tell you that the username is \"unavailable\" if you try to sign up with it, and the page just 404s. reply asylteltine 16 hours agorootparentAnd it’s called? reply charcircuit 15 hours agorootparentmalware is probably the best known case of thisToday the profile just 404shttps:&#x2F;&#x2F;github.com&#x2F;malwareedit: yep this is his account reply SeenNotHeard 15 hours agorootparentAnd Mike Alware is still salty about it. reply emmelaich 12 hours agorootparentMore likely Malcolm Ware? reply bigbillheck 16 hours agorootparentprevWhat was the username? reply jperras 14 hours agorootparentAs charcircuit figured out, the username is&#x2F;was `malware`. They deactivated it in 2018 without any explanation, and even my contacts at Github at the time couldn&#x27;t quite figure out why it was happening.My only thought was that it was during the MSFT acquisition due diligence, and my username was an unfortunate victim of whatever compliance requirements they had to satisfy. reply pests 8 hours agorootparentHonestly the url does not look good. I can see why they wouldn&#x27;t want it showing up in logs or across the internet. Maybe it was getting hit by virus scanners or other Internet filtering as well. reply ddalcino 16 hours agoparentprevSounds like a believable explanation.> I created my account two years ago in anticipation of being able to open-source more code and I wanted to reserve my name; I had a couple of forked repos but that&#x27;s it. reply cedws 1 hour agoparentprevAny idea if they still grant requests like this? There are some pretty nice usernames taken by completely empty accounts. reply nixgeek 16 hours agoparentprevPolicy on this seems to have shifted in the last 1-2 years.I’ve asked personally in the last 12 months for a couple situations and been declined by GitHub Support.Looking quickly on Reddit mine isn’t an unusual experience.It was good while it lasted! reply amacneil 13 hours agorootparentSame experience for me. 3 years ago I was able to claim an inactive username (the actual process was that you filed a complaint about an inactive user, they renamed the account, then said \"it&#x27;s available now, good luck you better be quick\", so it was not an official transfer process).Tried again about 12 months ago for a different username&#x2F;org and was told this is no longer possible. reply cortesoft 16 hours agoparentprevYeah, sounds like GitHub doesn&#x27;t let people squat usernames.The author says GitHub can &#x27;modify his repos at will&#x27;, but earlier he says he doesn&#x27;t even have any repos besides a few forks (which were likely not modified) reply siva7 12 hours agoparentprevThe problem was that this process was handled very poorly by their support team years ago. No notification or any kind of communication with the original owner. What seemed to you inactive could have been still an active user. This happened to me. It seems that after the Microsoft acquisition things may have improved and they don’t enforce the name squatting policy as easily as before. reply preciousoo 7 hours agoparentprevI did this (request an inactive name) for a username many years ago, which led to people scraping my personal email from commits, and using information I used in my readme to contact me and ask for it. “It’s my real name” and other stories.I almost gave it away the first time, but the person wouldn’t provide proof of it being their name. Future requests made me realize it was just a coveted username reply tripdout 13 hours agoparentprevSame here, not sure if they still list it but GitHub had a name-squatting policy on their site, and after referencing that in an email to support, requesting a username of someone who only had a handful of repos about 8 years ago, they released the username to the public so I could switch to it. reply fmeyer 16 hours agoparentprevThat happened to me too, I was able to secure our organization&#x27;s name that way. There was someone squatting on it, and it could have caused potential problems if they started uploading code. From what I recall about the process, it was pretty straightforward - I sent an email and just a few minutes later, I had the username linked to me. reply endorphine 14 hours agoparentprevSame story here reply dymk 16 hours agoprevI mean, fair play. If you squat on a username and don&#x27;t do anything with it for years, having it yoinked seems reasonable. It&#x27;s not like you paid for it. reply benjaminwootton 16 hours agoparentI do actually think this is reasonable. It&#x27;s really annoying when the handle you want is taken by someone who hasn&#x27;t used it for years.Two years might be a little short though. reply mbauman 15 hours agorootparentIt feels a little different if — as it seems to be the case — the GitHub account is used as a static site generator. Heck, the guy could&#x27;ve been depending upon CNAMEing to `rbishop.github.io`. reply funcDropShadow 2 hours agoparentprevWhy did the Github support add an ssh key, though? reply NotYourLawyer 15 hours agoparentprevWeird not to notify the original owner and give him a chance to respond though. reply fallat 15 hours agorootparentYeah I think this is the real issue at hand. reply rand_flip_bit 15 hours agoparentprev> It&#x27;s not like you paid for it.There are individuals that pay ~$4&#x2F;month for GitHub Teams, plus other services (Copilot, CI, LFS, Packages, etc). They may not have public repos, but that shouldn&#x27;t matter. reply paulddraper 13 hours agorootparentYou are talking about something different. reply Ferret7446 12 hours agorootparentprevI doubt GitHub is going to close the account of an actively paying user. Rather, the fact that they are paying for it constitutes proof that the account is actively owned. reply notorandit 15 hours agoprevThere is no cloud, dude. It is someone else&#x27;s computer. Deeply buried somewhere it is written they can do anything with your stuff that resides on their computers.Or simply they can do it, then it&#x27;ll up to you to sue them.Good luck! reply jlnthws 16 hours agoprevI was early adopter and managed to get a 2-letter username but I’ve also been renamed to -xx without notice and any explanation :( reply dobladov 16 hours agoprevThis can cause problems in repositories with CODEOWNERS files, at the very minimum the change should be notified. reply OJFord 15 hours agoparentIf old guy has (or creates without noticing the name change) a (possibly private!) repo called &#x27;test&#x27;, and then new user creates one with the same name, when old guy pushes...I assume they think their checking for emptiness and inactivity covers these cases to some reasonable likelihood. reply bastawhiz 13 hours agorootparentNothing will happen when the old guy pushes because the SSH key was changed. reply OJFord 13 hours agorootparentWell, or was it? Unclear to me why they did that in TFA - if they just changed the name, keeping same SSH key on that one (now under a new name) would be fine, helpful even. We don&#x27;t know if it was changed&#x2F;removed on the old name (just assume&#x2F;hope so). reply bastawhiz 10 hours agorootparentThe post opens with the author describing how his key wouldn&#x27;t work. But moreover, his account was renamed. Git has no knowledge of usernames. If the old key was kept on the account that was renamed, it wouldn&#x27;t have given anyone access to anything new. reply OJFord 9 hours agorootparentI didn&#x27;t say git did anything with GitHub usernames.Yes it would, OP would hypothetically push to old user&#x2F;org not realising their namespace had changed, but the key would check out, and potentially what was private would now be public.But anyway, it was a hypothetical, and relatively unlikely, since for real damage (what should be private being public) you&#x27;d need to know or be misfortunate&#x2F;lucky in happening to use exactly the right (or wrong) repo name anyway. And as I said hopefully&#x2F;I assume they do wipe remove the key anyway. replyking_geedorah 12 hours agoprevLots of discussion on the name changing portion of this, but I’m more perplexed by the github dev &#x2F; support adding an SSH key to the account. Obviously they have that kind of access to the data &#x2F; accounts hosted in their infra, but I don’t really understand why that would have been necessary or why they didn’t remove the key afterwards. reply dkarras 13 hours agoprevthis happened to me as well. I had repos, I was even approved members of several large scale open source projects. Just did not have to do anything related to GitHub for a few years. Turns out they renamed me and gave my name to someone else upon request. My links to various repos in my github scattered around the internet (with the old username) still works (so I assume, the new owner can&#x27;t create repos with the same names). Don&#x27;t know why GitHub goes through all those hoops to allow this to be honest (yes I&#x27;m salty). Like if it was just a registration and empty account that is understandable but they renamed an account full of repos and memberships and their infrastructure supports keeping old links active etc. Just weird. reply siva7 13 hours agoprevHappened to me also. I had registered my username in the first year Github started. Around 10 years later i discovered that someone else assumed my username through reaching out to their support. I was using Github still actively but hadn’t committed for quite some time in public. I was very pissed when i discovered. Support refused to change my name back instead giving me a coupon i never asked for. Whoever thought at Github this to be a good idea didn’t think through. It’s like the most retarded solution to a problem every social platform faces i’ve seen so far in how it is checked through. reply seszett 16 hours agoprevI can&#x27;t find a followup, but it seems like \"rbishop-xx\" is still there, \"rbishop\" still owned by someone else, and Russ Bishop has moved on to the user \"russbishop\".It&#x27;s still a bit curious and troublesome. reply duped 16 hours agoprevSeems like a reasonable approach to namesquatting, although an email notice would probably have been nice. reply ghusto 16 hours agoparentIs it though? For one thing it doesn&#x27;t stop squatting, since all an actual squatter has to do is create a repo with some legit looking code. All this does is inconvenience people like the author who have legitimate reasons for not having uploaded anything yet. reply squeaky-clean 15 hours agorootparentDoes the author have a legitimate reason for having not uploaded anything? I don&#x27;t see how they&#x27;re different than any other name squatter, they wanted to reserve the name while not using it. Another person who goes by rbishop wanted to actually use name. From the latter rbishop&#x27;s perspective, Russ was name squatting his username.Doing a bit of snooping, this post was March 2014, his first interaction on Github was February 2015. So he still didn&#x27;t do anything on Github for 11 months after the name change. reply crooked-v 15 hours agorootparent> Does the author have a legitimate reason for having not uploaded anything?Plenty of projects are using GitHub as a social hub. Pushing code isn&#x27;t the sole use of a username there. reply pohl 14 hours agorootparentBut was he using it as a social hub? reply eesmith 4 hours agorootparentsiva7 was, at https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38384928 . (\"I was using Github still actively but hadn’t committed for quite some time in public.\") reply pests 7 hours agorootparentprevI didn&#x27;t realize people needed a reason for not uploading code for a dueation. Wtf? reply epcoa 15 hours agorootparentprevUse it or lose it is a good base policy. Just because it isn’t perfect does not change that. Two years(!) is a long time to be sitting idly on a name and is squatting regardless of intent or circumstance. reply duped 15 hours agorootparentprevIt seems like GH admins are capable of looking at a user and making a judgement call (no repos, no activity, no SSH keys, and a few forks) to determine that the username is being squatted. And based on the article, the author was just name squatting. I don&#x27;t think there&#x27;s a distinction between \"legitimate\" or not - use it or lose it. reply ddalcino 16 hours agoprevThis is from 2014. Was there ever any resolution to this? I don’t see any previous discussions about this on HN. reply advisedwang 16 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;rbishop-xx still points to the author and https:&#x2F;&#x2F;github.com&#x2F;rbishop still points to the Richard B mentioned in the post. So if there was a resolution it didn&#x27;t reverse the rename. reply maronato 14 hours agoparentprevThe author created a new GH accounthttps:&#x2F;&#x2F;github.com&#x2F;russbishop reply OJFord 15 hours agoprevI wonder if they&#x27;ve ever used, or wanted to use, a path or org themselves (like actions, say) that was taken by some external user.Seems a good idea to put user generated content somewhere else, like example.com&#x2F;users&#x2F;OJFord instead of top-level say, and then if you decouple handle from displayed name people don&#x27;t care to claim they&#x27;re clean name as in OP so much either. But of course for the URL, you have to think of that in your early days - GitHub can&#x27;t break all those links now! reply pfarrell 16 hours agoprevWithout any context or followup, this seems like old news that doesn&#x27;t need to be rehashed on the front page today. This event pre-dates the Microsoft purchase of Github. reply afterburner5 15 hours agoparentAlso considering that since the acquisition, they won&#x27;t do anything to dissuade name-squatting anymore, despite their terms of service still suggesting otherwise reply sandaru1 13 hours agoprevHow would this affect you if you are using Github as a OAuth provider? Does Github mention under what conditions they are going to take away someone&#x27;s username? No code? No OAuth? No activity? reply bastardoperator 13 hours agoparentMost corps are looking at GH EMU, which means you bring the username&#x2F;email address, and that a public GH username is not possible. This also prevents the creation of public repositories.https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;enterprise-cloud@latest&#x2F;admin&#x2F;ide...The people they care about don&#x27;t use GitHub oauth, but instead use their own private idp like Okta. reply not_your_vase 14 hours agoprevIf you want your own username, don&#x27;t use someone else computer. Self-host github&#x2F;gitlab&#x2F;gitea&#x2F;whatev, and use your favorite username, without the fear of losing it. reply ZWoz 13 hours agoprevI found amusing that IP address in one screenshot has following field in whois:Address: 1800 Bishops Gate BlvdIsn&#x27;t gate common way to suffix scandals in USA? reply throwboatyface 12 hours agoparentBishops Gate has been a place before Watergate happened. reply ZWoz 12 hours agorootparentSure, Gate is somewhat common way to naming places. Not really related to trouble in article, but nice coincidence, we have Bishops and Gate. reply pbhjpbhj 12 hours agoprevSo you make usernamex, username-x, username-xx accounts and populate the repos ... do they then bump you to username-y? reply tgsovlerkhgsel 14 hours agoprevWow. This has pretty terrifying implications if people are using GitHub to sign into other services. reply forgotpwd16 12 hours agoparentUsername and user ID are distinct. If username was the ID, you couldn&#x27;t even change it yourself. reply tgsovlerkhgsel 8 hours agorootparentThat assumes that all third party sites use the user ID, not the username. From my understanding, the way \"login with Github\" works is by the app getting an OAuth token, then querying a \"give me the currently logged in user\" API using that token, which then returns an object identical to https:&#x2F;&#x2F;api.github.com&#x2F;users&#x2F;rbishopIf the client keys on \"login\" rather than \"id\" (this GitHub tutorial, for example, only mentions the former, not the latter: https:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;apps&#x2F;creating-github-apps&#x2F;writing...) and then stores \"github user rbishop can access account 123456 on our system\", the new owner of the account name would likely be able to hijack the previous owner&#x27;s 3rd party accounts. reply iamthejuan 16 hours agoprevMy user ID in Github is username and they just suddenly name it also to usernamex. reply _jal 15 hours agoparentNot github, but I signed up for a service with the username &#x27;duplicate_user_id&#x27;. It seems someone there didn&#x27;t find that as amusing as I did, locked the account, and refused service.I can only guess they thought it was setup for some sort of scam, but I can&#x27;t imagine what. reply deceptionatd 8 hours agoprevThis seems... deeply idiotic on GitHub&#x27;s part. Consider the following scenario:1. A script&#x2F;CI&#x2F;etc is pulling the latest releases from the repository. 2. Ownership of the account is changed. 3. The new owner controls the contents of the repository, and can perform a supply chain attack.I&#x27;m not sure GitHub would be liable there, but personally I wouldn&#x27;t want to find out the hard way. reply grumple 13 hours agoprev [–] That is troubling. Does this mean Github staff can basically take over any private account without contacting the owners? Can regular staff access private repos? Could they quietly manipulate my own repos by changing my ssh key and pushing commits? Sky&#x27;s the limit in terms of the negative impact that could have. Does SSO with Github depend on the username? Would a renamed account be able to access services where I used \"Sign in with Github\"? reply blep_ 11 hours agoparent [–] (I don&#x27;t work at Github, these are inferences from working on other cloud services)> Does this mean Github staff can basically take over any private account without contacting the owners?That&#x27;s an incredibly common feature to have on the admin side. Three of the four companies I&#x27;ve worked at have had some form of \"log in as this user\" button, with general guidance to not do anything dumb. The fourth had good reasons for not supporting that, but it made debugging anything happening in production incredibly annoying.> Could they quietly manipulate my own repos by changing my ssh key and pushing commits?They _literally own the servers_. They don&#x27;t need your ssh key. Likely not _everyone_ has direct filesystem access, but at least a few people do.By hosting anything on a cloud service, you are trusting the people running that service. If you don&#x27;t trust them, don&#x27;t do that. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author's Github account was renamed without any prior notification or explanation.",
      "An unknown individual uploaded an SSH key to the account, allowing them to modify the author's repositories.",
      "The author expresses frustration at the lack of documentation from Github regarding this account renaming policy."
    ],
    "commentSummary": [
      "GitHub allows users to request username changes for inactive accounts without repositories, but the approval process is inconsistent.",
      "Some users have been successful in changing their usernames, while others have been declined.",
      "GitHub's policy on username changes has evolved, with fewer requests being approved in recent years.",
      "There are concerns about accounts being renamed without notification and potential security risks such as account hijacking.",
      "Users have shared mixed experiences with claiming inactive usernames, highlighting both positive and negative outcomes."
    ],
    "points": 194,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1700666143
  },
  {
    "id": 38378992,
    "title": "Apple's M3 chips: Exploring Changes in CPU Core Configuration",
    "originLink": "https://eclecticlight.co/2023/11/22/what-has-changed-in-cpu-cores-in-m3-chips/",
    "originBody": "hoakley November 22, 2023 Macs, Technology What has changed in CPU cores in M3 chips? If you read the initial reviews of Apple’s new M3-based Macs, you’d be forgiven for thinking little had changed in their CPU cores, apart from a rejigging of numbers and an increase in the maximum frequency of their P cores. As my MacBook Pro 16-inch M3 Pro arrived three days early, this article presents a tentative first look at what has changed in their CPU cores, and from that, how you might choose the right chip for your next Apple silicon Mac. Like Apple, I’m going to make comparison between M1 and M3 chips, as in most respects discussed here, M2 CPU cores didn’t change as much from those in the M1, and I’ve had and tested four different M1 models. Cluster size The most obvious difference between M1/M2 CPU cores and those in M3 chips is in the size of their clusters. In M1 and M2 chips, CPU cores are grouped into clusters of 2 or 4, within which cores share L2 cache and run at the same frequency. In M3 chips (certainly the M3 Pro, and I understand the M3 Max as well) clusters are composed of 4 (M3 basic) or 6 (Pro and Max). This change has impact on chip selection. macOS tries to allocate threads running at higher priorities, as set by their Quality of Service (QoS), to P cores whenever possible. This is what we want, as it ensures that the apps we’re running deliver best performance, albeit at higher power consumption. When the P cores are already fairly fully occupied, macOS may instead run high QoS threads on the E cores. While it has compensatory mechanisms for doing this (see below), it may mean that those threads run more slowly than we’d want. If you already have an Apple silicon Mac and are wondering whether to upgrade to an M3 model, then you can use this as a way of working out which chip you’ll need. Load your current Mac up with the apps you normally use together when working, and watch their use in Activity Monitor’s CPU History window. If its P cores are fully occupied much of the time, and that workload often spills over to the E cores, then you should aim for an M3 with more P cores; if there’s always adequate spare capacity on the Mac’s P cores, then you probably wouldn’t get much added value from an M3 with more P cores. This changed cluster size in M3 chips is significant, as it could not only have effects on performance, but also on power use. When running at full pelt, all six P cores in an M3 Pro cluster can use as much as 5.5 W, while six in an M1 Pro will use about 5.8 W. E cores From my preliminary measurements, E cores in an M3 Pro differ little from those in an M1 Pro, except for their frequency management, which is determined by macOS. M1 E cores have a maximum frequency of 2064 MHz, while those in M3 chips reach 2748 MHz. But, when running low QoS threads in the M1 Pro chip, E core frequency is set to 972 MHz, and that in the M3 Pro is 744 MHz, giving a ratio of 1.3 for M1/M3. Integer, floating point, NEON and Accelerate performance at those frequencies matches the difference in frequency, at 1.3-1.4. That means the M3’s E cores run background threads slightly more slowly than the M1 because macOS sets their frequency lower. That isn’t true, though, when the E cores are being used to run high QoS threads that couldn’t be accommodated on P cores. Those are run at maximum frequency, which favours the M3 Pro by a factor of 1.3. Replacing an M1 Pro with an M3 Pro thus slows background tasks, but accelerates high QoS tasks that have overflowed onto the E cores. P cores There are greater differences between the P cores in an M1 Pro and those in an M3 Pro. M1 P cores have a maximum frequency of 3228 MHz, while M3 P cores run up to a maximum of 4056 MHz, a ratio of 1.26 in favour of the M3. A similar ratio is seen for integer and floating point performance, at 1.30 and 1.28 respectively, but vector performance using NEON or Apple’s Accelerate library is faster still on the M3 Pro P core, at ratios of 1.67 and 1.63. This suggests that improved integer and floating point performance is largely (if not completely) the result of increased core frequency, but that there are likely to be further improvements in vector processing. Perhaps Apple has improved the design of the NEON unit in M3 P cores. P v E Aside from any improvement in vector processing in M3 P cores, M1 and M3 cores show different patterns of performance under load. These are perhaps clearest in the two charts below. Loads were applied using AsmAttic, which here runs tight loops of floating point arithmetic that remains in-core, accessing only registers and not memory. These charts show the time taken to complete one or more threads, each running 200 million loops of assembly code. Each thread is run as if on a single core at 100% active residency, i.e. it’s one core’s worth of performance, so 6 threads will fully load a 6-core P cluster. This chart shows the total time to complete running all the threads, by the number of threads (effectively the number of cores), for an M1 Pro in red, and an M3 Pro in black. These threads were all run at maximum QoS (33), so were run preferentially on P cores. Those run on the 8 P cores in an M1 Pro (red) show a near-perfect linear relationship, with each thread fully occupying one core for a period of 1.3 seconds. The lower black line shows equivalent results for the 6 P and 6 E cores in an M3 Pro. For 1-6 threads, these were all run on its P cores, then on an increasing number of its E cores as well. That is quite linear up to 6 threads, where the time taken is significantly less than that of the M1 Pro. By 6 threads, that difference is over 1 second; in the time the M1 Pro took to run 5 threads, the M3 Pro had almost completed 6. From 6-8 threads, the two lines run in parallel, indicating that the M3 E cores were delivering similar performance to the P cores in the M1 Pro. You wouldn’t want to run more than 8 threads, though, on the 8P + 2E cores of the M1 Pro, as they would risk displacing background threads on the two E cores. On the M3 Pro, you can go safely up to a total of 10 threads, on 6 P and 4 E cores, without compromising background threads. Indeed, because the E cluster is running at maximum frequency, background tasks might even complete more quickly under that load. Differences are reversed when running low QoS threads on the E cores, as shown here, again with the 2 E cores of the M1 Pro in red, and the 6 E cores of the M3 Pro in black. The frequency of the M1 Pro E cores is increased when they’re running a second thread, which accounts for the small change in total time from 1-2 threads. However, with more than 2 threads, further threads are queued, and performance suffers as a result. The 6 E cores of the M3 Pro have three times the capacity for background threads, and although running them more slowly, they cope with up to 6 threads, beyond which those threads are queued, and the time required to complete them rises more rapidly. CPU History The most accessible window you have on core load and performance is CPU History in Activity Monitor. Although it can cast light on the use of different types of core, and help you decide whether your next Mac needs more cores, it’s also seriously misleading, as shown in the screenshot below. This shows what happened during two tests using my app AsmAttic: in the first, responsible for the large blocks of green in the E cores, I ran a load of 6 threads at low QoS; in the second, reflected in the much narrower blocks for the P cores below, I ran the same load of 6 threads on the P cores. When the E cores were fully loaded, their frequency was 744 MHz, that’s only a little above their idle, but when the P cores were fully loaded, they were running at close to their maximum at just under 4000 MHz. This persistent failure in Activity Monitor to take core frequency into account gives seriously misleading impressions. Summary There’s much more to comparing CPU cores than multi-core benchmarks. If you already have an Apple silicon Mac, observe patterns of use of P and E cores during normal use to determine whether you need a Mac with more cores. CPU core cluster size has changed in M3 chips, from 2-4 to 4-6, which is likely to have extensive effects on performance and power use. M3 E cores appear similar to those in the M1, but have a higher maximum frequency, and are run at lower frequency for background tasks. M3 P cores appear to have improved performance in the vector (NEON) unit, and have a higher maximum frequency. Increased E core count increases the capacity to accommodate overflow of high QoS threads from P cores. macOS core management has also changed. I will post further analyses of the M3 Pro chip’s CPU performance as I assess the data. Share this: Twitter Facebook Reddit Pinterest Email Print Like this: Like Loading... Related Posted in Macs, Technology and tagged Apple silicon, cores, CPU, M1, M3, performance. Bookmark the permalink.",
    "commentLink": "https://news.ycombinator.com/item?id=38378992",
    "commentBody": "What has changed in CPU cores in M3 chips?Hacker NewspastloginWhat has changed in CPU cores in M3 chips? (eclecticlight.co) 191 points by zdw 20 hours ago| hidepastfavorite269 comments dd_xplore 11 hours agoIt&#x27;s absolutely mind boggling that such a powerful processor can run at a power envelope less than 10 watts! reply arcticbull 5 hours agoparentWithout taking away from how cool that is, the Threadripper 7980X manages to run at just 3.4W&#x2F;core according to GamersNexus [1]It&#x27;s pretty amazing where everyone (other than Intel) is on the perf&#x2F;W scale.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=yDEUOoWTzGw reply pram 5 hours agorootparentI don’t know but I’m curious: I’d imagine at that many cores you’re probably reaching the limits of how much power the socket can realistically get? I know some motherboards have that supplemental power port. reply Jonnax 44 minutes agorootparentYeah motherboards for threadripler have extra power supply connections.I believe there&#x27;s a the option to connect twohttps:&#x2F;&#x2F;videocardz.com&#x2F;newz&#x2F;amd-threadripper-pro-7995wx-96-c...World record on cinebench with liquid nitrogen pulled 1.6kW reply trvz 10 hours agoparentprevI don&#x27;t believe that&#x27;s true, regardless of what you mean by \"can run at a power envelope\".The M1&#x2F;M2&#x2F;M3 use 20-25 Watt at peak, but only 10% of that when idle. (But that&#x27;s only in the notebooks – it goes beyond that in the Mac mini.)The M3 Pro is basically 50% more of everything than the M3, so I&#x27;d reuse that multiplier to guess its power levels. reply lend000 10 hours agorootparentParent (and the article) are talking about power per core. reply crooked-v 11 hours agoparentprevIf the rumors about LLM stuff baked into Siri on the next iPhone are true, it will be interesting see how they make the most use of the hardware with that. reply smcleod 10 hours agorootparentI&#x27;m really hoping for a complete replacement. Talk about a product that went downhill over time. reply thejazzman 4 hours agorootparentLiterally changes throughout the day from sort of working to insulting me by doing the opposite (\"turn on the kitchen lights\" -> all lights in the house turn off) reply brandall10 10 hours agorootparentprevWhat&#x27;s interesting is the A17 Neural Engine is about twice as powerful as it in on the M3 series - 35 TOPS vs. 18.It&#x27;s rumored the difference is to aid in photography and possibly Face ID, but of course this will be helpful for any onboard inference. reply bernaferrari 9 hours agorootparenteven if that&#x27;s true, the A series neural engine is much worse than the M series, I&#x27;ll say it wrong, but it can only do 32bit inference (or something like that) where M series can do 64bit, so A series can run LLM but has a series of limitations that M series doesn&#x27;t. reply icyfox 9 hours agorootparentPractically speaking, most models today infer at 8bit or 16bit (sometimes, rarely 32). You don&#x27;t see an empirical lift at more bits of precision. Size of the memory is far more important. reply OJFord 9 hours agorootparentIf we&#x27;re talking about the results, is there any reason to think it should make a difference at all? reply yieldcrv 9 hours agorootparentprevI think next year&#x27;s refreshes across the board will have a different architecture so the neural engine has a lot more access to RAM so that models with larger parameters can be used and faster reply Mistletoe 10 hours agorootparentprevGood Lord this may the brain transplant she has needed for so long. reply lostlogin 3 hours agorootparentI thought you were piling on a human and felt a bit outraged.Siri deserves more slander than you delivered. reply hospitalJail 10 hours agoparentprevToo slow to be useful for anything interesting.Too expensive to be useful for any IOT or general computing.I&#x27;m sure its really useful that one time you couldn&#x27;t take a flight to a location and didn&#x27;t have a car so you took a bus and that bus was made in 1990 and didn&#x27;t have 120V outlets retrofitted and you decided to work for 12 hours straight on things that never used GPU. reply AlexandrB 19 hours agoprevI&#x27;m totally flummoxed by the graphs in the \"P v E\" section. Shouldn&#x27;t \"Total Time\" remain constant-ish until the number of threads exceed the number of cores? Why does time increase linearly with the number of threads on a multi-core system? Or is \"Total Time\" here \"CPU Time\" and not wall clock time? reply mr_toad 7 hours agoparentBy “Total time” on the y axis” I assume that the time for all the threads is summed, otherwise the label “Time” would suffice. reply l33t7332273 11 hours agoparentprevThis is definitely the case on other processors. I’ve written a program to detect the number of cores by using that fact. reply renewiltord 10 hours agoparentprevAgreed. I don&#x27;t understand it either. If running two tasks on two cores takes twice as long, then I&#x27;m better off running two tasks one after another on a single core. But if it&#x27;s CPU time is the interesting result that the increased clock on the E-core when task is assigned means that assigning task to E-core doubles throughput so that two tasks spend equal CPU time as one task?That&#x27;s interesting but it wasn&#x27;t clear to me. reply _a_a_a_ 14 hours agoparentprevYeah. It would make sense if he was running them serially and he sort of says that - \"...show a near-perfect linear relationship, with each thread fully occupying one core for a period of 1.3 seconds\". But that&#x27;s not what he says elsewhere - \"...so 6 threads will fully load a 6-core P cluster\". It really doesn&#x27;t come together, does it. reply charlie0 17 hours agoprevJust an observation, I have an M1 Max and M3 Pro. The M3 Pros battery seems to drain much much faster than my M1 when watching YT. Wonder if this P core thing has anything to do with it. reply miyuru 16 hours agoparentM3 has AV1 hardware decoding built in, it should increase battery life in theory. Check the codec used by YT using stats for nerds. reply heavyset_go 12 hours agorootparentThis extension lets you enable&#x2F;disable codecs on YouTube[1]. It&#x27;s also available for Chromium-based browsers, as well.From what I&#x27;ve seen, though, is that M3 machines tend to consume more power than the M1 generation.[1] https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;h264ify&#x2F; reply KeplerBoy 9 hours agorootparentprevIs AV1 more energy efficient than h264?Sure, AV1 is the better, newer codec, but h264 has been around for a long time and is certainly implemented very efficiently in the HW decoder. reply lxgr 11 hours agorootparentprevI believe Youtube just uses VP9 if you don&#x27;t have AV1 hardware decoding. At least that&#x27;s what consistently happens on my Mac using various browsers. reply lights0123 5 hours agorootparentThere is no web standard to list what codecs are hardware accelerated—good for fingerprinting resistance, bad for battery. reply lxgr 4 hours agorootparentBrowsers can just limit the codecs they claim to support to those that the system supports in hardware.I believe that&#x27;s what Safari did for a while with VP8 or VP9 – it was only available while plugged in on my old Mac if I remember correctly. There was a developer option called \"support VP9 even on battery power\" or something similar. reply netol 11 hours agorootparentprevCould AV1 be more costly to decode, even in hardware, compared to VP9? reply KRAKRISMOTT 12 hours agorootparentprevBut no encoding :( reply fh9302 16 hours agoparentprevFrom the independent battery tests I&#x27;ve seen the battery life should be noticeably better. Did you take a look at Activity Monitor to see if something is using high CPU? reply IndySun 16 hours agorootparentCan you link to any one of the tests you&#x27;ve seen? I&#x27;m seeing similar results though for different reasons; and it&#x27;s too early for me to call.>...From the independent battery tests I&#x27;ve seen... reply fh9302 16 hours agorootparentThis test for example shows the longest battery life they have ever measured: https:&#x2F;&#x2F;www.pcmag.com&#x2F;reviews&#x2F;apple-macbook-pro-14-inch-2023...> In our video rundown test, the 14-inch Pro lasted even longer, crossing the 30-hour threshold, becoming the longest-lasting laptop we&#x27;ve ever tested.In this video they compare the M2 Pro and M3 Pro and the M3 Pro has more battery remaining at the end of the video: https:&#x2F;&#x2F;youtu.be&#x2F;aQvsZQ3QBiUSame for this video where they compare M1 Max, M2 Max and M3 Max: https:&#x2F;&#x2F;youtu.be&#x2F;BWeuhxnWDl0 reply charlie0 15 hours agorootparentprevI&#x27;ll re-test. I don&#x27;t use the M3 often, so it could be something else like spotlight running in the background that&#x27;s causing the drain. reply brandall10 10 hours agorootparentFWIW, I&#x27;ve noticed Chrome uses considerably more power than Safari when watching Youtube - about 3 watts - when having one video playing in the foreground. Just to be aware in case you switch between them.I&#x27;m seeing a bit better battery life in general on my 16\" M3 Max than I did on my former 16\" M1 Pro. reply chatmasta 10 hours agoparentprevIs it draining or just not charging to 100% (optimized charging)? reply Synaesthesia 11 hours agoparentprevWhat browser are you using? Safari? reply elAhmo 19 hours agoprev> Load your current Mac up with the apps you normally use together when working, and watch their use in Activity Monitor’s CPU History window. If its P cores are fully occupied much of the time, and that workload often spills over to the E cores, then you should aim for an M3 with more P coresAuthor mentions we can use Activity monitor to see where are apps running, in P or E cores, but I am unable to see this. Can anyone share how to check this? Running the latest Sonoma update reply chatmasta 10 hours agoparentSemi-related fun fact: if you open Activity Monitor with sudo from the command line, you get a lot more metrics and knobs to turn. reply krackers 9 hours agorootparentHow exactly do you do this? When I try sudoit immediately sigkills with a \"launch constraint violation\". And I tried on 10.8 from back before SIP was a thing, and didn&#x27;t see any difference in terms of the per-process metrics I could sort by. reply chatmasta 7 hours agorootparentThis works for me (macOS 13.5): sudo &#x27;&#x2F;System&#x2F;Applications&#x2F;Utilities&#x2F;Activity Monitor.app&#x2F;Contents&#x2F;MacOS&#x2F;Activity Monitor&#x27;But it&#x27;s certainly possible that I&#x27;m forgetting about some protection I had to disable to make it work.According to my notes, the reason I saved this command is because it let me see the list of open files and ports. But I&#x27;m actually not seeing those when running it now... reply krackers 7 hours agorootparentYou can get open files and ports even without sudo for non-root processes by just hitting cmd+i. Maybe running with sudo might allow you to sample or get files for processes owned by root (presumably the info is same as what you&#x27;d get with lsof though). (And by ports it seems to mean network ports. If you want mach ports, you can use lsmp). reply inferiorhuman 5 hours agorootparentprevThat doesn&#x27;t work on MacOS 14. It fails with a code signing violation. You need to use open(1) for app bundles. reply chedabob 44 minutes agorootparentYe, quite a few apps don&#x27;t function correctly if you run the executable directly. sudo open &#x2F;System&#x2F;Applications&#x2F;Utilities&#x2F;Activity\\ Monitor.app reply inferiorhuman 9 hours agorootparentprevLaunch an app bundle with open(1). reply pram 19 hours agoparentprevWindow -> CPU History ⌘3 reply elAhmo 19 hours agorootparentThanks, I was looking at the CPU tab and thought something changed in the CPU Load in the bottom. reply evulhotdog 14 hours agoparentprevYou can double click the cpu graph at the bottom of the process list, which is probably quicker than going through the menu bar. reply krackers 9 hours agoparentprevIf you want to see this per-process instead of in aggregate, xcode instruments cpu counters can show you which core a thread is running on. reply stevage 19 hours agoprev>If you already have an Apple silicon Mac and are wondering whether to upgrade to an M3 modelI see comments like this in various reviews. Are there really people out there who would replace a Macbook Pro M1 or M2 with a M3 just to get something a bit faster? What are they doing that is so performance critical?My last Macbook Pro is a 2014. I still find it usable for development work, and I&#x27;m only replacing it because of other hardware failures. reply rsynnott 19 hours agoparentM2, no, virtually none. The earliest M1s are three years old now, so may be up for replacement under some corporate refresh policies. A lot of corporates still _kind_ of live in the past, hearkening back to a time when a three year old laptop was largely unusable (and might well be _physically_ falling apart; general manufacture quality of this sort of thing has improved a lot in the last 20 years).In the late noughties I worked for a smallish company where engineers got MBPs and everyone else got mid-range PC business laptops (I think Dell or someone?) The failure rate on the PC laptops was just astonishing; they were practically disposable. The failure rate of the MBPs was higher than you&#x27;d see today, though not as bad. Replacing machines in under 3 years was the norm because many of them didn&#x27;t _work_ after 3 years. reply caycep 16 hours agorootparentMy M1 Pro still feels super fast...the corporate thing reminds me of my professor back in college - they&#x27;d upgrade him to the latest&#x2F;greatest Power Mac each year, only for him to boot it up and terminal into his VMS machine and launch min... reply MBCook 10 hours agorootparentprevThat’s a fantastic point, but I can also think of two more.Let’s say you were thinking of an M2 but knew this was coming. The difference between the M3 and M2 may tell you it’s worth getting the newer M3 or the (now cheaper) M2.Or perhaps you saw the M2 wasn’t a big leap. You want to replace your older laptop but didn’t want to get an M2 because it wasn’t a big leap over the M1 in many respects. This info would tell you if it was a big leap (buy now!) or you might as well hold off another year if you can.The other reason is simply making it interesting. If every article was comparing to a 5-6 year old laptop, the answer would almost always be “it’s amazing!” Even if that’s what most people come from it’s a boring story. But year to year variation is much higher. reply deskamess 18 hours agorootparentprev> The earliest M1s are three years old now, so may be up for replacement under some corporate refresh policiesIf anyone knows where I can be downstream of these M1&#x27;s (website, other old stock websites) please let me know. I would like to procure 1 or 2 on the cheap. Esp an M1 Pro. reply wombat-man 17 hours agorootparentI&#x27;ve only used it to get a phone, but backmarket has a lot of old apple machines listed. I&#x27;m real tempted to get a 2013 trashcan mac pro, but I just don&#x27;t know what I would do with it. reply deskamess 16 hours agorootparentThat&#x27;s a good site. Unfortunately, they do not ship to Canada. Will need to look at them later when I visit the US. I have a service that provides a US address but no immediate trips planned. reply wombat-man 16 hours agorootparentWhoever I bought the phone from shipped it real slowly, and backmarket doesn&#x27;t seem to have a lot of control over that. So if you decide to do that, be sure to order a couple weeks ahead of time at least. reply deskamess 15 hours agorootparentThanks. Good to know. Will plan accordingly. reply Threeve303 5 hours agorootparentprevDo a video where you turn it into an actual trash can reply IntelMiner 16 hours agorootparentprevI&#x27;ve been trying to get our IT manager to bend the knee on our own policyWe ship our laptops off to some company who gives us some nominal amount for I assume the scrap value of the machine, then we can donate it to a charityI&#x27;d be happy to \"buy\" an M1 Air with a cracked screen and run it as a headless Asahi Linux box for a hundred bucks or something. But he won&#x27;t budge reply droopyEyelids 16 hours agorootparentThis is hard to change because its a policy that affects finance, legal, infosec, and it.Finance has been depreciating those laptops as capital assets and if youre going to buy one from the company that means its not depreciated, and they need to amend their taxes.Legal and security are concerned about the data and dont know how to prove the encryption really worked and the keys are gone, but the recycling company has insurance and certifications “proving” they dispose of things properly. reply repiret 15 hours agorootparentYou don’t need to amend your taxes to sell a fully depreciated asset. reply sroussey 12 hours agorootparentSometime you can accelerate depreciation, so you would have to amend in that case. reply alexjplant 12 hours agorootparentprevLast I checked loaded M1 Airs were going for $600 on FleaBay.I was all set to upgrade to an M3 Pro until I saw the weird SKU binning for the higher memory models and remembered that my M1 Air still does everything that I need it to do and more. I originally bought it strictly for music production but have since used it more generally as I have to use Apple machines for work... I&#x27;ll probably end up keeping it for another two years and swinging back to a nice Thinkpad with Mint or similar as my dev machine as there are insane deals on 7840-based Lenovos right now. reply drdebug 16 hours agorootparentprevI believe SSDs are soldered onto the motherboard for M1 laptops + M1 mac mini, I wonder how bad of an issue it is when considering used M1s. reply rsynnott 11 hours agorootparentCan’t imagine it’s a big issue; the SSD on my 7.5 year old Skylake MBP is cheerfully claiming 96% lifetime remaining, and seems to be fine. The days of SSDs self-destructing after a couple of years seems to be largely behind us, at least for consumer applications; even low-end stuff has a decent practical lifetime these days. reply astrange 10 hours agorootparentprevVery much depends how it was used. You might be able to tell with the SMART report. reply Detrytus 19 hours agorootparentprevThree years is also when AppleCare expires. That’s enough for some people&#x2F;corporations to upgrade reply nagisa 12 hours agorootparentTwo to three years is also when laptops become a 0 value asset in the books in at least some jurisdictions (not sure about the US tho.) At which point it makes a ton of sense to get rid of it (e.g. sell or give it away to the employee.) reply astrange 10 hours agorootparentprevIt may also be tax depreciation related.2016-era MBPs failed in about three years though because the keys would fall off the keyboard or stop responding. reply abakker 19 hours agorootparentprevmy 3 year old corporate HP feels like its been at end of life since the windows 11 upgrade. The 2 year old M1Max MBP feels indestructible and still has hilariously long battery life and crushes basically everything I ask of it. reply OnlyMortal 16 hours agorootparentI might mention that many at HP use Macs at home. reply walteweiss 2 hours agorootparentAnd seems like they don’t plan to make the HP experience similar to Macs. reply dylan604 12 hours agorootparentprevDon&#x27;t forget that corps also have financial reasons for constant upgrades. Buying new hardware is a great way to reduce taxable profits. There&#x27;s also the amortization on write offs, and other accounting words I&#x27;ve heard people say but don&#x27;t pretend to fully grok.Also, decent way to lessen the beatings to improve moral since who doesn&#x27;t like getting new hardware? reply alwillis 9 hours agorootparent> Also, decent way to lessen the beatings to improve moral since who doesn&#x27;t like getting new hardware?In many organizations, budgets are ‘use it or loose it.’ The money has to be spent otherwise you may not be able to ask for the same amount or an increase.I recall getting a new laptop because it was close to the end of the fiscal year and there was a chunk of money that needed to be spent. It wasn’t that my current machine wasn’t useable but it was old enough to qualify me for a new laptop.There was always someone with something older I could pass my ‘old’ machine too. reply treve 10 hours agorootparentprevThis reminds me of seinfeld scene: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=XEL65gywwHQAnyway, for the bottom line of your company I think it rarely makes sense to frivolously spend more just to decrease your tax burden. There&#x27;s smarter ways to spend money. reply walteweiss 2 hours agorootparentprev>Buying new hardware is a great way to reduce taxable profits.Can anyone explain this to me? reply JCharante 19 hours agorootparentprev> The earliest M1s are three years old now, so may be up for replacement under some corporate refresh policies.Yup. It&#x27;s hmm should I upgrade now or wait next year for a juicy M4 model? (some corporate refresh policies let you buy your old work computer at a heavily reduced price, giving you an incentive to get a good work computer) reply kristianp 11 hours agorootparentMacrumors says buy now, based on the expected wait time for an update from Apple. But we already know it would be at least a year until the M4 would be released.https:&#x2F;&#x2F;buyersguide.macrumors.com&#x2F;#MacBook_Pro_16 reply theyeenzbeanz 17 hours agorootparentprevMy current jobsite still uses vista era laptops with 4GB of memory, a battery that dies within minutes if not plugged in, and a painfully slow spindle drive. A 3 year old computer would be a luxury here. reply cebert 8 hours agorootparent> My current jobsite still uses vista era laptops with 4GB of memory, a battery that dies within minutes if not plugged in, and a painfully slow spindle drive. A 3 year old computer would be a luxury here.That sounds bad enough that I wouldn’t want to work for such a firm. reply brailsafe 7 hours agorootparentprevAre you you in a computer-centric discipline or a construction site? reply Swizec 18 hours agorootparentprev> A lot of corporates still _kind_ of live in the past, hearkening back to a time when a three year old laptop was largely unusableWith the amount of nannyware and spyware these corporations load up on your laptop it actually does feel pretty unusable. The difference in performance between my personal 4 year old laptop and my corporate 3 year old laptop is ridiculous.The corporate laptop has so many antiviruses and stuff running all the time that it feels like a 2000’s era windows machine that’s been exposed to the internet for too long. reply cebert 8 hours agorootparentMy work makes us Delinea (Thycotic) PAM which is single process and blocks all OS calls to check if you have privilege to run&#x2F;execute a command. Additionally, we have to run CrowdStirke, Netspoke, Windows Defender, and some type of “inventory scanner” app. My work laptop is much more powerful than any of my personal personal computers on paper, but the nannyware slows everything to a halt (64 GB RAM, 12 cores).It’s very painful to not have local admin rights on a Windows machine if you’re a developer. We can’t even install Docker or make changes to it without “help” from our non-developer IT staff. reply Retr0id 19 hours agoparentprevThe M1&#x2F;M2&#x2F;M3 base models all have only 8GB of RAM. Someone who cheaped out on a first-gen model to test the waters (even if they didn&#x27;t necessarily go for 8GB) might now be looking to upgrade, and if they&#x27;re buying used then all three CPU generations are worth considering. reply jghn 19 hours agorootparentI have an 8GB M1 Air for the sole reason that I was so excited I decided to go with the model I could get on release day instead of waiting a month. Not the wisest decision.I figured I&#x27;d replace it at M2, and then at M3. But to be honest even with the 8GB it&#x27;s fine enough still. I don&#x27;t use it for much heavy lifting but it works ok-ish for that in a pinch. And for day to day personal use it&#x27;s fine. So every year I go through the cycle where I *want* to replace it and then convince myself I don&#x27;t really need it. I already have a monster machine for my work stuff, having extra horsepower for my personal machine would be nice but ....I&#x27;m sure M4 is the generation I&#x27;ll upgrade. Just wait :) reply adestefan 17 hours agorootparentI recently bought my wife a new Air and the only reason why I went with the M2 version was the nicer screen. Otherwise the M1&#x2F;8GB would be more than fine for what she needs. reply jonpurdy 16 hours agorootparentprevI replaced a 16GB Intel MacBook Pro with an 8GB refurb M1 Air and regretted it within weeks. (Due to the initial claims about M1 using less memory and that the M1 destroyed my Intel&#x27;s Javascript performance.)Turns out that my 8GB machine would slow down significantly when hitting the RAM limit. This was expecially noticeable when running Final Cut Pro (almost unusable) or Photo Mechanic + Photoshop (I&#x27;d have to quit one to run the other). I tolerated this situation until the M2 Airs came out and I maxed it to 24GB RAM, and have been beyond happy with it since then!My partner now has my 8GB M1 and it works perfectly for her. reply a_vanderbilt 17 hours agorootparentprevThis is what happened in my case. I had an 8GB Air and while the CPU performance was incredible, it lacked the RAM to fully take advantage of it. I upgraded to a 16GB M2 Mac Mini. I consider it to be the perfect UNIX machine for my use case. If I need to access it on the go I remote in from a cheapo laptop. reply kzrdude 18 hours agorootparentprevUsed market is full of those 8 GB models reply paulmd 10 hours agorootparentapple always sells the base-tier model the most, by a pretty significant margin. especially in MBA or mac mini. all the big-box stores like bestbuy and costco carry that model, and it usually sees further sales. So it&#x27;s hard to say that it&#x27;s specifically people being upset about ram vs just the expected distribution given the bayesian prior.but yea 8gb is barely acceptable except as a pure consumption laptop. TBH even 16&#x2F;256 is too small for anyone who&#x27;s posting here, some npm&#x2F;rubygems&#x2F;pipenv&#x2F;gradle&#x2F;docker packages will eat that right up. reply goosedragons 19 hours agorootparentprevApple also still sells everything but the M1 Pro&#x2F;Max&#x2F;Ultra brand new in various devices too. reply JanSt 19 hours agorootparentprevThis is me reply n8cpdx 18 hours agoparentprevPeople here are jumping through hoops to justify these purchases. I don’t get it.It is completely OK to want to have nice things in your life. It is OK to invest in yourself. It is OK to place a high value (2021 vs 2023 Mac) or any value (2014 Mac vs 2023 Mac) on your time.Maybe the shocked reactions are a result of currency conversions, but when you factor in trade in value, the M1 to M3 upgrade isn’t much more expensive than an iPhone.Over the course of two years, the Mac is no more expensive than a gym membership (actually quite a lot less depending on the gym) and probably gets a lot more use.But there I go justifying again. If personal computing is your hobby or your passion, you should spend your hard-earned money on what you want. reply smolder 17 hours agorootparentIt&#x27;s not about about having \"nice things\" or affordability for me. I try to minimize upgrades mainly out of concern for e-waste and other externalities of manufacture, and because setting up the environment on new hardware is a time sink. Picking appropriate hardware for a use case is also part of that. I won&#x27;t buy a threadripper workstation to game & watch YouTube on, for instance. It&#x27;s okay to be passionate about responsible spending, too. reply toast0 15 hours agorootparent> and because setting up the environment on new hardware is a time sinkIf you replace your laptop, don&#x27;t you just restore a backup and you&#x27;re ready to go?Wipe the old machine and sell it and you&#x27;re net the same amount of ewaste. reply smolder 11 hours agorootparentEssentially, yes, I&#x27;d transfer the account or restore from backup, but depending on the hardware change there may be other yak shaving to do.I don&#x27;t believe putting a used laptop on the market is necessarily cutting down e-waste in the same way as not purchasing one, though you make a good point. reply johnthescott 5 hours agorootparentprevimacs are mighty-fine unix workstations, ergonomically speaking. no other brand comes even close, in my opinion, although ubuntu is getting close. throw in ports&#x2F;homebrew and all the gnu&#x2F;linux tools i need for servers are at my fingertips. virtual machines scoop up the scraps. reply smcl 19 hours agoparentprevI know the whole \"carbon footprint\" thing was designed to allow big companies and governments to pretend that 7 billion people need to individually decide to change their lifestyles, to fully understand the environmental implications of the various consumer choices they make and assumes that environmentally-friendly options are already available in all cases ...But the carbon footprint of some people I see here must be astronomical. reply eric__cartman 18 hours agorootparentI at least hope they sell&#x2F;give away those machines to keep them in circulation. I&#x27;d be a real shame to have modern and environmentally expensive hardware like that be torn apart for scrap metal in a recycling facility. Many tech companies love the \"eco-friendly\" trade in programs that essentially serve to take working, used devices out of circulation. reply 2143 16 hours agorootparentprevFor my personal machine I have a relatively new ThinkPad running linux that works perfectly well for everything that I do.Ever since it came out I want to buy a MacBook with these new chips as my personal machine. But I haven&#x27;t yet bought one because I don&#x27;t need one.Or I&#x27;ll buy it when my ThinkPad dies. (Weird laughter).And then over here I read about people replacing laptops every other year or so, and I wonder why I am the way I am. reply astrange 10 hours agorootparentprevIt&#x27;s mostly governments that need to change because they control land use policy. This is up to individual decisions of those 7 billion people though, because that&#x27;s how voting works. reply renewiltord 10 hours agorootparentprevAn environmentalist friend told me that my use of Terrapass is pointless and that there&#x27;s no point attempting to reduce my footprint because big companies are the cause of it. So I stopped worrying about both things. This is fortunate because I&#x27;ve increased the amount of flying I do these days. Usually, environmentalists get in the way of things, so I was quite pleased that here was this positive development. reply Eric_WVGG 18 hours agoparentprevI picked up a 16gb M1 Pro about as soon as they came out. It was unbelievable for the first year, basic React web stack work.Now I&#x27;m working on a project that requires about six Docker images, and we made a questionable choice about Typescript packages for typing our API responses. The Docker consumes most of my RAM, and even when it&#x27;s turned off, there&#x27;s a visible different in the IDE between mine and my M2 equipped coworkers whenever a document that uses this dumb lib is opened.So anyway I&#x27;m picking up an M3 Max next week. reply smolder 17 hours agorootparentAn alternative to leaning on your laptop that way is to use a 2nd headless system to do builds, run tests, host containers, etc. It can be more economical over time and better DX to use this [semi-] dumb terminal approach, depending on specifics of your workflow. reply steve1977 17 hours agorootparentprevWhen you need a high end laptop for web development, what a sad state of affairs... reply mikece 16 hours agorootparentBecause, JavaScript. reply jocaal 12 hours agorootparentNo, in this case it is docker. Last I remembered, docker on macs run in a VM reply wkat4242 9 hours agorootparentprevIf you need docker, just get a Linux laptop, it really works way better. reply rowanG077 7 hours agorootparentprev6 docker instances... I didn&#x27;t click on this thread to be offended. reply grecy 18 hours agorootparentprevSelling the M1? My email is in my bio. Thanks reply nordsieck 19 hours agoparentprev> Are there really people out there who would replace a Macbook Pro M1 or M2 with a M3 just to get something a bit faster?Are there really people who buy a new car every 2 years?Yes. Yes there are.Some people like to have the newest stuff and don&#x27;t mind living paycheck to paycheck to do so. Or maybe they&#x27;re rich. reply troupe 19 hours agorootparentThere are some people who just waste their money, but there are also a wide difference in the value people get from their cars and computers. Someone billing $500 per hour is going to be a lot more willing to upgrade their computer for even a small improvement. They may even keep a spare computer just to make sure they have minimum downtime if something goes wrong. Someone who just uses their computer to watch youtube videos may be fine keeping their computer until it stops working. reply scarface_74 18 hours agorootparentWhen I got Amazoned a couple of months ago and didn’t have a personal computer at all, a side contract fell into my lap where I billed $150&#x2F;hour. (Don’t cry for me. I found a full time job 3 weeks later).I recouped the cost of the M2 MacBook Air 24GB RAM&#x2F;1TB in less than 15 hours worth of work - taking my after tax rate into account.My work was not compute intensive so the Air was fine. But I would definitely pay for a 30% improvement at that bill rate. reply jodrellblank 10 hours agorootparentExcuse me, but why? If your work takes longer on a slower computer, you can bill more. But if you can complete two projects in the same time on a faster computer, you work harder but can&#x27;t bill more. This only seems to work if you bill $150&#x2F;project but if you bill hourly it doesn&#x27;t work out. Yet you and the parent comment have said this, what am I missing? reply troupe 8 hours agorootparentIf you are billing at $150 per hour, people are probably counting on you to not be someone who would think, \"If I keep a slower computer, I could bill for more because the client would pay for the time I spend waiting for my computer.\"Imagine you go to see a lawyer who is charging you $750 per hour, but instead of using a computer, they are writing everything out by hand and then personally using a typewriter to type up their notes. You ask why they don&#x27;t use a computer and they point out that they can make more money by billing you for the time it takes to use slower technologies.Might you consider a different lawyer? reply nordsieck 19 hours agorootparentprevThat&#x27;s totally fair as well.However.I expect that the majority of people who upgrade their computer regularly can&#x27;t justify it as a business expense. But I could be wrong. reply petercooper 18 hours agorootparentprevOr maybe they work with computers in a business full time and the price of a new computer is minor compared to the income it&#x27;s used to produce, especially if it&#x27;s tax deductible, such that it&#x27;s a valid business decision if the improvements are barely more than marginal. reply cglace 18 hours agorootparentprevYou need to be rich to afford a new computer every 3 years? reply brucethemoose2 18 hours agorootparentAt Apple&#x27;s prices, yeah.I sit on desktops for 5 years+ with modest opportunistic upgrades, and I consider that extravagant.I think people forget that $4k+ for a computer is Quadro workstation territory. reply cglace 18 hours agorootparentI guess if you are paying 4k+ for your computer it makes sense to push out your next purchase. I&#x27;m usually paying ~2k. reply brucethemoose2 16 hours agorootparentIDK. My 3090&#x2F;7800X3D desktop, assembled new, was ~$2K. That&#x27;s a very premium computer.And that&#x27;s with the general Nvidia price gouging these days, and paying a premium for ITX as well.$2K is very expensive for a PC. reply Art9681 15 hours agorootparentprev$4k is a little or a lot depending on your circumstance. Assume three individuals that make the same income.- One of them supports a family of 3 on one income. - One of them is single and supports only themselves. - One of them is married with dual-income and no kids.This has nothing to do with wealth. reply 2OEH8eoCRo0 15 hours agorootparentThere are also those who can afford it but don&#x27;t see the value add. There better be some serious value add for me to spend $4k IMO. Others are a bit loose with their money which is their prerogative.I really only upgrade if my current PC cannot do a thing that I need it to do. reply xcv123 10 hours agorootparentprev> I think people forget that $4k+ for a computer is Quadro workstation territory.M3 MacBook Pro 16\" is $2499, roughly the same as an equivalent Dell XPS &#x2F; Precision laptop (for the same price Dell typically has half the screen resolution, much worse battery life, and more RAM)Divide $2499 over five years, that&#x27;s $500 per year. Not expensive on a developer salary in high income countries. It&#x27;s a business expense. reply brucethemoose2 6 hours agorootparentThat&#x27;s... not really a great comparison. New Asus G14s&#x2F;G15s are more similar to MBPs and much more competitively priced. reply xcv123 6 hours agorootparentNo. That&#x27;s cheap plastic gamer junk. Those are toys. Different market segment. Not comparable. MacBook Pro competes with high end professional laptops, not consumer gaming laptops. Dell Precision with 4k screen is what you would compare it to. reply brucethemoose2 5 hours agorootparentYeah, I dunno about that either. I have a 2020 G14, and its a fantastic piece of hardware. Honestly its overbuilt, except for the display (which I understand they have improved in more recent models). reply xcv123 4 hours agorootparentYou&#x27;re right, it&#x27;s good value for what it is, not a piece of junk. But it doesn&#x27;t compete in the same segment. replyfulafel 16 hours agorootparentprevMedian household income globally is about $10k, it&#x27;s about 2 months household income worth. reply nocoiner 19 hours agoparentprevI did something fairly out of character for myself and replaced a six-month-old M2 MBP with a brand new MBP with an M3 Max. I attribute it to three factors:1. I went with 16 GB of RAM on the M2 and sort of regretted it from day one. I have 36 GB on the M3 and feel much more comfortable about that in a machine I plan to use for the next 5-7 years.2. Apple gave me what I thought was a very generous trade-in offer on the M2 - something like 90% of what I paid for it, even after half a year’s use. At that value, it basically felt like a wash going from the old computer to a new one, and I was just paying for the substantial upgrade on the old machine (Max-level processor, bigger SSD, quite a bit more memory).3. I thought the darker color looked neat. That said, it’s much subtler than I imagined, and I wouldn’t have considered this as a factor.Of course, the truly hilarious thing is that I don’t do anything at all intensive on my computer so I’d be just fine with just about anything. But what can I say, I like to know I could if I wanted to. reply binkHN 18 hours agorootparent> 1. I went with 16 GB of RAM on the M2 and sort of regretted it from day one. I have 36 GB on the M3 and feel much more comfortable about that in a machine I plan to use for the next 5-7 years.Very fair; part of the reason I went with 64GB on my ThinkPad, and Apple makes this configuration almost cost prohibitive. reply jmnicolas 18 hours agorootparentIt&#x27;s not *almost* cost prohibitive, here (in France) a max spec Apple laptop cost about 8500€. Ridiculous. reply gwervc 17 hours agorootparentApple prices in France are insane, partially because of how Apple adapt the dollar to euros, and the 20% VAT. Heck, at the time I got my 16Gb 14\" M1 Pro plus an iPhone 11 mini for 50€ cheaper in Japan than just the laptop in France, in part thanks to a generous \"back to school\" offer. reply robotresearcher 18 hours agorootparentprevThat&#x27;s a lot of money for a laptop. But its roughly the same as single intercontinental business class flight.Computers are very, very cheap. reply nicoburns 17 hours agorootparent> But its roughly the same as single intercontinental business class flight.And most people (even in first world countries) never go on a single one of those in their lives. Even most businesses never purchase one. reply mahkeiro 18 hours agorootparentprev8500€ for a business class flight? Maybe first class. reply olliej 9 hours agorootparentSFONZ business class is easily $US10k+ which should put it above 8500euro reply baal80spam 12 hours agorootparentprevI can&#x27;t think of ANY airplane ticket that costs 5000 EUR, not to mention 8500. reply switch007 11 hours agorootparentOh very easy to find. London to San Francisco, AA, business class, this Monday returning Thursday, 9700 EUR. Not even a flexible ticketGoogle Flights says that’s a typical priceDirect with BA is €14kThough neither of course a price a business would usually pay, due to contracts for special pricing and booking a bit more in advance reply olliej 9 hours agorootparentprevLong range business class tickets are easily that, if not more. reply Detrytus 12 hours agorootparentprevWhat do you mean by max spec? In my country the 16inch, M3 Max, 128GB RAM, 8TB SSD is 9666 EUR[1] - France seems a lot cheaper.[1] My country does not use EUR, i calculated it based on the current exchange rate. reply Erratic6576 5 hours agorootparentprevI was hoping SSDs would be fast and durable enough these days to make ram redundant but here we are, back to the past in terms of price per kb reply browningstreet 19 hours agoparentprevIt’s contextualizatipn positioning. And a few.Marques Brownlee has been rocking an M1 Pro laptop and ordered an M3. Which he cancelled after he got his review unit. He’s got enough money to not think hard about it but he cancelled anyway. Which stands as an interesting data point. reply crazygringo 16 hours agoparentprev> What are they doing that is so performance critical?Anything related to multimedia processing.Whether it&#x27;s video encoding or live audio processing or rendering or whatever.M1 might be more than fast enough for emails and web development, but multimedia is a whole different beast.People forget that the \"Pro\" refers to media professionals, not development professionals. Remember the Touch Bar? It was designed for artists and editors for things like color selection and scrubbing and sound control, not for programmers. reply tjoff 16 hours agorootparentAnd why on earth would you do that on a laptop to start with?I&#x27;m sure apple not having decent desktops for a decade leaves a mark. I guess I&#x27;m surprised people put up with it. reply Art9681 16 hours agorootparentBecause the laptop can also be a desktop when hooked up to a big screen and accessories. But a desktop wont ever be a laptop. reply tjoff 3 hours agorootparentI&#x27;m not saying to ditch the laptop, just do the processing on a machine made for it.And of course use the desktop as your main device when you are at your home&#x2F;office wherever the desktop is. reply crazygringo 16 hours agorootparentprevFor the same reason literally everybody else uses laptops -- so you can take your work on the go.You don&#x27;t think sound producers visit different studios each week?You don&#x27;t think video editors have to get work done while they travel?You don&#x27;t think multimedia professionals work both at the office and home like the rest of us?Why wouldn&#x27;t you do it on a laptop if you can? reply matwood 11 hours agorootparent> You don&#x27;t think video editors have to get work done while they travel?MKBHD used to ship an iMac Pro around before Apple Silicon. :) reply Erratic6576 5 hours agorootparentI have been moving twice a year (June-September) with an iMac for the last six years and I think it’s been an overcomplication mistake, specially in March 2020.I thought desktops are more future proof reply tjoff 15 hours agorootparentprevWork on a laptop if you must. But don&#x27;t encode&#x2F;render etc. on a laptop. reply PeterisP 8 hours agorootparentWhy would someone need to buy an additional powerful computer if they can do it on directly on their laptop, which needs to be powerful anyway? reply crazygringo 15 hours agorootparentprevI use my laptop for encoding video all the time.What&#x27;s your justification for saying I shouldn&#x27;t, precisely?What&#x27;s next -- I shouldn&#x27;t use it to compile software either? reply tjoff 15 hours agorootparentIf you are buying a new laptop every generation just for it to be bearable just buy a proper machine that can encode it for you.Bonus points for being able to do it while your laptop is in your bag. reply callalex 5 hours agorootparentIn the United States, internet connectivity is insufficient for uncompressed video footage. reply tjoff 3 hours agorootparentDoes people really process uncompressed videos on their laptops? reply kbf 10 hours agorootparentprevWell you might work on projects where the extra performance makes working in the viewport faster. It’s not hard to find graphics workflows where extra resources aren’t useful. reply Retr0id 16 hours agorootparentprevWhy wouldn&#x27;t you want do to that on a laptop? Especially one with a bunch of hardware accelerated codec support and very decent HDR display. reply firecall 19 hours agoparentprevXcode and SwiftUI is one answer.I’m tempted to upgrade my M1 Pro to an M3 Max.Reports suggest id halve my build times and then some. reply bhouston 19 hours agorootparentGeekbench for an M1 Pro multi-core is 11643, while the M3 Max (16 core) has a pref of: 21387. That would be a major upgrade so yeah, it is probably worth it of you can afford it.All stats from here: https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1i5dBe_rsiNaQATH-D-Pj... reply kristianp 11 hours agorootparent> Single Core Prefshould be single core Perf, short for \"performance\"? reply nivertech 19 hours agorootparentprevHow much RAM do you need for fast Xcode + Swift UI development? reply cvwright 11 hours agorootparentSince the release of Xcode 15 it feels like the answer is, \"More than 16 GB\". reply c0pium 16 hours agorootparentprevNobody knows. reply culi 19 hours agorootparentprev... how long are your build times? If your build times are high enough to really affect your productivity, I feel like there are much cheaper (and environmentally friendly) ways to halve them reply firecall 10 hours agorootparentI&#x27;d be happy to hear them :-)Ditching SwiftUI and going back to Obj-C would absolutely slash my build times ;-) But who wants to do that!The productivity gain is all about instant feedback and developer flow.It might be hard to justify on paper to an IT Manager in charge of budgets when you add up the minutes.But as I work for myself, it&#x27;s easier.As for environmental concerns, well, two year used Macbooks don&#x27;t go in the trash. Used Macbooks have very long lives in my experience! reply smabie 18 hours agorootparentprevWhat&#x27;s the point of posting this and providing zero examples of how? reply culi 15 hours agorootparentHow could I possibly provide any advice. Of course build times are gonna be very specific to each project. I could tell you \"just rewrite it in rust\" but that obviously wouldn&#x27;t be helpful reply willsmith72 19 hours agorootparentprevlike what? genuinely curious. building native apps is notoriously painful reply bitzun 19 hours agorootparentprev(Not an ios developer, have worked with ios teams) Swift build times are notoriously awful. I don&#x27;t know if most developers have much influence over that. reply machinekob 18 hours agorootparentThey are okish a lot slower than c but still reasonable if you dont use tons of generics&#x2F;macros and other heavy stuff.Still it could be a lot better. reply saagarjha 18 hours agorootparentprevMost places are unable to beat silicon advances to improve their build times. reply antigirl 19 hours agoparentprevNot everyones a developer. M1 vs M3 performance boost for video editing seems like a decent upgrade. I&#x27;m still on M1 and I spent £4k+ on specced up MBP 14 inch. Its not struggling but it doesn&#x27;t perform well when editing 4k with one layer of effects in DaVinci. reply mikece 16 hours agorootparentI was wondering about the improvement for photo and video editing, but that would be more of a function of the GPU than the CPU, wouldn&#x27;t it? I certainly need more than 8GB of RAM for photo editing... memory pressure slows down Photoshop and Lightroom. reply antigirl 1 hour agorootparentI have 64GB of ram, doesnt seem like its enough for Lightroom either. I think M3 has more GPU cores btw. reply petercooper 18 hours agoparentprevDifferent strokes for different folks, but I have a higher bar than \"usable\" for tools that my income relies upon. A moderate improvement in experience (whether performance, screen, storage speed, or merely that a key on the keyboard no longer \"feels weird\") warrants frequent upgrades of my main machine, yes. reply lm411 16 hours agoparentprevI used to upgrade my MacBook every year.I&#x27;m not sure if this is still true, but I found the resale value great enough that it was almost the same cost over time to upgrade annually vs every 3-4 years. Of course if you&#x27;re only upgrading every 9-10 years, the math changes significantly.That said, due to changing priorities and needs, my current MBP is from 2018. I am planning to upgrade to an M3 MBP this week.While my current MBP does what I need, some development processes & platforms I use nowadays are taking more time than I&#x27;d like. If it saves me 15 minutes a day, it&#x27;s a great deal. reply pg5 19 hours agoparentprevI make music mostly for fun and my m1 is barely keeping up with Logic Pro and the plugins I&#x27;m running, which are amp sims, various typical mixing plugins, and virtual drums. I&#x27;m not even using a crazy number of tracks at any given moment. reply TheCleric 17 hours agorootparentMy rule for Logic Pro is that it will expand to make any computer you run it on \"just barely keep up\". reply gessha 17 hours agorootparentprevDid you have an Intel Mac before? If so, did you have the same workflow with the same amount of plugins or did you expand your usage based on the laptop capabilities? Just curious about “workflow creep” because I’m wondering if I should get an M[1..9]. reply mnw21cam 19 hours agorootparentprevGiven that a 7MHz Amiga 500 could mix eight tracks in CPU in real time, this is a very sad state of affairs. Your M1 is how many thousand times faster? reply redwall_hp 19 hours agorootparentVSTs didn&#x27;t even exist when Amgias were relevant. Each of those tracks was not running a virtual synthesizer, convolutional reverb, parametric EQ, compressor, amp sim, etc.. A modern DAW is simulating an entire studio worth of hardware, not just an eight channel mixer. One of these laptops can mix hundreds of tracks without issue; it&#x27;s the plugins that require more power. reply troupe 19 hours agorootparentprevAre you sure that what the Amiga was doing with 8 tracks is equivalent to what Logic is doing? I&#x27;d guess there is more to compare than just the number of tracks involved. reply uticus 19 hours agorootparentYes but I think there&#x27;s a point: hardware horsepower is undoubtedly capable of handling such workloads. I&#x27;m not knocking on Logic, but for &#x27;fun&#x27; projects especially I find it impossible to believe that the hardware listed is the problem. reply pg5 19 hours agorootparentprevThere&#x27;s a chance it&#x27;s a logic bug or one plugin having some issues, I suppose reply smolder 16 hours agorootparentAll plugins are certainly not made equal. Some I&#x27;ve used are surprisingly bad performance-wise for what they do, while others are just genuinely computation-heavy. reply jermaustin1 15 hours agoparentprevI just upgraded my top-spec Intel MBA from 2020 to an M3 Pro MBP.Adjusted for inflation, the M3 was about 20% more expensive for close to infinitely more performance.I could see holding on to this M3 Pro as my daily driver for 5-10 years assuming I don&#x27;t drop it too many times.I&#x27;ll probably replace my wife&#x27;s MBA from 2018 next month for whatever the bottom spec MBA is now. reply Amorymeltzer 19 hours agoparentprevDepends on your workload and what you&#x27;re doing. This is an extreme example, but Marco Arment over on ATP discussed going from a top-o-the-line M1 to top-o-the-line M3, and saw his Xcode build time for his app (Overcast) get nearly cut in half (I believe he said 19 seconds to 11 seconds). For something that happens several times a day and is a critical and interruptive step in his workflow, yeah, he found it meaningful. reply selimnairb 16 hours agoparentprevI went from an M1 Pro with 32GB of RAM to an M3 Max with 64GB. I had been regretting not getting 64GB of RAM. I plan to keep this machine at least five years, so I traded in while the trade-in value was still relatively high. I find the M3 Max to be dramatically faster. I do a lot of Python development (mostly numerical code, some micro services) and increasingly complex k8s setups. Some of my containers are still AMD64, and while these ran acceptably fast on the M1 Pro, they are MUCH faster on the M3 Max. For example, solving conda environments on a fairly complex container takes about 1&#x2F;2 the time it seems (about as fast as my work 12th gen i9 Linux laptop). I am very impressed with the jump between the M3 Max and the M1 Pro, and I haven’t even touched the GPU yet. reply baz00 19 hours agoparentprevI was going to change my M1 for an M3 because I like the black one :) reply JCharante 18 hours agorootparentmkbhd&#x27;s review is that the m3 isn&#x27;t black enough to be considered black. reply baz00 18 hours agorootparentIt&#x27;s black enough for me! reply Detrytus 11 hours agorootparentThat&#x27;s for your local BLM chapter to decide, not you!Also, isn&#x27;t using a black laptop by non-black person an act of cultural appropriation?Apple should at least test your familiarity with Critical Race Theory before selling you one. &#x2F;s reply have_faith 19 hours agorootparentprevChaotic Neutral reply bhouston 19 hours agoparentprevI upgraded from a MacMini M1 (Geekbench multicore pref: 8425) to an MacMini M2 Pro with 12 cores (Geekbench multicore pref: 14431.) That was definitely worth it.The only upgrade for the M3 line I would make would be to an M3 Max 16 core (Geekbench multicore pref: 21387) or an upcoming M3 Ultra 32 core (probably a Geekbench multicore pref: ~30000), but it is very expensive and probably not available in the MacMini form factor, so I will hold off for now.All stats from here: https:&#x2F;&#x2F;docs.google.com&#x2F;spreadsheets&#x2F;d&#x2F;1i5dBe_rsiNaQATH-D-Pj... reply kbf 10 hours agoparentprevYou can configure the M3 models with twice as much RAM (128GB) as the M1 models, that’s quite an upgrade if your workflow is memory intensive. It’s especially compelling for graphics work as that memory is also used as VRAM. A desktop RTX 6000 gets you 48GB of VRAM for $6800. reply flohofwoe 18 hours agoparentprevUnfortunately some very useful Metal profiling&#x2F;debugging tools [1] are only available on the latest hardware. Funny enough this was always the main reason for me to update, not performance (e.g. not being able to debug Metal shaders on my old Intel Mac was one important reason to finally upgrade to an M1 Mac).Otherwise I&#x27;m still entirely happy with my 2021 minspec M1 MBP.[1] https:&#x2F;&#x2F;developer.apple.com&#x2F;videos&#x2F;play&#x2F;tech-talks&#x2F;111374 reply pier25 5 hours agoparentprevDepends. Someone might want to go from base M1 to M3 Pro for example.That said I have an M2 Pro MBP and this thing is a monster. reply KolenCh 15 hours agoparentprevReading your comment, my first reaction is “are there really people or there who upgrade not because they want their computer faster?”Joke aside, for people who read reviews, I don’t think they read it because their computer is dying. So I think it is fitting from the selection bias there to focus on performance improvement. (Like when I buy a car I won’t read a review because I don’t care its performance.) reply treprinum 19 hours agoparentprevThe option to have 128GB RAM for stable diffusion and local LLMs. reply moondev 19 hours agorootparentSince 8GB unified memory is \"equivalent to a 16GB non Mac\" Is 128GB unified memory MacBook basically a 256GB Nvidia GPU(s)? reply lucasyvas 19 hours agorootparentThey are not equivalent - it&#x27;s pure marketing BS. reply jug 10 hours agorootparentprevI think that one is mostly marketing but there&#x27;s a grain of truth in terms of the combined effect of unified memory (which is fast as hell) and macOS memory compression. But I wouldn&#x27;t put 8 GB past similar to 10-12 GB on another system without these features. reply moondev 4 hours agorootparentSay I want to launch a vm with 8GB reserved memory. On a 10-12 GB machine I would have 2 to 4GB of memory left to actually allocate to the system. I don&#x27;t see how unified memory magically fixes this. It&#x27;s actually worse because even more memory has to be shared with the GPU.This is like saying a 8GB disk is actually like a 10-12GB disk elsewhere. reply treprinum 14 hours agorootparentprevNot in the machine learning world ;-) You&#x27;d need to switch to marketing workloads to make 8GB = 16GB. reply nottorp 19 hours agorootparentprev> Since 8GB unified memory is \"equivalent to a 16GB non Mac\"Yeah, right. reply matwood 11 hours agoparentprevCreative workflows can often use the extra power, particularly with video.For me, doing development and office work, I&#x27;ll be hard pressed to ever replace my M1 Max w&#x2F; 64GB. I don&#x27;t feel like I ever wait for anything. reply perfopt 19 hours agoparentprevI am still rocking a 2012 MBP. I even have a PPC MacMini but it now runs Linux. I have no idea who is upgrading from a M1&#x2F;M2 to M3 or why they would reply shawnc 19 hours agorootparentI work with a lot of 4K elements and video in Apple Motion, After Effects, and other applications. The better the chip the faster things go, especially previews and encoding. Every second ends up counting.I can see why others like me may upgrade. But I’m not going to bother just yet. reply youcantcook 19 hours agorootparentprevFunny how \"genius\" people on a \"genius\" forum can&#x27;t fathom how people do other things than write text in a text editor. reply jrockway 13 hours agorootparentI write text in a text editor all day but would still upgrade my machine on a regular basis. I have a Threadripper and use all 32 cores everyday. I&#x27;m still debating on whether or not to upgrade to the new generation released yesterday. 4 year old CPUs are not speedy. reply inferiorhuman 18 hours agorootparentprevYou&#x27;d be surprised at just how slow running zellij in iTerm was on an Intel MBP. Somehow in 2023 we&#x27;ve managed to create resource hungry text interfaces. reply JCharante 18 hours agorootparentprevthe battery life is really good reply inferiorhuman 18 hours agorootparentprevOver the years I&#x27;ve gone through a Core2 MacBook, a 2011 MBP, a 2015 MBP, and now a 14\" 2023 M2 Pro as each wore out physically over the years. Generally the charging systems and keyboards degraded severely by the 5 year mark. The 2015 had all those problems as well as janky graphics issues, but I used it until its SSD died recently.Aside from performance it&#x27;s hard to overstate just how quiet the current MacBook Pro is. The 2015 got noisy pretty easily especially if I had to switch to the discrete GPU, and anything heavier than 1080p30 in Firefox would cause the fans to go bonkers. By most accounts the last of the Intel models were worse. This one? After a few hours of transcoding video the fans still only spin up to a quiet whisper.What I don&#x27;t hear anyone talk about is the rigidity. You could hear the 2015 creak and flex if you picked it up with one hand. The 2023 just feels like a solid chunk of metal.For all of its warts, this is probably my favorite hardware of the bunch. The software (macos 14) is utter garbage though. That&#x27;s the culmination of lots of poor design choices over the years and nearly non-existent quality control. reply hinkley 16 hours agoparentprevI usually skip generations. I bought an M2 a couple months ago. Waiting for sure and largely ignoring the M3 hype. I don’t need to care, so I spend roughly half as much time consuming tech hype as I used to, and spend that extra time reading or touching grass. reply wil421 19 hours agoparentprevMy wife “stole” my M1 Air. At the time, it was good to see a comparison between the M1&#x2F;M2. I order custom spec ones but for someone who doesn’t they may want to buy a generation old to save me.However, I agree on the phrasing. The amount of people who are upgrading yearly is much smaller than people who would buy a generation older Mac to save money. reply totallywrong 16 hours agoparentprevI have a 2015 MBP with Linux that I miss every single day while using the work M1 Pro with its crappy keyboard and short key travel. The M1 is faster but doesn&#x27;t impact my work much, and I find macOS really frustrating to use. reply onlyrealcuzzo 16 hours agoparentprev> What are they doing that is so performance critical?There are close to 100M MacBook users.People will give you reasons here - because this is a non-representative group - but this is a tiny fraction of their user base.The main reasons are Apple&#x27;s marketing and signaling. reply swalsh 18 hours agoparentprevI have a MacBook pro m1. I&#x27;m considering an upgrade, but not for CPU. What I really need is more memory. This computer is not capable of doing any real load of development work without running out of memory. It&#x27;s insanely frustrating. reply esskay 19 hours agoparentprevPro no, Air however yep, I&#x27;m one of them. Big performance boost from the base M1 to the M3 Pro. reply thelittleone 19 hours agorootparentMe too. I get every second generation. Air is so cheap, why not. The business apps I run used to require a Macbook Pro to run. Now the 13\" air does it beautifully, and with amazing portability. I often have to carry 2 laptops when traveling. So before with an MBP 16\" and 2nd laptop, it was damn heavy. reply walteweiss 15 hours agorootparentI’m very curious why do you have to carry two laptops? If that’s not the case that you carry the second laptop for the other person. If you use the two, then I’m very curious of your use-case. reply evilduck 1 hour agorootparentNot who you asked but you might find it interesting regardless.I&#x27;ve had a development role with an AV company where I&#x27;d periodically go on site a couple times a year to assist with shows to test real world scenarios or lend a hand just to see things in action (\"production deployments\" in both senses of the phrase, as well as to see actual users and behaviors in the moment. Time management, stress, and risk in a live event is something you can&#x27;t really grok without having experienced it). Assuming the role of a show producer for those trips I would have two redundant company laptops to run the show that I carried but weren&#x27;t mine specifically, while I had my personally-assigned work laptop with me to work remotely with. And if it was a long enough trip to warrant it, my personal laptop also to keep those activities separated. If new OS updates were being tested and deployed, add in a tertiary show laptop for that. There are carry-on sized Pelican cases that handle it fine. You might be surprised at the sheer amount of stuff AV professionals tote around the world, on top of the ridiculous amount of cargo that gets shipped via freight directly to venues. Going through airport security with two to five laptops was an average Thursday for many of the people I interacted with at that job. reply james33 19 hours agoparentprevGame engines can be pretty hefty (especially the big 3D ones like Unity or Unreal), you can always find benefit from faster CPU&#x2F;GPU&#x2F;RAM with this type of dev work. This is the only reason I&#x27;m tempted to upgrade my M1 Max. reply rickette 19 hours agoparentprevYeah, most M-series are plenty fast I think. Just upgraded from a 2018 Intel Macbook to the M3 Max and the change is very noticeable. Hope and plan to keep using this machine again for 5+ years or so. reply semireg 18 hours agoparentprevIf spinning up a dev build on my M1 took 18 seconds, M2 takes 13 seconds, and an M3 takes 8 seconds... and I do this 50-100x per day, then the time saving can certainly be worth it. reply pjmlp 19 hours agoparentprevYes, people with too much money to spare like a couple of Mac podcasters. reply csydas 19 hours agoparentprevit’s not my thing but there are certainly tech enthusiasts and even brand specific enthusiasts that like details like this as they do try to get “the best” from their tech.so probably it’s not for everyone but i guess there is value in knowing how big of a bump the newest model gives. reply cglace 19 hours agoparentprevI replaced my M1 macbook pro because with 16 GB of ram I was constantly swapping. reply nottorp 19 hours agorootparentMost average HNers should get 32 or 64 Gb. You can use a 16 Gb machine but you&#x27;ll be limited.I bought a M2 Mac Mini with 16 Gb to test the platform. There&#x27;s a Studio with 64 Gb in my future ;) reply scarface_74 18 hours agorootparentYou assume that “most HNers” use their computers outside of work and a work provided laptop for anything processor or memory intensive.I use mine exclusively for a side contract and that’s the only reason I bought it. I’m either using VSCode with Python or Node and occasionally to build Lambdas in a Docker Amazon Linux 2 container.If I need more compute than that on my side project, I spin up a Cloud 9 instance on my client’s account. reply nottorp 14 hours agorootparentIf you only do Facebook you don&#x27;t need a computer at all?\"Most HNers\" mess with things I think. reply scarface_74 14 hours agorootparentSo you think most “HNers” spend most of their waking time outside of work on computers outside of gaming?The last thing I want to do is look at a computer for free and do anything “productive” after spending all day at work. replyrighthand 19 hours agoparentprevThey’re not doing anything critical, the people who upgrade for that minor bump are the fanatics who upgrade their cellphone every year for a minor megapixel bump. It’s fashion tech to the benefit of non-work related needs. reply scarface_74 18 hours agorootparentYes because people couldn’t possible have workloads that benefit from a 30% speed up or have bill rates that justify it. reply smcleod 19 hours agoparentprevM1 to M2 Pro for the 96GB which is nice for LLMs&#x2F;AI. reply baq 19 hours agorootparentOr you could buy a car...?Apple RAM premium is outrageous. reply infecto 19 hours agorootparentWhile the premium is indeed high, the total cost of the tool even at the premium is quite low. I think you can get the 14 M3 Max fairly decked out at around $5-7k. Not even close to a new car these days.Maybe I am in the minority but I see it as a tool. My workflows work well in MacOS, I like the build quality of the tool. My replacement timeline is generally pretty long. The value this tool generates is massive compared to the cost of it.I remember how often coworkers would joke about the cost of a Kinesis keyboard. They would die if they were a mechanic. reply J_Shelby_J 18 hours agorootparentAmazing that windows systems are so bad that people are justified in buying a $7k laptop instead of a 4x 4090 + threadripper super computer. reply infecto 17 hours agorootparentDo people actually care about costs this low for business use? Thats just a minor cost.Certainly there is a line to when it makes sense to compare costs but we are talking about sub $10k costs for a tool that lets say has a 3 year life for a business, so $3300 per year or $275 per month. I would think most of the individuals on this forum are generating more than $275 of value per month on their laptop.Its less about justifying and more that the cost is meaningless compared to the value. There is some intersection of objective and subjective analysis here, I don&#x27;t care if you want a $10k laptop that runs linux. reply Toutouxc 11 hours agorootparent> Do people actually care about costs this low for business use? Thats just a minor cost.Yes, in many places outside of SV, they do. $10k is slightly less than what I paid for my car, it’s more than a year of rent and is more than some (unfortunate) people in this country make in a year. And this is still Europe, a country with paved roads, fiber internet and free healthcare.I do my job on a $1700 MacBook, I could probably do it on a $300 Thinkpad and I personally could go and buy a $10k laptop, but my girlfriend would without doubt leave me on the very same day. reply scarface_74 14 hours agorootparentprevSurprisingly, I care about things like battery life, noise and being able to put a laptop on my lap without the heat ensuring that there will never be any little Scarfaces reply n8cpdx 18 hours agorootparentprevWhat are you talking about? Just the four cards is $10k, and then you still need to buy the rest of the computer. And you probably can’t take it with you and use it from the coffee shop or the couch.And yes, Windows systems are bad. They shipped broken TouchID for years, and they don’t trust you to turn off OneDrive (and will re-enable at every turn). Edge just gave me a toolbar yesterday that looked like browser chrome, but was actually a GamePass ad. I’m just pulling the easiest examples, listen to Windows Weekly for a full enumeration. reply anonymouskimmer 16 hours agorootparentI think GP used \"windows\" in lowercase to refer to all windowing operating systems, not just the MS one? reply Art9681 15 hours agorootparentprevA car that cheap will nickle and dime you until you&#x27;ve spend 5x its initial price. If you dont get lucky and it dies on you before your money was better spent by car mechanics. reply scarface_74 18 hours agorootparentprevWell, I can’t charge $150+&#x2F;hour for using a car… reply culi 19 hours agorootparentprevWhy not wait for M4? reply ajross 18 hours agoparentprev> My last Macbook Pro is a 2014For those curious: this is running a 3.7GHz 4-core Haswell. That&#x27;s very roughly the performance that you&#x27;d get from a contemporary Alder Lake-N (the E-cores only variant). c.f. this very reasonable mid-range $450 Chromebook: https:&#x2F;&#x2F;store.acer.com&#x2F;en-us&#x2F;acer-chromebook-314-cb314-4ht-3... reply VoodooJuJu 18 hours agoparentprevConsoomingis critical, the performance capabilities are just a nice bonus. reply devwastaken 10 hours agoparentprevUsually the upgrade is for better webcam, screen, a fresh keyboard, maybe want more storage, etc. MacBooks hold value, so you can resell them at good prices towards the next gen. reply anovikov 18 hours agoparentprevCompilation speed difference between 2015 15\" mbp and M1 Pro 14\" was truly profound. I could compile in a time it takes to make and drink a coffee what previously took half night. reply zaphod420 19 hours agoparentprevI upgraded from an M1 pro to an M3 max. it&#x27;s a nice upgrade. reply LeSaucy 19 hours agorootparentI just switched from 16\" 2019 i9 -> 16\" M3 pro and 2 weeks later still stunned at how amazing of a machine it is. I do a lot of c++ dev for $dayjob and my current project which took 1m45s to full rebuild on i9 is down to ~25s on m3. Without a fan turning on or barely getting warm. Its _magical_. I still get caught off guard by the chassis being cold when first placed on my lap. reply littlecranky67 19 hours agorootparentThe issue is that the 2019 MBP16 were crap. Especially the higer i7&#x2F;i9 models had thermal throttling issues when connected to an external monitor.My 3000€ i7 mbp16 2019 recently died and I replaced it with an \"interim\" base model, 650€ MacMini M2. The jump is huge, that freakin Mini beats my 3yo (I bought it in 2020) decked out MBP that constantly spun fans. While intended as Interim until M3 MBPs where announced, I see no reason to upgrade right now. reply minimaul 18 hours agorootparentprevI remember getting this jump accidentally - I bought a M1 Mac Mini for porting stuff too and for testing, and building on it was twice as fast as my 2018 15\" i7. And it was silent doing it. Pity it was only the 8GB base spec, because it would have made an amazing main machine! reply icedchai 9 hours agorootparentprevI used to have a 16\" i9 for a previous job. It was absolutely terrible. Any sort of build process would cause the fans to spin up. It sounded like a jet engine taking off. The corporate malware scanner didn&#x27;t help it much, either, as it slowed processing even more. reply jscheel 8 hours agorootparentI just disassembled mine a few days ago and cleaned it out completely. Before that, my fans would literally max out with almost nothing running. Now, they stay silent pretty much all the time (until I do something really intensive). Still thinking about an upgrade to Apple silicon now, though. reply barkingcat 9 hours agorootparentprevI&#x27;m using a MBP 2019 16\" at the moment, and I can&#x27;t upgrade yet. Hopefully I get to move over to the apple silicon laptops in the next couple years! reply muro 19 hours agorootparentprevI&#x27;d like to do the same. I want to upgrade to 4TB SSD, as I&#x27;m at the limit all the time and I spend a lot of time moving data from the laptop to NAS and back. With the upgrade, I&#x27;ll get a M3 max for the peace of mind - it will be ridiculously expensive anyway. reply 8 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple's M1 and M3 chips have differences in CPU cores, which can impact performance and power usage.",
      "M3 chips have larger clusters of CPU cores, potentially affecting overall performance.",
      "The M3 chips have E cores with higher maximum frequency but lower frequency for background tasks, while P cores offer improved vector processing performance and higher maximum frequency."
    ],
    "commentSummary": [
      "The discussion revolves around various aspects of Apple MacBooks, including model comparisons, RAM capabilities, battery life, environmental impact, performance, and upgrade options.",
      "Users share their personal experiences, frustrations, and preferences regarding different MacBook models and their performance in tasks like video editing, music production, and app development.",
      "Topics such as the cost of Apple laptops, the advantages of upgrading for different purposes, and the limitations of older hardware are also addressed in the discussion."
    ],
    "points": 191,
    "commentCount": 269,
    "retryCount": 0,
    "time": 1700660600
  },
  {
    "id": 38379543,
    "title": "Teenage Engineering: Innovating with High-Quality Design Products and Wireless Audio Synthesizers",
    "originLink": "https://teenage.engineering/products/ep-133",
    "originBody": "teenage engineering 2023 november products wireless audio synthesizers designs store view cart checkout now newsletter instagram ems support guides downloads support portal 10代工学は未来の製品と コミュニケーションを生 み出すスタジオです。 私たちのミッションは 先端工学を用いて上質で 機能的なデザインの 製品を作り出すことです。 是非、新たなスタイルで 音楽をお楽しみください。 0 we use cookies. read more in our privacy policy.",
    "commentLink": "https://news.ycombinator.com/item?id=38379543",
    "commentBody": "EP–133Hacker NewspastloginEP–133 (teenage.engineering) 184 points by bpierre 19 hours ago| hidepastfavorite107 comments capableweb 19 hours agoThe pricing is surprisingly low ($299) for being Teenage Engineering, wonder if they got tired of people complaining about their pricing? I guessed somewhere around $1000 before seeing the price. reply maxfurman 17 hours agoparentFrom the Verge article[0] on this device, it was designed from the ground up to a) only need parts that they could actually get during the pandemic, and b) sell for less than $300.I think this looks really cool and I want my in-laws to gift it to me for the holidays.[0] https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;11&#x2F;22&#x2F;23965528&#x2F;teenage-enginee... reply ketzo 17 hours agorootparentWow, that article is great -- some cool details on TE&#x27;s internal processes. reply dmicah 18 hours agoparentprevTheir pocket operator series were inexpensive, at $60-100 per model, but were very basic with essentially a bare PCB and most of the electronics protected by being placed under the screen. I believe that much of the cost of their expensive products is due to a lot of custom parts like CNC machined aluminum enclosures. This product seems designed to hit a price point between the pocket operators (~$100) and their plastic OP-Z (~$500). reply op00to 18 hours agoparentprevI&#x27;ll put my comment about price here. I saw \"teenage engineering\" and immediately thought \"no way I&#x27;d afford that\", but I clicked anyway. Sort of like how I&#x27;d look at a Lamborghini poster as a kid. reply lifty 18 hours agoparentprevIt looks like it&#x27;s made of plastic. Some of their other outrageously priced products are made of aluminium. Maybe that accounts for a chunk of the difference. reply yardie 18 hours agoprevWow, compared to some of their other products $299 for a TE sampler seems absolutely reasonable and much lower than I expected. reply MDGeist 17 hours agoprevYesterday an expensive desk toy, today a reasonably priced sampler. Not sure if TE is YOLOing or it is all part of a genius marketing plan. reply deebosong 17 hours agoparentCan&#x27;t help but feel it&#x27;s their gameplan. And I try to remain non-reactive, but I thought it was smart.That toy car looked ridiculous, but not completely out of line with their shenanigans in the past. So it seemed somewhat \"in character.\"And then to immediately follow-up with a way more useful, beautiful, functional, cool and interesting product that&#x27;s \"only\" $50 more expensive – with all the anchoring price point tactics and such dialed-in – and is like, 3x less than their OP-1 was (maybe even more), and \"only\" 2-3x more expensive than their higher-end pocket operators that essentially have similar functions... Then I do think they know exactly what they&#x27;re doing.All that being said, it absolutelye worked on someone like me and I bought one lol. I was so, so ready to be offended and be presented with more egregiously expensive-but-useless doodads. But $300 for a slick sampler... That&#x27;s really not bad at all. Considering the Roland 404 is $200 more, and some other audio gadgets I bought with less functions are in the $200 range. reply schwartzworld 16 hours agorootparentThis thing is an upgrade over the po33, but it&#x27;s not anywhere close to the same league as the 404. This is less of a criticism of TE and more of a credit to the incredible depth of features they&#x27;ve packed into the 404mkii. reply rumori 12 hours agorootparentThis, the 404mkii is a really strong machine on all fronts, if they manage to give us a proper looper in this year’s software update I will be over the moon. I like TE but their gear always ends up being closer to a toy than anything. It’s really fun but it mostly ends there. Elektron and Roland devices end up being much more versatile and professional in the long run. reply efields 15 hours agorootparentprevAs someone with a Chompi on the way, thank you for giving me some perspective to keep me from smashing that buy button. reply deebosong 15 hours agorootparentprevDang that&#x27;s good to know. No worries if not, but would you mind giving a broad breakdown between the two? reply rumori 11 hours agorootparentSP404mkii pros: DJ mode, SD card slot up to at least 64 Gb, 16Gb(!) internal memory for 16 projects 160 samples each, works as an audio interface over USB-C, full size 1&#x2F;4\" jack input and outputs, 33 effects with 3-6 parameters, 5 configurable effects simultaneously, resampling with effects, skipback recording, rubber pads, looping samples, real-time time stretching, OLED display, on screen wave editing and chopping.EP-133: 64 Mb internal memory, no SD card slot, 6.3mm jacks, predefined effects (considering the POs these are usually hardcoded with only couple of adjustable parameters), didn&#x27;t see an unquantizied mode in the manual, but it has note offsets, 9 effects in total, adorable design!My guess is that EP-133 is very immediate and fun to use but you hit a wall at some point due to lack of storage &#x2F; limited effects, whereas the 404 will take you from making beats to playing full multi-hour live set and beyond.Both great in their own right. reply art-not 11 hours agorootparentYou can unquantize actually! at the very least you can with midi input.I use my po 33 a lot. It&#x27;s something between a toy and a full fledged device. I&#x27;ve used it &#x27;live&#x27; when hosting a pen and paper event i wanted custom music for. Usually though it&#x27;s something I enjoy using when I want to do something musically without being too &#x27;committed&#x27;.I think there&#x27;s a lot of value from an item being easy to use and evoking the concept of play. It makes it easy to keep up &#x27;good habits&#x27; like music making on days where I dont want to or cant do more. reply deebosong 11 hours agorootparentprevWow appreciate it! This really helps.The SP404mkii sounds like a powerhouse and amazing value in comparison to the EP-133 now lol.But I&#x27;m def not anywhere near being able to take advantage of either to their full capacity.Thank you again. replytecleandor 17 hours agoparentprevYep! If you showed me that landing page hiding the price, and knowing TE, I would have said that it was going to be at least double or triple the price. reply merelysounds 14 hours agoparentprevAbsolutely both.They have been successfully releasing extremely well designed and extremely frustrating devices for a while now.And if anything, they’re getting more and more popular, working with ikea or panic and both iterating on old ideas and exploring new ones. reply wavemode 18 hours agoprevBeautiful device. Ugh. Coming across ads like this is like a bad drug.I can hear the equipment in my closet that I already barely use, crying out to me \"don&#x27;t do it!\" reply kstrauser 16 hours agoparentInsert the meme of me turning to look at this, while the dusty Novation Launchpad sitting on my desk is looking at me with jealous anger.I want this. I don&#x27;t need it at all. But wow, I want it. reply mr_sturd 18 hours agoparentprevHa! I&#x27;m teetering on the edge of buying a MicroFreak. There&#x27;s no way I could justify the cost of anything from TeenageEngineering - though £299 isn&#x27;t as steep as I was expecting from these. Stay Strong! reply capableweb 17 hours agorootparent> on the edge of buying a MicroFreakJust do it, it&#x27;s a lot of fun! You only live once, and if you save the box + bags and regret the purchase, you can sell it for minimal loss :) reply nekopa 14 hours agorootparentprevI have to back up the others: just buy the microfreak, it is awesome. It was my first hardware purchase, and I am so glad I got it. They keep adding functionality via firmware updates, so recently they added sample playback to it, along with granular synthesis. I added a volca drum and a multi effect pedal to my hardware line up, so now I can head out to my local pub and jam out without needing a laptop with me, and the whole setup fits in an old messenger bag. reply mr_sturd 14 hours agorootparentSounds like a neat set up! I&#x27;ve got the Volca Sample for the beats. Does audio go from Drum to Freak to headphones; and does the Freak control clock for the two? reply efields 15 hours agorootparentprevThe microfreak is a marvel. Buy it now. Take the time to understand it. You won’t regret it. reply pizzaminded1 14 hours agorootparentprevI bought one recently, and it sounds awesome, despite the fact that there are still some minor issues even after firmware update. reply mr_sturd 13 hours agorootparentWhat issues do you have with it?I do really like that they&#x27;re able to improve on the product with firmware updates. One of the benefits of software-controlled oscillators.I&#x27;d love it if they&#x27;d open it up with an SDK like Korg&#x27;s Logue series. reply pizzaminded1 10 hours agorootparentThere are the not really serious issues that still exists after firmware update: - When you quickly tap the pitch strip at the right edge few times, the screen turns off for a while (but it comes back up at next user input) - When connected via USB to my PC, and when arpeggiator with UP mode is enabled, then a first touch on the keyboard on any note will cause a Midi Start message to be sent to a DAW (and thus starting a playback) - Pressing octave up&#x2F;down, shift and arp&#x2F;sequencer buttons will sometimes result with random note being played.I like the fact that Arturia managed to squeeze new synthesis types and find a space for more presets in V5 update. I have my synth connected to NTS-1 which acts as a FX processor and i really recommend that setup as it sounds much better. replydriggs 18 hours agoprevCurious that its got a nonstandard 46.875 kHz samplerate rather than 44.1 or 48.0 kHz.Not that it matters since its only output appears to be on the analog side of the DAC.This is a surprisingly well-featured sampler&#x2F;sequencer for the price! reply tecleandor 17 hours agoparentIt might be because of the clock of the CPU or the dac being 24Mhz.24MHz&#x2F;512=46.875KHzEdit: or 12, 6, 3... 24MHz&#x2F;512=46.875KHz 12MHz&#x2F;256=46.875KHz 6MHz&#x2F;128=46.875KHz 3MHz&#x2F;64=46.875KHz... reply porkloin 18 hours agoparentprevYeah, very weird. They have a sample prep tool that converts existing samples to the correct format, and obviously the internal sampling records to that rate. reply duped 17 hours agoparentprevI&#x27;ve heard Lexicon used to use weird sample rates in its reverbs to make it harder to reverse engineer. reply lukeh 13 hours agoparentprevIt may have to do with part availability during the pandemic, perhaps? reply MrBuddyCasino 18 hours agoparentprev\"93.75kHz and 46.875kHz are the sampling frequencies Bruno Putzeys uses in all his digital products for Hypex, Grimm audio, KII, etc.\", as outline here[0], for the following reason: 5.2 Clock The clock circuit is the same as that used in the CC1 except that the sampling rate is set to 93.75kHz instead of one of the more traditional audio rates. This is specifically done to improve the performance of the SRC chip. An uncommon clock frequency reduces the odds that mix products between the incoming clock and the internal clock fall inside the PLL loop bandwidth of the SRC.[0] https:&#x2F;&#x2F;www.audiosciencereview.com&#x2F;forum&#x2F;index.php?threads&#x2F;w... reply driggs 18 hours agorootparentOK, you&#x27;ve pasted from the #1 Google result after searching for \"46.875 kHz samplerate\".What does this have to do with the Teenage Engineering EP-133? It doesn&#x27;t have USB audio or SPDIF, so no standard samplerate clock to conflict with. reply MrBuddyCasino 17 hours agorootparentIt does have DACs, that presumably operate at the standard frequencies. reply driggs 17 hours agorootparentThe ADC and DAC operate at 46.875 kHz, its samplerate. That&#x27;s the entire point of my original comment about it being nonstandard. reply CamperBob2 14 hours agorootparentprevThe thing is, if the sample rate matters with respect to anything other than the Nyquist limit, your filtering isn&#x27;t good enough.Relying on spacing between sample clock harmonics to keep beatnotes out of the passband isn&#x27;t great engineering practice. I have to do that in a relatively-exotic RF application, admittedly, but I wouldn&#x27;t advertise it as a feature. :) And I&#x27;d never choose that approach at audio frequencies. There&#x27;s just no need. reply driggs 14 hours agorootparentThe concern isn&#x27;t about the trivial difference in Nyquist frequency, it&#x27;s about aliasing and dithering when importing&#x2F;exporting&#x2F;synchronizing digitally.1 sample from the EP-133 is 1.0629251700680271 samples at 44.1kHz, or 0.9765625 samples at 48kHz.(But, again, it doesn&#x27;t export&#x2F;synchronize audio digitally, so it probably only matters if directly importing samples.) replyyitchelle 17 hours agoprevAs I load up the website, it dithers for a moment before the full image comes up. I love this effect...Have I gone full circle from my dialup days? I think I have... reply mr_sturd 16 hours agoparent> Whatever you now find weird, ugly, uncomfortable and nasty about a new medium will surely become its signature. CD distortion, the jitteriness of digital video, the crap sound of 8-bit - all of these will be cherished and emulated as soon as they can be avoided.— Brian Eno reply agloe_dreams 17 hours agoparentprevNot only is it a nice effect.... but the Muhammad Ali landing page is downright insane. That hero image choice is pure gold. It is insanely brave to not put the product in the hero too. Utter envy.Edit: OH MY GOD, THE PACKAGING. reply ketzo 17 hours agoparentprevIt&#x27;s so nice, actually. Great little effect that fits well with the rest of the page&#x27;s aesthetic. reply Night_Thastus 17 hours agoprevI have absolutely no use for this, but damn I love the aesthetics. That thing is just gorgeous. reply joakinen 14 hours agoparentTotally on the same page! The form factor is spot on, and the vibe is just downright cool. But samplers aren&#x27;t my cup of tea, so I&#x27;ll wait to see what other gadgets they roll out in this series. reply stigi 19 hours agoprevI don&#x27;t know how they do their math, but they advertise it for 299USD but when I open the store it&#x27;s sold for 349EUR which today converts to 380USD... That&#x27;s a 30% difference that hurts. reply alanfranz 18 hours agoparentPrices in the US generally don’t include VAT, and maybe there’s some exchange or import fee on top as well. reply donkeyd 18 hours agorootparentAnd often there&#x27;s also an invisible consumer rights &#x27;tax&#x27; on top. Since online purchases and warranty are quite heavily regulated in Europe, sellers often add some margin to cover the extra costs this might bring. reply ericpauley 18 hours agorootparentprevLikely this. 349 EUR is 17% VAT on 299. reply cammikebrown 18 hours agorootparentprevGonna pick this up in Portland on Friday. $300 out the door reply 6581 19 hours agoparentprevThe $299 don&#x27;t include VAT. reply stigi 17 hours agoparentprevThanks for the pointers everybody. They make sense. The frustration of seeing a 299 price tag and then being hit with a 349 price after one click on the store link is bad.. Didn&#x27;t stop me from buying though :D reply achairapart 16 hours agorootparentLooks like the price for Europe is always 349 Euros VAT included, whatever your local VAT is (it goes from 16% to 27%).Rest of the world is always $299, no VAT applied.Shipping is always free. reply marginalia_nu 18 hours agoparentprevSpeaking in general, prices tend to differ between regions away from just basic exchange rate math, since shipping costs means you don&#x27;t get proper arbitrage pressure, which is what would pushes prices toward (lowest advertised price) x (exchange rate). reply dubcanada 14 hours agoparentprevWelcome to most of the world outside of US. I can drive 3 hours and pay 20-30% less for everything including exchange rate. reply deebosong 16 hours agoprevOK I&#x27;m commenting twice and have no affiliations to TE or The Kount.But apparently, The Kount made a buncha sounds for this thing.https:&#x2F;&#x2F;twitter.com&#x2F;THEK0UNT&#x2F;status&#x2F;1727365475976216610I&#x27;m not that good at making beats, don&#x27;t have deep knowledge on tech specs, or even have good creative workflow (I&#x27;m a very enthusiastic dabbler). But The Kount&#x27;s free sample packs are so good (IMHO), and the beats he makes are certified bangers (he uploads 1 min vids of them on Twitter&#x2F; IG&#x2F; YouTube). Just wanted to highlight this as well and makes me happy to know. reply patapong 15 hours agoprevA long presentation and demo of the EP-133 is available here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rjW6_BuXN_4 reply simonebrunozzi 16 hours agoprevThe device looks gorgeous.I did a little bit of music creation with an Amiga 500 and Soundtracker, ~30-32 years ago.What would be an equivalent software-only thing to warm up to this again, before I decide I really need to purchase this thing? reply least 16 hours agoparentFor a software sampler, I would highly recommend Koala Sampler [1], which has a very easy to use workflow and is modestly priced ($5 for the base version, with sub $5 upgrades). If you don&#x27;t like it, you probably won&#x27;t like the EP-133.There&#x27;s also hardware trackers like the Tracker and Tracker Mini from Polyend [2] and the Dirtywave M8 [3] that might interest you as well. Their workflow is closer to what you used in the past.[1] https:&#x2F;&#x2F;www.koalasampler.com&#x2F;[2] https:&#x2F;&#x2F;polyend.com&#x2F;tracker-mini&#x2F;[3] https:&#x2F;&#x2F;dirtywave.com&#x2F;products&#x2F;m8-tracker reply Sirizarry 16 hours agoparentprevReally depends on the kind of music you wanna make. Since this is a sampler though, you can probably fire up something like reaper (free) or fl studio (less free) and start chopping up your favorite songs to make something new. Teenage engineering makes some really unique hardware though. I own their OP-1 and it’s a hell of a learning curve to get efficient with it but it’s so cool. reply themoonisachees 16 hours agoparentprevI&#x27;m not really in that scene, but I know for a fact trackers are going well in their niche. One that I know of is OpenMpt (I&#x27;m not good enough to use it properly so I can&#x27;t speak to how good it is), but there are more.In general, teenage engineering devices look fantastic and are really capable in the right hands, but they look deceptively simple while they are in fact really complex to make good music with. I know of a few people who burnt $1k on an OP-1 because they thought they could make music easily with it. reply bdowling 17 hours agoprevThe image of Muhammad Ali taunting Sonny Liston to get back up is one of the most famous images in sports. I can’t imagine how much it cost to license. reply dmd 17 hours agoparentYou think they licensed it, rather than just copying it from google image search? (Speaking as someone whose spouse licenses images and sees people doing that ALL THE TIME.) reply capableweb 17 hours agorootparentYes, absolutely they licensed it. Teenage Engineering is not a random mom-and-pop shop, and that image is not a photograph that most people wouldn&#x27;t recognize. reply dmd 17 hours agorootparentYou say that, but you&#x27;d say the same about, e.g. The New York Times, and my wife&#x27;s org has to contact them multiple times a year for using images without permission. They always pay up, but they keep doing it! Khan Academy is another big violator. reply porkloin 17 hours agorootparentThere&#x27;s a credit and statement in the footer of the page:> Muhammad Ali™; Rights of Publicity and Persona Rights: Muhammad Ali Enterprises LLC> Photos by Neil Leifer © ABG-SI LLC reply ErneX 17 hours agorootparentprevThey credit the Muhammad Ali Enterprises LLC in the bottom of the page so yeah they got the rights, I mean they are using boxing gloves also on the product pictures.Edit: even their limited edition packaging has these pictures. reply lq0000 14 hours agoprevWhat is a \"super segment hybrid display\"? Looks cool, has VFD vibes, but I assume it&#x27;s just an OLED with an overlay or something based off in the Verge article \"Most of the KO II’s parts are just off-the-shelf components, including the display\" reply jhbruhn 14 hours agoparentThat&#x27;s my guess as well. Either monochromatic OLED (cheap!) and colored icons (not so cheap?) or the other way around. LCD with front panel might also be fine as long as it&#x27;s bright enough, and the front panel is dim enough. reply danwee 17 hours agoprevI&#x27;m a total newcomer about this, but I would like to learn and start making \"music\". They advertise:> MAKE USE OF THE CURATED SELECTION OF DRUMS, BASS AND KEYS THAT COME PRE-LOADED ON YOUR K.O.II.Question: would I be stuck with their pre-loaded curated selection or is there any way I can \"upload\" any extra dum&#x2F;bass&#x2F;keys and use them? reply tecleandor 17 hours agoparentFrom what I see in their docs [0], you can either record samples directly from their hardware, or use a web tool [1] using Web MIDI (!) to update them. Guessing from the Web MIDI use, probably should be easy to create open tools or even load that page offline to update its samples. [0]: https:&#x2F;&#x2F;teenage.engineering&#x2F;guides&#x2F;ep-133&#x2F;functions#10.1-sample [1]: https:&#x2F;&#x2F;teenage.engineering&#x2F;apps&#x2F;ep-sample-tool reply lotsofpizza 17 hours agoparentprevThere is software included that allows you to add your own samples(audio files). reply capableweb 17 hours agoparentprevYes, you&#x27;d be able to use whatever samples you want; transfer from the computer (\"drag and drop samples using the sample tool\") or record them yourself via the input. reply ErneX 17 hours agoparentprevIt has 64MB for samples, I think you can record via the line in + microphone or with a software companion. reply masto 12 hours agoprevI can&#x27;t wait for Bad Gear to do this one. reply S_A_P 12 hours agoparentLove that guy. reply kazinator 11 hours agoprevThat looks too flimsy for pro audio; a month of gigging and it&#x27;s toast.No XLR or 1&#x2F;4\" TRS jacks. reply vitaflo 9 hours agoprevI like that the old PO line looked like small calculators and this new EP version looks like a big desk calculator that an accountant would use. Nice detail in sticking with the “theme”. reply art-not 18 hours agoprevi use my po-33 constantly. it&#x27;s one of my favourite things I&#x27;ve ever owned. it&#x27;s crazy how good they are at making little devices feel easy to use reply noman-land 18 hours agoprevHow do these guys manage to create such damn cool looking stuff every time? It&#x27;s really impressive. reply wintorez 17 hours agoprevI love their design language. reply codeulike 14 hours agoprevWhereas an Analogue Synth actually does something analogue that (in principle) a laptop could not emulate, a standalone sampler like this is just a digital device in a box with nice buttons, right? So it does the sortof thing you could do on an ipad by paying $5 for a sampler&#x2F;sequencer app. But it does it in a nice looking physical box with some cool buttons.I mean, thats fine, but I just want to be clear about that. reply nmeofthestate 14 hours agoparentYep - in the same way that you can prepare a meal with a Swiss Army knife instead of using kitchen knives, you can play music on a qwerty keyboard instead of a piano keyboard. You can achieve the same end result, but one tool is more tailored to doing the job. reply codeulike 14 hours agorootparentRight, and its nice to have shiny new tools to play with. But ipads and laptops are actually pretty good for music production too. Not really like preparing a meal with a Swiss Army Knife. reply JoeyJoJoJr 13 hours agorootparentWhy would you use a Mac versus PC. Why would you use FL Studio versus Logic, or grand piano versus a synthesiser?It comes down to the interface and the unique affordances it brings. A piece of musical hardware such a this is a musical instrument. reply jnovek 14 hours agoparentprevFor many -- myself included -- the buttons and encoders make it much easier to play as a musical instrument. When I buy a digital instrument I&#x27;m not just buying the sound engine, I&#x27;m also buying a specialized controller for playing that sound engine. reply alderz 19 hours agoprevThe store page is struggling with 502&#x27;s right now. reply dmd 17 hours agoparentI finally gave up and just bought it from their Amazon store. https:&#x2F;&#x2F;www.amazon.com&#x2F;teenage-engineering-sampler-sequencer... reply cats_ 17 hours agorootparentJust used this link to order. Thanks! reply Cockbrand 15 hours agoprevStupid noob question: would I be able to control this from a DAW like Reaper? reply vitaflo 9 hours agoparentIt has midi in so if your DAW has midi out then yes you can control it. reply tshaddox 16 hours agoprevI&#x27;d like to see a website UI that looks like that big video. reply zoklet-enjoyer 18 hours agoprevI love my PO-33. If I didn&#x27;t have a SP-404 MK2 I&#x27;d be getting this. I still might be able to figure out how to justify it to myself. But really I don&#x27;t need a 3rd sampler. reply frankfrank13 17 hours agoprevWow, for basically the price of a Circuit?? Insane reply cfr2023 17 hours agoprevTeenage Engineering Syndrome, oppressive proprietary products with undeniably appealing designs. On the surface, this is their bet effort yet. Props for that, I suppose. reply capableweb 15 hours agoparent> Teenage Engineering Syndrome, oppressive proprietary products with undeniably appealing designsKind of comes with the sector&#x2F;industry, not a lot high-quality, standalone gear that wouldn&#x27;t be considered \"oppressive proprietary products\". reply ge96 16 hours agoprevnot a music producer but the aesthetic of the TP-7 is so cool. reply tapeloop 19 hours agoprevneed to get me one of these reply stigi 17 hours agoparentyou&#x27;re username suggests so :) reply virtualritz 18 hours agoprevWhat a beauty! reply Dudester230602 17 hours agoprevNothing to write home about in 2024:* stereo &#x2F; mono sampling at 46.875 kHz &#x2F; 16-bit* 24-bit ADC &#x2F; DAC reply amelius 17 hours agoprevI don&#x27;t see why a laptop can&#x27;t do this. This will just turn into extra e-waste. reply dagmx 16 hours agoparentA laptop can do a great many things. That doesn’t mean it’s the best form factor for doing it.Music making devices are very much about the ergonomics of devices and the reduction of friction in workflow. This is also significantly more portable than a laptop, with much lower latency than you would likely get.When people compare devices, they should really consider not looking at just paper &#x2F;capabilities and what it means to a user. reply dwhit 17 hours agoparentprev> I have a few qualms with this app: > 1. For a Linux user, you can already build such a system yourself quite trivially by getting an FTP account, mounting it locally with curlftpfs, and then using SVN or CVS on the mounted filesystem. From Windows or Mac, this FTP account could be accessed through built-in software. > 2. It doesn&#x27;t actually replace a USB drive. Most people I know e-mail files to themselves or host them somewhere online to be able to perform presentations, but they still carry a USB drive in case there are connectivity problems. This does not solve the connectivity issue. > 3. It does not seem very \"viral\" or income-generating. I know this is premature at this point, but without charging users for the service, is it reasonable to expect to make money off of this? reply shoemakersteve 16 hours agoprevScrolling down, I see that they apparently also sell hoodies for $130USD (not including tax and shipping). Literal insanity reply iamben 16 hours agoparentCurious as to why that&#x27;s insane? It&#x27;s on par with &#x2F; a little less than most streetwear brands. Of course you can buy a hoodie for $25, but you can also buy one for thousands. You&#x27;re only going to pay what something is worth to you; it&#x27;s very subjective. reply 9999 15 hours agoprev [–] Absolutely gorgeous and like everything else I’ve owned from them it will probably break if I so much as look at it crosseyed. Still this one is actually cheap enough that I might buy it anyway. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Teenage Engineering is a studio that focuses on creating innovative and functional design products through advanced engineering techniques.",
      "They specialize in wireless audio synthesizers and offer a range of services such as an online store, shopping cart, and newsletter.",
      "They provide support guides, downloads, and an EMS support portal to assist users. They also promote a unique style of enjoying music and use cookies, with more details in their privacy policy."
    ],
    "commentSummary": [
      "Teenage Engineering has released the EP-133, an affordable device priced at $299, surprising customers with its low price point.",
      "Despite being made of plastic, customers are impressed with the product, and some speculate that the pricing strategy is part of Teenage Engineering's marketing plan.",
      "Other discussions revolve around the SP404mkII music-making device, concerns about minor issues with a recently purchased synthesizer, discussions on clock frequency and sample rate, and admiration for the design of the Teenage Engineering KO II and PO-33 devices.",
      "The affordable price and subjective value of these discussed items are significant factors influencing potential purchases."
    ],
    "points": 184,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1700662945
  },
  {
    "id": 38379893,
    "title": "Fortran 2023: The Latest International Standard for Programming Language Promotes Industry and Innovation",
    "originLink": "https://www.iso.org/standard/82170.html",
    "originBody": "ISO/IEC 1539-1:2023 p ISO/IEC 1539-1:2023 82170 ISO/IEC 1539-1:2023 Programming languages Fortran Part 1: Base language Status : Published enFormat Language std 1 208 PDFEnglish std 2 208 PaperEnglish CHF208 Buy Convert Swiss francs (CHF) to your currency General information Status : Published Publication date : 2023-11 Stage : International Standard published [60.60] Edition : 5 Number of pages : 674 Technical Committee : ISO/IEC JTC 1/SC 22 ICS : 35.060 RSS updates Read sample Preview this standard in our Online Browsing Plateform (OBP) Buy this standard Life cycle Previously Withdrawn ISO/IEC 1539-1:2018 Withdrawn ISO/IEC 1539-1:2018/Cor 1:2021 Withdrawn ISO/IEC 1539-1:2018/Cor 2:2023 Now Published ISO/IEC 1539-1:2023 Stage: 60.60 00 Preliminary 10 Proposal 10.99 2020-10-16 New project approved 20 Preparatory 20.00 2020-10-16 New project registered in TC/SC work programme 30 Committee 30.00 2022-01-03 Committee draft (CD) registered 30.20 2022-01-04 CD study initiated 30.60 2022-03-11 Close of comment period 30.99 2022-09-06 CD approved for registration as DIS 40 Enquiry 40.00 2022-09-07 DIS registered 40.20 2022-11-08 DIS ballot initiated: 12 weeks 40.60 2023-02-01 Close of voting 40.99 2023-04-12 Full report circulated: DIS approved for registration as FDIS 50 Approval 50.00 2023-06-28 Final text received or FDIS registered for formal approval 50.20 2023-08-04 Proof sent to secretariat or FDIS ballot initiated: 8 weeks 50.60 2023-09-30 Close of voting. Proof returned by secretariat 60 Publication 60.00 2023-10-03 International Standard under publication 60.60 2023-11-17 International Standard published 90 Review 90.20 International Standard under systematic review 90.60 Close of review 90.92 International Standard to be revised 90.93 International Standard confirmed 90.99 Withdrawal of International Standard proposed by TC or SC 95 Withdrawal 95.99 Withdrawal of International Standard This standard contributes to the following Sustainable Development Goals 9 Industry, Innovation and Infrastructure 11 Sustainable Cities and Communities Got a question? Check out our FAQs Customer care +41 22 749 08 88 customerservice@iso.org Opening hours: Monday to Friday - 09:00-12:00, 14:00-17:00 (UTC+1) Store Standards catalogue ICS 35 35.060 ISO/IEC 1539-1:2023 Sitemap Standards Benefits Popular standards Conformity assessment SDGs Sectors Health IT & related technologies Transport About us What we do Structure Members Strategy News Events Media kit Taking part Who develops standards Deliverables Get involved Climate action kit Resources Store Standards catalogue Publications and products",
    "commentLink": "https://news.ycombinator.com/item?id=38379893",
    "commentBody": "Fortran 2023Hacker NewspastloginFortran 2023 (iso.org) 176 points by hardmaru 19 hours ago| hidepastfavorite112 comments v8xi 17 hours agoI learned Fortran for a summer research job in college about 15 years ago. It was my first programming language and I used it to do some population modeling. I found an old Fortran book from when my dad went to school back in the early 70s and learned it from that which was a cool experience - I just had to skip over all the parts about entering your code into punch cards :D reply jonjacky 8 hours agoparent> I just had to skip over all the parts about entering your code into punch cardsA few years ago I worked with a scientist who used a huge Fortran program with a long history. He described the lines in a text file that configured the program: \"On the first card you put ... on the next card you put ...\" They still call them cards! He was born after actual punch cards went out of use. reply hnlmorg 14 hours agoparentprev> I just had to skip over all the parts about entering your code into punch cardsHaha I bet that was a fun and weird experience. reply m463 11 hours agorootparentA shame to skip the IBM 029 experience. (separate issue from drum cards with a skip) reply complex_pi 15 hours agoprevBesides the technical part, Fortran&#x27;s community has evolved a lot as well since 5-10 years. See the community paper here: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.15110 \"The state of Fortran\" (not an author myself) reply pklausler 17 hours agoprevF’23 doesn’t have much in it that’s new over F’18, which itself was also a pretty minor update to F’08.One thing to watch out for: in a departure from former commitments to compatibility, F’23 changes some semantics of working conforming code, specifically allocatable characters being used for internal writes, iomsg=, &c. reply bee_rider 16 hours agoparentIt must be hard to update a language that was already perfect in 1990. reply pklausler 12 hours agorootparentF&#x27;90 lacked allocatable derived type components, but was otherwise very well thought out, and its major contributions (modules, free form, internal procedures, generic interfaces, ELEMENTAL, array syntax, POINTER&#x2F;TARGET...) have held up well. Kind of a mixed bag since then, frankly (FORALL, LEN type parameters, FINAL, ENUM, DO CONCURRENT...) reply nolist_policy 12 hours agorootparentprevFortran first appeared in 1957... It&#x27;s probably older than most people here on HN. reply EVa5I7bHFq9mnYK 11 hours agorootparentIt&#x27;s just 34 more yeats until F&#x27;57 becomes ambigous .. reply bee_rider 11 hours agorootparentprevAs the other comment pointed out, F90 is surprisingly good considering it is also probably older than most people on this site, haha. reply fuzztester 11 hours agorootparentprev\"The first significantly widespread high-level language was Fortran.\"https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;High-level_programming_langu... reply dboreham 11 hours agorootparentprevThe \"new\" Fortran for me was f77. reply imachine1980_ 17 hours agoparentprev> allocatable characters being used for internal writes can you explain this ? reply pklausler 16 hours agorootparentIf you allocate a character object, then write to it with an internal write statement, F’23 now requires that the variable be reallocated to the actual length of the formatted record, instead of retaining its former length and being padded out with blanks (or truncated).The LLVM Fortran compiler (Flang) has warnings for various usages whose semantics would change if F&#x27;23 semantics were adopted by default, which I&#x27;m not sure I want to do. reply EE84M3i 15 hours agorootparentI&#x27;ve never used fortran so I&#x27;m not sure what a character object or an internal write is, but in C would this be something like allocating a character array and sprintf-ing to it? reply pklausler 15 hours agorootparentThat&#x27;s a good analogy, with the change being that sprintf is now somehow required to reallocate your buffer on every call if the length ever changes. replyhardmaru 19 hours agoprevFor a summary of changes to the language, see John Reid&#x27;s slides here: https:&#x2F;&#x2F;fortran.bcs.org&#x2F;2022&#x2F;AGM22_Reid.pdfMore info, The Home of Fortran Standards: https:&#x2F;&#x2F;wg5-fortran.org&#x2F; reply theodorethomas 17 hours agoparenthttps:&#x2F;&#x2F;wg5-fortran.org&#x2F;N2201-N2250&#x2F;N2212.pdf is John Reid&#x27;s complete document. reply thechao 16 hours agoparentprevDang ternary operator. I wish ternary was \"open\": X ? A : B : ... Z;Where the value of each expression counted down from A..Z, ie, of there&#x27;s 8 limbs, then A is 7, B is 6, ..., Z is 0. reply gamache 13 hours agorootparentSounds similar to computed GO TO, as in: GO TO (LABEL1, LABEL2, LABEL3, LABEL4) Ihttps:&#x2F;&#x2F;docs.oracle.com&#x2F;cd&#x2F;E19957-01&#x2F;805-4939&#x2F;6j4m0vn9l&#x2F;inde... reply smegsicle 14 hours agorootparentprevyou want a one-line switch expression?? reply fithisux 18 hours agoparentprevas a funny note John Reid was the singer of Nightcrawlers in the 90s. reply krylon 14 hours agorootparentThat is funny. Interesting career trajectory. reply fithisux 18 hours agoparentprevWhich FOSS compilers support it? reply pklausler 13 hours agorootparentIf \"it\" is F&#x27;23, then none. GNU Fortran has had the \"new\" degree-unit trig functions for a while, but no compiler, FOSS or otherwise, has the newly invented features of this revision.Fortran doesn&#x27;t prototype features with real implementations (or test suites) before standardizing them, which had led to more than one problem over the years as ambiguities, contradictions, and omissions in the standard aren&#x27;t discovered until years later when compiler developers eventually try to make sense of them, leading to lots of incomplete and incompatible implementations. I&#x27;ve written demonstrations for many examples and published them at https:&#x2F;&#x2F;github.com&#x2F;klausler&#x2F;fortran-wringer-tests&#x2F;tree&#x2F;main . reply certik 15 hours agorootparentprevGFortran, Flang and LFortran are all open-source compilers that support modern Fortran. reply rsecora 15 hours agorootparentprevflang [1], it&#x27;s part of the LLVM project.[1] https:&#x2F;&#x2F;github.com&#x2F;llvm&#x2F;llvm-project&#x2F;tree&#x2F;main&#x2F;flang reply nittanymount 18 hours agoprevhmm, wonder which fields people are using fortran now ?did a search, ha- numerical weather prediction,- finite element analysis,- computational fluid dynamics,- geophysics,- computational physics,- crystallography and computational chemistry. reply andy99 17 hours agoparentThere is a directory of github projects that use Fortran: https:&#x2F;&#x2F;github.com&#x2F;Beliavsky&#x2F;Fortran-code-on-GitHubI&#x27;ll add that it&#x27;s well suited to modern AI inference and several projects exist, e.g.https:&#x2F;&#x2F;github.com&#x2F;nlpodyssey&#x2F;rwkv.f90https:&#x2F;&#x2F;github.com&#x2F;certik&#x2F;fastGPThttps:&#x2F;&#x2F;github.com&#x2F;rbitr&#x2F;llm.f90 (disclaimer, mine) reply milancurcic 17 hours agorootparentA few more:https:&#x2F;&#x2F;github.com&#x2F;modern-fortran&#x2F;neural-fortran (disclaimer, I originally created this one)https:&#x2F;&#x2F;github.com&#x2F;BerkeleyLab&#x2F;inference-enginehttps:&#x2F;&#x2F;git.exeter.ac.uk&#x2F;hepplestone&#x2F;athena reply ravenstine 17 hours agoparentprevI wonder exactly why that is, though. I imagine it has more to do with historical use of Fortran in those fields than anything that Fortran specifically has to offer. There&#x27;s no real reason to switch to another language, I suppose, except that you&#x27;re limiting yourself to a much smaller pool of talent. Maybe learning Fortran \"proves\" one is passionate enough about one of these fields? Or requiring Fortran keeps out hordes of undisciplined JavaScript developers.EDIT: Wow, I didn&#x27;t expect so many informative and reasonable replies. Kinda makes me want to check out Fortran. Thanks y&#x27;all! reply archermarks 17 hours agorootparentI use Fortran for some research codes (I also use Julia and C++). The main advantage of Fortran, to me, is that it is very easy to write very fast code, and has very few foot-guns. The latter property also means it can be quite difficult to do non-numerical stuff, but that&#x27;s a great trade-off if you&#x27;re a physicist or engineer wanting to write simulations. The name comes from \"Formula Translation\" for a reason. Doing the kinds of multi-dimensional array manipulation and linear algebra you can do with out-of-the-box Fortran in C or C++ feels like torture.I generally prefer Julia, as its a more general-purpose language, but there are parts of Fortran I like better than Julia, such as- Fortran uses static typing and is statically-compiled- It&#x27;s a lot easier to write slow Julia code than I&#x27;d like, and you generally need to think more to make code fast than you do in Fortran.However, I think Julia beats Fortran in most everything else. My main gripe with Fortran these days is 1) lack of a decent default package manager (FPM seems great, but most Fortran codes don&#x27;t use it) and 2) slow evolution due to the conservative standards committee. I don&#x27;t understand why we still can&#x27;t have extremely basic generics in 2023, or a simple string type. reply adrian_b 17 hours agorootparentprevC and C++ and most modern programming languages have very poor support for arrays in comparison even with the ancient versions of Fortran, especially for multi-dimensional arrays.In C++ it is possible to define adequate types and operations for good support of multi-dimensional arrays, but this means that a user must choose some additional libraries to get the support that does not exist in the base language, unlike with Fortran.C++ can be much better than Fortran for scientific computing, but only after a significant initial effort of establishing a well-specified programming style, based on selecting an appropriate non-obsolete subset of C++ and after selecting carefully a set of libraries that provide all the missing features.For someone whose main job is not programming, using Fortran can be simpler. reply waynecochran 16 hours agorootparentC++ Eigen has become the defacto replacement for arrays for matrices and vectors. I am thinking this should make it more competitive w fortran in this domain. reply sampo 5 hours agorootparentPick out the even (i,j where both even) elements from a matrix m[0::2, 0::2] &#x2F;&#x2F; Numpy m(0::2, 0::2) &#x2F;&#x2F; Fortran [1] m(seq(0, last, 2), seq(0, last, 2)) &#x2F;&#x2F; C++ Eigen[1] If you have declared the array to start indexing from 0. reply frud 16 hours agorootparentprevOne big thing I remember is that it&#x27;s illegal to have multiple array arguments reference overlapping storage, so storage regions can&#x27;t alias. This means functions can be optimized more aggressively.My fingers can&#x27;t type Fortran anymore, so I&#x27;m going to use C as an example.Imagine you have this function: &#x2F;* Add entries in arg1 to arg2, put result in result *&#x2F; void add_vec(int arg1[], int arg2[], int result[], int length) { for(int i = 0; itypes with the LLVM equivalent of the \"restrict\" annotation, they exposed a lot of bugs in LLVM&#x27;s implementation of it, because most C code doesn&#x27;t use \"restrict\" pointers as extensively as Rust code uses mutable references and Boxes. reply ReleaseCandidat 17 hours agorootparentprevTheoretically with `restrict`, but that doesn&#x27;t really help. But the biggest advantage of Fortran is it&#x27;s support for multidimensional arrays, slices,... reply simplicio 17 hours agorootparentprevPartially historical inertia, partially the fact that commercial Fortran compilers have had decades to optimize numerical code to within an inch of its life.Also, for at least the older versions of it, its a pretty small language. If you have a grad student who&#x27;s already familiar with programming, they can probably teach themselves Fortran and start being able to make useful changes to your research code in a week or two. Compare, say, C++ where just learning the language enough to be useful could take most of a semester. reply InvisibleUp 17 hours agorootparentprevFortran is closer to a highly optimized Matlab than a general purpose language like Javascript. It excels at matrix and vector calculations and is simple enough of a language that getting something working isn’t too difficult. reply kitd 17 hours agorootparentprevIt&#x27;s been about 30 years since I last wrote FORTRAN (77), but back then it was used in computationally intensive applications because it was (or at least felt) like working much closer to the bare-metal data and code segments of a process than a &#x27;high-level&#x27; language like C. Certainly the compilers produced far fewer lines of assembly&#x2F;line of source compared to C, pushing the burden of correctness back on the programmer. It was almost like working with an assembly macro language.I suspect much has changed since though, so its fields of use may just be convention now. reply m463 11 hours agorootparentI vaguely remember early fortran code was really close to 1:1 source code -> assembly language. Probably just because that&#x27;s how low-level compilers were.I also remember from the era, that a one-line program with a &#x27;.&#x27; in column 6 would generate 600 lines of errors from the IBM optimizing cobol compiler. reply anon25783 16 hours agorootparentprevIf you’re writing a program or a library to perform fast arithmetic computation over large numeric arrays, Fortran is the optimal tool for the job. reply nine_k 15 hours agorootparentprevThink of FORTRAN as of a GPU shader language, or something like numpy. It&#x27;s heavily leaning towards massive vector processing, usually automatically parallelized, and the compiled code runs very fast. It gives you a lot of tools for doing numerical stuff straightforwardly and efficiently at the same time. It&#x27;s not a very ergonomic general-purpose language, but in its area it shines. reply jlarocco 14 hours agorootparentprevIn a lot of cases the libraries are developed by researchers and academics in physics, engineering, biology, and other sciences. Having a huge pool of CS graduates isn&#x27;t very helpful, except for the subset getting Phds in one of those other fields. reply dguest 15 hours agorootparentprevHow easy are strings and associative arrays in Fortran?My experience working with particle physics code (which is generally C++) is that we could probably make it a lot faster if we completely banned the use of `std::map`. But since it&#x27;s there, and since people use it to e.g. look for files or parse configuration, you often find an API that accesses elements in an array by string rather than by index. Sure, it just made your code 20x slower, but it&#x27;s only one part of much bigger framework and this wasn&#x27;t on the \"hot path\" anyway, so you just use it.Rinse and repeat a thousand times, you can see how things slow down a bit. reply dboreham 11 hours agorootparentprevOdd that so far nobody has mentioned nuclear weapons. reply jfkfif 11 hours agorootparentLLNL has ported most if not all of their codes to C++, but I think LANL is still full on Fortran reply sampo 16 hours agoparentprevEvery weather prediction model, and every climate model, is in Fortran.Caltech has a project attempting to write a new climate model in Julia:https:&#x2F;&#x2F;github.com&#x2F;CliMA&#x2F;ClimaCore.jlhttps:&#x2F;&#x2F;clima.caltech.edu&#x2F; reply milancurcic 16 hours agorootparentThere are a few other active projects porting weather, ocean, and climate models to Julia, C++, or Python.Getting a weather or climate model from zero to production grade requires approximately 100 person-years, or $20M (personal experience). Because of extremely high scientific expertise needed to correctly implement such models, it&#x27;s more difficult to leverage open source contributions from a broader community, like it is with web or ML frameworks. So most of the development in these projects is done by full-time hires, and to a lesser extent by contributions from early adopters.The key technical arguments that I hear&#x2F;read for such transition projects are ease of portability to accelerators (e.g. GPUs), and higher availability of programmers in the workforce.My intuition is that a $20M budget, if carefully allocated to compiler and hardware accelerator teams, could solve running Fortran on any accelerator in its entirety.With Fortran&#x27;s tooling and compiler support for offloading standard Fortran to accelerators slowly but surely improving over time, the rationale for porting to other languages becomes increasingly more questionable and is being revisited.But regardless of technical arguments, it&#x27;s a good thing for large models and frameworks to be written and explored in diverse programming languages. reply wiz21c 12 hours agorootparentCoding for GPU is more than language support. I&#x27;m currently rewriting a CFD engine that is implemented in Fortran with computer shaders and there are several cases where the logic of the code has to be rebuilt from scratch to fit the GPU model.Also, I understand the only Fortran compiler that supports GPU is the one from nvidia which is proprietary. I prefer to rely on open source for a code base that will last at least ten years...But reading this HN&#x27;s thread, I understand that Fortran is more alive than I thought. How many new developments are done with Fortran ? I mean, to me, Fortran is a bit like Cobol: it is so entrenched that, obviously, it still have a lot of activity but the momentum is moving towards more modern languages... But, well, that&#x27;s all guesses an impressions... reply bafe 12 hours agorootparentprevFor example the Exclaim project at ETH Zurich trying to rewrite ICON in python (granted, they use special decorators that JIT to GPU instructions). It looks like a bit of a fools errand to me to try an write such a complex and performance -sensitive software in a dynamic language. I wonder why Chapel hasn&#x27;t seen widespread adoption yet reply counters 11 hours agorootparentprevThe recent \"Neural General Circulation Models\" pre-print [1] from Google Research indicates that the team built a spectral dycore from scratch using JAX; in Appendix A they note that it comes in at just over 20,000 lines of code! This model isn&#x27;t quite \"production grade\" from the perspective of NWP (lacks microphysics and therefore any prognostic precipitation in the forecast), but it&#x27;s the only project I can think of that has rapidly produced such a atmospheric model \"from scratch\" with a high degree of engineering rigor.[1]: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2311.07222 reply adgjlsfhk1 16 hours agorootparentprevthere is a fairly major assumption being made here which is that none of the $20M cost is coming from Fortran. Part of the reason for porting the models is ease of development and if you make development easier, that $20m can go down pretty quickly. reply milancurcic 15 hours agorootparentAs a real-world counter-example, CLiMA (Julia) lists 54 people on their Sci&Eng team, and the project has been going for several years now. It is far from production ready. Granted, they tackle everything at once (atmosphere, ocean, data assimilation, machine learning etc.). I&#x27;m a big fan of the project and wish it the best. This is to illustrate what a huge endeavor it is to build a system like this, regardless of the implementation language. reply milancurcic 15 hours agorootparentprevDeveloping projects like this in Fortran is not any more difficult than other languages. I can&#x27;t speak to Julia because I don&#x27;t understand it well enough, but in my experience writing this kind of code in Fortran is more natural and easier than in Python + numeric&#x2F;array&#x2F;accelerator libraries. The key unfulfilled need is to have Fortran compilers do offloading efficiently for you. Then, there&#x27;s no comparison. reply gautamcgoel 15 hours agorootparentprevI did my PhD at Caltech and knew one of the grad students working on this project. I remember him telling me that Julia is a complete mess (don&#x27;t recall why he disliked it). I would imagine it feels more \"modern\" than Fortran, but that doesn&#x27;t necessarily mean it&#x27;s better per se. reply math_dandy 17 hours agoparentprevThere’s a long tail of highly optimized library code written in FORTRAN.Many high performance numerical computing libraries are “using FORTRAN” in the sense that they’re linking binaries compiled from FORTRAN for numerical linear algebra functionality. Cf BLAS (Basic Linear Algebra Subprograms). reply bee_rider 16 hours agorootparentThe best BLASes (BLIS, openBLAS, and MKL) have lots of C nowadays. IMO it is actually one of their weird cases where C makes more sense: you are mostly tuning GEMM and TRSM, so you can actually throw an unlimited amount of expert C coder effort at them.But most of the ecosystem other than BLAS doesn’t share this property. reply ilayn 14 hours agorootparentprevOther than the original reference implementation, you would not find any other fortran version of BLAS anymore. And nobody links to the reference for performance code. All written in either close to metal C with SIMD etc. or straight in assembly altogether. LAPACK is mostly fortran but there are also libraries slowly rewriting those in Rust&#x2F;Julia and C. reply RugnirViking 17 hours agoparentprevI saw a job offer wanting primarily fortran recently. It was from a government weather service, so I guess fluid dynamics&#x2F;weather prediction reply zX41ZdbW 11 hours agoparentprevThe list of the most popular Fortran repositories on GitHub:https:&#x2F;&#x2F;play.clickhouse.com&#x2F;play?user=play#U0VMRUNUICdodHRwc...WRF is one of the most notable... reply packetlost 17 hours agoparentprevLet&#x27;s include anything using numpy in there. It&#x27;s not a huge portion of the codebase (anymore), but it&#x27;s still there! reply SoftTalker 13 hours agoparentprevSame old same old. Nobody is starting new Fortran projects outside of the domains where it has been used for decades. reply ok123456 15 hours agoparentprev- everyone using numpy reply Cosi1125 16 hours agoparentprev- bioinformatics reply mike_heffner 16 hours agoprevJust in time for Advent of Code. reply marshallward 13 hours agoparentUnfortunately I don&#x27;t think the compilers will add it in time. reply fortran77 17 hours agoprevHooray! But I’ll stick to fortran77 reply xeonax 17 hours agoparenttrue to the username! reply UncleSlacky 14 hours agoparentprevI can write Fortran 77 in any language! reply fuzztester 9 hours agorootparentYou be one good Blub programmer.pg can write Lisp in any language!Heck, pg can write any language in Lisp!pg can even write On Lisp! reply findalex 16 hours agoparentprevCommon blocks for the win. reply dang 15 hours agoprevRecent and related:Fortran - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37291504 - Aug 2023 (223 comments) reply aborsy 16 hours agoprevNumpy probably calls Fortran and C libraries under the hood.Is Fortran still considerably faster than Numpy? reply ilayn 14 hours agoparentNo, NumPy has tools for Fortran inclusion, f2py, for the users but itself has no Fortran code. SciPy has Fortran77 code about 15% but slowly rewriting it in Cython&#x2F;C++.Both use BLAS from OpenBLAS library externally, that is mostly Assembly&#x2F;C for BLAS.NumPy use a flavor of LAPACK that is called LAPACK Lite, written in C, SciPy vendors LAPACK that comes with OpenBLAS if you are pip installing, or if you are using conda, it comes with MKL library from Intel. reply abdullahkhalids 15 hours agoparentprevThe passage of data from python -> fotran -> python takes some time.Right now, I am converting some numpy code to rust for exactly this sort of speed advantage. I barely know any rust, and don&#x27;t know the first thing about writing optimized rust code, but I am already getting constant factor improvements. reply bee_rider 16 hours agoparentprevThe overhead of a function call should be O(1) (I mean it must be, right?), and then most of the functions are probably O(N), where N is the size of the vector, at least.So, as long as most of the work is in the C or Fortran library, it should be about the same. reply chihuahua 16 hours agorootparentBut constant factors matter. We don&#x27;t expect there to be a difference in the big-O complexity between languages. If you have two O(N) implementations, but one is 10x faster than the other (or 1.5x or whatever), that&#x27;s still a significant difference. reply adgjlsfhk1 16 hours agorootparentprevthe problem is that O(1) here can be hundreds of nanoseconds which has a pretty notable impact for arrays shorter than a few thousand reply ok123456 15 hours agorootparentprevIt depends on how much conversion is needed to feed it into the FFI. Duck typing in python means there are a lot of implicit conversions that will take place. reply bee_rider 14 hours agorootparentTrue. But if the code is reasonably well written, and you are just doing Numpy operations on Numpy vectors and matrices, it should basically be equivalent to doing those operations in Fortran (because most of the actual compute should be performed by code written in Fortran and C).They asked if Fortran was faster than Numpy, not if it was faster than Python. reply synergy20 16 hours agoparentprevI think yes, numpy uses fortran. reply selimnairb 14 hours agoprevStupid ISO charging money for standards. reply dcchambers 16 hours agoprev [–] Absolutely wild to me that you need to buy access to a digital PDF of a spec for a programming language in 2023. reply krylon 16 hours agoparentIt&#x27;s kind of the default for ISO standards, not just for programming languages. Ada is - to my knowledge - the exception, the standard document and the rationale are available free of charge.However, the draft documents are usually available for free, and the difference between the final draft and the official standard is usually miniscule (typos, punctuation errors, and so forth). You can probably find it on the working group&#x27;s web site. reply trws 16 hours agorootparentYup, this. The final version the committee actually works on is free for C, C++ and Fortran. After that ISO has it. I’m honestly not sure I would trust the final as much as the final draft. You can also build the c++ spec from the latex for yourself, the repo is public. reply peppermint_gum 16 hours agorootparentprev> However, the draft documents are usually available for freeUnfortunately, not for SQL :( reply creer 15 hours agorootparentprevIt&#x27;s the default but are these orgs really getting significant funding from that kind of end-user hostile behavior? (And some drafts are available and sufficient but not in all fields) reply krylon 14 hours agorootparentI don&#x27;t know a lot about standards organisations. But the people who actually create the standards are not getting paid by ISO. So I don&#x27;t know what expenses ISO has to cover other than the cost of publishing the standard itself, which in digital form should be very low.In a corporate setting it might not be as big an issue, but as a private citizen who wants to read a standard document for educational purposes, paying upward of 100 bucks is fairly expensive, so this makes me a bit grumpy. I completely agree with your sentiment. reply jt2190 16 hours agorootparentprevhttps:&#x2F;&#x2F;wg5-fortran.org&#x2F;f2023.html reply krylon 14 hours agorootparentThank you very much! reply jonp888 16 hours agoparentprevThat&#x27;s how the ISO works. C++ is no different.I guess the theory is that only compiler developers need a copy of the standard. Everyone else should rely on their compiler manual reply tialaramex 16 hours agorootparentNobody needs or cares about the \"real\" document. It&#x27;s a MacGuffin at this point.STL (Microsoft&#x27;s ironically named STL guy) pointed out in a thread about whether there&#x27;s a difference between the ISO document and the draft that even Microsoft&#x27;s compiler devs just use the draft. reply IAmLiterallyAB 12 hours agorootparentDo you have a link to that thread? reply cyanydeez 16 hours agorootparentprevinfrastructure is a non-zero cost _and_ knowing that it&#x27;s \"authentic\" is non-zero cost also. reply pklausler 16 hours agoparentprev [–] The pdf of the final draft is available for free. reply vkaku 16 hours agorootparent [–] This is close enough:https:&#x2F;&#x2F;j3-fortran.org&#x2F;doc&#x2F;year&#x2F;23&#x2F;23-007r1.pdf replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ISO/IEC 1539-1:2023 is an international standard for the programming language Fortran, published on November 17, 2023, consisting of 674 pages.",
      "This standard replaces the previous version, ISO/IEC 1539-1:2018.",
      "ISO is a global organization that develops and publishes international standards for different sectors, promoting sustainability and supporting industry, innovation, and infrastructure."
    ],
    "commentSummary": [
      "The discussion revolves around the use of the Fortran programming language and its comparisons to other popular languages like Julia, C++, and Python.",
      "Users share their experiences and opinions on Fortran's evolution, features, and the challenges and benefits of transitioning to different languages.",
      "The advantages of Fortran in specialized fields like physics and climate modeling are emphasized, along with discussions on performance optimization, libraries, and the importance of language diversity.",
      "Some users prefer Fortran for its speed, while others mention potential advantages of other languages.",
      "The availability of ISO standards documents and their impact on development costs are also touched upon."
    ],
    "points": 176,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1700664390
  },
  {
    "id": 38386547,
    "title": "ChatGPT's Ability to Generate Fake Scientific Data Raises Concerns of Research Integrity",
    "originLink": "https://www.nature.com/articles/d41586-023-03635-w",
    "originBody": "NEWS 22 November 2023 ChatGPT generates fake data set to support scientific hypothesis Researchers say that the model behind the chatbot fabricated a convincing bogus database, but a forensic examination shows it doesn’t pass for authentic. Miryam Naddaf Twitter Facebook Email The artificial-intelligence model that powers ChatGPT can create superficially plausible scientific data sets.Credit: Mateusz Slodkowski/SOPA Images/LightRocket via Getty Researchers have used the technology behind the artificial intelligence (AI) chatbot ChatGPT to create a fake clinical-trial data set to support an unverified scientific claim. In a paper published in JAMA Ophthalmology on 9 November1, the authors used GPT-4 — the latest version of the large language model on which ChatGPT runs — paired with Advanced Data Analysis (ADA), a model that incorporates the programming language Python and can perform statistical analysis and create data visualizations. The AI-generated data compared the outcomes of two surgical procedures and indicated — wrongly — that one treatment is better than the other. Scientific sleuths spot dishonest ChatGPT use in papers “Our aim was to highlight that, in a few minutes, you can create a data set that is not supported by real original data, and it is also opposite or in the other direction compared to the evidence that are available,” says study co-author Giuseppe Giannaccare, an eye surgeon at the University of Cagliari in Italy. The ability of AI to fabricate convincing data adds to concern among researchers and journal editors about research integrity. “It was one thing that generative AI could be used to generate texts that would not be detectable using plagiarism software, but the capacity to create fake but realistic data sets is a next level of worry,” says Elisabeth Bik, a microbiologist and independent research-integrity consultant in San Francisco, California. “It will make it very easy for any researcher or group of researchers to create fake measurements on non-existent patients, fake answers to questionnaires or to generate a large data set on animal experiments.” The authors describe the results as a “seemingly authentic database”. But when examined by specialists, the data failed authenticity checks, and contained telltale signs of having been fabricated. Surgery comparison The authors asked GPT-4 ADA to create a data set concerning people with an eye condition called keratoconus, which causes thinning of the cornea and can lead to impaired focus and poor vision. For 15–20% of people with the disease, treatment involves a corneal transplant, performed using one of two procedures. The first method, penetrating keratoplasty (PK), involves surgically removing all the damaged layers of the cornea and replacing them with healthy tissue from a donor. The second procedure, deep anterior lamellar keratoplasty (DALK), replaces only the front layer of the cornea, leaving the innermost layer intact. How ChatGPT and other AI tools could disrupt scientific publishing The authors instructed the large language model to fabricate data to support the conclusion that DALK results in better outcomes than PK. To do that, they asked it to show a statistical difference in an imaging test that assesses the cornea’s shape and detects irregularities, as well as a difference in how well the trial participants could see before and after the procedures. The AI-generated data included 160 male and 140 female participants and indicated that those who underwent DALK scored better in both vision and the imaging test did than those who had PK, a finding that is at odds with what genuine clinical trials show. In a 2010 report of a trial with 77 participants, the outcomes of DALK were similar to those of PK for up to 2 years after the surgery2. “It seems like it’s quite easy to create data sets that are at least superficially plausible. So, to an untrained eye, this certainly looks like a real data set,” says Jack Wilkinson, a biostatistician at the University of Manchester, UK. Wilkinson, who has an interest in methods to detect inauthentic data, has examined several data sets generated by earlier versions of the large language model, which he says lacked convincing elements when scrutinized, because they struggled to capture realistic relationships between variables. Closer scrutiny At the request of Nature’s news team, Wilkinson and his colleague Zewen Lu assessed the fake data set using a screening protocol designed to check for authenticity. This revealed a mismatch in many ‘participants’ between designated sex and the sex that would typically be expected from their name. Furthermore, no correlation was found between preoperative and postoperative measures of vision capacity and the eye-imaging test. Wilkinson and Lu also inspected the distribution of numbers in some of the columns in the data set to check for non-random patterns. The eye-imaging values passed this test, but some of the participants’ age values clustered in a way that would be extremely unusual in a genuine data set: there was a disproportionate number of participants whose age values ended with 7 or 8. ChatGPT has entered the classroom: how LLMs could transform education The study authors acknowledge that their data set has flaws that could be detected with close scrutiny. But nevertheless, says Giannaccare, “if you look very quickly at the data set, it’s difficult to recognize the non-human origin of the data source”. Bernd Pulverer, chief editor of EMBO Reports, agrees that this is a cause for concern. “Peer review in reality often stops short of a full data re-analysis and is unlikely to pick up on well-crafted integrity breaches using AI,” he says, adding that journals will need to update quality checks to identify AI-generated synthetic data. Wilkinson is leading a collaborative project to design statistical and non-statistical tools to assess potentially problematic studies. “In the same way that AI might be part of the problem, there might be AI-based solutions to some of this. We might be able to automate some of these checks,” he says. But he warns that advances in generative AI could soon offer ways to circumvent these protocols. Pulverer agrees: “These are things the AI can be easily weaponized against as soon as it is known what the screening looks for.” doi: https://doi.org/10.1038/d41586-023-03635-w References Taloni, A., Scorcia, V. & Giannaccare, G. JAMA Ophthalmol. https://doi.org/10.1001/jamaophthalmol.2023.5162 (2023) Article PubMed Google Scholar Javadi, M. A., Feizi, S., Yazdani, S. & Mirbabaee, F. Cornea 29, 365–371 (2010). Article PubMed Google Scholar Download references Reprints and Permissions Latest on: Medical research Scientific community Machine learning Botox’s paralysing effects can relieve an uncontrolled head tremor RESEARCH HIGHLIGHT 17 NOV 23 How wild monkeys ‘laundered’ for science could undermine research NEWS EXPLAINER 16 NOV 23 CD201+ fascia progenitors choreograph injury repair ARTICLE 15 NOV 23 Jobs Professor / Associate Professor / Assistant Professor in the Thrust of Smart Manufacturing (SMMG) The Systems Hub will facilitate the integration of multidisciplinary technologies and explore their applications. Guangzhou, Guangdong, China The Hong Kong University of Science and Technology (Guangzhou) University of Health and Rehabilitation Sciences (Preparatory) I. University profile Located at Qingdao National High-tech Industrial Development Zone, the University of Health and Rehabilitation Sciences is a ... Qingdao, Shandong (CN) University of Health and Rehabilitation Sciences (Preparatory) Sir Run Run Shaw Hospital, School of Medicine, Zhejiang University, Warmly Welcomes Talents Abroad “Qiushi” Distinguished Scholar, Zhejiang University, including Professor and Physician No. 3, Qingchun East Road, Hangzhou, Zhejiang (CN) Sir Run Run Shaw Hospital Affiliated with Zhejiang University School of Medicine Multiple Positions Open in Stomatology Hospital, Zhejiang University School of Medicine Founded in 1897, Zhejiang University (ZJU) ranks among the top 3 universities on Chinese mainland and within the top 100 in the Times Higher Educat... Hangzhou, Zhejiang (CN) Stomatology Hospital, School of Stomatology, Zhejiang University School of Medicine(ZJUSS) Welcome Global Talents to West China Hospital/West China School of Medicine of Sichuan University Top Talents; Leading Talents; Excellent Overseas Young Talents on National level; Overseas Young Talents Chengdu, Sichuan, China West China School of Medicine/West China Hospital",
    "commentLink": "https://news.ycombinator.com/item?id=38386547",
    "commentBody": "ChatGPT generates fake data set to support scientific hypothesisHacker NewspastloginChatGPT generates fake data set to support scientific hypothesis (nature.com) 166 points by EA-3167 10 hours ago| hidepastfavorite113 comments sigmar 9 hours ago>“It will make it very easy for any researcher or group of researchers to create fake measurements on non-existent patients, fake answers to questionnaires or to generate a large data set on animal experiments.”Perhaps I&#x27;m naive, but I think the people that want to fake data were already doing it without tools like chatgpt. Especially since a ton of biological data is normally distributed, so it&#x27;s exceedingly easy to generate plausible fake results for such data without a system as advanced as chatgpt reply jampekka 3 hours agoparentCases of fabrication have been caught because the fabrication is done so badly, i.e. inplausibly. It&#x27;s often just imputing some \"random\" numbers or repeating samples etc. Many would be amazed how technically and mathematically illiterate scientists often are. And probably ones that fabricate even more so.Maybe it will increase and&#x2F;or get a bit higher quality with LLM fakery. But as with many \"AI bad\" themes, the problem isn&#x27;t that \"AI\" can fabricate the data. The problem is fucked up institutions and cultures. reply shishy 6 hours agoparentprevBeing able to do it at scale is an issue because of paper mills. reply cosmojg 4 hours agorootparentThe issue is that we consider passing peer review to be enough for something to be taken as truth when it should really be reproducibility&#x2F;replicability. That, and the incentives currently driving academia are absolutely ridiculous. Paper mills are merely a symptom of academia&#x27;s ills, not the cause of them. reply ipsum2 5 hours agorootparentprev`np.random.normal(0, 1)`. You too can generate infinite amount of normal distribution data to use for fake datasets, free of AI. reply joaogui1 4 hours agorootparentPeople are probably thinking data more complex than normal distributions (though I&#x27;m also not sure if GPT-4 is the best method for that) reply peteradio 9 hours agoparentprevThe easiest data to fake is null results because anything else is replicable, hence the importance of replication. reply _3u10 5 hours agorootparentnull results are also replicable. reply samtho 3 hours agorootparentA null result, or the absence of evidence, is not evidence of absence. If you fake a null result, you’re not asserting anything other than you could not measure and collect supporting data using your experiment to prove or disprove a hypothesis. It is difficult for someone doing replication to accuse you of ill-intent, as opposed to faked data that proves your point when anyone else can replicate your experiment and get totally different or even contradictory results. reply jampekka 2 hours agorootparentYou still have to give out the statistics that show the null result. E.g. something with a high p-value. You are in fact \"confirming the null hypothesis\". They aren&#x27;t any more difficult to replicate than results supporting \"the alternative hypothesis\".(The whole binary hypothesis system and culture is a mess though, but that&#x27;s besides the point.) reply dclowd9901 8 hours agoparentprevSo we’re pretending making something an order of magnitude easier makes no difference? Ok. reply insanitybit 7 hours agorootparentI&#x27;m not sure this is much better than the state of the art. Training a model on data and then having it generate new, fake data, is not only easy, it&#x27;s a standard tool for model boosting. reply spookie 1 hour agorootparentPoisoning the well for others, huh? reply passwordoops 8 hours agorootparentprevIt&#x27;s not an order of magnitude easier. It won&#x27;t make a difference reply sebosp 2 hours agorootparentprevThis is so worrying for me, the amount of digital garbage that can now be generated that is not obviously garbage, that one must read and discern first nonsensical bad text generation and second if factual, is truth becoming a needle in the hay stack? How can this be cleaned? reply lacrimacida 8 hours agorootparentprevChatGPT will unlock new levels of both good and bad. The question is what the ratio between the two is going to be. reply egberts1 6 hours agorootparentIf you think about it, it will make 99% of ChatGPT answer technically INCORRECT.It is harder to keep bad data out than it is to keep it filled with good data. reply throwaway14356 5 hours agorootparentwhich is the best kind of incorrect? reply BolexNOLA 6 hours agorootparentprevReminds me of the “asymmetric bullshit principle” reply muzani 5 hours agorootparentprevSure, but what do you expect? It&#x27;s like blaming Boeing for genocide and then trying to get rid of 747s.There&#x27;s plenty of research into AI safety. There were some damn coups going on over AI safety. The general public defines AI safety as Skynet and homemade bombs, but it&#x27;s also things like this - political manipulation, astroturfing, fake data, the risk of another industrial revolution.It&#x27;s something we should be slamming the brakes on, but most of the people calling out AI safety are also building their own B52 bombers, so nobody takes them seriously either.80000 Hours has been telling people to get into AI and nuclear policy for years now. Hopefully we have some competent people in govs who do something. reply devmor 8 hours agorootparentprevAre we pretending Faker hasn&#x27;t been a staple library in software testing for years? reply ethanbond 6 hours agorootparentAre we pretending GPT isn’t a leagues better data-faker than Faker? reply swatcoder 5 hours agorootparentAs always, it depends on your requirements.GPT definitely wins out if you want more novelty&#x2F;variety in your fake data and are willing to accept extraordinarily higher cost, less rigor, and less reliability. I&#x27;m sure there&#x27;s some occasion when those criteria win out, but Faker&#x27;s pretty decent most of the time. reply ethanbond 5 hours agorootparentThankfully using GPT doesn’t preclude you from using Faker, so I think we can all agree this is strictly an improvement in one’s ability to fake data. replyabnry 9 hours agoparentprevExactly. How is this news? What would be surprising is if ChatGPT _could_ generate fake data that passed analysis. reply marcuskaufmann 8 hours agorootparentThis could be the key to gain ultimate understanding reply civilitty 8 hours agorootparentAGI Silicon Valley style: Fake it till you make it, just like everything else. reply TeMPOraL 7 hours agorootparentI mean, that&#x27;s how adversarial networks work, isn&#x27;t it? reply zitterbewegung 7 hours agorootparentprevAdd bitcoin and a DAO and it becomes completely autonomous. Or lawyers… reply spacecadet 7 hours agorootparentprevThis. reply chrisweekly 6 hours agorootparentprevI think you meant _couldn&#x27;t_ reply dkjaudyeqooe 9 hours agoprevRoughly speaking, the whole point of an LLM is to create plausible sounding text, without regard to the truth (which it cannot determine or derive), so it&#x27;s a tool that is perfectly suited to this sort of malfeasance. reply SV_BubbleTime 4 hours agoparentI’ve read this over and over, and believe it - but it’s so easy to forget when it absolutely nails something like debugging or suggesting a CMake edit or finding 5 letter combinations that are reversible with a vowel in the middle, or etc.It’s just still mind blowing I can get a sarcastic summary of an email in the theme of GlaDOS from Portal and in the same screen get an email proofread.It’s funny how far “what should the next word be” can go. reply strogonoff 1 hour agorootparentIt might seem that there are cases where the ability to generate heaps of plausibly sounding text on demand is helpful, and there are cases where it is pretty much the worst possible capability to have. reply lazystar 2 hours agorootparentpreva billion humans typing on a billion keyboards for a few decades... just needed someone to come along and categorize each of the outputs. reply voganmother42 5 hours agoprev\"Gordon’s great insight was to design a program which allowed you to specify in advance what decision you wished it to reach, and only then to give it all the facts. The program’s task, which it was able to accomplish with consummate ease, was simply to construct a plausible series of logical-sounding steps to connect the premises with the conclusion.\"From the thumping good detective-ghost-horror-who dunnit-time travel-romantic-musical-comedy-epic: Dirk Gently&#x27;s Holistic Detective Agency reply carbocation 8 hours agoprevAs an academic researcher, I find analysis of GPT-4 itself — as it pertains to other fields — to be essentially meaningless. There are no guarantees that the version of the model that was used will be available in the future (the API endpoints seem to have a ~12 month future-looking guarantee at most).Don&#x27;t get me wrong:1. GPT-4 is incredibly interesting2. Studying GPT-4 is interesting for people working in that fieldBut when I see people writing about how GPT-4 can pass the USMLE (etc), it has no lasting meaning. It might as well be marketing for OpenAI, and to me it has roughly that amount of academic importance. reply blackoil 7 hours agoparentIt shows current state and progress. No strong reason to believe future models will preform worse. reply carbocation 6 hours agorootparentYes, and that&#x27;s interesting both popularly and to people doing research in developing better models.But for people who are nominally using this to conduct scientific inquiries in other domains, the specific performance characteristics are what actually matter. When I am writing about the results of my semantic segmentation model, the characteristics of that specific model are more important than the notion that future models will be at least as good.Hence my critique being pretty narrow (the academic use of GPT-4 for downstream science). reply ChainOfFools 8 hours agoprevIt&#x27;s only a matter of time until someone comes up with a GPT that takes whatever off-axis theories a research paper writer wishes to promulgate, and searches the entire corpus of academic literature for references that can be strung together in such a way as to support any argument one likes.A quack&#x27;s dream come true, substantiating an argument by backsolving from its feeble or malevolent conclusion to a set of well-known premises but-with-citations. converting untenable speculation into something that passes many superficial tests of legitimacy, which is more than enough to boost it into broader and less critical visibility.\"thick with citations, therefore truthy\" is a big blind spot in the casual heuristic used ro gauge the quality of a given piece of research writing, especially at the undergrad level where this tool, lets call it CheatGPT, would be stupendously popular. reply throwaway14356 5 hours agoparentThere is in fact a treasure throve of high level research that is to controversial for any expert to go near.Wild things will happen if screaming hoax from ignorance can no longer shut down constructive efforts.It will simply combine what is written about germ theory or heavier than air flying machines and produce sensible responses.The patent db&#x27;s are full of treasures if you have oh 1000 years? to study it. Maybe 10 000?It should also be possible to take a seemingly unworkable idea that makes no sense and gather just what is needed to bring it into reality.For stuff you can build or otherwise test properly it makes no difference what people think is possible.People think very little is possible, we always did! Everything that can be discovered has been discovered has been the mantra for thousands of years. This while the things people actually accomplish seem to get more and more astonishing. reply demondemidi 6 hours agoparentprevHave you been watching American politics for the last 20 years? Tea Party to Q&#x2F;Maga, they will cite any quack economist, quack scientist, or quack doctor that provides a theory that enforces their narrative, data be damned. reply m3m3tic 8 hours agoparentprevThis is already possible with search engines, there is enough information on the internet that you can substantiate just about any claim regardless of how much evidence there is to the contrary. (see flat-earth, plenty of plausible sounding claims with real, albeit, cherry picked evidence). reply ChainOfFools 7 hours agorootparentYes of course, this is already possible with AI writing assistance as well, if you&#x27;re willing to plug in some of the phrases they come up with into a search engine to figure out where they may have come from. But you still have to do the work of stringing the arguments together into a cohesive structure and figuring out how to find research that may be well outside the domains you&#x27;re familiar with.But I&#x27;m talking about writing a thesis statement, \"eating cat boogers makes you live 10 years longer for Science Reasons\" and have it string together a completely passable and formally structured argument along with any necessary data to convince enough people to give your cat booger startup revenue to secure next round, because that seems to be where all these games are headed. The winner is the one who can outrun the truth by hashing together a lighter weight version of it, and though it won&#x27;t stand up to a collision with real thing, you&#x27;ll be very far from the explosion by the time it happens. reply cosmojg 3 hours agoprevThe paper[1] itself reads like marketing material that was itself written by GPT-4. Why was this published? And why is Nature reporting on it? As someone who generates fake&#x2F;simulated datasets for a living, the scientific value of this paper is totally lost on me.[1] https:&#x2F;&#x2F;doi.org&#x2F;10.1001&#x2F;jamaophthalmol.2023.5162 reply simonw 9 hours agoprev\"The authors asked GPT-4 ADA to create a data set concerning people with an eye condition called keratoconus\"That had me confused for a moment, since there&#x27;s no GPT-4 model called Ada (the current embeddings model is called that, and there was a GPT-3 LLM model with that name too).Then I realized they were using ADA as an acronym for Advanced Data Analysis. reply pjot 9 hours agoprevWorking in analytics long enough has shown me how often people will p-hack their data to support their desired outcome.I’ve met many “data driven” teams that quickly turn their nose up at bad data reply anigbrowl 5 hours agoprevAnd people say LLMs can&#x27;t think like a human.(this is a joke; not all humans are able to analyze humor as well as an LLM) reply mmasu 9 hours agoprevIn this instance the ability to generate fake data is seen as negative, however in other realms it’s seen as a feature, rather than a bug.See:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Synthetic_dataor in scientific literature:https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2208.09191a few companies are doing exclusively this reply SrslyJosh 5 hours agoparentYes, there are situations where it&#x27;s useful to generate plausible fake data, but those are the exception, not the rule. reply mcqueenjordan 2 hours agoprevThis is some next-level human behavior prediction. reply Aloha 5 hours agoprevHow long til I can produce a paper that says smoking is good for you, and will extend life or increase quality of life? ;-) reply lakpan 5 hours agoparentSmokers are more likely to be social, so they have a better quality of life. Done.As for extending life… social creatures live more? therefore smoking extends life. reply SrslyJosh 5 hours agoparentprevHow fast can you sign up for an OpenAI account? reply insanitybit 9 hours agoprevThis is not particularly surprising, nor is it really bad - generating data that appears valid is really powerful. Although it was a bit funny since I happen to have keratoconus, and I don&#x27;t hear much about it often. reply sethbannon 9 hours agoprevThis is why for domains like science, tools like Elicit are so needed [1].They&#x27;ve been doing some interesting work on factored cognition to avoid these sort of hallucinations [2].1: https:&#x2F;&#x2F;elicit.com&#x2F; 2: https:&#x2F;&#x2F;blog.elicit.com&#x2F;factored-verification-detecting-and-... reply stainablesteel 9 hours agoprevi&#x27;m more concerned about people who couldn&#x27;t do this without chatgpt reply thomastjeffery 8 hours agoprevI think it would be more clear to say, \"ChatGPT assembled a fake data set as a continuation to scientific hypothesis\".ChatGPT does not generate data. It reassembles the data (text) it was given, including the text in its training corpus. reply nvrmnd 8 hours agoparentI don&#x27;t think that&#x27;s accurate, it generates novel outputs that were not observed in the training data. reply thomastjeffery 7 hours agorootparentIt doesn&#x27;t generate new tokens.Train an LLM on text that only uses lowercase, and it will never output an uppercase letter. reply nvrmnd 3 hours agorootparentSo the model is limited to using words and characters that already exist. I agree with you but I don&#x27;t see why is a limitation worth pointing out. reply dacryn 1 hour agorootparentyou literally have to put in every number for it to do mathematics correctly...its as stupid as that. some try to get around it by indeed only having the 10 different digits and glue them together, but its a hallucination that that works.an important point in generalization is for example that you teach it something. This is literally important&#x27;ycombinator is a website&#x27; is a prompt that is almost impossible of ycombinator is not in your training set reply pixl97 6 hours agorootparentprevBut can it put two tokens together10 01 = 1001? reply hunter2_ 8 hours agoparentprevWould you say the same about all systems that are considered \"generative\"? reply thomastjeffery 7 hours agorootparentProbably.It&#x27;s easy to mistake entropy for novelty. Computers don&#x27;t create: they compute. Calling an LLM \"Artificial Intelligence\" is a bit like mistaking a pseudorandom number generator for true noise. reply hunter2_ 6 hours agorootparentI think that by that same logic, you could say human artists, writers, etc. don&#x27;t create either, they just move existing matter (which typically isn&#x27;t created nor destroyed) from one place to another. You could also say an electric company doesn&#x27;t generate electricity but merely converts other energy into it -- one of the most popular uses of the word \"generator\" yet the atoms&#x2F;energy are already here; we just arrange&#x2F;convert and call it generation. I must insist that sorting some things a certain way is widely known as generation&#x2F;creation.I can see how other words are a bit more precise, though. Synthesize, perhaps? reply thomastjeffery 5 hours agorootparentWe think objectively about it. We have goals and intentions. We use logic. LLMs don&#x27;t.The dirt in the ground sorts impurities from water, but we don&#x27;t call it intelligent or generative. We call it entropy. replyCodeWriter23 9 hours agoprevIt&#x27;s just emulating a certain cross-section of human scientists. reply replwoacause 9 hours agoparentStill not good though. Only makes the behavior more prolific. reply nickpsecurity 6 hours agoparentprevIf Arxiv was used in training, some of those scientists were the ones that taught it to do this. Well, a good chunk of whatever they scraped off the Internet, too. reply itissid 8 hours agoprevDataColada people already had a lot of work prior to this. reply Threeve303 8 hours agoprevIt is becoming more human every day reply colechristensen 8 hours agoprevI asked ChatGPT to come up with a list of references for a topic I was researching. Every single citation it came up with was hallucinated except for one which turned out to be extremely useful. reply yieldcrv 9 hours agoprevits sad that people write entire research papers about how they are prompting it wrongthis stuff is getting old. it doesnt need studies on how an LLM bullshits. nobody needs a study on that, they need an article in a tabloid at best. reply LudwigNagasena 7 hours agoparentAt least it wasn’t published in Nature. I was kind of scared when I saw the submitted link. reply nickpsecurity 9 hours agoprevA long time ago, I ran into the books The Art of Deception and How to Lie With Statistics. They seemed like a good start on training people to spot deceptions. There were articles here on things like p-hacking. Then, the replication crisis.While no time now, I’m still interested in making a list of resources (esp free) that tells how to construct good studies, has comprehensive presentation of all categories of mistakes&#x2F;lies we see in them, examples of each, and practice studies with known errors. Anyone here got good books or URL’s that could go in a resource like that? That could train new reviewers quickly?If I return to AI or ever work in it, I also planned to teach all of that to AI models to automatically review scientific papers. Might contribute to solving the replication crisis. Anyone who’s doing AI now feel free to jump on that. Get a startup or Ph.D. with a tool that tells us which of the rest are fake. reply Obscurity4340 7 hours agoprevConfabulation, folks reply swayvil 5 hours agoprevIf the criteria for truth is a convincing argument, and we have a machine for generating convincing arguments to fit anything, and analyzing the argument is too much trouble, then what? reply dukeofdoom 6 hours agoprevSeems like lying gets a bar wrap... All kinds of great things came to be because of lying about the potential benefits, monorails included.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ZDOI0cq6G reply renewiltord 7 hours agoprevPeople will find such dumb reasons to get outraged. Folks have been photoshopping GFP expression for years. Then some halfwit will post it \"there&#x27;s some evidence that X is Y\". Try to replicate it, you can&#x27;t. Because the science is fake. reply photochemsyn 8 hours agoprevIf you haven&#x27;t read the breakdown of the epic Jan Hendrik Schön scandal in which he published about a half-dozen fraudulent papers in Science and Nature based on fabricated results regarding organic (chemically speaking) semiconductor devices cooked up out of thin air, start here. Required reading for any young graduate student IMO. The shame of Bell Labs, Science and Nature, all taken for a ride:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Plastic_FantasticIf that fraudster had started out with ChatGPT4, the fraud might have persisted for another decade (because organic semiconductors don&#x27;t seem to have the capabilities he believed they had), because he was only detected via replicated datasets. If he&#x27;d had ChatGPT4 to generate new plausible datasets, well...?I guarantee you that a significant fraction of the people in academia who &#x27;got there first&#x27; on significant discoveries in science did so by fabricating data along the lines of Schön. They just guessed right, and fabricated data, and then more serious careful scientists were able to replicate their bogus work later.Schön guessed wrong, and every effort to replicate his work failed, and Bell Labs, Science and Nature were left with egg on their face, which they&#x27;re still trying to wipe off. ChatGPT4 and its shady parents and affiliates will only make this problem worse, not better.\"Benefit to humanity\" my ass.[edit: if you wonder why I sound so salty I read all those Schön papers with interest and fascination when I was a young graduate student myself, now I&#x27;m older and seriously jaded.] reply bedhead 8 hours agoprevJust like people! reply ThrowawayTestr 9 hours agoprevGenerative text AI generates text. How is this a revelation? reply peteradio 9 hours agoprevGENIUS! reply Nition 9 hours agoprevSomewhere in the mind&#x27;s eye of science fiction is a world where we have near-unlimited productivity and knowledge and we&#x27;re all free to pursue our self-actualized lives as we see fit.But as productivity increases, and as AI improves, in both cases individual greed holds back lifting up the many. And so we end up asking for caution on automating away someone&#x27;s job, or caution on rapid AI progress.Does anyone know any good writing on how humanity might fight its way through all these mires of progress to the other side - that science fiction world that may or may not even be possible? How the world might look as these things continue to progress over time? Either fiction or a serious analysis is fine.Most sci-fi skips straight to \"There is no more need for University, we simply ask the AI\", missing the \"students are using AI to cheat\" phase entirely. reply hliyan 8 hours agoparentThe world of Star Trek is one where humanity learns from the devastation of world war three and over a century, creates a society where almost everything is run by computers, money doesn&#x27;t exist, and people work primarily for their personal satisfaction. But I think true AGI is frowned upon there. reply smitty1e 8 hours agorootparent\"Humanity learns\" is impossible. The unit of analysis is the individual.Some state may cross between individuals via education, but the individuals still must learn.History shows that knowledge transmission remains a sticky wicket. reply chongli 8 hours agorootparentFirm disagree! Example: take a tour of the tower of London and learn about all the nasty medieval tortures we used to inflict on people. Now we don&#x27;t do that anymore.Humans learn things collectively via culture and cultural transmission has been an extremely effective tool of knowledge preservation over the generations. reply pixl97 6 hours agorootparentI mean ya in some places in the world they still do torture people like that.Based on some of the shit my neighbors post online there is but a thin veneer on society that keeps them from doing it now. reply AndrewKemendo 7 hours agorootparentprevI’ve seen worse in person unfortunately reply nradov 6 hours agorootparentprevWho is \"we\"? Torturing people to death in equally horrific ways is still routine practice among radical Islamists and Mexican drug cartels, among others. reply ClumsyPilot 8 hours agorootparentprevArguably culture has been degrading somewhat lately reply dmix 7 hours agorootparentThis has been the popular narrative in almost all common written history forever. It’s basically the biggest recurring theme in diaries from the Middle Ages, especially among religious text.Things are never an upward hockey stick but they also aren’t saw waves skirting a baseline. reply mptest 8 hours agorootparentprevhumanity learns just mean sufficient individuals learn to take power and enact such a society reply inglor_cz 10 hours agoprevTuring test passed, because that is what quite a lot of human scientists did. Hello, Dr. Ariely, you&#x27;ve met your match.Sarcasm aside, once such systems really learn to lie, they will be all too human-like. Perhaps the defining quality of real intelligence is deception. reply Obscurity4340 2 hours agoparentIts insane how they think they can have their AGI and eat it too! The closest thing we have to AGI is like a human child even though that&#x27;s Synthetic (mankind made) General Intelligence and they can&#x27;t really be truly relied upon and not learn or formulate sentences you don&#x27;t like reply IanCal 9 hours agoprevFor anyone jumping in who hasn&#x27;t read the article, this is not about hallucinations and some researchers being surprised that GPT-4 doesn&#x27;t always respond with absolute truth.Instead it&#x27;s about how easily it can be used to generate plausible looking datasets that would confirm a hypothesis. It&#x27;s a warning note to journals about how fake data can more easily be created. reply jhbadger 9 hours agoparentExactly. It&#x27;s no different from the fake data sets created by hand in scientific misconduct cases for years, just I guess easier. I guess that&#x27;s not a good thing, but given even making a fake data set by hand is far easier than generating real data, I&#x27;m not sure if this will suddenly make more people fake data. reply Tostino 9 hours agorootparentThe fake data that&#x27;s been caught so far in just about every one of the cases that I&#x27;ve read about has been ridiculously poorly constructed fake data.I think the people that are good at faking data simply don&#x27;t get caught. reply xbar 6 hours agorootparentThe volume of bogus research is already growing non-linearly. It suggests that there is a market for fake datasets, which will lead to better AI training to fix this problem.Attacks only ever get better, not worse. reply pixl97 6 hours agorootparentprevEasier cheating tools allow more people to cheat. There is no particular reason it would lead to less fake data, and with the ability to get fake data in a few sentences rather than a few hours of work is apt to lead more people astray. reply Obscurity4340 7 hours agoparentprevConfabulation&#x27;s a better word for this reply elashri 9 hours agoprevIronically, I tried to ask ChatGPT to generate a signal + some plausibly background for a potential Supersymmetry particle discovery (with some details about model independent searches) and it started hallucinating like someone whose heart broken and spent the night drinking at the bar.I chose the wrong field to be able to fake data &#x2F;S. reply peteradio 9 hours agoparentIf anyone ever tried to talk to me about supersymmetry again I&#x27;d probably react the same. reply seba_dos1 10 hours agoprevIn other words: a text generator has generated a text. reply vikramkr 7 hours agoprevIt&#x27;s awesome to know that the scientific process that&#x27;s been in use for centuries, based on peer review and the importance of replication, is still so powerful that AI generated fake data can&#x27;t do anything to undermine it. Reality doesn&#x27;t care how the data was faked when you replicate an experiment!Now, if only scientists and institutions would actually bother using those tools we developed centuries ago. Unfortunately if they don&#x27;t - you don&#x27;t exactly need chatgpt to fake data you know? Replication crisis etc etc.Long story short: Man is it awesome that the scientific method is resilient to this! Too bad nobody uses it. reply ChrisMarshallNY 7 hours agoparentI’d be interested in seeing how AI can help replicate.Apparently, we have a replication crisis. From what I hear, many papers can’t be replicated, and we don’t know, because no one tries. reply vikramkr 5 hours agorootparentIronically one of the major papers that showed that many findings couldn&#x27;t be replicated couldn&#x27;t be replicated. Academia is packed to the brim with perverse incentives. It&#x27;s amazing that scientists are creative and capable enough to keep consistently changing the world and gaining deep, extraordinary, and replicable insights into our universe in a broken system. It would be nice if they didn&#x27;t need to fight the system though, see the story of the mRNA vaccine nobel and how hard she had to fight against the establishment to do the research that would end up saving a truly staggering number of lives reply ctoth 10 hours agoprevNow all it needs to learn is which asses to kiss and it&#x27;s well on it&#x27;s way to a PhD! reply spacecadet 10 hours agoprevIm working on honeypot data... the challenge continues. reply hackan 6 hours agoprev [–] \"Unbiased\"> personalised for youXD The joke writes itself. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The AI model ChatGPT has been found capable of generating fake scientific data sets, according to researchers.",
      "In a recent study, the AI-generated data misrepresented the effectiveness of different surgical procedures for an eye condition.",
      "Concerns have been raised about the potential threat to research integrity posed by AI's ability to produce convincing but fake data sets. Researchers and journal editors are considering the need for updated quality checks to identify AI-generated synthetic data."
    ],
    "commentSummary": [
      "Concerns have been raised about using ChatGPT and other language models to generate fake data for scientific research.",
      "It should be noted that fabricating data is not exclusive to AI and can be done through simple methods like random numbers.",
      "The focus should be on reproducibility and addressing flaws in academic culture to ensure the integrity of research.",
      "Debates are ongoing regarding the potential consequences and applications of generating fake data and the skepticism surrounding language models.",
      "Critical evaluation and vigilance in scientific research are crucial, as there is a potential for misuse of AI tools.",
      "Discussions also include the limitations of language models, knowledge transmission through education, the replication crisis in academia, and challenges and flaws present in the scientific community."
    ],
    "points": 166,
    "commentCount": 113,
    "retryCount": 0,
    "time": 1700694694
  }
]
