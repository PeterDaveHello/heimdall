[
  {
    "id": 39526057,
    "title": "Exploring Airfoils: Key to Efficient Flight",
    "originLink": "https://ciechanow.ski/airfoil/",
    "originBody": "Bartosz Ciechanowski Blog Archives Patreon X / Twitter Instagram e-mail RSS February 27, 2024 Airfoil The dream of soaring in the sky like a bird has captivated the human mind for ages. Although many failed, some eventually succeeded in achieving that goal. These days we take air transportation for granted, but the physics of flight can still be puzzling. In this article we’ll investigate what makes airplanes fly by looking at the forces generated by the flow of air around the aircraft’s wings. More specifically, we’ll focus on the cross section of those wings to reveal the shape of an airfoil – you can see it presented in yellow below: We’ll find out how the shape and the orientation of the airfoil helps airplanes remain airborne. We’ll also learn about the behavior and properties of air and other flowing matter. In the demonstration below, you can see a fluid flowing around a gray cube. Using the slider to change just one property of this substance, we can end up with vastly different effects on the liveliness of that flow: Over the course of this blog post we’ll build some intuitions for why these different effects happen to airfoils and other objects placed in flowing air. We’ll start this journey by looking at some of the methods we can use to visualize the motion of the air. Visualizing Flow If you’ve ever been outside in a grassy area on a windy fall day, you may have witnessed something similar to the little scene seen below. The slider lets you control the speed of time to observe in detail how the falling leaves and the bending blades of grass are visibly affected by the wind sweeping through this area: We intuitively understand that it’s the flowing air that pushes the vegetation around, but note that we only observe the effects that the wind has on other objects – we can’t see the motion of the air itself. I could show you a similarly windy scene without the grass and leaves, and I could try to convince you that there is something going on there, but that completely empty demonstration wouldn’t be very gratifying. Since the air’s transparency prevents us from tracking its movement directly, we have to come up with some other ways that can help us see its motion. Thankfully, the little outdoor scene already provides us with some ideas. Notice that as the wind hits a blade of grass, that blade naturally bends in the direction of the blowing gust, and the faster that gust, the stronger the bending. A single blade indicates the direction and speed of the flow of air in that area. In the next demonstration we’re looking at the same grassy field from above. When seen from this perspective, all the blades form short lines that are locally aligned with the wind. The more leaned over a blade of grass is, the longer the line it forms. We can mimic this behavior with a collection of small arrows placed all over the area, as seen on the right side: Each arrow represents the direction and the speed of the flow of air at that location – the longer the arrow, the faster the flow. In these windy conditions the flow varies from place to place and it also changes over time, which we can clearly see in the motion of the arrows. Note that we have some flexibility in how the speed of wind corresponds to the length of an arrow. I adjusted the lengths of the arrows to prevent them from visually overlapping, but I also made sure to maintain their relative lengths – if one arrow is twice as long as the other, then the flow at that location is also twice as fast. For visual clarity I’m also not packing the arrows as densely as the blades of grass are placed, but it’s important to note that every point in the flow has its own velocity which contributes to the complete velocity field present in this area. If we wanted to, we could draw a velocity arrow at any of the seemingly empty spots on the right side. The arrows are convenient, but the grassy scene also has another aid for visualizing flows. Many light objects like leaves, flower petals, dust, or smoke are very easily influenced by the motion of the surrounding air. They quickly change their velocity to match the flow of the wind. We can replicate the behavior of these light objects with little markers that are pushed around by that flow. You can see them on the right side: These little markers also show us the motion of the air. Each marker represents an object so small and light that it instantly picks up the speed of the surrounding airflow. We’d have a hard time seeing these miniscule specks at their actual sizes, so I’m drawing the markers as visible dots. In fact, the motion of each marker is equivalent to the motion of the parcel of air right around it. If you slow down time, you’ll be able to see how each marker just moves in the direction of the arrows underneath it. I also made each marker leave a little ghost trail behind it – this lets us track the path the air, as represented by the marker, took on the way to its current position. Let’s pause for a second to emphasize what the grass-like arrows and leaf-like markers represent – they both show the velocity of the flow of air, but in slightly different ways. An arrow is attached to its fixed point in space, so it represents the current direction and speed of the flow at that location. The whole collection of arrows lets us easily see what the entire flow is doing at the moment. On the other hand, the little markers are actively following the flow, letting us see how the air is actually moving through space, with the ghosty trails giving us some historical overview of where this parcel of air has come from. The two methods we’ve seen so far are very versatile, but sometimes we don’t care about the local direction of the flow, only its speed – in the middle of this grassy field one might get cold from a fast blowing wind regardless of the direction from which that wind is coming. This brings us the third way of visualizing flow: In this method we show the speed of the airflow using colors of varying brightness – the faster the wind, the brighter the color. You can see the whole spectrum of colors in the scale below the plot. This method shows the speed of the flow at all locations giving us a more fine-grained insight into the motion of air at the cost of the directional information. To help with that I’ll sometimes overlay the regular arrows on top to let us know where the flow is going as well. You may have noticed that all these methods present a flat, two dimensional view of the flow. It’s based on the assumption that the wind in our little scene doesn’t change with elevation, and that it also doesn’t blow towards or away from the ground. In reality, the air velocity could vary in all three dimensions, and that air could also flow upwards or downwards. Thankfully, the air flows we’ll consider in this article will be two dimensional and the simple flat drawings will suffice. Before we finish this section, let me bring up visualization of a simple airflow, but this time I’ll give you some control over its direction, which you can change using the second slider. The first one once more controls the speed of time: Don’t be misled by the frozen arrows, the wind is actually blowing there. Remember that the arrows represent the local velocity of the flow of air, so while the velocity doesn’t change, the position of each packet of does. You can see those changes by tracking the markers moving around with the flow. This demonstration represents a steady flow, which means that its properties don’t change over time. So far we’ve been exploring the notion of airflow’s velocity on a more intuitive level, with a general understanding that’s it’s “the air” moving around in some direction and at some speed. I illustrated that concept using simple arrows↑, markers •, and varying colors, but we’re now ready to investigate the details hiding behind those straightforward graphical representations. To do that, we have to look at individual particles of air. Although I briefly discussed the particle nature of air before, this time around we’re going to take a closer look at the motion of these molecules, and what it means for airflow as a whole. Velocity Let’s take a look at the air particles in a small, marked out volume of space seen in the demonstration below – you can drag the cube around to change the viewing angle. The slider controls the speed of time: You’re witnessing the motion of over twelve thousand air particles. It may seem like a lot, but this cube is extremely tiny, its sides are only 80 nanometers long. To put this in perspective using more familiar sizes, if that cube’s side measured just 1 inch1 centimeter, it would contain around 410 quintillion, or 4.1×102025 quintillion, or 2.5×1019 particles. The particles are zipping around in random directions, constantly entering and leaving this region. However, despite all this motion what you’re seeing here is a simulation of still air. To understand how all this movement ends up creating still conditions, we first have to look at the velocity of each particle – I’ll visualize it with a small arrow in the direction of motion. To make things a easier to see, I’ll also highlight a few of the particles while fading out the rest of them: The length of an arrow is proportional to the speed of a particle, so when you freeze the time you should be able to see how some particles are slower and some are faster. This speed variation follows a certain distribution that’s related to temperature – the warmer the air, the faster the motion of its particles. At room temperature the average speed of a particle in air is an astonishing 1030 mph1650 km/h, which is many times higher than even the most severe hurricanes. Given the size of the cube, this means that even at the fastest speed of simulation everything happens 11 billions time slower than in real life. If you paid close attention, you may have also noticed that sometimes the particles randomly change direction and speed of their motion – this happens when molecules collide. Each particle experiences roughly ten billion collisions per second. We’ll get back to these interactions later on, but for now let’s try to figure out how all this turmoil creates still air. Having just seen the small velocity arrows of individual particles, let’s calculate the average velocity of a group of three particles, using the process shown below. We first take the velocity arrows from each particle and place them head to toe, one after another. Then we connect the start of the first arrow with the end of the last arrow to create the sum of all velocities. Finally, we divide, or scale down, the length of this sum by the number of particles to get the average velocity: In the next demonstration we’re repeating this whole procedure by tallying up all the particles inside the red box. You can change the size of that region with the second slider. The large arrow in the middle shows the average velocity of particles in the box. To make that central arrow visible, I’m making it much larger than the tiny arrows tied to particles: The counter in the bottom part of the demonstration tracks the current number of particles in the red cube. That value fluctuates as the molecules enter and leave that region. While aggregating over a small number of particles creates a very noisy readout, it doesn’t take that many particles to get a much steadier measure. Recall that the scale of the large central arrow is much larger than the scale of individual tiny arrows attached to each particle. Despite that increase in size, the arrow practically disappears when we average out a larger number of particles and we can clearly see that the average velocity of particles is more or less zero even in this extremely small volume. In still conditions, all these motions in different directions average out to nothing. As some particles enter the area from a random direction, the others also leave it in a random way. The bulk of air doesn’t really go anywhere and the particles just meander in a random fashion. An imperfect, but convenient analogy is to imagine a swarm of bees flying in the air. While all the individual insects are actively roaming around at different speeds, the group as a whole may steadily stay in one place. All these experiments form the key to understanding what happens when wind sweeps through an area. In the demonstration below, we’re once again watching a small volume of space, but this time you can control the speed of the blowing wind: Notice the mphkm/h speedometer in the bottom of the demonstration. This is not a mistake – even with hurricane-level wind speeds it’s very hard to see any difference in the motion of the particles. Perhaps you’ve managed to see the tiniest shifts in the small particle arrows as you drag the second slider around with time paused, but it’s difficult to even perceive from which direction the wind is blowing. However, when we use the procedure of averaging the velocity of all the particles, we can reveal the motion of their group in the box of a given size, at a specific speed of the flow: Because the motion of each individual particle is so disordered, we have to look at many of them at once to discern any universal characteristics. And when we do just that, from all the chaos emerges order. It’s important to note that with this approach we’re tracking the velocity of the flow within the same region of space outlined by the red box – the molecules keep entering and leaving this area as the flow moves and the arrow in the middle shows the average velocity of the air’s particles in that area. This is exactly what the grass-like arrows we’ve played with in the previous section represent – each one shows the average velocity of air particles in that local region of space. The big arrow we just saw in the middle of the swarm in the averaging red box is equivalent to each of the arrows seen below: Naturally, the averaging box needs to be large enough to avoid the jitteriness related to aggregation of too few particles, but at any scale that we could care about the noisy readout completely disappears. The average motion of particles is very different than the motion of each individual molecule. Even in very fast flows, many of the molecules move in the opposite direction than what the arrow indicates, but if we tally up all the particle motion, the air as a whole does make forward progress in the direction of velocity. Up to this point, we’ve mostly looked at the flow of air by looking at wind and the way it moves through space, but what we consider a motion of air is relative. Let’s see how, by merely changing the point of view, we can create a motion of air in otherwise windless conditions. Relative Velocity Let’s zoom away from the world of microscopic particles to look at the motion of larger bodies. In the demonstration below, you can see two different views of the same car driving in the left direction. In the top part, the camera stays firmly on the ground, but in the bottom part, the camera tracks the motion of the vehicle. If needed, you can restart the scene with the button in the bottom left corner or tweak the speed of time with the slider: These two views show the exact same scene – we’re just changing what the camera is focusing on. As seen in the top part, from the perspective of the static camera, it’s only the car that has some velocity in the left direction. On the other hand, from the perspective of the camera focused on the vehicle, the car doesn’t move, but everything else does. The poles and road markings all move to the right with a speed equal to that of the car. This shouldn’t come as a surprise from daily experience in any form of transportation – when you’re sitting in a moving vehicle, static things in the surrounding environment seem to move towards and past you. The very same rules apply to any region of air – I’ve outlined some of them with dashed boxes up in the sky. For the observer on the ground that air is still, but from the car’s perspective, that air is moving. With that in mind, let’s see the same scene, but this time I’ll add the familiar small arrows showing the air’s velocity as “seen” by the camera: From the point of view of the car, as seen in the bottom view, the air is moving to the right, as if there was some wind blowing right at the vehicle. You’ve probably felt this many times by sticking your hand out the window – it feels no different than if you were standing still on the ground with the wind hitting your fingers. In fact, there is absolutely no difference between “regular” wind and wind experienced by the car or your hand sticking out the window – both are simply a motion of air relative to some object. This means that we can use our arrows to represent any motion of air, as long as we note what that motion is relative to. You may have also noticed that the moving car affects the motion of air in its vicinity. Let me bring up the previous demonstration one more time: In the top view, we can see how the front of the vehicle pushes the air forward, and how the air “bends” and speeds up around the shape of the car to roughly follow its shape, only to end up circling right behind the machine. The same effects are seen in the bottom view – they’re just experienced differently. For example, the air right in front of the car slows down, while the air on top moves even faster than the rest of the undisturbed, distant air. We’ll soon explore why the air behaves this way when flowing around an object, but for now let’s raise above the ground to see the motion of an airplane flying in the sky. We’ll use the familiar setup of a camera kept steady relative the ground, as seen in the top part, and a camera that follows the airplane, seen in the bottom part: Before we continue, notice that it’s getting a little hard to pay close attention to what happens to the moving objects in the ground-fixed camera view – the bodies quickly leave the field of view of the demonstrations. For the rest of this article I’ll stick to the camera style seen in the bottom part of the demonstration – this will let us directly track the interaction between the object and the air that flows around that object. From the point of view of the airplane, it also experiences a flow of incoming air as seen by the air “boxes” approaching the plane, which is very similar to the car example. What’s completely different from the car example is the fact that the airplane somehow stays suspended in the air, despite gravity pulling it down towards the ground. This means that there must be some other force acting on it to prevent the plane from falling from the sky. Let’s compare these two vehicles by looking at the basic forces affecting their motion, starting with the diagram of forces acting on the car: The down-pulling gravity force is counteracted by the reaction forces from the ground – they act through the car’s tires to prevent the car from sinking. The air drag and other forms of resistance push the car back, but the car’s tires powered by the engine keep propelling the car forward. In my previous article I presented a more elaborate description of the interplay between forces and objects, but to briefly recap here, if forces acting on an object are balanced, then that object will maintain its current velocity. All forces on the car are balanced and the vehicle moves forward with constant speed, and it doesn’t move at all in the up or down direction – the object’s velocity is indeed constant. Let’s draw a similar diagram of forces for the flying plane: We still have the air drag that pushes the vehicle back, and the plane’s propeller powered by the engine keeps pushing it forward. As a result the plane moves forward with constant speed. We also have the down-pulling gravity. This time, however, that gravity is not countered by the reaction forces from the ground, but instead it’s balanced by lift, a force that pushes the plane up. When gravity and lift are equalized, the plane doesn’t move up or down either. Airplanes create most of their lift with wings, which are carefully designed to generate that force. While length, area, and the overall geometry of the wings are very important, in this article we’ll focus on the shape of the cross-section of a wing which I highlighted below in yellow: This is an airfoil, the protagonist of this article. This airfoil has a smooth, rounded front and a sharp trailing edge. Let’s take a closer look at the flow of air around this airfoil using the grass-like arrows that show the velocity of air at that location: These arrows paint an interesting picture, but in the demonstration below I’ve also added the little leaf-like markers that track the motion of air parcels in the flow. I steadily release a whole line of them from the left side, but you can also clicktap anywhere in the flow to drop a marker at that location. You can do this in any demonstration that has a little hand symbol in the bottom right corner: The markers show that the flow splits ahead of the airfoil, then it gently changes direction to glide above and below the shape. Moreover, the markers right in front of the airfoil gradually slow down and lag behind their neighbors. The air somehow senses the presence of the body. It may be hard to see, but the top and bottom sections of this airfoil aren’t symmetric. This asymmetric design is very important, but right now it will needlessly complicate our discussion on how the flow around this shape arises. To simplify things a little, let’s use a less complicated shape of a symmetric airfoil – you can see it in the demonstration below. I overlay the previous asymmetric shape with a dashed outline to show the difference between the two: The motion of air around this airfoil is very similar – the flow changes its direction and speed when it passes around an object. Until now we’ve simply been observing that the flow changes to adapt to the shape of the body, but it’s finally time to understand why it happens. To explain that behavior we need to go back to the world of air particles to discuss the concept of pressure. Pressure As we’ve discussed, even in the seemingly steady conditions the particles of air are zipping around at high speeds colliding with each other at an incredible rate. The surface of any object placed in the air will also experience these bounces. In the demonstration below, you can see air particles bombarding a small box. Every time a collision happens I briefly mark it with a dark spot on the surface of that cube: To understand the implications of these collisions, let’s first take a look at objects with more ordinary sizes. In the demonstration below, tennis balls are hitting a large cardboard box from the left and right side. By dragging the slider you can change the intensity of both streams of balls: When a tennis ball hits the box, the collision imparts some force on it, causing the box to move. However, in this simulation the collisions from all the balls on each side balance each other out, so the box doesn’t make any consistent progress in either direction. In real air, the situation is similar, but at vastly different scales. The mass of each particle constituting air is absolutely miniscule, so the impact of an individual collision on any object of meaningful size is completely imperceptible. Moreover, each air particle hitting an object has a different speed, and it strikes the surface of that object at a different angle – some hit the object straight on, but some barely graze it. Due to the enormous number of these collisions happening at every instant of time, all these variations average out, and even a small section of surface of any body experiences uniform bombardment. In aggregate, we say that the air exerts pressure on any object present in that air. The magnitude of this pressure depends on the intensity of these collisions across an area. Let’s see how this pressure manifests on our tiny cube. In the demonstration below, you can use the second slider to control the number of air molecules present in this volume: The black arrows you see on the sides of the cube symbolize the magnitude of pressure on these walls. As we uniformly increase the number of particles in this volume, the intensity of collisions, and thus the pressure, also increases. Because the collisions happen at more or less the same rate on every side of the box, the net balance of forces is also maintained and the cube doesn’t move, regardless of how big or small the overall pressure is. This is exactly what happens in the Earth’s atmosphere – everything is constantly squeezed by relatively high pressure caused by the barrage of countless air particles. That pressure is typically balanced either by an object’s material, which resists compression like a spring, or by the air itself that fills the insides of the object. When that inner air is removed, the seemingly innocuous atmospheric pressure reveals its might. The underlying particle nature also shows us that pressure is never negative. Without any particle collisions, we reach the lowest possible pressure of zero. Beyond that, any impacts on the surface of an object create some amount of positive pressure. In the demonstrations we’ve seen so far, the balanced number of collisions on each wall was very important for keeping the objects steady. Unsurprisingly, more interesting things happen when this harmony isn’t maintained. Let’s first investigate this scenario using the tennis balls. In the demonstration below, the slider controls if it’s the left side or the right side that’s shooting more balls: As you can see, if one of the sides has a higher number of collisions, the forces acting on the box are no longer balanced and the box starts to move. The very same situation happens in air, which you can witness in the simulation below. Notice that the volume in which the tiny cube exists has more particles on one side than the other. Observe what happens to cube once you let the time run using the slider: The higher number of particle collisions on one side of the cube creates higher pressure forces on that wall. The uneven forces end up pushing the block to the side. In this demonstration, the pressure re-balances after a while and the cube stops moving. Intuitively, the air exerts an imbalanced net force on the cube only when different parts of that object experience different pressure – it’s the spatial variation in pressure that creates an acting net force. When the difference in pressure between any two points increases, the net force acting on the object also grows. It’s easy to see that a larger number of collisions on the left side of an object would start to exert a net force pushing that object to the right, but, perhaps surprisingly, the same rules apply to any chunk of air itself. In the demonstration below, I once again made one half of the test volume contain more particles than the other half. As you unpause the demonstration, observe the average velocity of molecules in the marked out section of air: The particles on the more occupied side can easily travel to the less crowded side, because there are fewer particles there to collide with and bounce back from. Additionally, each particle in the less populated section is more likely to hit a particle in the more populated section, which will typically cause that particle from the desolate side to bounce back where it came from. The particles end up, on average, traveling from the area of high pressure to the area of lower pressure. Even though we don’t have any clean borders between different sections, we can still see the bulk of particles getting accelerated towards the less dense section. Once again, the initial pressure differences in the test volume dissipate after a while. On their own, these freely suspended pressure variations quickly disappear, but we will soon see how, with the aid of airflow, these areas of different pressure can be sustained indefinitely. In the examples we’ve been playing with, the notion of increased pressure came from an increased number of collisions, which in turn came from an increased number of particles in the area. This shows that, all other things being equal, pressure is tied to the local density of the air, which was very easy to perceive in an increased concentration of molecules. However, the pressure can also grow due to increased average speed of the particles, which in turn comes with increased temperature. As particles get faster, each collision gets more impactful and it pushes on an object or other particles a bit harder, causing the overall pressure to also increase. In the demonstration below, we can simulate this with tennis balls hitting the cardboard box at the same rate, but with different speeds, which you can control with the slider: As we make the balls on one side of the box faster, their impacts also become stronger and the package starts moving to the right, even though the number of collisions per second is equal on both sides. The important point from these discussions is that air pressure exerts force on everything inside it, be it a solid object or any parcel of air. It’s a little unintuitive that the air itself both exerts the pressure and it also “feels” the pressure, but it’s all just a consequence of very rapid motions of particles and the collisions between them happening at an enormous rate. Recall that even in small volumes of air there are billions of billions of particles, and each particle experiences roughly ten billion collisions per second. What we’ve simulated at a micro scale and in slow motion as countable, individual interactions, very quickly smooths out into a uniform and uninterrupted notion of force-exerting pressure. This fact lets us abandon the molecules and their collisions yet again. It’s not a big loss, since counting the number and intensity of collisions was never convenient in the first place, but we can now investigate some other ways of visualizing pressure in a region of air. Visualizing Pressure As we’ve seen in the particle simulations, pressure can vary from place to place. One of the most convenient ways to express this variation is to use colors of different intensities. Let’s see how that simple approach could work here. In the demonstration below, the dashed circles represent regions of high and low pressure – you can drag them around to change their position: This map of pressure is colored with varying shades of red as indicated by the scale below – the redder the color, the higher the pressure. The small triangle ▼ in the middle of the scale indicates the location of the base, static pressure present in the atmosphere. In this simulation we have complete control over where the different locations of lower and higher pressure are. To make things more interesting, each draggable pressure circle has a different strength and range. You can infer this variation from color changes around these points. Let’s put an airfoil in this area to see how it’s affected by the pressure of the surrounding air. The arrows seen below symbolize the force that pressure exerts on the surface of the airfoil at that location. They’re the exact same arrows that we’ve seen acting on the walls of the tiny yellow cube, here we just see them at a larger scale: As you move around the locations of lower and higher pressure, the forces acting on the surface of the airfoil also change, matching what we’ve seen with little cubes bombarded by air particles. The static pressure always exerts some base load, but in the areas of higher pressure the surface forces are higher, and in the areas of lower pressure the surface forces are lower than these base forces. Note that you can also move the pressure circles into the airfoil, but it only serves as a convenience to let you customize the shape of the air pressure field around that body – we don’t particularly care about the pressure inside the solid itself. When we tally up all the pressure forces acting on each piece of the airfoil’s surface, we end up with the net force acting on that object. In the demonstration below, I’m showing it with the big arrow at the center of the airfoil: By changing the distribution of pressure around the airfoil, we can affect the total force that this object feels. The reddish plots we’ve been looking at are correct, but a little inconvenient. Recall that final net force on the object depends only on the differences of pressure – when we uniformly increased the number of collisions on the walls of the tiny cube, it steadily remained in place. This means that the static background pressure doesn’t matter for the cumulative forces acting on an object. It’s only the differences relative to that static pressure that affect the overall balance. This lets us overhaul our visual representation of pressure – we can use no color where the pressure has the static value, use blue color when the pressure is lower than the static pressure, and use red color when the pressure is higher than the static pressure: This is the exact same distribution of pressure that we’ve just seen. All the pressure demos in this section are connected, and here we simply changed the reference point against which we present the pressure variation. If we then throw in the airfoil back into the mix we can now also adjust the arrows representing the forces that the pressure exerts on the surface of that object: The areas of higher pressure still seem to push on the surface of the airfoil, but the areas of lower pressure now seem to pull it. However, I need to emphasize once more that pressure always pushes on the object, and we can only talk about a pulling force when we discard that uniform, pushing contribution coming from the static pressure. In those “pulling” areas the pressure is still pushing, it just pushes less intensely. I will also use the convenient terms of positive and negative pressure, but remember that this refers to their difference from the static pressure. The phrase “pressure lower than static pressure” is a mouthful, so the expression “negative pressure” is very handy, even when it hides the fact that pressure is always positive. While the color variations used here show the true nature of the smoothly varying pressure changes, they make it a little hard to see how quickly those changes happen. To fix this, I’ll also draw the contour lines that join the locations of the same pressure – they’re very similar to lines of the same altitude you may have seen on maps: Every point on one of those contour lines has the same value of pressure, and each subsequent line is drawn at the same increment of pressure – you can see this in the scale placed below the plot. This means that the closer the lines are together, the more quickly the pressure changes in that area. The mathematical concept that describes the direction and rapidness of these changes is known as a gradient. Informally, gradient describes how some property changes from one point to another, and, thankfully, this notion tracks closely with how this word is used in graphic design to describe smooth color changes. Wherever you see a color gradient , this also implies that there is a pressure gradient – the pressure changes from place to place. This spatial variation is particularly important for the motion of air. Recall that the air pressure differences don’t just exert forces on solid objects, but also on the air itself – any small parcel of air is subject to the same whims of pressure forces. Those spatial variations in pressure end up pushing the air around, changing its velocity. Let’s see this in action using the little leaf-like markers that are moved around by pressure differences. In the demonstration below, I’m steadily releasing the markers from the left side – notice how their trajectory changes when you modify the pressure field: You may still find it a little difficult to grasp how pressure differences affect the motion of a parcel of air. Luckily, we can draw parallels between the contour lines of pressure seen on these pressure maps and the contour lines of elevation seen on traditional maps. This lets us build a little pressure-landscape analogy. In the demonstration below, the very same distribution of pressure is expressed as a mountainy landscape. Positive pressure lifts the ground above the base level and negative pressure depresses it below the base level. A parcel of air moves like a marble that loses speed when climbing uphill and accelerates when rolling downhill. You can drag the demo around to change the viewing angle: Notice that when the pressure changes more rapidly and the contour lines are closer, the steepness of the corresponding hill or valley also increases, and so do the forces acting on a parcel of air. If the pressure is increasing by a large amount, it may even make the marker go back. This landscape analogy also shows that the static pressure doesn’t matter for the motion of air parcels, as any changes in static pressure would just lift all the areas by the same amount without changing their steepness. When watching these air parcels move around, you may have noticed that things were a little bit off. For example, it’s possible for air parcels coming from different directions to arrive at the same location, and then continue to travel in different directions. You can see an example of that on the left side of the demonstration below, with the slider letting you scrub back and forth in time: Recall that the markers always follow the local velocity of air, so the motion seen in the left part implies that the air at the location of the meetup of the two markers has two different velocities at the same time, which is not realistic. It’s worth pointing out that the situation seen on right side, where one marker merely intersects the historical path of the other, can be realistic, as long as we’re dealing with an unsteady flow, where the velocity of the air at the crossing location has changed since the first marker was there. For steady conditions in which no changes occur over time, the scenario seen on the right is also not physically correct. We’ll look at some unsteady flows later in the article, but for now we’re interested in steady conditions so the crossing paths of our markers indicate implausible velocities. Even more dubious result happen when we simulate the motion of these markers with an airfoil present in the flow: For most distributions of pressure, the air markers will flow right through the body. This is clearly wrong! The demonstrations we’ve seen so far correctly represent what would happen to individual air parcels and bodies placed in these pressure fields, but those pressure fields themselves were completely made up and didn’t correspond to any physical reality. Our mistake was that we completely ignored any interactions between the pressure of the air and the motion of that air. The flow of air, the pressure of air, and the shape of the objects placed in that air are all tied together – for a given incoming flow speed and the shape of the object, we can’t just arbitrarily arrange the pressure field like we did in our artificial demonstrations. Instead, that pressure field will arise on its own. Let’s see a real distribution of pressure around this airfoil and witness how it affects the motion of air parcels around it: The behavior of air parcels now matches our intuitive expectations – the markers don’t go through the body, and in these steady conditions they also don’t cross paths. We’re now one step closer to understanding how the flow of air takes its shape to move around an airfoil – it’s the pressure differences that cause the flow to change its direction and speed. The pressure field we’ve just seen clearly works – regions of lower and higher pressure guide the air around the airfoil. However, it’s still unclear how these areas emerged in the first place. Let’s try to follow nature’s path to see how this pressure distribution is created and sustained in a flow. Airfoil Flow Before we start building the correct pressure field from scratch, let’s first establish two guiding principles that the flow around any object has to follow. Firstly, the air can’t penetrate solid walls. A valid pressure field should either completely stop the flow at the surface of the object, or redirect that flow to make it travel in the direction perpendicular to the walls. This means that the markers that we track can never get inside the object. Secondly, we also have the restrictions on the relative motion of the markers. For now we’ll only be interested in steady conditions, which means that the markers can’t cross their paths – we expect the ghostly historical trails to never intersect. Let’s first focus on the pressure field in front of the airfoil. In the demonstration below, I created an artificial pressure field in that frontal region, you can control it using the slider: It should quickly become clear that to prevent the approaching air from getting into the object, the pressure in the frontal region has to be positive, so that it pushes the incoming air away. If that positive pressure in front is too low the air can still erroneously flow through the object. If that pressure is too high, the air parcels arriving at the airfoil will turn back and incorrectly cross paths with the incoming air. When the pressure is just right, the air parcels don’t go through the wall, and, at least in front of the object, they also don’t cross their paths. The faster the incoming flow, the higher the pushing force required to slow down and redirect the incoming air. In the demonstration below, you can also control the speed of that incoming air using the second slider: While for slow flows, only a small amount of positive pressure is enough to stop the incoming air, for fast flows, the pressure in front of the airfoil has to become much higher. The pressure needed to stop air at a given velocity is known as stagnation pressure and it’s proportional to the square of that velocity – twice as high speed requires four times larger pressure. Naturally, when there is no flow, no pressure is required as the air no longer tries to flow through the object. In the previous two demonstrations, we manually adjusted the pressure to get the correct result, but in nature this process happens on its own – it’s the flow itself that creates this region of increased pressure in front of the object. As the incoming parcels of air arrive at the surface of the airfoil, they can’t continue going forward, but air parcels from further up ahead continuously want to keep flowing into this region. This compresses the air close to the object, which causes the pressure in front to increase, which then helps to slow down the incoming flow. This mechanism is self-balancing – if the pressure is too low to push away the incoming air parcels, the air parcels will compact the existing air more, causing an increase in pressure. If the pressure is too high, it will easily push the incoming air away, which relieves the frontal area, causing the pressure to decrease. Any fluctuations quickly settle to an equilibrium that balances the pressure in the entire frontal region. Let’s look at the distribution of the positive frontal pressure once more: Notice that the positive pressure isn’t limited to just the close vicinity of the airfoil, but it spreads out much further ahead to gradually reach the value of the static pressure, far away from the airfoil itself. All in all, we have a large area of increasing pressure that starts far away from the body and ends at its surface. Those pressure differences create a pressure “hill” that not only gradually slows the incoming air down, but it also redirects that air to flow around the object. It seems that with our frontal pressure field we’ve easily completed our goal of preventing the air from flowing through the walls of the body. However, our second guideline of non-crossing marker paths is still not fulfilled – this condition is broken above and below the airfoil. Let’s first try to rectify this manually. In the demonstration below, you can control the pressure in these two regions using the slider: While positive values of pressure in those zones make the problem worse, negative values get us much closer to the expected behavior – in the top and bottom areas the markers no longer veer off into different directions. However, that pressure can’t bo too low, otherwise it will pull the markers back into the body. In real flow, these regions of lower pressure arise on their own, but the explanation for this phenomenon is a little less straightforward than what I’ve described for the area of positive pressure in the frontal region. We can get some, albeit a bit hand-wavy, understanding by observing what happens to the air markers when those negative regions are missing. In that scenario, the incoming air parcels no longer reach those areas above and below the airfoil, causing some local depletion of air that has since left those zones. This decreases the pressure in those regions, and that lower pressure attracts the surrounding air to flow into those less occupied spaces. If that lower pressure is too negative, more air will come in and the pressure will rise. If the pressure is not negative enough, those region will get depleted again. Once again, it’s the flow itself that creates the balancing system – without the flow no pressure differences would arise. As we’ll see later on, in more extreme scenarios that negative pressure can alter the flow more dramatically, and the regions of “missing” air get filled through other means, but for now let’s close things up by tweaking the pressure in the rear part of the airfoil: Some amount of positive pressure in the rear prevents the air parcels from smashing into each other after leaving the airfoil. Intuitively, this pressure arises naturally from the flow, because as the air slides off from the ends of the top and bottom sides, it all arrives into the same region, creating some compression. If that compressive pressure in the rear is too low, more air will manage to get in, which will further increase the pressure. If that pressure is too high, it will push the incoming air away, which depletes the area and the pressure decreases. The system balances itself yet again. The quite informal description of these balances that I’ve presented can be formalized mathematically using the Navier–Stokes equations. These equations describe the motion of liquids and gasses, collectively known as fluids, subject to various forces like gravity, or, most importantly for us, pressure. Navier–Stokes equations are notoriously difficult to solve analytically, but a lot of insight about the behavior of fluids can be gained with computer simulations with various degrees of complexity. In this article, I’m also employing simulations to investigate the flow of air around objects. However, the computer models used here are quite simplified and they don’t reflect the full richness of physics involved in the motion of air. These slow-motion demonstrations are intended to present the broad strokes of the delicate interaction between the air and the airfoil, but I would advise against relying on them when building an airworthy airplane. With all of these caveats in place, let’s get back to the pressure distribution around a symmetric airfoil. We’re done recreating the nature-made pressure field, but there is one small aspect that we haven’t yet accounted for. For our experiments, I kept the pressure steady in time so that we could focus on its general outlines. In practice, a pressure field imposed by a fast flow around any object will experience some degree of instability, which you can see in the demonstration below. You can once more drop the markers at any location to track the flow in the area: As the pressure builds up on one side, it redirects the flow, which changes the pressure again. The pressure ends up oscillating back and forth like a swing. The pressure distribution and the flow direction are once again at the mercy of their mutual balance, one affecting the other. We’ll soon see some other examples of these unstable behaviors. As we’ve just seen, the variation in pressure doesn’t just happen in the close vicinity of the airfoil, but it stretches quite far away from the body itself. This means that the velocity of the flow is also affected quite far away from the shape. However, when it comes to the forces exerted on the airfoil, it’s only the pressure right at the surface of the airfoil that matters. Let’s bring back the two tools we’ve used before: surface arrows that show how the air pushes or “pulls” on the airfoil, and the net force arrow that tallies up the net results of these forces: As the pressure field fluctuates, the resulting net force also moves around. Let’s decompose this force into two different components, one perpendicular to the flow, and one parallel to it: The force acting in the direction perpendicular to the flow is known as lift, and the one acting in the direction of the flow is known as pressure drag, or form drag. As the name implies, this component of drag is created by the distribution of pressure around the shape. For this airfoil, the pressure drag is very tiny. While airfoils are specifically designed to minimize the overall drag, most of that force hindering their motion comes from another source – we’ll discuss it soon enough. Notice that as this flow fluctuates, the lift force jumps around, but averaged over time the upward and downward swings of that force end up balancing each other. This airfoil in this configuration doesn’t generate any continuous lift. This shouldn’t come as a surprise since this situation is completely symmetric, so the pressure forces on the upper and lower sides of the airfoil are, on average, completely balanced. However, there is an easy way to disturb that symmetry. In the demonstration below, we’re once again meeting the plain, symmetric airfoil, but this time we can gently tilt it using the slider: The slider controls the so-called angle of attack, which is spanned between some reference line on the body, like the one joining the front and back, and the direction of the incoming flow. I’m showing this angle right in the middle of the airfoil. As we change the angle of attack, the shape that the airflow “sees” is no longer symmetrical relative to the incoming direction of that flow. The velocity and pressure fields adapt in their mutual push and pull to form a new, asymmetric distribution. Notice that the stagnation point of high pressure has moved around, and the little markers that indicate the motion of air now travel on very different paths below and above and below the airfoil. If we then put the pressure arrows back in, we can tally them all up to get the resulting lift and pressure drag. When compared to the previous simulation, I’m scaling down all the arrows to make them fit in the bounds of the demonstration: When this symmetric airfoil is tilted up, the asymmetric pressure distribution generates a lift force that pushes the object up. Conversely, for a downward tilted airfoil, the pressure forces push the airfoil down. Naturally, we’re typically interested in upward-pointing forces, and when the lift generated by the wings is equal to the weight of the plane, the plane will stay in the air without raising or falling to the ground – we’re finally flying. Let’s plot the dependence between the lifting force and the angle of attack of an airfoil – you can see it in the right side of the demonstration below. Note that this plot presents time-averaged and settled values, so you may have to wait a little for the flow to normalize and the lift to start oscillating around the expected value: Clearly, as the angle of attack increases, so does the generated lift. The same thing happens on the other end of the spectrum, where a more negative angle of attack creates more negative lift. Note that for this symmetric airfoil the positive and negative sides of the diagram are just mirror images of each other, so let’s focus only on positive angles of attack. One could naively hope that we could keep increasing the angle of attack to generate more and more lift. Let’s see what happens in practice: Initially, the lift force indeed keeps increasing with the angle of attack, but at some point it plateaus. Once that critical angle of attack is surpassed, the lift force starts to fall after the flow fully develops. What we’re witnessing here is known as a stall. The onset of a stall imposes limits on how much lift the wings of an airplane can generate from merely increasing the angle of attack. Notice that when the stall happens, the pressure distribution on the upper part of the airfoil becomes very erratic – it’s not only the surface pressure arrows that are changing rapidly, but the whole pressure field in that area is very disturbed. Let’s bring in the velocity arrows and markers to get a better feel on what’s going on in that region: At high angles of attack, the flow above the upper part of the airfoil becomes very complicated. If you clicktap in that region to drop a few markers, you’ll notice that the air is trapped in various swirling eddies that are eventually shed to fly away with rest of the flow. We’re witnessing flow separation, where the main part of the flow detaches from the surface and doesn’t follow its shape anymore. The interactions in the complicated flow right above the airfoil affect the pressure field, which then decreases lift. There is a lot going on there, but to understand how these effects arise we have to talk about a property that affects the flow of every fluid: viscosity. Viscosity You might have heard the term viscosity used to describe “thickness” of different liquids, with a classic example that contrasts the slowness of the flow of honey to the rapidness of the flow of water. Viscosity is also a property of gasses like air, but before I describe this concept more formally, we’ll first build an intuitive understanding of what viscosity is and what it does to the flow of different fluids. In the demonstration below, the fluid flows in from the left side, but note that the flow in the top half is faster than the flow in the bottom half, which is reflected by the different lengths of the arrows. Dragging the slider to the left decreases the viscosity of the fluid, and dragging the slider to the right increases viscosity: While we can see some changes to the arrows as we move the slider around, you probably agree that, for this flow, the arrow-based visualization isn’t very rewarding. Let’s add the color-based visualization of speed distribution in this flow: We can now see how viscosity blends the speed variation between different sections of the fluid. For highly viscous fluids, this mixing behavior spreads very easily and the initially distinct velocities of the two layers average out quite rapidly. At lower viscosity these two layers with different speeds remain quite separated. If you make the viscosity low enough, you may even notice that, after a while, the flow develops some interesting wave-like phenomena – we’ll get back to these soon. All this mixing behavior may remind you of a diffusion process, where some quantity, like temperature or concentration, evens out over time. Let’s see some basic diffusion in action. In the simulation below, I filled half of the bottle with with red-dyed water, while the other half is filled with blue-dyed water. The slider lets you control the speed of time: As time passes, the sharp difference between the two layer blends more and more to eventually completely disappear. Clearly, there is some similarity between the diffusion of differently colored dyes and the averaging of velocity that we’ve seen in the earlier example. In our flow demonstrations, viscosity seemed to have controlled the diffusion of velocity. To define it more precisely, viscosity controls the diffusion of momentum, which is a product of velocity and mass. The simplified fluids we’re looking at have more or less constant density, so each equally-sized parcel of those fluids has the same mass. Therefore, if it makes things easier for you, wherever you see the word momentum you can think of velocity, but in more complex scenarios these differences can matter. Let me bring in the previous flow simulation one more time: You’ve probably noticed that, as the flow moves to the right, the size of this blended region increases. When the regions of fluid with different momentums meet for the first time, they barely have any time to average out, and the blending is minimal. As time passes, these regions of fluid get to average out more, similarly to how two different layers of dyed water mix more over time. However, as time is passing, these parcels also keep moving, and that stronger blending happens further to the right. The downstream regions had more time to mix and average out, so the visible thickness of the blended region on the right side is also larger. With higher viscosity, the size of blended region grows much more quickly, which lets us be more precise about our working definition – viscosity controls the rate of the diffusion of momentum. So far we’ve only observed flows with nicely separated horizontal layers, but viscosity averages momentum between any two regions of fluids. In the demonstration below, you can witness how viscosity affects a swirly motion of fluid in a vortex: Notice that with high viscosity any differences in velocity are very quickly diluted out into nothing, but with low viscosity the revolving motion can survive for quite a while. Viscosity has a damping or smoothing effect that makes it much harder to sustain any large variation in a velocity field. Let’s see how this affects the motion of objects in fluids of various viscosity. In the demonstration below, we’re tracking a velocity field close to a very thin plate put directly in the stream of an incoming fluid of adjustable viscosity: With high viscosity, there is a large region of slow down around the plate that regains its speed fairly quickly behind the object. At lower viscosity that surrounding region is much smaller, but it extends much further behind the plate. For very low viscosity we’re once again seeing some more unusual behavior that we’ll get back to in a minute. From the dark colors we can easily see that right by the surface of the plate the fluid doesn’t move at all – it sticks to that surface. This velocity difference between the halted flow at the wall and the moving outer flow gets smoothed out over time by viscosity, similar to how it blended in the flow between two different layers of fluid. As before, with higher viscosity, the velocity averaging process becomes more rapid, and the blended region becomes more widespread. This averaging effect doesn’t just alter the velocity of fluid, but it also affects the plate. In some sense, the viscosity also wants to make the velocity of the surface of the plate to be more like the velocity of the surrounding flow. The viscosity makes the flow want to pull the plate with it, which creates a shearing force that tries to slide the surface of this object away. The net effect is that that viscosity creates additional drag known as skin friction drag that wants to slow down any object moving in it. All of these effects underline why highly viscous fluids are “thick”. Viscosity not only quickly averages any local differences in velocity, which prevents those fluids from flowing easily, but it also represses motion of objects in those fluids – you’ve likely experienced the difficulty of moving a spoon through a jar of honey. The flow of any fluid exhibits tiny, random disturbances. In fluids with high viscosity, these variations are very quickly dispersed, so their motion is rarely erratic. Fluids with low viscosity aren’t as effective at damping motion, and these disturbances can grow to create oscillatory patterns. We’ve seen glimpses of them in the previous simulations, but here is another example: At lower viscosity the flow becomes quite wave-y. Those instabilities happen at the border of regions of fluid with different velocities, like where the slow wake behind a plate is in contact with the fast external flow. In those regions, any tiny random intrusion of slower flow into the faster flow can get magnified and rolled over like a wave. In our discussion of the motion of air around an airfoil, we’ve seen how the flow, the pressure field, and the shape of the body have effects on each other. These influences can be quite dynamic in nature, with distributions of velocity and pressure swinging back and forth in a never-ending fight for dominance. In the demonstration below, we can see a more dramatic example of these battles, where, depending on the viscosity, the flow around a gray cube can take many different forms: With very high viscosity, the flow is completely stable, but as viscosity decreases, it starts to regularly oscillate from side to side, shedding vortices in the process. At very low viscosity, the motion becomes even more erratic. While I can’t easily simulate it here, with further decrease in viscosity, the flow can develop full featured turbulence in which highly irregular and chaotic mixing motions occur at different scales. Turbulent flow stands in contrast to laminar flow, in which neighboring areas of fluid move in an orderly way past each other without any varying fluctuations. Although we’ve put most of our focus on viscosity, which is often denoted with the Greek letter μ, the general behavior of the flow also depends on its velocity u, density ρ, and the size L of the body or container involved in the flow. These parameters are tied together by the Reynolds number Re: Re = ρ · u · L / μ Flows with the same Reynolds numbers exhibit similar behavior, which means that if we make the obstacle size L twice as large and we halve the speed of the flow u, the Reynolds number won’t change and neither will the characteristics of the flow – it will exhibit the same smooth or oscillatory motion. The Reynolds number also “predicts” the onset of turbulence. When we increase the speed of the flow u, or decrease the viscosity μ, the Reynolds number rises. When it reaches a high enough value, turbulence is likely to occur. Let’s quantify the difference in viscosity between different fluids. The precise values aren’t that important to us, but to briefly be a bit more formal, viscosity is expressed in units of pascal-seconds, or Pa·s. To let us use more manageable numbers, the following table uses millipascal-seconds, or mPa·s: honey ~10000 mPa·s olive oil ~100 mPa·s water 1.0 mPa·s air 0.018 mPa·s These values are measured at 68 °F20 °C, but many fluids like oil get much less viscous with increased temperature. As expected, honey is significantly more viscous than water. Compared to water, the viscosity of air is around 50 times less still, but even a very low viscosity has effects on flow and its interaction with solid walls. To understand how viscosity arises in gasses like air, we have to once more get back to the world of particles. So far we’ve been watching them from a distance, with individual collisions barely perceptible in the moving swarm. This time we’re going take a closer look at these interactions. In the demonstration below, you can experience a simplified simulation of two molecules colliding in space. Each molecule represents nitrogen or oxygen – these two elements constitute the vast majority of air, and, in normal conditions, each one consists of two atoms. You can drag the orange particle around, and once you let go I’ll automatically aim it so that it hits the blue particle. The speed of the orange molecule is four times larger than the speed of the blue one: Notice that after the collision, it’s the orange molecule that’s slow, and it’s the blue one that’s fast. In this demonstration the two particles have the same mass and they collide straight on, so they simply end up trading velocities. More generally, particles of different masses that strike each other at different angles will exchange some amount of momentum. Recall that the heavier the particle, or the faster it moves, the higher its momentum. Let’s see how this behavior ends up affecting the average velocities of larger quantities of molecules. In the paused demonstration below, air molecules are grouped into two different parts. The air in the blue region has higher velocity than the air in the red region, which you can see in the black arrows showing the average velocity in those regions. Notice what happens to these averages as you let time flow by dragging the slider: At the very beginning, the average velocities in these two sections are visibly different, but they quickly even out when fast particles from the blue region flow into the slower red region, and the slower particles from the red region move into the faster blue region, balancing the initial velocity differences. Moreover, some of the faster particles collide with slower particles in the red region and some of the slower particles collide with faster particles from above. The faster particles lose some of their higher momentum, while the slower particles gain some of the momentum. All of these effects “dilute” some of those average velocity differences between the two regions. You may also remember that when we observed a flow of fluid around a flat plate, that fluid wasn’t moving at all right on the surface of that plate, because it was stuck to it. Let’s see how this behavior may arise on a microscopic scale. In the demonstration below, we’re watching the familiar air particles right next to the surface of an object. To make tracking easier, I’m highlighting some of the particles in the vicinity of this surface: When seen at a very large magnification, this surface, like almost all surfaces, isn’t perfectly smooth and has various peaks and valleys. The particles hitting these irregularities get bounced in more or less random directions. Some of the unlucky molecules can even get stuck for a while in these local crevices. Close to the surface, the random collisions with peaks and valleys prevent the particles from making bulk progress in any direction. The average velocity of the air flow by the wall is more or less zero. Some molecular interactions between the particles and the surface can also prevent the fluid from moving. This sticking behavior is known as the no‑slip condition and it holds true for most typical flows of fluids that we experience day to day. It’s only in extreme conditions of very rarified gasses in the upper parts of the atmosphere or flows in microscopic capillaries that can break this assumption. Let’s leave the world of particles behind for the last time and see how these two effects play an important role of influencing the airflow close to the surface of any object. Boundary Layer Let’s take another look at a thin plate placed in the stream of incoming fluid: From this broader perspective, it’s hard to see how the flow interacts with the surface of that plate, because the effects of viscosity are limited to the region close to that surface. Let’s focus our attention on the small area that I’ve outlined with a dashed line, right in the top part of the plate. Here it is zoomed up close: We can once more see that, due to the no-slip condition, the velocity is zero at the wall, and then it grows to meet the velocity of the flow further away from the surface itself. What we’re seeing here is known as the boundary layer, which spans the region between the surface of the object and the “outer” flow, which is mostly unaffected by the presence of the object. Because the velocity in the boundary layer smoothly approaches the speed of the outer flow, it doesn’t have a well-defined end point. One of the choices is to agree that the boundary layer ends where the speed reaches 99% of the speed of the surrounding flow far away from the solid surface. Let me visualize this boundary in the flow using a dashed line: As we move with the flow along the distance of the plate, the viscosity keeps averaging out the velocity differences, making the boundary layer thicker – this is similar to what we’ve seen at larger scales with highly viscous flows around objects. Let’s quantify the distribution of speed in the boundary layer a little more precisely. In the demonstration below, I put the velocity arrows back in. I then connected the ends of these arrows with a thin line to show a profile of velocity at that location along the surface: Notice that, initially, the velocity close to the wall increases almost linearly, but then it smoothly tapers to reach the speed of the external flow. The velocity profile close to the surface has a certain steepness, which I’m showing with the white dotted line. This line determines the amount of skin friction drag at that spot – the closer to the surface, or more horizontal, the line is, the higher the skin drag. As the differences in velocity become less severe, the force with which viscosity wants to drag the surface with the flow also decreases. In the conditions present in the demonstration, the skin friction drag decreases over distance. At this point you hopefully have an intuitive grasp of how viscosity affects the flow close to the surface of the object. From our earlier discussion, you may also remember that pressure differences also affect how the flow behaves, with parcels of air slowing down when climbing the hill of increasing pressure and accelerating on the downhill of the decreasing pressure. In the boundary layer flows we played with, the pressure distribution was more or less constant in the investigated region. Let’s see how the flow changes when we vary that pressure. In the top part of the demonstration below we see the exact same view of velocity we’ve experimented with so far. In the bottom part of the demonstration below you can see the pressure distribution in the boundary layer, which you can change using the slider below. If the pressure decreases in the direction of the flow in the boundary layer, we say that the pressure gradient is favorable. Favorable pressure gradient accelerates the air, and the boundary layer doesn’t grow as quickly, since the slowdown caused by viscosity is opposed by that acceleration. When the pressure increases in the direction of the flow, we say that the pressure gradient is adverse. Adverse pressure gradient pushes against the direction of motion of the air. Far away from the surface, the air has enough momentum that the adverse pressure merely slows the flow down. However, close to the surface, the flow in the boundary layer was slow in the first place, so a pushing adverse pressure gradient may even reverse the direction of the flow. When the flow in the boundary layer gets reversed, we say that the boundary layer separates. This region of reversed flow can form a sort of wedge that can lift the rest of the flow away from the surface. Let’s take a step back from the subtleties of boundary layers to see how what we’ve learned corresponds to behavior of a flow around an airfoil. Let me once more bring up the demonstration that brought us here in the first place: As we move across the surface of the airfoil, the high pressure at the stagnation point up front gradually decreases to reach minimum close to the “peak” of that curved surface. Across this transition the pressure gradient is favorable, and that distribution works in our favor – the boundary layer stays nicely attached to the surface. However, as the air reaches the valley of the lowest pressure, it then has to start climbing back up to reach the slightly positive pressure in the rear of the airfoil. For small values of the angle of attack, the pressure pit from which the air has to climb out is not very deep and the adverse pressure gradient isn’t very strong, so the boundary layer remains attached. As we increase the angle of attack of the airfoil, the pressure on top becomes lower and lower. For even higher angles, the adverse pressure gradient becomes so strong that it eventually reverses the flow in the boundary layer, creating separation. Let’s look at this region up close to see how the arrows of velocity in the separated region point in the other direction: If you clicktap to add markers in the bottom right corner of the simulation you’ll notice that many of them move against the bulk of the flow – the boundary layer and the flow have separated. We’ll get back to looking at airfoils soon enough, but we still have a few things to wrap up in the world of boundary layers. The boundary layers we’ve looked at so far were laminar – the layers of fluid with different velocities flowed in an orderly way on top of each other. However, at higher flow speeds and over larger distances, or at high Reynolds numbers, the flow in the boundary layer transitions to a turbulent flow: Be aware that what you’re seeing here is a very simplified simulation of a turbulent boundary layer. Turbulence is inherently three dimensional and it contains various evolving structures of different sizes that are extremely computationally expensive to evaluate in detail. Thankfully, you can find many videos of computer simulations and real flows showing turbulent boundary layers. While the laminar boundary layers we’ve seen in the past exhibited very organized flows, the turbulent one is very chaotic, with large and small swirls causing the flow to mix very rapidly. The transition from laminar to turbulent boundary layer happens spontaneously, but for a given flow speed, the location of the transition depends on surface roughness, steadiness of the flow outside of the boundary layer, and presence of pressure gradients. At any given moment, the velocity profile in the turbulent boundary layer is very unsteady, but it can be averaged over time to get the mean distribution of speed. Let’s compare the time-averaged profiles of the laminar and turbulent boundary layers: In the dynamic simulation of the turbulent boundary layer, we saw how the slower flow close to the surface rapidly mixed with the upper regions of the flow. This slows down those faster sections, and we need to go farther away from the surface for these sluggish intrusions to stop affecting the flow. For this reason, the turbulent boundary layer is thicker and grows faster than a laminar boundary layer. On the other hand, the strong turbulent mixing causes the fast external flow to get close to the body, so the overall velocity profile by the surface increases much more quickly in the turbulent case as opposed to laminar case – I’m showing that with white dotted lines. Recall that the more horizontal the velocity profile at the surface of the object, the bigger the skin friction drag – a turbulent boundary layer has higher skin friction drag than a laminar layer. Despite the cost of increased friction drag, a turbulent boundary layer is often beneficial. Because of that higher velocity closer to the surface, a turbulent boundary layer is more resistant to adverse pressure gradients and it can stay attached to the surface of an object for longer distances. For some objects like golf balls, which purposefully make their boundary layer turbulent by roughing up the surface with little dimples, the delayed separation also decreases the pressure drag caused by uneven pressure distribution. That reduction more than compensates for the increased skin friction drag, making the dimply golf balls fly farther than equivalent smooth balls. For airfoils, a turbulent boundary layer delays separation of the flow, which can help prevent stall at higher angles of attack, but at normal cruising conditions the increased skin friction becomes an important drawback. For many aerodynamic shapes in typical conditions, the skin friction frag is the primary contributor to the total drag that these objects experience. As we’ve seen, by increasing the angle of attack on an airfoil, the lift force grows up to a certain limit, at which the boundary layer separates over most of the upper surface. By staying under this limit, a symmetric airfoil can safely generate lift force. However, when it comes to angle of attack and lift, the shape of an airfoil isn’t particularly unique in its lift-creation capabilities. Most simple elongated shapes generate lift when put in a flow at an angle of attack. In the demonstration below, you can tilt a flat plate and see the forces exerted by the pressure field around it: You may be surprised to see that, at small angles of attack, this flat plate also generates lift. An airfoil-like shape is not a requirement for lift generation. After all, paper airplanes with their flat wings can fly just fine. Lift is just an outcome of the pressure distribution created and sustained by the flow. Although it doesn’t take a sophisticated shape to generate lift at an angle of attack, a well-designed airfoil can often create more lift and with lower drag. In the last section of this article, we’ll explore how other variations to the shape of an airfoil can affect its characteristics. Airfoil Shapes Let’s go back to the simple symmetric airfoil we’ve been playing with thus far. This time, however, we’re able to control its thickness using the slider: Notice that as we increase the thickness of the airfoil, the pressure on the top and bottom sections of the shape becomes more negative. For this symmetric airfoil at 0° angle of attack the thickness doesn’t change much other than increasing the pressure drag. However, if we break the symmetry of the shape, we can use thickness-dependence to make one side of the airfoil have a higher negative pressure than the other. In the demonstration below, you can control the “thickness” of the upper surface of the airfoil using the slider: Notice that an asymmetric shape creates an asymmetric pressure distribution, which ends up creating lift without any changes to angle of attack. With some slight tweaking of this shape we finally recreated the asymmetric shape we first saw on the airplane in the early sections of this article. Naturally, when combined with an increasing angle of attack, this airfoil will generate even more lift until it eventually reaches stalling conditions: While symmetric airfoils are sometimes used in acrobatic airplanes, which often find themselves flying upside down, most typical planes use an asymmetric airfoil shape. The underlying mechanism of lift generation by changing the angle of attack or by shaping the object differently is ultimately the same – we’re changing the placement and orientation of the surface of the body relative to the incoming flow. The flow reacts by changing the velocity and pressure distribution, and the resulting pressure field creates the forces on that object. This all means that we have a lot of flexibility in how an airfoil is shaped, as long as the resulting pressure distribution fulfills the design goals of achieving a certain amount of lift while minimizing drag. For example, in some applications it’s important to minimize the skin friction drag caused by a turbulent boundary layer. Some laminar flow airfoils achieve this by shaping the airfoil to move the “pit” of negative pressure further to the back of the airfoil: The favorable pressure gradient between the front and the lowest pressure point extends over a longer distance across the surface of this airfoil, which, at least in principle, helps to keep the boundary layer laminar to keep the skin friction low. Notice that even this unusual airfoil had a rounded front and a sharp back. The roundness of the front helps the air smoothly flow around this area at different angles of attack, and the sharp back reduces the pressure drag by avoiding the separation of the flow. The velocity of the flow around the airfoil is also a contributing factor to the design of the shape. Let’s look at the speed distribution in the flow around a simple asymmetric airfoil using the varying colors and markers: The flow above the airfoil is faster than the incoming flow as indicated by brighter colors. The markers that start in the same line don’t end up sliding off the airfoil in the same formation – the ones on top are further ahead. This is particularly visible for larger values of the angles of attack. This acceleration in the upper part becomes another point of consideration for airfoil design. While commercial airliners don’t fly faster than the speed of sound, the accelerated flow in the top part of an airfoil can break that barrier. This creates a shockwave that can sometimes be seen in flight. Modern airliners use supercritical airfoils that are designed to reduce these drag-causing shockwaves by carefully controlling the speed of the flow around the wing. Planes designed to fly above the speed of sound use supersonic airfoils that are quite different from the shapes we’ve seen. These airfoils have a thin profile and their front edge is sharp and not rounded. Supersonic flows of air are more complicated than what we’ve explored in this article, as variations in density and temperature become an important component of the behavior of the flow. Many of the airfoils used today are designed specifically for the plane they’ll be used in. Moreover, that cross-sectional shape may change across the length of the wing. Real airplanes are three dimensional and the overall shape of the wings also significantly affects the lift and drag of an airplane, but ultimately all the resulting forces are an outcome of interactions between the flow and the body. Further Reading and Watching John Anderson’s Fundamentals of Aerodynamics is a very well-written textbook on aerodynamics. Over the course of over a thousand pages, the author presents a classic exposition of the motion of fluids and their interactions with bodies put in those flows. Understanding Aerodynamics by Doug McLean is a great textbook that takes a different approach of explaining aerodynamic phenomena using physical reasoning. For me, the crowning achievement of the publication is showing that many popular explanations of the origins of lift are either incorrect or they’re based on merely mathematically convenient theorems. The author’s video lecture gives an overview of some of these misconceptions. In this article, I’m using computational fluid dynamics to simulate the flow of air around different objects. For an approachable introduction to these methods I enjoyed Tony Saad’s series of lectures on the topic. For an alternative, and slightly more rigorous approach, Lorena Barba created 12 steps to Navier-Stokes. That website is also accompanied by video lectures. Finally, YouTuber braintruffle created a series of beautiful videos that start with the behavior of fluids on a quantum scale and build up increasingly abstract models that can be used in more practical applications. The videos are packed with interesting takes on fluid mechanics, and they’re worth watching for their visuals alone. Final Words If you were to sit on a flying airplane and look out the window to glance at its wings, you’d often have a hard time seeing anything going on. However, in that crisp clearness of air whose invisible flow sustains the varied pressure field, lies the hidden source of lift that overcomes the might of gravity to keep the plane safely above the ground. Since the first human flight, we’ve now mastered the art of soaring in the skies by bending the flow of air to our will, using physical quantities like pressure and velocity to help shape our designs. These tangible concepts are ultimately just a manifestation of motions and collisions of billions of inanimate air particles that somehow conspire to assemble the forces we need. I hope this deeper, technical exploration of airfoils hasn’t diminished your appreciation of the greatness of flight. Perhaps paradoxically, by seeing how all the pieces fit together, you’ll find the whole thing even more magical. If you enjoy these articles, consider supporting on Patreon. Copyright © 2024 Bartosz Ciechanowski",
    "commentLink": "https://news.ycombinator.com/item?id=39526057",
    "commentBody": "Airfoil (ciechanow.ski)2110 points by todsacerdoti 17 hours agohidepastfavorite240 comments hubraumhugo 3 hours agoCiechanowski is likely the best content producer we know, absolutely fascinating reads. Imagine having such a person as a teacher - he could probably excite students about any scientific topic. I'd love to spend my time working on such articles when I'm retired :) reply larodi 36 minutes agoparentWithout doubt. Question is why so many people who try to teach approach it like it’s 1878. reply porphyra 16 hours agoprevIt's pretty interesting that many airfoils used in aircraft design were derived by NACA in the 1920s and 1930s [1]. You'd think that with modern computer software it would be possible to design better airfoils, but apparently, those shapes have already been mathematically perfected by hand and by experiment. So nowadays if you want to design a plane you can just look up the desired NACA airfoil from a table based on the speed, air pressure, etc that you require. [1] https://en.wikipedia.org/wiki/NACA_airfoil reply namirez 13 hours agoparentNot quite true! Modern airplanes are way more complex. First of all, all modern airplanes have supercritical airfoils which go back to the 60s and 70s. Secondly, the airfoil of the wing root is typically different than the wing tip. Finally, new composite wings are adaptive during flight. They change their shape slightly to maximize efficiency. reply H8crilA 12 hours agorootparentCase in point would be modern gliders (sailplanes). One simple parameter that describes their aerodynamic performance is the maximum achievable Lift/Drag ratio, and that dimension-less ratio has climbed from ~30 in the 1960s to as high as 75 today. That means modern gliders can, using the same altitude/energy, go over 2 times further horizontally. The L/D is not the ultimate decider of performance but it is quite representative of the aerodynamic performance improvements. BTW, all lift based flying objects have an L/D ratio (which depends mainly on the airspeed), this includes birds, fighter jets, commercial airliners; and the discrepancies can be pretty interesting. For example if one looks at the L/D of the Concorde vs a subsonic jet it becomes clear why it was so damn expensive to operate. Or why the U-2 looks like a glider :). I cannot find any aerodynamic performance data on any famous long endurance (>24h) unmanned drone, but I bet it's rather high as well. reply dmoy 11 hours agorootparent> Concorde Another good example is the space shuttle. It does actually glide back down. But it glides like a brick at first (1:1 during its initial braking into the atmosphere), and then like a less dense brick (2:1 while it's still supersonic), and then like a brick with shitty wings (a whopping 4:1 or whatever on final approach). Which is about what the Concorde is during landing, 4:1, yea. Pretty crazy stuff (Obviously the space shuttle was a tradeoff for, you know, getting it into orbit via rocket) reply travisjungroth 10 hours agorootparentYour numbers are right but your analogies are misleading. I get “glides like a brick” is hyperbole, but you’ve added enough detail I can see people taking it seriously. A brick’s L/D is much worse than 1:1. I’m seeing people say 1:10 online, but I can’t find a source and I think that’s incredibly high. A real brick is going to tumble and essentially not make any lift. A less dense brick will have the same L/D. L/D is about the shape, not the mass. reply spenczar5 6 hours agorootparentSpace Shuttle pilots themselves referred to it as “The Flying Brick,” I think that is mostly what they were referencing. It was a term of endearment :) reply dmoy 6 hours agorootparentYea sorry, this was it. I didn't mean it literally has the glide ratio of a brick I mean it looks like a brick and it flies reply techdragon 1 hour agorootparentDespite knowing about its nickname… I found myself picturing a paraphrasing of the classic physicist’s “spherical cow in a vacuum”… “Steerable brick in an atmosphere”… or the slightly more accurate “orientable brick in an atmospheric reentry regime”… reply kqr 4 hours agorootparentprevI guess you get maximum L/D out of a brick by giving it some serious backspin (which is a stable configuration so it might be able to maintain it on the way down) to set up the lifting circulation around it. But would this count? reply taneq 7 hours agorootparentprevI’m trying to get my head around the L/D being independent of mass. Does lift scale with airspeed at the same rate as drag? Or is L/D only considering lift-induced drag (whatever the term is) and not total drag including parasitic drag? reply kqr 4 hours agorootparentThe way I've had it described is that when two objects of the same shape pitch for optimal glide (i.e. highest L/D) then the heavier one will reach the ground sooner (go faster), but both will take the exact same path and land the same distance away. In other words, same L/D. This is not the explanation you are looking for, but \"aha the heavier object takes the same path but drops faster\" was what made me okay with L/D not depending on weight. reply teraflop 7 hours agorootparentprevRoughly speaking, both lift and drag are proportional to v^2 for a given geometry. Neither lift nor drag has anything to do with mass. They are entirely determined by the surface of the object, and are not affected at all by the interior properties, including density. reply travisjungroth 7 hours agorootparentprevL/D changes with angle of attack. You can have a different airspeed at the same angle of attack and the ratio does stay the same. I think the Wikipedia page gives good descriptions. Something a bit misleading done generally is aircraft don’t have one L/D, they have many, depending on angle of attack. When you see one number, it’s usually the best one. reply harshreality 5 hours agorootparentprevAren't they comparing high-supersonic to supersonic to subsonic? I thought the point was that aerodynamics change from one domain to the next as shockwaves cause flow separation or eddies on or behind surfaces. reply Lance_ET_Compte 6 hours agorootparentprevI saw the space shuttle land once. From my perspective, it seemed to drop like a rock (fast!) and then as it got closer to the ground, it started \"flying\". I'd never seen anything like it. reply hanche 2 hours agorootparentThe flare-out is really difficult to get right, from what I’ve read. As soon as you start leveling off, air speed is going to drop really fast, and you have very little time to get that bugger on the ground before you get in a stall. They used to practice using a modified jet, flying from high altitude to a landing with thrust reversers engaged all the way! reply DiggyJohnson 4 hours agorootparentprevFor whatever reason the way I think about this phenomenon is like autorotation in a rotary craft. reply jameshart 12 hours agoparentprevNACA airfoils aren’t so much a numbered set of standard, tested designs as a useful set of mathematical curve formulae for making airfoil-like shapes, and describing them using parameters. NACA published empirically determined wind tunnel performance numbers for selected parameters, which was useful research but not a declaration of ‘these are the good values, you should only use these’. It’s a bit like saying all satellites follow TLE orbits derived by NASA/NORAD in the 1950s - they do, but only because that’s just a standard way of writing down the orbital elements that describe a particular ellipse, not a catalog of ‘known good’ orbits. reply g129774 14 hours agoparentprev\"better\" airfoils are used in experimental craft design. for example mark drela wrote and used xfoil to design wings for mit's project daedalus, a human powered long distance flight aircraft. this is the case where, like sibling commenter stated, you need that extra % to get better performance characteristics. you can still run xfoil, it's a delightfully oldschol fortran program. reply petsfed 14 hours agorootparentI have a friend whose PhD is in computational flow dynamics, as applied to airfoil design. He works almost exclusively in fortran (which is wild to me, for someone under 35, but I guess its the \"industry\" standard). I just asked him about xfoil and he observed that there are more modern programs for (as he put it) more \"realistic/complex\" designs, but said it was a good starting place. reply aredox 10 hours agorootparentBecause Fortran was the industry standard for any heavy scientific calculation (like aerodynamics or nuclear bombs), the Fortran compiler has been optimised to death... And thus Fortran is still the industry standard. reply g129774 14 hours agorootparentprevoh i'm sure state of the art has advanced since then. i have the necessary physics background, but it's not otherwise my domain: i once used xfoil to design an airfoil for an autonomous model glider as a hackerspace project back when i had free time for things like that many years ago. the glider was also loaded into x-plane to develop and test the autonomous part. so whenever various experimental aircraft projects popup, i'm likely to look into them, and then also notice the peculiar foils they use. reply jayyhu 14 hours agoparentprevNACA and the other published airfoils[1] are generally a good starting point for hobbyist/RC folks. However if you want to eke out that last 5% bit of performance (ie. you are a company/institution), you would start with one of the above airfoils and optimize them to fit your flight envelope & mission profile. Here's a neat video of optimizing a round profile into an airfoil optimized for supersonic speeds [2]. [1] http://airfoiltools.com [2] https://www.youtube.com/watch?v=FHYTBguMfWc reply roeles 3 hours agoparentprevFor gliders the naca airfoils have been abandoned around 1970, when the first glasfiber composite gliders were made. We mostly use airfoils from German professor Wortmann (FX) , Quabeck (HQ) or Boermans (DU). The naca airfoils are still used in wind turbines though. reply bouchard 14 hours agoparentprevNot really, they're a nice first step though, or if you require something \"good enough\". reply colechristensen 15 hours agoparentprevEh, it's more like you can get to 90% of where you want to be with the 100 year old airfoils (though several of the other series are quite a bit newer). https://aviation.stackexchange.com/questions/20798/are-naca-... >You'd think that with modern computer software it would be possible to design better airfoils, but apparently, those shapes have already been mathematically perfected by hand and by experiment. No, modern computer software indeed does better, but there's not a whole lot of room to do better, small changes to bump performance a percentage point or two. These are optimizations which can be (and are sometimes) skipped for many commercial projects. reply CPLX 12 hours agoparentprevThe big variation now though is that the airfoil shape varies quite a bit from one end of the wing to the other. reply jabl 4 hours agorootparentDifferent airfoil shapes for the root and tip were common already in WWII era planes. reply quickgist 6 hours agoprevThis is one of the best thought out UX I've ever seen. It's extremely well laid out and simple to navigate through, all the design choices are very meaningful, UI elements (like the unit conversion) are available inline when you need them... Not to mention the content itself is great. I'm taking notes. reply IncreasePosts 6 hours agoparentYou probably want to check out the rest of his site, which is pretty much on par with this: https://news.ycombinator.com/from?site=ciechanow.ski reply hanche 2 hours agorootparentHis mechanical watch piece is really something to behold. reply akouri 5 hours agorootparentprevI'd love to know how long it takes him to make each one of these \"interactive essays\" reply wraptile 4 hours agorootparentA long time would be my guess but writing interactive articles is much more engaging and addicting. We've started adding interactive stuff to our docs and it is really engaging so the spent hours just fly by! reply matheusmoreira 2 hours agorootparentprevI'd love to read about how he does it. How talented do you have to be to not only learn all this stuff but also model them in 3D and simulate them in real time and interactively? reply kqr 1 hour agorootparentGuessing from personal experience, I would not be surprised if 70 % of the domain knowledge is learned in the process of writing and modeling. Whenever I encounter a tricky subject I'm having a hard time learning, I start writing an article explaining it to someone else. It really forces me to confront the gaps of my knowledge because I can see so clearly that \"Wait, I can't explain what happens between these two steps here. What am I missing?\" reply Ringz 2 hours agorootparentprevI would also be interested in knowing which software is used? reply 9dev 39 minutes agorootparentHah. That question comes up on every single one of his explainers. The answer is none; he hand-crafts the JavaScript and WebGL shaders. From the design language, I’d guess he has built up a library of templates and snippets to draw from by now, but all in all, each of these pages is a bespoke work of art. reply ImHereToVote 47 minutes agorootparentprevLooks like pure JavaScript using the WebGL Canvas. reply CrimsonCape 13 hours agoprevI grew up duck hunting and learned intimately how ducks use their wings and the variations of shapes at different velocities as they slow down to land on the water. I also grew up boating and swimming and have a likewise similar understanding of paddling, tracking a canoe straight, and using boat motor trim to \"get on the plane\". I guess I struggle with articles like this because it's already so intuitive as a mix of air and fluid dynamics. In fact, fixed airfoils are so boring when you see what a duck can do. https://www.youtube.com/watch?v=-3CVZYY8xS4 So for all the fancy physics talk, this duck is literally just paddling air with his wings. The same physiology I use to stay afloat when treading water while swimming. reply turtledragonfly 8 hours agoparent> this duck is literally just paddling air with his wings Grossly speaking, sure. But I feel like this simplifies away a lot of the interesting bits. It's not as simple as, say, someone on a canoe paddling. Why is the duck's wing shaped just so, and not another way? Why does it move its wings just so instead of another way? I'm reminded of an analysis of fruit fly wings, showing how they re-capture energy from the air when flapping[1]. Maybe the duck is doing similar; I don't know. Of course, these animals make it look easy, thanks to millions of years of evolution (: https://www.nature.com/articles/s41598-021-86359-z reply solardev 13 hours agoparentprevBut when that fancy duck wants to get to Paris in a hurry, it still has to hop on a fixed-wing Concorde like everyone else. reply CrimsonCape 9 hours agorootparentHummingbirds go to mexico to vacation a lot more than I do. Imagine if humans had a manadatory 2000 mile trip and 6 month layover twice a year to survive. Once you have technology that enables flapping type motion, it's opening up the applicable physics to like 6 degrees of freedom versus zero in current wing technology (fixed = 0 degree of freedom); much more complex and interesting to study. How else will we move toward ornithopter style wings, or vehicles that can hover via wing movement. reply KeplerBoy 3 hours agorootparentRotating wing aircraft have no problem hovering mid-air. All we need are a handful of breakthroughs in battery tech. reply seer 2 hours agorootparentRotating wing aircraft have problems with supersonic flight - and the wing (rotor) itself reaches supersonic much quicker than the aircraft itself, thats why helis are usually slow, compared to aircraft. I guess “supersonic wing flapping” would have similar problems, but maybe there are more clever solutions than can be modeled, with so much degree of freedom? And is “supersonic flapping” even possible? reply kjkjadksj 12 hours agorootparentprevGive it a strong selective pressure towards speed and a few million years and you will have your supersonic duck. reply solardev 12 hours agorootparentIntercontinental ballistic mallards? Just another trillion-dollar boondoggle from the military-ornithological complex. reply LargoLasskhyfv 12 hours agorootparentprevReverse dragooning by expelling fiery farts made of hypergolics fueled by fantastic fermentation? reply bloopernova 9 hours agorootparentSomething like that is featured in Terry Pratchett's Discworld series of books. (Don't spoil the book it's in!) GNU Terry Pratchett reply solardev 8 hours agorootparentThere's also that Harry Potter spinoff movie in which he becomes a supersonic corpse with a farting jet-butt in order to visit some pretty redwood parks: https://www.inverse.com/article/17614-how-swiss-army-man-mad... reply LargoLasskhyfv 8 hours agorootparentprevSomething similar already happened in reality in another evolutionary chain: https://en.wikipedia.org/wiki/Bombardier_beetle (on a much smaller scale) reply megablast 3 hours agorootparentprevThe arctic tern flies from the north pole to the south pole. reply invalidlogin 5 hours agorootparentprevI once ate duck in Paris. reply mondrian 13 hours agoparentprevFixed airfoil physics become really important at very high speeds. reply jameshart 12 hours agorootparentOr if your Cessna isn’t equipped with a flapping system. reply mometsi 4 hours agorootparentAmusingly, the flappy Cessnas were designed with the engine mounted right in front of the windshield. Where else could it possibly go? https://gallery.vtol.org/image/P2xYJ reply estiaan 6 hours agoparentprevI think you might be experiencing a bit of a dunning-kruger effect Also, in my experience there’s a huge difference between having an intuition for something and having an understanding of something to the point where you could model it. reply aredox 13 hours agoprevFor an example of a flat-ish airfoil that performs well enough for model airplanes (and is easier to build than a NACA & co airfoil), see the KFm airfoil family: https://en.wikipedia.org/wiki/Kline%E2%80%93Fogleman_airfoil Very useful when making model airplanes out of foamboard. reply kqr 12 hours agoparentHuh, odd. I was under the impression that for swept/delta winged paper airplanes one wants a smooth top surface to encourage attachment and any steps on the bottom to provide decalage. (I.e. the area ahead of the step acts as a canard-like surface.) Is this an airfoil that works for tailed aircraft but not tailless ones, perhaps? Edit: I just skimmed the book on paper planes by KF and indeed they are using the variation with the step on the bottom for their paper planes. I'm actually even more surprised now. How on Earth did they manage to patent the idea of reflex on a delta wing to give a tailless plane stability? This seems like the thing that (a) was known since early human-carrying gliders, and (b) implicitly discovered by anyone that folds a lot of paper airplanes. I will definitely read their book in more detail. reply skykooler 6 hours agorootparentAttachment isn't as much of an issue with paper planes since the small size and low speed give much more favorable Reynolds numbers. reply kqr 4 hours agorootparentCould you elaborate on that, please? This is just at the edge of my understanding and I'd like to learn more. reply skykooler 3 hours agorootparentYou can see the effect in the second animation of the linked page, but the basic idea is the lower the Reynolds number, the less likely for flows to separate and become turbulent. Shrinking the scale and slowing the airspeed both lower the Reynolds number, so paper planes have vastly different aerodynamics to full size aircraft. reply taco-hands 6 hours agoprevRegardless of all the exacting comments, this is one of the most astonishing accounts and content on a topic I've seen for years; beautifully delivered and interactive to boot. reply denton-scratch 23 minutes agoprevThat page made my laptop fan start roaring. reply onetimeuse92304 14 hours agoprevI wish every presentation on how planes fly started with an actual flat plane. A wing that has a flat crossection. I think the shape of the airfoil of the wing is absolutely distracting and prevents people from understanding what is really happening. Every person who ever stuck a flat object outside the window of a moving car knows that you do not need a fancy shape to have lift. And so many people are stuck thinking that the shape of the airfoil is responsible for the plane to be able to fly, supposedly because the air needs to run a longer way around the foil above the wing than below the wing. And this somehow causes pressure difference due to Bernoulli law and this is what keeps the plane up. Which is almost total BS because planes can obviously fly inverted. Now I admit I only skimmed the article, and although the animations are beautiful, I am missing what really is key to understanding of what is happening. I am looking for a bigger, far away view of the wing and showing what happens to the air BEHIND the wing. Because how the plane really works is as it flies forward, it diverts large masses of air downwards. It pushes off of air. Part of the air is diverted by the lower portion of the wing, but the much larger portion of lift is generated by larger masses of air above and behind the wing. Those can be thought as being sucked down behind the wing (if you look at it from the point of view of a stationary air mass, not from the point of view of the wing). And the main role of the airfoil is to keep that mass of air behind the wing stuck to the airfoil at wide range of angles and speeds as possible, because a flat sheet is very poor at doing this. reply dameyawn 13 hours agoparentYea, I agree and try to explain it this way to friends. Airfoils help, but it's ultimately just the wing pushing air down and why planes can fly upside down. FWIW, aerospace engineering degree, used xFoil, did tons of fluid sims, etc. reply p_l 13 hours agorootparentAnd it's an \"even more wrong\" explanation than the \"lies for children\" diagram used in school physics class. For reference, actual \"proper\" discussion of lift in textbooks on aerodynamics have tendency to start with a sphere/cylinder. reply dameyawn 3 hours agorootparentThere is no lift on a sphere or cylinder without rotation dude. The whole point of parent post is that the \"proper\" discussion does not inlay a good intuitive understanding of lift, which in my opinion, should start with \"push air down to go up\". reply p_l 2 hours agorootparentYes, there's no lift. But there's quite different flow and drag around it, which was used as opening for for adding rotation (which would add viscosity effects including lift from rotation) and other changed shapes in better way than starting with flat plane. reply Xirgil 13 hours agorootparentprevDo you have any recommended reading on this topic? I'd like to brush up. reply bouchard 10 hours agorootparentUnderstanding Aerodynamics: Arguing from the Real Physics by Doug McLean, a former aerodynamics Technical Fellow at Boeing Commercial Airplanes. reply po 4 hours agorootparentprevBill Beaty's site was the one that opened my eyes to these misunderstandings: http://www.amasci.com/wing/airfoil.html If the diagram shows lift but doesn't show the air being directed downward after leaving the tailing edge of the wing, I basically stop reading. That's the whole thing. reply p_l 12 hours agorootparentprevThere used to be a good one from NASA, written for K-12 but 100% adhering to actual science not \"lies for children\". EDIT: This is a good starting point for the frankly awesome material from NASA Glenn Research Centre: https://www.grc.nasa.gov/WWW/K-12/VirtualAero/BottleRocket/a... Unfortunately it partly bitrotted due to using java applets for interactive demos, but I think most of it is still reachable - I'll try to find it later when I'm at the desk. Personally I learnt from a 1980 book that was still part of mandatory reading for glider pilot course in Poland in 2005. reply Ono-Sendai 8 hours agorootparentprevWhy is it wrong? reply quickthrower2 2 hours agoparentprevYou mean it is more akin to those grills you position to control your AC pushing the air in a certain direction. But with just one surface you get the AoA too high problem. Hell I am gonna stick my hand out next time in a car (being safe about it!) and see the stall angle of my hand. reply lovecg 11 hours agoparentprevTo me the most intuitive and practical mental image is imagining two large bubbles of lower pressure above the wing that hold the wing up by suction (you can see those literally as condensation under certain conditions). As you increase the angle of attack the bubbles get larger and stronger, until the angle is so large that they “break off” and the wing stalls. reply danmaz74 12 hours agoparentprevI once found an explanation that finally made it clear to me why the shape of the airfoil can create lift. Yes, the air above the wing needs to travel a longer distance with the typical section used in wings, which means that it goes faster than the air below the wing. It also leaves the wing moving downwards - and when this downward-moving, faster flux of air meets the slower one from below, the result is that a mass of air is pushed downwards - exactly as needed to lift the plane, as you correctly said. As the article says, you can have lift by just changing the inclination of a symmetrical airfoil, but an asymmetrical one can generate lift even without inclination (and with lower drag). The article also explains that acrobatic airplanes have symmetrical wing sections exactly because they need to be able to fly just as easily inverted. reply kqr 4 hours agorootparent> Yes, the air above the wing needs to travel a longer distance with the typical section used in wings, which means that it goes faster than the air below the wing. Both of these sub-clauses are true, but the \"which means\" connecting them aren't. There's no law of physics saying a fluid that has a longer path ahead of it speeds up in anticipation. reply danmaz74 2 hours agorootparentMy understanding is that \"which means\" only makes sense with the assumption that what is being studied is the laminar flow of an incompressible fluid (which was described as a fair assumption for air and a wing at subsonic speed). But thinking more about it, it's probably right that this isn't about the fact that the air above needs to travel a longer distance, which would also be true for a concave wing section, but the fact that the layers immediately above the wing need to travel the same X distance through a thinner Y section - as in a tube which becomes thinner. Which forces the fluid to go at a higher speed, and have a lower pressure. reply prmph 1 hour agorootparentprevIsn't there an even more basic explanation: If incoming air hits a flat surface at an angle, and is deflected downwards, then by the law of action and reaction, the surface itself moves upward. As a child, I quickly outgrew the airfoil explanation when I realized this. reply kqr 1 hour agorootparentYes and no. The thing you describe happens, but it's not enough to explain the amount of lift generated by a wing, because a surprising amount of air hits also the top of the wing! The difference in pressure between top and bottom wing surface is just a few percent. The reason wings produce significant lift anyway is that they deflect air far beyond their surface. Air several metres away from the wing is also deflected downward, even though it doesn't actually hit the wing itself. So yes, Newton's third law is involved, but in a \"spooky action at a distance\" form, where the wing somehow manages to deflect a bunch of air it doesn't even touch! reply Gibbon1 1 hour agorootparentprevMy dad who worked on wind tunnels just flat said you can either integrate the pressure over the surface of the wing or the momentum change as the air passes over to derive the amount of lift. Both give exactly the same results and are convertible mathematically. For wind tunnel work it was easier to measure pressures. I'm with you I don't think the standard hand wavy explanation gives you the ability to attack the problem mathematically. So it's basically wrong. reply p_l 13 hours agoparentprevUnfortunately, your explanation is entirely wrong... and you're attacking a \"lies to children\" simplification with your mention of \"needs to run longer way around\" bit. reply avn2109 12 hours agorootparentWell in defense of the GP, the \"planes can observably fly upside down\" point (and its close cousin the \"flat wing cross sections can fly too\" point) is a good one, this pokes holes in the usual two-dimensional \"the air goes faster on top\" themed explanation that omits any discussion of vortex shedding/third-dimensional effects. reply p_l 12 hours agorootparentOh, to be quite honest, I loved trolling my high school teachers with \"your explanation fails, here is a real world airfoil, please explain it\" and I would draw a symmetrical airfoil or - for extra trolling - a trapezoid one. (At that point I had already flown solo) But the same I found myself unable to pass by someone pushing \"flat plane at an angle\". reply quickthrower2 2 hours agorootparentDid you have to write the lie in an exam to pass too? reply itishappy 10 hours agoparentprev> planes can obviously fly inverted Many (most?) planes cannot sustain inverted flight. reply mechhacker 9 hours agorootparentIIRC that is due to other issues, not aerodynamics. For instance, the engine no longer receiving oil at negative 1 g, or fuel, as the system is designed for gravity flow. Stunt planes and airplanes capable of long inverted flight need special oiling and fuel systems to keep the engine from starving from either. reply itishappy 9 hours agorootparentFascinating! Commercial airliners have also optimized their engines enough they don't have the power budget to make up for the difference in lift. reply kqr 12 hours agoprevI agree with the other commenter that the specific shape of the cross section of the wing is overemphasised in almost all material including this one. Any shape longer than it's thick will, at a reasonable angle of attack, provide lift. This article did provide a barn door model also, but it was quite far down. The shape is mainly about efficiency and increasing the range of reasonable angles of attack, and then further nuances. reply tjkrusinski 12 hours agoparentIt's amazing how the article did such an incredible job building a deep understanding of how the airfoil works, yet you managed to completely miss that and find something to so small to critique. reply kqr 4 hours agorootparentTo be clear, the article was amazing. That has already been said multiple times by others so if I left a comment saing just that I would contribute nothing. Besides, the size of the criticism (in this case small, as you point out) is an even better measure of quality than number of fawning comments. I also publish articles (though nowhere near as good or ambitious as this one) online and the comments I look forward to most are the constructively critical ones. They are the reason I publish in the first place. My only goal of giving and receiving constructive criticism is to improve our collective understanding of the world. There's nothing sinister or ill-natured about it as another commenter suggested. (This extends to comments as well. I really appreciate you prompting me to check my tone.) reply carabiner 2 hours agorootparentbro just stop reply MattRix 11 hours agorootparentprevI think many of these kinds of comments are driven by a form of insecurity. They subconsciously wish they had written the article and are envious of the attention the author is receiving… so they find whatever small nitpick they can in order to tear it down. reply milliams 12 hours agoparentprevI thought they made it very clear and talked at length that the shape isn't the key important factor. They do also then go on to talk about the benefits of different shapes and why they are chosen. reply carabiner 10 hours agoparentprevYou gotta wonder why the Wrights spent so much time optimizing an airfoil. You could have been there to tell them to use a barn door wing and flat plate prop to save them a lot of time. I have noticed this \"it works or it doesn't work. Everything else is nuances.\" binary thinking among SWEs. It's odd. reply kqr 4 hours agorootparentDon't get me wrong -- for practical flight it is really important to expand the reasonable range of angles of attack because angle of attack is one of very few ways one has of controlling the aircraft. But for explaining how lift appears, it is an irrelevant detail. The purpose of modeling is not to mimick reality at high fidelity but to focus attention on the o parameters that matter for a specific situation. When you change the situation (going from explaining how lift happens to trying to fly) it is not surprising to have to switch to a different model. reply 8n4vidtmkvmk 4 hours agorootparentprevAn odd thing to say for a SWE. There's huge differences in the quality of apps, both from a user perspective and an internal/dev perspective. reply r3d0c 7 hours agorootparentpreveffect is amplified on hn reply mint2 17 hours agoprevWhy does the first slider with the cube not say what the “one property” the slider controls is? Viscosity? Airspeed? reply Etheryte 15 hours agoparentI think this is entirely intentional. All articles by Bartosz build up from simple basic principles and avoiding specific technical terms is a good way to onboard viewers of mixed backgrounds without scaring anyone off. Viscosity is actually mentioned for the first time only roughly three quarters into the whole thing. reply mint2 13 hours agorootparentI think it would benefit by being broken up into modules and a little less simplified, at least naming the things. reply lobsterthief 10 hours agorootparentMaybe you learn best that way, but that doesn’t mean everybody does reply cryptopian 15 hours agoparentprevYou're kind of correct on both guesses. You can get that change by changing the viscosity OR the airspeed. He elaborates later on, but you're changing the Reynolds Number - a calculated value from the velocity, fluid density, viscosity and length. The cool thing about a Reynolds Number is that you get identical (in theory) airflow characteristics for two setups with the same Reynold's Number, even if e.g. the airspeed is different. reply H8crilA 17 hours agoparentprevFrom the HTML: (...) reply philote 16 hours agoparentprevAlso, it says \"this substance\", which I initially thought referred to the cube as it was just mentioned in the previous sentence. But I guess it's the \"fluid\". reply ajkjk 12 hours agoprevPretty impressive. I was curious how they made the whole thing so I went to look at the source for the images. It's mostly in one 10000 line JS file which draws all the graphics ontoin JS, plus a bunch of WebGL that goes over my head. The code looks like function draw_car(ctx, rot) { ctx.save(); let sc = 0.04; ctx.scale(sc, -sc); ctx.lineWidth \\*= 1 / sc; ctx.translate(-286, -51); ctx.beginPath(); ctx.moveTo(463.93652, 9.89137); ctx.bezierCurveTo(462.12793, 6.72347, 461.22363, 3.5344, 461.22363, 0.32417); ctx.bezierCurveTo(447.58911, -1.16177, 434.20691, 2.81333, 434.85754, 5.10777); ... I wonder what their workflow was. Surely all those curves weren't programmed by hand? reply dubcanada 11 hours agoparentNot sure what you are looking at but https://ciechanow.ski/js/airfoil.js is the JS that contains the code for the graphics/visuals. And it is completely readable. The 2d part though is probably generated. reply nequo 9 hours agorootparentYeah, the \"draw_car\" snippet quoted by parent is from the JS file that you linked. It looks like maybe an SVG file converted into JS? Do you know if there is some standard tooling that generates this? reply bastawhiz 7 hours agorootparentSVG paths translate pretty directly to canvas commands. If you have an SVG path parser, it's pretty straightforward to walk it and output the equivalent js. reply ajkjk 7 hours agorootparentBut for that many paths it seems... tedious. Wondering if they had a better way. reply ajkjk 7 hours agorootparentprevYeah, that's the file I was looking at. I was wondering how that file got created. By hand, or generated somehow? reply grishka 5 hours agorootparentI asked him on Twitter about one of his previous articles, he said he writes all that JS by hand. https://twitter.com/BCiechanowski/status/1522067904522428417 reply syncsynchalt 6 hours agoparentprevIt doesn't look like it's publicly viewable but he has a writeup of his process for patrons at https://www.patreon.com/posts/on-airfoil-99289324 reply plopz 12 hours agoparentprevJust a small note, that code looks like Context2d rather than WebGL unless you were looking at something else in the code reply ajkjk 7 hours agorootparentAh, I wasn't clear. There's a bunch of both in the same giant file. reply civil_engineer 15 hours agoprevThe wings of an airplane in level flight direct air downward with a force equal to the airplane's weight. If one were to build a large scale on the ground, as an airplane flies over it, the scale would register the weight of the airplane. The wings act like a scoop forcing air downward behind the wing. At least that's the way I think about it when I'm out flying around in my Cessna. reply ivanjermakov 14 hours agoparentAlthough it is a nice mental model, that's not quite true. > The wings act like a scoop forcing air downward behind the wing Only bottom side of the wing acts as a scoop, creating positive pressure. Upper side, in opposite, creates negative pressure which \"sucks\" the plane into it, creating additional lift. It surprised me how much lift is coming from the negative pressure - about a half: https://aviation.stackexchange.com/a/16202 reply danmaz74 12 hours agorootparentActually, it is quite true. Gravity is exercising on the airplane a force F equal to the weight of the plane, towards the ground. For the airplane to stay at the same height, air needs to exercise a force that is equal and opposite to that of gravity. For an airplane buoyancy is negligible, so the force comes from accelerating enough air towards the ground so that F = M*A when M is the mass of air being accelerated, and A the (average) acceleration. Notice that this isn't a separate effect from the effect of pressure - it's just a different way of seeing the same effect. The wing is accelerating the air both upwards and downwards, but because the pressure is higher below the wing than it is above it, more air is accelerated down than it is accelerated up - which lifts the airplane, but makes the air go down. reply jameshart 12 hours agorootparentprevExcept that negative pressure is not a thing. Air molecules are not grabbing the wings and pulling them up - they are just not pushing down on the top as much as the ones underneath are pushing upwards. reply Tyrannosaur 9 hours agorootparentNegative pressure is not a thing, except you just described it. If you take the difference between the pressures above the wing and below the wing, you get a negative number. A thing not existing absolutely can still exist relatively. reply jameshart 6 hours agorootparentThat’s just a pressure differential, and not what the OP meant by ‘negative pressure’. 100% of the lift force on a wing is attributable to the pressure differential across it, after all. They (or their stackexchange source at least) are - like the referenced article and as is commonly done in aero engineering - subtracting out ambient pressure as a reference pressure, and then viewing pressure above the wing as ‘negative’ and pressure below as ‘positive’. It’s a convenient choice to make, for various reasons, but it is essentially an arbitrary one. The problem comes when you then go on, like OP did, to come across statements like “how much lift is coming from the negative pressure - about a half” Now, since in analyzing the pressure we have subtracted the reference pressure and made a zero point in between the low pressure value above the wing and the high pressure value below it, it actually shouldn’t surprise us at all that ‘about half’ of the lift seems to be attributed to the positive pressure below the wing, and half to the negative pressure above the wing. This is just saying that half the lift on the wing is attributable to the first half of the pressure differential across the wing, and about half the lift attributable to the other half. One of the problems of using a relative pressure and thinking about negative air pressure is that it gives the impression that negative air pressure, like positive air pressure, can grow arbitrarily large. It can’t. You can’t have a negative air pressure lower than negative ambient air pressure, because the absolute air pressure cannot go below zero. But what you’re talking about is a relative pressure differential. We can have an arbitrarily large negative pressure differential because we can have an arbitrarily high pressure on one side of it. reply WanderPanda 15 hours agoparentprevThat’s my mental model as well. The incompressible fluid-based explanations never made much sense to me reply bloppe 14 hours agoparentprevYa, I was hoping for more nuance related to this. I'm sure the air foils generate lift, but atmospheric pressure at cruising altitude is ~4psi, and the pressure differential across the foil must be only a tiny fraction of that. According to my understanding of Bernoulli's principle, you'd have to quadruple the speed to cut the pressure in half, and I can't imagine the top air traveling that much faster than the bottom air. Yet a 747 can produce 850000 pounds of lift with only 729000 square inches of wing? Feels like a very incomplete description at best reply p_l 12 hours agorootparentThe airfoil shape causes formation of vortex around the wing, which ridiculously changes the relative speeds and pressures involved. At low pressure you compensate with speed, which is squared in lift equation. reply Rapzid 12 hours agoparentprev> If one were to build a large scale on the ground, as an airplane flies over it, the scale would register the weight of the airplane No, it wouldn't. I think the article does a pretty good job building a more complete understanding than the simplistic \"deflection\" mental model. reply turtledragonfly 7 hours agorootparentI think what they were saying is that from a pure \"Newton's 3rd law\" standpoint, if the plane has an upwards force, then the air has a corresponding downward force, which must go somewhere. Yes, it is spread out and complicated and turbulent, etc, but ultimately must balance out. If we could somehow \"draw a box around\" the entire plane+air system, then the plane's upward lift will create a corresponding downward force on the box, one way or another. So, in the broad sense that you push the earth away from you when you jump, the plane also pushes the earth away from it when it flies (mediated by a bunch of fluid dynamics). Or, classic example: if a (sealed) truck full of birds is jostled so that they start flying, does the truck weigh less? [1] [1] https://www.youtube.com/watch?v=lVeP6oqH-Qo&t=35s reply Rapzid 6 hours agorootparentIt's wrong though. A large, hypothetical scale under the plane would not register the weight of the plane as it flies over. And not just because diffusion but that being one of many reasons. reply somat 6 hours agorootparentprevThe simple newtonian deflection model is correct however, As you engineer your deflector to have the least possible drag the airfoil shape naturally falls out. Actually that is a bit of a lie, the airfoil shape only falls out due to a third implied force that needs to be accounted for. the wing needs to be strong enough to hold itself up. if you had infinitely strong materials the deflector shape that would fall out would be like a slightly bent piece of paper. A clarification note on fluids: you are deflecting fluids, and everything this implies. just because I say newtonian deflection don't think I mean billiards balls, or if it has to be billiard balls think trillions of them simultaneously reply Rapzid 5 hours agorootparenthttps://www.grc.nasa.gov/www/k-12/VirtualAero/BottleRocket/a... reply somat 3 hours agorootparentI did not say reflector as implied by that link but deflector, a thing put in the fluidstream to move it somewhere else. airplanes lift because you are moving air down. People get hung up about the convex side of the airfoil but what else is the fluid going to do, stay a vacuum? it is going to move in the way the deflector shaped, adding to(actually providing most of) the downward flow. There is a lot of engineering that goes into it but at the end of the day an airfoil is the shape that moves enough enough air downward with the least drag. The only reason it is a thick teardrop shape is it has to be strong enough to support itself and the airplane. otherwise the ideal shape would be super thin shaped like the upper surface of the wing bending slightly from the cord(aspect directly into the stream) to the trailing edge(a few degrees of slope). reply Rapzid 3 hours agorootparentIDK man, what I said was correct; it's wrong. GLHF. reply p_l 13 hours agoparentprev... I'm honestly surprised it's possible to get PPL(A) without learning about wing vortices responsible for lift generation. In order to use \"scoop\" approach for lift, you need to have either very low wing loading (think paper airplanes) or very high speeds (above transsonic range). reply garyiskidding 3 hours agoprevAs an aerospace major in college, this has content from several semesters combined into a really well structured, clear and visual explanation of various aspects of flight dynamics. Thank you. reply Tistron 8 hours agoprevI really enjoyed reading this, and felt excited when the author promised to explain viscosity at a particle level. But there was just a short presentation about two colliding molecules and I didn't understand the connection to viscosity. It's like a section is missing or something..? How does viscosity work? reply apognwsi 6 hours agoparentviscosity has very interesting units - stress (force / area) divided by rate (1 / time). viscosity is measured (a field known as rheology) by, in some way, moving a thing through a fluid at increasingly fast accelerations, or equivalently, at increasingly high frequencies. that is, imagine moving your hand back and forth in a fluid - the faster you do so (the number of back and forth motions per second), the more resistance you will feel from the fluid. for newtonian fluids, the resistance you feel (measured in force / area, ie the area of your hand), is proportional to the frequency of your hand moving back and forth in the liquid, so, the graph is a line. non newtonion fluids do not have a linear relationship between shear stress and shear rate. air is also a fluid - all gasses are, and thus possess rheological properties. air, however, at stp, is essentially an ideal gas, that is, it is non-interactive, and thus, has 0 viscosity. the point here, is that viscosity is a consequence of the interactions of particles. as gases become denser, their viscosity increases. liquids, for comparison, is ~1000x as dense as air. the details of how molecular interactions lead to viscosity is actually quite complicated. reply Tistron 1 hour agorootparentThank you. I seem to have trouble using rate as a concept, especially dividing by it :) But I think I get it when I add a virtual distance into what you are saying. You are saying (force / area) / (1 / time). I add two distances that cancel out: (distance * force / area) / (distance * 1 / time) and get (energy / area) / speed, which is energy used per area and speed. I can feel that, and it seems to be what you are saying, right? reply turtledragonfly 8 hours agoparentprevNot really a full answer for you, but one thing that this page clarified for me: I had generally previously thought of viscosity as \"how slow\" a fluid is. High viscosity means high \"thickness,\" which means it flows slowly (like molasses vs. water). But as presented on this page, viscosity is actually a measure of \"how fast\" — how fast the effects on one molecule can spread out from there to neighboring molecules. Perhaps you could think of sounds waves moving through a substance — a \"thick\" substance like solid metal propagates those waves quickly (on a molecular level), while with a \"thin\" substance like air it's much slower. In the more precise language from the article: \"viscosity controls the diffusion of momentum...\" So, because this diffusion happens quickly in a high-viscosity situation, little whorls of turbulence are inhibited, because the forces governing those whorls get spread out/diffused quickly. Perhaps you missed the part of the article talking about diffusion, or did not see the connection? The link between that and viscosity was not immediately apparent to me, either. reply Tistron 1 hour agorootparentThank you, this feels helpful. Though I don't think I missed a part of the article, I feel more like the author did ;) What I still don't get is what the difference between high and low viscosity looks like on a particle level. I don't understand why he introduced the collision between two molecules and then never explained that.. :) reply alanbernstein 9 hours agoprevI expected to see a mention of the Joukowski airfoil (https://complex-analysis.com/content/joukowsky_airfoil.html). I guess there was plenty of other content to cover though. reply 1970-01-01 16 hours agoprevSomething that was never clear to me at this level of detail is how a tailwind enables an airplane to move faster. In other words, if the airflow is coming from behind, the lift equation should fall apart and the airplane should fall out of the sky. https://www.skytough.com/post/tailwinds-make-plane-faster reply lovecg 15 hours agoparentOur intuitive experience with wind on the ground is wrong. Next time it’s windy outside imagine the entire volume of air stretching out for miles and miles moving across with the wind speed, we’re just standing at the bottom of this vast air ocean. It will blow your mind and you’ll think about wind differently from then on. So with that in mind, once the airplane is in the air, it doesn’t “know” if there’s a headwind or a tailwind at all, unless you have a way to reference the ground somehow (for example, with a GPS) - just like a boat doesn’t “know” it’s carried by a current downstream. If you are still on the ground, it is very possible that the tailwind is strong enough for you to not be able to takeoff in the available runway - but then you would go in the opposite direction or more likely sit the storm out :) reply klabb3 14 hours agorootparentI’ve noticed this effect while diving. When you’re in a current, you’re basically the same density so you’re moving with the water. In mid-water with poor visibility, this is really freaky, because you have no way of telling in what direction you’re moving, and how fast. If you “forget” your orientation, you can’t really recover it. Thankfully, you always have highly accurate depth gauge, but as for lateral movement, it’s an eerie feeling. You could just pop up anywhere. reply CrazyStat 16 hours agoparentprevThe plane is just up in the air moving relative to the air around it, it doesn't care how the air it's in is moving relative to the ground. A tail wind is just saying that the air is moving in a certain direction with respect to the ground (the same direction the plane is flying). The plane doesn't give a shit about that. reply mechhacker 14 hours agorootparentIt also changes a lot for sailboats, and even more for faster sailing craft (windsurfers, etc.). You can feel a much stronger pressure in the sail when moving towards the wind on a fast windsurfer/windfoil as you can do 15-20kts 45deg towards the wind, giving you an apparent wind that is 10-14kts stronger than the true wind. On the same craft, going away/downwind, you will feel the apparent wind at a similar angle 10-14kts less. In fact, because of the change in drag and forces, you'll probably be going faster and feel even less wind on the downwind leg. When you turn, this can be a big benefit for going downwind (jibing) as at some point the sail feels zero apparent wind (your motion cancelling out the true wind), feels very light in your hand, and easy to rotate to face the other way. Even knowing the physics of it, the timing and execution is still something that takes a lot of practice...especially on big race gear with a 9.0m2 sail. reply 1970-01-01 16 hours agorootparentprevYes that makes sense at a high level, but there must be a point of transition between calm air and a jet stream that makes the wings useless to the airplane for at least a few seconds. reply lovecg 15 hours agorootparentThese sudden changes do indeed happen in stormy weather, as adjacent layers of air can move with different velocities relative to the ground (the technical term is “wind shear”). If an airplane climbs or descends through those it will look like your speed (relative to air) is suddenly increased or decreased by some amount and you would have to compensate. It’s also a bigger problem for large, heavy airplanes as you have more work to do to accelerate for a given amount of speed loss. Jet stream boundary is usually not this sharp, and the airplane would fly much faster than the difference anyway. reply fh973 16 hours agorootparentprevIt's relevant in practice when landing against head wind. You need to have extra speed to not stall when you enter the slower air near ground. reply rockostrich 16 hours agorootparentDo you mean landing with a tailwind? A headwind should allow the plane to create the same amount of lift it needs to avoid stalling at lower ground speeds. reply Toutouxc 15 hours agorootparentYes, that’s correct, but the headwind stops being so headwind-y near the ground, so your plane needs to go a bit faster to compensate for the loss of headwind-ness in the seconds before touchdown. reply The5thElephant 15 hours agorootparentOn the flip side you also get ground-effect when you are low to the ground where the high-pressure underneath the wing gets trapped against the ground creating a cushion of pressure increasing lift. reply bouchard 14 hours agorootparentWhich can be a bit of a challenge when trying to land, especially for aerodynamically efficient aircraft. reply CrazyStat 16 hours agorootparentprevIf you took a plane flying in still air and magically, instantaneously replaced all the air around it with a tail wind equal to its velocity then yes the plane would stall and fall out of the sky. Fortunately that kind of instantaneous change doesn't happen in real life. reply DrSAR 9 hours agorootparentGO AROUND, WINDSHEAR AHEAD! reply bityard 16 hours agorootparentprevIndeed it does, that's effectively what turbulence is. reply lanternfish 16 hours agorootparentprevPresumably the plane would accelerate as it climbed through the velocity gradient, never falling to a point of negative air-relative airspeed. reply rockostrich 16 hours agorootparentprevYes, the wings are useless once the air is moving close to the speed of the plane. Thankfully, we have jet engines that help planes move a lot faster than the 100-200 knots that jet streams can reach. They'll still affect the flight but only temporarily. reply ryandrake 16 hours agoparentprevAirplanes are always traveling forward relative to the wind, at some angle of attack. Tailwinds don't work by blowing against the airplane's surface and pushing it forward. Since the airplanes are themselves traveling at, say, N kt forward relative to the wind, then if they are inside a 10 kt tailwind, they'll be doing N+10 kt over the ground, if they are inside a 50 kt tailwind, they'll be doing N+50 kt over the ground. If they are inside a 25 kt headwind, the'll be doing N-25 kt over the ground. reply rockostrich 16 hours agoparentprevThe bottleneck when it comes to a plane going faster is drag which increases with the square of velocity relative to the air. More drag means the plane has to consume more fuel to stay at its current velocity. So if a plane normally goes 600 mph with no wind then a 100 mph tailwind will allow that plane to go 700 mph relative to the ground to experience the same amount of drag as if it were flying at 600 mph on a day with no wind. reply barbegal 16 hours agoparentprevYes airplanes have to travel faster (in terms of ground speed) to not stall. This is why head winds are preferred for landings and take offs as it allows ground speed to be lower. But during cruise you want a tailwind to reduce the amount of drag for a given ground speed. reply BWStearns 13 hours agoparentprevIt's like swimming in a stream. Even if you did nothing you would move basically at the rate that the water is moving. Lift only comes from the interaction of the air and the wing, so if there's zero relative motion then you will fall out of the sky, regardless of if you have a 200 knot groundspeed. This also means that, if the wind at altitude is above your plane's stall speed, you can hover in place by flying straight into the wind! (example here: https://www.youtube.com/watch?v=n_e6ijREScE) Similarly, if you are in a packet of air that is moving at 200 knots, the fact that you are moving at 500 knots indicated airspeed does not mean you are flying supersonic from an aerodynamic perspective, despite having a groundspeed of 700 knots. reply danmaz74 13 hours agoparentprevBoth drag and lift depend on the speed of the airplane relative to the wind, not relative to the ground. So, if the maximum efficiency dictates that the airplane should travel at speed X relative to the wind, and the wind is flowing at speed Y in the same direction as the airplane needs to travel, then the airplane, flying at maximum efficiency, will be travelling at speed X+Y relative to the ground. reply jahewson 15 hours agoparentprevIt works by reducing the amount of CSS the plane needs to carry. reply fouronnes3 16 hours agoparentprevPlanes move through the air, and relative to the air mass. reply colechristensen 15 hours agoparentprevThis is a kind of relativity thing. The only connection a plane has to the universe is the air around it. It simply does not know or care what the ground is doing until the ground is quite close. A small plane in a very high wind is perfectly happy having a \"backward\" ground track. Same thing as if you were trying to swim upstream in a fast river. How fast you move through the water doesn't have anything to do with how fast the water is moving across the land. reply Limborg 3 hours agoprevOh, thanks todsacerdoti. I really need such thing. Actually, I love reading contents which related to Planes, Wings and the base reasons of their flying. It shows that you and your posts are going to be the best items for my hobbies in the future. Thank you. reply Eudaimion 8 hours agoprevIf you find this interesting, I would also recommend https://ciechanow.ski/bicycle/. It is by the same author. reply colechristensen 14 hours agoprevFor anyone really interested, this is the authoritative reference for NACA, etc. airfoils. Theory of Wing Sections by Abbott and von Doenhoff (1959) https://www.amazon.com/Theory-Wing-Sections-Aeronautical-Eng... reply 0xbadcafebee 14 hours agoprevAs part of building my own truck-top camper, I got into researching aerodynamics of vehicles in order to try to reduce loss of fuel efficiency. The most interesting ideas I found were that aerodynamics don't matter much on most vehicles until they pick up significant speed. Most automobiles are pretty heavy, so the engine has to do significant work just to get it to move. At a certain point, the vehicle can change gears to get the engine to do less work and use less fuel. But around the same time, the force of the air is increasing. By the time an automobile goes over about 50mph, the air forces are getting increasingly strong, and the engine has to work harder to keep the vehicle moving. At this point, beginning to lower the air's coefficient of drag on the vehicle will lessen the work the engine needs to do to keep the car moving at speed. So you can optimize the design of the vehicle's exterior to reduce the drag coefficient, which will reduce things like flow separation and turbulence, creating fewer rear pressure zones and causing less drag. So you might wonder, why aren't more cars teardrop-shaped like the airfoil? The answer is, it depends. Most people want something that looks good more than they want efficient operation at speed. But sometimes having more drag actually helps. For example, the Lotus Elise: while it is smaller and looks more sleek than a Tesla Model 3, it actually has a much worse drag coefficient than a Tesla Model 3. The Lotus has way more force acting against it at speed than the Tesla. But the Lotus is a sports car, and sports cars benefit greatly from increased traction, and you can get more of that traction by increasing the downforce on the car. So the Lotus's design sacrifices top-speed drag coefficiency in order to gain some downforce which helps traction when cornering at speed. What about pickup trucks? Even though modern pickups actually have lots of subtle design changes to improve drag coefficient, they all tend to have open beds, which is terrible for drag. It creates this giant messy turbulent pressure area in the bed which drags on the tailgate and the rest of the car. By adding a truck topper, the drag is significantly reduced, but you don't see most trucks driving around with a topper on. But trucks naturally have worse gas mileage, so nobody really thinks twice about the aerodynamics. (To be fair, the air's impact on gas mileage is minimal unless you're going quite fast. But for trucks with extremely bad gas mileage, like 18-wheelers, it makes much more difference. That's why they often have airfoils on the front of the truck, gaps between cab and container closed, and skirts to reduce drag from the undercarriage. Strangely though, the biggest improvement to reduce drag coefficient actually comes from modern European big-rigs whose containers are actually tapered like a teardrop. The rear of the vehicle's shape makes the most difference to how severe flow separation is, and thus how big of a pressure area develops, pulling on the rear of the vehicle. If we wanted to make trucking more fuel efficient globally we'd change the shape of the containers to be more like teardrops, but that would make handling and shipping them much more awkward) You'll usually only see these effects on automobiles at higher speeds, due to the vehicle needing to overcome gravity before the air forces build up. Lighter vehicles (say, bicycles) with less impact on them from gravity will be impacted earlier (at lower speeds) by the force of the air, so optimizing drag coefficient is much more important, which is why bicycle racers have to put so much into aerodynamics at significantly lower speeds than an automobile. Interestingly, the drag coefficient on a bicycle and rider is actually equivalent to that of a small car. reply justinzollars 15 hours agoprevI'm taking a sailing class, and learned sails in addition to keels utilize this concept. reply globular-toast 17 hours agoprevThis looks incredible as usual. What puzzles me, though, is why some people find flying puzzling. At least the kind that we do, ie. helicopters and fixed-wing aircraft. It's easy to accept a fan works: just put your hand there and feel the draft. A wing is just like a linear fan pushing air down. It's completely intuitive to understand for me. The difficulties are just in making it practical and controllable. Conversely, many people don't seem concerned at all with bird or insect flight, which I find a lot harder to understand. reply andrewla 16 hours agoparentI think many of us were taught in school that airfoil shape was somehow magical -- that the fact that it was bowed more on the top was responsible for the fact that it worked. This is only partially true, though; a totally flat wing can also support flight. The shaped nature of the wing contributes to its efficiency (and other factors) but do not make other wing shapes incapable of supporting flight. The reality is that the Wright brothers' innovation was not the airfoil shape or even the lightweight motor. It was the control surfaces, to allow the operator to adjust the plane's attitude on the three axes of rotation, allowing actively stabilized flight. Paper airplanes and kites demonstrate all the same principles of heavier-than-air flight (the Wright brothers even had a kite version of their airframe they used for testing), despite the fact that they generally do not exhibit shaped airfoils. reply amenhotep 16 hours agorootparentThe Wrights did use a rudder and \"horizontal rudder\" on the 1903 Flyer, but they were for some time determined to achieve roll control by warping the wings rather than using control surfaces, and were only forced to adopt ailerons as other pioneers began demonstrating how superior a paradigm that was. So they don't deserve too much credit on that score! reply andrewla 16 hours agorootparent\"Control surfaces\" was more specific than I intended; what I meant was that their plane allowed them to control all three axes of rotation, and that was the innovation - that they could control pitch, yaw, and roll independently and that allowed them to have active stable flight. Without those controls, flight is basically impossible, and with them, you could use nearly any airfoil shape (modulo engine power, drag, and stall speed considerations) and achieve heavier-than-air flight. reply BWStearns 13 hours agorootparentprevAilerons were really only invented when they were (and named in French) because the Wrights were extremely litigious, they sued Curtiss for using ailerons and basically destroyed American aviation for a decade allowing the French a temporary lead. This had an interesting cultural effect of lots of things becoming named in French across aviation (including things like the weather code for mist being \"br\" for brume to this day). reply p_l 13 hours agorootparentprevBecause the explanation in school misses something like 90% of the detail replacing it with zero-explanation magical thinking. For example, yes, the air above the wing moves faster than the air below the wing, and it's related to shape of the airfoil. However, it has nothing to do with magical \"air has longer to travel\". It starts with how combining flows at the trailing edge of the airflow create a vortex which induces an opposite vortex around the wing, which is a bit counter-intuitive (but it has nothing on why swept wings work, which can be summarised for practical aircraft design purposes of \"because if we calculate at an angle we get better values and reality is crying in the corner\") reply kqr 3 hours agorootparent> It starts with how combining flows at the trailing edge of the airflow create a vortex which induces an opposite vortex around the wing, Wait, I was under the impression this Cutta circulation was a computational simplification and the \"real\" reason were the pressure differences as explained in this submission. What am I missing? reply plopz 11 hours agorootparentprevThe whole air has longer to travel thing is obviously hand waving a lot of different properties that are all combining to get better efficiencies. For example, don't forget the coanda effect and its contributions to the shape of a wing. Luckily we can always just return to the navier-stokes equations to help us out. reply djsavvy 12 hours agorootparentprevGrowing up I got the \"air has longer to travel on the top of the wing than the bottom\" explanation, and it always smelled like BS. This is the first explanation of flight aerodynamics that really made sense to me — incredible article as always from this author. reply carabiner 3 hours agorootparentprevWithout their wind tunnel optimized airfoils, the wright flyer wouldn't have flown. Without the controls, it wouldn't have flown. Without the high power to weight ratio motor, it wouldn't have flown. Which was the most critical? reply NovemberWhiskey 16 hours agoparentprevSurely it's a less impressive result that something powered by mains electricity can move the air in a draft than that a multi-hundred-ton aircraft can fly over the highest mountains. It's the size of the aerodynamic forces and the complexity of the physical mechanisms that create them that many people have trouble with. In particular: intuitions can be pretty wrong, most simplified explanations are wrong under simple experiments, and the problems exhibit scale variance that is unfamiliar (e.g. Reynolds number). One time I was working on air data computer for a transonic aircraft that could fly up to about M0.95 - during flight test, an air data probe mounted on a nose boom was used to supply impact and static pressures, angle of attack and sideslip etc. for various air data calculations like airspeed and altitude. I was fascinated that there was a term in the calculation that related to the aircraft flap position - what's happening way out on the trailing edge of the wing actually has a meaningful effect of pressures measured on a boom out the front of the nose during certain regimes of flight. reply globular-toast 15 hours agorootparentIt's just a matter of scale. What's impressive to me with the big aircraft is that we can organise thousands(?) of people to build something that big. But when it comes to the principle of flying it's just a bigger version of the fan. If you were to say they used the same amount of energy as a fan then that would be impressive. But they don't, they burn tons of fossil fuels. Geese can fly over the highest mountains too and all they eat is grass. reply NovemberWhiskey 14 hours agorootparent>it's just a bigger version of the fan I mean, actually, it isn't - that's the whole point about scale variance and Reynolds number and why wings that work for insects are not the wings that work for jumbo jets. reply risenshinetech 12 hours agoparentprevWho are these mysterious people you're interacting with who are concerned with (but don't understand) the physics of flight, but who are also not concerned with bird or insect flight? reply pants2 17 hours agoparentprevBecause an airplane doesn't move its wings like a bug or helicopter, and it's wings aren't shaped like fan blades. One might look at a plane and conclude that since the wings and engines are parallel to the ground, it must only move laterally. reply jahewson 15 hours agorootparentRectilinear fan blades are shaped very similarly to aircraft wings. And it does only move laterally until the ailerons are moved away from being parallel with the ground. reply globular-toast 15 hours agorootparentprevOf course it moves its wings. That's what the runway is for. reply d--b 16 hours agoparentprevI guess this is somewhat counter intuitive: https://www.youtube.com/watch?v=NBsvzMi9-f8 So yeah, fans are puzzling too. reply convivialdingo 14 hours agorootparentIf you watch it very slowly, the paper initially folds under the mouth and then it blows out straight. I'm guessing the initial puff creates a high pressure area on top of the paper, rolling it downward and back. Them after the puff has pushed the air away, there is now a low pressure zone on top of the paper which lifts it up as the air below is rushing upwards around the sides of the paper. reply tekla 16 hours agoparentprevThis is an incredible (over)simplification of flying. We still don't have a very good understanding of turbulence. Navier Stokes equations still make Aerospace engineers drink. Yes its stupid simple if you care about the simplest of analogies, but if you try to understand it, there are reasons why 80% of people drop out. reply jebarker 16 hours agorootparentI think you mean incredible oversimplification reply ubj 14 hours agoprevObligatory XKCD comic (also with the name \"Airfoil\"): https://xkcd.com/803/ reply Krastan 17 hours agoprevWake up babe, new Bartosz Ciechanowski just dropped reply Brajeshwar 16 hours agoparentLOL! Yeah, so the next should be at least in 2025-Q1. reply pcurve 16 hours agoprevThis man to me is a modern day Da Vinci of the Web reply anibalin 15 hours agoparentIt's truly impressive. the amount of time and dedication its uncanny. reply simple10 14 hours agoprevThe javascript code is not minified and is easy to follow. Beautifully done. https://ciechanow.ski/js/base.js https://ciechanow.ski/js/airfoil.js reply caditinpiscinam 6 hours agoparentI've never used webgl -- what's its advantage over normal 2d canvas drawing for a project like this? reply modeless 4 hours agorootparentSpeed. Drawing thousands of objects (such as the blades of grass or air molecules) with 2D canvas will be very slow. WebGL allows all drawing to be offloaded to the GPU, which can draw thousands of objects in parallel given a single CPU command. 2D canvas also doesn't provide any 3D primitives (as the name would suggest), while WebGL natively supports rasterizing 3D triangles with perspective correct texture mapping and z-buffering. The downside of WebGL is its complexity, but there are many libraries to help with that. reply nuz 17 hours agoprevBlows my mind that my computer isn't even turning on its fans considering how many shaders are running in this thing. reply jakebasile 7 hours agoparentI'm on Ubuntu and Edge (v122.0.2365.59) could barely render the page. Chrome (v122.0.6261.94) worked just fine, though. I don't know enough about browsers and GPUs to debug why that is, but I checked (edge|chrome)://gpu and nothing stood out as appreciably different. Edit: interestingly, it seems to only be the first animation. If I scroll it out of view the others all seem to render fine. reply efnx 16 hours agoparentprevI think they pause when they scroll out of view? reply naikrovek 16 hours agoparentprevThey’re simple shaders and it’s amazing what a computer can do billions of times per second. reply baobabKoodaa 16 hours agorootparentYeah, I mean come on, we're not rendering something hard and expensive to compute, like a React website that has to list items in a shopping cart. reply nuz 16 hours agorootparentPersonally all the fluid simulation shaders I've written usually makes my fan go off, and I'm counting a few of those here so that's impressive in my eyes. reply baobabKoodaa 16 hours agorootparentYeah. It's impressive to my eyes as well. I was just trying to make a joke about how normal websites need 100% of your CPU to render some text and images, and here's this guy doing multiple fluid simulations on a web page written in custom WebGL and it runs on a potato. reply flokie 16 hours agoprevHis work is always a good reminder the open web is still an amazing place! reply Ancapistani 17 hours agoprevI thought this was going to be about pipeline workflows... but then I saw it was Bartosz! I know what I'll be spending a stupid amount of time reading today :) reply atlas_hugged 15 hours agoprevI swear Bartosz’ posts deserve to be pinned to the top of hacker news on release day at this point. reply ipqk 17 hours agoprevIf you like his work, here's his patreon: https://www.patreon.com/ciechanowski/ reply diggan 16 hours agoparentIf you'd like to see more of their work, ranked by what HN thought was most interesting: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... reply frfl 16 hours agorootparentYou can also see all-time top posts: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que... The mechanical watch post is 6th on the list reply bhasi 17 hours agoprevHis mechanical watch internals page is also equally amazing. reply RaoulP 16 hours agoparentIt is currently the 6th most popular post on HN: https://news.ycombinator.com/item?id=31261533 reply cloogshicer 15 hours agoprevImagine a world in which all education was this level of quality. Imagine how much more you'd know, be able to do and understand. I really wish good education was valued more highly in society. reply pomian 14 hours agoparentYes, that. Call it enhanced learning? For instance, add Dan Carlin - Hardcore History podcasts for your history lectures. If everyone listened to those podcasts, then all you would need is a good teacher/professor to discuss what you learned - and there is 'so much' learned from any one of his episodes. reply fisherjeff 17 hours agoprevWhat? A ciechanow.ski airfoil explainer? But I have things to do today! reply tandr 15 hours agoparentIt is too late for us to be saved, my friend, way too late... reply nuz 17 hours agoprevAbsolutely beautiful article and presentation reply flightster 17 hours agoprevDare I ask for the code? reply yeknoda 17 hours agoparentIt's right there. unminified and unobfuscated. just click save reply maxmcd 16 hours agorootparentWow, I never realized this detail. What a wonderful thing. reply Tmpod 14 hours agorootparentprevIt's a bit sad this isn't the norn for education articles (and mostly everything else too). Bartosz's dedication and craftsmanship is really inspiring. reply pitzips 17 hours agoparentprevIIRC you can view the source and it's all custom WebGL available for viewing. reply diimdeep 15 hours agoprevThis is the future of education. Very approachable and seems to target the most common denominator of knowledgeable people that out there. I wonder will there be articles in the future with more math and code snippets? reply elwell 15 hours agoparentThe future of education is as an entertainment. There will be no need to educate oneself in the AI future (except for merely egotistical reasons?). reply ajross 16 hours agoprevnext [7 more] [flagged] Aloisius 15 hours agoparentI suggest reading the article. It goes into great lengths to show how lift is generated with symmetric airfoils or even flat planes and that the asymmetric airfoil is for efficiency and conditions. It does not invoke any kind of magic. Even the part you quoted doesn't. Indeed they even animate a flat plane at different angles of attack showing lift. reply aidenn0 15 hours agoparentprevI don't read that sentence to mean what you do. The article is indeed \"looking at the forces generated by the flow of air around the aircraft's wings\" and it's definitely focusing \"on the cross section of those wings\" which is a shape known as an \"airfoil.\" Later on TFA says \"the shape and the orientation of the airfoil helps airplanes remain airborne\" which is closer to your criticism, but still true; a shape that generates more drag or less lift in the equivalent airflow would not help airplanes remain airborne. Maybe if TFA included a simulation of a rectilinear wing and showed how it stalled at very low angles of attack, that would improve things, but I find it to be \"just fine\" as an introduction to lift. reply laborcontract 16 hours agoparentprev> It'd be like clicking on an article that purported to explain \"How computer programs work\" .... and then proceeded to describe a debugger. iirc the article is called “Airfoil”, not “Rectilinear Box”. reply ajross 15 hours agorootparentTo be nitpicky: I wasn't irked by the article's title, but by the framing in the lede. To be constructively nitpicky: a box used as a wing is absolutely an \"airfoil\" inasmuch as the term has any meaning. It's not the shape being \"special\" that makes a wing work, it's the shape that the airflow around it takes, which is to first approximation just a function of its \"tilt\" along its major axis relative to the flow direction. The business about shape is all just optimization, not what you want to describe if you want to know how an airplane flies. reply laborcontract 15 hours agorootparentVery amusing, enjoyed the constructive nitpick! reply colechristensen 15 hours agoparentprevIndeed, with sufficient thrust your wings can just be flat plates with a small angle between the plane of the plates and the direction of travel. Airfoils are first about reducing drag, second about stall speed and angles. But airplanes are quite constrained things, if you have a bad attitude and refuse to use airfoils many planes wouldn't even get off the ground and all the rest would have abysmal performance. Sort of like how with imagination everything is a hammer, but this being technically true doesn't mean that you shouldn't really use a hammer when one is called for. reply komodus 10 hours agoprev [–] Things fly because of thrust, not wings. Rockets, missiles, don't have wings and yet they still fly even longer distances. Shut the engines of a 747 and it will fall like a rock, no matter how perfect the airfoils. Bernoulli and Coanda are important but without thrust/velocity there is no lift reply hex4def6 9 hours agoparentThe engineers at Boeing are going to be really embarrassed once someone tells them they don't actually need to put wings on their aircraft... reply signa11 5 hours agorootparentnot to mention authors of rfc-1925 as well :o) reply travisjungroth 9 hours agoparentprev [–] A 747 won’t fall like a rock. It will glide. reply rjmunro 8 hours agorootparentYou can't say that without mentioning https://en.wikipedia.org/wiki/British_Airways_Flight_009 Where the pilot said what is probably the most British thing ever said in history: > Ladies and gentlemen, this is your captain speaking. We have a small problem. > All four engines have stopped. We are doing our damnedest to get them going > again. I trust you are not in too much distress. reply tstrimple 4 hours agorootparentJust in case folks don't click on the link, it was a safe landing and everyone survived. It turns out modern planes can glide quite well. reply kqr 3 hours agorootparentprev [–] This is a very important point. The key difference is that a rock (like any ballistic projectile) accelerates until terminal velocity. In contrast, a 747 (like any airplane) descends with a constant vertical velocity when they lose power. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post explores the physics of flight, specifically airfoils' significance in maintaining aircraft in the air.",
      "It details airflow visualization techniques, air particle behavior, pressure distribution, viscosity, and the influence of pressure gradients on airfoil efficiency.",
      "Understanding these aerodynamic principles is crucial for crafting effective airfoils, leading to the mastery of flight."
    ],
    "commentSummary": [
      "The discussion delves into aerodynamics, airfoil design, and aircraft performance, emphasizing lift generation, airspeed, and wind effects.",
      "Users exchange ideas on airfoil optimization, flight mechanics, and the intricate aerodynamic forces in aircraft design.",
      "Appreciation is shown for high-quality educational content, detailed technical explanations, and the utilization of JavaScript and WebGL for interactive articles."
    ],
    "points": 2110,
    "commentCount": 240,
    "retryCount": 0,
    "time": 1709051569
  },
  {
    "id": 39530203,
    "title": "Nintendo Sues Yuzu Emulator Creators, Alleging Switch Game Piracy",
    "originLink": "https://overkill.wtf/nintendo-sue-yuzu-emulator/",
    "originBody": "New documents filed Monday, February 26 reveal that videogame giant Nintendo is taking action against the creators of the popular emulator tool Yuzu. The copyright infringement filing, from Nintendo of America, states that the Yuzu tool (from developer Tropic Haze LLC) illegally circumvents the software encryption and copyright protection systems of Nintendo Switch titles, and thus facilitates piracy and infringes copyright under the Digital Millennium Copyright Act (DMCA). Nintendo alleges that Tropic Haze's free Yuzu emulator tool unlawfully allows pirated Switch games to be played on PCs and other devices, bypassing Nintendo's protection measures. The official Yuzu website suggests that the tool is to be used with software you yourself own: \"You are legally required to dump your games from your Nintendo Switch\" — but it's common knowledge, that this is not how these tools are primarily used. The legal document claims that over a million copies of last year's The Legend of Zelda: Tears of the Kingdom were downloaded prior to the game's official retail release. Story continues below... Additionally, Nintendo's filing points to the success of Yuzu's Patreon page, highlighting how the project is actively supported by over 7,000 members. At time of writing, the Yuzu Patreon currently brings in close to $30,000 USD per month. Nintendo's filing alludes that this Patreon page has been actively engaged in promoting the emulator, and thus by extension piracy. The Yuzu project on Patreon Emulator tools aren't inherently illegal, but the way in which Yuzu is being actively used and promoted is what Nintendo appears to be objecting to here. As a result, Nintendo is now seeking a trial by jury, damages, and is demanding that the Yuzu emulator is shut down. Via: Stephen Totilo of Game File Related: Plans to release Dolphin emulator on Steam abandoned Previously announced plans to bring the popular Wii and GameCube emulator ‘Dolphin’ to Steam have now been abandoned. overkill.wtfChris Brandrick",
    "commentLink": "https://news.ycombinator.com/item?id=39530203",
    "commentBody": "Nintendo is suing the creators of Switch emulator Yuzu (overkill.wtf)759 points by brandrick 12 hours agohidepastfavorite509 comments Lammy 11 hours agoSpeculating here but it feels like part of Nintendo's beef is the popularity of PC form factors that look like a Nintendo Switch. Most notably the Steam Deck but there are loads of them. In 2022 Nintendo starting taking down Youtube videos showing Steam Decks running Switch games: https://www.resetera.com/threads/nintendo-started-blocking-v... And last year went after Dolphin (GCN/Wii emulator) as soon as they announced plans to be listed on Steam: https://news.ycombinator.com/item?id=36090755 https://news.ycombinator.com/item?id=36100732 reply jsheard 11 hours agoparentAmusingly Valve themselves released an official trailer for the Steam Deck which showed Yuzu installed on the homescreen. It was quickly taken down and re-posted without any references to Yuzu, probably after a panicked email from legal. https://www.pcgamer.com/valve-edits-steam-deck-trailer-to-re... reply andy_ppp 11 hours agorootparentI can play Switch games on Steam Deck!? reply WithinReason 11 hours agorootparentYes, better than on the Switch. (now I'm awaiting legal action from Nintendo) reply darkteflon 10 hours agorootparentAfaik you need to own a modded Switch to get the necessary keys, though. That’s a big outlay, if you can even find one - they’re rare as hens teeth. Edit: Awesome - great to know! reply xyzzy_plugh 10 hours agorootparentYou do not need a Switch at all, unless you're trying to somehow skirt the legality issues. reply WithinReason 10 hours agorootparentprevYes, if you want to do it legally. reply coffeebeqn 8 hours agorootparentAs a owner of previous modded Nintendo consoles - they certainly don’t share your view reply kristofferR 7 hours agorootparentYeah, you might as well pirate it, that's just as bad in their view. Same with ripping DVDs/Blu-rays, it's illegal to rip them anyway, so might as well just download them. Especially now that they're suing emulator developers, it's almost unethical to buy Switch games anymore. reply loup-vaillant 35 minutes agorootparentHere in France, as far as I know I have a right to private copy, which I pay for through a specific tax whenever I buy storage. I can rip my DVDs, Blu-rays, or even Nintendo Switch cartridges or hard drive, perfectly legally, even if it means cracking open the thing and circumvent stuff. It's awfully less convenient than downloading the stuff, but it is legal. Or at least it was 20 years ago, but I'm not aware of any change on that front. Now there should be some ground rule. When you buy something, it's supposed to be yours, and you should be allowed to do what you want with it, especially studying it and sharing the results of your study. Any rule that allows some big corporation to retain power over something that's supposed to be yours is serious overreach and should be shut down. Now Nintendo does have a big problem here: without the exclusivity of their form factor (which is arguably difficult to improve upon[1]), all they have left is the exclusivity of their game library. [1]: https://loup-vaillant.fr/articles/ideal-computer reply 3abiton 8 hours agorootparentprevNintendo made it clear that this is also \"illegal\". You have to opt for the worse experience (using the switch) otherwise you're the bad guy ... reply sharpneli 1 hour agorootparentDepends on the place. This sort of interoperability is explicitly allowed in the EU. reply cqqxo4zV46cp 56 minutes agorootparentPer whose interpretation of the law? The DMA isn’t going to give nerds the utopia they think that they’re going to get. reply KingOfCoders 1 hour agorootparentprevLuckily Nintendo (Shadowrun is still some years away, when Ninsonmicro determines what is legal and what isn't) is not the authority to determine if something is illegal or not. But of course they are entitled to their own opinion. reply pierat 5 hours agorootparentprevhttps://github.com/PrincessAkira/road-to-yuzu-without-switch Cause we all like Github. reply sudosysgen 10 hours agorootparentprevYou can find the keys online. reply nicolas_17 10 hours agorootparentAnd that is the illegal part, rather than the development of the emulator... reply tonmoy 9 hours agorootparentClearly not according to Nintendo reply johnnyanmac 8 hours agorootparentThe moment they find a BIOS source they'll be taken out too. But the internet is a game of cat and mouse. reply Natsu 7 hours agorootparentprevSo it's like the 09F9 1102 thing all over again? I think I still have most of the key memorized from back then. reply 14 5 hours agorootparentprevAre they really rare? I have an older switch that is easily hackable and can’t be blocked due to it being a hardware vulnerability but I have never bothered to hack it as I just don’t know if it is worth it. Not sure if you can continue to play online once hacked and I assume once hacked play pirated games as why else hack it. But I haven’t pirated games in a long time I wonder if it is worth it. What the switch really needs is a messaging app maybe hacked switches can do that idk. reply progbits 11 hours agorootparentprevBetter how? The detachable joycon with accelerometer control are a mechanic in some games (eg. Zelda crossbow aim). I would imagine this would be worse experience on steam deck. reply climb_stealth 9 hours agorootparentBetter as in much better framerate with no performance drops. At least that's what I've heard. Pretty much all the games I have played allowed to disable the motion controls. I think it counts towards accessibility. Personally I really dislike the whole motion control aspect so always turn them off. Zelda included. I'm sure there are other tradeoffs as well. But would love it see what it's like on an emulator. Or maybe not, it might make running games on the original hardware feel terrible :) reply beardedmoose 3 hours agorootparentThat has not been my experience with switch games on the Steam Deck. Anytime shaders are loaded the FPS seems to stutter which in the newer Mario game is like every few seconds at first and it gets better the longer you play. I still prefer the switch for switch games myself. reply esskay 38 minutes agorootparentI've tried a few and it does very much seem to depend on the game. Some run better, some run worse. Most are about equal. reply thaumasiotes 9 hours agorootparentprev> Pretty much all the games I have played allowed to disable the motion controls. I think it counts towards accessibility. I think motion control is the only option for Pokemon Let's Go. reply just2043 10 hours agorootparentprevSteamdeck also has a gyro for this kind of mechanic. reply darkteflon 10 hours agorootparentBy the by, I recently switched to using a Dualsense as my SD external controller and found that the gyro controls make for an excellent desktop and M+K game controller. Surprised I didn’t think to check earlier. reply c-hendricks 9 hours agorootparentFYI this has been possible since the DS4. reply WithinReason 10 hours agorootparentprevNo, the SteamDeck gyro works too reply mplewis 10 hours agorootparentprevYou can play them at a higher resolution and frame rate than Switch supports. Steam Deck supports accelerometer control as well. reply progbits 10 hours agorootparentHuh, TIL. Thanks! reply faaarmer 10 hours agorootparentIn some cases. In other cases they run worse on Steam Deck, notably Tears of the Kingdom. reply al_borland 4 hours agorootparentThat's a pretty big asterisk. BotW and TotK account for about 90% of my Switch game time. reply asmor 10 hours agorootparentprevI found it funny that Linus of LMG endorsed this setup not because it is better, but because Yuzu doesn't hold your savegames hostage. If you don't know: you can't backup saves, they get written to NAND, not the SD card. you can however buy cloud backup, but only for games that don't opt out. Truly a problem of Nintendo's own petty making if even switch owners with a legitimate copy prefer to not run on their hardware. reply extraduder_ire 8 hours agorootparentIf you have a hacked console (paperclip with a 1st year console, modchip with later ones), you can back up your saves using a homebrew app (checkpoint) if you remember to do it regularly. You can also copy the saves off the console (or the emulated NAND you're supposed to create when hacking it) by running a different app (TegraExplorer) right from the bootloader. I had to do this when I messed up an update and my system wouldn't boot, but I hadn't backed up my saves in months. I do wonder if anyone's attempted to get nintendo to respond to a subject access request in the EU to get their saves from their cloud service. reply Cu3PO42 2 hours agorootparentI didn't want to run CFW, so I have actually written a tool to back up and decrypt all saves in a single click given any vulnerable Switch in RCM Mode. It's been really quite useful. reply j5155 6 hours agorootparentprev…and if you have a hacked console, you can easily and legally(!) just dump your ROMs and emulate as well. reply johnkizer 6 hours agorootparentprevThe savegame situation was part of what made me less interested in my Switch over time - I just didn't want to invest much time in any long-term games where I couldn't actually back up the savegames in any direct way. Now it gets pulled out every now and then when the kids want to play Club House Games or Mario Party. reply nox101 4 hours agorootparentprevAre 100% of features supported? Tilt sensor? Amiibo support? 2-8 controllers with motion camera, tilt sensor, internal speaker, and vibration? reply ranguna 3 hours agorootparentI'm not 100% sure tilt is supported out of the box, and amibo for sure is not unless you have a dongle or something. But I'm not sure why this is so surprising, the steam deck is a Linux PC. reply WithinReason 1 hour agorootparentprevAmiibos are supported (virtually), not sure about the rest reply bassiek 10 hours agorootparentprevBoss music start playing reply myko 8 hours agorootparentprevNot really better than the Switch generally, but it's pretty cool reply dclowd9901 9 hours agorootparentprevGet out of here. Seriously? I’ve been playing older system games pretty well on it but switch felt like it would be too much a load. reply ThatMedicIsASpy 9 hours agorootparentEmu Deck is the quickest way to set up emulation. The rest requires google. Not all games are stable/playable/without glitches. Mario Galaxy Wii + HD texture packs look like its from 2025 compared to the re-release on the Switch. reply ShamelessC 7 hours agorootparentprev> better than on the Switch That simply isn’t true. Downvotes don't make the statement magically more true. reply spoiler 7 hours agorootparentI played BotW on my friend's Switch, and loved it, but didn't really wanna buy another console. So I went through the tribulations of setting it up on the Deck (pro tip: use EmuDeck, I didn't know about it back then). I don't know about better, but for me it felt the same as the Switch! The only slight confusion thing was button labeling, but it's quick to get used to. I'd also say the slightly bigger screen is nicer. reply ShamelessC 5 hours agorootparentI'm not saying it's not possible. I'm saying it isn't universally better on every game the Switch can play. In fact, many games simply won't run. But yes, you can (and should!) run the popular titles such as Mario Odyssey and BotW/TotK. reply sergiotapia 10 hours agorootparentprevYes, and it runs really well and is very easy to launch and play. https://www.youtube.com/watch?v=rW4y8juFkOI Of course not as easy as just buying the game outright and putting in the cartridge. reply Sabinus 10 hours agorootparentDownloading a file and putting in on a Steam Deck seems easier than working for ~3 hours then purchasing a Nintendo game. reply vlz 4 hours agorootparentYeah, why pay for something, if you can also simply download/steal it? Something which took a lot of work to make? Reading comments like this I can almost understand Nintendos stance on emulation. Suing the emulator team is certainly not the right thing to do, but come on. At least pay for the game if you are not paying for the console. reply ekianjo 25 minutes agorootparentits not stealing it is copyright infringement reply emeril 8 hours agorootparentprevgotta love the streisand effect! reply johnnyanmac 8 hours agorootparentI don't think Nintendo cares about bringing short term awareness. They want to choke out the emulator team and more or less freeze development. reply andy_ppp 2 hours agorootparentIf the emulator is open source how will it be possible a load of forks won’t be created!? reply viraptor 10 hours agoparentprevIt would be amazing if Valve stepped up with legal funds/protection there. They do get money from people buying SteamDecks for emulation and well... free publicity if they take on Nintendo. reply jonny_eh 10 hours agorootparentThat flies in the face of what Valve did TO Dolphin. It was Valve that proactively reached out to Nintendo before putting Dolphin in Steam. Of course Nintendo responded \"please don't\", so Dolphin got blocked. reply foobarchu 9 hours agorootparentVery important (imo) nitpick, Valve didn't block Dolphin, they took it off their store. Blocked sounds like they made it so to dang run it, but you can install whatever you want on a steam deck and valve isn't going to stop you. reply Ekaros 3 hours agorootparentprevOn other hand after sale of device emulation does not pay... And selling games is where they earn money. Fight for emulation is useless legal fight for them and they are not org build for litigation. reply hx8 6 hours agorootparentprevI don't think this is likely. There is a convincible future where Nintendo publishes more and more games outside of their hardware platforms, so Valve needs to keep good business relations with Nintendo. reply johnnyanmac 2 hours agorootparentprevValve doesn't really benefit that much financially from emulation though. Steam deck profit margins are probably razor thin given the cost of the competition (many of whom are in China on top of it all). reply pipeline_peak 10 hours agoparentprevIf that’s true, I wonder if the Switch successor will be a lot similar. reply dev1ycan 11 hours agoparentprevI mean Valve literally had a trailer with a nintendo emulator as an app installed... Valve doesn't need to do RND for its games because they can just use whatever is on steam that is playable on the deck plus a ton of games from nintendo consoles via emulators as a selling point. reply freedomben 10 hours agorootparentNintendo could do the exact same thing if they made their platforms open like Steam does. That the switch is limited to only Switch games is entirely a choice they made because their whole existence they've been all about proprietary and locked down. reply lobsterthief 10 hours agorootparentI mean, to be fair, the NES lockout chip is what salvaged the video game industry after hoards of shitty games caused it to collapse. Obviously a lot has changed since then. Now they do it to protect their own IP and investments. reply ddtaylor 10 hours agorootparentThe lockout ship was there to prevent piracy. By the time the console made its way to North America there were known bypasses. Ironically enough if there's an argument to be made about what saved the industry and how quality control was involved it would be the Nintendo seal of quality and then the strong arming that they did to various retailers saying that if they sold any game that didn't have Nintendo's backing they would be blacklisted. At the time being blacklisted by a company like Nintendo where every kid was requesting their product was an impossibility reply Uvix 8 hours agorootparentThat's impossible; the lockout chip debuted with the North American version of the console, so there couldn't have been known bypasses beforehand. The Famicom had no CIC. The lockout chip is what made the \"seal of quality\" scheme feasible in the first place. If alternative games were widely available, Nintendo wouldn't have had nearly as much leverage to strongarm with. reply johnnyanmac 7 hours agorootparentprevSteam isn't open, Windows OS isn't even open. Windows is \"semi-open\", in that Microsoft can't stop you for developing and publishing whatever they want on the platform, while still not sharing source code. Microsoft only has (de facto) control of the Microsoft Store. reply ambichook 6 hours agorootparentyou seem to be conflating \"open\" and \"open source\" nintendo doesnt have to make the switch open source to make it open, they just have to allow people to make whatever the hell they want for it, but their business model depends on it being locked down (closed) reply johnnyanmac 4 hours agorootparentA bit, but I don't necessarily mean open source either. My main point is that people call Steam \"open\" but they in fact do not allow you to make whatever the hell you want. They are infamously vague about what they do or don't allow and devs constantly have trouble contacting them when they have issues, be it getting a game on the store, enabling steam features, keys, abusive users, etc. Given all that this doesn't feel like a plea to let people publish their games. Just a thinly veiled port begging. reply superb_dev 2 hours agorootparentI think in this thread we’re talking about the Steamdeck being open, not Steam itself. You can run anything on a Steamdeck, it’s just running Arch reply johnnyanmac 2 hours agorootparentThe hardware argument makes even less sense though. People in these circles complain so much about native performance, why would they want to install Linux on a Nintendo Switch like the PS3 days? Even if they could, it wouldn't let them play switch games better. It doesn't solve the clear problem here that is the super technically minded people wanting to play Mario and Zelda in 4k/60. reply BlueTemplar 7 hours agorootparentprevNot sure why you mention Windows considering how Steam Deck comes with Arch Linux out of the box, and Yuzu runs natively on Linux too ? reply johnnyanmac 4 hours agorootparentSteam =/= steam deck. And even then it's not really playing native Linux games if you argue Linux. Its just emulating (in layman's terms, I know what WINE stands for) where most devs actually make their games for. Microsoft doesn't seem to care (or it's legally dangerous to care). Nintendo does. reply _imnothere 1 hour agoprevThings like this and companies like Nintendo must be stopped, it's both morally and legally correct to emulate when people actually owns the machine and cartridges. reply aurareturn 1 hour agoparentDisagreed. I'm guessing that 99.99% of Switch emulator users do not own the cartridges. They're stealing, which is not only morally wrong, but legally wrong. Nintendo has the right to protect their IP and they have the right to make money. Furthermore, I disagree in general that it's morally and legally correct to emulate something you purchased. reply esskay 35 minutes agorootparentBy this logic we need to block Kodi, Plex, hell computers as someone might use them to download something instead of buying it. reply wiz21c 1 hour agorootparentprevThat is, Yuzu in itself doesn't do anything. You need Nintendo's IP to run Yuzu, so Nintendo should blame those who steal their IP. Now, the real question is: did Yuzu's creator have illegal access to Nintendo's IP to write Yuzu ? reply fartsucker69 51 minutes agorootparentprevwhat's morally problematic about emulating something you already own? reply hengistbury 1 hour agorootparentprevRegardless of the moral question, digital piracy is not really \"stealing\" reply loup-vaillant 13 minutes agorootparentIndeed it isn't: digital goods are non-rival, and as such fundamentally un-steal-able. Property as we usually understand it simply doesn't apply to them. There's still copyright infringement, but \"unlawful breach of a state-granted monopoly\" doesn't sound nearly as bad as stealing. You wouldn't steal a car, would you? reply catlifeonmars 37 minutes agorootparentprevIt may be morally wrong, but that is somewhat orthogonal to whether it is legally wrong (e.g. illegal). reply ryzvonusef 4 hours agoprevNothing Nintendo can do can shut the emulation genie... because China. A lot of Chinese sff pc/handheld producers (GPD/Minisforum/Ayaneo/Beelink etc)[1] are now creating device with the explicit understanding that these devices will be used for emulation, and are creating devices as such. even if Yuzu is banned...Chinese will take over, and nothing any american/japanese game manufacturers can do to stop it. ---- [1] AyaNeo literally created a DS clone called the Flip DS... doesn't get more explicit then that: https://www.ayaneo.com/product/AYANEO-FLIP-DS.html reply robbiet480 12 hours agoprevI knew that Patreon would bite them some day. Any time money comes into a \"offensive\" open source project, whoever feels they are getting hurt can make a claim a lot easier. Somewhat surprised they haven't yet sued Ryujinx (the other Switch emulator project) for also having a Patreon. reply crtasm 8 hours agoparentPatreon about page begins: >yuzu is a Nintendo Switch emulator capable of running many games! With yuzu, you can play such games as Pokémon Sword & Shield, Xenoblade Chronicles 3, Super Mario Odyssey, Mario Kart 8 Deluxe, Pokémon Legends: Arceus, Fire Emblem:Three Houses, and Super Smash Bros. Ultimate — on your PC. Regardless of the legal status of an emulator, I wouldn't list game titles if I were writing that copy. reply jzebedee 5 hours agorootparentIt's not illegal to play games that you already purchased and own. Piracy is just a convenient scapegoat to hobble emulation. reply aurareturn 1 hour agorootparentI'd argue that you should reverse your stance. It's illegal to pirate games. Being able to emulate things you purchased is a convenient scapegoat for people to pirate games. reply pierat 5 hours agorootparentprevThats not the problem. Zelda BoTW being released 7 days BEFORE being on Switch, and 60FPS, and better gameplay on a real computer is what caught Nintendo's attention. And with Yuzu and joycons, you can have EVERY game, including their online only stuff. And if you pay for those online only, piracy is the only way to guarantee that you'll keep them. They've destroyed the: NDS, Gamecube, Wii, WiiU stores/online content. They never needed to. They *chose* to. reply judge2020 10 hours agoparentprevMaking money is not a factor for fair use, but one factor is whether it’s a for-profit endeavor; you can be making money to fund an operation without doing so for profit. And even then, courts haven’t been too concerned with that aspect when other aspects are clearly met. reply hn_acker 45 minutes agorootparent> Making money is not a factor for fair use, but one factor is whether it’s a for-profit endeavor Whether the use is for-profit is not a factor either. It's part of a factor. The first factor of the fair use test [1] is: > the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes; \"including\" is not \"limited to\", so something as simple as whether the use brings in any revenue, whether through donations or sales, could be one consideration within the first factor. Whether the use is for-profit is another consideration. [1] https://en.wikipedia.org/wiki/Fair_use#U.S._fair_use_factors reply rightbyte 10 hours agorootparentprevYou need some sort of legal entity to receive the money, with ties to some real persons. It makes some corp. going after you so much easier, compared to trying to get to 'rightbyte' or 'judge2020' for doing git commits. reply judge2020 8 hours agorootparentNot the best idea to try to get around lawsuits by simply staying anonymous. Nintendo can sue GitHub and you as a John Doe to compel GitHub to give up all info it has on you, like IP address access logs (which can then be used to compel your ISP to hand over their records on you). reply rightbyte 29 minutes agorootparentMaybe but you added a ton of red tape between you and Nintendo. Staying semi-anonymous when also committing no actual crime is likely a really good filter versus lawsuits. reply crtasm 7 hours agorootparentprevIn that scenario, why would you have connected to Github from any IPs that link to your identity? reply jamiek88 6 hours agorootparentBecause perfect security is impossible and you only have to leak your real IP once - especially with committing to github it would be so easy for a tool or plugin to leak that. reply shzhdbi09gv8ioi 12 minutes agorootparentYou make it sound harder than it has to be. Just put your VPN on autostart and be done with it. Also, there are other git hosting providers out there. reply A4ET8a8uTh0 12 hours agoparentprevI am not part of that scene, but I am sympathetic to emulation. Is there a notable difference between Yuzu and other switch emulators? I wonder if there are other reasons than Patreon ( money changing hands ) or there were other considerations? reply deelowe 11 hours agorootparentYuzu has amazing compatibility. I'm guessing it's getting too good for Nintendo. Their concerns with TotK are not without merit. I played it on Yuzu (on PC) because it was a much better experience than on the switch. Within a few days of the game being out, there were resolution and fps patches which made the game run much better. That said, I'm not sure how Yuzu can be blamed for TotK piracy. Guessing Nintendo is throwing a hail mary here and hoping they can connect the dots during discovery. I hope this doesn't spell the end of Yuzu, because I use it to play switch games that I own on my steam deck. reply jwells89 11 hours agorootparentI’ve seen this sentiment echoed by many. Seems like it’d be more productive to reduce attrition of this sort by releasing a Switch with less-anemic hardware. There’s clearly a market for a “Switch Pro” or similar that can run TotK, etc at 60FPS without frame drops. reply filoleg 8 hours agorootparent> Seems like it’d be more productive to reduce attrition of this sort by releasing a Switch with less-anemic hardware. Truly, but you are preaching to the choir. I am a big fan of SMTV series, and since it was a Switch exclusive, I bought it on the release day. I wasn't happy about 30fps (which I knew about beforehand), but it wouldn't be a barrier for me to enjoy a great game, so I went into it despite knowing that. Long story short, I dropped the game just a few hours into it, and decided to wait until it gets a release on absolutely any other platform (and luckily enough, it was announced just last week). Turns out, 30fps was an aspirational goal, as literally in the first non-tutorial area of the game (the desert, I forgot the name), 30fps would rarely even hit, and the game would hover between 15-25fps the entire time. I just couldn't do it, no matter how good the game is. Nintendo straight up ruined a game for me that I was already liking, all due to the Switch hardware. I am not even asking for much, even 30fps would be fine. But I cannot stomach FPS oscillating between 15-25fps in multiple major areas where you spend a lot of time in a game. reply jwells89 8 hours agorootparentOuch yeah, that’s rough. I’m not as sensitive to FPS as some but I think I’d be bothered by 15-25 as well. reply SkeuomorphicBee 3 hours agorootparentprev> Seems like it’d be more productive to reduce attrition of this sort by releasing a Switch with less-anemic hardware. That is difficult for Nintendo, the GPU architecture used on the switch is long dead, so Nintendo has no easy way of releasing a better switch. Because of that they will probably wait as much as possible and then release a completely new console with only limited backwards compatibility. reply postexitus 16 minutes agorootparentOr they can release a Handheld PC with Yuzu running on it. And it wouldn't be the last time. reply alickz 11 hours agorootparentprevi also played TotK on Yuzu because of performance reasons I would've paid full price to play the game on my deck natively, but Nintendo doesn't consider the PC market worth entering it seems reply WithinReason 10 hours agorootparentIt's a shame considering how well the game looks with a good GPU: https://youtu.be/g2a5PmIhryA?si=OZJMc2IRCCgLMVBY&t=82 reply threeseed 11 hours agorootparentprev> Yuzu can be blamed for TotK piracy But they can be legally blamed for not taking any steps to prevent it. Which means there are two avenues for Nintendo to attack this situation. reply skeaker 11 hours agorootparentSeems a bit silly. Could you sue Microsoft because they did nothing to prevent death threats from being written in Word or sent over Outlook? reply balls187 10 hours agorootparentThat’s an argument to make. Jennifer Crumbley was found guilty of manslaughter for doing nothing to prevent her son from shooting up his school. That was criminal court with a much higher standard than a civil case. Nintendo has consistently been one of the strongest protectors of their IP, and a defense that says “We tell users not to commit piracy” is about as effective as a sex workers disclaimer that “money is exchanged for time.” reply skeaker 10 hours agorootparentThat case is in regards to a guardian figure who has some level of legal responsibility for the children in their care. In that case it makes sense to hold someone accountable for the actions of someone else because the person in question agreed to that when they became a guardian. Software developers should not be held liable for what their users do with the software unless the software itself does something illegal (such as malware that gains unauthorized access to secure systems). If developers were responsible for their users then you would have all kinds of bizarre lawsuits. You would be able to sue Microsoft for things written by users in Word. It wouldn't be a stretch to sue Linux contributers because someone used the OS to perform a DOS attack or to host a scam site. reply balls187 9 hours agorootparentI haven't looked at Nintendo's materials, but I would think they were able to find enough evidence to get them past any preliminary dismissal motions, and get to discovery in which case Nintendo would likely get access to all communications and electronic files (read: source code). I think Nintendo would be banking that the Yuzu team likely had lax (if at anything) policies and processes for compliance to their public stance on piracy. reply bkallus 6 hours agorootparentYuzu is free software, so its source code is already available: https://github.com/yuzu-emu/yuzu reply supernikio2 11 hours agorootparentprevIn that case, Linux creators would be liable for not taking any steps within the Linux kernel preventing you from pirating a game on the platform. reply threeseed 10 hours agorootparentNo because the primary use of Linux is not piracy. Whereas for emulation it is. The whole point of emulation is that you want to play content for which the original hardware no longer exists. And so there is no harm being done to anyone. This situation is obviously quite different because Nintendo is being harmed. reply boolemancer 10 hours agorootparent> No because the primary use of Linux is not piracy. Whereas for emulation it is. It's not piracy to play a game that you've backed up on different hardware than the original developers intended. reply deelowe 9 hours agorootparentMy understanding is that it actually is (or at least probably is) illegal to create and play your own backups... reply themoonisachees 9 hours agorootparentDepends on jurisdiction. In France and germany, it is totally legal, you are even allowed to acquire a backup through the internet if you so choose. reply kimixa 8 hours agorootparentThat's all well and good if true, but Patreon is based in the USA, so even if the people behind it aren't (which they presumably are, as the stated \"Tropic Haze LLC\" is also USA-based), they have to comply with the laws in that jurisdiction. reply Mindwipe 8 hours agorootparentprevNo it isn't. Where have you got any of those ideas from? reply BlueTemplar 6 hours agorootparentAre you suggesting that VLC is also now illegal across EU, in addition to the US ?? https://wiki.videolan.org/Frequently_Asked_Questions/#Is_lib... reply boolemancer 9 hours agorootparentprevPerhaps that's true, but not because it would be piracy. Backing up media for personal has a pretty strong fair use claim, so I don't think it should be considered copyright infringement. But there is also the DMCA, and the anti-circumvention provision, which can be attributed a lot more to the user backing up their game than it can be to the developers of the emulator. But that wouldn't be the same thing as copyright infringement. That said, if the\"interoperability exception\" applies to anything at all, I feel like it should apply here. You are circumventing copy protection mechanisms for the explicit purpose of interoperability with other software. On moral grounds, I also have absolutely no qualms whatsoever with someone circumventing copy protection mechanisms to make a copy of a thing they bought to use for personal use. The fact that that could be potentially illegal at all is disgusting. reply smaudet 7 hours agorootparentThere are (and should be) exemptions to the DMCA. If only we had a universal way to easily distribute data, without need to heavily license it, instead opting for easily accessible licenses from reputable sources at market prices... (we do, but torrents got a bad name) Netflix was a success not because it was a streaming service with a license fee, but because it provided unfettered access to data for a small fee. Of course, now there are AIs which can or will shortly be able to trivially reproduce most data formats, so that's a separate issue as far as that goes (and that's bad too, if AI spells the complete death of DMCA), but it really didn't need to be this complicated. Make your brand well recognized, make your products easy to obtain, go after the pirates not the users. I own a switch and TBH a lot of my enthusiasm is pretty chilled by Nintendo's dickery - I'm less likely to purchase their products (and I'll elsewhere with non-Nintendo stuff - and Nintendo's stuff is honestly becoming a lot of locked down crap these days). reply Dylan16807 10 hours agorootparentprevMost of my emulator use hasn't been piracy. And the weak chipset on the switch is a big reason to want to use emulators without piracy. And there's modding too. Your \"whole point\" is very far from whole. reply deelowe 11 hours agorootparentprevHrmm. Can you explain further? What sort of inaction would make them legally liable? reply threeseed 11 hours agorootparentIf you are aware of illegal activity being committed, have preventative measures available to you and choose not to use them then you're complicit. Similar to the approach that have been used in various jurisdictions against torrent sites. reply deelowe 9 hours agorootparentYuzu did not allow totk to be ran until after the release date. Not sure what else they could have done. reply boolemancer 10 hours agorootparentprevWhat preventative measures could they have used? reply crtasm 7 hours agorootparentprevWhat steps could they take? The emulator can't tell if the game dump I load into it is from my own cartridge or obtained elsewhere. reply saintradon 8 hours agorootparentprevActually, it's even crazier than that. The game got leaked and patches were created before the game got officially released. reply GabrielTFS 6 hours agorootparentWhat exactly do you mean by \"patches were created before the game got officially released\" ? It was my impression that some patches had been going around, but that they certainly weren't created by or endorsed by the Yuzu project in any official capacity - I don't see how random people creating patches for open source projects should give rise to any legal liability to the original project. reply starttoaster 9 hours agorootparentprev> That said, I'm not sure how Yuzu can be blamed for TotK piracy. >> I played it on Yuzu (on PC) because it was a much better experience than on the switch. I blame you, actually, (somewhat jokingly) because I own TotK for Switch, and ended up putting it away really quickly because the resolution in handheld mode looked awful. I actually couldn't stand playing the game in handheld mode while my wife took over the TV for her shows. reply johnnyanmac 12 hours agorootparentprevNot particularly. But it's the biggest fish so it's the biggest target. reply phone8675309 11 hours agorootparentprev> Is there a notable difference between Yuzu and other switch emulators? It's Nintendo. They sue everybody. reply slily 1 hour agoparentprevI'm actually surprised it took so long considering they were seeking crowdfunding while openly advertising the piracy use case and raking in thousands of dollars a month (now $30,000 - wow). Patreon rewards can be construed as profit-seeking; Patreon even charges sales tax if you donate under a reward tier (they don't if you go through the no-reward custom donation flow). It's cool to hate on Nintendo for being overly litigious these days, and they deserve that reputation, but with projects where piracy is clearly the main goal, and a significant amount of money is involved, I find it hard to sympathize. Even if it's technically legal, it strikes me as parasitic behavior. reply Medox 1 hour agorootparenthopefully a lot of that money was already put aside for upcoming lawsuits reply theultdev 12 hours agoprevThis is a pretty big case to watch. Are there any cases of emulators being sued successfully? A user being able to provide keys and a rom from which they could own or be homebrew doesn't seem to violate copyright to me. edit: seems the consensus is once via legal fund attrition, but the case went to the emulator authors in the end. reply monocasa 12 hours agoparentI don't believe so (the Sony v. Bleem cases mainly ended up in favor of Bleem), but also I don't think anyone has tried since the DMCA. It looks like Nintendo is taking a 'trafficking in circumvention device' legal strategy as opposed to a strictly anti-emulator legal strategy. reply stonogo 9 hours agorootparentDMCA was in effect the year before Sony first sued Bleem -- and it's notable that Bleem mostly won the lawsuits, but legal fees bankrupted them anyway. reply monocasa 9 hours agorootparentThe DMCA was in effect but not applicable to the case since the DRM scheme of the PS1 doesn't block access to the files of the disc, but instead simply attempts to block the usage of non DRMed media on legitimate PS1s. reply Natsu 7 hours agorootparentprevIt's funny, the game companies lost the emulator court cases. But the companies behind those emulators still went out of business. reply hn_acker 41 minutes agorootparentRight. What I hate about copyright is that winning a copyright infringement lawsuit with a fair use defense (fair use being by definition not infringement [1]) will still bankrupt you because of the legal fees. [1] https://en.wikipedia.org/wiki/Lenz_v._Universal_Music_Corp.#... reply johnny99k 12 hours agoparentprevThis won't matter. The goal will be to run them out of money. It's an open source project and they most likely don't have the capital to fund any sort of lengthy lawsuit. reply teeray 11 hours agorootparentI really wish our system had some kind of financial handicap when it came to access to the legal system. Weaponizing the legal system to bankrupt people that would be found Not Guilty shouldn't be possible. reply kelseyfrog 11 hours agorootparentI always wondered what would happen if litigants and defendants could contribute to a common legal fund which would equally fund their attorneys. It would at maximum make litigation twice as expensive which may be worth it alone. reply theultdev 11 hours agorootparentIf it's twice as expensive then the defendants would run out of money sooner right? You would have to somehow set a limit of legal expenses, which seems... difficult. You would have to win to get the common fund, you may not get that far if you have to pay into the fund and amount a defense. reply kelseyfrog 11 hours agorootparentThere might be a miscommunication. The litigants and defendants would not be compelled to contribute equal amounts. Just the disbursement would be equal. reply theultdev 11 hours agorootparentThen why would the litigants contribute in the first place? If nothing compels them to, they won't, so effectively the status quo. reply kelseyfrog 11 hours agorootparentWhat I'm hearing is that it solves the problem of Nintendo being to outspend the defendant. If Nintendo brings a lawsuit and spends zero dollars on court cost, it should be rather easy for the defense to also contribute zero and the lawsuit is avoided. Problem solved. reply theultdev 11 hours agorootparentAnd if Nintendo spends $10 million dollars? And Yuzu spends $25,000 and maybe wins the first case but runs out of money during the appeal and defaults judgment. Nintendo gets the pot because they won right? As I pointed out to another user, this reverses the damage if they win, but does not solve the problem of preventing them from being able to win. Now if you make it where if you want to spend $5 on lawyer fees, you have to loan $5 to the other side and if the other side wins they don't have to pay it back, that may work. reply rcxdude 10 hours agorootparentI think the proposal is not \"each side contributes to a pot and the winner takes it\", it's \"if one side wants to spend 10mil on a case and the other side puts in 25k, then each side has 5mil and 12.5k to spend on legal fees\" reply kelseyfrog 10 hours agorootparentThank you. Correct, there is not \"pot\" where the winner takes all. The fund is simply and always split 50/50 towards lawyers and fees. reply theultdev 10 hours agorootparentprevAh okay, if that's the case then yeah totally in support for that. That's essentially what I was suggesting with having to loan the opposing team the same amount of money you spend. reply syockit 11 hours agorootparentprevIt would be harder for big corpo to sue laypeople, but at the same time harder for laypeople to sue corpo. reply kelseyfrog 8 hours agorootparentWould fewer, fairer lawsuits be a win? reply jrockway 11 hours agorootparentprevThe legal system has sort of recognized this as a problem, which is why many states have anti-SLAPP lawsuits. Unfortunately, I don't think this strictly falls under the definition of \"public participation\", so there is no protection available. (And, big companies just try to sue you in federal court or states with no anti-SLAPP lawsuits. So anti-SLAPP is not the big victory it should have been.) reply kmeisthax 4 hours agorootparentAn anti-SLAPP law usually works by giving you a special motion that lets you say \"hey, I think this is a SLAPP lawsuit\", which basically gives you access to fee shifting (making the loser pay the winner's legal fees). Copyright already has this built in. Which is great news... for Nintendo. The problem that Nintendo is citing in their lawsuit is the fact that Yuzu ships Switch common keys. For the purpose of DMCA 1201, this is a smoking gun[0]. There isn't really a good legal argument for why emulators should be allowed to ship decryption keys, or at least, the EFF refused to come up with one when Dolphin asked for legal advice on this point a while ago. So if you go to court and provide a completely legally baseless argument, Nintendo wins, and then they move for fee shifting, which means they get to prosecute the case for free[1]. [0] While it is true that the scope of DMCA 1201 is far wider than just encryption keys, in this case, Nintendo has only cited the keys being in the emulator and the fact that Yuzu is really useful for running pirated software, which is \"good enough\". [1] In practice, it's more \"for cheap\" than \"for free\", because there's specific rules about how much you're allowed to fee shift, a whole bunch of stuff about 'lodestar amounts', etc. reply causality0 10 hours agorootparentprevLosing a lawsuit should make you liable for the opponent's legal funds up to the same amount you spent on yours. reply teeray 10 hours agorootparentYeah, but when cases take years you can run into cash flow issues, even if you might ultimately prevail. reply scarby2 9 hours agorootparentprevthis is how it works in a whole lot of places other than the USA reply Solvency 11 hours agorootparentprevEasy. The defendant and plaintiffs each hire and pay for lawyers they can or are willing to afford. But all of that money goes into a prize pot, which gets distributed based on who wins the case. This would ensure either Nintendo doesn't try to financially grind out a poor small company because the loss would not be worth it to them. reply theultdev 11 hours agorootparentThat doesn't solve grinding out the small company, though it does reverse the damage if they don't get ground out. The problem is not the end payout, it's the base cost can't be afforded along the way. One side can keep appealing and escalating, the other can't pay for the cases themselves. They may not get far enough to win the pool. You would have to have the lawyers work pro bono or some common legal fund pay for it until the case is won to get the pool. As I pitched to another user, how about: > for lawsuits, if you want to spend $5 on lawyer fees, you have to loan $5 to the other side. > if the other side wins they don't have to pay back the loan. reply Panzer04 10 hours agorootparentThe problem with that is you're ruined if you lose the court case. Few people would be willing to take on such a massive risk. reply DANmode 8 hours agorootparentBetter be sure of the veracity your case before taking the court's time. reply borski 12 hours agorootparentprevThat’s where approaching someone like the EFF comes in. reply giancarlostoro 5 hours agorootparentNow would be their time to shine. I know they do plenty, but this would be a great time for them to show up. reply theultdev 12 hours agorootparentprevIt matters for future precedence. It can be used to win cases against other emulators and even shut them down with limited legal action. reply johnny99k 12 hours agorootparentI suppose they could use Bleem VS sony reply theultdev 12 hours agorootparentBleem won in that case (but ran out of funds), so it's useful for the defendant. If Nintendo loses, the next defendant would have even more precedence. If Nintendo wins, it's easier to go after future emulator projects. reply nodja 10 hours agorootparentprev> The goal will be to run them out of money. They're already making $30k/month on patreon and you can easily foresee that this legal action will cause a call to arms for even greater funding, if that was indeed their goal they could have targeted the much smaller ryujinx and set a precedent. reply vineyardmike 9 hours agorootparent30K is nothing when it comes to paying for lawyers. This money will be gone by the time anyone enters a courthouse. reply diego_sandoval 11 hours agorootparentprevUnless the EFF or a similar org supports them. reply diggan 12 hours agoparentprevbleem! (PlayStation emulator) was sued by Sony and was forced to close down because of legal fees, so I guess that counts as a success for Sony. I seem to recall a bunch of ROM sites disappearing as well, but not sure if that's because they got sued or for other reasons. Some must have been sued and consequently shut down, so maybe not a bad idea (for the companies) to at least try? reply hellotomyrars 1 hour agorootparentSony also sued Connectix and lost. Sony purchased the rights to the emulator made by Connectix a year or so later. Connectix shut down 2 years after they sold the VGS to Sony but it isn't clear their fate was negatively impacted by Sony. This move by Nintendo is typical and there is no intent for it to ever actually go to court. It is legal bullying/posturing. The ironic/hopeful part is that team behind Yuzu does have some financial backing and this is going to create goodwill for them and they might actually be able to put up a defense (perhaps with the EFF getting involved maybe?) reply ender341341 12 hours agorootparentprevROM sites are different in that they are distributing the copywrited media The only 'emulator' cases I've seen be successful are due to the same, they didn't get in trouble for the emulator, they got in trouble for distributing ROMs. I wonder if there's some firmware code being distributed here? that's a common annoyance when it comes to using an emulator. reply tuetuopay 10 hours agorootparentAFAIK yuzu requires you provide your own firmware dump, so no redistribution happening reply Feorn 12 hours agorootparentprevI think ROM sites were an artifact of the internet speeds we had access to early on. Where it wasn't practical to just download an entire library for an older console. Downloading an N64 ROM over dialup still took a little longer than an mp3, whole collections of them were out of the question. Even early broadband in many areas was limited to speeds where a single ROM was more practical to download. Complete ROM collections were, and probably still are, available for most old systems as torrents and on usenet. reply gamepsys 12 hours agorootparentDownloading entire ROM collections quickly becomes too much data for local storage, starting with Saturn/PS1 and escalating from there. reply plussed_reader 12 hours agorootparentNah, you just need to scale up your storage expectation; I think 8TB will cover most of a PS1 localization. reply pierat 11 hours agorootparentSony Playstation NTSC-U dump is only 472GB. Oh, and they're available on Archive.org :) https://archive.org/search?query=Sony+PlayStation+-+%28NTSC-... reply plussed_reader 10 hours agorootparentMaybe it was PS2 localization, but those quantities are well within the consumer reach to maintain archives. It's just work, like anything else. reply Acrobatic_Road 11 hours agorootparentprevYou don't need to do this. I bought a 1TB sd card because I heard that was enough space to store every retro game up to n64. I ended up copying over a small hand-picked selection of games rather than the full romset. We need some people to keep copies of the full romsets for the sake of preservation, but typical users only want certain, popular games. reply theshackleford 11 hours agorootparentprevPlenty of large rom sites are still very actively used and trafficked today. reply anthk 11 hours agorootparentprevDownloading N64 roms as ZIP files was not a daunting task. PSX ISOs, OTOH... those were badly ripped. But most of the time you would just get Tony Hawk 2/3, the Zelda's, Mario 64, Jet Force Gemini, FIFA's, Wave Race and a few more in less than a week and the fun lasted months if not years. reply dartos 12 hours agorootparentprevROM sites are actually illegally distributing copyrighted content. Emulators are usually not stolen and are just reverse engineered. reply kevin_thibedeau 9 hours agorootparentModern consoles and arcades have anti-circumvention measures to restrict access to their internals. Software that bypasses such protections runs afoul of the DMCA even without any copyright violation. reply DinaCoder99 2 hours agorootparentprevThose sites are not illegal in all countries. reply xd1936 12 hours agoparentprevSony vs. Bleem! in 2001. Sony lost, but the cost still shut down the project. reply CobrastanJorji 12 hours agorootparentYep, Sony \"lost,\" but they still killed Bleem and forced the creator into an agreement to, among other things, not make any more Playstation emulators. So really, Sony 100% won. Bleem was a big deal, too. It let you just pop a Playstation game into a PC's CD-ROM drive and play it. When Sony finally nailed the coffin on them, they were working on a followup called \"bleemcast\" that would've let Playstation games be played on the Sega Dreamcast. reply prmoustache 11 hours agorootparentSome of it was released as individual emulators to play a single game. I played Gran Turismo 2 on my dreamcast using one of those. reply matheusmoreira 5 hours agoparentprev> Are there any cases of emulators being sued successfully? Sony lost all their cases in the past. They claimed they infringed copyright when copying PS1 BIOS for reverse engineering purposes, court ruled that was fair use as it was necessary to gain access to the unprotected elements of the console. The other case was some bullshit about advertising, they had the audacity to claim screenshots violated their copyrights. They lost in court but won in the market by bankrupting their competitors. Who knows what's gonna happen in 2024 though? Felony contempt of business model seems quite well entrenched at this point. Company puts \"IP\" into their product and suddenly they get to control what you do with it and it's illegal for you to resist in any way. Common sense says emulators are alternative compatible implementations of the original hardware which increases consumer choice. People should have every right to make an emulator, doesn't matter if it's an old console or one that's just been released. Emulators are competitors to Nintendo. If they don't like it then they should drop their \"exclusives\" nonsense and start releasing games on PC where they belong with better graphics and performance and all the bells and whistles that emulators provide. Who knows what these courts are gonna decide though. The copyright industry basically buys these laws anyway, there's no reason to believe they will rule favorably to the consumer. reply eemil 20 minutes agoprevI wish people would hold Nintendo to the same standards as Sony and Microsoft. But because they make the best games, everyone looks past their anti-consumer BS and permanently-stuck-in-the-90s corporate executives. reply ApolloFortyNine 9 hours agoprevWhen the game isn't be sold any more, along with the console, emulation makes sense. But the switch emulation for at least 2 years now has been more than good enough to run games of a current gen system, and you're absolutely kidding yourself if you think any meaningful percentage own the game. The emulator also requires Nintendo data they're not actually allowed to ship (there's a number of resources to download it though), but they specifically coded to support it. Imo switch 2 is coming and it'll likely be almost the same system just beefier, so going after the emulators makes sense for them. reply Liquix 8 hours agoparent> and you're absolutely kidding yourself if you think any meaningful percentage own the game. respectfully disagree. nintendo has fought hard to capture the casual/normie demographic and they have consistently sold more switches than M$ has sold xbox ones every month since launch. switch emulation is alive and well but doesn't jeopardize their position as the non-techie's console of choice. therefore they have taken to only pursuing legal action when an emulator is being packaged up for the masses to one-click install on steam reply johnnyanmac 7 hours agorootparentIs \"well they sold a lot I can just take it\" ever a good defense? >they have taken to only pursuing legal action when an emulator is being packaged up for the masses to one-click install on steam Well, this breaks that trend. AFAIK Yuzu has none of that. Their general argument is that it made too much patreon money over Tears of the Kingdom. reply NamTaf 8 hours agorootparentprevThe GP meant that they postulate a meaningful percentage within the scope of people who emulate don’t own the game they emulate. reply chii 7 hours agorootparentand the implied assumption is that all those who did use the emulator without buying would've bought them. reply joemi 6 hours agorootparentSurely not all would have, but similarly not zero either. I think this is the real implied assumption. reply dt3ft 2 hours agorootparentprevNormie here. I will not be buying any more switch games now that I heard about this emulation thing. reply yungporko 2 hours agorootparentif you own a pc that can run emulated switch games and you can use it well enough to actually do it, you aren't a normie. reply Lammy 9 hours agoparentprev> for at least 2 years now has been more than good enough to run games of a current gen system To be fair that's impressive but nothing new. I 'member running N64 games with my Voodoo card in 1999 when GameCube wouldn't be out for two more years: https://en.wikipedia.org/wiki/UltraHLE reply matheusmoreira 5 hours agoparentprev> When the game isn't be sold any more, along with the console, emulation makes sense. Emulation makes sense since day one. Frankly, good emulation is straight up better than the console. Accuracy is high and you get a lot more features. Truth is they should have released the games in this format to begin with but they insist on creating little digital fiefdoms with \"exclusives\" and DRM instead. If anything doesn't make sense it's all this copyright nonsense which should be abolished. > you're absolutely kidding yourself if you think any meaningful percentage own the game Not really their problem. It's the players who are infringing copyright, not them. > The emulator also requires Nintendo data they're not actually allowed to ship That's called adversarial interoperability and it's required for the system to function. https://www.eff.org/deeplinks/2019/10/adversarial-interopera... If anyone is to blame it's Nintendo for coming up with a system where it's impossible to not infringe on their precious \"IP\" while interoperating. Just like Sega was blamed when it tried to work their trademarks into their \"security systems\" in order to deny their competitors their rights: https://en.wikipedia.org/wiki/Sega_v._Accolade > The court's written opinion followed on October 20 and noted that the use of the software was non-exploitative, despite being commercial > and that the trademark infringement, being required by the TMSS for a Genesis game to run on the system, was inadvertently triggered by a fair use act and the fault of Sega for causing false labeling reply sircastor 10 hours agoprevI feel like there ought to be a sliding scale of cost associated with filing a law suit. If you're a very large company suing a very small company, it should be very expensive to file. Expensive enough to make your lawyers encourage you to think really hard about whether or not this is actually a threat to your business. Of course, applying that to the real world would obviously fall apart quickly. It's not hard to think through loopholes. It just seems to easy to crush a small company/group who are just doing something you don't like. reply aussieguy1234 10 hours agoprevThis is unfortunate. The switch is probably coming to the end of its life soon. As soon as Nintendos next gen (announced or not) console is released, the switch will be a legacy system and emulation is important for archiving purposes. This does make it less likely that i'll be buying any Nintendo products in the future. reply a_vanderbilt 5 hours agoparentI suspect that the \"Switch 2\" is going to be like the GameCube -> Wii, where the hardware is backward compatible and largely just a faster version of the previous generation. Essentially being a suped-up Switch means Yuzu could immediately work much better with whatever they come out with next. I think that is why they are going after Yuzu now, to try and get ahead of another Dolphin situation occurring much earlier in the lifecycle. Should Nintendo get a favorable ruling, this would open a huge can of legal worms for the tech industry as a whole. reply postexitus 13 minutes agoprevOh there is good emulation of Switch on powerful Switch-like devices? I will definitely give it a try. Thanks Nintendo! reply GrabbinD33ze69 11 hours agoprevCorrect me if I’m wrong, but wasn’t Nintendo caught using an open source emulator for the switch, without any sort of credit to the authors after suing? If so, I have no empathy for them. reply lmm 11 hours agoparent> Correct me if I’m wrong, but wasn’t Nintendo caught using an open source emulator for the switch, without any sort of credit to the authors after suing? Majesco Entertainment published some switch games made by Mistic Software, which used an open source emulator without credit and in violation of its license (and therefore were infringing copyright). Atari was somehow involved as well. Nintendo had no involvement, unless you consider them responsible for not doing a thorough enough license audit of every company that publishes Switch games or something. reply Aissen 2 hours agorootparent> unless you consider them responsible for not doing a thorough enough license audit of every company that publishes Switch games or something. That's the thing with closed platform, you can't have your cake and it too. reply globular-toast 1 hour agorootparentThey can if software is licensed under MIT or a similar \"permissive\" licence. In this case the software was correctly licensed under GPL, though. reply hn_acker 30 minutes agorootparentNintendo was not involved. Mistic Software ported Windows/Mac computer games to Wii using ScummVM, a virtual machine program under the GPL 2.0 or later license at the time (now 3.0 or later), without crediting the ScummVM team [1]: > In December 2008, the ScummVM team learned that the recently released Wii ports of three Humongous Entertainment Junior Adventure titles, Freddi Fish and the Case of the Missing Kelp Seeds, Pajama Sam: No Need to Hide When It's Dark Outside, and Spy Fox: Dry Cereal, have all used the ScummVM engine without proper attribution. The games were published on request of Atari through Majesco Entertainment, who turned to Mistic Software to port the games. Mistic had used ScummVM for these, but failed to credit the developers. While the ScummVM team contacted gpl-violations.org for legal advice, Atari instead threatened to sue the ScummVM team, as the terms of Nintendo Wii development kit heavily restricted the use of open source software, including the GPL. A settlement was made in 2009, in which ScummVM would drop the investigation of the GPL violation, on the condition that Mistic would sell or destroy all GPL-violating copies of the games, make a donation to the Free Software Foundation, and pay the legal fees. As a result, this legal dispute significantly limited the availability of the Wii ports of these three titles.[1] [1] https://en.wikipedia.org/wiki/ScummVM#Mistic's_GPL_violation... reply TillE 11 hours agoparentprevCanoe (their SNES emulator) is definitely their own creation, it's very limited and can mostly only run the games they've released with it. I think it has some similar bugs to ZSNES, but that's just because they're both crappy low-accuracy emulators. reply NobodyNada 10 hours agorootparentInterestingly, their NES emulator uses the file format of the freeware INES emulator (which became the de facto standard format for all NES emulators, and of course for distributing ROMs online). At the very least, this indicates that Nintendo definitely relied on resources and documentation from the NES emulation community. But it also raises questions as to why they used the INES format as opposed to some internal format of their own: was it just because they wanted to use a spec they found online instead of writing their own, or did they pirate their own games to test (or even ship)? reply ThatPlayer 10 hours agorootparent> But it also raises questions as to why they used the INES format as opposed to some internal format of their own The answer to that that I've seen is simply they hired a man who previously worked on INES: https://web.archive.org/web/20061228071701/http://www.n-side... . This man is then top credited in Animal Crossing for \"NES Emulator Program\". reply Mad_ad 11 hours agorootparentpreviirc they used a open-source emu on their snes/nes mini reply chungy 10 hours agorootparentNintendo's NES/SNES emulators have always been their own in-house tools. The NES/SNES Classic consoles did run on Linux, and Nintendo published the operating system source code as required by the software licenses, appropriately. The emulators are not part of the source release, and very likely derived from the same ones used on Wii virtual console (possibly older, Animal Crossing had a NES emulator on the GameCube too). There's a popular myth floating around that Nintendo downloaded Super Mario Bros. off the internet only to sell it back to players via the Wii virtual console, but I'm only comfortable with calling it a myth because it's based on the fact that the embedded iNES file in the VC release is identical to iNES files you can find online. There's only one standalone version of Super Mario Bros. on the NES, and you can trivially recreate an exact file on your very own if you have the cartridge and a ROM dumping utility. It's a pretty good possibility that Nintendo created their virtual ROM in exactly the same fashion. The iNES format itself is very simple, and Nintendo hired the iNES developer to work on their in-house software; he could have easily just brought that same format into their official projects. (EDIT: This last sentence appears to have been another myth I bought into, see the reply to this comment.) reply bc_programming 9 hours agorootparentMy understanding is that The \"Nintendo hired the iNES Developer\" story is actually it's own myth! The person referenced who Nintendo hired is Kawase Tomohiro. The basis for calling him \"The iNES Developer\" is that, in a changelog for 0.7 of iNES, Marat Fayzullin - the developer of iNES - wrote: \"Sound support completely rewritten, thanks to Kawase Tomohiro\" That is the entirety of the association. That single line in a changelog. Based on similar \"thanks\" lines it was probably because they reported some emulation issues and not because they personally rewrote the sound support for the emulator, but resulted in Marat doing so. It's actually interesting how these stories seem to change over time. The last time I heard this, the story was that Nintendo had hired somebody who contributed to iNES, which was at least technically true if a bit misleading, but it seems that now the story is that they hired *the* iNES Developer. Which seems particularly silly when we consider the basis is that 8 word changelog line. reply chungy 9 hours agorootparentInteresting, I always assumed Marat himself was hired. Thanks for the correction! reply Kirby64 11 hours agorootparentprevMaybe you're thinking of the 'Playstation Classic' ? That uses PCSX directly and got some flack for it. See: https://arstechnica.com/gaming/2018/11/sony-using-open-sourc... reply throwaway345353 6 hours agoparentprevYou're probably thinking of this: https://www.eurogamer.net/did-nintendo-download-a-mario-rom-... reply sureglymop 11 hours agoparentprevI recall something like that when they released those mini consoles like the mini NES (NES Classic). But looking into it now, it seems that only used OSS software (linux, busy box, alsa, etc.). reply deminature 10 hours agoprevI wish they'd offer a legal avenue to play Switch games at 4K/60 instead of 720p/20-30. Anyone looking for a higher fidelity experience than the 2017 Switch hardware is able to provide is forced to use software like Yuzu to enable it. Even Sony has started porting their crown jewel games to PC to enormous commercial success, allowing players with high-end hardware to legally enjoy a higher fidelity experience, but Nintendo is stuck in the past. reply dartharva 5 hours agoparentEmulators are a legal avenue. reply xnx 10 hours agoparentprevI've read rumors, and it seems very plausible, that Nintendo's next console might be able to play Switch games at higher resolution and/or framerate. reply bigpapikite 10 hours agorootparentThat's probably the case (as I don't know what else would make it worth buying), but the ultimate problem with Nintendo will still remain. They're bullies and they get away with it because they make some of the most consistently high quality first party games. Microsoft took the plunge first, but everyone is realizing that the future is an open platform. Turns out if you make a quality game and make it widely available people will buy it (surprise). But they're married to the idea of restricting how their titles are played, which is only going to continue to turn people off. reply johnnyanmac 7 hours agorootparent>They're bullies and they get away with it because they make some of the most consistently high quality first party games. You can look at it this way: Nintendo makes the most consistent high quality first party games and have the lowest hardware spec. So they are most prone to piracy and unauthorized emulation and thus get the most attention when lawsuits come up. MS has 99% of its games on PC and Playstation specs are so hard (or maybe lack of interest. Probably many things) that gen 7 tech is still difficult to emulate in Gen 9. So Nintendo has the biggest target. >but everyone is realizing that the future is an open platform. If \"release a port 2-3 years later on Windows OS to double dip\" is \"open platform\", I kinda get why Nintendo defends their platform so rigidly. They are all closed down source games on closed down source OS's hosted on closed down source storefronts. There's no legal distinction there, just technical preferences of the minority who take the time to figure out how to setup emulation. And despite all that, Nintendo sells more on one system than both competitors on all platforms combined. I don't think they are worried about sales. Especially since they aren't chasing 300m dollar productions with 10 hours of cinematics. reply Panzer04 10 hours agorootparentprevIt's the difference between being a publisher/game developer and a hardware company. Hardware companies see games as a means to sell consoles. Game developers see platforms as a means to sell games. If you're coming at things from the perspective of a hardware maker it makes sense to be as restrictive as possible, since that provides the differentiation that sells your (overpriced) hardware. In addition, if your hardware becomes common then you can charge game developers for access (more broadly, this is what Apple does, mostly) From the game developer side, it makes sense to be on as many platforms as physically possible, since that's just more places to make sales and money. reply BlueTemplar 6 hours agorootparentIs Nintendo even making money on the Switches themselves ? reply hellotomyrars 1 hour agorootparentNintendo is famous for not selling their hardware at a loss unlike other console manufacturers. The only systems known to be sold at a loss were the 3DS (after price cuts) and the Wii U. This is part of why the hardware is underpowered compared to contemporaries. reply garaetjjte 6 hours agorootparentprevMicrosoft, open platform, what? With all that Trusted Computing and Pluton stuff? reply pipes 2 hours agoprevNot sure how I feel about the developers making 30k a month in patreon donations for writing an emulator for a current gen console. Nintendo might have a point here. Edit: that said, I did pay 5 dollars (or something like that) for redream, which is a Dreamcast emulator. But in my mind at least, this doesn't deny the developers of the games I play on it the money they would get from a sale. Because it is a dead platform. I know for a fact that when I pirated Dreamcast games back in the day, I would have paid for at for some of them at least. I don't feel great about that. It was one of my favourite consoles and I probably aided in it's untimely demise. reply hamoodhabibi 1 hour agoparentPersonally I really don't get this outrage over emulators. A huge chunk of the population can't afford Nintendo Switch or its expensively priced licenses. They turn to a zero-cost grey-market online. Nintendo wants to turn those people into paying customers? Somebody who owns a Switch and buys games aren't going to stop paying so who is Nintendo really trying to deny? How do we decide who gets to listen to a song and who doesn't on the internet where information constantly tries to reach homeostasis by becoming free and widely available? Capital? reply johnnyanmac 2 hours agoparentprevwould it change if they were making less money? or emulating a previous generation? Or if that 30k was split between 100 devs and is basically a small tip per month instead of a very comfortable wage for a single dev? reply mock-possum 1 hour agoparentprevI know how I feel about it - 1) they deserve every penny and 2) Nintendo needs to back off. reply gamepsys 12 hours agoprevThis is truly awful for the gaming community at large. If this case makes a ruling then it will most likely have an impact on all emulation projects. If Nintendo decides to sue your open source project, how do you mount a legal defense? reply dartharva 5 hours agoparentAwful for the emulation team? Yes. Awful for the gaming community at large? Eh, Nintendo products are not as dominating as you think. It is only available in select countries and has a hundred million users at best. Compare that to PC and mobile gaming, it is almost negligible. Though it would indeed be problematic if American courts manage to establish a precedent criminalizing emulators. That is indeed a real threat; American courts are not known for robustness or integrity. reply Sakos 1 hour agorootparent> Though it would indeed be problematic if American courts manage to establish a precedent criminalizing emulators. That is indeed a real threat; American courts are not known for robustness or integrity. That's exactly why it's awful for the gaming community and honestly for human culture at large. Video game preservation isn't a thing without emulators. If Nintendo wins this, it means open season on every (major) contributor to an emulator and every emulation project. It means the end of the thriving emulation community and anybody interested in contributing except for a handful who are willing to risk being sued and/or live in a place where the US justice system has no reach. And it's not like Western Europe is particularly friendly to anything or anybody that circumvents DRM. reply Springtime 12 hours agoprev> The legal document claims that over a million copies of last year's The Legend of Zelda: Tears of the Kingdom were downloaded prior to the game's official retail release. As a result, the company is now seeking damages and is demanding that the Yuzu emulator is shut down. Quite the leap from existing as an emulator to inexplicably being held liable for some independent leak. reply burnte 11 hours agoparentWhen you file a lawsuit, you make it seem like the biggest thing since WW2, because it'll be cut down in court over time to a more reasonable level. reply realusername 11 hours agoparentprevThere's actually multiple arguments with zero proof there. - they didn't prove that Yuzu contributed to piracy (and since the amount of piracy tools on the Switch itself that's far from obvious that Yuzu is a first choice) - they didn't prove that the leak itself lead to a loss of revenue. And that's also very hard of an argument to make considering that this game was a huge commercial success. reply gknoy 11 hours agorootparentDoes loss of revenue matter at all? It feels like it should, but I had thought that it didn't matter in courts. reply inyorgroove 11 hours agorootparentFrom my podcast law degree, in civil action like this yes. To get standing you must show you were harmed in some way and that the court can remedy that harm. That is just one of many parts of the standing test that a federal court will apply. https://en.wikipedia.org/wiki/Standing_(law) reply hn_acker 10 minutes agorootparent> To get standing you must show you were harmed in some way and that the court can remedy that harm. That is just one of many parts of the standing test that a federal court will apply. Not in copyright cases. You have to show harm for actual damages, but copyright has statutory damages: you only need to demonstrate a violation of the law (the copyright statutes) for damages [1]: > In all countries where the Berne Convention standards apply, copyright is automatic, and need not be obtained through official registration with any government office. Once an idea has been reduced to tangible form, for example by securing it in a fixed medium (such as a drawing, sheet music, photograph, a videotape, or a computer file), the copyright holder is entitled to enforce their exclusive rights.[35] However, while registration is not needed to exercise copyright, in jurisdictions where the laws provide for registration, it serves as prima facie evidence of a valid copyright and enables the copyright holder to seek statutory damages and attorney's fees.[48] (In the US, registering after an infringement only enables one to receive actual damages and lost profits.) Statutory damages do not need to correspond to actual damages [2]: > The charges allow copyright holders, who succeed with claims of infringement, to receive an amount of compensation per work (as opposed to compensation for losses, an account of profits or damages per infringing copy). Statutory damages can in some cases be significantly more than the actual damages suffered by the rightsholder or the profits of the infringer. [1] https://en.wikipedia.org/wiki/Copyright#Registration [2] https://en.wikipedia.org/wiki/Statutory_damages_for_copyrigh... reply kevingadd 11 hours agorootparentprevIf you want to get a lot of money from the defendant, you usually have to prove damages. reply bitwize 11 hours agorootparentprevIf a device's only use involves copyright infringement, it's illegal to sell or distribute in the USA. That's how they went after cable descramblers and, less successfully, VCRs in the 80s. Since getting actual Switch game data necessarily involves violating the DMCA, Nintendo's lawyers will have an easy time showing that the only way yuzu can be useful is if the user violates copyright law, thus making the emulator itself illegal. That is if this even makes it to court. reply hellotomyrars 1 hour agorootparentThe DMCA specifically has language about being entitled to circumvent a technological measure\" for \"the purpose of enabling interoperability of an independently created computer program\". This language has never been tested in court but there is a compelling argument to be made. The Copyright Office has become increasingly friendly to these types of arguments as well, though they have imposed some limitations on games hardware. The next set of rules/guidance they put out won't be until october (They do it every 3 years). Yuzu isn't sold* as a product and unless Nintendo can convince the court that the mere act of emulation (or obtaining the console keys required to make Yuzu function in the first place) violate their copyright, then I don't see it personally. You can run code that isn't owned by Nintendo on a Switch. Maybe there is a reasonableness argument that people aren't using Yuzu to play Switch homebrew, but there is a homebrew scene around the Switch. reply gjsman-1000 12 hours agoparentprevNot necessarily. It's fairly easy to prove that if the emulator did not exist, the leak would be fairly inconsequential; and considering how easy it is to show the percentage of pirating users versus legitimate users (probably 95%+), it's not a good look. There's also the issue that, unlike prior emulators, Yuzu risks running afoul of DMCA anti-trafficking provisions for circumvention devices and software that uses circumvention devices. So, while per se emulating the Switch might be legal, decrypting the games may be illegal (as would software that is useless if it is unable to do that decryption). Edit: Strongly recommend reading my follow up comment explaining historical precedent: https://news.ycombinator.com/item?id=39530558 reply bentley 12 hours agorootparent> Not necessarily. It's fairly easy to prove that if the emulator did not exist, the leak would be fairly inconsequential… Well, no. Pirated Switch games can be played on a hacked Switch or a flashcart with no emulation necessary. Common sense suggests emulation would be significantly more common, but can Nintendo prove that in court, or prove that the leak wouldn’t have happened without Yuzu’s existence? reply jsheard 12 hours agorootparent> Common sense suggests emulation would be significantly more common, but can Nintendo prove that in court Nintendo is making that argument on the basis that Yuzu's Patreon income skyrocketed when TOTK leaked online. https://graphtreon.com/creator/yuzuteam It checks out, TOTK leaked on May 1st 2023 and Yuzus monthly income rose from $19k to $45k throughout May, having never broken $25k previously. reply tavavex 12 hours agorootparentI'm confused as to how or why the Yuzu team would be held liable for this. Is it their responsibility to ensure that people don't donate money to them if the timing of that donation coincides with an unrelated leak of Nintendo's IP? If emulation is allowed and the Yuzu team itself isn't engaging in the promotion of piracy, I don't see what the case is here. reply ndiddy 11 hours agorootparentAt the time Zelda leaked, it didn't work correctly in the release version of Yuzu. The lawsuit claims that the Yuzu team released a patched version that fixed the issue before the game's official retail launch date, but they have some sort of exclusivity period (looks like one week as far as I can tell) where new releases are exclusive to their Patreon before they become freely available. Nintendo is arguing that the large boost in Patreon subscribers was due to people wanting to get access to the patch so they could play Zelda early. reply tavavex 11 hours agorootparentI think this would be a big issue for them if they specifically marketed it as \"the Zelda fix\" or insinuated that the only purpose of that update was to make this leaked game playable. Otherwise, they could just say that updates address the dissimilarities between the Switch hardware and the emulator. How can Nintendo prove ill intent here? reply Lammy 11 hours agorootparentThey (publicly) blocked discussion of TOTK fixes until the game's release day, but that's still 0th hour and any build to include the fix would have been early access for whatever the ea period is: https://github.com/yuzu-emu/yuzu/issues/10226#issuecomment-1... Prescient comment marked as off-topic: https://github.com/yuzu-emu/yuzu/pull/10234#issuecomment-154... reply rincebrain 11 hours agorootparentprevThat's an interesting argument, but I'm not sure it'll hold water with the judge unless they can't show such arrangements are very common with donation-funded software and was in place well before this leak, e.g. yes, we made money off this leak, but not because we designed the model to profit off people wanting to pirate/cause loss of sales, it's just how this has always worked. We'll see. I'm not really sure there's anything they could have done better in that case as a positive defense if they had this in mind, though - like, releasing it not behind a timegate paywall could be an argument for actively destroy game sales even more, by that logic, and actively waiting until post-launch to release it could be argued to be around trying to extract more money from people to focus on it more. reply garaetjjte 11 hours agorootparentOuch, releasing patch before official launch sort of proves they pirated the game themselves, which somewhat undermines defense that they don't encourage piracy. reply Kirby64 11 hours agorootparentNot necessarily. I don't know the context, but bugs/issues reported from users may have been sufficient to patch their code without touching the ROM themselves. reply rincebrain 10 hours agorootparentIf you read their writeup about fixing the game, the issues appear to stem from it heavily using a texture format that most GPUs don't support natively and almost no games having done much with that texture format before, so losslessly reencoding them was eating truly astonishing amounts of VRAM to avoid load time issues, and they reworked a bunch of memory management things to make it playable without 12G+ of VRAM. I don't know if there were any other issues, but at least on that one, it doesn't seem like they needed deep knowledge of the game to try reworking it. reply rincebrain 11 hours agorootparentprevThis feels similar to arguing that the Flipper Zero is a car theft tool because people went out and bought one after a video explaining how to use it to break some common car's lock was posted. I mean, yes, they presumably turned a larger profit correlated to people going and buying it for something illegal, but it's not solely or even primarily used for that, people would be doing this without it, and they didn't have any involvement or encouragement that people do anything criminal with it. reply michaelmrose 12 hours agorootparentprevYou can prove irrelevant correlation. They weren't even paid for TOTK. The fact that users may have intended to play TOTK is something Yuzu had no control over. reply gjsman-1000 12 hours agorootparentprevNintendo can't prove the leak wouldn't have happened without Yuzu. But they don't have to. They can simply show that Yuzu made it infinitely worse. Also, suing Yuzu does not preclude suing emulator makers or flashcart makers - they can all be sued as they all have culpability. reply resizeitplz 12 hours agorootparentWith apologies for the pedantry, they didn't make it _infinitely_ worse. They may have made it _significantly_ worse. reply mardifoufs 11 hours agorootparentprevWhat do you mean they just need to show that it made it worse ? What are you basing that on? I don't know of any similar cases where an emulator or say, a video player (for example Kodi) was held liable for increasing demand? reply qingcharles 11 hours agorootparentprevOne thing to take into account is that civil trials don't require the absolute highest standards of proof, such as proof beyond a reasonable doubt. Usually much lower evidentiary standards such as \"preponderance of the evidence\" and other malarky. reply hsbauauvhabzb 12 hours agorootparentprevSo can companies of leaved PC games sue nvidia or windows? reply gjsman-1000 12 hours agorootparentThe law doesn't work on strict abstract principles. Windows has a million uses of which piracy is just one. Yuzu has two uses (playing legitimate backups and pirated backups), of which Nintendo may successfully argue, both are piracy (due to the circumvention of encryption in both cases). In which case, the only possible use in 99.9%+ of cases... is for illegal activity. reply wtetzner 3 hours agorootparent> Yuzu has two uses (playing legitimate backups and pirated backups) And maybe for developing homebrew games? reply tavavex 11 hours agorootparentprevI don't think it's likely that software developers can be sued on the grounds of \"some people use it for illegal activity\". Can IP rights holders sue any torrent tracker on that basis? Not to mention that playing backups of your own games is explicitly legal in many places, and I'd be shocked if it isn't in the US. Lastly, one can make an argument that the purpose of Yuzu isn't playing \"Switch games\", but emulating the Switch hardware stack, which is legal. For example, writing your own Switch homebrew and running it on Yuzu is permitted. reply withinboredom 12 hours agorootparentprev> It's fairly easy to prove that if the emulator did not exist, the leak would be fairly inconsequential That. Literally doesn't make any logical sense. That's like arguing that if computers didn't exist, the leak would be fairly inconsequential ... or if electricity didn't exist, the leak would be fairly inconsequential. reply UberFly 12 hours agorootparentLogical sense? I can't really just play the pirated game on my home electricity. Just like you can't sue the road when a car runs you down. reply withinboredom 12 hours agorootparentWell, let me put it this way. Why don't they sue Dell then? If Dell computers didn't exist, pirated games couldn't be played! Or sue themselves, because if hacked Switches didn't exist, pirated games couldn't be played! reply Zambyte 11 hours agorootparentprevI really can't just play the pirate game on a software emulator either. It needs an operating system to run on, hardware to run the operating system on, etc. reply Solvency 11 hours agorootparentprevOf course, it doesn't make sense. But Nintendo has infinite money and infinite lawyers compared to these people. That means they can do whatever they want with the law. reply withinboredom 11 hours agorootparentThat's when you go to the judge and ask for a summary dismissal on the grounds that it is ridiculous (they should be suing the power companies instead!). Maybe they say yes and you walk away. reply Gigachad 12 hours agorootparentprevI'd say most piracy is people with an actual console that they have modded to load pirated games. reply KeplerBoy 11 hours agorootparentImpossible to say. Downloading yuzu and watching a YouTube video to get roms going is easier than obtaining a modded switch, that one is certain. reply summerlight 12 hours agorootparentprev> unlike prior emulators, Yuzu risks running afoul of DMCA anti-trafficking provisions for circumvention devices and software that uses circumvention devices This is interesting, it'd be great to have a link to explain this matter more deeply. reply gjsman-1000 12 hours agorootparentSure. Just look up the DeCSS controversy which got the creator of a DVD ripping software arrested and barely avoiding extradition, or the 09 F9 controversy where the MPAA attempted to censor a number from the internet. This provision in the DMCA has been most often used against developers of unauthorized DVD copying software, Blu-ray copying software, etc; and the force of the legal argument has been well proven previously. It nearly killed RealPlayer when they made unauthorized software for DVD playback. You can also see this law invoked in Apple v Psystar; when Apple sued Psystar for circumventing protections in macOS to allow running macOS on non-Apple hardware. That lawsuit was dragged all the way to the final appeal to SCOTUS - and Psystar was shredded the whole way. Expect Apple v Psystar to come up in a Nintendo vs Yuzu lawsuit; because running macOS on unapproved hardware sounds awfully similar to running games on unapproved hardware. If Nintendo were to succeed invoking it here - emulation would be legal. Decrypting games would be illegal. Consoles before, say, the Wii (IIRC) would be free to emulate due to not being encrypted - but newer games, being encrypted, would be off-limits just like DVDs. reply oxguy3 7 hours agorootparentThere is some overlap with that case, but also some major differences. Psystar was distributing computers with a modified version of Mac OS X preinstalled, whereas Yuzu is not modifying or distributing any Nintendo-copyrighted materials. However, Psystar was also charged with violating DMCA section 1201(a), the section dealing with creating copyright circumvention devices, and Yuzu could potentially be found in violation of that. However, Yuzu requires that you bring your own decryption keys obtained from your own Switch device; it cannot circumvent copy protections without that. The only circumvention code included in Yuzu is basically just standard 128-bit XTS-AES decryption code; it seems like a ruling that makes that code illegal to distribute would be a bad idea. Psystar order granting permanent injunction: http://www.groklaw.net/pdf2/Psystar-242.pdf DMCA 1201(a): https://www.law.cornell.edu/uscode/text/17/1201 Yuzu's crypto code: https://github.com/yuzu-emu/yuzu/tree/master/src/core/crypto reply Acrobatic_Road 11 hours agorootparentprevI wonder if it would be possible to develop a Switch emulator without the ability to decrypt any games. Users would be expected to bring already-decrypted games, which they could decrypt via an \"unrelated\" program. reply throwaway48r7r 10 hours agorootparentYou already have to provide your own encryption keys to the emulator. reply Acrobatic_Road 6 hours agorootparentYes, but then it (presumably) decrypts the games for you, which could violate the DMCA. reply A4ET8a8uTh0 12 hours agorootparentprevThat was one of the few times, when I can look back and feel like the user has won. It has been something of a steady decline since. I would love for some clear indication that we have some digital rights left, but I am not certain the same reaction would not be possible to be replicated today. reply yamazakiwi 12 hours agorootparentprevThere are other emulators besides Yuzu and they would still exist if Yuzu didn't. reply monocasa 12 hours agorootparentprevI mean, the switch has been hacked to hell and back and is more than capable of playing pirated games without any emulators. It isn't necessarily easy to show stats on pirating users since they obviously work to cloak that behavior from Nintendo. reply bitwize 11 hours agoparentprevIt's called contributory copyright infringement. The Supreme Court only ruled that the VCR was legal based on a very narrow use case: if a television broadcast aired once and only once, never to be seen again, and the user could not see it as scheduled, they were legally entitled to use a device to record the broadcast and watch it at a later time -- once, after which they would presumably have to destroy the recording. And there are legal experts who believe even that is a yard too far. Nintendo's case is a lot more airtight. To play anything on yuzu, you have to defeat the encryption on Switch games, itself a felony DMCA violation (irrespective of how good or bad the encryption is). Therefore, yuzu can only be used to play pirated material, therefore it contributes to copyright infringement. \"But muh homebrew\" -- people who want to develop for Switch can get a development license from Nintendo. The fact that this is an option would weaken developing for Switch as a legitimate use for yuzu. reply wtetzner 3 hours agorootparent> \"But muh homebrew\" -- people who want to develop for Switch can get a development license from Nintendo. The fact that this is an option would weaken developing for Switch as a legitimate use for yuzu. Just because you can get a license from Nintendo doesn't mean the emulator isn't useful for development. reply 224 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nintendo has filed a copyright infringement lawsuit against the Yuzu emulator creators, accusing the tool of enabling piracy by bypassing copyright protection on Nintendo Switch games.",
      "The lawsuit mentions the significant earnings of Yuzu's Patreon page, generating nearly $30,000 monthly, leading Nintendo to seek damages, a jury trial, and the closure of the emulator.",
      "As a consequence, the release of the Dolphin emulator on Steam has been canceled."
    ],
    "commentSummary": [
      "Nintendo is suing the developers of the Yuzu emulator, enabling Switch games on PCs, sparking debates on emulation legality, copyright, and fair use.",
      "Discussions also include emulator performance versus the actual Switch, funding legal battles, and big corporations' influence on smaller entities in gaming.",
      "The conversation extends to hardware limits, game access, piracy, DMCA rules, and legal standing in emulator-related cases."
    ],
    "points": 759,
    "commentCount": 509,
    "retryCount": 0,
    "time": 1709069150
  },
  {
    "id": 39522348,
    "title": "From Open Source to Profit: Transforming Nodemailer into EmailEngine",
    "originLink": "https://docs.emailengine.app/how-i-turned-my-open-source-project-into/",
    "originBody": "How I turned my open-source project into a business Andris Reinman Feb 27, 2024 • 4 min read When I started writing and publishing open-source software about 15 years ago, I was pretty radical about it. I only used permissive licenses like MIT or BSD, as all I cared about was reach. Using a copyleft license with strings attached seemed to hinder that reach. Getting another A-category company to use my open-source libraries like Nodemailer was a badge of honor. I even went so far that when a founder of a major transactional email service sent me an email regarding Nodemailer and offered to make a donation to promote my efforts, I rejected it. I did not want to seem affected by one of the dominant providers because this would not be fair to other providers. In hindsight, what a fool I was. In any case, it changed years later when a startup using Nodemailer was acquired for half a billion dollars. I was financially not in a good place back then, and when I saw the news, I started to wonder – what did I get out of this? Sending email notifications was a huge part of that service, and they probably sent millions of email notifications a day using Nodemailer. At the very least, I saved them tons of developer hours by providing a free and solid library for sending these emails. I searched my mailbox for emails related to that company and found a single complaint about a feature. No pull requests, no donations, no nothing. And there was nowhere to complain either as I had knowingly given my software for the world to use with no requirements to compensate anything. My empty wallet was not happy about the turn of events. So, when I started what eventually became EmailEngine, I tried to cover my back as much as possible. I released the software under the copyleft AGPL license. I also set up an automated CLA process so that no one was able to get their PR merged without signing a CLA first. Many people hate CLAs, and several persons opened a PR first but closed it once they realized that there was a CLA requirement. Well, to be honest, I didn't really care. For example, 98.1% of the code for Nodemailer was written by myself, and only 1.9% was from other contributors, so not getting PRs merged was not a major issue. For EmailEngine, after a year and a half of being published as open source, the same numbers were 99.8% vs 0.2%. I use CLA assistant for managing CLAs in my projects Obviously, I wanted to make some money from my new project, and my business plan was simple. I published the project (it was called IMAP API at that time) as an AGPL-licensed application. I also offered an MIT version, but to get that, you had to subscribe. The subscription fee was 250€ per year. My assumption was that companies - the main target for the software - do not like copyleft licenses and would convert to the permissive license once they see how useful the app is. Well, it turns out my business plan was bonkers. I only gained a few paying subscribers, and it seemed to me those people weren't even using IMAP API. They just wanted to support my effort. It turned out that smaller companies did not care about the license at all, and larger companies were not using it. After a year and a half and 750€ in total revenue, I decided to jump ship — enough of providing free stuff. I re-designed the UI of the app to look more professional and implemented a license key system. From that moment if you wanted to use EmailEngine (the new name for IMAP API), you needed a license key that was only available for paying subscribers. I also changed the license from AGPL to a commercial license. The source code is still published publicly on GitHub. It is no longer open-source by definition but source-available. This change of license was only possible due to requiring outside committers to sign a CLA from the start. I still publish MIT-licensed projects, but only for smaller tools, not larger projects. The goal of these tools is to promote my main effort. For example, I extracted the IMAP client functions from EmailEngine and published it under an MIT license as a generic IMAP client library for Node.js. This module (ImapFlow) is gaining steam in adoption as it is by far better than any pre-existing alternative. The documentation page sends about 100 visitors per month to EmailEngine's homepage, which is not much, but hey, it is free traffic, and sometimes these visitors do convert, making the effort fruitful. At first, there wasn't even a trial option. If you did not provide a valid license key 15 minutes after the application started, the app just stopped working. I kept the price the same, 250€ per year, and during the first month, I sold 1750€ worth of subscriptions. That's like twice the amount I made in the previous year and a half, and it sealed the fate of the project. There was no going back. Next, I started to increase the pricing; 250€ became 495€, then 695€ and 795€, and finally 895€. To my surprise, it did not mean getting fewer customers. I guess any sub-$1k amount for businesses is peanuts, so the only thing these price increases changed was improving the revenue. The current MRR for EmailEngine is 6100€ and grows steadily, which in Estonia, where I live, allows me to pay myself a decent salary so that I can work on my project full-time. The only regret I have is that I did not start selling my software earlier and only published free, open-source software. Yes, I have some sponsors in GitHub, but it has never been a substantial amount, ranging from $50-$750 per month, depending on how many sponsors I happen to have. Selling to business customers is definitely more reliable and predictable than depending on the goodwill of random people. Edit: changed \"LGPL-licensed\" with \"AGPL-licensed\" as the original OSS license was AGPL, not LGPL.",
    "commentLink": "https://news.ycombinator.com/item?id=39522348",
    "commentBody": "I turned my open-source project into a full-time business (emailengine.app)584 points by andris9 23 hours agohidepastfavorite220 comments zoogeny 16 hours agoI think a key takeaway from this story is that the author started getting subscriptions once he caused the software to stop working without a license. > If you did not provide a valid license key 15 minutes after the application started, the app just stopped working. IMO, all of the shenanigans with license changes (MIT/LGPL/etc) are nothing to most users. On HN we are sensitive to these nuances . But in the \"real world\" of corporate worker bees just trying to get stuff done I doubt it even registers. More likely what happens is someone searches for a solution to a problem, installs it and sees if it works and then moves on with their day. Except they can't move on if the software stops working after 15 minutes. Clearly it is doing what they need, so now they need to unblock themselves. We might assume they'll read the code, find the license check and remove it. And I bet some percentage do exactly that. But some percentage of users would rather swipe a credit card for $X instead. reply bityard 16 hours agoparentI don't have a problem with commercial software, and I don't have a problem with open source software, but I do have a problem with developers releasing their code as open source, building a community while banging on the open source drum and then doing a rug-pull by taking the software commercial once they decided they have captured a big enough audience to extract money from it. All I'm asking is, if you want to eventually make money on your project, at least be up front about it in the beginning so that your users can make an informed decision when they decide whether to bake it into their stack. The rug-pull approach is always a much worse look in the end. reply j1elo 15 hours agorootparentI think like you. But also, one does not necessarily know beforehand that they will want to make money. Like a project could be born out of pure generosity, but after the happy initial phase the project might get too heavy on the maintenance requirements, causing the author to approach burnout, and possibly deciding that they want to make money to continue pulling the cart forward. However, here's something I do think: if you create something as Open Source, it should be out of a mentality of goodwill and for the greater good, regardless of how it ends up being used. OSS licenses do mean this with their terms. If you later get tired or burned out, you should just retire and allow the community to keep taking care of it. Just like it happened with the Jq tool [1]. [1]: https://github.com/jqlang/jq/releases/tag/jq-1.7 reply Vegenoid 13 hours agorootparentIf there is a community that is interested in taking care of it, can they not fork it? It seems better for the primary maintainer to continue working on it if people are willing to pay for it, than to stop working on it entirely. reply j1elo 10 hours agorootparentYes, but only a small subset of OSS projects reach the tipping point of having a large enough developer community with people willing to taking care of it. They are the most popular ones, so we tend to hear their names, as opposed to the other majority of projects which have users, but no devs that could take the lead. But of course, OSS ought to be, as I mentioned, a contribution to the greater good. If there are enough people interested in keeping something alive, they should be allowed to do so. reply pizza234 13 hours agorootparentprevThe implication here is that once an open source project is widespread enough, the maintainers are morally forced to provide development and support for free. This obviously doesn't make any sense. In real world, when maintainers change the license, if a software is widespread enough, a fork is created, and at least part of the community moves to it. reply lostlogin 10 hours agorootparentYour comment has me thinking about Markdown and the shenanigans with its future. John Gruber created Markdown but hasn’t done a lot for it in recent times, why should he? Others tried to fork markdown, which is also fine. But they forked it and named it Standard Markdown without good communication with Gruber about the project naming. It then got ugly. https://blog.codinghorror.com/standard-markdown-is-now-commo... Edit: I just realised how long ago this happened - 2014. The project appears to be active on GitHub and is now called Common Markdown. reply samatman 9 hours agorootparentIt's just CommonMark, Gruber was ticked off enough that he declined to allow them to use the term Markdown at all. Alone among the variations, or nearly so, he's fine (as your link indicates) with Git-Flavored Markdown. The thing is, they didn't fork it, they decided to \"standardize\" it. John Gruber had already published a Markdown standard: https://daringfireball.net/projects/markdown/, and a reference implementation. He's fine with variations on his standard existing, even somewhat encouraging, but took it as a personal insult that others set out on their own initiative to \"standardize\" something which already had both a standard and an implementation of it. I don't blame him at all. The outcome isn't so bad, really. We have a whole family of variations on Markdown, which is sometimes annoying for inter-op reasons but it's a lightweight plain-text standard, making a few tweaks to parse it with a different engine isn't going to ruin your day. CommonMark ended up being an acceptable standard for a minimum-but-extended dialect which the diverse implementations can (mostly) implement, which was the goal, and better yet, people don't get to be dicks about \"that isn't Markdown\" by reference to the CommonMark standard. Gruber made sure of that, and bless him for it. reply jowea 15 hours agorootparentprevI don't think it counts as a rug pull if you're free to grab the last open version. Why should they continue updating the software? reply andris9 15 hours agorootparentprevYou can't take the entire software commercial, as everything previously released under the open-source license will stay under that license. In the case of EmailEngine, all versions ever released under the AGPL license are still in Github; you can fork and use these freely. It is only the path forward that gets closed when going commercial - users can start paying, can stay indefinitely on the already released free versions, or can take the initiative and fork the project. reply StimDeck 13 hours agorootparentSimple. Open source doesn’t mean “free code for life”. Most people try to turn their time into money. Besides, any one of us could fork the project, compile binaries with a novel license check and charge for them. Why not the person who actually added value? reply gwbas1c 14 hours agorootparentprevAs many other respondents mentioned, the old version is still there. But, as TFA states: > I guess any sub-$1k amount for businesses is peanuts, so the only thing these price increases changed was improving the revenue. Businesses spend money to solve problems. $1k is a lot of money for a consumer product, but for a business product, $1k when something is business critical and handles high volume is significantly cheaper than hiring a person or contractor to solve the problem. Furthermore, the benefit goes both ways, as Reinman now supports the product full-time. The business customers are now working with a product that has full-time support, instead of hobbyist support. reply kiba 15 hours agorootparentprevYou mean making the software proprietary. The definition of open source itself is neutral on whether it's a commercial effort or not, or whether it's a community effort or not, or whether it's both community and a commercial effort. reply joveian 11 hours agorootparentThere is a difference between a commercial effort and calling something commercial software, which often (usually?) refers to licensed per use (often per installed system) software. Open source must be freely redistributable, which means it can't have a per use license. I think the main issue is the name. If a project is made more commercial or proprietary than it was before, please change the name (or additionally use a different name for the commercial/proprietary part, which seems to be common practice even when starting a project as partly open source). A clean break between different maintainers (particularly when a mostly single person effort) is a good reason to change the name too. Naming things is hard and it doesn't necessarily need to be all that different a name just something to reflect the change. reply kiba 4 hours agorootparentIt is not a requirement that open source software must be freely redistributable, just that you have the freedom to exercise free redistribution. reply cuu508 15 hours agorootparentprev> at least be up front about it in the beginning Treat CLA as that: an upfront statement that the author may and probably will change the license in the future. reply pcthrowaway 26 minutes agorootparentI think we should still draw a distinction between what the article author did and what a company like Hashicorp did. Hashicorp prominently displayed that they were committed to open source and that all of their projects would be open source forever. They had a CLA, but there are 2 good reasons to do this besides removing the OSS license: * You may want to be able to also offer the software under an alternate license, which some companies do due to the demands of a corporate client (e.g. one offered with a support agreement) * You may want the ability to relicense under a different OSS license. As long as the article author didn't make any promises about continued commitment to OSS, I don't see anything deceptive here (because without such a statement, a CLA usually means you want to relicense in the future) Hashicorp on the other hand pulled a jerk move by misleading the community as it formed, and which also contributed a lot to both Terraform and the corpus of terraform providers, etc. reply aseipp 12 hours agorootparentprev> All I'm asking is, if you want to eventually make money on your project, at least be up front about it in the beginning so that your users can make an informed decision when they decide whether to bake it into their stack. That isn't how it works in practice, I think. If you have already decided from the start to make money on your FOSS project, you're going to need a plan more evolved and refined than \"push to GitHub and sort out the details later\", otherwise you've already failed. Many people will even decide to just not do open source, for that reason. If you're not planning on making money, that might change later when you realize that the only value you get from million-dollar corporations making heaps of money off your work is some bug reports and requests to do more in your off time. Alternatively, you might decide you enjoy the work and want to make a living off it. Neither of these are bad, per se. Also, nobody signs a contract stating they're going to work for free forever, so you're going to have to live with that. The reality is that most of the people who derive great value from open source and free software just want it for free; the labor and economics can and must be sorted out by someone else, preferably at absolute zero cost to them. For many purposes, it's no different of a relationship than the one between a random underpaid restaurant server and random demanding customer. When you say \"users can [then] make an informed decision [on your monetized project]\", I assume the informed decision you're referring to is \"I'll never pay money,\" because that's what it is about 99% of the time. reply alex_lav 14 hours agorootparentprevThis is toxic though. People shouldn’t have to be able to predict the future should they? And if the opportunity to escape being a wage slave presents itself by simply changing an approach, should a person not take it just because potentially years prior they didn’t intend to? A person changed their mind. That is okay. reply logtempo 16 hours agoparentprevwould've been fun to see if putting the 15min restriction with a hidden option in the code or similar to remove it would've lead to the same result. I'm sure many people would've paid because the free version was not advertised. reply theturtletalks 16 hours agorootparentIsn't this what WinRAR did back in the days? It would be a 7 day trial and then asked you to pay, but the trial never expired. reply accrual 15 hours agorootparentI switched to 7-Zip and never looked back, but some cool kids did buy a WinRAR license (e.g. LGR on YouTube). reply xp84 14 hours agorootparentI used a keygen when I was a cool kid, but as a cool adult I finally bought a license (at roughly age 35) reply strictnein 13 hours agorootparentSame. Bought a key 5-10 years ago just as a \"thank you\" for all the pirating of it that I did. reply qup 12 hours agorootparentHow many times can you pirate software that you only have to buy once? reply theturtletalks 12 hours agorootparentMaybe he started fresh with Windows Vista/7 and needed to pirate it again. Or he had a laptop and desktop so pirated for both. reply ThePhysicist 21 hours agoprevGood for him! That's my experience with open-source software as well, if something is free, companies will almost never pay for it even if they get a ton of value out of it. On the other hand, if it's only a small amount e.g. 1,000 USD per year most companies let developers purchase that without much paperwork, so for these kind of tools such pricing is a sweetspot. If you go into enterprise sales territory things become way more complex and your sales cycles longer. For a solo founder that doesn't need to hyperscale this pricing scheme seems perfect. reply alex_suzuki 18 hours agoparentAgree. Developers seriously underestimate the amount of paperwork and organizational gymnastics larger companies require to buy literally anything. They won't be not buying your product because it's too expensive, but because it's just too much of a hassle. At that point, price is less of a factor than some people think. reply dzikimarian 16 hours agorootparentAlso if it's $1000/year (or even better per version) flat and really useful it's actually kinda easy to get green light. If it's $5/user/month, with 3 plans, with add-ons and it's unclear how many people you have to on board (just devs? Maybe business too? Does security team need access?) it's much harder discussion as nobody knows final cost (apart from the fact that we're not gonna like it in the long run). reply HeyLaughingBoy 15 hours agorootparentOne of the best versions I saw of this was for an IoT server product. Free for 10 devices or less. Flat fee of $1,000/month for 11+ They made it very clear that they only really cared about enterprise customers. reply haolez 17 hours agorootparentprevDoes marketplaces like the one at AWS help with that? I can pay with my AWS billing account. Sounds like another type of sweet spot. reply Valien 15 hours agorootparentIt can help for sure. Especially if a company has an EDP or PPA with Amazon. The process to become an ISV on AWS takes a bit of work though. reply StackRanker3000 14 hours agorootparentSorry, could you/someone please help with these acronyms? reply throwaway11460 13 hours agorootparentIndependent software vendor reply StackRanker3000 13 hours agorootparentThanks! After a quick search, EDP seems to stand for Enterprise Discount Program, and PPA means Private Pricing Addendum. reply playingalong 16 hours agorootparentprevIn principle that should work great. In practice I don't think it's working. Not sure why. reply playingalong 16 hours agorootparentprevIn principle that should work great. In practice I don't think it's working. Not sure why. reply eschneider 17 hours agorootparentprevThis is a big reason why enterprise software pricing is the way it is. reply rossy 20 hours agoprev> In any case, it changed years later when a startup using Nodemailer was acquired for half a billion dollars. I was financially not in a good place back then, and when I saw the news, I started to wonder – what did I get out of this? This is really what you should expect when you work to improve the commons in the same world where there are entities that are hyper-optimized to make the most short-term profit out of anything they can exploit. Of course they're not going to give anything back. It could happen to any FOSS dev. It sucks, and it's definitely human to look at all the money they're making and feel like you deserve some of it. You do deserve it! Everyone deserves to make a living. But the world is still a better place with FOSS in it. It's a shame for this to happen to someone and for them to decide that improving the commons was a mistake and instead they should have been making projects that FOSS orgs can't use and individuals and small orgs are priced out of (but is still \"peanuts\" for big businesses.) If you make best-in-class software that's FOSS, everyone benefits, and you can feel proud that individuals have access to the same resources as big corps because of what you've done. I'm also tentatively in favour of the idea of scaring away big corps with GPLv3 or AGPL licensed software. reply ZaoLahma 19 hours agoparentThis is just the thing - there needs to be a very clear reason for you to partake in FOSS, something that you want to gain from it that has a bigger value to you than the cost of allowing your time and effort to be used by others for free, and money can not be it. reply mnau 17 hours agorootparentExactly, before you go to open source, take a hard look at * why I am doing that * plethora of burned-out maintainers and their posts * how I am going to deal with the issues/PRs, toxic entitlement * what's my exit strategy The first thing before you go into open source (provided it's actually used open source) is to answer these questions honestly for yourself. Because it's massive time sink with no money and *there will never be money* (unless you go open core or your employer pays you, in that case that's just a job just like any other). reply xiphias2 16 hours agorootparentOne important thing the author got from working on open source is free feedback (issues). I don't view people taking the time to open issues as entitled people, but people offering their free time providing invaluable feedback. Those issues are quite often different from what I expect, and they represent of how people are using the software. The only mistake the author did was waiting too much monetizing, not doing open source software in the first place. reply pcthrowaway 24 minutes agorootparentPlenty of projects are source-available, but not open source, and get tons of issues, and even contributions (https://github.com/MetaMask/metamask-extension off the top of my head) reply andris9 15 hours agorootparentprevTBH, I get way better feedback from paying users than previously from free users. Free users like to tinker and think in terms of \"what if,\" so they bring up all kinds of features the software should also have because it can or it would be cool. The paying users only need actual features that help their business case, and they do not care at all about these \"what if\" features. reply xiphias2 15 hours agorootparentI see, do you think just _starting_ with payed product would have been better? (Or starting with a product + open source tools for marketing?) BTW good luck to scaling up to $60k / month, it will be fun reply andris9 14 hours agorootparentI did not plan to make the project paid at first, I would have prefered the OS / Open Core model, but it did not work out. So what I meant about the feedback was that the feedback for a free product might not help much for a paid product and vice versa. Different target groups, different priorities. On the other hand, more users, no matter if free or paid, help to detect edge case bugs better as there is a higher chance of someone stumbling on it and reporting it. In this case the first larger wave of free users did help me, yes. reply goodpoint 12 hours agoparentprev> I'm also tentatively in favour of the idea of scaring away big corps with GPLv3 or AGPL licensed software. GPL scares freeloaders. reply evgpbfhnr 22 hours agoprevFor anyone else wondering about the license, it's standard signing with an ec (sect239k1) key https://github.com/postalsys/emailengine/blob/master/lib/too... So the author can just write whatever validity date/license details (apparently hostname etc), sign it and give that to their customers. reply daemin 22 hours agoparentCould you elaborate on this, not necessarily the code itself, but about signing and \"an ec\". I'm new to this and will be wanting to provide licences for software in the future. reply scosman 21 hours agorootparentEcliptic curve signing. You can produce a message body like “valid_until=2025-02-25” then sign it and distribute it as an api key that’s body+sig. Client can verify signature using public key without a server call (sig validation). EC beats other signatures because signature is muuuuuch shorter, so it can still look like an API key. reply evgpbfhnr 21 hours agorootparentprev\"an ec key\" (elliptic curve) is just a detail, this can be done with any crypto library or utility - for example directly with the openssl command: https://stackoverflow.com/questions/15686821/generate-ec-key... embed the public part in your application and you can verify that something signed with the 'dgst' command and the private key really has been signed with the private key (which you obviously shouldn't publish) (Note if using plain commands there is more friendly than openssl, minify/signify are much harder to get wrong, but I'm not sure they're as easy to use programmatically in as many languages there are for libcrypto/sodium/etc; this is really just an example) reply semireg 19 hours agorootparentprevI use jwt for my app’s licensing. It works great. reply victor106 19 hours agorootparentAny resources you can provide that will help in understanding how this works? reply piyh 9 hours agorootparenthttps://jwt.io/ reply psnehanshu 14 hours agoparentprevSo all I have to do is generate my own private-public key pair, replace the hardcoded public key in the code you linked, then generate a license key with my private key. But yeah, I don't know what should be the payload of the signature. reply throwaway11460 13 hours agorootparentAdd \"face the angry company lawyers\" to the todo list reply evrimoztamur 21 hours agoparentprevCan't a user generate a fake license? Is there another layer of integrity checking, or can users simply patch in a fake checkLicense (which is apparently referred back to in four other spots in the code). reply notpushkin 21 hours agorootparentWell, you sure can patch it if you want :^) I think there isn't really a reason to add more than a simple license check though, as enterprise users are generally scared of using pirated software. reply slashdev 21 hours agorootparentAlso keep in mind pirated software doesn't cost the author anything if the user wasn't going to buy it anyway. If a company is willing to risk all that effort and liability to crack and maintaining the patches across changes to avoid paying for your software, they were not likely to pay for it in the first place. Nothing lost. reply alex_suzuki 18 hours agorootparentThis. Any licensing schema that protects locally running software can be circumvented by a reasonably crafty individual – but there is simply no overlap in the Venn diagram of Paying Customers /\\ These Crafty Individuals. reply klabb3 17 hours agorootparentYeah, or more specifically a company might have the competence but will not waste their engineers time, because the reason they’re using the service in the first place is to not have to focus on their core business. Not random accessories. A lot of time, circumventing a license check would be more work than - say - implementing sending email on their own. Depending on what the service is. Developers think they’re selling fancy tech. Most often, what we’re selling/providing is convenience - something boring that just works. reply e12e 10 hours agorootparentprevIt would probably be even easier to patch the license check function. That's presumably against the software license, so due to copyright you would no longer be legally entitled to run the software. reply GMoromisato 14 hours agoprevThe following is controversial and ill-thought-out, so feel free to flame (I gotta learn somehow!) Nobody does things for free. We do things because we gain either money or status or pleasure. If you want someone to work for you, and you don't want to pay them money, you have to give them either status or pleasure. One example of getting people to do things for pleasure is ad-supported social media sites. They are giving people pleasure (modulo engagement psychology) and getting their attention on ads for free. But let's focus on getting people to do things for status. PhDs are a classic example: if you get a PhD and stay in Academia, your salary is tiny relative to industry. But there is a promise of status (\"you're on the frontier of knowledge!\"; \"people call you 'doctor'!\"). The few principal investigators that get the giant grants are successful only because they rely on an army of underpaid experts. Which means there is an incentive--even if unconscious--to convince people that status is worth the lower salaries. The fights for being first-author, or publishing in a top-tier journal, or even insisting on being called \"Doctor\" are all competitions for status, because that's what you're getting paid instead of money. Open Source is the same way. Arguments about purity (\"is that really an OSS license\") and self-sacrifice (\"I won't accept money from corporations\") are all evidence that people are earning status instead of money. By itself, this is not a bad thing (in either OSS or Academia). People should be free to choose how to sell their time. The problem is that those who benefit from the work-for-status arrangement (large corporations, large universities, and their leaders) are incented to use dark patterns to preserve that arrangement. We're sensitive to social media sites using dark patterns to manipulate people into trading work (or money) for pleasure. We should be equally sensitive to how open-source culture can (even unintentionally) drive people to be underpaid. reply aatd86 5 hours agoparentYes, everything someone does is motivated. That's actually what gets people to do anything, physiologically as well. That's why someone who is not motivated won't do anything, disciplined or not. Lately people have been discipline at the forefront but motivation comes first and needs to be sustained. Just an aparté. You're not wrong. reply rglover 10 hours agoparentprevNeither controversial nor ill-thought out—you're just correct. Bookmarked this comment to reference later. reply hyperthesis 21 hours agoprevNext, I started to increase the pricing; 250€ became 495€, then 695€ and 795€, and finally 895€. To my surprise, it did not mean getting fewer customers. I guess any sub-$1k amount for businesses is peanuts, so the only thing these price increases changed was improving the revenue. Open sourcers identify with users, but businesses getting a ROI are unlike consumers. reply nusl 2 hours agoprevWhat stood out to me was this line for the company (based on the author’s tool?) that sold for ~500M USD. “I searched my mailbox for emails related to that company and found a single complaint about a feature. No pull requests, no donations, no nothing.” I find it quite pathetic that a company whose entire life depended on the work of the author but the only thing they ever contributed was a complaint. Surely something that meant this much to them was worth either compensation or contribution of more productive kinds. reply mogoh 21 hours agoprev> How I turned my open-source project into a business > I also changed the license from LGPL to a commercial license. OK ... reply StevenXC 20 hours agoparentThey didn't make a business using an open source project; they turned their open source project into a monetized non open source project. reply zepolen 16 hours agorootparentThat's not how that works: > Derivatives works (including modifications or anything statically linked to the library) can only be redistributed under LGPL reply jowea 15 hours agorootparentLGPL does not bind the author(s) of the software in this way. And since there was a CLA the other authors authorized the main dev to change the license. reply josebama 13 hours agorootparentThank you! This is the piece of information I was missing. I kept wondering as I read the article whether that was a LGPL license breach. Thanks for clarifying reply throwaway11460 13 hours agorootparentAs the owner of the intellectual property you're the one licensing to others. License is a kind of contract. You're not under any license yourself, it's yours. If you accepted PRs without a contributor agreement transferring the ownership, you might be infringing on their IP (licensed to you and others). reply jacooper 15 hours agorootparentprevDid you read the article? He forced a CLA on every commit reply sh79 13 hours agoprevThe title is misleading. The author changed their open source project into a commercial product with source available. It's not a business built around an open source project as the title implies, it's a license switch. reply carlossouza 21 hours agoprev> The only regret I have is that I did not start selling my software earlier and only published free, open-source software. Well… better late than never. Congrats! reply aglione 20 hours agoprevHey, I follow your project since I think 12 - 13 years and it has always inspired me to build something on it. At the end I didn't, but I'm really happy you found a way to live with it. Congratz! reply andris9 19 hours agoparentThanks! reply htsh 20 hours agoprevAs a longtime user of nodemailer, thank you. I am gonna check out emailengine for future work. reply xrd 20 hours agoprevI was curious about the automated CLA process. It is interesting to me to read the answer about not supporting GitLab: https://github.com/cla-assistant/cla-assistant/issues/534 Very terse answer that says: As you noticed, this would mean a completely different line of code I believe the author is not a native speaker, and means to say that this would require different code for each platform. Sure, that must be true, but the GitLab and GitHub APIs are not that dissimilar. I felt like this was a very strange response to a legitimate question and it makes me feel like there must be something more there. reply throwaway240227 13 hours agoparentA \"Code Line\" is SAP speak for \"branch\" or \"port\" in other software projects. (CLA Assistent is an SAP project.) See e.g. usage here https://community.sap.com/t5/technology-blogs-by-sap/one-cod... reply fastasucan 20 hours agoparentprevSure, that must be true, but the GitLab and GitHub APIs are not that dissimilar. Which they address in the later part of their answer which you leave out: Surely most parts of the project could be reused, but this development would still mean a huge investment, which we can't afford. Nevertheless all kinds of contribution are still welcome and we would try to provide our support as good as we can. reply xrd 19 hours agorootparentAs you point out, I am assuming malicious intent and you have every right to assume the same of me! I should have put that other part in. It just didn't jibe with me and still feels like it is an easy and obvious upgrade. But, you are right, they did justify it, it seems like an overstatement to say it would be a huge investment. I should review the code myself to verify, but a statement like that the lazy programmer in me shy away from even doing that. reply hmillison 16 hours agorootparentI'd guess \"huge investment\" in this case is relative. The maintainer is not spending a ton of time building features for the CLA tool since it's mostly \"done\" and so investing more time to build support for Gitlab would require many more hours of development than they're probably dedicating right now. And i can imagine that maybe they didn't abstract communication with Github enough and would need to refactor the system to handle that as well. Generally, i think it's not totally reasonable to expect them to do more free work to support use cases that the maintainer does not need. Since it's open source, we're all welcome to contribute back. reply auggierose 21 hours agoprevI like it, but I wonder: In a case like this, what is the point of offering a source-available license on GitHub at all? reply slashdev 21 hours agoparentIt can help your user's answer questions about the software, debug issues involving the software, have transparency into security, etc. reply MangoCoffee 16 hours agoparentprev>what is the point of offering a source-available license Long ago, I worked for a company that sold mortgage software. This is back when SOAP is all the rage. The software is not open source, but it is source-available, or rather, a law firm has the source code. My employer's customers are mostly banks or home builders that offer mortgage services. My employer is a very small one. Customers like banks want to know if you will stick around, if they buy into your software, and if you can't stick around. They need the source code. reply notpushkin 21 hours agoparentprevTransparency and maybe an occasional PR from your users. reply auggierose 20 hours agorootparentBut if they have the source code, they could just switch off the license key check, right? It seems to me he could just keep the license GPL then, wouldn't change a thing. The (small) businesses don't care about the license, but walk the path of least resistance. reply brap 20 hours agorootparent>But if they have the source code, they could just switch off the license key check, right? That's basically piracy. Unlike individuals who pirate stuff all the time, for businesses there's a much greater risk for lawsuit which is usually not worth it, even for many smaller businesses. For a 1-2 person business that's not making any money, maybe they can get away with it. But they probably don't make a great customer anyway. reply andris9 20 hours agorootparentprevThis was my initial business model and it did not really work. As soon as there was the license key requirement, previously free users opted to the paid subscription to get the license key and get the upgrades. In fact all the old and free releases are still available under AGPL license from Github. reply bachmeier 19 hours agorootparentI suspect the reason this model works is because it's easy to say \"We need X to do our work. It costs Y euros.\" and the company pays for it without thinking. It's probably a much tougher sell to say \"We need to pay for this even though we can get it for free.\" Even harder is \"We use this product so we should make a donation.\" It was never a matter of them wanting to avoid paying. I see this all the time in universities. Underfunded open source projects won't get a $100 donation from a university using thousands of copies, but a company like Matlab can get massive payments just because that's the only way to get it. You have to figure out how to make it easy to justify paying for your software. reply notpushkin 16 minutes agorootparentYeah, it's a bummer. I'm trying to run an open source product, too [1] and that's one of my major concerns with this model. One trick I want to try is, make everything open source but still paywall some features behind a license check. Easy to circumvent (and legal, too), but maybe businesses wouldn't be bothered with it, and for personal use – well, why not allow it – maybe some of them would convince their employers to use it as well :-) (And of course, providing it as a service is a much more straightforward business model, at least in my case.) [1]: https://lunni.dev/ reply Havoc 21 hours agoprevWhat sort of billing platform do people use for this sort of stuff? reply alex_suzuki 18 hours agoparentPaddle, Lemon Squeezy and Fastspring are popular choices for Merchants of Record. These are basically distributors that sell your software in their name and take on the liability of filing taxes correctly. Stripe for people who don't care about taxes or are large enough to have an accountant do it for them. reply Havoc 12 hours agorootparentThanks for the detailed response. Didn’t know the merchant of record thing exists. That’s neat reply jokethrowaway 11 hours agorootparentprevAccountants can charge a fair bit to handle N transactions so it may be cheaper to pay a MoR 5% instead of 3% for Stripe and pay your accountant extra. All the EU makers I know are using some sort of MoR. Stripe is still very popular in USA for makers who sell to USA, as sales taxes have tresholds; unless you sell a lot from an individual state, you don't have to worry about it. VATMOSS in Europe (the regulation which drove all the small sellers I know to drop their ecommerce websites and move to Amazon - talk about regulation to protect the people and damage Big Business!) doesn't have tresholds and you need a massive up to date VAT list + storing proof of user residing somewhere. reply andris9 20 hours agoparentprevI use a self-built web page (a simple Express.js app), that uses Stripe and Stripe’s customer portal for the subscription management. reply aatd86 5 hours agoprevTo be fair, as an adult, if I like something or need it, I don't mind paying at all. It is as a kid that I was a bit more... parcimonious? I think people need to be ok with being compensated. That's more cultural perhaps. reply mvkel 18 hours agoprevI like this story. Shipping OSS is a donation of one's time, money, and expertise. Volunteering is a rewarding way to participate in a community. Usually in any community, you meet someone who opens a door to an opportunity that you never would have found otherwise. reply RcouF1uZ4gsC 22 hours agoprev> I re-designed the UI of the app to look more professional and implemented a license key system. From that moment if you wanted to use EmailEngine (the new name for IMAP API), you needed a license key that was only available for paying subscribers. I also changed the license from LGPL to a commercial license. The source code is still published publicly on GitHub. It is no longer open-source by definition but source-available. This change of license was only possible due to requiring outside committers to sign a CLA from the start. This is the key portion. The open source project was turned into a commercial source available library with a license key. I am glad this has worked well for the developer who now has a decent income for all the hard work put into this library. reply graemep 21 hours agoparent> I am glad this has worked well for the developer who now has a decent income for all the hard work put into this library. it is also why people are reluctant to sign CLAs. reply KingMob 18 hours agorootparentIt's a sad irony that CLAs essentially put the project owner in the exact same position as the unicorn that screwed them over, by screwing over those downstream who make contributions, if/when they monetize the project. I came across some Scheme/Racket/? library recently that attempts to quantify contribution levels and distribute any received funds fairly based on that. Unfortunately, I can't find it at the moment, but it was a cool idea. reply andris9 18 hours agorootparentYou mean I screwed over those 0.1% of commits in EmailEngine (because the other 0.1% is from the Github Actions bot writing the changelog)? Everything else is my own code. For over 14 years, I've been actively developing Nodemailer, a hugely popular project. There has been no CLA in place, and the main outside commits I get are typo fixes during Hacktoberfest. This is why I'm still the owner of 98% of the committed code in Nodemailer. Usually, if I do not fix or build something, no one else will either. reply strken 11 hours agorootparentThe problem for the developer considering a CLA is that if you take any contributions at all, you now have a community of people who A) understand your source code and B) have had their contributions rolled into your proprietary product, possibly against their expectations and possibly leaving them rather upset. With 0.1% of commits it's not a likely problem, but if developers are making significant contributions then there's a good chance they'll fork your product as of the last LGPL commit and keep developing it as a direct competitor. It's safer to just not take contributions at all. reply graemep 13 hours agorootparentprevI would not say that in your case, but the problem is that if a project has a CLA there could be a lot of commits from other people and then it would be screwing them over. reply komali2 18 hours agorootparentprev> You mean I screwed over those 0.1% of commits in EmailEngine (because the other 0.1% is from the Github Actions bot writing the changelog)? I mean... yeah? Correct me if I'm wrong but you profited off their labor without compensating them, right? Why should the number of people you did that to make it less wrong? Obviously a corpo making bajillions of dollars without paying you sucks, but by sheer number of people negatively affected, it's still the same lol, in this case you're just the one with the bag, instead of a corporation. reply andris9 18 hours agorootparentWell, I guess you're right in a way. While there are no meaningful outside commits in EmailEngine, there are _some_ commits, even if these have minimal impact, by people who do not get paid for it, while I do. reply komali2 17 hours agorootparentI'm not judging you for this, btw. I find it extremely difficult to meaningfully measure in a dollar amount someone's contribution to a FOSS project, once monetized. The whole thing is messy. Honestly in general I find it quite difficult to measure labor value at all, which is why I guess basically every corporation on earth just lets \"the market\" decide, but that feels too arbitrary to me, and \"the market\" doesn't seem real when it gets to arbitrarily pay someone differently based on whether their passport says \"India\" or \"USA.\" I've been experimenting with just throwing my hands up and doing flat profit share, but we haven't really had an opportunity to really try this at scale (for a bunch of boring reasons), but I'm curious how it'll look. I don't think we'll have the crazy huge ratios you do on your FOSS though so I can see why that wouldn't be feasible for someone in your position. reply soegaard 14 hours agorootparentprevhttps://www.youtube.com/watch?v=-xnppM6GG9Q reply quaintdev 22 hours agoparentprevSo what prevents someone from bypassing the license check and run the version of application locally? reply andris9 21 hours agorootparentMost EmailEngine's customers are small-ish SaaS providers (different kinds of niche CRMs, etc), and in their position, it is not really an option to spend time / risk breaking copyright protections. Instead, they pay the subscription fee and get into building email integration features for their service. TBH, I wouldn't dare to use such a model in the B2C market, though. Everyone would pirate it. reply RyanHamilton 21 hours agorootparentFor niche applications, it's not that terrible. I've produced an SQL IDE for years with a license key that soldI am glad this has worked well for the developer who now has a decent income for all the hard work put into this library. Isn't this a rug-pull? Open source project which others havecontributed to, and whose reputation was earned by nature of being open source. Than, after you have users, switch to proprietary. Sounds bad to me, but maybe I didn't fully understand? BTW, Apple used to have a thing with Darwin server where you could disable the license check legally, but only a hacker would do that. Companies still paid for the software. That sounds like a better solution, IMO - at least for those that are two small to pay but growing by the seat of their pants can still use and promote the software. reply MattJ100 16 hours agorootparentThe main reason CLAs exist is to facilitate this kind of \"rug pull\", so I think the lesson is to either accept that it will happen or never sign a CLA. reply 727564797069706 22 hours agoprevThis is great stuff, thank you for sharing and congratulations! Looking to do something similar in terms of offering better, paid alternatives to the existing solutions out there in a source-available fashion. Anyone here experiencing trouble with tools you'd terribly want someone to improve? reply ponector 21 hours agoparentWe are struggling with TestRail. Barely usable expensive crap. Enterprise business love such things. reply amoh14 10 hours agoprevWondering if the author ever contacted Nodemailer for sponsorship? reply andris9 6 hours agoparentThe entire Nodemailer team is just 1 person, that’s me, so there is no one else for me to contact to. reply nulld3v 9 hours agoparentprevNot sure how that would work considering they wrote Nodemailer. reply satvikpendem 21 hours agoprevInteresting, I actually was making a competitor to Email Engine but also open source, similar to Nylas, because I didn't like the latter's opaque pricing and I didn't like the former's self-hosting, I wanted it to be in the cloud. I even got a YC interview based on this idea for last summer's batch (rejected primarily for being a solo founder, they seem to like solo founders only if they had a previous exit), but ultimately I gave up on the project because I realized I didn't actually like the problem space, it seemed too boring for me after a while and I wanted to concentrate on building things I thought were interesting. reply gramakri2 21 hours agoprevWe still use andris9's mailtrain even though the project has long died. Thanks andris9 for so many of email related node.js projects! Invaluable. reply zakariassoul 17 hours agoprevLove the story. I am curious on how your initial customers reacted to you increasing the prices? reply andris9 17 hours agoparentI locked prices for existing customers. So someone who signed up 2 years ago is still paying 250€ per year, while customers signing up today will pay 895€ per year. reply mundanevoice 14 hours agoprevLife is too short to give stuff away for free. Monetize wherever possible. Almost everyone who gives away useful software for free burns out and stops doing it. reply andrewmcwatters 18 hours agoprevI’m convinced that the MIT license and other public domain-like licenses are the worst licenses to actually use if you’re not a FOSS ideologue. So, most people. It works against your own interests in just a subtle enough way that also works against the interests of those who use your software. At a bare minimum, you should probably at least use the GNU General Public License version 2. reply kijin 18 hours agoparentExactly. Everything I've released over the last several years is GPLv2 or higher. If you don't like that, don't worry, I won't tell you to fuck off or give you a lecture on free software. You just need to pay me. Business is business. :) reply andrewmcwatters 13 hours agorootparentYeah, I stopped using the MIT license moving forward some time ago. There’s no benefit whatsoever to the author, and there are perfectly permissible licenses that one can still use without allowing others to walk all over you. reply sgu999 19 hours agoprev> I even went so far that when a founder of a major transactional email service sent me an email regarding Nodemailer and offered to make a donation to promote my efforts, I rejected it. To all of you around here who do FOSS, please reconsider this kind of attitude. The ones offering can be employees, and they had to argue your case. Just a couple weeks ago I asked a maintainer of one our Rust dependencies to give us a quote for fixing an issue. I had beforehand negotiated the deal with the CTO, it could have been anywhere up to $5k for roughly one day of work. No license involved, just money against some of their time to improve their open source code. To my dismay, they refused and did it \"for free\" while giving us a link for a donation. Guess what? The donation never came. It doesn't make sense for the ones who think in ROI, even less for the CFO behind them. Now I'm too ashamed to even show up on the issue board so we're all at a loss. reply pm215 19 hours agoparentOne problem from the open source project side of things is that unless the project happens to be one where at least one regular contributor is a consultant who is already set up to do work-for-hire like that, it can be way too much hassle to deal with a single one-off $5K, let alone smaller amounts. There's a big chasm of \"this isn't worth it administratively\" before you get to \"there is enough money coming in from this kind of thing that somebody could make it their job\" (for instance for a developer who already has a full time job, doing work for money probably requires them to go through a lot of hassle clearing it with their employer). Some projects don't even have a setup where they could do anything useful with a donation. reply ensignavenger 18 hours agorootparentUnless one is setup as a nonprofit, in the US, there is very little difference between recieving 5000 from a donation link and recieving 5000 as a payment on an invoice. It is all taxed the same. Some projects might not be setup for either, but it sounded to me like the above poster was dealing with some one who was willing to accept it as a donation, and it would likely have been trivial to send an invoice for 5000. reply gryn 17 hours agorootparentNot all open source devs are from the USA and in a lot of place outside it say the EU it can be quite the hassle. If you do it wrong it can very well be more than 5k worth of effort to fix it. When the taxman comes out 2 years later with a fine saying you didn't do X or Y. reply mrighele 17 hours agorootparentIn those countries the taxman will come out anyway because it will say that it was not a donation and you are trying to avoid paying taxes. It would be better to speak with an accountant beforehand in either case reply gryn 17 hours agorootparentit not about avoiding paying them (you will anyway unless you're in very narrow class of orgs) its about being in the wrong legal structure and getting stuck in administrative hell because you don't fit in their tidy little classification boxes. reply planb 18 hours agorootparentprevI remember the first time I sold code to a company for low 4 figure amount. The hassle of registering for a VAT-Id (in Germany) and writing an invoice wasn‘t the problem. I was afraid that there were any liabilities or other „rules“ I simply didn‘t know about like „what if something breaks and they sue me, because I didn‘t include a specific line of legalese in the contract?“. reply mgbmtl 18 hours agorootparentThis may be terrible advice, but as a freelancer, getting sued by a company will cost them a minimum of $20k in legal fees just to get started. Unless you really messed up in bad faith, I would assume that most people will attempt to resolve things amicably. reply giovannibonetti 19 hours agorootparentprevFor those of us that are used to working as contractors that isn't an issue, as we already have accountants and are used to making invoices every month. But I understand it can be daunting if you don't have all of that in place, yet. reply MrDarcy 18 hours agorootparentAn accountant isn’t necessary for something like this, plans like Zoho books free or harvest take care of the same things an accountant would take care of. reply dboreham 18 hours agorootparentParent said \"accountant AND...\". You need the accountant to provide advice so you don't do illegal things or run afoul of tax authorities, not to generate an invoice. reply vladvasiliu 17 hours agorootparentThis. Aren't there subtleties, for example, when doing inter-state commerce (assuming the two parties are both US-based)? In the EU, VAT isn't charged the same way if you invoice an entity based in your country or one based outside of it. reply giancarlostoro 17 hours agorootparentprevYou can also run into the opposite problem, where they license a commercial version of a dependency, and instead of paying ten grand or whatever, they pay a senior (way over six figures) to re-implement the same functionality, which wont be maintained anywhere as well, and it takes them over a year to reach parity. Totally never happened anywhere I worked. It astounds me that companies would rather waste hundreds of thousands of dollars instead of just throwing a few thousand that will benefit them in the long haul. I genuinely believe more companies should adopt a policy of just letting devs work half a day on fridays on whatever they want, whether it be technical debt, or even open source projects the company depends on. Maybe that would be more feasible, but even then lots of places would still not understand the value. reply lobocinza 15 hours agorootparentIt's not companies but people. I experienced both ends of the spectrum in the same company. reply giancarlostoro 15 hours agorootparentIn my particular case it was one person vs a team of managers and directors who refused to \"waste\" thousands, but kept a senior engineer working on a foolish waste of time and resources, there were so many other things this engineer could have worked on instead. reply lobocinza 4 hours agorootparentIn my case I think I could've made my case better but I was tired and lazy. It was me against one director where it could pay a few hundred bucks to have all the features it wanted or have me implement a single must have feature on top of the community edition. It's difficult to judge because maybe the project had a hard budget so even if having me implement things resulted in a costlier and possibly worse result it made more sense due to not resulting in a new discretionary cost. But I think it was more due to cultural background where the person was used to not pay much for software. My experience working with CEO was the opposite, those kinds of costs were pre-approved. reply packetlost 19 hours agorootparentprevYeah, there is a lot of hassle in some cases, it's really quite unfortunate that the laws don't protect individuals that want to do side work. reply Propelloni 18 hours agorootparentThis must be a non-EU thing. Sometimes I'm amazed how much western democracies and esp. the EU have achieved in protecting the employee from their employer. It all seems so natural that I tend to forget how much the social democrats and worker unions struggled to get to this point. reply vladvasiliu 17 hours agorootparentI'm not sure I understand how your point relates to getting paid for side work as somebody who doesn't do that regularly. For example, here in France, there's no such thing as \"freelance\". As an individual, you can't just invoice somebody. You need to set up some form of \"enterprise\". Sure, there are some forms which are supposed to be easier to set up, but you still have to go out of your way and do it. You can't just declare the income on your tax return. And now that you've created a company, you need to file tax returns every year, even if you don't do anything. It's also not free, an actual accountant has to sign them off (this may not be the case for the smallest forms of companies). Sending your taxes to the fiscal administration is also not free (fun fact: VAT is levied on that fee). reply sgu999 17 hours agorootparentIANAL but that's not entirely true. As long as it's exceptional, it's legal to earn money without having a company in France. It's the \"revenu commerciaux non professionnels\" box on your tax form. As for being an \"auto entrepreneur\" (equivalent of a sole trader), you don't need an accountant at all and the paperwork is rather small. Definitely worth it as it means you have some recurring revenue already. reply vladvasiliu 17 hours agorootparentAccording to the taxman's website [0] you need to be a \"liberal enterprise\". Not sure what exactly that means, but I'd be surprised there's no form of bureaucracy involved. I think you need to have at least a \"micro enterprise\". > As for being an \"auto entrepreneur\" (equivalent of a sole trader), you don't need an accountant at all and the paperwork is rather small. Definitely worth it as it means you have some recurring revenue already. Good to know, especially since, IIRC, they've removed the special social security you had to have for that kind of company. [0] https://www.economie.gouv.fr/entreprises/impot-sur-revenu-bi... reply sgu999 16 hours agorootparent> According to the taxman's website [0] you need to be a \"liberal enterprise\". Not sure what exactly that means, but I'd be surprised there's no form of bureaucracy involved. I think you need to have at least a \"micro enterprise\". We are not referring to the same thing, I think. You're looking at the tax for corporates when I'm looking at individuals [0]. The key seems to be that it's has to be exceptional and not regular. I'd still double-check on a case by case basis with the tax bureau before going ahead, but I've found them to be helpful in the past. It does make sense for niches like these to exist, otherwise you'd end up having to setup a legal entity before being on the receiving end of a transaction as an individual. [0] https://www.impots.gouv.fr/sites/default/files/media/1_metie... reply permanent 18 hours agorootparentprevEU is very large. If I were to believe your posts, Germany has achieved good protection of employees from their employers. Simply not true in ... many non-Germany EU countries. reply sgu999 18 hours agorootparentprevYes I understand that but if you can accept donations, you can surely hack together a quote and state that the payment will go through your donation platform. In most country I believe you don't have anything to do at all bellow a certain threshold. It's just a matter of not offering to work for free to a corporation that really doesn't need your generosity. reply sdenton4 17 hours agorootparentAnd sometimes a side project doesn't want to be a side hustle; dealing with payments and tax implications is time not being spent on the core project. It's an individual choice as to whether the time cost of accepting payment is worth it. reply Propelloni 18 hours agorootparentprevFrom my point of view there are two misconceptions in your post. 1) you need to be set up to work-for-hire to write an invoice. 2) you need to get clearance from their employer for things outside work hours. ad 1) No, you don't need to. At least in Germany anybody who's legally competent can write invoices. If the invoices are secondary income, you will be taxed heavily (and declare it you must), but that's it. It has been some time since I last lived and worked in the USA, but I mean to recall that it was basically the same. Of course, invoiced money is your money now and you need to donate it to the FOSS project, which then needs some kind of treasury. But you said as much already. ad 2) No, you don't need to. Your employer is your employer, not your owner. Now I don't know about the USA today (see above) but in European countries what you do outside working hours is your private affair -- discounting a few, very specific fringe cases. If you play soccer, dabble in explosives, or code for money doesn't matter. And frankly, your typical employer in most cases does not care anyway. reply permanent 18 hours agorootparent1) That may be allowed in Germany. Definitely not in Poland and many other countries. 2) In my experience, not true. Most often an employee needs to get a pre-approval that often take too long. As a full time developer, there's difference between playing soccer and developing software. reply COM2323 18 hours agorootparentprevIn my country a lot of people in IT are contractors (not employees) and sometimes these contracts are wild (like not working on anything else during that time and stuff like that). reply jen20 17 hours agorootparentThat kind of clause doesn’t fly in either the UK or US, since it is disguised employment. The definition of a contractor is someone who sets their own rate and hours, and works under their own direction. reply yogorenapan 18 hours agorootparentprevCrypto (as bad as it is) is a good way to take money. You can easily send and receive large amounts without worrying about laws and taxes. Might be unethical or illegal but just don’t get caught reply jokethrowaway 10 hours agorootparentgetting money out or using them without KYC is not that easy reply Brajeshwar 18 hours agoparentprevI believe it has more to do with accounting discrepancies. Unless the company already has a set process for donating/payments to Open Source Projects, it is a whole process to get that type of payment set up, approved, and paid. Corporates need to answer the what, why, who was/were the payments for. For bigger companies, a non-standard category of $5,000 would be more of an irritation to deal with. reply amelius 18 hours agorootparentI believe it has more to do with the feeling of \"we are in charge of our code\", so they don't let anyone pay for any changes/fixes in the code and there can't be any entitlement to more bugfixes should anything break. Donations don't have that moral obligation. reply didgetmaster 17 hours agoparentprevIt's not just open source projects. I have a project that I am considering converting to open source but have not done that yet so it is still proprietary. It reached a point where it was ready for beta test so I created an open beta. It attracted a few customers and one wanted to buy a license. I thought a yearly license of $250 sounded fair and they agreed to pay it. But then I got to thinking about all the hassle to keep track of that and file taxes. It's just not worth it for just a few customers. I told them to continue using it for free until it can attract at least 100 customers. Then it might be worth the hassle. reply stronglikedan 18 hours agoparentprevYou tried to do it your way, and they did it their way. Nothing to be ashamed about. But maybe don't always expect things to be done your way, since you make yourself uncomfortable when it doesn't happen. reply Capricorn2481 17 hours agorootparentSounds like pure moral hair-splitting. If they didn't want money, cool. But if they were expecting money but needed it to be via a donation for some moral reason, then I'd wager they read too much \"itsfoss\" reply bbsz 13 hours agoparentprevI always wondered if an oss-bid-for-pr marketplace has a point. Even repo owners could be in the loop - either taking up the offer, leaving it for others and just resorting to accepting the PR or straight up refusing the change (equivalent of closing a PR). In a way it feels against \"the spirit\", but maybe it's exactly the same way of thinking you're pointing out. reply halostatue 15 hours agoparentprevSome of us simply do not want the hassle of being paid for our efforts. We aren't working as contractors, and the meta-effort is far too high for any benefit. This is one of the reasons I have never set up sponsorships on any of my GitHub accounts (my taxes are complicated enough). reply VeninVidiaVicii 18 hours agoparentprevMake a donation now, then open an issue. If it’s an ROI problem, the return is getting the issue resolved. reply sgu999 17 hours agorootparentI'm not deciding what the company can spend on, that's the point. That person isn't doing me a favour, they are doing a favour to a company. reply VeninVidiaVicii 16 hours agorootparentSounds like you aren't trying to get the new issue resolved. reply kijin 17 hours agoparentprevOnce upon a time, I ran an open source project that accepted both donations and paid subscriptions, with similar benefits offered for both (larger quotas on the hosted service). A small amount of donations trickled in from time to time, usually from individuals. But most companies, both corporations and sole proprietors, chose the paid subscription. Even at a higher cost. After a while, I scrapped the donation option entirely. I own a business, not a charity, after all. Lesson: Unless you're registered as a 501(c), or an organization with similar status in your jurisdiction, don't even think of accepting \"donations\" from anyone who retains an accountant. It just doesn't work that way, open source or not. reply komali2 18 hours agoprevI've always felt like FOSS as a philosophy has been tangled up in trying to participate effectively in capitalism, when that was never really the point, nor really very possible unless you're lucky, nor really worth it. The origin of FOSS as I understand it from reading books like \"Hackers\" is from people that were mad that access was being restricted to systems and code from people that really wanted to use these systems and code, and hack them, and learn from them. I recall that one of the things Stallman likes to brag about from that time is not related to FOSS at all, but instead successfully decrypting a bunch of passwords, emailing the decrypted passwords to people, and recommending they instead set the password to an empty string instead. It was about keeping access to the system Free as in Beer. I suppose some have argued that FOSS represents a Public Commons in the way that fields and wells and physical marketplaces used to, but none of those things survived capitalism, so I don't see why a technological commons should be expected to either. For me I've been thinking lately that perhaps those interested in FOSS should instead consider how we can use FOSS to detach ourselves from needing to participate in global capitalism at all. Is there FOSS technology we can use to liberate people from things they need to spend money on right now? An example could be the Global Village Construction Set: https://www.opensourceecology.org/gvcs/ a set of open source designs for things like hydraulic motors or microcombines or steam engines that you can build on your own, usually not for cheap, but for far, far cheaper than you could buy from John Deere. Here's another cool project, some guy has just been building things like solar panels and basic circuit boards on his property from very base components for years: https://simplifier.neocities.org/ Some other FOSS liberation examples: Combining a tool like Jellyfin with Sonarr, Radarr, and etc, can liberate people from their 5 different media subscriptions. Or at least they can still buy DVDs and put them on Jellyfin to have the convenience of streaming with the media library of their own choosing. Deploying Matrix or another FOSS communication tool can let organizations have enterprise-level communication software without paying HUGE seat-based license fees to corporations like Slack. In fact there's many ways to liberate yourself from paid SaaS in this list: https://github.com/awesome-selfhosted/awesome-selfhosted at my co-op we self-host and deploy all our services for this reason, it saves us a TON of money. I don't have many other examples to mind because this is something I'm actively still researching. Friends in Venezuela though especially tell me how FOSS technology can liberate in ways I wouldn't expect here with my 64gb RAM machine with the latest processor, that I can easily replace components on on a whim. Such as how they can keep all their broken down machines pieced together from junkyards running pretty ok on various linux distros, and how they can sell creative work using free tools like gimp (no, really) or darktable. Like as not they'll just pirate software, though, but apparently FOSS often runs better on shitty hardware. Anyway my long term plan is to find or build more and more things that let people just not spend money on things anymore. That could be by making it easier to not have to throw things away anymore, or building tools to replace proprietary ones, or, idk, other ways I haven't thought of. reply ergonaught 21 hours agoprev> In any case, it changed years later when a startup using Nodemailer was acquired for half a billion dollars. I was financially not in a good place back then, and when I saw the news, I started to wonder – what did I get out of this? This is the root of most things like the BSL. You create an open source project or product, and companies with billions in quarterly revenue build the core of their business on your software, and meanwhile won't contribute to your ongoing viability (nevermind actual success) even in amounts that are entirely trivial for them. Toss the cloud providers into it now and it's even uglier. reply kerkeslager 20 hours agoparentThis is why copyleft is necessary, and also why large companies have spread a lot of anti-GPL propaganda. In a larger sense, we desperately need a societal shift in perspective from naively viewing companies as benevolent by default, to viewing companies as they actually are by default: they'll literally kill people if it's profitable. reply sokoloff 19 hours agorootparent> This is why copyleft is necessary How would copyleft* have prevented this? AGPL might, but GPL (and therefore, copyleft) doesn't prevent the upthread outcome. * - GPL is the prototypical/original [as far as I know] widely-used example of a copyleft license and the startup using nodemailer could have done that just as well (and for free) if nodemailer was GPL-licensed. reply immibis 20 hours agorootparentprevAGPL/proprietary dual licensed is a solution to this. Clients get two choices: give back as much as they take, or fuck you pay me. The former makes everyone happy, and the latter stops the developer making themselves homeless. reply rmbyrro 19 hours agorootparentAuthor tried it and didn't work. He presumes small businesses don't care about the potential risks associated with LGPL, and those were the majority of his most promising market. reply sokoloff 19 hours agorootparentThe risk profile to a SaaS company from LGPL and AGPL licensed code are night and day. Even GPL is pretty low risk for a hosting company, but LGPL's risk is strictly lower. reply tormeh 19 hours agorootparentprevAnd those small businesses were right. All the Apache/MIT-licensed software baffles me when LGPL for libraries and AGPL for applications seem clearly superior for promoting collaboration. reply immibis 17 hours agorootparentBig businesses convinced software developers they have the world's best intentions at heart, or at least, they are harmless and never need to be opposed. reply KingMob 19 hours agorootparentprevThe LGPL, which the author tried, is not the AGPL, which might have been a larger roadblock to the freeriding unicorn. reply jonhohle 18 hours agorootparentAny company big enough to have a legal department will tell their devs to say away from LGPL, GPLv3, etc. If a dev is using that as promo for their commercial offering, it will probably just be ignored. reply sokoloff 17 hours agorootparentMy company is big enough to have a legal department. (I'm the tech counterpart/coordinator with legal for open-source topics, whether its us open-sourcing code we work on, contributing to existing open-source, or consuming open-source.) We license under Apachev2, and we readily use LGPL & GPL v2/v3 with a quick review, and have very specific and much more thorough review processes for AGPL. I'm quite sure that I don't work for the only such company. reply jokethrowaway 10 hours agorootparentprevIt's definitely a matter of target market. He made a small business and he's targeting small companies who are probably still running a cracked version of photoshop CS6. Big companies have rules about which OSS licences they can use and enforce them on their developers. Developers in general will just skip it and pick an alternative they can use without problems from legal and possibly without paying. So even with the license in place, I don't think it would ever magically attract big clients. I think the author needs something a bit more unique or way better sales to get larger businesses. They are all likely on Amazon SES or SendGrid. reply eleumik 20 hours agorootparentprevThis they told me at first lesson of economics at university, 1989 reply pydry 20 hours agorootparentprevNot just anti GPL but anti BSL/Elastic license too. reply rmbyrro 19 hours agorootparentprevThat's the nature of some humans. A corporation is not required to kill for profit. Doctors would kill for profit. Politicians would. The same for engineers, cookers. Any profession, activity or line of business really. That's human nature. But not all humans. Not even majority, I'd say certainly. The problem is that this small minority gets 99% of the news. Very rarely one hears when a CEO avoids a decision that could endanger someone. Or when a Doctor is honest and preserves the patient's health above all. It doesn't mean these good things aren't happening all the time. Look at your life and remember: how many people could have done harm to you for a profit? How many do you remember actually doing it? reply kerkeslager 12 hours agorootparent> A corporation is not required to kill for profit. Some corporations aren't in a situation where killing people is profitable. But every corporation will come across situations where harming people is profitable, and if they don't harm people in that situation, one of their competitors will. People like Yvonne Chounard who manage to avoid unethical practices AND create a profitable company are the exception, not the rule, and he was aware of that, which is why he went to great lengths creating an atypical corporate management structure to try to preserve the ethics of Patagonia in his absence. > Doctors would kill for profit. Politicians would. The same for engineers, cookers. Any profession, activity or line of business really. > That's human nature. But not all humans. Not even majority, I'd say certainly. You're fundamentally not understanding what I'm saying. It's not the doctors I'm worried about. Doctors have to look their patients in the eye usually. It's not the cooks I'm worried about, because they're generally poor, and don't have the means to avoid regulation. It's not the engineers I'm worried about, because they generally don't get paid more if their work kills people (with the exception of those in the manufacturing of weapons). In fact, it's often engineers that are the whistleblowers saying \"we told them what was wrong and they did it anyway\" when the decision is made to do something dangerous. And if you think the majority of politicians won't kill to keep power, please tell me what country you are in so I can move there. I can only think of a handful of elected politicians at the federal US level who aren't obvious de-facto murderers. The people I'm worried about the most are the C-level execs, board members, and majority shareholders: the kind of people who can put a numerical value on what it will cost to not kill people, and then justify it to themselves and never have to look their victims or their victims' families in the eye. reply komali2 18 hours agorootparentprev> A corporation is not required to kill for profit. Perhaps no, but a corporation has no compunctions about killing for profit. Let's take the direct approach, and list some that will take money and a target list, and make those people dead for you: https://en.wikipedia.org/wiki/List_of_private_military_contr... Here's a list of companies in the USA who will sell you the tools you need to kill people at scale: https://en.wikipedia.org/wiki/List_of_United_States_defense_... But I think that's not exactly what we're talking about, we're talking more about how the corporate entity under this current system shields organizations of people from the deaths their decisions cause. GM knowingly let people die due to a defect in their vehicles that they were aware of: https://www.washingtonpost.com/business/economy/why-did-gm-t... PG&E was found culpable for the pipeline rupture that killed 8 people and destroyed 38 homes in San Bruno in 2010, because they ignored inspection data. An article came out a few weeks ago about how immigrant child laborers are being killed in shocking volumes in American factories https://www.theguardian.com/global-development/2024/feb/12/i... Here's a fun that goes through a bit of the history of corporations killing people directly (murdering trade unionists) and indirectly (tobacco companies suppressing research). https://jacobin.com/2020/01/corporations-profit-values-murde... There's something uniquely devilish about the corporation in our current legal and economic system. reply joelfried 18 hours agorootparentA corporation is a legal entity created on paper to allow people to do business more effectively. Corporations don't do anything, the people in them do. People working at GM didn't act to fix their vehicles and people died. People at PG&E chose not to perform actions based upon inspection data, and people died when their infrastructure failed. According to your Jacobin article, people at Coca Cola killed those trade unionists. How about let's not let the legal wrapper for people protect those who murder others? reply digging 18 hours agorootparent\"Prosecuting individual actors\" and \"treating corporations as hostile entities\" are not mutually exclusive; indeed I'd say we should all strive to do both. reply camgunz 17 hours agorootparentprevA major point of establishing a corporation is the liability shield it grants. Sometimes it doesn't work (google piercing the corporate veil) but, the whole idea is to grant indemnity to people within a corporation for the corporation's actions. reply kerkeslager 12 hours agorootparentprevI agree, people within corporations need to be held responsible for their actions. But a big part of why that isn't happening is that when people kill people from behind the shield of a corporation, we can't even get people to agree that anything should be done about it, because \"they were just following incentives\". And any attempt to change the incentives is met with \"but how can they do business if they're expected to comply with these onerous regulations\" or \"but that's socialism!\". Instead, we're just supposed to trust that if it made money for a corporation it must have been good, because the invisible hand of the market would never allow it to be otherwise. Until we break the idea that corporations are good by default, it's going to be hard to persuade people that going after people within a corporation for their wrongdoing is a good idea. reply samatman 9 hours agorootparentprevThis is exactly like saying \"a country has no compunctions about genocide\". Which country are we talking about? reply komali2 4 hours agorootparentPerhaps you're right! Many countries engage in genocide and war crimes. I think that that should also be punished. reply graemep 21 hours agoparentprevI get that, but the author did not try something like the BSL, just went to a fairly typical proprietary license. Even the right open source license, such as the AGPL, would probably have worked well, with the proprietary license as an option (in the same way he tried LGPL + MIT). reply kijin 18 hours agorootparentWell, one of OP's initial mistakes was that he thought LGPL was anywhere near \"copyleft.\" It isn't. For SaaS companies who just want to use the software on their backend and are not interested in redistributing it in any way, there's no realistic difference between LGPL and more permissive licenses like MIT and BSD. reply graemep 12 hours agorootparentIt looks like I was wrong. From the code he did use the AGPL. I am confused as to why the article says LGPL. Typo? Tried both? reply andris9 10 hours agorootparentIt was a typo/mixup. Correct is AGPL, not LGPL as in the article. reply leedrake5 19 hours agoparentprevNot billions, but I was in a similar position. What saved me was the GPL license on the open source code and hiring a lawyer that kept my ownership of any software I wrote (though at a reduced hourly for them) and patenting new ideas connected to the project. When it came time for the company to scale up, I couldn’t have been in a better position. reply raffraffraff 19 hours agoparentprevMore galling than the company getting acquired for half a billion dollars is the fact that they never even said \"thanks\"... > I searched my mailbox for emails related to that company and found a single complaint about a feature. No pull requests, no donations, no nothing. reply corentin88 20 hours agoparentprevWhich startup/company was bought that price? reply le-mark 21 hours agoparentprevI’ve been sitting on some code for about 15 years because it’s the key to disrupting a couple of entrenched players and would enable cloud vendors to offer the functionality “as a service”. No way I want Amazon/google/MS to run away with it. Edit down voters might ask themselves what is much older than 15 years that some companies pay a lot of money for? reply hn_throwaway_99 20 hours agorootparent> I’ve been sitting on some code for about 15 years because it’s the key to disrupting a couple of entrenched players I have a difficult time believing that any piece of code that can be \"sat on for 15 years\" would disrupt anything. 15 years, especially in tech, feels like a couple generations these days. reply goodpoint 11 hours agorootparentlol, no. reply abenga 20 hours agorootparentprevYou're not running away with it either. You should just release it as a proprietary tool or SaaS if you think it will be useful for people. reply wcedmisten 21 hours agorootparentprevWhy not release it as AGPL? reply solumunus 19 hours agorootparentprevPics or it didn’t happen. reply j1elo 21 hours agoprev [–] Well, Open source is NOT a business model (and your business will fail if you think that it is) https://anonymoushash.vmbrasseur.com/2018/08/24/open-source-... Previous HN discussion: https://news.ycombinator.com/item?id=26602316 reply jraph 20 hours agoparent [–] What should we take away from your comment? Sure, open source is not a business model, it defines a set of software programs that respect some rules: the OSD [1]. But you can certainly have a business model around open source software. [1] https://opensource.org/osd reply Veuxdo 18 hours agorootparent [–] Consider the OP's headline. They didn't even describe what their project was. All they said, all they think they needed to say, was that it is Open Source. And on HN, it's actually true. Open Source projects get lots of kudos here. The problem is, others may see what is essentially a marketing strategy aimed at a niche audience and conclude that Open Source is an essential, in fact they most essential, part of the business. Hence the need to remind people that Open Source is not a business model. reply jraph 14 hours agorootparent [–] I consider at some point running my own open source business. It must be around an idea that will speak to me at the time if it ever happens, but the open source part is important to me for ethical reasons. I'm not interested in running a software business if it's not open source. And so I'm interested in reading others about their business experiences around open source. What is their actual project is important since it has consequences on how the business will be run, but the exact project won't matter too much to me as a reader and it does not really matter to me if it doesn't appear in the title, I will click. Now the headline is a bit disappointing since the article is really \"How I didn't keep doing open source when I turned my project into a business\". reply Veuxdo 11 hours agorootparent [–] There's two valid, and opposing forces at play here: - Motivation is a precious resource. If you are more motivated to work in an Open Source software business, then this will prevent burnout. - You have to ask if you're playing to play, or playing to win [0]. If you're playing a game with self-imposed rules that exist only in your head, you put yourself at a huge disadvantage. [0] https://commoncog.com/playing-to-play-playing-to-win/ reply jraph 3 hours agorootparent [–] That's an interesting perspective, thanks for sharing. If I have to use this frame, the game I play is \"Be happy\" fundamentally. A way to do this is \"Spend time doing things that makes me happy\". I'm happy if I agree with what I do (not sufficient, but necessary). Let's assume one needs money to live (another game, this one imposed by society). A way to earn money is work. Work could be purely seen as a way to support one's free time. But work usually takes a lot of time so I'd better have one that makes me happy. I currently work in an open source company so doing non open source would be a downgrade. Now, nothing would prevent me to softly transition, with part time for instance. I can try making \"trying to start a business\" not too risky. So, play to play or play to win? I think I play to win, the question is which game I play? Running a business will certainly not be the game I play. That would be a means, not an end. A means to spend happy time while also playing the game imposed by society. Now, running my business will need to be more fulfilling than my current position, and the bar is very high. I don't get to work on exactly what I decided and schedule, while very flexible, is imposed, but everything else is great (including nice people to work with, interesting and useful stuff to do, open source, many days off, ...). You nailed it with your remark about motivation and burn out. I can work on non open source code (for instance for internal stuff), but I'd not be happy with proprietary software targeting end users (against my values) and I'm more happy if my time is spent doing open source. Something causing burn out is in fact a move one can't play. Now, open source, if not the easiest path, has its business advantages too. More and more (public) places requires, or favor it. If you happen to target these places, you may be advantaged against your non open source competitors. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author transitioned their open-source project, Nodemailer, into a business named EmailEngine to address financial challenges, implementing a subscription-based model to commercialize the software successfully.",
      "Initially hesitant, the author discovered selling software to be more sustainable than relying on donations, leading to a stable revenue stream.",
      "Regretting not starting the software sales earlier, the author now enjoys consistent financial success with their business venture."
    ],
    "commentSummary": [
      "The discussion delves into transitioning open-source projects to commercial models, addressing challenges in pricing, licensing, maintaining transparency, and handling contributions.",
      "It explores the moral implications of receiving payments for open-source work, the potential for FOSS technology to detach from global capitalism, and ethical decision-making in business.",
      "Issues concerning proprietary licenses, motivation, avoiding burnout, and finding work fulfillment are also part of the debate."
    ],
    "points": 584,
    "commentCount": 220,
    "retryCount": 0,
    "time": 1709028978
  },
  {
    "id": 39530487,
    "title": "U.S. probes UnitedHealth antitrust practices",
    "originLink": "https://www.wsj.com/health/healthcare/u-s-launches-antitrust-investigation-of-healthcare-giant-unitedhealth-ff5a00d2",
    "originBody": "wsj.com#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}Please enable JS and disable any ad blockervar dd={'rt':'c','cid':'AHrlqAAAAAMAwPrM3XkvNqsAFKwGpg==','hsh':'D428D51E28968797BC27FB9153435D','t':'bv','s':47192,'e':'3ace5511a00bf600ef084cd43b8d7bc04a2fc2937dd9a2c2e280ec22ddc04f68','host':'geo.captcha-delivery.com'}",
    "commentLink": "https://news.ycombinator.com/item?id=39530487",
    "commentBody": "U.S. opens UnitedHealth antitrust probe (wsj.com)457 points by moose_man 12 hours agohidepastfavorite166 comments moose_man 12 hours agohttps://archive.ph/meOGZ throwway120385 11 hours agoprevGiven the way United Healthcare is organized, with Optum as a second party that all claims or other billing issues is directed to, this allows them to very effectively point the finger at each other whenever there is a dispute. Optum in turn owns a lot of care providers including a ton of providers in my area. They have used this as a cudgel in the past, as someone I know was slammed with a bill during Optum's takeover of one of their providers. The Optum employee wouldn't provide any information about the charge and simply fired them as a patient for not paying it. Because Optum is buying up clinics left and right where we live this person has lost access to their PCP on multiple occasions as Optum buys more and more healthcare groups. UHC and UnitedHealth group need to be broken up, and these incestuous relationships between insurance companies, private equity companies, and care providers need to be stopped by the SEC, because their only purpose is to exploit the wrapping up of care providers under one umbrella to extract more money for less work from people seeking essential services. reply kurthr 8 hours agoparentThey key point is that healthcare insurers, pharmacy benefit managers, pharmacies, and healthcare groups are all owned by one holding company which benefits when prices go up. People think that the insurer will try to keep costs down, but in fact, if prices go up they can charge more for insurance... the only way they can keep increasing shareholder value is for prices to go up. So they do, and by owning the entire chain they can force that to happen. There is no market. Insurers will not negotiate prices lower, it is against their interests! reply roenxi 7 hours agorootparentIt is interesting to draw a comparison with food. Practically speaking we can't go 24 hours without food, it is essential. Most people are totally dependent on others to provide their food; look at any city - the population density is too high for people to grow their own food. The food providers have no inherent incentive to make food cheap. It is totally against their interests. A shallow look at the situation suggests food providers should be able to squeeze people until all the money goes to farmers. But that isn't what happens, food is actually absurdly cheap and available given how important it is and how much needs to happen to produce it. The situation with insurers is similar. If there was a real market that people could enter, competitive pressure would force them to be cheap. If the market was, hypothetically, choked by regulation then they'd be in a great position to charge absurd prices. Market incentives are odd beasts. It is technically against the interests of the insurers to negotiate lower prices - unless they are competing with other insurers. Then it is in their interests to offer fair prices. (if it isn't clear, I think I'm agreeing with you) reply hx8 6 hours agorootparentI think there are a couple of pitfalls in looking at healthcare as a free market. * People often have to make uninformed decisions or have decisions made for them in an emergency. This naturally puts them at an economic disadvantage in the market place. We consider it unfair because it's the sick, injured that are disadvantaged. * We have strict regulations about ensuring access to health care. People aren't turned away in an emergency. Sick people aren't treated differently for insurance. There are thousands of other regulations we do that shape the 'free' market. * Food is far from a free market, although it might look that way from the consumer standpoint. The government helps in both ensuring a strong supply with farm bills and giving $114B/yr in SNAP on the consumption side. reply rapatel0 4 hours agorootparentI’ve never understood The concept of competition in insurance. Fundamentally it’s about pooling funds to average out risk. We had this nonsensical system where we socially subsidize the most expensive (Medicare) and privatize lower risk. It literally makes no sense. Alternatively is we simply pooled assets and introduced competition into care delivery, health maintenance, and care quality I expect that the system would be more efficient and effective. reply roenxi 6 hours agorootparentprev1. I suspect the vast majority of engagement (and, spending) with the medical industry is non-emergency care. At least not emergency care required in the next hour or so. There are edge cases, but even considering most of what I've seen going to the emergency room there has been time to choose which hospital to head for. Basically I think this is over-weighting the importance of emergency care. I don't have any stats on hand, but people entering the hospital system at ultra-short-notice is quite rare in my experience compared to having a bit of time to think. Most healthcare engagement seems to be for planned consultation, planned surgeries, emergencies but with hours to spare and then urgent emergencies. In about that order of frequency, and heavily weighted towards the first few cases. 2. People are more than capable of figuring out which of two options are cheaper. The ability of consumers to reject goods over tiny price differentials is legendary. 3. If people aren't up for the challenge of figuring out what to do in an emergency, then in a fair market you'd probably find the insurer starts to step in and assist. If the insurer has to compete for business, they have a very strong incentive to make sure their customers get good and cost-effective care. 4. And on food markets; those are distortions to the market, not limits on it's freedom. A free market can be distorted with subsidies and it is still free. The important factors are whether new providers can enter the market and whether they are allowed to compete on price and service quality. reply Guvante 5 hours agorootparentNo one knows how much care costs. Insurance companies and providers hide the real Costa when predicting in the guise of \"information security\" which makes choosing a facility on price literally impossible. Time isn't a factor, if you have insurance that covers it you rarely if ever know how much it will cost. reply nradov 4 hours agorootparentCMS requires hospitals and health plans to publish price transparency data and give consumers tools for price estimation. https://www.cms.gov/priorities/key-initiatives/hospital-pric... https://www.cms.gov/healthplan-price-transparency/consumers reply dalyons 3 hours agorootparentVast majority aren’t in compliance, and the data they do publish is essentially useless. Lots about it online, but a reasonable interview here https://www.wbur.org/onpoint/2024/02/13/the-fight-for-transp... reply rincebrain 5 hours agorootparentprevre 2) People will reject more expensive options if and only if they have the time and energy to reach the point where they know what the price differential is. Almost no medical practices in the US will tell you what the price is until after you've had the service there, and that price might even vary across multiple trips depending on how your insurance processed the claim _that_ time. (Ask me how I know.) So you would need to schedule appointments and have the entire medical procedure done multiple times to have any price visibility, and even then, there's lots of nonsense around things like doctors operating in hospitals but billing separately, which completely obfuscates the end cost to someone. People can and will choose the cheaper option, but I personally, as someone who has limited time, cannot afford to go through totalling all the bills for having the same procedure done twice every time, with all the months of back and forth for setting up being a new patient, scheduling things, being lied to about the doctor being available for the consult, showing up and having the staff gaslighting everyone about how it's not a problem on their end, everyone angrily waiting in the waiting room clearly got their appointments wrong, even if you have the reminders written by the staff at your pre-actually-seeing-the-doctor visit in hand showing their system is wrong... It's incredibly exhausting and involved to visit a new doctor for even the most trivial things. Most people cannot afford the time commitment to do that multiple times even if the procedure is something where it's not a one-off or urgent. reply roenxi 5 hours agorootparentYeah. It is a comment talking about treating healthcare as a free market. The US doesn't treat healthcare as a free market, so none of the predictions or observations in that comment apply to the US. The US seems to have some sort of racket going on in healthcare. What I've heard about their regulation makes sense if interpreted as a fairly basic system built by lobbyists to extract money from people, using emotional blackmail to break up political opposition. Otherwise it seems a bit silly. reply nradov 4 hours agorootparentprevMedical practices in the US are now required to give uninsured patients a good faith estimate on request. https://www.cms.gov/medical-bill-rights/help/guides/good-fai... Health plans are now required to give comparison shopping tools to their plan members. Those can be difficult to use for patients who don't understand the system, but it is at least a step in the right direction. https://www.cms.gov/healthplan-price-transparency/consumers reply nonethewiser 4 hours agorootparentprevYet prices would come down if insurance companies actually had to compete. reply ffgjgf1 1 hour agorootparentprev> If the market was, hypothetically, choked by regulation then they'd be in a great position to charge absurd prices. There are countries in Europe like the Netherlands and Switzerland where the healthcare systems are almost entirely private (much more so than in the US, since there are no Medicaid/Medicare equivalents). Yet their markets are chocked fully of regulation while being able to maintain low prices (compared to the US) and very good outcomes. reply mlsu 1 hour agorootparentprevI completely agree, but even further: health insurance is itself a silly thing. Insurance is for: - costly things - that happen rarely - in an unpredictable way These are characteristics of things that are well suited to insurance. Healthcare -- the type of routine healthcare that makes up the vast majority of spending -- exhibits literally none of these qualities. Most healthcare expenditure is: - not costly. An Advil is not costly. 30 mins of some stupid doctor's time is not inherently costly. An MRI is not costly. Medical office space is not costly. - totally predictable (eye exams, checkups, scheduled visits, hell even big operations like a heart transplant or C-section are rarely done \"in the moment.\" Usually you can see them coming. The hospital can definitely see them coming; they know exactly how long a gastric bypass or a c-section takes, how much equipment and staff they need, etc. - not rare; most people visit a doctor at least yearly. That's on par with buying xmas gifts! Only a small fraction of healthcare spending should happen through insurance -- insurance should be for things where you travel in an ambulance to the hospital and that's it. PCPs should compete individual to individual on quality of service, price, etc. Hospitals should compete hospital by hospital on quality of care, facilities, scheduling, bedside manner etc. Rx should be decoupled completely from insurance. Why do I choose Humalog over Novolog? Not for any medical reason! It's because I need to have insurance to buy one or the other. Why do I need insurance to buy a pill? Because I need insurance to see the doc. Why do I need insurance to see a doc? No good f%@#$ reason. Drop it. Insurance is for when I need surgery NOW for I have no idea what, and I cannot make any kind of choice about it. It should cost $100 a year for a healthy 20yo adult and $400 a year for a healthy 60yo adult. None of this shit makes sense to have insurance mandated. None of it. I should be able to walk into any doc's office without insurance and pay a flat cash fee, posted on a big bulletin board outside that says $20 per 15 mins. If I don't like it, I should be able to LEAVE and go across the street! reply ClumsyPilot 4 hours agorootparentprev> If there was a real market that people could enter, competitive pressure would force them to be cheap. If the market was, hypothetically, choked by regulation then they'd be in a great position to charge absurd prices. This is a fabrication - a free market with large capital investment requirement tends towards a monopoly. Economists call These places natural monopolies. We had them in oil and in railways before regulation. This doesn’t happen in food because anyone can grow a cucumber in their yard. But that’s not gonna cut it for surgeries. And on top of that you get charlatans, snake oil salesmen, homeopathy, treating people with magnets. reply roenxi 2 hours agorootparentLarge capital investment? What large capital investment? Most of my doctor appointments are done by eye. Surgery needs more than a knife, but not that much more than a knife. Even expensive machines in hospitals are probably not that expensive; they certainly aren't large. A lot of them would cost single digit millions; ie, be far too cheap to allow monopolies to form. I looked up MRI machines for reference and apparently they can be picked up for around a million dollars. We aren't talking about expensive kit here. reply 0xbadcafebee 8 hours agorootparentprevIf only there were some way to give everyone in a country necessary and preventive health care regardless of whether they could pay for it or not. Like imagine a developed nation with health care for everyone? Where even the poor can have necessary medical procedures, medicine, etc without having to be buried under medical debt? Lol what a pipe dream reply nradov 7 hours agorootparentAll health plans are now required to cover preventive health services at no cost to the patient. https://www.healthcare.gov/coverage/preventive-care-benefits... reply Guvante 5 hours agorootparentFew things: only one doctor visit is allowed and for some insurance companies asking about health problems voids that. Preventative is very narrowly defined to exclude anything considered a sickness in anyway. Getting something done that will ensure you don't get more sick might be considered preventative naively but is considered fixing a problem and so not covered. So basically this covers vaccines (make sure if you get multiple you don't see a doctor past the first or you are paying) tests unrelated to medical problems and a single non diagnostic visit to the doctor per year. reply xyzzy4747 7 hours agorootparentprevSo the solution is to create even a bigger monopoly? reply hn72774 7 hours agorootparentUS spends 50% more per capita on healthcare than the next highest developed country, Switzerland. And double the average comparable country. It's hard to see how regulated, single payor healthcare could be bigger or more expensive if the middle man is cut out. https://www.healthsystemtracker.org/chart-collection/health-... reply nradov 6 hours agorootparentSimply replacing private payers with a single payer system (\"Medicare for all\" or whatever) wouldn't do much to cut US healthcare spending. Payer profit margins are relatively low and in total only constitute a small fraction of total healthcare spending. Any real savings would have to come from severe price controls on providers, drugs, and medical devices. Plus some forms of rationing. I'm not necessarily opposed to that, but it would be difficult to build a political consensus for it. reply Guvante 5 hours agorootparentHalf of our excess spending is just administrative costs dealing with insurance... reply nradov 4 hours agorootparentAdministrative expenses on the payer side are 7.5% of total US healthcare spending. Even under a single payer system, that number would decrease only slightly. https://www.healthsystemtracker.org/chart-collection/u-s-spe... reply FireBeyond 6 hours agorootparentprev> Payer profit margins are relatively low and in total only constitute a small fraction of total healthcare spending. What? The government was forced to make insurers cap their profits at 20%. Except now that means if they want to make more money, they just raise premiums and negotiated provider payments. Even easier when you're as vertically integrated as UHC. reply nradov 4 hours agorootparentYou appear to have confused payer profit margins with the 80 – 85% minimum medical loss ratio imposed by the Affordable Care Act (Obamacare). Medical insurance is a low margin business and industry profits have never been anywhere near 20%. https://www.cms.gov/marketplace/private-health-insurance/med... For the past quarter, the UnitedHealthcare business unit of UnitedHealth Group had a profit margin of 6.6%. https://www.sec.gov/ixviewer/ix.html?doc=/Archives/edgar/dat... The business is still highly competitive, and payers have limited ability to raise premiums due to push back from employers. reply barbazoo 7 hours agorootparentprevIs that what happened in countries with universal healthcare? reply vkou 7 hours agorootparentprevOne without a profit motive, directly accountable via elections..? That sounds great, compared to the status quo. reply nojito 7 hours agorootparentprev> People think that the insurer will try to keep costs down, but in fact, if prices go up they can charge more for insurance This isn't really how they make money. Insurers make their profits by limiting the amount that they have to pay out. The reason why owning both the care provider and the insurer is wrong is that it makes denying or \"moving care\" to less costly locations easier. reply Uvix 7 hours agorootparentInsurers used to make their money that way. But now that US health care insurers are required to use at least 80% of premiums to pay health care costs, they've lost the incentive to keep prices low. Increasing their profit now requires paying out more in claims. reply nojito 5 hours agorootparentNot really true. United's long play is with medicare advantage. They plan to add an insane 450k new members by 2024. https://www.forbes.com/sites/brucejapsen/2023/11/28/unitedhe... https://www.healthcarefinancenews.com/news/unitedhealths-med... This is a great example why United was the sole insurer who was able to absorb the Medicare cuts while everyone else is shedding their MA exposure. reply nradov 7 hours agorootparentprevNope, that's not how it works anymore. First, insurers (payers) no longer even provide much insurance. The majority of their business is now managing networks and processing claims on behalf of self-insured employers. Second, payer profit margins are now capped by the 80% minimum medical loss ratio introduced by the Affordable Care Act (Obamacare). Payers actually make less profit when they deny care. When coverage for certain services is denied it's usually because your employer designed your plan with strict limits. reply nojito 5 hours agorootparentMA plans complicate this. There's a reason why everyone but United is getting out of the MA space, because united is growing despite medicare cutting payments. reply rapatel0 4 hours agorootparentprevThis is one of the unintended consequences of Obamacare. The act mandates that administration is a fixed percentage of the revenue. Effectively this created the same perverse incentive as cost+ contracts that have hobbled the DoD. There is no incentive to keep costs down. Value based care models are however super effective when properly implemented. Look at Kaiser Permanente. Infinitely better than the alternatives. reply nocoiner 6 hours agoparentprevCVS Caremark is also in on the scam. UHC seems quite clearly to be the good cop - low deductibles, wide network, good coverage - and CVS Caremark is the bad cop who changes my drug availability month to month, makes me jump through prior authorization hoops that go nowhere, and randomly covers or refuses to cover my kids’ ADHD medicine on a whim. So as soon as we find a medicine with availability, that works, CVS decides to terminate coverage and we - me, my wife, our kids, their doctor, the pharmacist - all start again from square 1. I switched jobs recently and despite having a drug regime that worked well for me over an extended period and was also cost effective, CVS denied coverage (and required prior authorizations, that were all denied) for virtually every component of my prescription care. Now, about three months after the switch, it’s probably back up to 85%+ of what it was before, but there was a lot of bureaucracy between then and now - and all due to a change that was really purely administrative in nature. Frustrating. reply reaperman 7 hours agoparentprev> stopped by the SEC Seems like it would be more appropriate for the FTC to step in rather than the SEC? reply lotsofpulp 5 hours agoparentprev> UHC and UnitedHealth group need to be broken up, and these incestuous relationships between insurance companies, private equity companies, and care providers need to be stopped by the SEC, because their only purpose is to exploit the wrapping up of care providers under one umbrella to extract more money for less work from people seeking essential services. How about Kaiser Permanente? They have been a vertical healthcare provider/insurance organization for many decades. You pay Kaiser premiums, you see Kaiser doctors, and you get your medicine from Kaiser pharmacies. reply t-writescode 1 hour agorootparentKaiser is an HMO, which is a different style of operating vehicle. reply datavirtue 8 hours agoparentprevSounds like the pitch to investors. reply bearjaws 11 hours agoprevGo after all the healthcare giants. If people knew even half of how consolidated their treatment was, they would riot. For those who don't know about the significant conflict of interest present here: 1. United is a health insurer that has to make payments for people's 2. United owns several physician networks (totaling 90,000 physicians), who then determine what your care should be—no conflict with the fact that they pay the bills... 3. United owns Optum, which determines how much your drugs are going to cost, and of course, who makes them—brand vs. generic, etc. 4. Optum runs its own mail order and specialty pharmacies. Optum also writes your care plans for many chronic diseases and ships medications all over the country. 5. Optum could require their own customers to use their care plans and software in order to receive medications at all, or mark up the price for anyone who doesn't. Let's step through a workflow. You, a patient on United, go to a physician for treatment. Later on, you get referred to a specialist, then get diagnosed with a chronic disease and need medication that you receive delivered monthly. That pans out to: United pays United, who refers you to United, that forwards you to Optum (owned by United), who gets paid by United. Each and every month. Let's say you find a better deal for your medication at another pharmacy. Too bad, its not going to be in your network and Optum will no longer cover it. How is a health system or an independent supposed to compete with that level of integration? This, of course, does not result in any savings or quality of life improvement for the patient or the physician. United and Optum charge the same prices as everyone else, or more. reply joe_the_user 11 hours agoparentIf people knew half of how consolidated their treatment was they would riot. Most Americans experience first hand how horrible health care here is. No one can get upset at whatever little details are involved, however 'cause it's beyond them. Especially, you won't get people excited about more competition in a field where markets and competition seem neither logical nor have shown any benefit. The complex referral system you describe basically results in turning regulated monopoly behavior into unregulated monopoly behavior. And this is the upshot of breaking up the original, regulated monopoly Blue Cross/Blue Shield, which provided adequate insurance in America's \"Golden Era\". Which to say that, imo, \"restoring the free market\" isn't a useful action in this mess. State controlled medicine is essentially the only solution to the already partly collapsed US health care system. reply bearjaws 10 hours agorootparentOh I don't disagree that the system is fundamentally broken, but we clearly need to attack from all angles. reply touristshaun 10 hours agorootparentquicker to start from scratch reply rqtwteye 10 hours agorootparentThat's lie rewriting a code base from scratch because the current is deemed unmaintainable. Most of the time you end up with the same number, but different problems or it's even worse. In my view Medicare for all would be a viable path but even the Democrats are not interested in tackling healthcare. reply terr-dav 9 hours agorootparentLet's refactor it then: The government simply takes ownership of UHC and they get a new charter to run it like the Postal Service. reply kelseyfrog 8 hours agorootparentCurious, how at this point could BigGov make UHC worse? reply thallium205 7 hours agorootparentprevMy mailman refuses to take my stamped envelopes out of my mailbox. Can't be bothered. reply ascagnel_ 7 hours agorootparentI’ve lived at my current address for about five years. The first year, zero issues. Starting at around the 2020 election, service dropped off precipitously, to the point where I’ve had a piece of outgoing mail in my box since Friday. I can’t trust the mail with anything time sensitive any longer. I blame this on Louis DeJoy, who was appointed Postmaster General in May 2020, and has numerous conflicts of interest. reply vanattab 6 hours agorootparentprevCount your self lucky he is not stealing your packages. reply diob 5 hours agorootparentprevHonesty at this point I'm planning to move to a country with sane healthcare sooner rather than later. reply sjwhevvvvvsj 9 hours agorootparentprevAt this point I’m open to new and exciting problems, whatever they may be. Hell, I’d be ok with leeches making a comeback if it meant I didn’t have to pay a copay on top of a premium. reply AgentOrange1234 8 hours agorootparentprevA code base doesn’t have tons of middlemen taking their cut. The current system is unsalvageable. Massive disruption is needed. reply happytiger 9 hours agorootparentprevWhat evidence do you have that this would be a good thing? And to the larger question, which I hear all the time, what does “starting from scratch” even mean when it comes to ongoing health care? You can’t seriously argue that we should risk medication interruptions so your friend loses her dad to his heart condition so we can somehow “start over?” We need a smooth transition to a more sustainable system with incentives aligned to customers and not investors in one scenario, single payer in another, or some other working idea to continue to provide care while reducing the insane profits and aligning health and well being of patients, as well as the health and well being of the people providing it, with the actual service delivery again. Burning everything down could kill a lot of people. I think this position is actually not particularly compassionate. reply NoblePublius 9 hours agorootparentBan all health insurance. And Medicare. And Medicaid. Require all healthcare services be transparently and consistently priced in cash. Transform the IRS into an insurer of last resort by providing 100% tax credits for all medical care in excess of 8% of income. Fixed. reply candiddevmike 8 hours agorootparentWould you keep or get rid of EMTALA in this scenario? What would happen with medical debt? I'd hate my healthcare options to be tied to my credit score. reply lostlogin 10 hours agorootparentprev> quicker to start from scratch How would you even do that? You need nurses and doctors and buildings and training. The lead time is decades and the cost incredible. Best start now guess. reply greenavocado 8 hours agorootparentImagine a time before health insurance existed reply DANmode 8 hours agorootparentMore doctors, less work per day per doctor, more attention to each patient? reply ants_everywhere 8 hours agorootparentprevObligatory Gall's law > A complex system that works is invariably found to have evolved from a simple system that worked. A complex system designed from scratch never works reply cyanydeez 11 hours agorootparentprevthe healthcare complex employs millions. all these people would lose jobs. so there's really zero political will to crack the monolith, and why things like Obama care go forward, because they're bandaids. then there's the who employer leverage that businesses live having to immobilize a significant portion of their work force. it's absolutely not complicated to understand why nothing has moved the needle. reply SteveNuts 11 hours agorootparentRight. If these huge insurance companies had to \"compete\" with a real universal system, there's no way they could even exist. All they do is scrape profit off the top of every healthcare procedure in the US. The most useless middleman to ever exist, in my opinion. reply vinay427 10 hours agorootparentI agree with your broader point, but it’s worth noting that insurance middlemen exist in many European countries with universal health insurance, so surely some form of this can exist in a more regulated health insurance/provider market. reply kevin_thibedeau 9 hours agorootparentThe problem is the US has for-profit medical insurance as well as mutual insurance (collectively owned by their members). The laws were altered in the 90s to permit mutuals to convert to for-profit. This was generally a bad move as it takes out any real incentive to manage costs when jacking them up is the only way to boost profits so the C-levels can get 8-figure bonuses. reply rqtwteye 10 hours agorootparentprevI had private insurance in Germany. The big difference is that they have to compete there instead of having a captive audience they have in the US with employer based health insurance. Your employer picks the insurance options that are convenient for them, they don't care much about what's good for you. So you are basically trapped unless you are willing to not take insurance from your employer but go on the open market which will be very expensive. A while ago I asked my employer to just give me the money they give to Optum so I can buy insurance via ACA but they wouldn't do it. reply standardUser 10 hours agorootparentprevNot everyone in the healthcare industry would lose their jobs, that's absurd. It would mostly be the redundant insurance staff (and redundant sets of highly-paid insurance execs). reply NickC25 8 hours agorootparentThis! Execs would lose their jobs. Billing specialists (who do a 4 year degree in medical billing, which is in and of itself fucking absurd) would lose their jobs. You know who wouldn't lose their jobs? Doctors and nurses. The actual people who the system's outcome is dependent on. reply lotsofpulp 5 hours agorootparentThe managed care apparatus in the United States is about allocating insufficient supply of healthcare to excess demand based on the political value of the healthcare recipient. That is why Medicare pays doctors more than Medicaid for the same work (old people are worth more since they vote more than poorer and younger people). You can endlessly bucket people into infinite changing tiers based on their political power using reimbursement, deductible, out of pocket maximum, in and out of network providers, formularies, and prior authorization protocols. For example, you can give members of the military a different quality/quantity of healthcare than US federal Senators, who have a different set of policies, who in turn have a different set of policies from a highly profitable white collar firm’s employees, and yet again different from a less profitable business with lower paid employees, and so on and so forth. You can adjust reimbursements so that some people can immediately see doctors whereas others have to go to Physician Assistants or Nurse Practitioners. The system is a thing of beauty from a political point of view, and I bet countries with nationalized healthcare like UK and Canada move closer and closer to the US system as the population pyramids go upside down and cuts have to be made. And the whole time, people will waste their time being mad at managed care organizations, when the government leaders are the ones hiring them to be the “bad guy”. reply FireBeyond 5 hours agorootparentprev> Billing specialists (who do a 4 year degree in medical billing, which is in and of itself fucking absurd) What? I have never heard of such a thing, and I worked in the claims benefit management industry for nearly a decade. So I searched this, \"bachelor medical billing\" and while I got plenty of results, all of them were for certificate courses, which I'd expect. \"Top rated medical billing courses\" were all at community colleges. I am yet to find a Bachelor degree in medical billing. Indeed, on ... Indeed: > Can you get a bachelor's degree in medical billing and coding? > While a bachelor's degree in medical coding and billing isn't an option, people interested in pursuing this career can earn a degree in a related field instead. For example, you might consider earning a bachelor's in health care management or health information management. A certificate/diploma is going to be 9 months to 1 year. An associate diploma? 2 years. I also can't find any four year courses in medical billing. reply monksy 6 hours agorootparentprevThey're also firing people for fun. I know of a guy who is deep in the weeds upgrading their scala libraries that just got laid off within the week. (You have to do that to stay on top of all of the cves) reply keenmaster 10 hours agorootparentprevMore competition increases the number of jobs reply bearjaws 10 hours agorootparentOptum has billions of dollars in profit annually, none of that is going into the employees pockets or patient savings. reply echelon 10 hours agorootparentprev> State controlled medicine is essentially the only solution to the already partly collapsed US health care system. But wouldn't government control and subsidy lead to the same malinvestment and cost explosions as college tuitions? Wouldn't fierce competition at all levels be a good thing? Why not force insurers to cover everything up to a set cost on a per-disease basis? That is, let patients spend a set allowance before forcing them to use in-network? Why not adapt upfront cost estimates? Allow overages, but if a hospital goes consistently over estimate, then they get penalized? Allow patients to access cheaper doctors and services if they waive their rights to medical malpractice lawsuits. Give patients cheaper healthcare for demonstrable good health practices (taking into account diseases and existing conditions). reply worik 9 hours agorootparent> But wouldn't government control and subsidy lead to the same malinvestment and cost explosions as college tuitions? It could do. It is hard to see how it could be worse. The USA health care system, \"industry\", is a case study in failure at all levels except some pointy headed technology > Wouldn't fierce competition at all levels be a good thing? Definitely not. Competition is good in some areas, very bad in others. All sides must be able to enter and leave the market, and there must be even distribution of information. Most health care does not fit well Many countries have socialised systems that use waiting lists rather than wealth to ration access to health care. The private health industry work very hard, at all levels I have seen, to undermine those systems, but in many cases they offer very good care. Some of the best health care in the Americas is in Cuba reply thatfrenchguy 10 hours agorootparentprev> Most Americans experience first hand how horrible health care here is I mean, no, most Americans are just upset about cost-sharing, most providers in the United States are pretty good and have pretty good facilities and equipments. You can have systems that are mostly privatized (cough, France) that are better regulated than the United States, but that'd mean doctors would get paid less money & upper class folks would likely get worse care reply GCA10 10 hours agorootparent[upper class folks would likely get worse care] I agree that upper-class folks' experience would change in ways that would generate loud protests. But the biggest anger points likely wouldn't involve quality of care. Instead, we'd hear shouting about: providers' increased emphasis on cost-effective care. (You don't need an MRI because there's nothing in your symptoms that warrants it.) Right now, there's a lot of overtreatment in the U.S. medical system, catering to patients' desire to get big workups. scaling back of today's concierge-level ambiance, with fancy chairs, skyline views, etc. reply lostlogin 10 hours agorootparent> there's a lot of overtreatment in the U.S. medical system, catering to patients' desire to get big workups. It’s not just happening in the US. What goes on in the US is very influential elsewhere, and both patients and staff get pulled into the vortex of over-testing. And then to top it off, sometimes they are correct and they did need the test. reply thayne 8 hours agorootparentprev> Right now, there's a lot of overtreatment in the U.S. medical system, catering to patients' desire to get big workups. I think has more to do with a combination of overtreating results in higher income and fear of malpractice suits if you undertreat. reply FireBeyond 5 hours agorootparentPartly. Let's also talk about the ugly world of Certificates of Need and diagnostic imaging and how they collide. CoNs are something lobbied for by hospitals. If you want to open a new hospital or healthcare facility in an area, you need to apply for a certificate of need, which allows/asks existing hospitals if they think there is a need for your facility, to avoid \"overservice\" (lol, okay) of an area. Diagnostic imaging companies - each of the big ones (Siemens, GE, Philips) offer in house financing for MRI, CT, etc., that they advertise to physicians. They also all offer specialist consulting help to facilitate you getting a CoN for your facility. Hell, they all also well help you find other physicians in your area who'd like to go in on setting up a DI facility (and will assist with spinning up the practice). And then we find that physicians who own a DI practice (or a share in one) refer their patients to diagnostic imaging at rates several standard deviations above other physicians, and at rates that are \"statistically improbable\" when correlated to underlying ICD-10 diagnostic codes. Upton Sinclair comes to mind (\"It is difficult to get a man to understand something, when his salary depends on his not understanding it\"). reply mistrial9 9 hours agorootparentprevunneeded surgery is also a recurrent theme; prescriptions for just about anything is now the norm reply AHatLikeThat 10 hours agorootparentprevMaybe in large urban areas, and if you can afford insurance at all. In rural areas, even smaller urban areas, there are few physicians, long waits and not enough facilities. [https://www.krqe.com/health/new-mexico-needs-hundreds-of-hea...] reply arebop 10 hours agorootparentIt's the same in San Francisco, where we support returns to investors in residential real estate by banning new development since the 1960s and therefore doctor salaries don't afford a luxury lifestyle [https://www.nytimes.com/2017/06/03/business/economy/high-end...] and therefore we have a shortage of physicians. reply pyuser583 9 hours agorootparentSan Francisco is also overwhelmingly young and healthy. reply KerrAvon 9 hours agorootparentBetween COVID and the millennial cohort in SF, that's not going to be true very much longer, if it is at all today. reply HDThoreaun 10 hours agorootparentprevThis is because congress wont expand residencies so there arent enough doctors. Doctors make a bunch of money and can live anywhere they want, almost none of them want to live in bumfuck. reply echelon 10 hours agorootparentRemove the residency cap, allow foreign doctors to immigrate and quickly certify their skills, allow nurses to attend night school to become doctors, etc. reply HDThoreaun 10 hours agorootparentI agree this is the solution rural medicine needs. reply oatmeal1 11 hours agorootparentprev> Which to say that, imo, \"restoring the free market\" isn't a useful action in this mess. State controlled medicine is essentially the only solution to the already partly collapsed US health care system. I don't trust the US government is competent enough to run healthcare. If it can do better than the existing system, let it create a new voluntary, unsubsidized insurer, free of the BS rules it has created. Competition is the source of quality and low prices. Any monopoly is an invitation for poor quality and high prices. reply bcrosby95 10 hours agorootparentThe great thing about the \"50 states\" model is states can try random experiments. For example, Texas has done a lot to try to bring more competition but none of them have done a thing for the high cost of healthcare. reply oatmeal1 9 hours agorootparentThat would be great if we had real federalism. The states cannot try anything really unique, because they are hamstrung by federal law and federal subsidies with strings attached. reply FireBeyond 10 hours agorootparentprevYup. The big one to me being capping malpractice payouts. \"Healthcare costs a lot because physicians have to carry very expensive malpractice insurance because of astronomical judgments\". Texas caps malpractice payments and everything stays exactly the same. Also, malpractice insurance in itself isn't typically as onerous as people believe it to be. What is onerous, and what that industry does differently to most other insurance segments is \"tail insurance\". Tail insurance is the concept that major malpractice suits may appear well after your claims-made liability policy has ended. In most cases it's actually DOUBLE the premium you're paying for malpractice insurance, implying the insurer believes that your coverage is less than one-third of the claims they expect to pay. What -should- happen is that you carry \"claims-made and prior acts\" coverage. The challenge there is that in many cases your employer will cover claims-made as part of your compensation or part of their insurance, but don't elect prior acts coverage (and because of the way they do it, I suspect it's not as simple as \"let me pay the difference\"). But in general capping malpractice payouts has done nothing to offset malpractice coverage costs, let alone flow-through to end consumer costs. reply rainsford 11 hours agoparentprevThat kind of extractive, anti-consumer business model would be worth going after in any industry, but it feels especially bad in health care. Most health care isn't optional for the patient, and of course the more non-optional the care is the more expensive it tends to be. And serious health problems are both rare and incredibly stressful for the patient. Someone with cancer is going to have no experience shopping around for oncologists and will be willing to pay almost anything not to die. It's almost the worst possible scenario for consumer driven free market dynamics. My personal opinion is that giant health-care conglomerates probably shouldn't exist at all. But if they do, they should be subject to much higher standards when it comes to things like antitrust than regular companies. reply mywittyname 11 hours agoparentprev> If people knew half of how consolidated their treatment was they would riot. My partner deals with claims denials for care providers and if someone wrote a book on the stuff she's seen happen, I genuinely think it would be akin _The Jungle_ for modern audiences in terms of cultural impact. reply oogali 10 hours agorootparentI’ve been getting exposure to this space and the backend systems that drive it. It is mind-bogglingly dysfunctional. Aphyr recently provided a limited window[1] into the level of dysfunction that happens with one of these behemoths that are the result of 100+ mergers, acquisitions, spinoffs, and joint ventures. I feel terrible for the providers who have to try to navigate these antics. In my opinion, all of this contributes to two primary “bad” things: 1) increased rates of retirement from older physicians who don’t want to deal with this anymore (despite wanting to continue practicing for 5-10 more years), and 2) consolidation of physician practices into larger entities as a way of coping which inevitably leads to the entity being acquired by a hospital and absorbed into another behemoth of an organization. Both make it hard for individuals to receive consistent, quality care. 1: https://aphyr.com/posts/368-how-to-replace-your-cpap-in-only... reply tacticalturtle 10 hours agoparentprevIsn’t this just how HMO’s work? It’s not a PPO, you’re supposed to have the majority of your care managed within the large organization. Kaiser Permanente is another one. In theory it makes sense - by keeping everything in network there’s no constant negotiation over reimbursement rates. But the problem is there aren’t many competitive HMOs, and we have a healthcare system driven by employment, so you can’t switch to a new HMO if you’re unsatisfied by your current one. Edit: My point is that it’s not a conflict of interest to be routed through the UH network - that’s the entire point of an HMO vs a PPO. The idealized goal is that you have a coordinated team of providers across the organization. reply yborg 7 hours agoparentprevYou didn't even mention Optum Bank, which they use to also sponge up that sweet HSA cash lest any drop of healthcare spend somehow escape UHG's toll. reply bogota 2 hours agoparentprevI’m sick of paying 5k a year myself and close to 20k counting my employer for a doctor to see me for 20 minutes, ignore everything i say, and then prescribe some shit without explaining anything. Additionally seeing how my wife is treated by doctors makes me feel physically sick. I have no respect for the medical field reply not2b 11 hours agoparentprevYep. I have UHC through work. I'm on an expensive medication and UHC requires that I order it through Optum, so they keep more of the money. At least neither of the doctors I usually see work for them, so I don't have that conflict. reply joncp 11 hours agorootparentAnd has Optum conveniently forgotten to ship refills, but only for the expensive drugs? That happened to my wife on multiple occasions. Or maybe they've rejected refill requests until right before your supply runs out, such that you have to go days without your meds while the new supply is shipped? Optum is the shadiest shitshow I've ever dealt with. reply not2b 11 hours agorootparentThey make it extra painful sometimes when it's time to refill, requiring re-authorization every year. My doctor has a woman working for his practice who spends almost full time battling insurance companies so that patients can get their meds, and she's been my ally at managing these fights. reply khuey 11 hours agorootparent> My doctor has a woman working for his practice who spends almost full time Yep, and this is the sort of make work that the health care system is full of that drives up costs for everyone. reply ChrisMarshallNY 10 hours agorootparentEvery doctor has one of these people, and they are probably the most valuable member of the practice, after the doctor, themselves. Most of them (in my experience) have been middle-aged women, hard-nosed, cynical, and no-nonsense. They can easily be abrupt and cranky. It's a real good idea to ignore that, and make them your friend. They can do miracles. reply silverquiet 6 hours agorootparentprevA lot of the doctors I've seen recently just don't take insurance. Basically they just tell me what something costs and then I pay it. Obviously if you are poor this is a problem, but then again so is everything else and you probably can't afford health insurance anyway. reply jcdavis 10 hours agorootparentprevGetting new prior auths every year is annoying but not exclusive to Optum, thats been the case with all the specialty pharmacies I've gotten prescriptions from. reply biggc 9 hours agoparentprevOn paper this seems similar to how Kaiser operates. AFAIK Kaiser is generally well-liked by its members, why is UHC so terrible? I guess UHC doesn't own the hospitals? reply garyiskidding 1 hour agoparentprevThanks for breaking it down, especially for people outside America. reply fnordpiglet 8 hours agoparentprevRioting isn’t covered under the insurance terms and conditions so no one can afford to do so. reply earth2mars 9 hours agoparentprevFeel like you also explained the Apple walled garden. You pay 30% tax or no entry. Regulation need to be passed to change adapter port. Things won't work if you aren't in the ecosystem. And they cost a buck for Mediocre service. reply earth2mars 9 hours agoparentprevFeel like you also explained the Apple walled garden. You pay 30% tax or no entry. Regulation need to be passed to change adapter port. Things won't work if you aren't in the ecosystem. And they cost a buck for Mediocre service reply akeck 9 hours agoparentprevThis is like Luxottica owning optometrists offices, eyewear providers like Lenscrafters, and Eyemed vision insurance. reply oogali 10 hours agoparentprevWait until people catch on to the behemoth that is CVS Health… reply FireBeyond 10 hours agorootparentOh, and I love where my insurance would cover my prescriptions from CVS in Washington, but when I was down in California needing steroids and anti-inflammatories urgently for my gout, they would not cover them there (and I'd made the apparently idiot assumption of having the urgent care physician send the scripts to a nearby CVS because I thought they'd be covered. Nope. Not even \"out of network\" - I ended up paying out of pocket and arguing for reimbursement. reply vundercind 9 hours agorootparentFor non-Americans: US health insurance is often bound to a state or even a region of a state, paying only for emergency care (and that, only because they are required to) outside that area. We basically need travel insurance to safely travel in our own damn country. Add it to the list of crazy features of our system, any one of which would cause riots in another OECD state if not fixed promptly. And we’ve got several. reply nradov 7 hours agoparentprevIt's important to understand the factors driving consolidation in the healthcare industry as this goes beyond UnitedHealth Group. Everyone is sort of gradually converging on a \"payvider\" model like Kaiser Permanente with everything under one parent corporation. Payers and providers have been merging for years in order to gain more negotiating power over claim reimbursement rates. Regulatory compliance issues and IT costs are also killing off small, independent medical practices. In many regions a few large health systems now dominate the market. So, the only way for payers to hold down costs is to build up captive provider organizations where they can drive some operational efficiencies and economies of scale. reply ars 8 hours agoparentprevIsn't this basically how an HMO works? I've heard those have lower costs and patients seem to like them. What's different with United? reply toast0 2 hours agorootparentI've been with Kaiser in Northern and Southern California. But not really with other HMOs. I think the difference is Kaiser (in most places) is really a closed system; if you're with Kaiser, you go to Kaiser facilities for everything, as long as you're in the service area. If you're not with Kaiser, you don't go to Kaiser facilities, other than the emergency room maybe. Everyone you interact with is a Kaiser employee or contractor. You don't get recommended care that won't be covered, you don't get treated by someone who isn't in network, you show up, you pay your copay, and that's it, you're done. For HMO plans with other providers, it seems like the doctors are often independent; you have to stay in network, but you still have to deal with network BS like this office is in network, but only some of the doctors. There's not a Blue Shield medical center with doctors, specialists, and a pharmacy at one location. reply pierat 10 hours agoparentprevBasically, most forms (including ours) of capitalism turn into a oligopoly where each oligo-member is highly vertical and controls the whole narrative. Another word for this would be corporation-states. Amazon is another example of this. So is Google. So is Apple. It's high time that government steps in and breaks these 'too big to fail' corpo-states up into actual competing interests that, in the end, do better for the citizenry. Cause each corporation is a dictatorial 'state' acting in opposition to our elected government, and much of our monopoly laws, either in spirit or in application. reply gazpacho 6 hours agoprevI think the main problem is lack of free market. Oligopolies are part of the problem, but an equally large part is lack of choice from employes. Many (most?) insured in the US get their healthcare through their employer. You get maybe 2 choices of insurer, often only one. You’re not going to get a new job to switch insurers. The people negotiating the plans are too far away from the people receiving care (it’s probably the finance people anyway). Not everyone has the same healthcare needs or lives in the same area, group plans don’t make sense in today’s world. The government should be promoting and incentivizing ICHRAs and similar. If you haven’t heard of ICHRAs they allow employers to give you a stipend for healthcare. You get to choose your plan (including open marketplace plans, which have some affordability regulations), you can use it for copays or to just pay for stuff out of pocket. You can choose a catastrophic plan and get insurance / a plan from your PCP so you never have to worry about “network” changes. And it’s tax free for employers and employees. Cheaper for employers too, they don’t have to hire benefits administrators and negotiate with brokers/insurance companies. If you’re a company, especially a mid to small sized one, I highly encourage you to look into ICHRAs. reply ClumsyPilot 4 hours agoparent> lack of free market. Oligopolies are part of the problem Free market produces Oligopolies, monopolies, cartels and collusion. They are perfectly absolutely natural formations. FAANH Companies form anti-poaching agreements, now they suddenly all have layoffs at the same time, you think that’s a coincidence? Even drug cartels divide up territories instead of ‘competing’. reply jaredhallen 8 hours agoprevI've had United for a little over a decade, and overall I have to say it's been pretty good. My wife was hospitalized for about a month with our first born, racking up hospital bills over half a million USD. I think I paid about $3500 out of pocket. Then, a number of years later, the same child had her appendix removed. Again, terrifying bills, and about $3500 out of pocket. That being said, after the second event, we had discharge orders from the surgeon that included very specific conditions for when we should bring her in. When some of those conditions presented, we brought her to her (in network) primary care physician, whose office is (incidentally) in our in-network hospital. The physician agreed with our having brought her in, and recommended a CT scan. My daughter was sent down the hall from her in-network pediatrician to the in-network emergency room where the CT machine was located. CT scan proceeded, findings were good, and my daughter recovered just fine. So imagine my surprise when I get a bill for the CT scan. After many phone calls, emails, registered letters, etc. the final determination was that the ER was, at the time of the events in question, had been staffed by an out-of-network third party and thus would not be covered. Now in the scheme of things, the CT scan was a drop in the bucket compared to everything that was covered, and I'm very thankful for how things worked out. But the principal of that situation really left a bad taste in my mouth. We had no reason to suspect that the CT scan wouldn't be covered, and were in no way advised as such. Doesn't seem right. reply rqtwteye 7 hours agoparent\"After many phone calls, emails, registered letters, etc. the final determination was that the ER was, at the time of the events in question, had been staffed by an out-of-network third party and thus would not be covered.\" I always wonder how a normal person is supposed to figure out stuff like this. I suspect these traps are set intentionally to squeeze more money out of people. reply xyst 6 hours agorootparentBecause most people give up or forget after the first round of phone calls. It's more profitable to deny claims initially. Patient either forgoes care or pays out of pocket. Insurance company keeps the premium from customer. reply lotsofpulp 5 hours agorootparentprevAs of Jan 1, 2022, the No Surprises Act requires all healthcare providers that work in a hospital to be considered to be in network if the hospital is in network. And also, all emergency healthcare is considered in network even if the hospital or doctors or labs are not in network. reply nonethewiser 4 hours agoparentprev> We had no reason to suspect that the CT scan wouldn't be covered, and were in no way advised as such. Doesn't seem right. I can’t understand how this is even legal. I know its a somewhat normal occurrence but you wouod think people could at least easily win a lawsuit and get them to sure-up their policies. Its probably ignorance and not malice but it doesn’t really matter. It basically just amounts to a scam. reply quasse 1 hour agorootparentIt's no longer legal as of Jan 1, 2022 (part of the Consolidated Appropriations Act, 2021). If you want a list of the real worst of the worst Senators, go look at the people who voted against making this a law. reply nradov 7 hours agoparentprevSome of those abusive billing practices by out-of-network providers are now prohibited by the No Surprises Act. https://www.cms.gov/nosurprises reply theGnuMe 5 hours agoparentprevThe insurer is playing games here. Emergency care (ER care) is required to be covered even if it is out of network. So the CT scan should have been covered. Also if this was post 2021 there is the no surprises act that applies as well. This is when you go to an in network facility and out of network providers are staffing it. https://www.cms.gov/newsroom/fact-sheets/no-surprises-unders... reply droopyEyelids 7 hours agoparentprevWhat is and is not covered is set by your employer. That is the “plan design” they either choose entirely (for self funded plans) or pick a group’s plan to join (group plans) The surprise third party provider bills are kind of a separate issue, in that it was a scam every insurance company did. we’re mostly protected by the “no surprises act” that went into effect jan ‘22 reply sabujp 9 hours agoprevThere's also this : https://www.reuters.com/technology/cybersecurity/cyber-secur... , this hack caused by malware from 2021, caused huge portions of their employee base tied to optum and their change healthcare acquisitions to be unable to work for days (and it's still ongoing!). I guess their employees got a \"vacation\" out of it while everyone else waiting on prescriptions at CVS, etc got shafted. It literally took a huge portion of the US pharmacy network to go down for the US to realize what a big problem UNH is. reply bithead 3 hours agoparentFormer Optum/UHG employee, worked in automating things in IT. While I was there they went on a years long spree to get rid of everyone under 40. I finally got laid off and in my group of 153, 17 were under 40. I had automated most everything in my area,and although I meticulously documented everything, when you get the plug pulled like that you don't get time to do any hand off, so it hit things pretty hard. They did this for months (laying off people under 40). They gave me a large enough severance to cover a long time out of work, and the severance agreement stated if I sued for EIRSA I had to pay it back. I took it, but the entire thing painted a picture of management totally disconnected from the people putting code to programs. reply codegeek 10 hours agoprevAll health insurance companies need to die. They are all crooks and frauds and are using an outdated system in our country siphoning money from families. reply SlightlyLeftPad 6 hours agoparentA-f**ing-men reply Spivak 10 hours agoparentprevThis opinion isn't actually all that drastic. If we just got people on the HSA + disaster coverage* train a lot of the issues with the system would disappear. I am far far from the cheapest patient but my annual spending doesn't even get to 50% of my portion of the premiums of my employer's PPO plan. * Where if a doc prescribes insurance pays for it no questions asked (to you the patient). They can claw it back from the doctor if they think it's excessive. I think for disaster only coverage you could successfully pass laws to this effect without insurance companies starting a third world war. reply camhart 9 hours agoprevWe signed up for a United Healthcare plan a couple years back. It showed a bunch of Doctors in network. Once we were on the plan, 90%+ of the Doctors told us they didn't accept United Healthcare or weren't accepting new patients. We couldn't find quality Doctors near us as a result. Ended up having to switch off United Healthcares plan as a result. Certainly felt like it was false advertising to say all the Dr's are in network just to find out none of them will treat you. reply burkaman 7 hours agoparentIt is absolutely false advertising and probably illegal, and it's not just you: https://jacobin.com/2024/01/health-insurance-giants-companie.... There has been some congressional interest (https://www.finance.senate.gov/chairmans-news/wyden-calls-fo...) but I think it would take a big class action lawsuit or something to \"fix\" this. Obviously the only actual fix is universal coverage though. reply TheAceOfHearts 8 hours agoprevI started following this person called Doctor Glaucomflecken who makes funny short skits on TikTok and YouTube, and that was how I first learned about United Healthcare. The wild thing is that he makes these funny videos so you think it's a joke, but then you look it up and realize it's real. Healthcare in the US is not in a good place, so this definitely sounds like a good action. reply xyst 6 hours agoparentthose short videos are based on propublica stories. The \"30 days of healthcare\" series was pumped by the algorithm to me as well reply Blackthorn 11 hours agoprevOptum is the most garbage organization that has absolutely ruined local healthcare. I go out of my way to find places that aren't affiliated, even though they're much further distance, just to avoid them. It's about time this happened. reply rainbowzootsuit 10 hours agoprevNot shilling here, merely impressed by the work of journalist Marshall Allen—he has a book \"Never Pay the First Bill\". Search around on podcasts and YouTube for some interviews to get the jist. I've bought a few copies for friends that had expensive health issues and have used the techniques on relatively small stuff for myself. reply lvl102 8 hours agoprevCovered this space from an investment angle for nearly two decades. These guys are crooks. It’s a controversial take but UNH (and everything else in healthcare) became so big directly as a result of PPACA. That should really be Obama’s legacy. US healthcare system is broken because both the right and left are completely bought by these monsters. reply Geeek 6 hours agoparentCan you guide me where I can read up more on this? reply ChrisArchitect 11 hours agoprevRelated: US pharmacy outage triggered by 'Blackcat' ransomware at UnitedHealth unit, sources say https://www.reuters.com/technology/cybersecurity/cyber-secur... (https://news.ycombinator.com/item?id=39524514) reply SlightlyLeftPad 6 hours agoprevI want to know who exactly the “industry officials who compete with the healthcare giant” they’re interviewing are. The price fixing and collusion go way way deeper and broader than just United Healthcare and Optum. reply stop50 11 hours agoprevI sense a new glauckomflecken video. reply athenot 11 hours agoparentFor those not familiar, here is the one on Optum & United Healthcare: https://www.youtube.com/watch?v=_khH6pZnHCM reply John23832 8 hours agorootparent“Jimothy, when you make enough money, you get to write the laws.” reply LordDragonfang 11 hours agoparentprevMy first thought as well. Everything I know about UH and Optum (all of it negative) come from his videos, and it makes me appalled that any company like this is allowed to exist, when every study seems to indicate that patient in private-equity-owned care experience worse, more expensive care. It's the opposite of \"capitalism creating efficiency\". reply stop50 11 hours agorootparentIts my primary source of Schadenfreude, because whenever he says anything about insurance covering, i usually research it and come up with that it is covered. reply NickC25 11 hours agorootparentprev>opposite of \"capitalism creating efficiency\" It's rent seeking behavior by an actor that pretty much is a negative value-add from a patient's perspective. They are a cancer. reply roberttod 8 hours agoprevAll the awful reviews of united here, and yet it's reviewed as one of the highest rated insurance agencies (for example see https://www.forbes.com/advisor/health-insurance/best-health-...) Are these reviews completely paid for? What's going on here? Or are all the options awful. I am in the position to choose our provider at our (small) company, but between Gusto and JustWorks and the majority of our employees being in Texas there was slim to none options except united. reply burkaman 5 hours agoparentAll the options are awful. Obama got in trouble for saying \"if you like your plan you can keep it\" when promoting the Affordable Care Act, because it wasn't true, but in some sense it was true because I truly cannot imagine any American liking their healthcare plan. No matter how expensive your plan is, the simplest interactions like changing a birth control prescription or getting new glasses are absolute torture. reply jjulius 8 hours agoparentprevThe criteria that your Forbes piece judges UHC on don't seem to be the things that people are complaining about. Seems that the Forbes piece is more of a surface-level judgement than anything. reply SlightlyLeftPad 6 hours agoparentprevYes reply NickC25 11 hours agoprev>UnitedHealth executives have said that Optum and UnitedHealthcare don’t favor one another Yeah, that's laugh-out-loud levels of bullshit. You think executives are just going to admit to facilitating what effectively is a form of racketeering? NINJA EDIT: The Optum arm itself needs to be broken up into a bunch of smaller pieces. United Healthcare also needs to be broken up. reply AuryGlenz 11 hours agoparentThat's insane. The archive link isn't working for me so I can't read the article, but we received a letter that any long term prescriptions might need to go through Optum and that we'd only be able to fill a few at a local pharmacy before the refused to cover them. I was a bit flabbergasted as that didn't seem like it could possibly be legal. By the way - that's absolutely not great if you have controlled medications, as you need to sign for them and can't exactly get them filled early. I take three different ones. Luckily my wife and I work from home. reply justinclift 10 hours agorootparent> The archive link isn't working for me ... For me, that link bounces to the archive.md version of it (same url, but archive.md domain), which is resolving to 139.99.171.251. You can probably get it to work by adding an override in your /etc/hosts (or equivalent) file, and using the archive.md version of the url. In theory. ;) reply om154 6 hours agoprevThe healthcare system in the United States is so hard to navigate. I recently switched to Sedera (https://sedera.com/). They to have much better incentives, better prices and service. We'll see how it goes reply FireBeyond 10 hours agoprevMy \"favorite\" story about UHC is from a provider perspective. Taking a page from Section U in The Rainmaker (\"deny all claims\"), they went through a phase where multiple people took them to court over HEMS (helicopter EMS) transport denials, including from the scene of serious car accidents, due to lack of \"pre-authorization\". Apparently in their mind, us paramedics (or maybe the chopper pilot) should have been calling their 800 number as we stabilized our patient... \"This is John, I'm a paramedic working on one of your patients who was hit by a truck. We would like to fly him to the hospital due to extensive multisystem trauma but we need a pre-auth. His name? Hang on, let me find his wallet. No, that's Smythe, S-M-Y-T-H-E, I know, I know, sorry, it's a bit loud with the jaws of life and the engines... What's that? Um, sure, yes, I can hold for a nurse consult...\" reply xyst 6 hours agoprevend private health insurance. single payer system needed. reply claytongulick 4 hours agoprevI see a lot of comments on here about how to \"fix\" the system, ranging from informed to terribly uninformed. There's one thing that I haven't seen mentioned that would be a great place to start: Be healthy. I know, many people don't have that choice. There are hereditary conditions, and accidents and chronic conditions - I know. I work in the industry. However, as a nation we've largely chosen to outsource our health. It makes sense, in a world that operates around specialization, we tend to follow those patterns for everything. Electrical problem? Call electrician. Plumbing problem? Call plumber. Health problem? See a doctor. It's understandable, but it's reactive and not an optimal solution for wellness. Consider these leading areas of healthcare costs in the U.S.: Obesity: 173 billion per year. [1] Diabetes: 412 billion per year. [2] Heart disease & stroke: 216 billion per year. [1] Smoking: 240 billion per year. [3] And alcohol just makes all of that way worse. [4] Most of the above can be controlled. If we really want to reduce costs and improve healthcare, I think it's best to start at home and work towards making sure we and our families are healthy and fit. It's not easy, and it takes a lot of education and work, but it's worth the effort. If Americans did that, we could reduce healthcare spend and ease the burden of stressed medical systems. We'd all be healthier and happier. It's not the whole answer, but it would be a great start. The path we're on seems to be trending in the opposite direction. Processed foods, sedentary lifestyle, addictive additives, high stress jobs - it all adds up. I think rising healthcare costs are (amongst other things) a symptom of our choice to deprioritize our wellness. Sure there are lots of opportunities for disintermediation in the gordian knot of U.S. healthcare, and we should pursue good solutions. But we should start with what we can directly control: our diet and fitness. [1] https://www.cdc.gov/chronicdisease/about/costs/index.htm [2] https://diabetes.org/newsroom/press-releases/new-american-di... [3] https://www.cdc.gov/tobacco/data_statistics/fact_sheets/fast... [4] https://www.sciencedirect.com/science/article/pii/S277306542... reply dandigangi 10 hours agoprevDo Discover/Capital One next. reply voakbasda 10 hours agoprevUnitedHealth is by far the worst health coverage I have ever had. They are so bad at paying claims that our local hospital network has dropped them; all of our emergency care in the immediate region is now out-of-network. They absolutely are criminals and deserve to be put out of business. reply earthwalker99 9 hours agoparentA friend of mine couldn't get his claims paid even as a UHC corporate employee. He ended up quitting his job at a health insurance company because he wanted functional health insurance. reply mindslight 11 hours agoprevHow is there an argument of wrongdoing here when the regulatory approach for healthcare is still based around this idea that multiple anticompetitive arrangements (the price fixing between providers and \"insurers\") will somehow actually create competition? Like don't providers have to be standing alone as their own market independent of payer before one could say that UHC's actions here are specifically anti-competitive, rather than just the HMO system working as envisioned? reply place_order 8 hours agoprev [–] Most health issues are connected to food. Synthetic sugars, seed oils, herbicides, pesticides, and diminished quality of vitamin mineral content. If you think the heal5 care industry has it locked up look into ag. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The United States has initiated an antitrust investigation into UnitedHealth Group, citing worries about price manipulation and limited competition in the healthcare sector.",
      "Key points in the debate involve market incentives, price transparency, insurance coverage, regulatory impact, and proposals like universal healthcare and government involvement.",
      "Healthcare system challenges encompass consolidation, care accessibility, insurance problems, and the necessity for reforms focusing on preventive healthcare measures and better outcomes."
    ],
    "points": 457,
    "commentCount": 166,
    "retryCount": 0,
    "time": 1709070401
  },
  {
    "id": 39531536,
    "title": "Enhance Unit Testing with Testcontainers: Lightweight Database & Brokers in Docker",
    "originLink": "https://testcontainers.com/",
    "originBody": "Unit tests with real dependencies Testcontainers is an open source framework for providing throwaway, lightweight instances of databases, message brokers, web browsers, or just about anything that can run in a Docker container. How it works Test dependencies as code No more need for mocks or complicated environment configurations. Define your test dependencies as code, then simply run your tests and containers will be created and then deleted. With support for many languages and testing frameworks, all you need is Docker. Get started with Java Get started with Go Get started with .NET Get started with Node.js Get started with Python Get started with Rust Get started with Haskell Get started with Ruby Get started with Clojure Get started with Elixir Java Go .NET Node.js Python Rust Haskell Ruby Clojure Elixir GenericContainer redis = new GenericContainer(\"redis:5.0.3-alpine\") .withExposedPorts(6379); Copy container, err := testcontainers.GenericContainer(ctx, testcontainers.GenericContainerRequest{ ContainerRequest: testcontainers.ContainerRequest{ Image: \"redis:5.0.3-alpine\", ExposedPorts: []string{\"6379/tcp\"}, WaitingFor: wait.ForLog(\"Ready to accept connections\"), }, Started: true, }) Copy RedisContainer redisContainer = new RedisBuilder().Build(); await redisContainer.StartAsync(); Copy const redis = await new GenericContainer(\"redis:5.0.3-alpine\") .withExposedPorts(6379) .withWaitStrategy(Wait.forLogMessage(\"Ready to accept connections\")) .start(); Copy redis = ( DockerContainer(\"redis:5.0.3-alpine\") .with_exposed_ports(6379) ) redis.start() wait_for_logs(redis, \"Ready to accept connections\") Copy let docker = clients::Cli::default(); let redis = docker.run(redis::Redis::default()); Copy redis(tc/create {:image-name \"redis:5.0.3-alpine\") :exposed-ports [6379]}) (tc/start!))) Copy {:ok, _} = Testcontainers.start_link() config = %Testcontainers.Container{image: \"redis:5.0.3-alpine\"} {:ok, container} = Testcontainers.start_container(config) Modules Test Anything You Can Containerize: Database, Message Broker, And More See all 50+ Modules Use cases How Testcontainers can help you Data access layer integration tests Use a containerized instance of your database to test your data access layer code for complete compatibility, without requiring a complex setup on developer machines. Trust that your tests will always start with a known state. UI/Acceptance tests Use containerized web browsers, compatible with Selenium, to run automated UI tests. Each test gets a fresh, clean instance of the browser, without having to worry about variations in plugins or required updates. Application integration tests Run your application in a short-lived test mode with dependencies, such as databases, message queues or web servers, to give you a rich interactive and explorative testing environment. Get started Supported Languages There are implementations of Testcontainers in all of your favorite languages. Click through to read their specific documentation. Java Go .NET Node.js Python Rust Haskell Ruby Clojure Elixir Industry standard Companies using Testcontainers Articles About Testcontainers engineering.atspotify.com Announcing the Recipients of the 2023 Spotify FOSS Fund Testcontainers was also part of last year’s fund, receiving 13,000 EUR. And there’s a good reason why it’s back in 2023 devblogs.microsoft.com Trying out MongoDB with EF Core using Testcontainers An introduction to the MongoDB database provider for EF Core, including use of Testcontainers uber.com Handling Flaky Unit Tests in Java Building a stable and reliable testing system is often a key requirement for software development organizations doordash.engineering How to Boost Code Coverage with Functional Testing Introducing a non manual functional testing approach that can be run like unit tests locally or in a Continuous Integration (CI) pipeline. capitalone.com Testcontainers & LocalStack for Spring Boot functional tests A guide from Capital One to using Docker and Testcontainers to make functional tests more portable & economical without sacrificing testing quality. cloud.google.com Develop and Test Spring Boot Applications Consistently Learn how to consistently build and test with environment parity from development to production with Emulators and open-source Testcontainers. A huge thankyou to our sponsors Bronze Sponsors Donors Backers Philip Riecks Karl Heinz Marbaise Sascha Frinken Christoph Dreis Nikita Zhevnitskiy Bas Stoker Oleg Nenashev Rik Glover Amitosh Swain Mahapatra Paris Apostolopoulos Community Champions Inspirational members of the community Testcontainers Community Champions actively contribute to the growth and betterment of the Testcontainers community. They are passionate about Testcontainer, and use their knowledge and skills to help others succeed. Meet our Community Champions",
    "commentLink": "https://news.ycombinator.com/item?id=39531536",
    "commentBody": "Testcontainers (testcontainers.com)410 points by floriangosse 10 hours agohidepastfavorite167 comments SOLAR_FIELDS 5 hours agoI did not come in here expecting to read such effusive praise for testcontainers. If you’re coming from a place where docker wasn’t really a thing I can see how it looks beautiful. And in a fair amount of use cases it can be really nice. But if you want it to play well with any other containerized workflow, good freaking luck. Testcontainers is the library that convinced me that shelling out to docker as an abstraction via bash calls embedded in a library is a bad idea. Not because containerization as an abstraction is a bad idea. Rather it’s that having a library that custom shell calls to the docker CLI as part of its core functionality creates problems and complexity as soon as one introduces other containerized workflows. The library has the nasty habit of assuming it’s running on a host machine and nothing else docker related is running, and footguns itself with limitations accordingly. This makes it not much better than some non dockerized library in most cases and oftentimes much much worse. reply simonkagedal 4 hours agoparentTestcontainers is not shelling out to the docker CLI; at least on Java, it is using a Java implementation of the docker network protocol, and I believe that’s the case also for the other platforms. Not sure this matters for the core argument you are making, just thought I’d point it out. reply doctorpangloss 2 hours agorootparentThe comment you are replying to makes so many mistakes about how Testcontainers works on Java that I'm not sure what source code the commenter is looking at. reply perbu 2 hours agorootparentWhy don't you point them out, please. We already know about testcontainers not using the shell, but rather talking to the HTTP API. Making comments like \"this is wrong, but I'm not gonna explain why\" has no place here, imho. reply collyw 1 hour agorootparentTry criticizing agile. \"You aren't doing it right\" reply CodeNest 1 hour agorootparentprevIt doesn't matter if it interfaces via CLI or not. Testcontainers tends to make things work but also introduces difficulty in resolution. You seem to have missed the point. reply fuzzy2 1 hour agoparentprevI'm interested to hear what you would do instead! I'm using Testcontainers in a very basic scenario: A web app with a PostgreSQL database. There are different database backends available (like Sqlite) but I use PostreSQL-specific features. Currently, in my integration testing project, I use Testcontainers to spin up a PostgreSQL database in Docker and then use that for testing. I can control the database lifecycle from my test code. It works perfectly, both on my local PC and in the CI pipeline. To date it also did not interfere or conflict with other Docker containers I have running locally (like the development database). From what I gather, that is exactly the use case for Testcontainers. How would you solve this instead? I'm on Windows by the way, the CI pipeline is on Linux. reply piokoch 19 minutes agorootparentThere is no alternative if you want Postgres \"embedded\" within your test, I have researched that for a long time, as full PGSQL as Docker image sounded as overkill, but nothing else exists. reply razemio 1 hour agoparentprevNever had any issues. We have 100+ build jobs running on Jenkins and most of them have some Testcontainer tests. These never collide if implemented correctly (randomised ports with check for e.g.) even when run in parallel. On my machine running several docker dev environments it was also never an issue. Can you specify what issues you had? Also I am pretty sure the library does not work as you describe. Isn't it using the Docker Engine API? I could be mistaken, never checked the source code. Edit: Just checked the documentation. According to the docs it is using the Docker API. reply theK 1 hour agoparentprevI have had a similar intuition from when trying out testcontainers some years ago. I do not know how the project has developed but at the time I tried it it felt very orthogonal or even incompabtible to more complex (as in multi language monorepo) projects, cde and containerized ci approaches. I do not know how this has developed since, the emergence of cde standards like devcontainer and devfile might have improved this situation. Yet all projects I have started in the past 5 years where plain multilingual cde projects based on (mostly) a compose.yml file and not much more so no idea how really widespread their usage is. reply Szpadel 26 minutes agoparentprevcould you elaborate what limitations does is have? how this does not play nice with remote docker/other docker containers? I don't know this library but it looks like something that I started writing myself for exactly the same reasons so it would be great to know that's wrong with this implementation or why shouldn't I migrate to use that, thanks reply choeger 3 hours agoparentprevCame here with exactly this on my mind. Thanks for confirming my suspicion. That being said, having specific requirements for the environment of your integration tests is not necessarily bad IMO. It's just a question of checking these requirement and reporting any mismatches. reply eecc 50 minutes agorootparentexcept the parent is wrong (at least the Java impl). see: https://github.com/testcontainers/testcontainers-java/blob/m... https://github.com/testcontainers/testcontainers-java/blob/m... reply Jnr 2 hours agoparentprevSimilarly to CI agents, I run them in docker-in-docker container, which makes it a lot harder to break anything on the host. reply cdata 5 hours agoparentprevI would guess that this speaks to an unattended (developer) user story related to other workflows, or perhaps the container-adjacent ecosystem overall. Testing with any workflow is always tricky to get just right, and tools that make it easy (like, \"install a package and go\" easy) are underrated. reply rollulus 2 hours agoparentprevDoes anyone happen to know which testcontainer implementations shell out, if any? reply nrabulinski 1 hour agorootparentSeems like the „community-maintained” ones they endorse, like the Rust implementation, do I did not realize Rust wasn’t officially supported until I didn’t go to their GitHub and see in the readme that it’s a community project, and not their „official” one reply mellutussa 14 minutes agoprevThis is a very nice project, but it's awful that they're blurring the line of unit test and integration test. They are very different and both very important. Things in the software world are very trendy. If this starts a trend of making people think that they're writing unit tests when they are writing integrations tests, we are fucked. If I need to change code that you wrote I need a lightning fast way to figure out that I haven't broken your code according to the tests that you wrote. That's unit tests. My changes might break the whole system. That's integration tests. I just to run that once and then I can go back to unit tests while I fix the mess I've made. reply dm03514 9 hours agoprevTest containers is such a game changer for integration testing, they have language specific docker apis that make it trivial to bring up containers and verify that they are fully initialized and ready to accept connections. Pretty much every project I create now has testcontainers for integration testing :) I setup CI so it lints, builds, unit tests then integration tests (using testcontainers) https://github.com/turbolytics/latte/blob/main/.github/workf... Their language bindings provide nice helper functions for common database operations (like generating a connection uri from a container user) https://github.com/turbolytics/latte/blob/main/internal/sour... I use them in $day job use them in side projects use them everywhere :) reply gui77aume 6 hours agoparentIf you are testing a microservices \"ball of mud\", you can (and probably should) setup a testing environment and do your integration tests right there, against real dependencies. The tool seems nice for simple dependencies and local testing but I fail to see it as a game changer. reply root_axis 4 hours agorootparent> and local testing You mention this as an afterthought but that's the critical feature. Giving developers the ability to run integration tests locally is a massive win in a \"ball of mud\" environment. There are other ways to accomplish this locally, but the test-infrastructure-as-test-code approach is a powerful and conceptually elegant abstraction, especially when used as a tool to design testcontainers for your own services that can be imported as packages into dependent services. reply AdrenalinMd 4 hours agorootparentprevI agree with this. At work we use both approaches but at different levels of the test pyramid. To test integration with 1 dependency at class level we can use test containers. But to test the integration of the whole microservice with other microservices + dependencies we use a test environment and some test code. It's a bit like an E2E test for an API. I would argue that the test environment is more useful if I had to choose between the two as it can test the service contract fully, unlike lower type testing which requires a lot of mocking. reply TeeWEE 5 hours agorootparentprevThis is useful too but expensive. Test containers provide a middle ground. For example we have pure unit tests. But also some tests that boot up Postgres. Test the db migration and gives you a db to play with for your specific “unit” test test case. No need for a complete environment with Kafka etc. It provides a cost effective stepping stone to what you describe. What would be nice if test containers could create a complete environment, on the test machine and delete it again. Still a deploy with some smoke tests on a real env are nice. reply AdrenalinMd 2 hours agorootparentIt's not really a middle ground if you're not testing your service in the same conditions as in production environment. If you're not testing integration with Kafka, and the producer, your service is still lacking integration tests. Testing classes in isolation with testcontainer is fine. But I observed that with microservice architecture the line between E2E tests and integration tests are blurred. Microservices can and should be tested from the client perspective. reply TeeWEE 4 minutes agorootparentTrue but if you want to test every merge-request it becomes expensive. We had a customer k8s cluster per feature branch with e2e testing. A middle ground is testcontainers for feature branches, and the trunk branch a full e2e suite deployed to a live cluster... reply circusfly 5 hours agorootparentprevAgreed, this is the best way, testcontainers are over hyped. reply silon42 7 minutes agorootparentYeah, I prefer setting up docker-compose.yml myself, so I can startup services once, and also do manual testing. The only thing I would maybe use testcontainers for is to deploy my own service into docker as part of integration test so I can test a more realistic deployment scenario instead of running it locally outside docker. reply paxys 8 hours agoparentprevFYI Docker already has a RESTful API, and programming container start/stop is trivial to do in any language. I haven't used Testcontainers before, and can kinda see the utility, but IMO it really isn't worth it in the long term to take on a new external dependency for a bit of code that (1) is a critical part of the team's development and release process and (2) can be written in-house in maybe an hour. reply andrewxdiamond 7 hours agorootparentConveniently as of a few days ago, you don’t need to be worried about this anymore. TestContainers is no longer a third-party! https://www.docker.com/blog/docker-whale-comes-atomicjar-mak... reply comprev 1 hour agorootparentIf only Docker used a Sperm Whale as their mascot…. reply jchw 5 hours agorootparentprev> it really isn't worth it in the long term to take on a new external dependency for a bit of code that (1) is a critical part of the team's development and release process and (2) can be written in-house in maybe an hour. This seems to be quite a contradiction. If it's so easy to just write from scratch, then why would it be scary to depend on? Of course, it's not that easy to write from scratch. You could make a proof-of-concept in maybe an hour... Maybe. But they already took the proof of concept to a complete phase. Made it work with Podman. Added tons of integration code to make it easy to use with many common services. Ported it to several different languages. And, built a community around it. If you do this from scratch, you have to go through most of the effort and problems they already did, except if you write your own solution, you have to maintain it right from the git-go, whereas if you choose Testcontainers, you'll only wind up having to maintain it if the project is left for dead and starts to bitrot. The Docker API is pretty stable though, so honestly, this doesn't seem likely to be a huge issue. Testcontainers is exactly the sort of thing open source is great for; it's something where everyone gets to benefit from the wisdom and battle-testing of everyone else. For most of the problems you might run into, there is a pretty decent chance someone already did, so there's a pretty decent chance it's already been fixed. Most people have GitHub and Dockerhub dependencies in their critical dependency path for builds and deployment. Services go down, change their policies, deprecate APIs, and go under, but code continues to work if you replicate the environment it originally worked in. The biggest risk with code dependencies (for non-production code like test code) is usually that it blocks you from updating some other software. The biggest risk with services is that they completely disappear and you are completely blocked until you fully remove the dependency. I think people depending on Testcontainers are fine and doing very well with their risk analysis. reply TheDong 4 hours agorootparent> This seems to be quite a contradiction. If it's so easy to just write from scratch, then why would it be scary to depend on? It's easy to write an implementation specific to your existing project's development environment and workflow correctly. It's hard to write a generic version that works in any environment. It's hard to write a version that lets you build a company and make money. It's scary to depend on this generic version because it's too generic, and it's built by a for-profit company now who wants to upsell you to some \"testcontainer cloud\" crap, which doesn't exactly incentivize them to make the OSS version perfect. For example, we were already using bazel, so writing a version using bazel to create a correct bare rootfs for a dependency + using runc to execute it in tests resulted in something with a roughly 3ms warm startup time that fulfilled all our needs, and cached correctly (since bazel has good caching). A junior engineer, starry-eyed at test-containers, switched some code over to it, and the warm startup time went up by 1000x from 3ms to 3s, as did the flake-rate, and docker's caching is far worse than bazel's so the several minute cold-starts also happened even more often. > Testcontainers is exactly the sort of thing open source is great for; it's something where everyone gets to benefit from the wisdom and battle-testing of everyone else. You get to have a mismatched mess of solutions to everyone's problems, including solution's to problems you don't have. You get code of the quality of the average OSS programmer which, while higher than the average programmer, is still pretty crap. Free Software is great when it's run by a small group of smart opinionated people. As soon as you try to build a company around that OSS and, god forbid, hire some enterprise sales people and product managers, it quickly becomes worse at the actual small developer problem than what even a mediocre developer could hack out in an hour. Depending on testcontainers is fine, but if you know what you're doing, writing something purpose-built is fine too, and probably gives you something much nicer in the end. reply jchw 4 hours agorootparentTo be honest, it doesn't sound like you really had a good use case for Testcontainers anyways. Where it excels the most is in just pulling in some external containers, especially databases, e.g. PostgreSQL and Redis, directly in your test harness. In those cases, it works well. reply TheDong 2 hours agorootparentOur use-case was redis servers, one of your supposedly good use-cases for testcontainers. I didn't mention, but the testcontainer code also preferred to add that network io to the actual test runtime, which made measuring the test's performance harder, and meant we couldn't as safely cache the test's results. The bazel version made it easy to build the test's dependency as part of the test compilation process (as it should be) so the test runtime didn't have to do external network IO. \"Excels\" is also a stretch; we had a few hundred tests launching dedicated redis servers, and with hand-rolled code, that worked fine with zero flakes. With testcontainers, it regularly flaked with some opaque docker network error or sometimes just plain a timeout because apparently launching 100s of containers in parallel is a hard problem for docker or something. I'm sure it works well for some people, but if those people wanted to build out their own version without docker and testcontainers, specific to their development tooling and environment, it would probably work better in most cases I think. reply Too 4 hours agorootparentprevWhen writing something like this for yourself you would only support one database, one programming language, one unit testing framework, much less documentation and none of the edge cases that someone else requires. The effort would not be equal to replicating the whole project. It wouldn’t be the same quality of course. Question is do you need all of it or not. reply jchw 3 hours agorootparentYeah, but that's kind of the thing, you get less battle testing most likely for also less surface area. If you pull in a project like this, it makes it vastly easier when you need more, because if it happens to already have built-in support, you don't need to spend additional engineer time on it. To me it seems straightforwardly a win to start with Testcontainer and move to something else when it proves insufficient. reply pitah1 7 hours agoparentprevI think they make the biggest difference when testing data pipelines (which have historically been difficult to test). You can now easily test out compatibility between different versions of databases, verify data types, embed as part of your build, etc. I believe the next step, once using test containers, would be automating data generation and validation. Then you will have an automated pipeline of integration tests that are independent, fast and reliable. reply afro88 6 hours agorootparentYou can automate data validation with snapshot tests. I do it this way with a data pipeline and have a function that queries the destination DBs and puts them unto json to be written validated with a snapshot reply weq 8 hours agoparentprevCan you explain more in more detail why this is a game changer if i already have an inhouse framework that is similiar in using docker for integration tests? Does it start docker up faster then you could do normally? Is it just the out of the box apis it provides? I dont know why integration testing like this is considered a gamechanger. the testing pyramid is a testing pyramid for a reason and its always considered them important. Sometimes starting with integration tests in your project is right because your dont waste time doing manual point and clicks. Instead you design your system around being able to integration test, this includes when you choose dependancies. You think to yourself \"how easily will that be able to be stood up on its own from a command?\" If the answer is \"not very good\" then you move on. reply sverhagen 8 hours agorootparentIf you have an existing in-house framework for anything, maybe it's not worth switching over. It does help though when a best practice bubbles to the top and makes this in reach for those who don't have an existing in-house framework and who wouldn't know how to get started on one. It also helps for more people to have a shared understanding about a subject like this thanks to a popular implementation. Meanwhile, Testcontainers is done quite well. It's not perfect, but it's sure better than the in-house stuff I built in the past (for the same basic concept). No, it does not start faster than other Docker containers. I do challenge the testing pyramid, though. At the risk of repeating my other comment on a different branch of the discussion: the value of integration tests is high, as the cost of integration tests has decreased, it makes sense to do more integration testing, at the expense of unit testing. The cost has decreased exactly due to Docker and mature application frameworks (like in Java: Spring). (See: Testing Trophy.) reply debosmit 7 hours agorootparentone thing i have seen with testcontainers (been a user for a few years) is the ergonomic SDKs that they have especially in languages like golang, it makes spinning containers up/down, accessing the ports (eg: a mongodb container for some e2e test flow) super trivial - its like a nicety layer on top of vanilla docker (w/ the cost of including their sdk in your test build process) yes, 100% can be done using docker directly or docker rest api (and def doesn't make sense to migrate if you have already made an investment in an in-house framework that doesn't require much upkeep) reply weq 7 hours agorootparentthanks for the responses, i just wanted to cut through the marketing. taking on standardised tools is a win for me, i just wanted to know about real world experience and use-case. Indeed taking on deps is not something i do lightly. > value of test pyramid I mean more from the perspective of covering your bases, you never just want one kind of testing pattern in your project. Each codebase is different and i agree that taking on high value test styles/cases is a project by project challange that should be tailored by many variables. The shape of your testing pyramid may be different to others. If your inheriting a legacy system, maybe its top heavy because the effort/reward ratio just isnt there. In this circumstances i usually take on the approach of \"add more layers when bugs are found\" to hone in on places that could use more or less test coverage. Our inhouse framework is really just a wrapper around certain tools that fill different gaps (think docker/selenium etc) in order for different projects to build suites that are compatible with our ci/cd pipelines that do things like generate environments on demand to run test suites against. So dropping in testcontainers to replace the home-grown docker will be trivial. Keeping test frameworks fresh and compatible with the cloud vendors that agreesively upgrade is a challange just like keeping the API bleed of other programming deps is. Our test suites essentially have a domain language that is consistant. We can upgrade selenium, swap functions for different operations, without having to change any tests. Same goes for unit or integration tests - they are exactly the same in terms of assertions, syntax etc, they may just just have different environment setup logic. CI/CD can inject and overrride logic as it needs. Sometimes its suitable, in some cases, to mock certain external hard deps in integration tests for instance to having all the unit testing tools availible a plus. Or in other cases, we may take a unit test written against mocks, and inject real deps into it for certain CI/CD scenarios. reply simonw 9 hours agoprevNot sure how I hadn't encountered this before, I LOVE this pattern. I find integration tests that exercise actual databases/Elasticsearch/Redis/Varnish etc to be massively more valuable than traditional unit tests. In the past I've gone to pretty deep lengths to do things like spin up a new Elasticsearch index for the duration of a test suite and spin it down again at the end. It looks like Testcontainers does all of that work for me. My testing strategy is to have as much of my application's functionality covered by proper end-to-end integration-style tests as possible - think tests that simulate an incoming HTTP request and then run assertions against the response (and increasingly Playwright-powered browser automation tests for anything with heavy JavaScript). I'll use unit tests sparingly, just for the bits of my code that have very clear input/output pairs that afford unit testing. I only use mocks for things that I don't have any chance of controlling - calls to external APIs for example, where I can't control if the API provider will be flaky or not. reply CobrastanJorji 5 hours agoparentI love integration tests. You know why? Because I can safely refactor all I want! Unit tests are great, but if you significantly refactor how several classes talk to each other, and each of those classes had their own, isolated unit tests that mocked out all of the others, you're suddenly refactoring with no tests. But a black box integration tests? Refactor all your code, replace your databases, do whatever you want, integration test still passes. Unit test speed is a huge win, and they're incredibly useful for quickly testing weird little edge cases that are annoying to write integration tests for, but if I can write an integration test for it, I prefer the integration test. reply rollulus 2 hours agorootparentThanks for saying this out loud. I’m a solo dev and in my project I’m doing exactly this: 90% black box integration tests and 10% unit tests for edge cases I cannot trigger otherwise. It buys me precious time to not adjust tests after refactoring. Yet it made me feel like a heretic: everyone knows the testing pyramid and it comes from Google so I must be very wrong. reply fiznool 2 hours agorootparentYou might be interested in the ‘testing trophy’ as an alternative to the traditional pyramid. https://kentcdodds.com/blog/write-tests reply imiric 1 hour agorootparentThis advice is so misguided that I'm concerned for our industry it's getting so much traction. > You really want to avoid testing implementation details because it doesn't give you very much confidence that your application is working and it slows you down when refactoring. You should very rarely have to change tests when you refactor code. Unit tests don't need to test implementation details. You could just as well make that mistake with integration or E2E tests. Black box testing is a good practice at all layers. What unit tests do is confirm that the smallest pieces of the system work as expected in isolation. Yes, you should also test them in combination with each other, but it serves you no good if you get a green integration test, when it's likely only testing a small fraction of the functionality of the units themselves. This whole \"unit tests slow you down\" mentality is incredibly toxic. You know what genuinely slows me down? A suite with hundreds of integration tests, each taking several seconds to run, and depend on external systems. But hey, testcontainers to the rescue, right? Tests shouldn't be a chore, but an integral part of software development. These days I suppose we can offload some of that work to AI, but even that should be done very carefully to ensure that the code is high quality and actually tests what we need. Test code is as important as application code. It's lazy to think otherwise. reply ric2b 1 hour agorootparentIf by \"smallest pieces of the system\" you mean something like individual classes then you are definitely testing implementation details. Whenever you change a method's parameters in one of those internal classes you'll have unit tests breaking, even though you're just refactoring code. Unit testing at the smallest piece level calcifies the codebase by making refactors much more costly. reply imiric 25 minutes agorootparent> If by \"smallest pieces of the system\" you mean something like individual classes then you are definitely testing implementation details. No, there's nothing definite about that. The \"unit\" itself is a matter of perspective. Tests should be written from the perspective of the API user in case of the smallest units like classes and some integration tests, and from the perspective of the end user in case of E2E tests. \"Implementation details\" refers to any functionality that's not visible to the user, which exists at all levels of testing. Not writing tests that rely on those details means that the test is less brittle, since all it cares about is the external interface. _This_ gives you the freedom to refactor how the unit itself works however you want. But, if you change the _external_ interface, then, yes, you will have to update your tests. If that involves a method signature change, then hopefully you have IDE tools to help you update all calling sites, which includes application code as well. Nowadays with AI assistants, this type of mechanical change is easy to automate. If you avoid testing classes, that means that you're choosing to ignore your API users, which very likely is yourself. That seems like a poor decision to make. reply Aeolun 10 minutes agorootparentprevIf I change something at the lowest level in my well abstracted system, only the unit tests for that component will fail, as the tests that ‘use’ that component mock the dependency. As long as the interface between components doesn’t change, you can refactor as much as you want. reply hughesjj 4 hours agorootparentprevLegit. Probably an unpopular opinion but if I had to chose only one type of test (queue a long discussion with no resolution over defining exact taxonomic boundaries), I'd go with integration over unit. Especially if you're a new contributor to a project. I think it comes down to exercising the flow between... Well, integrations across components. Even better? Take your integration test, put it on a cronjob in your VPN/vpc, use real endpoints and make bespoke auth credentials + namespace, and now you have canaries. Canaries are IMHO God tier for whole system observability. Then take your canary, clean it up, and now you have examples for documentation. Unit tests are for me mostly testing domain+codomain of functions and adherence to business logic, but a good type system along with discipline for actually making schemas/POJOs etc instead of just tossing around maps strings and ints everywhere already accomplishes a lot of that (still absolutely needed though!) reply piokoch 14 minutes agorootparentRight. Unit tests are typically a waste of time unless you have some complicated business logic (say, some insurance rates calculation, etc.). This was advocated long time ago in the (great) book \"Next Generation Java Testing: TestNG and Advanced Concepts\" by Cédric Beust and Hani Suleiman (old people will remember his (in)famous The Bile Blog...). reply Aeolun 8 minutes agorootparentUnit tests are fine for testing any kind of logic. Whether you consider the logic important is a different question. reply imiric 2 hours agorootparentprevI've heard this aversion to unit tests a few times in my career, and I'm unable to make sense of it. Sure, integration tests \"save\" you from writing pesky unit tests, and changing them frequently after every refactor. But how do you quickly locate the reason that integration test failed? There could be hundreds of moving parts involved, and any one of them malfunctioning, or any unexpected interaction between them, could cause it to fail. The error itself would likely not be clear enough, if it's covered by layers of indirection. Unit tests give you that ability. If written correctly, they should be the first to fail (which is a good thing!), and if an integration test fails, it should ideally also be accompanied by at least one unit test failure. This way it immediately pinpoints the root cause. The higher up the stack you test, the harder it is to debug. With E2E tests you're essentially debugging the entire system, which is why we don't exclusively write E2E tests, even though they're very useful. To me the traditional test pyramid is still the best way to think about tests. Tests shouldn't be an afterthought or a chore. Maintaining a comprehensive and effective test suite takes as much hard work as, if not more than, maintaining the application itself, and it should test all layers of the system. But if you do have that, it gives you superpowers to safely and reliably work on any part of the system. reply mk89 1 hour agorootparent> I've heard this aversion to unit tests a few times in my career, and I'm unable to make sense of it. It's very simple: most of the time people are told by management that they MUST achieve a 80-90-95% of code coverage (with unit tests), which leads to a lot of absolutely worthless tests - tests for the sake of it. The irony is that the pieces that really count don't get tested properly, because you unit-test the happy-path and maybe 1 or 2 negative scenarios, and that's it, missing out a bunch of potential regressions. EDIT: This just to say that I don't believe the author of the comment said \"don't write unit tests\" (I hope not, at least!) but, if I can rephrase it, \"well, the integration tests give you a better dopamine effect because they actually help you catch bugs\". Which would be partially true also with properly written unit tests (and they would do so in a fraction of the time you need with integration tests). reply imiric 10 minutes agorootparent> most of the time people are told by management that they MUST achieve a 80-90-95% of code coverage (with unit tests), which leads to a lot of absolutely worthless tests - tests for the sake of it So strict rules from management in a company that likely doesn't understand software development, and lazy developers who decide to ignore this by intentionally writing useless tests, lead to thinking that unit tests and coverage are useless? That doesn't track at all. I'd say that the answer is somewhere in the middle. If the company doesn't understand software development, it's the engineer's job to educate them, or find a better place to work at. It's also the engineer's job to educate lazy developers to care about testing and metrics like code coverage. > if I can rephrase it, \"well, the integration tests give you a better dopamine effect because they actually help you catch bugs\" And unit tests don't? I would argue that unit tests give you much more of that dopamine, since you see the failures and passes much more quickly, and there should be much more of them overall. Not that we should structure our work towards chasing dopamine hits... I'd say that most of the people who advocate for this position haven't worked with a well tested codebase. Sadly, not all of us have the privilege of working with codebases like SQLite's, which go much beyond 100% line/statement coverage[1]. Is all that work in vain? Are they some crazy dogmatic programmers that like wasting their time? I would say: no. They just put in a lot of effort and care in their product, which speaks for itself, and I would think makes working on it much more pleasant. I would also argue that the current state of our industry, and in turn everything that depends on software, where buggy software is the norm would be much better overall if that kind of effort and care would be put in all software projects. [1]: https://www.sqlite.org/testing.html reply hamandcheese 1 hour agorootparentprev> But how do you quickly locate the reason that integration test failed? There could be hundreds of moving parts involved, and any one of them malfunctioning, or any unexpected interaction between them, could cause it to fail. The error itself would likely not be clear enough, if it's covered by layers of indirection. As long as the error is reproducible, never in my career have I had a hard time locating the source of the error. Bisection does wonders (as a general concept, not specifically referring to git bisect). That said, I have encountered plenty of non-reproducible test failures. Moral of the story: make things reproducible, especially tests. Easier said than done. reply ric2b 1 hour agorootparentprevIf the test fails consistently (as it should) it is usually just a question of using a debugger and stepping through some suspect sections of the code to find the issue. Compared to the amount of time saved by not rewriting unit tests every time you refactor stuff, it's a great trade-off. reply cyptus 4 hours agorootparentprevhow do you handle resetting a sql database after every integration test? Testcontainers may help here by spinning up a new instance for every test but that seems very slow reply simonw 3 hours agorootparentIf I'm using Django I let Django's default test harness handle that for me - it runs each test in a transaction and rolls it back at the end of the test, which is pretty fast. https://docs.djangoproject.com/en/5.0/topics/testing/overvie... For my other projects I'm generally using SQLite where starting a new in-memory database is so fast it's effectively free. reply dkdbejwi383 1 hour agorootparentHow does that work when the system under test uses transactions itself? reply flakes 2 hours agorootparentprevI do this a lot for Postgres testing. In my setup, I create a single database for the entire test run. Each test creates its own schema in that database and applies the latest table definitions. With this setup, I only eat the container creation once, while allowing every test to operate in isolation from one another, be parallelized, and test against a real database. I do a similar trick for S3 containers by applying a unique guid prefix to the buckets in each test. reply theonething 5 hours agoparentprevI once failed a take home assignment because of this. It was writing a couple of api endpoints and for testing, I focused on integration over unit. I even explained my reasoning in the writeup. There was no indication that the company preferred unit tests, but the feedback was \"didn't have enough unit tests\". What a dumb company. reply briHass 6 hours agoparentprevAnother technique I've found very useful is generative integration tests (kind of like fuzzing), especially for idempotent API endpoints (GETs). For example, assuming you have a test database with realistic data (or scrubbed production data), write tests that are based on generalizable business rules, e.g: the total line of an 'invoice' GET response should be the sum of all the 'sections' endpoint responses tied to that invoice id. Then, just have a process that runs before the tests create a bunch of test cases (invoice IDs to try), randomly selected from all the IDs in the database. Limit the number of cases to something reasonable for total test duration. As one would expect, overly tight assertions can often lead to many false positives, but really tough edge cases hidden in diverse/unexpected data (null refs) can be found that usually escape the artificial or 'happy path' pre-selected cases. reply mzi 3 hours agorootparentRunning unit tests as integration tests will explode in your face. In any decent complex code base testing time will go through the roof and you will have a hard time getting the genie back in the bottle. Testing that you actually run \"sum()\" is a unit test. reply DanHulton 7 hours agoparentprevThis is exactly the strategy I have discovered to bring the most value as well. And honestly, something that simplifies the setup of those containers is pretty great. reply trevor-e 7 hours agoparentprevDo you find this results in less overall test code to maintain since you likely have fewer but higher quality/signal tests? reply stingraycharles 4 hours agorootparentYes, you just focus on a few high level behaviors that you want to validate, instead of the units. It’s more difficult to pull these tests off, as there are more chances for them to become flaky tests, but if they work they provide much more value. I’d prefer a dozen well written integration tests over a hundred unit tests. Having said that, both solve different problems, ideally you have both. But when time-constrained, I always focus on integration tests with actual services underneath. reply simonw 7 hours agorootparentprevYeah - I find that sticking to tests like this means I don't have hundreds of tiny unit tests that rely on mocks, and it's still very supportive of refactoring - I can make some pretty big changes and be confident that I've not broken anything because a given request continues to return the expected response. reply gorjusborg 6 hours agorootparentThe choice isn't unit tests vs . end-to-end tests, its between testing things you don't really care about and those you do. You care about real use cases and verifying design constraints are met. You don't care about internal implementation details. The nuance is that there are often things one cares about at multiple levels. reply domano 37 minutes agoprevI dont understand how this is better than a docker-compose.yml with your dependencies, which plays nicer with all other tooling. Especially if there are complex dependencies between required containers it seems to be pretty weak in comparison. But i also only used it like 5 years ago, so maybe things are significantly better now. reply callamdelaney 16 minutes agoparentBecause you may want to spin up a new postgres database to test a specific scenario in an automated way. Testcontainers allows you to do that from code, for example you could write a pytest fixture to provide a fresh database for each test. reply silon42 5 minutes agorootparentIf you need that, sure, but often this will be too expensive (heat my laptop too much). reply et1337 6 hours agoprevI looked at testcontainers and ended up rolling my own version. One issue I had is that Docker is a very leaky abstraction. I needed to write one test and have it run in all these scenarios: - on a Mac - on a Linux VM - in a Docker container on a Linux VM, with a Docker socket mounted The networking for each of these is completely different. I had to make some opinionated choices to get code that could run in all cases. And running inside Docker prevented the test from being able to mount arbitrary files into the test containers, which turns out to be a requirement often. I ended up writing code to build a new image for each container, using ADD to inject files. I also wanted all the tests to run in parallel and spit out readable logs from every container (properly associated with the correct test). Not sure if any of these things have changed in testcontainers since I last looked, but these are the things I ran into. It took maybe a month of off and on tweaking, contrary to some people here claiming it can be done in an hour. As always, the devil is in the details. edit: I did end up stealing ryuk. That thing can’t really be improved upon. reply redact207 10 hours agoprevI didn't quite understand why this was made. We create our local test environments using docker-compose, and so I read: > Creating reliable and fully-initialized service dependencies using raw Docker commands or using Docker Compose requires good knowledge of Docker internals and how to best run specific technologies in a container This sounds like aabstraction over docker-compose, which lets you define your docker environment without learning the syntax of docker-compose itself. But then > port conflicts, containers not being fully initialized or ready for interactions when the tests start, etc. means you'd still need a good understanding of docker networking, dependencies, healthchecks to know if your test environment is ready to be used. Am I missing something? Is this basically change what's starting your docker test containers? reply c0balt 10 hours agoparentGoing to the sections for language interactions shows a lot more stuff, e.g., the first full go example: https://testcontainers.com/guides/getting-started-with-testc... Shows how you can embed the declaration of db for testing in a unit test: > pgContainer, err := postgres.RunContainer(ctx, > testcontainers.WithImage(\"postgres:15.3-alpine\"), > postgres.WithInitScripts(filepath.Join(\"..\", \"testdata\", \"init-db.sql\")), > postgres.WithDatabase(\"test-db\"), > postgres.WithUsername(\"postgres\"), > postgres.WithPassword(\"postgres\"), > testcontainers.WithWaitStrategy( > wait.ForLog(\"database system is ready to accept connections\"). This does look quite neat for setting up test specific database instances instead of spawning one outside of the test context with docker(compose). It should also make it possible to run tests that require their own instance in parallel. reply simonw 9 hours agorootparentOn Hacker News you need to indent code examples with four spaces - like this: pgContainer, err := postgres.RunContainer( ctx, testcontainers.WithImage(\"postgres:15.3-alpine\" ), postgres.WithInitScripts(filepath.Join(\"..\", \"testdata\", \"init-db.sql\")), postgres.WithDatabase(\"test-db\"), postgres.WithUsername(\"postgres\"), postgres.WithPassword(\"postgres\"), testcontainers.WithWaitStrategy( wait.ForLog(\"database system is ready to accept connections\"). reply altairprime 8 hours agorootparentAnd, to quote non-code text, you have to do it manually; there is no formatting operator and the code-indent method won’t work (unreadable at many browser widths). I tend to do it like so: > *Paragraph one.* > *Paragraph two. Etc.* Which produces the desired effect: > Paragraph ‘one’. > Paragraph two. (To use a * in a paragraph that’s italic-wrapped, backslash it.) reply mleo 10 hours agoparentprevIt’s not coming across in your comment, but Testcontainers can work with unit tests to start a container, run the unit tests and shutdown. For example, to verify database operations against the actual database, the unit test can start an instance of Postgres run tests and then shut it down. If running tests in parallel, each test can start its own container and shutdown at the end. reply DanHulton 5 hours agorootparentWouldn't that just massively, _massively_ slow down your tests, if each test was spinning up its own Postgres container? I ask because I really like this and would love to use it, but I'm concerned that that would add just an insane amount of overhead to the point where the convenience isn't worth the immense amount of extra time it would take. reply orphea 1 hour agorootparentA better approach is to spin up one container and a _template_ database before the tests. Apply migrations to that database. Then, each test creates its own database from the template, runs, and drops the database. Tests can be run in parallel, and they are fast because the database is prepared just once, tests simply make a copy. We're doing this in my company, I'm happy how it works. reply scns 3 minutes agorootparentYou can use one container for all tests. https://java.testcontainers.org/test_framework_integration/m... reply stonecolddevin 10 hours agoparentprevTestcontainers is great. It's got seamless junit integration and really Just Works. I've never once had to even think about any of the docker aspects of it. There's really not much to it. reply marginalia_nu 10 hours agoparentprevTestcontainers are for testing individual components, apart from the application. I built a new service registry recently, its unit tests spins up a zookeeper instance for the duration of the test, and then kills it. Also very nice with databases. Spin up a clean db, run migrations, then test db code with zero worries about accidentally leaving stuff in a table that poisons other tests. I guess the killer feature is how well it works. reply dns_snek 10 hours agorootparent> Also very nice with databases. Spin up a clean db, run migrations, then test db code with zero worries about accidentally leaving stuff in a table that poisons other tests. Are you spinning up a new instance between every test case? Because that sounds painfully slow. I would just define a function which DELETEs all the data and call it between every test. reply NomDePlum 9 hours agorootparentIt supports both patterns (and variations in between). So you get to pick between isolation at a test level or if you want less overhead, rolling back the commit or other ways to cleanup. Can only speak for the Golang version of the lib, but spinning up new instances was surprisingly quick. reply marginalia_nu 9 hours agorootparentprevI usually do one per suite with a reset method run before each test. It's a decent compromise between performance and isolation, since weird interactions can only originate from the same suite, rather than anywhere in any test. Also permits parallel execution of db test suites. reply codeonline 7 hours agoparentprevThis looks to be like just language specific bindings over the docker compose syntax. You're right that docker compose handles all of the situations they describe. reply mickael-kerjean 7 hours agorootparentThe major issue I had with docker compose in my CI environment is flaky tests when a port is already used by another job I don't control. With testcontainers, I haven't seen any false positive as I can use whatever port is available and not a hardcoded one hoping it won't conflict with what other people are doing. reply Ajedi32 5 hours agorootparentUnless I'm mistaken, this is only a problem if you're forwarding ports from the Docker containers to the host machine, which isn't necessary if the test itself is running from inside a Docker container on the same bridge network as your dependencies. (Which compose will set up for you by default.) reply ath3nd 10 hours agoparentprevAs a user of testcontainers I can tell you they are very powerful yet simple. Indeed all they do is provide an abstraction for your language, but this is soo useful for unit/integration tests. At my work we have many microservices in both Java and python, all of which use testcontainers to set up the local env or integration tests. The integration with localstack and the ability to programmatically set it up without fighting with compose files, is somewhat I find very useful. reply cosmosgenius 9 hours agoparentprevI just started using them specifically to test docker container implementation (Correctness of Dockerfile, entrypoint etc.) reply ants_everywhere 9 hours agoprev> No more need for mocks or complicated environment configurations. Define your test dependencies as code, then simply run your tests and containers will be created and then deleted. Wait what? They think you don't need unit tests because you can run integration tests with containers? It's trivial to set up a docker container with one of your dependencies, but starting containers is painful and slow. reply sverhagen 8 hours agoparent1) At least in the Java world, the term \"unit testing\" is often confused by \"things you do in JUnit\", which runs both \"pure\" unit tests and project-level integration tests, i.e. spinning up an application context (like Spring) and testing against real REST endpoints etc. 2) While unit tests are cheaper and quicker than (project-level) integration tests, they also in many cases don't provide results as good a result and level of confidence, because a lot of run-time aspects (serialization, HTTP responses, database responses, etc.) are not as straightforward to mock. There's been some noise about The Testing Trophy, instead of the Testing Pyramid where, in short, there are still unit tests where it makes sense, but a lot of testing has moved to the (project-level) integration tests. These are slower, but only by so much that the trade-off is often worth it. Whether it's worth it, depends heavily on what you're testing. If it's a CRUD API: I use integration tests. If it's something algorithmic, or string manipulation, etc.: I use unit tests. When I saw the Testing Trophy presented, it came with the asterisk that (project-level) integration testing has gotten easier and cheaper over time, thus allowing a shift in trade-off. Testcontainers is one of the primary reasons why this shift has happened. (And... I respect that it's not for everyone.) Some references: https://kentcdodds.com/blog/the-testing-trophy-and-testing-c... https://www.youtube.com/watch?v=t-HmXomntCA reply ants_everywhere 8 hours agorootparentYeah, certainly I see the value of those kinds of tests. And clearly as you say the simpler tests don't provide as realistic a simulation as the more expensive tests. But on the test philosophy angle, my take on what's happening is just that developers traditionally look for any reason to skip tests. I've seen this in a few different forms. - right now containers make it trivial to run all of your dependencies. That's much easier than creating a mock or a fake, so we do that and don't bother creating a mock/fake. - compiler folks have created great static analysis tools. That's easier than writing a bunch of tests, so we'll just assume static analysis will catch our bugs for us. - 's types system does a bunch of work type checking, so I don't need tests. Or maybe I just need randomly generated property tests. - no tests can sufficiently emulate our production environment, so tests are noise and we'll work out issues in dev and prod. What I've noticed, though, is that looking across a wide number of software projects is there's a clear difference in quality between projects that have a strong testing discipline and those that convince themselves they don't need tests because of . Sure it's possible that tests don't cause the quality difference (maybe there's a third factor for example that causes both). And of course if you have limited resources you have to make a decision about which quality assurance steps to cut. But personally I respect a project more if they just say they don't have the bandwidth to test properly so they're just skipping to the integration stage (or whatever) rather than convince themselves that those tests weren't important any way. Because I've seen so many projects that would have been much better with even a small number of unit tests where they only had integration tests. reply sverhagen 4 hours agorootparentI think testing is very important. But it's very hard to test everything. (It is not hard to get 100% test coverage by some metric, but that does not mean that all scenarios or even the most useful ones are covered.) So it's an economics game: how can you get the most value for the least amount of money? Or if you want me to rephrase that in a more-positive way: how can you get the most value out of the time that you have available? And I contend that a shift \"up\" in the pyramid (at which time it looses that shape, hence the \"testing trophy\") is where the current sweet spot lies. You have to use the tools that you have. reply lmm 6 hours agorootparentprevSounds like some kind of protestant work ethic mentality: testing should be hard work, the harder writing your tests was the better your soul and the better your system. I've seen plenty of projects that made oodles of mocks and fakes and unit tests and just sucked, outright didn't work at all in a way that would've been obvious if they'd done testcontainers-based integration tests or even just manual testing in prod. I would absolutely trust a project that was written in Haskell and had no tests, or only integration tests, ahead of one that had lots of unit tests. Indeed if anything I'd say the number of mocks/fakes is negatively correlated with the actual project quality. reply sverhagen 4 hours agorootparentJust to add, there's also a (Chicago) school of thought that pushes back against mocks and fakes, so even if you're religiously (to stick with the metaphore) writing unit tests, you might still not invest in mocks and fakes. reply Mavvie 3 hours agorootparentCan you (or someone else) explain what the alternatives are? How can I write unit tests without mocks or fakes? reply hyperadvanced 2 hours agorootparentThey might mean that rather than using a mock, use a real typed object/instance of a real thing and inject it into the unit that you’re testing. Admittedly, that might meet the definition of a fake/mock once you get down to the level of testing something that needs db access. Another way of interpreting that is that you can use in memory versions of your deps to mirror the interface of your dependency without needing to repeatedly, and possibly haphazardly mock certain functions of your dependency. reply zer00eyz 6 hours agoparentprevI have been doing E2E testing exclusively for close to a decade on several apps and it works great. Note, not integration, E2E. I can go from bare vm to fully tested system in under 15 minutes. I can re run that test in 1-5 (depending on project) ... Im creating 100's of records in that time, and fuzzing a lot of data entry. I could get it to go \"even faster\" if I went in and removed some of the stepwise testing... A->B->C->D could be broken out to a->b, a->c, a->d. Because my tests are external, they would be durable across a system re-write (if I need to change language, platform etc). They can also be re-used/tweeked to test system perf under load (something unit tests could never do). reply tomnipotent 8 hours agoparentprevNo mocks doesn't mean no tests. It means running tests against the full code path which includes requests to running instances of the services you might otherwise mock. For many apps and use cases, the overhead in managing container state is worth it. reply ants_everywhere 8 hours agorootparent> It means running tests against the full code path which includes requests to running instances of the services you might otherwise mock. Yeah, those are called end to end tests and you run them after integration tests which you run after unit tests. It sounds to me like they're saying just skip to the end to end tests. > For many apps and use cases, the overhead in managing container state is worth it. Yeah, and typically you'd run them after you run unit and integration tests. If I have 10 libraries to test that have database access, I have to run 10 database containers simultaneously every few minutes as part of the development process? That's overkill. reply lmm 6 hours agorootparent> Yeah, and typically you'd run them after you run unit and integration tests. If I have 10 libraries to test that have database access, I have to run 10 database containers simultaneously every few minutes as part of the development process? That's overkill. If it's actually causing you problems, then by all means replace some of them with more lightweight tests, at the cost of some test environment faithfulness. But don't optimise prematurely. reply nsteel 56 minutes agoprev> Each test gets a fresh, clean instance of the browser, without having to worry about variations in plugins or required updates. Except where everyone is saying that's too slow and instead they have a long-lived instance which they manually teardown each time. That's even what the examples do (some, at least, I didn't check them all). If you've already bought into the container world then why not embrace a few more. For everyone else, not sure there's much point in extra complexity (they call it simplicity) or bloat. reply omeid2 42 minutes agoprevAbout 7 years ago I wrote conex, which is basically testcontainers for Go, with first class integration with the Go's official testing framework: https://github.com/omeid/conex reply jake_morrison 5 hours agoprevYou can do something similar with docker compose, driving the system from the outside. Create dockerized versions of dependencies like the database, build and run tests, and then run tests against the production app container. It's particularly useful for testing a set of microservices. See https://github.com/cogini/phoenix_container_example for a full example. This blog post describes it in detail: https://www.cogini.com/blog/breaking-up-the-monolith-buildin... reply m00x 4 hours agoparentWe use docker environments like this for tests, but it does have its issues. You often need to add custom behavior like waiting for the app to load and start serving, healthchecks, etc. Having it all in code is pretty useful, and it's self-contained within the code itself vs having to set up the environment in different places (CI, Github actions, local dev, etc). The negative is that code isn't portable to prod, it doesn't test your environment as well (important for staging), and you're missing out on sharing some environment settings. I feel like it definitely has its place in the stack and in certain companies. reply nonethewiser 8 hours agoprevIts great but I find it harder to debug. And I have to say, I usually dont need it. Typically i just have some command which spins everything up from docker-compose files. I prefer this over putting configuration in code like you often do with test containers. You can also load from docker compose files but at that point the test container API isn’t really doing much. Its pretty much required when you want to setup/teardown in between tests though. This just usually isnt the case for me. reply mellutussa 23 minutes agoparent> I usually dont need it But I need it to catch the bugs you commit to CI so you can fix them right away instead of letting me catch them and report them and wait wreck my productivity. (this is of course not directed at you personally, feel free to replace you/I/me with whatever names you can imagine!) reply avensec 5 hours agoprevReading through the comments, I'm quite shocked to see how many deterrent conversations are happening without any understanding of the underlying tech stacks being tested. Testcontainers can be fantastic, especially when you are facing test environment overhead challenges, assuming you have the appropriate architectures / service boundaries to support it. I believe there is more code out there in existence with architectures that make using Testcontainers more challenging than it is worth. reply senorrib 9 hours agoprevPulling up infra to run unit tests is an anti-pattern. This is a great tool for integration tests, though. reply maxdaten 9 hours agoparenthonest question: how are you writing integration tests? We are writing these as separate test suite often with the same test style. And in this scenario testcontainers are very valuable. reply codeonline 7 hours agorootparentWhy not use docker compose, bring up your infra in one container, your application in a second and your tests access it the application from a third. reply imp0cat 4 hours agorootparentBecause you don't have to muck around with docker-compose. I guess some people might find that more attractive. reply OJFord 1 minute agorootparentMeanwhile docker compose selling point: 'because you don't have to muck around with testcontainers; I guess some people might find that more attractive'. marginalia_nu 9 hours agoparentprevWhat if you are unit testing something that is dependent on infra? reply occz 3 hours agorootparentArguably you're no longer testing a unit if the unit involves an integration with an external component, making it an integration test per definition. Integration tests are fine, but they test something else - that your component integrates as intended with , while a unit test moreso tests that your unit behaves in accordance with its specification. reply politelemon 3 hours agorootparentprevIf you aren't mocking away the infra, that's an integration test. reply paxys 8 hours agorootparentprevYou unit test your own code, not its underlying dependencies. If the dependencies cannot be easily mocked then the code is in need of a refactor. reply metaltyphoon 7 hours agorootparentThis makes no sense tho. Simple example, your code needs to reach into Cosmos / DynamoDB, why mock this service when u can get so much wrong by assuming how things work? reply paxys 7 hours agorootparentMocking doesn't mean you have to reimplement the fully featured service. In the simplest form your internal library which calls out to Cosmos is mocked, the mock records the request parameters and returns ok, and the test verifies that the expected data was passed in the call. reply devthane 9 hours agorootparentprevTypically you mock them in unit tests. reply nomel 9 hours agorootparentI've rarely found this to be worth it, for the effort required for a proper mock, in a complex system. I've seen most people mock in ways that are so superficial that it's basically a no-op. reply CuriouslyC 9 hours agorootparentMocks are a contentious topic as you've probably guessed. In my opinion they're a sign of coupled code, you should be able to hit very high coverage without a single mock, but if you're a dev in an org that tracks code coverage you'll probably end up writing a fair number of them since the odds are high you'll be consuming coupled code. reply jerrygenser 9 hours agorootparentIf you have a dependency like a third party API (or even internal code), and you write an API client, then depend on that client, would it be considered couple code? In such cases, if I am using dependency injection and creating a (stub?) versions of that client which returns a hardcoded or configured output, would that be considered a mock? OR would this be OK and not \"coupled\"? reply aleksiy123 8 hours agorootparentI think mocking with DI makes perfect sense. Most people will say something like for unit tests you should test your functions by passing the state as parameters to test. I'm going to call this \"outside in\" loose coupling. Mocking is for the inverse. When you want to test a unit of code that is calling some other outside unit code. Its really not any different just \"inside out\". So imo with DI you gain loose coupling through dependency inversion. But because of dependency inversion you need to mock instead of passing state as params. So I think if you are injecting a mocked stub this is still loose coupling because you are testing against its interface. You're still passing state through your test but its coming from inside instead of outside, hence the mock. Another way I have thought about this is: framework (framework calls you) vs library (you call library). Frameworks naturally lend themselves to a more mock way of testing. Library lends itself to a more traditional way of testing. Testing something that accepts a callback is also essentially a mock. I hope that thought made sense. reply marginalia_nu 9 hours agorootparentprevSeems like such a test would be strictly less useful than a test that runs against the real dependeny. reply vilunov 9 hours agorootparentThen don't do it in unit tests and write an integration test. reply joshuamorton 9 hours agorootparentprevBut vastly faster. A good rule of thumb for a unit test is that you should be able to run it a few thousand times in a relatively brief period (think: minutes or less) and it shouldn't ever fail/flake. If a unit test (suite) takes more than a single digit number of seconds to run, it isn't a unit test. Integration tests are good to have, but unit tests should be really cheap and fundamentally a tool for iterative and interactive development. I should be able to run some of my unit tests on every save, and have them keep pace with my linter. reply marginalia_nu 9 hours agorootparentTestcontainers don't typically add more than a few seconds to a suite though. They are very fast. reply badoongi 5 hours agoprevI see testcontainers being used in tests making the test code style feel more like typical unit tests with fake implementations for system components. Which is misleading as these are more on the integration testing side typically. In essence this is another DSL (per language) for managing containers locally. And this DSL comes in addition to whatever system is actually used for managing containers in production for the project. reply simonw 9 hours agoprevI was intrigued to see that they have PyPI packages for a ton of different things - like https://pypi.org/project/testcontainers-postgres That wheel file is only 2.9KB, so I grabbed a copy to see how it works. I've put the contents in a Gist here: https://gist.github.com/simonw/c53f80a525d573533a730f5f28858... It's pretty neat - it depends on testcontainers-core, sqlalchemy and psycopg2-binary and then defines a PostgresContainer class which fires up a \"postgres:latest\" container and provides a helper function for getting the right connection URL. reply gv83 8 hours agoparentThis is also its downfall as my organization uses asyncpg and compatibility with it is still absent iirc :( reply iamkoch 2 hours agoprevIf you build inside docker, running tests that use docker is a pain. Go has a lot of in-memory versions of things for tests, which run so much quicker than leaning on docker. Similarly, I found C# has in-memory versions of deps you can lean on. I really feel that test containers, although solving a problem, often introduces others for no great benefit reply Claudiusseibt 55 minutes agoprevDuke as the logo for java? reply paxys 8 hours agoprevI read through the docs and am still confused about what this actually does beyond running a single docker run command in the background and returning control to your code when the container is up. reply alifaziz 9 hours agoprevUnit test suppose to be fast. Especially during coding. I wonder how this is necessary & not affecting the test feedback speed reply alemanek 9 hours agoparentThis is for integration tests. reply thomasfromcdnjs 8 hours agorootparentHomepage hero says \"Unit tests with real dependencies\" reply marginalia_nu 9 hours agoparentprevTestcontainers are surprisingly fast. Like seconds of runtime for a suite. reply nslindtner 6 hours agoprevWow ... the syntax reminds me so much of aspire (microsoft new \"composer\"-syntax). Makes a lot of sense. Why not keep this information in code .. often the developers are ending up doing those task anyway. (not recommended .. but seen it so many times) Link: Microsoft aspire (https://learn.microsoft.com/en-us/dotnet/aspire/get-started/...) reply pylua 7 hours agoprevI found test containers to be slow to startup last year. It wasn’t worth the effort considering how long it took to run compared to traditional spring IT h2 hibernate. reply febed 5 hours agoprevI tried to use Testcontainers just last week but ended up using simple docker commands instead. I didn’t find an easy way to connect an already running set of containers started via docker compose. Was straightforward to do with a set of scripts that just call docker exec. reply deathanatos 7 hours agoprev> Unit tests with real dependencies That's an integration test. These are integration tests. You're literally testing multiple units (e.g., Redis, and the thing using Redis) to see if they're integrating. Why do we even have words. These are valuable in their own right. They're just complicated & often incredibly slow compared to a unit test. Which is why I prefer mocks, too: they're speedy. You just have to get the mock right … and that can be tricky, particularly since some APIs are just woefully underdocumented, or the documentation is just full of lies. But the mocks I've written in the past steadily improve over time. Learn to stop worrying, and love each for what they are. (Our CI system actually used to pretty much directly support this pattern. Then we moved to Github Actions. GHA has \"service containers\", but unfortunately the feature is too basic to address real-world use cases: it assumes a container image can just … boot! … and only talk to the code via the network. Real world use cases often require serialized steps between the test & the dependencies, e.g., to create or init database dirs, set up certs, etc.) reply shykes 25 minutes agoparent> GHA has \"service containers\", but unfortunately the feature is too basic to address real-world use cases: it assumes a container image can just … boot! … and only talk to the code via the network. Real world use cases often require serialized steps between the test & the dependencies, e.g., to create or init database dirs, set up certs, etc.) My biased recommendation is to write a custom Dagger function, and run it in your GHA workflow. https://dagger.io If you find me on the Dagger discord, I will gladly write a code snippet summarizing what I have in mind, based on what you explained of your CI stack. We use GHA ourselves and use this pattern to great effect. Disclaimer: I work there :) reply leonardXu 5 hours agoprevMy team maintain a lot of flink connectors, We've changed external test resources to testcontainer as much as possible, it makes things simple and saves money as well. reply joeevans1000 4 hours agoprevForgive the question... but... why can't 'test' containers be 'prod' containers? reply jamesdepp 4 hours agoparentSome tests might have side effects. Probably not a great idea to test the function “bill customer” on a prod deployment. That’s why containers for testing is great—it’s easy to spin up an environment that can be messed around with without consequences (even if things go wrong or your tests have side effects). reply asciii 5 hours agoprevNever heard of this, also the label in footer for careers said \"We're hiring\" but then lists no open positions :/ reply mrAssHat 9 hours agoprevTestcontainers aren't even compatible with kubernetes, that's a tool from the past. reply the_jeremy 9 hours agoparentWe use [kubedock](https://github.com/joyrex2001/kubedock) to run testcontainers in kubernetes clusters. As long as you're only pulling the images, not building or loading them (explicitly not supported by kubedock), it works pretty well. reply marginalia_nu 8 hours agoparentprevWhy'd you run them in kubernetes? Seems like extreme overkill for launching a short lived container for an integration test. What could kubernetes possibly add to that? reply mrAssHat 8 hours agorootparentBecause we are a big company and would like to utilize resources better. We also want homogeneity in tech when possible (we already heavily use kubernetes, we don't want to keep docker hosts anymore). Teams of testers need to be accounted in terms of resource quotas and RBAC. What exactly do you see as an overkill in wanting to run short-lived containers in kubernetes rather than in docker (if we already have kubernetes and \"cook\" it ourselves)? reply politelemon 3 hours agorootparentThat reasoning seems more like one from policy/cargo cult rather than reasoning specific to your org. For something short lived and meant to be isolated I wouldn't want to subject them to even more infrastructural dependencies outside their control. reply dboreham 8 hours agoparentprevROAC \"runs on any computer\", which k8s does not. reply bloopernova 8 hours agoprevSomewhat related: anyone here using AWS Neptune graphql database? How do you develop locally against Neptune? Apart from Localstack, is there a way to mock Neptune for local testing and development? reply dboreham 8 hours agoparentYou might take a look at Tinkerpop: https://tinkerpop.apache.org/ reply paulv 7 hours agoprevDoes this work with podman or is it docker only? reply zer00eyz 6 hours agoparentIf your running podman you should pull your production deployment configs down and tweak those. You will get a much more complete env that way (routing, network, scale, load balance) https://www.redhat.com/sysadmin/kubernetes-workloads-podman-... << as a for instance ;) reply ozarker 5 hours agoparentprevI’ve used it with podman before, worked fine reply circusfly 5 hours agoprevNo thanks, I will continue to roll my own to control it full, at home and at work. reply jillesvangurp 3 hours agoprevI never really liked testcontainers. Too complicated. And I don't want to have my tests make too many assumptions about what level of control there is over their environment. IMHO it's just the wrong place to be messing with docker. I don't like layering abstractions on top of abstractions that were fine to begin with. Docker-compose is pretty much perfect for the job. An added complexity is that the before/after semantics of the test suite in things like JUnit are a bit handwavy and hard to control. Unlike testng, there's no @BeforeSuite (which is really what you want). The @BeforeAll that junit has is actually too late in the process to be messing around with docker. And more importantly, if I'm developing, I don't want my docker containers to be wasting time restarting in between tests. That's 20-30 seconds I don't want to add on top of the already lengthy runtime of compiling/building, firing up Spring and letting it do it's thing before my test runs in about 1-2 seconds. All this is trivially solved by doing docker stuff at the right time: before your test process starts. So, I do that using good old docker compose and a simple gradle plugin that calls it before our tests run and then again to shut it down right after. If it's already running (it simply probes the port) it skips the startup and shut down sequence and just leaves it running. It's not perfect but it's very simple. I have docker-compose up most of my working day. Sometimes for days on end. My tests don't have to wait for it to come up because it's already up. On CI (github actions), gradle starts docker compose, waits for it to come up, runs the tests, and then shuts it down. This has another big advantage that the process of running a standalone development server for manual testing, running our integration tests, and running our production server are very similar. Exactly the same actually; the only difference configuration and some light bootstrapping logic (schema creation). Configuration basically involves telling our server the hosts and ports of all the stuff it needs to run. Which in our case is postgres, redis, and elasticsearch. Editing the setup is easy; just edit the docker compose and modify some properties. Works with jvm based stuff and it's equally easy to replicate with other stuff. There are a few more tricks I use to keep things fast. I have ~300 integration tests that use db, redis, and elasticsearch. They run concurrently in under 1 minute on my mac. I cannot emphesize how important fast integration tests are as a key enabler for developer productivity. Enabling this sort of thing requires some planning but it pays off hugely. I wrote up a detailed article on how to do this some years ago. https://www.jillesvangurp.com/blog/2016-05-25-functional-tes... That's still what I do a few projects and companies later. reply sigmonsays 8 hours agoprevbeen doing this for years, I would not say this gets rid of testing though. Running integration tests are significantly more complicated to write and take longer to run. There is also race conditions present that you need to account for programmatically.. Such as waiting for a db to come up and schema to be applied. Or waiting for a specific event to occur in the daemon. That being said, this looks like a decent start. One thing that seems to be missing is the ability to tail logs and assert specific marks in the logs. Often you need to do an operation and wait until you see an event. reply m3kw9 8 hours agoprev [–] Not everything can be placed in a docker which seem as a requirement. reply PaoloBarbolini 7 hours agoparent [–] Could you provide an example? reply gui77aume 5 hours agorootparent [–] Legacy systems I guess, maybe cloud specific services reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Testcontainers offers lightweight instances of databases, message brokers, and more in Docker containers for unit testing with real dependencies, removing the need for mocks or complex setups.",
      "It supports various languages and testing frameworks like Java, Go, .NET, Node.js, Python, Rust, Haskell, Ruby, Clojure, and Elixir, catering to different developers and projects.",
      "Companies like Spotify and Capital One have leveraged Testcontainers; the community includes Community Champions dedicated to enhancing the framework."
    ],
    "commentSummary": [
      "Testcontainers is a tool for integration testing in software development, simplifying container setup and verification for some users, while others find it complex and limiting.",
      "There is a debate on Testcontainers' effectiveness in running embedded Postgres instances within tests and integrating with various project workflows.",
      "The importance of choosing the right testing approach, balancing unit and integration testing based on project needs, maintaining legacy systems, ensuring reproducibility, and writing unit tests are key discussions highlighting the significance of testing for ensuring software quality."
    ],
    "points": 410,
    "commentCount": 167,
    "retryCount": 0,
    "time": 1709075757
  },
  {
    "id": 39525243,
    "title": "F-35C Tailhook Testing Challenges and Redesign",
    "originLink": "https://the-engi-nerd.github.io/posts/welcome/",
    "originBody": "Welcome to the blog. As a way to kick things off, here’s a single-page version of my thread on the F-35C tailhook. The primary source for material here, aside from my own experiences, is “F-35C Carrier Suitability Testing” by Tony “Brick” Wilson, who gives us one of the greatest flexes in an AIAA paper I’ve ever seen. The F-35C is the variant of the F-35 Joint Strike Fighter intended for use on CATOBAR (Catapult Assisted TakeOff, Barrier Assisted Recovery) aircraft carriers operated by the United States Navy. Aircraft are launched via steam or electromagnetic catapults, and on landing, the aircraft uses a tailhook to engage an arresting wire. The F-35C hook is stowed in a bay that’s covered by clamshell doors during flight. The hook is electronically controlled and moved by hydraulics. And originally, it didn’t work. We began serious carrier suitability testing with F-35C at Lakehurst NAS in the summer of 2011. We would hold our briefings in the same hangar that the Hindenburg was trying to reach when it crashed. This is a level of irony that took zoomers another ten years to reach. After things like Jet Blast Deflector compatibility testing, we get down to testing the hook. Brick tells us, in a masterful understatement: I was at Lakehurst for most of this testing and I never saw the hook engage the wire. It was interesting to see it play out this way. I heard it predicted first, by, of all people, one of our instrumentation technicians on November 6, 2010 That was the day CF-01 arrived at Pax. We went to look at the jet. I remember standing with this tech, looking at the hook. “Boss,” he says to me, “This fucker ain’t gonna work. Look at this thing. It’s short, it’s too close to the wheels, and look at this dumbass hook shoe they got on it. If the wire don’t hit it exactly right, it’s just gonna go under the hook and you’ll bolter.” The hook point is only a little over 7 feet from the main landing gear axle center. The amount of space in the airframe available is extremely tight, so this is what the designers had to work with. Here’s pretty much what we were looking at in this conversation. Why was it like this? Because the engineers at Northrop Grumman engineered to a computer model that can simulate how an arresting wire acts when used for arrestment, and the model was wrong. I heard years later in the course of my job verifying and validating other F-35 simulations that the wire dynamics model supplied by the Navy had not been properly V&V’d. I don’t know this for sure. However it happened, the model led to a design that didn’t work. To understand how it didn’t work, back to Brick’s article. When an aircraft performing an arrestment lands, its main and/or nose tires hit the wire first. This starts a wave in the wire that moves away from the tire. Here’s an example, the nose gear has just hit the wire. Now the aircraft continues to move forward. We have a wave propagating in both directions along the wire, causing the wire to lay mostly flat against the deck. The wire dynamics model said that what should happen next is that the wire rebounds off the deck. But what actually happened is that the wire stayed down and the hook skips over the wire. What isn’t shown is how FAST the hook would rebound into the jet. The readings were so high that the test team believed the accelerometer measuring hook up-swing was broken, but it wasn’t. We tried, and tried, and tried over and over again to get the hook to work. While we were at Lakehurst, the program had a few days where we were forbidden from flying due to an IPP issue, but we kept trying roll-in arrestments at slower and slower speeds. None were successful. The hook kept rebounding at very high angular accelerations, damaging our very fragile tailhook instrumentation. Many of my memories of August 2011 are of sitting on the concrete floor of a clamshell near the old F-8/F-14 engineering building, cleaning up damaged wiring and tediously calibrating rotational position sensors on the tailhook. All usually done late at night. Hurricane Irene came through late in the month and made a direct line for us at Lakehurst. I came in to work one morning only to turn around and go back to my hotel and leave for home; the jet was sent back to PAX, ending our frustrating trials. It was clear that the hook needed a redesign. The new hook has much stronger hold down damper, an all new damper for the upstroke, a better lateral limiter, and improved instrumentation that didn’t break on every arrestment. Here’s the new hook: We also got an all new hook shoe! This one looks much more like a scoop, to catch the wire even if it’s down low on the deck. The new hook profile in red, old in blue, the arresting cable shown in purple: Now, program note: for personal circumstances, I left the F-35 program entirely in mid 2012 only to return a little less than two years later to the same job. So I wasn’t there to see this in 2013: The story most definitely does NOT end here though, because we had much struggle to go. We kept having issues with the bearing that the pitch pivot pin sits within. The pin is supposed to last at least 25 arrestments, but we were getting 1-2 before the pin sleeve would gall (Galling is wear that happens when metals slide past each other. Some material gets transferred from one metal surface to the other via frictional forces). We had a position sensor in that pin/sleeve to directly tell the control room the hook angular position during test, and all this pivot pin replacement meant I and a few other engineers spent a LOT of time working on CF-03’s tailhook. During my years on the F-35 flight test program, I usually worked night shift engineering. Night shift had next to no meetings, it was pure flight support, problem solving, and performing instrumentation preflights for the next day’s test. Me and another engineer almost always worked together on the mission systems jets. CF-03 and its tailhook (as well as its launch bar and gear) instrumentation needed so much care and feeding that one of us would work just on CF-03. The other would take both BF-04 and BF-05. We worked out some tricks for being able to replace a pitch pivot pin without having to re-perform a synchro (rotational position sensor) calibration. Why? Because new calibrations mean new instrumentation projects, which took several days and required a display check. Engineers, saving your program time and money out of the sheer laziness of not wanting to make a new XML format for an instrumentation project. This is how progress is made in the world, I guess. Most of 2015 saw me paying more attention to instrumentation project efficiency (something that, I am pleasantly surprised to see, gets a 1 paragraph mention in “From Concept to Cockpit”) but in 2016 I returned to Lakehurst with CF-03 to perform the trickiest tailhook tests. We were doing tests with full external weapons (modulo not having AIM-9X on the outer wing stations…the wing structure needed a fix) and trying for off-center arrestments. One cloudy day in May 2016 we try for an arrestment as far off centerline as we can go. Here’s the story of that day. I am sitting in something called the MITS (Mobile Instrumentation/Telemetry System). It’s literally a giant 18 wheeler trailer the Navy made that’s a mini control room. I am watching my instrumentation health screen and listening to the test audio, while watching the video on a television in the trailer. An F-35C coming in for landing is usually at about 11 to 13 degrees nose high so that when it hits the carrier deck, it looks something like this: Everything seems normal at first. I hear our pilot call the ball. But then I see on the screen that he’s actually coming in almost flat, and sinking like a stone. I expect to hear “WAVE OFF” from the fellow pilot monitoring him on the ground, acting as the Landing Signal Officer. I don’t hear that. And horrified, I watch on the video screen as the F-35 hits the ground with all three tires at once, then bounces off the runway, hits the runway again. The control room is full of engineers muttering curses under their breaths and staring at their screens. Through the hotmic channel we have recording everything our pilot says and hears, I hear him yell “FUCK!” but he keeps control somehow and gets back in the air. “Lightning seven three is airborne, going back around” he says on the radio. Someone in the control room says that we have violated a flight test continuation criterion: we hit so hard that all the landing gear bottomed out. The lead test engineer gets on the radio and says “We need a gentle flared landing.” The pilot replies, “My body needs a gentle flared landing.” Fortunately, once we come back around for a conventional landing, there is no further difficulty. But now, the post-flight debrief we have to talk about what happened and decide what to do next. An immediate review of the data shows that the landing was at such a high sink rate that it is as if we have taken the F-35C and dropped it from a height of 20 feet. We hit almost entirely flat, just 2 degrees angle of attack. It turns out that somehow the fresnel lens optical landing system (FLOLS) we are using was not set properly. Thus when the pilot thought he was flying on glideslope, he was flying a much too steep path. The LSO did not realize what was happening until it was too late. Much consultation has to be done with the leaders of the program at Fort Worth. The day is late, the jet is impounded by the crew chief and no one is to work on it until formal inspection criteria are created. They arrive the next morning in my email, 200+ steps that I must conduct just on my flight test instrumentation hardware. Other maintainers and engineers have their own thick inspection stacks. It takes three days. We discover that we need new landing gear, but that can’t happen at Lakehurst. Fortunately it looks like the gear is good enough to support one more takeoff/landing cycle, so back to PAX it goes. The program decides to officially stop trying to chase the off-center arrrestments and wire only arrestments. Thus ends the tailhook test saga.",
    "commentLink": "https://news.ycombinator.com/item?id=39525243",
    "commentBody": "Testing the F-35C Tailhook (the-engi-nerd.github.io)401 points by sklargh 18 hours agohidepastfavorite171 comments euler_angles 17 hours agoAuthor here. Did not expect to see this on HN at all. Just an engineering war story I shared. reply egorfine 8 minutes agoparentFirst of all, thank you for the super interesting read! Now, as a Ukrainian I do have a philosophical question of sorts. What we have seen here in a real full-scale combat is that some of the modern machines are way too delicate for actual operations on the ground. For example, I have heard some feedback about the Abrams tank: way too finicky for real use, not durable, not reliable. The same goes about many other western items. (Some hardware demonstrated exceptional reliability, like Bradleys and HIMARS) My question is about modern fighter jets like F-35. Does that level of engineering and the amount of delicate electronics somewhat limit the durability and reliability of the airplane compared to much simpler designs? reply tra3 16 hours agoparentprevThis is really cool, thanks for sharing. What's wild to me is that the program started in the late 90s and only now is the F35 fleet up to originally specified? operational capacity. Since then I graduated high school, got a degree, got married etc etc. The time span is mind boggling. Would be interesting to see how continuity is maintained for so long. In software it feels like if a project is more than 6 months old, we throw it out and rewrite it. reply roughly 13 hours agorootparent> In software it feels like if a project is more than 6 months old, we throw it out and rewrite it. I think that would be a bad way to operate, but what's worse is what we _actually_ do, which is write the project like it's gonna be replaced in 6 months and instead keep that poorly-documented untested duct-tape contraption around for a decade as the central load-bearing component of critical infrastructure. reply Jenk 8 hours agorootparentA decade is infancy in that scenario. The world's economies are running on stuff way, way older, for example. reply euler_angles 7 hours agorootparentprevThe F-35 contract was awarded on October 26, 2001. I was in my freshman year of undergrad, 18 years old. I started on the program in August, 2010. I was 26 years old. The program has just completed its Initial Operational Test & Evaluation, including its runs for score in the Joint Simulation Environment. I am 40 years old. reply xattt 9 hours agorootparentprev> In software it feels like if a project is more than 6 months old, we throw it out and rewrite it. “The Phoenix pay system is a payroll processing system for Canadian federal government employees, provided by IBM in June 2011 using PeopleSoft software, and run by Public Services and Procurement Canada… By July 2018, Phoenix has caused pay problems to close to 80 percent of the federal government's 290,000 public servants through underpayments, over-payments, and non-payments.“ https://en.wikipedia.org/wiki/Phoenix_pay_system reply tempestn 5 hours agorootparentThat situation was (is?) absolutely mind-boggling. I personally know government employees that were being underpaid with no recourse for months on end because the software wasn't working and the government apparently had no alternate way to pay. Some people weren't getting paid at all. And as you quoted, it affected 80% of the workforce, hundreds of thousands of people. reply dj_gitmo 4 hours agorootparentprevSomeone should get fired for choosing IBM in this case reply jonp888 9 hours agorootparentprevI work on software that has a lifetime once installed of about 30 years, and if a safety critical error is found during that time, ideally it needs to fixed with a minimal patch, so we have to maintain the capability to do so. I guess the ethos is quite different to top tech company. We don't get the pay or perks that you would get in Silicon Valley, but we are unionised, and it's a viable option to spend your entire career just on one project so it's very stable. Partly it depends on documentation, but also on thinking long term. There are certain people who are the technical authority for a particular area, and they know that about 5 years before they retire or move on they need to find someone who can take on their role for at least the next decade, to keep their knowledge rolling forward. reply tra3 7 hours agorootparentThat's fascinating. Is it possible for you to share more details? Industry? Tech stack? If your project started 30 years ago, that means DOS, or Network or maybe one of the IBM behemoths? Then the maintenance includes pacing OS updates and dependency changes? reply HeyLaughingBoy 6 hours agorootparentNot OP, but I work on medical devices. One product at my last job had an expected service life of 20 years. FDA requires that the manufacturer maintain the ability to support and service a medical device for, IIRC, 5 years after market exit. In the 10 years after release that I was on that project, we went through multiple OS upgrades from Windows NT to XP Embedded, to Windows Embedded Industry (replacement for XP Embedded) and a number of replacement x86 CPU boards had to be qualified as one manufacturer after another exited the market. Since the device is validated as a complete system, we often had to buy a year or two stockpile of existing product to give us time to start the Validation process for replacement hardware. You usually have plenty of warning from a supplier that a product (Windows or a CPU board) is going EOL at a certain point, so you need to start validating whatever the next replacement will be well ahead of time. reply tekla 16 hours agorootparentprevYou write shit down and you have career engineers that enforce continuity It's trendy in software to complain about doing annoying work like writing reports and documenting things. But most hard tasks require writing reports and documenting things. reply eitally 15 hours agorootparentAnd this isn't limited to aerospace. My wife has spent a career in pharma (drug save & pharmacovigilance specifically) and it's the same way there. People complain about rigidity and sluggishness in these industries but there absolutely is an ingrained attitude of documentation and process compliance that pervades. At one point -- and this was just last year -- my wife took over running a monthly safety report that involves manipulating a bunch of data in Excel. Even that has a 9 page instruction guide, and since she now owns the output she also owns maintaining the manual. Too often in the land of software we underestimate the potential negative impact the traditional \"move fast and break things\" approach to product development can have when it comes to real world use in mission critical systems. reply trhway 15 hours agorootparentOn the other side this unwillingness and mental non-acceptance of those reports/manuals/etc. as a wasteful activity frequently comes from the understanding that there are more efficient ways of doing things, and that drives the \"software eating the world\" effect. While I naturally don't know the details of the case you mention and pharma is far from the domains I've been in, yet in many business/enterprise situations the software approach is to code the many-page guide into business logic, including ETL-ing the data instead of manual import, etc. Move fast and break things brings you to the Moon in a decade using primitive tech, where is total process compliance can't do that even in 50 years using much more advanced tech. reply falcolas 13 hours agorootparentSo, an amusing anecdote related to your second paragraph - one reason it's taking so long the second time around is everything has to be repeated. They lost the knowledge of how to make rocket stages and engines of that size, and had to re-learn those lessons. It's also quite important to remember how many lives were lost (or nearly lost) because of \"breaking things\" in the Apollo program. Something that's not nearly as acceptable today than it was at the height of the cold war. Something that directly implies moving more slowly and being more sure that everything works the first time, every time. reply inamberclad 9 hours agorootparentSeconded. People burned alive until we learned. Surely there is a middle ground that will let us speed up while staying fairly safe, but it's important to remember that outside of software, many rules are written in blood. reply doctor_eval 7 hours agorootparentI don’t hold a strong opinion either way - in terms of process and documentation versus freestyling it - but that fire was predicted, and I think the concerns were documented. It can and did happen again, twice, on the shuttle project. Both the O rings and the ice damage were documented. Ultimately, any process (or lack of process) can be subverted by a bad culture. And unreasonably excessive process - as perceived by the participants - can damage culture as much as not enough. The problem is that culture is ineffable, so we try to nail it to the ground with whatever we can think of. reply hanche 2 hours agorootparentprevHeck, even maintaining my computers at home requires documenting things! I have lost count of the number of hours I’ve lost trying to rediscover how or why I set things up the way I did. reply wazokazi 16 hours agoparentprevWas there ever any consideration given to building a \"testing harness\" to physically simulate the F35 landing? Something like the \"dead load\" testing that the EMALS undergoes. Just in reverse. Anyway, that was great read. reply euler_angles 16 hours agorootparentThere was a lot of static load testing done, and things like a drop test [0] of a full scale article. But to my knowledge, the only way to test the dynamics of a carrier arrestment is to actually do an arrestment. We do them on land; NAS Patuxent River and NAS Lakehurst (among others) have a full set of Mark 7 arresting gear like you would find on a Nimitz class. Lakehurst also has the advanced arresting gear present on the Ford class. [0] https://www.youtube.com/watch?v=lGPseVNfZO0 reply fatbird 16 hours agorootparentHow much of a difference is there between dry land arresting and carrier arresting? I would guess some since the carrier represents a somewhat dynamic surface, and flight conditions might likewise vary. Is there enough that a second round of carrier based testing is required that might trigger significant changes? reply euler_angles 15 hours agorootparentAll of this was done as a work up to a carrier deployment. In software terms, trying the arrestments on land is deploying to test, doing them on a carrier is production. There were three separate developmental test deployments to carriers for the F-35C. Each deployment sought to expand the understood envelope and and handling procedures. The hook redesign happened before the first deployment. The hard landing story in the post happened during the work up to the third and final deployment. reply psunavy03 15 hours agorootparentprevThe Navy developmental test community does carrier suitability testing of every new airframe, and there's a whole program of nominal and off-nominal arrestments they have to test in order to prove the jet can recover in all expected scenarios. reply whartung 12 hours agorootparentprevI don’t know if it’s significant but on the carrier the arresting system is going 25-30 mph. The ship is moving. Again, maybe not enough to really matter, but enough to at least take into consideration. reply doctor_eval 7 hours agorootparentI imagine it means that the arresting system is being tested to greater limits on the ground than at sea, all else being equalish? Since the relative speed of the aircraft to the ship will be reduced. reply jtriangle 15 hours agoparentprevWhy exactly did they redesign the tail hook? Surely they could have just used one off any number of other aircraft with some modification? Or are all of those tail hooks bespoke designs because reasons? reply wbeckler 15 hours agorootparentIt could be related to the fact that they didn't have much space for a normal size tailhook, as stated in the article. reply jtriangle 14 hours agorootparentI mean more the design of the hook itself, though, I don't know if that design is even atypical to be honest. reply tharkun__ 9 hours agorootparentThe article goes into that. The model provided by -the manufacturer- correction NAVAIR (thanks OP!), stated that the cable will bounce up after having been hit by the landing gear. Thus the hook design made sense. The cable jumps up and over the hook. Plane arrested. Instead, again as the article states, the cable is actually being pressed tightly against the flight deck and the elevated hook nose makes the entire hook get thrown up in the air when drawn over the tight cable, back towards the plane and would even destroy some parts of the monitoring mechanisms, so violently did that happen. They also provide the new design, which is basically the old design and that is also why the techs that saw the new hook for the very first time (and know about the cable I presume) instantly said \"That ain't gonna work!\". It's all in there. reply euler_angles 8 hours agorootparentMinor correction, the wire dynamics model was provided by Naval Air Systems Command (NAVAIR), the Navy engineering organization in control of research, development, test, evaluation, and sustainment of Navy aircraft. reply tharkun__ 8 hours agorootparentThanks! Corrected my comment. I would actually love to know if someone on the hook design team questioned the model. I guess we won't know but I also it doesn't hurt to ask. Like did someone go: odd, why would that cable go up and not tighten when waves are sent through it towards the outward attachments? But was inevitably shut down and didn't have \"access to the customer\" to ask/verify. Like one of the first things to ask for when having to design this that comes to my mind is: I want high speed camera footage of current arrestor in action at the customer site! reply mech987987 14 hours agorootparentprevEven if two different aircraft have the same space constraints for the hook (which is a pretty big if), they have different mass and deceleration characteristics (i.e. minimum and maximum approach velocity) during landing- changing the force exerted on the hook. Designing a lighter hook for the lower loaded aircraft is VERY desirable for high tech fighter jets- every ounce saved is better range, better agility, etc. As far as the little lip at the very tip of the hook- it looks to me like the initial design was trying to minimize any risk of digging into the flight deck and causing damage- this is just a guess though. reply cwillu 2 hours agorootparent“After the LSO finished what he had to say and left the ready room my B/N allowed that he might fly with me again. Me, I was still shaking inside. The next morning I went up on the flight deck before flight ops started and walked to the aft edge of the deck. I was looking for something and found it. About one foot from the end, there was a single, shiny, brand new, solitary hook imprint in the deck.” https://thelexicans.wordpress.com/2013/09/10/one-foot/ reply wolverine876 13 hours agorootparentprevDue to the planes and to the rest of the tailhook (the shank, etc.), they could hit at different angles, speeds, etc. That's just a guess, however. Each plane costs ~$100 million and the entire program will cost over $1 trillion when it's done. Performance needs are extreme: They need to land in all sorts of adverse, imperfect conditions - damage to the plane, the carrier, the wire, the personnel; bad weather; bullets and missiles flying around. It seems worthwhile to design the highest-performing tailhook for this plane, rather than to save a few bucks. Also, IME people doing something this sophisticated don't miss those really simple, obvious issues that we happen to be able to observe and grasp from the outside. reply imglorp 14 hours agorootparentprevThey designed for the F-35B as the \"baseline\" with carrier requirements secondary. Also, the engineers knew but, \"their concerns would have just as likely been ignored.\" This reference was 2012, when they knew it was a problem but before OP was fixing it. https://www.f-16.net/f-35-news-article4494.html reply sufficer 6 hours agorootparentprevHave you seen an f14 in person? An f35? Wildly different. For one the f14 is massive! And it's tail hook is like the size of a medium man So yeah tail hooks vary wildy reply throwanem 10 hours agoparentprevThe name \"ham-peas\" might be familiar. If so, how've you been keeping lately? Been a minute! reply euler_angles 10 hours agorootparentI have not forgotten your user name here, ha. Yep, been a minute. I should hit you up via email. reply throwanem 10 hours agorootparentI wouldn't mind that at all. If you don't still happen to have the address, the one in my profile here's good too. reply euler_angles 10 hours agorootparentI actually still have your personal email address. Expect something from me soon. It took a few years but I work as a developer now (C++, electronic warfare simulator) reply throwanem 6 hours agorootparentThat's great to hear! I'll keep an eye out, and hoping all's well in the meantime. reply LorenDB 16 hours agoparentprevHey, would you mind adding an RSS feed to your blog? reply euler_angles 16 hours agorootparentI am but a grunt who mostly programs radar models, I didn't know Quarto blogs could do that until just now. Yeah, sure, I'll add it. reply euler_angles 16 hours agorootparentDone! reply LorenDB 16 hours agorootparentThank you! reply euler_angles 16 hours agorootparentQuarto made that really easy. Very cool. reply idontwantthis 15 hours agorootparentprevSorry, it’s been so long that I’m afraid to ask. What will you do now that it has an RSS feed? reply LorenDB 15 hours agorootparentUh, put it in my feed reader? What else is there to do with RSS feeds? reply dylan604 15 hours agorootparentIf you're Googs, you deprecate them reply superjan 16 hours agoparentprevIsn’t there a normally a mechanism that lifts the wire after the landing gear has crossed it? reply euler_angles 16 hours agorootparentYes, there are pendants that are supposed to keep the wire above the deck, but the short space between the F-35C main landing gear and the tail hook point means that there's not enough time for the pendants to raise the wire above the deck in the manner that the original (erroneous) wire dynamics model would have suggested. reply aidenn0 14 hours agoparentprev> “Boss,” he says to me, “This fucker ain’t gonna work. Look at this thing. It’s short, it’s too close to the wheels, and look at this dumbass hook shoe they got on it. If the wire don’t hit it exactly right, it’s just gonna go under the hook and you’ll bolter.” Did nobody with practical experience with arrested landings look at the arresting hook design prior to this? Obviously computer models can and do predict extremely novel solutions to existing problems, but it's worth double-checking the model when someone with practical experience says \"it will never work\" In this case, it seems like a simple slow-motion video of an arresting wire going under the wheels of an F-18 would have been enough to debunk the model. reply the_af 13 hours agorootparentRandom thought: this is a case where someone's intuition matched what actually happened, making us think \"why don't they listen to people with common sense?\". But what about the many other cases where someone with \"common sense\" said \"this fucker ain't gonna work\" but the thing worked as predicted by simulations? Surely they must have happened too. reply aidenn0 12 hours agorootparentMy point is that when models predict counterintuitive results (which they often correctly do; See e.g. Eurisco in the Traveller TCS championship, or the shape of the F-117 compared to contemporary stealth aircraft), it's worth double-checking. reply icegreentea2 14 hours agorootparentprev> Did nobody with practical experience with arrested landings look at the arresting hook design prior to this? I mean... it's very likely that the answer is no. The last new carrier aircraft made was the Super Hornet - and that design was basically done by 1995 (the F-35 tests in question were in 2011/2012). That expertise would also be at McDonald Douglas/Boeing. Northrop Grumman has a long history of carrier aircraft development, but it would have been long dormant by that point. I'm sure there's all sorts of reasons the model's inaccuracy wasn't caught before hand, but sometimes... if you're given a model that's someone says that's been V&V'd, and it produces a result that's only a little weird, you just go with it. There are only so many things you can add extra testing onto in a project. Sometimes you choose wrong. Anyhow, consider that the model results were probably exactly what they were expecting. Remember that the designers would be honing in on the shorter tailhook. You can imagine their mental model going - \"ok on legacy aircraft, we have flatter tailhooks because there's enough time for the cable to settle\". And then going \"ok, with a shorter tailhook, there won't be enough time to settle\". And then their model comes out and say \"ya, with the shorter tailhook, it won't have enough time to settle - it'll be UP IN THE AIR\". Whereas reality is \"ya, with the shorter tailhook, it won't have enough time to settle - it'll still be displaced DOWN\". reply MadnessASAP 13 hours agorootparentprevUnfortunately, my decade plus as a military aircraft tech has taught me that no, practical knowledge does not make it through the system nearly as fast as engineering \"expertise\". reply mechhacker 10 hours agorootparentSame, but different industry. Lots of re-engineering of the wheel after the original designers give their warnings and recommendations, but everyone's too smart to try the simple thing that already works first. reply kevin_thibedeau 7 hours agoparentprevHope you have proof that the diagrams aren't export controlled. Otherwise you're going to receive some unexpected visitors soon. reply euler_angles 7 hours agorootparentThey all came out of a book that anyone can buy called \"F-35: From Concept to Cockpit\". That book is a compilation of papers presented at an AIAA conference in 2018. reply mlekoszek 15 hours agoparentprevGlad you did. reply tiahura 16 hours agoparentprevInstead of a lot of modeling and testing, wasn't Northrop just allowed to inspect an F18 and measure? reply euler_angles 16 hours agorootparentThe F-18 tailhook geometry is far different than the F-35 tailhook geometry. F-18 hooks are much farther back from the main landing gear, and are also much longer. reply iab 16 hours agoparentprevAre you actually euler_angles, or are you really tait_bryan_angles reply euler_angles 7 hours agorootparentDeep down I am indeed tait_bryan_angles reply iab 6 hours agorootparentI appreciate your candor (and your article) reply foxyv 16 hours agoprevI love hearing about these engineering challenges. Media loves to point to these design iterations as proof that the F-35 is over-hyped or inferior to existing jets. But what I see is innovation and trying new stuff. Sometimes failing, but in the end making an amazing jet. I just kind of wish we lived in a world where we didn't NEED a new fighter jet and could instead invest this time and effort into peaceful pursuits. reply ckozlowski 16 hours agoparentIt's true, and it often forgets that most other aircraft go through the same teething problems. As the article skillfully shows, there's a lot of work that goes into seemingly simple things like a hook. Other elements can be really complex to work out. The F-35's integrated power pack[1] was the source of quite a few issues if I recall correctly. But it was developments like that which allowed the plane to keep weight under control such that we now have a supersonic STOVL jet in the F-35B. It's a pet peeve of mine when commentators say \"that's stupid, they should just do !\" . Well, if it were so easy... I get your sentiment regarding the need for new fighter jets. At the very least, some of these engineering developments end up helping commercial applications as well. A good example is the C-5 Galaxy, which went through torturous development. But lead to the development of the TF-39 engine, which was revolutionary in concept. It then became the CF6, which then went on to power a long line of successful airliners. [1] https://www.defenseadvancement.com/feature/3-aircraft-system... reply MadnessASAP 12 hours agorootparent> It's a pet peeve of mine when commentators say \"that's stupid, they should just do !\" . Well, if it were so easy... Why don't they just put windows in the submarine... It's good to remind ourselves and occasionally others that if the answer to a problem in a domain we don't have much knowledge on seems simple. Chances are the people with the knowledge are well aware of your answer and know why it won't work. reply rkagerer 16 hours agoparentprevBut what I see is innovation and trying new stuff. I like your positive attitude. Though I think there were some engineering shortfalls that should have been avoided with common sense. Eg. The original hook didn't work because the shoe was angled up too high to catch the wire. The engineers designed it based on a flawed simulation model. The guys field testing took one look and knew it wouldn't work. Heck, I showed this photo to my partner (non-engineer) and the first thing she said was \"it's not pointing right\". https://the-engi-nerd.github.io/posts/welcome/images/clipboa... You can see the original (blue) vs revised (red): https://the-engi-nerd.github.io/posts/welcome/images/clipboa... reply foxyv 14 hours agorootparentMy first class in Calculus based physics, my professor did an interesting thing. We would be asked to intuit the answer to problems before we did the math to know for certain. Physics is simply not intuitive. Now, with regards to the simulation, the thing I think they failed on wasn't a lack of common sense. I think what they should have done is reproduce the results in real life using a similar jet. They relied on the model a bit too much and \"Tested in production.\" However, as far as mistakes go, this is a pretty small one. reply euler_angles 11 hours agorootparentThere isn't a similar carrier aircraft in the inventory that could have been used, as far as I know. reply hef19898 15 hours agorootparentprevLooking at the image, and knowing designers assumed the cable would rebound before being cought by the hook, the original design of the hook itself makes sense: catch the cable in the air and make sure it doesn't slip down the hook. Obviously it doesn't work to catch cable lying flat on the ground. Which was, again, not the initial design requirement. In another thread about Boeing, the topic of good sources to learn about real engineering came up. Well, this is a great example. Just assume the engineers designing the initial hook were not complete clueless idiots. reply wolverine876 13 hours agorootparentprev> The guys field testing took one look and knew it wouldn't work. You have a hearsay, hindsight story (no offense to the author) that one person thought it wouldn't work. And now we have a hindsight HN comment that they would have known it all along. I'm guessing the people who worked on it weren't idiots, though people seem to delight in supposing they are smarter than all the dumb people whose plans don't work out perfectly. reply euler_angles 13 hours agorootparentNo offense taken. The observation of an instrumentation technician and an engineer (me) definitely counted for not much at all in the grand scheme of things. And we could have just as easily been proven wrong. reply the_af 13 hours agorootparentYes, that's what I'm thinking. Since you're the author: can you remember any cases where the person with \"common sense\" thought \"this crap ain't gonna work\" but it worked anyway? Surely people only remember those cases when common sense won, and selectively forget those where it didn't? reply krisoft 12 hours agorootparent> can you remember any cases where the person with \"common sense\" thought \"this crap ain't gonna work\" but it worked anyway I have one! Totally different field though. Cruise ships (and roro ferries) look sooo ungainly in water that regular people frequently ask how do they not just roll over. The Icon of the Seas goes 9 meter underwater and 20 stories over the water. It does not feel or look right. Yet it is right, and keeps upright :), because it does not have uniform density. The engines and machinery, and tanks at the bottom of it keeps the center of gravity low enough to make it stable. The funny twist is that vehicle carrier ships also look unstable the same way and there the intuition is more correct. There have been multiple accidents where such ships capsized. But the intuition there is still not correct about the reasons why they flip over. (It is not that they don’t have enough draft, but due to free surface effects and the cargo destabilising). reply euler_angles 11 hours agorootparentprevFor F-35 flight test specifically, nothing comes to mind. Perhaps I'm a victim of the forgetting you mention. reply mardifoufs 14 hours agoparentprevYeah it's amazing how it is currently the best jet in the world considering how reviled and criticized it was in the media. And said criticism had real consequences, here in Canada we basically got stuck buying 1970s trash just because the f-35 became a taboo and a meme due to projected costs, even if it means that we will pay even more for the alternatives for much much less capabilities. reply foxyv 14 hours agorootparentTo be honest, I think the F/A-18 is an excellent jet for Canada's needs. Also Canada currently has 88 F-35s on order and will get their first ones in 2026. reply dralley 13 hours agorootparentThe ancient F/A-18s airframes Canada purchased however, were not. >Canada expects to receive its first four F-35As beginning in 2026, another six in 2027, and six more in 2028, with the full fleet to arrive in time to enable the phase out of the CF-18s by the end of 2032. But its CF-18 fleet, even bolstered by the purchase of 18 ex-Royal Australian Air Force F/A-18A-Bs, may not be able to effectively hang on until then. They wasted a lot of time and money setting up supply chains and training pipelines for a fleet of near-end-of-life airframes that required constant maintenance, provide only the bare minimum capabilities and won't end up in service for very long. And they're having so many retention issues with their pilots that even that is wasted. reply wolverine876 13 hours agorootparentThe world changed significantly since that initial order, with the threats greatly increasing (from China and Russia). F/A-18 jets might have made sense in a more peaceful world. Now Canada has bigger problems and needs to better interoperate with NATO allies. Many countries switched their plans to F-35's after Russia invaded Ukraine. reply mardifoufs 13 hours agorootparentThe issue is really that they bought used, worn out airframes just because they weren't as old as ours. From another Airforce that basically deemed them to be too old and worthy of replacement by the f-35... the same f-35 that we chose to not buy instead! It's such a Canadian thing but we just basically swept the problem away for the couple of years that we can get from the airframes, but we had to basically go through all of the procurement again not even half a decade after that decision. So there was no point at all, we could've just bought actual replacements (f-35 or not) that would last for an entire generation back in 2p15. But hey, problem solved for the current government so who cares about what happens in 10 years! But then the issue got too big and we ended up circling back to buying the exact same f-35 that we wanted to have for the past 20 years. Just with a worse deal and even more clapped out f18 and pilot accidents. reply foxyv 13 hours agorootparentprevI don't mean that the airframes are any good, I just mean that Canada has a population similar to that of California and almost half the GDP. They neighbor their closest ally and are separated by ocean and arctic wastes from anyone who would want to invade them. They don't really have much expeditionary need and their defense would be backed by all of NATO. So a couple old multi-role fighters are sort of okay for what they are doing. Mostly air to ground missions and demonstration flights. They need to up their defense spending a bit to meet NATO obligations, but not that much honestly. No one is going to kick out Canada, especially after the USA dragged them into Iraq. reply TMWNN 7 hours agorootparent>I just mean that Canada has a population similar to that of California and almost half the GDP. That makes the mistake in not buying the F-35 the first time around all the worse. >especially after the USA dragged them into Iraq This is so not right, it's not even wrong. reply ambichook 7 hours agorootparentF-35s are significantly cheaper than they were a few years ago, and as more are produced the prices continue to drop reply euler_angles 7 hours agorootparentThe regime of steadily decreasing F-35 prices as new lots are contracted is at an end [0]. With inflation and the cost-overruns on the Tech Refresh 3 upgrade package, we are in a regime where prices will slowly increase. [0] https://www.defensenews.com/industry/2022/11/18/f-35-costs-h... reply ambichook 6 hours agorootparentTIL, although it does make sense, thanks! reply TMWNN 6 hours agorootparentprev>F-35s are significantly cheaper than they were a few years ago, and as more are produced the prices continue to drop I've heard this argument before about Canada's F-35 saga and it is now what it was then, massive copium overdose. By this logic Canada ought to wait until the F-35 is obsolete and other nations are selling airframes off for cheap. That Canada did not have to use its air force in war during the Trudeau years does not mean that its 100% politically driven decision to shirk on the F-35 buy, then jump back on it again, was not a mistake. reply ambichook 6 hours agorootparenti'm not saying canada not buying f35s to begin with was necessarily the correct choice, but the fact that they don't have a massive GDP and have now managed to purchase them for a lower price isn't \"infinitely worse\" than if they had bought them to begin with, it has lucked out in their favour reply euler_angles 11 hours agorootparentprevAs a guy who knows the F-35 and the program pretty well, I think the best Canadian minds on the F-35 are Richard Shimooka with the Macdonald-Laurier Institute, and former CAF and F-35 test pilot Billie Flynn. Shimooka has a number of works chronicling the Canadian F-35 decision making process, e.g. https://macdonaldlaurier.ca/assessing-damage-canadas-fighter... Billie Flynn discussing the F-35 and the current state of the CAF on \"The Merge\" podcast: https://youtu.be/kibWNHr9hdg reply 2OEH8eoCRo0 11 hours agorootparentprev> the f-35 became a taboo and a meme Who benefited? I assumed that while criticism is healthy, some calls for cancelling the aircraft were from adversaries. Easiest way to defeat the plane is to get Congress to kill it. reply lmm 10 hours agoparentprevMaking a new experimental jet design is great. It's the committing to buy and pay for thousands of them before you've even confirmed whether that design works that I object to. reply davidjytang 10 hours agoparentprevSome would argue that arming oneself is the pursuit of peace. reply helpfulContrib 14 hours agoparentprevThe cost of a single F35 could fund so much peace in the world. The only reason this isn't happening is because the people making sure the American people keep endlessly funding these programs have no intention whatsoever to make peace. They just don't have the intention to do so. They intend for there to be endless war, which is what these machines produce. It is the only thing they can be used for.. reply euler_angles 11 hours agorootparentI abhor war. I believe the only way to secure peace is to be very good at war. That's why I participated in flight testing the F-35, and why I work on electronic warfare simulations now. I wish I lived in a world where there's no need for any of this, but as far as I know, war is as old as the species. reply 2OEH8eoCRo0 9 hours agorootparentYou may have crossed paths with some of my bad code. I'm sorry. reply euler_angles 6 hours agorootparentI have crossed paths with a lot of bad code. They write it faster than I can fix it. reply robocat 10 hours agorootparentprev> the American people keep endlessly funding these programs Fighter planes are a significant export earner for the USA - it isn't just domestic demand. reply foxyv 13 hours agorootparentprevI would love to live in a world where I can know for a fact that war will never again happen. However, the path to that world is a very long one. In the meantime I want to know that the acquisitive psychopaths that run many of the countries in the world have a very good reason to not line me up in front of a wall and shoot me. Should we be taking steps to a more peaceful world that we aren't right now? Yes, very much so. However, unless you want to imitate the path of Tibet or Ukraine, then you better spend some money on guns and fighter jets. reply marcinzm 11 hours agorootparentprevYes, America funded Russia's recent invasions. Yup. All America. reply scottyah 10 hours agorootparentprevHow do you fund peace? Defense is pretty straightforward to me, but even Toms trying to give away free shoes in Africa created a lot of conflict. reply oogali 9 hours agorootparentprevI think if you want endless war you would increase the numbers of your armed forces by several orders of magnitude. Not spend very large sums of money on things piloted by 1-2 people that can end wars relatively quickly. reply avalys 12 hours agorootparentprevThis is such nonsense. Could the USA have won WWII by paying off Hitler? reply jessriedel 16 hours agoprev> The program decides to officially stop trying to chase the off-center arrrestments and wire only arrestments. What does this mean? That the F-35C can only hook correctly when it lands very close to center? And what does \"wire only\" mean? Aren't all arrested landings on carriers \"wire only\"? reply euler_angles 16 hours agoparentThe whole purpose of this series of tests was to try to exercise the arresting gear in the most punishing ways. One way that's usually done is to try to arrest far off the centerline (where the arresting force will be applied far more intensely to one side) and also to try to have the arresting hook grab the wire while the jet is still wheels above deck (this slams the aircraft down, HARD) After this incident it was determined that we had fulfilled the intent of the test plan. Also, instrumented aircraft capable of doing arrestments were in short supply: the program only had two of them, and we pushed one to its very limit. reply jessriedel 16 hours agorootparent(BTW, the twitter link on your blog is mistakenly going to twitter.com. I think you meant to link to your account: https://twitter.com/the_engi_nerd Cheers!) reply euler_angles 15 hours agorootparentOh, thanks for the spot. Not sure why it's doing that... reply euler_angles 15 hours agorootparentFixed reply jessriedel 16 hours agorootparentprev> After this incident it was determined that we had fulfilled the intent of the test plan. Ok, so it was considered good enough? (This quote made it seem like the testing had failed and they were giving up: \"The program decides to officially stop trying to chase the off-center arrrestments and wire only arrestments.) Also, I still don't understand what wire-only arrestments are. Aren't all arrestments wire only? Thanks. reply hbrav 16 hours agorootparentI think \"wire only\" means the hook catches while the wheels are still off the deck. I suppose that hard landing might have, in some ways, replicated the hard slam-down this would produce. Author, is that the case? Was the hard landing judged to have been a decent proxy for the wire-only arrestment? reply bronson 15 hours agorootparentSeems unlikely. One is slamming due to a heavy glideslope. Two is slamming due to a serious yank on the rear section. The airframe stresses and flight dynamics will be different. reply euler_angles 15 hours agorootparentYeah, dynamics will be different, though caveat I am not a structures/loads engineer. I just don’t think anyone had the risk appetite to chance a test asset against a very difficult to achieve test point. reply hef19898 14 hours agorootparentIt is also fair to assume the decision to not do additional testing of wire-only arrests was well analyzed by the respective engineering teams. Program management does not take decisions like this by themselves. reply euler_angles 12 hours agorootparentAbsolutely. We had a whole carrier suitability team full of people who lived and breathed this stuff. It was just my responsibility to make sure the aircraft instrumentation system got them the data they needed, at a high enough quality, to empower their analyses and decision making process. reply ferfumarma 15 hours agorootparentprev> Ok, so it was considered good enough? (This quote made it seem like the testing had failed and they were giving up: \"The program decides to officially stop trying to chase the off-center arrrestments and wire only arrestments.) Kind of both: it was too dangerous to test a wider range of parameters, and the testing was therefore \"successful\" because it was crystal clear that going beyond the point where they had the problem would not be safe. So in this case \"giving up\"/stopping and \"determining the limits of the landing envelope, were reached at the same time. reply werrett 16 hours agorootparentprevBased solely on the above description -- wire-only is when you don't have wheels on deck, also slowing the craft down. reply jessriedel 16 hours agorootparentGot it, thx! reply bombcar 15 hours agorootparentprevI assume wire-only means no reverse thrust and no brakes. reply jessriedel 14 hours agorootparentNo, aircraft land on carriers while applying full forward thrust and (I am 99% sure) no wheel brakes. The idea is that if the wire fails to catch they \"bolter\", i.e., do a touch-and-go, so they can come around for another landing attempt. (If they stopped or reversed thrust and the wire didn't catch, they'd end up in the drink.) Based on other comments (or re-reading the authors comment carefully), it turns out that \"wire only\" mean that the wire catches before the wheels touch the ground. (This puts additional strain on the wire and airframe.) reply wolverine876 13 hours agorootparent> no wheel brakes There are brakes on the wheels (that can slow a plane moving at flying speed)? That's a lot of force. I assumed the wheels merely prevent friction between the plane body and the deck, and the engines and control surfaces, and the wire, did the braking. reply ambichook 13 hours agorootparent\"no wheel brakes\" here means that the brakes aren't engaged, as stated so that if the aircraft misses the wires it can touch and go without drowning the pilot and destroying an $80m aircraft reply jki275 7 hours agorootparentprevAll planes have wheel brakes, including naval aircraft. But in an arrested landing the wire stops the plane, not the brakes. reply jki275 7 hours agorootparentprevYou're correct, no wheel brakes and throttle to full as soon as the wheels touch. If the cross-deck pendant snaps, the engines don't have time to throttle up before you go over the edge. And of course if you don't catch a wire you really don't want to be trying to stop. No reverse thrust in carrier aircraft. reply moelf 16 hours agoparentprevI thought there's also the net they can use if, say, an aircraft lost tailhook reply jessriedel 16 hours agorootparentSure but that's emergency only. reply fusslo 17 hours agoprevI think every engineer has been burned by faulty test equipment. and I think every senior engineer has been burned by not trusting test equipment that IS working properly! that was a pleasant read reply vlachen 16 hours agoprevGreat read. Looking forward to more! I was once a Harrier mechanic, and I was told very often that I'd be learning to work on the F-35Bs during my 2002-2007 enlistment, which obviously didn't happen. So, as a former mech and current engineer, I am very interested in hearing more about it's development. reply euler_angles 16 hours agoparentI have other threads on Twitter discussing the F-35 > https://twitter.com/the_engi_nerd/status/1758633498464952414 Labeling everything I could see in the cockpit > https://twitter.com/the_engi_nerd/status/1757243336941871159 a discussion of my primary job in flight test, aircraft instrumentation. > https://twitter.com/the_engi_nerd/status/1747803565987381495 riffing along with chapter one of \"F35: From Concept to Cockpit\", a compilation of papers written by Lockheed-Martin employees at the conclusion of F-35 system design/development. reply lchengify 15 hours agoprev> Engineers, saving your program time and money out of the sheer laziness of not wanting to make a new XML format for an instrumentation project. This is how progress is made in the world, I guess. I've worked in healthcare, fintech, and ads and this is one thing I've done in all three fields. I swear i've written or debugged XML parsers in 20 different languages at this point just so I didn't have to get consensus on a new format. reply euler_angles 15 hours agoparentWe made our XMLs with, horror of horrors, a Visual Basic script that ran in Excel and digested several input documents to generate a map template that we could then tweak by hand and turn into an XML through another VB script. reply lchengify 15 hours agorootparentHonestly, makes sense. This is how much of finance runs their models. reply euler_angles 15 hours agorootparentWe weren’t allowed to have any other real programming tools, and the telemetry “maps” we were trying to make were/are major/minor frame oriented. This maps nicely to a grid of data: a spreadsheet. IRIG 106, Chapter 4 PCM telemetry covers what we were doing in this process, along with Chapter 9. reply jki275 7 hours agorootparentI feel your pain. I've written entire applications in Visual Basic in Excel onboard the CVN before. It was the only programming language I could get access to. reply sillywalk 12 hours agoprevAn interesting side-note on the F-35C - when it was ordered/designed there was no aircraft that could deliver replacement engines (even when disassembled) to an aircraft carrier. They wouldn't fit into the C2 Greyhound. Kind of an odd oversight. They can fit into the CMV-22B variant of the Osprey, which is grounded for now, and I believe the CH-53K King Stallion. But they those aircraft didn't exist until recently. edit: I meant to say that the C-2 couldn't carry F-35 engines in particular because they don't fit, not that they couldn't carry replacement engines in general. reply lmm 10 hours agoparentReplacing a whole engine at sea is something I wouldn't necessarily expect to be done often. Do they swap out wings while underway too? Having to stick a pile of spare engines in storage and replenish them when you dock doesn't seem like the worst limitation to have. reply sillywalk 9 hours agorootparentI don't know the details on how often engines get repaired, that's a good question. The lack of ability to do it during a \"Real War\" means that if the engine has problems, that fighter is now sitting in the hangar useless, except for parts to cannibalize. In terms of the F-35 engines they under-speced them, so they have to run twice as hot[0] to cool the electronics: \"The original program engine specification allocated 15 kW [kilowatts] of bleed air extraction to support system cooling requirements, and the F135 engine was designed, tested, and qualified to this specification with a level of margin available for future growth,\" Schmidt wrote. \"During the final stages of initial aircraft development, air vehicle cooling requirements grew to exceed planned bleed air extraction.\" \"To provide the necessary bleed air, the engine is required to run hotter, and the program is realizing the effects of this through an increase in operating temperature, and a decrease in engine life, which is driving earlier depot inductions and an increase in lifecycle cost,\"[1][2] [0] https://www.defenseone.com/threats/2023/03/f-35s-need-more-p... [1] https://www.twz.com/f-35-engine-running-too-hot-due-to-under... [2]https://www.pogo.org/newsletters/the-bunker/the-bunker-hardw... reply lmm 8 hours agorootparent> The lack of ability to do it during a \"Real War\" means that if the engine has problems, that fighter is now sitting in the hangar useless, except for parts to cannibalize. If it has problems severe enough that the engine can't be repaired and must be replaced, and they don't have sufficient replacement stock, yes. But what I was trying to get at with my question about replacing the wing is that having an aircraft return to the carrier damaged severely enough that it's unflyable and unrepairable must be a somewhat routine/normal occurrence during \"real war\". (Of course the more you can repair while underway the better, all else being equal). reply jki275 7 hours agorootparentprevOh you absolutely can change an engine at sea. Naval aircraft are very modular for good reason. Engines can be removed and tested (there's a whole massive test jig and setup on the fantail for it), and removed and replaced at sea. A whole wing replacement, I'm actually not sure but it wouldn't surprise me at all. You might not see a port for nine months or a year -- that's not an acceptable amount of time to just have a plane or multiple planes down waiting on parts that are available. There's no way to get them off the ship other than a crane pierside if they can't fly. The entire reason for the switch from the C-2 to the MV-22 for Carrier resupply was to be able to bring an F35 engine replacement aboard. https://www.youtube.com/watch?v=OeNCtMkaYRs https://www.youtube.com/watch?v=QHC4CqCy9RY reply nickff 11 hours agoparentprevYour statements are vague and incorrect. First off, there are CTOL airplanes which can deliver replacement engines to aircraft, just not F-35 replacement engines (because of their large blade diameter). USN had previously used C-2 Greyhounds for these sorts of duties, but they have too small a fuselage, and were being decommissioned. There was talk of converting some decommissioned S-3B for COD, exchanging their fuselage for a wider one to accommodate the F135, but this was not pursued. https://archive.ph/20150209193642/http://www.defensenews.com... Second, lots of helicopters can carry F-35 replacement engines, including the Boeing Sea Knight. https://en.wikipedia.org/wiki/Boeing_Vertol_CH-46_Sea_Knight I believe that the USN didn't want to depend on conventional helicopters because of their relatively short range. reply sillywalk 11 hours agorootparentI edited my comment to make it clear it was just F-35 engines that couldn't fit. But I think the rest stands true. There was no V-22 COD variant at the time and the main COD aircraft couldn't deliver replacement engines. Other helicopters could deliver replacements to the carriers, as you said, but the carrier would have to be relatively close to shore. Other side note: the V-22 isn't pressurized, so they have to stay at a relatively low altitude. reply euler_angles 11 hours agorootparentprevThe CH-46 has been out of US Navy service for 20 years and Marine Corps service for almost 10, just as a program note. reply scirner22 15 hours agoprevAwesome read! I worked on IFLOLS as a new grad software engineer during this time. Since leaving the government to work at various software startups, I miss real world engineering like this. reply wolverine876 13 hours agoparentWhat do you mean by \"real world engineering\"? That is, how does it differ in your perception? reply euler_angles 9 hours agorootparentI went from doing things like I describe in the blog post, to verifying and validating the most complex electronic warfare simulation the DOD has ever done, to being a developer of one of the enabling technologies of that simulation. I believe what I do now is important, but getting an issue past test and into the release that's sent to customers isn't nearly as satisfying as \"I fixed the tailhook last night, which let today's flight test happen\". I miss having an aircraft that I can touch. reply scirner22 8 hours agorootparentprevWriting software to control a dynamic light plane compared to writing springboot rest apis. reply torcete 16 hours agoprevSince the new aircraft carriers have this new fancy electromagnetic catapults. Why don't they just use regenerative braking like the hybrid cars? They could save a lot of energy recharging those catapult accumulators. I'm joking, of course. reply jcgrillo 16 hours agoparentIf those hybrid cars just had nuclear reactors they wouldn't need all that complex regeneration stuff, or an IC engine even :) reply superjan 16 hours agoparentprevWell the ship gets a little nudge in the right direction for free. reply dieortin 14 hours agorootparentOr in the wrong direction, depending on the wind reply jki275 7 hours agorootparentAlways sail into the wind doing flight ops. reply Scubabear68 17 hours agoprevOne thing that stood out to me - based on the narrative here the tail hook never could work in real world conditions. The blog mentions that the computer model used by the manufacturer was wrong. Does that mean that manufacturers don’t field test the hardware? If so, that is scary. reply euler_angles 15 hours agoparentThat's what the flight testing was for. I am not aware of a way to all-up test something as dynamic as an arrestment without actually building a jet and trying to catch a wire. reply toast0 15 hours agoparentprevThis is the field test of the hardware. When you've got a single customer anyway, it makes sense for the customer to participate in or fully drive the field test. reply someotherperson 10 hours agoprevJust of curiosity, I would have thought that things like this are considered classified? Did you need to seek clearance to publish this? Or is there certain things that the US military isn't as fussy about (like this)? reply euler_angles 8 hours agoparentMy own engineering war stories are just that, stories. Any technical information I gave was taken from released sources only. I am extremely conscious of this reply speed_spread 10 hours agoparentprevI assume that since the plane is public and there are pictures of it landing, information regarding the tailhook doesn't have to be classified. People who want to know, will. reply extraduder_ire 17 hours agoprevI thought tailhooks predated the f35. Did they need a different design on this aircraft for some reason? reply DiggyJohnson 16 hours agoparentYes, the packaging geometry is pretty different on the F35C compared to other carrier-operated platforms like the F14, F/A-18, or E2C. Notably the platforms I just listed were designed from the ground up for CATOBAR operation. The F35C is just one variant of the platform, and must share certain geometries and constraints with its conventional and hovering sisters. reply shitlord 16 hours agoparentprevTailhooks do predate the F-35C, but this particular airframe needs to maintain certain properties (low observability, aerobatic performance, weight, etc.). You can't simply enlarge the tail hook compartment and use the other aircraft's hook without compromising some of these properties. reply jcgrillo 15 hours agoparentprevMost machines don't have modular, swappable systems. For example you can't generally take the wheels of one model of car and just bolt them onto another (even if the bolt holes and centering ring line up) expecting it to go well. A tailhook is undeniably more complex than a car wheel--it's not a reasonable expectation to be able to just bolt one on from a different aircraft. reply avalys 12 hours agoparentprev\"Our existing service already has 'export to PDF' functionality. Why do we need to spend money building and testing 'export to PDF' functionality in our new service? Can't we just reuse the same code?\" reply jeffrallen 16 hours agoparentprevThe author says the design was constrained by the space available for it when stowed in the airframe. reply euler_angles 10 hours agorootparentYes, the tailhook bay is very, very small. We had a primary disconnect in the bay for the instrumentation wiring for our tailhook sensors. Any time we had to get at that disconnect without having the tailhook trestle removed, we would call it \"proctology\". reply brokenmachine 6 hours agoprevTIL where \"galling\" comes from. reply ballooney 2 hours agoprevQuestion for anyone still browsing this far back in the timeline - any recommendations for other good engineering war-story blogs? Ideally aerospace, robotics etc. reply BruceEel 17 hours agoprevnext [3 more] [flagged] smoldesu 17 hours agoparentDepends where it's standing on the carrier deck when the arresting gear snaps =) reply BruceEel 16 hours agorootparentoops, hadn't thought of that! reply HumblyTossed 14 hours agoprev [–] Isn't this over engineered aircraft supposed to VTOL? reply ranger207 14 hours agoparentThere's three versions. The F-35B is the one that can take off in a short distance and land vertically[0] and it has a big lift fan behind the cockpit. The F-35A and F-35C don't have the lift fan; the C has large wings and a reinforced tailhook[1] compared to the other versions. [0] The F-35B _can_ take off vertically, but it can't do so with any reasonable weapons or fuel load. [1] Many non-Navy planes have tailhooks to work with emergency arresting wire systems at Air Force bases, but those are for emergencies and are rarely used, whereas the Navy uses tailhooks all day every day reply dralley 13 hours agoparentprev [–] Only the B, and the B is only intended to do short takeoffs not vertical ones (it is possible to take off vertically but pointless, you can't do it with a combat load). The C is meant to do carrier takeoffs and landings. Landing on a carrier the traditional way is more reliable than trying to land vertically every time. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Testing the F-35C tailhook for carrier landings faced challenges due to the initial design flaws, resulting in numerous failed attempts and necessitating a redesign.",
      "The test team addressed issues with the pivot pin and made adjustments to enhance functionality, although a landing test incident caused damage to the landing gear, prompting a reevaluation of testing methods.",
      "Despite setbacks, the post ends with the discontinuation of specific test protocols and the ongoing testing of the F-35C tailhook."
    ],
    "commentSummary": [
      "The article delves into testing and designing the F-35 fighter jet, highlighting the intricate challenges in aircraft engineering.",
      "It emphasizes the significance of rigorous testing, thorough documentation, and informed decision-making in aerospace and software industries.",
      "The discussion extends to the hurdles in military technology development, aircraft engine reliability, and the acquisition process for fighter jets such as the F-35."
    ],
    "points": 401,
    "commentCount": 171,
    "retryCount": 0,
    "time": 1709047956
  },
  {
    "id": 39524164,
    "title": "Green Spaces in Cities Can Lower Temperatures by 5°C",
    "originLink": "https://newatlas.com/environment/surrey-cooling-effects-green-spaces-waterways/",
    "originBody": "Environment Botanical gardens can cool city air by an average of 5 °C By Paul Ridden February 26, 2024 Facebook Twitter Flipboard LinkedIn Botanical gardens can cool city air by an average of 5 °C As climate change warms the planet, planning to include urban infrastructure like botanical gardens, parks, street trees, green walls and wetlands could help cool city air Depositphotos View 3 Images 1/3 As climate change warms the planet, planning to include urban infrastructure like botanical gardens, parks, street trees, green walls and wetlands could help cool city air Depositphotos 2/3 The potential cooling effects of GBGI infrastructure across 10 categories selected in the study Prashant Kumar et al 3/3 Table showing the cooling effects of several green spaces and waterways University of Surrey View gallery - 3 images Temperatures around the world are on the rise, with 2023 recently confirmed as the hottest since records began. A new study has found that bringing nature into cities could help lower temperatures during heatwaves. If you're lucky enough to live near forested areas, you'll know that one of the best ways to escape the mid-day heat while out rambling is to head for tree cover. Living in a concrete jungle might present fewer options than being out in the sticks, but even a visit to a local park or botanical garden could help you keep your cool. In fact, research led by the University of Surrey in the UK has found that botanical gardens can lower the temperature of inner city air by as much as 5 °C. Wetlands and rain gardens are not far behind in the cooling stakes, at 4.7 and 4.5 °C respectively, trees planted along streets also lowered air temps by 3.8 °C while city parks managed 3.2 °C. The potential cooling effects of GBGI infrastructure across 10 categories selected in the study Prashant Kumar et al \"We have known for some time that green spaces and water can cool cities down,\" said Professor Prashant Kumar, founding director of the Global Center for Clean Air Research at the University of Surrey, as well as professor and chair in Air Quality and Health, and co-director at the Institute for Sustainability. \"However, this study provides us the most comprehensive picture yet. What's more – we can explain why. From trees providing shade, to evaporating water cooling the air.\" The paper notes that an air temperature of 40.3 °C (104.5 °F) broke records in the UK on July 19, 2022, some 62,862 deaths were linked to summer heat across Europe in the same year while the 2003 heatwave in Europe led to an economic loss of €16 billion thanks to drought and crop failures. The team of 29 scientists from the UK, Australia, Brazil, China, Hong Kong and the US also says that the IPCC reckons that \"green and blue urban infrastructure elements are particularly effective in reducing air temperatures in cities.\" From a pool of more than 27,000 research papers, the researchers selected 202 for meta-analysis based on a number of urban green-blue-grey infrastructure categories – including parks, engineered greening projects, wetlands, green walls, parks and botanical gardens. Trees and plants, for example, help reduce heat by reducing the amount of direct sunlight reaching the ground, while also releasing moisture into the air. Water bodies cool the surrounding environment via \"evapotranspiration, shading, the albedo effect, groundwater recharge and temperature buffering\" and could also serve as heatsinks, cooling during daylight hours and offering warming potential at night. Green roofs and walls not only help insulate buildings, but also reduce heat absorption, and vegetation can serve as windbreaks for natural ventilation. Table showing the cooling effects of several green spaces and waterways University of Surrey We've already seen a number of architecture projects around the world employ large amounts of greenery to both enliven facades and promote local cooling, along with beneficial landscaping. The researchers conclude by stating that \"all urban green-blue-grey infrastructure types provide cooling benefits\" and that \"nature needs to be brought back into densifying and expanding cities and any opportunity to expand plant cover on the ground, podiums, wall and roofs must be taken.\" But they also recognize that there isn't one simple solution to suit every locale, and much will depend on effective planning – \"before selecting suitable urban green-blue-grey infrastructure interventions, it is necessary to assess the local context, environmental conditions, available resources and the budget to ensure their long-term effectiveness and avoid possible drawbacks.\" \"Our paper confirms just how many ways there are to keep cool,\" added Professor Maria de Fatima Andrade of the Atmospheric Sciences Department at the University of Sao Paulo, Brazil. \"But it also reveals how much work is left to do. Institutions around the world need to invest in the right research – because what’s very clear from our study is that there is no one-size-fits-all solution. It depends on what works for your community.\" The study is open access via the journal The Innovation. Source: University of Surrey View gallery - 3 images",
    "commentLink": "https://news.ycombinator.com/item?id=39524164",
    "commentBody": "Botanical gardens can cool city air by an average of 5°C (newatlas.com)365 points by Brajeshwar 20 hours agohidepastfavorite145 comments Mizza 19 hours agoI've become really obsessed with 'Miyawaki Forests' lately - small, dense, urban forests which can reach a mature state in only a few years. I hope they start showing up everywhere. Fuck minimum parking requirements, where are the minimum forest requirements? reply Affric 13 hours agoparent> I hope they start showing up everywhere. For people in urban hellscapes? Yes. For non-human animals? More complicated. These sorts for forests are generally dominated by “edge species”. Edge species generally do relatively well out of habitat fragmentation. The most sensitive species that need a lot of depth in forest generally don’t do well with these small pockets. This is not to say that Miyawaki forests aren’t an improvement, just that their “conservation” value is limited and still need to preserve/manage huge amounts of actual contiguous forest with a minimum perimeter compared to the area covered. reply ggm 9 hours agorootparentI don't disagree but if the choice is between edge forest and species support for species in edge forests, or carparks and species support for carpark friendly species, I would prefer to have edge forest species. This is not re-wilding. We aren't trying to get urban badgers and lions. So, in summary I think your critique is true but misplaced. Consider the viable alternatives, not the pipe dream. When we de-populate on the next virus, we can re-forest for bears. reply Affric 5 hours agorootparentWe actually can affect development patterns, deforestation, and afforestation through democracy. I am not against Miyawaki forests but I think we need to recognise they are largely for people. They vastly improve important metrics for us but in the press for Miyawaki forests the benefits for forests are sometimes conflated with the benefits of Miyawaki forests. It’s a little like when growing afforestation for the sake of timber is sold as a benefit to the environment as though it’s just like any other forest. TFA is about urban overheating. Biodiversity is a powerful idea and valued aesthetic in our society but ultimately biodiversity will only be conserved through a cessation of deforestation and significant afforestation on large scales. reply TulliusCicero 12 hours agorootparentprevThat's fair. It's definitely a complementary thing, you want both types of forest I'm sure. Small forests don't cover all the needs, and large forests don't fit everywhere. reply jimkleiber 16 hours agoparentprevFrom minimum parking requirements to minimum park requirements :-) Ok maybe minimum forest requirements is more accurate but had to do it reply nemo8551 36 minutes agorootparentI like the first one, down with minimum parking requirements we want more requirements for minimum parks! RaRa. reply FredPret 18 hours agoparentprevIncredible - apparently you can do one in your back yard! https://canadiangeographic.ca/articles/the-many-benefits-of-... reply Aromasin 17 hours agorootparentI'd love to know if there was an equivalent one for species native to the UK. EDIT: Found a great list after a little investigation! https://www.north-norfolk.gov.uk/tasks/projects/miyawaki-for... reply sp332 16 hours agorootparentIt doesn't always have to be trees. Hedgerows can be good too. reply ajb 13 hours agorootparentAnd a good thing too, because trees in London cause havoc with all the Victorian houses with no foundation in the modern sense. reply pvaldes 12 hours agorootparentprevThat 3x3m project shown is not realistic. Not for a newbie and probably not easy to keep from falling apart for an expert. But yes, wild hedgewoods of a mix of useful shrubs are totally doable even in really small spaces. I had designed a few. They are low maintenance, beautiful, useful, funny, and tasty and everybody should have space for one of this wildlife lifesavers in their gardens. reply crazygringo 18 hours agorootparentprevI'm having a hard time picturing what they look like -- and the photo in that article is unrelated. Googling them, I can find images of a few proof-of-concept plots in the middle of fields but I can't find a single example of how they might integrate with a city. It would be nice to see some kind of before-and-after, even if just an illustration, to get a sense of how they would fit into a cityscape aesthetically and practically. reply burkaman 17 hours agorootparentHere's a NYT article with some good photos, gift link: https://www.nytimes.com/2023/08/24/climate/tiny-forests-clim... Here's a photo of what it looks like when it's first planted: https://voice.somervillema.gov/miyawaki-micro-forest reply 3D30497420 17 hours agorootparentAnother good article: https://www.creatingtomorrowsforests.co.uk/blog/the-miyawaki... reply Luc 16 hours agorootparentprevPDF with lots of pictures and information: https://urban-forests.com/wp-content/uploads/2020/05/Report-... reply jay_kyburz 11 hours agorootparentprevI bought three boxes of Microforest from Edwina Robinson here in ACT Australia and planted them in my front yard. Here is an article about her project. https://www.abc.net.au/news/2021-07-08/act-micro-forests-in-... It's been two years, the some of the trees are well over 2m tall already. reply defrost 9 hours agorootparentHere's video footage of the linked 2021 Canberra plantings from nine months ago - mid 2023. https://youtu.be/P2_YVkfzpnE?t=23 reply lostlogin 10 hours agorootparentprevPossibly a misconception of mine; Australia has some added complexities that not all of us face. What creatures will my mini forest it attract and will my little forest set fire to my home? I’m in New Zealand where life is less spicey. reply stubish 8 hours agorootparentYou choose what species get planted, so you can control all that. Plant a grove of mainly sheoak for example, and you have fire retardant species that discourage snakes. reply JadeNB 17 hours agorootparentprevThey're surely extremely region-specific—sourcing with native trees is a big part of their sustainability. Do you know anything about where to find local growing guides for different regions? reply burkaman 16 hours agorootparentHere's one site that seems solid: https://nativeplantfinder.nwf.org/ Note though that your climate is changing, and what was historically considered native for your region may no longer be a good fit: https://heatmap.news/is-native-gardening-becoming-pointless reply darth_avocado 15 hours agoparentprevThe idea that everything needs to be a dense forest is a problem. What is more helpful is a variety of ecosystems available. I don't have a lot of space, but I managed to have 4 ecosystems in all of my yards with 200+ species of plants: California chaparral, Coastal forest, Xeriscape and a wildflower meadow. Cities could also build such environments and that would be more positive than just planting Miyawaki Forests everywhere. reply binonsense 12 hours agorootparentI can’t imagine these forests will pop up “everywhere”. Seems like a groundless concern. reply pvaldes 9 hours agoparentprevAs a rule of thumb if is associated to a fancy name, it has been invented before, and the plan will not fulfill its promises. \"Forests will reach a mature state in only a few years\" is just other of this marketing statements that sound nice, but are wrong. > Fuck minimum parking requirements, where are the minimum forest requirements? I want a t-shirt with this phrase. Is simply brilliant reply mobilemidget 17 hours agoparentprevAccidentally I recently looked up when a bunch of trees are, or can be called a forest. Which I learned is minimal 500 square meters. reply quixoticelixer- 11 hours agorootparentThere isn't actually a strict definition of what is or isn't a forest reply lostlogin 9 hours agorootparentIf it’s small area you can’t see a forest, you can see trees. reply thfuran 16 hours agorootparentprevHow many trees have to be in that region? reply andsoitis 18 hours agoprevIf your city cannot afford botanical gardens, then planting trees on sidewalks, more boulevards, and other places not only bestow ecological benefits but is also good for the human psyche and reduces crime. https://www.fs.usda.gov/research/treesearch/40701 reply sokoloff 16 hours agoparentDoes planting trees reduce crime? Or are areas that have planted trees areas that also tend to have reduced crime? The abstract of that paper indicates an inverse correlation between trees and crime, but stops well short of claiming or proving a causal relationship. reply B56b 14 hours agorootparentThe correlation they saw was after controlling for potentially confounding variables, like income level, housing stock, density, and demographics, as explained in this article: https://caseytrees.org/2023/09/mythbusting-trees-and-crime/. So of course it's not proof of causation, but reverse causation(nice neighborhoods lead to more trees planted) seems unlikely to explain the effect. reply lhomdee 11 hours agorootparentIndeed. Islington in London was famous for having few trees and lots of crime. Now it’s a nice fancy area that still doesn’t have a lot of trees. reply lostlogin 9 hours agorootparentThere is about white collar crime lurking here somewhere. reply ggm 9 hours agorootparentThe crime is understood to be street crime. The bankers and lawyers would have to decide to insider-trade on the pavement outside the pub, for this crime to become street crime. Or, kick people because street crime is often crime of violence. So, get that suit on, start dealing ahead of the market, and kick a beggar. THEN you can contribute to the statistics. reply kwhitefoot 15 hours agorootparentprev> Or are areas that have planted trees areas that also tend to have reduced crime? Perhaps fake it till you make it? Worth a try surely. reply zahma 13 hours agoprevI hope this isn’t a revelation to anyone at this point. Of course greenery reduces heat, but more than anything it means removing concrete, which mitigates the urban heat island effect. (Urban heat islands absorb heat energy during the day, amplifying extremes, and release heat at night, making it impossible for effective cooling.) And yet there is still so much resistance or otherwise apathy to the idea of planting more trees and removing space for vehicles — as if it’s merely some hippy-dippy shit only good for gentrification. reply vetinari 13 hours agoparentPlanting more trees and removing space for vehicles are two different things; it is not necessary to make them dependent. Those who do, usually do it for their anti-vehicle agenda, and planting green is only an excuse / a tool, not the objective or intent to improve the environment. If you want more space for parks and green, you can do it also other way. For example, like Hausmann did in Paris. reply zahma 13 hours agorootparentIn a hierarchy of urban planning, I’d favor removing space for cars over demolishing precious space for affordable housing. To that effect, I wouldn’t point to Haussmann who bulldozed plenty of homes and neighborhoods for his unified vision of Paris connected by major thoroughfares. As a result, we have few parks and the city lacks any kind of real arboreal shelter except on some of the boulevards. He was a visionary, but he didn’t have scientific papers or the threat of climate change to contend with. The idea I have in mind is that the control over cities has been wrested from its citizens. A special car commuting class has more comfort moving about a city like Paris than regular inhabitants — but at what cost and borne by whom? Removing space for cars means removing vehicles, which re-empowers city-dwellers, cleans the air, and cools the city. reply woodruffw 11 hours agorootparentprevIn much of the US, the two are interdependent: to plant more trees on streets, for example, many US cities will need to trim the arterial roads that swallowed up neighborhood sidewalks half a century ago. reply ddalex 17 hours agoprevI wonder if they could cool down a desert; let's say, make nuclear reactors and plant them on the edge of Sahara, and do one thing with them: desalinate water from the sea; use the water to irrigate large portions of the desert, and plant them with bamboo; this will cool the desert, sequester CO2, and have global influence on the climate warming. Back on the envelope calculations: 3.5 kWh/m^3 to desalinate water, 10 nuclear reactors, 1sq meter for a bamboo plant, you can water and grow 5.5 billion bamboo plant; let's say each plant fixes 10kg of CO2 per year, you reduce 10% of world's emissions in one clean sweep, for a total investment of maybe 100 billion USD reply araes 14 hours agoparentThere have been a couple attempts to do this previously. In India, there was one version used as a physical barrier on a customs line for 450 miles. Also happened to improve the area. https://en.wikipedia.org/wiki/Inland_Customs_Line#Great_Hedg... https://amocarroll.com/projects/tracing-the-great-salt-hedge China has the China's Three-North Shelterbelt Program where they're trying to hold back the desert in North China and Inner Mongollia. https://en.wikipedia.org/w/index.php?title=Three-North_Shelt... Based on reports, it has issues with tree survival, yet seems to be making progress based on aerial surveys. https://www.sciencedirect.com/science/article/pii/S259033221... There's also an attempt in Africa in the Sahara that a bunch of countries signed on to. Unfortunately, their commitments have mostly amounted to talk without much funding or governmental support. Seen a few videos of locals who seems to believe in the idea, its just not getting much large scale help. https://en.wikipedia.org/wiki/Great_Green_Wall_(Africa) I also use Ecosia (https://www.ecosia.org/) as a web browser, and they supposedly plant trees based on number of searches and a percent diversion of search revenue. Seems to at least have some photographic evidence of money actually being spent somewhere. Senegal's an example with desert work. Seems to have evidence that at least some amount of trees are being planted with videos (harder to falsify). https://blog.ecosia.org/senegal/ https://blog.ecosia.org/tag/senegal/ reply jamie_ca 16 hours agoparentprevDesalination doesn't produce (freshwater + salt), it produces (freshwater + saltier water). Dealing with the waste brine is a challenge if you want to process that much in such a localized area. reply quesera 15 hours agorootparentThe real problem is that the cost would be outrageous. If you go this route for greening the Sahara, you could allot 5% for the evaporation ponds to turn brine into dry salt. There are other reasons it will never happen, but this one is solvable! :) reply lostlogin 9 hours agorootparentThat’s a vast amount of salt. They can go from destabilising the world energy supply to messing with world salt supply. reply marcosdumay 15 hours agorootparentprevThe area is very clearly not \"localized\". reply downrightmike 13 hours agoparentprevYou need a ton of water just to run the reactors and the droughts have already required ones that are in desert like the Palo Verde plant to reduce output. reply BurningFrog 13 hours agoparentprevSaudi Arabia is building a mega-project that's kinda like that: https://www.youtube.com/watch?v=-13bKIS75Gk&ab_channel=TheIm... reply lostlogin 9 hours agorootparentThanks for that. I wasn’t clear on how they power it. Solar? Oil? reply xbmcuser 16 hours agoparentprevyou can't do mass change like that. This will change weather patterns could result in a lot of rain being sucked into the Sahara and make South America a desert. https://news.mongabay.com/2015/03/how-the-sahara-keeps-the-a... reply com2kid 15 hours agorootparentHuman activity has lead to the Sahara being much larger now than it was in the past. There are ongoing efforts (https://www.youtube.com/watch?v=WCli0gyNwL0) to try and keep the Sahara from growing any more. reply pkphilip 19 hours agoprevI have always been very curious as to why many cities do not push for more forests to cool down the place. I studied in a college with a lot of trees on campus and the temperature was at least 5 C cooler than just outside the college. reply FirmwareBurner 19 hours agoparentBecause parking spaces or other such things are more profitable for business owners and the city. Nobody can monetarily profit from trees, unless you were to charge people money for time spent under their shade. reply nonrandomstring 16 hours agorootparentIn Britain I've seen trees planted in urban spaces. And then local residents come and pour rock-salt and weed-killer on the saplings there - because it stops them parking. reply graemep 12 hours agorootparentOn the other hand in Sheffield there was a huge movement from residents to stop the cutting down of trees. Everyone I know there supported it. reply lostlogin 9 hours agorootparent> in Sheffield there was a huge movement from residents to stop the cutting down of trees I cynically searched as I was sure the trees would all have been cut down. They weren’t. There were wrongful arrest payouts, more trees planted and everyone started working together to plant more trees. Is this really correct? https://en.m.wikipedia.org/wiki/Sheffield_tree_felling_prote... reply nonrandomstring 8 hours agorootparentI think about doing this. Just guerilla tree planting. Harvest saplings from where they're obviously not going to thrive, grab a foldable entrencher and just hit spots that need a bit of reforestation. However I suspect most of them wouldn't take and that there's a bit more to successful tree planting than I suppose. reply bongodongobob 18 hours agorootparentprevYou act is if the people living there don't want parking spaces. reply c0nfused 18 hours agorootparentAs city dweller, I really would like less parking in my city. Turns out surface parking is a better $/sqft than garages once you count maintenance. This means that the core part of the city where density is greatest is ringed by a 2-5 block wide wasteland of surface lots. Its not great. Especially now that work from home is a thing and the divide between people who live here and people who drive here to work is obvious because the suburb people aren't here any more but their parking spaces still are reply mjevans 15 hours agorootparentThe parking spaces are still there because the city's 'density' or 'daytime population' was pumped by ecologically unsustainable commutes. The US has never had a high level civic planning process or ability. Housing ends up built where-ever, and it's often cheapest to go built it in places with less regulation. Like wild frontiers in not even states. Or in areas outside of city limits as a tax dodge. There also aren't formal processes for renewing areas; instead informally they're allowed to decay and crime rise, and eventually reach a point where it becomes 'economically viable' for building something new. Those lots exist because there's still enough whatever is desired in the city you live in, probably too much retail and office space. Probably not enough apartment / condo / housing space, but none of those investors want to admit their market was over-valued and de-value the present investments so they'll happily keep supply low and rents high. reply acdha 16 hours agorootparentprevParking spaces by definition benefit people who drive, which usually means someone well out of walking distance. That leads to some interesting dynamics where people who are enough richer to have nice separated homes use their social status to demand parking everywhere even though the main thing people near those spaces get out of it is negative health impacts. One interesting angle involves small businesses: you’ll often see owners interviewed complaining about losing parking spaces. This makes no sense for a local business, and there are decades of studies showing that pedestrian/transit/bike traffic generates more revenue for small businesses (if you’re already in the car, you’re probably continuing to a big store) but it makes total sense when you realize that the owners are far more likely to live out in the suburbs and are making the mistake of assuming this is also true of their customers. There’s a staple in some city planning debates of noting that the people complaining loudest about how their customers won’t stop if they can’t park right in front are often leaving their own cars in those spaces all day. reply devilbunny 13 hours agorootparent> pedestrian/transit/bike traffic generates more revenue for small businesses Sure, if you have a walkable/transitable/bikeable city. If you don't, then losing parking spaces can be an issue. I would have to walk for 24 Google Maps minutes to get to the nearest store of any kind. And I'm close; people farther down the main road that feeds my street could face almost an hour's walk each way (with no sidewalks or shoulders; you're walking in a ditch) to get to the same place. Several large hills along that route and a hot, muggy climate means that nobody is going to bike it. My niece, from Colorado, came to visit her grandfather (my dad). She wanted to go for a hike in the South in July. I said sure, I'll take you. Five minutes into it, she said, \"Now I know why everyone is fat here. This is miserable.\" And my reply was \"Yes, and this isn't as hot or as humid as it gets. It's actually not that bad today.\" reply TulliusCicero 10 hours agorootparent> Sure, if you have a walkable/transitable/bikeable city. If you don't, then losing parking spaces can be an issue. But a huge part of what makes cities terrible for walking/biking/transit is having too much parking. Shop entrances being right next to the sidewalk is ENORMOUSLY more pleasant for pedestrians compared to needing to walk across a veritable sea of asphalt, as is the case in typical American strip malls and similar developments. > I would have to walk for 24 Google Maps minutes to get to the nearest store of any kind. Probably a zoning/density issue. We've intentionally designed our cities to be shit for walking and to our credit we've succeeded enormously. > Five minutes into it, she said, \"Now I know why everyone is fat here. This is miserable.\" And my reply was \"Yes, and this isn't as hot or as humid as it gets. It's actually not that bad today.\" Nope, that's not it at all. The American South has a somewhat similar climate to Japan, and even the warmer parts of Japan have way skinnier people. I lived in Alabama for a couple years, and I'd say it's mostly just transportation design and culture around eating. I biked a bunch in Alabama and it was fucking terrible. That shit sucked. Granted, biking almost anywhere in the US is pretty bad, but Alabama was definitely worse than some of the other places I lived, and infrastructure was the biggest part of that. reply acdha 12 hours agorootparentprevWe’re talking in the context of cities so I was only referring to more dense scenarios. I agree that rural or really low-density suburban communities are different. The key point is really just the function of distance: people who live near a small shop will go there due to convenience. If it’s far enough to need a car, they’ll probably keep going to a bigger shop with lower prices because the cost of having and using the car is already incurred and the cost of doing anything else is greater. reply TulliusCicero 10 hours agorootparentprevI'd love to see fewer parking spaces if it meant better transit/walking/biking, and yeah trees are part of that (especially for walking). reply NewJazz 18 hours agorootparentprevStreet parking in a lot of cities in america is notoriously \"free\". I think somebody wrote an article about how in SF, their car pays less rent per sqft than they do. reply kapp_in_life 17 hours agorootparent>their car pays less rent per sqft than they do This shouldn't be surprising though. Cars don't need heating or cooling or sewage or a roof or ... reply lostlogin 9 hours agorootparentThey often get most of that with a garage. No sewage is needed, though runoff from parking should really be treated before being dumped into waterways. reply yifanl 18 hours agorootparentprevPeople who live there profit from the trees through quality of life benefits (such as being 5 degrees cooler). Maybe part of the problem is that a lot of landowners tend to not live in the land they own, so they can't see these profits. reply FirmwareBurner 18 hours agorootparentI was talking about monetary profit not quality of life profit. reply yifanl 18 hours agorootparentMoney is just an abstraction for quality of life :) reply is_true 16 hours agorootparentprevAdd a tax for those that don't have trees. There you have your incentive. It's so easy, unfortunately taxes aren't often used this way. reply nxm 19 hours agoparentprevBecause more housing is seen as a more immediate and higher need reply kjkjadksj 18 hours agoparentprevMost land that isn’t already a park is privately owned. Most cities can’t afford to buy out a forests worth of real estate let alone clear it and replant it. reply BurningFrog 18 hours agoparentprevThe whole point of a city is to concentrate human activity in a small area. reply acdha 18 hours agorootparentThat doesn’t mean you can’t have trees: a high-rise building next to a park is quite dense, as are tree-lined streets. The problem is those streets: the 20th century model focused on maximizing individual vehicle usage, which meant lots of open space for safe operation and subsidized storage. Cars can’t go around trees like pedestrians or bicyclists and owners don’t want branches falling on their parked cars, so anywhere there isn’t enough space for both it tended to result in more heat-amplifying asphalt. reply crazygringo 18 hours agoprevThis feels misleading. I totally believe that botanical gardens cool the air within them. That's what happens when you have an area full of trees and shade, with denser vegetation than a park. But I have a hard time believing that they have any significant effect on the city air 5 or 10 blocks away, where the asphalt is baking in the sun. So I'm not sure what the point of this article is, because it's not like we're going to replace half the blocks in a city with botanical gardens, as nice as that would be. Meanwhile, the article claims claims planting trees on the street has less effect, but surely is far more important -- because it affects the whole city, rather than a small localized area in and around a botanic garden? So there seems to be a major flaw in this article, in that it's comparing the cooling effects of various interventions (botanical gardens, street trees, etc.) but without ever specifying how the sizes or densities are being compared. Honestly, I can't even imagine what a unit of comparison between botanical gardens and street trees would be, since botanical gardens replace streets and buildings, while street trees merely add to them. It's apples and oranges. reply zdragnar 18 hours agoparentI think the article addresses this fairly well. In addition to shade, evaporation from open water and plant leaves contributes, as does the soil acting as a heat sink. Botanical gardens are only slightly more effective than trees over roadways from their study, so shade is likely the strongest factor, but the others clearly play a part- from cooling down enough overnight compared to roadways and cement to the evaporation from the denser vegetation having a stronger effect. The thing that I missed was how such a garden compared to an open, grass park. The difference in vegetation density would be clearer, I think, and might better explain the difference measured between trees over roads and gardens. reply athenot 16 hours agorootparentFrom an energy perspective it makes sense, since at least some of the solar energy hitting tree leaves is used for photosynthesis, and reducing Carbon out of its oxydized state. So it's not just accumulated/reflected like for pavement. reply mlyle 15 hours agorootparentEffectively none of the incident energy is used for photosynthesis. Much bigger effects are reflecting energy well above things that can store heat, and acting as evaporative coolers. reply onlyrealcuzzo 15 hours agorootparentprevInteresting how easy it is to mitigate 5C - and yet we think the world is going to end if temps increase another 2C - when we are basically in an Ice Age and the Earth has only been cooler for brief periods of time in the last 500M years: https://www.climate.gov/news-features/climate-qa/whats-hotte... Luckily, fossil fuels are going to get phazed out massively over the next 50 years strictly due to economics. reply macromagnon 12 hours agorootparentThe increase in temperature is just one of the issues. It has probably been mainly publicized as it's an easy \"key performance indicator\" to get the point across/that can be succinctly referred to. Sea level rise, ocean acidification, global weather pattern shifts, etc. are all also major problems. reply Aloisius 14 hours agorootparentprevEasy to mitigate it in urban environments which are heat islands due to the low albedo of man-made surfaces. 99% of the earth, however, is not paved. Reducing heat on a global scale is a wee bit more difficult. reply emj 14 hours agorootparentprevYou are mistaking global for local, and 50 years is too late. I am positive I think some of us will survive. reply Jabbles 14 hours agorootparentprevDid you read the link you posted? Specifically the update at the top? reply kevstev 16 hours agoparentprevComplete anecdote here, but I live on a park that is about two acres big. Its filled with large old (~100 years) trees and lawns, though it does also cram in a basketball court and two tennis courts. In the summer heat, when we walk around our area, the temperature astonishingly drops about 5 degrees once you get within 2-3 blocks of the park. Its striking in how noticeable it is. I have no idea why, but it seems even a bit of green space can have a big impact. reply cnity 17 hours agoparentprevThey do have a significant effect. Trees scoop up rain from the soil, lift it through their trunks and up into the leaves where little mouths (stomata) in the leaves deposit that water back into the air in a process called transpiration. It is actually in this way that places deep inland can still receive rainfall. Without this process clouds wouldn't be able to make it far inland. reply ako 15 hours agoparentprevHigh temperature air rises (by expanding and becoming less dense), the void is filled with low temperature air. So a colder forest will start a wind outward of the forest towards the warmer areas, thereby distributing the colder air into the surrounding area. You can see the same effect mostly in spring in coastal areas, when the land is heated faster than the sea. Hot air over land will rise, colder air from the sea will move in, causing thermal wind, making the coast a lot cooler. This can cause enough wind for kitesurfing or wingfoiling. reply Anotheroneagain 15 hours agoparentprevI think it's misleading for a worse reason: These trade temperature for humidity. They seem to work great as long as the temperatures don't go too high. They become hot ovens when they would be the most needed. reply quixoticelixer- 5 hours agorootparentIts good to trade temperature for humidity reply timeon 18 hours agoparentprev> But I have a hard time believing that Have you built your argument against the study on belief? reply mariusor 18 hours agoparentprevI don't see anywhere in TFA where it's implied that the temperature drops as an average, or that somehow it extends past the green area. I feel like you've been misled by a strawman that you created yourself. reply nottorp 17 hours agorootparentEmpirically, it extends a tiny bit past the green area. When I go for walks in summer in my city, it's noticeable how the temperature drops while on the sidewalk when I walk past a green area as opposed to past a building. reply cnity 17 hours agorootparentThermodynamically it must. High temperature will flow towards low temperature areas like a heat-sink, where it is cooled by the shade and vapour. reply ako 15 hours agorootparentIt’s actually the opposite. High temperature air rises (by expanding and becoming less dense), the void is filled with low temperature air. So a colder forest will start a wind outward of the forest towards the warmer areas, thereby distributing the colder air into the surrounding area. reply cnity 17 minutes agorootparentServes me right for thinking two-dimensionally! reply BurningFrog 18 hours agoprevReading past the headline, the effect is from trees providing shadow, and evaporating water cooling the air. You don't need any actual botanical gardens. reply tonmoy 18 hours agoparentBut it’s probably the easiest and cheapest way. Another plus point would be creating habitat for smaller animals and morale boost for the city inhabitants reply BurningFrog 13 hours agorootparentLooking out my window, I see trees planted on the sidewalk along a road. It takes little space away from pedestrians, but provides a lot of shade. That seems both easier, cheaper and better that taking up whole city blocks. reply Cthulhu_ 18 hours agorootparentprevWell, both require making land available, and while amenity gardening is manageable, a botanical garden is often a research site that requires a lot of expertise to set up and maintain. Mind you, that's just fine, the county can and should hire people. reply Filligree 16 hours agorootparent> botanical garden is often a research site that requires a lot of expertise to set up and maintain But it doesn't have to be, right? It's just that we don't have very many, so the ones that do exist end up being research sites. reply GrumpyNl 18 hours agoparentprevWe need more trees, i am shouting that for years. reply vondur 16 hours agoprevI think this should be common knowledge that planting trees and having native green spaces in cities helps keep things cooler. In my neighborhood in Los Angeles, we have people who don't want trees in their yards and one who actually damaged a city planted tree in order to get rid of it. To a certain extent I get it, trees have to be maintained, which does cost money. We have a large and fast growing pepper tree in our yard, which is just over the line where the city would maintain it. We usually spend $700/year to have it trimmed back from hitting the house. I really appreciate how much shading it provides in the late afternoon in the summer. reply LispSporks22 12 hours agoprevI didn’t notice it until I got a motorcycle and started riding, because there’s very little between you and the environment and you’re moving so fast you can definitely feel the cooler and hotter parts of a city. Areas with trees, not necessarily sharing the road definitely feel a few degrees cooler reply Ekaros 16 hours agoprevHmm, what is the general availability of water resources these would need in areas that would benefit most of them? If there is already droughts I don't think too much water usage could be afforded adding more vegetation. reply bluGill 15 hours agoparentIf you are planting native trees there should be no problem - there have been droughts before and so the trees can handle them. You might need to water them for the first 5 years, but after that they should be okay. Select trees that are not native (or native species but from a very different location) and you can run into problems. reply quixoticelixer- 5 hours agorootparentNative trees aren't always the 'best' option in modified urban environments. Just becuase they grew on what used to be there doesn't mean they will like what is there now reply p0w3n3d 13 hours agoprevAny grass can cool the city 5°C but city need to maintain it and first of all, need to sacrifice the money the city would make off of building another four flats on it reply quixoticelixer- 5 hours agoparentAny grass can not cool the city by 5c reply gatane 16 hours agoprevAnother reason to do guerrilla gardening, or seed bombs: https://en.m.wikipedia.org/wiki/Seed_ball#Seed_bombing reply pvaldes 9 hours agoparent> seed bombing Please don't encourage anybody to do this. Let it to people that knows what they are doing. Invasive species burn millions and aren't a joke reply walthamstow 17 hours agoprevI'm not sure. I live in London, 51 degrees north. We have a lot of parks in London, but the bus stops near them still have deep grooves of melted asphalt from recent heatwaves. reply n4r9 17 hours agoparentPerhaps it would be even worse without the parks? This article suggests that variation in temperature across the city does correlate with vegetation cover: > the Kilburn and South Hampstead area, with 38% vegetation cover, experienced heat over 7°C hotter than Regent’s Park, with 89% vegetation cover, a short distance away. https://www.pbctoday.co.uk/news/digital-construction-news/bi... reply pvaldes 9 hours agorootparent> This article suggests Is more like a proven fact. Temperatures measured on hard landscape of modern parks based on stone is consistently higher than on old fashioned parks with big trees and fallen leaves. Sadly, cities still love this sun scorched inhospitable parks with passion because: 1) civil responsibility. A branch can kill a person and politicians hate this possibility 2) they are much easier to tidy up and much cheaper to maintain. Cheaper in the sense of \"people will pay for their air conditioner, not us\". 3) Vehicles can pass easily over stone surfaces (Also cleaning vehicles). Is not so easy to clean and drive over gravel reply lostlogin 9 hours agoparentprev> but the bus stops near them still have deep grooves of melted asphalt from recent heatwaves. Are you sure it isn’t from massively heavy busses repeatedly taking the same route across ‘not-that-hard’ tarmac? reply walthamstow 1 minute agorootparentThe grooves are at the stops, where a double-decker bus rests for 30-60 seconds on baked tarmac to (un)load passengers. Over years of cycling around London I have observed new grooves in the days after heatwaves reply Kon-Peki 17 hours agoparentprevI used to live in Chicago, and they managed this by putting a concrete pad at the bus stops that were high-frequency enough to get the grooves. The concrete pads are not bus-sized! They are only placed where the bus wheels are when the bus comes to a stop, with a little bit of a buffer since the bus doesn't stop in exactly the same place every time. reply inglor_cz 16 hours agoprevAnecdotally, Spanish cities seem to have really beautiful and well-kept gardens. Might have something to do with mitigating the hot climate. (Córdoba during the summer is a veritable oven.) reply nhggfu 6 hours agoprevshame they used an image of a table, instead of a html table. [accessibility fail] reply Solvency 19 hours agoprevNow, if only we can do something about the absolutely endemic heat desert effect we've created by caking our country in massive black asphalt parking lots and 6-lane freeways. Nope, can't examine that. Parking lots are peak human design. The most logical design solution for our species. reply 01HNNWZ0MV43FF 18 hours agoparent\"The road to hell is paved with asphalt\" saw this here on HN not long ago - https://devonzuegel.com/the-road-to-hell-is-paved-with-aspha... They mention less heat as one of the multiple benefits of pavers / bricks. I used to dislike them by default - \"They're bumpy\". They're not bumpy. There's a shopping center in my town, and even a new Taco Bell, that use pavers for their parking lot, and I can't even notice. We could probably do pavers for new parking lots and keep asphalt / concrete for heavy-duty stuff like interstates and roads over 30 MPH and not lose much except the up-front cost of pavers. (But hey if Taco Bell thinks they're worth it...) reply CalRobert 15 hours agorootparentBut bumpy is good!!!! A bumpy street is one where you drive slowly and don't run over children riding bikes to school. A bumpy street is one where you pay attention. A bumpy street says \"you may drive here but this is not a space _just_ for your car\". If only they were more common outside the Netherlands. I love my bumpy, brick, tree-lined, narrow, street. reply dublinben 15 hours agorootparentprevEvery residential street should be paved with bricks or other paving stones, instead of asphalt. It's safer, because people drive more slowly. The maintenance costs are also lower. reply quesera 15 hours agorootparentBricks and pavers are very difficult to plow safely. They are also more expensive than asphalt. But for warm, affluent locations, they make sense. reply apercu 18 hours agorootparentprev\"Bumpiness\" could be climate related - I've spent a lot of time in the upper midwest US and Canada, the freeze/thaw cycles mean things move in the earth. reply Filligree 16 hours agorootparentIf you've got freeze/thaw cycles, then your asphalt roads will be bumpy as well. Trust me on that one. reply kwhitefoot 13 hours agorootparentOnly if the foundations are bad and the road surface is not rated for the axle load of the vehicles that drive on it. I live in Norway where it is hovering around freezing just now. The only places where this affects the road is where water has penetrated the foundations in such a way as to wash away some support or where heavy vehicles have cracked the road surface allowing water in which subsequently freezes. If the road is properly constructed and maintained with sufficiently good drainage on both sides frost heave (telehiv in Norwegian) should not be a problem. reply Filligree 31 minutes agorootparentI grew up in Northern Norway, and pretty clearly there are a lot of roads with telehiv. ;-) You're probably right about foundation quality. But there sure are a lot of roads that didn't get that right. reply freeone3000 16 hours agorootparentprevIt might honestly be easier to fix freeze-thawed cracked pavers than having to rip up asphalt and lay it back down. reply NikkiA 17 hours agoparentprevTBF, my experience of america when I lived there, was that black asphalt was far less common than light grey (and thus higher albedo) concrete for both. Increasing albedo is considered to be one of the geo-engineering solutions to try. reply inglor_cz 16 hours agoparentprevI live in a place where we have a Tesco mall with a big parking lot nearby, but then I have to walk a path through a green area with mostly grass, but some trees and bushes as well. The temperature difference is staggering. In hot summer, the parking lot is unbearable and the green area feels much better. In early spring/late autumn, the parking lot is uhm-okay (though still ugly), while walking through the green area gives you shivers: cool and wet wind. Only in deep winter, during the freezing days, both areas feel the same. reply o_____________o 19 hours agoparentprevObligatory mention of Not Just Bikes: https://www.youtube.com/@NotJustBikes/videos reply dunk010 14 hours agoprevExcept plants increase the humidity, exasperating conditions. reply quixoticelixer- 5 hours agoparentBut they make it cooler more than they make it more humid reply bane 16 hours agoprevI hope that the renewed interest in urban gardens and the appreciation for plant life in urban landscapes persists. The benefits can be wild in terms of improved quality of life for those living in the city. I live very near an urban core that is undergoing rapid development and densification. That core is part of a larger planned area that includes apartments, condos, town houses, and suburban style homes going back more than 50 years. The nearby suburban areas are walkable, and almost entirely embedded in so much greenery it's virtually a wildlife preserve. A local association owns some significant percentage of the land and has strict rules about development on their property which keeps it out of the hands of developers and well forested. My understanding was that all of these thousands of acres were virtually tree free farmland when it was selected for development. Now the entire area is absolutely filled with 30-70 foot (10-20 meter or so) trees planted when development started, dense undergrowth, and absolutely chock full of various kinds of wildlife like deer, foxes, raptors, and so on. Yards are allowed, but not really required, so many people have just let them go fallow and return to nature, or keep minimal outdoor areas for lawn furniture or play areas for their kids. The urban area needs a place for rainwater runoff to go, so the runoff areas dump into artificial streams which have been designated as parks, and provided with paved trails, and bridges and so on. They too have become heavily forested, the only sign that they're part of the local urban infrastructure is the occasional manhole cover. The runoff condenses into a selection of local artificial lakes that open up opportunities for waterfront property and parks, and personal watercraft and recreation areas. I live in a suburban home, 3 miles from the middle of the urban core which features an Apple store and other big named retailers, as well as offices, restaurants, recreation etc. It's a nice walk on weekends or evenings. The core is connected into the nearby major city and other nearby urban areas and the local airport via light rail. In the summer, we're about 5-10 deg F cooler than all of the surrounding areas, and much more humid in general. Because of the trees, we get very little wind. It can sometimes be difficult to predict how to dress when going out as our house sits even cooler than that, and stepping outside is still not representative of the way it feels in other nearby areas. It can be cold in our home in the early fall and late spring when the outside sits at around 20 deg C or 70 deg F. In some parts of the world this may sound absolutely normal, but here in the U.S. it's absolutely bonkers that it exists. My understanding was that it was explicitly patterned on a \"more European\" style of land development. reply RecycledEle 16 hours agoprevI wonder if the centers of cities are hotter now that they are all pavement and buildings than they were when they were grasslands or forests? Could this contribute to warming? Could warmer cities even cause us to overestimate the current temperature because the temperature 100 years ago on a prairie was less than the temperature today in a parking lot? reply bluGill 15 hours agoparentDo you want to account for the people living denser in those cities and thus freeing up room in more rural areas? reply marklubi 17 hours agoprevnext [4 more] [flagged] NeoTar 16 hours agoparentApparently not, since both terms have been around for at least three hundred and fifty years... Botanical: Of or relating to botany, or the biological characteristics and attributes of the plants with which it is concerned. (1627) Botanic: Of or relating to botany or plants; = botanical, adj. A.1. (1647) \"Botanical Garden\" has been attested since the early 1700's (https://www.oed.com/dictionary/botanical-garden_n?tab=factsh...) whilst Botanic garden (although attested from earlier) is now just listed as a synonym of Botanical Garden (https://www.oed.com/search/dictionary/?scope=Entries&q=botan...). reply burkaman 16 hours agoparentprevThat might be true in Latin but that isn't how English works. Botanic and botanical are synonyms, just like cyclic/cyclical, geologic/geological, mystic/mystical. Generally the -al versions are more common, but either one is fine. reply readthenotes1 16 hours agoparentprevApparently botanical is the preferred adjective for the garden that holds a bunch of plants. Even worse than the article talking about botanical gardens, should it not have just talked about heavily forested parks? reply loloquwowndueo 18 hours agoprevnext [5 more] [flagged] mysterydip 18 hours agoparentAs a car person, I'd love to see some kind of ordinance in my city of \"any single-story paid parking lot is required to add a rooftop park that covers 90% of the area of the lot\". I'm sure it adds to their $0/yr maintenance, but it would benefit everyone else. reply everdrive 18 hours agoparentprevThis is a straw man and does not feel particularly valid. I've never seen trees planted _in the streets_ and have always seen them planted along sidewalks. I don't believe trees steal parking spaces. Also, even with A/C, extreme temperatures can be a significant pain. Your car still gets scorching hot, and you waste a lot of energy cooling it down. (and further, it takes time for the A/C to actually start working. reply Filligree 16 hours agorootparentYou've never seen trees in the street? They're fairly common here in Dublin, either along the midline or separating cars from cyclists. reply kwhitefoot 13 hours agorootparentYou are talking past each other. They mean planted in the roadway. reply karaterobot 17 hours agoprev [–] The chart and table in that article are confusing. They seem to indicate that if a city has botanical gardens, wetlands, green walls, street trees, balconies, permeable paving, woodlands, playgrounds, adopted public spaces, and mixed biomes, the air temperature would be reduced by 35°C. If so, I'm prepared to ban all these things to prevent our cities from becoming frozen hellscapes. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Incorporating green spaces in urban areas, such as botanical gardens and parks, can reduce city air temperatures by up to 5 °C, aiding in fighting climate change and enhancing air quality.",
      "Tailored planning solutions are crucial for each community to fully utilize the cooling advantages of green infrastructure, states a study by the University of Surrey.",
      "Green spaces like street trees and wetlands play a vital role in mitigating heatwaves and creating a healthier urban environment."
    ],
    "commentSummary": [
      "The importance of green spaces in urban areas is highlighted to combat urban overheating, promote biodiversity, and cool city air.",
      "Discussions delve into the benefits and challenges of planting trees and creating mini forests in cities, examining ecological, social, and economic factors.",
      "Emphasis is placed on how vegetation helps mitigate heat absorption, decrease global warming, and enhance the quality of life in urban settings."
    ],
    "points": 365,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1709042385
  },
  {
    "id": 39523813,
    "title": "Boeing Safety Culture Criticized by FAA Panel",
    "originLink": "https://www.ainonline.com/aviation-news/air-transport/2024-02-26/boeing-missing-key-elements-safety-culture-faa-report",
    "originBody": "Menu Search LATEST POPULAR AIRCRAFT FOR SALE SECTIONS Business Aviation Rotorcraft General Aviation FutureFlight Aerospace CHANNELS Aircraft Maintenance Avionics Charter & Fractional Safety All Categories News Archive MORE Print Archives Expert Opinion In-Depth Reports Videos Webinars Airshows & Conventions Aviation Events Whitepapers ABOUT About AIN Our Writers History Advertise Contact Us Subscribe LATEST POPULAR AIRCRAFT FOR SALE SECTIONS ABOUT Search Subscribe Search Safety Boeing Missing Key Elements of Safety Culture: FAA Report Employees lack awareness of the basics in reporting safety concerns. An FAA panel has strongly criticized safety practices at airliner manufacturer Boeing. Share Post Share Print Copy Email By Gregory Polek • Senior Editor February 26, 2024 In this article Boeing 737 Series Aircraft Boeing Company More In Safety Helo Pilot Relives Dark Day, on Road to Recovery Helicopter Pilot Details Tailboom Separation Crash in NTSB Safety Symposium Accidents Utah Medevac Program Aims To Save Stricken Service Dogs It represents the third program of its kind in the U.S. Rotorcraft AviationManuals Sees Uptick in SMS Business Increase comes as attention to safety intensifies and SMS rule looms Safety ASU Unveils Lightweight E3 Night-vision Goggle The new night-vision goggle is available for orders Rotorcraft Enstrom Certifying Genesys Autopilot in 480B The three-axis autopilot features automatic recovery to near-level flight attitude Avionics Argus: Prism SMS Success and the 2024 Helicopter Market Global helicopter activity was up almost 20 percent in 2023 Rotorcraft Vita Aerospace Unveiling Rapid Extraction Device The new device enables safer hoisting of unconscious victims Rotorcraft Aircare Offers Trade-ins For Medical Diagnostic Units The company will offer its own equipment at a discount Safety AIN Products Aviation International News (AIN) Business Jet Traveler FutureFlight Corporate Aviation Leadership Summit (CALS) SUBSCRIPTIONS Subscribe Customer Service Renew RESOURCES Print Archives Expert Opinion In-Depth Reports Videos Webinars Airshows & Conventions Aviation Events ABOUT AIN About Our Writers History Contact Us Advertise Copyright ©2024 AIN Media Group, Inc. All Rights Reserved. Terms of UsePrivacy PolicyCookie PolicyContent Policy",
    "commentLink": "https://news.ycombinator.com/item?id=39523813",
    "commentBody": "Boeing missing key elements of safety culture: FAA report (ainonline.com)364 points by elorant 20 hours agohidepastfavorite297 comments hammock 18 hours agoThe deficiencies found in the report were in Just Culture and Reporting Culture. The five Key Elements of Safety Culture are: 1) Informed Culture- the organization collects and analyses relevant data, and actively disseminates safety information. 2) Reporting Culture- cultivating an atmosphere where people have confidence to report safety concerns without fear of blame. Employees must know that confidentiality will be maintained and that the information they submit will be acted upon, otherwise they will decide that there is no benefit in their reporting. 3) Learning Culture- an organization is able to learn from its mistakes and make changes. It will also ensure that people understand the SMS processes at a personal level. 4) Just Culture- errors and unsafe acts will not be punished if the error was unintentional. However, those who act recklessly or take deliberate and unjustifiable risks will still be subject to disciplinary action. 5) Flexible Culture- the organization and the people in it are capable of adapting effectively to changing demands. Sources: https://www.faa.gov/newsroom/Sec103_ExpertPanelReview_Report... https://www.airsafety.aero/safety-information-and-reporting/... reply joe_the_user 11 hours agoparentI'd note that financial markets driven reorganizations are antithetical to elements 1-4 and this explains how Boeing managed to have a culture of safety but lose it (it's often put as MD management took but an article a bit back showed that this was part of the Boeing CEO seeing the financial writing on the wall). Uh, and that happened \"under the watchful eyes\" of the FAA. The opposite of 1-4 could be described as the \"culture of lies, ignorance and fear\". Fear is a good strategy for getting people working hard (if not always well) and lies make fear universal. Compartmentalizing information is needed to allow more and more functions to be subcontracted. If the company is extracting maximum value from it's assets this year, it has no incentive to report problems that will only appear in the future - by the time the future rolls around, the share holders have their and the shell of the remaining company can be tossed away. etc. Also, another HN commentator mentioned how eliminating a culture of lies and retaliation is once it's in place. There's never a guarantee that those revealing a problem won't be punished once regulators turn their backs. And 5 is only useful once 1-4 are in place. Otherwise, it's a culture of flexibly hiding your shit in different places. Edit: This article was on HN a while back. https://qz.com/1776080/how-the-mcdonnell-douglas-boeing-merg... Key quote: These decisions, made by Boeing CEO Phil Condit, were made with a close eye on the company’s bottom line ahead of a hotly anticipated commercial-jet boom. An ambitious program of cost-cutting, outsourcing, and digitalization had already begun. reply euroderf 4 hours agorootparent>> 1) Informed Culture >> 2) Reporting Culture >> 3) Learning Culture >> 4) Just Culture > > I'd note that financial markets driven reorganizations are antithetical to elements 1-4 If this idea could be explored in depth, and more-or-less codified as received wisdom about market players, it would be a great contribution to management \"science\" and economics. My 0,02€. reply crazytony 10 hours agoparentprevI'm really at a loss on this news. All the employees at airlines in the US I know of have this drilled into them on a regular basis and it's just taken for granted that you report incidents when they happen (even when someone falls: report it!) and the incident will get investigated. It just confounds me (but explains a lot) that the manufacturer of the aircraft the airlines operate does not share a similar safety culture given that they are in a similar ecosystem (airlines report issues to the manufacturer and the FAA/NTSB all the time) reply ethbr1 17 hours agoparentprevI thought this was critical: >> It also noted that employees do not understand how to use the different reporting systems and which reporting system to use and when. As was noted by the purported insider, re: multiple overlapping systems of record/not-record, Boeing's actual processes themselves are badly in need of overhaul. This feel like a clear example of where top-down + bottom-up independent read-back verification would have been useful. I.e. management decides they're going to create Safety Process X using Systems A, B, and C. They do so, then circulate training (top-down). THEN you conduct independent interviews with employees at the bottom, to measure whether the new processes are understood at that level (bottom-up). If results aren't satisfactory, then add additional training or reengineer the processes. Too often, it seems like this shit gets done at the VP PowerPoint level, and ground reality diverges without anyone noticing. The map is not the world: interviews with a representative random sampling aren't hard. reply lenerdenator 15 hours agoparentprevI'd say Learning Culture is also a problem. Boeing has made numerous missteps in the last 15 years after being the world leader in airliners for around half a century. This only happens when knowledge about how to make a safe product is purposefully discarded and attempts to bring that knowledge back are intentionally ignored. In Boeing's case, it's due to desires for increased profits. They are unwilling to learn these lessons because it costs money that _may_ be there at quarter's end. reply burnerburnson 18 hours agoparentprev> errors and unsafe acts will not be punished if the error was unintentional. No sane organization would ever implement this. If someone repeatedly makes mistakes, they're going to get fired even if the mistakes are unintentional. Anything else is going to cause more safety issues in the long-term as inadequate employees are allowed to proliferate. reply empath-nirvana 18 hours agorootparentThis is just blameless post mortems and many, many many places implement this. There are always going to be some level of \"inadequate\" employees, and also perfectly adequate employees that sometimes make mistakes in any organization and if your organization requires that no employees ever make mistakes in order to operate safely, then you have serious problems. The purpose of a statement like that is that you don't just have a post-mortem that is like: \"Our company went off the internet because an employee had a typo in a host name. We fired the employee and the problem is solved.\" When in reality the problem is that you had a system that allowed a typo to go all the way into production. reply error_logic 17 hours agorootparentIt's like that story of the pilot who, after his refueling technician almost caused a crash by using the wrong fuel, insisted that he always have that technician because they'd never make that mistake again. reply buildsjets 16 hours agorootparentThat was the late, and definitely great, R.A. \"Bob\" Hoover, I am proud to have shared a beer with him at Oshkosh. His Shrike Commander was miss-fueled with jet fuel instead of avgas because it was mistaken for the the larger turboprop model. Rather than blaming the individual refueler, he recognized that there was a systemic problem and developed an engineering solution. He proposed and the industry adopted a mutually incompatible standard of fuel nozzles/receptacles for jet fuel and avgas as a result. You can find some great YouTube material on him, or the film \"Flying the Feathered Edge\" https://sierrahotel.net/blogs/news/a-life-lesson https://en.wikipedia.org/wiki/Bob_Hoover#Hoover_nozzle_and_H... https://www.imdb.com/title/tt2334694/ reply buildsjets 14 hours agorootparentHere's an old timey video of Bob in his prime. At 8:55 he flys a barrel roll with one hand while pouring himself a glass of iced tea with the other. Hardest part was pouring the tea backhanded so the camera had a good view. Then he finishes with his trademark no-engine loop, roll, and landing. https://www.youtube.com/watch?v=PT1kVmqmvHU&t=510s reply s1artibartfast 17 hours agorootparentprevthe question is what do you do with the technician after the 2nd mistake. that is to say, When does this logic break down? reply wolverine876 13 hours agorootparentThat's not really the question: Punishment culture assumes people naturally do bad, lazy things unless they are deterred by punishment and fear. Therefore we must punish mistakes. That perspective has long been debunked. You don't see competent, skilled leaders using it. It turns out that generally people want to do well (just like you do), and they don't when they are scared / activated (in fight/flight/freeze mode), poorly trained, poorly supported, or poorly led. They excel when they feel safe and supported. If you are the manager and the technician makes the same mistake the 2nd or 3rd time, you will find the problem the next morning in your bathroom mirror. :) At best, you have put them in a position to fail without the proper training or support. Leadership might also be an issue. reply s1artibartfast 11 hours agorootparentI would say that every skilled leader must use punishments and consequences to some degree. If your tech gets drunk every day and doesnt do their job, you need to cut them loose. This isn't a management problem. Sometimes people end up in positions where they are not suited and will continue to fail. If you hired a plumber and you need a doctor, that isnt an on the job training, support, or leadership issue. reply reverius42 11 hours agorootparent> you need to cut them loose. This isn't a management problem. That is 100% a management problem. > Sometimes people end up in positions I wonder how they got in those positions? That sounds like a management problem too. reply s1artibartfast 11 hours agorootparentIt isnt always managements job to make the person workout in the role. Sometime it is managements job to fire that person to find someone better. Some people are bad fits for positions. They might look good on paper, they might be trying something new, they might lie to get hired, they might change after starting, they might have been a risky hire, or any number of reasons. reply refulgentis 9 hours agorootparentI think you're envisioning people all being absolutists who follow an exacting rule book and can't consider context. (that's covered by the *flexibility* tentpole) As N approaches infinity, there's definitely a value of N at which we discover the root cause is the airman and have to move on from him. I don't think it's particularly interesting to try to identify a constant value for N because it's highly situational, and we know we have to do *just* and *reporting* as well, the reporting falls out when the just does. reply s1artibartfast 9 hours agorootparentYou hit the nail on the head. I do perceive a lot of people being \"no bad employee\" absolutists. All I am looking for is recognition that the content of N matters. It is part of what I see as a broader phenomenon where people emphasize systems and ignore agents. In reality, agents shape systems and systems shape agents in continuous feedback. reply lucianbr 16 hours agorootparentprevIf you implemented some changes so the mistake is caught before disastrous consequences, you're already doing better. Well enough to let the 2nd one slide. Even the 3rd. After that, action seems reasonable. It's no longer a mistake, it's a pattern of faulty behavior. reply s1artibartfast 16 hours agorootparentThat is a big IF. At some point it comes down to the error type, and if it is a reasonable/honest mistake. The situation is very different if the fuel cans are hard to distinguish vs if the tech is lazy and falsifying their checklist. Underlying any safety culture is a one of integrity. No safety culture can tolerate a culture of apathy and indifference. reply ethbr1 15 hours agorootparentI expect there's precisely 1 safety culture that can tolerate a culture of apathy and indifference -- one in which no work is ever completed (without infinite headcount). You apply risk mitigation and work verification to resolve safety issues. Then you recursively repeat that to account for ineffective performance of the previous level of verification. Ergo, end productivity per employee is directly proportional to integrity, as it allows you to relax that inefficient infinite (re-)verification. reply s1artibartfast 14 hours agorootparentExactly! All this talk about man vs system misses the point that man is the system designer, operator, and component. This is why Boeing cant just solve their situation with more process checks. From the reporting, they are already drowning in redundant quality systems and complexity. What failed was the human elements. Someone was gaming the system saying that the doors weren't \"technically\" removed because there was a shoelace (or whatever) holding them in place, Quality assurance was asleep at the wheel, and management was rewarding those behaviors. Plenty of blame to go around. reply throwway120385 15 hours agorootparentprevRedesign the system again if it's unintentional. It is almost impossible to control humans to the degree that they never make mistakes. It's far better to design a system in which mistakes are categorically impossible. reply s1artibartfast 15 hours agorootparentI'm trying to push back on the knee jerk sentiment that there are no bad employees, only bad systems. There are no systems that are human proof, and what kind of human behavior is tolerated is a characteristic of the system. In fact, there are humans that lie, cheat, are apathetic, and incompetent. Part of a good system is to not only mitigate, but actively weed these people out. For example, if someone falsifies the inspection checklist for your plane, you dont just give them a PIP. reply wolverine876 12 hours agorootparent> I'm trying to push back on the knee jerk sentiment that there are no bad employees, only bad systems. Why is it important to you? reply s1artibartfast 11 hours agorootparentBecause Im an engineer in a quality controlled field (Medicine), and my personal experience is that firms place too much faith in quality systems and not enough emphasis on quality employees. I see lots of engineers and QA following a elaborate procedures with hundreds of checks, but not bothering to even read what they sign off on, so they can go golf all day. People seem to think that you can engineer some process flow to prevent every error, but every process is garbage if the humans dont care or know what they are doing. Every process is garbage is you dont hire workers with the right skills demanded by that process. In an effort to drive down costs, lots of companies try to make up for talent with process, with poor results, for both the companies and patients. you cant replace a brain surgeon with 2 plumbers and twice the instructions. reply wolverine876 10 hours agorootparentVery interesting, I'm glad I asked. Similarly, I read some head of a leading engineering organization (I think a NASA head or maybe Admiral Rickover) who said, essentially, 'you can't replace ability with process'. All the process in the world, they said, will not substitute for highly able personnel. But perhaps safety, not usually dependent on ability, is a different matter. Possibly, the problems you describe are a matter of leadership and management - which doesn't undermine your point; those also are things that can't, past a certain irriducible point, be replaced with process. reply s1artibartfast 9 hours agorootparent>Possibly, the problems you describe are a matter of leadership and management I wholeheartedly agree that leadership/management is a part of problem. My main objection is the \"no bad employee\" rhetoric. Sometime times the problem with management is that they aren't getting rid of bad employees. Rot can start anywhere in an organization, and the rest of the org really needs to push back, not just management. It actually reminds me a lot of the culture/discipline problems with some Police departments in the US. It is hard to enforce and cultivate organizational culture top down. Most of it is maintained peer-peer. reply wolverine876 8 hours agorootparentI guess it seems like that argument takes the discussion to an extreme. Does anyone actually advocate never firing employees? That there are literally no bad employees? > It is hard to enforce and cultivate organizational culture top down. Most of it is maintained peer-peer. I think it's a combination. The leader has a large influence; they set the standards and the norms. At the same time, I agree with what you say about peers - perhaps peers spread and 'enforce' those norms. It may also depend on the size and age of the organization. reply xenadu02 7 hours agorootparentprevYes there are obviously bad employees but the line for actual incompetent/malicious employee is a lot further away than most people understand. A lot of bad management is hand-waved as crappy employees (by management - shocking!) reply mike_ivanov 14 hours agorootparentprevFalsifying the inspection checklist is not a honest mistake. reply afp14 9 hours agorootparentprevIt's seemingly simple \"oh the technician keeps messing up\" Did the technician mess up (sometimes true), or were they doing their job in good faith - was it the system/protocol/organization that made the task mistake prone? Did someone else actually mess up but the situation made it look like it's the technician's fault? Does this technician do a task/service that is failure prone? Are there other technicians on other tasks that are far less failure prone? Here the former technician would seem poor, the latter, excellent, but it's a function of the task/role and not the person. I've been \"the technician\" - I catch a lot of blame because people know I'm anti-blame culture, so I'd rather take the blame on myself that point my finger to the next guy in line. I'm also willing to take on high risk tasks for the greater good even if they suck and are blame prone / risky. I believe in team culture in this way. If the organization doesn't respect that belief and throws me under the bus, I leave - which is quite punishing for them since they remain completely unaware of a major internal problem. If an organization \"sees me\" and my philosophy, then together we get very very good at optimizing the system to minimize the likelihood of failure / mistakes. reply hughesjj 14 hours agorootparentprevWell certainly not after the first time at least Imo it's a function of time, company and team culture, severity, and role guidelines. If an employee makes a mistake but followed process, and no process change occured, that's just acknowledging the cost of doing business imo and would be a unbounded number of times so long as it's good faith from the employee reply roenxi 13 hours agorootparent> a function of ... severity Not severity; that sort of thinking is actually part of low-safety cultures. A highly safe culture requires the insight that people don't behave differently based on outcome. In fact, most people can't assess the severity of their work (this is by design; for example someone with access to the full picture makes the decisions so that technicians don't have to). So they couldn't behave differently even if they did somehow make better decisions when it matters. But, and I'll reiterate the point for emphasis, people make all their decisions using the same brain. It is like bugs; any code can be buggy. Code doesn't get less buggy because it is important code. It gets less buggy because it is tested, formally verified, battle scarred, well specified and doesn't change often. reply hughesjj 2 hours agorootparentWould s/severity/impact/g also be counterproductive of safety culture? Genuinely trying to learn here, gotta be responsible/accountable and all. Maybe impact relative to carelessness/aloof-ity? I agree that an engineer/person will not behavior differently based on outcomes, but if they know in advance something can have a wide, destructive blast radius if some procedure is not followed, I feel there's a bit more culpability on the part of the engineer. Regardless I don't think I feel I have a sufficient grasp on this concept I'm trying to define so definitely agreed I shouldn't have included 'severity' in the function definition nor any alternative candidate reply s1artibartfast 14 hours agorootparentprevMy point is that good faith and sufficient competence are crucial. If the employee didn't care if the plane crashed, they are a bad fit. If they cant read the refueling checklist, they are a bad fit. Ideally you have system controls to screen and weed these people out too. reply Log_out_ 16 hours agorootparentprevYou take him into a boolean tree within a and with another employee for quality and put him on a improvement plan? reply s1artibartfast 15 hours agorootparentmaybe. or maybe you turn them over to the authorities because the 2nd time their lazy and reckless disregard killed several people. reply EnnEmmEss 7 hours agorootparentprevExactly. https://asteriskmag.com/issues/05/why-you-ve-never-been-in-a... is a great article illustrating this in the airline industry itself. reply ChrisMarshallNY 13 hours agorootparentprev> When in reality the problem is that you had a system that allowed a typo to go all the way into production. That's a typical root cause, and is exactly what should come out of good post-mortems. But human nature is human nature... reply icegreentea2 18 hours agorootparentprevJust culture doesn't prevent you from firing someone who makes repeated mistakes. In fact, Just Culture in itself provides the justification for this. As the next line says \"However, those who act recklessly or take deliberate and unjustifiable risks will still be subject to disciplinary action\". A person who repeated makes mistakes is an unjustifiable risk. reply hinkley 18 hours agorootparentWhen a punishment is applied with more deliberation, it can also be more severe. reply wolverine876 12 hours agorootparentWhy is severity desirable? Or if it's not desirable, so what? reply sokoloff 12 hours agorootparentSeverity is desirable iff it's justified. I wouldn't ever sign off on a policy that says \"you'll be fired for a single mistake\" (that would be a severity of punishment out of proportion to the risk/underperformance). But a policy that never provided for the possibility of termination (insufficient maximum severity) is also not desirable. reply wolverine876 12 hours agorootparent> Severity is desirable iff it's justified. It's necessary if it's (necessary & efficient & justified); it's never desirable IMHO. Doing severe things because they are justified is just acting out on a desire or drive - internal anger - but now we can 'justify' the target and feel ok about it. Lynch mobs think they are justified. reply applied_heat 18 hours agorootparentprevYou can really dumb it down to why didn’t you follow the checklist? If someone makes the same mistake after being corrected three times and the proper procedures exist for the worker to follow then the safety culture provides the structure and justification for their dismissal reply buildsjets 15 hours agorootparentNo, you really need to smarten it up, and start off by making sure that your checklist is correct. Is it the correct checklist for the airplane model that you are building? Are all the right items on the checklist? Are they being done in the correct order? Do you have the correct validation/verification steps in your checklist? Does your checklist include all the parts that will need to be replaced? If the mechanic finds a quality issue while working the checklist and a job needs to be re-done, which checklists then need to be re-done? What other jobs are impacted by the rework? All indications here (from the NTSB prelim and the widely reported whistleblower account) are that during rework for a minor manufacturing discrepancy, the mechanics on the shop floor followed bad manufacturing planning / engineering instructions to-the-letter, then the ball was dropped in error handling when the engineering instructions did not match the airplane configuration, because Boeing was using two different systems of record for error handling that did not communicate with each other except though manual coordination. That's not the fault of the front-line assembly worker not following a checklist. reply applied_heat 14 hours agorootparentI agree with you. If the systems/procedures/checklists are bad it is not the fault of a front line worker. I thought I was replying more to a parent comment addressing the inability to people go who repeatedly make mistakes, which is acceptable unless they are not following procedures. reply buttercraft 18 hours agorootparentprevThat's quite a leap from \"unintentional\" to \"repeatedly.\" reply wolverine876 12 hours agorootparentNot at all: Systemic problems will result in repeated errors until the system is changed. reply zettabomb 17 hours agorootparentprevEvery sane organization implements this. Failure to do so leads to fear of reporting mistakes, and you get Boeing. This isn't news. reply inglor_cz 16 hours agorootparentprevIdeally, as a result of the post-mortem, the same mistake shouldn't even be repeatable, because mechanisms should be introduced to prevent it. And if someone keeps making new original mistakes, revealing vulnerabilities in your processes, I would say that it is a very valuable employee, a lucky pen-tester of sorts. reply ThrowawayTestr 17 hours agorootparentprevI once destroyed $10k worth of aerospace equipment. I admitted it immediately and my only reprimand was that my boss asked me if I learned my lesson. (I did) reply Log_out_ 16 hours agorootparentOnce destroyed a industrial manufacturing site with a unfinished robot program that ran because I allowed myself to be distracted mid alterations. reply wolverine876 12 hours agorootparentAnd what happened? reply ClumsyPilot 17 hours agorootparentprevWho do you think came up with this rule, bleeding heart liberals’? Stop and think for a second, why does that rule exist? You described a fantasy world, in the real world everyone makes mistakes, and if the mistakes are punished, then there are no mistakes because no one reports them. That is until the mistake is so catastrophic, it cannot be covered up- that’s how you get Chernobyl or Boeing max reply shiroiushi 5 hours agorootparentBoeing max (if you mean the crashes caused by MCAS) wasn't due to a \"mistake\" not being reported, it was deliberate and intentional on the part of company management. The system was designed badly and without redundancy, and without any information available to the pilots about its very existence, specifically because management wanted it that way. It wasn't caused by some kind of accident. reply dclowd9901 17 hours agorootparentprevI think the wording is clumsy, but this is analogous no-blame processes. The wording is just accounting for the possibility of wontonly malicious or recklessly negligent work quality. Think someone either sabotaging the product, or showing up to work very high or drunk. reply inglor_cz 16 hours agorootparentThis. A mistake like \"accidentally turning the machine off when it shouldn't be\" is a fixable problem. If someone has attitude like \"fuck the checklist, I know better\", it is not really a mistake, and that person should be rightfully fired or at least moved to a position where they cannot do any harm. reply WheatMillington 13 hours agorootparentprevWowwww never become a manager please. reply beaeglebeached 18 hours agorootparentprevnext [18 more] [flagged] gklitz 17 hours agorootparentWhat a reductive attitude. If your planes fall from the sky because a single employee is negligent. The ones to blame isn’t the worker, the union or the state. It’s your business that has key deficiencies in implementing safety. Your QC process has to be able to catch these things. It’s not like you can avoid any reliability in your process and just lean back and be like “don’t worry bro, it’ll fly, we hired all non-union workers” reply hinkley 17 hours agorootparentThis also sounds like someone in the New Boeing management chain. A lot of these culture problems were already evident during the 787 program, which is when MD’s mismanagement started to fester. And when the hardon for union busting first came to my attention. reply beaeglebeached 17 hours agorootparentprevWhat a reductive attitude. Nah not just one negligent worker. Many, including QC staff. reply ethbr1 17 hours agorootparentprev> The ones to blame isn’t the worker, the union or the state. It’s your business that has key deficiencies in implementing safety. I don't think you're charitably reading parent. Sometimes, the employee is the problem. And sometimes, union contracts preclude changing processes (or make change unnecessarily burdensome) to improve outcomes. Introducing another party into agreements doesn't come free. I'm as pro-union as anyone around here... but it is another level of bureaucracy. And sometimes, protecting \"our people\" can include not letting go people who should be let go (e.g. decreasing headcount in assembly to hire more professional QA people). That said, solutions do need to come from all levels, and I think unions do provide a necessary counter-pressure to management deciding only employees need to bear the brunt of change. reply shagie 17 hours agorootparent> where certain difficult to fire union parasites have a stranglehold > where such fatally negligent parasitic workers can be easily shit canned How charitable of a read does one need to give a comment that uses pejorative and hyperbolic language without providing any substantive refutation? reply ethbr1 15 hours agorootparentForums improve through ignoring hyperbolic language, not responding to it. reply acdha 14 hours agorootparentForums improve by rejecting rude and deceptive language - as Gen. Morrison said, the standard you walk past is the standard you accept. reply ethbr1 12 hours agorootparentAgree to disagree. IMHO, there are more people who thrive on internet conflict than thrive on being ignored. It takes self control, but walking past the problem is sometimes the more effective solution. \"Man, that asshole on the Internet disagreed with me. I'm going to write a detailed rebuttal of why they're the asshole.\" vs. \"Hunh, I wonder why I occasionally get down voted and no one ever responds to me? And also, the responses I do get are a lot nicer in tone than mine...\" reply acdha 12 hours agorootparentYou’re right that there is a challenge about giving attention when that’s what they’re seeking. I generally prefer either flagging (worse cases) or up-voting the one person who left a “dude, not cool” reply so they get clear community feedback. reply zettabomb 17 hours agorootparentprevPerhaps the worker is at fault, but in (good) aerospace companies one person's mistake cannot lead to a bad unit going out the door. At the very least, two people need to be wrong in the same way - but more likely, several people would need to miss the problem. That being said, \"operator error\" as a reason for a problem is heavily discouraged (at least in official reports). Rather, it's typical to blame a human factors issue, commonly one of the \"dirty dozen\" [0]. I couldn't say exactly which ones are present at Boeing but frankly, from the public reports almost all of them sound applicable. With this in mind, process change is the only appropriate remedy, regardless of what the union thinks. I've never heard any union people get mad at something that improves their job though. [0] https://skybrary.aero/articles/human-factors-dirty-dozen reply Zigurd 17 hours agorootparentprevI wouldn't put it past Boeing management to try to move more production to South Carolina. In fact they put the 787 there thinking that the 787 would be the future of Boeing. It isn't, and it can't be, because of the problems in developing and building the 787. So their move to a anti-union state ended up being a dead end. In the 787 project they pushed outsourcing of design to their suppliers so they could reduce dependence on their own engineers. That was a disaster. They spun out Spirit Aerosystems to fragment their unionized manufacturing workers. The same Jack Welch influence via Harry Stonecipher sets the management tone even today. It's the wrong culture. They need to move headquarters and production of their next plane back to the Pacific Northwest, and they need to develop the next plane not in the way that they developed the 787 which was which was designed to be a thumb in the eye of the union and their engineers. It's a cultural problem. Look at the word cultural throughout the FAA report. The culture that Boeing had doesn't work, and they need to change it root and branch. reply hinkley 17 hours agorootparentprevYeah because the QC of the Carolina plant has been sooooo great. Airlines are trying to get ahold of the planes built in Everett because the SC plant planes have quality control issues still, ten years in. Pull the other one. reply bumby 17 hours agorootparentprevCan you point to where a union employee was a root cause of the Max debacle? Because as I read it, most of the mistakes were of a design nature (i.e., mistakes of white-collar employees). Your comment reads like you started with a conclusion and worked backwards. reply beaeglebeached 17 hours agorootparentLook up SPEEA reply bumby 14 hours agorootparentThe existence of a labor union does not make your point. You point to an industry group; I'm asking if there is a specific instance in the Boeing 737Max mishaps that is attributed to a union-member disregarding generally good safety practices by the very nature of being defended by the union. I'm not aware of one, but the opposite is true: white-collar decisions can be shown to be direct contributors to the problem(s), and I don't think they have anything to do with union membership. E.g., Boeing did not 1) classify MCAS correctly in their hazard analysis, and 2) even with their mischaracterized risk in the HA, they did not follow their own procedures to have redundant sensor readings mandatory for the equipment as classified. Those are designer decisions, not some labor-union issue. To my knowledge, those held responsible were relatively high level engineers, implying they were not being protected by the union for their decisions. reply Mordisquitos 17 hours agorootparentprevWait till you hear how \"difficult to fire\" it is at Airbus assembly locations in Germany, Spain and France, and how unionised the workforces of these countries are... and yet Airbus doesn't ostensibly have a \"fatally negligent parasitic workers\" problem having an impact on its airliner safety. How come? reply beaeglebeached 17 hours agorootparentIt could be worker organization in Europe is mutually cooperative rather than antagonistic as often found in USA. reply byteknight 18 hours agorootparentprevFurthering the insinuation that everyone has the right to work every job. Sometimes people suck at their job. reply error_logic 18 hours agorootparentAs your sibling comments mentioned, there's a difference between giving a chance for someone to learn from a single mistake without punishment, and allowing them to make the same mistake twice without taking matters out of their hands after. If it's a really critical role, the training will have realistic enough simulation for them to make countless mistakes before they leave the training environment. Then you can assess their level of risk safely. reply hinkley 17 hours agorootparentThis whole thread is missing the fact that the NTSB had a theory that transparency leads to safer airplanes, they tried it, and it works. People hesitate to self-report when it comes with punishment (fines, demotions, or just loss of face among peers). You need a formal “safe space” where early reporting is rewarded and late reporting is discouraged. Safety is a lot about trust, and there is more than one kind of trust. At a minimum: are you capable of doing this thing I need you to do? Will you do this thing I need you to do? reply zettabomb 17 hours agorootparentIt's not just the NTSB, it's part of things like the Toyota Production System. There's ample evidence to show both that punishment discourages safety and that lack of punishment encourages safety, across multiple industries. reply nyrikki 16 hours agorootparentYes this is cross industry best practices. Goodhart's law also applies, as in the case of the edoor bolts, Spirit intentionally bypassed safety controls to meet performance metrics. The Mars Climate Orbiter is another example. While unit conversion was the scapegoat, the real cause of the crash is that when people noticed that there was a problem they were dismissed. The Andon cord from the Toyota Production System wasn't present due to culture problems. Same thing with impact scores in software reducing quality and customer value. If you intentionally or through metrics incentivize cutting corners it will be the cost of quality and safety. I am glad they called out the culture problem here. This is not something that is fixable under more controls, it requires cultural changes. reply StableAlkyne 13 hours agorootparent> The Mars Climate Orbiter is another example. While unit conversion was the scapegoat, the real cause of the crash is that when people noticed that there was a problem they were dismissed. Challenger too. Multiple engineers warned them about the O-rings. They weren't just ignored, but were openly mocked by the NASA leadership. (https://allthatsinteresting.com/space-shuttle-challenger-dis...) A decade later a senior engineer at NASA warned about a piece of foam striking Space Shuttle Columbia and requested they use existing military satellites to check for damage. She was ignored by NASA leadership, and following (coincidentally) a report by Boeing concluding nothing was wrong, another 7 people were killed by a piss-poor safety culture. (https://abcnews.go.com/Technology/story?id=97600&page=1) reply ethanbond 15 hours agorootparentprevBut but but what about my intuition and gotcha questions about how this could never work in practice? reply s1artibartfast 16 hours agorootparentprevI think there is more nuance to it than that. Not everything is a mistake, not every mistake is recoverable, and not all skills are trainable. The fundamental goal is to distinguish between recoverable errors and those that are indicative of poor employee-role fit. reply nyrikki 15 hours agorootparentMistakes are the problem, as they will always happen. The point is to build a culture where you value teamwork and adjust and learn from failures. This isn't an individual team problem, this is an organization problem. It is impossible to hire infallible, all knowing employees. But it is quite possible to enable communication and to learn from pas mistakes. When you silence employees due to a fear of retribution bad things happen. People need to feel safe with calling out the systemic problems that led to a failure. If that ends up being the wrong mixture of skills on a team or bad communication within a team that is different. Everything in this report was a mistake, and not due to gross incompetence from a single person. The E door bolts as an example was directly attributed to metrics that punished people if they didn't bypass review. The delivery timelines and defect rates were what management placed value on over quality and safety. Consider the prisoner delema, which is resolved by communication, not choosing a better partner. reply s1artibartfast 15 hours agorootparentI don't disagree with what you said about this instance, but I'm trying to push back on the knee jerk sentiment that there are no bad employees only bad systems- There are both. cultures that are too permissive of bad actors degrade the system. Part of maintaining quality culture is maintaining red lines around integrity. Like I said above, not all errors are recoverable or honest mistakes. I work in medicine and a classic example would be falsifying data. That should always be a red line, not a learning opportunity. You can add QA and systemic controls, but without out integrity, they are meaningless. I have seen places with a culture of indifference, where QA is checked out and doesn't do their job either. reply filleduchaos 9 hours agorootparent> I work in medicine and a classic example would be falsifying data Certainly nobody has ever thought about that before. In fact, there definitely isn't a second sentence in the definition of aviation's just culture that is being completely ignored in favour of weird devil's advocacy. > 4) Just Culture- errors and unsafe acts will not be punished if the error was unintentional. However, those who act recklessly or take deliberate and unjustifiable risks will still be subject to disciplinary action. Oh wait. reply s1artibartfast 9 hours agorootparentI have no problem with the stated safety culture. I simply agree that \"that everyone has the right to work every job\" is not a reasonable interpretation of them. as stated above, a reasonable reader should understand: > Not everything is a mistake, not every mistake is recoverable, and not all skills are trainable. The fundamental goal is to distinguish between recoverable errors and those that are indicative of poor employee-role fit. reply filleduchaos 8 hours agorootparentWho is claiming that \"everyone has the right to work every job\", though? The only person to even bring up the sentence is someone who's handwringing about an interpretation that nobody was making to begin with. This is why I called it weird devil's advocacy, because what exactly is the point of jumping to caution people about something they aren't doing? reply s1artibartfast 8 hours agorootparent>Who is claiming that \"everyone has the right to work every job\", though? The only person to even bring up the sentence is someone who's handwringing about an interpretation that nobody was making to begin with. Thats the parent in the thread we are posting in in. User Error-Logic replied, and I built upon their reply adding that: >goal is to distinguish between recoverable errors and those that are indicative of poor employee-role fit. You and others wanted to dive further. reply cameroncf 19 hours agoprevIsn't this just confirming a seemingly widely held opinion that the safety culture started to break down after 1997 after the merger with McDonnell Douglas? See also: https://news.ycombinator.com/item?id=26417095 reply beowulfey 18 hours agoparent>Isn't this just confirming a seemingly widely held opinion Yes-- this represents formal acknowledgement by a regulatory agency. The hope is that agency can now use this formalization to enforce change within Boeing. reply bbor 12 hours agorootparentDoes anyone else share my wish that the result of this investigation was “poof no more Boeing”? I don’t understand why corporations can be fundamentally flawed and keep going, where a person in that situation would be prosecuted as a criminal. If Boeing has a bad safety culture because they keep investing unbelievable sums of money into stock buybacks and dividends, so much so that they don’t even have reporting culture… I don’t think they deserve a second chance, and frankly I think the shareholders deserve jail time so I really don’t care if they lose some money. Yes, I know some pension fund somewhere is invested in Boeing. No, I don’t care. Will we ever solve corruption and climate change if we refuse to actually change our ways? reply falserum 10 hours agorootparentNo, we can not solve corruption, because people are greedyand organization needs hierarchy. Regarding climate change I have hope, but again, same greed, kind of would dictate that at best we will slow it down. Whatever you will decide to do with boeing, you will have to make employees, shareholders and numerous clients (incl. Us military) content. Btw. I own a share of a fund which has shares of boeing. Should I go to jail? reply bbor 7 hours agorootparentpeople are greedy I think that people are far more culturally and historically specific than they appreciate, so I take claims like this (i.e. non-specific ones about human nature and virtue therein) with a massive grain of salt. I agree in the general sense of the word, of course! Whatever you will decide to do with Boeing, you will have to make employees, shareholders and numerous clients (incl. Us military) content. I totally agree with many of your points re:climate change and hierarchies, but I don't see how that responds to my initial charge: that specific companies that are found systematically guilty of some sort of crime should be forcibly disbanded. What if many of the smart, motivated Boeing engineers would be more productive in a dynamic marketplace of smaller firms? What if there's a warp drive concept lurking in the mind of an underutilized systems analyst deep in the basements of their valley? Investing all these resources, especially public fiscal ones, into a company that has proven again and again to prioritize suicidally negligent, short term, excessively selfish thinking... well, it seems criminally unjust. TL;DR_1: I don't need him, he needs me! I own a share of a fund which has shares of boeing. Should I go to jail? I would separate laborers who have shares as some form of retirement from capitalists who deploy unimaginable sums of money. I know the 1% discourse is tired but the general sentiment is extremely valid: a relatively small group of powerful people pressured the Boeing board to make these decisions. In the paraphrased words of AOC: \"..and it's, like, twelve people.\" Yes, I think the people who lobbied for cost cutting and dividend/buyback programs within the company deserve to be criminally investigated. I am so far from a lawyer and doubt our exact current laws and policies (esp. SEC) would be enough, so the most specific I can get is \"charges related to negligence and greed\" TBH. But no, I was being unclear when I said \"owners\" -- not all owners of any amount of the stock are complicit, other than in a broad ethical-consumerism sense. You're on Hacker News, so I have no doubt at all that you're living your life in good faith. TL;DR_2: capitalists != investors reply dclowd9901 17 hours agorootparentprevAnd, what, undo capitalism? The motivating forces here are profit, plain and simple. I've come to think that it's not only probable, but _inevitable_ that any growth-oriented, profit-motivated company (read: any company) will reach a point that their only remaining growth path is to undermine quality. reply Zigurd 17 hours agorootparentCapitalism in practice is an artificial environment. People speak of it as if it is a force of nature, but anywhere it is put into practice it is put into practice in the context of norms and regulations. Undo capitalism is a conversation terminating tactic. If the Jack Welch style of capitalism is failing, it can be changed. For example, there is a national Labor relations board because we don't do this anarchically. reply GuB-42 15 hours agorootparentprev> And, what, undo capitalism? No, they just have to make following a safety culture less expensive than not. For example, by conducting proper audits. If not following safety requirements means that new planes are not certified and the others get grounded before it is fixed, then it is going to get more costly for Boeing than doing it right to begin with. That's what regulations are for. And undermining quality is often not profitable. That's because their customers also want to maximize their profits, and a bad plane, one that doesn't last, requires frequent repairs, is unreliable, has a bad reputation with passengers, etc... isn't going to be very valuable. Customers will pay more for a good plane that offers better returns on investment. This is the same for any B2B company. Consumers are a bit easier to fool, especially with good advertising (which is also expensive), but at some point, they too will realize that a brand is worthless. reply calf 14 hours agorootparentThis is reducing culture to money, which I imagine the safety culture theorists anticipated a layperson, misinformed understanding of it. reply MomoXenosaga 13 hours agorootparentprevShort term profits. Literally nobody gives a shit anymore what happens to a company ten years in the future. Outsourcing and building the Max fast led to good numbers at the annual shareholder meeting. Arguably it still does because what is anyone going to do? Buy Airbus? They have waiting lists too. reply masklinn 17 hours agorootparentprevCapitalism is a tool, not a force of nature*. It can be channeled, directed and mitigated. That is what regulations and regulatory agencies do. Although of course you need to watch the watchers so they don't get captured. * and even if it were, we channel, direct, and mitigate forces of nature all the time, if not always to great success, or without consequences reply bumby 17 hours agorootparent>of course you need to watch the watchers I don't cut Boeing much slack, but some of this also falls on the FAA for delegating certain oversight activities to the manufacturer. I assume they do it for manpower reasons (ie there just aren't enough FAA employees to do the job sufficiently). reply masklinn 17 hours agorootparentI don't think there's any need to cut Boeing any flack to point out that the regulators did fail to do due diligence. It is understandable that regulators would take a lighter hand to a company which has shown good ethics — which was historically the case of Boeing (more of an issue if that is because of not being able to handle the load), it's a problem if they go completely hands off. I don't think the FAA is the sole culprit here either, we've not heard much of non-american regulators. While it makes sense that the FAA would be the primary regulator for Boeing, that regulators would cooperate internationally, and that non-primary regulators would have to be careful e.g. around the risk of being called out for trade restrictions, I still feel non-US regulators should have been a lot more involved with and suspicious of Boeing following the MCAS mess. reply bumby 14 hours agorootparentOne of the looming risks is that other nations lose faith in the FAA to certify their aircraft. Particularly smaller nations, which, in effect, inherit the FAA certification as safe instead of levying their own. reply iskander 15 hours agorootparentprevExceptions so far are Novo Nordisk and CostCo. Not sure if there are many others at scale. reply hodgesrm 15 hours agorootparentprev> And, what, undo capitalism? No, just make it very costly to have quality lapses. Capitalism takes care of the rest. When it's effective government regulation makes companies pay for costs that would otherwise be externalized. reply akira2501 14 hours agorootparentprevWell, how about, just enforce laws already passed by congress? Monopolies are illegal. They have been for 100 years and it has yet to \"undo capitalism.\" reply bbor 12 hours agorootparentprevUndo American capitalism :). A true capitalism would have strong regulations to prevent this sort of thing, and companies that recognize that making bad products is bad for themselves and society in the long run. That said, I hope to god you’re a socialist lol. The stance “capitalism inevitably leads to corner cutting, but it’s still the best we’ve got” would have the potential to literally break my mind with consternation. reply TheCondor 18 hours agoparentprevConfirms some serious issues in culture. Not sure if confirms the cause of those issues or where/when the infection took hold. reply schainks 11 hours agoparentprevYes, this video also had a great historical breakdown and context about what's going on: https://www.youtube.com/watch?v=URoVKPVDKPU Everything Wendover Productions makes is so helpful! reply hinkley 17 hours agoparentprevReally started when Congress decided they were supporting too many aerospace companies and some asshat got the idea that forcing some of them to merge would be a good idea. Spreading manufacturing all over the US is also more to do with getting kore congressional districts “pregnant” than with national defense. In war you want multiple, as in redundant, supply lines so if one is cut, you can source matériel from somewhere else. What we have is multiple, as in single point of failure, supply lines. Lose one and everything collapses. reply basseed 17 hours agoparentprevwidely held as you read it in one post on HN? reply cameroncf 15 hours agorootparentIt's been covered for at least the last 5 years by many reputable news orgs. That HN link (you looked at the link right?) includes several refs, and a Google search dozens more. reply zettabomb 17 hours agorootparentprevWidely held by many in the industry, including those working at Boeing. reply schainks 11 hours agoprevThe leaders of Boeing are clearly fumbling the ball, paying themselves more than ever, shitting on their labor and supply chain sub-contractors, all while costing ME as a taxpayer and occasional user more money and stress than ever. Such a small group of leaders extracting maximum value for themselves at both the cost of the company, greater economy, AND the US Taxpayer sounds, I don't know... criminal? reply euroderf 3 hours agoparentBut in the absence of criminal enforcement, it just sounds... clubby. Welcome to Techno-Neo-Feudalism. Your superiors are handling their own compensation quite nicely, thank you. Now get back to work !! reply letsdothisagain 11 hours agoparentprevIt's not new either. Teddy Roosevelt ran on trust busting and defeated both the dems and republicans. reply dathinab 18 hours agoprev> The panel expressed concern that the confusion might discourage employees from reporting what they see as safety problems. so who is opening bets that this was at least partially intentional? Quite often when there are overly complicated reporting pipelines and people not knowing how to use them is because the company doesn't want you to report because that leaves a paper trail which could screw them over if they ignore it and something goes wrong. reply hinkley 17 hours agoparentDieselgate is an example of what happens when managers are rewarded for achieving goals they haven’t been given the resources to achieve. When you promote people for achieving the impossible without investigating how they achieved it, that’s how you end up with superfund sites, pollution, or giant safety recalls. They didn’t do what you asked. They found a way to cheat. And worse, their coworkers and reports know what they did, and see them getting rewarded. The “morally flexible” copy, and the boy scouts leave, or burn out. reply hef19898 14 hours agorootparentDieselgate started as far up the top of VWs fod chain as you can get: the CEO handpicked and protected by the god father himself, Ferdinand Piech. Well possible that Piech was involved in all of that as well. It started as a deliberate decision to limit AdBlue tank volume to safe money, and extend AdBlue usage to the point drivers didn't have to replenish themselves between inspections, which allowed VW to make more money on service. That cheating was not engineers cutting corners to please management, it was engineers at the very top of management deliberately ordering the organization to cheat. reply hinkley 11 hours agorootparentI think you have a different story. The TDIs involved with Dieselgate shipped with no adBlue tank. VW claimed to have some special process where they could catalyze the soot without the nitrogen supply to manage it. But that was all a lie. Adblue (the accepted solution) wasn't added until 2014 at the earliest. The naughtiest thing they did was that the vehicles detected if they were being run in inspection mode, and adjusted the fuel mixture to avoid exceeding particulate emissions. They may also not have been telling people to refill the tanks on cars that had them, but actively circumventing EEA/EPA compliance checks was what infuriated governments. reply hef19898 3 hours agorootparentThe engines had AdBlue, tuey reduced AdBlue in the mix when not in inspection mode. Without AdBlue, there was no way to ever meet emission requirements. reply whitej125 19 hours agoprev20 years ago nobody thought there'd be a another US automaker beyond the big three (Ford, GM, Chrysler)... yet today here we are with Tesla and a list of others. Are there any other US companies today that could ostensibly be viable alternatives to Boeing's spot 20 years from now? Electric-first-and-only was the differentiator for Tesla vs big three... what differentiator will it be in the aero industry? reply dghlsakjg 18 hours agoparentMaybe one of the private jet manufacturers? In the US we have Cessna and Gulfstream, and in Canada we have Bombardier which designed and sort of made the CSeries/A220 in Alabama in conjunction with Airbus. The whole Bombardier CSeries fiasco was basically Boeing using the US government to try to kill Bombardier because they had managed to put together a plane that was very competitive with with the 737-MAX in a number of categories. The takeaway though is that it is possible, with significant government support, for a small jet manufacturer to put up a feasible competitor to Airbus/Boeing. reply 0xffff2 16 hours agorootparentI think you mean Textron and General Dynamics. Cessna and Gulfstream haven't been independent companies for 10 and 20 years, respectively. reply buildsjets 15 hours agorootparentAlso, they did not \"try to kill Bombardier\", they did kill Bombardier, at least as far as the commercial jet industry is concerned. Bombardier does not sort of make the CSeries/A220 in Alabama in conjunction with Airbus. The CSeries does not exist any more, the A220 is now a 100% Airbus program, as of Feb. 2020, Bombardier has zero involvement in it. reply dghlsakjg 11 hours agorootparentBombardier jets are not dead just their passenger airline jets, they are still making jets, just not the CSeries, and nothing for the airline industry. The Alabama A220 production started while Bombardier was still a partner which is why I used past tense \"made\" and \"sort of\" reply buildsjets 5 hours agorootparentThat’s EXACTLY what I just said. They completely killed Bombardier at least as far as the commercial jet industry is concerned. Bombardier now makes no commercial jet aircraft. Zero. None. They still make a few general aviation jet aircraft, but that product line is also dwindling. They completely stopped production of all their Lear products in 2021. reply dghlsakjg 10 hours agorootparentprevSure, if you want to play semantics: Cessna Inc. owned by Textron Aviation Inc. owned by Textron Inc., and Gulfstream Aerospace Corp. owned by General Dynamics Corporation. Both are wholly owned subsidiaries of their respective parent corporation ownership chains, and are commonly known by Cessna and Gulfstream. reply ARandumGuy 15 hours agoparentprevProbably the biggest barrier to a new creating a new commercial airline manufacturer is that there just aren't that many new planes sold each year. There aren't that many customers for commercial airplanes, and existing airplanes can last for decades when properly maintained. Combine all that with the inherently high costs of running a commercial airline manufacturer, and there just isn't enough demand to support more companies in the space. Changing that would require huge technical breakthroughs, or fundamental changes to how passenger air travel works. Neither of those seem to be likely in the near future. reply ponector 18 hours agoparentprevImagine you've spent 20 billion USD to develop, certify and create a production line. How you're going to convince airlines to buy hundreds of new planes they have no pilots for, no maintenance facilities and no predictions of reliability? reply thehappypm 9 hours agorootparentIt'd be a business decision; it'd be hard to imagine a brand-new manufacturer of a competitor to the 737 doing well for that reason. But maybe a supersonic jet, or electric-powered with lower operating costs, or more automation to reduce pilot needs.. there are many ways to innovate. reply wand3r 19 hours agoparentprevBoom is taking a Tesla approach to aerospace focusing on high end first with a Concord replacement. I am sure there are others working their way up the value chain reply hef19898 19 hours agorootparentBoom still isn't dead yet? reply ghaff 19 hours agorootparentBoom has all these fans on sites like this--and to be clear I wish Boom well--who also wouldn't consider spending $10K for a comfortable lie-flat seating flight from the US to Europe. reply notatoad 16 hours agorootparentprevBoom won’t die until the saudis give up on supersonic flight as a method to increase the demand for oil. reply consumer451 18 hours agorootparentprevHas Boom found a new engine supplier yet? reply buildsjets 15 hours agorootparentEvery major and minor engine manufacturer punted, so now they're making their own. https://boomsupersonic.com/symphony Hired an experienced propulsion guy away from Boeing to run the show. https://boomsupersonic.com/team-members/scott-powell They are not going to be able to do it, my opinion. There are very few people in the world who have deep experience doing 3D CFD on supersonic turbofans, I've talked to a few of them and none have been headhunted. The will need good analysis work, they are asking for a LOT out of a single stage fan. They certainly will not have the metallurgical research and manufacturing technologies of the engine manufacturers to use. But best of luck to Scott, his Porsche GT3 was getting kind of old and needs to be upgraded to the latest model. reply hef19898 14 hours agorootparentIf they hired a propulsion guy from Boeing to develop a new super-sonic engine, Boom fucked up. Boeing, same for Airbus, doesn't develop or built engines, let alone super sonic ones. But dor sure, said Boeing hire will be royaly paid for his service, good for them. And good for Boom, a prominent Boeing hire will make fundraising so much easier. But sure, as if building a new commercial airframe manufacturer isn't hard enough, becoming a new jet engine manufacturer on top of that is a winning strategy... reply buildsjets 14 hours agorootparentIn the specific case of Mr. Powell, I would agree that his skill set is primarily in the management of procuring and integrating of new engines from engine vendors into new airframes, and in the detail design of engine accessories and externals, and he is not experienced in the design of internal turbo machinery. And that's where the high risk for Boom is. However you would be completely mistaken to think that Boeing, and Airbus, and my friends down there with Embraer, do not have people who actively pursue and develop the core technologies needed to develop, analyze, and test all types of turbine engines, even if they do not result in market products. It is a necessary tool in order to evaluate offerings from the different competitive engine vendors. And at the senior level of engineering, there is basically a revolving door between the airframe manufacturers, the engine manufacturers, and a few of the high-level engineering focused airlines. People are constantly jumping around between them, there is a lot of cross-pollination going on. reply hef19898 13 hours agorootparentYeah, I know some of those engineering managers. They all work best in well-established, large orgs with people knowing the ins and outs of their jobs. The last time they actually developed something is quite a while ago. And managing engine suppliers, and component suppliers only gets you so far in developing the engines yourself. And we are talking super sonics ones. reply ghaff 11 hours agorootparentDesigning airframes isn't easy but aren't really novel. This is about coming up with engines that don't have noise concerns and have economics that would allow airlines to operate aircraft at prices that aren't that out of line with current ticket prices. It's not at all clear how big the market is for very premium tickets for supersonic travel is transatlantic and transpacific has a bunch of other range issues. reply hef19898 1 hour agorootparentConventional airframes are not novel, building an aircraft is still incredibly hard so. Civilian super sonic airframes so are novel, nobody did that since the days of the Concord and its Tupolev clone. reply consumer451 13 hours agorootparentprevThis is a tangent, but you are well informed in the space, and I would love to read your opinion. There is a new heli player trying to start from clean-sheet, called Hill Helicopters.[0] They are building a sleek new carbon fiber fuselage, but what I am wondering about is the fact that they are also making their own turbine engine.[1] I have assumed that their new turbine is the hardest part of their plan, am I correct in that assumption? Is it crazy, or not crazy, that they are trying to do this themselves? [0] https://www.hillhelicopters.com/ [1] https://www.hillhelicopters.com/gt50-engine reply buildsjets 4 hours agorootparentI would say it is not impossible for them to do it themselves if they are adequately funded, but I question the wisdom of choosing to do so rather than buying an existing certified turboshaft engine off the shelf, of which there are many in that power range. Also, that seems like an excessive amount of power for that size helicopter. A similar horsepower engine is the Pratt-Whitney PW206B, used in the Eurocopter EC135. But the EC135 is a much larger helicopter and has twice the payload capacity of this design. The engine itself is a fairly standard centrifugal compressor design, not particularly challenging from an engineering, or material science standpoint. But with no new technology being brought to the table, there is no performance reason roll your own engine, and you are going to have to beat existing engines that have decades of refinement behind them. I know of two other companies developing microturbines that are considerably smaller than this in an market where there is no real competition, with some cool new technologies like regenerative microtube recuperating heat exchangers. One of them is in development, one is flying their turboprop and developing their turboshaft. https://www.turbotech-aero.com/ https://turb.aero/ There is a design/prototyping/manufacturing company called ConceptsNREC https://www.conceptsnrec.com/home that specializes in turbine engine and pump design. They do analysis work for basically every jet engine manufacturer and automotive turbocharger manufacturer, have manufacturing facilities to prototype just about every part of a jet engine, and an extensive testing facility. I would just about bet that Hill has used their services in the design and prototyping of their engine. It's a great place to work if you have a PhD in aerodynamics but want to live in rural Vermont. They also sell a CAD design and CFD analysis software package specific to turbomachinery. If you like industrial stuff, here's a video of their prototype shop, showing some of the parts they make. My favorite is a tiny titanium impeller for a jet fuel starter system on the F-22, at 3:35. It's about the size of a quarter, and took 40 hours to machine with an 0.020\" / 0.5mm diameter ball end mill. I've met both the guys in the video, they are brilliant machinists, but definitely not well polished youtube influencers, lol. https://www.youtube.com/watch?v=6v98_oxqY7E reply ghaff 15 hours agorootparentprevI wish them the best but, even if they can get the technology to more or less work, the economics and regulatory environment are pretty tough. At the end of the day, it's almost certainly going to be an expensive airline ticket and even if United was (rather inexplicably) touting Boom in their advertising, I'm not sure how many customers there are to pay out-of-pocket for supersonic flights that are likely to be a premium over current top-end seating. I'd love to zip over to Europe a lot faster from the East Coast of the US. But I'm not going to pay as much to save time as I would for the rest of my trip. reply whimsicalism 18 hours agoparentprevThere's even more government protectionism/capture in plane makers than automakers. It would have to be a horizontal play by an existing company with large amounts of capital and relationships, like a Lockheed Martin or something. reply peterfirefly 12 hours agoparentprevIt might even be Tesla again. Somebody, somewhere will make an electric jet that is good enough. It will be very destructive for the old manufacturers, for old airports, and for many airliners. It won't need the long airways we are used to so we will likely get more point-to-point like travel to/from city centers (multiple sites for bigger cities). Longer-distance travel will still remain the remit of traditional jets -- but they will have a much smaller market so there won't be much R&D, except through state subsidies and military contracts. reply akira2501 14 hours agoparentprevAnother differentiation for Tesla was not having the dealership model. Perhaps the things not acknowledged are more important than those that are. reply ghaff 10 hours agorootparentI'm not sure how big a differentiation it was. There are no haggle dealerships, a lot of people still need financing, and people still need to get their cars serviced. reply rafale 19 hours agoparentprevThe barrier of entry is much higher with commercial aviation. You can get started with a lousy car but a lousy plane will never be acceptable. The MAX fiasco could have killed Boeing. Maybe Boom will succeed by getting its feet wet in the supersonic flight niche. Time will tell. reply 01HNNWZ0MV43FF 18 hours agorootparentWell, you could make a small plane if it's not lousy. Lilium and Electra are betting on something like an air taxi niche opening up if the fuel savings are worth it: https://www.electra.aero/ https://lilium.com/jet reply hef19898 14 hours agorootparentAt least Lilium is at least a couple of years, and billions, away from having a product they can sell. reply jowea 15 hours agorootparentprevMaybe start with a small plane instead of a lousy plane? reply ardaoweo 19 hours agoprevThis is the real problem with Boeing. The MCAS design fiasco and the door plug falling off were not isolated incidents, but symptoms of broader issues. I can only wonder what remaining hidden flaws aircraft currently in the air may have, and what they might cause in the future. Recently I had the option to fly on either 737MAX or 20 year old A319, and chose the latter option simply because I have more faith in safety culture at Airbus. reply hef19898 18 hours agoparentIf the Aircraft is 20 years old, you should worry a lot more about the airline's safety culture than the manufacturer's. Just saying. reply ardaoweo 15 hours agorootparentAs long as maintenance is done properly there's nothing wrong with old aircraft, there are very well defined maintenance programs that specify which parts should be checked / changed and when. The airline in question is among the oldest in EU, and has an excellent safety record. reply slices 18 hours agorootparentprevhttps://avgeekery.com/oldest-flying-airliners-in-the-united-... reply AnarchismIsCool 15 hours agoprevSomething that helps a lot: have a safety incident team with absolutely no connection to HR. They have no ability to fire anyone or report on your performance review, they don't talk to managers about people and just record and compile safety related issues. Yeah, you may have an employee or two who screams wolf a lot, but their job is just to investigate, fix the specific issue, anonymize, and aggregate the reports. This lack of connection should be very public so everyone feels comfortable talking to them. This is part of how the FAA vastly reduced the fatality rate in GA. They stopped playing cop and started playing engineer. reply kmonad 15 hours agoparentI like the idea, but I am pessimistic. The more experienced I get (aka getting older), the more I see administrative bloating as the cancer of institutions---a somewhat equally inescapable fate. Installing a safety reporting administration may do what it set out to do, initially. But at some point, promotions may be handed out to those with most reports, perhaps perverting the initial intent. In another thread I read that the EASA and FAA used to send Airbus/EASA engineers to Boeing (and maybe vice versa) who could raise all sorts of hell if mistakes were found. Such a setup seems perhaps harder to \"game\". I do not know this for a fact, I recall it from reading another debate, so take it as hearsay. reply euroderf 3 hours agorootparentThese sound like variations on \"tiger teams\". And they sound appropriate. reply bux93 19 hours agoprevIt's not that Boeing doesn't have any safety policies or procedures, it's just that no-one is aware of them, so nothing gets reported or fixed? Those findings are worse than you'd expect.. Wonder what it's like over at Airbus and Embraer. reply atoav 19 hours agoparentAs far as I know they have a very strict safety culture at Airbus. Living in Hamburg, close to their location there, made a factory tour once and met multiple employees during the years and had chats with them about general ways how things are done at the place. But a few chats with employees and a factory tour isn't the most reliable source to judge this. reply icegreentea2 17 hours agoparentprevIt's not that no-one is aware of them. I read at least two different sets of problems in this report. But first, some background. In the following paragraphs you can substitute \"safety\" with \"quality\" in every instance to get equivalent statements that might be more analogous to your experiences. There is big letter \"Safety Culture\". This is what happens when you study emergent behavior that you want to replicate, and try to systematize it as much as possible. For excample - as noted in the report, \"Safety Culture\" consists of 5 pillars - this categorization is purely the result of research and analysis and post-hoc reasoning. The point of \"Safety Culture\" is that we noticed some organizations that have (little letters) \"safety cultures\" or \"cultures of safety\" which were able to achieve long-term excellence in terms of safety, and decided to study their common elements. A company \"implements\" a big letter \"Safety Culture\" in hopes of inoculating and maintaining an actual \"safety culture\". A Safety Management System is a tool used to achieve and maintain the Safety Culture. For those not sure of what \"X management system\" means - it's basically a stack of documentation that defines a meta-process and processes that all of your other processes need to conform to, and by doing so, your employees will be forced into \"doing the right thing\", and aligning their actions and outputs with the goals of Safety Culture, and therefore eventually getting you an actual culture of safety. In the worst case when you fail at actually sustaining a real safety culture, an SMS then becomes a tool to enforce a minimal standard of safety, from even the most apathetic employee. This comes at enourmous cost of course. Anyone who has had to wait for 3 different authorizations to get a replacement computer at work has witnessed an analogous situation. Another point that's relevant is that the \"Safety Culture\" model that Boeing (and ICAO) is referencing is acutally quite young compared to Boeing's overall age. The Safety Culture references in the report are from 1997. The first edition of the ICAO Safety Management manual is from 2006. Boeing has been building safe plans for decades before these \"new fangled\" capital letter things have even existed. It's absolutely possible for an organization to build safe product without formalized adherence to the formalized \"Safety Culture\". Back to problems identified in the report: The first is that Boeing rolled out a new Safety Management System (SMS) in the last 5-8 years, along with adopting \"Safety Culture\" policies. But they seem to have blotched the roll out. The report notes that Boeing has its legacy policies and processes for dealing with safety, and those continue in parallel to the new policies and procedures defined in their SMS. They also noted that employees were skeptical of the sustainability of the SMS - ie, they were not sure if this was just some management fad. Many of the findings about \"lack of knowledge\" read exactly as I'd expect from someone who apathetically clicked through an online training module because they assumed it was useless fluff, because all the real work they've ever seen was handled through legacy processes. Note that a blotched roll out is not the predestined result, even in an environment which was previously lacking a real safety culture, or even middling management. This is a problem, but could maybe be tolerable (from the perspective of short-term safety), except for the fact that it seemed that that legacy backbone has been rotting away in terms of its effectiveness. The dual system surely isn't helping with its effectiveness. In other words, while this report focuses on Boeing's failure to achieve \"big letter\" Safety Culture, reading between the lines also implies a general lack of actual safety culture, and a lack of competent change management. reply michaelcampbell 17 hours agoprevSafety culture is too hard for the MBA's to put a dollar value on, until it's too late. Having worked in the (network) Security domain for some time, the same thing there. When things are going well, \"what do we pay you for?\", and when they turn catastrophic, \"what do we pay you for?\" reply chongli 19 hours agoprevI think the ultimate problem with Boeing is that they're too big to fail. They're too important to the US's strategic interests so the government won't allow them to go out of business despite gross incompetence. A classic case of \"putting all your eggs in one basket.\" reply mrtksn 19 hours agoparentHow does a failure look like? I mean, this is not a financial institution and in the case of a financial failure people who make planes, the machines they use and all the IP wouldn't disappear. The Boing might actually be too big to fail but their failure, IMHO, looks like what we have today: An inability to make high quality cutting edge aircraft. For the USA, the disaster would be to be reliant on EU/Russa/Brazil/Canada/China for conducting its transportation operations in this massive country. What happens if people start freaking out when their planes are not Airbus? Would increase in government contracts keeping the stocks and profits the same mitigate the problems? So maybe Boing has failed already, its just that its still institutionally solvent for one reason or another. reply adolph 19 hours agorootparent> in the case of a financial failure people who make planes, the machines they use and all the IP wouldn't disappear. Things get lost all the time. People move on, retire, machines require maintenance and remanufacturing, IP might describe an end state but not how to get there. Some say Boeing itself is an example of this after the MD merger. reply ActionHank 18 hours agoparentprevSure, but maybe fire and prosecute some of the execs? Given that they are largely not responsible in delivering the value that will ensure continued success of the company, signal that risking the lives of people is not a good business strategy, and may act as a wake up call for others in leadership positions that they should be leading towards what is best for customers and the business and not what is going to give them the biggest short term payday. reply euroderf 3 hours agorootparent> maybe fire and prosecute some of the execs? Call me a cynic - but isn't an organization like Boeing designed to diffuse responsibility, so as to shield the guilty behind corporatespeak ? Sure you can subpoena millions of pages of documents and countless emails, but then the sheer size of the legal effort threatens to defeat the entire idea of assigning responsibility. reply lenerdenator 19 hours agoparentprevThis is when you split the company's civilian aircraft operations into two companies. reply jajko 19 hours agoparentprevNo pressure for excellence usually leads to lack thereof reply Sebb767 19 hours agoparentprevI think the problem is not that Boeing is too big to fail, it's the massive cost of designing, certifying and efficiently building a new airframe, which makes it hard for a competitor to emerge. The US doesn't really have another basket to put eggs into. reply dotnet00 19 hours agorootparentExcept that they have had issues with other things as well. Over on the space side, their Starliner crew capsule has had several safety debacles over the past 4 years, such that maybe it'll finally carry crew this year. First it was poorly tested software, then stuck valves, then the tape they wrapped certain wires in to make them more fire resistant turned out to not work, and then finally after all that testing, their parachute system had issues. Boeing has had cultural issues for a while now, part of their rocketry division was forced to be spun out (by the government) with Lockmart's into ULA because Boeing was caught conducting espionage on Lockmart, which would've potentially disqualified them from bidding on launches. They had also had information leaked to them about bidding on the Artemis lunar lander contracts. Plus other incidents like trying to get people at ULA proposing things like orbital refueling systems fired because if they allowed such technology to emerge, Boeing couldn't get blank checks from the government for building near-useless rockets. That last one, in my opinion, making it clear that they're exploiting the perception that they're too big to fail. reply gmerc 19 hours agorootparentprevWhy is Airbus not falling out of the sky? reply giva 18 hours agorootparentThey do, the just need more effort: https://en.wikipedia.org/wiki/Air_France_Flight_447 reply kayodelycaon 17 hours agorootparentNot a great example. Any plane would have crashed with the pilots doing what they did. Most planes don't do well when you try to climb them out of a stall. (Climb out, not power out.) reply thelastgallon 18 hours agorootparentprev\"Air France and Airbus have been investigated for manslaughter since 2011, but in 2019, prosecutors recommended dropping the case against Airbus and charging Air France with manslaughter and negligence, concluding, \"the airline was aware of technical problems with a key airspeed monitoring instrument on its planes but failed to train pilots to resolve them\" reply amelius 19 hours agoparentprevMaybe true for the company, but certainly not for its management. reply 7thaccount 19 hours agorootparentThe last one fired got a $60M golden parachute and then became CEO of another company. There seems to be little incentive there. reply chii 19 hours agorootparentwhat gets to me is how anyone would hire the fired CEO given the reputation. reply lucianbr 18 hours agorootparentSeems like nobody hired him as CEO. Him and some buddies tried to start something, and it didn't get anywhere, and they lost money with it. Sounds quite reasonable to me :) https://www.seattletimes.com/business/boeing-aerospace/forme... reply tass 19 hours agorootparentprevI haven’t looked at their financials, but I’m assuming he successfully increased profits for Boeing. He’s probably hireable so long as there’s no culture of safety or engineering to be destroyed. reply godzillabrennus 19 hours agorootparentprevA known quantity to the industry who managed to deploy billions in budgets for a massive player is valuable at the helm of any company that wants those kinds of things. reply lenerdenator 19 hours agorootparentprevTypically it happens when buddies are on the board. reply lucianbr 19 hours agorootparentprevWhat company did he become CEO of? Couldn't find anything on Google. reply Tempest1981 19 hours agorootparentNew Vista Acquisition Corp. reply lucianbr 18 hours agorootparentI thought he was put CEO of an existing company that did something. This was just him and some buddies starting a new venture that didn't go anywhere, and they only lost money with it. I mean, it's far less paradoxical than it sounded at first. reply spamizbad 19 hours agoparentprevIIRC Boeing's defense and airliner business units are separate. So they really aren't too big to fail: the defense side is insulated from the commercial airliner side. reply lenerdenator 19 hours agorootparentThey are to a point. The military side typically uses Boeing's airliner offering as a basis for things like transport, AWACS, and logistics aircraft. reply CobaltFire 18 hours agorootparentI’m unsure what you mean by transport and logistics; we use civilian airframes with any amount of modifications for only one in production aircraft that I’m aware of (P-8 Poseidon is based on the 737). The TACAMO and AWACS are both based on the 707, which is long since out of production. None of our strategic lift capability (logistics in your comment?) is based on civilian airframes. reply lenerdenator 18 hours agorootparentKC-767, C-40, KC-46, E-4, VC-25. reply CobaltFire 18 hours agorootparentThanks! I was in aviation, but primarily tactical and expeditionary. I always forget about the C-40 despite having ridden in one multiple times. The E-4 and VC-25 aren’t really a fair one; you don’t need the divisions to be the same company for their integration (though I suppose it would make it vastly cheaper). We also don’t fly many at all (meaning cost per unit is relatively inconsequential). I also somehow always forget the tankers. Thanks for that. I’ll still maintain the links aren’t necessary. I honestly think a dedicated military platform for all of those would have been a smarter investment and that the current way of modifying airliners is suboptimal. reply lenerdenator 15 hours agorootparentIt's agree it's probably suboptimal, but I don't think anyone's going to be willing to front the cash for development of a new airframe specifically for military/government use. The advantage of the airliner route is you have at least some revenue stream to fall back on if the military decides it doesn't want the new shiny or a court/congressional committee decides the military went about choosing the new shiny the wrong way, which happens often. It's just a ton of financial risk. I guess the new supersonic startups like Boom think they bring enough novelty to the market to justify that risk. reply CobaltFire 14 hours agorootparentThat’s a very solid point. I do wonder why the heavy lift platforms won’t work (C-17, etc.). reply tsunamifury 19 hours agorootparentprevCommercial airline manufacture is also in our global strategic interest. reply adolph 18 hours agorootparentWhy is that? Could it be that reduced commercial aircraft lead to better outcomes for high speed rail and future suborbital passenger rockets? Is seeing a strategic interest in commercial aircraft a local minima that prevents further improvement? reply tsunamifury 18 hours agorootparentThis is some paranoid nonsense. It’s that keeping capacity for one of the leading forms of global travel is a strategic interest. Don’t let your conspiracies get in the way of the obvious. Also I feel like the rail circle jerk is so unearned. Last time I was in London it cost 100 pounds to fly to paris from London downtown airport and 600 to take the Chunnel. How “superior”. reply bee_rider 18 hours agorootparentI don’t see the paranoia or conspiracy in their comment. Plane based infrastructure could be a local minima that we’ve bungled our way into without any need for coordination. reply adolph 16 hours agorootparentprevHey, no paranoid conspiracy intended. Simply thinking out the counterfactuals. Is tying a particular activity to \"national interest\" itself a form of paranoia? What about passenger aircraft is a strategic interest? For example, the US seems to do ok with little large-scale shipbuilding outside military concerns. People seem to take cruises from the US in ever-larger cruise ships without a domestic capacity for building them. Additionally, no disagreement on my part regarding the high regard people have for hypothetical rail. On the other hand, I'm open to the idea that high capacity terrestrial transportation similar to rail would have cause to improve if airplanes weren't in an optimization sweet spot. reply dboreham 19 hours agoparentprevThis argument doesn't make sense: the US military is also too big to fail, yet apparently reasonably competent. reply fallingknife 19 hours agorootparentThe US military is a massive inefficient bureaucracy. Just look at the $5 billion and 8 years wasted on their failure to implement an ERP software system that is standard in large organiations https://www.thirdstage-consulting.com/lessons-from-the-us-ai... Note the senate investigation report that describes an “organizational disaster” that caused the failure. Don't assume competence because of size and persistence. reply CobaltFire 18 hours agorootparentI think this is a common civilian misunderstanding of how the military breeds competence. The US Military is absurdly competent at what its mission is, war fighting and logistics. What it is not competent at is things that are not yet internalized as part of that mission. Unfortunately non visible logistics (software) hasn’t made that cultural shift yet, and once it does will take a long time to breed the institutional competence that the military leans on, primarily due to the compensation gulf. reply kube-system 18 hours agorootparentprevThe US military is the largest employer on Earth, some amount of bureaucracy is inevitable. But they are not a business and do not optimize for dollar-efficiency like for-profit businesses do. They optimize for other goals. 'Wasting' 5 billion out of an 842 billion dollar budget, for an organization that doesn't even have to make money, is nothing. Plenty of startups squander even more money, and never accomplish any of the entire point of a for-profit company, making money. reply bee_rider 18 hours agorootparentprevWhat does efficiency have to do with anything? Efficiency and robustness are often opposed (one hates redundancy and the other loves it, for example). reply velcrovan 19 hours agoparentprevThe federal government should buy a controlling share in the company, problem solved. reply euroderf 3 hours agorootparentIsn't there some precedent for this in the automotive industry ? For example, in running Chrysler ? reply godzillabrennus 19 hours agorootparentprevFederal government can’t run itself today. Probably not going to be effective running Boeing either. reply FirmwareBurner 19 hours agoparentprevIsn't this what our version of capitalism encourages? Grow to dominate so much of the market and of stock and pension portfolios at all costs, that you'll have to be bailed out no matter your incompetence. So as long as this behavior only gets rewarded and never punished, why would you expect different results? reply nequo 19 hours agorootparentCar manufacturing is similar in a lot of ways yet notably different in the putting all eggs in the same basket sense that parent mentions. Ford and GM are too big to fail yet they do compete and it does lead to at least one of them making decent cars that don’t fall apart under you. reply FirmwareBurner 19 hours agorootparentFord and GM have much more competition than Being. It's a lot easier to enter the auto market than the aircraft market. reply nequo 18 hours agorootparentThat is true, but Boeing wasn't always the only player in aircraft manufacturing either. Even subsidizing two or three players so that they can compete might be better for safety and quality than letting them merge and operate as a complete monopoly. reply lp4vn 19 hours agoparentprevModern capitalism supresses competition, that's what happens. What if McDonnell Douglas had never been merged? What if Embraer had been bought by Boeing? That's the harm that monopolies do to society and yet somehow they have been even incentivized in recent times. reply neilv 13 hours agoprevIf company leadership recklessly eroded safety practices, of a well-understood safety-critical national institution... is there individual criminal liability? Prosecuting willful bad behavior at the top that led to deaths might help push the culture back. reply WheatMillington 13 hours agoparentI don't know the situation in the USA, but it would appear there is virtually never indivdiual liability. Here in New Zealand there is absolutely personal director and executive responsibility and accountability where it comes to safety. reply dboreham 19 hours agoprevThe KPIs are all good though. reply jeffrallen 17 hours agoparentExcept \"number of days since last door fell off\" which is trending a bit lower than we'd like to see. And \"number of days since last damning report from our regulator saying our safety culture is totally messed up\" which is (checks notes) 1 day. reply rapatel0 19 hours agoprevBoeing is another in the long list of companies that were taken over by process and finance people and driven into the ground with short term thinking largely centered on reducing cost-structure and financial engineering. Elon has a great diatribe describing how the big automakers largely broke down and outsourced most parts manufacturing just became system integrators and customer support. In the short term, this is great for the bottom line, but it hollows out the engineering culture and make it extremely difficult to innovate. Imagine trying to get 100s suppliers to make small tweaks to each of their parts. Also, imagine when you need multiple suppliers to work together to build (NDAs, IP agreements, etc). You get buried in bullshit Great companies are generally lead by R&D (product, science, engineering) with strong finance / process acting as gravity to keep the company grounded & functioning. When finance / process take over, then gravity will dominate and you crash reply matthewdgreen 18 hours agoparent>Elon has a great diatribe describing how the big automakers largely broke down and outsourced most parts manufacturing For a company that purports to be an energy storage and generation business (with cars as an initial application), Tesla remains hugely dependent on their own suppliers. Panasonic occupies a major chunk of Tesla's own Gigafactory and has repeatedly delayed the production of new cells [0], [1]. [0] https://electrek.co/2024/01/15/panasonic-to-soon-make-new-ba... [1] https://www.reuters.com/technology/panasonic-delays-producti... reply toomuchtodo 18 hours agorootparentPanosonic is trying to keep up with Tesla. There are technical challenges with the 4680 cell manufacturing process they are attempting to resolve that are leading to suboptimal yields. https://cleantechnica.com/2023/12/24/tesla-4680-battery-prod... reply amluto 17 hours agorootparentI’m no expert, but I do recall Tesla saying, at the beginning, that they were using 18650 cells because they were widely available. Well over a decade later, the major battery makers are producing prismatic cells in volume, and Tesla is still working on their fancy new cylindrical cell. I wonder if they’re doing this is due to some kind of design inertia at this point. Right now, I can buy US-assembled complete energy storage systems (not necessarily at volume), retail, using prismatic LFP cells, for a lower price per unit energy than the Tesla Megapack. reply toomuchtodo 16 hours agorootparentTesla uses prismatic cells as well. You are no expert (as you said), and of course you can buy your own storage cheaper than turnkey utility scale systems. Energy developers aren’t building their own systems; they cut Tesla a check and install the asset (orchestrated by Autobidder). https://insideevs.com/news/542064/tesla-model3-lfp-battery-p... > Tesla uses LFP cells supplied by a Chinese manufacturer - CATL, which has basically become a strategic partner with a contract for the next several years. > Because the LFP chemistry does not offer as high energy density as NCA or NCM, Tesla uses LFP only in the standard range versions of its cars (produced in Shanghai and soon globally). LFP will be used also in Tesla's energy storage systems. reply matthewdgreen 16 hours agorootparentThis seems to confirm the initial point, which is that Tesla mainly outsources its most critical ingredient (batteries) to outside suppliers. Suppliers that are, incidentally, increasingly competing directly with its main lines of business. That might be ok in the car industry, where people will pay a premium for brand names. Seems bad if your goal is to dominate energy storage. reply toomuchtodo 15 hours agorootparentNo one builds energy storage at the rate Tesla does, so while this risk keeps being surfaced on HN (\"but what about...\"), until there is material movement from competitors, \"meh.\" If it's so easy, by all means, do it. But talk is relatively cheap. https://www.energy-storage.news/tesla-deployed-nearly-4gwh-o... https://www.energy-storage.news/tesla-deployed-6-5gwh-energy... https://carboncredits.b-cdn.net/wp-content/uploads/2023/07/T... (Source: https://carboncredits.com/tesla-413m-megapacks-revolutionize...) > Such tremendous growth has been particularly attributed to ramping up Tesla’s Megapack production capacity in its recently built 40 GWh Megafactory in California. The company aims to produce 10,000 Megapacks each year in this factory. > Earlier this year, Tesla also revealed plans to construct another 40 GWh Megafactory in Shanghai, China to meet the robust demand for its energy storage systems. Construction will start later this year. https://electrek.co/2023/12/22/tesla-launches-project-build-... The global market for energy storage is enormous, approaching almost half a trillion dollars by 2030. https://www2.deloitte.com/content/dam/Deloitte/us/Documents/... https://www.precedenceresearch.com/energy-storage-systems-ma... reply matthewdgreen 13 hours agorootparentI'm as excited about this progress as anyone. But (1) Tesla's Megapack business isn't objectively that big compared to its other businesses, (2) while it may be big in the future, that assumes they don't face serious competition from cheaper suppliers, (3) Tesla currently seem to be hugely reliant on Chinese suppliers and factories to build its storage, with no immediate plan to change this, and (4) the Chinese government and battery sector has made clear that it intends to dominate these industries at any cost. Saying \"I'm not worried about this\" is like saying you're not worried about a giant truck that's speeding directly at you. The question I'm asking in this thread is whether Tesla has a plan to avoid getting hit by it. reply toomuchtodo 13 hours agorootparentI assume their plan is to continue to have the business run by the human equivalent of an AI reward maximizer. It has worked for them so far to have obsessive people in key leadership positions, and I would expect it to continue to work. Without material non public information from Tesla internal, hard to say either way, we can only speculate. Past performance does not guarantee future returns, but still valuable signal. reply LeifCarrotson 18 hours agoparentprev> Great companies are generally lead by R&D (product, science, engineering) with strong finance / process acting as gravity to keep the company grounded & functioning. When finance / process take over, then gravity will dominate and you cra",
    "originSummary": [
      "An FAA panel harshly criticized Boeing's safety practices, pointing out a lack of employee awareness in reporting safety issues.",
      "The article delves into various safety-related subjects within the aviation industry, offering a broader perspective on safety concerns beyond Boeing.",
      "-"
    ],
    "commentSummary": [
      "Boeing is experiencing a decline in safety culture due to prioritizing cost-cutting over safety, emphasizing the necessity of a robust safety culture in organizations.",
      "The summary stresses the significance of learning from mistakes, promoting accountability, and the role of leadership, unions, and regulatory oversight in upholding safety standards.",
      "Topics such as supersonic travel, helicopter manufacturing, and challenges in the energy storage market, especially for companies like Tesla, are also touched upon in the discussion."
    ],
    "points": 364,
    "commentCount": 297,
    "retryCount": 0,
    "time": 1709040624
  },
  {
    "id": 39522249,
    "title": "Why Experience Makes Time Seem to Pass Faster",
    "originLink": "https://invertedpassion.com/why-time-seems-to-pass-faster-as-we-age/",
    "originBody": "Why time seems to pass faster as we age Posted on February 27, 2024February 27, 2024Author Paras ChopraPosted in Personal, Philosophy 1/ I’ve been mega-obsessed with this feeling. A year as a 36-year-old seems so much shorter as compared to when I was a kid or even as a teen. It seems cosmically unfair – we have fewer years to live, and each year flies by faster. 2/ But, why is that happening? My tentative conclusion is that it’s an unfortunate outcome of how evolution shaped our brain to be an efficient storage device. 3/ Our brain is a prediction device. Its top job is to construct a model of the world so that we get a survival and reproductive edge. 4/ To be able to predict a phenomenon is to be able to control it and have power over it, so our brain is obsessed with predicting how things are going to go. It wants to be able to predict how mates are found, how money is made, what makes people laugh, and so on.. 5/ But it’s also efficient. If an event has happened before, what’s the point of paying attention to it and storing it in memory? Redundant storage is inefficient, so the brain likely only pays attention to and memorises what’s new and surprising. 6/ As kids, everything is new and surprising. The world is full of learning opportunities, so the brain makes massive updates in memories. Full snapshots of your birthdays, vacations, days at school and so on. 7/ Surprising information comes in droves every single day, so the brain simply paid a lot of attention, and hence you felt there were so-many-slices-of-time in a day. It also stored that rich information in memory, so even looking back, days felt longer. 8/ As we grow, new surprises become a merely tiny-patch on an old memory. Why store the full details of your N-th vacation when you can simply store the diff of it from your first one? 9/ In other words, as we age, our memories and attention become low-fidelity versions of their former self. As patterns in life start repeating themselves, the slices-of-time that you notice and memorise become fewer and coarser. 10/ Naturally, if anyone asks where did time in your life go, you’d access your memory and find the majority of them relating to childhood, and very few from the recent times. And that’s why time feels like it accumulated in the past, and not in the recent present. 11/ The main culprit in time-speeding up is predictability. The more predictable your days are, the shorter they will feel. 12/ A thought experiment. If you have a stable job, you can pretty much mentally time travel a full year and find your days to be similar. But if I ask you to imagine doing a PhD in Sanskrit at a foreign university, you would have no idea what your days are going to look like. 13/ So, predictability not just impacts perception of time in the present but also for the future. As kids, a vacation was full of surprising information, so it actually felt rich and long. Now, your nth trip to Goa feels much shorter as you know what you’re going to do. 14/ So, what to do? How to slow down time? The only approach I can think of is to break the predictability and actively plan to be (massively) surprised. Take on projects that you have no idea about. 15/ Unfortunately, we are evolved to avoid exploring and taking risks as we age. Our brain pushes us to exploit more of the world we have come to understand better instead of pushing us to explore more. But that’s precisely how you’ll make your years fly. 16/ You need to ask yourself. How do you want to answer how you lived your life? Long one, or the one that *feels* long? What’s more important to you? 17/ Interestingly, the solution to slowing down time is not boredom (as I thought). Boredom is a negative state. The solution is to dive head-first into unknown territory. That is, to travel physically or mentally, 18/ Note that we’re really good at grokking patterns / making predictive models. As soon as we figure out a winning condition for a game or the story plot, we lose interest in it. 19/ So an existential crisis is a spoiler alert for life. The brain with all its predictive models asks: is this all to life? But it’s mistaken – it’s all only to the life that it has chosen to live. 20/ A (radically) different life that it can’t predict will keep brain at its toes. The key word here is “radically”. The smaller the change, the less memorable the time. Join 150k+ followers Follow @paraschopra Get my new essays in your email",
    "commentLink": "https://news.ycombinator.com/item?id=39522249",
    "commentBody": "Why time seems to pass faster as we age (invertedpassion.com)342 points by paraschopra 23 hours agohidepastfavorite225 comments jvanderbot 20 hours agoI've been journalling for 10+ years. In addition to forcing me to actually write down what happened that day, reviewing old entries provides a feeling of history that makes life feel soooo long and so rich. I can review my now-wife's rocky courtship and feel grateful we made it. I looked back 3 years ago and found the day our children were conceived :D (we have twins). I can review the anxieties of my PhD years, etc etc. For some reason, feeling like my past life has not been short helps me to feel that there's so much life left to live. Looking back at the phenomenal changes of the last 5 years (or 10), shows me that I can do a lot with the next 5 years. Novelty and so on may help to \"slow\" time, but for me the perception of the shortness of life is best fought by reminding yourself that it is not short, and there is so much change coming - more than you could imagine. (and I'm horrible at doing it every day, maybe every week or so during slumps) We're at our computers all day every day. So I just lowered the barrier to entry with a few bash tricks. It's helped me keep the habit up. https://jodavaho.io/tags/bullet-journal.html Now, I review 1, 5, and 10 years ago every day, to re-live my life from those years, so to speak: # list dates from 10 years ago +/3 3 days # get years and day range from args echo \"### $years years ago\" for i in `seq -w -$days $days` do olddate=`date -d \"$years years ago $i days\" +%Y-%m-%d` longdate=`date -d \"$years years ago $i days\" +%A\\ %B\\ %d,\\ %Y` echo \"### $olddate.md ($longdate)\" cat $olddate.md done reply fufufu123 15 hours agoparentYou're apparently in a good place so looking back is your path to your joyful present. I'm in a bad place so looking back is my seeing back when I was still hopeful for my various life goals. I'd meet someone and have someone to share my life with, do activities with, travel with, raise kids with, etc. I never met that person and now at 60+ that's nearly impossible so looking back hurts. It hurts a-lot. Seeing the opportunities I missed, the time I squandered, the naiveté that \"it will happen when it happens\" etc.. I absolutely want to strangle Google/Apple/Facebook when they shove \"memories\" in my face. I didn't ask for it, piss off! As for the topic itself. The obvious reason time passes faster when we're older to me is that each day is less of my life. At 1 week old a day is 1/7th of my entire existence. At 60 one day would be 1/22000th of my life. I also feel it in terms of time left. When you have $1000 in your wallet, splurging on a $50 meal might seem fine. When you've got $75 in your wallet you're unlikely to blow $50 of it on a meal (unless you've got a supply elsewhere). In the same way, when I've have got 20yrs left in my life, some of them probably not in the best of health, then committing 10 of them to move to a foreign country to immerse myself in a new language feels very different than when I've got 60 years left (20yrs old). Seeing your life left clock go down 1/60th (1yr at 20yrs old) feels slower than seeing it go down 1/20th (1yr at 60yrs old). that's 3x faster. reply Spooky23 12 hours agorootparentMy situation is different. I lost the love of my life and felt lost and alone. Even with the support of good friends and family. But that said, there’s alot of philosophy and other things to help. Aeschylus said “Happiness is a choice that requires effort at times.” Another relevant quote is that the best time to plant a tree was 20 years ago, the next best is today. You won’t get what you wanted, but live in the present and enjoy what you can have. I’d give anything to get my wife back, but that’s not reality. The next best thing to live today and find joy. reply druub 1 hour agorootparentsorry for your loss and thanks for sharing. At times I think I don't have the strength to go on after something like this happens to me. But so happy that you are able to still find joy. reply Hendrikto 11 hours agorootparentprevSorry for you loss and thanks for the advice. I like the Aeschylus quote, it‘s a good one. reply richardw 5 hours agorootparentprevAlmost 51 here. I moved countries partly because it refreshes my mental clock. So much to learn and experience and try new things. I've lived more in the past year than the previous 5, and filled up the photo book so much. I'm truly sorry about all the bad memories. I do know what that is like, many what-ifs. If you're receptive to any thoughts: Mourn them, but try not to waste the present being angry about the past, or you'll regret missing out on this time too. Give yourself another shot, try again. There will be a time where you don't get any more chances, but it's not yet. I know post-70 year olds that have cycled up mountains in France. One that just stopped being a climber after two replaced hips. I'm sorry about the kids. Maybe travel and meeting someone is still an option. Take care. reply nuancebydefault 14 hours agorootparentprevSorry to hear that things did not turn out as expected for such a long time. If I may provide a suggestion... search for a serious website that is about dating (not tinder or something the like) in your area and connect to people and try to date (meet in person for at least an hour or so) at least one person once a week. Don't spend too much effort in people who just want to stick to online conversations or fooling around, just move on. If at the meetup there's no click, you have a good evening or at least you built up experience in dating. You will need to get probably seriously out of your comfort zone but it becomes easier each time! Practice makes perfect! reply SoftTalker 12 hours agorootparentprevThe past is the past, no sense in regretting it since you cannot change it. I'm not quite as old you but close, and I already feel what you're feeling about the time left. That there isn't a lot of it, or that it will be gone quickly. Everyone has things they will not get a chance to try or experience. No lifetime offers everything, and every path taken means many, many others will be never explored. Like money, you can't take memories with you. So try not to dwell on things you didn't do or that didn't work out the way you imagined. Half or more of people who get married end up divorced. Probably many more are less than happy. Kids can be a joy but they can also be a heartache. Every criminal is somebody's kid. Nothing comes with any guarantees. Make life interesting today, as today is the only thing you really experience. reply popularonion 14 hours agorootparentprevThank you for expressing what myself and so many others can’t put into words. reply jvanderbot 13 hours agorootparentprevI'm sorry to hear this has been difficult. I want you to know that I feel this way often as well. If you ever want to chat, my email is at the link in my post (GP to this comment). I'd be a very lucky man to hear your experiences and learn from you. reply overtomanu 14 hours agorootparentprevMaybe you are better off than people in bad marriage's. reply EEMac 14 hours agorootparentprevI hope things get better for you. If it helps: https://www.7cups.com/ reply koyote 12 hours agorootparentprev> then committing 10 of them to move to a foreign country to immerse myself in a new language feels very different than when I've got 60 years left Could you elaborate on that? As someone who is younger I have noticed that many (but by no means all) people over 60 often do not want to commit to these kind of 'life-changing' escapades, despite now having the time (kids out of the house and/or retired). I assumed it was more around lack of (youthful) energy/health and the fact that you're so used to how you've lived for decades that change is far more difficult or feels more daunting. You're saying that having a relatively shorter amount of 'time left' makes such a move different, wouldn't that fact make it easier? (YOLO and so on...) reply RaoulP 3 hours agorootparentIt's kind of an investment. It's a chore to begin with, that hopefully pays off in the long run. Moving to a foreign country with an unfamiliar culture and language, and establishing a new life there, is a chore. Probably even more so if you don't have a spouse or something who's familiar there: Learn the language, the culture, establish or reestablish your daily habits, find new friends and ways to socialise, perhaps new hobbies if the old ones aren't available. Find out where and what to shop and how to cook, when the stuff you know is gone. Turn your house into a comfortable home, etc. If you're older you might not feel that you'll get to see much of the payoff. I also imagine it gets harder to find people who are open to new friendships, as you get older. reply munksbeer 21 minutes agoparentprevThank you very much for this helpful comment and sharing your experience. It is really encouraging me to resume journaling, as I've made several efforts over the years but always fade away after a few months. I'm sorry you've received negative comments in reply, it is weird that people feel the need to be so negative to someone trying to help. I just sometimes have a hard time understanding their mindset. reply simpletone 16 hours agoparentprev> reviewing old entries provides a feeling of history that makes life feel soooo long and so rich. This doesn't sound right at all. For me, and I suspect for most people, it has the opposite effect. It makes life feel short, fleeting and mundane. Looking back to 2014, I can't believe how quickly the past 10 years has gone. Heck just looking back 4 years, the pandemic years seems to have flown by. It's like a distant memory now. > but for me the perception of the shortness of life is best fought by reminding yourself that it is not short So it isn't journaling at all. You are just rationalizing. Life is precious because it is short and fleeting. And it's why people keep a journal. To keep track of precious time. It's also why parents keep a scrapbook of their kids. Because in a blink of an eye, the kids grow up and leave the nest. If you truly thought life wasn't short, you wouldn't keep a journal. You'd just live and not keep track of time. reply balaji1 13 hours agorootparent> It makes life feel short, fleeting and mundane I read somewhere else that time speeds up when we repeat a few boring/not-so-stressful things each day. > reviewing old entries provides a feeling of history that makes life feel soooo long and so rich I want to agree with it. The more I take on and do, however imperfectly and which involves a bit more stress, it starts to slow down time. At least in the sense that you look back at the previous year and think \"wow that was a lot and it seems like so long ago\" when it actually wasn't that long ago. > It makes life feel short, fleeting and mundane In fact, the key might be to journal more of the mundane things. Like how many times I had to get on a call with the background verification company to speed up my move to the new company. and from OP article, > Surprising information comes in droves every single day, so the brain simply paid a lot of attention how come all the new/surprising info from shorts/reels/tiktok not have a effect of slowing down time haha? reply fufufu123 15 hours agorootparentprevAgree. When I look at my photo collection it can glance at my entire life since ~1998 to present in just a few moments. It feels extremely short. reply bonoboTP 13 hours agorootparentprev> the pandemic years seems to have flown by. It's like a distant memory now. So does it feel distant or just like yesterday (i.e. time flew by)? The two seem contradictory. reply bowsamic 14 hours agorootparentprev> Heck just looking back 4 years, the pandemic years seems to have flown by. It's like a distant memory now. I'm confused, does it feel recent or very long ago? This seems to contradict your previous sentence. If 10 years has gone past quickly, how could the pandemic feel like a distant memory? In that case it should feel like yesterday reply overtomanu 14 hours agorootparentI think he has forgotten most of the memories related to pandemic, so it feels like distant memory, only bits and pieces left. reply bowsamic 14 hours agorootparentOkay but again that makes it sound like it feels very long ago, not recent reply theodric 15 hours agorootparentprevLife is long, provided you don't just waste your time with nonsense. Even eternity wouldn't be long enough for the compulsive procrasturbator. reply simpletone 15 hours agorootparent> Life is long, provided you don't just waste your time with nonsense. Life is short whether you waste it on nonsense or not. It's the nature of human life. > Even eternity wouldn't be long enough for the compulsive procrasturbator. Sure. But eternity isn't enough for the most accomplished either. There is a reason why the emperor of china https://www.smithsonianmag.com/smart-news/2000-year-old-text... and steve jobs https://archive.nytimes.com/well.blogs.nytimes.com/2009/06/2... both wanted to prolong their lives. I don't think anyone would characterize the emperor of china nor steve jobs as 'procrasturbators'. You make it sound like active people ( who don't waste their time ) feel that life is long when it's precisely the opposite. It's those who don't waste their time who want to live longer because they have so much more to do. Then again, 'wasting time' is a concern for many precisely because life is short. reply david-gpu 14 hours agorootparentprev> Life is long, provided you don't just waste your time with nonsense. Even eternity wouldn't be long enough for the compulsive procrasturbator. Is it possible you are projecting your own insecurities, given that you are commenting on HN during work hours on a weekday, of all things? reply leokennis 19 hours agoparentprevI am trying journaling as well but most days I don't know what to write...most days I'm not really doing special things, I have no special feelings. These days are enjoyable because I like my work and love my family, but I don't get further than \"went to work, afterwards cookedand playedwith , in the evening \"... What are you journaling on a daily basis? reply jvanderbot 18 hours agorootparentMost of the time it's \"I have to do this\" or \"I wish I had time to do this\" or \"Hey here's a random idea I had\" or \"My kids did this cute thing\" or \"We fought about this, here's what I think\" or \"oh here's my 3 favorite links from HN and what I thought about them or what they made me think about.\" It took time to realize that was worth writing down. Honestly I look back 10 years and see things like you describe. \"I went to the gym for an hour, worked on this or that, blah blah\", and I really love seeing that too. That's life man. Those memories fill your brain up with experiences and a sense of time if you let it. Just remembering how fit I used to be makes me happy and makes me want to do that again. reply xahrepap 18 hours agorootparentprevSlightly different angle: I’ve been digitizing my grandparents’ journals. Something I’ve appreciated is the mundane. “Had a headache. Went to bed early” seeing how often my grandpa was sick was very eye opening to me. “Got the X repaired/replaced. Cost me $Y and it took Z days to finish” “I sat and just visited with $Child. What a good kid. He’s just a teen. He told me about his friends and school” Etc. I don’t know. I guess reading a normal life makes me feel better. Growing up I thought they were perfect. Seeing they were people just like me with very similar struggles is actually fun. reply RaoulP 15 hours agorootparentSo lovely to read this. My late father was, in his later years, often writing in his diaries at the kitchen table. I haven’t taken the time to go though these diaries after he passed, but I did take a peek since I never really knew what he wrote. The little I saw was so surprisingly mundane, like you describe. I can’t quote it now, being thousands of miles away, but I remember something about my mom making a tasty soup. I found it endearing but also forgiving, since I’ve struggled with journaling myself. Your post reminded me now that it’s okay to note the mundane. reply jollyllama 18 hours agorootparentprevI have the opposite problem. I could write a page of literary prose about every day. Bulleting feels like it would be doing an injustice. So I do nothing. reply RaoulP 14 hours agorootparent> Bulleting feels like it would be doing an injustice. So I do nothing. I usually suffer from the same. Some periods I do bother bulleting, as reminders for thoughts to expand on later in the day. But I never do, and then only the bullets remain - as a kind of headstone for unwritten thoughts. Still, they are better than nothing. reply zmgsabst 19 hours agorootparentprevI keep a daily journal, usually: - “I could have handled X better by doing Y.” - “Seeing A made me curious about B; maybe look into that.” - “I really tried at K, but oof didn’t work out; let’s try L tomorrow!” - “I did really good at P, Q, and R today — I’ll get a treat tomorrow and start on S.” Mostly just internal monologue kinds of things, but there’s three benefits I’ve noticed: - I don’t think about frustrations as much if I write them down. - I am better at self-compassion when I externalize the monologue. - I slowly adjust my monologue to reflect how I word it in writing, eg how I choose to frame things or what kinds of things I notice. reply insonable 12 hours agoparentprevI do something similar, but with photos. I have a 4k display on the wall with a rpi/python script that picks photos from today +/- 15 days for all years, then makes collages to display, 1 per minute. So the photos are from the same time of year, but for years past, and every day new photos cycle in and out. Another neat way to stir up memories of old, if you have a pile of photos around. reply nunez 10 hours agoparentprevSame. Journaling adds another dimension to my memories that makes them even richer and more enjoyable. It also prevents me from forgetting memories, which I'm very prone to doing! I started journaling back in 2012 (or 1999 depending on whether you count a Pokemon notebook that I barely wrote in!). I used to handwrite my journal entries. I refused to type them because they didn't feel personal enough. How foolish of me that was. I discovered Daylio while looking for a mood journal back in 2021. It's easily one of the best apps I've ever purchased. I've journaled daily since getting it, and it (with therapy) helped me understand and better control my introversion and mood swings. I eventually moved all of those entries over to Day One two months ago. Day One is even better. You can add recordings! From your Apple Watch! And everything syncs nicely via iCloud! No more talking into the ether! reply _thisdot 18 hours agoparentprevIt’s amazing how quick we forget things we thought at the moment were so important. Not in the same vein as journaling, but I’d been keeping a list of Notion entries on things I found important enough to keep notes on at work for the past 2-3 years. It’s different from my JIRA work log or Todoist list of completed tasks in that these are not everything I did, but just the important items. The things where I ran the risk of getting stuck Come appraisal process, I’ll have forgotten most things I worked on in the year. My imposter syndrome creeps in, but this Notion page keeps me sane! With this proof in hand, I’ve started journaling. I use the Apple Journal app. And it’s doing a good job of prompting me! reply stephen_g 18 hours agoparentprevI don’t have the motivation to journal, but I do get a fair bit of this kind of feeling scrolling back through my camera roll. I just take quick photos of all sorts of random stuff that happens or places I go, and it’s amazing the rush of memories that come back looking over them. reply RaoulP 14 hours agorootparentThis! For all my lack of journaling consistency, my habit of taking these kind of quick photos of anything noteworthy has given me lots of joy when looking back - although I do feel it can be slightly neurotic “in the moment”. reply chasd00 19 hours agoparentprevthat's really cool. I use to always have a small notebook with my at work to jot down notes and sketches. I had boxes and boxes of those notebooks saved over the years and would flip through old ones from time to time to see what i was up to back then. In a move I was very tired of carrying boxes so threw them all out instead of loading them up and transferring them to the next attic.. i really _really_ wish i hadn't. reply type0 5 hours agoparentprev> but for me the perception of the shortness of life is best fought by reminding yourself that it is not short Memento mori reply ozzydave 19 hours agoparentprevI journal ~daily since having kids. I feel the same way - it gives me peace knowing I can look back in time later and relive just a little what I was feeling today. reply paraschopra 19 hours agoparentprevIt's great to hear journaling helps you reflect on actual passed time. For me, I never get around to revisiting old entries regularly. How do you motivate yourself to do so? reply jvanderbot 19 hours agorootparentI just lower the barrier enough that it's trivial. I'm at my terminal all day, and one bash command spits out X years ago +/- 3 days. Right now, I'm really curious to see why I took a trip 10 years ago to my hometown - all I see in my journal is my packing list, so someday the journal entry for that trip will pop up. That helps too. reply zubairq 19 hours agoparentprevGreat idea. i should try journaling more to make life feel longerr and richer too. Thanks reply jzm2k 18 hours agorootparentI'd like to recommend giving Daylio [1] a try if you want to start journaling. Someone on HN recommended this two years ago and I decided to try it because all past attempts at journaling had failed miserably after few weeks. I'm now on a 700+ day streak and I'm really happy that I started doing this 2 years ago. So much has happened and it's all documented. It takes so little effort to add an entry for the day and reading past entries is fun because what actually happened past year is not just a blur but a detailed record of activities, words and photos. [1] https://daylio.net/ reply WarOnPrivacy 17 hours agoparentprev> reviewing old entries provides a feeling of history that makes life feel soooo long and so rich. I don't disagree. But I think the flavor of the richness depends on the quality of the days. It is my experience that decades can also be built from days that ought not be preserved. Or at least not without strong curation and editorial treatments. reply TeMPOraL 16 hours agorootparentI have semi-regular journal notes going back over a decade, and my experience was opposite to GP - instead of discovering how many things happened in that time, I discovered my mind has been spinning in circles, trying to find solutions to the same problems, and despite feeling otherwise day-to-day, no actual progress has been made. It was an important discovery for me, though not much came of it anyway. reply WarOnPrivacy 3 hours agorootparentUgh. I hadn't considered that. I had kids, a biz and a disabled wife. I had to achieve. Even then, some days I wasn't much capable. Other days I forced out results but at a high cost. reply overtomanu 14 hours agoparentprevsimilar to google photos memories notifications. reply 1vuio0pswjnm7 7 hours agoparentprev\"# get years and day range from args\" What are example initial values of $days and $years in \"args\". reply barbs 12 hours agoparentprevJust wanted to post a quick comment - I really appreciate your simple and elegant journalling solution. I think I want to implement something similar. Thanks! reply 6B 12 hours agoparentprevThank you for the inspiration. I'll start journaling again. And I miss it too. reply larve 14 hours agoprevOne thing I love about the speedup of time is that picking a compounding habit (say, doing something for 10 minutes each day) feels like having an almost instant pay-off. \"Oh wow 3 years already passed\" -> \"Oh wow I got pretty good at this thing I picked up just yesterday\" I picked up biking during the pandemic, and 3 years later I have legs of steel, 10k miles under my belt, and people know me as \"the bike guy\", when I think of myself as \"ok this biking thing is kind of fun\". reply skeeter2020 8 hours agoparenthow old are you know? I've continued to pursue biking quite aggressively and now at 50 find the speed of progression and the ability to recover much slower. Right when I have more time and money than ever before :( reply Madmallard 12 hours agoparentprevIt kinda sucks that you learn much slower when you’re older though. I’ve been practicing piano an hour or two a day for 7 months and I don’t really feel like I’ve improved at all. I was intermediate when I started and I am taking professional lessons. Mid 30s here. reply yoyohello13 9 hours agorootparentI don't know, I think standards are just higher as an adult. When I was a teenager, I thought I learned things quickly, but in reality I was still a novice. Now that I'm older I don't feel like I pick things up more slowly, but I definitely am more aware of how much work it takes to be good at pretty much anything. reply hosh 11 hours agorootparentprevI don't pick things up nearly as fast now (early 40s) as I was when I was younger (pre-tten, teen, 20s, and 30s). However, I also pick things up in a very different way that in some ways, are more effective than when I was young. For example, it takes me longer to gain the intuition of something, but on the other hand, when I do, it plugs into a vaster web of knowledge. I am certainly more disciplined in both mind and body compared to when I was younger. I'm capable of clearer visualization and simulations now than before. I've got a lot more math under my belt. I learned piano as a kid, picked it up pretty fast, and forgot a lot of it. I am not practiced in sight reading any more. On the other hand, when I poked around learning again, it's tapping much deeper into music theory, composition. For example, I learned Petzold's Minute in G Major (formerly attributed to Bach) as a kid and as an adult. I still can't quite get both hands working together as an adult ... but I was cracking up as I kept seeing how beautiful the chords are composed together in a way I never noticed as a kid. reply codethief 10 hours agorootparentprevThe other day, I heard about this lady that started playing the piano in her 60s when we she retired. Fast forward to 20(?) years later and she's giving professional concerts and everyone just assumes she's been playing the piano all her life. In other words: Keep it up, you'll the reap the fruit of your labor eventually! reply khazhoux 9 hours agorootparent> In other words: Keep it up, you'll the reap the fruit of your labor eventually! No, you won't necessarily reap the fruit of your labor. You will certainly improve, but most of us will face a hard upper limit with diminishing returns as an adult. I've played trumpet and guitar since age 13. I started learning piano ~10 years ago, age 40. But even after a decade with thousands of hours of practice, I still can't \"natively\" read bass clef. I still mis-read G as E, e.g., if I'm not actively paying close attention. Where I could sight-read treble clef basically perfectly since I was a kid, I'm still clumsy on bass clef after 10 years of learning as an adult. Just like learning a new language. reply whelp_24 8 hours agorootparentDefeat yourself and you won't need time to do it for you. Maybe there is a hard limit, maybe you've hit a false peak, a local maxima. If you've hit a plateau, try something else, you probably only hit the limit of your current methods. reply larve 11 hours agorootparentprevI'm not sure how it applies to learning, but for any activity based on consistency and quantity, I find it wild how quickly time seems to shrink and \"writing 500 words a day\" seems to overnight turn into \"I wrote 100k words in the last 3 years\". My goal at this point in life (42) is not really to get better at stuff, but just focus on doing what I like and want to be doing, while leading a stable life. reply Madmallard 9 hours agorootparentThe interesting thing with that is the only way people really master things is when they just like what they're doing enough to put up with the difficulty of getting to that level. reply treflop 9 hours agorootparentprevMaybe you just plateaued? I’ve noticed practicing something over and over does not make you better. It just makes you faster at doing something you already know how to do. Trying a new approach when you practice is what I find actually makes you better. reply skeeter2020 8 hours agorootparentI typically promote the little book of talent in this scenario. Sure, it's all common sense, but distilled and focused on this specific scenario. https://www.amazon.com/Little-Book-Talent-Improving-Skills/d... reply quickthrower2 11 hours agorootparentprevYou probably improved alot. Is there an objective test. If that test can be rescaled by a function to linear based on average person’s time even better. reply deminature 10 hours agorootparentprevPiano requires adaptation in the corpus callosum of your brain to coordinate two-handed playing - it takes time to develop. Competent players have usually been playing for years to a decade before they're at a level of public performance. reply jasonfarnon 9 hours agorootparentMy anecdotal experience is that someone who starts at 25 and plays until 35 will be a shadow of a 15yo who started at 5. Are there concert pianists who started late, say post-puberty? I think maybe jazz, but the standards are pretty different. reply spurgu 9 hours agorootparentOne aspect of it is that the 5-15 kid has a ton more spare time. And when practicing is able to be more immersed, not bugged down by real life chores and problems like the 25-35. Personal history: I started playing guitar around 18 and at ~25 I was way ahead most of my 18-20 year old peers who had started way younger. And I was a jazz snob since like 20. I did learn the basics of piano and reading music when I was around 7 but never played actively, but it might've helped that I didn't start from scratch at 18. But I was immersed once I started - music was literally all I did in my spare time aside from doing drugs. :D I'm now in my 40s and have been learning piano for the past 2 or so years. I think I've been progressing quite fast, but it's easy since I already know what to do, it's just another instrument (the challenge is mainly the hand coordination). reply Barrin92 9 hours agorootparentprevMost children who start to learn instruments at some point just stop doing it. Kids who actually turn into concert pianists undergo rigorous training that is effectively a full time job. How many adults at age 25 have even attempted that? Just in financial terms, how many adults have spent the resources on themselves that the parents of highly competitive kids do? Most adults who pick up skills just don't do it in a deliberate way. When I moved to Japan for work I thought as an adult it'd take me years to acquire a new language. But the company I worked for got me professional training and I hunkered down about 2 hours per day and in ~14 months I did much better than I thought was possible. reply boredemployee 12 hours agorootparentprevlearning curve of the piano is crazy. and if you stop playing you go back to zero really really fast reply QuercusMax 11 hours agorootparentThat's very much not been my experience. I learned to play when I was in grade school, took most of a decade off during college and early 20s, then picked it back up. I also had an enforced multi-year hiatus when I broke my arm at age 35. I might need to do some extra drills and practice to get back to where I had been, but the fundamentals never left. Like riding a bike - might be out of shape, but I still know how everything works. reply hosh 11 hours agorootparentThat's not been my experience with the piano. I definitely forgot a lot. Maybe I never got the fundamentals set enough. It wasn't my lifelong passion either. You don't forget how to ride a bike because the bike is doing most of the work. Because of physics, a bike stays better balanced when it is moving. Compare that to say, pro racers, mountain bikers, trick riders, etc. there are significantly more skill involved in those than casually riding around. reply julienmarie 10 hours agorootparentprevI quite disagree. Started to learn extremely young (3 years old) and I guess my relationship with the instrument became second nature. I feel there is a kind of threshold that you cross at some point and then, the skill becomes part of you, forever engraved. You know you're there when you can play the piano without a piano, just in your head and in the tingle of your muscles. When you do not need a rational stage like a score or even a piece to play. You just play what you feel. I don't play that often now, maybe 30 mins to an hour once every two or three days. My technique is not as good as it used to be. But my understanding of music, harmony and emotion is deeper. My music is better now than when I was at my peak as a technician, because as a human being, I matured. reply khazhoux 9 hours agorootparentSimilar with me and trumpet. I started in 6th grade and was very serious about it through high school. Put the trumpet down for probably 25 years. Then I got the bug in me again and started practicing and getting my chops back. In almost no time, I was once again an \"advanced trumpet player\" -- solid tone, good range, etc. My fingers are a bit less nimble and out of shape, but the core tone is there. That instrument is --as you say-- part of me, forever engraved. reply crossroadsguy 12 hours agorootparentprevWhat instruments are relatively easier to play? reply marktucker 11 hours agorootparentI could recommend taiko (Japanese) drums as an adult hobby. You very quickly get off the ground in terms of making wonderful music together with a group. reply AlecSchueler 10 hours agorootparentprevTin whistle could be worth looking at. You'll still need a good ear and a lot of practice for your intonation though. reply boredemployee 11 hours agorootparentprevsorry, in fact i think its hard to play any instrument, but my experience is with piano only. i studied hard for 18 months in my mid 30s and could play many pieces of Erik Satie and some other musicians. reply Der_Einzige 9 hours agorootparentprevPeople who are saying \"Guitar\" or \"Piano\" don't play insturments. The cello: 1. You're literally sitting when you play, whereas many violinists, violists, and bass players have to stand. 2. Big enough strings to not cause a player to develop callouses, no pain/bleeding. 3. Almost always only play one string at a time - no knowledge needed of chords. 4. Until you get ultra good, you will only need to learn 1 clef, and only a handful of key signatures I think guitar and piano are among the harder of instruments to learn. Bowed string instruments are among the easiest. reply dheera 10 hours agorootparentprevPiano or guitar are probably the best instruments for fastest path to gratification i.e. you can play something vaguely nice sounding pretty quickly, on the other of a couple months. With string instruments you sound like a crying baboon for 2 years, and with brass instruments you sound like an underwater crow for 2 years. reply skeeter2020 8 hours agorootparentprevnot back to zero, but IME back to some previous, steady state. reply navane 12 hours agorootparentprevYou might need a teacher. Biking is all endurance, piano involves a bit more. reply skeeter2020 8 hours agorootparent>> Biking is all endurance If you're riding a Peloton I guess, but not a real bike in any of the many disciplines. reply Madmallard 9 hours agorootparentprevI do have a professional teacher, if that was not clear. reply Solvency 11 hours agorootparentprevCycling, maybe. Mountain biking anything of merit takes extreme skill. reply risenshinetech 12 hours agorootparentprevWeird that with no other information you just immediately attribute this to your (not-very-old) age reply jimbob45 11 hours agorootparentprevhttps://www.youtube.com/watch?v=XC-8P-sapHw This guy has a lot of really great videos on how to practice smarter and has a lot of answers to dumb questions that you don't really wanna ask. I hope it helps. reply quickthrower2 11 hours agoparentprevReading this after a workout! Agree. Seems like yesterday I started going. reply stared 20 hours agoprevThere is already a body of research on the perception of time as a function of age, see https://en.wikipedia.org/wiki/Time_perception#Changes_with_a.... It stems from a few things, and novelty is only one factor. (Also, it is not only that the world begins (to us) as full of novelty, but also most people gradually transition from exploration to exploitation.) In addition to remembering previous events, there is also how fast we process information (e.g. reaction times). It seems that as we are getting longer, we get fewer clock ticks per second. (On an interesting take on that, read a short story \"Exhalation\" by Ted Chiang.) reply MyFirstSass 12 hours agoparentThe ticks per second thing is very interesting because of a something weird i encountered the other day - i suddenly realised seconds are WAY faster than they used to be. I play music so have a pretty good feel for rhythm and i distinctly remember the clock in a family members house ticking each second being way, way slower as a kid. Slept there the other day and it was fast as hell. So incredibly weird. I'm sure my memory of the BPM is much slower than the feeling from today. Sitting looking at the digital clock right now two seconds seem close to one as a kid. reply makz 4 hours agorootparentInteresting just made a quick test and I'm off by around 30%, seconds seem to be faster by that amount. reply red369 11 hours agorootparentprevNow that you mention it, I think have noticed this too, but perhaps not to quite the same extent. Sort of joking, but sort of not, they seem to go pretty slowly while doing an exercise like the plank reply andai 12 hours agorootparentprevI had the same realization a few years ago and it horrified me. Is it gonna keep getting faster? reply MyFirstSass 12 hours agorootparentExtrapolating from my own case time seems to have doubled in speed from 5 to in my 30's, if that doubles when im 70, then when im 100 it's 8 times as fast, wow. I wonder what that would mean for life extension, imagine this exponential - then you'll get very little effect from living past 200 years: https://imgur.com/crLQUy6 Pretty interesting thought experiment. reply dakial1 14 hours agoparentprevYes, and one thing you can do is doing something/everything different everyday, but the downside of this is that you'll get fatigue out of keeping your brain on alert all the time. I observed this with people traveling, I used to call travel cognitive impairment, as usually functional human beings (like my close relatives) suddenly get very lost and helpless during travel (specially at airports). I then realized that this was because this was a unusual experience for them (once every year) and this would overload them with things out of their routing (even if they traveled before). That didnt happen to me (yet) because I was traveling a lot for work, so this was a routine for my brain. reply ehnto 9 hours agorootparentI am travelling right now, freeform exploration of another country is full of novelty. It feels like I have been here for a month but it has only been two weeks. The downside is I am exhausted. I also couldn't imagine doing any of my work while travelling even if I had a computer with me. There is downtime enough to do some, but I don't think I'd have the capacity to engage with it. I think advanced abstract thinking relies on a bit of cognitive room being created by routine. Perhaps that is at the consequence of the routine moments disappearing into a void of compressed time. reply cruano 19 hours agoparentprevMy anecdata is that my late-twenties felt way slower than my early-twenties, mostly because I switched from a 9-5 office job to a remote job that allowed me to slow travel. I spent a month in Rome and I remember most days and definitely remember all weekends, but I would have to really dig deep for a memory from 2019. reply dougmwne 19 hours agoprevI’ve learned that the passage of time is extremely relative. My college years were extremely full of new experiences and they feel like ages. Once I started working, my life was very rote and consisted mainly of driving from home to work and back again. I worked a lot of hours and vacations and weekend trips were infrequent. Time flew by. Then I ditched settled life and started traveling year round with a couple of bases i spend more time in between traveling. I’ve learned that the change in environment keeps putting the mind back into a more neuroplastic state where we are more open to the experiences around us, can change our habits more easily and just generally turn off autopilot for awhile. I’ve been doing this for about 9 years. It’s been like a century. I feel like a very different person then when I started. I have some friends who still live in the same city at the same job that I left originally and it absolutely blows my mind that they stood still while it feels like I went to Mars and back. reply bongodongobob 19 hours agoparentYeah I can't believe more people don't just travel for a decade. reply dougmwne 18 hours agorootparentCertainly many people on this website could if it were their priority. Some money is required, but not very much. I’m sure I make less money than many here because I take jobs that prioritize remote work and flexibility. So what’s really the blocker for many is a choice of priorities. I won’t have children. I don’t have a strong need to play homemaker or gardener. My lifestyle is pretty similar to a lot of retirees who have second homes and travel between them. I talk to quite a few in one of my home bases and we have a lot of the same travel plans as well as it’s common for them to try to spend a month or two a year traveling to new places. reply globular-toast 13 hours agorootparentDefinitely. My brother works in a trade, works for a year or two then quits and travels for 6+ months at a time. He also has very few possessions and no liabilities or commitments. I prefer a slightly different balance with a few more possessions but still travel for about a month a year. Like you say, it's all about priorities. We all work way longer/harder than we need to for basic sustenance. reply dingnuts 16 hours agorootparentprevworking and travelling on occasion -- \"on an average net salary\" implies not actually quitting your job -- is not what the GP described. The GP described quitting their job and going traveling for an entire decade, which is an incredible luxury over an enormous timespan that only the luckiest will ever be able to enjoy. The fact that the GP then chooses to treat this gift as though it makes him better than his colleagues who had to stay and work for that decade is.. frankly just gross. \"They stood still\" no bud, they had a life experience that 99% of the world population has no choice but to experience. Maybe instead of being pretentious about your experiences, try gratefulness? I say this as a \"privileged\" tech worker, with \"only\" a six figure salary. I could quit my job and go traveling, maybe for a year, and then be broke and set far back on my retirement goals, and my hopes of ever retiring. And I could only do that if I was tremendously selfish, like you: choosing to have no kids, choosing to allow the elders in my family to face poverty instead of proper end of life care, etc. If you have the ability to not work and travel for a DECADE of your life, I suggest you have an immense gratitude towards everyone else keeping society running while you luxuriate, instead of pretending as though the fact that you've had this opportunity somehow makes you superior to those who had to work reply dougmwne 15 hours agorootparentI am he as you are he as you are me and we are all together;) I did make a choice, and it didn’t involve all that much luck beyond what everyone here has, a lucky break in a good career and a high income birth country. Actually there was bad luck, my partner and I were laid off at the same time. Sometimes the good comes from the bad. I don’t think I am better or worse, but I do push myself always to experience new things. It’s hard to imagine my life any other way, but then lots of people are deeply passionate about things that I’m not going to understand and vice versa. I think it’s interesting that you call not having children a selfish act. Having biological children always struck me as very egocentric. For me I have no choice. I am gay and our families live in places where one day in the not too distant future LGBTQ couples could have their children taken away. Maybe that would have been a good road to walk down, but it was not my road to take. It’s also interesting what you project onto me around elder care. What I see is that most people I know live far from their parents and families. They spend their whole professional lives in major cities and visit home maybe 2 weeks a year. That pattern of life doesn’t make sense to me. I love my family and want the flexibility to see them often. If they needed money or needed care, I would give it to them, but they have no need. Besides spending some of the year near them, I know that I inspired them to travel more and take bigger risks in their retirement. I know I have helped enrich their lives. We will go on a few trips together this year and I never have to decline an invite because of not enough PTO. If there’s something about your life you feel trapped in and unhappy with, try to change it! reply bscphil 15 hours agorootparentprev> The GP described quitting their job and going traveling for an entire decade You replied to the person who wrote the GP. I don't see anything in their post that confirms not working - they just work remotely, as the post you are replying to confirms. > And I could only do that if I was tremendously selfish, like you: choosing to have no kids, choosing to allow the elders in my family to face poverty instead of proper end of life care, etc. This is deeply unfair. Choosing not to have kids is not selfish at all. By some metrics it's even laudable, but you don't have to go that far to simply not condemn people who make that choice. And you have no idea how much they make or whether their parents are \"facing poverty\". Perhaps their parents died younger. Perhaps they have excellent retirement savings. Perhaps OP is one of seven children who contribute equally to their parents' care. You don't know. I'm in full agreement with you that traveling like this is a privilege of the wealthy. But I think the way you condemn it falls pretty flat. reply rcbdev 18 hours agorootparentprevIt's not as unreasonable as you think - even in lower income / high tax burden countries like Austria an avg. net salary is enough to keep on travelling to all kinds of places. I know people who work for the state government who keep appearing in India, Thailand, Brazil etc. when we're in meetings - usually they're billed as external consultants to avoid tax liability issues. The true crux is that most people don't actually want the digital nomad lifestyle, humans naturally seek out some form of stability. reply dougmwne 18 hours agorootparentExactly this. But I disagree that settled is natural. Humans evolved in nomadic tribes that followed the herds. Stability is a social technology that was developed alongside agriculture. Stability feels unnatural to me and I get the itch after too many months in one place. My two bases are near family and I have developed friendships with other traveling people. I’ll meet up this weekend in Miami with a Swede that I met in Portugal and last saw in New York. reply smokel 15 hours agorootparentI think this argument is a bit of a stretch. Nomadic tribes did not travel by plane, and they certainly did not have friends in strange places. reply dougmwne 14 hours agorootparentFair enough! The tribe has changed for sure and so have the antelope. reply wing-_-nuts 13 hours agorootparentprevI had a whole rant queued up until I realized you were being sarcastic. /me with my 15 days of vacation a year reply tetha 13 hours agoparentprevFor me, it's been throwing myself into a complex hobby - music. like, as much as I like where I work, and as much as work throws new and weird challenges at me, but .. it's just computer maintenance. Entire years are kinda the same rote of work-shopping-sleep-work. I don't even have many memories of these years, honestly. Now that I've left my comfort zone with my instruments, do stuff with the instruments, go to a lot more concerts... life is kinda revolving around concerts and every day has some thing to approach with the instruments I'm not happy with. Suddenly that week is when I picked up TES BOS to make the bass sound better, that week was with a few friends, that week was a frozen crown concert, that week was when I got a really cool intro in a riff challenge, that week my teeth confused the fuck out of my dentist and their tool tray ended up as a diorama of a medieval battlefield, ... reply 1234letshaveatw 17 hours agoparentprevI'm sure from their perspective you are the one that stood still lol reply dougmwne 16 hours agorootparentThey are probably thinking that life starts to pass by fast and wondering where the last 10 years went. I had some friends living interesting lives when I was settled. Sailing the globe, doing seasonal work in the arctic and backcountry skiing mountains with no name. Doing field work in the African bush. I kept thinking about them and wondering how I could be them, like the little scratch on the roof of your mouth that would heal if only you could stop tonguing it. reply librish 11 hours agorootparentI think the intellectually honest counterpoint is more about relationships. As someone who has been a digital nomad, it's hard to form deeper relationships when people are always leaving. It's also hard to have hobbies that rely on the same group of people meeting in person over a long period of time. reply dougmwne 11 hours agorootparentI don’t think there’s any one size fits all way to digital nomad. I go back to the same places year after year. My friends and family are in those places. They are not in New York and San Francisco, I have no family there. My partner and I enjoy our hobbies with groups of people when we are there. It’s not that different than being a snowbird. The main difference is that in addition to home base time, we also spend 4 months a year traveling, sometimes on our own, sometimes with our people. reply dartos 20 hours agoprevI think mediation and gratefulness is a good way around this too. If your take explicit time to recognize and examine the world around you, even in your backyard, time seems to stretch and you notice and retain more. I’m lucky enough to have lots of different colored birds show up in my backyard, so sometimes I sit out there and wait for them. It’s not exciting, but every time I see one it’s a new memory and those new memories make time feel more. reply AltruisticGapHN 18 hours agoparentCompletely non scientific theory, although inspired by McGilchrist's \"The Divided Brain\" I'd wager that as we age the left hemisphere takes more and more of our awareness as we map the world internally and we tend to live more and more from \"what is already known\" as opposed to present experience. I too have hundreds of hours of meditation and I remember the feeling of time was very much affected. One night I remember out of sheer stubborness I sat for 5+ hours and I always remember the next week felt like it was a month. It doesn't have to do with having \"new\" experiences, or new memories, or doing anything \"interesting\". It has to do with how we attend to the world. And as Gilchrist pointed out this is being worsened as the devices we use day to day like smartphones, which aren't inherently bad, tend to stimulate mostly the left hemisphere unless you just listen to music. All the time you're going after buttons, notifications, looking at the icons, you're just continually sucked back into the world of the left hemisphere : icons, words, symbols, \"things\" to do or that could be done, things that could happen, emails, posts, likes, whatnot. Actually I think it was already shown through EEGs that long time meditators, buddhist monks, had some areas of the brain more developed.. which would seem to support my theory likely those areas are related to the right hemisphere (and hence the right hemisphere's qualities such as ability for compasssion, seeing the whole, seeing things in context, ... and therefore seeing one's life in context as well instead of an old tape repeating in your mind everyday). edit: also if you think logically, then it makes sense that the common intuition that having new experiences, or adding more variety in your life would make time feel like it goes by slower, but it is not because of \"new\" experiences, but as in my theory above, because those new experiences stimulate the right hemisphere, as you become more focused and attentive to what is happening NOW. In fact by definition any new experience will stimulate the right hemisphere. So if you dont have the $$$ to go out and enjoy the world, or take a vacation the good news is you'll probably enjoy the benefits of right hemisphere activation by doing... NOTHING! (ie. meditation, focused attention on the breath or any one of many techniques all revolving around developing concentration and attention) :) reply alsetmusic 20 hours agoparentprevI heard someone on a podcast talk about the compression of new experiences during the pan / lockdown as a reason why time became meaningless. That seemed right, to me. I can hardly believe that it's been almost four years since that started. > If you have a stable job, you can pretty much mentally time travel a full year and find your days to be similar. > But if I ask you to imagine doing a PhD in Sanskrit at a foreign university, you would have no idea what your days are going to look like. This also feels right, to me. But also, I spent nine months learning new languages to try to build a service to launch with a friend and that didn't turn into a long memory of effort. In fact, I recall it as sandwiched. It was a blip. I think the real key is new experiences, not the aspect of study. Maybe that's the foreign university aspect: what happens when you aren't at study. The people you meet, the places you go, etc. reply smokel 14 hours agoparentprevI've meditated quite a lot, and I am now often able to \"live in the moment\" so much so, that I only experience the most recent bite that I'm taking out of a Snickers bar. It gives me the strange feeling that I might as well not have eaten the entire bar, just the last bit. reply bwestergard 20 hours agoparentprevIf you're not already aware, Cornell offers a bunch if resources to enhance your birding experience. https://www.allaboutbirds.org/ reply johnmaguire 19 hours agorootparentI love Cornell's Merlin app for sound-based identification of birds. reply dartos 17 hours agorootparentprevI know literally nothing about birds lol. There are just some pretty ones around me. reply avgcorrection 19 hours agoparentprevAround this? Assuming that it’s something that needs to be gotten around. reply locallost 13 hours agoprevI always thought of it as each unit of time being relatively shorter in relation to your life on earth. A year is 20% of the time a 5-year old is aware of, but only 2% of a 50-year olds life. But the boredom argument is pretty strong. I remember vividly the time when I moved to another country and those first three months still feel like they lasted longer than the last three years. reply nerder92 12 hours agoprevOne very simple explanation I’ve read is that time perception (as time itself) is relative. Time goes slower when you are a child because your perception of time is relative to the totality of time you’ve experienced. So for instance, when you go from 1 to 2yrs old, it’s double the amount of your entire life, but from 80 to 81 it’s just a small fraction. Not sure if this has been proven or is even possible to prove. reply bibliotekka 11 hours agoparentI thought I watched a Vsauce video that debunked this idea. Instead they suggested it was the fact that adults have fewer novel experiences than children. In other words, have lots of new experiences and time seems to extend. Something about the brain storing \"same\" in some kind of compressed time memory slot. Oh yeah, found it https://www.youtube.com/watch?v=zHL9GP_B30E reply 3abiton 7 hours agorootparentIs the brain applying LoRa on our memory model? reply awb 11 hours agoparentprevThat makes sense to me. Also, if you think about memory recall, it takes a second to recall a memory. So you have the ability to traverse time at a rate of (Your Current Age - Age of Your Earliest Memory) / 1 second So maybe it’s also the feeling that looking back in time feels faster (more time has elapsed relative to the speed of memory recall) as you get older. reply eep_social 11 hours agoparentprevOn top of this, the totality of your experience also grows with time. To a four year old, many day-to-day experiences are fresh and new. By the time they’re thirty, there are far fewer such events on any given day. reply themagician 11 hours agoparentprev“Life is short and life is long, but not in that order.” https://youtu.be/SNgyEmYyQF4 reply LorenDB 11 hours agoparentprevI also tend to view it this way. reply osmsucks 11 hours agoparentprevCame here to write the same thing :) reply raspyberr 20 hours agoprevI've always rationalised it as: When you're one years old, 1 year is your whole life. When you're 100 years old, 1 year is 1/100th of your life. reply alberth 20 hours agoparentThis plus … Time as you perceive it, is related to new memories you make. When you’re young, everything is a new experience which in turn becomes a new memory. When your 100, to use your example, you’ve done everything there is to do. So no new memories & days blur together. reply rrgok 20 hours agoparentprevSo, if I suddenly have amnesia and don't remember the past 99 years, will my time slow down? It is just a thought experiment... reply ji_zai 19 hours agorootparentIf you don't remember the past, slow down relative to what? reply rrgok 15 hours agorootparentThat's exactly my question: is memory or timespan that regulate the speed of time-passing? Another thought experiment: suppose reincarnation exists and, as soon as I'm born, I remember my past lives, would time go faster or slower? I don't expect an answer, they are just thoughts that I have... reply planb 20 hours agoparentprevThat's the explanation I came up with for myself, too. As humans, we rate most things not in absolute but in relative terms to what we are used to (see studies about happiness or how rich people don't realise how wealthy they are when they don't leave their bubble). Why should we perceive time differently than in comparison to our timescale? reply mistermann 19 hours agorootparentIt even distorts logical processing, things like what is true and what is possible are also according to what (is known to the individual observer, or the culture they're embedded in) currently exists. reply avgcorrection 19 hours agoparentprevThat the mind compresses oft-repeated experiences makes more sense than this math-as-psychology nonsense. Notice how when you have to wait for an hour, you’re bored, time seems to pass slowly, yet for those last ten minutes time passes more quickly because there’s only 1/6 hours le— yeah exactly, no, that doesn’t happen. The whole hour passes slowly because that whole fraction theory is bunk. reply holoduke 19 hours agoparentprevThe older you get the less you learn and the less new things you learn. Days are becoming repetitive. Looking back at last year contains the same information as 1 week when you were young. reply standardUser 16 hours agoprevI try to balance my life between new and exciting experiences and more routine and mundane experiences. The routine and mundane are important. They are how I maintain my important relationships and pay the bills. But when it all becomes routine, time will fly by regardless of age (at least for adults). But my sense of time reliably slows to a crawl if I have enough new stimulus. And the older I have gotten (40's currently) the more I have gone out of my way to purposefully generate experiences that slows things down. I lived abroad for 2 months a few years back and it felt like 6 months. I moved states not long after and once again, massive slowdown. That first year in a new city felt like three. New relationships can do the same thing. As can new jobs or, even more so, a career change. And let's not forget drugs. But those are all things a person can completely avoid if they don't make a conscious effort not to. My default for many years was to sit snuggly at a boring job, travel only intermittently and otherwise immerse myself in repetitive media. I refer to those as the lost years (mid-to-late 20's). reply jerrygoyal 51 minutes agoprevDopamine also plays a role in the perception of time. Basically, high dopamine gives more processing power it means you get higher frame rates so time feels slower. similarly, low dopamine leads to time flying quickly. Moreover, the speed at which we blink eyes also affects the perception of time. (Learned this in one huberman podcast) reply rstuart4133 12 hours agoprevI have a simpler theory. The apparent speed of the passage of time is inversely proportion the number of memories being accumulated. I don't remember what it was like to be a toddler. All I can tell you is \"they are sponges\" is a common description. It blows me away they can learn how to recognise faces, walk, speak a language in the space of a few years. As a kid I recall getting bored very easily. I needed a constant stream of stimulation to feed my brain. As a young adult I recall a friend asking me to look up a telephone book to find the a persons address. I got back to the car and told them the address. \"Oh\", they said \"I must have the spelling wrong, try ...\". No problem, I remembered every name and address on the page I've just seen. But as I grew older, remembering stuff came less easily. Now at over 60, if I put in a situation where I'm forced to remember a while pile of new stuff I feel distinctly uncomfortable, whereas before I was better at it than most. And during all that time, the passage of time has sped up. Ergo, my theory is I gauge the amount of time that has passed between events X and Y by the number of memories accumulated in the period. reply Qem 8 hours agoparent> I have a simpler theory. The apparent speed of the passage of time is inversely proportion the number of memories being accumulated. I had this same realization. In other words, our internal clock is not like a mechanical, or a quartz watch, with seconds flowing at a constant rate. It's more like a hourglass or a clepsydra, but instead of sand/water, the flow is of bits of information from the world into the brain. As in a hourglass, near the end the flow is weaker (learning is much slower as an adult than as a child), and the same amount of physical time corresponds to much less sand (subjective time). reply Shawnecy 19 hours agoprevThe Dictionary of Obscure Sorrows calls it 'Zenosyne' [0], or the sense that time keeps going faster. I quite like it and have found myself coming back to rewatch it every couple years. [0] = https://www.youtube.com/watch?v=SNgyEmYyQF4 reply mikedelfino 20 hours agoprevNice hypothesis. I've always thought that it had to do with the percentage of life already spent. When you're a teen, an afternoon counts as 0,004% of your whole life thus far. In your mid 30's, it gets down to 0,001%. So to me it's only fair that it feels to pass four times faster now. But this is just a random thought. reply zoky 19 hours agoparent100% this. The older you get, the shorter a minute or an hour seems to be. When I was 12, an hour was an interminably long amount of time to spend in a classroom. Now that I’m 42, it’s barely long enough to take a decent nap. Life is cruel that way. Can hardly wait for how quickly it passes when I’m in my 70s or 80s… reply 4RealFreedom 20 hours agoparentprevThis is what I've always thought - time is relative to how long you've lived. reply airocker 12 hours agoprevAccording to this book: https://valsec.barnesandnoble.com/w/slow-down-time-the-power... , it basically happens because the number of snapshots you encode per second goes down. Snapshots are visual cues that we encode. The best example is that if we are watching a fan start, after a certain speed, we cannot tell how many wings are there on the fan. We are not snapshotting fast enough. Younger people can probably tell the number of wings on a faster fan :). Various things slow down this snapshotting in our brain, and the best antidote is to get in the zone and do things with immense attention. reply WuxiFingerHold 5 hours agoprevThis touches the personal topic of life choices and I find many posts here inspiring. I'm striving for not causing harm to others, avoiding things that lead to ill mental states like compulsion or anger, seeking things that lead to healthy mental states like calmness and focus. This seems to be a boring life from the outside, but doesn't feel like that to me. Maybe because I've got enough challenges. Time perception is not important to me. reply debo_ 13 hours agoprevI had some very long periods of intense suffering over the last decade. After... a lot, I'm in a much better place now. I made some minor lifestyle changes to make things a bit easier on myself, but nothing earth-shattering. Most of my days are largely the same. However, life moves much more slowly now. When I get to the end of a week, Monday seems quite a long time ago. I'm not sure about the predictability thesis. The way I think about it is that I have no expectations from life anymore; I take what I can get, give what I can, and focus on one day at a time. I think this more than anything has contributed to a feeling of my life slowing way down. reply rjh29 20 hours agoprevI'm also obsessed with this and have mostly countered it so far by moving house every few years, living and studying in several countries and trying new things. The negative being that I don't have any stability. reply plmpsu 20 hours agoparentTo each his own. I've been enjoying getting familiar with the sun's location and cyclic changes of nature as the seasons and years pass where I live. reply rjh29 5 hours agorootparentYou can do that for a year or two, then move on to somewhere else. reply al_borland 20 hours agoparentprevI did this for quite a while. I am able to tell roughly when something happened based on where I was living at the time. I’ve moved 26 times and finally got sick of it. While I’m not sure how I’ll tell time now, I’ll figure something out. A lot of people use their kids for this. “Bobby was in 2nd grade, must have been 2014.” reply ourmandave 19 hours agoparentprevHow do you deal with no stability? Do you have any sort of home base you can always go back to? reply rjh29 5 hours agorootparentAt the moment I got a visa that allows me to stay for 15 months, which provides a good deal of stability. I think a few years is probably the sweet spot before moving on. reply urda 15 hours agorootparentprevYou learn to live with the instability. You come to terms with how short and limited life and life's experiences can be. It can be a lonely life, but it by far can be the most rewarding. I look back from having diverged from a world where I never escaped my home-town gravity well and I'm glad I took the leap. It made me a deeper, richer, and more interesting individual. reply anonzzzies 19 hours agoprevI have been able to avoid this by just immediately switching to something else when I feel things are getting too comfy. Doing things that are not comfortable seem to stretch time for me. It works so well that for me (at 50) time is moving incredibly slowly and I like it that way. reply paraschopra 19 hours agoparentI also do the same. Spent a bunch of time scaling a B2B company, and now I'm doing a consumer app intentionally for an intentionally different challenge. reply naasking 19 hours agoprevThe explanation is probably simple in the end: children are mentally more present and mindful, and thus bored, and as adults we become increasingly distracted by higher order thoughts and projections and plans so we're considerably less mindful of the present. reply lumb63 15 hours agoprevYesterday I watched a video that described a two-dimensional grid where the x and y axes were “skill” and “challenge” respectively. A range surrounding y=x was the flow state. Below it was boredom (skills exceed demands) and above it was anxiety (demands exceed skills). Flow arises when our skills align to what we must do; not something easy, not something hard. The presenter also noted that amount of time in flow correlated with life satisfaction, and that it’s also when people do their best work, and time moves the fastest. That’s the sweet spot to be. Where life is challenging, so you aren’t bored, but not so challenging to where you are overwhelmed. It seems the author urges people to flip from the boredom side of the flow state to the anxiety side because both of those are where time feels like an eternity (which anyone who has been in either of those states can attest to). I think a better idea is to question if what the author is proposing, trying to make time feel slower, is a good idea. Personally, I think the exact opposite is the case; all the best moments I’ve had are ones that went by “too quick”, and we can’t have our cake and eat it too. Time going by slowly is likely a canary in the coal mine for something being wrong. reply jenoer 13 hours agoprevI think that the older you get, the less new milestones/events you have (that impress you and remember in detail). This results in having less moments to refer to when looking back in time, (skipping uneventful timespans). This makes things seem closer to the current time than they really are as everything in between is empty noise. reply Ekaros 14 hours agoprevI feel that as children your experience is lot more variable... Every year of school or even university is slightly different, but once you get to work life many years can mostly be same or at least weeks and months... On other hand I am sure there is some difference with perception of time when you get older and you will handle boredom better or can take something nap like just easier... reply glimshe 14 hours agoparentI think that's the reason of the trope \"As days becomes months, and months becomes years\". The days eventually become very much alike. reply bachmeier 15 hours agoprevI don't agree that it does. Something I've noticed as I've gotten older is that it feels like time is passing more slowly. My late 30s is when time felt like it passed the fastest. On the other hand, if you're talking about \"that happened two years ago, but it feels like it was yesterday\" I agree. I don't think that's what the post is talking about. reply smokel 14 hours agoparentYou might be an interesting specimen for scientific research. What food do you eat? Do you travel the world year round? Do you moisturize? Seriously, I'd probably give a year of my life to experience it being two years longer. reply bachmeier 13 hours agorootparentWhen my kid was young, it felt like time was evaporating. Days would fly by without any possibility of doing the things I needed to do, much less do the things I wanted to do. My life was defined by my time shortages. That's no longer the case. Not that I'm less busy (this is the busiest I've ever been) but I seem to have things better under control. So I think it's more about being better at time management. reply davis 12 hours agoprevWe've known this for over a decade at least https://www.popsci.com/science/article/2010-03/how-time-flie... reply randomdata 19 hours agoprevWatching my children, they appear to have more time. I expect it is not so much that time seems to pass faster, but that as you age you move into loftier goals that take longer. reply BenFranklin100 9 hours agoprevMy advice: Start a company. Every day is a new adventure. reply nox101 14 hours agoprevThis is the part I found most interesting about the first few episodes of \"Frieren: Beyond Journey's End\" anime. The main character is an elf. In this world elves are rare so she hasn't see another in 100s of years. Time for her passes differently than humans. She's got 1000s of years so for her, spending 10yrs in some library researching a hobby topic is not a big commitment. For her human friends it would be a large portion of their life. She commits to multi-year projects easily (10 years of a 5000 year life is 1/500th of your life vs a human where it's more like 1/8th). And, she watches her human friends pass away. Societies form and collapse. Etc... reply seydor 10 hours agoprevDoes it? Not if you switch away from the 9-5 routine. Daily work makes life feel fast, as do routines of all kinds, family kids etc. Switching to on-demand employment leaves a ton of opportunities for our attention to drift away and travel. It s true that novelty is rewarding. When mice are placed in a novel environment, their neurons become more excitable, but that doesn't necessarily correlate with subjective perception of time reply hosh 11 hours agoprevIn my early and mid 30s, as a result of visionary experiences, my experience of \"lived time\" changed. In general, moments lasts a lot longer. This doesn't really have to do with the brain becoming a better prediction machine so much as how mindful and present you are in the moment. While it is true that doing the same things over and over creates habits (ruts) of the mind, the practice of mindfulness reverses this. These days (in my early 40s), when I spar with swords, time stretches out by a lot. Especially during tournaments. reply olav 16 hours agoprevI wonder if the way the author describes it, ie. new memories are just diffs against older experiences, is scientifically grounded. I came up with another explanation: My thought processes have slowed, so the world has sped up, relative to myself. Is there scientific evidence for either explanation? reply HumblyTossed 19 hours agoprev1. Time is, literally, relative. We have nothing to compare things to when we are young, so everything takes for-ev-eeeeer. 2. The brain optimizes for storage. Our day to day is very consistent; we have routines. Those routines blur because why remember details if the details are very similar. Combine the two and as you age, things just feel like they fly by. reply avgcorrection 19 hours agoparent(1) is nonsense (and literally not needed to explain this phenomenon) but (2) is true. reply munchler 8 hours agoprevI think long periods of time are experienced logarithmically, with a base of around 2. So the period from, say, 10 to 20 years is comparable to the period from 20 to 40 years, and then 40 to 80 years. The seasons really start to zoom by at my age. (I'm in my late 50's.) reply justanotherjoe 19 hours agoprevit might be because schools are just more interesting than adult existence. Everyone comes from all walks of life and all you seem to think is to have fun (and other wholesome things) reply tacone 16 hours agoprevI have a memory from my childhood that still makes me smile. At six years old I have been told that old people tend do sleep less. So I went to my father and asked: \"Daddy, why do old people sleep so little?\" He looked at me and said: \"Because in a way they always sleep\". reply everybodyknows 12 hours agoprev> Processing speeds start decreasing well before age forty (which may be why mathematicians and physicists commonly do their best work in their youth). Atul Gawande, Being Mortal reply velcrovan 19 hours agoprevI think this blog post of mine from 2007 gives a better (or at least more succinct) answer to this question: https://thelocalyarn.com/article/this-is-your-life reply avgcorrection 19 hours agoparentThat’s just some made up math-as-psychology that makes sense to nerds for some reason. Just conflating two completely different concepts. Any explanation that doesn’t say anything about the mind is just baloney. Time here is an experiential phenomenon. It’s not fractions. Insert your pet theory in a context where adults have the same mindset as children and retain memories perfectly and have no reason to discard/compress memories them—you see that it’s totally irrelevant whether your life is 2/3 or 1/8 over. It has everything to do with how the mind works, not how numbers work. Bonus points for the “unscientific representation of your potential cumulative effect”… which is very self-aware-useless. reply iwontberude 10 hours agoprevSeems like time goes the same for me. I don’t ever do the same thing each day, I don’t keep a routine or show up consistently and sort of follow my interests and they change constantly. This makes me utterly incompatible with most people but I kind of like this more, I want to enjoy life as it comes. I am in no rush. reply javier_e06 12 hours agoprevMy way to slow down time is using git to write a diary with every day is a commit. I try to be careful not fall on the fallacy that \"I get it\" and draw assumptions about things. If not, after your pass your 50s time turns into blurring mashup of deja-vu's and the feeling that you are Fred Flinstone rolling in my Flintmobile while the background scenery, the houses, the palm trees and buildings repeat every 3 seconds. reply erererereere 9 hours agoprevThis post is extremely speculative and the author stretches the CS analogies way, way too far, but the gist is reasonably accurate. Time does pass faster on average as you get older because our brain doesn't bother to record repeated experiences. But guess what? That means that all you have to do to make time pass more slowly is bring more novelty into your life. I can say from personal experience that the year I spent living abroad seemed to go on forever. Every single day was filled with new experiences. There was a huge amount of continuous novelty and learning and growth. It was really nice. I need to move to a new country again. reply ajuc 8 hours agoprevIt's also the reason going back feels much faster despite the fact you're exhausted and probably walking/biking slower. You know the route so you switch to automatic more often and remember less. reply karaterobot 12 hours agoprevIt would be interesting to know when the subjective midpoint of your life is. I mean, if you lived to 80, and time seemed to speed up as you get older, is the subjective middle of your lifespan more like age 35, or more like age 25? I recognize it's impossible to answer this question from inside a life, but I have wondered it many times. reply jmathai 18 hours agoprev> Take on projects that you have no idea about. The idea of high correlation between predictability and time flying is interesting. I'm working on patenting an idea and have filed the provisional. This gives me exactly 1 year to file the full application. There's so many unknowns between now and then which has me very aware of time and actively wanting to slow it down. I'm not certain it always applies though. I've definitely had periods of high unpredictability where I enjoyed what I was doing and it didn't seem to go by slow at all. reply rayrey 5 hours agoprevMy father in law opined that life is a toilet paper roll. It spins faster towards the end reply nerevarthelame 11 hours agoprevThis is a lot of speculation about the brain and how memories are recorded, by someone with no apparent training on the subject, and with no sources cited. Maybe they're right. But I'd prefer more reliable sources, which other commenters here have provided. reply dapearce 20 hours agoprevI was always told it's because as you age a year becomes a smaller portion of your life. When you are 35 a year is 1/35th of your life, compared to 1/5th as a 5 year old. reply avgcorrection 19 hours agoprevI think with these things it helps to reflect. If you reflect you can either glean the truth about it or make up some intuition that is instrumentally useful. I think a lot of use manage to reach some wisdom milestones completely independently by just reflecting. And if you are concerned about this feeling of time going by faster: being less of a tunnel-visioned adult who is mostly focused on the extrinsic can maybe counteract this feeling. reply Alifatisk 14 hours agoprevYou all should checkout https://www.maximiliankiener.com/digitalprojects/time It explains and illustrates why time flies so well, love that site. reply rajeshp1986 13 hours agoprevModern society and work makes people have less free time to form memories. Certainly, people felt time is running fast even in older times but I doubt if time ran faster at the same rate for people from say 50s as much as it is for us today? reply Olumde 10 hours agoprevI wonder if prisoners feel the same way. I think time seems to pass by quickly because as we get older we get busier with family, work, children, spouse, friends, a few side interests etc. reply pizzafeelsright 20 hours agoprevPain extends time. Pleasure decreases it. Do things that are painful. Find pleasure in the painful like discipline and stuff that is uncomfortable. reply arethuza 19 hours agoparentThat sounds like Dunbar in Catch-22: \"Dunbar loved shooting skeet because he hated every minute of it and the time passed so slowly. He had figured out that a single hour on the skeet-shooting range with people like Havermeyer and Appleby could be worth as much as eleven-times-seventeen years.\" reply GuB-42 18 hours agoparentprevThat's not my experience. Intense pain makes time feel longer, but it is the same for all intense experiences. And I am not even sure about that, endorphines can make time fly. And when I consider memories, pleasurable events tend to take more time in my mind, pain tend to get erased more than pleasure. For example, I don't remember much about sick days, though obviously uncomfortable, they don't take much subjective time, thankfully. reply pjerem 19 hours agoparentprevI’m not sure that a long and painful life is preferable to shorter and happier life but if that’s your thing … reply nemo44x 19 hours agoparentprevI’m not sure you’re optimizing correctly here… reply novia 8 hours agoprevRecently I've been listening to the song \"Time and I\" by Jukebox the Ghost on this very topic. reply nutate 15 hours agoprevMy thought has always been that the ratio of lifetime to any given sublifetime unit of time is always increasing, leading to a change in relative experience. But if you focus on the fact that a second is constant, you always have the same amount of time right now. reply irrational 16 hours agoprevI wonder if people who daily reflect on their day and write in a journal experience time passing more slowly? I’ve heard that time seems to pass faster because it is such a smaller percentage of our life. For a 2 year old, 1 year is 50% of their life. For a 100 year old, 1 year is 1% of their life. reply RunawayGalaxy 8 hours agoprevThe concept of tolerance is most often used in the context of drugs, but it applies here too. reply bradley13 15 hours agoprevI think it is much simpler. When you are 4 years old, a year us a quarter of your life. When you ate 40, it is a mere 2.5%. Comparatively, that difference is huge: a year is far more significant to the child than to the adult. reply smokel 15 hours agoparentThis sounds like a reasonable argument, but I don't think it is. A day for a 4 year old still takes the same 24 hours as a day for a 40 year old. The argument presupposes that you experience the length of an event relative to the sum length of all experiences you've lived through. That seems pretty much related to the premise of the article we are discussing. So it's not much simpler. reply NoPicklez 10 hours agoprevI remember discussing this in Psychology about a decade ago. Supposedly it's quite a bit to do with routine and not having new experiences. reply gnatman 16 hours agoprev\"My grandfather used to say: 'Life is astonishingly short. As I look back over it, life seems so foreshortened to me that I can hardly understand, for instance, how a young man can decide to ride over to the next village without being afraid that, quite apart from accidents, even the span of a normal life that passes happily may be totally insufficient for such a ride.'\" - Franz Kafka, The Next Village reply beaugunderson 14 hours agoprevAnother explanation: https://www.kafalas.com/Logtime.html reply Apreche 20 hours agoprevThis is one of those things that seems true, but is it? They’ve presented no evidence whatsoever. Even the question itself carries with it an assumption. Does time seem to pass faster as we age? I bet you could find some people for whom it does not. reply avgcorrection 19 hours agoparentWhat are you arguing against? This is an experiential thing. Or phenomenological. Evidence? This is just something that people often report. No one cares if there are counter-examples. That doesn’t make it less true for those that experience it. reply justanotherjoe 19 hours agoparentprevyeah im 31 and i don't feel it. I do however, remember being 22 and just marvelling that its been 5 years since (an event) at high school. reply jalk 18 hours agoprevMy dad (who is in his late seventies) told me that while years seems to pass faster and faster with age, the future is still as far away, as it has always been. reply xenodium 15 hours agoprevIf anyone’s keen to journal on iOS, I’m looking for beta testers! No login, social, tracking, etc. Saves to plain text. https://xenodium.com/an-ios-journaling-app-powered-by-org-pl... reply user90131313 12 hours agoprevNo mention of energy? I think energy plays a big role because your movement and energy literally becomes less and less each year. At 80 you don't have much energy, forget about any other thing reply whoomp12341 16 hours agoprevI assumed it was just short term memory loss perceived as a framerate reply throw0101c 15 hours agoprevSee also Greek chronos versus kairos: > It is one of two words that the ancient Greeks had for 'time'; the other being chronos (χρόνος). Whereas the latter refers to chronological or sequential time,[2] kairos signifies a good or proper time for action. In this sense, while chronos is quantitative, kairos has a qualitative, permanent nature.[3] * https://en.wikipedia.org/wiki/Kairos > The ancient Greeks recognized the difference between chronological time (chronos) and subjective time (kairos). * https://en.wikipedia.org/wiki/Time_perception reply adawg4 15 hours agoprevThe vsauce video on time reminds me of this thread reply kamaal 18 hours agoprevNah Actually we do have very little time, its just that the upswing and downswing have different feels to it. You might have noticed this even when you are driving for a vacation. Drive to the picnic spot feels like an eternity, drive back home feels quick. There are ~52 weeks a year. Which makes a week 2% of a year. That's already a fast enough tick. Weeks do go by fast. An year is like 10% of a decade. Once you are past the age of 40. You indeed have little time left. Human life is short if you are doing remotely well in life. It can be a suffering if you are not doing great. reply archsurface 9 hours agoprevI came here to see what the 60 somethings have to say - the comments are from 30 somethings. The 30 somethings feeling old are in for a ride. reply simonblack 9 hours agoprevA year as a 36-year-old seems so much shorter as compared to when I was a kid or even as a teen. You think that's fast? Just wait till you're over 75! reply m0llusk 12 hours agoprevThis sounds highly rational and also comes across to me as completely wrong. I have maintained a fairly tight circle of friends and acquaintances for more than three decades. One of the patterns that stands out very strongly is the high variability in the perception of time. Those who have settled into a routine such as a relationship that endures and work that remains highly similar even if the company and title change tend to experience this time flying by effect strongly. Others who have had major complications to deal with like relationships coming and going, medical problems, big changes to location, fundamental changes in work situation and so on end to have a critical time slowing effect. Coming to grips with big changes and getting settled again requires a lot of attention and work and does not allow for a relaxed grip on life events. Try getting mugged, dumped, fired, sick, and then moving somewhere unfamiliar and you might find this time passing faster effect disappears, if only until adjustments are made. This implies the whole effect may be about how humans must focus when pushed but then tend to zoom out and ease up when ongoing attempts to steady themselves are successful. Reminds me of the book Tempo by Venkatesh Rao (https://www.ribbonfarm.com/tempo/). reply s0teri0s 13 hours agoprevIt is a progression: year 1 = 100% of your life year 2 = 50% of your life year 3 = 33% of your life ... year 10 = 10% of your life ... year 50 = 2% of your life etc. reply hiddencost 19 hours agoprevLSD can put you in a childlike state, increasing neuroplasticity. reply nathias 20 hours agoprev [–] it's just simple math, when you're 1 year old 1 year is the totality of your experience, when you're 2 years, it's half, etc. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Our brains process time differently as we age; familiarity and predictability make time seem to pass quicker, while novelty and surprise create longer-lasting memories.",
      "To slow down our perception of time, it is advisable to actively pursue new and unpredictable experiences rather than falling into routines.",
      "Embracing change and unpredictability can enhance the quality of our lives by making time feel more extended and experiences more memorable."
    ],
    "commentSummary": [
      "The article delves into how time perception changes as people age, with discussions on journaling benefits and the impact of new experiences.",
      "Various perspectives are shared on making life changes, skill improvement, and lifestyle choices influencing time perception, along with personal anecdotes.",
      "Suggestions on slowing down the feeling of time passing quickly are provided, emphasizing the importance of finding joy in the present moment."
    ],
    "points": 342,
    "commentCount": 225,
    "retryCount": 0,
    "time": 1709028164
  },
  {
    "id": 39532367,
    "title": "Introducing RecurseChat: macOS App for Local AI Chat",
    "originLink": "https://recurse.chat/",
    "originBody": "Hi Hackers,Excited to share a macOS app I&#x27;ve been working on: https:&#x2F;&#x2F;recurse.chat&#x2F; for chatting with local AI. While it&#x27;s amazing that you can run AI models locally quite easily these days (through llama.cpp &#x2F; llamafile &#x2F; ollama &#x2F; llm CLI etc.), I missed feature complete chat interfaces. Tools like LMStudio are super powerful, but there&#x27;s a learning curve to it. I&#x27;d like to hit a middleground of simplicity and customizability for advanced users.Here&#x27;s what separates RecurseChat out from similar apps:- UX designed for you to use local AI as a daily driver. Zero config setup, supports multi-modal chat, chat with multiple models in the same session, link your own gguf file.- Import ChatGPT history. This is probably my favorite feature. Import your hundreds of messages, search them and even continuing previous chats using local AI offline.- Full text search. Search for hundreds of messages and see results instantly.- Private and capable of working completely offline.Thanks to the amazing work of @ggerganov on llama.cpp which made this possible. If there is anything that you wish to exist in an ideal local AI app, I&#x27;d love to hear about it.",
    "commentLink": "https://news.ycombinator.com/item?id=39532367",
    "commentBody": "I made an app to use local AI as daily driver (recurse.chat)304 points by xyc 9 hours agohidepastfavorite126 comments Hi Hackers, Excited to share a macOS app I've been working on: https://recurse.chat/ for chatting with local AI. While it's amazing that you can run AI models locally quite easily these days (through llama.cpp / llamafile / ollama / llm CLI etc.), I missed feature complete chat interfaces. Tools like LMStudio are super powerful, but there's a learning curve to it. I'd like to hit a middleground of simplicity and customizability for advanced users. Here's what separates RecurseChat out from similar apps: - UX designed for you to use local AI as a daily driver. Zero config setup, supports multi-modal chat, chat with multiple models in the same session, link your own gguf file. - Import ChatGPT history. This is probably my favorite feature. Import your hundreds of messages, search them and even continuing previous chats using local AI offline. - Full text search. Search for hundreds of messages and see results instantly. - Private and capable of working completely offline. Thanks to the amazing work of @ggerganov on llama.cpp which made this possible. If there is anything that you wish to exist in an ideal local AI app, I'd love to hear about it. pentagrama 6 hours agoSadly I can't try this because I'm on Windows or Linux. Was testing apps like this if anyone is interested: Best / Easy to use: - https://lmstudio.ai - https://msty.app - https://jan.ai More complex / Unpolished UI: - https://gpt4all.io - https://pinokio.computer - https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generat... - https://github.com/LostRuins/koboldcpp Misc: - https://faraday.dev (AI Characters): No UI / Command line (not for me): - https://ollama.com - https://privategpt.dev - https://serge.chat - https://github.com/Mozilla-Ocho/llamafile Pending to check: - https://recurse.chat Feel free to recommend more! reply wanderingmind 2 hours agoparentlmstudio is using a dark pattern I really hate. Don't have a Github logo in your webpage if your software is not source available. It just takes to Github to some random config repos they have. This is poor choice in my opinion. reply woadwarrior01 1 hour agoparentprevSince I couldn't find it in your list, I'd like to plug my own macOS (and iOS) app: Private LLM. Unlike almost every other app in the space, it isn't based on llama.cpp (we use mlc-llm) or naive RTN quantized models (we use OmniQuant). Also, the app has deep integrations with macOS and iOS (Shortcuts, Siri, macOS Services, etc). Incidentally, it currently runs Mixtral 8x7B Instruct[2] and Mistral[3] models faster than any other macOS app. The comparison videos are with Ollama, but it generalizes well to almost every other macOS app that I've seen uses llama.cpp for inference. :) nb: Mixtral 8x7B Instruct requires an Apple Silicon Mac with at least 32GB of RAM. [1]: https://privatellm.app/ [2]: https://www.youtube.com/watch?v=CdbxM3rkxtc [3]: https://www.youtube.com/watch?v=UIKOjE9NJU4 reply iknowstuff 46 minutes agorootparentMacGPT is way handy because of a global keyboard shortcut which opens a spotlight-like prompt. I would love to have a local equivalent reply sigmoid10 1 hour agorootparentprevWhat's the performance like in tokens/s? reply woadwarrior01 34 minutes agorootparentYou can see ms/token in a tiny font on the top of the screen, once the text generation completes in both the videos I'd linked to. Performance will vary by machine. On my 64GB M2 Mac Studio Max, I get ~47 tokens/s (21.06ms/token) with Mistral Instruct v0.2 and ~33 tokens/s (30.14ms/token) with Mixtral Instruct v0.1. reply greggsy 15 minutes agoparentprevKhoj was one of the first 'low-touch' solutions out there I think. It's ok, but still under active development, like all of them really. https://khoj.dev/ reply chown 6 hours agoparentprevI am the author of Msty app mentioned here. So humbled to see an app that is just about a month old that I mostly wrote for my wife and some friends to begin with (who got overwhelmed with everything that was going in LLM world), on the top of your list. Thank you! reply Datagenerator 3 hours agorootparentLooks interesting, but can't see what it is doing. Any link to the source code? reply crooked-v 1 hour agorootparentprevOne bit of feedback: there's nowhere to put system messages. These can be much more influential than user prompts when it comes to shaping the tone and style of the response. reply petemir 2 hours agorootparentprevIf you need help for testing the Linux version let me know, I’d be happy to help reply hmdai 2 hours agoparentprevTry this one: https://uneven-macaw-bef2.hiku.app/app/ It loads the LLM in the browser, using webgpu, so it works offline after the first load, it's also PWA you can install. It should work on chrome > 113 on desktop and chrome > 121 on mobile. reply visarga 4 hours agoparentprevAdd Open-WebUI (used to be Ollama-WebUI) https://github.com/open-webui/open-webui a well featured UI with very active team reply lolpanda 5 hours agoparentprevOh thanks! didn't know there are quite a few ChatGPT local alternatives. I was wondering what users they are targeting. Engineers or average users? I guess average users will likely choose ChatGPT and Perplexity over local apps for more recent knowledge of the world. reply chown 5 hours agorootparentHi. I'm the author of Msty app, 2nd on the list above. You are right about average users likely choosing ChatGPT over local models. My wife was the first and the biggest user of my app. A software engineer by profession and training but she likes to not worry about LLM world and just to use it as a tool that makes you more productive. As soon as she took Msty for a ride, I realized that some users, despite their background, care about online models. This actually led me adding support for online models right away. However, she really likes to make use of the parallel chat feature and uses both Mistral and ChatGPT models to give same prompt and then compare the output and choose the best answer (or sometimes make a hybrid choice). She says that being able to compare multiple outputs like that is a tremendously helpful. But that's the extent of local LLMs for her. So far my effort has been to target a bit higher than the average users while making it approachable for more advanced users as well. reply AriedK 1 hour agorootparentLooks great, though the fact that you have to ignore your anti-virus warning during installation, and the fact that it phones home (to insights.msty.app) directly after launch despite the line in the FAQ on not collecting any data makes me a little skittish. reply Gunnerhead 5 hours agorootparentprevI’m looking for a ChatGPT client alternative, i.e. I can use my own OpenAI API key in some other client. Offline isn’t important for me, only that $20 is a lot of money, when I’d wager most months my usage is a lot less. However, I’d still want access to completion, DALL-E, etc. Would Msty be a good option for me? reply chown 4 hours agorootparentGive it a try and see how you feel. \"Yes, it will\" be a dishonest answer to be completely honest at least at this point. The app has been out for just about a month and I am still working in it. I would love a user like you to give it a try and give me some feedback (please). I am very active on our Discord if you want to get in touch (just mention your HN username and I will wace). reply Gunnerhead 4 hours agorootparentThank you so much, I’m excited to give this a try in the next few days. reply vorticalbox 1 hour agoparentprevhave you seen llamafile[0]? [0] https://github.com/Mozilla-Ocho/llamafile reply theolivenbaum 4 hours agoparentprevWe just added local LLM support to our curiosity.ai app too - if anyone wants to try we're looking for feedback there! reply joshmarinacci 5 hours agoparentprevDo any of these let you dump in a bunch of your own documents to use as a corpus and then query and summarize them ? reply greggsy 1 hour agorootparenthttps://github.com/imartinez/privateGPT reply chown 4 hours agorootparentprevAuthor of Msty here. Not yet but I am already working on the design for it to be added in very near future. I am happy to chat more with you to understand your needs and what you are looking in such apps. Please hop on the Discord if you don't mind :) reply windexh8er 5 hours agorootparentprevYes, GPT4All has RAG-like features. Basically you configure some directories and then have it load docs from whatever folders you have enabled for the model you're currently using. I haven't used it a ton, but I have used it to review long documents and it's worked well depending on the model. reply Datagenerator 3 hours agorootparentprevOpen-WebUI has support for doing that, it works using #tags for each document so you can ask questions about multiple specific documents. reply 8n4vidtmkvmk 4 hours agorootparentprevThe new one straight from Nvidia does I believe. reply stlhood 5 hours agoparentprevJust FYI, llamafile includes a web-based chat UI. It fires up automatically. reply ggerganov 46 minutes agoprev> Thanks to the amazing work of @ggerganov on llama.cpp which made this possible. If there is anything that you wish to exist in an ideal local AI app, I'd love to hear about it. The app looks great! Likewise, if you have any requests or ideas for improving llama.cpp, please don't hesitate to open an issue / discussion in the repo reply xyc 23 minutes agoparentOh wow it's the goat himself, love how your work has democratized AI. Thanks so much for the encouragement. I'm mostly a UI/app engineer, total beginner when it comes to llama.cpp, would love to learn more and help along the way. reply petargyurov 36 minutes agoparentprevDid not expect to see the Georgi Gerganov here :) How is GGML going? Поздрави! reply tartrate 1 hour agoprev> Full Text Search. Blazingly fast search over thousands of messages. Natural language processing has come full circle and just reinvented Ctrl+F. I had to double check that a regular '90s search function was actually the thing being advertised here, and sure enough, there is a gif demonstrating exactly that. reply addandsubtract 48 minutes agoparentCtrl+F only gets you so far. It doesn't allow you to perform semantic searches, for example. If you don't happen to know a unique word (or set of words) to search for, you're out of luck. Just the other day, I was able to find a song by typing the phonetic pronunciation (well, as best I could) into ChatGPT, and it knew which song I was talking about right away. No way a regular search engine would've helped me there. reply zzz999 4 minutes agoprevAny censorship? (Can't try MacOS Apps) reply girishso 8 hours agoprevI will totally pay for something like this if it answers from my local documents, bookmarks, browser history etc. reply vunderba 5 hours agoparentThere are already several RAG chat open source solutions available. Two that immediately come to mind are: Danswer https://github.com/danswer-ai/danswer Khoj https://github.com/khoj-ai/khoj reply chb 7 hours agoparentprevThis. There was a post in HN last week, iirc, referring to just such a solution called ZenFetch (?). I would have adopted it in a heartbeat but they don’t currently have a means of exporting the source data you feed to it (should you elect it as your sole means of bookmarking, etc) reply gabev 6 hours agorootparentHey there, This is Gabe, the founder of Zenfetch. Thanks for sharing. We're putting together an export option where you can download all your saved data as a CSV and should get that out by end of week. reply xyc 8 hours agoparentprevYes it would be the next big focus on this. Personal data connectivity is what I see where local AI would excel - despite model power differences. reply Satam 4 hours agorootparentI have doubts about that. Most personal data actually lives in the cloud these days. If you need your Gmail emails, you'll need to use their API which is guarded behind $50k certification fee or so. I think there is a simpler version for personal use, but you still need to get the API key. Who's going to teach their mom about API keys? So I think for a lot of these data sources you'll end up with enterprise AIs integrating them first for a seamless experience. reply noduerme 21 minutes agorootparentSeconding a sibling question: What $50k API fee? To access your gmail? I've been using gmail since 2008 or so without ever touching their web/app interface or getting an API key. You just use it as an IMAP server. reply coev 1 hour agorootparentprevWhy wouldn't you be able to use IMAP over the gmail api? IMAP returns the text and headers of all your emails, which is what you'd want the LLM to ingest anyway. reply xyc 1 hour agorootparentprevI think this is a good take. While there's big enough niche for personal data locally, I'd love if there's a way to solve for email/cloud data requiring API keys. reply noduerme 16 minutes agorootparentIdeally, though, a sufficiently smart LLM shouldn't need API access. It could navigate to your social media login page, supply your credentials, and scrape what it sees. Better yet, it should just reverse-engineer the API ;) reply ssnri 5 hours agorootparentprevI would even let it have longer processing times for queries to apply against each document in my system, allow it to specialize/train itself on a daily basis… Use all the resources you want if you save me brainpower reply xyc 4 hours agorootparentAgree, there's a non real-time angle to this. reply _boffin_ 6 hours agorootparentprevGood to know there's a market for that. Currently building out something. Integrating from numerous sources, processing and then utilizing those. nice. reply chaostheory 7 hours agorootparentprevYeah, we’re getting closer to “Her” reply spiderfarmer 1 hour agoparentprevNext version of MacOS will probably have that. reply tethys 1 hour agorootparentAs long as you use Safari for browsing, Notes for note taking, iCloud for mail … reply toomuchtodo 6 hours agoparentprevhttps://news.ycombinator.com/item?id=38787892 (\"Rem: Remember Everything (open source)\") ? https://github.com/jasonjmcghee/rem reply jlund-molfese 7 hours agoparentprevSounds like https://www.rewind.ai/ ? reply scottrblock 7 hours agoparentprevplus one, I would love to configure a folder of markdown/txt(+ eventually images and pdfs) files that this can have access to. Ideally it could RAG over them in a sensible way. Would love to help support this! reply xyc 3 hours agorootparentThank you! I'd love to learn more about your use cases. Would you mind sending an email to feedback@recurse.chat or DM me on https://x.com/chxy to get the conversation started? reply rkuodys 2 hours agoprevHonest question - can it be used for programming? Or anyone maybe can recommend local-first development LLM which would take in all project (Python / Angular) and write code based on full repo, not only the active window as with Copilot or Jetbrains AI reply code51 1 hour agoprevThank you for the work. Please take this in a nice way: I can't see why I would use this over ChatbotUI+Ollama https://github.com/mckaywrigley/chatbot-ui Seem the only advantage is having it as MacOS native app and only real distinction is maybe fast import and search - I've yet to try that though. ChatbotUI (and other similar stuff) are cross-platform, customizable, private, debuggable. I'm easily able to see what it's trying to do. reply ayhoung 1 hour agoparentNot everyone is a dev reply giblfiz 6 hours agoprevSo there are a few questions that leap out at me: * What are you using for image generation? Is that local as well (stable diffusion?) Does it have integrated prompt generation? * You mention the ability to import ChatGPT history, are you able to import other documents? * How many \"agent\" style capacities does it have? Can it search the web? use other APIs? Prompt itself? * Does it have a plugin framework? you mention that it is \"customizable\" but that can mean almost anything. * What is the license? what assurances do users have that their usage is private? I mean, we all know how many \"local\" apps exfiltrate a ton of data. reply rexreed 7 hours agoprevWhat are the MacOS and hardware requirements? How does it perform on a slightly older model, lower powered Mac? I wish I could test this to see how it would perform, and while it's only $10, I don't want to spend that just to realize it won't work on my older, underpowered Mac mini. reply xyc 4 hours agoparentGood question, I'll put some system requirements on the website. It only supports mac with Apple Silicon now, if that's helpful. reply pantulis 1 hour agorootparentInstant buy, great work and the price point is exactly right. Good luck! reply CGamesPlay 8 hours agoprevPossibly a strange question, but do you have plans to add online models to the app? Local models just aren't at the same level, but I would certainly appreciate a consistent chat interface that lets me switch between GPT/Claude/local models. reply longnguyen 1 hour agoparentShameless plug: if you need multiple AI Service Provider, give BoltAI[0] a try. It’s native (not Electron), and supports multiple services: OpenAI, Azure OpenAI, OpenRouter, Mistral, Ollama… It also allows you to interact with LLMs via multiple different interfaces: Chat UI, a context-aware called AI Command and an Inline mode. [0]: https://boltai.com reply xyc 8 hours agoparentprevNot strange at all! It's a very valid ask. The focus is local AI, but GPT-3.5/GPT-4 are actually included in the app (bring your own key), although customization is limited. Planning to expose some more customizability there including API base urls / model names. reply iansinnott 8 hours agoparentprevYou could try out Prompta [1], which I made for this use case. Initially created to use OpenAI as a desktop app, but can use any compatible API including Ollama if you want local completions. [1]: https://github.com/iansinnott/prompta reply CGamesPlay 8 hours agorootparentThis one doesn't seem to support system prompts, which are absolutely essential for getting useful output from LLMs. reply iansinnott 7 hours agorootparentYou can update the system prompt in the settings. Admittedly this is not mentioned in the README, but is customizable. reply refulgentis 5 hours agorootparent> the system prompt There isn't a singular system prompt. It really does matter! Copy the OpenAI playground, you'll thank yourself later reply iansinnott 1 hour agorootparentFair point, and it's not implemented that way currently. It's more like \"custom instructions\" but thanks for pointing that out. I haven't used multiple system prompts in the OpenAI playground either, so I hadn't given it much thought. reply 8n4vidtmkvmk 4 hours agorootparentprevYou use multiple system prompts in a single chat? What for? reply a_bonobo 7 hours agorootparentprevI've run into the same problem with deploying Gemini locally, it does not seem to support System Prompts. I've cheated around this by auto-prepending the system prompt to the user prompt, and then deleting it from the user-displayed prompt again. reply derwiki 7 hours agorootparentprevCan you speak more to this? I get useful output from LLMs all the time, but never use system prompts. What am I missing? reply CGamesPlay 6 hours agorootparentSure, I use one system prompt template to make ChatGPT be more concise. Compare these two: https://sharegpt.com/c/fEZKMIy vs https://sharegpt.com/c/S2lyYON I use similar ones to get ChatGPT to be more thorough or diligent as well. From my limited experience with local models, this type of system prompting is even more important than with ChatGPT 4. reply addandsubtract 43 minutes agorootparentIs there a difference in using a system prompt and just pasting the \"system prompt\" part at the beginning of your message? reply castles 8 hours agoparentprevhttps://recurse.chat/faq/#:~:text=We%20support%20Mistral%2C%... reply christiangenco 7 hours agorootparent...how did you highlight a specific sentence like that? reply sandyarmstrong 7 hours agorootparentLooks like a Chromium-specific feature: https://web.dev/articles/text-fragments Pretty cool. Doesn't work on Firefox. reply QuinnyPig 7 hours agorootparentIt just worked on Safari on iOS. That’s pretty impressive. reply svat 3 hours agorootparenthttps://caniuse.com/url-scroll-to-text-fragment -- yes Safari supports it reply 911e 1 hour agoprevNot a bit of open code while I'm 100% sure they use some that require it. If you\"re using AI + Your data without insight on how it's used you're a fool. 2 cents reply devinprater 4 hours agoprevThere's another one someone made for blind users like themselves and me, called Vollama (they use a mac, so VoiceOver + Llama). It's really good. I haven't tested many others for accessibility, but it has RAG and uses Ollama as backend, so works very well for me. https://github.com/chigkim/VOLlama/ reply chown 4 hours agoparentIt's very nice that there exists something like that. I am an author of one of the similar apps [1] someone listed in a different thread. I was hoping I could get in touch with someone like you who could give me some feedback on how to make my app more accessible for users like you. I really want to it be an \"LLM for all\" kind of app but despite my best efforts and intention, I suck at it. Any chance of getting in touch with you and get some feedback? Only if you want and have time, no pressure at all. [1] https://msty.app reply devinprater 4 hours agorootparentSure, I'll probably join the discord tomorrow morning, but a few notes: * For apps like this, using live regions to speak updates may be helpful. either that or change the buttons, like from \"download local AI\" to \"configuring.\" Maybe a live region would be best for that one since sighted people would probably be looking near the bottom for the status bar, but anyway... * Using live regions for chats is pretty important, because otherwise we don't know when a message is ready to read, and it makes reading those messages much simpler. The user types the message, presses Enter, and the screen reader reads the message to them. So, making a live region, and then sending the finished message, or a finished part of a message, to that live region would be really helpful. * Now on to the UI. At the top, we have \"index /text-chat-sessions\". I guess that should just say \"chats\"? Below that, we have a list, with a button saying the same thing. After that list with one item, is a button that says \"index /local-ai\". That should probably just be \"local AI\". Afterwards, there is \"index /settings\", which should just be \"settings.\" Then, there is an unlabeled button. I'm guessing this is styled to look like a menu bar, across the top of the window, so it'd be the item on the right side. Now, there's a button below that that says \"New Chat^N\". I, being a technical user, am pretty sure the \"^N\" means \"Control + N\", but almost no one else knows that. So, maybe change that text label. Between that and the Recent Chats menu button are two unlabeled buttons. I'm not sure why a region landmark was used for the recent chats list, but after the chat name \"hello\" in this case, where I can rename the chat, there is an unlabeled button. The button after the model chooser is unlabeled as well. After the user input in the conversation, there are three unlabeled buttons. After the response, there is a menu button with (oh, that's cool) items to transform the response into bullets, a table, ETC. but that menu button was unlabeled so I had to open it to see what's inside. After that, all other buttons, like for adding instructions to refine this message, are also unlabeled. So, live regions for speaking chat messages and state changes like \"loading\" or \"ready\" or whatever (keep them short), and label controls, and you should be good to go. Live regions: https://developer.mozilla.org/en-US/docs/Web/Accessibility/A... reply jiriro 37 minutes agoprevOut of curiosity – how is this app built?:-) There is a demo clip with a vertical scroll bar which does not fade out as it would do in a native mac app:) reply rangera 3 minutes agoparentScroll bars don't fade out if you're using a mouse (as opposed to just a trackpad) or if you've set Mac OS Settings > Appearance > Show scroll bars to \"Always\". reply cooper_ganglia 5 hours agoprevI read the website for 30 seconds and instantly bought it. It's clean, easy to use, and works really well! Easy local server hosting was cool, too. I've used the other LLM apps, and this feels like those, but simplified. It just feels good to use. I like it a lot! I'm gonna test drive it for a while, and if I keep using it regularly, I'll definitely be sending in some feedback. Other users have made a lot of really great recommendations already, I'm excited to see how this evolves! reply xyc 4 hours agoparentThanks so much for the kind words and giving it a spin! Feel free to send feedback, issues, feature suggestion as you use it more, I'm all ears. My twitter DM is also open: https://x.com/chxy. reply madduci 4 hours agorootparentAny chance to see it available on other operating systems as well? reply xyc 3 hours agorootparentUnfortunately not now. If you are interested in email updates: https://tally.so/r/wzDvLM reply bradnickel 6 hours agoprevLove this! Just purchased. I am constantly harping on decentralized AI and love seeing power in simplicity. Are you on Twitter, Threads, Farcast? Would like to tag you when I add you to my decentralized AI threads. reply xyc 6 hours agoparentThank you so much for the support! Simplicity is power indeed. I'm on twitter: https://x.com/chxy reply bradnickel 6 hours agoparentprevFound your Twitter account in a previous post. Just tagged you. reply xyc 4 hours agorootparentAwesome, thanks for the tag! reply raajg 8 hours agoprevlooks promising, but after looking at the website I'm yearning to learn more about it! How does it compare to alternatives? What's the performance like? There isn't enough to push me to stop using ChatGPT and use this instead. Offline is good, but to get users at scale there has to be a compelling reason to shift. I don't think that offline capabilities are going to be enough to get significant number of users. Another tip, I try out a new chat interface to LLMs almost every week and they're free to use initially. There isn't a compelling reason for me to spend $10 from the get to for a use case that I'm not sure about yet. reply bradnickel 6 hours agoparentThe compelling reason to shift to local/decentralized AI is that all of compute will soon be AI and that means your entire existence will go into it. The question you should ask yourself is do you want everything about you being handled by Sam Altman, Google, Microsoft, etc? Do you want all of your compute dependent on them always being up and do you want to trust their security team with your life? Do you want to still be using closed/centralized/hosted AI when truly open AI surpasses all of them in performance and capability. If you have children or family, do you want them putting their entire lives in the hands of those folks. Decentralized AI will eventually become p2p and swarmed and then the true power of agents and collaboration will soar via AI. Anyway, excuse the soap box, but there are zero valid reasons for supporting and paying centralized keepers of AI that rarely share, collaborate or give back to the community that made what they have possible. reply FloorEgg 8 hours agoparentprevMaybe this isn't for everyone, just the people who place a high value on privacy. reply vunderba 5 hours agorootparentIf your ultimate goal is privacy, then you should only be looking at open source chat UI front ends: https://github.com/mckaywrigley/chatbot-ui https://github.com/oobabooga/text-generation-webui https://github.com/mudler/LocalAI And then connecting them to off-line models servers: - Ollama - llama.cpp And you should avoid closed source frontends: - Recurse - LM Studio And closed source models - ChatGPT - Gemini reply copperx 2 hours agorootparentAre you implying Claude is an open source model? reply ukuina 7 hours agorootparentprevBut how can I guarantee this app is private? I'm assuming I cannot block internet access to the app because it needs to verify App Store entitlement. reply giblfiz 7 hours agorootparentprevI mean, ok, then how do you distinguish yourself from LM Studio (Free) reply rbtprograms 8 hours agoprevLooks great! Does it support different sized models, i.e. can I run llama 70B and 7B, and is there a way to specify which model to chat with? Are there plans to allow users to ingest their own models through this UI? reply xyc 7 hours agoparentIf you have a gguf file you can link it. For ingesting new models - I'm thinking about adding some CRUD UIs to it, but I'd like to keep a very small set of default models. reply rbtprograms 2 hours agorootparentthanks, its a great project reply tkgally 8 hours agoprevFor an app like this, I would really like a spoken interface. Any possibility of adding text-to-speech and speech-to-text so that users can not only type but also talk with it? reply xyc 3 hours agoparentyes I wish it could talk. It's after other priorities though, but I might try something experimental. reply sen 5 hours agoprevThis is awesome. I currently use Ollama with OpenWebUI but am a big fan of native apps so this is right up my alley. reply woadwarrior01 40 minutes agoparentIt looks like an Electron app, and not a native app. https://imgur.com/a/pz0kzJ1 reply xyc 4 hours agoparentprevThank you! reply SkepticMystic 4 hours agoprevI've found great utility with `llm` https://llm.datasette.io, a CLI to interact with LLMs. It has plugins for remote and local models. reply xyc 3 hours agoparentGood to know. I've learned lots of things from Simon Willison's blog (datasette's author), so can't imagine llm being unuseful. reply xyc 6 hours agoprevWow, I did not expect at all this will end up on the front page. Thank you for all the enthusiasm, I'll try to get to more questions later today but if there's something I missed my X/twitter DM is open: https://x.com/chxy reply android521 6 hours agoprevhow big is the local model? what is the Mac spec requirement? I don't want to download and find out it won't work in my computer. It seems like the first question everyone would ask and should be addressed on the website. reply xyc 4 hours agoparentAppreciate the feedback! It works on mac with Apple Silicon only. I'll put some system requirements on the website. reply visarga 4 hours agoparentprevIt uses ollama which is based on llama.cpp, and adds a model library with dozens of models in all quant sizes. reply xyc 4 hours agorootparentno this doesn't use ollama, just based on llama.cpp. reply toomuchtodo 5 hours agoprevHey! This is awesome! How hard would it be to plug it into something like Raindrop.io (bookmark manager) to train on all bookmarks collected? reply xyc 4 hours agoparenthaven't tried Raindrop.io, looks neat! Saw some other posts mentioning bookmarks as well. I'll keep this in thought, but will have to try it out first to find out. reply geniium 2 hours agoprevI am very glad to see that kind of app. Well done! reply 3abiton 8 hours agoprevHow different is this compared to Jan.ai for example? reply xyc 7 hours agoparentas i understand jan.ai is more focused on enterprise / platform, while I'd see where recursechat would go is more like \"obsidian.md\" but as your personal AI. reply gexla 7 hours agorootparentObsidian has add-ons which do much of this. reply internetter 7 hours agorootparentPeople are treating Obsidian like it's the next Emacs reply surrTurr 1 hour agoprevany plans on supporting ollama integration? reply pentagrama 7 hours agoprev [–] Congrats! Plans on Windows support? reply xyc 4 hours agoparentThanks! Sorry no immediate plan. People have recommended Chat with RTX so it might be worth checking out. https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generat... reply theolivenbaum 4 hours agoparentprev [–] You can try https://curiosity.ai, supports Windows and macOS reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "RecurseChat is a macOS application allowing users to chat with local AI models, emphasizing simplicity and customization for advanced users.",
      "Key features include zero config setup, multi-modal chat, importing ChatGPT history, full-text search, and offline functionality.",
      "The author acknowledges @ggerganov's llama.cpp contribution, enabling the app's development, and welcomes feedback for future enhancements."
    ],
    "commentSummary": [
      "The conversation revolves around developing AI chat applications for macOS, emphasizing simplicity, customization, and performance.",
      "Users discuss their experiences with apps like Msty, GPT4All, and Rem, covering features, data collection concerns, pricing, and integration possibilities with other platforms.",
      "There is also a dialogue on the significance of system prompts to enhance the performance of extensive language models and accessibility features, alongside talks about decentralized AI platforms, privacy issues, and potential cross-platform support and add-ons."
    ],
    "points": 305,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1709080800
  },
  {
    "id": 39523495,
    "title": "Ant Geopolitics: Ant Societal Structure and Human Challenges",
    "originLink": "https://aeon.co/essays/the-strange-and-turbulent-global-world-of-ant-geopolitics",
    "originBody": "× CLOSE Philosophy Science Psychology Society Culture Essays Videos Audio Popular About DONATE NEWSLETTER MENU DONATE NEWSLETTER SIGN IN Ant geopolitics Over the past four centuries quadrillions of ants have created a strange and turbulent global society that shadows our own A queen Solenopsis invicta, an invasive fire ant. Photo by Alex Wild John Whitfield is the opinion editor at Research Professional News. A journalist specialising in science, his writing has appeared in Nature, The London Review of Books and Slate, among others. He is the author of In the Beat of a Heart (2006), People Will Talk: The Hidden Power of Reputation (2011) and Lost Animals: The Story of Extinct, Endangered and Rediscovered Species (2020). He lives in London, UK. Edited byCameron Allan McKean 3,900 words SYNDICATE THIS ESSAY Email Save Tweet Share It is a familiar story: a small group of animals living in a wooded grassland begin, against all odds, to populate Earth. At first, they occupy a specific ecological place in the landscape, kept in check by other species. Then something changes. The animals find a way to travel to new places. They learn to cope with unpredictability. They adapt to new kinds of food and shelter. They are clever. And they are aggressive. In the new places, the old limits are missing. As their population grows and their reach expands, the animals lay claim to more territories, reshaping the relationships in each new landscape by eliminating some species and nurturing others. Over time, they create the largest animal societies, in terms of numbers of individuals, that the planet has ever known. And at the borders of those societies, they fight the most destructive within-species conflicts, in terms of individual fatalities, that the planet has ever known. This might sound like our story: the story of a hominin species, living in tropical Africa a few million years ago, becoming global. Instead, it is the story of a group of ant species, living in Central and South America a few hundred years ago, who spread across the planet by weaving themselves into European networks of exploration, trade, colonisation and war – some even stowed away on the 16th-century Spanish galleons that carried silver across the Pacific from Acapulco to Manila. During the past four centuries, these animals have globalised their societies alongside our own. A polygyne population of red imported fire ants at Brackenridge Field. Austin, Texas, USA. Photo by Alexander Wild It is tempting to look for parallels with human empires. Perhaps it is impossible not to see rhymes between the natural and human worlds, and as a science journalist I’ve contributed more than my share. But just because words rhyme, it doesn’t mean their definitions align. Global ant societies are not simply echoes of human struggles for power. They are something new in the world, existing at a scale we can measure but struggle to grasp: there are roughly 200,000 times more ants on our planet than the 100 billion stars in the Milky Way. In late 2022, colonies of the most notorious South American export, the red fire ant (Solenopsis invicta) were unexpectedly found in Europe for the first time, alongside a river estuary close to the Sicilian city of Syracuse. People were shocked when a total of 88 colonies were eventually located, but the appearance of the red fire ant in Europe shouldn’t be a surprise. It was entirely predictable: another ant species from S invicta’s native habitats in South America had already found its way to Europe. What is surprising is how poorly we still understand global ant societies: there is a science-fiction epic going on under our feet, an alien geopolitics being negotiated by the 20 quadrillion ants living on Earth today. It might seem like a familiar story, but the more time I spend with it, the less familiar it seems, and the more I want to resist relying on human analogies. Its characters are strange; its scales hard to conceive. Can we tell the story of global ant societies without simply retelling our own story? S ome animal societies hold together because their members recognise and remember one another when they interact. Relying on memory and experience in this way – in effect, trusting only friends – limits the size of groups to their members’ capacity to sustain personal relationships with one another. Ants, however, operate differently by forming what the ecologist Mark Moffett calls ‘anonymous societies’ in which individuals from the same species or group can be expected to accept and cooperate with each other even when they have never met before. What these societies depend on, Moffett writes, are ‘shared cues recognised by all its members’. Recognition looks very different for humans and insects. Human society relies on networks of reciprocity and reputation, underpinned by language and culture. Social insects – ants, wasps, bees and termites – rely on chemical badges of identity. In ants, this badge is a blend of waxy compounds that coat the body, keeping the exoskeleton watertight and clean. The chemicals in this waxy blend, and their relative strengths, are genetically determined and variable. This means that a newborn ant can quickly learn to distinguish between nest mates and outsiders as it becomes sensitive to its colony’s unique scent. Insects carrying the right scent are fed, groomed and defended; those with the wrong one are rejected or fought. Colonies spread without ever drawing boundaries because workers treat all of their own kind as allies The most successful invasive ants, including the tropical fire ant (Solenopsis geminata) and red fire ant (S invicta), share this quality. They also share social and reproductive traits. Individual nests can contain many queens (in contrast to species with one queen per nest) who mate inside their home burrows. In single-queen species, newborn queens leave the nest before mating, but in unicolonial species, mated queens will sometimes leave their nest on foot with a group of workers to set up a new nest nearby. Through this budding, a network of allied and interconnected colonies begins to grow. In their native ranges, these multi-nest colonies can grow to a few hundred metres across, limited by physical barriers or other ant colonies. This turns the landscape to a patchwork of separate groups, with each chemically distinct society fighting or avoiding others at their borders. Species and colonies coexist, without any prevailing over the others. However, for the ‘anonymous societies’ of unicolonial ants, as they’re known, transporting a small number of queens and workers to a new place can cause the relatively stable arrangement of groups to break down. As new nests are created, colonies bud and spread without ever drawing boundaries because workers treat all others of their own kind as allies. What was once a patchwork of complex relationships becomes a simplified, and unified, social system. The relative genetic homogeneity of the small founder population, replicated across a growing network of nests, ensures that members of unicolonial species tolerate each other. Spared the cost of fighting one another, these ants can live in denser populations, spreading across the land as a plant might, and turning their energies to capturing food and competing with other species. Chemical badges keep unicolonial ant societies together, but also allow those societies to rapidly expand. A ll five of the ants included in the International Union for the Conservation of Nature’s (IUCN) list of 100 of the world’s worst invasive alien species are unicolonial. Three of these species – the aforementioned red fire ant (S invicta), the Argentine ant (Linepithema humile) and the little fire ant (Wasmannia auropunctata) – are originally from Central and/or South America, where they are found sharing the same landscapes. It is likely that the first two species, at least, began their global expansion centuries ago on ships out of Buenos Aires. Some of these ocean journeys might have lasted longer than a single worker ant’s lifetime. Unicolonial ants are superb and unfussy scavengers that can hunt animal prey, eat fruit or nectar, and tend insects such as aphids for the sugary honeydew they excrete. They are also adapted to living in regularly disrupted environments, such as river deltas prone to flooding (the ants either get above the waterline, by climbing a tree, for example, or gather into living rafts and float until it subsides). For these ants, disturbance is a kind of environmental reset during which territories have to be reclaimed. Nests – simple, shallow burrows – are abandoned and remade at short notice. If you were looking to design a species to invade cities, suburbs, farmland and any wild environment affected by humans, it would probably look like a unicolonial ant: a social generalist from an unpredictable, intensely competitive environment. When these ants show up in other places, they can make their presence felt in spectacular fashion. An early example comes from the 1850s, when the big-headed ant (Pheidole megacephala), another species now listed on the IUCN’s top 100, found its way from Africa to the Madeiran capital of Funchal. ‘You eat it in your puddings, vegetables and soups, and wash your hands in a decoction of it,’ complained one British visitor in 1851. When the red fire ant (S invicta), probably the best-known unicolonial species, spread through the US farming communities surrounding the port of Mobile, Alabama in the 1930s, it wreaked havoc in different ways. ‘Some farmers who have heavily infested land are unable to hire sufficient help, and are forced to abandon land to the ants,’ was how E O Wilson in 1958 described the outcome of their arrival. Today, the red fire ant does billions of dollars of damage each year and inflicts its agonising bite on millions of people. But the largest colonies, and most dramatic moments in the global spread of ant societies, belong to the Argentine ant (L humile). New Zealand is the only country to have prevented the spread of the red fire ant Looking at the history of this species’ expansion in the late 19th and early 20th centuries, it can seem as if the spread of global trade was an Argentine ant plot for world domination. One outbreak appeared in Porto, following the 1894 Exhibition of the Islands and Colonies of Portugal. The insects had likely travelled on produce and wares displayed at the exhibition from Madeira – ornamental plants, which tend to travel with a clump of their home soil, are particularly good for transporting invasive species. In 1900, a Belfast resident, Mrs Corry, found a ‘dark army’ of the same species crossing her kitchen floor and entering the larder, where they covered a leg of mutton so completely that ‘one could scarcely find room for a pin-point’. In 1904, the US Bureau of Entomology dispatched a field agent, Edward Titus, to investigate a plague of Argentine ants in New Orleans. He heard reports of the ants crawling into babies’ mouths and nostrils in such numbers that they could be dislodged only by repeatedly dunking the infant in water. Other reports described the ants entering hospitals and ‘busily carrying away the sputum’ from a tuberculosis patient. When the species arrived on the French Riviera a few years later, holiday villas were abandoned and a children’s hospital was evacuated. In December 1927, Italy’s king Vittorio Emmanuel III and its prime minister Benito Mussolini signed a law setting out the measures to be taken against the Argentine ant, splitting the cost equally with invaded provinces. The state’s effectiveness, or lack of it, is shown in the novella The Argentine Ant (1952) by Italo Calvino, one of Italy’s great postwar writers. Calvino, whose parents were plant biologists, sets his tale in an unnamed seaside town much like the one where he grew up, in the northwestern province of Liguria. The ant has outlasted both Mussolini and the monarchy, and saturates the unnamed town, burrowing underground (and into people’s heads). Some residents drench their houses and gardens with pesticides or build elaborate traps involving hammers covered in honey; others try to ignore or deny the problem. And then there is Signor Baudino, an employee of the Argentine Ant Control Corporation, who has spent 20 years putting out bowls of molasses laced with a weak dose of poison. The locals suspect him of feeding the ants to keep himself in a job. In reality, people who found themselves living in the path of such ant plagues learned to stand the feet of their cupboards, beds and cots in dishes of kerosene. However, this was not a long-term solution: killing workers away from the nest achieves little when most, along with their queens, remain safe at home. Slower-acting insecticides (like Baudino’s poison), which workers take back to the nest and feed to queens, can be more effective. But because unicolonial workers can enter any number of nests in their network, each containing many queens, the chances of delivering a fatal dose gets much slimmer. In the early 20th century, an intensive period in the human war against ants, pest-control researchers advocated using broad-spectrum poisons, most of which are now banned for use as pesticides, to set up barriers or fumigate nests. Nowadays, targeted insecticides can be effective for clearing relatively small areas. This has proved useful in orchards and vineyards (where the ants’ protection of sap-sucking insects makes them a hazard to crops) and in places such as the Galápagos or Hawaii where the ants threaten rare species. Large-scale eradications are a different matter, and few places have tried. New Zealand, the world leader in controlling invasive species, is the only country to have prevented the spread of the red fire ant, mostly by eradicating nests on goods arriving at airports and ports. The country is also home to a spaniel trained to sniff out Argentine ants nests and prevent the insects from reaching small islands important for seabirds. H uman inconvenience pales in comparison with the ants’ effects on other species. Exploring the countryside around New Orleans in 1904, Titus found the Argentine ant overwhelming the indigenous ant species, bearing away the corpses, eggs and larvae of the defeated to be eaten: ‘column after column of them arriving on the scene of battle’. Other entomologists at the time learned to recognise the disappearance of native ants as a sign of an invader’s arrival. Unicolonial species are aggressive, quick to find food sources and tenacious in defending and exploiting them. Unlike many ant species, in which a worker who finds a new food source returns to the nest to recruit other foragers, the Argentine ant enlists other workers already outside the nest, thus recruiting foragers more quickly. However, the decisive advantage of unicolonial ant species lies in their sheer force of numbers, which is usually what decides ant conflicts. They often become the only ant species in invaded areas. The effects of these invasions cascade through ecosystems. Sometimes, the damage is direct: on the Galápagos, fire ants prey on tortoise hatchlings and bird chicks, threatening their survival. In other cases, the damage falls on species that once relied on native ants. In California, the tiny Argentine ant (typically under 3 mm long) has replaced the larger native species that once formed the diet of horned lizards, leaving the reptiles starving – it seems they do not recognise the much smaller invader as food. In the scrublands of the South African fynbos heathland, which has some of the most distinctive flora on Earth, many plants produce seeds bearing a fatty blob. Native ants ‘plant’ the seeds by carrying them into their nests, where they eat the fat and discard the rest. Argentine ants – almost certainly imported to South Africa around 1900 along with horses shipped from Buenos Aires by the British Empire to fight the Boer War – either ignore the seeds, leaving them to be eaten by mice, or strip the fat where it lies, leaving the seed on the ground. This makes it harder for endemic flora such as proteas to reproduce, tipping the balance towards invasive plants such as acacias and eucalypts. In the past 150 years, the Argentine ant has spread to pretty much everywhere that has hot, dry summers and cool, wet winters. A single supercolony, possibly descended from as few as half a dozen queens, now stretches along 6,000 kilometres of coastline in southern Europe. Another runs most of the length of California. The species has arrived in South Africa, Australia, New Zealand and Japan, and even reached Easter Island in the Pacific and St Helena in the Atlantic. Its allegiances span oceans: workers from different continents, across millions of nests containing trillions of individuals, will accept each other as readily as if they had been born in the same nest. Workers of the world united, indeed. But not completely united. As with inbred species everywhere, this may make them prone to disease Expanding in parallel with the world-spanning supercolony are separate groups of the Argentine ant that bear different chemical badges – the legacy of other journeys from the homeland. Same species, different ‘smells’. In places where these distinct colonies come into contact, hostilities resume. In Spain, one such colony holds a stretch of the coast of Catalonia. In Japan, four mutually hostile groups fight it out around the port city of Kobe. The best-studied conflict zone is in southern California, a little north of San Diego, where the Very Large Colony, as the state-spanning group is known, shares a border with a separate group called the Lake Hodges colony, with a territory measuring just 30 kilometres around. Monitoring this border for a six-month period between April and September 2004, a team of researchers estimated that 15 million ants died on a frontline a few centimetres wide and several kilometres long. There were times when each group seemed to gain ground, but over longer periods stalemate was the rule. Those seeking to control ant populations believe provoking similar conflicts might be a way to weaken invasive ants’ dominance. There are also hopes, for example, that artificial pheromones – chemical misinformation, in other words – might cause colony mates to turn on one another, although no products have yet come to market. In the very long term, the fate of unicolonial societies is unclear. A survey of Madeira’s ants between 2014 and 2021 found, contrary to fears that invasive ants would wipe the island clean of other insects, very few big-headed ants and, remarkably, no Argentine ants. Invasive ants are prone to population crashes for reasons that aren’t understood but may be related to genetic homogeneity: a single colony of Argentine ants in their homeland contains as much genetic diversity as the whole of California’s state-spanning supercolony. As with inbred species everywhere, this may make them prone to disease. Another potential issue is that the ants’ lack of discrimination about whom they help may also favour the evolution of free-riding ‘lazy workers’ in colonies, who selfishly prosper by exploiting their nest mates’ efforts. Though it’s assumed this uneven distribution of work may eventually lead to social breakdown, no examples have been found. Unless natural selection turns against them, one of the most effective curbs on unicolonial ants is other unicolonial ants. In the southeastern United States, red fire ants seem to have prevented the Argentine ant forming a single vast supercolony as it has in California, instead returning the landscape to a patchwork of species. In southern Europe, however, the Argentine ant has had a century longer to establish itself, so, even if the fire ant does gain a European foothold, there’s no guarantee that the same dynamic will play out. In the southern US, red fire ants are themselves now being displaced by the tawny crazy ant (Nylanderia fulva), another South American species, which has immunity to fire ant venom. I t is remarkable how irresistible the language of human warfare and empire can be when trying to describe the global history of ant expansion. Most observers – scientists, journalists, others – seem not to have tried. Human efforts to control ants are regularly described as a war, as is competition between invaders and native ants, and it is easy to see why comparisons are made between the spread of unicolonial ant societies and human colonialism. People have been drawing links between insect and human societies for millennia. But what people see says more about them than about insects. A beehive is organised along similar lines to an ant nest, but human views of bee society tend to be benign and utopian. When it comes to ants, the metaphors often polarise, either towards something like communism or something like fascism – one mid-20th-century US eugenicist even used the impact of the Argentine ant as an argument for immigration control. For the entomologist Neil Tsutsui, who studies unicolonial ants at the University of California, Berkeley, insects are like Rorschach tests. Some people see his research as evidence that we should all get along, while others see the case for racial purity. In addition to conflating a natural ‘is’ with a political ‘ought’, the temptations of ant anthropomorphism can also lead to a limited, and limiting, view of natural history. Surely the habit of worker ants in Argentine nests to kill nine-tenths of their queens every spring – seemingly clearing out the old to make way for the new – is enough to deter parallels between ant societies and human politics? Unicolonial species can overwhelmingly alter ecological diversity when they arrive somewhere new The more I learn, the more I am struck by the ants’ strangeness rather than their similarities with human society. There is another way to be a globalised society – one that is utterly unlike our own. I am not even sure we have the language to convey, for example, a colony’s ability to take bits of information from thousands of tiny brains and turn it into a distributed, constantly updated picture of their world. Even ‘smell’ seems a feeble word to describe the ability of ants’ antennae to read chemicals on the air and on each other. How can we imagine a life where sight goes almost unused and scent forms the primary channel of information, where chemical signals show the way to food, or mobilise a response to threats, or distinguish queens from workers and the living from the dead? As our world turns alien, trying to think like an alien will be a better route to finding the imagination and humility needed to keep up with the changes than looking for ways in which other species are like us. But trying to think like an ant, rather than thinking about how ants are like us, is not to say that I welcome our unicolonial insect underlords. Calamities follow in the wake of globalised ant societies. Most troubling among these is the way that unicolonial species can overwhelmingly alter ecological diversity when they arrive somewhere new. Unicolonial ants can turn a patchwork of colonies created by different ant species into a landscape dominated by a single group. As a result, textured and complex ecological communities become simpler, less diverse and, crucially, less different to each other. This is not just a process; it is an era. The current period in which a relatively small number of super-spreading animals and plants expands across Earth is sometimes called the Homogecene. It’s not a cheering word, presaging an environment that favours the most pestilential animals, plants and microbes. Unicolonial ants contribute to a more homogenous future, but they also speak to life’s ability to escape our grasp, regardless of how we might try to order and exploit the world. And there’s something hopeful about that, for the planet, if not for us. The scale and spread of ant societies is a reminder that humans should not confuse impact with control. We may be able to change our environment, but we’re almost powerless when it comes to manipulating our world exactly how we want. The global society of ants reminds us that we cannot know how other species will respond to our reshaping of the world, only that they will. If you want a parable of ants’ ability to mock human hubris, it’s hard to improve on the story of Biosphere 2. This giant terrarium in the Arizona desert, funded by a billionaire financier in the late 1980s, was intended as a grand experiment and model for long-distance space travel and colonisation. It was designed to be a self-sustaining living system, inhabited by eight people, with no links to the world’s atmosphere, water, soil. Except that, soon after it began operations in 1991, the black crazy ant (Paratrechina longicornis), a unicolonial species originally from southeast Asia, found a way in, reshaped the carefully engineered invertebrate community inside, and turned the place into a honeydew farm. It is possible to be both a scourge and a marvel. Animals and humans Biology Evolution 16 February 2024 SYNDICATE THIS ESSAY Essay Religion Inventing Hindu supremacy Vinayak Savarkar ridiculed Gandhi, preaching that anti-Muslim violence was the only means to unite India into a nation Mihir Dalal Essay Evolution Kinship Science must become attuned to the subtle conversations that pervade all life, from the primordial to the present David Waltner-Toews Essay History of technology Indexing the information age Over a weekend in 1995, a small group gathered in Ohio to unleash the power of the internet by making it navigable Monica Westin Essay Political philosophy Liberal socialism now As the crisis of democracy deepens, we must return to liberalism’s revolutionary and egalitarian roots Matthew McManus Essay Sports and games The moral risks of fandom Players, coaches and team owners sometimes do terrible things. What, if anything, should their fans do about that? Jake Wojtowicz & Alfred Archer Essay Religion There was no Jesus How could a cult leader draw crowds, inspire devotion and die by crucifixion, yet leave no mark in contemporary records? Gavin Evans Essays Ideas Videos About Contact RSS Feed Donate Community Guidelines Follow Aeon © Aeon Media Group Ltd. 2012-2024. Privacy Policy. Terms of Use. Aeon is published by registered charity Aeon Media Group Ltd in association with Aeon America, a 501(c)(3) charity.",
    "commentLink": "https://news.ycombinator.com/item?id=39523495",
    "commentBody": "Ant Geopolitics (aeon.co)255 points by romaintailhurat 20 hours agohidepastfavorite77 comments ryanblakeley 18 hours agoAdrian Tchaikovsky's sci-fi book Children of Time has a pretty cool take on the future of ant wars. I'm interviewing him in a couple weeks to talk about ecology in science fiction. If anyone has a suggestion for a question I'd love to hear it. reply ScotterC 17 hours agoparentRe: Ecology in Scifi The interactions between Ants and Spiders gave me some associations with Butler's Xenogenesis trilogy (aka Lilith's Brood). Particularly, I loved how both were painting an alternative evolutionary path but 'grafting on' to existing notions and understandings of what we know to be true in species development. I wish there was more of this! I felt Children of Ruin was weaker in this regard, maybe because the conflict for the species was absent. The Spiders vs Ants and then Spiders vs Humans being conflicts which created a fanstatic narrative to explain alternative solutions to prisoner's dilemma (spiders choosing to co-opt their enemies' strengths or in Lilith's brood, Oankali being a hybrid of alien/human). I'd be curious to learn if there's more examples in zoology/ecology of species choosing this route instead of competition every time - and also, what factors might impact this. reply ssnri 18 hours agoparentprevI enjoyed that book. After I read it I made my bio on dating apps: “Active, creative, hairy; but enough about Portia spiders.” My question is: how successful do you think that’s been for me as a straight man? reply gryn 18 hours agorootparentDepends on your metric for success I guess. - number of matches ? Probably not. - number of fellow fans ? Probably. reply ryanblakeley 18 hours agorootparentprevIs sexual cannibalism off the table? reply snapcaster 17 hours agorootparentprevIt depends on how physically attractive you are obviously, that variable confounds everything people say about dating apps and what works or doesn't reply ssnri 16 hours agorootparentI go to yoga studios and the instructors hit on me. Still have a mostly shit time with apps. Not zero dates, but going out and doing things in the real world is a much better strategy. Being attractive is probably enough for women, not men though. reply lukan 15 hours agorootparent\"Being attractive is probably enough for women, not men though. \" That is valid only for a certain subset of humanity. reply Jemaclus 16 hours agorootparentprevYou said \"book\" (singular), and I just wanted to let you know it's actually a trilogy, so there are more if you want to read them! reply dmix 13 hours agorootparentprevI'm not sure talking about hairy spiders in your opening sentence will work wonders with women. reply Loughla 13 hours agorootparentIt won't work until it works really well with one specific woman. reply ssnri 12 hours agorootparentprevI guess I’ll have to fall back on my oversized genitals reply tomcam 11 hours agorootparentCan't unsee this reply AlecSchueler 13 hours agorootparentprevI'm not sure women are as homogeneous as you're suggesting. reply grimgrin 17 hours agoparentprevI'll piggyback this sci-fi thread to link the beginning of Phase IV, because I rather like it: https://www.youtube.com/watch?v=vTv4WYHsncQ The plot: \"After a spectacular and mysterious cosmic event, ants of different species undergo rapid evolution, develop a cross-species hive mind, and build seven strange towers with geometrically perfect designs in the Arizona desert.\" reply fritzo 13 hours agoparentprevQuestion for Adrian: All your sentient beings are animal-like: they are discrete animals that move around, or at weirdest are a ruinous sludge that moves around and assumes the form of animals. But might we see mycelium networks as sentient? Zoubin Ghahramani argues that intelligence is about motion, that the sea squirt digests its own brain as soon as it settles down. But might there be intelligent communities of static individuals that nevertheless form dynamic networks? reply SeanAnderson 17 hours agoparentprevLove this book! I wrote Adrian after reading it and asked for permission to build a game inspired by it and received his blessing (https://i.imgur.com/JWwNMR4.png) :) (slight spoilers, FYI) https://ant.care/ https://github.com/MeoMix/symbiants It's my first game, so it's going pretty slowly, but the goal is to have the player fill the role of the Eliza/Kern hybrid. You send commands to your pet ant colony once-per-day when orbiting the planet gives you line-of-sight. The act of caring for the pet gives you a renewed sense of purpose and a reason to care for yourself and is a mechanism for helping undue the insanity and create personal growth. I'm still trying to figure out exactly what the game mechanics will look like (if you have suggestions, I'm all ears!), but I took a stab at some creative writing to build up the plot a bit. It feels very Children of Time-y and some might enjoy reading bits of it: Half-Assed Technical Document: https://docs.google.com/document/d/17ACH1XLCn7hkKz2dhuL1c_nx... Freeform Creative Writing of Scripted Game Intro: https://docs.google.com/document/d/1wET9mWaYae_GMqbm8n37UoNF... --- Regarding the interview, I would love to know more about his process for deciding which aspects of an animal's ecology/behavior to represent in his fiction. Tynan Sylvester (creator of RimWorld, a popular video game) wrote this article called The Simulation Dream, https://www.gamedeveloper.com/design/the-simulation-dream, and I think about it a lottt. One concept Tynan stresses for creating a rich and engaging simulation is to \"Choose the minimum representation that supports the kinds of stories you want to generate.\" I would love to know why Adrian chose to give ants/spiders/(octopi..) the behaviors they have throughout his series and, if he considered other behaviors that he ultimately omitted, what his thought process was for ruling those other behaviors out. reply vagrantJin 13 hours agorootparentI love Adrian's work. Take my money. reply BlueTemplar 7 hours agorootparentprevThanks, this has put in perspective my frustrations with RimWorld simulation being a bit skin-deep... also how that frustrating rotting plants issue that you get zero advanced warning for might have made it into RimWorld ! Also : https://ludeon.com/forums/index.php?topic=57492.msg497822#ms... reply photochemsyn 17 hours agorootparentprevGreat idea. Leaf-cutter ants have something like five worker castes (soldier, excavator, forager, garbage collector, gardener) so managing that distribution might be a fun part of a game (tending towards Ant Factorio). e.g. https://youtu.be/VLBDVXLiWxQ?t=301 reply renjimen 8 hours agoparentprevOlaf Stapledon has two sci fi works that incorporate many ecological ideas into his vision of a future history of the human species (Last and First Men) and his ideas for possible alien life (Star Maker). They are both incredible works of human imagination reply bebopfunk 14 hours agoparentprevIf you’re interested in ecology in science fiction you should give Kill Decision by Daniel Suarez a read. It’s not about ants specifically, but they play a large roll in a way (I don’t want to spoil too much and it’s been long enough since I read it I can’t remember what’s a spoiler or not). It’s a good read. reply abrookewood 6 hours agoparentprevCan you please let everyone know where this interview will be available? reply romaintailhurat 16 hours agoparentprevLove all the scifi recommendations in this thread! reply zabzonk 17 hours agoparentprevnot to mention ant-based computers hosting super-human level AIs, which seems highly unlikely. but it did work for terry pratchet. reply wonderwonder 14 hours agoparentprevI really liked Children of Time and Ruin. I could not get through Children of memory and its very rare for me to abandon a book. It just seemed very different than the prior ones for me. Maybe I will give it another shot. With that said I loved his Final Architecture series and just finished the final book in it. reply ssnri 17 hours agoparentprevnext [3 more] [flagged] whichfawkes 17 hours agorootparentIt's totally solved, first class is just too expensive for most people. The future is not evenly distributed. reply lynguist 16 hours agorootparentWhy not bunk beds like in a sleeper car? They don’t take up more space, and let you have a good night’s rest. reply mullingitover 16 hours agoprevI can't believe this article doesn't mention the slave maker ants. They're fascinating. These ants live in colonies so small they fit inside an acorn. They raid other acorn ant colonies, kill adult ants indiscriminately, and abscond with their pupae. They then raise the pupae in their colony. The enslaved ants feed and care for their captors and their young, and even help their captors on future slave raids. However, the enslaved ants opportunistically kill the queen pupae of the slave maker ants. It's an ongoing evolutionary arms race. There are other socially parasitic ants in this vein: some will infiltrate a colony, kill only the queen without the colony realizing it, and lay their own eggs which are raised by the slowly replace the entire colony. There are also 'cuckoo' ants which simply sneak into the colony, lay their eggs and leave. reply permo-w 14 hours agoparent>However, the enslaved ants opportunistically kill the queen pupae of the slave maker ants. I'm guessing by this you mean the species of ants that tend to be enslaved, rather than the enslaved ants themselves? reply mullingitover 13 hours agorootparentThe enslaved ants which grew up in the slave maker ant colony kill the slave maker ant queens (along with other pupae, but they kill the queens at higher rates) in their pupal stage. They're basically in rebellion. Researchers think that this behavior is selected for, as it reduces the effectiveness of the slave maker ants and increases the odds of survival of the enslaved ant species. reply permo-w 10 hours agorootparentit could make a pretty cool film. baby taken as a child turns on his captors and destroys their queen. reply kibwen 5 hours agorootparentA tale as old as time. Literally, this is the story of Moses. reply octagons 18 hours agoprevIf you found this story interesting, you may be interested to know that antkeeping is a rewarding and fairly inexpensive hobby. The Global Ant Nursery (GAN) project run by AntsCanada, a popular YouTube channel, is a great way to obtain new queens responsibly. Alternatively, it’s fairly easy to find queens on your own. AntsCanada offers a starter guide, and there are many other resources that teach you when and where to find new queens. I keep a few test tubes in my truck year-round, just in case. Note: I’m not affiliated with AntsCanada in any way. reply ses1984 17 hours agoparentAntsCanada is a great gateway into antkeeping but I would beware about the GAN. I connected with someone listed on the GAN in my state. As I was working out the purchase and delivery, there were a lot of red flags, which I ignored because I trusted AntsCanada. The person said that they already gave away the species I wanted, but maybe I would be interested in other species instead. They pushed a species which isn't really known to native to my area, but he insisted he found them locally. They aggressively tried to upsell me on expensive extra supplies they said were critical to the care of this species. When I got my ants, they were shipped from several states away. I reported this to AntsCanada. I'm not sure what happened, but I recently tried to get a different queen from GAN and I ended up talking to the same person under a different identity. I'm sure there are some great people on GAN, just beware. I ended up getting a queen from Atlantic Ants. It did ship across state lines, but the species is one that's ubiquitous in my region. reply octagons 12 hours agorootparentI’ve also experienced this using GAN. Be wary and use common sense. I never bothered reporting it but I’d be willing to bet we’re talking about the same person. They listed the same advertisement in basically every state with a different Google Voice number so as to appear local. I was under the impression that we would be meeting because they were local, which is how GAN is intended to operate.?Instead, they shipped the queen to me without any USDA permits. The queen also died within a few weeks of arriving. They started a web store not longer afterwards. That said, I’ve had plenty of good experiences with GAN. This was one bad actor out of many good ones. reply throw310822 7 hours agorootparentSo there is someone that is running a shady operation selling ants? > They started a web store not longer afterwards. At this point I'm not sure if it's a store online or one that sells spider-related stuff. reply UniverseHacker 12 hours agoparentprevIt's truly easy and inexpensive to get into- all I had to do was forget to do the dishes one night! ....my apologies, I don't mean to ridicule your hobby, it's just I couldn't imagine wanting more of them in my house on purpose. reply xipho 18 hours agoprevDisclaimer- shameless plug involved. Humans are one species, a complicated on for sure, Ants are well over 15k species. Of course not all are found together, but many species are. As the article notes the diversity of their social structures is collectively nuts. The combinatorics of all these species interacting with a myriad of micro-habitats and resultant behaviors emerging is crazy. The sheer number of non-ant species that have evolved to look and behave exactly like ants, from being drug-pushers to parasitoids, to meme-ready social influencers says a lot about how long they've been around and how important they are to how natural systems work. We're happy that AntWeb (https://www.antweb.org/) recently moved their data to TaxonWorks and are now building that site of data curated there. Data for over 250k individuals, with many more coming as we work to aggregate data are there. Check out a wealth of data and images there. reply hammock 18 hours agoparent> The sheer number of non-ant species that have evolved to look and behave exactly like ants, from being drug-pushers to parasitoids, to meme-ready social influencers says a lot about how long they've been around and how important they are to how natural systems work. Fascinating to me, and thank you for calling it out. Ants aren't the only \"form\" that this happens to in the animal kingdom either. Homo sapiens used to live alongside other similar species like neanderthals etc, and eventually we crowded them all out. Often we tell ourselves it's because we were superior to them. Many have wondered what society would be like if we still had close species cousins living among us. Certainly our own approach to geopolitics would be quite different to what it is today reply graemep 1 hour agorootparent> Many have wondered what society would be like if we still had close species cousins living among us. Certainly our own approach to geopolitics would be quite different to what it is today It would not be great. If you consider the track record human being have of being horrible to those who look very slightly different or have a slightly different culture, how would we treat beings who were far more different? It would be even worse if they were are mental inferiors. Imagine a world in which scientific racism was proven true rather than debunked. They would be perfect slaves or research subjects. reply digging 16 hours agoparentprevHow exciting. I'm a huge fan of ants and I didn't know about AntWeb. Insects tend to be harder to find identification resources for than spiders, which is what I spend more time on. However, this site seems to exceed any individual digital resource I know of for spiders. RIP to SpiderID.org, which hasn't had moderation in years and now has ads. How would I get started creating a new community-driven hub for spider identification in the vein of AntWeb? I'm not associated with any research organizations but maybe I should be. reply xipho 15 hours agorootparentI would first engage, if you haven't, the spider community at iNaturalist. It is likely that others are thinking along the same lines as you. We (Species File Group) are trying to build out open-source tools (e.g. TaxonPages, 'distinguish') that would ultimately help to make these types of projects possible, through GitHub pages or other similar approaches. If you wish, we have multiple ways to be reached, see 'Events' after doing a little sleuthing as to who we are. We are definitely interested in facilitating the structuring of communities that link people like you to those doing the science behind the scenes, this is really important for the long term stability of resources like those you're interested in. reply octagons 18 hours agoparentprevI am an avid ant hobbyist and use AntWeb regularly to aid in identification and distribution of ant species when hunting for new queens. I’m glad to hear about this change - the site had needed a bit of a refresh for a while! reply xipho 16 hours agorootparentAt present it's just the data being dumped from TaxonWorks and re-integrated into the existing front-end (separation of concerns nicely done). In the future we hope efforts that wrap TaxonWorks APIs and tooling, \"companions\", will evolve to make things look better. For example it would be trivial to wrap AntWeb in TaxonPages (see Github for everything) to get a new front end there, though that software is focused at the Taxon level. Multiple groups are looking to build out similar efforts at the specimen level (perhaps SpecimenPages). We've recently has some amazing success with previously \"unknown\" people contributing to our open-source framework(s). These contributions, and hopefully future ones, will let us deliver additional features in a more timely fashion, for example things like multi-entry and \"traditional\" taxonomic keys. TLDR - there are opportunities to chip in to the \"refresh\" efforts on multiple fronts. reply octagons 12 hours agorootparentI’d love to discuss contributing further. Do you have a link to a GitHub repository or organization? reply xipho 7 hours agorootparenthttps://speciesfilegroup.org and https://github.com/SpeciesFileGroup, among others. reply derekja 16 hours agoprevI've been really enjoying the AntsCanada youtube channel lately. He stages ant wars in a controlled environment and films them really well. https://www.youtube.com/channel/UCONd1SNf3_QqjzjCVsURNuA reply permo-w 10 hours agoparentit's such an interesting subject matter, presented visually in a really nice way, but his script-writing is so jarring to listen to, and it feels like half the time he doesn't even really comprehend the words that he's reading out. perhaps it's just me though; he's got a lot of subs reply nickthegreek 13 hours agoparentprevFound AntsCanada a few weeks back when his new build blew up on youtube. Its now a Sunday morning staple for my partner and I. reply make3 16 hours agoprevI think it's fascinating that, according to Wikipedia, Argentine ant colonies attack one another in their native range because of the increased genetic diversity (which they detect by smell). The mega colonies would only be a consequence of the inbreeding that follows rapid expansion. reply tsunamifury 18 hours agoprevThis article seems to be continuing the “genes eye view” of the world. That we are mostly vessels for gene propagation and socialization. Ants are becoming superior gene propagation and socialization vessels and therefor may succeed in reframing the worlds ecosystem to their goals. Of course that discounts intelligence where in we as humans could probably roundly poison them into extinction if we wanted. reply gryn 18 hours agoparentThe problem with that is that humans depends on the ecosystem making them extinct would probably have very long chain of negative effects that would poison us in return if not make us extinct too. reply bee_rider 15 hours agorootparentAlso, lots of our systems depend on people evaluating incentives locally and picking their behavior based on their interests—humans that all decided to pointlessly try and wipe our ants wouldn’t be engaging in normal human behavior! Are we going to give the ants supernatural coordination as well? reply ta2112 17 hours agoparentprev> Of course that discounts intelligence where in we as humans could probably roundly poison them into extinction if we wanted. What is that, irony?! reply larsiusprime 17 hours agoparentprevI'm not convinced we could drive ants to extinction even if we tried. reply HelloMcFly 13 hours agorootparentI think we could, but I believe it would be the most quintessential (and likely final) Pyrrhic victory humanity has ever known. reply kibwen 18 hours agoparentprev> we as humans could probably roundly poison them into extinction if we wanted We probably could extinct all the ants in the world if we wanted to, if we were content to extinct all other life on the planet as well. https://xkcd.com/1217/ reply mistermann 14 hours agoparentprevOur relative intelligence seems insufficient to overcome our default behavior as vessels for the unthinking propagation of memes though, which has resulted in serious harm to the ecosystem of a variety of species, including us! reply TheCaptain4815 17 hours agoprevAfter reading the article, I really want a bug/ant RTS game. reply TapamN 9 hours agoparenthttps://en.wikipedia.org/wiki/Microsoft_Ants reply hyperman1 16 hours agoparentprevThere used to be SimAnt. The game worked great when you simply let it run itself without actually playing it. https://en.m.wikipedia.org/wiki/SimAnt reply __MatrixMan__ 15 hours agorootparentI'd play the heck out of an updated version that taught you more about ants while you played it. reply BlueTemplar 12 hours agorootparentNot sure about the teaching, but there's Empires of the Undergrowth and soon Empire of the Ants ? reply binarymax 16 hours agoparentprevZerg vs Protoss is pretty close, but we need something new! reply m3kw9 14 hours agoprevAnd then we have social media for Ants reply FrustratedMonky 17 hours agoprevAsking because it isn't spelled out in HN Guidelines. What are the actual automated rules for posting 'dupe' stories? This is a dupe from 10 days ago. https://news.ycombinator.com/item?id=39400770 When I submit something that is a dupe, it gets labeled as dupe and not posted. But this post was dupe and did get posted. What are the automated rules? reply romaintailhurat 16 hours agoparentWeird because the app i used for posting this story usually points me to a dupe when there is one, i'm not sure if it's part of the HN API and why this mechanism has not worked as intended. reply FrustratedMonky 14 hours agorootparentah. thank you. that might explain it. I'll try the app next time, maybe that bypasses some check. Or better, next time I submit, I'll use website regularly, and if it flags as dupe, I can switch to app and see if it bypasses the check. reply pegasus 17 hours agoparentprevThere's a somewhat recent post by dang saying that (if I remember correctly) moderators sometimes manually look over rejected posts and give them a second chance if they feel it's worth a shot. reply Obscurity4340 14 hours agoprevWhat's this, an geopolitics article for ANTS? reply richrichie 19 hours agoprevnext [5 more] [flagged] ketanmaheshwari 19 hours agoparentThey hold 12 megatons of dry carbon. Kinda opposite of climate change! reply thworp 19 hours agorootparentPeople hold about 100 Megatons of dry carbon unless I made some fundamental error (9 billion * 65 kg * 0.185 [18.5% carbon by mass]). It's actually a bit amazing when one calculates figures like this. reply Etheryte 19 hours ago [flagged]parentprevnext [2 more] Just wait until this guy hears about bacteria. reply richrichie 18 hours agorootparentMost of them live inside human gut and are already accounted for. reply ysofunny 16 hours agoprev [–] if ants were mammals they would be humans equivalently if humans were insects we would be ants reply kevinwang 16 hours agoparent [–] Well we're social but we're not really eusocial like they are reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The essay delves into the global society established by ants in the last four centuries, drawing parallels to human civilizations in terms of growth and expansion.",
      "It examines the distinctive societal structure of ants and the disruptive presence of species such as the Argentine ant and red fire ants, emphasizing their impact on ecosystems and the challenges they present to humans.",
      "Efforts to manage invasive ants and the repercussions of human intervention on species diversity are addressed, showcasing the intricate abilities of ant colonies that set them apart from human societies."
    ],
    "commentSummary": [
      "The discussion on Aeon.co delves into \"Children of Time\" by Adrian Tchaikovsky, exploring alternative evolutionary paths and species conflicts.",
      "Anecdotes range from dating app bios to the concept of sentient beings resembling animals, as well as ants and spiders' role in creative writing.",
      "Topics such as slave maker ants, antkeeping as a hobby, and the repercussions of human interventions in ant communities are discussed alongside ant identification, gene propagation, and human impact on ant populations, with additional debates on duplicate posts, carbon stored by humans, and human-ant comparisons."
    ],
    "points": 255,
    "commentCount": 77,
    "retryCount": 0,
    "time": 1709038663
  },
  {
    "id": 39522798,
    "title": "Global Rainwater Unsafe to Drink Due to PFAS Chemicals",
    "originLink": "https://phys.org/news/2022-08-rainwater-unsafe-due-chemicals.html",
    "originBody": "August 10, 2022 Rainwater unsafe to drink due to chemicals: study Credit: Pixabay/CC0 Public Domain Rainwater everywhere on the planet is unsafe to drink due to levels of toxic chemicals known as PFAS that exceed the latest guidelines, according to a new study by Stockholm University scientists. Commonly known as 'forever chemicals' because they disintegrate extremely slowly, PFAS (per- and polyfluoroalkyl substances) were initially found in packaging, shampoo or makeup but have spread to our entire environment, including water and air. \"There is nowhere on Earth where the rain would be safe to drink, according to the measurements that we have taken,\" Ian Cousins, a professor at the university and the lead author of the study published in Environmental Science and Technology, told AFP. A compilation of the data since 2010 that his team studied showed that \"even in Antarctica or the Tibetan plateau, the levels in the rainwater are above the drinking water guidelines that the US EPA (Environmental Protection Agency) proposed\", he said. Normally considered pristine, the two regions still have PFAS levels \"14 times higher\" than the US drinking water guidelines. The EPA recently lowered its PFAS guidelines significantly after discovering that the chemicals may affect the immune response in children to vaccines, Cousins noted. Once ingested, PFAS accumulate in the body. According to some studies, exposure can also lead to problems with fertility, developmental delays in children, increased risks of obesity or certain cancers (prostate, kidney and testicular), an increase in cholesterol levels. —Planet 'irreversibly contaminated'— Cousins said PFAS were now \"so persistent\" and ubiquitous that they will never disappear from the planet. \"We have made the planet inhospitable to human life by irreversibly contaminating it now so that nothing is clean anymore. And to the point that's it's not clean enough to be safe\", he said. \"We have crossed a planetary boundary\", he said, referring to a central paradigm for evaluating Earth's capacity to absorb the impact of human activity. However, Cousins noted that PFAS levels in people have actually dropped \"quite significantly in the last 20 years\" and \"ambient levels (of PFAS in the environment) have been the same for the past 20 years\". \"What's changed is the guidelines. They've gone down millions of times since the early 2000s, because we've learned more about the toxicity of these substances.\" Cousins said we have to learn to live with it. \"I'm not super concerned about the everyday exposure in mountain or stream water or in the food. We can't escape it... we're just going to have to live with it.\" \"But it's not a great situation to be in, where we've contaminated the environment to the point where background exposure is not really safe.\" More information: Per- and polyfluoroalkyl substances (PFAS) define a new planetary boundary for novel entities that has been exceeded, Environmental Science & Technology (2022). DOI: 10.1021/acs.est.2c02765 Journal information: Environmental Science and Technology , Environmental Science & Technology © 2022 AFP Citation: Rainwater unsafe to drink due to chemicals: study (2022, August 10) retrieved 28 February 2024 from https://phys.org/news/2022-08-rainwater-unsafe-due-chemicals.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
    "commentLink": "https://news.ycombinator.com/item?id=39522798",
    "commentBody": "Rainwater everywhere on the planet is unsafe to drink due to chemicals (2022) (phys.org)239 points by Brajeshwar 22 hours agohidepastfavorite181 comments nostrademons 21 hours ago> However, Cousins noted that PFAS levels in people have actually dropped \"quite significantly in the last 20 years\" and \"ambient levels (of PFAS in the environment) have been the same for the past 20 years\". > \"What's changed is the guidelines. They've gone down millions of times since the early 2000s, because we've learned more about the toxicity of these substances.\" I think what's changed most is our standards. Used to be if you survived to reproduce, you were doing pretty good. Extra points if you got to watch your kids grow up. Now the standard is basically \"Every substance that can be demonstrated to have worse health outcomes than its absence is toxic\" - which on a technical level is true, and might even be what you care about, but you also need take a bigger-picture perspective and weigh it against all the other risks of ordinary living you face. reply tomxor 21 hours agoparent> I think what's changed most is our standards. PFAS didn't exist 75 years ago. Now we've almost permanently contaminated our environment and atmosphere with it, that's quite a big change. reply pookha 20 hours agorootparentI'll go out on a limb and say that 99% of the people buying \"Glide\" dental floss at COSTCO have NO IDEA that they're coated in toxins (PFAS) and if they pick up a gargantium bag of Cheerios for their kids they also probably aren't aware that those too are coated in Chlormequat chloride. Modern living. reply sva_ 19 hours agorootparent> I'll go out on a limb and say that 99% of the people buying \"Glide\" dental floss at COSTCO have NO IDEA that they're coated in toxins (PFAS) Thanks for making me aware of this. I've been trying to make a point of avoiding PFAS, but it seems to be everywhere. > The study found that women who flossed with Oral-B Glide floss had higher levels of a chemical called perfluorohexane sulfonic acid (PFHxS) in their blood than women who didn’t use that type of floss. https://www.hsph.harvard.edu/news/hsph-in-the-news/dental-fl... reply Workaccount2 19 hours agorootparentI've been in the same camp, mostly against BPA (and it's analogs) and PFAS. It's amazing how casually they are used in consumer products, even by brands who carry marketing that is nauseatingly \"save-the-earth-happy-healthy-eating\". Another one is nitrites in processed meat. All the fancy \"health conscious\" brands proudly state \"NO NITRITES!\", but then those ass hats put in a bunch of celery salt...which is just nitrites with a different name. Note: For anyone curious, trader joes actually does sell a bacon with no nitrites of any form. First and only time I have seen it. reply japanuspus 18 hours agorootparentComparing nitrites (which occur naturally) with PFAS and other \"forever chemicals\" is off the board. To my understanding the observed and very real ill-effects of toxic bacterial excretions due to nitrites being phased out in lunch-box products (sliced ham, salami) here in the EU far outweigh any possible effects of the nitrites. Source: reddit comments that seemed legit. reply TeMPOraL 18 hours agorootparentprev> All the fancy \"health conscious\" brands proudly state \"NO NITRITES!\", but then those ass hats put in a bunch of celery salt...which is just nitrites with a different name. Marketing that takes into accounts biases of particular target group. That particular case is, I think, becoming common: since large fraction of the population is irrationally afraid of anything that has numbers in its name, whether as digits or words in any language, the companies look for whatever plant they can pull that specific substance from, and use that in production process - possibly compromising quality and efficiency, but allowing them to write ${good natural plant} in the ingredient list instead of evil E-number or satanic 6-6-hexa-whatever. I'm conflicted about this practice. On the one hand, I hate pulling wool over other people's eyes; on the other hand, I also hate reflexive fear and anti-intellectualism of our society. reply BizarroLand 16 hours agorootparentprevI would hazard to say that PFAs and microplastics are safer than lead and mercury but less safe than not having them at all, but only with the caveat that I believe there's got to be some sort of Zeno's Paradox correlation with environmental human health and safety. To wit: People used to do all sorts of self-harming things not knowing any better and now we do fewer of them. The Romans used to sweeten their wines with powdered lead. The ancient Chinese alchemists used to make elixirs of immortality out of mercury compounds and feed them to their wealthy. I'm not saying things are good now and that we shouldn't push for them to be better, not by any means. Rather I am saying that as we take further steps towards optimal human health, aligning our common environmental encounters with our biology, we should remember that the effort people have put in to get us this far is only going to take us half as far the next time, and half again the time after. And that is all well and good, progress is progress, right? However, does it not seem like the smaller the flaw we find the more we get upset about it? I believe this phenomenon is caused by a continuing delusion that we were once ever perfect, that we ever lived in harmony with nature, that there is some paradisian SI Garden of Eden unit we can measure our present environment against, and that the current state of events is the face of our fall from grace and must be destroyed like the monster it is. I believe the truth is things have never been better in hundreds of ways, and they're going to keep getting better as we repent of our past mistakes and learn more about what mistakes we are still currently making, and that the world 25 years from now will be as different a world as the world of today is to the world of 1999. reply jddj 14 hours agorootparentThe secret, and it is a secret, is to understand everything that you've just written, and quietly let the machine worry on. That collective handwringing (set in eternal struggle as it is with financial greed) is what got us here, and it's what will get us the next 50% and the 50% after that. Wink and enjoy the ride. reply salawat 4 hours agorootparent...I'd like to think that we can do a bit better than that. The world could have done without things like Tetra-Ethyl-Lead, Thalidomide, and all the other fd things we've ended up with as a result of just letting the machine whirr on. We need to recognize that perverse incentives exist, the system is vulnerable to them, and as our technical prowess increases, the consequences of even one lapse are becoming larger and broader in scale beyond, in some cases, our ability to handle it by just winging it, and not* applying some level of precautionary principle. reply cyounkins 6 hours agorootparentprevI tried a few PFAS-free dental flosses that were horrible. I settled on Reach Waxed - https://www.amazon.com/gp/product/B005IHMXEQ reply stronglikedan 17 hours agorootparentprevJ&J Reach floss is pfas-free, very cheap, and a pleasure to use. reply wodenokoto 20 hours agorootparentprev> Cheerios for their kids they also probably aren't aware that those too are coated in Chlormequat chloride. From Wikipedia: > Chlormequat has not previously been registered for use on food crops in the United States. In April 2023, the U.S. Environmental Protection Agency proposed allowing the use of the chemical on food crops such as barley, oat, triticale, and wheat. The EPA’s human health risk assessment indicated \"no dietary, residential, or aggregate (i.e., combined dietary and residential exposures) risks of concern.\" No risks were identified by EPA to aquatic species of invertebrates, vertebrates, and plants in addition to terrestrial plants. So probably not coated in it. reply 34679 19 hours agorootparentThey're probably referring to the following study: https://www.nature.com/articles/s41370-024-00643-4 \"Chlormequat was detected at low concentrations in samples from 2017 through 2022, with a significant increase in concentrations for samples from 2023. We also observed high detection frequencies of chlormequat in oat-based foods. These findings and chlormequat toxicity data raise concerns about current exposure levels, and warrant more expansive toxicity testing, food monitoring, and epidemiological studies to assess health effects of chlormequat exposures in humans.\" ... \"Despite being approved for use on crops in Europe and parts of North America, chlormequat exhibits concerning toxicological properties, as documented in historical as well as more recently published laboratory animal studies. In the early 1980s, the impacts of chlormequat exposure on reproductive toxicity and fertility were first described by Danish pig farmers who observed reproductive declines in pigs raised on chlormequat treated grains [4]. These observations were later investigated in controlled laboratory experiments on pigs and mice, whereby female pigs fed chlormequat treated grain exhibited disrupted oestrus cycling and difficulty mating compared to animals on a control chlormequat-free diet [4]. Additionally, male mice exposed to chlormequat via diet or drinking water during development exhibited decreased fertilization capacity of sperm in vitro [5]. More recent reproductive toxicity studies on chlormequat show delayed onset of puberty, reduced sperm motility, decreased weights of male reproductive organs, and decreased testosterone levels in rats exposed during sensitive windows of development, including during pregnancy and early life [6,7,8]. Developmental toxicity studies also suggest that chlormequat exposure during pregnancy can dysregulate fetal growth and metabolism [9]. Other investigations did not find impacts of chlormequat on reproduction in female mice, male pigs, or a subsequent investigation of fertilization capacity in male mice developmentally and postnatally exposed to chlormequat [4, 10, 11]. Equivocal evidence in the toxicological literature on chlormequat may be due to differences in doses tested and outcomes measured as well as selection of model organism and the sex of laboratory animals. Consequently, further investigation is warranted.\" reply brandon272 19 hours agorootparentprevAre the Cheerios slathered in Chlormequat? reply germinalphrase 19 hours agorootparentThat phrasing suggests that Cheerios are intentionally coated with Chlormequat which doesn't appear to be the case. Instead, tthe grains used to manufacture Cheerios are treated with Chlormequat (though, arguably, any food product utilizing those grains would have the same issue, I'd assume). Might not make anyone feel any better, but different issue. reply bassrattle 15 hours agorootparentpotato potato, literally the same thing reply demondemidi 19 hours agorootparentprevI don’t know about you but that doesn’t make me feel any better. reply doo_daa 17 hours agorootparentThis might make you feel better... https://sciencebasedmedicine.org/pesticide-in-oat-products-s... ... unless you regularly eat more than 85,000 tons of oats. reply demondemidi 7 hours agorootparent> unless you regularly eat more than 85,000 tons of oats. Between muesli in the summer and oatmeal in the winter I'm averaging close to that, but I exercise a lot so I got that going for me. reply fnordpiglet 17 hours agorootparentprevExcept this isn’t true. It’s made of PTFE, which hasn’t been made with a PFA process in 15 years and is itself one of the most non reactive substances known unless you heat it to very high temperatures. reply estiaan 17 hours agorootparentIt’s not clear which part of the comment you meant when you said it’s not true, but PTFE is a PFAS, exactly how toxic it is or isn’t I don’t think is well known yet but people have been living with PTFE implants. reply fnordpiglet 17 hours agorootparentThe toxicity of Glide. PFAS is a very broad class of chemicals. The toxic PFAS associated with PTFEs are PFOA and PFOS, both of which were phased out in production in the 2010s. Whenever this topic of Glide being toxic comes up they cite this article : https://www.hsph.harvard.edu/news/hsph-in-the-news/dental-fl... Which is written based off this study: https://www.nature.com/articles/s41370-018-0109-y Which is based off blood samples drawn in 2010-2013, which is at the time PFOA was being phased out of the PTFE production process due to lawsuits around the PFOA toxicity, which DuPont was aware of. The new process using GenX (seriously), which is known to cause problems too but at a lesser extreme than PFOA. However the issue with PTFE was with the residuals of PFOA which you don’t find in commercial PTFE for GenX. And yes, PTFE is widely used in medical implants and devices. reply thriftwy 17 hours agorootparentprevNon-reactive usually implies forever chemical. reply fnordpiglet 17 hours agorootparentThe entire right side of the periodic table is composed exclusively of forever chemicals by this definition. Non-reactive also means doesn’t interact chemically with other chemicals, which is a desirable thing in a plastic that might be ingested. While maybe not awesome that it sits in silt not reacting to the end of time, if it also doesn’t react with anything in your body, it’s safe to take into your body, no? The problem with some PFAS is they don’t readily degrade but they’re biologically reactive and interact with the bodies chemistry. That’s not a great feature. But it’s a huge class of chemicals, all of which are chemicals stable due to their carbon fluorine bonds - one of the most stable bonds in nature. But that doesn’t mean they can’t react in ways that don’t break the molecule apart, or form other chemicals that maintain the integrity of the C-F bond. But it also doesn’t mean that they DO react. Life isn’t so simple it can be reduced to a mantra like “plastic bad” or whatever. PTFE has a lot of very useful characteristics, and its lack of reactivity in the body isn’t the least of them. reply kgc 5 hours agorootparentIf it doesn’t react with anything in your body, how would your body clear an accumulation of it? reply aqfamnzc 17 hours agorootparentprevHow am I supposed to keep track of things like this? Between all the chemicals, boycotts, etc etc etc I don't know how I'm supposed to use any modern product again. (Or primitive product, for that matter.) It's honestly driven me to apathy. I just don't have the bandwidth to worry about it. reply 7thaccount 17 hours agorootparentMake all your own food. Even then, the crops are all loaded with Roundup and who knows what all else. reply nickd2001 17 hours agorootparentA high-fibre diet is supposed to help, as fibre can absorb toxins. To what extent I don't know. So, make your own sourdough wholewheat bread. And eat plenty of greens like broccoli, cabbage . I guess the greens are sprayed with stuff too though. As is the wheat in the bread. The fibre might counteract the effects of the sprays somewhat. reply infecto 16 hours agorootparentGreens I believe absorb more heavy metals. reply Arrath 10 hours agorootparentprevHaven't some studies found that donating plasma helps scrub your blood? reply toomim 16 hours agorootparentprevI just take some sheets of aluminum foil, fold them into a hat, and then jump inside and hide from the world. reply nipponese 17 hours agorootparentprevDon’t forget about all the dihydrogen monoxide in everything these days. /s reply tmaly 16 hours agorootparentprevCan you recommend a brand of floss that is not coated in toxins? reply stephenbez 13 hours agorootparentI like Radius Sponge Floss and switched to it after I heard about the issues with Glide. reply hn_throwaway_99 20 hours agorootparentprevI feel like that's taking the commenter's quote out of context, or at least missing the point. They aren't arguing that PFAS aren't everywhere, or even that they aren't harmful. They're arguing that, in the grand scheme of things, the harm produced by PFAS to humans is relatively inconsequential, especially when you consider all the improvements that technology, broadly, has brought to the human condition. To emphasize, I think that point is very debatable, but I don't know enough about the real harms of PFAS to comment. But I do think it's valid to have a substantive debate on the true harms of PFAS, even if the other side of that debate is that comparing ourselves now to a time when the majority of kids died is the wrong yardstick. reply nostrademons 20 hours agorootparentI went and did some research, and have a friend who's a material scientist. The harms of PFAS are pretty substantial. Teflon is nasty; if you can do without it in your cookware, you probably should. However, statistically the things that are most likely to prevent you from passing on your genes are: 1. Not making enough money. 2. Anxiety/depression 3. Drug overdoses 4. Car accidents 5. An unhappy family life 6. Swimming pools And on that list of offspring averted, PFAS basically don't register. You are much better off making sure you get into a good career, talking to your kids about drugs, being very careful when you drive, and otherwise not sweating the small things than obsessing about forever-chemicals in the atmosphere. reply nonrandomstring 19 hours agorootparentWhat is remarkable here is that every single thing you say is correct. Everything on your statistical list looks right, and can probably be proven by a stack of peer-reviewed scientific studies from medicine, sociology, psychology... And yet as an argument, it's worthless. Worse... it's dangerous. Because in your schema, the impact of climate change, pollution and other threats that will end this species each rank as zero! You get to \"pass on your genes\" merely to consign a few hundred of your descendents to a miserable death. This is the tyranny of instrumental reason that you so cleverly use against the goal (reproduction of genes) that you purport to champion. reply PeterisP 19 hours agorootparentWait, neither climate change nor pollution are in the category of threats that are expected to literally end this species. reply cj 19 hours agorootparentWithin our lifetime we’re safe. I think the point is 100-300 years (maybe longer?) from now things might reach a tipping point. reply scarby2 17 hours agorootparentNone of the above are actually expected to end the species. Not in anyone's lifetime, given the range of climates humans survive in. We might end up with a 90% reduction in population but Short of a massive asteroid impact or massive solar event it's pretty hard to imagine wiping out the entirety of humanity. reply nonrandomstring 16 hours agorootparent> it's pretty hard to imagine wiping out the entirety of humanity. That's kinda my complaint here. Imagination is more important than knowledge. If we started much earlier in education explaining to kids how remarkable and fragile our existence is, how intricately interconnected we are with nature, birds, bees, mushrooms and microbes, then maybe Hollywood disaster movie plots wouldn't seem like the only route to the end of humanity. reply cj 17 hours agorootparentprevI agree. But anything causing even a 10% population decline over a short period of time would have insane second order effects (e.g. nuclear war) as we fight over control of resources. reply jay_kyburz 8 hours agorootparentprevWith only 10% of the population, we might find so much institutional knowledge lost that the remaining just can't feed themselves. We'd have to relearn hunting and gathering, and that just might not happen. reply jl6 19 hours agorootparentprevArguably climate change risk comes under #1 (not making enough money), because in the most likely climate change scenario, people above a certain wealth threshold will probably survive. Not saying this will be a pleasant experience. Billions may starve. But that still leaves billions, and the purely mercenary reality is that money is what puts you on one side of that dividing line or the other. reply nonrandomstring 18 hours agorootparentFrom a certain perspective maybe. But I think that would be one coloured by a narrow mentality [0] In a \"purely mercenary reality\", what you need to survive is not wealth, but peace, and that is something you cannot buy with many of the futures we're now looking at. In a funny way, PFAS is a great metaphor. Forever chemicals have now been found in places nobody would ever have predicted. Bad things have a way of spreading in ways you won't see until they're at the gate. It might not be a good idea to bet the farm on isolationism and exceptionalism. [0] https://en.wikipedia.org/wiki/Island_mentality reply Geisterde 19 hours agorootparentprev1, 2, 5 is my best guess. reply nulld3v 9 hours agorootparentprevAre actually there any studies that say Teflon is harmful? Not the fumes when it is heated, I mean Teflon itself. reply joe8756438 19 hours agorootparentprevSwimming pools because of drowning or chemical exposure? reply ativzzz 19 hours agorootparentDrowning is the leading cause of death for 1-4 year olds and 2nd after car accidents for 5-14 year olds https://www.cdc.gov/drowning/facts/index.html reply timeon 19 hours agorootparentprev> being very careful when you drive That helps, but there are more participants in traffic than just you. reply heresie-dabord 20 hours agoparentprevThis is at best an incomplete, complacent position to take. Homo plasticus has polluted the atmosphere and oceans, exploited topsoil and groundwater to the point of long-term destruction, and made polymers part of the global food supply. [1,2,4] > Used to be if you survived to reproduce, you were doing pretty good. Used to be. And if you were lucky, you lived in a stable democracy instead of any one of the variants of violent dictatorship. Fertility levels are in steep decline. Today's children will grow to adulthood in a world abused to the point of global disaster. [3] Things have changed for the worse in ways that our species has never before faced. = = = [1]_ https://www.smithsonianmag.com/smart-news/in-a-first-micropl... , https://www.theseacleaners.org/news/microplastics-in-human-b... [2]_ https://www.forbes.com/sites/davidbressan/2023/06/16/humans-... [3]_ https://www.bbc.com/future/article/20230327-how-pollution-is... [4]_ https://news.un.org/en/story/2022/07/1123462 reply nonrandomstring 20 hours agorootparent> Things have changed for the worse in ways that our species has never before faced. This question of \"facing things\" is what bothers me. Sure, science and technology is difficult and has awful side effects. Progress is a complex vector, and it isn't easy to have 'purpose' (telos) see where we should be going. But what I see here every day is very intelligent, witty, well read people ... using their intelligence against themselves. The extraordinary intellectual acrobatics of denial and apologetics just makes me weep. And so many who just down-vote challenging questions but lack the patience and courage to form an argument. reply red-iron-pine 19 hours agorootparent> And so many who just down-vote challenging questions but lack the patience and courage to form an argument this is a lame attempt to flatter our intelligence but then criticize for not engaging on what are essentially marketing platforms where the stakes are usually zero, and there is no way to demonstrably prove that we're not shills, morons, or GPT bots. reply nonrandomstring 19 hours agorootparentYou owe yourself more self-respect. You're probably in the 0.1% of people who could make a difference. reply pas 10 hours agorootparentprevsorry, denial/apologetics of what? could you expand on this a bit? thanks! reply dirtyhippiefree 20 hours agorootparentprev>so many who just down-vote challenging questions but lack the patience and courage to form an argument. Fear of the unknown is an impetus for herd mentality. Hopefully your comment ceases to be gray… reply nonrandomstring 17 hours agorootparentJust been thinking about your remark about \"gray\". Like am I really so dull? Wow! I just realised that people who use some regular browsers see down-voted comments as kinda faded out. That's really sinister but also quite funny and in character with the dystopian creed. How about adding random characters and line noise to unpopular comments, or replacing odd words to make them seem more deranged and subtract credibility? That wo ld g1ve the \"hacker-like\" #eel 00f marg1nal comments ^e$inG aT th33 3nd of s0me %$(k3d Up dd^H^H^Hddddistant dddddial-up modem w$)th iiiine noize insert hippopotamus hatstands sleep furiously Can you hear me? reply pas 10 hours agorootparentprev> Fertility levels are in steep decline. and IVF works. (yes, it's a bit more risky than the Nike method - just do it, yes, it's expensive, but having kids is a lot more expensive usually.) the linked BBC article seems to contradict its title (\"For the majority of men with fertility problems, the cause remains unexplained\") also, mixing up ability and willingness to have kids is just fucking revolting. of course a lot of people are don't have kids, because bad journalism takes away people's joy. well, also this little thing called ladder pulling, and the usual coordination problems (NIMBYs, etc) reply Solvency 19 hours agorootparentprevWhy is the average height in the US getting taller every year? Shouldn't it be shrinking if each generation is allegedly less healthy? reply redwall_hp 19 hours agorootparentThis assumes height is universal proxy for health. Marfan Syndrome will make you taller, but it doesn't mean you're more healthy. reply nonrandomstring 21 hours agoparentprev> Used to be if you survived to reproduce, you were doing pretty good. Extra points if you got to watch your kids grow up. \" I had to get up in the morning at ten o’clock at night, half an hour before I went to bed, eat a lump of cold poison, work twenty-nine hours a day down mill, and pay mill owner for permission to come to work, and when we got home, our Dad would kill us, and dance about on our graves singing Hallelujah.\" [0] WTAF is it with this \"noble savage\" glorification of mythical past miseries as a way to avoid thinking about how massively we've screwed up as a civilisation? That sort of response is a \"Don't look up\" level of avoidance and rationalising. [0] https://python.mzonline.com/sketches/wewerepoor/ reply stuartjohnson12 21 hours agorootparentI actually think this is the opposite of noble savage imagery, and that's actually what you're doing. They're not saying things were better in the past when technology was more primative, you're the one saying that the past was better and that getting to where we are now how we have is \"screwing up\" something (presumably a good thing that existed in the past that is no longer present). reply nonrandomstring 20 hours agorootparentThen I am mistaken in my labelling. Maybe something more like the \"pathetic savage\"? Or what other name might we give to this phenomenon of dismissing extinction level mistakes with the appeal to the idea that \"hey, it's progress\"? reply stuartjohnson12 20 hours agorootparentI think \"bad tradeoffs\" is the term you're looking for. If you think the negative outcome has infinite negative value, there's not really a lot that can be said to that as it becomes a Pascal's wager. If you don't acknowledge any of the tradeoffs involved in pollution and instead just make a point about harm in a vacuum, it's hard to know how to consider it. reply nonrandomstring 19 hours agorootparentNo, I think everyone recognises tradeoffs here and your belief that I'm creating a dichotomy is unwarranted. I'm addressing distorted perception of the parameters of tradeoffs. Like the overwhelming exceptionalism of how we all care about the environment and the future health of our children... just don't take our gas-guzzling cars and non-stick pans way! We are not rational beings, but we so deeply believe we are. reply Geisterde 19 hours agorootparentIm on my 4th electric car, every single one has been remarkable in terms of cost, build quality, innovation etc. If the cybertruck was out a year earlier, I suspect I know a few people driving \"gas guzzling\" trucks that would have bought that instead, because it would have been cheaper, faster, and in almost every measurable and unmeasurable quality, better. Why do you think people will forever hold on to ICE? It strikes me that electric cars are a step change in almost every way, maybe the reason people still have ICE is they didnt have a compatible electric alternative at the time. reply bowsamic 20 hours agorootparentprevNoble savage doesn't mean that you think the environment of the past was better than the present, it means that you think the people were better before being corrupted by civilisation. I.e. it's about thinking that the changing environment under progress corrupts humans, which is the opposite of what the person you are replying to is saying and is exactly what the person they're replying to is saying... Noble savage = humans fundamentally corrupted by civilisational progress reply r3d0c 20 hours agorootparentprevlol that's definitely not what he's doing, way to miss the point unless you're actually arguing for toxic chemicals in the water that didn't exist more than 60 years ago reply nonrandomstring 20 hours agorootparent> way to miss the point All of those commenters deconstructing my clumsy use of \"Noble Savage\" (I admit it's not quite the right thing) - are indeed (maybe wilfully) missing the point. A better expression might be the \"Parochialism of the present\". But that doesn't quite get to it. Nor even Thomas Hobbes' flowery and overblown conceit of past life as \"Nasty, brutish and short\". It's about a phenomenon of lionising a one dimensional idea of \"progress\" in a patently self-deceiving way. reply thworp 20 hours agorootparentprevI think the parent comment made a reasonable point and did so in a calm manner. It in no way overplayed the misery of the past (I'd argue it vastly underplayed it). Now, to your contention that \"we've screwed up as a civilisation\". What do you mean exactly? What civilization and when did the screwing up start? reply nonrandomstring 19 hours agorootparent> I think the parent comment made a reasonable point and did so in a calm manner. As I have pointed out in other remarks here today, calmness reasonableness do not make a bad position good. If anything they add a palatable veneer to the harm. > It in no way overplayed the misery of the past I completely disagree. The idea that in the past people were \"lucky to see their children grow up\" is dramatic, and a tautology anyway since we are all \"lucky\" to see our children grow up in any epoch. It paints a needlessly bleak picture of some awful past that technological progress is implied to have eliminated with justifiable costs. > What do you mean exactly? What civilization? Actually, you know what. You're right [0]. \"What do I think of Western civilisation? I think it would be a very good idea.\" [0] https://en.wikiquote.org/wiki/Mahatma_Gandhi reply thworp 18 hours agorootparent> I completely disagree. The idea that in the past people were \"lucky to see their children grow up\" is dramatic, and a tautology anyway since we are all \"lucky\" to see our children grow up in any epoch. It paints a needlessly bleak picture of some awful past that technological progress is implied to have eliminated with justifiable costs. You got me there, I do think the costs for (almost) eliminating famine and diseases with double-digit mortality rates are justifiable. That said you didn't really answer my question, but I'll roll with it. Consider the extinction of megafauna [0], the deforestation of China [1] or Mesopotamian farming practices [2]. It would be hard to blame these on Western civilization (real or imagined). I'd say we have been operating in the same unsustainable way for a long time. I wish it were otherwise because it would make everything easier. [0] https://royalsocietypublishing.org/doi/10.1098/rspb.2013.325... [1] https://www.sciencedirect.com/science/article/pii/S003101822... [2] https://www.science.org/doi/10.1126/science.128.3334.1251 reply nonrandomstring 17 hours agorootparent> you didn't really answer my question Fair remark, I brushed it off. > when did this start? It started when science and technology changed from something we do, into something we believe in. I don't think that actually happened any time around the Enlightenment of even the Industrial Revolution, but we're definitely deep in it now. I'll leave you to put the pin in the map. Also, the cause and effect are not so simple. It's not as if we changed our culture and beliefs, and then embarked on a century of planet-destroying madness. Rather, like the sunk-cost bias of an addict, we realised we are on a bad road, labelled that as \"inevitable\", surrendered before the forces of \"technological determinism\" and found we had no choice but to believe. But that was a false choice. reply bowsamic 21 hours agorootparentprevThe way these people talk about the past makes it sound like people in the past were somehow perfectly stoic in the face of discomfort or disease, but it's extremely easy to find historical documents showing that this isn't the case. I think the reason people fall into this \"noble savage\" trap is because they (rightfully) can't imagine living without modern technologies like refridgerators and flushing toilets, and therefore (wrongfully) conclude that the people in the past were simply more rugged to be able to live without it. Also, as you say, it's an easy way to explain away our problems, to say that people in the past were better and if they were here today then they wouldn't be complaining like we are. reply nonrandomstring 20 hours agorootparentYou have also entirely missed the point reply bowsamic 20 hours agorootparentI thought I was agreeing with you, what was your point then? reply lazide 19 hours agorootparentprevObsessing about ‘how we screwed up’ instead of actually working on making things better is a sign of clinical depression. FYI. reply nonrandomstring 19 hours agorootparentSorry to hear that's what's eating you my friend [0]. Just hit the Xanax, heh? But as soon as you feel well come and join the rest of us working on making things better. [0] https://www.psychologytoday.com/us/basics/projection reply unmole 16 hours agoparentprevThis comment is known to the State of California to cause cancer or reproductive harm. reply dogman144 18 hours agoparentprevI mean, are you arguing this is somehow a bad development? “Sorry kid, but at least your dad got to see you ride your first bike, chalk that up to win, used to be much worse! You know, DuPont and 3M can’t give ground all the time.” It is very hard to read about the cancer clusters in WV/OH around the heavy PFAS sites and not feel some extreme disgust at how bad it got and feel thankful that this is getting significant attention. reply Hugsun 20 hours agoparentprevIt's true but other risks are usually discrete. PFAS exposure continously decreases your health while driving a car has no effect on your health until you get into an accident. The risk calculation feels different in those cases. reply theGnuMe 16 hours agorootparentCars impact your health if you would have otherwise used some form of self propelled transportation (i.e. walking). reply theGnuMe 21 hours agoparentprevCause I really need my water to be non-stick. reply dylan604 19 hours agorootparentI feel like we’ve missed a branding opportunity in the bottled water scene with this one. “Non-stick water” can be listed right next to the “Glutton Free” on the label reply JoeAltmaier 18 hours agoparentprevLots of deliberately-missing-the-point by crusaders posting to your point, @nostrademons. Yes it's bad there's plastic in rainwater, they bang on about that like they've thought of something you missed. But I agree we live with so many other risks, there may conceivably be better windmills to tilt. Heart disease dominates the US health problems. Maybe we could do something about food in America. Something we can actually do something about, with a measurable improvement in living. And so on. reply theGnuMe 16 hours agorootparentPFAS, plastics etc.. are all related to food in America. reply teekert 19 hours agoprevIn the Netherlands we have Chemours, they produce and dump PFAS. So naturally we find PFAS in and around the factory in Dordrecht NL. We find 13.000 x the norm in certain \"swimming\" waters. And naturally we find it the eggs of hobby chickens (not industrial ones)... So people stop eating fresh eggs. Many get rid of their chickens. But wait... As it turns out we find PFAS/PFOS that aren't even produced nor used by Chemours! What gives? We investigate and we find it all over the country. Some are above the norm, some below. How does it get into the chickens? No one knows atm. The rain? The food? It seems like the stuff is just everywhere indeed. We also stopped eating our eggs, looking for a testing service. reply johnmaguire 19 hours agoparentDo you happen to have sources? I see Chemours was found liable. It looks like NL is also going after 3M. https://www.reuters.com/markets/commodities/dutch-court-rule... https://www.reuters.com/business/environment/dutch-governmen... reply coryrc 16 hours agorootparentWording issue, I think. I think parent poster meant they also find PFAS that are unlikely to come from Chemours, not that Chemours didn't create any. reply teekert 16 hours agorootparentYou are correct. reply Solvency 19 hours agoparentprevI mean the answer about the chickens is obviously the water and the food. Mass produced chicken feed is garbage and I guarantee you your chickens are not fully pasture raised. And even if they were, all of your crops and fields are sprayed with chemicals. And, yeah, PFAS rain. reply Neil44 21 hours agoprevSuch a headline surely suggests that the definition of 'unsafe' needs clarification, since we are not all dead. reply anymouse123456 21 hours agoparentTo your point, from the article: \"I'm not super concerned about the everyday exposure in mountain or stream water or in the food. We can't escape it... we're just going to have to live with it.\" I agree that it doesn't feel right to read a quote like, \"I'm not super concerned about...\" along with such a dire sounding headline. reply lm28469 21 hours agoparentprevNot dead but you have 50% of the testosterone of your great grandpa due to environmental pollution and other factors reply red-iron-pine 19 hours agorootparentwe have 50% of the testosterone of our grandpas because body fat produces small quantities of estrogen, and we're the fattest, most sedentary, most in-doors-y humans in the history of humans. reply avgcorrection 18 hours agorootparentThe great thing about modern living is that a thousand variables have changed in the last 70 years so we can pick our own favorite pet peeve and just hammer on that point in every conversation. reply dblack12705 18 hours agorootparentprevBaseline testosterone levels are actually even lower in most hunter gatherer populations. This suggests that your explanation is not necessarily correct. reply veunes 20 hours agorootparentprevNot dead but we have the increasing prevalence of cancer reply Neil44 20 hours agorootparentprevCitation needed reply elif 19 hours agorootparentThis is non controversial established medical fact. Here are the first three results when you Google 'testosterone rates dropping' The only thing vague is the precise etiology. However, when it comes to legalizing irreversibly blanketing the planet in poisons, the onus should be on proving they are not the culprit, not the inverse. 'The average levels of the male hormone dropped by 1 percent a year, Dr. Thomas Travison and colleagues from the New England Research Institutes in Watertown, Massachusetts, found. This means that, for example, a 65-year-old man in 2002 would have testosterone levels 15 percent lower than those of a 65-year-old in 1987.' 'Research carried out on Finnish and Danish populations has shown the same trend [1,6]. And even more recently, a large-scale study of Israeli men has shown how average testosterone levels have dropped between 2006 and 2019 [7] — by over 10% across almost every age category. ' 'Testosterone deficiency has a prevalence of 10%-40% among adult males, and 20% among AYA men aged 15-39 years, he added.' reply Neil44 17 hours agorootparenta) nobody has tested my testosterone or my great grandpas to my knowledge b) Both of those are taking drops over a certain period and then you're extrapolating back to my great grandad and assuming certain results, which is a bit tenuous. No to mention also assuming the cause. Quite a long way away from a \"non-controversial established fact.\" reply a_gnostic 20 hours agorootparentprevLook bruh, we have the documents, and they're turning the frogs gay. reply Izkata 19 hours agorootparentHe was reading an article about how chemicals we're dumping are triggering a frog species natural ability to change sex. The frogs normally do it when there's too many of one sex, to even it out, but the chemicals were making them switch when there was balance and were causing an imbalance. Truth is stranger than fiction: it would have been more accurate for him to say \"they're turning the frogs trans\". reply zarathustreal 18 hours agorootparentIf one has delegated their thinking to the point that they’re essentially a parrot, do they really care about accuracy? reply a_gnostic 13 hours agorootparentTake your accuracy, put a frog in it, make it gay and lame! reply lazide 19 hours agorootparentprevIf you workout and aren’t overweight and obese you don’t. reply maerF0x0 18 hours agorootparentplease source that, I'd love to keep that reference handy if it's true. reply lazide 18 hours agorootparentIt’s got a ton of papers, but here is a quick and easy cite from 5 seconds of googling. Weight lifting increases it more than cardio. [https://www.nm.org/healthbeat/healthy-tips/fitness/quick-dos...] More activity, and more muscle, leads to more testosterone. More fat leads to more estrogen (and some other problematic hormones for men) - [https://www.betterhealth.vic.gov.au/health/healthyliving/obe...] We’re a nation in the midst of an obesity epidemic. Also, sex also seems to increase testosterone. Participating much more than watching. For both genders. So more sex == more sex, generally. [https://www.medicalnewstoday.com/articles/325418] Notably, we’re at record levels of sedentaryness in western society - and record levels of low sex. Low sex IMO also partially due to high levels of narcissist abuse by society (and mothers) aimed at - well - everyone - coupled with little support or guidance on how to fight back. Especially in younger folks. Personally, I noticed schools phasing out recess, PT, and physical activity a long time ago. Steadily decreasing for almost 30 years. It’s gotten pretty bad, to the point now that many schools do almost none now. I’m sure everyone has noticed the ‘dads are incompetent losers’/predators schtick that’s been on TV for decades too. The level of physical activity in most jobs has also been dropping. Also, the widespread use of high SPF sunscreen, while likely reducing cancer rates, is also likely depressing vitamin D levels, in combination with the amount of sun most people are exposed is likely leading to subsets of the population (non supplementing) which seem highly correlated to neuroticism and mood regulation issues. [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4496526/] Anecdotally, I’ve seen no decrease in sex drive among active folks - and any following of news from the olympic villages shows similar behavior. If anything, there is a pretty clear correlation between activity/health/sex (or at least sex drive). And always has been. Personally, I’ve noticed a very strong correlation between seasonal weather patterns (aka winter) and everyone losing their minds (more), especially online, especially the last few years - as everyone has stayed at home more, and people are online more, staying single more, etc. The big issue with this kind of problem is that it can be self reinforcing. Contagious even. The best thing to do is get outside into nature, get some sun, exercise/lift heavy things, and have some good sex. Easier said than done though eh? Especially when there is so much ‘crabs in a bucket’ going on. Maybe it’s caused by endocrine disruptors - they certainly aren’t helping, and we should do what we can to remove them. But the elephant in the room is that our society has shifted in exactly the way one would expect would cause these issues too. And it correlates with the various mental health issues that are going nuts as well. If you look at the daily habits and attributes of the population 100 years ago on these elements vs today - they couldn’t be more different. So society, we need to get out, workout, and get laid if we want to be healthy. reply Filligree 21 hours agorootparentprevnext [4 more] [flagged] hackerlight 20 hours agorootparentTestosterone doesn't directly cause aggression, it causes people to compete which may manifest as aggression if aggression leads to status in whatever culture you live in. - my recollection of Robert Sapolsky reply r3d0c 20 hours agorootparentprevnothing to do with testosterone but emotional intelligence reply lm28469 20 hours agorootparentprevAll I know is that we're rapidly changing things that have been much more stable for thousands and thousands of years. Getting rid of aggressivity is good but if it takes your fertility/strength/bone density/dementia resistance/&c. with it... but then again is humanity a good thing ? reply Lendal 21 hours agoparentprevBecause we don't drink rainwater. reply phyzome 20 hours agorootparentIn the Boston area, our water comes from the Quabbin Reservoir. That's largely fed by rain, as far as I am aware. How much PFAS actually gets filtered out? Probably not much. reply lulzury 19 hours agorootparentYou can actually easily find this information online [0] > PFAS compounds, used since the 1940s for many purposes, from stain and waterproofing to firefighting, continue to be a concern. Tests of MWRA water show only trace amounts of these compounds, too small to be quantified, and well below the state standard of 20 parts per trillion. MWRA results are also well below recently proposed EPA standards. [0] https://www.mwra.com/annual/waterreport/2022results/PDFS/Bos... reply stubish 8 hours agorootparentprevA lot of the world most certainly does, especially in rural areas that are not connected to water treatment plants. Bore water tends to be hard, so humans stick to the rain water when we can get it. reply bamboozled 21 hours agorootparentprevWhat are we drinking then ? reply lm28469 21 hours agorootparentSpring water or water coming from water treatment plants, both of them are very dissimilar to rain water reply kwhitefoot 21 hours agorootparentAll of which ultimately comes from rainwater. reply belorn 20 hours agorootparentUltimately all water comes from the creation of the earth, which in turn got it from space. The ultimate origin is not very useful. If we just want the first step before treatment plants, it depend on location. Generally it is what ever water that is cleanest and cheapest, usually lakes and rivers with the best connection and high flow of ground water. Ground water tend to be highly filtered which lowers the amount of treatment that treatment plants has to do. Rainwater collection is usually not used for drinking water given the high amount of pollution. It can be used in industry/agriculture, or as backup for areas where the ground water is severely limited. reply lm28469 20 hours agorootparentprevOf course, and most of it comes from sea water, it doesn't mean you can drink sea water reply PeterisP 19 hours agorootparentprevThere is a substantial level of natural filtration between rainwater and springwater, so they are not equivalent. reply Gasp0de 21 hours agorootparentprevGroundwater, water from wells. reply gambiting 21 hours agorootparentIn a lot of places drinking water is pumped from open air aquifiers(a lake basically) so presumably it contains everything rain does, since it doesn't go through the rock layers. reply shantara 20 hours agorootparentprevWhich is also polluted with pesticides and other agricultural pollutants. reply defrost 20 hours agorootparentNot all wells, mainly those that are in aquafier catchments that include heavy PFA sites and agricultural runoffs, etc. Airports are notorious sources, PFA's were used in fire fighting foams for a decade or more (depending on global location). reply timeon 19 hours agorootparentprevWe don't but are we alone on this planet? reply johnnyjeans 11 hours agoparentprevAlarmism might be the modern crisis actually worth being alarmist about. reply alistairSH 21 hours agoparentprevUnsafe doesn’t have to mean immediately fatal. The dangers of PFAS are pretty well known - hormone disruption, cancers, reduced vaccine efficacy. reply kornhole 18 hours agoprevThe only way water after being distilled by the sun to pure H2O can be contaminated with these chemicals is if the chemicals are in the air. To my knowledge, we have zero regulations on what airplanes are allowed to spray into the atmosphere. Scientists at https://www.geoengineeringwatch.org/ and https://climateviewer.com/ have tested the aerosols and other chemicals being sprayed and found them to include a number of harmful chemicals. If enough people were aware of what is going on, we could demand some transparency and accountability. reply jerry80 17 hours agoparentMany small aircraft are still required, by law, to use leaded gasoline. Meanwhile, leaded gas has been outlawed for use in cars for decades. reply kornhole 15 hours agorootparentFuel additives in any vehicle can put stuff in the air. If you look at these sites to see what they are intentionally spraying into the atmosphere, you will never look up at the clouds and airplanes in the same way. reply pas 10 hours agoparentprevPFAS boiling point is around 189 Celsius, so it can also evaporate with water - of course very slowly, but it's enough to simply get everywhere on Earth reply Nifty3929 17 hours agoprevThis is a bit exhausting. I care about the environment. And I care about it's impact on humans. But I feel like it's a never-ending march of things to fret about. It really seems like folks are looking for thins to sound the alarm about. Maybe PFAS really are a major problem, I don't know. But I'd love to see a bit more circumspection about this and other issues. Keeping people on red alert, all the time, about everything - does not seem like a recipe for human flourishing overall. Though it may be a good way to keep people under control. reply ttpphd 17 hours agoparentYou are exhausted. That doesn't mean the concern isn't well considered by those who are presenting it. The problem is your emotional fatigue, not that people are insufficiently \"circumspect\". reply friend_and_foe 15 hours agorootparentAnd the solution is to not care? Seems like the same outcome either way. reply globular-toast 17 hours agoparentprevThat's why you vote in a government to worry about things for you. There's no reason why individuals should have to worry about stuff like this. reply coryrc 16 hours agorootparentIsn't that the problem with democracy though, mass uneducated voting for worse education and killing us all. reply 93po 14 hours agorootparentand yet we want to align AI to general human values reply pas 9 hours agoparentprevPFAS is just the currently hyped and talked-about symptom of reactive regulation. The problem is that there's no requirement for demonstration of safety for new products/chemicals, not even monitoring, nothing (in most parts of the world). Which seems obviously bad. But we currently live in a particularly idiotic mass-communication by memes times, hence we have defund the police and PFAS, and so on. reply DinaCoder99 17 hours agoparentprev> Keeping people on red alert, all the time, about everything - does not seem like a recipe for human flourishing overall. It would help if we had some sort of mechanism to turn these \"alerts\" into action, which seems to be a sticking point for a globe dominated by society obsessed with corporate liberties to do nothing or double down on the problematic behavior. reply banga 21 hours agoprevUnsafe for humans likely means unsafe for many other organisms too. reply amenghra 21 hours agoparentA common model for chemical intake is based on the person's weight. I.e. if it's unsafe for the average human it's likely even worse for children, smaller animals, etc. reply msdrigg 21 hours agorootparentThis would need to account for how much more or less of the chemical that the person consumes (e.g. children would likely drink proportionately less water all things considered) reply amenghra 21 hours agorootparentData point = 1 but my kids eat/drink 2-3x less than I do. They weigh 5-7x less. reply gruez 20 hours agorootparentThat's because they're growing, not because they weigh less. reply jakeinspace 20 hours agorootparentIn general, smaller organisms tend to consume more calories or resources per mass of body weight than larger ones. One reason, for mammals especially, is that maintaining homeostasis means scaling energy input with surface area, since that’s what radiates away heat. Surface area roughly scales with square of height, while mass scales with volume (cube of height). reply Qem 20 hours agorootparentprev> children would likely drink proportionately less water all things considered Children tend to be more physically active, and have higher surface area to volume ratios, so proportional to body mass their water intake must be higher. reply dsq 20 hours agoprevWould it matter if the water is from the first rain of the seaon, when the air is still full of particles, or after, say, a week of constant rain. reply Nifty3929 18 hours agoprevSafety is not Boolean. Things are not safe or unsafe. It's just a question of HOW safe something is, what the risks are, etc. Do we have any sense of the actual amount of PFAS in rainwater, and the human health impact of such? I didn't see any mention of this in the article. Maybe more investigation along these lines would be helpful. reply alistairSH 16 hours agoparentHere's the study on which this article is based: https://pubs.acs.org/doi/10.1021/acs.est.2c02765 As noted in the article, the EPA recently lowered the \"safe limit\" based on evidence that the previously acceptable levels were still high enough to reduce vaccine efficacy in children. And we already know PFAS impact fertility and hormones, can cause some cancers, etc. reply maerF0x0 18 hours agoprevRelevant related: https://www.nbcnews.com/health/health-news/new-way-destroy-p... https://www.science.org/doi/pdf/10.1126/science.abm8868 (Method to destroy PFAs) https://news.ycombinator.com/item?id=35764476 reply thrawn0r 21 hours agoprevDetail absent from the article for context: The new proposed EPA guideline is 4.0[1] parts per trillion (also expressed as ng/L) for PFOA and PFOS. [1] https://www.epa.gov/sdwa/and-polyfluoroalkyl-substances-pfas reply TeMPOraL 18 hours agoprevThis gives a new spin on the question, what does rain taste like? (I don't remember if that was part of the books too, but in the show The Expanse, a major character who was born and lived on Ceres pondered this occasionally. In the end, he was told by an Earther that \"it tastes like nothing, it's just water\". I guess this is an improvement over status quo.) reply cpburns2009 18 hours agoparentFYI: Your other comment in this post looks like it triggered auto-moderation. It's marked \"[dead]\". reply TeMPOraL 16 hours agorootparentThanks. It wasn't my best comment, but I'm not sure what could've killed it without incuring any net downvotes :/. dang? :) reply tutfbhuf 17 hours agoprevI'm not sure which one will kill us first: forever chemicals, nanoplastics, or global warming. reply krunck 16 hours agoprevI hope this is the last nail in the coffin of \"Better living through chemistry™.\" Just because we can make it (and make money from it) doesn't mean we should. reply boyka 16 hours agoprevIs there any analogous research on groundwater and tap water? Are sewage treatment plants that effective in removing PFAS? reply Alifatisk 21 hours agoprevThat’s so tragic, what’s the consequences of me still collecting and drinking the rain water? Cancer? reply wongarsu 21 hours agoparentIt's worth noting that filters capable of removing PFAS are readily available (in the industrialized world). Apparently even regular activated charcoal filters do a good job. reply hasbot 20 hours agorootparentMaybe not completely though: https://nicholas.duke.edu/news/not-all-home-drinking-water-f... and https://www.epa.gov/sciencematters/reducing-pfas-drinking-wa... Sounds like a reverse osmosis filter works best. reply alistairSH 21 hours agoparentprevPossibly. Plus hormone disruption, reduced vaccine efficacy, and other problems. But, as the article noted, PFAS levels in humans are steady for now. So, the damage is probably already done. reply Lendal 21 hours agorootparentPFAS levels have gone down because we drink treated water. Making municipal water safe to drink is a big industry now. Anyone drinking only rainwater is exposed to those higher levels of whatever is in the rainwater. A small amount of rainwater is probably fine, but if you really do live off the grid year round then you need to treat your rainwater. reply gregmac 19 hours agorootparent> A small amount of rainwater is probably fine, but if you really do live off the grid year round then you need to treat your rainwater. Drinking untreated rainwater is a pretty bad idea [1], even without considering PFAS. A bird pooping on the surface you collect it from is enough to contaminate the tank with bacteria, parasites and/or viruses, and if you collect any kind of ground run-off it gets significantly worse. [2] [1] https://www.cdc.gov/healthywater/drinking/private/rainwater-... [2] https://novascotia.ca/nse/surface.water/docs/SurfaceWaterQA.... reply engineer_22 20 hours agorootparentprevIn my area of the country most municipal water treatment systems don't have PFAS treatment. These systems are expensive to install and come with their own headaches. That said, funding is now available to upgrade water treatment plants for PFAS. reply nonrandomstring 21 hours agorootparentprevPerhaps you can tell us the magical way that PFAS is currently removed in commercial water treatment? reply Lendal 20 hours agorootparentCertain technologies have been found to remove PFAS from drinking water, especially Perfluorooctanoic acid (PFOA) and Perfluorooctanesulfonic acid (PFOS), which are the most studied of these chemicals. Those technologies include activated carbon adsorption, ion exchange resins, and high-pressure membranes. These technologies can be used in drinking water treatment facilities, in water systems in hospitals or individual buildings, or even in homes at the point-of-entry, where water enters the home, or the point-of-use, such as in a kitchen sink or a shower. reply nonrandomstring 20 hours agorootparent> Certain technologies Actual ones. Actual ones in use right mow in your neighborhood? In use on the water you're drinking today? reply twodave 20 hours agorootparentReverse osmosis water filtration systems that use activated carbon are pretty common, and least where I live. We have one under our kitchen sink, and so do my in-laws. Most refrigerators that include a water dispenser come with an activated-carbon-based water filter as well. reply nonrandomstring 20 hours agorootparentThat's nice that you've got that in your home. But at scale? For the rest of us? I live in a \"developing nation\" [0] of 70 million people whose private water companies are fined billions every year because they cannot meet the most basic standards of supplying potable water and not dumping raw sewerage into the rivers and sea. [0] https://www.theguardian.com/commentisfree/2013/dec/09/britai... reply twodave 13 hours agorootparentI’m not sure what point you’re trying to make anymore. You asked if people actually have these things. We do. Why does this need to scale? If you want to be pedantic, anyone can make themselves an activated charcoal water filter using fire, wood, half a plastic bottle and some rocks and straw and stuff. If you’re on the Internet you already have access to this knowledge. reply nonrandomstring 20 hours agorootparentprevDownvoting my question will make it go away. It will not make the problem go away. reply engineer_22 20 hours agorootparentI thought it was a fair question reply datavirtue 21 hours agorootparentprevKale doesn't get any credit. reply galangalalgol 21 hours agoparentprev>The EPA recently lowered its PFAS guidelines significantly after discovering that the chemicals may affect the immune response in children to vaccines, Cousins noted. reply Filligree 21 hours agorootparentSo, 'unsafe' here means 'unsafe for children'. That... still seems like an issue, to be honest. Not that you were saying it weren't, but... hmm. I wonder how much of a problem we're making for ourselves. reply hef19898 20 hours agorootparentPFAS are not natural, so I think we make all of that particular problem ourselves? reply Nifty3929 17 hours agorootparentGP wasn't questioning who is creating the problem, they were questioning the size of the problem we are creating. reply hef19898 17 hours agorootparentThose chemicals are a huge problem of epic proportions we created for ourselves here, that's true! reply dang 18 hours agoprev [–] If anyone were to collect the major PFAS/microplastics/foreverchem threads from HN, I bet the list would be even more mammoth than the tax-filing perennial for which I had to convert the \"related\" list into continuation-passing style: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... I'd do it myself, but am le tired. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Stockholm University study revealed that rainwater globally is unfit for drinking due to high levels of persistent toxic chemicals called PFAS, found throughout the environment.",
      "PFAS, known as \"forever chemicals,\" do not break down easily and have surpassed safe drinking water limits in rainwater, posing health risks upon consumption.",
      "Despite a decline in human PFAS levels over two decades, stricter guidelines are in place due to better understanding of their harmful effects, highlighting the necessity to accept PFAS contamination as an inescapable environmental issue."
    ],
    "commentSummary": [
      "The discussion raises awareness about harmful chemicals such as PFAS in common products and the environment, underlining potential risks to human health and ecosystems.",
      "Emphasis is placed on the necessity for government regulation, accountability, and heightened awareness to tackle these concerns effectively.",
      "Various topics include chemical toxicity, effects on reproductive health, water pollution consequences, and the significance of environmental consciousness for future sustainability."
    ],
    "points": 239,
    "commentCount": 181,
    "retryCount": 0,
    "time": 1709033237
  },
  {
    "id": 39528726,
    "title": "SuperTux: A Super Mario-inspired Jump'n'Run Adventure",
    "originLink": "https://github.com/SuperTux/supertux",
    "originBody": "SuperTux SuperTux is a jump'n'run game with strong inspiration from the Super Mario Bros. games for the various Nintendo platforms. Run and jump through multiple worlds, fighting off enemies by jumping on them, bumping them from below or tossing objects at them, grabbing power-ups and other stuff on the way. Story: Penny gets captured! Tux and Penny were out having a nice picnic on the ice fields of Antarctica. Suddenly, a creature jumped from behind an ice bush, there was a flash, and Tux fell asleep! When Tux wakes up, he finds that Penny is missing. Where she lay before now lies a letter: Tux, my arch enemy! I have captured your beautiful Penny and have taken her to my fortress. The path to my fortress is littered with my minions. Give up on the thought of trying to reclaim her, you haven't got a chance! -Nolok Tux looks and sees Nolok's fortress in the distance. Determined to save his beloved Penny, he begins his journey. Installation For major platforms, stable releases are built and available for download from supertux.org or alternatively directly from GitHub. You should be able to install these using default tools provided by your platform. On macOS, when Gatekeeper is enabled (default) it will refuse to open SuperTux. This is due to the lack of a signature on the application. If you wish to open SuperTux anyway without disabling the Gatekeeper feature entirely, you can open the application from the context menu (control click on the icon). macOS will then remember your choice the next time. Documentation Important documentation for SuperTux is contained in multiple files. Please see them: INSTALL.md - Requirements, compiling and installing. README.md - This file NEWS.md - Changes since the previous versions of SuperTux. LICENSE.txt - The GNU General Public License, under whose terms SuperTux is licensed. (Most of the data subdirectory is also licensed under CC-by-SA) data/credits.stxt - Credits for people that contributed to the creation of SuperTux. (You can view these in the game menu as well.) Playing the game Both keyboards and joysticks/gamepads are supported. You can change the controls via the Options menu. Basically, the only keys you will need to use in-game are to do the following actions: jump, duck, right, left, action and 'P' to pause/unpause the game. There isn't much to tell about the first few, but the \"action\" key allows you to pick up objects and use any powerup you got. For instance, with the fire flower, you can shoot fireballs, or with the ice flower fire ice pellets. Other useful keys include the Esc key, which is used to go to the menu or to go up a level in the menu. The menu can be navigated using the arrow keys or the mouse. In the worldmap, the arrow keys are used to navigate and Enter to enter the current level. Community In case you need help, feel free to reach out using the following means: IRC: #supertux on Libera Chat hosts most of the discussions between developers. Also, real-time support can be provided here. If you don't know how to use an IRC client, you access the channel using a web-based client. Please stay around after asking questions, otherwise you will be disconnected and might miss potential answers. Matrix: #supertux:matrix.org is bridged to our IRC room. Forum: The SuperTux community is very active on the forum, the discussion ranges from feature proposals to support questions. In particular, most community-contributed add-ons are published there first, so this is worth checking. Mailing Lists: The supertux-devel mailing list is dead. Here is the archive. Social Media: Mostly on Twitter at the moment. Discord: Also, you can join our Discord server to get in touch with us. Development status As of now, with the release of SuperTux 0.6.3 (December 2021), the Forest World is almost finished, since the ghost forest section has been included. However, some levels, especially the Ghostree Level, are considered to be placeholders, because for the next version (0.7.0) a great overhaul is planned with new features like reworked boss fights, graphics, and worlds. If you have some Constructive Feedback, Contributions or ideas to share, don't hestitate to contact us with one of the possibilities given above.",
    "commentLink": "https://news.ycombinator.com/item?id=39528726",
    "commentBody": "SuperTux (github.com/supertux)236 points by floriangosse 14 hours agohidepastfavorite45 comments histories 0 minutes agoOne of my first linux distro was Knoppix, which had inside incredible games like Kobo Deluxe, Frozen Bubble, The Battle for Wesnoth, and of course SuperTux. reply tiagod 12 hours agoprevThis game got weirdly very popular among kids of a very specific generation, here in Portugal. The \"Magalhães\", an Intel Classmate variant that was available to school kids between 2008 and 2010 for a price between 50€ and 0€ (depending in social security status), came bundled with both Windows and a Portuguese Linux distro, which shipped with SuperTux by default. reply linkpuff 11 hours agoparentI've got a bunch of these Magalhães at home due to having my parents work at schools. If I recall correctly, SuperTux was exclusive to the first version of the laptop(there were two) and you can still turn heads nowadays if you take one out in public, which is pretty cool. Too bad that, despite their ruggedness, the Magalhães 1 had a very frail hard drive whose death meant that the BIOS would lock up completely when booting, not even allowing you to get to the setup menu, which for a kid meant that it became a paperweight. reply FirmwareBurner 10 hours agoparentprev>Portuguese Linux distro Be curious to know what makes a Portuguese linux distro. Isn't changing the language on any other mainstream distro enough? What does the Portuguese market desire extra on top to warant the extra effort? reply linkpuff 9 hours agorootparentWhile you're not wrong, I believe that the effort was made with the intent of supporting everything in-house instead of relying on the community. The UI(KDE) of the Linux Caixa Mágica (Magic Box) was worked on to be user friendly and translated in portuguese as back then everything was still a bit rough around the edges, it was also pretty well documented for parents. I think my first linux was that one, and I learned a lot with it. Unfortunately I can't say the experience was universal, as the lack of teacher training(the education system evolves very slowly) and lack of resources that involved it lead to a complete flop in the classroom environments. reply varias 10 hours agoparentprevAlso in an Andalusian-flavored Linux distro, Guadalinex. reply haunter 13 hours agoprevShout out to Tux Racer too, still works perfectly (at least the Windows binaries) https://tuxracer.sourceforge.net/ reply kcb 12 hours agoparentAlso: https://github.com/supertuxkart/stk-code reply Intralexical 6 hours agorootparentUnfortunately, the three people who programmed the vast majority of modern SuperTuxKart and managed the community were bullied out of the project a couple years ago. [1] The new team lead was somebody who seemed to have a habit of stonewalling [2] ideas and code contributions from both community members and the dev team, talking down about \"newbie-tier players\" with \"zero skill\", and [3] hyperfixating on \"balance\" (in what is fundamentally a kids' game) without room for fun or discussion. The lead artist, who made basically all the tracks that are worth looking at, and whom I'd worked with now and then to get a couple contributions included, eventually disappeared too. Naturally, commits, contributors, and blog posts/updates are now at an all-time low. [4] So, don't let your group dynamic be taken over by domineering personalities, I guess, is the lesson. 1: https://blog.supertuxkart.net/2019/05/my-departure-from-supe... 2: https://forum.freegamedev.net/viewtopic.php?f=17&t=8086&p=77... 3: https://github.com/supertuxkart/stk-code/issues/3888#issueco... 4: https://openhub.net/p/supertuxkart reply hnfong 1 hour agorootparentFrom your [1] it looks like the original dev(s?) left because their goal was accomplished? I'm confused because reputable dev leads getting \"bullied out of a project\" seems like a 2000s thing which shouldn't exist after the proliferation of git where the repo is in theory decentralized, so nobody could without \"commit access\" like the CVS days of old. When the original contributor left because they thought the game did what they wanted it to do, I'm not sure it's really a major sticking point if the new leader decided to be conservative about things... not that I have a stake in it or whatever. reply nhggfu 6 hours agorootparentprevinteresting, and GREAT advice! reply colinsane 11 hours agorootparentprevOpenStreetMaps x SuperTuxKart has got to be one of my favorite hidden niches: https://wiki.openstreetmap.org/wiki/SuperTuxKart reply kej 12 hours agorootparentprevSuperTuxKart runs well on Android, and it will let you use the accelerometers to steer (so you just tilt the whole device like a steering wheel) which gives it a feeling a little like the Wii version of Mario Kart. reply freedomben 8 hours agorootparentYep, even works with controllers! My kids will play this together using controllers on the Nvidia Shield, and it runs great. They have an absolute blast! reply Intralexical 7 hours agoparentprevTux Racer even had physical cabinets made at one point. There was one in I think the left back corner of an arcade we went to in middle school. I pointed it out to my friend, I think. https://rasterweb.net/raster/2004/08/13/20040813073000/ https://www.highwaygames.com/arcade-machines/tux-racer-9072/ reply zerr 10 hours agoparentprevAny course/tutorial dissecting Tux Racer (or similar) sources would be nice. reply kunrii8528 12 hours agoparentprevIt immediately crashes for me on Ubuntu 22.04, unfortunately. I wanted to play it. reply monocasa 12 hours agorootparentIt's in the default package manager as extremetuxracer which is the fork that's still maintained. reply forthwall 13 hours agoprevI remember playing supertux as a kid when my grandparents bought me a disk of games for my birthday. It was just a bunch of FOSS games like these ripped to a disk and sold to unknowing grandparents. Fun to see that the source is out there on github reply lewispollard 55 minutes agoprevIt's a little odd that there's a wasm build that's seemingly only available for download from the official sources, rather than being playable on the web. reply alsetmusic 11 hours agoprevI was hoping this would be the belly-sliding game that I had on Mac OS X circa 2001. Someone made it with whatever new-to-MacOS tech to show off what could be done that wasn't possible on Mac OS 9 and I downloaded it from somewhere. Was a fun third-person 3d racing game of some sort. Tux raced down a hill covered in snow on his front and you could steer around trees and rocks and such. My memory is probably getting the details wrong. Edit: haunter had the answer. It was a port of TuxRacer. reply parentheses 10 hours agoparentSee the other comment about tux racer reply orblivion 13 hours agoprevI haven't played for more than a minute, but reading the README here, it's interesting how there's a different experience with a FOSS game released but still in development, especially over so many years. Instead of \"SuperTux 2\" you have incremental changes. \"The next level is finished, all the boss battles are improved\". There's no canonical versions like there are with at least classic console games. I know modern games have patches and stuff but I don't think they rework the game this way but I could be wrong. reply j5155 12 hours agoparentMinecraft (Java Edition) is probably the most notable game like this. It’s continued to be the same game with few engine changes/rewrites from the single dev basement project up until the present day dedicated sub company in Microsoft. reply chungy 10 hours agorootparentTeam Fortress 2 had this effect too. 17 years of incremental patches have resulted in a game entirely different from its original release. reply phh 11 hours agoparentprevWell, there actually is/was a Supertux 2. I don't remember the specifics, I think they rewrote it from blit 2D into OpenGL? You can see here : https://github.com/SuperTux/supertux/blob/master/supertux2.d... that it's called supertux2 But yeah this has nothing to do with the actual content of the levels, it only refers to the engine. reply o11c 7 hours agorootparentTo clarify, supertux2 is mostly a distro thing. For a while both 0.1 and 0.3 were shipped, and the user-made levels were not quite compatible between them. Specifically, 0.1: * had a fixed screen size * only let you go forward * used different mechanics for the fire-throwing upgrade Nowadays it's been long enough that most levels are written for the later versions. And IIRC recent versions re-added some support for forward-only levels (race against the clock). reply JoshTriplett 13 hours agoparentprev> I know modern games have patches and stuff but I don't think they rework the game this way but I could be wrong. Sometimes game patches for modern games do rework game balance or playability, rather than just fixing bugs. reply entropicdrifter 12 hours agorootparentYeah, Cyberpunk 2077 2.0 patch changes the game massively, for instance reply FirmwareBurner 10 hours agorootparentConsidering how broken and beta quality the first release of Cyberpunk was, maybe the 2.0 version is the actual 1.0 version they intended to launch in the first place. reply a_vanderbilt 7 hours agorootparentHonestly, yes. I played through the campaign on launch day and noticed a few bugs. The game felt pretty shallow. 2.0 brought to what I though it would be on launch day. Kinda wish I just waited a year or so for the 2.0 update before I played it. reply Tommah 12 hours agoparentprevDOTA 2 gets rebalanced constantly; certain characters are made stronger or weaker. Overwatch also received some major changes relating to team composition. reply dudul 12 hours agoparentprevThey definitely do rework modern games. I don't know if it's still technically EA but No Man's Sky gets massive patches regularly. MMOs also get game changing updates. reply FirmwareBurner 10 hours agorootparent> No Man's Sky gets massive patches regularly To be fair MMORPGs need to do taht to stay relevant. reply dudul 9 hours agorootparentDoes NMS count as an MMORPG? But to your point yes of course, MMOs that are subscription based need these updates. Regardless, parent was wrong. reply 0xDEADFED5 7 hours agorootparent> Does NMS count as an MMORPG? nah, I've personally only played it offline reply andix 6 hours agoprevWow, it's still alive. Around 20 years ago we modified the sprites of this game to create a new games featuring our classmates and friends. It was great fun. reply Intralexical 6 hours agoprevHow is Grumble, anyway? Has he found his sense of snow yet? reply Mathnerd314 5 hours agoparenthe's around on GitHub https://github.com/Grumbel reply danjoredd 13 hours agoprevclassic game reply tux 9 hours agoprevI approve this message. =) reply johnea 13 hours agoprev [5 more] [flagged] josephcsible 13 hours agoparentGitHub still works fine in Firefox. reply danjoredd 13 hours agoparentprevIf you want the source code, just get it off the website https://www.supertux.org/download.html reply jesprenj 13 hours agoparentprev [–] Which browser are you using? reply orblivion 13 hours agorootparent [–] And are you blocking 3rd party javascript etc? That's broken github for me before. There's githubassets.com and githubusercontent.com which you could allow; arguably they're not really third party. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SuperTux is a jump'n'run game reminiscent of Super Mario Bros, with players exploring various worlds, battling enemies, gathering power-ups, and aiming to save Penny.",
      "The game is downloadable on leading platforms and provides guidance on setup and gameplay, with avenues like IRC, forums, social media, and Discord for community assistance.",
      "Ongoing development for SuperTux includes upcoming enhancements and features for forthcoming versions."
    ],
    "commentSummary": [
      "The GitHub discussion about SuperTux involves its popularity in Portugal and its integration into a Portuguese Linux distribution.",
      "Users share experiences with related games like Tux Racer and follow the progress of SuperTuxKart.",
      "Additionally, the conversation touches on the continuous development and updates of contemporary games such as Minecraft and DOTA 2."
    ],
    "points": 236,
    "commentCount": 45,
    "retryCount": 0,
    "time": 1709062941
  }
]
