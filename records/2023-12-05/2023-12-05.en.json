[
  {
    "id": 38519012,
    "title": "Harvard disbands team analyzing Facebook Files after $500M Zuckerberg donation",
    "originLink": "https://live-whistleblower-aid.pantheonsite.io/joan-donovan-press-release/",
    "originBody": "Harvard Gutted Initial Team Examining Facebook Files Following $500 Million Donation from Chan Zuckerberg Initiative, Whistleblower Aid Client Reveals FOR IMMEDIATE RELEASE December 4, 2023 MEDIA CONTACT Radim Dragomaca, press@whistlebloweraid.org Harvard Gutted Initial Team Examining Facebook Files Following $500 Million Donation from Chan Zuckerberg Initiative, Whistleblower Aid Client Reveals University’s Former Disinformation Expert Joan Donovan Calls for Investigation WASHINGTON, D.C. – Harvard University dismantled its prestigious team of online disinformation experts after a foundation run by Facebook’s Mark Zuckerberg and his wife Priscilla Chan donated $500 million to the university, a whistleblower disclosure filed by Whistleblower Aid reveals. Dr. Joan Donovan, one of the world’s leading experts on social media disinformation, says she ran into a wall of institutional resistance and eventual termination after she and her team at Harvard’s Technology and Social Change Research Project (TASC) began analyzing thousands of documents exposing Facebook’s knowledge of how the platform has caused significant public harm.. In her whistleblower declaration, Donovan lays out in detail how she and her research team at Harvard’s Kennedy School (HKS) came under sudden scrutiny from the school’s dean, Douglas Elmendorf, and other Kennedy School leaders, after they started working on Haugen’s Facebook Files – a cache Donovan describes as “the most important documents in the history of the internet.” TASC rose in size, prominence, and resources under Dr. Donovan’s leadership – and Dr. Donovan was elevated to Research Director of the Shorenstein Center for her success. The importance and prestige of TASC’s work became irrelevant to Dean Elmendorf when in October 2021 Dr. Donovan announced she had lawfully received the Facebook Files at a HKS Dean’s Council meeting, which was attended by a Facebook PR executive who became irate when she discussed it. She intended to create a public archive with a collaborative platform, where participants could publish research and her team would host workshops for researchers and journalists on how to analyze the extensive trove of internal documents. Following the meeting, Dean Elmendorf began a two year campaign to purge Dr. Donovan, silence her voice, decrease her public profile, and stifle her team’s impactful research. Suddenly her work became a threat to some of HKS’s most treasured donor relationships – just as Harvard was finalizing the largest donation the school had ever received, $500 million from the Chan Zuckerberg Initiative in December 2021. HKS leadership systematically rendered TASC mute with an escalating series of restrictions and bureaucratic hurdles designed to stop their work and the power of Dr. Donovan’s research findings to challenge Meta’s false public narratives. Harvard’s own code of conduct and commitment to academic freedom was trampled in the campaign to silence Dr. Donovan – culminating in the dissolution of TASC and her termination this past summer. Meta could not use any of its previously reported tactics to silence other researchers as Dr. Donovan’s research neither relies on access to their data nor would she accept any grants affiliated with any company she researches. “The mood changed overnight. The work we were doing turned from a source of pride for Harvard into a source of shame,” wrote Dr. Donovan. “Instead of seizing on an extraordinary opportunity to further our knowledge of social media platforms and how they work hidden from public scrutiny, the university subjected my team and our projects to death by a thousand cuts.” In sending the lawful whistleblower disclosure to the President and General Counsel of Harvard University, the U.S. Department of Education, and subsequently to the Massachusetts Attorney General’s Office, Dr. Donovan and Whistleblower Aid are calling for an urgent and impartial investigation into inappropriate influence at the Harvard Kennedy School. “This is a shocking betrayal of Harvard’s academic integrity and the public interest,” said Libby Liu, CEO of Whistleblower Aid. “We’ve seen in the past how Big Tobacco, Big Energy and Big Pharma have succeeded in influencing, undermining, and co-opting research to protect their lies, their profits and evade accountability. Now Meta, with the complicity of a powerful ally, is following the same playbook. Whether Harvard acted at the company’s direction or took the initiative on their own to protect Meta’s interests, the outcome is the same: corporate interests are undermining research and academic freedom to the detriment of the public.” Dr. Donovan, now an Assistant Professor at Boston University, was hired by the Kennedy School in 2018 and served as the Director of TASC and was promoted to Research Director of the Shorenstein Center in early 2020. She lectured for several years on media manipulation and disinformation at HKS. Alongside her team, Dr. Donovan set out to make sure the public, lawmakers, regulators, and academics could all analyze the Facebook Files, opening the doors to unprecedented and transparent public collaboration allowing for public accountability. Her team’s vision of a global research collaborative that openly analyzes the Facebook Files remains, to this day, largely unrealized. At a time of unprecedented legal scrutiny of Meta by both states and the Federal Trade Commission, Meta has benefited tremendously from the curtailing, delaying, and undermining of this research by the Kennedy School leadership. This case represents a watershed opportunity for lawmakers, regulators, and academia to address the pervasive and detrimental tactics deployed by powerful and wealthy interests like Big Tech to influence vital public interest research. The inadequate safeguards that exist in law, regulation, practice, and academic integrity by universities require meaningful reform. “If the most powerful university in the world cannot safeguard the integrity of public interest research in the face of corporate influence-buying, what hope is there for any other research institution?” Libby Liu said. “What hope is there for rank and file academics seeking to pursue the truth and hold power to account?” ### Whistleblower Aid is a non-profit legal organization in Washington, D.C. supporting individuals who lawfully report government and corporate law breaking. It provides assistance to individuals in the United States and abroad seeking to disclose illegal conduct, including misconduct relating to government officials, securities fraud, sexual violence, and violations of tax, labor or environmental laws. In recent years Whistleblower Aid lawyers have represented Facebook whistleblower Frances Haugen and the intelligence community whistleblower whose disclosures led to the first impeachment of President Trump. « Joan Donovan Disclosure: Harvard Betrayed Academic Freedom and the Public Interest to Protect Meta Joan Donovan Declaration: Detailed Account of How Harvard Protected Meta from Research Scrutiny »",
    "commentLink": "https://news.ycombinator.com/item?id=38519012",
    "commentBody": "Harvard gutted team examining Facebook Files following $500M Zuckerberg donationHacker NewspastloginHarvard gutted team examining Facebook Files following $500M Zuckerberg donation (pantheonsite.io) 1127 points by anticorporate 17 hours ago| hidepastfavorite11 comments skilled 17 hours agoDecent article on the matter,https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2023&#x2F;12&#x2F;04&#x2F;joan-do...https:&#x2F;&#x2F;archive.is&#x2F;oKsbi reply dang 15 hours agoparentThanks—comments moved to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38517550, which has that article, which presumably gives more background.In a case like this it&#x27;s probably best to have the main link be the best third-party report and link to the advocacy site in the comments. reply ClickedUp 15 hours agorootparentMove the upvotes (1033 points in 2 hours). reply dang 14 hours agorootparentThat isn&#x27;t necessary—I rolled back the clock on the other submission and added enough upvotes that it would be on the front page. (Not quite as high as it was before, but that&#x27;s standard moderation for any sensational-indignant kind of story.) reply lossolo 15 hours agorootparentprevWhy didn&#x27;t you move upvotes also? Because of this it disappeared from the first place on the front page. reply dang 14 hours agorootparentIt&#x27;s still high on the front page - I was careful to ensure that (more at https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38521932).Even if we hadn&#x27;t changed the URL we would have downweighted the thread from #1. We generally moderate HN to downweight sensational-indignant stories—otherwise the front page would consist of nothing but that. This is standard practice on HN. reply java-man 13 hours agorootparentprevSomething I thought about when working on a news aggregator idea: for similar cases, where multiple sources report slightly different takes, have a kind of a submenu with the list of other sources. Like [similar] perhaps? reply dang 9 hours agorootparentYes, I definitely want to implement something like this at some point. There are higher priorities, and precious little time to write code, so I don&#x27;t know when we&#x27;ll get to it though. reply NilsIRL 7 hours agorootparentprevGoogle News? reply karmakaze 14 hours agoprevAt this rate of poisoning the brand, it&#x27;s almost time to take-the-money-and-run. reply lewdev 14 hours agoprev [–] Hmm... I could use some donations... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Harvard University disbanded its team of disinformation experts, led by Dr. Joan Donovan, after receiving a $500 million donation from the Chan Zuckerberg Initiative.",
      "The team at Harvard's Technology and Social Change Research Project was investigating Facebook's awareness of the harm caused by its platform.",
      "The whistleblower disclosure emphasizes the importance of protecting public interest research from powerful corporate interests and calls for an investigation into potential inappropriate influence at Harvard."
    ],
    "commentSummary": [
      "Harvard University has scaled back its team investigating the Facebook Files after receiving a $500 million donation from Mark Zuckerberg.",
      "The decision to reduce resources has sparked concerns about the university's independence in scrutinizing the social media giant.",
      "The move has raised questions about potential conflicts of interest and the impact on the objectivity of the investigation."
    ],
    "points": 1127,
    "commentCount": 11,
    "retryCount": 0,
    "time": 1701706198
  },
  {
    "id": 38519257,
    "title": "A Decade of Monitor Your Data: Reflecting on Have I Been Pwned",
    "originLink": "https://www.troyhunt.com/a-decade-of-have-i-been-pwned/",
    "originBody": "A Decade of Have I Been Pwned 04 December 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38519257",
    "commentBody": "A decade of Have I Been PwnedHacker NewspastloginA decade of Have I Been Pwned (troyhunt.com) 603 points by c5karl 17 hours ago| hidepastfavorite149 comments adameasterling 15 hours agoTroy Hunt is such a treasure. And for us web application developers, there is no excuse for not having protection against credential stuffing! While the best defense is likely two-factor [1], checking against Hunt&#x27;s hashed password database is also very good and requires no extra work for users!I don&#x27;t have anything to back this up, but my guess is that the vast majority of compromised user accounts comes from credential stuffing&#x2F;password re-use. It&#x27;s really surprising to me when I hear that huge companies don&#x27;t do this check.[2] It&#x27;s simple, easy, takes about a day to set up.If you&#x27;re a young CTO or early-stage engineer working on a web app and have never been targeted with a credential stuffing attack, let me tell you: It&#x27;s coming! It&#x27;s just a matter of time before it&#x27;s 1AM and your phone blows up; your site is getting hammered; you think it&#x27;s DDOS, but then realize most of the hits are on your login page, then realize that and then realize with a horrible feeling that some % of those hits are getting through the login page. You&#x27;ll be up all night dealing with it, and then you have to make breach notifications, and that really sucks.Troy Hunt&#x27;s free database will save you that heartache (probably). Just do it.1. https:&#x2F;&#x2F;cheatsheetseries.owasp.org&#x2F;cheatsheets&#x2F;Credential_St...2. Like 23andMe. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37794379 reply rockskon 13 hours agoparentAbout a decade back, I was at an event that had an FBI employee presenting. During his presentation, he had mentioned a story of a sys admin who had been arrested for taking a hashed PW database in his company, comparing the hashes against known compromised one&#x27;s (perhaps from haveibeenpwned?), and forced a password reset for everyone who had reused a password that had separately been compromised and sent an email to each employee explaining this.One of the employees was apoplectic at the actions of the sys admin and had accused him of violating her privacy by doing this. While I do not recall which party initiated legal action against the sys admin that led to his arrest (i.e. the employee or the company), the bottom line of the story was that the FBI employee (and, by extention, whichever judge was involved in adjudication the case) considered the act of a sys admin accessing password hashes placed under his care to be a criminal breach of privacy regardless of his intent being to improve his company&#x27;s security against password stuffing attacks.Assuming the FBI employee didn&#x27;t just make the whole thing up (which I have no reason to believe - there are a lot of tech-stupid judges and, especially a decade ago, tech-stupid FBI employees), it might be prudent to pass this by your legal team before checking for password hashes for your employees being in haveibeenpwned. reply adameasterling 13 hours agorootparentThe FBI feeds data into Troy Hunt&#x27;s database and FBI Director Christopher Wray gave Troy Hunt a medal for his work [1].The Open Web Application Security Project&#x27;s Application Security Verification Standard recommends that you do a hashed password check [2].For bigger companies, sure, go talk to legal, but for young startups, my feeling is it&#x27;s not worth the $200 or whatever your counsel will charge to say it&#x27;s ok. I personally did not ask anyone (am cto), I just added the check.1. https:&#x2F;&#x2F;twitter.com&#x2F;troyhunt&#x2F;status&#x2F;16741328018374778882. See OWASP ASVS 4.0 2.1.7 https:&#x2F;&#x2F;github.com&#x2F;OWASP&#x2F;ASVS&#x2F;blob&#x2F;master&#x2F;4.0&#x2F;en&#x2F;0x11-V2-Aut... reply rockskon 13 hours agorootparentThe whole situation did seem pretty exceptional when I heard it and I felt like I was being exposed to an alternate reality where lawyers made security worse for everyone.That said I struggle to believe the sys admin had competent representation. reply CoffeeOnWrite 13 hours agorootparentThey forced a password reset. You can use HIBT data in a way that&#x27;s less disruptive. reply betenoire 8 hours agorootparentnot a crime reply Exoristos 7 hours agorootparentTell it to the judge. reply no_wizard 8 hours agorootparentprevIt is worth it, that $200 dollars gives you lots of credibility to stand on if something should arise and you need to prove diligence, which is not at all uncommon in these cases, if legal recourse is ever saught (unlikely if you do it from day 1, I think, but never the less) reply CoffeeOnWrite 13 hours agorootparentprev> sys admin accessing password hashes placed under his careParent commenter never mentioned anything about comparing stored password hashes. What you do is block bad passwords at password set time by hashing the prospective password and comparing with HIBP. A prospective password you haven&#x27;t accepted or stored or transmitted off the application server - common sense says that&#x27;s not a privacy violation - and many giant companies including my employer do this routinely.[Edit] Oh yea I remember HIBP has an online API. Don&#x27;t use this. Take the HIBP dumps that they make freely available and compare locally. If not for reasons of privacy, for reasons of simplicity and removing an unnecessary external business&#x2F;legal&#x2F;software dependency. reply twisteriffic 6 hours agorootparent> Oh yea I remember HIBP has an online API. Don&#x27;t use this.That&#x27;s not the greatest advice IMO. The API gets updated data more frequently, doesn&#x27;t require that you transmit the password or a useable hashed form, and it&#x27;s dead simple to consume. I&#x27;d argue that it&#x27;s more effort to maintain an internal store and synchronization infrastructure, and you&#x27;re less likely to accidentally breach anonymity and leak a weak hash by using the API than you are rolling your own query against the raw data.It&#x27;s also used by hundreds of bigcorps and government agencies who have way more pedantic lawyers than you&#x27;re likely to have. If they couldn&#x27;t find a good reason not to use it I doubt yours will. reply berkes 1 hour agorootparentThose are good arguments for using an online service. But your conclusion is premature and certainly cannot be made blanket like that in favor of using the API.Just as many arguments can be made for an offline check. Or against an online check. From added latency via required uptime to added dependencies.My point being: no. \"It depends\" reply Vicinity9635 13 hours agorootparentprevIdeally, but what if you&#x27;re a new hire and the passwords already exist? reply CoffeeOnWrite 12 hours agorootparentBe satisfied with fixing the new passwords going forward. Or gracefully force a new password for everyone, if circumstances permit that (circumstances including decision making authority; if you are the new CTO or CISO, and you&#x27;re paranoid about reviewing the existing hashes, you should strongly consider the batched graceful forced reset!)You can set a flag on login to use the password in memory rather than stored. reply uxp8u61q 12 hours agorootparentThat&#x27;s how you get the whole company to love you as a new CTO - force everyone to change their password, including people who have a strong non-reused password. reply CoffeeOnWrite 10 hours agorootparentWe’re evaluating different options in this thread. The right move is based on the circumstances and your judgement. I would support a new leader with the courage to close a security hole, maybe respect them even if I don’t love them.By the way, I don’t feel paranoid to flag bad passwords on login (perhaps triggering an email OTP and forcing a password reset), personally. I responded to this thread because a commenter made an unfounded implication about using HIBP data to reduce vulnerability to credential stuffing. reply pavel_lishin 10 hours agorootparentprevYour job as a CTO isn&#x27;t to be loved by the entire company. replybrianpan 11 hours agorootparentprevBesides legal, I think it&#x27;s important to realize that there is a very emotional response to discovering that your password is not good.I know a company that started doing quarterly brute-forcing of passwords as a security check and the reaction to finding out that your password is not strong enough is....all sorts of emotions.If you have a 10-12 character password that may have been strong at one point but now is not and your IT team is informing you, you&#x27;re reaction is NEVER, oh thank you for helping me out. It&#x27;s not stupidity, it&#x27;s human nature to feel attacked. reply dano 9 hours agorootparentAs part of fixing security problems 20+ years ago we put together a migration process that included cracking passwords. First off we created an interface for updating your password and that interface essentially ran through all the tests that the cracking software to better ensure you&#x27;d picked something good. Passwords were expired every 90 days (remember, this was 2001. The migration first set the expiration date so that people got used to the process and then, on occasion, we&#x27;d run the passwords through a brute force attack. To your point, the users were most unhappy when their password would get cracked and expired, but that&#x27;s life. 2FA, keys, etc.. is really an improvement over what we&#x27;ve had for such a long time. reply doix 4 hours agorootparentprevWhen a 12 character gets bruteforced, my initial reaction is to blame the system for allowing so many password attempts!Like imagine how many failed attempts must&#x27;ve happened for a 12 character password to get bruteforced. Alarms should have been raised way before it became an issue. reply barkingcat 37 minutes agorootparentwhat if it was a crappy 12 character password like 123456789012 and got bruteforced in 2 tries?also, at one point it was popular to use l33t speak for passwords so there are many crappy 12+ char l33t passwords floating around that are trivial to guess, no brute forcing required. reply 1vuio0pswjnm7 10 hours agorootparentprevWould it matter which hash function was used to create the password database.But there&#x27;s more than just the issue of discovering the passowrd itself.What about the issue of discovering that a particular password hash comes from an employee at a certain company.As I understand it, Tory Hunt downloads dumps of stolen passwords. He does not share the dumps. Instead he collects queries, like a search engine. Until people start sending him queries of hashes to check he does not necessarily know the locations of the people whose passwords were stolen.However if he gets a series of hashes sent from some IP address belonging to a perticular corporation, then argubaly he now knows these are likely to be passwords belonging to employees at that corporation. reply twisteriffic 6 hours agorootparentThe API doesn&#x27;t require the full hash, just a short prefix. They don&#x27;t have enough information for your scenario to work.https:&#x2F;&#x2F;www.troyhunt.com&#x2F;understanding-have-i-been-pwneds-us... reply hirsin 3 hours agorootparentprevI certainly believe it a user was upset by it. We&#x27;ve gotten support tickets before from users accusing of of \"snooping on their local machine\" to find passwords... Like no, it was just in a breach, relax.They&#x27;re often now upset they&#x27;ve been called to task so it&#x27;s just hard all around. reply TacticalCoder 13 hours agorootparentprevAccessing password hashes already in a DB is not the same as preventing, during account creation, the reuse of a password known to be compromised.If I&#x27;m not mistaken it&#x27;s all done using cryptographic schemes that leak neither the password nor the hash. reply adameasterling 13 hours agorootparentThis is true. The story as written probably didn&#x27;t happen with HIBP&#x27;s database. Troy Hunt&#x27;s database only includes SHA-1 hashes, and passwords in your own database will be hashed with a stronger algorithm (hopefully) and salted (hopefully), so you can&#x27;t do a simple hash-to-hash comparison. The way to do a HIBP check is, when a user signs in, you hash their password in the way HIBP expects, and check that against either their API or against a local copy of HIBP&#x27;s database, and if a hit is returned, you give them a nice message and direct them to the password reset flow. There&#x27;s no easy way to use HIBP&#x27;s data to identify users with compromised passwords until users actually try to log in. reply kranke155 13 hours agorootparentprevI would love to get a proper source on this. Seems a bit crazy, and wouldn&#x27;t this be thrown out on appeal? reply rockskon 13 hours agorootparentUnfortunately I have no source to give. The FBI employee was just giving an example of illegal behavior he knew of. He didn&#x27;t cite jurisdiction or the names of people involved. Hell - even if he did, I likely wouldn&#x27;t have remembered it as this was roughly 8 years ago I was in the audience for this (I know I said roughly a decade ago in my prior post - but I checked a receipt for the event and it was in 2015). reply bigiain 10 hours agorootparentQuite likely Randal Schwartz.\"In July 1995, Schwartz was prosecuted in the case of State of Oregon vs. Randal Schwartz, which dealt with compromised computer security during his time as a system administrator for Intel. In the process of performing penetration testing, he cracked a number of passwords on Intel&#x27;s systems. Schwartz was originally convicted on three felony counts, with one reduced to a misdemeanor, but on February 1, 2007, his arrest and conviction records were sealed through an official expungement, and he is legally no longer a felon.\" -- https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Randal_L._Schwartz reply terminous 9 hours agorootparentImportant aspect: he had been fired and cracked passwords while no longer an employee, to try to get rehired:\"Rather ill-advisedly, the Perl-programming guru (who&#x27;s written several books on the subject) tried to prove his worth by running a password cracking package after he&#x27;d left in order to produce evidence that security practices had deteriorated since his departure. Instead of re-hiring Schwartz, as he hoped, Intel called in the police and he was charged with hacking offences.\"https:&#x2F;&#x2F;www.theregister.com&#x2F;2007&#x2F;03&#x2F;05&#x2F;intel_hacker_charges_... reply fragmede 8 hours agorootparentprevWikipedia is a little light on the details. How much time did he end up serving, and were there any repercussions for the other parties involved? reply vasco 11 hours agorootparentprevReally hard to belief without anything else to go by. This sounds like old wives tales like people that add disclaimers saying they aren&#x27;t laywers when they comment on the internet because someone once told them they heard someone got in trouble. reply resonantjacket5 10 hours agorootparentDoes it sound that unbelievable for the 2010s? There was quite a discrepancy between how the internet&#x2F;computers were generally being used and the legality.Like https:&#x2F;&#x2F;www.eff.org&#x2F;deeplinks&#x2F;2016&#x2F;07&#x2F;ever-use-someone-elses... > Last week, the Ninth Circuit Court of Appeals, in a case called United States v. Nosal, held 2-1 that using someone else’s password, even with their knowledge and permission, is a federal criminal offense.Also, the courts only just legalized white hacking last year. Before that violating the terms of service was also potentially a federal crime. https:&#x2F;&#x2F;www.spiceworks.com&#x2F;it-security&#x2F;security-general&#x2F;news... reply virtue3 13 hours agorootparentprevJobs can ask if you have ever been arrested outside of CA. (Note: not convicted of a crime).Also you are going to spend a long time being arrested before the appeal goes out.\"In California, a criminal appeal can take several months to several years. The length of time depends on the complexity of the case and how quickly it moves through the appeals process.\" reply incahoots 13 hours agorootparentprevWell this unlocked a new fear I didn&#x27;t know I needed to have. I suppose this is the massive drawback to allowing dinosaurs to spearhead policy and govern laws. reply rockskon 13 hours agorootparentFor what it&#x27;s worth, the average tech-smarts in the legal realm and within the FBI are significantly improved compared to 8 years ago. This is just from my personal observation.That said, there are still tremendous gaps yet to be bridged with the understanding of many procecutors and lawyers as well as weird applications of the law that aren&#x27;t intuitive to people whose life is technology.For example (and I caveat this with IANAL): Did you know the physical medium you get Internet to your house determines what laws and processes the government can use to monitor your Internet traffic? reply incahoots 11 hours agorootparent>Did you know the physical medium you get Internet to your house determines what laws and processes the government can use to monitor your Internet traffic?That I did know, only because I was dumb enough to hitch my wagon to Comcast&#x2F;Xfinity as a headend tech for years. Just affirmed the idea that all ISPs should be community owned. reply eszed 11 hours agorootparentprev> the physical medium you get Internet to your house determines what laws and processes the government can use to monitor your Internet traffic?I did not! Do you have &#x2F; know a good explanation of the details? reply rockskon 8 hours agorootparentFrom my (non-lawyer) understanding, if you have a coax cable connected to a cable modem providing Internet to your residence, your privacy is governed by https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;uscode&#x2F;text&#x2F;47&#x2F;551Other means of Internet getting to your residence is covered by Title 3 of the ECPA which, historically, Feds have played fast and loose with getting data from. reply zlg_codes 7 hours agorootparentprevWhy are good deeds punished so much by authorities?This is a good way to disincentivize prosocial behavior. reply bruce511 4 hours agorootparent>> Why are good deeds punished so much by authorities?The problem can be \"who defines good deeds?\" There are so many things which seem good when presented one way, but can be harmful when viewed another way. Obviously, as presented above this seems like \"an obvious good\", but context matters, snd clearly you don&#x27;t get the whole context from a one paragraph summary.Ultimately we have civil structures (government at every level) that tries to codify \"good\" and \"bad\". Life is seldom that clean though, so inevitably every regulation and law is good for some bad for others.So, to answer your question, because \"good\" and \"prosocial\" are not universally true. reply BonoboIO 9 hours agorootparentprevI‘m flabbergasted how broken the system is.It sounds like it was made up, should not be so hard to find the verdict. reply stuckkeys 10 hours agorootparentprevHmm. Interesting. Shitty outcome if true, but AD&#x2F;Azure AD has an extension (3rd party if I recall) that automatically checks for breached passwords and lets the user know and forces them to change their password. reply yashap 7 hours agoparentprevBesides 2FA, rate limiting your login endpoint (both by IP address and username) is a much more robust protection against this attack. Especially if you include temporary bans (e.g. “20 failed login attempts with the same IP, and&#x2F;or same username, in the past minute = 15 minute ban for that IP and&#x2F;or username”). A lot of API gateways, K8s ingresses, etc. make this dead simple, and if not it’s also super easy to add with a few lines of code and something like Redis to store counts of recent login attempts.I do think checking against the HIBP DB is a good call too, but it doesn’t stop this attack overly well, rate limiting is a much better way to stop it. reply santiagobasulto 12 hours agoparentprevSorry, I don&#x27;t understand the procedure. If the database contains hashed passwords (I haven&#x27;t seen or download the database), how can you know you&#x27;re using the same salt and method that the one in the datbase?For example, let&#x27;s say Tumblr was hacked and with it my password `hunter2`. Tumbler used some naive HMAC-MD5 method with a salt, but my site uses argon2 with (obviously) a different salt. Even though my password is the same (`hunter2`) the resulting hashed passwords will be different. How is this any effective preventing credential stuffing? reply Denvercoder9 11 hours agorootparentThe HIBP database only stores hashes of leaked passwords, but the source material is often (always?) plaintext passwords. If the hash of a password is in the HIBP database, the plaintext password is out there somewhere in a database of a malicious actor. reply that_guy_iain 52 minutes agorootparent> If the hash of a password is in the HIBP database, the plaintext password is out there somewhere in a database of a malicious actor.My understanding this isn&#x27;t true. These leaks are often just the password hashes. reply adameasterling 12 hours agorootparentprevOne can only implement a HIBP check when one has access to the user&#x27;s unhashed password. So, at login, registration, and password reset. reply santiagobasulto 12 hours agorootparentYes, exactly, so that&#x27;s why I was asking, you mentioned the database was of hashed passwords. The database then contains the source passwords? And you&#x27;re preventing the user from using one of those passwords?Sorry, I still don&#x27;t understand the procedure you mentioned and I&#x27;m genuinely curious. reply adameasterling 11 hours agorootparentOh, I see the issue. The HIBP database is SHA-1 hashed with no salt. It was created from unhashed passwords. You can&#x27;t download the unhashed version (you could of course compute it, if you really wanted to; but there&#x27;s no need).So, the procedure you need to implement is, on login&#x2F;registration&#x2F;pw reset, you SHA-1 hash the user&#x27;s unhashed password and do a indexed lookup on your copy of HIBP&#x27;s database. Or if you don&#x27;t want to maintain that copy, you can use HIBP&#x27;s API to do something similar. reply santiagobasulto 11 hours agorootparentAh! Thanks a lot, it now makes sense. So at some point HIBP has the unhashed passwords, they obviously don’t make those public, good trick. How do you handle this from a UX perspective? Just tell the user that password is “not strong enough”? reply aareet 7 hours agorootparentPassword managers that have HIBP integration are open about it - one says \"this password appears in a list of compromised passwords\" replysolatic 4 hours agoparentprev> If you&#x27;re a young CTO or early-stage engineer working on a web appIf you&#x27;re working on a greenfield login&#x2F;auth, please don&#x27;t accept and store passwords in a database! Setup social OAuth, SSO, or magic link emails and make it someone else&#x27;s problem. reply g_p 57 minutes agorootparentIf you do go down this route though, be sure to read up on what you&#x27;re deploying, and understand what your libraries are doing (and more importantly, not doing).You don&#x27;t want to end up with a naive implementation of OAuth2 (like some big names had recently) which fails to check the audience parameter, and therefore lets anyone other service using the same SSO gain access to your users&#x27; accounts.Recent HN post on this - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38009291 reply KolmogorovComp 12 hours agoparentprev> ... and then realize with a horrible feeling that some % of those hits are getting through the login page.(Non sarcastic), why would you feel bad for users using 1234 as their passwords? Unless your website is aimed at vulnerable people, I consider this to be their responsibility.As other comments have said these users will probably go the easiest route (1234websitename) to fix the error.Any restriction you put on your password field reduces entropy, and safety for everyone (even if marginally so). reply CoffeeOnWrite 10 hours agorootparentHave you ever operated an online business? Poor password choice is practically harmful to business. Marginal reduction of entropy by blocking breached passwords, what&#x27;s the practical harm from that?1234websitename is objectively better than 1234.I&#x27;ll go with NIST on this one (yes, and have a minimum length too):> When processing requests to establish and change memorized secrets, verifiers SHALL compare the prospective secrets against a list that contains values known to be commonly-used, expected, or compromised... If the chosen secret is found in the list, the CSP or verifier SHALL advise the subscriber that they need to select a different secret, SHALL provide the reason for rejection, and SHALL require the subscriber to choose a different value.https:&#x2F;&#x2F;pages.nist.gov&#x2F;800-63-3&#x2F;sp800-63b.html#memsecret reply cqqxo4zV46cp 11 hours agorootparentprevBecause anyone that has ever been responsible for anything knows that there’s a difference between something being your fault and something being your problem.Breach notification etc legislation in some jurisdictions will also require that you report successful widespread credential stuffing.Even AWS with their “shared responsibility model” works with GitHub etc to ensure that programmatic access credentials aren’t accidentally exposed via public repositories. This isn’t credential stuffing, but it’s a blindingly accurate demonstration of the fact that drawing a line in the sand and saying “users, work it out from here!” and attempting to wash your hands of the situation is nothing more than the ill-informed pipe dream of someone that’s never had to deal with this stuff in reality. reply LeifCarrotson 14 hours agoparentprev> ... and then realize with a horrible feeling that some % of those hits are getting through the login page.The alternative is the exact same scenario, except that the percentage is several orders of magnitude lower, right?The small subset of your users that explicitly opted-out of 2-factor authentication (if you allow that) and who try to choose \"Password1!\" with a second exclamation point when your site said \"Error, your password has seen 83,000 times in password dumps, please use a unique password\" will still get hacked.Or is your expectation that no one will attack every user on your webapp with a credential stuffing attempt if they see that the probability of success is 0.001% instead of 1%? reply cedilla 12 hours agorootparentWait, a thousand fold decrease is not worth it?Your numbers literally turns a scenario where 200,000 accounts are hacked into one where 200 are exposed. Or one where 30 hacked accounts turn into 0 hacked accounts.There is a point where a difference in quantity becomes a difference in quality. I far prefer the latter scenarios. reply cqqxo4zV46cp 11 hours agorootparentAnybody (like GP) that doesn’t understand that this is entirely the nature of security work, should not be making any material decisions about security.The number of times I’ve seen DEVELOPERS neglect to implement materially useful security measures because “they’re not technically perfect!” Is astounding. reply mulmen 14 hours agorootparentprevThe bad feeling comes from knowing you could have reasonably done something to mitigate the harm. Don&#x27;t let perfect be the enemy of good.Remember that \"identity theft\" is marketing fluff. In a credential stuffing attack your business is the victim of fraud. reply adameasterling 12 hours agorootparentprevYes, same scenario, but far fewer logins are successful. 3 orders of magnitude sounds right, but I don&#x27;t know precise numbers. (Can others shed light?) Three orders of magnitude is a lot! reply Sephr 12 hours agoprevI have memories of this site providing me with an excellent experience. Now it&#x27;s just a cash-grab, asking for $169.50&#x2F;year just to see 100 breached accounts!I use unique email addresses (breach canaries) on every website to detect when sites leak my data. When I tried to search for my domain results with a previous domain ownership verification, I got hit with this error: \"In order to search a domain with any more than 10 breached accounts on it, you need a sufficiently sized subscription\"To make matters worse, Troy includes public data compilations as &#x27;breaches&#x27; which artificially inflates counts for the breached accounts quota. For example, when a compilation of public contact details scraped from GitHub leaked, Troy counted that as a breach. I explicitly listed my email address as public.I&#x27;d be willing to pay $5-12&#x2F;year. These rates are outrageous for such a low-overhead service. reply eganist 10 hours agoparentEncountered the same. My hope is that there&#x27;s a pricing scheme for people like us; may be worth reaching out. reply aaronharnly 10 hours agorootparentI’m in the same boat — not a company, just an individual doing the separate-email-per-site thing.(UPDATE): I’ve posted a suggestion to the UserVoice community, which it appears Troy actively monitors.If the several (dozens?) of us with this use case upvote it, it may catch his attention.https:&#x2F;&#x2F;haveibeenpwned.uservoice.com&#x2F;forums&#x2F;275398-general&#x2F;s... reply aaronharnly 8 hours agorootparentTroy responded: https:&#x2F;&#x2F;haveibeenpwned.uservoice.com&#x2F;forums&#x2F;275398-general&#x2F;s...Basically he suggested doing a monthly subscription for just one month periodically as a way to reduce the cost.Another option is to read the notification email, and if it’s for Acme Corp, to remember that the associated email must be acme.com@mydomain.com, and then manually check that. reply benced 11 hours agoparentprevYou’re doing a weird thing (running your own email domain), doing an even weirder thing (using a different address per site), and then doing an even more weirder thing (scanning your personal domain for breaches) and your supposition is that very specific use case is a cash cow for Troy Hunt? Come on. reply Sephr 11 hours agorootparentI said cash-grab, not cash cow. A cash grab is something that has an unreasonably high profit margin. A cash cow is something that provides a significant portion of an entity&#x27;s income.I have no idea if HIBP is a cash cow for Troy. It may be, given these prices, but I don&#x27;t know much about his other sources of income.HIBP didn&#x27;t start out as a cash-grab, but it is one now. Troy could have chosen to price it reasonably to cover the costs of the service. This pricing is clearly taking advantage of HIBP&#x27;s popularity as the de-facto breach list site. reply ehhthing 8 hours agorootparentI can&#x27;t tell whether this is a joke or not.I would bet you that over 99.99 percent of HIBP&#x27;s users do not pay for the service. Troy&#x27;s time has value, so working on a service that provides no income is not really something you can expect a person to do. Troy decided to create an enterprise subscription service to get a bit of revenue from something he&#x27;s created. It&#x27;s not cheap, but it&#x27;s not something you&#x27;re meant to buy unless you&#x27;re a company looking to monitor your employee email addresses. This service is pretty cheap in that regard, actually.I really do not understand why you feel that you&#x27;re being ripped off here. This is just a lack of product-user fit, his pricing structure simply doesn&#x27;t work for you because you use email canaries. But for a company with 100 people, this pricing is entirely reasonable, if not something incredibly cheap.What you&#x27;re paying for is everyone who doesn&#x27;t pay for the service, the time he takes to add new breaches to the service and the time he takes to develop the service.Just because their pricing model doesn&#x27;t fit you doesn&#x27;t mean it&#x27;s a cash grab. Is this too hard to understand?EDIT: Also, I assumed this was a common understanding, but product pricing is based on the value it gives to the person buying. For a company of 100 people, do you think paying $160&#x2F;yr is worth breach monitoring? I think for any IT department, this would be a no-brainer. reply Sephr 4 hours agorootparentThe cost of this service doesn&#x27;t scale with number of &#x27;breached accounts per domain&#x27;. Ideally, Troy should charge per domain and only choose a modest profit margin. reply rkagerer 8 hours agorootparentprevdoing an even weirder thing (using a different address per site)It should actually be considered best practice. reply tptacek 8 hours agorootparentIt is not. reply Sephr 7 hours agorootparentNot yet. Best practices can change. reply tptacek 7 hours agorootparentBest practices have two attributes, both of which represent consensus among practitioners in the field: that it produces an optimal outcome, and that it can reasonably be broadly adopted.Email canaries clearly flunk the second test. reply Sephr 5 hours agorootparentIt seems like Apple iCloud Private Email Relay may be Apple&#x27;s own stealth way to introduce similar functionality, albeit with the useful spam&#x2F;leakage data only available to Apple in this case. replydotancohen 11 hours agorootparentprevI do the exact same thing. Every site, service, and contact gets a personal something@mydomain email address to reach me. reply cheschire 11 hours agorootparentSomewhere in the distance, the Count from Sesame Street says \"TWO... ah ah ah...\" reply acheong08 1 hour agorootparentprevI do the exact same thing minus the breach scanning. It’s not uncommon. reply stuckkeys 10 hours agoparentprevYou can download the DB from the DarkNet and run it locally so you don’t have to pay. The only downside is, you have to manage this db yourself and frequently update it. But it is similar. I have seen lot of these (cash-grab) services pop up offering API DB access for a cost. reply paulpauper 10 hours agorootparentthis is the way. you never want to alert someone to the fact your address is possibly vulnerable in the first place reply paulpauper 10 hours agoparentprevanother example of \"everything as a service\". Bullshit freemium model where a service starts out good, and then once they start getting usage: put the functionality behind paywall and degrade the free service to the point of being useless. Facebook, as bad as it is, has not succumbed to this: &#x27;free Facebook&#x27; is still as functional as it was in 2010, but more tracking obviously. reply rkagerer 8 hours agorootparentbut more tracking obviouslyThat&#x27;s a price of its own. reply user_7832 16 hours agoprev> Not to mention all the other weird variations including haveibeenburned.com, haveigotpwned.com, haveibeenrekt.com and after someone made the suggestion following the revelation that PornHub follows me, haveibeenfucked.comThat is honestly pretty hilarious of a side effect of media fame! reply m3047 15 hours agoparentI&#x27;ve always loved pornhub&#x27;s blog: https:&#x2F;&#x2F;www.pornhub.com&#x2F;insights&#x2F; reply Cthulhu_ 14 hours agoparentprevThat last one would be an interesting repository of revenge porn, although it&#x27;s illegal to distribute it in a lot of jurisdictions.Although, maybe it could be a database of facial recognition hashes from revenge porn, and you can upload a similar hash of your own face to see if you&#x27;re online somewhere? reply gumby 16 hours agoparentprev> haveibeenfucked.comYears ago we had friends, a couple in which the wife was pregnant. They were actually a bit embarrassed that “everyone will know that we ‘did it’”. A level of squeamishishness I could not have imagined! reply koolba 15 hours agorootparent> They were actually a bit embarrassed that “everyone will know that we ‘did it’”.Most people would be more embarrassed if the wife is clearly pregnant and nobody thinks they “did it”. reply yesbabyyes 11 hours agorootparentI remember reading about something like that in a book, think they were called Mary & Joseph. reply lainga 15 hours agorootparentprevHaha, yes, for the same reason it used to be rude to ask \"when are you expecting?\", especially if newly married reply lainga 11 hours agorootparent(too late to edit...) P.S. Not in the sense of \"when will you have a baby\", in the sense of \"was the baby conceived before the marriage\" reply romanhn 12 hours agorootparentprev\"Still practicing\" is as good an answer as any reply onionisafruit 15 hours agorootparentprevThat reminds me of my early twenties being embarrassed when my wife told her parents we are trying to get pregnant. reply gumby 10 hours agorootparentWhen people would ask us, “when will you have a second baby?” we started to answer, “oh, we figured out what causes it!” which usually shut down that line of questioning. reply saagarjha 9 hours agorootparentprevThe alternative sounds worse, no? reply dylan604 14 hours agoparentprevIt just proves that rules of the internet work. If it exists, there&#x27;s a porn version of it. reply prepend 15 hours agoprevI really like his informative posts. I remember reading about how he used k-anonymity to check passwords against the pwned file without having to transmit the passwords and it led to me studying that and later using it for some professional projects.I sometimes think what I would have done had I never read his posts about checking without transmitting real PII. reply gnyman 12 hours agoparentThe k-anonymity is such a clever trick, I remember being impressed by the simplicity and efficacy of it back when I read about it also.I&#x27;d also like to call out the one who Troy says suggested him [1], Junade Ali who goes into more details about this in his post about it [2]Not because Junade would have invented it (apparently that was Pierangela Samarati, Latanya Sweeney and Tore Dalenius. [3]) but because his blog post on it is a really great explainer of it using concepts software developers are familiar with.[1] https:&#x2F;&#x2F;www.troyhunt.com&#x2F;ive-just-launched-pwned-passwords-v... [2] https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;validating-leaked-passwords-with... [3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;K-anonymity reply agentultra 14 hours agoprevBlackmail scammers have been using pwned password databases to craft some pretty convincing phishing emails (\"I have installed RAT on your system and have been watching you through your webcam, proof I hacked you:-- send $1800 of BTC to this address and don&#x27;t go to the police. Maybe use a password manager next time.\"). Do people get caught in these scams?I assume most get blocked by spam filters. I&#x27;ve only noticed them when they get past SPI&#x2F;DKIM filtering and I have to train more. They seem pretty clever.I appreciate the service and enjoy Troy Hunt&#x27;s posts. HIBP is great. reply mtmail 10 hours agoparentA family member called me in distress asking if the email is legic. It had his full postal address and last 4 digits of a credit card (not an old password). People do believe it. reply cafard 14 hours agoparentprevCaught, I can&#x27;t say. I have heard of users becoming alarmed and running to IT for reassurance.I got one or two of these emails, and couldn&#x27;t for the life of me guess on what sites I had used the (pretty weak) passwords. reply _benj 14 hours agoparentprevI mean, I once got an email with my password in plain text and it was pretty disturbing. I did a quick search and realized that that password wasn’t used in anything I cared about so, I just went about my day, still disturbed but knowing that it’s an old password.I can’t imagine how it would feel if I didn’t use a password manager and couldn’t quickly see where was that password used instead of wreaking my brain trying to remember! reply 49 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Have I Been Pwned is a website that helps users check if their personal information has been compromised in data breaches.",
      "The website, created by Troy Hunt, celebrates its 10-year anniversary.",
      "The article emphasizes the significance of secure passwords and online privacy in the current digital landscape."
    ],
    "commentSummary": [
      "Protecting against credential stuffing attacks is crucial for maintaining online security.",
      "Troy Hunt's hashed password database can provide an additional layer of security.",
      "The debate on password hashes, API vs internal store, and the emotions surrounding weak passwords is ongoing.",
      "Legal complexities surrounding password usage are also discussed.",
      "Internet privacy regulations, punishment for good deeds, and user frustration with pricing on the Have I Been Pwned website are mentioned.",
      "Online security experiences and the popularity of Pwned Passwords are covered.",
      "The dangers of scam emails are highlighted."
    ],
    "points": 603,
    "commentCount": 149,
    "retryCount": 0,
    "time": 1701707215
  },
  {
    "id": 38517099,
    "title": "Introducing Django 5.0: New Features and Urged Upgrades",
    "originLink": "https://www.djangoproject.com/weblog/2023/dec/04/django-50-released/",
    "originBody": "Django The web framework for perfectionists with deadlines. Menu Toggle theme (current theme: auto) Toggle theme (current theme: light) Toggle theme (current theme: dark) Toggle Light / Dark / Auto color theme Overview Download Documentation News Community Code Issues About ♥ Donate Toggle theme (current theme: auto) Toggle theme (current theme: light) Toggle theme (current theme: dark) Toggle Light / Dark / Auto color theme News & Events Django 5.0 released Posted by Natalia Bidart on December 4, 2023 The Django team is happy to announce the release of Django 5.0. The release notes cover a deluge of exciting new features in detail, but a few highlights are: The database-computed default values allow for defining database-computed defaults to model fields. Continuing the trend of expanding the Django ORM, the generated model field allows the creation of database generated columns. The concept of a field group was added to the templates system to simplify form field rendering. You can get Django 5.0 from our downloads page or from the Python Package Index. The PGP key ID used for this release is Natalia Bidart: 2EE82A8D9470983E. With the release of Django 5.0, Django 4.2 has reached the end of mainstream support. The final minor bug fix release, 4.2.8, was issued today. Django 4.2 is an LTS release and will receive security and data loss fixes until April 2026. All users are encouraged to upgrade before then to continue receiving fixes for security issues. Django 4.1 has reached the end of extended support. The final security release (4.1.13) was issued on November 1st. All Django 4.1 users are encouraged to upgrade to Django 4.2 or later. See the downloads page for a table of supported versions and the future release schedule. Back to Top Additional Information Support Django! jesus cova donated to the Django Software Foundation to support Django development. Donate today! Upcoming Events DjangoCon Europe 2024 June 5, 2024Vigo, Spain 🇪🇸 Want your event listed here? Archives 2023 December 2023 November 2023 October 2023 September 2023 August 2023 July 2023 June 2023 May 2023 April 2023 March 2023 February 2023 January 2023 2022 December 2022 November 2022 October 2022 September 2022 August 2022 July 2022 June 2022 May 2022 April 2022 March 2022 February 2022 January 2022 2021 December 2021 November 2021 October 2021 September 2021 August 2021 July 2021 June 2021 May 2021 April 2021 March 2021 February 2021 January 2021 2020 December 2020 November 2020 October 2020 September 2020 August 2020 July 2020 June 2020 May 2020 April 2020 March 2020 February 2020 January 2020 2019 December 2019 November 2019 October 2019 September 2019 August 2019 July 2019 June 2019 May 2019 April 2019 March 2019 February 2019 January 2019 2018 December 2018 November 2018 October 2018 August 2018 July 2018 June 2018 May 2018 April 2018 March 2018 February 2018 January 2018 2017 December 2017 November 2017 October 2017 September 2017 August 2017 July 2017 June 2017 May 2017 April 2017 March 2017 February 2017 January 2017 2016 December 2016 November 2016 October 2016 September 2016 August 2016 July 2016 June 2016 May 2016 April 2016 March 2016 February 2016 January 2016 2015 December 2015 November 2015 October 2015 September 2015 August 2015 July 2015 June 2015 May 2015 April 2015 March 2015 February 2015 January 2015 2014 December 2014 November 2014 October 2014 September 2014 August 2014 July 2014 June 2014 May 2014 April 2014 March 2014 February 2014 January 2014 2013 December 2013 November 2013 October 2013 September 2013 August 2013 July 2013 June 2013 May 2013 April 2013 March 2013 February 2013 January 2013 2012 December 2012 November 2012 October 2012 September 2012 August 2012 July 2012 June 2012 May 2012 April 2012 March 2012 February 2012 January 2012 2011 December 2011 November 2011 September 2011 August 2011 June 2011 April 2011 March 2011 February 2011 January 2011 2010 December 2010 November 2010 October 2010 September 2010 May 2010 April 2010 March 2010 February 2010 January 2010 2009 December 2009 October 2009 August 2009 July 2009 May 2009 March 2009 February 2009 2008 November 2008 October 2008 September 2008 August 2008 July 2008 June 2008 May 2008 April 2008 January 2008 2007 December 2007 November 2007 October 2007 September 2007 August 2007 July 2007 June 2007 May 2007 April 2007 March 2007 February 2007 January 2007 2006 December 2006 November 2006 October 2006 September 2006 August 2006 July 2006 June 2006 May 2006 April 2006 March 2006 February 2006 January 2006 2005 December 2005 November 2005 October 2005 September 2005 August 2005 July 2005 RSS Feeds Latest news entries Recent code changes Django Links Learn More About Django Getting Started with Django Team Organization Django Software Foundation Code of Conduct Diversity Statement Get Involved Join a Group Contribute to Django Submit a Bug Report a Security Issue Get Help Getting Help FAQ #django IRC channel Django Discord Official Django Forum Follow Us GitHub Twitter Fediverse (Mastodon) News RSS Django Users Mailing List Support Us Sponsor Django Official merchandise store Benevity Workplace Giving Program Django Hosting by In-kind donors Design by Threespot & andrevv © 2005-2023 Django Software Foundation and individual contributors. Django is a registered trademark of the Django Software Foundation.",
    "commentLink": "https://news.ycombinator.com/item?id=38517099",
    "commentBody": "Django 5.0Hacker NewspastloginDjango 5.0 (djangoproject.com) 518 points by sarahboyce 20 hours ago| hidepastfavorite195 comments ralmidani 17 hours agoDjango made me fall in love with programming 13 years ago, and since then it has always had a special place in my heart.I’m revisiting a business idea I was working on for a couple years, before I sought and found employment in the industry (where I used Java for a couple years, then Elixir for a couple more). My project was built with Django and Django REST Framework, and Ember on the client-side. 6 years later, the Django side needed minimal changes and is up and running (I jumped all the way from 1.11 to 5.0 beta).Meanwhile, the Ember part is “lost in time… like tears in rain”. I tried everything, downloading older versions of Node and even the now-deprecated Bower. I don’t fault Ember (which is actually the most stable of the major JS client frameworks). But the JS (especially Node) ecosystem is beyond redemption in my eyes.For my rewrite of the client, I’m going to skip the drama and just use htmx. Render Django templates server-side, include a single JS script, thrown in some HTML attributes, distinguish between full page requests vs. requests for a partial with updated data, and call it a day. No TypeScript, no Webpack, none of that nonsense. If I need special interactivity I can throw in some hyperscript.At work I’ve used Elixir&#x2F;Phoenix&#x2F;LiveView and it’s revolutionary, truly awesome tech. But to get to market I would rather not have to customize an auth system and build a decent admin interface myself (I tried Ash; its auth and admin are not mature enough to be compared to what “just works” with Django). Yeah, it won’t be as scalable as a Phoenix app, but to me, Django seems like the most clean and rapid way to get to a point where you’ll actually need scalability. reply rollcat 15 hours agoparent> 6 years later, the Django side needed minimal changes and is up and running (I jumped all the way from 1.11 to 5.0 beta).I&#x27;ve been using Django since before 1.0, and the upgrade story has been nothing short of fantastic for something that&#x27;s been around this long. But still, YMMV!Depending on how ancient a project you run into, it definitely can be a major pain, even with the original authors&#x27; best intentions. For example, Django didn&#x27;t have its own DB migration system until 1.7 (relying on third party solutions); this means you also have to adjust the deployment procedure, which means recreating an ancient setup (ideally in an easily repeatable fashion, because you&#x27;re going to be trying that migration at least a dozen times).The builtin admin system is also a pretty decent CMS on its own, but falls short as you run into slightly more complex use cases (such as basically anything that requires even a single line of JS). The docs will encourage you to copy and override the builtin templates; this often becomes a pain point during upgrades. It&#x27;s wise to get off the builtin admin system as your project grows. reply Alex3917 15 hours agorootparentFWIW I&#x27;ve also had the same experience; the last version of Django where upgrading took a non-trivial amount of time was 1.8, because it changed how isolation is enforced within test cases. Since then it&#x27;s rarely taken more than an hour or two, regardless of how big the codebase is. reply rglullis 10 hours agorootparentprev> The builtin admin system is also a pretty decent CMS on its own (...) It&#x27;s wise to get off the builtin admin system as your project grows.And go to another superbly robust and easy to use actual CMS: wagtail. reply rollcat 8 hours agorootparentWagtail is absolutely fantastic for content-heavy websites, like blogs, journals, catalogues, archives, venues (event schedules), also everything that deals with loosely-structured data. It&#x27;s much less useful as a general purpose CRUD framework - it&#x27;s too focused on \"content\", it wouldn&#x27;t spark joy.Also it&#x27;s been a few years since I&#x27;ve last used it, but the overwhelming dominance of deeply nested JSON fields makes ordinary DB migrations unnecessarily interesting. reply rglullis 5 hours agorootparent> it&#x27;s too focused on \"content\".Isn&#x27;t that a good thing for a Content Management System?I am not sure I understand what you think could be done to either the admin (or wagtail) to make them \"CRUD frameworks\". reply stuaxo 9 hours agorootparentprevThe jump from Django to wagtail was like the jump to Django in the first place, I wish more projects I get to work on were based on it. reply qup 10 hours agorootparentprev want to increment the version number of things like React, MUI, webpack, TS by.. one!To be fair, in semver that means a breaking change of some sort. reply rigoleto 16 hours agoparentprev> I’m going to skip the drama and just use htmx for the client-side. Render Django templates server-side, include a single JS script, thrown in some HTML attributes, distinguish between full page requests vs. requests for a partial with updated data, and call it a day.More of a side comment, but I&#x27;m skeptical of the way HTMX encourages partial renders like this. It feels like a premature optimization that adds more complexity on the back end. `hx-select` takes care of it, but to me it feels like it should be the default (it&#x27;s what Unpoly does). reply megaman821 15 hours agorootparentThere is a package, https:&#x2F;&#x2F;github.com&#x2F;carltongibson&#x2F;django-template-partials, that is basically like server-side hx-select, when there is some performance concern. Overall, I agree with you though, hx-select is going to be fine most the time. reply ralmidani 14 hours agorootparentThanks for sharing that! I also just finished watching Carlton’s talk from DjangoCon EU (linked in the repo) and it is gold: https:&#x2F;&#x2F;youtu.be&#x2F;_3oGI4RC52s reply ralmidani 15 hours agorootparentprevThere is a header that htmx injects to indicate you want a partial render, and it’s really not that hard to add an if on the server-side to check for it. A larger codebase would probably break templates up anyway for maintainability, so it’s just a tiny amount of extra work if you want to reduce the amount of HTML being sent over the wire and swapped in. reply winrid 15 hours agoparentprevDjango and django-unicorn is really nice. It feels like meteorjs but for Django, extremely productive. I&#x27;ve been working with the creator closely and he&#x27;s awesome. reply mattgreenrocks 14 hours agorootparentdjango-unicorn is really impressive! So glad to see people pushing back on all the gunk inherent in webdev still. reply Keats 14 hours agoparentprevI haven&#x27;t used Elixir yet and mostly using flask in Python for work but I started with Django (and still think it&#x27;s better than flask for most apps). If stuff like https:&#x2F;&#x2F;github.com&#x2F;aesmail&#x2F;kaffy (first thing I&#x27;ve found on google, never heard of it before) is on par with the Django admin, would you still use Django or Elixir and never look back? reply ralmidani 14 hours agorootparentI don’t know if I would “never look back” to Django (I’m a sentimental person). But admin is one aspect, the other big one is auth. I also like DTL better than EEx&#x2F;HEEx. And all the pieces of Django just fit together really nicely; where Ecto happens to be the preferred way to interact with a database from Elixir, and Phoenix happens to be the preferred way to build Web apps using Elixir, (maybe with Ash layered on top), they weren’t designed by the same people, so you have packages like ecto_phoenix, ash_phoenix, etc. to make them all play together in an elegant way.I will admit, Elixir and Phoenix have better real-time and scalability stories.If I had a choice I would probably prefer Elixir&#x2F;Phoenix&#x2F;LiveView when joining an org to work on an established codebase that may have actual scalability needs and concerns. But I would probably prefer Django when starting from scratch. reply snoopsnopp 16 hours agoparentprevTotally agree, but is Ember truly the most stable? This is pretty much my only criteria for JS at this point. reply ralmidani 15 hours agorootparentIf you want a heavyweight JS framework, Ember is the most stable and best supported. I enjoyed Ember when I used it in the 2015-2017 time frame.But I’m abandoning the heavy JS paradigm in favor of htmx. Aside from the fact that I don’t want to duplicate routing and data validation across client and server, htmx is intentionally a single JS file with no build step, so in theory it should run fine as long as browsers maintain backward compatibility. reply bluecheese452 10 hours agorootparentprevFwiw trying to get an old ember app running was an absolute nightmare. On top of that it is way too heavy for my liking. Pretty much polar opposite of jquery. reply greenie_beans 14 hours agoparentprevi&#x27;ve been using django + htmx and vanilla js where needed. it&#x27;s great!my biggest beef with it is code organization, which will only get better with more experience. and it&#x27;s a side project so it doesn&#x27;t matter. i do worry about using it on a team because i could this stack getting messy if not done the right way. reply sarahboyce 20 hours agoprevRelease notes: https:&#x2F;&#x2F;docs.djangoproject.com&#x2F;en&#x2F;5.0&#x2F;releases&#x2F;5.0&#x2F;Related Community Resources* New goodies in Django 5.0 [blog]: https:&#x2F;&#x2F;fly.io&#x2F;django-beats&#x2F;new-goodies-in-django-50&#x2F;* What&#x27;s new in Django 5.0 [video]: https:&#x2F;&#x2F;youtu.be&#x2F;lPl5Q5gv9G8?feature=shared* Database generated columns⁽¹⁾: Django & SQLite [blog]: https:&#x2F;&#x2F;www.paulox.net&#x2F;2023&#x2F;11&#x2F;07&#x2F;database-generated-columns...* Database generated columns⁽²⁾: Django & PostgreSQL [blog]: https:&#x2F;&#x2F;www.paulox.net&#x2F;2023&#x2F;11&#x2F;24&#x2F;database-generated-columns...* Building a Bootstrap styled form in vanilla Django [blog]: https:&#x2F;&#x2F;smithdc.uk&#x2F;blog&#x2F;2023&#x2F;bootstrap_form_in_vanilla_djang... reply jmduke 17 hours agoprevMy app is a Django backend and a Vue frontend. There are large swathes of Django that I ignore, but to me the core of Django — its ORM, routing and middleware system, and admin interface — are worth their weight in gold. The migration from DRF to Django-Ninja (which is, roughly, FastAPI + Django) has also been a great improvement in terms of productivity and performance.Not a lot of whizbang features in 5.0, but GeneratedField looks like a very nice addition, and reason enough to migrate. reply jim180 17 hours agoparentComing from iOS&#x2F;macOS background, I&#x27;ve kinda enjoyed Django with its all time classics (forms, templates, etc.) + HTMX.Admin interface was extremely helpful, when we are trying to validate business idea. reply cdcarter 15 hours agoparentprevGeneratedField looks interesting, but I&#x27;m not _really_ sure what gains I get over just calling annotate() on my queryset with some computed fields. At least on the backends where the computed GeneratedField isn&#x27;t stored. reply radus 15 hours agorootparentIt&#x27;s easier to re-use if you need the same generated field in multiple places. reply cdcarter 14 hours agorootparentI&#x27;ve been in the habit of replacing the default manager for my model with one with an annotated query set. that way, any Model.objects.all() call will have the computed fields.I find this pretty easy to get used to and re-use. though I do admit I like them defined as actual model-fields with verbose names etc... reply tmnvix 6 hours agorootparentprevActually having the derived data in the database would be helpful for simplifying something like a website search implementation. I know I could have used it last month! reply OJFord 10 hours agorootparentprevIt&#x27;s a generated column in the database, vs. annotate is just a python alias for something you&#x27;re selecting in the query. reply sprainedankles 17 hours agoparentprevAny resources&#x2F;examples you&#x27;d recommend for a Vue frontend w&#x2F;django? I&#x27;ve been pretty firmly in backend land for a while and would to experiment with the other half of the puzzle! reply jmduke 17 hours agorootparentI&#x27;ll preface all of this with a couple esoteric design goals that I had in mind:1. I actually _want_ an SPA. You might not need an SPA, if you don&#x27;t need one then Vue&#x2F;React&#x2F;etc are overkill, etc.2. I want to power as much of the SPA as I can using the same REST API as my core product, both for dogfooding reasons and for consolidation. Many people might argue that this is a bad idea.---With that in mind, some specific packages that I highly recommend:1. Django-vite (https:&#x2F;&#x2F;github.com&#x2F;MrBin99&#x2F;django-vite). This makes it very easy to serve an SPA from the actual django response&#x2F;request model2. Some sort of way to get type information (if you&#x27;re using TypeScript) into the frontend. I use a frankensteined system of the OpenAPI spec that django-ninja generates + openapi-typescript (https:&#x2F;&#x2F;github.com&#x2F;drwpow&#x2F;openapi-typescript). This means when I add, say, a new field to a response in Django, I immediately get typechecking for it in Vue — which has been _tremendously_ useful.3. Django-typescript-routes (a package I extracted and open-sourced!: https:&#x2F;&#x2F;github.com&#x2F;buttondown-email&#x2F;django-typescript-routes) which gives your front-end routing information based on the Django router. reply zelphirkalt 15 hours agorootparentprevIf you really need VueJs in the frontend, consider, that you can simple serve the VueJs on any page where it is actually needed. VueJs does not necessarily mean you must create a SPA. VueJs can be delivered like any other script and this is often the easiest way without having to commit to build a full blown SPA. reply amir_karbasi 16 hours agoparentprevHow was the effort to migrate from DRF to Django-Ninja? I saw Django-Ninja mentioned in another post and am thinking of switching one of my projects over from DRF. After skimming their documentation, it looks very pleasant and simple and perfect for my use case. reply jmduke 16 hours agorootparentGoing from 0 → 1 migrated route was \"medium difficulty\", I&#x27;d say — there was a non-trivial amount of scaffolding I had to build out around auth, error codes, and so on, and django-ninja&#x27;s docs are still a little lackluster when it comes to edge cases.Once I had that one migrated route, though, the rest were very simple. (And I am very happy with the migration overall!) reply crucialfelix 12 hours agorootparentI&#x27;ve had that on my list to try out for a while now. FastAPI is a joy, having generated OpenAPI is a must, so Ninja sounds good.I&#x27;ve had quite enough of DRF&#x27;s tower of mixins and rails like magic. It always sucks up development time and fails too easily. reply malux85 17 hours agoparentprevMine too - Vue and django, and the django rest framework, it’s super productive - no writing all the crud views manually for the hundreds of models I have, the django admin interface is very helpful like you say, and backend is running (a very highly customized) django celery mix,Django + REST framework takes a little more to learn than something like FastAPI, but once you understand how all the middleware, permission and query classes work, you can be hyper productive reply collyw 15 hours agoparentprevAgreed, the admin makes development so much easier, being able to easily enter and view your data. reply quantiq 15 hours agoprevDjango is such a lovely framework I can&#x27;t speak higher praises of it. I&#x27;m blessed to still be able to use it in my day to day work. It&#x27;s maybe not the most flashy framework out there these days but Django and Rails are really the Toyota Corollas and Honda Civics of the web dev world that often go so underappreciated for their unfussy reliability. :) reply anon373839 11 hours agoparentI’d say they’re the Lexuses of the web dev world. Very nicely appointed and rock-solid, just not very sexy. reply pwython 1 hour agorootparentThe Lexus LFA would like to have a word with you. reply h4kor 18 hours agoprevSadly I don&#x27;t use Django anymore at work but it still has a special place in my heart. The ORM model is the best I&#x27;ve ever worked with and any other always feels clunky with sharp edges to cut you when you hold it wrong.In recent years Django had multiple major releases, I still remember it as being in 1.x forever. Does somebody know what changed within the Django Community that they break backward compatibility more often? reply sarahboyce 17 hours agoparentThe release process is time-based as to roughly every 8 months[1] with X.0, X.1, and X.2 (LTS). This is mostly to communicate which release has long term support.The deprecation policy[2] is taken very seriously and Django doesn&#x27;t opt to break things if it can.Recently there was a very interesting discussion[3] between the Fellows as to whether the version numbering is confusing as this doesn&#x27;t follow the same pattern as other libraries.1: https:&#x2F;&#x2F;docs.djangoproject.com&#x2F;en&#x2F;dev&#x2F;internals&#x2F;release-proc...2: https:&#x2F;&#x2F;docs.djangoproject.com&#x2F;en&#x2F;dev&#x2F;internals&#x2F;release-proc...3: https:&#x2F;&#x2F;fosstodon.org&#x2F;@carlton&#x2F;111300877531721385 reply DarkNova6 17 hours agoparentprev> The ORM model is the best I&#x27;ve ever worked with and any other always feels clunky with sharp edges to cut you when you hold it wrong.Idk. I have to grant that Django ORM likes to make your life easy, but lazy loading on property calls is a dark pit full of shap punji sticks. Just overlook one instance where this is happening in a loop and say goodbye to performance and hello to timeouts left and right... reply har777 16 hours agorootparentSimple middleware can warn you about lazy loading&#x2F;N+1 queries. Most of the time people just forget it happens.Try using: https:&#x2F;&#x2F;github.com&#x2F;har777&#x2F;pelletDisclaimer: I built it :pYou can easily see N+1 queries on the console itself or write a callback function to track such issues on your monitoring stack of choice on production. reply Izkata 14 hours agorootparentI did this by adding every SQL query to a new log file (only active in development), then tailing it while developing. Not only is 1+N very visible as a long string of the same query over and over, it also lets you see in real time when there&#x27;s a long pause from a query taking longer than expected.Also we often had something that was more like 1+3N, basically a 1+N problem but it was looping through the same 3 queries over and over. reply bdzr 13 hours agorootparentprevFWIW Sentry has recently (within the last year or so) rolled out support for N+1 monitoring as well. reply dinkleberg 15 hours agorootparentprevThat looks handy, thanks for sharing! I used to use some other n+1 logger, but yours actual shows the query which is more useful. reply fbdab103 15 hours agorootparentprevHave a pitch on what differentiates this from django-toolbar? Just the focus on query count monitoring? reply har777 14 hours agorootparentYeah the query count monitoring is the main focus as N+1 queries are super common in Django.I don&#x27;t really have a pitch but here is why this was made:1. we had a production DRF app with ~1000 endpoints but the react app consuming it was dead slow because the api&#x27;s had slowed down massively.2. we knew N+1 was a big problem but the codebase was large and we didn&#x27;t even know where to start.3. we enabled this middleware on production and added a small callback function to write endpoint=>query_count, endpoint=>query_time metrics to datadog.4. once this was done it was quite trivial to find the hot endpoints sorted by num of queries and total time spent on queries.5. pick the most hot endpoint with large number of queries, enable debug mode locally, fix N+1 code, add assertNumQueries assertions to integration tests to make sure this doesn&#x27;t happen again and push to prod.6. monitor production metrics dashboard just to double check.7. rinse and repeat.For me this ability to continuously run on prod -> find issues and send to your monitoring stack -> alert -> fix locally workflow is the main selling point. Or of course you can just have it running locally on debug mode and check your console before pushing your changes but sometimes its just hard to expect that from every single engineer at your company. Then again your local data might not cause an issue so production N+1 monitoring is always nice. reply fbdab103 14 hours agorootparentMonitoring production is the piece I was missing. Was thinking of it as strictly for development.Unless it adds a bunch of overhead, seems like a no-brainer to enable. reply har777 13 hours agorootparentIt only adds like ~5ms. Unless you have `query_level_metrics_enabled` as True which takes more time. I didn&#x27;t find that particularly useful on prod and instead just used it locally when fixing stuff. Depends on what data you need populated in your callback function on prod.The header feature can also be useful. If you have a client on-call who&#x27;s complaining about super slow page loads. Just check their network tab and see which response has a query count&#x2F;time header which seems unnatural. replygen220 12 hours agorootparentprevI think Django&#x27;s ORM is a product of its time, when limitations about the expressibility of the \"active record\" concept were not fully understood.I like to describe it as Django&#x27;s ORM will satisfy 80% of your needs immediately, 90% if you invest and sweat, 95% if you&#x27;re quite knowledgeable in the underlying SQL. But there are still some rather common query shapes that are inexpressible or terribly awkward with Django&#x27;s ORM.SQLAlchemy on the other hand never tries to hide its complexity (although to be fair they&#x27;ve become much better at communicating it in 2.0). On Day 1 you&#x27;ll know maybe 20% of what you need to. You might not even have a working application until the end of week 1. But at the end of, idk, month 6? You&#x27;re a wizard.The long-term value ceiling of SQLAlchemy&#x2F;Alembic is higher than Django&#x27;s, but Django compensates for it with their comparatively richer plugin ecosystem, so it&#x27;s not so easy to compare the two. reply fbdab103 15 hours agorootparentprevNon-performant code is going to eventually slip into any codebase. The trick is to monitor for when performance falls to an unacceptable level. Not toss all ORMs because some minority of generated queries are problematic.If maximum performance, 100% of the time was the end-goal, I would not be writing Python. reply andybak 44 minutes agorootparentI agree. Combined with a few good habits like favouring select_related() - it&#x27;s never been a problem. reply DarkNova6 14 hours agorootparentprevThe python team I joined grew their codebase from a thin data access layer into a full blown application. Staff was full of data guys and had no idea about application engineering, but lots of opinions. The client was another company who intended the product as heart of their digital transformation.Guess who had to refactor this mess and steer away from catastrophy.I’m haunted to this day. reply fbdab103 14 hours agorootparentThat general story can happen with any tech stack.POC whipped together without good architecture. Having proven itself, usage increases until the application starts to burst at the seams. Program must be redesigned, avoiding performance gotchas.I still think Django + the ORM give you a lot of runway before performance should be a concern. reply Alex3917 17 hours agorootparentprev> Just overlook one instance where this is happening in a loop and say goodbye to performance and hello to timeouts left and right...FWIW they do give you assertNumQueries in the testing tools, which makes it relatively easy to catch this as long as you have tests. reply robertlagrant 14 hours agorootparentprevI sort of said this elsewhere. Others are saying \"that&#x27;s just what happens\" and \"well, Python?\" but it doesn&#x27;t just happen, and slow database queries are nothing to do with the application language. The problem is Django ORM, like Ruby on Rails, uses the Active Record pattern. Alternate ORMs, such as SQLAlchemy or Hibernate, uses Data Mapper pattern, which avoids the pitfalls of Active Record. reply pmontra 12 hours agorootparentWe can have 1+N queries in any language even without an ORM. Maybe an ORM facilitates mistakes because it hides joins but lack of experience is lack of experience. Some naive bad pseudocode: for book in select * from books: author = select * from authors where id == book.id print book.title author.nameIn the real world that nested select could be hidden many levels down in method or function calls or even in code run from the templating language. Example: Django templatetags can query the database from the HTML template and any framework or non framework I worked with can do that too. reply robertlagrant 10 hours agorootparentI&#x27;m not criticising ORMs, just how active record works. reply chris12321 9 hours agorootparentWell it&#x27;s trivial in ActiveRecord to avoid n+1s by preloading associations. As with any technology, if you use it wrong and inefficently then things will be incorrect and slow. reply belorn 17 hours agorootparentprevThere does seem to be a natural conflict between large data with hierarchical structure and the generally flat lists and dictionaries of Python, that quickly leads to poor performance. It usually only takes a few foreign keys to create an exponential number of queries.But I have no idea if there are database interfaces that make this problem simplistic. In my experience with Django, anything but the most simplistic page will be so noticeable slow that one has to go through the queries and use things like select related. Occasionally it is also better to just grab everything into memory and do operations in Python, rather than force the data manipulation to be done as a single database query.It is a good tool for its purpose, but it is no replacement for SQL knowledge when working with complex relational databases. reply h4kor 15 hours agorootparentYes you do have to work on your queries to keep them fast with growing complexity. Django also has a usable intermediate API to construct your queries, instead of writing raw SQL. Nice feature to have if you don&#x27;t want to commit to a specific database yet.And as already written above, a slow but correct page is preferable to a wrong page because you ORM is omitting related data. reply eYrKEC2 17 hours agorootparentprevORM&#x27;s always abstract away details, but you monitor for slow queries and slow endpoints and then just fix the issues when they crop up. reply h4kor 15 hours agorootparentprevI&#x27;d rather have a slow page because of lazy loading, than a wrong page because the related objects are not loaded (i.e. typeorm) reply greenie_beans 14 hours agorootparentprevlol been refactoring something like this reply pmontra 12 hours agoparentprevThe ORM is OK as long as you refrain from using any inheritance. If you do, the database becomes a mess quickly and only that very Django app will be able to read and write to it (including manage.py shell). Anything else, other apps in any language or a SQL client, will be lost in a sea of tables and joins.I&#x27;ve got a customer with two Django apps. One was developed enthusiastically in the object orientation way. The database is a nightmare. The other one was developed thinking table by table and creating models that mimic the tables we want to have. That&#x27;s a database we can also deal with from other apps and tools. reply dd82 12 hours agorootparenttbh, any OOP paradigms used with db tables will end up in a clusterf*ck. reply freedomben 18 hours agoparentprevHave you worked with ActiveRecord or Ecto? Just wondering for framing your comment reply ralmidani 16 hours agorootparentNot who you’re asking, but I’ve used all 3. I think in terms of query interface you can’t go wrong with any of them. In fact, I like Ecto the most because of its separation between the concept of a “Query” (super flexible and composable) vs. a “Repo” (the module where you call an actual database operation). This helps you avoid hitting the database until you’re sure you want to.Where Django’s ORM shines is in the modeling stage: classes in models.py are your single source of truth, relationships only need to be defined once, no separate “schema” file, and most of the time migrations can be generated automatically. It’s truly top-notch. reply robertlagrant 15 hours agorootparentI think SQLAlchemy is better, personally. Still just model files, but it&#x27;s data mapper pattern means you won&#x27;t be hitting all the issues people do with active record. reply h4kor 15 hours agorootparentprevI briefly used Ecto when trying out Phoenix framework but have not worked enough with it to form an opinion. reply jedi_stannis 18 hours agoparentprevThey switched their versioning scheme after the 1.x.https:&#x2F;&#x2F;docs.djangoproject.com&#x2F;en&#x2F;dev&#x2F;internals&#x2F;release-proc... reply adastra22 17 hours agoparentprevSimilar to bitcoin, they changed to a time-based versioning scheme. Major releases don&#x27;t indicated that they DID break compatibility, but that they MIGHT HAVE, and more importantly prior versions are no longer supported. Effectively the same as a LTS release. reply yuppiepuppie 17 hours agoprev3 years ago I moved to fast growing startup that was founded with fast api slap-dashed together. I jammed Django down their throats and I can safely say it was the best decision we made as an Org. The teams using Django are far far more productive than the others.When a product I think is going to need users and roles and permissions, I grab Django off the shelf and never look back.Thank you mister reinhardt reply alfor 9 hours agoparentI am trying to show the value of it in my company: fastapi + vue.js and severy short staffed.There are so much structural mistakes in our codebase, they use async python but messed it up in all the important places yet believe that Django is slow or innadequate.They belive that Django is too \"old school\" and that if you want good results you need vue.js an api and all that.Truth is, no one has the time and experience to make something good with that.Developpement is very slow and code is buggy management is unsatisfied with the results yet they refuse to try it out.It seem their ideas are made up and won&#x27;t change. reply yuppiepuppie 2 hours agorootparentFwiw, it was an investment while short staffed that paid dividends later on.It sounds like in your case, like mine, it’s a cultural issue that you are trying to solve, not a technical one. A cultural issue of wanting to deploy and ship a product fast and not worry about the stuff that’s already been solved.You can always do a POC and show the value of it to the stakeholders. What I did was picked a product that would greatly benefit from it and went through the entire migration process with product and got their buy in. reply IshKebab 11 hours agoparentprevYeah this is definitely Django&#x27;s strength - it has a lot of the stuff you&#x27;re probably going to need already implemented. Massive time saver when you&#x27;re setting things up.Python definitely holds it back though. Does it have type hints yet? reply yuppiepuppie 2 hours agorootparentWhy do you say python holds it back? reply SadWebDeveloper 17 hours agoprevIMHO... Django hold a high standard in terms for projects running beyond the infamous 5+ years of support... still have some projects that with minimal changes (mostly configs and dependencies that got redundant&#x2F;integrated into django -like choices-) are working with the latest version, surely 5.0 will not be that drastic if you are already doing software \"the django way\".Things that are Django achilles heel are not developing software \"the django way\", mostly anything that needs some client-side to work is a PITA, requires lots of rewriting and custom templates that at some point you gotta start looking django as a backend more like the full stack framework that was meant to be. Also anything related onto getting things to production is another PITA that hasn&#x27;t been solved or touched in years, dx deployment is one of those things almost any JS Framework out there is doing things better than what django supports. reply dexwiz 16 hours agoparentIsn&#x27;t Developer DX mostly a way to get developers locked into your platform? I have avoided Next.js for this reason, it seems like just a way to funnel developers towards Vercel. DX is largely a service specific problem since its coupled to the service you are deploying to. reply yunohn 16 hours agorootparentDjango is free, in all definitions and purposes of the word. No agenda, no VC funding, no BS. replynickjj 16 hours agoprevCongrats on the release to the Django community!If anyone is curious, I updated my Django &#x2F; Docker starter app to use Django 5.0 at: https:&#x2F;&#x2F;github.com&#x2F;nickjj&#x2F;docker-django-exampleIt pulls together gunicorn, Celery, Redis, Postgres, esbuild and Tailwind with Docker Compose. It&#x27;s set up to run in both development and production. reply hipjiveguy 9 hours agoparentwhere do you tend to run stuff in production? and if you were a startup - any preferences? reply hipjiveguy 9 hours agoparentprevnice... thanks! reply loughnane 15 hours agoprevI can’t tell if it’s Django or just how I use it—-I’m a mechanical engineer by training and only dabble on web dev—-but I deeply appreciate how it gives me enough abstraction to get going but doesn’t get too far ahead of itself. If I go away for a year or two then come back I still get what’s going on. Meanwhile anything I try on JS land has gone through a few half-lives. reply rglover 14 hours agoparentIf you want a similar experience in JS check out Joystick [1]. It&#x27;s being built to mimic the indefinitely stable design of stuff like Django and Rails.[1] https:&#x2F;&#x2F;github.com&#x2F;cheatcode&#x2F;joystick reply 0xblinq 2 hours agorootparentWhich is just yet another js framework which might disappear next month.That&#x27;s the problem. reply ajhai 15 hours agoprevI&#x27;ve been using Django as my main choice for web projects for over ten years. The reason I like it so much is because it comes with a lot of built-in features that one needs to ship web projects to production. For example, I was first attracted to Django because of its admin interface and its straightforward views and templating system.Over the years, Django has kept up with changes in web development. An example of this is when database migrations, which used to be a separate project, were integrated into Django itself. The Django community is also strong with great ecosystem projects like DRF for APIs, Django Channels for real-time features, and social-auth for social sign-ins.My recent use of Django is in (https:&#x2F;&#x2F;github.com&#x2F;trypromptly&#x2F;LLMStack). We use Django Channels for WebSocket support, DRF for APIs, and ReactJS for the frontend. reply the__alchemist 14 hours agoprevDjango owns! The blazingly-fast flask-alikes that come out in Python and Rust every year still can&#x27;t touch it for building websites.My only beef is that the official docs and community chats make you feel like you&#x27;re an outlaw or doing things wrong if you use the raw SQL API.Regarding this new version in particular, the feature that jumps out at me the most is the improved field choices. I&#x27;ve been using an odd workaround with the decorator API to tie them to python Enums. reply 95 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Django 5.0 has been released, featuring new functionalities like database-computed default values, generated model fields, and field groups for form field rendering.",
      "Django 4.2 has reached the end of mainstream support, so it's crucial for users to upgrade to ensure they receive security fixes.",
      "Django 4.1 has also reached the end of extended support, making it necessary for users to upgrade to Django 4.2 or a later version.",
      "DjangoCon Europe 2024 has been scheduled for June 5, 2024, in Vigo, Spain."
    ],
    "commentSummary": [
      "Django is a popular framework known for its simplicity, productivity, and built-in features like the admin system.",
      "Alternatives like Wagtail and FastAPI are suggested by some users, highlighting the drawbacks of Django.",
      "Discussions also cover topics such as using htmx for client-side rendering, performance issues with database queries, and the importance of monitoring and optimizing performance."
    ],
    "points": 518,
    "commentCount": 195,
    "retryCount": 0,
    "time": 1701697489
  },
  {
    "id": 38517550,
    "title": "Harvard Accused of Caving to Meta, Ousting Disinformation Scholar",
    "originLink": "https://www.washingtonpost.com/technology/2023/12/04/joan-donovan-harvard-dismissal-complaint/",
    "originBody": "Joan Donovan at Boston University on Thursday. (Jesse Burke for The Washington Post) Listen 10 min Share Comment Add to your saved stories Save A prominent disinformation scholar has accused Harvard University of dismissing her to curry favor with Facebook and its current and former executives in violation of her right to free speech. Joan Donovan claimed in a filing with the Education Department and the Massachusetts attorney general that her superiors soured on her as Harvard was getting a record $500 million pledge from Meta founder Mark Zuckerberg’s charitable arm. Tech is not your friend. We are. Sign up for The Tech Friend newsletter. As research director of Harvard Kennedy School projects delving into mis- and disinformation on social media platforms, Donovan had raised millions in grants, testified before Congress and been a frequent commentator on television, often faulting internet companies for profiting from the spread of divisive falsehoods. Story continues below advertisement Last year, the school’s dean told her that he was winding down her main project and that she should stop fundraising for it. This year, the school eliminated her position. The surprise dismissal alarmed fellow researchers elsewhere, who saw Donovan as a pioneer in an increasingly critical area of great sensitivity to the powerful and well-connected tech giants. Advertisement Donovan has remained silent about what happened until now, filing a 248-page legal statement obtained by The Washington Post that traces her problems to her acquisition of a trove of explosive documents known as the Facebook Papers and championing their importance before an audience of Harvard donors that included Facebook’s former top communications executive. Harvard disputes Donovan’s core claims, telling The Post that she was a staff employee and that it had not been able to find a faculty sponsor to oversee her work, as university policy requires. It also denies that she was fired, saying she “was offered the chance to continue as a part-time adjunct lecturer, and she chose not to do so.” Story continues below advertisement Donovan obtained the Facebook documents when they and the former Facebook employee who leaked them, Frances Haugen, were the subject of extensive news coverage in October 2021, with The Post writing that the documents showed Facebook “privately and meticulously tracked real-world harms exacerbated by its platforms, ignored warnings from its employees about the risks of their design decisions and exposed vulnerable communities around the world to a cocktail of dangerous content.” Frances Haugen took thousands of Facebook documents: This is how she did it As the main attraction at a Zoom meeting for top Kennedy School donors on Oct. 29 that year, Donovan said the papers showed that Meta knew the harms it was causing. Former top Facebook communications executive Elliot Schrage asked repeated questions during the meeting and said she badly misunderstood the papers, Donovan wrote in a sworn declaration included in the filing. Ten days after the donors meeting, Kennedy School dean Doug Elmendorf, a former director of the Congressional Budget Office, emailed Donovan with pointed questions about her research goals and methods, launching an increase in oversight that restricted her activities and led to her dismissal before the end of her contract, according to the declaration. Donovan wrote that the Chan Zuckerberg Initiative’s $500 million gift for a new artificial intelligence institute at the university, announced Dec. 7 that year, had been in the works before the donor meeting. Leaders at the Kennedy School “were inappropriately influenced by Meta/Facebook,” Donovan claims in her declaration. “A significant conflict of interest arising from funding and personal relationships has created a pervasive culture at HKS of operating in the best interest of Facebook/Meta at the expense of academic freedom and Harvard’s own stated mission.” Advertisement Story continues below advertisement The filing raises questions about the potential conflict of interest created by Big Tech’s influence at research institutions that are called upon for their expertise on the industry. “The document’s allegations of unfair treatment and donor interference are false. The narrative is full of inaccuracies and baseless insinuations, particularly the suggestion that Harvard Kennedy School allowed Facebook to dictate its approach to research,” Kennedy School spokesperson Sofiya Cabalquinto said by email. “By policy and in practice, donors have no influence over this or other work.” Cabalquinto’s email added: “By long-standing policy to uphold academic standards, all research projects at Harvard Kennedy School need to be led by faculty members. Joan Donovan was hired as a staff member (not a faculty member) to manage a media manipulation project. When the original faculty leader of the project left Harvard, the School tried for some time to identify another faculty member who had time and interest to lead the project. After that effort did not succeed, the project was given more than a year to wind down. Joan Donovan was not fired, and most members of the research team chose to remain at the School in new roles.” Advertisement Story continues below advertisement Elmendorf declined to comment. At one point, Elmendorf told Donovan that she did not have academic freedom because she was staff rather than faculty, she recounts. Officials confirmed that position to The Post. But Harvard Law School professor Lawrence Lessig said that stance should be limited to traditional staff work, not research papers, other publications and teaching. “When you’re doing what looks like academic work as one of the most prominent people in an academic field, the university ought to award that person the protections of academic freedom,” said Lessig, an expert on corruption who made inquiries to Harvard’s administration on Donovan’s behalf. “When she was presenting herself to the world, there was no asterisk at the bottom of her name saying, ‘As long as what she says is consistent with the interests of Harvard University.’” Donovan was recently hired for a tenure-track professorship at Boston University. The Donovan case comes at a time when researchers who focus on social media platforms find themselves under increasing attack. Trump adviser Stephen Miller’s legal foundation has sued academic and independent researchers, claiming that they conspired with government agencies to suppress speech, and Republican-led congressional committees have subpoenaed their records, adding to the pressure. Advertisement Story continues below advertisement In addition, Big Tech companies themselves have sponsored research, made grants to some colleges and universities, and doled out data to professors who agree to specific avenues of inquiry. The filing asks the federal Education Department’s civil rights division to investigate whether Harvard violated Donovan’s right to free speech and academic freedom. It asks Massachusetts’s charity regulators to examine whether the university deceived donors or misappropriated their funds by retaining millions that Donovan had raised for her research. A copy sent to Harvard’s new president, Claudine Gay, asks her to determine whether the Kennedy School had breached the university’s own policies. Story continues below advertisement “All of the efforts taken to undermine Dr. Donovan came at great costs — to the donors who contributed millions of dollars to her work, and to the public more broadly who every day, all day long, are exposed to disinformation and misinformation,” Whistleblower Aid attorneys Andrew Bakaj and Kyle Gardiner wrote in the filing. Advertisement “There are a handful of tried and true means to coerce someone or some entity to do something they would not otherwise do, and influence through financial compensation is at or near the top of the list,” the filing says. “Objectively, $500 million is certainly significant financial influence.” In addition to Donovan, Whistleblower Aid has represented Haugen, the Facebook whistleblower; former Twitter security chief Peiter Zatko; and anonymous whistleblowers from the intelligence community. Story continues below advertisement In the documents, Donovan contends that Meta’s influence at Harvard goes beyond money and includes deep personal connections. Schrage, for one, earned degrees from Harvard College, the Kennedy School and Harvard’s law school. Zuckerberg and Facebook’s former longtime chief operating officer, Sheryl Sandberg, were Harvard undergraduates, as was Zuckerberg’s wife, Priscilla Chan. Elmendorf served as Sandberg’s adviser for a club she started in college. They remained close, and Elmendorf attended Sandberg’s wedding in August 2022. Four days later, he told Donovan he was winding down her research team, she says in the complaint. Advertisement Kennedy School officials said Elmendorf and Sandberg never discussed Donovan. Schrage and Sandberg declined to comment. Story continues below advertisement Meta also declined to comment, while the Chan Zuckerberg Initiative said it contributed money because it cared about the science. “CZI had no involvement in Dr. Donovan’s departure from Harvard,” spokesperson Jeff MacGregor said. Donovan says in her complaint that Elmendorf emailed her after the October donors’ meeting and asked to discuss her Facebook work and “focus on a few key issues drawn from the questions raised by the Dean’s Council and my own limited reading of current events.” He wrote that he wanted to hear from her about “How you define the problem of misinformation for both analysis and possible responses (algorithm-adjusting or policymaking) when there is no independent arbiter of truth (in this country or others) and constitutional protections of speech (in some countries)?” Advertisement Donovan said in the filing that Elmendorf’s use of the phrase “arbiters of truth” alarmed her because Facebook uses the same words to explain its reluctance to take actions against false content. She explained to Elmendorf that rather than making moral judgments about politics or proclaiming that a vaccine is good or bad, she looked for provable manipulation of platforms, as with fake accounts. “We do not generally speak about what is good or bad for a society, but rather what is true or false about a specific public event,” she emailed him. Donovan then alerted colleagues with whom she was starting to work on the Facebook Archive of leaked documents that she was drawing heat. Both suggested that they take the name of Donovan’s Technology and Social Change Research Project off the archive project’s website. Advertisement “Let’s remove the explicit listing of TASC, minimally, or of all three groups, when the website updates later today,” Kennedy School professor Latanya Sweeney wrote in an email included in Donovan’s filing. “No reason to put a target on the project that allows FB to claim bias before we even do anything.” Donovan’s project remained listed on the page until this year, according to copies preserved by the Internet Archive. Sweeney said her role was twisted by the Donovan filing. “The number and nature of inaccuracies and falsehoods in the document are so abundant and self-serving as to be horribly disappointing,” she told The Post. “Meta exerted no influence over the Facebook Archive or any of our/my work.” Elmendorf met with Donovan again in August 2022 and told her that her project at the Kennedy School would end in the coming year, the filing says. Though Donovan’s contract was supposed to keep her on the job through the end of 2024, her superiors took away her ability to start new projects, raise money or organize large events, she alleges. They kept the money she had brought in, including more than $1 million from Craigslist founder Craig Newmark that he wanted specifically to go to her research project, according to documents quoted in the declaration. Newmark declined to comment. The Kennedy School said no money was misused. The Massachusetts attorney general’s office said it is reviewing the filing. The Education Department did not respond to a request for comment. This September, Elmendorf said that the current academic year would be his last as dean and that he would continue to teach. The Facebook Archive finally went public in October. Far down a page devoted to the history of the site, it says that Sweeney’s Public Interest Tech Lab “received an anonymous drop of the internal Facebook documents” and that “Dr. Joan Donovan immediately recognized the valuable insight the documents provided.” It does not say Donovan obtained the documents and launched the project, as she contends. Share Comments",
    "commentLink": "https://news.ycombinator.com/item?id=38517550",
    "commentBody": "Ousted propaganda scholar accuses Harvard of bowing to MetaHacker NewspastloginOusted propaganda scholar accuses Harvard of bowing to Meta (washingtonpost.com) 460 points by ta988 16 hours ago| hidepastfavorite456 comments c5karl 15 hours agoHere&#x27;s a \"gift\" link: https:&#x2F;&#x2F;wapo.st&#x2F;3Nb5tm8 ta988 16 hours agoprevhttps:&#x2F;&#x2F;archive.is&#x2F;oKsbi yellow_lead 17 hours agoprevHer actual whistleblower declaration contains a lot of the evidence some may be looking for:https:&#x2F;&#x2F;live-whistleblower-aid.pantheonsite.io&#x2F;wp-content&#x2F;up...To sum up the first few pages after skimming it, Facebook tried to bribe her (well \"fund\" her research), she refused. Later she had a meeting with the former head of comms at Facebook, who was now on the Dean&#x27;s council, where he became incredibly angry with her research (page 4, 13). Following this, she got an email from the Dean of the Kennedy school which sounds very much like someone tattled to them and they now want to \"review\" her research (see page 5, 15). It continues from here. reply jcheng 16 hours agoparentNot sure why I decided to spend so much time on this on a Monday morning but I&#x27;ve read to page 35, and the picture is much more muddled.It looks like the FB Archive project gains momentum and launches but Dr. Donovan and the TASC get sidelined along the way (which understandably is very upsetting, you can feel the pain on every page). It does seem clear that the Dean doesn&#x27;t approve of Dr. Donovan&#x2F;TASC and he eventually shuts the group down, but if he allows the Facebook project to move forward under other groups that are also within the Kennedy school, then the title of this post is pretty misleading. (Oh, maybe why the actual article title says \"initial team\" instead of just \"team\".)BTW, not a particular fan of Meta, no feelings about Harvard&#x2F;Kennedy school, never heard of any of these people before except Frances Haugen and Dr. Latanya Sweeney. reply macksd 16 hours agorootparentI think sidelining the lead researcher and giving the project to another group is accurately described at \"gutting a team\". No, they didn&#x27;t end the project, but the series of events described seems to be insinuating that she could have led the project if she was willing to have her work funded by Facebook, listen to one of their former people, etc. So if that was their goal, and they just got someone else to do the work, is that any better? reply cporios 15 hours agorootparentNoting that the project and all its documents are publicly accessible to anyone at https:&#x2F;&#x2F;fbarchive.org&#x2F;. reply mjhay 15 hours agorootparentBut further work from the same leadership has been discontinued... reply tensor 13 hours agorootparentprevThat&#x27;s not quite what I imagine when I hear the term \"gutting a team.\" Gutting a team is when then very significantly reduce its size and priority. Simply switching leadership of a project isn&#x27;t gutting a team, it&#x27;s normal university politics and infighting.If they are forcing funding by Facebook&#x2F;Meta, then that does seem like a conflict of interest, but is a quite a different headline. reply rrobukef 12 hours agorootparentThe sidelining is to show damages to her reputation etc. Page 50 or so starts the description alleging how the administration and the dean gutted her department by blocking, reallocating funds, stopping hiring, and refusing to extend contracts when funds are available. reply ImPostingOnHN 12 hours agorootparentprevFrom what I gathered, they didn&#x27;t simply switch leadership, they removed it entirely, along with the person doing the most work, replacing them with nothing, which effectively shut down the project.Is there someone continuing it that I missed? reply jcheng 8 hours agorootparentAccording to the complaint, \"the project\" was FB Archive, which Dr. Donovan came up with the idea for and was the only person in the room with the actual source material. The Public Interest Tech Lab was the organization actually tasked with building out FB Archive, which they did, and it shipped: https:&#x2F;&#x2F;fbarchive.orgI think Dr. Donovan&#x27;s complaint is not that it didn&#x27;t happen, so much as she was not allowed to play a larger role in it despite having the desire, the people, the funding, and the right--as the person who came up with the idea and the person who provided the material, without which there would be no project. (And then worse, history rewritten to exclude her contributions) reply ImPostingOnHN 5 hours agorootparentWho exactly did the university get to replace the lead researcher they dismissed*?Who remains at the university doing the research halted by the dismissal* of the lead researcher?* – whether overtly or via constructive dismissal reply cbsmith 14 hours agorootparentprevFair, but it raises the question of the motives behind it. It would seem they didn&#x27;t necessarily have a problem with the research, but rather with the lead researcher. There&#x27;s complicated issues of academic freedom to parse here, but in principle, if you aren&#x27;t happy with the work someone is doing, it&#x27;s not entirely unreasonable that you&#x27;d let them go and have someone else pick up the work. reply cortesoft 14 hours agorootparent> It would seem they didn&#x27;t necessarily have a problem with the research, but rather with the lead researcherThis is the entire crux of the issue; do they have a problem with the lead researcher because she isn&#x27;t good at her job or because she is finding things that their large donor doesn&#x27;t like? reply cbsmith 14 hours agorootparentExactly. It&#x27;s easy to presume one interpretation, but it&#x27;s far from clear. reply ImPostingOnHN 14 hours agorootparentExactly. The evidence* points to the act being corrupt, but the university is free to attempt to convince people otherwise.* - The researcher being removed without any good cause evident reply gcr 6 hours agorootparentprevUniversities don&#x27;t work that way. There&#x27;s generally very little oversight over the PI of projects. The university generally wants more projects leading to more publications and grants, not less. Administrators understand that removing a PI generally means abandoning their lab&#x27;s projects, so it usually doesn&#x27;t happen. reply boringg 13 hours agorootparentprevFWIW that&#x27;s definitely not gutting a team. Swapping out leaders makes a big impact but it isn&#x27;t gutting a team. It could lead to the same outcome. reply omginternets 7 hours agorootparentIn academia, it very much is the same thing. reply ajb 11 hours agorootparentprevAn academic team isn&#x27;t the same as a team in a company though, right? My understanding (which could be incorrect) is that a PI is almost like the CEO of a startup which happens to have the goal of doing research, and operates in the context of a university. A PI is not like a team lead in a company . Each PI-led team is doing research independently of the rest of the department. I have the impression it&#x27;s not even expected to outlive the PI&#x27;s employment there. reply zbyte64 11 hours agorootparentprevImagine swapping out leaders and expecting the same outcomes. Why even bother? reply doctorpangloss 14 hours agorootparentprevGoing out and getting Washington Post, New York Times articles about your issues through \"Whistleblower Aid\" - it brings to mind Barack Obama&#x27;s great line: When some activists at that meeting said they felt that their voices were not being heard, Mr. Obama replied, \"You are sitting in the Oval Office, talking to the president of the United States.\"https:&#x2F;&#x2F;www.nytimes.com&#x2F;2016&#x2F;04&#x2F;24&#x2F;us&#x2F;obama-says-movements-l...I don&#x27;t work in PR, the issues I am politically active over are very local. This researcher paints a big target on her back, in an issue as amply documented as an academic firing, it isn&#x27;t surprising that things are not cut and dried. reply didibus 5 hours agorootparentTo be honest, there&#x27;s a difference between having your issues entertained, versus taken seriously. The former is often done as political theater. reply Beldin 15 hours agorootparentprev> but if he allows the Facebook project to move forward under other groups that are also within the Kennedy school,Move forward in the direction the dean and Facebook want, or in the direction the original team wanted to explore?Because it doesn&#x27;t seem - at all - that the two are equivalent. And it is not misleading to call out replacing a non-bribe-able PI with a susceptible or even already bribed one. reply jcheng 13 hours agorootparentI was not nearly clear or explicit enough in my comment, apologies for that. In sections 25 and 26 (page 14), the whistleblower report talks about the origins of the project. Dr. Donovan acquired the entire archive of the Facebook Files, and reached out to Dr. Latanya Sweeney, who she calls her \"most trusted colleague\":> I chose to work with Dr. Sweeney because she was the shoulder I leaned on when I needed to decode the politics of HKS. I regard Dr. Sweeney to be brilliant at computer science, the foremost authority on privacy in technology, and had a vision to build the FB Archive on the base of a data sharing platform that she had designed previously.Donovan&#x27;s vision was to build \"a searchable archive of these documents for the public interest\" and hold training workshops for other researchers. So Dr. Sweeney&#x27;s lab built it, as was the plan; and held training workshops, which was a little hurtful to Donovan as she was not invited into that process.After the fact, Sweeney summed up her view of their respective contributions in a private email to Donovan:> The technological IP (design, architecture, and implementation) in FBarchive belongs to the Lab [i.e. Sweeney] alone. No one can claim IP over the original content of course, but the Lab also has IP in the redaction strategy used. Your team contributed the citation reference used to identify each image and document, and of course, you were part of the original concept. This is the kind of details that we will document on the history page.And implies, like it&#x27;s not even worth asserting directly, that TASC&#x27;s contributions are historical, not current. A couple of responses later, Donovan says:> TASC made many contributions including getting the documents and categorizing them, as well as promoting the archive in public forums, and having my team write testimonies and 1pagers, reviewing abstracts and holding office hours with students and so many meetings.Dr. Donovan&#x27;s complaints with the project as delivered seem to mostly NOT be that she wanted it to be different than it was, but rather, that the history page contains blatant lies that minimize Dr. Donovan and TASC&#x27;s contributions. And also that it is incredibly unjust that she brought this highly valuable asset to the table, and without cause was not only shut out, but basically fired, and her historical contributions scrubbed. (Section 42.)(To be clear, this is a sad and frustrating tale and if I was Donovan I&#x27;d be pissed too.) reply juujian 11 hours agorootparentprevThe picture becomes much more clear later on. The Dean sidelined and reallocated the very generous funding which donors provided specifically for her, while also lying to the donors about this. And then winds down her research even though there is obviously demand for and interest in it. All while stringing her along. She should have been able to take her funding elsewhere if the dean didn&#x27;t want her around, there is ample precedent for that. The degree of manipulation is unprecedented and amounts to the dean stealing her funding from her&#x2F;her donors. reply ImPostingOnHN 16 hours agorootparentprev> Dr. Donovan and the TASC get sidelined along the waythis is described dismissively and in the passive voice, but it&#x27;s an active action, and quite damning.who sidelined them, and why?it seems the answers are: the school, because the researchers upset facebook, who was giving the school money> if he allows the Facebook project to move forward under other groups that are also within the Kennedy school, then the title of this post is pretty misleadingthis is misleading: if the research is allowed to continue, it should continue under the researchers who did the research, unless there&#x27;s a good reason otherwise reply klyrs 13 hours agorootparent\"The school\" is not a person with motive. Dr. Donovan&#x27;s report strongly implicates the Dean, who maintains a personal friendship with Sheryl Sandberg, as the driver behind these actions. The remaining actors appear to be interest in saving their own necks. reply 1vuio0pswjnm7 10 hours agoparentprevExhibitshttps:&#x2F;&#x2F;live-whistleblower-aid.pantheonsite.io&#x2F;wp-content&#x2F;up... reply LewisVerstappen 17 hours agoparentprevIf you&#x27;re familiar with this woman&#x27;s past research, you&#x27;d realize she is quite.... biased politically.She strongly believes in increased content moderation by \"fact checkers\".She&#x27;s spread misinformation herself like- Suggesting Russian disinformation on Facebook shifted the 2016 election (anyone who&#x27;s run a facebook ad in their life knows how absurdly ridiculous this is)- Advocating for increased censorship of information during COVID on lab leak hypothesisThis is just off a few minutes of reading her past work.I&#x27;m not a fan of Facebook (in the slightest) but also am really not a fan of the type of censorship this person wants. reply r3trohack3r 12 hours agoprevI&#x27;m hesitant to share this because it&#x27;s completely unverifiable in any way I&#x27;d be comfortable documenting. Not my life, not my secrets to tell.I had a close friend who did undergraduate research in a fisheries department.They had been researching plant selection for aquaponics to increase the yield of tilapia. They had a filtration system that pushed tank water through a bed of plant roots. The plants would be harvested, processed into fish food, and fed back to the fish. On top of this platform, they&#x27;d experiment with different plant combinations to measure the impact on water quality and protein conversion.They were seeing very high protein conversion with their plant choices (numbers high enough they gave me pause at what it would mean for society, but if I tried to throw out a number now I&#x27;d certainly get it wrong).Recycling energy like this reduced the amount of food you&#x27;d have to put into the system, and the plants handled a good portion of the filtration for the system.At some point, a large agriculture business with strong ties to the department offered a large grant that was understood to be contingent on this project being discontinued.The project was abandoned and my buddy dropped out of his degree program. reply snowflakeandrey 4 hours agoparentForgive me if I&#x27;m being dense, but why wouldn&#x27;t the researchers just go off and sell this to the customers of the large agriculture business? reply paxys 4 hours agoparentprevOn one hand I absolutely believe this does routinely happen. On the other every researcher&#x2F;inventor out there with a project that went nowhere claims that they were on the cusp of a breakthrough and only silenced because of the government&#x2F;corporations&#x2F;illuminati. I&#x27;d wager the vast majority are in the second category. reply rdedev 5 hours agoparentprevAt that point is it legally okay to just open source whatever findings you have in hand? Do university research come with some form of NDA? reply JacobThreeThree 6 hours agoparentprevPar for the course in higher education.Corporations and wealthy donors don&#x27;t give money while expecting nothing in return. reply jurynulifcation 11 hours agoparentprevCan you give any further details? This might be worth experimenting with, and I do already have an aquaculture setup. reply jongjong 9 hours agoparentprevWell isn&#x27;t that a similar story behind OpenAI drama? Big money suppressing innovation. reply 1letterunixname 8 hours agorootparentNot even closely related. One is big money corrupting academia, another is startup drama. reply jongjong 8 hours agorootparentThis is incorrectly assuming that all innovation happens in academia. reply omginternets 7 hours agorootparentSigh… no.It’s saying that this is a case of academic innovation, and that that is startup drama. reply jongjong 1 hour agorootparentI know what intentional suppression of innovation looks like. I worked in blockchain sector. I think you&#x27;re underestimating the scale of it and hence you do not see that it&#x27;s the same ideology behind both cases and many more cases. replyabeppu 16 hours agoprevSetting aside the institutional failures within Harvard, shouldn&#x27;t this also pose legal problems for the Chan Zuckerberg Foundation? I am certainly not a lawyer, but I thought the tax-benefits of a non-profit were supposed to be tied to some governance requirements and operating in pursuit of some mission other than profit. If when the Chan Zuckerberg foundation gives a donation to a school, an exec from Meta is then put on some Dean&#x27;s council, and if the foundation&#x27;s donation is used to pressure the school to advantage the corporation, then it seems like the foundation is operating as an arm of Meta, and is compromised as an independent philanthropic org. reply jonchang 15 hours agoparentCZI and CZF are structured as a for-profit LLC and a non-profit arm, respectively. Depending on where the money came from, it might not be a problem at all, though it could potentially jeopardize Harvard&#x27;s nonprofit status. I&#x27;ll leave it up to you to figure the odds of the IRS revoking that designation. reply scottyah 15 hours agoparentprevThey purposely did not make the Chan Zuckerberg Foundation a non-profit so as to not be encumbered by all the laws that affect those organizations. reply capableweb 11 hours agorootparentIsn&#x27;t \"Foundation\" a word that is usually for non-profits? I understood the different between \"Charity\" and \"Foundation\" just to be about \"Public\" vs \"Private\" organization, but both of them being non-profits. Am I misunderstanding what \"Foundation\" means here? reply AlbertCory 11 hours agorootparentI think I could start the Evil Foundation and as long as I don&#x27;t file for 501(c)(3) status, I&#x27;m still for-profit. reply shkkmo 9 hours agorootparentThe foundation here is a 501(c)(3) non profit. However it is not a public charity, which is a sub classification that comes with stricter rules and higher donation tax write-off limits.People tend to assume all 501(c)(3)&#x2F;nonproft and \"public charity\" are synonymous, but they aren&#x27;t and that can make discussions like this confusing. reply nulbyte 7 hours agorootparent> However it is not a public charity, which is a sub classification that comes with stricter rules and higher donation tax write-off limits.It sounds like you mean public charities have stricter rules. I find the opposite to be true. There are additional rules and reporting requirements that apply only to private foundations because of the limited funding and tight control of such organizations by a close-knit group of people. replyWendyTheWillow 15 hours agoparentprevAlso NAL but there’s a wiiiiide gap between committing what may be a crime, and the federal government charging a crime. reply Simon_ORourke 15 hours agoparentprevIt&#x27;s deeply dirty, in a sort of teflon get-away-with-anything way. Of course Harvard needs money to run, and has in the past accepted all manner of dubious donors, but implicitly receiving a payment quid pro quo to kill research is pretty low. reply 1letterunixname 8 hours agorootparentWhat&#x27;s actually dirty? Silicon Valley Community Foundation (SVCF): a tax breaks now, pay-give later DAF. It ostensibly does some community projects that are token billionaire pet projects, but it exists first and primarily to reduce taxes of the gigarich. reply intrasight 17 hours agoprevI just read that this morning. I&#x27;m interested enough in the outcome that I put a calendar reminder 6 months out to check what happened. Doing so made me wonder if there&#x27;s a service that would email me updates about legal cases like this that I would like to follow. reply WaffleIronMaker 17 hours agoparentIt&#x27;s possible that a Google Alert[1] might be enough for your use case, depending on how well the legal cases are covered by Google.[1] https:&#x2F;&#x2F;support.google.com&#x2F;websearch&#x2F;answer&#x2F;4815696?hl=en reply beretguy 16 hours agorootparentAny non Google alternatives out there? reply alwayseasy 16 hours agorootparentThis social listening company does one: https:&#x2F;&#x2F;alerts.talkwalker.com&#x2F;alerts&#x2F;They might try to call and email you though. reply turminal 16 hours agorootparentprevUnless Google Alert gets shut down by then. reply doublerabbit 15 hours agorootparentOr bought to silence any alarms with the terms \"Facebook\" reply sertbdfgbnfgsd 17 hours agoparentprevWho would pay for this?Random people like you and me wouldn&#x27;t pay for something they&#x27;re gonna use twice in their lifetime, and lawyers surely have something like this, possibly integrate with all the other tools they use. reply gessha 16 hours agorootparent> lawyers surely have something like thisNot a lawyer and not familiar with their systems but based on my knowledge of other industries I’d say it’s not guaranteed they have a solution.Could be good ol sticky notes and manual calendar events. reply freejazz 12 hours agorootparentYeah, check out docketbird. Also, noticed attorneys already automatically get all ECF filings. reply sertbdfgbnfgsd 16 hours agorootparentprevThis is really really naive. reply TaylorAlexander 9 hours agorootparentI do love it when people say \"I am not familiar with this situation at all but\" and then proceed to speculate about it having made clear they have no basis for their speculation. reply gessha 8 hours agorootparent> they have no basis for their speculation> based on my knowledge of other industries:) reply graphe 15 hours agorootparentprevWhy does it need to be paid? reply 23B1 9 hours agorootparentprevI would pay for a comprehensive AI-driven service that delivers alerting on any topic. Google alerts SUCKS for so many reasons.I might not be aware of other services though so if anyone is – please enlighten me! reply johnchristopher 17 hours agoparentprevThere are services that monitors changes on webpages so you could plug the \"official\" page where legal&#x2F;official information about that case lives and wait for a change, maybe it would even work with a search engine results page. reply natrys 16 hours agorootparentI set up cron to run urlwatch[1] once a day on a vps, and it emails me updates to pages. It supports CSS selectors, various filters (like html2text) and so on. Combined with a little elisp to diff highlight emails in Emacs, this has one of the highest usefulness&#x2F;maintenance ratio of things I self-host.[1] https:&#x2F;&#x2F;urlwatch.readthedocs.io&#x2F;en&#x2F;latest&#x2F; reply Cthulhu_ 17 hours agorootparentprevMight be a good addition to archive.org, since they will index and re-index pages from time to time anyway and detect changes. reply AlbertCory 16 hours agoparentprev\"Follow up on stories we reported six months ago\"Sounds like something that anyone claiming to practice Journalism should be doing already. reply bowmessage 16 hours agoparentprevYou might be interested in https:&#x2F;&#x2F;www.courtlistener.com&#x2F; reply kbenson 16 hours agoparentprevAnything that provides a calendar and&#x2F;or timed TODO&#x2F;list items. Just set calendar item or the TODO item&#x27;s due date 6 months out. Any OS you&#x27;re using whether mobile or desktop probably has an app for this shipped with it. reply Kon-Peki 17 hours agoparentprev> if there&#x27;s a serviceThere are plenty of mailing list services that associates of large law firms sign up for. I haven&#x27;t been around people in that world for a while so I don&#x27;t know the names, but I&#x27;m sure you can find them if you spend time looking. reply karaterobot 14 hours agoprev> [Harvard] also denies that she was fired, saying she “was offered the chance to continue as a part-time adjunct lecturer, and she chose not to do so.”I have not read her filing, or followed her specific research, so I have no opinion about the possible merits or conspiracy theories regarding winding down her project. But, that statement by Harvard is suspicious. You take someone who is high profile, doing their own research, and offer them basically an insulting part time job (sorry to my adjunct lecturer friends, you know what I mean) and say \"well, we didn&#x27;t fire her, it was her choice.\" It would be like having a Director level position at a company, and being told your department was shutting down, but you could stay on as a part time contractor if you want. You just soft-fired her and tried to give yourself cover. reply anonymouskimmer 14 hours agoparentYeah, this is called \"constructive dismissal\" in the real world. reply thomastjeffery 14 hours agoparentprevI don&#x27;t know how it would be at a Harvard school, but all the adjunct professors I have ever known (working for large, but not ivy-league universities) were making significantly less than the part-time software contractors I have known. reply teachrdan 14 hours agorootparentI went from being an adjunct instructor at a California community college to a software engineer. Now I earn more in a month than I used to make in a year. And the more prestigious a school, the worse the pay in a lot of cases. Like I made more at my CC than I would have made teaching at UC Berkeley, which is by some measures the #15 university in the US! reply SamoyedFurFluff 17 hours agoprevThis isn’t unusual in academia btw. It’s an open secret that economics departments are bought the same way— a generous donation to the department in exchange for the donor hand-picking the department chair. reply nerpderp82 16 hours agoparentInvisible Hand indeed. reply miohtama 16 hours agorootparentThe invisible hand has its thumb up. reply kbenson 16 hours agorootparentThe invisible hand has its thumb on the scale. reply ryeights 16 hours agorootparentprevMore like a middle finger… reply isk517 15 hours agorootparentprevPlease pay no attention to the hand behind the curtain. reply Arson9416 16 hours agorootparentprevWhat does this have to do with the free market? reply ajkjk 16 hours agorootparentFairly obvious, right? reply Arson9416 15 hours agorootparentNo, which is why I&#x27;m asking. reply fmbb 15 hours agorootparentThe current economic system where (in the US) bribes are “speech” and corporations are people unavoidably leads to things like this project getting neutered.“The invisible hand” Adam Smith refers to are the unintended consequences from merchants’ want to keep their capital: increasing the domestic capital stock and enhancing military power for the state, i.e. protectionism etc.More broadly and lately it refers to any unintended societal consequences from the free market.Consequently it never means “finding a good price” which 99% of everyone using the term seems to believe. reply Arson9416 15 hours agorootparentBribery exists in every economic system, even before economic systems existed, and is not uniquely connected to the free market. Nor are they connected to \"unintended societal consequences\", since bribes very clearly have a specific goal. So it doesn&#x27;t make any sense. reply karaterobot 14 hours agorootparentJust wanted to say that you&#x27;re completely correct and making a very reasonable statement which is not controversial. I would love to hear about an economic system in which bribery did not exist or have influence, but I have not seen any examples of that yet, in the present day or in history.I don&#x27;t agree that bribes can&#x27;t have unintended social consequences. They do have specific goals, yes. But some unintended consequences of bribery would be things like discouraging honest participants, or encouraging the most corrupt people (rather than the best, on merit) to place themselves in positions of authority, so as to get bribes. All of these are unintended in the sense that neither the person giving the bribe nor the person taking the bribe are trying to bring them about per se, they&#x27;re only thinking about the immediate consequences (I get what I want). reply Der_Einzige 11 hours agorootparentUhh, Singapore? Not everywhere is corrupt you know! reply karaterobot 11 hours agorootparentSingapore&#x27;s not an economic system, but rather a country. In any case, it&#x27;s still got corruption. Bribery is one form of corruption, and I have no doubt whatsoever that you can bribe someone in Singapore.https:&#x2F;&#x2F;www.transparency.org&#x2F;en&#x2F;cpi&#x2F;2022&#x2F;index&#x2F;sgp reply staunton 6 hours agorootparentIllegally bribing someone is different from legally and secretly using money to influence the actions of institutions reply Arson9416 14 hours agorootparentprevI agree that they can have unintended consequences, but I wouldn&#x27;t say any more or less than anything else. This is why I&#x27;m struggling with the \"invisible hand\" analogy, which focuses on a connection to unintended (positive) consequences. reply ajkjk 7 hours agorootparentprev\"Bribery exists in every economic system\" is not an argument for being okay with bribery in this system. reply Arson9416 4 hours agorootparentGood thing I didn&#x27;t make that argument anywhere. My point with that statement is that bribery is in no way connected to capitalism or free markets because it exists independent of the market type.When bribery happens in a country with a command economy, do you still say \"there&#x27;s that invisible hand of capitalism again\"? reply shuntress 11 hours agorootparentprevThe point is that this type of corruption is inevitable when the \"invisible hand\" is completely unrestrained. reply Arson9416 4 hours agorootparentBribery is a corruption that happens in every single economic system, so it has nothing to do with the \"invisible hand\" of capitalism. In fact, arguments could be made as to why it happens less in free markets (where an economy flows more freely) than in non-free markets (where there are artificial barriers, making bribery more effective&#x2F;needed). reply ajkjk 7 hours agorootparentprevWell if you need it spelled out: the \"invisible hand\" refers to indirect social impacts of free markets which are typically meant to be good things. So any example of market-ish behavior causing things that seem incontrovertibly bad, like buying a department chair under the guise of targeted donations to influence policy to (presumably) protect a certain class of actors, is an example of the \"invisible hand\" doing a bad thing, hence an example of how this \"feature\" of free markets, often used to defend them, is actually a bad quality.This is totally unsurprising to most people who aren&#x27;t directly benefitting from an unchallenged free market and it usually seems like the \"invisible hand\" is brought up as a bullshit argument by those already in power to justify accumulating more power, so it&#x27;s a point of bitterness, hence the OP&#x27;s sarcasm. reply Arson9416 4 hours agorootparentBribery is not \"market-ish\" behavior in the sense that it is connected to capitalism and free markets. But you also mention bitterness, which explains the reactions to my question. I think that means people want to be bitter at the idea of capitalism and free markets, whether or not it actually makes sense in this instance of bribery. replyblindriver 15 hours agoprevIs this a surprise? All of these universities are known to bow down to the biggest wallets, so why on earth would anyone expect that they wouldn&#x27;t can any investigations to someone who donated $500 million? I&#x27;m shocked that anyone else is shocked. reply harry8 7 hours agoparentWhether you are surprised or not is barely relevant. It is newsworthy and worth discussing particularly when there is concrete evidence on which to make or fail to make a case.\"This surprises you?!\" Is a statement that contributes nothing. The occurrence of people doing wrong is not surprising, it is frequently shocking. The fallout when such people are caught out is worth noting. reply ben0x539 12 hours agoparentprevI assume people are less shocked and more upset in, you know, that weary and disappointed way. Sometimes it&#x27;s good to loudly complain about bad things happening even if you&#x27;re not surprised about them happening! reply LightHugger 12 hours agoparentprevI suppose each one of these posts is a lesson to at least somebody about how widespread institutional corruption is. reply 353 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Disinformation scholar Joan Donovan accuses Harvard University of firing her to appease Facebook and violating her right to free speech.",
      "Donovan claims her dismissal was due to Harvard receiving a $500 million pledge from Mark Zuckerberg's charitable arm and her involvement with the Facebook Papers.",
      "Harvard denies firing Donovan and asserts that she was offered a part-time adjunct lecturer position, prompting Donovan to file a legal statement with the Education Department and Massachusetts attorney general for an investigation into her dismissal and Harvard's alleged deception of donors."
    ],
    "commentSummary": [
      "Recent discussions and incidents at Harvard University have raised concerns about research funding and the influence of major donors.",
      "Allegations of research suppression, conflicts of interest, and unethical actions by university officials have been brought to light.",
      "The discussions also explore topics such as academic freedom, the ethics of accepting restricted funding, and the role of bribery in economic systems, emphasizing the need for transparency and integrity in research institutions."
    ],
    "points": 460,
    "commentCount": 456,
    "retryCount": 0,
    "time": 1701699637
  },
  {
    "id": 38520487,
    "title": "Decompiler Explorer: Open-Source Tool for Analyzing Binary Files",
    "originLink": "https://dogbolt.org/",
    "originBody": "Decompiler Explorer What is this? Upload File Your file must be less than 2MB in size. Uploaded binaries are retained. Samples Or check out one of these samples we've provided: Select a Sample... A CTF Challenge on x86 Linux Hello World on Arm Linux Megatest Decompiler Test Binary: arm64 FreeBSD Megatest Decompiler Test Binary: arm64 macOS Megatest Decompiler Test Binary: x86 Windows Ping6 on x86_64 Linux VTables on x86 Windows Yet Another x86 Linux CTF Challenge angr BinaryNinja Boomerang dewolf Ghidra Hex-Rays RecStudio Reko Relyze RetDec Snowman angr 1 BinaryNinja 1 Boomerang 1 dewolf 1 Ghidra 1 Hex-Rays 1 RecStudio 1 Reko 1 Relyze 1 RetDec 1 Snowman 1 Decompiler Explorer is open source! Fork it on GitHub!",
    "commentLink": "https://news.ycombinator.com/item?id=38520487",
    "commentBody": "Dogbolt Decompiler ExplorerHacker NewspastloginDogbolt Decompiler Explorer (dogbolt.org) 399 points by ingve 16 hours ago| hidepastfavorite68 comments psifertex 9 hours agoCan I just say, thanks to the person who posted this for waiting until this week to do so. (Side note: I suspect it was due to the recent coverage from C++ Weekly which is a great resource: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=h3F0Fw0R7ME)As recently as last week we had some horrible performance problems but it looks like the queue (https:&#x2F;&#x2F;dogbolt.org&#x2F;queue) is mostly still fine! Other than the long pole of a few of the decompilers being backed up, things are humming along quite smoothly! Josh + Glenn have done some great work on it! (https:&#x2F;&#x2F;github.com&#x2F;decompiler-explorer&#x2F;decompiler-explorer&#x2F;c...) reply dang 15 hours agoprevRelated:Decompiler Explorer - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32079227 - July 2022 (82 comments) reply hoosieree 14 hours agoprevWow, I really could have used this for my Ph.D. research (deep learning for obfuscated code).I ditched Ghidra in my experiments in favor of angr early on because Ghidra did not play nicely with multiprocessing and I had a lot of data to process. Well maybe it does but it was much easier for me to achieve the same thing with angr.Love the name! Although I feel compelled to point out that Compiler Explorer is the name of the project and Godbolt is its author&#x27;s last name, but I suppose if people are to the point of using Godbolt as a verb the ship has sailed. reply psifertex 14 hours agoparentWe know! Similarly, the GH repo is actually the Decompiler Explorer:https:&#x2F;&#x2F;github.com&#x2F;decompiler-explorer&#x2F;decompiler-explorer&#x2F; reply mvelbaum 5 hours agoparentprevHas there been any good progress in deobfuscating&#x2F;decompiling machine code using Machine Learning techniques? reply tomcam 8 hours agoparentprevSometimes we must look back in angr reply rixtox 14 hours agoprevI really wish a similar tool for exploring binary lifting to different IRs. Like Ghidra p-code with sleigh, LLVM Machine IR, Qemu TCG etc reply psifertex 14 hours agoparentIRs aren&#x27;t generally suited toward small snippets of examination by human when you&#x27;re starting with a full binary. I would imagine something like that would only work well when done for very small bits of assembly. Likewise, you might be interested in BNIL which is an entire stack of ILs that Binary Ninja is based on. (You can see it exposed in the cloud.binary.ninja UI or the demo) reply JonChesterfield 10 hours agoparentprevQemu works by translating a binary to an IR then doing stuff with it. Valgrind likewise. There&#x27;s an optimiser called bolt (associated with facebook) which has the same idea. reply psifertex 9 hours agorootparentYup, I&#x27;m aware of both of those, but none of those tools listed so far are intended for the IR to be for human-consumable unlike disassemblers and decompilers. You think disassembly is verbose compared to a decompiler? Go look at the equivalent Vex (Valgrind&#x27;s IR) for any non-trivial disassembly. It&#x27;s suuuper verbose.As far as I know, BNIL (https:&#x2F;&#x2F;docs.binary.ninja&#x2F;dev&#x2F;bnil-overview.html) is the only one that is designed to be readable and it still wouldn&#x27;t make sense to include it in an IL comparison such as the one done here for decompilation in my opinion. reply aidenfoxivey 5 hours agoprevSpeaking of decompilers, would Binary Ninja be a safe bet to pick? I&#x27;ve been told IDA is the gold standard, but it&#x27;s also expensive for someone who wants to recreationally reverse engineer. reply kdbg 2 hours agoparentBinja decompiler is more-or-less fine. Its not as mature as IDA or Ghidra but its not a bad decompiler.Though for me the big selling point on Binja is the Intermediate Languages (ILs). HIgh-level IL is the decompiler but you also get Low-level and Medium-level ILs as steps between assembly and source. If the decompiler is a bit funky you can look at the ILs to get a better idea of what is happening. the ILs are also just much nicer to read than plain assembly so I tend to use them a lot.Its a feature that isn&#x27;t really matched on any other platform. Ghidra and IDA both have a single IL that is more machine readable compared to Binja&#x27;s human-readable ones. reply IAmLiterallyAB 5 hours agoparentprevHonestly just use Ghidra. It has it&#x27;s quirks but it&#x27;s pretty good. And open source. If it&#x27;s good enough for the NSA it&#x27;s probably good enough for recreational use. reply codedokode 37 minutes agorootparentIf Ghidra is made by NSA, does it mean that it can have backdoors for non-US users? reply cristeigabriel 15 hours agoprevVery nice. A parallel, I&#x27;ve been working on an emulator project recently, implementing my own disassembler, and I keep thinking about how I would turn patterns of machine code into a generalized form, which could then be turned into something like C-like pseudo-code, so it&#x27;s been really compelling me lately to implement my own toy decompiler reply iBotPeaches 14 hours agoprevLove this - I can almost imagine the convincing for other companies wasn&#x27;t even needed when they realized a small binary size and comparison to competitors would net them more business. A perfect little solution for triaging issues between services and comparing solutions. reply psifertex 14 hours agoparentThat was indeed the logic. The two main commercial solutions included (Binary Ninja made by Vector 35, where I&#x27;m one of hte founders) and Hex-Rays both pay for all the hosting costs. And it&#x27;s not particularly cheap -- there&#x27;s a fair amount of compute to drive the decompilers especially as some of them are... not very efficient. reply Arch-TK 15 hours agoprevHexRays online? Is that allowed? reply alright2565 15 hours agoparentFrom the FAQ, Hex-Rays actually sponsors the project:> Vector 35 and Hex-Rays jointly sponsor the hosting on Digital Ocean as a community service. reply cristeigabriel 15 hours agorootparentIt makes sense, it&#x27;s a perfect advertisement of their superiority. reply Fabricio20 14 hours agorootparentIndeed, looking at the samples HexRays really did a great job compared to the others, much more readable code. reply rychco 15 hours agoparentprevWhen this first came out a year(ish?) ago, I remember seeing somewhere that they had received permission from Hexrays&#x2F;Ilfak Guilfanov. reply sonicanatidae 15 hours agoparentprevNot anymore!angrily writes a letter to his congressman who won&#x27;t understand a word of it reply quickthrower2 12 hours agorootparentYour congressman doesn’t yet have hexrays to decompile your letter reply exikyut 12 hours agorootparentHis brain is relegated to spewing out the Matrix unparsed as he receives it. He gets none of the blondes, brunettes or redheads. reply costco 8 hours agoprevI wish I saw this when it was posted last year. This is awesome and really convenient. reply fritzo 10 hours agoprevIs there a similar project for javascript? That is, de-obfuscating large javascript codebases? reply w10-1 14 hours agoprevOMG I am so happyOf note: HexRays is not only cleaner, but right now their queue is mostly empty while others are backed up. reply psifertex 9 hours agoparentBinary Ninja likewise is empty and keeps up just fine as well. It&#x27;s not a coincidence that the two commercial products that are funding it are both confident enough to put their stuff online like this.And it&#x27;s no conspiracy theory or intentional sandbagging, you can see the implementation: https:&#x2F;&#x2F;github.com&#x2F;decompiler-explorer&#x2F;decompiler-explorerand if anyone can improve the other tools performance we&#x27;d be happy to accept it. We reached out to the Ghidra devs: https:&#x2F;&#x2F;github.com&#x2F;NationalSecurityAgency&#x2F;ghidra&#x2F;issues&#x2F;5228 but they didn&#x27;t have any silver bullets for us either. reply 29athrowaway 10 hours agoprevNow take the output of dogbolt and feed into godbolt. reply userbinator 5 hours agoparentMachine translation, for machine code.Theoretically, a fixed point should be reached. reply staunton 10 hours agoparentprevAnd reinforcement-train an LLM to reconstruct the original code... reply 29athrowaway 9 hours agorootparentThat would be dogebolt reply Carbocarde 13 hours agoprev> All submitted binaries are saved and made available to any of the authors of the tools used so they may improve their decompilers. If you&#x27;re such an author who would like access, let us know!.oof reply CaliforniaKarl 13 hours agoparentGood that this is clearly mentioned up-front on their site. reply saagarjha 11 hours agoparentprevSweet, free file hosting reply marcellus23 8 hours agoparentprevThey make it very clear. If you don&#x27;t notice that before uploading some private binaries, that&#x27;s on you. reply einpoklum 12 hours agoparentprevIf you believe that content you submit to websites is not examined by interested parties associated with that website, then - I have a bridge to sell you... or perhaps I should say a Google account to give you, free of charge. reply Carbocarde 10 hours agorootparentCompare this policy to godbolt’s policy:> In short: your source code is stored in plaintext for the minimum time feasible to be able to process your request. After that, it is discarded and is inaccessible. In very rare cases your code may be kept for a little longer (at most a week) to help debug issues in Compiler Explorer. reply saagarjha 9 hours agorootparentPretty sure links work basically forever reply extraduder_ire 5 hours agorootparentI think they changed it recently, but all of the code you submit is embedded in the URL. (after an anchor) So, it&#x27;s stored by google&#x27;s link shortening service, but is resubmitted to the site every time you load it. reply smegsicle 11 hours agoparentprevso like vscode? reply danielwmayer 14 hours agoprevThe name of this is a reference to the incredibly useful godbolt compiler explorer. If you are interested in this you will likely enjoy the other as well:https:&#x2F;&#x2F;godbolt.org&#x2F; reply riffraff 14 hours agoparentand for those who don&#x27;t know it, that one is named after the author, Matt Godbolt.I thought for a longtime it was some joke I wasn&#x27;t getting related to deities smithing people. reply insulanus 14 hours agorootparent> deities smithing people.That&#x27;s \"deities smiting people.\", but I really like the idea of deities smithing people :) reply WJW 10 hours agorootparentThe Dwarven god in DnD is so good at crafting he can literally make new souls in his forge. :) reply stcredzero 12 hours agorootparentprevThis happens in the Norse myths. reply pjmorris 13 hours agorootparentprevThere&#x27;s a joke about Adam and Eve in here somewhere. Genesis 2 for reference. reply reactordev 12 hours agorootparentSculpty terracotta would be a fitting choice. It&#x27;s pretty easy to sculpt when kneaded, bakes in a traditional oven, keeps it&#x27;s details. Perfect for silicone mold making. reply TeMPOraL 10 hours agorootparent> bakes in a traditional ovenNow that reminds me of a verse from a song I heard on the radio as a teenager: Had a meeting with my maker The superhuman baker He popped me in the oven And set the dial to lovin&#x27; reply Waterluvian 14 hours agorootparentprevDamn. To just name something your last name.I thought it was the sibling part to the Jesus Nut. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Jesus_nut reply mattgodbolt 13 hours agorootparentIt&#x27;s never been called anything but either \"GCC Explorer\" or \"Compiler Explorer\", by me, anyway... The URL it&#x27;s accessible for is an accident of the one I had hanging around :) (it&#x27;s now available at compiler-explorer.com too, but...the name other people use has stuck so I&#x27;ll never be able to reclaim my own domain...) reply joemi 13 hours agorootparentI think you _could_ reclaim your own domain if you wanted. You&#x27;d want to have a banner at the top with a clear note directing people to the new domain for the compiler explorer, so that people realize immediately that you&#x27;re not domain squatting. A few people might put up a stink, but I&#x27;m pretty confident that most people wouldn&#x27;t mind, especially since the tool itself is so useful. The name, for those who don&#x27;t know it as your last name, is fun, but it isn&#x27;t the reason people use the tool. Eventually, over enough time, people would start remembering the new URL, and you could shrink or remove the banner (and&#x2F;or put a note elsewhere on the page). reply johannes1234321 10 hours agorootparentEven then the internet (and even books) are full of \"godbolt\" links, to the tool itself, to specific code samples. Till all those became irrelevant will take quite some time.As a data point: Search on stack overflow yields \"500\" hits. https:&#x2F;&#x2F;stackoverflow.com&#x2F;search?q=godbolt reply bombcar 11 hours agorootparentprevHonestly \"godbolt\" is so memorable I can find it instantly even though I rarely use it; but \"compiler-explorer\" sounds like some generic SEO spam site that I&#x27;d probably never click on. reply nhatcher 12 hours agorootparentprevIt is fantastic name of an otherwise fantastic tool. The day I found it was your last name made me chuckle and liked it even more. And since I am here, thank you very much for it!I always call it the compiler explorer but the url, as a sibling comment says, is memorable. reply Waterluvian 13 hours agorootparentprevIt’s such a memorable name for a tool like that. Other than losing your domain name to the topic, how do you feel about the de facto name?To a far far lesser degree, I’ve experienced many examples of “you named it X but everyone at work calls it Y and now you have to live with that.” It used to really irk me for some reason. reply jchw 14 hours agorootparentprevCould be misremembering, but IIRC it was called Compiler Explorer and used to live only on a subdomain of godbolt.org. But, it was so useful that it became presumably vastly higher traffic than the personal homepage part and people often referred to it as just \"Godbolt\" probably because it sounds cooler and is shorter than saying \"Compiler Explorer\" (and it may not be obvious the domain name is a last name rather than just a cool name for something.) reply Waterluvian 14 hours agorootparentNow that’s a pretty cool origin story for a name. What a compliment! reply jjoonathan 11 hours agorootparentprevTo be fair it&#x27;s an amazing last name and it feels like there probably is a story, it just has to do with this guy&#x27;s ancestors rather than the assembler tool we all know and love. reply 29athrowaway 10 hours agoparentprevThere&#x27;s also RMSbolt, which is a Compiler explorer for Emacs, where Richard M. Stallman is regarded as the \"creator\". reply extraduder_ire 5 hours agorootparentIt makes for a nice parallel, since the original version of godbolt was just a split tmux session with vim running on one side, and \"watch &#x27;gcc -S -o &#x2F;dev&#x2F;stdout&#x27;\" on the other. The main advantage of putting it online is not needing all of the compilers locally. reply reaperman 14 hours agoparentprevIt might also be a bit of a portmanteau with a second reference to dogpile.com which was a pre-Google \"search engine\" that compiled search results from multiple search engines. Back in the day you often had to separately search altavista.com, lycos.com, askjeeves.com, yahoo.com, etc. because some of them would work for your query but others would not and it was difficult to predict the performance of any particular search engine, but usually at least one of them would have the result you wanted&#x2F;needed.Dogpile was an automated way to search all of the search engines at the same time with one query.https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;19990429194414&#x2F;http:&#x2F;&#x2F;dogpile.co... reply codetrotter 14 hours agorootparentLook no further than https:&#x2F;&#x2F;dogbolt.org&#x2F;faq> It&#x27;s meant to be the reverse of the amazing Compiler Explorer.With a link to https:&#x2F;&#x2F;godbolt.org&#x2F;It’s very obvious that Dogbolt Decompiler Explorer is primarily named after Godbolt Compiler Explorer. reply psifertex 14 hours agorootparentprevI do remember dogpile, but as one of the folks who named it, nope, that wasn&#x27;t a conscious influence! reply borski 11 hours agorootparentOh, it you! Hi Jordan I miss you let’s hang out sometime :) reply psifertex 9 hours agorootparentYes, lets! And before hacker summer camp when we&#x27;re way way too busy! :-) replyT3RMINATED 15 hours agoprev [–] nice replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Decompiler Explorer is an open-source tool that enables users to upload and analyze binary files.",
      "It supports multiple samples and provides various decompilers for code exploration.",
      "The tool is hosted on GitHub and can be easily forked for customization and collaboration."
    ],
    "commentSummary": [
      "The conversation revolves around the Dogbolt Decompiler Explorer and its performance, along with other code disassembling and decompiling tools like Binary Ninja and Ghidra.",
      "Hex-Rays and Vector 35 showcase their decompiling capabilities in HexRays Online, a sponsored platform.",
      "The conversation also mentions \"agoprev,\" a website for sharing binaries and making comparisons with similar platforms, and the popularity of the GCC Explorer tool. The creator of Godbolt denies any intentional influence from Dogpile."
    ],
    "points": 399,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1701712375
  },
  {
    "id": 38523704,
    "title": "YouTuber gets 6 months in prison for obstructing plane crash probe",
    "originLink": "https://www.justice.gov/usao-cdca/pr/santa-barbara-county-man-sentenced-6-months-prison-obstructing-federal-probe-plane",
    "originBody": "Press Release Santa Barbara County Man Sentenced to 6 Months in Prison for Obstructing Federal Probe into Plane Crash He Posted on YouTube Monday, December 4, 2023 Share For Immediate Release U.S. Attorney's Office, Central District of California LOS ANGELES – A YouTuber pilot was sentenced today to six months in federal prison for obstructing a federal investigation by deliberately destroying the wreckage of an airplane that he intentionally crashed in Santa Barbara County to gain online views. Trevor Daniel Jacob, 30, of Lompoc, was sentenced by United States District Judge John F. Walter. Jacob pleaded guilty on June 30 to one count of destruction and concealment with the intent to obstruct a federal investigation. Jacob is an experienced pilot, skydiver and former Olympic athlete who had secured a sponsorship from a company that sold various products, including a wallet. Pursuant to the sponsorship deal, Jacob agreed to promote the company’s wallet in a YouTube video that he would post. On November 24, 2021, Jacob took off in his airplane from Lompoc City Airport on a solo flight purportedly destined for Mammoth Lakes. Jacob did not intend to reach his destination, but instead planned to eject from his aircraft during the flight and video himself parachuting to the ground and his airplane as it descended and crashed. Prior to taking off, Jacob mounted several video cameras on different parts of the airplane and equipped himself with a parachute, video camera and selfie stick. Approximately 35 minutes after taking off, while flying above the Los Padres National Forest near Santa Maria, Jacob ejected from the airplane and videoed himself parachuting to the ground. Using the video camera mounted on the selfie stick and the video cameras he mounted on the airplane, Jacob was able to record the airplane as it descended and crashed into a dry brush area in Los Padres National Forest. After parachuting to the ground, Jacob hiked to the location of the wreck and recovered the data containing the video recording of his flight and the crash of the airplane. On November 26, 2021, Jacob informed the National Transportation Safety Board (NTSB) about the plane crash. The NTSB, which launched an investigation into the crash on or about that same day, told Jacob that he was responsible for preserving the wreckage so the agency could examine it. Jacob agreed to determine the crash location and provide both the coordinates of the downed plane and videos of the crash to NTSB investigators. Three days later, the Federal Aviation Administration (FAA) launched its own investigation into the plane crash. In the weeks following the plane crash, Jacob lied to investigators that he did not know the wreckage’s location. In fact, on December 10, 2021, Jacob and a friend flew by helicopter to the wreckage site. There, Jacob used straps to secure the wreckage, which the helicopter lifted and carried to Rancho Sisquoc in Santa Barbara County, where it was loaded onto a trailer attached to Jacob’s pickup truck. Jacob drove the wreckage to Lompoc City Airport and unloaded it in a hangar. He then cut up and destroyed the airplane wreckage and, over the course of a few days, deposited the detached parts of the wrecked airplane into trash bins at the airport and elsewhere, which was done with the intent to obstruct federal authorities from investigating the November 24 plane crash. On December 23, 2021, Jacob uploaded a YouTube video titled, “I Crashed My Airplane,” that contained a promotion of the wallet and depicted him parachuting from the plane and the aircraft’s subsequent crash. Jacob intended to make money through the video. Jacob lied to federal investigators when he submitted an aircraft accident incident report that falsely indicated that the aircraft experienced a full loss of power approximately 35 minutes after takeoff. Jacob also lied to an FAA aviation safety inspector when he said the airplane’s engine had quit and, because he could not identify any safe landing options, he had parachuted out of the plane. “It appears that [Jacob] exercised exceptionally poor judgment in committing this offense,” prosecutors argued in a sentencing memorandum. “[Jacob] most likely committed this offense to generate social media and news coverage for himself and to obtain financial gain. Nevertheless, this type of ‘daredevil’ conduct cannot be tolerated.” The United States Department of Transportation – Office of Inspector General investigated this matter. The NTSB and FAA provided substantial assistance. Assistant United States Attorneys Dominique Caamano and Dennis Mitchell of the Environmental Crimes and Consumer Protection Section prosecuted this case. Contact Ciaran McEvoy Public Information Officer ciaran.mcevoy@usdoj.gov (213) 894-4465 Updated December 4, 2023 Component USAO - California, Central Press Release Number: 23-265",
    "commentLink": "https://news.ycombinator.com/item?id=38523704",
    "commentBody": "YouTuber sentenced to 6 months in prison for obstructing probe into plane crashHacker NewspastloginYouTuber sentenced to 6 months in prison for obstructing probe into plane crash (justice.gov) 388 points by grecy 12 hours ago| hidepastfavorite216 comments JumpCrisscross 11 hours agoCritically, he is not going to jail for intentionally crashing the plane. He is being jailed \"for obstructing a federal investigation by deliberately destroying the wreckage of an airplane.\"Had he cooperated, it&#x27;s plausible to see him getting away with a license revocation and fine. Instead he did this:\"In the weeks following the plane crash, Jacob lied to investigators that he did not know the wreckage’s location. In fact, on December 10, 2021, Jacob and a friend flew by helicopter to the wreckage site. There, Jacob used straps to secure the wreckage, which the helicopter lifted and carried to Rancho Sisquoc in Santa Barbara County, where it was loaded onto a trailer attached to Jacob’s pickup truck.Jacob drove the wreckage to Lompoc City Airport and unloaded it in a hangar. He then cut up and destroyed the airplane wreckage and, over the course of a few days, deposited the detached parts of the wrecked airplane into trash bins at the airport and elsewhere, which was done with the intent to obstruct federal authorities from investigating the November 24 plane crash.\" reply throw0101b 10 hours agoparent> Had he cooperated, it&#x27;s plausible to see him getting away with a license revocation and fine.Reminder of the quotation from Howard Baker (R-TN): “It is almost always the cover-up rather than the event that causes trouble.”Though some would disagree:> There&#x27;s this old line the wise folks in Washington have that &#x27;it&#x27;s not the crime, but the cover-up.&#x27;> But only fools believe that. It&#x27;s always about the crime. The whole point of the cover-up is that a full revelation of the underlying crime is not survivable. Let me repeat that, the whole point of the cover-up is a recognition that a full revelation of the underlying bad act is not survivable. Indeed, the cover-ups are usually successful. And that&#x27;s why they&#x27;re tried so often. Just look at this administration [in 2007]. They&#x27;re the ultimate example of this truth.* https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20071026022311&#x2F;https:&#x2F;&#x2F;talkingpo... reply JumpCrisscross 10 hours agorootparent> the whole point of the cover-up is a recognition that a full revelation of the underlying bad act is not survivableThere are numerous counter-examples to this claim. In many cases, it&#x27;s obvious because the cover-up is of a civil infraction. reply kesslern 10 hours agorootparentI feel like the Toupee Fallacy is lurking around in this conversation. We know how many cover-ups are successful, and the ones we know about are nearly universally unsuccessful. reply JumpCrisscross 10 hours agorootparentNot disagreeing. Just pushing back on cover-ups being rational. In many cases, the cover-up wasn&#x27;t worth it. \"Full revelation of the underlying bad act\" would have been utterly survivable, even taking into account the odds of getting away with no consequence. reply TeMPOraL 10 hours agorootparentYeah, my feel is that the underlying act was often enough survivable, but it didn&#x27;t feel like it at the time. A cover-up attempt in state of panic is opposite of rational (except maybe in terms of calming your own nerves). reply ethbr1 8 hours agorootparentAnd it takes a steely set of nerves to calmly wait for the dice to finish rolling.Panic tends to bias towards action. reply TerrifiedMouse 9 hours agorootparentprevGuess some people like to play the odds. Rather than take 50% damage, they choose to gamble between 0% damage (cover up successful) and 100% damage (cover up failed and isn’t survivable) - they are equivalent in terms of expected value. reply petsfed 9 hours agorootparentBut they&#x27;re not necessarily equivalent. If option a (0% damage) is equiprobable with option b (100% damage), then yeah, the expectation value is 50% damage. But if option b is 4 times more likely than option a, then the expectation value is 80% (1&#x2F;5 *0 + 4&#x2F;5*100 = 80). It&#x27;s that misapprehension of the probabilities that is the error of the person failing to coverup a crime.Just because there are only two possible outcomes doesn&#x27;t mean that they are equiprobable. Not all coin tosses use a \"fair\" coin. reply zztop44 9 hours agorootparentThere are three outcomes in this hypothetical: don’t bother with the cover up (50% damage); successful cover up (0% damage); and failed cover up (100% damage). So the calculation is a bit more complicated. reply petsfed 8 hours agorootparent\"don&#x27;t bother with the cover up\" doesn&#x27;t contribute to the probabilistic model. If I flip a coin, it can&#x27;t come up \"I didn&#x27;t flip the coin\". reply JumpCrisscross 8 hours agorootparentYou&#x27;re right. To expand: don&#x27;t bother is the null. Deciding to cover-up leads to one of two outcomes, the good one (you get away) and the bad (you get boned). You don&#x27;t know which of those outcomes you&#x27;ll get.The percentages the comment you&#x27;re responding to provides aren&#x27;t probabilities, but damage fractions; 50% isn&#x27;t a 50&#x2F;50 likelihood, but 50% damage of the 100% case. reply hndamien 3 hours agorootparentprevTangentially relevant, I have found that when people crash into my parked car, they universally attempt to cover up, and flee the scene. Inevitably they are on camera, and they end up paying for damage. This has happened multiple times. However, there is no extra punishment adminstered for the fleeing and the cover up. So (at least in Australia) you are universally incentivsed to try and coverup a vehicle hit and run, than you are to leave details. Sad. reply Dalewyn 3 hours agorootparentprevThe three outcomes are:* Successful cover up (0% damage).* Failed cover up (100% damage).* Don&#x27;t bother (100% damage).So if doing nothing and failing to cover up lead to the same result, you might as well give a shot at successfully covering up. Whatcha got to lose?It is assumed not bothering is 100% damage because the screw up is apparently bad enough to warrant attempting a cover up. reply blowski 1 hour agorootparentIn the UK it’s a crime to “flee the scene of an accident”, even if that accident was a minor scratch on a stationery vehicle. reply generic92034 1 hour agorootparentIt is the same in many other European countries. But I guess in case of minor scratches those laws belong to the most frequently broken ones... ;) replyselcuka 8 hours agorootparentprev> We know how many cover-ups are successfulDid you mean \"we don&#x27;t know\"? reply vGPU 8 hours agorootparentprevSimple. Look at what was a conspiracy theory in the 80’s and turned into a “yeah we did that, so what” in the 2000’s re: the government?The Dalai Lama literally pulled down a six figure paycheck from the CIA, for example. The government was, is, and will continue to spy on you.The difference is that if something is successfully covered up for 10-20-30 years, by the time the public finds out about it nobody really cares. reply mattmaroon 10 hours agorootparentprevProbably including Watergate which I believe was the inspiration for that quote. The underlying act was probably survivable. The coverup was not. reply jjoonathan 9 hours agorootparentNixon didn&#x27;t know that the evidence tying him to the Chennault Affair was weak. If it was weak, he could play the \"I didn&#x27;t know\" card. If it was strong, he would have had to play the much worse \"It wasn&#x27;t illegal\" card. These are mutually exclusive, so conducting a criminal operation to get a peak at the evidence was a rational gamble. It didn&#x27;t pay off, but no, just chilling was not a good option and no, the underlying act was not the lesser evil. reply Kon-Peki 10 hours agorootparentprevIt’s worth mentioning that the Watergate coverup eventually failed because of a plane crash and the events set in motion due to it.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;United_Air_Lines_Flight_553 reply anatnom 7 hours agorootparentWoodward and Bernstein were already investigating (for many months prior to the crash), and Nixon&#x27;s later coverups (after March 1973) don&#x27;t seem to be connected to the crash in any way.Perhaps if the crash hadn&#x27;t happened, the people&#x2F;money on board could have ensured McCord (and the other plumbers) would have stayed quiet instead of telling Judge Sirica that it was a White House operation. Without some significant evidence of intent for the passengers, though, this is a pretty soft argument. reply ceejayoz 8 hours agorootparentprevYour link says that’s a conspiracy theory? reply JeremyNT 6 hours agorootparentprev> There are numerous counter-examples to this claim. In many cases, it&#x27;s obvious because the cover-up is of a civil infraction.Indeed, people go out of the frying pan and into the fire all the time.I think the kernel of truth in the parent post is that the subjects might genuinely believe that the revelation of the original \"crime\" alone would be impossible to recover from, so they might as well go all in on trying to cover it up.So, the \"marginal cost\" of additional penalties from a failed coverup just doesn&#x27;t seem all that high given the potential upside of a successful coverup. reply fbdab103 5 hours agorootparentI probably watch too much popular media, but I am only thinking of bigger crimes where it seems like the rational choice is to attempt a coverup.Murder? Check. Stealing a Snicker&#x27;s bar? Probably just leave the evidence in place.What is the threshold where you have to make the call? White-collar crimes feel the only place where you could make the argument that further action on the scene is likely to leave behind more evidence. reply zer00eyz 5 hours agorootparent>White-collar crimes feel the only place where you could make the argument that further action on the scene is likely to leave behind more evidence.Nixon tapes, Iran Contra paper shredding, Enron paper shredding (we got Sarbanes Oxley out of that.) There are plenty of places where further action likely prevented far far worse things.I think white collar crime is harder now, as evidenced by recent political scandals (fucking up your secure messaging app, bungling PDF&#x27;s). I dont know of any one who has the technical acumen to fully cover their tracks. reply voisin 9 hours agorootparentprevIsn’t the Martha Stewart insider trading story one of these counter examples? reply andrewinardeer 9 hours agorootparentMartha Stewart was never convicted for insider trading. This is a common mistake people make.She was found guilty of conspiracy to obstruct, of obstruction of an agency proceeding, and of making false statements. reply fbdab103 4 hours agorootparentHad she said she made the trade(s) on the basis of a tip, would that have been the better outcome? Was keeping her mouth shut an option? reply nostromo 3 hours agorootparentprevSurvivorship bias...When the coverup works, we don&#x27;t hear about it. reply mannykannot 5 hours agorootparentprevIn practice, there are examples both for and against the proposition that the cover-up is worse than the crime. Having said that, the argument presented here against the proposition is being justified with a fallacy: numerous cases have shown that cover-ups are attempted even when a full revelation of the underlying crime is survivable (either literally or metaphorically.) In at least some and perhaps many cases, attempting a cover-up may be the statistically-justifiable rational choice even if its failure will bring worse consequences than the infraction being covered up. reply omginternets 10 hours agorootparentprev>To say that there&#x27;s a scandal because the cover-up didn&#x27;t work is no more than a dingbat truismThis nails it quite succinctly, IMO. reply anigbrowl 9 hours agorootparentprevI think you&#x27;re misinterpreting it a bit. Yes, the covered-up thing is usually bad enough that there&#x27;s an incentive to conceal it, but it&#x27;s the efforts at concealment that often end up drawing attention to the perpetrator. Absent those, many crimes would either not be investigated so thoroughly or talked down to less significance with a &#x27;so what&#x27; or &#x27;I didn&#x27;t think it was illegal&#x2F;a big deal&#x27; response (this happens a lot in politics nowadays). Covering up some incriminating action implicitly admits that the action was known to be bad, making it impossible to downplay after discovery. reply dzhiurgis 8 hours agorootparentThe problem with cover ups is that they are creating more data points and evidence to find&#x2F;arrest&#x2F;prosecute you. reply BobaFloutist 6 hours agorootparentThey also demonstrate intent that was potentially unproveable before the attempt to cover up. It&#x27;s pretty hard to say \"oh whoops, was that illegal?\" if you&#x27;ve gone to significant lengths to hide it from law enforcement. reply unyttigfjelltol 10 hours agorootparentprevI don&#x27;t think there&#x27;s cold rational thought that goes into most coverups, it&#x27;s more like ....https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=rN97tqSwI44 reply duskwuff 11 hours agoparentprevNote, however, that this doesn&#x27;t mean that he would have gotten away with it if he&#x27;d cooperated. It means that the federal prosecutor decided that the act of obstruction would be easier to prove, since the intentional nature of those acts is much more self-evident. reply avar 10 hours agorootparent> [...]this doesn&#x27;t mean that he would have gotten away with it if he&#x27;d cooperated[...]If he&#x27;d stuck to the story that he just had an engine mishap would they have been able to prove that it was intentional?They&#x27;d almost certainly have revoked his license to ever fly again, but filming everything you&#x27;re doing isn&#x27;t illegal.Nor is wearing a parachute because you know you&#x27;re a crappy pilot that&#x27;ll bail out at the first sign of trouble. reply ksherlock 9 hours agorootparentGeneral Aviation airplanes require an annual inspection (from an IA A&P mechanic -- that&#x27;s airframe & powerplant with inspection authorization). My understanding is that the plane was out of annual (ie, bought as parts) and he fixed it up enough to fly. There are strict limits on what repairs you can do yourself without involving a licensed A&P mechanic. FAA actually does ramp checks on occasion to verify that your bug smasher has up to date registration and annual inspection. Regardless of how the flight ended, the flight shouldn&#x27;t have happened in the first place and his PPL could be revoked for that alone. reply jacurtis 6 hours agorootparent> There are strict limits on what repairs you can do yourself without involving a licensed A&P mechanic.Sure, you&#x27;re right that this plane was clearly violating a myriad of maintenance violations. But maintenance violations aren&#x27;t going to get you thrown in jail. They might get your license taken away and would definitely yield some fines, but not thrown in jail.I am assuming of course this is on a personal GA plane (like the youtuber was using to fly himself). Skipping maintenance and&#x2F;or doing it himself would have gotten him a few relatively small fines. He probably wouldn&#x27;t have lost his license and certainly wouldn&#x27;t have been thrown in jail for these.Of course the rules would change significantly if this was a charter plane like Part 135, then things are more serious. He would have lost his license then, and maybe gotten some jailtime. Skipping or fraudulent maintenance on a part 121 (scheduled commercial airlines like United or Delta) would certainly yield jailtime. reply lovecg 8 hours agorootparentprevEdit: this is wrong as pointed out below.FAA doesn’t mess around with the maintenance regulations. If I remember correctly the A&P knowledge test requirement was to answer 99% of questions correctly, compared to something like 75% for a PPL (I might be way off but there was a large difference). reply civilitty 8 hours agorootparentYou&#x27;re way off. Comically so. A&P passing grade is more like 70%. It&#x27;s not a comparable figure to PPL ground school. reply lovecg 7 hours agorootparentYou’re right, but I’m wondering where my confusion comes from. I’m absolutely positive something required a much higher %. Maybe a different license or regs changed in the last decade or so? reply ultrarunner 6 hours agorootparentI thought I remembered something like this— maybe it&#x27;s a higher question count or lower time limit for e.g. commercial?The FAA testing matrix seems to suggest all are 70% as of now[0][0] https:&#x2F;&#x2F;www.faa.gov&#x2F;sites&#x2F;faa.gov&#x2F;files&#x2F;2022-09&#x2F;testing_matr... reply lovecg 5 hours agorootparentGetting strong Mandela Effect vibes now… can’t find anything other than 70%, now or a decade ago. But I’m virtually certain I didn’t make something like this up :) replydannyw 8 hours agorootparentprevYes, he’ll certainly face punishment. But I don’t think he’ll go to prison (or perhaps a suspended sentence) if he cooperated. reply throwaway2037 8 hours agorootparentprevNice reply. For other readers, I needed to Google these terms:IA: Inspection AuthorizedA&P: Airframe & Powerplant reply JumpCrisscross 10 hours agorootparentprev> If he&#x27;d stuck to the story that he just had an engine mishap would they have been able to prove that it was intentional?In a normal setting, probably not. General-aviation aircraft don&#x27;t have flight recorders. Helpfully for the investigators, however, this numpty decked his plane out in cameras. And then posted the video online. After he&#x27;d executed the cover-up. reply phire 9 hours agorootparentprevIt was pretty blatantly obvious from just the video.The engine didn&#x27;t just stop producing power, that would leave typically the propeller spinning, windmilling in the air. (unless the engine seized, but he was faking fuel starvation)He put a bunch of effort into making sure the propeller actually stopped spinning, I think he had to actually reduce speed; Just so that your average YouTube viewer could clearly see the engine had stopped. reply tass 5 hours agorootparentprevProbably, because he was stupid enough to record a video with cameras in the plane. But there’s plenty of ways to achieve it which could pass as accidental:Accidentally lean mixture (e.g., grab the wrong control). Set to use an empty fuel tank. Set the fuel valve to off or in between settings. With some preparation, destroy a spark plug or two, only enable those spark plugs in the air - extreme misfires will be obvious on video.There are plenty of pilots who wear chutes (and there are special chutes which basically replace your seat) but he also had a fire extinguisher strapped to his leg which is not a normal occurrence. reply omginternets 10 hours agorootparentprevApplying a bit of abduction, I see two narratives that track:1. Some other illicit activity was going on in or around that plane.2. The pilot thought he could make the whole mess go away by erasing physical evidence of the crash; his reasoning might be along the lines of \"no evidence, no feds\".I find both equally credible. I&#x27;m stumped. reply jxf 10 hours agorootparentNever overestimate the intelligence of someone willing to jump out of a moving plane for clicks and views. reply omginternets 8 hours agorootparentNever underestimate the propensity of a criminal to engage in multiple crimes.I maintain it could go either way. reply constantly 10 hours agorootparentprevMy understanding reading the original incident report, to my recollection, was that there was enough there that random grossly negligent youtuber trying to get clicks for an ad + a dozen cameras + parachute + not following safety protocol + not giving enough time of trying to restart before immediately bailing meant the beyond reasonable doubt conclusion would almost certainly be that this was premeditated. reply calamari4065 10 hours agorootparentprev>If he&#x27;d stuck to the story that he just had an engine mishap would they have been able to prove that it was intentional?Isn&#x27;t that what the black box is for? reply sokoloff 9 hours agorootparentThe tech in that airplane is much closer to a 1935 tractor than it is to even a 1985 passenger car (which also didn’t have anything like a black box). reply seabass-labrax 10 hours agorootparentprevIt&#x27;s very unlikely that a private aircraft this small would have a &#x27;black box&#x27; (either of the cockpit voice recorder or flight data recorder variety). That said, the pilot in this case had incriminating evidence on board due to his own recording devices. reply mplewis 10 hours agorootparentprevYes, because nothing in the plane caused a loss of power. reply vkou 8 hours agorootparentAnd even if it did, he made no effort to resolve the issue. reply bhhaskin 11 hours agorootparentprevIs there a law that says you can&#x27;t intentionally crash a plane? Honest question. There isn&#x27;t a law that prevents you from intentionally crashing other vehicles. Just around property damage and endangering other people. reply throw0101b 10 hours agorootparent> There isn&#x27;t a law that prevents you from intentionally crashing other vehicles. Just around property damage and endangering other people.You can probably do whatever you want with your private vehicle on your private land. But on public roads you need a license to operate, and you must operate the vehicle in certain prescribed ways.Similarly you can probably do whatever you want with your private air vehicle while it sits on your private land, but when you are operating in public air space then you must operate in the ways prescribed by your pilot license. reply JumpCrisscross 10 hours agorootparent> can probably do whatever you want with your private vehicle on your private landSort of.Own plane, own land and a filed flight path should satisfy the FAA&#x27;s requirements, though you may also need to take active measures to ensure your private land is clear of things that could be harmed. After that, there is the environmental component. Our influencer here not only inundated the crash site with leaded avgas, but likely also sprinkled it all the way to the hangar. Given the track record of decision making, I have no hope he disposed of the parts properly, either. reply throw0101b 6 hours agorootparent> Own plane, own land and a filed flight path should satisfy the FAA&#x27;s requirements, though you may also need to take active measures to ensure your private land is clear of things that could be harmed.If he had a private air field&#x2F;airport and \"landed\" (crashed) the plane on his air field, then that could be argued, but there&#x27;s still the fact that he bailed out of the airplane and left it in an uncontrolled state, in which case there&#x27;s probably some kind of &#x27;reckless&#x27; charge that could be thrown at him. reply masklinn 3 hours agorootparentOtoh people crash stuff on the reg (crash tests, stunts, …) and an unoccupied plane should be quite predictable. If you can demonstrate that you secured the area and it is large enough there is low-to-no chances of the plane getting out from bailout conditions everyone woukd likely be satisfied. reply krisoft 18 minutes agorootparent> you can demonstrate that you secured the area and it is large enough there is low-to-no chances of the plane getting out from bailout conditionsYou are probably underestimating how wast that area must be to do that. reply pavel_lishin 10 hours agorootparentprev> Given the track record of decision making, I have no hope he disposed of the parts properly, either.Your instincts are correct:> Jacob drove the wreckage to Lompoc City Airport and unloaded it in a hangar. He then cut up and destroyed the airplane wreckage and, over the course of a few days, deposited the detached parts of the wrecked airplane into trash bins at the airport and elsewhere reply JumpCrisscross 10 hours agorootparentprev> law that says you can&#x27;t intentionally crash a plane?No. We do crash tests from time to time [1]. But at a minimum, you must control--not even just own--the terrain you&#x27;re crashing into. (It&#x27;s also not solely a Part 91&#x2F;FAA matter. The EPA, for example, would also want to have a say.)[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2012_Boeing_727_crash_experime... reply throwaway2037 8 hours agorootparentThe Wiki page says: The site in Mexico was chosen because authorities in the United States would not allow the test to take place.When you wrote \"we\", did you mean the United States? reply omginternets 10 hours agorootparentprevWhat does \"control\" mean, technically?I have an intuitive sense of what you&#x27;re pointing at with the Boeing 727 crash experiment, but how does the law phrase it? reply JumpCrisscross 10 hours agorootparent> What does \"control\" mean, technically?\"The power to govern, manage, direct, or oversee something\" [1]. So if I own&#x2F;possess acres of unfenced grasslands, I&#x27;d need to put up fences or people to monitor the property or at the very least crash site&#x27;s borders.[1] https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;wex&#x2F;control reply mikeyouse 9 hours agorootparentIt&#x27;s a more specific definition in aviation -- think air traffic control. You need to actively make sure that there won&#x27;t be any other flights near where you&#x27;re intending to crash your plane which is tricky if you just bail at altitude and let it sail into terrain for YouTube.If you want to crash a plane, you&#x27;d likely have to apply for&#x2F;receive temporary flight restrictions over the area where you want to crash it so that ATC can ensure everyone else stays clear.https:&#x2F;&#x2F;www.faa.gov&#x2F;air_traffic&#x2F;publications&#x2F;atpubs&#x2F;foa_html... reply JumpCrisscross 9 hours agorootparent> you&#x27;d likely have to apply for&#x2F;receive temporary flight restrictions over the area where you want to crash it so that ATC can ensure everyone else stays clearCorrect. I was simply talking about control of the land underneath. Owning and controlling the land doesn&#x27;t mean you have any rights to its airspace. replyCOGlory 10 hours agorootparentprevIs there a scenario where intentionally crashing a vehicle on property that you do not have permission to crash a vehicle on isn&#x27;t reckless endangerment&#x2F;reckless driving? Except maybe steering away from the oncoming bus into the jersey barrier or something? reply Sebb767 7 hours agorootparent> Is there a scenario where intentionally crashing a vehicle on property that you do not have permission to crash a vehicle on isn&#x27;t reckless endangerment&#x2F;reckless driving?Arguably whenever you could expect that not crashing the vehicle would lead to a worse outcome. In the plane example, this might be true if you expect to loose control of the plane at some point (due to mechanical failure or force) and a controlled crash is the best option to avoid (possibly) impacting a more populated area. But I agree that this is a rare scenario. reply tomatotomato37 10 hours agorootparentprevI know there was at least one remote-controlled airliner intentionally crashed in the desert filled with crash dummies and stuff, though that was in an active partnership with the FAA reply ryandrake 10 hours agorootparentprevIt probably falls under Careless or reckless[1] at the very least 14 CFR 91.13.EDIT: Looks like user JumpCrisscross beat me to it.1: https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-14&#x2F;chapter-I&#x2F;subchapter-F... reply bmitc 9 hours agorootparentprev> There isn&#x27;t a law that prevents you from intentionally crashing other vehicles. Just around property damage and endangering other people.Those two sentences don&#x27;t make any sense next to each other. There&#x27;s no way to intentionally crash your vehicle that doesn&#x27;t include several other things for which their are specific laws for. One can&#x27;t intentionally crash a car in the same way that you can intentionally swing a bat in your backyard without hitting anything.Edit: Also, for what it&#x27;s worth, it wasn&#x27;t even his plane. reply ImPostingOnHN 4 hours agorootparent> One can&#x27;t intentionally crash a car in the same way that you can intentionally swing a bat in your backyard without hitting anythingWhat exactly do you mean here? I&#x27;ve witnessed plenty of vehicle damage done on private ranchland from various obstacles, and in some cases, other family&#x2F;friends&#x27; vehicles. If you wanted to drive your vehicle into a big rock on your own land, what exactly stops you? reply gosub100 7 hours agorootparentprevSo far, all of us are just guessing, so here&#x27;s my guess:What Trevor did would be considered an \"aerobatic flight\" [1]\"aerobatic flight means an intentional maneuver involving an abrupt change in an aircraft&#x27;s attitude, an abnormal attitude, or abnormal acceleration, not necessary for normal flight.\"He may have been technically legal on the FAA side, but reckless dumping of hazardous materials in the desert is probably an actual charge they could have nailed him on. Perhaps \"operating a vehicle off an approved trail\" type of charge, or some kind of wildlife violation &#x2F; fire hazard are also what I would guess. Perhaps running afoul of some kind of parachuting laws as well, maybe having to file for that so other aviators know about it.Someone below mentioned filing a flight plan, which has nothing to do with anything. Flight plans are to aid in search-and-rescue if you dont show up.[1] https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-14&#x2F;chapter-I&#x2F;subchapter-F... reply zlg_codes 5 hours agoparentprevWhat prior evidence do we have of government honoring such \"if you were honest we&#x27;d be easier on you\" crap?Zero incentive to trust such a statement. It&#x27;s backed by nothing. reply MBCook 5 hours agorootparentI’m not sure it’s that they’d go easy on you, I think it’s more that they would go extra hard as a deterrent when they catch you trying to cover things up. reply keepamovin 1 hour agoparentprevWhat a weirdo psycho, omg, it&#x27;s like he&#x27;s chopping up a body. Why didn&#x27;t he just leave the wreckage there? Surely everything would have been far better if he had done that. Guilt and fear makes people do insane things, this is today&#x27;s reminder. reply dmix 9 hours agoparentprevWas the federal investigation already underway before he enacted his plan to cover it up? Or does it not matter. When does an investigation formally start? When they heard about the fake crash like everyone else did when it went viral on youtube? reply NegativeK 8 hours agorootparentAircraft crashes may operate under different rules? reply foobarian 11 hours agoparentprevWow, that&#x27;s a lot of expensive trouble to go through to cover up. I wonder what the penalties would be otherwise - I&#x27;m sure there is some kind of code it broke but it&#x27;s not obviously illegal. It&#x27;s like me crashing my car on purpose. reply JumpCrisscross 10 hours agorootparent> sure there is some kind of code it broke but it&#x27;s not obviously illegalIt&#x27;s very illegal. Part 91 § 91.13 careless or reckless operation [1] and § 91.15 dropping objects [2]. (I&#x27;m studying for my pilot&#x27;s license.)Also, until SCOTUS rules otherwise, agency rules carry the strength of statute.[1] https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-14&#x2F;section-91.13[2] https:&#x2F;&#x2F;www.ecfr.gov&#x2F;current&#x2F;title-14&#x2F;section-91.15 reply foobarian 10 hours agorootparentSure, but is it a felony-20-years-in-a-FPITA-prison illegal, or a giant-fine-and-revocation-of-pilot-license illegal? :-) reply JumpCrisscross 10 hours agorootparent> is it a felony-20-years-in-a-FPITA-prison illegal, or a giant-fine-and-revocation-of-pilot-license illegalProbably the latter unless someone gets hurt. (Agree with you that this was a dumb cover-up. Particularly when he seems to have done the cover up before posting the video?) reply fbdab103 5 hours agorootparentWhen does it become a cover-up vs \"oopsie, didn&#x27;t know\"?If he had dismantled the plane before the FAA knew about the crash, would that still qualify as destroying evidence? reply ImPostingOnHN 4 hours agorootparentChopping up the plane and distributing the pieces in assorted different regular trash bins over time sounds like mens rea to me reply heyoni 10 hours agorootparentprevSome forms of reckless driving are considered felonies and can land you in prison, I feel like it would or should be worse with an airplane. reply throwaway2037 8 hours agorootparentprevI&#x27;m pretty sure it is legal in the United States to buy a car and drive it uninsured on your own private property... and drive it into a brick wall at high speed. There is a YouTuber who is basically doing this now: Buying expensive cars and wrecking them on his private land. (I forget his name, but US-based guy. One video was him wrecking a highly customized Mercedes G Wagon.) reply singleshot_ 8 hours agorootparentIf you google the search terms \"talladega big one\" you will see a great variety of uninsured, expensive cars being driven on private property and aggressively junked ten or twenty at a time. This is most certainly not illegal without additional bad conduct. reply rcpt 7 hours agorootparentprevOkay but in the US cars are generally above the law in many ways reply bradfox2 6 hours agorootparentprevWhistlindiesel reply bomewish 3 hours agoparentprevSuper curious how they even found out. Did he confess? Anyone got the info? reply krisoft 4 minutes agorootparent> Super curious how they even found out.Found out what exactly?> Did he confess?He posted a video on youtube, the rest of it is just standard investigation. reply MBCook 5 hours agoparentprevIs there any reason to believe that there will be a future trial in which he gets in trouble for purposefully crashing the plane as well? reply berniedurfee 6 hours agoparentprevThat takes a lot of cash and a lot of stupid. reply fxtentacle 11 hours agoprevFor me, the really interesting question is not if he&#x27;s guilty - I had assumed as much - but if he will come out financially successful. That video had millions of views and a sponsorship deal. Call me a cynic, but it seems that some companies will deliberately break the law and pay the price if it&#x27;s worth it, so why not independent hustlers. reply WillPostForFood 11 hours agoparentLegal fees alone are going to be many times YouTube revenue. Add lost wages for a half year in prison. Add future lost revenue from sponsors who don&#x27;t want to be associated with this, and it has to be a huge financial disaster. reply ryandrake 10 hours agorootparentEven if the legal fees weren&#x27;t many times the revenue, I never understood why couldn&#x27;t the justice system default to fines like \"All income arising out of crime + $XYZ\" for all crimes, so that the fine is never a cost of doing business? reply bdonlan 5 hours agorootparentThis is called disgorgement and is indeed frequently used for certain types of crimes (particularly financial crimes). reply mcmoor 8 hours agorootparentprevI&#x27;d argue that it&#x27;s shouldn&#x27;t even be only income + $xyz, it&#x27;s income * (1 &#x2F; chance of succesful enforcement) to reduce companies that thought that as long as it&#x27;s hidden enough you&#x27;ll be safe. It&#x27;ll be a lot more arbitrary though. reply paulryanrogers 10 hours agorootparentprevPerhaps laziness? Determining which profits are due to a crime could be difficult to separate from legitimate activity. That said, they could write the law to claw back anything that&#x27;s easily accounted for, and just use some approximations when that&#x27;s impractical. reply autoexec 9 hours agorootparentIt doesn&#x27;t even need to be an exact or accurate accounting of money made due to crime. The legal system could impose fines high enough to hurt regardless of where the money came from, and pretty much everyone agrees that they should because otherwise fines are just a cost of doing business. The fact that the legal system refuses to do that when it&#x27;s so obvious that not doing it is harmful to everyone except criminal corporations is troubling. reply Deprecate9151 9 hours agorootparentThe technical term for it is \"disgorgement\" and it does exist in some contexts. I agree it is shockingly absent in far too many. reply TeMPOraL 10 hours agorootparentprevMy guess: it&#x27;s too expensive to keep track of what constitutes \"income arising out of crime\" for the statutory period &#x2F; lifetime of the perpetrator, especially if it could spawn an endless stream of minor cases for whether any specific income is truly \"arising out of crime\". reply glasshug 8 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Son_of_Sam_law reply altairprime 10 hours agorootparentprevWhat percentage of viewer income was due to the crime? reply constantly 8 hours agorootparentI presume this is hypothetical. A reasonable start would be to see the difference average views on a video and views on this particular video times as revenue per view.Admittedly I’ve never heard of this guy and avoid most YouTube “creators” and it got a view out of me out of morbid curiosity and so I could speculate on whether it was pre planned. reply altairprime 7 hours agorootparentThat question, as posed, represents why this isn’t often done. It’s very difficult to determine the contributing revenue fraction when one illegal action is laundered among many. Seizure tends to be all or nothing as a result. reply rtpg 8 hours agorootparentprevThis is a thing (this is the whole thing about treble damages). Despite what people say on HN, \"Fines are a cost of doing business\" is more a statement of fact (running a business, you sometimes fuck up and pay for it), rather than a statement of intent (do things that get fined but make money off of it). For most people anyways.If you run scam X and earn Y from that scam, then get caught doing X, it is extremely unlikely that you are walking away with a fine less than Y. The problem is of course maybe the feds only notice Y&#x2F;2 or Y&#x2F;10. There&#x27;s some hand wringing about scam X earning you Y directly but helping to support scam Z in the future that you will do better (or legitimate businesses A,B,C that earn you Y * 1000). But there&#x27;s a base principle, and \"let&#x27;s just fine off of overall revenue\" things leading to \"some case officer in Omaha lied on forms, so we will fine this bank $2 billion\" is kinda silly[0].But generally speaking illegal activity where you get caught is going to end badly for you. And illegal activity you get away with will end better for you, but that&#x27;s true independent of the fee structure.[0] the case officer might be part of a larger pattern. This is what discovery and investigations are for! Do enough work and you can prove that the earnings from the illegal activity is higher! reply pavon 9 hours agorootparentprevI thought that was what criminal forfeiture laws were supposed to be about. Is there are reason why they aren&#x27;t routinely applied in cases like this? Seems to be a much more productive use than typical civil forfeiture. reply dataflow 8 hours agorootparentprevProbably because it&#x27;s not necessarily always a proportional punishment?Like if you drive somewhere with a suspended license somewhere and make a million dollars as a result, should all that money be subject to seizure? reply dzolob 9 hours agorootparentprevPlus, and I’m speculating here, there might be a breach of contract or tos here and there due to illegal activities, so he might even have to return some or all revenues. reply pengaru 8 hours agorootparentprevNo chance for future lucrative film and book deals?If this kind of thing becomes increasingly common in the \"influencer\" economy, this instance could be seen as Ground Zero making him an OG pioneer of sorts. That has to be worth something, for better or worse.Six months prison time isn&#x27;t very long after all, six months of average salary doesn&#x27;t buy you anywhere near this level of fame. reply hackerlight 8 hours agorootparentprevWe have the benefit of hindsight. If he thought there was a 20% chance of being caught, then maybe 0.2*(legal fees + other consequences)Jean Valjean (self-evident)Jean Valjean is a character in a novel, not a real person, and is about as relevant to this discussion as a Wookiee from the planet Kashyyyk. reply financltravsty 7 hours agorootparentApparently not self-evident!A.k.a Eugène Vidocq reply mkl 2 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eug%C3%A8ne_Fran%C3%A7ois_Vido... says he stole a lot of money from his parents&#x27; bakery, but wasn&#x27;t imprisoned for that (though was for plenty of other crimes). replyfinancltravsty 10 hours agorootparentprevFraud, conspiracy, and wage theft are the common ones that companies commit every day.How many times have people been fraudulently misled about the scope and responsibilities of their roles? How many times have companies misclassified workers or denied overtime pay? How many times have companies lied about their products and services? How many times have big tech companies conspired to keep wages down? How many private equity and pharmaceutical companies have engaged in profiteering?They regularly commit crimes. Though the definition of crime is constantly being patched with loopholes by lobbyists and other well-connected jackals. The Overton window keeps on shifting. It&#x27;s just a power battle between people more powerful than you. reply gorgoiler 6 hours agorootparentprevI agree with you of course but I wonder how wise it is for governments to follow the strategy of felonies being irrevocable black marks?That is to say if we rely on the permanent reputation taint as a deterrent then once you’ve been tainted are you not now much more likely to go do more harmful, felonious things?I don’t know much about felonies though — perhaps they can be expunged after X years of good behaviour? reply zlg_codes 5 hours agorootparentprevTell me what 6 months in a cage and financial ruin will do to teach someone about a victimless crime.Justice is not in play here. The punishment should match the crime. reply blackoil 3 hours agorootparent> Tell me what 6 months in a cage and financial ruin will do to teach someone about a victimless crime.Don&#x27;t do victimless crimes. If you have already done it, don&#x27;t cover it up. And if you have to do it all, don&#x27;t do it stupid. reply zlg_codes 3 hours agorootparentYeah that&#x27;s complete BS. They don&#x27;t own us, nor are they entitled to any particular respect or behavior.Their rule is firm as long as people allow themselves to be ruled. reply paulpauper 10 hours agorootparentprevIt’s a big black mark on your reputation, it’s rarely worth it.Maybe if he was applying for a job at the FAA, as a pilot, or as a school teacher. but for a professional youtuber, not so much. reply TerrifiedMouse 9 hours agorootparentIt does close those doors though. reply dzhiurgis 8 hours agorootparentprev> He could have injured or killed someone for a video.I&#x27;m pretty sure you are more likely to kill someone driving to work today than crashing a plane in some random as forest. reply goles 6 hours agorootparentKilling someone driving to work so you can pay for rent&#x2F;mortgage&#x2F;groceries is somewhat different than putting Go Pros on your car and deliberately crashing into someone so you can pay for rent&#x2F;mortgage&#x2F;groceries. reply constantly 8 hours agorootparentprevBut you’re more likely to kill someone when the remote forest fire you sparked by intentionally crashing your plane grew and took out a bunch of firefighters and a village than you are to kill someone driving to work. reply JoeAltmaier 47 minutes agorootparentprevBeing an entitled dickhead, endangering the public and flaunting basic rules of decent society - pretty much in the &#x27;don&#x27;t do it&#x27; column. Worth it? If your ethics are worthless an argument could be made. But there&#x27;s no conversion between character and cash; it&#x27;s a null set. reply smcin 8 hours agoparentprevA more hip headline would be \"Feds hand YouTuber the ultimate demonetization for plane crash vid\" reply tokai 10 hours agoparentprevThats assuming that yt pays out and his sponsors doesn&#x27;t sue him. reply laborcontract 8 hours agoparentprevWe&#x27;re living in the age of advertisers hyperfixated on brand safety. I can&#x27;t see any brand thinking it&#x27;s a good idea to throw money at this guy. More attention is a good thing until you&#x27;re OJ Simpson. reply jahsome 7 hours agorootparentWill ridge wallet come crawling back? Heck no.But in the world of influencers one of the primary currenciez is notariety, some cess pool like kick or rumble would gladly take the publicity, good or \"bad.\" reply ugh123 10 hours agoparentprevI doubt its anything that can beat 6 months in jail reply tw04 6 hours agoparentprevIs YouTube actually letting him monetize it? I didn’t think you could make money off a video of yourself committing a crime? reply dvngnt_ 5 hours agorootparentthe crime was the cover-up tho reply madeofpalk 8 hours agoparentprevHow much money would you take to spend 6 months in jail? reply wruza 2 hours agorootparentDepends on a jail. Some are more like resorts&#x2F;rehabs compared to others. US jails for 6-month crimes aren’t particularly bad, afaiu. Personally I’d take around $200k too for a US jail, assuming I have nothing to do for half a year and there will be no social&#x2F;legal consequences that matter.Disclaimer: I wouldn’t commit a crime to make money&#x2F;time tradeoff, only a hypothetical experimental exchange with no real danger to anyone. reply blackoil 3 hours agorootparentprevIf I can choose it to be a Norwegian prison, may be 100-200k USD. I always wanted to take a self-discovery retreat but can&#x27;t commit to it. reply jahewson 5 hours agoparentprevDemonetized. reply paulpauper 10 hours agoparentprevFor me, the really interesting question is not if he&#x27;s guilty - I had assumed as much - but if he will come out financially successful. That video had millions of views and a sponsorship deal. Call me a cynic, but it seems that some companies will deliberately break the law and pay the price if it&#x27;s worth it, so why not independent hustlers.given all the media attention and the general frivolity of the matter, that answers it. A tiny sentence at prison camp for a few months makes it worth it for a career of earnings and buzz. reply58 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "YouTuber pilot Trevor Daniel Jacob has been sentenced to six months in federal prison for obstructing a federal investigation into a plane crash that he deliberately caused for online views.",
      "Jacob destroyed the wreckage of the airplane and lied to investigators about its location, while also monetizing the crash through a YouTube video promoting a wallet.",
      "The investigation was conducted by the United States Department of Transportation – Office of Inspector General, with assistance from the National Transportation Safety Board (NTSB) and Federal Aviation Administration (FAA)."
    ],
    "commentSummary": [
      "A YouTuber has been sentenced to six months in prison for hindering a federal investigation into a plane crash, shedding light on the repercussions of cover-ups.",
      "Failed cover-ups can garner attention and provide more evidence for prosecution, emphasizing the potential risks involved.",
      "The conversation delves into violations of aviation maintenance regulations, intentional acts causing plane crashes, legal ramifications, potential penalties, control in aviation, and the limited implementation of \"disgorgement.\""
    ],
    "points": 388,
    "commentCount": 216,
    "retryCount": 0,
    "time": 1701726975
  },
  {
    "id": 38518994,
    "title": "Switch off settings that ruin your TV experience",
    "originLink": "https://practicalbetterments.com/switch-off-bad-tv-settings/",
    "originBody": "index technology Switch off bad TV settings Smart TVs have an abundance of weird settings designed to make Seinfeld look like it was directed by James Cameron. At first this seems great. Why shouldn't 90s sitcoms seem like they were filmed in 4k at 60 frames per second? Then you start noticing things… Was Kramer's hair always surrounded by rectangles? Were George's frenetic movements always trailed by a cartoonish blur? Wouldn't I have remembered Elaine being a 9ft tall blue humanoid alien with a tail? Settings like motion interpolation, noise reduction, and dynamic contrast undo the work of the film makers, introduce unwanted artefacts to the image, and make new movies look like soap operas.1 Watch movies as the makers intended, and save a small amount of electricity,2 by switching off weird smart tv settings. How to switch off weird smart tv settings The names of these settings differ between manufacturers, and so it's difficult to give a comprehensive guide — so below is an explanation of each feature with it's equivalent name for different brands. You'll need to navigate to your TVs settings and switch them off. If you're lucky, your TV has filmmaker mode, a setting which will adjust your tv to align with the intentions of the filmmakers without you having to learn any terminology — brought to you by Tom Cruise complaining.3 I won't list every setting for every TV here — there are too many — but most new smart TVs have these three settings, which you should switch off: Motion interpolation Motion interpolation4 or motion smoothing increases the frames per second from 24fps to 60fps by creating and inserting new frames not present in the original film. Motion interpolation is also known as motion smoothing, TruMotion, Motionflow,MotionSmoother, Clear Action, Intelligent Frame Creation, Action Smoothing, Auto Motion Plus and variations on a theme. Dynamic contrast and brightness There are lots of settings that dynamically adjust the contrast and brightness of scenes. Dynamic contrast5 is designed to increase the contrast of dark scenes — present darker blacks. It can inadvertently cause overexposure in dark scenes with bright spots or show you more detail than the filmmakers intended. Some TVs also dynamically dim the backlight in different areas of the screen. These settings have an even wider variety of names including Dynamic Contrast, Dynamic Range Remaster, Local Dimming, Local Dimming, Brightness Optimisation, Adaptive Backlight. Noise reduction Noise reduction is supposed to reduce noise from terrestrial television, pixelation, and compression. It can inadvertently remove textures and result in a blurry picture — sometimes it's called Smooth Gradation Learn more I'm not an expert on picture quality. I did a cram session on it before writing this article. If you require further convincing that these changes will improve your quality of life watch How your TV settings ruin movies from Vox. For more detailed changes you can make to your specific model of TV take a look at How to get the best TV picture from which.co.uk. Footnotes 1 Wikipedia – motion interpolation – the soap opera effect 2 I think it's a fair assumption that switching off computationally intensive features of a smart TV will save energy — I will put this to the test at somepoint. I promise. 3 Tom Cruise talking about \"video interpolation\" 4 Wikipedia – motion interpolation 5 Wikipedia – dynamic contrast Tags entertainment saving energy Published 4 Dec 2023 Updated 4 Dec 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38518994",
    "commentBody": "Switch off bad TV settingsHacker NewspastloginSwitch off bad TV settings (practicalbetterments.com) 360 points by DitheringIdiot 17 hours ago| hidepastfavorite427 comments jeffmcmahan 5 hours agoAs a former high end audio&#x2F;video salesperson, I just want to state for accuracy that local dimming, as a feature, is not dynamic contrast. Dynamic contrast is terrible. By having an LED backlight array dim spots that are darker in the source material, the display achieves better absolute contrast. It is not adjusting the exposure to fake it. It is instead getting closer to the contrast given by the source material. It created some halo issues, but it was a step in the right direction.This is not new tech at all - I was selling Samsung LED TVs with this feature in 2007 or so. Samsung, Sharp, and Sony has little choice but to improve contrast, because their LED sets were right next to Pioneer KURO plasmas that were just absolutely amazing - OLEDs are only catching up their PQ now, 15 years later. First on the scene was the Samsung LN-T5781 - https:&#x2F;&#x2F;www.cnet.com&#x2F;reviews&#x2F;samsung-ln-t5781f-review&#x2F; reply jonny_eh 4 hours agoparentI came here to warn people that they should not disable local dimming on their TVS. It&#x27;ll make dark scenes look overly bright and washed out. reply grishka 1 hour agoprevI don&#x27;t know if it carried over into 4K TVs, but I&#x27;m surprised that the dreaded HDMI overscan isn&#x27;t mentioned anywhere. I&#x27;ll never understand WHY and HOW someone thought that implementing this at all, let alone making it the default, is a good idea. You had one job, accept a 1080p signal and output it pixel-perfectly to the 1080p display panel. Yet somehow, someone thought that it would be a great idea to cut off the edges of the image and interpolate it so everything looks atrocious. And then every single TV manufacturer agreed and implemented it. Whenever I see this kind of cropped image on a TV, I grab the remote and set it to the only mode that should exist on digital displays, direct pixel-to-pixel mapping. Just blows my mind I have to do that. reply fideloper 11 hours agoprevOne thing I seemingly can’t disable is how my samsung tv gets louder when ambient noise is high.I absolutely do not want my TV to get louder when one of my kids is shrieking. Just adds stress on top of stress reply squeaky-clean 10 hours agoparentDoes this help? It&#x27;s related to the \"Sound Sensor\" but the menu setting is not called sound sensor. There&#x27;s also apparently a physical switch you can turn off? I can&#x27;t check that though.https:&#x2F;&#x2F;www.samsung.com&#x2F;latin_en&#x2F;support&#x2F;tv-audio-video&#x2F;how-... reply fideloper 9 hours agorootparentI’ll give it a shot, thanks!! reply idontwantthis 2 hours agoparentprevIt makes me anxious just knowing that TVs exist that do this. reply j45 11 hours agoparentprevI believe there is a setting for that.Using an external receiver can help too. reply jjoonathan 11 hours agorootparentExternal bluetooth transmitters&#x2F;receivers are also the cure for shitty PC bluetooth stacks.They don&#x27;t switch to garbage quality mode every time an app, website, or game queries the microphone. They don&#x27;t re-enable shitty defaults every software update. They don&#x27;t require text config files in linux and the critical settings in those files don&#x27;t get ignored due to open source politics. They don&#x27;t mess up pairing every time you reboot into a different OS. They just work. $50 will banish all your bluetooth troubles to the deepest pits of the underworld, where they belong. reply j45 11 hours agorootparentI should have been more clear. An audio&#x2F;video receiver.Beyond Bluetooth optical audio is quietly pretty decent. reply jjoonathan 11 hours agorootparentYes, TOSLINK is a godsend. It&#x27;s immune to ground loops and motherboard manufacturers that don&#x27;t give a shit, which is all of them, even ones that brand around having decent audio (ProArt I&#x27;m looking at you). reply jrockway 6 hours agorootparentI have a different Asus motherboard and the audio hardware is on an apparently flaky USB bus (the motherboard has several, as they do). Even with an optical connection, the audio drops out sometimes. It was maddening to me when I first got the computer, because things like this are usually \"not all the CPU pins connected to the motherboard\" or \"you know that RAM you bought on Amazon? yeah, it doesn&#x27;t remember what you store in it! savings!\". But... not this time. (I can pretty much kill USB on this machine by plugging in a bunch of unused USB cables; plugged into the computer, but nothing on the other end.)I use an external DAC and I&#x27;ve learned which buses break USB when looked at the wrong way. But ... of course the on-board audio is just a USB device. Can&#x27;t waste a PCIe lane on that! reply cf100clunk 11 hours agorootparentprev> an external receiverYes, passthrough digital audio to an AVR if at all possible. reply Daneel_ 11 hours agorootparentprevOpen TV. Find microphone. Apply tape. reply autoexec 10 hours agorootparentscrew tape, cut it out. Any samsung TV with a microphone and an internet connection is probably sending everything it picks up to data brokers. reply OJFord 9 hours agorootparentprevTape? My television does not need a microphone, if I identify one and open it up, there is no reason to leave it there. reply AlecSchueler 11 hours agorootparentprevJust gotta find a proprietary Samsung screwdriver first. reply justinclift 6 hours agorootparentThis should be what you&#x27;re looking for: :)https:&#x2F;&#x2F;www.milwaukeetool.com&#x2F;Products&#x2F;Hand-Tools&#x2F;Hammers&#x2F;48... reply I_Am_Nous 11 hours agorootparentprevApply dollop of superglue, THEN tape for maximum quiet reply fideloper 9 hours agorootparentprevI don’t hate this solution one bit reply omnicognate 2 hours agoprevA modern panel is a complex, powerful device with a wide range of capabilities. Human beings are diverse and even an individual&#x27;s preferences can change over time. It&#x27;s right that there are settings for this stuff.What isn&#x27;t right is that instead of using standard terms common across manufacturers and clearly related to what the settings actually do, manufacturers expect anyone who wants to change them to reverse engineer what Dynamic TruScungle means, how it interacts with Active ProHorngus and whether 100 means the ProHorngus is turgid or flaccid. reply TheGRS 1 hour agoparentThis article is timely because we just setup our new cyber Monday Samsung TV. The screen was on for about 2 seconds before I recognized the frame interpolation. We spent a good 15 minutes going through the settings to find what we thought was doing it and seeing how it looked. Hate that they turn this shit on by default.Even worse is I’m always the one who notices it when no one else does. It’s immediately obvious to me and everyone else is going “I don’t see what you’re talking about”, drives me bonkers. And then trying to find the setting to make me happy takes too long. reply matt89 1 hour agorootparentI feel you, I have the exact same experience. I always see this and I&#x27;m bothered by it, yet most of the time nobody else sees it and it&#x27;s hard to really convey to other people what you mean. reply izzydata 12 hours agoprevFrame interpolation is so incredibly awful looking in my opinion. Especially when it comes to animation. I can not comprehend all of the people on Youtube that take a beautiful drawn animation that is intentionally 24 frames per second and increase it to 60 thus ruining the hand crafted perfection of the drawn key frames. reply Doxin 2 hours agoparentA lot of good animators will also vary how many frames they animate per second. Trying to smear all of it into 60fps doesn&#x27;t improve anything.A good example is FUNKe[0], He&#x27;s got a style with very pronounced changes in framerate. One movement will be 3fps and the next 30, never mind that the lipsync tends to be at a high framerate no matter what the rest of the animation is doing. Imagine trying to convert that to 60fps and still have it look good.[0] e.g. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=maqIaT_ZUxs reply tuna74 12 hours agoparentprevVery little hand drawn animation is done a 24 fps. Which make interpolating the actual movements even crappier. reply extraduder_ire 4 hours agorootparentI think the phrase they use is \"drawing on 2s\" for every second frame (12 fps) being drawn and \"drawing on 3s\" and so on depending on how many native frames there are between drawn ones. Usually, different things onscreen will be animated differently for effect&#x2F;budget. reply karmakaze 14 hours agoprevI&#x27;m surprised it doesn&#x27;t mention \"sharpness\". It&#x27;s tricky find the zero point: e.g. &#x27;0&#x27;, &#x27;50&#x27;, or &#x27;100&#x27; depending on whether it means &#x27;add sharpening&#x27;, &#x27;smooth&#x2F;sharp&#x27;, or &#x27;remove smoothing&#x27;. reply layer8 10 hours agoparentYeah, that’s often inconvenient. There are test images like http:&#x2F;&#x2F;www.lagom.nl&#x2F;lcd-test&#x2F;sharpness.php one can use for testing this. A USB stick with some test images can be useful. reply jwells89 12 hours agoparentprevThis is a frustration shared with some monitors, too. Either the zero-point should be obvious or there should be a toggle that disables the setting altogether. reply smusamashah 12 hours agoparentprevAgree with sharpness, I undo this on every TV I get a chance to touch at friends&#x2F;family. reply WheatMillington 11 hours agorootparentYou really go around to people&#x27;s homes and change their TV settings? reply karmakaze 10 hours agorootparentI once fixed the remote at a brother-in-law&#x27;s place. Came back a week later and changed channels using the remote. He shouted \"You mean it&#x27;s been working the whole week and I&#x27;ve been on my knees changing channels?!\" reply smusamashah 10 hours agorootparentprevAs in I randomly knock some doors, ask to come in, find their TV, then their remote, then change settings to my liking and leave? reply paledot 5 hours agorootparentNot all heroes wear capes. replyinterestica 9 hours agoprevFor those with a Sony Bravia panel (2015 and later I think), you can enable a pro-mode with a key combo that can turn a laggy and unusable panel into mostly a dumb display.Display, Mute, Vol +, HomeI used this to basically save a frustrating laggy panel. reply sbliny 12 hours agoprevConsumer Reports has a \"TV Screen Optimizer\" that aims to give users optimal picture settings by Brand&#x2F;Model.Also nice that they mention how to turn off ACR and other privacy related features as well.https:&#x2F;&#x2F;www.consumerreports.org&#x2F;mycr&#x2F;benefits&#x2F;tv-screen-opti... reply dontlaugh 16 hours agoprevSadly, (mild) motion interpolation is necessary for those of us that get headaches from 24fps video, especially panning shots.If only filmmakers started with decent frame rates. The few films that came out in 48 fps are so much nicer to look at. reply jiayo 16 hours agoparentIt&#x27;s funny, watching films in 48fps in theatres (specifically the first Hobbit movie that pioneered the concept) to me looks like the actors acted in 2x slow motion and then someone pressed fast forward. Everything looks incredibly unnatural. reply cassianoleal 14 hours agorootparentI had a different experience. At first, I found things unnatural like you did. After a few minutes, I figured out that it was actually the opposite - it had a bit of a theatrical thing going on, i.e. live action vs. recorded and played back.At that point I figured out that it was just because I&#x27;ve been so used to crappy frame rates that the more natural movements feel out of place.I wonder what the first pass, with less motion blur, would have felt like. Maybe better, maybe worse. I kind of feel it would make it worse, in the same way that the transitional from analog to high definition digital made it look worse to me since I could notice the transitions between frames. That is, at least at first. I&#x27;m used to it now. reply whynotminot 6 hours agorootparentI firmly believe most people complaining about the Hobbit in 48 FPS just don’t like change.It’s not worse. In fact it’s so vastly better. Watching a 3 hour movie in 3D without getting a headache from 24 FPS judder (“magic”) was a revelation.But different bad. reply stefandesu 2 hours agorootparentBack in the day, I watched The Hobbit first in 3D 48 fps, and I hated it. Sure, it got less bad throughout the movie, but I just couldn&#x27;t get used to it at all.I then rewatched the movie (also in theaters) in 2D 24 fps and it was infinitely better.I have the same with YouTube videos. I can&#x27;t stand 60 fps videos (except for gaming content); it causes headaches for me. If it&#x27;s something I really want to watch, I&#x27;ll download the 24 fps version and watch it offline (YouTube has it on their servers, but only serves it to certain clients or something).I know other people who just can&#x27;t see a difference, or rather, they don&#x27;t notice it much. I feel like I can spot a 60 fps YouTube video in about 2-3 seconds (usually I pause then to check and reconsider whether I really want to watch it). I also tend to notice 30 fps videos (compared to 24), although they don&#x27;t really bother me.Considering that I&#x27;ve always been the only one at movie nights to notice when the TV&#x27;s frame interpolation setting is on, I guess I&#x27;m an outlier. reply kalleboo 6 hours agorootparentprevI was really looking forward to 48 fps - the juddering in wide panning shots on 24 fps always takes me out of the immersion so I was hoping the cinema world could move forward.There was just something very wrong with it. It kept feeling like suddenly parts of the movie were sped up and going at 2x speed. To the point where I wonder if the cinematographer was just not experienced with the technology to make it work right (like, maybe there are collaries to the 180 rule that need to be experimented with)I watched it in 2D, I&#x27;m sure for 3D it makes a whole different experience. reply wharvle 3 hours agorootparentAlso saw the first film in 2d in the theater at 48fps, also very excited going in, also felt like everything looked sped-up.What it reminded me of was silent era film that’s been slightly sped up on purpose for comic effect. All the walking looked kinda jerky, like it does when you speed up footage of someone walking, for instance. Or very early manual-timing film that was cranked a bit inconsistently. It was so distracting I could hardly focus in anything else the entire movie. If it’d been a better film, I’d say that gimmick ruined it, but… well. reply kalleboo 3 hours agorootparentYeah it was very strange. Like, you don&#x27;t get that effect from 60fps TV or video shot on your smartphone, so I wonder what went wrong to cause it. reply eternityforest 1 hour agorootparentprevMaybe they should try dynamic frame rates, or even dynamic rates for different parts of the screen, since 24 is usually fine for most shots. reply olyjohn 3 hours agorootparentprevI didn&#x27;t like it either. I think it looks too real and takes you out of the fantasy. Something about the way 24fps looks is different from reality and lets your imagination take you away a bit easier. I can&#x27;t really explain it.Like I can watch an animated show, and I have no expectations of it looking real. I can still get lost in the story and enjoy it. I don&#x27;t need it to look like I&#x27;m actually there. reply zhoujianfu 4 hours agorootparentprevI watched it in 3D HFR and it was terrible terrible terrible to me. I felt like I was watching a play. The special effects looked weird&#x2F;bad, the acting felt worse, the makeup more obvious, everything yuck yuck. reply ender341341 14 hours agorootparentprevI think people blamed the frame rate, but for me it was the rest of the effects that put me off, faces were too softened, lots of scenes had weird color saturation, as others mentioned there was a lot of motion blur, compared to LOTR the VFX really pulled me out of lots of scenes. reply thaumasiotes 4 hours agorootparentI did not notice anything that I would attribute to the frame rate. Frankly I think the visuals of the movie were fine.It was the writing that was the problem. reply sp332 15 hours agorootparentprevPeter Jackson added more motion blur in those because he said that it played better with a focus group. I think sticking to a normal 180-degree shutter angle would not feel so weird. reply dontlaugh 14 hours agorootparentprevThere was weird motion blur, but to me it looked far more normal than most films. I realise it’s a minority opinion. reply rocqua 11 hours agoparentprevThere is the alternative of Black frame insertion. It loses a lot of brightness, but helps a lot with stuttering at 24 fps.The problem that causes stuttering is (simplified) that your eye is moving smoothly to follow something on the screen, whilst the image is moving in discrete steps. So when your eyes expect something fixed in side your view, its actually stuttering.Black frames make use of a natural image retention in the eye. Where you effectively continue to see the last bright thing. Hence what you expect to be stationary in your field of view does remain stationary.This was actually key to film based projectors working, because they need a period of black to advance to the next frame. Without image retention it would seem to flicker. Though 24 hz is a bit to slow for that, so they actually added a black period (by just blocking the light) in the middle of each frame to even out the effect. They were already doing BFI, not for motion smoothing, but for flicker smoothing. It seems likely this is accidentally why 24hz film doesn&#x27;t have stuttering whilst 24hz screens do need it.Personally I care too much about the brightness loss of BFI, but it might be interesting for you. reply dontlaugh 2 hours agorootparentIt helps a little and I prefer lower brightness anyway. But it doesn’t remove the panning judder entirely. Mild interpolation does better. reply Timon3 15 hours agoparentprevI&#x27;m personally fine with 24 and 48 FPS (without interpolation), but what I absolutely can&#x27;t stand is a variable rate. I saw Avatar 2 in the cinema with this, and it ruined the experience for me. Switching down always felt like the projector is lagging. reply cpach 14 hours agoparentprevInteresting. Did you ever go to the movies in the 90s? Those were all 24 fps. Did you get a headache then? reply dontlaugh 2 hours agorootparentCinema at 24 fps also gives me headaches in panning shots. It did as far back as I can remember. reply rocqua 11 hours agorootparentprevCinema has a black period in the middle of every frame, that actually prevents these problems. reply huytersd 6 hours agorootparentWait, are you saying that 50% of the movie is a black screen? reply ace2358 4 hours agorootparentYes. Also, most of your LEDs are off 50% of the time too. If it’s done quick enough, you don’t see it. reply bee_rider 5 hours agorootparentprevShould be 50% off in that case! reply lainga 14 hours agoparentprevDid you get this symptom from the narrow shutter snapshot-like filming in Saving Private Ryan?https:&#x2F;&#x2F;cinemashock.org&#x2F;2012&#x2F;07&#x2F;30&#x2F;45-degree-shutter-in-savi... reply jokowueu 14 hours agoparentprevI&#x27;ve never heard of headaches from 24fps video , must be rare reply smcleod 14 hours agorootparentI get it too. I visually see tearing &#x2F; juddering on most video lower than about 40FPS and it’s incredibly tiring. reply dontlaugh 14 hours agorootparentprevAfaict it’s a kind of migraine. Everyone I know that gets headaches from low fps also gets migraines. reply Finnucane 14 hours agorootparentprevI&#x27;d never heard of it growing up in the era when that&#x27;s all there was. I don&#x27;t know if it&#x27;s rare, but it&#x27;s only in the last decade or so I&#x27;ve heard people complaining about it. reply exitb 12 hours agorootparentWe don’t perceive all types of screens in the same way. Film projectors and CRTs display parts of the frame, only part of the time. TFT and IPS screens introduce a lot of inertia and blend the frames. Both of these help the motion illusion. OLED on the other hand has the harshest frame transition - it displays the entire area for the entire time and switches frame content almost immediately. reply foresto 2 hours agorootparent> it displays the entire area for the entire time and switches frame content almost immediately.I&#x27;ve heard this called the sample-and-hold effect. It looks a bit like a fast slide show, and really stands out in high-contrast, steady motion scenes. reply JohnFen 12 hours agorootparentprevI grew up in the same era, and I definitely knew people who could not watch TV because it induced headaches in them. reply thedougd 11 hours agoparentprevAre we including 3:2 pull down and frame doubling as interpolation? reply dontlaugh 2 hours agorootparentNo, that makes it much worse. Avoiding it is a big reason to get 120 fps tv. reply TylerE 14 hours agoparentprevEven if they just moved to 30 like normal TV that’d be noticeably better. reply squidsoup 12 hours agorootparentI don&#x27;t think many cinematographers would agree with you. We have the technology to make films at higher framerates, yet few choose to do so.Interestingly, David Lynch shot Inland Empire at 60fps interlaced, but the film was released at 24fps. reply anthonypasq 10 hours agorootparentanything with cgi will be much more expensive at higher frames right? I also have absolutely no idea how any of that works. reply squidsoup 10 hours agorootparentI would think so, double the render time for 48fps, which is how Cameron shot Avatar II. reply mejutoco 14 hours agorootparentprevJust a note that NTSC has 30 fps. PAL has 25 fps. reply dontlaugh 14 hours agorootparentprevTV in the UK is generally 50 , at least. reply TylerE 13 hours agorootparentThat&#x27;s interlaced though. Effectively half for a progressive scan. reply dontlaugh 13 hours agorootparentI don’t think interlaced video is still broadcast, since analog was shut down. reply kalleboo 6 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_HD_channels_in_the_Uni...> All HD channels in the UK broadcast at 1080i, apart from Sky Sports Main Event UHD channel and the BT Sport Ultimate 4K reply dontlaugh 2 hours agorootparentThat surprises me. I guess I never noticed since I always have interpolation on nowadays. replyhoseja 1 hour agoparentprevYes! Panning shots are such a pain. Motionblur them or something please. reply ssss11 9 hours agoprevI put my Samsung tv behind pihole and holy s** did it chatter. It stopped ads in the tv ui and I can only imagine other dystopian data exfiltration api calls. reply godelski 9 hours agoparentHow did you get the ads to go away? Some left for me but most stayed. I understand that this is because pihole can only do DNS based rejection. I actually had to reduce some blocking because the tighter restriction on DNS calls completely made my Samsung TV inaccessible (a la dumb TV, which may be desired by others but not if you want to use viewing apps like Netflix).I&#x27;ve heard chatter on and off about ad blocking through packet inspection but I suspect this would not be computationally feasible for a pi. But way out of my wheelhouse to even know tbh. reply ssss11 1 hour agorootparentI think I had to block and unblock some calls to figure it out but I don’t recall it being too tricky reply wpm 4 hours agorootparentprevYou can hook up an Apple TV or a PC to your TV and watch whatever you want. reply accrual 6 hours agorootparentprevI had to fine-tune my local pihole to achieve this with a Samsung TV. I basically turned on maximum filtering, then unblocked domains one by one until the needed functionality worked. reply huytersd 6 hours agorootparentWhat do you mean by needed functionality? Do you mean apps like Netflix working or something more fundamental in the TV itself not working without being able to connect to the Internet. reply bkm 12 hours agoprevJust get a modern Sony TV and be done with it. They perfected Motionflow to the point where you no longer think about framerate (choppiness nor soap opera). It&#x27;s clearly a priority, probably because they are the only manufacturer with their own studios (Columbia&#x2F;Sony pictures). There is a reason people pay the $800+ Sony tax over any TV that has the same panel. reply com2kid 11 hours agoparentThe Sony tax is because ads on Sony TVs can all be turned off. Plenty of TVs have their price subsidized by ads, where as when going through initial setup, I&#x27;ve had Sony TVs with ads disabled by default and questions asking if you want to turn them on.Sadly disabling \"recommended content\" on the Google TV launcher also disabled voice search from the remote, but I am pretty sure that is a Google problem and not something Sony chose.(Also my Sony TV cannot stay connected to my WiFi network for more than half an hour before I have to toggle WiFi on and off again...) reply kridsdale1 5 hours agorootparentAll TVs can have ads disabled: unplug the Ethernet. reply com2kid 3 hours agorootparentGiven that 100% of my TV usage falls into these categories:1. Controlling Spotify 2. YouTube videos 3. Photo Albums from Google PhotosNo network connectivity would render my TV completely useless.Though I think I could show photo from a thumb drive, so I&#x27;d have that going for me I guess. reply hirvi74 3 hours agorootparentChromecast, Apple TV, Fire Sticks, Rokus, etc. could all help out here too. I connect a few of those but never my TV. reply com2kid 1 hour agorootparentFire Stick and Roku are worse for ads than what Sony ships.To clarify, my TV shows a list of apps, and that is it, aside from a single \"suggested channel\" at top I cannot get rid of.No content previews, no \"watch now!\" no special promos, just a list of apps.To explain a bit more what I said up above, Sony TVs cost more than other TVs with identical specs, ~$200-$300 USD more, but compared to a mid-range LG or Samsung, Sony opts you out of advertising by default (the initial setup is hilarious, for the most part you&#x27;d have to manually select a bunch of checkboxes to opt into tracking!). reply hackmiester 6 hours agorootparentprevThat behavior follows, given that Google is an ad company. reply newhotelowner 3 hours agorootparentprev> Sadly disabling \"recommended content\" on the Google TV launcher also disabled voice search from the remoteWTF. reply dewbrite 6 hours agoparentprevNot sure exactly what display I have, but it&#x27;s a recent OLED Bravia. Motion smoothing is still awful. reply viktorcode 10 hours agoparentprevI own one, and can say that Motionflow produces uneven results. In certain scenes it kicks in, while completely ignoring others. Still has a way to go. reply thedougd 11 hours agoparentprevAre they changing their interpolation settings based on source material? Some TVs will disable motion interpolation when they detect 24 frame rate content. reply imp0cat 3 hours agorootparentYes, Sony TVs try to detect the original fps and display it accurately.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;bravia&#x2F;comments&#x2F;7ztuwv&#x2F;what_is_moti... reply Flameancer 7 hours agoparentprevBit the don’t tax almost three years ago on an A80J. Honestly the best panel I’ve had. Probably going to buy another Sony panel to replace a circa 2012 4K Samsung. reply richwater 12 hours agoparentprevIs it just that easy? Do you have any specific model recs? reply imp0cat 3 hours agorootparentIt&#x27;s easy, but expensive. ;) Search for Digital Trends on youtube, they have a lot of videos about this. Their current \"budget\" pick seems to be the Sony Bravia X90L. reply Flameancer 7 hours agorootparentprevI have an A80J and it’s possibly the best panel I’ve owned&#x2F;seen in any house that didn’t have something similar. My dad who is a big movie buff with an Atmos HiFi actually got one like a month later after being a big LG fan. reply chpatrick 11 hours agoparentprevBut then what framerate is it? reply deanCommie 11 hours agoparentprevThat doesn&#x27;t make sense. Are you saying these TV&#x27;s still butcher the original artistic intent of the creators for the sake of arbitrary petty consumer desires to have their expensive TV purchase be justified?But they just do it better than the other manufacturers do? reply fomine3 5 hours agorootparentIt&#x27;s a sort of truth. Creators&#x27; intension isn&#x27;t so special for consumers. reply flir 11 hours agorootparentprevC&#x27;mon, that&#x27;s a reddit-level wilful misinterpretation of what he actually said. I mean, look:Are you saying the original artistic intent of the creators to insert unskippable ads at the beginning of the disc is more important than the consumer&#x27;s right to control the playback of the content they bought? Plus I heard it might kill babies.See? It&#x27;s just silly. reply 319 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Certain settings on smart TVs, such as motion interpolation and dynamic contrast, can distort images and make movies look like soap operas.",
      "The article provides alternative names for these settings and recommends switching them off for a better viewing experience.",
      "It suggests using filmmaker mode if available and provides resources for optimizing TV settings and learning more about the topic."
    ],
    "commentSummary": [
      "The discussion covers various TV settings and features, including local dimming, HDMI overscan, microphones, frame interpolation, animation, video display, motion interpolation, and high frame rates in films.",
      "Opinions on high frame rates vary, with some viewers finding it unnatural and uncomfortable, while others enjoy it.",
      "Black frame insertion is mentioned as an alternative to reduce stuttering but results in a loss of brightness. Some individuals may experience headaches or migraines when watching videos with low frame rates.",
      "Different TV models and their capabilities are also discussed, along with ad blocking and unskippable ads.",
      "The debate around preserving the original artistic intent of creators is touched upon."
    ],
    "points": 360,
    "commentCount": 427,
    "retryCount": 0,
    "time": 1701706112
  },
  {
    "id": 38519277,
    "title": "Forecasts without error bars hinder accurate interpretation",
    "originLink": "https://andrewpwheeler.com/2023/11/19/forecasts-need-to-have-error-bars/",
    "originBody": "About C.V. Comment Policy Consulting Courses Advanced Criminology (Undergrad) Crim 3302 Communities and Crime (Undergrad) Crim 4323 Crim 7301 – UT Dallas – Seminar in Criminology Research and Analysis Crime Science (Graduate) Crim 7381 GIS in Criminology/Criminal Justice (Graduate) Crime Analysis (Special Topics) – Undergrad Code Snippets TOC Andrew Wheeler Crime Analysis and Crime Mapping Forecasts need to have error bars Richard Rosenfeld in the most recent Criminologist published a piece about forecasting national level crime rates. People complain about the FBI releasing crime stats a year late, academics are worse; Richard provided “forecasts” for 2021 through 2025 for an article published in late 2023. Even ignoring the stalecasts that Richard provided – these forecasts had/have no chance of being correct. Point forecasts will always be wrong – a more reasonable approach is to provide the prediction intervals for the forecasts. Showing error intervals around the forecasts will show how Richard interpreting minor trends is likely to be misleading. Here I provide some analysis using ARIMA models (in python), to illustrate what reasonable forecast error looks like in this scenario, code and data on github. You can get the dataset on github, but just some upfront with loading the libraries I need and getting the data in the right format: import pandas as pd from statsmodels.tsa.arima.model import ARIMA import matplotlib.pyplot as plt # via https://www.disastercenter.com/crime/uscrime.htm ucr = pd.read_csv('UCR_1960_2019.csv') ucr['VRate'] = (ucr['Violent']/ucr['Population'])*100000 ucr['PRate'] = (ucr['Property']/ucr['Population'])*100000 ucr = ucr[['Year','VRate','PRate']] # adding in more recent years via https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/docApi # I should use original from counts/pop, I don't know where to find those though y = [2020,2021,2022] v = [398.5,387,380.7] p = [1958.2,1832.3,1954.4] ucr_new = pd.DataFrame(zip(y,v,p),columns = list(ucr)) ucr = pd.concat([ucr,ucr_new],axis=0) ucr.index = pd.period_range(start='1960',end='2022',freq='A') # Richard fits the model for 1960 through 2015 train = ucr.loc[ucr['Year'] |z| [0.025 0.975] ------------------------------------------------------------------------------ ar.L1 -0.4545 0.169 -2.688 0.007 -0.786 -0.123 ma.L1 1.1969 0.131 9.132 0.000 0.940 1.454 ma.L2 0.7136 0.100 7.162 0.000 0.518 0.909 sigma2 392.5640 104.764 3.747 0.000 187.230 597.898 =================================================================================== Ljung-Box (L1) (Q): 0.13 Jarque-Bera (JB): 0.82 Prob(Q): 0.72 Prob(JB): 0.67 Heteroskedasticity (H): 0.56 Skew: -0.06 Prob(H) (two-sided): 0.23 Kurtosis: 2.42 =================================================================================== So some potential evidence of over-differencing (with the negative AR(1) coefficient). Looking at violent.test_serial_correlation('ljungbox') there is no significant serial auto-correlation in the residuals. One could use some sort of auto-arima approach to pick a “better” model (it clearly needs to be differenced at least once, also maybe should also be modeling the logged rate). But there is not much to squeeze out of this – pretty much all of the ARIMA models will produce very similar forecasts (and error intervals). So in the statsmodels package, you can append new data and do one step ahead forecasts, so this is comparable to Richard’s out of sample one step ahead forecasts in the paper for 2016 through 2020: # To make it apples to apples, only appending through 2020 av = (ucr['Year'] > 2015) & (ucr['Year']2020,'VRate'], refit=False) updated_forecast = violent.get_forecast(3).summary_frame(alpha=0.05) And here are my predictions: VRate mean mean_se mean_ci_lower mean_ci_upper 2023 371.977798 19.813228 333.144584 410.811012 2024 380.092102 39.803285 302.079097 458.105106 2025 376.404091 57.846105 263.027810 489.780373 You really need to graph these out to get a sense of the magnitude of the errors: Note how Richard’s 2021 and 2022 forecasts and general increasing trend have already been proven to be wrong. But it really doesn’t matter – any reasonable model that admitted uncertainty would never let one reasonably interpret minor trends over time in the way Richard did in the criminologist article to begin with (forecasts for ARIMA models are essentially mean-reverting, they will just trend to a mean term in a short number of steps). Richard including exogenous factors actually makes this worse – as you need to forecast inflation and take that forecast error into account for any multiple year out forecast. Richard has consistently in his career overfit models and subsequently interpreted the tea leaves in various macro level correlations (Rosenfeld, 2018). His current theory of inflation and crime is no different. I agree that forecasting is the way to validate criminological theories – picking up a new pet theory every time you are proven wrong though I don’t believe will result in any substantive progress in criminology. Most of the short term trends criminologists interpret are simply due to normal volatility in the models over time (Yim et al., 2020). David McDowall has a recent article that is much more measured about our cumulative knowledge of macro level crime rate trends – and how they can be potentially related to different criminological theories (McDowall, 2023). Matt Ashby has a paper that compares typical errors for city level forecasts – forecasting several years out tends to product quite inaccurate estimates, quite a bit larger than Richard’s 10% is useful threshold (Ashby, 2023). Final point that I want to make is that honestly it doesn’t even matter. Richard can continue to keep making dramatic errors in macro level forecasts – it doesn’t matter if he publishes estimates that are two+ years old and already wrong before they go into print. Because unlike what Richard says – national, macro level violent crime forecasts do not help policy response – why would Pittsburgh care about the national level crime forecast? They should not. It does not matter if we fit models that are more accurate than 5% (or 1%, or whatever), they are not helpful to folks on the hill. No one is sitting in the COPS office and is like “hmm, two years from now violent crime rates are going up by 10, lets fund 1342 more officers to help with that”. Richard can’t have skin the game for his perpetual wrong macro level crime forecasts – there is no skin to have. I am a nerd so I like looking at numbers and fitting models (or here it is more like that XKCD comic of yelling at people on the internet). I don’t need to make up fairy tale hypothetical “policy” applications for the forecasts though. If you want a real application of crime forecasts, I have estimated for cities that adding an additional home or apartment unit increases the number of calls per service by about 1 per year. So for growing cities that are increasing in size, that is the way I suggest to make longer term allocation plans to increase police staffing to increase demand. References Ashby, M. (2023). Forecasting crime trends to support police strategic decision making. CrimRxiv. McDowall, D. (2023). Empirical Properties of Crime Rate Trends. Journal of Contemporary Criminal Justice, 10439862231189979. Rosenfeld, R. (2018). Studying crime trends: Normal science and exogenous shocks. Criminology, 56(1), 5-26. Yim, H. N., Riddell, J. R., & Wheeler, A. P. (2020). Is the recent increase in national homicide abnormal? Testing the application of fan charts in monitoring national homicide trends over time. Journal of Criminal Justice, 66, 101656. Share this: Twitter Facebook LinkedIn Pinterest Like this: Like Loading... Related Leave a comment by apwheele on November 19, 2023 • Permalink Posted in Crime Analysis, Criminal Justice, data science, Python Tagged arima, forecast Posted by apwheele on November 19, 2023 https://andrewpwheeler.com/2023/11/19/forecasts-need-to-have-error-bars/ Previous Post The sausage making behind peer review Next Post Sentence embeddings and caching huggingface models in github actions Leave a comment Leave a Reply Search for: Recent Posts Sentence embeddings and caching huggingface models in github actions Forecasts need to have error bars The sausage making behind peer review Fitting a gamma distribution (with standard errors) in python AMA: Advice on clustering Categories Categories Select Category art ask me anything Crime Analysis Crime Mapping Criminal Justice data science Data Visualization excel geocoding ggplot2 healthcare interval-censored javascript Macro Mapping Meta Networks NIBRS Papers Personal Productivity Python R Regression scholarly social networking SPSS Stata Tableau Uncategorized website writing Site RSS Feeds RSS - Posts RSS - Comments Follow Blog via Email Enter your email address to follow this blog and receive notifications of new posts by email. Email Address: Follow Join 352 other subscribers aoristic cartography census choropleth citeulike color cost-benefit courses crime-mapping crime-trends Crime Analysis Criminal Justice data-manipulation data visualization deep-learning excel flow-data geocoding ggplot2 github google-streetview-api grammar of graphics group-based-trajectory gun-violence healthcare homicide-rates hot spots hypothesis-testing kernel-density linear programming logistic-regression machine-learning MACRO mapping matplotlib meta multi-level negative-binomial network NetworkX officer-involved-shooting open-science paper Papers peer-review Poisson prediction Predictive-Policing presentation Python Python-programability pytorch quasi-experiment r recidivism regression resources scatterplot scholarly seaborn shootings simulation slopegraph small-multiples social-networking SPSS stackexchange Stata statistics survey time-series uncertainty wdd web-scraping writing Top Posts & Pages Forecasts need to have error bars About The spatial dispersion of NYC shootings in 2020 Stack Exchange Blog at WordPress.com. %d",
    "commentLink": "https://news.ycombinator.com/item?id=38519277",
    "commentBody": "Forecasts need to have error barsHacker NewspastloginForecasts need to have error bars (andrewpwheeler.com) 306 points by apwheele 17 hours ago| hidepastfavorite125 comments amai 6 minutes agoNot only forecast need error bars. Every statistic needs error bars. But even then most people interpret error bars wrongly, see e.g. https:&#x2F;&#x2F;errorbars.streamlit.app&#x2F; reply bo1024 16 hours agoprevTwo things I think are interesting here, one discussed by the author and one not. (1) As mentioned at the bottom, forecasting usually should lead to decisionmaking, and when it gets disconnected, it can be unclear what the value is. It sounds like Rosenfield is trying to use forecasting to give added weight to his statistical conclusions about past data, which I agree sounds suspect.(2) it&#x27;s not clear what the \"error bars\" should mean. One is a confidence interval[1] (e.g. model gives 95% chance the output will be within these bounds). Another is a standard deviation (i.e. you are pretty much predicting the squared difference between your own point forecast and the outcome).[1] acknowledged: not the correct term reply mnky9800n 13 hours agoparentRecently someone on hacker news described statistics as trying to measure how surprised you should be when you are wrong. Big fat error bars would give you the idea that you should expect to be wrong. Skinny ones would highlight that it might be somewhat upsetting to find out you are wrong. I don&#x27;t think this is an exhaustive description of statistics but I do find it useful when thinking about forecasts. reply nonameiguess 10 hours agorootparentThis can be true but depends on other sources of error being small enough. Standard error is just a formula and it varies inversely with the square of the sample size, so you trivially narrow a confidence interval by sampling more often. In this specific case, imagine you had daily measures of violent crime instead of only annual. You&#x27;d get much tighter error bars.Does that mean you should be more surprised if your predictions are wrong? It depends. You&#x27;ve only reduced model error, but this is the classic precision versus accuracy problem. You can very precisely estimate the wrong number. Does the model really reflect the underlying data generating process? Are the inputs you&#x27;re giving reliable measurements? If both answers are yes, then your more precise model should be converging toward a better prediction of the true value, but if not, you&#x27;re only getting a better prediction of the wrong thing.We can ask these questions with this very example. Clearly, ARIMA is not a causally realistic model. Criminals don&#x27;t look at last year&#x27;s crime rates and decide whether to commit a crime based on that. The assumption is that, whatever actually does cause crime, it tends to happen at fairly similar levels year to year, that is, 2020 should be more different than 2010 than it is different from 2019. We may not know what the causually relevant factors really are or we may not be able to measure them, but we at least assume they follow that kind of rule. This sounds plausible to me, but is it true? We can backtest by making predictions of past years and seeing how close they are to the measured value, but the possibility of this even working depends upon the answer to the second question.So then the second question. Is the national violent crime data actually reliable? I don&#x27;t know the answer to that, but it certainly isn&#x27;t perfect. There is a real crime rate for every crime, but it isn&#x27;t exactly the reported number. Recording and reporting standards vary from jurisdiction to jurisdiction. Many categories of crime go undereported, the extent of which can change over time. Changes may reflect different policing emphasis as much as or more than changes in the underlying true rate. I believe the way the FBI even collects and categorizes data has changed in the past, so I&#x27;m not sure a measurement from 1960 can be meaningfully compared to a measurement from 2020.Ultimately, \"how surprised you should be when you are wrong\" needs to take all of these sources of error into account, not just the model&#x27;s coefficient uncertainty. reply Retric 10 hours agorootparentYou can arbitrarily scale error bars based on real world feedback, but the underlying purpose of a model is rarely served by such tweaking. Often the point of error bars is less “How surprised you should be when you are wrong” than it is “how wrong you should be before you’re surprised.”When trying to detect cheating in online games you don’t need to predict exact performance, but you want to decent anomalies quickly. Detecting cereal killers, gang wars, etc isn’t about nailing the number of murders on a given day but patterns within those cases etc. reply wizzwizz4 10 hours agorootparentIs this the difference between Bayesian and Frequentist approaches? reply wayfinder 10 hours agorootparentprevI disagree.You only really need to take those sources of error into account if you want an absolute measure of error, which as you explain, seems pretty impossible.An error for weather only needs to be relative -- for example, if the error for rain today is higher than yesterday, it&#x27;s not important the exact number higher that it is -- only that it&#x27;s higher. (Not that I know if this is possible.)It&#x27;s like how you can&#x27;t describe how biased a certain news source is or how to read a Yelp or Rotten Tomatoes review -- you just have to read it often enough to get an intuitive sense that a 4.1 star Yelp-rated restaurant with 800 reviews is probably good while a 4.6 star restaurant with 5 reviews is quite possibly terrible. reply ISL 8 hours agoparentprevA position espoused by Bill Phillips [1], and to which I now adhere:\"You should be willing to take either side of the bet that confidence interval implies.\" (paraphrasing; he says it better).For a concrete example, with a 95% confidence interval, you should be as willing to accept the 19:1 odds that the true value is outside the interval as you are the 1:19 odds that the true value is inside the interval.Aside from being generally correct, this approach is immediately actionable by making the meaning more visceral in discussions of uncertainty. Done right, it pushes you to assign uncertainties that are neither too conservative nor too optimistic.If the notion of letting your reader take either side of the bet makes your stomach a little queasy, you&#x27;re on the right track. The feeling will subside when you&#x27;re pretty sure you got the errorbar right and your reasoning is documented and defensible.Edit for OP&#x27;s explicit question: One standard-deviation errorbars are 68% confidence intervals. Two standard deviations are 95% confidence intervals. (assuming you&#x27;re a frequentist, of course)[1] https:&#x2F;&#x2F;www.nobelprize.org&#x2F;prizes&#x2F;physics&#x2F;1997&#x2F;phillips&#x2F;fact... reply eru 7 hours agorootparent> Edit for OP&#x27;s explicit question: One standard-deviation errorbars are 68% confidence intervals. Two standard deviations are 95% confidence intervals. (assuming you&#x27;re a frequentist, of course)Also assuming normal distribution, I think?> If the notion of letting your reader take either side of the bet makes your stomach a little queasy, you&#x27;re on the right track. The feeling will subside when you&#x27;re pretty sure you got the errorbar right and your reasoning is documented and defensible.> For a concrete example, with a 95% confidence interval, you should be as willing to accept the 19:1 odds that the true value is outside the interval as you are the 1:19 odds that the true value is inside the interval.I would like to build some edge into my bets. If a reader takes both sides of your example, they would be come out exactly even.But since readers are not forced to take any side at all, they will only take the bet if one of the sides has an advantage.So I would like to be able to say, 20:1 payout the true value is inside the error bar, and 1:10 payout it&#x27;s outside the error bar (or something like that).The tighter the spread I am willing to quote, the more confident I am that I got the error estimates right. (I&#x27;m not sure how you translate these spreads back into the language of statistics.) reply jrumbut 6 hours agorootparent> Also assuming normal distribution, I think?95% is 95% regardless of the distribution.> I would like to build some edge into my bets. If a reader takes both sides of your example, they would be come out exactly even.You can imagine yourself being equally unhappy to take either side of the bet, if that&#x27;s easier than imagining yourself being happy to take either side.It is for me, which is probably something to bring up in therapy.I also think that framing things as bets brings in all the cultural baggage around gambling and so it isn&#x27;t always helpful. I&#x27;m not sure what a better framing is though. reply eru 4 hours agorootparent> 95% is 95% regardless of the distribution.Standard deviation away from the mean don&#x27;t correspond to the same percentiles for all distributions, or do they?If you want to be (almost) independent of distribution, you need Chebyshev&#x27;s inequality. But that one is far weaker.> Its practical usage is similar to the 68–95–99.7 rule, which applies only to normal distributions. Chebyshev&#x27;s inequality is more general, stating that a minimum of just 75% of values must lie within two standard deviations of the mean and 88.89% within three standard deviations for a broad range of different probability distributions.[1][2]https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chebyshev%27s_inequality> I also think that framing things as bets brings in all the cultural baggage around gambling and so it isn&#x27;t always helpful. I&#x27;m not sure what a better framing is though.Underwriting insurance without going bankrupt, perhaps? reply hgomersall 14 hours agoparentprevError bars in forecasts can only mean uncertainty your model has. Without error bars over models, you can say nothing about how good your model is. Even with them, your hypermodel may be inadequate. reply gyrovagueGeist 5 hours agorootparentThey can also mean pushed forward uncertainty from input parameters which isn&#x27;t exactly the same as model error reply hgomersall 2 hours agorootparentI&#x27;m not sure I see the distinction. Would you mind clarifying? reply bo1024 13 hours agorootparentprevTo me, this comes back to the question of skin in the game. If you have skin in the game, then you produce the best uncertainty estimates you can (by any means). If you don&#x27;t, you just sit back and say \"well these are the error bars my model came up with\". reply PeterisP 12 hours agorootparentThere are ways of scoring forecasts that reward accurate-and-certain forecasts in a manner where it&#x27;s provably optimal to provide the most accurate estimates for your (un)certainty as you can. reply bo1024 11 hours agorootparentYes, of course. I don&#x27;t see that as very related to my point. For example, consider how 538 or The Economist predict elections. They might claim they&#x27;ll use squared error or log score, but when it comes down to a big mistake, they&#x27;ll blame it on factors outside their models. reply eru 7 hours agorootparentWell, but at least 538 has a reputation to defend as an accurate forecaster. So they have some skin in the game.(Of course, that&#x27;s not as good as betting money.) reply hgomersall 13 hours agorootparentprevIt&#x27;s worse than that. Oftentimes the skin in the game provides a motivation to mislead. C.f. most of the economics profession. reply eru 7 hours agorootparentHow do economists have skin in the game?Many of them eg work in universities and some even have tenure. There&#x27;s not much skin in the game between any forecasts they might make and their academic prospects.Economists working for companies often have to help them understand micro and macro-economics. Eg (some of) Google&#x27;s economists help them design the ad auctions. It&#x27;s relatively easy to figure out for Google how well those ad auctions work. So they certain have skin in the game. But: what motivation to mislead do those economists have? reply hgomersall 2 hours agorootparentMany economists are so fully bought into their models that they can&#x27;t think of any alternatives, despite them being essentially useless. I interpreted skin-in-the-game in that way - as professionally committed. Perhaps something different was meant. reply eru 2 hours agorootparent> Many economists are so fully bought into their models [...]How do you know that? Whenever I interact with economists, mostly online via blogs but also sometimes via email, they always seem painfully aware of the shortcomings of their models, and don&#x27;t seem to confuse them with reality.Perhaps you have studied a different sub-population of economists than the ones I have anecdotal experience with? reply hgomersall 2 hours agorootparentI&#x27;m a sense, that makes my point. Why do they persist with models that don&#x27;t represent reality despite knowing it? Eventually you must realise that adding epicycles isn&#x27;t going to cut it, yet still the sage voices echo the standard dogma when economies are dragged into the doldrums by policy posed by useless models.Bought into is not the same as believing. reply eru 2 hours agorootparent> Why do they persist with models that don&#x27;t represent reality despite knowing it?Why do physicists ignore friction whenever possible?In general, for any task, you take the simplest model that represents the aspects of reality that you care about. But you stay aware of the limits. That&#x27;s true in physics or engineering just as much as in economics.That&#x27;s why NASA uses Newtonian mechanics for all their rocket science needs, even though they have heard of General Relativity.That&#x27;s why people keep using models known to have limits.> [...] sage voices echo the standard dogma [...]You do know that most of published economics is about the limits of the &#x27;standard dogma&#x27;? That&#x27;s what gets you published. I often wish people would pay more attention to the orthodox basics, but confirming well-known rules isn&#x27;t interesting enough for the journals.So if eg you can do some data digging and analysis that can show that maybe under this very specific circumstances restriction on free trade might perhaps increase national wealth, that can get you published. But the observation that most of the time free trade, even if the other guy has tariffs, is the optimal policy, is too boring to get published.Compare also crap like &#x27;Capital in the Twenty-First Century&#x27; that catapults its author to stardom with its comparatively boring refutation by orthodox economists that no one cares about.> [...] dragged into the doldrums by policy posed by useless models.Most orthodox economics is pretty unanimous about basic policies: for free trade, against occupational licensing, for free migration, for free movement of capital, for simple taxes without loopholes, against messing with the currency, against corruption, against subsidies, for taxes instead of bans (eg on drugs, or emissions, or guns), against price floors or ceilings or other price controls, etc.Many doldrums happen when policy ignores or contradicts these basic ideas. Alas, economics 101 is not popular with the electorate almost anywhere. reply hgomersall 1 hour agorootparent> Most orthodox economics is pretty unanimous about basic policies: for free trade, against occupational licensing, for free migration, for free movement of capital, for simple taxes without loopholes, against messing with the currency, against corruption, against subsidies, for taxes instead of bans (eg on drugs, or emissions, or guns), against price floors or ceilings or other price controls, etcIt&#x27;s interesting that if you oblige your models to fit a set of policy positions then they return that set of policy positions and are pretty useless in general. A cynic might say that&#x27;s by design.Orthodox macroeconomic modelling is laughably naive and mathematically wrong before even getting to the basic issues of failure to validate. Let&#x27;s not compare it to disciplines where validation is the entire point.Your rhetoric clearly shows you don&#x27;t want to think too critically about this so I&#x27;ll sign off now. replynequo 13 hours agorootparentprevThis is a pretty sweeping generalization, but if you have concrete examples to offer that support your claim, I’d be curious. reply m-murphy 15 hours agoparentprevThat&#x27;s not what a confidence interval is. A confidence interval is a random variable that covers the true value 95% of the time (assuming the model is correctly specified). reply bo1024 15 hours agorootparentOk, the &#x27;reverse&#x27; of a confidence interval then -- I haven&#x27;t seen a term for the object I described other than misuse of CI in the way I did. (\"Double quantile\"?) reply cubefox 12 hours agorootparent\"Credible interval\":https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Credible_interval reply bo1024 11 hours agorootparentNo, predictive interval is more precise, since we are dealing with predicting an observation rather than forming a belief about a parameter. reply m-murphy 15 hours agorootparentprevYou&#x27;re probably thinking of a predictive interval reply borroka 15 hours agorootparentIt is a very common misconception and one of my technical crusades. I keep fighting, but I think I have lost. Not knowing what the \"uncertainty interval\" represents (is it, loosely speaking, an expectation about a mean&#x2F;true value or about the distribution of unobserved values?) could be even more dangerous, in theory, than using no uncertainty interval at all.I say in theory because, in my experience in the tech industry, with the usual exceptions, uncertainty intervals, for example on a graph, are interpreted by those making decisions as aesthetic components of the graph (\"the gray bands look good here\") and not as anything even marginally related to a prediction. reply fjkdlsjflkds 2 hours agorootparent> Not knowing what the \"uncertainty interval\" represents (is it, loosely speaking, an expectation about a mean&#x2F;true value or about the distribution of unobserved values?) could be even more dangerous, in theory, than using no uncertainty interval at all.And, from what I understand, this is what is happening in this article.The person is providing an uncertainty interval for their mean estimator and not for future observations (i.e., the error bars reflect the uncertainty of the mean estimator, not the uncertainty over observations).Like you said: before adding error bars, it probably makes sense to think a bit about what type of uncertainty those error bars are supposed to represent. reply m-murphy 13 hours agorootparentprevAgreed! I also think it&#x27;s extremely important as practitioners to know what we&#x27;re even trying to estimate. Expected value (i.e. least squares regression) is the usual first thing to go for, does that even matter? We&#x27;re probably actually interested in something like an upper quantile for planning purposes. And then the whole model component of it, the interval that&#x27;s being simultaneously estimated is model driven and if that&#x27;s wrong, then the interval is meaningless. There&#x27;s a lot of space for super interesting and impactful work in this area IMO, once you (the practitioner) think more critically about the objective. And then don&#x27;t even get me started on interventions and causal inference... reply fjkdlsjflkds 2 hours agorootparent> We&#x27;re probably actually interested in something like an upper quantile for planning purposes.True. But a conditional quantile is much harder to accurately estimate from data than a conditional expectation (particularly if you are talking about extreme quantiles). reply bo1024 13 hours agorootparentprev> is it, loosely speaking, an expectation about a mean&#x2F;true value or about the distribution of unobserved valuesIf you don&#x27;t mind typing it out, what do you mean formally here? reply m-murphy 10 hours agorootparentI think they mean either what is E[x| y] (standard regression point estimate) along with a confidence interval (this assumes that the mean is a meaningful quantity), or the interval s.t. F(xy) -- the PDF of x -- is between .025 and .975 (the 95% predictive interval centered around .5). The point is that the width of the confidence interval around the point estimate of the mean converges to 0 as you add more data because you have more information to estimate this point estimate, while the predictive interval does not, it converges to the interval composed of the aleatoric uncertainty of the data generating distribution of x conditioned on the measured covariates y reply bo1024 9 hours agorootparentAh, that makes sense. The word expectation was really throwing me off, along with the fact that, in the kind of forecasting setting of this post, the mean and confidence interval (used in the correct sense) are not meaningful, while the quantile or &#x27;predictive interval&#x27; are meaningful. reply bo1024 13 hours agorootparentprevYes, that term captures what I&#x27;m talking about. reply lr1970 9 hours agoparentprevError bars (either confidence interval or standard deviations) are of little use because they do not tell you how the probability is distributed within the confidence interval band. The holy grail of forecasting is the Probabilistic Forecast that predicts the entire posterior distribution so that you can sample from it generating scenarios or realizations of the underlying random process. reply americast 9 hours agorootparentWhile I agree, we can always have multiple overlapping error bars to understand how the probability is distributed. I am not sure how a probabilistic forecast method is able to perform this better because the confidence interval is always generated through sampling in either situation.Though probabilistic forecasting methods may have a Bayesian approach, it is Monte Carlo sampling that helps generate the confidence intervals.Feel free to correct me if I am wrong! Thanks :) reply pacbard 13 hours agoparentprevAs far as error bars are concerned, you could report some% credible intervals calculated from taking the some%tile out of your results. It’s somewhat Bayesian thinking but it will work better than confidence intervals.The intuition would be that some% of your forecasts are between the bounds of the credible interval. reply ramblenode 15 hours agoparentprev> Another is a standard deviation (i.e. you are pretty much predicting the squared difference between your own point forecast and the outcome).What you probably want is the standard error, because you are not interested in how much your data differ from each other but in how much your data differ from the true population. reply bo1024 13 hours agorootparentI don&#x27;t see how standard error applies here. You are only going to get one data point, e.g. \"violent crime rate in 2023\". What I mean is a prediction, not only of what you think the number is, but also of how wrong you think your prediction will be. reply nonameiguess 13 hours agorootparentStandard error is exactly what the statsmodels ARIMA.PredictionResults object actually gives you and the confidence interval in this chart is constructed from a formula that uses the standard error.ARIMA is based on a few assumptions. One, there exists some \"true\" mean value for the parameter you&#x27;re trying to estimate, in this case violent crime rate. Two, the value you measure in any given period will be this true mean plus some random error term. Three, the value you measure in successive periods will regress back toward the mean. The \"true mean\" and error terms are both random variables, not a single value but a distribution of values, and when you add them up to get the predicted measurement for future periods, that is also a random variable with a distribution of values, and it has a standard error and confidence intervals and these are exactly what the article is saying should be included in any graphical report of the model output.This is a characteristic of the model. What you&#x27;re asking for, \"how wrong do you think the model is,\" is a reasonable thing to ask for, but different and much harder to quantify. reply bo1024 9 hours agorootparentAnother import point of discussion:> What you&#x27;re asking for, \"how wrong do you think the model is,\" is a reasonable thing to ask for, but different and much harder to quantify.This definitely seems to me to be what the original author is motivating: forecasts should have \"error bars\" in the sense that they should depict how wrong they might be. In other words, when the author writes:> Point forecasts will always be wrong – a more reasonable approach is to provide the prediction intervals for the forecasts. Showing error intervals around the forecasts will show how Richard interpreting minor trends is likely to be misleading.The second sentence does not sound like a good solution to the problem in the first sentence. reply bo1024 11 hours agorootparentprevThanks for explaining how it works - I don&#x27;t use R (I assume this is R). This does not seem like a good way to produce \"error bars\" around a forecast like the one in this case study. It seems more like a note about how much volatility there has been in the past. reply fjkdlsjflkds 2 hours agorootparent> I don&#x27;t use R (I assume this is R)Just to clarify... this is Python code, not R. replyrented_mule 15 hours agoprevYes, please! I was part of an org that ran thousands of online experiments over the course of several years. Having some sort of error bars when comparing the benefit of a new treatment gave a much better understanding.Some thought it clouded the issue. For example, when a new treatment caused a 1% \"improvement\", but the confidence interval extended from -10% to 10%, it was clear that the experiment didn&#x27;t tell us how that metric was affected. This makes the decision feel more arbitrary. But that is exactly the point - the decision is arbitrary in that case, and the confidence interval tells us that, allowing us to focus on other trade-offs involved. If the confidence interval is 0.9% to 1.1%, we know that we can be much more confident in the effect.A big problem with this is that meaningful error bars can be extremely difficult to come by in some cases. For example, imagine having something like that for every prediction made by an ML model. I would love to have that, but I&#x27;m not aware of any reasonable way to achieve it for most types of models. The same goes for online experiments where a complicated experiment design is required because there isn&#x27;t a way to do random allocation that results in sufficiently independent cohorts.On a similar note, regularly look at histograms (i.e., statistical distributions) for all important metrics. In one case, we were having speed issues in calls to a large web service. Many calls were completing inThis makes the decision feel more arbitrary.This is something I&#x27;ve started noticing more and more with experience: people really hate arbitrary decisions.People go to surprising lengths to add legitimacy to arbitrary decisions. Sometimes it takes the shape of statistical models that produce noise that is then paraded as signal. Often it comes from pseudo-experts who don&#x27;t really have the methods and feedback loops to know what they are doing but they have a socially cultivated air of expertise so they can lend decisions legitimacy. (They used to be called witch-doctors, priests or astrologers, now they are management consultants and macroeconomists.)Me? I prefer to be explicit about what&#x27;s going on and literally toss a coin. That is not the strategy to get big piles of shiny rocks though. reply kqr 12 hours agoparentprev> That caused us to dig a bit deeper and see that the two peaks represented logged-out and logged-in users.This is extremely common and one of the core ideas of statistical process control[1].Sometimes you have just the one process generating values that are sort of similarly distributed. That&#x27;s a nice situation because it lets you use all sorts of statistical tools for planning, inferences, etc.Then frequently what you have is really two or more interleaved processes masquerading as one. These distributions generate values that within each are sort of similarly distributed, but any analysis you do on the aggregate is going to be confused. Knowing the major components of the pretend-single process you&#x27;re looking at puts you ahead of your competition -- always.[1]: https:&#x2F;&#x2F;two-wrongs.com&#x2F;statistical-process-control-a-practit... reply mightybyte 15 hours agoprevCompletely agree with this idea. And I would add a corollary...date estimates (i.e. deadlines) should also have error bars. After all, a date is a forecast. If a stakeholder asks for a date, they should also specify what kind of error bars they&#x27;re looking for. A raw date with no estimate of uncertainty is meaningless. And correspondingly, if an engineer is giving a date to some other stakeholder, they should include some kind of uncertainty estimate with it. There&#x27;s a huge difference between saying that something will be done by X date with 90% confidence versus three nines confidence. reply kqr 12 hours agoparentSo much this. I&#x27;ve written about it before, but one of the big bonuses you get from doing it this way is that it enables you to learn from your mistakes.A date estimation with no error bars cannot be proven wrong. But! If you say \"there&#x27;s a 50 % chance it&#x27;s done before this date\" then you can look back at your 20 most recent such estimations and around 10 of them better have been on time. Otherwise your estimations are not calibrated. But at least then you know, right? Which you wouldn&#x27;t without the error bars. reply niebeendend 14 hours agoparentprevA deadline implies the upper limit of error bar cannot exceed it. That means you need to appropriately buffer to hit the deadline. reply mightybyte 6 hours agorootparentI don&#x27;t think that&#x27;s the way it works out in practice. The fact of the matter is that deadlines are missed all the time. In many cases, there is no such thing as 100% certainty that you&#x27;ll hit a \"deadline\"--there are always circumstances outside your control (global pandemics anyone?). There&#x27;s just some implicit confidence threshold or other assumptions lurking around that probably need to be communicated. Do you want three 9s of confidence? Five 9s? Those things are very different and the cost to actually achieve the latter can often be prohibitive. Everyone benefits if we make explicit our pre-conceived idea of precisely what \"cannot exceed\" means. reply staunton 5 hours agorootparentGoing even further, deadlines are often a tool for signaling \"the organization is trying really hard to achieve this fast\". The shorter the deadline (as long as it&#x27;s at least somewhat in theory plausible), the harder you&#x27;re trying. Often most people involved (even those deciding on the date for the deadline) know from the very start that the deadline will almost certainly be missed.I regularly see two kinds of deadlines. \"Planning deadlines\" describe an estimate when something will be done. \"Signalling deadlines\" signal priorities and motivation to employees or clients. Sometimes both exist in parallel for the same task and there is a subset of people who know both. reply bsder 10 hours agoparentprevThe problem is that date estimates for deadlines are NOT a standard distribution and everybody&#x27;s normal statistical tools do not work.They are pretty much a one sided distribution power law. Deadlines almost never come in early and, when they do, it&#x27;s rarely by much. On the other hand, deadlines can come in late by wild amounts.Generating confidence intervals on that is really hard. reply esafak 15 hours agoprevUncertainty quantification is a neglected aspect of data science and especially machine learning. Practitioners do not always have the statistical background, and the ML crowd generally has a \"predict first and asks questions later\" mindset that precludes such niceties.I always demand error bars. reply amai 4 minutes agoparentError bars are important. But most people misinterpret their meaning, see https:&#x2F;&#x2F;errorbars.streamlit.app&#x2F; reply gh02t 12 hours agoparentprevYou can demand error bars but they aren&#x27;t always possible or meaningful. You can more or less \"fudge\" some sort of normally distributed IID error estimate onto any method, but that doesn&#x27;t necessarily mean anything. Generating error bars (or generally error distributions) that actually describe the common sense idea of uncertainty can be quite theoretically and computationally demanding for a general nonlinear model even in the ideal cases. There are some good practical methods backed by theory like Monte Carlo Dropout, but the error bars generated for that aren&#x27;t necessarily always the error you want either (MC DO estimates the uncertainty due to model weights but not say, due to poor training data). I&#x27;m a huge advocate for methods that natively incorporate uncertainty, but there are lots of model types that empirically produce very useful results but where it&#x27;s not obvious how to produce&#x2F;interpret useful estimates of uncertainty in any sort of efficient manner.Another, separate, issue that is often neglected is the idea of calibrated model outputs, but that&#x27;s its own rabbit hole. reply kqr 12 hours agorootparentI&#x27;m going to sound incredibly subjectivist now, but... the human running the model can just add error bars manually. They will probably be wide, but that&#x27;s better than none at all.Sure, you&#x27;ll ideally want a calibrated estimator&#x2F;superforecaster to do it, but they exist and they aren&#x27;t that rare. Any decently sized organisation is bound to have at least one. They just need to care about finding them. reply sobriquet9 9 hours agorootparentprevConformal prediction solves that problem. Split conformal and Jackknife+ are two simplest examples. reply figassis 15 hours agoparentprevSo is it really science? These are concepts from stats 101. And the reasons and need, and the risks of not having them are very clear. But you have millions being put into models without these pre-requisites, and being sold to people as solutions, and waved away as \"if people buy is it&#x27;s bc it has value\". People also pay fraudsters. reply borroka 15 hours agorootparentBut even in academia, where supposedly \"true science\" is, if not done, at least pursued, uncertainty intervals are rarely, with respect to the times they would be needed, understood and used.When I used to publish stats- and math-heavy papers in the biological sciences, very rarely the reviewers--and I used to publish in intermediate and up journals--were paying any attention to the quality of the predictions, beyond a casual look at the R2 or R2-equivalents and mean absolute errors. reply nradov 15 hours agorootparentprevMostly not. Very few data \"scientists\" working in industry actually follow the scientific method. Instead they just mess around with various statistical techniques (including AI&#x2F;ML) until they get a result that management likes. reply marcinzm 13 hours agorootparentMost decent companies and especially tech do AB testing for everything including having people whose only job is to make sure those test results are statistically valid. reply staunton 5 hours agorootparentThe magic words here are make sure. reply macrolocal 14 hours agoparentprevAlso, error bars qua statistics can indicate problems with the underlying data and model, eg. if they&#x27;re unrealistically narrow, symmetric etc. reply CalChris 14 hours agoprevI&#x27;m reminded of Walter Lewin&#x27;s analogous point about measurements from his 8.01 lectures: any measurement that you make without any knowledge of the uncertainty is meaninglesshttps:&#x2F;&#x2F;youtu.be&#x2F;6htJHmPq0OsYou could say that forecasts are measurements you make about the future. reply lnwlebjel 13 hours agoparentTo that point, similarly:\"Being able to quantify uncertainty, and incorporate it into models, is what makes science quantitative, rather than qualitative. \" - Lawrence M. KraussFrom https:&#x2F;&#x2F;www.edge.org&#x2F;response-detail&#x2F;10459 reply doubled112 16 hours agoprevI really thought that this was going to be about the weather. reply dguest 13 hours agoparentMe too, and I was looking forward to the thread that talks about error bars in weather models, which is totally a thing!It turns out the ECMWF does do an ensamble model where they run 51 concurrent models, presumably with slightly different initial conditions, or they vary the model parameters within some envelope. From these 51 models you can get a decent confidence interval.But this is a lower resolution model, run less frequently. I assume they don&#x27;t do this with their \"HRES\" model (which has twice the spacial resolution) in an ensemble because, well, it&#x27;s really expensive.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Integrated_Forecast_System#Var... reply lispisok 12 hours agorootparentA lot of weather agencies across the world run ensembles including US, Canada, and the UK. Ensembles are the future of weather forecasting but weather models are so computationally heavy models have a resolution&#x2F;forecast length tradeoff which is even bigger when trying to run 20-50 ensemble members. You can have a high resolution model that runs to 2 days or so or have a longer range model at much coarser resolution.ECMWF recently upgraded their ensemble to run at the same resolution as the HRES. The HRES is basically the ensemble control member at this point [1][1] https:&#x2F;&#x2F;www.ecmwf.int&#x2F;en&#x2F;about&#x2F;media-centre&#x2F;news&#x2F;2023&#x2F;model-... reply dguest 3 hours agorootparentEven with all the hype around deep learning and GPUs, the weather services are building a lot of new, CPU-only supercomputers [1]. There are plans to use more GPUs and ML in the coming years, but the weather models are real, tangible, economically impactful and strategically essential products. It&#x27;s pretty inspiring to see governments dumping a huge amount of computing power into the working models, and also funding research ideas.[1]: https:&#x2F;&#x2F;www.mdpi.com&#x2F;2073-431X&#x2F;11&#x2F;7&#x2F;114 reply earthscienceman 4 hours agorootparentprevI&#x27;m someone working in the field with weather modelers&#x2F;forecasters but not a modeler myself. Reading this discussion has been an absolute treat ...The most fascinating thing about the concept of error in models, including in ensembles, is you can only calculate and propagate error for contributors that you can quantify. There are many unquantifiable sources of error. Imagine a physical process that you are unaware of that propagates as a bias, for example ice nucleation via aerosols. Perhaps you don&#x27;t even model aerosols. How do you account for error here? What does error even mean?Ensembles only show you intramodel variability. Which is like error, sort of, but only really represents a combination of \"real\" variability in initial conditions and how that propagates through your physics&#x2F;parameterizations.\"models\" the HN commentators make for their businesses surely have parallel concepts, but I don&#x27;t see anyone talking about them. Only discussion about the errors you know when the ugliest errors are the ones that no one knows. reply iruoy 12 hours agoparentprevI&#x27;ve been using meteoblue for a while now and they tell you how sure they are of their predictions. Right now I can see that they rate their predictability as medium for tomorrow, but high for the day after.https:&#x2F;&#x2F;content.meteoblue.com&#x2F;en&#x2F;research-education&#x2F;specific... reply kqr 12 hours agorootparentI&#x27;ll give you one better. The ECMWF publishes their probabilistic ensemble forecasts with boxplots for numeric probabilities: https:&#x2F;&#x2F;charts.ecmwf.int&#x2F;products&#x2F;opencharts_meteogram?base_...They also have one for precipitation type distribution: https:&#x2F;&#x2F;charts.ecmwf.int&#x2F;products&#x2F;opencharts_ptype_meteogram... reply nullindividual 16 hours agoparentprevSame, but in a human context, are mundane atmospheric events so far off today that error bars would have any practical value and&#x2F;or potentially introduce confusion? reply NegativeLatency 16 hours agorootparentFor this reason I really enjoy reading the text products and area forecast discussion for interesting weather: https:&#x2F;&#x2F;forecast.weather.gov&#x2F;product.php?site=NWS&issuedby=p... reply doubled112 15 hours agorootparentAnybody happen to know if there&#x27;s anything more detailed from Environment Canada than their forecast pages?https:&#x2F;&#x2F;weather.gc.ca&#x2F;city&#x2F;pages&#x2F;on-143_metric_e.htmlI really like that discussion type forecast. reply kqr 12 hours agorootparentprevSure -- just a few day outs the forecast is not much better than the climatological average -- see e.g. https:&#x2F;&#x2F;charts.ecmwf.int&#x2F;products&#x2F;opencharts_meteogram?base_...Up until that point, error bars increase. At least to me, there&#x27;s a big difference between \"1 mm rain guaranteed\" and \"90 % chance of no rain but 10 % chance of 10 mm rain\" but both have the same average. reply yakubin 15 hours agorootparentprevAbsolutely. 15 years ago I could reasonably trust forecasts regarding whether it’s going to rain in a given location 2 days in advance. Today I can’t trust forecasts about whether it’s raining currently. reply LexGray 12 hours agorootparentI think that is a change in definition. 15 years ago it was only rain if you were sure to get drenched. Now rain means 1mm of water hit the ground in your general vicinity. I blame an abundance of data combined people who refuse to get damp and need an umbrella if there is any chance at all. reply yakubin 4 hours agorootparentNo. I mean getting drenched, when forecast predicted no rain. 1mm isn’t really noticeable by humans. reply Smoosh 12 hours agorootparentprevIt seems unlikely that the modelling and forecasting has become worse, so I guess there is some sort of change happening to the climate making it more unstable and less predictable? reply lispisok 12 hours agorootparent>I guess there is some sort of change happening to the climate making it more unstable and less predictable?I&#x27;ve been seeing this question come up a lot lately. The answer is no, weather forecasting continues to improve. The rate is about 1 day improvement every 10 years so a 5 day forecast today is as good as a 4 day forecast 10 years ago. replydatadrivenangel 16 hours agoprevThe interesting example in this article is nowcasting! The art of forecasting the present or past while you&#x27;re waiting for data to come in.It&#x27;s sloppy science &#x2F; statistics to not haven error ranges. reply RandomLensman 16 hours agoparentNot easy to always say what the benefit is: if you present in-model uncertainty from a stochastic model that might still say nothing about an estimation error vs the actual process. For forecasting to show actual uncertainty you need to be in a quite luxurious position to know the data generating process. You could try to fudge it with a lot of historical data where available - but still... reply aidenn0 9 hours agoparentprevMakes sense that such a thing would exist, though it renders less funny my joke: \"I&#x27;m almost clairvoyant; I can predict things shortly after they happen\" reply _rm 4 hours agoprevDoesn&#x27;t work.For instance in a business setting, if I say \"it&#x27;ll be done in 10 days +&#x2F;- 4 days\", they&#x27;ll immediately say \"ok so you&#x27;re saying it&#x27;ll be done in 14 days tops then\".More effective to sound as unsure as possible, disclaim everything in slippery language, and promise to give updates to your predictions as soon as you realise they&#x27;ve changed (granted this wouldn&#x27;t work as well for an anonymous reader situation like in this article). reply lordgrenville 1 hour agoparentIs it wrong of them to interpret you that way? What is the correct interpretation? reply KingOfCoders 4 hours agoprevTake the error bars for Scrum estimations, 3, 5, 8 - people treat them as real things although they have huge errors and are very course. reply clircle 15 hours agoprevEvery estimate&#x2F;prediction&#x2F;forecast&#x2F;interpolation&#x2F;extrapolation should have a confidence&#x2F;prediction&#x2F; or tolerance interval (application dependent) that incorporates the assumptions that the team is putting into the problem. reply lagrange77 11 hours agoprevThis is a great advantage of Gaussian Process Regression aka. Kriging.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gaussian_process#Gaussian_proc... reply Arrath 7 hours agoprevI&#x27;m just imagining adding error bars to my schedule forecasting (with schedules that are typically one the optimistic side thanks to management), with bars pointing in the bad direction, and seeing management still insist it&#x27;ll take too long. reply Animats 15 hours agoprevLooking at the graph, changes in this decade are noise. But what happened back in 1990? reply netsharc 11 hours agoparentProbably no simple answer, but here&#x27;s a long paper I just found: https:&#x2F;&#x2F;pubs.aeaweb.org&#x2F;doi&#x2F;pdf&#x2F;10.1257&#x2F;089533004773563485Another famous hypothesis is the phasing out of lead fuel: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lead%E2%80%93crime_hypothesis reply _hyttioaoa_ 12 hours agoprevForecasts can also be useful without error bars. Sometimes all one needs is a point prediction to inform actions. But sometimes full knowledge of the predictive distribution is helpful or needed to make good decisions.\"Point forecasts will always be wrong\" - true that for continuous data but if you can predict that some stock will go to 2.01x it&#x27;s value instead of 2x that&#x27;s still helpful. reply predict_addict 14 hours agoprevLet me suggest a solution https:&#x2F;&#x2F;github.com&#x2F;valeman&#x2F;awesome-conformal-prediction reply sobriquet9 8 hours agoparentThat&#x27;s not a solution, but more like lots of different solutions, many too complicated to understand.I would suggest split conformal first. reply 25 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The academic article criticized by the author provides crime rate forecasts without including prediction intervals.",
      "The author demonstrates with ARIMA models in Python how reasonable forecast error intervals should be included for accurate interpretation of trends.",
      "The author highlights the importance of including error bars and criticizes the original article for overfitting models and misinterpreting correlations. They conclude that macro-level crime forecasts are not useful for policy response and suggest alternative methods for allocating resources to address crime."
    ],
    "commentSummary": [
      "Incorporating error bars or uncertainty intervals in forecasting and statistical analyses is crucial for improving the reliability of scientific models and forecasts.",
      "Discussions highlight the value of forecasting in decision-making and the challenges of accurately measuring and predicting certain outcomes.",
      "The preference for non-traditional economic ideas in academia, different terminology for representing uncertainty intervals, and the difficulty of estimating conditional quantiles are also covered in the discussions."
    ],
    "points": 306,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1701707289
  },
  {
    "id": 38525978,
    "title": "Unveiling a Bot Logic Exploit in Magic: The Gathering Arena, Triggering Automatic Concessions",
    "originLink": "https://www.mayer.cool/writings/I-Hacked-Magic-the-Gathering/",
    "originBody": "Home Writings About Twitter GitHub LinkedInI Hacked Magic the Gathering: Arena for a 100% Winrate TLDR I could make opponents concede at will so that I never lost a game in Magic: The Gathering Arena Hey @MTG_Arena I figured out how to make an opponent auto-concede the game. Let me know how you'd like me to report the issue and I will send over the source + an explanation of how it can be mitigated. Thank you! pic.twitter.com/dWMdkKjOA2 — Daniel Mayer (@dan__mayer) March 31, 2023 Prelude Before we get into it, I want to address some folks who read my last post and were upset that WOTC doesn't obfuscate their client-side code. I actually think it is really rad that they don't! Very motivated folks (read: people who make paid cheats, botters who sell accounts, etc) will always find ways to deobfuscate and analyze client logic they are interested in anyway. All the obfuscation does is raise the barrier to entry in order keep out less invested folks, which means less hacks overall, sure, but it also means less bored nerds like me who just want to poke at something on the weekend. These bored nerds are the sorts of people who report vulnerabilities that they find! You want these people looking at your game! This is my opinion for most games, but especially card games, because the client does even less than usual. Card games are usually pretty tough targets for game hacks because they are turn based, and not a lot of information needs to move between the client and the server. This means that card games are excellent candidates for being 100% server-side authoritative, meaning that the server keeps track of the entire game state and only tells the client what it needs to know. Unlike a fast-paced shooter where the opponent team's models may need to be loaded before you can see them (allowing for wallhacks), or computationally heavy routines like player movement may be offloaded to the client to save resources (allowing for speedhacks), card games are relatively chill in terms of resource consumption and the information boundaries are concrete. All a player can do is play cards and read the board state, and the server tells the player what they can do and when. This means the client will do very little work itself and it will only be given information about unrevealed cards as the cards are played (by an opponent) or drawn (by you). Unrevealed information such as an opponent's hand or the decks never exists locally so they cannot be read. You can't shuffle the deck in a specific order, or change what card you draw. The server just performs these verbs for you and tells you the result. This in stark contrast to something like a first-person shooter, where a player has a lot of verbs and agency available to them at all time. That results in abuses like this: Our MW2 cheat is now done and we're currently in closed testing. This means our cheat will be ready when the game launches, with all the features you'd expect. Once the game is launched you'll be able to get our cheat at a discounted price for a limited time, don't miss it! pic.twitter.com/65N4T0ieFl — EngineOwning.to (@engineowningto) September 25, 2022 In this first-person shooter hack, all that revealed information is already stored and cached within the client - the hack just draws it to screen. Because of the fast-paced and dynamic nature of the game, this information must be available client-side before a player gains line-of-sight to an enemy or object. Otherwise, all of the enemy or object data would have to be sent over the wire realtime at the moment line-of-sight is gained and rendered (and then immediately deleted after line of sight is broken). Performance and latency issues get in the way of that. For now, at least. Check out Riot's anti-wallhack blog HERE about how they minimized client-side player position data. They are making gains in this realm. So yeah. In something like a card game, since the actions a player can take are limited and happen at a set time, the client does not need to store data before it is needed. This also makes the logic to detect invalid actions, like playing a card that is not in your hand or out of turn much easier to implement. I think that's part of the reasong why you don't see a big cheating ecosystem around card games the way you do around FPSes. That doesn't mean that bugs don't exist still though! So let's explore one. Where to start For a card game, I thought that the best course of action was to take a look at the network communication. This is a good rule of thumb for game hacking in general - my favorite defcon talk is just 45 minutes of MMO hacking war stories by Manfred. It is really worth a watch. You will see that the root of all the analysis he performs to find all these bugs comes down to reversing the network protocol. He has custom tooling built that hooks whatever function send/recieves messages after they have been decrypted (if there's encryption) and displays the traffic in some sort of hex viewer UI. It also seems like it has the ability to edit the requests before they are sent to the server or interpreted by the client, and replay messages. Since MTGA is written in C#, the nice thing is that we don't need to do all the fancy stuff he does of hooking the ingress and egress of traffic. Instead, we can very easily manipulate in-game objects at runtime using reflection, including accessing private fields and methods. I have a basic tutorial on how to do this if you are curious. All I needed to do was find the client code and start taking a look. From there I could fiddle with the client at runtime as needed. A lead Looking at decompiled C# is also really nice because it utilizes metadata tokens to associate elements of the compiled code with their human-readable names, which are still stored in the compiled .NET assembly. That means I can see all the function, variable, and class names that the developers wrote when they wrote their code. It turns the decompilation of non-obfuscated .NET assemblies into essentially source code review! So I started searching for functions I would associate with joining a match, as that is where I would expect a lot of the client initialization for a specific game against an opponent to begin. Lo and behold, there was a JoinMatch function! This function was quite long (over 200 lines long), and a lot of it was just dealing with the player metadata, like rank, cosmetics, etc. Down at the bottom though, I got what I was looking for: private void JoinMatch(NewMatchCreatedConfig matchConfig) { ... this._matchManager.ConnectAndJoinMatch(connectionConfig, matchConfig.controllerFabricUri, matchConfig.matchId); if (matchConfig.matchType == MatchType.NPE) { this._npeState.NewNPEOpponent(connectionConfig.MatchDoorHost, connectionConfig.MatchDoorPort, matchConfig.controllerFabricUri, matchConfig.matchId, this._matchManager, this._assetLookupSystem); return; } if (matchConfig.matchType == MatchType.Familiar) { this._botTool.NewBotOpponent(connectionConfig.MatchDoorHost, connectionConfig.MatchDoorPort, matchConfig.controllerFabricUri, matchConfig.matchId, !flag3, this._cardDatabase, this._accountInformation, this._matchManager, this._assetLookupSystem); } } A function named ConnectAndJoinMatch that takes in our match configuration information. Nice. That is likely where our game connects to the match for the first time! ...But that's not all that is there. There are two other checks after we connect to the game server. Do you know what those are? They are Sparky! For those unfamiliar with MTGA, Sparky is sort of MTGA's mascot. Embodied as a small wisp of light, Sparky guides new players through the tutorial and are always available to practice new decks against. Essentially, its a cute dressing up of the tutorial and bot match features of MTGA. Adorable. Well, I got totally side-tracked by this. Sparky is implemented in a pretty interesting way. As you can see there, if the match type is either NPE (which I assume stands for \"New Player Experience\") or Familiar (a standard bot match), other functions are called, which seem to take in a lot of the same information as the function to join a match as a player. Why would that be the case? Because under the hood, any time you play a bot in MTGA, the bot logic runs locally on your machine! It just also connects to the same match server as you, but all the decision-making process for what it is playing runs inside your game running on your computer. I was totally surprised by this, because it means that a (mostly) fully-functioning bot capable of playing arbitrary games of Magic: The Gathering has a small enough footprint to run locally on your machine. I would have thought that a game as complex as MTG would require a lot of overhead in terms of creating an AI opponent. But nope! You can actually check out all of the logic for Sparky, including a few places in the debug UI where WOTC developers reached a corner case that they felt was not worth implementing. I don't blame them - MTG is a beast of a game to try to have full coverage for! Here's my personal favorite, it is reminiscent of the leaked Valve and Yandex source code comments: Don't worry anonymous WOTC developer - we've all been there. The devil's in the implementation (details) Let's take a closer look at what exactly happens when you start a bot match: There's a lot of code here that you don't have to worry about. But check out the highlighted portion. The actual logic handler for the bot is housed inside of a class called HeadlessClient. That class is, well, a headless client. The bot doesn't need to render a game board or anything, so it just connects to a game server and plays the game in its brain, like a Magic: The Gathering Magnuss Carlsen. Since the headless client is also spawned from your game, it uses the same user credentials to authenticate to the game server - in this case a user ID called PersonaID and a JSON web token that is granted to your game after you successfully log in. Standard web authenication. To me that was interesting though, because it means that the game servers don't see anything wrong with the same client essentially connecting to both sides of a match. Were bot match game servers unique in this regard? I doubted that they were. If that were the case, I didn't think that WOTC would have implemented the bot logic client-side. To me one of the benefits of offloading the bot client is that all game servers can run exactly the same and the clients will worry about connecting, filling the appropriate seats, and interfacing with the server properly. I mean \"seat\" literally too! That's how the game keeps track of which player you are, since the credentials are the same for a bot match: Match takeovers! So, as we know from my tutorial on using reflection to hack unity games, we can use game objects to our own ends and alter their behavior. So to test if I could connect to both sides of a regular match, instead of a bot match, I could use a lot of the game logic already written for the bot and matchmaking! I just had to make my own headless client, determine what seat in the game I was, and then connect the client to the other seat. The code I came up with can be found in Appendix A right below this section. Most of the is just accessing in-game memory objects to get all the information needed to know what game I am currently connected to in matchmaking. I then use that information to connect the bot to the game. Once I have all the info, the code figures out the opponent's seat based off of my own, creates and connects the bot, and as some added spice, immediately makes the bot concede. Lo and behold, this worked! Even if the opponent had already connected and we are in the middle of a game, which is what you see in the video. As you can also see, I got rewards as if I beat a human opponent, because this was a matchmaking game: Hey @MTG_Arena I figured out how to make an opponent auto-concede the game. Let me know how you'd like me to report the issue and I will send over the source + an explanation of how it can be mitigated. Thank you! pic.twitter.com/dWMdkKjOA2 — Daniel Mayer (@dan__mayer) March 31, 2023 I hope you have a little bit more respect for Sparky now. You can check out the code below if you are interested, but the servers have now been patched to make sure both seats don't have the same account and JWT for matchmaking games. Thanks for reading, and don't forget to sign my guestbook. Appendix A: Instawin code using System; using UnityEngine; using System.Reflection; using Wizards.Mtga; using Wizards.Mtga.Logging; using WGS.Logging; using Wotc.Mtga.Cards.Database; using Wizards.Mtga.FrontDoorModels; using AssetLookupTree; namespace hax { public class InstaWin : MonoBehaviour { //HeadlessClient cheater; UnityFamiliar cheatbot; // Cast a wide net with our BindingFlags to catch most variables we would run into. Scope this down as needed. // https://learn.microsoft.com/en-us/dotnet/api/system.reflection.bindingflags?redirectedfrom=MSDN&view=net-7.0 BindingFlags flags = BindingFlags.InstanceBindingFlags.PublicBindingFlags.NonPublicBindingFlags.Static; // Create logger for printing to debug log UnityLogger logger = new UnityLogger(\"Tool\", LoggerLevel.Debug); public void OnStart() { // Register our logger LoggerManager.Register(logger); } public void OnGUI() { // Create a window at the center top of our game screen that will hold our button Rect windowRect = new Rect(Screen.width - (Screen.width / 6), Screen.height / 10, 120, 50); // Register the window. Notice the 3rd parameter is a callback function to make the window, defined below windowRect = GUI.Window(0, windowRect, DoMyWindow, \"HackBox\"); // Make the contents of the window void DoMyWindow(int windowID) { // Combo line that creates the button and then also will check if it has been pressed if (GUI.Button(new Rect(10, 20, 100, 20), \"Instawin\")) { Instawin(); } } } public Matchmaking GetMatchmaking() { PAPA papa = GameObject.FindObjectOfType(); return papa.Matchmaking; } public void Instawin() { Matchmaking mm = GetMatchmaking(); if (mm != null) { logger.LogDebugForRelease(\"Matchmaking Exists\"); } // Get cached config Type matchmakingType = mm.GetType(); FieldInfo matchConfigField = matchmakingType.GetField(\"_cachedMatchConfig\", flags); NewMatchCreatedConfig config = (NewMatchCreatedConfig)matchConfigField.GetValue(mm); logger.LogDebugForRelease(String.Format(\"config.matchEndpointHost: {0}\", config.matchEndpointHost)); logger.LogDebugForRelease(String.Format(\"config.matchEndpointPort: {0}\", config.matchEndpointPort)); logger.LogDebugForRelease(String.Format(\"config.controllerFabricUri: {0}\", config.controllerFabricUri)); logger.LogDebugForRelease(String.Format(\"config.matchId: {0}\", config.matchId)); // Get account information FieldInfo accountInformationField = matchmakingType.GetField(\"_accountInformation\", flags); AccountInformation ai = (AccountInformation)accountInformationField.GetValue(mm); logger.LogDebugForRelease(String.Format(\"ai.PersonaID: {0}\", ai.PersonaID)); logger.LogDebugForRelease(String.Format(\"ai.Credentials.Jwt: {0}\", ai.Credentials.Jwt)); // Get card database CardDatabase cdb = Pantry.Get(Pantry.Scope.Application); if (cdb == null) { logger.LogDebugForRelease(String.Format(\"cdb is null: \", cdb)); } logger.LogDebugForRelease(String.Format(\"cdb.VersionProvider.DataVersion: {0}\", cdb.VersionProvider.DataVersion)); // Get Match Manager FieldInfo matchManagerField = matchmakingType.GetField(\"_matchManager\", flags); MatchManager man = (MatchManager)matchManagerField.GetValue(mm); // Get Match Manager FieldInfo assetLookupSystemField = matchmakingType.GetField(\"_assetLookupSystem\", flags); AssetLookupSystem ass = (AssetLookupSystem)assetLookupSystemField.GetValue(mm); logger.LogDebugForRelease(String.Format(\"ass.Blackboard.ContentVersion: {0}\", ass.Blackboard.ContentVersion)); // Get other seat uint otherSeat = man.LocalPlayerSeatId % 2U + 1U; UnityFamiliar.SpawnFamiliar_DEBUG(cdb, config.matchEndpointHost, config.matchEndpointPort, ai.PersonaID, ai.Credentials.Jwt, config.controllerFabricUri, config.matchId, otherSeat, null); cheatbot = UnityEngine.Object.FindObjectOfType(); cheatbot.Client.Gre.ConcedeGame(); } } } Back Sign My Guestbook",
    "commentLink": "https://news.ycombinator.com/item?id=38525978",
    "commentBody": "I Hacked Magic the Gathering: Arena for a 100% Win RateHacker NewspastloginI Hacked Magic the Gathering: Arena for a 100% Win Rate (mayer.cool) 294 points by danielwmayer 8 hours ago| hidepastfavorite66 comments Bluecobra 3 hours agoMy first real foray into Linux was inspecting network traffic with a program called ShowEQ for EverQuest. At the time, the traffic was unencrypted and had lots of juicy info in it. I used a hub to replicate traffic to my Linux box, and it would draw a live map of the zone and showed where the mobs, NPCS, and users were. It even showed what loot the mobs had on them so you could cherry pick certain ones. The beauty of this was that it was passive and impossible to detect. Eventually SOE wised up and started to encrypt the traffic. reply gnyman 1 hour agoparentI&#x27;ll admit I did something similar for a game called Dark Age of Camelot as a teenager. Very educative, learned about both network sniffing, hubs vs switches and Linux. Was it worth it to give me an advantage in the game? No, I never played the game seriously enough to be able to use it, I think I used it for a week after spending two setting it up, but it was a great learning experience. reply Kiro 2 hours agoparentprevHow does encryption help? Your client obviously needs to decrypt it so can&#x27;t you just piggyback on that? reply Scarjit 25 minutes agorootparentIf you don&#x27;t encrypt your network traffic, you can quite easily decrypt it on another PC (as you can just set promiscuous mode on your 2nd PC NIC), giving you undetectable read-only hacks like \"radar\", where you basically have a map of the game with the enemy positions, health, gun, ...If you encrypt it, this is no longer possible. If a cheater wants to decrypt it, he has to get access to the decryption key, which usually is send over an TLS encrypted connection (with certificate pinning in place) [Or in some cases self made encryption :&#x2F;].Therefore he has to either reverse the game to get the certificate or has to attempt to read it while the game is running. In the first case the game developers (and the Anti-Cheat providers) will try there best by obfuscating the specific regions. And the 2nd case is basically what AC is all about, and therefore difficult for modern Anti-Cheats. reply vasco 2 hours agorootparentprevYou need to hack the client for that vs just binding to a network port, or at least have access to a decryption key. reply JimWestergren 41 minutes agoprevOn a related note, I have a blast playing old school magic 93&#x2F;94 with my son. Of course using physical cards. We travel to Madrid each year to participate in the world championship of 7pts Singleton. This summer my son placed #9 which I am very proud of. 7pts Singleton is such a wonderful way to play the game with diverse affordable deck-building and balanced gameplay ( https:&#x2F;&#x2F;7pts-singleton.com ) reply indigo945 8 minutes agoparentI wouldn&#x27;t call a format where Black Lotus, Ancestral Recall and the Moxen are legal \"affordable\" - even though you can&#x27;t play all of them in 7pts Singleton, even any single one of them costs thousands (or tens of thousands) of dollars. However, I&#x27;m glad you and your son enjoy the game, and congratulations on his placement. reply extraduder_ire 6 hours agoprev> I would have thought that a game as complex as MTG would require a lot of overhead in terms of creating an AI opponent. But nope! You can actually check out all of the logic for Sparky, including a few places in the debug UI where WOTC developers reached a corner case that they felt was not worth implementing. I don&#x27;t blame them - MTG is a beast of a game to try to have full coverage for!This is a huge understatement, since the game is nearly (no infinite loops) Turing complete, and people have a lot of fun with that. I assume there&#x27;s a lot of work already done on AI strategy for it though.The post title should probably have a \"Show HN:\" on it too, since you&#x27;re posting it yourself. reply Dylan16807 5 hours agoparentShow HN is for projects people can play with, not blog posts. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;showhn.html reply fauria 2 hours agoparentprevIt is actually Turing Complete: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1904.09828 reply tcbawo 4 hours agoparentprevThe game is constantly changing because new sets are rotating through, but I believe it is possible to create infinite loops with certain dynamics, or at least it has been possible at various points. ie. something like creating&#x2F;killing token characters with \"on entry\"&#x2F;\"on exit\"&#x2F;\"untap\" mechanics, etc. Not all of them result in either player taking damage. reply chmod775 4 hours agorootparentThe rules explicitly address infinite loops and forbid players from forever taking actions that create one. If one would occur anyways, the game ends in a draw.https:&#x2F;&#x2F;mtg.fandom.com&#x2F;wiki&#x2F;Loop reply gpm 4 hours agorootparentOk, so instead of being turing complete it requires solving the halting problem to properly referee it? reply lanternfish 3 hours agorootparentThere are multiple unresolvable game states (panglacial wurm...) but there are catch all rules which allows judges to say &#x27;you&#x27;re not trying to win, so your blocking line results in a game loss&#x27;. They have banned cards before (painter&#x27;s servant) which resulted in competitive non-deterministic winning sequences that forced hundreds of game actions to resolve. reply aidenn0 2 hours agorootparent> &#x27;you&#x27;re not trying to win, so your blocking line results in a game loss&#x27;.Is that how it goes now? It used to be infinite loops (e.g. playing a Faceless Butcher when the only creature in play is a Faceless Butcher that exiled another Faceless Butchers) resulted in a draw, not a loss. reply ivanbakel 33 minutes agorootparentForced infinite loops are still a draw, but setting up a complex-enough board state where the infinite-ness or forced-ness of a particular loop is hard for the judge to decide on will just result in a game loss.Put another way: you can try to set up a game state in a competitive match where the judge has to solve the Collatz conjecture, but because that would take way too long and clearly be contrary to good sportsmanship, you&#x27;d never reach that point. reply chmod775 3 hours agorootparentprev> Ok, so instead of being turing complete it requires solving the halting problem to properly referee it?No - because the referee doesn&#x27;t have to devise a program to do it. They can decide whatever they want. Also the statement of the halting problem isn&#x27;t about it being impossible to tell whether a program will terminate, it&#x27;s about it being impossible to devise a program that can tell whether any other program running on a turing machine (which actual physical computers are not, since they have finite state) will terminate.For any program running on actual physical computer hardware it is obviously possible to tell whether it will terminate. For an actual game of magic, which has considerably less possible state, it&#x27;s likely even trivial 99.9% of the time. The remaining 0.01% are up to the judge. In the case of MTGA on a computer, there are hard-coded limits on many things (but a lack of enforcement of the first part of the loop rule. Nexus of Fate wasn&#x27;t a good time.). reply readams 3 hours agorootparentIt is absolutely not true that for any problem on a real computer it&#x27;s possible to tell if it terminates, other than fairly trivial observations such as noting that if it runs longer than 2^(size of memory) steps it must be looping.If you could, then I&#x27;d start using your \"real computer\" halt checker to instantly mine bitcoin or break all cryptography, so let me know when you figure out out. reply aidenn0 2 hours agorootparentMTG doesn&#x27;t require solving the halting problem because, if neither player nor the referee can come up with a way to halt a loop, then the match ends (long ago, when I played, it ended in a draw; other comments in this thread suggest that a player intentionally doing this may incur a loss now). reply chmod775 2 hours agorootparentprev> It is absolutely not true that for any problem on a real computer it&#x27;s possible to tell if it terminatesHmmm. Reading on...> [..] other than fairly trivial observations such as noting that if it runs longer than 2^(size of memory) steps it must be looping.So you are saying \"You can&#x27;t do it, even though it&#x27;s trivially obvious that you can.\"Or maybe \"If we ignore that it is possible, it is not possible.\"What am I supposed to do with your comment? reply robertlagrant 34 minutes agorootparent> So you are saying \"You can&#x27;t do it, even though it&#x27;s trivially obvious that you can.\"They&#x27;re referring to the halting problem. If you believe you can solve it, you will win money[0].[0] https:&#x2F;&#x2F;www.claymath.org&#x2F;millennium&#x2F;p-vs-np reply kbrkbr 2 hours agorootparentprevYou probably meant 99.99%, or 0.1%. reply joshuamorton 3 hours agorootparentprevProbably not, the infinite loop rules are specifically about rules where a player cannot make a choice in the process.It&#x27;s possible that there&#x27;s a way to do something turing-challenging or busy-beavery in such a situation, but it&#x27;s usually pretty difficult to make complex unbendable loops, they&#x27;re usually very direct cases where taking an action more or less forces you to immediately take the same action again, so the loop has...two steps. Anything much bigger or more complex and you&#x27;re basically assured to have player choice.There&#x27;s probably room to do something where a player is clearly losing unless they do something which might continue a situation that is undecidable. reply asmor 2 hours agoparentprevArena&#x27;s rule engine and AI is based on Duels of the Planeswalkers, so they had several years to develop the AI player. reply jncfhnb 5 hours agoparentprevIs there any practical strategy that approaches this complexity at all? I have never played. But I assume this claim is just that you can technically create some stateful stuff if you’re explicitly not trying to win reply squeaky-clean 4 hours agorootparentTuring machines? Not really. Infinite loops[0]? All the time. The designers generally try to avoid those being legal in \"Standard\" unless it&#x27;s extremely unlikely to happen (only the most recent few years of cards are legal in tournament play. In casual play anything can be legal if your group is okay with it).A common trope is to have a card that allows you to create mana, and then a way to infinitely bring that card back from the discard pile, allowing for infinite mana. Then you play a card that says something like \"spend X mana to deal X damage\" and you deal a trillion damage.[0] the above commenter is correct that a true infinite loop is not allowed. But you&#x27;re allowed to create a scenario where an infinite loop happens according to a repeating choice you can make (essentially a while loop) and repeat as much as you want within the match timer while still allowing time for your damage card. The general etiquette is just to say \"I can do this a billion times and so I deal a billion damage\".I&#x27;ve actually been at a local (mostly informal) tournament where someone with an Elf deck managed to pump their life into the thousands (you start with 20 or 40 depending on the ruleset), and his opponent with a Goblin deck got an infinite combo for infinite damage. But the Elf player refused to accept \"I can do this infinity times\" and made him actually try to perform his card combo over a thousand times before the round timer ran out. Goblin deck did not win. reply aidenn0 2 hours agorootparent> I&#x27;ve actually been at a local (mostly informal) tournament where someone with an Elf deck managed to pump their life into the thousands (you start with 20 or 40 depending on the ruleset), and his opponent with a Goblin deck got an infinite combo for infinite damage. But the Elf player refused to accept \"I can do this infinity times\" and made him actually try to perform his card combo over a thousand times before the round timer ran out. Goblin deck did not win.So the Goblin-deck owner allowed the Elf-deck owner to do a \"I give myself 1000 life\" with a combo but the Elf-deck owner wouldn&#x27;t let the Goblin-deck owner do the same with damage? That&#x27;s kind of a jerk move if so. reply gpderetta 2 hours agorootparentprevI&#x27;m not terribly familiar with tournament rules, but AFAIK in paper games you can always shortcut truly infinite actions by picking a number and the opponent has to accept it, it is not just etiquette. reply deredede 2 hours agorootparentThis is only true if the series of actions you take in the combo are fully deterministic. If the combo includes non-deterministic steps (usually anything related to deck shuffling) you can&#x27;t use shortcuts and have to actually perform the steps. reply gpderetta 1 hour agorootparentWell yes, don&#x27;t bring four horsemen or Gitrog dredge to a tournament. But the majority of combos are not like that. reply jncfhnb 1 hour agorootparentprevEven if the deck shuffling is deterministically irrelevant? reply sciolist 4 hours agorootparentprevHere&#x27;s a paper on creating a Turing machine in Magic:https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1904.09828 reply sdenton4 3 hours agorootparentprevLet us listen to the sweet stories of Sherazad...https:&#x2F;&#x2F;gatherer.wizards.com&#x2F;pages&#x2F;card&#x2F;Discussion.aspx?mult... reply x86x87 4 hours agorootparentprevIt&#x27;s not that easy. There are strategies but they depend on the game format (standard, legacy, modern, etc) and on a deep understanding of the game meta. You cannot devise a strategy that works under any conditions. Lookup the rules + understand that new abilities and cards are introduced all the time. reply saghm 4 hours agorootparentprevI&#x27;m not sure what level of complexity you&#x27;re looking for, but there are some pretty complex combos that have been viable over the years, even in formats that don&#x27;t use some of the older \"broken\" cards. One popular strategy for a while in the \"Modern\" format, which doesn&#x27;t allow cards for the first 10 years or so of the game, used a mechanic called \"Storm\" where a spell would be copied for every spell you previously cast in the same turn. A card called Grapeshot had this ability and did 1 damage, so the deck played creatures that made your spells cost less mana and spells that gave you extra mana or draw cards, and the goal was to cast 19 spells and then grapeshot your opponent for their entire starting life total of 20, often as early as on their fourth turn. It was consistent enough that it was a staple in the format for at least a few years (although I haven&#x27;t kept up with the meta as much for a few years now). Another higher variance but potentially even faster combo used a creature called Griselbrand, which let you pay 7 life to draw 7 cards, a bunch of mana \"rituals\" like storm, and used a card called Nourishing Shoal to let you exile certain cards from your hand to gain life. The win condition was typically to draw at least 7 lands and cast a creature that let you discard a land to do 3 damage, and it could potentially do this on the very first turn, although eventually one of the cards that was necessary for it to function got banned in modern, although by then Griselbrand decks weren&#x27;t really ever played due to there being far more consistent options with better ability to deal with an opponent trying to thwart their game plan. If you include Legacy (which allows cards from any point in the history of the game but still with a custom ban list) or Vintage (where all cards are allowed but some are \"restricted\" to only one copy instead of the typical 4 per deck), there are even more powerful combos you can take advantage of.Combo decks have always and likely will always be a part of the meta for most formats, although to varying degrees depending on how many cards the format has available and how effective it happens to be in the current meta. It&#x27;s considered one of the three main deck archetypes along with \"control\" decks that attempt to shut down what the opponent is trying to do and slowly build an advantage over time and \"aggro\" which use a more straightforward approach of just attacking the opponent with creatures or spells (or both). Not everything cleanly fits into one of those strategies of course, and even a deck that has a win condition that fits into one archetype might dip into the other as a backup plan (e.g. a combo deck with control elements that help it buy time if it can&#x27;t get off the combo as quickly as it would prefer, or a control deck with some efficient creatures that it can use for a surprise attack if the circumstance makes sense), but even in a setting like playing a few games at a card shop on a Friday night, seeing a combo deck with the level of complexity described above isn&#x27;t really uncommon at all.That said, I&#x27;ve read that a lot of the hardest cards to program tend to be the ones that subvert the basic expectations of the game. One infamous example that comes to mind is a creature that after being cast added an extra turn after yours where you controlled your opponent, after which they took their regular turn and the turn order resumed its previous alternation. Programming that would require adding in the ability to show one player&#x27;s hidden game state to the other, let them make any sort of decisions using their cards that the player would normally do (short of literally conceding the game) and inserting an extra turn in the order with that weird control mechanism...all just for one card out of tens of thousands! Obviously most cards are not that complex, and Arena specifically doesn&#x27;t attempt to support literally every card in existence and instead supports cards going back to its initial stable release along with explicitly chosen cards added to special Arena-only sets in order to introduce them, but when its an explicit rule that the text on the card overrides the normal rules of the game when they disagree, it very quickly gets to the point where you need to consider that there will likely be an edge cast for almost any possible state transition. reply hfuaiobfa 6 hours agoprevCongratulations again for the top story, Daniel! I was hacking on MTGA since you posted this article and spoke a little about that with you on GitHub [0].For anyone interested, I&#x27;m _inactively_ working on an unofficial client of MTGA which does hardly anything meaningful for now. The vision is to provide some automation for playing ranked games and stronger bot opponents. Sadly I was distracted lately away from the project and am still puzzled how to make a good UI to see things clearly. I can&#x27;t even estimate when it will be barely useful.Beside that, I&#x27;m still very interested in any game hacking story of Daniel and anyone else! Please tell me more about how to spot such bugs, how not to worry being banned after such hacking, how to `disclosing the bug to them` like @aethros commented, how to structure an unofficial card game client, and other stories. Thank you![0] https:&#x2F;&#x2F;github.com&#x2F;MayerDaniel&#x2F;mayerdaniel.github.io&#x2F;issues&#x2F;... reply no_time 3 hours agoprevHow hard would it be to write a server emulator that facilitates LAN matches with all cards unlocked?I have no interest in interacting with a glorified skinnerbox. reply bodangly 2 hours agoparentYou can just use Cockatrice for that. Sure it’s not as pretty or as easy, but it supports every card since you pretty much are playing paper magic and it’s not trying to be the referee. reply asmor 1 hour agorootparentI think a lot of people explicitly do not want to bother with playing essentially paper magic, because it requires quite a bit more concentration if your board state is complicated to not miss any triggers or phase change too far accidentally. reply chupasaurus 7 hours agoprevIn League of Legends there was a division-by-zero bug with a certain champion and item which caused server to kick all players and then crash. Because the exploiter was being kicked last, their team gets the win while opponents get Loss Prevented because the game doesn&#x27;t have a normal result. reply MaxikCZ 2 hours agoparentIf the enemy doesnt get loss because game doesnt have normal result, winning team should not get win aswell... reply r1ch 7 hours agoprevThis takes me back to the Diablo 2 days when you could connect an open server character (LAN) onto the official bnet (internet) servers by reusing the same connection packets. Since open server data was all saved locally, you could create all kinds of items that aren&#x27;t supposed to exist and the official server would still accept them. reply ProjectArcturis 7 hours agoprevI love the accessible yet insightful level of detail in this post.One thing I don&#x27;t understand is, in the case where you connect your bot during a real match, 1) why does the game allow someone to join mid-match, and 2) when the bot resigns, why does that count as your opponent resigning? If it&#x27;s creating a 3-player game, Player 3 conceding shouldn&#x27;t also make Player 2 concede. reply squeaky-clean 7 hours agoparent> If it&#x27;s creating a 3-player game, Player 3 conceding shouldn&#x27;t also make Player 2 concede.It stays a 2 player game, his code has to figure out which \"seat\" index his account is, and then has the bot join the other seat index.The problem is that they&#x27;re not validating that the joining user is the correct user that should be in that seat.There&#x27;s also the thought that you shouldn&#x27;t allow a player to connect to an already connected seat. But since this game is also available on mobile, you probably want disconnection timeouts to be fairly long, and you don&#x27;t want to interrupt a player who briefly disconnected and then reconnected before the timeout has recognized their early connection is broken. I&#x27;ve seen this in other games, where you try to reconnect and get a \"cannot join game in progress\" for about 10 seconds until you&#x27;re actually able to reconnect.Basically imagine showing up to an MTG tournament at your local game store, pushing someone out of their seat, sitting in it and shouting \"I concede!\". And then the judges agree that player B forfeited the game because the person in their chair declared it. reply Vicinity9635 6 hours agorootparentThanks for this simple explanation! I got distracted by the [FULL VERSION] Magnus Carlsen Blind & Timed Chess Simul at the Sohn Conference in NYC (https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=xmXwdoRG43U) video and now I&#x27;m late for dinner! reply virgildotcodes 7 hours agoparentprev1) I&#x27;m guessing this is how they handle people reconnecting after a disconnection. You terminate the old connection? 2) The bot replaces player 2, then submits a resignation. The server registers it as player 2 resigning. reply ProjectArcturis 7 hours agorootparentAh, makes sense. I guess they just assume that any client who is requesting to sit in that seat is authorized to. reply knallfrosch 1 hour agorootparentLooks to me like they only verified match ids, not the seats at all. reply YawningAngel 7 hours agoparentprevMTG: Arena doesn&#x27;t allow three player games, so what the bot is doing is joining _in_ the opponent&#x27;s seat. Presumably this is why it can concede on their behalf. I guess the game doesn&#x27;t check for this because its developers didn&#x27;t see why anyone would even care to try. reply squeaky-clean 7 hours agoprevThat&#x27;s very fun. This is a \"simple\" enough exploit that I sent it to my MTG group chat, I bet they can understand it without needing to understand any programming jargon beyond client&#x2F;server.I&#x27;m simultaneously surprised something this simple worked, and also not surprised at all. He does make a good point, this is an effective way to provide a practice bot and not need to make many server side modifications. I understand why they did it this way. The problem is they didn&#x27;t make any server side modifications haha.Edit: so far 3 of them have given me a lol or laugh emoji. This is excellent writing. reply adw 5 hours agoparentIt’s shown up in one of the bigger Magic-podcast Discords too. You nailed the writing on this. And “always validate your inputs”! reply danielwmayer 6 hours agoparentprevThank you! reply w-ll 7 hours agoprevLol, i recently got into MTG again with MTGA. I did a quick decompile as its a Unity game and not il2cpp (not that it would have protected it that much) but I found some fun stuff too. Keys for their epic launcher build, some undocumented apis.I never wanted to use it to cheat, i really just wish there was a battle log. What matches I won, what I lost, view the battlefied of a finished game, etc...Gonna check this out, but hopefuly its patched quick. reply danielwmayer 7 hours agoparentThis vulnerability was patched before I wrote the post - I disclosed it to MTG.In terms of viewing your history, you should check out https:&#x2F;&#x2F;untapped.gg&#x2F;en. I have talked to them a bit and they essentially do what you want. They take most of their info from MTG&#x27;s debug log, which you can find in MTGA&#x27;s application directory, so you could also make your own tracker as well if you want. They talk about it on their site: https:&#x2F;&#x2F;help.hearthsim.net&#x2F;en&#x2F;articles&#x2F;3620440-how-do-i-supp... reply aethros 6 hours agorootparentWhat was the process like disclosing the bug to them? One part of your post that you left out and I was curious on. Was it friendly&#x2F;straightforward? Were they surprised at all that this was possible? reply danielwmayer 6 hours agorootparentPretty nondescript. I just sent them the code and explained how to replicate it. They said they&#x27;d patch it and then they did haha. They offered me some in-game currency as a reward (20,000 gems, which I think is equivalent ~115 bucks). reply EdwardDiego 5 hours agorootparentI hope you have the blingiest cards ever now, great write up. reply maxwindiff 4 hours agoparentprevhttps:&#x2F;&#x2F;www.17lands.com&#x2F; collects your limited game win&#x2F;loss stats, and it also records your turn-by-turn game history for both limited and constructed games. (I was a contributor) reply Namahanna 7 hours agoparentprevhttps:&#x2F;&#x2F;mtgaassistant.net&#x2F; is the most common one I know of for collecting your play data. reply tayo42 7 hours agoparentprevI&#x27;m pretty sure this exists. I think it&#x27;s player log. There are a bunch of apps that do tracking that use it iirc reply althea_tx 7 hours agoprevGreat post. Thank you for highlighting that hilarious code comment. reply chrisweekly 7 hours agoprevKudos for a very well-written and educational post! reply MountainMan1312 5 hours agoprev [–] Wish we could hack the card-shuffler for MTGA. I can&#x27;t remember the last time I had a match where at least one of us didn&#x27;t have either no land or nothing but land. reply mproud 3 hours agoparentThere’s supposed to be some non-random hand smoothing going on MTGA. reply baoluofu 17 minutes agorootparentMy understanding is that at the start of a game, the system shuffles and draws three hands for you, and then selects one of them to be your actual starting hand. I don&#x27;t know what heuristics it uses for which of the three to select, but typically in real life you would be hoping for three lands as a baseline, ideally that can tap for the colours of the spells in your hand as well.I believe this only applies in best of 1 matches, but not best of three matches.Unfortunately I don&#x27;t have a credible source for this. reply minimaxir 4 hours agoparentprev [–] This goes all the way back to the original Magic the Gathering: Online in 2001. tl;dr it&#x27;s actually random unlike real shuffling: https:&#x2F;&#x2F;forum.nogoblinsallowed.com&#x2F;viewtopic.php?f=15&t=1184... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author of the post found a way to make opponents concede in the game Magic: The Gathering Arena and informed the game developers about it.",
      "The post explains why card games like Magic: The Gathering are generally more resistant to hacking.",
      "The author discovered a bot logic within the game that runs locally on the player's machine and used it to make opponents automatically concede in a regular match. They shared the code and reported the issue to the game developers."
    ],
    "commentSummary": [
      "The article explores a user's experience in hacking Magic the Gathering: Arena to achieve a 100% win rate.",
      "It discusses network traffic sniffing and encryption as measures to prevent cheating in the game.",
      "The article also delves into the affordability and complexity of the game, including infinite loops, unresolvable game states, and the rules surrounding them."
    ],
    "points": 294,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1701740955
  },
  {
    "id": 38519719,
    "title": "Calculating Fibonacci number based on user input",
    "originLink": "https://html-lang.org/",
    "originBody": "userValue Please enter a number between 0 and 20 userValue We recommend entering a number less than 20 to avoid a delay userValue Please enter a number greater than 0 userValue The userValue th fibbonacci number is result num num num num num",
    "commentLink": "https://news.ycombinator.com/item?id=38519719",
    "commentBody": "HTML, the Programming LanguageHacker NewspastloginHTML, the Programming Language (html-lang.org) 280 points by recursivedoubts 17 hours ago| hidepastfavorite127 comments DistractionRect 13 hours agoIt&#x27;s too early in the week, and I&#x27;m too sober for this.My one nit, is the lack of static typing. I&#x27;m not a fan of radically changing the direction of a project, so instead of baking it into HTML, the Programming Language I suggest the TypeScript route. Something like a hypertext typed programming syntax, HTTPS, to compile to HTML, the Programming Language. reply lassejansen 4 hours agoparentI&#x27;m using Swift Result Builders as a statically typed language to generate HtmlScript code (which a similar approach as html, the programming language):https:&#x2F;&#x2F;htmlscript.orgThis works pretty well for composable server side generated view components. reply recursivedoubts 10 hours agoparentprevconsidering a hindley milner type system for the language, but it would be a big lift w&#x2F; explicit stack semanticsalso looking at HTML, the programming language,++, or, possibly, Objective-HTML, the programming langauge, which would be easier to get to and potentially more awful reply spindle 7 hours agorootparent> hindley milner type system for the languageHindley Type Milner Language#ifixeditforyou reply zeckalpha 7 hours agorootparentprevYou joke but XQuery isn&#x27;t too far off reply ianamartin 8 hours agorootparentprevHow about HTML, the programming language, &#x27;s Flying Circus with a very powerful yet flexible and optional type hinting system? reply djbusby 7 hours agorootparentParrot Typing. reply gemstones 14 hours agoprevOne suggestion - it would be really cool to allow FFI. Something likeconst foo = (bar) => { document.getElementById(&#x27;my-element&#x27;); &#x2F;&#x2F; More here! }; That way you could really leverage the full power of HTML, the programming language! reply cantSpellSober 12 hours agoparentThe contents should be wrapped in a dangerouslySetInnerJS attr to prevent XSS reply recursivedoubts 10 hours agoparentprevHTML, the programming language, is fully interoperable w&#x2F; JavaScript, the programming langauge (sic):https:&#x2F;&#x2F;html-lang.org&#x2F;#jsfunctions defined in HTML, the programming language, can be invoked by JavaScript, the programming language (sic) and vice versa. reply laurent_du 15 hours agoprevFinally I can use html on the frontend and the backend! I am adding a \"full-stack html\" badge to my Linkedin account right away. reply rob 11 hours agoparentPersonally I&#x27;m using CSS [0] on the backend, but might switch it out for HTML. It&#x27;d be cool to use the same technology for both. The CSS+HTML combo has some big limitations.[0] https:&#x2F;&#x2F;dev.to&#x2F;thormeier&#x2F;dont-try-this-at-home-css-as-the-ba... reply dullcrisp 9 hours agorootparentIt would also be cool if someone would explore CSS for the frontend. I think isomorphic CSS could be a really neat stack.Edit: I actually think I recall some pure-CSS frontend examples. We might just need to combine that with backend CSS technologies.Edit edit: Probably the biggest issue will be to prevent the server from evaluating the CSS fully but maybe something like what Next.js does with server and client components could work here. reply dexwiz 13 hours agoparentprevWould an HTML template system written in HTML lang be considered bootstrapping? reply MikeTheGreat 15 hours agoprevThe best part is how they have to keep repeating \"HTML, the programming language\" or \"HTML, the markup language\" everywhere in an attempt to keep things clear :)It would be awesome if they were using some sort of macro system &#x2F; templating engine to consistently expand {{html_prog}} and {{html_markup}} just to keep it straight while they&#x27;re writing it.Thank you for posting this, it made my day a bunch brighter! reply gorgoiler 14 hours agoparentHTPL?I appreciate their joke, but “HyperText Markup Language, the markup language” is a little redundant.Some of us have had to include XSLT programming in our careers. We have seen into the dark abyss… and been paid to do it! reply crdrost 10 hours agorootparentXSLT was the best!Well, except for the syntax and the lack of resources and that it wasn&#x27;t designed to be a programming language...Okay so it wasn&#x27;t the best. But somewhere in there is a language which does want to be the best! reply JonChesterfield 9 hours agorootparentXSLT might have the greatest ratio of brilliance to marketing of anything in our industry.XSLT is a pattern matching DSL for converting trees into other trees. What things are trees? Programs.It is also XML. XML is a boring business thing for boring business people associated with legacy Java codebases. We like json here. Or maybe yaml. To quote an otherwise excellent past colleague, \"the pointy brackets hurt my eyes\". It&#x27;s horrible to edit in notepad too.Who wants XML syntax for a purely functional programming language? No-one wants that, we write our compilers in C++ thank you.As a bonus extra, \"XML schema\" are a similarly crufty rubbish old thing in nasty XML syntax that look suspiciously like \"type of that tree\". So you can typecheck the intermediate IR in your compiler pipeline. If you wrote it in the bad language from the before times. Emacs knows what those schema mean too.The world has moved on to better marketed semantically worse things with prettier syntax. This brings me joy. reply dehrmann 4 hours agorootparentHey, XSLT is functional, and functional languages are sexy, right?What XSLT did do was standardize XML on a transformation language. JSON never really got that, and the ecosystem is worse for it. reply gorgoiler 7 hours agorootparentprevWhoa there, “lack of resources”?!The definitive and complete resource is Michael Kay’s XSLT book (originally Wrox Press, but now part of O’Reilly I think?). Granted, a paper book as a resource isn’t great, but it’s some book!Kay went to Cambridge (Trinity) and did his PhD under Sir Maurice Wilkes. He’s no joke: one of the examples from the book is implementing the Knight’s Tour. Although this is only the chapter pre-amble, the commentary is indicative of what kind of book this is:https:&#x2F;&#x2F;www.oreilly.com&#x2F;library&#x2F;view&#x2F;xslt-20-and&#x2F;97804701927...It’s like Dijkstra writing the definitive reference manual for CSS and one of the formatting examples being an engine for solving Towers of Hanoi.While I have qualms about the utility of XSLT as a general purpose language — it’s fine if you embed it in an imperative language a la SQL in Python, and awful if you try and use it standalone — it also gave us XPath which is by far the best way of querying markup that I’ve ever used. (Well, until CSS got attribute selectors, so I use it less and less these days I suppose.)(You probably know all this, but it was interesting to add to the thread.) reply __MatrixMan__ 10 hours agorootparentprevSo it&#x27;s like... jq for xml, except the language is an xml dsl?Is it pronounced \"ex-slut\"? reply jraph 14 hours agoparentprev> It would be awesome if they were using some sort of macro system &#x2F; templating engine to consistently expand {{html_prog}} and {{html_markup}} just to keep it straight while they&#x27;re writing it.You could use thetag. To use it: Using source to look familiar to bash users because why not. reply recursivedoubts 14 hours agorootparentBy the way, you can implement in HTML, the programming language, because it is extensible!https:&#x2F;&#x2F;html-lang.org&#x2F;#extending reply paulddraper 11 hours agorootparentprevMaybe evenreply paulddraper 13 hours agoparentprevIt&#x27;s \"HTML\" aka \"HTML Turing-complete Markup Language\" reply chrismorgan 7 hours agoprevNot fond of using single-row tables for objects; definition lists are far more suitable:fooFoo bar You could reasonably leave tables as a way of defining an Array.Usingfor addition andfor duplication just makes me sad. It almost makes be suppose you don’t care about HTML (the markup language) semantics! reply xupybd 15 hours agoprevNow the discussion around HTML being a programming language gets really muddy.Thanks to \"a slightly unhinged man living in montana\" reply TremendousJudge 12 hours agoparentReminds me of xkcd&#x27;s Frankenstein: https:&#x2F;&#x2F;xkcd.com&#x2F;1589&#x2F; reply scop 15 hours agoprevIs this \"HTML-based\" or \"HTML, based\"? reply moritzwarhier 14 hours agoparent is an obscure tag that I think allows to exploit accidental turing completeness similar to the checkbox hack.Or is it? I once considered using that tag for some price calculator widget, but it couldn&#x27;t even replace a div because of styling issues or something.That being said, I spent like half a minute trying to figure out the point of this post and then lost interest...Will try again, was hoping for a funny Rube Goldberg machine instead of T-shirt merchandise.So nah, it&#x27;s about as \"based\" as blogging about JS frameworks IMO. reply recursivedoubts 10 hours agorootparentwell that&#x27;s no fun reply toddmorey 14 hours agoprevI’m going to make it my career mission to build something on this that you have to maintain, recursivedoubts reply recursivedoubts 14 hours agoparentbased reply halosghost 10 hours agoprev[1] suggests that I should define functions with the `` tag, but the documentation appears out-of-date, because the HTML program sample shows using the `` tag. Is the next revision of HTML, the Programming Language, A Programming Language going to cover the difference between the `` and `` tags, or deprecate one of them?All the best,[1]: https:&#x2F;&#x2F;html-lang.org&#x2F;#defining-functions reply recursivedoubts 9 hours agoparentit appears there may have been an error in the example (not in HTML, the programming language, which is correct by definition)i tried to fix it reply halosghost 9 hours agorootparentI appreciate your tireless efforts towards the perfection of HTML, the programming language, as well as its accompanying documentation.Thank you!All the best, reply recursivedoubts 14 hours agoprevbtw, this is a working programming language and there is an example of fib()https:&#x2F;&#x2F;html-lang.org&#x2F;#exampleand live demo at the bottom:https:&#x2F;&#x2F;html-lang.org&#x2F;#live-demothat runs disturbingly fast given the implementation is an inefficient recursive algocomputers are fast reply xnx 15 hours agoprevAs long as we&#x27;re creating confusing names, are there any Hypertext Machine Learning projects (HTML)? reply xyproto 8 hours agoprevThis makes conversations that much harder:Mallory: Is HTML a programming language?Bob: No! Well some people think is, but they are wrong! Then again, there is the HTML programming language...Mallory: !??? reply GuB-42 13 hours agoprevInterestingly, since it is actually XML, you could take advantage of all the XML features. A XSD may be able to encode the language grammar, and with XSLT, get some nice rendering.Of course, the parser is just a DOM parser, which is built in browsers and that&#x27;s what the interpreter is using. But if you want to write a standalone compiler for it, just take an off the shelf XML DOM parser and you have your AST. reply g9yuayon 12 hours agoprevI remember in the hay days of XML, someone made an article that discussed why XML is really just a language of S-expressions. This article seems argue something similar.P.S., S-expression or not, XML-based DSLs are horrible. I don&#x27;t know how many people have PTSDs using ANT or a slew of commercial \"user-friendly\" DSLs for test automation, process automation, and etc. It turns out the companies just didn&#x27;t know how to design small programming languages and certainly lacked of compiler-writing skills. reply abrolhos 9 hours agoparentOh, you reminded me about this article: https:&#x2F;&#x2F;www.defmacro.org&#x2F;ramblings&#x2F;lisp.html reply k__ 12 hours agoparentprevI remember JSX examples that went in this direction. reply mrighele 13 hours agoprevMaybe I am mistaken but it seems to me that the stack is implemented with a Javascript. I am a bit disappointed, in the sense that the stack too could have been implemented as a a list of tags in the containing document.This would enable interesting features such as visual debugging (you just check the document to see the status of the program) and more importantly would enable the \"code as data\" paradigm, giving us easy metaprogramming and essentially a \"lisp with brackets\"(Yes, I am not being completely serious) reply recursivedoubts 10 hours agoparentprogress... not perfection reply maxwelljoslyn 8 hours agoparentprevI want this too. reply fuzztester 8 hours agoparentprevs&#x2F;stack&#x2F;Slack&#x2F;(Neither am I) reply chubot 16 hours agoprevUh, why call it HTML? Why not call it HTML-Stack or something?It&#x27;s not HTML, but a language using HTML syntax. reply recursivedoubts 16 hours agoparentit&#x27;s not called HTMLit&#x27;s called HTML, the programming langauge(sometime I use \"HTML\" just to keep things shorter) reply jakelazaroff 16 hours agorootparentHow about HTML: Turing-complete Machine Language reply recursivedoubts 16 hours agorootparentHTMLTML has a nice ring to it! reply chalsprhebaodu 15 hours agorootparentI’d shorten it to just HTML at that point, where the H is short for HTML:HTML: Turing-complete Machine Language reply recursivedoubts 15 hours agorootparentah, a good ideai mean, who knows, maybe that&#x27;s what HTML in HTML, the programming language stands for! reply fuzztester 8 hours agorootparent>ah, a good ideanah, a GNU (new) idea reply alexpetros 15 hours agorootparentprevI think we need to save that for HTML, The Markup Language reply proc0 6 hours agorootparentprevHow about HTML 2: Electric Boogaloo reply nickpeterson 10 hours agorootparentprevHTMPL? “Hyper Text Markup Programming Language”Then you could pronounce it “High temple”. reply PrimeMcFly 15 hours agorootparentprevSo, HTPL then. reply syndicatedjelly 15 hours agoparentprevIt&#x27;s web dev, the best way to get adoption is to trick people into using your stack reply IroncladDev 15 hours agoprevExtremely based reply klibertp 13 hours agoprev...now I&#x27;m starting to wonder whether htmx and _hyperscript are similar to this, just disguised better...? And I was seriously considering using htmx for one thing, too. reply fabiancook 13 hours agoparent> Footnotes: > This was revealed to me in a dream. > HTML: the programming language is brought to you by big sky softwareIs the same big sky software :)Had seen this pop up on github.. https:&#x2F;&#x2F;github.com&#x2F;1cg&#x2F;html.js reply dewey 13 hours agoparentprevLook at the footer, the site is connected to htmx reply hoosieree 14 hours agoprevStill better than YAML. reply imhoguy 12 hours agoprevThe next challenge - let it run itself:reply n3storm 5 hours agoprevI don&#x27;t think usingascommand when add could be used and a dd tag already exists is a good idea.Same with sub, ul, ...The more a I read the page the more it looks like a joke... reply dejawu 13 hours agoprevThis almost reads like a deconstruction of my favorite explanation of Lisp: https:&#x2F;&#x2F;www.defmacro.org&#x2F;ramblings&#x2F;lisp.htmlThe explanation basically uses an AST that&#x27;s apparent to the user to explain the language - and this is a language built on an AST whose structure is apparent to the user. I love it and will definitely be turning the idea over in my head for the next few days. reply recursivedoubts 17 hours agoprevi made this reply jakelazaroff 16 hours agoparentextremely cursed. great job reply arp242 15 hours agoparentprevHow many people have bought the shirt? reply recursivedoubts 15 hours agorootparentlooking now... so far 0 (zero) peoplestill optimistic! reply arp242 15 hours agorootparentHm, I&#x27;d order one, but unfortunately your form doesn&#x27;t use proper ISO-8859-1 encryption so I&#x27;m a bit wary. It&#x27;s always best to use ISO standards. reply recursivedoubts 14 hours agorootparentprevupdate: 4 (four) people! reply arp242 13 hours agorootparentSo how high is my sales commission? reply recursivedoubts 10 hours agorootparent$0! reply scop 15 hours agorootparentprevIt&#x27;s my birthday today so I might just not buy myself a little something. reply toasterlovin 15 hours agorootparentprevshould be at least 1 now reply protopete 15 hours agoparentprevHey I noticed that the division code example is using the \"ul\" tag instead of the \"div\" tag. Thanks!Edit: nevermind, but the comment still says \"This ul tag\" reply recursivedoubts 14 hours agorootparentjust pushed another fix! reply dullcrisp 14 hours agoparentprevIn the setting properties example I think it should be body rather than body. reply recursivedoubts 9 hours agorootparentthank you fixed! reply krapp 15 hours agoparentprevThanks, I hate it. reply recursivedoubts 15 hours agorootparent:heart-hands: reply wds 15 hours agoprevEverybody&#x27;s so creative! reply layer8 14 hours agoprevShould have called it HTPL.That already exists, though: https:&#x2F;&#x2F;esolangs.org&#x2F;wiki&#x2F;HTPL reply 0x00C0FFEE 8 hours agoprevGreat work! I’d love to see a server-side tempting engine written in HTML, the programming language that can be used to send HTML, the markup language files to clients. reply guseyn 8 hours agoprevhttps:&#x2F;&#x2F;e-html.org&#x2F;html&#x2F;documentation.html reply replwoacause 5 hours agoparentThis is awesome! Can’t believe I haven’t seen it before. Reminds me of HTMX in a way. Did this project come before or after it? Can you differentiate them? I’d like to use this in a hobby project but am not sure how it differs from HTMX. They seem to overlap in some areas? reply jayknight 11 hours agoprevOk, I guess I&#x27;ll do Advent of Code in HTML, the Programming Language this year... reply ivanjermakov 13 hours agoprevI did something similar for fun in uni: HTPL[1].Basically, HTML->Python transpiler.[1]: https:&#x2F;&#x2F;github.com&#x2F;Koous61&#x2F;htpl&#x2F;blob&#x2F;master&#x2F;example&#x2F;scratch.... reply 51Cards 15 hours agoprevGiving me memories of tag based Coldfusion days. reply SpaceL10n 14 hours agoparentSame. I liked ColdFusion for what it was, but I also don&#x27;t miss it. The spaghetti code I had to fix is what I remember most. While spaghetti code isn&#x27;t a unique problem to CF, it is made so much harder to fix when you don&#x27;t have a debugger and you can&#x27;t right-click to find references. The horrors of endlessly nested cfloops inside cfifs with cfaborts and cflocation tucked away wherever the programmer needed it. never again! reply eagle2com 11 hours agoprevHow am I supposed to complete the LinkedIn quizz for HTML (the programming language) when the documentation states thatwill result in values \"anded\" together >:( reply recursivedoubts 10 hours agoparentpushed a fix! reply socketcluster 10 hours agoprevI&#x27;m really into this HTML web components trend. I built a similar set of primitive HTML components except the focus is to allow interfacing with data from my serverless platform.See https:&#x2F;&#x2F;github.com&#x2F;Saasufy&#x2F;saasufy-components#saasufy-compon...Actually, the elements from this article could complement my own nicely as they seem to provide more fine-grained control.My platform is https:&#x2F;&#x2F;saasufy.com&#x2F; (you can log in with GitHub) reply dexwiz 15 hours agoprevWhy is the iterator implemented as a GOTO instead of something like the following? Genuine question, I don&#x27;t use stack based langs.reply recursivedoubts 15 hours agoparentin designing HTML, the programming language, i tried to stay as close as possible to existing semantics in HTML, the markup language, as I could, so that HTML, the markup language, developers would be comfortable with it in a minimum amount of timemost HTML, the markup langauge, developers are used to anchor tags (i.e. thetag) with an href that begins with a hash \"jumping\" to that element. Therefore I decided to take that well known semantic and integrate it into HTML, the programming language.there are multiple examples of loops using this (as well as the\"if\" conditional) tag that I think show how intuitive this will be for most HTML, the markup language, developers, but of course research is ongoing in this and other matters reply dexwiz 14 hours agorootparentI guess I don&#x27;t really think of HTML as \"sequential\" but I definitely do think of it as \"composed.\" Meaning I don&#x27;t often consider siblings elements, but I often do consider parent&#x2F;child elements. Anchor tags that link to other parts of the doc are relatively rare compared to links to other docs. The only exception is stuff like schema definitions or reusable shapes in SVGs.Either way, fun project! reply recursivedoubts 14 hours agorootparentresearch ongoing! reply PrimeMcFly 15 hours agoparentprev> Genuine question, I don&#x27;t use stack based langs.How and why not? What languages do you use? reply dexwiz 14 hours agorootparentCommon ones like JavaScript, Java, C#, etc. They all have a stack, but aren&#x27;t stack oriented like Assembly or Forth. The stack in modern languages is abstracted so you don&#x27;t have to worry about pushing&#x2F;popping values in a specific order, and you can&#x27;t explicitly reference it. C and Rust is probably the closest I get with Heap v Stack memory, but even that is not truly stack oriented.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Stack-oriented_programming reply toasterlovin 14 hours agorootparentWas literally reading that wikipedia page last night before bed, so this is all very timely for me. reply PrimeMcFly 14 hours agorootparentprevAh gotcha. Thanks. reply24 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The program prompts the user to input a number between 0 and 20.",
      "Users are advised to choose a number less than 20 to prevent any delays.",
      "The program then asks the user to input a number greater than 0.",
      "The output of the program is the nth Fibonacci number, where n is the user's input."
    ],
    "commentSummary": [
      "The discussions revolve around the idea of using HTML as a programming language and the potential benefits and drawbacks of this approach.",
      "Suggestions are made to incorporate static typing or use TypeScript to enhance HTML as a programming language.",
      "There is also a discussion about the interoperability of HTML with JavaScript and its use on both the frontend and backend."
    ],
    "points": 280,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1701709044
  },
  {
    "id": 38518473,
    "title": "Google's Critique: A High Satisfaction Code Review Tool",
    "originLink": "https://engineercodex.substack.com/p/how-google-takes-the-pain-out-of",
    "originBody": "Share this post How Google takes the pain out of code reviews, with 97% dev satisfaction engineercodex.substack.com Copy link Facebook Email Note Other Discover more from Engineer’s Codex Case studies and practical lessons from real-world software engineering. Become a smarter software engineer in just 7 minutes a week. Over 10,000 subscribers Subscribe Continue reading Sign in How Google takes the pain out of code reviews, with 97% dev satisfaction A study of Google's code review tooling (Critique), AI-powered improvements, and recent statistics Dec 4, 2023 43 Share this post How Google takes the pain out of code reviews, with 97% dev satisfaction engineercodex.substack.com Copy link Facebook Email Note Other 6 Share Engineer’s Codex is a publication about real-world software engineering. Subscribe A lot of ex-Google engineers talk about how much they miss Critique, Google’s code review tool, out of all the internal tools they leave behind. Source: X/Twitter Another Reddit comment laments about how they “miss [Critique] so bad”, listing off various features they miss, like its “attention set,” which is explained below. This tracks with Google’s own findings. Internally, 97% of Google software engineers are satisfied with Critique.1 But what is Critique exactly and what makes it so good? How does this pair with Google’s actual process of code review? In this article, I dive into: Google’s guidelines for efficient code review Critique, their code review tooling, and AI-powered improvements Internal statistics on Google code reviews Why Critique seems to be so loved by Googlers While the SWE Book covers the basics of Critique, new blog posts and research by Google show new developments in their code review processes, such as using AI to make automatic suggestions and improvements to code changes. Google’s Code Review Guidelines To understand how Google writes clean, maintainable code, I wrote about Google’s readability process here. Google’s guidelines for a good code review include: Continuous improvement over perfection: While a more seasoned developer may find a less experienced developer’s code to not be up to their personal standard, Google encourages continuous improvement over perfection. Developers need to make progress; overly difficult reviews can discourage future improvements. Maintain or improve the health of the codebase Follow the Style Guide: When code style comes into question, Google’s style guides are followed and referenced to a tee. Always Share Knowledge: Reviewers are encouraged to share knowledge about language features, the codebase, and other relevant artifacts through code review. Usually, these guidelines are sent with “supporting documentation,” such as links to Google/Abseil’s C++ Tips of the Week. At Google, the educational aspects of a code review are highly emphasized. Write Small Changes: Keep changes limited to about 200 lines of code if possible. Strict Standards for Lightweightness: Google expects reviewers to review a code change in less than 24 hours and encourages reviews to only have one reviewer if possible, which saves time for everyone involved. “The majority of changes at Google are small, have one reviewer and no comments other than the authorization to commit. During the week, 70% of changes are committed less than 24 hours after they are mailed out for an initial review.”2 Politeness and Professionalism: Maintaining a culture of trust and respect is crucial. Feedback should be professional, avoiding personal criticism. Reviewers should be open to the author's approach, offering alternatives only if necessary, and treating each comment as a learning opportunity. I wanted to comment on this one specifically, as while it seems obvious, it’s not as easy to do in practice. It’s common for people to get attached to the code they’ve written or for reviewers to come off as harsher than they meant to. The written word leads for less nuanced communication compared to face-to-face. Google has done a lot of research into how code comments can affect developer productivity and motivation. Predicting Developers’ Negative Feelings about Code Review Destructive Criticism in Software Code Review Impacts Inclusion Detecting Interpersonal Conflict in Issues and Code Review: Cross Pollinating Open- and Closed-Source Approaches Using research to make code review more equitable For a changelist (CLs are Google’s version of pull requests, or PRs) to go through, it must have 0 unresolved comments, a LGTM (Looks Good To Me) from at least one reviewer, and 2 types of approval: people who “own” the part of the codebase the files go into Readability approvals, who approve the “readability” and style of the code One person can be the LGTM-er and approver all at once. Subscribe Critique: Google’s Code Review Tool Critique is Google’s code review tool, allowing engineers to efficiently review and submit code changes. Critique’s UI, from SWE Book They also have a diff view between the current codebase and the proposed changes: The diff view, from Resolving Code Review Comments with ML Importantly, Google’s recent publications in 2023 show they have comprehensive AI-powered code review tools in-house now (as shown above). When reviewers leave comments on code, Critique will show suggested ML-powered edits, which mean that the author of the code review just has to click one button to address the comment in entirety. Recent developments, based on Google research papers, tell us that Google is improving developer productivity with AI-powered code review tools where possible. The Code Review Flow The SWE Book covers Critique in detail with over 5000 words, but I summarize the key points here and have provided a link for those who want to dive deeper into it. Stage 1: Create a Change A CL (or Pull Request) is created in Google’s in-house code editor Cider, which is “tightly integrated with Critique and other in-house Google tools”, leading to higher developer productivity. Prereview Tools: Critique assists in polishing changes before review, showing diffs, build and test results, and style checks. Diffing and Visualization: Enhanced with syntax highlighting, cross-references, intraline diffing, whitespace ignoring, and move detection. Analysis Results: Displays results from static analyzers, highlighting important findings and offering fix suggestions. These include “presubmits,” which are automated tests that are run in Critique that enforce project-specific invariants. Critique integrates feedback channels for analysis writers. Reviewers have the option to click “Please fix” on an analysis generated comment as a signal that the author should fix the issue. Either authors or reviewers can click “Not useful” in order to flag an analysis result that is not helpful in the review process. (Source) Stage 2: Request Review When a pull request is ready to be reviewed, the code author adds reviewers and sends it to them officially for review. When a PR/CL is sent in for review, “presubmits” are run if they haven’t already on the current snapshot of code. This means that everyone involved in the review knows whether or not the code breaks anything. From SWE Book Code reviews can also be anonymized, where the code author can be kept anonymous from the reviewer. However, Google didn’t find much of an useful difference between anonymous code reviews and “real” code reviews.3 Using research to make code review more equitable Stages 3 and 4: Understanding and Commenting on a Change Anyone can comment on a change and there are features to track review progress and resolve comments. Unresolved comments represent action items for the change author to definitely address. These can be marked as “resolved” by the code author themselves when they reply to the comment. Resolved comments include optional or informational comments that may not require any action by a change author There’s a dashboard for review statuses and an “attention set” which lets people involved in a certain code review who is the current person being waited upon. The attention set is commonly a highly-regarded feature by Google engineers. The Critique dashboard, from SWE Book Stage 5: Change Approvals As noted above, for a review to go in, it needs an LGTM from at least one reviewer. It needs 0 unresolved comments, though a code author can mark a comment resolved themselves when they reply. It also needs approvals from owners of the part of the codebase the code is going into, along with a readability approval. As mentioned before, this can all be done by one reviewer. Stage 6: Committing a Change Changes are submitted and committed within Critique itself. Critique is valuable even after changes are submitted. “Google researchers found strong evidence that Critique’s uses extend beyond reviewing code. Change authors use Critique to examine diffs and browse analysis tool results. In some cases, code review is part of the development process of a change: a reviewer may send out an unfinished change in order to decide how to finish the implementation. Moreover, developers also use Critique to examine the history of submitted changes long after those changes have been approved.” Modern Code Review Stats at Google Google conducted a study on code review at the company specifically. I’ve listed some interesting stats from their paper. Change Authoring Frequency: Median: 3 changes per week. 80% of authors make fewer than 7 changes weekly. Review Frequency: Median: 4 changes reviewed per week. 80% of reviewers handle fewer than 10 changes weekly. Time Spent Reviewing Per Week: Average: 3.2 hours per week Median: 2.6 hours per week Initial Feedback Waiting Time: Small changes: Median time under 1 hour. Very large changes: About 5 hours. Overall Review Process Time: Median latency for all code sizes: Under 4 hours. Comparison with Other Companies: AMD: 17.5 hours (median time to approval). Chrome OS: 15.7 hours. Microsoft Projects: 14.7, 19.8, and 18.9 hours. Microsoft (another study): 24 hours. “Previous studies have found that the number of useful comments decreases and the review latency increases as the size of the change increases. Size also influences developers’ perception of the code review process; a survey of Mozilla contributors found that developers feel that size-related factors have the greatest effect on review latency.” (Source) Furthermore, the number of comments received per change decreases with seniority. Source Another stat for you: 100% of Engineer’s Codex readers report higher satisfaction after reading. So subscribe, it’s free :) Subscribe Why is Critique so loved by Googlers? Most Googlers and ex-Googlers are big fans of Critique. Internally, 97% of Google software engineers are satisfied with Critique.4 I asked 7 Googlers about why they prefer Critique over tools they may have used in the past, like GitHub. They noted: Static analysis: Google has a full-featured suite of static analysis tools that provide actionable feedback on code automatically. This saves both code authors and reviewers time as reviewers then don’t have to nitpick at obvious items. Focus on only the latest changed files: There’s a focus on just the latest “snapshot” of code. Previous snapshots, commits, and code changes are not really a focus, allowing for a cleaner user interface. A familiar, side-by-side diffing interface: It shows \"diff from the last review\" by default. ML-powered suggestions: Google’s new ML-powered suggestions speed up code review immensely. Tight integration with other Google tooling: Critique is integrated extremely well with Google’s IDE and other internal tools, like their bug tracker. When everything is connected together, productivity is better. This includes easy linking of code, comments, and tickets. “Action set” tracking: This lets people know who is supposed to be taking the next action. Satisfying gamification: While Critique isn’t built to be gamified, Googlers reported how they enjoyed it when Critique “went green,” which meant a PR was ready to submit (all tests passed, reviewers LGTM-ed and approved). A Reddit comment lists more: A great quote on static analysis: A qualitative study of 88 Mozilla developers found that static analysis integration was the most commonly-requested feature for code review. Automated analyses allow reviewers to focus on the understandability and maintainability of changes, instead of getting distracted by trivial comments (e.g., about formatting). Thoughts and Takeaways While many of these features are available in other tools today, I believe it is the tight integration and extreme “personalization” of the tooling towards a Google-specific workflow and codebase that makes it so loved. At the same time, that means it’s not realistic for every company to replicate Critique and related tools exactly. For example, some of their tooling seems specific to challenges created by their monorepo structure. While Critique itself will never be open-sourced, Gerrit is a similar tool to Critique. It’s an open-source code review tool also created and maintained by Google. However, I think Google does put a lot of effort and thought into developer productivity. They publish their research freely and there are useful takeaways from their work. Thanks for reading Engineer’s Codex! If you enjoyed this post, please consider joining 10,000+ others in subscribing below. Subscribe 1 Modern Code Review: A Case Study at Google 2 Modern Code Review: A Case Study at Google 3 https://research.google/pubs/pub50130/ 4 Modern Code Review: A Case Study at Google 43 Share this post How Google takes the pain out of code reviews, with 97% dev satisfaction engineercodex.substack.com Copy link Facebook Email Note Other 6 Share Previous",
    "commentLink": "https://news.ycombinator.com/item?id=38518473",
    "commentBody": "A study of Google&#x27;s code review tooling (Critique)Hacker NewspastloginA study of Google&#x27;s code review tooling (Critique) (engineercodex.substack.com) 274 points by vinnyglennon 18 hours ago| hidepastfavorite274 comments mstachowiak 13 hours agoShameless plug - I&#x27;m one of the creators of GitContext (https:&#x2F;&#x2F;gitcontext.com), a code review tool which has drawn much inspiration from Critique and others, and would love feedback from anyone who&#x27;s interested in kicking the tires. We just launched in private alpha.We&#x27;re putting a maniacal focus into the user experience of code reviews, which we feel is overlooked by most tools. Many of the features of Critique that developers enjoy have been included in our first release... - A focus on only the latest changes - A familiar, side-by-side diffing interface - show &#x27;diff from the last review&#x27; by default - Tight integration with other tooling - &#x27;Action set&#x27; tracking - we allow you to pinpoint and assign line-level issues to relevant team members and track who&#x27;s turn it is to act - Satisfying gamification - plenty of buttons that go green and even some fun visual rewards for mergingAdditionally, we&#x27;ve layered in... - A beautiful, modern UX that provides light or dark mode - Comments that never become outdated and reposition&#x2F;evolve with the review - Smart version tracking that handles rebases, merges, and force-pushes gracefully - Progress tracking that allows you to see what each participant has left to complete down to the file revision level. - A real focus on trying to get turn tracking rightWe&#x27;re just getting started and have a ton of ideas we can&#x27;t wait to layer on. If anyone is up for giving it a try, we&#x27;re actively seeking feedback. If you mention &#x27;Hacker News&#x27; in the waitlist form we&#x27;ll let you in right away. reply spartanatreyu 9 hours agoparentSomething is going horribly wrong on this page.Putting an svg filter over the video element is making the page render 1fps a second on Firefox MacOS.I legitimately thought you uploaded a massive gif as your feature asset instead of a video.If the effect is always on the video, you may want to just bake it into the video.Otherwise, you might want to recreate the filter without using SVGs to do it. reply mplanchard 8 hours agorootparentI have the same problem on Firefox on Linux. It is also extremely heavy on Firefox for iOS, causes the phone to heat up. reply mstachowiak 8 hours agorootparentprevThanks for highlighting, we&#x27;re investigating and should have a fix shortly. reply stavros 9 hours agoparentprevI&#x27;ll say what I said downthread to someone who made something similar: This costs more than twice as much as GitHub, does it provide twice the value? reply randall 9 hours agorootparentGitHub&#x27;s code review is pretty mediocre imo... just left Meta and I miss phabricator. I&#x27;m interested to see new stuff, hope I can get off the waitlist! reply stavros 9 hours agorootparentI definitely agree there, I just don&#x27;t know if a tool that adds a feature is worth twice as much as the tool that the feature is being added to. reply mstachowiak 8 hours agorootparentprevWe agree! Thanks for adding yourself to the waitlist, I&#x27;ll make sure you&#x27;re granted access reply selcuka 9 hours agorootparentprev> This costs more than twice as much as GitHub, does it provide twice the value?This is not always the right question to ask. One can argue that both products are too cheap with respect to the value they offer, so the relative value between the two is irrelevant.In other words, if you can afford $X and $2X without even thinking, and if you think even $10X would be a fair value for either, it doesn&#x27;t matter if the $2X product offers only 20% more value. You would simply want to get the best, even if it&#x27;s a diminishing return. I believe $9&#x2F;month&#x2F;developer can be classified in this category if you are actually doing code reviews. reply mstachowiak 8 hours agorootparentprevFair question. We&#x27;re aiming to provide enough value for the price we&#x27;ll ultimate target. We aren&#x27;t charging yet, but wanted to provide people with some of our rough thoughts on pricing since it&#x27;s a common question. For now, it&#x27;s free for folks who want to kick the tires. reply stavros 8 hours agorootparentI&#x27;ll probably try it, but there&#x27;s no way I can get our finance department to pay $900&#x2F;mo for something we aren&#x27;t sure if we&#x27;re going to use. Maybe pricing it as \"Free for the first five users, $9&#x2F;mo&#x2F;user afterwards\" would be much better aligned with the customers&#x27; incentives. reply mstachowiak 6 hours agorootparentAgreed, that&#x27;s a tough pill to swallow. We envisioned trial period to let people make up there mind, but free for the first few users is another route. We&#x27;ll noodle it when we loop back to pricing. Appreciate the feedback, it&#x27;s helpful. reply mplanchard 9 hours agoparentprevIs this a desktop app? If so, is it cross-platform? I couldn’t find this info anywhere on your site. reply mstachowiak 9 hours agorootparentSorry for the confusion. It&#x27;s currently only offered as a web application and only works with GitHub. We are working to expand beyond these limitations based on customer needs &#x2F; interest. I assume your interest is in a desktop application? reply mplanchard 9 hours agorootparentI was just wondering! I&#x27;m on Linux, so I wasn&#x27;t sure on reading the web page whether it was something I&#x27;d be able to run, and the screenshots looked more desktop-app than web-app.We use GitLab at work, so I wouldn&#x27;t be able to use it there, but I use GitHub and sourcehut for some personal and open source stuff. Code review is one of the few things I don&#x27;t do in emacs, so there remains room for other tools :) reply mike_hearn 17 minutes agorootparentOne thing you could try is using a JetBrains IDE. They can do side-by-side diffs, static analysis in the diff view, you can edit directly from the diff viewer and of course you get full navigation and comprehension tools. When I left Google I spent some time trying to use GitHub&#x27;s code review tools, but they are extremely basic. In recent years I found that with a custom git workflow I could use the IDE as a code review tool and it worked much better than any web based thing.The trick is to use git commits as the review comments. As in, you actually add &#x2F;&#x2F; FIXME comments inline on someone else&#x27;s branch. They then add another commit on top to remove them. Once you&#x27;re done, you can either squash and merge or just merge. This is nice because it avoids \"nit\" comments. If you dislike a name someone picked, you just go change it directly yourself and avoid a round-trip, so it reduces exhaustion and grants a notion of ownership to the reviewer.If you need discussion that isn&#x27;t going to result in code changes (about design for instance) you do it on the relevant ticket. This also has the advantage that managers who stay away from code review tools still feel like they understand progress.It helps to use a specific way of working with git to do this, and to have it integrated into your other tools. I use gitolite combined with YouTrack and TeamCity to implement this workflow, along with a kernel-like ownership tree, but it works well enough at least in a small team (I never got to try it in a big team). replyyegle 15 hours agoprevI don&#x27;t see it mentioned, but there&#x27;s a recent addition that greatly improved my turnaround time to review incoming CLs: A prompt will show up in the corner about the next pending CL that you can approve, when you give LGTM to the CL that you are reviewing.It&#x27;s kind of like those \"Customers who bought this also bought\" prompts on e-commerce websites. Only here it slightly nudges you to have a \"CL review streak\" and clean up your review queue. reply dgellow 11 hours agoparentI never thought about this but it’s a fantastic idea. Would love to have something like this for GitHub. reply dontreact 17 hours agoprevI generally like the tool.When your code review tool is really nice one unexpected negative is that it can create a culture of nitpicking. Sometimes it’s not worth arguing over small details like variable naming but the tool makes it really easy for things to head in that direction.Sometimes variable naming isn’t a small detail. But sometimes it is and it’s a waste of everyone’s time to argue about it. reply ayberk 14 hours agoparentI don&#x27;t know if it&#x27;s the tool honestly. I&#x27;ve recently switched teams and I&#x27;m in the process of getting java readability. The whole experience so far has been much worse than getting my C++ readability. I even get \"nit\" comments on the code I haven&#x27;t changed. I have had multiple comments where reviewer basically \"preferred\" one style over another. It&#x27;s been still mostly helpful, but I&#x27;ve had my share of frustration.C++ readability was a much, much better experience. All the comments were about actually making the code better, eg, \"use THIS_MACRO() instead of THAT_MACRO(), because go&#x2F;...\".I guess I think it&#x27;s much more about the reviewer, and based on my anecdotal experience, the language :) reply tunesmith 12 hours agorootparentGetting reviews from multiple people that disagree on style is definitely an org problem that sucks to be in the middle of.However, I&#x27;d say that getting nit comments on code that surrounds your changes, but that you didn&#x27;t change, is still fair game. It&#x27;s part of the leave your campsite cleaner than you found it. It depends on the culture though - if it&#x27;s suggested in the manner of \"since you&#x27;re here, here&#x27;s an opportunity for how to improve this area of the code\", that&#x27;s better then acting like you made a mistake in failing to change it. reply compiler-guy 9 hours agorootparentThis can add cost and latency to the change author and distracts them from the project at hand. And because it costs the reviewer basically nothing to say, \"While you are in there....\", it slows the original author&#x27;s work.Even worse, if there are enough of these minor changes, some other reviewer may take issue with their \"small, focused changes\" preference, and ask you to split it.This is why Google has the \"It doesn&#x27;t have to be perfect; it just needs to be better\" standard: So reviewers can&#x27;t impose undue costs on authors. reply mgraczyk 5 hours agorootparentprevI fought with the review admins about this crap a lot when I was at Google. When you&#x27;re working toward readability, code that isn&#x27;t related to change is not in scope. The reviewer can comment on it but you&#x27;re not expected to change it. That is in the official \"rules\". reply xKingfisher 11 hours agorootparentprevI try to avoid nits totally unrelated to the changes at hand, since on a subconscious level they may discourage people from even wanting to touch older&#x2F;less loved files at all.The critical exception being avoiding issues due to path dependence.E.g while a change is \"correct\" is doing X poorly because of surrounding issue Y. So we should fix Y now instead of building atop it. reply eichin 11 hours agorootparentprevSomething I find helps with this in particular is only allowing style comments with citations to an actual style guide item. (I talk about domain-specific style guides as \"crystallized arguments\" - we agreed on this and wrote it down, not because it&#x27;s necessarily right (though it probably is) but that we really wanted to stop wasting time arguing about these particular things.) reply TheBlight 17 hours agoparentprevExcessive subjective feedback can be soul-crushing. reply MarkLowenstein 17 hours agorootparentAnything subjective that doesn&#x27;t fix an identifiable execution problem must be explicitly labeled as a suggestion. You don&#x27;t get first choice over the code because you are asked to be the reviewer. You are there to (1) catch mistakes and (2) teach the other coder if they appear to not know something useful that you do know. If you have a preference about a simple stylistic matter that is not covered by your style guidelines, either put it in the guidelines, or hold your tongue. reply everforward 12 hours agorootparentThe only exception that I would tag on to that is documentation. \"I can&#x27;t understand this documentation&#x2F;comment\" deserves more attention than I think most places give it.It doesn&#x27;t directly relate to execution today, but it might later on when someone misunderstands the docs or just gives up on them and tries to hack it together blind. reply zeroCalories 14 hours agorootparentprevIMO you should never provide feedback that can be implemented as an automated check. If you don&#x27;t like deeply nested control flow, then you should catch that with static analysis. If you need code coverage, you should require it for merging. Implement your check and provide a new PR to fix your nitpicks, or shut up. The goal is to put 100% of the focus on correctness. reply tunesmith 12 hours agorootparentThis seems precisely backward to me. Programmers are humans, not input&#x2F;output machines, and there&#x27;s definitely a role for encouraging a certain standard of judgment that doesn&#x27;t require tooling to enforce. To argue otherwise seems akin to arguing that any bad behavior is fine that isn&#x27;t explicitly banned in paragraph 5 subsection D. Tooling is expensive, especially for smaller teams, and should be saved for phenomena that hit the cost&#x2F;benefit calculations squarely. reply zeroCalories 8 hours agorootparentI agree that sometimes the cost&#x2F;benefit analysis doesn&#x27;t make sense for adding tools, but I would argue that in many of those cases the benefit of your nitpicking isn&#x27;t worth it either, so just don&#x27;t say anything so that we can focus on the important parts of the code. Of course people will sometimes do some really silly stuff that couldn&#x27;t realistically be checked, so I would hope that less important stuff gets put aside so we can focus on the real issues. reply er4hn 10 hours agorootparentprevOn that note, what good code coverage tools are out there? GitHub and Gerrit, as well as (egads) ReviewBoard don&#x27;t seem to have native support for this in the review. It&#x27;s unfortunate since it seems super useful to have be up front and visible. reply zeroCalories 8 hours agorootparentHave not tried a ton of tools, but Codecov seems to work fine for my projects on Github. reply merb 14 hours agorootparentprevSadly typos in variable names are not checkable that easy reply kridsdale1 10 hours agorootparentWe (at google) do have this checker. reply zeroCalories 13 hours agorootparentprevDoesn&#x27;t seem hard to me? You could easily run a spell checker on identifiers and comments. It will produce a lot of false-positives, but that can be solved by making the changes optional or using an allow list. reply bluGill 13 hours agorootparentThen please write one.Note that the important part is a good way to mark all those false positives that is simple and doesn&#x27;t go to far. Just because I want a bad spelling in one place doesn&#x27;t mean I want it everywhere. As a result I&#x27;m going to predict that your tool either results in too much boilerplate needed to suppress all the false positives, or your tool lets pass a lot of things that shouldn&#x27;t. But that might be just that I don&#x27;t have good ideas: if you create a good tool for this I&#x27;m willing to be proven wrong. reply dgellow 11 hours agorootparentIt’s called cspell https:&#x2F;&#x2F;cspell.org&#x2F; reply johannes1234321 10 hours agorootparentDoes that understand that when talking about HTTP headers I talk about \"referer\" but when talking about JavaScript I have to use \"referrer\"? - What is wrong in one place can be different elsewhere. Terminology, spelling, accepted abbreviations depend very much on context. And sometimes even a wrong spelling is right as it&#x27;s in some standard ... reply comex 8 hours agorootparent> Does that understand that when talking about HTTP headers I talk about \"referer\" but when talking about JavaScript I have to use \"referrer\"?I bet GPT-4 understands that.(Though I have no personal experience using it for code review.) replyacscott 17 hours agorootparentprevAgreed; after > 20 years of coding successfully, got hit by a storm of subjective feedback; it totally ruined any joy in development reply TheBlight 17 hours agorootparentIt didn&#x27;t used to be this way. A code review used to mostly function as a quick sanity check. Now it&#x27;s basically code by committee. reply wubrr 17 hours agorootparentprevThe fun thing to do in these situations is to add yourself as reviewer to all PRs by the person giving such feedback and return the favor. They learn pretty fast. reply runlevel1 13 hours agorootparentThat seems like it risks creating conflict out of what&#x27;s often just a misunderstanding.Assuming it&#x27;s a corporate environment (it&#x27;s fuzzier in the open source bazaar):If it&#x27;s the first time or I don&#x27;t really know the reviewer, I ask them to hop on a call to discuss (usually to walk me through) their feedback and I go in with an open mind. That gives me the opportunity to find out if I&#x27;m missing some context, can see how reasonable they are, and can get clarification of what they actually care about versus FYIs&#x2F;suggestions. As they go, if it isn&#x27;t clear, I just ask them if something is a soft opinion or hard opinion.If everything is a hard opinion and they don&#x27;t seem reasonable, I reach out to someone else (ideally a team lead or peer on their team) over a private channel for a 2nd opinion. If they also think it&#x27;s unimportant stuff, I ask them to add their own comments to the PR. Give it a reasonable amount of time and they&#x27;ll either have reached a consensus or you can roll the side you agree with.If it&#x27;s an issue again later and they seem reasonable, respectfully push back. If they seem unreasonable, skip right to DMing their lead for a 2nd opinion.If it keeps being in issue, then some frank conversations need to happen. Something I&#x27;ve noticed about folks who steadfastly focus on minor stylistic nits in CRs is they (1) tend to be cargo culting them without understanding the why behind them and (2) they&#x27;re usually missing the forest (actual bugs in logic) for the trees.Most people are pretty reasonable when they don&#x27;t feel like they&#x27;re under attack, so in my experience it&#x27;s usually possible to resolve these things without dragging it out. Of course, if you&#x27;re at a company with a lot of disfunction, well... I can understand why what I&#x27;ve written above won&#x27;t work. reply wubrr 11 hours agorootparentIf it&#x27;s the first time - yeah, reach out to the person and talk to them.But if the person is consistently leaving such comments under the guise of mentorship, &#x27;raising the bar&#x27;, or some other bullshit which boils down to them attempting to demonstrate their own seniority at the expense of other people&#x27;s time and stress - then showing them how it feels is a great approach.Bringing in other people and managers is not very effective I&#x27;ve found - it takes additional time, other people have their own stuff to focus on, and managers often don&#x27;t have the technical expertise or confidence to push back against subjective comments which claim to be &#x27;raising the bar&#x27; or whatever. It also doesn&#x27;t look great when you have to bring other people in to help you address PR comments.And, of course, you do this without ostensibly creating any conflict - if they complain simply respond along the lines of &#x27;I totally love the care and attention to detail you bring when reviewing my PRs, I&#x27;ve learned from you and thought it would be appropriate to keep the same high standards and not lower the bar... etc&#x27;.> As they go, if it isn&#x27;t clear, I just ask them if something is a soft opinion or hard opinion.Nah, if they don&#x27;t explicitly state that&#x27;s a soft opinion via &#x27;nit&#x27;, approving with comment or some other means, they are disrespecting the person who&#x27;s PR they are reviewing. I shouldn&#x27;t have to chase them down to see how strong their opinions are.> If it keeps being in issue, then some frank conversations need to happen. Something I&#x27;ve noticed about folks who steadfastly focus on minor stylistic nits in CRs is they (1) tend to be cargo culting them without understanding the why behind them and (2) they&#x27;re usually missing the forest (actual bugs in logic) for the trees.What do you do if the comments are purely subjective and all backed up by internal&#x2F;corporate dogmaspeak? &#x27;Raising the bar&#x27; ... &#x27;keeping the standards high&#x27; ... &#x27;mentoring&#x27;, etc. , or open ended comments asking to explain how stuff works, and whether &#x27;this approach is the best&#x27;? There is no shortage of rhetorical bullshit that can be used to justify subjective PR comments.> Most people are pretty reasonable when they don&#x27;t feel like they&#x27;re under attack, so in my experience it&#x27;s usually possible to resolve these things without dragging it out.The above will generally not work in a company that emphasizes PR comment count as a good metric for promotions&#x2F;performance, and has a lot of internal rhetorical dogma. You WILL get people who leave these types of comments because they view it as a way of promoting their career, these people often cannot be reasoned with logically because they aren&#x27;t actually all that smart, and they view any pushback against their comments as an attack against them.Other people&#x27;s feedback against the bullshit comments definitely help, but can look bad if you keep reaching out to other people to help address PR comments - I made sure to go through other people&#x27;s PRs, on my own initiative, and refute bullshit comments when I realized how some people were behaving.And yeah it totally depends on the company&#x2F;team. reply layer8 15 hours agorootparentprevUnlike excessive objective feedback? reply egl2021 12 hours agoparentprevDifferent languages had different pools of readability reviewers, so the expectations varied, but readability reviews were generally constructive and helpful. I was thrilled to have Ian Taylor review my go code.The non-readability reviewers were usually on your team, so there was social pressure in both directions. You wanted to learn and conform to the team&#x27;s norms, and the reviewer couldn&#x27;t be a total jerk about their comments. Everyone was generally on their best behavior. reply chii 8 hours agoparentprev> Sometimes it’s not worth arguing over small details like variable namingbut naming is quite important. May be it&#x27;s not that this is a nitpick, but that previous review tools prevent the fruitful discussion of names. reply seanmcdirmid 14 hours agoparentprevyou can mark your comment (in text) as a NIT and then unmark \"Action required.\" reply dontreact 13 hours agorootparentYeah… but people sometimes dont do this reply Tyr42 6 hours agoparentprevAt least with the AI assist it&#x27;s easy to one click accept the name change and be done with it. reply jeffbee 17 hours agoparentprevWriting readable code is not \"nitpicking\". It is common that an author doesn&#x27;t see why their parameter name or function name is misleading but their reviewer, who comes to the change without as many preconceptions, sees it right away. reply bheadmaster 17 hours agorootparent\"Readable\" and \"misleading\" are subjective, and depend on the person&#x27;s \"preconceptions\".I disagree that the reviewer comes \"without as many preconceptions\" - they just come with different preconceptions, the ones they&#x27;re used to. Programming language is a language like any other, and each person has their own style of writing it, and they&#x27;d prefer the rest of the world to use their own style because it&#x27;s \"more readable\". reply tikhonj 17 hours agorootparentAre you saying there is no such thing as clearer or less clear writing in natural languages or programming languages? It&#x27;s 100% subjective and depends entirely on the reader? reply bheadmaster 16 hours agorootparentOf course, it&#x27;s not 100% subjective - rarely anything in the world is 100% anything.But I think that most people consider their personal preferences to be better and more readable just because they&#x27;re used to them, so I tend to take the opposite attitude as the starting point. There were more than a few situations where I&#x27;ve had a coworker tell me \"just read the code, it&#x27;s very readable\", only to spend the next two weeks just trying to figure out how it works. Sure, once you figure out how it works and it \"clicks\", it&#x27;s no longer (that) unreadable, but the fact that I have to spend so much time reading the codebase in the first place made me convinced that personal familiarity is a great part of what \"readable\" means. reply TeMPOraL 9 hours agorootparentprevSome thing are objectively bad. But a lot is up to, if not subjective preferences, then at least situational ones. With modern programming languages, we&#x27;re operating close to Pareto frontier in terms of expressiveness - there&#x27;s just no way to make a piece of plaintext code more readable for some readers, without sacrificing readability for other readers with different goals.Things like \"lots of small functions vs. few large functions\", or \"exceptions vs. sum type return value\", are such cases - they seem subjective, but they&#x27;re less about preferences, and more about the kind of work a given reader is doing. Either choice is better than the other for some kind of work. We can&#x27;t improve on this until we move past working directly on plaintext, single-source-of-truth codebases.Plaintext is fine. Single source of truth is obviously needed. The problem is with insistence on only ever working directly on it, which leads to a futile attempt at inventing styles and languages that would express every cross-cutting concern and needs of every job in a clear and readable fashion. It&#x27;s just not possible.(And yes, I believe the bleeding edge of programming language development is effectively just spinning the wheels now - adding increasingly complex abstract math to programming languages isn&#x27;t going to help square the circle.) reply KptMarchewa 15 hours agorootparentprevI believe overtly verbose, enterprise Java names make code _less_ clear in modern times with proper development tools.Entire group of people has to think otherwise due to proliferation of that style. reply jeffbee 17 hours agorootparentprevCan&#x27;t agree here. Often an author is writing code and they start with a tentative function, parameter, variable, or type name, then as the change progresses the semantics of the thing changed but the name stayed the same. Authors won&#x27;t always see this but reviewers are more likely to notice it. reply faster 17 hours agorootparentprevI struggle with this. I work with devs who think that a function with 3 side effects is fine, and suggestions that it would be more maintainable if it did one thing (and even more offensive, that the function name should be a clue to what the function does) are often met with hostility. In the end they&#x27;re angry and resistant and I&#x27;m frustrated. Sometimes I just approve it, write a technical debt ticket, and move on. reply runlevel1 13 hours agorootparentAnger and frustration is obviously not an appropriate response to constructive feedback offered in earnest, but do you have any insight into why they respond that way? Like naïveté as to why it&#x27;s usually a bad idea to do that, them misinterpreting your intent, or redirected aggression from another source of frustration (like workload, deadlines, etc.)? reply seanmcdirmid 14 hours agorootparentprevIf it truly a matter of readability, then it really isn&#x27;t a nitpick. If it is a matter of \"I think doing X is slightly better than doing Y, and if you start doing X rather than Y, that would improve things somewhat\", then it is a nit.To put it this way, you should use Kotlin vals with get methods with getters rather than fun getXXX() functions, but this is controversial, so I always suggest it as a nit (Nit: maybe use val xxx get() = ... rather than fun getXXX() = ...). reply dontreact 17 hours agorootparentprevIm not saying it’s always nitpicking. I’m saying that sometimes it is. reply shadowgovt 17 hours agoparentprevIt can be tricky to find a balance point here. At Google scale (in time-of-maintenance, not space... Code can last for years and will be worked on by multiple engineers disconnected from the original project), the hard problem of naming things becomes real.I find that it&#x27;s useful to keep context. Even though one can never predict with certainty, sometimes you can be real confident that some code is prototype that will be thrown away in six months. And there&#x27;s a big difference between the code that makes up an API layer and the code that implements a feature constrained to one module. reply arp242 17 hours agorootparentAt not-Google-scale code also often lasts for years; perhaps even more so since there&#x27;s typically a lot fewer people maintaining it.I think the key thing is to ask yourself \"is this really objectively better yes&#x2F;no?\" before commenting. Not that you can never comment if the answer to that is \"no\", but quite a lot of the time when the answer is \"no\" it doesn&#x27;t really matter and it&#x27;s just \"I would have done it slightly different, but both are fine\". reply shadowgovt 17 hours agorootparentGood point. Making renames a suggestion, not gating (unless it contradicts the name in some design doc somewhere that another team is relying on not to move) may be the balance point there. reply arp242 17 hours agorootparentBut \"another team is relying on not to move\" is an objective point, right?Things like \"I find this code very hard to follow, and I think it could be made easier\" is also objective, and even \"I don&#x27;t understand what this variable name means, and I think it could be clearer\".I once names a function mkdir(). This created a directory tree. In the review it was called \"obscure\" so it became createDir(). Then someone pointed out that \"dir\" was a needless abbreviation so it became createDirectory(). Then yet someone else pointed out that it&#x27;s actually recursive, and a discussion on the merits of createDirectoryRecursively() vs. createRecursiveDirectory() was inflicted on everyone. In-between there was a side-quest about directory vs. folder. Just fucking stick a fork in my eye already.Was anything of any objective value gained? I&#x27;m having a hard time seeing it. Well, it makes for a slightly amusing anecdote so there&#x27;s that. reply ryandrake 16 hours agorootparentI&#x27;d wonder what the rest of that API surface looked like. If the rest of the functions were longDescriptiveCamelCase() and then you tried to slip in mkdir(), then I&#x27;d say yes, \"stylistic consistency\" was gained during that unnecessarily difficult back-and-forth.If the other functions were chdir(), remove(), rmdir() and so on, and somehow the reviewers picked your code change as the time to change it all, then yea, what a waste. reply arp242 15 hours agorootparentIt was a mix of short and long and there wasn&#x27;t really much \"style\". The company had taken over the maintainership from someone else at some point (before I joined) and it was all fairly inconsistent. I don&#x27;t really mind the inconsistencies as such, it&#x27;s just the argueing over nothing that I mind.This kind of stuff was typical. At some point there was a lengthy discussion which prevented rolling out a rather important hotfix over: while (true) { if (someCond()) break; if (otherCond()) break; [..] }It wasn&#x27;t even about whether someCond() and otherCond() should be in that while(..) condition, it was allegedly \"dangerous\" because it \"could loop infinitely\". Well, ehh, that&#x27;s the case with any lop innit? That&#x27;s kind of how they work? There was a bunch of instances of code like this, \"but it&#x27;s still dangerous\". Hmkay...Oh, and then there was the great \"evil incident\". I had rewritten much of the frontend to this newfangled thing called \"jQuery\" that was all the rage. That was all fine and worked pretty well, but suddenly there was a bug hubhub about the jslint comment; the keyword to allow eval() was \"evil\" (one of those not-too-funny Crockford jokes), so at the top of &#x2F;static&#x2F;js&#x2F;app.minified.js?v=12311 in prodiction there was something like: &#x2F;*! jslint: keyword1 evil keyword2 *&#x2F; &#x2F;*! MIT license blah blah *&#x2F; minified_js()...And people were up in arms and there was a big panic deploy during lunchtime for this \"because customers might see this, and it&#x27;s highly unprofessional, and it&#x27;s a big problem we need to fix ASAP\" etc. etc. etc. This was in the Netherlands with regular people, not some highly conservative part of the world. It was downright surreal and bizarre.What I&#x27;m trying to say is that these people were rather obsessed with minor details to a point I&#x27;ve never seen before or since. Hell, there was a Company Blessed IDE™ that you had to use. Nothing else allowed. It was a complete piece of shit (IMHO) and after a few weeks I just used Vim. It worked. I got stuff done. No one was bothered by it. Still got comments I shouldn&#x27;t be doing that...While I didn&#x27;t formulate \"is this really objectively better yes&#x2F;no?\" clearly at that time, I&#x27;m sure it&#x27;s been a pretty big influence. reply IanCal 14 hours agorootparent> it was allegedly \"dangerous\" because it \"could loop infinitely\". Well, ehh, that&#x27;s the case with any lop innit? That&#x27;s kind of how they work?No? You can clearly have loops that exit. Loops that can be infinite should only be so where you really want that to happen in those cases &#x2F; are fine with it. \"Infinitely until the user does X with no timeout\" is a fair one. reply arp242 13 hours agorootparentEvery while&#x2F;for loop is essentially \"keep doing this until I tell you to stop\". You can argue what the best way to \"tell to stop\" is, but that doesn&#x27;t really change the concept. No one could even articulate under which conditions this could happen. Cosmic rays altering memory? That&#x27;s the kind of stuff we&#x27;re talking about here. For a PHP webapp. I don&#x27;t recall the exact specifics but we spent a long time on that stupid loop and no one even had any alternative. Eventually the loop committed.The thing is, if I had written the conditions in the loop body it would have been fine with no comments. People were tripped over the \"while (true)\" and commented on that. That&#x27;s okay, I can just change that, no problem. But the kept analysing and thinking about it to the subatomic detail. That as really the problem: small things tended to escalate to \"a big thing\" even when it was just a small thing. I don&#x27;t know what it was – a kind tunnel vision? I don&#x27;t know.I once carefully suggested to paint a wall in a brighter colour during a HOA meeting. People objected. Fine, not a big deal and just a suggestion, I&#x27;m okay with the grey it was. They kept discussing it. I back-pedalled harder. People started to suggest we need to form a committee. I started to run. They asked if I wanted to join the committee \"as I had brought up the issue\". I overtook Usain Bolt. I heard they had several meetings. They choose the same grey it was before (or something so similar I couldn&#x27;t spot the difference). Not my favourite colour or what I would have chosen, but it&#x27;s fine. reply joshuamorton 13 hours agorootparentI can prove, pretty trivially that for i in range(10):Will halt.Slightly less trivially, you can prove that while true: if x: break else: breakWill halt.But once the if conditions aren&#x27;t exhaustive, it becomes difficult, perhaps impossible, to know that you won&#x27;t end up in a weird unhandled state.Preferring and even insisting upon code that is not only possible, but easy, to reason about is good. Or iow it should be incumbent on you to prove the loop halts, not on the reviewers to prove it doesn&#x27;t. reply arp242 11 hours agorootparentYou can prove that a different construct from a different language can do a different thing because it&#x27;s a different construct from a different language.> it should be incumbent on you to prove the loop haltsThis is a nice one-liner platitude, but also completely unworkable. reply joshuamorton 9 hours agorootparent> You can prove that a different construct from a different language can do a different thing because it&#x27;s a different construct from a different language.This is the same construct, it&#x27;s just using python syntax instead of c&#x2F;c++ syntax. There aren&#x27;t functional differences between the examples.[Edit: To elaborate, your initial example translated to python is while(true): if x: break if y: breakand there is no way to verify that `x || y` is always true. If you can in fact show that it&#x27;s always true, you can probably restructure the code to both convey that invariant (use an exhaustive if&#x2F;else if check) that is better supported by linters and gives you warnings when you miss something.Writing code in a way that makes it more difficult for both humans and machines to divine your intent should be questioned in review! Perhaps it isn&#x27;t possible to verify that (but that&#x27;s also concerning), or perhaps you have some good justification for doing the unusual thing, but then that justification should also go in the code as a comment to give future folks context on why you have a strange and misleading pattern.]> This is a nice one-liner platitude, but also completely unworkable.Perhaps, in some cases (yes, we can&#x27;t always follow NASA&#x27;s coding standards), but ensuring that most of the time invariants are locally verifiable is possible, that&#x27;s what typecheckers are, and it&#x27;s not like Java or Rust are unworkable languages to write code in.Just because we can&#x27;t statically encode \"this loop halts\" as a type, doesn&#x27;t mean that we shouldn&#x27;t make that fact clear and verifiable by a human. And \"it is incumbent on the person writing the code to justify why it needs an exception from \" is exactly what code review is for. It&#x27;s not that hard at all. It&#x27;s how I review code, and how I expect my code to be reviewed. replyshadowgovt 16 hours agorootparentprev> Things like \"I find this code very hard to follow, and I think it could be made easier\" is also objectiveThe \"I\" in that sentence suggests this should be considered subjective. And that&#x27;s I think the cleave-point between gating and non-gating: \"Other people have already agreed on this\" vs. \"In the moment, I, a single code-reviewer, think this name could be improved.\" reply arp242 15 hours agorootparentIt&#x27;s not an exact science and there&#x27;s a grey area of course, but what I have in mind is mostly code that&#x27;s just needlessly confusing in ways I think very few would disagree with. I can&#x27;t really think of a specific non-trivial example at the moment, but just like natural language I do think some code can objectively \"hard to follow\", even if that&#x27;s somewhat vague and not strictly defined.Other factors are if I&#x27;m the primary or one of the primary maintainers, the standing of the other person (also a maintainer or one-time contributor from another team), and things like that. reply shadowgovt 14 hours agorootparentI can&#x27;t speak to everyone&#x27;s experience, but I can say how teams I&#x27;ve been on have handled that sort of thing.When it&#x27;s not explicitly documented in the style guide and it doesn&#x27;t violate some agreed-upon convention (which needs to be gleanable from within the file itself or it&#x27;s not an agreed-upon convention... No \"We know it was always done like that but now we&#x27;re doing this,\" if you want to change it, you do the heavy lifting of putting together the consistency refactor to bloody well change it...), it&#x27;s a suggestion. Non-blocking.But taste does matter, so if an engineer is observed by their peers to be ignoring too many refactor suggestions with no explanation, it becomes an issue with the project lead and that engineer might get put on a shorter leash (in the form of \"These are normally non-blocking... Except for Steve, he wouldn&#x27;t know consistent and terse naming if it bit him on the FaceManagerFactoryService). It required enough human touch to understand what each others&#x27; strengths and weaknesses were, so more expensive in terms of mind-space, but I think it generated better results overall.(And as the one whose code is reviewed: if you have a good reason not to change something and can express it, fine! You&#x27;re a team member too and your opinion on how things should be also matters). reply arp242 14 hours agorootparentI&#x27;m not talking about style, I&#x27;m talking about logic. Some logic is easier to follow than others, and as mentioned this is not exact and somewhat fuzzy, but \"every logic is equal to every other logic\" is obviously nonsense. All other things being equal two \"if\" statements are better than nine \"if\" statements.I don&#x27;t care about style; as far as I&#x27;m concerned it&#x27;s \"do what thou wilt shall be the whole of the style guide\" (well, within some obvious limits of reason). I don&#x27;t even care about consistency all that much. replyyx827ha 17 hours agoprevIf you want something similar, check out Gerrit: https:&#x2F;&#x2F;www.gerritcodereview.com&#x2F; It&#x27;s open source and used by Android and Chrome. reply sparcpile 15 hours agoparentIt looks like Critque is a branch of Gerrit. The user interface is similar. I assume that Critque is Grerrit with a bunch of Google-specific changes.Gerrit itself is an interesting review tool. It uses Git references to manage the review changeset before it is merged into the parent branch.I used it on a project that used Redmine for issue tracking and Gerrit for the git repo and review tool. It took a bit to get used to how to git to push changes to a Gerrit review so we ended up using Git extensions to manage that. reply dvirsky 13 hours agorootparent> It looks like Critque is a branch of GerritIIRC Gerrit is an open source re-implementation from scratch of Critique. reply cmrdporcupine 15 hours agorootparentprevI assume that Critque is Grerrit with a bunch of Google-specific changes.Not even close. I have another comment where I get into some details, but, no, three&#x27;s no overlap beyond the fact that Gerrit pulled some UI and workflow things from Critique (and Mondrian before that, the tool that predated Critique) reply crotchfire 35 minutes agorootparentI dunno. I use gerrit frequently and nothing in this article surprised me. Aside from \"ML-powered woo woo\" I&#x27;ve seen and used everything bragged about in this article.Gerrit is awesome. I will never, ever go back to github. reply jasonlotito 17 hours agoparentprevYeah, it seems like Gerrit with lots of Google-specific stuff. Not surprised. Used Gerrit for 12 years, and loved it. reply nappy-doo 17 hours agorootparentGerrit is pretty crap compared to critique. It has a workflow that works for Android, but critique is really much better. reply k_dumez 12 hours agorootparentWhat do you think Gerrit is missing compared to Critique?Graphite[0] is also similar in that space(code review platform built on GitHub), the CLI could use some work but combined with the web UI it scratches that same itch that Critique did for me[0] https:&#x2F;&#x2F;graphite.dev&#x2F; reply cmrdporcupine 15 hours agorootparentprevThe essential thing is that Gerrit is a swiss army knife review tool for git, whereas Critique is able to be consistent and fluid because it only has to worry about working with the standard workflow in Piper&#x2F;CitC (and now fig I guess)I agree Critique is much nicer, but mostly because it&#x27;s more consistent and doesn&#x27;t have to deal with all the oddities of git. reply crotchfire 31 minutes agorootparentCan you be more specific?Gerrit does in fact impose a particular workflow: each commit is the atomic unit of review.This, BTW, is a beautiful thing. Most of the idiocy of github is trying to have multi-commit pull requests. Then they had to bodge on that \"suggested changes\" nonsense instead of having proper dependency tracking between pull requests.When each commit is the unit of review, you get pull request dependencies and recursive pull requests automatically. Instead of suggesting changes you can simply create a commit with your suggestion which has the reviewed commit as its parent. It&#x27;s so simple yet so much more powerful. replycompiler-guy 17 hours agoprevWorth noting that Google engineers had this level of satisfaction long before the mostly useless AI suggestions came on the scene. Those additions are comparatively recent. reply vinkelhake 16 hours agoparentI find them generally very helpful. In a majority of cases, it&#x27;s able to translate my review comments into the exact delta that I had in mind.Source: me, C++ readability reviewer - this means I review code from lots of different people, all over the codebase. reply andromeduck 14 hours agorootparentIt takes way too long though - it&#x27;s almost always quicker to just do it in cider&#x2F;subl if there&#x27;s more than 1 of them. reply summerlight 14 hours agoparentprevI think the AI-powered suggestions are often useful, around 30~40% accuracy. The number might seem underwhelming. But when I work on code written in unfamiliar language&#x2F;frameworks, this saves lots of my time because it gives some hints on how a possible change looks like and which keyword I need to look up for. reply teaearlgraycold 17 hours agoparentprevMy experience with the AI recommendations was mostly positive as an L4 doing Java reply makerofthings 13 hours agoprevOne thing I like about it is that reviewers can suggest changes and you can accept them inline. Makes it really easy to deal with nits. reply eftychis 13 hours agoparentYou can do that in Github, but for some reason a lot of reviewers are not familiar or bother doing that. Fixing nits that way or giving a suggestion improves turnaround speed greatly and builds a relationship between reviewer and proposer and the final product&#x2F;commit(s). reply yohannparis 12 hours agorootparentYes, I have been \"suggesting\" a lot of one liners, typo, rephrasing, or just simple clean up of code with it. Make it a breeze, it&#x27;s like playing tidy-up without having to branch out or bother much the author. reply froh 11 hours agorootparentI feel stupid. How do I do this? reply mplanchard 9 hours agorootparentWhen writing an inline comment, there’s a button to make a suggestion. It inserts a markdown code fence with the existing code on the line(s), which you can edit. When you submit the comment, it shows up with diff highlighting and can be applied by the author with one click.Essentially the same thing exists in both GitHub and GitLab reply Tempest1981 6 hours agorootparentprevA lot of folks didn&#x27;t know it was there. It&#x27;s just 1 of many icons, and tbh, I&#x27;m not sure when the feature got added. reply bbu 12 hours agorootparentprevIt’s not integrated well into the UI and thus a big hassle to use. Much easier to just checkout the branch and create a commit (or just write a comment…) reply throwawaaarrgh 17 hours agoprev> Developers need to make progress; overly difficult reviews can discourage future improvements.This, to me, is the most important aspect of code review: get out of the way.If you are putting in nit picks, asking for changes that aren&#x27;t related to a bug or bad architecture choice, etc, then get out of the way. If you are holding up the approval because you want someone to rewrite the code the way you would have written it, get out of the way. If you&#x27;re saying anything that isn&#x27;t directly related to a necessary change to the code, get out of the way.When I review, if there&#x27;s no bugs, and nothing that&#x27;s going to affect performance, and it passes tests and works, I approve it. If somebody wants mentorship I&#x27;ll add my thoughts in a comment along with my approval.I don&#x27;t have this kind of authority, but I would also recommend just not requiring a PR for certain changes. Create a guideline so that changes which a person couldn&#x27;t improve by reviewing or that have no impact on the working product are just merged. More merging, less useless blockage. reply cgearhart 17 hours agoparentThis kind of greedy optimization approach is fine if all you’re just trying to maximize velocity, but it starts showing cracks on a long enough timeline in sufficiently large or complex projects. Speed without alignment on direction leads to ugly, tangled messes.As with most quality issues, the key is to try and surface quality problems as early as possible. Finding a bug in prod is worse than finding it in PR is worse than finding it with tests is worse than finding it at your desk is worse than finding it in the design. Engineering teams should choose an operating point in their processes that balances quality and velocity to match the business needs of their project. Most often I’ve seen slow PRs caused by stuffing too much of the responsibility for software quality into that single step.In my team we prefix nitpicky comments explicitly with “nit:” and it’s up to the author to decide what to do with it. We minimize trivial nits by enforcing a style checker. We also discuss in retro if the PRs are too big to review effectively or if PRs are turning up comments on solution architecture, because at that point it’s too late—the author likely should’ve separately discussed the architecture before it got to a PR. reply zdragnar 16 hours agorootparent> In my team we prefix nitpicky comments explicitly with “nit:” and it’s up to the author to decide what to do with itThis is different from what the OP is talking about.I&#x27;ve worked at places where staff engineers seem to have been rated on number of comments left on PRs... they were typically somewhere between nit picky and useless, with the occasional person directly contradicting feedback they&#x27;d given in a previous PR.Oh, and you had to address every one of them before getting approval. reply Reubend 15 hours agorootparent> I&#x27;ve worked at places where staff engineers seem to have been rated on number of comments left on PRs> Oh, and you had to address every one of them before getting approval.This just sounds horrible. reply d0mine 15 hours agorootparentprev> rated on the number of commentsIt sounds idiotic.It is unrelated to the question whether short-term (one PR) only reviews are preferable over reviews that recognize the reality that it is not the last PR ever and therefore more long-term view may be useful. reply hot_gril 15 hours agorootparentprevLong-term project health rests on bigger things like API design, database choices, or service layout. reply uoaei 15 hours agorootparentHopefully these are in-scope when it comes to accepting or rejecting PRs and are not just considered incidental to whatever the stated purpose of the PR is. What you listed appears to be more fundamental system design concerns so hopefully they are candidates for further review. reply hot_gril 15 hours agorootparentIt&#x27;s usually out of scope by the time you&#x27;re writing a CL, which is fine because there&#x27;s design review. The issue is about priorities. Nitpicky code review can be very expensive, and I&#x27;m not convinced it brings noticeable benefit.I&#x27;ve seen team-quarters wasted due to bad large-scale decisions. Sometimes the truth doesn&#x27;t come out until the the real thing is in production, and all these extra burdens make it harder to change course. I think people are starting to get this because the amount of code nitpicking or caring about small things in general has gone way down. reply throwawaaarrgh 13 hours agorootparentprev> it starts showing cracks on a long enough timeline in sufficiently large or complex projectsShow me a project which this doesn&#x27;t happen to on a long timeline and I&#x27;ll show you a project with no users and perfect programmers.Entropy is unavoidable. It will eventually degrade despite your best efforts and in the meantime you aren&#x27;t benefiting from a working feature. We should try to delay software entropy as much as practical, but not at the expense of shipping.Basically there is a balance to strike. I don&#x27;t have a formula for it, but I do know that merging often ends up being more valuable than merging later just to ensure clean code. Working features are more valuable than a mess. A mess sucks, so we should try to avoid it, but the world runs on messes, not clean code. reply danielovichdk 12 hours agorootparentRead the Redis code base please. reply wubrr 17 hours agorootparentprevGenerally agree, but at some companies&#x2F;teams the ratio of &#x27;nitpicky subjective feedback&#x27; to &#x27;you have a bug here feedback&#x27; is like 95:5 while at others it&#x27;s 5:95. The latter function much better. reply poolopolopolo 16 hours agorootparentprevMRs are bad place to align things at scale. reply creshal 15 hours agorootparentThey should be a last resort for that sort of alignment, but it&#x27;s still important to pull that last resort if it&#x27;s necessary, so you don&#x27;t end up like Cloudflare and let your own standards slip so badly that you end up with a 100% preventable multi-day outage. reply sanderjd 17 hours agoparentprevI appreciate suggestions that are not \"directly related to a necessary change to the code\", and I believe my coworkers appreciate mine. It is very useful to say \"did you consider doing it xyz way &#x2F; using xyz library?\" while also mashing the \"approve\" button. If they say \"yep and I decided not to because of xyz\" or \"yep I like that idea but I&#x27;m not gonna change it at this point\" then no harm done. But pretty often in my experience they say, \"ah, nice, thanks, I didn&#x27;t think of that &#x2F; I wasn&#x27;t aware of that, I like that more; updated now\", and then everybody is even happier.Another useful thing, in my opinion, is to use your \"fresh eyes\" to make suggestions on what could use to be clarified in code or documentation. \"This wasn&#x27;t immediately obvious to me, could you add a comment on why it works this way?\". The author is often too close to the code to see that it isn&#x27;t obvious, because it is to them, because they&#x27;ve already spent hours thinking about it. But this should almost always what be optional suggestions. (But, rarely, code is so unclear that it really shouldn&#x27;t go in without being clarified or documented.)But in general I do think it&#x27;s important to consistently be thinking to oneself \"my goal is to be useful to my team and organization. are my comments achieving that? would it be more useful to approve or to not approve this right now?\". The temptation to be a fastidious editor can be strong - if most of us didn&#x27;t have this impulse we&#x27;d probably be doing different jobs... - but I find this \"usefulness\" framing to help me a lot in resisting it.And very strong disagree on not requiring reviews. It is much better to tirelessly foster a low-friction review culture. reply jsight 17 hours agorootparent> [...] while also mashing the \"approve\" button+1 - It is easy to forget that it is possible to approve with comments. Not all review feedback should block a merge. reply nox100 16 hours agorootparentIt is a merge block in some code bases. You need to know the code the person said they were going to commit is the code they actually commit. Especially when there is financial incentive and state actors that want code inserted.In my project we used to be allowed to approve with nits but recently they changed it that the code needs a re-review for almost any edits. The system has some criteria for which it will allow minor edits but it&#x27;s strict enough that I&#x27;ve rarely seen it pass an edit. I assume there must have been some incident that triggered this. reply dkersten 16 hours agorootparentI read it as it’s up to the person who opened the PR whether to apply the nits, or whether to ignore them and use the approval to merge. This is how our codebase works: you’re free to ignore minor suggestions, but if you do edit the code, reviews are dismissed and need to be provided again.Basically, an unaddressed nit doesn’t block merging. But any code changes will require fresh reviews.If the change is very minor, it’s very quick for someone who has already approved to check the last commit diff and reapprove. reply lokar 16 hours agorootparentprevIME this is always driven by lazy compliance people pushing the most straight forward way to satisfy some audit. Plenty of places subject to strict audit rules manage to make small post review edits work. reply yjftsjthsd-h 16 hours agorootparentprevI think it&#x27;s legitimate to force a re-review for any code change, given that programming is one of those charming areas where a single character can completely change the meaning of something.That said, if you can read the commits individually then final review for something where minor changes were added should be utterly trivial. reply jsight 15 hours agorootparentprevYes, it is pretty common to require re-review if it is changed again. But approval with comments shifts control back to the submitter. They then have choices:- Modify it and accept that this will trigger re-review- Merge as-is... maybe they don&#x27;t even agree with the nit- Merge as-is and followup with a new MR under the same JIRA. This sometimes makes sense if it gets them into an important preprod environment, but they are really still working on the issue.- Merge as-is and follow up with a JIRA on the backlog. Maybe they realized that the \"nit\" is really a bigger issue and should be addressed separately.Regardless, there&#x27;s value in not blocking the merge for non-functional issues. reply lazyasciiart 14 hours agorootparentI got a merge blocked last week with the comment &#x27;I think this work is more related to \"TFS X: prepare for Y\" than it is \"TFS Y\".&#x27; (I eventually realized they wanted me to change the commit message). I hate this fucking team. replydawnerd 16 hours agoparentprevYeah no, part of code review is ensuring code quality is maintained. If you start letting badly written code fly because it passes tests, that’ll bite you. If something isn’t blocking I’ll make a note that it should be fixed if theres budget knowing sometimes you gotta let things go. But you can’t just ignore code quality and call it nitpicking. reply withinboredom 16 hours agorootparentBadly written, or badly designed? Bad code, to me, would be an unrolled for-loop, or a for-loop where a foreach loop would do better (though now, we&#x27;re getting in the realm of nit-picking). A PR is waaaaay too late to bring up architectural&#x2F;design improvements (unless it is a WIP PR opened expressly for discussing the approach).I very rarely see bad code in PR&#x27;s unless it is from a Junior programmer, and even then, it&#x27;s usually because they don&#x27;t know better. Even then, I choose to trust them to do the right thing. In most environments, you can even review the code AFTER it has been merged. So, if they don&#x27;t address the issue, I can still review the code and let them know that I expect to see a follow-up PR addressing it. reply thiht 16 hours agorootparent> A PR is waaaaay too late to bring upNo. That’s literally the point of a review. reply withinboredom 16 hours agorootparentNo, it&#x27;s not and there is a ton of literature (even entire books) written on why it isn&#x27;t the time to bring this up during a review.For starters, it results in a waste of time for literally everyone involved:1. The person writing has to rewrite it (probably).2. The reviewer could have sat down with the person before a single line of code was written.3. Anyone else reviewing just wasted their time because it will be rewritten.If you see code badly designed, walk over to, or call the developer and say \"hey, can we discuss the design of the code.\"The saying \"measure twice, cut once\" doesn&#x27;t just apply to wood. Design before you ever write any code. reply johnnyanmac 15 hours agorootparent1. That&#x27;s the point. It&#x27;s not up to standard2. They could but they usually don&#x27;t. It&#x27;s fine to sit down and make sure they understand some esoteric structure within a system I owj I&#x27;m not going to sit down with someone else to make sure they use for each loops unless it&#x27;s a very new junior (i wouldn&#x27;t block that in most code reviews anyway unless the code was legitimately painful to read, but every company is different).3. IME there may be multiple reviewers but one primary reviewer. Half the time the non-primary ones either focus on \"is this code going to break your work flow?\" or are simply there for bookkeeping and isn&#x27;t the approval you&#x27;re looking for (i.e. A lead on a review that already talked about the plans but doesn&#x27;t have the knowledge to review that specific module). Anymore than 1 primary reviewer probably needed a smaller PR if possible. reply withinboredom 14 hours agorootparentAnyone who has ever come along in a code review and told me my code “isn’t up to standard” will inevitably start a very long game of attrition with me. Here’s the thing: there’s no such thing as “standard” software architecture (until someone writes a new kind of software architecture called “standard”).I’ve seen and used everything from MVC to DDD to TDD to MVVC to whatever React is to reactive to event-oriented to actors to whatever you can imagine. There simply isn’t a “standard” way to do anything in this industry. If you hired me, you hired me for these different perspectives on problem solving, and that goes for all of us.A code review simply isn’t the place to enforce your unique perspectives on someone else.Sometimes, there is simply a better way to do things. These might even be new ideas in the code base. If it looks like it is, hopefully the author will bring it up with the team beforehand. If the reviewer changes their mind in the code review… well, that’s not the authors problem. The reviewer should rewrite it and the author review it.Actually, that’s exactly what I suggest if someone ever tries that with me (usually when I’m the new guy). Please submit your own PR showing me how it’s done. I’ll move on to another ticket.Usually, about half way through their implementation, they’ll see why I did it the way I did it and approve my PR. It only takes one time before they start asking “why” instead of assuming they know everything; every line of code exists for a reason, after all.In one case, one specific dude (bless his heart) kept blocking PRs after we discussed everything before hand. I had to get HR involved, and other engineers. Dude just didn’t like being wrong and would throw tantrums when he was. He eventually got fired after people realized they could do what I was doing to stop the nits he said was a blocker. Nobody cared if a variable should be renamed from “SameFactory” to “EqualFactory”.Ah, but code quality! It’s so subjective. High code quality, to me, is easy to maintain code. Is the intention clear, do the comments reflect reality, is it easy to read, but more importantly, easy to change? Will changing a line in the module break 15 other sibling modules? God I hope not. Dependencies should be obvious. And, no, I’m not writing an interface if there is exactly one implementation. That’s ridiculous.For some people, they want layers. More layers of abstraction than a layered cake on a wedding day. To them, that’s good code quality! Some people think high code quality is beautiful code. The kind you frame and put over your fire place to admire with a glass of wine.There’s no objectively “high quality” code in existence. reply ravenstine 14 hours agorootparentYeah, gotta love it when someone uses terms like \"standard\" and \"quality\" but definitions of those are written nowhere. Quality is almost never objective either; some cultures like \"overripe\" bananas and some consider the best bananas to have no spots, and those picking bananas need a different basis for what makes a good quality banana to the buyer. Unless programmers diligently document their standards (which they rarely do adequately), they shouldn&#x27;t be surprised if the other programmers is dumbfounded by being told their code isn&#x27;t up to standard. reply johnnyanmac 12 hours agorootparentprev>Anyone who has ever come along in a code review and told me my code “isn’t up to standard” will inevitably start a very long game of attrition with me.standard is relative, and while I&#x27;m talking generically as someone on the internet with no context of your experience, a code reviewer shouldn&#x27;t. Someone literally saying \"the code is not up to standards\" needs to clarify.For my generic take, take \"standard\" as \"whatever that team has laid out in its code architecture\". Sometimes there may be times to question the standards if it compromises other important factors, but personally I don&#x27;t think the code review is the time to fight over whitespace and bracket placement (those should be solved via a linter anyway). Make the correction and submit, those later discussions can happen offline.>A code review simply isn’t the place to enforce your unique perspectives on someone else.Likewise, the goal is to align everybody, not to argue over semantics or enforce your own POV. That&#x27;s why code style sheets are a thing; it&#x27;s a mediator that can serve as its own battlground should team&#x2F;company style need to be changed. Again, every place is different, but1. style should be automated as much as possible. If there&#x27;s some stupid whitespace rule, it should be a one button click on my IDE from some provided linter to resolve (even if I will proceed to re-lint it to my style afterwards on my local machine).2. style sheets can have suggestions as well as laws. Be reasonable on what is what>For some people, they want layers.sure, lawful evils exist, both maliciously and inadvertently. Sounds like you ran into both kinds. Office politics are inescapable even at the best companies.That sounds like another discussion to adjust to style sheet, not throw it out upright. If you see a bunch of examples of a law being broken, adjust it to a suggestion unless is a strong argument made otherwise. (most) companies aren&#x27;t a congress where amending such things takes months of proposal, and we can very much adjust the document to the people if there&#x27;s no resistance.Now, do you actually care enough to spearhead that change? I imagine many don&#x27;t, and there in lies the problem. That&#x27;s why I&#x27;m not on management track; I don&#x27;t have the care nor attention to worry about documenting such things unless someone throws it at me. I&#x27;ll leave that to those who do care. reply withinboredom 11 hours agorootparentTo be clear, I&#x27;m not talking about code style (easily objectively quantifiable) or bad code (also easily objectively quantifiable), but architecture&#x2F;design. This can be things like which folder an interface belongs in, where to put a method in a parent&#x2F;child relationship that touches both, when to use value objects vs. scalars, when to break functionality into another service&#x2F;library, which methods are allowed to call which methods, which classes must be injected vs. instantiated, etc. reply JoeAltmaier 14 hours agorootparentprevI&#x27;d like to agree. But there is one part of that distinction that is real: there is such a thing as low quality code. reply withinboredom 14 hours agorootparentI think there is a such thing as “bad code” but not low quality code. Bad code can be detected by automated tooling and be improved through simple refactoring. reply JoeAltmaier 11 hours agorootparentI&#x27;d say it this way: bad code doesn&#x27;t robustly handle all the use cases, mis-interprets inputs sometimes, or is a mess to read and debug.Yes, it matters what the code looks like. Knew a guy, named everything in his code a letter of the alphabet. a,b,c and when he got to z started za, zb etc.That was &#x27;bad code&#x27;. Or, it was &#x27;Low Quality Code&#x27;. Nobody wants junk like that. Even if it passes tests, is robust etc. reply withinboredom 9 hours agorootparent> Nobody wants junk like that.I can think of a few tools that do that to your PHP or JS code, on purpose. They even cost quite a bit of money (obfuscation). Sounds like you might have gotten a good deal there ... &#x2F;s replyArainach 12 hours agorootparentprev>The reviewer could have sat down with the person before a single line of code was written.This is a bigger waste of time. If every change requires asking someone in person, that&#x27;s an infinite source of distraction and kills productivity for that person.MOST code reviews don&#x27;t end up in comments asking for big changes, and when they do the one-time cost on the author is much better to pay than the constant tax on your subject matter experts of what you&#x27;re proposing. reply withinboredom 11 hours agorootparentHow is spending 5 minutes x TEAM_SIZE to go over what you&#x27;re going to do more time than 1-2 days solving a problem, then another hour or two for the reviewer to write out why it&#x27;s wrong, then another day or two rewriting everything from scratch? reply Arainach 11 hours agorootparentNone of those timelines are realistic:* Most CLs don&#x27;t take multiple days to write* Reasonably-sized CLs take 5-10 minutes to review - if I have things to say. Much less if the code looks good and I don&#x27;t have any requests.* I cannot think of any CL in the last 5 years where I made a comment that caused someone to \"rewrite everything from scratch\". Most feedback can be done in a few clicks in an IDE which supports refactor or a few minutes of copy&#x2F;paste. reply DandyDev 15 hours agorootparentprevThe alternative is a big design upfront? reply withinboredom 15 hours agorootparentGenerally, it goes something like this imaginary Slack convo:Me: I think we are getting events from SQS out of order and that’s why we are seeing some weird synchronization issues. What do you think about sending events to the regular queue and a FIFO queue at the same time and comparing them?Team: How would that work?Me: Since we are using a single threaded consumer here, I think we can simply override the transport class and instead of pulling from one queue per transport instance, we set up a feature flag allowing us to pull from two, compare the events and if they are different, alerting us in the logs.Team: Sounds good!You don’t need a full design spec, just agreement from the team on the approach. There won’t be any surprises in the review. reply thiht 14 hours agorootparent> There won’t be any surprises in the review.There can always be surprises. Sometimes when you see something implemented you can get a « click » as to why another solution would be better. It happens to me regularly both on the receiving and giving end of this and it’s rarely a big deal. Most of the time it happened to me, I could reuse the functional tests I had written and parts of the code anyway.Reworking on something so that it’s better is never a waste of time, and it’s always better to do it before it reaches Prod. reply withinboredom 14 hours agorootparentMaking a suggestion on how to do something better is quite a bit different than saying “this isn’t up to standard. Do not pass go. Do not collect $200”We all see these suggestions. That’s ok, and wanted. But to say “ah, no I think it should be the other way.” [reject]That’s what I was talking about here. replyravenstine 14 hours agorootparentprevKind of off topic but I&#x27;m curious what it is about a foreach that you think would do a better job than a syntactical for-loop. In my experience, for-loops are almost always the better choice, unless the implementation of \"foreach\" is done in a way that is functional and recursive. Foreach in the usual sense (like the method in JavaScript) provides too little control to the callee and is only really of benefit if one really needs to conditionally pass in different callback functions.Besides, that, I mostly agree with your stance on code reviews. The way that most programmers do code review is so very \"waterfall\" and they don&#x27;t even realize it. reply withinboredom 13 hours agorootparent> what it is about a foreach that you think would do a better job than a syntactical for-loopIt depends on the language. For example, an optimizing compiler can optimize the shit out of a for-each loop, but can only go so far in a for-loop. For example, in a for-loop, you can \"skip around\" the indices, and even go backward after going forward, while in a for-each loop, it will always go one-by-one, and the compiler can rely on that fact. Even the CPU can probably optimize it better since the data access will be more predictable. reply ravenstine 14 hours agorootparentprevCode \"quality\" is almost always an opinion, and not one that is based on anything objective. That doesn&#x27;t mean that the idea of it doesn&#x27;t have a purpose, but it&#x27;s almost always used as a bat to knock someone over the head with. It&#x27;s not like code can be distinguished as fresh or moldy and rotten like fruit. If that were so, then most programmers would hardly ever bicker about code quality; it would be self-evident, just as any moron can separate the good fruit from the bad.If a unit of code fixes or improves the user experience without slowing it down and is memory efficient, then it becomes incredibly hard to objectively define said code as being bad. Perhaps it ruins the developer experience, but then again, many programmers object to things they simply don&#x27;t like on a philosophical or theological basis. Programmers, depending on the language community, may consider anything that isn&#x27;t \"object oriented\" to be poor quality, but good luck finding objective proof that object orientation is always better. reply BytesAndGears 17 hours agoparentprevI like your thought process here, but let me propose an alternative. I’m going to assume that we’re talking about Senior->Senior level reviews here. Junior engineers should obviously always get more guidance. But for Seniors, the alternative is:Be extremely picky for PRs from new hires, so that they do things the way that your company does them. Make sure they put files in the right places, and adhere to the “flow” of the rest of the codebase. Also the sorts of style that aren’t picked up by a linter — like architecture choices — should be heavily scrutinized to make sure that they fit with your company’s paradigms.After a while, they’re fully assimilated and you have a coherent style so that everyone is on the same page. Future code reviews go quickly because everyone makes similar architecture decisions and you’re never surprised. This also makes code easier to read if it all follows the same subset of patterns.I’m not actually sure which way is better, but I think that both options have benefits. reply marcosdumay 16 hours agorootparentI&#x27;ve received plenty of negative feedback on the internet for this (and up to now, discarded all), but I really don&#x27;t think acceptance review is the correct time for guidance.Yes, juniors need guidance. That means you must read their code, and talk to them about it. They also need real-world feedback. They do really need you not managing all of the interaction they have with the real world. Now, what you can not manage is up for a complex risk analysis, but they really need you to get out of the way at some point. reply johnnyanmac 15 hours agorootparentSo, when is the right time? reply marcosdumay 14 hours agorootparentAt some time you plan for it. Preferably a calm time, not one they are waiting a decision from you.E.g. before they start implementing a feature is better than after they finish it. replywithinboredom 16 hours agorootparentprev> Be extremely picky for PRs from new hires, so that they do things the way that your company does them.I think the word you are looking for is \"hazing\":> haze (v): force (a new or potential recruit to the military or a university fraternity) to perform strenuous, humiliating, or dangerous tasks.I had this at my current job. I almost quit because it was downright humiliating to get called an \"idiot\" in so many nice words. I don&#x27;t do well with hazing... so I brought out quotes from text books, papers, and famous authors to point out how wrong they were. reply johnnyanmac 15 hours agorootparentNo, the word is called \"alignment\">an arrangement of groups or forces in relation to one anotherIf you&#x27;re being harassed in PRs the peer review system has failed. It&#x27;s a place to make sure everyone is on the same page, not judge someone for how they code. reply notnullorvoid 15 hours agorootparentprevThey are not suggesting hazing. I don&#x27;t doubt that you experienced hazing. Being vigilant with new hires to assure assignment on code quality and design is not hazing though.If someone has legitimate concerns about the design decisions made, then they should voice them. However if they are refusing to adhere to guidelines, simply because they dislike the approach then that&#x27;s being overly problematic. reply withinboredom 15 hours agorootparentIt’s literally the definition of hazing. But instead of being asked to jump in a pool, naked, while snowing, you are asked to build things a new hire has no business building. Then nit-picked for not knowing things. Literally set up for failure.A better solution is to actually sit with them while they build a feature, show them around the code, and answer questions. You know, treat them like a team member instead of making them prove their mettle. reply BytesAndGears 13 hours agorootparentI definitely didn’t mean it like hazing.I don’t see what’s so wrong about saying “you used inheritance for this relationship, but we have a pattern of keeping classes like this separate, since this system tends to change frequently. Please organize this like xyz module instead.”Just a random example of something that a new person might do who is unfamiliar with xyz module and the complications there.I agree that it’s good to mentor someone new, but honestly I think they still make most decisions themselves, and sometimes those decisions don’t match established patterns that they don’t know about. Ideally you notice sooner than a PR but I also think that people get busy and it’s ok to not have time to monitor everything a new person does. So sometimes it comes down to the code review to notice.It’s not derogatory or hurtful, literally at all, it’s just pointing on that they did something in a way that goes against established patterns, and it’s teaching them what those patterns are. reply withinboredom 13 hours agorootparentMy response would be a simple \"Why does code changing frequently prevent inheritance from being used?\" if I got a comment like that. Granted, I don&#x27;t like inheritance, so I have nearly 1000 arguments on reasons not to use it that has nothing to do with code changing frequently, so ... this is probably a bad example for me, personally.But seriously, I&#x27;d ask why, and why again. I&#x27;m very much against cargo culting, and I will refuse to make changes in my PR if it is cargo culting. You&#x27;re welcome to open a PR to my PR with changes if you feel strongly about it though.Maybe this makes me hard to work with, but so far, I feel like it has led to better code and a higher velocity, everywhere I&#x27;ve worked. reply Arainach 12 hours agorootparentTeam conventions are not cargo culting.Change is bad unless it&#x27;s great. Being able to look around a codebase and know how things work because similar coding styles and patterns are consistently followed is a huge productivity boost (this is also what commenters complaining about the idea of readability elsewhere in this thread are missing). Something must be 10x better to compensate for diverging from those patterns.What you write is not YOUR code. It is your TEAM&#x27;S code, and the good of the team is far more important than what you personally like. reply withinboredom 12 hours agorootparentHeh, if that&#x27;s your reasoning on why something should be the way it is, then that is what it is. Somewhat reasonable, but don&#x27;t be surprised if any reasonable person quits that day. The argument is not grounded at all in computer science or anything else objectionable. It doesn&#x27;t allow the team to grow and change what is in front of them every day and forces them to live with old mistakes forever. Doesn&#x27;t sound like a good place to work. You don&#x27;t get to a 10x solution overnight, in a single PR, you get there in increments.I also disagree with it being \"the team&#x27;s code\":What you write is your code (and copyright law almost universally backs this up), what gets merged is a maintenance burden for all time. It very much matters what you like and don&#x27;t like, and it very much matters that it is maintainable (whatever that means).The team ... doesn&#x27;t matter when it comes to code conventions ... they&#x27;ll all be gone and moved on to other parts of the code&#x2F;company&#x2F;industry outside of five years. Most code lives long beyond today&#x27;s team. reply Arainach 11 hours agorootparentI&#x27;ve worked with some amazing engineers, including multiple whose blog posts regularly get posted here. None of them have egos or consider code review feedback personal attacks.It&#x27;s not like you&#x27;re being told to never use for loops. Code review feedback such as the following is all objective, beneficial to the reader, and not worth pushing back against:* This logic should live in [other component] * Our RPCs are named as GetFoo, not DetermineFoo * That function name does not make it obvious what this code does, please change it * This needs a test * This is untestable and needs to be refactored to support XIf anyone on my team ever described themselves as in \"a war of attrition\" with another teammate I&#x27;d fire them. reply withinboredom 10 hours agorootparent> If anyone on my team ever described themselves as in \"a war of attrition\" with another teammate I&#x27;d fire them.I wasn&#x27;t sure if I was going to reply to this part or not. But you took a comment out of context here.I&#x27;m incredibly touchy about code reviews. I used to have the popular opinion here where \"the code belongs to the team!\" and all that. And then I was stuck on a team with a very toxic guy who weaponized this stuff. His code was \"perfect\" and he&#x27;d approve your PR to turn around and rewrite it just to show how much better it could be (and gloat about it -- not realizing if he hadn&#x27;t deleted half the tests, they&#x27;d be failing). He&#x27;d constantly point out all the things that were \"wrong\" and with the justification of \"code quality\" without actually being able to point out why it was better. After working with them for two years, the entire team&#x27;s philosophy turned into the one I&#x27;ve shared here ... because it can&#x27;t be weaponized. It can&#x27;t be used to tyrannically rule the code. It can&#x27;t be used to bully people around \"for the sake of quality!\"His \"code quality tyranny\" did more damage to the code than any actually bad code could have done.So yeah, I will go into a war of attrition over certain kinds of comments that are spoken authoritatively yet are entirely opinionated ... because I&#x27;ve seen what happens when it gets out of hand. I have no desire to go through that ever again. Ever. If that means someone like you fires me for it, it&#x27;s better than going through that shit again. Sorry, not sorry. reply redditor98654 9 hours agorootparentYou experience one extreme ans then decided to take the opposite extreme stance. I recommend being more pragmatic. reply withinboredom 9 hours agorootparentEventually, sure.I&#x27;m also starting to think this is how the Paradox of Tolerance happens. I&#x27;m intolerant of intolerance these days. I&#x27;m much more tolerant of people having their way of doing things than I was just 10 years ago. However, as soon as one person comes along and says \"It MUST be this way because QUALITY!\" I go into intolerance mode and don&#x27;t tolerate it.Now, if you can give me a reason grounded in computer science, or whatever paradigm we&#x27;re using (DDD, hexagonal arch, actor-model, etc), then I&#x27;m perfectly happy to agree or spend a few minutes over a coffee discussing merits. But if the reason is &#x27;quality&#x27; ... it&#x27;s a \"dual to the death.\" reply redditor98654 7 hours agorootparentI see. I want to try and understand this because I am also trying to get better at code reviews and not come across as a dogmatic person.I have spent almost 15 years in mostly AWS and I want to keep myself in check and make sure people don&#x27;t take my suggestions as the vague \"quality\" as you so mention just because of my seniority.Here is the most recent PR I did for a relatively young person in my org. Part of the PR was doing a type of snake_case to CamelCase conversion from some user inputs to some enums classes. It was done manually with String manipulation and playing with indexes etc. It also came with a bunch of unit tests to make sure the conversion was working correctly.I put in a comment along the lines of \"hey, this conversion seems like it can be done with this Apache Commons Text library; given that we are already using it in the same project in some other place, we can remove this manual code and call the library function; we can even remove the tests assuming the well-tested library is doing the right thing\".Was this comment warranted? If you think this is a reasonable comment, what computer science principle would you say it is based on? reply withinboredom 1 hour agorootparentThere are three parts to every code review:1. Code style: such as formatting and when to use certain things (non-negotiable and you really should automate that).2. Working code: does the PR have a description&#x2F;ticket and does the code do what it promises to do? Can we refactor anything to make it better?3. Conventions: does the PR have tests when necessary, are there negative and positive tests? Does it pass those tests? Is there anything against the conventions? If so, bring it up with the dev and find out why, outside of the PR. Maybe they didn&#x27;t know the convention or there is some legitimate reason for it. Don&#x27;t be an ass and call them out for it on the PR in front of the whole team, give them the benefit of the doubt and if someone else comes along and calls them out, you can present a united front vs. forcing them to defend themselves all alone.In this particular case:Suggesting a library should have been done before the code was even written. At this point, I wouldn&#x27;t even suggest using it without some homework for the reviewer and look at the implementation in the library.If the library implementation covers cases not found in the code I was reviewing, I would suggest looking at that library for some inspiration and&#x2F;or switching to it. I would emphasize switching to it if it is far and away from the library code; as time could be better spent elsewhere. If the new implementation looks better than the library one, I might even suggest refactoring the entire codebase to use the new implementation instead of the library and&#x2F;or spending some time to open a PR with the original library and improve it.The work has already been done. Try to capitalize on it, instead of dismissing it.Seriously though, look at the library implementation before moving forward. I&#x27;ve seen some very popular libraries and frameworks be very poorly implemented in some areas but because \"it&#x27;s popular\" people seem to think it is better. That&#x27;s not always the case. replywithinboredom 11 hours agorootparentprev> I&#x27;ve worked with some amazing engineers, including multiple whose blog posts regularly get posted here. None of them have egos or consider code review feedback personal attacks.Same. Nor do I consider code review comments personal attacks, but anything that must be changed for \"reasons,\" must be questioned. Not because it&#x27;s personal, but because I legitimately want to know and I won&#x27;t give up until I get a good answer.> Code review feedback such as the following is all objective, beneficial to the reader, and not worth pushing back againstI&#x27;ll agree that none of this is probably worth pushing back against, but it isn&#x27;t objective. Very little is objective, in our industry.> This logic should live in [other component]Why? DDD will say one thing, MVC will say something different, though usually they are compatible or can be made to be compatible. You can also subscribe to hexagonal architectures and that might say something different...There&#x27;s nothing objective about where code should live, except on a hard drive or some other storage medium. I would argue that code probably shouldn&#x27;t live on paper. I imagine most of us would agree with that.> Our RPCs are named as GetFoo, not DetermineFooThis is a nit. I&#x27;d honestly probably ignore it.> That function name does not make it obvious what this code does, please change itI&#x27;d probably ask for a suggestion because it probably looks obvious to me after staring at the code for so long. That being said, it might be a valid suggestion, especially if the code was refactored, but wasn&#x27;t renamed.> This needs a testI hope nobody ever says this on my code reviews. However, I don&#x27;t write tests for \"obviously correct\" code (code where the test implements the logic to test the logic): such as a function like: function returnTrue(): true { return true; }If I see code that changes \"obviously correct\" code, then a test is warranted.> This is untestable and needs to be refactored to support XDo you know there is a such thing as legitimately untestable code (or at least, it shouldn&#x27;t be tested in traditional unit tests)? Usually at the edges of two systems. For example, an API integration can&#x27;t be tested fully, only the known contract from the other system. Then you start running into Postel&#x27;s Law ... things get weird. Only if you have some kinds of guarantees with the other system (not usually), would I recommend traditional tests. reply Arainach 10 hours agorootparent>> Our RPCs are named as GetFoo, not DetermineFoo>This is a nit. I&#x27;d honestly probably ignore it.Congratulations, until the end of time your team now has to remember multiple naming conventions, and when they want to do a code search for the RPC that retrieves foo, if they search for \"GetFoo\" because all the other RPCs are \"GetBar\", \"GetBaz\", and \"GetTaco\", they&#x27;ll find no results and be confused.\"The team\" is not a static thing, it is an evolving team-of-Theseus. Consistent naming and coding styles make it easier for the team, until the end of time, to read and search code. These \"nits\" are productivity multipliers.As other reviewers have called out, I am a fan of \"LGTM with comments\", but any teammate who starts ignoring comments loses the privilege of receiving LGTM with comments from me and gets to wait until I actually review a version of the code that is acceptable to the team. reply withinboredom 10 hours agorootparent> until the end of time your team now has to remember multiple naming conventionsDo they not have PR&#x27;s where you are from?If someone is that annoyed by it, just open a PR. Just because I don&#x27;t find it annoying, doesn&#x27;t mean someone else won&#x27;t. And vice-versa.The code is mutable. It doesn&#x27;t have to be perfect on the first iteration.I will say this though: if you want me to do your nits, you also have to do mine. It&#x27;s a two-way street when it comes to nits. If you don&#x27;t do my nits, then I won&#x27;t do yours. It&#x27;s pretty simple. If you start withholding approvals because I stop doing your nits, then yay ... politics, I guess. reply Arainach 10 hours agorootparentThe code is mutable, but the cost to fix it during the original code review is WAY lower.Once you land RPC DescribeFoo, I have to:1) Define a second parallel RPC GetFoo2) Wait for it to roll out to prod3) Update all callers to call GetFoo, probably controlled with an experiment for safe rollover4) Wait for all of those to roll out5) Clean up all the callers6) Clean up the DescribeFoo RPC.....or you could just fix it in code review with half an hour of work. reply withinboredom 9 hours agorootparentI thought it was DetermineFoo?Anyway. To me, DetermineFoo doesn&#x27;t sound like a getter and seems like it might even possibly mutate some states. So, I suspect creating a GetFoo would be orthogonal to deprecating DetermineFoo. This means DetermineFoo might only Get a Foo by side-effect. That&#x27;s why I would probably ignore it; simply because DetermineFoo might be a better name, in my opinion.New behaviors occur all the time in software, but it doesn&#x27;t mean we need to be rigid with naming things. reply Arainach 12 hours agorootparentprevThere is no hazing because there is nothing personal here. You are not being judged. The code you wrote is, but feedback in a code review doesn&#x27;t say anything about your competence (though how you respond to that feedback says a lot).If your team is insulting you or saying that you&#x27;re a bad engineer based on code review comments, that&#x27;s a bad team. That doesn&#x27;t mean that ensuring new team members learn the team&#x27;s style and patterns is hazing. reply withinboredom 11 hours agorootparentI&#x27;m sure that is what the frat boys would say when they tell everyone to jump in the pool, in a blizzard... it&#x27;s not personal.If you don&#x27;t suck it up, you&#x27;re not \"one of us\" and you need to go. Or maybe they told you to do the wrong thing and see if you point it out. Who knows!? replykstrauser 17 hours agoparentprevNote that PRs are mandatory if a company goes through SOC-2 or any other compliance framework. The underlying question they answer is “could a malicious or incompetent employee send bad code to production without another engineer viewing it first?”The specific response auditors expect is “no, because another human reviews all change requests before they’re approved”. reply notyourwork 17 hours agoparentprev> If somebody wants mentorship I&#x27;ll add my thoughts in a comment along with my approval.This is always the approach I take. Especially for junior engineers. Stay out of the way, let them merge code with as little friction and discouragement as possible. Anything that I would have implemented or approached differently I try to elaborate on. Even go so far as to write some (most or all) of the code in a comment or in a remote branch to share. I will still ship the code but let the submitter digest my thoughts. reply ravenstine 15 hours agoparentprevThe fact that your comment is currently at the top of the thread tells me that a lot of people go through this, yet this is interesting to me because past HN discussions have suggested said experience to be an exception. In my own experience, blocking (or simply not approving) PRs over nits, out-of-scope improvements, and mere personal preferences is the norm. What&#x27;s worse is when PRs get blocked because a person doesn&#x27;t like the pattern the author is using even though it&#x27;s already one of many existing patterns and there&#x27;s no explicit guideline anywhere. I find this happens a lot when lead and staff engineers make decisions on what&#x27;s \"considered harmful\" but don&#x27;t actually broadcast that decision in an effective way.What I try to do with my code reviews is prefix my comments with \"Non-blocking suggestion:\" or \"Minor question:\" so that the other person is more likely to know that a particular piece of feedback doesn&#x27;t come with the expectation of needing to be addressed.Otherwise, if the code works, has tests, and isn&#x27;t objectively incorrect, I try to give an approval. If you don&#x27;t like something about it, there should be room in the process to make improvements. The idea that \"mistakes won&#x27;t actually get fixed later\" is a cop out. If your team can&#x27;t fix mistakes, then you should turn in your \"engineer\" titles.Also, when programmers do things that others on their team disagree with, it almost always comes down to a breakdown in communication. Junior developers are a bit of a different story, but senior developers not knowing how to write code that the rest of the team approves of means that people aren&#x27;t communicating, and it probably means that your system is so complex that it&#x27;s unreasonably difficult to determine the proper approach in the first place. reply Kelkonosemmel 16 hours agoparentprevI communicate on purpose that code review is never the 99% markIt&#x27;s the time to get feedback and improve.The problem is: if people are stuck and don&#x27;t learn the code review phase will always stay as a long thing.The whole team is responsible for security, maintainability, etc.I don&#x27;t care about some code monkey able to write some code or fixing something. I care about a team, a product.Your attitude would not work in my team, which is fine reply iwontberude 17 hours agoparentprevI am as unopinionated as I want others to be. All they need to do is commit a patch to my branch and fix it. It won&#x27;t hurt my feelings and I don&#x27;t need to consent. Let&#x27;s get past the egos and wasted time asking for permission to change things. reply colonwqbang 11 hours agoparentprevMissing or misleading documentation. Confusing names. Lacking test coverage for new functionality. Unnecessarily complex code that can readily be simplified. Code that looks important but in fact does nothing useful. Unrelated changes mixed in with a patch that&#x27;s ostensibly about something else.These are all things I think are valid to point out in a code review. I don&#x27;t think I would like to work in a company that rejects the notion. reply hn_throwaway_99 17 hours agoparentprevYour comment is why I highly recommend using conventional comment labels, https:&#x2F;&#x2F;conventionalcomments.org&#x2F;#labels, when doing code reviews.We&#x27;ve internalized them where I work and I think they&#x27;re really valuable. When it&#x27;s abundantly clear whether something is a nitpick, suggestion, or a blocking issue, because it literally has a prefix to that effect, it takes a lot of the potential stress and confrontation out of the code review process, on both sides.Note you also don&#x27;t need to memorize the labels, but starting with one forces the reviewer to ask themselves the question \"Should I really block the merge for this?\" reply daveguy 17 hours agoparentprevI think PRs are necessary. You can make a very minor change that introduces a bug or discrepancy in documentation. But I 100% agree with your \"get out of the way\" philosophy. That notice should come with the PR notification for the reviewer! reply ruszki 17 hours agoparentprevSo you don’t care about readability, extensibility and techni",
    "originSummary": [
      "Google's code review tool, Critique, is highly regarded and has a high satisfaction rate among software engineers.",
      "The article discusses Google's guidelines for efficient code reviews and highlights the features of Critique, as well as recent advancements in AI-powered code review tools.",
      "It provides insights into Google's code review process, including statistics on code review at the company, and concludes by highlighting the reasons why Critique is so highly regarded by Googlers."
    ],
    "commentSummary": [
      "This article explores different aspects of code reviews, including the use of various tools and the importance of consistent variable naming conventions.",
      "It discusses subjective feedback, code readability, logic, and naming conventions, as well as nitpicking in coding.",
      "The article also covers the role of code reviews in maintaining code quality, including the use of AI suggestions, the debate on how strict code reviews should be, and evaluating engineers based on comment quantity."
    ],
    "points": 274,
    "commentCount": 274,
    "retryCount": 0,
    "time": 1701703894
  },
  {
    "id": 38522650,
    "title": "Judge denies Amazon's motion to dismiss in bathroom spycam lawsuit",
    "originLink": "https://arstechnica.com/tech-policy/2023/12/amazon-faces-trial-after-selling-bathroom-spycam-used-to-abuse-minor/",
    "originBody": "\"A very ordinary hook\" — Judge: Amazon “cannot claim shock” that bathroom spycams were used as advertised A West Virginia judge largely denied Amazon's motion to dismiss lawsuit. Ashley Belanger - 12/4/2023, 8:16 PM Enlarge zhihaoMoment reader comments 169 After a spy camera designed to look like a towel hook was purchased on Amazon and illegally used for months to capture photos of a minor in her private bathroom, Amazon was sued. The plaintiff—a former Brazilian foreign exchange student then living in West Virginia—argued that Amazon had inspected the camera three times and its safety team had failed to prevent allegedly severe, foreseeable harms still affecting her today. Amazon hoped the court would dismiss the suit, arguing that the platform wasn't responsible for the alleged criminal conduct harming the minor. But after nearly eight months deliberating, a judge recently largely denied the tech giant's motion to dismiss. Amazon's biggest problem persuading the judge was seemingly the product descriptions that the platform approved. An amended complaint included a photo from Amazon's product listing that showed bathroom towels hanging on hooks that disguised the hidden camera. Text on that product image promoted the spycams, boasting that they \"won't attract attention\" because each hook appears to be \"a very ordinary hook.\" Enlarge / Amazon's listing for the spy cam, included in the amended complaint. Because \"Amazon approved product descriptions suggesting consumers use\" the spycam \"to record private moments in a bathroom,\" US district judge Robert Chambers wrote, \"Amazon cannot claim shock when a consumer does just that.\" Advertisement \"These allegations raise a reasonable inference Amazon sold a camera knowing it would be used to record a third party in a bathroom without their consent,\" Chambers wrote. Perhaps most alarming to the plaintiff, Amazon's Product Safety Team specifically inspected the camera to \"ensure\" that Amazon wasn't platforming a product being used to “infringe privacy,” “surreptitiously record others for sexual purposes,” or “create and store child sex abuse material.” That review allegedly did not prevent the spy cam from being used to do just that, the lawsuit alleged, putting consumers at risk of alleged harms suffered by the plaintiff, including \"chronic tremors, insomnia, headaches, nausea, hypotension with associated blurred vision, dizziness, compulsive overeating, avoidance behavior, and paranoia.\" In addition to refusing blame, Amazon unsuccessfully argued that none of those harms could be considered physical injury. To the contrary, Chambers wrote that \"if proven,\" the plaintiff's physical harms are considered \"severe\" because \"emotional trauma inflicted during a child’s 'tender years' has an 'indelible effect' from which 'they may never recover.'\" A lawyer for the plaintiff, Lee Javins, told Ars that he thinks this is an important issue for the court to explore. He commended the court for making the right decision after taking its time \"to provide a thorough legal analysis\" on legal theories that he said \"haven't come up a lot with today's technology.\" A potentially “dangerous ruling” for spycam industry The plaintiff hopes a jury will decide that Amazon \"had wanton, conscious, reckless, and outrageous indifference to the health, safety, and welfare of children.\" She has also alleged that Amazon \"conspired\" with the spycam seller to \"market and distribute a defective product both knew was intended and used for illegal and criminal purposes.\" Not only did Amazon allegedly \"shape\" the \"marketing and promotion of the camera\" by controlling \"how products are depicted and the content of product listings and descriptions,\" but Amazon also \"boosted the camera’s sales\" with its \"specialized algorithms,\" the lawsuit alleged. Advertisement A loss for Amazon could put the online retailer on the hook for punitive damages. Amazon could also be ordered to stop selling the spycam used to harm the plaintiff and any products considered \"identical\" to that spycam. Chambers wrote that proving \"foreseeability\" of harms \"is key\" to defeating Amazon's defense. Tech legal expert Eric Goldman wrote that a victory for the plaintiff could be considered \"a dangerous ruling for the spy cam industry and for Amazon,\" because \"the court’s analysis could indicate that all surreptitious hook cameras are categorically illegal to sell.\" That could prevent completely legal uses of cameras designed to look like clothes hooks, Goldman wrote, such as hypothetical in-home surveillance uses. Now, discovery will proceed as the plaintiff can argue her case at trial. The trial could shed more light on \"what Amazon’s Product Safety team thought when it evaluated this item,\" Goldman wrote. Currently, Amazon advertises several \"clothes hook hidden camera\" products when users search for \"bathroom spy camera,\" an Ars search found, but it's unclear if the spy cam at the center of this lawsuit is still available on Amazon. In his blog, Goldman pointed to an Amazon online listing that appeared to be the spycam in question. However, Javins told Ars that while that particular listing looked like the \"same type of camera,\" it had a different product description from the spycam sold in the case, where \"the whole vibe\" of the listing \"was just kind of creepy.\" Ars unsuccessfully attempted to contact Amazon for comment on the judge's order and the online listing Goldman found. Shortly after submitting that request, Amazon appears to have removed the online listing but has not yet offered Ars any explanation. reader comments 169 Ashley Belanger Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience. Advertisement Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 The F-35's next tech upgrade US Navy Gets an Italian Accent SITREP: DOD Resets Ballistic Missile Interceptor program SITREP: DOD's New Long-Range Air-to-Air Missile Aims to \"Outstick\" China Army's New Pistol Has Had Some Misfires Army's Next (Vertical) Lift En Route SITREP: President Trump's Missile Defense Strategy Hybrid Options for US's Next Top Fighter The Air Force’s Senior Citizen Chopper Can’t Retire Yet Ars Live #23: The History and Future of Tech Law Police re-creation of body camera evidence - Pueblo, COArs Technica Visual Labs body camera software with the Dos Palos PDArs Technica He knew his rights; he got tased anyway More videos ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=38522650",
    "commentBody": "Judge: Amazon \"cannot claim shock\" that bathroom spycams were used as advertisedHacker NewspastloginJudge: Amazon \"cannot claim shock\" that bathroom spycams were used as advertised (arstechnica.com) 233 points by MBCook 13 hours ago| hidepastfavorite145 comments Sanzig 12 hours agoGood. Amazon has been happy to rake in commissions for years from dodgy products sold by third party sellers (uncertified electrical equipment, scam flash drives&#x2F;SSDs, spycams, etc) and then turn around and blame the marketplace sellers when the inevitable happens.Unlike eBay, Amazon goes to great lengths to sow confusion about what it sells versus its marketplace participants. The average user thinks that when they buy something off Amazon, they&#x27;re buying something procured and vetted by Amazon, when it&#x27;s really a marketplace seller using Amazon&#x27;s logistics services.Well, they can&#x27;t have it both ways, either Amazon is a well vetted marketplace or the wild west. They can&#x27;t project one image to their customers and claim another in court. reply space_fountain 12 hours agoparentAnd I&#x27;m not convinced we need a wild west either, at least if it&#x27;s also more or less impossible to trace responsibility back to the producer. It&#x27;s pretty new for something like Amazon to exist with the ability to market (through product recommendations), handle payments, and handle shipping logistics for a product that they need never even see. It means it&#x27;s easy for manufacturers like this to basically get away scot free because they have to invest literally nothing in the US that can get taken away in the event that they turn out to be doing something like this. Some of the lines on the product page are chilling.> 【Motion Detection Mode】 When you turn on its motion detection mode, the camera will automatically start to record a video when motion is detected. You do not need to worry about missing any important moments, ensure the security of your home, garage or anywhere you want.Every line they&#x27;re sure to end like this is being used for home security, but idk that someone could read this and think that was true reply Sanzig 12 hours agorootparenteBay is a wild west, but it&#x27;s at least honest about it. It&#x27;s very clear when you buy something from eBay, it&#x27;s coming from an independent seller, and eBay provides you all the history of seller feedback so you can try to vet the seller yourself. They also provide a dispute resolution system through PayPal that heavily favours the customer. reply toast0 12 hours agorootparentprev> And I&#x27;m not convinced we need a wild west either, at least if it&#x27;s also more or less impossible to trace responsibility back to the producer.I don&#x27;t think it&#x27;s wise to try to end the wild west. At the end of the day, we&#x27;ve been able to send money overseas and get things of questionable quality practically forever; some of the earliest writings are complaints about quality of foreign sellers. It&#x27;s unreasonable to expect a courier to accept full responsibility for the packages it delivers, and it&#x27;s usually not feasible to take effective action against a foreign seller.It might be reasonable to require a registered agent for a seller who is realistically subject to the legal jurisdiction(s) where products are warehoused&#x2F;shipping originates though. It&#x27;s generally pretty easy and inexpensive to find registered agents for incorporation requirements, but I imagine if there were real consequences for registered agents of products being warehoused, costs would be real as well. If that drives people to Aliexpress, so be it? reply legitster 12 hours agoparentprevAmazon used to have a rule that all sellers had to have a US business address. So you at least had importers stateside who could deal with product liability questions.They got rid of it to compete with Wish.com et al who had huge product selections. But the product quality on Amazon has been awful ever since then. reply voytec 12 hours agoparentprev> Amazon has been happy to rake in commissions for years from dodgy products sold by third party sellers (...) and then turn around and blame the marketplace sellers when the inevitable happens.They&#x27;ve also been happy with making it harder for the customer to choose a particular seller (especially one w&#x2F;o Amazon Storefront site) reply JohnFen 11 hours agorootparentThis is the main reason why I stopped buying things from Amazon. It became too difficult to separate the wheat from the chaff, in part because it became 90% chaff. reply wiml 11 hours agorootparentI&#x27;ve started using Amazon&#x27;s website to find a product and then going to the seller&#x27;s website to buy it... what goes around comes around, I guess. reply redserk 11 hours agoparentprevThe wild thing is, Amazon’s first-party offerings generally stand out well by itself! They don’t need to trick people with Marketplace junk. They could completely drop the marketplace and still be, IMO, the most useful shopping subscription.I can get my weekly groceries, soap, toilet paper, a TV, and socks with a handful of clicks. On my doorstep. The same day I click. No driving to a store, no walking around, just grab off my doorstep. This is the entire reason I find Amazon worth it (even a steal!). I don’t care for millions and millions of items, of which many are duplicitous clones.This marketplace trend has been completely ridiculous and I hope Amazon (among others!) are found to be just as responsible for what’s sold. A lot of electronics I’ve seen are dodgy at best, but very clearly dangerous at their worst. If there’s a problem, just spin up a new nonsense “brand name” to mask the problems of the former one.This marketplace trend has completely turned me off from other websites. Target and Walmart’s websites are immensely frustrating. I haven’t used Newegg in ages. reply JohnFen 11 hours agorootparent> This marketplace trend has completely turned me off from other websitesIf I can&#x27;t find what I want in a local store, I order directly from manufacturer&#x27;s websites instead of using any online marketplace (when possible -- which is the majority of the time). reply isk517 12 hours agoparentprevI&#x27;ve had to explain to my father so many times that just because you&#x27;ve bought something off of Amazon does not mean that you bought it from Amazon. They really should have a separate store front for 3rd party sellers. reply Sanzig 12 hours agorootparentHonestly, given that it seems like tons of retailers are trying to follow Amazon&#x27;s lead with a marketplace system, I think we need a consumer protection law to require companies to make it very clear to consumers when they are buying from third party sellers. The issue is rampant. Here in Canada, CBC did an investigation about Best Buy&#x27;s marketplace listings on their online store [1]. It&#x27;s greed, pure and simple: these large retailers are willing to mortgage their reputation for some risk-free sales commission and absolve themselves of any liability by blaming their marketplace sellers.[1] https:&#x2F;&#x2F;youtu.be&#x2F;Gdc9_uPETIE reply duxup 12 hours agoparentprevI was helping my kids pick out Christmas gifts recently.I searched \"lego\" on amazon. Numerous knock off non lego products all over the place, many with very similar boxes, even lego numbers and fonts and all.It&#x27;s just one ongoing scam site now. reply jjk166 11 hours agoparentprevI don&#x27;t think the people buying spycams off Amazon are too surprised when a spycam arrives. If Amazon had put a big banner at the top of the page saying \"this is a third party product, it seems skethy af\" I doubt any of the purchasers would change their behavior. Certainly no one at Amazon duped someone into accidentally setting up a bathroom cam.Spycams are legal to sell in the US, and it is the responsibility of owners of cameras to use them legally. I wouldn&#x27;t expect a brick and mortar store to certify that the products they sell are impossible to be &#x27;used to “infringe privacy,” “surreptitiously record others for sexual purposes,” or “create and store child sex abuse material”&#x27; and be held liable when one of their products is used as such. Perhaps the sale of such cameras should be more regulated, but it shouldn&#x27;t be Amazon&#x27;s place to decide that the law is insufficient and fix it. reply wkat4242 4 hours agoparentprev> they&#x27;re buying something procured and vetted by Amazon, when it&#x27;s really a marketplace seller using Amazon&#x27;s logistics services.And Amazon often seems to label random products \"Amazon recommended\" including those from completely made-up Chinese brands. reply Pxtl 12 hours agoparentprevYes. I&#x27;m quite tired of hearing \"it&#x27;s not our fault that toys full of lead were sold on our storefront and stored, fulfilled, and shipped from our warehouse in boxes bearing our logo! When we said that we &#x27;recommend&#x27; the product, we meant, like, algorithmically, not for realsies. We had nothing to do with these products! It&#x27;s all XGZDoo, a company we kicked off the store. And now would you like to buy any products from XGZDee, our latest new seller?\". reply grobbyy 12 hours agorootparentI like having a Wild West, but it should be clearly advertised as such. AliExpress and eBay are clearly Wild West platforms and I appreciate them.Getting scammed on Amazon is different. Amazon should be fully liable since very sophisticated customers can be confused by commingling, marketplace settlers, algorithmic recommendations, etc. all designed to look legitimate to the unwary while being completely unsafe.I stopped buying food and medical products on Amazon because... scams. reply oceanplexian 12 hours agorootparentI like having an online store with better selection than whatever I can get at the local Big Box store.People forget how bad it was before Amazon, packages took weeks to deliver with even less accountability than Amazon (i.e no reviews). I remember the days of paying $40 for a 3 foot HDMI cable. Bought an unsafe or defective product at a “Trusted” retailer? Enjoy your $3.50 check from the class action lawsuit 3 years later. reply JohnFen 11 hours agorootparent> with even less accountability than Amazon (i.e no reviews)Given that Amazon reviews are utterly worthless, I&#x27;m not sure that&#x27;s an example of Amazon having more accountability. reply wkat4242 4 hours agorootparentYeah so many are paid for reviews. You can tell in Europe because they&#x27;re obliged to mention it. Almost all reviews on sketchy products are from people recieving the product for free or getting paid. reply devilbunny 10 hours agorootparentprev> I remember the days of paying $40 for a 3 foot HDMI cable.Only if you needed it right away, though? And even then, back when Google search actually worked, I was able to get an HDMI cable within walking distance (in Beverly Hills, no less) by searching for \"cheap HDMI cable Beverly Hills\". You&#x27;d only pay full freight if you were buying for something important, like a business meeting, that meant you needed it right now and didn&#x27;t have time to look. That was over a decade ago. I bought most of my stuff from two local businesses that have, unfortunately, discontinued their retail sales in one case (it was never a big part of their business, they mostly do bespoke projects to wire auditoriums, churches, schools, etc. for AV gear) and gone out of business in the other. reply Pxtl 11 hours agorootparentprevRight? Maybe at this point it&#x27;s mostly historical inertia and they&#x27;ve converged to similar UIs, but the mental brand people have for these companies is very different.eBay is buying from Some Guy. AliExpress is buying from a sketchy unlicensed and unregulated warehouse in China. Amazon is a store. These are the reputations they cultivated for themselves. reply metadat 13 hours agoprevIs there an archive snapshot of the Towel bar Cam product page as displayed by Amazon?Kinda wondering what the product actually looks like, and how Amazon allowed it to be presented.Edit: whoa, @navels how&#x27;d you do that?! Thank you, amazing: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230527030738&#x2F;https:&#x2F;&#x2F;www.amazo...The product reviews are creepy.--Rest of my comment for posterity:There&#x27;s an image in TFA, though it&#x27;s only a partial, limited view: https:&#x2F;&#x2F;cdn.arstechnica.net&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;12&#x2F;MS-v-...Another article from yesterday contains a zoomed in image but no description: https:&#x2F;&#x2F;blog.ericgoldman.org&#x2F;archives&#x2F;2023&#x2F;12&#x2F;amazon-may-be-...If we knew the product ID it could be checked for existence on archive.org.Anyhow, the research link I used is: https:&#x2F;&#x2F;www.google.com&#x2F;search?q=%22it+wont+attract+attention... reply navels 12 hours agoparenthttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230527030738&#x2F;https:&#x2F;&#x2F;www.amazo... reply gnfargbl 12 hours agorootparentThat link doesn&#x27;t mention anything about it being a \"bathroom spy camera\".It was sold as a nanny cam which is really a legitimate, if slightly distasteful, function. There is an image of it shown with towels on the hook, but it isn&#x27;t stated or implied that it should be used to spy on people as they use the bathroom.I&#x27;m a big fan of holding tech companies to the same standards as other industries, but not a big fan of holding them to unreasonably high standards. reply 0xEFF 12 hours agorootparentIt literally says spy cam in the product title. reply praptak 11 hours agorootparentIt&#x27;s obviously only for the legitimate usage by the James Bond type of spy. reply praptak 11 hours agorootparentprevNanny cam is obviously a crappy attempt at covering the seller&#x27;s ass and no judge should believe it. reply gnfargbl 11 hours agorootparentAre nanny cams not a legitimate product?If they are a legitimate product, how do we tell the legitimate product from this (in your words) \"crappy attempt at covering the seller&#x27;s ass?\"If they are a legitimate product and we can&#x27;t reasonably tell the difference, why should Amazon have banned this product? reply chias 12 hours agoparentprevDear courts, do this one next https:&#x2F;&#x2F;www.amazon.com&#x2F;Bathroom-Shower-Security-Cameras-Outd...The product description is... wild. reply metadat 11 hours agorootparentEven while the lawsuit unfolds, Amazon still hasn&#x27;t done a sweep.Should I be shocked? reply paulddraper 10 hours agorootparentprev> You don&#x27;t have to worry about thieves or your child&#x27;s babysitter any longer.LMAO I hate it when thieves steal my hot water reply chias 7 hours agorootparentGotta throw the babysitter into the description just in case your imagination is so limited that you ACTUALLY think this is about catching thieves taking a shower in your home during a break in. reply tzs 12 hours agoparentprevThe \"Customers who bought this item also bought\" for it is interesting...it seems to be all women&#x27;s bathing suits. reply tyingq 12 hours agorootparent\"It puts the lotion on its skin\" reply space_fountain 12 hours agoparentprevI mean I also have a morbid curiosity, but is there anything that could have been there that would have made it ok? This isn&#x27;t lock picks were a lot of people buy them to mess around with and to get back into their own property reply mamurphy 12 hours agorootparentAnother commenter posted the archive page. No comment on whether this \"made it ok,\" but some of the other photos show the hooks being used in a different context, more like a nanny cam.This one (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231204210803&#x2F;https:&#x2F;&#x2F;m.media-a...) shows hooks in what looks like a mudroom catching an image of a person in black clothing in a ski-mask, indicating a use case of the hook would be to surreptitiously record a thief.On the archive, it is advertised as a \"Hidden Clothes Hook Camera, Mini Spy Camera HD 1080P, Nanny Cam with Motion Detection, Wireless Security Camera for Home&#x2F;Office&#x2F;Pet Monitor, Video Recorder No WiFi Needed, No Audio\" with no mention of it being a \"bathroom spycam.\" reply space_fountain 12 hours agorootparentYeah, but I mean I assume the people selling date rape drugs do a bit of wink, wink, nod, nod, thing too. Do you think literally a single person bought this and used it as a nanny cam? I think I can imagine, maybe it got used outside of a bathroom, or got used by people play acting hidden cameras, aka used with everyone&#x27;s consent, but I don&#x27;t think it gets much worse than this, except maybe for this other product amazon still sells https:&#x2F;&#x2F;www.amazon.com&#x2F;Bathroom-Shower-Security-Cameras-Outd... reply lcnPylGDnU4H9OF 12 hours agorootparent> Do you think literally a single person bought this and used it as a nanny cam?There is actually one person who left a review and seems to have bought it with a less nefarious purpose than spying on someone in the bathroom:> I set this up on my back window to keep an eye out for any suspicious activity in the area behind our house. We share a communal back yard area and people tend to walk through quite often. I love how this camera is disguised and I can place it anywhere!However, it does appear to be marketed for the nefarious purposes despite the comical \"bad guy with ski mask\" you need to hide the camera from for some reason. reply fckgw 12 hours agorootparentprevMaybe some dude who likes to watch themselves shit? reply BobaFloutist 12 hours agorootparentIt&#x27;s pretty common for people taking a sport seriously to record themselves to improve their technique.So maybe competitive shitting? reply rhqq2 12 hours agorootparentprevOr possibly watch others take care of their private business? Either way, facilitating maximum perv is not a great look for Amazon. reply huytersd 12 hours agorootparentprevAbsolutely. Making sure the help is not stealing. Spying on a spouse you suspect is cheating in your home. Filming contractors while they work in a room to make sure they’re not cutting corners etc. reply webmaven 9 hours agorootparentIn theory, you could use a bathroom spy cam for a non-nefarious purpose, such as checking whether someone is flushing their meds instead of taking them, but it&#x27;s a fairly contrived scenario. reply huytersd 9 hours agorootparentI mean one of the examples above is a regular hook. Those can go in any room and there are plenty of non contrived scenarios for those, check my comment above. replybdw5204 12 hours agoprevA spy camera that looks like a towel hook seems like a product that should be illegal to sell. For what legitimate purpose would somebody want a towel hook camera? Don&#x27;t most people put towel hooks in bathrooms?It seems perfectly reasonable to hold Amazon legally responsible for selling this product even if it was a 3rd party seller (not clear from the article). A product whose intended use is to secretly record videos of people in settings where they will probably not be wearing clothes should be unlawful to sell just as it is (or should be) unlawful to knowingly record such videos without informed consent. reply notatoad 12 hours agoparent\"you can&#x27;t sell a spy cam that looks like a towel hook\" is sort of too broad and too specific to be a good law. what does \"looks like a towel hook\" actually mean? a law like this would end up having some unintended consequences, where bad actors use it for something like claiming all their competitors products look like towel hooks.i think what&#x27;s happening here is really the ideal solution: you can sell a camera that looks like anything, but if somebody uses the towel-hook spy cam that you sold for it&#x27;s obvious intended purpose, you&#x27;re liable for the damages. reply superjan 12 hours agorootparentThe “ideal” is not yet reached: the judge rejected a motion to dismiss, there is no verdict yet. And then there’s appeal. Amazon has deep pockets. reply SV_BubbleTime 12 hours agorootparentprevI&#x27;m not sure I can agree with either of you.I definitely don&#x27;t agree with \"thing I don&#x27;t like should be illegal\".And I can&#x27;t really agree with \"People who sold something I don&#x27;t like should be liable for it&#x27;s use\".I think the \"blame\" for objects should lie in the people that misuse them. Now, obviously, it&#x27;s a little hard to come up with legitimate reasons to have a towel hook camera. However... All you&#x27;re asking for is smaller cameras.To which we restart this whole thing with \"These super small cameras should be illegal\". reply wiml 10 hours agorootparentIn the copyright-adjacent space, there&#x27;s the concept of something having no substantial non-infringement-supporting use. It&#x27;s a judgment call, of course, and certainly it&#x27;s abused... but that seems like what people are angling for: making it illegal to sell things which have no legal use.I can come up with a few legal uses for this, though. Not many, and I doubt the primary use of this thing is legal. But it means any law would have to involve some kind of balancing test.I remember people trying to make various open source software illegal under this kind of argument. Debuggers, tool suites, and so on. Because obviously only evil hackers used them, and open source development was a negligible fringe activity. reply notatoad 9 hours agorootparentprev>I think the \"blame\" for objects should lie in the people that misuse themthe case here specifically isn&#x27;t about misusing things though, it&#x27;s about using things for exactly the purpose it was advertised for.\"these super small cameras should be illegal\" is, again, vague and has probably unintended consequences. for example, an ESPCam has all sorts of legitimate uses, but could easily be turned into a spy cam. should that be illegal? reply diputsmonro 12 hours agorootparentprevI understand where you&#x27;re coming from, but the effect of rules like that is to essentially create a system where spying on people with towelhook cameras is totally legal and easily doable unless you happen to get caught.Most laws could be reduced in the same way, but a lot of dangerous illegal activities have proactive protections, like regulations on purchasing and selling guns, etc.Small cameras as a class are probably too broad not to sell as a rule, but cameras sold with a specifically designed case to pass them off as other objects might be a step too much. Of course one could always drill a small hole into anything and add a camera, but we shouldn&#x27;t just be giving the offenders the tools so easily right off the shelf. reply pcl 12 hours agorootparentprevThere is a world of difference between a tiny camera and a tiny camera mounted in a towel hook. reply bryanlarsen 12 hours agoparentprevThe standard answer is to prevent the crime that happens in bathrooms: drug use, rapes, bullying, et cetera.But that&#x27;s a BS answer IMO. If you actually want to prevent the crime, the criminals have to know the surveillance is there. Make the cameras visible, or take the doors off the bathroom stalls[1]. People will be outraged at that; but hidden surveillance is even worse.1: https:&#x2F;&#x2F;www.cbc.ca&#x2F;news&#x2F;canada&#x2F;kitchener-waterloo&#x2F;some-water... reply asveikau 12 hours agorootparentLooking at the photo of the product, it&#x27;d be substantially less sketchy to put it somewhere other than a bathroom for home security purposes. But I know a lot of people are sketched out by putting security cameras indoors, even in a living room or hallway. I&#x27;ve got lots of cameras on my perimeter but none inside the house. reply chankstein38 12 hours agoparentprevYeah I thought the quote in the article claiming there were \"legitimate and legal uses\" was odd. They said \"like in-home surveillance\" but... why do you need to surveil your bathroom? What legal purpose does that serve? Maybe a way to film burglars while they don&#x27;t know they&#x27;re being filmed? But isn&#x27;t part of the reason security surveillance works is visible cameras making people do the \"right thing\" or whatever. The quote was so weird. I don&#x27;t see any legitimate use that doesn&#x27;t have a pretty easy contradiction. reply tiltowait 12 hours agorootparentWe have coat hooks that look similar to this in our foyer. I can definitely see a legitimate use for a camera there, and having it be discreet would be great. reply paulddraper 12 hours agoparentprevAFAIK, \"towel hook\" = \"coat hook\" and is often placed in entryways. reply bhelkey 12 hours agorootparentIt&#x27;s up to the legal system to decide whether this was advertised as a hidden bathroom camera.I imagine that the advertising pictures of the camera holding a towel made this a rather easy decision. reply paulddraper 11 hours agorootparent> a product that should be illegal to sellIs the suggestion that should be \"marketing that should be illegal\"? reply thsksbd 12 hours agorootparentprevWhere Amazon gets nabbed is the listing specifically says towel hook. reply wavemode 12 hours agoparentprev\"should be illegal\" isn&#x27;t really a tenable criteria to require vendors to apply to their products. What does that even mean, broadly? A product is either legal to sell or it isn&#x27;t. reply randyrand 38 minutes agoparentprevIt looks the same as a jacket hook too. reply tyingq 11 hours agoparentprevI guess you could argue nanny cam for when the kid is being bathed, but of course, that&#x27;s not the only activity it would monitor. reply Zigurd 12 hours agoparentprevAmazon doesn&#x27;t need, or, rather, shouldn&#x27;t need laws in order to do the right thing. reply toolz 12 hours agorootparentand what is the \"right\" thing with regards to a coat hook camera?I know someone who put a spy camera in their kitchen to catch a person drugging their beverages. Could&#x27;ve just as easily been a coat hook spy camera.To go at it from another angle, how about those snake cameras that bomb detection units sometimes use. You can use that for illicit purposes and good purposes.I&#x27;m not saying the wrong thing is to ban these things, all I&#x27;m saying is that it&#x27;s not quite so black and white as some people are making this out to be. reply thsksbd 12 hours agorootparentIt&#x27;s advertised as a towel hook. By their own admission, the product is designed, meant and marketed to be used in a bathroom.That&#x27;s what&#x27;s great about the case. They can&#x27;t claim that they&#x27;re not liable because it is meant for legitimate use because they advertise specifically for an illegal use.By their own admission, they have to find a legitimate use of a bathroom spy cam. reply tzs 12 hours agorootparentThe archive.org copy of the listing linked elsewhere in this thread shows it listed as a clothes hook. One of the photos does show towels on it, suggesting it can work as a towel hook, but another shows a coat on it and is not in a bathroom. reply thsksbd 7 hours agorootparentDoesn&#x27;t matter what other uses they marketed; they also marketed it as a bathroom spycam. They have to explain what legitimate use there is of marketing a bathroom spycam.Its kinda nasty, actually. stretching it, there might be legitimate reasons for a camera in a bathroom (say the elderly, or making sure a drug test is done honestly). But a hidden camera? No way. reply Zigurd 12 hours agorootparentprevIt doesn&#x27;t matter what you, or I, think is the right thing to do. Commerce is a consensual act. I can deny you a deal on any basis. Amazon did not exercise judgement. reply scrollbar 12 hours agoprevThe article links to an amazon search results page for \"bathroom spy camera\"Here is the first result: \"1080P Bathroom spy Shower Nozzle Hidden Spy Security Cameras Mini Camera DVR 32GB,Mini Nanny Cam Smart Home, Indoor Outdoor Baby Camera\"https:&#x2F;&#x2F;www.amazon.com&#x2F;Bathroom-Shower-Security-Cameras-Outd...Kind of incredible that this still continues. They at least give some kind of cover for the use case of a \"baby camera\" but honestly even that feels so flimsy. This is disturbing. reply wkat4242 4 hours agoparent> \"This is a 1080P mini Shower shelf spy camera that looks like an ordinary can of Shower shelf. The camera is so well hidden that no one will know that the Shower shelf actually contains a mini bathroom spy camera. Because it is so well hidden, you can put it anywhere, even in the bathroom, and no one will be suspicious. \"I don&#x27;t know who buys their \"Shower shelves\" in cans but this whole blurb makes no sense. The picture shows a shower head, not a shelf or a can.The malicious intent is clear at the end of the quoted paragraph though. Not to mention that I wouldn&#x27;t know where else to use a shower head other than \"even in the bathroom\". reply walrus01 12 hours agoparentprevthe \"baby camera\" part is just the vendor keyword-stuffing for search results so that their product will show to more people. reply neilv 12 hours agoprevI&#x27;d expect Amazon product safety people to know what these are. Spycams have been widely advertised for decades, often overtly targeted specifically for use of spying on women.For example, pretty early in Web history (before WiFi and then IoT were popular), \"X10\" cameras were advertised heavily: https:&#x2F;&#x2F;pages.cs.wisc.edu&#x2F;~kuan&#x2F;x10.html reply mtlmtlmtlmtl 12 hours agoparentI mean it&#x27;s a spy camera that only makes sense in a bathroom. There&#x27;s even a showerhead one sold on Amazon.I&#x27;m not even sure it&#x27;s humanly possible to look at one of these and not realise the primary use case is criminal.The only conclusion I&#x27;m left to draw from this is either that no actual review takes place, or that the review is merely there to ascertain \"is this product literally illegal right now?\" reply autoexec 11 hours agorootparentYou can create convoluted excuses for the showercam too. For example, cases where you wanted to keep an eye on a babysitter while they bathed your child or a nurse or caretaker bathing an adult&#x2F;elderly family member who was disabled. reply lakpan 11 hours agorootparentPh-lease! You don’t need to be that damn close to “keep an eye on”, and actually I don’t think you’d really want to be that close. reply isk517 12 hours agoparentprevHoly crap, that one that flat out says &#x27;We are not responsible for what you do with this camera&#x27;. Usually that is something they slip into the fine print, not make the main point of the advertisement. reply Someone1234 13 hours agoprevI love technology, but some things we&#x27;re able to build today cheaply and using mass-market parts concerns me. Hidden cameras can be so good now that it is impractical for someone to find them.You may disagree with that assertion, but I&#x27;d put to you that maybe you just haven&#x27;t seen some of the top-end products where the only clue is pin-hole sized, or even invisible like hidden behind the LCD screen of a set top box&#x2F;clock&#x2F;etc. reply pixl97 12 hours agoparentHidden cameras, hidden microphones, hidden sensors, hidden wifi, etc.Miniaturization has and will lead to these devices becoming more powerful and everywhere in our environment. reply autoexec 11 hours agoparentprevAt lest in this case it was not a top-end product. The girl found out about it and interestingly she&#x27;s even accusing amazon of \"marketing and distributing a defective product\" reply onionisafruit 12 hours agoparentprevOr maybe you have seen some top-end products without realizing it. reply TeMPOraL 12 hours agorootparentOr, in this case, perhaps some of the top-end products saw you. reply kennethrc 11 hours agorootparent\"In Soviet Russia, ...\"OK, I&#x27;ll see myself out :) reply onionisafruit 6 hours agorootparentIn Soviet Russia top end products see themselves out replyjacquesm 13 hours agoprevYou wonder why they even have a review team if this passed. reply belval 12 hours agoparentThat part is confusing to me because it specifically calls out items that are for violating privacy. Any defense from \"we are not responsible for how a product is used as long as it&#x27;s legal\" or \"our safety team inspects products that could hurt people\" (AC appliance without a properly grounded case) would have sounded much more reasonable to me.The reality of it is probably that reviewers can only spend ~1 minute per item before flagging it or not, the reviewer was a bit on \"autopilot\" and didn&#x27;t flag it because it doesn&#x27;t look like a camera at all. reply bluGill 12 hours agorootparentYou cannot possibly review this in one minute. You need a team of different experts and they need time to think. If you saw this for one minute before looking at this article you probably wouldn&#x27;t think about this use case - even though it is obvious once someone points it out. So Amazon needs to show they gave the review team enough time to think about this type of thing.Amazon might be able to get out of this if they can show the court a long enough checklist of things they did look for that this does pass. If that list is long enough (a term I specifically did not define!) they can argue they did due diligence, this is just different from everything they thought of and so it slipped threw the cracks. Of course the checklist better have a clear procedure for \"something else not on this list\" and a it needs to be clear anytime something not on the list is thought of that the process gets that new thing on the list. This is NOT easy or cheap. reply belval 12 hours agorootparent> You cannot possibly review this in one minute.I didn&#x27;t mean to imply that you can. It&#x27;s more that at Amazon&#x27;s scale, they are surely constrained by how many new items are put up for sale every second. If even just 1&#x2F;100 needs to be reviewed, then that&#x27;s a considerable amount of work. Once the pipeline is setup their workforce probably got progressively better so they increase the review&#x2F;day targets to match. That loop does not have a lot of feedback so they probably raised it too high at some point and this is the result.All of that to say, it&#x27;s much more likely to be a process failure than anything else. They probably tried to optimize that process but cut too close to the bone and this is the result. reply maeil 10 hours agorootparentThey choose to be constrained. Do you know just how big of a % of their budgets Tencent and the likes spend on employing people who maintain censorship on their Chinese platforms? Amazon, Meta et. al could spend the same amount to keep their platforms clean and an actual boon to society instead of scam-infested, negative externality fests.But they don&#x27;t. They could though. reply tdeck 12 hours agorootparentprevHow about this shower head spy camera? Does it take more than a minute to figure out how this might violate someone&#x27;s privacy?https:&#x2F;&#x2F;www.amazon.com&#x2F;Bathroom-Shower-Security-Cameras-Outd... reply ceejayoz 12 hours agoparentprevTo be able to tell press inquiries \"we have a review team\". reply bluGill 12 hours agorootparentOf course to the courts that means an effective review team, and so gets Amazon in more trouble for them not being effective. (note Amazon is not setup like ebay, and thus Ebay can get by without a review team in ways amazon cannot despite being similar) reply jacquesm 12 hours agorootparentApparently they spent 8 months in court arguing this already. Think about that: instead of just admitting they fucked up they are running out the clock on the legal side. Insanity, that alone should be enough to double or triple any damages. reply hnburnsy 11 hours agoprevSort of related...https:&#x2F;&#x2F;www.kxan.com&#x2F;investigations&#x2F;son-of-buc-ees-co-founde...>The son of a co-founder of the nationally renowned Buc-ee’s convenience store was arrested Tuesday in Travis County and faces 28 separate state jail felony charges of invasive visual recordings. A woman reported she and a few friends were visiting the lake house with Mitchell Wasek when one friend, who works cybersecurity for the Department of Defense, noticed a charging port with a hidden camera plugged into the wall of their bathroom, court records state. The group of friends left with the camera and on its micro-card found dozens of videos of themselves and other people in bathrooms and bedrooms at the lake house as well as at Mitchell Wasek’s Dallas apartment, according to court records.Another story reports...>Amazon records linked purchases of a half-dozen spy cameras and hidden cameras to Mitchell Wasek, the affidavit says. reply kshacker 13 hours agoprevSo can I sell a camera with the following description?SpyCamDisclaimer: should not be used for spying reply btilly 12 hours agoparentThere is historical precedent.My favorite were winemaking kits sold during Prohibition that told you what you needed to avoid doing, because doing that would make wine.https:&#x2F;&#x2F;grapecollective.com&#x2F;articles&#x2F;prohibitions-grape-bric... reply unaindz 11 hours agorootparentThat&#x27;s really funny, thanks for sharing.It&#x27;s worth to point out that the article tells it was legal to make wine in your own home during the prohibition because of a loophole. reply mtlmtlmtlmtl 12 hours agoparentprevIt&#x27;s a common trope in grey markets.Not sure to what extent this is still the case, but when I was messing around with greyzone drugs about a decade ago, they tended to be sold on technically legal, UK, Swedish, Polish etc web stores. They&#x27;d have names similar to illegal drugs they were analogues of and like descriptions of the effects. But have the disclaimer \"not for human consumption. Research purposes only\".Of course even the purportedly pure chemical products were unsuitable for actual research or standards use due to lack of attestation to purity(at least with most vendors) and so on.It didn&#x27;t affect the legality, probably just a weak attempt to avoid potential liability. reply bluGill 12 hours agoparentprevMaybe. Can you should legitimate uses that people actually buy this for? There are legal uses for a spyCam. Check with your local laws though as what is legal is different in different areas. For example you can use a spyCam to see who&#x2F;what is knocking over your garbage can - anything you film would be legal. I&#x27;m sure there are a lot of other legal uses for a spyCam. reply folmar 12 hours agoparentprevThis is the situation of cannabis seeds in at least large part of the EU. You can have&#x2F;buy&#x2F;sell the seeds but it&#x27;s illegal to grow them. reply jjk166 10 hours agoparentprevSpycams are legal to sell without the disclaimer, so adding the disclaimer isn&#x27;t going to make it less legal. reply 43 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A judge in West Virginia has denied Amazon's motion to dismiss a lawsuit brought against the company over a spy camera sold on its platform.",
      "The plaintiff alleges that Amazon inspected the camera multiple times but failed to prevent it from being used to capture photos in her private bathroom.",
      "The judge ruled that Amazon cannot claim shock as the product descriptions suggested using it to record private moments in a bathroom."
    ],
    "commentSummary": [
      "Hidden spy cameras disguised as everyday items are being sold on Amazon, causing controversy and raising questions about legality, ethics, and responsibility.",
      "There is a debate about regulating third-party sellers and the decline in product quality, as well as concerns about invasion of privacy and the facilitation of potential illegal activities.",
      "Different perspectives exist, with arguments made for legitimate uses of these devices as well as concerns about their potential misuse."
    ],
    "points": 233,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1701721992
  },
  {
    "id": 38524599,
    "title": "Zen: Open-source ad-blocker and privacy guard for Mac, Windows, and Linux",
    "originLink": "https://github.com/anfragment/zen",
    "originBody": "Zen: Your Comprehensive Ad-Blocker and Privacy Guard There is, simply, no way, to ignore privacy. Because a citizenry’s freedoms are interdependent, to surrender your own privacy is really to surrender everyone’s. Edward Snowden, Permanent Record Zen is an open-source system-wide ad-blocker and privacy guard for Windows, MacOS, and Linux. It works by setting up a proxy that intercepts HTTP requests from all applications, and blocks those serving ads, tracking scripts that monitor your behavior, malware, and other unwanted content. By operating at the system level, Zen can protect against threats that browser extensions cannot, such as trackers embedded in desktop applications and operating system components. Zen comes with many pre-installed filters, but also allows you to easily add hosts files and EasyList-style filters, enabling you to tailor your protection to your specific needs. Downloads During the first run, Zen will prompt you to install a root certificate. This is required for Zen to be able to intercept and modify HTTPS requests. This certificate is generated locally and never leaves your device. Windows x64: 💾 Installer📦 Portable ARM64: 💾 Installer📦 Portable Unsure which version to download? Click on 'Start' and type 'View processor info'. The 'System type' field under 'Device specifications' will tell you which one you need. MacOS x64 (Intel): 💾 Installer📦 Portable ARM64 (Apple Silicon): 💾 Installer📦 Portable Unsure which version to download? Learn at Apple's website. Linux x64: 📦 Portable Support for installation via package managers is coming soon. Screenshots Request history Filter list manager Request history shows all requests blocked by Zen. Each request can be inspected to see which filter and rule blocked it. Zen comes with many pre-installed filters. You can also add your own by providing a URL to a hosts file or an EasyList-style filter. License This project is licensed under the MIT License. Some code and assets included with Zen are licensed under different terms. For more information, see the COPYING file.",
    "commentLink": "https://news.ycombinator.com/item?id=38524599",
    "commentBody": "System-wide open source ad blocker for Mac, Windows, and LinuxHacker NewspastloginSystem-wide open source ad blocker for Mac, Windows, and Linux (github.com/anfragment) 214 points by krpl 10 hours ago| hidepastfavorite143 comments anfragment 5 hours agoHello HN!Having just posted the app to a couple of small subreddits before sleep and then waking up to being on the front page over here is quite an experience :) I was hoping to make a Show HN post after giving Zen a bit more polish, but I guess here we are.Thanks for all the constructive feedback. I totally share your concerns about its security and likewise wouldn&#x27;t use some unverified application trying to install a root CA on my system. For those wanting to audit the certificate generation and installation code, feel free to take a look at certmanager&#x2F;get.go and certmanager&#x2F;install_{platformname}.go. It is mostly self-contained and, I hope, easy to understand. The lack of any instructions on how to delete the certificate is an oversight on my part, and I&#x27;ll be working on this. Regarding the binaries: all of them are built on GitHub&#x27;s CI. I wish there was a way for users to verify this fact, but to my knowledge, there is no way to do that currently. You can run and build the app yourself using Wails (https:&#x2F;&#x2F;wails.io&#x2F;docs&#x2F;gettingstarted&#x2F;installation). I&#x27;ll be sure to add more instructions to the repo in the coming days.As always, any feedback, help, and suggestions are much welcome. reply mike_d 5 hours agoparentThank you for starting this project. There is a bit of overall negativity in this thread from users who don&#x27;t fully understand what is going on here, but please don&#x27;t get discouraged. This is ultimately the correct approach to addressing browsers that have a financial interest in serving ads. reply quyleanh 4 hours agoparentprevThank you for your work. I appreciate it very much. Please don’t be down motivation by the negative comments.About your comment of security, I think it’s better to make a FAQ file and write it there to clearly explain.And one suggestion is I hope zen will have function to choose upstream DNS server (can be DoH or DoT server). It will be the best block ads with combo DNS and HTTPS. reply hummingn3rd 3 hours agoparentprevThank you for your work! If you are interested in users verifying your binaries, maybe sigstore could help you.https:&#x2F;&#x2F;www.sigstore.dev&#x2F; reply PrimeMcFly 2 hours agorootparentAre any well known projects using sigstore? It looks interesting. reply tejohnso 10 hours agoprevI&#x27;m comfortable with a DNS based blocker (pi-hole) and it seems to work quite well. Bonus: It works across all devices on the network, rather than installing something onto the OS. reply anticorporate 9 hours agoparentI seem to end up regretting anything I do at the network level to block traffic. It always seems to pop up that one weird time I actually do need something from a blocked domain to load, and it takes me way too long to remember that&#x27;s what I did to block it. reply netsharc 9 hours agorootparentThat&#x27;s when you connect to your VPN.I have a network configuration with 2 dnsmasqs, 1 with pi-hole-style hosts block, and 1 without, and most of my devices get the ad-blocking DNS, 1 gets the \"unfiltered\" DNS.To do this from the DHCP component of dnsmasq, you can tag MAC addresses and create different configurations (including which DNS they get) for each tag, e.g. https:&#x2F;&#x2F;github.com&#x2F;imp&#x2F;dnsmasq&#x2F;blob&#x2F;770bce967cfc9967273d0acf... reply Cannabat 9 hours agorootparentThat&#x27;s a simple and practical solution to a common problem. Thanks for sharing. reply woleium 5 hours agorootparenti have four ssids on my wireless network. One is filtered DNS, one is unfiltered, one for iot devices and one thats vpn’d to the USA. reply 000ooo000 8 hours agorootparentprevI&#x27;m not refuting what youre saying in any way; this is just a related suggestion for anyone using PiHole who occasionally runs into what you&#x27;ve described.There&#x27;s an Android app called flutterhole which can connect to and activate your pihole&#x27;s &#x27;pause blocking&#x27; feature. I have found this to be the easiest way around the scenario the poster above has mentioned. Doesn&#x27;t help with figuring out PiHole is responsible obviously. HTH. reply alargemoose 8 hours agorootparentSince you shared an android app, I’ll share the iOS app I use for the same purpose, called “Pi-Hole Remote”https:&#x2F;&#x2F;apps.apple.com&#x2F;app&#x2F;id1515445551 reply califsp484 5 hours agorootparentThis looks convenient and powerful. Good share!I personally setup an instance of Homebridge on the device running Pi-Hole, then use HomeKit on my Apple products to turn Pi-Hole on&#x2F;off as if it were a light bulb. reply bigethan 5 hours agorootparentprevPi-holes have an api that lets you hit a url that’ll pause the blocking for a configurable time. I use a Mac shortcut, but even a bookmark would work reply yumraj 6 hours agorootparentprevI have a very simple setup that works for us.ISP’s router has unrestricted Wi-Fi access. I run a router behind it with restricted (via pi-hole) access.All devices connect to the restricted Wi-Fi. Any time I need unrestricted access, I connect to the ISP router Wi-Fi for some time and back to the restricted when done. reply PrimeMcFly 1 hour agorootparentDon&#x27;t you mean you run the restricted router in front of the ISP router? reply roblh 9 hours agorootparentprevI had that same issue until I started using mine over tailscale. One of my computers acts as the DNS server for the whole network with pihole on it, and then anytime I need to get around something I temporarily disconnect from my tailnet. Super nice cause then I get no ads on my phone too. reply godelski 7 hours agorootparentprevI find it also a bit frustrating because browsers may even ignore your network&#x27;s DNS settings so you can easily get unexpected behavior (yes, I know it&#x27;s expected if you are a domain expert but I&#x27;m not and it shouldn&#x27;t be surprising when users are shocked that they implement a pihole and see their machine is using a different DNS than expected. I&#x27;d actually expect novice users to be surprised in this case) reply hulitu 2 hours agorootparent> browsers may even ignore your network&#x27;s DNS settingsThey should&#x27;t. Bypassing policy is malware behaviour.Funny that they ignore \"my\" network DNS, not ISP&#x27;s. (in the name of freedom) reply thedaly 9 hours agorootparentprevGood point. Its fine if I&#x27;m the only one using the network, but I&#x27;ll admit it can take a bit before I connect the dots between pi-hole and \"this link I&#x27;m clicking off google won&#x27;t load\". reply scosman 9 hours agoparentprev+1I connect to mine over tailscale DNS.I recommend adding a tray icon that disables it for 60 seconds (super helpful for the odd site that serves something critical from an ads domain… like my bank).Only downside is apps don’t have to use system DNS and a few mobile ones are wise enough to bypass. reply 1vuio0pswjnm7 2 hours agoparentprev\"Bonus: It works across all devices on the network, rather than installing somthing onto the OS.\"A proxy can be installed \"onto the OS\" of a RPi. It does not have to be installed on the computer used to view web pages.A Pi-Hole is a modified dnsmasq installed \"onto the OS\" of a RPi. reply PrimeMcFly 2 hours agorootparentThey were clearly referring to the OS of a device someone would browse on, not the OS of a network device. reply Kadin 5 hours agoparentprevI don&#x27;t mind PiHole, but it doesn&#x27;t do nearly as good a job of ad blocking as a \"real\" browser plugin does.The amount of crap that still comes through when I turn off uBlock -- but am still using PiHole DNS, which is always active on my home network -- is a lot.Honestly I don&#x27;t think DNS-based adblocking is really viable, long-term. It&#x27;s just too easy for advertisers and dirtbag website operators to get around it. There&#x27;s just no substitute for controlling the retrieval of content elements and their presentation from the application where the user is doing the interaction.This is why keeping browsers out of the hands of adtech corporations is pretty important; once they control that presentation layer it&#x27;s largely game over. They can just tunnel all the traffic through a single connection to a relay server, if they want to, and there won&#x27;t be shit a user can do about it once they&#x27;ve decided that&#x27;s the only browser they can use. reply cloudking 8 hours agoparentprev+1 using AdGuard on Home Assistant Raspberry Pi reply brightball 7 hours agoparentprevI’m using NextDNS for this and it’s great. reply kgwxd 9 hours agoparentprevCan confirm, never leaving the house is a very effective way to avoid unpleasant interactions :) reply exitzer0 10 hours agoprevIt is just not wise to allow some random application to MiTM your SSL traffic. reply develatio 10 hours agoparentIf you can read the code and asure that the traffic won’t be sent to a malicious third party, why not? What is the concern? reply lxgr 5 hours agorootparentIf I can miss subtle and not-so-subtle bugs in my own team&#x27;s code that I&#x27;m working on every single day, what are the chances I&#x27;ll get it right on somebody else&#x27;s project?Being able to MITM any HTTPS request on my system is a privilege I&#x27;d not grant lightly. It&#x27;s up there with browsers, browser extensions (with \"all content on all sites\" access), and password managers in terms of blast radius in case anything goes wrong. reply eviks 1 hour agorootparentprevThe concern is that it&#x27;s a huge waste of time for everyone to read the code, and a significant investment of time for anyone to do so, that&#x27;s why not reply sedatk 10 hours agorootparentprevHow would you know if the binary was built from the code verbatim?How would you know that for future updates? reply jmvoodoo 10 hours agorootparentThe build steps are provided as a GitHub action in the repo. You can audit the build pretty easily, or if you&#x27;re super paranoid you can build it yourself by following the build steps. reply themerone 9 hours agorootparentEven if the app is trustworthy, it still adds an attack vector to your system. It could have a bug, or the certificate could be exploited by another program. reply anigbrowl 9 hours agorootparentEqually true of every ad reply lolinder 9 hours agorootparentThis would be a reasonable argument if there weren&#x27;t many alternative ad blocking methods that don&#x27;t require MITMing your TLS traffic. reply rollcat 8 hours agorootparentIt&#x27;s in no way worse than running a single browser extension with overly broad privileges. If this method of adblocking gains more traction (quite possible, as Google keeps moving to damage in-browser ad blockers), I expect the implementation to receive a lot more scrutiny.I think we have to face the reality that web browsers might no longer be considered \"user\" agents. reply lelanthran 4 hours agorootparent> I think we have to face the reality that web browsers might no longer be considered \"user\" agents.I think too many techies are, much like yourself, contributing to the problem by refusing to move away from Chrome for \"reasons\"[1], and then compounding it by refusing to acknowledge that \"web browsers\" != \"Google Chrome\".[1] The \"reasons\" are of dubious quality. Myself and many others are able to do all normal web-browsing from firefox or firefox forks with no functional or performance degradation. reply rollcat 18 minutes agorootparent> I think too many techies are, much like yourself, contributing to the problem by refusing to move away from Chrome [...]Contrary to your assumptions, I&#x27;ve been quite vocal against the Chrome&#x2F;Blink monoculture for a while. Unfortunately there is a legit case for it; several generations of \"low-end\" devices (anything older than 10 years basically), that are still quite capable and in common use, where the difference in performance between Firefox and Chromium becomes quite noticeable, especially as you try to watch video.I don&#x27;t think the problem is \"techies\", we have zero influence outside our own circles - see the historical rates of Linux adoption. The problem is we need the good ol&#x27; hammer of antitrust to start swinging again. We also need the regulators to be smart; if we get really unlucky, they will target iOS Safari instead. (This would be good in a healthy ecosystem, but would only serve to further entrench Google&#x27;s position in the current situation.)By the way, using a filtering&#x2F;rewriting proxy has other merits, especially on said older hardware; you can rewrite the entire web page to make it more lightweight and accessible. Check out miniwebproxy[1] and medium-rare[2]. It&#x27;s also quite simple to write one; you need maybe a hundred lines of Go to start getting results. I&#x27;ve been experimenting with integrating Readability[3][4]; and I think there&#x27;s more potential to this approach.[1]: https:&#x2F;&#x2F;humungus.tedunangst.com&#x2F;r&#x2F;miniwebproxy[2]: https:&#x2F;&#x2F;humungus.tedunangst.com&#x2F;r&#x2F;medium-rare[3]: https:&#x2F;&#x2F;github.com&#x2F;go-shiori&#x2F;go-readability[4]: https:&#x2F;&#x2F;github.com&#x2F;mozilla&#x2F;readability lolinder 7 hours agorootparentprev> I think we have to face the reality that web browsers might no longer be considered \"user\" agents.If by \"web browsers\" you mean specifically Chrome, yes. Firefox, Brave, and others are all committed to supporting MV2, and will continue to serve my interests as a user for the foreseeable future. reply shiroiuma 7 hours agorootparentprev>I think we have to face the reality that web browsers might no longer be considered \"user\" agents.Well obviously, if you keep insisting on using a browser made by Google, an ad company. reply zzo38computer 6 hours agorootparentprevI think it is a mistake for programs that have SSL traffic to not have an option for a user-defined non-secure proxy (usually this would be for a proxy running on the local computer, rather than a remote proxy). A non-secure proxy would save energy (since then it doesn&#x27;t need to decrypt and encrypt it twice) as well as allowing use of newer (or older) cipher methods in programs that do not support them. reply sedatk 7 hours agorootparentprevHow do you know that the downloaded binaries are built by the GitHub action? If I must audit the code and build it myself every release, then how is this a usable product? reply mtizim 7 hours agorootparentNot a product. It&#x27;s literally free, free as in free speech, and free as in you&#x27;re free not to use it.Building the code yourself for every update is also a solved problem on every system with a feature complete package manager, including Windows. Trust is not so easily solvable, but if you trust nobody, you can choose to look at ads. reply sedatk 6 hours agorootparent> Not a product. It&#x27;s literally free, free as in free speech, and free as in you&#x27;re free not to use it.Sorry, I change my question to \"how is this a usable free?\" reply Centigonal 7 hours agorootparentprevWhere is the bar for software you trust? do you trust your OS, router firmware, VPN client, web browser, etc? reply sedatk 6 hours agorootparentIn fact, that&#x27;s what I&#x27;m trying to say. The line we draw at \"hey we can at least audit open source\" is a fully imaginary one. It&#x27;s a false comfort we create. It&#x27;s the Kool-Aid we drink.I don&#x27;t have any trust in any of those components you mentioned, but I came to terms with the risks associated with using them as part of my threat model. However, I find the notion that open source is somewhat safer because \"we can audit it\" exaggerating if not misleading. It&#x27;s not a valid argument, and it should never be used because there&#x27;s no way to do it in an either practical or consistent way for the users of the said product. reply hnfong 6 hours agorootparentThere&#x27;s a difference between \"you&#x2F;I can audit it\" and \"we (collectively) can audit it\".You&#x27;re not living in a vacuum. The more users (and perhaps more importantly, contributors) an open source product has, the less likely it has intentional backdoors built into it. reply sedatk 6 hours agorootparentWhat&#x27;s your process to validate if that said software has been collectively audited sufficiently? replygodelski 7 hours agorootparentprev> You can audit the build pretty easily,Please define \"easily\" reply rubyn00bie 10 hours agorootparentprevYou could just compile it. For updates you could like pull down the new code, check the diff, and rebuild. reply meesles 9 hours agorootparentprevNo one will do this, and those that read source code during installation do not review it for every upgrade. It&#x27;s one of those &#x27;just do this!&#x27; arguments that has little to no basis in reality. There&#x27;s more of them replying to the parent comment: \"Just do this! Just compile a thing! Just verify signatures for every update!\". Come on... Meanwhile the negatives immediately implicate anyone with access to the executable.You don&#x27;t know this person, and I see no personally identifiable information to make me trust them. They could literally be a state actor right now! We&#x27;ve also seen so many large supply-chain attacks over the last decade which could easily target a tiny project like this.I agree with the parent - not wise. reply develatio 9 hours agorootparentBut doesn’t that apply to chromium &#x2F; firefox as well (or any other big application). Web browsers are insanely huge, nobody is reading the entire code. What makes this different? reply vlovich123 6 hours agorootparentTo take a different argument, it’s another party that’s less well known that you have to trust. The more parties you trust, the less secure things become. Whether that additional risk is something you want to take on is a personal decision. MITM SSL traffic would make me uncomfortable. reply jolux 9 hours agorootparentprevNo, because Google and Mozilla pay loads of people to write and review the code that goes into their browsers and ensure it’s not malicious. reply pinewurst 8 hours agorootparentGoogle pays loads of people to conceive and write code that is malicious to endusers e.g. those not paying it for eyeballs. reply vore 8 hours agorootparentIs Google going to hack your bank account? reply autoexec 1 hour agorootparentThey&#x27;re going to do everything they can to learn how much money you have in your account and then they&#x27;ll relentlessly try to manipulate you into losing more of your money. reply toomanydoubts 7 hours agorootparentprevIf we start with the reasonable assumption that \"being malicious\" !== \"hacking a bank account\", then the answer to your question does not matter at all. reply Dalewyn 6 hours agorootparentprevSo I can apply the same logic to Microsoft concerning Windows, Office, etc. and you wouldn&#x27;t dispute me, right?Incidentally, no I have no objections against closed source. I find the religious dogma behind FOSS patently stupid. reply jolux 6 hours agorootparent> So I can apply the same logic to Microsoft concerning Windows, Office, etc. and you wouldn&#x27;t dispute me, right?I mean, no, I would dispute you, because everything Microsoft is doing in those products isn&#x27;t publicly available for the world to see.Still probably pretty unlikely because those products are hugely popular and widely scrutinized. reply Dalewyn 2 hours agorootparentSo you would dispute me, but not for the criteria you originally posed. reply meesles 9 hours agorootparentprevDo you trust Google + Firefox as much as this random developer? Seems pretty different. reply 1231232131231 9 hours agorootparentprevIf you really wanted&#x2F;NEEDED this, you could definitely go through all the code. It would take a bit, but it&#x27;s doable with determination (lol). Also, you don&#x27;t have to necessarily review all of the code every update. All you have to do is view the changes&#x2F;new commits every time you want to update.The hardest part is determining that you want to go through all of this hassle to replicate something browser extensions already do (for the most part). reply lxgr 5 hours agorootparentIf you believe you can find even just all unintentional bugs, let alone deliberate security vulnerabilities, you&#x27;ve never looked at the underhanded C contest [1].> All you have to do is view the changes&#x2F;new commits every time you want to update.These can be thousands of lines of code per day in busy projects.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Underhanded_C_Contest reply imiric 9 hours agorootparentprevI&#x27;m as paranoid about this as you, but this type of verification seems easier today with AI tools. I&#x27;m not aware of any that do this, but if LLMs can give insight about what a piece of code is doing, they can surely be trained to detect possible suspicious behavior. Perhaps even by inspecting a binary, but certainly by processing code. reply lxgr 5 hours agorootparentMaybe for well-intended code (and even there I have my doubts – the halting problem says hi!), but most definitely not for malicious backdoors at this point. reply krpl 9 hours agorootparentprevhttps:&#x2F;&#x2F;any.run&#x2F;cybersecurity-blog&#x2F;chatgpt-powered-analysis-... Sort of did this reply meesles 9 hours agorootparentprevI think that&#x27;s a great use-case. I&#x27;d love a real-time security scanning system covering as many open source projects out there as possible. reply RockRobotRock 9 hours agorootparentprevPlease don&#x27;t downvote an earnest and important question which should be answered reply I_Am_Nous 10 hours agoparentprevNo but it might be fun to play with in a Qubes environment or similar where you can inspect packets going in and out for anything weird happening. reply lxgr 5 hours agorootparentLooking at packets will only get you so far if they&#x27;re encrypted.Software like this has way too many opportunities to exfiltrate information for that approach to work. reply fostware 8 hours agoparentprevBut as developers, we&#x27;re happy enough to suggest `wget -qO - https:&#x2F;&#x2F;github&#x2F;urlsudo bash -s` reply zzo38computer 6 hours agorootparentUnfortunately many people do like that, but I hate it and I don&#x27;t do stuff like that (and it seems many other people hate it too; fortunately you can just download the file without immediately executing it, if you want to view (and possibly modify) it). reply kiney 8 hours agorootparentprevNo, we&#x27;re not. reply mike_d 5 hours agoparentprevWhy not? We allow Cloudflare to do it every day. reply CodeNest 10 hours agoprevApplication doesn&#x27;t provide a way to remove installed certificate. Don&#x27;t use this app. reply rosywoozlechan 10 hours agoparentThe way Charles does this is by generating a root certificate dynamically and makes it really easy to remove by giving you instructions for how to install and remove it just for Chrome for example:https:&#x2F;&#x2F;www.charlesproxy.com&#x2F;documentation&#x2F;proxying&#x2F;ssl-prox...https:&#x2F;&#x2F;www.charlesproxy.com&#x2F;documentation&#x2F;using-charles&#x2F;ssl... reply lxgr 5 hours agorootparentThat only works on Windows, I believe (and maybe on Linux). Chrome on macOS uses the system root certificate store. reply passerby1 9 hours agoprevHow many apps do use certificate pinning and so will be broken as a result of this app&#x27;s MITM? reply SushiHippie 8 hours agoparentAfaik most desktop applications don&#x27;t do certificate pinning. Mobile apps definitely do.Except things like browsers (e.g. Firefox, Chrome) or python that ship their own root CA trust store. reply Xeamek 9 hours agoprevI don&#x27;t know how it actually works, but won&#x27;t website like youtube simply deny you access if it detects that the ad related request timed out? I imagine that browser extensions actually tap into the site&#x27;s code and somehow go around such detection. But if this is a simple firewall, how will this work against any website that doesn&#x27;t just default to most trivial \"import ad service\", but rather actually takes steps to block the ad blockers (Like youtube)? reply nurettin 7 hours agoparentI&#x27;ve wondered what-if scenarios like this for a long time. I see them being implemented smaller websites, but never at scale like amazon.com or YouTube where they serve petabytes per second. My conclusion is: it gets so expensive to track and block users at session level that they just let go. reply Kadin 5 hours agorootparentThat&#x27;s only true if only a small percentage of users actually use that particular ad-blocking strategy. If a significant number of users did, then it would be a real concern.Although I think YouTube et al see an increasing amount of revenue and viewership coming from apps... and if they could, I suspect they would kill their web sites in favor of apps where they have much more control. reply normalaccess 10 hours agoprevI haven’t had time to look at the code. Is this generating a unique root certificate per install? If not this could become an attack vector to decrypt TLS traffic. reply lxgr 5 hours agoparentEven if it does create unique root certificates it is a massive attack vector. How good is the tool at protecting the corresponding private key from other software on the device, for example? reply hug 10 hours agoparentprev> During the first run, Zen will prompt you to install a root certificate. This is required for Zen to be able to intercept and modify HTTPS requests. This certificate is generated locally and never leaves your device. reply thefz 1 hour agoprev> During the first run, Zen will prompt you to install a root certificate.Well, nope. reply quyleanh 9 hours agoprevI can see it&#x27;s some kind of replacement for uBlock Origin when MV3 is official. reply userbinator 5 hours agoprevIt&#x27;s interesting to see the paranoia FUD in the comments here around MITM, when this is happening on your own machine under your control, and it&#x27;s open-source too. It should be painfully obvious by now that Big Tech is using \"security\" as an excuse to effectively force-feed you whatever they want, and depriving you of the right to refuse should be illegal.Fuck the corporate-authoritarians who are taking away the freedom to do what we want to content that enters our machines. They&#x27;ve been fighting that war for a long time, and we can see through the tactics they&#x27;ve been using.I&#x27;ve been using Proxomitron as a filtering proxy for over 2 decades after its author&#x27;s death, and it is even more powerful than this (but requires more setup and tuning.) reply netsharc 9 hours agoprevDoes an ersatz root certificate work with HSTS? A quick DDG seems to suggest it&#x27;s still possible to disable HSTS on the browsers: https:&#x2F;&#x2F;appuals.com&#x2F;how-to-clear-or-disable-hsts-for-chrome-... reply josephcsible 9 hours agoparentAs long as the custom root certificate is properly installed, HSTS will still work. reply acl777 8 hours agoprevHow does this compare to using a hosts file with known ad servers?like: https:&#x2F;&#x2F;github.com&#x2F;StevenBlack&#x2F;hosts reply mike_d 5 hours agoparentHosts files have never been a good idea for ad blocking, I really wish users would stop promoting them. reply hellotomyrars 4 hours agorootparentIt isn&#x27;t the best way to do it as far as effectiveness goes but it it is pretty good, especially for web browsing. It is the easiest way to do it on my iOS devices (as a fake VPN profile) and can be switched off in a corner case where I need to access something it is filtering out.It isn&#x27;t as flexible or powerful as other methods, but it is very simple. Tools are all about how you use them. Ignoring them isn&#x27;t any better than suggesting them. reply quyleanh 5 hours agoparentprevAn easy example for comparison is hosts file cannot block YouTube ads, while this one can. reply lxgr 5 hours agorootparentHow? Can&#x27;t Youtube just detect which expected resources are not loading and refuse to play? reply quyleanh 3 hours agorootparentI know the YouTube ads is getting more complicated now, but it&#x27;s just simple example. Another is hosts file&#x2F;DNS blocking will remain the blank space on web page, but this one will not. reply satvikpendem 9 hours agoprevNice, I use AdGuard (on mobile and desktop), would this be a suitable replacement? reply mkskm 9 hours agoparentAdGuard for Mac is the same offering (not to be confused with AdGuard for Safari, which is a browser extension):https:&#x2F;&#x2F;adguard.com&#x2F;en&#x2F;adguard-mac&#x2F;overview.htmlThere&#x27;s also Little Snitch Mini:https:&#x2F;&#x2F;www.obdev.at&#x2F;products&#x2F;littlesnitch-mini&#x2F;index.html reply mrAssHat 9 hours agorootparentThis snitch is proprietary crapware. Instead, use OpenSnitch when on Linux and LuLu Firewall when on Mac. reply mkskm 7 hours agorootparentIt&#x27;s proprietary but quality software. LuLu is cool but doesn&#x27;t offer the same functionality. reply satvikpendem 9 hours agorootparentprevAny differences in performance or how well each works for adblocking compared to the others? reply 40 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zen is an open-source ad-blocker and privacy guard available for Windows, MacOS, and Linux.",
      "It intercepts HTTP requests and blocks ads, tracking scripts, malware, and unwanted content.",
      "Users can customize their filters and it offers system-level protection. It requires the installation of a root certificate for HTTPS interception."
    ],
    "commentSummary": [
      "Zen is an open source ad blocker that is being discussed by users.",
      "Users have expressed security concerns and suggested improvements like a FAQ section and the ability to choose upstream DNS servers.",
      "There are mixed opinions about blocking ad traffic at the network level, and discussions also cover challenges of blocking network traffic and the importance of user-defined non-secure proxies.",
      "Trustworthiness of software developers and the effectiveness of ad-blocking methods on platforms like YouTube are also topics of discussion.",
      "Various ad-blocking tools and their performance are mentioned in the summary."
    ],
    "points": 215,
    "commentCount": 143,
    "retryCount": 0,
    "time": 1701731842
  },
  {
    "id": 38522031,
    "title": "DoorDash Raises Minimum Pay to $29.93 per Hour for NYC Delivery Workers",
    "originLink": "https://about.doordash.com/en-us/news/nyc-platform-experience",
    "originBody": "As we have repeatedly made clear in recent months, the ill-conceived, extreme minimum pay rate for food delivery workers in New York City will have significant consequences for everyone who uses our platform. Unfortunately, these regulations will significantly increase the costs of facilitating delivery in NYC and force us to make a number of operational changes, which is why we’re providing an update on what local consumers and Dashers will be seeing beginning today. Implementing new minimum pay requirements Dashers who deliver in NYC will now earn at least $29.93 per hour of active time, nearly twice NYC’s $15 minimum wage for other workers. This rate excludes tips and is just a minimum, so Dashers still have the opportunity to earn more than the minimum. Dasher earnings will be reviewed weekly to see if their DoorDash pay meets the earnings minimum, and any Dashers who earn below the required minimum will receive a pay adjustment. Moving tipping to after checkout in preparation for increased fees These new regulations will force us to raise fees for orders in New York City. In order to better balance the impact of these new costs, we’re moving the option to tip in the DoorDash app to after checkout. This change comes as a recommendation by the NYC Department of Consumer and Worker Protection, and has been done to help ensure our platform remains affordable for all New Yorkers. However, we know tips are still an important way for consumers to show Dashers their appreciation, so consumers will still be able to tip after checkout and for up to 30 days after they order. As always, 100% of a consumer’s tip goes to the Dasher. Pausing our Dasher Priority Access program With the changes required by NYC and the impact it will have on our system, we are pausing our Priority Access program, which gives Dashers who have high ratings priority on higher-paying offers. Since Dashers will earn a guaranteed minimum rate, the benefits offered by this program will not apply in NYC. The Top Dasher program is still available for qualified NYC Dashers. We know that these are significant changes for the way Dashers will use the platform, and we always seek feedback from them on important topics like app functionality, new features, and public policy. We sent early communications to some Dashers making them aware of changes that would be coming to the platform and provided an opportunity to offer feedback so that we could most effectively implement these changes. We anticipate needing to make other operational changes in response to these new regulations that will further impact the experience of consumers, Dashers, and merchants on DoorDash in New York City. In the meantime, we will continue to engage with policymakers and focus on what matters most: continuing to serve communities across New York City.",
    "commentLink": "https://news.ycombinator.com/item?id=38522031",
    "commentBody": "DoorDash raises minimum pay to $29.93 per hour in NYCHacker NewspastloginDoorDash raises minimum pay to $29.93 per hour in NYC (doordash.com) 213 points by 1594932281 14 hours ago| hidepastfavorite286 comments zepton 11 hours agoDoorDash is being misleading when they imply that NYC required a minimum wage of $29.93&#x2F;hr for delivery workers. DoorDash could comply with the bylaw by paying its contractors $17.96&#x2F;hr for the full time they work (including time waiting for orders). But DoorDash instead chose to use the \"Alternate Method\" which has a 67% higher minimum wage, but only for the time the contractor is actively delivering food (not standby time). (full text of bylaw: https:&#x2F;&#x2F;codelibrary.amlegal.com&#x2F;codes&#x2F;newyorkcity&#x2F;latest&#x2F;NYC...)The implication that Dashers earn 2x more per hour than \"other workers\" earning minimum wage is false, since \"other workers\" are paid for 100% of the time they work, including when they are waiting for work. reply darth_avocado 11 hours agoparentThe other part of this is that Doordash workers need to pay for their own delivery vehicles (gas, upkeep etc.) which factors into the actual wages they get. They are not making significantly more than minimum wage workers. reply standardUser 11 hours agorootparentI&#x27;d estimate in NYC that 90% of deliveries I get are made by bicycle, so their average expenses are comparatively very low. reply massysett 8 hours agorootparentThough the significant risk to life and limb from working on a bicycle has to be accounted for. reply throwaway2037 7 hours agorootparentWhat is the hourly rate for bicycle couriers in NYC? They are frequently used in the legal and real estate industry to quickly move physical documents between offices. reply radicality 9 hours agorootparentprevI’ve even had Uber eats deliveries from places close-by where it said “X is walking”. reply CydeWeys 11 hours agorootparentprevThe delivery vehicles being used in NYC are almost entirely e-bikes, so the expense is not as big as you might be thinking. It&#x27;s certainly nothing close to the cost to gig workers for running an Uber car. reply interactivecode 10 hours agorootparentSo does it include health and sick pay for when you get injured or older and you’re less mobile? Cycling all the time could be way more taxing than driving. reply CydeWeys 10 hours agorootparentOf course it doesn&#x27;t include any of that. It&#x27;s \"independent contracting\".Though keep in mind they&#x27;re throttle e-bikes, so there isn&#x27;t a lot of actual pedaling going on. And as far as accumulated workplace injuries go, merely riding a bike is pretty easy compared to a lot of blue collar work. No, I think what&#x27;d get you here is the crashes. reply porknubbins 8 hours agorootparentI wouldn’t discount the long term health costs of breathing exhaust fumes all day either. Even as a recreational cyclist or occasional commuter in NYC I noticed it. reply pinkgolem 2 hours agorootparentTbh... It&#x27;s likely still has a better balance then your average office job where you are sitting all day every day. reply throwaway2037 7 hours agorootparentprevI&#x27;m not sure if you noticed that the GP wrote \"e-bike\". Yes, even riding a e-bike would be more taxing than driving for many, I would say that an e-bike is much less taxing than a regular bicycle. reply lancesells 9 hours agorootparentprevThe act of cycling shouldn&#x27;t be any sort of problem. The accidents though are another story. The e-bikes are as silent as regular bikes but much faster. reply syndicatedjelly 9 hours agorootparentprevSitting in a chair in a metal box is definitely worse for health than cycling all day reply dyarosla 8 hours agorootparentThan (e-)biking on roads alongside metal boxes? This ain’t biking through the woods. Just think about the pollution and chance of getting hit. reply syndicatedjelly 7 hours agorootparentHow often are people on e bikes getting mowed down where you live? What kind of hellscape do you live in where cycling causes you to ingest more polluted air than sitting in your bioweapon-proof, hermetically-sealed, fart-fermenting 3000 kilo Tesla? Sheesh reply Dylan16807 7 hours agorootparentAre you joking that everywhere is a hellscape, or did you make a typo, or what?Because anywhere that has any air pollution, you&#x27;ll ingest more when you&#x27;re breathing harder and have no air filter. reply syndicatedjelly 5 hours agorootparentI’m kinda joking, but I genuinely feel bad for people who live in places where cycling makes their health worse because of the air pollution. I had to deal with that situation a few summers ago when wildfires caused ash to rain from the sky and made the air quality shit. It felt like a low-level hell. replySai_ 5 hours agorootparentprevCan they not offset these expenses against their tax? If you’re running a business out of your vehicle, the cost of operating that vehicle is the cost of running the business which should be treated like that by the tax code. reply sowbug 5 hours agorootparentThe marginal federal tax rate for someone making $50,000 is 12%. So every dollar spent on gas (or whatever other deductible expenses) would lower federal taxes by 12 cents.But I&#x27;d be surprised if many drivers grossed more than $50K&#x2F;year. If they earn less, the tax benefit of deductibility is even smaller. reply Sai_ 3 hours agorootparentPersonal income tax and the tax treatment of businesses are different - as a business, you’d earn some revenue from doordash while showing some expense (like gas, insurance premiums, and your salary). Your company would then pay tax on the net and you’d pay tax on the salary you give yourself from your company.Not a CPA so I’m pretty sure I’m oversimplifying this and there are lower bounds I don’t know about which prevent most gig workers from operating like this. reply shmatt 9 hours agoparentprevWhile true this would lead to thousands of people being online without demand. If one really wants their food in 45 minutes, or an uber driver always 3 minutes away, they need a lot of people doing nothing staring at their screens for long periods of timeCapping the # of people online would cause tons of other issues, its very easy to exploit a system like that, plus it would slow everyone downEither we want people to do things for us, want it super fast, and want to pay everyone for every second of their time. Can&#x27;t have all of these without hiring a personal driver working just for you full time reply cantSpellSober 9 hours agorootparentNot in a city the size of NYC.In between deliveries, they are on their shift, and they should be paid for their time. reply troupo 2 hours agorootparentprev> Either we want people to do things for us, want it super fast, and want to pay everyone for every second of their time.Yes, you either pay people for every second of their time, or pay enough money for their work hours. There&#x27;s no way out of this.A courier or a taxi driver does not chose to sit on their ass the entire day. You can get a hundred orders in a row, or you can have no orders for an hour or two, and you have no control over that. And it&#x27;s not like they can just get up, get a cup of cofee and go to a second job in the meantime. reply handy2000 11 hours agoparentprevDoes this also introduce a bad incentive for drivers to delivery food slowly? Or do delivery apps account for that somehow already?.. reply actionablefiber 11 hours agorootparentNit: Most food delivery workers in NYC are on e-bikes or mopeds. There are surely some drivers but it is prohibitively difficult to use a car for food deliveries in nearly all of Manhattan and decent portions of Brooklyn&#x2F;Queens&#x2F;the Bronx.As it is there is public outcry about dangerous and aggressive riding behavior from food delivery workers. It is not strictly a bad idea to tilt the incentive structure so that while you can earn a little extra on tips for completing more deliveries, it&#x27;s not such a huge part of your earnings that you need to cut corners, ride the wrong way on one-way streets, ride on sidewalks etc. to hyperoptimize your delivery rate. reply asfasfo 11 hours agorootparentprevI&#x27;m pretty sure Doordash tracks that and will boot drivers that don&#x27;t deliver quickly as that affects their bottom line. reply Larrikin 7 hours agorootparentI stopped using door dash when I watched multiple delivery drivers go pick up my food, sit and wait for a bit, drive in the wrong direction, pick up food from another restaurant, drive in the wrong direction to another location, then deliver my cold food. reply jsyang00 10 hours agoparentprevWouldn&#x27;t this incentivize Dasher&#x27;s to... take longer to deliver?This whole model feels screwed up to me. reply interactivecode 10 hours agorootparentIndeed, it would be better if doordash would just hire full time employees. And vet them before hiring with a regular interview process. Instead of constant punitive surveillance with the threat of instant unemployment.Can you imagine if your dev job was like this? Picking up jobs to write a single function. And if youre too slow, or one too many tests fail you get sacked. reply zachkatz 8 hours agorootparentThe “problem” is that many (most?) delivery cyclists in NYC aren’t legally allowed to work, so this option would be jeopardizing a large part of their workforce (bad for DoorDash) while also being bad for the workers themselves (who aren’t exactly swimming in job options). I’m not making a value judgement here, just weighing in with a tradeoff to consider. reply throwaway2037 7 hours agorootparentnext [–]many (most?) delivery cyclists in NYC aren’t legally allowed to workWoah. Are you saying these people are illegal immigrants, or don&#x27;t have a work visa? I never heard this before. That is a bold claim. Do you have any evidence to share? I tried Googling, but I couldn&#x27;t find anything. reply zachkatz 7 hours agorootparentIllegal immigrants. Here are some sources:https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;09&#x2F;15&#x2F;nyregion&#x2F;migrant-delivery...https:&#x2F;&#x2F;nypost.com&#x2F;2023&#x2F;09&#x2F;20&#x2F;tidal-wave-of-migrants-in-nyc-...https:&#x2F;&#x2F;gothamist.com&#x2F;news&#x2F;doordash-legal-group-set-to-deliv... reply xkekjrktllss 8 hours agorootparentprev>Can you imagine if your dev job was like this?Mine is. We have stack ranking and it&#x27;s a living nightmare. reply throwaway2037 7 hours agorootparentWeekly or monthly stack ranking? I doubt it. Probably annual or twice-yearly reviews. And how much of the stack is released for poor performance during each review? 5&#x2F;10&#x2F;15%? Still: Nothing compared to being a DoorDash delivery person. reply Scoundreller 10 hours agorootparentprev... or incentivize them stop instead of running over pedestrians, ride on roads&#x2F;bikelanes instead of sidewalks.I know I stay the hell out of the way of by-the-minute \"communal\" rental cars. reply xboxnolifes 3 hours agorootparentprevOnly if you ignore tips. reply stefan_ 9 hours agorootparentprevAnd as an additional incentive, DoorDash has decided to fuck with tips! reply throwaway2037 7 hours agorootparentThanks for the info. Can you share more details? Tipping a delivery person always seems bizarre to me. Any reasonable society would just pay a better wage, but instead, the US prefers slave wages plus \"tips\" to maaaaaaaaybe make a living wage. reply stefan_ 6 hours agorootparentThey reduced the default tip amount, hide tip information from delivery drivers and moved the tipping to after the order, all together ensuring that tipping happens less & for lower amounts. reply throwaway2037 8 hours agoparentprev+9000. Thank you very much to share this vital information.How do you know this information? Example: Are you involved from the legal or labor (union?) side? Or, are you a DoorDash \"partner\"? reply crmd 12 hours agoprevAs an old person, I&#x27;d like to point out that my hometown of New York City had a dynamic, world class restaurant scene, including a cornucopia of home delivery, long before the tech platform companies found a way to siphon ~40% of consumer spend out of the local restaurant economy in exchange for some friction reduction. We were doing great. But you had a drawer full of paper menus and had to call the restaurant. reply darth_avocado 11 hours agoparentThis was not very doable pretty much everywhere outside NYC. The lower density of restaurants made it harder for delivery to be a thing except all the pizza places that offered it. reply bigtunacan 10 hours agorootparentThat&#x27;s a generalization with no supporting data. As an actual sample size of 1; I lived in a smaller city of only about 250k people and there was a huge selection of restaurants that offered delivery, not just pizza.Honestly DoorDash when it did come reduced restaurant profits, lowered quality of food delivered, and increased consumer costs. Zero advantage for anyone other than DoorDash unless you consider being able to search for the food in a single app and paying extra for it to be cold on arrival an advantage. reply Flameancer 6 hours agorootparentIt’s always dependent on wear you lived. I’ve always lived in my city of at least 1mil+ and growing up before DoorDash we could never get delivery because of zip code. Now with DoorDash it doesn’t matter. Delivery has always existed but that was mostly dependent on if the restaurant wanted to come to your area. reply darth_avocado 9 hours agorootparentprevThat is not a generalization, that is actually a fact. Doordash and other delivery apps gradually added restaurants on their platforms and still add new ones regularly. The fact that this happened in itself is a proof that they didn’t have food delivery as an option before.If you want more concrete data, you need to look at how McDonald’s did deliveries in Manhattan but not rest of the US until they partnered with food delivery apps. Most other fast food chains did not have their own delivery network either. reply runeb 8 hours agorootparentWithout commenting on this topic in general, you appear to have a flaw in your reasoning. That a restaurant was added to Doordash does not prove that it never had the ability to deliver before that. reply darth_avocado 7 hours agorootparentIt doesn’t guarantee that they never had the ability to deliver. But the fact that delivery apps grew (kept adding more restaurants so quickly) was in part that restaurants could do delivery when previously they didn’t. The parent‘s argument was that delivery was already a norm before, which clearly was not the case.And I also point to restaurants that are newly added to delivery platforms, because you can easily verify if they previously could deliver or not. reply RHSeeger 8 hours agorootparentprevI&#x27;ve lived in a city of 50k people and smaller, and in various suburbs (of major cities) and ALWAYS had a collection of delivery menus in a bag next to the junk drawer. I don&#x27;t think I&#x27;ve even lived anywhere that didn&#x27;t have a reasonable amount of delivery. That&#x27;s not to say such places aren&#x27;t common... just that \"unique to NYC\" certainly doesn&#x27;t describe it. reply throwaway2037 7 hours agorootparentprevYes, I agree. That is ridiculous. For about 10 years, I lived in a small town with less than 15k residents. Tons of local restaurants had delivery. reply justsomehnguy 4 hours agorootparentprev> Zero advantage for anyone other than DoorDashSince when the capitalism seeks for advantage of Regular Joe? reply interactivecode 10 hours agorootparentprevDoordash could just employ delivery drivers to solve this problem. No need for a 100% at will temp work force. They could just hire people part time or full time. And if work is really that surgy they could just have workers on call.Why does “innovation” have to go hand in hand with fucked up labor practices? reply troupo 2 hours agorootparent> Why does “innovation” have to go hand in hand with fucked up labor practices?While still losing a billion dollars a year, or more, for years. reply Draiken 9 hours agorootparentprevBecause we live in a capitalist society and profit is the only objective.Not exploiting your workforce as much as you can is an almost guaranteed road to failure.Imagine taking investor money and saying \"I&#x27;ll pay more to my workers so they can have decent lives\". They&#x27;d oust you in a second. Same if you&#x27;re in a publicly traded company.The only possible way this doesn&#x27;t happen is if you&#x27;re running an already profitable private company, you&#x27;re willing to grow at slower rates (which carries its own risks), your market allows it and you&#x27;re not a sociopath.That&#x27;s a very rare combination. reply handy2000 11 hours agorootparentprevAt the end of the day this is all driven by market dynamics that affect everyone. Uber Eats doesn&#x27;t have a secret sauce that makes it cheaper for drivers to deliver food in cities with lower restaurant density. Someone has to pay for gas, someone has to pay for drivers&#x27; time. Even in large cities Uber Eats is now more expensive than ordering directly from restaurants in the past, why would it be different for cities with fewer restaurants? reply Dylan16807 10 hours agorootparentOh I don&#x27;t think anyone said they&#x27;re making it cheaper. But a lot of restaurants now have expensive delivery instead of no delivery. Before, there were very few places where most restaurants would deliver. reply candiddevmike 11 hours agoparentprevAnd if you called the restaurant enough, you typically got on a first name basis with them and had incredible customer service. Now you&#x27;re just another customer #47523 that created order #37324. reply tsm 11 hours agorootparentWe had friends who got Domino&#x27;s every Thursday. On days when they hadn&#x27;t called by a certain time, Domino&#x27;s would call them and ask if they wanted their usual.(This was in Tegucigalpa in the &#x27;90s, fwiw) reply Scoundreller 10 hours agorootparentWhen I showed up to pickup my pizza and they recognized me, I scaled back a lot. I knew then that I was going too often relative to everyone else. reply lozenge 10 hours agorootparentI got a notification from my bank when my girlfriend used her debit card to order at the local Chinese on her way home from work. I was bored so I went to surprise her... she was then greeted there every time with \"is your boyfriend coming?\" reply Flameancer 6 hours agorootparentprevEhh some restaurants still know you on a first name basis even with DoorDash. I used to order from this one Philippine spot like twice a week and after a month a decided to go there in person to sit down and when they asked for my name they immediately asked if I wanted my usual DoorDash order reply koolba 11 hours agorootparentprev> And if you called the restaurant enough, you typically got on a first name basis with them and had incredible customer service.Also Caller ID isn’t that new. reply Scoundreller 10 hours agorootparentCaller ID made answering phones at work fun. When we saw \"you know who\" calling, we&#x27;d rock paper scissors and the loser would have to answer. reply throwaway2037 7 hours agorootparentprevIt existed since at least the 1990s in the US. Is 30 years enough for you? reply hiatus 9 hours agorootparentprevI don&#x27;t know about your experience but zero restaurants I&#x27;ve worked in had caller id. reply bobbylarrybobby 5 hours agorootparentprevI definitely miss the experience of hearing “the usual?” once I tell them my address. reply phendrenad2 4 hours agoparentprevThe time savings of having a digital, interactive menu, where you don&#x27;t have to worry that the person on the other end will interpret \"no mayo\" as \"extra mayo\" should not be underappreciated. reply Consultant32452 11 hours agoparentprevHas the local restaurant scene recovered from the lockdowns? I live in a smaller city and we have recovered some but it&#x27;s nothing like it was. I heard it was particularly rough in NYC. reply crmd 11 hours agorootparentIn my experience, the more \"corporate\" restaurant groups are growing but the less well capitalized small businesses are in a world of hurt trying to balance the books with the leftovers after the rise in physical rent and advertising&#x2F;platform company costs. reply JumpCrisscross 11 hours agorootparent> the more \"corporate\" restaurant groups are growing but the less well capitalized small businesses are in a world of hurtWithin theonly change I saw was a growth of fine dining Korean foodI can count half a dozen on my block in Flatiron alone. The only Korean fine-dining place to have opened near me is Nōksu, and I&#x27;m a few blocks from Koreatown. reply Consultant32452 11 hours agorootparentprevNow that you have written it, this models my experience too. Thanks for sharing. reply ChrisMarshallNY 11 hours agorootparentprevI live in the NYC suburbs.COVID killed a number of restaurants, but some, thrived. A couple of local sit-down restaurants switched to take-out only, fired all their waitstaff, and probably got a lot of financial assistance. They made out well.A couple, never went back to in-house dining. They are still take-out only.Doordash became huge around here (Ubereats, too). Pretty much every restaurant does them.The prices have gone way up, for many of these places. A few places have doubled their prices, in just a few months.Not sure of all the causes, or the long-term effects, but I am not seeing too many \"Help Wanted\" signs. reply standardUser 11 hours agorootparentprevThere are still more amazing places to eat in NYC than you could comfortably visit in a lifetime. I can&#x27;t even keep up with the new places that open in my own neighborhood. reply graphe 12 hours agoparentprevDid you experience the automats? reply 8bitben 13 hours agoprevThe platform fees and the insane menu price markups that restaurants apply for delivery app orders have made it impractical to use Uber Eats & DoorDash for a couple years now IMO. I only ever consider using them when offered at least 50% off.Mandated minimum earnings will benefit the drivers, but that won&#x27;t help drivers that have to quit the platforms because people stop using them. reply legitster 12 hours agoparentIt was never a sustainable business model to begin with.It takes 10 minutes for a chef to make my meal, and 25 minutes for someone to come to the restaurant, pick it up, and drive it to my house.The only way it works is if someone else&#x27;s time is an order of magnitude less valuable than yours. reply dragontamer 11 hours agorootparent> The only way it works is if someone else&#x27;s time is an order of magnitude less valuable than yours.Ish.There&#x27;s clearly a logistics problem here. 1-meal being delivered promptly on time scales poorly. But 15 meals delivered to 15 different people within 45 minutes is in fact, a net gain.Alas, Doordash and Uber have gone about it in all the wrong ways. Its the drivers who double-book this process (ie: picking up more orders than they can handle), leading to inconsistent quality, cold food, late deliveries and more.Its a legitimate model though. A more \"proper\" company that&#x27;s doing this officially is Foodsby, where one Restaraunt makes a single delivery to 15-ish people in one trip at a designated time and location (usually within 5 minutes walking distance of an office complex. IE: One particular office building has a Foodsby drop-off point).Everyone pays $2 each, the driver is happy, the restaraunt is happy (their personal staff deliver and therefore ensure quality food &#x2F; hot food at the appropriate, predesignated time), and a ~5 minute walk for a bunch of office workers is a good idea anyway cause we&#x27;re all sitting on our asses all day.---------It double-benefits because professional chefs like doing ~15 or 20 of the same order all at once, its more efficient for them... especially if they can plan such an order ahead of time (Foodsby isn&#x27;t offered every day for a Restaraunt, they pick-and-choose the days that they&#x27;ll offer the service).So the chefs can cut-down on scheduling if they&#x27;re burning out, or they can plan ahead and offer more days if they know some days are lulls &#x2F; they have extra freetime.Doordash &#x2F; Grubhub &#x2F; Uber is almost malicious for everyone involved. There&#x27;s some ideas of convenience to some people, but its not good enough for the overall environment. In contrast, Foodsby (and hopefully more companies that adopt that model) has proven itself sustainable, at least in my area. reply handy2000 11 hours agorootparentYou are describing a completely different service though. Prep-meal delivery also works, but it&#x27;s addressing a different usage pattern.In the same way you could propose to replace Uber with... buses? 15 people get on the same bus at a specific time and get dropped off within 5 miles, thus optimizing the process. reply dragontamer 11 hours agorootparentUberEats is a \"bus\" that pretends otherwise.I&#x27;ve seen the Uber drivers come in. They always grab like 4 or 5 orders, and possibly drive to a 2nd or 3rd restaraunt before they start delivering.Its not like those UberEats drivers have a big penalty if they arrive late or if the food is cold.-----------What I&#x27;m saying is, consolidated food delivery services is *already* what we have with DoorDash&#x2F;UberEats&#x2F;whatever, they just lie to you about the details.The reason why Foodsby works (albeit on a smaller scale) is because they&#x27;re honest about it. There&#x27;s nothing wrong with consolidating orders to minimize driving time, the problem occurs because those other services _PRETEND_ they&#x27;re a 1-to-1 order service with dedicated drivers. IE: Its the lies where things have gone wrong, not necessarily the practice.If all the drivers are double-booking &#x2F; consolidating orders anyway, then work it into the model. Embrace it, rather than pretend otherwise. reply Zircom 9 hours agorootparent>I&#x27;ve seen the Uber drivers come in. They always grab like 4 or 5 orders [from the same restaurant], and possibly drive to a 2nd or 3rd restaurant before they start delivering.Having done Doordash&#x2F;Ubereats in the past myself that is ABSOUTELY not the norm, god I wish it was that streamlined. Picking up a single order and delivering it straight to the customer is by far and away the most common scenario for the drivers.They do have stacked orders which are the multiple pickups you&#x27;re talking about, but I&#x27;ve never had more than 3 orders \"stacked\" together, and I would say it&#x27;s more common to have stacked orders from multiple different restaurants rather than multiple orders from the same restaurant. And from the driver point of view stacks suck because almost always only one order in the stack will have a tip, the others will be no-tip orders they couldn&#x27;t get someone else to deliver by themselves.Doordash also recently changed how they pay out on these stacked orders to the drivers detriment. It used to be you&#x27;d get the base rate for each order in the stack, so 3 orders stacked together would be the base rate x 3 + whatever tips by each customer, but now they pay them out as one big order no matter how many orders are stacked together, so you get a single count of the base rate even if you&#x27;re delivering two or more orders in a stack, which again are usually only a single order with a tip, so you&#x27;re effectively delivering the other orders for free. reply dragontamer 9 hours agorootparentThanks for the anecdotes. Good to hear how things work from someone who has actually experienced it.All I&#x27;ve seen are the big orders that get handed to someone who immediately runs out the door and into a car that they left running (with the keys in and everything), lol. They&#x27;re obviously stressed and trying to make time.I guess the big orders &#x2F; stacks are more noticeable to me and obvious what&#x27;s going on. If a more \"normal\" driver comes in, it looks like any other internet order (like my own, except I&#x27;m picking it up personally). reply handy2000 11 hours agorootparentprevYou are partially correct describing that some delivery drivers already batch their orders. But that&#x27;s still a different use case. Foodsby can&#x27;t scale to 15 min increments for all restaurants in the city. While some people can preplan and are OK ordering food from a specific restaurant that Foodsby works with, most people don&#x27;t want that. How many people want to order food from an expensive Spanish (i.e. Spanish, not Mexican) restaurant I order from sometimes? So my options are going to be: #1 not ordering from this restaurant because it&#x27;s not a common food preference and is expensive or #2 wait for 15 people to join the order for this restaurant and get food hours or days later.It&#x27;s a good business idea, it&#x27;s just a different usage pattern. I order food when I am hungry. I don&#x27;t preplan, don&#x27;t like food from the majority of popular local places (pizza, Mexican, Chinese). reply dragontamer 11 hours agorootparent> Foodsby can&#x27;t scale to 15 min increments for all restaurants in the city.For some definition of increments and \"all\", yes they can.Restaraunt#1 delivers at 10:15am.Restaraunt#2 delivers at 10:30am.Etc. etc. etc. Covering the entirety of lunch hours. This is how it works in practice, today.If you&#x27;re in a location with lots of Foodsby usage, then you might have 3 or 4 different Foodsby locations to check within a reasonable distance, which dramatically increases the restaurants and timeslots available. Like 1x Foodsby is already fine, but if you&#x27;re in an area with 5x walking-distance Foodsby dropoff points like I am, things start to get really convenient, and the selection becomes dramatically wider.It also means for the drivers, that one \"trip\" can hit 3, 4, 5 offices in one drive. I&#x27;m sure that on Foodsby days, these drivers are delivering multiple dozens of meals. In fact, the *MANAGER* of one local Restaurant was the driver for one of my recent orders (we recognize each other&#x27;s faces because I visited his restaraunt a lot, so it surprised me to see the manager making delivery runs). So its more fulfilling work than typical grunt labor, since they&#x27;re making so many deliveries on relatively low effort. If he&#x27;s got ~30 orders, that&#x27;s $60 ($2 per meal) in less than 30 minutes of driving&#x2F;delivering, which is certainly more money flowing than most UberEats &#x2F; DoorDash setups.--------Now yes, you may be arguing that \"its not what you want\". But... when that Spanish Restaraunt says \"We&#x27;re offering $2 delivery (no tip) 3 days from now at X-oclock\"... I think you&#x27;ll be thinking of using Foodsby that day.Or maybe you check the website to see today&#x27;s Restaraunts and whether or not your favorite is on the list.-----------In any case, _THIS_ is innovation. Actually playing with models and finding things that are better for everyone (chefs, restaraunt owners, drivers, users) as a whole. I&#x27;m sure other models can work too, for some sliding scale of individualism, bulk deliveries and whatnot.But as far as the personalized 1-to-1 service? Its dead, its so dead I&#x27;m convinced it never even existed. UberEats _never_ promised a driver on the standby ready to personally serve you, and months&#x2F;years of using the service has made it obvious to everyone.There&#x27;s only so many times that I get a meal 1.5 hours too late that causes me to give up on UberEats (and similar) services. reply somethoughts 10 hours agorootparentInterestingly in Silicon Valley, there&#x27;s an angel funded startup founded by an ex-Google foodie who worked with some of the more notable Asian restaurants (the super popular ones with long lines).She arrange it such that users from a given neighborhood could order via the website app by 4:30 from a specific set of 2-3 restaurants per day. The orders from a given neighborhood are bulk ordered for 3-4 drivers to pick up from the 2-3 restaurants and delivered to the same neighborhood between 6-7pm.The list of 2-3 restaurants for a given neighborhood are shared a week in advance and in cooperation with the restaurants so they can handle the surge. Since the restaurants no it will likely be reheated the packaging is optimized.Because there is a rotation of the restaurant - it paradoxically avoids the tyranny of choice issues with picking a restaurant and actually feels fresher in a discover new restaurants type of way.During ZIRP&#x2F;Covid the menu prices were sometimes lower and there was no delivery fee. Post Covid they do have a membership option or a very modest delivery fee. reply 4b11b4 5 hours agorootparentHello, what is the name of this? I am currently working with a few restaurants to launch almost the exact model. The idea is to transition from on-demand to in-advance. reply handy2000 11 hours agorootparentprev> In any case, _THIS_ is innovation. Actually playing with models and finding things that are better for everyoneYup, that&#x27;s a good point. The current model doesn&#x27;t seem to be sustinable. reply dragontamer 11 hours agorootparentThe Food Truck model also seems to be taking off in my area.Which is somewhat different than internet-based calling of food, but still a convenient walk that gets me lunch. replyOkayPhysicist 10 hours agorootparentprevUber was experimenting with that exact process before covid. For a lower fare, you let Uber dynamically re-route your driver to pick up more people headed in roughly the same direction as you. Worked alright, maybe took 1.5x as long for you to reach your destination while you paid about half as much as you did usually. reply lozenge 10 hours agorootparentprevBusses work, though. If you removed busses, there is no amount of Ubers you could add to the roads to \"fix\" the system. It&#x27;s clearly impractical for each office worker to pay for even half an hour of someone&#x27;s time every day to deliver a meal just to them. While most counter services can serve 20 meals with the same half hour of wages.Uber Eats is doing it here in London with \"ghost kitchens\". 15 fast casual brands cooking (mostly reheating really) from 3 kitchens in 1 building. A much better chance for delivery drivers to be able to pick up multiple orders. It still isn&#x27;t enough optimising though, as the destinations are still scattered. reply Consultant32452 11 hours agorootparentprevI spent a number of years working at a pizza place in high school&#x2F;college and on busy nights they had a dedicated \"router\", a human who was sometimes also a driver, who grouped orders together so they got where they needed to go in a timely fashion and the food was always warm.When I order DoorDash my driver either only has my order or they have a secondary delivery that is insanely out of the way. This is a very inefficient use of driver time.The pizza place is practically all delivery and it&#x27;s easy to bunch up the orders heading in the same direction. Comparing that to UE&#x2F;DD, a single restaurant might have 2-3 delivery orders at any given time, but what are the odds they are all headed in the same direction? I wonder if extreme density cities have less of a problem with this.For reference, I live in a \"2nd tier\" city. Not NY&#x2F;LA, but a city everyone has heard of.On an unrelated note, I&#x27;ve always thought the big problem is their market is too narrow. These companies should deliver literally anything that can fit in a passenger car. One example I know of is that auto shops do not keep parts for every car in the shop all the time. They contract out to parts warehouses. Those warehouses have employees which deliver your new carburetor to the auto shop that&#x27;s installing it. There&#x27;s no reason your Uber driver can&#x27;t pick up pasta and a carburetor. reply johnnyanmac 12 hours agorootparentprev>The only way it works is if someone else&#x27;s time is an order of magnitude less valuable than yours.Targeting mainly the wealthy isn&#x27;t necessarily a bad business strategy.It should also be noted that it&#x27;s also useful for bulk order to people and those unable to physically move themselves to a place (disability, lack of car, etc). It&#x27;s not a \"use everyday\" mechanism, but it has uses. reply lokar 11 hours agorootparentBut the whole structure of these companies (and valuations) is based on a much larger scale&#x2F;market. reply shiroiuma 1 hour agorootparentprev>It takes 10 minutes for a chef to make my meal, and 25 minutes for someone to come to the restaurant, pick it up, and drive it to my house.And in that 25 minutes, the food has gotten cold and its chemistry has changed too. You could reheat it in the microwave, but now it&#x27;ll just taste like reheated leftovers.Why do people buy this crap? reply pcurve 11 hours agorootparentprevMost of my favorite local restaurants use other platforms now. It&#x27;s been 3 years since I&#x27;ve last used Uber or DD. If they don&#x27;t deliver, I just go pick it up myself. reply prawn 11 hours agorootparentprevI wish there were Indian curry vans instead of ice cream vans, driving around the streets playing distinctive music from 5-8pm. Group buy discounts for individual streets to promote pre-purchase, etc. Do a different suburb each night of the week. Please someone make this. reply bloodyplonker22 12 hours agorootparentprevIndeed, the only way it is working right now is because a significant piece of their revenue is from discounted gift cards so their revenue grows while taking a loss. In the future, they will have to replace the driver with something automated if they want to make money. reply adolph 11 hours agorootparentprev> The only way it works is if someone else&#x27;s time is an order of magnitude less valuable than yours.Food delivery also seems to work with vertically integrated geo-segmented services like pizza and Chinese takeout. My best guess is that the profit margin and delivery packing are high enough to make it worthwhile. reply grecy 11 hours agorootparentprev> The only way it works is if someone else&#x27;s time is an order of magnitude less valuable than yoursI mean, you&#x27;ve basically just described the entire service industry and virtually any job in North American where tips are expected.There is an entire class of people ready to serve you. reply legitster 4 hours agorootparentI mean, don&#x27;t get me wrong. My first job was fast food. But there&#x27;s a difference between being able to serve 50 customers in an hour and 2. reply kiba 13 hours agoparentprevThey aren&#x27;t really viable business models to begin with. Only VC funding can keep these online platform up. reply Nextgrid 13 hours agorootparentThe basic concept of food delivery existed long before tech and VC and was viable.The only reason these companies can&#x27;t turn a profit is because all those microservices, ads and \"engagement\" don&#x27;t come for free. reply jltsiren 12 hours agorootparentFood delivery existed before platforms, but only where it made sense. You could order something like a pizza, where the marginal cost and effort required to make another meal was low, and the sales volume was high enough to justify using paid employees for delivery. Service area was also chosen by the restaurant itself to ensure that they would not spend too much time on a single delivery.In the end, it&#x27;s pretty simple. How many deliveries does a single person make in an hour, including idle time? Is someone paying enough for that? And does the kitchen have enough spare capacity for that? reply lokar 11 hours agorootparentThere were also 3rd party services that would deliver from most anywhere, but they were expensive (they made actual net profit on each delivery). reply chimeracoder 11 hours agorootparentprev> Food delivery existed before platforms, but only where it made sense.This article is about NYC, where food delivery was ubiquitous long before DoorDash. In fact, Seamless in 2010 was a better experience than Doordash is in 2023, when you consider the absurd markup on Doordash.Doordash struggled to enter the NYC market for a while because it was trying to compete with an established product, yet using a higher price point. It was only with massive amounts of VC funding that they were able to get a foothold. reply ghaff 12 hours agorootparentprev>The basic concept of food delivery existed long before tech and VC and was viable.In limited markets, for specific types of food, and for pretty crappy wages for the delivery people. (And, yes, for mostly pretty low tech approaches.) reply bobbylarrybobby 5 hours agorootparentprevIn NYC, before Seamless and the like, restaurants just offered free delivery when you called over the phone. It was just part of the deal; didn&#x27;t have to be profitable on its own (the business it brought was enough). Restaurants evidently did fine back then.Seamless et al are really just siphoning money out of restaurants’ pockets because you cannot, these days, be the only restaurant who still makes people call over the phone. reply roboror 11 hours agorootparentprevThese companies have spent a ton of money to convince lawmakers and consumers that they are not in the food delivery (or taxi) business. The whole plan was to not have to deal with these pesky regulations. reply troupo 11 hours agorootparentprev> The only reason these companies can&#x27;t turn a profit is becauseis because their business model is unviable and unsustainable reply mym1990 13 hours agorootparentprevNot sure why you got downvoted, its true. These platforms are all a race to the bottom to capture market share and then jack up of prices to recover lost revenue. Overall, it ends up being a terrible experience for the customer and the driver&#x2F;deliverer. reply WendyTheWillow 12 hours agorootparentBecause it’s not true anymore, and complaining about high prices for a service that is just moving up market kind of ignores the reality that a business can make fewer sales if its margins on the remaining sales are sufficiently high, which is exactly what has happened.In other words, delivery apps went through the “burn vc money” phase already, and are now focusing on profitability, and successfully so. reply lokar 11 hours agorootparentI just opened the DoorDash app. A ton of fast food ads&#x2F;offersI have not eaten fast food in like 10 years, and never had it delivered.Not really up market imo. reply Nextgrid 13 hours agorootparentprev> a race to the bottom to capture market shareThat is the real problem, not that the concept of food delivery is unprofitable by itself. reply MichaelZuo 12 hours agorootparentNot sure where you folks live but all the major ordering apps present in Toronto have been excellent in the suburbs. I was fully satisfied at least 9 out of 10 times.And even the most expensive, ubereats is only, at most, a 20% surcharge compared to the in-restaurant price plus tip, for a $50 order. reply throwaway2037 7 hours agorootparentThis is a good post. Do you have any thoughts about why this works in Toronto? What is different from other cities? And do workers make living wages? reply stevenwoo 11 hours agorootparentprevI live near Mountain View, California and its probably sampling bias but i would swear that for the entirety of pandemic there were complaints about food delivery missteps and prices on my Nextdoor neighborhood. reply standardUser 11 hours agorootparentprevHow does the customer have a terrible experience? I order delivery more often than is reasonable across many different platforms and I usually have a perfectly fine experience. reply lhorie 13 hours agorootparentprevThat&#x27;s a somewhat outdated narrative to still be parroting.Uber just got included into the SP 500. One of the pre-requisites for that is being profitable on a GAAP basis. reply BoiledCabbage 13 hours agorootparentWhich if I recall correctly they are only profitable due to a one time revenue boost right of something like hundreds of millions ?And that one time \"revenue\" boost was that a company they own they are asserting is now valued more than last year. And they are calling that \"revenue\". reply lhorie 12 hours agorootparentNo, it&#x27;s operating profit. reply kiba 7 hours agorootparentI took a look at a fool article. If you exclude the unrealized return from an investment they made, their profit are in the single digit millions. Not really confidence inspiring, but maybe I am wrong and that they could indeed make their business sustainable. reply Dylan16807 7 hours agorootparent\"could indeed make\"? What&#x27;s not sustainable about that level of profit? And aren&#x27;t they still spending a lot on expansion? reply kiba 6 hours agorootparentIt implies that their margin is really low. We&#x27;re talking about revenues in hundred of millions and they&#x27;re only able to make single digit millions.Next quarter, their margin might entirely be wiped out by a slight downturn in business. If they could increase their margin and make profit consistently, then I&#x27;ll change my mind. reply Dylan16807 5 hours agorootparentIs a particularly big percentage of their costs fixed? Because that affects the math a lot. If we consider a generic slightly-profitable company facing a 25% revenue drop, there&#x27;s a huge gulf between a world where costs drop 10% and a world where costs drop 22%. replyitsoktocry 11 hours agorootparentprev>One of the pre-requisites for that is being profitable on a GAAP basis.Uber lost money for 22 straight quarters, then made money for the last two. Bit optimistic to think it&#x27;s smooth sailing from here, in my opinion. I enjoy Uber, the product, but they are middle manning a couple of low margin industries. Hard to imagine it being a multi-hundred-billion dollar company. reply ceejayoz 12 hours agorootparentprevI mean, Enron was in the S&P 500, too. reply troupo 11 hours agorootparentprev> That&#x27;s a somewhat outdated narrative to still be parroting.It&#x27;s not. Most of those \"innovators\" are still posting losses in the hundreds of millions> Uber just got included into the SP 500. One of the pre-requisites for that is being profitable on a GAAP basis.Because you can somehow lose a billion dollars a year for 10 years, become a publicly traded company with a steatement \"we don&#x27;t even know if we&#x27;ll ever turn a profit\", still continue operating at a huge loss for several years, write off 6 billion in losses, and finally become profitable enough to be included in S&P.Any any other, sane world, Uber would be gone after two years of losing a billion dollars a year. Not crawl into S&P after 10 years of unsustainable losses. reply sokoloff 8 hours agorootparentI don’t have much dog in this fight, but it seems as if Uber’s losses were self-evidently sustainable. reply troupo 2 hours agorootparent> it seems as if Uber’s losses were self-evidently sustainable.With the unlimited free investor money. Same goes for the rest of \"amazing starup innovators\" of recent years (e.g. YCombinator&#x27;s startups). The flow of money has now stopped&#x2F;slowed, and we now see mass layoffs and a wave of bankrupcies.Losing a billion dollars a year for 10 years is not a sustainable business. But somehow it has become the norm in IT. reply hotpotamus 13 hours agorootparentprevI&#x27;ve never really gotten this. We can speculate about the intelligence of VCs, but I assume most of them know a bit of basic math. I wonder if perhaps they are so deep into a bubble of wealth and privilege that to them, spending $50 for a (cold by the time it arrives) burger seemed reasonable. Perhaps they thought that once everyone could experience this for an amount of money they find trifling, it would catch on?I&#x27;ve used these services a time or two just to see what the fuss is about and I don&#x27;t get it myself. reply mym1990 13 hours agorootparentThe VCs are hoping to hype the product enough in the early stage to achieve a lucrative exit, and do that 10% of the time(or whatever). What happens with the product once the company is public is not of their concern. reply johnnyanmac 12 hours agorootparentprev>I&#x27;ve used these services a time or two just to see what the fuss is about and I don&#x27;t get it myself.It&#x27;s similar to fast food itself. convenient and cheap. these days the latter is falling off the wayside (again, just like modern fast food). It was invaluable during a pandemic to help encourage social distancing, but even if it was still cheap it was bound to fall off a bit (probably not to pre-pandemic levels, but no longer record customers).>I wonder if perhaps they are so deep into a bubble of wealth and privilege that to them, spending $50 for a (cold by the time it arrives) burger seemed reasonable.As others have mentioned, it&#x27;s more a matter that VC&#x27;s aren&#x27;t necessarily looking to be the next big tech company. Many are looking for a profitable IPO and then move on to the next company. Lots of problems with enabling that model to begin with, but that&#x27;s a whole other bucket of worms. reply sokoloff 8 hours agorootparent> convenient and cheapBut it’s neither of those things, assuming you believe (as I do) that receiving food that should be hot but is cold isn’t convenient. reply bubblethink 8 hours agorootparentprevThey work kind of OK in dense expensive cities like SF or NYC where people don&#x27;t drive as much. Less so in other sparse areas where driving and picking up or even eating out is less of a hassle. I think you&#x27;re using $50 as hyperbole; more realistically, a $20 takeout becomes $30 with delivery, and a lot of people seem to be OK with that. reply rendang 11 hours agorootparentprevA lot of Americans can&#x27;t \"reasonably\" spend $25+ on a single delivery meal but do anyway, probably quite often on 25% APR credit cards reply acchow 12 hours agorootparentprevThese services are very popular. Just look at DoorDash&#x27;s explosive growth. It&#x27;s not only out-of-touch VCs that like ordering food. reply crdrost 12 hours agorootparentprevI mean I think it can be, given that there&#x27;s a $20-$30 markup per order, but it definitely requires some particular circumstances.The bigger thing is that if you&#x27;re thinking of Lean manufacturing principles or Theory of Constraints, where the goal is to get the noise out of the system, you would never maximize a business the way that Uber Eats and Doordash are. It&#x27;d instead be something like the following pipe dream:- We sell \"pizza delivery as a service\" to businesses who want it -- at first we&#x27;re trying to partner with Target and Walmart, etc. Our value proposition to them is \"hey Amazon is eating you alive, how about we help you offer ultra-rapid delivery and the people you&#x27;re working with basically become fellow trusted Target employees?\" (Of course, we&#x27;d be happy to double-dip -- ideally we&#x27;d convince Amazon that we&#x27;re a cheaper way to reach their customers than their own delivery drivers. But that&#x27;s a really hard sell.)- The company rents delivery people from us per day, we provide the delivery network. If you need to \"burst\" we can provide extra folks to augment at a premium. Ideally someday we&#x27;ll get some lucrative Amazon contract where the Amazon warehouse, but to start with we&#x27;re doing laundry delivery and other odd jobs. The company maintains their brand; we&#x27;re just a courier service. You don&#x27;t go to the FedEx website to order something, you select FedEx at the end with \"how would you like this to come to you.\"- On the side, we do sell a service of \"we will give you a new pickup&#x2F;delivery portal web site that works with our delivery service\" to smaller businesses so that they can get started with us.- We are a courier service but we only operate in cities where we can sufficiently average out the volumes needed. Amazon, UPS, FedEx can be the kings of the countryside, that&#x27;s fine.- The company, assuming food, sends their delivery-person right when the food is cooked, they are our employee and package it to our standards and bring it straight out to our delivery hub. In general they will not be going to the final address. We use this as a process buffer to maximize our throughput for the people actually driving to the home addresses, we can make sure that certain people get to know neighborhood X better, etc.- The shipping price should come in two tiers, give people a generous shipping discount for advance orders where we can have more opportunity to batch and optimize.- Because the company pays us (and the user pays them for \"shipping\"), under no circumstance does the user tip; that workflow is just too indirect to sustain tipping.- Which means we have to do a 180 on how we treat the delivery folks; ideally they&#x27;d be full-time employees and we&#x27;d proactively unionize them.That last bit sounds like suicide but really there&#x27;s a ton of noise in terms of all of this \"well the question of who are our delivery people is fraught, they can drop off the map at any time\" and it&#x27;s like, no, I want to be able to say at the central hub, \"here&#x27;s the route you&#x27;re about to follow, review it while you wait 2 more minutes for Tina to arrive with order 6AF12B, that&#x27;s your third one, we&#x27;ve got the motor running for you and you know these streets better than anybody,\" and under no circumstance is that person saying \"eh, I have a party I want to go check out, I&#x27;m just going to go with these 2 orders and leave Tina in the lurch.\" And, we can sell it to city-goers as \"this is the ethical way to deliver, the union makes sure that we maintain the cars and that we pay as well as we can.\"And the rest of it is making the profit back up in volume. reply stronglikedan 12 hours agoparentprevFWIW, the people that order food regularly don&#x27;t care that they are paying an exorbitant fee for it, and there are plenty of them. The folks that don&#x27;t regularly order may order less, but that&#x27;s not going to really have a significant impact on the business overall. reply delfinom 10 hours agoparentprevEverytime I get one of those uber eats coupons for 25% or even 50% off a order, it&#x27;s rigged.Open two windows, apply the coupon in one. Watch as the order totals are not 50% apart. They instantly jack the service fees on the 50% coupon order. reply resolutebat 4 hours agorootparentIt&#x27;s 50% off the base price, which excludes the delivery fee, the convenience fee, the inconvenience fee, the COVID recovery charge, the Livable Wage surcharge etc.The last time I ordered UberEats, all the fees plus tip nearly doubled the cost of my order. reply 141 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "DoorDash is implementing operational changes in response to new minimum pay requirements for food delivery workers in New York City.",
      "Dashers will now receive a minimum of $29.93 per hour, excluding tips, which is nearly double the NYC minimum wage.",
      "The option to tip in the app will be shifted after checkout to accommodate increased fees, and the Dasher Priority Access program will be temporarily paused. DoorDash will also continue to engage with policymakers and expects further operational adjustments."
    ],
    "commentSummary": [
      "The discussion centers around food delivery services, particularly DoorDash and Uber Eats.",
      "Topics include minimum pay for delivery workers, health risks for cyclists, tax implications for gig workers, concerns about delivery drivers' practices, tipping's impact on the restaurant industry, and the availability and sustainability of food delivery.",
      "Other points of debate include alternative delivery models, the viability and profitability of food delivery platforms, challenges faced by these platforms, and the financial situation of companies like Uber."
    ],
    "points": 213,
    "commentCount": 286,
    "retryCount": 0,
    "time": 1701718643
  },
  {
    "id": 38516717,
    "title": "Implementing Long-Term Support (LTS) for Kubernetes: Simplifying Cluster Upgrades and Management",
    "originLink": "https://matduggan.com/why-kubernetes-needs-an-lts/",
    "originBody": "There is no denying that containers have taken over the mindset of most modern teams. With containers, comes the need to have orchestration to run those containers and currently there is no real alternative to Kubernetes. Love it or hate it, it has become the standard platform we have largely adopted as an industry. If you exceed the size of docker-compose, k8s is the next step in that journey. Despite the complexity and some of the hiccups around deploying, most organizations that use k8s that I've worked with seem to have positive feelings about it. It is reliable and the depth and width of the community support means you are never the first to encounter a problem. However Kubernetes is not a slow-moving target by infrastructure standards. Kubernetes follows an N-2 support policy (meaning that the 3 most recent minor versions receive security and bug fixes) along with a 15-week release cycle. This results in a release being supported for 14 months (12 months of support and 2 months of upgrade period). If we compare that to Debian, the OS project a lot of organizations base their support cycles on, we can see the immediate difference. Red Hat, whose entire existence is based on organizations not being able to upgrade often, shows you at what cadence some orgs can roll out large changes. Now if Kubernetes adopted this cycle across OSS and cloud providers, I would say \"there is solid evidence that it can be done and these clusters can be kept up to date\". However cloud providers don't hold their customers to these extremely tight time windows. GCP, who has access to many of the Kubernetes maintainers and works extremely closely with the project, doesn't hold customers to anywhere near these timelines. Neither does AWS or Azure. The reality is that nobody expects companies to keep pace with that cadence of releases because the tooling to do so doesn't really exist. Validating that a cluster can be upgraded and that it is safe to do so requires the use of third-party tooling or to have a pretty good understanding of what APIs are getting deprecated when. Add in time for validating in staging environments along with the sheer time involved in babysitting a Kubernetes cluster upgrade and a clear problem emerges. What does upgrading a k8s cluster even look like? For those unaware of what a manual upgrade looks like, this is the rough checklist. Check all third-party extensions such as network and storage plugins Update etcd (all instances) Update kube-apiserver (all control plane hosts) Update kube-controller-manager Update kube-scheduler Update the cloud controller manager, if you use one Update kubectl Drain every node and either replace the node or upgrade the node and then readd and monitor to ensure it continues to work Run kubectl convert as required on manifests None of this is rocket science and all of it can be automated, but it still requires someone to effectively be super on top of these releases. Most importantly it is not substantially easier than making a new cluster. If upgrading is, at best, slightly easier than making a new cluster and often quite a bit harder, teams can get stuck unsure what is the correct course of action. However given the aggressive pace of releases, spinning up a new cluster for every new version and migrating services over to it can be really logistically challenging. Consider that you don't want to be on the .0 of a k8s release, typically .2. You lose a fair amount of your 14 month window waiting for that criteria. Then you spin up the new cluster and start migrating services over to it. For most teams this involves a fair amount of duplication and wasted resources, since you will likely have double the number of nodes running for at least some period in there. CI/CD pipelines need to get modified, docs need to get changed, DNS entries have to get swapped. None of this is impossible stuff, or even terribly difficult stuff, but it is critical and even with automation the risk of one of these steps failing silently is high risk enough that few folks I know would fire and forget. Instead clusters seem to be in a state of constant falling behind unless the teams are empowered to make keeping up with upgrades a key value they bring to the org. My experience with this has been extremely bad, often joining teams where a cluster has been left to languish for too long and now we're running into concerns over whether it can be safely upgraded at all. Typically my first three months running an old cluster is telling leadership I need to blow our budget out a bit to spin up a new cluster and cut over to it namespace by namespace. It's not the most gentle onboarding process. Proposed LTS I'm not suggesting that the k8s maintainers attempt to keep versions around forever. Their pace of innovation and adding new features is a key reason the platform has thrived. What I'm suggesting is a dead-end LTS with no upgrade path out of it. GKE allowed customers to be on 1.24 for 584 days and 1.26 for 572 days. Azure has a more generous LTS date of 2 years from the GA date and EKS from AWS is sitting at around 800 days that a version is supported from launch to end of LTS. These are more in line with the pace of upgrades that organizations can safely plan for. I would propose an LTS release with a 24 months of support from GA and an understanding that the Kubernetes team can't offer an upgrade to the next LTS. The proposed workflow for operations teams would be clusters that live for 24 months and then organizations need to migrate off of them and create a new cluster. This workflow makes sense for a lot of reasons. First creating fresh new nodes at regular intervals is best practice, allowing organizations to upgrade the underlying linux OS and hypervisor upgrades. While you should obviously be upgrading more often than every 2 years, this would be a good check-in point. It also means teams take a look at the entire stack, starting with a fresh ETCD, new versions of Ingress controllers, all the critical parts that organizations might be loathe to poke unless absolutely necessary. I also suspect that the community would come in and offer a ton of guidance on how to upgrade from LTS to LTS, since this is a good injection point for either a commercial product or an OSS tool to assist with the process. But this wouldn't bind the maintainers to such a project, which I think is critical both for pace of innovation and just complexity. K8s is a complicated collection of software with a lot of moving pieces and testing it as-is already reaches a scale most people won't need to think about in their entire careers. I don't think its fair to put this on that same group of maintainers. LTS WG The k8s team is reviving the LTS workgroup, which was disbanded previously. I'm cautiously optimistic that this group will have more success and I hope that they can do something to make a happier middle ground between hosted platform and OSS stack. I haven't seen much from that group yet (the mailing list is empty: https://groups.google.com/a/kubernetes.io/g/wg-lts) and the Slack seems pretty dead as well. However I'll attempt to follow along with them as they discuss the suggestion and update if there is any movement. I really hope the team seriously considers something like this. It would be a massive benefit to operators of k8s around the world to not have to be in a state of constantly upgrading existing clusters. It would simplify the third-party ecosystem as well, allowing for easier validation against a known-stable target that will be around for a little while. It also encourages better workflows from cluster operators, pushing them towards the correct answer of getting in the habit of making new clusters at regular intervals vs keeping clusters around forever. Share AI is Already Killing Books I love reading. It is the thing on this earth that brings… 24 Nov 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38516717",
    "commentBody": "Kubernetes Needs an LTSHacker NewspastloginKubernetes Needs an LTS (matduggan.com) 199 points by todsacerdoti 19 hours ago| hidepastfavorite162 comments FridgeSeal 13 hours agoI disagree.Software is a garden that needs to be tended. LTS (and to a lesser extent requirements for large amounts of backwards compatibility) arguments are the path the ossification and orgs running 10+ year out of date, unsupported legacy garbage that nobody wants to touch, and nobody can migrate off because it’s so out of whack.Don’t do this. Tend your garden. Do your upgrades and releases frequently, ensure that everything in your stack is well understood and don’t let any part of your stack ossify and “crust over”.Upgrades (even breaking ones) are easier to handle when you do them early and often. If you let them pile up, and then have to upgrade all at once because something finally gave way, then you’re simply inflicting unnecessary pain on yourself. reply jl6 11 hours agoparentThat’s great if you have control over all the moving parts, but a lot of real-world (i.e. not exclusively software-based) orgs have interfaces to components and external entities that aren’t so amenable to change. Maybe you can upgrade your cluster without anybody noticing. Maybe you’re a wizard and upgrades never go wrong for you.More likely, you will be constrained by a patchwork quilt of contracts with customers and suppliers, or by regulatory and statutory requirements, or technology risk policies, and to get approval you’ll need to schedule end-to-end testing with a bunch of stakeholders whose incentives aren’t necessarily aligned to yours.That all adds up to $$$, and that’s why there’s a demand for stability and LTS editions. reply Grimblewald 4 hours agorootparentIm curious, help me understand where the breakdown happens. Abstracting a few layers away, can we assume that you have system input, your system does something, it has output. If this is correct, can we also then say that inputs are generated by systems you dont control that might not play nice with updates within your system. Similarly, changing outputs might break something dow stream.If all that holds, my question then becomes, why does your system not have a preprocesisng and postprocessong layer for compatibility? Stuff like that is easier than ever to build, and would allow your components to grow with the ecosystem? reply jl6 1 hour agorootparentIt’s all about risk. If you have a simple enough system, you might be able to hide it behind an abstraction layer that adequately contains the possible effects of change.But many interesting useful real-world systems are difficult to contain within a perfect black box. Abstractions are leaky. An API gateway, for example, cannot hide increased latency in the backend.People accountable for technology have learned, through years of pain, not to trust changes that claim to be purely technical with no possible impact on business functionality. Hence testing, approval and cost. reply Alcatros552 10 hours agorootparentprev@ji6 I have to tell you, we are using Kubernetes since the very early versions available.If you automate everything you will never have an issue with K8, you can deploy all the required dependencies in one go. You can run the tests, if done correctly this literally requires 10 minutes.This argument to have an LTS Version for me is like air. It&#x27;s the kind of Nuclear Reactor argument. We did have the money to buy Uranium to burn but now we can&#x27;t afford to dispose it normally.Kubernetes is for flexibility not for big companies which want to use their software development processes of the 90&#x27;s... reply JamesonNetworks 9 hours agorootparentYeah? Through the RBAC changes? Because thats where I gave up reply baby_souffle 12 hours agoparentprev> Don’t do this. Tend your garden. Do your upgrades and releases frequently, ensure that everything in your stack is well understood and don’t let any part of your stack ossify and “crust over”.You can&#x27;t see me, but I&#x27;m violently nodding in agreement. Faithfully adhering to these best practices isn&#x27;t always possible, though; management gonna manage how they manage and now how your ops team wants them to manage.> Upgrades (even breaking ones) are easier to handle when you do them early and often. If you let them pile up, and then have to upgrade all at once because something finally gave way, then you’re simply inflicting unnecessary pain on yourself.How different could things be if k8s had a \"you don&#x27;t break userland!\" policy akin to the way the Linux kernel operates? Is there a better balance between new stuff replacing the old and never shipping new stuff that would make more cluster operators more comfortable with upgrades? reply mfer 12 hours agoparentprevConsider where people would use something for a long time and want to keep it relatively stable for long periods? Planes, trains, and automobiles are just a few of the examples. How should over the air updates for these kinds of things work? Where are all the places that k8s is being used?If we only think of open source in datacenters we limit our thinking to just one of the many places it&#x27;s used. reply oneplane 11 hours agorootparentOr, they could use something that is not Kubernetes. If you are working with a system that is super static, Podman comes to mind. reply samus 11 hours agorootparentprevYou don&#x27;t need Kubernetes for over-the-air updates. Kubernetes is also not suitable for that. It scales up alright, but not down. As TA expounds, there are simply too many moving parts that require expertise to operate. And that&#x27;s fine. Not every software has to be able to accommodate all use cases. reply Palomides 11 hours agorootparentthey run kubernetes on fighter jets now reply andreasmetsala 10 hours agorootparentWhat kind of pilot would upgrade their fighter jet cluster midair? These are made up problems. reply vbezhenar 10 hours agorootparentThose who use GKE Autopilot, I guess? reply ClumsyPilot 9 hours agorootparentprevThe correct solution to that problem is to delete it.Seriously, I am sick of elevators thay run Javascript, cars that run docker and self driving cars running linux.This is not good enough. Our industry is a joke. reply carlhjerpe 9 hours agorootparentIf the elevator company can put in a display, run Linux, cage and electron &#x2F; webbrowser I think that&#x27;s a good idea. What I don&#x27;t think is great is frontend people I work with having \"map\" explained to them because they don&#x27;t know. vscode proves \"js bad\" wrong over and over, crap software can be written in any language. reply sitkack 7 hours agorootparentAll of those things are so complex that faults are repaired by rebooting it. That is not a solution reply carlhjerpe 1 hour agorootparentI disagree, if they can get a product with great UX through the door but has to reboot the system on a timer (maybe once it knows its empty from a PLC input) every so often I&#x27;d call it a solution. In fact, Boeing thinks rebooting an airplane is a solution to integer overflow[0].While I do not appreciate everything being a Web app it&#x27;s also a very robust platform to build upon, there aren&#x27;t many projects that gets as many eyes as browsers and their components.[0]: https:&#x2F;&#x2F;www.i-programmer.info&#x2F;news&#x2F;149-security&#x2F;8548-reboot-... replycramjabsyn 10 hours agoparentprevIts not a garden. Gardens are horizontal with no dependencies between plants.Infrastructure is a high rise building. Long term planning and careful maintenance is needed. And it shouldn&#x27;t be necessary to replace the foundation every year or two. reply oceanplexian 5 hours agorootparentYeah imagine if someone built a bridge and was like, yeah, we need to do regular updates or else it will fail and come crashing down.I feel like software engineers who preach that everything must be connected to the internet and update from the mothership regularly are fundamentally disconnected from reality. If your design is robust to begin with you should be able to depend on it without constantly fiddling with everything. reply terom 3 hours agorootparentBridges need regular maintenance or they will fail and come crashing down. reply mcmcmc 2 hours agorootparentRegular maintenance for bridges means tensioning cables, tightening loose bolts, repainting exposed parts. Not redoing the foundations every month. reply pas 29 minutes agorootparentk8s doesn&#x27;t require redoing foundations every monththis LTS hysteria is completely made-upit benefits from updates every year, also who uses naked k8s (the hard way?), folks use a distribution with an updater reply Grimblewald 4 hours agorootparentprevIt shows you do not garden. There are some pretty strigent dependancies between plants. Certain plants protect one another from specific pests, others wont tolerate the same soils. Others require planting at specfic seasons. What for some plants is underwatering is another plants overwatering. Plants arent just things we stick in the ground and watch grow. Succesful gardening requires careful consideration of each plants requirements, or dependencies if you will.That being said, you build gardens with soil and highrises with concrete. Kubernetes is soil, not cement. reply cratermoon 7 hours agorootparentprev> Gardens are horizontal with no dependencies between plants.Two words: companion plantingsAlso, there&#x27;s a world of incompatible plants. Some plants actively harm the growth of others, and some simply can&#x27;t grow in the same place because of different soil and nutrient requirements. reply iwontberude 12 hours agoparentprevKubernetes doesn&#x27;t improve sufficiently to justify the broken compatibility anymore. Projects slow down and become mature. This isn&#x27;t a bad thing. reply jmspring 8 hours agorootparentI happen to agree. Many \"new features\" aren&#x27;t necessarily needed by a large segment of the community that uses K8s.Some of the attitudes in here about software needs to be constantly evolving is just odd. Many many systems run on legacy software and hardware because, for the most part, they just work.Innovation and evolution are important, yes. But churn for the sake of churn does not fit every (most) use case... reply FridgeSeal 11 hours agorootparentprev> Projects slow down and become mature. This isn&#x27;t a bad thingI completely agree, but that’s also not-incompatible with my argument. reply wouldbecouldbe 11 hours agoparentprevKubernetes feels like Javascript has reached the sysadmins, new updates, libraries, build tools every week.It&#x27;s mainly good for keeping high paid people employed, not keeping your servers stable.I ran a cluster 1.5 years in production, took me so much energy. Especially that one night where digital ocean managed cluster forced an update that crashed all servers; and there was no sane way to fix it.I&#x27;m back to stability with old school VPS; it just works. Every now and then you run a few patches. Simple & fast deploys; what a blessing. reply hot_gril 10 hours agorootparentJavascript stuff tends to stay working, unless you&#x27;re talking about React which breaks all the react-whatever libs every time. reply firesteelrain 9 hours agorootparentprevI am not understanding how you say you ran a cluster when you were using a managed instance so you weren’t really running it. Now , going to a VPS makes you effectively the MSP. I don’t see how that addresses the LTS issues since k8s is updating so often that you have to keep pace with the updates (that you now need to do).I use a managed instance and manage my own private instance. reply btasker 1 hour agorootparent> I don’t see how that addresses the LTS issues since k8s is updating so often that you have to keep pace with the updates (that you now need to do).They&#x27;re not saying they moved to running k8s on a VPS - they&#x27;re saying they moved to using a VPS instead of k8s (i.e. have escaped the k8s upgrade cycle). reply sitkack 7 hours agorootparentprevYou do understand, please don’t use that rhetorical device here. reply firesteelrain 2 hours agorootparentPlease don’t be a dick here reply zzyzxd 9 hours agoparentprevYup. At my last company, Kubernetes was the only place where software was not 2+ years behind upstream because of this and I appreciate it a lot. And its API deprecation policy [1] made upgrade not so painful (if upgrades frequently break your stuff, check if your infra people really understand this policy, and your software vendors are compliant).1. https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;reference&#x2F;using-api&#x2F;deprecation-p... reply incahoots 12 hours agoparentprevI agree on the very principal of what you&#x27;re laying out here, but the reality is often rare if not at all in tandem with principals and \"best practices\"Manufacturing comes to mind, shuttering a machine down to apply patches monthly is going to piss off the graph babysitters, especially if the business is a 24&#x2F;7 operation, and most are currently.In an ideal world there would be times every month to do proper machine maintenance, but that doesn&#x27;t translate to big money gains for the glutton of shareholders who don&#x27;t understand anything, let alone understand that maintenance prolongs processes as opposed to running everything ragged. reply dwattttt 11 hours agorootparentYou can also run your car for longer if you never stop to take it to a mechanic too. reply Volundr 11 hours agorootparentI don&#x27;t think the comparison to taking your car to a mechanic is a good one. When I take my car to a mechanic they are returning it to a stock configuration. They don&#x27;t need to update to a new, slightly different power steering this month, new brakes next, then injectors.... reply dwattttt 11 hours agorootparentCertainly. But it&#x27;s being compared to not taking systems down to do maintenance at all.> if the business is a 24&#x2F;7 operation> In an ideal world there would be times every month to do proper machine maintenance reply ClumsyPilot 9 hours agorootparentprev> They don&#x27;t need to update to a new, slightly different power steering this month, new brakes next, then injectors....Then they find a compatability problem and the car n3eds to be rebuilt reply cultofmetatron 6 hours agoparentprev> Do your upgrades and releases frequentlythis sounds great in theory. after 5years of running a startup, you learn to pick your battles. that db library you upgraded? works great except for this one edge case where they changed the interface in an obscure portion that affects 5% of your users. it got past QA but thaat 5% of users get REAL VOCAL about it. now its in production and you&#x27;re planning an emrgency revert of that dependncy after you verify that you aren&#x27;t using any of the new features of the library.sounds doable? now multiply that by the number of dependencies your app has.I agree that it good to periodically update deps and allocate time for keeping your system up to date but Its easy to let tracking all your deps suck up all the time your startup would be better off spending on adding features that bring new users in and add to your bottom line. reply waynesonfire 4 hours agorootparentAbsolutely, it&#x27;s clear the OP hasn&#x27;t maintained anything at scale. Last thing I want to do is upgrade a rock solid library just because. reply FridgeSeal 2 hours agorootparentI suggested upgrading like it’s the wild-west where?When your rock solid dependency releases a new major version, when you’re ready you update it, and fix all the things you need to in a single PR, you take that to prod when you’re ready, and roll it back if it’s unhappy, or your favourite variation of out-and-back.What I’m advocating against, is picking a version, and then sitting on it for so long that it inevitably goes out of support, and then find yourself having a really bad, un-fun time-probably at some awful time of day- and discovering the work you need to do to get out of the current system is so much more than you initially realised, because you’re so far behind.Breaking changes happen anyway at some point, you may as well stay abreast of them. reply quickthrower2 6 hours agoparentprevI like the idea, and with something like say Chrome, this is excellent.However each upgrade of k8s needs planning. Need to check through the list to see what APIs are broken, and figure out if anything needs changing, preparing for it, including stuff the cloud provider has chucked in the mix.Probably to the point I feel like a cluster of clusters would be safer, so you can slowly roll it out. reply cpeterso 9 hours agoparentprevAt the far end of the update frequency spectrum from LTS is Google&#x27;s \"live at head\" philosophy. Google&#x27;s Abseil C++ library, for example, recommends that consumers update to Abseil&#x27;s latest commit from the master branch as often as possible. Abseil have no tagged releases besides master and an LTS branch (updated every 6-9 months).https:&#x2F;&#x2F;abseil.io&#x2F;about&#x2F;philosophy#we-recommend-that-you-cho... reply waynesonfire 4 hours agorootparentThe tag is the commit. So what. Same thing. reply stouset 5 hours agoparentprev100% agreed.Make upgrades easy, automate the tedious parts, and do them as often as possible.If you do upgrades once per several years, yes, it is going to be excruciating. reply hot_gril 10 hours agoparentprevEven if you could get everyone to tend the garden, it encourages unnecessary breaking changes or fragile design. LTS provides some much-needed backpressure. If a new feature truly requires breaking things, people who really want it will put in the effort. reply p_l 3 hours agorootparentThat&#x27;s why Kubernetes provides versioned APIs with proper lifecycles and levels of stability.A stable API is not going to change randomly on you, and of it does, it&#x27;s going to come with deprecation policy so you have time to do it.Personally I did have few \"painful\" k8s upgrades, but every time it happened it was due to long-announced large scale change... That another team didn&#x27;t want to upgrade over despite delaying so long the last version compatible became EOL reply jvans 10 hours agoparentprevI&#x27;ve spent so much time chasing down performance problems and bugs where the problem was due to an outdated dependency. Simply spending a few hours a month upgrading dependencies is a big win to avoid those situations reply jacurtis 6 hours agoparentprevI both agree and disagree with you.In theory, I agree. Tend your garden, do small upgrades often instead of major upgrades less often.In a homelab this is easy to implement. In a small organization it is too.But in the facetious \"real world\", things are a lot more complicated. I work as an SRE Manager and my team is basically ALWAYS upgrading Kubernetes. New releases drop about as fast as we can upgrade the last ones.When you work on a large cluster, doing an upgrade isn&#x27;t a simple process. It requires a ton of testing, several steps, and being very slow and methodical to make sure it is all done properly. Where I currently work, we have 2 week sprints and infrastructure changes must align with sprint cycles. So to promote an upgrade at the fastest possible schedule it requires:- Week 0: Upgrade Dev environment- Week 2: Upgrade QA Environment- Week 4: Upgrade Sandbox Environment- Week 6: Upgrade Prod EnvironmentThat is the fastest possible schedule. That assumes we do a cluster upgrade every sprint, which is 2 weeks. It also ignores other clusters for other business units. We have 4 primary product lines, so multiply all that work times 4. Plus we have supporting products (like self-hosted gitlab, codescene, and custom tools running in k8s clusters).I say fastest possible schedule because, we can&#x27;t keep up with this schedule, but even if we could it is the fastest we could go and still maintain our deployment and infrastructure promotion policies.With new releases every 3-4 months (12-16 weeks), we are essentially in a constant state of always upgrading kubernetes. Right now my team is 2 versions behind. Skipping versions doesn&#x27;t make sense because you can&#x27;t guarantee a safe upgrade when skipping versions.This is why LTS releases are nice. When you run systems at large scale, it is impractical to upgrade that often. I&#x27;d prefer to limit upgrades to no more than twice a year and personally I find annual upgrade cycles to be the best balance between \"tending the garden\" and \"not drowning in upgrade work\". LTS releases are usually tests to skip upgrades so that companies can go from LTS release to LTS release, without the need to worry about upgrading every minor version in sync.Remember, upgrading K8s clusters isn&#x27;t what my bosses want to hear my team spends our time. They want to know that observability is improving, devs are getting infrastructure support, we are building out new systems, deploying hardware for the product team, running our resiliency tests, etc.. Sure upgrading is part of the job, but i can&#x27;t be ALWAYS upgrading. I have a lot of other responsibilities. reply thiht 1 hour agorootparentWhy don’t you update dev+qa at the same time? Or qa+sandbox? Or dev+qa+sandbox? Separating these 3 might make sense for the applicative part (and even then, I think 4 environments is too many), but I’m not sure it really make sense to follow it on the infra side.I’m also not sure of why you manage all these clusters, why not merging dev, qa and sandbox in a single cluster with namespace partitioning? It would be way less work and probably more cost effective reply solatic 5 hours agorootparentprevI don&#x27;t know what your internal architecture looks like, but on the face of it, arguably you should be running Dev and QA loads on the same cluster. Either you have an organization where an SRE team is responsible for running clusters for teams, in which case why not run Dev and QA on the same cluster, or you are responsible for last-line-of-support for teams responsible for running their own clusters, in which case you say, here&#x27;s a new version of Kubernetes (e.g. a Terraform module) and in this sprint you are responsible for deploying it through dev, QA, pre-prod, and production clusters. Especially if you have separate Kubernetes clusters per product line (do you really need separate dev Kubernetes clusters per product line?). reply dalyons 4 hours agorootparentunless you have some strict security reasons, why even have separate prod clusters per product? We definitely don’t. seems to kinda miss the point of k8s - aka running all kinds of mixed workloads with separation within a cluster if you need it. reply solatic 3 hours agorootparentAgreed. Separate prod clusters per product usually fixes an organizational problem (lack of trust that running shared workloads would&#x2F;could be safe, versus giving each team their own servers) first. A lot of organizations, sadly, prefer to pay for separate clusters than to set up RBAC, ResourceQuotas, etc.Hypothetically, since the scaling limit for Kubernetes clusters is ~10,000 nodes (last I checked), you could have multiple product lines that took up 10k+ nodes each. Then there&#x27;s no reason why not to split by product line. But in the beginning it should be fine.There&#x27;s also edge cases - Kubernetes doesn&#x27;t support setting resource requests or limits for networking or I&#x2F;O, which you usually solve by setting up taints&#x2F;tolerations&#x2F;affinity to manually schedule those workloads onto nodes where you&#x27;ve manually run the numbers. But still not usually a reason to prefer separate production clusters. reply FridgeSeal 2 hours agorootparentprevFor sure, with scale comes slow-downs and new problems, that’s just an organisational reality, totally get that.I am slightly curious why an upgrade takes 2 weeks? At my current work, rolling out an upgrade (self managed clusters), rolling out an upgrade on the “happy path” is a fairly low-intensity task: we kick it off, nodes gracefully drain, upgrade and come back online. No intervention necessary. Unhappy path just requires another command to roll them back. Prod is the same, but happens slightly slower because there’s more nodes (and more independent prod clusters). reply maximinus_thrax 11 hours agoparentprevTo paraphrase someone else&#x27;s reaction, I&#x27;m violently shaking my head in disagreement. What you&#x27;re saying only works when you have 100% full control of everything (including the customer data). As someone who spent years in the enterprise space, what you&#x27;re describing is akin to &#x27;Ivory Tower Architecture&#x27;.LTS is a commitment. That is all. If someone is uncomfortable with such a commitment, then that&#x27;s fine, let me free market sort it out. But what LTS does is it tells everyone (including paying customers) that the formats&#x2F;schemas&#x2F;APIs&#x2F;etc.. in that version will be supported for a very long time and if I adopt it, I won&#x27;t have to think about it or budget too much for its maintenance for a period of time measured in months&#x2F;years.I would go the extra mile here and say that offline format should be supported FOREVER. None of that LTS bs for offline data, ever. LTS means that you&#x27;re accountable for some of the costs in your partnership with the customers. If you move fast and break things, they will have to work extra just to keep up. If you move fast but mindful with back-compat, you will work extra but your customer will be happier. That is all.Re-reading your comment gives me chills and reinforces my belief that I will never pay money to Google (they have a similar gung-ho attitude against &#x27;legacy garbage&#x27;) or have any parts of my business depend on stuff which reserves the liberty of breaking shit early and often. reply MuffinFlavored 13 hours agoparentprev> long-term support> out of date, unsupported legacy garbage reply jen20 12 hours agorootparentYou can probably remove the \"unsupported\" part without changing the overall correctness of the statement. reply Waterluvian 11 hours agoparentprevSometimes I get this feeling that a lot of developers kind of want to be in their code all the time, tending to it. But it’s just not a good use of my time. I want it to work so I can ignore it and move on to the next best use of my time.I trial upgraded a years old Django project today to 5.0 and it took almost zero work. I hadn’t touched versions (other than patch)in over a year. That’s the way I want it. Admittedly this was less about an LTS and more about sensible design with upgrading in mind. reply selcuka 8 hours agorootparent> I trial upgraded a years old Django project today to 5.0 and it took almost zero work.Django is great at backwards compatibility, but to be honest they haven&#x27;t added many revolutionary features to Django for years, except a half-baked implementation of async support. reply sofixa 17 hours agoprevThis, like a recent LTS discussion I saw for a different tool, ignores one tiny little detail that makes the whole discussion kind of moot.LTS doesn&#x27;t mean it&#x27;s immune to bugs or security vulnerabilities. It just means that the major release is updated and supported longer - but you still need to be able to apply patches and security fixes to that major release. Yes, it&#x27;s easier to go from 1.20.1 to 1.20.5 than to 1.21, because there&#x27;s less chance of breakage and less things that will change, but the process is pretty much the same - check for breaking changes, read changelogs, apply everything. The risk is less, might be slightly faster, but fundamentally, it&#x27;s the same process. If the process is too heavy and takes you too long, having it be slightly faster won&#x27;t be a gamechanger.So LTS brings slight advantages to the operator, while adding potentially significant complexity to the developer (generally backporting fixes into years old versions isn&#x27;t fun).The specific proposed LTS falvour is also hardcore, without an upgrade path to the next LTS. The exact type of org that needs an LTS will be extremely reluctant to having to redo everything, 2 years later, with potentially drastic breaking changes making that change very hard. reply x86x87 16 hours agoparentThat&#x27;s not how LTS is supposed to work. You should be able to uograde effortlessly with minimum risk.If you&#x27;re at a point where a patch for LTS looks like an upgrade to the new version you&#x27;ve screwed up LTS.Also, getting to the point of having an LTS and actually providing the support is expensive. You need experts that can backport security fixes and know the product inside out. reply sofixa 16 hours agorootparent> That&#x27;s not how LTS is supposed to work. You should be able to uograde effortlessly with minimum risk.How do you do that on something as complex and with as many moving parts as Kubernetes? And how do you as an operator update that many things without checking there&#x27;s no breaking changes in the patch? reply Rantenki 14 hours agorootparentWe upgrade our distros pretty much fearlessly, all the time. While I have had breakage from Kernel upgrades, they&#x27;ve been very rare (and generally related to third party closed drivers). Kubernetes is _not_ more complicated than the Linux kernel, but it is much more dangerous to upgrade in place. reply eddythompson80 11 hours agorootparent> Kubernetes is _not_ more complicated than the Linux kernel, but it is much more dangerous to upgrade in place.eh, the kernel is an incredibly mature project with 1 machine scope. The kernel also has decades of operating systems research and literature to build on. Kubernetes in comparison is new, distributed and exploring uncharted territory in terms of feature set and implementation. Sometimes bad decisions are made, and it&#x27;s fair to not want to live with them forever.The kernel project looks very different today than it did in 1999.There is a happy medium though, especially that Kubernetes is kinda far from it. reply x86x87 4 hours agorootparentSpoiler alert: k8s is not in uncharted territory.Erlang and its runtime discovered and solved most of the problems in the 80s. We are slowly rediscovering this the same way react discovered the event loop that Windows had discovered in the 90s. reply jen20 12 hours agorootparentprevMy answer is simple: don&#x27;t. Use something far simpler and with fewer moving parts than Kubernetes, and something where crucial parts of the ecosystem required to make things even basically work are not outsourced to third party projects.Nomad is a good solution. reply x86x87 16 hours agorootparentprevbingo! how do you do it? and do you want that kind of complexity to begin with? reply sofixa 15 hours agorootparentDon&#x27;t ask me, I&#x27;m firmly in the HashiCorp Nomad camp: https:&#x2F;&#x2F;atodorov.me&#x2F;2021&#x2F;02&#x2F;27&#x2F;why-you-should-take-a-look-at... (Note: quite old, some things are no longer true most notably around Nomad downsides) reply rigrassm 15 hours agorootparentI&#x27;m with you, Nomad is highly underrated! reply freedomben 16 hours agorootparentprevI don&#x27;t see anywhere that GP said an LTS patch would take effort. They said the upgrade path to the next LTS would.If you are talking about upgrade from LTS to LTS, can you give an example project where that is effortless? And if so, how do they manage to innovate and modernize without ever breaking backwards compatibility? reply x86x87 16 hours agorootparentHere: \"it&#x27;s easier to go from 1.20.1 to 1.20.5 than to 1.21, because there&#x27;s less chance of breakage and less things that will change, but the process is pretty much the same\"LTS to LTS is another story. But the point is that L=LongTerm so in theory you&#x27;re only going to do this exercise twice in a decade.> manage to innovate and modernize without ever breaking backwards yeah. fuck backwards compatibility. that is for suckers. how about stopping the madness for a second and thinking about what you are building when you build it? reply pixl97 14 hours agorootparent> in theory you&#x27;re only going to do this exercise twice in a decade.So I&#x27;ve seen things like this in corporations many times and it typically works like this...Well trained team sets up environment. Over time team members leave and only less senior members remain. They are capable of patching the system and keeping it running. Eventually the number of staff even capable of patching the system diminishes. System reaches end of life and vendor demands upgrading. System falls out of security compliance and everything around it is an organizational exception in one way or another. Eventually at massive cost from outside contractors the system gets upgraded and the cycle begins all over again.Not being able to upgrade these systems is about the lack of and loss of capable internal staff. reply x86x87 4 hours agorootparentWhat is the cost of keeping it \"up to date\" vs doing this exercise once every say 7 years? Are most software systems even around for 7 years? reply p_l 3 hours agorootparentI&#x27;ve recently worked in a high profile company where it took them long and painful to move from CentOS 6 to 7 (over a year long effort, IIRC, finished for prod in 2021? but with some crucial corp infra still on 6 in 2022).In 2022 they had to start a new huge effort do deal with migration off CentOS7, and the problems were so painful it was considered reasonable to build a Linux distro from scratch and remove all traces of distro dependency from the product (SaaS) replyKarellen 16 hours agoparentprev> but the process is pretty much the same - check for breaking changes,Unless you&#x27;re relying on buggy behaviour, there should be no breaking changes in an LTS update.(...of course, there&#x27;s no guarantee that you&#x27;re not relying on buggy (or, at least, accidental) behaviour. People relying on `memcpy(3)` working as expected when the ranges overlap, simply because it happened to do so with historic versions of the `libc` implementation they most commonly happened to test with, is one example. But see also obxkcd https:&#x2F;&#x2F;xkcd.com&#x2F;1172&#x2F; and https:&#x2F;&#x2F;www.hyrumslaw.com&#x2F; ) reply natbennett 14 hours agorootparentIt’s impossible to avoid the occasional breaking change in an LTS, especially for software like this. Security fixes are inherently breaking changes— just for users we don’t like. reply natbobc 14 hours agorootparentprevComparing a single function to an entire ecosystem is crazy. Making an LTS imposes a skew of compatibility and support to all downstream vendors as well as the core team. The core team has done a great job on keeping GAed resources stable across releases. Understand there’s more to it than that but you should be regularly upgrading your dependencies as par-four the course not swallowing an elephant every 2 years or whenever a CVE forces your hand. The book Accelerate highlights this quite succinctly. reply Karellen 11 hours agorootparent* https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;par_for_the_course reply sofixa 15 hours agorootparentprev> Unless you&#x27;re relying on buggy behaviour, there should be no breaking changes in an LTS update.Or a security vulnerability has forced a breaking change. Or any other issue, which is why you have to check. reply Karellen 15 hours agorootparent> Or a security vulnerability has forced a breaking change.Theoretically, I suppose?Do you have a historic example in mind?I&#x27;ve been running Debian \"stable\" in its various incarnations on servers for over a decade, and I can&#x27;t remember any time any service on any installation I&#x27;ve run had such an issue. But my memory is pretty bad, so I might have missed one. (Or even a dozen!) But I have `unattented-upgrades` installed on all my live servers right now, and don&#x27;t lose a wink of sleep over it. reply natbennett 14 hours agorootparentThis happens all the time on systems that are running hundreds of thousands of apps across hundreds of customers.The worst one I know: for a while basically all Cloud Foundry installations were stuck behind a patch release because the routing component upgraded their Go version and that Go version included an allegedly non-breaking-change that caused it to reject requests with certain kinds of malformed headers.The Spring example app has a header with the specific problem impacted. And the vast majority of Cloud Foundry apps are Spring apps, many of which got started by copying the Spring example app.So upgrading CF past this patch release required a code change to the apps running on the platform. Which the people running Cloud Foundry generally can’t get — there’s usually a team of like 12 people running them and then 1000s of app devs. reply sofixa 15 hours agorootparentprevYes, I have an example in mind - https:&#x2F;&#x2F;askubuntu.com&#x2F;questions&#x2F;1376118&#x2F;ubuntu-20-04-lts-una...Yes, it&#x27;s Ubuntu, but doesn&#x27;t matter - sometimes security fixes require a breaking change and there&#x27;s nothing that can be done to avoid it. reply toast0 14 hours agorootparentprevOpenSSL isn&#x27;t necessarily the best at LTS, but 1.0.1 released a series of changes to how they handled ephemeral diffie hellman generation, which could be hooked in earlier releases, but not in later releases.For the things I was doing on the hooks, it became clear that I needed to make changes and get them added upstream, rather than doing it in hooks, but that meant we were running OpenSSL with local patches in the interim of upstream accepting and releasing my changes. If you&#x27;re not willing to run a locally patched security critical dependency, it puts you between a rock and a hard place. replycyrnel 11 hours agoprevGood overview! I&#x27;d personally rather have better tooling for upgrades. Recently the API changes have been minimal, but the real problem is the mandatory node draining that causes downtime&#x2F;disruption.In theory, there&#x27;s nothing stopping you from just updating the kubelet binary on every node. It will generally inherit the existing pods. Nomad even supports this[1]. But apparently there are no guarantees about this working between versions. And in fact some past upgrades have broken the way kubelet stores its own state, preventing this trick.All I ask is for this informal trick to be formalized in the e2e tests. I&#x27;d write a KEP but I&#x27;m too busy draining nodes![1]: https:&#x2F;&#x2F;developer.hashicorp.com&#x2F;nomad&#x2F;docs&#x2F;upgrade reply zzyzxd 9 hours agoparent> but the real problem is the mandatory node draining that causes downtime&#x2F;disruption. > ... > In theory, there&#x27;s nothing stopping you from just updating the kubelet binary on every node.I am pretty sure Kubernetes itself does not mandate node draining. I have been doing upgrade for bare metal cluster for years, and like you said, it&#x27;s mostly just replacing kubelet binary and bounce.However, I do understand in public cloud it&#x27;s usually recommended to perform a node rolling update instead of modifying online nodes in place. Actually, I prefer this way because of the benefits of immutable infrastructure. The downtime is unfortunately, but so far I have been enjoying working with devs to better designing reliable apps to tolerate node issues like this. reply op00to 11 hours agoparentprev100% as someone who used to support Kubernetes commercially, long term support is an engineering nightmare with kube. My customers who could upgrade easily were more stable and easily supported. The customers that couldn’t handle an upgrade were the exact opposite - long support cases, complex request processes for troubleshooting information, the deck was probably stacked against them from the start.Anyway, make upgrades less scary and more routine and the risk bubbles away. reply xnyanta 4 hours agoparentprevYou definitely don&#x27;t need to drain your nodes. I have never drained my nodes on my peronal cluster and just update and restart the control-plane components.The procedure is more of a cloud-ism where people don&#x27;t upgrade their nodes in place but rather get entirely new nodes. reply willejs 10 hours agoparentprevRotating out nodes during an upgrade is slow and potentially disruptive, however your systems should be built to handle this, and this is a good way of forcing it. reply linuxftw 10 hours agoparentprev> the real problem is the mandatory node draining that causes downtime&#x2F;disruption.This sounds a lot like \"We don&#x27;t actually patch the OS\" which is quite common among many companies.As a former enterprise kubernetes distro maintainer, I can tell you with certainty that most on-premise kubernetes customers aren&#x27;t patching their machines between kubernetes releases, and try to stay on kubernetes releases for 18+ months. reply cyrnel 9 hours agorootparentI have hope for that problem to be solved too, with some combination of minimal kernels and live patching. I really don&#x27;t think running two copies of everything and hammering CPU&#x2F;RAM&#x2F;Disk&#x2F;Network with constant drain operations is a permanent solution for applying patches. reply kevin_nisbet 13 hours agoprevFrom my perspective as a former developer on a kubernetes distribution that no longer exists.The model seems to largely be, the CNCF&#x2F;Kubernetes authors have done a good job of writing clear expectations for the lifetime for their releases. But there are customers who for various reasons want extended support windows.This doesn&#x27;t prevent the distribution from offering or selling extended support windows, so the customers of those distributions can put the pressure on those distribution authors. This is something we offered as a reason to use our distribution, that we can backport security fixes or other significant fixes to older versions of kubernetes. This was especially prevalent for the customers we focussed on, which were lots of clusters installed in places without remote access.This created a lot of work for us though, as whenever a big security announcement came out, I&#x27;d need to triage on whether we needed a backport. Even our extended support windows were in tension with customers, who wanted even longer windows, or would open support cases on releases out of support for more than a year.So I think the question really should be, should LTS be left to the distributions, many of which will select not to offer longer releases than upstream, but allow for some more commercial or narrow offerings where it&#x27;s important enough to a customer to pay for it. Or whether it should be the responsibility of the Kubernetes authors and in that case what do you give up in project velocity with more work to do on offering and supporting LTS.I personally resonate with the argument that this can be left with the distributors, and if it&#x27;s important enough customers to seek out, they can pay for it through their selected distribution, or switching distributions.But many customers lose out, because they&#x27;re selecting distributions that don&#x27;t offer this service, because it is time consuming and difficult to do. reply JohnFen 13 hours agoparentAs an industry, we need to get back to having security releases separate from other sorts of releases. There are tons of people who don&#x27;t want to, or can&#x27;t, take every feature release that comes down the pike (particularly since feature updates happen so insanely often these days), and this would be a huge win for them. reply xnyanta 4 hours agoparentprevThis was my immediate though while reading thr article. Why should the kubernetes authors be burdened by having to maintain an LTS release.That should be Red Hat&#x27;s job, just like they do with RHEL. reply edude03 13 hours agoparentprevMaybe more importantly, you could get a distribution to support you but what about upstream projects? It&#x27;d be a big lift (if not impossible) to get projects like cert-manager cilium whatever to adopt the longer release cycle as well.Is it normal for a distribution to also package upstream projects that customers want? reply baby_souffle 13 hours agorootparent> Maybe more importantly, you could get a distribution to support you but what about upstream projects? It&#x27;d be a big lift (if not impossible) to get projects like cert-manager cilium whatever to adopt the longer release cycle as well.Exactly this. I see a lot of parallels between k8s releases and OS releases. Even if you&#x27;re paying microsoft for patches to windows XP, I&#x27;m not seeing any of that and the python runtime that most of my software relies on also isn&#x27;t seeing their cut so... I guess upgrade to at least python 3.10 and then call me back?I would prefer to see the conversation turn more to \"what can be done to reduce reluctance to upgrading? How can we make k8s upgrades painless so there&#x27;s minimal incentive to stick with a long out of date release?\" reply kevin_nisbet 13 hours agorootparentprev> It&#x27;d be a big lift (if not impossible) to get projects like cert-manager cilium whatever to adopt the longer release cycle as well.It&#x27;s a great point which probably should be part of the discussion. Say even if Kubernetes project offered LTS, how would that play into every other project that is pulled together.> Is it normal for a distribution to also package upstream projects that customers want?I suspect it differs by distribution. The distribution I worked on included a bunch of other projects, but it was also pretty niche. reply sgift 13 hours agoparentprev> But many customers lose out, because they&#x27;re selecting distributions that don&#x27;t offer this service, because it is time consuming and difficult to do.Sure, but if they really need that service they will gravitate to distributions that do provide it, so, I think, no harm done here. It&#x27;s to me like JDK distributions. Some give you six month, some give free LTS and others give you LTS with a support contract. LTS with backports is work, someone has to pay for it, so let those who really need it pay. Everyone else can enjoy the new features.tl;dr: I&#x27;m with you in the camp that you can leave it to the distributors. reply fostware 7 hours agoprevFor a group so devoted to \"cattle, not pets\", so many responses here indicate an almost constant need for hands-on effort from upgrade testing, UAT, right through to post-upgrade hypercare.I&#x27;d like a slightly longer LTS purely so I&#x27;m not having to spend all my time spinning the plates to keep things up. I don&#x27;t need 10 years LTS, I need three so I can work with the rest of the enterprise that moves even slower. reply barryrandall 15 hours agoprevNo open source package that&#x27;s given away for free needs to or should pursue LTS releases. People who want LTS need a commercially-supported distribution so that they can pay people to maintain LTS versions of the product they&#x27;re using. reply watermelon0 14 hours agoparentNot saying that companies shouldn&#x27;t pay for extended support, but many other open source software have LTS releases with multi-year support (e.g. Ubuntu&#x2F;Debian 5 years for LTS releases, and Node.js for 2.5 years.)Additionally, I think one of the major reason for LTS is that K8s (and related software) regularly introduces breaking changes. Out of all the software that we use at work, K8s probably takes the most development time to upgrade. reply ses1984 12 hours agorootparentPeople pay for longer versions of that, called extended support, ubuntu provides a cut down version for free. reply airocker 12 hours agoparentprevMaybe GKE and EKS should make LTS versions. reply stackskipton 10 hours agorootparentAzure already has. https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;azure&#x2F;aks&#x2F;long-term-suppor... reply airocker 9 hours agorootparentTwo years may or may not be enough \"long term\" depending on the product and the business. reply stackskipton 6 hours agorootparentIt&#x27;s not long enough for a ton of their customers.They are probably at extent of what they can handle with 2 years without Kubernetes Team getting onboard. reply waynesonfire 14 hours agoparentprevMaybe my team of 15 engineers that manage the k8s stack can do it. reply 55 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Upgrading Kubernetes clusters can be challenging and complex, prompting the idea of implementing a long-term support (LTS) release with a fixed support period.",
      "An LTS release could offer organizations a more manageable upgrade cycle and encourage better cluster management practices.",
      "The revival of the LTS workgroup brings anticipation for potential progress in this area, which could benefit Kubernetes operators globally and simplify the third-party ecosystem."
    ],
    "commentSummary": [
      "There is an ongoing debate regarding whether Kubernetes needs a Long-Term Support (LTS) version.",
      "Some argue for frequent upgrades to prevent outdated and unsupported software, while others emphasize the need for stability and LTS editions due to organizational constraints.",
      "The discussion also includes alternative solutions, challenges of maintenance and continuous operation, system management, different approaches to updates, running Kubernetes on different platforms, and the importance of compatibility and careful planning."
    ],
    "points": 199,
    "commentCount": 162,
    "retryCount": 0,
    "time": 1701694903
  }
]
