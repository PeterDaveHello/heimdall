[
  {
    "id": 37791002,
    "title": "Making Hard Things Easy",
    "originLink": "https://jvns.ca/blog/2023/10/06/new-talk--making-hard-things-easy/",
    "originBody": "Julia Evans ABOUT TALKS PROJECTS TWITTER MASTODON GITHUB FAVORITES ZINES RSS New talk: Making Hard Things Easy • TALKS • A few weeks ago I gave a keynote at Strange Loop called Making Hard Things Easy. It’s about why I think some things are hard to learn and ideas for how we can make them easier. Here’s the video, as well as the slides and a transcript of (roughly) what I said in the talk. the video the transcript Hello, Strange Loop! Strange Loop is one of the first places I spoke almost 10 years ago and I'm so honored to be back here today for the last one. Can we have one more round of applause for the organizers? I often give talks about things that I'm excited about, or that I think are really fun. But today, I want to talk about something that I'm a little bit mad about, which is that sometimes things that seem like they should be basic take me 10 years or 20 years to learn, way longer than it seems like they should. One thing that took me a long time to learn was DNS, which is this question of -- what's the IP address for a domain name like example.com? This feels like it should be a straightforward thing. But seven years into learning DNS, I'd be setting up a website. And I'd feel like things should be working. I thought I understood DNS. But then I'd run into problems, like my domain name wouldn't work. And I'd wonder -- why not? What's happening? And sometimes this would feel kind of personal! This shouldn't be so hard for me! I should understand this already. It's been seven years! And this \"it's just me\" attitude is often encouraged -- when I write about finding things hard to learn on the Internet, Internet strangers will sometimes tell me: \"yeah, this is easy! You should get it already! Maybe you're just not very smart!\" But luckily I have a pretty big ego so I don't take the internet strangers too seriously. And I have a lot of patience so I'm willing to keep coming back to a topic I'm confused about. There were maybe four different things that were going wrong with DNS in my life and eventually I figured them all out. So, hooray! I understood DNS! I win! But then I see some of my friends struggling with the exact same things. They're wondering, hey, my DNS isn't working. Why not? And it doesn't end. We're still having the same problems over and over and over again. And it's frustrating! It feels redundant! It makes me mad. Especially when friends take it personally, and they feel like \"hey I should really understand this already\". Because everyone is going through this. From the sounds of recognition I hear, I think a lot of you have been through some of these same problems with DNS. I got so mad about this that I decided to make it my job. I started a little publishing company called Wizard Zines where -- (applause) Wow. Where I write about some of these topics and try to demystify them. Here are a few of the zines I've published. I want to talk today about a few of these topics and what makes them so hard and how we can make them easier. We're going to talk about bash, HTTP, SQL, and DNS. For each of them, we're going to talk a little bit about: a. what's so hard about it? b. what are some things we can do to make it a little bit easier for each other? Let's start with Bash. What's so hard about it? So, bash is a programming language, right? But it's one of the weirdest programming languages that I work with. To understand why it's weird, let's do a little small demo of bash. First, let's run this script, bad.sh: mv ./*.txt /tmmpp echo \"success!\" This moves a file and prints \"success!\". And with most of the programming languages that I use, if there's a problem, the program will stop. [laughter from audience] But I think a lot of you know from maybe sad experience that bash does not stop, right? It keeps going. And going... and sometimes very bad things happen to your computer in the process. When I run this program, here's the output: mv: cannot stat './*.txt': No such file or directory success! It didn't stop after the failed mv. Eventually I learned that you can write set -e at the top of your program, and that will make bash stop if there's a problem. When we run this new program with set -e at the top, here's the output: mv: cannot stat './*.txt': No such file or directory Great. We're happy. Everything is good. But every time I think I've learned everything that go wrong with bash, I'll find out -- surprise! There are more bad things that can happen! Let's look at another program as an example. Here we've put our code in a function. And if the function fails, we want to echo \"failed\". So use set -e at the beginning, and you might think everything should be okay. But if we run it... this is the output we get mv: cannot stat './*.txt': No such file or directory success We get the \"success\" message again! It didn't stop, it just kept going. This is because the \"or\" (|| echo \"failed\") globally disables set -e in the function. Which is certainly not what I wanted, and not what I would expect. But this is not a bug in bash, it's is the documented behavior. And I think one reason this is tricky is a lot of us don't use bash very often. Maybe you write a bash script every six months and don't look at it again. When you use a system very infrequently and it's full of a lot of weird trivia and gotchas, it's hard to use the system correctly. So how can we make this easier? What can we do about it? One thing that I sometimes hear is -- a newcomer will say \"this is hard\", and someone more experienced will say \"Oh, yeah, it's impossible to use bash. Nobody knows how to use it.\" But I would say this is factually untrue. How many of you are using bash? A lot of us ARE using it! And it doesn't always work perfectly, but often it gets the job done. We have a lot of bash programs that are mostly working, and there's a big community of us who are using bash mostly successfully despite all the problems. The way I think this is -- you have some people on the left in this diagram who are confused about bash, who think it seems awful and incomprehensible. And some people on the right who know how to make the bash work for them, mostly. So how do we move people from the left to the right, from being overwhelmed by a pile of impossible gotchas to being able to mostly use the system correctly? Well, bash has a giant pile of trivia to remember. But who's good at remembering giant piles of trivia? Not me! I can't memorize all of the weird things about bash. But computers! Computers are great at memorizing trivia! And for bash, we have this incredible tool called shellcheck. [ Applause ] Yes! Shellcheck is amazing! And shellcheck knows a lot of things that can go wrong and can tell you \"oh no, you don't want to do that. You're going to have a bad time.\" I'm very grateful for shellcheck, it makes it much easier for me to write tiny bash scripts from time to time. Now let's do a shellcheck demo! $ shellcheck -o all bad-again.sh In bad-again.sh line 7: f || echo \"failed!\" ^-- SC2310 (info): This function is invoked in an || condition so set -e will be disabled. Invoke separately if failures should cause the script to exit. Shellcheck gives us this lovely error message. The message isn't completely obvious on its own (and this check is only run if you invoke shellcheck with -o all). But shellcheck tells you \"hey, there's this problem, maybe you should be worried about that\". And I think it's wonderful that all these tips live in this linter. I'm not trying to tell you to write linters, though I think that some of you probably will write linters because this is that kind of crowd. I've personally never written a linter, and I'm definitely not going to create something as cool as shellcheck! But instead, the way I write linters is I tell people about shellcheck from time to time and then I feel a little like I invented shellcheck for those people. Because some people didn't know about the tool until I told them about it! I didn't find out about shellcheck for a long time and I was kind of mad about it when I found out. I felt like -- excuse me? I could have been using shellcheck this whole time? I didn't need to remember all of this stuff in my brain? So I think an incredible thing we can do is to reflect on the tools that we're using to reduce our cognitive load and all the things that we can't fit into our minds, and make sure our friends or coworkers know about them. I also like to warn people about gotchas and some of the terrible things computers have done to me. I think this is an incredibly valuable community service. The example I shared about how set -e got disabled is something I learned from my friend Jesse a few weeks ago. They told me how this thing happened to them, and now I know and I don't have to go through it personally. One way I see people kind of trying to share terrible things that their computers have done to them is by sharing \"best practices\". But I really love to hear the stories behind the best practices! If someone has a strong opinion like \"nobody should ever use bash\", I want to hear about the story! What did bash do to you? I need to know. The reason I prefer stories to best practices is if I know the story about how the bash hurt you, I can take that information and decide for myself how I want to proceed. Maybe I feel like -- the computer did that to you? That's okay, I can deal with that problem, I don't mind. Or I might instead feel like \"oh no, I'm going to do the best practice you recommended, because I do not want that thing to happen to me\". These bash stories are a great example of that: my reaction to them is \"okay, I'm going to keep using bash, I'll just use shellcheck and keep my bash scripts pretty simple\". But other people see them and decide \"wow, I never want to use bash for anything, that's awful, I hate it\". Different people have different reactions to the same stories and that's okay. That's all for bash. Next up we're gonna talk about HTTP. I was talking to Marco Rogers at some point, many years ago, and he mentioned some new developers he was working with were struggling with HTTP. And at first, I was a little confused about this -- I didn't understand what was hard about HTTP. The way I was thinking about it at the time was that if you have an HTTP response, it has a few parts: a response code, some headers, and a body. I felt like -- that's a pretty simple structure, what's the problem? But of course there was a problem, I just couldn't see what it was at first. So, I talked to a friend who was newer to HTTP. And they asked \"why does it matter what headers you set?\" And I said: \"well, the browser...\" But then I thought... the browser? the browser? The browser! Firefox is 20 million lines of code! It's been evolving since the '90s. There have been as I understand it, 1 million changes to the browser security model as people have discovered new and exciting exploits and the web has become a scarier and scarier place. The browser is really a lot to understand. One trick for understanding why a topic is hard is -- if the implementation if the thing involves 20 million lines of code, maybe that's why people are confused! Though that 20 million lines of code also involves CSS and JS and many other things that aren't HTTP, but still. Once I thought of it in terms of how complex a modern web browser is, it made so much more sense! Of course newcomers are confused about HTTP if you have to understand what the browser is doing! Then my problem changed from \"why is this hard?\" to \"how do I explain this at all?\" So how do we make it easier? How do we wrap our minds around this 20 million lines of code? One way I think about this for HTTP is: here are some of the HTTP request headers. That's kind of a big list there are 43 headers there. There are more unofficial headers too. My brain does not contain all of those headers, I have no idea what most of them are. When I think about trying to explain big topics, I think about -- what is actually in my brain, which only contains a normal human number of things? This is a comic I drew about HTTP request headers. You don't have to read the whole thing. This has 15 request headers. I wrote that these are \"the most important headers\", but what I mean by \"most important\" here is that these are the ones that I know about and use. It's a subjective list. I wrote about 12 words about each one, which I think is approximately the amount of information about each header that lives in my mind. For example I know that you can set Accept-Encoding to gzip and then you might get back a compressed response. That's all I know, and that's usually all I need to know! This very small set of information is working pretty well for me. The general way I think about this trick is \"turn a big list into a small list\". Turn the set of EVERY SINGLE THING into just the things I've personally used. I find it helps a lot. Another example of this \"turn a big list into a small list\" trick is command line arguments. I use a lot of command line tools, the number of arguments they have can be overwhelming, and I've written about them a fair amount over the years. Here are all the flags for grep, from its man page. That's too much! I've been using grep for 20 years but I don't know what all that stuff is. But when I look at the grep man page, this is what I see. I think it's very helpful to newcomers when a more experienced person says \"look, I've been using this system for a while, I know about 7 things about it, and here's what they are\". We're just pruning those lists down to a more human scale. And it can even help other more experienced people -- often someone else will know a slightly different set of 7 things from me. But what about the stuff that doesn't fit in my brain? Because I have a few things about HTTP stored in my brain. But sometimes I need other information which is hard to remember, like maybe the exact details of how CORS works. And so, that's where we come to references. Where do we find the information that we can't remember? I often have trouble finding the right references. For example I've been trying to learn CSS off and on for 20 years. I've made a lot of progress -- it's going well! But only in the last 2 years or so I learned about this wonderful website called CSS Tricks. And I felt kind of mad when I learned about CSS Tricks! Why didn't I know about this before? It would have helped me! But anyway, I'm happy to know about CSS Tricks now. (though sadly they seem to have stopped publishing in April after the acquisition, I'm still happy the older posts are there) For HTTP, I think a lot of us use the Mozilla Developer Network. Another HTTP reference I love is the official RFC, RFC 9110 (also 9111, 9112, 9113, 9114) It's a new authoritative reference for HTTP and it was written just last year, in 2022! They decided to organize all the information really nicely. So if you want to know exactly what the Connection header does, you can look it up. This is not really my top reference. I'm usually on MDN. But I really appreciate that it's available. So I love to share my favorite references. I do sometimes find it tempting to kind of lie about references. Not on purpose. But I'll see something on the internet, and I'll think it's kind of cool, and tell a friend about. But then my friend might ask me -- \"when have you used this?\" And I'll have to admit \"oh, never, I just thought it seemed cool\". I think it's important to be honest about what the references that I'm actually using in real life are. Even if maybe the real references I use are a little \"embarrassing\", like maybe w3schools or something. So that's HTTP! Next we're going to talk about SQL. The case of the mysterious execution order. I started thinking about SQL because someone mentioned they're trying to learn SQL. I get most of my zine ideas that way, one person will make an offhand comment and I'll decide \"ok, I'm going to spend 4 months writing about that\". It's a weird process. So I was wondering -- what's hard about SQL? What gets in the way of trying to learn that? I want to say that when I'm confused about what's hard about something, that's a fact about me. It's not usually that the thing is easy, it's that I need to work on understanding what's hard about it. It's easy to forget when you've been using something for a while. So, I was used to reading SQL queries. For example this made up query that tries to find people who own exactly two cats. It felt straightforward to me, SELECT, FROM, WHERE, GROUP BY. But then I was talking to a friend about these queries who was new to SQL. And my friend asked -- what is this doing? I thought, hmm, fair point. And I think the point my friend was making was that the order that this SQL query is written in, is not the order that it actually happens in. It happens in a different order, and it's not immediately obvious what that is. So how do we make this easier? I like to think about: what does the computer do first? What actually happens first chronologically? Computers actually do live in the same timeline as us. Things happen. Things happen in an order. So what happens first? The way I think about an SQL query is: is you start with a table like cats. Then maybe you filter it, you remove some stuff. Then you make some groups. Then you filter the groups, remove some of them. Then you do some aggregation. There's two things in each group. And you sort it. And you can also limit the results. So, that's how I think about SQL. The way a query runs is first FROM, then WHERE, GROUP BY, HAVING, SELECT, ORDER BY, LIMIT. At least conceptually. Real life databases have optimizations and it's more complicated than that. But this is the mental model that I use most of the time and it works for me. Everything is in the same order as you write it, except SELECT is fifth. I've really gotten a lot out of this trick where you try to tell the chronological story of what the computer is doing. I want to talk about a couple other examples. One is CORS, in HTTP. This comic is way too small to read on the slide. But the idea is if you're making a cross-origin request in your browser, you can write down every communication that's happening between your browser and the server, in chronological order. And I think writing down everything in chronological order makes it a lot easier to understand and more concrete. \"What happens in chronological order?\" is a very straightforward structure, which is what I like about it. \"What happens first?\" feels like it should be easy to answer. But it's not! I've found that it's actually very hard to know what our computers is doing, and it's a really fun question to explore. As an example of how this is hard: I wrote a blog post recently called \"Behind Hello World on Linux\". It's about what happens when you run \"hello world\" on a Linux computer. I wrote a bunch about it, and I was really happy with it. But after I wrote the post, I thought -- haven't I written about this before? Maybe 10 years ago? And sure enough, I'd tried to write a similar post 10 years before. I think this is really cool. Because the 2013 version of this post was about 6 times shorter. This isn't because Linux is more complicated than it was 10 years ago -- I think everything in the 2023 post was probably also true in 2013. The 2013 post just has a lot less information in it. The reason the 2023 post is longer is that I didn't know what was happening chronologically on my computer in 2013 very well, and in 2023 I know a lot more. Maybe in 2033 I'll know even more! I think a lot of us -- like me in 2013 and honestly me now, often don't know the facts of what's happening on our computers. It's very hard, which is what makes it such a fun question to try and discuss. I think it's cool that all of us have different knowledge about what is happening chronologically on our computers and we can all chip in to this conversation. For example when I posted this blog post about Hello World on Linux, some people mentioned that they had a lot of thoughts about what happens exactly in your terminal, or more details about the filesystem, or about what's happening internally in the Python interpreter, or any number of things. You can go really deep. I think it's just a really fun collaborative question. I've seen \"what happens chronologically?\" work really well as an activity with coworkers, where you're ask: \"when a request comes into this API endpoint we run, how does that work? What happens?\" What I've seen is that someone will understand some part of the system, like \"X happens, then Y happens, then it goes over to the database and I have no idea how that works\". And then someone else can chime in and say \"ah, yes, with the database A B C happens, but then there's a queue and I don't know about that\". I think it's really fun to get together with people who have different specializations and try to make these little timelines of what the computers are doing. I've learned a lot from doing that with people. That's all for SQL. So, now we've arrived at DNS which is where we started the talk. Even though I struggled with DNS. Once I got figured it out, I felt like \"dude, this is easy!\". Even though it just took me 10 years to learn how it works. But of course, DNS was pretty hard for me to learn. So -- why is that? Why did it take me so long? So, I have a little chart here of how I think about DNS. You have your browser on the left. And over on the right there's the authoritative nameservers, the source of truth of where the DNS records for a domain live. In the middle, there's a function that you call and a cache. So you have browser, function, cache, source of truth. One problem is that there are a lot of things in this diagram that are totally hidden from you. The library code that you're using where you make a DNS request -- there are a lot of different libraries you could be using, and it's not straightforward to figure out which one is being used. That was the source of some of my confusion. There's a cache which has a bunch of cached data. That's invisible to you, you can't inspect it easily and you have no control over it. that And there's a conversation between the cache and the source of truth, these two red arrows which also you can't see at all. So this is kind of tough! How are you supposed to develop an intuition for a system when it's mostly things that are completely hidden from you? Feels like a lot to expect. So, what do we do about this? So: let's talk about these red arrows on the right. We have our cache and then we have the source of truth. This conversation is normally hidden from you because you often don't control either of these servers. Usually they're too busy doing high-performance computing to report to you what they're doing. But I thought: anyone can write an authoritative nameserver! In particular, I could write one that reports back every single message that it receives to its users. So, with my friend Marie, we wrote a little DNS server. (demo of messwithdns.net) This is called Mess With DNS. The idea is I have a domain name and you can do whatever you want with it. We're going to make a DNS record called strangeloop, and we're going to make a CNAME record pointing at orange.jvns.ca, which is just a picture of an orange. Because I like oranges. And then over here, every time a request comes in from a resolver, this will -- this will report back what happened. So, if we click on this link, we can see -- a Canadian DNS resolver, which is apparently what my browser is configured to use, is requesting an IPv4 record and an IPv6 record, A and AAAA. (at this point in the demo everyone in the audience starts visiting the link and it gets a bit chaotic, it's very funny) So the trick here is to find ways to show people parts of what the computer is doing that are normally hidden. Another great example of showing things that are hidden is this website called float.exposed by Bartosz Ciechanowski who makes a lot of incredible visualizations. So if you look at this 32-bit floating point number and click the \"up\" button on the significand, it'll show you the next floating point number, which is 2 more. And then as you make the number bigger and bigger (by increasing the exponent), you can see that the floating point numbers get further and further apart. Anyway, this is not a talk about floating point. I could do an entire talk about this site and how we can use it to see how floating point works, but that's not this talk. Another thing that makes DNS confusing is that it's a giant distributed system -- maybe you're confused because there are 5 million computers involved (really, more!). Most of which you have no control over, and some are doing not what they're supposed to do. So that's another trick for understanding why things are hard, check to see if there are actually 5 million computers involved. So what else is hard about DNS? We've talked about how most of the system is hidden from you, and about how it's a big distributed system. One problem I've run into is that the tools are confusing. One of the hidden things I talked about was: the resolver has cached data, right? And you might be curious about whether a certain domain name is cached or not by your resolver right now. Just to understand what's happening: am I getting this result because it was cached? What's the deal? I said this was hidden, but there are a couple of ways to query a resolver to see what it has cached, and I want to show you one of them. The tool I usually use for making DNS queries is called dig, and it has a flag called +norecurse. You can use it to query a resolver and ask it to only return results it already has cached. With dig +norecurse jvns.ca, I'm kind of asking -- how popular is my website? Is it popular enough that someone has visited it in the last 5 minutes? Because my records are not cached for that long, only for 5 minutes. But when I look at this response, I feel like \"please! What is all this?\" And when I show newcomers this output, they often respond by saying \"wow, that's complicated, this DNS thing must be really complicated\". But really this is just not a great output format, I think someone just made some relatively arbitrary choices about how to print this stuff out in the 90s and it's stayed that way ever since. So a bad output format can mislead newcomers into thinking that something is more complicated than it actually is. What can we do about confusing output like this? One of my favorite tricks, I call eraser eyes. Because when I look at that output, I'm not looking at all of it, I'm just looking at a few things. My eyes are ignoring the rest of it. When I look at the output, this is what I see: it says SERVFAIL. That's the DNS response code. Which as I understand it is a very unintuitive way of it saying, \"I do not have that in my cache\". So nobody has asked that resolver about my domain name in the last 5 minutes, which isn't very surprising. I've learned so much from people doing a little demo of a tool, and showing how they use it and which parts of the output or UI they pay attention to, and which parts they ignore. Becuase usually we ignore most of what's on our screens! I really love to use dig even though it's a little hairy because it has a lot of features (I don't know of another DNS debugging that supports this +norecurse trick), it's everywhere, and it hasn't changed in a long time. And I know if I learn its weird output format once I can know that forever. Stability is really valuable to me. So we've talked about these four technologies. Let's talk a little more about how we can make things easier for each other. What can we do to move folks from \"I really don't get it\" to \"okay, I can mostly deal with this, at least 90% of the time, it's fine\"? For bash or HTTP or DNS or anything else. We've talked about some tricks I use to bring people over, like: sharing useful tools sharing references telling a chronological story of what happens on your computer turning a big list into a small list of the things you actually use showing the hidden things demoing a confusing tool and telling folks which parts I pay attention to When I practiced this talk, I got some feedback from people saying \"julia! I don't do those things! I don't have a blog, and I'm not going to start one!\" And it's true that most people are probably not going to start programming blogs. But I really don't think you need to have a public presence on the internet to tell the people around you a little bit about how you use computers and how you understand them. My experience is that a lot of people (who do not have blogs!) have helped me understand how computers work and have shared little pieces of their experience with computers with me. I've learned a lot from my friends and my coworkers and honestly a lot of random strangers on the Internet too. I'm pretty sure some of you here today have helped me over the years, maybe on Twitter or Mastodon. So I want to talk about some archetypes of helpful people One kind of person who has really helped me is the grumpy old-timer. I'll say \"this is so cool\". And they'll reply yes, however, let me tell you some stories of how this has gone wrong in my life. And those stories have sometimes helped spare me some suffering. We have the loud newbie, who asks questions like \"wait, how does that work?\" And then everyone else feels relieved -- \"oh, thank god. It's not just me.\" I think it's especially valuable when the person who takes the \"loud newbie\" role is actually a pretty senior developer. Because when you're more secure in your position, it's easier to put yourself out there and say \"uh, I don't get this\" because nobody is going to judge you for that and think you're incompetent. And then other people who feel more like they might be judged for not knowing something can ride along on your coattails. Then we have the bug chronicler. Who decides \"ok, that bug. This can never happen again\". \"I'm gonna make sure we understand what happened. Because I want this to end now.\" We have the tool builder, whose attitude is more like \"I see people struggling with something, and I don't feel like explaining it. But I can write code to just make it easier permanently for everyone.\" There's this \"today I learned\" person who's into sharing cool new tools they learned about, a bug that they ran into, or a great new-to-them library feature. There's the person who has read the entire Internet and has 700 tabs open. If you want to know where to find something, there's a good chance they already have it open in their browser. We have the person who is just willing to answer questions! \"Yeah, I can tell you how that works!\" And at the end of all this, sometimes you have someone who likes to write some things down so that other people can read it and can find it later. But all of us have different roles and we need to work together. I'm into writing but a lof of the stuff I've written about, I only know about because someone told me about it or explained it to me. To end: the one thing I would like to convince you of is: if you're struggling with something that feels basic, it's not just you! You're not alone. We're all struggling with a lot of these things that feel like they should be \"basic\". And we're struggling with these things for a lot of the same reasons as each other. And much like when debugging a computer program, when you have a bug, you want to understand why the bug is happening if you're gonna fix it. If we're all struggling with the same things together for the same reasons, if we can figure out what those reasons are, we can do a better job of fixing them. Some of the reasons we've talked about were: a giant pile of trivia and gotchas. or maybe there's 20 million lines of code somewhere. Maybe a big part of the system is being hidden from you. Maybe the tool's output is extremely confusing and no UI designer has ever worked on improving it And there are a lot more reasons. I don't have all the answers for why things are hard. For example I don't really understand why Git is hard, that's something I've been thinking about recently. But that's something I'm excited to keep working on and keep trying to figure out. And that's all I have for you. Thank you. I brought some zines to the conference, if you come to the signing later on you can get one. some thanks This was the last ever Strange Loop and I’m really grateful to Alex Miller and the whole organizing team for making such an incredible conference for so many years. Strange Loop accepted one of my first talks (you can be a kernel hacker) 9 years ago when I had almost no track record as a speaker so I owe a lot to them. Thanks to Sumana for coming up with the idea for this talk, and to Marie, Danie, Kamal, Alyssa, and Maya for listening to rough drafts of it and helping make it better, and to Dolly, Jesse, and Marco for some of the conversations I mentioned. Also after the conference Nick Fagerland wrote a nice post with thoughts on why git is hard in response to my “I don’t know why git is hard” comment and I really appreciated it. It had some new-to-me ideas and I’d love to read more analyses like that. Want a weekly digest of this blog? Subscribe In a git repository, where do your files live? ARCHIVES © Julia Evans. If you like this, you may like Ulia Ea or, more seriously, this list of blogs I love or some books I've read. You might also like the Recurse Center, my very favorite programming community (my posts about it)",
    "commentLink": "https://news.ycombinator.com/item?id=37791002",
    "commentBody": "Making Hard Things EasyHacker NewspastloginMaking Hard Things Easy (jvns.ca) 870 points by hasheddan 19 hours ago| hidepastfavorite175 comments justin_oaks 15 hours agoThe part that resonated most with me is \"Show things that are normally hidden\".Tools that do this make things clearer almost immediately. Consider the developer tools in a web browser. Do you remember the \"dark ages\" before such things existed? It was awful because you had to guess instead of seeing what was going on.Tools like Wireshark that show you every last byte of network packets that it has access to AND parses it to help you see the structure. This isn&#x27;t just for debugging networking data; it&#x27;s hugely beneficial in teaching networking concepts because nothing is hidden.This is also one of my favorite things about open source software. I can view the source to understand what&#x27;s causing a bug, to fill in knowledge gaps left by the documentation, or just learn more about programming concepts. Nothing is hidden. reply raincole 9 hours agoparentThe game development equivalent of these is renderDoc. I was stunned when I learned its existance for the first time. reply carterschonwald 8 hours agorootparentI’m about to embark on my first real and truly massive graphics project. Thx for mentioning such a cool tool. reply jzwinck 14 hours agoparentprevWireshark is great but it does not show you every byte the network carried. For example it never shows Ethernet preambles, only sometimes shows Ethernet frame checksums, and never shows interpacket gaps (which are a required part of the Ethernet protocol).So yes it comes close but it just goes to show you, there is always more detail hiding somewhere! reply justin_oaks 14 hours agorootparentYes, the toughest \"hidden things\" problems are pulling together data that is related, but not part of the same system. In this case, Wireshark can only show you what the OS gives to it.In the article, it was pointed out that DNS caches can be hidden. They&#x27;re especially hidden when they&#x27;re upstream and in another computer! reply kortilla 6 hours agorootparentprevIt doesn’t show electrical signals either. That’s a pointless nitpick if you’re developing anything beyond an Ethernet implementation. reply AceJohnny2 9 hours agorootparentprevAre the Ethernet frame checksums even visible to Wireshark, which hooks into the IP layer? would some of the ethernet stuff be only visible within the ethernet card itself, not to the software stack? reply jzwinck 6 hours agorootparentSometimes they are. It depends on how the capture was generated. If you look in the options of Wireshark there is one to detect bad checksums, so clearly there is a way to capture them. Here is one such way: https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;22101650&#x2F;how-can-i-recei...This can be used to detect partially-bad network cables, because there is no reason you should ever receive a bad FCS. reply thelittleone 33 minutes agorootparentprevWireshark works at the data link layer (L2). reply 5pales 14 hours agorootparentprevTo be fair, the preamble can be easily considered just an electrical signal due to its objective (sync) which doesn&#x27;t affect how the network works. reply vaughan 12 hours agoparentprevMy dream is to make everything visualizable at runtime. I think all of computing becomes very simple and much less complex if we can do this.We are visualizing things in our head already. And any explanation of anything in computing is a diagram. But we have zero diagrams when coding.Just dynamically instrument all code to send messages to a GUI. reply the-alchemist 11 hours agorootparentClojure does pretty well. See https:&#x2F;&#x2F;github.com&#x2F;nubank&#x2F;morse, https:&#x2F;&#x2F;docs.datomic.com&#x2F;cloud&#x2F;other-tools&#x2F;REBL.html, and https:&#x2F;&#x2F;vlaaad.github.io&#x2F;reveal&#x2F;.It&#x27;s one of the areas that homoiconicity helps: code is data, data is code, so visualization tools can work on both sides. reply giantg2 6 hours agoparentprev&#x27;\"Show things that are normally hidden\". Tools that do this make things clearer almost immediately.&#x27;At least with all the DevOps shit going on now, it seems that many of the tools increasingly hide things. And the gurus who had that knowledge and could teach you are now concentrated in those tool companies instead of in your org. reply wilkystyle 6 hours agoparentprevThis is one thing I love about Magit for Emacs. The UI is really clever and slick—maybe the best Git frontend that I&#x27;ve ever used—but the way you interact with UI is by toggling flags and options that actually map to the underlying command line Git arguments. I can seamlessly hop into the command line and feel right at home using it directly. reply TeMPOraL 3 hours agorootparentOn top of the UI having very tight and visible relationship to git CLI commands, there&#x27;s also a log buffer showing you exact commands executed and their outputs, and it&#x27;s only a single $ press away. reply agent281 3 hours agoparentprevThis is what I like about SQL databases. They frequently have tables that you can query to find system information. This makes it easy to explore the system within the system.The proc filesystem on Linux is philosophically similar. It allows you to understand processes by working with files. reply Natsu 11 hours agoparentprevMan, having spent waaaay too long troubleshooting errors where it&#x27;s not remotely clear what part of the config the program is even consulting makes this hit home. reply userbinator 7 hours agoparentprevThis is also one of my favorite things about open source software. I can view the source to understand what&#x27;s causing a bug, to fill in knowledge gaps left by the documentation, or just learn more about programming concepts. Nothing is hidden.On the contrary, you don&#x27;t need the source, and in some cases it may even be misleading in many ways, when you can look directly at the instructions the machine executes. Tools like disassemblers and decompilers would be equivalent to what you speak of. reply saghm 6 hours agorootparentNothing stops you from doing this with open source software either, though; making something open source is strictly an increase in the information available, and at least to me that seems in the spirit of \"show me things that are normally hidden\" reply dclowd9901 8 hours agoparentprevYep. Mozilla developer tools basically launched my career. reply swayvil 13 hours agoparentprevSector editor!(Or back in the day, looking at the source code because we ran uncompiled stuff in Basic and whatever and that was pretty cool) reply justin_oaks 12 hours agorootparentThat&#x27;s one of the advantages of using programming languages where source code is distributed (e.g. Python, JavaScript, PHP), not compiled binary artifacts (C&#x2F;C++, Java). You can see the source. You can even modify it and run the modified version without compilation.It&#x27;s also awesome to use Java IDEs that can show both the bytecode of .class files and also perform decompilation. reply JacobSeated 21 minutes agoprevThanks for this. It is similar to how I feel these days; I am currently learning vue.js, and working on 3 different components at the same time (I should probably have focused on a single component, but the boss kept finding things that needed improvements).I also never worked with vue before. At one point I found myself utterly confused; opening up a file to do something, and instantly forgetting what I was doing, having to go back and re-read code. I was super tired after an near all-nighter at this point, but felt like I had sleep deprived induced dementia or something. In occasional brief moments, I was totally unable to focus or remember what I was doing. Very interesting feeling actually.When you have not worked with something before, and you are on a deadline, it is just a pretty awful experience. Vue, however, is supposed to be simple and make things easier for the developer. Well, not if you come from a back-end PHP background, with only moderate JavaScript experience, and there is literally no documentation on how things work in the CMS I am currently working with. Have to read existing code and try to replicate things. It is nasty beyond nasty! reply dkarl 11 hours agoprev> One thing that I sometimes hear is -- a newcomer will say \"this is hard\", and someone more experienced will say \"Oh, yeah, it&#x27;s impossible to use bash. Nobody knows how to use it.\"> But I would say this is factually untrue. How many of you are using bash?I think the meaning of the statement is not that straightforwardly literal.I think what it means is, \"We don&#x27;t have strong confidence in our understanding of our bash code or confidence that it will behave as we expect in untested scenarios. If anything out of the ordinary happens, we kind of expect that something will fail and we will learn something new about bash that will make us cringe and&#x2F;or strike a nearby object hard enough to injure ourselves.\"Bash is a complex language, and for most programmers, it is unlike any other language they use. Most companies have a little bit in production somewhere, and most of them don&#x27;t have a single person who writes enough bash to know it well. I think it&#x27;s no accident that build tools, CI tools, and cloud orchestration tools are evolving in the direction of minimizing the need for shell scripting. reply saghm 6 hours agoparentI think the question is whether a newcomer will understand the implicit meaning or if they might interpret it more literally than its meant. In particular, \"for most programmers, it is unlike any other language they use\" is not something someone new would necessarily be able to infer because that sentiment requires enough experience to tell the difference between \"uncommon\" and \"extremely esoteric\". reply hiAndrewQuinn 15 hours agoprevJulia has to be one of the most likable people in tech! Every time I read one of her articles I feel that same bubbly rush of excitement I got when I was a kid, just starting to unfurl the secrets of reality through my own little experiments. Absolutely lovely. reply WiSaGaN 6 hours agoparentYes, it&#x27;s rare to find someone who possesses deep technological know-how and is also a brilliant teacher and communicator. Andrej Karpathy is another who comes to mind. Fortunately, I&#x27;ve discovered that more people fit this mold recently. reply MrPoush 14 hours agoparentprevShe was LOVELY in person as well. I got her to sign my copy of How DNS Works. reply nuancebydefault 14 hours agoparentprevFor a second I thought you were talking about Julia the language. :) reply hiAndrewQuinn 9 hours agorootparentShhh... You&#x27;ll make me miss undergrad. c: reply andrepd 10 hours agoparentprevVery much. I&#x27;m usually not a fan of the \"omg awesomesauce\"-style of overexcited blogposts or tutorials, (I much prefer the drier, high signal-to-noise ratio, concise, beautiful texts of the Landau&Lifschitz style), but her posts all make me feel that giddy rush of excitement you&#x27;re talking about :) reply Aeolun 8 hours agorootparentI think because it feels authentic, rather than forced.It’s really easy to bleed one into the other. reply cryptonector 17 hours agoprevTo make hard things easy you have to find the right way to abstract them so you hold only some bits of the hard things in your head and all the frequently-used details too (maybe), and everything else you have to look up as needed. That&#x27;s what I do, and that&#x27;s roughly what TFA says.The problem is that people don&#x27;t necessarily bother to form a cognitive compression of a large topic until they really have to. That&#x27;s because they already carry other large cognitive burdens with them, so they (we!) tend to resist adding new ones. If you can rely on someone else knowing some topic X well, you might just do that and not bother getting to know topic X well-enough. For those who know topic X well the best way to reduce help demand is to help others understand a minimal amount of topic X.> So, bash is a programming language, right? But it&#x27;s one of the weirdest programming languages that I work with.Yes, `set -e` is broken. The need to quote everything (default splitting on $IFS) is broken. Globbing should be something one has to explicitly ask for -- sure, on the command-line that would be annoying, but in scripts it&#x27;s a different story, and then you have to disable globbing globally, and globbing where you want to gets hard. Lots of bad defaults like that.It&#x27;s not just Bash, but also Ksh, and really, all the shells with the Bourne shell in their cultural or actual lineage.As for SQL, yes, lots of people want the order of clauses to be redone. There&#x27;s no reason it couldn&#x27;t be -- I think it&#x27;d be a relatively small change to existing SQL parsers to allow clauses to come in different orders. But I don&#x27;t have this particular cognitive problem, and I think it&#x27;s because I know to look at the table sources first, but I&#x27;m not sure. reply chubot 12 hours agoparentYes, `set -e` is brokenThe need to quote everything (default splitting on $IFS) is brokenGlobbing should be something one has to explicitly ask forBy the way OSH runs existing shell scripts and ALSO fixes those 3 pitfalls, and more. Just add shopt --set ysh:upgradeto the top of your script, and those 3 things will go away.If anyone wants to help the project, download a tarball, test our claims, and write a blog post about it :)Details:https:&#x2F;&#x2F;www.oilshell.org&#x2F;release&#x2F;latest&#x2F;doc&#x2F;error-handling.h...https:&#x2F;&#x2F;www.oilshell.org&#x2F;release&#x2F;latest&#x2F;doc&#x2F;simple-word-eval...These docs are comprehensive, but most people don&#x27;t want that level of detail, so having someone else test it and write something short would help!For awhile I didn&#x27;t \"push\" Oils because it still had a Python dependency. But it&#x27;s now in pure C++, and good news: as of this week, we&#x27;re beating bash on some compute-bound benchmarks!(I&#x2F;O bound scripts have always been the same speed, which is most shell scripts)(Also, we still need to rename Oil -> YSH in those docs, that will probably cause some confusion for awhile - https:&#x2F;&#x2F;www.oilshell.org&#x2F;blog&#x2F;2023&#x2F;03&#x2F;rename.html ) reply chubot 4 hours agorootparentSlight correction: bin&#x2F;ysh has a few things that ysh:upgrade doesn&#x27;t catchhttps:&#x2F;&#x2F;lobste.rs&#x2F;s&#x2F;6gycoi&#x2F;making_hard_things_easy#c_sjfxifFeedback is welcome (especially based on upgrading real scripts) reply esafak 17 hours agoparentprevThe problem is that we&#x27;re still using these ancient shells when we have better ones. Users shouldn&#x27;t be wasting time memorizing arcana like \"set -e\". At least we have search engines now... reply hiAndrewQuinn 15 hours agorootparentI&#x27;m quite partial to the fish shell myself for this reason.But I SSH into a lot of embedded systems these days, where you don&#x27;t exactly have the luxury of installing your own shell all the time. For those times I like to whip out the \"minimal safe Bash template\" and `sftp` it to the server.https:&#x2F;&#x2F;betterdev.blog&#x2F;minimal-safe-bash-script-template&#x2F; reply theshrike79 13 hours agorootparentWhen the shell script is that long, I reach for Python or Go instead pretty fast =) reply imp0cat 14 hours agorootparentprevAu contraire, bash&#x2F;sh is pretty much everywhere.Also, we have ChatGPT now. That helps a lot. reply dgb23 17 hours agoparentprevA possibly radical way of fixing the SQL clause order would be to introduce \"project\" which behaves like \"select\" but can be put in the right place. reply esafak 14 hours agorootparenthttps:&#x2F;&#x2F;malloydata.github.io&#x2F;documentation&#x2F;language&#x2F;views reply hyperthesis 12 hours agoparentprevWhen explanations include superfluous detail, I find it very confusing. Like Chekhov&#x27;s gun, I keep trying to fit it into the plot but it doesn&#x27;t fit.My super power is a terrible memory. So I have to understand things in order to remember them (aka a cognitive compression). I can&#x27;t just learn things like normal people. reply vaughan 12 hours agoparentprev> As for SQLWe should peel off SQL and get access to the underlying layers. reply mfrw 18 hours agoprevTiL: The shell does not exit if the command that fails is a part of any command executed in a && or || list except the command following the final && or ||.Reference: https:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;bash&#x2F;manual&#x2F;bash.html#index-set reply bityard 18 hours agoparent\"Fails\" is a higher-level concept than the shell is concerned with. Failure conditions and reactions are entirely at the discretion of the programmer and are not built as an assumption into the shell.The only thing &#x2F;bin&#x2F;false does is return 1. Is that a failure? No, that&#x27;s how it was designed to work and literally what it is for. I have written hundreds of shell scripts and lots of them contain commands which quite normally return non-zero in order to do their job of checking a string for a certain pattern or whatever.Programs are free to return whatever exit codes they want in any circumstance they want, and common convention is to return 0 upon success and non-zero upon failure. But the only thing that the shell is concerned with is that 0 evaluates to \"true\" and non-zero evaluates to \"false\" in the language.It would be pretty inconvenient if the shell exited any time any program returned non-zero, otherwise if statements and loops would be impossible.If a script should care about the return code of a particular program it runs, then it should check explicitly and do something about it. As you linked to, there are options you can set to make the shell exit if any command within it returns non-zero, and lots of beginner to intermediate shell script writers will _dogmatically_ insist that they be used for every script. But I have found these to be somewhat hacky and full of weird hard-to-handle edge cases in non-trivial scripts. My opinion is that if you find yourself needing those options in every script you write, maybe you should be writing Makefiles instead. reply rightbyte 14 hours agorootparent> It would be pretty inconvenient if the shell exited any time any program returned non-zero, otherwise if statements and loops would be impossible.In another life I worked as a Jenkins basher and if I remember correctly I had this problem all the time with some Groovy dsl aborting on any non zero shell command exit. It was so annoying. reply jks 18 hours agoparentprevThis is because && and || are often used as conditionals: [ -e README ] && cat READMEavoids an error if the file README doesn&#x27;t exist, and [ -e README ] || echo \"You should write a README!\"works the opposite way.What&#x27;s more pernicious is that pipelines don&#x27;t cause the shell to exit (assuming set -e) unless the last command fails: grep foo READMEsortdoes not fail if README doesn&#x27;t exist, unless you&#x27;ve also used `set -o pipefail`. reply strangesmells02 17 hours agorootparentso what happens?? it just hang up on the foo?? reply osmsucks 17 hours agorootparent`grep` should terminate with an empty output on `stdout` and an error message on `stderr`, then `sort` will successfully sort the empty contents of `stdout` reply jstimpfle 17 hours agoparentprevThere are more arcane things to learn about shell, at some point one has to go shrug, it&#x27;s a fine tool for getting quick results but not for writing robust programs. reply jongjong 10 hours agoprevOn a related note, most software is over-engineered. I think it&#x27;s partly because of centralization of the industry; it&#x27;s pushing everyone towards a small number of tools for the benefit of a small number of people who control them and so many of these tools end up becoming &#x27;everything tools&#x27; and cover more use cases than they should.Companies want developers to all know the same tools; that way they are easily replaceable across projects and companies and have little bargaining power in the industry. This is why software has a single mainstream trunk and alternative approaches are shunned with no jobs available. The industry is not being allowed to decentralize despite the fact that it naturally &#x27;wants&#x27; to.On the bright side, I think that eventually, some new, far superior non-mainstream approaches are going to materialize and they will erode the mainstream approaches.Tech is not like math and not even like science; it can support MANY different branches solving any given problem in many different ways. reply quickthrower2 9 hours agoparentI agree. In some ways it feels like we have gone backwards in web dev since say the early days of ASP.NET and Rails. Back then we had browser wars to keep is busy. But now browsers are broadly compatible but we have invented all this front end complexity for web apps that often don’t need it.Stuff like DNS, IP, https can’t be helped as they are fundamental things that need backwards compatibility and are somewhat political too.I feel that learning those things well is a better investment though than learning the frameworks.… if I keep going I will start talking about innovation tokens! reply hiAndrewQuinn 8 hours agorootparentYou can learn both, though. As much as people like to trash talk it, I think learning from \"the bottom up\", as long as you remember to follow the 80&#x2F;20 principle and not go too deep into unnecessary rabbit holes, is still the best approach in terms of long term ROI on your time. I got a degree in EE because I wanted to be a \"true\" full stack engineer; last year I finally got a chance to learn React and a lot of cockpit flight hours setting Microsoft Azure. It took longer but I feel I&#x27;m on much steadier ground to keep climbing up. reply karmakaze 18 hours agoprevThis is a great description of things that seem like they shouldn&#x27;t be so difficult but can have many complications. The SQL part seems to double-down on a conceptual failure rather than demystifying it though.A query&#x27;s logic is declarative which defines the output. It&#x27;s the query plan that has any sense of execution order or procedural nature to it. That&#x27;s the first thing to learn. Then one can learn the fuzzy areas like dependent subqueries etc. But being able to see the equivalence between not-exists and an anti-join enables understanding and reasoning.Using an analogy such as procedurally understanding of written queries only kicks the can further down the road, then when you&#x27;re really stuck on something more complicated have no way to unravel the white lies. reply zvmaz 18 hours agoparent> The SQL part seems to double-down on a conceptual failure rather than demystifying it though.She talked about a mental model to help her understand the query (it can be useful), and mentioned that it probably is not how the database actually processes the query. reply karmakaze 17 hours agorootparentMy point is that there should be two mental models. One for getting the correct results. Then another for doing so performantly. Being able to write many different forms of obtaining the same correct results is where this leads to combined understanding and proficiency.An example of where muddling these ends up with real questions like \"how does the db know what the select terms are when those sources aren&#x27;t even defined yet?\" By &#x27;yet&#x27; they mean lexically but also procedurally. reply justinpombrio 12 hours agorootparentI suspect that Julia is solely using the first kind of mental model (getting the correct result), and completely ignoring query planning. But even this model has an order to it! Three examples of how this order can manifest, that should all agree with each other:1. The explanatory diagrams that Julia drew for the talk. These wouldn&#x27;t make sense if they were in a different order.2. The order of operations you would perform if you developed a proof of concept SQL implementation that completely ignored performance. In this example the order would be: \"cats, filter, group, filter, map, sort\". This is exactly the order that Julia&#x27;s explanation showed.3. The relational logic expression for this query. There should be a correspondence between this expression and this ordered list of operations, though it&#x27;s somewhat annoying to state. I think it&#x27;s that, assuming all the operators in the relational logic expression are binary, if you reverse the order that a subset of the operators are written in, then the operators in the tree occur in the same order as the ordered list of operations. (I don&#x27;t actually know relational logic, so I&#x27;m making a prediction here. This prediction is falsifiable: you can&#x27;t put the operators in the tree in an arbitrary order.)(Side note: the order isn&#x27;t completely fixed. The last two steps --- SELECT and ORDER BY --- could happen in either order.) reply Izkata 2 hours agorootparentIf there&#x27;s an index on the ORDER BY fields, it can even be first. reply renegade-otter 18 hours agoparentprevTopical recent episode about Postgres - but can be extrapolated in many cases to other databases: https:&#x2F;&#x2F;www.se-radio.net&#x2F;2023&#x2F;09&#x2F;se-radio-583-lukas-fittl-on... reply zvmaz 19 hours agoprevExcellent talk. She seems to be a very likable person. She is right about Bash being full of \"gotchas\" and trivia and memorizing them all is very hard, but I think it is nice to memorize some trivia. For instance, I tended to forget the order of the arguments of the find command, and I would lose time trying to remember its syntax when I&#x27;m in front of a machine with no readily available internet connection. So I committed to learning and memorizing the most common command line tools and some of their \"gotchas\". I used Anki for that, and some mnemonics, and the return on the investment has been worth it I think. reply hiAndrewQuinn 15 hours agoparentI came here to say Anki is my lifeline for grokking difficult things like DNS.It was in fact on jvns.ca&#x27;s book recommendation that I got Michael W. Lucas&#x27;s _Networking for System Administrators_, and strip mined it for Anki cards containing both technical know-how and more than a little sysadmin wisdom.It might be one of the highest ROI books I&#x27;ve ever read, considering I actually remember how to use things like nectat and tcpdump to debug transport layer issues at a moment&#x27;s notice now. reply asicsp 18 hours agoparentprevI maintain a file with commands that I don&#x27;t use often (ex: increase volume with ffmpeg, add a border to an image with convert, etc). I even have a shortcut that&#x27;ll add the last executed command to this file and another shortcut to search from this file. reply xenodium 10 hours agorootparentOh, specially ffmpeg and imagemagick! I have a handful of incantations saved over time.Just today I saved a new one for trimming borders on video screenshots https:&#x2F;&#x2F;xenodium.com&#x2F;trimming-video-screenshots to https:&#x2F;&#x2F;github.com&#x2F;xenodium&#x2F;dwim-shell-command&#x2F;blob&#x2F;main&#x2F;dwi... (that’s my cheat sheet).I wrote an Emacs package that works fairly well for saving commands but also making them reusable from its file manager without the need to tweak input or output file paths https:&#x2F;&#x2F;github.com&#x2F;xenodium&#x2F;dwim-shell-commandWhile Emacs isn’t everyone’s cup of tea, I think the same concept can be applied elsewhere. Right click on file(s) from macOS Finder or Windows Explorer and apply any of those saved commands.Edit: More examples…- Stitching multiple images: https:&#x2F;&#x2F;xenodium.com&#x2F;joining-images-from-the-comfort-of-dire...- Batch apply on file selections: https:&#x2F;&#x2F;xenodium.com&#x2F;emacs-dwim-shell-command reply redlohr 18 hours agorootparentprevOh, that&#x27;s a great idea. I have a doc that I maintain by hand, either via \">>\" or editing directly. Time to go and make a shortcut. Do you do any annotation to help with the search? reply mmcdermott 18 hours agorootparentA large Justfile (https:&#x2F;&#x2F;just.systems&#x2F;) of random recipes might be a way to make it both executable and searchable (at least on zsh, you can get an autocomplete list of completions from the command line). reply cole-k 17 hours agorootparentCan you think of a single CLI tool that would let me commit a past incantation to a file and retrieve it later? Especially one that syncs well across devices.The best I can think of is Atuin (https:&#x2F;&#x2F;github.com&#x2F;atuinsh&#x2F;atuin) but I wasn&#x27;t super interested in using it - I kind of want something more lightweight. reply mmc 15 hours agorootparentI&#x27;ve been using a little set of bash funcs I called `hs` for this for a few years:https:&#x2F;&#x2F;github.com&#x2F;mikemccracken&#x2F;hsyour snippets are stored in a git repo that you can sync around how you like. reply asicsp 18 hours agorootparentprevUsually no annotations, as I typically search by command name. But sometimes I edit the file to add comments if there are many examples for the same command. reply cole-k 17 hours agorootparentprevIf you don&#x27;t mind, it would be awesome to see your cheatsheet. I think this would be a great thing for people to share - like their dotfiles. But maybe they already do and I don&#x27;t pay much attention to it because I&#x27;m lazy - like their dotfiles. reply hiAndrewQuinn 15 hours agorootparentprevI like `fzf`&#x27;s default override of Ctrl+R backwards search for this purpose, along with the fish shell&#x27;s really good built in autocompletion.I&#x27;ve been thinking about updating the GIFs in my fzf tutorial to show off fish, but I think I&#x27;d rather leave them with ish just so I don&#x27;t dilute the pedagogical message. reply fiddlerwoaroof 17 hours agorootparentprevIf you’re already putting them in a file, you might as well put them in a shell script on $PATH: at a certain point I started writing shell scripts and little utilities for relatively infrequently used commands and other tasks (e.g. clone this repo from GitHub to a well-known location and cd to it) reply eschneider 17 hours agorootparentKeeping a ~&#x2F;bin directory with all your personal shell shortcut scripts has been my go-to for years. I tend to make a lot of project-specific shortcut scripts for anything that I want to remember&#x2F;becomes a common task. reply brezelgoring 15 hours agorootparentprevNobody asked but I&#x27;d like to chime in with my method.I have a lot of aliases, for example to start my QEMU VM with my development stuff in it, I make an alias for &#x27;qemu-system-x86_64 [...]&#x27; with all the switches and devices and files required, called &#x27;startvm&#x27;. I have another that takes me to my current project&#x27;s folder and pulls the repo. And a third that creates a new folder called &#x27;newproject&#x27;, creates a small set of folders and empty files with specific names, and finally makes a git repo in it. I am a serial abandoner of projects so I use this more often than I care to admit.It&#x27;s not pretty, but functional; and since I always copy my dotfiles when I change computers, I&#x27;ve kept these small helpers with me for a while now. reply ustad 16 hours agorootparentprevWait, how do you “cd to it” from within the script? Doesn’t exiting the script take you back to where you were? reply justin_oaks 16 hours agorootparentYou&#x27;re right that you often can&#x27;t modify your current environment by invoking a shell script. That&#x27;s because it&#x27;s executed in a sub-shell.For cases where you need to modify your current environment (setting environment variables, changing directories, etc), you need to run the script using the \"source\" built-in. That will execute the script in the current shell rather than a sub-shell.So instead of .&#x2F;some-script.shyou&#x27;d run source some-script.shor use the dot (\".\") shorthand . some-script.shIn cases where I need to source a script, I generally create an alias or a shell function for it. Otherwise I may forget to source it. reply fiddlerwoaroof 15 hours agorootparentprevFor this I use shell functions in my .zshrc and I wrote a loader to source a bunch of files in a .zsh.d directory. reply tripleo1 13 hours agorootparentRolled your own direnv? reply fiddlerwoaroof 9 hours agorootparentNo, this is global: I use direnv too.It’s more like “roll your own oh-my-zsh” replykenoh 18 hours agorootparentprevPretty much the same, though I usually just keep the file open in a side terminal. I want to use stuff like cheat.sh (ex. curl cheat.sh&#x2F;grep) but I never remember. reply thwarted 18 hours agoparentprevI tended to forget the order of the arguments of the find command, and I would lose time trying to remember its syntax when I&#x27;m in front of a machine with no readily available internet connection.The man pages are readily available.The bash man page is huge and hairy, but comprehensive, I&#x27;ve found it pretty valuable to be familiar with the major sections and the visual shape of the text in the man page so I can page through it quickly to locate the exact info I need. This is often faster than using a Internet search engine. reply zvmaz 18 hours agorootparent> The man pages are readily available.True, but I find the man pages not easy and quick to parse. reply pixelbyindex 17 hours agorootparentI&#x27;m not a fan of man pages. Or any documentation that focuses on textual explanations rather than examples in code (looking at you aws).I recently found https:&#x2F;&#x2F;tldr.sh&#x2F; and found it more convenient. I ended up writing myself a vscode extension to have a quick lookup at my fingertips, since I am at least 60% of the time looking at a terminal in vscode reply imp0cat 18 hours agorootparentprevRight. I don&#x27;t think you&#x27;re supposed to read them top-to-bottom.Use `&#x2F;` and search for the things of interest (keywords, arguments, options, etc...). Use n&#x2F;N to quickly jump forward&#x2F;back. reply lazide 14 hours agorootparentFind has a particularly bad man page to find things that way. reply imp0cat 11 hours agorootparentAFAIK there is a find replacement with sane defaults: https:&#x2F;&#x2F;github.com&#x2F;sharkdp&#x2F;fd , a lot of people I know love it.However, I already have this in my muscle memory: find-name &#x27;&#x27; -type f(file)&#x2F;d(directory)Works in 90% of situations when searching for some file in terminal, ie: find &#x2F; -name &#x27;stuff*&#x27;The rest of the time is spent figuring out exec&#x2F;xargs. :)And once you master that, swap xargs for GNU parallel. I bet your machine has a ton of cores, don&#x27;t let then sit idly. ;) reply tripleo1 13 hours agorootparentprevFWIW it&#x27;s `-maxdepth 1` not `-depth 1`.But yeah, you&#x27;re right. reply lazide 7 hours agorootparentDude, flashbacks. Aren’t you supposed to do a trigger warning or something first! ;) replylayer8 17 hours agorootparentprevFor find, I think the Info pages are (even) more comprehensive (info find), and you get more structural navigation. reply eviks 17 hours agorootparentprevComprehensiveness is not a benefit if it&#x27;s poorly searchable reply eviks 17 hours agoparentprevIt might be better to invest in something more general like better docs&#x2F;cheatsheets (the bad old man pages which you could convert to a text editor friendly format, or something better like tldr, or something like Dash) so you don&#x27;t depend on the internet, but also don&#x27;t have to memorize bad designs (since find wouldn&#x27;t be the only one) reply grumblingdev 12 hours agoparentprevWe should stop using Bash, and use TypeScript instead.Bash is terrible. reply corobo 10 hours agorootparentwell this shell is just broken > ls -al .ts:4:1 - error TS2304: Cannot find name &#x27;ls&#x27;. 4 ls -al ~~ .ts:4:5 - error TS2304: Cannot find name &#x27;al&#x27;. 4 ls -al ~~ reply RugnirViking 29 minutes agoprevExcellent talk. I sent it to a few folks I know who ive been helping to understand things. Very fun and engaging, with a few iconic slides reply bsaul 35 minutes agoprevI wonder if the speaker manages to keep their good personality and optimism when shits hits the fan and customers get angry (it’s a sincere question, i’m not being snarky). reply zoogeny 17 hours agoprevI have no idea why but I wanted to hate this article. Maybe jvns shows up on HN too often and I was in a bad mood. But this is a great article and as someone with 20 years of development experience is about as true as any meta-level discussion on programming could be.The selective vision thing is so true, both for `dig` and for `man` pages. I can&#x27;t count the number of times have I `man ` and just felt overwhelmed by the seemingly endless pages of configuration options and command line flags. One tip I use for `man` is use vim style search functions triggered with `&#x2F;`. For example, if I want to find how to output the line number of each match in grep and I can&#x27;t remember how - I&#x27;ll just `man grep` then type `&#x2F;line` and hit enter and it will search for any occurrence of the word \"line\" in the man page. Next match is just `&#x2F;`.I&#x27;m also a bit sad to hear that Strange Loop is now finished? I only found them last year or so and it seemed like so many of the talks were exceptional quality. reply dgb23 17 hours agoparent> I&#x27;m also a bit sad to hear that Strange Loop is now finished? I only found them last year or so and it seemed like so many of the talks were exceptional quality.You might want to watch Alex Miller&#x27;s talk that has been uploaded recently:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=suv76aL0NrAAnd yes, it&#x27;s sad that it ended!However he made a very good case for why sometimes it&#x27;s good for things to end. If you watch the whole talk it all makes sense. reply tepitoperrito 16 hours agorootparentSubtitles courtesy of DownSub (poor formatting my own). https:&#x2F;&#x2F;pastebin.com&#x2F;isDPeBQd reply kristopolous 17 hours agoparentprevhttps:&#x2F;&#x2F;cheat.sh is your lifelineAlso I made https:&#x2F;&#x2F;github.com&#x2F;kristopolous&#x2F;mansnip reply odysseus 16 hours agorootparentThis looks like https:&#x2F;&#x2F;tldr.sh in a browser. reply hiAndrewQuinn 15 hours agorootparentcurl cheat.sh&#x2F;awk # is the intended behavior, and it frequently goes into way more detail than tldr does. Both great tools! reply odysseus 9 hours agorootparentThanks, didn&#x27;t know about the curl behavior. Nice! reply Sakos 16 hours agorootparentprevThere&#x27;s also tldr: https:&#x2F;&#x2F;github.com&#x2F;tldr-pages&#x2F;tldrIt lets you check the most commonly used options from your terminal, for example \"tldr badblocks\". reply emi2k01 16 hours agoparentprev> Next match is just `&#x2F;`.You can also press `n` reply BoiledCabbage 10 hours agoprevOn a target, Strange Loop seems to have some of the best presentations I&#x27;ve seen over the years.It&#x27;s really unfortunate that this will be the last one. reply andrepd 10 hours agoparentWhat?? What happened reply tgecho 9 hours agorootparentAlex Miller (the organizer) decided to stop. Probably best to let him explain in his own words: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=suv76aL0NrA reply nikodunk 4 hours agorootparentWhat an incredible talk, too! Thank you so much for sharing! So glad I scrolled down this far haha reply LeifCarrotson 18 hours agoprevWell said! I&#x27;m in manufacturing, not web tech, so the hard things I work with are very different (RS-274 G-code, servo motion systems, PLC&#x2F;SCADA network connections are a few examples), but it&#x27;s interesting to see the overlap in causes of difficulty like trivia, gotchas, frequency of use, and visibility. And disheartening to see that the web tech community is so open and friendly and communicative, while controls engineers may rarely hang out on forums but rarely share anything even close to this outside of a $2,000 training course.And not to nitpick, but I don&#x27;t have Julia&#x27;s email, but when struggling with hard things like DNS I hate to have someone bounce off this little roadblock...her link to to the demo of the DNS exploration website is pointing to the .com, when it&#x27;s actually at the .net TLD: messwithdns.net^^^ =&#x2F;= ^^^Looks like someone needs an HTML linter... :)The correct link - https:&#x2F;&#x2F;messwithdns.net&#x2F; - is actually pretty neat! reply jvns 17 hours agoparentfixed, thanks! reply syadegari 17 hours agoprevThe point Julia makes about `grep` resonate with me alot! I have the same (call it problem if you want) issue with `ps`. There is only one variation of ps I know of (`ps aux`) and if I want to change that I have to either look for the options in the man page or google it. reply Joker_vD 16 hours agoparentOh, that&#x27;s a nice one, thanks for mentioning it. I&#x27;m personally used to \"ps afx\", but the \"u\" does give out some quite useful info... and it&#x27;s compatible with \"f\"! So I guess I&#x27;ll add \"ps aufx\" to my repertoire. reply jwkane 16 hours agorootparentfaux is easier to remember reply somat 14 hours agoparentprevps is bad in general, the default view is almost never what you want and lots of minor formatting options make for a complicated man page. But it is especially a shitshow on linux.fsf: which ps options should we use(bsd, systemv, solaris, sgi)?also fsf: well that&#x27;s a tricky one... why not all of them?The linux ps man page is a wild mess. reply norir 18 hours agoprevI really disagree strongly with the take on bash. The best solution is not to add tooling on top of bash or memorize its idiosyncrasies. It is to not use bash. That is the only way to escape its pitfalls. reply justin_oaks 15 hours agoparentI have yet to find a proper replacement for bash. Especially for scripts.The two most common alternatives are 1) using some of the newer shells people have created, like Oil shell [0], or 2) using programming language like Python, JavaScript, or PHP.The problem with using a newer shell is that you&#x27;ll have to install the new shell anywhere you want to use the script. Meanwhile bash is ubiquitous. Unless you&#x27;re the only one maintaining the script, you&#x27;re requiring others to learn the other shell to maintain the script.The problem with using another programming language is that they rarely have good ergonomics for doing what bash does: stringing together commands, command input, command output, and files. If you try to do that in another programming language, things suddenly get a lot more complicate or at least more verbose.So I still use bash, but I recognize that it&#x27;s strength is in running other commands and dealing with I&#x2F;O. If I&#x27;m doing complicated logic that doesn&#x27;t involve that, then I&#x27;ll offload my work to another language. Sometimes that just means calling a python script from bash, not avoiding bash completely.If people found that they work better by taking other approaches, the please share them.[0] https:&#x2F;&#x2F;www.oilshell.org reply ff317 14 hours agorootparentI&#x27;ll still write bash, but only if it&#x27;s very trivial (~The problem with using another programming language is that they rarely have good ergonomics for doing what bash does: stringing together commands, command input, command output, and files. If you try to do that in another programming language, things suddenly get a lot more complicate or at least more verbose.tclsh is one way around that. Use a real first-class programming language, but in a mode where calling programs is as easy as it is in shell. reply scrozier 17 hours agoparentprevI think this is a valid point. bash is an overly complicated tool...so I&#x27;ll write another tool on top of that (with none of the decades of debugging that bash itself has undergone) to make bash...LESS complex?The problem is with bash itself.We tend to undervalue ease of use and overvalue \"cleverness.\"Case in point: git. Very clever tool. Ease of use: terrible. But Linus wrote it and Linus is clever, so it must be us that&#x27;s the problem.We get what we value. Let&#x27;s value ease of use more. reply t43562 17 hours agoparentprevIt has idiosyncracies because it&#x27;s not a general purpose language. Even the things that she mentions are happening for good reasons - like the fact that set -x would break the expected behavior of || and &&.Actually what language does crash when a function returns false? I mean some throw exceptions but isn&#x27;t \"false\" a valid thing to return?I find the same thing with makefiles - people don&#x27;t understand what they&#x27;re doing and expect them to work in a certain way because they haven&#x27;t ever thought about build systems very deeply. Recursive assignment in Make catches almost everyone out e.g.FLAGS=-bCOMPILE=compile $(FLAGS)$(info compile command=$(COMPILE))FLAGS=-amyfile:echo $(COMPILE) $? -o $@outputs:t43562@rhodes:~ make -f t.mkcompile command=compile -becho compile -a -o myfilecompile -a -o myfileDespite this, making all assignments immediate to match other programming languages would take a VERY useful tool away. The more you understand these tools the more you know where to bother using them and how much effort to put into it. reply Izkata 2 hours agorootparentYou can get code formatting by indenting it all with 2 spaces. reply TonyTrapp 18 hours agoparentprevThat&#x27;s easier said than done, and completely getting rid of bash may often not be worth the time and effort. But in general I agree, anything remotely complex I try to offload into scripts written in less idiosyncratic languages. Having some tools to help avoiding mistakes with the last 5% that stay bash scripts is super helpful in that case. reply Too 4 hours agoparentprevYes. While I’m a huge fan of shellcheck and am one who actually have used and know bash deeply. No amount of linters or other tooling on top of bash can fix it.Best solution is to just stay away.For real. Just stop. Don’t try to be macho. The whole model of the language is fundamentally broken. I mean, stringly typed, global mode switches, one-character flags for fundamental comparison operators, defaulting to ignoring errors at every corner you look, functions especially. Each such idiosyncrasy on its own is enough to dismiss such a language, bash has them all plus more. reply dgb23 17 hours agoparentprevMany have tried, nobody succeeded.Bash scripts are extremely useful and productive for their niche. You&#x27;d have to change a whole lot of things to match that. reply marcosdumay 16 hours agoparentprevSo, you never use bash?That&#x27;s not a very practical hill to die on. But well, you get to decide what fight you engage on. reply avg_dev 18 hours agoparentpreva part of me agrees with the aim of what you say: why not start afresh with something that is less prone to accidents? and i do agree with that idea. but i think it is also somewhat impractical to ignore that pretty much every server i&#x27;ve ever interacted with has a default, vanilla, bash installed, and if i know how to use that, it helps me get by.not to say we can&#x27;t and shouldn&#x27;t try to do better. reply eviks 17 hours agoparentprevIndeed, especially now when you have so many great alternatives, use python as your shell if you likeMany bad designs are too entrenched to be fixed with some tooling reply Upvoter33 18 hours agoparentprevIf you think this way, you will quickly stop using anything. Most computer things are pretty complex and have really intricate oddities. reply esafak 17 hours agorootparentNo, you won&#x27;t. There are numerous shells that are better. The path to improvement lies in being able to call drek by its name. reply _TwoFinger 5 hours agoprev> So, bash is a programming language, right?No, it&#x27;s a shell that lets you interact with the OS. All the \"clasical\" UNIX shells were created with interactive use in mind and optimized for it, but happen to be good enough at batch processing[1] to be conflated with programming languages (mostly these days, like, 40+ years later).The focus on interactive use is the reason you don&#x27;t have to- surround command argument lists with parentheses- put commas between command arguments- put semicolons at EOL- surround string literals with quotes (unless the content interferes with the syntax, like, sigils or IFS chars, and you want to escape it).- surround variable names in braces (unless you want to use some advanced substitution)- call commands to manipulate I&#x2F;O; it&#x27;s baked in.And these are just the things that existed 40 years ago. Bash gives you so much more stuff that makes interactive use a bliss, but I&#x27;m not going to dump the man page here.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Batch_processing reply jezzamon 4 hours agoparentIn practice, it&#x27;s also a programming language :) reply _TwoFinger 3 hours agorootparentEmphasis on \"also\".If you optimize a shell feature for general-purpose programming, interactivity will suffer (increased verboseness, usually), and vice versa.If we try to bring shells closer to the real PLs, instead of just using those PLs when it matters, we&#x27;ll lose some of things that made shells attractive in the first place. reply sz4kerto 16 hours agoprevThese are the use cases where generative AI is great. I want to convert an mp4 to mov and resize it to 720p with ffmpeg, give me the command. I want a bash script to filter out the third column from a CSV and convert the result to a JSON.These are not hard, but I won’t remember ffmpeg flags because I only use it once per year. reply tompt 18 hours agoprevThis is a talk turned into a web page done right. It seems like it should be a simple thing to do, but often the results are confusing and hard to read. Not here, well done! reply hiAndrewQuinn 15 hours agoparentI&#x27;d love to know if jvns has a library or something she uses for this. I&#x27;ve seen this kind of slide thingy on https:&#x2F;&#x2F;boringtechnology.club&#x2F; too, and I&#x27;m really curious! reply akprasad 11 hours agoparentprevAnother lovely example of this format is https:&#x2F;&#x2F;idlewords.com&#x2F;talks&#x2F;. reply wombatpm 14 hours agoprevShout out to https:&#x2F;&#x2F;explainshell.com&#x2F; for being a great resource to understand cli tools and options reply tripleo1 12 hours agoparentShout out to you for finding this for me reply pcj-github 17 hours agoprevEvery time a jnvs.ca article goes popular on HN I have to relive the trauma of my Stripe interview with Julia where I just could not get that simple test to pass despite having years of programming experience. Ugh! She was nice though :) reply commandlinefan 15 hours agoparentWhat was the test? reply jroseattle 17 hours agoprevI both agree and disagree with her sentiments here. Not in a right&#x2F;wrong sense, but just what I found works for me.I agree with having helpers to understand how tooling works. Any resources that increase understanding of how to use a tool to it&#x27;s full capability is productively beneficial. (Hat-tip to anything that unpacks all the `curl` switches.)Here&#x27;s where I have disagreement: an old boss of mine once said \"don&#x27;t worry about the tricks of the trade; learn the trade.\" That&#x27;s very contextual, but sometimes understanding the core first makes the rest of it easy. And understanding the core takes both effort and increases cognitive load, so I understand why one might not go that route.So, for me, I always try to keep a balance between trying to back my way into execution via those helpers, and recognizing when I need to take a step back and learn at a bit more core level.Her down-to-earth approach is refreshing, that&#x27;s for sure. reply lcnPylGDnU4H9OF 16 hours agoparent> Here&#x27;s where I have disagreement: an old boss of mine once said \"don&#x27;t worry about the tricks of the trade; learn the trade.\" That&#x27;s very contextual, but sometimes understanding the core first makes the rest of it easy.Seems like you might agree more than you realize! From TFA:> And much like when debugging a computer program, when you have a bug, you want to understand why the bug is happening if you&#x27;re gonna fix it.It sounds a lot like \"don&#x27;t worry about how to fix the bug; learn what the bug is.\" reply pwenzel 17 hours agoprevI see jvns.ca, I click. I am a simple person. I know that it&#x27;ll probably be the best thing on HN that day. reply nomilk 8 hours agoprev> people share things by sharing a &#x27;best practices (guide)&#x27; but I always love to hear the story. Every time someone has a strong opinion like \"no one should ever use bash\", I&#x27;m like \"tell me.. what did bash do you to, I need to know!\"So true! reply mparnisari 16 hours agoprev> Everything is in the same order as you write it, except SELECT is fifth.been using SQL for years and didn&#x27;t stop to think about that... reply ickyforce 15 hours agoparentI don&#x27;t think her conclusion is correct in this case (that it&#x27;s all about chronological order). It&#x27;s not about what happens first but about levels of abstraction. It doesn&#x27;t make sense to say that we want to decide on the number of doors before specifying if we&#x27;re building a LEGO car or a skyscraper in Manhattan.The reasonable approach is to start from high-level concepts and only then deal with the details - without specifying high-level concepts the details have no particular meaning.As a side note I have to say that I definitely prefer languages with `object.function` rather than `function(object)`, precisely because of this. Another example: `if(foo == 5)`, not `if(5 == foo)` reply oalders 14 hours agoprevI recently wrote \"is\" so that I would have a tool to make shell scripting just a little bit easier: https:&#x2F;&#x2F;github.com&#x2F;oalders&#x2F;is reply avg_dev 18 hours agoprevthat was fantastic. i didn&#x27;t watch the talk, i opened up the transcript and thought to myself i would read a few slides and see if i enjoyed it. that was maybe 20-30 mins ago and i finished it all. really well done, i enjoyed it from start to finish.i like the way she broke it down. i feel like the author addressed ways to learn and communicate effectively and also grounded it in very concrete terms. i don&#x27;t want to get too much into psychology or anything which i really am not qualified to talk about but i feel like going through these types of ways of learning and communicating is a continued exercise in ego deflation and in pragmatic problem solving.i liked the SQL order-of-query-operations thing, the bash and shellcheck thoughts (i will use `-o all` from now on), i am curious to play with the DNS tool (the article links to https:&#x2F;&#x2F;messwithdns.com&#x2F; but the actual URL - taken from the text - is https:&#x2F;&#x2F;messwithdns.net&#x2F; , FYI), and i enjoyed the part about HTTP (i was hoping she would talk about SPDY and whatnot, i have not even begun to explore such things and am curious what that is all about).i am going to read the two posts linked the behind-the-scenes on \"hello, world\".thanks for the link!edit: two things this made me think of:1. the XKCD comic \"ten thousand\": https:&#x2F;&#x2F;xkcd.com&#x2F;1053&#x2F;2. Mark Russinovich on git: https:&#x2F;&#x2F;twitter.com&#x2F;markrussinovich&#x2F;status&#x2F;15784512452490526... reply theusus 17 hours agoprevAnd that is why I like the book Accelerated C++. Instead of explaining each and everything. It helps just the right things, thus preparing you for further adventures. Another literature that comes closer is Designing Data Intensive Applications and SICP. reply culopatin 13 hours agoprevI enjoy the content and I feel pretty bad saying this. But while her constant laughing starts cute, ends up being like when I’m sober and I’m talking to someone high and can’t stop laughing at everything even if it’s not funny. Maybe it’s a nervous thing? It’s part of what makes her unique I know, but I enjoyed the parts when she’s talking somewhat more seriously about something and it doesn’t sound like she’s hearing a joke I’m not getting reply aiunboxed 5 hours agoprevAfter reading the doc, I started to realise things were really hard pre GPT era. reply nikodunk 17 hours agoprevWhat an awesome, entertaining, and informative talk!! The pure joy of the talk makes the information in it seem way more digestible! Amazing. reply chagen 13 hours agoprevThis was a great read. I especially liked how you can read the presentation below with the slides if you&#x27;d rather do that than watch the video. No issues with video, but sometimes I&#x27;m in the mood to read, and this was very satisfying to be able to do here. reply jmfldn 12 hours agoprevJulia Evans is amazing. So likeable, such a great teacher, so much enthusiasm and love for her subject and so much wisdom. An example to us all. reply minroot 17 hours agoprevIs it better to set -e or check return code of processes and decide to exit? reply zoogeny 17 hours agoparentBetter&#x2F;worse is one of those subjective things that comes with experience. No one can definitively answer such a question in a way that will apply to every circumstance.But as someone who rarely writes bash scripts but just enough to be dangerous ... I use `set -xe` at the top of every single shell script I write. The -x flag causes the script to echo every command that is executed to stdout which can be very valuable if I am debugging a shell script that is running on an external environment (like a CI). I&#x27;ve seen this habit suggested many times and it has served me well. reply OJFord 15 hours agorootparentMine&#x27;s `set -eEuo pipefail`.I&#x27;d have to look up exactly what&#x27;s what, but if you&#x27;re inclined to `-e` you probably want the others too. (Off the top of my head I think E is the same thing in functions, u is bail out if a variable is used without being defined (instead of treating it as empty string), and pipefail is similar for when you pipe to something else like `this_errsgrep something`.)I don&#x27;t like `-x` personally, I find it way too verbose; more confusing than helpful. reply imp0cat 14 hours agorootparentYeah, `-x` can be annoying if it&#x27;s always on.My suggestion would be to run your script like this `bash -x your_script.sh` when (and only when) you need to debug something. reply lifeisstillgood 15 hours agoprev\"Tools we use to reduce cognitive load\"The essence of the software literacy revolution\"Share Tools we use to reduce cognitive load\"The essence of the FOSS revolutionJust one line and it was like a road to damascus reply DantesKite 12 hours agoprevOn a side note, I use GPT-4 to help me create simple Bash scripts. Haven&#x27;t run into a problem yet, but I double&#x2F;triple check they won&#x27;t do anything strange and most of the time, it works quite well.Don&#x27;t understand the script, but this is only for personal use. I wouldn&#x27;t do the same in a work setting (obviously).And in this specific example, it&#x27;s been quite a powerful tool to make many parts of my life easier. reply nomilk 8 hours agoprevI wonder if tools like shellcheck are outperformed by ChatGPT? reply nullbyte 10 hours agoprevThis is an AMAZING article and you should feel very proud of making it reply TheClassic 17 hours agoprevI expected there to be an abstracted, general, repeatable tldr that can be reapplied as a mental model. I haven&#x27;t digested the whole thing, but after skimming, I can&#x27;t identify what it is. reply jes5199 16 hours agoparentit&#x27;s kind of more like the beginning of a pattern language for why things seem hard to novices but simple to experts, and ways to mitigate those effects - a different mitigation is appropriate for each pattern reply dgb23 17 hours agoparentprevShe illustrates several (not one) general techniques that can be applied in different situations. reply revskill 17 hours agoprevThe problem is, people love making easy thing harder. reply darkerside 14 hours agoprevI think the problem with making hard things easy is that we&#x27;re conflating tools and problems.Are these hard problems? Maybe. Some HTTP problems are hard, and some are not. Some SQL problems are hard, and some are not.Are tools intrinsically difficult? That&#x27;s an even more complicated question because it is completely context dependent. A better question might be, does this particular tool make it harder to solve this particular problem than it otherwise might be?And that&#x27;s where you run into trouble. These tools have been designed to do a LOT -- to solve many different problems, both easy and hard. If you just \"show everything\", you may make the easy problem much harder to solve.At the end of the day, some tools make some things easy (or possible!) to do in a way that they otherwise wouldn&#x27;t. And we should appreciate that. There will always be hard problems, and for the most common ones, there are probably some better tools waiting to be written. reply chaostheory 14 hours agoprevThis is why the Dummy&#x27;s and Idiot&#x27;s series of books written in layman&#x27;s are so popular.If more people realized how great the chat AIs are for this purpose, they would be even more popular despite the hallucinations. reply j45 17 hours agoprevscreenshots with a summary is a great way to let someone skim a talk before hitting okay. reply garba_dlm 18 hours agoprevand impossible things difficult (hence no longer impossible)! reply pierrebai 16 hours agoprevWell, I&#x27;m going to disagree with her solution to bash. Bash is terrible, end of story. Just the *.txt is actually an endless pit of trap, badness and wrong behaviour.I&#x27;ve not written a bash script in years. I always use Python and in my experience professionally, most people automating things nowaday use Python. I only use bash to write one-line to invoke the underlying Python script. For the record, I do the same for batch file on Windows, with a simply .bat file to invoke the underlying Python script.Trying to improve the bash experience with tools and knowledge is throwing bad time at a problem that has a well-known solution.Edit: to be clear, the presentation itself is awesome. I&#x27;m just disagreeing that bash needs to be better explained. I&#x27;m ready to admit that there are existing scripts out there, most of which are probably only working in the trivial, normal case and are just one snag away from exploding, and having a known source of help can help. But please, take you&#x27;re bash scrip to the shed and upgrade them to Python. reply kunalgupta 18 hours agoprev [–] Warp.dev solves this reply AA-BA-94-2A-56 11 hours agoparent [–] A paid LLM solves this? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The speaker at Strange Loop conference recognizes the hardships in understanding complex concepts such as DNS and SQL, and programming languages like bash.",
      "The talk emphasises on sharing knowledge and experiences, and using tools and examples to reveal obscure facets of computer processes.",
      "The speaker appreciates conference organizers and indicates their interest in explorations focused on improving UI design elements, like Git."
    ],
    "commentSummary": [
      "The article discusses the significance of tools that provide hidden information and the challenges faced while programming in bash and SQL, including difficulties in remembering command line tool syntax.",
      "Interactive shells, their benefits, the demand for better tooling, and alternative programming languages are debated.",
      "The need to comprehend core concepts, sharing knowledge, the utilization of forums, cognitive load reduction tools, AI like GPT-4 in scripting, and varying preferences in learning methods are also brought up."
    ],
    "points": 870,
    "commentCount": 175,
    "retryCount": 0,
    "time": 1696601381
  },
  {
    "id": 37793635,
    "title": "AMD may get across the CUDA moat",
    "originLink": "https://www.hpcwire.com/2023/10/05/how-amd-may-get-across-the-cuda-moat/",
    "originBody": "Search the site Go TABOR NETWORK: DATANAMI ENTERPRISEAI HPCWIRE JAPAN QCWIRE HPC & AI WALL STREET Since 1987 - Covering the Fastest Computers in the World and the People Who Run Them Home Topics Sectors Exascale Specials Resource Library Podcast Events Solution Channels Job Bank About Subscribe How AMD May Get Across the CUDA Moat By Doug Eadline October 5, 2023 When discussing GenAI, the term “GPU” almost always enters the conversation and the topic often moves toward performance and access. Interestingly, the word “GPU” is assumed to mean “Nvidia” products. (As an aside, the popular Nvidia hardware used in GenAI are not technically Graphical Processing Units. I prefer SIMD units.) The association of GenAI and GPUs with Nvidia is no accident. Nvidia has always recognized the need for tools and applications to help grow its market. They have created a very low barrier to getting software tools (e.g., CUDA) and optimized libraries (e.g., cuDNN) for Nvidia hardware. Indeed, Nvidia is known as a hardware company, but as Bryan Catanzaro, VP of Applied Deep Learning Research, Nvidia has stated ” Many people don’t know this, but Nvidia has more software engineers than hardware engineers.” As a result, Nvidia has built a powerful software “moat” around their hardware. While CUDA is not open source, it is freely available and under the firm control of Nvidia. While this situation has benefited Nvidia (As it should. They invested time and money into CUDA), it has created difficulties for those companies and users that want to grab some of the HPC and GenAI market with alternate hardware. Building on the Castle Foundation The number of foundational models developed for GenAI continues to grow. Many of these are “open source” because they can be used and shared freely. (For example, the Llama foundational model from Meta) In addition, they require a large number of resources (both people and machines) to create and are limited mainly to the hyperscalers (AWS, Microsoft Azure, Google Cloud, Meta Platforms, and Apple) that have huge amounts of GPUs available, In addition to the hyperscalers, other companies have invested in hardware (i.e. purchased a massive amount of GPUs) to create their own foundational models. From a research perspective, the models are interesting and can be used for a variety of tasks; however, the expected use and need for even more GenAI computing resources is two fold; Fine-tuning — Adding domain-specific data to foundational models to make it work for your use case. Inference – Once the model is fine-tuned, it will require resources when used (i.e., asked questions). These tasks are not restricted to hyperscalers and will need accelerated computing, that is, GPUs. The obvious solution is to buy more “unavailable” Nvidia GPUs, and AMD is ready and waiting now that the demand has far outstripped the supply. To be fair, Intel and some other companies are also ready and waiting to sell into this market. The point is that GenAI will continue to squeeze GPU availability as fine-tuning and inference become more pervasive, and any GPU (or accelerator) is better than no GPU. Moving away from Nvidia hardware suggests that other vendor GPUs and accelerators must support CUDA to run many of the models and tools. AMD has made this possible with HIP CUDA conversion tool; however, the best results often seem to use the native tools surrounding the Nvidia castle. The PyTorch Drawbridge In the HPC sector, CUDA-enabled applications rule the GPU-accelerated world. Porting codes can often realize a speed-up of 5-6x when using a GPU and CUDA. (Note: Not all codes can achieve this speed up, and some may not be able to use the GPU hardware.) However, in GenAI, the story is quite different. Initially, TensorFlow was the tool of choice for creating AI applications using GPUs. It works both with CPUs and was accelerated with CUDA for GPUs. This situation is changing rapidly. An alternative to TensorFlow is PyTorch, an open-source machine learning library for developing and training neural network-based deep learning models. Facebook’s AI research group primarily develops it. In a recent blog post by Ryan O’Connor, a Developer Educator at AssemblyAI notes that the popular site HuggingFace, (that allows users to download and incorporate trained and tuned state of the art models into application pipelines with just a few lines of code), 92% of models available are PyTorch exclusive. In addition, as shown in Figure One, a comparison of Machine Learning papers shows a significant trend toward PyTorch and away from TensorFlow. Figure One: Percentage of papers that utilize PyTorch, TensorFlow, or another framework over time, with data aggregated quarterly, from late 2017, Source: assemblyai.com. Of course, underneath PyTorch are calls to CUDA, but that is not required because PyTorch insulates the user from the underlying GPU architecture. There is also a version of PyTorch that uses AMD ROCm, an open-source software stack for AMD GPU programming. Crossing the CUDA moat for AMD GPUs may be as easy as using PyTorch. Instinct for Inference In both HPC and GenAI, the Nvidia 72-core ARM-based Grace-Hopper superchip with a shared memory H100 GPU (and also the 144-core Grace-Grace version) is highly anticipated. All Nvidia released benchmarks thus far indicate much better performance than the traditional server where the GPU is attached and accessed over the PCIe bus. Grace-Hopper represents an optimized hardware for both HPC and GenAI. It also is expected to find wide use in both fine-tuning and inference. Demand is expected to be high. AMD has had shared memory CPU-GPU designs since 2006 (AMD acquired graphics card company ATI in 2006). Beginning as the “Fusion” brand many AMD x86_64 processors are now implemented as a combined CPU/GPU called an Accelerated Processing Unit (APU). The upcoming Instinct MI300A processor (APU) from AMD will offer competition for Grace-Hopper superchip. It will also power the forthcoming El Capitan at Lawrence Livermore National Laboratory. The Integrated MI300A will provide up to 24 Zen4 cores in combination with a CDNA 3 GPU Architecture and up to 192 GB of HBM3 memory, providing uniform access memory for all the CPU and GPU cores. The chip-wide cache-coherent memory reduces data movement between the CPU and GPU, eliminating the PCIe bus bottleneck and improving performance and power efficiency. AMD is readying the Instinct MI300A for the upcoming inference market. As stated by AMD CEO Lisa Su in a recent article on Yahoo!Finance. “We actually think we will be the industry leader for inference solutions because of some of the choices that we’ve made in our architecture.” For AMD and many other hardware vendors, PyTorch has dropped the drawbridge on the CUDA moat around the foundational models. AMD has the Instinct MI3000A battle wagon ready to go. The hardware battles for the GenAI market will be won by performance, portability, and availability. The AI day is young. Topics: AI, Analysis, Hardware, Processors, Software Sectors: Academia & Research, Community, Entertainment, Financial Services, Government, Life Sciences, Manufacturing, Oil & Gas, Retail, semiconductor, Space & Physics, Weather & Climate Tags: CUDA, GPU, Grace Hopper, HuggingFace, Instinct MI300A, PyTorch, ROCm, TensorFlow Leading Solution ProvidersOff The Wire Industry Headlines October 6, 2023 EuroHPC Launches New Call for Tender Targeting Federation of Supercomputers and Quantum Computers ORNL, Tennessee State University to Partner on Research Education Programs BQP and Quest Global Partner to Solve Complex Engineering Problems with Quantum Applications Argonne Lab, Purdue University Agree to Create Joint Research Positions Israel Joins the EuroHPC Joint Undertaking TSMC Releases September 2023 Revenue Report North Dakota’s Largest Academic Supercomputing Facility Adopts Open OnDemand October 5, 2023 ORNL: Evaluating the Cloud for Capability Class Leadership Workloads Altair Enhances Leadership in Optimization Technology by Acquiring OmniQuest BSC Champions EU’s EUCAIM Initiative: Cancer Image Europe Sets New Standard for AI in Oncology Infleqtion’s Quantum RF Solution Excels at Army C5ISR NetModX23 Assessment ACCESS Empowers Cancer Researchers with Big Data Analysis Skills at BigCare Workshop NVIDIA, Intel and Google Alums Launch Lemurian Labs and Secure $9M in Funding to Solve AI’s Compute Capacity Limitations RIKEN and Fujitsu Announce New 64 Qubit Superconducting Quantum Computer ALCF’s Michael E. Papka Honored with Argonne Board of Governors’ Distinguished Performance Award DOE Announces $16M for Research on the DIII-D National User Facility and Small-scale Experiments Europe’s Exascale Supercomputer in Its Starting Blocks October 4, 2023 OpenHPC Announces the Release of OpenHPC v3.0 UT’s Texas Institute for Electronics and Infleqtion Launch Quantum Manufacturing Center of Excellence Keshav Pingali Receives Ken Kennedy Award for High Performance and Parallel Computing More Off The Wire ISC 2023 Booth Videos Subscribe to HPCwire's Weekly Update! Be the most informed person in the room! Stay ahead of the tech trends with industry updates delivered to you every week! THE LATEST EDITOR’S PICKS How AMD May Get Across the CUDA Moat October 5, 2023 When discussing GenAI, the term \"GPU\" almost always enters the conversation and the topic often moves toward performance and access. Interestingly, the word \"GPU\" is assumed to mean \"Nvidia\" products. (As an aside, the p Read more… AWS Survey Showcases Quantum Algorithms and Applications October 5, 2023 Somewhat quietly, while quantum hardware developers have been steadily improving today's early quantum computers (scale and error correction), developers of quantum algorithms and applications have also been accelerating Read more… EU Grabs ARM for First ExaFLOP Supercomputer, x86 Misses Out October 4, 2023 The configuration of Europe's first exascale supercomputer, Jupiter, has been finalized, and it is a win for Nvidia and a disappointment for x86 chip vendors Intel and AMD. The Jupiter supercomputer, which will cost €2 Read more… HPC User Forum: Sustainability at TACC Points to Software October 3, 2023 Recently, Dan Stanzione, Executive Director, TACC and Associate Vice President for Research, UT-Austin, gave a presentation on HPC sustainability at the Fall 2023 HPC Users Forum. The complete set of slides is available Read more… Google’s Controversial AI Chip Paper Under Scrutiny Again October 3, 2023 A controversial research paper by Google that claimed the superiority of AI techniques in creating chips is under the microscope for the authenticity of its claims. Science publication Nature is investigating Google's c Read more… AWS Solution Channel VorTech Derisks Innovative Technology to Aid Global Water Sustainability Challenges Using Cloud-Native Simulations on AWS Overview No more than 1 percent of the world’s water is readily available fresh water, according to the US Geological Survey. Read more… Visit the Previous: Introducing a Community Recipe Library for HPC Infrastructure on AWS How Maxar Builds Short Duration ‘Bursty’ HPC Workloads on AWS at Scale How Amazon’s Search M5 Team Optimizes Compute Resources and Cost With Fair-Share Scheduling on AWS Batch QCT Solution Channel QCT and Intel Codeveloped QCT DevCloud Program to Jumpstart HPC and AI Development Organizations and developers face a variety of issues in developing and testing HPC and AI applications. Challenges they face can range from simply having access to a wide variety of hardware, frameworks, and toolkits to time spent on installation, development, testing, and troubleshooting which can lead to increases in cost. Read more… Visit the Previous: QCT DevCloud Provides Comprehensive Environment for HPC & AI Use Cases A Purpose-Built HPC/AI Solution for Higher Education And Research QCT DevCloud Lets Developers Build HPC/AI Applications with Ease Rust Busting: IBM and Boeing Battle Corrosion with Simulations on Quantum Computer October 3, 2023 The steady research into developing real-world applications for quantum computing is piling up interesting use cases. Today, IBM reported on work with Boeing to simulate corrosion processes to improve composites used in Read more… Leading Solution ProvidersContributors Tiffany Trader Editorial Director Douglas Eadline Managing Editor John Russell Senior Editor Jaime Hampton Contributing Editor Mariana Iriarte Contributing Editor Alex Woodie Contributing Editor Addison Snell Contributing Editor Drew Jolly Editorial Assistant Nvidia Delivering New Options for MLPerf and HPC Performance September 28, 2023 As HPCwire reported recently, the latest MLperf benchmarks are out. Not unsurprisingly, Nvidia was the leader across many categories. The HGX H100 GPU systems, which contain eight H100 GPUs, delivered the highest throughput on every MLPerf inference test in this round. Read more… Hakeem Oluseyi Explores His Unlikely Journey from the Street to the Stars in SC23 Keynote September 28, 2023 Defying the odds In the heart of one of the toughest neighborhoods in the country, young Hakeem Oluseyi’s world was a confined space, but his imagination soared to the stars. While other kids roamed the streets, he Read more… Nvidia Takes Another Shot at Trying to Get AI to Mobile Devices September 28, 2023 Nvidia takes another shot at trying to get to mobile devices Long before the current situation of Nvidia's GPUs holding AI hostage, the company tried to put its chips in mobile devices but failed. The Tegra mobile chi Read more… IonQ Announces 2 New Quantum Systems; Suggests Quantum Advantage is Nearing September 27, 2023 It’s been a busy week for IonQ, the quantum computing start-up focused on developing trapped-ion-based systems. At the Quantum World Congress today, the company announced two new systems (Forte Enterprise and Tempo) in Read more… Rethinking ‘Open’ for AI September 27, 2023 What does “open” mean in the context of AI? Must we accept hidden layers? Do copyrights and patents still hold sway? And do consumers have the right to opt out of data collection? These are the types of questions tha Read more… Leveraging Machine Learning in Dark Matter Research for the Aurora Exascale System September 25, 2023 Scientists have unlocked many secrets about particle interactions at atomic and subatomic levels. However, one mystery that has eluded researchers is dark matter. Current supercomputers don’t have the capability to run Read more… Watsonx Brings AI Visibility to Banking Systems September 21, 2023 A new set of AI-based code conversion tools is available with IBM watsonx. Before introducing the new \"watsonx,\" let's talk about the previous generation Watson, perhaps better known as \"Jeopardy!-Watson.\" The origi Read more… Researchers Advance Topological Superconductors for Quantum Computing September 21, 2023 Quantum computers process information using quantum bits, or qubits, based on fragile, short-lived quantum mechanical states. To make qubits robust and tailor them for applications, researchers from the Department of Ene Read more… Fortran: Still Compiling After All These Years September 20, 2023 A recent article appearing in EDN (Electrical Design News) points out that on this day, September 20, 1954, the first Fortran program ran on a mainframe computer. Originally developed by IBM, Fortran (or FORmula TRANslat Read more… Intel’s Gelsinger Lays Out Vision and Map at Innovation 2023 Conference September 20, 2023 Intel’s sprawling, optimistic vision for the future was on full display yesterday in CEO Pat Gelsinger’s opening keynote at the Intel Innovation 2023 conference being held in San Jose. While technical details were sc Read more… ISC 2023 Booth Videos Click Here for More Headlines Technologies: Applications Cloud Developer Tools Interconnects Middleware Networks Processors Storage Systems Visualization Sectors: Academia & Research Business Entertainment Financial Services Government Life Sciences Manufacturing Oil & Gas Retail Exascale Multimedia Events Organizations and Affiliations Editorial Submissions Subscribe About HPCwire Contact Us Sitemap Reprints The Information Nexus of Advanced Computing and Data systems for a High Performance World TCI Home Our Publications Solutions Live Events Press Privacy Policy Cookie Policy About Tabor Communications Update Subscription Preferences California Consumers © 2023 HPCwire. All Rights Reserved. A Tabor Communications Publication HPCwire is a registered trademark of Tabor Communications, Inc. Use of this site is governed by our Terms of Use and Privacy Policy. Reproduction in whole or in part in any form or medium without express written permission of Tabor Communications, Inc. is prohibited. This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish.Accept Reject Read More",
    "commentLink": "https://news.ycombinator.com/item?id=37793635",
    "commentBody": "AMD may get across the CUDA moatHacker NewspastloginAMD may get across the CUDA moat (hpcwire.com) 430 points by danzheng 16 hours ago| hidepastfavorite235 comments omneity 14 hours agoI was able to use ROCm recently with Pytorch and after pulling some hair it worked quite well. The Radeon GPU I had on hand was a bit old and underpowered (RDNA2) and it only supported matmul on fp64, but for the job I needed done I saw a 200x increase in it&#x2F;s over CPU despite the need to cast everywhere, and that made me super happy.Best of all is that I simply set the device to `torch.device(&#x27;cuda&#x27;)` rather than openCL, which does wonders for compatibility and to keep code simple.Protip: Use the official ROCM Pytorch base docker image [0]. The AMD setup is so finicky and dependent on specific versions of sdk&#x2F;drivers&#x2F;libraries and it will be much harder to make work if you try to install them separately.[0]: https:&#x2F;&#x2F;rocm.docs.amd.com&#x2F;en&#x2F;latest&#x2F;how_to&#x2F;pytorch_install&#x2F;p... reply mikepurvis 13 hours agoparentSigh. It&#x27;s great that these container images exist to give people an easy on-ramp, but they definitely don&#x27;t work for every use case (especially once you&#x27;re in embedded where space matters and you might not be online to pull multi-gb updates from some registry).So it&#x27;s important that vendors don&#x27;t feel let off the hook to provide sane packaging just because there&#x27;s an option to use a kitchen-sink container image they rebuild every day from source. reply xahrepap 12 hours agorootparentI know it&#x27;s still different than what you&#x27;re looking for, so you probably already know this, but many projects like this have the Dockerfile on github which shows exactly how they set up the image. For example:https:&#x2F;&#x2F;github.com&#x2F;RadeonOpenCompute&#x2F;ROCm-docker&#x2F;blob&#x2F;master...They also have some for Fedora. Looks like for this you need to install their repo: curl -sL https:&#x2F;&#x2F;repo.radeon.com&#x2F;rocm&#x2F;rocm.gpg.keyapt-key add - \\ && printf \"deb [arch=amd64] https:&#x2F;&#x2F;repo.radeon.com&#x2F;rocm&#x2F;apt&#x2F;$ROCM_VERSION&#x2F; jammy main\"tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;rocm.list \\ && printf \"deb [arch=amd64] https:&#x2F;&#x2F;repo.radeon.com&#x2F;amdgpu&#x2F;$AMDGPU_VERSION&#x2F;ubuntu jammy main\"tee &#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;amdgpu.list \\then install Python, a couple other dependencies (build-essential, etc) and then the package in question: rocm-devSo they are doing the packaging. There might even be documentation elsewhere for that type of setup. reply mikepurvis 12 hours agorootparentOh yeah, I mean... having the source for the container build is kind of table stakes at this point. No one would accept a 10gb mystery meat blob as the basis of their production system. It&#x27;s bad enough that we still accept binary-only drivers and proprietary libraries like TensorRT.I think my issue is more just with the mindset that it&#x27;s okay to have one narrow slice of supported versions of everything that are \"known to work together\" and those are what&#x27;s in the container and anything outside of those and you&#x27;re immediately pooched.This is not hypothetical btw, I&#x27;ve run into real problems around it with libraries like gproto, where tensorflow&#x27;s bazel build pulls in an exact version that&#x27;s different from the default one in nixpkgs, and now you get symbol conflicts when something tries to link to the tensorflow c++ API while linking to another component already using the default gproto. I know these problems are solveable with symbol visibility control and whatever, but that stuff is far from universal and hard to get right, especially if the person setting up the build rules for the library doesn&#x27;t themselves use it in that type of heterogeneous environment (like, everyone at Google just links the same global proto version from the monorepo so it doesn&#x27;t matter). reply mgaunard 6 hours agorootparentI don&#x27;t know what world you live in, but this is a problem for any software development.You need to ensure that there is only one version of any library used globally throughout the code and that the set of versions is compatible with each other, and preferably you also want everything to be built against the same toolchain with the same flags.That usually means onboarding third-party libraries into your own build system. reply anuraaga 2 hours agorootparentI&#x27;d say with semver becoming far better known, this is not a problem for \"any\" software development. The developer gets the choice to pick libraries that are stable, often also influencing language choice. Mistakes happen, Guava broke the Java ecosystem for about two years, but it&#x27;s never something that is accepted as just a fact of software development, it is a mistake.Wanting to hold Python+C ecosystem more accountable is fair I think, at least from my own experience around half a year ago, Anaconda doesn&#x27;t work and you need a Dockerfile for any sort of reproducibility, which can have issues since GPU with docker isn&#x27;t that easy. And this means developers from the vendors working with Anaconda, for example, on solving the issue rather than just hoping for contributors to do it. If AMD were to make easy, reproducible builds without root or VM a reality, that would be reason enough to try their hardware. If not, hopefully Nvidia does and then there really would be no way across the moat for me at least. reply mgaunard 10 minutes agorootparentSemver is a joke and doesn&#x27;t work. Languages like C and C++ can easily have problems if you link code built with different versions together (even if you aim for them to be compatible, or even if they are indeed the same source version but with subtly different flags), and there are no good solutions for this, except not doing it.A docker container is not really any different from any other process; the main difference is that it runs in a chroot pretty much. reply anthk 1 hour agorootparentprevThis would be the work for Guix. Much better than docker, and exportable to a lot of formats. Or just build a vm from the CLI, an ad-hoc environment, a Docker export or a direct rootfs to deploy and run in any compatible machine. reply iopq 1 hour agorootparentprevIn NixOS, I can install multiple versions of librariesOr rather, I install no versions of libraries because NixOS will put them all in the store in different folders, and will compile the executable to use the correct path (or patch the elf when needed)it has an issue with pip because it&#x27;s allergic to just randomly executing things as part of package management, but pip in general is wtf reply josephg 3 hours agorootparentprevIt’s not a universal problem. A lot of modern languages allow multiple versions of a library to be pulled in to the same code base, through different dependency paths. (Eg nodejs, rust). It’s not a perfect answer by any means, but it’s nice not needing to worry about some package pulling in an inconvenient version of one of its dependencies.Also, just to name it, it’s ridiculous that a specific graphics card manages to restrict the version of gproto that you’re using. You don’t have this problem with nvidia drivers, since cuda stuff is much less fiddly. AMD needs to pull a finger out and fix the bugs in their stack that make it so fragile like this. reply anthk 1 hour agorootparentprevThat&#x27;s trivial with Guix. reply JonChesterfield 13 minutes agorootparentprev> No one would accept a 10gb mystery meat blob as the basis of their production systemWell, except for cuda. Which is a massive pile of proprietary software that people are using in production anyway. reply hotstickyballs 8 hours agorootparentprevIf anything, the situation with tensor rt shows that companies are absolutely willing to accept a multi gig meat blob reply amelius 12 hours agorootparentprev> So it&#x27;s important that vendors don&#x27;t feel let off the hook to provide sane packaging just because there&#x27;s an option to use a kitchen-sink container image they rebuild every day.Sadly if e.g. 95% of their users can use the container, then it could make economical sense to do it that way. reply fwsgonzo 13 hours agorootparentprevI feel the same way, especially about build systems. OpenSSL and v8 are among a large list of things that have horrid build systems. Only way to build them sanely is to use some randos CMake fork, then it Just Works. Literally a two-liner in your build system to add them to your project with a sane CMake script. reply mikepurvis 13 hours agorootparentI was part of a Nix migration over the past two years, and literally one of the first things we checked is that there was already a community-maintained tensorflow+gpu package in nixpkgs because without that the whole thing would have been a complete non-starter, and we sure as heck didn&#x27;t have the resources or know-how to figure it out for ourselves as a small DevOps team just trying to do basic packaging. reply mathisfun123 13 hours agorootparentprev> especially once you&#x27;re in embeddedis this a real problem? exactly which embedded platform has a device that ROCm supports? reply mikepurvis 13 hours agorootparentRobotic perception is the one relevant to me. You want to do object recognition on an industrial x86 or Jetson-type machine, without having to use Ubuntu or whatever the one \"blessed\" underlay system is (either natively or implicitly because you pulled a container based on it). reply mathisfun123 12 hours agorootparent>industrial x86 or Jetson-type machinethat&#x27;s not embedded dev. if you1. use underpowered devices to perform sophisticated tasks2. using code&#x2F;tools that operate at extremely high levels of \"abstraction\"don&#x27;t be surprised when all the inherent complexity is tamed using just more layers of \"abstraction\". if that becomes a problem for your cost&#x2F;power&#x2F;space budget then reconsider choice 1 or choice 2. reply mikepurvis 11 hours agorootparentNot sure this is worth an argument over semantics, but modern \"embedded\" development is a lot bigger than just microcontrollers and wearables. IMO as soon as you&#x27;re deploying a computer into any kind of \"appliance\", or you&#x27;re offline for periods of time, or you&#x27;re running on batteries or your primary network connection is wireless... then yeah, you&#x27;re starting to hit the requirements associated with embedded and need to seek established solutions for them, including using distros which account for those requirements. reply serf 10 hours agorootparentfwiw CompTIA classifies an embedded engineer&#x2F;developer as \" those who develop an optimized code for specific hardware platforms.\" reply mathisfun123 11 hours agorootparentprev> IMO as soon as you&#x27;re deploying a computer into any kind of \"appliance\", or you&#x27;re offline for periods of time, or you&#x27;re running on batteries or your primary network connection is wirelessyes and in those instances you do not reach for pytorch&#x2F;tensorflow on top of ubuntu on top of x86 with a discrete gpu and 32gb of ram. instead you reach for C and micro or some arm soc that supports baremetal or at most rtos. that&#x27;s embedded dev.so i&#x27;ll repeat myself: if you want to run extremely high-level code then don&#x27;t be \"surprised pikachu\" when your underpowered platform, that you chose due to concrete, tight budgets doesn&#x27;t work out. reply rcxdude 8 hours agorootparentNot that I want to encourage gatekeeping in the first place, but you&#x27;ll have more success if you have a clue what the other person is talking about in the first place (and some idea of what embedded looks like outside of tiny micros, and how the concerns about abstractions extend beyond matters of how much computational power is available). reply Const-me 10 hours agorootparentprevThe hardware can be fast, actually. Here’s an example of relatively modern industrial x86: https:&#x2F;&#x2F;www.onlogic.com&#x2F;ml100g-41&#x2F; That thing is probably faster than half of currently sold laptops.However, containers or Ubuntu Linux don’t perform great in that environment. Ubuntu is for desktops, containers are for cloud data centers. An offline stand-alone device is different. BTW, end users don’t typically aware that thing is a computer at all.Personally, I usually pick Alpine or Debian Linux for similar use cases, bare metal i.e. without any containers. reply cannonpalms 6 hours agorootparent> Ubuntu is for desktopsTell that to their (much larger, more profitable, and better-funded) server org. This is far from true. reply iopq 1 hour agorootparentIt also works much better as a server. Snaps work really well for things like certbotOn Desktop you have to worry about things like... UIs, sound, Wine, etc. reply ngcc_hk 9 hours agorootparentprevThat is the moat they tried to cross. Imagine you have a PyTorch app and run on iOS, arm based, amd based and intel … cloud, or embedded. just imagine. You scale and embed as your business case, not as any one firm current strategy is.Or at least you have some case as heaven never come. Or come just we do not aware now like internet. Can you need to use ibm to rub sna to provide a token ring based network. In 1980 …Imagine and let us or they competite … reply nightski 10 hours agorootparentprevClearly you&#x27;ve never used a Nvidia Jetson and have no idea what it is. You don&#x27;t need a discrete GPU, it has a quite sophisticated GPU in the SoC. It&#x27;s Nvidia&#x27;s embedded platform for ML&#x2F;AI. replyngcc_hk 9 hours agorootparentprevBetter to come if the tide shift so we can have compatible layer. The key is the tide. Obviously would n try to sue … it would be a sign that finally we have real competition. Gar is where innovation do.X86 cannot do 64 bit let us do this and that so the market can use only our cpu. Repeat with me x86-64 is impossible.Not sure Apple is in this otherwise the real great competition come. reply wyldfire 12 hours agoparentprev> Best of all is that I simply set the device to `torch.device(&#x27;cuda&#x27;)` rather than openCL, which does wonders for compatibilityMan oh man where did we go wrong that cuda is the more compatible option over OpenCL? reply KeplerBoy 12 hours agorootparentIt must be a misnomer on PyTorch&#x27;s side. Clearly it&#x27;s neither CUDA nor OpenCL.AMD should just get it&#x27;s shit together. This is ridiculous. Not the name, but the fact that you can only do FP64 on a GPU. Everybody is moving to FP16 and AMD is stuck on doubles? reply JonChesterfield 7 minutes agorootparentFP64 is what HPC is built on. F32 works on the cards too (same rate or faster). I don&#x27;t know the status of F16 or F8.Some architectures provide fast F16->F32 and F32->F16 conversion instructions so you can DIY the memory bandwidth saving - that always seemed reasonable to me, but I don&#x27;t know if the AMD hardware people are&#x2F;will go down that path. reply omneity 11 hours agorootparentprevI believe the fp64 limitation came from the laptop-grade GPU I had rather than inherent to AMD or ROCm.The API level I could target was at least two or three versions behind the latest they have to offer. reply KeplerBoy 11 hours agorootparentMight very well be true. I don&#x27;t blame anyone for not diving deeper into figuring out why this stuff doesn&#x27;t work.But this is one of the great strengths of CUDA: I can develop a kernel on my workstation, my boss can demo it on his laptop and we can deploy it on Jetsons or the multi-gpu cluster with minimal changes and i can be sure that everything runs everywhere. reply iopq 1 hour agorootparentSorry, still trying to install some dependencies for DNN and CUDA, not sure why it says my Clang version is too new (!) reply brutus1213 8 hours agorootparentprevThere is indeed something excellent about CUDA from a user perspective that is hard to beat. I do high-level DNN and it is not clear to me what it is or why that is. Anytime I have worked on optimizing to mobile hardware (not Jetson, but actual phones or accelerators), it is just a world of hurt and incompatibilities. This notion that operators or subgraphs can be accelerated by lower level closed blobs .. I wonder if that is part of the issue. But then why doesn&#x27;t OpenCL not just work? I thought it gave a CUDA kernel like general purpose abstraction.I just don&#x27;t understand the details enough to understand why things are problematic without CUDA :( reply NavinF 3 hours agorootparentprevThis has always been the case. OpenCL is a shit show reply RockRobotRock 11 hours agoparentprevHave you gotten it to work with Whisper by any chance? reply kkielhofner 6 hours agorootparentWhisper is actually a great example of why Nvidia has such a stronghold on ML&#x2F;AI and why it’s so difficult to compete.There’s getting something to “work”, which is often enough of a challenge with ROCm. Then there’s getting it to work well (next challenge).Then there’s getting it to work as well as Nvidia&#x2F;CUDA.With Whisper, as one example, you should be running it with ctranslate2[0]. Of all the platforms on their supported list you won’t find ROCm.When you really start to look around you’ll find that ROCm is (at best) still very much in the “get it to work (sometimes)” stage. In most cases it’s still a long way away from getting it to work well, and even further away from making it actually competitive with Nvidia for serious use cases and applications.People get excited about the progress ROCm has made getting basic things to work with PyTorch and this is good - progress is progress. But saving 20% on the hardware when the equivalent Nvidia product is often somewhere between 5-10x as performant (at a fraction of the development time) because of vastly superior software support you realize pretty quickly Nvidia is actually a bargain compared to AMD.I’m desperately rooting for Nvidia to have some actual competition but after six years of ROCm and my own repeated failed attempts to have it make any sense overall I’m only more and more skeptical that real competition in the space will come from AMD.[0] - https:&#x2F;&#x2F;github.com&#x2F;OpenNMT&#x2F;CTranslate2 reply errnoh 1 hour agorootparentWhile I agree that it&#x27;s much more effort to get things working on AMD cards than it is with Nvidia, I was a bit surprised to see this comment mention Whisper being an example of \"5-10x as performant\".https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;whisper-audio-transcriptio... is a good example of Nvidia having no excuses being double the price when it comes to Whisper inference, with 7900XTX being directly comparable with 4080, albeit with higher power draw. To be fair it&#x27;s not using ROCm but Direct3D 11, but for performance&#x2F;price arguments sake that detail is not relevant.EDIT: Also using CTranslate2 as an example is not great as it&#x27;s actually a good showcase why ROCm is so far behind CUDA: It&#x27;s all about adapting the tech and getting the popular libraries to support it. Things usually get implemented in CUDA first and then would need additional effort to add ROCm support that projects with low amount of (possibly hobbyist) maintainers might not have available. There&#x27;s even an issue in CTranslate2 where they clearly state no-one is working to get ROCm supported in the library. ( https:&#x2F;&#x2F;github.com&#x2F;OpenNMT&#x2F;CTranslate2&#x2F;issues&#x2F;1072#issuecomm... ) reply pedrovhb 4 hours agorootparentprevI&#x27;ve had luck with an RX5700XT and whisper.cpp built with clblast. Works like a charm, not entirely a scarring experience getting it to work (easier than most other stuff which was surprising to me).One arcane detail is that whereas for PyTorch I have to set the env var HSA_OVERRIDE_GFX_VERSION to 10.3.0, getting it to run with whisper.cpp and llama.cpp requires setting it to 10.1.0. Good luck and may it cost you less hair than it did me. reply incognition 4 hours agoparentprevFp64?? reply fransje26 0 minutes agorootparentHardware limitation. reply latchkey 3 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Double-precision_floating-poin...NVIDIA fp32 (H100) has 2x more TFLOPS than AMD&#x27;s fp32 (MI250) and AI doesn&#x27;t need fp64 precision. reply javchz 14 hours agoprevCUDA is the only reason I have an Nvidia card, but if more projects start migrating to a more agnostic environment, I&#x27;ll be really grateful.Running Nvidia in Linux isn&#x27;t as much fun. Fedora and Debian can be incredibly reliable systems, but when you add an Nvidia card, I feel like I am back in Windows Vista with kernel crashes from time to time. reply distract8901 11 hours agoparentMy Arch system would occasionally boot to a black screen. When this happened, no amount of tinkering could get it back. I had to reinstall the whole OS.Turns out it was a conflict between nvidia drivers and my (10 year old) Intel integrated GPU. But once I switched to an AMD card, everything works flawlessly.Ubuntu based systems barely worked at all. Incredibly unstable and would occasionally corrupt the output and barf colors and fragments of the desktop all over my screens.AMD on arch has been an absolute delight. It just. Works. It&#x27;s more stable than nvidia on windows.For a lot of reasons-- but mainly Linux drivers-- I&#x27;ve totally sworn off nvidia cards. AMD just works better for me. reply aftbit 10 hours agorootparentAs a counter-argument, I ran Arch Linux + nvidia GPUs + Intel CPUs between 2012 and 2020, and still run Arch + nvidia (now with AMD CPU) to this day. I won&#x27;t say it has been bug free at all, but it generally works pretty well. If you find a problem in Arch that you cannot fix without reinstalling, you do not sufficiently understand the problem or Arch itself. \"Installing\" Arch is refreshingly manual and \"simple\" compared to the magic that is other Linux distros or the closed source OSes. reply iopq 1 hour agorootparentI tried using an Nvidia card with OBS to record my screen and it kind of freezes in Wine. I switched from x11 to Wayland and now Wine shows horizontal lines (!) and performs like crap.Even my 4GB RX 570 from years ago gives a better experience doing this. You just install OBS from flathub, Wayland works, everything works without any setup or tinkering. You click record and you can record your gameplay footage. reply wildzzz 9 hours agorootparentprevI ran a laptop with the swappable dedicated Nvidia and integrated Intel GPU for a decade with no issues. Used to use something called Bumblebee to swap between them depending on workload, actually worked surprisingly well given the circumstances. Eventually I just dropped back to integrated only when I stopped doing anything intensive with the machine. reply nextaccountic 6 hours agoparentprev> CUDA is the only reason I have an Nvidia card, but if more projects start migrating to a more agnostic environment, I&#x27;ll be really grateful.What AMD really needs is to have 100% feature parity with CUDA without changing a single line of code. Maybe for this to happen it needs to add hardware features or something (I see people saying that CUDA as an API is very tailored to the capabilities of nvidia GPUs), I don&#x27;t know.If AMD relies on people changing their code to make it portable, it already lost. reply mrweasel 3 hours agorootparent> I see people saying that CUDA as an API is very tailored to the capabilities of nvidia GPUsI&#x27;m wondering how true that is, because that could give NVidia issues in the future if they need to redesign their GPU should they hit some limit with the current designs. Dependence on certain instruction makes sense, but there&#x27;s not technical preventing AMD from implementing those instructions, only legal mumbo jumbo. reply mschuetz 1 hour agorootparentprevNot just feature parity, but proper UX. Things need to just work, without spending hours or days to make them work. reply javchz 3 hours agorootparentprevI think that could work too. I wonder if they could do a translation layer, something like Apple with the M1 chips that translates JIT x86 to ARM. reply PH95VuimJjqBqy 13 hours agoparentprevI see these complains from time to time and I never understand them.I&#x27;ve literally been running nvidia on linux since the TNT2 days and have _never_ had this sort of issue. That&#x27;s across many drivers and many cards over the many many years. reply LtWorf 11 hours agorootparentI&#x27;ve had kernel panics that disappeared when I started using the on board intel graphics instead of the nvidia.Your statement makes no sense. It&#x27;s like a smoker claiming that since he didn&#x27;t die of lung cancer, smoke is 100% safe. reply kkielhofner 6 hours agorootparentDescribing kernel panics and general nightmare scenarios as the general course with Nvidia doesn’t make sense either.Nvidia has 80% market share of the discrete GPU desktop market and at least 90% market share of cloud&#x2F;datacenter.Nvidia GPUs are used almost exclusively for every cloud powered AI service and to train virtually every ML model in existence. Almost always on Linux.Do you really think any of this would be possible if what you are describing was anything approaching the typical experience starting at the &#x2F;driver&#x2F; level?Nvidia would have never achieved their market dominance nor held on to it this long if the issues you’ve experienced impacted anything approaching a statistically significant number of users or applications.Nvidia gets a lot of hate on HN and elsewhere (much of it fair) but I will never understand the people who claim it doesn’t work and get the job done (often very well). reply mr_toad 4 hours agorootparentPeople use flakey software all their time. As long as it mostly works most of the time most people put up with it. Examples: Windows in the 90’s and 00’s, or any AAA game on first release in the last 10 years. reply iopq 1 hour agorootparentprevNvidia is bad when combined with Wine&#x2F;Firefox&#x2F;Chrome on WaylandWhich is literally only 1% of users anyway reply jjoonathan 12 hours agorootparentprevSame but linux experience is a steep and bumpy function of hardware.My guess: something like laptop GPU switching failed badly in the nvidia binary, earning it a reputation. reply HideousKojima 12 hours agorootparentThat was my experience, Nvidia Optimus (which is what allows dynamic switching between the integrated and dedicated GPU in laptops) was completely broken (as in a black screen, not just crashes or other issues) for several years, and Nvidia didn&#x27;t care to do anything about it. reply lhl 12 hours agorootparentYeah, Optimus was a huge PITA. I remember fighting with workarounds like bumblebee and prime for years. Also Nvidia dragged their feet on Wayland support for a few years too (and simultaneously was seemingly intent on sabotaging Nouveau). reply distract8901 11 hours agorootparentI tried bumblebee again recently, and it works shockingly well now. I have a thinkpad T530 from 2013 with an NVS5400m.There is some strange issue with some games where they don&#x27;t get full performance from the dGPU, but more than the iGPU. I have to use optirun to get full performance.It also has problems when the computer wakes from sleep. For whatever reason, hardware video decoding doesn&#x27;t work after entering standby. Makes steam in home streaming crash on the client, but flipping to software decoding usually works fine.The important part is that battery life is almost as good with bumblebee as it is with the dGPU turned off. No more fucking with Prime or rebooting into BIOS to turn the GPU back on. reply PH95VuimJjqBqy 12 hours agorootparentprevI don&#x27;t run laptops except when work requires it and that tends to be windows so that may explain the difference in experience. reply temp0826 13 hours agorootparentprevI understand it, but I also haven&#x27;t had any trouble since I figured out the right procedure for me on fedora (which probably took some time, but it&#x27;s been so long that I can&#x27;t remember). Whenever I read people having issues it sounds like they are using a package installed via dnf for the driver&#x2F;etc. I&#x27;ve always had issues with dkms and the like and just install the latest .run from nvidia&#x27;s website whenever I have a kernel update (I made a one-line script to call it with the silent option and flags for signing for secure boot so I don&#x27;t really think about it). No issues in a very long time even with the whackiness of prime&#x2F;optimus offloading on my old laptop. reply bootsmann 10 hours agorootparentSo you don‘t recommend going the rpm-fusion route? reply PH95VuimJjqBqy 12 hours agorootparentprevactually, it&#x27;s a good point because that&#x27;s how I always install nvidia drivers as well. Never from the local package manager. reply ant6n 13 hours agorootparentprevWell tnt2 should be pretty well supported by now ;-) reply PH95VuimJjqBqy 12 hours agorootparentlmao, touche :) reply einpoklum 11 hours agorootparentprevI have been NVIDIA cards for compute capabilities only, both personally and at work, for nearly a decade. I&#x27;ve had dozens and dozens of different issues involving the hardware, the drivers, integration with the rest of the OS, version compatibilities, ensuring my desktop environment doesn&#x27;t try to use the NVIDIA cards, etc. etc.Having said that - I (or rarely, other people) have almost always managed to work out those issues and get my systems to work. Not in all cases though. reply kombine 13 hours agoparentprevI use a rolling distro (OpenSUSE Tumbleweed) and have had zero issues with my NVIDIA card despite it pulling the kernel and driver updates as they get released. The driver repo is maintained by NVIDIA itself, which is amazing. reply filterfiber 13 hours agorootparentDo you use wayland, multiple monitors, and&#x2F;or play games or is it just for ML&#x2F;AI? reply smoldesu 12 hours agorootparentI do all of those things with my 3070 and it works just fine. Most of them will depend on your DE&#x27;s Wayland implementation.I&#x27;m not here to desparage anyone experiencing issues, but my experience on the NixOS rolling-release channel has also been pretty boring. There was a time when my old 1050 Ti struggled, but the modern upstream drivers feel just as smooth as my Intel system does. reply gymbeaux 10 hours agoparentprevI often have issues booting to the installer or first boot after install with an NVidia GPU.Pop_OS, Fedora and OpenSUSE work out of the box. Those are all Wayland I believe. Debian&#x2F;Ubuntu distros are a bad time. I think they’re still X11. It’s ironic because X11 is supposed to be the more stable window manager. reply Flameancer 1 hour agorootparentI think they moved to Wayland on 23.04 or 23.10. I just recently installed both to try and get a 7800xt working with PyTorch and the default was Wayland. reply anthk 1 hour agorootparentprevX11 is not a window manager. reply chaostheory 8 hours agoparentprevYeah with my CUDA setup, it feels like I just ducktaped my deployment. I am very hesitant to make changes and it’s not easy to replicate reply smoldesu 14 hours agoparentprevThose problems might just be GNOME-related at this point. I&#x27;ve been daily-driving two different Nvidia cards for ~3 years now (1050 Ti then 3070 Ti) and Wayland has felt pretty stable for the past 12 months. The worst problem I had experienced in that time was Electron and Java apps drawing incorrectly in xWayland, but both of those are fixed upstream.I&#x27;m definitely not against better hardware support for AI, but I think your problems are more GNOME&#x27;s fault than Nvidia&#x27;s. KDE&#x27;s Wayland session is almost flawless on Nvidia nowadays. reply arsome 14 hours agorootparentIf GNOME can tank the kernel, it ain&#x27;t GNOME&#x27;s fault. reply kombine 13 hours agorootparentprevI really hope that with KDE 6 I can finally switch to Wayland! reply Zardoz84 4 hours agorootparentI&#x27;m using KDE on Debian 12 with AMD GPU with Wayland, and works. it keeps being a bit annoying compared with X11 with a few programs (Eclipse, Dbeaver... I need to launch both with flags to not use Wayland backend). But even I can play AAA games without problems reply wubrr 14 hours agoparentprevYeah, nvidia linux support is meh, but still much better than amd. reply phkahler 12 hours agorootparent>> Yeah, nvidia linux support is meh, but still much better than amd.Can not confirm. I used nvidia for years when it was the only option. Then used the nouveau driver on a well supported card because it worked well and eliminated hassle. Now I&#x27;m on AMD APU and it just works out of the box. YMMV of course. We do get reports of issues with AMD on specific driver versions, but I can&#x27;t reproduce. reply Zambyte 14 hours agorootparentprevIs it better than AMD? I have had literally no graphics issues on my 6650 XT with swaywm using the built in kernel drivers. reply aseipp 13 hours agorootparentThis week I upgraded my kernel on a 2017 workstation to 6.5.5 and when I rebooted and looked at &#x27;dmesg&#x27; there were no less than 7 kernel faults with stack traces in my &#x27;dmesg&#x27; from amdgpu. Just from booting up. This is a no-graphical-desktop system using a Radeon Pro W5500, which is 3.5 years old (I just had the card and needed something to plug in for it to POST.)I have come to accept that graphics card drivers and hardware stability ultimately comes down to whether or not ghosts have decided to haunt you. reply HansHamster 14 hours agorootparentprevGuess I&#x27;m also doing something wrong. Never had any serious issues with either Nvidia or AMD on Linux (and only a few annoyances on RNDA2 shortly after release)... reply treprinum 14 hours agorootparentprevI never had an issue with nVidia drivers on Linux in the past 5 years, but recently bought a laptop with a 4090 and AMD CPU. Now I get random freezes, often right after I login into Cinnamon but can&#x27;t really tell if it&#x27;s the nVidia driver for 4090, AMDGPU driver for integrated RDNA, kernel 6.2 or Cinnamon issue. The laptop just hangs and stops responding to keyboard so I can&#x27;t login to console and dmesg it. reply SoftTalker 14 hours agorootparentThe main issue with Nvidia on Linux AIUI is that they don&#x27;t release the source code for their drivers. reply treprinum 13 hours agorootparentThat might be a philosophical problem that never prevented me from training models on Linux. The half-baked half-crashing AMD solutions just lead to wasting time I can spend on ML research instead. reply 65a 4 hours agorootparentI literally gave away my last laptop with a discrete nVidia card because it wasted so much of my time. reply christkv 14 hours agorootparentprevI think the problems are pro drivers and the issues with ROCm being buggy not the open source graphics drivers. reply bryanlarsen 13 hours agorootparentprevNot my experience. The open source AMD drivers are much more pleasant to deal with than the closed source Nvidia ones. reply silisili 12 hours agorootparentprevIn the closed source days of fglrx or whatever it&#x27;s called I&#x27;d agree. Since they went open source, hard disagree. AMD graphics work in Linux about as well as Intel always has. reply acomjean 14 hours agorootparentprevAs someone who was tasked with trying to get nvidia working on Ubuntu, it’s a pretty terrible experience.I have a nvidia laptop with popos. That works well. reply IronWolve 15 hours agoprevYup, thank the hobbyists. Pytorch is allowing other hardware. Stable diffusion working on m chips, intel arc, and Amd.Now what I&#x27;d like to see is real benchmarks for compute power. Might even get a few startups to compete in this new area. reply mandevil 14 hours agoparentIt isn&#x27;t the hobbyists who are making sure that PyTorch and other frameworks runs well on these chips, but teams of engineers who work for NVIDIA, AMD, Intel, etc. who are doing this as their primary assigned jobs, in exchange for money from their employer, who are paying those salaries because they want to sell chips into the enormous demand for running PyTorch faster.Hobbyist and open-source are definitely not synonyms. reply janalsncm 8 hours agorootparentSpecial mention to Facebook and Google AI research teams that maintain PyTorch and Tensorflow respectively. And also to ptrblck on the PyTorch forums [1] who has the answer to basically every question it seems. He alone is probably responsible for hundreds of millions of dollars of productivity gain.[1] https:&#x2F;&#x2F;discuss.pytorch.org&#x2F;u&#x2F;ptrblck&#x2F;summary reply Eisenstein 13 hours agorootparentprevPeople don&#x27;t usually get employed to make things with no demand, and people who work for companies with a budget line don&#x27;t really care how much the nVidia tax is. You can thank hobbyists for creating a lot of demand for compatability with other cards. reply kiratp 11 hours agorootparentThere are so many billions of dollar being spent on this hardware that everyone other than Nvidia is doing everything they can to make competition happen.Eg: https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;developer&#x2F;videos&#x2F;opt...https:&#x2F;&#x2F;www.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;developer&#x2F;tools&#x2F;onea...https:&#x2F;&#x2F;developer.apple.com&#x2F;metal&#x2F;tensorflow-plugin&#x2F;Large scale opensource is, outside of a few exceptions, built by engineers paid to build it. reply johngossman 8 hours agorootparentprevI can only point you to cloud financial results and the huge cost of the AI race. Note also the story recently about OpenAI looking at building their own chips. Companies absolutely care immensely about the cost of GPUs. It&#x27;s billions of dollars. reply roenxi 10 hours agorootparentprevThere is huge demand for AMD cards that can efficiently multiply matrices together. The issue is that while there are currently isolated cases where people can make them do that, it doesn&#x27;t seem to be possible at the scale that it needs to happen at.AMD are being dragged along by the market. Willingly, they aren&#x27;t fighting it, but their focus has been on other areas. reply iopq 1 hour agorootparentLook at the earnings call:https:&#x2F;&#x2F;www.fool.com&#x2F;earnings&#x2F;call-transcripts&#x2F;2023&#x2F;08&#x2F;01&#x2F;ad...it&#x27;s literally ALL AI, server, enterprise talk - AI is mentioned 64 timesAMD literally doesn&#x27;t care about gaming anymore, server is their primary focus reply viewtransform 10 hours agorootparentprevThey&#x27;ve shifted a large pool of experienced engineers from legacy software projects to AI and moved the team under a veteran Xilinx AI director. Fingers crossed we should see significant changes in 2024. reply Flameancer 1 hour agorootparentAs a new owner of a 7800XT I’m excited. replymattnewton 15 hours agoparentprevRe: startups, Geohotz raised a few million for this already. https:&#x2F;&#x2F;tinygrad.org&#x2F; reply IntelMiner 14 hours agorootparentDidn&#x27;t he do what he always does. Rake in a ton of money, fart around and then cash out exclaiming it&#x27;s everyone else&#x27;s fault?The way he stole Fail0verflow&#x27;s work with the PS3 security leak after failing to find a hypervisor exploit for months absolutely soured any respect I had for him at the time reply throwitawayfam 14 hours agorootparentYep, did exactly that. IMO he threw a fit, even though AMD was working with him squashing bugs. https:&#x2F;&#x2F;github.com&#x2F;RadeonOpenCompute&#x2F;ROCm&#x2F;issues&#x2F;2198#issuec... reply aeyes 13 hours agorootparentHe&#x27;s back on it after getting AMD&#x27;s CEO to commit resources to this:https:&#x2F;&#x2F;twitter.com&#x2F;realGeorgeHotz&#x2F;status&#x2F;166980346408248934...https:&#x2F;&#x2F;twitter.com&#x2F;LisaSu&#x2F;status&#x2F;1669848494637735936 reply nomel 12 hours agorootparentprevTo be fair, kernel crashes from running an AMD provided demo loop isn’t something he should have to work with them on. That’s borderline incompetence. His perspective was around integration into his product, where every AMD bug is a bug in his product. They deserve criticism, and responded accordingly (actual resources to get their shit together). It’s not like GPU accelerated ML is some new thing. reply kinematikk 14 hours agorootparentprevDo you have a source on the stealing part? A quick Google search didn&#x27;t result in anything reply IntelMiner 14 hours agorootparentMarcan (of Asahi Linux fame) has talked about it many times before. But an abridged versionFail0verflow demoed how they were able to derive the private signing keys for the Sony Playstation 3 console at I believe CCCGeohot after watching the livestream raced into action to demo a \"hello world!\" jailbreak application and absolutely stole their thunder without giving any credit reply ryanjshaw 10 hours agorootparentIf they demod something then they released it publically and it was fair game?In any case he absolutely did credit them, it&#x27;s easily verifiable: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20110104040706&#x2F;http:&#x2F;&#x2F;geohot.com...Sony sued them both, afterall! reply aftbit 10 hours agorootparentprevThis apparently worked pretty well for him, as I still remember him primarily as \"that guy who hacked PS3\". Some people let someone else do the hard technical core, then do all the other easy but boring stuff and claim 100% credit. reply 22c 10 hours agorootparentI remember geohot as being one of the people who developed a fairly successful jailbreak for iPhone. I understand that iPhone jailbreaking is often standing on the shoulders of predecessors, but I believe he does deserve significant credit for at least one popular iPhone jailbreak. reply adastra22 14 hours agorootparentprevWow, TIL reply ShamelessC 9 hours agorootparentprev> The way he stole Fail0verflow&#x27;s work with the PS3 security leak after failing to find a hypervisor exploit for months absolutely soured any respect I had for him at the timeThat sounds interesting. I tried googling about it but can&#x27;t really find much other than that failoverflow found a key and didn&#x27;t release it, and then geohot released his own subsequently. I&#x27;d love to hear more about how directly he \"stole\" the work from the Fail0verflow team.edit: Reading some sibling comments here, it seems you are either mistaken and&#x2F;or were exaggerating your claim about the \"theft\" here. As far as I can tell, he simply took their findings and made his own version of an exploit that they had detailed publicly. That may be in poor taste in this particular community but it&#x27;s certainly not theft. I do agree that his behavior there was lacking in decency, but not to the degree implied here where I was thinking he _literally_ stole their exploit by hacking them, or something similar to that. reply cyrux004 7 hours agorootparentPeople here generally try to bash people who are much smarter than them, throwing shade at their background. They will say that he abandoned his first company, gave up on tiny grad but both of them are very much alive projects reply nomel 12 hours agorootparentprevObligatory Lex Fridman podcast, where he discusses it: https:&#x2F;&#x2F;youtu.be&#x2F;dNrTrx42DGQ?t=2408 reply jauntywundrkind 14 hours agoparentprevPytorch is just using Google&#x27;s OpenXLA now, & OpenXLA is the actual cross platform thing, no? I&#x27;m not very well versed in this area, so pardon if mistaken. https:&#x2F;&#x2F;pytorch.org&#x2F;blog&#x2F;pytorch-2.0-xla-path-forward&#x2F; reply fotcorn 12 hours agorootparentYou can use OpenXLA, but it&#x27;s not the default. The main use-case for OpenXLA is running PyTorch on Google TPUs. OpenXLA also supports GPUs, but I am not sure how many people use that. Afaik JAX uses OpenXLA as backend to run on GPUs.If you use model.compile() in PyTorch, you use TorchInductor and OpenAIs Triton by default. reply jauntywundrkind 6 hours agorootparentThank you for saying something useful here. I was vaguely under the impression that pytorch 2.0 had fully flipped to defaulting to openxla. That seems to not be the case.Good to hear more than a cheap snub. OpenAI Triton as the reason other GPUs work is a real non-shit answer, it seems. And interesting to hear JAX too. Thank you for being robustly useful & informative. reply mathisfun123 11 hours agorootparentprev> Pytorch is just using Google&#x27;s OpenXLA nowthis is so far from accurate it should be considered libelous; from the link> PyTorch&#x2F;XLA is set to migrate to the open source OpenXLAso PyTorch on the XLA backend is set to migrate to use OpenXLA instead of XLA. but basically everyone moved from XLA to OpenXLA because there is no more OSS XLA. so that&#x27;s it. in general, PyTorch has several backends, including plenty of homegrown CUDA and CPU kernels. in fact the majority of your PyTorch code runs through PyTorch&#x27;s own kernels. reply voz_ 7 hours agorootparentprevWrong. reply Roark66 2 hours agoprevI think the article claiming \"PyTorch has dropped the drawbridge on the CUDA moat\" is way over optimistic. Jest pytorch is widely used by researchers and by users to quickly iterate various over various ways to use the models, but when it comes to inference there are huge gains to be had by going a different route. Llama.cpp has showed 10x speedups on my hardware for example (32gb of gpu ram + 32gb of cpu ram)for models like falcon-40b-instruct, for much smaller models on the cpu (under 10b) I saw up to 3x speedup just by switching to onnc and openvino.Apple has showed us in practice the benefits of CPU&#x2F;GPU memory sharing, will AMD be able to follow in their footsteps? The article claims AMD has a design with up to 192gb of shared ram. Apple is already shipping a design with the same amount of RAM(if you can afford it). I wish them-and) success, but I believe they need to aim higher than just matching apple in some unspecified future. reply physicsguy 2 hours agoprevDon’t agree at all. PyTorch is one library - yes, it’s important that it supports AMD GPUs but it’s not enough.The ROCm libraries just aren’t good enough currently. The documentation is poor. AMD need to heavily invest in their software ecosystem around it, because library authors need decent support to adopt it. If you need to be a Facebook sized organisation to write an AMD and CUDA compatible library then the barrier to entry is too high. reply pama 13 hours agoprevThere is only limited empirical evidence of AMD closing the gap that NVidia has created in the science or ML software. Even when considering pytorch only, the engineering effort to maintain specialized ROCm along with CUDA solutions is not trivial (think flashattention, or any customization that optimizes your own model). If your GPUs only need a simple ML workflow all times for a few years nonstop, maybe there exist corner cases where the finances make sense. It is hard for AMD now to close the gap across the scientific&#x2F;industrial software base of CUDA. NVidia feels like a software company for the hardware they produce; luckily they make the money from hardware thus cannot lock the software libraries.(Edited “no” to limited empirical evidence after a fellow user mentioned El Capitan.) reply fotcorn 12 hours agoparentROCm has HIP (1) which is a compatibility layer to run CUDA code on AMD GPUs. In theory, you only have to adjust #includes, and everything should just work, but as usual, reality is different.Newer backends for AI frameworks like OpenXLA and OpenAI Triton directly generate GPU native code using MLIR and LLVM, they do not use CUDA apart from some glue code to actually load the code onto the GPU and get the data there. Both already support ROCm, but from what I&#x27;ve read the support is not as mature yet compared to NVIDIA.1: https:&#x2F;&#x2F;github.com&#x2F;ROCm-Developer-Tools&#x2F;HIP reply Certhas 13 hours agoparentprevThe fact that El Capitan is AMD says that at least for Science&#x2F;HPC there definitely is evidence of a closing gap. reply pama 13 hours agorootparentThanks. You are actually right that this new supercomputer might move the needle once it is in production mode. I will wait and see how it goes. reply withwarmup 10 hours agoprevCUDA is the result of years of NVIDIA supporting the ecosystem, some people likes to complain because they bought hardware that was cheaper but can&#x27;t use it for what they want to use it, when you buy NVIDIA, you aren&#x27;t buying only the hardware, but the insane amount of work they have put into the ecosystem, the same goes for Intel, mkl and scikit-learn intelex aren&#x27;t free to develop.AMD has the hardware but the support for HPC is non-existent outside of the joke that is bliss and AOCL.I really wish for more competitors to enter the market in HPC, but AMD has a shitload of work to do. reply arcanus 8 hours agoparent> AMD has the hardware but the support for HPC is non-existent outside of the joke that is bliss and AOCL.You are probably two years behind the state of the art. The world&#x27;s largest supercomputer, OLCF&#x27;s Frontier, runs AMD CPUs and GPUs. It&#x27;s emphatically using ROCm, not just BLIS and AOCL. See for example: https:&#x2F;&#x2F;docs.olcf.ornl.gov&#x2F;systems&#x2F;frontier_user_guide.htmlThat&#x27;s hardly non-existent support for HPC. reply 65a 4 hours agorootparentAgreed...the main gap is support on consumer and workstation cards, which is where nVidia made headway, but that is starting erode super recently. ROCm works pretty well for me, I have had a lot more problems with specific packagers than the ROCm layer. reply aiunboxed 5 hours agoparentprevExactly, with NVIDIAs core focus on AI way before it was cool has lead to them being in this advantageous position. For AMD just being a price friendly competitor to Intel and Nvidia was the motto. reply runiq 9 hours agoparentprevYeah, that&#x27;s a pretty shortsighted take of things. Do you really believe that Nvidia hasn&#x27;t taken steps do make sure their moat is as wide as possible? reply Blammar 8 hours agorootparentThe thing about owning the CUDA spec is that Nvidia can add new features quickly without having to argue with other hardware vendors. I find that a positive thing overall.Also, I choose to pay the ~$120 Windows tax once (per box), everything works very well, and I don&#x27;t have the driver issues that some fraction of other users seem to have with Linux and Nvidia cards. Seems like a good use of my time. reply pixelesque 15 hours agoprevDoes AMD have a solution to forward device combatibility (like PTX for NVidia)?Last time I looked into ROCm (two years ago?), you seemed to have to compile stuff explicitly for the architecture you were using, so if a new card came out, you couldn&#x27;t use it without a recompile. reply mnau 14 hours agoparentNot natively, but AdaptiveCpp (previously hiSycl, then OpenSycl) has a single source single compiler pass, where they basically store LLVM IR as an intermediate representation.https:&#x2F;&#x2F;github.com&#x2F;AdaptiveCpp&#x2F;AdaptiveCpp&#x2F;blob&#x2F;develop&#x2F;doc&#x2F;...Performance penalty was within ew precents, at least according to the paper (figure 9 and 10) https:&#x2F;&#x2F;cdrdv2-public.intel.com&#x2F;786536&#x2F;Heidelberg_IWOCL__SYC... reply einpoklum 11 hours agoparentprevI don&#x27;t know what they do with ROCm, but with OpenCL, the answer is: Certainly. It&#x27;s called SPIR:https:&#x2F;&#x2F;www.khronos.org&#x2F;spir&#x2F; reply mark_l_watson 8 hours agoprevNVidia hardware&#x2F;CUDA stack is great, but I also love to see competition from AMD, George Hotz’s Tiny Corp, etc.Off topic, but I am also looking with great interest at Apple Silicon SOCs with large internal RAM. The internal bandwidth also keeps getting better which is important for running trained LLMs.Back on topic: I don’t own any current Intel computers but using Colab and services like Lambda Labs GPU VPSs is simple and flexible. A few people here mentioned if AMD can’t handle 100% of their workload they will stick with Intel and NVidia - understandable position, but there are workarounds. reply bigcat12345678 14 hours agoprevCuda is the foundationNVIDIA moat is the years of work built by oss community, big corporations, research insistuteThey spend all time building for cuda, a lot of implicit designs are derived from cuda&#x27;s characteristicThat will be the main challenge reply mikepurvis 13 hours agoparentIt depends on the domain. Increasingly people&#x27;s interfaces to this stuff are the higher level libraries like tensorflow, pytorch, numpy&#x2F;cupy, and to a lesser degree accelerated processing libraries such as opencv, PCL, suitesparse, ceres-solver, and friends.If you can add hardware support to a major library and improve on the packaging and deployment front while also undercutting on price, that&#x27;s the moat gone overnight. CUDA itself only matters in terms of lock-in if you&#x27;re calling CUDA&#x27;s own functions. reply bigcat12345678 13 hours agorootparentwhat I meant is that all these stuff have 15 years of implicit accumulation of knowledge and tips and even hacks builtin in the softwareNo matter what you depends on, you&#x27;ll have a slew of larger or minor obstacles or annoyanceThat collectively is the most itselfAs you said, already it&#x27;s clear that replacing cuda itself is not that daunting reply nabla9 14 hours agoprev> Crossing the CUDA moat for AMD GPUs may be as easy as using PyTorch.Nvidia has spent huge amount of work to make code run smoothly and fast. AMD has to work hard to catch up. ROCm code is slower , has more bugs, don&#x27;t have enough features and they have compatibility issues between cards. reply latchkey 13 hours agoparentLisa has said that they are committed to improving ROCm, especially for AI workloads. Recent releases (5.6&#x2F;5.7) prove that. reply einpoklum 11 hours agoparentprev> Nvidia has spent huge amount of work to make code run smoothly and fast.Well, let&#x27;s say \"smoother\" rather than \"smoothly\".> ROCm code is slowerOn physically-comparable hardware? Possible, but that&#x27;s not an easy claim to make, certainly not as expansively as you have. References?> has more bugsPossible, but - NVIDIA keeps their bug database secret. I&#x27;m guessing you&#x27;re concluding this from anecdotal experience? That&#x27;s fair enough, but then - say so.> ROCm ... don&#x27;t have enough features andLikely. while AMD has both spent less in that department (and had less to spend I guess); plus, and no less importantly - it tried to go along with the OpenCL initiative, as specified by the Khronos consortium, while NVIDIA has sort of \"betrayed\" the initiative by investing in it&#x27;s vendor-locked, incompatible ecosystem and letting their OpenCL support decay in some respects.> they have compatibility issues between cards.such as? reply kkielhofner 6 hours agorootparentI wouldn’t say ROCm code is “slower”, per se, but in practice that’s how it presents. References:https:&#x2F;&#x2F;github.com&#x2F;InternLM&#x2F;lmdeployhttps:&#x2F;&#x2F;github.com&#x2F;vllm-project&#x2F;vllmhttps:&#x2F;&#x2F;github.com&#x2F;OpenNMT&#x2F;CTranslate2You know what’s missing from all of these and many more like them? Support for ROCm. This is all before you get to the really wildly performant stuff like Triton Inference Server, FasterTransformer, TensorRT-LLM, etc.ROCm is at the “get it to work stage” (see top comment, blog posts everywhere celebrating minor successes, etc). CUDA is at the “wring every last penny of performance out of this thing” stage.In terms of hardware support, I think that one is obvious. The U in CUDA originally stood for unified. Look at the list of chips supported by Nvidia drivers and CUDA releases. Literally anything from at least the past 10 years that has Nvidia printed on the box will just run CUDA code.One of my projects specifically targets Pascal up - when I thought even Pascal was a stretch. Cue my surprise when I got a report of someone casually firing it up on Maxwell when I was pretty certain there was no way it could work.A Maxwell laptop chip. It also runs just as well on an H100.THAT is hardware support. reply binarymax 15 hours agoprevAnd the question for most that remains once AMD catches up: will the duopoly result in lower prices to a reasonable level for hobbyists or bootstrapped startups, or will AMD just gouge like NVidia? reply quitit 14 hours agoparentI think in this case the changes needed to make AMD useful will open the market to other players as well (e.g. Intel).PyTorch is already walking down this path and while CUDA-based performance is significantly better, that is changing and of course an area of continued focus.It&#x27;s not that people don&#x27;t like Nvidia, rather it&#x27;s just that there is a lot of hardware out there that can technically perform competitively, but the work needs to be done to bring it into the circle. reply binarymax 14 hours agorootparentLast I checked I saw the H100 was about two gens more advanced for certain components (tensor cores, bfloats, cache, mem bandwidth) - but my research may have been wrong as admittedly I&#x27;m not as familiar with AMDs offerings for GPU. reply FuriouslyAdrift 13 hours agorootparentThey are not behind... https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;amd-expands-mi300-with-gpu...You can also actually buy them as opposed to the nVidia offerings which you are going to have to fight for. reply klysm 15 hours agoparentprevA simplistic economic take would suggest that the competition would result in lower prices, but given two players in the market who knows. reply binarymax 15 hours agorootparentMy intuition is along the lines that if AMD had a competing product earlier, then it would have kept prices down. But since Nvidia has shown what the market will pay, AMD won&#x27;t be able to resist overcharging. It will probably come down a little, but nowhere near to the point of affordability.I sure hope I&#x27;m wrong. reply tyre 13 hours agorootparentAMD might have to charge less to break into customers that are already bought into Nvidia. There has to be a discount to cover the switching costs + still provide savings (or access). reply zirgs 12 hours agorootparentAMD will have to provide a REALLY steep discount to convince me to come back. reply sumtechguy 14 hours agorootparentprevIt is oligopoly pricing.https:&#x2F;&#x2F;www.investopedia.com&#x2F;terms&#x2F;o&#x2F;oligopoly.aspWith that few competitors pricing would not change much. reply AnthonyMouse 14 hours agorootparentThat&#x27;s mostly when there isn&#x27;t a lot of price elasticity of demand. If you&#x27;re Comcast and Verizon, each customer wants one internet connection and you&#x27;re not going to change the size of the market much by offering better prices.If you&#x27;re AMD and NVIDIA and lowering the price would double the number of customers, you might very well want to do that, unless you&#x27;re supply constrained -- which has been the issue because they&#x27;re both bidding against everyone else for limited fab capacity. But that should be temporary.This is also a market with a network effect. If all your GPUs are $1000 and nobody can afford them then nobody is going to write code for them, and then who wants them? So the winning strategy is actually to make sure that there are kind of okay GPUs available for less than $300 and make sure lots of people have them, then sell very expensive ones that use the same architecture but are faster.That has been the traditional model, but the lack of production capacity meant that they&#x27;ve only been making the overpriced ones recently. Which isn&#x27;t actually in their interests once the supply of fab capacity loosens up. reply ngcc_hk 8 hours agorootparentActually there is already a market like this they are in - game. Most Gpu used are low to mid-range see steam. The AI has to and will go down to that level for using or gaming. You cannot just have game for intel … you did. Then steam work hard and realize the steam deck. You can have total different software like j and a did. Hence you really can’t have 1 N to rule for long. Do thank for it and all the fish, without it we might be still doing Gpu for numerical computing research. reply ad404b8a372f2b9 14 hours agorootparentprevPrices seemed to have lowered when AMD came out with CPUs competitive with Intel&#x27;s. reply tibbydudeza 14 hours agorootparentprevPrice difference between 13900K and AMD Ryzen 9 7950x is not big - the latest 7950X3D is about on par with the higher clocked 13900KS as well. reply redeeman 13 hours agorootparentbecause intel lowered their prices reply tibbydudeza 1 hour agorootparentI was on the market last month - Intel was the better choice because AM5 boards and DDR5 was too expensive.Ryzen 9 7950X — $799 on release Intel 13900K - $589. reply hackerlight 10 hours agorootparentprevLooking at the CPU market, competition did lead to lower prices: AMD are the best, but their CPUs are very reasonably priced because Intel is close behind.In the gaming market for GPUs, Nvidia has no competition except in some niche areas. Overall, their lead in upscaling software is too commanding so they can price how they want. Customers are paying 15-20% premiums for the same raw hardware performance, all to access Nvidia&#x27;s DLSS, because there&#x27;s no good competition. reply adamsvystun 10 hours agoparentprevThis is not a binary question. Two players, while not ideal, are better then just one. reply johngossman 8 hours agoparentprevWhen AMD caught up to Intel in CPUs, prices went down (at least compared to when Intel had a complete monopoly). The same was true when AMD gaming cards were more competitive. Chip manufacturers have shown themselves willing to both raise prices when they can and lower them when they must. reply evanjrowley 14 hours agoparentprevAMD prices will go up because of the newfound ability to gouge for AI&#x2F;ML&#x2F;GPGPU workloads. Nvidia&#x27;s will likely go down, but I don&#x27;t expect it will be by much. The market demand is high, so the equilibrium price will also be high. Supply isn&#x27;t at pandemic &#x2F; crypto-rush lows, but the supply of cards useful for CUDA&#x2F;ROCm still is. reply rafaelmn 15 hours agoparentprevIf the margins and demand is there Intel will eventually show up reply wmf 14 hours agorootparentIntel already showed up three or four times but their software is as bad as AMD&#x27;s used to be. reply ilc 14 hours agorootparentThankfully, software can be fixed over time as AMD has shown. Lack of another competitor can&#x27;t be fixed as easily. reply Havoc 14 hours agorootparentprevIs either in doubt? reply rafaelmn 14 hours agorootparentWouldn&#x27;t be surprised if a bunch of investment is hype bubble and demand correction forces price correction. Maybe not immediately but at Intel&#x27;s pace - they managed to miss out on mining bubble, wouldn&#x27;t be surprised for them to release in a correction. reply rdsubhas 14 hours agoparentprevDemand will push AMD prices up by couple hundred bucks and Nvidia cards down by couple hundred bucks. A hobbyist customer will be neither better or worse. reply wil421 14 hours agoparentprevWhy would their investors allow anything else? I’m sure they see it as a huge loss like intel and mobile. reply stjohnswarts 9 hours agoparentprevIn general I think it will lower prices, certainly not as much as if there were 4+ on the market where it&#x27;s hard to anticipate your rivals. a 2 body system is pretty straight forward, 3 body can be stable for a while with some restrictions, a 4 body problem is really damn hard... reply ris 12 hours agoprevI don&#x27;t understand the author&#x27;s argument (if there is one) - pytorch has existed for ages. AMD&#x27;s Instinct MI* range has existed for years now. If these are the key ingredients why has it not already happened? reply benreesman 2 hours agoprevI know a lot of people don’t like George, I dislike plenty of people who are doing the right thing thing (including by some measures sama and siebel while they were pushing YC forward).But not admitting the tinygrad project is the best Rebel Alliance on this is just a matter of letting vibe overcome results. reply alecco 15 hours agoprevRegurgitated months-old content. blogspam reply upbeat_general 4 hours agoprevThis article doesn’t address the real challenge [in my mind].Framework support is one thing, but what about the million standalone CUDA kernels that have been written, especially common in research. Nobody wants to spend time re-writing&#x2F;porting those, especially when they probably don’t understand the low-level details in the first place.Not to mention, what is the plan for comprehensive framework support? I’ve experienced the pain of porting models to different hardware architectures where various ops are unsupported. Is it realistic to get full coverage of e.g., PyTorch? reply bdowling 4 hours agoparentSomeone could reimplement CUDA for AMD hardware. That would be legal because copying APIs for compatibility purposes is not copyright infringement. (See Google LLC v. Oracle America, Inc., 593 U.S. ___ (2021)).AMD is unlikely to do this, however, because it would commodify their own products under their competitor’s API.A third party could do it though. It may make sense as an open source project. reply blueboo 2 hours agoparentprevResearch kernels mostly turn to ash upon publication anyway. The wheel turns and the next post-doc gives ROCm a try and we move on reply fluxem 13 hours agoprevI call it the 90% problem. If AMD works for 90% of my projects, I would still buy NVIDIA, which works for 100%, even though I’m paying a premium reply hot_gril 13 hours agoparentI&#x27;m lazy, so it&#x27;s 99% for me. I don&#x27;t even mess with AMD CPUs; I know they&#x27;re not exactly the same instruction set as Intel, and more importantly they work with a different (and less mainstream) set of mobos, so I don&#x27;t want em. If AMD manages to pull more customers their way, that&#x27;s great, it just means lower Intel premium for me. reply Flameancer 1 hour agorootparentWhat mainstream board company is intel only? Maybe a decade ago on AM3(+) but on AM5&#x2F;AM5 I haven’t seen a main board partner not offer the same board SKU that works with Intel and AMD. reply bornfreddy 3 hours agorootparentprevThat&#x27;s an interesting take. AMD mobos are no \"less mainstream\" than Intel ones are... When you choose a CPU you are also choosing a compatible mobo chipset. The companies that make motherboards are mostly the same, so there should be no big difference between those.Also, while the CPU instruction sets are not exactly equal, the same is true for Intel processors of different generations too. And it doesn&#x27;t matter one bit... Unless there is a bug in CPU you will never notice the difference, because it is taken care of at the compiler &#x2F; kernel level.Intel does have some advantages (and disadvantages too) over AMD, just not those. reply 65a 4 hours agorootparentprevAs an owner of some Sapphire Rapids parts, let me just direct you to: https:&#x2F;&#x2F;edc.intel.com&#x2F;content&#x2F;www&#x2F;us&#x2F;en&#x2F;design&#x2F;products-and-... reply hot_gril 13 hours agoprevPeople complain about Nvidia being anticompetitive with CUDA, but I don&#x27;t really see it. They saw a gap in the standards for on-GPU compute and put tons of effort into a proprietary alternative. They tied CUDA to their own hardware, which sorta makes technical sense given the optimizations involved, but it&#x27;s their choice anyway. They still support the open standards, but many prefer CUDA and will pay the Nvidia premium for it because it&#x27;s actually nicer. They also don&#x27;t have CPU marketshare to tie things to.Good for them. We can hope the open side catches up either by improving their standards, or adding more layers like this article describes. reply zirgs 12 hours agoparentCUDA was released in 2007 and the development of it started even earlier - possibly even in the 90s. Back then nobody else cared about GPU compute. OpenCL came out 2 years after that. reply killerstorm 11 hours agorootparentNot true. People got interested in general-purpose GPU compute (GPGPU) in early 2000s when video cards with programmable shaders became available. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;General-purpose_computing_on_g...People made a programming language & a compiler&#x2F;runtime for GPGPU in 2004: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;BrookGPU reply hot_gril 10 hours agorootparentEverything has old beginnings that the specialists will remember, but GPU compute really reached mass popularity and became a large selling point for Nvidia in the 2010s. reply ddtaylor 15 hours agoprevIt&#x27;s worth noting that AMD also has a ROCm port of Tensorflow. reply ginko 14 hours agoparentWhen I try to install rocm-ml-sdk on Arch linux it&#x27;ll tell me the total installed size would be about 18GB.What can possibly explain this much bloat for what should essentially be a library on top of a graphics driver as well as some tools (compiler, profiler etc.)? A couple hundred MB I could understand if they come with graphical apps and demos, but not this.. reply tomsmeding 14 hours agorootparentA regular TensorFlow installation, just the Python library, is an 184 MB wheel that unpacks to about 1.2 GB of stuff. I have no clue what mess goes in there, but it&#x27;s a lot.Still, if you&#x27;re right that this package seems to take 18 GB disk size, something weird is going on. reply slavik81 13 hours agorootparentThere&#x27;s a lot of kernels that are specialized for particular sets of input parameters and tuned for improved performance on specific hardware, which makes the libraries a couple hundred megabytes per architecture. The ROCm libraries are huge because they are fat binaries containing native machine code for ~13 different GPU architectures. reply Flameancer 58 minutes agorootparentprevHe’s not wrong. I did a new arch install to try and get a 7800XT working with ROCm and PyTorch and was concussed on how I ran out of space but saw that ROCm was 18GB. reply the__alchemist 13 hours agoprevWhen coding using Vulkan, for graphics or compute (The latter is the relevant one here), you need to have CPU code (Written in C++, Rust etc), then serialize it as bytes, then have shaders which run on the graphics card. This 3-step process creates friction, much in the same way as backend&#x2F;serialization&#x2F;frontend does in web dev. Duplication of work, type checking not going across the bridge, the shader language being limited etc.My understanding is CUDA&#x27;s main strength is avoiding this. Do you agree? Is that why it&#x27;s such a big deal? Ie, why this article was written, since you could always do compute shaders on AMD etc using Vulkan. reply frnkng 13 hours agoprevAs a former ETH miner I learned the hard way that saving a few bucks on hardware may not be worth operational issues.I had a miner running with Nividia cards and a miner running with AMD cards. One of them had massive maintenance demand and the other did not. I will not state which brand was better imho.Currently I estimate that running miners and running gpu servers has similar operational requirements and finally at scale similar financial considerations.So, whatever is cheapest to operate in terms of time expenditure, hw cost, energy use,… will be used the most.P.s.: I ran the mining operation not to earn money but mainly out of curiosity. And it was a small scale business powered by a pv system and a attached heat pump. reply latchkey 13 hours agoparentI ran 150,000+ AMD cards for mining ETH. Once I fully automated all the vbios installs and individual card tuning, it ran beautifully. Took a lot of work to get there though!Fact is that every single GPU chip is a snowflake. No two operate the same. reply rottencupcakes 13 hours agorootparentHave you ever written about this enterprise? This sounds super unique and I would be very interested in hearing about how it was run and how it turned out. reply latchkey 13 hours agorootparentIt was unique, not many people on the planet, that I know of, who&#x27;ve run as many GPUs as I have. Especially not working for a giant company with large teams of people. For the tech team, it was just me and one other guy. Everything had to be automated because there was no way we could survive otherwise.I&#x27;ve put a bunch of comments here on HN about the stuff I can talk about.It no longer exists after PoS. reply freedomben 13 hours agorootparentwhat type of cards did you have? what did you do with them after PoS? How did you even buy so many cards? Sorry, like the other commenter I&#x27;m extremely curious reply latchkey 12 hours agorootparentPrimarily 470,480,570,580. We also ran a very large cluster of PS5 APU chips too.Got the chips directly from AMD. Since these are 4-5 year old chips, they were not going to ever be used. It is more ROI efficient with ETH mining to use older cards than newer ones.Had a couple OEM manufacture the cards specially for us with 8gb, heatsinks instead of fans (lower power usage) and no display ports (lower cost).They will be recycled as there isn&#x27;t much use for them now.I&#x27;m also no longer with the company. reply xcdzvyn 5 hours agorootparentCool! Were the PS5 APUs actually attached to a PS5 motherboard, or were they repurposed entirely? reply latchkey 5 hours agorootparentAsrock bc-250. This is some hardware that I wouldn&#x27;t have purchased, if given the choice, especially that close to ETH PoS.That said, I made it work, which was an insane amount of work, and it mined really well. replytails4e 9 hours agoprevAMD playing catch up is a good thing, their SW solution is intended to run on any HW, and with hip being basically line for line compatible with cuda it makes porting very easy. They did it with FSR,and they are doing it with rocm. Hopefully it takes off as it&#x27;s a more open ecosystem for the industry. Necessity is the mother of invention and all that. reply pjmlp 14 hours agoprevUnless they get their act together regarding CUDA polyglot tooling, I seriously doubt it. reply whywhywhywhy 13 hours agoprevAnyone who has to work in this ecosystem surely thinks this is a naive take reply freedomben 13 hours agoparentFor someone who doesn&#x27;t work in this ecosystem, can you elaborate? What&#x27;s the real situation currently? reply tormeh 9 hours agoprevFor LLM inference, a shoutout to MLC LLM, which runs LLM models on basically any API that&#x27;s widely available: https:&#x2F;&#x2F;github.com&#x2F;mlc-ai&#x2F;mlc-llm reply raggi 10 hours agoprevCan we just get wgsl compute good enough and over the line instead, and do away with these moats? reply mschuetz 1 hour agoparentNot happening. WGSL wants to support the lowest common denominator, so it&#x27;ll always mainly be a 5-year old mobile-phone API. Also if you want to beat CUDA, you&#x27;ll need some functionality that&#x27;s completely missing in compute shaders, especially WGSL. Like pointers and pointer casting (and that glsl buffer reference extension is the worst emulation of that feature I&#x27;ve every seen). reply superkuh 15 hours agoprev>There is also a version of PyTorch that uses AMD ROCm, an open-source software stack for AMD GPU programming. Crossing the CUDA moat for AMD GPUs may be as easy as using PyTorch.Unfortunately since the AMD firmware doesn&#x27;t reliably do what it&#x27;s supposed to those ROCm calls often don&#x27;t either. That&#x27;s if your AMD card is even still supported by ROCm: the AMD RX 580 I bought in 2021 (the great GPU shortage) had it&#x27;s ROCm support dropped in 2022 (4 years support total).The only reliable interface in my experience has been via opencl. reply 65a 4 hours agoparentROCm works fine on my 2016 Vega Frontier edition, for what it&#x27;s worth. reply htrp 15 hours agoparentprevhas opencl actually improved enough to be competitive? reply orangepurple 15 hours agorootparentI thought ONNX is supposed to be the ultimate common denominator for machine learning model cross platform compatibility reply zucker42 15 hours agoparentprevDo you mean OpenCL using Rusticl or something else? And what DL framework, if any? reply superkuh 15 hours agorootparentI should clarify that I mean for human person uses. Not commercial or institutional. But, clBLAST via llama.cpp for LLM currently. Or far in the past just pure opencl for things with AMD cards. reply spandextwins 9 hours agoprevThat’s like saying Ford is gonna catch Tesla. reply cantaloupe 9 hours agoparentDo you see that as an inevitability or an impossibility? reply tpmx 9 hours agoparentprevNo, not really. They have similar enough silicon, they \"just\" need some software to make it work. reply RcouF1uZ4gsC 14 hours agoprevI am not so sure.Everyone knows that CUDA is a core competency of Nvidia and they have stuck to it for years and years refining it, fixing bugs, and making the experience smoother on Nvidia hardware.On the other hand, AMD has not had the same level of commitment. They used to sing the praises of OpenCL. And then there is ROCm. Tomorrow, it might be something else.Thus, Nvidia CUDA will get a lot more attention and tuning from even the portability layers because they know that their investment in it will reap dividends even years from now, whereas their investment in AMD might be obsolete in a few years.In addition, even if there is theoretical support, getting specific driver support and working around driver bugs is likely to be more of a pain with AMD. reply AnthonyMouse 14 hours agoparentThis is what people complain about, but at the same time there aren&#x27;t enough cards, so the people with AMD cards want to use them. So they fix the bugs, or report them to AMD so they can fix them, and it gets better. Then more people use them and submit patches and bug reporters, and it gets better.At some point the old complaints are no longer valid. reply jiggawatts 12 hours agoprevCan I buy an MI300 or even rent one in a cloud? reply arcanus 8 hours agoparentSoon. The card is coming in Q4. The early shipments are likely all going to LLNL&#x27;s El Capitan Exascale computer: https:&#x2F;&#x2F;www.tomshardware.com&#x2F;news&#x2F;amds-instinct-mi300-moves-... reply voz_ 10 hours agoprevThe amount of random wrong stuff about pytorch in this thread is pretty funny. reply atemerev 13 hours agoprevNope. PyTorch is not enough, you have to do come C++ occasionally (as the code there can be optimized radically, as we see in llama.cpp and the like). ROCm is unusable compared to CUDA (4x more code for the same problem).I don&#x27;t understand why everyone neglects good, usable and performant lower-level APIs. ROCm is fast, low-level, but much much harder to use than CUDA, and the market seems to agree. reply Zetobal 15 hours agoprevThey are just too late even if they catch up. Until they make a leap like they did with ryzen nothing will happen. reply Havoc 14 hours agoparent>They are just too late even if they catch up.Late certainly, too late I don&#x27;t think so.If you can field a competitively priced consumer card that can run llama fast then you&#x27;re already halfway there because then the ecosystem takes off. Especially since nvidia is being really stingy with their vram amounts.H100 & datacenter is a separate battle certainly, but on mindshare I think some deft moves from AMD will get them there quite fast once they pull their finger out their A and actually try sorting out the driver stack. reply dylan604 14 hours agorootparent>If you can field a competitively priced consumer cardif this unicorn were to show up, what&#x27;s to say that all the non-consumers won&#x27;t just scarf up these equally performant yet lower priced cards causing the supply-demand situation we&#x27;re in now? the only difference would be a sudden supply of the expensive Nvidia cards that nobody wants because of their price. reply AnthonyMouse 14 hours agorootparentThe thing that causes it to be competitively priced is having enough production capacity to prevent that from happening.One way to do that may be to produce a card on an older process node (or the existing one when a new one comes out) that has a lot of VRAM. There is less demand for the older node so they can produce more of them and thereby sell them for a lower price without running out. reply Havoc 14 hours agorootparentprev>if this unicorn were to show upA unicorn like that showed up a couple hours ago. Someone posted a guide for getting llama to run on a 7900xtxhttps:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;LocalLLaMA&#x2F;comments&#x2F;170tghx&#x2F;guide_i...It&#x27;s still slow and janky but this really isn&#x27;t that far away.I don&#x27;t buy that AMD can&#x27;t make this happen if they actually tried.Go on fiverr, get them to compile a list of top 100 people in the DIY LLM space, send them all free 7900XTXs. Doesn&#x27;t matter if half of it is wrong, just send it. Next take 1.2m USD, post a dozen 100k bounties against llama.cpp that are AMD specific - support & optimise the gear. Rinse and repeat with every other hobbyist LLM&#x2F;stable diffusion project. A lot of these are zero profit open source &#x2F; passion &#x2F; hobby projects. If 6 figure bounties show up it&#x27;ll absolute raise pulses. Next do all the big youtubers in the space - carefully on that one so that it doesn&#x27;t come across as an attempted pay-off...but you want them to know that you want this space to grow and are willing to put your money where your mouth is.That&#x27;ll cost AMD what 2m 3m? To move the needle on a multi billion market? That&#x27;s the cheapest marketing you&#x27;ve ever seen.As I said the datacenter & enterprise market is another beast entirely full of moats and strategy, but I don&#x27;t see why a suitably motivated senior AMD exec can&#x27;t tackle the enthusiast market single handedly with a couple of emails, a cheque book and a tshirt that has the nike slogan on it.>what&#x27;s to say that all the non-consumers won&#x27;t just scarf up these equally performant yet lower priced cardsIt doesn&#x27;t matter. They&#x27;re in the business of selling cards. To consumers, to datacenters, to your grandmother. From a profit driven capitalist company the details don&#x27;t matter as long as there is traction & volume. The above - opening up even the possibility of a new market - is gold in that perspective. And from a consumer perspective anything that breaks the nvidia cuda monopoly is a win. reply lhl 12 hours agorootparentllama.cpp, ExLlama, and MLC LLM have all had ROCm inferencing for months (here are a bunch of setup instructions I&#x27;ve written up, for Linux and Windows: https:&#x2F;&#x2F;llm-tracker.info&#x2F;books&#x2F;howto-guides&#x2F;page&#x2F;amd-gpus ) - but I don&#x27;t think that&#x27;s the problem (and wouldn&#x27;t drive lots of volume or having downstream impact in any case).The bigger problem is on the training&#x2F;research support. Eg, here&#x27;s no official support for AMD GPUs for bitsandbytes, and no support at all for FlashAttention&#x2F;FA2 (nothing that 100K in hardware&#x2F;grants to Dettmers or Dao&#x27;s labs wouldn&#x27;t fix I suspect).The real elephant though is that AMD still having the disconnect that lack of support for consumer cards and home&#x2F;academic devs in general has been disastrous (while Nvidia supports CUDA on basically every single GPU they&#x27;ve made since 2010) - just last week there was this mindblowing thread where it turns out an AMD employee is paying out of pocket for AMD GPUs to support build&#x2F;CI for drivers on Debian. I mean, WTF, that&#x27;s stupidity that&#x27;s beyond embarrassing and gets into negligence terriroty IMO: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37665784 reply bornfreddy 2 hours agorootparentWow, that is really awkward... AMD should be donating the cards and even paying extra for the privilege - this is an important step for getting satisfied consumers. I hope they notice and rectify this situation so that Debian (and with it all downstream distros, like Ubuntu) can provide better support for their cards. I mean, that&#x27;s a no-brainer... reply dylan604 12 hours agorootparentprev>an AMD employee is paying out of pocket for AMD GPUsI hope he&#x27;s at least getting an employee discount! I guess AMD is not a fan of the 20% concept either reply 65a 4 hours agorootparentprevI was running llama on a w7900 a month ago, with 48gb of VRAM and excellent performance. ROCm support got a lot better really recently. replyur-whale 15 hours agoprev> AMD May Get Across the CUDA MoatI really wish they would, and properly, as in: fully open solution to match CUDA.CUDA is a cancer on the industry. reply mschuetz 1 hour agoparentWhat&#x27;s wrong with CUDA? I avoided it for years because it&#x27;s proprietory but about one year ago I started using it because all the alternatives (OpenGL&#x2F;Vulkan compute, OpenCL, WebGPU, ...) couldn&#x27;t quite do what I wanted, and it turned out to be a game changer. Nothing comes close to it. Now I&#x27;m hooked because there simply isn&#x27;t an alternative that&#x27;s as easy to use, yet powerfull and fast.I wish there was an open alternative, but NVIDIA did several things right that others, especially Khronos, do not: The UX is top-notch. It makes the common cases easy yet still fast, and from there you can optimize to your hearts content. Khronos, however, usually completely over-engineers things and makes the common case hard and cumbersome with massive entry barriers. reply einpoklum 11 hours agoprev [–] TL;DR:1. Since PyTorch has grown very popular, and there&#x27;s an AMD backend for that, one can switch GPU vendors when doing Generative AI work.2. Like NVIDIA&#x27;s Grace+Hopper CPU-GPU combo, AMD is&#x2F;will be offering \"Instinct MI300A\", which improves performance over having the GPU across a PCIe bus from a regular CPU. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article tackles Nvidia's domination in the GenAI market and the issues faced by those seeking to use different hardware.",
      "It underscores AMD's competitive strategies, such as backing PyTorch and launching the Instinct MI300A processor, to rival Nvidia.",
      "The article emphasizes the significance of performance, portability, and availability amidst GenAI hardware competitions, along with updates on industry developments."
    ],
    "commentSummary": [
      "The discussion centers around the competition between AMD and NVIDIA in the GPU market, specifically regarding AI, machine learning, high-performance computing, and Linux-based graphics card usage.",
      "Participants focus on performance, compatibility, and limitations of AMD's GPU compute technology and the ROCm platform. They compare it to NVIDIA's CUDA framework and highlight the challenges related to hardware support, packaging, build systems, and software ecosystem.",
      "There's an identified need for better support, enhanced resources, and improved performance from AMD. Participants also discuss the potential impact of competition on prices, and the potential of new entrants like Intel in the GPU market."
    ],
    "points": 431,
    "commentCount": 235,
    "retryCount": 0,
    "time": 1696613736
  },
  {
    "id": 37789107,
    "title": "We’re opening up access to Gov.uk forms",
    "originLink": "https://gds.blog.gov.uk/2023/10/03/how-were-opening-up-access-to-gov-uk-forms/",
    "originBody": "Skip to main content GOV.UK Blog Government Digital Service Organisations: Government Digital Service, Cabinet Office Search for: How we’re opening up access to GOV.UK Forms Posted by: Adam Robertson, Senior Product Manager, Government Digital Service, Posted on: 3 October 2023 - Categories: GOV.UK Forms Here at GDS, we’re making it easier for departments to build better digital services. GOV.UK Forms is an online form builder which can be used to make accessible and easy to use digital forms for GOV.UK. It saves time for departments that are processing form submissions, and time for users that are filling in forms. In just a matter of minutes, government teams can replace PDF and other document-based forms with digital forms which all users can access and are legally compliant with the Public Sector Bodies Accessibility Regulations 2018. Best of all, there’s no need for any technical knowledge and it’s completely free! GOV.UK Forms is currently in private beta, where we’re testing the product out with a small number of teams that own forms. This is to help us steadily understand how our product is working and what issues we need to address. After that, we’ll move into public beta, where we’ll open up GOV.UK Forms for any central government department to use freely. We wanted to share what we’ve been up to since our last update, and what we’re doing to open up private beta for a wider pool of users - a phase that we’re calling ‘Early Access’. This will allow departments with forms that only require current features to start building them, and also allow any government user to try out our product. It will also help us to ramp up our overall user numbers and test the stability of our platform before public beta. What we’ve done In October 2022, the Insolvency Service was the first government organisation to publish a form with us. This was a relatively simple form as we only supported quite basic features at the time. The vast majority of document-based forms require more complex features to turn these into digital forms, including multiple options, declaration statements and more. Routing to skip questions that aren’t relevant One of these features is routing, or skippable questions. If you think of any form that you might have to fill out, for example at the GP or for an application, the chances are that it will say ‘If you answer ‘No’, skip to question 13’ or similar. This is a really core requirement for form building, and we needed to find a way to build this so that people who aren’t digital professionals could understand how to set up this kind of logic for their form. We created a new journey for form builders to add this to questions that ask for one answer to be selected from a list of options. They can specify which answer should route people to a future question and which question they should go to. The person filling out the form will then skip questions they don’t need to answer - saving them time and saving processing time too. You can see how this appears for form builders in the screenshot below: A screenshot of a page informing a form creator that if a user answers ‘Yes’ to a question, they will be taken to a further question. We know this is not going to cover all routing needs though - in the future, we’d like to look at building branching (two separate sets of questions depending on the answer), and later down the line we might be able to expand our routing so you can add routes to more than one answer, and also routes based on a combination of answers. Making a draft of a live form At the start of 2023, if one of our users created a form, made it ‘live’ (meaning it can now be put on GOV.UK), and then later on wanted to edit their live form, any change made would be updated on the live form immediately. This would cause issues as form builders may be making multiple changes, or change their mind about what they want to edit. And each time this would happen, people that are filling in the form would be at risk of losing their progress. So what we did is we made live forms uneditable - instead, if you want to make changes to a live form, you would create a new draft copy of that form. Then you could make all the edits you want, and only make that new version live when you’re happy with all the changes. This new version would automatically replace the existing live form - meaning this change only happens once, and affects a much smaller number of people filling in the form. Detailed guidance Our form builder already allows users to add hint text to a question, such as ‘Enter your name as it appears in your passport’. But sometimes on a form there are questions that need a bit more information for someone to answer - for example, specific guidance that they may need to refer to, or industry codes that need to be defined so that the right code is entered. To do this, in September we released a feature called ‘detailed guidance’ that will allow this more detailed information to be provided to the person filling in the form. Here’s what it will look like for people filling out an example form: A screenshot of a question that provides more information about adjustments for interviews that can be offered, before asking the user whether they need adjustments. What we still need to do User management and self-service accounts Right now we use GOV.UK Signon to allow users to sign into our product and use it. However, each time that a new user wants access, our team has to set that account up. We also can’t give people custom permission levels based on what we want them to be allowed to do (and not do). Signon is currently making improvements to make it more self-serviceable, but this wouldn’t have been ready for us to start expanding. So last year we decided that we needed to move off of Signon and use Auth0 (also used by Ministry of Justice’s MOJ Forms) for authenticating users, and bring the permission controls into the GOV.UK Forms product itself. We also wanted to create a system so that users could create their own trial accounts without our involvement (self-service), try out the product, and then be easily upgraded to the next permission level in order to make their forms live. Doing this work is one of our key challenges to adding many more users onto the platform, and we’ve designed an easy flow to allow quick access to the product, whilst also keeping enough control of who can make live forms whilst we’re still in private beta. We also want to ensure we’re following good governance practices and ensure Memorandum of Understandings (MoUs) are agreed before somebody from a department is able to make a form live. Other features Before we kick off Early Access, there are some other features that we’re working on to implement, including: an analytics page for each form that shows basic analytics such as submission numbers and completion rates email confirmations of submission delivery, so that form completers have a record that their submission was received by the department an updated product page with a more detailed public roadmap, guidance on the product, and an easier way to send the team support requests Launch of Early Access Once we’ve achieved all these things, GOV.UK Forms will be ready for launching into our ‘Early Access’ stage within private beta, with a public beta launch planned for the first half of 2024. We are planning to start our Early Access period in November 2023, at which point central government departments can start trying out GOV.UK Forms to see what they can make - and if they meet the criteria, we’ll be providing access to make those forms live. This will open up in public beta when departments can provide their own editor access to form creators. As with any agile development process, timescales can shift depending on what we find out along the way, and priorities. Before we move to public beta, we have some much-requested features that we’ll be working on, including: uploading file attachments saving form completion progress and returning to where you left off paying for services within the form We’re not currently supporting organisations outside of central government, such as local councils or NHS and Police, but we’re hoping that we can see this scope expand later in 2024 and beyond. If you’re interested in what we’re up to, please visit our product page and sign up to our mailing list, where we’ll update you when Early Access is launched - and please share with colleagues or any civil servants who may be interested in our form builder. GOV.UK Pay product strategy and upcoming features Sharing and comments Share this page Twitter Facebook LinkedIn Email 3 comments Comment by Nova Constable posted on 03 October 2023 Will this ever be made available to local government bodies? Link to this comment Reply Replies to Nova Constable> Comment by The GDS Team posted on 04 October 2023 Hi Nova, unfortunately we're not currently supporting organisations outside of central government at the moment, but we’re hoping to expand our scope later in 2024 and beyond. Kind regards, The GDS Team Link to this comment Reply Replies to The GDS Team> Comment by Nova Constable posted on 04 October 2023 Thank you - this will be a great option if/when made available to us. Link to this comment Reply Leave a comment Enter your comment Name Email We only ask for your email address so we know you're a real person Email me if someone replies to my comment Submit comment By submitting a comment you understand it may be published on this public website. Please read our privacy notice to see how the GOV.UK blogging platform handles your information. Related content and links Government Digital Service GDS is here to make digital government simpler, clearer and faster for everyone. Good digital services are better for users, and cheaper for the taxpayer. Find out more. Sign up and manage updates Email Atom Be part of the transformation If you’re interested in joining us, check out all open opportunities on the GDS careers site. Follow us Twitter Facebook YouTube Instagram LinkedIn GDS Podcasts Recent Posts How we’re opening up access to GOV.UK Forms 3 October 2023 GOV.UK Pay product strategy and upcoming features 6 September 2023 The new in-person identity check for GOV.UK One Login 30 August 2023 Comments and moderation Read our guidelines Social media house rules Read our guidelines Useful links All GOV.UK blogs All GOV.UK blog posts GOV.UK All departments Accessibility statement Cookies All content is available under the Open Government Licence v3.0, except where otherwise stated © Crown copyright This site uses cookies to store information. Press accesskey C to learn more about your options. This site uses cookies Cookies are files saved on your phone, tablet or computer when you visit a website. We use cookies to store information about how you use the GOV.UK blogs website, such as the pages you visit. For more information, check the cookie statement Accept all cookiesReject all cookies Necessary Cookies Necessary cookies enable core functionality. The website cannot function properly without these cookies, and they can only be deactivated by changing your browser preferences. Cookies that measure website use We use Google Analytics to measure how you use the website so we can improve it based on user needs. Google Analytics sets cookies that store anonymised information about how you got to the site, the blog pages you visit, how long you spend on each page and what you click on while you're visiting the site. Cookies that measure website use On Off",
    "commentLink": "https://news.ycombinator.com/item?id=37789107",
    "commentBody": "We’re opening up access to Gov.uk formsHacker NewspastloginWe’re opening up access to Gov.uk forms (gds.blog.gov.uk) 339 points by open-source-ux 23 hours ago| hidepastfavorite177 comments meindnoch 22 hours agoWhen I moved to the UK, one of the surprising things was how well the GOV.UK ecosystem worked. My original country uses a mishmash of Java applets, ajax-based websites, and a mixture of mildly broken, outdated web technologies, served from a variety of domains. GOV.UK was a breath of fresh air with its simple, consistent UI, served as static HTML. This is how internet services should look like. reply nonrandomstring 21 hours agoparentHoorah to that! We are lucky to have wonderful .gov services; highly available, accessible, frictionless, simple, informative, well written and bullshit-free. Maybe the best online central government services in the world - though I hear Estonia are a contender too.However I live in perpetual fear that at any moment some corrupt minister will do a deal with Microsoft and the Devil. Out will go plain HTML and common interoperable standards, simple authentication, and in will come a vipers nest of javascript calling home to monstrous tracking infrastructure, AWS containers, Cloudflare MITM, hooked into some hideous TPM module and mandatory smartphone camera garbage that scans my iris....Somehow there is a stronghold of common sense and decency standing its ground within our government. I almost wish I could pay a little extra tax to fund them. reply 46Bit 21 hours agorootparentUmm, GOV.UK uses Google Analytics, Fastly CDN, AWS containers, and I believe is developing an app.(I worked at GDS until two years ago.) reply Aeolun 21 hours agorootparentLike he said:> a stronghold of common sense and decencyI get that OP was going for something else but…I don’t think there’s anything wrong with those things when in the right hands. reply arpinum 20 hours agorootparentprevgov.uk is not a monolith, different departments can make different decisions. There is no mandate for AWS containers or Fastly CDN. reply sonthonax 14 hours agorootparentThey tend to use the tools provided by Government Digital Services. reply switch007 18 hours agorootparentprevThey have to provision from a market place of approve service though right? reply nonrandomstring 21 hours agorootparentprevIndeed, but everything still works for me even though much of that stuff is blackholed here. These are common efficiencies (mistakes on my opinion fwiw) and hopefully we can further improve data-leakage and bring even more things properly back in-house.Not to be too gushing or naive, I am quite aware that in the UK we recently \"sold\" big chunks of GCHQ to Amazon, so I&#x27;m not all wide eyed that parts of our government IT aren&#x27;t idiots. reply djhn 13 hours agorootparentSold parts of GCHQ? Could you elaborate? That sounds rather bad. reply pjc50 21 hours agorootparentprevEveryone uses Google Analytics. I don&#x27;t find it particularly high up any list of real worries. reply ekianjo 20 hours agorootparentWhy does the government need to send its data to google exactly? reply cdogl 19 hours agorootparentShould they instead invest time and public money into solving simple product problems (“how many times was this thing looked at?”) in a way that can be understood by the average desk worker? When that problem is well met by the private sector? reply nonrandomstring 18 hours agorootparent> Should they instead invest time and public money into solving simple product problems ... when that problem is well met by the private sector?I think the answer is yes, and in my earlier post said I&#x27;d actually be happy to give more money for government projects that protect peoples&#x27; privacy better. For me the problem is not \"well met by the private sector\" because that solution imposes a hidden externality upon the public end-users. Part of the price we pay is leaking of our data to a non-national private company. reply pc86 14 hours agorootparentI&#x27;m not sure using Google Analytics qualifies as an \"externality\" but even if it does the UK government has proven time and time again it doesn&#x27;t give a damn about anyone&#x27;s privacy, so what makes you think any in-house version would be any better for privacy? Because it would certainly be worse from a technical standpoint. reply nonrandomstring 13 hours agorootparent> what makes you think any in-house version would be any better for privacy?Well, it&#x27;s a personal value judgement what is \"better\" of course, but for me being British, I see my government as having some legitimate interest in what I am doing, especially when transacting with them.On the other hand, a gargantuan for-profit American corporation that enriches it&#x27;s shareholders and was once run by Eric Schmidt, whose legendary face-palm gaffes buried \"Don&#x27;t be Evil\" under a smoking heap of sulphurous brimstone.... \"We know where you are. We know where you’ve been. We can more or less know what you’re thinking about\"No thanks!My government may be a sneaky bunch of bastards, but so far they&#x27;ve had the good manners not to openly show utter contempt for privacy. reply ozim 11 hours agorootparentI’d say they are “your bunch of sneaky bastards”.I’d rather have my government doing web analytics than some faceless corporation from across the globe.Might be of course different for people in totalitarian regimes - but as far as I am concerned I still can vote on ones in my country. replyallan_s 20 hours agorootparentprevFrench government websites use matomo if i m not mistaken reply angra_mainyu 20 hours agorootparentMakes sense, the French have a strong open source community and I believe the creator is French. reply 6510 14 hours agorootparentprevhttps:&#x2F;&#x2F;commission.europa.eu&#x2F;europa-analytics_en reply Gud 20 hours agorootparentprevI don’t.I despise Google and what they became and so should you.Maybe my 10 visits a day webpage is an anomaly, and I’m truly the only one not using Google analytics - Still, don’t pretend Google analytics is used by everyone. reply robertlagrant 16 hours agorootparent> I despise Google and what they became and so should youIt&#x27;s a bit laughable to talk about despising a company over this stuff. We&#x27;re not talking about an evil regime, or even Nestle for what they did with breast milk in Africa. It&#x27;s so over the top. reply nonrandomstring 19 hours agorootparentprevFor our podcast we specifically set up Plausible to exclude Google analytics. Rather little of value to be gained or lost either way, but it&#x27;s a matter of conscience and politeness to our users. Sadly we had to put in links to other big-tech application platforms, but those are links to click out of choice if you&#x27;re a user of those services. reply Gud 19 hours agorootparentThis is always the problem when interacting with the corporate internet. I have a Shopify store on my website where my readers can buy mugs and t-shirts to support me(not that anyone is lol). Lord knows what goes on in there.I hope someone reinvents the services we take for granted with a focus on privacy. reply dazc 19 hours agorootparentprevA lot of people use google analytics for no logical reason what soever though. Typical use case for a small to medium website seems to be a list of most visited pages. reply NavinF 19 hours agorootparentThat&#x27;s a perfectly logical reason to use GA. As long as HTTP servers don&#x27;t have a built-in UI for analytics, people will continue to use GA (with server side Measurement Protocol for counting hits from people with adblockers) for that use case. reply dalbasal 21 hours agorootparentprevIDK if those are, in themselves, indicators. The idea is not purity. The idea is for technical common sense to win over sales&#x2F;consultant-led architecture. reply tannhaeuser 19 hours agorootparentprevGA and external CDNs require cookie banner&#x2F;consent under GDPR (which is still valid in UK AFAIK). So that alone should be reason enough to avoid it.But you can never be sure: very recently, I&#x27;m seeing (unnecessary) popups coming up informing me about the site not using cookies! To make up for the phantom pain of not having one in EU where \"real\" sites do have cookie dialogs? The web and its self-referential UI idioms have become a strange place indeed. reply PaulHoule 20 hours agorootparentprevIt&#x27;s the HTML forms that are good and Angular, React and all that which are bad. reply bzmrgonz 19 hours agorootparentI wonder what technology they are using to wrangle these forms... I remember reading an article a few days ago concerning vuejs project to do something similar. reply petepete 10 hours agorootparentMy form building library is used for all the form wrangling.https:&#x2F;&#x2F;govuk-form-builder.netlify.app&#x2F; reply bitcharmer 19 hours agorootparentprevWhy does that matter? reply mtillman 19 hours agorootparentprevSingapore recently did a deal with a company no one has heard of for their immigration process and the results are cameras that don’t work to the point of the officials needing to manually adjust them, forms that don’t contain consistent data across pages, and my favorite “save a photo of the confirm just in case lah.” The old system just worked, the new system insists upon APPs. reply delta_p_delta_x 19 hours agorootparent> Singapore recently did a deal with a company no one has heard of for their immigration processSource? I&#x27;ve lived in Singapore all my life and have not heard of this. There was an outage on the 31st of March[1], and parliamentary discussion after that[2] doesn&#x27;t mention any of what you said.[1]: https:&#x2F;&#x2F;www.channelnewsasia.com&#x2F;singapore&#x2F;changi-airport-ter...[2]: https:&#x2F;&#x2F;www.mha.gov.sg&#x2F;mediaroom&#x2F;parliamentary&#x2F;oral-reply-to... reply yonatan8070 15 hours agorootparentprevEntirely off-topic, but why do some comments on HN have manual line breaks but most just soft-wrap? On my phone (Hacki app) each line is soft-wrapped, then hard-wrapped after 1 or 2 words, which looks quite off reply gadders 17 hours agorootparentprev>>simple authenticationThis is my only gripe. Every time I do self assessment or complete my tax returns as a contractor I had to find some arcane combination of government gateway ID, password, authentication app etc etc. It&#x27;s so secure it stops you paying the government money. reply whimsicalism 18 hours agorootparentprevHalf of the technologies you named are actually useful and it wouldn’t shock me if gov.uk uses them reply mozey 21 hours agoparentprevI applied for a UK visa from South-Africa about a year ago. To start my application I had to submit a form on this domain. The navigation to the form was obscured by a giant banner about the Ukraine invasion and a message about how service levels might be reduced due to refugees... no matter how I resized my browser window I couldn&#x27;t get to the part of the page behind the banner. Eventually I opened up the Dev Tools and added some CSS to hide the banner. The link was revealed and I could continue with my application reply koo5_2 19 hours agorootparentYou passed the first test! reply whimsicalism 18 hours agorootparentprevhow else do you think they were planning on reducing service levels? reply doublesocket 20 hours agoparentprevThe flip side of this is local government technology. Truly some of the worst crimes against web development have been committed by local councils, or rather their outsourcing partners.The service that takes that crown in my experience is tarantopermits.com, a parking permit management system that fills me with rage just thinking about it. reply gadders 17 hours agorootparentIt takes the piss that you have to pay to park outside your own house anyway.I mean, a nominal fee enough to correlate car registration with owners address, but not £210 like google told me it costs in Wandsworth. I bet about £10 of that goes to the council. reply hgomersall 14 hours agorootparentWhy? Do you own that bit of road? reply dazc 19 hours agorootparentprevI often wonder why so many Local Authorities and Gov Departments have to have their own unique web portals?There must be a massive cost-saving opportunity here. reply doublesocket 18 hours agorootparentAbsolutely, there&#x27;s massive duplication of functionality. I think it&#x27;s partly incompetence and partly a control thing. reply chinabot 13 hours agorootparentAll a control thing, incompetence is just a side effect. reply hooverd 19 hours agorootparentprevWell, they probably want to be able to update them as things change without waiting so many weeks on a ticket to central IT. I can&#x27;t imagine they&#x27;re doing anything unique though, so the best of both worlds could be central IT providing tools and managed hosting. reply gerdesj 18 hours agorootparentprevAre you sure:\"Welcome to tarantopermits.com\"\"This domain name is parked for FREE by fasthosts.co.uk\" reply doublesocket 18 hours agorootparentYes, they&#x27;re so incompetent they haven&#x27;t changed their parking page. See google search results:https:&#x2F;&#x2F;www.google.com&#x2F;search?client=firefox-b-d&q=tarantope...It&#x27;s all on subdomains, e.g. https:&#x2F;&#x2F;wandsworth.tarantopermits.com reply myth2018 21 hours agoparentprev> This is how internet services should look like.Yes, definitely.I&#x27;ve called UX designers out a couple times on the aesthetical complexity of their designs: if you award GOV.UK&#x27;s quality a prize [0], why don&#x27;t you mimic them instead of Google?[0] https:&#x2F;&#x2F;www.gov.uk&#x2F;government&#x2F;news&#x2F;govuk-wins-design-of-the-... reply pjc50 21 hours agorootparentThe GOVUK deliberately bare branding serves a purpose similar to the old Tesco Value branding: to make it look austere. If it looked luxurious people would be more likely to complain about taxpayer&#x27;s money being wasted. reply superhuzza 21 hours agorootparentNot really. They publish a lot of blogs explaining design decisions. It almost always comes down to making the services as accessible as possible.Part of that involves really simple layouts, very high contrast text, legible fonts, compatibility across many devices, simple language etc.It&#x27;s certainly an added benefit that it gives an appearance of austerity, but that&#x27;s more a byproduct of simplicity. reply anonymous_sorry 20 hours agorootparentprevCompanies need branding because they&#x27;re trying to stand out from the crowd. To be distinctive and memorable, so you think of them and trust them when making buying decisions.Governments generally don&#x27;t have that requirement. So GDS doesn&#x27;t need fancy branding and other concerns can take priority. It&#x27;s remarkably refreshing.It would have been so easy to just cargo-cult whatever is fashionable in the private sector. It&#x27;s kinda miraculous they didn&#x27;t. A mark of thoughtful, self-confident professionals. Bravo! reply tfgg 20 hours agorootparentprevThere was actually a lot of pushback against the austere aesthetic by government ministers - they wanted fancy looking photo banners and pretty things. This was pushed back on in the name of making something functional the prioritizes users. reply LeonardoTolstoy 21 hours agoparentprevI moved there from the US (and since then I&#x27;ve moved back). The main surprise was learning that working for the government is relatively high paying and considered a very nice and challenging job that great programmers coveted. At least that was my impression when a very good systems engineer workmate left my company to start working for gov.uk. I do wish there was a similar system in the US as I would find public service a rewarding field to work in in general. reply kaashif 20 hours agorootparentAs someone from the UK, with friends who work as programmers in both the public and private sectors, I&#x27;m not sure what you&#x27;re saying is true. It&#x27;s definitely not highly paying to work for the government, although \"relatively\" may be doing the heavy lifting in that sentence. reply LeonardoTolstoy 13 hours agorootparentI&#x27;m going off what I was told when I expressed surprise that such a good engineer would go for government work. Looking online it looks like they pay about median for a software engineer in London. And yeah, relatively here is basically meaning I was surprised you didn&#x27;t have to take a pay cut to work for the government. reply noodlesUK 20 hours agorootparentprevUnfortunately this is not true at all (at least for the past decade or more). There are definitely some really high quality people working for GDS, but for the life of me I have no idea how they keep them. Civil Service salaries are extremely low compared to industry rates, and the perks (such as pensions) aren&#x27;t nearly as good as they used to be. reply dazc 19 hours agorootparentI have a friend who is a civil servant (ONS). She would be the first to concede that salaries are low but there are other benefits that compensate. Working from home 3 days a week, generous time off in lieu for the odd extra hours worked and so on.I should add she is late 50&#x27;s and the prospect of finding work elsewhere in a comparable role would be very unlikely. reply gadders 17 hours agorootparentI bet the pension would help as well. reply aaronsnow 19 hours agorootparentprevIn the US government, take a look at https:&#x2F;&#x2F;www.usds.gov&#x2F;apply and https:&#x2F;&#x2F;join.tts.gsa.gov&#x2F; — and there are many more opportunities emerging as the USG gets better at all of this.More generally for federal and state&#x2F;local government opportunities to use your technology expertise to make a difference, these folks are excellent: https:&#x2F;&#x2F;techtalentproject.org&#x2F;tech-talent&#x2F; reply whimsicalism 17 hours agorootparentThe problem with working in the government&#x2F;nonprofit sphere is that you will always be treated as second fiddle&#x2F;grunt work to the real movers and shakers.I mean just look at the breakdown of who runs that “tech talent project” to see what I mean. In the industry, ideally, decisions are being made and executed by other technical people. It’s part of what has made Silicon Valley so uber successful. reply Chaosvex 20 hours agorootparentprevThis is definitely not true. Developers are better off in the private sector and I&#x27;ve never heard of any developer regard working for the government as coveted or prestigious. reply qaisjp 19 hours agorootparentWhen I retire I want to go work for the GDS reply ricardobayes 19 hours agorootparentprevThat&#x27;s the same in Spain, the key is that public employees generally speaking can&#x27;t be fired for performance reasons. That is the ultimate workplace in a country of 20%+ unemployment. reply vidarh 20 hours agorootparentprev> The main surprise was learning that working for the government is relatively high payingIt&#x27;s middle of the tree at best. I&#x27;m sure you can find people for whom it&#x27;s well paying, but the recruiters from UK gov departments that regularly contact me keep trying to sell me on the benefits of jobs where the upper salary band is less than half of what I earn. reply bloqs 9 hours agorootparentprevI would say that this is true for the breed of programmers that like to help other people, who I respect over anyone who goes for higher paying work. Gov.uk has some real stars associated with it reply e2le 20 hours agoparentprev>This is how internet services should look like.Thankfully I&#x27;ve noticed more sites copying gov.uk, very few but still positive. reply jeff_vader 19 hours agoparentprevThe design, look and feel is great. Authenticating &#x2F; proving your identity on the other hand is lacking: https:&#x2F;&#x2F;www.gov.uk&#x2F;using-your-gov-uk-one-login&#x2F;proving-your-...Meanwhile, at least in some EU countries, you can authenticate using your identity card and USB smartcard reader. reply Ylpertnodi 19 hours agorootparentProving your id: passport or ID card, &#x27;new&#x27; driving license, domestic bill. There&#x27;s a lot of ex-pats don&#x27;t have the last two. Repeatedly being told to log in to the site is a pain if its impossible. Extremely well designed, though. reply marwis 11 hours agorootparentprevOr identity card and your phone as an NFC reader reply kwhitefoot 19 hours agorootparentprevIt can be done without an ID card and card reader too. BankID is what we use in Norway. reply bpye 18 hours agorootparentI’m guessing that’s similar to what we have in Canada - which is essentially sign on through a banking provider? A couple provinces have their own sign on system with their services card now too - BC included. reply xcdzvyn 21 hours agoparentprevAustralia&#x27;s somewhat similar too. I wouldn&#x27;t call our government services optimal nor \"simple\", but it&#x27;s clear they&#x27;re all operating on the same design principles. At the very least it inspires confidence that they&#x27;re operating on roughly the same guidelines at federal and state levels. reply manojlds 21 hours agoparentprevMy first disappoint in the UK was the DVLA where I was sent to the older form. reply dazc 19 hours agoparentprevIf you stay around long enough you&#x27;ll accumulate a few different log-in id&#x27;s and find yourself redirected to legacy pages with no way of finding your way back.The GOV.uk team loves moving things forward and leaving an awful lot of guff behind. reply ricardobayes 19 hours agorootparentWell in my country they love changing URLs so there is no continuity at all. Any link from a year ago is 99% guaranteed to be 404. reply Roark66 19 hours agoparentprevWhen I was living in the UK I thought so to, but when I moved to another country (Poland) I realised 3 huge shortcoming of the UK&#x27;s online gov system (perhaps they fixed it by now, I moved 6 years ago). These were: a unified way to authenticate oneself to all gov services, a way to sign electronic forms&#x2F;documents in a legally binding way without having to buy a personal certificate and a establishing a standard \"document submission receipt\" that proves what and when you submitted.I&#x27;ll start why this really matters from the last item. Even after my move I kept my UK company for a while, I was making regular electronic VAT submissions until sometime in July 2021 I decided to deregister my company&#x27;s VAT. I did that via HMRC&#x27;s online form. In December I logged in to check to find out that any record of me doing that evaporated, and now I had an \"estimated\" VAT bill of around £5k. I submitted a zero return for the previous quarter I should&#x27;ve been deregister in and after I rang HMRC and 2 weeks later the balance \"I owed\" dropped to zero. I deregistered again and this time \"it worked\". However, I had no way whatsoever to prove I indeed deregistered before. The person I spoke to on the phone that day decided my story believable so I didn&#x27;t get any fines. What if they had a worse day? Ability to reliably prove you submitted government documents when you say you did is extremely important. In the country I now live in(Poland) you get a cryptographically signed XML document you can use as proof. You get one from any level of government you submit stuff to online (taxes, local councils anything). There is an online service you can check the validity of such signature and the content is all readable with a text editor.Then a way to electronically sign documents that is equivalent to your in person signature legally without any special equipment or software for free. And a way to authenticate oneself to government services(including national healthcare) Here any citizen (or a foreigner that registers) can do so with one \"thing\". There are few ways to authenticate, an app, an online bank account (all banks in the country support it), a national id with a nfc chip and a pin, or you go to a local council in person and they create an account for you with a usename&#x2F;password +2FA(sms,or auth app). You can sign any document using an online service, there is a history of stuff you signed you can check and you have a \"mailbox\" you can use to receive documents instead of the post.The system is mostly XML based and it uses ssl for signatures. I have no idea what they use in the backend (probably lots of java). One can also purchase certificates to use as a signature like in other EU countries. The government sites look reasonably modern with dynamic forms, but they deteriorate gracefully if all you want is to read them, but good luck getting forms to work without JS.Personally I think they did a pretty good job with this system. reply dgroshev 10 hours agorootparentThe digital signature thing is an extension of the overall document culture prevalent at least in Germany and Eastern Europe (or maybe continental Europe overall?).From what I saw, their legal and bureaucratic systems are geared to try to authenticate everything via physical means, be it signatures (that are supposed to be unique and not just an expression of intent), wet stamps, or (recently) digital signatures. On the contrary, UK works on trust and its legal systems, so you can (theoretically) sign a large money contract with a cross on a napkin, you can open a bank account with a letter from a \"a person of good standing in their community\" without ever holding a government issued ID, and you can sign contracts with a simple checkbox.I really enjoy the latter. It&#x27;s a bit messier, but also feels more humane. reply joshxyz 14 hours agoparentprevone of the many good measures of the company and country is their design system implementation.love u gov.uk. reply V__ 22 hours agoprevThe GOV.UK Design System team [1] is really doing great work. Wish there would be more like this from other governments.[1] https:&#x2F;&#x2F;design-system.service.gov.uk&#x2F;design-system-team&#x2F;Edit: Apparently there are a lot! Really nice to see. reply ZeKK14 22 hours agoparentFrance launched a similar program and publish everything they can on GithubSee https:&#x2F;&#x2F;www.systeme-de-design.gouv.fr&#x2F; and https:&#x2F;&#x2F;github.com&#x2F;GouvernementFR&#x2F;dsfr reply sofixa 21 hours agorootparentI find it really funny that it&#x27;s published on GitHub with the MIT license, but with a disclaimer it&#x27;s illegal to use it outside of government websites.It&#x27;s great that it&#x27;s publicly available, like many other public stuff the French Government is doing like https:&#x2F;&#x2F;beta.gouv.fr&#x2F; or the tax calculators, but it&#x27;s still funny. reply debugnik 19 hours agorootparentThe conditions in the disclaimer only apply to the French government. Translated with Firefox (which apparently still makes some typos):> Conditions for the use of the Components by the Other Users> All Other Users are allowed to use the source code according to the terms of the MIT license.> Other Users are expressly reminded that any use of the Components outside the limits referred to herein or for the purpose of diverting them and otherwise appropriateing the State Mark is punishable by civil and&#x2F;or criminal sanctions. reply sofixa 13 hours agorootparent> Prohibited Use Outside Government WebsitesIt explicitly states it&#x27;s forbidden to be used by private actors. reply debugnik 10 hours agorootparentOh, right, on the readme! That&#x27;s so weird, because it kinda contradicts the \"general conditions for use\" document. I guess they mean the source code is ok to use but you must alter the design first? The UK&#x27;s doesn&#x27;t have such a dumb limitation. reply Aeolun 21 hours agorootparentprevThat seems unenforcable under a MIT license? Especially outside of France. reply londons_explore 20 hours agorootparentGovernments can write laws to do whatever they like... And they have police to enforce stuff however they like. reply als0 20 hours agorootparentHow can French police enforce things outside of France? reply ceejayoz 20 hours agorootparentExtradition, cooperation with other EU nations...Or they just blow up your boat. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Sinking_of_the_Rainbow_Warrior reply Halvedat 15 hours agorootparentprevThe same way anyone enforces things outside of their borders, through force. replytotetsu 22 hours agorootparentprevand Australia https:&#x2F;&#x2F;www.dta.gov.au&#x2F;help-and-advice&#x2F;digital-service-stand... reply Gigablah 22 hours agorootparentHere&#x27;s Singapore&#x27;s: https:&#x2F;&#x2F;www.designsystem.tech.gov.sg&#x2F; reply aaronsnow 22 hours agorootparentAnd the US: https:&#x2F;&#x2F;designsystem.digital.gov&#x2F; reply sjogress 22 hours agorootparentAnd Norway: https:&#x2F;&#x2F;www.designsystemet.no&#x2F; replybrokebroadbeat 19 hours agoparentprevThanks so much for this! I’m the design system lead and this has made the team very happy. reply lode 22 hours agoparentprev> Wish there would be more like this from other governments.There is:Argentina - https:&#x2F;&#x2F;argob.github.io&#x2F;poncho&#x2F;Australia - https:&#x2F;&#x2F;gold.designsystemau.org&#x2F;Canada - https:&#x2F;&#x2F;design.gccollab.ca&#x2F;Czech Republic - https:&#x2F;&#x2F;designsystem.gov.cz&#x2F;#&#x2F;Estonia - https:&#x2F;&#x2F;brand.estonia.ee&#x2F;?lang=enFlanders - https:&#x2F;&#x2F;www.vlaanderen.be&#x2F;digitaal-vlaanderen&#x2F;onze-oplossing...France - https:&#x2F;&#x2F;www.systeme-de-design.gouv.fr&#x2F;Germany - https:&#x2F;&#x2F;styleguide.bundesregierung.de&#x2F;sg-de&#x2F;Greece - https:&#x2F;&#x2F;guide.services.gov.gr&#x2F;Italy - https:&#x2F;&#x2F;developers.italia.it&#x2F;en&#x2F;designers&#x2F;Netherlands - https:&#x2F;&#x2F;www.digitaleoverheid.nl&#x2F;achtergrondartikelen&#x2F;het-nl-...New Zealand - https:&#x2F;&#x2F;www.digital.govt.nz&#x2F;standards-and-guidance&#x2F;design-an...Singapore - https:&#x2F;&#x2F;www.designsystem.tech.gov.sg&#x2F;Switserland - https:&#x2F;&#x2F;swiss.github.io&#x2F;styleguide&#x2F;en&#x2F;United States - https:&#x2F;&#x2F;designsystem.digital.gov&#x2F;Ukraine - https:&#x2F;&#x2F;diia-en.fedoriv.com&#x2F; reply davidy123 21 hours agorootparentThank you for this, but I guess it&#x27;s out of date, for Canada at least it&#x27;s now https:&#x2F;&#x2F;articles.alpha.canada.ca&#x2F;forms-formulaires&#x2F;It went from DIY open source to something more like the UK&#x27;s model; in fact Canada is running with a number of UK-origin projects & ideas, like Notify, which is of course a good thing, we should all learn from each other&#x27;s best practices and innovations. reply masterrr 22 hours agorootparentprevFedoriv work for Ukraine is unmatched! reply Sheeny96 22 hours agoprevHonestly, the people behind the scenes of gov uk are doing gods work. See nothing but great stuff coming out of there. reply alt227 22 hours agoparentI fully agree.Two of my favourites:Holiday API I plug into every ecommerce site I work on:https:&#x2F;&#x2F;www.api.gov.uk&#x2F;gds&#x2F;bank-holidays&#x2F;#bank-holidaysDomain Email Security checker:https:&#x2F;&#x2F;emailsecuritycheck.service.ncsc.gov.uk&#x2F;checkPlease share any other favourites! reply pnut 22 hours agorootparentThe fact that the UK government&#x27;s bank holiday API has bunting advice just makes my day. reply alias_neo 22 hours agorootparentWhere did you find this? Is it part of the API response?Would be fun to use this for some digital decor at home.Next bank holiday is Christmas so I&#x27;ve got some time to build something!EDIT: Just found it in the JSON; shame, was hoping it would contain bunting patterns&#x2F;colours.https:&#x2F;&#x2F;www.gov.uk&#x2F;bank-holidays.json reply jordanrobinson 20 hours agorootparentIf you go off this issue it looks like they use tinsel at Christmas, although I&#x27;m not sure where that logic is.https:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F;calendars&#x2F;issues&#x2F;678 reply alias_neo 19 hours agorootparentI&#x27;d be interested in taking a look to see if they use different bunting styles for different occasions, my thought process was that I could create some form of digital-bunting in my home to indicate various occasions.As a(n) (English) Brit, I believe this could be quite an excellent indicator of whether I should be drinking Guiness, Tea, Whisky, Pimms, Champagne or Mulled Wine at any given time of the year. I suppose it should live in the Kitchen, near the kettle, or the wine cooler. reply pjc50 21 hours agorootparentprevIt looks like that&#x27;s only false for Good Friday, which I suppose makes sense that as a Christian you don&#x27;t \"celebrate\" the execution of Jesus. reply alias_neo 20 hours agorootparentIndeed, there are others such as the queen&#x27;s funeral. Bunting is reserved for celebrations. reply nicoburns 21 hours agorootparentprevYes: a plain JSON endpoint with no authentication! It&#x27;s the perfect way of exposing this kind of data. reply londons_explore 20 hours agorootparentI wonder how the backend works... Is it a microservice which queries over a globally distributed &#x27;bank holidays&#x27; database, which has a frontend for some admin to add&#x2F;remove bank holidays, and perhaps a custom approval workflow to approve&#x2F;deny bank holidays, and maybe a system to make new bank holidays &#x27;go live&#x27; on a certain date&#x2F;time?Or is it just a static file someone wrote in vim and checked into git which got hosted as a static asset? reply ZeroGravitas 20 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F;calendars&#x2F;blob&#x2F;master&#x2F;README.md reply londons_explore 20 hours agorootparentIt&#x27;s a static file manually written (and slightly post processed). reply butterknife 21 hours agorootparentprevDVLA VES. Never miss a car tax payment or MOT again.https:&#x2F;&#x2F;developer-portal.driver-vehicle-licensing.api.gov.uk... reply globular-toast 22 hours agorootparentprevI love that the bank holiday one tells you whether or not bunting is appropriate on that day. It looks like the ones for which it isn&#x27;t are ones commemorating death, like the state funeral of Elizabeth II and Good Friday (Crucifixion of Jesus). reply buggeryorkshire 22 hours agoparentprevHave been impressed with their work for years, the majority of my governments other IT bits are awful. reply blitzar 21 hours agoparentprev> the people behind the scenes of gov ukThose would be the people commonly refered to as incompetent traitorous woke lefty cultural marxists refusing to do the will of the people by the fair and balanced media. reply Aeolun 21 hours agorootparentThat sounds like the UK media alright. If you take one look at a newspaper stand on any day of the week you’d think the sky was falling. reply IshKebab 22 hours agoparentprev100%. Well maybe 99%. The tax free childcare website is very frustrating. reply tescocles 21 hours agorootparentIt seems to be taking a while for the framework to propagate to more independent arms of the government; as well as your example, for the (e.g.) DVLA a lot of the top level information-only pages are in the new framework (and also reside on www.gov.uk), but if you click any link to a form you get taken to the DVLA subdomain (motoring.dvla.gov.uk) and the difference is stark.For the DVLA the site isn&#x27;t so bad, but I definitely get that slightly disconcerted feeling that something is going to go wrong while you&#x27;re filling out this important, official form? Which I don&#x27;t get at all in the new framework. reply habosa 19 hours agoprevJust adding to the chorus here: I moved from the US to the UK and like any immigrant anywhere I had to fill out a lot of forms. Especially during covid, there was seemingly always a new form to fill. The Gov.uk forms are literally the most straightforward and usable internet forms I&#x27;ve ever used. As close to perfect as you can get. reply notpushkin 18 hours agoprevIf anybody wants to try figure out how to run this...Docker images: https:&#x2F;&#x2F;github.com&#x2F;notpushkin?tab=packages&tab=packages&q=go...Simple stub for the signon service (likely needs further modification): https:&#x2F;&#x2F;gitlab.com&#x2F;notpushkin&#x2F;stupidauth&#x2F;container_registryAnd the Docker Compose stack: https:&#x2F;&#x2F;gist.github.com&#x2F;notpushkin&#x2F;f174b52efc6285e6be30fb66b... (works with https:&#x2F;&#x2F;lunni.dev&#x2F; or Docker Swarm + Traefik)If you do manage to run it please ping me, I&#x27;m also interested in trying it out!—Edit: discusson on GitHub: https:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F;forms&#x2F;discussions&#x2F;106 reply mortallywounded 21 hours agoprevI was surprised to see a gov.uk page on progressive enhancement and their thoughts on it (https:&#x2F;&#x2F;www.gov.uk&#x2F;service-manual&#x2F;technology&#x2F;using-progressi...). I asked on HN yesterday if PE was dead and everyone seems to think it&#x27;s dead, and yet gov.uk gets lots of love.Maybe it&#x27;s not dead :)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37779408 reply mhitza 21 hours agoparentPlease refrain from talking in absolutes, when you got 3 comments on your question yesterday.Progressive enhancement is nice, and user friendly, and better UX overall. But when you get started with modern frontend stacks nowadays it&#x27;s out of the question. Whereas, I and others like me, that use a classical backend framework that spits out HTML might do a better job (but not always, due to time and budget). reply globular-toast 12 hours agoparentprevI&#x27;ve never heard this being called progressive enhancement before. I always thought it was just the obvious proper way to do things, but that people don&#x27;t do it out of laziness. It&#x27;s nice to know there is a name I can use to refer to it.I used to design sites like this explicitly in the mid-00s. I would explicitly test with no js and no CSS. I still aim to do it to this day, but it&#x27;s hard to get others to do it when most web devs are happy to throw shit at a wall and see what sticks. reply switch007 22 hours agoprevOne niggle I have is the departments’ over-use of forms (from my perspective) in employing the ‘landing page’ pattern.E.g. if you search ‘DVLA vehicle information’, you will land on this page https:&#x2F;&#x2F;www.gov.uk&#x2F;get-vehicle-information-from-dvla and you have to click ‘Start Now’ to get the page you actually wanted. The same is for logging in to HMRC Personal TaxI’d like the actual form I want on the same page reply imdsm 22 hours agoparentI can understand that, but I think it&#x27;s very subjective. For example, it&#x27;s an opportunity to explain what the form is, and give any other information (do you need the form? do you need something else?) before the option of, if you&#x27;re in the right place, click here to begin.I think ultimately, it works quite well. reply switch007 20 hours agorootparentI do see it from both sides, definitely. It’s just as a frequent user, it gets in the way. Once you understand what the form does, you don’t really need to be told every time. reply globular-toast 12 hours agorootparentCan&#x27;t you just bookmark the form itself? The example you linked seems to be a normal link to the form, I don&#x27;t think it&#x27;s posting anything? reply timblair 18 hours agoparentprevThis is actually an explicit decision, designed to maintain consistency of the user experience across GOV.UK services in terms of information architecture and content design. It&#x27;s not something that departments choose to do (or not), and is codified in the GOV.UK Service Manual: https:&#x2F;&#x2F;www.gov.uk&#x2F;service-manual&#x2F;technology&#x2F;get-a-domain-na... reply matthewcford 19 hours agoparentprevThis is so that search can work, they index service start pages so they have results for services that are hosted on other domains. There is also something about having a consistance UX, at least to the point of handoff to the service (which might not have been updated yet). The start pages also provide the user with guidance were say the service might be only avalible at certain times, or if you need documentation ready before you use it. reply londons_explore 20 hours agoparentprevThe fact the forms load so fast makes this less of a problem.If the form took 10 seconds to load after clicking &#x27;start now&#x27;, I&#x27;d be more frustrated. reply switch007 20 hours agorootparentDefinitely mitigates it. For me though it’s still an annoyance reply greo 22 hours agoprevComing from Japan which is notorious for having the worst digital experience, the UK&#x27;s gov.uk ecosystem is incredible reply Aeolun 21 hours agoparentJapan is so terrible because every service does it’s own thing. The absolute best I’ve seen was the national census, which seems to actually have a website not designed before the year 2000.But it’s still inconsistent with all other government services. reply imdsm 22 hours agoprevReally proud of what the gov.uk team are doing. Everything is clean, accessible, and predictable across the many different systems. A massive success I think. reply svilen_dobrev 20 hours agoprevif only this short \"manual on how to make maintainable-software\" below was a) studied and b) followed ... the software-world would be much-much better place. (and Avoiding the several-years-learning-500-pages-books-by-heart.. without ever understanding why those are what they are)https:&#x2F;&#x2F;www.gov.uk&#x2F;service-manual&#x2F;technology reply curtis3389 16 hours agoprev> We know this is not going to cover all routing needs though - in the future, we’d like to look at building branching (two separate sets of questions depending on the answer), and later down the line we might be able to expand our routing so you can add routes to more than one answer, and also routes based on a combination of answers.I&#x27;m very interested how they build a UI for branching. Communicating branching conditions visually and clearly without just handing the user a programming language is a hard problem. reply BOOSTERHIDROGEN 22 hours agoprevI would like a sharing session from the team behind. Would be awesome hear the thought process, their pain experience etc. reply jameshart 19 hours agoprevI wonder if they have given any thought to the possibility that if you’ve standardized forms, you could also expose all those services as APIs? reply mkaszkowiak 20 hours agoprevThis is good news, but aren&#x27;t well-phrased questions a strong suit of Gov.uk forms? Other government departments might not be familiar with proper guidelines for form creation. Has this issue been approached? (curious, as I&#x27;m not British) reply seabass-labrax 12 hours agoparentI&#x27;m British. I have no insider information about what the Government Digital Service do about other departments&#x27; use of their toolkit, but just as a citizen, I can tell you that the difference between the GDS sites and external ones is extremely stark.The passport application form[1], for instance, is smooth and well-designed, and the questions are well-written - a good example of the Government Digital Service&#x27;s excellent design and solid implementation. Perhaps the only downside is the rather disconcerting photograph evaluation tool that suggested to me that my photograph was &#x27;invalid&#x27; due to being &#x27;in black-and-white&#x27;, somehow missing my blue chequered shirt. The whole of the Gov.UK site loads very quickly for me, which is an additional benefit of the focus on accessibility. You can &#x27;view source&#x27; on your Web browser and see the very comprehensive metadata, both as JSON-LD and traditionaltags.The &#x27;Universal Credit service&#x27;[2] (the recent social welfare system), however, was seemingly not developed by the Government Digital Service, and it shows! It is still marked as &#x27;Beta&#x27; years after release, uses a shockingly insecure authentication for sensitive personal data, and has a video conferencing system that can&#x27;t show video. To top it all off, they very politely request feedback... but provide no feedback form.I think that illustrates well how easy it is for an excellent toolkit to be abused in the hands of the incompetent or the underfunded, not that the latter is likely to apply in this case[3]! I hope this provides some context related to your question.[1]: https:&#x2F;&#x2F;www.gov.uk&#x2F;apply-renew-passport[2]: https:&#x2F;&#x2F;www.universal-credit.service.gov.uk&#x2F;sign-in[3]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Universal_Credit#Implementatio... reply jameshart 19 hours agoparentprevThis is the double edged sword of making a standardized toolset like this available.It’s now easier than ever to make a government form!And, even when a process might be better delivered via a different mechanism… a form becomes a low friction way to do it.And a bad form might be worse than no form. reply colesantiago 22 hours agoprevI wish all websites were as good as GOV.UK&#x27;s, they should be taught in schools, colleges and computer science &#x2F; web courses as the gold standard in web design.No frills or silly scroll jacking animations plus javascript hogging contraptions that we see in almost all websites these days.This gives me hope. reply azangru 22 hours agoparent> No frills or silly scroll jacking animations plus javascript hogging contraptions that we see in almost all websites these days.Still the cookie warnings though :-( I&#x27;ve just visited on my phone the forms page linked in the title, and the first thing that greeted me was a full-screen page-blocking dialog with some cookie nonsense. You can&#x27;t interact with the contents of the page until you decide how you feel about cookies. reply LunaSea 21 hours agorootparentIt&#x27;s a legal requirement reply londons_explore 20 hours agorootparentBut the size and intrusiveness of the notification are not.At least it doesn&#x27;t reload the page or have a stupid spinner when you click accept. reply Teandw 21 hours agorootparentprevLegal requirement in the UK. No way around it. reply switch007 20 hours agorootparentOnly if you store non-essential cookies, as explained by the team themselves:> You can choose not to have a cookie banner if the service only sets essential or ‘strictly necessary’ cookies, as these do not need user consent.> However, you must tell users that you set essential cookies. You can do this with a cookies page — link to this page in the footer.https:&#x2F;&#x2F;design-system.service.gov.uk&#x2F;components&#x2F;cookie-banne... reply pjc50 21 hours agorootparentprevI would have hoped the government would be able to design a system that works only on \"technical necessity\" cookies and not anything more elaborate with regards to PII. reply bux93 21 hours agorootparentprevThe pop-up allows you to switch off certain functionality (statistics cookies). If that functionality wasn&#x27;t there in the first place, the pop-up would not be needed.Don&#x27;t shoot the messenger. reply dgb23 21 hours agorootparentprevEven if you don&#x27;t actually track users?> We use Google Analytics to measure how you use the website so we can improve it based on user needs. Google Analytics sets cookies that store anonymised information about how you got to the site, the blog pages you visit, how long you spend on each page and what you click on while you&#x27;re visiting the site. reply sofixa 21 hours agorootparentWhy would they not track users? They need to know how many users there are accessing from abroad (considering this is the UK which has many legitimate \"abroads\" like crown dependencies outside of the classic British citizens living outside of Britain), using what browsers and OSes, display sizes to know what they need to support. It would also be useful to know how much time users spend on the various pages, to know if some forms are super complex to fill out or what not. reply lambic 21 hours agorootparentSure, but why use google analytics? There are better trackers for this kind of thing that don&#x27;t need cookies and can be self-hosted. reply kamel3d 20 hours agorootparentCould you recommend some alternatives to Google Analytics? I am developing a plugin for Photoshop using UXP, and I have been unable to integrate it with GA. reply notpushkin 20 hours agorootparentPlausible seems like a fine choice for simple cases. It is oriented at websites, but you can send events directly to the API: https:&#x2F;&#x2F;plausible.io&#x2F;docs&#x2F;events-apiIt is self-hostable, too. https:&#x2F;&#x2F;github.com&#x2F;plausible&#x2F;hosting replyOctabrain 14 hours agoprevI have to admit, as a Spaniard that moved 7 years ago to the UK, that the government related sites are an absolute pleasure to work with. Taxes, information of any kind etc everything clear and straightforward. I take my hat off.PS: Does anyone know the stack they use? reply neillyons 12 hours agoparentgov.uk manages some of the content using Whitehall which looks like a custom CMS using Ruby on Rails https:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F;whitehallnhs.uk is built using Wagtail, a Django based CMS. reply FrustratedPers 14 hours agoparentprevEven the NHS website is so clean and accessible. I think every EU country should just adopt their format. reply adamretter 21 hours agoprevThis looks great :-) However reading the How it works section, it states:\"Each form needs an email address to be set for completed forms to be sent to when they’re submitted\"So... erm is an email Inbox needed for integration? - how very 1990!In addition to email, for use by developers in other UK GOV departments - surely HTTP PUT of an XML or JSON document to a user nominated URL (with provided auth token) would have been trivial to achieve? reply motogpjimbo 21 hours agoparentIt looks like this service is intended to replace the kind of random \"notify us of a missing manhole cover\" type forms that are found in their thousands on government websites. For those types of applications, emailing the form to a relevant mailbox is probably the correct thing to do, and in many cases it&#x27;s the way the existing forms already work. Only a small fraction of government services will have their own custom backend application supporting them. reply moritonal 21 hours agoparentprevI get the sentiment, but an email is just a standardised queue. What were you going to do after the HTTP PUT? My guess is it onto a queue. reply londons_explore 20 hours agorootparentIt&#x27;s a standardized queue with a lot of features too...You can set up filters and forwarding rules. It doesn&#x27;t require a programmer or special knowledge to do so.The queue can be viewed by one or many humans.Messages don&#x27;t have to be dealt with in-order.read&#x2F;unread state, stars, labels, drafts all allow construction of advanced workflows with no specialist knowledge.Sure, all these things can be done better with special software, but there is a massive benefit to something that all your existing untrained and probably-not-well-paid employees can set up themselves. reply pjc50 21 hours agoparentprevOld school HTML Forms don&#x27;t require an active backend. They can be a purely static site.> surely HTTP PUT of an XML or JSON document to a user nominated URLThis is the bit that&#x27;s more tricky than a static site. And then you need to do something with the data. reply petepete 20 hours agoparentprevThe main intent here is for non-technical folks to be able to replace the tens of thousands of low volume PDF forms, not for technical ones to use it while building actual services. reply globalise83 21 hours agoparentprevYou can optionally pass an onSubmit function that will return the fax number that the form should be submitted to after printing. reply kamel3d 21 hours agoparentprevit is really cool but at the same time I can not stop smiling when the governement is telling you of about the best practices how to use web technologies, it is just funny reply creativenolo 14 hours agoprevI had to fill out a companies legal questionnaires and forms. The company had pinched the gov.uk format. It was such a relief to find a company using something familiar and well thought out instead of some fancy survey form or email. reply ricardobayes 19 hours agoprevI wish my country invested more into IT, most of the sites are outright broken or even lying to you - saying there are no available appointments online, but if you call up, you can book for next day even. reply RobotToaster 22 hours agoprevseems to be mostly open source too https:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F;forms&#x2F;wiki reply yaseer 14 hours agoprevGov.uk is probably the greatest thing our government has achieved for quite a while.That&#x27;s not hyperbole. reply monkeydust 22 hours agoprevOn the surface looks like a great example of inner sourcing. reply seabass-labrax 12 hours agoparentIt&#x27;s actually full open source (MIT licence): https:&#x2F;&#x2F;github.com&#x2F;alphagov&#x2F; reply kennydude 22 hours agoprevThis is fantastic to see and should hopefully reduce the cost massively for building out, what is effectively forms, for other government services! reply thunkshift1 16 hours agoprevThis is basically a govt created turbo tax tool but for every govt form ever.. nice. reply peter_retief 22 hours agoprevTheir forms are excellent, I completed my British citizenship effortlessly, all online. reply nly 21 hours agoparentMy condolences reply peter_retief 20 hours agorootparentHaha it is not that bad, South Africa is not doing that well either. reply EToS 18 hours agoprevIts a great example of how to use design systems reply dgroshev 10 hours agoprev [–] If you want to peek behind the curtain, \"Digital Transformation at Scale: Why the Strategy Is Delivery\" by Andrew Greenway et al [1] is full of advice and background on what it takes to launch and operate something like GDS.Something that fascinated me: how they were planning the departure of GDS leadership years in advance. GDS had to push changes through, which means making enemies, which means eventually being squeezed out. So they just assumed that will happen and adjusted organisational structures, making sure there will be new leaders in place. Just incredible level of professionalism.[1]: https:&#x2F;&#x2F;www.amazon.co.uk&#x2F;Digital-Transformation-Scale-Strate... replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The article compliments the user-friendly interface and design of GOV.UK, while also shedding light on potential privacy concerns and dependency on external platforms.",
      "The piece also reflects differing views on the appeal of government technology jobs and the efficiency of government systems.",
      "It emphasizes the advantages of the UK government's digital signature system and features of the gov.uk website, suggesting a requirement for improved guidelines for government forms."
    ],
    "points": 339,
    "commentCount": 177,
    "retryCount": 0,
    "time": 1696589675
  },
  {
    "id": 37792690,
    "title": "Postman update removes all your stuff if you refuse to create account",
    "originLink": "https://news.ycombinator.com/item?id=37792690",
    "originBody": "I have been using postman offline without an account for a long time. Today when I opened the program it asked me to create an account. When I declined, it wiped all my collections and everything else.All I have is a &#x27;history&#x27; to work with and try to piece back together all the variables and collections that I had setup.I relented and created an account, but it did not recover anything. Beware!Update: I was able to manually import&#x2F;restore using a backup I found in ~&#x2F;.config&#x2F;Postman but I have no trust for continued use of this tool. Any alternatives that I can migrate to?",
    "commentLink": "https://news.ycombinator.com/item?id=37792690",
    "commentBody": "Postman update removes all your stuff if you refuse to create accountHacker NewspastloginPostman update removes all your stuff if you refuse to create account 314 points by drunner 17 hours ago| hidepastfavorite150 comments I have been using postman offline without an account for a long time. Today when I opened the program it asked me to create an account. When I declined, it wiped all my collections and everything else.All I have is a &#x27;history&#x27; to work with and try to piece back together all the variables and collections that I had setup.I relented and created an account, but it did not recover anything. Beware!Update: I was able to manually import&#x2F;restore using a backup I found in ~&#x2F;.config&#x2F;Postman but I have no trust for continued use of this tool. Any alternatives that I can migrate to? mtmail 17 hours agoSo they quickly followed what their competitor Insomnia did recently https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37680126Related \"Alternatives to Insomnia?\" https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37691914 and https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37725326 reply enraged_camel 15 hours agoparentInsomnia doesn’t wipe out your stuff if you don’t create an account though. reply makestuff 14 hours agorootparentIf you updated to v8 and missed the one small text link to export your data before creating an account, then all of your data was gone. Fortunately you could go to Github and download an old version.If you created an account all of the data was still there. By default the \"scratchpad\" that did not require an account would not show anything. reply isbvhodnvemrwvn 14 hours agorootparentprevPostman doesn&#x27;t either, but it doesn&#x27;t tell you where the backup is. Same deceptive shite. reply dannydainton 13 hours agorootparentYour Scratch Pad data is safe and accessible. It can be Migrated to a new Workspace, once you create an account, using the &#x27;Cog Icon > Settings > Data > Migrate data&#x27; menu option.Alternatively, it can be Exported from the Lightweight API Client(signed out version) using the &#x27;Cog Icon > Settings > Data > Export data&#x27; menu options. reply Two4 6 hours agorootparentI&#x27;m assuming you work for Postman. I hope you know that because of this, as well as the account requirement, other REST tools are going to eat your lunch. I don&#x27;t think this was a good move. reply mrguyorama 14 hours agorootparentprevPlenty of users reported that updating, being prompted to create an account, and then refusing denied them access to their requests. reply 12345hn6789 8 hours agorootparentprevIt effectively does. You can&#x27;t access it on the latest version without an account. So either downgrade or make an account. reply richbell 15 hours agoparentprevPostman did it first, unless I&#x27;m missing something. reply isbvhodnvemrwvn 14 hours agorootparentPostman is rolling out updates over time, for many people they only saw the changes now, a couple weeks after the roll-out started. reply skeeter2020 15 hours agorootparentprevyep, Insomnia was the alternative to Postman, now the cycle continues... reply whaleofatw2022 10 hours agorootparentWhich is kinda interesting, in that I know folks who started using Insomnia because postman started enshittification first...Sad Insomnia made it a race reply pests 15 hours agoprevThere are some extensions for VSCode that let you define your requests in a text file and has ways to run the file and show the data.Here&#x27;s one I just found: https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=humao.re...Syntax looks like: GET https:&#x2F;&#x2F;example.com&#x2F;comments&#x2F;1 HTTP&#x2F;1.1 ### GET https:&#x2F;&#x2F;example.com&#x2F;topics&#x2F;1 HTTP&#x2F;1.1 ### POST https:&#x2F;&#x2F;example.com&#x2F;comments HTTP&#x2F;1.1 content-type: application&#x2F;json { \"name\": \"sample\", \"time\": \"Wed, 21 Oct 2015 18:27:50 GMT\" } reply S04dKHzrKT 15 hours agoparentJetbrains IDEs also have builtin support for HTTP files.https:&#x2F;&#x2F;blog.jetbrains.com&#x2F;idea&#x2F;2023&#x2F;10&#x2F;intellij-idea-2023-3...https:&#x2F;&#x2F;www.jetbrains.com&#x2F;help&#x2F;idea&#x2F;exploring-http-syntax.ht... reply e-master 15 hours agoparentprevI use it too - it’s excellent, I’d think most developers don’t need more than this. reply progre 14 hours agorootparentYep, me to. Since it&#x27;s just textfiles I can have them checked into git and share them. Credentials stays in a separate environments file (not checked in). I&#x27;m pretty happy with this setup. reply skeeter2020 15 hours agoparentprevI use the VS Code REST extension a lot but it does lack some of the aspects that make Postman easier for teams and larger projects. It&#x27;s super easy to define a \"collection\" as an .http page for smaller and one-off needs though. reply Octabrain 14 hours agoparentprevI use this one for tests on microservices endpoints. Very good at least for my use case. I recommend it. reply dzhiurgis 7 hours agoparentprevIs it much better over bash file and curl? reply pests 5 hours agorootparentIt supports curl inside as well as its custom syntax so this provides the same thing. reply hanniabu 14 hours agoparentprevAnybody know of one for sublime? reply leosanchez 14 hours agorootparentI use hurl[0][0]https:&#x2F;&#x2F;hurl.dev&#x2F;docs&#x2F;tutorial&#x2F;your-first-hurl-file.html reply blahyawnblah 15 hours agoprevI&#x27;ve really been enjoying HTTPie: https:&#x2F;&#x2F;httpie.io&#x2F;Postman has long been too bloated to be useful. reply eddd-ddde 15 hours agoparentOn windows I even got to enjoy using Invoke-WebRequest directly. Extremely useful since powershell has structured output and input. reply kritr 14 hours agorootparentI also found it surprisingly how pleasant this was. For all Powershell’s quirks, this is one of those features that just makes sense to me. reply weinzierl 14 hours agoparentprevI almost ignored HTTPie as a Postman alternative because I thought it was CLI only but learned that it has a GUI now. Unfortunately the GUI seems to be proprietary.Also we were looking for HTTP&#x2F;2 support which neither Postman not HTTPie have and found xh which is a HTTPie clone in Rust. reply chasd00 14 hours agoparentprevi really like httpie, i didn&#x27;t know they had an application coming out. This is good stuff. reply weinzierl 14 hours agorootparentThe GUI is not under an open source license. reply omneity 12 hours agorootparentI wonder what it is about API client GUIs that warrants such cut-throat competition and practices.. reply pjmlp 15 hours agoprevYes, it happened to me as well.Fortunately I regularly export the collections that still matter.Now I am no longer a Postman user, as due to NDA&#x27;s we aren&#x27;t allowed to store project data on them.Paying was never an issue, not having a secure alternative is what killed it for us. reply isbvhodnvemrwvn 16 hours agoprevI have found Bruno (https:&#x2F;&#x2F;github.com&#x2F;usebruno&#x2F;bruno) to be a decent basic alternative with a nice bonus of being version control friendly, keep in mind that it&#x27;s fresh and relatively unpolished though - for instance it doesn&#x27;t ask you to save changes before closing the app. reply redox99 15 hours agoparentThis one is free from VC funding and promises to stay away from it. So it should not suffer from enshittification.See https:&#x2F;&#x2F;github.com&#x2F;usebruno&#x2F;bruno&#x2F;discussions&#x2F;269 reply isbvhodnvemrwvn 14 hours agorootparentThe one thing I&#x27;m afraid of is that it&#x27;s a single maintainer project, and while they are active now, I&#x27;m not sure how this is going to fare in a few months or so. reply toomuchtodo 16 hours agoparentprevhttps:&#x2F;&#x2F;www.usebruno.com&#x2F;Previous: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37701803 reply CommonGuy 15 hours agoprevAs one of the creators, I can recommmend https:&#x2F;&#x2F;kreya.app. It is not open source (like Postman), but has a strong focus on privacy and also stores the data locally.As it has more powerful features (IMO) than most alternatives listed here, I am a little disappointed that it isn&#x27;t mentioned more often. reply hummusFiend 15 hours agoparentKreya is the only alternative I&#x27;ve used that prioritizes gRPC support (along with REST). Regardless of source availability, thank you for creating this! reply CommonGuy 14 hours agorootparentThanks for the kind words! reply dannydainton 13 hours agorootparentprevThere&#x27;s also gRPC support in Postman&#x27;s signed out version. reply SamuelAdams 11 hours agoparentprevAny chance this can be made available via homebrew? Also, are there telemetry settings I can configure? I frequently work in HIPAA and DoD environments, so the less telemetry tools send the happier those sysadmins are. reply CommonGuy 3 hours agorootparentHomebrew \"support\" (and other package managers) is planned.Telemetry is opt-out and anonymous. More about what is collected and how to disable here: https:&#x2F;&#x2F;kreya.app&#x2F;docs&#x2F;telemetry&#x2F; reply helloanoop 10 hours agoprevTry Bruno - https:&#x2F;&#x2F;github.com&#x2F;usebruno&#x2F;bruno- Free and Opensource IDE for exploring and testing APIs- It is lightweight with MIT license- Bruno stores your collections directly in a folder on your filesystem- Use git for collaboration- No cloud sync. Fully offline.PS: I am the creator of this project reply helloanoop 9 hours agoparentIt&#x27;s like the Netflix series Dark. It&#x27;s a cycle.Start API ClientTractionVC FundingBloatwareDeprecate ScratchpadDelete ScratchpadBruno will put an end to this. Honestly, I don&#x27;t care if I end up making little money from Bruno. This shit has to stop. An API Client need not be VC funded.It&#x27;s been a decade now. 10yrs. reply coldtrait 4 hours agoparentprevIs there a way to use an interceptor on this?With postman when I could use their interceptor extension on the browser, that would transfer cookies (from when I was logged into an app that was running locally) onto any of postman&#x27;s requests. That was very convenient. reply user3939382 15 hours agoprevHighly recommend the HTTP client in the JetBrains IDEs. I looked carefully at the standalones in this category and IMHO it’s the best. Text based so you can seamlessly manage everything with your repo, with automatic features built in from parsing the text. reply pletnes 14 hours agoparentYes! Postman is git-hostile i.e developer unfriendly. reply Jaygles 15 hours agoprevAfter the whiffs of enshittification caught my nose I did some research and switched over to Insomnia. I don’t make use of any advanced features, just a pre request authentication call that was a little bit of a pain to set up. But it’s working exactly how I was using postman so it’s a suitable replacement for me reply CommonGuy 15 hours agoparentDidn&#x27;t they just push a similar update where they require an account? And pushed all data into their cloud sync without asking? reply Jaygles 15 hours agorootparentWhen I switched over they made it clear they were getting rid of offline mode. So I said whiffs but at that point there was a turd halfway up my nose reply baq 15 hours agoprevAm I crazy for using curl and editing the shell cmdline with vim when I need to work with lots of headers? reply petepete 14 hours agoparentNo, but unless portability is a concern or you&#x27;re massively familiar with curl, you might want to consider xh. It&#x27;s much more intuitive.https:&#x2F;&#x2F;github.com&#x2F;ducaale&#x2F;xh reply baq 14 hours agorootparentI’m not a curl pro but devtools ‘copy as curl’ gets me 95% there most of the time.That said, thanks! Didn’t know about this. Definitely adding to the toolbox. reply PufPufPuf 12 hours agorootparentprevxh is based on HTTPie CLI, which I would recommend over xh since it has better docs and more features. reply weinzierl 14 hours agoparentprevNo, I use curl similarly and a lot. Where I find Postman convenient is when using it against services that use OAuth2. You authenticate once, it fetches the token and you are good to go. Could I script this with curl? Sure. Do I want to? Nah. reply joe8756438 15 hours agoprevFor the emacs users: restclient.elIt’s excellent. Doesn’t have server mocking AFAIK, :shrug: reply imp0cat 14 hours agoparentAnother vote for spacemacs + restclient:https:&#x2F;&#x2F;develop.spacemacs.org&#x2F;layers&#x2F;+tools&#x2F;restclient&#x2F;READM... reply trey-jones 15 hours agoparentprevI really like restclient - also really makes sense for persisting tests in this manner to source control. Not that anybody else on your team will know how to use it... reply taesu 15 hours agoprevThis is how you kill a product. Ill be jumping ship too reply funvill 14 hours agoprevI been using &#x27;Advanced Rest Client&#x27; (ARC) https:&#x2F;&#x2F;install.advancedrestclient.com&#x2F;No accounts required, offline, open source, A little bloated using electron but its multiplatform and a desktop client. reply jphilip 14 hours agoprevI remember encountering Postman years ago when it was a chrome app where I&#x27;d fill some fields and use it against a server absent a frontend to prototype&#x2F;test.I never understood what&#x27;s the improvement from having a headless client written in Python using requests or something and the data in source-code, kept versioned? I figure requests or similar libraries have something with sessions and cookies that allows me to issue requests against an active or mock server. This way I can specify the API, data to send each endpoints and possibly also use these snippets in testing.I have usually taken this Python route when I&#x27;ve wanted something nicer (this is subjective) in comparison to cURL.Can someone experienced here tell me the value add over something like this with Postman? reply 4lejandrito 12 hours agoprevI started building my own 100% local tool in response to the current situation with postman and insomnia:https:&#x2F;&#x2F;github.com&#x2F;4lejandrito&#x2F;fetchbookI really liked Bruno (https:&#x2F;&#x2F;github.com&#x2F;usebruno&#x2F;bruno) but I prefer the flexibility of a real language like typescript and the Request Web API standard. reply jicea 11 hours agoprevYou can give a try to Hurl [1], a CLI open source tool, based on plain text and curl. It allows you to run and test Rest&#x2F;SOAP&#x2F;GraphQL APIs (I&#x27;m one of the maintainer).There is no GUI, so Hurl is not a drop-in Postman replacement, but it has nice features: it can be easily integrated in CI&#x2F;CD, it&#x27;s fast and it&#x27;s powered by curl!A detail: Hurl is given to the community by Orange, a French telco. Orange is not in the dev business, so it should remain free, open source, analytics free for a long time. In any case, you can easily convert Hurl files to JSON [2] in order to switch to another tool or not being trapped in a single provider...[1]: https:&#x2F;&#x2F;hurl.dev[2]: https:&#x2F;&#x2F;hurl.dev&#x2F;docs&#x2F;frequently-asked-questions.html#how-ca... reply SoftTalker 15 hours agoprevDo you use emacs? Have a look at https:&#x2F;&#x2F;github.com&#x2F;pashky&#x2F;restclient.el or similar. reply tsuru 14 hours agoparentOr org+verb https:&#x2F;&#x2F;github.com&#x2F;federicotdn&#x2F;verb reply SoftTalker 13 hours agorootparentThat does look a bit more recent. reply AdmiralAsshat 14 hours agoprevIs this all stuff that you had kept in your Scratchpad? I think Postman had been warning users for months that Scratchpad would be going away, and that you should migrate everything to a workspace.I&#x27;m not saying the decision is right; personally I much preferred the scratch, because it didn&#x27;t require a freaking network request every time I want to look at my API collections. I&#x27;m just saying, this didn&#x27;t come out of nowhere. reply moochee 9 hours agoprevI’d like to recommend Insomnium, a 100% local-first Insomnia fork. https:&#x2F;&#x2F;archgpt.dev&#x2F;insomnium reply wg0 14 hours agoprevBruno is great. Offline. Open source. reply eshack94 15 hours agoprevWhat a joke. Great reason to find a replacement tool. reply isodev 14 hours agoprevIf you’re on macOS, my preferred tool is Paw&#x2F;Rapid API https:&#x2F;&#x2F;paw.cloud&#x2F; reply aPoCoMiLogin 14 hours agoparentyeah, this one is the only thing that i&#x27;m missing after migration to linux box. the extensions and ability to write own extensions is very powerful, the speed and native UI were very welcomed, as postman and other electron based tools are just way too heavy for me. reply isodev 13 hours agorootparentIndeed, it&#x27;s very well-made and a “proper” macOS app—shortcuts, window management, sleeping in the dock and everything.My favourite aspect is that it supports both cloud and local projects. Local projects are single binary files which can be synced with iCloud&#x2F;OneDrive&#x2F;..., so it&#x27;s really quite flexible. reply hbn 14 hours agoprevIs that what happened? I DO have an account (begrudgingly made because it doesn&#x27;t just let you do a JSON export of your collections, you have to send it to the cloud and then download it for some baffling reason) and last time I opened it all of my environment variable values were wiped.I&#x27;ve been wanting to get off Postman for a while. It&#x27;s so clunky these days, and they&#x27;re shoving way too much shit in it that I don&#x27;t care about. reply james-revisoai 17 hours agoprevThis happened to me 2 years ago, I think it has always been a bit of an issue. reply masukomi 15 hours agoprevanother alternative: RapidAPI https:&#x2F;&#x2F;rapidapi.com&#x2F;it&#x27;s a good api client, and it&#x27;s free for individual use and they have some sort of nifty marketplace integration catalog...thing with remote API servers that makes it easy to find and try API services that offer data &#x2F; functionality you want to connect to. reply gkedzierski 14 hours agoparentIt was great before it got acquired, (and was called Paw back then) now the product development has virtually stopped. reply kstrauser 14 hours agoparentprevI’ve used that for years, from back when it was the paid Paw app, and I’ve been happy with it. reply cellis 15 hours agoprevPaw (now RapidAPI) is a very good alternative, though I can&#x27;t say they wont be under the same capitalist pressures as Postman. I paid $50, one time.https:&#x2F;&#x2F;paw.cloud&#x2F;Edit: To be clear it&#x27;s an app (downloadable client), despite the url. reply jpalawaga 15 hours agoparentI&#x27;m not sure why you&#x27;re downvoted. I still use paw&#x2F;rapidapi and I think it&#x27;s great. Maybe downvoters can explain. reply aPoCoMiLogin 14 hours agoparentprevthe mac client probably wont, as they were already bought by rapidapi.com and made web-based client that looks like PAW but has the same issues as other web-based solution reply vorticalbox 14 hours agoprevIf you use vs code you can use thunder[0][0] https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=rangav.v... reply robertlagrant 14 hours agoparentNot open source, though? reply KomoD 14 hours agoprevNot very surprised, Postman has continued to get more bloated and pushy with accounts, I ended up just moving to Insomnia after using Postman for many many years.Edit: turns out Insomnia has enshittified too reply maniflames 15 hours agoprevI’ve been using https:&#x2F;&#x2F;insomnia.rest&#x2F; and it has everything you need and does not require you to log in reply isbvhodnvemrwvn 15 hours agoparentSorry, but they pulled a Postman already:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37680126No reason to trust them at all at this point. reply stronglikedan 15 hours agorootparentWeird. Mine doesn&#x27;t, and it&#x27;s been 8 days since that post. I even checked for updates, and I&#x27;m up to date. Maybe they reverted their bone head move? (I don&#x27;t use it daily)EDIT: Maybe they did. See last comment here: https:&#x2F;&#x2F;github.com&#x2F;Kong&#x2F;insomnia&#x2F;discussions&#x2F;6590 reply stronglikedan 15 hours agoparentprevI lost everything in a update with them too. And not a create-account update. Just a regular update one day, and poof gone. reply vorpalhex 15 hours agoprevPostWoman (now called Hopscotch) is a foss clone of (possibly an older version) Postman if you want a 1:1.https:&#x2F;&#x2F;hoppscotch.io&#x2F;If you want \"curl but friendly\", I like httpie - https:&#x2F;&#x2F;httpie.io&#x2F;cli reply mjepronk 15 hours agoprevHttpyac, to install the VS Code extension, just do:ext install anweber.vscode-httpyac reply some_guy_in_ca 13 hours agoparentI love HttpYac. I use it all day every day.I stopped using Postman years ago because it got too bloated an \"enterprisy\".Also the fact that it syncs all my stuff to the cloud across many consulting clients is a no go. Passwords and other stuff means it is a target for hackers.Postman is a great product don&#x27;t get me wrong but my specific use case are around HTTP testing and I want to check everything into version control reply dannydainton 13 hours agoprevYour Scratch Pad data is safe and accessible.It can be Migrated to a new Workspace, once you create an account, using the &#x27;Cog Icon > Settings > Data > Migrate data&#x27; menu option.Alternatively, it can be Exported from the Lightweight API Client(signed out version) using the &#x27;Cog Icon > Settings > Data > Export data&#x27; menu options.You don&#x27;t need to go searching for the data in your file systems. reply Veen 13 hours agoparentTop notch developer experience there, Danny. Well done. reply dannydainton 13 hours agorootparentUmm, you&#x27;re welcome.I&#x27;m just sharing information that the OP isn&#x27;t actually true and no data is removed. reply zikang 14 hours agoprevCheck out https:&#x2F;&#x2F;recipeui.com! It’s an open source Postman alternative with TypeScript and autocomplete. reply pirsquare 14 hours agoprevWe need a free Postman replacement tool with Photopea business model that is driven by ads, not VC-funds. reply david422 15 hours agoprevSame. Quite a surprise. I switched to IntelliJ http requests and am seeing how that does for me. reply ok_dad 15 hours agoprevLearn and use curl, then you won’t have any issues like this. You can make some scripts in Python or something, too.I say this because the last three tools I used for this all got shitty (postman, insomnia, and thunder client). reply isbvhodnvemrwvn 15 hours agoparentI would rather cycle thorough tools than deal with piss poor user experience of something like that. reply rpdillon 13 hours agorootparentOne nice thing about FOSS CLI tools is they&#x27;re easy to script. While it&#x27;s pretty tough to script general cases, I often find my workflows orbit around a handful of commands, and scripting often can improve the UX by a large margin. It does require tinkering a bit though. reply polotics 14 hours agorootparentprevSeriously, python with the requests lib in a jupyter notebook is always a nicer user experience than any REST API GUI, most importantly once it&#x27;s grown a bit. reply great_cormorant 15 hours agoparentprevI really like the built-in `.http` file clients in IntelliJ products. You can paste from CURL and copy to CURL, so interop with CLI commands is very easy.https:&#x2F;&#x2F;www.jetbrains.com&#x2F;help&#x2F;idea&#x2F;exploring-http-syntax.ht... reply mplewis 15 hours agoparentprevCurl is not sufficient for rapid experimentation against an API. reply worksonmine 15 hours agorootparentDepends how comfortable you are with curl and your workflow. I&#x27;m much more productive using curl vs any GUI you give me. Still have OpenAPI specs in my projects but curl is much faster initially. reply isbvhodnvemrwvn 15 hours agorootparentIt falls apart instantly when you need to pass data from one endpoint to another or add any sort of logic like filtering through data - so any time you have non-trivial workloads where you don&#x27;t want to spend half your time fighting against jq or shell. reply ok_dad 14 hours agorootparentYou don’t have to fight tools if you learn them, but I understand— as a fellow programmer— that you don’t always have time to learn them. However, it’s pretty easy to use pipes and tools like jq to do complex stuff. reply isbvhodnvemrwvn 1 hour agorootparentWhile jq is powerful and I use it in scripts, it&#x27;s one of the least intuitive languages I use, to the point I have to look up basically everything non-trivial. reply worksonmine 13 hours agorootparentprev> pass data from one endpoint to another`curl ... > out.json` then `curl ... -d out.json`. Wrap it in a shell script for quick iterations.> filtering through data`curl ...jqgrep`. I don&#x27;t know of any tool that will find what I&#x27;m after faster than the shell.For bootstrapping and quick experiments curl is right there at my fingertips, no need to spin up an electron app, make a bunch of definitions and all that. When I want something more usable OpenAPI serves as stateful and interactive test environment and documentation at the same time.I do agree curl can get a little verbose but create an alias: `alias jc=&#x27;curl -H Content-Type: application&#x2F;json` and using it is as simple as `jc $URL` for GET or `jc -X POST -d &#x27;{ ... }&#x27; $URL` for the rest of the methods.I really recommend getting comfortable in the shell, it&#x27;s amazing how productive it can be and becoming a bit of a lost art these days. All the tools are composable and working together it&#x27;s so zen. reply kyriakos 5 hours agoparentprevWhat&#x27;s wrong with thunder client? reply ok_dad 3 hours agorootparentWeird pricing BS they just started. reply kyriakos 2 hours agorootparentWow, just visited the pricing page https:&#x2F;&#x2F;www.thunderclient.com&#x2F;pricingHadn&#x27;t noticed this change (I am not a heavy user) but it does look like its heading the postman way. I moved from Postman to Insomnia to Thunder Client. Time for yet another alternative. reply lowercased 15 hours agoparentprevfor individual users, i&#x27;ve not quite got the appeal of postman.in larger teams, I did see groups of people collaboratively creating various urls&#x2F;scripts&#x2F;tests, and putting some docs with them, to help with the dev and testing (mostly qa&#x2F;test folks). that was, imo, a relatively legitimate use for a full tool like postman. reply Eumenes 15 hours agoparentprevBut is there a VS Code extension for curl?!!? Does it work with ChatGPT? reply lghh 15 hours agorootparentI think you&#x27;re joking, but I actually want to know these things when adopting tools now to the extent that it&#x27;s applicable. reply Eumenes 13 hours agorootparentim just making fun of web devs reply taesu 15 hours agoparentprevNope reply floucky 15 hours agoprevI&#x27;m sure it&#x27;s a bug, they have nothing to gain from it, especially if there&#x27;s no warning about this.It&#x27;s also a good reminder for everyone to back up everything! reply isbvhodnvemrwvn 15 hours agoparentIt&#x27;s not a bug to release a version which removed a massive chunk of functionality. It&#x27;s intentionally fucking over their users who are not willing to create an account. reply mrguyorama 14 hours agoprevFYI some of our people internally use Jmeter. https:&#x2F;&#x2F;jmeter.apache.org&#x2F;It&#x27;s not flashy so it probably wont get the standard \"we are going to milk you for data\" plan reply isbvhodnvemrwvn 14 hours agoparentThe problem then is that you have to use jmeter, it&#x27;s a great example of early 2000s java desktop app user experience. reply procflora 9 hours agorootparentAnd if JMeter just isn&#x27;t quite doing it for you, turn the dial back another few years and experience the joy of the MDI GUI provided by SoapUI. You too can experience the thrills of getting to tweak JVM memory options so it doesn&#x27;t crash when you try to load a particularly large and unwieldly industry-specific WSDL for an interface standard that undergirds major national infrastructure.Oh and, it actually does do OpenAPI specs for REST and even mock services and all that, so I&#x27;m delighted to share that it&#x27;s actually relevant to this post! :^) What are you waiting for? reply iLoveOncall 15 hours agoprev> Any alternatives that I can migrate to?If it works for your use case: writing integration tests.I used Postman in the past but I never really got the point of \"storing\" queries beyond the history.I think if you have that need it means it&#x27;s time to write a frontend to call your endpoints, or use integration tests. reply kstrauser 14 hours agoparentI’ve used alternatives to explore under-documented APIs interactively and suss out their behavior. Then I could use the app’s codegen to turn the query I’d manually crafted into my chosen language’s code.You can do all that directly in the language, of course, but by the time you go through the trouble of pretty printing the output, parametrizing the input, etc, you’ve reimplemented a less ergonomic version of Postman-and-similar.(Not saying you’re wrong for doing it your way, but explaining why others might choose a different approach.) reply pipeline_peak 9 hours agoprevI can’t stand Postman, it’s just clunky in a distinctive Electron-powered way I can’t explain. I don’t get this new wave of dev tools that try to bypass programming but feel more complicated than just programming. The environment variable setting is weird, doesn’t handle &#x2F;r&#x2F;n without a plugin.Anytime I want to automate or do something slightly more complex than run a request it becomes a homework assignment.I’d much rather just use Python and work up a small library. Everyone has their own preferences in the end and it’s much less painful doing it my own way. reply tonfreed 10 hours agoprevCaught a workmate in my team out as well. We can&#x27;t create accounts and keep it all in the cloud at our job, so we had to find an installer for an older version.Absolutely scummy behaviour reply worksonmine 12 hours agoprevI&#x27;m surprised OpenAPI&#x2F;Swagger hasn&#x27;t been suggested. Define either as yaml or inline JsDoc comments if you&#x27;re working in js&#x2F;ts. I thought it was more popular than postman but I must be living in a bubble.Local, open source, versioned and can serve as interactive documentation for users. Never tried it personally but it can even generate code from the specs. reply isbvhodnvemrwvn 1 hour agoparentMy main use case for postman like tools is to get me into the middle of a workflow to reproduce some sort of a scenario. Stateless tools just don&#x27;t do it, as I need to spend a long time copying things around. reply liyasthomas 15 hours agoprevWe’re building an open-source Postman alternative.1.6m+ users, 100k+ monthly active users, 55k+ GitHub stars.Web app: https:&#x2F;&#x2F;hoppscotch.io GitHub: https:&#x2F;&#x2F;github.com&#x2F;hoppscotch&#x2F;hoppscotch reply redox99 15 hours agoparentDisappointing that there isn&#x27;t a standalone program like Postman. I don&#x27;t want to install an extension in my browser to handle CORS. reply robertlagrant 14 hours agorootparentDidn&#x27;t Postman start as an extension? reply shadowgovt 15 hours agorootparentprevWhat&#x27;s the issue with an extension? reply isbvhodnvemrwvn 14 hours agorootparentI don&#x27;t particularly enjoy a VC-fueled project having ability to intercept all my browser traffic to handle CORS. reply snazz 14 hours agorootparentHaving a dedicated browser profile is a good solution to this if you’re ever uncomfortable with a particular extension. reply lima 14 hours agorootparentprevRunning standalone binaries by a VC-fueled project on your host is even worse.I guess a separate quarantine browser profile is the best of both worlds? reply shadowgovt 14 hours agorootparentprevAh, I follow. I was confused because a small, open-source extension should be sufficient to handle sending test requests. Sounds like they&#x27;re doing something much bigger than that.POSTman started as an extension; hence my confusion. I was wondering if there was a technical issue I was unaware of. reply mortallywounded 15 hours agoparentprevIt&#x27;s a non-starter for me if it requires an extension. I also think it&#x27;s a matter of time before it goes the Insomnia&#x2F;Postman route. I&#x27;d love to be proven wrong though. reply petepete 14 hours agorootparentIt says on the page the the extension &#x27;enhances the experience &#x27; - it doesn&#x27;t look like a requirement. reply mortallywounded 9 hours agorootparentEnhances? Isn&#x27;t the point to override CORs because the browser will automatically block certain requests. Seems like a pretty critical feature unless all you have are GET requests. reply BoorishBears 15 hours agoparentprevBut you raised VC funding right?Insomnia was an alternative to Postman, raised VC funds, eventually needed to justify that, and suddenly accounts mattered more. They&#x27;re currently on the same trajectory.Insomnia is open source but just like OP experienced, a single update can do damage and it takes time for the community to react.Is this the same company that raised? If so, are you exempt from that? Have you figured out some monetization scheme for what is essentially a glorified curl UI that doesn&#x27;t incentivize account sign ups? reply ryandrake 14 hours agorootparentI wish tech product managers could get it through their skulls: creating and maintaining yet-another-account for yet-another-app is high friction and undesirable. If you&#x27;re going to give me an ultimatum where I need to either create an account or stop using the app. 99% of the time I&#x27;m just going to stop using your app. reply eduction 15 hours agorootparentprevIf it&#x27;s just a \"glorified curl UI\" what&#x27;s the problem? Just use curl, or build your own, if it&#x27;s so trivial.You are kicking the tires awfully hard for a solution to a problem you claim is easy. reply addicted 14 hours agorootparentThat’s actually what I do and did. I have a whole bunch of scripts that allow me to replicate a lot of what Postman did for me.The problem with these VC companies is that they enter the market with a whole bunch of lies and I was convinced that building on my ad hoc scripts wasn’t very useful since there were multiple alternatives including open source ones.It’s taken me a decade however to learn that if these projects are VC backed as opposed to having some sort of govt or heck, even a benevolent dictator, they will screw you.And while I might have learnt this lesson, which so much of the knowledge ecosystem also being filled with VC backed individuals (including this very forum) a whole another generation of potential OS developers will learn the lesson also too late.And that’s how Silicon Valley has built a massive eco system to suck money out of everything across the globe, especially open source, but not limited to it (taxis, restaurants, hoteling, everything…). reply isbvhodnvemrwvn 14 hours agorootparentprevI think it&#x27;s fair to criticize them given a fair number of alternatives in this thread (with their own shortcomings). It&#x27;s kind of silly to post something to hackernews and not expect criticism. reply BoorishBears 6 hours agorootparentprevYour defensiveness would be better justified if I was concerned about the curl wrapper... and not the VC firms seeking 10x returns attached to said wrapper reply bobobob420 15 hours agorootparentprevPostman is also open source lol. Unless its donation driven without funding its all going to be the same. reply isbvhodnvemrwvn 15 hours agorootparentIt&#x27;s not open source, only some of the components are. reply Firmwarrior 15 hours agorootparentprevCan&#x27;t someone just locally fork one of these apps and use it forever without updating it? What&#x27;s actually different about manually poking APIs from one week to the next? reply OJFord 14 hours agorootparentWell even curl has a high severity CVE pending announcement, updates aren&#x27;t always bad!https:&#x2F;&#x2F;twitter.com&#x2F;bagder&#x2F;status&#x2F;1709103920914526525 reply BoorishBears 15 hours agorootparentprevDid you read my comment? (Also Postman is not open source, it just has some open source pieces) reply _the_inflator 14 hours agoprev [–] I would really like to see Chrome offering an alternative to Postman. For me, it feels natural, to have everything in one place.What do others think? reply kbar13 14 hours agoparent [–] its funny because postman started out as a chrome extension reply baq 14 hours agorootparent [–] I checked out of postman for a few years. Color me confused in this thread until I figured that part out. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A user reported that using Postman offline without an account resulted in all their collections and settings being deleted upon declining to create an account when prompted.",
      "Despite creating an account subsequently, the wiped data did not recover, though the user managed to restore it manually from a backup in a specific location.",
      "This incident has led to a loss of trust in Postman from the user, who is now seeking alternative tools to transition towards."
    ],
    "commentSummary": [
      "The recent update to Postman, an API client tool, has sparked user frustration as it now demands the creation of an account, causing concerns about data loss.",
      "Users are exploring alternatives to Postman, which include tools like Insomnia, VSCode extensions, HTTPie, Bruno, Kreya, Paw/Rapid API, Hopscotch, and IntelliJ HTTP requests.",
      "A split emerges among these users with some favoring curl or command-line alternatives, while others argue for the convenience of GUI tools like Postman despite concerns about pricing and compatibility."
    ],
    "points": 314,
    "commentCount": 150,
    "retryCount": 0,
    "time": 1696608894
  },
  {
    "id": 37794379,
    "title": "23andMe says user data stolen in credential stuffing attack",
    "originLink": "https://www.bleepingcomputer.com/news/security/genetics-firm-23andme-says-user-data-stolen-in-credential-stuffing-attack/",
    "originBody": "NEWS DOWNLOADS VPNS VIRUS REMOVAL GUIDES TUTORIALS DEALS FORUMS MORE HomeNewsSecurityGenetics firm 23andMe says user data stolen in credential stuffing attack Genetics firm 23andMe says user data stolen in credential stuffing attack By Bill Toulas October 6, 2023 11:48 AM 2 23andMe has confirmed to BleepingComputer that it is aware of user data from its platform circulating on hacker forums and attributes the leak to a credential-stuffing attack. 23andMe is a U.S. biotechnology and genomics firm offering genetic testing services to customers who send a saliva sample to its labs and get back an ancestry and genetic predispositions report. Recently, a threat actor leaked samples of data that was allegedly stolen from a genetics firm and, a few days later, offered to sell data packs belonging to 23andMe customers. Initial leak of genetic data Source: BleepingComputer The initial data leak was limited, with the threat actor releasing 1 million lines of data for Ashkenazi people. However, on October 4, the threat actor offered to sell data profiles in bulk for $1-$10 per 23andMe account, depending on how many were purchased. Selling stolen genetic data profiles in bulk Source: BleepingComputer A 23andMe spokesperson confirmed the data is legitimate and told BleepingComputer that the threat actors used exposed credentials from other breaches to access 23andMe accounts and steal the sensitive data. \"We were made aware that certain 23andMe customer profile information was compiled through access to individual 23andMe.com accounts,\" stated 23andMe's spokesperson \"We do not have any indication at this time that there has been a data security incident within our systems.\" \"Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials.\" The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location. BleepingComputer has also learned that the number of accounts sold by the cybercriminal does not reflect the number of 23andMe accounts breached using exposed credentials. The compromised accounts had opted into the platform's 'DNA Relatives' feature, which allows users to find genetic relatives and connect with them. The threat actor accessed a small number of 23andMe accounts and then scraped the data of their DNA Relative matches, which shows how opting into a feature can have unexpected privacy consequences. 23andMe told BleepingComputer that the platform offers two-factor authentication as an additional account protection measure and encourages all users to enable it. Users should refrain from reusing passwords and consistently employ strong, distinct credentials for every online account they have. Related Articles: Dymocks Booksellers suffers data breach impacting 836k customers D.C. Board of Elections confirms voter data stolen in site hack MGM Resorts ransomware attack led to $100 million loss, data theft Sony confirms data breach impacting thousands in the U.S. BORN Ontario child registry data breach affects 3.4 million people 23ANDME CREDENTIAL STUFFING DATA BREACH DATA LEAK DNA GENETICS HACKER FORUM HEALTHCARE BILL TOULAS Bill Toulas is a tech writer and infosec news reporter with over a decade of experience working on various online publications, covering open-source, Linux, malware, data breach incidents, and hacks. PREVIOUS ARTICLE NEXT ARTICLE Comments rabidR04CH - 7 hours ago Congratulations, idiots. You willingly gave them your DNA even after we warned you this kind of thing would happen. rdiazjry2k - 4 hours ago Oh f off and stop blaming people for being so interested in their lineage and ancestral composition and makeup. It's such a fascinating and interesting subject and you can't fault people for being interested in it. Post a Comment Community Rules You need to login in order to post a comment Not a member yet? Register Now You may also like: POPULAR STORIES NSA and CISA reveal top 10 cybersecurity misconfigurations Exploits released for Linux flaw giving root on major distros LATEST DOWNLOADS Malwarebytes Anti-Malware Version: 4.6.3.282 5M+ DOWNLOADS Windows Repair (All In One) Version: 4.14.1 2M+ DOWNLOADS McAfee Consumer Products Removal tool Version: NA 437,794 DOWNLOADS AdwCleaner Version: 8.4.0.0 56M+ DOWNLOADS Everything Desktop Search Version: 1.4.1.1017 23,978 DOWNLOADS FOLLOW US: MAIN SECTIONS News VPN Buyer Guides Downloads Virus Removal Guides Tutorials Startup Database Uninstall Database Glossary COMMUNITY Forums Forum Rules Chat USEFUL RESOURCES Welcome Guide Sitemap COMPANY About BleepingComputer Contact Us Send us a Tip! Advertising Write for BleepingComputer Social & Feeds Changelog Terms of Use - Privacy Policy - Ethics Statement - Affiliate Disclosure Copyright @ 2003 - 2023 Bleeping Computer® LLC - All Rights Reserved",
    "commentLink": "https://news.ycombinator.com/item?id=37794379",
    "commentBody": "23andMe says user data stolen in credential stuffing attackHacker Newspastlogin23andMe says user data stolen in credential stuffing attack (bleepingcomputer.com) 287 points by nickthegreek 15 hours ago| hidepastfavorite256 comments xorcist 13 minutes agoOf course it could be massive credential stuffing. The problem is that an inside job would look completely identical. Or negligent security.If you sell your DNA profile to someone, they are free to give or sell it to someone else. At best that&#x27;s a breach of contract, but what are you going to do? A successful class action only changes the price retroactively.(I am told some people sell their DNA data at a negative price, which I suspect may be the same people who pay to have to have a remotely controlled microphone at home. That I don&#x27;t understand, and accept that I probably never will. But it doesn&#x27;t change the underlying premise and market dynamic. The above is still true.) reply valyala 5 minutes agoparentRemote-controlled microphone is embedded into every smartphone. This doesn&#x27;t prevent billions of people to buy and use them :) reply Urgo 13 hours agoprevUnless I&#x27;m reading this wrong all that happened was someone had an existing leaked database of emails&#x2F;passwords and then tried them on 23andme, and if they worked they took the data they could get. Yes, 23andme has some pretty extensive and personal data, but this attack could be done on literally any website. The issue is people re-used passwords, and also did not have 2fa enabled.So the database that is for sale is just a list of emails&#x2F;passwords from other breaches that worked on 23andme, along with the data that 23andme had on those users. Not exactly a 23andme breach. reply somsak2 8 hours agoparentEven if this is the case, 23andMe should have done better here. Why are you letting people log into an account from a brand-new IP with no additional verification? You have their email, you could have at least done 2FA with that. And as other commenters mentioned, CAPTCHA would have also made this slower &#x2F; more expensive. At my employer, we use both, and so it is not the case that this \"could be done on literally any website.\"For such a mature business (that is publicly-traded, no less!) it is shameful to allow credential stuffing on the scale of millions of accounts. reply codetrotter 7 hours agorootparent> Why are you letting people log into an account from a brand-new IP with no additional verification?Is that really feasible today? With widespread use of phones and laptops, most people probably have at least a handful of different IP addresses they regularly use (home WiFi, work WiFi, cellular connection) and then they randomly connect from new up addresses like those from libraries, coffee shops, commute, etcI think most “normal” apps and websites today allow any random IP to log in without jumping through extra hoops.Only companies with big budgets (Apple, Google, etc) make regular users jump through extra hoops.Banks, B2B have users that need extra hoops as well.But 23andMe. I would not expect them to take any extra steps. reply sfmike 6 hours agorootparentPlease don&#x27;t make this normal it&#x27;s absolutely tiresome to get codes for every single task reply Aachen 3 hours agorootparentOr include a setting for users that used a unique password.When, five to ten years ago, everyone started sending email conformations \"is this really you??\" when logging in with the correct username and password on the first try, I always contacted support if that can be turned off. I figured the only way they were going to know it&#x27;s a pain is if people complain. I have yet to learn of the first site where this is actually a choice...Come to think of it, why haven&#x27;t I made a Thunderbird plugin yet that recognises these emails and either sends the code to the browser or autotypes it. The credentials are filled in automatically, why not also their stupid email? Does this exist already? reply andylynch 2 hours agorootparentI think most sites doing this use SMS codes, and they works really well on mobile. If they are sending an email it’s more likely to be a magic likely with no password at all. reply Aachen 2 hours agorootparentYou don&#x27;t use twitter, github, amazon, spotify, steam, discord, etc.? Maybe that you can turn on SMS instead of email, but sending people emails for every login is the default for those.The only ones requiring an SMS for me are organisations with a bank license, which are obviously a minority of all the services out there.(Fwiw, I avoid all of the above besides Spotify, but a lot of code happens to be on github, audio books are invariably ~3x cheaper on amazon compared to buying from the publisher directly, many game developers insist that you let steam take a cut and don&#x27;t let you buy it from them directly... that&#x27;s how come I know these things all insist on sending emails.) reply dash2 1 hour agorootparentprev23andme isn&#x27;t just any small company. They process people&#x27;s DNA! It&#x27;s about as personal information as you can get. And the stolen data included information about people&#x27;s genetic ancestry. They should have very high-class security practices. reply dubcanada 47 minutes agorootparentGeneral question, but let’s say they get your genetic ancestry information. What could you do with that? reply nojvek 6 hours agorootparentprevMany sites like Google including my banking sites send me an email when a new IP &#x2F; location is used for login.This alerts if there is a sudden login without my knowledge and one click to disable.23&me could have definitely done that to alert logins.It is 100% on 23&me even though used id&#x2F;passwords were used.Genetic data is by definition extremely personal. reply est31 5 hours agorootparentIt&#x27;s exposed as \"new IP\" to the end user but it hides a lot of logic about ISP IP address pools for specific regions, behaviour of other devices, etc. For someone like Google, that&#x27;s easy to pull off, as a lot of people use it, and people use it daily. But it&#x27;s harder to get this technology for someone like 23andMe where people log in less often, and its product has low penetration of internet users. reply riffraff 4 hours agorootparentJust do it all the time then? If it&#x27;s infrequent it&#x27;s also not much of an hassle.GoG and Steam do \"email 2fa\" and while it&#x27;s annoying they do it anyway as they are a \"risky\" target, IIUC. reply codetrotter 5 hours agorootparentprev> Many sites like Google including my banking sites send me an email when a new IP &#x2F; location is used for loginAll of whom I already mentioned in the comment you are responding to reply chii 6 hours agorootparentprev2FA would&#x27;ve prevented those logins. I think sites should very much start mandating 2FA imho. reply malux85 1 hour agorootparentprevDrop a cookie in their browser and 2FA them if the cookie is not present. It&#x27;s much less likely the attacker will have the users credentials AND cookies, so this raises the bar for the attacker without annoying the user too much. reply faeriechangling 3 hours agorootparentprevI have to agree.Why blame the users for a broken by design security model like password auth? Credential stuffing attacks are a known weakness. We cannot reasonably expect everybody to take precautions against them.I&#x27;ve just become very irate at how people implement absolutely absurdly bad security and people just blame users when the inevitable happens. These attacks have happened for decades. It&#x27;s not the fault of the users. reply tgsovlerkhgsel 2 hours agorootparentprev> Why are you letting people log into an account from a brand-new IP with no additional verification?Because having to play a game of \"Simon Says\" every time I try to log into an account pisses off customers.Humble Bundle, for example, lost several sales because you can&#x27;t even buy a game for an e-mail address that has an account without logging into the account, which requires not just the password (stored in my password manager that I may not have with me everywhere I have my credit card), but also logging into my e-mail and clicking a link.The EU has decided to force banks and payment providers to implement this nonsense because companies like e.g. PayPal decided to rather eat the cost of non-prevented fraud than putting an extra barrier in front of users and losing the users to competitors (by forcing everyone to do it, they prevented companies from competing on this aspect of UX). reply morsch 1 hour agorootparentThis story about genetic data and other sensitive health data being leaked doesn&#x27;t really make the case for letting the market solve this particular problem without onerous regulations.I suppose massively increasing the liability would solve the problem by doing a little of both. reply eviks 3 hours agorootparentprevBecause many people change IPs all the time between devices and such, and it&#x27;s a user hostile practice to ask for an email code on loginInstead they could&#x27;ve monitored the password leaks to see if those got exposed reply faeriechangling 3 hours agorootparentYou can scrape email&#x2F;sms for codes automatically and add them to the clipboard or autofill, and what does user hostile even mean? User hostile is losing all of a users data because you were more concerned with customers liking how easy your service is to use than you were about ensuring your service didn&#x27;t hurt them.You can do better than email&#x2F;sms, especially sms, but they&#x27;re transitionary technologies. I login to way more things than most people do way more often. I don&#x27;t use password authentication alone unless it&#x27;s literally my only option. reply mxmlnkn 2 hours agorootparentprevBecause some people don&#x27;t get a static IP from their ISP and they don&#x27;t want to go through e-mail verification every day. At this point, some sites require this workflow from me: 1. Solve CAPTCHA for log-in form 2. Log in with valid password 3. Open E-Mail client, maybe even log-into your e-mail with the same workflow if not done yet 4. Verify the IP via E-Mail 5. Surf to website log-in form again 6. Solve CAPTCHA for log-in form again 7. Log in again with a valid password 8. Verify with 2FA codeThanks, I hate it. It feels like step 1 to 7 could be skipped. reply spacebanana7 2 hours agorootparentprev> Why are you letting people log into an account from a brand-new IP with no additional verification?Loosening this requirement to new country &#x2F; carrier would make life easier for users at small cost to security. reply bboygravity 1 hour agorootparentprevThat website sounds like a lot of fun to use for people who travel (and often have a new IP). reply pama 13 hours agoparentprevI don’t think you are reading this correctly. People could access (most importantly) the full raw DNA profile. And many of those breached were from people who opted in a “Relatives” feature even if their account was secure. reply ellisv 13 hours agorootparentI don&#x27;t see where in the article is suggests that the attackers were able to obtain the raw genotype data of anyone other than the compromised account. reply pama 12 hours agorootparentThe pics of the offer and pricing suggests uniform DNA info rather than names or passwords for some and raw DNA profiles for others. Also this from the article:“ The compromised accounts had opted into the platform&#x27;s &#x27;DNA Relatives&#x27; feature, which allows users to find genetic relatives and connect with them.The threat actor accessed a small number of 23andMe accounts and then scraped the data of their DNA Relative matches, which shows how opting into a feature can have unexpected privacy consequences.”Edit: maybe you are right about the lack of genetic info, if this account is correct (unless the researcher didn’t pay full price, and only got the metadata): https:&#x2F;&#x2F;therecord.media&#x2F;scraping-incident-genetic-testing-si... reply lozenge 12 hours agorootparentprev23andme doesn&#x27;t sequence DNA, it just checks some genomes.https:&#x2F;&#x2F;customercare.23andme.com&#x2F;hc&#x2F;en-us&#x2F;articles&#x2F;227968028... reply beaugunderson 11 hours agorootparent23andMe uses a SNP array, or SNP chip, to look at SNPs (single-nucleotide polymorphisms, or more generally, single nucleotides that vary within a population). Basically what it gives you is a diff against a reference genome. So yes, while not a full genome sequence you can still get a VCF file out of it, impute sites that are not on the chip, use it for genealogy analysis, look at someone&#x27;s disease carrier status, genetic disease likelihood, etc. reply dash2 1 hour agorootparentYeah, I mean this is about 1 million SNPs, right? It&#x27;s very very personal indeed. I could make good guesses at the chance of you going to university; your height; your risk of depression; what you look like.... reply placesalt 13 hours agoparentprevI guess one question is: should> did not have 2fa enabledbe allowed to coexist with> pretty extensive and personal data reply ApolloFortyNine 13 hours agorootparentIt&#x27;s the user&#x27;s data, its not on 23andme to baby the user. If the user wants to trade ease of login with risk of getting hacked, that&#x27;s not 23andme&#x27;s fault. reply jonny_eh 13 hours agorootparent> that&#x27;s not 23andme&#x27;s faultYes it is. It&#x27;s their fault for giving the user a choice. Google requires (some) users to enable 2FA, why can&#x27;t 23andme?https:&#x2F;&#x2F;www.tomsguide.com&#x2F;news&#x2F;google-forcing-2fa-users reply strken 9 hours agorootparentBecause user aversion to 2FA is often rational. The expected cost of learning how to use 2FA plus risking losing access to your account and not being able to get it back through support is often higher than the cost of having your account compromised. reply chii 6 hours agorootparent> user aversion to 2FA is often rational.The account recovery process should be setup at the start of the 2FA setup - e.g., you get emailed a bunch of backup codes (easiest way imho).The site should not be using their own 2FA app, but use a standard OTP implementation, and let the user use their own OTP app (most people default to google&#x27;s authy, but there&#x27;s a couple out there that are common too).Or, as an alternative, delegate the login to email and use a password-less login mechanism (effectively delegating the account security to the email&#x27;s security). I argue this is actually more convenient, but some people (esp. young people?) have an aversion to email which i don&#x27;t understand. reply shushpanchik 54 minutes agorootparentEmailing backup codes doesn&#x27;t sound like a good idea. You give the keys to the kingdom to email provider or anyone who would be able to access your mailbox. reply chii 18 minutes agorootparentIf the email is busted open, then it would already have been possible to do a a forgot password recovery (which i presume uses emails).Therefore, backup codes are no less secure than that. reply faeriechangling 2 hours agorootparentprevIt&#x27;s really not man.Maybe for some irrelevant social media site I can understand doing password-only auth because who cares, but this has your DNA on it. Even if the person who has all their personal information leak doesn&#x27;t care, they fucked over their entire family. I guess that&#x27;s not 23andMe&#x27;s fault though because they were just satisfying a rational user aversion!Not only that, but the aversion to using methods of logon other than passwords are less rooted in passwords being easy, and more in passwords being STANDARD. Passkeys for instance are faster to use than passwords. The ONLY thing that makes passwords \"Easy\" is peoples refusal to start using something better because of one-time switching costs and inertia. reply syndicatedjelly 8 hours agorootparentprevI really hope this is not the prevailing attitude in software security.can someone from that field please chime in? reply coding123 8 hours agorootparentprevBut that&#x27;s only because companies, like google, offer no human support for lost accounts. Somehow I wonder if 100 years from now personal data will be handled by something like a bank. If you lose your password you call your personal data bank - which can get you back online or something like that.Maybe that&#x27;s the next big thing - local, personal companies that are your \"online power of attorney\" that have the right to reset your shit, make claims about your identity. I have no idea. But the current state of things is just a mess. reply clnq 3 hours agorootparentprevGoogle can do a lot that no one else can. Think of user conversion rates if you require that they install an app and set up some TOTP stuff some never heard about just to access your platform. reply yungporko 2 hours agorootparentprevthis attitude is why almost all online services are absolutely insufferable to use now and it gets worse every day reply toofy 11 hours agorootparentprevif they’re hosting sensitive data, it isn’t “babying” the user to take some responsibility for the data your company exists on.if they can’t take responsibility for it, then they’re too irresponsible to make money it.it would be entirely reasonable for them to say “we don’t want anything to do with this data, we don’t want to profit from it, we don’t want to use it in anyway, therefor we will not retain it at all.”babying the user by taking responsibility for the very data they profit from? unreal. reply ipaddr 9 hours agorootparentCheckout the data in the screenshot. This is not sensitive data. Pretty useful data. reply toofy 7 hours agorootparent> The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location.i would absolutely argue that having my1) genetic ancestry,2) full name,3) date of birth,etc… is sensitive information.even removing genetic information, if a company is too irresponsible to catch millions of users info being stolen, then they’re too irresponsible to have that data.again, either it’s important to your business or it isn’t. if it isn’t important, then refuse to store it. reply jchw 10 hours agorootparentprevIt&#x27;s not always that clear cut, though; after all, wouldn&#x27;t this argument apply to e.g. laws requiring seatbelts? One could argue that in this early-ish stage of electronic data, vendors that hold very sensitive data are being irresponsible. Not just about not requiring more secure authentication, but also for pushing less secure authentication like SMS-based authentication factors. reply KRAKRISMOTT 9 hours agorootparentThe car makes an annoying beep beep sound, but it doesn&#x27;t force the user to use a seatbelt. The onus and responsibility is ultimately on the end user. reply jchw 9 hours agorootparentThe inability of the car to safely enforce this is probably the main reason why this works this way. The responsibility is split, though: cars are required to be designed in ways that discourage or prohibit some unsafe behaviors entirely. Not too different from services requiring 2FA: doesn&#x27;t mean the TOTP secret is necessarily stored safely. reply dizhn 2 hours agorootparentThere are cars from the 90s that put the seat belt on automatically when you close the door. It looks awful but it works. reply ImPostingOnHN 8 hours agorootparentprevA friend of mine rented a larger, newer Jeep SUV when in town. It would not go into gear unless seatbelts were buckled. It was awful - not a future I want to live in. I&#x27;d rather have the choice than have it made for me in the name of safety.> Not too different from services requiring 2FAThat is another practice I find awful for the above reason. reply serf 7 hours agorootparentAnother underlying problem with that kind of gatekeeping are the dangerous scenarios that can happen when the Jeep decides erroneously not to start due to a sensor anomaly.It&#x27;s a virtue that a car continues to operate when all the warning signs and buzzers are going off; this means that the human in charge is left in ultimate control of the situation and there doesn&#x27;t need to be any complex umbrella structuring of liability -- this allows a driver to safely drive away from a dangerous tidal wave&#x2F;assault&#x2F;lava flow&#x2F;whatever even if their seat belt sensor is broken ; this is very important for numerous reasons. reply Tagbert 6 hours agorootparentprevYou are assuming that all users consider this data to be especially sensitive as opposed to something that your body leaves about wherever you go. reply Clamchop 10 hours agorootparentprevThis stance is reckless and negligent. Pragmatically, you can be found liable. Ethically, it&#x27;s cut and dried. reply ApolloFortyNine 6 hours agorootparent... Do you really believe this? There&#x27;s countless services out there that don&#x27;t require 2fa by default. Honestly it&#x27;s probably easier to list the ones that do.If you think that means the company can be held liable, I&#x27;d honestly start leaking my information on the internet if I were you. You have millions of dollars of lawsuits to go win apparently. reply Clamchop 8 minutes agorootparentI absolutely believe this. If you think your service shall perform no due diligence that it is correct, accurate, and safe, then you have no business providing it to the user, who has little or no knowledge of the domain, which you are selling to them. That is your job, to sell a sophisticated service to someone who would enjoy the benefits but cannot begin to do it for themselves.If you don&#x27;t think so, then I think you&#x27;re beyond reprehensible, and so will the courts. There is no disclaimer that can protect you. Good gravy, this is the easy part. reply wilg 13 hours agorootparentprevPasskeys, baby! reply rkagerer 12 hours agorootparentGive me an implementation I can self-host, without Google, Apple, etc. having effective control (including claws in my relevant software supply chain) and with an easy user experience, where I can maintain secure backups (on my own infrastructure, thank you) and smooth transition to future devices, and ideally, if needed, securely export root keys (cause if I don&#x27;t control them then someone else owns them), and maybe I&#x27;ll be interested.In the meantime plain old high-entropy passwords with a good manager gives me all those features and a simplicity that&#x27;s hard to beat.In my 30+ years of computing I&#x27;ve suffered more harm from failures of other companies than I have from any failure of my own diligence. The whole lesson learned is to reduce trust in them and, maybe I&#x27;m wrong, but everything I&#x27;ve read about passkeys and the like seems to put me at liberty of the companies developing and pushing the implementations of them down my throat. It will take a lot of trust before I give up my ability to copy&#x2F;paste my credentials. reply elabajaba 9 hours agorootparentKeepassxc and bitwarden should both be getting support for passkeys soon. Bitwarden sometime in October (vaultwarden already has support for storing them), keepassxc there&#x27;s been an open PR for it that&#x27;s been tested and iterated on for awhile, but I&#x27;m not 100% sure how close it is to landing. reply rkagerer 6 hours agorootparentThanks! Last time I checked it out the top hit said \"Closed as Not Planned\". Could you point me to some good details or any article on how it&#x27;s being implementef (e.g. does it act as a third-party store or something to avoid being locked behind a TPM or whatnot?). Genuinely interested. reply elabajaba 5 hours agorootparentI&#x27;m not sure about any specifics beyond that both are getting support for them (for the keepass ecosystem I&#x27;m sure about other mobile clients, but I don&#x27;t think the feature request to support passkeys has been acknowledged by the keepass2android dev sadly). Here&#x27;s the keepassxc PR with some details about the implementation, and what should be done in future work on passkey support: https:&#x2F;&#x2F;github.com&#x2F;keepassxreboot&#x2F;keepassxc&#x2F;pull&#x2F;8825Bitwarden has a few blogs if you search for bitwarden passkeys, but from skimming one it didn&#x27;t seem to go into technical details (though I didn&#x27;t watch the videos). I guess you could look through the PRs: https:&#x2F;&#x2F;github.com&#x2F;bitwarden&#x2F;clients&#x2F;pulls?q=is%3Apr+passkey... but I don&#x27;t really feel like doing that. reply keep_reading 13 hours agorootparentprevTry convincing all the anti-passkey folks first reply adameasterling 2 hours agoparentprevWebsites should mitigate credential stuffing by checking against known cracked passwords. All you have to do is download Troy Hunt’s hashed password database, check it when someone logs in and if it’s cracked do your email password reset flow. Or you can use their API.It’s very simple, and I believe has been an accepted best practice since like 2017. This is 100% on 23andme. They are responsible.1. https:&#x2F;&#x2F;haveibeenpwned.com&#x2F;Passwords reply bostonsre 13 hours agoparentprevShouldn&#x27;t they have noticed that an ip or a set of ips were trying to log into a bunch of different accounts? reply Urgo 13 hours agorootparentDepends on how they tried to get in. They could have used a large amount of residential proxies to get around this. reply mrguyorama 13 hours agorootparentIf someone is trying to log in to \"Account A\" from fifty different places, that should be a red flag reply mullingitover 13 hours agorootparentThey&#x27;re not.They have a large set of different emails + passwords, and a large set of IPs.Each IP can check a single set of credentials, so you never get a single IP in a short timeframe with too many login attempts, and never trying to brute force a single account. If the attacker rented time on the botnet for a long enough period, they can fly under the radar for quite a while. 23andme sees lots of failed logins, but no real way to pin it down.reCAPTCHA would be the answer here. What&#x27;s interesting&#x2F;concerning is that it appears Google&#x27;s reCAPTCHA (assuming 23andme was using it, and they should&#x27;ve been) was defeated. reply hombre_fatal 12 hours agorootparentCaptcha still means you get to do the cred stuffing attack, just potentially more slowly which still doesn’t protect the user.I think for sensitive data where you want to protect the user, it makes even more sense to just generate passwords for them. It’s even simpler than 2FA. Some online casinos do this. reply mullingitover 11 hours agorootparentIf your attacker is stuck manually passing the captcha time after time, they&#x27;re probably not going to bother.The thing that worries me more is the possibility that newer AI tools are allowing attackers to beat reCAPTCHA with automation. If that&#x27;s the case, a lot of folks are going to be caught with their pants down.Edit: looks like it&#x27;s more than a possibility[1].[1] https:&#x2F;&#x2F;twitter.com&#x2F;sw33tlie&#x2F;status&#x2F;1710409035030122731 reply minitech 7 hours agorootparentThe linked post isn’t reCAPTCHA, it’s just some random bad CAPTCHA that’s been easy to defeat with OCR for ages. The real fundamental flaw is that human time is cheap enough: see Amazon Mechanical Turk. Many bulk, human-powered CAPTCHA-solving services have existed for years. replyrendaw 8 hours agoparentprevIf it was a known leaked database, they should have invalidated the passwords from the database before attackers exploited them. reply Urgo 7 hours agorootparentWhile it&#x27;s probably not a horrible idea to do something like this I don&#x27;t think any or at least many does this currently? It wasn&#x27;t a 23andme database that the attacker used, it was just some other random site&#x2F;sites. So every time any website is hacked should every other website invalidate the credentials of those users on their site too? reply chii 6 hours agorootparentIt is a lot of hassle, and the user isn&#x27;t really protected because the invalidation relies on public releases of email&#x2F;password combinations; there&#x27;s obviously going to be plenty of private releases, which means it&#x27;s actually just security theatre.2FA, or passwordless logins, are the solution. Forcing the user to change their password (at the most inconvenient of times - right after they logged in, but before they&#x27;re able to use the site) is annoying at best, and does nothing at worst. reply eviks 3 hours agorootparentHow is it a theater to save a lot of users, but not all? reply chii 3 hours agorootparenta theatre is where you have the feeling of security, but you don&#x27;t really have it in reality.You cannot claim that just because some users are &#x27;saved&#x27; as evidence that this is an effective security measure, because if a password was leaked, and not discovered, then this measure doesn&#x27;t prevent it. But it is imposing a cost, which cannot be measured against effectiveness.Change the whole process to 2FA is secure because there&#x27;s provable guarantees for the costs imposed, and therefore, you can make an objective decision on whether it is worth implementing. replyShadowBanThis01 4 hours agoparentprevAnd this is why you should never force people to use their E-mail address as a user ID. reply teaearlgraycold 13 hours agoparentprevUse a password manager with long, random passwords. Pick your own passwords and you&#x27;re leaving your door unlocked. reply Kiro 13 hours agorootparentGood luck trying to convince anyone who is not already using it. I&#x27;ve tried super hard to get my friends and family to use a password manager but they brush it off as a joke. Even when they lose their account it doesn&#x27;t seem to bother them. They just create a new one. It&#x27;s a dead race. reply ellisv 13 hours agorootparentThis has been my experience as well. You can even show them that they have been a part of breaches but not even that is motivating enough. reply dewey 13 hours agorootparentprevI don&#x27;t think you have to tell that to people on HN, but regular people will not be able to use most password managers. Not even 1Password is really user-friendly and it&#x27;s the most mainstream one.The included one on macOS is hidden in some setting panel.For non-technical people the best authentication method is probably their phone (Passkeys, or tokens sent to their email address). reply alistairSH 8 hours agorootparentThe included one on macOS is hidden in some setting panel.As long as you stay in the Mac&#x2F;iOS walled garden, you really don’t need to access the Settings page&#x2F;app. Safari and most apps will happily pull the user&#x2F;pwd from the manager for you. I’ve used for a few years now (after tiring of the mediocre UX of several other managers). reply randerson 13 hours agorootparentprevMost (all?) major browsers now have built-in password managers which are intuitive enough for regular people and provide sufficient security against these attacks. reply dewey 13 hours agorootparentAnd yet, passwords get guessed, stolen, re-used all the time. If you talk to regular people they still use pet names + a number because they want to be able to type it in everywhere.It&#x27;s not a solved problem, even if a rudimentary password manager is in most browsers.Personally I don&#x27;t know a single person outside of my tech bubble that uses passwords that you can&#x27;t keep in your head, or write down on a piece of paper on their desk. reply hunter2_ 8 hours agorootparentThere&#x27;s a simple trick to having a password that&#x27;s easy to type, easy to remember, and is pretty darn secure: repetition. Just take your pet&#x27;s name or whatever, type it several times, and then finish it off with a number or whatever. Should be resistant to typical dictionary and brute force attacks. reply dewey 6 minutes agorootparentAnd you already identified the main problem with this strategy: \"repetition\".As it&#x27;s not possible to remember n passwords for n sites, if one of them gets hacked \"darn secure\" isn&#x27;t so secure any more. The main point of password managers is that you don&#x27;t have to remember your password and if it leaks out on one site, it doesn&#x27;t matter as it&#x27;s only used on that one site.sib 10 hours agorootparentprevIn this case, unfortunately, at least as it&#x27;s being described publicly, your detailed information was at risk if someone you are (even distantly) related to failed use a long, random, unique password. reply hn_throwaway_99 11 hours agoprevI wonder if companies will seriously start to rethink \"transitive permissions\" or \"network permissions\". This is very similar to what bit Facebook in the ass years ago: I have permissions to see all the data of my friends, but in the past I could also click a button to let someone who requested see not just my own info, but also all the info from my friends.From a \"computer science\" perspective this makes sense: if I say you can view all my data, I lose control with who else you share that data with. But from a \"human\" perspective, most people don&#x27;t think that if I give you access that I&#x27;m essentially giving access to the rest of the world.These types of network permissions make any company who holds them a prime target because it means bad guys only need to hack a few accounts to get exponentially more data. reply hunter2_ 9 hours agoparent> also all the info from my friendsThey would only see the subset of what your friend shared, the set configured by its author as visible to friends of friends, right? reply hn_throwaway_99 6 hours agorootparentNo, IIRC this predates that entire permission model. \"Friends of friends\" today means just what it sounds like - my friends and all of their friends can see the data Iark that way.Back in the late 00s&#x2F;early 10s when lots of \"Facebook apps\" were a bit of a craze (think Farmville), you could give an app maker permission to view your personal data and all of the data that you could see about your friends. This is how Cambridge Analytics was able to build profiles of 87 million Facebook users when only a few hundred thousand actually installed the \"your digital life\" app: https:&#x2F;&#x2F;www.theguardian.com&#x2F;news&#x2F;2018&#x2F;mar&#x2F;17&#x2F;cambridge-analy... reply Calamitous 11 hours agoprevThis is precisely why, though I find it to be a fascinating idea, I have steadfastly refused to do one of these genetic tests. reply MerelyMortal 10 hours agoparentNot only that, you have to make sure all of your extended family members don&#x27;t take the test too. reply stjohnswarts 4 hours agorootparentthat&#x27;s impossible. All you can do is talk to them and tell them it&#x27;s a bad idea. The data will exist from now until the end of the current human age. Everyone wants it, 23 and me may be decent custodians, but eventually it will end up in the hands of every government, corporation, and entity interested in getting DNA information through breaches and some eventual buyer of the company selling it. reply Bluecobra 4 hours agoparentprevSame here, I wish there were some regulations in place to safeguard this data. It seems like the cat is out of the bag though:https:&#x2F;&#x2F;www.pbs.org&#x2F;newshour&#x2F;amp&#x2F;science&#x2F;dna-ancestry-search... reply libraryatnight 11 hours agoparentprevI remember a Simpsons joke where Homer finds out the government has everyone&#x27;s DNA on file and asks about it and they say \"Yep everyone who&#x27;s touched a penny since 1932\" or something.Turns out it didn&#x27;t need to be that elaborate, you could just ask folks to mail it in ;) reply teagoat 10 hours agorootparentyou could just ask folks to mail it in (and pay for the privilege) reply 4rt 6 hours agoparentprevCouldn&#x27;t you just do it but with a fake name? reply TedDoesntTalk 5 hours agorootparentThat is exactly what I did. And I got a temporary mailbox at the local UPS Store so they could not get my real address. And signup on their website was with a new email address. It’s a pain but it was worth it for me. Of course, I opted out of the DNA Relatives feature. reply stjohnswarts 4 hours agorootparentThey can pretty easily connect it to you via family members, hopefully your family avoids it. reply csomar 3 hours agorootparentprevMy sister didn&#x27;t have an account when we sent the packages. When the data got analyzed it showed it as \"My Sister\" with close to 100% accuracy. The packages were anon, so they couldn&#x27;t know which sent which. reply jdthedisciple 9 hours agoparentprevYeap, same here. Don&#x27;t think I&#x27;ll ever try any of them. reply hammock 11 hours agoprevAccording to this tweet, the hackers likely got ALL of the data but only leaked a subset, 1.3 million records (only the ashkenazi Jews)https:&#x2F;&#x2F;x.com&#x2F;mattjay&#x2F;status&#x2F;1710370423311888724?s=20 reply SaberTail 10 hours agoparentThat would explain how they got so much data with a probably small number of compromised accounts. Ashkenazi Jewish people were relatively genetically isolated from the rest of Europe and started from a relatively small founder population. Genetically, then, they&#x27;re all detected as distant cousins of each other using standard metrics.This means a typical Ashkenazi Jewish customer of 23andMe has a lot more relatives than most other customers, and so they&#x27;d be able to view that many more profiles. reply beaugunderson 10 hours agoparentprevas a 23andMe user with a high percentage of Ashkenazi genes I expected my data to be in the leak but it wasn&#x27;t so it&#x27;s probably not all of the Ashkenazi data reply justinzollars 10 hours agorootparentHow did you verify? I am ashkenazi reply beaugunderson 9 hours agorootparentassuming your last name is the same as in your HN username you are not in the file either(as to how I verified: the file is still available on the leak site) reply marcod 7 hours agorootparentOK, that CSV is just a subset of the data they claim to have.... so our data might still be out there even if it wasn&#x27;t in this file.These are the headers: profile_id; account_id; first_name; last_name; sex; birth_year; has_health; ydna; mdna; current_location; regions; subregions; population_idsFirst entry is Elon;Musk;Male;1971;... reply TedDoesntTalk 5 hours agorootparentGlad I used 23andMe with a fake name and UPS PO Box reply 1-6 5 hours agorootparentprevThere&#x27;s a whole debate about whether Elon Musk has Jewish ancestry. Are you saying he is? reply marcod 3 hours agorootparentI have almost 6% myself, but to me it feels like, if I don&#x27;t even know about who it might have been in my family tree, it doesn&#x27;t really count.But yes, for EM it said \"Ashkenazi;Balkan;British Irish\" - no percentages in there - and I believe 23andme has confirmed the authenticity of the data. replymock-possum 4 hours agoparentprevOh god, of course it’s a Jewish thingIf I live a hundred years I will never understand people’s obsession with the Jews reply Lord-Jobo 10 hours agoparentprevGreat, more neo-nazi terror. I love the 20&#x27;s &#x2F;s reply technol0gic 11 hours agoprevI&#x27;ve said it countless times now: until there is criminal liability for negligence with regard to data warehousing&#x2F;safekeeping, this is going to keep happening. because they do not care, and will not care (regardless of what their PR puts out) until their toosh is on the line.Every time there&#x27;s a breach, they pull a British Petroleum \"we&#x27;re reallllly sorrrrrry\" and buy a bunch of people LifeLock. Its absolute bullshit. reply pakyr 3 hours agoparentWhy would 23andMe face any criminal liability? Per the article, they were never breached; only individual accounts with reused credentials exposed in other breaches. They should have had 2FA, but I don&#x27;t think not having 2FA should be criminalized. reply prometheon1 1 hour agorootparentIf a bank allowed people to log in to their bank account and make transfers based on only email+password and someone stole money from a bunch of accounts, would the bank face any criminal liability?I don&#x27;t know the answer, but I would say your DNA sequence should be secured similarly to your bank account. reply adameasterling 2 hours agorootparentprevI don’t know about criminal liability, but they’re certainly at fault for not implementing a check against known compromised passwords[1]. I believe it’s been an accepted best practice since something like 2017.1. https:&#x2F;&#x2F;haveibeenpwned.com&#x2F;Passwords reply Footnote7341 10 hours agoprevWhile we&#x27;re talking about the privacy implications of sending your DNA to be sequenced &#x27;for fun&#x27;. 23andMe already work with law enforcement, and the data science is getting good enough that they can figure out your identity if one of your third cousins turned in a DNA sample and you never did.The average person has around 200 3rd cousins. reply jddj 10 hours agoparentCan you elaborate on how that works?One of my 200 third cousins did a 23andMe swab. I then committed a crime, possibly on the other side of the country*.Law enforcement collects DNA evidence. What now?* edit: Previously this said \"or world\" but that felt unreasonable for the question reply steelframe 10 hours agorootparentThe list of potential culprits reduces from perhaps tens or hundreds of thousands to about 200. Family trees are very easy discover. Check out your local Mormon genealogy center if you don&#x27;t believe that. At that point they can apply standard gumshoe investigative techniques to quickly narrow it down to you. reply soared 9 hours agoparentprevCan law enforcement ping the 23andme database with any DNA they swab? reply Footnote7341 8 hours agorootparentYes and it appears to be some kind of weird work around where 23andme doesn&#x27;t explicitly work with them. This exact technique was used to readdress some serial killer cases recently. https:&#x2F;&#x2F;www.cbc.ca&#x2F;news&#x2F;world&#x2F;dna-from-genealogy-site-used-t... https:&#x2F;&#x2F;www.latimes.com&#x2F;california&#x2F;story&#x2F;2020-12-08&#x2F;man-in-t... reply cstejerean 8 minutes agorootparent> What prosecutors did not disclose is that genetic material from the rape kit was first sent to FamilyTreeDNA, which created a DNA profile and allowed law enforcement to set up a fake account to search for matching customers. When that produced only distant leads, a civilian geneticist working with investigators uploaded the forensic profile to MyHeritage. It was the MyHeritage search that identified the close relative who helped break the case.Basically they send in the genetic material and create an account on the site, then see which relatives it matches with and go from there. reply mrobins 12 hours agoprev$75k. Tell me the government doesn’t take privacy seriously without telling me that government doesn’t take privacy seriously.> Three weeks ago, genetic testing firm 1Health.io agreed to pay the Federal Trade Commission (FTC) a $75,000 fine to resolve allegations that it failed to secure sensitive genetic and health data, retroactively overhauled its privacy policy without notifying and obtaining consent from customers whose data it had obtained, and tricked customers about their ability to delete their data. reply juunpp 11 hours agoparentI already find the narcissistic \"welcome to you\" message on the package inducing of extensive amounts of vomit. And then they only get $75k for this? I want them go DOWN. reply readyplayernull 11 hours agorootparentThe FTC takes the its_not_about_the_money.jpg meme very seriously. reply WendyTheWillow 10 hours agoparentprevWe’re not actually seeing the kinds of boogeymen people like to trot out when this kind of data is leaked. Nobody is conducting banned genetic research, nobody’s insurance rates are going up, nobody is getting ethnically cleansed as a result of this info…A few stolen identities, some bank fraud, but largely the systems in place can handle it. It’s caught at the other end.If you want big fines, prove big consequences. reply 93po 10 hours agorootparentA single stolen identity can cause years of emotional harm and turmoil. Someone’s life is often completely uprooted from this. That one person alone should receive significantly more than $75k reply WendyTheWillow 9 hours agorootparentA single car accident can end a life, yet we drive cars. The value gained by technology like 23andme is vastly outweighs the cost of some occasional negligence or theoretical harm.Besides, if you can find a specific person who was specifically harmed by this exact breach, I bet you could sue for damages, and get more than $75k. reply dheera 10 hours agoparentprevCapitalism being backwards as usual. If we really take privacy seriously we should fund them $75K to fix their privacy problems.If you take away $75K from their engineering budget they will only do a worse job, and more data will leak. reply 0134340 10 hours agorootparentI&#x27;m just going to do my monthly HN login to say, and possibly skirt ethics here because your comment truly deserves it, that this is the dumbest thing I&#x27;ve read on here in a long time. I can&#x27;t tell if this comment is satire or being real. reply Angostura 10 hours agorootparentprevThat sounds like a good way to ensure monthly data leaks reply seanhunter 4 hours agorootparentprevErr, no. If you give them $75k then everyone else will be incentivised to leak data so they too can get a free $75k. reply tremon 10 hours agorootparentprevWhat? No. If we really take privacy seriously, we might consider giving them a discount on their use of our genetic data once they have shown responsible care in handling that data -- similar to how no-claim bonuses work in insurance. reply rileymat2 10 hours agorootparentprevWouldn&#x27;t this incentivize insecure practices and bad practices so they can get 75k? Wouldn&#x27;t that be the effect, everyone tries to as little as possible until they get paid? reply jddj 10 hours agorootparentprevThat&#x27;s a fairly unconventional approach. Not a subscriber to traditional incentives-drive-behaviours theories I guess? reply landemva 10 hours agorootparentprevCapitalism brings abundant choices. Many or most people don&#x27;t care enough to protect themselves by choosing differently. reply stjohnswarts 4 hours agorootparent$75000 is a lot less than buying even 1 security expert. It&#x27;s just the cost of doing business if you don&#x27;t charge them some substantial % of their revenue for a year. Say 20% - 50%. It has to sting or there will be no change in their processes. reply dheera 2 hours agorootparentAnd if fined $75000 the first thing they would do is lay off that security expert.Provide the security expert to them at no cost, taxpayer funded, as a collective effort to stop identity leaks. replyganeshkrishnan 12 hours agoprevI visited the site in the screenshot and saw someone peddling NATO leaks from their Philippines visit including \"PLANCTON, CRONOS, CA SIRIUS, EMADS, MCDS, B1NT etc\" And one more list of some ukrainian citizens database from 2023.please don&#x27;t kill me CIA! I swear I accidentally saw it.welp! time to head back to my work. reply mottosso 11 hours agoparentThat&#x27;s exactly what a spy would say. Get&#x27;em boys! reply yieldcrv 30 minutes agoparentprevwhat site is it? reply riffic 13 hours agoprevThere are some genealogical services out there that do Leeds-Collins charts that to my knowledge work by asking their users for their 23andMe credentials, much like some third party banking services that work by asking their users directly for their banking credentials. There&#x27;s a lot of really bad security in this sector. reply beaugunderson 11 hours agoparentso sad given that there was a 23andMe OAuth2 API for some time that had SNPs as OAuth scopes! reply riffic 10 hours agorootparentgonna name and shame geneticaffairs.com here for this appalling practice:https:&#x2F;&#x2F;geneticaffairs.com&#x2F;faq.html> Genetic Affairs is able to retrieve DNA matches for several DNA matching companies. To download DNA matches of these companies we need to store your login credentials. See the next section concerning the secure storage of these credentials.> Since we have to use login information for 23andme and FamilyTreeDNA, we use an isolated database in which we encrypt and store the passwords of these websites. This database is only available in a private network in the cloud and not exposed to the Internet. reply beaugunderson 9 hours agorootparentbizarre... I wonder why they don&#x27;t just accept a raw data upload from 23andMe? reply spullara 12 hours agoprevMaybe they could send me my dad&#x27;s account password he lost years ago and no longer has the email address. reply smlavine 14 hours agoprevIt was only a matter of time. I feel sorry for all the people that were tricked into trusting a private company with their genetic information. reply fenalphthalein 14 hours agoparentAfter reading the article, I think it&#x27;s more that people were tricked into [reusing passwords across websites instead of having a password manager and randomized passwords].It&#x27;s not on 23andMe, or anyone (other than the user) for that matter, to ensure the passwords used by the user are not copied passwords from other credentials.Seems to me like passwords need to be regulated on a governmental level, but that&#x27;s a can of worms of an idea that I am not ready to defend. reply adameasterling 2 hours agorootparent> It&#x27;s not on 23andMe, or anyone (other than the user) for that matter, to ensure the passwords used by the user are not copied passwords from other credentials.In my opinion, it is, actually, on 23andMe. At my tiny startup, I implemented a simple check against Troy Hunt’s compromised password database.[1] If I can do it, 23andMe can.If anyone reading this is in the business of making web apps and there’s literally anything of value behind your login, prioritize this mitigation. OWASP recommends it too. [2]1. https:&#x2F;&#x2F;haveibeenpwned.com&#x2F;Passwords2. https:&#x2F;&#x2F;cheatsheetseries.owasp.org&#x2F;cheatsheets&#x2F;Credential_St... reply chatmasta 13 hours agorootparentprevI mostly agree with you, but 23andme could have prevented this by requiring 2FA for all accounts, or at least for accounts with an email in the HaveIBeenPwned database.Credential stuffing is most preventable by the user (who can simply not reuse passwords), but platforms have a responsibility as well. They can at least mitigate it through rate limiting, and mostly stop it with 2FA requirements.If an attacker is able to exfiltrate millions of records from a platform with credential stuffing, that means they tried to login to multiple millions of accounts. It shouldn&#x27;t be difficult for a service to detect and stop such a sustained level of load on its login infrastructure. You can&#x27;t get millions of proxies. reply supercucumber 13 hours agorootparentNone of this is surprising. I was a sw engineer at 23andMe about 5y ago. Their backend consisted of some of the worst python&#x2F;django spaghetti code I’ve ever worked on. There was also no engineering culture whatsoever. reply the8472 13 hours agorootparentprev> but 23andme could have prevented this by requiring 2FA for all accountsThey could have prevented that by not keeping the data longer than needed to send it to the user. reply thebrain 13 hours agorootparentprevActually, if the attacker is determined enough they can use enough IPs and make it really hard to detect and defend against.I work on combating credential stuffing on a regular basis... it&#x27;s quite challenging. reply kulahan 13 hours agorootparentprevWhat I make my password should be entirely up to me, with the knowledge that if my data is stolen because I reused a password, it was entirely my fault.I don&#x27;t really think this needs to be regulated; government-standard guidelines are probably sufficient, with companies knowing that deviating will expose them more to litigation in the event of a problem.Not trying to argue with you, I did read your last sentence, just tossing in another POV. reply sib 10 hours agorootparentIn this case, due to the \"genetic relatives\" feature, one user&#x27;s choice to use poor security (e.g., \"passw0rd\") enabled the bad guys to get the data of other users who did use good security.Sort of a \"negative security externality\"... reply smeej 13 hours agorootparentprev\"Tricked into\"? Who is tricked into reusing a password? reply fenalphthalein 12 hours agorootparentThis is my personal take: People are sometimes tricked by natural human instinct into performing actions that give benefit to a simple human need (\"it&#x27;s just easier for me\") at the detriment of higher-level outcomes (in this case, password security).It&#x27;s simply easier for me, as a human, to remember that my password for all websites is Hunter2, rather than spend the extra time, create a password manager account, store passwords, utilize best password management practices, etc. Not saying this is what I do, but for many people, this is how they remember their password(s).Maybe I should have changed the \"tricked into\" to \"trick themselves\", but I&#x27;m just a human and this was easier for me. reply leotravis10 13 hours agoparentprevNot just those people, but people who never even heard of the company or even visited the website due to the fact that their DNA and personal details have been shared to the site thanks to relatives&#x27; DNA.Source: https:&#x2F;&#x2F;www.linkedin.com&#x2F;feed&#x2F;update&#x2F;urn:li:share:7116053429... reply Svenskunganka 12 hours agorootparentVeritasium has an interesting video explaining this, mentioning 23andMe on multiple occasions: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KT18KJouHWg reply ellisv 13 hours agoparentprevMuch of healthcare is provided by private, for-profit companies. Even public, non-profit healthcare providers will use services (including genetic testing) from private, for-profit companies. reply amelius 13 hours agoparentprev> I feel sorry for all the people that were tricked into trusting a private company with their genetic information.And all their relatives (who share a lot of their DNA after all) reply justrealist 13 hours agoparentprevI have my genetic info on 23andMe and I could not care less.Seriously — what are people going to do with it? It&#x27;s illegal for insurance companies to discriminate. I&#x27;d post it myself on GitHub if anyone showed the slightest interest in using it. reply lm28469 13 hours agorootparent> It&#x27;s illegal for insurance companies to discriminateFor how long ? Being jewish on record in Germany in 1930 was fine, in 1940 not so muchData is forever, laws, regulations, governments, &c. aren&#x27;t reply justrealist 13 hours agorootparentI will bet you $10,000 that it will be illegal to tier health insurance on your genetics in 5 years, 10 years, or whatever timeframe you want.If you want to take that bet, let me know and I will send you my contact info. reply peyton 2 hours agorootparentInsurance companies don’t care so long as all their competitors have to play by the same rules. Insurance co decisionmaking is sometimes counterintuitive.Genetic data will definitely be used to limit freedom of movement somewhere on Earth in the next 25 years. We’ve already been mass-swabbing for COVID for the past three years, so it won’t be that big a change. reply lm28469 10 hours agorootparentprevDid you also predict, 10 years ago, that so many states would an abortion ?Get back to your crystal ball and tell me when the war in Ukraine will end and how much will a btc be worth in 5 and 10 yearsIf people in this forum believe Musk when he says fully autonomous vehicles will be there in two years (since 2012) and that the AI singularity is coming this decade, the possibility of genetic testing being extended to pre conditions isn&#x27;t so crazy reply justrealist 8 hours agorootparentSounds like easy money then. Are you taking the bet? reply timeon 2 hours agorootparentWhat they are saying is that it is not easy money for anyone. reply mistrial9 13 hours agorootparentprevcompletely agree, and it was not only Jewish people that were on that list right? reply progman32 13 hours agorootparentprevThat&#x27;s great, feel free to do that. Many others would rather keep their ancestry or genetic attributes out of the public eye. Maybe it&#x27;s a source of pain for them, or is required for personal safety reasons. And just because something is illegal doesn&#x27;t mean it won&#x27;t happen. Legal \"workarounds\" are a thing. How watertight is the legislation and practice around preventing employers from taking a peek? Or having someone else take a peek for them?A concrete example: What could the consequences in today&#x27;s USA political climate be of having a massive database be with columns: Firstname, Lastname, y_chromosome_present. reply justrealist 12 hours agorootparentAlmost 0, because even in the absence of public data (which is multitudinous) you can infer sex from first name with > 95% confidence. reply RoyalHenOil 11 hours agorootparentThey&#x27;re talking about trans people. reply heavyset_go 12 hours agorootparentprev> It&#x27;s illegal for insurance companies to discriminate.Only for health insurance. Other types of insurance companies are free to use that data to discriminate against you, include life, disability, and long-term care insurance. reply jstarfish 13 hours agorootparentprevIdentity theft, especially with today&#x27;s deepfakery. reply sdfghswe 13 hours agorootparentprevThe problem with this situation is A) precisely that you don&#x27;t know what people are going to do with it, and B) that once it&#x27;s out there it&#x27;s impossible to undo that.You&#x27;re confident enough that nothing can be done, to the point that you&#x27;d take the risk for no upside. That... doesn&#x27;t sound rational to me? reply latchkey 13 hours agorootparent> A) precisely that you don&#x27;t know what people are going to do with itWe know now, they are going to leak it.Everyone is going to know that I&#x27;m an Ashkenazi Jew who is more likely going to have blue or brown eyes and hair loss.Whooops. reply progman32 13 hours agorootparentAnd we now (hypothetically, in the context of leaking genetic info) know Meryem is Uyghur, James is trans, and Alex is related to a deeply divisive political figure. reply latchkey 13 hours agorootparent> By day, the government pays me to publish their data. reply progman32 13 hours agorootparentYes, my background is in publishing open government data, such as budgets, election results, environmental info, economic data, and government program accountability studies. Not personal information. And yes, I do have strong opinions on how data is to be responsibly managed, hence my participation in this conversation. So, I&#x27;m curious if you have additional thoughts on the matter. reply latchkey 12 hours agorootparentI see where you&#x27;re going with your point, but my gut feeling is none of that data is anything new.We know where Meryem was born (govt records which you probably helped make public), we can read James&#x27; twitter feed and we know the relatives of political figures (except for all the illegitimate children).So yea... I&#x27;m still not seeing the issue here. reply progman32 12 hours agorootparentIf you&#x27;d like to make an argument that my work led to the publication of personal records, please make it more explicitly. I&#x27;d love to hear it fully articulated. Otherwise it&#x27;s hard for me to read it as anything beyond a swipe.We are assuming James posted such details to a public twitter feed. That does not account for the others who did not. The issue in Meryem&#x27;s case is that obtaining birth records is not guaranteed (especially from a foreign country), and that birth location isn&#x27;t the same as genetic ancestry. Regarding Alex:> except for all the illegitimate childrenThat is part of my point. If my absent parent were actually some famous politician, I would personally not want to have that information leaked. Some might not care - that&#x27;s great. My point is a simple one - just because having private medical info exfiltrated is not really a big deal for many people, doesn&#x27;t mean that it&#x27;s ok to give a pass to the parties responsible for the exfiltration. reply latchkey 12 hours agorootparentSorry, it isn&#x27;t a swipe directly intended to be a personal attack of any sort. More that govt&#x27;s, in general, have a habit of leaking personal information for their own benefit.Your original comment was all about hypotheticals, so yes, it opens up the discussion to assumptions.Agreed that, in general, it sucks that stuff leaks out. That said, every time someone brings up 23andme, it feels like one of those \"the govt is going to shut down in a week if we don&#x27;t do something!\" type of headlines that seem to be on repeat... where in the end it turns out that at the last minute, something is done to prevent it, and everything turns into a giant nothing burger. reply progman32 11 hours agorootparentNo worries. Just wanted to make sure I understood.> More that govt&#x27;s, in general, have a habit of leaking personal information for their own benefit.I 100% agree with this.Cheers! reply neilv 13 hours agoprev> The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location.Is 23andMe going to actually be held responsible?I think both our industry and our information infrastructure would be vastly better if companies were forced to be serious about security when they are collecting and holding private data. reply kulahan 13 hours agoparentAs I understand it, only if they can prove some pretty intentional negligence. If some random dude sucks at his job and forget to encrypt so-and-so, or change the default password on such-and-such, it&#x27;s not really the CEO&#x27;s fault. Maybe you could chase after the CTO if they had policies which directly lead to this issue.Again, just as I understand it, that&#x27;s why nobody gets in trouble for this shit. It&#x27;s not really fair to blame any one particular person. Whether or not that can be remedied by modifying the corporate system we operate in somehow, I don&#x27;t know. Probably yes, but that&#x27;s not my skillset at all.edit: but in any case, this was due to people re-using passwords, so I doubt you could realistically blame the company. reply jstarfish 13 hours agorootparent> Maybe you could chase after the CTO if they had policies which directly lead to this issue.> It&#x27;s not really fair to blame any one particular personThese are literally the very circumstances that we were presented with as reason why executive compensation is astronomical. It&#x27;s all that responsibility they have to assume in times like these, right? They&#x27;re supposed to fall on their sword, and whoever replaces them is supposed to make damn sure shit like this doesn&#x27;t happen on their watch. The pay and parachutes ensure they land on their feet.The reason nothing ever changes is because these clowns never get in trouble. If you want that $10M salary, you better make sure everyone under you is doing their part to ensure events like this don&#x27;t happen-- or you get dethroned.Does China still sell melamine-tainted baby formula? We&#x27;ve been conditioned to just let our leaders stay in command after plowing into icebergs-- while they blame and execute the engineers shoveling coal below deck. reply kulahan 12 hours agorootparentNobody is getting paid that much because anyone is realistically expecting a CEO to watch every action taken by every employee. The reason CEOs get paid so much is because it was discovered that luring them to a company with big paychecks results in higher dividends, and we&#x27;ve swung in that direction on investments.The solution isn&#x27;t to randomly start blaming CEOs for things they had no realistic control over, it&#x27;s to swing in the other direction of putting more money towards workers by taking it away from pure growth-oriented goals. reply null0pointer 5 hours agorootparentI feel like the available data is way too scarce to attribute positive results to any individual executive with any degree of statistical significance. Do you know if there’s been research done on this?My perception is that it’s really really hard to differentiate between someone who’s genuinely a force to be reckoned with and someone who’s just in the right place at the right time. After their first success they can hop around between companies from executive role to executive role playing it safe and riding the gravy train just by not fucking it up. I’d be interested if anyone can provide examples of executives that consistently trigger inflections in a company’s performance within say 2 years of joining across multiple companies. I’m genuinely curious. reply philipov 13 hours agorootparentprevI frequently encounter software that doesn&#x27;t let me reuse my password. It is not an excuse. The company should be held accountable that it allowed clients to reuse their passwords; allowing it is negligence.Intent is not a sufficient legal standard to address this epidemic of negligence. We need Strict Liability for data protection. reply sib 10 hours agorootparentYou frequently encounter software that doesn&#x27;t let you reuse a password that&#x27;s been used anywhere else? Or just in the same system? I&#x27;ve not seen the former. reply grotorea 5 hours agorootparentI remember software that will stop me from using stuff like \"password\", how hard is it to grab a copy of any of those password leaks and ban any password found in there? reply adameasterling 2 hours agorootparentIt is not hard and every web service really should implement this sort of check. I’m actually pretty surprised to see so many comments here that aren’t aware of it!See: https:&#x2F;&#x2F;haveibeenpwned.com&#x2F;Passwords reply neilv 13 hours agorootparentprevFrom the perspective of the users&#x2F;customers&#x2F;people the harm was done to, the company is the abstraction that they deal with. Companies can be hit with a billion&#x2F;trillion dollar judgment. The injured parties don&#x27;t care which executive at the company will get a smaller bonus this year -- they&#x27;re not unfairly blaming.Separate from that, if there&#x27;s laws and regulations, the company could also be hit with fines. Officials could also investigate individual culpability for bad behavior by people within they company, but that possibility doesn&#x27;t mean that any kind of holding companies responsible would be unfair. reply leotravis10 13 hours agoparentprevProbably not as I would guess it&#x27;ll be just a wrist slap and nothing more.This not only affects users, but the user&#x27;s relatives&#x2F;loved ones as well. reply nradov 13 hours agoparentprevWhy would 23andMe be held responsible? The article doesn&#x27;t indicate that they did anything wrong. You can&#x27;t really blame them for users refusing the same password on multiple sites. reply candiddevmike 13 hours agoparentprevIs 23andme covered under HIPAA? reply mjsweet 12 hours agoprevIf I were operating a SaaS platform or any other online service, I&#x27;d be inclined to automatically reset passwords for users whose credentials have been compromised in a data breach. Has anyone here developed an automated system to handle this? I&#x27;m particularly curious about how one would automate the gathering of leaked databases and cross-reference user passwords against these lists, both at the point of signup and periodically thereafter. Seems like a compelling problem to solve. reply brap 8 hours agoparentI don’t know if there’s a service that does that, but I do know big tech companies do exactly this for their accounts (user accounts, not just employees). Additionally many password managers will warn you, including the built in ones in iOS and Chrome. reply dboreham 12 hours agoprevHow do you exfil data on 1.3M users by guessing a few passwords? reply SketchySeaBeast 12 hours agoparentWell, it seems they took advantage of a feature that indicates who you may be related to, so they must have guessed Genghis Khan&#x27;s password. reply ganeshkrishnan 12 hours agorootparentMONGOLIAN71682@HOTMAIL.com and password \"SHADOW_RAIDERZ123\" that was easy. reply varenc 11 hours agoparentprevEach valid login+password got the scrapers many many profiles.23andMe has a feature that lets you see people you&#x27;re related to and view their profiles. My guess is this feature had few rate limits and allowed you to view the profiles of people very distantly related. So perhaps with a couple thousand valid account logins you could eventually look up the profiles for 1.3M users. reply worksonmine 12 hours agoparentprevThey&#x27;re not guessing passwords, they have a list of e-mails and passwords from other leaks and are hoping the users are using the same credentials on all their accounts. Since password managers aren&#x27;t mainstream yet it works. reply nemacol 12 hours agorootparentHow do you hide authenticating 1.3+m unique accounts? A distributed system? A mess of VPN&#x27;s? Or they don&#x27;t hide it because the auth system is not checking for 1.3 million auth attemps? reply juunpp 12 hours agorootparentThe latter. Forget tracking auth attempts:> The researcher added that he discovered another issue where someone could enter a 23andme profile ID, like the ones included in the leaked data set, into their URL and see someone’s profile. reply jtriangle 11 hours agorootparentAh, so they were able to use a few accounts, then fuzzed the URLS to victory...Amazingly incompetent. reply gwbas1c 11 hours agorootparentI recently had to explain to a tech lead that you can \"never trust the client,\" because any dedicated party can just curl around your UI and send whatever HTTP request they want. reply dylan604 11 hours agorootparentI remember when this first occurred to me from me deciding that I didn&#x27;t want to click download a series of things on some website where this was the intended use. I wrote a small shell script to curl it for me, and somewhere during the process of writing the script, I realized the true \"power\" of this. Ever since then, GET with search queries were protected against in everything I wrote from that point forward. Luckily, that was in the late 90s, so it&#x27;s been a minute. replyhavelhovel 10 hours agoprevI hope someone investigates whether 23andMe adjusted user profile preferences or exposed this data through new features instead of assuming users chose to share the information now available in this leak. reply tgv 14 hours agoprevSounds like dystopia is nudging closer. But who gives their DNA to a company? reply huytersd 13 hours agoparentPeople that want to know very, very useful information about themselves. reply keep_reading 13 hours agorootparentThey were doing important Parkinson&#x27;s research maybe 10 years ago. I sent in my dad&#x27;s sample and mine. No idea what they got from my dad (it was a voluntary thing that didn&#x27;t give you account access, just participating in their research).I didn&#x27;t have any of the known genetic markers for Parkinson&#x27;s at the time and requested they destory my data and sample. reply mrguyorama 13 hours agorootparentprevVery very useful information like \"Our arbitrary data model that isn&#x27;t exactly based on science says you&#x27;re like 4% eastern european\" reply lo_zamoyski 12 hours agorootparentFodder for those who claim they&#x27;re 1&#x2F;17 Cherokee. reply maximinus_thrax 12 hours agorootparentprevI very much doubt the usefulness of the information you get from 23andme. I would say it&#x27;s useful with a grain of salt when it comes to clinical accuracy, maybe it would enable someone to actually go to the doctor and get properly and accurately tested. But on the other hand, it can also enforce a false sense of security when the tests are clean. &#x27;FDA approved&#x27; does not actually mean &#x27;clinically useful&#x27;[1].From the ancestry standpoint, I think it&#x27;s only useful for a very limited set of individuals&#x2F;scenarios. In my case, I&#x27;m 90% Eastern European which is... kind of basic considering I know where I was born. Yeah, I share a lot of my DNA with all the people who were born in roughly the same geographic area. Big fucking surprise?I never used 23andme and not planning to (the example is from a close friend of mine who did). I think the privacy concerns far outweigh the benefits.But I am interested in genetic testing so if anyone has any pointers for a privacy conscious, not-for-profit (maybe in academia?), non-Law Enforcement friendly entity and preferably does it anonymously, please let me know.[1]: \"Why You Should Be Careful About 23andMe’s Health Test\" - https:&#x2F;&#x2F;archive.ph&#x2F;lpaUU reply huytersd 9 hours agorootparentThe entire new world is very mixed. Ancestry tests are useful for people from North and South America, Southern Europe, India, Australia and New Zealand etc. those are a massive number of scenarios.There’s a lot of health information that’s useful. Propensity to alcohol dependency, propensity for fat retention, propensity for diabetes and high blood pressure etc. You can also download your SNPs and use that information on other sites that give you a lot more, less verified information. reply riffic 13 hours agoparentprevthere are a lot of really valid use cases for genetic testing but to address your point you (these customers, etc) really should be aware of the risk and privacy issues that may occur if that data was compromised. reply ellisv 13 hours agoparentprev> But who gives their DNA to a company?It is amusing to me that this idea was being celebrated here just a few days ago [1].[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37744350 reply Kiro 13 hours agorootparentI&#x27;m sure the people celebrating it in that thread still stand by their opinion. I don&#x27;t see how this changes anything. reply Kiro 13 hours agoparentprevI did and it was worth it even if my DNA is stolen. I&#x27;ve reconnected with many lost and unknown relatives. reply SoftTalker 6 hours agorootparentReally? I think if I got an out of the blue email or other contact from someone saying \"hey, 23andme says we&#x27;re related\" I would ignore it. reply mcpackieh 12 hours agoparentprevUnfortunately, a few of the people I share some of my DNA with. reply Eumenes 13 hours agoparentprevhave you heard of clayton bigsby? reply networkchad 12 hours agorootparentBased Clayton Bigsby enjoyer. reply GauntletWizard 13 hours agoparentprevPeople give their DNA to anyone who happens to be in their presence, or nearby, or come to a place you&#x27;ve been a few days later... You&#x27;re shedding your DNA all the time. reply yebyen 13 hours agorootparentThat&#x27;s a bit different than giving the DNA + cost of sequencing + full identifying info, all signed sealed and delivered, wrapped up in a bow with fully authorized permission to monetize for whatever purpose and share with whomever asks. If someone else is going to the trouble of finding my location, stealing a sample, getting it sequenced, and correlating the data, then I suppose they earned the database record the hard way, didn&#x27;t they! reply progman32 13 hours agorootparentprevI feel this is a straw man. The risk profile posed by this leak is not the same as someone going around and collecting people&#x27;s DNA off the street. The leaked database is a highly concentrated artifact, complete with likely-correct PII across a million people.If people were regularly surreptitiously collecting DNA samples from \"the wild\" at similar scale, this would be a different conversation. reply heavyset_go 12 hours agorootparentprevHow much of that shedded DNA is being sequenced and catalogued in an internationally available online database? reply neilv 13 hours agoprev> The initial data leak was limited, with the threat actor releasing 1 million lines of data for Ashkenazi people.When the evil kind of hackers disrupted a children&#x27;s hospital, did someone ask how they could be as evil as that, then had the idea, \"Hey, how about selling a list of Jewish people specifically?\"(They have to know that no one&#x27;s going to buy that for marketing, but rather for targeting due to hatred and insanity.) reply rhgamble 4 hours agoprevWhy keep calling the principle criminal entity a \"threat actor\", when in fact there is no &#x27;act&#x27; here. They are openly selling stolen data, and it&#x27;s been verified as stolen. Not deflecting the stupidity and criminality of 23andme...how stupid can a corporation working with peoples biological data be...oh wait...yes, repeatedly...its embedded in the business model apparently...operate for N+1 years, then provide a breach. Wish I could wake up from this recurring nightmare of groups with more money than they know what to do with, pretending to move humanity forward, making stupid mistakes. Nonetheless, please stop naming it a \"threat actor\". They are not &#x27;acting&#x27; in any sense of the word. reply pakyr 4 hours agoparent> Not deflecting the stupidity and criminality of 23andme...how stupid can a corporation working with this sensitive type of data beReally? If the article is accurate, 23andMe did not have a security breach; credentials leaked in other breaches were used to compromise accounts that reused those credentials on 23andMe. Now certainly 2FA would have been advisable, but I think it&#x27;s a bit much to suggest this rises to the level of criminality. reply rhgamble 3 hours agorootparentAppreciate the note, and agree &#x27;criminality&#x27; is a bit strong. But this is our biological data at stake. 2FA is a minimum now given the integrated credentials sharing across platforms today. reply yieldcrv 31 minutes agoprevwhat marketplace is this on? I’ve seen the screenshots but I’m not familiar with that forum reply ipaddr 9 hours agoprevWhat site is that posted on?Looking at the data: name, location, dna group. Not very worried reply tsuru 14 hours agoprevNo matter how securely you connect or rotate passwords, the inside-job or supoena risks were too d*** high reply taeric 12 hours agoparentExcept... this leak was from people not having good password hygiene? Right? reply RadixDLT 12 hours agoprevanything that has connections to google is going to be a privacy nightmare reply TradingPlaces 10 hours agoprevMany years ago I got a 23andMe kit. I was about to swab, when I asked myself, “Why is this thing so much cheaper than a lab?” I sent the unused kit back. reply danw1979 14 hours agoprev“user data” … reply mixmastamyk 8 hours agoprevA friend of mine who did this says they don&#x27;t record (any?) personal information and instead give you an id number. Sounds dubious to me. Anyone have any information on how effective their anonymization attempts were? reply jiveturkey 10 hours agoprevYep. Protect your precious bodily fluids people.In other news, this is surprisingly not very well known but california takes, and saves, a DNA sample of any baby born in a CA hospital. There is no consent nor opt-out, not even notification. You can write a letter to have the sample destroyed and sometime later you&#x27;ll get confirmation of such. You can only hope that it wasn&#x27;t sequenced and saved already and&#x2F;or that it was properly destroyed.https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;california-biobank-dna-babies-w...huh. \"many states\" do it, I had no idea. Apparently all 50 states are required to do a genetic screening but I guess above and beyond that some states save the sample.I wonder what would happen if a parent or family member physically intervened to prevent taking the sample. reply miriam_catira 9 hours agoparentThey actually will destroy it,if you have the paperwork. https:&#x2F;&#x2F;www.cdph.ca.gov&#x2F;Programs&#x2F;CFH&#x2F;DGDS&#x2F;Pages&#x2F;nbs&#x2F;nbsconse...(Or you know, give you a certificate that says they destroyed it.) reply pphysch 13 hours agoprev> The initial data leak was limited, with the threat actor releasing 1 million lines of data for Ashkenazi people.> The information that has been exposed from this incident includes full names, usernames, profile photos, sex, date of birth, genetic ancestry results, and geographical location.Not good. Really not good.This is why I never volunteer any PII to link with my DNA. Sampling DNA is not that hard (we leave traces literally everywhere) but credibly linking it to PII is another thing. reply trompetenaccoun 12 hours agoparentAll that ethnicity data will be a goldmine for future genocidal dictatorships. reply badrabbit 14 hours agoprevThere needs to be a term to describe this \"f*k you I got mine, who cares about the future or future generations\" behavior. The normalizing of dna collection, facial recognition, being oblivious to climate issues, screwing up housing market,etc... reply syndicatedjelly 8 hours agoparentMoral hazard perhaps.Or externalities.23andme kept the upside benefits - making money, but doesn&#x27;t have to realize the downside risk - facilitating future conflict.If anyone thinks that&#x27;s facetious, I encourage them to read Erin Kissane&#x27;s description of what went down in Myanmar - https:&#x2F;&#x2F;erinkissane.com&#x2F;meta-in-myanmar-part-i-the-setup. And then think about how they did that without DNA data. reply moretrashplz 13 hours agoparentprevLike, a government? Mine is too busy squabbling about gender identity and whether Pelosi should have her office back or not. reply mistrial9 13 hours agoparentprevthere is a rumor about bank employees during the 2007 crisis, passing a note that said \"IWBTYWBT\" meaning \"I won&#x27;t be there, you won&#x27;t be there\".. just what you are referring to.. reply smeej 13 hours agoparentprevGonna take my downvotes on this, but in my circles, we just call this \"being a Boomer.\"Goes to your head when you&#x27;re the largest generation during your formative years. Nobody has any choice but to do what you say.So you take what you can get and screw over everyone else coming after you.And then you belittle them for resenting you over it. reply edgarvaldes 13 hours agorootparentIn some years the boomer gen will be gone. The behavior, I think, wont. reply tpmx 13 hours agoprevSome background for new readers:The 23andMe founder (and current CEO) Anne Wojcicki is the sister of Susan Wojcicki, until recently a long time Youtube CEO.Anne is also the ex-wife of Google&#x2F;Alphabet founder Sergey Brin. Google&#x2F;Alphabet is also an investor in 23andMe. Youtube is an Alphabet company. reply cooper_ganglia 13 hours agoparentThe Wojcicki-Brin family tree seems like its own mini-map of Silicon Valley!It’s amusing and ironic to me that the co-founder of a gene-testing company has such an interconnected family network within the tech industry. reply toomuchtodo 13 hours agoparentprev> Anne is also the ex-wife of Google&#x2F;Alphabet founder Sergey Brin. Google&#x2F;Alphabet is also an investor in 23andMe. Youtube is an Alphabet company.It was sort of cool that as a 23andme employee some time back (10-12 yrs?), you could use some of Google&#x27;s amenities because of these relationships. reply 4 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Genetics company 23andMe has reported a data breach via a credential stuffing attack, resulting in stolen user data.",
      "The compromised data contains complete names, usernames, profile images, genetic ancestry results, and geographical locations of users.",
      "To prevent such attacks, the firm recommends users utilize two-factor authentication and establish strong, unique passwords for their online accounts."
    ],
    "commentSummary": [
      "The central theme of the discussions revolves around security and privacy issues linked with genetic testing firms, such as 23andMe, as well as topics like data breaches, password security, and liability for data protection.",
      "Different perspectives surface, with some participants advocating for sterner security measures and increased corporate responsibility, whereas others stress on user ownership of data and question the effectiveness of certain security strategies.",
      "The conversations underline the intricate challenges and possible ramifications of dealing with personal and genetic data."
    ],
    "points": 287,
    "commentCount": 256,
    "retryCount": 0,
    "time": 1696616947
  },
  {
    "id": 37790745,
    "title": "Thread-per-core",
    "originLink": "https://without.boats/blog/thread-per-core/",
    "originBody": "Without boats, dreams dry up Posts Tags Thread-per-core Oct 6, 2023 I want to address a controversy that has gripped the Rust community for the past year or so: the choice by the prominent async “runtimes” to default to multi-threaded executors that perform work-stealing to balance work dynamically among their many tasks. Some Rust users are unhappy with this decision, so unhappy that they use language I would characterize as melodramatic: The Original Sin of Rust async programming is making it multi-threaded by default. If premature optimization is the root of all evil, this is the mother of all premature optimizations, and it curses all your code with the unholy Send + 'static, or worse yet Send + Sync + 'static, which just kills all the joy of actually writing Rust. It’s always off-putting to me that claims written this way can be taken seriously as a technical criticism, but our industry is rather unserious. What these people advocate instead is an alternative architecture that they call “thread-per-core.” They promise that this architecture will be simultaneously more performant and easier to implement. In my view, the truth is that it may be one or the other, but not both. (Side note: Some people prefer instead just running single threaded servers, claiming that they are “IO bound” anyway. What they mean by IO bound is actually that their system doesn’t use enough work to saturate a single core when written in Rust: if that’s the case, of course write a single threaded system. We are assuming here that you want to write a system that uses more than one core of CPU time.) Thread-per-core One of the biggest problems with “thread-per-core” is the name of it. All of the multi-threaded executors that users are railing against are also thread-per-core, in the sense that they create an OS thread per core and then schedule a variable number of tasks (expected to be far greater than the number of cores) over those threads. As Pekka Enberg tweeted in response to a comment I made about thread per core: Thread per core combines three big ideas: (1) concurrency should be handled in userspace instead of using expensive kernel threads, (2) I/O should be asynchronous to avoid blocking per-core threads, and (3) data is partitioned between CPU cores to eliminate synchronization cost and data movement between CPU caches. It’s hard to build high throughput systems without (1) and (2), but (3) is probably only needed on really large multicore machines. Enberg’s paper on performance, which is called “The Impact of Thread-Per-Core Architecture on Application Tail Latency” (and which I will return to in a moment), is the origin of the use of the term “thread-per-core” in the Rust community. His understanding of the definition of thread-per-core is probably relevant here. He enumerates three different features of a thread-per-core architecture, of which he says only two are absolutely required for high throughput. This is helpful, because the dispute is really only about the third point, not the first two; if you are using async Rust, you are meeting both of those requirements. The distinction being made is really between two optimizations you can make once you have a thread-per-core architecture, and which are in tension: work-stealing tasks between your threads and sharing as little state as possible between them. Work-stealing The point of work-stealing is to improve tail latency by ensuring that every thread always has work to do. A problem that emerges in real systems is that different tasks end up requiring different amounts of work. For example, one HTTP request may require far more work to serve than another HTTP request. As a result, even if you try to balance work up front among your different threads, they can each end up performing different amounts of work because of unpredictable differences between the tasks. Under maximum load, this means that some threads will be scheduled more work than they can perform, while other threads will sit idle. The degree to which this is a problem depends on the degree to which the amount of work performed by different tasks differs. Work-stealing is a mitigation to this problem: threads with nothing to do “steal” work from the other threads that have too much work, so that they do not sit idle. tokio, async-std, and smol all implement work-stealing with the goal of reducing tail latency and improving CPU utilization. The problem with work-stealing is that it means a task can run on one thread, pause, and then be started again on another thread: that’s what it means for the work to be stolen. This means that any state that is used across a yield point in that task needs to be thread-safe. This appears in Rust’s APIs as futures needing to be Send, which can be difficult for people with a poor view of their system’s state to figure out the best way to ensure. This is why work-stealing is said to be “harder.” At the same time, if state is moved from one thread to another, this introduces synchronization costs and cache misses, violating the principles of a “share-nothing” architecture, in which each CPU has exclusive access to the state it operates on. This is why work-stealing is said to be “slower.” Share-nothing The point of share-nothing is to improve tail latency by keeping data in the faster caches that belong to a single CPU core, rather than the slower caches shared by multiple cores. I want to return to Enberg’s paper, which demonstrates the performance improvements of a share-nothing architecture over a shared-state architecture by benchmarking a new key-value store (which is share-nothing) against memcached (which is shared-state). Enberg shows substantial improvements in tail latency between the two architectures. I like this paper a lot, but I think the way it has been deployed in the Rust community as a soundbite (“71% performance improvement!”) is shallow and unhelpful. To achieve a share-nothing architecture, Enberg’s key/value store partitions the keyspace over the different threads using a hash function, and partitions incoming TCP connections over the threads using SO_REUSEPORT. Then, it routes requests from the thread managing the connection to the thread managing the relevant section of the keyspace using message passing channels. In contrast, in memcached all of the threads share ownership of the keyspace, which is partitioned, and each partition is protected by a mutex. Enberg’s paper shows that using channels over using mutexes can achieve lower tail latency. This is presumably because there are fewer cache misses, as each partition, which is accessed over and over again, stays in only one core’s cache. However, I’m not at all convinced that Enberg’s architecture is dramatically easier to implement than memcached’s. Enberg’s goal is to make use of advanced kernel features and a carefully planned architecture to avoid data movement, it’s hard for me to believe this would be easier than wrapping data inside a mutex. A key-value store is pretty much the ideal case for a share-nothing architecture, because it is fairly trivial to partition the state of the application among diferent threads. But if your application is more complicated, and requires mutating state in multiple partitions in a transactional or atomic manner, this requires a lot more attention to implement correctly. There’s a strong analogy between the advocates of a share-nothing architecture and the hype for eventually consistent databases over databases that enforced serializability ten years ago. Yes, this can be more performant, but at the expense of requiring careful consideration to avoid bugs that result from data inconsistency. It’s also important to note that neither Enberg’s implementation nor memcached use work-stealing. This makes it difficult to relate the core performance claims of Enberg’s paper to Rust’s work-stealing architectures. One wonders what the results would be to just add work-stealing to Enberg’s architecture and memcached’s. In Enberg’s it would increase data movement somewhat, but possibly in a manner which still maximizes CPU utilization. I can’t imagine it would do anything but help memcached. Enberg has carefully designed the implementation in the paper to try to evenly distribute work in advance, using a balanced partition of the keyspace and SO_REUSEPORT. Despite this, there are several sources of dynamic imbalance that would appear in practice: Hot keys will receive more reads and writes, which causes the thread managing their keyspace to receive more work. Some connections will perform more requests than others, which causes the thread managing those connections to receive more work. My understanding of the paper is that the benchmarking framework did not replicate these conditions, which would appear in the real world: each connection performs a consistent amount of work, operating on random keys, so it avoids these sources of imbalance. I wonder what benchmarks which add work stealing would show if these kinds of dynamic imbalance were tested. One can imagine others ways to architect a share-nothing system that may mitigate these forms of imbalance (such as caching hot keys on additional partitions). And some form of work-stealing may be such an optimization even if some tasks stay pinned to certain cores to avoid moving their state. No one would dispute that carefully architecting your system to avoid moving data between CPU caches will achieve better performance than not doing that, but I have a hard time believing that someone who’s biggest complaint is adding Send bounds to some generics is engaged in that kind of engineering. If you’re going to be using shared state anyway, it’s hard to imagine that work-stealing doesn’t improve your CPU utilization under load. rust async tokio || saoirse@without.boatsBlack Lives Matter",
    "commentLink": "https://news.ycombinator.com/item?id=37790745",
    "commentBody": "Thread-per-coreHacker NewspastloginThread-per-core (without.boats) 257 points by ingve 20 hours ago| hidepastfavorite171 comments duped 19 hours agoPersonally I feel like this post misses the forest for the trees.The debate isn&#x27;t about thread-per-core work stealing executors, it&#x27;s whether async&#x2F;await is a good abstraction for it in Rust. And the more async code I write the more I feel that it&#x27;s leaky and hard to program against.The alternative concurrency model people want is structured concurrency via stackful coroutines and channels on top of a work stealing executor.Until someone does the work to demo that and compare it to async&#x2F;await with futures I don&#x27;t think there&#x27;s any productive discussion to be had. People who don&#x27;t like async are going to avoid it and people who don&#x27;t care about making sure everything and its mother is Send + Sync + &#x27;static are going to keep on doing it. reply kllrnohj 18 hours agoparent> The alternative concurrency model people want is structured concurrency via stackful coroutines and channels on top of a work stealing executor.I mean why not just use a thread per connection and not bother with anything fancier at all unless you really truly need to hit those C10M scales? Which I suspect is a very rare need for most things?So many of these articles just go \"kernel threads are expensive\" and blow on past it as if that&#x27;s just inherently true & nothing else needs to be said on it. But they really aren&#x27;t, and unless your work is doing nothing but spawning no-op tasks then the overhead of a \"real thread\" is likely minimal and in exchange the simplicity you get is tremendous. reply VirusNewbie 17 hours agorootparent>I mean why not just use a thread per connection and not bother with anything fancier at all unless you really truly need to hit those C10M scales? Which I suspect is a very rare need for most things?At every larger company I&#x27;ve worked for, that breaks down right away. It&#x27;s really not hard to see how processing some larger proto&#x2F;json&#x2F;soap&#x2F;xml msg can slow the entire system down. reply kllrnohj 16 hours agorootparentThe larger the workload per connection the better thread-per-connection performs relative to the alternatives. So it&#x27;d do the exact opposite of break down under the workload you&#x27;ve outlined. reply fulafel 16 hours agorootparentprevCan you spell out how processing a large message would result in a bigger system slowdown with thread-per-connection than with async? reply mcguire 15 hours agorootparentHave a number of threads greater than the number of cores results in either synchronization costs or longer latency. reply bcrl 8 hours agorootparentLatency is not the only cost of an excessive number of threads: context switches are expensive! Every context switch is a waste of CPU cycles that could be better spent doing actual work for your application. Furthermore, the cost of context switches keeps going up with every new generation of CPU, and I don&#x27;t see that trend reversing any time soon. reply IshKebab 14 hours agorootparentprevNo it doesn&#x27;t. It results in more context switching costs maybe, but I seriously doubt that would make a difference in all but the most extreme cases. reply laurencerowe 15 hours agorootparentprev> At every larger company I&#x27;ve worked for, that breaks down right away. It&#x27;s really not hard to see how processing some larger proto&#x2F;json&#x2F;soap&#x2F;xml msg can slow the entire system down.What&#x27;s the problem with thread-per-connection in this case? It usually works well when application code is moderately heavy since the overhead from threads is very small in comparison.By contrast I&#x27;ve often seen issues in event driven systems without work stealing where heavy requests slow everything else down.I think work stealing is a sensible default for an event driven system in a language like Rust. But I do sometimes find myself wishing for the option to write non-async threaded http servers with zero-copy send. reply Spivak 15 hours agorootparent> without work stealing where heavy requests slow everything else downRight because threads vs async doesn&#x27;t make any sense. You use both, async is your default, free yourself up during io, and is basically the developer friendly abstraction on top of epoll, and then use threads for stuff you actually need threads for. reply laurencerowe 13 hours agorootparentMixing the two is absolutely the right approach in general. But I still find myself wishing it were easier to build a very simple threaded web server in Rust so I could play around with stuff like MSG_ZEROCOPY [1]. Last time I looked there were no non-async http libraries in cargo other than a few toy servers.[1] https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;726917&#x2F; reply fiddlerwoaroof 14 hours agorootparentprevI don’t understand this: context switching takes microseconds, I&#x2F;O latencies are typically in the millisecond range. I’d think thread overhead would be negligible in an I&#x2F;O-bound application (especially if you take steps to reduce the amount of memory per thread) reply jandrewrogers 13 hours agorootparentThe important distinction is between operation latency and operation rate. Modern I&#x2F;O devices are highly concurrent and support massive throughput. A device can have millisecond latency while still executing an operation every microsecond. In these cases, the operation latency doesn&#x27;t matter, your thread has to handle events at the rate the device executes operations. If it is a million operations per second then from the perspective of the thread you have a microsecond to handle each operation. Context switch throughput is much lower by comparison.In these types of systems, you may issue a thousand concurrent I&#x2F;O operations before the first I&#x2F;O operation returns a result. Threads don&#x27;t wait for the first operation to finish, they keep a deep pipeline of I&#x2F;O operations in flight concurrently so that they always have something to do. reply fiddlerwoaroof 12 hours agorootparent> Modern I&#x2F;O devices are highly concurrent and support massive throughput. A device can have millisecond latency while still executing an operation every microsecond. In these cases, the operation latency doesn&#x27;t matter, your thread has to handle events at the rate the device executes operations.This is true for some applications, like an OLAP database or similar. It’s not true for the typical user-facing app where you want to finish requests as soon as possible because a user is waiting and every millisecond costs you money. replygaldosdi 7 hours agorootparentprevWell, at every mid sized company I&#x27;ve been at, it&#x27;s worked great. You can service a fuckton or clients off of one machine even with thread per connection.And frankly, if well architected so much of the logic and business is well separated from the logistics, it&#x27;s not the hardest thing (and by then there plenty of money to fund it) to rearchitect a thread per client model into something more effecient.It&#x27;s hard to go wrong when you create a system initially and stick with the easy lower scale ways, like a single big MySQL (or oracle or postgres or even SQLite or whatever) database, thread per connection, etc. YAGNI, and if you do need it, get it when you do need it reply scottlamb 18 hours agoparentprev> The debate isn&#x27;t about thread-per-core work stealing executors, it&#x27;s whether async&#x2F;await is a good abstraction for it in Rust.I think async&#x2F;await vs stackful coroutines is a more interesting debate [1], but it&#x27;s definitely not the debate. The quote withoutboats discussed is from a linked article complaining specifically about multi-threaded by default and work-stealing.[1] https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;16p47f1&#x2F;the_state_of_... reply withoutboats3 18 hours agoparentprevIn fact there are multiple things in the world that people disagree about. This post addresses a different debate than the one you wanted me to write about, that&#x27;s all. reply duped 18 hours agorootparentThe post you quoted and whose author you insulted at the end was talking about this issue. reply withoutboats3 18 hours agorootparentNo it wasn&#x27;t. Anyone can follow the link and see that it was about preferring non-work-stealing executors, none of the things you complained about. reply efficax 17 hours agoparentprevYou can use async&#x2F;await with channels and restrict yourself to only passing immutable references or copy types through arguments to async functions, communicating w&#x2F; channels for mutable shared types. Like you could build Erlang style \"servers\" that own your mutable types and communicate with them over channels. Or you can Arc> your way through things. Rust gives you the power to do both. reply zozbot234 18 hours agoparentprevAIUI, nothing&#x27;s stopping you from using channels over Rust&#x27;s existing async support. Stackful coroutines are kinda pointless, since at that point you might as well be using separate threads. reply packetlost 18 hours agorootparentGreenthreads have their benefits though, especially for massive concurrency. reply littlestymaar 18 hours agorootparentStackless coroutines are a flavor of green threads though. And without a GC, your stackful coroutines would be using segmented stacks, which is almost indistinguishable to stackless coroutines anyway. reply vacuity 12 hours agorootparentThe important distinction of stackless coroutines-as-async vs. green threads-as-async is the function coloring problem. I think stackful coroutines are largely obviated given more manageable function coloring, structured concurrency, and whatnot that Rust is currently exploring and working on. Actual OS thread-like preemption probably requires a heavy runtime (I imagine Java can do this for their virtual threads?) or OS support, though. (See scheduler activations for the latter. They might actually catch on this time, who knows?) reply littlestymaar 11 hours agorootparentI don&#x27;t think “function coloring” (which is a concept that I find overhyped and uninformative anyway, especially when talking about Rust[1]) has anything to do with the difference between stackful and stackless coroutines: it&#x27;s about whether you let the language insert yield points automatically or force the programmer to spell them out explicitly. We could make the exact same thing for blocking code by the way: just create two keywords `blocking`&#x2F;`block` and mark all stdlib function that do trigger a blocking syscall as `blocking` and force the programmer to use the `block` keyword and transitively annotate the calling function as `blocking` and tada! You have static enforcement of blocking code (aka function coloring) in your language without even having any kind of coroutines.It also doesn&#x27;t have much to do with structured concurrency either, and we could have gotten structured concurrency for free in Rust had tokio decided to cancel tasks handles on drop like futures are. And they even weren&#x27;t that far of doing so[2][1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36497399[2]: https:&#x2F;&#x2F;github.com&#x2F;tokio-rs&#x2F;tokio&#x2F;issues&#x2F;1830 reply vacuity 10 hours agorootparentI get where you&#x27;re coming from, but it&#x27;s a real problem that we have const-async-fallible-panicking-allocating combinatorial explosion. An effects system could abstract all of this away except for the base libraries and the application developers. A big goal of Rust is to be accessible, and all these sorts of \"function colors\" are a hindrance to that goal.> You have static enforcement of blocking code (aka function coloring) in your language without even having any kind of coroutines.And now it&#x27;s annoying to write sync and async Rust. reply littlestymaar 6 hours agorootparent> it&#x27;s a real problem that we have const-async-fallible-panicking-allocating combinatorial explosion.True, but there&#x27;s no free lunch: you either have the ability to express these things in the type system, or you don&#x27;t. I&#x27;m personally very happy rust has `Result` even though it&#x27;s legitimately much more tedious than having invisible exceptions.> A big goal of Rust is to be accessible, and all these sorts of \"function colors\" are a hindrance to that goal.It&#x27;s always a trade-off between usability and expressive power. And not every Rust user have the same priorities. As an application developer, I care less about having allocations expressed in a tractable way than a kernel developer for instance.> An effects system could abstract all of this awayMaybe, but it&#x27;s not clear yet if that&#x27;s something that could be added at this point. Also it would add yet another layer of complexity which is also a factor that needs to be taken into accounts.> And now it&#x27;s annoying to write sync and async Rust.Honestly, this is just a matter of tooling: the annotation could&#x2F;should be transitively added to every caller function (with a boundary at threads spawn) by something like `cargo fix`. reply assbuttbuttass 11 hours agorootparentprevfunction coloring is exactly the stackful&#x2F;stackless division. Stackless functions can&#x27;t be called from a stackful function without special ceremony reply littlestymaar 6 hours agorootparentThis “ceremony” as you call it can totally be handled by the compiler, the same way the compiler deals with the unwinding ceremony without you ever knowing about it. The only reason why we ask the programmer to do it by themselves, is because explicitness is favored.This is exactly the same reasoning as the difference between Rust&#x27;s `Result` and C++ exceptions. They serve the same purpose, they spread into the code base the same way (if on of the function you transitively call can raise an exception, you can raise an exception) but in one case we ask the programmer to to the bookkeeping manually so that it&#x27;s explicit when reading the code.The only meaningful difference between stackful and stackless coroutines is the ability to write recursive function call. If your coroutines are stackless you need to box to avoid the sizedness issue, but in practice it&#x27;s only marginally different from segmented stacks. If you have a moving GC and can just relocate the stack then you performance in case of recursive function call will be better, but it&#x27;s also true about boxing if you have a generational collector with bump allocation. So this is mostly a difference of GC vs no-GC, in a situation where GC is actually improving performance characteristics. replyDarkNova6 18 hours agorootparentprevThe JVM has shown that copying the stackframes can be magnitudes more efficient then context switching via separate threads. Likely, Rust&#x27;s implementation would look different but this route seems too promising not to do basic research on.I mean, is there anybody who seriously thinks that colored functions is the holy grail? reply withoutboats3 17 hours agorootparentJust last month .NET ended a green threading experiment, mainly because the overhead it adds to FFI was too high: https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtimelab&#x2F;issues&#x2F;2398Rust had green threads until late 2014, and they were removed because of their impact on performance.Everyone has done the basic research: green threading is a convenient abstraction that comes with certain performance trade offs. It doesn&#x27;t work for the kind of profile that Rust is trying to target. reply pron 16 hours agorootparentThe performance tradeoffs are very different for different languages. In Java, virtual threads add no FFI costs and virtually no performance impact not because the baseline is lower but because memory management in Java is just so incredibly efficient these days (although that does come at the cost of a higher footprint). So the impact and the tradeoffs are not the same. Allocating heap memory in a very general way is simply faster -- even in absolute terms -- in Java than in a low-level language. Java, unlike .NET or Rust, also doesn&#x27;t allow pointers into the stack, so we can do very efficient copying \"in the shadow\" of cache misses, and that takes care of FFI. reply vacuity 12 hours agorootparent> also doesn&#x27;t allow pointers into the stack, so we can do very efficient copying \"in the shadow\" of cache missesHow does this work? reply raggi 17 hours agorootparentprevYup, the ffi cost is extremely painful. I work on a Go product that is performance sensitive and this exact problem is a constant source of aggravation reply geodel 16 hours agorootparentprevRather than green threads effectiveness in general dotnet experiment proves that sometimes early design decisions are pervasive enough to simply not allow efficient&#x2F;economical way of moving to new paradigm.And yes I agree Rust has its own application domain and they are perfectly right to do things as they see fit. reply kllrnohj 18 hours agorootparentprev> The JVM has shown that copying the stackframes can be magnitudes more efficient then context switching via separate threads....when there&#x27;s literally no work in those threads whatsoever, that is. Unless you have something more substantial than the many \"benchmarks\" out there that are \"look, spawning 10 bajillion virtual threads that don&#x27;t do anything at all but sleep is now super efficient\"? reply jandrewrogers 17 hours agoprevThe original problem thread-per-core was invented to solve ~15 years ago was scalability and efficiency of compute on commodity many-core servers. Contrary to what some have suggested, thread-per-core was expressly about optimizing for CPU bound workloads. It turned out to be excellent for high-throughput I&#x2F;O bound workloads later, albeit requiring more sophisticated I&#x2F;O handling. When I read articles like this, it looks like speed-running the many software design mistakes that were made when thread-per-core architectures were introduced. To be fair, thread-per-core computer science is poorly documented, having originated primarily in HPC.This article focuses on a vexing problem of thread-per-core architectures: balancing work across cores. There are four elementary models for this, push&#x2F;pull of data&#x2F;load. Work-stealing is essentially the \"load pull\" model. This only has low overhead if you almost never need to use it e.g. if the work is naturally balanced in a way that few real-world problems actually are. For workloads where dynamic load skew across cores is common, which is the more interesting problem, work-stealing becomes a performance bottleneck due to coordination overhead. Nonetheless, it is easy to understand so people still use work-stealing when the workload is amenable to it, it just doesn’t generalize well. There are a few rare types of workloads (not mentioned in the article) where it is probably the best choice. The model with the most gravity these days seems to be \"data push\", which is less intuitive but requires much less thread coordination. The \"data push\" model has its own caveats — there are workloads for which it is poor — but it generalizes well to most common workloads.Thread-per-core architectures are here to stay -- they cannot be beat for scalability and efficiency. However, I have observed that most software engineers have limited intuition for what a modern and idiomatic thread-per-core design looks like, made worse by the fact that there are relatively few articles or papers that go deep on this subject. reply withoutboats3 15 hours agoparentThanks for this response, it&#x27;s really interesting.> For workloads where dynamic load skew across cores is common, which is the more interesting problem, work-stealing becomes a performance bottleneck due to coordination overhead. Nonetheless, it is easy to understand so people still use work-stealing when the workload is amenable to it, it just doesn’t generalize wellThis sounds right to me. The reason Rust async frameworks use work-stealing is mainly that it&#x27;s easy to enable at the framework level and will improve performance in a lot of applications, especially those that are not ideally architected. Based on your comment and your self-description on your profile, these are not the kinds of applications you work on.I would be interested in receiving links to more literature. reply gukoff 7 hours agoparentprevWhat is the idea of \"data push\"? reply asd4 19 hours agoprev\"What they mean by IO bound is actually that their system doesn’t use enough work to saturate a single core when written in Rust: if that’s the case, of course write a single threaded system.\"Many of the applications I write are like this, a daemon sitting in the background reacting to events. Making them single threaded means I can get rid of all the Arc and Mutex overhead (which is mostly syntactic at that point, but makes debugging and maintenance easier). Being able to do this is one of the things I love about Rust: only pay for what you need.The article that this one is responding to calls out tokio and other async libraries for making it harder to get back to a simple single threaded architecture. Sure there is some hyperbole but I generally agree with the criticism.Making everything more complex by default because its better for high throughput applications seems to be opposite of Rust&#x27;s ideals. reply amluto 19 hours agoparentI’ve written services like this, and I would never have called them IO bound. They’re not throughput-bound at all. They mostly sit idle, then they do work and try to get it done quickly to minimize use of system resources. Unless they sometimes get huge bursts of work and something else cares quite a lot about latency during those bursts, using more than one thread adds complexity and overhead for no gain. reply withoutboats3 18 hours agorootparentA lot of people on the internet are confused about what \"IO bound\" means, and use it in this incorrect way. reply __alexs 19 hours agorootparentprevIn an era of 10Gb NICs in every server very few things are really IO bound. reply tuetuopay 18 hours agorootparentThe NIC does not really have a lot to do with being IO bound.IO bound means you spend most of your time waiting on an IO operation to complete. Usually writes are bound by the hardware (how fast your NIC is, how fast your storage is, ...), but reads are bounds by the hardware, but mostly by the \"thing\" that sends the data. So it&#x27;s great you have a 10Gbps NIC, but if your database takes 10ms to run your query, you&#x27;ll still be sitting for 10ms on your arse to read 1KB of data. reply withoutboats3 18 hours agorootparentIn this context, we&#x27;re talking about things for which the throughput is IO-bound. You&#x27;re talking about the latency of an individual request.Throughput being IO-bound is indeed about the hardware, and the truth is that at the high end it&#x27;s increasingly uncommon for things to be IO-bound, because our NICs and disks continue to improve while our CPU cycles have stagnated. reply raggi 17 hours agorootparentIn purely practical terms the old system interfaces are sufficiently problematic that for any workload with necessarily smaller buffers than tens of kb, most implementations will get stuck being syscall bound first. Spectre really didn’t help here either. reply vacuity 12 hours agorootparentI think this is where we have to really move towards the io_uring&#x2F;FlexSC approach. reply PaulDavisThe1st 16 hours agorootparentprevAlthough NVMe&#x2F;SSD drives have changed things a lot, any media creation software is still IO bound in the sense that:a. you cannot plan to read data from disk on demand, because it will take too long (still!), and it will almost certainly blockb. you cannot plan to write data to disk on demand, because it will take too long (still!) and it will almost certainly blockc. the bandwidth is still a limit on the amount of data that can be handled. It is much higher than it was with spinners, but there is still a limit. reply elteto 18 hours agorootparentprevThe speed of your NIC doesn&#x27;t matter when you are waiting for an INSERT on a DB with a bad schema. Heck, your DB could be on localhost and you are not even hitting the NIC card. Still the same. reply riku_iki 12 hours agorootparentprev> In an era of 10Gb NICs in every server very few things are really IO bound.for my data crunching project, one core processes about 500MB&#x2F;s = 4Gb&#x2F;s, and I have 64 cores.. reply hjl22 18 hours agorootparentprevThere are plenty of applications that do not run on servers. Lots of IO bound stuff in mobile or desktop apps - waiting for network responses, reading data files on startup, etc. reply kosolam 18 hours agorootparentprev10gb nics and their respective connections are quite expensive. Not many servers have these at all. reply reacharavindh 18 hours agorootparentAs a person with a sysadmin + HPc background having built several clusters recently, this is not true(anymore). 10G NICs are almost as common as Gigabit NICs(both in availability and cost). To give you an idea, we commonly use 10G NICs on all compute nodes, and they connect to a 10G top of the rack switch which connects to services like file servers via 100G connections. The 10G connections are all 10GBase-T simple Ethernet connections. The 100G connections are DACs that are more expensive but not prohibitively so.What cloud providers give you for VMs is not the norm in the datacenters anymore. reply kosolam 16 hours agorootparentEverything is relative. If you are a cloud provider it’s one thing. I’m speaking from the perspective of the small medium business that rents these physical or virtual servers. reply fulafel 16 hours agorootparentprev10Gb ethernet is 20+ year old tech and and used these days in applications that don&#x27;t have high bandwidth demands. 100 Gb (and 40 Gb for mid range) NICs came around 2014. People were building affordable home 40 Gb setups in 2019 or so[1]. But I can believe you that the low-end makes up a lot of the volume in the server market.[1] https:&#x2F;&#x2F;forums.servethehome.com&#x2F;index.php?threads&#x2F;cheap-40gb... reply packetslave 14 hours agorootparentIn my experience, 40gb and 100gb are still mostly used for interconnects (switch&#x2F;switch links, peering connections, etc.). Mostly due to the cost of NICs and optics. 25gb or Nx10gb seems to be the sweet spot for server&#x2F;ToR uplinks, both for cost, but also because it&#x27;s non-trivial to push even a 10gb NIC to line rate (which is ultimately what this entire thread is about).There&#x27;s some interesting reading in the Maglev paper from Google about the work they did to push 10gb line rate on commodity Linux hardware. reply fulafel 1 hour agorootparentI guess it&#x27;ll also depend a lot on what size of server you have. You&#x27;d pick a different NIC for a 384-vCPU EPYC box running a zillion VMs in a on-prem server room than a small business $500 1u colo rack web server.The 2016 Maglev paper was an interesting read, but note that the 10G line rate was with tiny packets and without stuff like TCP send offload (because it&#x27;s a software router that handles each packet on CPU). Generally if you browe around there isn&#x27;t issue with saturating a 100G nic when using multiple concurrent TCP connections. reply packetslave 18 hours agorootparentprevmy $700 Mac Mini has a 10gb NIC. 2.5gb and 5gb NICs are very common on modern PC motherboards. Modern servers from Dell and HP are shipping with 25gb or even 100gb NICs. reply andrewprock 15 hours agorootparentThe cost of 10g is much higher than a single computer. The entire networking stack must be upgraded to 10g. At the very least the Internet device, and possibly the Internet connection as well. It will be cheaper in the cloud than on site. reply packetslave 14 hours agorootparentWell, it depends on what your use case for \"10g\" is. If all you care about is fast file transfers between your PC and your NAS, you can get a small 5-8 port 10gb switch for under $300 that will easily handle line-rate traffic (at least for large packet sizes)If you want 10g line-rate bandwidth between hundreds or thousands of servers? Yeah, I used to help build those fabrics at Google. It&#x27;s not cheap or easy.10g to the internet is more about aggregate bandwidth for a bunch of clients than throughput to any single client. Except for very specialized use cases you&#x27;re going to have a hard time pushing anywhere close to 10g over the internet with a single client. replysurajrmal 19 hours agoparentprevYes exactly. Not everything seeking concurrency is a web server. In an OS, every single system service must concurrently serve IPC requests, but the vast majority of them do so single threaded to reduce overall CPU consumption. Making dozens of services thread per core on a four core device would be a waste of CPU and RAM. reply marcosdumay 18 hours agorootparent> Not everything seeking concurrency is a web server.Web servers should be overwhelmingly synchronous.They are the one easiest kind of application to just launch a lot more. Even on different machines. There are some limits on how many you can achieve but they aren&#x27;t anything near low. (And when you finally reach them, you are much better rearchitecting your system than squeezing a marginal improvement due with asynchronous code.)There&#x27;s a lot to gain from non-blocking IO, so you can serve lots and lots of idle clients. But not much from asynchronous code. Honestly, I feel like the world has gone crazy. reply withoutboats3 18 hours agoparentprevtokio supports a single threaded executor when you really need it, and its not even hard. It&#x27;s called a LocalSet in tokio&#x27;s API:https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;task&#x2F;struct.LocalSet.html... reply basro 18 hours agorootparentThis is true but the rest of the ecosystem is not built for it.If you try to use axum in this way you&#x27;d still need to use send and sync all over the place. reply Kinrany 19 hours agoparentprevI was going to comment on the same quote.The problem is that one may still want concurrency even when a single thread on a single CPU is enough. reply basro 18 hours agoparentprevInstead of Arc and Mutex you&#x27;d be using Rc and RefCell. Wouldn&#x27;t it be just as complex and verbose code-wise?I understand that it is less efficient but in the case you describe wouldn&#x27;t paying for a few extra atomics be negligible anyway? reply monocasa 17 hours agorootparentI&#x27;ve found that practically I&#x27;m more likely to simply use Box, Vec, and just regular data on the stack rather than Rc and RefCell when I esque Arc and Mutex by using a single context. The data modeling is different enough that you generally don&#x27;t have to share multiple references to the same data in the first place. That&#x27;s where the real efficiencies come to play. reply scottlamb 18 hours agoprevRegarding the quote:> The Original Sin of Rust async programming is making it multi-threaded by default. If premature optimization is the root of all evil, this is the mother of all premature optimizations, and it curses all your code with the unholy Send + &#x27;static, or worse yet Send + Sync + &#x27;static, which just kills all the joy of actually writing Rust.Agree about the melodramatic tone. I also don&#x27;t think removing the Send + Sync really makes that big a difference. It&#x27;s the &#x27;static that bothers me the most, and that&#x27;s not there because of work stealing. I want scoped concurrency. Something like .Another thing I really hate about Rust async right now is the poor instrumentation. I&#x27;m having a production problem at work right now in which some tasks just get stuck. I wish I could do the equivalent of `gdb; thread apply all bt`. Looking forward tolanding at least. It exists right now but is experimental and in my experience sometimes panics. I&#x27;m actually writing a PR today to at least use the experimental version on SIGTERM to see what&#x27;s going on, on the theory that if it crashes oh well, we&#x27;re shutting down anyway.Neither of these complaints would be addressed by taking away work stealing. In fact, I could keep doing down my list, and taking away work stealing wouldn&#x27;t really help with much of anything. reply teraflop 17 hours agoparent> I&#x27;m having a production problem at work right now in which some tasks just get stuck. I wish I could do the equivalent of `gdb; thread apply all bt`For all the hate that Java gets, this is something that has Just Worked(tm) for like 25 years, and it&#x27;s enormously helpful for troubleshooting. You don&#x27;t even need a debugger; you can just send the JVM a SIGQUIT, and it&#x27;ll dump a stack trace of every thread to stderr (including which locks each thread is holding and&#x2F;or waiting on) and keep running.I miss this feature in every other language I&#x27;ve worked with. You can even use it for ad-hoc profiling in production: just take a bunch of snapshots, and use grep&#x2F;sed&#x2F;sort&#x2F;uniq to look for hotspots. reply scottlamb 17 hours agorootparentGo does this well, too. iirc the std library has a package for servingso you don&#x27;t even need to ssh in to the server in question.There are libraries for doing the same for any language that just uses kernel threads. It&#x27;s when you throw in async that you really need to reinvent this kind of observability, and Rust isn&#x27;t there yet unfortunately. reply yawboakye 15 hours agorootparentprevi’m slowly coming around to the idea that in most cases (1) big runtimes are a good thing, and that (2) compile-once-run-many was a bad idea. i think our programming languages should create and run software in a highly introspective and interruptible environment. reply vacuity 12 hours agorootparentI don&#x27;t know what you have against compile-once-run-many, but as a Rust user I agree that most software doesn&#x27;t need C or Rust. I think there could probably be a Rust-like and a Java&#x2F;Go-like, two general-purpose languages that cover 99% of software. reply rav 17 hours agoparentprev> I&#x27;m having a production problem at work right now in which some tasks just get stuck.To mitigate this kind of problem, at my company we use a library [1] that allows regularly logging which tasks are running and what file&#x2F;line numbers each task is currently at. It requires manually sprinkling our code with `r.set_location(file!(), line!());` before every await point, but it has helped us so many times to explain why our systems seem to be stuck.[1] https:&#x2F;&#x2F;github.com&#x2F;antialize&#x2F;tokio-tasks&#x2F;blob&#x2F;main&#x2F;src&#x2F;run_t... has set_location(), and task.rs has list_tasks() reply scottlamb 15 hours agorootparentYeah, I can see how that&#x27;d be helpful. In my case, I suspect this is happening inside a third-party library I&#x27;d rather not have to vendor&#x2F;patch extensively. So that method could confirm my suspicion but probably wouldn&#x27;t easily allow me to drill down as far as I&#x27;d like.That said, I think the newest version of the third-party library might have some middleware hooks and&#x2F;or tracing spans. With the right middleware impl &#x2F; tracing subscriber, maybe I could accomplish something similar.This code also should be following the general distributed systems practice of setting deadlines&#x2F;timeouts at the top level of each incoming request, propagating through to all dependent requests, and also setting timeouts on background ops. It&#x27;s not. Fixing that is also on my list and might be enlightening... reply DarkNova6 19 hours agoprevGood writeup I recommend to read more than just the headline.My favorite line: > I have a hard time believing that someone who’s biggest complaint is adding “Send” bounds to some generics is engaged in that kind of engineering.Edit: I fully agree with the comment of \"duped\". I was not aware of the greater context of this discussion. As such, I might have quoted this sentence prematurely. reply newpavlov 18 hours agoprevI believe that having the Send bound as a requirement to allow migration of tasks between executor threads is a clear deficiency of the Rust async system by itself, together with the fundamental issues around async Drop, which prevent implementation of scoped APIs. Similarly to threads it should be sufficient to have Send bound on functions like spawning and sending data through channels. The share-nothing approach is usually used as nothing more than a workaround to hide this deficiency..Selectively pinning tasks to a thread&#x2F;core has advantages and can be really useful in some circumstances, but it&#x27;s a finer discussion, which has little to do with async users dissatisfaction related to Send. reply dpc_01234 17 hours agoprevThis is missing the forest for the trees.There is no one always-right way to get best performance for every program. You can argue about it all you want. Thread-per-core benefits&#x2F;downside is a typical \"it depends\" discussion.The problem is that using `async` in the first place is a premature optimization. 99% of Rust programs are not redis, linkerd and alikes. They are some CLI tools or Web apps that could have been written in Python or Ruby, and they would still be fast enough.So why as a community we abandoned blocking IO Rust and everything is async now, and developers are just doing `#[tokio::main]` by default on everything? reply vbezhenar 17 hours agoparentOne reason might be: if you&#x27;re fine with thread-per-core performance, you probably wouldn&#x27;t want to use Rust in the first place, as there are language with better programming experience trading it for speed. Like python. And if you want to use Rust, probably you need extra performance and you can adopt less convenient style (because you already adapted less convenient language) to get better performance. reply pornel 19 hours agoprevEveryone who has worked with sharding at scale knows the pain when there&#x27;s this one terrible key (your biggest customer, hottest key, largest blob) that just ruins load-balancing of the shards. reply scottlamb 18 hours agoparent100% true, but in fairness work stealing doesn&#x27;t completely solve that either. You often end up locking the shard anyway because lockless data structures are limited and hard. And if you&#x27;re doing something like a key&#x2F;value store, you&#x27;re probably sharding to decide which server to direct traffic to, and so you have the same problem at that layer. (There are things that can help, of course, e.g. .) reply IshKebab 14 hours agoparentprevYeah maybe, but how many people are running these high performance async servers on 2 core machines? reply samsquire 19 hours agoprevThank you for this blog post.I like the thread per core design because kernel context switches are expensive. But userspace context switching scheduling (such as an unbuffered golang channel) for a 64 bits of data at a time makes me uncomfortable too unless it represents a large amount of work backed by a pointer to work data.I think I like to multiplex sockets over threads and multiplex IO over threads so that you can do CPU work while IO is going on and you can process multiple clients per thread.You cannot scale memory mutation by adding threads. You want ideally one thread to own the data and be safe to mutate it uncontendedly.When you send data to another thread, don&#x27;t refer to that data again. Transfer ownership to that thread.If you can divide your request into phases of expansion (map) and contraction (synchronization) you can do intrarequest parallisation.I&#x27;ve been looking into runqueues of go and tokio where you have a local runqueue without a mutex and a global runqueue with a mutex.I&#x27;ve been trying to think how IO threads that run liburing or epoll can wake up a Coroutine or an async task on a worker thread without the mutex.The worker thread is looking for tasks to resume that are unblocked and needs to be notified when there is IO finished. I think you can have a Coroutine that is always runnable to read from a lock free ringbuffer. You can have that Coroutine that checks for finished IO&#x27;s ringbuffer yield if its contended by writes by the IO thread that is trying to make work available to the worker threads. reply ori_b 19 hours agoparent> I like the thread per core design because kernel context switches are expensiveYou can do a millions to tens of millions kernel entries&#x2F;exits per second per core. They&#x27;re on the same order of magnitude as a single digit number of full cache misses.So, expensive, but a lot less expensive than many people assume.Edit: for some (outdated, 2018) measurements, https:&#x2F;&#x2F;eli.thegreenplace.net&#x2F;2018&#x2F;measuring-context-switchi... reply amluto 18 hours agorootparentYou’re replying to a comment about context switches, not syscalls. Linux on x86 cannot do tens of millions of context switches per second per core. (I expect that, at high clock speed, carefully tuned, under ideal and possibly unrealistic conditions, you might get 2M&#x2F;s — it’s been a while since I benchmarked this.)But this is silly — shared nothing will have no substantial difference in the rate of context switches (or of syscalls) compared to a thread-per-core-shared-everything architecture. The architecture that actually loses is many-threads-per-core if it ends up in a small-batch mode in which it context switches once per request or so. reply kldx 19 hours agorootparentprevThat&#x27;s an interesting view and one I agree with. Surely if context switch = expensive is common knowledge for a long time in computing, the kernel people and CPU companies would have tried optimizing it to the fullest, no? reply insanitybit 19 hours agorootparentSyscalls have gotten quite a lot slower after Specter&#x2F;Meltdown mitigations. Though I suspect that if you&#x27;re writing a web service that wants TPC you should just disable these - I&#x27;ve told that to Scylla Cloud before, they have no reason to keep them enabled and plenty of reasons to disable them.The other thing is &#x27;io_uring&#x27;, which is trying to come at the problem by removing context switching altogether by providing a cheap primitive for communicating with the kernel. reply TexasMick 13 hours agorootparentprevI have seen context switches be a killer in some embedded contexts. Especially on FPGA soft core applications where you often are dealing with heavy I&#x2F;O, if you just naively spin up threads for I&#x2F;O then you will suffer heavily. reply cmrdporcupine 19 hours agorootparentprevAnd all our assumptions get blown up with every new hardware generation, too.Hardware engineers are building systems for the applications of today. And the kernel developers are optimizing as well. It&#x27;s all a moving target.Dogma has no place here. reply davidhyde 16 hours agoprev> “The problem with work-stealing is that it means a task can run on one thread, pause, and then be started again on another thread”.The article explains how work-stealing is a way to solve tail latency. I understand tail latency to be caused by tasks that yield (by themselves) after an unexpectedly long amount of time. This cannot be know in advance. The article explains how work-stealing results in cache misses and extra developer constraints like Send, Sync and ‘static.What if the executor only moves a task to another thread after a timeout period has expired? This should result in no latency penalty if things are running smoothly and a constant, low, extra latency when tasks need to be stolen now and again. This would mitigate cache miss issues but alas not the developer overhead of all those multithreaded constraints. reply catern 17 hours agoprevAn important thing omitted in this post, which makes work-stealing less attractive, is that one core being idle can actually improve performance of other cores. Today&#x27;s CPUs basically have a fixed energy budget, and if one core is idle that means more of that budget can go to other cores.In other words, core utilization is less relevant today - what you care about is energy utilization (which is shared across cores).Of course, there&#x27;s a point at which this stops being relevant - if you have multiple sockets for example, this won&#x27;t apply. But work stealing across multiple sockets is so expensive anyway that you would never want to do it. You might as well work-steal across machines at that point - something which is indeed useful sometimes, but usually niche. reply CyberDildonics 13 hours agoparentIf a CPU is being cooled enough to not throttle, it is much more time and energy efficient to use all the cores you can rather than have another core run at a slightly higher frequency.Higher frequencies have diminishing returns and exponential heat loss.You might as well work-steal across machines at that pointShared memory is extremely fast, it crushes using local loopback networking, let alone using actual networking. reply jeffbee 16 hours agoparentprevYou can practice energy-aware scheduling at higher levels, too. If you have to send an RPC and you can choose between multiple peers, choose the one with the coldest CPU temperature. reply Perenti 3 hours agoprevPerhaps the title should mention this is primarily about Rust, and not thread-per-core in general, which would be interesting. reply cryptonector 17 hours agoprev> It’s always off-putting to me that claims written this way can be taken seriously as a technical criticism, but our industry is rather unserious.It&#x27;s not the industry. It&#x27;s people.> What these people advocate instead is an alternative architecture that they call “thread-per-core.” They promise that this architecture will be simultaneously more performant and easier to implement. In my view, the truth is that it may be one or the other, but not both.Thread-per-core is hands-down better for performance. That&#x27;s because you can&#x27;t rely on storing application state smeared on a thread&#x2F;co-routine stack, so you have to instead make all your state explicit, and in the process you&#x27;ll effectively compress it by no longer smearing it on a very large data structure called the call stack. Smaller state == less cache thrashing.The problem with thread-per-core is that you really need async&#x2F;await or coding in continuation passing style in order to make it work. CPS is mostly not an option in most cases, so async&#x2F;await it has to be.Developers should understand the concepts of thread-per-core and thread-per-client and pick the best one for their case. IMO thread-per-core is always better because if your application explodes in popularity then you&#x27;ll really care to make it more efficient, but rewrites are always hard or infeasible, so if you get it right from the beginning, then you win. What I mean by \"pick the best one\" then has to do with the developer&#x27;s skills and productivity and time constraints. Sometimes \"best\" is about what you can manage, not what&#x27;s \"best\" in an objective vacuum that ignores real-world constraints. reply IshKebab 14 hours agoparent> It&#x27;s not the industry. It&#x27;s people.Yes, and this is just naive to think that other industries are somehow bastions of serious debate. reply sakras 17 hours agoprev> The problem with work-stealing is that it means a task can run on one thread, pause, and then be started again on another thread: that’s what it means for the work to be stolen. This means that any state that is used across a yield point in that task needs to be thread-safe.Do any existing \"thread-per-core\" systems actually provide yield points as a thing you can do? Most of my experience is with OpenMP (using both BSP and task parallelism) and a little bit of TBB (also task parallelism). If you want to yield in these systems, you break it up into two tasks.> if state is moved from one thread to another, this introduces synchronization costsThis isn&#x27;t obvious to me. If you&#x27;re moving state, then there is no synchronization because only one thread is touching the state at any given point. Unless we&#x27;re talking about synchronization due to starting a new task? reply exfalso 16 hours agoprevTLDR summary:1. Straw man 2. Talk about an unrelated paper 3. Conclusion: I am smart and those people are dumbOn a somewhat related note: I&#x27;d say 95% of the software I&#x27;ve written was IO bound(and if it wasn&#x27;t at the beginning then the goal was to make it IO-bound), and that remaining 5% does not benefit at all from async&#x2F;coroutines(used them in Haskell, Kotlin(Quasar) and Rust). I&#x27;m very curious about what real-world CPU-bound use cases people have that can benefit from async performance-wise. If you&#x27;re optimizing on that microsecond-nanosecond scale then you shouldn&#x27;t even have yields&#x2F;blocks on your hot paths, and synchronization will at most be done using memfences, so what are we talking about?I&#x27;d also conjecture that if you place your problem domain on the IO vs CPU bound axis, the problems where async would provide performance benefits can invariably be solved by other designs that perform even better (GPU&#x2F;FPGA).Yes I&#x27;m one of those people who thinks coroutines have extremely marginal actual value, and most of that value is the \"feeling of how cool this is\" that people experience when they first learn about the concept. If there was a way to bin the concept altogether I would do it in a heartbeat. As-is, the entire Rust ecosystem is suffering heavily because of it. reply slaymaker1907 13 hours agoparentA lot of the time, the benefit can be from much more controlled scheduling without having to introduce actual threads. A lot of software doesn&#x27;t want to take the overhead of creating platform threads (memory and taking additional CPU time) but does want to do scheduling internally for various CPU bound workloads. I think web pages are often like this. You don&#x27;t really want to hog tons of CPU, but you also want to have guarantees like not blocking rendering when running a user provided regex since said regex could take a long time to run, but in practice that regex will be fast. Even if we want to eventually offload that to a separate thread, async gives us the option to first try evaluating it in the main thread for some number of iterations before offloading it.GPU&#x2F;FPGA programming is kind of irrelevant because as expensive as developing high performance code is for CPUs, costs go up by an order of magnitude for those platforms unless there is some existing library you can utilize (mainly applicable for ML&#x2F;AI). These platforms are also very expensive. It&#x27;s like saying just rent a helicopter if you need to get somewhere quickly instead of asking what \"quickly\" actually means and optimizing accordingly. reply exfalso 14 minutes agorootparentSuspendable computations like regex statemachines are actually a good example use case. However I&#x27;d still categorize this as extremely marginal. I have seen literally zero Rust crates that handle suspendable computations (ofc outside of the scheduler runtime). Also note that by their nature regex statemachines do not actually necessitate the use of async, it&#x27;s effectively syntax sugar on top.My point with GPU&#x2F;FPGA is that if you&#x27;re at the point where this level of optimization matters then you&#x27;re actually dealing with situations where it&#x27;s worth to invest in the big boy tools. Examples are HPC in fintech (low latency trading) and scientific computations, game development, video codecs etc. You know, \"actual\" computations.Webservices are not in this category. Generally speaking with web services your goal is to \"hide in the shadow of IO\". If you max out your network and&#x2F;or database and&#x2F;or filesystem capacity, further CPU optimizations will have literally no effect. I have yet to encounter a web service where this wasn&#x27;t the case.What I do see sometimes with webservices is simply unnecessary compute, bad internal structuring, dynamic dispatch, parallelism overcommit, lack of batching, fragmented apis, fragmented data accesses etc etc all of which appear as CPU capacity saturation and also sometimes as kernelspace overhead in profiles. Async does not help solving any of these issues. And once you do solve them, you reached IO boundness and it doesn&#x27;t matter anymore.Again this is just my experience, and I&#x27;m happy to learn about what kind of web service can utilize coroutines with measurable performance benefits over a managed threadpool. reply TexasMick 12 hours agoparentprevI write software for FPGA soft cores. Even with all this acceleration around the soft core, we need some sort of scheduling and kernel context switches are really a big killer. We have the same issue as web developers, dealing with 50,000 things per second means we need to avoid kernel context switches. reply exfalso 0 minutes agorootparentAvoiding context switches is not a problem async solves. A threadpool popping work items from a queue(or something like lmax disruptors) has the same effect on context switches. The only thing one could argue is that the async runtime&#x27;s threadpool \"homogenizes\" work. Again, yet to encounter a case with web services where this was the issue.I&#x27;m not familiar with FPGA scheduling, are there any resources that explore the issue? I was under the impression it&#x27;s akin to GPU compute where the main bottleneck is the bus. reply lordnacho 17 hours agoprevFirst of all, does anyone know if there&#x27;s a flag that just turns off work-stealing? Seems like you could then decide for yourself how you want Tokio in particular to work.Second, the send + sync thing seems onerous, but from my POV you are encouraged to only pass little messages on channels anyway. I find it easier to just not share anything. If two things need the same structure, they can both subscribe to the ring that gets the messages, and each construct the object for themselves. I find if you have a bunch of Arc> something is wrong. YMMV. reply c-cube 14 hours agoparentYou can configure tokio with feature flags in cargo. I&#x27;m particular you can pick a single threaded scheduler. reply cryptonector 7 hours agoprevWork stealing is like process migration, and as such it has significant overhead and you really need to be picky about when to rebalance by moving loads. reply weinzierl 18 hours agoprev\"This means that any state that is used across a yield point in that task needs to be thread-safe. This appears in Rust’s APIs as futures needing to be Send [..]\"Does that mean that I have to unnecessarily use locking (e.g. ARC and Mutex) even with flavor = \"current_thread\" or am I misunderstanding this? reply necubi 18 hours agoparentNo locking (which provides mutable `Sync` in rust terms) is generally required, but things must be Send (i.e., allowed to move between threads, but not shared). In my experience is mostly an issue when dealing with references, because `&T` is only Send if `T` is sync.However, `&mut T` is Send if `T` is Send. So if you can avoid aliasing your references, you&#x27;re also ok. reply weinzierl 17 hours agorootparentThanks! So does that mean that if I write my code with default tokio and ARC where required and then when I add flavor = \"current_thread\" I can replace my ARC with Rc? reply hjl22 18 hours agoprevI haven&#x27;t touched async Rust, but have used normal Rust a little bit.My understanding is that &#x27;static is program lifetime, meaning either static compile-time data like constant strings, or it is memory leaks. How does this apply to async in practice? Do you need to leak things that you want to make async? reply pornel 16 hours agoparentNo, when used as a bound, it doesn&#x27;t really say how long data has to live. It just forbids use of all temporary references (types that are borrowing from something short-lived they don&#x27;t own).Lifetime requirements simply don&#x27;t apply at all to types that own their data. Or another way to see it is that self-contained types like Vec and String automatically meet every lifetime requirement, regardless of how long or short they actually live.Rust kinda screwed up with terminology here, because the general computing term of \"object lifetime\" applies to more things than the specific &#x27;lifetime concept that Rust applies to references&#x2F;loans. reply pitaj 17 hours agoparentprevMost heap-allocated values like `String` are also static. Essentially it means that anything the value references is not on the stack. reply Georgelemental 16 hours agoparentprev`T: &#x27;static` means that values of the type `T` own all their data (more specifically, their lifetime is not constrained by the lifetime of anything they reference).`&&#x27;static T` is a reference to something that lives as long as the program (static data or leaked memory). reply scottlamb 17 hours agoparentprevIt means spawned futures can&#x27;t contain references that aren&#x27;t &#x27;static. But they can own memory. String for example is &#x27;static. Likewise Vec, Box, Arc, Rc, etc. where T: &#x27;static. reply mikhailfranco 17 hours agoprevErlang&#x2F;Elixir&#x2F;BEAM emphasizes share nothing, allows (encourages) a bezillion user-space processes, then executes with a thread-per-core (by default).The actual number of schedulers (real threads) is configurable as a command line option, but it&#x27;s rare, approaching unheard-of, to override the default.Virding&#x27;s First Rule of Programming ...https:&#x2F;&#x2F;rvirding.blogspot.com&#x2F;2008&#x2F;01&#x2F;virdings-first-rule-of... reply jerf 16 hours agoparentIf Go with its green threads is a step down from Rust in performance, Erlang is two or three steps down from Go. If you step down your performance needs, a lot of these problems melt away.Most programmers should indeed do that. There&#x27;s no need to bring these problems on yourself if you don&#x27;t actually need them. Personally I harbor a deep suspicion a non-trivial amount of the stress in the Rust ecosystem over async and its details is coming from people who don&#x27;t actually need the performance they are sacrificing for. (Obviously, there absolutely people who do need that performance and I am 100% not talking about them.) But it&#x27;s hard to tell, because they don&#x27;t exactly admit that&#x27;s what they&#x27;re doing if you ask, or, at least, not until many years and grey hairs later.But in the meantime, some language needs to actually solve these problems (better than C++), and since Rust has volunteered for that role, that means that at the limit, the fact that other languages that chose to just take a performance hit don&#x27;t seem to have these problems doesn&#x27;t have very many applicable lessons for Rust, at least when it is being used at these maximum performance levels. reply mikhailfranco 16 hours agorootparentAgree, Erlang will never win any performance benchmarks, but that is mostly due to other aspects of the language: big integers, string handling, safer-rather-than-faster floating point, etc.[Elixir is a little better, supporting binary-first for strings, rather than charlists - Erlang is very good at pattern-matching binaries.]Share-nothing and thread-per-core are good for many reasons, including performance, but they also feed into the main philosophies for Erlang development: resilience, horizontal scalability and comprehensibility.As Joe Armstrong said:“Make it work, then make it beautiful, then if you really, really have to, make it fast.90% of the time, if you make it beautiful, it will already be fast.So really, just make it beautiful.” reply ergl 15 hours agorootparentprevThere&#x27;s nothing inherently slow about the way you structure a program in Erlang. Most of the problems come from copying values around when sending them across processes. reply jerf 14 hours agorootparentErlang&#x2F;BEAM is significantly slower than either Go or Rust. Its speed reputation was often misunderstood; it was very good at juggling green threads, but it was never a fast programming language. Now that its skill at juggling green threads is commoditized, what&#x27;s left is the \"not very fast programming language\".It&#x27;s not the slowest language either; it has a decent performance advantage over most of the dynamic scripting languages. But it is quite distinctly slower than Go, let alone Rust. reply MrBuddyCasino 19 hours agoprev> This appears in Rust’s APIs as futures needing to be Send, which can be difficult for people with a poor view of their system’s state to figure out the best way to ensure. This is why work-stealing is said to be “harder.”Is it just me or does this come across as rather arrogant? The problem of &#x27;static lifetimes and send&#x2F;sync constraints resonates among developers, and my impression is not that those were morons. reply withoutboats3 18 hours agoparentI&#x27;m just referring back to my earlier point: people say not doing work stealing would be both easier and faster. My claim is that its one or the other, because to get share-nothing to be faster you need to architect your code in a way that is not easier than making a shared-state architecture thread-safe. There is a parallel sentence with \"slower\" in the next paragraph.I don&#x27;t think people who struggle to get parallel & concurrent Rust to compile are morons, though I don&#x27;t like when they act like the APIs we built for them are ruining their lives. reply eminence32 18 hours agoparentprevFrom my own personal experience, I definitely struggle sometimes to understand if my state is Send or not. So the line you quoted from the article resonates with me. reply Guvante 18 hours agoparentprevHarder is in quotes because it isn&#x27;t necessarily harder.If you would need to do it anyway it isn&#x27;t harder.Less \"people are worked up over doing a little work\" more \"async makes you solve problems earlier you were going to solve anyway\".Similar vibe to the borrow checker. Sometimes it is overly restrictive othertimes you didn&#x27;t actually consider the corner cases when you assumed everything would be fine. reply cmrdporcupine 19 hours agoprevThere is no right answer on this front, and it&#x27;s all about different use cases.It comes down to I&#x2F;O-bound vs CPU bound workloads, and to how negatively things like cache evictions and lock contention might affect you. If your thing is an HTTP server talking to an external database with some mild business logic inbetween, and hosted on a shared virtual server, then, yeah, work-stealing and re-using threads at least intuitively makes sense (tho you should always benchmark.)If you&#x27;re building a database or similar type of system where high concurrency under load with lots of context switches is going to lead to cache evictions and contention all over the place -- you&#x27;re going to have a bad time. Thread per core makes immense sense. An async framework itself may not make any sense at all.But there is no right, dogmatic answer on what \"is better.\" Profile your application.I&#x27;ve said it before, but I feel like the focus of Rust as a whole is being distorted by a massive influx of web-service type development. I remain unconvinced that Rust is the right language for that kind of work, but it seems to do ok for them, so whatever. But the kind of emphasis it puts on popular discussion of the language, and the kind of crates that get pushed to the forefront right now on the whole reflect this bias. (Which is also the bias of most people employed as SWEs on this forum, etc.) reply anonymousDan 19 hours agoparentYeah I agree about the webdev influx. It would be a shame if Rusts utility for systems programming is ruined as a result. reply ThinkBeat 18 hours agoparentprev>I&#x27;ve said it before, but I feel like the focus of Rust as a whole is being >distorted by a massive influx of web-service type development.This. That is quite right and well said reply ndriscoll 19 hours agoparentprevFunny, I was thinking a web app is ideal for thread per core. The application itself generally has very little state outside of a request (other than for the socket listener and database connections, which can be segmented per thread), and what state it has is probably mostly static across requests (so caches don&#x27;t invalidate often). It should be easy to deal with ownership of shared state because there isn&#x27;t any. reply cmrdporcupine 19 hours agorootparentIt all depends on if you think the operating systems scheduler is better than your async framework&#x27;s.There&#x27;s a long tradition of not wanting to \"waste\" threads by blocking on I&#x2F;O. reply geodel 18 hours agoparentprev>.. focus of Rust as a whole is being distorted by a massive influx of web-service type development.True, I think it happened because Rust community quite aggressively sought out those developers to gain market and mindshare. I am not saying it is bad or good but now Rust has to live with unending stream of web related libraries and frameworks of varied quality.And async will remain constant topic of discussion because most of critical base libraries&#x2F;crates etc have taken async first approach. Now it is to a level that normal devs can not write plain sync code for business problems unless they make not using async one of main point of their projects. reply withoutboats3 18 hours agorootparent> True, I think it happened because Rust community quite aggressively sought out those developers to gain market and mindshare.Guilty as charged, honestly. But we were really target high performance web services where Rust really makes sense. And Rust has had a lot of success gaining market share in that area, but most people who work on things like that are writing closed source software and don&#x27;t comment so much on the internet, so what you see online is mostly people blogging about their side project that doesn&#x27;t need to serve a million concurrent connections. reply piperswe 17 hours agorootparentI feel lucky(-ish) that the only web Rust project I&#x27;ve ever really worked on is one that absolutely takes advantage of Rust&#x27;s performance, Cloudflare&#x27;s Pingora. But yeah, CRUD app #64326 probably should just use Rails&#x2F;Django&#x2F;Phoenix&#x2F;Go&#x2F;etc. instead of Rust. reply geodel 14 hours agorootparentThis makes me think of another reason of Rust in web space. It is that Rust rather explicitly tried to create an image of real hardcore language used for serious systems stuff. And it is of course true in technical sense. In larger context however message became more of like if I use Rust my stuff will become serious.So now if someone is told their web app is cute little thing more suited for Rails&#x2F;PHP&#x2F;Go etc. they will feel patronized and try to use Rust despite being unsuitable because their app is going to be serious one. reply cmrdporcupine 13 hours agorootparentI had someone reach out to try to hire me last year to build a website. A neat and useful one, but a website. And they had decided they wanted to use Rust, so they got in touch with me. This person was primarily non-technical, but an entrepreneur. I couldn&#x27;t understand the decision making that led them there, other than: people had told him that Rust was the new good thing. So that&#x27;s what he wanted. replyAr-Curunir 18 hours agoparentprevI haven’t really seen any issues with async affecting other parts of Rust. People are successfully building systems applications, including game engines, cryptography libraries, kernels, command line tools, compilers, etc, all without having to touch async.I maintain large cryptography libraries, and have been completely unaffected by the async business. reply cmrdporcupine 18 hours agorootparentI gripe about it all the time, but it hasn&#x27;t really been an issue for me, and TBH the biggest codebase that I&#x27;ve written outside of work (where we don&#x27;t really use async) ... uses tokio.I think it&#x27;s more a question of emphasis. If you go looking for crates for network I&#x2F;O related things (esp HTTP) on the whole you&#x27;ll find mostly async driven ones. And among them, you&#x27;ll often find they&#x27;re hardcoded for tokio, too. reply kosolam 18 hours agoprevVery nice write up that demonstrates the difference between theory and practice. reply Pxtl 19 hours agoprevI&#x27;ve never touched Rust, but I can see the complaint -- if I have to write my code in a special way so that its state can be marshalled across threads to redistribute load in a way that I do not need and will make the actual end-to-end latency of a single request actually slower in cases where I&#x27;ve got oodles of CPU head-room, I would find that infuriating.I could see this approach making sense in a platform where transferrable state was the default and is rarely broken, but it doesn&#x27;t sound like that&#x27;s the case in Rust?edit: I&#x27;m curious, what&#x27;s the ergonomics like for this? Is it just \"oh, your code won&#x27;t compile if you don&#x27;t add this magic incantation to say it has `Send`?\" Or is it \"your code will fail in intermittent, hard-to-debug ways as state gets mangled during work-steals if you don&#x27;t do this right\"? reply duped 18 hours agoparent> edit: I&#x27;m curious, what&#x27;s the ergonomics like for this? Is it just \"oh, your code won&#x27;t compile if you don&#x27;t add this magic incantation to say it has `Send`?\" Or is it \"your code will fail in intermittent, hard-to-debug ways as state gets mangled during work-steals if you don&#x27;t do this right\"?You write some code that looks like this. struct Server { &#x2F;&#x2F; ... } impl Server { async fn serve(&self) { loop { let server = self.clone(); let message = read_message().await; &#x2F;&#x2F; Each message handler is a new task, seems reasonable? spawn(async move { let result = server.handler(message).await; write_response(result); }) } } async fn handler(&self, arg:Message) -> Result { let this = do_this(); let that = do_that(arg).await; do_the_rest(this, that); } }And everything works fine.Then one day you change the implementation of `do_this` such that the type of `this` is no longer `Send`. You will get a nasty compile error that spawn(...) doesn&#x27;t work because the type created by the anonymous scope in `async move { }` is not Send. The reason is not necessarily obvious (and the error message is unhelpful). If `this` is not `Send` then you can&#x27;t hold it across the `.await` of `do_that(arg).await`, because each .await represents a point in execution where the future may yield and be scheduled onto another thread by the executor.If you can make the type Send then everything is fine. If you can&#x27;t (which is entirely possible!) then you need to change the scheduling of the future to `spawn_local` (or whatever your async executor calls it). This may require adding a bunch of boilerplate to even call `spawn_local` in the first place.This is the issue with Send. It&#x27;s not just adding type annotations. There are subtle ways it infects your code that may cause it to break later in non-obvious ways, because if a type implements Send is not always obvious. reply diath 18 hours agorootparent> And everything works fine.Until the handler needs to access a resource that&#x27;s shared by tasks. reply duped 18 hours agorootparentThat&#x27;s an example of how your code can subtly break reply diath 18 hours agorootparentMy bad, I made the remark before I finished reading the rest of your reply. reply cmrdporcupine 17 hours agorootparentprevOk, but it&#x27;s not Send that&#x27;s doing it, and causing you problems. It&#x27;s using async.You were always sending crap across concurrent execution contexts. But the language syntactically kinda-hid it from you and you got away with not worrying about it. And now it bit you in the ass.In general, this is the problem with implicit&#x2F;masqueraded behaviour. Why back in the day we moaned about REST vs RPC (stop trying to hide that there&#x27;s a network there!). Or why it&#x27;s a bad idea to have languages where \"+\" is a string append operator. Etc. In systems design: surprises suck.Tokio is sending your stuff around, passing it around. So of course it has to be Send. Yeah, you can avoid that by doing thread per-core and just never having things send. But I swear, it&#x27;s going to bite you in the ass in the end anyways. It&#x27;s your control flow that&#x27;s confusing (because it&#x27;s hidden), not the Send.In the end, C++ or etc would just let you hang yourself here, and you&#x27;d be puzzling over a segfault or deadlock later, at 3am.(There are some things that piss me off tho. AtomicPtr being Send+Sync while *T&#x2F;*const T is not makes no sense. Both are equally unsafe, and there&#x27;s no difference in how they behave across thread boundaries, really.) reply duped 14 hours agorootparentThe problem that I&#x27;m trying to illustrate is Send + Async which always comes up in this context, not just Send.> You were always sending crap across concurrent execution contexts. But the language syntactically kinda-hid it from you and you got away with not worrying about it. And now it bit you in the ass.I disagree. Here&#x27;s a more realistic example async fn func (resource: Resource) { let a = foo(resource).await; let b = bar(resource).await; baz(a, b).await }Assume that this isn&#x27;t \"crap\" and the only correct way to implement this code. There are two fundamentally distinct async operations over the same resource and you can&#x27;t call them in parallel.Now say you have an async callstack that looks like this let task = async move { outer(inner(func(resource).await).await).await; }; spawn(task);That call to func() could be buried deep in the callstack instead of inner or outer or anywhere else, and very small changes to the implementation of func can cause it to create a compiler error a mile away from where the problem actually is.I don&#x27;t feel like this is inherent complexity and it has nothing to do with tokio, it has a bunch of related problems with the limitations of Rust, from the stripped-down generator design to lack of specialization for traits.imo these limitations make async code quite fragile to write in practice, and it&#x27;s kind of frustrating to be gaslit repeatedly with \"no it&#x27;s actually good that your code is hard to write.\" reply cmrdporcupine 13 hours agorootparentI don&#x27;t think we disagree. I was saying: it&#x27;s async that&#x27;s the problem, not Sync tracing.Maybe I didn&#x27;t write that clearly? reply creata 19 hours agoparentprev> I&#x27;m curious, what&#x27;s the ergonomics like for this?Your code won&#x27;t compile unless everything is Send&#x2F;Sync as appropriate, and (I might be wrong, but) the lazy path to achieving this is usually wrapping things that might be shared in Arcs and&#x2F;or Mutexes. reply ko27 19 hours agoparentprevI think the argument against thread-per-core as the default can be made simply:- if you are CPU bound, work stealing will be better for most cases- if you are IO bound, thread-per-core might work better, but again, you have enough CPU headroom that the performance doesn&#x27;t really matterIMO, work stealing is a better default to encode into language API reply vlovich123 18 hours agorootparentThe main argument for work stealing is that it’s hard to achieve uniformity of work loads across all threads. The main argument for a single-threaded thread per core design is that it’s easier to code AND performs&#x2F;scales way better than work stealing (including average and tail latencies, TPS etc).IMHO it’s a misconception that this is somehow tied to CPU or IO bound work. Take for example databases. You’d think that that’s the prime “I&#x2F;O bound” use case. Except it’s not. There’s a talk about a DB researcher that analyzed that Postgres spends 70% of its time book keeping things within the database. And that makes sense. I&#x2F;O is done in bulk with the cost amortized over a lot of transactions. That book keeping work? Extremely expensive because you have to acquire locks all over the place, do atomics, memory allocations etc.Atomics and memory allocations are extremely expensive in certain contexts and atomics also have a negative in that your scaling with number of CPUs is sub linear due to hard to remove false sharing of cache lines and CPU stalls to handle the synchronization.On the other hand, a shared nothing approach where you’re not allocating memory in your hot path is very hard to achieve and not suitable for all problems. Nor does everyone need that performance. So the work stealing approach is better in those use cases as it provides reasonable performance and the programming model is simpler in some ways since you don’t have to think about the data path as careful since everything has an Arc &#x2F; Mutex in there. reply layer8 18 hours agorootparentprev> you have enough CPU headroom that the performance doesn&#x27;t really matterBut it would affect power consumption? (Just trying to understand.) reply basro 18 hours agorootparentNo, performance and power consumption should go hand in hand in this case. If you are strongly IO bound, paying for the synchronization is not really going to matter much I believe.There are cases where you can be CPU bound and using the share nothing model would work out to your advantage. There&#x27;s also the case where you only have one cpu core anyway (for example if you want to get all the juice out of a cheap single core VPS) reply cmrdporcupine 19 hours agoparentprevOn the whole the compiler detects when things are &#x27;Send&#x27; & &#x27;Sync&#x27;. If you write your program thread-safe, you won&#x27;t have issues.And that&#x27;s the crux of the matter: people are griping on the whole because maybe Tokio async is hard when it puts Send&Sync demands all over the placer, but the reality is that writing safe concurrent code of any kind is hard. It&#x27;s not intuitive, and the problem is that async makes them feel like it&#x27;s happening automagically and just \"taking care of it\" -- but it&#x27;s really not. You need to know what you&#x27;re doing, and the compiler is just helping you here.Yes, you can hide that by going thread-per-core and that could eliminate the need for Send in some circumstances (not all). But it might come back to bite you, architecturally, in the long run. reply insanitybit 19 hours agoprev> Some Rust users are unhappy with this decision, so unhappy that they use language I would characterize as melodramatic:Seriously. I&#x27;ve said this before, the way people talk about these problems is so dramatic. I&#x27;ve written 10s of thousands of LOC in Rust and you&#x27;d think, from these blog posts, that I must be miserable. I am not. I am quite pleased with it.It&#x27;s so funny to me that Thread Per Core is seen as the holy land. Like it&#x27;s just objectively better. It is not. TPC is quite tricky, indeed. Scylla had a great post recently talking about how they were suffering performance penalties due to accidentally sharing some memory - this is the sort of thing you have to be super careful about when leaning into TPC. \"Hot partitions\" is another one.I&#x27;m going to refrain from commenting more (this article looks excellent and I want to read the citations) but I&#x27;m very very happy to see this post. I think far to little credit is given to the effort put into getting a novel language like Rust to support this so well. reply Waterluvian 19 hours agoparentThis kind of attitude exists everywhere, but good gravy does it exist strongly in Software Development. I feel like every software developer could benefit from a summer tarring rooftops to mature their idea of what \"killing the joy\" of doing work feels like. reply insanitybit 19 hours agorootparentA big problem with software dev is the lack of rigor, imo.> It’s always off-putting to me that claims written this way can be taken seriously as a technical criticism, but our industry is rather unserious.From the article, this resonates so strongly with me. Instead of people reading papers, talking seriously, it&#x27;s so hand wavy and weak. reply Waterluvian 19 hours agorootparentMy general feeling is that I think people lean on how they feel about these problems because building an experiment and quantifying the problem to make a solid case for it actually being a problem worthy of resources and remediation is... tedious and unfun?Not to say these people don&#x27;t exist. But I think they exist in lesser numbers. Even I&#x27;m guilty of this. I know it... so I do it... but it&#x27;s very unfun and tedious and... well I&#x27;m paid to do it so I can&#x27;t complain. reply aeonik 19 hours agorootparentI think it&#x27;s more then tedium and fun that blocks the rigor. Though, those two properties definitely hold a fair number of people back.I&#x27;ll use myself as a research subject: I really like the scientific method, and don&#x27;t mind a long grind. But the main barriers I run into with software fall into at least two major categories: 1. Compatible datasets or software: it takes a LOT of manual effort to collate good data sets, and because I am a software engineer, I want to automate these things, then I end up in tarpits and rabbit holes, building bridges rather than testing hypotheses.2. Abstraction fatigue, There is so much vocabulary that we use, and we switch layers so quickly and in different contexts that I find it very time consuming and opaque to harmonize all the concepts. Real life pressures don&#x27;t always afford the ability to really understand an entire stack, which I posit is necessary for a certain level of Rigor.For example, right now I&#x27;m trying to Grok Clojure Transducers, and some folks are saying they are the same things as Monads. Are transducers a better pattern? Are they the same? Different? How much do they overlap?I have feelings relating to dynamic types vs static types. I have feelings about wrapping implementations. I have feelings about the JVM vs the Haskell compiler vs the V8 JavaScript engine. Also, I get feelings related to polymorphism, metaprogramming, dependent types, homoiconicty.But nothing fully baked. To call my feelings even 10% baked would be charitable. I can&#x27;t currently describe all the relationships, or why my brain is currently zeroing in here in full fidelity. Only parts of it, and I remain in a state perplexity for now.The formality of Category Theory and Abstract algebra sounds like it would be really nice here, but it&#x27;s going to take me years to get to to speed in those domains, and I&#x27;m not even sure they have the theorums to compare these two patterns! reply mulberrybush 16 hours agorootparentThis video [1] explaining Clojure transducers is excellent. No terminology, no analogies with category theory - just code getting built up in a repl.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=TaazvSJvBaw reply insanitybit 19 hours agorootparentprevI&#x27;m going to avoid derailing into a \"tech has these problems\", respectfully, as I think the core of the post is really worthwhile and I could talk about tangentially related things for too long and be too distracting. I think we are likely, overall, in agreement. reply withoutboats3 18 hours agorootparentprev> A big problem with software dev is the lack of rigor, imo.It&#x27;s amazing to me how much more informed you can seem than everyone else if you just read the thing everyone is quoting. reply insanitybit 15 hours agorootparentIndeed. I have brought this up when people reference \"premature optimization is the root of all evil\" and mistakenly attribute a false meaning to it. What an approachable paper, what is the excuse for not simply reading it? To boil it down to one quote and then to use that quote to dogmatically advocate for practically the opposite of the point is... sigh.I&#x27;ve also been banging the \"you are using &#x27;IO Bound wrong&#x27;\" drum for years and still this persists.HN is a daily example of this. Reading the blog post immediately highlights all of the comments where users seemingly did not. reply pjmlp 16 hours agorootparentprevA side effect from those calling themselves enginners without having a proper Software Engineer degree where this kind of stuff is actually taught. reply insanitybit 14 hours agorootparentAnd here I am with no degree at all :) I suspect I&#x27;ve read quite a few more papers than your average graduate, however. reply taeric 18 hours agorootparentprevI was going to say the same thing. My gut is it exists as strongly in other places, but that we don&#x27;t have direct exposure to their social zones to see it.And it isn&#x27;t like rust is particularly hit by it, either. You&#x27;d think people writing PHP or Java hate life, if you only went by what you are likely to see in our social sites. reply safety1st 18 hours agorootparentThe PHP developers I speak to these days seem pretty happy to be using PHP. The ones who fly into a rage over it seem to be people who don&#x27;t actually use it! reply cesarb 18 hours agorootparent> The ones who fly into a rage over it seem to be people who don&#x27;t actually use it!Well, that does make some sense: if something bothers you so much that you&#x27;d \"fly into a rage over it\", you would avoid using it as much as possible (and PHP is not like JavaScript which has no real alternative). reply taeric 18 hours agorootparentThe annoying thing is more that a ton of the ones that fly into a rage are also ones that have never used it. There is a ton of dog-piling in what people complain about. reply cesarb 17 hours agorootparent> The annoying thing is more that a ton of the ones that fly into a rage are also ones that have never used it.Even that does make some sense: if, on a first look, you see something you deeply dislike, you probably will also avoid using it in the first place.As a personal example, I never learned Go because, when I first looked at it (IIRC, it was when I had to use it to run a Heartbleed detector), I deeply disliked the way it required developers to organize their source code (a single per-language directory mixing all projects together, instead of the per-project directories I have always used); I understand this might have changed later, but in the meantime I invested my time in learning another programming language, and so far haven&#x27;t found a need to look at Go again. reply taeric 15 hours agorootparentIsh? You are, of course, more than welcome to not like things. Dislike them, even. Really, you are more than welcome to dog pile on things, freedom and all of that. It is still annoying and generally not a healthy activity, from my point of view. replymcronce 16 hours agorootparentprevYour analogy really hits. I don&#x27;t mind doing construction in general (I quite like doing it once in a while), but roofing absolutely sucks no matter how you cut it reply efficax 17 hours agoparentprevi&#x27;ve written about 30k lines of async rust this year alone and haven&#x27;t found the horror of Send + Sync + &#x27;static to impact me much at all. You just have to think about things for a second sometimes. reply insanitybit 14 hours agorootparentTBH most of the time you don&#x27;t have to think at all. Compiler says \"you need those annotations\" and you copy&#x2F;paste them and then you move on. It&#x27;s really incredible to me that people are acting like this is some extremely onerous process, like writing a dozen characters causes some sort of incredible pain. reply api 19 hours agoparentprevI&#x27;m pleased with it too. Seriously. When I learned it it took me a bit to get lifetimes and borrows and stuff but once I did I got it and I rarely have to \"fight\" it.Running in an IDE hooked to rust-analyzer helps a lot too since you get pretty instant feedback if you get something wrong most of the time. I have this suspicion that at least a few of the people who hate a lot of languages with more complex type systems or large stdlibs (e.g. Go, Java, C#) are trying to edit them in a plain vanilla text editor without these features. This would require you to memorize way too much shit. Why? Modern machines have gigabytes of RAM. Run a language server. reply VirusNewbie 17 hours agoparentprevI love this stuff, and while I consider myself informed, i&#x27;m not an expert.However, I&#x27;ve bantered a bit with Scylla&#x27;s CTO and others about how I would regularly run into issues with Scylla because they didn&#x27;t use TPC, and I&#x27;d see hot keys that would suffer performance because they only let one core manager a subset of keys...So, while I can&#x27;t make an authoritative statement, I think TPC is better overall... reply jacknews 18 hours agoprev [–] Paints the &#x27;rust community&#x27; as quite restrictive, and not a place I want to be, IMHO. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Rust community is debating the default usage of multi-threaded executors in asynchronous programming, with some advocating for a \"thread-per-core\" architecture.",
      "The article delves into \"work-stealing\" and \"share-nothing\" architecture concepts, exploring their implications on system performance. It references Pekka Enberg's paper that illustrates share-nothing architecture's advantages.",
      "The author raises doubts about the feasibility and simplicity of implementing Enberg's architecture versus traditional methods, concluding that work-stealing may prove beneficial for systems with a shared state."
    ],
    "commentSummary": [
      "The texts encompass discussions around programming languages, concurrency models, asynchronous programming, alongside the difficulties of debugging and troubleshooting.",
      "Specific topics highlighted include thread-per-core architecture, work stealing executors, stackful coroutines, data processing, high-speed network interface cards, and the Rust programming language.",
      "There's an emphasis on the importance of resource management efficiency, performance trade-offs consideration, robust debugging tools, and a need for more stringent technical criticism in the software development sector."
    ],
    "points": 257,
    "commentCount": 170,
    "retryCount": 0,
    "time": 1696600052
  },
  {
    "id": 37789371,
    "title": "Use an old tablet as an extra monitor",
    "originLink": "https://github.com/alex028502/extra-screen",
    "originBody": "but only for terminal and curses apps",
    "commentLink": "https://news.ycombinator.com/item?id=37789371",
    "commentBody": "Use an old tablet as an extra monitorHacker NewspastloginUse an old tablet as an extra monitor (github.com/alex028502) 240 points by alex028502 22 hours ago| hidepastfavorite125 comments but only for terminal and curses apps seizethegdgap 19 hours agoFor Windows, the paid program SuperDisplay will also allow you to use an Android device as a second screen, works wireless or over USB. My Galaxy Tab S7+ is great as a second monitor.https:&#x2F;&#x2F;superdisplay.app&#x2F; reply lkois 19 hours agoparentOr the free Spacedesk, does the same. reply lvncelot 19 hours agoparentprevA good SuperDisplay alternative is something I really miss on Linux. Even over wifi, the latency is imperceptible to me, and being able to use the pen input (with pressure and tilt) is the cherry on top. reply stonecharioteer 3 hours agoparentprevI also have an S7+, and I&#x27;ve been very happy with the device. How do you feel about it in 2023? I&#x27;m tempted to get the S9 Ultra as an upgrade but I&#x27;m on the fence right now. reply butz 19 hours agoprevGot to mention that you can use your tablet on Linux GNOME DE not only for terminal: https:&#x2F;&#x2F;www.omgubuntu.co.uk&#x2F;2022&#x2F;06&#x2F;use-ipad-as-second-monit... . Still waiting for even better solution, like streaming games to such second tablet \"monitor\". reply seiferteric 9 hours agoparentJust tried this but got \"this device needs iOS 15 or later\" when trying to install Microsoft rdp client, which isn&#x27;t available for my old iPad. So I guess you can&#x27;t actually use an old iPad for this. But maybe I can find another rdp client that will work. reply bluearchon 3 hours agorootparentDo you have the RD Client app installed on an iOS 15+ device? If you ‘own’ the app (and the developer allows it, I think) the App Store will let you install the latest supported version on an older iOS. I was able to install RD Client on my iOS 10 iPad that way a little while ago, but maybe something’s changed in the meantime. reply bogdart 15 hours agoparentprevIt doesn’t work on X11, and the cursor is not showing. But if don’t need it, works pretty well. reply elkos 18 hours agoparentprevdoes this work in KDE too or is there a similar solution? reply butz 17 hours agorootparentHere&#x27;s what I found for KDE, but did not test it myself: https:&#x2F;&#x2F;bugs.kde.org&#x2F;show_bug.cgi?id=454645#c5 reply bogdart 15 hours agorootparentIt works for me, but quite unstable. reply trevcanhuman 15 hours agoprevI&#x27;ve used Weylus [0]. It works over LAN, lets you control the mouse from your tablet. Sometimes it&#x27;s laggy, but you can configure the resolution so it&#x27;s not using too much bandwidth. I&#x27;m not sure if it&#x27;s stable at all. Haven&#x27;t used it on a regular basis.[0] https:&#x2F;&#x2F;github.com&#x2F;H-M-H&#x2F;Weylus reply DakotaR 14 hours agoparentIn the same vein, Remote Touchpad [0] is fantastic if you don&#x27;t need an extra screen.[0] https:&#x2F;&#x2F;flathub.org&#x2F;apps&#x2F;com.github.unrud.RemoteTouchpad reply gourneau 15 hours agoprevIf you are on Windows and have extra laptops of devices hanging around SpaceDesk https:&#x2F;&#x2F;www.spacedesk.net&#x2F; to a great free app (not open source). I use it with on my Windows Dev machine (WSL2 FTW) and use old laptops as external displays. It works well even on WiFI. reply PickledJesus 13 hours agoparentThanks, I just got SpaceDesk working on a cheap Amazon tablet over USB-C (after realising I had to set PTP mode on the tablet...) Should work really nicely as a second monitor when travelling, I have it on 60fps and high settings and the latency is barely perceptible. reply duffyjp 14 hours agoparentprevI was excited seeing iOS 9.3+ on their requirements listing, but after digging my useless but 100% functional iPad 2 out of storage it won&#x27;t install the app. :(I do use the built-in iPad as a second screen thing in MacOS with a still supported iPad on occasion and that works quite well. reply CYR1X 18 hours agoprevWould be better if the LVDS ribbon cable connectors for all of these devices was more standardized, and you could just buy an adapter to HDMI&#x2F;Display Port. These actually exist but AFAIK there isn&#x27;t just one LVDS ribbon cable standard or even close to one. reply sakopov 13 hours agoprevOn a similar note, you can use your old phone as a Streamdeck alternative using TouchPortal [1]. It&#x27;s not free, but it won&#x27;t cost you much and it works surprisingly well.[1] https:&#x2F;&#x2F;www.touch-portal.com&#x2F; reply cgriswald 8 hours agoparentThis seems to be a free, open source software that does something similar: https:&#x2F;&#x2F;stream-pi.com&#x2F;According to the video I&#x27;m currently listening to, it only has a Linux client currently, but has Windows and Linux hosts.Edit: I&#x27;ve played with this a bit with a surface pro running Linux as a client and Windows as host and the thing holding it back at this moment is lack of plugins. I use Stream Deck to manage my gaming sessions (Steam, Discord, Voicemod soundboard and voices, occassionally OBS, game launches, etc.) and as-is for my purposes this can really only manage OBS and things that have configured hotkeys. reply cracauer 18 hours agoprevTablets should have a HDMI&#x2F;Displayport in so that you can directly use them as displays. reply zackmorris 18 hours agoparentI&#x27;d even go one step further: we should have had a standard communications protocol like TCP for all devices. So a display would show up as just another device that we could use to read&#x2F;write bytes. All devices would have a standard queryable HTTP&#x2F;HATEOAS self-documenting interface. And HDMI&#x2F;DisplayPort or USB A&#x2F;B&#x2F;C&#x2F;...&#x2F;Z would all use the same protocol as gigabit ethernet or Thunderbolt or anything else, so the bandwidth would determine maximum frame rate at an arbitrary resolution. We could query a device&#x27;s interface metadata and get&#x2F;send an array of bytes to a display or a printer or a storage device, the only difference would be the header&#x27;s front matter. And we could download image and video files directly from cameras and scanners as if they were a folder of documents on a web server, no vendor drivers needed.There was never a technical reason why we couldn&#x27;t have this. Mostly Microsoft and Apple blocked this sort of generalization at every turn. And web standards fell to design-by-committee so there was never any hope of unifying these things.Is it a conspiracy theory when we live under these unfortunate eventualities? I don&#x27;t know, but I see it everywhere. Nearly every device in existence irks the engineer in me. Smartphones and tablets are just the ultimate expression of commodified proprietary consumerist thinking. reply takluyver 17 hours agorootparentIn fairness, there are standardised protocols for a lot of these things already, even if they&#x27;re not all part of one giant meta-protocol. Cameras in particular have mostly appeared as a folder full of files, with no need for special drivers, for something like 20 years.There&#x27;s definitely no need to invoke a conspiracy for the lack of &#x27;one protocol to rule them all&#x27;. It&#x27;s often hard agreeing on a standard even for a relatively limited topic - trying to agree on one for all electronic communications for all devices is probably impossible. reply lexlash 15 hours agorootparentThe meta protocol exists! Sort of. Check out the USB-C specs, which tried to answer a ton of this. It’s taken years for power delivery to reach the point where I don’t feel compelled to carry a USB-C power meter to check cables and chargers in the wild. My Switch still requires some out of spec signaling to charge&#x2F;dock properly.Meanwhile, half of the stuff I get off AliExpress only charges from A to C cables due to a missing resistor.I don’t think the markets (yet) incentivize implementations. Like how when my mortgage gets resold, autopay will only transfer over if it’s once a month; anything more complex and I have to endure a new account setup and a ton of phone trees. Same with paperless settings. The result? I just live with the MVP. reply marwis 12 hours agorootparentprev> There was never a technical reason why we couldn&#x27;t have this. Mostly Microsoft and Apple blocked this sort of generalization at every turn.On the contrary, Microsoft tried really hard with UPnP&#x2F;PnP-X&#x2F;DPWS&#x2F;Rally&#x2F;Miracast*&#x2F;etc but nobody was interested.*BTW any Windows 10+ device can act as a Miracast sink (screen) so you can link Windows laptops&#x2F;tablets as extra screens without any additional software. reply lexlash 15 hours agorootparentprevExtending your simile, some devices need the equivalent of UDP in order to function within the size&#x2F;power envelopes that make them useful. Bluetooth vs the nRF24L01+.There are standards like this in highly interoperable systems, but there’s a cost paid. USB-C power delivery negotiation (beyond the very basic 5V3A resistor that people omit) is roughly as complicated as gigabit ethernet. That compute has to come from somewhere and it turns out customers won’t even pay for that 5V3A resistor - they’ll just use A to C cables and replace it when it “won’t charge” from a compliant charger. :) Average person probably only cares that USB-C can be flipped and that the connector feels less brittle than microUSB.UPnP exists. Lots of what you describe exists. Between bugs in implementations becoming canon and a lack of consumer interest, no real conspiracy required. At least smartphones and tablets are trending in a good direction - Apple’s latest supports basic off the shelf USB-C Ethernet, displays, hubs, and so on. reply mixmastamyk 16 hours agorootparentprevAgreed in general. However, I wouldn&#x27;t stop anyone but having my monitor traffic go over the network would lead to a lot of congestion, especially wireless. Prefer a separate cable as the grandparent alluded. reply mcpherrinm 13 hours agoparentprevYou can plug a USB HDMI capture dongle into tablets and do this.Any webcam viewer would probably work to view it, though there&#x27;s dedicated apps intended for this like https:&#x2F;&#x2F;orion.tube&#x2F; on iPad. I know there&#x27;s options on Android but don&#x27;t have a modern android tablet to test them. reply radicality 11 hours agorootparentDo you know how come that app doesn’t work on the IPhone 15 Pro?I don’t have the iPad, but just recently got the 15 Pro, and it’s able to do a bunch of things via the usbc port (wired Ethernet, SD card reading, driving a Pro Display XDR etc), but I wasn’t able to do something like that Orion app is showing.Was thinking of pretty much same use case as shown in the app, where I could plug in an external camera and use the phone as a high resolution &#x2F; high-nit viewer display. Are these apis only for iPadOS because the iPhones are missing some required hardware for it? reply Gosper 7 hours agorootparentI know, I&#x27;d love to use my phone as a display via capture card so I don&#x27;t have to carry a portable monitor to troubleshoot headless boxes.The developer says the 15 and 15 Pro are only missing software, the hardware is capable:> I’m sad to say that we’ve confirmed with Apple that it will not be working with the iPhone 15. But this can be fixed in software, so feel free to file a feedback request for UVC support on iOS!https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;apple&#x2F;comments&#x2F;16qzdtx&#x2F;hi_reddit_we... reply radicality 6 hours agorootparentAhh, that sucks, hopefully future iOS will also have uvc support. replyboredemployee 20 hours agoprevThats a cool idea, I have a Fire tablet (and a Kindle) that I still don&#x27;t know why I bought it. reply citiguy 17 hours agoprevI&#x27;ve used Duet for this in the past. Works great by allowing me to extend my laptop screen with my ipad screen. https:&#x2F;&#x2F;www.duetdisplay.com&#x2F; reply seltzered_ 16 hours agoprevWorth mentioning this discussion that honed on latency specific when using Linux (Wayland) as a host os : https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31409010 -> https:&#x2F;&#x2F;tuxphones.com&#x2F;howto-linux-as-second-wireless-display... (2022) reply thanatos519 21 hours agoprevGood idea. I did this with bash and awk and xev and xdotool instead of a custom program.You can always use screen&#x27;s cut-and-paste for stuff within screen, and screen&#x27;s copy buffer and xclipboard for the rest. reply mekster 10 hours agoprevGenuinely curious but why would people put 2 displays side by side so that your neck would always be bent to a side?That totally looks like a tiring solution. I never do that but put the main display (which is an external monitor of my laptop) parallel to the keyboard and my laptop to the side so I will be facing forward naturally. reply SkyPuncher 9 hours agoparentI had side-by-sides at an old job. I found I switched back and forth often enough that I wasn&#x27;t really hurting my neck. reply kristopolous 9 hours agoparentprevI put multiple displays in portrait mode maybe 10 years ago and have never looked back. reply eastbound 10 hours agoparentprevIn France, my OSHA auditor actually requests that if there are two screens, they be put with the centerline in the middle (I bet it’s a clerical error, but it’s funny to see clerical errors that recommends the opposite of the healthy solution). reply squarefoot 12 hours agoprevIf manufacturers released enough details about their devices and drivers, then unlocked the bootloaders, we could do a lot more things than a 2nd monitor with old tablets. There are piles of them taking dust in drawers, or worse in landfills because of forced obsolescence. reply fudged71 19 hours agoprevAny options for an ancient iPad? reply ascagnel_ 18 hours agoparentIf you&#x27;re on a recent macOS + iPad, there&#x27;s Universal Control[0] (I use this as a way to have chat&#x2F;mail on a second monitor). If you don&#x27;t mind some noticeable latency, you can use it as a second display via Sidecar[1]. Finally, you can do the same thing described in the article with any terminal emulator app and SSHing into the remote system (I&#x27;ve had luck with Prompt[2], which is available as a one-time $15 purchase).[0]: https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT212757[1]: https:&#x2F;&#x2F;support.apple.com&#x2F;en-us&#x2F;HT210380[2]: https:&#x2F;&#x2F;panic.com&#x2F;prompt&#x2F; reply zyxin 11 hours agoparentprevFrom the Readme, their eventual plan for the project is to be able to serve the client through the web browser which would mean that almost all tablets would be supported. reply wkipling 10 hours agorootparentDidn&#x27;t Apple drop support for old iOS devices so they can&#x27;t access the web anymore. Safari is useless even for local sites I believe. reply zyxin 8 hours agorootparentIf you&#x27;re referring to the outdated certificates, I installed Let&#x27;s Encrypt&#x27;s ISRG Root X1 Certificate onto my old iPad 4 and that seems to have taken care of it. Local sites served over HTTP never had any issues. reply obmelvin 14 hours agoparentprevI&#x27;ve used duet display on a first gen ipad pro 9.7\". can&#x27;t speak to using in older iPads, but TBH I don&#x27;t recall having a problem with it reply Beijinger 18 hours agoprevWhen I had to work on my desktop but had to watch some educational videos on the side I just used https:&#x2F;&#x2F;remotedesktop.google.com&#x2F; Since the videos were web based it worked quite well. reply omneity 22 hours agoprevThis is cool. Maybe for copying you could spawn a text editor in your main screen with the content of the terminal in it? reply FrustratedPers 14 hours agoprevTried doing this for years, only got more and more frustrated with whatever wacky software I had to install to make this work. reply sigio 16 hours agoprevI prefer a single display and use virtual desktops to seperate tasks&#x2F;apps which each fill most&#x2F;all of the screen realestate reply cramjabsyn 13 hours agoprevMacos has the built in with sidecar. Just attach an ipad and select it as the external display reply gomox 12 hours agoparentSidecar is very glitchy for anything but casual use. reply james33 6 hours agorootparentIt seems to be pretty stable now. I&#x27;ve been using an iPad Pro as a 2nd monitor for a MBP while working remotely over the last year without any issues (8+ hours of daily use). reply angra_mainyu 16 hours agoprevI&#x27;ve done this with RDP + Android tablet on Linux. Performance depends heavily on your tablet&#x27;s hardware, enormously so. reply folmar 11 hours agoparentRDP is client-heavy, some flavor of VNC should do fine even on the most underpowered hardware (provided you are not watching videos). reply bdcravens 17 hours agoprevI never keep tablets around long - I usually sell them (and all electronics) once they&#x27;re no longer useful.eBay is my Marie Kondo :-) reply bazmattaz 13 hours agoparentSame. I’m a big believer of one man’s trash is another man’s treasure.I hate having gathering dust in my drawer if I can sell it for $50 on eBay and make someone happy in the process reply thesnide 17 hours agoprevI would really be interested for a X11 server on that tablet.So I can do a simple DISPLAY=tablet:0 to send the window to and enjoy output reply gatane 15 hours agoparenthttps:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=x.org.server reply Havoc 17 hours agoprevCan also be used as a janky screen pikvm style with the right adapters reply mavhc 19 hours agoprevI&#x27;d just run screen on both computers in multisession mode, and make the PC version tiny reply mixmastamyk 15 hours agoprevUnfortunately, I find systemctl hard to type. If you start&#x2F;stop services somewhat frequently, I recommend this alias: alias sc=&#x27;sudo systemctl&#x27;This has the nice property in that it mirrors the \"service control\" (sc) utility in later versions of Windows NT that I grew up on. Should work in bash&#x2F;fish.I have these others also when doing service development, because many of the subcommands start with &#x27;st*&#x27; and also having to change the second parameter each time is annoying. These work in fish, but are easily ported: function sce --description &#x27;systemctl stop # end&#x27; sc stop $argv; end function sci --description &#x27;systemctl status # info&#x27; sc status $argv; end function scs --description &#x27;systemctl start # start&#x27; sc start $argv; end reply sfink 15 hours agoparentI agree, though I find journalctl to be even worse to type. reply da39a3ee 4 hours agoprevvery cool!> I also never have enough screens and never know where to put my terminal when I need to tail a log or somethingWhat I do is just don&#x27;t think of the terminal as competing for screen space. My terminal is always full screen, and a single \"hotkey\" toggles between the world of GUI apps, and the terminal world. Then, you can divide up the terminal however you want; I use tmux.I&#x27;ve been trying this for more than 10 years. initially with iterm2, which has a built in \"hotkey\", and now with Alacritty, using hammerspoon for the hotkey. (the hotkey is sometimes called a \"visor\" key in this context, I think to do with first-person shooter games). reply momirlan 18 hours agoprevi use TeamViewer to log remotely into my working laptop from an Android device reply jchanimal 22 hours agoprevI love the suggestion to rebuild it for the browser. A tool like that could be generally useful. Anyone know of one? reply williamstein 20 hours agoparentCocalc uses a websocket and xterm.js to implement terminals on a remote server. Each terminal session corresponds to a file (with extension .term), so multiple clients can open the same session by opening the same file. If you type in one session then all sessions will see the typing at the same time. (Disclaimer: I wrote this. It’s way too heavy for this use case, but might be an amusing demo or proof of concept for somebody to play with before writing something new.) reply roessland 21 hours agoparentprevtmux + ttyd (or gotty) could be used in a similar way. But it&#x27;s not like an extra screen, it&#x27;s more like mirroring a terminal to another device. reply guraf 16 hours agorootparentSomeone asks for a webpage and not only do you propose tmux, you also acknowledge it doesn&#x27;t even do anything like what&#x27;s asked.Typical Linux user. reply A4ET8a8uTh0 15 hours agoprevNice. I just dusted off wife&#x27;s kindle in an attempt to repurpose it into a weird &#x27;i m in a meeting&#x27; sign and I may end up looking at your project more closely now. Much obliged!to layer contextSuch a good way of capturing it. reply Rudism 15 hours agoparentprevI agree. My opinion is that once you&#x27;ve trained yourself to use virtual desktops efficiently, multiple monitors becomes more of a hassle than a benefit.I think multiple monitors is the solution for people who would rather solve the problem by spending their money instead of the effort it takes to configure and become accustomed to switching between virtual desktops. Given that it is a strict biological limitation that the human brain can only focus attention on one thing at a time, I don&#x27;t believe there is any valid argument for why moving your eyeballs between physical monitors is any better than hitting a key combo to switch between virtual desktops on a single monitor once those key combos have become muscle memory. Additionally, the number of physical monitors you have is limited by how much money you have to burn and how much physical space you have to place them, whereas virtual desktops are theoretically unlimited. reply sfink 14 hours agorootparentThey&#x27;re not all for the same purpose.There are some things that don&#x27;t need to be actively looked at most of the time, but need to be visible so that you know when something happens that you do need to pay attention. You could do it by polling—put it on a virtual desktop and switch to it every so often—but that adds latency and can be even more distracting than having it visible in the corner of your eye. Think of things like Element or Slack or a dashboard that tracks bugs&#x2F;issues&#x2F;alerts.Then there are reference displays that you look at on demand. Most of the time switching virtual desktops is good enough for this, but not if you&#x27;re following along with a sequence while actively working.Then there are things that are just big. Perhaps you&#x27;re displaying an autogenerated graph, or you&#x27;re using an information-dense tool (maybe with multiple relevant layers).Not to mention wanting to consult things while on a video call, which constrains the screen to use based on camera positioning.I very actively use virtual desktops, yet I have two external monitors in addition to my laptop screen. Most of the time, I really only make use of one of the external monitors, but situations arise that require both. They arise frequently enough that I notice the lack (eg when I&#x27;m fighting with my configuration and only one is working, or I&#x27;ve loaned one monitor to someone else). And when I&#x27;m mobile and down to just the laptop screen, I definitely notice and even adjust what I&#x27;m working on to avoid losing productivity. reply bemmu 17 hours agoparentprevI&#x27;m doing some light gamedev, and with two 28\" screens I feel like I could use a little bit more screen real estate.The situation where this still feels lacking is when I&#x27;m trying to solve a problem and have a 3D game view, source code, object list and properties, debug output, debugger (watched variables, call stack) on one screen. Then on another screen I&#x27;ll read documentation of whatever I&#x27;m trying to fix.Productivity clearly had a jump when I added the second monitor, and I think I could get some boost still by either having larger monitors, or perhaps one big bigger curved one with two monitor inputs. reply maccard 11 hours agorootparentAlso games. 3x24 inch screens felt like the best balance to me. I had 2x27 and 1x 24 for a while, but I dropped back to 1x27 and 1x24 and prefer it. That&#x27;s what I roll these days reply NikolaNovak 15 hours agoparentprevIt depends somewhat on your job.When I was a techie I tried to be focused on one thing at a time as much as possible. Still liked two screens though!In many other roles though, having your email and your working document open, or having excel and PowerPoint open, or help docs and your code, or the operational plan and the server terminals, et cetera, are massive efficiency multipliers.Basically I&#x27;m at a place where one monitor feels claustrophobic, especially if it&#x27;s just the teeny laptop monitor. 2 are enough. 3 is nice. I wouldn&#x27;t know what to do with 4 32\" ones either!! reply tetraca 16 hours agoparentprevYou categorize your screens. One screen for dev work, one for communication, and one for documentation&#x2F;browsing. That way you can alt+tab between your primary work tasks with a tiny eye movement. reply dheera 15 hours agorootparentI used 2 screens for a while but I went back to 1. I would do 3 or 1 but not 2. 2 was bad for my neck. And I can&#x27;t fit 3 screens on my desk. reply danieldk 18 hours agoparentprevSame, one 5k 27” screen and I’m completely happy. I might consider 6k screen, but definitely not multiple screens. reply nunez 18 hours agorootparentIf it&#x27;s the Studio Display that you got, I got that same monitor a month ago and I absolutely love it. reply bdcravens 17 hours agoparentprevMost of the time I&#x27;m using 3: 2 big screens (often browser on one, IDE or similar on the other) and my laptop (usually terminal, or Slack, or a similar auxiliary app). It feels no more complicated to me than swiping between phone apps, and definitely simpler than someone with a carefully curated WM setup.My screen size has gone up over the years, but that&#x27;s more a matter of aging eyes than information density. :-) reply threeio 17 hours agoparentprevDoesn&#x27;t always work this way but:Smaller Monitor: Comms (email, calendar, slack, etc) -- often times I have this vertical (top email&#x2F;cal and slack below) and it doubles for viewing dashboards for stats during troubleshooting.Bigger monitor: Focus work (terminal, development env, etc) - normally split in 3 columnsLaptop Screen: Browsing (research, WebUI interfaces, entertainment, etc) reply switchbak 16 hours agoparentprevI think a lot of this depends on how you arrange your windows.I&#x27;ve used a bunch of monitors in the past, but found that my neck started to hurt after looking to the side too much. And having the bezels right in the middle of your view makes the most valuable real estate effectively unusable (unless you have 3!). 4 32&#x27;s would be way too much for me, no doubt.Having a single widescreen monitor has been better for me. Most of the time I&#x27;m not maximizing its use, but when I want to combine a bunch of views at once, it&#x27;s quite valuable. Like when I&#x27;m running a performance test while keeping tabs on a bunch of monitoring.I think you&#x27;re right that virtual workspaces are great, especially if you dedicate them for discrete purposes. reply jmbwell 15 hours agorootparentI have my primary display in the center, directly in front of me. Whatever needs my primary focus for my current task goes there... Outlook for email, vscode for code, Terminal for admin, web browser when web browsering, etc.To my left is for monitoring things, previewing things, and reference. Browser for checking changes to code, logs for monitoring changes to system, documentation for thing I&#x27;m working on, etc.The result avoids the bezel in my direct field of view, avoids strain and RSIs from awkward posture, and, incidentally, kinda degrades gracefully when I&#x27;m at home with only one display or traveling with only my laptop&#x27;s display.But the second display to my left allows my peripheral vision to monitor things for changes without diverting my focus, and helps me keep documentation or source material for comparison handy without having to switch away from the thing I&#x27;m working on. reply RealStickman_ 17 hours agoparentprevI&#x27;ve had a single monitor for a long time, but I&#x27;ve recently come around to dual monitors. It just makes working with additional information on the second screen so much easier. Indo spend more time shuffling windows around now though reply hotnfresh 17 hours agoparentprevI rarely feel a need for even two monitors unless I&#x27;m doing GUI development. Much of the time I just work off my laptop directly, not plugged in to anything (probably should knock it off for ergonomics reasons, though....) reply maccard 11 hours agoparentprevMy preference is 3x 24 inch screens. In theory, I&#x27;d like one of them to be a tablet or a touch screen device that sits underneath the other two.It basically boils down to one screen for \"the app&#x2F;website&#x2F;whatever\" one for code, and one for a reference. I _can_ hold contexts, but I also have tools to do that for me. reply c-hendricks 15 hours agoparentprevI&#x27;m similar. The idea of dedicating desk space, two extra cables, the compute to power the displays, and electricity, to show something like email seems incredibly wasteful to me. Not to mention, do people that do this not feel cramped when they don&#x27;t have their full setup?I&#x27;ve also never been a \"maximize the window\" type of person. Buying an ultra-wide was a huge help tho I will admit. reply brettermeier 18 hours agoparentprevI&#x27;m more of the 75,000 tabs faction, which is probably why I use 3 monitors. I prefer to have all the windows I&#x27;m actively working in open in parallel. With one monitor, the handling is too fiddly for me and the windows are much too small. If only one thing is in the foreground, I sometimes lose the context or the constant jumping back and forth annoys me.Edit: Just looked it up, there were like 30 tabs ;) But also more browsers, because it gets too much in only one. reply RugnirViking 17 hours agoparentprevive always said that going from one screen to two is a big jump in productivity. Comparing things between two windows is a very common task in almost all workloads. However I think three is already too many, and brings something between barely any benefit and a net negative. More than that seems superfluous, even for cctv or stock brokers. Attention can&#x27;t be split that easily. Personally for most of my working life ive had three, as in two 24\" and a laptop, but I usually either just have spotify fullscreen on the laptop all day or turn it off if I can.As for putting two windows side-by-side on a single screen? I don&#x27;t know, it always felt clunky to me. A lot of things are designed to be landscape 16:9. reply brainlessdev 16 hours agoparentprevTotally off-topic, but while reading this I was thinking \"that is exactly what I would say\". Then I saw your username... it looks like we share not only a taste for monitors but also a surname! reply ryukoposting 17 hours agoparentprevI&#x27;m a 1.5 screens at work (laptop + 24\" external monitor) and 1 screen at home person. Life has enough distractions. reply whiddershins 17 hours agoparentprevFor film composers (niche, I know) each screen can represent a distinct task all of which are happening simultaneously.So:- video reference- synthesizers- daw&#x2F;waveform playback- scoreI wonder what other professions might find value in a similar setup. reply dylan604 17 hours agorootparenti&#x27;m in the same vein but more film&#x2F;video post production in general. most of the time, in addition to how ever many monitors attached to the computer, there is at least one reference video monitor (that can be properly calibrated) that only receives a video signal from whatever software is being used. with only 2 computer screens, one screen has my timeline and preview windows. the other monitor will have all of the bins and effects controls and other various windows. if i&#x27;m in a real edit bay with dedicated scopes i&#x27;ll prefer those, but if i&#x27;m slumming it at home i&#x27;ll have to make room for them on one of the monitors too (usually tabbed behind the source monitor). reply yieldcrv 17 hours agorootparentprevI think thats good because you can manipulate the second screen without juggling the mouse pointerI think those are the best use cases, input is a much greater bottleneck with additional screens if its limited to keyboard and mouse modifying those windows reply croisillon 17 hours agoparentprevalmost everybody at my job has 2 screens, i&#x27;m sorry but i only have one brain reply maccard 11 hours agorootparentI&#x27;ve got a keyboard and mouse, but spend most of my day using just the keyboard. That doesn&#x27;t mean a mouse isn&#x27;t useful reply jrm4 19 hours agoprevLove this sort of hackery, but also -- it just kind of shows how very goofy all the limitations we have on this are.If you go with the idea that a computer should be a general purpose machine -- we have so many things that aren&#x27;t computers.\"Wireless external monitor\" should be a trivially easy built-in to all operating systems, and that it isn&#x27;t is kind of ridiculous. reply lexlash 16 hours agoparentRIP to FireWire target disk mode for Apple laptops and target display mode for iMacs.The new docs promote AirPlay screen mirroring and networked shares over usb-c but it’s nowhere near the same. :&#x2F; reply joombaga 13 hours agorootparentYou can still do target disk mode over usb-c. I used it when I switched from Intel to M1. reply throwaway167 18 hours agoparentprevI was thinking exactly the same when reading this, but wireless programmable led display keyboard buttons. I think these should exist, but don&#x27;t know of any easy implementations. reply hiccuphippo 14 hours agoparentprevMy phone can easily mirror the screen to my TV but my PC can&#x27;t, not with the built-in software, not with 3rd party apps. It&#x27;s all so tiresome. reply Netcob 19 hours agoprev> I have a couple old kindle fire tablets lying around. One of them has a battery that lasts about ten minutes.You might want to check if the battery is going \"spicy pillow\". reply wkat4242 18 hours agoparentYeah for this reason I replace the battery of old tablets that I use as control panels, with a DC-DC converter.Simply removing the battery isn&#x27;t enough because most tablets refuse to run on usb power alone. reply londons_explore 15 hours agorootparentYou can also replace the battery with a much smaller one - eg. a coin cell, and it&#x27;ll normally run fine. reply wkat4242 3 hours agorootparentBut what will a coin cell do when it&#x27;s trying to get charged? That sounds a bit worrying.But I didn&#x27;t realise that. Perhaps I could use a voltage divider then or simply input 5V. 5V is too high for a battery but most devices accept it there anyway. reply danielvf 15 hours agorootparentprevURL to an example of what you use? reply wkat4242 3 hours agorootparentI use cheap ones from Amazon (link below). I power them with 12V adapters which I \"shucked\". 5V is not enough to provide enough voltage because you lose some in the conversion.https:&#x2F;&#x2F;www.amazon.es&#x2F;gp&#x2F;product&#x2F;B07PBCYTFWThese adapters seem similar to what&#x27;s used in that instructibles link. I didn&#x27;t pick these for any specific reason other than they were available on Amazon. It uses the same LM2596. reply cheeko1234 13 hours agorootparentprevhttps:&#x2F;&#x2F;www.instructables.com&#x2F;Powering-a-Android-Device-From...https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;homeassistant&#x2F;comments&#x2F;13ovuqn&#x2F;ive_...You can use an LM2596 to step down the voltage. reply seanthemon 19 hours agoparentprevLithium hotpocket reply aaron695 21 hours agoprev [–] Computers still only have three mainstream input devices, keyboard, mouse and gamepad after 60-80 yearsI&#x27;d try and bring the addition inputs a smart phone has to computers, like touch.I know there are programable keyboards and many other things. But no one has cracked it yet.It&#x27;s a cool project as is. Just an idea if you were thinking of iterating forward. reply Kerrick 19 hours agoparentI collect and use as many input devices as I can, as a bit of a hobby. It all started when I was younger and got a CueCat. Now I’m up to webcams, microphones, fingerprint sensors, many keyboards, mice, trackpads, trackballs, many game pads, MakeyMakey, a VR system, CharaChorder, MIDI keyboard, floor dance pad, Wacom tablet, BlackMagic keyboard with jog shuttle, and HOTaS. I’ve still got my eye on a macro pad, MIDI Fighter, and a racing wheel. reply myself248 16 hours agorootparentHeyyy, CueCat club! Funny that QR codes are everywhere these days and people actually scan them; Digital Convergence was just ahead of their time.I have keyboards with mag-stripe readers, keyboards with smart-card readers, keyboards with assignable and relegendable keys (meant for point-of-sale usage), 6DOF 3D \"SpaceMouse\" devices, a 5-axis Lexip Pu94 mouse, I&#x27;ve mapped an R&#x2F;C quadcopter transmitter into a wireless joystick [1], and last year I finally bought my first USB gamepad. (To play Stray.)I was recently digging into some details of the BlackMagic keyboard and it sounds like it&#x27;s super difficult to remap the jog dial for other uses, what do you use yours for?1: https:&#x2F;&#x2F;hackaday.io&#x2F;page&#x2F;11784-rc-transmitter-tx-as-a-virtua... reply Kerrick 14 hours agorootparentI use mine for the most boring possible answer: exactly what it was marketed for. I edit videos in DaVinci Resolve with it. :-) reply landtuna 19 hours agorootparentprevI had a boss who was pretty excited about CueCat. It&#x27;s funny that it took another 15 years to catch on as smartphones and QR codes! reply jvm___ 19 hours agorootparentprevI picture you having them all hooked up at once, one-man band style. reply Kerrick 18 hours agorootparentI actually do have many of them attached at once. I have an extra-wide desk and two PCIe expansion cards that provide 7 USB ports each, with their own USB controllers to solve bandwidth&#x2F;timing issues. reply ericrallen 20 hours agoparentprevThere are lots of computers with touch capabilities out there.From the gesture support on Apple’s trackpads to touch screens like the Surface (and plenty of other laptops with touch screens).There are also stylus inputs and things like Wacom tablets that have been around for many years now. reply kedean 20 hours agorootparentThere&#x27;s also microphones and cameras that can act as inputs, it just turns out they don&#x27;t offer much power over kb&#x2F;m.But really, the problem being solved by OP was not enough outputs, rather than not enough inputs. reply ben_w 19 hours agoparentprev [–] Given how much we use them to talk to each other, I&#x27;m surprised you&#x27;re not counting the microphone; likewise video calls and the camera.And given how phones and tablets are so much more common than laptops and desktops, touch screens.Arguably there&#x27;s also passive continuous inputs like GPS and heart rate sensors, accelerometers, etc. — mainstream, but I doubt it was the category you had in mind. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The mentioned feature is exclusively available for terminal and curses applications."
    ],
    "commentSummary": [
      "The article delves into the usage of tablets and smartphones as secondary displays for computers, examining various software solutions.",
      "It debunks the topic of using multiple monitors for heightened productivity, discusses preferences regarding screen arrangement and input devices, and talks about the limitations of current options.",
      "Crucially, the discussion emphasizes a need for a broader range of input options and better task and information management systems."
    ],
    "points": 240,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1696592201
  },
  {
    "id": 37788847,
    "title": "Narges Mohammadi wins 2023 Nobel Peace Prize",
    "originLink": "https://www.cnn.com/world/live-news/nobel-peace-prize-2023-latest-news-intl/index.html",
    "originBody": "World Africa Americas Asia Australia More Audio Live TV Log In Search Edition U.S. International Arabic Español US Crime + Justice Energy + Environment Extreme Weather Space + Science World Africa Americas Asia Australia China Europe India Middle East United Kingdom Politics SCOTUS Congress Facts First 2024 Election Business Tech Media Success Perspectives Videos Markets Pre-markets After-Hours Market Movers Fear & Greed World Markets Investing Markets Now Before the Bell Nightcap Opinion Political Op-Eds Social Commentary Health Life, But Better Fitness Food Sleep Mindfulness Relationships Entertainment Movies Television Celebrity Tech Innovate Gadget Foreseeable Future Mission: Ahead Upstarts Work Transformed Innovative Cities Style Arts Design Fashion Architecture Luxury Beauty Video Travel Destinations Food and Drink Stay News Videos Sports Pro Football College Football Basketball Baseball Soccer Olympics Hockey Videos Live TV CNN Headlines CNN Max Digital Studios CNN Films HLN TV Schedule TV Shows A-Z CNNVR Audio CNN Underscored Electronics Fashion Beauty Health & Fitness Home Reviews Deals Money Gifts Travel Outdoors Pets CNN Store Coupons Weather Climate Storm Tracker Wildfire Tracker Video About CNN Photos Investigations CNN Profiles CNN Leadership CNN Newsletters Work for CNN FOLLOW CNN Hear jailed Iranian activist speak from behind bars04:52 Jailed Iranian activist Narges Mohammadi wins 2023 Nobel Peace Prize By Christian Edwards, Ed Upright and Sana Noor Haq, CNN Updated 8:14 a.m. ET, October 6, 2023 What we covered The 2023 Nobel Peace Prize has gone to jailed Iranian activist Narges Mohammadi for \"her fight against the oppression of women in Iran and her fight to promote human rights and freedom for all.\" Mohammadi has long campaigned for women's rights and for the abolition of the death penalty. It has come at huge personal cost – she's been sentenced to more than 30 years in jail, and has been banned from seeing her husband and children. In an audio recording and letter shared with CNN before she was awarded the prize on Friday, Mohammadi spoke about her activism from inside Iran's notorious Evin prison. The Nobel Committee said it hoped Iran would release Mohammadi so she could attend the prize ceremony in December. CNN Underscored No offense, but your water bottle is probably filthy. Here’s exactly how to clean it Fits like a sneaker, protects like a rugged boot: Hoka Anacapa 2 GTX hiking shoe review 24 Posts SORT BY Latest Oldest 21 hr 51 min ago Our live coverage of this year's Nobel Peace Prize has ended. Read more about the winner, Narges Mohammadi, and reaction to the prize. 21 hr 59 min ago \"A woman, a human rights advocate, and a freedom fighter\" From CNN's Lauren Kent and Sana Noor Haq Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough. Reihane Taravati Narges Mohammadi spearheaded the campaign for human rights in Iran, in the face of a regime that has used torture to crush dissent. Her rallying cry grew louder in September 2022, after the death of 22-year-old Mahsa Amini while in custody of the morality police sparked nationwide protests. Hundreds of thousands of demonstrators used the slogan -- woman, life, freedom -- to organize the biggest threat against the Iranian regime since it came into power in 1979. Even behind bars inside Tehran's notorious Evin prison, Mohammadi used her platform to lead the same chants, according to an audio recording she shared with CNN, before she won the Nobel Peace Prize on Friday. The motto adopted by the demonstrators -- woman life freedom -- suitably expresses the dedication and work of Narges Mohammadi,\" Norwegian Nobel Committee chair Berit Reiss-Andersen said. A history of campaigning: Mohammadi started advocating for women's rights while studying physics in the 1990s, later working as an engineer and writing for reform minded newspapers. In 2011, eight years after first collaborating with the defense of Human Rights Center in Tehran -- which was established by the Nobel Peace Prize Laureate, Shirin Ebadi -- Mohammadi was first arrested. In 2013, she was released on bail and used her freedom to campaign against the death penalty in Iran. The Iranian regime has historically been among the most prolific executioners in the world. Since January 2022, more than 260 prisoners have been subject to the death penalty in Iran, Reiss-Andersen said. Mohammadi's advocacy work against the death penalty resulted in her re-arrest in 2015. \"Upon her return to prison, she began ... opposing the regime's systematic use of torture and sexualized violence against political prisoners -- and especially women -- that is practiced in Iranian prisons,\" Reiss-Andersen added. The Iranian government has denied the widespread allegations of sexual assaults against detainees, including in an in-depth CNN investigation last year, calling them “false” and “baseless.” A Nobel tribute: \"Last year's wave of protests became known to the political prisoners held inside the notorious Evin Prison in Tehran. Once again, Ms. Mohammadi assumed leadership from prison. She expressed support for the demonstrators and organized solidarity actions among her fellow inmates,\" Berit Reiss-Andersen said. \"From captivity, Ms. Mohammadi has helped to ensure that the protests have not ebbed out. \"Narges Mohammadi is a woman, a human rights advocate, and a freedom fighter. In awarding her this year's Nobel Peace Prize, the Norwegian Nobel Committee wishes to honor her courageous fight for human rights, freedom and democracy in Iran,\" Reiss-Andersen said. 22 hr 26 min ago Family says award is a \"source of solace for our indescribable suffering\" From CNN's Jomana Karadsheh and Adam Pourahmadi Narges Mohammadi's family has been reacting to the news of her Nobel Peace Prize win. \"Although the years of her absence can never be compensated for us, the reality is that the honor of recognizing Narges' efforts for peace is a source of solace for our indescribable suffering,\" a statement given to CNN said. \"It has been more than eight and a half years since she has seen her children, and she has not heard their voices for over a year. All of this signifies what she has endured on the path to realizing her aspirations. Therefore, for us, who know that the Nobel Peace Prize will aid her in achieving her goals, this day is a blessed day. We express our gratitude to you for your attention to Iran, the oppressed people of Iran, and the prisoners, civil activists, and protesters.\" Mohammadi's activism has come at a great personal cost. She has been banned from speaking directly with her husband, Taghi Rahmani, and her children, Ali and Kiana. Rahmani, who was himself held as a political prisoner for a total of 14 years, has lived in exile with their children in France since Mohammadi's imprisonment in 2015. 23 hr 5 min ago A brief history of Iran's rules on the hijab This years's Peace Prize sends a likely unwelcome message to the authorities in Iran, which has for decades been dictating to women how they should dress. The Islamic regime made the hjiab compulsory in 1979, after toppling the Pahlavi dynasty. It also created the notorious morality police, tasked with ensuring that the rules are followed. Several anti-hijab movements have emerged in Iran over the years, often leading to crackdowns by the regime, with massive waves of arrest and persecution. Following the death of 22-year-old Mahsa Amini in September of last year, many took to the streets protesting the mandatory hijab law and other issues. The movement was violently quashed, however, and the regime responded months later with a new hijab bill that, if passed, would enshrine unprecedentedly harsh punitive measures into law. The 70-article draft law, which was published on Iranian media just weeks before the one-year anniversary of the protests, set out a range of proposals, including much longer prison terms for women who refuse to wear the veil, stiff new penalties for celebrities and businesses who flout the rules, and the use of artificial intelligence to identify women in breach of the dress code. Experts said the bill was a warning to Iranians that the regime would not back down from its stance on the hijab despite the mass demonstrations that rocked the country last year. Days after the protest anniversary, Iran’s parliament last month passed a draconian new hijab legislation, which authorities said would be enacted for a three-year trial period once the Guardian Council, which oversees legislative matters in the Islamic Republic, approves it. Parts of the bill are ambiguous, but some clauses sanction punishments of up to 10 years, and fines between 180 million rials ($4,260) and 360 million rials ($8,520). The punishments are a sharp split from today’s measures. Under the current Islamic penal code, those in breach of the dress code face between 10 days to two months in prison, or a fine between 50,000 to 500,000 Iranian rials, what is today between $1.18 to $11.82. It is “a clear response to the protests from September of last fall,” Sanam Vakil, director of the Middle East and North Africa program at the Chatham House think-tank in London, told CNN in August before the bill was introduced in parliament, adding that the establishment was attempting to “reassert authority over veiling and the requirements expected of women.” 23 hr 23 min ago 2022 Nobel Peace Prize winner congratulates Mohammadi From CNN's Sana Noor Haq Ukrainian rights defender Oleksandra Matviichuk, whose Center for Civil Liberties jointly won the 2022 Nobel Peace Prize with the Russian rights organisation Memorial poses during a interview at the University Catholique of Louvain in Louvain La Neuve, Belgium, on February 16. John Thys/AFP/Getty Images Oleksandra Matviichuk, a Ukrainian human rights lawyer and defender who won the Nobel Peace Prize in 2022, said she welcomed the committee's decision to award Narges Mohammadi \"for her fight against the oppression of women in Iran.\" \"We live in a very interconnected world. Right now, people in Iran are fighting for freedom. Our future depends on their success,\" Matviichuk posted on the social media platform X, formerly known as Twitter. She heads Ukraine's Center for Civil Liberties, which was founded in 2007 to advocate human rights values in Ukraine, in order to advance democracy in the country. The group jointly won the Nobel Peace Prize last year. It played a significant role in identifying and documenting Russian war crimes against the Ukrainian population since Moscow launched its invasion in February 2022. Matviichuk drew parallels between her and Mohammadi's efforts to hold authoritarian regimes accountable, while raising the voices of \"people fighting for freedom.\" \"It is more than obvious for Ukraine. I live in Kyiv, which is regularly bombarded by Russian missiles and Iranian drones. If authoritarian regimes cooperate, then people fighting for freedom have to support each other much more strongly,\" she said on Friday. 23 hr 4 min ago Prize also honors \"hundreds of thousands\" who have demonstrated for women's rights in Iran From CNN\"s Nadeen Ebrahim Protesters chant slogans during a protest over the death of a woman who was detained by the morality police, in downtown Tehran, Iran, on September 21, 2022. AP “This year’s Peace Prize also recognizes the hundreds of thousands of people who in the preceding year have demonstrated against the theocratic regimes’ policies of discrimination and oppression targeting women,” Norwegian Nobel Committee chair Berit Reiss-Andersen said. Reiss-Andersen was referring to the mass protests that broke out a year ago following the death of 22-year-old Mahsa Amini, who died in the custody of Iran’s notorious morality police. Days after her death, Iranians took to the streets in unprecedented widespread demonstrations, with many decrying the hijab law, the impunity of the morality police and other issues. Some called for the downfall of the regime. Authorities responded violently, suppressing the movement with widespread reports of deaths, disappearances and even torture in custody. Iran’s morality police, which had largely pulled back following the protests last year, this year resumed street patrols, and just weeks before the one-year anniversary of Amini’s death and the protests that followed, Iranian authorities began considering a draconian new bill on hijab-wearing that experts said would enshrine unprecedentedly harsh punitive measures into law. The country’s parliament passed a new legislation on hijab-wearing last month. The Guardian Council, which oversees legislative matters in the Islamic Republic, still needs to approve the bill before it is implemented. 23 hr 43 min ago Mohammadi is the 19th woman to win the Nobel Peace Prize From CNN's Thom Poole Narges Mohammadi is pictured at home in Iran during a stint out of prison on medical furlough. Reihane Taravati Narges Mohammadi is just the 19th woman to win the Nobel Peace Prize in more than 120 years of the prize. Nadia Murad, a Yazidi human rights activist and survivor of sexual slavery at the hands of ISIS in Iraq, jointly won the prize in 2018. Other female winners include Pakistani education campaigner Malala Yousafzai, and Ellen Johnson Sirleaf, who became Africa's first democratically elected woman leader when she became Liberian president in 2005. Another Iranian woman, human rights lawyer Shirin Ebadi, won the prize in 2003. The Nobel website says for much of its history the Peace Prize \"had almost exclusively been the preserve of highly educated white men from Europe and the United States.\" 23 hr 54 min ago Mohammadi's activism in Iran has come with \"tremendous personal costs\" From CNN's Jomana Karadsheh, Adam Pourahmadi and Sana Noor Haq An archival photograph of Narges Mohammadi with her children, Kiana and Ali. Courtesy of Narges Mohammadi The Iranian regime has imprisoned Narges Mohammadi for her advocacy work against the oppression of women inside Iran. “Her brave struggle has come with tremendous personal costs,\" Norwegian Nobel Committee chair Berit Reiss-Andersen said at the announcement ceremony on Friday. The government in Iran has arrested Mohammadi 13 times, convicted her five times, and sentenced her to a total of 31 years in prison, and 154 lashes, according to Reiss-Andersenn. Following her release on bail, she was re-arrested in 2015 and sentenced to additional time in jail, the Nobel Prize said on the social media platform X, formerly known as Twitter. But even behind walls, she has used her voice to campaign rail against the use of the death penalty in Iran and the regime's mandatory hijab law. Earlier this year, Iran's parliament passed draconian new legislation imposing much harsher penalties on women who breach hijab rules, days after the one-year anniversary of Amini's death sparked mass demonstrations. For refusing to be silenced while in prison, Mohammadi has been banned from speaking to her husband, Taghi Rahmani, and her children, Ali and Kiana, for the past 18 months. I am really proud of my mom,” Ali told CNN, before his mother was awarded the Nobel Peace Prize on Friday. “She was not always with us, but whenever she was, she took good care of us… she was a good mom and still is… I have accepted this kind of life now. Any suffering that I have to endure does not matter.” 5:52 a.m. ET, October 6, 2023 Nobel committee's recognition of Mohammadi sends \"powerful message to the leaders of Iran\" From CNN's Christian Edwards The recognition of Iranian activist Narges Mohammadi by the Norwegian Nobel Committee is a \"tremendous achievement for women's rights in Iran,\" a Peace Prize specialist told CNN. “Narges Mohammadi was top of my shortlist. Her win is a tremendous achievement for women’s rights in Iran,\" Henrik Urdal, director of the Peace Research Institute Oslo, said in a statement to CNN. \"Women in the country have been fighting for equality and freedom for generations, and the death of Mahsa Amini became a catalyst against oppression and violence. Today’s laureate, unfairly jailed in Tehran, sends a powerful message to the leaders of Iran that women’s rights are fundamental everywhere in the world.” Search US Crime + Justice Energy + Environment Extreme Weather Space + Science World Africa Americas Asia Australia China Europe India Middle East United Kingdom Politics SCOTUS Congress Facts First 2024 Election Business Tech Media Success Perspectives Videos Markets Pre-markets After-Hours Market Movers Fear & Greed World Markets Investing Markets Now Before the Bell Nightcap Opinion Political Op-Eds Social Commentary Health Life, But Better Fitness Food Sleep Mindfulness Relationships Entertainment Movies Television Celebrity Tech Innovate Gadget Foreseeable Future Mission: Ahead Upstarts Work Transformed Innovative Cities Style Arts Design Fashion Architecture Luxury Beauty Video Travel Destinations Food and Drink Stay News Videos Sports Pro Football College Football Basketball Baseball Soccer Olympics Hockey Videos Live TV CNN Headlines CNN Max Digital Studios CNN Films HLN TV Schedule TV Shows A-Z CNNVR Audio CNN Underscored Electronics Fashion Beauty Health & Fitness Home Reviews Deals Money Gifts Travel Outdoors Pets CNN Store Coupons Weather Climate Storm Tracker Wildfire Tracker Video About CNN Photos Investigations CNN Profiles CNN Leadership CNN Newsletters Work for CNN World Audio Live TV FOLLOW CNN Log In Terms of Use Privacy Policy Cookie Settings Ad Choices About Us CNN Store Newsletters Transcripts License Footage CNN Newsource Sitemap © 2023 Cable News Network.A Warner Bros. Discovery Company.All Rights Reserved. CNN Sans ™ & © 2016 Cable News Network.",
    "commentLink": "https://news.ycombinator.com/item?id=37788847",
    "commentBody": "Narges Mohammadi wins 2023 Nobel Peace PrizeHacker NewspastloginNarges Mohammadi wins 2023 Nobel Peace Prize (cnn.com) 226 points by michaeltimo 1 day ago| hidepastfavorite240 comments Gud 19 hours agoWell deserved. Iran has so much potential. It&#x27;s extremely sad how a small group of extremists holds the entire country hostage. reply bettercallsalad 14 hours agoparentEver wondered how these “small group of extremists” came about holding the entire country hostage? That’s because US nation state apparatus decided to overthrow democratically elected government there for their own interests.When you study American foreign policy, you can’t help but wondering it’s indeed not the interest of USA to have once unconquerable empires like Persia to be thriving and realize their full potential. US would rather have dysfunctional corrupt extremists dependent on foreign aids rule an entire region than challenging its hegemony.So next time you hear our media preach how detestable other foreign leaders like Erdogan or Modi or MBS is, think twice what the agenda there is. USA has had no problems supporting savage regimes for their own interests. I will pick WMD monster Saddam Hussein any day everyday over whatever there is left in Iraq today. History repeats itself. Nation state with media collusion saturating its own citizens mind with propaganda to serve their own interests (often just a very small group of people living north of Richmond) where the same group of people keep drumming the war machines for decades under different banners. Enough said. reply dahfizz 14 hours agorootparent> you can’t help but wondering it’s indeed not the interest of USA to have once unconquerable empires like Persia to be thriving and realize their full potential.This is rather conspiratorial.Great Britian and Russia have been involved in Iran since the 19th century (example[1]). They both invaded during WW2[2]. Britian left after the war but Russia stuck around. As the cold war began, the USA also got sucked into the mess in the middle east because Russia already had a presence there[3]. The US involvement is often portrayed as the beginning of this mess (just like you did), but it really isn&#x27;t.I promise that at no point did anyone involved say to themselves \"I sure am scared of a modern Persian Empire\". The country was simply caught up in the geopolitical chess game between world super powers. That doesn&#x27;t make it right, but that&#x27;s what it is.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Reuter_concession[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Anglo-Soviet_invasion_of_Iran[3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Iran_crisis_of_1946 reply kwar13 10 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;1953_Iranian_coup_d%27%C3%A9ta... reply leereeves 8 hours agorootparentThe CIA&#x27;s role in the coup has been greatly exaggerated. Even that source says:> In 2014, historian Ray Takeyh conclusively showed that the US-led coup attempt was unsuccessful, with the CIA writing to Eisenhower that \"The move failed […] We now [...] probably have to snuggle up to Mosaddeq if we&#x27;re going to save [our influence in Iran];\" the demonstrations that led to Mosaddeq&#x27;s resignation took place some weeks after the Roosevelt-organized ones, and were composed of average citizens, not the thugs-for-hire that the CIA and MI6 had recruited.[64] reply rnk 14 hours agorootparentprevYeah, the us did kick it off in Iran. Then religious extremists managed to transition that to longterm despotic control of the country. Before the us overthrew the former govt, Iran wasn&#x27;t exactly an unconquerable empire for a very long time though. And the us didn&#x27;t learn it&#x27;s lesson, having done this over and over again in south america and central america and other places. It seems like we are currently in a period of not doing this but all it takes is a new presidential whim to kick it off again, probably.US actions don&#x27;t remove the ability for their to be reliable observation that certain leaders are terrible. Kicking up hate for muslims is not a good thing long term for India. Killing your democratic enemies and cutting them up with saws in embassies is also clearly wrong. I feel completely empowered to point these things out, while being able to talk about the many problems in the US too. reply nojvek 14 hours agorootparentUS does whatever the President, Senate, Congress votes to do at the time.It seems US is learning it&#x27;s lesson but only takes one president to declare a war. Iran and Afghanistan were massive failures and trillions of tax payer dollars wasted.Even US supporting Ukraine has resulted in failure. Failure in the sense of millions of lives lost and displaced, no victory for Ukraine and Russia is still destroying their infrastructure.I support US helping other countries when a victory is swift and definitive. reply bogomipz 9 hours agorootparentprev>\"Ever wondered how these “small group of extremists” came about holding the entire country hostage? That’s because US nation state apparatus decided to overthrow democratically elected government there for their own interests.\"Honestly it doesn&#x27;t sound like you&#x27;ve studied very much then. I would recommend you read up Ali Shariati who was the revolution&#x27;s ideologue and someone who was extremely influential amongst those university students of 1979. He was also very influential among younger clerics as well as with Khomeini himself. His philosophy was that society would be guided by the intelligentsia instead of the clergy. His political philosophy was one that was intended to lead to a freer society. And indeed in the immediate aftermath of the revolution democratic institutions called \"shuras\" and \"komitehs\" arose which gave workers and the impoverished an economic and political voice. These were considered a threat to clerical power however and so power was consolidated and the revolution was highjacked. Your parroting of the just \"blame the west\" narrative is just plain lazy. reply lingben 11 hours agorootparentprev> Ever wondered how these “small group of extremists” came about holding the entire country hostage? That’s because US nation state apparatus decided to overthrow democratically elected government there for their own interests.It is tiresome to read again and again on the internet about how my country would be X or Y had the evil Westerners not \"overthrown\" the democratically elected government of Iran in 1953.This false narrative is bandied around so much and so many fall for it with zero interest or curiosity to delve deeper to see if any of it is true.Well, no, it isn&#x27;t true.Sadly, unfortunately, tragically, [insert adjective of your choice here]...#Iran has NEVER been a democracyRead that again.While our future is bright and with the imminent the removal of the Islamic theocracy we will have the opportunity to have a secular democracy that represents and governs all Iranians, that will be a very important first for our ancient people, land and society.What most ignorant people refer to in the above lazy copypasta are the events in and around 1953 with the appointment and dismissal of Mossadegh.#READ THAT AGAIN*appointment*and*dismissal*Mossadegh was appointed, not elected, as per the 1906 Iranian constitution:> ART. 46. The appointment and dismissal of Ministers is effected by virtue of the Royal Decree of the King.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_prime_ministers_of_Ira...You and I may not like that article in the 1906 constitution. While we&#x27;re free to have our opinions about it, we can not have our own facts. The facts are that just like previous PM&#x27;s (which included him btw!) Mossadegh was appointed legally (in accordance with the enacted constitutional framework) and also legally dismissed as well.Funny that no one mentions or even remembers the first time around that he was appointed and dismissed: 28 April 1951 appointed and 17 July 1952 dismissed (1 year, 80 days) but every ignorant person loses their minds re the second time in 1952&#x2F;1953 !!Furthermore, it is hilarious that Mossadegh is now seen by some ignorant people devoid of any historical knowledge as a symbol or champion of democracy.Mossadegh was so \"democratic\" that his referendum to dissolve parliament so that he obtains absolute power won 99.93% of the votes.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;1953_Iranian_parliamentary_dis...What did credible international publications think of his democratic zeal?> TIME magazine: “Hitler’s best as a vote-getter was 99.81% Ja’s in 1936; Stalin’s peak was 99.73% Da’s in 1946. Last week Premier Mohammed Mossadegh, the man in the iron cot, topped them all with 99.93%.”> NBC TV’s John Cameron Swayze announced: Mossadegh “has accomplished what Hitler and Stalin could not. He received 99 9⁄10 percent of the vote in a carefully managed referendum.”> New York Times: “A plebiscite more fantastic and farcical than any ever held under Hitler or Stalin is now being staged in Iran by Premier Mossadegh in an effort to make himself unchallenged dictator of the country.”> NYT, A Bid For Dictatorship, 7&#x2F;15&#x2F;52:”Having brought his country to the verge of bankruptcy,Premier Mossadegh is now trying to take it further along the road to ruin by demanding dictatorial powers for 6 months,on the plea that he needs these powers to pull Iran out of the crisis into which he has plunged it.What he proposes is in effect a legalized coup d’etat that smacks of Hitler’s technique.This is the legal device by which Hitler also acquired absolute powers he had no intention,of course, of surrendering them on termination of the ostensible period for which they had been granted, and there is no assurance that Mr. Mossadegh would act differently.”> Melbourne paper, The Argus (8&#x2F;21&#x2F;53): “THE swift and violent overthrow of Dr. Mossadegh , Premier and virtual dictator of Persia, has been a complete surprise to the world, and a pleasant surprise to the Western half of it.”The fact is many contemporary international news outlets referred to Mossadegh as a dictator because that’s what he was. There was nothing democratic about his reign (nor his coup attempt at overthrowing the Shah) Anyone who says otherwise is either naive or lying.There’s only one reason a handful of Iranians have rehabilitated, re-branded, mythologized and continue to promote Mossadegh: their disdain for the late Shah.Lamenting the loss of a Mossadeq because of democratic ambitions betrays a lack of knowledge of Iranian history.The most common misconception is that he was democratically elected. He wasn’t, he was appointed by the King.Another misconception is that he was a champion of democracy.During his tenure Mossadegh dissolved the senate, shut down parliament, not once did he hold a full meeting of the council of ministers, suspended elections for the National Assembly, announced he would rule by decree, jailed hundreds of opponents, and the cherry on top of this \"democratic\" so called champion: he dismissed the Supreme Court.This angered the National Assembly so he announced a referendum to decide if it should be dissolved. At the opening session he gave a speech aimed at intimidating dissenters saying only 80% of those present truly represented the people - for visuals think Saddam’s parliament speech with that cigar.Our “champion of democracy” arranged that those voting for dissolution and those against voted in plainly marked booths. The signal was clear: anyone brave enough to vote in opposition would be beaten up by his street hooligans&#x2F;Tudeh (Communist) supporters.Dissolution won by 99% of all votes!In one town with a population of 3,000, 18000 votes were cast in favor of Mossadeq’s undemocratic dissolution. His democratic ideals were so far reaching he allowed the dead to vote. Hundreds of people were killed during his rigged elections.By the time of the counter-coup that toppled him he had 27 gallows put up on Sepah Square to hang his enemies in public. All but approximately 4 days of his premiership were under martial law&#x2F;curfew. There was nothing democratic about his reign.While a member of parliament he posed as a champion of the constitution, due process, representative govt, free press; but only in a few months did he do the things mentioned above. Khomeini promised democracy too. Had his revolution not succeeded he too would be touted a great democratFrom 1941-1979 Mohammad Reza Shah Pahlavi appointed & dismissed 22 PMs (incl. Mossadegh twice) in accordance to the 1906 Constitution.Yet, Mossadeq is the only 1 referred 2 as “democratically elected” despite the fact that all were appointed and dismissed in the same manner.What set Mossadeq apart from the pack were his political ambitions.After becoming Prime Minister he successfully forced the Shah 2 appoint him Minister of War,granting himself absolute power.He soon replaced officers w&#x2F;those loyal 2 him, consolidating power to obtain the throne via a coupWhen the Shah finally dismissed Mossadegh in accordance with his legal authority under the Constitution of 1906, Mossadeq had the officer who delivered the dismissal decree arrested, his Foreign Minister published an editorial in Bakhtar-e-Emruz denouncing the Shah & called for his ouster.It’s clear to the objective student of Iranian modern history that Mossadeq initiated a coup against the Shah and the events that followed & led to Mossadegh’s downfall should more appropriately be labeled a “counter-coup”The Mossadegh that many promote is more of a myth like CheGuevara. People think he stood for things which were inconsistent with reality.Also, it bears notice that Mossadeq&#x27;s own Chief of Police & cousin, General Daftari, joined the royal forces to topple him. He was disliked by everyone except his communist friends. reply screye 18 hours agoparentprevGenuine question, doesn&#x27;t the ultra-orthodox wing reflect the popular opinion of the country ?My understanding is that Iran has among the greatest Urban-Rural divides in the world, and that the rural population is large enough to democratically force their conservative views onto the urban population. Turkey seems to be in a similar position, but their proximity to NATO and Europe keeps them somewhat grounded.> small group of extremists holds the entire country hostageI&#x27;m just not sure that the group of people we consider extremists are that small. reply Centigonal 18 hours agorootparentIran&#x27;s Supreme leader and guardian council have ultimate veto power over all legislation and candidates.In the past decade, there have been massive nationwide protests almost annually, often with election fairness as a theme.The Iranian military has a special wing, the IRGC, that is dedicated to the Supreme leader and used to crush protest or dissent.These are not characteristics of a functioning liberal democracy. If Iran&#x27;s regime reflects the popular opinion of Iranians (which I believe it doesn&#x27;t), then that&#x27;s in spite of their government, not because of it. reply lingben 11 hours agorootparentWhat you write is correct, except for this part:The IRGC is not a &#x27;special wing&#x27; of the Iranian military. They are a completely separate organization which has no equivalency in Western societies or defense departments.The IRGC is tasked with protecting and spreading Khomeini&#x27;s brand of Islamic theocracy throughout the world. This is why you see Iranian proxies in Yemen, Nigeria, Lebanon, Gaza, Syria, etc.The Iranian military is tasked with protecting the Iranian nation and people. The military is a lower priority and less funded that IRGC, especially since the IRGC is a major actor in Iran&#x27;s economy via various bonyads. reply lingben 11 hours agorootparentprevGAMAAN has provided insight into Iranian opinions with intelligent polling and verification methods that correct for the Islamic theocratic regime&#x27;s authoritarian control over society. The coles notes are that the majority of Iranians do NOT support the Islamic regime, are not religious and do not support the theocratic laws and regulations such as enforced hijab and other gender apartheid measures currently in place against Iranian women.This video explains their methodology and results: https:&#x2F;&#x2F;youtu.be&#x2F;YONfg85gPU4?t=4341https:&#x2F;&#x2F;nymag.com&#x2F;intelligencer&#x2F;article&#x2F;iran-secular-shift-g...https:&#x2F;&#x2F;gamaan.org&#x2F;survey-reports&#x2F; reply y-c-o-m-b 17 hours agorootparentprevThat is not possible to answer due to the very high level of oppression. I still have Muslim family back home in Iran, especially in rural areas of Gilan province. They are very much against the government and its form of rule, but they are also not too keen on the socially liberal aspects of western democracy either. If I were to draw a rough comparison to the US political spectrum, I would place them as moderates similar to Mitt Romney supporters, or at worst McCain. The ultra-orthodox - closer to the Ted Cruz types - is mostly made up of the the Mullahs and their following for which there are plenty, but far outnumbered by moderates and liberals combined. Again though, this is impossible to measure as if you go around surveying the country, most people (especially in the elder generation) will not publicly speak out against the government and its policies. reply red_trumpet 18 hours agorootparentprevWell, shooting down protestors is not democratic. Democracy is not a tyranny of the majority! reply realistic2020 14 hours agorootparent> Well, shooting down protestors is not democratic. Democracy is not a tyranny of the majority!Are you speaking about Iran or the USA or Israel?https:&#x2F;&#x2F;www.theguardian.com&#x2F;us-news&#x2F;2020&#x2F;jun&#x2F;08&#x2F;george-floyd...https:&#x2F;&#x2F;www.ohchr.org&#x2F;en&#x2F;press-releases&#x2F;2023&#x2F;05&#x2F;un-experts-d...https:&#x2F;&#x2F;www.history.com&#x2F;this-day-in-history&#x2F;rachel-corrie-ac... reply Gud 18 hours agorootparentprevThe Iranian government has killed thousands of people and repressed other viewpoints not supported by the ruling elite.It is possible the general population in Iran support this. All I know is that in countries where the people are allowed to voice their opinions freely, they generally oppose raping and torturing prisoners. reply quotz 17 hours agorootparentBut this also works for China. I dont see any nobel prizes awarded to the uyghurs yet reply catlover76 18 hours agorootparentprevI am only a little more informed than most people on the topic, but I think it&#x27;s kind of like this:The conservative majority likes having an Islamic Republic, and has a lingering \"memory\" of the corruption and such of the Shah&#x27;s regime, but that doesn&#x27;t necessarily mean they like what the current regime has become. And as another poster said, the majority of the country, whatever their social&#x2F;religious views, seems to be fed up with the country&#x27;s rather dire economic state. It&#x27;s been that way for the past like 5 years at least. reply michaeltimo 17 hours agorootparentThe main question is, what percentage of the society are these conservatives? What&#x27;s the opinion of the rest of people? Unlike you, in my opinion, most people have good memories of the Shah&#x27;s time (Zamane Shah). It&#x27;s quite funny, but most of the hospitals that are now named after Khomeini Hospital were built by the Shah. Also most stadiums and universities.Moreover, this is a superficial view of the story if we think that what annoys people in Iran is mostly economic. This can be seen even in the slogan of the biggest anti-government demonstration that started last year, \"Women, Life, Freedom\", the three things that has been oppressed in the last four decades. Yes, economic issues have put a lot of pressure on the people, but people&#x27;s wishes should not be reduced to it. reply catlover76 17 hours agorootparentIt&#x27;s probably a little bit like they now think this is worse than Zamaan-e-Shah, and that time is now viewed with history&#x27;s rose-colored glassesBut the Shah was overthrown for a reason (and his overthrow was good and just even if what succeeded it didn&#x27;t pan out well), and was a pretty popular event.In the absence of the Regime&#x27;s latest round of oppression, where they really turned it up a notch, and in the absence of economic turmoil, I doubt there would be much by the way of serious protests. I don&#x27;t believe that absolutely everything can be reduced to economic factors, but I think that&#x27;s usually a pretty big motivator in terms of getting most of any population to care enough about something to risk life and limb to protest. replyarchon1410 23 hours agoprevI feel the Nobel prize was less for fighting for women&#x27;s rights, and more for fighting against an anti-American, anti-Western government. For some reason, I don&#x27;t see the award ever going to a rights activist fighting against the Saudi, Pakistani, or any other American-allied regimes. I of course don&#x27;t ever see it going to someone fighting against the American regime itself, and its mass surveillance and war crimes, such as Edward Snowden or Julian Assange, or Chelsea Manning. reply fauigerzigerk 21 hours agoparent>For some reason, I don&#x27;t see the award ever going to a rights activist fighting against the Saudi, Pakistani, or any other American-allied regimes.There have been a few, such ashttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Yasser_Arafathttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nelson_Mandelahttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Maria_Ressahttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rigoberta_Mench%C3%BA reply imjonse 21 hours agorootparentTo be fair, Mandela did not get it while imprisoned and while the US and the UK were tacit supporters of the Apartheid regime.And Maria Ressa seems anti-Duterte, and pro-US if I read correctly. reply dragonwriter 18 hours agorootparent> To be fair, Mandela did not get it while imprisoned and while the US and the UK were tacit supporters of the Apartheid regime.To be even more fair, Mandela wasn’t the first anti-apartheid Nobel Peace Prize award, and Albert John Lutuli (awarded 1960) and Archbishop Tutu (awarded 1984) got it for fighting apartheid when the US and UK were tacit (active, of the regime if not the apartheid policy specifically, in 1960) supporters of the apartheid regime (Reagan’s reversal on his “constructive engagement” approach came inmediately after Archbishop Tutu&#x27;s address to Congress and subsequent meeting with the President after the award.. And Dr. King (awarded 1964) got it for his opposition to the parallel policy in America. reply imjonse 18 hours agorootparentYou are right. Although those recipients were clearly in favor of non-violent fighting for human rights and were not explicitly anti-western or anti-US (the definitions of non-recipients this subthread started with) When Dr King began opposing the Vietnam war instead of simply fighting for equal rights at home he became a larger menace. reply fauigerzigerk 17 hours agorootparentThe definition of non-recipients was never tied to violence. The examples given were Edward Snowden, Julian Assange and Chelsea Manning, all peaceful activists or journalists. reply imjonse 13 hours agorootparentMedia made sure these three were tied to violence. reply LindeBuzoGray 21 hours agorootparentprevRight, Mandela got it when he was being conciliatory to the government and its Western support, with other ANC elements being less so.The same with Arafat - he was conciliatory to Israel and its western support at Oslo, with Hamas and the PFLP being less so.Both were not fighting when.they got the prize, but being conciliatory. reply fauigerzigerk 21 hours agorootparentI don&#x27;t agree that Arafat was fighting any less than Narges Mohammadi when he got the Nobel Peace Prize. He didn&#x27;t get the prize for surrendering (neither did Mandela but he got the prize after he had already won). reply fauigerzigerk 21 hours agorootparentprev>Mandela did not get it while imprisoned and while the US and the UK were tacit supporters of the Apartheid regimeTrue>Maria Ressa seems anti-Duterte, and pro-US if I read correctlyDuterte is&#x2F;was a Trump style figure in a country that houses U.S military bases. If Pakistan counts then the Philippines must count as well. reply imjonse 20 hours agorootparentI mean the Philippines is traditionally a US ally, but Duterte both openly criticised the US and tried to get closer to China. And Maria Ressa is definitely not an anti-US or anti-Western activist. reply fauigerzigerk 20 hours agorootparent>but Duterte both openly criticised the US and tried to get closer to ChinaYes he did for a moment before completely reversing course.https:&#x2F;&#x2F;www.rand.org&#x2F;blog&#x2F;2021&#x2F;11&#x2F;dutertes-dalliance-with-ch...Pakistan&#x27;s various leaders on the other hand have criticised the U.S far more harshly and far more persistently over the years. They have also had close relations with China for decades. reply imjonse 18 hours agorootparentThere are no peace Nobel prizes for such Pakistanis though. Malala got it for figthing for education of young girls. Although I no longer remember how Pakistan got into the discussion and if we&#x27;re arguing or agreeing :) replyshihab 18 hours agorootparentprevYou&#x27;re mistaken about Yasser Arafat. He wasn&#x27;t awarded the Nobel Peace Prize for fighting Israeli apartheid; rather, he received it for ceasing that fight in line with the Oslo Accords- a deal brokered by the United States.Here&#x27;s a visual representation of why: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Oslo_Accords#&#x2F;media&#x2F;File:Bill_... reply fauigerzigerk 17 hours agorootparentArafat was awarded the Nobel Peace Prize for his efforts to make peace in the middle east (as were Shimon Peres and Yitzhak Rabin), not for ceasing his political fight or for giving up his ambitions.He said: \"Peace is in our interest: as only in an atmosphere of just peace shall the Palestinian people achieve their legitimate ambition for independence and sovereignty.\"Narges Mohammadi&#x27;s fight is a peaceful one as well. reply shihab 16 hours agorootparentI do not disagree that this was a peaceful move, I rather disagree that Yasser Arafat is an example of someone getting the peace prize despite acting against American&#x2F;Western interest. reply fauigerzigerk 15 hours agorootparentThe claim that I responded to was essentially that only opponents of anti-Western regimes ever get the Nobel Peace Price. Arafat is a counter example to that.Arafat&#x27;s decision to pursue his goals with political means is neither pro- nor anti-Western&#x2F;Israeli. It was meant to be pro-Palestinian. Hardliners on both sides hated the idea and unfortunately they have prevailed. replyimjonse 21 hours agoparentprevLê_Đức_Thọ, who fought the US in Vietnam, got it in 1973 (together with Kissinger) and promptly refused it. Maybe the Nobel committee does not want to be embarrassed by a refusal again, and that is the only reason it no longer awards it to anti-western activists :)https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;L%C3%AA_%C4%90%E1%BB%A9c_Th%E1... reply funnyflywheel 20 hours agorootparentThanks for the reminder that Heinz (Henry) Kissinger is still alive at age 100. reply sneak 22 hours agoparentprevThey gave the Nobel Peace Prize to a US president who had ordered so many drone strikes that even by the US&#x27;s own admission, hundreds of children were slaughtered.It&#x27;s pretty farcical. reply wizerdrobe 21 hours agorootparentBy virtue of the President’s role of Commander in Chief and that Doctor’s Without Borders as an organization has received the prize, it can be said that this President is the first to bomb another Nobel recipient after an attack on a MSF hospital.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Kunduz_hospital_airstrike reply zarzavat 20 hours agorootparent> On 7 October 2015, President Barack Obama issued an apology and announced the United States would be making condolence payments of $6,000 to the families of those killed in the airstrikeLiterally adding insult to injury. No wonder the US kills so many foreigners if it only values them at six thousand dollars a piece. reply imjonse 21 hours agorootparentprevWhile literary Nobel prize winners may have their feuds, peace prize winners&#x27; disagreements can get much more serious. reply voisin 21 hours agorootparentprevHad the drone strikes started when he Obama received the Nobel? It was awarded October 9, 2009, and he had only taken office that January. I recall the drone strikes (possibly incorrectly) being a second term controversy, not a first 9 months controversy. reply psychlops 19 hours agorootparentObama did more drone strikes in his first year (563) than Bush did his entire term. I can&#x27;t find the specific months, but it&#x27;s unlikely it was all done in the last quarter. He also authorized the first drone strike on an American. reply astrange 3 hours agorootparentBush didn&#x27;t do drone strikes because he was too busy starting wars. The drones were supposed to be a replacement for the war. reply brookst 20 hours agorootparentprevIt’s a common misconception that the prize is for being a 100% peaceful person one’s entire life. In fact the award is for making progress on peace in a specific context; it is not meant to certify the recipient has no blood on their hands.See also: all of the winners whose pasts include revolutionary actions that killed innocents. reply nirav72 16 hours agorootparentIncluding a former member of the Waffen-SS.https:&#x2F;&#x2F;www.dw.com&#x2F;en&#x2F;nobel-prize-winner-grass-under-fire-fo... reply toyg 20 hours agorootparentprevAs others said, the prize was well before drone strikes were a thing. It was basically honouring the effort to run and win the US presidential election as a black man, something nobody had ever managed to do. reply Luctct 18 hours agorootparentBecause being a black man is what really matters in a presidential election. Got it. reply alickz 14 hours agorootparentHow much it matters depends on many factorsI think you&#x27;d be intellectually dishonest saying it wasn&#x27;t a historical election reply 0xDEF 21 hours agorootparentprev>even by the US&#x27;s own admission, hundreds of children were slaughteredDid the US really admit that or was it something that was exposed by NGOs and investigators? reply shmde 21 hours agorootparentHead of the country Barack Obama literally apologized for bombing the Kunduz hospital ? Will anything change if they admitted to or not ? reply trimethylpurine 20 hours agoparentprevThis is because civil rights are a Western ideology. They certainly didn&#x27;t come from ISIS&#x27; views on women. Nor from Russia and China, who supported them.Snowden defected to Russia, see above about supporting ISIS. Assange and Manning&#x27;s exposure literally cost the lives of Afghan families who were working against AQ, another regime that openly oppresses its people&#x27;s civil rights.I think you might need to have a hard look at what you think peace is.So far, the most civil rights a person can experience is under Western governance, flawed as it is. reply user3939382 20 hours agorootparent> Snowden defected to RussiaTo add context, Snowden became trapped in Russia when the US State Department decided to cancel his passport while he was at an airport there on the way out of Russia.> Assange and Manning&#x27;s exposure literally cost the lives of Afghan familiesExposure like the footage they revealed of US drones killing innocent civilians?> The U.S. post-9&#x2F;11 wars in Iraq, Afghanistan, Yemen, Syria, and Pakistan have taken a tremendous human toll on those countries. As of September 2021, an estimated 432,093 civilians in these countries have died violent deaths as a result of the wars.Right, Assange is the problem, not the US military operations he exposed. reply trimethylpurine 20 hours agorootparent>Right, Assange is the problem, not the US military operations he exposed.It&#x27;s only clear that civilians were intentionally targeted by ISIS and AQ. It&#x27;s also true that civilians who opposed Western military forces were killed. That&#x27;s expected, because opposing a military force is an official enlistment.Assange is the problem. You don&#x27;t get a peace prize for aiding in civil rights oppression. reply muniq 19 hours agorootparentprevThe Soviet Union provided more material support against colonialism and apartheid than the United States. Ask Mandela. reply trimethylpurine 16 hours agorootparentThat might be true, but it&#x27;s largely irrelevant. When SA embraced civil rights, it became Western. reply AnonCoward42 20 hours agorootparentprev> This is because civil rights are a Western ideology. They certainly didn&#x27;t come from ISIS&#x27; views on women. Nor from Russia and China, who supported them.How do you come to the conclusion that Russia and China support ISIS? reply trimethylpurine 19 hours agorootparentThe insurgency was armed with Russian and Chinese equipment that was given to Iraq between 2003 and 2009.You can read about the Iraqi Insurgency for more information.But more generally, US, China, Russia have all been fighting&#x2F;arming proxy wars over there for around 50 years. reply AnonCoward42 15 hours agorootparentThey \"use the equipment\" and actual support are not the same. Did they arm ISIS directly or did the weapons end up there a different way?> But more generally, US, China, Russia have all been fighting&#x2F;arming proxy wars over there for around 50 years.But supporting terrorist groups is not something Russia nor China does on this level. reply trimethylpurine 11 hours agorootparentYes, they armed them directly.Yes they supported terrorist groups. As did the US. No one is innocent. But the US has always supported democracy and civil rights. That includes civil rights activism deemed \"terrorist\" by China and Russia.The West represents civil rights. That&#x27;s just as fact. Ask yourself, are people enjoying civil rights in China or Russia living with a quality of life far below Western nations? Obviously not. reply AnonCoward42 2 hours agorootparent> Yes, they armed them directly.Of course I want a source for that.> Yes they supported terrorist groups. As did the US. No one is innocent.How are \"we\" supposed to be better then?> But the US has always supported democracy and civil rights. That includes civil rights activism deemed \"terrorist\" by China and Russia.Al Qaida, Al Nusra, Taliban etc are civil rights activits for the US (sold as \"moderate rebels\" in Syria by German media at least). Of course they are deemed terrorists in other countries. I find the civil right activism of the US questionable to say the least.> Ask yourself, are people enjoying civil rights in China or Russia living with a quality of life far below Western nations?I ask myself if I do enjoy civil rights if I hold dissident opinions in western countries. Am I supposed to feel better that it is supposedly worse in other countries, while it&#x27;s obvious that we target 3rd world country standards for human rights? replyg232089 22 hours agoparentprevThat the Nobel Peace Prize is not a serious award should have been evident when Obama won it. reply cdogl 20 hours agorootparent“When Kissinger won the Nobel peace prize, satire died” - Tom Lehrer, long ago reply willcipriano 22 hours agorootparentprev2 wars when he was sworn in, 7 when he left. I&#x27;m pretty sure he is the peace prize recipient who started the most wars. reply perihelions 21 hours agorootparent- \"I&#x27;m pretty sure he is the peace prize recipient who started the most wars\"Henry Kissinger, 1973?edit: I think Wilson (1919 Nobel; 1913-1921 presidency) is also a contender, if anyone has the patience&#x2F;stamina to count all his conflicts and classify them. (I.e. what counts as \"starting a war\" and what&#x27;s better described as a continuation of an existing conflict).https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Presidency_of_Woodrow_Wilson#F...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Banana_Wars reply willcipriano 21 hours agorootparentIf we go off the war crimes outlined in Hitchen&#x27;s \"The Trial of Henry Kissinger\"> Hitchens presents Kissinger&#x27;s involvement in a series of alleged war crimes in Vietnam, Cambodia, Laos, Bangladesh, Chile, Cyprus and East Timor.They are tied for the record for number of nations they committed war crimes in. Although if you include CIA backed coups I think Obama pulls ahead. reply srean 21 hours agorootparentprevI&#x27;d kill for a Nobel Peace Prize -- Steven Wright reply catlover76 18 hours agorootparentprevAt the risk of further encouraging you to think that there is validity to anything you regurgitate, what do you think were the \"7 wars\"? And how did Obama \"start\" them? reply bnralt 20 hours agoparentprevElBaradei won in 2005, when he was a vocal opponent of Bush&#x27;s military interventions (Obama&#x27;s prize in 2009 was likewise mainly a rebuke of Bush).Tawakkol Karman (2011) has been a vocal critic of Saudi Arabia.Willy Brandt received his prize specifically for increasing ties with the Eastern Bloc.In terms of prizes giving for those working against particular regimes, anti-apartheid activists have received the most (1960, 1984, 1993).A lot of people end up making assumptions based on their own personal biases. reply muniq 19 hours agorootparentGandhi - whose name has become synonymous with peace and non-violence - was nominated 3 times but didn&#x27;t win.The evidence strongly suggests that the Nobel committee doesn&#x27;t like giving the prize against anti-western dissidents until they absolutely have to, i.e. when not giving the prize would raise more eyebrows and damage the Nobel&#x27;s reputation. The two anti-western dissidents that come to mind are Nelson Mandela and (arguably) Martin Luther King. Again, they received the prize after achieving global fame and recognition.ElBaradei won the prize for his work in the IAEA (whose primary focus has been on non-western nations) -not for his opposition to the Iraq war - whose primary focus has been on non-western nations.Tawakkol Karman (2011) is another dissident against a non-western country.Willy Brandt wasn&#x27;t a dissident of the West. Far from it in fact - known for fierce anti-communist domestic policies , support for right-wing governments, the Vietnam war and for promoting greater European and western integration.Nobel prizes given to anti-apartheid South African activists seem to be a laudable counter-example to the rule though. reply bnralt 18 hours agorootparent> The two anti-western dissidents that come to mind are Nelson Mandela and (arguably) Martin Luther King. Again, they received the prize after achieving global fame and recognition.Seems like a “no true Scotsman” argument. Naturally, the winners are going to often be prominent individuals.> Tawakkol Karman (2011) is another dissident against a non-western country.The previous poster specifically said “I don&#x27;t see the award ever going to a rights activist fighting against the Saudi, Pakistani, or any other American-allied regimes,” so I brought up a recent activist that has been against the Saudi government (and I guess Malala Yousafzai could be viewed as critical of many parts of the Pakistani government).> ElBaradei won the prize for his work in the IAEA (whose primary focus has been on non-western nations) -not for his opposition to the Iraq war - whose primary focus has been on non-western nations.It was pretty obvious to everyone at the time that this (as well as Obama’s prize) was a direct rebuke against Bush’s foreign policy. Here’s the opening paragraph of the New York Times article about his award[1]:> The Nobel Peace Prize was awarded Friday to the International Atomic Energy Agency and its chief, Mohamed ElBaradei, whom the Bush administration tried but failed to remove from his job just months ago.> The award was a vindication of a man and an agency long at odds with President Bush and his administration over how to confront Iraq and Iran. It could strengthen the agency&#x27;s position as conflicts loom over preventing Iran from obtaining fuel it could use for nuclear weapons and disarming North Korea.> For most of the last year, the Bush administration had tried to block Dr. ElBaradei from assuming a third term as chief of the agency, a part of the United Nations, arguing that he would not be strong enough to face down Iran and the covert nuclear weapons program it is suspected of having. But the United States had no support from any of its allies, and ultimately had to withdraw its objections to Dr. ElBaradei&#x27;s reappointment.[1] https:&#x2F;&#x2F;www.nytimes.com&#x2F;2005&#x2F;10&#x2F;08&#x2F;front%20page&#x2F;world&#x2F;atomic... reply muniq 18 hours agorootparent> Seems like a “no true Scotsman” argument. Naturally, the winners are going to often be prominent individuals.I would argue that the majority of recent Peace Laureates (including this years) became internationally prominent after winning the prize. Did you know of Narges Mohammadi before this announcement?> The previous poster specifically said “I don&#x27;t see the award ever going to a rights activist fighting against the Saudi, Pakistani, or any other American-allied regimes,”I really wasn&#x27;t defending the OP&#x27;s assertion. In fact, I don&#x27;t agree with it at all. These are largely transactional western alliances. While the Nobel Committee might want to avoid a confrontation with Saudi Arabia, I doubt it has too many qualms about awarding prizes to dissidents from Pakistan. You already mentioned Yousafzai. My point was really that the Nobel Prize is rarely awarded to western dissidents (including journalists or activists) and is almost exclusively awarded to dissidents in non-western countries.> For most of the last year, the Bush administration had tried to block Dr. ElBaradei from assuming a third term as chief of the agency, a part of the United Nations, arguing that he would not be strong enough to face down Iran and the covert nuclear weapons program it is suspected of having. But the United States had no support from any of its allies, and ultimately had to withdraw its objections to Dr. ElBaradei&#x27;s reappointment.Your post already has my rebuttal. The United States was the sole objector to ElBaradei&#x27;s appointment- with the rest of the west and in-fact the rest of the world backing him. The Iraq War was universally unpopular by 2005 ( with a case of mass amnesia by supporters from pre-2003) Hardly a controversial choice. reply tonmoy 22 hours agoparentprevThere have been some “anti-western” Nobel peace prize awards in the recent past. I think Saudi Arab was not happy about 2011 Nobel peace prize winner for example. While Snowden and Assange have done great things, they are not exactly in line with the human rights activism type activities rewarded by the committee. reply mc32 21 hours agorootparentThe peace prize should be about people who promote peace or bring about peace.Snowden exposed civil rights violations and constitutional violations but I wouldn’t say it contributed to the avoidance of war or conflict.This should not be about “activism” but about political stabilization and the promotion of peace. reply csmpltn 22 hours agoparentprevThe Nobel prize is awarded by a committee of (largely) Judeo-Christian westerners, in a western country.Equivalent awards given out by dictatorships or theocracies around the world can be just as easily seen through the same lens of hypocrisy and cynicism. reply wslh 22 hours agorootparentI am courious: could you name the committee members? [1] I am sure they are westerners, not clear about if the \"Judeo-Christian\" claim is very precise [0]Obviously there is a bias in the awards, but is there a way to not be biased? Also, there is space to create better Nobel prizes for sure so blaming Nobel prize is in a way linked to the world incapacity to promote something better?[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Judeo-Christian?wprov=sfti1[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Norwegian_Nobel_Committee?wpro... reply alephnerd 19 hours agorootparentprev> Judeo-Christian westerners, in a western countryNo. Only a handful of elite Norwegians, as the committee is 5 former MPs selected by the Norwegian parliament.Apartheid South Africa&#x27;s leaders were Judeo-Christian westerners as well, but the award was given to their foe Nelson Mandela reply krmboya 22 hours agorootparentprevCan the West still be characterized as Judeo-christian? Western culture seems largely liberal at this point with the more religious people being lumped to the right wing.It is said many churches&#x2F;cathedrals in Europe are now appreciated more for their historical value than as places of worship reply throw4847285 19 hours agorootparentThe word Judeo-Christian is often used to refer to exactly that kind of secularized Christian morality which undergirds the post-Enlightenment west. It became popular as a means to combat anti-Semitism in America, by arguing that Jews and Christians (and nobody else) shared some kind of common moral framework which so happens to be what the United States was built on.The problem is, if you asked Jews 200 years prior about \"Judeo-Christian values\" they would have laughed you out of the ghetto. It&#x27;s solely the product of an assimilating Jewish population trying to make a claim to American identity, like Italian Americans and Columbus Day. It&#x27;s also totally entangled in debates about Zionism, as Judeo-Christian comes to mean \"Abrahamic but not Muslim.\" Actually, you hear Abrahamic get used more often as Muslims in America stake a similar claim to America. reply eunos 22 hours agorootparentprev*SwedishMuch more specific reply sahlab 22 hours agorootparentThe Nobel peace prize is awarded by a Norwegian committee.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Norwegian_Nobel_Committee reply astura 22 hours agorootparentprevNo, The Peace prize, specifically, is awarded by the The Norwegian Nobel Committee in Oslo.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Norwegian_Nobel_Committee reply nine_k 22 hours agoparentprevI wonder.why a Peace Prize should ever go to anyone for fighting, even if the fighting is for a patently just cause. There should be a different prize, or at least a different name for it.But this ship has sailed, apparently.OTOH it&#x27;s really understandable that many people value fighting for a just cause higher than peace. The easiest way to peace is often to just surrender, and have peace on the terms of an evil aggressor. But it&#x27;s not a kind of peace many people prefer to live in. reply sim7c00 21 hours agorootparentyou are right. people fight for peace, fight for freedom, whatever. People do not understand what is peace. There is only very few places in the world (1 where I know of, by chance) that actually study, what is peace. culture of peace. Peace is known not to be simply the absence of war, and so, trying to remove war isn&#x27;t neccesarily moving towards peace or a culture of peace, while many things which do not remove violence, can still be considered contributions (very great ones) to peace.imho the nobel peace prize should take into account what is peace, not just focus on the absence of war. this is an outdated idea. Polemology vs. Irenology.There are so many people contributing greatly to peace who are invisible. only the ones &#x27;fighting against war&#x27; are made visible. and with those, like other commentors suggest, its often simply an opinion. one mans terrorist is another mans freedom fighter, and one mans soldier is anothers terrorist... they are all fighting, killing or destroying (destruction can be non-physical here). it should atleast be a nobel anti-war prize or something. not a peace prize. it doesn&#x27;t do justice to the many people contributing actively to a culture of peace in one way or another. reply csmpltn 21 hours agorootparent> \"There is only very few places in the world (1 where I know of, by chance) that actually study, what is peace\"Where would that be? reply AnimalMuppet 21 hours agorootparentprev\"The Nobel Prize For Doing Nothing In The Face Of An Oppressor And Calling That Peace\" has far too many candidates for them to be able to pick a winner. reply nine_k 20 hours agorootparentIndeed.I&#x27;d say that the way Dalai Lama or MLK or even Mahatma Gandhi fought for their causes is rather different from the way Nelson Mandela or Abraham Lincoln fought for their causes. In either case, the cause was just and noble, and sometimes even the same. reply alephnerd 19 hours agoparentprev> more for fighting against an anti-American, anti-Western government\"[t]he recipient is selected by the Norwegian Nobel Committee, a five-member committee appointed by the Parliament of Norway. Since 2020 the prize is awarded in the Atrium of the University of Oslo\" [0]The winners are basically selected by a subset of retired Norwegian MPs, and even Alfred Nobel&#x27;s living heir has become opposed to the politicization of the Nobel Peace Price [1]. So it&#x27;s reflecting the values of a subset of the Norwegian eliteThe comment above should NOT be viewed as a rejection of Narges Mohammadi&#x27;s work.[0] - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nobel_Peace_Prize[1] - https:&#x2F;&#x2F;www.aftenposten.no&#x2F;meninger&#x2F;i&#x2F;wP6y1&#x2F;i-strid-med-nobe... reply dragonwriter 19 hours agoparentprev> For some reason, I don&#x27;t see the award ever going to a rights activist fighting against the Saudi, Pakistani, or any other American-allied regimesRigoberta Menchú (awarded 1992) was an activist against the abuses of US allied regime, which abuses were aligned with and arguably a manifestation of US geopolitical priorities, and the Rev. Dr. King (awarded 1964) was an activist against the abuses of the American regime itself. reply elashri 22 hours agoparentprevMy favorite Nobel peace prize goes to Abiy Ahmed who was awarded 2019 prize. He went to Sweden took the prize, deliver a speech then a couple of months later he went on a streak of atrocious in Ethiopia [1]. You name it ( mass killing, rape, genocide..etc).Also take into consideration that any head of state, prime minister or cabinet member in any government can nominate people for the prize (A lot of other people can do that too)[2] . So it would be always interesting to know who our governments officials nominated over time[1] https:&#x2F;&#x2F;www.economist.com&#x2F;middle-east-and-africa&#x2F;2023&#x2F;07&#x2F;09&#x2F;...[2] https:&#x2F;&#x2F;www.nobelprize.org&#x2F;nomination&#x2F;peace&#x2F; reply alephnerd 19 hours agorootparent> He went to Sweden took the prizeNorway> So it would be always interesting to know who our governments officials nominated over timeThere&#x27;s a list of nominees [0].The Pakistani Senate nominated Erdogan for this year&#x27;s prize, for example [0].That said, most nominations seem to be done by Norwegian MPs trying to message to their own constituents (eg. Abiy&#x27;s nomination and the large Ethiopian diaspora voting bloc in Norway and Sweden) [1][0] - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;2023_Nobel_Peace_Prize[1] - https:&#x2F;&#x2F;www.nytimes.com&#x2F;2021&#x2F;12&#x2F;15&#x2F;world&#x2F;africa&#x2F;ethiopia-abi... reply sorenjan 19 hours agorootparentprevThe peace prize is awarded in Norway. reply csomar 22 hours agoparentprevThe Nobel peace prize is a joke. I think, at this point, everyone knows that. They should have called it something else, so not to devalue the other Nobel prizes. But then it&#x27;d not be as catchy. reply LindeBuzoGray 22 hours agoparentprevAlso Iran in 1953 had a prime Minister Mosaddegh, who wanted to nationalize Iran&#x27;s oil. The UK (and US) sought the support of right-wing mullahs, then overthrew the prime minister and replaced him with a dictator. Then the CIA helped SAVAK kill off the secular left for the next few decades. Eventually even the right-wing clerics and bazaari grew tired of foreign interference and threw the western powers out. reply bnralt 19 hours agorootparent> Also Iran in 1953 had a prime Minister Mosaddegh, who wanted to nationalize Iran&#x27;s oil.Iranian oil was nationalized; in 1951 the National Iranian Oil Company took control, and retained it even after Mossadegh’s ouster (even up to today).> The UK (and US) sought the support of right-wing mullahs, then overthrew the prime minister and replaced him with a dictator.First, by this point in time Mossadegh had dissolved parliament and was ruling by fiat based on a rigged plebiscite (he claimed that 99.9% of Iranians had voted to give him control of the country[1]). Second, he wasn’t replaced with a dictator. The Shah had been in power since the Soviet Union and the U.K. had forced his father to abdicate over a decade before, and had been in a power struggle with the Majlis for quite some time by that point.> Eventually even the right-wing clerics and bazaari grew tired of foreign interference and threw the western powers out.The Shah was (mostly) friendly with the West, but he was hardly a puppet. He was the one who got OPEC to double their prices during the 1973 oil crisis, which hit the West pretty hard. Here&#x27;s how PBS put it[2]:> The final blow came in December when the Shah of Iran, ostensibly a U.S. ally, took advantage of American impotence and persuaded the rest of the Organization of Petroleum Exporting Countries (OPEC) to more than double the price of a barrel of oil from $5.11 to $11.65.[1] https:&#x2F;&#x2F;www.nytimes.com&#x2F;1953&#x2F;08&#x2F;04&#x2F;archives&#x2F;mossadegh-gets-9... [2] http:&#x2F;&#x2F;www.pbs.org&#x2F;wgbh&#x2F;pages&#x2F;frontline&#x2F;tehranbureau&#x2F;2012&#x2F;06... reply LindeBuzoGray 18 hours agorootparent> Iranian oil was nationalized; in 1951 the National Iranian Oil Company took control, and retained it even after Mossadegh’s ouster (even up to today).Control of oil sales reverted back to British Petroleum (and the Seven Sisters) after the US&#x2F;UK ousted Iran&#x27;s prime Minister with Operation Ajax. Not all of Mosaddegh&#x27;s changes were undone as it would gave destabilized the Shah.> Second, he wasn’t replaced with a dictator. The Shah had been in powerThe Prime Minister ran the government like a modern western government, the Shah was a figurehead. What you&#x27;re saying is the US and UK wanted to remove the modern parliament to revert to an older, anti-democraric, conservative, traditional government. Which is what happened, and now the Swedes and westerners are whining about the traditionalism the west foisted on Iran, now that it is no longer western aligned.Aside from mullahs and the dictator, the CIA gave money to criminal elements in Iran to help regain western control.The Shah was a figurehead and left for Italy. He did not want to run Iran or even go back but was convinced to by westerners. He flew back to Iran with Allen Dulles.> had forced his father to advocated over a decade beforeForced his father to advocate? Advocate for what? reply bnralt 18 hours agorootparent> The Prime Minister ran the government like a modern western government, the Shah was a figurehead.This is simply false. If you want an example, look at the 1949 Iranian constitutional assembly where the Shah was able to successfully change the Iranian constitution to increase his political power. A lot of people are only interested in the U.S. involvement in ousting Mossadegh 1953, and frankly don’t seem to understand (or seem interested in understanding) anything else that was happening in the country at the time.> Forced his father to advocate? Advocate for what?Sorry, that should have read \"abdicate.\"> What you&#x27;re saying is the US and UK wanted to remove the modern parliament to revert to an older, anti-democraric, conservative, traditional government.No, the Majlis had been dissolved by Mossadegh after they threatened to oust him, and then he used a rigged plebiscite to take full control of the country[1]:> The Iranian Majlis, the lower house of Parliament, which last month threatened to oust Premier Mohammed Mossadegh with votes of no confidence, was declared today to have been dissolved as the result of the referendum completed this week, in which 99.94 per cent of the voters using non-secret ballots took the Premier&#x27;s side in his quarrels with the chamber.[1] https:&#x2F;&#x2F;www.nytimes.com&#x2F;1953&#x2F;08&#x2F;16&#x2F;archives&#x2F;mossadegh-terms-... reply tibbydudeza 22 hours agorootparentprevOr Chile where they overthrew an elected communist govt and they got Pinochet and the disappeared.But I am grateful for them helping Ukraine even if it for their own geopolitical goals. reply Luctct 18 hours agorootparentAllende was destroying Chile. The Chilean military had the good sense of putting an end to it. reply tibbydudeza 17 hours agorootparentBut he was elected good or bad policies it was up to the voters to decide - the CIA&#x2F;US supported coup bought in a military dictator who had people dropped into the sea and lakes from aircraft.How about the mothers still today protesting about their sons&#x2F;daughters who disappeared (1,248). reply rsynnott 18 hours agoparentprev> I of course don&#x27;t ever see it going to someone fighting against the American regime itselfMartin Luther King Jr got one. reply bohadi 22 hours agoparentprevye prestige award is a political football now. same as it ever was? reply 77pt77 13 hours agoparentprevMy personal favorite is still Henry Kissinger, alive and well at 100 years old. reply Theodores 19 hours agoparentprevIf I remember correctly, Saudi Arabia and Iran struck a peace deal this year, brokered with Chinese help. We haven&#x27;t heard about Yemen since.Surely Xi Jinping, MBS and Khamenei deserve the award for actual peace?Yeah, that is three people we are told to hate. But they achieved actual peace.Instead we get this Iranian woman that nobody had heard of before today.Something is not right. reply alephnerd 19 hours agorootparent> Saudi Arabia and Iran struck a peace deal this year, brokered with Chinese help.It wasn&#x27;t a peace deal - it was a normalization of relations (aka they&#x27;ve reestablished diplomatic contact) [0]. Iranian and Saudi proxies are still killing each other in Syria and Iraq.> We haven&#x27;t heard about Yemen since.That&#x27;s because of Oman acting as a mediator between the Houthis and Saudis [1][0] - https:&#x2F;&#x2F;foreignpolicy.com&#x2F;2023&#x2F;06&#x2F;12&#x2F;saudi-iran-rapprochemen...[1] - https:&#x2F;&#x2F;www.cfr.org&#x2F;global-conflict-tracker&#x2F;conflict&#x2F;war-yem... reply lettergram 21 hours agoparentprevTo be fair, Obama was granted a Nobel peace prize almost as soon as he got in office (just for being in office)… it was also right before continuing the drone assassination campaign, including the extra judicial killing of US citizens without trialhttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Killing_of_Abdulrahman_al-Aw...I’ve always views the Nobel peace prize as a political body. Designed to highlight and reward people of a certain persuasion. reply pastor_bob 20 hours agoparentprev>Edward SnowdenYou mean the guy who has sworn allegiance to Putin and takes an anti-Ukraine stance on Twitter to save his neck? A guy who has made millions peddling &#x27;his story&#x27; and lives a life of luxury in Moscow? Yeah, surely he should get a Nobel prize reply wheelerof4te 23 hours agoparentprevHonestly, I didn&#x27;t expect a rational comment about this on Hacker News.It&#x27;s scary how rare these are. reply zadler 22 hours agorootparentThe light from the Overton window is less every day… reply subjectsigma 22 hours agorootparentprev> I feel > I don’t seeInterpreting world events based on your own biased viewpoints and emotions and then making mostly unsupported predictions is not exactly rational reply nicce 22 hours agorootparentprevIt is very difficult to think these matters in rational and neutral way. Everyone has a side and if you talk against your own ”side”, you get cancelled.While, for example, the above is quite obvious if you know how politics and power work. Everyone likes to stay as ”a good guy”, but it is impossible to have and maintain power by being just a good guy.Many nations try to keep a specific narrative and most believe on it because they don’t like the alternative, as it would make many arguments hypocrite. reply binarymax 19 hours agoprevIt would be nice if instead of everyone hating on the prize, we could take a moment and reflect. Think of what this woman and many other women trapped in these regimes are going through, the sacrifices they&#x27;ve made, and the bravery they show to try to make things better.Think the prize is politicized and corrupt? Whatever - it&#x27;s not about you or your opinion. reply LindeBuzoGray 18 hours agoparent> Think of what this woman and many other women trapped in these regimes are going throughIran had a parliament in 1953, when the US and UK launched operation Ajax after the prime Minister nationalized Iran&#x27;s oil. The prime Minister was ousted, a dictator replaced him - who returned to Iran on a flight with Allen Dulles. The conservative mullahs were western allies in removing power from the parliament.Then this structure the west put into place fell out of alignment with the west in 1979, and we suddenly hear an enormous amount of stated sympathy about \"women trapped in these regimes\". Sympathy that we didn&#x27;t hear when the CIA was handing SAVAK lists of progressive, secular women to arrest or kill. It&#x27;s farcical. reply continuitylimit 17 hours agorootparentYour story about operation Ajax is just that - a story. Iran’s PMs were all elected by parliament and the one before Mr. Mossadeq was assassinated by Islamists allied to your “democrat” who then let the killer get off with no jail time.You also fail to note that the PM in question had a “99%” referendum during his tenure. You also fail to mention that the said PM refused his constitutionally valid dismissal by the Shah and then proceeded to launch a COUP against the constitutional monarchy.You fail to mention all this because NYTimes and CIA and the rest of the Western world is perfectly happy with the narrative of Kermit Roosevelt getting off the plane with a suitcase of dollars and then taking over a “99%” supported regime overnight! CIA is sure impressive!The facts are that the PM in question began to alienate his allies — the Islamists — so they withdrew support, and very substantial chunk of the nation absolutely did not agree with his coup and his program of unilaterally changing the outcome of the 1905 Constitutional Revolution of Iran which do grant certain powers to the monarch. This includes dismissing the PM.So, now that we have a more ‘rounded’ historic context of what actually led to ‘53 counter coup encouraged and supported by US and UK (which failed) and the next day’s Army’s counter-coup (which succeeded), the topical point remains:Whatever CIA, or “Anglo-Saxons” or this or that evil empire has done in NO WAY excuse or elucidate the dictatorial regime of the clergy and their very open trampling the rights of women in Iran.I am not sure what is the Islamist version of “Tankee” but you are it.[and a ps for Iranians in the audience]If you continue to repeat the ridiculous NYTimes&#x2F;CIA version of the story you are denigrating our great people. The idea that some flunky from CIA with a suitcase of cash managed to unseat a “99%” PM overnight mainly says that Iranians are mindless chumps who are trivially manipulated. This is neither flattering or accurate. reply Qiu_Zhanxuan 16 hours agorootparentMost people today would agree with Mossadegh&#x27;s initiative and the point remains that he was ousted from power for his nationalization of a western oil company and his inimity with the islamists and the Shah. The US helped in the process. And it&#x27;s no disrespect to the iranians to state those facts. reply continuitylimit 16 hours agorootparentwho are these “most people”?Everyone in Iran, including the Shah, wanted Iran’s oil nationalized. It was the economic consequences that tempered others. The Good Dr. had to go hat in hand to US and beg Eisenhower to aid after oil revenues stopped. That was his bright idea.Also your story is not the propaganda narrative that is repeated. This is the single paragraph story:Iran did have a democratic government, but because the PM nationalized the oil, US did a coup and installed a dictator, the shah.And that is entirely different from your “US helped in the process”. That would be accurate because that is all it was: in the main political support. Then, we in fact had a decade were Generals were powerful, until the Shah, finally in 60s (without CIA and to the great annoyance of the Kennedys) assumed all the power after having disbanded the Communist party and defanged the National Front. The “dictatorship” began 10 years later and it was far more benevolent than say a psycho killer like Mao who murdered millions. But Mao was a “great man” and the Shah is a “dictator”. Go figure. reply lolinder 15 hours agorootparentprevYour reply is a complete non sequitur.This is a prize awarded by the 2023 Norwegian Nobel Committee, appointed by the Norwegian Parliament. The oldest member of the committee was 4 years old in 1953, and all five are Norwegian, not American or British. The person who received the award is an Iranian woman.Why the hell is the bad behavior of the CIA in 1953 relevant to this discussion? \"The West\" is not a monolithic entity that should be held accountable as a single unit indefinitely for evil things done by two countries 70 years ago. reply beebeepka 15 hours agorootparentAre we still talking about Nobel peace prizes here?Even Obama got one. reply thriftwy 15 hours agorootparentprevHow about being held accountable at least once? That did not happen yet. The best thing that we hear is some random liberal american \"not approving\" Iraq or Libya invasions. reply Tao3300 18 hours agorootparentprevOk? Where&#x27;s this going? We&#x27;re not supposed to care now because the CIA did some shady stuff a million years ago? reply potatototoo99 17 hours agorootparentIt&#x27;s going to this being manufactured. As you say you are \"supposed to care\" when it&#x27;s convenient, only. It is obvious there is much more attention and criticism on Iran than other regimes you are not supposed to care, and you don&#x27;t even need to look very far. reply catlover76 15 hours agorootparent> It is obvious there is much more attention and criticism on Iran than other regimes you are not supposed to care, and you don&#x27;t even need to look very far.Everyone always acts like it&#x27;s some kind of conspiracy that their most-hated governments don&#x27;t get sufficient criticism or that their favorite governments get more than a fair share of criticism. reply thriftwy 15 hours agorootparentWhy do you assume it isn&#x27;t a conspiracy? It is. It is absolutely a conspiracy.WSJ, NYT or Guardian know which words are allowed for Iran and which are for Saudis. reply catlover76 12 hours agorootparentI can only roll my eyes at this and continue to not take you seriously.First of all, you&#x27;re assuming a parity between the governments of Iran and Saudi Arabia. A couple of years ago, I would have been more sympathetic to this point, but with Iran&#x27;s brutal crackdown of late, which apparently includes widespread rape of women in prisons, I think it&#x27;s safe to say the Regime is accomplishing the impressive feat of making Saudi Arabia look good.Really, I think it may really just come down to money; Saudi Arabia is in the fortunate position of being able to pay large chunks of its citizenry to be docile and follow the rules. If their economy was similarly bad, I do think it&#x27;s likely they would be also be engaging in violent repression.Second of all, you can probably find plenty of Guardian articles criticizing the Saudi government. In fact, you&#x27;ve provided very little evidence of any kind that those three publications use any of the same language at all about either government, or that they don&#x27;t criticize Saudi Arabia.Third, even if you could point to similarities, it wouldn&#x27;t be evidence of a \"conspiracy\"; it would instead merely reflect a double-standard held among the Western public at large, which tends to view Iran worse than Saudi Arabia because, on some reptilian level, it knows Saudi Arabia is a geo-political ally and Iran is an enemy. If you want to say this opinion is hypocritical, I&#x27;d say you&#x27;re probably right (especially since Saudi hasn&#x27;t been acting like an ally lately), but of course, you&#x27;re not making any such reasonable claim.At the end of the day, an allegation of \"conspiracy\" is simply something lodged by what I would call the \"ignorant arrogant\"; people who think they are smarter than they are, but who actually have no desire or ability to actually think critically. Instead, they just want an easy answer to lay blame for things they don&#x27;t like. There is a lot of mental and emotional infirmity involved in calling things \"conspiracies\". reply thriftwy 11 hours agorootparent> Iran&#x27;s brutal crackdown of lateWe only know about Iran&#x27;s brutal crackdown of late from western NGOs and their thralls. Heck, most of Iranians themselves are likely getting these news from these sources, and not from direct or second order witnesses.Meanwhile, we never seem to hear anything about Saudi Arabia. No crackdowns, no police brutality, no dress code enforcement. Yes, we do hear \"criticisms of SA government\", but that is a far cry from full throttle inciting of rebellions and then covering these rebellions 24&#x2F;7, by the means of media.I&#x27;m not saying that Iran is a nice country to live if you are a young woman. It&#x27;s just that in Saudi Arabia they could not even drive until very recently.A \"double-standard held among the Western public at large\" is the conspiracy I&#x27;m talking about. You don&#x27;t need to have any evil puppeteers if your media are obedient to the sufficient extent and if self-proclaimed critical thinking experts are in fact mental gymnastics experts.I&#x27;m also wondering how much do you need to be paid to be content about not being treated as a person. reply catlover76 10 hours agorootparent> A \"double-standard held among the Western public at large\" is the conspiracy I&#x27;m talking about. You don&#x27;t need to have any evil puppeteers if your media are obedient to the sufficient extent and if self-proclaimed critical thinking experts are in fact mental gymnastics experts.If you think the media is \"obedient\", then yes, you are alleging a conspiracy because it makes you feel smarter and more savvy than you are. A general double-standard is not a conspiracy.> We only know about Iran&#x27;s brutal crackdown of late from western NGOs and their thralls. Heck, most of Iranians themselves are likely getting these news from these sources, and not from direct or second order witnesses.This is such an absurd and kind of morally off thing to say; you&#x27;re basically acting like certain horrors that are being perpetrated against some people probably aren&#x27;t happening, and are ignoring any real footage that comes out of Iran.> Meanwhile, we never seem to hear anything about Saudi Arabia. No crackdowns, no police brutality, no dress code enforcement.You can hear plenty of negative news about it, but has it occurred to you that the reason why we hear less is because there is less? No, you could not give that notion any credence, because it would rob of you of the superiority you feel from being contrarian and sophomorically cynical. reply thriftwy 1 hour agorootparentWhat real footage? As far as I noticed there are two bodies in Iran stories on the timespan of a year, one of which is still warm. It is a horrible personal tragedy, but as far as social struggle goes, not so much.There are likely much more secondary victims who were incited by NGOs to riot and got brutalized by riot police. Who is to blame here, especially in the absense of results?How much less are we hearing from SA? Half a dead body per year? We&#x27;re not hearing anything and that&#x27;s it. replymichaeltimo 18 hours agorootparentprevIt might seem like a hard take but, what happened in 1979 is not much different that 1953 with regard to influence of western countries on it IMO. Many people in Iran also believe the 1979 \"revolution\" was supported by western countries, if not planned. Iran was on a path to rapid growth and also Shah&#x27;s decision on doubling the Oil&#x27;s price in 1973 could be another reason [1].http:&#x2F;&#x2F;www.pbs.org&#x2F;wgbh&#x2F;pages&#x2F;frontline&#x2F;tehranbureau&#x2F;2012&#x2F;06... reply bryanrasmussen 17 hours agorootparentprevI&#x27;m pretty sure there were people who cared in 1979, I wasn&#x27;t one of them because I was in school. And I mean, I&#x27;m probably older than most people on HN. Probably a significant percentage of the community here didn&#x27;t care in 1979 because they weren&#x27;t alive.Anyone old enough to vote in 1979 is probably pretty close to retirement now. Almost everyone in a position of power in 1979 is probably dead. Obviously Biden was a young senator, but that&#x27;s about it. reply AlbertCory 17 hours agorootparentprev#whataboutismThe fact is, the mullahs torture and kill anyone who speaks up. That&#x27;s happening now, not 71 years ago.\"women trapped in these regimes\" does not need quotation marks, unless you think there are NO women trapped in these regimes. reply oh_sigh 18 hours agorootparentprevThat&#x27;s one way to look at it. Another is that Mossadegh was legally asked to step down, and refused, and then the person with the legal right ousted Mossadegh.Regardless, if we don&#x27;t like dictators or power grabs, then we certainly shouldn&#x27;t like the current regime in Iran. reply selimthegrim 18 hours agorootparentMossadegh was buying people in the Parliament, let’s be realistic reply bellown 19 hours agoparentprevSadly, most commenters on HN rarely even attempt to understand female-centred perspectives. It&#x27;s always very apparent how the demographic here is so heavily skewed male, with all the usual toxicity that typically comes with that.I support your comment but unfortunately I think it will almost entirely fall upon deaf ears here. reply AlbertCory 18 hours agorootparentI&#x27;m male, and I&#x27;m with you. Yes, this IS political, and what&#x27;s your point? It&#x27;s a thumb in the eye to one of the worst regimes on the planet. I&#x27;m sure this will piss off the mullahs, and what better reason than that?People like her (whom I&#x27;d never heard of, sad to say) who put it all on the line to defend human rights -- if that&#x27;s what the Peace Prize has evolved into, then good. reply hef19898 16 hours agorootparentprevThere are subjects were shows that HN is not onpy skewed towards male, but also wealthy, priviledged and mostly white male. With a very healthy dose of SV bubble techbros thrown in the mix.HN still is one of the last places on the internet one can have interesting discussions. Sometimes so, it feels like is changing...(I know this change is a age old HN meme) reply 2OEH8eoCRo0 15 hours agoparentprevIf you praise her for her bravery it makes Iran look bad which implicitly makes the West look good and we cannot have that kind of thing around here. reply mhuffman 19 hours agoparentprev>Think the prize is politicized and corrupt? Whatever - it&#x27;s not about you or your opinion.Here&#x27;s a hot take -- I think all the Nobel Prizes, not just the Peace Price are politicized, corrupt, pop-culture-ish, and basically just in-group accolades! Similar to the Academy Awards. reply tshaddox 19 hours agorootparentWait, are you implying that popular culture is bad? Should we simply not have popular culture? reply mhuffman 18 hours agorootparent>Wait, are you implying that popular culture is bad? Should we simply not have popular culture?No, but probably not the best way to run science, academics, medicine, long-term civil projects, etc. reply tshaddox 16 hours agorootparentWell, Nobel Prizes aren&#x27;t exactly \"how we run science, medicine, etc.\" But perhaps you could argue that chasing Nobel Prizes is a counterproductively strong incentive in those fields (I have no idea if that is the case). reply Tao3300 17 hours agorootparentprevI&#x27;ve never been happier to be out of the in-group than I am on the day I learned Iranian prisons are part of the in-group. reply da_chicken 18 hours agorootparentprevI guess I&#x27;m not certain how any accolades could ever be anything but in-group accolades. reply mhuffman 18 hours agorootparentWell, the police giving a citizen that saved a baby and award for example. Or moviegoers praising a new film. I&#x27;m sure you can imagine a few. Whereas Nobel Prizes, Academy Awards, etc. seems to be a lot of self-dealing when they are not trying to get points for doing something that is currently popular in a \"fad\" sort of way. reply the_bookmaker 15 hours agoparentprev> It would be nice if instead of everyone hating on the prize, we could take a moment and reflect.Nice can also mean silly and ignorant, as any well-aged dictionary would tell you. [0] We are reflecting, on the corruption and politicization of our institutions.> Think of what this woman and many other women trapped in these regimes are going through, the sacrifices they&#x27;ve made, and the bravery they show to try to make things better.Essentially the same Bush-era \"plight of the Afghan women\" kind of appeal to emotion to justify corruption, interventionism, and war [1].Also, I&#x27;m pretty sure you don&#x27;t really know much about the political situation in Iran. Mohammadi belongs to a political faction called the Reformists [2], which is filled with regime apologists and charlatans. More specifically, she belongs to a particular branch which is sometimes called Neo-Shariatism [3]. Shariati himself was the \"ideologue of the Islamic Revolution\" [4], and a full-fledged charlatan who used to falsely claim to have a PhD in sociology from Sorbonne [5].Mohammadi is currently a political prisoner, but that obviously isn&#x27;t something which merits a Peace Prize. I&#x27;m sure that there isn&#x27;t a shortage of political prisoners in the Islamic Republic.[0]: https:&#x2F;&#x2F;www.websters1913.com&#x2F;words&#x2F;Nice[1]: https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;wp-srv&#x2F;nation&#x2F;specials&#x2F;attack...[2]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Iranian_Reformists[3]: https:&#x2F;&#x2F;era.library.ualberta.ca&#x2F;items&#x2F;6b552565-6ff8-45a0-a0e...[4]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ali_Shariati[5]: http:&#x2F;&#x2F;www.shariati.com&#x2F;bio.html (Compare this with the Wikipedia article, which says he got a PhD in Persian. Even that is dubious.) reply catlover76 15 hours agorootparentAlmost everything you said is basically irrelevant to the point put forth by the person to whom you are replying. reply A_D_E_P_T 23 hours agoprevThe prize is supposedly awarded to those who have \"done the most or the best work for fraternity between nations, for the abolition or reduction of standing armies and for the holding and promotion of peace congresses.\"Hmmm. Well. I don&#x27;t quite see how formenting revolution fits the bill, but the Peace Prize has been very strange of late in general.By its own lights, I don&#x27;t see a single person or entity who would deserve the prize this mad year. Maybe there&#x27;s some ethicist somewhere... reply michaeltimo 23 hours agoparent\"Since World War II, the Peace Prize has principally been awarded to honour efforts in four main areas: arms control and disarmament, peace negotiation, democracy and human rights, and work aimed at creating a better organized and more peaceful world. In the 21st century the Nobel Committee has embraced efforts to limit the harm done by man-made climate change and threats to the environment as relevant to the Peace Prize.\" [0]Narges is one of the most inspiring women in confronting the inhumane regime of the Islamic Republic, which never stops committing crimes. A regime that sent a 16-year-old girl into a coma just a few days ago because of her hijab [1]. Narges spent most of her life in the most dangerous prisons in Iran for her activities, and I think this award was not only for her, but also for the all oppressed women in Iran in the last four decades.[0] https:&#x2F;&#x2F;www.nobelpeaceprize.org&#x2F;nobel-peace-prize&#x2F;about-the-...[1] https:&#x2F;&#x2F;www.theguardian.com&#x2F;world&#x2F;2023&#x2F;oct&#x2F;03&#x2F;iran-activists... reply Luctct 7 hours agorootparentThe people who call out the \"inhumane regime\" of Iran are usually exactly the same ones who openly hate America (where women can do whatever the hell they want) and display sky high levels of admiration for Barack Obama, who gave a metric ton of American taxpayer money to Iran.I am posting this again because my first post has been shadow banned. reply csomar 22 hours agorootparentprevStop the spreading of fake news or low reliability news. This ([1]) has been making rounds of in all Media, and yet looking at the footage it does seem to not quite substantiated. It really makes you question whether the Western media cares about the truth about what happened or just beating drums...And while the Iranian regime is bad, it&#x27;s definitively not as bad as the Taliban one where [1] is a daily occurrence. reply michaeltimo 21 hours agorootparentThe propaganda of this barbaric Iranian regime is active everywhere, but the truth cannot be covered with words like the \"Western Media\", so try other things.This is also not the first time that the child-killing and anti-women regime of Iran commits such crimes. About a year ago, Mehsa Amini was killed by police forces for the same crime of insufficient hijab. In the revolutionary demonstrations after that, about 500 more people were killed, among them Nika Shakarami [1] by the \"impact of a hard object\" and 9-year-old Kian Pirfalak [2] by the shootings by the security forces. Other examples of innocent people killed can be found in the links in these wikipedia pages.[1]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Killing_of_Nika_Shakarami[2]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Killing_of_Kian_Pirfalak reply hollander 20 hours agorootparentprevThe Nobel peace prize is not about who has the worst life. Women in Afghanistan have it - in general - worse than in Iran, I&#x27;m quite sure about that. That&#x27;s not the criterium to get this prize.This is whataboutism, nothing less, and your fake-news remark makes me wonder your motivation even more. reply darkoob12 21 hours agorootparentprevThe footage is edited and the key seconds are taken out. There were dozens of witnesses and what you are doing is called whataboutism. reply ReptileMan 23 hours agorootparentprevBut the world is just as peaceful (or peaceless) as before her activism. Now if she actually overthrew or forced the government to reform - it would be different. But award should be given for results not efforts. reply nicce 22 hours agorootparentResults are important because many are giving a lot of effort or even more than her but just haven&#x27;t got the publicity.Publicity can lead to results but can it be measured in this case? reply no-reply 20 hours agorootparentprevOn the basis of effort, we could probably hand out awards to a large number of dead people reply bannedbybros 19 hours agorootparentWhy make the award reasonable when it can be a feel-good self-congratulatory propaganda fest? reply screye 19 hours agorootparentprevIt does feel more like the &#x27;Western moral prize&#x27; rather than a Peace Prize.Truth is, the most peaceful transitions are usually military coups. &#x27;Peacefully&#x27; won transitions are often the bloodiest. Fear is a terrible thing, but it does lead to effective peace.With the Nobel Peace Prize, it&#x27;s usually a coin toss between moral martyr, future genocider and someone who did impactful work towards peace. The best example of their schizo-ness is Gandhi. They didn&#x27;t award Gandhi when he lead a peaceful resistance. But, awarded it posthumously in the aftermath of the bloodiest & nastiest population exchange in the history of humanity. reply vijayr02 15 hours agorootparentGandhi was never awarded the peace prize. He was nominated in the year he was assassinated. The actual prize was not awarded that year.https:&#x2F;&#x2F;www.nobelprize.org&#x2F;prizes&#x2F;themes&#x2F;mahatma-gandhi-the-... reply AlbertCory 17 hours agorootparentprev> It does feel more like the &#x27;Western moral prize&#x27; rather than a Peace Prize.I&#x27;m not seeing the problem here. Some non-Western regimes seem to think it&#x27;s fine to deny people their human rights, e.g. Iran, Venezuela, Afghanistan, China. There is no moral equivalence between Western and those. reply screye 11 hours agorootparent2&#x2F;4 of those were in better conditions before the US invaded them for oil interests.Venezuela&#x27;s bloodiness is in part because of CIA funded violent opposition. Venezuela while a basket case now, is still a \"what if\" in a world without CIA interreference and unilateral sanctions.China is odd. It is an autocratic repressive regime with their recent founder having the 2nd highest body count of any leader. But, it is also the most impressive story of raising an slice of humanity from poverty into a strong middle economy.Western countries think about peace & human rights in isolation. What recent democratic nation has managed to elevate itself from abject poverty to being a strong middle economy, with no natural resources ride to infinity. India might have something to show over the next 30 years, but as of today, they started off richer than China at independence and find themselves miles behind. All of Singapore, Taiwan, Korea, Thailand & Japan had their growth occur under incredibly repressive govts. They might seem peaceful countries today, they certainly weren&#x27;t that during their growth.> moral equivalenceMoral equivalence can only exist when all other variables are the same. Norway might claim moral high ground on account of being an egalitarian nation, but its entire economy is oil. Remove the oil, and you might see their claimed unwavering morals waver. reply AlbertCory 10 hours agorootparent> Norway might claim moral high ground on account of being an egalitarian nation, but its entire economy is oil. Remove the oil, and you might see their claimed unwavering morals waver.apparently you were born after 1980. Who cares about their oil?> Venezuela&#x27;s bloodiness is in part because of CIA funded violent opposition.Oh, I see. So Chavez & Maduro are because of the CIA? What a world we live in, where the CIA has such awesome power such that everything \"bad\" is their fault. I suppose now they&#x27;re powerless until Maduro is finally gone, and then it&#x27;ll be their doing.Yet they still can&#x27;t get rid of Castro, predict the fall of the Soviet Union, keep the Shah in power, or stop 9&#x2F;11. They&#x27;re only powerful when something you don&#x27;t like happens.Maybe you should move to one of those people&#x27;s paradises. It sounds like you&#x27;d be happier there. reply RegnisGnaw 18 hours agorootparentprevThere is always the Confucius Peace Prize for those that want a &#x27;Eastern moral prize&#x27;. reply lostlogin 15 hours agorootparentprev> It does feel more like the &#x27;Western moral prize&#x27; rather than a Peace Prize.Iran, China, Afghanistan et al are welcome to start their own prize.I see that China’s Confucius price seems to be disbanded after getting offside with their government.Recipients include Putin.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Confucius_Peace_Prize reply NoMoreNicksLeft 18 hours agorootparentprevNot all peaces are equal. One peace might be that of some idyllic utopia where all are content, healthy, and safe. Then there is the peace of the death camp which has completed its mission and has no victims left to murder. And countless peaces in between those two extremes, some better and less violent, some gruesome and traumatizing even just to describe.I cannot say which peace the Nobel awards, or even if it awards to the same sort of peace year to year. But if anyone can do something about the Iranian government, then maybe they do deserve the thing. I doubt he ever meant it to become the \"successful eternal subjugation of humanity\" award. reply pipo234 23 hours agoparentprevThe Nobel Peace Prize has historically been surrounded by the kind of ambivalent feelings you allude to.To name one: Hume & Trimble (1998) was considered ironic because it was viewed as kind of reward for ceasing violence they initially caused. Similar remarks were made in 1993 about Mandela and De Klerk. It can even be argued that Gorbachev and Carter had blood on their hands before becoming saints.Maybe this kind of ambiguity is simply rooted in the fact that the monetary price is paid by the deeply ironic invention of dynamite by Alfred Nobel.&#x27; Guess \"contribution to peace\" is less about ethics and more of a political concept. reply 1024core 17 hours agorootparentDon&#x27;t forget Obama. He was given the prize before he even did anything.And then he proceeded to bomb the fuck out of Iraq, Syria, etc. reply vkou 15 hours agorootparentObama got it for being not-Bush (What a bar to clear!). It was a large middle finger raised by world, as a rebuke to 2001-2008 US foreign policy.It was disappointing, but unsurprising that 2009-20?? has gone down more or less the same road. reply KMag 17 hours agorootparentprev> monetary price is paid by the deeply ironic invention of dynamite by Alfred Nobel.Note that net-net, the invention of dynamite probably saved many lives. Nitroglycerin-based dynamite invented by Nobel isn&#x27;t very useful for military purposes, and has never been in wide military use. It can&#x27;t be safely stored for long periods or in hot conditions, making it ill-suited for battlefield logistics. Nitroglycerin-based dynamite is primarily used in mining and earth-moving.Properly stored, dynamite is both much safer and more powerful than the black powder or liquid nitroglycerine that were primarily used in mining and earth-moving before the invention of dynamite.Much later, \"military dynamite\", a more stable dynamite substitute devoid of nitroglycerine and more suited to military use was developed. While more stable, it&#x27;s more expensive, and less commonly used. I don&#x27;t believe Nobel had anything to do with the development of military dynamite. reply dragonwriter 18 hours agorootparentprevWhile De Klerk certainly participated in it, neither Mandela nor De Klerk started the system of violent racial oppression in South Africa.Neither of them started the armed resistance against it, either, though Mandela obviously participated in that. reply tgv 19 hours agorootparentprevMy newspaper had an interview with a former judge, and he said something along the lines of: if it doesn&#x27;t chafe, it will become irrelevant. So tend to prefer somewhat controversial figures over safe choices. reply selimthegrim 18 hours agorootparentprevWhen did Hume’s party cause any violence? reply zvmaz 23 hours agoparentprev> Well. I don&#x27;t quite see how formenting revolution fits the billOppressive regimes like to use these sorts of rhetorical ploys to discredit social movements. Do people under authoritarian regimes have any agency? Or are they just puppets to foreign machinations? reply zaphirplane 19 hours agorootparentYou are arguing the work done is good, which doesnt mean it should win or be included in every category. Keep hammering how horrible dictators are or child illiteracy is just shouting think of the children meme.Would it surprise you if she won Nobel prize for chemistry for advocating freedoms ? It would surprise me reply wheelerof4te 23 hours agorootparentprev\"social movements.\"LOL, try harder. NGOs paid by the westerners are a thing, but you sure know that. If these people did not get free money for their actions, they would be silent.\"Do people under authoritarian regimes have any agency?\"\"Authoritarian regimes\" usually have popular support since a huge majority supports the ruling party.Otherwise, the country would not be stable and vast sums of western money would not have to be sent there in order to ferment a color revolution. reply cderpz 22 hours agorootparent>\"Authoritarian regimes\" usually have popular support since a huge majority supports the ruling party.This argument makes about as much sense as the following one:>Otherwise, the country would not be stable and vast sums of western money would not have to be sent there in order to ferment a color revolution.The defining characteristic of an authoritarian regime as opposed to a democratic one is that it does not derive its power and legitimacy from the people - i.e. popular support. It may be stable and \"popular\" and still terrible, North Korea comes to mind. But as out of touch as you seem to be, you probably belong to that strange group of people who think NK is actually an anti Western paradise. reply wheelerof4te 22 hours agorootparent\"The defining characteristic of an authoritarian regime as opposed to a democratic one is that it does not derive its power and legitimacy from the people - i.e. popular support.\"That is a easily proven lie and you know it since you cited North Korean example. The same thing applies to Russia or Iran. But keep parroting the same mantra you are fed by the propaganda in your country. reply AlbertCory 17 hours agorootparentprevThere&#x27;s a simple test of\"a huge majority supports the ruling party\":Have a fair election, where both sides are permitted to make their case to the voting public. No candidates or supporters would be imprisoned or legally harassed, before or after the election.Then have another one a year or two later, since \"your vote actually counts\" would be a teaching moment for people who aren&#x27;t used to it. reply wheelerof4te 14 hours agorootparent\"No candidates or supporters would be imprisoned or legally harassed, before or after the election.\"You mean, like currently in the \"most democratic country\" in the world.So yeah, please do have a fair election. No vote stealing either, and no voting dead. reply thriftwy 22 hours agorootparentprevUnfortunately, this is very true. If we look at public opposition to authoritarian regimes, we will see layers upon layers of NGO pets and very few independent figures.It is so apparent that they actually discredit the idea of opposing authoritarianism. Democracy is a tough sell if you know your local democratic movement is paid for by other countries which do not have your country&#x27;s well-being, or existence, as a motivation.So there are a lot of people discontent with lack of options and restrictions to freedom of speech and expression, but they do not have a voice. People who have a voice are universally paid agents of NGOs. They get good money to film expensive produced youtube videos and get cited by world press all the time. There is significant mismatch between two groups, but they get compounded and written off by the majority and the regime. reply thriftwy 22 hours agorootparentSo it turned out just this week that the prominent democratic opposition figure, the guy behind the anti-authoritarian icon Pussy Riot and the anti-war, pacifist often-cited media Mediazona, brags that he is enlisted in Armed Forces of Ukraine.So he is non-Russian, non-democratic, non-pacifist non-journalist.He is just a proud Ukrainian fighter all along the way. Great for him. Have we got any Russian opposition? Give me a name, I challenge you.I also wonder how great it for low-level activists who were supplying Mediazona with information in order to raise awareness of Russian soldier deaths on Ukrainian fronts, that they are now liable to get high treason charges for offloading that data directly in hands of an enlisted AFU fighter. reply wheelerof4te 22 hours agorootparentprev\"There is significant mismatch between two groups, but they get compounded and written off by the majority and the regime.\"That is by nature. You can&#x27;t make every person in a country happy. There are millions of homeless people, discontent people, depressed people all around the West. These people have been mercilessly oppressed by the cruel practices of neo-liberalism and profit-oriented capitalism. Imagine what world-wide sanctions and isolation would do to them.Are there any NGOs that promote their plight? Of course not, since other countries either can&#x27;t pay or are not interested in them. In the best case, there is a few under-paid organizations that are (cleverly) not getting the media attention. replylancebeet 23 hours agoparentprevThere have been quite a few laureates who were awarded the prize for their activism against apartheid, some of whom also spent time in prison due to their revolutionary tendencies. Would you consider these prizes equally unjustified? reply ReptileMan 23 hours agorootparentYes. You have time man of the year for that kind. reply galangalalgol 22 hours agorootparentChoosing to face injustice with articles and signs and peaceful gatherings instead of masks and high explosives furthers the goals of peace. Unless her articles explicitly called for violence, I have not read them. reply ReptileMan 18 hours agorootparentBut she has not changed anything. It is irrelevant what method you use if the status quo is not moved. reply tonmoy 22 hours agoparentprevPlenty of human rights activists have won the Nobel peace prize in the recent past, this is nothing new. reply nemetroid 23 hours agoparentprevThe same could be said of Martin Luther King. reply ReptileMan 23 hours agorootparentMartin Luther King won. Iran is still the same. Subtle difference. reply UncleMeat 18 hours agorootparentMLK was killed. Key parts of the US are still extremely heavily segregated. Major portions of the Civil Rights Act and Voting Rights Act have been undone by the courts. Antidiscrimination legislation and jurisprudence is being more often leveraged to prevent policies that MLK would have supported like affirmative action than it is being used to continue the project of desegregation. Teaching core parts of MLK&#x27;s belief system can get you fired in some states.I don&#x27;t think \"MLK won\" is a complete story. reply klyrs 16 hours agorootparentprevThis sounds a lot like Trump&#x27;s dismissal of John McCain. A true coward&#x27;s take. reply mardifoufs 15 hours agorootparentRather be a coward than a blood thirsty war hawk like McCain was. reply jansan 23 hours agoparentprev> the Peace Prize has been very strange of late in general.Remember when a man received the Nobel Peace Prize for not being George W. Bush? reply A_D_E_P_T 23 hours agorootparentYou could at least make the case that Obama promoted -- indeed, in a sense, embodied -- \"fraternity between nations,\" for he was incredibly popular with most of America&#x27;s allies. (See, e.g., his \"rock star\" reception in Germany.) Even its enemies were at worst ambivalent towards him personally, and at best they were hopeful that he&#x27;d bring about positive change. In this sense, he",
    "originSummary": [
      "Iranian activist Narges Mohammadi, who is in jail for over 30 years due to her advocacy for women's rights, has been awarded the 2023 Nobel Peace Prize, representing a significant pushback against oppression in Iran.",
      "The Iranian government is imposing stricter penalties on women who violate the dress code, utilizing artificial intelligence for identification.",
      "Ukrainian human rights advocate Oleksandra Matviichuk has shown her support for Mohammadi, signalling the crucial role of solidarity in the fight for freedom, while the model's international recognition sends a strong message to the Iranian leaders emphasizing women's rights."
    ],
    "commentSummary": [
      "This text delves into controversies surrounding the Nobel Peace Prize, including its credibility and the concerns over politicization.",
      "The content explores criticism of the prize's selection process, and ties it to real-world events such as the overthrow of the Iranian government.",
      "The discussions underscore a variety of views on political regimes, the Nobel Peace Prize itself, and the global quest for peace."
    ],
    "points": 226,
    "commentCount": 240,
    "retryCount": 0,
    "time": 1696586601
  },
  {
    "id": 37792444,
    "title": "Shortbread – Create AI comics in minutes",
    "originLink": "https://shortbread.ai/",
    "originBody": "Just go to the link and click on \"Start Creating\". No signing in required.I built shortbread to help anyone to create comics &#x2F; manga series. The onboarding process helps you kick start a page from 60%, then you can use your creativity to bring it to 1000% in a fully-controllable editor.Tech stack:GPT 3.5 Turbo - the comic script generation. It handled everything from layout, character, scene, SD prompts, to dialogue.SD 1.5 - We put up SD servers on GCP. For every comic we generate one large image and crop it into panels. Per the experiments of u&#x2F;Deathmarkedadc on Reddit, this massively helps with consistency. The models are trained on anime scenes tho, and might not be so great with animals.Frontend: Next.js 13 on Vercel, React + Typescript. We built the entire editor from scratch to compose the comic (images, panels, speech bubbles, text) like a webpage. This allows you to edit and republish your comics like a website. You can dynamically generate panels as well. Try resizing a panel into a long narrow box and generate.Backend: Firebase.Sample comics:a japanese couple sits at dinner table. The husband told the wife a secret (link https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;debdf25c-3f95-492a-952a-...)An army of male soldiers fighting against an army of female soldiers in ancient china (https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;4566613c-7146-4ed7-9b8d-...)a team of girls play volleyball against a team of boys (https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;aafc2f61-d008-4f3f-aa8f-... )Next steps:- More pages- Fine panel-level control. Poses, control net, etc.- Multi-character.- Different styles.- Allows you to control character design.I’m Fengjiao Peng, founder and chief engineer at Shortbread. I was previously a webtoon artist. We want to build this into something you can create entire comics series &#x2F; manga &#x2F; webtoons with. Criticism and suggestions welcome!",
    "commentLink": "https://news.ycombinator.com/item?id=37792444",
    "commentBody": "Shortbread – Create AI comics in minutesHacker NewspastloginShortbread – Create AI comics in minutes (shortbread.ai) 201 points by Fengjiao 18 hours ago| hidepastfavorite53 comments Just go to the link and click on \"Start Creating\". No signing in required.I built shortbread to help anyone to create comics &#x2F; manga series. The onboarding process helps you kick start a page from 60%, then you can use your creativity to bring it to 1000% in a fully-controllable editor.Tech stack:GPT 3.5 Turbo - the comic script generation. It handled everything from layout, character, scene, SD prompts, to dialogue.SD 1.5 - We put up SD servers on GCP. For every comic we generate one large image and crop it into panels. Per the experiments of u&#x2F;Deathmarkedadc on Reddit, this massively helps with consistency. The models are trained on anime scenes tho, and might not be so great with animals.Frontend: Next.js 13 on Vercel, React + Typescript. We built the entire editor from scratch to compose the comic (images, panels, speech bubbles, text) like a webpage. This allows you to edit and republish your comics like a website. You can dynamically generate panels as well. Try resizing a panel into a long narrow box and generate.Backend: Firebase.Sample comics:a japanese couple sits at dinner table. The husband told the wife a secret (link https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;debdf25c-3f95-492a-952a-...)An army of male soldiers fighting against an army of female soldiers in ancient china (https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;4566613c-7146-4ed7-9b8d-...)a team of girls play volleyball against a team of boys (https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;aafc2f61-d008-4f3f-aa8f-... )Next steps:- More pages- Fine panel-level control. Poses, control net, etc.- Multi-character.- Different styles.- Allows you to control character design.I’m Fengjiao Peng, founder and chief engineer at Shortbread. I was previously a webtoon artist. We want to build this into something you can create entire comics series &#x2F; manga &#x2F; webtoons with. Criticism and suggestions welcome! brucethemoose2 16 hours agoThis is all super cool.Some random suggestions:- I dunno what diffusion framework you are using, but the AITemplate (for GPUS) or diffusers JAX (for TPUs) backend can massively increase your diffusion throughput.- Alternatively, I believe HuggingFace already has a JAX backend for Stable Diffusion XL, so you could run a model with much better support for large resolutions&#x2F;inpainting massive images at a similar (?) speed.- There are schemes for area prompting and subject \"subset\" prompting in stable diffusion, as well as using images as input. As an example of how y&#x27;all might use this, you could generate a image for Character A, an image for Character B, encode them. specify that the character A prompt latents go on the left side of the image, and the character B prompt latents go on the right side of the image. And of course you can add to these area prompts, like \"jumping\" on the left side and \"ducking\" on the right side of the image. There&#x27;s also a way to specify which prompts&#x2F;encoded images belong to which subjects instead of manually cutting out areas, see: https:&#x2F;&#x2F;github.com&#x2F;BlenderNeko&#x2F;ComfyUI_Cutoff reply Fengjiao 16 hours agoparentWoaaa love these inputs. Thank you! Wasn&#x27;t aware of the JAX backend will check it out. Right now we&#x27;re on SD 1.5. We tried SDXL but found the quality improvement to be marginal. Yes to area prompting&#x2F;regional control to help people create more complex scenes. I need some design thinking first since it&#x27;s easy to over build and spit out something super complicated. Immediate next step is to def add controlnet. reply brucethemoose2 16 hours agorootparent> JAXYeah, check out their post: https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;sdxl_jaxI dunno how expensive TPU instances are these days, but the performance is insane!> We tried SDXL but found the quality improvement to be marginal.Yeah, the vanilla HF diffusers pipe is unimpressive to me.Try playing with this though, turn on FreeU and specify an anime style: https:&#x2F;&#x2F;github.com&#x2F;MoonRide303&#x2F;Fooocus-MREI have never gotten such high quality results from simple prompts, even in cloud models like Midjourney&#x2F;GPT4. The question is how to port even part of that magic over to the diffusers pipeline... reply brucethemoose2 15 hours agorootparentprevAlso, VoltaML has a good reference GPU AITemplate SD 1.5 implementation:https:&#x2F;&#x2F;github.com&#x2F;VoltaML&#x2F;voltaML-fast-stable-diffusion&#x2F;tre...The speed jump is massive on my desktop GPU, probably even more dramatic on cloud hardware, and it may support some things (weight swapping&#x2F;lora swapping&#x2F;resolution changing&#x2F;controlnet) better than JAX. reply Fengjiao 13 hours agorootparentMy issue previously with these prebuilt backends is that you can&#x27;t tweak it like sdwebui does, but to make our thing work it took a thousand tweaks. Can look into this first to see how customizable it is. reply brucethemoose2 13 hours agorootparentVoltaML is a relatively vanilla diffusers-based backend, so its not a hairy monster to hack like you may have seen with SAI-based UIs (like Comfy, Fooocus and Automatic)The AITTemplate code is a lightly modified version of Facebook&#x27;s example dynamic AIT script, to get rid of small issues like VRAM spikes: https:&#x2F;&#x2F;github.com&#x2F;facebookincubator&#x2F;AITemplate&#x2F;tree&#x2F;main&#x2F;ex...InvokeAI is also diffusers based, but they seem to mess with the pipeline a bit more.Anyway, all that may be better as a reference for interesting features rather than a backend to try and adopt. replyanigbrowl 9 hours agoprevIt&#x27;s very cool. How will you keep the characters consistent? I generated a simple 3 panel page and there were some variations between the same character across two panels. I think it could be worth it to have special character design pages (like the bonus art&#x2F;mini posters many comics use now).The only negative feeling I had was that the layouts are kind of dull, no real way to do angled panels and break up the strict horizontal&#x2F;vertical flow. But since this would probably be used in combination with image editor software, that is not such a big deal. reply Fengjiao 9 hours agoparentYeah, the characters aren&#x27;t truly consistent yet. We did what we could to make them mostly look the same. I might be adding inpainting to help address this. Right now you can just regenerate a couple times in editor and pick the most consistent ones. I also like the slanted panels like in real manga. Right now you can resize the panels. I plan to add a custom layout thing on the select layout page. + allow folks to shape their panels into non-rectangular! reply lxe 10 hours agoprev\"A frantic person bursts open the hospital door. They talk to the receptionist, then the doctor. In the last panel we see them standing over their bed-bound partner, looking sad.\"https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;08769382-4e2f-426a-9779-... reply Fengjiao 10 hours agoparentI love this. I didn&#x27;t know it can do complex scenes like this yet. Thank you reply Kerrick 6 hours agoparentprevIs this loss? reply atleastoptimal 11 hours agoprevI think the flow should beI give summary => site gives me panel descriptions to choose fromI pick descriptions = > Site creates a \"skeleton\" layout option for each panel. At this point I can modify the skeleton or save themI get skeleton layout => Site makes it look prettyWith each stage modifiableI think this is very cool and well made. reply Fengjiao 10 hours agoparentThanks - you think more like a real comics creator. Right now the flow is maximally reduced to give minimal friction. But for creators to make meaningful long form content, providing a storyboarding process is important. I plan to add some optional stuff in the flow to do this! reply atleastoptimal 8 hours agorootparentYou must be running a lot of compute for this. What are the approx costs per 1000 user sessions? reply Fengjiao 7 hours agorootparentjust did some rough math. 1k session = 750 minutes compute time with our current GPU instance = $9.375. so gladly not broke yet! (rough math might be wrong, need to double check later) reply iamwil 9 hours agoprevI tried recreating one of my favorite strips, just to see what would result. This was the result:https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;41e5642c-86ee-421e-b985-...The original (SFW, despite the warning):https:&#x2F;&#x2F;www.oglaf.com&#x2F;trapmaster&#x2F;The writing obviously will need work, but I can see this being much better in six years time. The fact we can do this at all is pretty neat. And honestly, a lot of people have a hard time going from zero to one. It&#x27;s much easier for most people to fiddle and edit something, than to stare at a blank page.I suspect this kind of workflow will permeate all kinds of work, where the generative AI gives us a starting point, and we go from here. The question then, is whether starting points matter, because it&#x27;s still a far gap to get to the Oglaf strip given the current starting point. Would some people fare better by random? Or we can make AIs that have enough context to know what&#x27;s fresh for people? reply Fengjiao 7 hours agoparentI think the baseline can def be improved. But I suspect the gap between 60% and 99% would be so wide that it would still take a significant amount of time for the human creator reply Fengjiao 15 hours agoprevAuthor here - Didn&#x27;t expect the amount of traffic rn. The wait might be EXTRA long. We&#x27;re trying hard to spin up more servers!! reply aiunboxed 1 hour agoprevDo you super impose the text or make AI generate the text? Are there good tools to make AI generate text on images ? reply Fengjiao 1 hour agoparentDo you mean the text in the speech bubbles? Those are generated by the AI and we fill them in the bubbles. If you’re seeing text in images like a billboard, it probably isn’t that great quality. I heard Dalle3 does pretty good text in image! reply ianbicking 11 hours agoprevVery cool. I like the editor, though I wish I could drag the bubbles without clicking on them first.There&#x27;s not a lot of plot in a single page, but even with that I wish I had more control, and for longer pieces I would absolutely want a lot more control. I&#x27;d want to see some basic text previews, and be able to control both the large scale and fine scale of the progression. I&#x27;d want to be able to control the tone of the piece, clarify points that GPT might not be picking up on, override choices, etc. I might tweak some dialog... but most of the changes I envision are before dialog, about how scenes are broken up, or the basic premise of the story&#x2F;world.Many of the other features you list (outside of more pages, of course) feel less important than the story building itself. (But that&#x27;s also coming from my personal interest in the story design.) reply Fengjiao 10 hours agoparentThis makes total sense, and that&#x27;s how I work too. Comic artists, animators and directors all spend a lot of time on storyboarding before actual production. I&#x27;ll share that the current design is to allow 99% of people to make at least one comic ;) I think it&#x27;s possible for both end of the worlds to exist in the same product, but I need to design carefully and not add too much complexity too fast. And agreed on precise panel level control -> more coming soon reply ianbicking 8 hours agorootparentThat makes sense; I wouldn&#x27;t have wanted to use it, or had any feedback at all, until I got through the first complete generation. reply codetrotter 5 hours agoprev> Fine panel-level control. Poses, control net, etc.One thing that stuck out to me about the https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;4566613c-7146-4ed7-9b8d-... example, and to a lesser extent the https:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;aafc2f61-d008-4f3f-aa8f-... example is that the people of opposing teams sometimes face in the same direction. Typically you&#x27;d have them physically facing each other.But that is very much a nit-pick. And one that a human can manually fix when looking at the result by mirroring some of the panels. This is super cool! reply Fengjiao 1 hour agoparentYes was talking to a creator about this. Getting the eyeliner to match actually uplifts the story a lot. I imagine some simple rotation&#x2F;flipping image post processing can help a lot here reply riffraff 13 hours agoprevThis is cool, but it appears the consistency issue with this stuff is not solved yet, e.g. in every panel clothing and armors on the dame character are different.Perhaps a more simplified style might work better. reply Fengjiao 10 hours agoparentYes, we didn&#x27;t actually solve consistency, although the way we did it makes the same character pretty similar on the same page. If you do some more regenerates of a single panel, you can find some generations that are similar. I MIGHT be supporting inpainting to help fix incoherence details, but need to think about it more - reply weitzj 2 hours agoprevThis looks interesting. I am trying to generate comics for my daughter to explain graphically some upcoming events so she hopefully can understand them better or is prepared. reply Fengjiao 1 hour agoparentHope it helps! reply Fengjiao 17 hours agoprevAuthor here. Just go to https:&#x2F;&#x2F;shortbread.ai and click on \"Start Creating\". No signing in or anything required. reply totetsu 4 hours agoparenthttps:&#x2F;&#x2F;create.shortbread.ai&#x2F;viewer&#x2F;a500fa7c-04c3-4c4c-8708-... reply Fengjiao 1 hour agorootparentLMAO reply kristopolous 10 hours agoprevI&#x27;m always amazed when you type in things like \"Gothic Quarter of Barcelona\", \"at a home in Arcosanti Arizona\", \"busy Manhattan street\", \"red carpet at the Oscars\", etc, it basically nails the background in any style. reply Fengjiao 9 hours agoparentthat&#x27;s way more experimental than my prompts! glad it held up. From what I know if you try to generate animals as main characters it breaks p bad lol reply kristopolous 8 hours agorootparentright, but you can have someone walking, say, a pig on a leash and you&#x27;re in business. Also try something like \"man in realistic dog costume\" for anthropomorphism reply alex_c 14 hours agoprevVery cool! I was briefly toying with something similar just last week.Main challenge I see is character consistency. I really like the way you set up the prompts, but even so:Outfit - a simple black sleeveless gi with white pants, a black belt tied around his waistIn two consecutive panels, the output swaps the colors (first panel gets it right, second panel has white gi, black pants).Curious how you&#x27;ll tackle this challenge! reply Fengjiao 14 hours agoparentHi Alex, great catch -> We didn&#x27;t solve consistency, but we saw that if you regenerate a few times, you usually get something that&#x27;s visually similar. Right now AI artists all do loads of postprocessing - using AI, so later we might have a \"smear\" feature that inpaints the inconsistent part. Let me know if you have thoughts on this reply nottheengineer 11 hours agorootparentPeople can generate a few good samples of what they want a character to look like and then interrogate clip to get a more detailed prompt that makes it more consistent. It increases the prompt sizes a lot, but I don&#x27;t think there&#x27;s an easy way to solve this.Maybe you could build a UI that semi-automates this process? reply mentos 12 hours agorootparentprevCould eventually use GPT4vision to review the output of the art to see if all the panels are consistent? reply vimy 6 hours agoprevThis is really cool. :DThere’s a typo on the message founders page. reply Fengjiao 6 hours agoparentTy just fixed it. whew reply NaSeRneynd 6 hours agoprevCongrats on the launch!Whats the SD workflow? Which models, tools (controlnet, etc) do you use? reply HanClinto 13 hours agoprevThis is really impressive, well done!! reply Fengjiao 10 hours agoparentTy Ty reply jrflowers 14 hours agoprevI love “as seen on y combinator” reply Fengjiao 14 hours agoparenthahaha sorry the urge of putting on a nice looking logo overtook me reply colesantiago 16 hours agoprev [–] Was looking for something like this, i&#x27;m definitely signing up!I&#x27;m not a comic book artist by any means but now I can add this to my skills list with this.Is there any pricing yet on this and is this backed by YC or bootstrapped? reply Fengjiao 15 hours agoparent [–] - I intended for anyone to be able to use this - so def no worries - No pricing yet, everything is free since it&#x27;s early beta, but I&#x27;m thinking a subscription for a bunch of credits style like Midjourney. - Yes, we are YC reply anigbrowl 9 hours agorootparent [–] I&#x27;d definitely pay. I can draw and have multiple comics I&#x27;d like to do, but am not so good that I could commit to the time involved for long-form. This would be ideal as an assistive technology. reply Fengjiao 8 hours agorootparent [–] Thank you! I&#x27;d love you to play with it as much as you can. Can you go to create.shortbread.ai, click on \"login to save projects\", and then send me an email at fengjiao@shortbread.ai. I&#x27;ll give you a bunch of free credits to play with reply anigbrowl 7 hours agorootparent [–] I like your sales technique :D reply Fengjiao 6 hours agorootparent [–] hue hue hue (evil founder laugh) reply anigbrowl 2 hours agorootparent [–] I can&#x27;t log in with google rn (overloaded servers?) but I&#x27;ll try again tomorrow. reply Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Shortbread is a user-friendly platform that enables users to generate comics and manga series without the necessity of signing in, with an easy onboarding process and a fully customizable editor.",
      "The platform's technical structure relies on GPT 3.5 Turbo for script creation and SD 1.5 for image cropping, with a frontend and backend developed using Next.js 13 on Vercel and Firebase respectively.",
      "Shortbread plans to expand its features to offer more detailed panel controls and varied styles, and invites constructive criticism and suggestions to improve the service."
    ],
    "commentSummary": [
      "Shortbread.ai has released a new platform enabling users to generate AI-based comics and manga series by providing prompts for the AI to create comic panels.",
      "Notwithstanding, the current version of the platform suffers from issues with consistency and character control, which the company is actively addressing, along with scaling up the server capacity to handle increased user traffic.",
      "Though the service is currently free during its initial beta phase, a subscription model may be implemented in the future. The platform has drawn considerable user interest despite some reporting technical login issues."
    ],
    "points": 201,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1696607782
  },
  {
    "id": 37792507,
    "title": "A job application tracker with company reviews, recruiter autoresponder",
    "originLink": "https://rolepad.com",
    "originBody": "Hey folks. Rolepad is a product born out of my dissatisfaction with hiring processes - both as a candidate and as a hiring manager. Processes that are non-transparent, inefficient, and full of frustration for both sides. This early iteration has focused on the application tracking aspects with a few extra goodies.These days it is common to apply to dozens of positions (some users track over a hundred opportunities). Without a record-keeping system, it can quickly become an unmanageable mess. Even the better-organized among us often end up juggling spreadsheets, emails, and various notes. Rolepad was built to keep this data (company facts, role details, interview stages, contact info, freeform notes, follow-up actions, and more) in one place. Some of the other neat additions:- Forward emails to save@rolepad.com to save them as notes connected to specific opportunities. Forward recruiter messages to no@rolepad.com to have the system automatically reply with a decline response.- Generate shareable Sankey charts of your progress like this: https:&#x2F;&#x2F;app.rolepad.com&#x2F;metrics&#x2F;6QEbaktB7bqR8glhuYR32- Submit anonymous reviews and insights about application&#x2F;interview&#x2F;offer processes at a company . This is new and there aren’t great examples to share yet (https:&#x2F;&#x2F;rolepad.com&#x2F;companies&#x2F;brilliant.org is an early glimpse), and I didn’t want to create fake data as a matter of principle.Oh yeah, and it’s totally free :) Creating an account is passwordless and takes seconds, but if you want to kick the tires even faster, I created test credentials for this occasion: username: test@rolepad.com password: hntestWith this release, I am also starting conversations with employers (https:&#x2F;&#x2F;rolepad.com&#x2F;employers). A unified platform for candidates and employers can significantly reduce frustration for both in ways that email cannot. I should note that any solutions here have privacy implications and will require an exceedingly thoughtful execution.And now for the tech stack. The main application uses React with Tailwind on the frontend, C# on the backend, hosted in AWS (App Runner, Lambda, RDS Postgres, SES), with auth provided by Google Firebase, and CI&#x2F;CD via GitHub Actions. The home page is actually an SSR (server-side rendered) application built with vite-plugin-ssr (now vike) and hosted in a Cloudflare Worker that hits the AWS-hosted API. This is basically a best-of-all-worlds SSR configuration - very fast, zero cold start (!), and essentially free.Any and all feedback is sincerely appreciated!",
    "commentLink": "https://news.ycombinator.com/item?id=37792507",
    "commentBody": "A job application tracker with company reviews, recruiter autoresponderHacker NewspastloginA job application tracker with company reviews, recruiter autoresponder (rolepad.com) 193 points by romanhn 12 hours ago| hidepastfavorite86 comments Hey folks. Rolepad is a product born out of my dissatisfaction with hiring processes - both as a candidate and as a hiring manager. Processes that are non-transparent, inefficient, and full of frustration for both sides. This early iteration has focused on the application tracking aspects with a few extra goodies.These days it is common to apply to dozens of positions (some users track over a hundred opportunities). Without a record-keeping system, it can quickly become an unmanageable mess. Even the better-organized among us often end up juggling spreadsheets, emails, and various notes. Rolepad was built to keep this data (company facts, role details, interview stages, contact info, freeform notes, follow-up actions, and more) in one place. Some of the other neat additions:- Forward emails to save@rolepad.com to save them as notes connected to specific opportunities. Forward recruiter messages to no@rolepad.com to have the system automatically reply with a decline response.- Generate shareable Sankey charts of your progress like this: https:&#x2F;&#x2F;app.rolepad.com&#x2F;metrics&#x2F;6QEbaktB7bqR8glhuYR32- Submit anonymous reviews and insights about application&#x2F;interview&#x2F;offer processes at a company . This is new and there aren’t great examples to share yet (https:&#x2F;&#x2F;rolepad.com&#x2F;companies&#x2F;brilliant.org is an early glimpse), and I didn’t want to create fake data as a matter of principle.Oh yeah, and it’s totally free :) Creating an account is passwordless and takes seconds, but if you want to kick the tires even faster, I created test credentials for this occasion: username: test@rolepad.com password: hntestWith this release, I am also starting conversations with employers (https:&#x2F;&#x2F;rolepad.com&#x2F;employers). A unified platform for candidates and employers can significantly reduce frustration for both in ways that email cannot. I should note that any solutions here have privacy implications and will require an exceedingly thoughtful execution.And now for the tech stack. The main application uses React with Tailwind on the frontend, C# on the backend, hosted in AWS (App Runner, Lambda, RDS Postgres, SES), with auth provided by Google Firebase, and CI&#x2F;CD via GitHub Actions. The home page is actually an SSR (server-side rendered) application built with vite-plugin-ssr (now vike) and hosted in a Cloudflare Worker that hits the AWS-hosted API. This is basically a best-of-all-worlds SSR configuration - very fast, zero cold start (!), and essentially free.Any and all feedback is sincerely appreciated! danwee 28 minutes agoCongrats for launching the product!> These days it is common to apply to dozens of positions (some users track over a hundred opportunities).Honest question: is it that common? I&#x27;m an average software engineer in Western Europe. When I was junior (around 2010-2015) I usually got a job after submitting ~3 job applications (mainly, because I was accepting anything at that time). Nowadays, since I have more experience, whenever I want to switch my job, I know exactly to what kind of company I want to apply to, this means I don&#x27;t send a dozen applications; rather I send usually 1 or 2. But I do my investigation on that 1 or 2 companies I&#x27;m applying to. And I never interview with more than 1 company at a time (it would be very stressful for me).So, I&#x27;ve never had the struggle of \"keeping track\" of job applications. I&#x27;ve never worked for FAANG, though (not sure if this has anything to do). I thought my situation was more common, but based on your statement perhaps it&#x27;s not. reply akvadrako 10 minutes agoparentSure it&#x27;s common and it really depends how picky you are. I have 20 YoE and applied to over 150 places last year, some in Western Europe and some remote jobs in the USA. In the end I only got one offer, which I turned down. But I did gain a greater understanding of the market. reply smusamashah 4 hours agoprevThis looks great I am very suspicious about the company and interview reviews part. Glassdoor destroyed trust by giving incentive to employers destroying trust in reviews. I have a first hand experience about reviews I posted, and the fake reviews and then deletion of bad reviews of a company I worked for.It seems like any product offering public ratings will end up having fake ratings.What have you considered to make sure reviews remain legit? reply romanhn 2 hours agoparentTo be perfectly honest, I don&#x27;t have a great answer here yet. While the US has the Consumer Review Fairness Act, Glassdoor lost an important court case that saw a US court force them to furnish reviewer info to a non-US entity (https:&#x2F;&#x2F;www.shrm.org&#x2F;resourcesandtools&#x2F;hr-topics&#x2F;talent-acqu...). Terrible precedent, IMO.Some of the early thinking I&#x27;ve done is around the system being able to verify that a user did in fact apply to a company (assuming company is a customer of Rolepad). That provides some initial guarantees about the author of the data. With some ATS integration, there could be fairly concrete numbers on \"how quickly did X happen\" that don&#x27;t even need to be sourced from the candidate. That said, there is always a bit of a \"he said, she said\" with reviews, and I haven&#x27;t fully figured out an obvious way forward here. I think the general sentiment I&#x27;ve seen is that Glassdoor and Yelp reviews should be treated with a grain of salt, but they&#x27;re still better than nothing. reply pacerier 48 minutes agorootparentAnother method is to aim for safe harbor. Consider where would folks share this information today, legally, and make your solution legally similar. reply t0mas88 3 hours agoparentprevSame here. Glassdoor keeps saying everywhere that companies have no influence on the reviews. But they absolutely allow removal of bad reviews, even going as far as contacting our HR team offering it as a paid service. reply hashtag-til 1 hour agorootparentWhoever pays, has the power, so for Glassdoor that&#x27;s obvious. Companies can basically \"report\" anything they don&#x27;t like, and they do.My employer keeps asking us to \"leave honest reviews\" to help with hiring efforts. In practice that means they want us to leave GOOD reviews to raise rating scores on websites such as Glassdoor.Sorry HR, I&#x27;m not going to do your work for you. reply ngc6677 2 hours agorootparentprevSomehow it could be possible to created a \"trusted review\" system, based on existing tools. See \"Comments & reactions\" on https:&#x2F;&#x2F;profiles.joblist.today&#x2F;companies&#x2F;, where login is made with Github, and peers can \"upvote\" comments with reactions. reply somsak2 3 hours agorootparentprevWhat&#x27;s funny is that these bad reviews actually do show up on the RSS feed, so you can read them even after they&#x27;re removed. reply t0mas88 2 hours agorootparentWhich proves the point that Glassdoor is lying :-) reply maccard 1 hour agorootparentOr they&#x27;re technically telling the truth - the review hasn&#x27;t been removed, it&#x27;s just not visible on the website. replyshinryuu 3 hours agoprevSo I assume that in the end employers will somehow pay for this product. I encourage you to think long and hard about the alignment problem.If employers pay for this, when will the candidates experience suffer (and vice versa, the party that pays will always have priority though). How can you counteract this in the long-term? reply romanhn 2 hours agoparentI think I answered a very similar question here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37797516. Believe me, I have been thinking hard about alignment, conflicts of interest, privacy implications, etc. Alienating the candidate side will basically nullify the core premise of the platform, so avoiding short-term thinking and bonehead decisions is top of mind. reply Aeolun 47 minutes agorootparentYeah, it’s just that I’ve never been able to trust anything where the employer was the one paying…Even if I could trust it at the start, it eventually turned bad. reply usrme 24 minutes agoprevThis is absolutely gorgeous! Would you ever consider having a self-hosted version for job-seekers? reply benjaminwootton 39 minutes agoprevThis looks really nice and solves a real problem. One of the best niche SaaS ideas I&#x27;ve seen in a while. reply danielvaughn 6 hours agoprevI love this idea. When you&#x27;re in the hiring process, you&#x27;re managing an absolute mountain of detail between your various applications. There&#x27;s so much pain and toil, and a lot of it is lost once you get a job, and if you&#x27;re ever laid off you need to scramble to gather it all again.LinkedIn _kinda_ works here but it&#x27;s a distant afterthought for them. reply ickyforce 4 hours agoprevLooks interesting, I&#x27;ll probably try it.I think that the area where I&#x27;d love some tool to help me would be keeping track of phone calls - ideally even attaching recordings to a proper company, transcribing them and summarizing. It&#x27;s easy to get back to an email because stored but in case of a phone call I need to make notes quickly.When I keep track of things in a text file or spreadsheet it&#x27;s easy to get an overview quickly - because it&#x27;s all on a \"single page\". I can even grep for some key word. I don&#x27;t think Rolepad UI helps here. The current the company list shows only name, position and stage. I would like to at least see some \"comment\" for each.The last time I searched for a job I created labels in gmail for each position and created rules to automatically label incoming emails. It was very easy, just select an email -> \"filter messages like these\" -> label (set new to jobs&#x2F;company-name) and done. While I could potentially use Rolepad to store notes about companies I doubt that I would forward emails there because I don&#x27;t see potential benefits since Rolepad won&#x27;t automatically update any entries on its own. Maybe if I it aggregated all communication channels? emails, phone calls, linkedin messages, etcBy the way - I use multiple email addresses (wildcard in my own domain) when contacting recruiters but the accounts have just one so the email forwarding won&#x27;t work. reply romanhn 3 hours agoparentSome fantastic food for thought here, thank you!Definitely will acknowledge that searching the provided data has room for improvement. Re: emails, it actually does have some rudimentary capability to detect which opportunity the email should be assigned to, based on a few factors - this too will be improved in the future. One workflow I&#x27;ve thought about was adding save@rolepad.com to cc&#x2F;bcc on your outgoing emails to avoid the extra step. I have also kicked around the idea of creating custom Rolepad email addresses to use on outgoing resumes so that all communication is automatically captured in the system. Felt a bit fanciful at the time, curious if there&#x27;s interest.The multiple addresses is a doozy, will need to noodle on this. I guess easiest would be manually associating multiple emails with your account. Or the whole custom address thing... reply hubraumhugo 3 hours agoprevLove the progress visualizations as sankey diagrams. Reminds me of the many posts on r&#x2F;dataisbeautiful about job application progress, e.g.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;dataisbeautiful&#x2F;comments&#x2F;13if21g&#x2F;oc...https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;dataisbeautiful&#x2F;comments&#x2F;vrdcfz&#x2F;oc_...You could build pretty cool statistics around this once you have enough data. reply romanhn 3 hours agoparentThat&#x27;s where I got my inspiration :) reply mhlakhani 4 hours agoprevThis is a great idea! I remember facing similar pains when applying to dozens of companies last year and talked about a similar idea with a friend - glad to see someone building it. Wishing you the best of luck, and I’ll hopefully try and provide feedback soon reply jdthedisciple 10 hours agoprevLooks great and comes in perfectly in time for me.One concern: All my data incl. CV is stored plainly in the cloud, correct? reply romanhn 9 hours agoparentThanks! I suppose the answer depends on what you mean by \"plainly in the cloud\" :) It is indeed stored in Amazon&#x27;s RDS, which is a managed service. I approached this as a real product rather than a weekend project when it comes to security (application and infrastructure) and there is a lot in place protecting the data - Firebase&#x27;s jwt auth, XSS and SQL injection protection, default passwordless logins, data encrypted at rest, database in private subnet, DB credentials in a secrets vault with automatic rotation, multi-factor auth for all of my access to infra, probably a bunch more. Are there specific concerns not addressed here? reply jdthedisciple 1 hour agorootparentThank, that sounds great and fairly secure.I love your tech stack btw - C# backend is Elite (my main stack)! reply or113 5 hours agorootparentprevHave you done any penetration testing? reply lelanthran 3 hours agoprevThis looks good.How does the email addresses work? When I foward to sales@rolepad.com (or no@rolepad.com), how does it know that the message came from me[1]? Do you send back a confirmation I need to click on? Do I need to include a secret key in the subject line&#x2F;body?[1] I assume that you already know that email from&#x2F;reply-to headers are trivially spoofed (i.e. the email client will let anyone set any value for from or reply-to). reply romanhn 3 hours agoparentYeah, this one I went back-and-forth a lot during initial implementation. It&#x27;s not easy to find a balance between making it dead simple and preventing abuse. I kept it simple as far as forwarding goes - an account must exist for the sender address or else the email is not processed. For save@, I was mostly worried about covertly updating&#x2F;creating opportunities based on emails alone, so there is a step where the user has to take a manual action to confirm the email note assignment. For no@, all the same outcomes, but also the sender is bcc&#x27;ed on the decline email.In other words, theoretically spoofing could occur, but there are compensating controls in place to minimize any damage. Given a very low likelihood of an attack in this direction, that felt like a reasonable compromise. Would love to get feedback on that though! reply lelanthran 2 hours agorootparent> In other words, theoretically spoofing could occur, but there are compensating controls in place to minimize any damage. Given a very low likelihood of an attack in this direction, that felt like a reasonable compromise. Would love to get feedback on that though!I don&#x27;t have good recommendations right now[1], but I think not having a way to opt-out for those who are security conscious is a turn-off for some people. After all, having opt-out[2] doesn&#x27;t impact the existing users who don&#x27;t care (they won&#x27;t even notice), while those who care can turn it off.I mean, as a user I disagree with your assessment of the probability of an attack using this vector, but I don&#x27;t want to argue with you about it, I just want to turn it off for my account.After all, if I said something similar about an exploit in my product, I can expect to get roasted by the users. For example, if there is a well-known buffer-overflow in my product, and I said something like this:\"In other words, theoretically users could send a value for the &#x27;email&#x27; field larger than 255 bytes and smash the stack, but there are compensating controls in place to minimize the damage from overwriting the return address. Given a very low likelihood of a user sending more than 255 bytes for an email address, it felt like a reasonable compromise.\"With security you can&#x27;t really tell in advance how an exploit might be escalated. The only damage you see from allowing spoofed emails is \"attacker causes candidates to reject a position they don&#x27;t want to reject\". Could there be others?Could a coworker who knows I am on the prowl send an email to no@ with my address set in the &#x27;from:&#x27; field and his set in the \"forwarded\" email? At the very least this sounds like a leak of account email addresses.Still, see my point [2] below - maybe the return on implementing controls for attack prevention won&#x27;t help your product at this stage. It might make more business sense to rely on mitigating the damage than preventing it.[1] Simple: Don&#x27;t send anything, place it in an outbox that the user can review before hitting &#x27;send all&#x27;. Complex: Require user to upload their public key and process messages signed with the private key. Neither of these are &#x27;good&#x27; in the sense of frictionless management via email.[2] It depends on how much time you have. If this is a thing that would take 4 hours to implement, test and document, maybe you product has more pressing issues that those 4 hours would be better spent on. You&#x27;ll have to triage the feedback you get and determine which feedback would result in the most takeup. IME, people often don&#x27;t care about security, so you might find that spending even 5m on this has less positive influence on the business than spending those 5m cold-calling customers. reply romanhn 2 hours agorootparentJust want to say I super appreciate your balanced perspective here. I&#x27;m not a security engineer by trade, so getting this sort of feedback is quite valuable.The no@ scenario is an interesting one. The opt-out would certainly be one clean approach here. Going to give it some thought! reply dalai 45 minutes agorootparentYou could also consider a “personalized” no+uuid@ address that only the user knows. Slightly more work, but the user would just add it to their address book anyway. replyrandomsofr 11 hours agoprevLooks pretty good, i&#x27;m wondering how are you planning on monetizing this? reply romanhn 10 hours agoparentThrough employers, not job seekers. Not sure how to put this without marketing-speak, but I do truly believe that there is a win-win proposition here where an amazing candidate experience can be highly beneficial to the hiring org. I wrote down some thoughts on https:&#x2F;&#x2F;rolepad.com&#x2F;employers as well. As I mentioned in the original post, there is a lot of consider here privacy-wise but I definitely have some concrete ideas that I want to start bouncing off hiring managers and the like (which will likely involve sharing Rolepad job description links that add the position with a bunch of prefilled data to the candidate&#x27;s account in one click). reply Grimburger 7 hours agorootparentI honestly think you should aim to make jobseekers pay instead of the job offerers.The automation of job applications means that basically everyone tunes out when they hit 100+ CV&#x27;s, go post a small wage globally remote job to test and you will see what I mean.A dollar here or there definitely means your clients will get actual people who are serious about wanting it rather than the current spray and pray system that inundates and overwhelms anyone who puts up jobs today. reply clnq 6 hours agorootparentI also want to pay for this as a future jobseeker for two reasons: one, I want a platform like this to focus on me as the client, and two, I want it to exist.But what Grimburger says is also important - employers will hate your platform if it will become spam city.If a platform helped me track my applications CRM-style and automate some of the process, especially scheduling interviews, I would gladly pay LinkedIn bucks for it. reply deprecative 5 hours agorootparentThis platform will not change human behavior. Sorry to say. reply bbarnett 4 hours agorootparentYes.I think the only way to prevent spewing&#x2F;spamming of every employer with resumes, would be if there was a crazy high cost to apply to each job. If someone paid $10 per month for 1 application or 100 applications, or 1000, for many the 1000 is going to happen.If it was $10 per application, you wouldn&#x27;t be \"changing\" human behaviour, you&#x27;d be leaning into it, by de-incentivizing 1000 applications with \"virtual pain\". EG, money leaving wallet.I don&#x27;t see how to easily prevent this with such a platform, the per-application cost is a no-go, at best you could have hard limits of apps per month. reply bee_rider 5 hours agorootparentprevAs a currently not employed person, one interesting thing to note about me is that I have no income, which means not much money to pay for things. reply pacerier 23 minutes agorootparentSure, and you certainly have future money. if the app is that good that is. reply Grimburger 2 hours agorootparentprevI see this argument a lot, yet it falls apart upon closer inspection, I&#x27;m talking a few dollars a month to put your best foot forward at jobs that suit you rather than spray at basically every single open position and take whatever you can get.Try to see this from the other side of the equation. reply rewmie 50 minutes agorootparent> I see this argument a lot, yet it falls apart upon closer inspectionBut does it, though? I don&#x27;t think so.> I&#x27;m talking a few dollars a month to put your best foot forward (...)No, it really is not, and your portrayal really feels like a fraudulent way to frame the service.No job applicant becomes better suited for a position if they apply through service A or B. Moreover, the only thing that this sort of service enables is throwing your hat in the race, and it&#x27;s up to the candidate to successfully pass all subsequent tears. This sort of service does absolutely nothing to help you with those stages of the process, which are the ones that matter.> Try to see this from the other side of the equation.This is one of the many mistakes you&#x27;re making. For the job seeker, there is only one side: the job seeker&#x27;s side. There a already N services out there that allows them to apply for a job. None of them charges them a cent. Some companies even go through the trouble of posting the same job ad in multiple services. Some companies even hire multiple recruiters to find them the job applicant they are looking for. A job applicant can already apply through N services for free. Why would a job applicant suddenly feel the need to pay for the N+1?It&#x27;s stupid to confuse \"have money\" with willingness to pay, and mentioning vacuous statements like \"sides of the equation\" changes nothing. reply rewmie 4 hours agorootparentprev> I honestly think you should aim to make jobseekers pay instead of the job offerers.If I was a job seeker, specially if I was out of a job, I would never ever spend a single cent on a job application service, particularly one that does not work as a job board.All job boards such as LinkedIn already support some job application tracker features, including through third-party services. If you have access to a text file&#x2F;spreadsheet, you can easily fill in the blanks to track your own job applications. Any third party job application service ends up being only the n+1 webapp you&#x27;ll be using anyway,so why pay for the one out of n+1 particularly if it doesn&#x27;t add any value?There are plenty of job application tracking services out there already, but from the applicant&#x27;s pov the only issue worth fixing is how you end up using a different service for each company you applied for. Job boards such as LinkedIn kind of mitigate this problem due to its massive adoption, but still some companies only use LinkedIn to route applicants to their own service. Adding yet another job application tracker to the mix solves nothing, and is definitely not worth paying for as an applicant. reply Grimburger 2 hours agorootparent> If I was a job seeker, specially if I was out of a job, I would never ever spend a single cent on a job application serviceFind this very hard to believe. You really wouldn&#x27;t spend $1 to submit a job application to a position that is your bread and butter while unemployed? Even if it meant there wasn&#x27;t hundreds of others spamming the same endpoint? Taking such an ideological high ground over a few cents rarely works out well.I&#x27;ve seen&#x2F;been on both ends long before covid&#x2F;wfh stuff and the worldwide remote market is a complete fucking mess today due to automation, it&#x27;s bots all the way down and not a single bit closer to good client&#x2F;contractor relationships, you really have to wade through the weeds to find anyone half decent.Again, I ask you to post a job online and see the results for yourself then reconsider my comment. reply rewmie 1 hour agorootparent> Find this very hard to believe. You really wouldn&#x27;t spend $1 to submit a job application to a position that is your bread and butter while unemployed?No, it&#x27;s a stupid concept, and one that turns posting fake job ads into a profitable scam.> Even if it meant there wasn&#x27;t hundreds of others spamming the same endpoint?Take a minute to think about that nonsense. Do you really think a company will want to risk losing the ideal candidate to fill it&#x27;s position just because some mastermind decided to charge for each application?Specially when every single company out there already has no problem posting their own job ads without charging applicants.> Taking such an ideological high ground over a few cents rarely works out well.Nonsense. It&#x27;s a stupid move that goes against the best interests of all parties involved. But don&#x27;t take my word for it. Go ahead and invest your cash on yet another job tracking service and put a paywall on applicants. Best of luck. reply pacerier 17 minutes agorootparentprevI&#x27;m confused. Are you honestly selling to the CEO?If someone down the ladder, who exactly? reply altdataseller 10 hours agorootparentprevWhat kind of competitive benchmarking would you offer? reply romanhn 10 hours agorootparentCompensation is top of mind for me. An applicant [EDIT: application, not applicant] tracking system is well-positioned to have a solid, up-to-date view into the compensation landscape, unlike sites like Glassdoor and Blind which are more lagging and self-selecting. Balanced with privacy, there is some real opportunity here. Outside of compensation - all sorts of analytics pertaining to interview process, how quickly competitors fill their roles, that sort of data. reply altdataseller 10 hours agorootparentWhy is an applicant tracking system have an up to date view of the compensation landscape? Would I be required to submit how much I was offered to your system? Why would that be necessary? reply iakh 9 hours agorootparentI can see value in tracking offers to see how negotiations are going. so if there&#x27;s standard fields for this, then that&#x27;s a way he could track comp data without requiring, and even get offer increase info which is probably even more valuable. reply romanhn 10 hours agorootparentprevThat&#x27;s a fair question - and no, almost all data is optional. But... people do enter this, and companies have roles with open compensation as well. I&#x27;m talking about an aggregated view into anonymized data here.EDIT: Just realized I wrote \"applicant tracking system\" above. Total slip of the tongue, this is an _application_ tracking platform for job seekers, not an ATS used by companies. Though I do sometimes think of Rolepad as an ATS for the candidate. reply nvy 4 hours agorootparentprevI feel like at this point you&#x27;re also building glassdoor or levels.fyi in addition to rolepad. replyjbl0ndie 4 hours agoprevHow about a &#x27;pay what you think it&#x27;s worth&#x27; or &#x27;pay what you can&#x27; model for applicants?I object to paying for LinkedIn pro when they&#x27;re making money off me being recruited but for a tool I can use to manage a stressful process, this feels different. reply gadders 1 hour agoprevPlease build something that auto fills Taleo&#x2F;WorkDay application forms. reply Hasnep 7 minutes agoparentI&#x27;ve had a good experience auto-filling job applications using this browser extension: https:&#x2F;&#x2F;simplify.jobs&#x2F; You need to create an account to use it, but at this point it&#x27;s saved me so much time that I don&#x27;t mind. reply petesergeant 44 minutes agoprevHey, I&#x27;ve got a lot of experience in this space as a recruiter and someone who used to be CTO at a recruitment-tech company. This looks awesome! reply androng 4 hours agoprevsorry but I do not see this as useful. I just use a spreadsheet and that is good enough. The hard part of job interviewing is learning all the useless Leetcode and preparing the stories in \"STAR format\" and interviewing taking up 5 hours and the indefinite period of time for replies. Not the tracking. reply thih9 4 hours agoparentTo me the hard part is finding a company that doesn’t rely on this when interviewing (I consider it unnecessary and inefficient, I wouldn’t want to work in a place like this). So a tracker with reviews sounds good in theory. reply iwonthecase 3 hours agoparentprevSame, although I appreciate the work OP&#x27;s putting into this, and would find value in the aggregated statistics (especially stats about the interview funnel.)For me, I just have a big plain text file where I keep notes and stuff about companies once they get back to me after I send off a resume. I also have two email folders (one of all job search related stuff, the other for messages about upcoming or pending calls) and iCal. reply moneywoes 4 hours agoparentprevwhat is your spreadsheet like? reply rewmie 4 hours agoparentprevThis.Tracking which job you applied for is the least of the job applicant&#x27;s concerns when looking for a job. In some circumstances the first step of the job application process is even fire-and-forget, and tracking those only serves to not apply again which is a zero-effort move.Once you start to get a process going, emails and calendars already leave a good, easy to follow paper trail, and any need you might have is easily fixed with a text file&#x2F;spreadsheet. reply PaulHoule 8 hours agoprevYeah, the last version of the software that became my YOShInOn RSS reader was an application tracking system. I had a great answer to \"tell me about a project you&#x27;ve worked on\" that got me a machine learning job in two weeks. reply moneywoes 4 hours agoprevMay i ask what react tutorial you followed to make this? also, tools used reply romanhn 3 hours agoparentTBH, I just went through the official docs and that was sufficient - they are fantastic. I wrote a bit about my experience in the top comment here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35186812Other tools? Have been using Visual Studio mostly (due to C#) until recently when I switched from a Windows laptop to a Macbook. Now all coding is in VS Code, which is ... good enough so far. Really the only other item worth mentioning is I bought the Tailwind UI component library early on. It&#x27;s been a total lifesaver. Design does not come easy to me at all, and I was able to get started with semi-decent-looking UI from the get-go. It still requires a lot of effort to get things to where I like what I&#x27;m seeing, and there&#x27;s still lots of iteration, but it was definitely the right move, and the cost was well worth it. reply b8 8 hours agoprevVery cool, and useful! Though I wouldn&#x27;t trust this for jobs which require clearances etc. Also, I&#x27;d be afraid of hiring managers emails being leaked, but from one of your post, your security seems to be decent. reply romanhn 7 hours agoparentThank you! Would you mind expanding on the concern around hiring manager emails getting leaked? Curious what you consider sensitive in these emails and how that data might be used inappropriately. Just want to ensure I don&#x27;t have gaps in my risk assessment. reply bbarnett 4 hours agorootparentIt&#x27;s beyond easy to setup unique throwaway email addresses for things like this. Seems an unusual concern. reply davidmurphy 8 hours agoprevPhenomenal. Highly needed product. Wish I were a VC and could invest! reply iamcreasy 6 hours agoprevLooks cool - I&#x27;ll try it out.Is it possible to export my data if I decide to leave the platform? reply romanhn 6 hours agoparentThanks! Not at the moment, but you&#x27;re the second user asking about it today so that definitely bumps it up on the priority list. reply iamcreasy 1 hour agorootparentInspired by your product I started logging my job search into a postgresql db. :) reply ravivooda 6 hours agoprevI love that you gave test credentials :) reply romanhn 6 hours agoparentFun fact - dang (the HN moderator) suggested this earlier while we were figuring out why this post was stuck in flagged status (props to him for unblocking it eventually). reply altdataseller 6 hours agorootparentWhy was it in flagged state? reply romanhn 6 hours agorootparentdang followed up on it and it turned out someone flagged it by mistake reply taubek 2 hours agoprevIt is nice to see that you mention GDPR in your legal documents. Can you tell me can I export my data in some json, csv or some similar format? reply romanhn 2 hours agoparentNot yet in an automated fashion. Interesting to see this request pop up a few times now today. I would attempt to provide this manually to comply with the spirit of GDPR data portability clause for now. Note that I don&#x27;t claim GDPR compliance for Rolepad at this stage, but would do my best to ensure data privacy and security. reply erehweb 9 hours agoprevHave you looked at Duotrope (duotrope.com)? That solves a similar problem - tracking acceptances &#x2F; rejections for writers. The constraints are a little different in that an author may have many pieces, but usually each magazine will only look at one piece at a time, and they will often request that you not submit a piece to multiple magazines at once. reply romanhn 9 hours agoparentI have not, will check them out, thank you. One at-a-glance difference is that they charge individual writers, which probably makes sense. I&#x27;m fairly allergic to charging job seekers though. reply rkho 8 hours agorootparentIf I were looking for a job, I would gladly pay a couple hundred dollars to use this. There is real value in a streamlined way to track all of my applications&#x27; statuses like this. I&#x27;ve used lists on Asana with custom categories in the past, but this is a lot cleaner.If you&#x27;d really rather not go the monetization of job seekers route, one suggestion would be to try and sell this to people running upskill programs i.e. coding bootcamps as a product they could give their students&#x2F;graduates access to. reply romanhn 6 hours agorootparentThank you for the suggestion! I&#x27;ve considered the bootcamp&#x2F;school route and I think there is opportunity there. For now trying not to spread my focus too thin though. reply yieldcrv 6 hours agoprev [–] If you ever scale up, you might find it difficult for recruiting for that stack, ironically> The main application uses React with Tailwind on the frontend, C# on the backendI&#x27;m curious what about your experience gave you that stack? I&#x27;m sure it works fine, but the \"not JS backend\" people are usually stuck in older frontend frameworks, and the JS everything world has Next.js and various things to power both the frontend and backend together reply scrapcode 6 hours agoparentBoth C# (ASP.NET Core) and React consistently rank pretty high up in the Stack Overflow Developer Survey frameworks section, with both being in the top 5 for 2023 [0].[0] https:&#x2F;&#x2F;survey.stackoverflow.co&#x2F;2023&#x2F;#section-admired-and-de... reply Pannoniae 4 hours agoparentprevHave you ever heard of \"making people learn tools\"? Not every job has to be the cookie-cutter node&#x2F;react stack... you can also train people to use your stack. reply yieldcrv 1 hour agorootparenttell that to employers and what they tell recruiters about needing someone to “hit the ground running”despite having the job open for 6 months reply romanhn 5 hours agoparentprev [–] It was a mix of what I already knew (.NET) and what I wanted to learn (React). I love C# as a language and it works just fine with whatever frontend you throw at it (it&#x27;s just an API after all). I wouldn&#x27;t touch a Microsoft frontend framework with a ten-foot pole. reply yieldcrv 5 hours agorootparent [–] yeah, itll be a high performant API server as C# replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Rolepad is a free service designed to enhance job hunting by offering a record-keeping system, allowing tracking and management of applications, saving recruiter correspondence, creating progress charts, and anonymous reviews of companies' application processes.",
      "The technology stack of Rolepad comprises React with Tailwind on the frontend, C# for the backend, and is hosted on AWS for robust and scalable cloud solutions. The application is server-side rendered (SSR) for faster performance and no cold start.",
      "Rolepad's creator is initiating discussions with employers to discover strategies to mitigate frustration for both job candidates and employers, showing a commitment to improving the overall hiring process."
    ],
    "commentSummary": [
      "Rolepad is a job application tracker designed to enhance transparency and efficiency in the hiring process, allowing users to track job applications, accumulate company information, and visualize progress through charts.",
      "Users can also provide feedback on their experience with the application, interview, and job offer procedures. Rolepad employs React, C#, and is hosted on AWS, utilizing Google Firebase for authentication.",
      "The founder is contemplating the development of a unified platform for job seekers and employers, with discussions focusing on privacy concerns, review authenticity, future features, effective security measures, possible monetization methods, and the technology stack. Applications for YC Winter 2024 are currently open."
    ],
    "points": 193,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1696608072
  },
  {
    "id": 37792294,
    "title": "Java 21 VirtualThreads vs. Clojure Lazy Seqs",
    "originLink": "https://clojure.org/news/2023/10/06/deref",
    "originBody": "Clojure OVERVIEWREFERENCEAPIRELEASESGUIDESCOMMUNITYDEVNEWS Clojure Deref (Oct 6, 2023) Clojure Deref (Sept 29, 2023) Clojure Deref (Sept 22, 2023) Clojure Deref (Sept 15, 2023) Clojure Deref (Sept 8, 2023) Clojure Deref (Sept 1, 2023) Clojure Deref (Aug 25, 2023) Clojure Deref (Aug 18, 2023) Clojure Deref (Aug 11, 2023) Clojure Deref (Aug 6, 2023) (next Rich) Clojure Deref (July 28, 2023) Clojure Deref (July 20, 2023) Clojure Deref (July 7, 2023) Clojure Deref (June 30, 2023) State of Clojure 2023 Results Clojure Deref (June 23, 2023) Clojure Deref (June 16, 2023) Clojure Deref (June 9, 2023) Clojure Deref (June 2, 2023) Clojure Deref (May 26, 2023) Clojure Deref (May 19, 2023) Clojure Deref (May 12, 2023) Clojure Deref (May 5, 2023) Clojure Deref (May 1, 2023) Introducing Morse Clojure Deref (Apr 21, 2023) Clojure Deref (Apr 14, 2023) Clojure 1.12.0-alpha2 Clojure Deref (Apr 10, 2023) Clojure Deref (Mar 31, 2023) Clojure Deref (Mar 27, 2023) Clojure Deref (Mar 18, 2023) Clojure Deref (Mar 10, 2023) Clojure Deref (Mar 3, 2023) State of Clojure 2023 Survey Clojure Deref (Feb 26, 2023) Clojure Deref (Feb 17, 2023) Clojure Deref (Feb 10, 2023) Clojure Deref (Feb 3, 2023) Clojure Deref (Jan 30, 2023) Clojure Deref (Jan 20, 2023) Clojure Deref (Jan 13, 2023) Clojure Deref (Jan 6, 2023) Clojure Deref (Dec 22, 2022) Clojure Deref (Dec 16, 2022) Clojure Deref (Dec 8, 2022) Clojure Deref (Dec 2, 2022) Clojure Deref (Nov 23, 2022) Clojure Deref (Nov 18, 2022) Clojure Deref (Nov 11, 2022) Clojure Deref (Nov 4, 2022) Clojure Deref (Oct 28, 2022) Clojure Deref (Oct 21, 2022) Clojure Deref (Oct 14, 2022) Clojure Deref (Oct 10, 2022) Clojure Deref (Oct 3, 2022) Clojure Deref (Sep 26, 2022) Clojure Deref (Sep 16, 2022) Clojure Deref (Sep 9, 2022) Clojure Deref (Sep 2, 2022) Clojure Deref (Aug 26, 2022) Clojure Deref (Aug 19, 2022) Clojure Deref (Aug 12, 2022) Clojure Deref (Aug 5, 2022) Clojure Deref (July 30, 2022) Clojure Deref (July 15, 2022) Clojure Deref (July 8, 2022) Clojure Deref (July 1, 2022) Clojure 1.12.0-alpha1 Clojure Deref (June 24, 2022) Clojure Deref (June 17, 2022) Clojure Deref (June 10, 2022) State of Clojure 2022 Results Clojure Deref (June 2, 2022) Clojure Deref (May 27, 2022) Clojure Deref (May 20, 2022) Clojure Deref (May 13, 2022) Clojure Deref (May 6, 2022) Clojure Deref (Apr 29, 2022) Clojure Deref (Apr 22, 2022) Clojure Deref (Apr 14, 2022) Clojure Deref (Apr 8, 2022) Clojure 1.11.1 release Clojure Deref (Apr 1, 2022) Clojure Deref (Mar 25, 2022) Clojure 1.11.0 release Clojure Deref (Mar 20, 2022) Clojure Deref (Mar 11, 2022) Clojure Deref (Mar 4, 2022) Clojure Deref (Feb 28, 2022) State of Clojure 2022 Survey Clojure Deref (Feb 18, 2022) Clojure Deref (Feb 14, 2022) Clojure Deref (Feb 4, 2022) Clojure Deref (Jan 28, 2022) Clojure Deref (Jan 21, 2022) Clojure Deref (Jan 14, 2022) Clojure Deref (Jan 7, 2022) Clojure Deref (Dec 23, 2021) Clojure Deref (Dec 17, 2021) Clojure Deref (Dec 10, 2021) Clojure Deref (Dec 2, 2021) Clojure Deref (Nov 24, 2021) Clojure Deref (Nov 19, 2021) Clojure Deref (Nov 12, 2021) Clojure Deref (Nov 5, 2021) Clojure Deref (Oct 29, 2021) Clojure Deref (Oct 22, 2021) Clojure Deref (Oct 14, 2021) Clojure Deref (Oct 8, 2021) Clojure Deref (Sept 24, 2021) Clojure Deref (Sept 17, 2021) Clojure Deref (Sept 10, 2021) Clojure Deref (Sept 3, 2021) Clojure Deref (Aug 27, 2021) Clojure Deref (Aug 20, 2021) Clojure Deref (Aug 13, 2021) Clojure Deref (July 30, 2021) Clojure Deref (July 23, 2021) Clojure Deref (July 16, 2021) Source Libs and Builds Clojure Deref (July 9, 2021) Clojure Deref (July 2, 2021) Clojure Deref (June 25, 2021) Clojure Deref (June 18, 2021) Clojure Deref (June 11, 2021) Clojure Deref (June 4, 2021) State of Clojure 2021 Results Keyword argument functions now also accept maps Clojure 1.10.3 release Clojure 1.10.2 release State of Clojure 2021 Survey Cognitect Joins Nubank! Clojure Homebrew Tap State of Clojure 2020 Results State of Clojure 2020 Survey Clojure Forum Clojure 1.10.1 release JIRA Migration State of Clojure 2019 Results State of Clojure 2019 Survey Clojure 1.10 release State of Clojure 2018 Results Git Deps for Clojure Clojure 1.9 is now available State of Clojure 2016 Results Introducing clojure.spec State of Clojure 2015 survey results Clojure 1.8 is now available Welcome to the new clojure.org! Clojure 1.7 is now available Transducers are Coming Clojure core.async Channels Anatomy of a Reducer Reducers - A Library and Model for Collection Processing Clojure Governance and How It Got That Way Introducing ClojureScript Clojure Deref (Oct 6, 2023) 06 October 2023 Alex Miller Welcome to the Clojure Deref! This is a weekly link/news roundup for the Clojure ecosystem (feed: RSS). Thanks to Anton Fonarev for link aggregation. From the core Recently Java 21 was released (congrats!) and this has driven a lot of interest and experimentation with the new virtual threads feature. Virtual threads have the ability to park and resume a virtual thread (particularly one blocked on I/O) and this cooperates transparently with many blocking constructs in Java - I/O, sockets, java.util.concurrent.lock, etc. However, one thing it does not (yet) cooperate with is object monitors (synchronized) and thus doing a blocking call while holding a synchronized monitor prevents a virtual thread from parking (ie, \"pins\" the virtual thread). Note that synchronization itself is not inherently bad - normal use of synchronized to serialize reads and writes to fields is fine (as there is no blocking I/O that can pin a thread). Several people doing new things with virtual threads have detected cases where user code is doing I/O blocking while Clojure is in a synchronization block, thus pinning threads. The two most important cases are lazy seqs and delay - both hold some suspended computation in a thunk and invoke the thunk under synchronization, thus allowing for the possibility of user I/O under a lock in the language level. As people have raised this as an issue, we have spent the last week taking a hard look at this area. At a meta level, there are a bunch of options here and we have still not decided on our approach or timeframe. From a user level, it is possible to simply not do (or tolerate) I/O under delay or lazy seqs. Delay is a one-time thing, so it may not generally be an issue to pin a thread that is reading a config file as that is a one-time thing. Pulling I/O over a lazy seq is not uncommon and can definitely present this kind of issue, but there are a lot of other options - controlling via loop/recur, using transducers and sequence, etc. If you are experiencing this problem now, these are probably worth exploring. We’ve spent a ton of time over the last week looking at the internals of LazySeq and options for avoiding synchronization. The general guidance from Java is to replace synchronized with ReentrantLock (which has virtual thread coordination), but this advice leaves out the inherent tradeoffs in that change. synchronized relies on object monitors which are built into every Java object at the JVM level, whereas ReentrantLocks are additional Java objects (which hold a reference to an internal Sync object). Clojure makes a lot of lazy seqs and allocating two objects (plus adding an additional field to LazySeq) for every lazy seq is a real cost in allocation, heap size, and GC. Additionally, while ReentrantLock seems to be a bit faster than synchronized in Java 21, LazySeq makes one reentrant call, and reentrant calls seems to be noticeably slower than synchronized. There are lots of options though. We think it’s relatively easy to make lazy seq walking faster, but a lot harder to keep realization costs under control (as making locks takes non-zero time). One interesting branch we have explored is making one lock per seq and passing it through the seq as we go - lots of tradeoffs in that. Additionally, we continue to work on functional interface adapters and method thunks. With FI adapters, we continue to refine when implicit coercion and conversion occur and I think that draws asymptotically closer to completion. With method thunks, we have taken a bit of a detour to examine array class representation. Generally, classes are represented by symbols that name the class, but this does not work for array classes as they cannot be represented as a valid symbol. The fallback right now is using a String that holds the internal class name, like ^\"[Ljava.lang.String;\" which I think we can all agree is no fun. Our plan going forward is to support a new array class syntax which is a symbol of the class with a * suffix. Imported classes can use their short name, so String* will represent a Java String[] (or a String… vararg). Multiple ** will represent multidimensional arrays. This will work with both classes and with primitives, so long* will be a synonym for the existing longs. Rich also wishes you to notice the C pointer punnery. :) That was a bit of a diversion, but I think it is a big win to fix a long-time representational gap. It also helps create some new \"columns\" in the varargs decision matrix, which is not going to be addressed in 1.12, but I think we have teed up to work on immediately after. Podcasts and videos #91 Josh Glover - defn Ep 092: Freeing Limits - Functional Design in Clojure Ep 093: Waffle Cakes - Functional Design in Clojure Matrix Exposed! (or, You Don’t Know Reactive) (by Kenny Tilton) - London Clojurians Scicloj LLM Meetup 4: transformer-based generative LLMs - Sci Cloj Scicloj LLM Meetup 5: Library overviews - Sci Cloj Parens of the Dead - Episode 24: Merry Happy! - emacsrocks Complete Clojure Development Environment Setup: IntelliJ IDEA, Cursive, ASDF/RTX, Toolbox - Andrey Fadeev Private Methods in Clojure - Clojure Diary Pedestal 7 – Cookies - Clojure Diary Conhecendo Datomic - João Palharini - clojure-br Blogs, articles, and projects Following our first five LLM meetups - Daniel Slutsky Include interactive Clojure/script code snippets in a web page with SCI & friends - Jakub Holý OSS updates September 2023 - Michiel Borkent Lazy, Chunked, and Buffered: Understanding Clojure’s Lazy Sequences - Bruno Bonacci Libraries and Tools New releases and tools this week: fulcro-troubleshooting v7 - A development-time library for Fulcro that helps to detect problems earlier and find and fix their root cause faster minimalist-fulcro-template-backendless - A minimal template for browser-only Fulcro apps for learning clojure-test 2.1.182 - A clojure.test-compatible version of the classic Expectations testing library clerk 0.15.957 - Moldable Live Programming for Clojure deps-diff 1.1 - A tool for comparing transitive dependencies in two deps.edn files datalevin 0.8.20 - A simple, fast and versatile Datalog database antq 2.7.1133 - Point out your outdated dependencies tab 2023-10-03.333 - A tool for tabulating Clojure collections pp 2023-10-05.5 - Pretty-print Clojure data structures, fast raphael 0.3.0 - A Clojure library for parsing strings containing the Terse Triples Language: Turtle clj-otel 0.2.4.1 - An idiomatic Clojure API for adding telemetry to your libraries and applications using OpenTelemetry neil 0.2.61 - A CLI to add common aliases and features to deps.edn-based projects squint 0.2.30 - ClojureScript syntax to JavaScript compiler Tutkain 0.19.0 (alpha) - A Sublime Text package for interactive Clojure development cherry 0.1.9 - Experimental ClojureScript to ES6 module compiler taplet 1.0.58 - A Clojure/ClojureScript macro, let> that works like a let, and also tap>s the binding vector nbb 1.2.179 - Scripting in Clojure on Node.js using SCI COMMUNITY Resources Contributing Companies Site LEGAL License Privacy Policy DOCUMENTATION Overview Reference API Guides Libraries & Tools UPDATES News Events ETC ClojureTV Books Swag CODE Releases Source ClojureScript ClojureCLR Copyright 2008-2022 Rich HickeyPrivacy Policy Logo & site design by Tom Hickey Published 2023-10-06 Update this page",
    "commentLink": "https://news.ycombinator.com/item?id=37792294",
    "commentBody": "Java 21 VirtualThreads vs. Clojure Lazy SeqsHacker NewspastloginJava 21 VirtualThreads vs. Clojure Lazy Seqs (clojure.org) 191 points by grzm 18 hours ago| hidepastfavorite110 comments mike_hearn 17 hours agoThe Clojure devs should be aware that the synchronization pinning problem is intended to be temporary and doesn&#x27;t apply at all with GraalVM native images. One of the Loom developers talks about it here:https:&#x2F;&#x2F;mail.openjdk.org&#x2F;pipermail&#x2F;loom-dev&#x2F;2023-September&#x2F;0...So they could also just choose to ignore this problem for now. reply puredanger 15 hours agoparentWe are aware, and that is one of the options. :) reply puredanger 15 hours agorootparentThe other thing I didn&#x27;t mention is that the change to remove biased locking a while back has also had an impact in some places that do almost always uncontended locking, so we&#x27;re kind of considering that too. reply fnordsensei 17 hours agoparentprevA lot of Clojure projects choose to stick with the LTS releases though, so it might take a while before this problem disappears on its own, even if fixed in the JVM. reply koito17 17 hours agorootparentIn fact, the officially supported Java releases for Clojure are all LTS releases. This is also reflected in their CI. At the moment, that means 1.8, 11, 17, and 21.I would also like to mention, for non-Clojure users: it took ages for Clojure to finally get off Java 1.5. The compiler was still emitting 1.5 compatible bytecode as late as 2018. Since the release of Clojure 1.10 (17 December 2018), the minimum Java version was bumped up to 1.8, in the sense that the compiler now emits 1.8-compatible bytecode.There is a strong emphasis on moving slowly and NOT breaking things in the Clojure community. Likewise, if you look at the most recent Clojure survey results, the vast majority of people were still on 1.8 and 11 releases.[1][1] See Q24 in https:&#x2F;&#x2F;www.surveymonkey.com&#x2F;stories&#x2F;SM-_2BH3b49f_2FXEkUlrb_... reply tombert 16 hours agorootparentI actually do feel like this is partly what&#x27;s responsible for Clojure&#x27;s relative success in industry. If you have a company with a ton of Java 5 code, and you want some of the sexy functional programming features, your options basically boil down to \"upgrade everything to the newer Java 8 to get maps and optionals and whatnot\" or \"just write this new service in Clojure that will happily interop with our Java 5 code\".I&#x27;m not making a judgement on which decision is better, but I can totally see the appeal, at least in the short term, for people choosing Clojure, especially if they think that Clojure&#x27;s API will be largely unchanged in the Java 8 update. It doesn&#x27;t hurt that Clojure is just broadly a really pleasant to work with, at least in my opinion. reply Quekid5 11 hours agorootparent> If you have a company with a ton of Java 5 code...You are in deep deep trouble already, just process-wise. If you&#x27;re making money hand over fist you might be able to afford to do that, but choice of language is not even on the radar in terms of what needs fixing.Now, if you mean in terms of digging out of that hole... just upgrade to newer dependencies, newer JDK versions, etc. That&#x27;s the way to better performance, better memory usage, better GC, better everything... and THEN think about the language you&#x27;re using. reply nlitened 4 hours agorootparent> You are in deep deep trouble already, just process-wise.Code is usually a much smaller piece of company&#x27;s business process than we developers like to think.> If you&#x27;re making money hand over fist you might be able to afford to do thatHere&#x27;s the problem though: the vast majority of companies on the planet don&#x27;t \"make money hand over fist\", they just have small to reasonable profit margins. And most businesses can&#x27;t just risk losing what&#x27;s already been working for a decade just because some developers want a new shiny thing every six months.That&#x27;s the reality which JVM and Clojure folks take very seriously, but is very often overlooked by younger people. reply vemv 17 hours agorootparentprevTo be entirely fair, there&#x27;s arguably little overlap between devs that stick to LTS, and devs that will play with JVM virtual threads on Clojure (before the Clojure team has any particular, public stance on them). reply fulafel 16 hours agorootparentYes, especially since the use case for virtual threads is so niche. reply raspasov 3 hours agorootparentIt&#x27;s niche if you don&#x27;t have much traffic&#x2F;request volume&#x2F;etc.Once you have even an arguably relatively small amount (100s to 1000s of requests per second) it can be a game changer in terms of efficiency. reply fulafel 1 hour agorootparentAre there published case studies or other empirical evidence available with numbers about this?OS threads in Linux are fast and you can have a lot of them. Eg https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37621887 reply raspasov 1 hour agorootparentJust try starting ~100,000 threads that each sleeps for ~60 seconds in your JVM and check if you can succeed! :)``` (run! (fn [x] (future (Thread&#x2F;sleep 60000))) (range 100000)) ```(hint: likely not...)TLDR; Efficiency difference: you can think of virtual threads as being about 1,000 times (3 orders of magnitude) less expensive, in the general case. Exception: If you are only doing CPU-only work, regular threads will be better (that&#x27;s not how most web servers&#x2F;services operate).But if you&#x27;re waiting 100ms of ms for your database (or any network) to respond and you have many of those (blocking) method&#x2F;function calls in flight... virtual threads are the way to go in terms of efficiency.Great video explaining all of this (at timestamp, all 30 min is worth watching):17:05 Making threads less expensive: by how much? https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=5E0LU85EnTI&t=1025s reply weatherlight 16 hours agorootparentprevIs this sarcasm, or just generally true in the java community? reply bcrosby95 16 hours agorootparentI can&#x27;t think of a project I&#x27;ve worked on in the past 10 or so years that couldn&#x27;t benefit from virtual threads. Right-sizing your thread pools in an environment with a lot of IO is&#x2F;was a pain in the ass.Many of the core concurrency constructs in Clojure has separate functions for when you are doing something that is blocking vs not blocking. If it were all virtual threads this distinction generally wouldn&#x27;t matter. reply Alupis 16 hours agorootparentNot just that - the kicker is everything that already exists (libraries, JDBC drivers, etc) are now just automagically non-blocking too if you seed the thread pool with a virtual thread factory.I can&#x27;t remember the last time such a transparent, drop-in-able change was so impactful for just about everything.While it doesn&#x27;t remove the need for the event&#x2F;reactive&#x2F;async paradigm in all cases, it does removes the need for async code just for the sake of being non-blocking.Code can now be written much more clearly, and still be non-blocking. That&#x27;s huge. reply fulafel 16 hours agorootparentprevNeither for me (I&#x27;m in the Clojure camp), it just seems to me there aren&#x27;t many situations where you&#x27;d need millions of threads. Plus we&#x27;ve got core.async to reach for to multiplex many control flows on one OS thread - though I feel it&#x27;s more needed when targeting JS (ClojureScript) and the single-threaded world there. reply weatherlight 15 hours agorootparentI&#x27;m coming at this from a Erlang&#x2F;Elixir background , Where we basically have \"virtual threads\" but they aren&#x27;t at the OS level. It&#x27;s easy to use and making things concurrent (or parallel) is often trivial. Whether it&#x27;s 1 extra virtual thread or millions of virtual threads, the code (and the horizontal scaling of that code is the same) reply raspasov 3 hours agorootparentprevI love core.async (been using it since... 2014 I think... both Clojure and ClojureScript), and yes, core.async&#x2F;go basically was&#x2F;is solving (some) of the same problems. But there&#x27;s a number of gotchas around (go ...) blocks...Without being an expert on the core.async internals, I believe core.async can potentially benefit tremendously from this, by the virtue of being a powerful and super-elegant API for communicating between different parts of an application (typically within the same JVM process). Now it can continue to do that, while (likely) being free from most macro gotchas... replyvips7L 17 hours agorootparentprevAs pron always says.. that&#x27;s a risk of staying on an LTS release. You&#x27;re choosing to not receive updates. reply geodel 16 hours agorootparentIt seems to me by design or by indifference Java is now tired of JVM ecosystem languages at large who claim innovation by surface level changes while relying heavily on JVM bedrock.Now Java is moving fast and they are taking JVM compiler, runtime, class metadata etc along where Java, the language is headed. reply pjmlp 16 hours agorootparentNot only Java, that is the fate of all guest languages, as they don&#x27;t evolve alongside the platform, always require additional tooling and most language cultures than start making their own little islands of idiomatic libraries instead of directly using platform libraries.Since most platforms are leaky, one ends up needing to master two ecosystem in parallel, eventually it gets tiring and always cost extra in development.C++, Objective-C and Typescript get around this problem in UNIX and Web, as they are extensions of the platform languages, not something completely different. reply geodel 15 hours agorootparentYep agree with all you said. Nowadays new job every year people at work are scaring me with their enthusiasm to replace decades old solid Java applications which are performant and working fine with Kotlin and what not. reply Alupis 15 hours agorootparentI wouldn&#x27;t advocate for replacing&#x2F;re-writing old stuff - but you should try out Kotlin for backend work. It&#x27;s amazing.Java programmers will have only a small learning curve before feeling productive, and can gradually get more comfortable with idomatic Kotlin as they progress through their journey.Kotlin, as a language, was very well through out, letting you use as much or as little of it as you are comfortable with. reply vips7L 14 hours agorootparentFor me personally Kotlin does not bring that much to the table over a modern version of Java. Sure if you&#x27;re stuck in Java 8 it can be a win, but compared to Java 21 it just doesn&#x27;t bring enough to warrant the switch for me. reply usrusr 2 hours agorootparentInfinitely chainable expressions, .let, .also and friends. You shouldn&#x27;t overdo it (lengthwise) and it&#x27;s almost hilariously superficial, but I miss it in every other language since.Tying down a value to a name only if you have something meaningful to say in the name, and only when the value is actually finished instead of being a work in progress, that gives me great piece of mind and frees up mental resources for other things. I wish every language had a \"kotlinized\" sibling that simply added the scope functions on syntax level (or a subset of the scope functions, not sure you need a zoo that size) reply AgentME 10 hours agorootparentprevHonestly the main thing I find killer about Kotlin over Java is its stricter null safety (types do not permit null values unless you mark the type as nullable with a \"?\" suffix). (I know Java does have the @Nonnull annotation but it&#x27;s extremely verbose to use much and Java doesn&#x27;t enforce its use on values that are expected to be non-null, which both greatly diminish its usefulness.) I&#x27;ve been spoiled by languages like Typescript and Rust which have great null safety like Kotlin, and it&#x27;s very annoying going back to a language without it and questioning whether a null is expected or possible for every single value. reply unlikelytomato 7 hours agorootparentI wish I could get a strong sense of the hype around null safety. Sure, I would like to have the extra expressive option. However, optional has been fine for me. I still barely use it. It has to be at least 3-4 years since I last encountered a null pointer exception in my daily java programming. I feel like there are plenty of other things that pain me on a daily basis that rank far higher on my asks for the language. Collection and stream ergonomics cause constant pain, for example. reply skwirl 14 hours agorootparentprevI’ve seen this sentiment a lot and I don’t understand it. I actually feel like very little has been added between Java 8 and Java 21. Virtual threads is probably the biggest thing, and it looks very promising, but the language itself is still a chore to use, and Kotlin does a good job at cleaning a lot of that up.I think Kotlin is at risk, though, of having the JVM force them to support two competing models to accomplish the same thing - coroutines and virtual threads is a good example (although Java still doesn’t have language level structured concurrency). This could really make things messy. reply koreth1 10 hours agorootparent> I think Kotlin is at risk, though, of having the JVM force them to support two competing models to accomplish the same thing - coroutines and virtual threads is a good exampleI don&#x27;t think it&#x27;s that good an example, though there&#x27;s some merit to it. Kotlin coroutines, to me, target three main use cases:1. An abstraction over an underlying threading model. Get threaded execution without having to explicitly deal with thread pools and such. I&#x27;d consider structured concurrency to be part of this use case.2. A way to write non-blocking code that is structured as if it were blocking. (Incidentally: I love Kotlin&#x27;s decision to make \"await\" opt-out instead of opt-in.)3. A way to write code that generates sequences of values without having to either write an explicit class that maintains state across calls or use callbacks&#x2F;CPS. Or in other words, a way to use the \"yield\" function.Use case 1 still makes sense with virtual threads. Run your coroutines on an executor that uses a virtual thread pool instead of a platform thread pool. If you prefer the coroutines API, you can still use it for structured concurrency and such.Use case 2 is much less interesting in the presence of virtual threads; you can just write blocking code directly, no need for the language to turn it into async code for you.Use case 3 has nothing to do with threads to begin with, so it remains exactly as valuable as before and there&#x27;s no reason to change any existing code at all.Do coroutines get less useful in the presence of virtual threads? Absolutely. But they aren&#x27;t competing with virtual threads; there are substantial non-overlapping use cases that make them a worthwhile language feature. reply vips7L 14 hours agorootparentprev> I’ve seen this sentiment a lot and I don’t understand it.I just don&#x27;t think any feature of the language of Kotlin is that much better than Java&#x27;s implementation. I&#x27;m also a big supporter of brevity != clarity when it comes to code.What language feature in Kotlin do you think is that much better? reply Alupis 12 hours agorootparentI was you not that long ago. I&#x27;ve had the same conversation with a lot of other Java developers too - they&#x2F;we always say the same things.It&#x27;s weird being on the other side of the fence now - hearing the same things I used to say.Kotlin was a gateway drug out of not just Java, but OO&#x2F;Solid and into FP for me (FP being another thing I used to not \"get\"). The beauty of Kotlin is you don&#x27;t have to ever write FP code if you don&#x27;t want to - but you will want to before too long.I would recommend trying it out for yourself. It&#x27;s Spring integration is amazing, and you&#x27;ll have a great time. Write even a little Kotlin and you&#x27;ll have an \"ah ha!\" moment and everything will forever be different.It&#x27;s one of those things where you need to experience it for yourself before you actually understand how great it is. There is no argument you will hear that will convince you, sadly. I was the same once... reply kaba0 3 hours agorootparentYou can do many FP things in Java as well, as it is a multi-paradigm language, hell, Kotlin is not even particularly functional-y. reply bcrosby95 10 hours agorootparentprevTo me Kotlin is different enough to be annoying to learn, but not different enough to matter that I use it over Java. So it just kinda feels like a waste of time. reply sitta 12 hours agorootparentprev> I actually feel like very little has been added between Java 8 and Java 21.var, records, sealed types, and pattern matching make a huge difference in how Java is written. A lot has changed since 8. reply Alupis 11 hours agorootparentThe issue with these new structures is they&#x27;re necessarily clunky, to maintain interoperability with non-modern Java. Java&#x27;s backwards compatibility is legendary, but is also why some of it&#x27;s newer features are often criticized as not being as good as they could be. reply sitta 10 hours agorootparentIt&#x27;s one thing to say, \"very little has been added between Java 8 and Java 21,\" and something else entirely to say, \"newer features are often criticized as not being as good as they could be [to maintain backwards compatibility].\" reply kaba0 3 hours agorootparentprevI don’t think any of then is clunky - hell, pattern matching is straight better in java. replyjcadam 15 hours agorootparentprevKotlin is the closest thing to a \"better Java\" that I&#x27;ve found. I&#x27;ve used it with Spring Boot and the interoperability with Java is fantastic. A Java dev would have no problem picking it up quickly (as opposed to Clojure and even Scala).I say this as a Clojure fan, there are many instances where I&#x27;d probably choose Kotlin nowadays. You can also mix JVM languages within the same application; I&#x27;ve found it rather useful to sprinkle some Clojure into a Java&#x2F;Spring application for certain tasks. Maven and Gradle both have tooling to handle it :) reply Alupis 15 hours agorootparentIf you&#x27;re into FP stuff, using Arrow within Kotlin takes you to that next level. It even works with Spring&#x2F;Boot. reply bafe 14 hours agorootparentprevCouldn&#x27;t agree more! It&#x27;s particularly disappointing when you need to work on an older java codebase after finishing a Kotlin project. You&#x27;ll constantly miss features reply ahoka 14 hours agorootparentprevEven C# seems like something stuck in the 1990s compared to Kotlin. (I know it’s not a high bar). reply pjmlp 14 hours agorootparentNot kept up with the times in regards to C# 12 features? reply Alupis 11 hours agorootparentC#&#x27;s problem is it&#x27;s quickly becoming C++ in that it doesn&#x27;t just have the kitchen sink, it has three kitchen sinks...Unlike C++ though, one day the powers that be will just remove features as part of yet-another framework rewrite and you&#x27;ll just have to deal with it.The other issue is just how tightly coupled C# as a language is to the .NET framework&#x2F;platform. Some of the things people like C# for are actually framework things and they don&#x27;t realize it because that separation isn&#x27;t as clear as with Java and say, JavaEE or Spring or $X.If you talk to a C# developer - of course they&#x27;re using .NET and of course they&#x27;re using Entity Framework - to them, there&#x27;s no other way. It&#x27;s inconceivable that any other library or framework might do it better than Microsoft&#x27;s official offering... and then you&#x27;ll find the official offering to be lacking in fundamental ways.Talk with a Java developer and you&#x27;ll find there&#x27;s a lot more diversity of frameworks and libraries being used - so there&#x27;s a lot more differing opinions on priorities and a lot more good ideas being tried out or implemented everywhere. The communities are vastly different in that regard. reply Rapzid 5 hours agorootparentprevCollection literals are going to be fantastic. Many don&#x27;t know that there is actually momentum to keep moving right into Dictionary literals.There is a \"roles\" proposal and investigation team. This roles proposal is going to unlock so much potential it is bonkers. reply ahoka 3 hours agorootparentprevWhat do you think I’m missing that makes C# 12 not a-lot-of-lipstick-on-a-java-pig? reply pjmlp 15 hours agorootparentprevIt is still another syntax, with idioms moving away from JVM, their own little islands of Kontlin only libraries, and only works on InteliJ&#x2F;Android Studio.I don&#x27;t see any value in Kotlin outside Android shops. reply pianoben 11 hours agorootparentI&#x27;ve worked in several JVM backend projects, and Kotlin has been a stark improvement over Java (at least up through version 17, the most recent with which I&#x27;ve worked directly). Compose, and Compose UI, are tremendously promising technologies; I&#x27;ve shipped desktop apps with Kotlin for multiple platforms, and compared to just about every other desktop UI framework, it&#x27;s a clear winner in terms of productivity and an ability to GSD.All that to say, I believe that Kotlin has a lot of value, independently of Android. reply jcadam 15 hours agorootparentprev> I don&#x27;t see any value in Kotlin outside Android shops.Developer experience is important to some people - not just devs, but those who seek to recruit and retain good ones.Of course, if you&#x27;re looking to hire massive numbers of butts-in-seats (gov work, large enterprise shops, etc) I suppose Java is probably the ideal choice. reply Alupis 15 hours agorootparentprevWhile true it has it&#x27;s own syntax, the syntax is better than Java and more ergonomic. With that said, you can write Java in Kotlin - and by that I mean Kotlin code that looks almost exactly like Java. Heck, you can have .java and .kt source within the same project all mixed together if you want.Kotlin libraries are interoperable with Java and vice versa. In some specific cases, a Kotlin library needs a little syntactic sugar to make it work with Java like a Java developer would expect, but it&#x27;s easy to do. Going the other direction though - Java library used in Kotlin, zero issues, it just works. Some Java developers don&#x27;t even realize they&#x27;re already using Kotlin - take a look at OKHttp and friends...Lastly, there&#x27;s Kotlin support is all major IDE&#x27;s, including IntelliJ of course, but also Eclipse and likely whatever editor&#x2F;ide you prefer. Kotlin is basically just a bunch of libs.I would argue Kotlin is better outside of Android than in Android. For backend work, particularly when coupled with Spring&#x2F;Boot, it&#x27;s freaking amazing. The Spring team has put in an impressive amount of work to make Kotlin a first-class language within the ecosystem, and it really shows. reply pjmlp 14 hours agorootparentTry to call Kotlin co-routines from Java.Telling me there is Kotlin support in Eclipse only tells me you never actually tried it, specially after JetBrains ramped down the team that was doing the now stale plugin. reply Alupis 14 hours agorootparentYou should look harder before saying it doesn&#x27;t work. Updated 10&#x2F;6&#x2F;2023[1]Coroutines are a specific paradigm within Kotlin, and should not be in library code anyway. With the addition of JVM Virtual Threads, the need for Coroutines is significantly diminished anyway.It&#x27;s anecdata, yes, but I&#x27;ve written a lot of Kotlin code and do not use coroutines. Kotlin really just lets you do what you want - as much or as little idomatic code as you need.Kotlin on the backend is amazing. You really should give it a try. Java sucks badly, in comparison (I say that as a former Java nerd...)[1] https:&#x2F;&#x2F;marketplace.eclipse.org&#x2F;content&#x2F;kotlin-plugin-eclips... reply pjmlp 14 hours agorootparentAnd you should read before posting random links, After installation of the Kotlin plugin the Java plugin is not running anymore. I cannot open a Java project anymore. The log file says: !MESSAGE org&#x2F;eclipse&#x2F;jdt&#x2F;internal&#x2F;ui&#x2F;refactoring&#x2F;actions&#x2F;RenameJavaElementAction$AjcClosure1 !STACK 0 java.lang.NoClassDefFoundError: org&#x2F;eclipse&#x2F;jdt&#x2F;internal&#x2F;ui&#x2F;refactoring&#x2F;actions&#x2F;RenameJavaElementAction$AjcClosure1 at org.eclipse.jdt.ui.actions.RenameAction.(RenameAction.java:60) at org.eclipse.jdt.ui.actions.RefactorActionGroup.(RefactorActionGroup.java:372) at org.eclipse.jdt.ui.actions.RefactorActionGroup.(RefactorActionGroup.java:206) at org.eclipse.jdt.internal.ui.packageview.PackageExplorerActionGroup.(PackageExplorerActionGroup.java:139) at ... reply Alupis 14 hours agorootparentYou copy&#x2F;pasted an error some random person on the internet had in June due to using an incompatible Eclipse & plugin versions?The beauty of Eclipse is the ecosystem. If that official Jetbrains plugin doesn&#x27;t do it for you for some reason, then use another one[1].[1] https:&#x2F;&#x2F;marketplace.eclipse.org&#x2F;content&#x2F;enhanced-kotlin-ecli... replyTainnor 15 hours agorootparentprev\"Only works on IntelliJ\" is patently false. Stop spreading FUD. reply pjmlp 14 hours agorootparentWhere is Kotlin support for Eclipse and Netbeans?Prove me wrong. reply Alupis 14 hours agorootparentDo you use Eclipse? Have you looked at the available plugins?There&#x27;s nothing special about Kotlin. It&#x27;s a bunch of libraries for runtime and compile time... like anything else you use. reply pjmlp 14 hours agorootparentIt is my main Java IDE.There is a difference between supporting a language with a Notepad++ like experience, and what JetBrains was doing before ramping down the Eclipse plugin team, as means to sell more InteliJ licenses instead. reply Alupis 14 hours agorootparentWhat do you believe you are missing?It compiles fine with Maven or Gradle, it provides auto-prompt&#x2F;complete&#x2F;hints. It just works. reply pjmlp 14 hours agorootparentSame experience as in InteliJ, which JetBrains no longer provides.And above all, no crashes left and right. reply Alupis 14 hours agorootparentI&#x27;ll ask again more clearly - what is the \"same experience\" you are missing?Kotlin is plugins for Maven&#x2F;Gradle, and classpath libraries. There is no magic going on here... replypeterashford 1 hour agorootparentprevI did a year of Kotlin in a recent job. I liked it, but not enough to prefer it over Java - especially with the recent updates to Java. YMMV reply never_inline 15 hours agorootparentprevThat&#x27;s an interesting hypothesis. Is that applicable to platforms other than programming languages? reply Tainnor 15 hours agorootparentprevAnd many developers are tired of Java making minuscule improvements to developer ergonomics while pretending to be progressing, when even now, it doesn&#x27;t have features that other languages have had for 30 years. reply kaba0 14 hours agorootparentBased on pure statists about the number of important, business critical java-applications that run most of the internet, it seems like it just straight doesn’t matter in any significant way. reply Tainnor 14 hours agorootparentMaybe it doesn&#x27;t matter to you, but it does matter to me.All the power to people who enjoy working in Java, but that doesn&#x27;t have to make me like it. replytheanonymousone 16 hours agoprev [–] Still waiting for VS Code to support Java 21. Java is not the language to use without an IDE. reply matsemann 15 hours agoparentI can&#x27;t imagine doing Java in VS Code instead of Intellij. Is there something I&#x27;m missing out on? reply jcadam 15 hours agorootparentNo idea. I use IntelliJ for Java&#x2F;Kotlin and emacs for everything else (Clojure, Python, JS, etc). I still encounter the occasional lunatic who uses eclipse or netbeans.I know VSCode is the \"standard\" editor for front-end devs, and so I assume some of them are trying to keep their code editor when moving into backend work. I have to believe it&#x27;s not as good - for a time I really, really tried to make emacs work for Java development, but it just.... doesn&#x27;t :) reply theanonymousone 14 hours agorootparentThe reason I use VSCode is Code Server[0]. It is certainly not as powerful as IntelliJ, but the I have to get used to it because the web-based IDE is a must for me.By the way, unless my English is terribly bad, calling someone lunatic for their choice of IDE may not be a great idea.[0] https:&#x2F;&#x2F;github.com&#x2F;coder&#x2F;code-server reply deepsun 4 hours agorootparentSame for IntelliJ: JetBrains SpaceBut it also supports Gitpod, Google Cloud, GitHub Codespaces, Amazon CodeCatalyst, and Connect to Coder [0]There&#x27;s also Dev Container, that gives all the developers the same dev environment as a container.https:&#x2F;&#x2F;www.jetbrains.com&#x2F;help&#x2F;idea&#x2F;remote-development-a.htm... reply theanonymousone 1 hour agorootparentDoesn&#x27;t it require you to have JetBrains locally installed on your machine to be able to connect? reply smlavine 8 hours agorootparentprevIt&#x27;s a hyperbole that no reasonable person would get offended by.So nobody except Emacs users. ;) reply BinaryRage 8 hours agorootparentLunatics all. reply ilikehurdles 14 hours agorootparentprevLunatic meaning maniac or fool. reply jcadam 13 hours agorootparentprevI was being facetious, of course :) reply Phelinofist 13 hours agorootparentprevAt my job a lot of people hate on Eclipse, but honestly I find it quite nice. I use IntelliJ for my private projects and think both are on par. reply BeefWellington 3 hours agorootparentBase vs Base installations, Intellij is better. Ergonomically, I find Intellij better.However, my experience with it has been that once you get every plugin you need loaded it becomes dog slow and even basic stuff like reference jumping becomes a slow, tedious slog compared to Eclipse. reply watwut 1 hour agorootparentprevYeah, I used both Eclipse and Intellij and Eclipse is actually good IDE. Both have advantages and disadvantages, but I can not say that Intellij is better.The most hate for Eclipse, in my job, comes from people who never used it. They basically dislike how it looks like and that it is not exactly same as Intellij. reply zmmmmm 13 hours agorootparentprevfellow eclipse die hard here ...It&#x27;s definitely a very complex beast but once you do master that complexity it is such a power tool. Even though I routinely do work in IntelliJ I miss various things enough from Eclipse that I always go back.I just wish it had proper Kotlin support. reply bafe 14 hours agorootparentprevHow&#x27;s the Kotlin language server performance for you? When I last tried it was using up so much resources for the simplest Kotlin file. I gave up and moved to intelliJ (which incidentally offers plenty of refactoring features you don&#x27;t get in vscode) reply mey 11 hours agorootparentKotlin is horrible in every IDE other than IntelliJ&#x2F;AndroidStudio and JetBrains has little motivation to fix that. reply bafe 50 minutes agorootparentThat was my feeling too. Kotlin in Vscode was not usable. My computer ground to an halt as soon as I typed something reply delecti 10 hours agorootparentprevIntellij does a lot, and VS Code is very light. Some people prefer an IDE that does a lot, but some don&#x27;t care and benefit from VSC being lightweight. Also, some projects are janky, and VS Code is easier to get to ignore that jank. Plus, I find VS Code&#x27;s hotkeys to be much more intuitive as a long-time Windows user and hotkey addict.No matter what I do locally, the final word is a pipeline build. A command line is closer to that than either IDE, so at times I&#x27;ve really appreciated VS Code mostly getting out of my way. reply theanonymousone 59 minutes agorootparentExactly. Being lightweight is important when you are running the thing on some cheap VPS. Also the multi-lunguality, since you don&#x27;t have \"room\" for multiple IDEs. reply kaba0 2 hours agorootparentprev> VSC - lightweightAre we talking about the same thing? reply specialist 14 hours agorootparentprevThough I prefer IntelliJ, VS Code is fine.I sometimes switch to VS Code just to use Lischke&#x27;s terrific ANTLR plugin.https:&#x2F;&#x2F;marketplace.visualstudio.com&#x2F;items?itemName=mike-lis... reply jgon 16 hours agoparentprevBrian Goetz just gave a talk about all the stuff that&#x27;s been delivered up to Java 21 that announced they&#x27;d be rolling out a fully supported VS Code plugin for Java that should be better than the current language support. It should be out within the next week or two.Timestamp for the announcement: https:&#x2F;&#x2F;youtu.be&#x2F;eXCx2hW_xNI?t=1955 reply vips7L 15 hours agoparentprevThings take time. If you want you can contribute resources to the vs code plugin and the eclipse language server. reply avodonosov 15 hours agoparentprev [–] What in the java language makes you think it is less suitable to be used without an IDE than other languages? reply jillesvangurp 11 hours agorootparentThe fact that IDEs are just unusually smart specifically for that languages relative to relatively dumb editors like vs code, which lack most of the conveniences in the form of auto complete, a wide variety of refactorings, auto fixes, etc. Opting out of all that is not something a lot of people do. Botttom line, you are missing out on so many good tools by not using a proper IDE with Java that it&#x27;s borderline negligent to opt out of that. It&#x27;s negligent because you start opting into preventable issues (formatting, warnings, common bug patterns, dead code, etc.) and generally end up wasting a lot of time fixing things manually that you shouldn&#x27;t have to deal with because your IDE should be doing those things. For example imports are not a thing I ever type manually. Not a thing. Most warnings are addressed with a simple alt+enter, which will typically suggest a usable fix. With and IDE you see those warnings and can act on them.Kotlin has the same advantage and is developed by Jetbrains who also develop intellij and of course know what they are doing on this front. Support for other languages in intellij is also nice but typically a lot more limited than the support for Java and Kotlin. E.g. pycharm is alright for python but not that much different from what you get in vs code. You get a handful of refactorings and that&#x27;s about it. Dynamically typed languages are just a lot harder to support with proper tools. Too much uncertainty about what does what or even what types things are. reply avodonosov 4 hours agorootparentYou describe the great advantage IDE gives. My point though is that without IDE java is basically as good as most other languages without IDE.I&#x27;ve spent years coding in java daily, most of the time in IntelliJ of course. But there was a time when I had to use for a project a very modest editor, with just basic syntax highlighting. After several days you get used to it and it does not bother you. reply jillesvangurp 3 hours agorootparentWhich would put you at a disadvantage relative to other Java programmers. In many teams, that would not be tolerated if you then start committing code with obvious issues related to your poor tooling choices. reply theanonymousone 55 minutes agorootparentprevMy other language of heavy use is Python. Maybe not writing a Python script from scratch, but at least I can modify a Python script in some basic editor (e.g. GitHub web UI). The same thing will be more difficult in Java.I cannot judge about Rust and C++ which are mentioned here. I also write some Scala and it is not far from Java in that manner. reply paulddraper 15 hours agorootparentprevIt&#x27;s verbose to write and read.You need an assist for both. reply palata 12 hours agorootparent> You need an assist for both.I don&#x27;t. Do you? reply collinvandyck76 11 hours agorootparentObviously GP think it&#x27;s helpful? Just because you&#x27;re in the minority that doesn&#x27;t need IDE or LSP assist writing Java, I think that most people would argue that assist for Java is beneficial even if you personally don&#x27;t need it and there&#x27;s no sense in flexing about it.I personally always use IDE&#x2F;LSP for Java, even though it&#x27;s been many years since I&#x27;ve written it, because it helps me deliver business value faster. reply avodonosov 3 hours agorootparentWe are comparing java with other languages here, not questioning advantages of IDE.Why people think java without IDE is different than some other language without IDE.Is java more verbose than, for example, C++? reply palata 3 hours agorootparentExactly this. Who develops in Swift, Kotlin or Rust without ever using an IDE nowadays? reply paulddraper 3 hours agorootparentprevI do.Or at least, it&#x27;s a big, big improvement. reply palata 3 hours agorootparentAnd it is not for other languages? What makes Java special here? reply matsemann 15 hours agorootparentprevIt used to be lots of boilerplate. LikeMyClassType myClassType = new MyClassType()And then it was nice to use an IDE to help write some of that. Or generate java beans etc.But with that said, I don&#x27;t think it&#x27;s much you need an IDE for, it&#x27;s more that java enables IDEs to do much more than it can for certain other languages. reply palata 12 hours agorootparentThat&#x27;s a thing I don&#x27;t get. Maybe I am doing something completely wrong, but the vast majority of my time as a developer, I am not typing code. I can afford 5s typing `MyClass myClass = new MyClass()`. reply vips7L 14 hours agorootparentprevYou haven&#x27;t had to declare the type since Java 10. var myThing = new MyThing(); reply matsemann 14 hours agorootparentYup, hence \"used to\", but I could be clearer it&#x27;s no longer an issue. reply riku_iki 5 hours agorootparentprevstill need it for class members, unlike in some other languages. reply kaba0 2 hours agorootparentMost languages don’t do type inference in “signatures” (function, but also class&#x2F;struct members), as it would give you negligible benefit, a huge cost for the compiler and is commonly thought of as a bad practice.Out of Scala, Rust, I believe even Kotlin, none do inference in these places. Even Haskell, which does infer function signatures as well, need explicit type annotation for `data` definitions. reply riku_iki 2 hours agorootparenttypescript does such inference.I disagree with you about huge cost for the compiler and benefits are the same as in normal code block: reducing boilerplate. reply kaba0 2 hours agorootparentTypescript’s type system is deliberately not sound though.In general, there is no type inference available for OOP type-hierarchies as opposed to a more Haskell-like type system, where Hindley-Milner works replylern_too_spel 11 hours agorootparentprev [–] Class-level imports and lots of classes. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The newest edition of Clojure Deref announces the release of Java 21, highlighting its effects on virtual threads and problems concerning object monitors during I/O blocking.",
      "The issue explores various solutions like the use of ReentrantLocks to resolve conflicts between object monitors and virtual threads.",
      "The issue details ongoing work on functional interface adapters, method thunks, refinements in implicit coercion and conversion, and the introduction of a new array class syntax."
    ],
    "commentSummary": [
      "The article focuses on the differences between Java 21 VirtualThreads and Clojure Lazy Seqs, touching upon the issue of temporary synchronization pinning in Clojure and the potential fix using GraalVM native images.",
      "It suggests the use of virtual threads in Java as a niche but potentially efficient solution for high-traffic applications, and reviews the pros and cons of utilizing Clojure, ClojureScript, Kotlin, and Java in software development.",
      "It includes a comparison of Kotlin compatibility and support across different Integrated Development Environments (IDEs) like Eclipse, IntelliJ, and VS Code, and prompts a discussion on the relevance of IDEs for languages such as Java."
    ],
    "points": 191,
    "commentCount": 110,
    "retryCount": 0,
    "time": 1696607053
  },
  {
    "id": 37790174,
    "title": "Thirty Years Ago: MS-DOS 6.00",
    "originLink": "https://www.pcjs.org/blog/2023/10/04/",
    "originBody": "PCjs Machines Home of the original IBM PC emulator for browsers. AboutBlogRepositoryTools PCjs Blog Thirty Years Ago: MS-DOS 6.00, DoubleSpace, and MultiConfig Over 30 years ago, in March 1993, Microsoft released MS-DOS 6.00, the next major release of MS-DOS after 5.00 shipped in June 1991. In addition to several new full-screen utilities, like DEFRAG to defragment your hard disk (licensed from Symantec), MSBACKUP to efficiently backup your hard disk (also licensed from Symantec), and MSAV to check for viruses (licensed from Central Point Software), there were a number of new command-line programs, such as CHOICE, DELTREE, MOVE, MSCDEX, and SMARTDRV. But the biggest addition to MS-DOS 6.00 was a new feature called DoubleSpace (dubbed “MagicDrive” internally) that automatically compressed everything on your hard disk, providing up to “double” the amount of effective disk space – or more, or less, depending on how compressible your files were overall. DoubleSpace was a significant feature that required changes across the entire system. Most of the action, however, took place inside a new device driver, DBLSPACE.BIN, that stored all your data in a Compressed Volume File (CVF) generally named DBLSPACE.000. In fact, if you booted an older version of MS-DOS (like 5.00), you wouldn’t see much more than that: A>DIR C: /A Volume in drive C is HOST_FOR_C Volume Serial Number is 5739-B1B5 Directory of C:\\ IO SYS 40470 03-10-93 6:00a MSDOS SYS 38138 03-10-93 6:00a DBLSPACE BIN 51214 03-10-93 6:00a DBLSPACE INI 91 10-03-23 12:26p DBLSPACE 000 131474432 10-03-23 12:26p 5 file(s) 131604345 bytes 2605056 bytes free When MS-DOS 6.00 starts up, it reads DBLSPACE.INI, which usually looks something like this: MaxRemovableDrives=2 FirstDrive=D LastDrive=H MaxFileFragments=115 ActivateDrive=H,C0 and tells the operating system to mount the real drive C: as drive H: instead, and to mount the CVF as drive C: C:\\>DIR /C Volume in drive C is MS-DOS_6 Volume Serial Number is 101B-323E Directory of C:\\ DOS09-25-23 10:13p COMMAND COM 52925 03-10-93 6:00a 1.4 to 1.0 WINA20 386 9349 03-10-93 6:00a 5.3 to 1.0 AUTOEXEC BAT 75 09-26-23 8:55a 16.0 to 1.0 CONFIG SYS 109 09-26-23 8:55a 16.0 to 1.0 2.0 to 1.0 average compression ratio 5 file(s) 62458 bytes 253927424 bytes free So our original hard disk, a 128Mb drive, now appears to be almost twice as large – thanks to DoubleSpace. Aside from the new DBLSPACE.BIN driver, the other main piece of DoubleSpace functionality resided in DBLSPACE.EXE, which operated as both a setup and a maintenance program. It provided a friendly UI, making it easy to create additional CVFs, as well as resize, defragment, reformat, unmount, remount, and more. Feel free to tinker with MS-DOS 6.00 on the website: Microsoft MS-DOS 6.00 (Installed) Microsoft MS-DOS 6.00 (Installed and Compressed) Legal Woes Microsoft bootstrapped its compression efforts by licensing code from Vertisoft, makers of DoubleDisk, a disk compression product first released in 1989. Starting with Verisoft’s code, Microsoft created DBLSPACE.BIN, along with operating system changes that allowed it to be loaded before CONFIG.SYS was processed – so that CONFIG.SYS and any system files loaded from that point forward could be inside the compressed volume instead of outside it. Vertisoft was not directly involved with any of that work, but they did help produce other pieces of functionality, such as code to convert Stacker and SuperStor compressed disks to DoubleSpace – although apparently Stacker conversion was pulled at the last minute, in February 1993, just as MS-DOS 6.00 was being finalized. Or rather, February 1993 would have been “last minute”, until the lawsuit filed by Stac in January 1993 forced Microsoft to re-evaluate. Stac claimed that the DoubleSpace infringed two of Stac’s patents: 5,016,009 and 4,701,745. For me, life quickly changed on February 13, 1993, when I received this email: From: Paul Maritz Sent: Saturday, February 13, 1993 12:06 PM To: Jeff Parsons; Mark Zbikowski Cc: Ben Slivka; Brad Chase; Brad Silverberg; Jim Allchin; John Mason; Nathan Myhrvold; Rick Rashid Subject: special duty You are both amongst the best x86 assembly language coders that we have at MS. We are thus asking you to help out with a very serious problem that we face - namely the STAC / DOS6 lawsuit. Our lawyers have recommended that we have a backup compression mechanism for DOS6 ready to go as soon as possible. The initial work on this has been done under Rick Rashid in Nathanm's area. They have a C language implementation of a technique that we believe is safe (covered under patents that we have rights to). The challenge is to get this technique into the tightest possible x86 assembly code, as soon as possible. This is where we are asking you to help. Jimall and Bradsi are aware that you will be \"stolen\" for some weeks. Could you both meet with Rick Rashid as early as possible on Monday to get this effort under way as soon as is possible. Thanks. The next several weeks were probably some of the most stressful that I’d experienced at Microsoft. Looking back, it’s amazing to me that with all the critical-path code that was being rewritten at that late date, MS-DOS 6.00 still shipped the following month, in March 1993. I don’t recall all the details of the alleged patent infringement, and I’m not sure I ever knew all the details, because frankly, it wasn’t necessary for me to know the details. A number of other people had already been working on the problem and had come up with several solutions, and it simply fell to me and MarkZ to implement them in x86 assembly – preferably very fast, bug-free assembly, of course. As far as I can tell now, Stac patent 5,016,009 was the crux of the problem. It combined LZ77 compression with hashing, and while LZ77 compression was fine, and hashing was fine, apparently the combination of the two became a patentable innovation. So we were initially tasked with writing a compressor based on Miller-Wegman, an algorithm that was either not patented or that Microsoft owned or licensed. When that turned out to be too slow, we instead built a compressor (internally known as XCFR or the “Rashid Search Algorithm”) that avoided hashing by using a 256x8 look-up table along with a 256-entry LRU table, and also incorporated a new Microsoft Realtime Compression Format (MRCF) for outputting the raw bytes and offset-length pairs. That, of course, meant that the decompressor had to be rewritten as well. With hindsight, it’s probably safe to say that Microsoft should not have shipped MS-DOS 6.00 quite so quickly after that rewrite, because unfortunately, our code (well, in the case below, my code) was not, um, bug-free: From: Chuck Strouss To: SYS Astro Team Development Group; Peter Stewart; Jeff Parsons Subject: Bug in DBLSPACE decompress Date: Monday, June 14, 1993 3:40PM In RDCOMP.ASM, near the first JC instruction, there is a bug when a block ends at 10000h and the last several bytes are in a repeat string. It was reported by Temporal Acuity Products. to which I replied: From: Jeff Parsons Sent: Monday, June 14, 1993 4:49 PM To: Chuck Strouss; Ben Slivka; Jim Mathews; Peter Stewart Subject: RE: Bug in DBLSPACE decompress well... shit! This bug was only in the 80386 code path, but that wasn’t much consolation. And it was one of at least a half-dozen or so DoubleSpace bugs that Microsoft was aware by June of 1993. Other bugs included: A particular series of reads, writes, and undeletes may cause an undelete to fail (FAT is marked USED, but MDFAT is left marked FREE; note that MDFAT refers to the “MagicDrive” FAT internal to the CVF) A particular series of operations followed by undelete may cause a cross link (not taking into account data that may be in buffers) Read into video memory in planar VGA modes results in garbage display (decompression depends on being able to read previously decompressed data, but VGA memory in these video modes does not read back what was written to it) If a disk error occurs while updating a cluster, a cross link may be created (error would be on writing to a part of the sector heap that we had not used previously) When Metro Software’s LaserTwin 5.0 TSR is loaded, it intercepts write operations and breaks them up into smaller writes; however, sometimes those smaller writes can end up being ZERO bytes long, which DOS correctly treats as a truncate operation. If that happens when the system is writing to the DoubleSpace CVF, the compressed volume will be truncated (not really a DoubleSpace bug, but a bug with severe consequences) I don’t know if the video memory bug was ever fixed. Wikipedia’s article on DriveSpace (which was the new name for DoubleSpace as of MS-DOS 6.22) alludes to the problem: A few computer programs, particularly games, were incompatible with DoubleSpace because they effectively bypassed the DoubleSpace driver. But I’m not aware of any problems with games that involved “bypassing” the driver. Any game-related problems were almost certainly due to DoubleSpace decompressing data directly into video memory while the video card’s write and read modes differed. Introducing MultiConfig On a happier, or at least less contentious note, MS-DOS 6.00 also introduced a feature known as MultiConfig, which I have some fondness for, because it was something I personally championed and implemented. And – good news – I don’t think it had any serious bugs. I don’t recall precisely where the idea came from. I think it started as something that I and Naveen Jain, a Program Manager on the team, discussed in early 1992. He created a preliminary spec in February 1992, and then I implemented the feature in March 1992 and updated the spec to match what I had implemented. The code was originally added to Jaguar, which was planned to be the next major update to MS-DOS after 5.00. But at some point, Astro – originally intended as a smaller interim MS-DOS update – grew to the point where it was clearly going to be the next major update, thanks in large part to the addition of DoubleSpace disk compression. When it was clear that Astro would become MS-DOS 6.00, I think management went looking for other low-hanging fruit, such as any new Jaguar features that could be incorporated into Astro relatively easily with minimal risk. MultiConfig fit the bill. However, it wasn’t a slam dunk. I had to push for it, because there were a few risk-averse people in management that felt the risk/reward ratio was too high. They claimed that most users would not use this feature (which was true), but that point also worked in my favor: most of the new code would not be executed until and unless someone actually added one or more of the new commands to their CONFIG.SYS. So any risks largely affected only “power users”. What is MultiConfig? MultiConfig was a collection of features added to the processing of CONFIG.SYS, to make it easier to start your PC in a particular way without having to boot from a special floppy or edit/copy a new CONFIG.SYS each time. It added some new commands to CONFIG.SYS: INCLUDE MENUCOLOR MENUDEFAULT MENUITEM NUMLOCK SET SUBMENU and it included some new ways to interact with CONFIG.SYS. The message “Starting MS-DOS…” was added as an indirect means of alerting you that you now had two seconds to press one of several new start-up keys: F5: Bypass CONFIG.SYS and AUTOEXEC.BAT F8: Interactively step through CONFIG.SYS You could also tap a Shift key – that was equivalent to pressing F5. Apparently there was an Astro “press tour” in August 1992, and someone in that tour suggested adding the Shift key, so we did. They claimed that holding the Shift key while starting Windows also bypassed certain files and/or functions, but I don’t recall to what extent that was true. Additionally, if you didn’t want anyone using your machine to bypass or alter CONFIG.SYS, you could add these lines to the file: SWITCHES=/N: disable all start-up keys SWITCHES=/F: eliminate the two-second pause /N also implied /F, since if start-up keys were disabled, there was no need to wait two seconds. Note that SWITCHES was not a new command; other older “switches” included: /K: Forces an enhanced keyboard to behave like a conventional keyboard (DOS 4.0+) /T: Indicates the BIOS time rollover byte is a flag instead of a counter (DOS 5.0+) /W: Specifies that the WINA20.386 file has been moved to a directory other than the root directory (DOS 5.0+) Finally, while we’re on the subject of the keyboard-related features, I should add that NUMLOCK wasn’t really a MultiConfig feature; it was just something I thought would be handy. Recall that early PCs had no BIOS setup screens, and MS-DOS was still an operating system designed to run on any PC, including the original IBM PC. So this CONFIG.SYS command: NUMLOCK=[ON|OFF] could be used to set your keyboard’s initial Num-Lock state. A case could be made for this being a legitimate MultiConfig feature though, since you could select menu items with arrow keys or by pressing the number of a menu item. So if you wanted to use your numeric keypad, then you would want to ensure that Num-Lock matched your preferred selection method. With Great Power Comes… Menus The real power of MultiConfig was the ability to create user-friendly boot menus and let you organize sets of CONFIG.SYS commands into either named or [common] blocks. Blocks began with a bracketed block name (eg, [menu], [common], [doslow]) and ended at the next bracketed block name (or end of file). Here’s a simple example: [menu] menuitem=doslow,Load DOS in LOW memory menuitem=doshigh,Load DOS in HIGH memory menudefault=doslow,15 menucolor=15,1 [common] device=c:\\dos\\himem.sys [doslow] dos=low [doshigh] dos=high [common] device=c:\\dos\\setver.exe files=30 And the screen that would appear when booting: Each menuitem in the [menu] block describes a menu item; the first argument is a block name (eg, doslow, doshigh), and the second argument is a description. Other [menu] block keywords included menudefault, which specifies the default menu item (and optional timeout value in seconds), and menucolor, which selects foreground and background colors for the menu. In the above example, no matter which menu item you selected, HIMEM.SYS would always be loaded first, because it was in a [common] block that appeared before the other blocks. Then all commands in the selected block ([doslow] or [doshigh]) would be processed next, then all the commands in the next [common] block – and so on. Another feature was “forced prompting”. If you included a ? after the DEVICE keyword, you would receive an unconditional prompt for that particular driver. For example: device?=c:\\dos\\setver.exe would always generate the following prompt: DEVICE=C:\\DOS\\SETVER.EXE [Y,N]? And that feature wasn’t limited to device drivers. The following line: dos?=high would also generate a prompt: DOS=HIGH [Y,N]? Menu Overload Below is a more complex example, extracted from an email I wrote back on July 1, 1992 (at 2:34am apparently). This example illustrates how you could use submenu (as opposed to menuitem) to define menu items that referred to other menu blocks, in order to create multi-level menus. Originally, the keyword for that feature was simply menu, but the Astro team (specifically, Betsy Tinney, who helped refine the MultiConfig UI for Astro) suggested a keyword that was clearer. It also shows how you could include named blocks from other blocks. For example, a number of the blocks, like [dosumb], include another block, [dos], that contains commands common to the other blocks. Every block could duplicate those commands itself, but factoring out common sets of commands made for a more maintainable CONFIG.SYS. Blocks named [common] were always processed in the order they appeared, whereas blocks with any other name would be processed whenever (and only whenever) they were explicitly included. Finally, this example also uses the SET command, which defines environment variables to be passed to COMMAND.COM. In addition, a special CONFIG environment variable is automatically set to the name of the block from the final selected menuitem (eg, dosumb). This was useful for batch files like AUTOEXEC.BAT, if they needed to customize their actions according to the selected CONFIG.SYS configuration. [menu] numlock=off menucolor=15,1 menudefault=lanmenu,15 submenu=dosmenu,DOS configurations submenu=lanmenu,LanMan configurations [dosmenu] menudefault=dosumb,15 menuitem=dosumb, DOS 7.00 only menuitem=dosems, DOS 7.00 w/EMS menuitem=dosansi, DOS 7.00 w/ANSI menuitem=dos386max, DOS 7.00 w/386Max menuitem=dosdbg, DOS 7.00 w/Soft-ICE menuitem=cougar, DOS 7.00 w/Cougar [lanmenu] menudefault=winball,15 menuitem=lanman20, DOS 7.00 w/Lanman 2.0 menuitem=lanman21, DOS 7.00 w/Lanman 2.1 w/XNS menuitem=lanman21nb, DOS 7.00 w/Lanman 2.1 w/XNS+NetBeui ;menuitem=lanman21xm,DOS 7.00 w/Lanman 2.1 w/XNS Mono menuitem=lanman21dbg,DOS 7.00 w/Lanman 2.1 w/Soft-ICE menuitem=winball, DOS 7.00 w/Winball [common] set tmp=c:\\tmp set linktmp=c:\\tmp set temp=c:\\win31\\temp set dircmd=/l/o set home=d:\\tools\\bound set init=d:\\tools\\bound set alias=jeffpar set logname=jeffpar set mailname=jeffpar set basspec=d:\\tools\\dos set helpfiles=d:\\tools\\help;c:\\src\\cougar\\dev\\tools\\help set country=usa-ms set proj=c:\\src\\cougar\\dos\\dos86 set lib=d:\\tools\\windev\\lib set include=d:\\tools\\windev\\include;d:\\src\\myinc set path=d:\\tools\\dos;d:\\tools\\bound;d:\\tools\\windev;c:\\lanman\\netprog;c:\\win31;c:\\dos set prompt=$p$g [dos] break=on dos=high,umb files=60 buffers=10 stacks=9,256 lastdrivehigh=z shell=c:\\dos\\command.com /p c:\\dos /e:1024 /z [dosumb] include dos device=c:\\win31\\himem.sys device=c:\\win31\\emm386.exe noems i=b000-b7ff x=d800-dfff [dosems] include dos device=c:\\win31\\himem.sys device=c:\\win31\\emm386.exe 1024 ram i=b000-b7ff x=d800-dfff frame=e000 [dosansi] include dosumb devicehigh=c:\\dos\\ansi.sys [dos386max] include dos device=d:\\tools\\386max\\386max.sys [dosdbg] device=c:\\s-ice\\s-ice.exe /tra 1000 include dos [lanman20] include dosumb include lanman20_drivers include lanman_logon [lanman20_drivers] devicehigh=c:\\lanman\\drivers\\protman\\protman.dos /i:c:\\lanman devicehigh=c:\\lanman\\drivers\\ethernet\\ub\\ubnei.dos devicehigh=c:\\lanman\\drivers\\protocol\\netbeui\\netbeui.dos devicehigh=c:\\lanman\\drivers\\protocol\\xns\\ubxpw.dos devicehigh=c:\\lanman\\drivers\\protocol\\xns\\ubloop.dos installhigh c:\\lanman\\drivers\\protman\\netbind.exe [lanman21] include dosumb include lanman21_drivers include lanman_logon [lanman21nb] include dosumb include lanman21_drivers install c:\\lanman\\netprog\\load.com netbeui include lanman_logon [lanman21xm] include dosumb install c:\\lanman\\xnsmono\\loadniu.exe -r -d -m:d8 -i:5 -p:4 c:\\lanman\\xnsmono\\exniu2.xfm c:\\lanman\\xnsmono\\1a.lc install c:\\lanman\\xnsmono\\xnsbios.exe -m:d8 -i:5 -p:4 include lanman_logon [lanman21dbg] device=c:\\s-ice\\s-ice.exe /tra 1000 include dos include lanman21_drivers include lanman_logon [lanman21_drivers] devicehigh=c:\\lanman\\drivers\\protman\\protman.dos /i:c:\\lanman devicehigh=c:\\lanman\\drivers\\ethernet\\ub\\ubnei.dos device=c:\\lanman\\drivers\\protocol\\ubxns\\ubxps.dos install c:\\lanman\\netprog\\netbind.com [lanman_logon] install c:\\lanman\\netprog\\net.exe start workstation install c:\\lanman\\netprog\\net.exe logon jeffpar2 /y ;install c:\\lanman\\netprog\\net.exe use k: \\\\jeffpar\\astro dos6 ;install c:\\lanman\\netprog\\net.exe use j: \\\\jeffpar\\cougar dos7 [winball] include dosumb include lanman21_drivers devicehigh=c:\\win31\\redirdrv.sys devicehigh=c:\\win31\\system\\vnbhlp.dos shell=c:\\dos\\command.com /p c:\\dos /e:1024 /z /k windb set path=d:\\tools\\dos;d:\\tools\\bound;d:\\tools\\windev;c:\\win31;c:\\dos [cougar] include dosumb include lanman21_drivers devicehigh=c:\\win31\\redirdrv.sys devicehigh=c:\\win31\\system\\vnbhlp.dos shell=c:\\dos\\command.com /p c:\\dos /e:1024 /z /k cougar7 set path=d:\\tools\\dos;d:\\tools\\bound;d:\\tools\\windev;c:\\win31;c:\\dos;d:\\cougar [common] installhigh d:\\tools\\dos\\keyfix.com installhigh c:\\win31\\mouse.com installhigh c:\\dos\\share.exe installhigh c:\\win31\\smartdrv.exe 1024 installhigh c:\\dos\\doskey.com /a /e /x /p /k:128 /f:d:\\tools\\dos\\aliases install c:\\dos\\mode.com con:rate=30 delay=1 install d:\\tools\\dos\\50.com [GitHub Source] Jeff Parsons Oct 4, 2023 PCjs Explorer Expand AllCollapse AllSurprise Me Hardware All PCs Arcade DEC Intel LEDs OSI TI Software DEC IBM PC OSI C1P PCjs Documents Books Datasheets Magazines Manuals Papers Photos PCjs Archives pcjs.org © 2012-2023 Jeff Parsons PCjs is released under an MIT License",
    "commentLink": "https://news.ycombinator.com/item?id=37790174",
    "commentBody": "Thirty Years Ago: MS-DOS 6.00Hacker NewspastloginThirty Years Ago: MS-DOS 6.00 (pcjs.org) 175 points by ingve 21 hours ago| hidepastfavorite97 comments hed 20 hours agoI really enjoyed this post.As a kid I used the MultiConfig (based on a guide in PC Magazine!) to have different menus. When all you were trying to run was games, maxing your conventional memory was key. I had different combos for sound, no sound, CD-ROM, boot to windows, moving stuff between EMS&#x2F;XMS so older games could fit.I would meticulously try different combos and seeing that `mem` command return something above 600KB was a reward in and of itself. reply npongratz 20 hours agoparentI was stuck with MS-DOS 5.0 as a child, and was mildly envious of 6.x&#x27;s MultiConfig that I read about in magazines; it seemed so much better than using boot floppies for nonstandard configurations. So I rigged autoexec.bat to present a menu of various configs and rename the related config.sys files so that the one I chose was used after autoexec.bat ran. Worked quite well; the only minor downside I encountered was having to reboot again when choosing a different config than the one config.sys currently held. reply mike_hock 14 hours agorootparentI thought config.sys ran before autoexec.bat ... reply netsharc 10 hours agorootparentIt seems his&#x2F;her hack was to select a particular configuration, get autoexec.bat to copy the file with that configuration as the new config.sys, and then reboot the PC so that config.sys would get read at next boot. reply jhoechtl 14 hours agorootparentprevIt did for sure reply usrusr 19 hours agoparentprevA part of me still feels like I could still jump right in, like it would be the most natural thing for me to quickly juggle around some config.sys and autoexec.bat lines to get that balancing act between conventional and extended right for a given game. Iirc for wing commander the amount of one or the other was even key to adjusting simulation speed relative to CPU, more memory allowing more debris particles, slowing down in-game time?The other part of me is fully aware that I have forgotten just about everything, even the filename of config.sys was only resurfaced by other posts here. reply saulpw 15 hours agorootparentI&#x27;m guessing you were between the age of 10-20 at that time? Whatever tech minutiae you learned as a tween&#x2F;teenager will be with you the rest of your life. I still can code in real-mode x86 assembly even though I haven&#x27;t done so in years.That said, the other reason you could still jump right in, is that these systems were accessible. Small enough to be understandable by a child&#x27;s brain, a couple of text files you edited by hand, tinkering among a small number of parameters each of which you could test within a few minutes at most, so that worst case you spent a day dinking around with your setup. And without the distractions of the internet or thousands of free ad-supported dopamine pumps to displace your main purpose of getting this game to work.Contrast this with today: you buy a game on Steam for $30, it doesn&#x27;t work. What do you do? You have to search the internet or go to the forums, and try any number of random things that are in no way contained or enumerable and the knowledge isn&#x27;t transferable. Our systems are 100x bigger than any single person can conceivably know. reply RandomGuy456 15 hours agorootparentI totally agree! I was 15 years old at that time. Just edit and reboot until the game run the way I like it. No internet, no distraction. As much a phone call (line phone) to a friend to discuss possible configurations. Golden days! reply usrusr 11 hours agorootparentprevSecond paragraph is gold, both parts. First unfortunately not true (the rest of your life part, not the numbers) reply omnibrain 19 hours agoparentprev> and seeing that `mem` command return something above 600KB was a reward in and of itselfI remember Tornado needing 612kb. That took me some serious optimizing. reply agumonkey 18 hours agorootparentI&#x27;m always amazed of times when kilobytes would be life altering reply accrual 17 hours agoparentprev> I had different combos for sound, no sound, CD-ROM, boot to windows, moving stuff between EMS&#x2F;XMS so older games could fit.A great retro YouTuber, Phils Computer Lab, has a similar menu available for download. It&#x27;s a pretty slick menu kind of like the one you&#x27;ve described.https:&#x2F;&#x2F;www.philscomputerlab.com&#x2F;ms-dos-starter-pack.html reply singleshot_ 11 hours agoparentprevI learned Logo in elementary school, and some scraps of basic in junior high, but I have no doubt that my baseline computer systems engineering knowledge came about because if I wanted to play video games, I had to get my drivers and my EMS and XMS squared away.When I hear people today ask, “how do I get into security?” My immediate answer is that you’re going to need a very underpowered 486 and a copy of Wing Commander 3 if you really want to do it right. reply arnvidr 20 hours agoparentprevI did the same thing. I didn&#x27;t have internet back then, so I assume I also got the knowledge to do this from magazines. Also, lots of time on my hand back then, so probably dove deep into various weird manuals. reply rep_lodsb 16 hours agorootparentI used the \"help\" command that is included in DOS. Though today is the first time I learned you could have multiple \"[common]\" sections! reply ubermonkey 19 hours agoparentprevI never ran 6, but under 3.3 and 4 we (my pals and I) had all created a complicated array of batch files to create multiple booting options (autoexec&#x2F;config combos).It was originally borne of a need to allow us all to have our own preferred setup on shared PCs in the computer lab we worked in, and just grew from there. My pal Dave may have given us the idea with his scheme of multiple boot profiles on his Amiga, come to think of it.>moving stuff between EMS&#x2F;XMS so older games could fit.Oh god this. My pal Mike and I -- who, I note fondly, I was visiting with last weekend, 30+ years later -- spent a LONG time basically becoming subject matter experts on DOS memory allocation and manipulation. It was my first experience with hard-won knowledge that was nevertheless useless relatively quickly; I remember NONE of it now. But holy cow we futzed around with this SO MUCH -- initially to accommodate various games or other heavyweight programs, and then out of momentum. reply stuaxo 19 hours agoparentprevI think with NDOS I could get about 617k but that was it. reply jbandela1 20 hours agoprevDon&#x27;t forget one of the most important new utilities in DOS 6: Memmakerhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;List_of_DOS_commands#MEMMAKERIt would help you change your configuration so that you maximized the amount of conventional memory. This was useful in getting games to run. reply alkonaut 20 hours agoparentI remember being the only kid who knew how to hand-craft your config.sys&#x2F;autoexec.bat to play some games, and random people would call me saying they got my name of some friend of a friend. reply pjmlp 15 hours agoparentprevAnd DriveSpace, turning my 20 MB disk into a 40 MB, greatly appreciated as I couldn&#x27;t afford buying a new disk at the time. reply Narishma 14 hours agorootparentThat&#x27;s discussed in the article. reply ggambetta 15 hours agorootparentprevThere was Stacker years before that :) reply pjmlp 14 hours agorootparentWhich I used in DR-DOS before moving into MS-DOS. reply stonogo 14 hours agorootparentprevMicrosoft tried to license it, failed, and wound up licensing DoubleSpace instead. As usual, the utility being built into MS-DOS 6 pretty much destroyed competition in that space. Stacker&#x27;s ace in the hole was their coprocessor card, which I coveted pretty hard.. reply ralphc 7 hours agorootparentWindows 95, 98 and ME can read DoubleSpace drives. If you get USB drives set up, which you can do with 95 and 98, and format the drive FAT, not FAT32, put the drive file on it, those versions of Windows will mount it. replyrwmj 19 hours agoprevFun MS-DOS fact: The MSDOS.SYS, IO.SYS & COMMAND.COM files had a timestamp that matched the version number (as you can see in the screenshot in this page). The file time is 6:00a [am]. In MS-DOS 6.22, the last version before it was integrated into Windows, the timestamp of those files was 6:22a. reply accrual 16 hours agoparentI happened to have a folder containing DOS 6.22 on my desktop and indeed, all the files in the DOS directory are dated 1994-05-31 06:22. Thanks for the interesting knowledge, I never noticed that! Maybe it was touch-like command run as a part of the release process. reply Dwedit 13 hours agoparentprevOther random MS-DOS fact, if your filesystem is badly corrupted and it attempts to read sector 0 as a directory, you will see what looks like a file named \"δ In early builds of Windows 95, the taskbar originally wasn&#x27;t a taskbar; it was a folder window docked at the bottom of the screen that you could drag&#x2F;drop things into&#x2F;out of, sort of like the organizer tray in the top drawer of you desk.The image is really fascinating to me. The whole taskbar paradigm we&#x27;re familiar with today started life as what sounds like a quick hack. Draw a bar that draws the contents of a folder in a narrow bar format. Later extend it to hold running applications instead. reply atombender 19 hours agorootparentprevThe image in links 2-3 doesn&#x27;t load for me. Is there an archived copy somewhere? reply cesarb 18 hours agorootparentThe trick is to know that the true address of that blog was at blogs.msdn.com. Here it is, complete with comments (which were lost when the blog was moved): https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20050924221736&#x2F;http:&#x2F;&#x2F;blogs.msdn... reply bluedino 20 hours agoparentprevAnd 1 year after Windows 3.1 (which was Pretty Good) reply galangalalgol 19 hours agorootparentFor work maybe? As a gamer I never used 3.1 for anything. Even the gui apps I used were dos based. Seemingly a lot of them were ported from amiga. Trying to imagine a modern os with no window manager, just applications that all used gl or vulkan directly with some unmaskable keyboard combos to allow switching. reply M95D 19 hours agorootparent> Trying to imagine a modern os with no window manager, just applications that all used gl or vulkan directly with some unmaskable keyboard combos to allow switching.Can I have that? Please!Firefox won&#x27;t open full-screen if started in X without a window manager. reply btrettel 18 hours agorootparentThe easiest approach would be configuring Linux to do this.I have a Linux laptop without X or Wayland. It&#x27;s mostly for CLI and TUI applications, but I do have some framebuffer applications like fbpdf.There are a lot of little annoyances, many of which could be fixed with a proper Linux configuration, though others require improvement to the applications.The framebuffer versions of graphical programs are unfortunately clunky compared against the conventional versions. And I&#x27;m disappointed that they don&#x27;t work when called from tmux or Midnight Commander, or at least I haven&#x27;t figured out how to make them work.Some key combinations don&#x27;t seem to work and I haven&#x27;t been able to figure out why for all of them yet.I miss having a unified clipboard.I&#x27;ve also become more adept at Midnight Commander and its built in editor, diff tool, and viewer. Though this exposes some issues, for example: If a file is edited with F4 configured to be mcedit, then I can switch between the editor and file manager with the screen list (Alt-`). But if I open mcedit from the command line or user menu, then the screen list will only be for that mcedit run and not include any other screens open. I rarely use the Midnight Commander screen list outside of this specific computer.(As for why I have this computer, it&#x27;s to have a distraction-free setup. It works nicely for that purpose.) reply hulitu 15 hours agorootparentprev> Firefox won&#x27;t open full-screen if started in X without a window manager.firefox -geometry 1024x768+0+0does not work ? reply jlarocco 15 hours agorootparentprevI could be missing the gist here, but don&#x27;t StumpWM, EXWM, and possibly others do this? reply anthk 15 hours agorootparentprevJust use cwm. reply treve 17 hours agorootparentprevYou&#x27;re right, it took a while for Windows gaming to really take off, even in the Windows 95 era. But Windows 3.1 was great for other kinds of productivity-related tasks. reply mseepgood 20 hours agoparentprevTime passed slower back then. reply accrual 16 hours agorootparentA silly pet idea I have is that while time didn&#x27;t literally pass slower, there was less overall entropy in the world back then. There were fewer people working on fewer things, so less new things happened overall. Today there are more people working on more things, so the rate of new things happening is higher, and thus the perception of time passing faster. reply saulpw 14 hours agorootparentAnd we are all connected, so there are not only twice as many people on the planet, and more people with computers, but also people in China, India, Brazil, and Russia are able to collaborate instead of being completely isolated in their own locales. reply dbsmith83 10 hours agorootparentprevor the TPM role hadn&#x27;t been invented yet reply livrem 20 hours agoparentprevYes, crazy that something this good could turn so bad in just two years. In hindsight I am happy their move to Windows pushed me to switch to Linux though. reply galangalalgol 19 hours agorootparentWas it really ever good though? I came to dos after us having an amiga and it mostly seemed like garbage except that there was more software. Having to jave different autoexec.bat and config.sys files for every game I wanted to play, and laboriously solving the knapsack problem forneach one to get all the drivers I needed into ram. reply livrem 14 hours agorootparentIn MS-DOS 5.0 and later at least you could make a menu at start-up to pick what to activate. I looked at my old config.sys and autoexec.bat recently and it was amazingly simple. 100% of system configuration in maybe 1-200 lines of text, in two files. Not so bad compared to hunting for were to configure something in any modern OS?DOS did what it had to do. For coding you could start up emacs (and ctrl-z somehow magically could drop you in a command.com shell that you could exit from to go back to emacs; I think there was a DOS interrupt to allow applications to start sub-shells like that?). And otherwise (i.e. most of the time for most of us) you just booted and started a game and then when you were done playing turned off the computer.Anyway I must admit, many years later, that many games (and some applications) around 1990 were definitely better on an Amiga. DOS games for some time were rarely the best ports. But I never used an Amiga enough to learn if I liked the operating system much. I did buy Amiga Forever some year ago and that comes with a few pre-configured disk images with AmigaOS and various applications, but I am barely able to use that at all since I have no idea how to use it. It would be fun to play with some day. reply neilv 15 hours agoprevI used MS-DOS since 1.25, but I kinda wish I&#x27;d instead been using Unix all that time.MS-DOS had much better video games, but I didn&#x27;t much play those. Overall, the things I did do would&#x27;ve been better on Unix, and I would&#x27;ve gotten plugged into that scene earlier. (When I finally got access to Unix workstations, I sold my PC, and never again used another MS box at home.) reply mixmastamyk 12 hours agoparentUnix was very expensive at the time of course, meaning only used by big business. I remember asking a computer&#x2F;IT teacher what it was, in the early 90s. Sounded interesting and somehow we found out about Minix and downloaded it from somewhere to tinker, maybe a BBS?Luckily this happened, because when I later got an IT job in the mid-nineties at a aerospace company I was good to go. At which point I discovered Linux and then BSD. reply neilv 11 hours agorootparentAlso, engineering-ish small businesses, and universities, and the occasional non-profit saving money with dumb terminals where they&#x27;d otherwise need a PC on each desk.I once paid ~$100 for Coherent (Unix-like) for my &#x27;286, then sent it back due to the 64KB process limit, while I used Unix workstations at an internship. My next home computer was to buy a used Sun-3&#x2F;75 from the local Sun office, for a fraction of a what a PC would cost. reply zwieback 18 hours agoprevOh, wow. I remember when it came out. My multi-configs were epic. At that time I was actually an OS&#x2F;2 programmer but we also had a DOS product so some time reluctantly spent in DOS. reply mike_hock 14 hours agoprev> LZ77 compression was fine, and hashing was fine, apparently the combination of the two became a patentable innovationlolwat reply 31337Logic 11 hours agoprevI suspect this topic is going to generate a very long thre.... Oh. Nevermind. It already did. ;-)Cheers to my fellow old-farts in keeping these memories alive. :-) reply charles_f 18 hours agoprevInteresting that a lot of the updates were actually licensed software.Deciding to (re)build a system level disk compression system the month before a major release, in an era when distribution of patches was done through floppies, was a balsy move.It also somewhat explanatory of the reputation regarding bugs of MS back then. reply glonq 18 hours agoprevIt&#x27;s 30+ years later, but I&#x27;m pretty sure that I could still use \"copy con\" to craft a decent config.sys and autoexec.batHaving done it so many times, those things are burned into my brain forever. reply NikkiA 17 hours agoprevI think I was on DR-DOS at that point from MS 5.0 until MS released 6.20, and ISTR feeling that dblspace was a huge step down from the DR equivalent SuperStor. reply elteto 20 hours agoprevWoah! I remember my dad setting up a MultiConfig menu! Very neat. reply acqq 14 hours agoprevRegarding the DoubleSpace context, Wikipedia helps (1):Sept 1991: Digital Research releases DR DOS 6.0 with AddStor&#x27;s SuperStor disk compression.March 1993: Microsoft introduces MS-DOS 6.0, the first with DoubleSpace disk compressionJune 1993: IBM announces PC DOS 6.1November 1993: Microsoft MS-DOS 6.2, leapfrogging IBM&#x27;s PC DOS 6.1 and with improved the stability of DoubleSpace.February 1994: Microsoft found guilty of patent infringement, and Stac Electronics guilty of trade secret theft. Microsoft MS-DOS 6.21, removing DoubleSpace.June 1994: After a judge ordered Microsoft to recall all unsold infringing products worldwide, Microsoft settled its dispute with Stac, and released MS-DOS 6.22, bringing back disk compression with internally developed DriveSpace, which is about 5% slower than DoubleSpace.An interesting detail:In the MS-Stac trial, \"Stac’s lawyers showed a videotape of Microsoft Chairman Bill Gates\" \"at the unveiling of MS-DOS 6.0 in which he wore a T-shirt saying, “We came, we saw, we doubled,” to underscore the importance of the compression feature.\" (2)A second detail, the \"trade secret theft\" was:Stac was found \"to have committed a trade secret violation by reverse engineering features of a beta version of MS DOS that they had gotten in confidence and then using the information they gained in making their own product.\" (3)1) https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Timeline_of_DOS_operating_syst...2) https:&#x2F;&#x2F;www.latimes.com&#x2F;archives&#x2F;la-xpm-1994-02-24-fi-26671-...3) https:&#x2F;&#x2F;lwn.net&#x2F;Articles&#x2F;134642&#x2F; reply SoftTalker 18 hours agoprevContemporaneously you could have bought a NeXT computer running what would eventually become Mac OS X, instead of that pile of hot garbage. reply mikestew 18 hours agoparentAnd how many multiples over a machine capable of running MS-DOS would I have had to spend to get a NeXT? I&#x27;ll let you do the math on that one, because I already did it 30 years ago.(Note: I have never owned a NeXT machine.) reply layer8 18 hours agoparentprevFor at least double or three times the price. And good luck running Wing Commander on that. reply SoftTalker 16 hours agorootparentIt wasn&#x27;t a mainstream gaming platform, true. But the productivity and development tools available would absolutely run rings around what was available for DOS. Easily worth the price if you needed it.Also, https:&#x2F;&#x2F;doomwiki.org&#x2F;wiki&#x2F;NEXTSTEPAnyway my main point was that DOS was nearly as primitive then compared to state of the art as it would be considered today. reply anthk 15 hours agorootparentAnd compared to Irix the NeXT was nothing, but by the price of a basic -functional- SGI machine you could get a car. reply kjs3 17 hours agoparentprevI can spend several (2-3x) as much for a computer that doesn&#x27;t run the software most people need? From a company with no track record? Well, at least it&#x27;s pretty.You can always tell the replies from someone who only read about it on the interwebs. reply anthk 15 hours agoparentprevCompare what you had for DOS against what you had for NeXT and 10x less the price. reply gavin_gee 17 hours agoprevdamn these were the good old daysThe people the leaps in tech the simplicity the naivety reply block_dagger 20 hours agoprevWhat about PC-DOS (the good DOS)? reply mikepurvis 20 hours agoparentI grew up with PC-DOS and I always felt slightly like a second class citizen for missing goodies that others had, like qbasic, and also there would be subtle differences when it came time to set up stuff like CD-ROM drives and sound cards.What were the good parts of PC-DOS? reply older 19 hours agorootparentREXX interpreter. reply timw4mail 16 hours agoparentprevWhich reminds me...I was thinking about smashing MSDOS 6.22 and PC-DOS 2000 together.I wonder how well it would work to copy the MSDOS &#x27;DOS&#x27; folder into the PC-DOS one, just keeping the programs with different names. reply lproven 9 hours agorootparentI&#x27;ve got complete pre-configured runnable VM disk images of PC-DOS 7.1 on my blog, too.Note, 7.1, the last version and capable of FAT32, not to be confused with 7.01. reply raverbashing 20 hours agoprevInteresting, and good reminiscencesI wonder what email system it was being used at the time (I mean, was it even over TCP? SMTP&#x2F;IMAP?) reply Narishma 14 hours agoparentProbably over IPX&#x2F;SPX instead of TCP&#x2F;IP. Novell Netware networks were all the rage back then in the PC world. reply mixmastamyk 14 hours agoprev [–] Worked in IT in the mid-90s, was a great time and I became a sought after \"expert\" to free conventional memory for lab PCs connected to equipment. Did it all by hand at first with mem.exe and edit.com?, but I think in 6.0 I started also using a TUI to visualize the upper area—the helpful msd.exe:https:&#x2F;&#x2F;i.postimg.cc&#x2F;2jX8LpF0&#x2F;memorymap.pngMore recently in the XP era, I used the DOS multi-config menu in a classroom environment. Combined with ghost the partition imager. There was a menu that defaulted quickly to booting the current OS partition. But hit the right key at boot and you could restore the computer from a pristine pre-configured XP image. Since the images were on a primary partition it would be hidden from the end-user and not mounted for them to prevent issues. You could also update the current image and save it back to the menu partition for next time. This happened once in a while to apply windows&#x2F;app updates.Worked incredibly well, until the whole classroom was dismantled around 2015ish. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The summary introduces the MultiConfig feature in MS-DOS 6.00, a system that allows for easy customization of startup configurations.",
      "It highlights the existence of bugs within the DoubleSpace feature of MS-DOS.",
      "There is a discussion about various configurations and options linked to the COMMAND.COM command interpreter for DOS 7.00."
    ],
    "commentSummary": [
      "The article prompts an nostalgic discussion surrounding early versions of MS-DOS 6.00 and Windows, including the challenges faced, memory optimization and gaming during that era.",
      "Commenters share diverse experiences of using MS-DOS, Windows, and disk compression software, along with usage of alternative operating systems.",
      "References are made to the rapid advancements in Information Technology (IT) during the 1990s in the discussions."
    ],
    "points": 175,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1696597047
  },
  {
    "id": 37797606,
    "title": "DotBigBang – Multiplayer game engine with 120fps and 2 second load time",
    "originLink": "https://dotbigbang.com/game/1af877e9bfdb47088611f55982b7570f/prestons-diamond-wars?mp=playdw",
    "originBody": "With all the turmoil in the game engine world recently, I thought I&#x27;d quickly post to show progress on our game platform dotbigbang.com.It&#x27;s a fully integrated game platform where the multiplayer game editor and games all run on the web. You can make multiplayer games and share them with just a link with no setup at all.Breakdown of major features here: https:&#x2F;&#x2F;twitter.com&#x2F;bobbydigitales&#x2F;status&#x2F;152647067103481856...We have comprehensive docs at http:&#x2F;&#x2F;docs.dotbigbang.com and a cosy Discord server at https:&#x2F;&#x2F;dotbigbang.com&#x2F;discordAll updates are on our blog here: https:&#x2F;&#x2F;blog.dotbigbang.com&#x2F;",
    "commentLink": "https://news.ycombinator.com/item?id=37797606",
    "commentBody": "DotBigBang – Multiplayer game engine with 120fps and 2 second load timeHacker NewspastloginDotBigBang – Multiplayer game engine with 120fps and 2 second load time (dotbigbang.com) 164 points by bobbydigitales 10 hours ago| hidepastfavorite64 comments With all the turmoil in the game engine world recently, I thought I&#x27;d quickly post to show progress on our game platform dotbigbang.com.It&#x27;s a fully integrated game platform where the multiplayer game editor and games all run on the web. You can make multiplayer games and share them with just a link with no setup at all.Breakdown of major features here: https:&#x2F;&#x2F;twitter.com&#x2F;bobbydigitales&#x2F;status&#x2F;152647067103481856...We have comprehensive docs at http:&#x2F;&#x2F;docs.dotbigbang.com and a cosy Discord server at https:&#x2F;&#x2F;dotbigbang.com&#x2F;discordAll updates are on our blog here: https:&#x2F;&#x2F;blog.dotbigbang.com&#x2F; schemescape 8 hours agoI assumed this would be unusable on my phone, but it actually works great!And nice work on the load time. Every time a non-photorealistic game takes more than a few seconds to load on my desktop, I get unreasonably annoyed.Note: I don’t think I’d ever want to really play a first person 3D game on my phone, but it’s fun to see that it would be possible. reply bobbydigitales 8 hours agoparentThanks! We work hard to make it work well on all our platforms. I can get 120fps on my Samsung Galaxy S23 on simple games!Yes FPS can be a bit hard on mobile devices, but a lot of younger players only play e.g. Minecraft on phones!If you want a 3rd person experience, this is a nice one for an ambient experience: https:&#x2F;&#x2F;dotbigbang.com&#x2F;game&#x2F;cab2b545338144d68fb8934801a1cd97...And this is a good 3rd person game: https:&#x2F;&#x2F;dotbigbang.com&#x2F;game&#x2F;567aa34f2ee14adbb2cb1ea87cc65eff... reply meheleventyone 2 hours agoprevHey, I work with bobbydigitales on this (along with a bunch of others) and had a hand in making a lot of the games including Diamond Wars linked here so if anyone has question about gamedev on dot big bang please ask away!If you’re interested as a developer and want to know how we plan to support you we have this landing page: https:&#x2F;&#x2F;developers.dotbigbang.com&#x2F; reply parasti 31 minutes agoprevThis is very cool, but doesn&#x27;t actually load in two seconds. I would have been really impressed if that part was legitimately true. reply meheleventyone 19 minutes agoparentThanks! Load times obviously vary depending on your connection, hardware and so on. I expect two seconds is true for bobbydigitales. We’ll continue to optimise loading though so it’s great for everyone. reply bryan_w 7 hours agoprevIf Meta was still allowed to buy things, you&#x27;d be billionaires. This is pretty much as good as their horizon platform but can actually run on my phone. Good job reply bobbydigitales 7 hours agoparentThanks! My DMs and bank account are open :) reply Tade0 1 hour agoprevThis works on my six year old phone - impressive, considering that more often than not in such cases I don&#x27;t even get past the loading screen.I like the architecture - most game engines working in the browser don&#x27;t use anything resembling ECS, which makes it impossible for me to produce anything but very simple demos. reply bobbydigitales 1 hour agoparentThanks, glad it worked for you! We want to make sure it actually works on a broad range of devices! Our lead artist regularly tests on his Pixel 2 :) reply davedx 1 hour agoprevTheir company website: https:&#x2F;&#x2F;controlzee.com&#x2F;#job-list reply Exuma 9 hours agoprevHow long did it take to build this, and how many people? My brother was interested in game development and I wanted to send him something inspiring, but not \"I will never do this in a million years\" reply bobbydigitales 9 hours agoparentIt&#x27;s actually a complete game development platform. The game I posted was made using only the tools available on the website. The game editor is multiplayer and runs in the browser.Overall it took a long time as it&#x27;s a complete platform, engine, tools and editors, multiplayer system and website! I do free game dev mentoring though and I can be reached at https:&#x2F;&#x2F;mastodon.gamedev.place&#x2F;@bobbydigitales reply meheleventyone 36 minutes agoparentprevThe game that’s linked was built on dot big bang itself by a team of two developers and one artist with occasional help. The total dev time to make it was about six months, a lot of which was spent refining the game and making sure it was super solid as we launched it with a livestream in front of thousands of people!Games on dot big bang come in a variety of shapes and sizes though. You can make something in a couple of hours or take your time. For some smaller examples:This fun puzzle game was made by one of our community for our summer game jam: https:&#x2F;&#x2F;dotbigbang.com&#x2F;game&#x2F;0c4038a5fe064711ba339b1e1c2bbd74...We also run a weekly scripting challenge in our Discord for tiny experiments on a theme, here’s a pachinko potion mixing game that got made for one: https:&#x2F;&#x2F;dotbigbang.com&#x2F;game&#x2F;69153d59db5b45f3aa4485e8af2dafa1... reply mentos 9 hours agoprevI think the https:&#x2F;&#x2F;www.dotbigbang.com&#x2F;game ‘101 tutorial’ is down? reply NathanFlurry 9 hours agoparentLooks like https:&#x2F;&#x2F;dotbigbang.com&#x2F;game (no www) works reply bobbydigitales 9 hours agorootparentThanks! Where did you get the original link from? reply Physkal 2 hours agoprevHad a really intense battle on my first try, the response time is great and very playable. Great lobby music too. thanks reply bobbydigitales 2 hours agoparentAwesome, glad you enjoyed it! Those lobbies can get pretty sweaty! reply endisneigh 9 hours agoprevWhat’s the stack look like? reply bobbydigitales 9 hours agoparentIt&#x27;s Python and Go on the backend and TypeScript on the front end :) reply endisneigh 9 hours agorootparentThe rendering is done entirely in typescript? Very impressive. Great work - I was actually curious about how one could crest something like animal crossing hah reply bobbydigitales 8 hours agorootparentYes it&#x27;s all TypeScript and there&#x27;s still a lot more performance left on the table! reply umen 3 hours agorootparentprevWhere do you host your servers ? And why GO? Do you use Three.js ? Thanks reply bobbydigitales 3 hours agorootparentServers are on AWS and Cloudfront. We started out with three.js for rendering but we froze at 78 and are currently working on rewriting the renderer to not use the scene-graph and instead move to a more data oriented design. reply Scaevolus 2 hours agorootparentHave you seen the HypeHype renderer talk? reply bobbydigitales 2 hours agorootparentYep! It&#x27;s very interesting, but our problem space is a bit different because we can do some optimizations based on our models being voxels. Great stuff though! reply umen 16 minutes agorootparentWhy did you use GO for server side ? did you test with other teach ? Can you share how your server side design of servers looks like ? Do you use simple ec2 or what ? replyambrose2 7 hours agorootparentprevWhat is written in Python and what in Go and why? reply bobbydigitales 3 hours agorootparentWe&#x27;re moving from Python to Go as we see about a 100x performance improvement for our specific use case. So it&#x27;s basically old stuff in Python and new stuff in Go :) reply wg0 7 hours agorootparentprevBeauty back and forth you mean.Web assembly? Pricing?Typo: Web assembly reply bobbydigitales 7 hours agorootparentI don&#x27;t know if this is a question! If it is, I don&#x27;t understand, I&#x27;m sorry! reply NathanFlurry 9 hours agoprevLooks awesome! I worked on Krunker.io a few years back (which had a UGC aspect similar to this), love seeing more people picking up on the < 5s time-to-fun mechanic. reply bobbydigitales 9 hours agoparentThanks! Krunker is super awesome! What parts did you work on? reply NathanFlurry 1 hour agorootparentI was employee #1, worked on basically everything that wasn&#x27;t actual gameplay (core engine, matchmaking&#x2F;servers, WASM-based anticheat) and left mid-2020. I work with a lot of non-web games nowadays, but I really miss building for web (esp with WebGPU & WebTransport in the mix now).Hope we cross paths at a conference at some point! reply davedx 1 hour agoprevSuper impressive. Good work! reply a257 7 hours agoprevThis is so cool! Though, how do you ensure that people are playing fair? When I dabbled in web-based games a year ago, I noticed that it&#x27;s pretty difficult to have a good anti-cheat system for games that runs on browsers. reply bobbydigitales 7 hours agoparentFor a lot of types of games (e.g. social, creative, silly fun) it doesn&#x27;t matter. For those where it does you have to run servers that you control and write server-authoritative code.You have to assume clients are hacked whenever you&#x27;re writing competitive games anyway, so there&#x27;s not much difference there. reply a257 6 hours agorootparentFair enough, I guess it doesn&#x27;t really matter if someone hacks a drawing&#x2F;building game. But people love competitive games.I guess you can prevent most overt hacks through server-side validation. But still, that doesn&#x27;t stop more sophisticated users from creating and using subtler hacks (such as aimbots). reply bobbydigitales 6 hours agorootparentYep! Cheating and combating cheating is a never-ending arms race! You can use heuristics on the server to try and detect suspect behavior, but the issue is that the very best players can be very difficult to distinguish from cheaters. Even with client-side anti-cheat, you have to have the cheat before you can add the signature to have the client-side search for it and ban the player, so there are no simple solutions unfortunately. (Most of this coming from my previous life working on PC games :) ) reply chrisweekly 7 hours agoprevHaha, this looks AWESOME. I just played a bit of \"Escape Unspeakable\" (one of the featured games) and if it&#x27;s any indication, dotbigbang is going to do very well. Great job! Good luck! reply meheleventyone 2 hours agoparentI made this game so thanks! reply bobbydigitales 7 hours agoparentprevThanks so much! Yes Escape Unspeakeable is a very silly fun game :) reply zfxfr 7 hours agoprevhttp:&#x2F;&#x2F;docs.dotbigbang.com&#x2F; gives 403 ERROR The request could not be satisfied. reply meheleventyone 2 hours agoparentIt didn’t matter for me but maybe try https rather than http. On iOS Safari it redirected me to the https url and loaded. reply bobbydigitales 7 hours agoparentprevThat&#x27;s super weird! It&#x27;s working for me here on wifi and on my cell connection on my phone. Could you try another connection? reply jvdvegt 1 hour agorootparentSame here, from the Netherlands.Small print on the error page says: Generated by cloudfront (CloudFront) Request ID: nu9PuEmZJeaWA8op7PaSfAal0M3IfCzp9mnd04PlxRiSWErx1M4qOw reply pragmatick 3 hours agorootparentprevSame here. From germany, if that makes any difference. reply bobbydigitales 2 hours agorootparentThanks for reporting, we&#x27;ll look into it! reply paulmd 7 hours agoparentprevsame here. wayback machine to the rescue.http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230530134020&#x2F;http:&#x2F;&#x2F;docs.dotbig... reply nnnnnnnnnnnnn 8 hours agoprevThis is like Roblox, right? What are the differences between the two? reply bobbydigitales 8 hours agoparent1) You can send a link to anyone and they can play on any device in multiplayer, no install needed.2) All the tools you need are built in and supported on all platforms (even XBOX!), no separate downloads. Windows, Mac, Linux (including Raspberry Pi), XBOX Series S&#x2F;X. Android, iOS have a simplified editor.3) We&#x27;ll give the majority of revenue to the creator where Roblox take about 86% themselves. reply sdwr 8 hours agoprevRuns pretty damn smooth on my budget android! reply bobbydigitales 8 hours agoparentThanks so much! We work hard to make it run well on lower-spec devices! reply cpersona 7 hours agoprevAbsolutely blown away. Not sure what I’m looking at but it’s amazing. reply bobbydigitales 7 hours agoparentThanks so much! Don&#x27;t need to know what you&#x27;re looking at if you like it! :) reply laustta 7 hours agoprevThis looks very impressive, great work and best of luck with the platform reply bobbydigitales 7 hours agoparentThanks so much! reply readyplayernull 9 hours agoprevGreat work Robert! reply bobbydigitales 9 hours agoparentThanks! reply bobbydigitales 7 hours agorootparentWait a second! reply chrisan 9 hours agoprevLove the arcade skin :) reply bobbydigitales 9 hours agoparentThanks it&#x27;s one my favorites too! reply Geee 2 hours agoprev [–] It doesn&#x27;t lock mouse cursor on Safari, making it impossible to play. reply bobbydigitales 2 hours agoparent [–] Thanks for the report. We&#x27;ll take a look, Safari pointer lock is sometimes a bit fickle and we have a regression there! replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post discusses the advancements on dotbigbang.com, a fully encompassing platform where multiplayer games, as well as the game editors, operate on the web.",
      "It provides a unique feature that allows users to create and share multiplayer games just by providing a link, eliminating the need for any setup.",
      "Users can access more details, documents, and updates on the platform's own website, blog, and Discord server."
    ],
    "commentSummary": [
      "DotBigBang is a web-based multiplayer game engine, allowing for easy creation and sharing of games across multiple devices. The platform boasts high frame rates and quick loading times.",
      "Developed by a small team using Python, Go, and TypeScript, it facilitates discussion around its features, implementation challenges, and shared experiences with technical issues.",
      "User feedback indicates the need for effective anti-cheating measures to enhance the gaming experience."
    ],
    "points": 163,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1696634767
  },
  {
    "id": 37792030,
    "title": "Unreal Engine will no longer be free for all",
    "originLink": "https://www.creativebloq.com/news/epic-games-unreal-engine-charge",
    "originBody": "Skip to main content ART AND DESIGN INSPIRATION Search Sign in Subscribe 6 for £12 mag offer News How to Features Buying guides Reviews Magazines Events TRENDING Best drawing tablets Graphic design Web design Adobe deals UX course When you purchase through links on our site, we may earn an affiliate commission. Here’s how it works. News Digital Art Unreal Engine will no longer be free for all By Joseph Foley last updated about 20 hours ago Bad news for non-gaming creatives. (Image credit: Epic Games) Bad news for those using Unreal Engine for VFX or animation this week – or at least for some. Epic Games has confirmed that it will begin charging industries outside gaming to use the 3D graphics engine next year. Until now the company has not charged directly for use of Unreal Engine. Instead it charges royalties for projects that surpass $1m in revenue – and only those that use code from the engine. That means that while the developers of big-selling games pay royalties, those who use Unreal Engine for film making and other uses pay nothing. Epic Games now plans to start charging subscription fees on a per-seat basis, but it has clarified that not everyone will be affected (also see our pick of the best 3D apps). See more Speaking at Unreal Fest 2023, Epic Games CEO Tim Sweeney said Unreal Engine would become “a licensable piece of software like Maya or Photoshop” with a subscription-based pricing model. Studios using it for non-gaming work like animation, VFX and visualization will be charged through a “seat-based enterprise software licensing model” Sponsored Links 0% Video from our partners Brought to you by Taboola Tommy Chong: The Horrifying Truth About CBD Tommy Chong's CBD Watch Now The video above, shared from the event by the creative developer Immature on Twitter, shows Sweeney outlining the company’s sources of income, which will include licensing Unreal Engine, in the context of Epic's recent decision to lay off 16% of its staff. RECOMMENDED VIDEOS FOR YOU... See more Understandably, the news has caused concern among creatives, especially independent filmmakers and non-professionals. Unreal Engine was developed as a graphics engine for gaming, but is now routinely used for real-time rendering and virtual production in everything from animation, to commercials, including by aspiring filmmakers who may not be able to pay for a subscription. Replying to a question raised on X, Sweeney has now clarified that there will be minimum revenue thresholds for commercial projects that have to pay for a subscription and that student and educator use of Unreal Engine will remain free. There is no detail as yet on what the threshold will be, but the idea seems to be to charge larger studios and developers. It's also unknown what the Unreal Engine price or terms will look like – Sweeney said pricing would not be \"unusually expensive, or unusually inexpensive”. The move will not affect game developers who will continue to pay a 5 per cent royalty rate after revenue passes $1m. Sweeney said he was announcing the change ahead of time to ensure transparency. Some have suggested that the move was inevitable, noting that it was unusual that access has remained free. However, others have raised concerns that a subscription model could means some creatives cannot afford to use the tool. \"Can you imagine that there are some really good unreal engine users that cannot afford subscription in some countries? Please keep it free to use and monetize results for movie and nongame usage,\" the producer Mihai Ogasanu wrote. In our Unreal Engine 5.3 review, we note that Unreal Engine continues to redefine the game engine industry with a new skeletal mesh editor, cloth editor and volumetric capabilities. Get the Creative Bloq Newsletter Daily design news, reviews, how-tos and more, as picked by the editors. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Joseph Foley Joe is a regular freelance journalist and editor at Creative Bloq. He writes news and features, updates buying guides and keeps track of the best equipment for creatives, from monitors to accessories and office supplies. A writer and translator, he also works as a project manager at London and Buenos Aires-based design and branding agency Hermana Creatives, where he manages a team of designers, photographers and video editors who specialise in producing photography, video content, graphic design and collaterals for the hospitality sector. He enjoys photography, particularly nature photography, wellness and he dances Argentine tango. TOPICS DIGITAL ART VFX ANIMATION GAMING VIDEO GAMES NEWS SOFTWARE RELATED ARTICLES Artists hate these AI-made game character redesigns AI is replacing artists, and here's the proof This '90s AI portrait trend is taking over TikTok Making Netflix's Nimona: why it owes a surprising debt to Chuck Jones The best free VPN of 2023 We help you pick the best free VPN service in 2023, explaining the pros, cons, and risks. Avoid VPN scams and get a free VPN for streaming Netflix. Tommy Chong: The Horrifying Truth About CBD Tommy's products are best, by far. I am so happy that I finally found a product that works wonders. Tommy Chong's CBDSponsored Watch Now What Vitamin Causes Immediate Relief From Sciatic Nerve Pain? Fortunately there is a vitamin that anyone over 55 can take for sciatic nerve pain SciatiEaseSponsored Learn More Nanuet: These New $250/Month Senior Living Apartments Are Stunning Senior ApartmentsSponsored Advertisement RECOMMENDED How to make and sell an NFT The best drawing tablets in 2023 Advertisement MOST READ MOST SHARED 1 New logo dropped because of public criticism 2 This month could finally bring a new Apple iMac 3 New AI tool could be a game-changer for 3D animation 4 I'm shaking my head at KFC's new optical illusion billboard 5 7 subtle logo changes that made a big difference DESIGN MAGAZINE SUBSCRIPTIONS ● Enjoy 12 months for £/$/€12 From $12 VIEW Advertisement Creative Bloq is part of Future plc, an international media group and leading digital publisher. Visit our corporate site. About Us Contact Future's experts Terms and conditions Privacy policy Cookies policy Advertise with us Accessibility Statement Careers © Future Publishing Limited Quay House, The Ambury, Bath BA1 1UA. All rights reserved. England and Wales company registration number 2008885. We'd like to show you notifications for the latest news and updates. Allow Cancel",
    "commentLink": "https://news.ycombinator.com/item?id=37792030",
    "commentBody": "Unreal Engine will no longer be free for allHacker NewspastloginUnreal Engine will no longer be free for all (creativebloq.com) 157 points by intunderflow 18 hours ago| hidepastfavorite114 comments lholden 18 hours agoVery misleading article title.The licensing changes target big commercial usages outside of game development. (With revenue thresholds, similar to how it already works right now for game development.)For example, up until now Unreal has seen use in vfx for movie and tv production. The licensing model for Unreal was primarily oriented for game development, which meant that this wasn&#x27;t generating any revenue for Epic unless that company opted into the optional support plan.Unlike the crazy situation with Unity, these changes are being announced in advance without affecting usage of previous versions of Unreal.(Not saying I like or care for subscriptions for software. But context helps understand what&#x27;s going on here.)I&#x27;m surprised they didn&#x27;t make this change sooner. reply ksec 32 minutes agoparent>I&#x27;m surprised they didn&#x27;t make this change sooner.Same here, I thought they were also earning big money from TV and Hollywood. As they have been constantly improving non-gaming usage in every release. reply Dylan16807 17 hours agoparentprevBased on your bullet points here, I&#x27;m not sure what you find misleading?The headline doesn&#x27;t specifically say outside of games, but I don&#x27;t think that makes it misleading, especially because the \"for all\" makes it clear that it&#x27;s only about some cases. And people generally know that games pay.Being announced in advance, not affecting previous versions... none of that is implied otherwise by the headline. reply lholden 17 hours agorootparentThe title, especially in light of the stuff that went on with Unity, makes one think that this will affect a much wider group of people than it actually does.Unreal was never \"free for all\". For game development, there has always been revenue thresholds.The new licensing is around commercial use outside of game development, and will also be revenue threshold based. Meaning, just like with game development, if your project is making you money over X threshold, then the licensing kicks in.The title is misleading. reply Dylan16807 17 hours agorootparent> The title, especially in light of the stuff that went on with Unity, makes one think that this will affect a much wider group of people than it actually does.If you look at the title and think of a different company, that&#x27;s not the headline&#x27;s fault. It doesn&#x27;t even try to reference Unity.Also what I said in my previous comment is relevant here.> Unreal was never \"free for all\".I accept that it&#x27;s bad wording, but I don&#x27;t see how that misleads anyone unless you thought the engine was completely free. reply lholden 16 hours agorootparent\"no longer free for all\" implies that it was \"free for all\" and the change is making it no longer \"free for all\". In other words, the title is presenting information to the reader that is literally not true.For your personal reference, here is how the dictionary defines the word \"misleading\". (Cambridge and Merriam Webster, respectively)> causing someone to believe something that is not true> to lead in a wrong direction or into a mistaken action or belief often by deliberate deceit> to lead astray : give a wrong impressionI would say that the title manages to hit on all 3 of these definitions, with a possible note that perhaps the author \"misspoke\" rather than intentionally creating a deliberate deceit. reply Dylan16807 16 hours agorootparentI think the sense in which the title is being criticized for being misleading is not the interpretation where the engine was completely and entirely free. I&#x27;m sure a few people thought that by accident but it&#x27;s not what people are talking about when they bring up comparisons to Unity. That particular wording issue is not something that gets a top comment callout. There isn&#x27;t any motive to cause that particular confusion on purpose. reply pests 16 hours agorootparentprev> If you look at the title and think of a different company, that&#x27;s not the headline&#x27;s fault. It doesn&#x27;t even try to reference Unity.Things don&#x27;t happen in a vaccuum. The Unity fiasco is still fresh on everyone&#x27;s mind. For any company anywhere in the gaming sphere to change their prices so soon - is going to draw comparisons to Unity. The fact multiple people are discussing this with you should prove that. reply Dylan16807 16 hours agorootparentDo they need to explicitly contrast the situation with Unity in the headline to avoid being misleading?Headlines don&#x27;t have a lot of space!And as I said in a different comment, the subheading seems to address the main complaints, and in most situations you&#x27;d see the headline and the subheading together. reply pests 16 hours agorootparentI think the mere fact this is an engine license change happening so close to the Unity fiasco that yes, it is impossible to talk about this without automatically invoking thoughts of what Unity did. Some news and blogs will take advantage of this association and use it for clicks. reply Dylan16807 16 hours agorootparentAre you suggesting it&#x27;s impossible to avoid being misleading, or do you have a solution in mind? Since you didn&#x27;t really answer my question.If it&#x27;s the former then I think that absolves the author. reply pests 16 hours agorootparentI just read through this chain of comments and I do think there is a lot of talking past each other.I do not think the author was purposefully being misleading. I do not think they need absolution for anything. I think it may be interperted as misleading by some (as it did for the original commentor) based on the reader&#x27;s recent experiences with Unity and the latest drama; which is not a property of the article, the headline, or the author - but the reader. reply johnnyanmac 15 hours agorootparentprev>Headlines don&#x27;t have a lot of space!\"Unreal Engine starts charging for non-game development\".It&#x27;s not about space, and we know it&#x27;s all too easy to bury the lede and leave the internet to lash out as it is oft to do. But I don&#x27;t blame the author. I know in larger sites editorial will make the title without context of the writing independent of the contents in order to maximize traffic. reply ksec 29 minutes agorootparent>\"Unreal Engine starts charging for non-game development\".Exactly. Surprised that argument was coming from an 2010 account. reply starttoaster 16 hours agorootparentprev> If you look at the title and think of a different company, that&#x27;s not the headline&#x27;s fault. It doesn&#x27;t even try to reference Unity.Being aware of current events and how they may shape how people come to conclusions is a skill that not everybody possesses I suppose.The headline is most definitely misleading and poorly worded. A better headline would be \"Unreal licensing change targets tv production use cases\" or something like that.As the other user pointed out, Unreal Engine was never free for all. So wording it like this misleads the reader into thinking about the most commonly talked about use-case, video game development. And when they read \"no longer be free for all\" it leads them to believe that people that currently don&#x27;t pay for Unreal Engine may now have to. Hence the title being \"misleading.\" But hey, journalism is a skill that you work on over time. The editor should have caught this. reply taway1237 16 hours agorootparentprev> I don&#x27;t see how that misleads anyone unless you thought the engine was completely free.That&#x27;s how i understood it, was surprised, clicked the thread to find out more.Sample size of 1, but I was (maybe accidentally) misled. reply johnnyanmac 15 hours agorootparentIt was very much intentional, don&#x27;t blame yourself. Or I don&#x27;t know, blame yourself for not reading the article? Either way, this is why an accurate non-click sit headline is necessary, there are many many more people like you and some like to shout and spread misinformation on social media. reply aroo 17 hours agorootparentprev\"Unreal Engine will no longer be free for non-gaming companies\" is 100x less misleading. You are right in that technically speaking it&#x27;s not misleading, but to me it feels like it&#x27;s skirting the line of lying by omission. Obviously now with hindsight I can see how the \"for all\" changes the meaning, but it wasn&#x27;t obvious (at least to me). reply ezekg 17 hours agorootparentprevNo, the headline is blatantly trying to elicit a negative response towards Unreal i.r.t. Unity&#x27;s recent pricing change. reply Dylan16807 17 hours agorootparentBlatantly!Please explain how this headline connects to Unity at all?Yes we can assume a lot of people reading the headline will know about it... but I don&#x27;t see this blatant connection. Would they have to explicitly say it&#x27;s not like Unity in the headline to escape this?They even put \"non-gaming creatives\" in the subheading. Maybe whoever posted should have copied that? If you post the link on most social media you&#x27;ll automatically see the headline and the subheading. reply Fissionary 16 hours agorootparentprevThe headline assumes the point. If Unreal Engine will no longer be free for all, that implies that, right now, it is free for all, like e.g. Godot. Which is just emphatically untrue.It&#x27;s like saying (to use the classic example), \"I will no longer beat my wife.\" I never did, just like Unreal was never free for all. reply lwhi 17 hours agoparentprevYep, it seems pretty fair. reply zlg_codes 16 hours agoparentprevRather than make excuses for more revenue, I think it&#x27;s apparent that programmers cannot trust commercial engines or their business models to not up and change one day to suit Epic&#x27;s revenue.In-house development doesn&#x27;t suffer from this issue, and you&#x27;ll have full control over the code.Unreal doing this around the same time Unity pulls its shit isn&#x27;t a coincidence.As an aspiring game dev I kinda want nothing to do with these tools that want to jerk you around on pricing and aren&#x27;t absolutely crystal clear on costs.Blender is free and can do a ton. reply iyasu 15 hours agorootparent>In-house development doesn&#x27;t suffer from this issue, and you&#x27;ll have full control over the code.Proprietary engines suffer from plenty which you haven&#x27;t stated - can be a mess to read or understand; many hacks done to accomplish a certain feature because it helped ship X feature- tons of tribal knowledge. If you&#x27;ve worked with a proprietary engine before, you already know documentation will be lackluster and to little fault of the engineers - there&#x27;s so much to know about the engine that developers don&#x27;t have the time to chart out what everything does in the engine while pushing out fixes and features.Often, you need to poke the principal programmer who&#x27;s been with the studio since its inception to understand how a certain long-existing feature works. That&#x27;s a major point of weakness for the studio!- Engine limitations! Ask the bethesda devs on their experience building multiplayer for Fallout 76[0]. Imagine building multiplayer in an engine that has never needed to support it. That&#x27;s a huge refactor and a ton of time spent doing that when it&#x27;s already handled by Unreal Engine. Developers will need to maintain that engine in the future so the pain doesn&#x27;t stop after the game gets shipped!Your post sounds like someone who hasn&#x27;t worked in game development before. I advise listening to GDC talks, noclip documentaries, and more if you want to get a better understanding of what game development actually looks like. It&#x27;s a lot more complicated than \"your change in price policy makes me mad\" (by the way, most AAA studios already have contracts&#x2F;price agreements with these engines given the amount of revenue they generate for Unity&#x2F;Unreal).[0]:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=gi8PTAJ2Hjs reply zlg_codes 15 hours agorootparentGame development is not exclusive to business, but you are correct I have not worked for a firm to make a game. Nothing about that arrangement attracts me, especially given the abusive nature of the industry and the frequency that they go through crunch, lack any real worker protections, no unions, etc.The way AAA studios make games and do business puts me off as well, so pointing to them as an example doesn&#x27;t really change my outlook. I already don&#x27;t buy their games and disapprove of their business models.If I was interested in being exploited for my passion I would consider entering that industry, but as it stands I will be going solo dev.No game dev company out there seems to treat its staff well during a game&#x27;s development, so even if I wanted to work on a game as part of a team, I&#x27;d be looking at a poor work&#x2F;life balance and a stressful work environment. I&#x27;m too old for that kind of BS.If I can&#x27;t build and release the game myself, then it simply isn&#x27;t good enough to release. I cannot trust collaborators to not take control of my projects, nor would I entrust creative ideas to a for-profit entity without my cut.Long story short, I might work in the industry if it was a healthy one. Because it&#x27;s not, and I still want to make a game, it falls to me and only me to make it happen. That&#x27;s kind of comforting, knowing your failure or success ride on your own action instead of someone else&#x27;s. Nothing is more disappointing in a group project than failing because of someone else&#x27;s fuck up. reply iyasu 14 hours agorootparent>Nothing about that arrangement attracts me, especially given the abusive nature of the industry and the frequency that they go through crunch, lack any real worker protections, no unions, etc.I&#x27;d beg to differ on this point. Lots of changes have been made in game development culture including less crunch culture[0]. Worker protection&#x2F;unions aren&#x27;t exactly something that&#x27;s afforded to many white collar jobs in the first place, not sure why that would be an expectation here. Even so, there have been improvements to this - e.g. the Game Workers Alliance. I encourage you to ask developers this question today.>No game dev company out there seems to treat its staff well during a game&#x27;s development, so even if I wanted to work on a game as part of a team, I&#x27;d be looking at a poor work&#x2F;life balance and a stressful work environment. I&#x27;m too old for that kind of BS.There are game companies that do treat their staff well! I don&#x27;t think it&#x27;s fair to make blanket statements like this when there are a ton of studios with a ton of varying cultures. It&#x27;s not like solo development isn&#x27;t stressful or immune to crunch either, even if you choose your own hours. Solo development calls for highly varying skills - it&#x27;s one of those things you underestimate until you&#x27;ve actually tried it.>If I can&#x27;t build and release the game myself, then it simply isn&#x27;t good enough to release. I cannot trust collaborators to not take control of my projects, nor would I entrust creative ideas to a for-profit entity without my cut.Nothing good in this world gets built in a vacuum. A hyperbole, potentially (e.g. Stardew Valley, Rainworld), but game development really is a road best driven with a team - people to help out in different disciplines, lighten the load on others. Finding a good team is hard, but once you do, it&#x27;s hard to want to forgo them. I don&#x27;t think I can convince you on this front, but the vast majority of solo developers who don&#x27;t release a game should be proof enough.No hard feelings from me - I just wanted to clarify what the game industry is actually like today. The Kotaku articles can be frightening, but talking to people in the industry today and getting thoughts from different roles (e.g. producers, designers, engineers, QA, artists, etc.) and different industries within game dev (indie, AA, AAA studios,etc.) would help form a more informed opinion.[0]: https:&#x2F;&#x2F;twitter.com&#x2F;GrantPDesign&#x2F;status&#x2F;1402325020890652672 reply elteto 15 hours agorootparentprevI mean, why would you expect them not to charge you money for something they clearly spend tons of money in developing? They are a business.The bait and switch is real, but after N of them we have to start asking ourselves whose fault is it if we fall for the N+1th one. reply zlg_codes 15 hours agorootparentIn my case I haven&#x27;t fallen for anything, but this community seems to have a problem with pointing out it&#x27;s mostly businesses doing this behavior. If you stay away from commercial software, this crap disappears.It shouldn&#x27;t be normal to expect to be exploited imo. reply ksec 23 minutes agorootparent> but this community seems to have a problem with pointing out it&#x27;s mostly businesses doing this behavior.Wow. I was typing \"It is fairly recent behavior, at least it wasn&#x27;t like this before 2014.\"Then I realise that was nearly 10 years ago...... reply elteto 13 hours agorootparentprevIt was a rhetorical \"you\" ;) Businesses will do business things, I don&#x27;t think we should really be surprised when they decide to not subsidize everyone anymore.In other words, a company giving you a \"free\" product like Unreal should be assumed to be a loan that you will have to pay in the future. reply johnnyanmac 15 hours agorootparentprevIt isn&#x27;t a coincidence. But the situation is larger than unreal nor Unity. It&#x27;s the beginning of Q4&#x2F;end of Q3 and this tends to be when companies make new initiatives and it&#x27;s been no secret that big businesses&#x27;s low interest rate borrowing has been done for months now.Same reason why we have yet another flurry of layoffs happening.>In-house development doesn&#x27;t suffer from this issue, and you&#x27;ll have full control over the code.Yet many AAA studios have at least dabbled with Unity&#x2F;Unreal. A few have switched entirely. Engine programmers aren&#x27;t cheap to keep in house and it&#x27;s much easier to have entry level workers come in with existing engine knowledge than teaching them on the job. Even if this all feels shitty, full control for a business may not necessarily be the answer.>As an aspiring game dev I kinda want nothing to do with these tools that want to jerk you around on pricing and aren&#x27;t absolutely crystal clear on costs.I wish you the best of luck. That&#x27;s my endgame. But I&#x27;m not at a point where I can disengage from big corporate and I have bills to pay. I&#x27;m laying the groundwork slowly but maybe in a decade.>Blender is free and can do a ton.Blender isn&#x27;t a game engine. And lender&#x27;s attempt at making a game engine is exactly why it can be harder to switch from big corporate than it should be. It&#x27;s a lot of moving parts and is hard to maintain. Open source&#x27;s biggest weakness is interest, since there is no financial incentive to keep supporting a free product.That said, look into UPBGE as a spiritual successor if you rely a lot on Blender for development. reply zlg_codes 15 hours agorootparentI am in 2D for now, so anything SDL based is enough. But, part of what&#x27;s put me off of 3D is the business side. Modeling tools are difficult to use and take years to learn adequately. I&#x27;m not interested in paying for a sub while I&#x27;m learning, and terms in a license that are subject to change do nothing to inspire confidence in any particular solution. This is a social and ethical problem imo.As you pointed out, doing it correctly requires experienced developers who will stick around. I think that&#x27;s a more rewarding and better cost to spend money on. At least the worker won&#x27;t try to modify the terms of what you&#x27;re building on.I&#x27;ll check out that project sometime. 3D is still a ways out for me but any libre software that can make it easier to learn sounds great. reply raytopia 18 hours agoprevHonestly it makes sense. I was always a little confused that non-gamedevs had to pay 0. Of course that could&#x27;ve also just been the plan to get VFX and other industries onto Unreal Engine so Epic Games could start charging them later.I&#x27;m also confused how Epic Games has become unprofitable suddenly. I think I read somewhere it was in the last 10 weeks but I could be wrong about that. reply to11mtm 17 hours agoparentIf I had to guess, it&#x27;s a few factors.They probably overhired during 2020-2022 period like everyone else did.Additionally, AFAIR there were tax rule changes going in play this year that would change the accounting balance sheet. [0]But, the biggest one in my mind, realities of inflation&#x2F;shrinkflation are setting in. I&#x27;d have to guess that my food cost has gone up enough that I could have theoretically purchased at least one or two skins with the extra money I&#x27;m spending on the same or less food [1]. I think this is a factor that is easy to be insulated from in tech, however my friends in various luxury service industries are feeling the pinch; folks cutting down on \"spa days\" and fancy restaurant trips.[0] - I know earlier this year a bunch of changes around how Capital Expenditures&#x2F;R&D were allowed to be deducted, and in some cases it would lead to a large increase in the cost of engineers.[1] - I don&#x27;t do Fortnite so I have no clue what stuff costs, broadly speaking however 10-20$ a week is a light estimate. reply SeanAnderson 17 hours agoparentprevI don&#x27;t know about suddenly, but Fortnite makes more money for Epic than Unreal Engine and Fortnite&#x27;s numbers are going down. Seems pretty easy to extrapolate from there that dials need to get turned until innovation occurs. reply Manfred 18 hours agoparentprevThe strategy is to worm your product into companies and make people comfortable with (or depend on) your tools. When there is enough adoption, you slide in and claim a piece of the pie. reply slowmovintarget 17 hours agorootparentWhich is a good strategy when you don&#x27;t do it retroactively, and you do give time to switch. If your product is best of breed (which UE5 is) it would make sense. reply yazzku 17 hours agorootparentprevMind if I slytherin? reply Krutonium 18 hours agoparentprevIt&#x27;s not that they suddenly became unprofitable, it&#x27;s that they&#x27;re (partially) owned by Tencent, and Tencent is calling in their dues. Epic took their money to try and unseat Valve, which clearly did not work. Now the economy is taking a dip, so they need money. reply SeanAnderson 17 hours agorootparentWhy do you feel this is Tencent&#x27;s doing if they&#x27;re not the majority shareholder? reply moe_sc 14 hours agorootparentGoing with the theory this is caused by a shareholder:They own 40%, the only bigger stakeholder beeing Tim Sweeney, Epics CEO and founder. [1]Assuming Sweeney wouldn&#x27;t be the one causing it, Tencent is the party that would be able to cause the most financial headaches.[1] https:&#x2F;&#x2F;www.fool.com&#x2F;investing&#x2F;how-to-invest&#x2F;stocks&#x2F;how-to-i... reply 3seashells 16 hours agoparentprevThey now have to pay by include tictacto to the credit page. reply justin66 17 hours agoprevBurying this six paragraphs deep seems a little douchey:Sweeney has now clarified that there will be minimum revenue thresholds for commercial projects that have to pay for a subscription and that student and educator use of Unreal Engine will remain free. reply tomschwiha 18 hours agoprevThe headline may be better less clickbaity by clarifying \"not free anymore for vfx or movie users\". reply SideburnsOfDoom 18 hours agoparentMovie VFX budgets are often in tens of millions anyway. Not sure that \"not free\" will kill them.I&#x27;ve heard it sad that \"The three most expensive are wars, space programs and making movies\". reply johnnyanmac 15 hours agorootparentI&#x27;m not worried at all about Disney paying more licenses. I&#x27;m honestly shocked to realize that the Madelorian was made and the engine behind it got nary a penny for it. reply SideburnsOfDoom 14 hours agorootparentThe engine running on the virtual set screens (1) is a small part of the whole Mandolorian production.But yeah, \"a small part\" of a few $10 million budget would not trivial to Unreal.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;StageCraftI see that I accidentally a word above. It&#x27;s the word from the quote that I wasn&#x27;t sure of ... \"The three most expensive - One of (endeavours, enterprises, occupations, hobbies, pastimes, things) are\"? reply CyberDildonics 14 hours agorootparentprevThey didn&#x27;t say it \"will kill them\" or anything about that, they were just correcting the title. reply automatoney 18 hours agoprevHmmmm just given the recent Unity news, maybe this headline is a bit misleading as it seems to be focused on VFX users, and not game developers? Maybe \"Unreal... be free for animators\"? reply endisneigh 18 hours agoprevWhy should VFX people not have to pay when gamedevs did? There&#x27;s no winning with people - ads bad, paying bad. reply ravenstine 17 hours agoparentI&#x27;m guessing because engines like Unreal have game developers in the bag. VFX, on the other hand, has been a long term pursuit of Unreal and can have a large payoff for them. Based on some second hand insider knowledge I have, the VFX and animation industries are all over the place in terms of tooling, and a lot of pipelines are more or less bass-ackwards, especially when it comes to the pre-visualization stage of production. Even big studios are relying on tools that would appear \"legacy\" to many software engineers and are inferior to game engines in a lot of ways. The status quo often remains because these studios are already making enough money and have little incentive to address their internal bureaucracy that prevents them from making legitimate improvements to their pipelines. There are plenty of technical directors and artists out there pushing to use things like Unreal Engine, but these efforts often go nowhere for a variety of reasons. I know of at least one major animation studio that pondered over utilizing Unreal for over a decade, and there&#x27;s another major studio I&#x27;m aware of where they&#x27;re trying to use Unreal but the organizational support just isn&#x27;t there.Another problem I see in adoption of Unreal in animation is that the entertainment industry historically hasn&#x27;t valued its engineers in the same way that Silicon Valley does. Unless you&#x27;re working directly for a company like Unreal or Autodesk, why would a software engineer go work on some shitty duct-taped pipeline for a studio that will inevitably pay them less and make them work more hours, unless said engineer is particularly enamored with movies or shows? Based on what I know, I believe that the entertainment industry struggles to find and hold on to engineering talent, and not in the cliche way we hear from every company out there.However, if Unreal reaches the same level of ubiquity and vendor lock-in within VFX that Autodesk has, for instance, then it would be a humongous cash cow for them. They want to keep their engine free to that industry for that reason, and it&#x27;s a big incentive considering the exorbitant costs typical to VFX software. reply nullptr_deref 18 hours agoprevThis would probably drive all the hobbyist to learn something open source like Godot, wouldn&#x27;t it?This would mean Godot would be the thing worth investing for. reply dragonwriter 18 hours agoparentNo, it doesn&#x27;t affect game developer hobbyists (actually, if anything, it makes them more secure, since Unreal would have a broader pool of paying clients and less beed to squeeze low-revenie games before they can afford it.)Unless you mean, e.g., movie-making hobbyists where they go from never having to pay to having some (probably, as currently exists for games, based on a revenue threshold) some condition where they would have to pay, which might drive some of them to a different toolchain, though if it is setup similar to gaming, it won&#x27;t affect most hobbyists unless they have way unexpected success, so probably shouldn&#x27;t rationally affect hobbyiat choices much. reply Snafuh 17 hours agorootparentTim Sweeney confirmed on Twitter there will be a revenue threshold just like for game dev. Small time studios or individuals won&#x27;t have to pay unless they make money.Lots of enterprise customer paid before already anyway for Epic&#x27;s (questionable) support reply zlg_codes 16 hours agorootparentprevWhat incentives are there to learn Unreal if the money you make with it will be dipped into? That percentage is subject to change, too.I don&#x27;t want the success of my game to ride on paying my game&#x27;s protection&#x2F;engine licensing fee. It&#x27;s hard enough to make money with a game and Unreal makes it harder. reply jlarocco 15 hours agorootparentLooking at it from the otherside, what incentive is there for them to pay teams developers to build Unreal Engine, and then let you use the technology for free and get nothing when your product takes off?By all means, if you don&#x27;t like the terms don&#x27;t use the engine, but it&#x27;s hard to take it seriously when you make it sound as if you&#x27;re doing them a favor using their engine for free. reply zlg_codes 15 hours agorootparentOh I understand it&#x27;s a business. I&#x27;m just making it clear why I&#x27;m not biting, on the off chance Epic employees are here.Businesses should study their markets. Sadly, many people in the market are completely fine giving away things to get shiny, even giving up revenue. So until standards of customer treatment rise, we&#x27;ll be dealing with various levels of SaaS.Except some of us just aren&#x27;t buying anything, due to the terms and lacking perceived value.If Unreal works for you that&#x27;s fine. Why do I have to like or buy it? reply nrb 15 hours agorootparentprevUnreal can make your game possible in the first place depending on your required functionality, timeline, and budget. That can be a mightily powerful incentive. reply zlg_codes 15 hours agorootparentWhat does Unreal provide that other engines can&#x27;t? reply drunkan 13 hours agorootparentAn unreal amount more. No - seriously. It practically has everything you need to build a game. I guess a clear and easy way to learn it though.. that it cannot seem to provide. reply donio 15 hours agorootparentprevFor everyone else it indicates that Epic is willing to change the terms on you when it suits them. reply croes 18 hours agoparentprevIt does not affect game developers, but only VFX artists who have never had to pay anything so far. reply acomjean 16 hours agoparentprevI think this doesn&#x27;t change the equation for hobbyist&#x2F; game developers.Unreal is starting to get traction as a 3d model tool (free unlike the pricey: Cinema4d or Maya). It was used on set for \"virutual rooms\" used in productions like the madolorian. This use of Unreal wasn&#x27;t being charged for.. But now it is.But Godot seems to have a lot of traction for game dev anyway. It seems to be a lot of places.Unreal is a big giant tool, with tons of leavers. They have a robust marketplace of assets and such that makes life easier for companies and such. reply rockemsockem 17 hours agoparentprevNo, since it won&#x27;t affect hobbyists per the CEO&#x27;s tweet in the article and unreal is, as I understand it, far ahead of everything else. reply Thaxll 17 hours agoparentprevAs if godot was used where Unreal is used ... reply lamontcg 17 hours agoprevSeems like every company these days are trying to figure out how to increase the rents that they collect. No actual value add, just trying to optimize to make that top line number go up. It feels very end-of-business-cycle. reply diggan 17 hours agoparentNot sure you could argue that Unreal Engine hasn&#x27;t provide any actual value, it basically helped spawn a whole new area in film production via the whole \"Virtual Production Sets\" that you can build with Unreal Engine. reply lamontcg 17 hours agorootparentI&#x27;m saying this pricing change doesn&#x27;t add any value. I would be literally impossible to argue that UE doesn&#x27;t add any value, which is why I&#x27;m not making that argument. reply diggan 16 hours agorootparentI&#x27;d say they already added the value but never charged for it, until now. Seems fair to me. reply lamontcg 15 hours agorootparentWhich still means that this change doesn&#x27;t add any value. I&#x27;m uninterested in if it is \"fair\" or not. reply diggan 15 hours agorootparentSo if someone builds something of value but doesn&#x27;t charge for it until 2 years later, you&#x27;d say that they aren&#x27;t providing value with this change?I mean, I get what you mean, but seems needlessly pedantic to just \"forget\" the thing that is being charged for and because there was no other changes made with the new price being added, the change itself isn&#x27;t adding any value.Regardless, I get what you mean, no value for you that they start charging. True. reply lamontcg 14 hours agorootparentWhat I&#x27;m saying is that in the aggregate that as more companies are doing that it begins to look like the proverbial \"rearranging the deck chairs on the titanic\" or \"everyone looking for their seats before the music stops\". This is because macroeconomically everyone&#x27;s sales numbers are someone else&#x27;s expenses. You can get down into the weeds where even though this is just resource allocation of capital that it is doing useful work in the economy to correct a misallocation of capital, but my point is more that this is a late-business cycle signal. Businesses are looking at their finances and looking at the interest rate environment and trying to squeeze more sales out of their existing customers. That is an indicator that the financials at Epic Games probably weren&#x27;t trending in a good direction. And I&#x27;m unsurprised to find this fairly recent news article:https:&#x2F;&#x2F;www.cnbc.com&#x2F;2023&#x2F;09&#x2F;28&#x2F;epic-games-is-eliminating-16...Even with the success of UE and Fortnite they&#x27;re still a money losing business. They&#x27;ve probably been surviving off of cheap debt since 2009 but that has now ended. Multiply that by all the businesses in the Russell 3000 or whatever that have been doing exactly the same thing. replyalmatabata 14 hours agoparentprevIn this case it went from completely free to pay something. The completely free tier clearly could not last. The company has to pay the bills somehow. They wanted to gain market share in the sector and now that they think they want to recoup some of the cost.You have cases where companies jack up the prices out of pure greed but i would not count this as one. Why should studio not pay a license fee for high quality software like the unreal engine? reply lamontcg 14 hours agorootparentPlease read the other thread completely and particularly my last comment.I&#x27;m making a macroeconomic comment, you&#x27;re assuming I&#x27;m arguing about the morals of the microeconomic decision making here.Arguing about the morality or ethics or greed involved isn&#x27;t useful. Just like it wasn&#x27;t useful to argue about greed involved in our recent spike of inflation.This fairly large company is still just another cog in the macroeconomic machine and their behavior is almost deterministic.The more interesting question to me is what it indicates about the macro climate and if there&#x27;s stormclouds on the horizon or not. reply AlexandrB 15 hours agoparentprevYup. A good time for open-source alternatives to re-assert themselves in the market. Low interest rates made commercial software unnaturally cheap for a long time.Will also be interesting to see how well subscription-based software fares when people start tightening their belts due to inflation and rising interest rates. reply lamontcg 14 hours agorootparentYes, someone who gets what I&#x27;m talking about. reply dark-star 17 hours agoprevUnreal Engine was never \"free for all\"... reply croes 18 hours agoprev>That means that while the developers of big-selling games pay royalties, those who use Unreal Engine for film making and other uses pay nothing.Understandable but could introduce a revenue limit too. reply wlesieutre 18 hours agoparentArticle does say \"There will be minimum revenue thresholds for commercial projecrs, and student&#x2F;educator use will remain free\" reply croes 17 hours agorootparentMissed that part, thanks reply dragonwriter 18 hours agoparentprevThey have a revenue limit ($1M) but also currently only apply that to people who use the engine code in the delivered product (which is apprximately gaming uses, but could include some other interactive non-gaming use), not people who use the engine to produce things like movies that are distributed without the engine code. reply croes 18 hours agorootparentThat&#x27;s what I mean, a revenue limit for VFX would be good too reply frameset 16 hours agoprevWhat non-zero interest rates does to a company. reply dang 14 hours agoprevRecent and related:Unreal Engine Pricing Changes - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37774917 - Oct 2023 (51 comments) reply JamesLeonis 18 hours agoprevEpic raised nearly $2 Billion dollars (yes, with a B) last year [0]. A week ago they laid off staff [1]. Now they are changing the pricing rules to bring in more revenue.Enshittification[0]: https:&#x2F;&#x2F;techcrunch.com&#x2F;2022&#x2F;04&#x2F;11&#x2F;epic-2b-nearly-32b-valuati...[1]: https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2023-09-28&#x2F;epic-game... reply lolinder 17 hours agoparentUsing the word \"enshittification\" is a great way to get a comment pinned to the top of an HN thread, but this is not that.This is Cory Doctorow&#x27;s definition of enshittification [0]:> Here is how platforms die: first, they are good to their users; then they abuse their users to make things better for their business customers; finally, they abuse those business customers to claw back all the value for themselves. Then, they die.Note that he&#x27;s talking about platforms, specifically middlemen. For Doctorow&#x27;s enshittification to be a thing, there has to be a dichotomy between \"users\" and \"business customers\". Enshittification is the cycle of luring in users to make yourself valuable to your real customers (the \"business customers\"), then abusing those users to make your business customers even happier, then abusing your business customers to extract the absolute largest amount of value for yourself, then dying because you forgot who payed the bills.Unreal Engine is not a platform in this sense. Epic doesn&#x27;t have \"users\" that it needs to lure in in order to appease \"business customers\", it just has business customers. It brought a lot of business customers in by offering the product for free for non-gaming use cases in order to demonstrate to those non-gaming business customers that it was actually a viable product for their needs. Now that they don&#x27;t need to make that case any more, they&#x27;re doing what every business eventually needs to do and actually charging for the product.[0] https:&#x2F;&#x2F;pluralistic.net&#x2F;2023&#x2F;01&#x2F;21&#x2F;potemkin-ai&#x2F; reply JamesLeonis 15 hours agorootparentHere&#x27;s Epic&#x27;s Enshittification Journey as a platform. Let it be known that it didn&#x27;t have to be this way. Epic (Mega)Games was a mild-mannered game development company that sold a popular engine used in many AAA games.Act I; Users lured, moats built: Epic pivoted towards Games-as-a-Service. They took investment [0] and guidance from Tencent to the tune of 40% of the company. Fortnite and the F2P Unreal Tournament reboot were developed and released in this timeframe. These free titles would bring in the gamers into the Epic ecosystem.Act II; Users exploited, business customers courted: Fortnite adds subscriptions in 2017 (Battle Pass Season 2 [1]) and makes money hand-over-fist. At the same time, the Tencent deal allowed them to relicense their engine away from the high upfront cost to \"Free\" until a certain point [2]. They also charged a far less cut than Steam, used hundreds of millions of dollars of their own investment to bring other developers to the ecosystem, as well as publishing a number of games that used the engine. This lured developers to the platform with their own dreams of Fortnite revenues. More investment poured in.Relating this back to the original article here, in 2019 Epic gave a grant of $1.2 million to Blender [3] to develop their tools to integrate Unreal Engine, including those for visual artists and film.Act III; Everybody is shafted: See my original comment.[0]: https:&#x2F;&#x2F;www.investopedia.com&#x2F;news&#x2F;how-tencent-changed-fortni...[1]: https:&#x2F;&#x2F;fortnite.fandom.com&#x2F;wiki&#x2F;Season_2[2]: https:&#x2F;&#x2F;fortune.com&#x2F;2015&#x2F;03&#x2F;03&#x2F;epic-games-unreal-tech-free&#x2F;[3]: https:&#x2F;&#x2F;www.blender.org&#x2F;press&#x2F;epic-games-supports-blender-fo... reply anonylizard 18 hours agoparentprevIts not obvious at all how this is enshittification.UE5 was previously provided for free in non-video game contexts, as they clearly were trying to expand their presence in say film production. Now they&#x27;ve succeeded, they are charging for it, what is so unfair about it? Are they expected to provide the engine for free?UE5 is also constantly trying intensive innovation. So the product quality is going up, not going down.Unity was bombed because it was trying some inane pricing model (imagine UE5 charging moviemakers by number of viewers). And the fact that Unity Engine itself was being heavily neglected.And fundraising is not relevant when their core business, Fortnite, is declining. Sorry fundraising != charity for employees. reply londons_explore 17 hours agorootparent> imagine UE5 charging moviemakers by number of viewersActors commonly demand a percentage of revenue. The main software package used for all the special effects demanding the same doesn&#x27;t seem unreasonable. reply Arelius 17 hours agorootparentExcept UE5 is far from the main software package used for all the special effects. reply londons_explore 16 hours agorootparentThey&#x27;ll just have to price appropriately... reply sbarre 17 hours agorootparentprev> UE5 was previously provided for free in non-video game contexts, as they clearly were trying to expand their presence in say film production. Now they&#x27;ve succeeded, they are charging for it, what is so unfair about it?The problem here is that \"providing for free\" to gain adoption and then suddenly charging is a bit of a rug-pull.The same argument was made for Unity, it&#x27;s not the customer&#x27;s job to make your business model work.> Are they expected to provide the engine for free?If you choose to grow your market share in an unsustainable way (like giving your product away for free), and then later on go \"oh shit we can&#x27;t keep doing this!\" then you should expect that some of the customers who adopted your product based on the previous terms will be unhappy with this switch.Many might be fine with it, but the idea that everyone should just accept this switch is bullshit.Lots of companies are clear up front that their product will be free for some time (like during a beta or early access period) but that customers should expect to be charged at some point in the future.I&#x27;m not sure this is what Epic did. But I don&#x27;t follow this space closely so maybe they did set that expectation? Some other commenters seem to be saying this was \"expected\".. reply Guvante 17 hours agorootparentUnity was different because the pricing was insane for F2P titles. Some successful titles only manage $0.50&#x2F;install, going from 0 to 40% revenue share was insane.Way more importantly making it retroactive was unheard of. Unity even had promised to support \"pick your license\" for released titles in perpetuity but then during this change said \"we never said the runtime was free in perpetuity\".Charging more for your product isn&#x27;t great but it always happens.Also on that topic Unity got started as the \"no revenue sharing\" option and was paid for by very expensive per seat costs. So there was a bit of \"you are double dipping\" feeling too.In this case Unreal is charging for a new market is the goal which makes sense.Certainly the bait and switch of free now not is a bit sour but how sour depends on the cost. reply Retric 17 hours agorootparentprevProviding for free is hardly going to continue forever. This will end should be a basic assumption whenever you start using a free product.Anyway, current versions are unaffected it’s only people who want to keep adopting new versions which will face the changes. reply Night_Thastus 18 hours agoparentprevI don&#x27;t really see this as \"enshittification\". This is completely expected and people knew for years something like this was coming.Epic has been trying to use the money from Fortnite&#x27;s success to build a more stable platform. They&#x27;ve dumped endless amounts of Fortnite money on paying developers for Epic exclusivity, lower cuts from developers, developing their storefront, developing Unreal Engine, etc.This was not done out of the goodness of their hearts. They wanted to see a return. They needed to break into the market more and now they have.Now that they&#x27;ve firmly planted themselves with a lot of games on EGS, and a lot of games using Unreal, they want that return on investment. Not surprising. reply rockemsockem 17 hours agoparentprevNo. This targets large shops not personal use or small projects. It&#x27;s right there in the article..... reply whimsicalism 18 hours agoparentprevor just profit taking?I wouldn’t call raising prices enshittification. reply c7DJTLrn 17 hours agoparentprevLayoffs are often unrelated to a company&#x27;s financials. They are a way to increase margins. See it as you will but they have no obligation to employ people they don&#x27;t need. reply marksmith2996 17 hours agoparentprevEpic makes money therefore film studios should get free money? reply cjohnson318 17 hours agoparentprevIt&#x27;s unreal that a software product like that was available for free in the first place. reply ChrisArchitect 18 hours agoprev[dupe] reply ChrisArchitect 18 hours agoparentSome more discussion earlier: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37774917 reply AequitasOmnibus 18 hours agoprev [–] > Speaking at Unreal Fest 2023, Epic Games CEO Tim Sweeney said Unreal Engine would become “a licensable piece of software like Maya or Photoshop” with a subscription-based pricing model.SAAS is rent-seeking at its worst. It’s predatory, anti-consumer and downright annoying. I hope this backfires on Epic. reply nonethewiser 18 hours agoparentSAAS pays for continued development and support. One upfront license fee returns us to the Microsoft Office 13, 15, 20 etc. world. Marginal differences, little to no support, and new releases for the sake of new revenue. SAAS is far better aligned to customer and business interests. reply cool_dude85 17 hours agorootparentIn other words, the developer has to produce a worthwhile feature to charge me for it? I don&#x27;t have to pay for Office 20 when it&#x27;s the same as Office 13 which I already own?Sign me up. reply zlg_codes 15 hours agorootparentprevWhich interests are those, and how is a subscription better than a one-time purchase?I smell dishonesty. SaaS is aligned solely to the business&#x27;s interest. They control the code, they control whether you even access it after paying, etc. The customer gets no rights or considerations, so it&#x27;s a one-sided transaction.Just like Netflix and friends. I only do one subscription service and it&#x27;s to play online with my niece and nephew. The rest of the subscription world can suck it, they want rent for Internet-bound software that spies and tells on you so they can sell data on top of your subscription.Business cannot get software sales correct. Game makers did back in the 80s, 90s, and 00s before DLC became a thing.One purchase, one perpetual license, no phoning home. Too hard to do for the modern commercial developer, it seems.So, which interests of mine would a SaaS satisfy? reply tomschwiha 18 hours agoparentprevIn contrary I like PhpStorm (and other Jetbrains software) which has a nice SAAS license. You always own the old versions or you keep subscribed and pay for upgrades. With evolving software (aka never finished) someone has to pay for the upgrades. In the best case its the existing user base. But true, most SAAS is just cash cow milking. reply pxc 17 hours agorootparentI&#x27;d say that PhpStorm doesn&#x27;t really qualify as SaaS.Not all software subscriptions are SaaS. See, e.g., here: https:&#x2F;&#x2F;www.dataversity.net&#x2F;saas-and-subscription-complement...SaaS means someone else runs the software and your access to it is mediated by their service (usually a networked service).Some SaaS tests:If you can keep running it when your subscription runs out, it&#x27;s not SaaS. If it runs on your own hardware, it&#x27;s not SaaS.This concept creep elides the extraordinary level of alienation inherent in SaaS, which is exceptional even for proprietary software. This overly broad usage of the term can make the tradeoffs involved¹ in actual SaaS seem less severe than they are.--1: https:&#x2F;&#x2F;www.gnu.org&#x2F;philosophy&#x2F;who-does-that-server-really-s... reply tomschwiha 17 hours agorootparentMakes sense, thank you for clarifying. reply ukd1 18 hours agoparentprevWhat do you propose? They should continue to allow everyone outside of gaming to use it for free? reply PurpleRamen 17 hours agoparentprevSeems fair to let those pay who make significant money with your product. Especially when they screw over other themselves with their creative accounting. At least as long as there are significant costs for the product, like ongoing development. reply raytopia 18 hours agoparentprevIt&#x27;s only for non gamedevs who were paying $0 for the engine. reply tomcam 17 hours agoparentprevWhat would you do to allow them to not lose money? reply whimsicalism 18 hours agoparentprev [–] sass is the only business model that works well for continuously developed software replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Epic Games has announced a switch to a subscription-based pricing model for Unreal Engine, their graphics engine, directed at industries beyond gaming, affecting use for VFX or animation.",
      "Unlike the previous royalty model which only applied to projects earning over $1 million in revenue, this new model could potentially impact independent filmmakers and non-professional users.",
      "While pricing details are yet to be shared, Epic Games CEO Tim Sweeney assured that the new rates won't be exorbitant or unusually cheap; student and educator access to Unreal Engine will continue to be free."
    ],
    "commentSummary": [
      "Unreal Engine has modified its licensing model and will no longer be free for all users. It now incorporates revenue thresholds for large commercial use outside of game development.",
      "The article argues that changes, although widely debated regarding fairness and impact on industries, are not as dramatic as they seem and could have been anticipated earlier.",
      "The author discusses the pros and cons of the subscription-based model and the necessity of a sustainable business model in the context of the financial situation of Epic Games."
    ],
    "points": 157,
    "commentCount": 114,
    "retryCount": 0,
    "time": 1696605859
  },
  {
    "id": 37795652,
    "title": "23andMe scraping incident leaked data on 1.3M users",
    "originLink": "https://therecord.media/scraping-incident-genetic-testing-site",
    "originBody": "This website stores cookies on your computer. These cookies are used to improve your website experience and provide more personalized services to you, both on this website and through other media. To find out more about the cookies we use, see our Privacy Policy. Accept Leadership Cybercrime Nation-state People Technology Mobile App About Podcast Contact Subscribe IMAGE: 23ANDME Jonathan Greig October 6th, 2023 News Cybercrime Privacy Get more insights with the Recorded Future Intelligence Cloud. Learn more. 23andMe scraping incident leaked data on 1.3 million users of Ashkenazi and Chinese descent Genetic testing giant 23andMe confirmed that a data scraping incident resulted in hackers gaining access to sensitive user information and selling it on the dark web. The information of nearly 7 million 23andMe users was offered for sale on a cybercriminal forum this week. The information included origin estimation, phenotype, health information, photos, identification data and more. 23andMe processes saliva samples submitted by customers to determine their ancestry. When asked about the post, the company initially denied that the information was legitimate, calling it a “misleading claim” in a statement to Recorded Future News. The company later said it was aware that certain 23andMe customer profile information was compiled through unauthorized access to individual accounts that were signed up for the DNA Relative feature — which allows users to opt in for the company to show them potential matches for relatives. “We do not have any indication at this time that there has been a data security incident within our systems. Rather, the preliminary results of this investigation suggest that the login credentials used in these access attempts may have been gathered by a threat actor from data leaked during incidents involving other online platforms where users have recycled login credentials,” they said. “We believe that the threat actor may have then, in violation of our terms of service, accessed 23andme.com accounts without authorization and obtained information from those accounts. We are taking this issue seriously and will continue our investigation to confirm these preliminary results.” A screenshot from the posting of 23andMe data on the BreachForums site. When pressed on how compromising a handful of user accounts would give someone access to millions of users, the spokesperson said the company does not believe the threat actor had access to all of the accounts but rather gained unauthorized entry to a much smaller number of 23andMe accounts and scraped data from their DNA Relative matches. The spokesperson declined to confirm the specific number of customer accounts affected. Anyone who has opted into DNA Relatives can view basic profile information of others who make their profiles visible to DNA Relative participants, a spokesperson said. Users who are genetically related can access ancestry information, which is made clear to users when they create their DNA Relatives profile, the spokesperson added. Once the company has more information from the investigation, they said, it will determine the best approach to notifying any impacted customers. ‘A botch job’ The incident shows how a company's customer data can be vulnerable even if intruders don't get deep into its network. A researcher approached Recorded Future News after examining the leaked database and found that much of it looked real. The researcher spoke on condition of anonymity because he found the information of his wife and several of her family members in the leaked data set. He also found other acquaintances and verified that their information was accurate. The researcher downloaded two files from the BreachForums post and found that one had information on 1 million 23andMe users of Ashkenazi heritage. The other file included data on more than 300,000 users of Chinese heritage. The data included profile and account ID numbers, names, gender, birth year, maternal and paternal genetic markers, ancestral heritage results, and data on whether or not each user has opted into 23andme’s health data. “It appears the information has been scraped from user profiles which are only supposed to be shared between DNA Matches. So although this particular leak does not contain genomic sequencing data, it’s still data that should not be available to the public,” the researcher said. “23andme seems to think this isn’t a big deal. They keep telling me that if I don’t want this info to be shared, I should not opt into the DNA relatives feature. But that’s dismissing the importance of this data which should only be viewable to DNA relatives, not the public. And the fact that someone was able to scrape this data from 1.3 million users is concerning. The hacker allegedly has more data that they have not released yet.” The researcher added that he discovered another issue where someone could enter a 23andme profile ID, like the ones included in the leaked data set, into their URL and see someone’s profile. The data available through this only includes profile photos, names, birth years and location but does not include test results. “It’s very concerning that 23andme has such a big loophole in their website design and security where they are just freely exposing peoples info just by typing a profile ID into the URL. Especially for a website that deals with people's genetic data and personal information. What a botch job by the company,” the researcher said. “I’ve tried contacting 23andme however they keep denying that there is anything wrong and are replying with cookie cutter responses. I don’t know how to prove this without doxing myself. But this is pretty serious and no one is taking it seriously.” The security policies of genetic testing companies like 23andMe have faced scrutiny from regulators in recent weeks. Three weeks ago, genetic testing firm 1Health.io agreed to pay the Federal Trade Commission (FTC) a $75,000 fine to resolve allegations that it failed to secure sensitive genetic and health data, retroactively overhauled its privacy policy without notifying and obtaining consent from customers whose data it had obtained, and tricked customers about their ability to delete their data. Tags genetic testing Privacy Data breach dark web scraping Previous article Next article Victims reported $2.7 billion in social media scam losses since 2021: FTC Rhysida ransomware gang claims attacks on governments in Portugal, Dominican Republic JONATHAN GREIG Jonathan Greig is a Breaking News Reporter at Recorded Future News. Jonathan has worked across the globe as a journalist since 2014. Before moving back to New York City, he worked for news outlets in South Africa, Jordan and Cambodia. He previously covered cybersecurity at ZDNet and TechRepublic. Victims reported $2.7 billion in social media scam losses since 2021: FTCOctober 6th, 2023 Snap AI chatbot scrutinized by UK watchdog over how it processes kids’ dataOctober 6th, 2023 China-based spies are hacking East Asian semiconductor companies, report saysOctober 6th, 2023 Florida court pauses many proceedings following cyberattackOctober 6th, 2023 Suspected China-linked hackers target Guyana government with new backdoorOctober 5th, 2023 Privacy nonprofit calls on FTC to investigate Grindr’s data practices October 5th, 2023 Cybercrime gangs now deploying ransomware within 24 hours of hacking victimsOctober 5th, 2023 Belgian intelligence fears Chinese tech giant Alibaba may be spying on logisticsOctober 5th, 2023 From AI with love: Scammers integrate ChatGPT into dating-app toolOctober 5th, 2023 NEAR-SPACE IN CHINA’S MILITARY STRATEGY: STRATEGIC RECONNAISSANCE, PRECISION STRIKE, AND BATTLEFIELD ADVANTAGE NEAR-SPACE IN CHINA’S MILITARY STRATEGY: STRATEGIC RECONNAISSANCE, PRECISION STRIKE, AND BATTLEFIELD ADVANTAGE MULTI-YEAR CHINESE APT CAMPAIGN TARGETS SOUTH KOREAN ACADEMIC, GOVERNMENT, AND POLITICAL ENTITIES MULTI-YEAR CHINESE APT CAMPAIGN TARGETS SOUTH KOREAN ACADEMIC, GOVERNMENT, AND POLITICAL ENTITIES EMPIRE DRAGON ACCELERATES COVERT INFORMATION OPERATIONS, CONVERGES WITH RUSSIAN NARRATIVES EMPIRE DRAGON ACCELERATES COVERT INFORMATION OPERATIONS, CONVERGES WITH RUSSIAN NARRATIVES CONVERGING NARRATIVES ON HAWAII WILDFIRES ADVANCE DIFFERENT INFLUENCERS’ OBJECTIVES CONVERGING NARRATIVES ON HAWAII WILDFIRES ADVANCE DIFFERENT INFLUENCERS’ OBJECTIVES MALIGN NARRATIVES OPPOSE “THE VOICE” AHEAD OF AUSTRALIA’S REFERENDUM MALIGN NARRATIVES OPPOSE “THE VOICE” AHEAD OF AUSTRALIA’S REFERENDUM Privacy Policy © Copyright 2023The Record from Recorded Future News",
    "commentLink": "https://news.ycombinator.com/item?id=37795652",
    "commentBody": "23andMe scraping incident leaked data on 1.3M usersHacker Newspastlogin23andMe scraping incident leaked data on 1.3M users (therecord.media) 154 points by doener 14 hours ago| hidepastfavorite4 comments skilled 13 hours agoOngoing discussion,Genetics firm 23andMe says user data stolen in credential stuffing attack (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37794379) reply dang 10 hours agoparentComments moved thither. Thanks! reply ChrisArchitect 12 hours agoprev [–] [dupe] reply ChrisArchitect 12 hours agoparent [–] More discussion over here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37794379 replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Genetic testing company 23andMe has acknowledged a data scraping incident where hackers accessed and sold sensitive user data on the dark web.",
      "The leaked data includes origin estimation, health-related information, and photos of nearly 7 million users, manifesting a security loophole in 23andMe.",
      "Despite initial denial, the company confirmed the violation and theorizes that the breach happened due to leaked login credentials from other platforms, raising privacy and security concerns in genetic testing companies."
    ],
    "commentSummary": [
      "The genetic testing firm 23andMe witnessed a data breach, resulting in a leak of personal information of approximately 1.3 million users.",
      "The data breach was due to a credential stuffing attack, a type of cyber attack where stolen account credentials are used to gain unauthorized access to user accounts.",
      "More details and discussions regarding the event are available on the Hacker News platform."
    ],
    "points": 154,
    "commentCount": 4,
    "retryCount": 0,
    "time": 1696622932
  }
]
