[
  {
    "id": 40133976,
    "title": "Did Prabhakar Raghavan Kill Google Search?",
    "originLink": "https://www.wheresyoured.at/the-men-who-killed-google/",
    "originBody": "This is the story of how Google Search died, and the people responsible for killing it. The story begins on February 5th 2019, when Ben Gomes, Google’s head of search, had a problem. Jerry Dischler, then the VP and General Manager of Ads at Google, and Shiv Venkataraman, then the VP of Engineering, Search and Ads on Google properties, had called a “code yellow” for search revenue due to, and I quote, “steady weakness in the daily numbers” and a likeliness that it would end the quarter significantly behind. For those unfamiliar with Google’s internal scientology-esque jargon, let me explain. A “code yellow” isn’t, as you might think, a crisis of moderate severity. The yellow, according to Steven Levy’s tell-all book about Google, refers to — and I promise that I’m not making this up — the color of a tank top that former VP of Engineering Wayne Rosing used to wear during his time at the company. It’s essentially the equivalent of DEFCON 1 and activates, as Levy explained, a war room-like situation where workers are pulled from their desks and into a conference room where they tackle the problem as a top priority. Any other projects or concerns are sidelined. In emails released as part of the Department of Justice’s antitrust case against Google, Dischler laid out several contributing factors — search query growth was “significantly behind forecast,” the “timing” of revenue launches was significantly behind, and a vague worry that “several advertiser-specific and sector weaknesses” existed in search. I should note that I’ve previously — and erroneously — referred to the “code yellow” as something that Gomes raised as a means of calling attention to the proximity of Google’s ads side getting too close to search. The truth is much grimmer — the Code Yellow was the rumble of the Rot Economy, with Google’s revenue arm sounding the alarm that its golden goose wasn’t laying enough eggs. Gomes, a Googler of 19 years that built the foundation of modern search engines, should go down as one of the few people in tech that actually fought for a real principle, destroyed by and replaced with Prabhakar Raghavan, a computer scientist class traitor that sided with the management consultancy sect. More confusingly, one of the problems was that there was insufficient growth in “queries,” as in the amount of things people were asking Google. It’s a bit like if Ford decided that things were going poorly because drivers weren’t putting enough miles on their trucks. Anyway, a few days beforehand on February 1 2019, Kristen Gil, then Google’s VP Business Finance Officer, had emailed Shashi Thakur, then Google’s VP of Engineering, Search and Discover, saying that the ads team had been considering a “code yellow” to “close the search gap [it was] seeing,” vaguely referring to how critical that growth was to an unnamed “company plan.” To be clear, this email was in response to Thakur stating that there is “nothing” that the search team could do to operate at the fidelity of growth that ads had demanded. (Editor’s note: If you read those emails, start from the bottom and work your way up). Shashi forwarded the email to Gomes, asking if there was any way to discuss this with Sundar Pichai, Google’s CEO, and declaring that there was no way he’d sign up to a “high fidelity” business metric for daily active users on search. Thakur also said something that I’ve been thinking about constantly since I read these emails: that there was a good reason that Google’s founders separated search from ads. On February 2, 2019, just one day later, Thakur and Gomes shared their anxieties with Nick Fox, a Vice President of Search and Google Assistant, entering a multiple-day-long debate about Google’s sudden lust for growth. The thread is a dark window into the world of growth-focused tech, where Thakur listed the multiple points of disconnection between the ads and search teams, discussing how the search team wasn’t able to finely optimize engagement on Google without “hacking engagement,” a term that means effectively tricking users into spending more time on a site, and that doing so would lead them to “abandon work on efficient journeys.” In one email, Fox adds that there was a “pretty big disconnect between what finance and ads want” and what search was doing. When Gomes pushed back on the multiple requests for growth, Fox added that all three of them were responsible for search, that search was “the revenue engine of the company,” and that bartering with the ads and finance teams was potentially “the new reality of their jobs.” On February 6th 2019, Gomes said that he believed that search was “getting too close to the money,” and ended his email by saying that he was “concerned that growth is all that Google was thinking about.” On March 22 2019, Google VP of Product Management Darshan Kantak would declare the end of the code yellow. The thread mostly consisted of congratulatory emails until Gomes responded congratulating the team, saying that the plans architected as part of the code would do well throughout the year. Prabhakar Raghavan, then Google’s Head of Ads and the true mastermind behind the code yellow, would respond curtly, saying that the current revenue targets were addressed “by heroic RPM engineering” and that “core query softness continued without mitigation” — a very clunky way of saying that despite these changes, query growth wasn’t happening. A day later, Gomes emailed Fox and Thakur an email he intended to send to Raghavan. He led by saying he was “annoyed both personally and on behalf of the search team.” in a long email, he explained how one might increase engagement with Google Search, but specifically added that they could “increase queries quite easily in the short term in user negative ways,” like turning off spell correction, turning off ranking improvements, or placing refinements — effectively labels — all over the page, adding that it was “possible that there are trade offs here between different kinds of user negativity caused by engagement hacking,” and that he was “deeply deeply uncomfortable with this.” He also added that this was the reason he didn’t believe that queries were a good metric to measure search and that the best defense about the weakness of queries was to create “compelling user experiences that make users want to come back.” In the March 2019 core update to search, which happened about a week before the end of the code yellow, was expected to be “one of the largest updates to search in a very long time. Yet when it launched, many found that the update mostly rolled back changes, and traffic was increasing to sites that had previously been suppressed by Google Search’s “Penguin” update from 2012 that specifically targeted spammy search results, as well as those hit by an update from an August 1, 2018, a few months after Gomes became Head of Search. While I’m guessing, the timing of the March 2019 core update, along with the traffic increases to previously-suppressed sites, heavily suggests that Google’s response to the Code Yellow was to roll back changes that were made to maintain the quality of search results. A few months later in May 2019, Google would roll out a redesign of how ads are shown on the platform on Google’s mobile search, replacing the bright green “ad” label and URL color on ads with a tiny little bolded black note that said “ad,” with the link looking otherwise identical to a regular search link. I guess that's how it started hitting their numbers following the code yellow. In January 2020, Google would bring this change to the desktop, which The Verge’s Jon Porter would suggest made “Google’s ads look just like search results now.” Five months later, a little over a year after the Code Yellow debacle, Google would make Prabhakar Raghavan the head of Google Search, with Jerry Dischler taking his place as head of ads. After nearly 20 years of building Google Search, Gomes would be relegated to SVP of Education at Google. Gomes, who was a critical part of the original team that made Google Search work, who has been credited with establishing the culture of the world’s largest and most important search engine, was chased out by a growth-hungry managerial types led by Prabhakar Raghavan, a management consultant wearing an engineer costume. A quick note: I used “management consultant” there as a pejorative. While he exhibits all the same bean-counting, morally-unguided behaviors of a management consultant, from what I can tell Raghavan has never actually worked in that particular sector of the economy. But do you know who has? Sundar Pichai, who previously worked at McKinsey — arguably the most morally abhorrent company that has ever existed, having played roles both in the 2008 financial crisis (where it encouraged banks to load up on debt and flawed mortgage-backed securities) and the ongoing opioid crisis, where it effectively advised Purdue Pharma on how to “growth hack” sales of Oxycontin. McKinsey has paid nearly $1bn over several settlements due to its work with Purdue. I’m getting sidetracked, but one last point. McKinsey is actively anti-labor. When a company brings in a McKinsey consultant, they’re often there to advise on how to “cut costs,” which inevitably means layoffs and outsourcing. McKinsey is to the middle class what flesh-eating bacteria is to healthy tissue. These emails are a stark example of the monstrous growth-at-all-costs mindset that dominates the tech ecosystem, and if you take one thing away from this newsletter, I want it to be the name Prabhakar Raghavan, and an understanding that there are people responsible for the current state of technology. These emails — which I encourage you to look up — tell a dramatic story about how Google’s finance and advertising teams, led by Raghavan with the blessing of CEO Sundar Pichai, actively worked to make Google worse to make the company more money. This is what I mean when I talk about the Rot Economy — the illogical, product-destroying mindset that turns the products you love into torturous, frustrating quasi-tools that require you to fight the company’s intentions to get the service you want. Heroes and Villains Ben Gomes is a hero. He was instrumental in making search work, both as a product and a business, joining the company in 1999 — a time long before Google established dominance in the field, and the same year when Larry Page and Sergey Brin tried to sell the company to Excite for $1m, only to walk away after Vinod Khosla (an Excite investor and the co-founder of Sun Microsystems) lowballed the pair with a $750,000 offer. In an interview with FastCompany’s Harry McCracken from 2018, Gomes framed Google’s challenge as “taking [the PageRank algorithm] from one machine to a whole bunch of machines, and they weren’t very good machines at the time.” Despite his impact and tenure, Gomes had only been made Head of Search in the middle of 2018 after John Giannandrea moved to Apple to work on its machine learning and AI strategy. Gomes had been described as Google’s “search czar,” beloved for his ability to communicate across departments. Every single article I’ve read about Gomes’ tenure at Google spoke of a man deeply ingrained in the foundation of one of the most important technologies ever made, who had dedicated decades to maintaining a product with a — to quote Gomes himself — “guiding light of serving the user and using technology to do that.” And when finally given the keys to the kingdom — the ability to elevate Google Search even further — he was ratfucked by a series of rotten careerists trying to please Wall Street, led by Prabhakar Raghavan. Do you want to know what Prabhakar Raghavan’s old job was? What Prabhakar Raghavan, the new head of Google Search, the guy that has run Google Search into the ground, the guy who is currently destroying search, did before his job at Google? He was the head of search for Yahoo from 2005 through 2012 — a tumultuous period that cemented its terminal decline, and effectively saw the company bow out of the search market altogether. His responsibilities? Research and development for Yahoo's search and ads products. When Raghavan joined the company, Yahoo held a 30.4 percent market share — not far from Google’s 36.9%, and miles ahead of the 15.7% of MSN Search. By May 2012, Yahoo was down to just 13.4 percent and had shrunk for the previous nine consecutive months, and was being beaten even by the newly-released Bing. That same year, Yahoo had the largest layoffs in its corporate history, shedding nearly 2,000 employees — or 14% of its overall workforce. The man who deposed Ben Gomes — someone who worked on Google Search from the very beginning — was so shit at his job that in 2009 Yahoo effectively threw in the towel on its own search technology, instead choosing to license Bing’s engine in a ten-year deal. If we take a long view of things, this likely precipitated the overall decline of the company, which went from being worth $125bn at the peak of the Dot Com bubble to being sold to Verizon for $4.8bn in 2017. With search no longer a priority — and making less money for the company — Yahoo decided to pivot into web 2.0 and original content, making some bets that paid off, but far, far too many that didn’t. It spent $1.1bn on Tumblr in 2013, only for Verizon to sell it for just $3m in 2019. It bought Zimbra in 2007, ostensibly to compete with the new Google Apps productivity suite, only to sell it (for a reported fraction of the original purchase price) to VMware a few years later. Yahoo was a company without a mission, purpose, or objective. Nobody — and, I’ll speculate, even those leading the company — really knew what it was, or what it did. In an interview with ZDNet’s Dan Farber from 2005, Raghavan spoke of his intent to “align the commercial incentives of a billion content providers with social good intent” while at Yahoo, and his eagerness to “inspire the audience to give more data. Before that, it’s hard to find out exactly what Raghavan did — according to ZDNet, he spent “14 years doing search and data-mining research at IBM.” In April 2011, the Guardian ran an interview with Raghavan that called him “Yahoo’s secret weapon,” describing his plan to make “rigorous scientific research and practice… to inform Yahoo's business from email to advertising,” and how under then-CEO Carol Bartz, “the focus has shifted to the direct development of new products.” It speaks of Raghavan’s “scientific approach” and his “steady, process-based logic to innovation that is very different to the common perception that ideas and development are more about luck and spontaneity,” a sentence I am only sharing with you because I need you to see how stupid it is, and how specious the tech press’ accolades used to be. This entire article is ridiculous, so utterly vacuous that I’m actually astonished. What about Raghavan’s career made this feel right? How has nobody connected these dots before and said something? Am I insane? To be clear, this was something written several years after Yahoo had licensed its search engine to Microsoft in a financial deal that Marisa Mayer, who replaced Bartz, was still angry about for years. Raghavan’s reign as the “search master” was one so successful that it ended up being replaced by a search engine that not a single person in the world enjoys saying out loud. This Guardian article ran exactly one year before dramatic layoffs at Yahoo that involved firing entire divisions-worth of people, and four months before Carol Bartz would be fired by telephone by then-Chairman Roy Bostock. Her replacement — Scott Thompson, who previously served as President of PayPal — would last only five months in the role before he too was replaced by former Google executive Marissa Mayer, in part because it emerged he lied on his resume about having a Computer Science degree. Bartz joined Yahoo in 2009 in the aftermath of its previous CEO Jerry Yang refusing to sell the company to Microsoft for $45 billion. In her first year, she laid off hundreds of people and struck a deal to power Yahoo’s search using Microsoft’s Bing search engine tech, with Microsoft paying Yahoo 88% of the revenue it gained from searches — a deal that made Yahoo a couple hundred million dollars for handing over the keys to its most high-traffic platform. As I have previously stated, when Prabhakar Ragahavan, Yahoo’s secret weapon, was doing his work, Yahoo Search was so valuable it was replaced with Bing. The company’s sole value, in many ways, was entirely driven by nostalgia and the association with the days before he worked there. A Near-Anonymous Villain It’s very, very difficult to find much on Raghavan’s history — it took me hours of digging through Google results to find the three or four articles that went into any depth about him — but from what I’ve gleaned, his expertise lies primarily in “failing up,” ascending through the ranks of technology on the momentum from the explosions he caused. In a WIRED interview from 2021, Steven Levy said Raghavan “isn’t CEO of Google— he just runs the place,” and described his addition to the company as “a move from research to management.” While Levy calls him a “world-class computer scientist who has authored definitive texts in the field,” he also describes Raghavan as “choosing a management track,” which definitely tracks with everything I’ve found about him. Raghavan proudly declares that “Google’s third-party ad tech plays a critical role in keeping journalism alive” at a time when he was aggressively incentivizing search engine optimized content, and a year after he’d deposed someone who actually gave a shit about search. Under Raghavan, Google has become less reliable, less transparent, and is dominated by search engine optimized aggregators, advertising, and outright spam. As I’ve argued previously, we — with good reason — continually complain about the state of Twitter under Elon Musk, but I’d argue Raghavan (and, by extension, Google CEO Sundar Pichai) deserve as much criticism, if not more, for the damage they’ve done to society. Because Google is the ultimate essential piece of online infrastructure, just like power lines and water mains are in the physical realm. Raghavan and his cronies worked to oust Ben Gomes, a man who dedicated a good portion of his life to making the world’s information more accessible, in the process burning the Library of Alexandria to the ground so that Pichai could make more than 200 million dollars a year. And Raghavan — a manager, hired by Sundar Pichai, a former McKinsey man and a manager by trade — is an example of everything wrong with the tech industry. Despite his history as a true computer scientist with actual academic credentials, Raghavan chose to bulldoze actual workers and replace them with toadies that would make Google more profitable and less useful to the world at large. Since Prabhakar took the reins in 2020, Google Search has dramatically declined, with the numerous “core” search updates allegedly made to improve the quality of results having an adverse effect, increasing the prevalence of spammy, search engine optimized content. It’s because the people running the tech industry are no longer those that built it. Larry Page and Sergey Brin left Google in December 2019 (the same year as the Code Yellow fiasco), and while they remain as controlling shareholders, they clearly don’t give a shit about what “Google” means anymore. Prabhakar Raghavan is a manager, and his career, from what I can tell, is mostly made up of “did some stuff at IBM, failed to make Yahoo anything of note, and fucked up Google so badly that every news outlet has run a story about how bad it is.” This is the result of taking technology out of the hands of real builders and handing it to managers at a time when “management” is synonymous with “staying as far away from actual work as possible.” And when you’re a do-nothing looking to profit as much as possible, you only care about growth. You’re not a user, you’re a parasite, and it’s these parasites that have dominated and are draining the tech industry of its value. Raghavan’s story is unique, insofar as the damage he’s managed to inflict (or, if we’re being exceptionally charitable, failed to avoid in the case of Yahoo) on two industry-defining companies, and the fact that he did it without being a CEO or founder. Perhaps more remarkable, he’s achieved this while maintaining a certain degree of anonymity. Everyone knows who Musk and Zuckerberg are, but Raghavan’s known only in his corner of the Internet. Or at least he was. Now Raghavan has told those working on search that their \"new operating reality\" is one with less resources and less time to deliver things. Rot Master Raghavan is here to squeeze as much as he can from the corpse of a product he beat to death with his bare hands. Raghavan is a hall-of-fame rot economist, and one of the many managerial types that have caused immeasurable damage to the Internet in the name of growth and “shareholder value.\" And I believe these uber-managers - these ultra-pencil-pushers and growth-hounds - are the forces destroying tech's ability to innovate. And in my next newsletter, I'm going to walk you through how a very specific kind of managerial mindset has poisoned Silicon Valley, making career failures unfathomably rich while your favorite tech products decay.",
    "commentLink": "https://news.ycombinator.com/item?id=40133976",
    "commentBody": "The man who killed Google Search? (wheresyoured.at)1503 points by elorant 17 hours agohidepastfavorite703 comments gregw134 13 hours agoEx-Google search engineer here (2019-2023). I know a lot of the veteran engineers were upset when Ben Gomes got shunted off. Probably the bigger change, from what I've heard, was losing Amit Singhal who led Search until 2016. Amit fought against creeping complexity. There is a semi-famous internal document he wrote where he argued against the other search leads that Google should use less machine-learning, or at least contain it as much as possible, so that ranking stays debuggable and understandable by human search engineers. My impression is that since he left complexity exploded, with every team launching as many deep learning projects as they can (just like every other large tech company has). The problem though, is the older systems had obvious problems, while the newer systems have hidden bugs and conceptual issues which often don't show up in the metrics, and which compound over time as more complexity is layered on. For example: I found an off by 1 error deep in a formula from an old launch that has been reordering top results for 15% of queries since 2015. I handed it off when I left but have no idea whether anyone actually fixed it or not. I wrote up all of the search bugs I was aware of in an internal document called \"second page navboost\", so if anyone working on search at Google reads this and needs a launch go check it out. reply barbariangrunge 6 hours agoparentMachine learning or not, seo spam sort of killed search. It’s more or less impossible to find real sites by interesting humans these days. Almost all results are Reddit, YouTube, content marketing, or seo spam. And google’s failure here killed the old school blogosphere (medium and substack only slightly count), personal websites, and forums Same is happening to YouTube as well. Feels like it’s nothing but promoters pushing content to gain followers to sell ads or other stuff because nobody else’s videos ever surface. Just a million people gaming the algorithm and the only winners are the people who devote the most time to it. And by the way, would I like to sign up for their patreon and maybe one of their online courses? reply raxxorraxor 7 minutes agorootparentMachine learning is probably as much or even more susceptible to SEO spam. Problem is that the rules of search engines created the dubious field of SEO in the first place. They are not entirely the innocent victim here. Arcane and intransparent measures get you ahead. So arcane that you instantly see that it does not correspond with quality content at all, which evidently leads to a poor result. I wish there was an option to hide every commercial news or entertainment outlet completely. Those are of course in on SEO for financial reaesons. reply willvarfar 2 hours agorootparentprevI think a case can be made that the spam problem can be traced all the way back to Google buying Doubleclick. Its really easy to spot the crap websites that are scaping content-creating websites ... because they monetize by adding ads. If Google was _only_ selling ads on the search results page, then it could promote websites that are sans ads. Instead, it is incentivised to push users to websites that contain ads, because it also makes money there. And that means scraping other sites to slap your ads onto them can be very profitable for the scammers. reply rvba 2 hours agorootparentThey hired people who introduce Jack Welch methods. This is like in that Steve Jobs video about product people being kicked out and exchanged by ones who dont care about product: https://m.youtube.com/watch?v=P4VBqTViEx4 They will not make good search. That is not their priority. reply freetinker 5 hours agorootparentprevA bit chicken-and-egg. Another perspective: Google’s system incentivizes SEO spam. Search for a while hasn’t been about searching the web as much as it has been about commerce. It taps commercial intent and serves ads. It is now an ad engine; no longer a search engine. reply dazc 4 hours agorootparentBest exercise bike articles, and such, are what lots of people people actually search for. There is no incentive to provide quality work which answers these queries hence the abundance of spam and ads. If you want to purchase consumer products at your own expense and offer an impartial opinion on each of them then you will have no problem getting ranked highly on google. You will lose a lot of money doing so, however, and will also be plagiarized to death in a month. The sites you want to be rid of will outrank you for your own content, I have been there and have the t-shirt. reply somenameforme 2 hours agorootparentprevAbsolutely this. I don't think many people consider how odd it is that the largest internet advertising company in the world and the largest search engine company in the world are one and the same, and just how overt a conflict of interest that is, so far as providing quality service goes. It would be akin to if the largest telephone service company in the world was also the largest phone maker in the world. Oh wait, that did happen [1] - and we broke them up because it's obviously extremely detrimental to the functioning of a healthy market. [1] - https://en.wikipedia.org/wiki/Breakup_of_the_Bell_System reply haspok 3 hours agorootparentprevI don't know, but Youtube seems to have a more solid algorithm. I'm typically not subscribed to any channel, yet the content I want to watch does find me reasonably well. Of course, heavily promoted material also, but I just click \"not interested in channel\" and it disappears for a while. And I still get some meaningful recommendations if I watch a video in a certain topic. Youtube has its problems, of course, but in the end I can't complain. reply jajko 1 hour agorootparentI don't think youtube is trying that hard to desperately sell stuff to you via home screen recommendation algorithm. And I agree its bearable and what you describe works cca well, albeit ie I am still trying to get rid of anything related to Jordan Peterson whom I liked before and detest now after his drug addiction / mental breakdown, it just keeps popping back from various sources, literal whack-a-mole. I wish there was some way to tell \"please ignore all videos that contain these strings, and I don't mean only for next 2 weeks\". Youtube gets their ads revenue from before/during video, so they can be nicer to users. reply Ambolia 1 hour agorootparentprevFor me what killed search was 2016, after that year if some search term is \"hot news\" it becomes impossible to learn anything about it that wasn't published in the last week and you just get the same headline repeated 20 times in slightly different wording about it. After that I only use search for technical problems, and mouth to mouth or specific authors for everything else. reply codegladiator 5 hours agorootparentprevspam didn't kill search. Google willingness to promote spam for ads killed Google. Google is not search. reply re5i5tor 5 hours agorootparentprevHard disagree. As another reply mentions, just compare the alternatives such as Kagi that aren’t breaking search by pursuing ad growth. reply pkphilip 4 hours agorootparentprevCorrection: It is Google's willingness to display search results by what is MOST PROFITABLE and/or POLITICALLY expedient to them that killed search. This includes their willingness to promote/demote content based on what the thought police wanted to promote/demote. reply seospamsuck 16 minutes agorootparentThis is the correct insight. Google has enough machine learning prowess that they could absolutely offload, with minimal manhours, the creation of a list ranking a bunch of blogspam sites and give them a reverse score by how much they both spam articles or how much they spread the content over the page. Then apply that score to their search result weights. And I know they could because someone did make that list and posted it here last year. reply underdeserver 2 hours agorootparentprevI've heard this argument again and again, but I never see any explanation as to why SEO is suddenly in the lead in this cat-and-mouse game. They were trying ever since Google got 90%+ market share. I think it's more likely that Google stopped really caring. reply rob74 2 hours agorootparentWell yeah, it's in the article - at some point, they switched completely to metrics (i.e. revenue) driven management and forgot that it's the quality of results that actually made Google what it is. And, with a largely captive audience (Google being the default-search-engine-that-most-people-don't-bother-or-don't-know-how-to-change in Chrome, Android, on Chromebooks etc.), they arguably don't have to care anymore... reply madcoderme 5 hours agorootparentprevIt's like \"Do some SEO magic and Tada!\" And who forgot the recent Reddit story. reply bergen 4 hours agorootparentCould you link it please? I have unfortunately no idea what you are referencing reply baryphonic 5 hours agorootparentprevWhat I don't understand about this explanation is that Google's results are abysmal compared to e.g. DuckDuckGo or even Brave search. (I haven't tried Kagi, but people here rave about it as well.) Sure, all the SEO is targeting googlebot, but Google has by far more resources to mitigate SEO spam than just about anyone else. If this is the full explanation, couldn't Google just copy the strategies the (much) smaller rivals are using? reply raincole 2 hours agorootparentHave you read the article this thread is about? To summarize it: Google reverted an algorithm that detected SEO spams in 2019. (Note that I never work for Google and I don't know whether it's true or not. It's just what this article says.) reply freeone3000 2 hours agorootparentprevWhen a large search engine deranks spam websites, the spam websites complain! Loudly! With Google they have a big juicy target with lots of competing ventures for an antitrust case; no such luck for Kagi or DDG. reply yannickt 5 hours agorootparentprevI've been using Kagi for a while, and I find that it delivers better results in a cleaner presentation. reply choppaface 3 hours agorootparentprevSEO Spam didn't kill search so much as Google failed to retain Matt Cutts or replicate his community involvement https://www.searchenginejournal.com/matt-cutts-resigns-googl... reply arromatic 2 hours agorootparentWhat did he used to do ? Your comment seems contradictory cutts seem to be on anti spam but your comment implies seo did not kill search . Is seo not part of spam? reply JohnFen 13 hours agoparentprev> where he argued against the other search leads that Google should use less machine-learning This better echoes my personal experience with the decline of Google search than TFA: it seems to be connected to the increasing use of ML in that the more of it Google put in, the worse the results I got were. reply potatolicious 12 hours agorootparentIt's also a good lesson for the new AI cycle we're in now. Often inserting ML subsystems into your broader system just makes it go from \"deterministically but fixably bad\" to \"mysteriously and unfixably bad\". reply ytdytvhxgydvhh 9 hours agorootparentI think that’ll define the industry for the coming decades. I used to work in machine translation and it was the same. The older rules-based engines that were carefully crafted by humans worked well on the test suite and if a new case was found, a human could fix it. When machine learning came on the scene, more “impressive” models that were built quicker came out - but when a translation was bad no one knew how to fix it other than retraining and crossing one’s fingers. reply satvikpendem 7 hours agorootparentAs someone who worked in rules-based ML before the recent transformers (and unsupervised learning in general) hype, rules-based approaches were laughably bad. Only now are nondeterministic approaches to ML surpassing human level tasks, something which would not have been feasible, perhaps not even possible in a finite amount of human development time, via human-created rules. reply Anotheroneagain 4 hours agorootparentThe thing is that AI is completely unpredictable without human curated results. Stable diffusion made me relent and admit that AI is here now for real, but I no longer think so. It's more like artificial schizophrenia. It does have some results, often plausible seeming results, but it's not real. reply space_fountain 9 hours agorootparentprevYes, but I think the other lesson might be that those black box machine translations have ended up being more valuable? It sucks when things don't always work, but that is also kind of life and if the AI version worked more often that is usually ok (as long as the occasional failures aren't so catastrophic as to ruin everything) reply ethbr1 8 hours agorootparent> Yes, but I think the other lesson might be that those black box machine translations have ended up being more valuable? The key difference is how tolerant the specific use case is of a probably-correct answer. The things recent-AI excels at now (generative, translation, etc.) are very tolerant of \"usually correct.\" If a model can do more, and is right most of the time, then it's more valuable. There are many other types of use cases, though. reply nojs 5 hours agorootparentA case in point is the ubiquity of Pleco in the Chinese/English space. It’s a dictionary, not a translator, and pretty much every non-native speaker who learns or needs to speak Chinese uses it. It has no ML features and hasn’t changed much in the past decade (or even two). People love it because it does one specific task extremely well. On the other hand ML has absolutely revolutionised translation (of longer text), where having a model containing prior knowledge about the world is essential. reply ytdytvhxgydvhh 9 hours agorootparentprevCan’t help but read that and think of Tesla’s Autopilot and “Full Self Driving”. For some comparisons they claim to be safer per mile than human drivers … just don’t think too much about the error modes where the occasional stationary object isn’t detected and you plow into it at highway speed. reply someguydave 7 hours agorootparentrelevant to the grandparent’s point: I am demoing FSD in my Tesla and what I find really annoying is that the old Autopilot allowed you to select a maximum speed that the car will drive. Well, on “FSD” apparently you have no choice but to hand full longitudinal control over to the model. I am probably the 0.01% of Tesla drivers who have the computer chime when I exceed the speed limit by some offset. Very regularly, even when FSD is in “chill” mode, the model will speed by +7-9 mph on most roads. (I gotta think that the young 20 somethings who make up Tesla's audience also contributed their poor driving habits to Tesla's training data set) This results in constant beeps, even as the FSD software violates my own criteria for speed warning. So somehow the FSD feature becomes \"more capable\" while becoming much less legible to the human controller. I think this is a bad thing generally but it seems to be the fad today. reply throwaway2037 3 hours agorootparentI have no experience with Tesla and their self-driving features. When you wrote \"chill\" mode, I assume it means the lowest level of aggressiveness. Did you contact Tesla to complain the car is still too aggressive? There should be a mode that tries to drive exactly the speed limit, where reasonable -- not over or under. reply space_fountain 9 hours agorootparentprevWell Tesla might be the single worst actor in the entire AI space, but I do somewhat understand your point. The lake of predictable failures is a huge problem with AI, I'm not sure that understandability is by itself. I will never understand the brain of an Uber driver for example reply Terr_ 8 hours agorootparentprevOr in some cases, the Tesla slows down, then changes its mind and starts accelerating again to run over child-like obstructions. Ex: https://www.youtube.com/watch?v=URpTJ1Xpjuk&t=293s reply simion314 4 hours agorootparentprev> For some comparisons they claim to be safer per mile than human drivers They are lying with statistics, for the more challenging locations and conditions the AI will give up and let the human take over or the human notices something bad and takes over. So Tesla miles are miles are cherry picked and their data is not open so a third party can make real statistics and compare apples to apples. reply raincole 2 hours agorootparentprevBut rule-based machine translation, from what I've seen, is just so bad. ChatGPT (and other LLM) is miles ahead. After seeing what ChatGPT does, I can't even call rule-based machine translation \"tranlation\". *Disclaimer: as someone who's not an AI researcher but did quite some human translation works before. reply beefnugs 4 hours agorootparentprevyes, who exactly looked at the 70% accuracy of \"live automatic closed captioning\" and decided Great! ship it boys! reply throwaway2037 3 hours agorootparentMy guess: They are hoping user feedback will help them to fix the bugs later -- iterate to 99%. Plus, they are probably under unrealistic deadlines to delivery _something_. reply chrisweekly 9 hours agorootparentprevI've heard AI described as the payday loan (or \"high-interest credit card\") of technical debt. reply munk-a 11 hours agorootparentprevI think - I hope, rather - that technically minded people who are advocating for the use of ML understand the short comings and hallucinations... but we need to be frank about the fact that the business layer above us (with a few rare exceptions) absolutely does not understand the limitations of AI and views it as a magic box where they type in \"Write me a story about a bunny\" and get twelve paragraphs of text out. As someone working in a healthcare adjacent field I've seen the glint in executive's eyes when talking about AI and it can provide real benefits in data summarization and annotation assistance... but there are limits to what you should trust it with and if it's something big-i Important then you'll always want to have a human vetting step. reply munificent 10 hours agorootparent> I hope, rather - that technically minded people who are advocating for the use of ML understand the short comings and hallucinations. The people I see who are most excited about ML are business types who just see it as a black boxes that makes stock valuation go vroom. The people that deeply love building things, really enjoy the process of making itself, are profoundly sceptical. I look at generative AI as sort of like an army of free interns. If your idea of a fun way to make a thing is to dictate orders to a horde of well-meaning but untrained highly-caffienated interns, then using generative AI to make your thing is probably thrilling. You get to feel like an executive producer who can make a lot of stuff happen by simply prompting someone/something to do your bidding. But if you actually care about the grit and texture of actual creation, then that workflow isn't exactly appealing. reply spacemadness 9 hours agorootparentThey wouldn’t think this way if stock investors weren’t so often such naive lemmings ready to jump off yet another cliff with each other. reply fragmede 8 hours agorootparentprevWe get it, you're skeptical of the current hype bubble. But that's one helluva no true Scotsman you've got going on there. Because a true builder, one that deeply loves building things wouldn't want to use text to create an image. Anyone who does is a business type or an executive producer. A true builder wouldn't think about what they want to do in such nasty thing as words. Creation comes from the soul, which we all know machines, and business people, don't have. Using English, instead of C, to get a computer to do something doesn't turn you into a beaurocrat any more than using Python or Javascript instead does. Only a person that truly loves building things, far deeper than you'll ever know, someone that's never programmed in a compiled language, would get that. reply WWLink 6 hours agorootparentGetting drunk off that AI kool-aid aren't ya reply fragmede 6 hours agorootparentthe othering of creators because they use a different paintbrush was bothering me. reply stavros 5 hours agorootparentI can relate, AI is a tool, and if I want to write my code by LEGOing a bunch of AI-generated functions together, I should be able to. reply ethbr1 8 hours agorootparentprev> Using English, instead of C, to get a computer to do something doesn't turn you into a beaurocrat any more than using Python or Javascript instead does. If one uses English in as precise a way as one crafts code, sure. Most people do not (cannot?) use English that precisely. There's little technical difference between using English and using code to create... ... but there is a huge difference on the other side of the keyboard, as lots of people know English, including people who aren't used to fully thinking through a problem and tackling all the corner cases. reply dragonwriter 6 hours agorootparent> Most people do not (cannot?) use English that precisely. No one can, which is why any place human interaction needs anything anywhere close to the determinancy of code, normal natural langauge is abandoned for domain-specific constructed languages built from pieces of natural language with meanings crafted especially for the particular domain as the interface language between the people (and often formalized domain-specific human-to-human communication protocols with specs as detailed as you’d see from the IETF.) reply cultofmetatron 1 hour agorootparentI gotta say, I love how you use english to perfectly demonstrate how imprecise english is without pre-understood context to disambiguate meaning. reply xarope 6 hours agorootparentprevusing English has been tried many times in the history computing; Cobol, SQL, just to name a very few. Still needed domain experts back then, and, IMHO, in years/decades to come reply WWLink 6 hours agorootparentOr you can draw pretty pictures in LabVIEW lol reply pbar 7 hours agorootparentprevWas it intentional to reply with another no true Scotsman in turn here? reply satvikpendem 7 hours agorootparentYeah, I was also reading their response and was confused. \"Creation comes from the soul, which we all know machines, and business people, don't have\" ... \"far deeper than you'll ever know\", I mean, come on. reply fragmede 6 hours agorootparentprevIf you have to ask, then you missed it reply acdha 10 hours agorootparentprevI’m not optimistic on that point: the executive class is very openly salivating at the prospect of mass layoffs, and that means a lot of technical staff aren’t quick to inject some reality – if Gartner is saying it’s rainbows and unicorns, saying they’re exaggerating can be taken as volunteering to be laid off first even if you’re right. reply godelski 9 hours agorootparentprev> but we need to be frank about the fact that the business layer above us (with a few rare exceptions) absolutely does not understand the limitations of AI and views it as a magic box where they type in I think we also need to be aware that this business layer above us that often sees __computers__ as a magic box where they type in. There's definitely a large spectrum of how magical this seems to that layer, but the issue remains that there are subtleties that are often important but difficult to explain without detailed technical knowledge. I think there's a lot of good ML can do (being a ML researcher myself), but I often find it ham-fisted into projects simply to say that the project has ML. I think the clearest flag to any engineer that this layer above them has limited domain knowledge is by looking at how much importance they place on KPIs/metrics. Are they targets or are they guides? Because I can assure you, all metrics are flawed -- but some metrics are less flawed than others (and benchmark hacking is unfortunately the norm in ML research[0]). [0] There's just too much happening so fast and too many papers to reasonably review in a timely manner. It's a competitive environment, where gatekeepers are competitors, and where everyone is absolutely crunched for time and pressured to feel like they need to move even faster. You bet reviews get lazy. The problems aren't \"posting preprints on twitter\" or \"LLMs giving summaries\", it's that the traditional peer review system (especially in conference settings) poorly scales and is significantly affected by hype. Unfortunately I think this ends up railroading us in research directions and makes it significantly challenging for graduate students to publish without being connected to big labs (aka, requiring big compute) (tuning is another common way to escape compute constraints, but that falls under \"railroading\"). There's still some pretty big and fundamental questions that need to be chipped away at but are difficult to publish given the environment. /rant reply jorblumesea 9 hours agorootparentprev> technically minded people who are advocating for the use of ML understand the short comings and hallucinations really, my impression is the opposite. They are driven by doing cool tech things and building fresh product, while getting rid of \"antiquated, old\" product. Very little thought given to the long term impact of their work. Criticism of the use cases are often hand waved away because you are messing with their bread and butter. reply __loam 11 hours agorootparentprevThis is why hallucinations will never be fixed in language models. That's just how they work. reply jokoon 11 hours agorootparentprevthat's not something ML people would like to hear reply oblio 11 hours agorootparentIs ML the new SOAP? Looks like a silver bullet and 5 years later you're drowning in complexity for no discernible reason? reply ChrisMarshallNY 11 hours agorootparent> SOAP Argh. My PTSD from writing ONVIF drivers just kicked in. reply eschneider 11 hours agorootparentBeen there, Done that. Slides over a bottle of single malt. reply cgh 10 hours agorootparentHorrifying memories of Microsoft Biztalk reply raincole 2 hours agorootparentprevML is a quite well adopted technology. iPhones has ML bulit in since about 2017. It has been more than 5 years. reply bitwize 10 hours agorootparentprevML is somewhere between the new SOAP and the new cryptocurrency. reply peoplenotbots 10 hours agorootparentWell thats grim reply ajross 8 hours agorootparentprevSo... obviously SOAP was dumb[1], and lots of people saw that at the time. But SOAP was dumb in obvious ways, and it failed for obvious reasons, and really no one was surprised at all. ML isn't like that. It's new. It's different. It may not succeed in the ways we expect; it may even look dumb in hindsight. But it absolutely represents a genuinely new paradigm for computing and is worth studying and understanding on that basis. We look back to SOAP and see something that might as well be forgotten. We'll never look back to the dawn of AI and forget what it was about. [1] For anyone who missed that particular long-sunken boat, SOAP was a RPC protocol like any other. Yes, that's really all it was. It did nothing special, or well, or that you couldn't do via trivially accessible alternative means. All it had was the right adjective (\"XML\" in this case) for the moment. It's otherwise forgettable, and forgotten. reply tensor 4 hours agorootparentML has already succeeded to the point that it is ubiquitous and taken for granted. OCR, voice recognition, spam filters, and many other now boring technologies are all based on ML. Anyone claiming it’s some sort of snake oil shouldn’t be taken seriously. Certainly the current hype around it has given rise to many inappropriate applications, but it’s a wildly successful and ubiquitous technology class that has no replacement. reply oblio 1 hour agorootparentThat ML I have no problem with. This new ML that's supposed to be the basis for an entire new economic wave, that I mostly dislike. But I guess that's how we build new things... We explore and throw away 80% of what we've built. reply yen223 1 hour agorootparentprevThank you for this. Reading these comments I thought I stepped into some alternate timeline when we don't already have widespread ML all over the place. Like, nobody does rules-based image recognition for a decade now already! reply __loam 11 hours agorootparentprevDon't forget about that expensive GPU infrastructure you invested in. reply jokoon 11 hours agorootparentand the power bill and how difficult it is to program those GPU to do ML reply fuzztester 12 hours agorootparentprevSame here with YouTube, assuming they use ML, which is likely. They routinely give me brain-dead suggestions such as to watch a video I just watched today or yesterday, among other absurdities. reply 998244353 11 hours agorootparentFor what it's worth, I do not remember a time when YouTube's suggestions or search results were good. Absurdities like that happened 10 and 15 years ago as well. These days my biggest gripe is that they put unrelated ragebait or clickbait videos in search results that I very clearly did not search for - often about American politics. reply FullstakBlogger 8 hours agorootparent15 years ago, I used to keep many tabs of youtube videos open just because the \"related\" section was full of interesting videos. Then each of those videos had interesting relations. There was so much to explore before hitting a dead-end and starting somewhere else. Now the \"related\" section is gone in favor of \"recommended\" samey clickbait garbage. The relations between human interests are too esoteric for current ML classifiers to understand. The old Markov-chain style works with the human, and lets them recognize what kind of space they've gotten themselves into, and make intelligent decisions, which ultimately benefit the system. If you judge the system by the presence of negative outliers, rather than positive, then I can understand seeing no difference. reply Aerroon 5 hours agorootparent>The relations between human interests are too esoteric for current ML classifiers to understand. I would go further and say that it is impossible. Human interests are contextual and change over time, sometimes in the span of minutes. Imagine that all the videos on the internet would be on one big video website. You would watch car videos, movie trailers, listen to music, and watch porn in one place. Could the algorithm correctly predict when you're in the mood for porn and when you aren't? No, it couldn't. The website might know what kind of cars, what kind of music, and what kind of porn you like, but it wouldn't be able to tell which of these categories you would currently be interested in. I think current YouTube (and other recommendation-heavy services) have this problem. Sometimes I want to watch videos about programming, but sometimes I don't. But the algorithm doesn't know that. It can't know that without being able to track me outside of the website. reply nox101 2 hours agorootparentI think there are things they could do and that ML could maybe help? * They could let me directly enter my interests instead of guessing * They could classify videos by expertise (tags or ML) and stop recommending beginner videos to someone who expresses an interest in expert videos. * They could let me opt out of recommending videos I've already watched * They could separate sites into larger categories and stop recommending things not in that category. For me personally, when I got to youtube.com I don't want music but 30-70% of the recommendations are for music. If the split into 2 categories (videos.youtube.com - no music) and (music.youtube.com - only music) they'd end up recommending far more to me that I'm actually interested in at the time. They could add other broad categories like (gaming.youtube.com, documentaries.youtube.com, science.youtube.com, cooking.youtube.com, ...., as deep as they want). Classifying a video could be ML or creator decided. If you're only allowed one category they would be incentive to not mis-classify. If they need more incentive they could dis-recommend your videos if you mis-classify too many/too often). * They could let me mark videos as watched and actually track that the same as read/unread email. As it is, if you click \"not interested -> already watched\" they don't mark the video as visibly watched (the red bar under the video). Further, if you start watching again you lose the red-bar (it gets reset to your current position). I get that tracking where you are in a video is something that's different for email vs video but at the same time (1) if I made it to 90% of the way through then for me at least, that's \"watched\" - same as \"read\" for email and I'd like it \"archived\" (don't recommend this to me again) even if I start watching it again (same as reading an email marked as \"read) reply FullstakBlogger 4 hours agorootparentprev>I would go further and say that it is impossible. Human interests are contextual and change over time, sometimes in the span of minutes. Theres a general problem in the tech world where people seem to inexplicably disregard the issue of non-reducibility. The point about the algorithm lacking access to necessary external information is good. A dictionary app obviously can't predict what word I want to look up without simulating my mind-state. A set of probabilistic state transitions is at least a tangible shadow of typical human mind-states who make those transitions. reply rvba 1 hour agorootparentprevThey probably optimize your engagement NOW - with clickbaity videos. So their KPIs show big increases. But in long term you realize that what you watch is garbage and stop watching alltogether. Someone probably changed the engine that shows videos for you - exactly as with search. reply Narishma 7 hours agorootparentprevI do remember when Youtube would show more than 2 search results per page on my 23\" display. Or when they would show more than 3 results before spamming irrelevant videos. Or when they didn't show 3 unskippable ads in a 5 minute video. Or when they had a dislike button so you would know to avoid wasting time on low quality videos. reply throwaway2037 3 hours agorootparent> Or when they didn't show 3 unskippable ads in a 5 minute video. On desktop Chrome, a modern ad-blocking browser extension will block 100% of YouTube adverts. I haven't watched one, literally, in years. I don't watch YouTube from a mobile phone, but I think the situation is different. (Can anyone else comment about the mobile experience?) reply snickerer 2 hours agorootparentOn Android devices I use the app PipePipe to avoid the YouTube ad hell. I recommend it. I also use Firefox for Android, which has Addon support. Ublock Origin works on the phone and disables a a lot of the ad horror. reply WWLink 6 hours agorootparentprev> I do remember when Youtube would show more than 2 search results per page on my 23\" display. Wait what?! You \"Consume Content\" on a COMPUTER? What are you some kinda grandpa? Why aren't you consuming content from your phone like everyone else? Or casting it from your phone to your SMART TV! Great way to CONSUME CONTENT! CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT CONSUME CONTENT reply skydhash 5 hours agorootparentLol, Youtube on Apple TV is great. Mostly because I either need to find something fast or I switch it off because the remote is not conducive to skipping. But the only time I watch Youtube on my computer is for a specific video. The waste of space is horrendous. Same with Twitter (rarely visited), just a 3/4 inches wide column of posts on my 24 inch screen. reply Aerroon 5 hours agorootparentprevI'm not consuming the content on my phone, because the user experience of using these services on my phone sucks. Just the app vs website difference with urls is a difference in behavior I hate let alone all the UI differences that make the mobile experience awkward. I don't know about the TV though. reply peoplenotbots 10 hours agorootparentprevLong long time ago; youtube \"staff\" would manually put certain videos on the top of the front page when they started. Im sure there we're biases and prioritization of marketing dollars but at least there was human recommending it compared to poorly recorded early family guy clips. I dont know when they stopped manually adding \"editors/staff\" choice videos but I recall some of my favorite early youtubers like CGPGgrey claim that recommendation built the career. reply superluserdo 9 hours agorootparentSee this >15-year-old video \"How to get featured on YouTube\" - https://www.youtube.com/watch?v=-uzXeP4g_qA, which I remember as being originally uploaded to the official Youtube channel but looks like it's been removed now, this reupload is from October 2008. reply alovelace 3 hours agorootparentprevIt all depends on your use case but a lot of people seem to be in agreement it fell off in the mid to late 10s and the suggestions became noticeably worse. reply gverrilla 11 hours agorootparentprevYT Shorts recommendations are a joke. I'm an atheist and very rarely watch anything related to religion, and even so Shorts put me in 3 or 4 live prayers/scams (not sure) the last few months. reply dekhn 10 hours agorootparentSimilarly, Google News. The \"For You\" section shows me articles about astrology because I'm interested in astronomy. I get suggestions for articles about I-80 because I search for I-80 traffic cams to get traffic cam info for Tahoe, but it shows me I-80 news all the way across the country, suggestions about MOuntain View because I worked there (for google!) over 3 years ago, commanders being fired from the Navy (because I read a couple articles once), it goes on and on. From what I can tell, there are no News Quality people actually paying attention to their recommendations (and \"Show Fewer\" doesn't actually work. I filed a bug and was told that while the desktop version of the site shows Show Fewer for Google News, it doesn't actually have an effect). reply WWLink 6 hours agorootparentPart of the reason I switched from google to duckduckgo for searching was I didn't WANT \"personalization\" I want my search results to be deterministic. If I am in Seattle and search for \"ducks\" I want the exact fucking same search results as if I travel to Rio de Janeiro and search for \"ducks\". Honestly, I'd prefer my voice assistant (siri mostly) to be like that as well. It was at first, and I think everyone hated that lol. reply AlexCoventry 9 hours agorootparentprevYT Shorts itself is kind of a mystery to me. It's an objective degradation of the interface; why on earth would I want to use it? It doesn't even allow adjustment of the playback speed or scrubbing! reply kmeisthax 4 hours agorootparentSo, there's a few ways to explain it. From a business strategy level, TikTok exists, and is a threat to YouTube, so we need to compete with it. From a user perspective, Shorts highlights a specific format of YouTube that happened to have been around for a lot longer than people realize. TikTok isn't anything new, Vine was doing exactly the same thing TikTok was a decade prior. It was shut down for what I can only assume was really dumb reasons. A lot of Viners moved to YouTube, but they had to change their creative process to fit what the YouTube algorithm valued at the time: longer videos. Pre-Shorts, there really wasn't a good place on YouTube for short videos. Animators were getting screwed by the algorithm because you really can't do daily uploads of animation[0] and whatever you upload is going to be a few minutes max. A video essayist can rack up hundreds of thousands of hours of watch time while you get maybe a thousand. (Fun fact: YouTube Shorts status was applied retroactively to old short videos, so there's actually Shorts that are decades old. AFAIK, some of the Petscop creator's old videos are Shorts now.) But that's why users or creators would want to use Shorts. A lot of the UX problems with Shorts boils down to YouTube building TikTok inside of YouTube out of sheer corporate envy. To be clear, they could have used the existing player and added short-video features on top (e.g. swipe-to-skip). In fact, any Short can be opened in the standard player by just changing the URL! There's literally no difference other than a worse UI because SOMEONE wanted \"launched a new YouTube vertical\" on their promo packet! FWIW the Shorts player is gradually getting its missing features back but it's still got several pain points for me. One in particular that I think exemplifies Shorts: if I watch Shorts on a portrait 1080p monitor - i.e. the perfect thing to watch vertical video on - you can't see comments. When you open the comments drawer it doesn't move over enough and the comments get cut off. The desktop experience is also really bad; occasionally scrolling just stops working, or it skips two videos per mousewheel event, or one video will just never play no matter how much I scroll back and forth. [0] Vtubers don't count reply minetest2048 7 hours agorootparentprevYou can scrub on the mobile player, that's what makes it so much frustrating because you can't do that on desktop reply fuzztester 6 hours agorootparentWhat does scrubbing mean in this context? Blocking the Shorts? reply mondobe 6 hours agorootparentSeeking to a certain part of the video. On mobile, you can do it by dragging the progress bar at the bottom of the screen. reply nevster 5 hours agorootparentprevScrubbing means quickly moving the current playback position back and forward reply barnabyjones 8 hours agorootparentprevI think there is a large demo of people now who actually prefer to watch videos in portrait. reply skydhash 5 hours agorootparentIf you’re watching a single subject of interest video on your phone (TikTok type of content), it’s great. But landscape videos is more pleasant and there’s a reason we move from 4:3 for media. But that actually means watching the videos, but what I see is a lot of skipping. reply watwut 3 hours agorootparentprevI dont mind portrait. I mind inability to jump forward in the video. reply fuzztester 8 hours agorootparentprevSolid point. Not to mention that Shorts content is mainly linkbait and/or garbage. reply alovelace 3 hours agorootparentprevJust because you're an atheist doesn't mean you won't engage with religious content though. YT rewards all kinds of engagement not just positive ones. I.e. if you leave a snide remark or just a dislike on a religious short that still counts as engagement. reply epcoa 11 hours agorootparentprevPrayers for the unbelievers makes some sense. But I associate YouTube promotions with garbage any how. The few things I might buy like Tide laundry detergent are entirely despite occasional YouTube promotion. reply gverrilla 10 hours agorootparentLmao. I'm very positive that the conversion rate for placing an atheist in a live mass out of the blue is very very very low. Because I never stayed for more than 3 seconds, I'm not sure if it's real religious content or a scam, though - and they don't even let me report live shorts :( reply BuyMyBitcoins 6 hours agorootparent“Conversion rate”. I’m not sure if you intended that pun but it’s pretty good. reply delfinom 10 hours agorootparentprevI imagine my blocked channels list is stress testing YouTube at this point from the amount of shit Shorts results it's fed me after 2 years. Lol Besides the religious crap, ill randomly get shit in India in hindu, having had not watched anything Indian and not even remotely Indian. reply gverrilla 10 hours agorootparentI only get those when it's new content with in hindu Hindi is the word for the language, bro. reply etc-hosts 8 hours agorootparentI knew I could count on you. reply fuzztester 6 hours agorootparentYou bet. Think nought of it. We gave the world zero, after all. Even computers owe us. ;) https://en.m.wikipedia.org/wiki/0 reply jasonfarnon 10 hours agorootparentprevnext [2 more] [flagged] bitwize 10 hours agorootparentThat's a feature, not a bug. reply makeitdouble 8 hours agorootparentprevI think it's probably pushing pattern it sees in other users. There's videos I'll watch multiple times, music videos are the obvious kind, but for some others I'm just not watching/understanding it the first time and will go back and rewatch later. But I guess youtube has no way to understand which one I'll rewatch and which other I don't want to see ever again, and if my behavior is used as training data for the other users like you, they're probably screwed. reply godshatter 8 hours agorootparentA simple \"rewatch?\" line along the top would make this problem not so brain dead bad, imho. Without it you just think the algorithm is bad (although maybe it is? I don't know). reply layer8 11 hours agorootparentprevThis is happening to me to, but from the kind of videos it's suggested for I suspect that people actually do tend to rewatch those particular videos, hence the recommendation. reply sakesun 8 hours agorootparentprevInstall \"Unhook\" chrome extension. That changed my life. reply banish-m4 11 hours agoparentprevThanks for writing this insightful piece. The pathologies of big companies that fail to break themselves up into smaller non-siloed entities like Virgin Group does. Maintaining the successful growing startup ways and fighting against politics, bureaucracy, fiefdoms, and burgeoning codebases is difficult but is a better way than chasing short-term profits, massive codebases, institutional inertia, dealing with corporate bullshit that gets in the way of the customer experience and pushes out solid technical ICs and leaders. I'm surprised there aren't more people on here who decide \"F-it, MAANG megacorps are too risky and backwards not representative of their roots\" and form worker-owned co-ops to do what MAANGs are doing, only better, and with long-term business sustainability, long tenure, employee perks like the startup days, and positive civil culture as their central mission. reply godelski 9 hours agorootparentWhat's odd to me is how everything is so metricized. Clearly over metricization is the downfall of any system that looks meritocratic. Due to the limitations of metrics and how they are often far easier to game than to reach through the intended means. An example of this I see is how new leaders come in and hit hard to cut costs. But the previous leader did this (and the one before them) so the system/group/company is fairly lean already. So to get anywhere near similar reductions or cost savings it typically means cutting more than fat. Which it's clear that many big corps are not running with enough fat in the first place (you want some fat! You just don't want to be obese!). This seems to create a pattern that ends up being indistinguishable from \"That worked! Let's not do that anymore.\" reply jaynate 6 hours agorootparentAgree you have to mix qualitative with the quantitative, but the best metrics systems don't just measure one quantity metric. They should be paired with a quality metric. Example: User Growth & Customer Engagement Have to have user growth and retention. If you looked at just one or the other, you'd be missing half the equation. reply dbingham 6 hours agorootparentprevThe hard part about starting worker owned co-ops is financing. We need good financing systems for them. People/firms who are willing to give loans for a reasonable interest, but on the scale of equity investment in tech start ups. reply barfbagginus 11 hours agorootparentprevI formed a worker co-op - but it's just me! And I do CAD reverse engineering, nothing really life-giving. I would love to join a co-op producing real human survival values in an open source way. Where would you suggest that I look for leads on that kind of organization? reply atif089 9 hours agorootparentLet's start with replacing Google. Count me in. While DDG, Brave, Kagi etc are working generously to replace Google search. The other areas that I think get less attention and needs to be targeted to successfully dismantle them and their predatory practices are Google maps and Google docs. Maps are hard because it requires a lot of resources and money and whatever but replacing docs should be relatively easier. reply disqard 9 hours agorootparent(paid user of Kagi here) FWIW, Kagi is built on top of Google search, so yes it's \"replacing\" (for you and me) a dependence on Google search, but it is categorically not a from-the-ground-up replacement for Google search. reply ninjaa 6 hours agorootparentOh that's pretty smart reply jaynate 6 hours agorootparentprevUsing OSS to commoditize complements plays a big role in breaking up big advantages. There is big tech open source consortium working on maps now to commoditize it: https://siliconangle.com/2022/12/15/aws-microsoft-meta-tomto... Not sure it'll work. I think half the advantage comes from the integration across all these tools (maps, search, etc). Have you ever tried to use duckduckgo? It surprised me what I take for granted in Google's user experience. reply hsbauauvhabzb 10 hours agorootparentprevI would imagine GitHub and technology social media reply jaynate 6 hours agorootparentprevI guess it depends on how much equity you own as to what is better (to your first paragraph), and how large the paycheck is (to the 2nd paragraph. reply delfinom 10 hours agorootparentprevProblem is, worker owned co-ops would still require money to do anything even remotely competitive to existing businesses. So... people go walk up for handouts from VCs....and the story begins lol. reply mrkeen 2 hours agoparentprev> There is a semi-famous internal document he wrote where he argued against the other search leads that Google should use less machine-learning, or at least contain it as much as possible, so that ranking stays debuggable and understandable by human search engineers. There's a lot of ML hate here, and I simply don't see the alternative. To rank documents, you need to score them. Google uses hundreds of scoring factors (I've seen the number 200 thrown about, but it doesn't really matter if it's 5 or 1000.) The point is you need to sum these weights up into a single number to find out if a result should be above or below another result. So, if: - document A is 2Kb long, has 14 misspellings, matches 2 of your keywords exactly, matches a synonym of another of your keywords, and was published 18 months ago, and - document B is 3Kb long, has 7 misspellings, matches 1 of your keywords exactly, matches two more keywords by synonym, and was published 5 months ago Are there any humans out there who want to write a traditional forward-algorithm to tell me which result is better? reply datadeft 2 hours agorootparentYou do not need to. Counting how many links are pointing to each document is sufficient if you know how long that link existed (spammers link creation time distribution is widely differnt to natural link creation times, and many other details that you can use to filter out spammers) reply mrkeen 1 hour agorootparent> You do not need to. Ranking means deciding which document (A or B) is better to return to the user when queried. Not writing a traditional forward-algorithm to rank these documents implies one of the following: - You write a \"backward\" algorithm (ML, regression, statistics, whatever you want to call it). - You don't use algorithms to solve it. An army of humans chooses the rankings in real time. - You don't rank documents at all. > Counting how many links are pointing to each document is sufficient if you know how long that link existed - Link-counting (e.g. PageRank) is query-independent evidence. If that's sufficient for you, you'll always return the same set of documents to each user, regardless of what they typed into the search box. At best you've just added two more ranking factors to the mix: - document A qie: length: 2Kb misspellings: 14 age: 18 months + in-links: 4 + in-link-spamminess: 2.31E4 qde: matches 2 of your keywords exactly matches a synonym of another of your keywords - document B qie: length: 3Kb misspellings: 7 age: 5 months + in-links: 2 + in-link-spamminess: 2.54E3 qde: matches 1 of your keywords exactly matches 2 keywords by synonym So I ask again: - Which document matches your query better, A or B? - How did you decide that, such that not only can you program a non-ML algorithm to perform the scoring, but you're certain enough of your decision that you can fix the algorithm when it disagrees with you ( >> debuggable and understandable by human search engineers ) reply datadeft 36 minutes agorootparentStatistical methods are debuggable. Is PageRank not debuggable? I am not sure where ML starts and statistics end. reply raincole 2 hours agorootparentprev> spammers link creation time distribution is widely differnt to natural link creation times Yes, this is a statistical method. Guess what machine learning is and what it actually excels? reply AlbertCory 13 hours agoparentprevAmit was definitely against ML, long before \"AI\" had become a buzzword. reply mike_hearn 11 hours agorootparentHe wasn't the only one. I built a couple of systems there integrated into the accounts system and \"no ML\" was an explicit upfront design decision. It was never regretted and although I'm sure they put ML in it these days, last I heard as of a few years ago was that at the core were still pages and pages of hand written logic. I got nothing against ML in principle, but if the model doesn't do the right thing then you can just end up stuck. Also, it often burns a lot of resources to learn something that was obvious to human domain experts anyway. Plus the understandability issues. reply zem 12 hours agoparentprevi worked on ranking during singhal's tenure, and it was definitely refreshing to see a \"no black box ML ranking\" stance. reply jokoon 11 hours agoparentprevsimplicity is always the recipe for success, unfortunately, most engineers are drawn to complexity like moth to fire if they were unable to do some AB testing between a ML search and a non-ML search, they deserve their failure 100% there are not enough engineers blowing the whistle against ML reply 1024core 8 hours agorootparent> most engineers are drawn to complexity like moth to fire Unfortunately, Google evaluates employees by the complexity of their work. \"Demonstrates complexity\" is a checkbox on promo packets, from what I've heard. Naturally, every engineer will try to over-complicate things just so they can get the raises and promos. You get what you value. reply ants_everywhere 9 hours agorootparentprevI definitely think the ML search results are much worse. But complexity or not, strategically it's an advantage for the company to use ML in production over a long period of time so they can develop organizational expertise in it. It would have been a worse outcome for Google if they had stuck to their no ML stance and then had Bing take over search because they were a generation behind in technology. reply baryphonic 5 hours agoparentprevI'm glad you shared this. My priors before reading this article were that an uncritical over-reliance on ML was responsible for the enshittification of Google search (and Google as a whole). Google seemed to give ML models carte blanche, rather than using the 80-20 rule to handle the boring common cases, while leaving the hard stuff to the humans. I now think it's possible both explanations are true. After all, what better way to mask a product's descent into garbage than more and more of the core algorithm being a black box? Managers can easily take credit for its successes and blame the opacity for failures. After all, the \"code yellow\" was called in the first place because search growth was apparently stagnant. Why was that? We're the analysts manufacturing a crisis, or has search already declined to some extent? reply ot1138 15 hours agoprevPhenomenal article, very entertaining and aligns with my experience as a prominent search \"outsider\" (I founded the first search intelligence service back in 2004, which was later acquired by WPP. Do I have some stories). The engineers at Google were wonderful to work with up to 2010. It was like a switch flipped mid-2011 and they became actively hostile to any third party efforts to monitor what they were doing. To put it another way, this would like NBC trying to sue Nielsen from gathering ratings data. Absurd. Fortunately, the roadblocks thrown up against us were half-hearted ones and easily circumvented. Nevertheless, I had learned an important lesson about placing reliance for one's life work on a faceless mega tech corporation. It was not soon after when Google eliminated \"Don't Be Evil\" from the mission statement. At least they were somewhat self aware, I suppose. reply ChuckMcM 14 hours agoparentI'm really glad the article came out though, it fills in some gaps that I was fairly confident about but didn't have anything other than my sense of the players and their actions to back up what I thought was going on. I and a number of other people left in 2010. I went on to work at Blekko which was trying to 'fix' search using a mix of curation and ranking. When I left, this problem of CPC's (the amount Google got per ad click in search) was going down (I believe mostly because of click fraud and advertisers losing faith in Google's metrics). While they were reporting it in their financial results, I had made a little spreadsheet[1] from their quarterly reports and you can see things tanking. I've written here and elsewhere about it, and watched from the outside post 2010 and when people were saying \"Google is going to steam roll everyone\" I was saying, \"I don't think so, I think unless they change they are dead already.\" There are lots of systemic reasons inside Google why it was hard for them to change and many of their processes reinforced the bad side of things rather than the good side. The question for me has always been \"Will they pull their head out in time to recover?\" recognizing that to do that they would have to be a lot more honest internally about their actions than they were when I was there. I was also way more pessimistic, figuring that they would be having company wide layoffs by 2015 to 2017 but they pushed that out by 5 years. I remember pointing out to an engineering director in 2008 that Google was living in the dead husk of SGI[2] which caused them to laugh. They re-assured me that Google was here to stay. I pointed out that Wei Ting told me the same thing about SGI when they were building the campus. (SGI tried to recruit me from Sun which had a campus just down the road from where Google is currently.) [1] https://docs.google.com/spreadsheets/d/18_y-Zyhx-5a1_kcW-x7p... [2] Silicon Graphics -- https://www.sfchronicle.com/news/article/peninsula-high-tech... reply iamthirsty 14 hours agorootparent> I was also way more pessimistic, figuring that they would be having company wide layoffs by 2015 to 2017 but they pushed that out by 5 years. Well in 2011 Google had just over 30k employees, and now they're doing \"layoffs\" with 180k+ in 2024. I don't think the layoffs mean much. reply ChuckMcM 12 hours agorootparentDid I mention I was more pessimistic? :-) I expect that today they could layoff 150k, keep the 30K that are involved with search and enough ads that are making business and that husk would do okay for a long time. I don't suppose you watched SGI die, that happened to them, kind of spiraled into a core that has some money making business and then lived on that. One of my observations between \"early\" Google and \"late\" Google (and like the grandparent post I see 2010 as a pretty key point in their evolution) was employee \"efficiency.\" I don't know if you've ever been in that situation where someone leaves a company and the company ends up hiring two or three people to replace them because of all the things they were doing. Not 10x engineers but certainly 3 - 5x engineers. Google starting losing lots of those in that decade. They had gone through the \"Great Repricing\" in 2008 when Google lowered the strike price on thousands of share options. And having been there 5 to 10 years had enough wealth built up in Google stock that for a modest level of \"this isn't fun any more\" could just do that. But aside from your observation that \"they have plenty of people\" it is similar to observing that a plane that has lost its engine at 36,000' has \"plenty of altitude\" both true and less helpful than \"and here is the process we're going to use as we fall out of the sky to get the engines back on.\" Google has lots of resources. If you have ever read about IBM reinventing itself in the 90's its quite interesting to note that had IBM not owned a ton of real estate it likely would not have had the resources to restructure itself. I worked with an executive at IBM who was part of that restructuring and it really impressed on me how important \"facing reality\" was at a corporation, and looking at the situation more realistically. I had started trying to get Google to do that but gave up when Alan Eustace explained that he understood my argument but they weren't going to do any of the things I had recommended. At that point its like \"Okay then, have fun.\" Still, at some point, they could. They could figure out exactly what their \"value add\" is and the big E economics of their business and realign to focus on that. Their 'mission oriented' statement suggests that they are paying some attention to that idea now. But to really pull it off a lot of smart, self-interested, and low-EQ people are going to have to come to terms with being wrong about a lot of stuff. That is what I don't see happening and so I'm not really expecting them to transform. Both not enough star bits and the luma are just not hungry enough. reply dekhn 10 hours agorootparentAre you suggesting that Google fire all the engineers who work on Cloud? That would... be a very interesting business decision, likely closing any door for them working with enterprise in the future. Here's a few more realistic changes that Alphabet could make: - shut down X - shut down Verily - sell calico or shut it down if no buyers - sell Fiber or shut it down if no buyers - shut down Intrinsic, Wing, and all the other X spinoffs - make Cloud be its own Alphabet company with Kurian as an actual CEO That would show Wall Street that GOogle is really serious about not wasting money on crazy ideas. That would boost the price (along with reducing costs) giving them some runway. I think it would be a shame if Waymo was shut down but it has a long, long way to being highly profitable. It looks like Alphabet wants to sell Verily or spin it out of the Alphabet family entirely (after decoupling Verily's infrastructure from Google's) but nobody wants to buy it. reply ChuckMcM 9 hours agorootparentI was suggesting that they fire all the engineers that work on things that don't make money. It was only last quarter that Cloud actually made a profit. That said, I think you make a reasonable restructuring case; Now you just have to figure out how to get leadership to buy in and execute on that plan. In my experience two things work against that. 1) If it isn't their idea that don't believe it will do any good and could not possibly be the \"right\" thing to do. 2) If they don't have a job after it happens, they will work behind the scenes to sabotage attempts to make it happen. You can work around those, but you need \"existential risk\" level energy to create that sort of change in a company. reply lupire 7 hours agorootparentBut Google seems to be doing decently well compared to blekko and Watson? reply ChuckMcM 7 hours agorootparentThat it is, but a more apt comparison would be Duck Duck Go which was a contemporary of Blekko and definitely out performed relative to Blekko's success. DDG still going strong and even buying TV ads, so yeah. That said, how Blekko and Watson ended up squandering good technology in search of something else is also an interesting learning experience/tale. reply skybrian 2 hours agorootparentprevLooking at financials, all metrics are improving. They haven’t even started to lose altitude - they’re still gaining. We might not like what they’ve become, but the comparison to a plane that’s lost its engine seems rather odd. Why couldn’t they keep going indefinitely, without making the changes that some would like? reply bane 6 hours agorootparentprevChuckMcM, I just wanted to say, I really appreciate the long view you bring to HN discussions. When you've been in tech for a few decades you start to see predictable patterns. History may not repeat, but it often rhymes. reply disqard 3 hours agorootparentPiggybacking on this to also express my appreciation. If/when you write a memoir someday, it would be a valuable historical record. If not, your hn comments are a wonderful corpus too :) Thank you for sharing your experiences, Chuck! reply maxerickson 14 hours agorootparentprevWhat is definition of dead? 15 years later they have huge majority of traffic share and lots of revenue. reply AnthonyMouse 14 hours agorootparentCompanies this size die several years before the body hits the floor. They're dead when everyone starts to hate them and someone says \"no, look how much money they're making, they're fine.\" That's the fatal blow, because they think they're fine, and keep doing the things that make everyone hate them. At that point you're just waiting for someone else to offer an alternative. Then people prefer the alternative because the incumbent has been screwing them for so long, and even if they change at that point, it's too late because nobody likes or trusts them anymore, and ships that big can't turn on a dime anyway. You have to address the rot when customers start complaining about it, not after they've already switched to a competitor. reply ChrisMarshallNY 13 hours agorootparentThat sounds a lot like Kodak. I remember running into Kodak engineers, at an event in the 1990s, and they were all complaining about the same thing. They were digital engineers, and they were complaining that film people kept sabotaging their projects. Kodak invented the digital camera. They should have ruled the roost (at least, until the iPhone came out). Instead, they imploded, almost overnight. The film part was highly profitable. Until it wasn't. By then, it was too late. They had cooked the goose. reply binarymax 12 hours agorootparentIf they owned the digital camera space like they should have, who’s to say they wouldn’t have eventually released a smartphone. It probably would have been an absolutely incredible camera first, and some mobile internet and phone features second. One can really dream up a fascinating alternate timeline of iKodak if they didnt shoot themselves in the foot. reply SllX 11 hours agorootparentAnd even if they didn’t, maybe it would be Kodak sensors in iPhones instead of Sony sensors. A lot of possibilities. reply BlueTemplar 5 hours agorootparentprevNote that Nokia was already \"great camera, first smartphones\". reply Terr_ 8 hours agorootparentprevI'm not a Steve Jobs fan, but one business-quote I do like: \"If you don't cannibalize yourself, someone else will.\" In other words, it could have been better for Kodak as a whole if they allowed their digital-arm to compete more with their film-arm, so that as the market shifted they'd at least be riding the wave rather than under it. reply MattyRad 4 hours agorootparentI'm also not a Steve Jobs fan, and this reminds me of how Flash died[1]. The Flash Renaissance was the counter-era to the search despair era we currently find ourselves in. In the same vein as Kodak, I wonder what the alternate timeline would look like where Adobe cannibalized native apps. [1] https://youtu.be/65crLKNQR0E?si=mXPgXxlMRxU-xjcu&t=2472 reply AnthonyMouse 36 minutes agorootparentThe mistake Adobe made was in canceling Flash instead of open sourcing it. Publish a spec and the let browsers implement the client side, then you can keep selling tools to make animations without everyone having to deal with the bug-riddled proprietary player Adobe clearly had no interest in properly maintaining to begin with. It's kind of astonishing that all these years later we still don't have something equivalent in browsers. In theory they're Turing-complete and you can do whatever you want, but where's the thing that makes it that easy? reply jeffbee 12 hours agorootparentprevThe just-so story about Kodak is one of those things that bugs me. Kodak did own the digital camera market, stem to stern, for years. They did not ignore it. They did, however, invent all that stuff a little early, before the semiconductor manufacturing technology had matured to the point where it could be a consumer good. The company imploded because it spent all of its time, attention, and capital trying to become a pharmaceutical factory, starting in the mid-1980s. reply phonon 1 hour agorootparentWell, NYSE: EMN is worth $12 B..... reply binarymax 12 hours agorootparentprevYeah, lots of things happened for a perfect storm of downfall…probably starting with the antitrust breakup of the film processing division. They did indeed have a huge patent arsenal from all their research efforts that was very valuable. They were also really good at consumer tech - so it’s a shame it didn’t amount to more. reply Certhas 12 hours agorootparentprevAny examples of this actually playing out with a company as established as Google? You can read comments like this on many companies... Microsoft (70B$ income), Meta (40B$), Oracle (8.5B$), IBM(7.5B$), SAP (6B$), yet none of them seem to ever actually enter the predicted death spiral. And the internet isn't new anymore. There is no vast landscape of unexplored new technological possibilities, and no garage start up with an engineering mindset that will just offer a better solution. reply makeitdouble 8 hours agorootparentMicrosoft and Meta reinvented themselves a few times over. At this point Windows is just an legacy business unit for instance, and Meta literally changed name to mark the turn. Oracle, IBM and SAP have the advantage(?) of being heavily business focused from the start, and I don't see them ever die a natural death in our lifetimes. As long as they have the money to outbribe the competition they'll be there, and it will require a small miracle to break that loop. reply AnonymousPlanet 3 hours agorootparentThe one thing that has kept Microsoft afloat is their business oriented part. They are deeply entrenched in any company that needs to use Office and only ever hires Windows admins who won't even look beyond Windows. That is pretty much every non tech small to medium company. When things were shifting to the cloud they were smart enough to make sure it would be their cloud, locking customers even deeper into their own technology. Anything else they do is a bonus. reply makeitdouble 3 hours agorootparentTo add to this, Microsoft is really really good at understanding businesses, in a way Google will probably never be I think. Having on premise hosting options for Exchange and all their core services is an example of that, even as they're also pushing for 365 in the cloud. I remember them being earlier than GCP to deal with GDPR and the in EU requirements as well but my memory might be failing. reply Certhas 36 minutes agorootparentprevThe point is, if Microsoft managed, why wouldn't Google be able to reinvent itself? reply AnthonyMouse 20 minutes agorootparentReinventing yourself because you imploded your primary market is still an own-goal. If you can capture a new market then you could have had both. And what if the primary market collapses first? reply whizzter 6 hours agorootparentprevIBM used to be bigger than MS, it's a 10th of it today. But most importantly all the above listed companies with the exception of Meta are those that are heavily ingrained in large companies operations. IBM still provides mainframes, MS has Exchange and Windows domains and is successfully transitioning a lot of customers to Azure, Oracle has their databases and other products, SAP their ERP systems. Once a non-IT company has their internal IT systems and some legacy working they're going to be very very slow in changing them out if it works, companies that provide those and get a critical are going to have very very long runways compared to regular b2c companies if a significant portion of their revenue comes from this. Google has Chromebooks that are used in schools and some GCP usage but could that save Google long enough if search revenue was cut into a fraction? And GCP is kinda of an also-ran today, people looking at larger options usually look at AWS(nr 1) or Azure (Windows legacy). reply Certhas 30 minutes agorootparentIn 2023 the revenues of Google Cloud, Youtube Ads and \"Google Other\" and Google Network Members Ads were 130B combined. If they could reduce headcount and operating expenditures to 2019 levels without losing that, they would be roughly breaking even without any search. They also have 280B$ in equity to tide them over. When Google actually sees its business failing, it will have many many many chances to turn things around. reply Eisenstein 12 hours agorootparentprevAT&T, GE, AOL, Yahoo, Sony technology (they are a media company now, but they did used to make things that weren't a game console), Time Warner, SGI, Compaq, 3DFx, DEC... reply AnthonyMouse 11 hours agorootparentNot only that, most of the other examples are just not at the end of their death spiral yet. Take a look at Windows market share, it's down 20% over the last 10 years: https://www.statista.com/statistics/218089/global-market-sha... And that's just desktop. Microsoft ceded the entire mobile market, which in turn now represents the majority of devices. The majority of the company's profits no longer come from selling Windows and Office. If they hadn't pivoted into a new line of business (Azure) they'd be on a trajectory to impact with the ground. IBM has been bleeding customers -- and business units -- for decades. Their stock is flat, not even keeping up with inflation, compared to +300% over the last decade for the overall market. And they have no obvious path to redemption. Oracle is kind of an outlier because of the nature of their business. Their product has an extraordinarily high transition cost, so once you're locked in, they can fleece you pretty hard and still not have it cost more than the cost of paying database admins high hourly rates for many hours to transition to a different database. Then they focus their efforts on getting naive MBAs to make a one-time mistake with a long-term cost. Or just literal bribery: https://www.cnbc.com/2022/09/27/sec-fines-oracle-23-million-... And even with that, their database market share has been declining and they're only making up the revenue in the same way as Microsoft through cloud services. Meta isn't a great example because people just don't hate them that much. Facebook sucks but in mostly the same ways as their major competitors, they're still run by the founder and they do things people like, like releasing LLaMA for free. reply Certhas 8 minutes agorootparentAll of the companies I cited are hugely profitable. They might not be as large as they once were, or as important, but a business that has non-declining net income in the billions is not in a death spiral. IBM has shrunk a lot, but except for the financial crisis in the 90s, they have been profitable every year, and profits are roughly flat since 2017. This is certainly a completely different picture than Yahoo for example. And your argument for Microsoft is that they are in a death spiral because they only have 70% of market share on the desktop, and are shrinking by 2% per year, so in, uh 15 Years they might only have 50% of the market share! Also, please ignore that they successfully diversified their revenue streams to other markets (Cloud). And your evidence is that they failed to capture the mobile market. While you also argue that Google is in a death spiral when Google is actually the company that won the mobile market. I think you might be using the term death spiral in an unconventional way here. arromatic 2 hours agorootparentprevstatista is locked behind paywall reply AnthonyMouse 29 minutes agorootparentYeah, it's a pain in the butt. It often shows you the graph and then you try to show the link to someone else and it tries to get them to swipe their card as if anybody is going to do that. Meanwhile it ranks highly in Google search results instead of some other site that contains the same information without the bait and switch, because Google has completely lost the ability to produce quality search results. Maybe it's time to switch to a competitor. reply agar 6 hours agorootparentprevSymantec comes to mind. reply samch 13 hours agorootparentprevI know they aren’t the same scale as Google, but what you wrote really describes Atlassian for me. reply rurp 12 hours agorootparentWhile I totally agree that Atlassian products are terrible and steadily getting even worse, I'm not sure they are going anywhere anytime soon given their disconnect between users and customers. Most people who have to suffer their products have no say in the purchasing decision, and the company does a somewhat better job of appealing to the relative small group that does. Atlassian could very well have Oracle-like staying power. reply carlossouza 8 hours agorootparentprevThat also sounds a lot like Blockbuster. Google continues generating profits out of inertia and a lack of a better alternative. It went for “don’t be evil” to “a necessary evil” (just until something a little better appears). reply eproxus 14 hours agorootparentprevThe bigger the behemoth, the slower the fall. reply ChuckMcM 14 hours agorootparentprevYou know how a chess player will say something like \"mate in 6\" because their experience of all the options left to their opponent are both easily countered and will not prevent them from losing? Companies, and tech companies in my experience, get into death spirals due to a combination of people, culture, and organization. Pulling out of one of those is possible but requires a unique combination of factors and a strong leadership team to pull off. Something that is very hard to put into place when the existing leadership has overriding voting power. You can look at GE, IBM, and to some extent AT&T as companies that have \"re-invented\" themselves or at least avoided dissolution into an over marketed brand. I have a strong memory of watching a Jacques Cousteau documentary on sharks and learning that Sharks could become mortally wounded but not realize it because of how their nervous system was structured. As a kid I thought that was funny, as an engineer watching companies in the Bay Area die it was more sobering. If you have read the article, I think Gomes was right and saw search as a product, whereas Raghavan saw it as a tool for shoveling ads. A good friend of mine who worked there until 2020 wouldn't tell me why they left, but acknowledged that it was this that finally \"ruined\" Google. Their cash cow is dying, I know from running a search engine what sort of revenue you can get from being \"just one of the search engine choices\" versus the 800lb gorilla. Advertisers are disillusioned, and structurally their company requires growth to support the stock price which supports their salary offerings. There is a nice supportable business for about 5,000 - 8,000 people there, but getting there from where they are? My best guess at the moment is that when they die, \"for reals\" as they say, their other bets will either be spun off or folded, their search team will get bought by Apple with enough infrastructure to run it, Amazon or someone else buys a bunch of data centers, and one of the media companies buys the youtube assets. reply iamthirsty 14 hours agorootparent> You know how a chess player will say something like \"mate in 6\" because their experience of all the options left to their opponent are both easily countered and will not prevent them from losing? As a chess person, saying \"Mate in _\" means it's a calculated inevitability. There is no mathematical way out of it. It is not nearly equivalent to the outside judgement of a company with so many factors — it's just incomparable. reply ChuckMcM 12 hours agorootparentI don't disagree, chess is much more algorithmic and predictable. Maybe it is more like seeing your best mate of the last 20 years getting into their fourth or fifth relationship with the same kind of partner they failed with before and thinking, \"Seen this movie before, it is not gonna work out.\" No algorithms, just you know how you're friend sabotages themselves and you also know they can't (or won't) look critically at that behavior, and so they are doomed to fail again. But I can guarantee you that Google employees are reading these comments and saying \"Wow, this guy is totally full of it, he doesn't know about anything!\" and for some of them that thought will arise not from flaws in what I and others are saying, but in the uncomfortable space of \"if this is accurate my future plans I'm invested in are not going to happen..., this must be wrong.\" I have lived in that space with an early startup I helped start, when I went back and worked on the trauma it had caused me it taught me a lot about my willingness to ignore the thinking part of my brain when it conflicted with the emotional part. You have to do some of that to take risks, but you also have to recognize that they are risks. Painful lesson for me. reply narag 13 hours agorootparentprevYes, but there are other positions that do fit the comparison, like a couple of advanced passed pawns that can still be defended against with surgical precision, but most times are lethal. reply iamthirsty 13 hours agorootparentAgain, I think there is a misunderstanding of what the saying is used for. In chess, it's specifically used for saying \"even with the best defense possible, you will be mated no mater what in a maximum of X moves.\" Computers use this definition as well. If Stockfish says # in 6, that means there is an indefensible path to mate available, and with the best play of the opponent will take 6 moves. It's not a \"Mate in X, probably.\" reply temporarely 13 hours agorootparentprevChuck, curious if you have ever posted here on what happened to Sun Micro. Love to read your take on it. reply ChuckMcM 11 hours agorootparentI don't think so. At one of the Sun Reunion events a bunch of us sat around and talked about it. I suggested someone should write a companion volume to \"Sunrise: The first 10 years of Sun\" called \"Sunset: The last 10 years of Sun.\" But as far as I know nobody followed up (if they did they didn't reach out to me for my take) reply temporarely 11 hours agorootparentQuit teasing. Give us a taste, then. [:)] reply ChuckMcM 9 hours agorootparent#E#M#A#I#L#I#N#B#I#O# :-) reply temporarely 8 hours agorootparentwill do, sir. reply bane 6 hours agorootparentprevWith Google, I always feel like the side hustles (waymo, X, etc.) Really exist to be sold off in the future to prop up the add/search business and ensure future profitability. Everything not adds/search is on that list, and anything shut down despite being useful isn't seen as future-sellable. Google today is starting to smell of future financial engineering games, like when a car maker earns more through financing than selling core product. reply bevekspldnw 13 hours agorootparentprevThe majority of that revenue comes from violating data protection law and regulators and litigants are slowly racking up a series of wins which will gut ads margins. There is no Plan B, they are just going to break the law until they can’t and there’s zero clue what happens after that. They sat back and let OpenAI kick their ass precisely because ghouls like Prabakar call the shots and LLM are not a good display ads fit. The best parallel for Google is Kodak. reply sevagh 14 hours agorootparentprevNumber of HN complaints per day posted. reply arromatic 14 hours agorootparentprevHow did the slashtag feature worked and what did it do ? It seems like a interesting concept but sadly the site is dead . What happened to it ? reply ChuckMcM 14 hours agorootparentPeople would add sites for a particular topic (aka slashtag) to their list. That would build a virtual custom search engine within the search engine. And topic specific searches thrown at it would consistently out perform Bing and Google in terms of search quality. The meta \"spam\" slash tag (everyone got their own) would let you tell the engine sites you never wanted to see in your search results so if you were tired of your medical queries being spammed by quacks, add them to your spam list and they wouldn't be in your results. reply leoc 11 hours agorootparentFWIW, I've wanted things like that for so long. I'm sad that I never even heard of Blekko. reply arromatic 2 hours agorootparentprevWhy did it shut down ? reply bbor 14 hours agorootparentprevA) I think it’s important to acknowledge that in many ways Google is actively trying to keep CPC low - what they care most about is total spend. A low CPC means an effective advertising network where interested consumers are efficiently targeted. Their position is complex thanks to their monopoly status over online advertising. B) I don’t think it’s fair to characterize recent layoffs as some put-off collapse… criticize Google all you want for running a bad search engine, but right now they’re still dominant and search is the most effective advertising known to man. They’re raking in buckets of money: they had 54K employees on 01/01/2015, and 182K on 01/01/2024. Similarly, they made 66B in 2014, and 305B in 2023. The latest layoffs are them cleaning house and scaring their workers into compliance, not the death throes of a company in trouble — they’re barely a dent in the exponential graphs: https://www.macrotrends.net/stocks/charts/GOOG/alphabet/numb... reply candiodari 12 hours agorootparentA) This is short-sighted. What you're suggesting is in fact a way to optimize short-term gain over long-term viability. It's pure MBA tactics. Additionally, it's complete and total oversimplification. If you look at Google's earnings it's pretty damn clear that at least until 2020 they were not just going for maximum total spend, but for a steady, gradual raise in total spend. Not too slow, not too fast. They were NOT taking every opportunity they had, in fact they're famous for systematically refusing many opportunities (see the original founders' letter, but even after that). They were farming the ad market, the ad spend, growing it, nurturing it. Then COVID blew up the farm. Maybe you're right now, but I do hope they're recovering their old tactics. Because if they maximize it you'd see nothing but scams ... wait a second. B) Google was built by providing a vision, and getting out of the way of ground-up engineer efforts. \"Scaring workers into compliance\" IS killing the golden goose. You can see this in AI. Every story from an AI engineer that ran away from Google is the same. They didn't run away for the money, they ran away because they were getting scared into compliance. Now AI may make it, or not. I don't know. But this is happening EVERYWHERE in Google. Every effort. Every good idea, and every bad idea runs away, usually inside the mind of \"a worker\". Not to make them personally maximum money, but it's natural selection: if the idea doesn't run away, the engineer it's in is \"scared into compliance\", into killing the idea. Whatever the next big thing turns out to be, it simply cannot come out of Google. And it will hit suddenly, just like it did for Yahoo. reply bbor 12 hours agorootparentTotally agree on the overall prognosis of Google - I am (also?) one of said engineers! Here’s a recent update from a tiny corner of the company: the rank and file is still incredibly smart and generally well-intentioned, but are following hollow simulacrums of the original culture - all-hands, dogfooding, internal feedback, and ground-up engineering priorities are all maintained in form, but they are now rendered completely functionless. I am personally convinced that the company is — or was, before ChatGPT really took off - focused on immediate short term stock value above all else. After all, if you were looking down the barrel of multiple federal and EU antritrust suits and dwindling public support for the utility you own and operate, you might do the same… I guess I’m standing up for the simple idea that terribly inefficient organizations can prevail when they’re the incumbents, at least for significant periods if not forever. We can’t be complacent and assume they’ll fall on their own, esp when AGI threatens social calcification on an unheard of scale. reply cbsmith 7 hours agorootparentIronically (and unsurprisingly), it's a repeat of what happened at Yahoo. ;-) reply barfbagginus 11 hours agorootparentprevDrop your good intentions - towards Google, that is. Work to sabotage and collapse the organization - do that for the good of humanity. Thank you for your work, and good luck getting out without harm or reprisalYou can see this in AI. Every story from an AI engineer that ran away from Google is the same. They didn't run away for the money, they ran away because they were getting scared into compliance. Can you elaborate? reply swader999 12 hours agorootparentYeah, what is scared into compliance? reply candiodari 11 hours agorootparentBeing pushed/forced to implement top-down efforts, forced to comply with management's directives instead of being empowered to build things bottom-up https://sifted.eu/articles/deepmind-talent https://www.businessinsider.com/ai-researcher-quit-google-op... https://www.bloomberg.com/opinion/features/2023-07-13/ex-goo... https://mdwdotla.medium.com/why-im-leaving-google-for-a-star... reply worik 10 hours agorootparentprev> The latest layoffs are them cleaning house and scaring their workers into compliance, not the death throes of a company in trouble Really? I have the impression Google’s other tools (I have lots of uses of Docs and Meet ) are degrading in quality quite quickly That is a subjective judgement, but it seems Google no longer cares reply greg_V 17 minutes agoparentprevThe 2010-2013 timeline was also when the problem of ad fraud exploded. Google even acquired a company (or multiple, if I recon correctly: https://www.ft.com/content/352c7d8e-9acc-11e3-946b-00144feab... ). You had these companies popping up left and right that were snooping on Google and the emerging programmatic advertising environment to see if the websites and the traffic delivered were legit, and there were some scary numbers flying around. The whole problem kind of got swept under the rug with most advertising ecosystems implementing a checkbox solution for clean traffic, and the web turned mobile user first. My impression is that ad fraud never disappeared - it just got sanitized and rolled in with the other parts of the ad stack. reply arromatic 15 hours agoparentprev1. Do you know what caused it ? 2. How did the hostility look like ? 3. How did you circumvented them ? 4. What did your search service do ? reply ot1138 14 hours agorootparentI don't know what caused it but I suspected at the time, and still do, that it was simply business people getting more involved in order to drive growth. The hostility was simply this. One day we had a dedicated high level Google engineer helping us out and giving us guidance (and even special tags) to get the data we needed in a cost effective manner for both Google and us. The next day, he was gone and we received demands to know exactly what we were doing, why and even sensitive information about our business. After several months of such probing, we were summarily told that the access we had was revoked and that there was no recourse. We circumvented by setting up thousands of unique IP addresses in 50+ countries throughout the world and pointing our spiders at Google through them (same as they do to everyone else). These were throttled to maintain very low usage rates and stay off the radar. We continually refilled our queues with untouched IPs in case any were ever blacklisted (which happened occasionally). As for what we did, we sampled ads for every keyword under the sun, aggregated and analyzed them to find out what was working and what wasn't. This even led to methods for estimating advertiser budgets. At one point, we had virtually every Google advertiser and their ongoing monthly spend, keywords and ad copy in our database. Highly valuable to smart marketers who were looking for an edge. reply ChrisMarshallNY 11 hours agoparentprevI enjoy reading this chap's stuff. It's not the way that I would write, but he's got a much broader audience than I do, so he obviously is meeting the needs of the reading population. I do feel that I can't argue with his stuff, although it is very dark and cynical (and, truth be told, I have a lot of dark and cynical, in me, as well, but I try not to let it come out to play, too often). reply ilrwbwrkhv 14 hours agoparentprevHow many companies have management consultants taken down? It's quite amazing how bad they are at anything. Peter Thiel's hatred for consultants is really legit. reply sn41 6 hours agoprevGreat article. But the author can't be serious about no one knowing who Prabhakar Raghavan is. He is, for instance, the co-author of the definitive text on randomized algorithms [Motwani and Raghavan]. He has also been a well-respected database researcher for many years. In a previous avatar, Raghavan was a pure theoretical computer scientist. As a student, he won the best student paper in FOCS, the Machtey award, which is kind of a big deal. The work was related to randomized rounding, which is a bread-and-butter technique for LP relaxation approaches to integer optimization, similar to knapsack problems. This is not to defend any bad decisions he may have made at Google and Yahoo, but to make him an anonymous clueless corporate honcho who is good only at scheming and wrecking companies is bizarre. All this information, moreover, is available on Wikipedia and (cough) Google scholar. https://scholar.google.com/citations?user=FtMADIMAAAAJ&hl=en... reply tflol 4 hours agoparenti love this person google scholar, it is important to this employee resume that the moment i click on this link i immediately see compact list of articles with brief introductions in plaintext. very easy to see everything and access exactly what i'm interested in almost immediately with a swift skim. it sadly ironic how google search used to look like this, now it looks like bloated shit, this dude pushed ruining it, yet this guys resume google scholar page just looks so slick. wow what a slick, _compact_, looking resume page. wish google search looked like this EDIT: we should advertise between the articles, missed revenue google scolar reply sumanthvepa 7 hours agoprevFull Disclosure: Prabhakar Raghavan was my skip-level manager at Yahoo! and I'd known of him well before that, from my days at IBM Research. The author says very few people knew who Raghavan was. Clearly he isn't a computer scientist. It is more an indication of the ignorance of the writer than anything else. Raghavan's contributions to Computer Science and, Search in particular, which were made long before he joined Yahoo!, were word-class. That is the reason he was so sought after by search engine companies. His text book on Randomised Algorithms is a classic. Calling Raghavan a 'McKinsey' consultant is just a pure ad-hominem attack. The purpose seems to be to vilify him by association. Which is utterly ironic considering that he never worked for them or was ever a 'consultant' As for his contributions at Yahoo!, I don't think he had any significant influence on the management direction that company took. In my opinion, absolutely no one at Yahoo!, CEO downwards, had much control over their destiny. Yahoo! was a clusterfck all around, with the primary problem being its utterly dysfunctional board, and unfortunate share ownership structure that made it beholden to the demands of Wall St, resulting in a parade of CEOs. Personnel churn was at such a high volume, that I, an individual contributor usually seven levels below the board, calculated that the average tenure of my leadership chain to the board changed once every fifteen days. So blaming Raghavan for what happened at Yahoo! is just stupid. I have never worked for Google, but as an outsider, I don't disagree with the assessment, that Google Search was 'getting too close to money.' But to assign blame in this manner smells like a hit piece. Managers, take their marching order from their bosses, ultimately this is the board of the company. If the board feels the need for revenue growth, no manager, CEO included has the power to resist too much. They advise against it, but in the end they will either need to to their biding or be fired. Edited for typos and grammatical errors. reply ryeights 7 hours agoparentThe author called Sundar a McKinsey consultant, not Raghavan. >A quick note: I used “management consultant” there as a pejorative. While he exhibits all the same bean-counting, morally-unguided behaviors of a management consultant, from what I can tell Raghavan has never actually worked in that particular sector of the economy. It also seems like a stretch to say that Yahoo's former \"Chief Strategy Officer\" had no influence on Yahoo's management direction. reply cbsmith 7 hours agorootparentHe called Raghavan a \"management consultant\", whilst acknowledging that he never was a management consultant. It's slinging pejorative nonsense labels. reply sumanthvepa 7 hours agorootparentprevSo why needlessly call him a management consultant? Yes it is a stretch to say he had much influence. There reason is very simple. Yahoo! was in its death throes. The core products were not bringing in revenue, and it was in the middle of multiple hostile takeover attacks by various private equity players. First it was a hostile offer from Microsoft, a hostile take over effort by Carl Icahn, and then a finally yet another, hostile take over (I forget the name of the last raider) When there is so much uncertainty, and the fight is for mere survival, strategy has no meaning. You don't strategize, when someone is shooting you in the head. reply uptownfunk 3 hours agorootparentIs it that bad to have been a mgmt consultant? My goodness reply eutropia 5 hours agoparentprevThis is a very long way of saying a very intelligent person was “just following orders”. Gomes said no. Raghavan clearly didn’t. If that’s not a clear cut case of “bearing responsibility” I don’t know what is. reply TrackerFF 1 hour agoparentprevI didn't really get the same message from this article. What I got was: Raghavan is/was a world-class computer scientist in his field, but actively pursued the management track and business strategy. And for that, well, who's the blame him? If your main goal is to make an established company make more money - making wildly unpopular decisions (as far as the customer experience goes) can be tempting and easy. The main problem here is that Google at that point was, and still is, a monopolistic behemoth. And frankly, why would they give a shit about what the customer thinks? 99% of google users are casual users that will neve scroll past the first page of search results, and will click on whatever top links google returns. As far as enshitifacation goes, google is one of the worst offenders - so clearly anti user-friendly strategy is being rewarded. reply",
    "originSummary": [
      "Google Search faced a revenue decrease in February 2019, causing conflicts within teams regarding growth strategies, with a focus on user experience preferred over negative engagement tactics.",
      "Despite attempts to rectify the situation, Google's search revenue continued to plummet, sparking discussions around management practices, profit-driven decisions, and the implications on search technology.",
      "Prabhakar Raghavan's management, influenced by his experience at Yahoo and IBM, has become a point of scrutiny for its effects on innovation and product quality within Google and the broader tech sector."
    ],
    "commentSummary": [
      "The discussion delves into Google's search quality, machine learning, AI, and business strategies, addressing leadership changes' impact, spam, SEO, and recommendation algorithm challenges.",
      "Comparison with companies like IBM and Microsoft is made, considering Google's heavy reliance on advertising revenue.",
      "Participants express skepticism towards AI and machine learning, highlighting the importance of a balanced approach with human oversight in decision-making processes."
    ],
    "points": 1503,
    "commentCount": 704,
    "retryCount": 0,
    "time": 1713890639
  },
  {
    "id": 40139398,
    "title": "CoreNet: Apple's Toolkit for Deep Neural Networks",
    "originLink": "https://github.com/apple/corenet",
    "originBody": "CoreNet: A library for training deep neural networks CoreNet is a deep neural network toolkit that allows researchers and engineers to train standard and novel small and large-scale models for variety of tasks, including foundation models (e.g., CLIP and LLM), object classification, object detection, and semantic segmentation. Table of contents What's new? Research efforts at Apple using CoreNet Installation Directory Structure Maintainers Contributing to CoreNet License Relationship with CVNets Citation What's new? April 2024: Version 0.1.0 of the CoreNet library includes OpenELM CatLIP MLX examples Research efforts at Apple using CoreNet Below is the list of publications from Apple that uses CoreNet: OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement FastVit: A Fast Hybrid Vision Transformer using Structural Reparameterization Bytes Are All You Need: Transformers Operating Directly on File Bytes MobileOne: An Improved One millisecond Mobile Backbone RangeAugment: Efficient Online Augmentation with Range Learning Separable Self-attention for Mobile Vision Transformers (MobileViTv2) CVNets: High performance library for Computer Vision, ACM MM'22 MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer, ICLR'22 Installation You will need Git LFS (instructions below) to run tests and Jupyter notebooks (instructions) in this repository, and to contribute to it so we recommend that you install and activate it first. On Linux we recommend to use Python 3.10+ and PyTorch (version >= v2.1.0), on macOS system Python 3.9+ should be sufficient. Note that the optional dependencies listed below are required if you'd like to make contributions and/or run tests. For Linux (substitute apt for your package manager): sudo apt install git-lfs git clone git@github.com:apple/corenet.git cd corenet git lfs install git lfs pull # The following venv command is optional, but recommended. Alternatively, you can create and activate a conda environment. python3 -m venv venv && source venv/bin/activate python3 -m pip install --editable . To install optional dependencies for audio and video processing: sudo apt install libsox-dev ffmpeg For macOS, assuming you use Homebrew: brew install git-lfs git clone git@github.com:apple/corenet.git cd corenet cd \\$(pwd -P) # See the note below. git lfs install git lfs pull # The following venv command is optional, but recommended. Alternatively, you can create and activate a conda environment. python3 -m venv venv && source venv/bin/activate python3 -m pip install --editable . To install optional dependencies for audio and video processing: brew install sox ffmpeg Note that on macOS the file system is case insensitive, and case sensitivity can cause issues with Git. You should access the repository on disk as if the path were case sensitive, i.e. with the same capitalization as you see when you list the directories ls. You can switch to such a path with the cd $(pwd -P) command. Directory Structure This section provides quick access and a brief description for important CoreNet directories. Description Quick Access Getting Started Working with the examples is an easy way to get started with CoreNet.└── tutorials ├── train_a_new_model_on_a_new_dataset_from_scratch.ipynb ├── guide_slurm_and_multi_node_training.md ├── clip.ipynb ├── semantic_segmentation.ipynb └── object_detection.ipynb Training Recipes CoreNet provides reproducible training recipes, in addition to the pretrained model weights and checkpoints for the publications that are listed in projects/ directory. Publication project directories generally contain the following contents: README.md provides documentation, links to the pretrained weights, and citations. /.yaml provides configuration for reproducing the trainings and evaluations. └── projects ├── byteformer ├── catlip (*) ├── clip ├── fastvit ├── mobilenet_v1 ├── mobilenet_v2 ├── mobilenet_v3 ├── mobileone ├── mobilevit ├── mobilevit_v2 ├── openelm (*) ├── range_augment ├── resnet └── vit (*) Newly released. MLX Examples MLX examples demonstrate how to run CoreNet models efficiently on Apple Silicon. Please find further information in the README.md file within the corresponding example directory.└──mlx_example ├── clip └── open_elm Model Implementations Models are organized by tasks (e.g. \"classification\"). You can find all model implementations for each task in the corresponding task folder. Each model class is decorated by a @MODEL_REGISTRY.register(name=\"\", type=\"\") decorator. To use a model class in CoreNet training or evaluation, assign moels..name =in the YAML configuration. └── corenet └── modeling └── models ├── audio_classification ├── classification ├── detection ├── language_modeling ├── multi_modal_img_text └── segmentation Datasets Similarly to the models, datasets are also categorized by tasks.└── corenet └── data └── datasets ├── audio_classification ├── classification ├── detection ├── language_modeling ├── multi_modal_img_text └── segmentation Other key directories In this section, we have highlighted the rest of the key directories that implement classes corresponding to the names that are referenced in the YAML configurations.└── corenet ├── loss_fn ├── metrics ├── optims │ └── scheduler ├── train_eval_pipelines ├── data │ ├── collate_fns │ ├── sampler │ ├── text_tokenizer │ ├── transforms │ └── video_reader └── modeling ├── layers ├── modules ├── neural_augmentor └── text_encoders Maintainers This code is developed by Sachin, and is now maintained by Sachin, Maxwell Horton, Mohammad Sekhavat, and Yanzi Jin. Previous Maintainers Farzad Contributing to CoreNet We welcome PRs from the community! You can find information about contributing to CoreNet in our contributing document. Please remember to follow our Code of Conduct. License For license details, see LICENSE. Relationship with CVNets CoreNet evolved from CVNets, to encompass a broader range of applications beyond computer vision. Its expansion facilitated the training of foundational models, including LLMs. Citation If you find our work useful, please cite the following paper: @inproceedings{mehta2022cvnets, author = {Mehta, Sachin and Abdolhosseini, Farzad and Rastegari, Mohammad}, title = {CVNets: High Performance Library for Computer Vision}, year = {2022}, booktitle = {Proceedings of the 30th ACM International Conference on Multimedia}, series = {MM '22} }",
    "commentLink": "https://news.ycombinator.com/item?id=40139398",
    "commentBody": "CoreNet: A library for training deep neural networks (github.com/apple)330 points by rocauc 8 hours agohidepastfavorite93 comments gbickford 7 hours ago> Relationship with CVNets > CoreNet evolved from CVNets, to encompass a broader range of applications beyond computer vision. Its expansion facilitated the training of foundational models, including LLMs. We can expect it to have grown from here: https://apple.github.io/ml-cvnets/index.html It looks like a mid-level implementations of training and inference. You can see in their \"default_trainer.py\"[1] that the engine uses Tensors from torch but implements its own training method. They implement their own LR scheduler and optimizer; the caller can optionally use Adam from torch. It's an interesting (maybe very Apple) choice to build from the ground up instead of partnering with existing frameworks to provide first class support in them. The MLX examples seem to be inference only at this point. It does look like this might be a landing ground for more MLX specific implementations: e.g. https://github.com/apple/corenet/blob/5b50eca42bc97f6146b812... It will be interesting to see how it tracks over the next year; especially with their recent acquisitions: Datakalab https://news.ycombinator.com/item?id=40114350 DarwinAI https://news.ycombinator.com/item?id=39709835 1: https://github.com/apple/corenet/blob/main/corenet/engine/de... reply davedx 1 hour agoparent> It's an interesting (maybe very Apple) choice to build from the ground up instead of partnering with existing frameworks to provide first class support in them. It smells of a somewhat panicked attempt to prepare for WWDC to me. Apple has really dropped the ball on AI and now they're trying to catch up. reply audunw 6 minutes agorootparentI don’t get the idea that Apple dropped the ball on AI. They were fairly early with adding neural engine hardware to their chips and have been using ML extensively on-device for a long time now They haven’t put an LLM assistant out there. But they don’t make their own search engine either so I don’t think “online LLM assistant” is something they’ll ever put much effort into unless it’s part of a bigger effort to launch their own AI-based search engine as well. As for generative AI I don’t think the quality is up to a level that would be reasonable for Apple. The only area where i would expect Apple to keep up is the kind of Copilot integration Microsoft is working on. And we know Apple is working on on-device AI assistant, and probably have for a long time. It’ll be launched when they can get good quality results on-device. Something nobody else has achieved anyway, so we can’t say that they’re behind anyone yet. reply pizza 1 hour agorootparentprevWouldn’t WWDC-related endeavors be more product-facing? I’m not so sure this has to do with their efforts to incorporate ai into products, and tbh I would say their ai research has been pretty strong generally speaking. reply davedx 1 hour agorootparentI expect that a lot of WWDC will be Apple trying to get more developers to build AI products for their platforms, because at the moment, Apple products don't have much AI. The other tech companies have integrated user facing LLM products into a significant part of their ecosystem - Google and Microsoft have them up front and center in search. Apple's AI offerings for end users are what exactly? The camera photos app that does minor tweaks to photos (composing from multiple frames). What else actually is there in the first party ecosystem that significantly leverages AI? Siri is still the same trash it's been for the last 10 years - in fact IMO it's become even less useful, often refusing to even do web searches for me. (I WANT Siri to work very well). So because their first party AI products are so non-existent, I think WWDC is a desperate attempt by Apple to get third party developers to build compelling AI products. I say desperate because they're already a year behind the competition in this space. (I can imagine they'll be trying to get developers to build Vision Pro software too, though I hear sales there have collapsed so again, way too little, too late) reply tzakrajs 14 minutes agorootparentThey have tons of computer vision, NN inference and natural language processing in their products. It's reductive to say Apple products don't have much AI. reply niek_pas 30 minutes agorootparentprevI'm not sure what you mean by \"AI products\", and why you think Apple needs them for their platforms. reply error9348 5 hours agoparentprevThe interface looks very Apple as well. Looks like you create a config file, and you already have a model in mind with the hyperparameters and it provides a simple interface. How useful is this to researchers trying to hack the model architecture? One example: https://github.com/apple/corenet/tree/main/projects/clip#tra... reply sigmoid10 3 hours agorootparentNot much. But if you just want to adapt/optimize hyperparams, this is a useful approach. So I can certainly see a possible, less technical audience. If you actually want to hack and adapt architectures it's probably not worth it. reply blackeyeblitzar 7 hours agoparentprev> It looks like a mid-level implementations of training and inference I’m not familiar with how any of this works but what does state of the art training look like? Almost no models release their training source code or data sets or pre processing or evaluation code. So is it known what the high level implementation even is? reply spott 6 hours agorootparenthttps://github.com/NVIDIA/Megatron-LM This is probably a good baseline to start thinking about LLM training at scale. reply ipsum2 6 hours agoprevIt's interesting that Apple also actively develops https://github.com/apple/axlearn, which is a library on top of Jax. Seems like half the ML teams at Apple use PyTorch, and the other half uses Jax. Maybe its split between Google Cloud and AWS? reply josephg 3 hours agoparentIn my experience, this is pretty normal in large companies like Apple. Coordination costs are real. Unless there's a good reason to standardize on a single tool, its usually easier for teams to just pick whichever tool makes the most sense based on the problem they're solving and what the team has experience with. reply te_chris 2 hours agoparentprevI don’t know as haven’t worked there, but have always heard Apple described more as a series of companies/startups than one coherent entity like Meta or whatever. Each is allowed a large degree of autonomy from what I’ve heard. reply jn2clark 1 hour agoprevI would love an LLM agent that could generate small api examples (reliably) from a repo like this for the various different models and ways to use them. reply coder543 7 hours agoprevThey also mention in the README: > CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data This is the first I’m hearing of that, and the link seems broken. reply simonw 6 hours agoparentThe link should go here I think: https://github.com/apple/corenet/tree/main/projects/catlip reply huac 7 hours agoparentprevcat's out of the bag, too early? reply benob 1 hour agoprev> OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework https://arxiv.org/abs/2404.14619 Apple is pushing for open information on LLM training? World is changing... reply tzakrajs 12 minutes agoparentWe are all starting to better understand the ethos of their engineering teams more generally. reply mxwsn 7 hours agoprevBuilt on top of pytorch. reply jauntywundrkind 7 hours agoparentnext [12 more] [flagged] MBCook 6 hours agorootparentMetal was released before Vulkan, and had a different design philosophy. So that’s not a good argument. They follow the licenses. Apple has paid developers to work on WebKit, Clamg/LLVM, and CUPS. That’s off the top of my head. All open source. All available to you. I remember reading how they contributed fixes to a huge number of packages in the OSS ecosystem when working to get POSIX certification as they fixed issues. They released Swift as open source when they didn’t need to, and keep opening more libraries for it as they work to reimplement foundation. You may not like Apple, but they’re not a leech. They give back. reply Jtsummers 6 hours agorootparentApple also contributed substantially to OpenCL (I mean, they were the originators of it), though CUDA (the closed, proprietary solution) ate that world. reply threeseed 5 hours agorootparentprevThey also had paid developers working on Apache Spark. As well as Apache Cassandra before they switched to FoundationDB which is still open-source and maintained. reply throwaway5959 5 hours agorootparentprevMaybe it’s because you need to take a breath while typing. reply andrewmcwatters 6 hours agorootparentprevApple does this with some other technologies as well. CoreData \"is\" SQLite. reply randomdata 6 hours agorootparentCoreData is an object graph and persistence framework. It is more like an ORM toolkit than like a database engine. Indeed, SQLite is one of the possible 'backends', but it is not limited to SQLite. It also supports XML, binary, and in-memory stores out of the box, and you can also create your own if none of those suit. reply threeseed 5 hours agorootparentprevCoreData is a derivative of the WebObjects' Enterprise Object Framework (EOF). They just tied it to SQLite whereas in the past it was a general ORM. reply loaderchips 6 hours agorootparentprevYou have articulated what i have been feeling towards apple really well. I like their products But their philosophy and approach is not up to par reply BuckYeah 7 hours agorootparentprevAs someone who owns apple stock. I’m good with it reply pquki4 6 hours agorootparentThe first sentence has almost no meaning. Basically anyone who has a 401k or SP500/VOO/etc owns significant amount of Apple stock. Not something worth pointing out. reply jeffhuys 4 hours agorootparentThere exists a world outside the USA bud. reply leodriesch 6 hours agoprevHow does this compare to MLX? As far as I understand MLX is equivalent to PyTorch but optimized for Apple Silicon. Is this meant for training MLX models in a distributed manner? Or what is its purpose? reply reader9274 4 hours agoparentAs mentioned in the \"mlx_examples/open_elm\": \"MLX is an Apple deep learning framework similar in spirit to PyTorch, which is optimized for Apple Silicon based hardware.\" reply simonw 6 hours agoparentprevIt looks like MLX is a part of this initiative. https://github.com/apple/corenet lists \"MLX examples\" as one of the components being released in April. reply dagmx 6 hours agoparentprevJust skimming the README it looks like it’s a layer above MLX. So looks like a framework around it to ease ML reply ipsum2 5 hours agorootparentIt's a layer on top of PyTorch, and it has code to translate PyTorch models into MLX. reply Mandelmus 4 hours agorootparentSo, is CoreNet the equivalent of Keras, whereas MLX is the Jax/PyTorch equivalent? reply ipsum2 10 minutes agorootparentNot quite. The closest equivalent would be something like fairseq. It's config (yaml) driven. reply hmottestad 4 hours agorootparentprevSounds reasonable. Apple writes the following about MLX: \"The design of MLX is inspired by frameworks like NumPy, PyTorch, Jax, and ArrayFire.\" reply miki123211 7 hours agoprevWhat's the advantage of using this over something like Huggingface Transformers, possibly with the MPS backend? reply pshc 7 hours agoparent\"MLX examples demonstrate how to run CoreNet models efficiently on Apple Silicon. Please find further information in the README.md file within the corresponding example directory.\" > mlx_example/clip: ... an example to convert CoreNet's CLIP model implementation to MLX's CLIP example with some customized modification. - FP16 Base variant: 60% speedup over PyTorch - FP16 Huge variant: 12% speedup > mlx_example/open_elm: ... an MLX port of OpenELM model trained with CoreNet. MLX is an Apple deep learning framework similar in spirit to PyTorch, which is optimized for Apple Silicon based hardware. Seems like an advantage is extra speedups thanks to specialization for Apple Silicon. This might be the most power-efficient DNN training framework (for small models) out there. But we won't really know until someone benchmarks it. reply upbeat_general 1 hour agoparentprevThe implementation seems to be pretty clean and modular here where transformers (and diffusers) isn’t, unless you take their modules standalone. This repo has a lot of handy utilities but also a bunch of clean implementations of common models, metrics, etc. In other words, this is more for writing new models rather than inference. reply jaimex2 5 hours agoparentprevNothing, its basically pytorch with an Apple logo. reply javcasas 8 minutes agoprevLooks at Apple: CoreNet Looks at Microsoft: Net Core My inner trademark troll demands a bucket of popcorn. reply buildbot 7 hours agoprevDoes this support training on Apple silicon? It’s not very clear unless I missed something in the README. reply zmk5 7 hours agoparentI believe the MLX examples allow for it. Seems like a general purpose framework rather than a Mac specific one. reply gbickford 7 hours agorootparentI couldn't find any training code in the MXL examples. reply blackeyeblitzar 7 hours agoparentprevWould such a capability (training) be useful for anything other than small scale experimentation? Apple doesn’t make server products anymore and even when they did, they were overpriced. Unless they have private Apple silicon based servers for their own training needs? reply donavanm 4 hours agorootparent> Unless they have private Apple silicon based servers for their own training needs? Id be SHOCKED if so. Its been 15 years, but I was there when xserve died. Priorities were iphone > other mobile devices >>> laptops > displays & desktops >>> literally anything else. When xserve died we still needed osx for OD & similar. Teams moved on to 3P rack mount trays of mac minis as a stop gap. Any internal support/preference for server style hardware was a lolwut response. Externally I see no reason to suspect thats changed. reply MBCook 6 hours agorootparentprevThere are an insane number of Apple Silicon devices out there. If your product runs on an iPhone or iPad, I’m sure this is great. If you only ever want to run on 4090s or other server stuff, yeah this probably isn’t that interesting. Maybe it’s a good design for the tools or something, I have no experience to know. Maybe someone else can build off it. But it makes sense Apple is releasing tools to make stuff that works better on Apple platforms. reply blackeyeblitzar 5 hours agorootparentI can understand the inference part being useful and practical for Apple devs. I’m just wondering about the training part, for which there Apple silicon devices don’t seem very useful. reply rgbrgb 4 hours agorootparentI’ve seen several people fine tune mistral 7B on MacBooks. reply jjtheblunt 5 hours agorootparentprevIsn’t the current Mac Pro available in rack mount form? https://www.apple.com/mac-pro/ reply andreygrehov 7 hours agoprevWhat hardware would one need to have for the CoreNet to train efficiently? reply gnabgib 8 hours agoprevh1: CoreNet: A library for training deep neural networks reply symlinkk 7 hours agoprev [–] Pretty funny that Apple engineers use Homebrew too. reply guywithabike 7 hours agoparentWhy is it funny? Homebrew is the de facto standard terminal packaging tool for macOS. reply AceJohnny2 7 hours agorootparentnext [–]reply TMWNN 7 hours agorootparentI also use MacPorts, but certainly have often noticed that Homebrew has some package that MacPorts doesn't. I guess there's nothing stopping me from moving to Homebrew other than familiarity. reply fastball 6 hours agorootparentI used MacPorts a decade ago, but at some point realized that Homebrew had more packages that were kept consistently up-to-date. Switched and never looked back. reply nicolas_t 5 hours agorootparentI switched away back to macports when homebrew decided to get rid of formula options. To be honest, I always find homebrew frustrating, it feels that they've often made technical decisions that are not necessarily the best but they've been much more successful at marketing themselves than macports. reply pnw_throwaway 4 hours agorootparentIf I’m reading the formula docs right, only homebrew-core packages don’t support it (due to CI not testing them). That part does suck, though. Other taps, like homebrew-ffmpeg, offer a ton of options. reply photonbeam 7 hours agorootparentprevI hear a lot about people moving to nix-darwin, is it popular or am I showing my own bubble reply armadsen 5 hours agorootparentI’m a full-time Mac and iOS developer, have been for almost 20 years, and this is the first I’ve heard of it. Might just be my bubble, but I don’t think it’s a huge thing yet. (I’m going to check it out now!) reply jallmann 6 hours agorootparentprevI use nixpkgs on MacOS, is nix-darwin is a different project? I love Nix but it probably has too many rough edges for the typical homebrew user. reply tymscar 5 hours agorootparentIts a different complementary thing. It lets you define your macos settings the same way you would on nixos reply firecall 6 hours agorootparentprevI've never heard of it until now, but will check it out! :-) reply pyinstallwoes 4 hours agorootparentprevI never even heard of nix-Darwin. Interesting. reply sevagh 5 hours agorootparentprevApple should do like this library, re-release Homebrew with their own name on the README and people would lap it up. reply ramesh31 7 hours agorootparentprev>Why is it funny? Homebrew is the de facto standard terminal packaging tool for macOS. It's funny because a multi-trillion dollar company can't be bothered to release a native package manager or an official binary repository for their OS after decades of pleading from developers. reply randomdata 6 hours agorootparentThey released \"App Store\" for the average Joe. We can all agree it is not suitable for power users, but at the same time what would power users gain over existing solutions if they were to introduce something? reply katbyte 4 hours agorootparentYou can brew install mas (I think) and then install/manage Mac store stuff via the cli pretty easily reply astrange 7 hours agorootparentprevThey did, they sponsored MacPorts. (And then Swift Package Manager.) reply Tagbert 6 hours agorootparentprevSo you want them to Sherlock Homebrew? reply TillE 5 hours agorootparent\"Sherlocking\" can be unfortunate for a developer, but it's odd to view it as an inherently bad thing. A package manager is a core OS feature, even Microsoft has WinGet now. reply Someone 3 hours agorootparent> A package manager is a core OS feature It has become a core OS feature. Historically, you see the set of core OS features expand tremendously. Back in the 80’s drawing lines and circles wasn’t even a core OS feature (not on many home computers, and certainly not on early PCs), bit-mapped fonts were third part add-ons for a while, vector-based fonts were an Adobe add-on (https://en.wikipedia.org/wiki/Adobe_Type_Manager), printer drivers were third party, etc. I think that’s natural. As lower layers become commodities (try making money selling an OS that only manages memory and processes), OS sellers have to add higher layer stuff to their products to make money on them. As to Sherlocking, big companies cannot do well there in the eyes of “the angry internet”: - don’t release feature F: “They don’t even support F out of the box. On the competitor’s product, you get that for free” - release a minimal implementation: “They have F, but it doesn’t do F1, F2, or F3” - release a fairly full implementation: “Sherlocking!” and/or nitpicking about their engineering choices. reply fragmede 4 hours agorootparentprevit's odd to feel empathetic when someone has their livelihood taken from them? reply etse 7 hours agorootparentprevWell, without charging for it, right? reply 2muchcoffeeman 7 hours agorootparentThey should do it to become the de facto platform for programming. reply ClassyJacket 7 hours agoparentprev [–] What, they don't wanna pay 17.99$ a month for cURL installed from the Mac App Store™ riddled with ads? reply vsnf 7 hours agorootparent [–] As a thought exercise, how would one even begin to try to pollute a curl with ads? Would it print out suggested websites after every get request? reply ronsor 7 hours agorootparentProbably. That's basically how npm ads work. reply TaylorAlexander 7 hours agorootparentprevOh if we’re thinking of terrible ideas, it could save ads as a JPG in to the folder where you saved whatever you were grabbing with curl. reply dylan604 6 hours agorootparentOr even more terrible, open the image full screen with no way to close it until it feels it has been open long enough to close on its own. maybe show some sort of timer counting down, and then before dismissing itself, it opens the App Store listing for the app. it'll be very convenient for the user as no user interaction will be required for any of this reply TaylorAlexander 3 hours agorootparentSubscribe now to CURL PLUS for 30% fewer unskippable ads! reply pjmlp 3 hours agorootparentprevThat is definitly an idea, see npm packages. reply blackoil 7 hours agorootparentprevBefore you see the output, please read about this brilliant product. Type name of product to continue. reply airstrike 7 hours agorootparentprevPrint a coupon to the terminal that expires in 15 mins. Buy more to save more reply fiddlerwoaroof 7 hours agorootparentprevDetect iterm or kitty or other image-capable terminals and display an image reply fragmede 4 hours agorootparentprevsell advertising space on the progress bar and charge for faster download speed reply arzig 7 hours agorootparentprevI mean, there are a a number of tty graphics protocols. I’m sure with enough dedication someone could figure something out. reply epistasis 7 hours agorootparentprev [–] Careful what you suggest! VCs are starting to back open source companies these days! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "CoreNet is a neural network toolkit created by Apple for training small to large models for object classification, detection, and segmentation tasks.",
      "Requires Python 3.9+ or 3.10+ with PyTorch and offers optional dependencies for audio and video processing.",
      "Evolved from CVNets, CoreNet now supports a wider range of applications beyond computer vision like training LLMs, and welcomes contributions from users."
    ],
    "commentSummary": [
      "Apple is working on CoreNet, a library for deep neural network training that goes beyond computer vision tasks, indicating their focus on advancing AI technologies.",
      "Speculation is ongoing about Apple's AI progress and initiatives like CoreML, along with the development of LLM training libraries such as Axlearn and CatLIP using open-source frameworks.",
      "The discussions also involve Apple's utilization of technologies like CoreData, Apache Cassandra, and MLX, as well as considerations for using Apple Silicon devices and tools for developers, Nix-Darwin for macOS settings management, and potential monetization of open-source products."
    ],
    "points": 330,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1713922008
  },
  {
    "id": 40135250,
    "title": "Rabbit R1 Source Code Reveals Limitations",
    "originLink": "https://github.com/rabbitscam/rabbitr1",
    "originBody": "rabbit r1 source code [part 1] rabbit.tech has been making waves with its highly publicized release of the Rabbit R1 device, claiming it can perform tasks on your behalf and liberate you from app-based interactions. But let's call a spade a spade – this is a blatant lie. And we're about to expose it with the first partial release of the source code for its so-called \"large action model\". For those with a technical background, it's painfully clear that there's no artificial intelligence or large action model in sight. In reality, they're simply relying on several Playwright automation scripts to do the job for you, which is why they only support four apps: Spotify, Midjourney, Doordash, and UberEats. What's even more alarming is that they ask you to login through their web portal, which is just a virtual machine connected via NoVNC. They also expect you to fill in your private passwords on their VMs. To make matters worse, they store the user sessions on their machines without any additional layers of security. This is both a blatant disregard for user privacy and a hilariously bad engineering practice. Sadly, this shouldn't come as a shock to anyone who's done minimal due diligence on the team. After all, they were still hawking NFTs just two years ago. Spread the word and stay vigilant. Download: https://pixeldrain.com/u/vYHXbUwP https://mega.nz/file/rRdwhaII#02OcaqQghqhJQ5nvF3rjAdlCfeVOzdrkbBIM3sX6Gl4",
    "commentLink": "https://news.ycombinator.com/item?id=40135250",
    "commentBody": "Rabbit R1 source code [part 1] (github.com/rabbitscam)326 points by wibbily 15 hours agohidepastfavorite161 comments NetOpWibby 12 hours agoAccording to their CTO in the Discord[0]: > If someone spends enough time with the login minions they can extract these code. But these code are locked down and are sanitized. LAM lives elsewhere. This is someone looking at the rabbit hole not understanding how it works. And tries to be smart. [0]: https://cdn.discordapp.com/attachments/1185274946981732374/1... reply patleeman 11 hours agoparentCan somebody translate this? reply _heimdall 11 hours agorootparentThe original claim in the code dump is that no ML tools are used at all and the tool is just leaning on Playwright to automate specific actions on a website. The CEO here is claiming that the ML code is being run outside this code base and that the original claim is being made by someone who doesn't know how the code works. The CEO's mention of sanitized code isn't as clear to me, that can mean different things. Compiled code can be considered sanitized since it likely isn't human readable, obfuscated code makes that harder, and removing some code all together would be the most effective. The problem with removing code all together is that you would still find code paths that just can't be executed at all, leaving some trail of what code was removed. That wouldn't leak any secrets obviously, but would support the argument that code has been removed and the codebase is being misread. reply kotaKat 8 hours agorootparentprevThe code is their \"minions\" to handle actions on websites. When you ask it to, say, book a trip, and it tries to search AirBnB. \"If someone spends enough time with the login minions they can extract these code\" AKA \"Someone will figure out how this worked, but our code is secure, trust us\". The \"rabbit hole\" they mention is the whole \"cloud\" system that Rabbit talks about using to manage all of your services and integrations and 'rabbits' you create that run tasks. reply saltsaman 7 hours agorootparentSo it is a confirmed leak and they are just doing damage control? reply rhinoceraptor 5 hours agorootparentIt seems to just be a leak of their sandboxed headless browser setup and the API code for controlling it. Obviously such a thing will run arbitrary JS from the web so inevitably there will be something like a browser sandbox exploit, and subsequent dump of its filesystem. The leak doesn't seem to contain what Rabbit calls the LAM, their purported AI model for interacting with UIs. And what the leakers are claiming is that Rabbit's automation is just handwritten scripts which seems to be completely unsubstantiated. The rabbit secret sauce could still turn out to be a scam but I didn't see anything to corroborate any of the leakers' claims. Grepping the files I found no reference to doordash, uber eats or midjourney, only a path reference to what appears to be a spotify integration library, but the source for that isn't there. reply threeseed 11 hours agorootparentprevI think it means to say that: 1) The got the code by bruteforcing the login credentials on device. 2) Server-side code is not accessible which is where the LAM runs. reply plugin-baby 5 hours agorootparentThis isn’t likely though, is it? The device is unlikely to be running NodeJS and playwright. reply floren 11 hours agorootparentprev\"Shit, shit, shit, shit! Dissemble!\" reply ado__dev 15 hours agoprevNot surprised at all. This and the Humane Pin both seemed like a quick cash grab before phones integrated all the new AI goodness. I'm expecting we'll see that window close by the time I/O and WWDC wrap up this year, so they had to move fast. reply hncel 14 hours agoparentI don't think this is a fair characterization of Humane. I don't and haven't worked at Humane, but I did interview there and have some friends who work there now. They are notoriously secretive about their product (founders are ex-Apple, and they try to keep an Apple like secrecy culture) but I do know a bit about the evolution of the product. Humane was founded in 2018, well before ChatGPT was released in November 2022. If you look online you can find some articles about patent applications they made well before ChatGPT was released that give you an idea about their idea for the product at the time, e.g. https://9to5google.com/2022/01/07/humane-android-ar-wearable... Developing the hand tracking, laser projection system, voice recognition, etc. is very hard, especially considering the power constraints on the device. They spent years working on this and when LLMs hit the scene they realized that the original product idea was going to be severely lacking if they didn't integrate this technology. This caused a big internal pivot to more closely integrate with these LLMs. I'm not sure which they're using, presumably they're paying for GPT-4 access or something like that. It's understandable why they felt like they had to do this, and why it feels like a rushed integration. The bottom line is that they were way too optimistic with the hardware capabilities when they started working on the product, and the last minute rush to integrate with LLMs to at least improve the software capabilities to kind of close the gap is what we're left with. It's not a great situation, but I also think it's unfair to characterize it as a \"cash grab\". reply rodiger 11 hours agorootparentCash grab from their VCs is probably more accurate... I have zero doubt some incredible engineering has gone into the product. However, from what I can tell they were searching for a problem to solve instead of coming with a distinct, compelling, articulable vision of what they wanted to build reply megaserg 12 hours agorootparentprevSecretiveness in a startup at that stage is not a good sign. See e.g. Theranos or Magic Leap. reply fragmede 11 hours agorootparentprevthe hardware is phenomenal, but it's tied down by bad software reply miki123211 8 hours agoparentprevThis is really troubling to me. I feel like all these companies are really hamstrung by the fact that they don't have enough access to our phone's features. There's no way to build a Siri competitor if you're not Apple or Google, the APIs to send and read texts, make calls, control music apps etc just don't exist. Chat GPT integrated with your phone's operating system is a lot more useful than pure Chat GPT. I wouldn't be surprised if Open AI gets dethroned by Apple and Google because of that fact alone. It doesn't matter how good your model is if you're not allowed to use it due to anticompetitive practices. If anything deserves antitrust scrutiny, it's the locking down of private APIs, not some petty disputes about App Store fees. reply ENGNR 4 hours agorootparentThis is why we need change to open it up. We can’t allow a platform to just forever swallow the next layer of tech up forever and ever reply SheinhardtWigCo 15 hours agoparentprevTheir \"keynote\" just screams shenanigans. It's the most blatantly fake product demo I have ever seen. To take one example, at 14m30s, the CEO is shown using the device to book a trip to London. This is presented as a live demo, but it's clearly simulated. https://www.youtube.com/watch?v=22wlLy7hKP4 reply RockRobotRock 14 hours agorootparentTo be fair, he doesn't \"book\" a trip to London in the presentation, he gets flight, hotel, and car rental information, which isn't that out there. But, he does imply that you can book from the device, which is completely insane. How do you deal with flight selection with multiple layovers? Seat choices? DOBs? KTNs? Phone numbers? Frequent flyer number? Payment? Travel insurance? Disability accommodations? What could possibly be the overlap of people who travel enough that this is all worth setting up, who don’t already have their own personal assistant? reply kmlx 14 hours agorootparentjust the payment part is it’s own universe of issues, friction, fraud, security etc etc etc reply imiric 14 hours agorootparentprevPlaying devil's advocate, tech demos are often faked. From the famous \"Hello\" Mac introduction in 1984[1], to Google with their Gemini demo a few months ago. A certain degree of smoke and mirrors to generate hype around ground-breaking tech is the norm, not the exception. This doesn't necessarily mean that the product itself is a scam. [1]: https://www.folklore.org/Intro_Demo.html reply duskwuff 8 hours agorootparent> From the famous \"Hello\" Mac introduction in 1984 I feel like that's a little different. The Macintosh demo was obviously a \"sizzle reel\", not an example of how the machine would normally behave in use. No one would have watched the demo and expected the computer to talk to the user when turned on. A more interesting reference point might be the iPhone intro, which wasn't \"fake\", but did rely on a carefully orchestrated sequence of events to avoid known bugs. reply msephton 12 minutes agorootparentThe 1984 Macintosh demo also wasn't running on a stock Macintosh, but rather an expanded version of the hardware. reply qingcharles 8 hours agorootparentprevI remember the CEO of Nokia showing off their latest phone on stage at Mobile World one year, live in front of the world's assembled press. Little did he know two developers were sweating their nuts off as everything on his screen was coming from an old PC stuffed in a closet in a bedroom thousands of miles away, fed down a ratty cable modem. reply pnw 15 hours agoparentprevA company founded in 2018 that raised over $200m is a \"quick cash grab\"? reply SheinhardtWigCo 14 hours agorootparent\"Quick\" as in being quick to exploit LLM hype. \"Cash grab\" as in Elizabeth Holmes grabbing $700m from Theranos investors. reply ipsum2 14 hours agoprevI implemented my own DIY version of Rabbit at a hackathon using Playwright and VNC. I feel extremely validated that they use the same things that I thought of. reply rkwz 5 hours agoparentWow, can you share more about the Playwright+VNC combo? reply rodiger 15 hours agoprevAt least it'll look nice on a shelf thanks to Teenage Engineering's good work :) reply kotaKat 14 hours agoparentI bought it because I figured out it's gonna be some crummy little Mediatek thing underneath the skin (and it is) running some form of Android (and it is) so I'm just sitting back to hack it back to be a real communicator ;) EDIT: It's an MT6765 (Helios P35). It's got a known BootROM exploit. Won't be long until someone dumps it and cracks it open, though would be hilarious if a part2/part3 dump is just a factory stock ROM. reply WanderPanda 15 hours agoparentprevTE might have their name really damaged by this. I wonder why they agreed to this colab in the first place reply msephton 9 minutes agorootparentThe rabbit guy is on the board of Teenage Engineering. reply talldayo 14 hours agorootparentprevSelling underpowered toys at eye-popping prices has been Teenage Engineering's modus-operandi since the beginning. After the OP-1 price hike (and subsequent re-release at an even higher price), I don't think their target audience cares past this point. You either buy TE stuff for the brand recognition or you own a bunch of Behringer gear because you're poor. reply caseyy 13 hours agorootparenthttps://teenage.engineering/store/field-desk/ reply talldayo 11 hours agorootparentI retract my previous statement. Indeed, toys are not the only expensive stuff they have for sale. Hey look down there! The computer-1 case is on sale for $149, down from $249. How much profit you still think they're making, considering it's a DIY kit of bendable sheet metal? reply BadHumans 10 hours agorootparent150 for a mini-ITX case is very reasonable. I don't this is the own you think it is. reply MichaelMug 10 hours agorootparentI bought that case and it’s not great quality and does not look as good as the picture. Also it is flat pack so you have to bend all the pieces and the toggle switch feels terrible. So definitely overpriced for what you get. reply BadHumans 10 hours agorootparentI didn't buy the case so I can't comment on quality. Just that asking $150 for a mini-ITX case is in the ballpark for what I expect to pay. Most small-batch ITX cases are also flat pack. All the dan cases, formD T1, among others. reply hbn 6 hours agorootparentprevSnazzyLabs bought their case a few years ago for a hackintosh project and did not review it favorably. They send you a bunch of flat panels of metal you have to bend into shape yourself, and are supposedly very flimsy and can be easily bent even once the whole thing is assembled. They didn't even punch out the screw holes so you have to bore your own holes and screw through them manually. The USB-C port on the front uses a 3.0 header instead of 3.1. And it can't even fit a small formfactor GPU. https://youtu.be/WOMeETfRQkE?t=418 reply fortyseven 3 hours agorootparentprevMaybe give it another think? This time taking thermals and air flow into consideration? reply noman-land 13 hours agorootparentprevWhile I agree this has been true of TE for most of their existence, their most recent $300 sampler bucks this trend considerably. https://teenage.engineering/store/ep-133/ Neither that, nor this little AI cloud device are eye watering in price. reply neom 12 hours agorootparentPeople loooove to complain about TE pricing. OP-Z is $499, find me anything else that can sequence sound, video and DMX (on the go) like OP-Z can, there are exactly zero others. OP-1 for portable synths.... are people pulling a Deluge out on a flight? I've seen people compose a whole set with a OP-1, over 30 minutes, with nothing else... good luck doing that on a MC-101. reply talldayo 11 hours agorootparentI own a Pocket Operator, my head's not in the sand about their cheaper offerings. The Pocket Operators are cheap toys though, you cannot tell me with a straight face that it's about to prop up your next EP. It's a mass-produced calculator PCB they forgot to make a case for, and sell at insane markup. The same goes for the KO and indeed, the OP-Z. The OP-Z doesn't even have a screen, it has no business costing $499 for being a bunch of buttons with a USB-C plug. > find me anything else that can sequence sound, video and DMX (on the go) like OP-Z can How about the mandatory paired device it requires to sequence everything? That iPhone/iPad is certainly capable of doing that itself, alongside multiple things the OP-Z can't. Nevermind how far you'd get with a $300 laptop and $200 DAW. reply neom 10 hours agorootparentYou can't memorize how to use an OP-Z.......?? That aside, what company is making an OP-Z alternative? What company is making pocket operator alternative? What company is making an OP-1 alternative...? Right, that's what I thought. On your laptop point, I'm going to be doing a show this weekend, OP-Z, OP-1, 170 and 400. I don't even know HOW I would do that without TE gear, $50k worth of Eurorack? reply talldayo 10 hours agorootparentThey've existed for almost 4 decades now under a market labelled \"MPCs and MIDI controllers\". To name a few common alternatives, you have the Digitakt and Octatrack, a cheap TASCAM and a laptop, a 4-track cassette recorder, the Akai grooveboxes, the Electribe series, the recent Novation Circuit line... the list goes on. People have been making beats on battery-power long before the iPhone and Garageband, if that's news to anyone. > I don't even know HOW I would do that without TE gear, $50k worth of Eurorack? A quad-core laptop running Reason and VCV Rack would do just as well, but I won't spoil your hardware fun. Who can deny how sweet TE's analog DCO sounds? reply neom 10 hours agorootparentRight, anyway. Can you spec for spec find me alternatives for the TE gear I mentioned? Same form function, similar software, interoperable within its ecosystem. Just name the TE model and then the brand and model alternative that is basically the same, and then how they work together in terms of their sync clocks. For example: OP-Z, you could buy X device, it has all the same features, is about the same price, same size, battery etc. Very curious to check out your suggestions! reply talldayo 10 hours agorootparentOP-Z: iPhone or iPad, it has all the same features, is about the same price, same size as you would have carried, same battery, whatever OP-1: Literally just about anything. It is a 4 channel digital recorder. You have an iPhone with USB-class compliant audio, you can do multichannel recording. Use a guitar, some iOS plugins and a $40 DAC. If you're going to complain about buttons, go blow your cash on a midi controller (it will still come up cheaper than ANY OF THE OP-1 MODELS!) Pocket Operator: God, please grant me reprieve from finite suffering. There is no hope for humanity if we are looking for \"alternatives\" to grooveboxes with kilobyte-sized memory. What do I say? Fairlight CMI? Do I send a picture of the Mellotron as a joke? The Ti-84 graphing calculator? Heaven forbid... the Akai Rhythm Wolf. Is there a future for us yet if iPad children would rather pay college-tuition prices for Fischer-Price hardware that can do what their iPad does already? You'll never please everyone, which is why snake oil still finds customers in the 21st century. reply iamsaitam 1 hour agorootparentprevOr you buy them because they know how to design products unlike Behringer? reply vegadw 14 hours agorootparentprevHonestly, while I agree there's a massive price discrepancy, I don't know that I even see Behringer as the \"lower end\" option anymore. The lowest end is a laptop and pirated VSTs. Behringer pedals? Yeah, those are because you're poor (or just don't care, I guess?) but synths? The K2 is better built than the MS20 mini, the Wasp reissue doesn't have a good equivilent I know of, and their 303 clone isn't any better or worse than the other similarly priced 303 options - and it's easily hackable. I mean, don't get me wrong, I still think Behringer as a company is doing bad things to the music land scape and that they've done some pretty horrendous IP theft and racist stuff, but I don't think \"because you're poor\" is right either. To the point though, yeah, no, TE absolutely won't get a black eye for this: Nobody cares, and hardly anyone but tech bros even know. It's no worse than their wooden choir thing. reply BadHumans 14 hours agorootparentprevI don't think any fan of Teenage Engineering is no longer a fan because they were paid to design a product that flopped. reply serf 12 hours agorootparentwhy not? they clearly wanted to exploit AI hype in order to turn a profit, even if they did so indirectly. Why shouldn't that speak to their motives and trustworthiness? if Apple started churning out guns, landmines, snakeoil, cancer cures, NFTs, and magic-AIs their reputation would falter. reply BadHumans 10 hours agorootparentTeenage Engineering isn't making guns, landmines, NFTs, or magic AI. Maybe I'm just not a deep thinker like you so I'm not making the connection but in my mind a company paid Teenage Engineering to design some hardware; Teenage Engineering designed the hardware. That is all there is to it. They made no promises about the functionality because that wasn't their job because it wasn't their product. reply wilsonnb3 11 hours agorootparentprevApple might be able to get away with all that, their reality distortion field is unmatched, but I agree that teenage engineering might actually take a reputation hit if they are too liberal with their outsourcing. Personally, the Vision Pro wasn’t really my cup of tea but I will be standing in line on day one at my local Apple Store for the Landmine Pro. reply kevindamm 11 hours agorootparentWait til you find out that the Vision Pro can detect the presence of Landmine Pro in your vicinity. It's all about that vertical integration. reply j4ustin 13 hours agorootparentprevThe Rabbit CEO is on the board of TE. reply chambored 14 hours agorootparentprevI highly doubt that. TE has a strong reputation and their involvement in another company's product outside of their normal business won't impact their sales regardless of whether or not R1 is a flop or a ruse. reply micromacrofoot 15 hours agorootparentprevthey were paid money in exchange for services reply slily 14 hours agoparentprevThis reminds me of how Playdate owners make it very obvious they don't use the thing in the way they retroactively justify their purchase by commenting on quirkiness or aesthetics at the expense of functionality or usability. I guess I get it but there's cheaper plastic toys out there. reply msephton 2 minutes agorootparentI'm a Playdate owner, I definitely use it, and one of the games I've made for it was a GOTY 2023. So, there were go. reply mulderc 14 hours agorootparentprevI don't think that is retroactive, people bought it because it was different and looks cool and is quirky. I think it is a very fun device and has some great games for it. It isn't for everyone but it is a cool device for people that appreciate what Panic is doing with it. reply extr 15 hours agoprevI really think this + the humane AI pin would be super interesting products if they made them hackable. The hardware is super cool, no problem if the software isn't there yet, it's not like they're being sold at Best Buy, I'm not worried about my mom acquiring one of these and getting her passwords leaked. Who cares if the auth flow is super hacky/insecure? Let us self host it! Let the community create more playwright scripts! reply roughly 15 hours agoparentHumane is founded and populated by ex-Apple folks, so I wouldn't hold my breath. You're right, though - it's a bit weird because ostensibly the interface is via the GPT system and you've gotta work through those interactions (same problem Alexa had), but given how early both the platform and the product category are, they'd benefit big from letting early adopters build capabilities for them. reply harryp_peng 11 hours agorootparentWorst possible thing is that bozos learn the closed source model. The closed source model only worked because they had the Great SJ. reply disconcision 14 hours agoparentprevthis exists! https://www.openinterpreter.com/ even their hardware is (apparently) open-sourced reply spaceship__sun 11 hours agorootparentBut how is an hardware version of a mic/speaker anything interesting? The humane AI pin, to which you wear and gets contextual data, is the only wearable of interest to hackers. reply vineyardmike 12 hours agoparentprevIf you want something fun and hackable look at these glasses: https://brilliant.xyz/products/frame They have shipped products before, and they include a bunch of code - today on GitHub to start hacking with. reply 999900000999 15 hours agoparentprevAgreed. The Rabbit R1 looks like it would be the perfect device to play with. As is I just assumed Rabbit was sending off pictures and stuff to a Chat GPT API or something. I never assumed the models ran on device reply jsunderland323 7 hours agoparentprevYeah, I had a similar thought. If they just removed the ai or only focused on building a voice command to mobile app sdk there could be something viable there. Sadly that’s just not what they made at all. reply amiantos 14 hours agoprevI'm really into AI stuff but both the AI Pin and Rabbit R1 underwhelm. They are products that don't need to exist if the problem they're solving was truly solvable right now, because the best place for that problem to be solved is already in our hands: our phones. But we're not all talking to AI assistants in our phones all day. Why? Because the technology isn't good enough to do it yet? Because people don't want to talk to digital assistants? Once the tech is good enough that it can motivate ordinary people to look silly talking to their phones outloud, it'll be on our phones and easy to use, and there will be no need for kitschy little handheld devices. No one wants to carry around another device. That said, smart glasses sound like a great idea to me, but I wear glasses all ay long, so I am extremely biased. I don't think most people want to voluntarily wear glasses to just put a computer on their face, so I wouldn't bet on glasses, either. Sorry, Zuck. reply imiric 14 hours agoparentIt wasn't that long ago that it wasn't socially acceptable to have phone conversations in public wearing Bluetooth ear pieces, whereas now we don't think twice about it. A few decades before that, the same thing with portable music players and headphones. Society adapts quickly to technology, but, as you say, the tech needs to be good first. I think we've reached that point with voice recognition and AI assistants. It's now a matter of time until someone connects the pieces into a functional and accessible product. The reason smartphones are not the devices to get us there is because they're not a good fit for this use case. Pulling out a rectangular slab with a huge screen out of your pocket every time you want to interact with a voice assistant is enough of a UX hurdle that most people won't do it, even if it would be socially acceptable. Even if this was in a watch form factor, which we'll surely see as well, just bringing your arm close to your face would get slightly annoying over time. So a light pebble device you can pin on your shirt or wear as a necklace seems like a good form factor for this. The Limitless Pendant is another recent contender, and seems like a better thought out product compared to the Humane Pin. These devices aim to be unobtrusive, and disappear into the background, yet still remain deeply integrated into our lives. This is what technology is trending towards. I reckon the smartphones of today will seem primitive in a few decades, replaced by seamless VR/AR in glasses and primarily voice-driven wearable tech. We're currently in this transitional period where companies are investing in high-risk products to see what sticks, but eventually someone will launch something that resonates. Just like Apple did for smartphones in 2007. reply mulderc 11 hours agorootparentWhy wouldn't the device just be your ear buds connected to your phone? I already use siri all the time as I usually have my AirPods in and it works great. That seems like a much more likely device to access our digital assistance than some necklace or pin. Better yet, you could just pair it with your smartwatch and not even need the phone. I'm still deeply skeptical on voice driven tech as we have had that available and easy to use from various devices for over a decade now and it hasn't taken off for tons of reasons. I just am not going to have a conversation with my computer with others around. reply imiric 3 hours agorootparent> Why wouldn't the device just be your ear buds connected to your phone? Because nobody will realistically wear ear buds for long periods of time. This tech needs to be entirely unobtrusive if the goal is to blend in with our lives 24/7, and we're heading in that direction, for better or worse. > I'm still deeply skeptical on voice driven tech as we have had that available and easy to use from various devices for over a decade now and it hasn't taken off for tons of reasons. Voice recognition has only gotten _really_ good in the past couple of years, with the advent of LLMs. E.g. Whisper, etc. This is enough of a generational leap to transform how much we rely on the tech. > I just am not going to have a conversation with my computer with others around. Honestly, I can't imagine myself doing that either. But if you think of a scenario where the tech is so good that it understands your intent from short commands, with 100% accuracy, in every type of environment, then it's not so farfetched. Especially once everyone else starts doing it, it will seem as normal as people interacting with screens is today. I don't think we'll hold long conversations with AI in public, or around others. Just as some people avoid doing that with humans today. But for short interactions like \"record this moment\", or \"remind me to ...\", it certainly seems plausible. The device doesn't even need to respond back. It should be reliable enough that you're always sure it understood you. But we'll certainly hold long conversations with AI in private. For collaboration, companionship, etc. In either scenario, a smartphone or smartwatch are just not the devices that will deliver that experience. reply mulderc 3 hours agorootparentPeople already wear earbuds all day. Go to any college campus and tons of those kids never take them out, even when taking with each other. Lots of people at work keep them in most of the day. I am pretty sure I wear my AirPods Pro more than I wear my glasses. Voice recognition is already really good but people barely use what their devices can already do. For these short interactions you are talking about, our phones can already do this and people rarely use it. Our home assistants can already do much of what you are talking about and uptake has been abysmal because people don't like it. The smart phone and smartwatch paired with earbuds already does what you are wanting. Hell the HomePod/alexa/google home already do much of what you are taking about and people don’t use it. reply imiric 1 hour agorootparent> People already wear earbuds all day. Those are outliers, not representations of something most people would do. And even within that population, do they really wear them for 12+ hours straight? While driving, in class, etc.? I doubt it. The reality is that no gadget that you put inside or over your ear will be as comfortable for long periods of time as something you wear on your clothes, or around your neck. I keep mentioning the word \"unobtrusive\", but this aspect is critical for mass adoption. > For these short interactions you are talking about, our phones can already do this and people rarely use it. The voice recognition accuracy and, more importantly, the actions you can do with it on current gen devices is not generally useful for many people. But this will improve. I mentioned use cases that I can (poorly) imagine, but once the tech is 100% reliable, there will be many others that we can't think of today. The Rabbit demo seems fake partly because some of these scenarios are far fetched, but there will be a time when it will seem normal. Just like we couldn't imagine what smartphone apps would enable us to do in, say, 2005. > Our home assistants can already do much of what you are talking about and uptake has been abysmal because people don't like it. This is another category of devices. A speaker with microphones you put on your desk in one room is not a personal device. And many people, myself included, don't feel comfortable with a device built by a corporation that profits from personal data always listening, but I think that will change as well. And we'll have entirely self-hosted and open source alternatives for the privacy conscious as well. Though I still think smart speakers, earbuds, smartphones and smartwatches will also see improvements, and become more useful as voice recognition and what it enables us to do becomes better. But these are not personal or unobtrusive enough to become deeply embedded in our daily lives. Wearable tech together with highly accurate voice recognition as an interface to AI assistants that know our preferences on a deep level, and are integrated with many of the same services we use today, sure seems like an improvement over any current gen \"smart\" gadget. reply hbn 5 hours agorootparentprevI agree. No matter how good LLMs and voice recognition get, having a screen is still the best way of inputting and reading information in many scenarios. If I'm trying to find a restaurant to go to, unless I'm in a real \"just decide for me\" mood, I want a screen. I can read fast, see pictures of the food, open multiple browser tabs to remember potential options, quickly scroll menus, etc. I don't want a voice slowly reading me out the names of restaurants one-by-one. And that's just finding a restaurant. Imagine using voice input to book a flight. I feel sick just thinking about it. reply imiric 3 hours agorootparentFor visual content we'll need some kind of screen, of course. But I don't think this will be in the form of a rectangular slab we carry in our pockets, where we use our fingers as input. It's much more likely that it will be in the form of lightweight glasses, and eventually contact lenses, or if we get to that sooner, directly in contact with our visual cortex. It's scary to think about today, but we'll get there eventually. As for input, think about how slow, clunky and imprecise touch typing really is. I'm typing this on my phone right now, and it's still infuriating. And this is after more than 15 years of perfecting this technology. This is just the best it's ever going to get. Voice recognition OTOH, if it gets to a state where it's 100% reliable, understands all our accents and nuances, in all kinds of environments, then it's not difficult to imagine it becoming the primary input method. And in recent years, LLMs have made generational leaps in this area to the point where this can finally be a competent option. You won't need to have a list of restaurants read back to you, or have to have long interactions to book a flight or vacation. This is what the Rabbit device is trying to sell, and they at least have the right idea. The AI will have deep knowledge about you, so that just by saying \"book me a restaurant tonight\", it will make the right decision for you. At least, that's the idea. I think we'll get there eventually, even if the Rabbit is not the device that does it today. reply runlevel1 10 hours agorootparentprev> It wasn't that long ago that it wasn't socially acceptable to have phone conversations in public wearing Bluetooth ear pieces, whereas now we don't think twice about it. When amongst other people? Maybe I'm behind the times, but it's still rather annoying in my mind. And the younger generations don't really seem to talk on the phone much at all anymore. They just text. reply vineyardmike 12 hours agoparentprevSo I agree generally, BUT existing phone companies have an incentive to maintain the app-centric world that keeps their app stores profitable, and app companies have an incentive to lock you into their app to keep customer loyalty and be “more than an API”. All that’s to say, the Rabbit idea of manually scripting against apps to allow “business as usual” for all these individual parties who wouldn’t want to collaborate fills a void that existing players don’t have incentives to fill. reply ENGNR 3 hours agoparentprevBecause the phone platforms want 30% of everything sold and won’t let your app change its behaviour. It’s the same reason YouTube and Netflix actively opted out of having their iPads apps work on Vision Pro - platform wars. So the only real play is to be Apple/Android or try to bypass them by pretending there’s a new product category other than a phone and hope to get some small critical mass there. reply azinman2 14 hours agoparentprevI don’t know why I need to keep saying this, but the point of the pin is to replace phones. It’s meant for you to have access to digital services while staying in the moment and avoiding a screen. Many ppl are addicted to their smartphones, so they propose something different. You can like and prefer a phone but it’s their raison d’etre. reply _heimdall 10 hours agorootparentTo be fair, it seems reasonable to presume that the goal of these pins is to get users addicted to the new form factor with much less competition in the market rather than to help with tech addiction. reply phh 15 hours agoprev> In reality, they're simply relying on several Playwright automation scripts to do the job for you, which is why they only support four apps: Spotify, Midjourney, Doordash, and UberEats. I think that part is mostly fine? I'd rather make give a LLM access to https://woob.tech to be my personal assistant while parsing 99% less noise, than have a LLM that parse and understand stupidly complicated web pages, and randomly fail at the task because the name of my doctor is bobby drop tables. That being said, it can be interesting to use LLMs to assist creating woob plugins. reply saltsaman 13 hours agoparentThe problem is that they claim to have developed a groundbreaking Large Action Model when in fact it's just a playwright wrapper reply ach9l 11 hours agorootparentyou can't automate playwright without a decision making component in front of it, they are definitely using a transformer there. one could train a llama and make it perform triggers to playwright automations. you can even get deep into transformer tokenization and create action tokens and a formal grammar for your generation, build a parser on top of your predict function and have a \"lam\" working. the fact that they use playwright does not imply it is not generative ai. i'd say it is really hard to do those actions without a transformer involved reply vunderba 14 hours agoparentprevMidjourney does not have a public API and I'm pretty sure that automating a Midjourney account is against the TOS, so I wouldn't expect that functionality to last long. reply jthnme 15 hours agoprevSome will call it scam, some will call it MVP reply godelski 14 hours agoparentIf your product doesn't work anywhere near what your \"live demo\" shows, it's a scam. That's very different from \"here's the product we envision and need money to build it.\" And just because others have scam demos (including Gemini) that doesn't make it okay. It makes it a race to the bottom (and is why I'm more upset about Gemini because big players are held to higher standards) reply ikurei 13 hours agoparentprevIn and of itself, the product might be a decent MVP to validate the idea or some aspects of the design. The problem is in how they've marketed. If you're taking people's money and giving them an MVP, you need to be upfront about it; if you aren't you're doing a bad thing. reply animex 14 hours agoprevI just couldn't fathom the big three phone platforms not implementing this on a device that we all have and is capable of same if-not better dynamic voice integration. At the very least, I hope products like the Rabbit spur these companies to start innovating again. Even if they are smoke & mirrors, the interest shows there's demand for these features. Site Note: I've noticed Google Home's voice assistant has declined over time -- it used to handle complex queries and now it can barely understand simple directions. It used to understand me perfectly in the noisiest environments and now it makes many transcribing errors. reply redserk 14 hours agoparentLike in iOS with SiriKit? Blame app developers for prioritizing implementing less useful features. https://developer.apple.com/documentation/sirikit/ reply Wowfunhappy 13 hours agorootparentThe problem with Siri is their voice recognition sucks, especially compared to e.g. Whisper. reply xori 14 hours agoprevNot much here explicitly in the source code dump. A little insight into their worker node infra but no \"secret sauce\" imo. reply saltsaman 13 hours agoparentIsn't the secret sauce just VNC with playwright? What more do you need to achieve 80% of what they are showcasing (basic doordash orders, spotify controls)? reply rhinoceraptor 12 hours agorootparentI can't find any purported auomation scripts for those services as claimed in the Github page. There is a reference to \"cm-spotify-client\" which seems to be some sort of custom integration code they've written, but other than that there is no reference to doordash, midjourney, or uber eats. This dump seems to just be the code/infrastructure to run chromium/playwright in kubernetes, wrapped in a Node API to accept commands, persist/hydrate browser state, etc. reply unraveller 3 hours agorootparentIs there a less convoluted less enterprisy implementation of such a project someone can point to. I was interested to see what is or isn't so intensive about it. Or is this a good scaffold to start a fork? reply adlpz 15 hours agoprevAny background on how the code got leaked? Insider? Hacked servers? reply Jonovono 14 hours agoprevWhat NFT projects were they involved with? reply ugh123 14 hours agoparent/s? Underrated comment. reply tripletao 14 hours agorootparentNo sarcasm, https://web.archive.org/web/20221203132009/https://gama.io/ reply itishappy 14 hours agorootparentprev> Sadly, this shouldn't come as a shock to anyone who's done minimal due diligence on the team. After all, they were still hawking NFTs just two years ago. reply stranded22 13 hours agoprevThey gave 12 months perplexity pro with it - and I am already a subscriber. So, I basically paid a bit extra for another 12 months and a rabbit r1 to play with. If it doesn't work how I want, I should be able to sell on whilst keeping the perplexity pro sub. reply latentcall 12 hours agoprevI thought the idea of the Rabbit R1 was cool. I have a strong feeling this will end up like the Humane Pin, which is sad. I'm glad companies are trying something different. I'd love to be able to use my phone hands free without having to look at it, and interface with ChatGPT/Claude/whatever but I am not sure if it's possible? Siri works very poorly and is unreliable. I'd like to be able to use an LLM as a personal assistant. Set timers, call people, message people, but also be able to ask questions like the voice chat function in the ChatGPT app. Maybe one day! reply mulderc 11 hours agoparentI must be a Siri unicorn but for setting timers, calling people, messaging people, controlling my smart home, adding things to my shared shopping list, adding items to my 3rd party task manager, controlling my music. It works great! reply vunderba 14 hours agoprevOne of the bizarre talking points in defense of the existence of rabbit was to get away from our phones. It's just completely inexplicable to me because it's not like it was ever intended to be a replacement, the only difference is congratulations you now have to lug around two separate brick shaped appliances wherever you go... reply eterpstra 14 hours agoprevMaybe they hacked together something that can feasibly me marketed as an AI-assistant knowing that whatever they build now will get \"steamrolled\" by GPT-5 (Sam's words, not mine). When GPT-5 gets released, update the OS and it'll work as advertised... EZ-PZ! reply mafuyu 14 hours agoprevPretty much in-line with my expectations. I ordered one because I thought the design was neat, and I was interested in hacking around and flashing my own stuff onto it. The pricing was clearly at or below cost. Looking at just the concept (and ignoring execution), I don't really see the point of this thing? The whole thing is a feature that could exist on a smartphone. The dream of an AI agent that you can converse with to replace your smartphone could be compelling, but nowhere close to reality yet. Even then, the big smartphone OS companies are obviously better positioned for this. The smartphone is the hub for all your information, plus they have years of voice assistant, automation, and home IoT integration to build off of. Humane was silly because it was a smartwatch without any of the proper software support, but Rabbit is essentially doing the same but targeting a smartphone replacement. If you really want to break out and try to dethrone smartphone vendors, you'll have to come up with something more compelling than a worse user interface to a poorly made software platform. That's a software feature you're building. In some sense, I do think Rabbit had a better approach than Humane, though. Getting a bunch of low-priced \"toy\" devices into the market that are just a frontend to your server software could get you off the ground. The software needs to exist, though... reply iamleppert 14 hours agoprevWho cares how its made if you can make a bag from it before anyone is the wiser? The point in all this stuff is to make bags of money, whatever way you can do that don't matter as long as you gettin the bread. reply serf 12 hours agoprevI never understood the appeal outside the cute form-factor, all of the demos were absolutely terrible. an aside : npr doesn't like the 'spade' comment, although I think the explanation is kind of iffy.[0] [0]: https://www.npr.org/sections/codeswitch/2013/09/19/224183763... reply aw4y 15 hours agoprevI expect it (or at least I hope) to be really hackable. reply plugin-baby 12 hours agoparentBased on how hackable their infra is? reply aw4y 32 minutes agorootparentbasically reply ugh123 14 hours agoprevIf it can do what it claims to do, which is automate on top of existing apps by your voice, whats the difference? Seems innovative regardless of the tech underneath. reply georgehill 15 hours agoprevWhy did they upload the code to some random site instead of GitHub? EDIT: > But let's call a spade a spade – this is a blatant lie. And we're about to expose it with the first partial release of the source code for its so-called \"large action model\". FYI, Text to Action is possible. I personally tested a couple of apps, but I don't think anything reliable exists like we humans. I would not disregard what they claim is completely false. reply no-dr-onboard 15 hours agoparentIt buys time for them. GitHub will have a lengthy internal discussion about DMCA takedown requests and the fact that the code isn't on their server. During this time it'll give the HN and reddit communities time to grab the link and redistribute. reply georgehill 15 hours agorootparentUnderstood! But zipped files are super fishy though. What if this repo is spreading malware? reply fwip 14 hours agorootparentZip is just a tarball that Windows understands. reply dxbednarczyk 15 hours agoparentprevPotentially due to the threat of DMCAs. Pixeldrain and Mega are widely used in piracy and sometimes leaks like these, considering they are not known for complying with them most of the time, unlike GitHub. reply paxys 15 hours agoparentprevBecause it will be taken down from Github. reply claytonjy 15 hours agoparentprevto reduce the chances of GitHub taking it down, perhaps? not sure it'll help though reply m3kw9 13 hours agoprevThe UIUX isn’t good, AI models are useless without good user experiences reply GaggiX 15 hours agoprevWe already know that the large action model would not be available at launch, but I wonder how well it does works as an AI assistant. reply anon115 13 hours agoprevLOL reply godelski 15 hours agoprevPlease upload source in an unzipped format. If the concern is about GitHub taking it down, use an alternative. There's plenty and many other ways to distribute source in an uncompressed manner. Otherwise this is indistinguishable from a hack. How do I know these zips are secure? The mega and pixeldrain report different sizes. Rabbit is entirely about hype and a scam, how are we supposed to know this isn't the same nefarious ploy? I appreciate what's being done and think it's good to call out these scams (I've done so myself) but help by building some trust. We understand the need for anonymity but a nefarious actor could just as easily mascaraed as the same repo. And if you do need files downloaded, provide hashes. (Fwiw, xz, despite recent events, is great at compression and can help you reduce your bandwidth if needed) reply titaniumtown 15 hours agoparent> (Fwiw, xz, despite recent events, is great at compression and can help you reduce your bandwidth if needed) zstd level 22 is even better in my experience reply nebulous1 15 hours agoparentprevWhat is the reason for it to be uncompressed? reply godelski 14 hours agorootparent1. I can read it on my phone or in my browser. 2. Why should I have to download text to __read text__? 3. We don't want to normalize unnecessary behavior that is something scammers and bad actors can easily take advantage of. While I don't believe the leak is nefarious or contains an exploit, normalizing a requirement to download files that can issue exploits -- when there are easy alternatives that make this unnecessary -- just helps create the exact type of environment that scammers thrive in. 3 is incredibly important. If we're going to call out scammers we shouldn't do it in a manner where we're enabling an environment for more scammers to thrive in. Doing what's done here just created a rich opportunity for hackers who can now post a \"rabbit source code leak\" and just provide people with a different link. Makes for easy picking. Uncompressed and readable code just makes this harder and easier for people to determine if something nefarious is going on. reply nebulous1 14 hours agorootparentIt's not a single file unless it's tar'd or compressed or whatever. It's completely normal to distribute software projects as some form of archive. This is doubly true for a \"leak\" like this where you want the single file to spread around. I agree that it would be nice to have it browsable online, like in a github repo or whatever, but that's a separate issue. reply godelski 14 hours agorootparent> It's completely normal to distribute software projects as some form of archive Again, I think you're missing my point >> normalizing a requirement to download files that can issue exploits -- when there are easy alternatives that make this unnecessary -- just helps create the exact type of environment that scammers thrive in Yes, it is \"normal\" and that is exactly the problem. Ask yourself this Is there a reasonable alternative? Is downloading necessary? I think you'll find that the answer to both is unambiguously \"no.\" I think you'll also recognize that having the readable source __also__ unambiguously creates higher utility. So you don't need to explain to me that this stuff is normal because I already understand that (and am actively demonstrating a knowledge of this). I realize communication isn't always obvious, but if someone is telling you that you're missing the point of what they're saying, please consider that you might actually be missing the point rather than doubling down. Even if you aren't, someone telling you that indicates that somewhere there's a miscommunication, and that needs to be resolved. reply nebulous1 14 hours agorootparentI would prefer that it is distributed as a zip. It allows me to easily get the entire file, and hash it to make sure it's the same file as other people are getting, and have an archive of it. I would also like to be able to browse it online, but this is a usability issue for strictly when I'm intending to read it in a browser alone. As to your final paragraphs referring to communication and me \"explainig to you that this stuff is normal\", you specifically said that \"We don't want to normalize unnecessary behavior\" which implies that you do not think it is already normalized. You're also implying that I should have altered my interpretation of your words when you said that I was missing your point, even though you didn't say I was missing your point until the same reply. In any case, I think I understand your POV regarding archives, and I disagree. reply godelski 12 hours agorootparent> I would prefer that it is distributed as a zip. It allows me to easily get the entire file, and hash it to make sure it's the same file as other people are getting, and have an archive of it. I mean hosting it on any GitHub alternative makes this possible too. We also get better archival because when things change, we can see. Considering this says \"Part 1\" I expect things to change. History tracking is better for archival. > you specifically said that \"We don't want to normalize unnecessary behavior\" which implies that you do not think it is already normalized. That's not accurate. Here's a counter example \"We don't want to normalize clickbait headlines.\" Clickbait headlines are already normalized, that does not mean we want them to be nor does it mean we should accept them and not fight against them. I'm sure you can find many other similar examples. reply andrewflnr 12 hours agorootparentprevTo me the question is, why would you put source code on github if you're not going to make it uncompressed? What's the point of using a source code hosting website if your payload is a link to an upload site? Pastebin sites have been around for years. reply godelski 11 hours agorootparentExactly. Similar questions Why does a user need to download a file to achieve the goals? Does doing so provide added utility? Does obscurification provide some benefit? Does distribution in this manner help normalize environments which scammers take advantage of? I'd argue: - Don't make users download things they don't have to. - Serving in plain text gives higher utility as users can view it on any device (e.g. mobile. Am I the only one that reads repos on mobile?) - A GitHub alternative also provides the capacity to download an archived zip, thus achieving any benefits that aren't obscurification related - Git helps for better archiving as we can have a track record of commits and changes (this is labeled \"Part 1\"!) - Did no one else notice that there are \".github\" directories with workflows? But there is no \".git\" folder? I'd honestly like that... - While a zip itself is not an executable and not generally dangerous in of itself, scammers (hackers) do take advantage of such environments. Because you can... change a file extension. Or because a user may double click the zip to extract, but this will cause execution. Or idk, hackers are fucking smart and people are dumb. I'm a bit peeved that people feel the need to explain to me that a zip isn't nefarious in of itself, because that's not what I was concerned with (and that there's several such comments and we don't need to keep repeating the same comment...). My concern is with how such formatting is (as best as I can tell) not necessary, suboptimal, and normalizes practices that nefarious actors take advantage of. This topic is obviously hot, so I won't be surprised if there are \"alternative links\" that could just contain straight up maleware. Yeah, the user has to execute it, but people are dumb, lazy, and/or tired and there is a *better* form of distribution that just doesn't leave this script-kiddy style attack around. Like for fuck's sake, people at intelligence agencies plug in USBs they find on the ground... reply mimischi 14 hours agorootparentprevI suppose the risk of a 0-day in the compression format, given we’re in the post-xz-era. Publishing the source code in clear text would alleviate such risk for the consumer reply mrstone 11 hours agoparentprevAt the very least, here's a scan from Jotti. https://virusscan.jotti.org/en-US/filescanjob/svl9focwgt reply wibbily 14 hours agoparentprevI've nothing to do with the leak itself, so can't help you there. But did check - both archives are identical, and contain a Node project that seems to match what is claimed. (Run it at your own risk.) $ md5sum lam.zip 3a78b14e1379ac5c059dbbe5660fca8a lam.zip reply godelski 14 hours agorootparentThanks! I don't actually assume that the person is being nefarious, but I think it is also important to make sure that they understand these things. Especially if we're talking about scams. Scams take advantage of what is normalized, it is how they fly under the radar and bypass people's bullshit detectors. It's why a safety vest, hardhat, and a clipboard is the most covert disguise around. So one of the best ways to prevent scams is to normalize behavior that is harder to take advantage of! (same reason people fall for fake voice scams, because we're so used to distortion in calls anyways. A glitch poor voice can be difficult to distinguish from poor cell reception) As for the filesizes, I assume it is just the websites reporting incorrectly. Pixeldrain reports 188 MB compressed and 510 MB uncompressed. Mega reports 179.r MB. Pixeldrain at least shows all the files, which look to not have been cleaned up since they have things like .DS_Store. But at least the files are individually downloadable. reply fwip 14 hours agorootparent179 MB if a megabyte is 1024^2 bytes, 188MB if it's 1000^2. Zip files aren't evil, just unzip them and look inside. reply godelski 14 hours agorootparentI think you're missing the point of my comment. The point of the comment and request is about not requiring technical knowledge and minimizing amount of necessary thinking. The point is about helping stop scammers in the first place! > 179 MB if a megabyte is 1024^2 bytes, 188MB if it's 1000^2. This is not entirely correct though because MB != MiB. Us on HN will probably know this but proper labeling helps prevent mistakes. The improper labeling requires us to think more when considering security, which is bad security (not that you shouldn't think, but I'm saying \"don't set off alarms when you don't need to set off alarms\") reply dns_snek 11 hours agorootparent> This is not entirely correct though because MB != MiB. The point the parent was making is that the file is 188026773 bytes long. One site represents that as 179 MB (base 1024) and the other one as 188 MB (base 1000). Your complaint is therefore with one of the websites and not with the uploader. reply godelski 9 hours agorootparent> Your complaint is therefore with one of the websites and not with the uploader. That particular issue, yes. But that wasn't the main issue. I guess you're right, I could have clarified that I'm aware that the uploader is not in charge of the label and it was naive of me to presume that this was obvious. I should have explicitly stated such rather than let it be implicitly said. reply indrora 14 hours agoparentpreva zip archive is not executable unless something has gone very wrong. reply godelski 14 hours agorootparentYou're missing the point. As I've been explaining in other comments which have expressed the same thing as you have (please read to reduce noise and repetition), the point is about not normalizing environments which scammers can easily take advantage of. And clearly, the request has higher utility, so in either way, it is an advantage. reply kish_kush 14 hours agoparentprevuncompressed and compressed have nothing to do with what you said. you can choose to run the code or not, but it doesn't have to do with the uncompressed thing. reply godelski 14 hours agorootparentYou're missing the point. The point is to make it harder for scammers. Yes, I can safely extract files but on many systems if you double click a zip instead then there you go. Either way, it is always best to not download when you don't have to. The question here is \"is there a reasonable alternative that doesn't require the user to download.\" The answer is unambiguously \"yes\" and unambiguously has higher utility. reply meindnoch 12 hours agoparentprevBro, it's a zip file. It won't set your computer on fire. reply godelski 12 hours agorootparentBro, no one claimed this. reply rvz 15 hours agoprevBig if true. Could set back the AI device hype 5 years back after Humane getting exposed as another scam. reply jagger27 15 hours agoparentYou already have the best AI hardware we’ll see for a while in your hand. reply passion__desire 14 hours agorootparentI remember Mozilla was working on 3D web browsers. Could be new way to do things in Vision Pro? Is there any progress on that front? reply paxys 15 hours agoprev [–] Meh. I don't think they ever hid the fact that the device is basically a ChatGPT wrapper. As long as it can achieve what it advertises, who cares how the backend looks? At least it has the decency to charge a reasonably price ($200, rather than $700 + subscription like the Ai Pin). reply furyofantares 15 hours agoparent> I don't think they ever hid the fact that the device is basically a ChatGPT wrapper. \"Large Action Model\" reply k8svet 15 hours agoparentprev>As long as it can achieve what it advertises, who cares how the backend looks? so if I pump out enough advertising, you're going to give me the usernames, passwords, and active sessions for your accounts to me? I need to log out of this thread asap. I thought the defenses of Ai Pin were going to drive me nuts, I need to preserve some sanity. Has everyone lost their minds? Are tons of people here working for equally scummy, shoddy, if not scammy, startups? Seriously, what the hell. reply bogwog 14 hours agorootparentThis is probably what it felt like to be alive during the peak of the \"dotcom\" craze I read about in historical literature. reply cogman10 13 hours agorootparentprevHaven't you done that already? I mean this in all seriousness, have you used Oauth with google/facebook or the like to login and register with online services? Why not? Have you put passwords into a password manager? Why? Did you give Uber or Lift your credit card number? What if they were a scam? I say this also thinking rabbit R1 is a pointless product that based on hype that nobody should buy. However, I can see why people might think it reasonable to give their AI assistant a bunch of personal information. For the same reason people have trusted google with health data. reply k8svet 13 hours agorootparent> have you used Oauth with google/facebook or the like to login and register with online services? No, I don't use federated login anywhere. I can show you my Google account. The only place I've compromised is Tailscale, and I plan to replace that imminently. And frankly I consider it lazy of them to not support email, especially since google.com accounts are single-tenant anyway. And tailscale never sees my password, never has raw access to my entire damn account, etc, etc. Also, besides, federated login or delegated access, sure, OAuth is great, I wouldn't have commented in this thread if they were using it. Typing my raw creds into a [redacted] VNC session is not comparable. >Did you give Uber or Lift your credit card number? What if they were a scam? I call my credit card company. They reverse the charge, and ding the merchant. My life goes on. Takes a shockingly small amount of time. reply paxys 15 hours agorootparentprev> you're going to give me the usernames, passwords, and active sessions for your accounts to me? You give all of those to every smartphone maker. Why is this any different? Is there evidence that their handling is insecure? reply k8svet 15 hours agorootparentIf I found out that Android was eavesdropping my Spotify credentials, I'd be just as stupified, yes. If I found that Android built in some Spotify integration that worked by stealing my active session cookies to do some backdoor integration with it, and billed it as some future AI smart service, I'd find it equally g-d absurd, yes. Do I think that me logging into the Spotify app, in Android, and it exchanging those credentials for an app-internal access token is the same as a server hijacking my session? No, not really, I don't. That's what's so damn brazen and shoddy about this. SPOTIFY HAS OAUTH. reply paxys 14 hours agorootparentI have no idea what you are trying to say. The device works by running apps for Spotify, Uber etc. in a VM and logging you into it. They say it right on their homepage. If you don't trust it, sure don't buy it. That's your own decision, but doesn't make them any more right or wrong. reply k8svet 14 hours agorootparentI'm saying it's shoddy, and scammy, and I can't believe anyone would lift a finger to defend this type of product, engineering, or actively training people to get phished. Hope that clarifies. reply madeofpalk 15 hours agorootparentprevWell, I actually don't. I only use hardware from companies that I have a semblance of trust in, and I certainly don't run around entering my Spotify or Uber password into other services. reply ado__dev 15 hours agorootparentprevYeah, I have a lot more faith that Google and Apple will properly secure my private data vs a random startup. reply skywhopper 14 hours agoparentprev [–] It can't achieve what it advertises, though. I mean, what even did it advertise? Voice transcription? Playlist management? Phones do these already. \"Order me a pizza, whatever the most popular option is\"? That's laughable. No one actually wants that. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Rabbit R1 device from rabbit.tech aims to free users from app-based interactions but falls short of expectations, as its source code disclosure shows it lacks the advanced features it claims to have.",
      "The device depends on automation scripts for minimal app compatibility and doesn't incorporate artificial intelligence capabilities.",
      "Users are required to log in through a virtual machine, potentially introducing security vulnerabilities like storing user sessions without adequate safeguarding, prompting worries over user privacy and the device developers' engineering standards."
    ],
    "commentSummary": [
      "The leaked Rabbit R1 source code on GitHub sparked discussions on security and authenticity, with skepticism towards the leakers' claims, leading to debates on various tech topics.",
      "Conversations included technology, pricing, AI integration, wearables, voice recognition, and automation tools in app development, along with concerns about source code distribution, scams, file sizes, and security risks.",
      "Users also explored new AI devices like the Vision Pro, privacy ethics, and product features' actual performance effectiveness."
    ],
    "points": 326,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1713896322
  },
  {
    "id": 40132281,
    "title": "The Beauty of Japanese Language Complexity",
    "originLink": "https://aethermug.com/posts/the-beautiful-dissociation-of-the-japanese-language",
    "originBody": "The Beautiful Dissociation of the Japanese Language An extra dimension that you can play with. Marco Giancotti, April 20, 2024 Marco Giancotti, April 20, 2024 When I tell people around the world that I've been living in Japan for over a decade, many look both impressed and mystified at once. The place has a good reputation. Some folks are in awe at the temples and the gardens, others at the nature or the food. The extreme tidiness and civility of the local culture are the target of universal admiration. But many of those same people see the local language as an almost impenetrable barrier, a world of pain that one must go through in order to be allowed to live here. I must be so patient and smart, they think. But I (begrudgingly) have to tell them that it's not entirely true. The thing is (I tell those people) the language is part of the wonders of the place. It was the biggest charm for me in the first place. It's complex, yes, but it's rich and quirky and different. In particular, a whole realm of consciousness exists in the sphere of Japanese speakers that's perhaps truly unique in the world, more so than the sushi and the nature and decorum. It even allows for new literary techniques that are unimaginable in any other language. Usually this is the point when I lose my interlocutor. I might as well be speaking Japanese to them. I've always wanted to explain that realm, to show what a strange and mind-bending world is accessed by learning Japanese. It feels almost impossible. In this rather long and winding post, I'll try anyway. I'll do my best to convey something that's damn near untranslatable. Whether this is a rabbit hole you want to tumble down with me, that's up to you. The Things I'm Not Talking About Unless you've studied the language for a good while, you might only be aware of one or more of the following strange-sounding facets of Japanese: It uses kanji characters for writing (more on this later), and it uses a whole lot of them. Depending on who you ask, there are four, five or more thousand characters in use, and you can't read a newspaper if you don't know at least 2,000 of the more common ones. There are also two syllabic scripts (syllable-based alphabets) in use, called hiragana and katakana. These two, plus kanji, are used all together, sometimes but not always interchangeably. There are lots of \"untranslatable\" words in Japanese, like the salutation お疲れ様 (otsukare-sama), roughly meaning \"I appreciate the hard work you've been doing\", and もったいない (mottainai) for \"it would be a pity not to enjoy that to its fullest value\". Exotic-sounding grammar features like the subject-object-verb sentence structure (i.e. \"anteater ant eat\") and the lack of important-sounding grammatical elements like articles (\"the\", \"a\"), any singular-plural distinction, and most verb tenses familiar to English/Romance language speakers. It's very vague and context dependent. These aspects give the language an arcane and difficult-sounding aura, but none of them is truly unique to Japanese. Chinese, for instance, uses way more characters and has an even more bare-bones grammar. All languages have untranslatable terms. And several other cultures routinely employ multiple writing systems. These aren't the things I mean by \"a truly unique realm\", and they're not the topic of this post. What's usually not known are the subtle effects of the strange history of the Japanese tongue. These effects are, I believe, absolutely unique to this language, with no parallel anywhere else in the world. On top of that, native Japanese speakers are usually so accustomed to these quirks that they never give them a second thought. So no one—except, I guess, some linguists—ever talks or thinks about these fascinating aspects of Japanese. I write about them here because, well, that's mottainai. It took me a while to put my finger on it, but now I know what the source of that uniqueness is: it's the unstoppable, wonderful dissociation between what's written and what is spoken in Japanese. To see how that could have happened, we need to take a step back. Subscribe to receive emails for future posts on Aether Mug. It’s free. Dissociated from Birth: a History The Japanese language existed in purely oral form for centuries, until mainland scholars brought Chinese characters to the Japanese islands. That happened in the 5th century C.E. These characters are, unlike the western alphabets, \"logograms\", that is, each character is associated with a specific meaning. Chinese and Japanese are enormously different spoken languages. Except for a large number of words imported directly into Japanese (but evolved to sound quite unlike the originals), the two languages have essentially nothing in common. The pronunciation, the grammar, everything is 180° different. A consequence of this is that those Chinese characters, evolved over millennia to fit the Chinese language like a glove, were a bad match for the way the islanders spoke. Imagine those poor scholars of the Yamato court in Western Japan in the 7th century. They must have been intrigued by this revolutionary technology called \"writing\", where you could freeze your words onto a stone or the blade of a sword so that others may understand it later. Why leave it to the Chinese immigrants? Why not master it for their own native language? Except it must have been excruciatingly difficult. The characters were meant to be used as modular building blocks—a kind of modularity that Japanese just didn't have. Not many depictions of scholars from the Kofun period survive (they must have been too busy wrangling the kanji), but warrior statues abound. So here is a warrior. While Chinese uses fixed \"plug-and-play\" markers to indicate tenses and and grammatical functions, on this front Japanese is more similar to English, because it modifies the very shape of words for those things. So in Chinese you say \"chī\" for \"eat\" and \"chīle\" for \"ate\". The \"le\" part indicates an action that has completed, and it can be strapped onto any verb to turn it into a past tense. So those two spoken words can be neatly segregated into written logograms: 吃 (\"chī\") for the present tense, and 吃了 (\"chī\" + \"le\") for the past. Compare that to English where we transform \"eat\" into \"ate\", and the equivalent Japanese modification of \"taberu\" into \"tabeta\". In both cases we're not adding or removing blocks but changing part of the word to convey the difference. In techie terms, the Chinese script doesn't support the structure of languages like English and Japanese. It doesn't have what it takes. The only solution for those early Japanese scribes, then, was to do a lot of shoehorning. And boy, did they shoehorn. The Japanese scholars-aristocrats began repurposing the Chinese characters, which they called kanji (for, well, \"Chinese characters\"). Sometimes, instead of using them for their meaning, they used them for (gasp!) their pronunciation. By ignoring the original content of a kanji, they could string them together to form almost any sound. To a Chinese reader, such words would have looked utterly random, devoid of any coherence or structure. But to a trained Japanese, they translated into familiar words. Over the centuries those \"sound-only\" kanji, called man'yougana, evolved into something else entirely. They became simpler, more streamlined, and more standardized. Where the symbols were originally composed of many short strokes, they gradually lost detail and complexity. Where the scribes could choose between a slew of different kanji for any given sound (for instance, the sound pa could be represented by any of 20 characters), later the number of options dwindled and eventually settled to two. That's how the two syllable-based alphabets in use today, hiragana and katakana, came about (collectively kana). For example, this is how the sound for \"i\" (pronounced \"ee\") evolved from two separate kanji into respective kana pronounced exactly the same. With this new sound-based tool invented by the islanders, finally the Japanese language had a suitably flexible way to write anything one could pronounce. Today full-blown kanji are used for their meaning, while hiragana and katakana are used for sound-based writing and grammar stuff. (By the way, the application of Chinese characters to other languages happened in several other places, like Korea and Vietnam, but only Japanese still retains the writing system today, making it a unique case among contemporary languages.) And so, thanks to this grafting of one language's way of writing into a vastly different tongue, a dissociation was born. Japanese is a language where the spoken and the written co-evolved in directions never seen elsewhere. The differences in grammatical structure are only part of the story. Let's start with the basics. Anomaly 1: One Way to Write It, Many Ways to Read It Like most language pairs, there was rarely a one-to-one correspondence between Chinese and Japanese words. Often a single Chinese word or character could merely approximate the meaning of several spoken Japanese words. Each of those local words might have been related to the others, but it carried a different nuance. Even so, for lack of a better solution, often the same kanji was used for all the various meanings. This had two major effects. First, while in any Chinese language each character is associated with a single way to speak it, in Japanese every kanji can be pronounced in multiple, very different ways. This part is perhaps the biggest bane of Japanese students. Extreme cases have 15+ different pronunciations (readings) for a single kanji! For example, the kanji for \"life\": Some of these pronunciations are common, others quite rare, but you need to know and be able to discriminate most of them in order to correctly read and write modern Japanese. The second effect of the imperfect match between the written word and the meanings it is associated with is a kind of \"chronic looseness\" in the conversion of language to and from writing. A Japanese reader isn't expected to correctly pronounce everything. New, unfamiliar words will be opaque to them. In a sense, this is similar to English, only much worse. In English, the question is usually about the right way to pronounce a vowel or two. As is clear from the example just above, in Japanese, sometimes you don't know if the kanji for life has to be read as \"nasu\" or \"shou\". Add to that the huge number of kanji in circulation, and in many cases you have absolutely nothing to work with. If you haven't seen the kanji before, you have zero hints about the right sounds to make. Japanese has a trick up her sleeve to solve this problem, called furigana. These are tiny kana characters showing you how to pronounce a difficult kanji. A sign in a train station. It's often impossible to guess the pronunciation of place names, hence the furigana above the official kanji name. Source: Wikipedia. Kids keep on learning new fundamental kanji until the end of high school, so they wouldn't be able to read without extensive application of furigana. Adults are able to survive with less furigana, but you'll still find them on the rarer words that people might not have encountered before (or for which they might have forgotten the reading). For example, this is a page I opened at random from a Haruki Murakami non-fiction book. In the whole page, only one kanji word (a somewhat rare way to say \"mock\") has the pronunciation spelled out with furigana (those two tiny squiggles between the lines). Remember this part about furigana, because they'll come up again in the following sections. Now for a practical consequence: people need to get creative just to teach others how to write their names. Anomaly 2: Spelling Bee, but Creative There is one problem that arises because of how kanji work: how do you explain which character you're talking about without writing it down? This happens all the time with people's names. The Japanese like to choose nice and distinctive kanji for their names, even when using common name pronunciations (another instance of dissociation: common name readings on unheard-of kanji choices are all the rage this century). This means that, just by hearing what someone is called, you're usually unable to write it down. So people have to explain the kanji to you, and they do it by telling you which other well-known words each kanji appears in, or how it is built from simpler components. Perhaps the most famous scene showing the hoops you have to jump through just to explain your name's spelling. It's from the manga \"Death Note\". Here the woman is giving a fake name, but soon afterwards Raito finds out her real name and uses it to kill her real quick. Anomaly 3: Breaking Out of the Box Reading is made more difficult by the frequent use of jukujikun, words where the pronunciation is not the combination of the normal readings of the individual kanji contained. In these cases there isn't any correspondence between parts of the spoken word and the kanji that represent it. Japanese has a lot of compound words of Chinese origin, where two or more kanji appear as a set. These compounds are usually very straightforward sequences of kanji readings. So 美術 (bijutsu), meaning art, is the combination of 美 (\"bi\", beauty) and 術 (jutsu, skill). If you're confident about the individual sounds, you just have to say them one after the other. Finally something simple! But no, you can't let your guard down. The shoehorning work of the ancients has left deformations that survive in the modern language. Take, for example, the word for \"adult\". It's pronounced otona and written 大人, the kanji for \"big\" and \"person\" respectively. Following the usual method, you might wonder, is oto a pronunciation of the first kanji, and na of the second? Or is it o and tona? Well, neither. There is no way to split them. The two-kanji word exists as a single block, and looking up each kanji separately won't yield even a bit of this word's true reading. There are many examples like that. A bull-headed shrike. Source: Alpsdake, Wikimedia Commons (CC BY-SA 4.0). In some cases, the number of kanji is longer than the number of syllables in the word! Try splitting that up. Anomaly 4: Two Words in a Trench Coat But, despite all of its difficulties, this dissociation of writing and speaking opens up some interesting opportunities. For example, there is a category of verbs that I find fascinating. As far as I know, it has no official academic name, and I've never heard anyone else even mention this. I would describe them as \"two words in a trench coat\". In each case, you can see how two simpler verbs were chained and wrapped with a single kanji. For example, the verb 司る (tsukasadoru), meaning \"to be in charge\" seems pretty innocent at first. It's one kanji plus its hiragana ending indicating the tense, like all other verbs. But look up the etymology, and you'll find that it used to be two words: 官 (tsukasa) for \"position of authority\" and 取る (toru) for \"take\". Each of these two words has its own kanji and independent meaning. But over the years, their combined form became so routine that someone decided to give it its own different kanji, probably for no other reason than convenience. Here are a couple more cases: These fusions are like language fossils. It shows that kanji are only an after-the-fact addition to a pre-existing vocabulary. But at a practical level, they're a way to exploit the looseness of Japanese writing to make writing more convenient (notice how short the final written words are compared to the original). Anomaly 5: Make the kanji Work for You In Anomaly 1 I said that one kanji can be ambiguous in terms of its pronunciation. But the flip side of the same phenomenon is that kanji can help reduce ambiguity in meaning, increasing the precision of the written word. Spoken Japanese is actually rather poor in vocabulary. A lot of its verbs are reused in very different contexts with different meanings that are only related in a very abstract way. Thanks to the unique slap-it-on-and-you're-ready-to-go mindset of Japanese writing, however, the vagueness can be pared down a lot. There is a surprising number of verbs that have exactly the same pronunciation, but are written with different kanji in different contexts. For example: The cool thing here is that these are all different meanings, but if you squint you can see how they must have originated from the same primordial word. They started with a generic, blunt verb (e.g. toru, to take), and later applied to it different kanji to distinguish its nuances. Handy! There are also non-verbs examples of this trick. My favorite are all the versions of the word \"cousins\" meant in a reciprocal sense, as in \"she and I are cousins (of each other)\". In spoken language, you just say itoko in all cases, and that's it. In written language, you use the appropriate combinations of the kanji 兄 (ani, older brother), 弟 (otouto, younger brother), 姉 (ane, older sister), and 妹 (imouto, younger sister), preceded by the kanji 従 (shitagau, accompany), to specify the exact genders in the relationship. (These are also jukujikun, come to think of it.) You can use kanji, then, to add a layer of meaning that doesn't exist in the spoken language. Which brings us to the last and, in my opinion, most interesting point. Anomaly 6: Dissociation as Canvas Finally we come to gikun, the most exquisite (ab)use of the rift between written and spoken Japanese. It's based on the clever use of furigana, the little pronunciation marks explained above. Ninety-nine percent of the time, people use furigana as you would expect—plainly indicating the correct dictionary reading of each word. But once you have a tool, who can resist playing with it? Gikun is the replacement of a kanji's or word's normal pronunciation with something else through furigana. Novelists and manga-ka use it to inject an almost subliminal layer of meaning beyond what is afforded by the words and kanji. It achieves an effect similar to a textual voice over, at the same time as the actual text you're reading. You see it a lot in manga: the actual kanji say something, but the furigana, instead of giving you the true pronunciation of the word, give you something else entirely. Sometimes it's a synonym of the word with a more pungent nuance. For example: Source: Boku no Hero Academia, cited by japanesewithanime.com (CC BY-SA 4.0) The author of the excellent gikun explanaton on japanesewithanime.com clarifies the context: Todoroki Shouto 轟焦凍 has both cold and heat abilities, which come from the sides of his body: from the right comes cold, from the left comes heat. Here Shouto, the protagonist, is telling the flame-y man \"during combat, I won't use my heat power for any reason at all.\" Being a kids' comic, all kanji have furigana. But the kanji for \"heat\" (highlighted in red) comes with an unexpected reading. Instead of the official netsu, the furigana reads hidari, which means \"left\". So the reader gets two messages at the same time: the character says \"I won't use the left\", but the text is saying \"I won't use heat\". Sometimes, authors use gikun for the luxury of introducing cool foreign-sounding words while simultaneously providing the meaning for it through kanji. Source: Full-Metal Alchemist, cited by japanesewithanime.com (CC BY-SA 4.0) And the context from japanesewithanime.com: Good guy with mechanical arm fights bad guy with mechanical arm. The blond guy says, \"Oh, an automail colleague?\" to say that they both have mechanical arms. But \"automail\" isn't a real word, and the Japanese reader may not guess the etymology of \"automatic\" + \"mail (armor)\". So the meaning is provided by the kanji (literally \"mechanical armor\"), and the word \"automail\" comes as furigana above that. Again, you get two things in one swoop: a neologism and its meaning. Other times it's simply a clarification of the word in that specific context. Source: Noragami, cited by japanesewithanime.com (CC BY-SA 4.0) The context: Yato 夜ト, who is a God fighting spiritual beings related to human's negative feelings, goes to the hospital make [sic] a visit to someone... The off-screen speaker is saying, \"Tonight will be rough too. This place is their nest. Now that the regalia aren't with us, we shouldn't stay long.\" (I assume the \"regalia\" are some kind of warrior.) In this case the words \"this place\" appear as furigana for the word \"hospital\". The kanji say \"hospital\", the reading says \"here/this place\". Through gikun, the author is avoiding confusion on the current location of the characters. Some novelists use this dissociation for artistic effect, too. Horror-mystery writer Natsuhiko Kyogoku, who loves to create the Japanese version of a Gothic atmosphere, constantly uses archaic, long-forgotten kanji in his brick-sized novels. You, as the average Japanese reader, probably have never seen most of those kanji before, but you're able to follow without problems thanks to his gikun. The furigana expose the modern, recognizable readings that you can recognize, even though they are not the real readings of those obsolete kanji. Kyogoku's gikun shenanigans are a bit too much at times. Someone who uses them more sparingly and subtly is Haruki Murakami. This is a page from his novel Norwegian Wood. Jay Rubin, the novel's English translator, worded the highlighted sentence like this: What if somewhere inside me there is a dark limbo where all the truly important memories are heaped and slowly turning into mud? But the word \"limbo\" (pointed by the arrow) in the original is actually a gikun. The Japanese reader sees two things at once: the kanji with the meaning of \"a remote region\"—normally pronounced hendo—and the katakana pronunciation of the foreign word \"limbo\" as furigana next to it. The Japanese language does have more accurate words for \"limbo\", words with a stronger link to the original catholic meaning of the word, but Murakami decided not to use them. This little choice, seen by the reader in a fleeting instant as they devour the pages, and likely not even noticed consciously, is doing a lot of work. It's indulging in the mystical-sounding foreign word \"limbo\", but it's also clarifying the general meaning of liminal space for the readers unfamiliar with it. It's making the metaphor of an actual hidden place within oneself stronger, while avoiding overly religious undertones. In short, this gikun alters the flavor of the word a tiny bit, just enough to achieve the thematic and stylistic goals of the sentence. Like a pinch of nutmeg in your butter cake. How is one to translate that? It's difficult to convey what it feels like to read in this way. For me, back when I started reading in Japanese some 16 years ago, it was a totally new experience, something that I never thought would be possible with text. It's like reading in stereo, where sometimes the same message is conveyed to you in two different formats on separate channels, and sometimes two messages blend together as something new. Because of the unique dissociation between the written word and the way it is pronounced, Japanese is not only harder to learn, but it's also more malleable and richer in a way that cannot be imitated. It's an extra dimension of language and a happy historical accident. ● Subscribe to receive emails for future posts on Aether Mug. It’s free.",
    "commentLink": "https://news.ycombinator.com/item?id=40132281",
    "commentBody": "The beautiful dissociation of the Japanese language (aethermug.com)309 points by mrcgnc 19 hours agohidepastfavorite208 comments worldsoup 15 hours agoSuper interesting article, as a native english speaker who lived in Japan for many years and speak Japanese fluently, he pointed out a lot of things I always took for granted in Japanese (and never recognized as unique). One things I was hoping he would point out, and that I always found extremely unique in Japanese, was the giyongo (basically onomatopoeia). Japanese uses these extensively and the sounds can have extremely sensory driven meanings. They use these giyongo to describe physical textures (tsuru-tsuru is something smooth and slippery), hard to describe souns (pera pera is the sound of speaking a foreign language), flutently), actual sounds (tatata is the sound of fast running), a general feeling (bisho bisho is the sound of being soaked), specific actions (gussuri is the sound of being out cold), even specific emotions (zukizuki is the sound of extreme pain). There are hundreds if not thousands of these and I think they also make the language, as the author describes, 'rich and quirky and different'. reply thedailymail 7 hours agoparentMinor pedantry (sorry!), but it's giongo (擬音語) not giyongo. There's a related term gitaigo (擬態語), both of which fall under the catgeorical giseigo (擬声語). All are generally translated as onomatopoeia in English. The basic distinction is that giongo are used to express sounds made by physical things, both living and inaminate, whereas gitaigo are used to express abstract effects, such as emotional states, energy levels, etc. The Japanese-language wikipedia page goes into it in more detail: https://ja.wikipedia.org/wiki/%E6%93%AC%E5%A3%B0%E8%AA%9E reply ternaryoperator 6 hours agorootparentYour point only deepens my appreciation of Japanese (which was already deep). To have two different categories of onomatopoeia is just sensational. reply atribecalledqst 14 hours agoparentprevI've started to suspect recently that an important secret of being able to sound natural in conversational Japanese is using a LOT of onomatopoeia words. I've considered mining all of them from jmdict and studying them specifically. reply jankcorn 3 hours agorootparentI have always liked the book \"日本語擬態語辞典\" by Gomi Taro:It has great illustrations that quickly get the idea across for Japanese onomatopoeia. To give an idea of what it is like, here are a couple of example pages: Quite fun to read! reply anigbrowl 11 hours agorootparentprevThat's a great idea. I love them because many of them are evocative of either an actual real sound, or play with some loan word. This makes them easier to remember, plus they don't need any kind of special conjugation. Abbreviation, repetition, and stacking bits of words together are a big difference between natural vs formal Japanese language skills. It's very Lego-like that way. reply worldsoup 14 hours agorootparentprevdefinitely, you really need to master these to be anything close to native level reply latentsea 9 hours agoparentprevThere are thousands at least. I recall seeing an entire dictionary of them once in the library at my university. To this day I still discover new ones that constantly amaze me someone was able to put a sound to it. I think my favorite to date is probably mozomozo. My wife used it to describe a baby flailing it's arms around. I was like ok... What do you mean? She repeated the action of flailing the arms around. I laughed. Oh the Japanese. reply frereubu 12 hours agoparentprevI bumped into another English guy who was teaching English in Japan and he made me laugh when he told me that the name of my favourite conveyor sushi restaurant in London - Kulu Kulu - meant \"round and round\". Sounds like it might be similar to these phrases. reply Delk 11 hours agorootparentくるくる (usually romanized as 'kurukuru') does seem to mean going round and round: https://jisho.org/search/kurukuru Japanese isn't generally considered to have the equivalent of the 'l' sound from most other languages, and it rather has a sound that's perhaps somewhere between 'l' and a rolling 'r'. In romanized text it's generally written as 'r'. Transliteration isn't really unambiguous in the end, though, and there are multiple ways of romanizing Japanese, so while romanizing くるくる as 'kulukulu' doesn't sound like a very common transliteration, it may be possible. Also, 'kuru' means 'to come', but I don't know if that's related. reply jonhohle 6 hours agorootparentIt’s amusing that the characters even look like a conveyor belt. reply frereubu 11 hours agorootparentprevThanks for the explanation. I'd heard about the r / l issues with romanizing Japanese but hadn't made the link. reply Lammy 10 hours agorootparentprevRelevant We ♥ Katamari: KuruKuru Rock https://www.youtube.com/watch?v=AKsNvLAiPc8 reply kbf 10 hours agorootparentAlso: https://en.wikipedia.org/wiki/Kuru_Kuru_Kururin reply zenogantner 12 hours agoparentprev\"Fifty Sounds\" by Polly Barton is a book-length essay about this. Very entertaining read. Plus some Wittgenstein thrown in ... reply wulfeet 15 hours agoparentprevI remember talking to a Japanese coworker about some pain I was experiencing, and they asked if it was like zukizuki or - some other word. reply worldsoup 13 hours agorootparentya there are many different giyongo to describe various states of exhaustion...probably due to the workaholic culture that is prevalent in Japan reply lIl-IIIl 13 hours agorootparentI think there are different onomatopoeia for different kinds of pain. English equivalent is probably when a doctor may ask if a pain is sharp, dull, pulsating, burning, etc. reply jameshart 10 hours agorootparentprevCareful... it's a little too easy to ascribe things like that to a superficial cultural trait. English has a huge variety of terms for extreme tiredness: whacked, bushed, wiped out, worn out, drained, burned out, beat, knackered, fried, shattered, frazzled, zonked... must be the puritan work ethic or something. We've even got a few onomatopoeia of our own: feeling kinda.. ugh.. meh... bleugh... I mean, whew, yeesh. Just... phew. Maybe being tired is just the global human condition. reply edgyquant 9 hours agorootparentIt may be due to Protestant work ethic, no idea, but non of the English words you cited are actual onomatopoeias reply jameshart 9 hours agorootparentWell, ぐたぐた, へとへと and よたよた aren't exactly onomatopoeias either. reply Jagerbizzle 9 hours agorootparentprevNot to mention \"sigh\", which I find impossible to say without also sighing. reply tarentel 13 hours agoparentprevI read a lot of manga and they often have a lot of hyper specific sound effects. I don't speak Japanese but always found this interesting. I guess this explains it. Thank you. reply rauljordan2020 17 hours agoprevAs someone who speaks Chinese and is learning Japanese, I have been so surprised at just how incredibly complicated and obtuse Japanese is. Chinese (Cantonese) 7-9 tones, loads of characters, but after memorizing the first 2000-3000, you pick up on all the radicals, patterns, and meanings which help you fill in the gaps. Grammar is barebones: I only had to learn 5 to 10 different grammar rules for Chinese that I recall, and basically everything else is incredibly easy. Whereas in Japanese, I am learning 2-3 grammar rules per LESSON. Having each character pronounced a single way in Chinese is also super easy, and communication is even more direct than English. With Japanese, the cultural context, the phrasing, the end particles, and subtle vocab changes the meaning significantly. I think for me, it took 5 years to reach fluency in Chinese but I feel that even after 10 years I will barely reach conversational fluency in Japanese. It just feels like an inefficient language for communication. Why does it have to be so complicated? reply pm215 16 hours agoparentI think some of the \"Japanese has a ton of grammar points\" is an effect of how the Japanese-as-a-second-language teaching resources label things, where a lot of what you could classify as \"sentence patterns\" are described and taught as \"grammar\". For example, the Dictionary of Intermediate Japanese Grammar lists ~に比べると as one of its grammar points, but this (meaning \"compared to ~\") isn't really new grammar, it's just a specific usage of particle に, a particular verb and と for if/when (in the same way \"compared to X\" isn't new English grammar but is a pattern of use of a particular verb). My experience is that Japanese grammar isn't particularly complicated, it's just that it works backwards from Indo-European languages. Vocab is a pain because there's no common root of word origins to help the way there is between say English and French, but that's true for Chinese too I suppose. The writing system is kind of silly but it is what it is (and of course it doesn't matter at all for conversational fluency). reply thaumasiotes 15 hours agorootparent> I think some of the \"Japanese has a ton of grammar points\" is an effect of how the Japanese-as-a-second-language teaching resources label things, where a lot of what you could classify as \"sentence patterns\" are described and taught as \"grammar\". Sentence patterns are grammar. They are a major presence in English grammar, where e.g. in almost all cases you can only determine the subject of a sentence by the fact that it precedes the verb. Other languages are more explicit. Fundamentally we use \"grammar\" to refer to whatever governs the meaning that appears in a well-formed sentence that isn't just part of the individual meanings of (the uninflected forms of) the words in that sentence. But this is not an entirely satisfactory definition, and grammar can show up in surprising ways. Consider the difference between the verbs \"look\" and \"see\". In Japanese, there is no difference. They are the same verb and they mean the same thing. Japanese learners do not understand why English speakers draw a distinction, and they struggle to use the correct word when speaking English. In Mandarin, these verbs are also the same verb. But Mandarin speakers draw the same distinction that English speakers do - if they mean \"look\", they will say 看, and if they mean \"see\", they will say 看到, inflecting the verb with a grammatical suffix indicating successful completion. Although they do not use separate verbs, they have no trouble tracking the English distinction. In English, obviously, the same distinction is drawn. But the mechanism is lexical; we treat these as being entirely different words. I suggest that a Japanese learner choosing \"see\" when they mean \"look\" or \"watch\" is making a grammatical error, the same way that they'd be making a grammatical error if they said 看 instead of 看到 while trying to speak Mandarin. reply pm215 14 hours agorootparentWhat I mean is that, to use an English example \"in comparison to X, Y\" and \"in contrast to X, Y\" are not grammatically different -- the words are all doing the same jobs in the same structure, it's just a different verb. But they're both useful idiomatic patterns to learn. It happens that the standard in Japanese as a second language teaching is to call (the Japanese equivalents to) these different idiomatic patterns different grammar points. Personally I don't care too much about the terminology as long as everybody is on the same page, and because this is the standard in the J2L communities it's generally fine; but it does mean that looking at the size of the volumes of a \"Dictionary of Japanese Grammar\" is a bit misleading about how grammatically complex the language is. I would suggest that choosing \"see\" when you mean \"watch\" is a vocabulary error, not a grammar error - you picked the wrong verb, but didn't use it in an ungrammatical way (eg wrong tense or mixing transitive and intransitive or getting subject and object the wrong way round). reply thaumasiotes 6 hours agorootparent> I would suggest that choosing \"see\" when you mean \"watch\" is a vocabulary error, not a grammar error - you picked the wrong verb, but didn't use it in an ungrammatical way (eg wrong tense or mixing transitive and intransitive or getting subject and object the wrong way round). Have you tried doing this? In general you can't swap these verbs without the resulting use being ungrammatical. The problem is that \"watch\" is durative (it takes time) and \"see\" is punctual (it takes no time). reply pm215 2 hours agorootparent\"I watched the hawk landing in the tree\" ; \"I saw the hawk landing in the tree\" -- both fine grammatically. reply thaumasiotes 2 hours agorootparentIs this the level of analysis you apply to all your work? Try \"I was watching the hawk as it landed in the tree.\" reply Izkata 14 hours agorootparentprev> Consider the difference between the verbs \"look\" and \"see\". > In Japanese, there is no difference. They are the same verb and they mean the same thing. Japanese learners do not understand why English speakers draw a distinction, and they struggle to use the correct word when speaking English. Isn't that like 見る and 見える? reply chaorace 11 hours agorootparentMy understanding is that in many (but not all) cases they're gramatically interchangeable, but imply different levels of directness. Something like the difference between \"I see you\" (direct) and \"I can see you\" (indirect), with a general preference for the latter in polite conversation. It's not a perfect comparison because in English both usages of see are transitive, but hopefully the general idea comes across. Circling back to the original discussion: I'd say that it's better to compare the past & non-past tenses of Japanese verbs: - \"Thank you\" in the past tense (\"ありがとうございました\") conveys that you are thankful for acts already rendered and that you do not intend to impose further. - \"Thank you\" in the non-past tense (\"ありがとうございます\") conveys that you are actively thankful, generally when the act in question is still in progress or otherwise not yet completely rendered. This is a nuance that English renders trivial with a simple \"Thank you\", much like Japanese renders trivial the difference between a completed \"look\" and an incomplete \"see\". reply chrisoverzero 13 hours agorootparentprev見える only means “look” in the “to seem” or “to appear” sense. Often in English, we have multiple words for sensory experiences to indicate how much focus is put into the action. “Seeing” a picture is less focused than “looking at” a picture. “Hearing” a song is less focused than “listening to” a song. reply emmelaich 13 hours agorootparentI wonder if that inspired the lyric in \"Come Together\" Got to be good-lookin', 'cause he's so hard to see According to Wikipedia, \"The lyrics were inspired by his relationship with Ono,\" reply Izkata 11 hours agorootparentprev> “Seeing” a picture is less focused than “looking at” a picture. Isn't that backwards? Like in the phrase \"they look but do not see\", which was what I had in mind in my first comment. Isn't that something like \"見るけど見えない\" ? reply jprival 8 hours agorootparentTo look is to train one’s eyes on, or to scan for, something. To see is to perceive it. So one can look without seeing, and one can also see something without intentionally looking. reply thaumasiotes 3 hours agorootparentBut as you've implicitly noted, you cannot see something without looking. That would be physically impossible. You can also use \"look\" to emphasize that focus does not exist; one of the sentences I've collected for interesting use is \"He stared at the page, not seeing it.\" In that case, there is no possibility of a page being overlooked or otherwise missed. What the sentence is telling us is that although \"he\" is directing his eyes at the page, his mind is on something else, so \"seeing\" never occurs. The difference between \"see\" and \"look\" has nothing to do with focus. It is what I noted in the discussion of Mandarin - success. Seeing is the goal of looking. Note that this phenomenon where native speakers have no trouble obeying a distinction that their language requires, but come out with total nonsense when asked why they choose one form or another, is completely characteristic of grammatical rules, and not characteristic of vocabulary selection. reply eloisant 17 hours agoparentprevThe Japanese grammar is pretty simple in fact, but it's very confusing coming from a European language because of how different it is. OK, once you get to the high level politeness (keigo) it can get pretty complex but you don't have to learn that until you're fluent in casual and neutral polite forms (teinei). I don't know Chinese but I've read that it's \"subject-verb-object\" like in English, so maybe that's why you found it easier than Japanese. I got to fluency in Japanese in roughly 6 months to 1 year while living there. And it makes a big difference, if you use it daily they you can catch up whole sentences and understand the grammar logic later on. reply rauljordan2020 16 hours agorootparentThere's no tense, no verb ending, no conjugation, zero of any of that stuff in Chinese...the difference is night and day. There is barely any grammar to learn. I finished the Chinese grammar in less than a week lol A few examples from endless notebook on Japanese grammar notes I have from lessons - Various て forms, which have their own complexity and nuance. Spent almost a year on this - Volitional forms - X-なければ, conditionals, should/shouldn't - the \"te-shimau\" form - くれる / あげる - Conjugations for past tense for the 3 different verb categories...which were so hard to remember - しか - ばかり - ように - X-ところだ - X-ほうが-Y - Command forms, conjugations, etc. reply wk_end 16 hours agorootparent(background disclaimer: native English speaker; can read Japanese and French reasonably well; German somewhat less so; have also lightly studied Latin + Russian + Spanish; Chinese not at all) Chinese sounds more like the exception than the rule. I feel like if you're going to say \"It just feels like an inefficient language for communication. Why does it have to be so complicated?\" you should come for the Indo-European languages first; exoticizing Japanese as this bizarrely complex, weird language just isn't accurate. In fact, even with the various things you listed, Japanese grammar is still relatively simple compared to most European languages, for instance. No genders, few tenses, only two irregular verbs, a word order system that's both pretty consistent (SOV) and flexible...meanwhile, a lot of what's called \"grammar\" in Japanese language pedagogy feels more like what European languages would call idiomatic expressions. Even keigo, which is definitely a pain point...English, for instance, has all sorts of subtle ways of communicating tone and politeness, it's just not quite as explicit. In a way, the strict manner in which it's codified in Japanese makes those nuances somewhat easier to grasp. reply gerdesj 10 hours agorootparentI think you have it right and OP doesn't. For example: \"Exotic-sounding grammar features like the subject-object-verb sentence structure\" There is nothing exotic about SOV vs any other order. Latin (and all Romance languages French, Italian int al): SVO, German: SOV. English: SVO. All of them are complex enough that word order can be re-arranged and the meaning remains and often enhanced. All human spoken languages are Turing complete (not enough room in this column for a wonderful proof I came across tomorrow). All humans have the same set of hardware and software (I hate the term wetware) and facilities. There are some variations in how they are used but in the end I refuse to allow for concepts that are \"untranslatable\". I do allow that some people have, say, four colour vision instead of three and so they can experience a colour spectrum beyond the norm. My Mum had better than normal visual acuity - she could see much further than the rest of the family. Regardless of sensors, we all have largely the same set of equipment to process and convey our ideas and notions. Creative use of that equipment and deployment of the same should be applauded and encouraged. However, don't get yourself hung up on the idea that your ideas are somehow different or unique or even worse: better, due to some sort of racial alignment or language. I'm a massive fan of vive la differance but I also like to see vive la meme. reply thaumasiotes 6 hours agorootparent> Latin (and all Romance languages French, Italian int al): SVO, German: SOV. English: SVO. All of them are complex enough that word order can be re-arranged and the meaning remains and often enhanced. Latin is definitely not SVO. Those roles are marked explicitly enough that they can occur in any order without really causing any problems (and in poetry, they do), but to the extent that an order applies to Latin, it is SOV. This is one of the features that is felt to result from simplification. As you note, Romance languages tend to be SVO. It's also true that Mandarin is SVO where other Chinese languages tend to be SOV. And that creoles tend to be SVO even when every source language uses some other order. So the theory does float around that SVO order is in some sense more intuitive than the others, and that's the reason for its appearance in Romance, Mandarin, and creoles. reply pilaf 7 hours agorootparentprev> only two irregular verbs This is what textbooks often say, but it's kind of a soft lie. Besides the typical する and 来る (which are strongly irregular), there's: ある → ない (negative form) 行く → 行って instead of expected 行いて くれる → くれ (imperative form) instead of expected くれろ And a number of others. https://en.wikipedia.org/wiki/Japanese_irregular_verbs reply glandium 4 hours agorootparentI'll go pedantic, but ない is technically not an irregular negative form of ある. The negative form of ある is the regular あらぬ/あらない, but it has been substituted with ない, which is an entirely different word. You'll often hear あらへん in Kansai dialect, which is derived from ある. Edit: there are idioms that use あらず which is also a standard negative form of ある, like なきにしもあらず. reply actionfromafar 10 hours agorootparentprevO this! English is like a runtime typed language, and Japanese sounds like a statically typed language. reply jcranmer 16 hours agorootparentprev> There's no tense, no verb ending, no conjugation, zero of any of that stuff in Chinese...the difference is night and day. There is barely any grammar to learn. I finished the Chinese grammar in less than a week lol What you're saying is that Chinese is not inflectional. It's a pretty common trope that people equate grammar with verb inflection. But Chinese does have grammar, it's just in the things that aren't as in-your-face as verb inflection is. Chinese has numerical classifiers, which don't have a clear corresponding feature in Indo-European languages (the closest I can think is the... I forget the term, but those silly terms like \"pride of lions\" or \"murder of crows\" which are more erudite wankfests than proper English grammar). There may be other features, but I don't know Chinese well enough to highlight them. The things is that if you're learning an Indo-European language (and you already know on), you can largely import your native language's grammar and expect things to work. Take, e.g., the superlative construction: in English, it's \"most\" + adjective; in French, it's \"le plus\" + adjective. Word-for-word translation (including tense/aspect/mood as word-for-word, when you'd use past perfect in English is pretty damn the same time you'd use it in other languages) gets you pretty close to correct, you just have to fix up some word order issues, and some agreement issues, and you're done, so grammar instruction largely focuses on teaching those elements of grammar. It can actually be somewhat jarring when you hit upon a situation where the grammar isn't in close alignment: e.g., in English, we would say \"it has been several days since I've seen you\" whereas in French, it would be (doing tense-for-tense translation) \"it is several days since I've seen you\". The focus in grammar instruction on the elements that are different from your native language rather than the ones that are the same can lead you into a false sense of what grammar is. reply Kronopath 10 hours agorootparentA better comparison for numerical classifiers would be uncountable nouns. In English, you don’t say “give me three waters”, you say “give me three glasses of water” or “three bottles of water”. You can think of the classifier words as being that, but for everything: 三杯水 three glasses of water 十头牛 ten heads of cattle 两支铅笔 two rods of pencil 一条路 a strip of road 六只猫 six animal-units of cat 五个人 five “gè” (generic units) of people reply dllthomas 16 hours agorootparentprev> I forget the term, but those silly terms like \"pride of lions\" or \"murder of crows\" Collective nouns. reply jcranmer 16 hours agorootparentActually, from the Wikipedia article, it's specifically the \"terms of venery\" reply tptacek 8 hours agorootparentSpeaking of erudite wankfests! :) reply eloisant 16 hours agorootparentprevComing from French I don't consider there is any conjugation in Japanese. The verb is the same no matter what the subject is - I, you, he/she, we, plural you, they... So in French you can multiply by 6 the number of verb ending. In Japanese you never have to care about gender and plural. Same with German, where you have declinaisons on the articles depending on their grammatical position in the sentence (den/der/dem/etc.) So maybe Chinese is even simpler than Japanese, but I would still rank Japanese as a language having a \"simple\" grammar. reply lIl-IIIl 13 hours agorootparentThere's conjugation but it's on different axes. One unusual feature is that Japanese verbs conjugate on politeness/formality. There's also te- forms, past forms, imperative, \"I can verb\" form, \"I want verb\" form, \"I must verb\" form, causative, etc, etc. The low number of irregular verbs is a blessing though. reply airstrike 13 hours agorootparentprevPortuguese has something like 50 different verb endings, Wikipedia tells me https://en.wikipedia.org/wiki/Portuguese_conjugation In reality few people use half of these, I would think My favorite bit is that \"to be\" is two different verbs entirely in Portuguese, \"ser\" and \"estar\". Both Italian and Spanish also have this distinction, but in my (admittedly limited) experience with those languages, neither really makes the distinction as clear as it is in Portuguese reply trocado 10 hours agorootparentActually most if not all of those verb endings are used colloquially (the most important exception would be the second person plural, which is only used in some regions of Portugal). reply airstrike 9 hours agorootparent2nd person singular is also never really used correctly, and even 1st person plural is sometimes replaced by 3rd person singular e.g. \"a gente vai\" instead of \"nós vamos\" reply arrowsmith 12 hours agorootparentprevI don't know about Italian but the ser/estar distinction works in pretty much exactly the same way in both Spanish and Portuguese. I can't think of any difference between how Spanish and Portuguese treat those two verbs. reply airstrike 12 hours agorootparentYou're right, I stand corrected. I guess I've been hearing too much Italian lately reply gtranger 13 hours agorootparentprevI’m extremely skeptical of your claims that you learned Chinese grammar in a week as a Chinese learner myself and I’m willing to bet you don’t realize how much you don’t know. The Chinese grammar wiki has 505 articles on grammar split across A1-C1 levels of the European Common Framework for language proficiency. This wiki is also non-exhaustive. This isn’t even including the fact that Classical Chinese, which is a basis for many 成语 used today, has a completely different grammar than modern Chinese. reply hnfong 3 hours agorootparentIt might not be technically correct that they learned the full set of Chinese grammar in a week, but I can imagine one week is sufficient for a beginner to get the basics and start reading/speaking/writing the language and absorb the other nuances or nitty-gritty details through everyday usage. I mean, I'm pretty much a Chinese/Cantonese native user, so I can't be sure about that since I never \"learned\" the language in a classroom setting, but my impression is that this short period of learning grammar for Chinese language leaners is quite typical. reply thaumasiotes 6 hours agorootparentprev> There's no tense, no verb ending, no conjugation, zero of any of that stuff in Chinese... This is plainly untrue. Speaking for Mandarin: 1. It's necessary to track tense in negative-polarity sentences because past-tense verbs are negated differently from present-tense ones. Technically this is accomplished by using an auxiliary verb, though in many cases that verb doesn't actually appear in the sentence where you're using it. 2. There are three aspectual verb endings, 了 (perfect), 着 (continuous), and 过 (experiential). 3. Verbs are inflected for possibility and impossibility, so that 动 is \"move\" and 动不了 is \"cannot move\". > I finished the Chinese grammar in less than a week lol Right. reply johngossman 12 hours agorootparentprevI haven't found Japanese grammar to be particularly complex either...at least compared to English or French. It is different. The 80/20 Japanese Book was a great help, as was \"English Grammar for Students of Japanese\" (the title is confusing, but it really is for learning Japanese, not English). You can get a sample of 80/20 here: https://8020japanese.com/japanese-sentence-structure/ Pronunciation also isn't that hard (Kanto dialect, at least) compared to, say, French. The writing system is definitely the hardest part for me. reply brigandish 4 hours agorootparentprev> I got to fluency in Japanese in roughly 6 months to 1 year while living there Your experience is not the norm, not according to research and not according to most people who've tried learning Japanese. Either you have a talent or you had a more effective method for learning, but it does undermine your judgement as something generalisable to others. Let's hope it's the method and you share it. reply hoseja 2 hours agorootparentprevI love when watching things in Japanese you can tell they are talking in hyperpolite register because all the words are suddenly dozen-syllable tongue twisters. reply emodendroket 12 hours agoparentprevI don't think Japanese is really any more grammatically complicated than any other language (the writing system is a different story but if you're comfortable with Chinese you already have an appropriate degree of Stockholm Syndrome on that front anyway). Different languages just move the complexity around to different places rather than getting rid of it. For instance, Japanese has only 3 irregular verbs in the entire language. Singular and plural need not be marked. Verb and adjective agreement aren't issues. And so on. reply bloppe 15 hours agoparentprevI don't speak either, but would posit that the status of Chinese as an East Asian Lingua Franca caused it to trend toward simplicity, whereas Japanese insularity (physical, cultural, and political, especially during the Edo period) provided far less incentive to simplify. I'm sure that's an over-simplified explanation. reply hnfong 3 hours agorootparentI don't think there's any trend of written Chinese toward simplicity. Broadly speaking it has evolved towards \"complexity\" over its history. If you looked up the texts in the most ancient Chinese (oracle bones, bronze inscriptions, etc.) they were basically characters stringed into very terse sentences with minimal grammar. IIRC typical \"sentences\" were like ~5-7 characters at most. They typically looked something like: \"King Attack Barbarian. Good Luck? Win.\" Then the classical texts (which had a status similar to Latin in East Asia) had sentences that were considerably more fully formed, but often still terse. Case in point: yesterday I was trying to understand a story about a man meditating in Zhuangzi, where it describes the sitting position as \"隱几而坐\" (the characters mean \"hide\", \"chair/desk\", \"and\", \"sit\"). So, was the person putting away the chair, then sitting (on the floor)? Or hiding behind the chair? Or possibly even hiding the chair with his clothes by sitting on it? Or was there a typographical error and another character was intended? I don't think anyone has a conclusive answer. Modern Chinese (Mandarin) generally does not have these vague sentence structures and is much more fully fleshed out than classical Chinese. The same idea expressed in Mandarin would typically be 2-3 times longer than it would be in classical Chinese. The Chinese language has evolved from extreme simplicity in ancient times to I guess moderate complexity today. Generally there was no simplification. reply nialv7 13 hours agoparentprevDoes Chinese really not have that much grammar though? I think it may have fewer _formalized_ grammar, but there are a lot of rules that are difficult to pin down. And if you don't follow them, your Chinese will sound wrong to native speakers, even though _technically_ the grammar is fine. For example, I only very recently learned (in Mandarin) characters' tones change when they form words. The number one (一) has 3 different tones in different contexts, what!? reply dotnet00 10 hours agoparentprevI'm not too far into learning to speak/read Japanese, but have gotten pretty good at understanding it when spoken from years of only really watching/listening to Japanese media (human pattern matching ability is crazy!). My feeling has been that similar to what others have said, that the popular learning resources seem to make the early grammar seem broader than it is by teaching each sentence 'type' as a separate rule. Although I haven't put enough thought into the exact differences (and thus might be entirely wrong), I've felt the grammar is fairly intuitive (I presume due in part to my background of also speaking fluent Hindi). reply giuscri 20 minutes agorootparentHow did you get exposed to Japanese media? You lived there? Or just anime? You used English subtitles or Japanese ones? reply ksdnjweusdnkl21 16 hours agoparentprev> I feel that even after 10 years I will barely reach conversational fluency in Japanese Interesting. I feel exact opposite with Mandarin. My progress learning Japanese was incredibly fast, I could speak decently in 6 months and read after 1 year. But I always lose motivation learning Mandarin because it's so hard. Maybe it's because my mother tongue is closely aligned with Japanese in pronounciation and grammar such as conjugation. reply rauljordan2020 16 hours agorootparentWhat's hard about Mandarin aside from memorizing the characters and pronunciations? reply gtranger 13 hours agorootparentThe fact that it is a well-documented language that has evolved over thousands of years with almost no external influence and is entrenched with thousands of years of cultural concepts that are distinctly unfamiliar to a majority of the western world. Many phrases used in Mandarin today date back millennia. Also something that many people don’t recognize is that a single character can embody many meanings depending on the context. It’s not as simple as memorizing the character because you have to know which meaning a character is representing within a particular context. reply jimbokun 14 hours agorootparentprevTones. reply richarme 16 hours agorootparentprevIs your mother tongue Finnish? I always found Japanese to have somewhat similar sounds. And as a bonus hint, you're missing a \"the\" in your first sentence ;) reply Lance_ET_Compte 10 hours agorootparentFrom their username, I'm guessing Polish... reply StefanBatory 54 minutes agorootparentw szczebrzeszynie chrząszcz brzmi w trzcinie... reply wk_end 16 hours agorootparentprevYeah, linguistic difficulty is almost always relative - I can learn French or Dutch much more effortlessly than a native Japanese speaker. A native Korean (I'm guessing?) speaker would definitely have a leg up when learning Japanese that they wouldn't have with Mandarin, and that a native English speaker doesn't have with either. reply z2 13 hours agorootparentThe way I think of this for some Asian languages is that Japanese and Korean are like English and Dutch, while Mandarin is like one of the Romance languages (e.g., Mandarin is to Cantonese as Spanish is to French). The three have an easier time learning any of the other two for different reasons of shared vocabulary or grammar depending on the direction. reply yongjik 14 hours agoparentprev\"Complicated\" is in the eye of the beholder. It looks daunting to someone who didn't grow up using a heavily inflected language, but also consider the reverse direction. \"A reading room\" means a room that is for reading. \"A reading person\" means a person who is reading. And \"Reading the room\" means, well, the act of reading the room. Or it could be used as an adverbial prose to modify the following phrase: \"Reading the room, I stopped right there.\" Or it could be part of a progressive: \"He was merely reading the room.\" Don't confuse it with \"What he did was merely reading the room,\" which must be parsed differently. All from a single form of a verb. You just have to figure out which one is intended from context. ...and the point is, it's just so natural to a native English speaker that they don't even stop and think about it! reply j7ake 13 hours agorootparentI disagree that complicated is subjective. Japanese is more difficult to learn than an English objectively. One way to ask this objectively is to ask, for every non-native speaker, which languages are easiest and which are hardest to learn? You can set this as a questionnaire and ask people to rank. You will find that Japanese is among the hardest to learn amongst nearly all cultures. reply filoleg 11 hours agorootparent> Japanese is more difficult to learn than an English objectively. I press “doubt” on the entire comment just due to this statement. There is no “objectively more difficult” for most of the major languages (but it exists), and especially not Japanese. It imo heavily depends on your first language. Ask any friends of yours who speak Korean as their first language. They will likely find Japanese language to be extremely easy compared to almost any other language. Almost all of them, even those who had zero prior knowledge of Japanese language, will be able to understand bits and pieces all the time. Russian was my first, but I can confirm that Japanese was signficantly easier than English for me in majority of the aspects, esp when it comes to basics needed to be somewhat functional in the language. Only two tenses (past and non-past), pronunciation makes perfect sense (if you know how to read a kanji character, you know how to pronounce it; cannot say anything even remotely similar about English at all), grammar overall doesn’t feel overly complicated, etc. However, from what I’ve observed, native English speakers seem to struggle with quite a few of those things, including pronunciation. Hell, I would say Ukrainian would be just as difficult for a native English speaker to learn as Russian would be. For any native Russian speaker though? A person who speaks only Ukrainian can have a conversation with someone who speaks only Russian, and both of them will be able to understand at least half of what the other person is saying (despite speaking to each other in different languages, without having any prior knowledge of each other’s language). All of this leads me to believe that there is no such thing as “objectively easier”, unless we know the person’s first/primary language. reply gtranger 13 hours agorootparentprevAnecdotally speaking, my spouse is from China and she thinks it was easier for her to learn Japanese than English despite learning English from a young age and not having any formal Japanese education until college by which point she was already fairly conversational in Japanese from having watched variety shows and anime. We met while I was studying Japanese at college so I have a pretty good idea of where her Japanese ability stands. Another anecdote, a Chinese friend of mine from college just passed the N1 with a perfect score. His Japanese education consists of a few classes in college, anime, and video games. He says although he thinks his English is more fluent due to him living in the States, Japanese was easier for him to learn. Point being? I think it’s subjective. reply brigandish 2 hours agorootparent> Another anecdote, a Chinese friend of mine from college just passed the N1 with a perfect score. The Japanese Language Proficiency Test does not include a speaking portion, which is the part of Japanese that Chinese people usually struggle with most - being kanji masters, the rest looks a breeze, lucky them! That tempers the point somewhat (somewhat). reply yongjik 12 hours agorootparentprevWhat you're proposing is not an objective measure, it's a popularity contest. And yes, in a lot of such surveys you'll find Chinese/Japanese/Korean sitting at the top of the list. Sometimes with Arabic. Maybe Japanese is a really hard language objectively, but these surveys aren't actually showing that. What they are showing is that the majority of organizations that are doing these kind of surveys are populated by speakers of western European languages, who find Japanese \"objectively\" much harder than Spanish. reply quartesixte 4 hours agorootparentThat list is the CIA/State Department evaluating the average time to fluency for English natives going through one of the foreign language training programs they run. Chinese, Korean, Japanese and Arabic sit on top of the list because they are the most isolated away from English. Koreans find Japanese extremely easy to learn. Vice versa. reply huytersd 8 hours agoparentprevMemorizing 3000 characters seems impossible. I know I would never be able to do it. reply StefanBatory 54 minutes agorootparentHow about memorizing 20 characters over 150 days, though? Or 10 over 300? ;) And there's a pattern to them too in the end. reply nonrandomstring 17 hours agoparentprev> Why does it have to be so complicated? I know nothing about Japanese, or Chinese. (Edit: actually that's not true, I learned this today [0]) Maybe a little about language in general from studying linguistics (for compilers), but I think the answer to your question is; Because it is able to express things that we can't in English. That is beautiful, necessary and precious. The fact that groups of people exist in the world who can have whole ideas and worldviews that we barely conceive or express at all, seems so valuable. [0] https://news.ycombinator.com/item?id=40119457 reply stickfigure 17 hours agorootparentI don't buy this at all. Maybe \"can't express as concisely\". reply bluepizza 17 hours agorootparentExactly. Japanese _mostly_ doesn't have plurals in the English sense (it actually does have a few plural words), but you do use counters to specify quantities, which is just another way to express plurality. I understand some folks might find the Japanese exotic ways gripping, but I find the realities of the language much more interesting. I find the thought \"there are many ways to express plurality\" much more fascinating than \"wow, these people can build very reliable cars without expressing if a car has a wheel or many wheels.\" reply geraldwhen 11 hours agorootparent車は車輪がよぅつあります。 Car has 4 wheels. You can say many, few, a number, etc so the lack of plurality is overstated I suspect. You can use context to derive the plurality when none is given. reply ropejumper 17 hours agorootparentprevMy favorite simple example of this is exclusive \"we\". It's not a thing in most languages, but it allows a level of passive aggressiveness that you can't achieve without it. Saying \"we're going without you\" isn't nearly as impactful as \"_we_ are going\", using a hypothetical exclusive we. As another example, Romanian has a relatively unique \"presumptive\" verb mood, which has a certain connotation that's hard to achieve without it. It can show curiosity and resignment at the same time (besides other things.) The conciseness is the whole point. Using words to explicitly describe things can ruin the effect. reply eszed 12 hours agorootparentI'd push back on that, because you do get that passive-voice exclusive \"we\" in English, just as concisely - except it's expressed through stress pattern (as you indicate with your underlines), not vocabulary / grammar. I think that's exciting, because it gives English (as written) a lot of poetic ambiguity and (as spoken) a lot of performative - if you will - flexibility. reply ropejumper 3 hours agorootparentFair point! I think it's just a different way of expression, and both are valuable in their own way. reply nonrandomstring 14 hours agorootparentprevWhy not \"unable to express at all\"? Maybe you prefer the \"languages are like Turing complete\" argument? You've heard of Russell's paradox and Godel's incompleteness, I am sure. Wouldn't a concept that escaped our capacity, be by definition unthinkable? Someone literally can't think of an example. So maybe we should approach it a different way - is there any possibility for the \"existence\" of a concept that could not be successfully communicated at all, say between a human adult and a 5 year old child, or the the adult and an advanced alien being? If concepts exist only in the mind, that are more than literal depictions of physical reality, surely here must be conceits thinkable in some systems but not in others. (I am probably just replaying Douglas Hofstadter here) The alternative is that every language is kinda \"complete\" and I could spend three hours trying to explain what a Alpha-Centurion has one word for. Edit: sorry our discussion is getting down-voted for bizarre reasons. Is there a kind of racist/anti-pluralist thing here on HN? reply hnfong 3 hours agorootparentRussell's paradox speaks of logical contradictions. Language is full of logical contradictions, but it's fine to us (not to logicians though). Similarly Gödel speaks of consistent proofs in logical systems. His incompleteness theorem talks about either a system has statements it cannot prove (but they can expressed!), or is inconsistent. Since natural language is probably not that consistent, the whole issue is moot. It should be possible to show under some loose conditions that all natural languages are \"Turing complete\". Even the halting problem does not impose a problem -- we're really not interested in telling whether long-running computation halts in natural language. The expressivity is guaranteed by not insisting on strict consistency in language. (PS: the situation changes where there is a mandate to only speak things that are \"correct\", for example, censorship. Now you get into the realm where something might be technically \"correct\" but the decision algorithm is imperfect and does not allow you to speak that truth) > is there any possibility for the \"existence\" of a concept that could not be successfully communicated at all, say between a human adult and a 5 year old child, or the the adult and an advanced alien being? I don't think so as long as the concept is constructed from physical objects or shared emotions/feelings. There is a problem with something that can only be subjectively felt though. Let's say some alien can see the X-ray spectrum. How does the alien communicate to humans what the colors look and feel like? But this is kinda off-topic. reply nonrandomstring 1 hour agorootparent> There is a problem with something that can only be subjectively felt though. Let's say some alien can see the X-ray spectrum. How does the alien communicate to humans what the colors look and feel like? This is the kind of thing I'm thinking of, it's an old philosophical chestnut in epistemology. Godel and Russell are relevant because we can always look for meaningful statements that can be well formed under wone system but not under another. > But this is kinda off-topic. I had theory about that. It's so _on topic_ to be discussing the nature of language itself in a time when the biggest festival in town is \"Large Language Models\". Nobody so violently attacks a comment unless it hits a nerve, And I don't want to believe that my fellow HN commenters are simple racists. I think some people worry about basing the computing work on something as precarious and pluralistic as language. And they'd be right to. reply drdeca 13 hours agorootparentprevThe issue I see with the \"can't express at all\" view, is that, if it can't be expressed, then how do newborns learn to speak the language? If from some sequence of sense perceptions, a child can learn to associate some word(s) with some concept, why couldn't one describe that sequence of sense perceptions in another language, and have the listener, by imagining those sense perceptions, grasp the concept? Now, I don't want to be absolutist about that. Maybe some concepts get attached to some words through ways other than what sense perceptions pick out, somehow? Like, maybe when discussing theology or whatever, God intervenes and influences what meanings people learn for different words? (like, in a way that can't exactly be formalized and expressed in terms of math, sense perceptions, and any ideas that might be built-in to the human mind which one might intuitively associated with some combination of the previous two?) But, outside of things like that, I would expect that meanings for words that are shared among an identifiable collection of people, can be explained in any of the most common natural languages. (Though, maybe not so much for the meanings or aspects of meanings that are specific to one person.) Unless there is some mechanism by which a meaning could be communicated from one person to another child-person, which can't be replicated with another language. Now, that's all just for concepts between humans. For the Alpha-Centurion, perhaps they could have some innate ideas which they could learn words for, but which we would not learn to associate the idea with the word if we were given analogous sense perceptions, because we don't have those ideas built in to us? This also doesn't seem likely to me, but I seem to have less argument against it than I do for the same thing for the analogous thing between different human languages. We should still be able to describe the statistics of how they use certain words together though, and how this correlates to the world, or at least, the world as described through those concepts that we can comprehend. And, perhaps we could also describe the statistics of what words they would use to describe the ways in which our description of how they use the words (including correlation with aspects of the world that we comprehend), falls short of the true meaning of the words. There's an idea of \"semantic primes\", supposedly semantically irreducible concepts, that can't be defined except in terms of words that would be defined in terms of these (though, one might ask, \"couldn't one pick some other collection of concepts as the base case instead?\" and idk what the counterargument is), and which supposedly every natural human language has a word for each of these (though the word might not only mean one of these semantic primes/primitives, possibly having other meanings as well). The idea goes that every word in any natural human language can ultimately be expressed in terms of these primitive concepts (of which there are supposedly like 65). If this is true, then no idea in any natural human language would be entirely untranslatable to any other human natural language. But, it does raise of course raise the question, \"what if there was something else beyond these 65 or so, that we (humans) lack the concept of?\" (which is I think similar to the question you were raising) reply eloisant 17 hours agorootparentprevThis is true for every language, you can never perfectly translate a text. Something is always lost. reply brabel 16 hours agorootparentI've studied translation and what was fascinating to me was all the terminology that a language uses that's totally linked to the culture in which it's used. For example, in Brazilian Portuguese, someone may say something like \"show de bola\" (literal translation: \"ball show\" using the borrow English word \"show\" for something like \"great performance\") even in seemingly completely unrelated context, like when you do well on your math homework :D. Because football parlance is ingrained so deep into the collective mind of the population that you can \"transfer\" what would normally describe a fantastic play by a football team to pretty much any other context you like. I know Americans have a similar relationship with baseball-specific words, right (not a native speaker so I won't try to give examples)? That's one of the biggest difficulties when trying to translate... how would you translate that to English? You may need to use a similarly local \"slang\", which requires you to know where the target audience is from exactly (USA - East / West coast?? -, UK - London, Manchester? -, Australia??) to do it justice... and even the ideal translation may need to even consider recent (and not so recent) events and local customs/sensitivities (an obvious example is words to describe races in the USA) and pop references. reply olddustytrail 14 hours agorootparent> know Americans have a similar relationship with baseball-specific words, right I'm not American either but a fairly obvious example is to \"knock it out of the park\". reply arrowsmith 12 hours agorootparentIn British English you can be \"knocked for six\", meaning you're stunned or shocked. It originates from cricket, where you score six points by knocking the ball out of the park. reply brabel 13 hours agorootparentprevI was thinking \"in the ballpark\" and \"touch base\" as well... reply rauljordan2020 16 hours agorootparentprevMy point is that it doesn't need to be. Chinese is concise, simple, single pronunciation per character, very little grammar. It has no need for verb conjugations, tense markers, 3 different writing systems super-imposed into one like Japanese does, and can still express highly sophisticated thoughts and meaning that English cannot reply kingkawn 17 hours agoparentprevGuess they weren’t thinking of you when they made it reply minmax2020 1 hour agoprevI'm a Korean currently learning Japanese, and while I do understand that this mash of Chinese characters and kana writing system can be appreciated for its exoticness, as a learner I can't help but feel it's more of a hassle resulting from it being a not yet fully optimized writing system. (I mean, do we really need both hiragana and katakana?) I'm definitely not claiming that Korean is a more \"optimized\" language overall, but at least when it comes to the writing system, we had exactly the same problem as the Japanese (if you look at Korean newspapers just a few decades ago they are littered with Chinese characters), and at some point we fully ditched Chinese characters and have no problem going on with our lives. In fact, it made our lives easier in many cases, especially in keyboard typing. As a side note, we obviously have some side effects from switching to entirely phonetic alphabet system. For example, the words \"tea\" and \"car\" have the same pronunciation (차=cha) and so they are indistinguishable in writing, but it wasn't the case when Chinese characters were used (茶/車). I'm not sure how this side effect propagates into some sort of sociolinguistic phenomenon, but at least for average people it doesn't seem to have much significance. reply StefanBatory 56 minutes agoparentI began studying Korean recently for fun because of video games influence (I'm huge Project Moon fan and then I got into Korean literature). When I saw things like ㄱ for k/g or ㅏ for i I was in awe, like that's is so damn clever. reply bluquark 13 hours agoprevOne interesting thing about gikun is the widely different forms it can take according to the stylistic purposes of the text. - Most of the time it's simply a pragmatic way to introduce a clarification without breaking the flow of the text, essentially a more concise form of parenthetical or footnote. - In classical poetry it is used for a variety of effects, for example novel synecdoches. One side of the gikun might refer to a season, and the other side might refer to a key detail the poet idiosyncratically associates with that season. - But the contemporary Japanese learner usually notices them the most in fantasy/sci-fi manga and novels. In this genre it's used to introduce in-universe jargon while showing its meaning in parallel. At the extreme, it can allow writers to go over-the-top with how much special jargon the universe includes, without slowing down the pace of storytelling. (This can pose quite a challenge for translators!) reply RyEgswuCsn 13 hours agoprev> Japanese has a lot of compound words of Chinese origin, where two or more kanji appear as a set. In the original Chinese language, a \"word\" mostly consists of a single character. Interestingly, many of the compound words commonly seen in modern Chinese were in fact coined by the Japanese scholars during their attempts to translate western writings around the 19th century and were later \"imported\" back into Chinese language. Interestingly, the two examples in the article, \"art\" (美术) and \"science\" (科学) are both of Japanese origin, though one can still tell whoever coined the terms chose the individual characters due to their meaning being relevant to the concepts the words are describing. reply bluquark 12 hours agoparentAccording to this paper https://www.lingref.com/cpp/decemb/5/paper1617.pdf the natural linguistic evolution towards compounds in Chinese was well under way by the time of Middle Chinese (~800CE). And most of the cultural exchange with Japan happened after that. reply smallnamespace 5 hours agorootparentThat’s true, but many Japanese terms for describing the modern world were mass-imported into Chinese during the late Qing and Republican eras (think 1900-1930). The Chinese republicans looked towards Japan as a model for how to develop, and part of that was importing new lexicon wholesale, since Japanese scolars had already helpfully transliterated Western concepts into new compounds during the Meiji era. reply ThinkingGuy 12 hours agoprevFor an alternative viewpoint on the supposed “vagueness” of Japanese, I would recommend “Gone Fishin: New Angles on Perennial Problems,” by Jay Rubin, from the Power Japanese series. https://openlibrary.org/works/OL5609329W/Gone_Fishin%27 reply tkgally 10 hours agoparentI recommend that book, too. (I translated and wrote several books in the same series and knew the editor.) Claims that Japanese is inherently vague are often made by people who either don't understand the language fully yet, are frustrated at trying to translate expressions that have precise meanings in Japanese but no equivalents in another language, or are focusing on literary or creative language, which, yes, can be ambiguous and allusive. When necessary, Japanese can be as clear and precise as any other language. The design, manufacture, and operation of the Shinkansen, for example, have been implemented through millions of documents and conversations that were nearly all in Japanese. In sixty years of operation, the train system has never had a major accident. That would not be possible if the language were inherently vague. reply emodendroket 12 hours agoparentprevQuick, amusing read and well worth the time. reply huhtenberg 17 hours agoprevRe: Anomaly 6 - Providing two versions of the same sentence bit is not that uncommon in non-Japanese literature as well. For example, War and Peace in its original (Russian) language is sprinkled with French words and phrases, all duly translated via footnotes. This might not be as user-friendly as gikun as it requires glancing down and up the page a lot, but the idea is the same. Even in spoken language mixing in foreign words often helps conveying nuances of what's being said. Some words don't exist in some languages or require longer phrasing or don't mean exactly that, etc. This sort of thing a very common in multi-lingual families. So that \"Anomaly 6\" is not that much of an anomaly if you think about it. PS. It was a good read regardless. reply ogurechny 15 hours agoparent“War and Peace” has more complex history. First revision had nobles speaking French when suitable, because “everyone” could still speak some French in Tolstoy's times (just like people in IT all across the world link to original English documentation every day without even thinking about it). Then it was found that “everyone” meant “well-educated nobles like Tolstoy”. For second revision, Tolstoy rewrote all French utterances into Russian (and moved most of philosophical sections to dedicated postscripts). Then it was reverted to original form (with later corrections), but with translations of French text in footnotes. Second revision was printed in “cheap” editions, third revision was used in higher quality ones. Later Soviet prints follow Collected Works version based on French-enabled revision (and thorough comparison of printed editions and manuscripts). Depending on the age of your translation and its source, you may find any of those. Some translators also chose to translate French instead of using footnotes. reply qweqwe14 12 hours agoparentprevThere's an interesting piece of trivia regarding the title \"War and Peace\". The title in Russian is \"Война и Мир\", where \"Мир\" can mean both \"peace\" and \"world\", depending on context. However, there's some debate regarding which meaning was intended by Tolstoy. I couldn't find anything about this on English wikipedia, but here's a rough translation from the Russian page: Before the 1917-1918 language reform, \"peace\" was written as \"миръ\", and \"world\" as \"мiръ\". There's a legend which claims that Tolstoy initially intended to use the \"world\" meaning. Indeed, the second part of the epilogue has some thoughts about why the wars happen and how they affect the world as a whole. Despite this, every edition of the novel published during Tolstoy's life was titled as \"Война и миръ\" (= peace), and the French version of the title as written by Tolstoy was \"La guerre et la paix\". There are different explanations of this legend. (explanations follow, can't be bothered to translate) https://ru.m.wikipedia.org/wiki/%D0%92%D0%BE%D0%B9%D0%BD%D0%... reply basscomm 16 hours agoparentprev>Even in spoken language mixing in foreign words often helps conveying nuances of what's being said. Some words don't exist in some languages or require longer phrasing or don't mean exactly that, etc. This sort of thing a very common in multi-lingual families. So, in other words, adding in foreign words can add some je ne sais quoi reply senkora 16 hours agoparentprev> For example, War and Peace in its original (Russian) language is sprinkled with French words and phrases, all duly translated via footnotes Amusingly, my English edition kept the French and didn't have footnotes. I read it as a kid and had no hope of understanding the French so I just skipped over it whenever it came up. reply achr 6 hours agoprevAnother interesting \"anomaly\" is that the same concept can be expressed both with 漢語 (kango: Chinese-origin vocabulary) and 和語 (wago: Japanese-origin vocabulary). Kango is mostly nouns but one can easily add する (to do) and turn a noun into a verb. So, for example, if one wants to say \"to compare\" there's both kango version: 比較する (hikaku suru) and wago version: 比べる (kuraberu). Usually kango sounds a little bit more formal and used in writing more often but plenty of them are also used in casual contexts. However, even though they often share a common character, the reading is different (onyomi for kango and kunyomi for wago). Non-native speakers need to basically learn both versions separately and one cannot easily deduce one from another (which is the case for example in English: comparison - to compare; or Polish: porównanie - porównać). reply hbn 13 hours agoprevI get hung up when people say there are terms that are \"untranslatable\". What does that mean? Is it just a series of sounds that people use in a certain context to convey a certain meaning, but the greater phrase can't be broken down into individual words, tokens, or concepts? Do we have anything like that in English? reply resolutebat 12 hours agoparentEverything is translatable, but some concepts are difficult to convey in a compact way in other languages, and Japanese has a ton of set phrases for situations that don't really have obvious counterparts in other languages. As an example, the author mentions otsukaresama, which is the set phrase to use if you've been driving for a long time with guests and have reached your destination (and many, many other situations). But having the driver thank their guests for their patience is basically not a thing in English, so how do you translate that? The literal translation, \"honorable tired lord\" (~ thank you for your effort/patience), is completely incomprehensible. reply hbn 11 hours agorootparentI think that explanation proves perfectly that it can be translated. Depending on the context, you'd want either explanation. If you're learning Japanese you'd probably want the explanation of how and when it's used, and the literal words that compose it. But if you were translating a manga book and it used that phrase, you would probably just put \"Ahh, we're finally here!\" I think there's just something of a bastardized use of the word \"untranslatable\". As long as a language can convey abstract concepts, you should be able to translate anything into it. reply resolutebat 6 hours agorootparentI think we actually agree here: it's not \"untranslatable\", it just does not translate easily or well. But regarding translating it as \"we're finally here\", that's not what it means: it's not an expression of satisfaction, it's acknowledging that to others that it's been a long trip for them. reply bigstrat2003 11 hours agorootparentprevI think when people say \"untranslatable\", there's an implied \"without breaking the flow or losing nuance\" there. Of course you can in principle translate anything into any language, it's sometimes impossible to translate something without either a lengthy digression, or giving up on translating the full nuance. Poetry is notoriously hard to translate because of stuff like that. I don't know that I would say this is a bastardization of the word, but I see where you're coming from. reply jwells89 10 hours agoparentprevI think in cases like this, “untranslatable” is really shorthand for, “cannot be translated without loss of information and/precision”. Of course words can be massaged to produce a similar meaning, but conveyance of the entirety of the original meaning can be somewhere between difficult and impossible, particularly when one must be succinct and cannot use sprawling sentences to dial in the message. This is also why at its best, translation is a skill and an art. The same text can have significantly differing impacts readers depending on who’s translating. reply compiler-devel 13 hours agoparentprevWriters use “untranslatable” as a device to evoke a vague mysticism surrounding a language. IMHO it lends a flavor of superiority over the reader which I find gauche. reply tsukikage 11 hours agorootparentPhrases have properties other than their literal meaning. These can be both important to an author's intent, and hard to get across; in the same way that when someone fails to get a joke, you can likely explain it to their satisfaction but it's much harder to get them to actually find it funny - the punchiness and associations are part of what makes one laugh, and these become lost during extended explanation. You can explain the meaning of a text, sure, and for technical texts that may be all you need, but if the goal is not simply the transfer of dry information and the result fails to trigger the intended associations and emotions, your job as a translator is not yet done. reply autoexec 8 hours agorootparent> Phrases have properties other than their literal meaning. These can be both important to an author's intent, and hard to get across; Personally I prefer footnotes in those situations. I'd rather have a few sentences that explain the nuance an author was trying to convey with their word choice that a native speaker would have picked up on rather than have a phrase thrown out entirely and replaced with some alternative localization that might be familiar in an effort to try to capture the same \"feel\" but barely comes close to what was actually said (if you're lucky). reply vunderba 10 hours agorootparentprevHundred percent. Language is nothing more than a \"conveyance vehicle\" to encode the physical phenomenon around us and our experiences of it. Unless you're a believer in some kind of parallel to the largely outmoded Waldorf hypothesis, nature is nature regardless of who is experiencing it. To declare something \"untranslatable\" is essentially to imply that a non-native speaker is incapable of understanding it no matter how much they study the language. It deals in \"touchy feely unquantifiable nonsense\". Noticed that everyone in here who proclaims that some things are untranslatable have yet to provide actual concrete examples of them (SRC LANG, TGT LANG, SRC SENTENCE) The fact that you can have legal documents translated from one language to another is all the proof you need that if you're a good enough translator, all languages are interchangeable. You might need a whole lot more words or a whole lot less words depending on the source and target language though. reply TillE 8 hours agorootparent> actual concrete examples Here's an easy one: nearly any pun is literally impossible to translate while still being a pun. You can explain the pun by talking about the original language, but it can't be adequately translated. reply anigbrowl 10 hours agorootparentprevYou and your hoity-toity French words :) I get your irritation but I think it's also a way of signaling to the reader that the difficult word is heavily freighted with meaning that would be blindingly obvious to a native/fluent speaker but require a small essay to convey in English (and still wouldn't have the emotional impact) - linguistic operator overloading, if you will. reply jasonjei 11 hours agoparentprevI think what the writer means to say is there is a cultural aspect to language for words that don’t have direct equivalents in other languages. Interestingly, Chinese colloquially refers to languages as the same as culture. For example, Chinese is 中文, literally Chinese culture; English 英文, English culture; Japanese 日文, Japanese culture. The suffix 文 signifies culture. There is also the word 語 and 語言 to signify language; this is more formal but without the connotation of culture. But my point is culture is indelibly tied to language. reply hnfong 2 hours agorootparentI hesitate to nitpick on you given your surname, but I haven't seen 中文 (or any other _文) referring to culture specifically, as opposed to language. My understanding is that 文 (in this context) refers to the written language, whereas 語 and 語言 refers to the spoken language. Which is why we say 寫中文 instead of 寫中語. 語 and 文 often gets mixed up, but the nitty-picky-correct way should be what I described. FWIW here in Hong Kong we have a term \"兩文三語\" which means two written (Chinese and English) and three spoken languages (Cantonese, Mandarin and English). reply glandium 10 hours agorootparentprev> The suffix 文 signifies culture. 文 has a broad meaning. Here it would be https://en.wiktionary.org/wiki/%E6%96%87#Pronunciation_1 8. (written) language. (as opposed to spoken language, which is what 語 is) reply stevenwoo 12 hours agoparentprevI was reading the making of at the end of Roadside Picnic and the authors wrote there was no word stalker in the Russian language until they wrote their book and introduced the concept and word to Russian language. Maybe more properly a neologism. reply Swizec 13 hours agoparentprev> Do we have anything like that in English? \"You are shit\" vs \"You are the shit\". Explaining \"the shit\" to someone who's fluent in English but not culturally fluent in American is almost impossible. There's a qualitative difference between \"You are very good\" or \"You are the best\" and \"You are the shit\". They're not exactly synonyms. Another good example: Dude or Guy as used in Californian. reply hbn 13 hours agorootparentI wouldn't really say that's untranslatable though. I feel like you could pretty easily translate something like \"you are poop\" into any language and explain that in the English phrase, adding \"the\" is modern cultural slang that means it's \"the best\" instead. Or you skip all the context and just say it means \"you're great\", very easy translation. \"Eres el mejor\" - I just translated it into Spanish reply TillE 13 hours agorootparentEvery language is built on a mountain of cultural context and assumptions. That's the part which is impossible to translate. You can translate the words but you're missing layers upon layers of subtle meaning. reply hbn 12 hours agorootparentPerhaps I'm just taking the word \"untranslatable\" more literally than some, but I think if you can explain the surrounding cultural context, you've translated it. Different scenarios require different methods of translation, sometimes you'll want something literal, and sometimes you can just translate the intent behind the words. As long as you can do that, I would consider it \"translatable\". reply Swizec 13 hours agorootparentprevI don't speak Spanish so can't judge your translation, but I know that \"you're great\" and \"you're the shit\" feel different. The simplification drops a lot of implicit information and social signaling. It's that emotional and cultural baggage layered on top of words that's hard to translate. So for example in USA you can call someone \"a benedict arnold\". As an immigrant this means nothing to me. People tell me it means \"bad\". I understand the words, but there's no impact behind them because I lack the cultural background. reply vunderba 10 hours agorootparentThat's not a lack of cultural background, that's merely a lack of knowledge around who Benedict Arnold was, and apparently somebody doing you a disservice by explaining that it's a synonym for bad. If somebody had first explained to you that Benedict Arnold was a well known traitor during the revolutionary war you'd have nearly the same context as your average American. It's hardly what I would call untranslatable. I'm sure you could find some poor sod who the public education system failed so terribly that Benedict Arnold is as equally opaque in America. reply samus 16 hours agoprevIt's admittedly less common, but also in Chinese lots of characters have multiple pronunciations. Sometimes they are associated with different meanings. Even if the other pronunciation is just considered formal or poetic, it can carry a different shade of meaning. reply Symmetry 15 hours agoprevNice article, but if I were writing it[1] I'd list having subjects, topics, and objects as first class nouns in sentences rather than just subjects and objects of sentences as a big fascinating difference from what I was used to[2]. And also the role of timing[3] in pronunciation with cases like Yuki being a common girl's name meaning \"snow\" and Yuuki being a less common boy's name meaning \"courage\" distinguished only by how long you hold the first vowel. [1] My Japanese is terrible and I couldn't come close to writing it, but lets leave that aside. [2] https://en.wikipedia.org/wiki/Topic_and_comment [3] https://en.wikipedia.org/wiki/Mora_(linguistics)#Japanese reply anigbrowl 8 hours agoprevBy the way, Japanese with Anime (cited in the article) is an absolutely great resource for digging into the fine details of language and language use, without the pomposity that often infects technical discussion coughStackExchangecough* https://www.japanesewithanime.com reply layman51 9 hours agoprevI really liked this article. I really love the examples given. The part about names and pronunciation, and the manga examples actually reminded me of a anime scene that appears confusing at first. In the scene, there’s a character that receives a business card from another and he ends up pronouncing his name incorrectly.[1] I guess it does seem weird that a written name can be mispronounced, but isn’t the same kind of phenomenon as when you have an artificial English word like “ghoti” which is meant to be pronounced as “fish”? [1]: https://www.youtube.com/watch?v=b4dysjr5-FE reply shiomiru 14 hours agoprevGood article, but misses one very interesting detail. E.g. in the example with 司る (tsukasadoru \"be in charge\"): the article says they \"gave\" the phrase a kanji. I would however assume that it happened the other way: the kanji was approximated with two Japanese words. What's the difference? Let's go back to when kanji was adopted. The article notes Japanese writers approximated sounds with Chinese kanji readings, but there's another overlooked part: they also approximated Chinese text with Japanese words. That is, traditionally they would often write in classical Chinese, but read it out loud in Japanese. Indeed, they developed a system[0] that let them retrofit an entire language, with a completely different sentence structure, phonetics, etc. into their own. Or, in short: they could read Chinese in Japanese. This is likely where 司る comes from; some classical text using 司 in a way that was at some point best approximated by the Japanese word tsukasadoru in that context. [0]: Example from https://en.m.wikipedia.org/wiki/Kanbun (abridged): > 楚人有(下)鬻(二)盾與(一)(レ)矛者(上) > [...] the word 有 'existed' marked with 下 'bottom' is shifted to the location marked by 上 'top'. Likewise, the word 鬻 'sell' marked with 二 'two' is shifted to the location marked by 一 'one'. The レ 'reverse' mark indicates that the order of the adjacent characters must be reversed. > Following these kanbun instructions step by step transforms the sentence so it has the typical Japanese subject–object–verb argument order. > Next, Japanese function words and conjugations can be added with okurigana, [...] > The completed kundoku translation reads as a well-formed Japanese sentence with kun'yomi: > 楚(そ)人に盾と矛とを鬻(ひさ)ぐ者有り Obviously, the system comes with limitations; it's more of a system to analyze classical Chinese text than a way to magically translate it into Japanese. Still, I find it the most fascinating part of the language, because you can view it as a sort of \"machine translation\" from a millennium before computers existed, simply by abusing the fact that they used the same sort-of-semantic alphabet. This is also where the \"many readings of a single word\" property of kanji comes from. Modern Japanese writing is the fusion of the phonetic and semantic interpretation of kanji - kana being the simplification of phonetic forms, and kanji's weird readings being derived from kanbun-kundoku. reply kybernetikos 12 hours agoparent> That is, traditionally they would often write in classical Chinese, but read it out loud in Japanese. I seem to remember something similar from the Tarzan novel. He learns to read in English, but his first spoken language is French, so his understanding of how to make the words into sounds is all wrong. reply danielscrubs 8 hours agoprevMost surprising for me is the humor part. Let a normal everyday Japanese person watch ANY of the greatest US comedians of all time (translated or not) and they just won’t find it funny. Now use the techniques in the article with ambiguous meanings and they will be rolling on the floor laughing. This works in the reverse too, westerners won’t find everyday Japanese comedians funny (it is pretty much untranslatable though). reply autoexec 7 hours agoparentI wonder how much grammar interferes with comedy. It seems like there would be certain jokes which would be ruined depending on how a sentence is structured. Revealing a surprising punchline before the set up for example. reply Aeolun 8 hours agoprevSome people think things are more fun if they are more complicated. The only thing I want to do is learn the damn language already, but study is just no substitute for actual usage with Japanese (like author says, since the pronounciation is often 10x simpler than figuring out all the different readings). reply jwrallie 10 hours agoprevOne interesting thing I observed is that many talk shows will have something akin to subtitles to things being said in order to bring the power of quickly getting the meaning from Kanji to the spoken language. Once you understand the meaning of some Kanji, turning on subtitles feels like a superpower on understanding what is going on even for people still learning the language. reply komali2 17 hours agoprevI learned both Japanese and Mandarin over the last 15 years and I gotta say, this was an interesting article, but I'm mildly disappointed. > In particular, a whole realm of consciousness exists in the sphere of Japanese speakers that's perhaps truly unique in the world, more so than the sushi and the nature and decorum. It even allows for new literary techniques that are unimaginable in any other language. I was expecting some kind of insight into the super complex multitude of ways to say something as simple as \"thank you\" in Japanese, complex not only today but also historically. The linguistics tie into socioeconomics, class, and history, in a really fascinating way. A highly educated person has, in my opinion, a far greater \"resolution\" with Japanese than with English, in terms of what they can convey with a simple \"thank you.\" Though I think English has the best \"resolution\" in most cases out of the three languages. It's extraordinarily difficult in Mandarin (especially if you aren't fluent and educated on top of that) to for example speak subtle differences such as \"how would you feel about helping John with the dishes tonight?\" vs \"can you help John with the dishes tonight?\" vs \"It would mean a lot to me if you could help John with the dishes tonight\" vs \"I think John would appreciate if you helped him with the dishes tonight\" vs \"I need you to help john with the dishes tonight.\" Especially in sales and marketing, I really want that kind of granular resolution in Mandarin. It's a little possible of course, but you'll simply lose your audience. 99.99% of the time Mandarin speakers will expect to hear \"tonight can you please help me with the dishes?\" The notes about combining kanji and root characters to construct larger complex characters e.g. cousins male/female is interesting, but really in the brain of a native reader it just doesn't work like that, you simply memorize the meaning and move on. It takes the same sort of education to learn latin roots and the attention to notice them in English, as it does in Japanese / Mandarin. reply spidersouris 12 hours agoparentSo does that mean Mandarin can be considered as more \"straight to the point\" and as not featuring a system of \"gradual politeness\" compared to other languages? Does that also mean that Mandarin speakers will express themselves more or less the same regardless of the social status of the person they're talking to? It's funny because I've had the opportunity to speak with a few Mandarin speakers, and sometimes when they were asking things in English, I felt something quite different. I wouldn't say that they were not polite, because that was not the case in their attitude, but the way they formulated their request was rather direct and as if the result of the request was a given. reply komali2 7 hours agorootparent> So does that mean Mandarin can be considered as more \"straight to the point\" and as not featuring a system of \"gradual politeness\" compared to other languages? It definitely feels more \"straight to the point\" to me than English, but I'm not the best person to ask. It definitely has some degrees of gradual politeness, not nearly as much as Japanese though. > Does that also mean that Mandarin speakers will express themselves more or less the same regardless of the social status of the person they're talking to? A little? There's definitely class consciousness, plus a whole slew of fun LARP words from the communist revolution, not that anybody uses that in Taiwan. Unsure about the PRC. But in any case people definitely talk to me differently when they find out I own a restaurant, which makes me a \"boss,\" which makes me apparently worthy of some new form of address, usually more serious and having less of what I call \"taiwan noises\" (there's a proper linguistic term, I don't know it) aka the \"aahs\" and \"oh's\" that end a sentence, and the tendency to leave one's mouth open after speaking. > I felt something quite different. I wouldn't say that they were not polite, because that was not the case in their attitude, but the way they formulated their request was rather direct and as if the result of the request was a given. This could just be ESL stuff. I probably sound like this in Mandarin. In fact I'm sure I do, I don't make Taiwan noises and I don't hedge so I probably sound quite abrupt and possibly even rude. I've asked and nobody's complained but I suspect it. reply 999900000999 15 hours agoprevWhat a great article. I've long since given up on trying to learn( Mandarin is slightly easier for me, while Korean is even harder) , but I'll always be fascinated by Japanese. reply kazinator 16 hours agoprevHere is a nut: 糾す (tadasu) ascertain; confirm; verify; make sure of 糾う (azanau) twist (something) reply sova 14 hours agoprevAs the creator of Japanese Complete I would like to mention on this article about Japanese that we're hard at work making a multiplayer version of our curriculum to add to the excitement of learning Japanese intuitively. I really appreciate discussions about the beauty of Japanese and its contextually-dependent vagueness, as it is a wholly new way of framing the world when the situation itself is a memetic moment of dynamism, where the ongoing vibrational nature of phenomena is highlighted constantly via active verb endings similar to how we use -\"ing\" in English. I must apologize (as would be custom in Japan) for the delay in offering our multiplayer version of our award-winning curriculum. I am looking forward to helping the world master Japanese, and get an insight into a new way of framing the world and our experience of it. reply anthk 16 hours agoprev>Mottainai Que aproveche/aprovéchalo from Spanish. (May you take advantage/do benefit from something). Aprovechar it's the literal opposite of desperdiciar, to waste. >Exotic subject-object-verb Not for a Basque. reply bitcurious 12 hours agoprevInteresting article. The history of the various scripts actually does have at least a limited parallel in the world - Ancient Egypt. >Although many people think of Egyptian hieroglyphs as logographic or pictographic, it actually combines symbols for entire words with symbols for individual sounds. That is, it is a system that is partly logographic and partly alphabetic. It can be called logophonetic. [0] This evolution continued for a while yet! The monumental hieroglyphs into a more easy to write cursive called \"hieratic\". The hieratic script further evolved into \"demotic\" - this was closer to a real alphabet, with directionality and ease of writing driving this change. The hieroglyphic roots are essentially lost at this point. Demotic then mixed with the greek alphabet by the Coptic community into the Coptic script! > Generally, Hieroglyphics were used for monumental inscriptions and decorative texts, and Hieratic was used for administrative texts which placed more importance in content than appearance, which were written by hand, and which needed to be written quickly. Demotic writing developed around 600 BC. It was derived from Hieratic writing, but developed into a highly cursive form so that the pictographic element of some symbols was lost. Although many single symbols were still used to write whole words or concepts, the symbol did not necessarily visually resemble the concept it represented. [1] Script comparison (see page 5): https://www.egyptologyforum.org/bbs/Stableford/Roberson,%20A... Hieratic: https://en.wikipedia.org/wiki/Hieratic Demotic: https://en.wikipedia.org/wiki/Demotic_(Egyptian) Coptic: https://en.wikipedia.org/wiki/Coptic_script [0] https://web.mnstate.edu/houtsli/tesl551/Writing/page4.htm#:~.... [1] https://scriptsource.org/cms/scripts/page.php?item_id=entry_... reply zilti 10 hours agoparent>Demotic then mixed with the greek alphabet by the Coptic community into the Coptic script! At that point, it already was a looong time since the greek alphabet evolved - via a few other cultures in between - from hieroglyphs, so it went back to egypt the long way around reply SuperNinKenDo 10 hours agoprevWonderful article. The author really nailed it. Reminded me why this stuff is so interesting, and reminded me to not be so frustrated with the difficulty it can pose sometimes. It really is one of the reasons I fell in love with written Japanese in the first place, and I should remember that. reply Jun8 17 hours agoprevInteresting and well-illustrated article. The claim that Japanese (or any other language) totally unique is a romantic one, showing the ignorance of the author with the very wide variety of languages and writing systems (the effect go writing system on language is not covered a lot in Linguistics, whose focus is the spoken language). For example, they mention furigana, characters that aid in reading Kanji characters (https://en.wikipedia.org/wiki/Furigana). There are many examples of similar use in the languages, one that I'm familiar with is the use of determinatives in Ancient Egypt (https://en.wikipedia.org/wiki/Determinative). Their use is similar to radicals in Mandarin, which is to provide additional semantic clarification. If you want phonetic clarification, examples are even more numerous, e.g. the use of shaddah in Arabic (https://en.wikipedia.org/wiki/Shaddah). The idea expressed in the \"Dissociation from Birth\" section sounds interesting until you learn that all alphabetic systems arose from a similar process, e.g. aleph was a drawing of an ox's head, etc. The part that I find really interesting about Japanese is it's well-developed system of honorifics (https://en.wikipedia.org/wiki/Honorific_speech_in_Japanese). reply fenomas 17 hours agoparent> they mention furigana, characters that aid in reading Kanji characters ... There are many examples of similar use TFA's main point about uniqueness with furigana was how it's occasionally used for out-of-band communication, like an author having a character say one thing while conveying to the reader that they mean something else. Do other languages have similar features? reply NoToP 16 hours agorootparentTones in non tonal languages do this, which can make tonal languages very difficult because instinctively you aren't used to tones being used for in-band communication. reply fenomas 15 hours agorootparentEvery language has various out-of-band features (gestures, etc). I was asking if any of them are similar to the (written) furigana usage described in TFA. reply Karrot_Kream 14 hours agorootparentprevAs others have said, this is common in Chinese writing. The unique thing about furigana is that it's typeset above/beside the kanji for the second meaning. Perhaps the more interesting thing is how even songs will often use kanji for a concept but the sung lyrics are expressed in furigana, but IIRC Chinese culture has this too. reply nicolas_t 13 hours agorootparentHow is that common in Chinese writing? I haven't seen anything similar to gikun in Chinese. Outside of graded readers, I've not seen the pronunciation written above a character and in the case of graded readers, it would always be the expected pronunciation not a different pronunciation that carries a different sense. That's something I agree with the writer as being unique. reply Kolya 7 hours agorootparentWriting the pronunciation above a character is normal when the character is rare or has an unexpected pronunciation. For example recently 龘 was often written with the pinyin above. Writing a different pronunciation with a different sense is also often seen on WeChat or in adverts. Often with a positive meaning in characters and a negative meaning in pinyin. reply inkyoto 48 minutes agorootparentprevIt is not common at all, but in Taiwan there is bopomofo, which is used the same way as furigana in Japanese – to indicate the pronunciation of Chinese characters. In fact, children in Taiwanese schools learn bopomofo first and only later proceed with learning the traditional Chinese characters. Bopomofo is not used outside Taiwan, though. reply brabel 17 hours agorootparentprevThat felt to me to play the same role as \"local footnotes\" (those footnotes that sometimes appear not at the end of the page, but at the end of a short section or paragraph)?! reply fenomas 16 hours agorootparentThe nuance is a bit different. With what TFA is talking about with furigana, the implication is that whoever is speaking has said one word but pronounced it like another. That doesn't really make sense in English but with JP and kanji having lots of readings it's kind of a normal way to think. So in some cases it's really no different from a footnote - e.g. in the JP version of Neuromancer there are bits where dialogue has the word for \"immerse\" with the furigana \"jack in\", and the effect is that the character has said the in-universe slang, and the base word is giving the reader a sense for what the slang means. But if a character says \"She's my friend\" and \"friend\" has the furigana for \"lover\", or vice-versa, the effect becomes very different. You can think of it as one word being in the speaker's mind and another coming out of their mouth, or maybe as the character saying one thing and the author telling us another. I'm not a native speaker, just fluent, but anyway that's how it works in my mind. reply wodenokoto 14 hours agorootparentprevI think they are completely different. I think the way the author calls it \"reading in stereo\" is a very good picture. It's not a footnote or a liner note that explains the meaning of a word. Those live outside the text. It _is_ the word and it lives within the text. It's the inherent meaning of the characters painted on to another word. reply kccqzy 16 hours agorootparentprevYeah the Chinese language simply uses parentheses for that purpose. The convention is that each Chinese character is placed into its own parenthesis unlike a regular parenthetical remark. For example, if the one thing being said is ABCD but the other meaning, most likely an ironic one, is WXYZ, the author simply writes A(W)B(X)C(Y)D(Z). Of course this requires the two to have the same number of characters, which is reasonably easy to do. reply thaumasiotes 15 hours agorootparentprev> Do other languages have similar features? No, that isn't a language feature. Japanese doesn't have that feature either. Note that a written text displaying this feature has no spoken equivalent. Other writing systems do have similar features; it's common in Chinese internet culture. reply dduugg 16 hours agoparentprev> \"Dissociation from Birth\" section sounds interesting until you learn that all alphabetic systems arose from a similar process, e.g. aleph was a drawing of an ox's head, etc. My understanding of Korean (Hangul) is that the alphabet design is based on the shape of mouth in articulation, sonics, category, etc. of the letters themselves: https://en.wikipedia.org/wiki/Hangul#Letter_design This is known generally as \"featural writing system\": https://en.wikipedia.org/wiki/Featural_writing_system reply yencabulator 15 hours agorootparentHangul is an exception to many similar \"historically true\" patterns mostly because it was created so late. Hangul is more a single person's well-educated effort, not something that emerged over time from various local customs. The castle I grew up near is easily 150+ years older than Hangul. reply PaulHoule 17 hours agoparentprevI definitely found Chinese was much easier to learn to read at a minimal level. Since the sounds per character are 1-1 and the semantics are very clean you can get a lot out of a text by looking characters up in the Unihan database. Words are usually composed out of the semantics of the characters and the grammar is pretty regular, more than some artificial languages. reply canjobear 16 hours agorootparent> Since the sounds per character are 1-1 and the semantics are very clean you can get a lot out of a text by looking characters up in the Unihan database. You probably got a lot of wrong meanings this way. The characters aren't 1-1 mapped to sounds and their semantics are profoundly context-dependent. reply kfk34k 16 hours agorootparentThe characters are mostly 1-1. There are a few exceptions, but usually one is a lot more typical than the other, so reading it with the typical reading won't usually get you in trouble reply canjobear 13 hours agorootparentThe multi-sound characters are common in usage. For example 长 can be cháng meaning \"long\" or zhǎng meaning \"to grow\". 行 is xíng \"to walk\" or háng with no real single coherent meaning, appearing in compounds like 银行 yínháng \"bank\" and 行业 hángyè \"profession\". All of these are very common usages. In context they are essentially never ambiguous, but if you are going through character-by-character it's not going to make sense. reply gtranger 16 hours agorootparentprevWhile not as egregious as Japanese where characters can have 15+ readings, the number of exceptions certainly are not few. Below is a link to the official table of words with multiple pronunciations in standard Mandarin. https://zh.m.wikisource.org/wiki/%E6%99%AE%E9%80%9A%E8%AF%9D... reply housel 14 hours agorootparentWhile I couldn't find any characters with more than three or four readings in this list, the Taiwan list (https://language.moe.gov.tw/files/people_files/%e5%88%9d%e7%...) has one character with five readings (著) and one with six (和). Still a long way from 15, though. reply Asraelite 15 hours agorootparentprev872 in that list. It would be interesting to see how many of those exceptions are actually common and relevant to everyday speech. But yeah, even taking that into account, Japanese is a trainwreck compared to Chinese. reply gtranger 14 hours agorootparentIt's worth noting that the aforementioned list is the unified pronunciation list that was published in 1985 by the Ministry of Education. The reason why you see some words only having a single (unified) reading in that list is due to the necessity of having to unify them in the first place, although there are still quite a few words with multiple readings. Keep in mind that there was no official language of China until 1932. Without going into detail about how pronunciations evolved with the change of dynasties and how China actually has 300+ spoken languages, the need for a unified pronunciation stems from the fact that many people in China, historically and even today, do not speak standard Mandarin as their first language. In other words, prior to 1985 it was much more chaotic. If you want a more up-to-date comprehensive list of words with multiple readings (多音字) you can find it below (although this is not an official government list). I've linked directly to the common words of which there are 106 (although the page does not define what is considered \"common\"). https://baike.baidu.com/item/%E5%A4%9A%E9",
    "originSummary": [
      "The text delves into the intricacies of the Japanese language, emphasizing its distinct features like kanji characters, syllabic scripts, untranslatable words, and grammar nuances.",
      "It explores the historical evolution of Japanese, the complexities of the writing system, and the specific challenges posed by kanji characters.",
      "The use of furigana in literature is discussed for its role in improving comprehension and creating artistic impacts, while the separation between written and spoken Japanese is noted for offering a unique reading experience with added depth and complexity."
    ],
    "commentSummary": [
      "The article discusses the distinct features of Japanese and Chinese languages, such as onomatopoeia, grammar complexity, and cultural nuances.",
      "It covers challenges like language acquisition, translation difficulties, and expressing untranslatable concepts.",
      "Emphasizes the significance of grasping language context, cultural references, and pronunciation nuances in understanding these languages."
    ],
    "points": 309,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1713881840
  },
  {
    "id": 40130304,
    "title": "10-Level Balancing Game: Stay Balanced as Difficulty Increases",
    "originLink": "https://www.balanc3dgame.com/",
    "originBody": "I made this 10 level Game. Excited for people to try it. :) Stay Balanced :)",
    "commentLink": "https://news.ycombinator.com/item?id=40130304",
    "commentBody": "Balancing game for the mobile browser with increasing difficulty (balanc3dgame.com)303 points by nargaw 23 hours agohidepastfavorite99 comments I made this 10 level Game. Excited for people to try it. :) Stay Balanced :) meowster 4 minutes agoSuggesttion: Have a button where people can \"zero\" their phone orientation. Looks good! reply Laremere 19 hours agoprevNice work! Some thoughts: The camera is tilted instead of looking straight down, and my phone needs to be flat to be in the no movement neutral position. This is unpleasant in to ways: How I'm sitting right now makes it hard to look at my phone while it's flat; it would be much nicer to be able to set my neutral point so I could play with the phone mostly vertically. The combination of flat phone and camera angle is awkward, as when you're looking straight down at the flat phone it looks like the level is tilted, and the ball should be rolling. If you're sticking with flat always being neutral, the corresponding camera angle should be from directly above, imo. After trying the phone and dying, I ended up playing on the desktop with the arrow keys, much more pleasant. Your light is coming from a direction where the magnitude is the same in x,y, and z. This means there's no difference in shading between three of the visible faces. (Or, you're using shaders which does this for some other reason.) This may be an intentional choice on your part, but I think it'd probably look better with a light angle which gives more definition to the geometry. Especially the level text suffers from this. On the last level, is the spinning obstacle at a slightly offset pace from the first moving platform? When I first saw the level, they were very poorly timed with the obstacle sweeping past where you'd go to get on to the moving platform right as the moving platform came closest. Waiting a bit seemed to slowly improve the situation, and I eventually got tired of waiting and just went for it. Still unsure if they're actually in sync or not. I died the third time on the last level, and called it quits when it put me back at the start. A very harsh punishment. reply jagged-chisel 15 hours agoparentThird death being a reset to the beginning is indeed a harsh punishment. reply SlightlyLeftPad 7 hours agorootparentI was expecting to have three balls but the UI makes me feel like I should 4. reply krisoft 12 hours agorootparentprevYeah, that is where i said to myself “f-this, you are not paying me enough to put up with this” and closed the “game” reply hombre_fatal 11 hours agoparentprevI think setting a different “up” point ruins the metaphor and you’re trying mentally map tilting into arrow key inputs. I’d recommend instead forgetting that your phone has an up. Hold it in landscape and rotate it as needed to get the angle you want before tilting. reply lwansbrough 12 hours agoparentprev+1, tilt should be dampened towards the natural orientation the phone was in during initialization reply s3krit 16 hours agoparentprevFor the last level, you can get onto the moving platform on the first cycle if you're quick reply SamBam 21 hours agoprevAwesome! Make it a daily Wordle-style game! I need something new in my morning routine. I think having a universal 3-life max is very harsh. I died on level 9 and was sent back to level 1. No way am I going to do the first 9 again, so I won't find out what was on 10. I think it would be more casual friendly to have infinite repeats in every level, but you could have a total count of deaths, for people who care about their score. reply ppezaris 9 hours agoparentTempest had the best implementation of this. Every 3-4 levels was a checkpoint and with 3 lives as long as you cleared at least one level, you can start at your last checkpoint. If you died 3 times without completing the level, you have to start at the checkpoint below. reply M4v3R 21 hours agoprevOne of the first big games on the original iPhone after the App Store was shipped was “super Monkey Ball”, a port of a popular console franchise. It was basically this but with fancier graphics, many more levels and mechanics and cute characters. I remember being amazed how well it worked with the phone’s accelerometer and how good it looked back then. Hard to believe that was ~15 years ago already. [0] https://supermonkeyball.fandom.com/wiki/Super_Monkey_Ball_(i... reply sunnybeetroot 15 hours agoparentIf you liked monkey ball you may like Marble Blast, it even runs on web https://github.com/RandomityGuy/MBHaxe?tab=readme-ov-file reply nargaw 1 hour agoprevI'm so grateful for all the feedback and suggestions. Thank you!!! Here is a link to the repo: https://github.com/nargaw/Balanc3d_game Twitter: https://twitter.com/nate_dev_ If you had a great time and want to support the project: https://natedev.gumroad.com/l/balanc3d reply yashg 20 hours agoprevIt is cool, but having to redo from the first level after 3 drops kills the fun for me. Of course some would like that aspect, but for me as a casual fun game it's a no. reply amadeuspagel 18 hours agoparentI felt the same way at first, but it's ten levels, so you'd be done in one session if you could redo every level infinitely. This extends the fun a bit. reply jncfhnb 16 hours agorootparentIt’s ok to be done in one session Replaying a level is boring reply rjmunro 14 hours agorootparentprevAfter 10 levels, it could be the same levels again, but with a time limit that gets shorter for each cycle, or something else to make it harder, like wind that blows the ball off course and changes direction all the time. reply stavros 6 hours agorootparentprevI think it very much extends the non-fun bits of the thing. reply sen 21 hours agoprevMarble Madness vibes. One of my favorite nostalgia games. I think having 3 lives per level with it resetting just that level might be better for starters, then the 3 lives for the entire game being a “hard mode”. reply codingdave 19 hours agoparent> Marble Madness vibes. Those are the exact words I head in my head while playing as well. I'd love to see a remake on modern devices. reply sunday_serif 19 hours agoparentprevFor me, this took me back to Marble Blast Gold. An early 2000s game with essentially the same concept. Great fun :-) reply sunnybeetroot 15 hours agorootparenthttps://github.com/RandomityGuy/MBHaxe?tab=readme-ov-file You’re welcome reply pyryt 11 hours agoprevYou can get the ball off the ground if you turn your phone upside down. Then you can just sort of fly over the places where you'd normally fall. Takes maybe a minute or two to complete all the levels. reply lovegrenoble 21 hours agoprevIn zoom meetings, I prefer this one, based on \"Knot Theory\": https://brainteaser.top/knot/ Not sure I learned anything about Knot Theory from playing this, but that was fun. reply cuechan 21 hours agoprevWhen you put Smartphone upside down, the ball will fall up reply bee_rider 19 hours agoparentI wonder what could be done with a Super Mario Maker style community of people who make obscenely difficult maps. I guess maps where you have to hover the ball by rapidly flipping the phone would be just the start. reply 2dvisio 14 hours agoparentprevCame here to say the same. Also one can combine that with extreme tilts to accelerate massively and win easily reply tromp 22 hours agoprevI lost a bunch of times on level 7 and then was sent back to level 1. Is there a way to avoid redoing completed levels? reply risenshinetech 17 hours agoparentThis is what we like to call a \"skill issue\". reply otteromkram 21 hours agoparentprevGet better, then you won't have to redo any of them ;-) reply mopierotti 19 hours agoprevIdea: It would be super cool if the camera angle also shifted a bit when you tilt your phone, making the level look more like a real object. You would have to assume the relative position of the phone from the viewer, but that assumption is already being made (given that the view of the level is not from directly overhead currently). reply darepublic 1 hour agoprevvery cool, I enjoyed this. One stupid random idea -- have a tiny pet or human running in the ball. reply swagmaster8008 20 hours agoprevBUG: If I make it to under the finish square by accident (falling off right before the end of a level), it still counts as a win when it should count as a death. reply encypruon 1 hour agoprevI'm extremely disappointed to learn that Firefox allows access to motion sensors by default and provides no option to make it ask for permission. It can only be disabled completely but this silently breaks legitimate uses like this one. This is a privacy nightmare. There is so much that can potentially be inferred from motion data, like user identity, mode of transport (maybe even location), what they're likely to be typing in the url bar or in an iframe, emotional state, a bunch of health information... edit: Nice game, though. I wonder what it's made with. There seems to be a huge amount of generated shader code in the js. I wonder if that could be avoided. reply shawabawa3 22 hours agoprevhaving only 3 lives for all levels is a bad idea imo Gave up once it started again from scratch, its not fun just re-doing all the levels to try again reply risenshinetech 17 hours agoparentSo to clarify: With infinite lives, it would have guaranteed you made it to the end, at which point you would stop playing anyway. So in both cases you stop playing, but at least in one of the cases the game remains hard for people who like a challenge. Win win! reply jncfhnb 16 hours agorootparentModern game design would suggest it’s better to simply put a death tracker for those who want a challenge rather than impose tedium on those who just want to play the game casually “Stop playing” is not a meaningful metric reply latexr 16 hours agorootparentprevA win win would be if both types of people were happy, but the status quo frustrates one of them. It’s only a win if you stop playing because you’re satisfied, not because you’re annoyed. Games are supposed to be fun. Plenty of games have a “zen mode” or “story mode” or “explorer mode” or any other kind of name to enable an option where’re you’re not severely punished by mistakes. Better yet, they usually allow you to switch modes mid-game. Which means you can progress at your own pace and appreciate everything without getting stuck and rage quitting. Anecdotally, even if I never turn those modes on I find that the games who have them tend to be more fun and better designed in terms of difficulty progression. Examples include Celeste and Cross Code. For this game, such a mode would even allow someone to see all the levels or practice in one where they’re stuck and then try again with lives turned on. That would be a win win. reply VS1999 8 hours agorootparentprevThis is some insane logic. The goal of the game isn't just to get the player to stop playing. Obviously two players haven't reached the same point just because one quit because he doesn't want to replay the starting levels again. This is known as \"artificial difficulty\". reply bogtog 21 hours agoparentprevThe fear of needing to start all over adds a lot of suspense, which is cool reply lifeisstillgood 13 hours agoprevI liked it - thank you. Can I suggest that you put something like “hold your phone flat and face up” On the instructions / landing page And make sure the start button can be seen in landscape mode I gave up and it’s only because HN gave me those hints that I got tomplay at all But - well done - you shipped ! Brilliant :-) reply alabhyajindal 3 hours agoprevExtremely well done! I didn't know you could access gyroscope from the browser. reply nasso_dev 15 hours agoprevyou can speedrun by playing with the phone screen facing down. tilt it slightly and the ball will go super fast. you can sort of \"fly\", too, and climb up walls. i got to level 9 in like 30 secs like this reply Liftyee 12 hours agoparentCan confirm. \"Finished\" all 10 levels in a minute on my first try of this strategy. Maybe the end detection area is too high... reply thsksbd 13 hours agoparentprevAwesome. Thanks. I made it to level 10 like that reply luplex 22 hours agoprevDidn't work on Brave on Android, but it did work on Chrome :) Kind of fun reply logrot 21 hours agoparentAnd Firefox reply hanniabu 20 hours agoparentprevI'm on chrome on android and it's not working for me. I see 3 dots on the left, a 1 on the right, but nothing seems to happen when clicking/swiping reply TulliusCicero 11 hours agorootparentYou have to tilt your phone. reply stpedgwdgfhgdd 19 hours agoprevDoesn’t work on ipad? I can click Start, but in the next screen nothing reacts to input. reply dlivingston 18 hours agoprevWhat engine / library was used to make this? reply joshstrange 21 hours agoprevIt doesn’t have a privation aspect but if you like games like this you might want to check out “Road to Ballhala” [0]. I haven’t completed it yet but I’ve been enjoying it quite a bit. The “dialog” is very well done. [0] https://store.steampowered.com/app/425410/Road_to_Ballhalla/ reply oxcabe 21 hours agoprevCool game! Level 9 made me realize there's some inner dread deep within me when it's about playing web-based games with mazes. Especially for those where you can fall off the path. reply georges_gomes 21 hours agoprevA leaderboard for speed runners would be interesting :) reply udev4096 22 hours agoprevFinished all levels without falling at once. Great game! reply xyst 16 hours agoprevI was laying on my back. Started up the game without resetting my phone to a flat state. Then the ball fell off the map. No automatic reset like the other levels. Maybe this is a speed run tactic that can be used later ;) reply atum47 16 hours agoprevNice. I made one where you should guide a sphere into a hole a few years ago. It was in 2D and I don't think it worked all that great. I'll see if I find it and post it here reply nayuki 18 hours agoprevThis reminds me a bit of https://en.wikipedia.org/wiki/SkyRoads_(video_game) reply grasseh 19 hours agoprevManaged to make it through by only losing a life on Level 6. The last two were very scary (and I think I got very lucky on the last one). But I guess I played enough Super Monkey Ball as a teen to still have a lot of practice for this. reply brightball 19 hours agoprevAwesome work Nate!!! I’ve been following your work ever since that Lightning talk on Three.js at the Carolina Code Conference. You’ve got a lot of talent and motivation, which is a killer combination. reply wanttosheeddp 21 hours agoprevI did it with arrow keys on desktop. Got lost 2 lives at level 9 and got frustrated so I hit full throttle ahead and basically bounced over all of the gaps. Then on mobile got to level 5. Cool! Thanks! reply recursive 17 hours agoparentArrow keys! Thank you! I could not figure out how to do anything. reply Waterluvian 22 hours agoprevVery cool! An issue I immediately had is that it seems to be coded for a horizontal plane being zero. This means I must hold my phone looking down at it, which isn’t how I want to hold my phone. One idea is to sample orientation for a little bit at start, then consider the average to be zero. Then have a button that zeroes motion to whatever it currently is as a backup. That way I can play your game without getting up from bed just yet. reply andrelaszlo 21 hours agoparentMy neutral position is tilting away from me, even. Not ideal but fun game either way. Reminds me of Oxyd: https://en.m.wikipedia.org/wiki/Oxyd (I've only played the nineties mac version) reply Waterluvian 21 hours agorootparentOxyd was core to my childhood gaming as a Mac-only household. Theres a free version called Enigma that has the Oxyd levels by the way! reply jeffreygoesto 14 hours agorootparenthttp://www.nongnu.org/enigma/ reply spuz 20 hours agoparentprevI feel like that would make intuitively finding the zero point hard. At least with the zero point being horizontal, all you need to do is look at the world around you and see which way things fall. reply Waterluvian 20 hours agorootparentYou can always have a “bubble level” showing you the orientation. Anything is better than requiring a player to orient themselves very specifically to play at all. reply Aromasin 20 hours agoprevVery responsive; can't say the same for most browser games so well done. I managed to complete it in one shot. The old dog still has it :) reply yzzyx 12 hours agoprevThis is awesome! Makes me wanna play Monkey Ball! reply logrot 22 hours agoprevI like it! Unsolicited improvement suggestion: When I finish a level, let me see how well I did compared to others. reply developer1000 16 hours agoparentvery good idea reply spxneo 10 hours agoprevgot to level 8 and gave up but this was very fun could be better with changing camera angles reply sufficer 18 hours agoprevDoesn't work on Chrome for android. Mid range android phone though reply dfc 18 hours agoparentWorks like a charm on my Pixel 7. reply developer1000 16 hours agoprevvery nicely done with all the graphics and motion. One thing i would add is autofocus attribute on the next button so that i just have to hit enter. reply ghnws 19 hours agoprevNice! I would like it more without the \"lives\" though. reply jonnycomputer 19 hours agoprevNicely implemented; controls felt very intuitive on the keyboard. reply brospars 20 hours agoprevNice and very precise. I was expecting controls to be less reactive. reply matthewhartmans 12 hours agoprevAbsolutely love this! Well done OP! reply speg 20 hours agoprevThe ball just falls off and then endlessly falls through space… reply georges_gomes 21 hours agoprevThe keyboard controls are particularly satisfying. Well done. reply maremmano 22 hours agoprevI'm unable to go forward. I'm using arrow keys. reply bitdivision 22 hours agoparentIt's accelerometer based, though arrow keys do seem to work for me on Chrome / Linux reply paranoidxprod 22 hours agorootparentArrow keys also seem to work on Firefox 126 Beta / Linux for me reply dotancohen 22 hours agorootparentYeah, the arrow keys also work on IE4 in Win98. No accelerometer though. reply ttrrooppeerr 22 hours agoparentprevWorked for me using A/S/D/F reply kosolam 22 hours agoprevNice. How did you build it? reply skilled 22 hours agoparentLooks to be React with Three.js. No GitHub repo but source can be seen using dev tools. reply andai 21 hours agorootparentThree.js games run fine on my old phone. Even with physics! Buttery smooth. React games however (even 2D ones) are a slideshow. reply IshKebab 12 hours agoprevNeeds to have some visual feedback of the orientation. Also the ball is too heavy & slow. And as someone else said the perspective is wrong. reply JohnSSS1978 22 hours agoprevVery cool game! reply dmos62 20 hours agoprevDoesn't work in Firefox for Android. reply k1t 19 hours agoparentYou may (like me) have been trying to interact by tapping/dragging/etc. You need to physically tilt your device to play. reply dmos62 2 hours agorootparentNo, tried to tilt, no effect. I didn't get any permission prompts either. reply nebulous1 16 hours agoparentprevIt worked FF/Android for me, but it froze for a second every so often. reply toss1 19 hours agoparentprevAlso doesn't seem to work on FF for Windows. Can click thru initial [Start] screen, but no clicks are effective on the initial game screen showing the layout and [start] (at least none that I could find). reply holoduke 19 hours agoprevCreate a webapp from it. The typical usecase for an installable version. Add service worker and a manifest.json. that way on android phones you have an icon. reply ReptileMan 21 hours agoprev [–] this has the feel of an old game called Ballance ... it was amazing and begging for level editor. Amazing job. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The mobile browser game, resembling Super Monkey Ball with 10 levels, receives mixed reviews from users, suggesting enhancements like daily challenges, checkpoints, and new obstacles.",
      "Players criticize the game for its harsh penalties upon dying and subpar controls, while also expressing privacy concerns regarding motion sensors on Firefox.",
      "Despite some compatibility and control problems, users commend the game for its difficulty and entertainment value, proposing additions like varied camera angles and a feature to compare scores with other players, some recommending a webapp version for improved accessibility."
    ],
    "points": 303,
    "commentCount": 99,
    "retryCount": 0,
    "time": 1713867735
  },
  {
    "id": 40130924,
    "title": "New Foundations Consistency Proof with Lean",
    "originLink": "https://leanprover-community.github.io/con-nf//",
    "originBody": "New Foundations is consistent In 1937, Quine proposed a set theory called “New Foundations”, and since 2010, Randall Holmes has claimed to have a proof of its consistency. In this repository, we use the interactive theorem prover Lean to verify the difficult part of his proof, thus proving that New Foundations is indeed consistent. The proof is now complete, and the theorem statements can be found in ConNF/Model/Result.lean (source, docs). See our website for more information, the documentation of our Lean code, and the deformalisation paper that translates the Lean definitions into English. To run our code locally, install elan, clone the repository, and run the following command in a terminal in the repository’s root directory. lake exe cache get The code can then be viewed in an editor such as Visual Studio Code, or compiled directly from the command-line using lake build. Objective It is known that New Foundations is consistent if and only if a theory called Tangled Type Theory (TTT) is consistent (see theorem 1 here). We have formally constructed a model of TTT in Lean, thus proving (on paper) that New Foundations is consistent, or in short, Con(NF). We are working from various versions of the paper proof by Holmes: untangled.pdf; retangled.pdf; newnfdoc.pdf; maybedetangled.pdf, but many alterations and additions have been made to make the proof compatible with Lean’s type theory. This project depends on mathlib, the community mathematical library written in Lean. This allows us to use familiar results about things like cardinals and groups without having to prove them ourselves. Every definition and theorem in mathlib and this project have been checked by Lean’s trusted kernel, which computationally verifies that the proofs we have constructed are indeed correct. However, Lean cannot check that the statements of the definitions and theorems match their intended English equivalents, so when drawing conclusions from the code in this project, translation to and from English must be done with care. Tangled type theory TTT is a many-sorted set theory with equality “=” and the membership relation “∈”. The sorts are indexed by a limit ordinal λ, and elements of λ are called type indices. A formula “x = y” is well-formed if x and y have the same type, and a formula “x ∈ y” is well-formed if x has any type less than y. One of the axioms of tangled type theory is extensionality, which stipulates that a set of type α is uniquely determined by its elements of any type βλ be a regular ordinal, and μ > κ be a strong limit cardinal with cofinality at least κ. Sets of size less than κ are called small. We first construct an auxiliary type at level -1, called the base type, below all types that will eventually become part of the model. Elements of this type are called atoms (although they are not atoms in the ZFU or NFU sense, for instance). There are μ atoms, partitioned into litters of size κ. Constructing each type At each type level α, we will produce a collection of model elements for our intended model of TTT, which we will sometimes call t-sets. We also produce a group of permutations, called allowable permutations, which act on the t-sets. The membership relation is preserved under the action of allowable permutations. Each t-set is stipulated to have a support under the action of allowable permutations; this is a small set of objects called addresses, such that whenever an allowable permutation fixes all elements of a support, it also fixes the t-set. Each t-set at level α will be given a preferred extension of some type β < α, and we can recover from a t-set’s elements which extension it prefers. The extensions of such a t-set in other lower types can be deduced from its β-extension. This allows us to satisfy TTT’s extensionality axiom. Controlling the size of each type Each type α can only be constructed under the assumption that all types β < α are of size exactly μ (among other hypotheses). It is easy to prove that the collection of t-sets at level α has cardinality at least μ, so we need to show that there are at most μ elements of this set. We do this by showing that there are not that many fundamentally different descriptions of tangles under the action of allowable permutations. This requires the freedom of action theorem, which is a technical lemma that allows us to construct allowable permutations. The main result of this section is here. Finishing the induction We can then run the above process recursively to produce the types of tangles at all type levels α. This is an easy step to perform in set theory, but requires a lot of work in type theory because of the interconnectedness of the various inductive hypotheses we need. We then check that our construction indeed produces a model of TTT by checking that it satisfies a finite axiomatisation of the theory. We have chosen to convert Hailperin’s finite axiomatisation of NF’s comprehension scheme into a finite axiomatisation of TTT, which we present in our results file. Note, however, that this choice is arbitrary, and any other finite axiomatisation can be easily proven with the infrastructure already in place. Dependency graph con-nf is maintained by a team of contributors from the University of Cambridge. Visit the repository on GitHub for more information.",
    "commentLink": "https://news.ycombinator.com/item?id=40130924",
    "commentBody": "New Foundations is consistent – a difficult mathematical proof proved using Lean (leanprover-community.github.io)295 points by namanyayg 20 hours agohidepastfavorite112 comments randallholmes 16 hours agoI would say that there is very little danger of a proof in Lean being incorrect. There is a serious danger, which has nothing to do with bugs in Lean, which is a known problem for software verification and also applies in math: one must read the conclusions carefully to make sure that the right thing is actually proved. I read Wilshaw's final conclusions carefully, and she did indeed prove what needed to be proved. reply btilly 15 hours agoparentThe paper makes a similar point like this: Every definition and theorem in mathlib and this project have been checked by Lean’s trusted kernel, which computationally verifies that the proofs we have constructed are indeed correct. However, Lean cannot check that the statements of the definitions and theorems match their intended English equivalents, so when drawing conclusions from the code in this project, translation to and from English must be done with care. reply amw-zero 11 hours agorootparentThis is precisely why humans will always be involved with creating software. reply naasking 10 hours agorootparentLLMs already write English better than most native speakers. I wouldn't bet everything on this. reply The_Colonel 5 hours agorootparentDo you trust LLM so much that you don't check what it writes before sending the email? LLMs can write better English, but the curating step is still critical, because it also produces a lot of garbage. reply chongli 1 hour agorootparentConstructing a sentence is only the last step in writing, akin to pressing the shutter release on a camera. LLMs can turn a phrase but they have nothing to say because they do not experience the world directly. They can only regurgitate and remix what others have said. reply naasking 5 hours agorootparentprevWould you trust a brand new assistant to write up an email for you without proof reading it? How much training would they require before you didn't need that step? How much training / fine-tuning would an LLM need? What about the next gen LLM? Remember, we're not talking about a static target here, and the post I replied to set no qualifications on the claim that a human will always be needed to check that a mathematical definitions in the proof match the English equivalents. That's a long timeline on a rapidly moving target that is, as I said, already seems to be better than most humans at understanding and writing English. reply The_Colonel 5 hours agorootparent> Would you trust a brand new assistant to write up an email for you without proof reading it? Depends on the complexity, but for the simpler things I think I could get confident in a day or so. For more complex things, it might take longer to assess their ability. But I'm not going to trust LLM blindly for anything. > I replied to set no qualifications on the claim that a human will always be needed to check that a mathematical definitions in the proof match the English equivalents. I don't defend this strong claim and limit my answer to LLMs (and mostly just state of the art). OTOH I believe that trust will continue to be a big topic for any future AI tech. reply hyperthesis 3 hours agorootparentprevIt will eventually become as chess is now: AI will check and evaluate human translation to and from English. reply justinclift 2 hours agorootparentAnd if it says the human got it wrong, then tough luck for the human if they didn't. :( reply fsckboy 4 hours agorootparentprev>LLMs already write English better than most native speakers... till they incorporate more of what some of your writing and loose their advantages reply justinclift 2 hours agorootparentprevApart from the whole \"generating bullshit\" thing, sure. reply rsaarelm 5 hours agorootparentprevHow do you think humans are doing this this if you don't think machines can ever do anything similar? reply nathan_compton 11 hours agorootparentprevThis doesn't seem to follow. Why kind computers get better at doing this (anticipating what humans want or whatever) than people? Some people are better at it than others and people are not magic, so I'd guess at some point computers will get it too. reply wolfram74 10 hours agorootparentI think what the parent post is referring to is that clarifying human intention rather axiomatically involves a human at some stage in the process. reply randallholmes 16 hours agoparentprevThe problem I express relates to the issues people mention about libraries: if a defined concept is used, one has to be sure the definition is correct (i.e., that the right thing has been proved). Wilshaw's formalization is not vulnerable to this objection, though libraries were used. What is proved is that a certain defined concept satisfies a certain suite of formulas of first order logic. If there is a predicate satisfying that suite of formulas, NF is consistent. reply Smaug123 15 hours agorootparentI am sure you know this, but for the audience: the danger can be mitigated somewhat with a \"test suite\" of theorems and examples about the definitions. These examples can be very simple (\"this particular object, with this particular operation, is a group; this other object is not\") or much more sweeping and general (e.g. fundamental theorems like \"all objects with this property are isomorphic\" or \"all objects with this property embed canonically in this other construction\"). It doesn't prove that your definitions are correctly capturing what your natural-language proof talks about, but it can help you be more confident. reply randallholmes 15 hours agorootparentprevand it very much IS an essential part of my confidence in this proof that conversations between me and Sky Wilshaw reveal that she understands my argument [and was able to point out errors and omissions in paper versions!] human interaction helps create confidence. But the software is extremely reliable: a philosophical challenge based on bugs in theorem proving software just is not going to hold water. reply pvg 15 hours agorootparentThere's a (small, grey) link that reads 'edit' among the links at the top of each comment you can use if you want to change or add something to a comment you've already written, if you prefer that to replying to yourself. reply jpt4 14 hours agoparentprev> Every definition and theorem in mathlib and this project have been checked by Lean’s trusted kernel, which computationally verifies that the proofs we have constructed are indeed correct. From a foundational perspective, it is also important to note that this proof is one of equiconsistency between NF and the Lean kernel, which itself is handchecked. Mechanized theorem provers preserve that level of correctness imputed to them via outside injection, from humans or other out-of-band systems. reply randallholmes 4 hours agorootparentIt certainly isnt a proof of equiconsistency between NF and the Lean kernel. The theory implemented in the Lean kernel is considerably stronger than NF. reply Strilanc 7 hours agoparentprevAnother danger is some sort of bug in Lean itself. This isn't unprecedented in theorem provers [1][2]. These might be hard to hit by accident... but there are larger and larger collaborations where arbitrarily people fill in steps (like [3]). Someone trolling one of these efforts by filling a step in using a bug they found might become worth worrying about. [1]: https://inutile.club/estatis/falso/ [2]: https://www.youtube.com/watch?v=sv97pXplxf0 [3]: https://terrytao.wordpress.com/2023/11/18/formalizing-the-pr... reply sterlind 6 hours agorootparentIt's kind of a root of trust problem, isn't it? I think the algorithm for checking proofs is relatively simple. All those fancy tactics boil down to a sequence of rewrites of an expression tree, using a small handful of axiomatic rewrite rules. The trusted codebase becomes that checking algorithm, along with the \"compiler\" that translates the high-level language to term rewriting syntax. Formally verifying that codebase is a rather circular proposition (so to speak), but you could probably bootstrap your way to it from equations on a chalkboard. reply Smaug123 2 hours agorootparentNote also that there is an independent checker https://github.com/leanprover/lean4checker to ensure that you're not pulling any fancy tricks at the code level: that the compiled output, free of tactics, is in fact a proof. reply mckirk 9 hours agoparentprevThat's always the problem with these pesky computers. They do exactly what you tell them to. reply sn41 8 hours agoparentprevCongratulations on the verification of your proof! It must be great to have your research life's crowning work being formally confirmed! Also a great victory for the new foundations of Quine. reply spindle 9 hours agoparentprevMany congratulations on being formally proved right, Randall! reply amw-zero 12 hours agoparentprevThis is why specification is much more important than verification / proof. We are bound by how accurate we make our propositions. reply cwzwarich 19 hours agoprevIf I’m not mistaken, this is the first use of a proof assistant to settle the status of a difficult proof that had been sitting in limbo for years. There were some previous projects (e.g. the Four Color Theorem in Coq) that validated existing proofs with a large computational element handled by untrusted software, but I think this is the first one where the epistemological status of the result was uncertain in the larger mathematical community. reply hiker 19 hours agoparentLiquid Tensor Experiment also comes to mind: https://www.nature.com/articles/d41586-021-01627-2 https://leanprover-community.github.io/blog/posts/lte-final/ reply Davidzheng 14 hours agorootparentDisagree. That one was not in question for years. Only Peter Scholze proved it and said he's not completely sure reply OscarCunningham 16 hours agoparentprevIt's a similar situation to the Kepler Conjecture (https://en.m.wikipedia.org/wiki/Kepler_conjecture). The proof was already known, but people weren't sure it was correct until it was formalised. reply isaacfrond 19 hours agoparentprevNext up the abc-conjecture! Claimed to be proven in 2012, and to 400+ page paper is online. But I don't many accept the proof. reply nicklecompte 18 hours agorootparentThere is a major difference though: Holmes's proof was broadly comprehensible, just extremely complicated and easy to get lost in the details. In particular Holmes really tries to make the reader understand, with a fairly gentle/apologetic introduction. But Mochizuki's \"proof\" is completely impenetrable even to experts on, like, page 3, and makes no effort to explain what is happening. Another key difference is that New Foundations is a niche field, so there simply was not a huge amount of human effort spent reading Holmes's work. That's not the case with Mochizuki's proof. There's a big difference between \"a small number of mathematicians didn't understand the proof but suspect it's correct\" and \"a large number of mathematicians didn't understand the proof and concluded it was incorrect.\" And, most of all: Holmes's formulation of twisted type theory made the proof a natural candidate for dependently-typed formal verification. Mochizuki's proof is not type-theoretic and does not seem like a great candidate for the calculus of constructions - maybe it is! I actually have no idea. I suspect Mochizuki is the only person in the world who can answer that. But it's critical that Holmes did so much background work to simplify his proof and make this Lean program possible. Mochizuki should do the same. AFAICT, both in terms of the \"sociology of mathematics\" and the amount of work required to even attempt a Lean formalization, trying to verify Mochizuki's proof is a waste of time. reply ducttapecrown 15 hours agorootparentKirti Joshi from the IAS has made very serious attempts to patch up Mochizuki's work by developing new math and by making the exposition good. If you're an expert in arithmetic geometry presumably he's readable, if you're just interested, I found it fun to skim. reply Davidzheng 12 hours agorootparentNo comments on the correctness of his work (plenty of discussions online e.g on MO) but why do you say he's from IAS? reply nextaccountic 17 hours agorootparentprevThere's a proposed proof of abc conjecture that is supposedly more readable. Here is a discussion thread about it: https://www.reddit.com/r/math/comments/1bhiz0s/construction_... It would be nice if this one were formalized in Lean (or Coq or HOL) though. reply barfbagginus 17 hours agorootparentprevI seriously doubt mochi's going to be any help for the lean formalization effort. But a lean-assistive llm trained on mochi's work? Ahhh! What an intriguing possibility! reply Chinjut 16 hours agorootparentI do not imagine LLMs will be of any use here. reply barfbagginus 16 hours agorootparentThen it's time to update your LLM reading! https://leandojo.org/ https://github.com/lean-dojo/LeanCopilot https://arxiv.org/abs/2404.07382 reply Davidzheng 12 hours agorootparentThese llm's are usually only proving some trivial lemmas right now. Hopefully it changes soon but... reply barfbagginus 10 hours agorootparentJust bolting llms onto proof search improves the state of the art. So if you want to improve the state of the art of proof search, bolt some llms onto proof search, and enjoy! As far as making LLMs understand mochi math... I'm going to go out on a limb and say it will probably take less time for us to build an AI that understands mochi than it would take to understand mochi ourselves. reply dimask 49 minutes agorootparentI would bet for this use case LLMs to be worse than random walk, as they would probably disregard certain possibilities in crucial steps, unless we are talking about easier stuff. reply toneman 13 hours agorootparentprevI have studied IUT since 2012, and it is indeed, totally baroque. However, Motizuki Theory, is totally rebased and admits results of much interest. I will write more on this matter if my claim is of mutual interest. IRT, the topic and digression here, LLM and LEAN4 are of not much use for IUT. IUT Theory is much easier understood by a hacker than by a math guy, eventually tho, monitors and tv's did kinda become the same thing but there are, some minor differences. reply user070223 14 minutes agoprevSee also discussion on reddit with one of the creators.[0] https://old.reddit.com/r/math/comments/1ca6bj8/new_foundatio... reply YoshiRulz 4 hours agoprevZFC is dead, long live NF..? As an amateur mathematician whose use of sets is mostly as a lingua franca for describing other things, it's not clear to me what implications this has for the wider mathematical field, especially if the usefulness of NF is comparable to the established ZFC and its variants. Is it expected to become as popular as ZFC in machine proofs? I do find the existence of a universal set more intuitive, so if nothing else this proof has rekindled my own interest in formalisation. reply barfbagginus 1 hour agoparentFrom my naive and amateur view, the relative consistency result makes NF at least as useful as ZFC, since every model of ZFC can be extended into a model of NF. But it seems it won't make NF all that useful unless: 1. We prove NF is inconsistent. Then ZFC is also inconsistent (and the stars start winking out in the night sky ;) 2. We prove ZFC is inconsistent. Then there's still a chance NF is consistent (fingers crossed!) I'm probably ignoring more practical \"quality of life\" benefits of NF, like being able to talk about proper classes, and side stepping Russell's paradox with stratified formulas. reply einpoklum 18 hours agoprevCan someone give a rough description of what is special, or novel, in the \"New Foundations\" set theory formulation, relative to other formulations? Or at least, link to a description readable by, say, a math undergrad student or an engineering professional? reply Mathnerd314 16 hours agoparentI was just editing the Wikipedia article, it should be more readable now: https://en.wikipedia.org/wiki/New_Foundations I think the main thing is the existence of the universal set. For my use case, the type system of a programming language, such a universal set is very useful. There are various hacks used in existing systems like cumulative universes or type-in-type which are not as satisfying - instead, I can just check that the type signature is stratified and then forget about types having numerical levels. reply dwheeler 15 hours agorootparentI agree, a \"cool\" think about NF is the universal set. Another way to be introduced to New Foundations, along with how one can use it, is the Metamath database for New Foundations: https://us.metamath.org/nfeuni/mmnf.html Metamath is a proof system, but unlike most alternative systems like Lean, it doesn't have a built-in set of axioms - you need to declare your axioms, and then you can prove theorems (using only previous axioms and proven theorems). So you can declare the axioms of New Foundations, and then use them to prove other things. One thing you immediately discover when you try to use New Foundations is that \"the usual definition of the ordered pair, first proposed by Kuratowski in 1921 and used in the regular Metamath Proof Explorer, has a serious drawback for NF and related theories that use stratification. The Kuratowski ordered pair is defined as > = { { x } , { x , y } }. This leads to the ordered pair having a type two greater than its arguments. For example, z in > , z >> would have a different type than x and y, which makes multi-argument functions extremely awkward to work with. Operations such as \"1st\" and complex \"+\" would not form sets in NF with the Kuratowski ordered pairs. In contrast, the Quine definition of ordered pairs, defined in definition df-op, is type level. That is, . has the same type as x and y, which means that the same holds of . , z >. This means that \"1st\" is a set with the Quine definition, as is complex \"+\". The Kuratowski ordered pair is defined (as df-opk), because it is a simple definition that can be used by the set construction axioms that follow it, but for typical uses the Quine definition of ordered pairs df-op is used instead.\" One eye-popping result is that the Axiom of Choice can be disproven in NF. See that site (or other pages about NF) for details. reply seanhunter 4 hours agorootparent> Metamath is a proof system, but unlike most alternative systems like Lean, it doesn't have a built-in set of axioms - you need to declare your axioms, and then you can prove theorems (using only previous axioms and proven theorems). So you can declare the axioms of New Foundations, and then use them to prove other things. I've only used lean a little bit but I'm pretty sure you can start lean with a blank slate, declare whatever you want and then build up from there. In fact the Natural Number Game[1] is basically this, you develop the Peano axioms etc and prove everything about the natural numbers from scratch without using the standard library (which obviously would have all that built in). [1] https://adam.math.hhu.de/#/g/leanprover-community/NNG4 reply digama0 3 hours agorootparentNo, Lean is not suitable for axiomatic investigations, it comes with too much baggage from \"classical foundations\". As Randall said above, Lean is axiomatically much stronger than NF, and that's even with \"no axioms\"! You can use Lean to prove things about axiom systems, but you have to model the axiom system explicitly as a \"deep embedding\" with syntax and a typing judgment. For metatheory work like the one reported on here this is exactly what you want, but if you want to actually work in the theory then it's an extra layer of indirection which makes things a lot more cumbersome compared to using Lean's own logic. Metamath is much more configurable in this regard, you just directly specify the axiom system you want to work in and there is no special status given to first order logic or anything like that. reply dkbrk 13 hours agorootparentprev> In contrast, the Quine definition of ordered pairs, defined in definition df-op, is type level. That is, . has the same type as x and y How is that not a problem? The type of a set needs to be higher than its elements to prevent the construction of a set containing itself. If a tuple is the same type as an elements, then can't you construct a tuple that contains itself as its first element, i.e. \"x.0 = x\" is a stratified formula so x exists. reply LudwigNagasena 7 hours agorootparentHow is that a problem that a set contains itself? It's allowed in NF. reply randallholmes 15 hours agorootparentprevIt's not magic: the universe of NF and other \"big\" objects in this system must be handled with extreme care. reply randallholmes 15 hours agorootparentto the original poster, the universe is a boolean algebra in NF: sets have complements, there is a universe. The number three is the set of all sets with three elements (this is not a circular definition; it is Frege's definition from way back); in general, a cardinal number is an equivalence class under equinumerousness, defined in the usual set theoretic way, and an ordinal number is an equivalence class of well-orderings under similarity. When you look at objects which lead to paradox (the cardinality of the universe, the order type of the natural well-ordering on the ordinals) then you discover the violence inherent in the system. Very strange things happen, which are counterintuitive. None of this depends on my proof to work: these are all features of NFU (New Foundations with urelements) which has been known to be consistent since 1969, and one can explore what is happening by looking at its known models, which are far simpler than what I construct. reply einpoklum 12 hours agorootparentSo, is the article/project concerned with \"just NF\", or \"NF with urelements\"? Also, now I have to go learn about urelements too :-( reply Mathnerd314 15 hours agorootparentprevWhile you're around, I have a question: In TST, the restriction for x^m in y^n is that n = m+1, i.e. the level must increment by 1. In TTT, the restriction is instead that mRandall Holmes has claimed to have a proof of its consistency. In this repository, we use the interactive theorem prover Lean to verify the difficult part of his proof, thus proving that New Foundations is indeed consistent. I think proponents of Lean are a little bit too strong in their use of language. Lean is not a superior method of proof, as is often implied. It is an alternative way of proof. If one looks into getting into Lean, one quickly realizes this situation. It is a programming language and system, with its own bugs, and you are highly reliant upon various stacks of libraries that other humans have written. These libraries have choices made in them and potentially gaps or even bugs. So I think I take issue with the language here that it was Lean that said the proof was good. I think the more accurate and honest language is that the written proof was verified by human mathematicians and that the proof was translated into Lean by humans and verified there as well. I don't think it's necessarily accurate, or I haven't seen explanations that say otherwise, that it's Lean that provides the sole, golden verification, but that is often implied. I think the subtitle is the most accurate language here: \"A digitisation of Randall Holmes' proof\". reply dwheeler 15 hours agoparentI do think that machine-verified proofs in strong systems like Lean are far superior to proofs merely verified by humans. Humans are amazing, but they also get bored and miss details. This isn't just a theoretical claim. People read Euclid's Elements for over two thousand years before noticing a missing axiom. That's the sort of basic mistake that any properly-working machine proof verification system would immediately reveal. Published math proofs are often later revealed to be wrong. The increasing sophistication of math means it's getting harder and harder for humans to properly verify every step. Machines are still not as good at creating proofs, but they're unequalled at checking them. There are \"competing\" systems to Lean, so I wouldn't say that Lean is the \"one true way\". I like Metamath, for example. But the \"competition\" between these systems needs to be in quotes, because each has different trade-offs, and many people like or use or commit to multiples of them. All of them can verify theorems to a rigor that is impractical for humans. reply agalunar 14 hours agorootparentFor the curious: I assume the parent is referring to Pasch's axiom. https://math.stackexchange.com/questions/1901133/euclids-ele... reply dwheeler 13 hours agorootparentCorrect. The good news that Elements still works otherwise, you just need to add the missing axiom. But many other \"proofs\" have been found to be false. The book \"Metamath: A Computer Language for Mathematical Proofs\" (by Norm Megill and yours truly) is available at: https://us.metamath.org/downloads/metamath.pdf - see section 1.2.2, \"Trusting the Mathematician\". We list just a few of the many examples of proofs that weren't. Sure, there can be bugs in programs, but there are ways to counter such bugs that give FAR more confidence than can be afforded to humans. Lean's approach is to have a small kernel, and then review the kernel. Metamath is even more serious; the Metamath approach is to have an extremely small language, and then re-implement it many times (so that a bug is unlikely to be reproduced in all implementations). The most popular Metamath database is \"set.mm\", which uses classical logical logic and ZFC. Every change is verified by 5 different verifiers in 5 different programming languages originally developed by 5 different people: * metamath.exe aka Cmetamath (the original C verifier by Norman Megill) * checkmm (a C++ verifier by Eric Schmidt) * smetamath-rs (smm3) (a Rust verifier by Stefan O'Rear) * mmj2 (a Java verifier by Mel L. O'Cat and Mario Carneiro) * mmverify.py (a Python verifier by Raph Levien) For more on these verifiers, see: https://github.com/metamath/set.mm/blob/develop/verifiers.md reply enricozb 17 hours agoparentprevWhile there indeed may be bugs, it's my understanding that any trust needs to be placed only on the kernel. > various stacks of libraries that other humans have written If you're referring to mathlib here, I'm not sure this is correct. As again all mathlib code compiles down to code that is processed by the kernel. Indeed this is reinforced by the draft paper on the website [0]: > Lean is a large project, but one need only trust its kernel to ensure that accepted proofs are correct. If a tactic were to output an incorrect proof term, then the kernel would have the opportunity to find this mistake before the proof were to be accepted. [0]: https://zeramorphic.github.io/con-nf-paper/main.l.pdf reply bmitc 16 hours agorootparentI think that's an overly formalistic view by the Lean team. When I looked into Lean last (sometime last year), it was a hodgepodge of libraries and constructions. The maturity of the library depended upon if someone in that area of math had spent a lot of time building one up. There were even competing libraries and approaches. To me, that implies that there's \"choice\" there, just as there is in mathematics. And a choice could be \"buggy\". What's to say that the construction of a mathematical structure in Lean is the same as the mathematical structure in \"normal\" mathematics? So yes, if that statement by the Lean team is accurate, you can build correct things on top of the kernel, but the use of \"correct\" is a very formal one. It's formally correct in terms of the kernel, but it doesn't mean that it's necessarily mathematically correct. This is to my understanding of course, garnered from trying to get into Lean. reply cvoss 14 hours agorootparentI think you are misunderstanding the relationship between the theorem and the proof. You express doubt that the proof is a good one, but then you point to the libraries in Lean as a possible source of incorrectness. The libraries cannot be the source of incorrectness in the proof. They can only be the source of incorrectness in the statement of the theorem. That's why others are challenging you to declare that you don't trust the Lean kernel. A kernel bug is the only thing that can permit incorrectness in the proof. The exact content of the proof doesn't matter for the purposes of deciding whether you should believe the theorem. At all. What matters are two things: 1) Is the theorem correctly stated? That is, does it say what it's supposed to say in the agreed upon (natural or programming) language? 2) Do you trust the Lean kernel (or human reviewer of the proof, if applicable)? If you accept 1) and 2), then you must accept the truth of the theorem. No library used in the construction of the proof, nor any library used in the expression or the proof, can make or break the result. If one uses a library in the statement of the theorem, then that matters. That's letting someone else define some of the terms. And one must investigate whether those definitions are correct in order to decide whether the theorem is stated correctly. If you wish to challenge the work on these grounds, by all means proceed. But you can't say you don't think the proof is a good one for such reasons. reply vilhelm_s 16 hours agorootparentprevBut like, you can look at what parts of Mathlib this development imports, it's mainly stuff imported by files in this subdirectory https://github.com/leanprover-community/con-nf/tree/main/Con... , and it's pretty basic things: the definition of a permutation, a cardinal number etc. Almost all of these are things that would feature in the first one or two years of an undergraduate math degree (from just quickly scanning it, the most advanced thing I could see is the definition of cofinality of ordinals). It seems practically impossible to me that someone would make a mistake when e.g. defining what a group is, in a way subtle enough to later break this advanced theorem. If you think that people could mess up that, then all of math would be in doubt. reply Certhas 14 hours agorootparentprevYour analogy to buggy implementations in ordinary programming languages is deeply flawed though. The things formally defined and stated are proven. There can be no bugs in a library that lead to formally stated theorems being erroneously proven. Bugs at the library level can only appear in the form that formally stated theorems might not be what you think they are. So I object to your characterization that they might be mathematically incorrect. The mathematical content might be different than believed though. reply bmitc 11 hours agorootparent> The things formally defined and stated are proven. There can be no bugs in a library that lead to formally stated theorems being erroneously proven. That can't actually be true in practice can it? These are things running on a computer, a machine, and not paper. Additionally, I'm consider two types of \"bugs\". (1) bugs in software or hardware that the stack relies on; (2) \"bugs\" in the conceptual sense of a Lean construction being something different than what was meant or what people thought it was, which is effectively the same problem that regular mathematics runs into. reply naasking 9 hours agorootparent> Additionally, I'm consider two types of \"bugs\". (1) bugs in software or hardware that the stack relies on; Then run the Lean proof on a non-x86 computer and on both Windows and Linux. The possibility that two independent computer architectures and two independent operating systems converge on some buggy behaviour that just so happens to allow a buggy proof through is so remote it's not worth considering further. > (2) \"bugs\" in the conceptual sense of a Lean construction being something different than what was meant or what people thought it was, which is effectively the same problem that regular mathematics runs into. A specification is orders of magnitude shorter than proofs, on average. So if you're saying they managed to reduce the amount of manual verification work and possible human error by orders of magnitude, that sounds like an uncontroversial win for correctness. reply Certhas 2 hours agorootparentprevTheorem provers work like this: the axioms are input, then there is a program (using libraries) that transforms them, and the output of that program is the theorem. If the runtime is correctly executing the program, then the theorem is proven from the axioms. Importantly, as long as there is any program that outputs the theorem from the axioms, you have a proof. So even if your program doesn't do what you think it does, if it outputs the theorem, that doesn't matter. So do you trust the runtime? Bit flip errors can be eliminated by running things multiple times. The more human proven statements the runtime executes correctly the more you believe it's implemented correctly. Importantly, all proofs done in lean increase the trust in the common runtime. And: do you trust your ability to understand the formal theorem that is output. That's the question discussed elsewhere in this comment section in depth. reply fwip 16 hours agorootparentprevFrom my understanding, the libraries written in Lean are also formally proven by the kernel. They may be hodge-podge or incomplete, but they are (by construction) not \"buggy\" in a way that could lead to incorrect proofs, right? reply appplication 17 hours agorootparentprevI think their point is it’s turtles all the way down. At some point you’re relying on software, kernel or otherwise, which will always have the possibility for bugs. It seems like Lean is an interesting tool that maybe could help with proving, but ultimately will never be authoritative itself as a statement of proof. Of course, this is ultimately a philosophical debate, which hinges on the fact to at while Lean may be demonstrably correct in any number of known applications, there are no guarantees that it is and will remain correct. Such is the nature of software. reply konstantinua00 16 hours agorootparentI think the counterpoint is it's turtles all the way down. At some point you're relying on human mind, logic or otherwise, which will always have possibility of misunderstandings and mistakes. It seems like Mahematicians are interesring tools that maybe could help with proving, but ultimately will never be authorative itsel as a statement of proof. Of course, this is ultimately a philosophical devate, which hinges on the fact to at while Mathematicians may be demonstrably correct in any number of known applications, there are no guarantees that they are and will remain correct. Such is the nature of wetware. --- development of proof assistants is in noticable part fueled by the same fear - fear that wetware had a fault somewhere in the long ladder of math, causing all the layers above be a useless junk and those things did happen, it isn't just an imagined threat what proof assistants propose is a clever trick - write one, simple, kernel. Stare at those 100 lines of code. Stare at mathematical definitions of intended API. Conclude that those coincide. Then use that kernel on the text files with all the proof ladder All mistrust of \"whole mathematics\" gets condensed in mistrust of 100 lines of code And mistrust of wetware gets replaced with mistrust of hardware - something we already do since even before computers appeared reply enricozb 17 hours agorootparentprevSuch is the nature of math as well. reply appplication 17 hours agorootparentI’m not a mathematician, so I’d be interested in any perspectives if the two are ultimately so similar in this regard, or is there is something foundationally different about the traditional mathematical approach. I suppose any proof is ultimately a matter of review and consensus, and potentially would rely on some fundamentally unprovable assumptions at a basic level (e.g. the underlying laws of the universe). reply enricozb 16 hours agorootparentWhat I was referring to is that we don't know if ZFC, for example, is consistent. And it is only consistent if there are unprovable statements. And of course, you can't know which statements are unprovable (because then you would prove its consistency). So, in some sense you're always chasing your own tail. Theorems might be proven true only because ZFC is inconsistent and therefore everything can be proven. The Lean language is known to be equivalent to ZFC + {existence of nIt is a programming language and system, with its own bugs The cool thing about theorem provers is that an invalid proof won’t even compile (as long as the kernel is correct). There’s no such thing as a traditional software bug that happens only at runtime in these systems when it comes to proofs, because there’s no runtime at all. You can also use Lean as a “regular” programming language, with the corresponding risk of runtime bugs, but that’s not happening here. reply rowanG077 16 hours agoparentprevThe difference is that in lean you only need to trust the kernel. The rest is constructed on top. If the kernel is sound everything else is as well. This is in stark contrast with a standard programming language. Where at any time a bug can be introduced. It's also in stark contrast with math where any lemma may contain an error. reply Agingcoder 16 hours agoprevI very much like this. I wonder whether this will eventually lead to collaborative proofs , and ‘ bug fixes’ , essentially turning maths into a process similar to code on GitHub. reply trenchgun 15 hours agoparentAlready is. Check Lean blueprints. https://terrytao.wordpress.com/2023/11/18/formalizing-the-pr... reply practal 11 hours agoparentprevYes, this idea of collaborative proofs has been around for a while now, at least for 10 years: https://arxiv.org/abs/1404.6186 reply xylol 18 hours agoprevI'm really not from the field but wasn't there some Gödel theorem showing every system strong enough cannot show its own consistency? reply hyperpape 18 hours agoparentGödel's incompleteness theorems are what you're thinking of. https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_... That said, if you have a system X, it can't prove it's own consistency, but a stronger system Y can prove its consistency (and perhaps some other stronger system can prove Y's consistency. This gives us a chain of systems, each proving the consistency of some weaker system). That doesn't absolutely prove that the system is consistent--if Y was inconsistent, it could prove X is consistent (and also could prove that X is inconsistent). Nonetheless, it is still valuable. After all, part of our use of Y is the fact that we know of no inconsistency in it. And since formal systems often are subtly inconsistent, \"consistent assuming some other system is consistent\" is a lot better than \"we have no proof whatsoever of consistency\". reply pulisse 18 hours agoparentprevThe system isn't being used to prove its own consistency. The consistency is proved in a different, stronger system. reply skhunted 18 hours agoparentprevWhat’s interesting to note is that even if a strong system could prove its own consistency then it wouldn’t tell you anything. An inconsistent system can prove its own consistency. So if a system has a proof that it is itself consistent then you still wouldn’t know if it is consistent. reply libeclipse 16 hours agorootparentIt would tell you that the system is inconsistent reply skhunted 16 hours agorootparentIt would not. If a system can prove (I know sufficiently rich systems can’t do this but suppose it could) its own consistency you still can't conclude it is consistent. EDIT: I'm working under the hypothetical situation in which PA could prove its consistency. I know it can't but assuming that it could prove it's own consistency you still couldn't conclude that it was consistent since an inconsistent system can prove it's consistency. reply roywiggins 15 hours agorootparentGP is (I think correctly) stating that a system that can \"prove\" its own consistency is definitely inconsistent. Inconsistent systems can \"prove\" anything; if a system can appear to prove its own consistency, it isn't. reply skhunted 15 hours agorootparentYes. I know this. What I'm saying is that even if a consistent system that was strong enough could prove it's consistency then it still wouldn't tell you anything. There are system that can prove their own consistency for which it is known that they are consistent. https://en.wikipedia.org/wiki/Self-verifying_theories reply naasking 9 hours agorootparentThese are weaker than the systems Godel's theorems are referring to, as discussed in the opening paragraph. Do these systems are not \"strong enough\" in the sense described in this thread. reply skhunted 7 hours agorootparentObviously I’m aware of this. As stated several times, my original comment refers to the hypothetical situation in which PA could prove its consistency without Godel’s theorems being true/known. One would not be able to conclude anything. The point being, having PA prove its own consistency couldn’t tell you anything of value even in the case that Godel’s theorems were not true. This is an interesting phenomenon. The only way to know a system is consistent is to know all of its theorems. reply francasso 17 hours agoparentprevYou should take this proof as saying: if Lean 4 is consistent then New Foundations is consistent. There is no contradiction of Godel's incompleteness theorem. reply peteradio 18 hours agoparentprevI don't think the system here is trying to prove any of its underlying assumptions, just building on some set of existing ones. I doubt the theorem you are thinking of is applicable. reply seanhunter 4 hours agoprevThis is a fantastic result, congratulations! reply _jcrossley 19 hours agoprevI wish I had the free time to keep up with the mathlib project - this is so cool. Is there any way someone can get involved in a super hands-off way? reply isaacfrond 19 hours agoparentYou could start with the Natural numbers game. https://adam.math.hhu.de/#/g/leanprover-community/NNG4 reply gerdesj 17 hours agorootparentWell, thanks a lot! One minute I'm setting up a monitoring system and then ... I've just proved two is the number after the number after zero \\o/ 8) reply _jcrossley 15 hours agorootparentHope you keep going with it, it’s a blast! reply gerdesj 12 hours agorootparentI read \"GEB\" by Hofstadter after I finished my A levels (UK, aged 18). I picked up a random book in the school library to fill in 20 mins before going out on a pub crawl (as you do). Once we had finished off the Abingdon Ock Street crawl in fine style and the hangover had subsided, I devoured it. I'd never read anything like it before - what a communicator of ideas. A few unwise life style choices later and I find myself running a small IT company for the last 25 odd years. I'll never get beyond undergrad engineering maths n stats but it's works like GEB and the Natural Numbers Game (and I see there are more) that allow civilians like me to get a glimpse into the real thing. There is no way on earth I could possibly get to grips with the really serious stuff but then the foundations are the really serious stuff - the rest simply follows on (lol) Whom or whoever wrote the NNG tutorials are a very good communicator. The concepts are stripped to the bare essentials and the prose is crystal clear and the tone is suitably friendly. Top stuff. reply _jcrossley 15 hours agorootparentprevYea I’ve run through that a couple of years ago - was brilliant, had a lot of fun. But I mean to stay up to date and somehow contribute from the sidelines reply shepherdjerred 14 hours agorootparentprevWow, that's actually really fun. Is this what \"proofs\" are in math classes? reply stogot 5 hours agoprev [–] Do the incompleteness theorems not apply here? reply lmm 5 hours agoparent [–] They start with a large cardinal assumption which is the usual workaround - you have a proof that this theory is consistent if a large cardinal like that exists, which is something you can't prove within the theory. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In 2010, Randall Holmes claimed to prove the consistency of Quine's \"New Foundations\" set theory, now verified using the Lean interactive theorem prover.",
      "The project establishes a connection between New Foundations and Tangled Type Theory, demonstrating the former's consistency.",
      "Hosted on GitHub by the University of Cambridge team, the project relies on mathlib and constructs diverse tangles across different levels."
    ],
    "commentSummary": [
      "Discussions revolve around the reliability of proof systems such as Lean and Metamath for verifying mathematical proofs, stressing the significance of human involvement in interpreting results.",
      "Debate includes the use of language-learning models for translation in proof tasks and the AI's effectiveness in proofreading.",
      "Explorations cover the consistency of New Foundations set theory, the power of theorem proving software, and the reliability of machine-verified proofs, with a focus on the accessible Mathlib project engaging users in complex mathematical ideas."
    ],
    "points": 295,
    "commentCount": 112,
    "retryCount": 0,
    "time": 1713873663
  },
  {
    "id": 40131597,
    "title": "Accidental Expert: Conway's Game of Life Pioneer",
    "originLink": "https://news.ycombinator.com/item?id=40131597",
    "originBody": "I drifted into the Conway&#x27;s Life research community in 2001 when I won a small cash prize for a lucky discovery of something called a \"boojum reflector\". My involvement has gradually snowballed since then. Off and on I&#x27;ve helped maintain various Life-related mailing lists and blogs, the Life Lexicon, and more recently the conwaylife.com forums and LifeWiki.Another thing I stumbled into was helping Nathaniel Johnson complete an improbably thorough 480-page Conway&#x27;s Life textbook, with end-of-chapter exercises and everything. The book could be used to teach a college-level class on the subject. https:&#x2F;&#x2F;conwaylife.com&#x2F;book&#x2F; has a free PDF download for the book.So... I&#x27;m not the cleverest Lifenthusiast by a long shot, but for a random question about the Game of Life, I&#x27;m more likely to know something about it than at least 99.9999% of the world&#x27;s population. Ask me anything!",
    "commentLink": "https://news.ycombinator.com/item?id=40131597",
    "commentBody": "AMA: I'm Dave Greene, an accidental expert on Conway's Game of Life294 points by dvgrn 20 hours agohidepastfavorite137 comments I drifted into the Conway's Life research community in 2001 when I won a small cash prize for a lucky discovery of something called a \"boojum reflector\". My involvement has gradually snowballed since then. Off and on I've helped maintain various Life-related mailing lists and blogs, the Life Lexicon, and more recently the conwaylife.com forums and LifeWiki. Another thing I stumbled into was helping Nathaniel Johnson complete an improbably thorough 480-page Conway's Life textbook, with end-of-chapter exercises and everything. The book could be used to teach a college-level class on the subject. https://conwaylife.com/book/ has a free PDF download for the book. So... I'm not the cleverest Lifenthusiast by a long shot, but for a random question about the Game of Life, I'm more likely to know something about it than at least 99.9999% of the world's population. Ask me anything! HarHarVeryFunny 18 hours agoWe see people doing insane things nowadays with Conway's Life, such as simulating CPUs. Two questions: 1) How are people building things this complex? Are there open source libraries and toolkits for this - building blocks for chunks of functionality that can be assembled? 2) For you, what are the most interesting, impressive and varied things that you've seen with Life? Is it just these increasing levels of complexity, or maybe something else? reply dvgrn 16 hours agoparentQuestion 1: There are really surprisingly few \"standard libraries\" or tools for this kind of thing. You would think we'd have a CA editor capable of doing object-based editing by this time -- like, copy in a complete device made out of reflectors and converters, each of which is made out of still lifes and oscillators, each of which is made out of cells, and you could do \"group\" and \"ungroup\" operations and snap to the right locations to fit the circuits together correctly. But at the moment, pretty much all we have is tools to copy and paste rectangular sections of patterns at the cell level -- plus we've got good scripting tools (in Golly) that can be used to string together whatever pieces we might want, but it's up to individual pattern-builders to write those scripts for each specific purpose. So our \"library\" is pretty much just the LifeWiki and a few other pattern repositories, and we borrow liberally from existing large constructions -- but when we're building something new, we usually just build flat bitmaps, not anything with built-in annotations or metadata. Question 2: The thing that's been the most interesting to me in the last decade or so is the increase in collaboration. Projects used to be done by just one person more often than not -- but now a very large fraction of the biggest discoveries are completed via a large group effort over the course of a few weeks or month. One big recent example has been the RCT fixed-cost universal glider synthesis project, which needed contributions from quite a few people to solve all of the tricky little sub-problems: https://conwaylife.com/wiki/Reverse_caber-tosser reply jaymzcampbell 15 hours agoparentprevThe Game of Life is a 2-dimensional cellular automata (CA), so given the 1-dimensional rule 110 has been proven to be universal / Turing-complete [1], it becomes less mysterious. Albeit the complexity of the system required to set it up to do anything \"useful\" would be prohibitive. I'm currently finishing up my OU MSc and the project I picked was specifically around cellular automata - only in this case relating to them calculating any arbitary automatic sequence - which are sequences you can create from finite state machines - that really opened my eyes to the fact these sorts of very, very simple machines can, with the right (and rather complex) setup, be made to do pretty much whatever you want from a computational PoV. In that paper by Rowland and Yassawi they give a constructive proof to calculate the required update rules for a CA that outputs any particular automatic sequence. That itself gives some hints at some ways of deriving the input and rules for these systems to do some particular job. [2] I know Wolfram often gets dunked on for ego/hubris but in Chapter 11 of a New Kind Of Science he goes into how the Rule 110 CA can be setup to \"calculate\" (output) other CAs. From there it starts to become a little less mysterious that these systems can generate behaviour you could imagine running on a CPU of some sort.[3] [1] https://mirror.explodie.org/universality_in_elementary_cellu... [2] https://arxiv.org/abs/1209.6008 [3] https://www.wolframscience.com/nks/chap-11--the-notion-of-co... reply thrww0300392 52 minutes agoprevWhat would be your advice/roadmap for someone who wants to start with automated exploration of emergent behaviour in systems that are similar to GoL? I think it would be interesting to try transfering some of the automated search techniques to Minecraft's redstone mechanics, even though it probably doesn't fit the definition of a celular automata. Redstone is a feature in a videogame Minecraft that acts similar to logic circuits. Because building mechanics in Minecraft is inately restrictive (building is snapped to the 3d grid of \"blocks\", and there is only a limited number of blocks that all have predefined behaviour), there is naturally a community of people using redstones in ways that serve no purpose to the core gameplay loop, such as flying machines (think GoL's ships) [0], computers (since Minecraft's redstone is practically Turing-complete) [1] [2] or printers/autobuilders [3]. I would go so far as to say that redstone is the GoL for nerdy Zoomers. [0] https://minecraft.fandom.com/wiki/Tutorials/Flying_machines [1] https://www.minecraftforum.net/forums/minecraft-java-edition... [2] https://minecraft.fandom.com/wiki/Tutorials/Redstone_compute... [3] https://minecraft.fandom.com/wiki/Tutorials/Printing reply bell-cot 19 hours agoprevThe basics, JIC anyone here is still unfamiliar with the Game: https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life And generalizing Games from there: https://en.wikipedia.org/wiki/Life-like_cellular_automaton Question #1: How far has Lifeology(?) advanced since 2001, for people similar to your younger self (without awesome skills, or huge time investment) to have a chance at making their own lucky discoveries, and becoming modest Somebodies in the community? Question #2: How highly (or otherwise) would you rate Wikipedia's articles on Conway's Game of Life, and closely-related topics? reply dvgrn 18 hours agoparentA really impressive number of discoveries have been made since 2001 -- there's been kind of a proliferation of new sub-fields, so it seems like there's never any shortage of things for newcomers to work on. There are definitely areas that haven't really been explored fully yet, like the use of SAT solvers in new and inventive ways to tackle difficult Life problems that are currently just beyond our reach. Just for example, there's the problem of finding a fast elbow for a 2c/3 \"signal wire\" -- https://conwaylife.com/wiki/Wire#2c/3_wire It's not clear if SAT solvers can be applied usefully to glider synthesis questions, like \"is it possible to collide gliders to build a Sir Robin spaceship?\" At the moment that particular question seems way beyond reach, but maybe in a few years we'll be running an AI that is experimentally setting up new SAT solver problems, and something will pop up that we just haven't managed to think of yet. Question 2: Wikipedia's articles tend to be very good quality -- partly because if they weren't, there are a lot of Lifenthusiasts with some experience maintaining the LifeWiki who would immediately go and fix any technical errors that might show up on Wikipedia. But the really detailed documentation on Life is definitely kept in the LifeWiki, not on Wikipedia: https://conwaylife.com/wiki/ reply blastro 17 hours agorootparentReminds me of the Busch-Gass Gambit in chess - something so new and mind boggling that it absolutely destroys the best chess engines in the world. Discovered through computer analysis. Insane to watch this opening played well. reply hollerith 17 hours agorootparent>it absolutely destroys the best chess engines in the world. Citation? I'm willing to believe that someone used the gambit to win against an engine, but in response I would've expected the engines to be modified to restore their absolute dominance against human players. So, I would be very interested to see any evidence that this gambit continued to work against the version of the engine released after the gambit's effectiveness became widely known. reply kwhitefoot 17 hours agoparentprevI was unfamiliar with JIC, had to read the sentence twice to make sense of it. :-) reply mihaitodor 19 hours agoprevHave you followed the https://codegolf.stackexchange.com/questions/11880/build-a-w... thread where Tetris was implemented using their Cogol (and low level QFTASM) programming language? I'm curious if that work led to any new insights and if it found any usage beyond implementing Tetris. reply dvgrn 18 hours agoparentYup, the Quest for Tetris project caused an entertaining stir for a while. The people that worked on that were the best kind of \"hacker\" -- fearless experimenters who didn't let their lack of Life-specific knowledge get in the way of cobbling together an amazing structure that fit the bill for simulating Tetris. The project has at least one unnecessary extra layer of abstraction in it, but somehow nobody has quite gotten around to rebuilding it 100x smaller. A \"HashLife-friendly\" version could run thousands of times more quickly in Golly. Since then, several people have invented their own independent computer architectures in Conway's Life, so that kind of experimentation is still going on. See, e.g., https://conwaylife.com/wiki/8-bit_programmable_computer reply mihaitodor 18 hours agorootparentThank you! reply pavel_lishin 19 hours agoprev> boojum reflector That absolutely sounds like a codename from one of cstross's Laundry Files novels. (I think \"boojum\" was actually part of one, but I don't recall which.) edit: found it, it was from A Colder War, which is a great novellette: https://www.infinityplus.co.uk/stories/colderwar.htm reply sevenseventen 19 hours agoparentThe word \"boojum\" originates in Lewis Carroll's \"The Hunting of the Snark,\" an amusing epic poem about the importance of negative testing. reply lamename 19 hours agorootparentI'm interested. Scanning wikipedia, I'm missing the link with the importance of negative testing. Could you explain? reply sdwr 18 hours agorootparentPositive testing, in this case, is matching a sample to a pre-existing pattern Negative testing is trying to invalidate the sample The hunting of the snark is written in a way that reads like \"normal English\" from a distance. The sentences flow fine, the words look about right if you squint. So it passes a lot of \"positive tests\", in that it matches our expectations for what language looks like. You have to \"negative test\" the story to realize you don't know the definitions for any of the words, and that the plot is uninterpretable. Same idea as Kahneman's system 1 that comes up with instant answers, or ChatGPT hallucinating facts by association that \"look right\". reply s1artibartfast 14 hours agorootparentReminds me of Ted Hughes' Wodwo, playing with the concept of the known, unknown, and unknowable. It challenges the reader to try to model and define a Wodwo, but provides basically no information on what a wodwo is, aside from the fact that it is something that itself is struggles to define it's relation and connection to the world. In my opinion, it highlights how we are all physical perception machines looking for meaning and identity, but meaning and identity can not be physically perceived. https://allpoetry.com/poem/8495307-Wodwo-by-Ted-Hughes reply dvgrn 19 hours agorootparentprevYes, please -- I'd like to hear more about that! I've got the poem memorized, but mostly what I know about it is that Carroll thought of the last line first -- \"For the Snark _was_ a Boojum, you see.\" and ended up writing the other umpteen dozen verses just so that that would make sense as a punch line. reply bombcar 13 hours agorootparentprevAnd also is given to a cactus-like tree: https://en.wikipedia.org/wiki/Boojum_tree reply rosmax_1337 19 hours agoprevWhy is Conway's Game of Life so interesting? Does it prove anything or lead to insightful discoveries? The game itself seems to me, like a fun little toy at best. reply crdrost 19 hours agoparentThis won't directly answer the question, but just to give some added context: Note that in abstract mathematics (which is what Conway was doing here) you’re kinda creating building blocks, and you're kinda playing for “street cred” among the rest of the abstract mathematics community. This is kind of true in all academic publishing, that your success is due to your publications’ ability to inspire follow-up publications. But for abstract mathematics the “street cred” follows three rules: you get more cred based on, • the wimpier the building blocks look • the larger and more complex the structures you can build with them • the more memorable or intuitive the blocks are (so like marketing... SK-calculus is the same as lambda calculus but lambda can say “I am the abstract mathematics of template substitution!” while SK-calculus can't, directly.) All a way to say that the field is full of “fun little toys” and the key about criterion (2) is that we have figured out how to build structures of arbitrary complexity in Life, because we have discovered it is Turing-complete. It therefore is also NP-hard and a lot of other good stuff. Really revitalized work into cellular automata by giving some good marketing, which led to Stephen Wolfram's success etc etc. reply TimTheTinker 18 hours agorootparentExcellent info. > which led to Stephen Wolfram's success etc etc. Wolfram's A New Kind of Science takes the idea a bit too far, in my opinion. It's an exposition of the hypothesis that the underlying stratum of life and the universe is, like cellular automatons, discrete—and therefore can be understood in terms of discrete processes, which he views as analogous to real life. He points to emergence in cellular automatons as evidence that an analogous emergent phenomenon was the reason biological life came into existence. Mathematically and philosophically, it's a very interesting idea, but I'd hope that at this stage in scientific history, we'd understand that step 2 to validating an interesting hypothesis is testing it. reply seanhunter 17 hours agorootparentyeah wolfram's famous idea (which is sort of the whole point behind a new kind of science) is this computational equivalence principle which is that most things that are at a certain level of computational complexity are equivalent to each other[1]. Which may be true in some limited sense but is definitely not true in the general sense that he tries to imply. This has led him to saying things like you can implement the whole universe \"in 4 lines of the wolfram language\" even though mathematica (which is in the universe and implements the wolfram language) takes more than 4 lines of code to implement. [1] https://mathworld.wolfram.com/PrincipleofComputationalEquiva... reply defrost 3 hours agorootparentBoring mathematicians of the school of actual concrete formalisations level the criticism that his Principle of Computational Equivalence is never given a formal definitive statement and is more of an aspirational feel good kind of fuzzy wuzzy thingy. eg: Lawrence Gray in his 12 page review: https://www.ams.org/notices/200302/fea-gray.pdf Cosma Shalizi's infamous Rare Blend of Monster Raving Egomania and Utter Batshit Insanity review: http://bactra.org/reviews/wolfram/ reply bschmidt1 14 hours agoparentprevIt shows that complex structures, importantly those with generative capabilities and other utilities, can evolve from a simple pattern. It's a fun toy because it's implemented in pixels with arbitrary rules, but the concept is exportable to other domains. The eeriness of it I think comes from that we still don't understand a lot about the world - concepts like consciousness, the origin of the universe, origin of life - or, any mystery where we don't understand how a whole became greater than the sum of its parts - when you see a model like this, it shows visually how such unknown complexities probably originated in far simpler forms. When I see those epic Game of Life videos where there's a giant stealth bomber looking structure steaming across the screen creating sub-processes in its wake, to me it's like a blue whale moving through the ocean, or a vast alien spaceship silently yet steadily barreling through the void of space. There's an ominous intelligence that seems to emerge out of what was once simple, binary, unconscious, incapable. reply TimTheTinker 19 hours agoparentprevA simple set of rules leads to a fascinating array of emergent phenomena, which themselves can be utilized to do all sorts of interesting things. In fact, the game of life is Turing complete -- you can build whole processors[0] or programming languages in it. You can even implement the game of life in the game of life. Someone did that and implemented infinite zooming between GOL levels.[1] [0] https://github.com/nicolasloizeau/scalable-gol-computer [1] https://oimo.io/works/life/ reply abetusk 18 hours agoparentprevConway's Game of Life (GoL) provides a clear demonstration that simple rules can lead to complex behavior. The complex behavior is deep in the sense that Conway's GoL is Turing Complete [0]. The local update rules provide an analogy to our universe with a kind of built in \"speed of light\" of how fast information can propagate in the system. Further, since there is a system clock of sorts, the system is massively parallel with further analogies to our universe. The game looks like a toy but note that many profound models are also \"toy-like\". Ising systems, precolation models, Bethe lattices, self avoiding walks, etc. all provide seeding grounds for deep insights into our physical world. Just as an aside, I heard a quote, which I can't find anywhere, about how Maxwell playing with magnets could have been considered him playing with frivolous toys but his setup was critical to him figuring out the underlying mechanics of electromagnetism. On one hand, I sort of agree that there's a lot of uninteresting exploration but on the other hand, taking a step back, GoL research is exploring the more general space of cellular automata and how it could potentially map to real world simulation. For example, how small can a system be before it can do arbitrary computation? Can all patterns emerge eventually (no, garden of eden style patterns)? What do rotationally invariant patterns looks like? Can you \"copy\" arbitrary patterns from some setup? If so, how fast? Is it dependent on how big it is, or how complex it is? etc. GoL provides a sandbox in order to answer these questions and potentially give insight into other systems as well. In my opinion, one of the reasons for the popularity of GoL is because it was created right when computers became commodities, allowing hackers, amateur mathematicians and others to program something simple, that could be heavily optimized for limited hardware, and create intricate and complex behavior. There was a quote somewhere, that I'm also having trouble finding, about how, at one point, GoL simulations accounted for a significant portion of wasted compute. [0] https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life#Undeci... reply aj7 18 hours agorootparentJust leave physics out, and you’ll be OK. God doesn’t play the GoL. reply meschi 19 hours agoparentprevIt's a cellular automaton showing complex behavior emerging from very simple rules. Through especially crafted inputs you can simulate a Turing machine or Conway's Game of Life inside itself. reply JoeDaDude 13 hours agoprevA silly question and a PSA: 1. There was a two-player game called The Immigration Game [1] using GoL rules. Has anyone actually played this? Even better, has anyone developed an AI to play it? Is there really much of a game there? 2. The PSA: The Immigration Game was described in Lifeline, a 1970's era (typewritten!) newsletter about GoL. I managed to obtain a set of them. I've been planning to scan them and make them available online. I don't think there is any ground breaking info in them, after all, folk were programming on mainframes (surreptitiously). [1]. https://boardgamegeek.com/boardgame/129088/the-immigration-g... reply dvgrn 8 hours agoparentMy sense is that people don't usually play the Immigration Game for very long -- it just doesn't seem all that interesting to most folks ... and so there hasn't been much interest in developing a computer opponent for the game. It seems to be rather difficult to convert cellular automata into any kind of playable game. If it's an arcade game then it's usually too arbitrary, and if it's a puzzle game then it's usually way too easy or way too difficult. There have been some good efforts, but they're mostly only playable by dedicated Lifenthusiasts, and that's ... well... not a very large market! Re: the LIFELINE public service announcement -- no need to do the scanning and online-ing. That's been done already, though there's still some review and typing-up work left for someone to do: https://conwaylife.com/wiki/Category:Lifeline_issues reply bradleyy 18 hours agoprevI've been fascinated by Cellular Automata and the Game of Life ever since seeing the art installation of _Network IV_ by James Seawright. It was at Sea-Tac Airport, and has since been removed. There's some debate whether it was the Game of Life or some other automata, but I remember the sounds of the relays clacking and the light bulbs humming so distinctly. It certainly had a \"Game of Life vibe\". Are you aware of this art installation? Ever seen it? reply dvgrn 16 hours agoparentHadn't heard of it. Looks like it was removed sometime in the 90's, maybe, so it's not too likely that there would be a good video of it in action. https://www.reddit.com/r/Seattle/comments/1xzypl/something_i... https://imgur.com/gallery/3zwVKc3 It does seem like the kind of thing I might have been drawn into staring at for hours and/or playing around with, kind of like the marble perpetual-motion machine I remember from a Toronto museum at around the same time period. reply cauliflower99 18 hours agoprevConway has said GOL is not something he is particularly pleased got as famous as it did. (Ref: https://youtu.be/R9Plq-D1gEk?t=600) Why do you think that is? Edit: This is the video I meant: https://www.youtube.com/watch?v=E8kUJL04ELA reply gnramires 18 hours agoparentWhat I got from his interviews is not that he disliked the GoL, it's just he disliked the GoL overshadowing everything else he did (basically, becoming the GoL guy). He personally didn't see much more interesting mathematics that could be done after answering basic questions like universality (although it's likely he wasn't aware of everything the community was up to). Also, it's clear he seemed to come to terms with it in his final interviews (including the second one you linked) :) I've played around with several CAs and Conway's rules stands out to me as one of the most interesting still, for many reasons (like simplicity, interesting patterns, long lived structures). reply travisjungroth 15 hours agorootparentReminds me of Steve Paxton, an amazing dancer who passed away recently. He led a project called “Contact Improvisations”, which became a movement form called Contact Improvisation. He taught some classes and many others contributed. 50 years later, it’s still going strong. But, he didn’t embrace this role of “Contact Improv guy” that was really available to him. He just kept doing other stuff, even as this community exploded. I think that’s partly the nature of pure researchers. They usually have something more interesting to them than what they got famous for, and they probably don’t want to lead an organization. This is different from BDFLs like Guido van Rossum and Rich Hickey. Neither type is good or bad, and I appreciate them all. reply bombcar 13 hours agorootparentIt's almost by definition that if you get popular for something, it is not the thing you're most interested in or best at - because you're an expert in the craft and for something to be popular it has to be at least somewhat approachable by non-experts. reply JoeDaDude 18 hours agoprevDecades ago, I read an article in Byte magazine discussing various implementations of GoL. The article ended with an implementation in one line of APL. What are the chances you (or anyone) still has that article, and that one line program? reply dvgrn 16 hours agoparentHeh -- \"if you need more than one line of APL you do not fully understand your problem\". https://news.ycombinator.com/item?id=1041500 People have done similar things in all kinds of languages by now: https://codegolf.stackexchange.com/questions/3434/shortest-game-of-life reply RBerenguel 16 hours agoparentprevThis video constructs a GoL in APL (not one liner). It is quite understandable even if you don’t know APL (I had just started tinkering with APL when I first found it I think): https://m.youtube.com/watch?v=a9xAKttWgP4 In case somebody is curious to see how it might look like. reply kirubakaran 16 hours agoparentprevlife←{⊃1 ⍵ ∨ .∧ 3 4=+/,¯1 0 1∘.⊖¯1 0 1∘.⌽⊂⍵} reply ptrott2017 8 hours agorootparentand if you want some additional explanation: https://aplwiki.com/wiki/Conway%27s_Game_of_Life reply p1esk 20 hours agoprevIs there a 3d equivalent of the game? What would be different about it? reply dvgrn 19 hours agoparentThere's been quite a lot of experimentation with 3D versions of Conway's Life -- including rules where you can easily emulate Life on a 2D slice of the 3D plane. Carter Bays did some investigations and published papers back in the 1980's: https://conwaylife.com/wiki/Three-dimensional_cellular_automaton There's been a little bit of revived interest lately, when newer versions of Golly ( https://golly.sourceforge.io/ ) started to include at least some support for 3D rules. Other programs have been showing up recently, though some of them are more ways of visualizing the history of a 2-dimensional rule in three dimensions. There are a couple of big difficulties that seem to prevent 3D rules from getting a lot of attention. It's just plain a lot more computationally intensive to emulate 3D rules. Also it's a lot harder to see what's going on in the middle of an active 3D pattern -- a lot of the detail tends to get hidden. reply tromp 19 hours agoparentprevCarter Bays wrote a paper \"Candidates for the Game of Life in Three Dimensions\" on that back in 1987 [1] and another in 2006 as mentioned on Wikipedia [2]: [1] https://content.wolfram.com/sites/13/2018/02/01-3-1.pdf [2] https://en.wikipedia.org/wiki/3D_Lifex reply cornstalks 19 hours agoparentprevThis was posted yesterday: https://news.ycombinator.com/item?id=40124682 reply npinsker 19 hours agoprevWhat are the coolest problems that have been recently solved? What are the coolest open problems you'd like to see solved? reply dvgrn 19 hours agoparentIt's hard to choose one these days -- a whole pile of open problems actually got solved in the last few years, like omniperiodicity, glider syntheses of really complicated things like spacefillers, fixed-cost universal construction (it only takes fifteen gliders to build anything buildable) and still lifes and oscillators that solve the \"unique father problem\" (i.e., there are groups of cells that, if they're found in the Life universe at any point, they must have been there from the beginning of time.) So now I don't know what to wish for next! I suppose if I get a free wish for anything I want, I'd love to see a glider synthesis for Sir Robin, which a big oblique spaceship discovered in 2018. It's currently way beyond our ability to figure out how to build it out of gliders -- but twenty years ago the same was true of just about every Life spaceship, and now we have recipes for dozens of them. reply SandmanDP 3 hours agorootparent> fixed-cost universal construction (it only takes fifteen gliders to build anything buildable) Here’s the Hacker News discussion from when this was discovered: https://news.ycombinator.com/item?id=33797799 Dave, I’m still regularly blown away by this discovery. I don’t know what else there is to be said, but do you have any other comments regarding this? reply ghodith 18 hours agorootparentprevWhat would that investigation look like, just large amount of trial and error? reply dvgrn 17 hours agorootparentIt's going to have to be the opposite of trial and error, I would think -- though maybe in some sense some of the underlying searches for useful predecessors of patterns like Sir Robin could count as \"directed super-high-speed trial and error\". The problem at the moment is that nobody can see how to direct those searches toward a predecessor that's made entirely out of gliders -- it's clear that the Sun will burn out long before a trial-and-error search would be at all likely to return a result. We can easily make a huge number of non-Sir-Robin predecessor patterns that will evolve into Sir Robin -- and we can find ancestor patterns for most of those predecessors, too -- but each step backward always produces something that's a little bigger, a little blobbier, and a little more random and chaotic looking than Sir Robin was... so ultimately all we're doing is making the problem more difficult with each step. reply bilsbie 19 hours agoprevWhat’s the largest world we can run these days? Are they run on gpus now? Has anyone looked into ASICs? Is caching heavily used for optimization? reply dvgrn 19 hours agoparentYup, there's an increasing amount of GPU use these days, mostly related to soup searching -- see https://catagolue.hatsya.com/home for the software and a tabulation of results from the last several years of collaborative searching. Caching is very very heavily used for running the biggest universes, which are truly mind-bendingly large. Golly's \"HashLife\" algorithm can in practice handle patterns that are over a trillion cells in each dimension: https://conwaylife.com/forums/viewtopic.php?&p=153609#p153609 Patterns with interesting behavior very often have a lot of repeating patterns, with the interesting stuff happening as complex interactions between those predictable patterns. HashLife capitalizes on remembering interactions that it has seen before, so basically the more memory your computer has available, the better HashLife will do in the long run at simulating that type of pattern. reply bradleyy 18 hours agorootparentI'm curious at the term \"soup searching\": is this just looking for particular shapes? Or shapes that have certain behaviors? reply dvgrn 18 hours agorootparent\"Soup searching\" generally means not looking for anything in particular. It just involves setting up a random initial configuration, letting it run until it stabilises (\"goes boring\") and then takes a census of what's sitting around in the ashes of the burned-out pattern. Mostly, of course, the census just reports piles and piles of blinkers and blocks and beehives and boats and everything else that you almost always see when you run a random scribble -- but every now and then something turns up that has never ever been seen in the history of Life, and that turns out to be useful and building new mechanisms that weren't possible before: https://mathematrec.wordpress.com/2016/07/05/richs-p16/ https://conwaylife.com/wiki/Rich%27s_p16 reply MattyRad 4 hours agoprevMaybe this question is too low-concept, but what is your opinion of the glider as a Hacker symbol? reply MattyRad 4 hours agoparentEr- I just viewed your book, clearly you think it's relevant and appropriate! Do you have any particular thoughts about the glider as a Hacker symbol? reply openrisk 15 hours agoprevOver the years there must have been countless interesting generalizations of Life. I wonder if there is good concise reference that classifies and groups the main ideas that have been proven \"productive\", in the sense that they open up non-trivially different and interesting types of dynamic behavior? A while ago I was toying with the idea of introducing a \"macro\" stimulus. Basically coupling the local rules of the game to global metrics like how many nodes are alive. This is emulating a bit agent based modeling in economics and in particular the role of regulators raising or lowering rates, alternatively a physical system exposed to higher or lower temperature. But what happens (at least with a simple implementation) is that whatever \"stimulus\" is introduced tends to overwhelm the known patterns, there seems to be little new \"emergent\" behavior in the coupled system. https://www.openriskmanagement.com/game_of_life_with_macroec... reply dvgrn 14 hours agoparentI don't know about \"concise\", but one place to start for references is the LifeWiki. We've been trying to extend the non-Conway's-Life part of the wiki for a few years now, to cover more of the OCA space (\"Other Cellular Automata\"): https://conwaylife.com/wiki/Cellular_automaton https://conwaylife.com/wiki/OCA There's an \"Other Cellular Automata\" board on conwaylife.com/forums and several channels on the ConwayLife Lounge on Discord -- \"#naturalistic\", \"#circuitry\", \"#exotic-ca\" -- that collect discussions on these kinds of topics. reply paulgerhardt 19 hours agoprevNot a question but as a fellow Life enthusiast I thought I’d surface an alternative Life hack I made a few years ago based on physical Kong Bucks from Stephenson’s Snow Crash: https://kong.cash/ Each note is an actual flexible polyimide PCB containing a hardware storage wallet - the PCBs are translucent in parts or solid in others depending on a copper pour but overprinted with ink using a special UV process - but one of the security features is when one holds a note up to the light one can see a Game or Life program which when executed emits a corresponding number of gliders and oscillators as the notes value. This feature is to prevent one from “washing” a note and printing a different value as is done with $5 and $100 US bills for instance as the copper pour is “baked” into the medium. Writing a c program to encode arbitrary numbers into a Game of Life program was a very fun distraction during an otherwise thorny project that involved connecting people from the print world to people from the electronics world while shaving a few thousand cycles off a crypto library with ECDSA P256 operations before the smart phone powering the chips via NFC turned off. Real engineering work to bring cryptographic proof of authenticity that unfortunately gets written off as a 'crypto scam' when the poc token attached to the circuit boards was the least interesting part. One can see some of the denominations here: https://twitter.com/NoviolNFT/status/1341468948416512000 reply smusamashah 16 hours agoprev1. Are there any practical/real life applications for Game of Life? 2. Has any discovery made in life been used in real life or any practical application? reply neoneye2 3 hours agoparentIt's great for generating synthetic data for training LLMs for solving Abstraction & Reasoning Corpus (ARC) by François Chollet. Game of life helps the LLMs with a 2D understanding of the world. https://github.com/fchollet/ARC reply c22 15 hours agoparentprevThis is like asking about the practical applications of chess. They're probably mostly nth-order effects. reply dvgrn 15 hours agorootparentHeh, yes, the comparison to chess is a very good one. You probably need a similar level of focus and dedication to be a good Life pattern engineer or a good chess player -- and that level of focus is something that improves with enough practice, in both cases. I've mentioned in other answers that Life can make a good teaching tool for various mathematical and computer-science topics, mostly because it's entertainingly eye-catching. When you get a design right it's very satisfying -- like one of those huge domino chains that you see on YouTube, except that (for some designs) it keeps on setting itself back up again as it's in the process of falling down. reply lugao 19 hours agoprevWhat's your take on continuous life? SmoothLife, Lenia and Bert Wang-Chak Chan work in general? reply dvgrn 18 hours agoparentI think SmoothLife and Lenia are great fun -- lots of highly watchable \"eye candy\" tends to get produced by those types of experiments. The better you get at running experiments, the more new behavior you can turn up: https://www.youtube.com/c/Slackermanz There's a channel on the ConwayLife Lounge on Discord called \"#exotic-ca\" that's devoted to these kinds of explorations. I just simply haven't had time to dig into those topics much, but if I could clone myself I'd definitely assign one copy to playing around with that kind of thing. reply tobinfricke 5 hours agoprevIf you do a second edition, I would love a chapter on Life implementations, particularly how to implement a Life simulator that can execute these enormous patterns efficiently. reply JoshuaMHanson 8 hours agoprevThank you for the link to the book. I have always been interested in how to make the starting shapes. I am going to study the book more but started to realize that there are re-usable shapes that can be used to make more complex shapes (early, still, oscillators, gliders, etc..). This seems to be what I was looking for with the starting x/y and then the rule combo and pattern. I was also thinking there must be a better way than knowing exactly how big the board is vs an infinite board. Also making the edges either always dead or alive VS letting the shapes pass through like pac-man. Here is my horrible implementation using HTML canvas, JS/JQuery. https://github.com/JoshuaMichaelHanson/GOL/blob/master/js/go... Yes, I also made a new green account so as to not dox myself with my other accounts. reply nomilk 18 hours agoprevI haven't studied CS or bio. Do I understand correctly that what makes cellular automata special is they're approachable and demonstrate how complexity can emerge from simple rules (e.g. analogously to how life may have come to be)? Do other games (or simulations) demonstrate similar ideas, or are cellular automata a rare case? reply dvgrn 18 hours agoparentI'd say there's no shortage of demonstrations of complexity emerging from the iteration of simple rules -- fractals like the Mandelbrot set, simple edge-matching rules for aperiodic tilings, the logistic map, etc., etc. What makes Conway's Life particularly \"catchy\" (along with other 2D CAs) seems to be the motion. Humans love watching stuff move, especially when the motion is partly predictable and partly surprising -- i.e., like a screen-saver, not like TV static. And they like watching things blow up. A lot of Lifenthusiasts probably got their start by aiming gliders at carefully balanced Life patterns and gleefully watching the resulting explosions... it's a lot more fun than actually blowing things up, because you can always hit Undo and run it all over again, no harm done! reply slingnow 18 hours agorootparentNot sure that \"being able to hit undo\" and \"no harm done!\" is what makes blowing things up enjoyable, but to each his own. reply dvgrn 17 hours agorootparentHeh, well, I'm speaking as somebody who was fairly obsessed with making Rube Goldberg domino chains as a kid, spending hours at a time covering a large oak trestle table with precarious stacks of wooden blocks, rulers, tape cases, strings, marbles and so on -- and then knocking them all down. (This was long before YouTube, so I don't have any documentation of any of this.) I would really have appreciated an \"Undo\" button for rewinding entropy and running those things over again, especially when they went disappointingly wrong halfway through...! reply dwaite 18 hours agoprevBack in the day I read an article on HashLife in Dr Dobbs, which had a bit of an effect on me in terms of software architecture in terms of a set of new approaches, tightly coupled, providing astounding results. Are there other interesting and unexpected algorithms in implementations of GoL? reply dvgrn 17 hours agoparentThe relatively-big, relatively-new thing at the moment is the application of SAT solvers to CGoL problems. Donald Knuth got the ball rolling on this, but we're still in the very early days of seeing what is possible with SAT solvers. Every now and then a lucky or inspired SAT solver problem setup will throw out an answer to a really difficult-looking problem, with no apparent effort. But then that tends to tempt people into setting up more difficult problems to solve... and of course it's still very easy to set up problems that cover such a large search space that the search would take billions of years to complete on a planet-sized supercomputer. So it's still very much an art form, rather than an exact science, to figure out what searches to try next. reply lawlorino 19 hours agoprevI discovered Langton ants and Turmites a couple of months ago, I guess these are a subset of cellular automata. I was talking with a friend about using them somehow for art somehow (music generation came to mind), is this a topic you might know about and could recommend some resources to get started? reply dvgrn 17 hours agoparentLangton's Ant is one of many, many CA rules that run for a while, seeming to be \"predictably unpredictable\" -- creating lots of blobby chaos -- but then produce a highly recognizable emergent phenomenon (the final \"highway\", in this case). For music generation you'd want to somehow avoid ending up with the music \"going boring\" when the highway appears... As with a lot of math-inspired art (I guess I'm thinking about Mandelbrot-set colorizations here) the key is going to be in very specific presentation choices -- color choices for still frames or videos, or the specific method of mapping sounds to frames in a Langton's Ant evolution. So you'll just need to have (or develop) tools to try a lot of options and see what looks the most compelling. Still frames are probably not going to be that interesting -- the fun part about CAs is the predictable-yet-surprising motion, which can be either the usual visual form or converted to sound somehow. A recent version of Golly ( https://golly.sourceforge.io ) added support for listening to evolving patterns -- see pop-sounds.py / pop-sounds.lua in the Scripts directory. That reduces patterns to a single dimension in an obvious way (just looking at population), ignoring a lot of the 2D complexity. No doubt there are a lot of other possible avenues to explore there. reply pyinstallwoes 3 hours agoprevWhat would an operating system look like built using conway’s game of life ? reply guy4261 19 hours agoprevDid the Game of Life change anything in your world view? Your belief in god, or how you view society and societal changes? Even if the change is not rigorous or logical but something anecdotal that nonetheless changed your emotions, I'd be glad to hear about it. reply dvgrn 18 hours agoparentThere have been a lot of \"wow\" moments in my Life career, watching complexity emerge out of the repeated application of simple rules -- but I guess I'd say that it was more a confirmation of things that I thought I knew already. In 2001 I had already been playing around with things like the Mandelbrot set and aperiodic tilings and Douglas Hofstadter's strange loops for quite a few years, so I knew the kinds of magical things that the iterative application of simple rules could produce. reply jesuslop 15 hours agoprevHave you dug a bit in the concept under wolframphysics.org? Discretization of PDE equations is interesting and some generating-functionology/combinatorics can be spotted more or less over there. CAs can enter anything under the computational umbrella, question being how sleekly. Have they achieved something already, do you share their interests? (you said \"ama\") reply dvgrn 14 hours agoparentHa, well, I've mostly successfully dodged the various Wolfram-science questions so far. I just finished reading a book on cosmology -- VSL theory -- but honestly a lot this kind of thing seems to be way too far above my personal abstraction ceiling. I can't tell whether some of these ideas really even mean anything at all, or if it's just somebody who is better at waving words around than I am. This is wandering off of the Wolfram physics project a fair distance, but it's hard to see how space could be quantized in a Fredkin \"Nature is finite and digital\" kind of way, without the underling \"grain\" of the universe becoming obvious in some kind of experiment, and/or without causing deep contradictions in various experimentally well-supported relativistic effects that require that there isn't any such thing as a unique fixed frame of reference. But quite possibly that's just a failure of imagination on my part, not anything wrong with the actual theories in question -- I'm probably complaining about some apparent implausibility two levels above or below where the information is actually flowing. And there are certainly all kinds of properties of our physical universe that are quantized in one way or another, for utterly mysterious reasons. Long story short, there is certainly still room for some big surprises in theoretical physics, and I'm not about to claim that I'm clever enough to rule out any of these wild options. reply isomorph 19 hours agoprevWhere would you direct someone for tips on implementing Game of Life? reply dvgrn 19 hours agoparentThese days, without knowing more about preferred programming language or the purpose of the implementation, I'd probably start by pointing to this very thorough series of blog posts by Eric Lippert, from LifeWiki/Tutorials: https://conwaylife.com/wiki/Tutorials/Coding_Life_simulators Life simulators have been coded in so many different ways, in so many languages, by so many different people in the last half-century ... that it takes several dozen articles to work through a reasonable survey of the possible ideas and methods. reply isomorph 19 hours agorootparentThank you! reply dh-g 18 hours agoprevI made a small solar powered CGOL(https://davidhampgonsalves.com/solar-powered-conways-game-of...) that has a low pixel count. After 100 frames it randomly generates a new starting point b/c I didn't implement loop detection. Are their any algorithms or techniques for generating interesting starting states? reply AeiumNE 19 hours agoprevI'm super interested in cellular automata. One thing that particular piques my interest is the diversity of possible automata, not just forms in any particular one, but diversity of rule sets as well. What do you think is special about the GOL rule set compared to other life-like rules? Do you think it was a historical accident this particular rule set became so famous, or not? Are there alternatives you are also interested in? reply dvgrn 16 hours agoparentIt was _kind of_ a historical accident, in the sense that if we ran history over again, it wouldn't be too surprising to see an alternate-history \"Conway's Life\" with a rule like \"B36/S23\" (HighLife) instead of \"B3/S23\". (Conway did really like the replicator and bomber and a few other fun things that HighLife has that Life doesn't.) On the other hand, Conway had some very specific criteria for the rule he was looking for. \"B3/S23\" is about as simple a set of rules as you can find for a range-1 Moore-neighborhood outer totalistic cellular automaton on a square grid. So unless Conway's eye had happened to get caught by some slightly more complicated rule before he and his team happened on B3/S23, he'd be quite likely to settle on \"B3/S23\" all over again. It's one of the few candidates for the simplest rule that does obviously interesting things and seems likely to allow for computational universality. I mean, there are untold numbers of equally promising rules in larger rulespaces like the \"isotropic non-totalistic\" rules https://conwaylife.com/wiki/Isotropic_non-totalistic_rule ... but most of those have rulestrings like \"B2ci3ai4c8/S02ae3eijkq4iz5ar6i7e\": it's just not anywhere near as simple to describe the rules, as it is for Life. --------------- If we meet up with an alien civilization some day, it would be extremely amusing if we happened to show them some Life patterns and they said (in so many words) \"Hey! You know about Pnurflpeef's Game of Life?!?\" Not a likely scenario, by any means, but not quite impossible either. reply alextheterrible 18 hours agoprevThis post was funny to read thinking OP was referring to the old \"Game of Life\" board game. https://en.m.wikipedia.org/wiki/The_Game_of_Life reply BinRoo 19 hours agoprevDo you subconsciously see gliders and other patterns in your day to day life? In your dreams? reply dvgrn 19 hours agoparentIf a glider shows up somewhere by accident, like in an an otherwise random-looking arrangement of floor or wall tiles in a bathroom or somewhere, then I'll certainly pick it out immediately (and be unwarrantedly cheerful for the next half hour or so). But that doesn't happen all that often. It seems like I rarely have dreams about Life patterns, though it does happen. Maybe some people with better-resolution imaginations might have a different experience, but Life patterns need a lot of precision and focus, and in my dreams everything is always fluid and shifting and I can never find my car keys or my homework, let alone any interesting Life configurations. reply abetusk 19 hours agoprevThis is not a question about GoL directly but more generally about CA. Do you have a sense for what the probability of a random CA is to be TME? Do you have any idea of how to automate the process, if not in general, then at least for a class of CA? reply dvgrn 15 hours agoparentThis is a very good question, but I'm not sure I can give a very good answer. I'm not sure the \"probability\" part of the question is even well-defined, let alone answerable, unless you state a specific rulespace -- two-state range-1 Moore-neighborhood CAs on a square lattice, or three-state range-2 isotropic CAs on a hexagonal lattice, or what have you. Basically, you just have to be able to demonstrate a working universal logic gate (a NAND gate or a NOR gate) in a candidate rule, and you've pretty much got Turing-machine equivalence. The problem is, a lot more rules are computationally universal than you'd think when you first look at them. This is because it's often possible to get a candidate rule to act like a completely different rule, by filling the universe with something other than empty space. So you can't just try out a few random-soup patterns, dash off a quick proof that \"this rule necessarily explodes uncontrollably in all directions, so it's impossible for any circuitry to survive\" or anything along those lines. What if you start with a universe of all ON cells, or a checkerboard of ON and OFF? There are lots of rules where signals can propagate beautifully through that kind of non-empty medium, and occasionally some kind of Turing-complete mechanism might be found there, along the lines of what Matthew Cook did with Rule 110. So you really have to look at a lot of options before you can say for sure that a rule does not support universal computation -- and so far, it seems like a very tricky problem to automate the process of looking. reply robdpi 4 hours agoprevWhat is so special about the game of life? how does it differ from some simple game mechanics found in other videogames? The aim of this question is to understand what motivates and fuels passion for yourself and people in your community reply dusted 3 hours agoparentYour question also demonstrates that you've not done any effort at all to find out what game of life is. reply eimrine 19 hours agoprevI would like to see a setup which is going to spawn as much dots as possible, I mean something like a gun but having as little static elements as possible while creating as much gliders as possible. reply dvgrn 15 hours agoparentThe \"spawn as much dots as possible\" sounds like a spacefiller: https://conwaylife.com/wiki/Spacefiller But that's maybe a little too static for the \"creating as much gliders as possible\" part. You might like the glider-gun version of \"Jason's p156\": https://conwaylife.com/wiki/Period-156_glider_gun Or ... this last year or two have seen an impressive number of new glider-gun discoveries, where a very active small \"engine\" produces a dense stream of gliders: https://conwaylife.com/wiki/Period-24_glider_gun#Other_perio... https://conwaylife.com/wiki/Period-25_glider_gun https://conwaylife.com/wiki/Period-48_glider_gun https://conwaylife.com/wiki/Period-15_glider_gun https://conwaylife.com/wiki/Period-16_glider_gun reply eimrine 13 hours agorootparentThank you for perfect answers! Seems like a binary symmetry plays some role in this game because both configs are so. And I am amazed that Period-156 has a quadro symmetry!!! (at least if I refuse to consider it as a static image). Are there any configs (I mean, those having any interesting behaviour) with intention having more than 4 symmetry parts? Or at least just more quadro symmetry configs? I am absolutely sure (since today) there are some for any 2^n, just all unfound. Any attemts to create Conway's life on hexagon map with apropriate rules? upd: for a single stream of gliders, what config gives as many gliders per 100 generations as possible? No matter what else it does, I just want a line of gliders with as little space as possible. reply dvgrn 9 hours agorootparent-- It's interesting to look at the different symmetries on Catagolue, where the idea is to generate a lot of random soups with different symmetry types, and then just run those patterns and see what comes out. The D8_1 and D8_4 symmetries are 8-way symmetric, which is as high as you're going to be able to get on a square grid. https://catagolue.hatsya.com/census/b3s23/D8_1 https://catagolue.hatsya.com/census/b3s23/D8_4 Scroll down to the bottom of those pages and click on, especially, some of the higher-period \"xq{N}\" categories. These are objects that showed up \"naturally\", evolving from random soups. -- There have definitely been a number of people over the years exploring various outer-totalistic rules on a hex grid, and (to a lesser extent) isotropic non-totalistic rules: see https://conwaylife.com/wiki/Hexagonal_neighbourhood -- The smallest period at which gliders can follow one another is period 14. We don't have a true period-14 gun yet, though. The closest we have is a \"pseudo-period\" gun -- actually period 28, but it generates two gliders per period, so you end up with a period-14 stream: https://catagolue.hatsya.com/object/gun_14/b3s23 reply franze 19 hours agoprevNot a serious question, but what should I improve to make my g.o.l. background cooler @ https://www.franzai.com/ ? reply dvgrn 14 hours agoparentThat background seems pretty cool as it is -- I like the changing colors. Maybe try playing with depth as well, along the lines of the T=450 point of the LifeViewer demo pattern here https://conwaylife.com/wiki/LifeViewer -- or go for broke and steal some code from https://oimo.io/works/life/ for an infinite zoom into (or out of) a fractal Life pattern. reply chapliboy 19 hours agoprevWhat do you think about other forms of cellular automata? I came across excitable media recently and found it fascinating. Do you have any other examples of cellular automata you found interesting or worth pursuing? reply gonlad_x 18 hours agoprevCould the Game of Life run Doom, since it's Turing-complete ? I remember seeing an excerpt of a video where you could run the Goal inside the GoL. reply Mateon1 18 hours agoparentYes, you'd just need to have a way to provide input (probably easiest as a demo file), and a machine big enough to simulate the pattern. You'd definitely be waiting for a while to see any action, though :P reply fudged71 13 hours agoprevHave there been any interesting applications of fuzzy logic or neural nets for rules? reply bilsbie 19 hours agoprevI e always wondered are there setups in GOL that seem to go on forever with new patterns or does everything ready a static or repeating state? reply DylanDmitri 19 hours agoparentSome can be constructed with varying levels of success. Default Golly comes with an “infinite novelty” scenario; it’s worth checking out for a couple hours. reply dvgrn 13 hours agorootparentYup, it doesn't take a very big starting pattern to produce likely infinite novelty -- though it's not always easy to prove that any given pattern won't eventually unexpectedly \"go boring\" due to some kind of unexpected feedback effect. Life being Turing complete, it's also not difficult to build a pattern with an unknown fate -- like a Fermat-prime calculator that will stop growing if it ever finds a sixth Fermat prime, or the Collatz-sequence simulator described here: https://conwaylife.com/wiki/Fate#Unknown_fate reply sitzkrieg 10 hours agoprevThank you for sharing your curiosity with the world reply lamename 19 hours agoprevWhat are the best ways to keep up with GOL developments? Links you posted and hobbyist forums, formal research papers, or something else? reply dvgrn 14 hours agoparentWe've tried a lot of different methods over time. Currently the LifeWiki -- https://conwaylife.com/wiki/Main_Page -- is the most likely central location; any sufficiently big news will probably find its way into the CurrentNews pane, sooner rather than later. For a couple of years I've been trying to keep up with an informal summary of new developments, in an email-newsletter form mostly intended for \"old-guard\" Lifenthusiasts: https://conwaylife.com/forums/viewtopic.php?f=7&t=5650 As I mostly expected, it ends up being a bit too much work for one person to do properly. But the back issues there do go into a bit more detail than there is room for in LifeWiki CurrentNews back issues. reply poulsbo 19 hours agoprevDid you ever meet or interact with Conway? reply dvgrn 19 hours agoparentNot quite, unfortunately! I almost had the opportunity, briefly, in 2019 when I was contributing some patterns to a short film that Will Cavendish was working on with Conway, called \"Thoughts on Life\": https://www.thoughtsonlifefilm.com/ But there was never really a good excuse to arrange a meeting, given Conway's very fragile health at that point -- and then COVID came along. Conway regularly attended the bi-annual Gatherings for Gardner in Atlanta for quite a while, but by the time I started attending he could no longer travel that far. reply telcal 7 hours agoparentprevNot the author but I'd often seen him at the local coffee shop in Princeton reading or working. He was incredibly kind and generous with his time (I also made sure to not ask about GoL because I'd read about his feelings regarding it). He even showed my 6 year old a few puzzles. Even though we'd see him all the time, each time was like seeing a celebrity for me. reply x86x87 19 hours agoprevGiven a torus what initial configuration yields the maximum number of unique generations? :) reply simonbarker87 17 hours agoprevDo you think asking a candidate to implement GOL in a 45 minute live coding exercise job interview and then expecting a fully working implementation if it’s clear they have never come across the problem before? Devs I ask this come down 50:50 on if it’s reasonable or not. reply sp332 16 hours agoparentWhat is the environment? What language and frameworks are you testing them on? reply dvgrn 16 hours agorootparentAnd what are these hypothetical candidates interviewing for, exactly? In the '80s and '90s, every time I got a new computer, one of the first things I'd do is write a very simple CGoL simulator, and then sit back and marvel at how much faster it was than the previous PC was. So personally I guess I would have aced that question, in any number of languages and platforms... and yet I'm not really a particularly good programmer. It took me quite a few new-computer cycles before I started wandering down the various optimization rabbit-holes -- https://conwaylife.com/wiki/Tutorials/Coding_Life_simulators -- and I never got anywhere near as far as either HashLife or QuickLife. Now I just happily use other people's nicely optimized code, for the most part. So... it's a problem that a sufficiently nerdy programmer type of a certain age will be very likely to have encountered before, and you'd learn completely different things about a candidate depending on the level of that past experience. reply ugh123 17 hours agoprevDo you see a role for generative AI to discover new patterns? reply dvgrn 8 hours agoparentI don't want to say that there's no possible role for AI in Life research, but it's hard to see how something like ChatGPT can be helpful. 1) The placement of a single cell in a huge pattern will very often make the difference between a working Life pattern and something that catastrophically implodes. So making a generative AI like ChatGPT do any work on Conway's Life is very much like making it play chess: sooner rather than later, something really important will end up slightly out of place, and ChatGPT will have no way of knowing. 2) Unlike a lot of other subjects where ChatGPT really shines, Conway's Life is an incredibly niche subject. There simply isn't anywhere near enough training data for ChatGPT to give reliable results, even for fairly basic questions: https://conwaylife.com/forums/viewtopic.php?p=183306#p183306 3) However, there are definitely a number of areas of Life research where other types of AI might end up coming in very handy -- e.g., in monitoring and tuning parameters for very long-running and difficult searches. For this we need something much less like ChatGPT and more like Douglas Lenat's EURISKO, to try new experiments and learn what it can from the results ... EURISKO also happened to come up on Hacker News today: https://news.ycombinator.com/item?id=40128285 We just can't rely on generative AI to re-shuffle what is already known and make it into a nice new package, when what we're searching for is something that's never been seen before. reply chrislloyd 19 hours agoprevWhat is something that you think the average HN user would find useful/surprising about Life? How could it apply to their daily lives? reply dvgrn 19 hours agoparentHeh, I think I can find answers for \"surprising\" a lot more easily than for \"useful\". The main practical use for Conway's Life is as a teaching tool, giving a nice explorable example of layers upon layers of incredible complexity that can arise from very simple rules. So I suppose that people who can benefit from that kind of insight might find Conway's Life \"useful\", in a way -- engineers, mathematicians, and just anyone who is curious about the universe we live in and the physical laws that seem to underly its behavior. The big surprise that I've been spending the most time on lately is the utterly strange result that if you can build something by colliding gliders together -- no matter now many gliders and no matter how big the final pattern is -- then you can also build it by starting with exactly fifteen gliders in an otherwise empty Life universe: https://biggieblog.com/building-arbitrary-life-patterns-in-15-gliders/ It's a mind-bending result -- partly just a mathematical trick, since you end up encoding a whole lot of information in the space between the gliders -- but it's just really amazing that all the details have actually been figured out to make the trick work, and that it's possible to simulate the whole process on a personal computer. reply wizard_of_null 19 hours agoprevWhat is in common between the bazillions of CGoL implemetations? Is convergance possible? reply anthk 18 hours agoprevYou would like subleq/muxleq languages them. reply m3kw9 15 hours agoprevWhat has the Conway game of life done for mankind lately? reply dvgrn 13 hours agoparentIt's made a lot of Lifenthusiasts happy, and that's not nothing I suppose. It has also taught a lot of people a little something about the likelihood of emergence of complex behavior from very simple iterated rules. And maybe you could say that several of the larger collaborative Life projects that have happened recently have been very good examples of non-political international co-operation, in a world that these days seems like it could use a few reminders that such things are still possible. reply larsrc 19 hours agoprevWolfram's \"A New Kind of Science\" posited the study of cellular automata as a revolutionary new field of science. Did you agree then? Do you now? If you changed you mind, why? reply dvgrn 17 hours agoparentI've never had a good short answer to this kind of question. It's much more of a twenty-page essay question, with a lot of subtleties to dive into. I've tangentially crossed paths with Stephen Wolfram off and on for a bit over a decade now, starting with attending a Wolfram Summer School session -- https://education.wolfram.com/summer-school/alumni/2011/ -- and every few years someone from Wolfram Research will show up for an email discussion about one interesting topic or another. I'm more of a \"determined hobbyist\" than a proper theorist along the lines of Ed Fredkin, though, so while I'll enthusiastically agree that _A New Kind of Science_ documents a whole lot of fascinating stuff... I might not be the best judge of whether it all adds up to something that should be called \"revolutionary\". (I'm quite sure that I don't do anything \"revolutionary\" myself -- I just try to encourage Conway's Life research to continue. Discoveries have kept building on previous discoveries for fifty years now, and I'm just really curious to see what will happen next.) reply PeterStuer 16 hours agoparentprevHe has since stated fixed geometry models are not sufficient and has moved on to graphs. reply sdwr 18 hours agoparentprevOoh answer this one! reply przeor 15 hours agoprevWhy you are so clever than 99.9999% of the world's population? reply dvgrn 13 hours agoparentI'm not -- I'm just more of a Conway's Game of Life expert than 99.9999% of the world's population. But that's just due to experience and invested time, not cleverness. Could probably add at least one more nine to the end of that number, and maybe two ... the CGOL community is very widely dispersed geographically but it's really very small. There just aren't very many Conway's Life Expert candidates out there! For me to hit 99.999999%, there would have to be fewer than eighty people out there who have more knowledge about Conway's Life than I do At least for certain topics -- like the reverse caber tosser, for example -- https://conwaylife.com/wiki/Reverse_caber-tosser -- I'm fairly confident that I can list pretty much every person in the world who has a deep knowledge of the workings of 15-glider RCT universal construction ... and there are a lot less than eighty of them. reply ohwellhere 19 hours agoprevHave you read Alien Information Theory: Psychedelic Drug Technologies and the Cosmic Game by Andrew R. Gallimore [0], and do you have any thoughts on his cosmology vis a vis cellular automata? And perhaps also the same question related to Stephen Wolfram's physics project? [0]: https://www.amazon.com/Alien-Information-Theory-Psychedelic-... reply precompute 19 hours agoprev [–] Shouldn't this be a \"Ask HN\" or something similar? Also, let's not make AMAs a thing on HN. Better to post an interesting link and then engage with people in the comments. reply dvgrn 18 hours agoparent [–] I did a bit of homework before posting this, and there were just enough Hacker News hits on \"AMA\" (from Sam Altman, Peter Roberts, etc.) that it didn't look like there would be any harm in trying this experiment. I could certainly try an \"Ask HN\" at some point, but haven't been able to think exactly what question I would ask. \"How many people know what a reverse caber tosser is?\" is one that I'm curious about, but I suspect I'd get mostly just crickets. Really I wanted other people to ask questions... and I'm having lots of fun with the results so far! reply pvg 12 hours agorootparent [–] it didn't look like there would be any harm in trying this experiment There isn't any harm, if anything, more experts, accidental or otherwise, should do this. reply precompute 2 hours agorootparent [–] There is harm, yes. Regularly hosting AMAs will turn this website into a social platform like reddit. Regular discussion will die down as personalities take over. It's the quick road to decline. The internet isn't what it used to be, public forums need to be guarded from the influx of low-quality commenters that consider everything a social platform first and throw regular, on-topic discussion out of the window. In time, low-quality and high-quality commenters form two groups and when they interact, the high-quality commenters leave. reply pvg 1 hour agorootparent [–] The site is a social platform as it is and AMAs by knowledgable people that fit the forum are totally fine on HN. 'HN is turning (or is going to turn) into reddit' is trope as old as the site. This post and its thread were of higher quality than most HN threads so if something is going to ruin HN, it's not going to be this AMA. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author joined the Conway's Life research community in 2001 after finding a \"boojum reflector\" and has since supported Life-related resources like mailing lists and blogs.",
      "They contributed to a 480-page textbook on Conway's Life and are considered an expert on the topic, willing to address any related inquiries."
    ],
    "commentSummary": [
      "The text delves into Conway's Game of Life, a 2D cellular automata system, including its applications, advancements, and challenges, along with related topics like Wolfram's work on cellular automata.",
      "It discusses practical applications of Game of Life patterns, the limitations of AI in discovering new patterns, and the impact of presentation choices on mathematical art, highlighting the emergence of complex behavior from simple rules.",
      "The conversation underlines collaborations in Life projects and the potential for further exploration and experimentation in this field."
    ],
    "points": 294,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1713878062
  },
  {
    "id": 40134921,
    "title": "Apple aims to boost CarPlay adoption through deeper integration and monetization",
    "originLink": "https://www.theturnsignalblog.com/apples-risky-bet-on-carplay/",
    "originBody": "Drivers love CarPlay. Apple's WWDC 22 keynote revealed that 79% of drivers only consider a car if it has CarPlay. And it's easy to see why. Even compared to the best native infotainment systems, CarPlay does several things way better. Best Services I use only three apps when driving: Google Maps for navigation, Spotify for music, and Castro for podcasts. The number of cars on sale today with these three apps available is zero. This is a little unfair because Castro is a small, iOS-only app. There are a couple of carmakers that use Android Automotive with Google's services, which means they natively support Google Maps and Spotify. But it does mean that if I want to listen to podcasts in these cars, I have to change my podcast app to one available in the Play Store. Seamless Experience Continuing with the above example, let's imagine I just downloaded a new podcast app on my phone (one that is also available in the automotive Play Store). The next day I have to go on a long drive and I want to listen to a podcast episode I downloaded on my phone. When I enter my car, I have to go to the Play Store, find the app, download it, log in, and then download the episode. When I use CarPlay, I only have to connect my phone. No matter how many services are available inside the car, there is no match for seamlessly transferring the phone's state to the car. Familiar Design Cars have too many features and most are designed differently. Even functions like climate controls can vary greatly between car brands. It's reassuring to know that no matter which car I drive, the most complicated part of the interior works exactly like my iPhone, and is set in the right language, with my preferences, and my favorite apps. Longevity Entering an 8-year-old car and having access to the latest CarPlay version is amazing. By untying the fastest aging part from the rest of the interior, it can remain relevant longer. Especially given that the car industry is switching to running third-party Android apps with no history of long-term support. The Ferrari FF was one of the first cars with CarPlay The Next Version of CarPlay The first version of CarPlay has been available since 2016 and has been a major success. For car industry standards, it was adopted quickly and by almost every carmaker. But since then, the car industry has been changing while the design and functionality of CarPlay have mostly stayed the same. With lower hardware cost and an increased focus on software, carmakers have invested more in their interiors to set themselves apart. Google jumped on this opportunity by releasing Android Automotive. Unlike Android Auto, Google's equivalent to Apple CarPlay, Android Automotive runs natively inside the car and any carmaker is free to use it. Google monetizes it by licensing its 'Google Automotive Services' to carmakers. This gives carmakers access to Google's services like Google Maps, Waze, the Play Store, and Google Assistant. The Android Automotive infotainment system with Google Automotive Services of the Polestar 4 Competition aside, from Apple's perspective, CarPlay is also not ideal in its current form. For a company that values control over the user experience, it's an eyesore to see their product embedded inside another product. The integration of CarPlay looks awful in some infotainment systems Apple's answer is a new version of CarPlay. It doesn't have an official name, so I'll refer to it as CarPlay 2. Today, CarPlay is a standard that carmakers can use to pass a video signal from the phone to the head unit and return input events. There's only a limited connection with the vehicle. This is changing with CarPlay 2 which has a deeper integration with the vehicle. The concept Apple used to introduce CarPlay 2 Thanks to a deep integration with the software stack of the vehicle, CarPlay 2 can control most infotainment functions. It can therefore take over the entire infotainment display, the instrument cluster, and any passenger displays. For customers, it will appear like CarPlay works exactly in the same way but underneath, a lot of custom work is necessary by the carmaker and Apple to integrate. For example, even though most of the computing power still comes from the iPhone, there will be some software engineering necessary on the carmakers' hardware to ensure that safety-critical information like speed doesn't disappear when the iPhone crashes. Apple is fully dependent on the carmaker's willingness to work with them to implement this. This is why the WWDC keynote was clearly a pitch aimed at carmakers, not consumers. But so far, on the surface, it seems like carmakers have not been eager to implement the new version. Mercedes was supposedly on board according to Apple's WWDC slide, but its CEO seemed less enthusiastic in reality. Apple also announced it would show the first brands in 2023 and barely made that deadline by announcing Porsche and Aston Martin only two weeks before the end of the year. The concepts from Porsche and Aston Martin Why Are Some Carmakers Hesitant to Integrate CarPlay 2 There are two camps among carmakers. There are brands like Porsche and Volvo who recognize they can't compete with Apple and Google in infotainment and want to work with them, while other carmakers see them as a threat. The first group of carmakers has likely already been working with Apple to integrate CarPlay 2. One reason why it has been mostly silent around it is that it can take years to release something that touches complicated software and hardware, requires a collaboration between Apple and the carmaker, and all in the long development times of the car industry. That is why I'm sure we will see more brands announced soon. However, some carmakers aren't jumping to work with Apple. The reason for this mostly comes down to who owns the in-car experience, and here is why. Brand Differentiation There used to be a big difference in driving characteristics and technology between premium and budget brands. Compared to a Volkswagen, a BMW used to have a more powerful engine, better handling, and comfort features like seat-heating and cruise control. However, a Volkswagen Golf now has similar tech as a BMW and with the transition to EVs, drivetrains and handling won't be the same differentiator as before. Now, the focus has moved to the interior. Infotainment systems have become a central part of that, so carmakers are coming up with unusual concepts to set them apart, both in hardware and software. CarPlay 2 is going exactly in the opposite direction, more towards standardizing the in-car software. Carmakers want to differentiate through unusual interior concepts A lot of the concerns around branding focus on the instrument cluster as it's one of the most recognizable parts of an interior. If you look at the CarPlay concept for Porsche and remove the steering wheel, there is no way you can tell it's a Porsche. I'm sure many brands took notice of this. If you remove the steering wheel, there is no way you can tell it's a Porsche Lack of Design Control With many traditional differentiators being democratized, design is a good way to stand out. An EV drivetrain may not be that different between cars, but it comes with the added burden of charging and route planning. Premium brands can offer a better experience than budget brands. For example, Tesla's route planning is a major unique selling point. No other EV brand offers the ease of entering a car, planning a route, and setting off without worrying about the charging experience. Tesla could only have done this by creating their own routing algorithm. It would have been impossible if it had relied on Google and Apple. In some way, brands using a native Android infotainment system with Google's services have a similar challenge. But these brands also happen to be the ones that are eager to work with Apple. Monetization Carmakers are envious of big tech's app store and services revenue. With their own software platforms, they are desperately trying to find recurring revenue streams, whether it's a subscription for seat heating or driver assistance systems. But it won't be possible to sell a subscription for a feature when all is controlled by Apple CarPlay. Many cars already come with these awful popups Integration Cost vs. Value Most carmakers offer the current CarPlay version. It doesn't require much effort as they only have to implement the CarPlay standard and have the hardware certified. CarPlay 2 requires a lot more work but does it offer significantly more value? As mentioned above, the core benefit of CarPlay is access to your favorite apps in a familiar design. CarPlay 2 offers more features and a nicer experience but will customers choose a car because it has CarPlay 2 over a one with CarPlay 1? Many carmakers think not and are happy to wait and see where the market is going. CarPlay 2 is also not a full substitute for an infotainment system and not all new car customers are iPhone users. Carmakers spend millions making their infotainment systems, so why would they spend even more to work with Apple on something that is an add-on, and not for all customers? Apple's Risky Strategy Unlike Android, which carmakers can customize extensively, Apple avoids turning CarPlay into a full native infotainment system. The reasons are clear: carmakers vary widely in display layout, features, and safety-critical software. Apple would have to give up control over the software and design to carmakers, or invest massively in adapting to each brand itself. Consequently, Apple tries to take over as much of the in-car experience with a software and hardware platform that they totally control. This means that any customization requires investment from Apple's side. From a business perspective, Apple must find the sweet spot between offering enough customization to satisfy carmakers while keeping investment at a minimum. Especially considering that, even though it indirectly boosts app store, services, and iPhone revenue, CarPlay is free for carmakers. Apple’s long-term goal is likely to find ways to directly monetize CarPlay. It could license CarPlay to carmakers at some point. But with the entire global car market amounting to only around 70 million cars per year and the car industry’s slim profit margins (ranging from 5% to 15%), it must reach a high market share to get significant revenue from it. However, carmakers may be hesitant to invest in what they see as a competing product. What Can Apple Do to Convince Hesitant Carmakers? Apple can do two things to accelerate the adoption of CarPlay 2: tailor more to the wishes of carmakers and turn CarPlay 2 into a major purchasing reason for consumers, forcing carmakers to adopt it. Apple has many opportunities to explore to achieve that. More UI Customization It's very difficult for Apple to find a balance between creating a UI that is clearly 'Apple', that is at the same time custom enough to the carmaker, allows drivers to personalize it, and requires minimum design and development cost. From carmakers' perspective, current concepts are leaning too much towards Apple in that balance. But there are ways to improve this. One great example is the collaboration between Nike and Apple for the Apple Watch. The Apple Watch Nike offers different watch faces with custom fonts that bring branding from Nike into a design that is still unquestionably Apple. The Apple Watch Nike has different branding than the normal Watch Allowing similar changes to CarPlay with more elaborate dials and carmakers' own fonts would already be better: Allowing for custom fonts already makes it look more like a Porsche interface Third-Party Integrations Apple won't let carmakers alter the operating system, but they can provide a way for carmakers to add custom features through third-party integrations. For example, Porsche could create a track-driving app that can display a widget in the instrument cluster, or Land Rover could create a widget for displaying specific off-road-related information. It will allow carmakers to offer unique features while staying inside the CarPlay environment. A concept for a Porsche track-driving widget Passenger Entertainment Passenger entertainment will be a big focus in the coming years. With cheaper display prices and changing customer expectations, we will see more cars with screens for passengers. So far, they have been quite useless and carmakers are struggling to improve the experience. Apple owns this domain with Apple TV and Airplay. A mix between CarPlay and Apple TV would create the perfect passenger experience. As carmakers will continue to struggle to provide all the popular services inside the car, it's a real selling point for CarPlay. Revenue-sharing Missing out on potential service revenue is one reason why carmakers are hesitant to adopt CarPlay 2. Apple could implement several ways for revenue sharing. For carmakers, offering their services inside the Apple ecosystem has benefits because it is a trusted platform and everybody has accounts and payments set up already which means they reach a wider audience. Apple could create a way for carmakers to offer upgrades and subscriptions through CarPlay, the App Store, or other channels, and share revenue with them. Create the Best Navigation Experience Carmakers hesitate with CarPlay because they think they can compete with tech giants by building their own navigation services, payments platform, and app store. However, so far, only a few of the existing services are actually good enough. Most drivers prefer Google Maps but even that leaves a lot of room for improvement. There isn't really a navigation app that sticks head and shoulders above the rest. Apple has an opportunity with Maps to turn it into the ultimate navigation and route-planning app. I'd love to be able to plan a route, reserve a charger, and pay for parking inside one app. If Apple Maps and other Apple services are the preferred ones by drivers, they may be more likely to choose a brand with a deep CarPlay integration, pushing carmakers to adopt it. Apple Maps is already the most beautiful navigation app out there Expand Non-CarPlay-Related Car Interactions Carmakers see their cars as the center of the universe, but in reality, a car is more part of an ecosystem. Apple is the best at creating a holistic experience across all my devices and cars can be a part of that. I want to control the cabin temperature from the Apple Home app, see my battery status in the Apple Maps app, use my iPhone to unlock my car, and remotely customize the instrument cluster. These are the kind of features that carmakers will forever struggle with and show the real benefit of CarPlay. Apple is going in a different direction than Google in the automotive industry. While maintaining full control over software and hardware is a smart move, it demands significant investment to integrate and adapt to each carmaker. For Apple to remain dominant in the car industry and explore future monetization opportunities, it must convince most car manufacturers to come on board. It's not possible to say how many brands are currently working with Apple to implement it. Due to long development times and some public comments by carmaker executives, it may appear like Apple is struggling to get carmakers to adopt it but I wouldn't be surprised if most brands that Apple presented during WWDC 2022 are currently implementing it. However, it's also true that CarPlay competes directly with carmakers' own systems which makes some hesitant to integrate CarPlay in its current form. To convince those carmakers, Apple has many opportunities to adapt CarPlay should it need to. Once the first cars with CarPlay 2 are in the showrooms, it will be interesting to see whether it will influence purchasing decisions. I'm a big fan of the CarPlay approach of extending the phone to the car and standardizing the design to some extent across the industry. I will be rooting for CarPlay 2 and I can't wait to try it when the first cars hit the road! New post notification Receive an email when I post a new article Don't worry, I won't spam you with anything else Recent posts Apple's Risky Bet on CarPlay April, 2024 Mixed Reality: The Future of Automotive UX Prototyping March, 2024 The Problem With Digital Instrument Clusters and How to Design a Better One January, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40134921",
    "commentBody": "Apple's risky bet on CarPlay (theturnsignalblog.com)215 points by vsdlrd 16 hours agohidepastfavorite413 comments mannyv 15 hours agoCarPlay mostly works, and although it has issues it's definitely user-focused. CarPlay doesn't prevent car makers from tracking vehicle activity. In the end, consumers don't give a shit about the in-vehicle infotainment. It sucks, or it's AA/CarPlay. The first generation of iDrive showed that rich people people will buy cars in spite of the in-car stuff. In fact, most car infotainment sucks, yet people still buy cars. Let's turn the question around: why would car makers want to spend millions of dollars a year rolling their own infotainment system? So they can make incremental revenue selling ads and user data? So they have control? Control over what, exactly? reply numpad0 11 hours agoparentI wonder how much of those frustrations has to do with Japanese market share of car industry; I think the touchscreen infotainment is not there because car manufacturers value it as integral and central part of car experience but simply because otherwise their product loses against one of Japanese brands. Japanese road network is a disorganized weighted node graph and absolutely not a grid, and a bulletproof navigation unit has been a must for a car in Japan since its inception around 1990. It is also preferred that they are 2DIN compatible so it can be later upgraded. AFAIK, those are not high priority checkbox items elsewhere, but all cars nevertheless follow the Japanese manufacturer layout because of manufacturers' collective dominance. Cars before 2DIN navigation units seem to have had 1DIN AM/FM radio units with radio buttons[1], by the way. That dominance leaves a 4:3 8\" diagonal hole in immediate view of driver for all cars globally that must be filled with something of value. That doesn't have to be a touchscreen but usually are, and it ends up being a navigation-audio combo unit, and it's outsourced to the lowest bidder. It is not the primary interaction point for cars by overwhelming global demands or principles of automotive product design. That leads to jarring subpar experience that appear to be but are perhaps not intended to be part of core UX of the whole car. I think. 1: https://www.alamy.com/1956-mercedes-benz-190-sl-steering-whe... reply Xixi 1 hour agorootparentI'm not quite sure what you mean by saying that the Japanese road network is not a grid. In terms of actual layout, it's quite grid-like. I would even say it's usually much closer to a nicely laid-out grid than the mess any European city is. What Japan lacks are addresses that can be found easily without using a map. Apart from Kyoto, roads in Japanese cities don't have names (or number), so addresses within cities are not \"{number} {name of street}\". Cities are cut in areas smaller and smaller all the way down to a block. The last number will be the house on that block. So addresses within cities are \"{name of area} {sub-area number} {block number} {house number}\", with some variations from city to city. An address might be \"Nantokacho 11-16-8\", which means the 8th house around the 16th block of the 11th sub-area of the Nantoka area. Good luck figuring that out without a map! reply throw0101c 9 hours agorootparentprev> That doesn't have to be a touchscreen but usually are […] With back up cameras being mandated in the US (and other jurisdictions?): * https://www.cnbc.com/2018/05/02/backup-cameras-now-required-... There needs to be a screen: I'm not sure what the incremental cost is of it being touch-sensitive. And I think a lot of designers (or cost cutters) may have figured that since they have to have software anyway, it may easier/cheaper to deal with software buttons than with moving parts like physical buttons and dials. reply toast0 6 hours agorootparentI'm pretty sure a touchscreen is cheaper than buttons, or at least awful close. You'll still get some buttons, unless the car maker really hates you, and hopefully something to turn for volume control (which may even work most of the time, if you're lucky). reply jajko 1 hour agorootparentTouchscreen is such a stupid low value move for driver. Physical knobs are safer in many ways, last much much more, I don't need to lose contact with whats happening in front of the car to manage these, just muscle memory. BMW has nice big physical knob (turn&press) to control all menus, much better than hunting on flat glossy screen with fingers. Some stuff can be managed from steering wheel, but instead of putting there things like AC there are voice controls, while we all know very well this increases danger on the roads and calls shouldn't be made while driving. That being said, I choose (used) cars based on many metrics, and this is just one of them and not the most important one. So its sort of self-inflicted move to worse. reply ryandrake 11 hours agorootparentprevDon't Japanese people have smartphones or tablets with navigation on them that they can use? I'd rather cars just have a place I can mount my own device, rather than include any kind of screen whatsoever with crappy un-updated, un-maintained software. reply johnwalkr 1 hour agorootparentThe Japanese navigation units in cars have been really good for at least 15 years. The signs and lane markings usually match exactly what’s ahead of you in real-life, and there’s a radio system on the highway gives traffic and road closure information even if you’re not connected to the internet. It’s only recently that smartphone apps are as good. reply astrange 7 hours agorootparentprevCars can have better GPS reception, which is important when you're trying to drive in an urban area with a lot of buildings. Phones are bad at accuracy there. (CarPlay can provide car GPS to the phone though.) reply katbyte 4 hours agorootparentMy iPhone 12 has much better reception then my 22 Tacoma even when tossed on the passenger seat. Like waaaaaay better and more accurate reply withinboredom 2 hours agorootparentIt just pretends to be more accurate by using AI. A car tends to be more raw, which is what you want when navigating at speed. As someone who used to help out with Waze maps, raw GPS tracks from phones can be WAAAY off from actual roads and other GPS tracks. Your phone looks for the most likely road for you to be on and snaps you to that road. Your car does a similar thing but has much higher GPS resolution than your phone so it is more likely to be right. reply WesolyKubeczek 1 hour agorootparentCould we please for once stop using the term \"AI\" when we mean \"heuristics\"? reply withinboredom 1 hour agorootparentPhones do use AI though, at least iPhones. They look at all sensors (accelerometers, gps, wifi, etc). reply lupusreal 49 minutes agorootparentSensor fusion is AI I guess. reply withinboredom 41 minutes agorootparentAI can be distilled down to a series of if-statements. That's basically all it is. reply lupusreal 3 minutes agorootparentRight, expert systems are GOF AI. What isn't? rusticpenn 1 hour agorootparentprevheuristics and Meta-heuristics are AI. Heuristics are how children (and adults) learn to solve new problems. reply t0mas88 1 hour agorootparentprevBut the in-car unit has both GPS (with the antenna being on the roof) as well as wheel speed. Noticeable in longer tunnels with traffic jams that make the speed vary. Then it's clear Google maps takes a random guess at where you are while the in-car system knows how far along you are. reply mavhc 1 hour agorootparentprevCars have wheel rotation and direction sensors so can do dead reckoning when the gps isn't being useful reply makeitdouble 10 hours agorootparentprevPhone navigation apps are surprisingly bad in Japan (Google ones in particular). Not unusable, but the in-car GPS is more competitive than in other markets IMHO. Also with an aging population a phone screen is just too small for many. BTW, to parent's point VW has been trying different approaches with a top mounted GPS/infotainment unit that can be omitted on cheaper trims. reply lobochrome 9 hours agorootparentThat's not true. Google Maps, in particular, has by far the best route guidance. It used to be different - but not anymore. Most in-car systems don't even attempt to route the last 300m here because the detailed one-way street narrow layout of tiny streets isn't in their mapping data, or their algorithms are too weak. Google has mostly no problem with that. Entering Japanese addresses IS tricky, though; here, custom-built Japanese solutions outshine. There are (mainly) no street names; instead, you specify your location by filtering down from Prefecture (Tokyo), City (Ota-ku), Commune (Kugahara), District (1-Chome), Block (26), House Number (1). Japanese systems allow you to enter it this way - with Google (or, even worse, Apple Maps), it's a bit hacky. You would specify it as Kugahara 1-26-1 and hope for the best. reply makeitdouble 9 hours agorootparentGoogle Maps fails in subtle but weird and sometimes costly ways. On one side, it can't route through a bunch of valid paths. I first assumed it could be because of residents asking Google to cut traffic, but sometimes it's not even through residential areas. I see routes on the map that are avoided in favor of bigger loops, and when trying the shorter routes they're perfectly fine. Or perhaps it's the vehicle size and they optimize for SUVs ? On the other side it will happily route you through paths that are restricted to specific categories of cars. It's up to the driver to carefully avoid them, but it really wants you to go through and reroutes you there when you deviate, so it's a huge PITA in areas you don't know and try to navigate while ignoring the navigation instructions. Cops seem to have noticed it, We've got fined the first time we fucked up, and now that I'm aware of the issue I see the cops in many of these spots basically waiting for the jackpot. reply bunabhucan 7 hours agorootparent>avoided in favor of bigger loops At this point at google, I wouldn't be surprised if they were selling your route to advertizers to \"optimize your driving experience.\" reply presentation 3 hours agorootparentprevI notice that Google Maps does very poorly on my iPhone 13 Pro with the multi-level roads, like riding around in the tunnels under Tokyo or on the roads with highways above the local roads, whereas builtin navigation units usually have no problems with this. I also find their directions to be much harder to follow than the built-in navigation units when riding around the major roads where turning right requires you to exit to the left for instance. Also, Google Maps fails to provide the variety of route options with fine-grained toll-booth costs, that all navigation units I've used in the last 5 years have gotten spot-on. reply pr337h4m 8 hours agorootparentprevWhy not use plus codes? They're well-integrated into Google Maps: https://maps.google.com/pluscodes/ reply makeitdouble 7 hours agorootparentTIL. The weird part is Maps will accept them for search, but not display the plus code except when looking at POI (randomly selecting a point on the map doesn't show it for me, I only could get that from the /pluscodes/ map) This seems genuinely useful, but as usual we're having the chicken and egg problem to get it adopted ? reply shagie 5 hours agorootparentprevJapan has some challenges with traditional GPS and satellites that can be low on and buildings interrupt the signal. https://en.wikipedia.org/wiki/Quasi-Zenith_Satellite_System > The Quasi-Zenith Satellite System (QZSS), also known as Michibiki (みちびき), is a four-satellite regional satellite navigation system and a satellite-based augmentation system developed by the Japanese government to enhance the United States-operated Global Positioning System (GPS) in the Asia-Oceania regions, with a focus on Japan. ... > The primary purpose of QZSS is to increase the availability of GPS in Japan's numerous urban canyons, where only satellites at very high elevation can be seen. A secondary function is performance enhancement, increasing the accuracy and reliability of GPS derived navigation solutions. The Quasi-Zenith Satellites transmit signals compatible with the GPS L1C/A signal, as well as the modernized GPS L1C, L2C signal and L5 signals. This minimizes changes to existing GPS receivers. Its got a neat orbit that does a figure 8 with the apogee over Japan (see also https://en.wikipedia.org/wiki/Tundra_orbit ) reply onethought 10 hours agorootparentprevAging population prefers low quality tiny screens with awkward interfaces? reply makeitdouble 9 hours agorootparentThey're not tiny, at least not compared to a phone. https://www.daihatsu.co.jp/lineup/move_canbus/03_exterior_in... reply 10u152 6 hours agorootparentDamn that looks like a cool car. Shame it's Japan only reply oneplane 9 hours agorootparentprevThey prefer something they are already familiar with. reply chgs 2 hours agorootparentThat’s one reason I use CarPlay - the interface hasn’t changed for years. Apart from one really annoying change to Apple Maps when they replaced the “silence directions” toggle from a big square to a touch, wait, touch tiny icon interface. reply drekipus 11 hours agorootparentprevIn car navigation came before mobile smart phones reply adamomada 7 hours agorootparentIronically, the nav unit I used on a rental car circa 2007-08 (birth of touchscreen smartphones) was exactly like the GP describes, a separate unit that had a mount like the modern smartphone variants. reply babypuncher 11 hours agorootparentprevThis is sort of the goal of Android Auto and CarPlay, but not as a mount for your phone. Rather, it turns the screen into a dumb terminal for your phone, bypassing all the shitty built-in software and providing a UX designed specifically for use while driving. reply mikepurvis 10 hours agorootparentAnd critically lets you directly access CarPlay interfaces to apps for streaming, podcasts, navigation, etc, all of which is much richer than a dumb audio only passthru with skip buttons. reply presentation 3 hours agorootparentprevI don't own my own car here, but whenever I ride taxis or rent cars in Japan I noticed that they almost all appear to have aftermarket infotainment units. This makes sense now! reply eloisant 1 hour agorootparentprevHonestly I would prefer to have a 2DIN hole where I can put whatever infotainment I want, instead of being stuck with whatever the car maker included, and that I can change without changing my car. reply Jtsummers 13 hours agoparentprev> Let's turn the question around: why would car makers want to spend millions of dollars a year rolling their own infotainment system? So they can make incremental revenue selling ads and user data? So they have control? Control over what, exactly? There's an interesting (and apparently often misunderstood) article called \"IT Doesn't Matter\" [0]. In it, Carr is largely arguing that IT, as a business differentiator, was over for many of the things people thought were differentiators. That is, things that helped a company (say American Airlines) get a lead on their competitors in the 1960s had become commoditized. Now every airline was offering flight search and booking online (directly and through aggregators). The IT edge had become table stakes, you didn't do it to beat out a competitor but just to stay in the game. And, even more importantly, many of the things that used to be IT differentiators became commoditized. Car infotainment was once a differentiator for car manufacturers or for classes of vehicles within the same manufacturer. Today, it's table stakes. Not all the manufacturers have figured that out (have any?). [0] https://hbr.org/2003/05/it-doesnt-matter and https://www.nicholascarr.com/?page_id=99 reply the_snooze 15 hours agoparentprev>Control over what, exactly? Planned obsolesence. Without proper CarPlay/AA integration, car manufacturers get to decide when those whiz-bang infotainment features stop working. You'd have to replace the whole car to get those features back instead of just buying a new phone. reply com2kid 15 hours agorootparentHeck simple bluetooth audio playback has degraded year over year in my car. After an android update a few years back I don't get to see the track name any more, pause/play sort of works, and thankfully audio still comes through and I can go to the previous/next track. Without constant updates, software that is part a a larger ecosystem will eventually breakdown. reply the_snooze 11 hours agorootparent>Without constant updates, software that is part a a larger ecosystem will eventually breakdown. This is why we should be so skeptical of tight software integration with durable hardware (e.g., cars and appliances with operational lifespans 10+ years easily). Software has a pretty short half-life, especially software that integrates with internet services; vulnerabilities get discovered in third-party components and remote APIs shift out from under you. Durable goods manufacturers have little skill or interest in long-term software upkeep (maybe they like the profits and the rent-seeking, but not the actual maintenance), so the most sustainable design is one where the software is easily seperable and replaceable from the core durable item. Manufacturer-specific internet-connected infotainment in cars ain't it. reply shiroiushi 5 hours agorootparent>so the most sustainable design is one where the software is easily seperable and replaceable from the core durable item. No, the most realistically sustainable design is one where the software is built into the durable item and not connected to the internet, so it never changes and doesn't need to worry about security issues. You can keep using the thing until it fails from mechanical issues and can't be easily repaired. If it's internet-connected for some reason, then the software should be open-source so interested parties can take over maintenance after the OEM decides they don't want to bother any more. However, I don't consider this \"realistic\": how many manufacturers are going to do this in reality? Almost none: they want you to buy a replacement device. reply kergonath 4 hours agorootparent> No, the most realistically sustainable design is one where the software is built into the durable item and not connected to the internet, so it never changes and doesn't need to worry about security issues. How would that work in a car, where people expect map updates and streaming music or radio over the internet? reply shiroiushi 1 hour agorootparentI don't think it would. I was really thinking more about things like home appliances. An embedded computer is handy for a washing machine, for instance, but it doesn't need to be connected to the internet (no, notifying you it's finished isn't necessary: the machine should tell you when you press \"start\" approximately how long it will take). For a car, I really don't know. I don't see any way of putting up-to-date navigation software into a dashboard without a significant security risk, which means needing the ability to keep software updated. Even CarPlay/AA are non-trivial and would need security updates. reply diffeomorphism 3 hours agorootparentprevJust like that. Robust, simple software, open standards a r/w partition for map data. Having well-defined, narrow access to the outside world is much easier to secure and keep working. reply s0rce 15 hours agorootparentprevDo people do that? I just use my phone beside the old useless infotainment. Honestly, I wouldn't buy a new car that used an in-house infotainment specifically because they go obsolete quickly ( Let's turn the question around: why would car makers want to... The tech giants are not component suppliers you can symbiotically partner with to add value to your product. They are predatory and parasitic goliaths. They are wolves more powerful than governments with designs on your hen-house. It is frankly insane to let them own the primary interface to your customer and auto will likely regret letting them get this far. Google/Apple infotainment ventures cannot even be called trojan horses given how open they are in their investments and desires to seize the auto industry the moment tech/profit makes it feasible. Unattractive low-margin manufacturing keeps them at bay but they are gambling on \"software eats the world\" long-term. For now, they will drain every available high margin service for themselves. reply potatolicious 15 hours agoparentprev> \"So they have control? Control over what, exactly?\" I think a key thing to consider is that there are in fact three separate questions at play here: 1 - Does infotainment/software UI differentiation matter in the car market? Is there a significant enough market advantage for having better UI that anyone should care? 2 - If there is an advantage for better UI, is it enough of an edge that would compel you to build your own? Or is it the case where it simply has to be good enough? 3 - If there is enough differentiation to be worth building your own, is your company good enough at software to pull it off? Personally I think the answer to #1 is YES. I think cars with better UIs - while not sufficient in and of itself - have a market advantage. Where car makers start veering off from each other is the answer to #2. If you believe that you just need a \"good enough\" experience to not be actively awful, then you buy off-the-shelf. You see this with Volvo/Polestar and Google Automotive. The \"skin\" around the stock experience is minimal at best, with only minor customizations. If you believe that being excellent at it confers some advantage, you'd try to roll your own. This would include folks like BMW and Mercedes-Benz. Now, where the latter strategy really goes off the rails is question #3. That said, if you believe the answer to the first two questions compels you to roll your own - would you easily surrender to a third-party? Or would you at least try to level up your software orgs to make a serious play? reply eloisant 1 hour agorootparentAndroid Automotive is already way beyond what manufacturers are releasing as \"their own\". So unless it costs a lot of money to integrate, not picking AA isn't about building your own that's better, but it has to be about control. Or at least independance from a big tech, which I can understand. reply anthony_d 13 hours agorootparentprevFor what it’s worth I agree on #1. I really like RR/Jaguar’s current UI. When I’m in a rental or someone else’s car and I’m forced to use CarPlay I hate it. Feels like I’ve been pushed to kindergarten and given crayons… any car manufacturer that just expects me to use CarPlay is probably not on my potential buy list. I might be unusual in my preference but I really expect people to have preferences as strong. reply vsdlrd 15 hours agoparentprevI thought about that as well. At the moment, CarPlay can't take over every function so carmakers still have to make their own. But in the long term, there is an opportunity for Apple to make the whole thing and monetize it as a cost-saver to carmakers reply krater23 15 hours agorootparentNo, never. This would mean to concentrate only to customers with Apple devices. Why should a carmaker do this? reply londons_explore 10 hours agorootparentI assume Apple would also provide code for a fallback UI that offered basic functionality for when you didn't have an iphone attached. reply eloisant 1 hour agorootparentSo everything turns green? reply kevin_thibedeau 9 hours agorootparentprevCarPlay poverty mode. Sign me up. reply bonestamp2 5 hours agorootparentBasically Valet mode for the headunit. reply babypuncher 11 hours agoparentprevGM's plan is to sell a subscription service that covers all the things you already pay for on your phone (maps, music streaming, etc). It's why they're killing CarPlay, because they know that even if their service is good, nobody will pay $20/mo for shit they already get for free on their phones. Basically, their goal in life is to be a worthless middleman who takes peoples money while providing no real value to society. reply jasondigitized 8 hours agorootparentHow is GM a middleman when they are producing the product I am buying which is a car? If GM bundled OnStar with a top tier infotainment / navigation / ChatGpt / I’m hungry where do I eat app, I’ll pay for that as long as it’s reasonable and lets me know I’ll be taken care of if I crash and need assistance. reply hedora 6 hours agorootparentThey are trying to be a middleman between you and the internet. It’s analogous to a TV and monitor manufacturer saying they are no longer providing non-wifi inputs, app side loading, or supporting screen casting from local devices. Then the manufacturer would charge a monthly fee for the monitor to keep working. Hopefully, next, the CEO acts surprised when reporting the resulting massive drop in shipments. reply eropple 7 hours agorootparentprevMaybe for you. If it doesn't exactly mirror the stuff on my phone, though, it's distinctly worse than using my phone. If it doesn't start playing music from my phone when I turn the car on, it's distinctly worse than using my phone. If it doesn't act like my phone does today, it's distinctly worse than using my phone. For me, there is no room for GM to become a player here. I have friends' addresses, etc. in my iPhone's contacts and they show up on Maps. GM isn't going to do that, so GM isn't going to get my business. I'm starting to look for a new car right now, and this is a hard no. If it doesn't support CarPlay and Android Auto (both--I've used both in the last five years, and might switch back again to Android in the lifetime of my next car), it's outside my observable universe. reply lokar 6 hours agorootparentI would never consider buying GM. I was, in the past, a UAW shop steward. reply hedora 6 hours agorootparentI once bought a GM vehicle. Never again. reply shiroiushi 4 hours agorootparentMy family had GM cars when I was a child, decades ago. Never would I seriously consider buying a GM. reply lotsofpulp 7 hours agorootparentprevWhy would you pay for that when your phone already does all of that and you always have it on you? reply lokar 6 hours agorootparentprevYou pay for maps on your phone? reply ThePowerOfFuet 1 hour agorootparentEither you pay with your data (Google) or upfront for the phone (Apple). I use Organic Maps on GrapheneOS and add businesses I want which aren't there (hence I had to look them up in Google Maps in Firefox Focus, which is painful enough that I don't want to have to repeat it). reply what_ever 10 hours agorootparentprevDoesn't Tesla do that as well? reply jdminhbg 10 hours agorootparentNo, Tesla sells internet connectivity for $10/month. reply hatsix 6 hours agorootparentWhile Tesla does have a $10/m plan, you still get basic Internet without paying for it... Tesla's free is better than any other company's paid subscription. That said, $10 is far too much for what it is, should be $5. reply chgs 2 hours agorootparentA Tesla costs $80k and lasts 10 years. Why are you saying $1200 for internet is too much and $600 isn’t? Why do they even bother charging - just bundle it in with the headline price. It’s a tiny portion of the revenue, nobody is going to think “oh that $87,345 Tesla is too much I’ll go for the $86,145 one” reply mavhc 1 hour agorootparentTesla costs $30k https://www.tesla.com/modely/design#overview $29450 with tax incentive reply delfinom 10 hours agorootparentprevYea but that's the joke is they plan. Toyota should also plan to expand their manufacturing capacity to pickup GMs lost sales to anyone under the age of 60. Lol reply donw 9 hours agorootparentToyota offering a V8 (both gas and diesel) in its trucks would change the market in a big way. reply hedora 6 hours agorootparentI’m surprised Toyota doesn’t offer a hybrid pickup similar to Ford’s. I wish any manufacturer offered a 250-class electric truck with a basic trim line. They probably want to sell more cars per battery for now. reply katbyte 4 hours agorootparentTacoma and tundra both come in hybrid now reply 10u152 5 hours agorootparentprevTundra Hybrid doesn't count? reply kortilla 3 hours agorootparentNo, that’s a half ton class truck (f-150 comparable). A 250 class truck (f-250, 2500, etc) is a 3/4 ton class and is what you need if you want to tow >10k pounds while having basically any load in the truck. reply duxup 15 hours agoparentprevYeah it's CarPlay or whatever Android uses, or I want nothing to do with it. Every time I rent a car it's a HELLSCAPE of figuring out whatever crappy UI this brand of car created for that year ... until I get my phone hooked up. Man I just want to get to my hotel not futz with some garbage UI in the garage forever. reply ossusermivami 40 minutes agorootparentI just carry those vent phone holder and use my phone when renting cars.. it's not the best but does the job for getting to the hotel.... obviously i rather have carplay if i could but i am worry about security implication, plugging to a car i don't know reply lotsofpulp 7 hours agorootparentprevEvery single car I have rented in the last ~5 years in the US has had CarPlay. reply daanvr 15 hours agoparentprevThe auto industry is really at a crucial point with how it integrates tech. As cars get more autonomous, infotainment is becoming a key part of our driving experience. I'm wondering, are carmakers at risk of falling behind if they don’t embrace platforms like CarPlay? Or do they have solid reasons to keep developing their systems in-house to keep control over their tech narrative? reply WirelessGigabit 15 hours agoparentprevIsn't that exactly what VW did? No more GPS. Just use CarPlay. reply api 11 hours agoparentprevAuto makers want what everyone else wants: recurring revenue. They want to find a way to sell subscriptions to something. The infotainment system is a potential angle for that. CarPlay makes that irrelevant. reply leovander 15 hours agoparentprevTop of my head, most car makers aren't rolling their own. It's either off the shelf with some white labeling or they buy it from another care manufacturer. i.e. Mazda default infotainment can be found in some Toyotas reply neogodless 15 hours agorootparentNot sure if there's any more to it than this, but the Toyota Yaris is a rebadged Mazda 2. I suspect you won't find Mazda infotainment in other Toyota models, though. reply shiroiushi 4 hours agorootparentI think you're right. Also, the Mazda infotainment in the mid-late 2010s was made by Johnson Controls. The newer systems might be too, I don't know. reply moduspol 15 hours agoparentprevI mean, theoretically they could make money by selling additional services. Tesla sells \"Premium Connectivity\" for ~$10/mo, though it might be against the license agreements traditional manufacturers have with dealers to sell enhancements directly to the consumer. IMO it's more about control over the user experience. You don't want your customers' UX to be dependent on the whims of Apple or Google, because now you're implicitly building a long-term dependency with a third party that may not be acting in your interests in the future. You're moving closer toward a future where the vehicle becomes commoditized, and now you have more trouble differentiating from competitors. And keep in mind: it's only very recently that the \"Apple car\" project was cancelled. That said, traditional automakers are also famous (or infamous?) for sourcing tons of components (including infotainment systems) from the same parts manufacturers. But I guess at least that retains the ability to pivot and use it as a point of differentiation in the future. reply throwaway11460 14 hours agorootparentEvery traditional European car manufacturer sells services directly to customers. Not sure about the US/Japanese/Korean, though. reply geoelectric 10 hours agorootparentHistorically, Hyundai/Genesis charged $300/yr for BlueLink connected care. Think my 2023 Ioniq 5 is one of the last (EV) models with that yearly charge, and that year's Ioniq 6 and subsequent models get it free. Unfortunately, I don't think they're planning on offering it free to my model or earlier, and I don't know if the same deal exists for ICE cars. reply devmor 9 hours agoparentprev>In the end, consumers don't give a shit about the in-vehicle infotainment. It sucks, or it's AA/CarPlay. My ideal \"infotainment\" is a button that lets me pair bluetooth and volume/skip controls on my steering wheel. I have a phone mount, like almost everyone does. I don't need a display on my dashboard. AA/CarPlay (and everything else) are genuinely just distracting annoyances that take up space. Especially in newer cars where the screens are for some reason, no longer matte and often angled upwards so that they just blast reflected sun into your eyes. reply Tagbert 8 hours agorootparentIf find the Bluetooth interface too limited because it requires interacting with the touchscreen on the phone. I want to use the large screen on the car with an interface that is optimized to work while in the car not small controls on a small phone. reply bluGill 7 hours agorootparentNo touch screen i should be accessable by the driner unless the car is in park. I don't care if it is the phone or infotainment, no touchscreen is allowed. reply Tagbert 5 hours agorootparentThe person I was replying to was arguing for a Bluetooth connection to their phone instead of CarPlay. CarPlay is much better from a safety standpoint than a phone screen. reply prmoustache 3 hours agorootparentYou just choose a superlong playlist before starting the car and then play it randomly. You don't have to interact with the phone. Last time I had a car I had an old mp3 portable mp3 player constantly hooked up to the car with 4GB of music inside. I would just hit play and drive and would only adjust volume from the steering wheel if I needed to. If I had a car again I would probably do the same, that is the lowest distracting way to have music in your car. reply lokar 6 hours agorootparentprevIt what if I’m in FSD mode? /s reply internetter 9 hours agorootparentprevLikewise. I vastly prefer the physical buttons, as I can hit them without taking my eyes off the road. The only two things I use infotainment for is mapping and music control. reply hedora 6 hours agorootparentBluetooth should let you select phone audio sources from your car buttons. It’s usually terribly implemented. iOS doesn’t support it for third party apps or first party podcasts, and apple music’s support is a shit show. Android is better, but it is hit-or-miss depending on the car. I wish the government would declare this a safety feature and mandate recalls for incorrect implementations (including phones and cars). reply sandworm101 15 hours agoparentprev>> In the end, consumers don't give a shit about the in-vehicle infotainment. Drivers don't car, but I think car buyers actually do. Remember that many people are not buying cars for themselves but for other people, usually family. They fall into the trap of thinking that those other people might want such features, if not now then in the future. Look at automatic transmissions. I know many people who much prefer manuals, but they always end up buying an automatic because they believe that other people will want the automatic. And a few years later, all the cars are automatics. The same is happening with in-car entertainment systems. We buy them not because we ant them but because we think other people do. reply baseballdork 15 hours agorootparent> Remember that many people are not buying cars for themselves but for other people, usually family. Can you explain this? I guess maybe the devil is in \"many\"? reply sandworm101 14 hours agorootparentUnless you are single, and even then you carry occasional passengers, many/most cars are used by multiple people. So people who buy cars are thinking not just about the primary driver but about all the other people who will drive/ride in the car too. Nobody buying a car actually wants in-dash 4k movies, but they think that their partner/kids will. reply kelnos 10 hours agorootparentThis doesn't really ring true for me. I agree that when people buy cars, they are often not just buying for themselves. But the purchase decision is not usually made without input from the other drivers. Well, a purchaser will probably discuss things with their spouse, and ask if they care about particular features. But in the case of someone buying a car for their kid, it's usually \"they'll get what they get, and they'll like it\". reply chgs 2 hours agorootparentKids are in the back and thus a screen in the back is what’s needed. An iPad or similar will do that, so a place to mount would be good. By the time they are old enough to be in the front they have their own phone and headphones and care less about a mounted display than they do about a TV. reply bombcar 11 hours agorootparentprevIt's true for some features (the wife (and I, to be fair) were pretty strongly on the \"heated seats\" side of things) but things like infotainment were not dealbreakers if everything else lined up. But CarPlay is darn close; I'd not say I'd never buy a car without it but having it means I don't need to worry if the infotainment setup is crap or not, because I won't be using it. reply dboreham 11 hours agoparentprevRegarding \"it sucks\", if we're talking mapping/directions I disagree. Google maps is really a pretty piss poor application. It hasn't changed in 15 years and it's obvious its maintainers haven't ever driven anywhere using the application, even around the Google campus in MT View, or downtown SF. It's deeply bad. In my experience some car manufacturer mapping applications are quite a bit better. Since they obviously suck at software, who knows how good it could get with the combination of (not Google) AND (competent team)? reply sokoloff 10 hours agorootparentUntil Apple Maps got offline downloads (in iOS 17), Google Maps was way ahead for offline use, which was enough to have me use it normally as well. reply chgs 2 hours agorootparentprev> It hasn't changed in 15 years Good. It works. I use Apple rather than Google as I try to avoid Google as much as possible but it’s the same principle. I want long term stability in software, not new changes put in to earn a PM a promotion. reply yabones 15 hours agoprevThere's an interesting gap when discussing carplay/aa. Cars from the 90s up until about 2013 can be easily fitted with a $500 head unit upgrade, and support carplay quite well. With the right tools, it can be done in about two hours right in your driveway. Cars from 2018 and up pretty universally support carplay, and it's generally quite well integrated into the car's infotainment system. But, between 2013 and 2017, things were a complete mess. In-car systems were too integrated to be replaceable with a third party 2-DIN unit, but too primitive to run carplay/AA. People who have cars from this era either sell them (for less than they're worth, since only 21% of people will buy a car without carplay!) or put up with it for another 8 years or so until the car's wound out. For example, my rustbucket '06 Toyota has a great sounding stereo with carplay but my sibling's 2017 Nissan is stuck with flaky and poorly integrated bluetooth. Or, if you do want to upgrade your 2013-2017 car, you end up replacing half of the in-dash components with ones from a couple model years up, tapping into the car's CAN bus to recognize the new controller, and then running some sketchy scripts to patch the firmware to remove component protection since the VIN's don't match up anymore. Not for the faint of heart. reply js2 8 hours agoparent> But, between 2013 and 2017, things were a complete mess. In-car systems were too integrated to be replaceable with a third party 2-DIN unit, but too primitive to run carplay/AA Mazda sells a retrofit kit for their 2014 (Mazda 3) / 2016 (other models) and newer cars that didn't come with native CP/AA. It's about $200 and DIY if you're the least bit handy: https://mazdaparts.org/mazda-3-smartphone-mirroring-kit.html reply jay-aye-see-key 4 hours agorootparentThis is so cool, I have a compatible Mazda and never thought to check if such an upgrade existed. Have ordered the kit and very excited. Thanks! reply srockets 7 hours agorootparentprevFor other brands, there are third party retrofits that replace the integrated stereo with a DIN mount, or with a carplay compatible head unit. The software on those is usually clunky, but it's not like OEM car head units are known for their UX. reply wvenable 7 hours agorootparentprevSadly my 2014 CX-5 is not supported. reply tssva 5 hours agorootparentI replaced my 2014 CX-5 head unit with a 3rd party unit which supports CarPlay/AA, integrates with the steering controls, the factory Bose amplifier and retains the ability to change the car settings through the head unit. Took about 2 1/2 hours to install it. reply js2 6 hours agorootparentprevSorry if I got your hopes up. I edited my comment to be more accurate. I didn't realize 2014 only applied to the Mazda 3 and it's 2016 for the other models. reply katbyte 4 hours agorootparentprevSeems like there are third party options if you google it reply 4rt 10 hours agoparentprevPorsche has a reasonably priced upgrade path for their head units even in quite old cars which add Carplay. The value is obvious to them - it maintains a high resale value on older vehicles which maintains their higher current sale value. Something I found interesting when I was hacking my VW to add Carplay (without paying £300) was that a ton of manufacturers in the ~2016 era use the exact same head unit and OS but with a different front fascia, different button layout and a relatively advanced UI skinning system. If you can be bothered you can add e.g. Audi track G-sensors to your VW or use a different skin. reply wodenokoto 2 hours agoparentprev> Cars from 2018 and up pretty universally support Carplay, and it's generally quite well integrated into the car's infotainment system. I don't know what cars you drive, but they are not budget or Chinese. I recently rented a bottom-of-the-line Nissan '24 and just getting audio from my iPhone was a struggle - and there was absolutely no Carplay in sight. Most Chinese cars I've rented (all 23 or 24 models) have advertised Carplay, but what they really have is a half-baked phone mirroring, which maybe worked on ios11 or something, but definetely doesn't today. reply chgs 2 hours agorootparentI rent almost exclusively in the “B” level in the U.K. and have always had CarPlay. Maybe it’s a policy by Enterprise UK. Occasionally I’ve had something like a D or so, or a van, but even the last van I had had CarPlay. reply bdcravens 8 hours agoparentprevAnother option is to get a device that is essentially a tablet that runs Carplay and connects to the car's audio via Bluetooth. https://www.amazon.com/Portable-Receivers-Display-Stereo-Blu... reply tssva 4 hours agoparentprevI have a 2014 Mazda CX-5 and a 2017 Subaru Outback. I have replaced the head units in both with 3rd party units which support CarPlay/AA. Both installations were easy and took about 2-3 hours. Both support changing the car settings through the 3rd party headhunt, integrate with the steering wheel controls, factory backup camera and the factory installed amplifiers (Bose and Harmon Kardon). The key to these integrations were iDatalink Maestro units. I ordered mine through Crutchfield but most decent car audio websites will generate an installation package including the appropriate wire harnesses, iDatalink unit, 2-DIN adapter and trim pieces once you select a head unit to purchase. reply fransje26 2 hours agorootparent> Both support changing the car settings through the 3rd party headhunt, integrate with the steering wheel controls, factory backup camera and the factory installed amplifiers (Bose and Harmon Kardon) Wow, I'm impressed. I wouldn't have thought manufacturers nowadays would be forthcoming enough to allow that. Do you know if it is something specific to (some?) Japanese manufacturers, or is it a form of info-display standard that would also make it possible with other brands? reply 1970-01-01 9 hours agoparentprevPeople like to complain about touch screens and lack of buttons, but the loss of the double DIN slot is a much worse loss. It more or less forces you to buy a new car to get satellite navigation updates or properly functioning Bluetooth. reply bonestamp2 5 hours agorootparentAgreed. These days you can get a double DIN carplay/aa deck with a slot load DVD player for under $80 USD. That is absolutely shocking. I mean, we couldn't even get a 5\" slot load CD drive for our computers for that kind of money and these things have a 5\" screen on them too! reply SkyPuncher 8 hours agoparentprevWe had a 2014 that suffered from this. It some touchscreen that was basically useless besides showing the backup cam and a few random, infrequently changed settings. However, replacing it was essentially impossible it also served as a critical system for a few things. By contrast, my 98 Jeep and '08 sedan were both easy upgrades to modern head units with standard DINs. Not having CarPlay/AA was actually a massive reason I wanted to get rid of that car. reply talldatethrow 8 hours agoparentprevOnly 21% of people will buy a car without car play? Maaaaybe new cars. Maybe. I sold cars up til a few years ago. Countless cars got sold where Bluetooth itself barely works, and people are basically fine with it. People buying used cars will take Bluetooth as a nice perk, but to think they make major decisions based on carplay in a 2015 Chevy Volt is funny. reply kergonath 4 hours agorootparent> People buying used cars will take Bluetooth as a nice perk, but to think they make major decisions based on carplay in a 2015 Chevy Volt is funny. That was my position until we bought our last car. We got it second hand, so we did not really have a definite set of required features and CarPlay was just nice to have. After having used it over the last 4 years, it completely changed though, and I can guarantee I won’t consider a car without it for my next one. It helps that around here all non-garbage car have had it for quite a few years now. reply prmoustache 3 hours agoparentprevIt is not advertised by the car makers but most cars of that era can still be retrofit with dual DIN slots. reply superfunny 8 hours agoparentprev\"...since only 21% of people will buy a car without carplay\" That statistic is complete bullshit. reply eloisant 1 hour agorootparentI don't have an iPhone but I wouldn't buy a car without Android Auto - and it's usually the same cars that support carplay. Anyway it's pretty much moot because besides Tesla, all new cars support both Carplay and AA. reply chgs 2 hours agorootparentprevI suspect it came from https://9to5mac.com/2023/12/05/carplay-popularity-iphone-tes... A non statistically relevant random poll of Apple fanboys reply spike021 15 hours agoparentprevMy car is from between 2013-2017 and it supports a standard 2-DIN replacement with Apple CarPlay. reply bdcravens 8 hours agorootparentThat's what I did with my 2018 Toyota C-HR. For a time, that same radio was in my wife's 2018 Rav4 and a friend's 2013 Dodge Grand Caravan. reply floxy 13 hours agoparentprev>(for less than they're worth, since only 21% of people will buy a car without carplay!) ...is there a handy list of which models these are? I'm in the market for a used car, and I'm perfectly happy to pay less for something without CarPlay. reply bombcar 11 hours agorootparentThe percentages only apply to new car buyers, in my experience. Once you're in used territory, all bets are off and you'd have to poke around. reply MBCook 8 hours agorootparentThe percentage for new car buyers is actually less than 21%. reply mfeldheim 1 hour agoprevThe only reason I use CarPlay is because I have an iPhone. The experience with Android auto is way ahead. Did you ever try to call a business that’s not in your contacts? Did you ever try to ask a simple question? Siri integration is horrible reply rekoil 17 minutes agoparentI feel like we should separate Voice Assistants from infotainment in general here. Yes, Siri is terrible, but the EUs new DMA law requires that I be able to select a different voice assistant on iOS too, and that should theoretically, once implemented, also apply to CarPlay. In my opinion, and while I haven't used \"Android Auto\" I have used \"Android Automotive\" (the OS version, without a phone driving the integration), and in my opinion (besides Siri) CarPlay the infotainment integration offers a better user experience. reply withinboredom 49 minutes agoparentprevSiri, in general, is horrible. Just ask Siri: \"set an alarm for 12:00 UTC\" or \"set an alarm for 12:00 Eastern Standard Time\" and she will create an alarm named UTC or Eastern Standard Time ... but it's actually in your current timezone. Super annoying when you want to set an alarm in a timezone you are going to be traveling to. reply graftak 3 hours agoprevI much rather have car manufacturers creating ‘exclusive to their brand’ themes and skins for the CarPlay 2 dials than not having car play (2) at all. Car manufacturers have had decades to develop their software but almost all are difficult to work with, slow, give bad user feedback (full screen pop-up with entire paragraphs while navigating) and are cumbersome to get accustomed to when switching cars. I’m one of the 79% that demands CarPlay, if it’s not part of the car I don’t want it. reply camillomiller 2 hours agoparentHaving had to do with car executives, especially in Europe, let me tell you... they're a peculiar lot. The older ones confuse their old school pride for business acumen more often than not, because of survival bias from an era when the two things actually coincided. The younger ones are frustrated by the fact that older upper management is extremely conservative and they're often put down or given toy projects to tinker with. On the other hand, incumbent carmakers might have also seen how Apple was able to turn the carriers' business around by convincing Cingular/AT&T about giving up their control and they don't like the idea of ending up like the carriers, with overarching licensing fees for keeping on using the tech... reply wilde 3 hours agoprevUgh, CarPlay 1 is exactly the division of responsibilities I want. I don’t want Apple anywhere near the actual driving functions and instruments. It takes a long time for my car to connect to CarPlay and it’d be super distracting to have the instruments suddenly change to Apple’s as I’m driving. reply AceJohnny2 15 hours agoprevArticle is really about the unofficially called \"Carplay 2\", a deeper integration that Apple announced in 2022 but hasn't been heard about since. As the article itself says, CarPlay Original Flavor is a massive success, I'm in the \"79% of drivers only consider a car if it has CarPlay\" (bye-bye GM!) reply ComputerGuru 15 hours agoparentApparently this isn't true. If you have a car where the 2nd screen behind the steering wheel also shows CarPlay-related stuff, you have CarPlay 2 (or so I've been told). It's just not as invasive and all-or-nothing as it was billed to be. reply MBCook 8 hours agorootparentNo. There are three things, which makes it confusing. 1: “original” CarPlay. Shows up on your head unit 2: enhanced “original” CarPlay. Some cars can show the map or turn by turn instructions behind the steering wheel on a screen there 3: “new” CarPlay. This is where CarPlay fully takes over every screen. Nothing has been released, I think only one very expensive model has even said they’re going it. Today e dry one has #1 or #2. The article is about a mix of #3 and maybe a version of #3 run on the car not the phone, like Android Automotive. The lack of distinct names for things on both the Apple side and Google side (auto vs automotive) just makes this all very hard to discuss at times. reply thedougd 7 hours agorootparentAny idea when #2 was released? I have a 2019 Honda. Android Auto can use the instrument panel as a second screen but CarPlay cannot. I miss seeing the next-turn distance countdown right in front of me. reply MBCook 6 hours agorootparentI know it requires both sides to support it. My car originally didn’t but a later update to my car enabled it. I don’t know when the first car got that, it’s possible it simply didn’t exist when yours was made. Or maybe it did and they just didn’t bother? I don’t know. My car doesn’t have the version where it just shows Apple Maps, which I would love. Instead the next turn/etc. is clearly being sent to the cars operating system because it gets displayed the same way the cars internal navigation stuff does on the screen behind the wheel. reply davidcsally 5 hours agorootparentprevI have a 2023 rav4 prime and it shows apple maps directions in the instrument cluster and HUD, maybe that counts? reply jojobas 5 hours agorootparentprevI'd say trusting phone vendors whether to show me an oil pressure warning is kinda stupid, but that's just me. reply sitharus 8 hours agorootparentprevCarPlay 2 is arriving late 2024 according to Apple, so it's definitely not a CarPlay 2 feature. Dual screen CarPlay was released in 2019 https://www.theverge.com/2019/9/20/20875604/apple-carplay-io... reply genmud 2 hours agoparentprevI sold my GM truck because of how horrible the head unit was. I am still driving my 8 year old f150 because the infotainment system works fairly well. reply randomdata 5 hours agoparentprev> (bye-bye GM!) To be fair, at this point only the Ultium EV-based models won't have CarPlay, and they are struggling to build them anyway. Even if they do figure out the production issues and achieve the targets of their wildest dreams, they will still only account for around 6% of all the vehicles GM produces. They're not exactly betting the farm on it. reply robertoandred 14 hours agoparentprevHuh? There were updates a few months ago https://www.macrumors.com/2024/01/27/apple-confirms-next-gen... reply kelnos 10 hours agoprevIt's pretty funny to me to see an Apple user complaining about lack of interop with other ecosystems. You've chosen your walled garden; now it's time to realize you're stuck in it. The author seems to blame everyone but Apple for this, though. Apparently it's Google's fault that his preferred podcast app isn't available on Android. What about the app developer, who has decided not to support Android? And it's the auto manufacturer's fault for deciding to go with Android Automotive as the infotainment OS. What about Apple, for refusing to license any of their OS offerings to third parties? (Let alone not having an automotive-suitable version of any of their OSes anyway.) Instead, Apple wants auto manufacturers to implement a complex, proprietary Apple protocol to give iPhones the ability to control most aspects of the car's infotainment functions. Why would auto manufacturers want to do this? Not only would the auto manufacturer have to develop their own infotainment system (perhaps even using Android Automotive, but perhaps something else), but then they have to do all this extra work to essentially allow drivers to not use their own system. (And while I agree that most auto manufacturer software is weak or outright garbage, that point of fact isn't really relevant here.) I don't agree with the author that some car makers are not excited about CarPlay 2 primarily because they want to own the automotive experience. It's because of all the extra work they need to do to support CarPlay 2 (probably an order of magnitude what it takes to support CarPlay 1 or Android Auto), and doing so isn't really in their interests, outside of Apple users who might refuse to consider their cars without CarPlay 2 support. But this is a chicken-and-egg problem: CP2 doesn't exist yet in any car, so customers don't know what they're potentially missing. reply kergonath 4 hours agoparent> It's pretty funny to me to see an Apple user complaining about lack of interop with other ecosystems. You've chosen your walled garden; now it's time to realize you're stuck in it. I am still amazed that some people see it as a brain-free non-decision to buy into a status symbol. I have an iPhone. It has things that I like and things that I hate. I have a brain that can process nuance, and it’s entirely possible to say nice things about some features and rant against others. I bought my current phone knowing what I can do and cannot do with it. It is an informed decision and a compromise by necessity. I bought it expecting it to integrate with my car via CarPlay, and I would definitely complain if it either stopped working or if car manufacturers dropped it. (I don’t care about CarPlay 2 at all) reply seanmcdirmid 8 hours agoparentprev> and doing so isn't really in their interests, outside of Apple users who might refuse to consider their cars without CarPlay 2 support. I would be interested in CarPlay 2 if I were buying a new car when it’s out. Infotainment is still a huge weakness in many cars, and is definitely a plus to many users. Carmakers are free to ignore it of course, but unless they are maybe Tesla, they have no good reputation to rely on in selling their own custom infotainment experiences. reply bonestamp2 5 hours agoparentprev> You've chosen your walled garden; now it's time to realize you're stuck in it. Yes and no. Android Automotive supports android apps, but GM's implementation (for example) still locks out android phones from using Android Auto. Yes, you can install the same apps, but the nice thing about hooking up your phone is that you're maintaining all of your apps, data, and state in one place instead of two and it's inherently different for as many different drivers as there are phones. reply jnaina 8 hours agoparentprevCarPlay 2 needs a deeper integration to the car, as part of the vehicle's SDV stack. From what I understand, Apple will license software that runs on the vehicles SDV stack (RTOS, etc) with support for various Auto specific SoCs (Nvidia, Qualcomm, Renesas, NXP, etc). There is an existing vibrant ecosystem of Tier 1 partners who can do the CarPlay (or AA) integration, lessening the burden on the Auto OEMs for such specialised integration work (Luxoft, etc). CP2 is an eventual pathway (pure conjecture here) for Apple to offer other upgrades in the future, like an L2+ ADAS package, via a subscription model, with a potential profit split between Apple and the OEM. Somewhat like what MobilEye currently offers and their current business model. Apple gets valuable realtime traffic info from such an L2+ offering, which can feed into making Apple Maps better with up to the minute traffic updates. And the OEM gets to leverage a valuable \"sticky\" offering that is bound to attract the Apple crowed (usually well heeled folks with deeper pockets). And they both get to monetize CP2 via a paid subscription model. reply graftak 3 hours agoparentprevPretty much all new car reviews are complaining about the built in infotainment, and it only gotten worse after manufacturers decided to jump on the all out touch screen bandwagon (to save a few bucks) but without Tesla’s generally alright UI and responsiveness. In that respect a UI made by Apple will certainly appeal to an audience already demanding current CarPlay. On the other hand, it could be that the current level of CarPlay integration is already enough. reply SOLAR_FIELDS 10 hours agoparentprevI also think the author misses the mark on this statement > Apple’s long-term goal is likely to find ways to directly monetize CarPlay. It could license CarPlay to carmakers at some point. But with the entire global car market amounting to only around 70 million cars per year and the car industry’s slim profit margins (ranging from 5% to 15%), it must reach a high market share to get significant revenue from it. However, carmakers may be hesitant to invest in what they see as a competing product. I don’t think Apple sees this as a promising revenue stream. It’s just another way to encourage people to stay within the walled garden. That seems many times more valuable than any possible licensing fees they would get from manufacturers reply godelski 8 hours agorootparent> I don’t think Apple sees this as a promising revenue stream. Isn't the value of CarPlay/AndroidAuto indirect? As in that the value is coming from the data being generated to enable better mapping? Because the truth is that some of these mapping services' main utilities depend on a large network of users (e.g. information about congestion, road notices, etc[0]). In that way it seems beneficial to get your app onto as many vehicles as possible and even gives motivation for making CarPlay cross-platform (even if the main benefits only go to Apple users). [0] Also, wtf AndroidAuto. You pull data from Waze users for things like speed traps, road hazzards, etc, but you don't let me contribute when using Auto? Why is there no button (or voice command) \"report road hazard\"? Hell, this'll even help you classify events for your ML models. reply SOLAR_FIELDS 8 hours agorootparentThe information you are referencing could be retrieved without CarPlay though. I am sure car specific data has some value to Apple, but given they aren’t really in the car business it might not be the primary driver/motivation here. It’s probably more likely that the data was way more valuable when they were building their own car but now that has been scrapped perhaps not as much? reply karmakaze 9 hours agorootparentprevI hate to say it but monetize subscriptions, not new car sales. It's got to be worth as much as a seat warmer. reply dmoy 8 hours agorootparentWait I gotta be missing something. Are seat warmers a subscription now? Damn, indeed I missed that section > With their own software platforms, they are desperately trying to find recurring revenue streams, whether it's a subscription for seat heating or driver assistance systems .......... reply filoleg 8 hours agorootparent> Are seat warmers a subscription now? They almost became a subscription, but BMW backpedaled at the last second[0]. 0. https://www.theverge.com/2023/9/7/23863258/bmw-cancel-heated... reply rrdharan 7 hours agorootparentPretty soon the pedals will be a subscription or pay per use. reply filoleg 7 hours agorootparentThat’s called “leasing a car”, and it comes with a limited number of miles per year, beyond which you pay $X/per 100 miles iirc. I wouldn’t know the details, because I bought my car instead of leasing, but I remember looking at lease terms that all had a mileage limit +extra pay per N number of miles. reply raihansaputra 7 hours agorootparentprev> I don’t think Apple sees this as a promising revenue stream. It’s just another way to encourage people to stay within the walled garden. That seems many times more valuable than any possible licensing fees they would get from manufacturers I agree this is the optimal way of seeing it. Apple did not do the same with App Store though. The initial vision was to just apply enough fees for hosting and vetting the apps. Now with the way they hold on to the 15/17/30% fee, they are treating it like a revenue stream instead of a \"courtesy service\". reply FridgeSeal 6 hours agoparentprev> give iPhones the ability to control most aspects of the car's infotainment functions Because the solutions the auto makers came up with _sucked_ and as it’s not core to the operation of the car, I’d prefer it be done by someone that even approximately knows what they’re doing with software? I am not buying the car for their infotainment features, I’m buying it for the car. I’d like it the entertainment bits were just delegated to the setup I already have… reply eloisant 1 hour agorootparentThat's why I'm happy with CarPlay/AA for infotainment... ONLY. Maps, music, podcasts, that's all I need. I don't need my whole car UI to be taken over by my phone. My car maker solution to display and control speed, HVAC, gas tank/battery status is perfectly fine. reply lotsofpulp 7 hours agoparentprev> And it's the auto manufacturer's fault for deciding to go with Android Automotive as the infotainment OS. Yes, as far as I know, any automaker can choose to make the screen in the dash compatible with Carplay, at least the non fancy Carplay that will be able to show all the apps on the phone. Zero reason, in my opinion, to not offer a Carplay compatible screen, other than to inconvenience car users. Not the CarPlay 2 thing, but just original Carplay. reply willcipriano 9 hours agoparentprevImagine a world where Apple and Google (and others) worked together and made a open standard that is as good as what they both have today. Bluetooth but for cars. Such a missed opportunity. reply khimaros 8 hours agorootparentpersonally, i am hoping for (and working slowly toward) modernized AACS so that eg. a raspberry pi can be used to control most modern car head units unmodified: https://github.com/tomasz-grobelny/AACS reply zeckalpha 8 hours agorootparentprevThis would be considered a trust worth busting. reply npteljes 2 hours agorootparentNot if it's anything like the video standardization efforts. The result is royalty free and open source. Every provider and consumer benefits when the infra is open https://en.wikipedia.org/wiki/Alliance_for_Open_Media reply pegasus 8 hours agorootparentprevNot if it's open. reply valianteffort 10 hours agoparentprevnext [5 more] [flagged] internetter 9 hours agorootparentTFA yapped about iPhones 8.7x more than OP reply chris_wot 10 hours agorootparentprevThat’s a ridiculous statement - he was responding to substantive points raised by the article. I’m a huge Apple fan, but let’s be fair here and not flame others. reply batch12 9 hours agorootparentIt's funny that calling someone an Android user is considered a flag-worthy insult. reply freedomben 8 hours agorootparentI don't think it is. I think dismissing a well thought out post by calling it \"yapping\" was the insult. reply 51Cards 14 hours agoprev>Continuing with the above example, let's imagine I just downloaded a new podcast app on my phone (one that is also available in the automotive Play Store). The next day I have to go on a long drive and I want to listen to a podcast episode I downloaded on my phone. When I enter my car, I have to go to the Play Store, find the app, download it, log in, and then download the episode. When I use CarPlay, I only have to connect my phone. Does the author have no experience with Android Auto? The same happens there, if the app is on my phone and it supports Android Auto then it will automatically be available in the car, along with all media on my phone. This isn't a CarPlay only functionalitiy, it's just how phone mirroring works on both platforms. Author seems to think there is an extra step involved on Android. Perhaps by \"Play Store\" they mean the car manufacturer's own app store? Source: I use Android Auto constantly in my own vehicle and in the 15+ rental cars I have every year. reply dagmx 8 hours agoparentThe author is talking about Android Automotive which is different than Android Auto. Auto is driven from your phone whereas Automotive is running on your car directly. reply mintplant 8 hours agorootparentAlright, but then comparing CarPlay 1 to Android Automotive is comparing apples and oranges. The author should be comparing CarPlay 1 to Android Auto and CarPlay 2 to Android Automotive. reply dagmx 8 hours agorootparentSure but I’m just providing more info to the other person? I’m not defending the author. I think many of their criticisms on both sides have flawed arguments and misconceptions . reply eddythompson80 8 hours agorootparentprevUmmm, no? Sort of. First we don’t really know much about CarPlay 2. It was announced in 2022 but hasn’t been detailed yet. However, all the assumptions are that it runs of your phone just like CarPlay 1, but with more control and integration in the car. Nothing I have seen from Apple or others suggests that Apple is building an Android Automotive-like product. I.e: Apple software that runs off the car itself. Also it will be very unlike Apple to sell software that car companies run, which is what Android Automotive is. Unless the plan is to sell an iOS box that car manufacturers integrate into the car. But I haven’t seen any thing that suggests that. reply 51Cards 8 hours agorootparentprevThanks for the clarification! reply dagmx 8 hours agorootparentNo problem. It’s a really common misunderstanding because Google purposefully like to name things to reduce distinction. reply MBCook 8 hours agorootparentI agree it’s a mess. But Apple isn’t doing itself any favors on CarPlay branding now that it sort of means multiple things. And don’t get me started on the Apple TV naming mess. reply Jtsummers 13 hours agoparentprev>> Continuing with the above example, let's imagine I just downloaded a new podcast app on my phone (one that is also available in the [Android A]utomotive Play Store). They lost a capitalization which makes it a bit ambiguous but their scenario is this: There are two app stores being discussed: iOS (for CarPlay), and Android Automotive (the infotainment system's play store). If you have Android Automotive on an infotainment system and an iPhone and can't connect your iPhone to the infotainment system, you have to download the app twice: iOS App Store and Android Automotive Play Store. I don't know the numbers, but Android Automotive infotainment systems don't universally support CarPlay. Some only got it via updates over the last couple years (that's also a selling point of them, though, that they could do it via software updates and not a whole hardware refresh). reply arjvik 11 hours agorootparentThere's a difference between Android Auto (Google's CarPlay equivalent for phone projection to any infotainment system) and Android Automotive (Google's Infotainment OS). reply MBCook 8 hours agorootparentprevAny car that supports android auto (not automotive), no matter what software it’s running, is technically capable of supporting CarPlay. If it doesn’t, that’s a choice the automaker made. Either to disable it or to not write that part of the software. I know Android Automotive already has all the code to support it. So for an android automotive car to not support CarPlay is 100% a decision. reply deergomoo 46 minutes agoprevAll I want from CarPlay is for it not to start blaring the last thing I was playing on the car speakers as soon as I plug it in, especially given there’s about a 10 second window between the sound playing and the head unit being booted enough to actually show the screen so I can pause it. I have no idea if it’s the car or CarPlay but could I please just have a toggle somewhere? reply rekoil 39 minutes agoparentIt's the car I'm pretty sure. If anyone has another take I'd love to hear what they think, but I've used many implementations of CarPlay and have never encountered what you're describing. reply jonny_eh 43 minutes agoparentprevMost radios have a mute that’ll also pause the playback reply can16358p 50 minutes agoprevOne thing that is ridiculous with CarPlay is that I can't read messages: it only allows to \"speak\" it and while I use my phone in English I message with my friends in my native language and speaking works terrible. Even my car's shitty infotainment system can display messages. This results in the worst possible outcome: I need to take my phone and read the messages on my phone screen, creating a safety risk. reply trodat14 47 minutes agoparentWhy do you need to read messages while you’re driving? reply fragmede 14 minutes agorootparentbecause the message may be informing the driver of a change in destination reply bzzzt 47 minutes agoparentprevIs the message so important it justifies creating a safety risk? You could also just wait until you've arrived or stop the car at a safe place... reply mihainov 35 minutes agorootparentThat's the problem. I don't know if the message is important or not unless I see it. There wouldn't be a safety risk if at least the beginning of the message was displayed on screen. That would be enough to figure out if it's something worth stopping for or something that can wait. reply frankus 10 hours agoprevA bit of a tangent, but those \"distinctive\" interior mockups made me instantly cringe. I'm fine with designers having a bit fun with every part of the car other than the top of the dashboard, which should be flat, dull, and dark (ideally covered in something like Vantablack), because any bit of visual clutter there gets superimposed over the road in front of you thanks to the reflection of the windshield in sunny weather. reply teeray 9 hours agoprev> But it won't be possible to sell a subscription for a feature when all is controlled by Apple CarPlay Good I bought the car, now get out of my life. I’m not paying hundreds of dollars for GPS map updates when I can plug in my phone and use any other mapping app’s evergreen maps. Also, subscriptions for heated seats are patently absurd. reply parski 1 hour agoprevI went from CarPlay (Kia e-Niro) to Tesla (Model 3) to CarPlay (Volvo XC40 Recharge) and I vastly prefer CarPlay. I've tried wireless CarPlay (BMW M2) and while convenient when entering and exiting the vehicle I found it to be quite laggy compared to wired. While Tesla does have the Apple Podcasts app it's a really bad experience. It won't sync playback state properly so I have to memorize what I'm listening to and how far I've gotten when I switch from car to phone or back. Similar story with Apple Music and even Spotify (which is usually great at keeping state between devices but not with Tesla for some reason). Yes, I paid for \"premium connectivity\". Tesla did have better route planning though. I also really don't like wireless charging. It spares the port from constant wear but my device tends to get really hot and the charging is very inefficient. I plan to go back to slow wired charging everywhere to put less strain on the battery. I already have in my car and by my PC. Unfortunately my XC40 doesn't support dual screen CarPlay so I use the Google Maps in Android Automotive for navigation and use CarPlay for music, podcasts, etc. Switching from AA Google Maps and CarPlay and back is not a high friction interaction though so it's an okay solution. I'm also able to deactivate wireless charging so I'm pretty happy with this solution. reply m000 34 minutes agoprevWhy can't we have a car that only has: (a) a standardized mechanism for attaching and powering your phone on its dashboard (think a \"mini VESA mount\" with options for USB/wireless charging) (b) bluetooth HID-compatible physical controls on the steering wheel and/or center console so you don't have to reach for your device (c) a minified car \"radio\" that only offers AM/FM radio and bluetooth audio connectivity All other controls should be physical, copied straight out of a 90s/00s car. reply hsbauauvhabzb 3 hours agoprevTwo things scare me about Android / Apple car integration - I’d be interested in experiences others have had: Obsolescence - ‘your phone is too old to use with this car’ or your car being too old for your phone. Double points for software updates to either which disable functions or features. Vendor lock-in - are the players mutually exclusive? Does having a phone from one manufacturer limit my car choices? reply StephenSmith 15 hours agoprevIf you're in the market for a new-to-you car, then I recommend looking at the model years where they switch from wired car-play to wireless car-play and buying the previous model-year. Typically this difference of one model-year can add thousands to the cost of the vehicle, especially because wireless car-play is so coveted. The experience of wireless is fantastic, but is it worth several thousand dollars? Maybe, but herein lies the trick. Buy a dongle. They're about $100 for a good one. They can be tucked away in the vehicle. They work almost* as good as integrated wireless car-play. *Maybe add 5 seconds to auto-connect when you get in your car. reply SkyPuncher 7 hours agoparentI have one wired and one wireless vehicle. I will absolutely pay more for integrated wireless. It just works flawlessly. We've upgraded the wired one with one of those dongles. It mostly works, but has some quirks. The three most annoying: * Phone calls result in a feedback loop for the other end. Essentially, they break the in-car noise cancellation and playback the caller audio to the caller. * When my wife pulls in the garage, my phone will connect - even though it should have been connected to her phone. * The USB port that connects to the head unit remains power for a period of time after the vehicle is off. Annoying when I'm in the kitchen (next to the garage) and my phone keeps trying to CarPlay. EDIT: I'm also realizing that I believe the car with Wireless has associated each of our keys with our phones. Despite them both being paired, it will prioritize the phone last used with the key. That's pretty handy for not having to fight with pairing. reply kelnos 10 hours agoparentprevI haven't used wireless yet, so maybe I just don't know what I'm missing, but I kinda just don't see why I'd ever need it. I'm going to plug in my phone anyway to charge, so what's the draw? reply hypothesis 9 hours agorootparentIt’s kinda convenient for short trips (thus no plugging required) because it just works: it shows up on screen immediately when you get into the car, no extra movements. Also, I think cars with wireless CarPlay are equipped with wireless charging for a convenient combo. But boy it’s enraging to use with multiple phones when you share a car with someone. It will stay connected to other person phone, while in range, and, if you to call that person, car will ring. It’s chaos… or maybe it’s just me. reply adastra22 8 hours agorootparentYeah my RAV4 has a nice wireless charging feature which I expected to make lots of use of. Just place the phone on a little nonslip pad and it charges as I drive! Perfect and so convenient. Except I misunderstood that my year didn’t have wireless CarPlay, so I have to choose between CarPlay and wireless charging :( Hopefully my next car will have both. reply ThatPlayer 6 hours agorootparentprevI haven't seen a car USB port that does fast charging, only slow 5V @ 1 or 2 amps. So if I need a charge, I'd rather use a fast 18W \"cigarette lighter port\" charger and wireless connection. Otherwise my trips are usually short enough. Also my phone's dual screen addon case (LG V60) blocks the USB port. reply MBCook 8 hours agorootparentprevI hate it. In my car (admittedly the only one with wireless I’ve ever tried) there is an extremely noticeable delay between input and action. Tapping on the screen for the next song or pressing the steering wheel button to do the same can take a half second or more. Doing it on the phone is nearly instantaneous, just a very tiny audio delay. Using a cable? Never any delay at all. Unnoticeable. Between that and the fact that it can really burn battery I’m happy to plug it in every time. reply SkyPuncher 7 hours agorootparentprevBeing able to simply leave it in my pocket is really nice. Particularly nice when running errands around town (in and out frequently) Prior to switching to Apple, I was running into major issues with USB-C ports being hyper sensitive to physical positioning. Charge would always work, but Android Auto would simply drop out seemingly randomly. Didn't matter on cable. It was just something that would happen. reply jrmg 9 hours agorootparentprevI don’t find I need to charge - my phone lasts all day even with relatively heavy CarPlay use. I suspect it uses less power than you think it might because it doesn’t need to power the screen. reply gnicholas 8 hours agorootparentprevThe draw is that wireless charging is faster/easier than plugging, or so I understand. reply bdcravens 8 hours agoparentprevSome of the dongles function as Android tablets as well, allowing you to run pretty much any Android app (like Youtube, Netflix, etc without any restriction, though not all apps are safe and may even be illegal while driving) reply hunter2_ 15 hours agoparentprevAndroid Auto: I use the Motorola wireless dongle in a VW. It's great when only 1 phone is paired, but my wife and I share the vehicle in question. It allows multiple pairings (despite the instruction manual hardly mentioning that ability, if at all) but it's finicky as hell. Half of all attempts at swapping phones end in unplugging the thing and using a cable, to the point where I'm thinking I keep wireless AA for myself (driver 90% of the time) and have her use a vent mount with only BT audio (driver 10% of the time). Connection handshake delay before visible feedback is about 30 seconds, which makes troubleshooting an extremely latency-riddled nightmare. But the other half of the time, it's as simple as selecting the desired phone in the Bluetooth menu of the car. Once connected, the experience is identical to wired AA. This problem didn't exist at all before going wireless. reply dap 15 hours agoparentprevI am not sure if this would be a problem with wireless as well, but I've had very inconsistent experiences having Carplay start at all using a dongle. I'd say right now it works about 70% of the time, and about 25% of the time when it doesn't, I can get it working by unplugging and re-plugging after the car is on. The rest of the time I have to stop the car and start it for it to work. This all started about a year ago though. (2022 RAV4 Prime, multiple iPhone and iOS versions, genuine Apple lightning cable, both with and without an extra Lightning->USBC dongle.) reply hedgehog 11 hours agorootparentIn my experience it's over cable CarPlay is reliable if the head unit is already booted and the phone is unlocked when plugging in. If either of those things aren't true then no guarantee the phone will connect after the booting / unlocking finishes (I use and recommend the setting to disallow accessories when the phone is locked). reply wil421 15 hours agoparentprevThe wifi dongle audio quality was reminiscent of the old iPod FM Transmitters that would plug into the cigarette lighter. Not to mention the annoying delay. reply MBCook 8 hours agorootparentReally? I never had any audio issues, but wireless is built in. So I don’t think it’s an inherent issue. The delay though… ouch. reply api 11 hours agoparentprevI actually prefer wired. Otherwise when I get in the car and turn it on, it pairs with my wife's phone half the time instead of mine. I also almost always want to charge the phone anyway. reply jamesfmilne 15 hours agoparentprevAgreed, I bought a 2017 VW Golf recently, it has wired Apple CarPlay. Bought a dongle for £55, works fine. Love having a car with a steering wheel with real buttons, and climate controls with real knobs. It feels like around 2018 is the zenith of Human Machine Interface in cars and it's all been downhill since, as they cram everything in a fucking touchscreen. reply dboreham 11 hours agoparentprevIn my experience wireless car play is a nothingburger -- you end up plugging in your phone to charge it anyway. If it's not plugged in, the wireless interaction draws so much power that you need to plug it in. Stable configuration is therefore: plugged in. (yes you can sometimes have the combination of wireless CP and wireless charging, but wireless charging also sucks). reply MBCook 8 hours agorootparentWireless CarPlay = heat. Wireless charging = heat. Both = furnace. reply definitelyauser 15 hours agoparentprevI've tried a few dongles and have had nothing but bad experiences. \"Kinda works\" for a while, with a noticeable delay when changing songs etc. Actually pondering replacing the infotainment system itself to get wireless airplay. reply luhn 15 hours agorootparentI thought the audio delay was because of a crappy dongle too, but when I rented a car with built-in wireless CarPlay it was exactly the same. reply axxl 15 hours agorootparentprevThe delay happens with integrated systems as well apparently. My brother's car has it built in and he confirmed my adapter is the same. reply albumen 15 hours agoparentprevWhen I looked into this previously, the delay seemed pretty significant, not just upon auto connect. Can you recommend your dongle? reply spike021 15 hours agorootparentI've had a Carlinkit 3.0 for two years connected to a standard $400 or so Pioneer head unit with CarPlay and it works fine. Initial connection is a bit slower than wired, maybe 20 seconds or so, but it's up and running by the time I'm moving my car. There's very small amount of input lag for stuff like skipping songs or pause/play. I'd say that lag is almost exactly the same as when I used to only use bog-standard Bluetooth to connect to a head unit with my phone so I think that's just the downside of a wireless connection-- wired doesn't have this lag. reply babypuncher 11 hours agoparentprevI have an actual wireless carplay head unit from Pioneer in my 2011 RAV 4, but I still use it in wired mode with one of these dongles because Pioneer's implementation is so buggy as to be practically useless and they refuse to issue any firmware updates for the device. Moral of the story: Don't buy a head unit from Pioneer. They suck ass. This is quite possibly the shittiest tech product I have ever spent money on. reply globular-toast 15 hours agoparentprevOr just get a car that you can retrofit a head unit to. Could be a third party one or a better one from another model. In my VW I retrofitted a head unit with navigation and cruise control, amongst other things. Be sensible and get things like parking sensors that are hard to retrofit, but don't pay for things you can easily fit yourself. reply RobT7k 15 hours agoprevI have zero interest in the CarPlay v2 (as described in the article). CarPlay v1, however, is an absolute requirement. It works great and gives me pretty much everything I want. reply MBCook 8 hours agoparentI’m curious, but honestly I don’t see any automaker ever playing along. reply eddythompson80 7 hours agorootparentI don’t know man. Never underestimate Apple’s marketing. If it’s a good implementation, all they would need is 1 automaker to do it the others will have to. I wouldn’t consider a new car without AA/CarPlay and many others are in the same boat. Automakers had to start offering upgrades to their old cars to support AA/CarPlay. There is no way automakers could invest as much into software development as Apple or Google. I hear people like their Tesla infotainment systems, but I don’t have a Tesla nor plan on buying one. Also don’t see how they could match the AppStore/Play Store. reply MBCook 6 hours agorootparentI won’t buy without CarPlay either. But if Android Automotive runs CarPlay, I’m not sure how much I care. And I’m a huge fanboy. I’d like to be able to use Siri to control the temperature and a few other things. And taking over the whole screen could be nice. But Apple is such a control freak about things I have a hard time seeing most car makers agree to it. And just about every industry Apple has touched has learned the lesson that Apple takes things over. Car makers clearly already dislike the fact that CarPlay is so popular, I don’t think they want to give Apple MORE leverage. I find the idea of Android taking over the industry a problem (monoculture = bad, manufacturers are clearly not up to it themselves). Apple could be a hedge. But they’re not a play nice company even when they should be. They haven’t learned humility again after losing it during iPod/iPhone rise. reply jeffchien 8 hours agoprevYou don't have to download a new podcast app because you could just play it through Bluetooth. CarPlay and AA probably wouldn't even exist if it weren't for car vent phone holders and 2.5mm/Bluetooth upending automakers' grip on navigation and entertainment. reply hot_gril 8 hours agoparentIt's amusing how some new cars seemingly deliberately have no place to put your phone, while some older ones were specifically designed to hold your iPod. reply hn_throwaway_99 10 hours agoprev> Google jumped on this opportunity by releasing Android Automotive. Unlike Android Auto, Google's equivalent to Apple CarPlay, Android Automotive runs natively inside the car and any carmaker is free to use it. Tangential I know, but I giggled at yet another example of Google's incompetent branding and product naming. How a company filled with so many brilliant people can be so bad at brand strategy is baffling to me. reply makeitdouble 10 hours agoparentThe actual name is Google Automotive Service [0], which shortens as GAS. That's not bad I think, at least it's easy to remember. The fact that it's still confusing with android auto being another thing is I think partly on purpose, to make it look like Android is doing more than what it's actually responsible for. [0] https://developers.google.com/cars reply Nevermark 7 hours agorootparentFew things are as big a win as ensuring your customers are never quite sure they really understand your product line up. Because they actually never really understand your product line up. I can understand this kind of thinking in a here-and-gone used car lot. reply MBCook 8 hours agorootparentprevIsn’t that a recent renaming though? reply fragmede 10 hours agoparentprevthat the really good computer thinking people aren't really really good at people thinking is surprising to you? reply 10u152 9 hours agorootparent156500 employees. I'm sure there's a few PR/Marketing people in there. It's not all \"Good computer thinking people\" Google isn't a plucky startup with just a few dedicated engineers. reply Nevermark 7 hours agorootparent> Google isn't a plucky startup with just a few dedicated engineers. They made great long term corporate value and customer relationship decisions then, for their context. When big corporations full of talent get sloppy, it is usually either a very competent emphasis on short term financial growth or value multiple growth. Or the result of multiple competent actors infighting or working at cross purposes, due to a lack of strong internal alignment. The latter jungle case saves a CEO from having to deep dive, they can just see what happens and select winners. Either way, by competent I mean someone is accomplishing exactly what they intend. Optimizing their net worth given the company's incentive and power structures, in the absence of a CEO who cares more about the long than the short term. It only takes that one difference at the very top to trickle down. The greater the talent, the greater the effect. reply 159 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple CarPlay is favored by drivers for its smooth integration with popular apps and user-friendly design.",
      "CarPlay 2 promises more profound integration with vehicles, but automakers are cautious due to worries about brand uniqueness and integration expenses.",
      "Apple might monetize CarPlay by offering licenses and customization features, while collaboration between tech firms and automakers is crucial for CarPlay's acceptance in the automotive sector."
    ],
    "commentSummary": [
      "The article delves into Apple's CarPlay system, its efficacy, and the influence of the Japanese car industry on global infotainment systems.",
      "It discusses the challenges of merging software into long-lasting products like cars, potential for subscription services in the automotive sector, and the preference for CarPlay over other infotainment choices.",
      "The debate includes CarPlay's compatibility, wireless connectivity issues, and its future integration in vehicles, as well as the impact of Apple and Google on the automotive industry."
    ],
    "points": 215,
    "commentCount": 413,
    "retryCount": 0,
    "time": 1713894892
  },
  {
    "id": 40138228,
    "title": "Empower Microcontrollers with ESPHome",
    "originLink": "https://esphome.io/index.html",
    "originBody": "Quick search Table of Contents Supported Microcontrollers Microcontroller Peripherals ESPHome Components Network Hardware Network Protocols Bluetooth/BLE Management and Monitoring Hardware Peripheral Interfaces/Busses I/O Expanders/Multiplexers Sensor Components Core Air Quality Analogue Bluetooth Low Energy (BLE) Digital Signals Distance Electricity Environmental Light Magnetic Miscellaneous Motion Thermocouple Weight Binary Sensor Components Core Capacitive Touch Mechanical NFC/RFID Touchscreen Presence Detection Miscellaneous Output Components Light Components Switch Components Button Components Fan Components Display Components Display Hardware Platforms Touchscreen Components Cover Components Text Components Text Sensor Components Climate Components Number Components Select Components Lock Components Media Player Components Microphone Components Speaker Components Time Components Home Assistant Components Alarm Control Panel Components Datetime Components Energy/Solar Management Electromechanical Wireless Communication Miscellaneous Components Custom Components Cookbook Join the community Follow us on Twitter Source Code Contact (no support!) ESPHome is an open source project by Nabu Casa This site is powered by Netlify ESPHome is a system to control your microcontrollers by simple yet powerful configuration files and control them remotely through Home Automation systems. Getting started from Home Assistant using the command line install ready-made project by migrating from Tasmota esphome: name: awesome esp32: board: nodemcu-32s Next steps FAQ and Tips Automations DIY Examples Configuration types Sharing ESPHome devices Made for ESPHome program Keeping up Discord Forums Changelog Supporters Contributing Supported Microcontrollers¶ ESP32 ESP8266 RP2040 BK72xx RTL87xx Microcontroller Peripherals¶ Peripherals which directly support the operation of the microcontroller’s processor(s). PSRAM Deep Sleep ESPHome Components¶ ESPHome-specific components or components supporting ESPHome device provisioning post-installation. Core Captive Portal Copy Demo External Components Improv via BLE Improv via Serial Network Hardware¶ WiFi ESP32 Ethernet Network Protocols¶ Network Core Native API MQTT HTTP Request mDNS WireGuard Bluetooth/BLE¶ ESP32 BLE Beacon ESP32 BLE Client ESP32 BLE Tracker Bluetooth Proxy Improv via BLE Management and Monitoring¶ Debug Logger OTA Updates Prometheus Web Server ESP32 Camera Web Server Hardware Peripheral Interfaces/Busses¶ CAN Bus I²C Bus I²S Audio SPI Bus UART I/O Expanders/Multiplexers¶ MAX6956 - I²C Bus MCP230XX - I²C Bus MCP23SXX - SPI Bus PCA6416A PCA9554 PCF8574 SN74HC165 SN74HC595 SX1509 TCA9548A I²C Multiplexer XL9535 Sensor Components¶ Sensors are split into categories. If a sensor fits into more than one category, it will be listed multiple times. Core¶ Sensor Core Template Sensor Home Assistant MQTT Subscribe Uptime Sensor WiFi Signal Strength Air Quality¶ AGS10 Volatile Organic Compound Sensor AirThings BLE CCS811 CO2 & Volatile organics EE895 CO2 & Temperature & Pressure ENS160 CO2 & Air Quality GCJA5 Particulate HM3301 Particulate iAQ-Core CO2 & Volatile organics MH-Z19 CO2 & Temperature MiCS-4514 Gas concentration PM1006 Sensor Particulate PMSA003I Particulate PMSX003 Particulate RadonEye BLE Radon SCD30 CO2 & Temperature & Humidity SCD4X CO2 & Temperature & Humidity SDS011 Sensor Particulate SEN0321 Ozone SEN5x SenseAir CO2 SFA30 Formaldehyde SGP30 CO2 & Volatile organics SGP4x Volatile organics and NOx SM300D2 Air quality SPS30 Particulate T6613/15 CO2 ZyAura CO2 & Temperature & Humidity Analogue¶ ADC ADC128S102 8-channel ADC ADS1115 4-channel ADC ADS1118 4-channel ADC CD74HC4067 16-channel analog multiplexer MCP3008 8-channel ADC MCP3204 / MCP3208 4-channel ADC Resistance Bluetooth Low Energy (BLE)¶ Alpha3 AM43 Lux & Battery level BLE Client Sensor BLE RSSI HHCCJCY10 (MiFlora Pink) Soil moisture & Temperature & Light Inkbird IBS-TH1 Mini Temperature & Humidity Mopeka Pro Check LP tank level Mopeka Standard Check LP tank level RuuviTag Temperature & Humidity & Accelerometer Xiaomi BLE Various Digital Signals¶ Duty Cycle Pulse Counter Pulse Meter Pulse Width Distance¶ A01NYUB Acoustic distance A02YYUW Acoustic distance HRXL MaxSonar WR Acoustic distance JSN-SR04T Acoustic distance TOF10120 IR optical distance Ultrasonic Sensor Acoustic distance VL53L0x IR optical distance Zio Ultrasonic Sensor Acoustic distance Electricity¶ ADE7880 Voltage & Current & Power ADE7953 Power ATM90E26 Voltage & Current & Power ATM90E32 Voltage & Current & Power BL0939 Voltage & Current & Power & Energy BL0940 Voltage & Current & Power BL0942 Voltage & Current & Power CS5460A Voltage & Current & Power CSE7761 Voltage & Current & Power CSE7766 Voltage & Current & Power CT Clamp AC current Daly BMS Voltage & Current & Power DSMR Electrical counter HLW8012 Voltage & Current & Power INA219 DC Current INA226 DC Current & Power INA260 DC Current & Power INA3221 3-Ch DC current Kamstrup KMP District Heating Meter MAX9611 +60VDC Voltage & Current & Power & Temperature PZEM AC Voltage & Current & Power PZEM DC Voltage & Current & Power PZEM004T Voltage & Current & Power SDM Meter Modbus energy monitor Selec Meter Modbus energy monitor Teleinfo Electrical counter Total Daily Energy Environmental¶ Absolute Humidity AHT10 / AHT20 / AHT21 / DHT20 Temperature & Humidity AirThings BLE Temperature & Humidity & Pressure AM2315C Temperature & Humidity AM2320 Temperature & Humidity b-parasite Moisture & Temperature & Humidity & Light BME280 Temperature & Humidity & Pressure BME680 via BSEC Temperature & Humidity & Pressure & Gas BME680 Temperature & Humidity & Pressure & Gas BMP085 Temperature & Pressure BMP280 Temperature & Pressure BMP388 and BMP390 Temperature & Pressure BMP581 Temperature & Pressure Dallas DS18B20 Temperature DHT Temperature & Humidity DHT12 Temperature & Humidity DPS310 Temperature & Pressure EMC2101 Temperature ENS160 CO2 & Air Quality ENS210 Temperature & Humidity HDC1080 Temperature & Humidity HHCCJCY10 (MiFlora Pink) Soil moisture & Temperature & Light Honeywell ABP Pressure & Temperature Honeywell ABP2 I2C Pressure & Temperature Honeywell HIH I2C Temperature & Humidity HTE501 Temperature & Humidity HTU21D / Si7021 / SHT21 Temperature & Humidity HTU31D Temperature & Humidity Hydreon Rain Sensor Rain HYT271 Temperature & Humidity Inkbird IBS-TH1 Mini Temperature & Humidity Internal Temperature MCP9808 Temperature MH-Z19 CO2 & Temperature MLX90614 Temperature MPL3115A2 Temperature & Pressure MS5611 Pressure MS8607 Temperature & Humidity & Pressure NTC Thermistor Temperature PMWCS3 Soil moisture & Temperature QMP6988 Temperature & Pressure RadonEye BLE Radon RuuviTag Temperature & Humidity & Accelerometer SCD30 CO2 & Temperature & Humidity SCD4X CO2 & Temperature & Humidity SDP3x / SDP800 Series Pressure SFA30 Formaldehyde SHT3X-D Temperature & Humidity SHT4X Temperature & Humidity SHTCx Temperature & Humidity SMT100 Moisture & Temperature STS3X Temperature TEE501 Temperature TMP102 Temperature TMP1075 Temperature TMP117 Temperature XGZP68xx Series Differential Pressure Light¶ AM43 Lux APDS9960 Colour & Gesture AS7341 Spectral Color Sensor BH1750 Lux LTR390 Lux & UV MAX44009 Lux TCS34725 Lux & RGB colour TSL2561 Lux TSL2591 Lux VEML3235 Lux VEML6030 Lux VEML7700 Lux Magnetic¶ AS5600 12-Bit Magnetic Position Sensor ESP32 Hall Sensor HMC5883L 3-Axis magnetometer MLX90393 3-Axis magnetometer MMC5603 3-Axis magnetometer MMC5983 3-Axis magnetometer QMC5883L 3-Axis magnetometer Miscellaneous¶ AS3935 Storm lightning b-parasite Moisture & Temperature & Humidity & Light Binary Sensor Map Map binary to value Combination Duty Time EZO sensor circuits (pH) FS3000 Air velocity Growatt Solar Solar rooftop Havells Solar Solar rooftop Integration Kuntze pool sensor MicroNova pellet stove Modbus Sensor Nextion Sensors from display Person Sensor (SEN21231) Resol VBus Rotary Encoder SMT100 Moisture & Temperature Tuya Sensor TX20 Wind speed & Wind direction uFire EC sensor EC & Temperature uFire ISE sensor pH & Temperature WireGuard Motion¶ APDS9960 Colour & Gesture BMI160 Accelerometer & Gyroscope LD2410 Motion & Presence LD2420 Motion & Presence MPU6050 Accelerometer & Gyroscope MPU6886 Accelerometer & Gyroscope RuuviTag Temperature & Humidity & Accelerometer Seeed Studio MR24HPC1 mmWave Motion & Presence Thermocouple¶ KMeterISO MAX31855 K-Type MAX31856 All types MAX31865 Platinum RTD MAX6675 MCP9600 All types Weight¶ HX711 Load cell amplifier Xiaomi Miscale Looking for a sensor that outputs its values as an analog voltage? Have a look at the ADC Sensor together with a formula like in the TEMT6000 configuration. Binary Sensor Components¶ Binary Sensors are split into categories. If a sensor fits into more than one category, it will be listed multiple times. Core¶ Binary Sensor Core Template Binary Sensor GPIO Home Assistant Status Capacitive Touch¶ CAP1188 Capacitive Touch Sensor ESP32 Touch Pad MPR121 Capacitive Touch Sensor TTP229 Mechanical¶ Matrix Keypad TM1637 TM1638 NFC/RFID¶ Often known as “tag” or “card” readers within the community. NFC Tag PN532 PN7150 PN716X RC522 RDM6300 Wiegand Reader Touchscreen¶ Touchscreen Core FT5X06 GT911 Nextion Binary Sensor TT21100 Presence Detection¶ AT581X DFRobot mmWave Radar LD2410 LD2420 Seeed Studio MR24HPC1 mmWave Miscellaneous¶ Analog Threshold ESP32 BLE Presence Hydreon Rain Sensor Binary Sensor Modbus Binary Sensor PipSolar - compatible PV Inverter Pylontech Batteries Qwiic PIR Motion Remote Receiver Resol VBus Tuya Binary Sensor WireGuard Output Components¶ Output Core Template Output AC Dimmer BLE Binary Output BP1658CJ BP5758D DAC7678 EMC2101 ESP32 DAC ESP32 LEDC ESP8266 Software PWM GP8403 GPIO Output LibreTiny PWM MCP4725 MCP4728 MCP47A1 Modbus Output MY9231/MY9291 PCA9685 Sigma-Delta Output Slow PWM SM16716 SM2135 SM2235 SM2335 TLC59208F TLC5947 TLC5971 X9C Potentiometer Light Components¶ Light Core Binary Light Cold+Warm White Light Color Temperature Light ESP32 RMT FastLED Light H-bridge Light Light Partition LightWaveRF Monochromatic Light NeoPixelBus Light RGB Light RGBCT Light RGBW Light RGBWW Light RP2040 PIO Shelly Dimmer Sonoff D1 Dimmer SPI LED Strips Status Led Tuya Dimmer Looking for WS2811 and similar individually addressable lights? For the ESP32 and its variants, we recommend the ESP32 RMT LED Strip or SPI LED Strip Light; for other processors, have a look at the FastLED Light. Switch Components¶ Switch Core Template Switch BLE Client Switch Factory Reset Switch Generic Output Switch GPIO Switch Modbus Switch Nextion Switch Restart Switch Safe Mode Switch Shutdown Switch Tuya Switch UART Switch Button Components¶ Button Core Template Button Factory Reset Button Generic Output Button Restart Button Safe Mode Button Shutdown Button UART Button Wake-on-LAN Fan Components¶ Fan Core Template Fan Binary Fan H-bridge Fan Speed Fan Tuya Fan Display Components¶ Display Core Display Menu Core Font Renderer Graphical Display Menu LCD Menu Display Hardware Platforms¶ Addressable Light ILI9xxx ILI9341 ILI9342 ILI9481 ILI9486 ILI9488 WSPICOLCD Inkplate LCD Display MAX7219 Dot Matrix MAX7219 Nextion PCD8544 (Nokia 5110/ 3310) PVVX MiThermometer Quad SPI AMOLED RPI_DPI_RGB SSD1306 SSD1322 SSD1325 SSD1327 SSD1331 SSD1351 ST7567 ST7701S ST7735 ST7789V ST7796 ST7920 TM1621 TM1637 TM1638 TM1651 Battery Display Waveshare E-Paper Touchscreen Components¶ Touchscreen Core CST226 CST816 EKTF2232 Inkplate 6 Plus FT63X6 GT911 Lilygo T5 4.7” TT21100 XPT2046 Cover Components¶ Cover Core Template Cover AM43 Cover Current-Based Cover Endstop Cover Feedback Cover HE60R Cover Time-Based Cover Tuya Cover Text Components¶ Text Core Template Text Text Sensor Components¶ Text Sensor Core Template Text Sensor BLE Scanner Ethernet Info Home Assistant LibreTiny Modbus Text Sensor MQTT Subscribe Text Nextion Text Sensor Tuya Text Sensor Version WiFi Info WireGuard WL-134 Pet Tag Sensor Climate Components¶ Climate Core Anova Cooker Bang Bang Controller BedJet Climate System Haier Climate IR Remote Climate Midea PID Controller Thermostat Controller Tuya Climate Uponor Smatrix Base Pulse Underfloor Heating Number Components¶ Number Core Template Number Modbus Number Tuya Number Select Components¶ Select Core Template Select Modbus Select Tuya Select Lock Components¶ Lock Core Template Lock Generic Output Lock Media Player Components¶ Media Player Core DFPlayer I2S Audio Microphone Components¶ Microphone Core I2S Microphone Speaker Components¶ Speaker Core I2S Speaker Time Components¶ Time Core DS1307 RTC GPS Time Home Assistant Time PCF85063 RTC PCF8563 RTC SNTP Home Assistant Components¶ Components specifically for interacting with Home Assistant. Binary Sensor Bluetooth Proxy micro Wake Word Sensor Text Sensor Voice Assistant Alarm Control Panel Components¶ Alarm Control Panel Core Template Alarm Control Panel Datetime Components¶ Datetime Core Template Datetime Energy/Solar Management¶ PipSolar-compatible PV Inverter Power Supply Resol VBus SML SUN-GTIL2 inverter Electromechanical¶ Atlas Scientific Peristaltic Pump Grove TB6612FNG Matrix Keypad RTTTL Buzzer Servo Stepper Wireless Communication¶ Wireless communication that is not Wi-Fi. IR Remote Climate Remote Receiver Remote Transmitter RF Bridge SIM800L Miscellaneous Components¶ ESP32 Camera Exposure Notifications GPS Grow Fingerprint Reader Modbus Controller Sprinkler Status LED Sun Tuya MCU Custom Components¶ Note: Custom Components are deprecated in favor of External Components! Generic Custom Component Custom Binary Sensor Custom Climate Custom Cover Custom Light Custom Output Custom Sensor Custom Switch Custom Text Sensor Custom I²C Component Custom SPI Component Custom UART Component Cookbook¶ Lambda Magic: Tips and Tricks Garage Door Template Cover Time & Temperature on OLED Display ESP32 Water Leak Detector BME280 Environment extras Non-Invasive Power Meter Sonoff Fishpond Pump Arduino Port Extender EHMTX a matrix status/text display Share data directly between ESPHome nodes Do you have other awesome automations or cool setups? Please feel free to add them to the documentation for others to copy. See Contributing. If you’d like to share configurations for specific devices, please contribute to our ESPHome Devices database. A new version has been released since you last visited this page: 2024.4.1 🎉 Dismiss View Changelog",
    "commentLink": "https://news.ycombinator.com/item?id=40138228",
    "commentBody": "ESPHome (esphome.io)193 points by kaycebasques 11 hours agohidepastfavorite54 comments balloob 2 hours agoOne of the people leading ESPHome here. Let me know if there any questions. Last Saturday we announced that ESPHome is now owned by the Open Home Foundation. The Open Home Foundation fights for privacy, choice, and sustainability for smart homes. And for every person who lives in one. Learn more at https://www.openhomefoundation.org/blog/announcing-the-open-... reply Gazebra12 2 hours agoparentNo questions, only praise. This project is simply awesome, I've been astonished time and time again by the features. I had done a complete dive into the Espressif SDK trying to implement a wireless switch with temperature sensor and mqtt and had nearly finished the project when I stumbled on ESPHome obsoleting all of my work at once. It was just everything I had written so far plus many added features and obsoleted all my work at once. reply rubenbe 1 hour agorootparentI agree, programming is fun, but using ESPHome to quickly have project finished and working reliably is arguably even more satisfying. reply jtwaleson 1 hour agoparentprevThank you! I've rarely been as impressed by how well software works. Flashing, compiling, logging and OTA updates were always a PITA and with ESPHome it's a breeze. Logging over wifi feels like it shouldn't be that simple. I've created a mini IR receiver / transmitter to control my sound system with my TV remote. It was super simple to set up, and the integration with Home Assistant is great! reply sen 5 hours agoprevI've got 20+ devices running ESPHome, about 3/4 of them are part of my Home Assistant network, and maybe 6 or so that are standalone and just using ESPHome to talk to MQTT for other stuff (cheap Chinese weather station that I replaced the insides of with an ESP32, etc). I've got my rain water tanks monitored, my soil moisture in my greenhouse, the temperature and humidity in all different parts of the house, air quality in the kitchen and kids rooms, etc etc. It's such an underrated project. In literally 5 minutes and with $10 of hardware and no programming at all, you can build your own IoT devices in your home and get real-time data on anything you want on your property. reply throwup238 5 hours agoparentSame here, plus a dozen or so random ESP32 variants just sitting in my electronics parts box because they're so cheap. It's incredibly freeing to just have all that hardware available at arms reach whenever you have an idea. They're surprisingly reliable and with modules like the sprinkler controller, they can be programmed to be independent so that they keep running as long as they have power. It took me months to realize that HomeAssistant microSD card had failed last time because all of my hydroponics gear just kept running. By far the biggest time consumer has been wiring them up to DC/DC converters to drive relays in a waterproof Sockitbox. Another really useful part to keep around are wire terminal breakout boards: https://www.amazon.com/whiteeeen-Development-Expansion-ESP-W... Also CloudFree is great for off the shelf IoT parts that can be reprogrammed with ESPHome: https://cloudfree.shop/ reply darkwater 1 hour agoparentprevNow you MUST share more details on the hardware (case, power etc) and process you followed for all of those devices. reply alias_neo 1 hour agorootparentI keep a stockpile of cheap ESP32 and ESP8266s at home, and any time I need something \"ensmartened\" (opposite of enshittified?) I grab whichever one is appropriate, solder up what I need, design/3D print a case, flash it from my _other_ laptop which has Chrome on because Firefox doesn't support WebUSB :'(, and it'll show up in Home Assistant for adoption the moment it lands on my IoT WiFi network. reply regularfry 34 minutes agorootparentI did exactly this with WLED over the weekend, just to see what the ecosystem was like and what the capabilities are. That flow from soldered hardware to HA integration is astonishingly slick. reply macropin 2 hours agoparentprevHow do you power them? I've used ESPHome previously to scrape my solar analytics for consumption in Home Assistant using $3 Wittycloud ESP8266's. But as yet I haven't found an elegant solution for powering them other than using a USB adapter. It would be nice to find an elegant battery solution for outside sensors. reply spicyjpeg 58 minutes agorootparentYou can buy off-the-shelf modules that take a lithium ion cell and provide charging, overcurrent and overdischarge protection; just search your Chinese online retailer of choice for \"TP4056 module\" and you will find plenty of them. There is a Hackaday article [1] that goes in depth on how to use them properly. If you'd rather not wire it up yourself there are also ESP32 dev boards with built-in battery management functionality, such as the LoLin32 Lite and Sparkfun ESP32 Thing. I haven't had much luck with the former (possibly due to its lack of RF shielding) but the latter seems to be pretty solid. I think Adafruit sells similar boards as well. [1] https://hackaday.com/2022/10/10/lithium-ion-battery-circuitr... reply 15155 31 minutes agorootparentprevhttps://shop.m5stack.com/products/battery-module-13-2-1500ma... Featured yesterday on HN for being acquired by Espressif. reply Nextgrid 1 hour agorootparentprevCar \"cigarette lighter\" charger adapters are cheap and can take ~12V (and some even go up to 24) and give you a USB output. reply teekert 1 hour agoparentprevHow do you monitor your rain tanks? I tried ultra sonic sensors but they invariably oxidize. reply Faaak 1 hour agorootparentThere are black \"waterproof\" (weatherproof?) ultrasonic sensors that last a way longer time reply squarefoot 1 hour agorootparentprevThere are magnetic sensors in which a floating magnet (sealed in plastic) position is read by sensors (Reed, Hall, etc) sealed as well. reply macropin 1 hour agorootparentprevI've heard that pressure sensors are the most reliable. reply lostlogin 3 hours agoparentprevI agree with everything here, except the $10 of hardware. You must be running some very fancy chips! For extra savings the ESP8266 might be as low as $4us. It really is amazing. reply rubenbe 2 hours agorootparentI started valuing the enclosure that comes with the 10 dollar versions (e.g. the M5stack atom). Since most use-cases for me are literally 1 sensor connected to an Atom, it (largely) fixes the enclosure problem. Although I'd like to have more DIN rail mounted options. reply baq 2 hours agorootparentprevESP8266 is not recommended for new projects though. Its age is starting to show. reply Asmod4n 2 hours agorootparentprevOr you could buy a rpi2040 for 99 cents. reply hagbard_c 1 hour agorootparentThat'd get you the chip which you'd have to solder to a board. Possible and feasible but not as easy as plugging in an ESP8266. reply regularfry 25 minutes agorootparentYou would not only have to solder it to a board, you would also have to provide a radio peripheral. At which point you're pretty much looking at a pico W, which just isn't as cheap or small as a D1 Mini (or similar). reply dnchdnd 3 hours agoparentprevcan you share details of the weather station please? ive been looking into gathering wind data on the cheap... reply pzduniak 3 hours agorootparentI built mine using a Hydreon Rain Gauge sensor (RG11 in my case) and combined it with an off the shelf wind sensor from AliExpress, presumably sold by Adafruit's supplier, which closes a reed switch every rotation. Everything is powered through PoE, controlled by wESP32. I spent a couple hundred bucks at most including all the mounting hardware. It all controls an aluminum \"awning\" in my house that's supposed to open above certain wind speed, close when it rains. reply throwaway290 1 hour agoparentprevCould you recommend a good component for security purposes? Like if someone enters my flat without breaking in (I rent). The docs list a bunch of options... do I go for motion & presence or binary presence detector? Which sensor is better (and most cost effective)? reply petemir 1 hour agorootparentIkea's PARASOLL? I would expect that for your use-case, just knowing if a/the door was opened is already enough. reply throwaway290 57 minutes agorootparentIs Ikea stuff compatible with ESPhome? Never mind, parasoll costs like $12. I mean something like HLK-LD2420 which should be around $2. ESPHome lists many similar sensors and I was asking which one is better. Curious if anyone had any experience with any of those reply zeroping 5 hours agoprevRelated: A collection of device configurations for commercially-available hardware: https://devices.esphome.io/ A collection of Tasmota configurations for devices, many of which can also run ESPHome: https://templates.blakadder.com/ reply Liftyee 2 hours agoprevRunning a few ESPHome projects, it's great for rescuing those which I lost motivation to write code for. The ability to do processing on-device as well as with Home Assistant is neat, but writing those procedural routines with YAML takes a little getting used to. The concepts used in the ESPHome system design are not completely intuitive. reply reid 5 hours agoprevMade a time clock with ESPHome and a M5StickC. Clock in and out. Home Assistant sends the time to a Google Sheet. Super reliable. reply Apatheticdino 3 hours agoprevDove into this when I flashed my AirGradient device. At first I had a hard time understanding how everything integrated together (does ESPHome need a hub? how does HomeAssistant work with this?). After (mostly) figuring things out I discovered how powerful it is to have configurability ranging from OTA updates to MQTT support. My only gripe right now is the lack of documentation and confusion on the HomeAssistant side. The ESPHome addon turned out to be a red herring for getting everything set up. reply hendry 2 hours agoprevRequires nerves of steel to navigate Aliexpress. reply stavros 6 hours agoprevI don't use this, personally, but it strikes me as a fantastic idea. I made a sensor board and wrote my own firmware for it, maybe I'll see if I can easily configure ESPhome to run on it. The only thing I'd need that my thing already has is pull-based OTA updates. Right now I just copy a firmware to a folder, and all my sensors around the house automatically update to that firmware via an HTTP server. With ESPhome, I'd have to push the update to each sensor separately, which is tedious when you have tens of them. reply lelanthran 3 hours agoparent> I don't use this, personally, but it strikes me as a fantastic idea. I made a sensor board and wrote my own firmware for it, maybe I'll see if I can easily configure ESPhome to run on it. I've done pretty much the same, but last I looked there were very few resources (other than reading the code for the ESPHome project) to help on creating custom firmware for a new board with multiple sensors. It seemed easier and faster to simply write the firmware to talk to a simple backend. I'm also curious about how they get the code for esp32 devices to fit: on a device with 4MB flash, you effectively have a 1MB program limit if you want OTA (which you do). A simple program that does nothing but make calls to the libraries for GPIO, ADC, UART, Wifi, https, https server, interrupts, FreeRTOS, mqtt, nvs, chip info, logging, OTA and functions in the standard library (scanf alone uses 30kb) already takes you over the 1MB limit. Compiling with all the logging turned off can get you a roughly 800kb program, which is still close to the limits considering that doesn't include program logic. I'll have to look at this again when I next require some remote monitoring thing. reply jhogendorn 5 hours agoparentprevThe web interface has an 'update all' button thats just as convenient. I find if theres ones i want to not update i just temp break their yaml file with an unexpected keyword and it fails to compile and then update. reply stavros 4 hours agorootparentHm, I wasn't aware of this web interface. Is it some sort of management panel? Do I have to deploy it on prem? reply Havoc 2 hours agoparentprevYou should give it a try. ESPHome is super convenient. Especially the fact that you can flash them from a browser initially and over the air after that reply NegativeLatency 5 hours agoparentprevMaybe fewer bugs and need to make changes with this? I have a fair number of esp devices with temp probes around the house, and I’ve been meaning to switch to esp home so I have less code to maintain reply stavros 5 hours agorootparentYeah, definitely fewer bugs. Hopefully I won't mind the decreased flexibility, but the lack of HTTP updates really hurts. reply balloob 2 hours agoparentprevThis is coming in the next release. reply eternityforest 3 hours agoprevOne of my favorite projects in all of FOSS. The only big thing missing is power management! I just wish there was a little more native hardware. I wonder if there's enough interest to do a run of PLC-like units? reply Mashimo 3 hours agoprevIt's so nice. Just a simple .yaml file to configure IoT devices. And it works really well. reply gnyman 3 hours agoparentAnd the best part is that it allows you to write logic in C(++) if you want. I tried Tasmota first but struggled with trying to get the rules to handle my slightly complex logic. Which was that when a water level sensor triggered, run a pump 15 seconds, wait 5 mins, run 15 sec and repeat for x times. But with the catch that if the sensor triggered before the run was done, it should ignore that. After reflashing esphome I got it done in a few minutes in C. reply allenbina 5 hours agoprevI’ve been happy with tasmota but I imagine that this would serve the same purpose. reply M95D 2 hours agoparentIt is a lot more configurable than Tasmota, but a lot harder to do it. reply squarefoot 1 hour agoprevDoes it support some sort of mesh networking? reply djbusby 5 hours agoprevAnyone got this to replace their thermostat? Like sensors in zoneA signal and a device connected to the HVAC triggers ON? Maybe they're on WiFi or Ethernet connection? reply bsoft16385 1 hour agoparentI have 7 Mitsubishi heat pump head units being controlled using ESPHome running on D1 mini clones (ESP8266). The D1 mini clones are powered by and interface with the head units with Mitsubishi's CN105, which is just 5 volt UART. The total cost was maybe $30 of parts on AliExpress. I use 433Mhz Acurite temperature sensors with a software defined radio (rtl433) running on my Home Assistant box to have remote temperature sensing. The 433MHz sensors are cheap, have good range, and have excellent battery life. reply Szpadel 4 hours agoparentprevI have one over complicated in floor heater that requires 2 signals to control, one for opening radiator valve and second to enable fan to blow air through it. there is only few thermostats dedicated for such setup that are extremely expensive and I decided to make my own that is also better. i have 2 temperature sensors connected, one to monitor room temperature and the second touching radiator inside, then I'm able to open valve when room temperature is below threshold and wait until radiator is hot enough and we are trying to heat for few minutes (without fan this will also work but less efficiently, but will be silent) then when temperature is reached I close valve and keep fans on until radiator cools down. I also have temperature reported to home assistant where I have pyscript automation that controls AC based on multiple temperature sensors, open window sensors, humidity, presence, time, etc to most efficiently cool down my apartment if you need to get signal on a wire, you can output it from the same device, from other esphome device or through home assistant using integration. reply oleg_tarasov 3 hours agoparentprevActually I did exactly that :) I use ESPHome to control a gas boiler which heats my home. It's not without problems and required a lot of tinkering, but after the initial phase it required very little maintenance throughout the winter. This year I plan on adding an ability to control AC. https://news.ycombinator.com/item?id=40017176 reply seszett 4 hours agoparentprevThat's what I do at home. I have little Xiaomi LYWSD002MMC and LYWSD003MMC devices (the latter with custom firmware - pvvx) and my radiators are switched on or off (via their pilot wire) by an ESP device, using a few rules to lower the temperature when nobody's there. It works much better than the radiator's own thermostat. I control my devices (I have a lot more than just for the radiators) through a kind of interface that I wrote myself (PHP and only very few, reliable dependencies) because I hate maintaining Home Assistant. reply balloob 2 hours agoparentprevI use this one and it works great: https://github.com/kbx81/ClimateSprinklerController reply kiney 2 hours agoprev [–] I'm jist getting started with home automation and have a couple of ESP32 running tasmota. How do they compare? Thr site explains how I can migrate bit not why or under which circumstances I should... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ESPHome is an open-source project allowing microcontroller control via configuration files and integration with Home Automation systems.",
      "It supports sensors for monitoring temperature, humidity, CO2, and more, and features components for climate control, alarm systems, and wireless communication.",
      "Users can exchange data between devices, contribute to documentation, and discover the newest release, 2024.4.1."
    ],
    "commentSummary": [
      "ESPHome, from the Open Home Foundation, is popular for simplifying DIY IoT devices to monitor home conditions such as temperature, humidity, and air quality.",
      "Users suggest wire terminal breakout boards and CloudFree for flexible parts in creating IoT devices.",
      "Discussions involve sensor options, affordability, and compatibility, with users sharing positive experiences and considerations when moving from Tasmota to ESPHome for home automation."
    ],
    "points": 193,
    "commentCount": 54,
    "retryCount": 0,
    "time": 1713912404
  },
  {
    "id": 40132373,
    "title": "Introducing Getada: Simplifying Ada Toolchain Installation",
    "originLink": "https://getada.dev",
    "originBody": "One of my goals with Ada is to have a one-liner copy-paste terminal command for people to install Ada so they can get to coding in just a few minutes. After extensive testing I feel like it&#x27;s ready for general release[1].Getada was inspired by Rustup[2] and aside from the init script is written entirely in Ada.It&#x27;s completely open source and you can check out the readme and code on github[3]. It currently supports all non-windows platforms that Alire has an official release for, which at present is Linux (glibc) and MacOS. If you try running it on an unsupported platform, it tries to point you in the right direction. For example, you can install Alire on windows with an already-existing installer.It downloads the latest version of Alire[4] (Ada&#x27;s toolchain and package manager, similar to Cargo) for your platform as a zip file to a temporary directory and then extracts it to a binary directory. By default the temporary directory (configure with \"-t &#x2F;directory\" or \"--tmp=&#x2F;directory\") defaulted to $TMPDIR or &#x2F;tmp. The config directory is ~&#x2F;.getada (change via \"-c &#x2F;directory\", \"--cfg=&#x2F;directory\", or $GETADA_CFG), and the alr and getada binaries go in ~&#x2F;.getada&#x2F;bin (configure with \"\"-b &#x2F;directory\", \"--bin=&#x2F;directory\", or $GETADA_BIN). It also tries to add the file to your path by dropping a \"env.sh\" file into ~&#x2F;.profile&#x2F; (disable with -p or --no-path).If you don&#x27;t allow executables in temporary or home directories, you can change all of these via environmental variables or passing parameters.You can remove it all by running: getada --uninstallNow you can create a brand new Ada project with: alr init --bin my_project (How to use Alire[5] for more details)Since one of the biggest complaints about Ada is getting the toolchain [6], I hope this can solve a lot of problems for newcomers to the language.[1] https:&#x2F;&#x2F;www.getada.dev[2] https:&#x2F;&#x2F;rustup.rs&#x2F;[3] https:&#x2F;&#x2F;github.com&#x2F;aj-ianozi&#x2F;getada[4] https:&#x2F;&#x2F;alire.ada.dev&#x2F;[5] https:&#x2F;&#x2F;www.getada.dev&#x2F;how-to-use-alire.html[6] https:&#x2F;&#x2F;programming.dev&#x2F;comment&#x2F;9438211",
    "commentLink": "https://news.ycombinator.com/item?id=40132373",
    "commentBody": "Getada: rustup-like installer for Ada's toolchain/package manager (getada.dev)182 points by ajdude 19 hours agohidepastfavorite110 comments One of my goals with Ada is to have a one-liner copy-paste terminal command for people to install Ada so they can get to coding in just a few minutes. After extensive testing I feel like it's ready for general release[1]. Getada was inspired by Rustup[2] and aside from the init script is written entirely in Ada. It's completely open source and you can check out the readme and code on github[3]. It currently supports all non-windows platforms that Alire has an official release for, which at present is Linux (glibc) and MacOS. If you try running it on an unsupported platform, it tries to point you in the right direction. For example, you can install Alire on windows with an already-existing installer. It downloads the latest version of Alire[4] (Ada's toolchain and package manager, similar to Cargo) for your platform as a zip file to a temporary directory and then extracts it to a binary directory. By default the temporary directory (configure with \"-t /directory\" or \"--tmp=/directory\") defaulted to $TMPDIR or /tmp. The config directory is ~/.getada (change via \"-c /directory\", \"--cfg=/directory\", or $GETADA_CFG), and the alr and getada binaries go in ~/.getada/bin (configure with \"\"-b /directory\", \"--bin=/directory\", or $GETADA_BIN). It also tries to add the file to your path by dropping a \"env.sh\" file into ~/.profile/ (disable with -p or --no-path). If you don't allow executables in temporary or home directories, you can change all of these via environmental variables or passing parameters. You can remove it all by running: getada --uninstall Now you can create a brand new Ada project with: alr init --bin my_project (How to use Alire[5] for more details) Since one of the biggest complaints about Ada is getting the toolchain [6], I hope this can solve a lot of problems for newcomers to the language. [1] https://www.getada.dev [2] https://rustup.rs/ [3] https://github.com/aj-ianozi/getada [4] https://alire.ada.dev/ [5] https://www.getada.dev/how-to-use-alire.html [6] https://programming.dev/comment/9438211 rami3l 10 hours agoAs a current Rustup maintainer with a bit of Ada background I gotta say: nice work! I do feel Ada as a language is way ahead of its time, but when I was learning it (a while before the first Alire release) I was also puzzled by dev environment setup. I guess the Rust experience has shown the importance of a friendly onboarding experience, so I’m very glad to see Ada is going this direction as well with Alire and now Getada :) reply apitman 10 hours agoprevI got my start programming through an avionics apprenticeship. My first project was porting an Ada project to C. Still hurts my heart to think about now that I'm experienced enough to appreciate a lot more of the implications. reply throwaway81523 12 hours agoprev> One of my goals with Ada is to have a one-liner copy-paste terminal command for people to install Ada so they can get to coding in just a few minutes. After extensive testing I feel like it's ready for general release[1]. I never had trouble with this? Apt-get install gnat or similar has always worked for me. I only played around with Ada though, never did anything serious with it. Installing from source wasn't too bad either. But, trying to install spark from source was a big mess back in the day. I don't know about now. reply tormeh 11 hours agoparentWhat's cool about rustup is having many different versions of the same toolchain installed at the same time, and automatically using the appropriate toolchain version for a project. That's downright magical. reply ajdude 10 hours agorootparentYeah, that's another major benefit; I can get different toolchain versions or even cross-compile to different architectures via \"alr toolchain --select\" reply 01HNNWZ0MV43FF 9 hours agoparentprevDistro package managers often lag by a bit, hence the explosion of language-level package managers in the last... when did NPM come out... 14 years reply adezxc 18 hours agoprev> Since one of the biggest complaints about Ada is getting the toolchain [6], I hope this can solve a lot of problems for newcomers to the language. It might be just me, but Alire isn't great, I tried it multiple times, it's great for getting complicated dependencies e.g Utilada, but I go for GPRBuild as it just avoids all the fuss when programming across Linux/macOS. I might try a hard switch at one point as I didn't use Alire 2.0.0 that much, so maybe it's better now. reply Avshalom 15 hours agoparentI believe you'll find its actually utilada alire doesn't let you use capital letters... reply anta40 6 hours agoparentprevalire is similar to virtualenv, yes? Every time you create a project, a fresh Ada toolchain will be downloaded. reply synack 4 hours agorootparentThe toolchain is cached, so it only gets downloaded once. reply anta40 3 hours agorootparentReally? Hmm let me check Alire again. reply Lucretia9 17 hours agoparentprevAlire is a frontend to the toolchain, including gprbuild, it just handles grabbing the projects as well. reply adezxc 16 hours agorootparentYes, but it kinda locks you into running 'alr build' and adds other things inside 'config' directory like user's distro and other things. My guess it's probably great when you already have a done project and want to publish it, but if you want to compile your code ASAP, it's much easier to avoid it completely (except for pulling packages) reply ajdude 15 hours agorootparentAlire puts \"/obj/\", \"/bin/\", \"/alire/\", and \"/config/\" into its .gitignore when creating a new project so the platform-specific stuff shouldn't end up on other developer's machines. After your initial \"alr init --bin myproj\" you can dive into your \"myproj.gpr\" and do more than what alire supports in its toml file. reply adezxc 12 hours agorootparentWe use SVN in our university lab, so no, that didn't work when I tried it initially. obj and bin was obvious to ignore, but I wasn't so sure about config and alire, might be helpful though reply Avshalom 13 hours agorootparentprevwhich is fine if you're using git. Just like asking me for my github login would be fine, if I used github and expected to ever distribute sdl_helloworld. reply crabbone 13 hours agorootparentprevTurns out putting \"config\" in .gitignore isn't a very good idea. Or, at least, there's a problem with what setting go into \"config\". In particular, compiler options, end up ignored... I had to undo it in the project I'm working on because I got tired of having to restore these options every time I change something else in dependencies / other project configuration. reply kevlar700 13 hours agorootparentprevliterally alr init --bin new_project cd new_project alr edit reply crabbone 13 hours agorootparentprevWhat's the need to compiler code ASAP? I understand it that you mean the initial effort, as running whatever command you normally use to build will have just the same amount of effort regardless of its length... But, even if for some reason you are typing it out every time: the difference will amount to just a few characters... I mean, how long of a delay are we talking about? ---- As an aside, for me, a newcomer, GPRBuild is hard to deal with. I've dealt with at least a dozen of build systems, and GPRBuild isn't something I'm excited about. It belongs in the same category as Maven / Gradle / MSBuild / Bazel etc.: very bad at debugging, very limited documentation, impossible to tell what things are possible... The way for me to deal with GPRBuild is to create a project file using Alire, and when something breaks -- use Web search to find what needs to be changed. GNAT's errors are in general very, very bad, but when it comes to GPRBuild, it's almost like MS: the only use for the error message is that it's hopefully unique enough that there's a KB article somewhere that references it by id. reply didip 16 hours agoprevThis is amazing. devX matter a lot for adoption. I keep hearing about Ada a lot but the learning experience were difficult when I tried it. reply kevlar700 14 hours agoparentDid you come across? https://learn.adacore.com reply inamberclad 18 hours agoprevI'm a little confused - is this just a wrapper around https://alire.ada.dev/ ? That tool itself isn't very hard to install. reply ajdude 17 hours agoparentGetting alire installed involves downloading the zip, extracting the binary, and moving the binary to a directory in $PATH. If you're on a mac, you also have to run an \"xattr\" command on the tool to get it running. I've seen the last parts get newcomers tripped up so Getada takes the rustup approach. It uses github's api to retrieve the latest published release of alire[1] and then downloads and extracts it to a specified directory in $HOME. Then it creates an env file[2] and sources that file in .profile and/or .zshenv. It also logs everything that it does so it can undo it later with getada --uninstall [1] https://github.com/alire-project/alire/releases [2] Here's roughly what the env file looks like that it creates https://github.com/AJ-Ianozi/getada/blob/main/src/shells.adb... reply Karellen 17 hours agorootparent> Getting alire installed involves downloading the zip, extracting the binary, and moving the binary to a directory in $PATH. If you're on a mac, you also have to run an \"xattr\" command on the tool to get it running. Is that considered a high bar for software developers to get right? reply adastra22 17 hours agorootparentIn practice, yes. reply zilti 10 hours agorootparentWe're doomed. reply workingjubilee 4 hours agorootparentyeah, g-d forbid that any routine busywork gets automated by software, otherwise all those lines of code might actually have a point! reply zilti 1 hour agorootparentThat is literally a bash oneliner - pipe curl into tar, and have it unpack to ~/.local/bin. reply vips7L 17 hours agorootparentprevShouldn't a good package manager just take care of those steps? reply zilti 1 hour agorootparentprevThat is literally a bash oneliner - pipe curl into tar, and have it unpack to ~/.local/bin. reply crabbone 13 hours agoparentprevAlire is kind of a bummer on musl systems... I don't know if this tool solves the problem, but on musl systems (eg. Apline) you have to build Alire from source... i.e. bootstrapping, dependencies... it's not pretty. reply ajdude 12 hours agorootparent> I don't know if this tool solves the problem Not yet but it's on my list as a \"phase 2\" of sorts for getada. I have an alpine VPS that I'm playing around with but the main issue is that while alire can be built for alpine, any compilers it pulls from its toolchain won't work with it since none of them are built against musl. We've been talking about it here https://github.com/alire-project/alire/issues/792#issuecomme... reply ultra_nick 18 hours agoprevBringing Ada into the 21st century bit by bit. reply owlstuffing 11 hours agoparentYep, happy to see it, well deserved. Def a sleeper with tons of potential. Comprehensive IntelliJ-level IDE tooling could bring Ada to the forefront where it belongs. Would be nice anyway. reply sitzkrieg 17 hours agoparentprevOther ecosystems are still catching up in some ways reply fer 18 hours agoprevOn a related note, here's a throwback for old-timers: https://adagide.martincarlisle.com/ reply agsacct 17 hours agoparentone of my old professors. Blast from the past! reply xyproto 18 hours agoprevDoes this make it possible to use Ada and SDL2 on Linux? reply synack 18 hours agoparentSDLAda has been around for a while: https://github.com/Lucretia/sdlada You can add it as a dependency to your Alire project: `alr with sdlada` reply nmz 17 hours agoparentprevWhy can't you use sdl on ada? You can use raylib fine enough. https://www.youtube.com/watch?v=MUISz2qA640 reply xyproto 14 hours agorootparentI've had issues with the combination of Ada + SDL2 + Linux in connection with https://github.com/xyproto/sdl2-examples. Raylib is cool, though. reply Lucretia9 13 hours agorootparentLook at the \"Linking\" section https://github.com/ada-game-framework/sdlada I'm looking into getting it all automated through pragma's and gpr's. reply trollian 18 hours agoprevHow is this not called \"Byron\"? reply pixelatedindex 13 hours agoparentIs this supposed to be a reference to something? I'm not following this logic :( reply sebtron 12 hours agorootparentByron (the poet) was Ada Lovelace's father reply nmz 17 hours agoparentprevStop being smart. The tool is called GetAda, what does it do? It gets ada. What would byron do? will you remember 3 years from now? reply fiddlerwoaroof 16 hours agorootparentWhat happens when the community decides this one isn’t good enough and comes up with a replacement? The problem I’ve always had with these descriptive names is (a) they are often hard to google because they conflict with all sorts of documentation about the problem space and (b) when they’re deprecated, they become a trap for beginners. “Cute” project names are better for the same reason as we don’t name children and pets random English phrases describing them. reply jrockway 16 hours agorootparentThe replacement can just be called getada2. It worked for Python's standard library (unittest2 and all that). reply nmz 13 hours agorootparentOr fetchAda or grabAda, english is filled with synonyms. reply jclulow 17 hours agorootparentprevWell then surely it should be \"UpdAda\"? (I hardly...) reply timeon 11 hours agorootparentHow about \"AddUp\"? reply ithkuil 17 hours agoprevThis! Tooling ease of use matters! A lot of interesting tech died off or never took off because the tooling was just too cumbersome to setup and use. reply dijit 16 hours agoparentHonestly I think a lot of the Rust zealotry is because the tools are amazing. If it was just rustc on it's own I doubt it would have people chest-thumping like they do. I say this, as a lover of Rust: precisely because of Cargo, rustup and the crate system. reply andrewflnr 16 hours agorootparentI would be slightly more cynical and suggest that the easy tooling enables people prone to cheap chest-thumping to get into the language, when otherwise those types would probably wander somewhere else. The difficulty of the borrow checker will already create investment-induced loyalty[0], but if the first difficulty isn't even unique to the project, then the interesting difficulty doesn't have a chance to work. Speaking, myself, as someone who likes Rust but wishes people would be more clear-eyed and less obnoxious about it. [0] Someone remind me what the standard term for this is? You know, the thing where people get really emotionally invested in things where they've invested a lot of time and effort, like Vi or Emacs or Dark Souls? reply flakes 16 hours agorootparent> investment-induced loyalty Would generally refer to this as a sunk cost dilemma reply andrewflnr 15 hours agorootparentI thought about trying to use \"sunk cost\", but I usually see it written as \"sunk cost fallacy\" and that's a (closely related, but) slightly different thing. reply sammoe13 13 hours agorootparentprevI often use the phrase \"[I/he/she/they/we] have already sunk so much time into ...\" Not dissimilar to \"sunk cost\". reply hu3 16 hours agorootparentprevEve more so in Go where the single standalone executable can: - run code - build code - format code - generate code - profile code including flame graphs - run tests and report performance down to allocations - benchmark code - manage packages - manage workspaces - scan and vet suspicious code It's amazing how much a 2 character command can do. reply hyperman1 15 hours agorootparentSince I started programming, I see every generation of programming languages slowly raise the bar. From the top of my head, in the order I encountered them. * C: make gave a standard way to compile/link a program. * Perl: CPAN as standard library/repository location. * Java: javadoc gave a standard format for low level documentation. Rules like 1 file=1 class, 1 folder=1 package gave a standard source tree layout. * Java/maven gave standard way to download, install and upgrade dependencys * Go: Built in formatter. * rust: cargo combines the strengths of Go standardization and Java/maven repositorys Every iteration provides extras that the previous tooling generation sees as trivial. They'll say you can add them to the mix yourself if you want to. Their company likes things in a different way, and are happy to have the option. But that's missing the point. The whole language ecosystems standardizes on a reasonable (but not 100% perfect) way of working. This has a lot of secondary benefits: * People move easily between organisations with minimal up-to-speed costs. * Somewhere in the ecosystem, someone still has your ancient tooling version, and the upgrade path is clear(er). * No discussion about in-house standards. (Try to get 2 C programmers agree on a coding style and watch the hours fly discussing what to take from ugly K&R vs ugly GNU.) * Real pain-points get solved, because someone feels your pain. I've seen the in-house stack developed by a Cobol company. It's finely tuned to that 1 company, yielding huge benefits. It's also a very non-trivial investment and maintenance cost. reply jrockway 16 hours agorootparentprevgofmt is actually a separate command. reply hu3 14 hours agorootparentIndeed! And it can be called from go command too: go fmt main.go https://pkg.go.dev/cmd/go#hdr-Gofmt__reformat__package_sourc... reply jchook 5 hours agorootparentprevAnd yet, the number of times 3rd party Go code has died on my macOS machine due to a segfault... reply ithkuil 15 hours agorootparentprevI agree. Same with Go. When I started with Go, I quickly forgave it all little rough edges in the language itself because they were offset by a tooling that was just miles ahead the state if the art of the time. reply kevlar700 13 hours agorootparentThey have improved go modules since but if you didn't use github gos tooling wasn't so great. I actually dropped Go for Ada and prefer Adas packaging. reply ithkuil 4 hours agorootparentThe package management story before go.mod was sad but I have to plat devil's advocate and point out that GitHub did have special treatment by go get, you could use any domain name to host your code and you just had serve atag in a html file and you could tell go where to fetch your code (several version control tools including Mercurial are supported) reply zamalek 15 hours agorootparentprevI chest thump because more errors happen at compile time, and fewer at runtime. The tooling is what I would consider basic competency these days. Go has a similar tooling story and, while I do enjoy the language, it doesn't inspire chest thumping. reply randomdata 13 hours agorootparent> I chest thump because more errors happen at compile time, and fewer at runtime. Why Rust, then? It is not particularly good on this front. Hardly the worst, but is still pretty Mickey Mouse compared to the languages that excel here. I expect the zealotry/chest thumping is entirely a product of fashion. There are some things about Rust that are truly great, but nobody would go out of their way to mention it if it wasn't what is in style. reply zamalek 12 hours agorootparentPeople get pretty riled up about the likes of Haskell, Elm, and OCaml. Rust brings some of the virtues of functional into procedural code/average developer hands, and out of \"monads are just a monoid in the category of endofunctors.\" At the end of day, people are afraid of functional languages. It doesn't matter how amazing they are if almost everyone is too scared to use them. reply randomdata 12 hours agorootparent> Rust brings some of the virtues of functional into procedural code/average developer hands But so does, say, ATS and does a better job on the aforementioned merits. But, indeed, it is not in fashion. > At the end of day, people are afraid of functional languages. To be fair, they are also afraid of Rust. reply kevlar700 9 hours agorootparentI'm not afraid of functional programming. I just dislike it. I avoid recursion in Ada personally (others like it). I think OOP is over rated and the clarity of imperative is under rated. Though I do like how Ada provides object oriented design to imperative programs even without touching Adas OOP features (tagged types). reply tome 1 hour agorootparentprevWhy are people afraid of functional languages? reply bluGill 16 hours agorootparentprevI'm a hater of rust because of cargo and cargo - while it makes getting started easier, it is one of several opinions rust forces on me that are not compatible with my current code and so it make it more difficult to figure out how to incrementally start using rust in my code base. For small greenfields projects it is nice, but I'm not in that world and rust is fighting me. reply dijit 55 minutes agorootparentThat's fair, opinions are annoying when they don't align with your own (for me for example; I really hate that go-imports are URLs and the monorepo story for them is really bad... which I find ironic). If you like rust, but hate Cargo, I'd suggest looking at building with Bazel :D Bazel is a build system, but I don't use it as much as I'd like precisely because I'd have to manually write out all the DAG stuff. reply IshKebab 14 hours agorootparentprevPart of it is, but the language is also great. It isn't Zealotry. Rust really is that great. Not flawless (async is a big wart), but still fantastic. I would say that applies much more for Go, where the language is decidedly meh, but the tooling is fantastic. Arguably even better than Rust. reply zilti 10 hours agoparentprevAh yes, when using your package manager is too cumbersome... reply glass-z13 18 hours agoprevI don't know if it's the algorithm but for the past few months i've been seeing bits and pieces in random places about ada. Is there a reason the language is seeing more traction lately? I would assume the whole White House \"approved\" languages had something to do with it reply ajdude 18 hours agoparentAda's been steadily making a reassurance I think since safer languages like Rust had started to gain traction. It appeared for the first time ever on the stackoverflow survey for example. It used to be hampered down by confusing licenses but around 2021 those constraints were lifted when Adacore's \"GNAT Community Edition\" was retired. This was around the time Alire (works similar to if you combined Rustup with Cargo) came on the scene which meant getting the FSF version of the compiler was as trivial as running \"alr toolchain --select\". The most recent standard came out in 2022 along with a more centered community. Most of the ada community was living in a newsgroup (comp.lang.ada) until a year ago, and now ada-lang.io is gaining a lot of traction. Then Alire 2.0 just recently came out which made everything even more streamlined. Ada has been my favorite language for years, so I'm happy to see more people noticing it. reply brabel 17 hours agorootparentI tried learning Ada a few years ago and was really put off by GNAT. Installation was something straight out of the 80's and I just forgot about it after a little fussing around without getting anything working. Great to know that's no longer the experience with Ada, I might finally get it and try to start a project using it. reply riku_iki 16 hours agorootparentprev> Ada's been steadily making a reassurance I think since safer languages like Rust had started to gain traction Why one would use Ada now when it looks like there are much stronger contenders in this space: rust for close to metal and C#, Java, Go for slower programs? reply sevagh 5 hours agorootparent>Why one would use Ada now when it looks like there are much stronger contenders in this space: rust for close to metal and C#, Java, Go for slower programs? Define stronger? C#, Go, Java probably by wide use in enterprise/industry, but Rust? Power of sunshine and rainbows? Wishful thinking? reply riku_iki 4 hours agorootparent> but Rust? Power of sunshine and rainbows? Wishful thinking? adaptation, active community, more modern features, larger ecosystem reply fwip 14 hours agorootparentprevAda has features built in that those languages do not have. Off the top of my head, Ada has \"restricted types\" (e.g: you can say a function takes an integer of the range 5-15 only), as well as pre-and-post conditions you can annotate your procedure definition with. reply riku_iki 14 hours agorootparentIt sounds like this can be implemented as some 3p libs, and not necessary be a part of language? reply ajdude 13 hours agorootparentI like in Ada's type system in that I can do constraints such as \"type Positive is Integer range 1 .. Integer'Last;\" to give me a number that I know must always be in the positive range of an integer, and it's easily readable in plain text. From what I have read, trying to do something like \"type Element is Integer range 100 .. 1000;\" in rust requires something along the lines of struct BoundedU16(u16); impl BoundedU16 { pub const fn new(value: u16) -> Result { if value >= MIN && valueAda is far better than Rust for close to metal as it was designed for it. Sorry, can you elaborate on this? Rust was also designed to be close to the metal, so I'm assuming that there's some concrete difference that you're referring to. > Ada has also been demonstrated to be more cost effective over a programs lifetime than C, C++ and Java. Do you have a citation for this improved cost-effectiveness? Things like that are notoriously difficult to prove, so I'd be curious to know how this was measured. reply kevlar700 9 hours agorootparentAdas specification was developed competitively over a number of years with embedded development as well as the ability to replace all 450 languages in use by the D.O.D. at the time as requirements. Rusts first official specification is still in the works aside from the one created by AdaCore. Representation clauses are just beautiful for embedded memory-mapped registers and network protocols and driver registers received over spi/i2c etc.. There is even built-in validity checking. No need to shift generally as the compiler does everything for you. https://learn.adacore.com/courses/Ada_For_The_Embedded_C_Dev... The D.O.D study that includes Java would need to be dug up but this one is interesting too. https://forum.ada-lang.io/t/comparing-the-development-costs-... I only found out recently that the D.O.D. Ada mandate didn't say you had to use Ada. It said you had to demonstrate why your project would be more cost-effective than using Ada. Considering Ada was designed with cost-effectiveness/maintainability as a primary requirement then that was a difficult task. reply kitd 16 hours agorootparentprevOof! You were going so well . reply spauldo 18 hours agoparentprevMy guess? There have been a few high profile security CVEs lately and the \"why are we still using C\" crowd is louder than usual. Ada's a viable alternative for performant system code, and it's kind of the underdog to Rust. reply nicce 17 hours agorootparentAda is not memory safe language tho, while it might make it a bit harder to introduce those bugs. reply ajdude 17 hours agorootparentAda is memory safe if you just work with the stack or avoid Unchecked_Deallocation. Since functions can allocate and return entire arrays and other data structures completely on the stack, you don't need to mess with the heap that often (and when you do, you can also define your own memory pools). If you have to use dynamic allocation, you could also use the built in container libraries or controlled types for additional safety. Though if you want the kind of memory safety that Rust has, there's always SPARK (a subset of Ada). reply bluGill 15 hours agorootparentIs there a free version of SPARK? Proven correct code appeals to me, but I don't enjoy trying to get anything past purchasing. reply ajdude 15 hours agorootparentSPARK is free by default, and readily available. You can use it as-is in ada by adding \" with SPARK_Mode => On\" to your code; here's some examples: https://learn.adacore.com/courses/intro-to-spark/chapters/01... You can install gnatprove with alire via \"alr install gnatprove\" reply mcguire 13 hours agorootparentIt's been a while since I looked at SPARK and Ada, but the last time I did, SPARK was very well integrated with the GNAT Studio IDE. I still preferred frama-c, because C, but it's a really nice toolchain. reply kevlar700 12 hours agorootparentprevAda goes beyond memory safety. reply Barrin92 17 hours agoparentprevI saw a fairly popular programming Twitch streamer / Youtuber put out a bunch of Ada content recently, don't know if it's cause or effect but content creators seem to have a bit of influence these days. Was definitely the case with the recent htmx wave. reply jjgreen 18 hours agoprevnext [11 more] [flagged] nmz 17 hours agoparentWhats the viable alternative? reply Karellen 17 hours agorootparentsudo apt install gnat :-) reply nmz 13 hours agorootparentbash: sudo: command not found :) reply zilti 10 hours agorootparentThank goodness, someone with a decent distro reply jjgreen 17 hours agorootparentprevIf you curl > install.sh sh install.sh then you have a copy of what you just executed reply brabel 17 hours agoparentprevBecause downloading an installer from the same website you curl from is so much safer, right? /s reply jjgreen 17 hours agorootparentYes, it is. Because the server can detect curlsh, serve different content and you will never know about it. Discussed numerous times on this site. https://web.archive.org/web/20230304061743/https://www.idont... reply brabel 12 hours agorootparentWhen you download an installer, unless you reverse engineer it you also have no idea what it's doing. As others said, you must trust the domain you're downloading from in both cases. I really don't understand why people still argue about it. When you study security threat models, you should immediately understand that there's no difference from a security point of view. Perhaps the only alternative that's more secure is when you install the package from a package manager or app store... as in that case you have some sort of guarantee that the binaries are \"vetoed\" by someone who knows what they're doing it, hopefully.. i.e. you transfer your trust to the package manager's owners/maintainers... but you still need to trust the package publisher is not bent on trying to get you, because if they are, they will still find ways around package managers. reply yjftsjthsd-h 17 hours agorootparentprevUnder what threat model would that matter? reply nicce 17 hours agorootparentprevYeah, but your trust is always on the domain owner anyway. reply max-privatevoid 15 hours agoprev [–] Just use Nix reply zilti 10 hours agoparent [–] Or Guix reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Getada is a one-liner terminal command, similar to Rustup, enabling users to conveniently install Ada and its toolchain Alire on Linux and MacOS.",
      "It is an open-source tool that automatically fetches the latest Alire version, configures essential directories and paths, targeting to streamline Ada programming initiation for novices."
    ],
    "commentSummary": [
      "Getada simplifies the installation of Ada's toolchain and package manager on Linux and MacOS with a one-liner command, inspired by Rustup.",
      "Discussions revolve around various package managers and version control tools for Ada projects, emphasizing the significance of efficient installation processes for newcomers.",
      "The community explores Ada's unique features, advancements, comparisons with languages like Rust, C, and Java, as well as using SPARK and security considerations when downloading programming tools' installers."
    ],
    "points": 182,
    "commentCount": 110,
    "retryCount": 0,
    "time": 1713882386
  },
  {
    "id": 40132719,
    "title": "Decoding the Intrigues of Ableton Live Suite 12",
    "originLink": "https://twitter.com/gf_256/status/1782656618015904103",
    "originBody": "im pirating Ableton Live suite 12the .NFO has an interesting tidbit:\"does not modify any original binaries\".How does it work? lets find out. live reversing thread lets go pic.twitter.com/IFGQFeYqL8— cts🌸 (@gf_256) April 23, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40132719",
    "commentBody": "Reverse engineering a software crack (twitter.com/gf_256)181 points by nharada 19 hours agohidepastfavorite69 comments msla 16 hours agoThreadreader: https://threadreaderapp.com/thread/1782656618015904103.html?... Archives: https://archive.ph/rpFft https://web.archive.org/web/20240423175847/https://threadrea... stong1 13 hours agoprevOh hey, this is my thread. Thanks for reading, yall!... it seems to be good enough as they have no recent cracks. challenge accepted reply eps 1 hour agorootparentYeah, the GP should've not said that. reply reactordev 12 hours agoparentprevWhile code signing and verification is the way, you should also include a step on your own and not rely on the OS to do that for you. Apple’s code signing has been bypassed a few times. Granted they patch it, however one can include a script that enables developer mode in a terminal process that can then disable code signing (enable in-secure apps via developer-mode AppleScript). It’s impossible to get past inspection on the Apple Store due to that extra script in the app bundle but a downloaded dmg off the web… reply alin23 12 hours agorootparentYes, I was referring to the fact that I do a manual code sign check in my own code. Otherwise, Gatekeeper will be happy to run any cracker-signed app, they even found ways to staple forged notarization tickets. Manual code sign checks can only be cracked by patching the binary, which requires a lot more effort than swizzling some methods in a dylib. Or by process injection with Frida, but that requires disabling SIP which most people won’t do just for a cracked app. reply doix 5 hours agoparentprevThis is different though, because it's modifying the executable to load the new lib, right? If you're modifying the executable anyway, why not just patch it directly instead of going through these hoops? The equivalent on Linux would be setting LD_PRELOAD and putting your .so file there. A quick Google search seems to imply that the OSX equivalent is DYLD_INSERT_LIBRARIES but I have no idea how similar they are. reply bobmcnamara 9 hours agoparentprevSometimes fixing integrity checks can be as simple as replacing the failure case with nops :) reply int3 11 hours agoparentprevseems like crackers could just patch the app code that detects this, no? reply alin23 11 hours agorootparentFor sure, it’s just a bit more effort to reverse the app binary and find that part of the code. Enough effort to deter most crackers apparently. reply internetter 10 hours agorootparentThe macOS cracking scene is also much much weaker. It's 1. Mildly harder on a OS level 2. Less popular in countries that produce the most cracks 3. Less popular in general 4. Has an audience that is demonstrably more likely to pay for software 5. Has less strong reverse engineering software. Hopper was awful. Also, I just wanted to say I love your work. I've learned a lot from your blog, your free trial strategies are interesting, and quite effective: https://shottr.cc/s/1vQa/SCR-20240423-re6.png reply ghostpepper 6 hours agorootparent> 4. Has an audience that is demonstrably more likely to pay for software The flip side of this is that I've noticed software written solely for macOS/iOS is often more polished than many of the most popular FOSS projects written for Linux. Obviously I don't have any expectation of software provided for free, but as someone who makes a living developing software I do find it funny how much reticence there is among other developers to pay for high quality software. reply internetter 5 hours agorootparentI am a developer who likes to be paid for my work. I was also a diehard FOSS fan. I've also switched to macOS, and after I did so I spent probably $200 on software. What was interesting to me is that even in my Linux phase, some proprietary software was acceptable — notably steam. Why was this the case? I think, as a developer, I value the ability to fix things I don't like. I've done it quite a lot in open source software. Just plant my fix and move on. Steam always felt complete. macOS software often feels closer to completion, though sometimes I do wish I could modify it still. Also, another class is software I trust that I could not do a better job on, like Affinity. Anyway, I think that's the root of the developer aversion to paying for software.... Well, for me anyway. I wish we had better culture around donating to free software as well. reply Zambyte 3 hours agorootparentprevI have an aversion for paying for artificially scarce things. I am happy to \"pay for software\" if that software doesn't exist yet, and what I'm actually paying for is the labor to make it. reply blueboo 1 hour agorootparentQuite convenient that you’d only pay software if developers contacted you years in advance, and none of them were clever enough to do so reply fragmede 10 hours agorootparentprevida pro has a Mac release reply saagarjha 7 hours agorootparentAs does Ghidra or Binary Ninja. reply redbell 50 minutes agoprevPretty interesting! I believe being successful in reverse engineering, cracking, bypassing security layers (e.g., unlocking cars without keys), and other hacks comes down to understanding the basics of how these systems are designed to work in the first place. Add to this, the possession of the right toolbox to do the job. Back in 2010, I took on the challenge of cracking paid/licensed POS software. I am, in no way, a cracker or hacker, but once I understood how this app works, I followed a simple logic based on these rules: a. The app had a trial version with a number of *runs* set, and with each launch of the app, the number will decrease by one. It was set to around 100, I believe. b. The app runs on a LAN, on multiple computers, with one being the server. To my surprise, there were no IP configurations, and it turned out that it worked on LAN by setting the app directory as a *shared folder* in Windows!! c. On each app launch, even from other computers (having access to the shared folder), the count will decrease. So, I started my investigation: 1. Since you have a shared folder, based on (c) above, I assumed the location where the count number is stored *must be inside* this shared folder, not in the Windows registry or other places. 2. I launched the app, wrote down the current count, and closed it. 3. I searched inside this shared folder for *.* (all files), then sorted them by last edited. 4. I picked the first one from the search result as it was the only one with the same time as *now*; it was in a binary format. 5. I opened it using a hex editor, converted (using calc.exe) to HEX the count I wrote down on (2), searched for it, and found it. I identified its position. 6. I closed the hex editor, repeated (2),(3) and (4), and got the same results. 7. Now, I typed 999 in calc.exe and converted it to HEX, and in the open HEX editor, I edited the count at its current position with the new value, saved, and closed the binary file. 8. Restarted the POS app, went to about, and.. booooom , it now thinks that you have 999 days remaining :) Although I never used this Point of Sale software, it was an exciting achievement for me. I felt like a real hacker. reply WirelessGigabit 15 hours agoprevWhat is interesting here is that a signed piece of software can pick up an unsigned dll, execute it, and that execution causes a compromise of the system. reply speps 13 hours agoparentRaymond Chen has a ton of \"being on the other side of the airtight hatchway\" articles. Most relevant I found: https://devblogs.microsoft.com/oldnewthing/20200420-00/?p=10... Probably in this case the installation of the crack requires admin privileges to modify files in \"Program Files\" folder. Boom, you've broken the rules ;) reply saagarjha 7 hours agorootparentTurns out that building the airtight hatchway halfway through the crew’s sleeping quarters was a bad decision. reply Nextgrid 11 hours agoparentprevThis also raises a vulnerability. The author seems convinced this pirated copy is safe because the main binary is signed by Ableton, but there’s no guarantee if there’s a signature check on any of its dependent files (or that the check is not vulnerable or the parsing isn't vulnerable in some way which would allow hijacking the execution flow). reply mhh__ 11 hours agoparentprevShared libraries are a scam reply smolsky 9 hours agoprevNice! P.S. who remembers the legendary Phrozen Crew cracks? They were minimal byte patches that often toggled a conditional jump in an MS-DOS app/game... reply pests 7 hours agoprevAll the swearing turned me off. I don't mind cussing and use them myself, but does every tweet need to drop the f bomb? reply silisili 3 hours agoparentSame, I'm far from a prude, but time and place. And reading about reverse engineering is neither. It reminds me of a really smart kid who doesn't want to be seen as a nerd, so writes nonchalantly and injects vulgarities into an otherwise brilliant project. Good Will Hunting vibes. It's not really offensive, it's just distracting. reply tucnak 4 hours agoparentprevYes, it does reply hermitcrab 14 hours agoprevIf anyone is interested in crackers and their motivation, you might find this interview interesting: https://successfulsoftware.net/2011/04/07/interview-with-a-c... reply tamimio 14 hours agoparentThe first software I cracked was in 2004 (some video converter software), the motivation was simply that I can’t afford it, but the “feeling” you get after is like a drug, then it’s more of a challenge knowing that it’s doable no matter what, just like lock picking, then that spark just dies and you stop cracking them. reply RetroTechie 13 hours agorootparentCracked plenty software back in the day but mostly for personal use. For the challenge, and because I disliked software being tied to a specific storage medium. It was a sport to minimize changes. Like pad out a single assembly instruction with NOPs, change a conditional jump into unconditional one, etc. reply 3abiton 11 hours agorootparentprevIn the android space, most app cracking is rather easy. Surprisingly. reply grishka 11 hours agorootparentBecause Dalvik/ART (and regular JVM for that matter) bytecode is much less lossy than machine code. Most of the type information stays intact even after obfuscation, so you still get sensible output from a decompiler. This is in contrast with C/C++ where all struct and class usage gets converted into direct memory accesses. reply cedws 10 hours agoprevVery interesting. I really should get back into RE. Selfish question for a project of my own: is there any way to magically gain early code execution in a process on Windows other than a shim DLL? I'm too lazy to write one to pass through the all exports (reflective shim DLL possible...?) reply chc4 10 hours agoparentCreateProcess the victim with CREATE_SUSPENDED, do whatever code patching, then ResumeThread it. Pretty sure you can even CreateRemoteThread into the victim for DLL injection, since it just suspends the primary thread, and then patch \"yourself\" in DllMain instead of having to do remote memory calls. reply reeeeaway 3 hours agorootparentAlternatively, give frida a go. It handles all the hard parts for you magically and then you get to instrument the binary with Javascript :) mixing dynamic and static techniques is really powerful reply lionkor 4 hours agoprevI found this pretty insufferable to read, and in good X fashion, the second comment from the top is \"we should teach llama3 to do this stuff!\". Thanks for sharing, it was interesting, but wow that's a bad format and bad writing. reply hruzgar 16 hours agoprevthis is really interesting! reply skilled 16 hours agoprevhttps://nitter.poast.org/gf_256/status/1782656618015904103 reply dewey 16 hours agoparentThis says „Tweet not found“ now. reply skilled 16 hours agorootparentIt works fine but does lag sometimes. It’s the only public Nitter instance that is reliably up since nitter.net was shut down or whatever else happened to it. Your error has happened to me also but it does eventually work. reply littlestymaar 13 hours agoparentprevOh, a Nitter instance that still works? I guess it's going to die soon like the other as they run out of guest accounts from scrapping… reply _aavaa_ 16 hours agoparentprevThank you! This really should be the link, the twitter link is unusable reply ptsneves 13 hours agoprevA nice topic and insight if not for the way it is written. I could not finish it. It feels the author is unable to articulate his thoughts without interjecting curses and write incoherently. Is this how people communicate technically in the newer generations? reply m0zzie 12 hours agoparent> Is this how people communicate technically in the newer generations? I suspect this question is in bad faith but I'll answer anyway: this live tweeted thread is more like someone's thought stream, it is not a technical report. Many humans are capable of both technical writing, free of cursing, and also of dumping a swear-filled thought stream right into their favourite medium - especially when excitedly reverse engineering, or doing anything they're passionate about. This has been happening for a long time and is not about \"the newer generation\". You could've found me writing in a similar way on IRC in the late 90s, also talking about reversing. FWIW your comment feels valid enough up until your final sentence, you just didn't need to attack \"the newer generations\". reply axoltl 11 hours agoparentprevHaving worked with stong before I can assure you they're perfectly capable of articulating their thoughts when they want to. This is quite a bit more off-the-cuff. reply can16358p 14 hours agoprevWhy can't I see the rest but only the first title tweet? Is that the case or is it a bug? reply amatecha 14 hours agoparent\"as designed\", due to the gradual decrease in Twitter's functionality due to unknown reasons (probably trying to manipulate people into signing up to boost user count and ad revenue) reply 486sx33 9 hours agorootparentBecause AI models kept trying to train on twitter for free. reply soonerroadie 9 hours agorootparentOkay, Elon (jk). reply mimischi 14 hours agoparentprevTwitter requires an account for anything more than a single tweet nowadays. There’s a link with an unrolled thread in the comments here. reply lcnPylGDnU4H9OF 14 hours agoparentprevIt's been that way for a little while. I presume it's a compromise between requiring a log-in and full \"guest\" access. reply doix 16 hours agoprevThis was a pretty long read and I didn't really get much from it. The format of a million tweets is awful. tl;dr it patches the executable by having a shim dll that does the patch when it gets loaded. Pretty common in the game modding community. It finds where it needs to patch by scanning for a byte pattern. What does the actual patch do? No idea, that's what I was waiting for and I never got it. I was expecting a disassembly comparison of the before and after. Someone please correct me if I'm wrong. reply tamimio 14 hours agoparentBecause the whole article can be written in 2 tweets but you need that social media “interaction”, so the author goes on talking about non essential things. The crack itself is simple and smart to bypass the check by changing the public key, the only issue from what I have seen is there’s a lot of hardcoded stuff like the key and the functions numbers, so most likely it won’t work in future updates. reply Agingcoder 15 hours agoparentprevSame here - I was interested in the mechanics of the crack, having spent a fair amount of time reverse engineering binaries back in the days. This is just a bunch of screenshots with ‘lol’ interspersed. reply fullspectrumdev 16 hours agoparentprevAs far as I can tell - and I could be wrong having spent about five minutes reading the thread - the shim DLL basically swaps out a public key used by the applications key verification system for a different one so the keygen can create a valid licence key. Without affecting any integrity checks in the target binary. reply doix 16 hours agorootparentAh, that makes sense, thanks! I was pretty confused about the string copy and what that was doing. Normally I'd expect it to be writing a byte array. Now it all makes more sense. reply kaladin-jasnah 14 hours agoparentprevIs this akin to using LD_PRELOAD on Linux to hook something like __libc_start_main and modifying specific data in one of the data sections of the ELF binary or something? reply rumdz 14 hours agorootparentYes reply carom 15 hours agoparentprevAgree, this was just a really long thread of someone creating structs in Ida. reply fullspectrumdev 12 hours agorootparentThat’s about 75% of reverse engineering work in IDA or Ghidra, to be fair: labelling/annotating shit, adding types to shit, and making sense of structs and other data types. There’s extensions to both which automatically try detect such things from common libraries/known calls/etc which massively cuts down on the timesink. reply mrguyorama 15 hours agoparentprevI feel like this person is trying to copy Foone's voice but just doesn't get it reply RockRobotRock 13 hours agorootparentCybersec twitter is just awful. Everything has to be a call out or a dunk on someone/some company. It's all so negative. reply toofy 9 hours agorootparentAs a sibling already pointed out, this is pretty much all of twitter now. Infosec twitter moved over to Mastodon a while back, some are also trying out bluesky but Mastodon is where the community has mainly roosted. reply userbinator 5 hours agorootparentprevAs the saying goes, there's a fine line between genius and insanity... and a lot of these people are sitting on it. reply lmm 10 hours agorootparentprevMuch like the rest of twitter then. reply RockRobotRock 9 hours agorootparentyep reply archgoon 14 hours agorootparentprev'This person' sounds like cts being cts doing cts things. Don't see why you'd think they're copying Foone. reply brcmthrowaway 8 hours agoprev [–] Stop this at once. Ableton folks are gonna go hungry reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A Twitter user is trying to pirate Ableton Live Suite 12 and is intrigued by a statement in the NFO file claiming it does not alter the original binaries.",
      "The user is initiating a discussion to explore the software's functionalities and potentially engage in reverse engineering."
    ],
    "commentSummary": [
      "The conversation delves into reverse engineering software cracks, specifically on macOS, addressing code signing and circumventing security measures.",
      "It explores the incentives behind cracking software, various techniques employed, accessing Twitter material, and critiques of cybersecurity Twitter.",
      "Emphasis is placed on specific cracking methodologies, associated difficulties, and the significance of comprehending system architecture."
    ],
    "points": 181,
    "commentCount": 69,
    "retryCount": 0,
    "time": 1713884303
  },
  {
    "id": 40139434,
    "title": "Creating Realistic Visuals in Game Design: Simulating Jupiter's Cyclones",
    "originLink": "https://emildziewanowski.com/flowfields/",
    "originBody": "Flowfields Realistic is not necessarily the most convincing. Audio designers know that well and use frozen leeks and watermelons to create sounds of breaking bones and tearing flesh. Chalk shot from slingshot was safer alternative for actual firearms in old westerns. Fake doesn’t have to mean worse, especially when it is hard to tell the difference. With that in mind I will try to create complex flow without using computational fluid dynamics. New, Better Jupiter Jupiter’s is undeniably beautiful, but it’s safest to admire it from a distance. Characteristic patterns observed on the surface are, in fact, massive storms and Earth-sized cyclones. Jovian winds can reach speeds of hundreds of kilometers per hour, although they may appear quaint from orbit. I plan to feature a Jupiter-like planet as part of the skybox. While not a unique concept and often seen in the sci-fi genre, I want to take it a step further by animating it. In reality, the motion of the atmosphere is too slow to be noticed. However, I will speed it up substantially to make the movement obvious. This should capture players’ attention and remind them that the action is taking place on a distant, alien world. Flow While I don’t want to create a carbon copy of Jupiter, there is a set of features that immediately come to mind when thinking about gas planet. Hopefully, by recreating these, I will get the visuals reminiscent of Jupiter. There are three distinct flow patterns I want to replicate : Cyclones: A couple of large, easily identifiable vortices, much like Jupiter’s ‘Great Red Spot.’ Typically elongated, they are often accompanied by a ‘wake’ – a trail of secondary vortices. Jets: These are linear currents that run parallel to the equator, with easily visible turbulent transition layers. Storms: Smaller, more volatile, and less defined flow structures that contribute to the texture of the atmosphere. Animating Fluids Recreating water or any other sort of fluid in games is challenging. Computational fluid dynamics is demanding in terms of memory and processing power, but that hasn’t prevented game developers from including water in their games. With a set of clever hacks and workarounds, there is no need for expensive simulation. Color Cycling Color cycling is a technique with a long history, dating back to systems like the NES. It’s akin to painting by numbers, where colors representing different numbers change each frame. Despite its simplicity, when applied to well-prepared input sprites, it can produce eye-catching effects. Frame-by-Frame Animation For a while, the frame-by-frame approach was the standard solution. Each frame was stored as a separate sprite, which demanded a lot of memory. As a result, this method was typically reserved for short animation loops consisting of only a few frames. Limited number of animation frames leads to a ‘choppy’ motion, typical of 90s shooters. Texture Scrolling As soon as games moved into fully textured 3D environments, texture scrolling became a viable option for creating rivers. This method involves incrementing one of the UV components over time to create the illusion of moving texture. When combined with appropriate geometry and shaders, texture scrolling can yield impressive results and remains a popular choice. While versatile this technique is limited to laminar flow – it is non-trivial to add vortices or any other complex flow patterns. Quake UV Distortion Id Software, the developer behind Quake, is renowned for its innovations. The water distortion they created is rarely listed among them, but is still worth looking into. This simple formula lends Quake’s lava, water, and portals their distinctive appearance. Although it’s straightforward to replicate using shaders, the original effect was made without them, relying instead on software rendering. Unreal WaterPaint WaterPaint is one of the most intriguing methods for simulating fluids in games, yet it’s also one of the most challenging to understand. It appears to generate the surface of the liquid and subsequently uses this information to distort a texture. The system’s complexity borders on overengineering, particularly given that the resulting effect is often overlooked in a fast-paced shooter. Similarly to Quake this technique also predates shaders. Texture pixels are manipulated by CPU and then sampled just like in the case of normal texture. The methods mentioned are decades old and, on their own, may not hold up well today. However, they still have value as components within larger, more complex systems. Velocity Texture Let’s create a “universal” flow shader capable of representing any motion of the fluid. Intuitively, we’ll need two textures: one representing the color of the flowing substance, and another one storing the velocity field. This velocity field texture will be a 2-component 2D texture, with the red component representing the x component of the normalized velocity and the green component representing the y component. The velocity field is then used to incrementally modify the texture coordinates of the color texture, in the same manner like in the ‘Texture Scrolling’ described previously. However, in this case, the velocity values vary for each pixel. The result, while interesting, is rather disappointing as it doesn’t accurately simulate fluid motion. Instead, it is an animated distortion that gradually bends the color texture over time. The formula worked for simple scrolling because in that case the motion was linear and constant. At each point, the velocity was the same. However, here the velocity is more complex – it is defined per pixel. The correct approach would be to use integration. Euler Method Let’s simplify the problem. Imagine we have a tiny speck of dust sitting on the surface of water that’s moving. We describe the water’s movement using a texture that shows its velocity. Now, we want to figure out the path this speck of dust would take. The first solution that comes to mind is to take a small step forward, check and update the velocity, then take another step using the updated velocity, and repeat this process. This is called Explicit Euler Method: The Explicit or Forward Euler method is often seen as the most basic and least accurate numerical integration method. The larger the integration step, denoted as “h,” the greater the error, and these errors accumulate over time. Even in the example shown, the integrated path represented by the orange arrows deviates significantly from the particle’s true path, depicted by the gray line. Fortunately this inaccuracy won’t be noticeable in the animation. The problem is, it’s not easy to transform Euler Method directly into a shader. We need to keep track of the particle’s position after each step, and this is something shader alone cannot do. Position, in form of a deformed color texture, has to be stored in a texture. The shader reads the texture storing the color of the fluid and deforms it slightly based on the velocity texture. The resulting deformation is then written back into the color texture. This operation is performed every frame of the animation. To complicate the problem further, it’s generally not possible to read from and write to the same texture in a fragment shader. Unreal Engine solves this problem with Canvas. Canvas Node Setup Canvas enables the use of a flow shader (Material) to be drawn into a Render Target texture. What sets Canvas apart is its capability to use the same Render Target in both the input and output of the flow shader, forming a feedback loop. To make this process work, several components are necessary: Render Target Texture: This image stores the state of the flow, or the color of the fluid in our case. It must be created before the animation begins and initial color has to be set. Rendering Event: The process of updating the animation has to be performed every frame, or at least every frame the animated object is visible. Flow Material Instance: An instance of the Flow Material is necessary, and it has to be supplied with its own Render Target Texture. Once all these elements are in place, the Rendering Event, which corresponds to one step of fluid simulation, can be achieved using just 3 nodes: Begin Draw Canvas to Render Target Draw Material End Draw With everything set up, the resulting animation should look like this: The initial image is shifted in a more fluid manner, with each pixel moving more continuously. However, it still falls short of resembling the motion of a liquid. Improving Velocity Field Up until now, we’ve relied on basic smoothed 2D vector noise. While sufficient for testing basic functionality, it not enough to realistically representing fluid flow. Liquids tend to swirl around, forming vortices and other complex patterns, which simple noise cannot approximate effectively. Fortunately, a mathematical operator, the curl, can be particularly useful here. By applying it to scalar noise, we transform it into a velocity field full of vortices. To describe curl in the simplest way possible – in 2D case curl will create a clockwise flow around areas brighter than the surrounding, and counterclockwise flow around darker areas. I describe curl in more detail in Dissecting Curl Noise article. There are multiple ways to calculate curl. DDX and DDY operators are useful in Shadertoy, where the input is not a static texture but a procedural noise. For more traditional applications like Unreal and Unity, it’s probably better to generate it using image generation software like Substance Designer or Photoshop. Any software capable of generating a normal map from a grayscale image will be helpful here, as converting a normal map to curl is simply a matter of swizzling and inverting channels. The addition of swirly motion adds a fluid-like quality to the animation, although it still appears somewhat static. The stationary vortices are the reason behind the artificial appearance. This can be addressed by distorting velocity field using the same function that manipulated lava in Quake. The flow still lacks the complexity needed to resemble natural motion, but this can be remedied with a more detailed velocity field. Mixing When the algorithm runs for too long, another problem becomes apparent: mixing. While it’s a desired feature, after a while, it turns the flow colors into a solid mass, devoid of any visual interest. To remedy that, color can be reintroduced by sampling the initial color texture and blending it with the Render Target texture. This process involves using a point grid mask to mimic pigment dissolving in the fluid. That solves the issue of mixing, but the pattern of points remains too noticeable. By using a noise texture and applying Quake distortion to it, the effect becomes less conspicuous and more natural. Jupiter’s appearance is attributed to its water-ammonia clouds, which have a range of compositions and colors. These clouds undergo atmospheric circulation, occasionally pushing layers from below to the surface. This phenomenon results in changes in surface colors and structure over time. I’ll artificially limit cloud compositions to 3 and assign a texture channel to each. Then, to simulate shifts in composition, I’ll utilize color cycling. In shader terms, the initial color, before being sampled and mixed with the render target, will undergo slight modifications over time. The result may look psychedelic, but ultimately, it will replaced by more natural set of colors. Right now those rainbow patterns serve as an useful placeholder. The left side displays the initial color, while the right side shows the flow. Sharpening Another side effect of mixing is the blurring of the texture. As the image becomes progressively smoother, the details are lost, causing the texture to appear low-resolution, which is certainly an undesirable outcome. The obvious solution is to use sharpening – an operation opposite to blurring. In its simplest form, it samples five pixels – the original one and its four neighbors – and returns their weighted sum. The layout of the pixels with their respective weights is called a kernel. I will use a slightly different formula, one that isolates the ‘delta’ or change in color. This delta is then multiplied by the strength of sharpening. This approach gives me more control over the effect. The material graph representation might seem daunting at first glance, but it’s essentially the result of repeating the same sampling operation multiple times with different parameters. Sharpen is a separate Canvas rendering operation that follows the animation step. Sharpening enhances the details but also introduces stripe artifacts. This occurs because it is part of the feedback loop. It amplifies the difference between pixels, and the next sharpening step further magnifies the difference. This continues until the color values reach their maximum or minimum value. The solution to that problem is far from elegant but very effective – clamping the calculated difference. This way, the difference doesn’t increase exponentially and the artifacts have no chance to form. Sharpening with clamping: With that in place, we can consider the whole system complete – we have a set of tools that allow for recreating a wide array of flow types in real-time. Now, to make further improvements, we need to enhance the input data – specifically, the velocity field. Flow Patterns There are 3 flow patterns that can be easily identified on Jupiter: Cyclones Jets Storms This list is by no means exhaustive. While there are numerous smaller and less noticeable flow details, many of them can be replicated using the same techniques employed for the main three patterns. I will attempt to translate these patterns into corresponding velocity fields. This way, the complex flow on Jupiter can be broken down into individual flow components. These components could then be rearranged later to create a new, unique gas giant. Creating Flowfields As mentioned earlier, in a real-game scenario like Unreal or Unity, it’s not practical to generate the velocity field from scratch. It’s more efficient to generate most of the components in Substance Designer or Photoshop and then combine them in the shader to achieve the desired result. This approach allows us to create complex patterns with no additional costs. I chose to create velocity textures in Substance Designer due to its flexibility and non-destructive workflow. Cyclones A cyclone is essentially a large vortex. Creating one involves generating a large blurred black or white dot and passing it through the curl operator. To add more complexity, the result can be combined with another operator – the gradient. This allows the cyclone to either suck in or expel matter, making it more dynamic. Relation between curl and gradient is explained here in more detail. The velocity field is generated by blending a mixture of curl and gradient operators over the previously created flow pattern. Substance Designer enables the creation of more complex and detailed velocity fields. In this case, the cyclone flowfield was slightly deformed and elongated, featuring a non-linear speed distribution. Unlike a flowfield generated in a shader from scratch, all these details incur no additional cost – everything is baked into the texture. Jets The bands around Jupiter are known as belts and zones. Belts consist of darker, warmer clouds, while zones are characterized by brighter clouds made of ice. Strong currents form at the transitions between these bands. These currents, known as jets, run parallel to the equator and alternate in direction. Where two jets meet, the flow becomes turbulent, creating chains of vortices. Replicating that is relatively simple: blurred stripes represent the laminar flow of the jets, while a curl applied to a series of dots creates vortices. It’s worth noticing the color of the dots; the spin of resulting vortices has to match the direction of the surrounding jets. Once again, the flowfield generated in Designer exhibits more detail. Transition vortices are more scattered and vary in size. Additionally, jets are slightly disturbed to create a more wavy flow. Storms “Storms” is the term I used to encompass all the smaller vortices and turbulent streams that accompany the main currents. They are essentially noise, and I will approach creating them in the same way I would create noise. Noise is typically comprised of multiple layers called octaves. Each subsequent octave contains smaller details and has a diminishing influence. In the case of a velocity field, each layer also has to be animated separately. Those layers are then blended together to form complex, turbulent motion. Substance Designer features storms gathered into clusters. Two versions of that texture are packed into a single texture and blended using moving masks to simulate quickly shifting currents. It’s a different approach that results in patches of turbulent flow, as opposed to the uniformly distributed storms generated in Shadertoy. These patches resemble what can be observed on Jupiter more closely. Combined The division into cyclones, jets, and storms was artificial but proved quite useful for illustrating some of the techniques that can be used to mimic real flowfields. Each flow pattern can be achieved in many different ways, with no single approach that can be described as the “right” one. To merge all these components together, a simple addition would suffice, but using alpha blending allows for accentuating some features like cyclones and toning down turbulence in certain areas. At this stage, when all the components are ready, blending them together is more a matter of artistic choice than mathematics. After all, none of the presented techniques have solid grounding in physics – they are just approximations of natural phenomena. 2010: The Year We Make Contact When I started working on the animation of the gas giant, I was really excited about the idea because I naively thought that this was going to be something novel, never tried before. Obviously, I was wrong. Films like ‘Outland’, ‘2010: The Year We Make Contact’, and ‘Contact’ all featured animated Jupiter. The most interesting portrayal here is the rendition created by Digital Productions for ‘2010: The Year We Make Contact’. The technology behind it is a marvel of CGI, even though it looks like a perfectly executed practical effect. The basic idea remains largely the same: utilizing a flowfield to deform the initial image. However, the execution differs significantly. While I used Substance Designer to generate flow textures, the team at Digital Productions utilized actual fluid mechanics to simulate the flow. My solution to the problem of mixing was to artificially reintroduce the color, whereas they sidestepped the problem entirely by converting the image into particles. Remarkably, all of this was accomplished without the aid of modern CGI software or computing power. Instead, it relied on the ingenuity of a team of brilliant engineers and artists, supported by the CRAY X-MP. The work of Larry Yaeger and Craig Upson is described in greater detail in Siggraph and Cinefex articles. Additionally, there is a documentary available on YouTube. Further Developement The presented methods should be sufficient to create convincing-looking flow, but not necessarily a visually appealing planet. Achieving that requires several additional steps: Colors: Currently, the R, G, and B channels represent different substances. Ultimately they will be replaced with a color texture. UV Mapping: Currently, the texture is just a square; it needs to be wrapped around a sphere. However, I plan to use the method described in Flat Planets and apply it to a flat disc. Shading: Atmosphere is lit differently than a solid, opaque object. A specialized shading model has to be created to complete the effect. Conclusions The initial setup required some effort, both in Unreal and in Substance Designer, but once in place, it allowed for easy tweaking and modifications. Since it does not rely on computational fluid dynamics, the motion can be handcrafted, which is both a strength and a challenge. It offers total freedom to create any flow imaginable, but requires the artist to have a basic understanding of fluid dynamics. Most importantly, it can compete with actual fluid simulations while using only a fraction of resources. A full planet with a 1024×1024 texture takes less than 0.5ms to render, which is a modest price for such VFX.",
    "commentLink": "https://news.ycombinator.com/item?id=40139434",
    "commentBody": "Simulating Jupiter (emildziewanowski.com)166 points by imadr 8 hours agohidepastfavorite15 comments DrBazza 2 hours agoWhen I was at university, we did a different Jupiter simulation - the whole planet. We were fortunate enough to have a comet smack into it and ring it like a bell. Then a few of my senior colleagues used the observations in asteroseismology models (a generalised helioseismology model really) to study the interior. https://en.wikipedia.org/wiki/Asteroseismology https://en.wikipedia.org/wiki/Comet_Shoemaker%E2%80%93Levy_9... reply cmehdy 5 hours agoprevThis article was a joy to read, both for explanations and visuals. I'm not knowledgeable at all in visual generatio but I'm now wondering about other uses to extend the method. What other shapes can be coupled (with the technique to create those various storms) in order to create large-scale transitions, where for example a large vortex would follow a sigmoid over the other zones. Or even in what subtle ways could the visuals follow the envelope of a Hans-Zimmeresque audio background.. Thanks for having shared this blog! reply keyle 3 hours agoprevThe author seems to be experimenting in UE4 or UE5 (material graph shown in screenshot), but the examples are displayed in sharedtoy embeds? I'm wondering, is there a direct way to save UE4 material shader to shadertoy or some easy conversion tool? Otherwise it would have taken eons to produce this page... reply barfbagginus 2 hours agoparentUE translates shader graphs to HLSL - high level shading language, see: https://dev.epicgames.com/community/learning/knowledge-base/... Shadertoy needs GLSL - open gl shading language. Luckily, UE has a HLSL -> GLSL transpiler built in: https://docs.unrealengine.com/4.27/en-US/ProgrammingAndScrip... There are other HLSL transpilers: Microsoft's ShaderConductor, Unity's hlsl2glsl, Vulkan's vcc, etc. To port your favorite Shadertoy examples back to UE, you can transpile GLSL to HLSL with ShaderTranspiler, glslcc, ShaderConductor, etc. Disclaimer: I don't use UE or Shadertoy. In fact, this is my first exposure to GLSL/HLSL. My claims may be inaccurate. reply mandarax8 2 hours agoparentprevLooking at the final shadertoy example (https://www.shadertoy.com/view/4XSXz3) I would think he just recreated each effect in shadertoy (variable and function names dont seem exported to me). Most of the effects on the page are only a couple of lines it seems so maybe he did just rewrite them all? I do wonder why he bothered with UE material graphs if he's this proficient at shaders anyway. reply davedx 1 hour agorootparentI can imagine using material graphs is a much better way to experiment, iterate and progressively build up the effects than hand coding a shader. It's kind of like asking why write code in C# in Visual Studio when you can just write assembly? reply adzm 2 hours agoprevThe other articles on this site are just as fascinating. What a treasure!! reply noSyncCloud 5 hours agoprevProps for a site of that visual complexity that was performant, visually appealing, and eminently readable on mobile. reply ReleaseCandidat 1 hour agoparent> eminently readable on mobile Sadly the font colour on non-mobile devices is way too dark, the whole site is way too low contrast: #666b67 (desktop) vs #B2B5B3 (mobile) on #222623. Desktop colours: https://webaim.org/resources/contrastchecker/?fcolor=666B67&... Mobile colours: https://webaim.org/resources/contrastchecker/?fcolor=B2B5B3&... reply enriquto 3 hours agoparentprevThe article is incredibly interesting, but the choice of colors is so low-contrast that I can only read in it \"reader mode\", where the animations don't work. I have resorted to \"select all\" where the letters stand out a bit, but it's ugly and not very ergonomic... reply amarant 2 hours agorootparentIt's white on black, or at least white on very dark gray. Contrast is about as high as it could be on my device. Might there be a problem with your device? reply ReleaseCandidat 1 hour agorootparent> It's white on black, or at least white on very dark gray. It's light grey (#666b67) on dark grey (#222623), not much contrast on desktop. Mobile uses other colours, the same background (#222623) but a lighter font color (#B2B5B3), which is _way_ better. Why not use the same foreground color on desktop? reply throwaway290 4 hours agoparentprevThe use of weird non-native scrolling really hurts navigation and full justification looks clumsy when screen is narrow. But otherwisr it's not terrible. reply mikercampbell 6 hours agoprevI can almost feel the drops in my hair. But for real this is so cool reply ConcernedCoder 3 hours agoprev [–] now this is programming :) thank you! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explores techniques in game design to achieve realistic visuals and sounds, including simulating fluid motion, color cycling, texture scrolling, and animation for enhanced visual effects.",
      "It highlights challenges in integrating velocity values for accurate fluid simulation and utilizing tools like Unreal Engine and Substance Designer for dynamic effects on gas giants such as Jupiter.",
      "The primary aim is to efficiently and cost-effectively create visually appealing and realistic flow patterns in game environments."
    ],
    "commentSummary": [
      "The post explores simulating Jupiter with tools like UE4, ShaderToy, and transpilers, showcasing different techniques.",
      "Users provide feedback on the website's aesthetics, readability, and color contrast, along with discussing shader coding and experimentation.",
      "It's a unique blend of technical analysis on shader coding, visual design feedback, and simulation techniques for Jupiter enthusiasts."
    ],
    "points": 166,
    "commentCount": 15,
    "retryCount": 0,
    "time": 1713922359
  }
]
