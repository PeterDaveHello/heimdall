[
  {
    "id": 36329483,
    "timestamp": 1686764212,
    "title": "New York State Senate passes prohibitions on non-competes",
    "url": "https://ogletree.com/insights/new-york-state-senate-passes-prohibitions-on-non-competes/",
    "hn_url": "http://news.ycombinator.com/item?id=36329483",
    "content": "New York, State Developments, Unfair Competition and Trade SecretsNew York State Senate Passes Prohibitions on Non-CompetesJune 12, 2023Kelly M. CardinNew YorkStamfordAuthorMatthew P. GizzoNew YorkDallasAuthorCaitlin L. O\u2019FallonNew YorkAuthorJessica R. SchildNew YorkAuthorMonumental changes to New York law on non-compete agreements appear imminent. On June 7, 2023, the New York State Senate approved two bills concerning non-compete agreements. The first, Bill No. S3100A, proposes a ban on all non-compete agreements, while the second, Bill No. S6748, proposes a limited ban of certain non-compete agreements. Both bills are currently pending before the New York State Assembly. If the State Assembly passes the bills, they will be sent to Governor Kathy Hochul for her sign-off, which could come as early as this week.Quick HitsOn June 7, 2023, the New York State Senate gave its approval to two bills that would prohibit or limit the use of non-compete agreements in New York.The first bill, S3100A, would ban post-employment non-compete agreements between employers and workers; the second bill, S6748, would, among other things, prohibit employers from entering into or maintaining non-compete agreements with workers, absent a \u201cgood faith basis\u201d to believe a non-compete agreement is enforceable.The bills must pass the New York State Assembly and receive final approval from New York Governor Kathy Hochul to become law.Bill No. S3100AIf enacted, Bill No. S3100A would prohibit an employer from entering into a non-compete agreement with an employee, independent contractor, or \u201cany other person who, whether or not employed under a contract of employment, performs work or services\u201d (collectively, \u201ccovered individuals\u201d) for the employer. Covered individuals would have a private cause of action against employers that violate the law and, if found liable, employers would be subject to up to $10,000 in liquidated damages for each violation, as well as payment for lost compensation, damages, and attorneys\u2019 fees and costs. The legislation provides for a two-year statute of limitations, triggered by the later occurrence of one of the following events: (i) when the agreement was signed; (ii) when the covered individual learns of the prohibited agreement; (iii) when the employment or contractual relationship is terminated; or (iv) when the employer takes any step to enforce the prohibited agreement. S3100A would become effective thirty days after being signed into law.Bill No. S6748Bill No. S6748 is generally aimed at preventing the establishment of monopolies, monopsonies, and restraints of trade.If enacted, the provisions of S6748 would prevent employers from entering into or maintaining non-competition agreements with workers, including independent contractors, absent a \u201cgood faith basis\u201d to believe that a non-compete agreement is enforceable. The bill does not expand upon what constitutes a \u201cgood faith basis.\u201d The legislation would also define \u201cnon-compete agreement\u201d broadly to include any \u201cde facto\u201d agreement that \u201chas the effect of prohibiting [covered individuals] from seeking or accepting employment[,]\u201d such as overbroad non-disclosure agreements and training-repayment obligations. Employers would also be required to rescind unenforceable non-compete agreements with both current and former workers, and they would be required to provide notice to each worker that an agreement is no longer in effect. If enacted, the law would take effect immediately.Next StepsOgletree Deakins\u2019 New York office and Unfair Competition and Trade Secrets Practice Group will continue to monitor developments and will provide updates on the New York and Unfair Competition and Trade Secrets blogs as additional information becomes available.Follow and SubscribeLinkedIn | Twitter | Webinars | PodcastsShare this Insight",
    "summary": "- The New York State Senate has approved two bills that could ban or limit the use of non-compete agreements in the state.\n- Bill No. S3100A would prohibit employers from entering into non-compete agreements with employees, independent contractors, or others who perform work for the employer. Violators could be subject to up to $10,000 in damages per violation.\n- Bill No. S6748 aims to prevent the establishment of monopolies and restraints of trade. It would require employers to have a \"good faith basis\" to believe a non-compete agreement is enforceable and would also broaden the definition of non-compete agreements to include certain other types of agreements.\n- Both bills still need to pass the New York State Assembly and be approved by Governor Kathy Hochul to become law.",
    "hn_title": "New York State Senate passes prohibitions on non-competes",
    "original_title": "New York State Senate passes prohibitions on non-competes",
    "score": 704,
    "hn_content": "- The New York State Senate has passed prohibitions on non-compete agreements, which is a significant development.\n- This ban primarily affects the finance and technology sectors, particularly high-frequency trading (HFT) firms and proprietary trading shops employing software professionals.\n- While this may not have a widespread impact due to the way deferred compensation is structured in the industry, it is still a step in the right direction.\n- The new law invalidates contractual non-compete agreements but does not address non-association clauses, which restrict working with former colleagues.\n- Non-compete agreements have been a cause for concern, especially with their broad scope and selective enforcement by employers.\n- This action in New York may set a precedent for other states to follow and could potentially lead to an overall change in how non-compete agreements are used.\n- The bill is significant for individuals looking to switch jobs, start their own businesses, or work in a competitive environment without fear of legal repercussions.\n- Non-compete agreements have the potential to stifle competition, hinder innovation, and restrict employees' career opportunities.\n- It is important to recognize that this is a complex issue that varies across industries and may have different implications for different professionals.\n- The new prohibitions aim to protect employee rights and foster a more competitive and innovative business environment.- New York State is considering a bill (Bill No. S6748) that aims to prevent the establishment of monopolies, monopsonies, and restraints of trade.\n- If enacted, the bill would prevent employers from entering into or maintaining non-competition agreements (NCAs) with workers, including independent contractors, without a \"good faith basis\" for enforceability.\n- The bill defines \"non-compete agreement\" broadly and includes any agreement that prohibits individuals from seeking or accepting employment.\n- Employers would be required to rescind unenforceable NCAs with current and former workers and provide notice that the agreements are no longer in effect.\n- The bill also encompasses overbroad non-disclosure agreements and training-repayment obligations.\n- It is currently unclear if the bill would apply retroactively or only to new agreements.\n- The inclusion of NDAs in the bill is seen as significant by some commenters.\n- Commenters express mixed opinions on the impact of the bill, with some praising it as awesome news and others questioning its potential effects.\n- Hedge funds and investment banks are mentioned as potentially affected by the bill.\n- The comment section raises questions about the implications of the bill for recruitment ethics and existing contracts.\n- One commenter mentions that Working Families members are sponsors of the bill, and Working Families is described as a progressive party in NY.\n- The post generates some discussion about political parties and progressive ideals.",
    "hn_summary": "- The New York State Senate has passed prohibitions on non-compete agreements, which is a significant development.\n- This ban primarily affects the finance and technology sectors, particularly high-frequency trading (HFT) firms and proprietary trading shops employing software professionals.\n- The new law invalidates contractual non-compete agreements but does not address non-association clauses, which restrict working with former colleagues."
  },
  {
    "id": 36325986,
    "timestamp": 1686750873,
    "title": "I booted Linux 293k times in 21 hours",
    "url": "https://rwmj.wordpress.com/2023/06/14/i-booted-linux-292612-times/",
    "hn_url": "http://news.ycombinator.com/item?id=36325986",
    "content": "Richard WM JonesHOMEABOUT\u2190 NBD-backed qemu guest RAMJUNE 14, 2023 \u00b7 9:42 AM\u2193 Jump to CommentsI booted Linux 292,612 timesAnd it only took 21 hours.Linux 6.4 has a bug where it hangs on boot, but probably only 1 in 1000 boots (and rarer if using Intel hardware for some reason). It\u2019s surprising to me that no one has noticed this, but I certainly did because our nbdkit tests which use libguestfs were randomly hanging, always at the same place early in booting the libguestfs qemu appliance:[  0.070120] Freeing SMP alternatives memory: 48KSo to bisect this I had to run guestfish in a loop until it either hangs or doesn\u2019t. How many times? I chose 10,000 boots as a good threshold. To make this easier I wrote a test harness which uses up to 8 threads and parses the output to detect the hang.After a painful bisection between v6.0 and v6.4-rc6 which took many days I found the culprit, a regression in the printk time feature: https://lkml.org/lkml/2023/6/13/733To prove it I booted Linux 292,612 times before the faulty commit (successfully), and then after (failed after under 1,000 boots).7 CommentsFiled under Uncategorized7 responses to \u201cI booted Linux 292,612 times\u201dproblemchild68June 14, 2023 at 10:17 amImpressed with the tenacity of the search. I\u2019d ASS-u-ME that at 1 in 1000 failure they attributed to H/W failure or glitching. Some more detail on your method of homing down the code segment would be useful \u2026CheersReplyrichJune 14, 2023 at 10:21 amI guess people would think that yes.Finding the commit was actually simple (albeit taking days). I just use git bisect with the test linked above. The problem was the amount of time it took to run 10,000 boot iterations to prove that the kernel was good (vs bad if it hung).For unclear reasons the bisect only got me down to a merge commit, I then had to manually test each commit within that which took about another day.ReplyAllanJune 14, 2023 at 6:26 pmBisecting with flakiness is tricky. \u201cNoisy binary search\u201d somewhat alleviates the pain: https://github.com/adamcrume/robust-binary-searchJennifer ThompsonJune 14, 2023 at 3:42 pmThis is yet more evidence, not that we really need it at this point, that it\u2019s time to rewrite the rest of the Linux kernel in Rust.It can\u2019t happen in an instant, of course, but if the kernel devs set a goal of reducing C\u2019s usage by, say, 0.5% with each release, we\u2019d soon see real progress being made toward a safer and more reliable Linux kernel.C has served us well, but it\u2019s time to move beyond it. The future is Rust, and only Rust.ReplyNobodyJune 14, 2023 at 7:59 pmHow does Rust prevent this bug? The change: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=f31dcb152a3d0816e2f1deab4e64572336da197dReplyexampleJune 14, 2023 at 9:22 pmOf course it doesn\u2019t, which is why we should re-write the kernel in zig.Ollie JonesJune 14, 2023 at 7:05 pmSoftware Test Engineer walks into a bar, orders a beer, orders 292,612 beers! This is outstanding detective work.ReplyLeave a ReplyThis site uses Akismet to reduce spam. Learn how your comment data is processed.Recent PostsI booted Linux 292,612 timesNBD-backed qemu guest RAMnbdkit\u2019s evil filterFrame pointers vs DWARF \u2013 my verdictSmithForthFrame pointers \u2013 an important updatenbdkit + libblkioCreating a modifiable gzipped disk imageAn NBD block device written using Linux ublk (user block device)nbdkit for macOSSSH from RHEL 9 to RHEL 5 or RHEL 6Composable tools for disk imagesnbdkit now supports LUKS encryptionInstalling Fedora 34 on my Turing Pi 7 node clusterInterview for Red Hat BlogHiFive UnmatchedBeagleVTuring Pi 1nbdkit 1.24 & libnbd 1.6, new copying toolnbdkit 1.24, new data plugin featuresRecent Commentsexample on I booted Linux 292,612 ti\u2026Nobody on I booted Linux 292,612 ti\u2026Ollie Jones on I booted Linux 292,612 ti\u2026Allan on I booted Linux 292,612 ti\u2026Jennifer Thompson on I booted Linux 292,612 ti\u2026rich on I booted Linux 292,612 ti\u2026problemchild68 on I booted Linux 292,612 ti\u2026rich on nbdkit\u2019s evil filterJames on nbdkit\u2019s evil filterStephan on Why the Windows Registry sucks\u2026About the authorI am Richard W.M. Jones, a computer programmer. I have strong opinions on how we write software, about Reason and the scientific method. Consequently I am an atheist [To nutcases: Please stop emailing me about this, I'm not interested in your views on it] By day I work for Red Hat on all things to do with virtualization. I am a \"citizen of the world\".My motto is \"often wrong\". I don't mind being wrong (I'm often wrong), and I don't mind changing my mind.This blog is not affiliated or endorsed by Red Hat and all views are entirely my own.aarch64 AMD ARM bbc c++ centos cluster cron debian disk image disk images febootstrap fedora filesystems fosdem fpga FUSE git guestfish guestfs-browser guestmount hardware hivex ideas kernel kvm kvm forum libguestfs libguestfs-1.12 libnbd libvirt linux lvm nbd nbdkit ocaml odroid openstack performance perl programming python qemu rants red hat registry rhel risc-v rpm security ssh tip ubuntu v2v video virt-builder virt-cat virt-df virt-edit virt-inspector virt-install virt-manager virt-p2v virt-rescue virt-resize virt-sysprep virt-tools virt-v2v virt-win-reg virtualization virtual machine vmware whenjobs windows windows registry RSS - Posts RSS - CommentsRichard WM Jones \u00b7 Virtualization, tools and tipsBlog at WordPress.com.Do Not Sell or Share My Personal InformationFollow",
    "summary": "- A bug in Linux 6.4 causes it to hang on boot, but only in about 1 in 1000 boots.\n- The author noticed this bug while running tests with libguestfs, and decided to investigate further.\n- Through a process called bisection, the author identified the specific commit that introduced the bug by running Linux 292,612 times.\n- This post is special because it highlights the tenacity and effort required to locate and fix a bug in a complex software system like Linux.",
    "hn_title": "I booted Linux 293k times in 21 hours",
    "original_title": "I booted Linux 293k times in 21 hours",
    "score": 664,
    "hn_content": "- A developer shares their experience of debugging a rare failure in a large integration test suite.\n- They had trouble bisecting the issue because the failure wasn't consistent and found it difficult to verify changes.\n- Ultimately, they triggered a large number of runs overnight and used Bayesian statistics to narrow down the failure point.\n- The issue turned out to be a dependency slowly turning on a feature, causing sporadic failures.\n- A discussion follows about various topics, including monorepos, multi-armed bandits, and best practices for feature flags in tests.\n- The original developer provides a reproducer and suggestions for further testing.\n- Some developers express interest in the bug, while others debate the pros and cons of different testing approaches.\n- The thread concludes with a suggestion to move the discussion to the mailing list.- The post discusses a bug in the Linux kernel that caused the system to crash.\n- The bug was discovered through a process called bisecting, where the developer systematically narrows down the range of commits that may have caused the bug.\n- The bisecting process involved testing over 292,000 different commits, which took a considerable amount of time.\n- The bug was eventually traced back to a regression in the printk time feature.\n- The bug report and the discussion on the Linux Kernel Mailing List provide a fascinating example of how developers troubleshoot and debug complex issues in a large-scale software project like the Linux kernel.\n- The post highlights the importance of persistence and tenacity in debugging and problem-solving, as well as the significance of thorough testing and version control in software development.\n- The discussion also touches on topics like the use of different tools and techniques for bug hunting, the challenges of managing concurrent processes, and the impact of hardware and environmental factors on software behavior.",
    "hn_summary": "- A developer shares their experience of debugging a rare failure in a large integration test suite by triggering a large number of runs overnight and using Bayesian statistics to narrow down the failure point.\n- The bug in the Linux kernel that caused the system to crash was discovered through the bisecting process involving over 292,000 different commits.\n- The bug report and discussion on the Linux Kernel Mailing List highlight the importance of persistence, thorough testing, and version control in software development while discussing various tools and techniques for bug hunting."
  },
  {
    "id": 36321780,
    "timestamp": 1686720425,
    "title": "The Reddit blackout will continue",
    "url": "https://old.reddit.com/r/ModCoord/comments/148ks6u/indefinite_blackout_next_steps_polling_your/",
    "hn_url": "http://news.ycombinator.com/item?id=36321780",
    "content": "MY SUBREDDITSPOPULAR-ALL-RANDOM-USERS | ASKREDDIT-FUNNY-WORLDNEWS-PICS-TODAYILEARNED-MILDLYINTERESTING-NEWS-GAMING-MOVIES-EXPLAINLIKEIMFIVE-AWW-TIFU-VIDEOS-TWOXCHROMOSOMES-JOKES-ART-LIFEPROTIPS-OLDSCHOOLCOOL-MUSIC-NOTTHEONION-FUTUROLOGY-SHOWERTHOUGHTS-DATAISBEAUTIFUL-BOOKS-IAMA-ASKSCIENCEMORE \u00bbreddit.com ModCoordcommentsother discussions (15)Want to join? Log in or sign up in seconds.|Englishthis post was submitted on 13 Jun 202324,814 points (78% upvoted)shortlink:remember mereset passwordloginSubmissions restrictedOnly approved users may post in this community.ModCoordjoin15,621 readers2,003 users here nowModCoordThis subreddit is to facilitate organization of multiple mod teams to accomplish goals that require multiple mod teams.Technologies utilized:Discord - you can request access by sending us a modmail from your own subreddit's modmail (for mods of subreddits participating in the blackout)Twitter - @CoordModReddit - r/ModCoordIFTTT scriptsBots as necessaryNoticesNo namecalling, slapfighting, bigotry. Act like an adult. First assume you misunderstood, or they misspoke. Report, don't engage.Not everyone in here will necessarily see eye-to-eye about everything. The mods expect everyone to act like adults, the way moderators should be capable. Behavior on a different subreddit will not necessarily warrant removal from this one.Leaks are going to happen. Conduct yourself in a way where you'd be fine if your comment got posted elsewhere publicly. We can't stop all the leaks, and we aren't able to spend an untoward amount of time chasing them down. Don't give them attention and they'll more than likely go away.Do not use r/ModCoord to: directly harass other users or subreddits or coordinate bans of other users.a community for 1 yearMODERATORSMESSAGE THE MODSdiscussions in r/ModCoord<>X2771 \u00b7 818 comments\"Huffman says the blackout hasn\u2019t had \u201csignificant revenue impact\u201d and [...] anticipates that many of the subreddits will come back online by Wednesday. \u201c[...] Please know that our teams are on it, and like all blowups on Reddit, this one will pass as well,\u201d the memo reads\" - The Verge24.8kIndefinite Blackout: Next Steps, Polling Your Community, and Where We Go From Here (self.ModCoord)submitted 1 day ago * by SpicyThunder335[M]522& 37 more - announcementOn May 31, 2023, Reddit announced a policy change that will kill essentially every third-party Reddit app now operating, from Apollo to Reddit is Fun to Narwhal to BaconReader, leaving Reddit's official mobile app as the only usable option; an app widely regarded as poor quality, not handicap-accessible, and very difficult to use for moderation.In response, nearly nine thousand subreddits with a combined reach of hundreds of millions of users have made their outrage clear: we blacked out huge portions of Reddit, making national news many, many times over. in the process. What we want is crystal clear.Reddit has budged microscopically. The announcement that moderator access to the 'Pushshift' data-archiving tool would be restored was welcome. But our core concerns still aren't satisfied, and these concessions came prior to the blackout start date; Reddit has been silent since it began.300+ subs have already announced that they are in it for the long haul, prepared to remain private or otherwise inaccessible indefinitely until Reddit provides an adequate solution. These include powerhouses like:/r/aww (34.1m)/r/music (32.3m)/r/videos (26.6m)/r/futurology (18.7m)Such subreddits are the heart and soul of this effort, and we're deeply grateful for their support. Please stand with them if you can. If you need to take time to poll your users to see if they're on-board, do so - consensus is important. Others originally planned only 48 hours of shutdown, hoping that a brief demonstration of solidarity would be all that was necessary.But more is needed for Reddit to act:Huffman says the blackout hasn\u2019t had \u201csignificant revenue impact\u201d and that the company anticipates that many of the subreddits will come back online by Wednesday. \u201cThere\u2019s a lot of noise with this one. Among the noisiest we\u2019ve seen. Please know that our teams are on it, and like all blowups on Reddit, this one will pass as well,\u201d the memo reads.We recognize that not everyone is prepared to go down with the ship: for example, /r/StopDrinking represents a valuable resource for a communities in need, and the urgency of getting the news of the ongoing war out to /r/Ukraine obviously outweighs any of these concerns. For such communities, we are strongly encouraging a new kind of participation: a weekly gesture of support on \"Touch-Grass-Tuesdays\u201d. The exact nature of that participation- a weekly one-day blackout, an Automod-posted sticky announcement, a changed subreddit rule to encourage participation themed around the protest- we leave to your discretion.To verify your community's participation indefinitely, until a satisfactory compromise is offered by Reddit, respond to this post with the name of your subreddit, followed by 'Indefinite'. To verify your community's Tuesdays, respond to this post with the name of your subreddit, followed by 'Solidarity'.14577 commentssharesavehidereporttop 200 commentsshow 500sorted by: new (suggested)Want to add to the discussion?Post a comment!CREATE AN ACCOUNT[\u2013]demmian[M] [score hidden] 1 day ago stickied comment The community's list of demands:API technical issuesAccessibility for blind peopleParity in access to NSFW contentAPI technical issuesAllowing third-party apps to run their own ads would be critical (given this is how most are funded vs subscriptions). Reddit could just make an ad SDK and do a rev split.Bringing the API pricing down to the point ads/subscriptions could realistically cover the costs.Reddit gives the apps time to make whatever adjustments are necessaryRate limits would need to be per user+appkey, not just per key.Commitment to adding features to the API; image uploads/chat/notifications.Accessibility for blind peopleLack of communication. The official app is not accessible for blind people, these are not new issues and blind and visually impaired users have relied on third-party apps for years. Why were disabled communities not contacted to gauge the impact of these API changes?You say you've offered exemptions for \"non-commercial\" and \"accessibility apps.\" Despite r/blind's best efforts, you have not stated how they are selected. r/blind compiled a list of apps that meet users' access needs.You ask for what you consider to be a fair price for access to your API, yet you expect developers to provide accessible alternatives to your apps for free. You seem to be putting people into a position of doing what you can't do while providing value to your company by keeping users on the platform and addressing a PR issue. Will you be paying the developers of third-party apps that serve as your stopgap?Parity in access to NSFW contentThere have been attempts by devs to talk about the NSFW removal and how third-party apps are willing to hook into whatever \"guardrails\" (Reddit's term) are needed to verify users' age/identity. Reddit is clearly not afraid of NSFW on their platform, since they just recently added NSFW upload support to their desktop site. Third-party apps want an opportunity to keep access to NSFW support (see https://redd.it/13evueo).Please also note that not all NSFW content is just pornography. There are many times that people seeking help or sharing stories about abuse or medical conditions must also mark their posts NSFW. However, even if this were strictly about porn, Reddit shouldn't take a stance that it's OK for them but not any other apps, especially when demanding exorbitant fees from these 3rd part devs.permalinkembedsavereportreplyload more comments (127 replies)[\u2013]JamieIsReading 1 point 2 minutes ago r/Twilight, r/TwilightMemes, and r/TwilightFanfic are going for a week. r/Twilight is going to be restricted for 24 hours so users can see the update before we go darkpermalinkembedsavereportreply[\u2013]Nheea 2 points 8 minutes ago /r/coloring, /r/adultcoloring, /r/hematology will go indefinite.permalinkembedsavereportreply[\u2013]kattheclown 2 points 18 minutes ago r/charlixcx indefinitepermalinkembedsavereportreply[\u2013]AddendumOutrageous99 2 points 19 minutes ago r/FlashTV indefinite. That sub is indefinitely closed. Can\u2019t even find it now.permalinkembedsavereportreply[\u2013]General-Pryde-2019 1 point 34 minutes ago Anyone care to provide an update on r/Purdue yet? So far it's stayed private and I haven't seen anything on whether it will stay that way indefinitelypermalinkembedsavereportreply[\u2013]BuckVoc 1 point 19 minutes ago You should be able to message the subreddit mods even if it's private and ask them.Or better, ask them to update their sub private message to indicate status. Some clients won't show it (e.g. I'm currently typing this with Infinity on Android, which does not) but if you look at the sub in the Web UI, it will.permalinkembedsaveparentreportreply[\u2013]lukenamop 3 points 39 minutes ago r/dankmemes indefiniteDecision made with the help of a community poll, open for 24h, to which a majority of users agreed to go private.permalinkembedsavereportreply[\u2013]cantremembermypasswd 2 points 40 minutes ago /r/FastFlix - deleted after 30th if not changedpermalinkembedsavereportreply[\u2013][deleted] 50 minutes ago [removed][\u2013]gwion35 0 points 27 minutes ago I can access r/raceplay still. I\u2019m not getting the \u201cthis community is private\u201d message, and I can see posts.permalinkembedsaveparentreportreply[\u2013]Zacoftheaxes 2 points 54 minutes ago /r/NPCswap indefinitepermalinkembedsavereportreply[\u2013]Reddit-username_here 2 points 1 hour ago r/Tennessee will stay closed until at least June 20th unless Reddit changes course.permalinkembedsavereportreply[\u2013]voltfalcon 2 points 1 hour ago r/Brantsteele will go dark Friday to Sunday before another vote will take place before going indefinitepermalinkembedsavereportreply[\u2013]ajn0592 2 points 1 hour ago /r/skylineporn indefinitepermalinkembedsavereportreply[\u2013]Mr_Popularun 2 points 1 hour ago It'd be interesting if Reddit disabled the ability for Subs to go private/restricted for those over X users. I mean, mods aren't gonna cede power in protest suddenly. I wouldn't lolpermalinkembedsavereportreply[\u2013]BuckVoc 1 point 12 minutes ago It's true that mods don't really have leverage WRT Reddit as regards taking subs private. Reddit can just undo that and can demod the mods.But focusing on the subs being closed is kind of missing what's actually at stake.What is actually at stake is whether a number of the mods continue to mod, because if the subs get forced open, some portion of them probably won't continue modding. Maybe a lot.Reddit can force the subs open whether the mods want it or not, but cannot force the moderators to mod.If that happens, things are going to be a mess for some time regarding spammers and user abuse and all that, and some of whatever replacement mods are put in place are probably going to be a clusterfuck. Means that a bunch of subs will be undermoderated for some time to come.permalinkembedsaveparentreportreply[\u2013]living_vicariously 5 points 1 hour ago* /r/gameofthrones, /r/GilmoreGirls, /r/TheMarvelousMrsMaisel, /r/InterviewVampire, and /r/XennialsIndefinite.permalinkembedsavereportreply[\u2013]acegfx 4 points 2 hours ago r/leafs has been indefinitepermalinkembedsavereportreply[\u2013]-_-BanditGirl-_- 2 points 2 hours ago /r/cartnarcs indefinite. We're normally democratic, but not right now.permalinkembedsavereportreply[\u2013]CyclopicSerpent -2 points 2 hours ago Im not sure if this is the right place to ask but why blacking out as protest?Why not ask users to stop going on reddit for X amount of time and have mods just abandon their subs. Or just delete the subs.Blacking out subs feels more like mods flexing on their users and sending the message to reddit \"hey we will stop your users from using reddit\" which feels more like a strongarm than a protest.Polls as well dont seem to be representative of those communities. Letting a couple thousand determine how a sub of a million reacts may as well not even poll. Now if there was a way to have everyone who visited that sub get a pop up that made you vote before using it thatd probably be a bit more realistic.Advising stopdrinking and ukraine to have one blackout day also feels weird. Like either theyre essential subs and people need access to or if you need help on a tuesday too bad fuck off somewhere else.Is there any other movements to protest besides the blackouts?permalinkembedsavereportreply[\u2013]Capital-Trouble-3549 -3 points 37 minutes ago This. This is an attempt at strong arming reddit rather than a protest. Why are mods not looking to move away from reddit? They can experiment and tell the community as wellpermalinkembedsaveparentreportreply[\u2013]Mgwinn0526 3 points 2 hours ago r/Influenster indefinitepermalinkembedsavereportreply[\u2013]inanis 2 points 2 hours ago* /r/glasscollecting is indefinitelypermalinkembedsavereportreply[\u2013]Hotbigoby 3 points 2 hours ago Refusing to at least partially meet your users, who make you money, halfway because you know they're addicted is reason enough IMO.If they know this they'll just keep having a complete disregard for what the userbase wants and focus on max profit instead.We should show them a complete disrespect for the users will result in consequencesWhat he said translates to: \"As long as it doesn't affect our bottom line, fuck the users\"Maybe instead of a blackout, we should just move to another platform. So they know we won't HAVE to come back.permalinkembedsavereportreply[\u2013]DigitalDude_42 2 points 36 minutes ago We should show them a complete disrespect for the users will result in consequencesIt's funny how we can agree on this.permalinkembedsaveparentreportreply[\u2013]StrangeGibberish 1 point 2 hours ago /r/armoredwomen - Indefinitepermalinkembedsavereportreply[\u2013]HeirToGallifrey 3 points 2 hours ago /r/SampleSize, /r/MakeYourChoice, and /r/WallpaperDump, indefinitepermalinkembedsavereportreply[\u2013]PorkyPain 4 points 2 hours ago r/Malaysia is having a poll here:https://www.reddit.com/r/malaysia/comments/149bron/reddit_api_changes_whats_next/?utm_source=share&utm_medium=android_app&utm_name=androidcss&utm_term=1&utm_content=share_buttonAnd looks like it's rather balance between indefinitely and ending the blackout.permalinkembedsavereportreply[\u2013]Kronusx12 2 points 24 minutes ago Is it just me or are a bunch of these pills set up in an odd way?As it stands right now, the most voted option is to reopen, but that\u2019s because there are 3 different options to stay closed.There should really be 2 polls.Poll 1Reopen the sunKeep the sub closedIf \u201ckeep the sub closed\u201d wins poll 1, then do something like:Poll 2Stay closed for X daysStay Closed for Y daysStay closed indefinitely.As it is, more people are voting to keep the sun closed but those votes are split across 3 different options. I\u2019ve seen a bunch of subs pills set up the same way.permalinkembedsaveparentreportreply[\u2013]freakydeku 2 points 1 minute ago maybe if all of the \u201ckeep the sub closed\u201d choices add up to more than \u201ckeep it open\u201d then you do the secondary closed choice.permalinkembedsaveparentreportreply[\u2013]BuckVoc 1 point 6 minutes ago Probably better to use ranked-choice voting if the concern is capturing user preferences.I think that polling is going to fundamentally be vulnerable to brigading, though.permalinkembedsaveparentreportreply[\u2013]That-Establishment24 -1 points 2 hours ago Linking your poll externally is a surefire at to make sure there\u2019s voter manipulation and brigading from people who aren\u2019t actually sub members.permalinkembedsaveparentreportreply[\u2013]WintryInsight 0 points 1 hour ago That's probably why they linked itpermalinkembedsaveparentreportreply[\u2013]FuriousAlbino 4 points 3 hours ago* r/Boston is having a debate on itthere is a poll herepermalinkembedsavereportreply[+]That-Establishment24 -1 points 2 hours ago (0 children)[\u2013]richardparadox163 0 points 3 hours ago For the protest to be effective it needs to not have an end date, it needs to be able to credibly threaten Reddit\u2019s bottom line in order for us to have leverage to make reddit meet our demands. Otherwise they can, as they have simply wait us out. Of course the problem with being indefinitely private is1. Depriving our communities2. At some point most people will just make and congregate in another subreddit rendering the protest ineffective. And/or communities will give up one by one.My recommendation (similar in idea to Touch Grass Tuesday) and this is for all subs, so I hope that you will spread this to other moderators. Is subs should go private for two days out of every week for the foreseeable future. Two days is long enough to have a noticeable impact on reddit\u2019s revenue (more than just one day) but not long enough to where it becomes too intrusive for users/community members and worth it for people to start alt subreddits. Of course ideally subreddits would coordinate which days of the week to decrease site traffic instead of having people spend time on other subreddits. The weekend is the obvious choice for maximum impact, but I could see that leading to the alt subreddit problem. Monday and Friday are the next highest traffic days.I\u2019m sure users would be willing to sacrifice two days out of the week to potentially have a better site experience in the long term, whereas the polls being conducted currently only allows members to decide whether to have a sub or not have one for an indeterminate amount of time, and of course people will choose the former. Two days allows us to have a functional community while impacting reddit more than we impact ourselves. [Asymmetrical warfare if you will]Once reddit realizes we can actually do this all day (to quote Captain America), they\u2019ll actually have to address our concerns, potentially quickly. Instead of the \u201cit\u2019ll blow over\u201d, \u201cthey\u2019ll be crawling back by Wednesday\u201d stuff Spez is spouting.permalinkembedsavereportreply[\u2013]CasuallyViewingStuff 1 point 8 minutes ago both points are not a real concern, as an effective protest inherently must disrupt and inconveniences the authority at the top in order to force changes. Non-essential subs blacking out indefinitely is valid as there are other sites and forums to discuss the content they're consuming, and even if people make a new sub, it would never meet up to the og sub's traffic and numbers.going private for two days per week is a measly action that wouldn't do a thing and is a needless compromise that would affirms Huffman's thoughts in reddit's internal memo https://www.theverge.com/2023/6/13/23759559/reddit-internal-memo-api-pricing-changes-steve-huffmanSo yeah, any subs that's blacking out indefinitely is doing good here.permalinkembedsaveparentreportreply[\u2013]sugar-peas 1 point 3 hours ago not a mod but r/ProgrammerHumor said they are staying closed incredibly on their discordpermalinkembedsavereportreply[\u2013]JetsNovocastrian 1 point 44 minutes ago Grr, I hate it when people do this. You can only view that announcement by signing up to Discord. Another reason why Discord is not a substitute for a public forum. Discords are not Googleable either! Makes it silo information in a hidden vacuum of the internet except those who know how to identify it.permalinkembedsaveparentreportreply[\u2013]Capital-Trouble-3549 1 point 33 minutes ago This. The inability to find information is annoying as fuck.permalinkembedsaveparentreportreply[\u2013]Rivered_The_Nuts 0 points 3 hours ago Brigading other subs to sway poll results\u2026 real good look.If you want to go dark, it can be done without fucking with subs other people enjoy - simply delete your account and stop supporting Reddit.permalinkembedsavereportreply[\u2013][deleted] 3 hours ago [removed][\u2013]DigitalDude_42 1 point 23 minutes ago Oh no, you're going to have to manually do your job for free! How awful.Probably not even that. It's telling that none of them have thought outside of the box for a solution between catering to specific apps or holding everyone hostage.permalinkembedsavereportreply[\u2013]Thegermandoge 3 points 3 hours ago* r/ancientrome, r/AfterTheEndFanFork, r/lgballt are staying closed indefinitelypermalinkembedsavereportreply[\u2013]Best-Expert 1 point 2 hours ago Staying open or closed indefinitely? Mention it.permalinkembedsaveparentreportreply[+]PastrychefPikachu 1 point 3 hours ago (1 child)[\u2013]WholeNote1 2 points 3 hours ago reminder to random people angry about the lack of access to some subs: if you're on chrome and you add \"cache:\" to the beginning of the post url, you can still access it and not give reddit any ad revenue! if you're on any other browser add \"http://webcache.googleusercontent.com/search?q=cache:\" to the start of the urlpermalinkembedsavereportreply[\u2013]Nick_BD 4 points 3 hours ago Anyone got an idea about r/Korea?Subs like that when my Korean is bad was helpful like for example month back we had a false alarm text alert about a North Korean missile. That sub that morning was helpful.permalinkembedsavereportreply[\u2013]WithersChat 12 points 3 hours ago r/egg_irl indefinitepermalinkembedsavereportreply[\u2013]greninjaisevil 5 points 4 hours ago r/TheSinsOfEurope is in for the long haul, not the biggest but its Worth itpermalinkembedsavereportreply[\u2013]Certain-Bank4444 3 points 4 hours ago Join this coordinating post blackout subRedditsCoordinating subs after blackout join https://discord.gg/FqCxVb7RNTpermalinkembedsavereportreply[\u2013]TheGreyGuardian 12 points 4 hours ago So, I'm trying to support the blackout but I keep getting responses that modding tools and accessibility apps are exempt from the API pricing change and I just don't have a good response other than \"Some mod tools are baked into third party apps like Apollo/RIF\" and I don't want to give Spez being immoral as a reason because the people arguing with me couldn't care less as long as they get their dopamine from scrolling. Can anyone help me with some better points?permalinkembedsavereportreply[\u2013]Kronusx12 1 point 3 minutes ago Honestly I\u2019d open with the advice that engaging in good faith with people who are adamantly opposed to the protest is probably just going to end up a frustrating experience for you. However, if you decide to, I\u2019d add a bit on to your points.No matter has said, it doesn\u2019t add up.they\u2019ve been promising better mod tools since at least 2015 and continue to fail to deliver them. The mod tools have instead been built into apps by smaller developers that have had 10+ years to refine them. IIRC Apollo was 8 years old and RIF was like 11.So specifically looking at exclusions for mod tools, Reddit is really referring to bots / scripts that subreddits use. While that\u2019s great it doesn\u2019t help mods out when they are on mobile. It\u2019s not as though all mods are sitting at their computers all day. So this still leaves mods without good ways to run their subs from their phones.As far as accessibility options, well Spez is full of shit. Again, major apps have had about a decade of experience and development to get to where they are. They have a mature product with a ton of features built in. The 2 apps that Spez keeps mentioning that are exempt are Redreader (Android) and Dystopia (iOS). Redreader looks promising promising for those on Android, but Dystopia isn\u2019t even released yet. You have to sign up to Testflight to request beta access for the app. In my opinion taking away a mature app with great features and saying \u201cHey use this app that\u2019s not even released yet\u201d instead is pretty shitty.If Reddit have 2 shits about any of this, they would have at the very least released better mobile mod tools and added accessibility features to their own app BEFORE cutting off API access. The reality is that the timing shows that they just don\u2019t carepermalinkembedsaveparentreportreply[\u2013]autobahn 1 point 55 minutes ago Personally, I'm not in this protest JUST for mod access. Everyday users deserve 3rd party app access as well. Forcing people onto the awful native app is draconian. And I don't buy for a second that \"accessibility apps are exempt\". What does that mean? At this point the native app is a mess, so accessibility app at this point means a third party client.permalinkembedsaveparentreportreply[\u2013]DigitalDude_42 1 point 46 minutes ago What does that mean?That means that for instance the app that the vision impaired use to help them read through reddit still gets free API usage.permalinkembedsaveparentreportreply[\u2013]ClearlyAThrowawai 0 points 1 hour ago People who don't care about what Spez says probably aren't going to convinced regardless of what you say - they weren't using the tools in the first place and they won't care now.At this point I just don't trust reddit to be a good custodian of the community when they so clearly couldn't give a shit about their users throughout this situation. They've made it clear that they are happy to degrade the user experience in favor of squeezing a little extra cash out of their control of the website.It's API access now, old.reddit next, more ads mixed in after that, and so on. Their only real plan to improve their monetisation is to squeeze the userbase harder - if they'd had an alternative course of action they would have charged a \"reasonable\" API price that people could tolerate, not an exorbitant price clearly intended to drive out the vast majority of users.permalinkembedsaveparentreportreply[\u2013]anal_everywhere 14 points 3 hours ago As u/Hiccup said, all NSFW content will be restricted via the API.NSFW does not by default mean porn, but there are support groups that have NSFW content, and that support will go dark July 1.permalinkembedsaveparentreportreply[+]SomeExpression123 comment score below threshold (8 children)[\u2013]Hiccup 7 points 4 hours ago Anything labeled as NSFW will not flow through 3rd party apps. Basically censorship.permalinkembedsaveparentreportreply[+]SomeExpression123 comment score below threshold (0 children)[+]missingmytowel comment score below threshold (4 children)[\u2013]BRC_Haus 5 points 4 hours ago r/xxketoOver50 - indefinite.r/xxketo4u2 - indefinitepermalinkembedsavereportreply[\u2013]Srybutimtoolazy 6 points 4 hours ago r/puberty indefinitepermalinkembedsavereportreply[\u2013]JOEY2X 13 points 4 hours ago r/Disney indefinitepermalinkembedsavereportreply[\u2013]AlexanderDaychilde 3 points 3 hours ago Woot! Go /r/Gisnep! ;-)permalinkembedsaveparentreportreply[\u2013]wkLeon 6 points 4 hours ago r/tenilledashwood Solidaritypermalinkembedsavereportreply[\u2013]DeathBug9976 5 points 4 hours ago r/miraculousroleplay is indefinitepermalinkembedsavereportreply[\u2013]CityOfChamps09 5 points 4 hours ago /r/projectglowfest indefinite/r/ARCMusicFestival indefinitepermalinkembedsavereportreply[\u2013]BroMatterhorn 5 points 4 hours ago* r/stickerstore indefinitepermalinkembedsavereportreply[\u2013]Kitteh5 5 points 4 hours ago /r/lincolnmotorco - indefinitepermalinkembedsavereportreply[\u2013]Millennial-Mason 7 points 4 hours ago r/plotholes indefinitepermalinkembedsavereportreply[\u2013]GloInTheDarkUnicorn 6 points 4 hours ago r/raiseyourglass and r/petsofcriticalrole indefinite. Both are small but going dark.permalinkembedsavereportreply[\u2013]seacucumber98 1 point 5 hours ago Solidarity Tuesdays? Make it Sundays, see what happenspermalinkembedsavereportreply[\u2013]Toptomcat[M] 6 points 4 hours ago I argued for it. Didn't work out.permalinkembedsaveparentreportreply[\u2013]learhpa 1 point 1 hour ago as the mod of a book subreddit i'm torn between wanting to show solidarity if we reopen and thinking that shutting down on the day new book releases happen is not friendly to the community.permalinkembedsaveparentreportreply[\u2013]seacucumber98 -1 points 4 hours ago Well, at least Tuesday is better than no day at all I guesspermalinkembedsaveparentreportreply[\u2013]Magiwarriorx 9 points 5 hours ago Not a mod, but:/r/3dshacks said they were indefinite/r/POTCmemes initially said they were outright deleting the sub, but its private nowpermalinkembedsavereportreply[\u2013]Manny-Both-Hanz 2 points 4 hours ago Good on r/3dshacks. 3dspiracy was aggressively against it, didn't even do a community vote.permalinkembedsaveparentreportreply[\u2013]edderiofer 9 points 5 hours ago /r/math, indefinite.permalinkembedsavereportreply[\u2013]InspiratorAG112 2 points 3 hours ago Do you have a new destination for them, like a Discord server or Squabble page?permalinkembedsaveparentreportreply[\u2013]Teddetheo 3 points 5 hours ago r/solution indefinitepermalinkembedsavereportreply[\u2013]DerisionConsulting 4 points 5 hours ago /r/swiftcurrent Indefinitepermalinkembedsavereportreply[\u2013]anal_everywhere 9 points 5 hours ago r/Couplesporn (330k+) is taking a vote. We'll find out in 24 hours.edit: being a NSFW sub, not a lot of talk about how Reddit will restrict NSFW content with this new API plan.permalinkembedsavereportreply[\u2013]Kumquat_conniption[M] 8 points 5 hours ago I'm pretty sure they said they will be restricting NSFW content completely from the API :(permalinkembedsaveparentreportreply[\u2013]anal_everywhere 12 points 5 hours ago Up doot for you. That is exactly what I mean. No NSFW access through API. Sounds like censorship to me.permalinkembedsaveparentreportreply[\u2013]Kumquat_conniption 2 points 5 hours ago Oh I just read your comment again and I read it wrong the first time, which is why it looks like I'm answering a question you didn't ask! You already know that, my bad :)permalinkembedsaveparentreportreply[\u2013]anal_everywhere 4 points 4 hours ago All good my friend! I just wish this censorship was mentioned more!NSFW does not necessarily mean porn (in my case it does) but there are NSFW things on Reddit that are a cry for support and help. That cry will go dark July 1. And to me, that is unacceptable.permalinkembedsaveparentreportreply[\u2013]Kumquat_conniption 1 point 4 hours ago Oh for sure, even on the subs I mod like r/PublicFreakout and r/therewasanattempt we mark lots of stuff NSFW because they can be somewhat gory and it's a way to warn people.It's going to screw up so much stuff :(permalinkembedsaveparentreportreply[\u2013]Ok_Chemistry_5900 3 points 5 hours ago r/torties indefinitepermalinkembedsavereportreply[\u2013]AlexanderDaychilde 1 point 3 hours ago Clockwise will be disappointed. I'm glad I posted in there the other day <3permalinkembedsaveparentreportreply[\u2013]EDCMod 6 points 5 hours ago /r/electricdaisycarnival indefinite/r/edcorlando indefinite/r/edcmexico indefinite/r/edctickets indefinite/r/campedc indefiniteWe were polling our members before we came to a final decision. Blackout will resume at midnight UTC, in a little under an hour.permalinkembedsavereportreply[\u2013]learhpa 0 points 1 hour ago do y'all have a discord or something for interested parties to join if y'all stay down indefinitely? (i'm an interested party)permalinkembedsaveparentreportreply[\u2013]annoyinghamster51 8 points 5 hours ago Just wanted to say that I appreciate you guys' efforts in this blackout.permalinkembedsaveparentreportreply[\u2013]HyKaliber 7 points 5 hours ago /r/Colts indefinitepermalinkembedsavereportreply[\u2013]haircombsnightmare 5 points 5 hours ago r/NetflixSexEducation indefinitepermalinkembedsavereportreply[\u2013]_Timboss 4 points 5 hours ago r/JustBadNews Indefinitepermalinkembedsavereportreply[\u2013]_Timboss 5 points 5 hours ago r/JustGoodNews Indefinitepermalinkembedsavereportreply[\u2013]Poppamunz 5 points 5 hours ago /r/itcosinedinaflash indefinitepermalinkembedsavereportreply[\u2013]ZinkZoodles_YT 8 points 5 hours ago r/ClubPenguinRewritten indefinitepermalinkembedsavereportreply[\u2013]Carolina_Heart 8 points 5 hours ago r/Gaming4Gamers indefinitepermalinkembedsavereportreply[\u2013]phillygeekgirl 8 points 5 hours ago r/lupus indefinitepermalinkembedsavereportreply[\u2013]AL2009man 13 points 6 hours ago /r/gyrogaming (2.3k) was previously private, but reverted to Restricted juuuuuust so some of the Gyro Aiming community folks (who don't follow the news) get the memo before I revert back to Private.basically: indefinitely.permalinkembedsavereportreply[\u2013]Cautious_Expert_2501 6 points 6 hours ago I hear that /r/2600 is indefinitepermalinkembedsavereportreply[\u2013]learhpa 0 points 1 hour ago i would expect nothing else from them.permalinkembedsaveparentreportreply[\u2013]evit_cani 8 points 6 hours ago r/Avrae Indefinite (~1.5k)permalinkembedsavereportreply[\u2013]SNE3Z 8 points 6 hours ago r/piedude67iscool (~1k) Indefinitepermalinkembedsavereportreply[\u2013]zyncoolmint420 -1 points 6 hours ago How does this affect Lebron\u2019s legacy?permalinkembedsavereportreply[\u2013]AFruitShopOwner 6 points 6 hours ago* /r/Microvast (3.8k) indefinite.permalinkembedsavereportreply[\u2013]HipHopSpaceBop 14 points 6 hours ago r/femalefashionadvice indefinitepermalinkembedsavereportreply[\u2013]bb010g 12 points 6 hours ago /r/ainbowroad (~5.2k) will be remaining private indefinitely (instead of switching to protected).permalinkembedsavereportreply[\u2013]bandaidsplus 7 points 6 hours ago Also /r/gamingstories set private. ( 500 subscribers strong \ud83d\udcaa\ud83d\udcaa\ud83d\udcaa)permalinkembedsavereportreply[\u2013]bobsmithm 12 points 6 hours ago /r/bioniclememes Indefinite.permalinkembedsavereportreply[\u2013]Ediwir 10 points 6 hours ago r/Pathfinder2e (93k) joins in solidarity.Might talk to some friends and affiliates, too.permalinkembedsavereportreply[\u2013]bandaidsplus 10 points 6 hours ago Just set /r/flags_irl to private. Keep the blackout rolling.permalinkembedsavereportreply[\u2013]maniacalmanicmania 9 points 6 hours ago r/housingforall indefinitepermalinkembedsavereportreply[\u2013]ambo100 6 points 6 hours ago /r/arboriculture indefinitepermalinkembedsavereportreply[\u2013]Dark_Magus 15 points 6 hours ago Is there a full list of all the subs that are going dark indefinitely (as opposed to the ones only off for 48 hours)?permalinkembedsavereportreply[+]TurdFergusonlol comment score below threshold (39 children)load more comments (15594 replies)aboutblogaboutadvertisingcareershelpsite rulesReddit help centerreddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile website<3reddit premiumreddit coinsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. \u00a9 2023 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.\u03c0",
    "summary": "- Reddit has announced a policy change that will affect third-party Reddit apps, leaving only the official mobile app as an option.\n- In response to this, many subreddits have gone black in protest, including popular ones such as r/aww, r/music, r/videos, and r/futurology.\n- Over 300 subreddits have announced that they are prepared to remain inaccessible indefinitely until Reddit addresses their concerns.\n- The blackout is demanding changes in API technical issues, accessibility for blind users, and parity in access to NSFW (not safe for work) content.\n- Reddit CEO Steve Huffman claims that the blackout has not had a significant revenue impact, but many subreddits are committed to staying black until their demands are met.",
    "hn_title": "The Reddit blackout will continue",
    "original_title": "The Reddit blackout will continue",
    "score": 565,
    "hn_content": "- The poster claims that the internet has transitioned from being built by volunteers for volunteers to being owned by corporations.\n- They express hope that platforms like Twitter, Reddit, and Facebook will be replaced by \"corresponding Wikipedias\", suggesting a desire for decentralized and community-driven platforms.\n- Another user expresses nostalgia for the early days of the internet when forums were the primary form of online community and laments the current state of social media.\n- The trajectory of platforms like Discord is discussed, with speculation on how they may evolve and monetize user data.\n- The importance of user-generated content is mentioned, with a focus on the ownership and rights of that content.\n- There is debate about the future of the internet, with some arguing for the continued consolidation of platforms and others advocating for more decentralized and user-controlled alternatives.\n- The limitations and drawbacks of centralized social media platforms are acknowledged, with calls for greater control and ownership by users.- Reddit users are engaging in a protest over changes made by the platform's CEO, Steve Huffman.\n- The changes include a new policy that requires third-party app developers to pay high fees for API access.\n- Many users and moderators are unhappy with these changes and have organized a blackout of various subreddits.\n- The protest is driven by concerns over the direction and monetization of the platform.\n- Users are discussing alternatives to Reddit, such as Discord or Lemmy, as potential migration options.\n- The future of the platform is uncertain, with potential consequences for both users and moderators.",
    "hn_summary": "- The internet has transitioned from being built by volunteers to being owned by corporations.\n- Hope for the rise of decentralized and community-driven platforms to replace Twitter, Reddit, and Facebook.\n- Nostalgia for the early days of the internet and dissatisfaction with the current state of social media."
  },
  {
    "id": 36328352,
    "timestamp": 1686760080,
    "title": "First people sickened by Covid-19 were scientists at WIV: US government sources",
    "url": "https://public.substack.com/p/first-people-sickened-by-covid-19",
    "hn_url": "http://news.ycombinator.com/item?id=36328352",
    "content": "First People Sickened By COVID-19 Were Chinese Scientists At Wuhan Institute Of Virology, Say US Government SourcesThe three scientists were engaged in \u201cgain-of-function\u201d research on SARS-like coronaviruses when they fell illMICHAEL SHELLENBERGER, MATT TAIBBI, AND ALEX GUTENTAGJUN 13, 2023964165Ben Hu, one of threee \u201cpatients zero,\u201d and a researcher who led the Wuhan Institute of Virology\u2019s \u201cgain-of-function\u201d research on SARS-like coronaviruses, which increases the infectiousness of viruses.After years of official pronouncements to the contrary, significant new evidence has emerged that strengthens the case that the SARS-CoV-2 virus accidentally escaped from the Wuhan Institute of Virology (WIV).According to multiple U.S. government officials interviewed as part of a lengthy investigation by Public and Racket, the first people infected by the virus, \u201cpatients zero,\u201d included Ben Hu, a researcher who led the WIV\u2019s \u201cgain-of-function\u201d research on SARS-like coronaviruses, which increases the infectiousness of viruses.More than three years after the pandemic\u2019s outbreak, many around the world had given up on learning the origin of SARS-CoV-2, the highly infectious respiratory virus that has killed millions, and the response to which shut down businesses and schools, upended societies, and caused enormous collateral damage.Public officials in the U.S. and other countries have repeatedly suggested that uncovering the pandemic\u2019s origin may not be possible. \u201cWe may never know,\u201d said Anthony Fauci, the former director of the National Institute of Allergy and Infectious Diseases, who oversaw pandemic response for two administrations.Now, answers increasingly look within reach. Sources within the US government say that three of the earliest people to become infected with SARS-CoV-2 were Ben Hu, Yu Ping, and Yan Zhu. All were members of the Wuhan lab suspected to have leaked the pandemic virus.As such, not only do we know there were WIV scientists who had developed COVID-19-like illnesses in November 2019, but also that they were working with the closest relatives of SARS-CoV-2, and inserting gain-of-function features unique to it.When a source was asked how certain they were that these were the identities of the three WIV scientists who developed symptoms consistent with COVID-19 in the fall of 2019, we were told, \u201c100%\u201d\u201cBen Hu is essentially the next Shi Zhengli,\u201d said Alina Chan, a molecular biologist at the Broad Institute of MIT and Harvard, and coauthor with Matt Ridley of Viral: The Search for the Origin of Covid19. Shi is known as \u201cthe bat woman of China,\u201d and led the gain-of-function research at the WIV. \u201cHe was her star pupil. He had been making chimeric SARS-like viruses and testing these in humanized mice. If I had to guess who would be doing this risky virus research and most at risk of getting accidentally infected, it would be him.\u201dShi Zhengli, \u201cthe bat woman of China,\u201d who oversaw Wuhan Institute of Virology\u2019s coronavirus research and engineering. (Getty Images)Hu and Yu researched the novel lineage of SARS-like viruses from which SARS-CoV-2 hails, and in 2019 coauthored a paper with Shi Zhengli that described SARS-like lineages they had studied over the years.Jamie Metzl, a former member of the World Health Organization expert advisory committee on human genome editing who raised questions starting in early 2020 about a possible research-related pandemic origin, said, \u201cIt\u2019s a game changer if it can be proven that Hu got sick with COVID-19 before anyone else. That would be the \u2018smoking gun.\u2019 Hu was the lead hands-on researcher in Shi\u2019s lab.\u201dSources tell Public and Racket that other news organizations are chasing aspects of this story. On Saturday, The Times of London quoted an anonymous U.S. State Department investigator saying, \u201cIt has become increasingly clear that the Wuhan Institute of Virology was involved in the creation, promulgation, and cover-up of the Covid-19 pandemic.\u201dPublic and Racket are the first publications to reveal the names of the three sick WIV workers and place them directly in the lab that collected and experimented with SARS-like viruses poised for human emergence.Next week, the Directorate of National Intelligence is expected to release previously classified material, which may include the names of the three WIV scientists who were the likely among the first to be sickened by SARS-CoV-2.A bill signed by President Biden earlier this year specifically called for the release of the names and roles of the sick researchers at the WIV, their symptoms and date of symptom onset, and whether these researchers had been involved with or exposed to coronavirus research.On Dec. 29, 2017, two years before the pandemic began, Chinese state-run television aired a video that includes a scene of Ben Hu watching a lab worker handle specimens. Neither are wearing protective gear. The same video shows WIV scientists hunting for bat viruses with little protective gear. \u201cIf they were worried about being infected in the field, they would need full body suits with no gaps\u201d to be safe, said Chan. \u201cThat\u2019s the only way.\u201dThe WIV research with live SARS-like viruses was performed at too low of a safety level, \u201cBSL-2,\u201d explains Chan, \u201cWhen we now know that the pandemic virus is even capable of escaping from a BSL-3 lab and infecting fully vaccinated young lab workers.\u201dWhile scientists justify such research as necessary for developing vaccines, President Barack Obama banned federal funding for gain-of-function research of concern in 2014, because experts had come to the consensus that it was too dangerous. However, the National Institute of Health and NIAID headed by Francis Collins and Fauci, and a major U.S. government grantee, EcoHealth Alliance, deemed their work on SARS-like viruses as not falling under the gain-of-function research of concern definitions and funded this project in China and Southeast Asia.In March 2018, the WIV, the EcoHealth Alliance, and the University of North Carolina applied for a $14 million grant from the U.S. Defense Advanced Research Project Agency DARPA to engineer \u201cfurin cleavage sites\u201d into SARS-like coronaviruses to study how this affected their ability to grow and cause disease.Scientists say the key piece of the COVID-19 virus, which made it so transmissible compared to its closest relatives, was its unique furin cleavage site.DARPA rejected the grant, but it now appears the WIV went forward with the research anyway. The Times of London reported that US collaborators of the WIV had come forward and said the Wuhan scientists had put furin cleavage sites into SARS-like viruses in 2019.Hu co-authored multiple papers on coronavirus research, including a 2017 paper on chimeric bat coronaviruses with Peter Daszak, the head of EcoHealth Alliance, which was funded in part by the NIH and the USAID Emerging Pandemic Threats PREDICT Program. Data privately shared with the NIH revealed that these chimeric SARS-like viruses grew far more quickly and caused more severe disease in humanized mice in the lab.Peter Daszak, the head of EcoHealth Alliance, which was funded in part by the NIH and the USAID Emerging Pandemic Threats PREDICT Program. (Getty Images)When the WIV put out their first paper about the pandemic virus, they failed to point out the novel furin cleavage site despite having had plans to and allegedly putting such gain-of-function features into SARS-like viruses in their lab. \u201cIt\u2019s as if these scientists proposed putting horns on horses, but when a unicorn shows up in their city a year later they write a paper describing every part of it except its horn,\u201d said Chan.Public sent emails and made phone calls to the NIH, WIV, EcoHealth Alliance, Daszak, Hu, and Shi over the last several days and did not hear back.It is unclear who in the U.S. government had access to the intelligence about the sick WIV workers, how long they had it, and why it was not shared with the public. \u201cYou would expect the country of origin to be defensive,\u201d said Chan, \u201cbut you wouldn\u2019t expect a country receiving the virus to be withholding key evidence.\u201dOn January 15, 2021, five days before President Joe Biden took office, the U.S. State Department published a fact sheet that pointed to the likelihood of a lab leak as the cause of a pandemic.Already, the State Department in 2021 suspected that the WIV had lied to the public. \u201cThe U.S. government has reason to believe that several researchers inside the WIV became sick in autumn 2019, before the first identified case of the outbreak, with symptoms consistent with both COVID-19 and common seasonal illnesses. That raises questions about the credibility of WIV senior researcher Shi Zhengli\u2019s public claim that there was \u2018zero infection\u2019 among the WIV\u2019s staff and students by SARS-CoV-2 or SARS-related viruses.\u201dIn February of this year, the Director of the FBI, Christopher Wray, told a reporter that \u201cthe FBI has for quite some time now assessed that the origins of the pandemic are most likely a potential lab incident in Wuhan.\u201dThe Times of London reported that State Department investigators \u201cfound evidence that researchers working on these experiments were taken to hospital with Covid-like symptoms in November 2019.\u201d As previously reported in Vanity Fair, some of the information State Department investigators found in 2021 was \u201csitting in the U.S. intelligence community\u2019s own files, unanalyzed.\u201d\u201cEver since I put out my [May 2020] preprint [research paper] saying that an accidental lab origin was possible, I was criticized as a conspiracy theorist,\u201d said Chan. \u201cIf this info had been made public in May of 2020, I doubt that many in the scientific community and the media would have spent the last three years raving about a raccoon dog or pangolin in a wet market.\u201dIdentifying the first COVID-19 case as a Wuhan Institute scientist overseeing gain-of-function research has significant ramifications for investigators in search of a motive for a cover-up.Politicians, scientists, journalists, and amateur researchers for years now have zeroed in on the possibility that Covid-19 may have resulted from U.S.-funded gain-of-function research conducted in China.Publications ranging from the Washington Post to the Intercept to the Wall Street Journal have uncovered suggestive details, including the fact that the NIH awarded funding for at least 18 gain-of-function research projects between 2012 and 2020, and NIH scientists in 2016 expressing concern about supposedly paused hybrid \u201cchimera\u201d virus research.Had the information come out earlier, governments may have responded to the pandemic differently. After Public shared the information with Chan, she said, \u201cI feel vindicated, but I\u2019m frustrated. If you knew that this was likely a lab-enhanced pathogen, there are so many things you could have done differently. This whole pandemic could have been reshaped.\u201dSaid Metzl, \u201cHad US government officials including Dr. Fauci stated from day one that a COVID-19 research-related origin was a very real possibility, and made clear that we had little idea what viruses were being held at the Wuhan Institute of Virology, what work was being done there, and who was doing that work, our national and global conversations would have been dramatically different. The time has come for a full accounting.\u201d964 Likes\u00b759 Restacks964165A guest post byMatt TaibbiSubscribe to Matt",
    "summary": "- Evidence suggests that the first people to be infected with COVID-19 were Chinese scientists at the Wuhan Institute of Virology (WIV).\n- The scientists were engaged in \"gain-of-function\" research, which involves increasing the infectiousness of viruses like SARS-like coronaviruses.\n- This information challenges previous official statements and adds to the growing evidence that the virus accidentally escaped from the WIV.",
    "hn_title": "First people sickened by Covid-19 were scientists at WIV: US government sources",
    "original_title": "First people sickened by Covid-19 were scientists at WIV: US government sources",
    "score": 508,
    "hn_content": "- US government sources suggest that some of the earliest people to become infected with SARS-CoV-2 were scientists at the Wuhan Institute of Virology (WIV).\n- The article does not provide new sources but rather links to various quotes and suppositions from different individuals.\n- The Director of National Intelligence is required by law to declassify information about the infected researchers on June 18th, including their names, symptoms, date of onset, and role at WIV.\n- The article raises curiosity about the upcoming declassification of information and the potential consequences of proving that the mentioned scientists were the first to fall ill.\n- There may be skepticism about the authenticity and reliability of the article due to the author's reputation or affiliation with Substack.- The article discusses the theory that the COVID-19 virus originated from a lab leak at the Wuhan Institute of Virology.\n- Some people pushing the lab leak theory mix fact with speculation, while those pushing against it don't need to.\n- The odds of the market being the first superspreading event in Wuhan are estimated to be low based on an analysis of early cases.\n- It is suggested that the market was not densely trafficked and there were other areas in the city with higher footfall.\n- The article raises questions about the hospitalization of healthy researchers and the definition of \"hospital\" in China.\n- The wet market isn't considered a typical location for a virus outbreak, and high-density areas are more likely to contribute to the spread.\n- The article mentions a thread criticizing the findings of a paper supporting the lab leak theory, but it argues against the thread's claims.\n- The debate over COVID-19 origins is complex, involving multiple theories and interpretations of evidence.\n- The article emphasizes the need for rigorous pathogen surveillance and the prevention of reckless research practices to avoid future pandemics.",
    "hn_summary": "- The US government sources suggest that scientists at the Wuhan Institute of Virology were among the first to be infected with SARS-CoV-2.\n- The Director of National Intelligence is required to declassify information about the infected researchers on June 18th.\n- The article raises questions about the origins of COVID-19, including the lab leak theory, the wet market, and high-density areas contributing to the spread."
  },
  {
    "id": 36328433,
    "timestamp": 1686760372,
    "title": "Bay Area woman is on a crusade to prove Yelp reviews can't be trusted",
    "url": "https://www.sfgate.com/tech/article/yel-review-fraud-kay-dean-18150617.php",
    "hn_url": "http://news.ycombinator.com/item?id=36328433",
    "content": "Press & Hold to confirm you area human (and not a bot).Having a problem?Reference ID 721443e5-0b37-11ee-8f3b-7a654b52526a",
    "summary": "N/A",
    "hn_title": "Bay Area woman is on a crusade to prove Yelp reviews can\u2019t be trusted",
    "original_title": "Bay Area woman is on a crusade to prove Yelp reviews can\u2019t be trusted",
    "score": 465,
    "hn_content": "- A woman in the Bay Area is on a mission to expose the lack of trustworthiness of Yelp reviews.\n- Yelp's business model appears to favor businesses that pay for promotion and advertising.\n- Users have reported issues with Yelp's search algorithm, which seems to hide certain results and favor others.\n- Google Maps has similar problems, with users complaining about hidden results and inaccurate rankings.\n- The internet as a whole has experienced a decline in search quality and reliable recommendations.\n- Yelp, Google Maps, and other review platforms are prone to fake reviews, both positive and negative.\n- There have been accusations of extortion and manipulation of reviews by Yelp sales representatives.\n- Whistleblowers have reported shady practices by Yelp, including offering to remove negative reviews in exchange for payment.\n- Businesses are advised to rely on word-of-mouth recommendations rather than trusting online review platforms.\n- The issue of fake reviews is not limited to Yelp but is a broader problem across the internet.\n- It is important to be cautious and skeptical when reading online reviews and to consider multiple sources of information before making decisions.- Many people have concerns about the authenticity of Yelp reviews and whether or not they are manipulated or extorted.\n- There have been legal cases involving Yelp and allegations of wrongful economic loss, posting and sequencing both positive and negative reviews, and false advertising as a trusted review source.\n- Section 230 of the law provides some protection for review websites like Yelp, but end users can potentially be held responsible for defamation.\n- The authenticity of online reviews is a challenge for many platforms, and it is difficult to determine good versus bad actors in review systems.\n- Yelp is deeply entrenched in American consumer habits and remains relevant despite criticisms.\n- Yelp reviews should be taken with caution and evaluated using other sources of information such as personal recommendations, menu photographs, and interior photographs.",
    "hn_summary": "- Yelp reviews are considered untrustworthy by many due to concerns about manipulation and extortion.\n- Both Yelp and Google Maps have issues with their search algorithms, leading to hidden results and inaccurate rankings.\n- The problem of fake reviews extends beyond Yelp and is a broader issue on the internet."
  },
  {
    "id": 36327210,
    "timestamp": 1686755628,
    "title": "The Reddit blackout has left Google barren & full of holes",
    "url": "https://www.techradar.com/opinion/the-reddit-blackout-has-left-google-barren-and-full-of-holes",
    "hn_url": "http://news.ycombinator.com/item?id=36327210",
    "content": "Home Opinion ComputingThe Reddit blackout has left Google barren and full of holesBy Muskaan Saxena published about 18 hours agoGoogle really did rely on Reddit for a lot of content(Image credit: Sarnia via Shutterstock )Over 8,000 subreddits have gone dark in protest of Reddit's upcoming API changes, and it\u2019s highlighted just how empty Google becomes without access to those subreddits.The sheer number of very specific subreddits (essentially smaller forums dedicated to a certain topic) means there is something for everyone, and if you\u2019ve got a question, someone out there will have the answer. Even if you don\u2019t just tag \u2018Reddit\u2019 to the end of your search query, the site usually turns up close to the top of most searches anyway, so even if you don\u2019t actively use the platform, you\u2019re likely to have gotten some useful information from there at some point.However, now that so many of these subreddits have gone private it\u2019s almost impossible to ignore the impact it\u2019s made on the everyday Google experience. Yes, Google can show me answers to most things and direct me to other websites, but it\u2019s simply not the same. Why would I scroll through an article or long blog post when someone on Reddit has asked the same thing and gotten a quick answer?Hard to find answersFor example, I\u2019m currently playing Tears of the Kingdom and I\u2019ve been having trouble figuring out a lot of the shrines in the game. There are hundreds of shrines, and instead of crawling through YouTube videos or tearing through a walk-through only to realise I have no idea what\u2019s going on, I would just go onto Reddit.I could either search for the shrine, tag \u2018Reddit\u2019 on the end and find a thread on the exact same shrine, being discussed by people who either have completed the shrine or are just giving out hints or tricks. And I know if I head over to the Tears of the Kingdom subreddit, r/TOTK (which is now private) and drop the name of the shrine I need help with, I\u2019ll get assistance and handy tips for completing it.Reddit has a conversational and deeply communal feel that makes it so useful. You never feel like you\u2019re just throwing your comment or question into the void and hoping you find something useful. The comments and questions on Reddit let you see other recommendations, different points of views and links to resources. It\u2019s a wealth of information, all in one place.With many threads no longer showing up (or appearing private, so you cannot read the content) when you\u2019re using Google, you realise just how much Reddit carried the search engine for a lot of people. While the protest was only set to be for 48 hours, it is unclear if a majority of the protesting subreddits will stick to this time frame or if things will go on for longer.Hopefully, the protest will end soon (ideally with Reddit management acknowledging the community\u2019s concerns over its proposed API changes), otherwise, Reddit\u2019s blackout will continue to have repercussions for the wider internet, and not just one website.Muskaan SaxenaComputing Staff WriterMuskaan is TechRadar\u2019s UK-based Computing writer. She has always been a passionate writer and has had her creative work published in several literary journals and magazines. Her debut into the writing world was a poem published in The Times of Zambia, on the subject of sunflowers and the insignificance of human existence in comparison.Growing up in Zambia, Muskaan was fascinated with technology, especially computers, and she's joined TechRadar to write about the latest GPUs, laptops and recently anything AI related. If you've got questions, moral concerns or just an interest in anything ChatGPT or general AI, you're in the right place.Muskaan also somehow managed to install a game on her work MacBook's Touch Bar, without the IT department finding out (yet).MORE ABOUT COMPUTINGThree ways to secure maximum ROI from AIThere's trouble in AI paradise as Microsoft and OpenAI butt headsLATESTMulti-cloud trend driving business resilience for data managementSEE MORE LATEST \u25ba",
    "summary": "- Over 8,000 subreddits have gone offline in protest of Reddit's upcoming API changes, leading to a significant impact on Google search results.\n- The loss of these subreddits means that users no longer have access to the valuable content, discussions, and answers found on Reddit.\n- Reddit's blackout highlights the communal and informational nature of the platform, and the impact it has on the wider internet beyond just one website.",
    "hn_title": "The Reddit blackout has left Google barren and full of holes",
    "original_title": "The Reddit blackout has left Google barren and full of holes",
    "score": 425,
    "hn_content": "- The open internet is becoming centralized, with platforms like Reddit dominating the space.\n- This shift has made it more difficult to find decentralized sources of information, as communities are now concentrated within specific platforms.\n- Discord, a popular communication platform, is seen as a potential alternative to forums and chat rooms but is criticized for its lack of searchability and content indexing.\n- The lack of searchability in platforms like Discord hinders the preservation and discoverability of valuable information.\n- The move towards centralized platforms raises concerns about privacy, as users are required to give away their credentials to private companies to access content.\n- There is a need for more open and transparent alternatives that provide better searchability and content preservation.\n- The fragility of centralized platforms is evident in recent events like the Reddit blackout, highlighting the risks of relying on a single platform for information and communication.- The open web is dying as more content is centralized on platforms like Reddit and Medium.\n- Google has lost the spam war and is prioritizing popular sites over smaller, high-quality content.\n- The lack of indexing for platforms like Discord and TikTok is contributing to the decline of the open web.\n- Hosting a personal website is expensive and requires technical expertise, deterring many from participating in the open web.\n- The open web offers a level of authenticity and personal experiences that curated platforms like Medium lack.\n- Decentralized alternatives like the fediverse are becoming popular as people seek a more open and self-owned internet.\n- Google's recency bias in search results is favoring newer but less relevant content over older, more valuable resources.\n- The decline of the open web is driven by a lack of motivation for individuals to contribute and the bloat and commercialization of centralized platforms.\n- There is hope for a more permanent and public solution with federated systems like Mastodon and the creation of a directory of forums divided by interest.\n- The open web offers a broader range of perspectives and content, whereas platforms like Reddit can become homogeneous and biased.\n- The shift from blogs and forums to platforms like Reddit has limited the discoverability of specialized and niche content.\n- Search engines like Google should prioritize authentic and valuable content over SEO spam and low-quality articles.\n- The open web requires moderation, collaboration, and engagement from individuals to thrive.\n- Many of the older resources on the web are still valid and valuable, but recency bias and SEO spam often hide them from search results.\n- Platforms like YouTube and Discord have replaced blogs and forums, leading to the loss of valuable, searchable content.\n- Content generators need to find a balance between the effort required to run a website and the engagement and visibility they can achieve.\n- The open web enables unbiased, personal, and first-hand experiences, unlike sponsored and generic content found on blogs.\n- The search landscape is dominated by a few major companies like Google, which prioritize their own interests over user satisfaction.\n- Open-content sites like Wikipedia and StackOverflow provide valuable information, but there is potential for more non-profit, open platforms.\n- Running a website can be lonely without guaranteed engagement, but comment sections and multiple authors can help foster a sense of community.\n- Crypto and cryptographic solutions could ensure proof of authorship and enable the revocation of content to address privacy concerns.\n- The open web has its challenges, but there is still hope for its revival through community engagement and a focus on quality and authenticity.",
    "hn_summary": "- The open internet is becoming centralized, with platforms like Reddit dominating the space.\n- The lack of searchability in platforms like Discord hinders the preservation and discoverability of valuable information.\n- The shift from blogs and forums to platforms like Reddit has limited the discoverability of specialized and niche content."
  },
  {
    "id": 36330972,
    "timestamp": 1686769663,
    "title": "Native JSON Output from GPT-4",
    "url": "https://yonom.substack.com/p/native-json-output-from-gpt-4",
    "hn_url": "http://news.ycombinator.com/item?id=36330972",
    "content": "Native JSON Output From GPT-4SIMON FARSHIDJUN 14, 20231110When integrating LLMs in your products, you often want to generate structured data, like JSONs. With the help of function calling (released June 13th 2023), this process has become much simpler! In this post I will explore the new API.Function CallingFunction calling allows GPT to call a function instead of returning a string. At the time of writing, this feature is available for the chat models gpt-3.5-turbo-0613 and gpt-4-0613.For this feature, two new parameters have been introduced in the Chat Completions API:functions: An array of functions available to GPT, each with a name, description and a JSON Schema of the parameters.function_call: You can optionally specify none or { \"name\": \"<function_name>\" }. You can force GPT to use a specific function (or explicitly forbid calling any functions)I realized that by setting the function_call parameter, you can reliably expect JSON as responses from GPT calls. No more strings, yay!Lets see it in action with a demo app, Recipe Creator.Recipe CreatorRecipe Creator is an app where the user inputs the name of a dish and is provided with instructions on how to cook it. Of course, it can be used to generate recipes for completely fictional dishes; if you can name it, there\u2019s a recipe for it!Our frontend developer has asked us to create a backend API which returns a JSON like this one:{ \"ingredients\": [  { \"name\": \"Ingredient 1\", \"amount\": 5, \"unit\": \"grams\" },  { \"name\": \"Ingredient 2\", \"amount\": 1, \"unit\": \"cup\" }, ], \"instructions\": [  \"Do step 1\",  \"Do step 2\" ], \"time_to_cook\": 5 // minutes}Let\u2019s get started.JSON SchemaFirst, let\u2019s create a JSON schema based on the example dataset.schema = { \"type\": \"object\", \"properties\": {  \"ingredients\": {   \"type\": \"array\",   \"items\": {    \"type\": \"object\",    \"properties\": {     \"name\": { \"type\": \"string\" },     \"unit\": {       \"type\": \"string\",      \"enum\": [\"grams\", \"ml\", \"cups\", \"pieces\", \"teaspoons\"]     },     \"amount\": { \"type\": \"number\" }    },    \"required\": [\"name\", \"unit\", \"amount\"]   }  },  \"instructions\": {   \"type\": \"array\",   \"description\": \"Steps to prepare the recipe (no numbering)\",   \"items\": { \"type\": \"string\" }  },  \"time_to_cook\": {   \"type\": \"number\",   \"description\": \"Total time to prepare the recipe in minutes\"  } }, \"required\": [\"ingredients\", \"instructions\", \"time_to_cook\"]}API callNow, let\u2019s call the OpenAI API and pass the JSON schema defined above:import osimport openaiopenai.api_key = os.getenv(\"OPENAI_API_KEY\")completion = openai.ChatCompletion.create( model=\"gpt-4-0613\", messages=[  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  {\"role\": \"user\", \"content\": \"Provide a recipe for spaghetti bolognese\"} ], functions=[{\"name\": \"set_recipe\", \"parameters\": schema}], function_call={\"name\": \"set_recipe\"}, temperature=0,)print(completion.choices[0].message.function_call.arguments)Here\u2019s the result of running the above code: recipe for spaghetti bolognese{ \"ingredients\":[  {\"name\": \"spaghetti\", \"unit\": \"grams\", \"amount\": 400},  {\"name\": \"ground beef\", \"unit\": \"grams\", \"amount\": 500},  {\"name\": \"onion\", \"unit\": \"pieces\", \"amount\": 1},  {\"name\": \"garlic cloves\", \"unit\": \"pieces\", \"amount\": 2},  {\"name\": \"carrot\", \"unit\": \"pieces\", \"amount\": 1},  {\"name\": \"celery stalk\", \"unit\": \"pieces\", \"amount\": 1},  {\"name\": \"canned tomatoes\", \"unit\": \"grams\", \"amount\": 400},  {\"name\": \"red wine\", \"unit\": \"ml\", \"amount\": 125},  {\"name\": \"olive oil\", \"unit\": \"ml\", \"amount\": 30},  {\"name\": \"salt\", \"unit\": \"teaspoons\", \"amount\": 1},  {\"name\": \"pepper\", \"unit\": \"teaspoons\", \"amount\": 1} ], \"instructions\": [  \"Heat the olive oil in a large pan over medium heat. Add the finely chopped onion, carrot, celery, and minced garlic and cook until softened.\",  \"Add the ground beef to the pan and cook until browned.\",  \"Pour in the red wine and let it simmer until the alcohol has evaporated.\",  \"Add the canned tomatoes, salt, and pepper. Reduce the heat to low, cover the pan, and let it simmer for about 1 hour, stirring occasionally.\",  \"In the meantime, cook the spaghetti in a large pot of boiling salted water according to the package instructions until al dente.\",  \"Drain the spaghetti and add it to the pan with the Bolognese sauce. Toss well to combine.\",  \"Serve the Spaghetti Bolognese with a sprinkle of freshly grated Parmesan cheese on top.\" ], \"time_to_cook\": 90}Perfect! \ud83e\uddd1\u200d\ud83c\udf73ImplicationsI believe the new API will change the way we interact with OpenAI LLMs beyond the obvious use-case of plugins.This is different than prompt engineeringYou could already generate JSON output with the help of prompt engineering: You put some json examples as part of GPT\u2019s context window and ask it to generate a new one (few shot prompting).This approach works well for simple cases but is prone to errors. GPT makes simple mistakes (like missing commas, unescaped line breaks) and sometimes gets completely derailed. You can also intentionally derail GPT with prompt injection.This means that you need to defensively parse the output of GPT in order to salvage as much usable information as possible. Libraries like Langchain or llmparser help in this process, but come with their own limitations and boilerplate code.With lower level access to the large language model, you can do much better. I don\u2019t have access to GPT4\u2019s source, but I assume OpenAI\u2019s implementation works conceptually similar to jsonformer, where the token selection algorithm is changed from \u201cchoose the token with the highest logit\u201d to \u201cchoose the token with the highest logit which is valid for the schema\u201d.This means that the burden of following the specific schema is lifted from GPT and instead embedded into the token generation process. Lower token usageThe example above used 136 prompt tokens and 538 completion tokens (Costing $ 0.036 for GPT4 or $ 0.0013 for GPT 3.5).If you were to use few-shot learning to get the same results, you would have needed more prompt tokens for the same task.Lower token usage means faster and cheaper API calls.Less cognitive load on GPTThe more things you ask of GPT at the same time, the more likely it is to make mistakes or hallucinations.By removing the instructions of following a specific JSON format from your prompts, you simplify the task for GPT.My intuition is that this increases the likelihood of success, meaning that your accuracy should go up.Furthermore, you might be able to downgrade to a smaller GPT model in places where the JSON complexity made it otherwise infeasible, and gain speed and cost reduction benefits.Natural language to structured dataI was surprised by the little amount of code needed to build the recipe example. Doing something like this used to take far more boilerplate code in my previous attempts without function calling.It is very cool that you can \u201ccode\u201d an \u201cintelligent\u201d backend API in natural language. You can build such an API in a few hours.LLMs as backendsWhile most examples from OpenAI present functions as a step towards the goal of answering the user\u2019s query in a chat context (plugins); the recipe example here shows that you can use functions as a final target.An example could be Excel allowing users to define new buttons for the toolbar by explaining the buttons functionality in plaintext. The prompt gets fed to GPT and the response is coerced to be a valid Excel API call.Another example would be no-code prototyping tools, which could leverage LLMs to let their users define button functionality.The fact that you no longer need prompt engineering to generate correct output makes it easier to use LLMs as no-code backends.Running an LLM every time someone clicks on a button is expensive and slow in production, but probably still ~10x cheaper to produce than code, and accessible to larger groups of people.Thought processes as JSON SchemaYou can do Chain of Thought Prompting or even implement ReAct as part of the JSON schema (GPT seems to respect the definition order of object properties).OpenAI\u2019s API seems to support JSON Schema features like #ref (recursion) and oneOf (multiple choice); meaning that you should be able to implement more complex agents and recursive thought processes via JSON schema in a single API request (as long as it fits in the context window).This means that you can embed complex strategies into a single API call which makes your agents run faster and consume fewer tokens (since you don\u2019t pass the same context across multiple API calls).Not every JSON Schema feature is supported (if/else seems to be ignored, as are consts), but I do wonder if the supported features are enough to turn the schema language into a turing-complete one.11 Likes1110",
    "summary": "- OpenAI has released a new feature called function calling for their GPT models, which allows them to call a function and return JSON data instead of just a string.\n- This feature is currently available for the chat models gpt-3.5-turbo-0613 and gpt-4-0613.\n- A demo app called Recipe Creator showcases how this new feature can be used to generate JSON responses for providing instructions on cooking dishes.\n- By using a JSON schema, developers can define the structure of the JSON data they want to receive from the GPT model.\n- This new feature reduces the need for prompt engineering and makes it easier to generate correct JSON output.\n- It also allows for the possibility of using GPT models as intelligent backend APIs for applications and no-code prototyping tools.\n- The JSON schema can be used to implement more complex agents and thought processes in a single API call.\n- OpenAI's API supports various JSON Schema features, allowing for the creation of more sophisticated and efficient agents.\n- While not all JSON Schema features are supported, the ones that are enable developers to embed complex strategies into a single API call.",
    "hn_title": "Native JSON Output from GPT-4",
    "original_title": "Native JSON Output from GPT-4",
    "score": 416,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginNative JSON Output from GPT-4 (yonom.substack.com)416 points by yonom 9 hours ago | hide | past | favorite | 204 commentsdanShumway 1 hour ago | next [\u2013]I'm concerned that OpenAI's example documentation suggests using this to A) construct SQL queries and B) summarize emails, but that their example code doesn't include clear hooks for human validation before actions are called.For a recipe builder it's not so big a deal, but I really worry how eager people are to remove human review from these steps. It gets rid of a very important mechanism for reducing the risks of prompt injection.The top comment here suggests wiring this up to allow GPT-4 to recursively call itself. Meanwhile, some of the best advice I've seen from security professionals on secure LLM app development is to whenever possible completely isolate queries from each other to reduce the potential damage that a compromised agent can do before its \"memory\" is wiped.There are definitely ways to use this safely, and there are definitely some pretty powerful apps you could build on top of this without much risk. LLMs as a transformation layer for trusted input is a good use-case. But are devs going to stick with that? Is it going to be used safely? Do devs understand any of the risks or how to mitigate them in the first place?3rd-party plugins on ChatGPT have repeatedly been vulnerable in the real world, I'm worried about what mistakes developers are going to make now that they're actively encouraged to treat GPT as even more of a low-level data layer. Especially since OpenAI's documentation on how to build secure apps is mostly pretty bad, and they don't seem to be spending much time or effort educating developers/partners on how to approach LLM security.replyabhibeckert 1 hour ago | parent | next [\u2013]In my opinion the only way to use it safely is to ensure your AI only has access to data that the end user already has access to.At that point, prompt injection is no-longer an issue - because the AI doesn't need to hide anything.Giving GPT access to your entire database, but telling it not to reveal certain bits, is never going to work. There will always be side channel vulnerabilities in those systems.replydanShumway 1 hour ago | root | parent | next [\u2013]> e.g. define a function called extract_data(name: string, birthday: string), or sql_query(query: string)This section in OpenAI's product announcement really irritates me because it's so obvious that the model should have access to a subset of API calls that themselves fetch the data, as opposed to giving the model raw access to SQL. You could have the same capabilities while eliminating a huge amount of risk. And OpenAI just sticks this right in the announcement, they're encouraging it.When I'm building a completely isolated backend with just regular code, I still usually put a data access layer in front of the database in most cases. I still don't want my REST endpoints directly building SQL queries or directly accessing the database, and that's without an LLM in the loop at all. It's just safer.It's the same idea as using `innerHTML`; in general it's better when possible to have those kinds of calls extremely isolated and to go through functions that constrain what can go wrong. But no, OpenAI just straight up telling developers to do the wrong things and to give GPT unrestricted database access.replyBoorishBears 25 minutes ago | root | parent | next [\u2013]You don't need to directly run the query it returns, you can use that query as a sub-query on a known safe set of data and let it fail if someone manages to prompt inject their way into looking at other tables/columns.That way you can support natural language to query without sending dozens of functions (which will eat up the context window)replysillysaurusx 1 hour ago | parent | prev | next [\u2013]I was going to say \u201cI look forward to it and think it\u2019s hilarious,\u201d but then I remembered that most victims will be people learning to code, not companies. It would really suck to suddenly lose your recipe database when you just wanted to figure out how this programming stuff worked.Some kind of \u201cheads up\u201d tagline is probably a good idea, yeah.replyswyx 8 hours ago | prev | next [\u2013]i think people are underestimating the potential here for agents building - it is now a lot easier for GPT4 to call other models, or itself. while i was taking notes for our emergency pod yesterday (https://www.latent.space/p/function-agents) we had this interesting debate with Simon Willison on just how many functions will be supplied to this API. Simon thinks it will be \"deep\" rather than \"wide\" - eg a few functions that do many things, rather than many functions that do few things. I think i agree.you can now trivially make GPT4 decide whether to call itself again, or to proceed to the next stage. it feels like the first XOR circuit from which we can compose a \"transistor\", from which we can compose a new kind of CPU.replyquickthrower2 13 minutes ago | parent | next [\u2013]The first transistors were slow, and it seems this \"GPT3/4 calling itself\" stuff is quite slow. GPT3/4 as a direct chat is about as slow as I can take. Once this gets sped up.I am sure it will, as you can scale out, scale up and build more efficient code and build more efficient architectures and \"tool for the job\" different parts of the process.The problem now (using auto gpt, for example) is accuracy is bad, so you need human feedback and intervention AND it is slow. Take away the slow, or the needing human intervention and this can be very powerful.I dream of the breakthrough \"shitty old laptop is all you need\" paper where they figure out how to do amazing stuff with a 1Gb of space on a spinny disk and 1Gb RAM and a CPU.replyjonplackett 7 hours ago | parent | prev | next [\u2013]It was already quite easy to get GPT-4 to output json. You just append \u2018reply in json with this format\u2019 and it does a really good job.GPT-3.5 was very haphazard though and needs extensive babysitting and reminding, so if this makes gpt3 better then it\u2019s useful - it does have an annoying disclaimer though that \u2018it may not reply with valid json\u2019 so we\u2019ll still have to do some sense checks into he output.I have been using this to make a few \u2018choose your own adventure\u2019 type games and I can see there\u2019s a TONNE of potential useful things.replysheepscreek 3 hours ago | root | parent | next [\u2013]The solution that worked great for me - do not use JSON for GPT to agent communication. Use comma separated key=value, or something to that effect.Then have another pure code layer to parse that into structured JSON.I think it\u2019s the JSON syntax (with curly braces) that does it in. So YAML or TOML might work just as well, but I haven\u2019t tried that.replyjacobsimon 2 hours ago | root | parent | next [\u2013]Coincidentally, I just published this JS library[1] over the weekend that helps prompt LLMs to return typed JSON data and validates it for you. Would love feedback on it if this is something people here are interested in. Haven\u2019t played around with the new API yet but I think this is super exciting stuff![1] https://github.com/jacobsimon/promptingreplybombela 2 hours ago | root | parent | prev | next [\u2013]It's harder to form a tree with key value. I also tried the relational route. But it would always messup the cardinality (one person should have 0 or n friends, but a person has a single birth date).replyrubyskills 1 hour ago | root | parent | next [\u2013]It's also harder to stream JSON? Maybe I'm overthinking this.replyignite 6 hours ago | root | parent | prev | next [\u2013]> You just append \u2018reply in json with this format\u2019 and it does a really good job.It does an ok job. Except when it doesn't. Definitely misses a lot of the time, sometimes on prompts that succeeded on previous runs.replybel423 4 hours ago | root | parent | next [\u2013]It literally does it everytime perfectly. I remember I put together an entire system that would validate the JSON against a zod schema and use reflection to fix it and it literally never gets triggered because GPT3.5-turbo always does it right the first time.replythomasfromcdnjs 3 hours ago | root | parent | next [\u2013]Are you saying that it return only JSON before? I'm with the other commenters it was wildly variable and always at least said \"Here is your response\" which doesn't parse well.replytravisjungroth 2 hours ago | root | parent | next [\u2013]If you want a parsable response, have it wrap that with ```. Include an example request/response in your history. Treat any message you can\u2019t parse as an error message.This works well because it has a place to put any \u201ckeep in mind\u201d noise. You can actually include that in your example.replywhateveracct 3 hours ago | root | parent | prev | next [\u2013]No it doesn't lol. I've seen it just randomly not use a comma after one array element, for example.replyLanceJones 5 minutes ago | root | parent | next [\u2013]Yep. Incorrect trailing commas ad nauseum for me.worik 3 hours ago | root | parent | prev | next [\u2013]> It literally does it everytime perfectly. I remember I put together an entire system that would validate the JSON against a zod schema and use reflection to fix it and it literally never gets triggered because GPT3.5-turbo always does it right the first time.Danger! There be assumptions!!gpt-? is a moving target and in rapid development. What it does Tuesday, which it did not do on Monday, it may well not do on WednesdayIf there is a documented method to guarantee it, it will work that way (modulo OpenAI bugs - and now Microsoft is involved....)What we had before, what you are talking of, was observed behaviour. An assumption that what we observed in the past will continue in the future is not something to build a business onreplytravisjungroth 2 hours ago | root | parent | next [\u2013]ChatGPT moves fast. The API version doesn\u2019t seem to change except with the model and documented API changes.replylmeyerov 2 hours ago | root | parent | prev | next [\u2013]Yeah noreplycwxm 7 hours ago | root | parent | prev | next [\u2013]even with gpt 4, it hallucinates enough that it\u2019s not reliable, forgetting to open/close brackets and quotes. This sounds like it\u2019d be a big improvement.replyjonplackett 6 hours ago | root | parent | next [\u2013]Not that it matters now but just doing something like this works 99% of the time or more with 4 and 90% with 3.5.It is VERY IMPORTANT that you respond in valid JSON ONLY. Nothing before or after. Make sure to escape all strings. Use this format:{\u201csome_variable\u201d: [describe the variable purpose]}replySamPatt 6 hours ago | root | parent | next [\u2013]99% of the time is still super frustrating when it fails, if you're using it in a consumer facing app. You have to clean up the output to avoid getting an error. If it goes from 99% to 100% JSON that is a big deal for me, much simpler.replyjonplackett 6 hours ago | root | parent | next [\u2013]Except it says in the small print to expect invalid JSON occasionally, so you have to write your error handling code either wayreplydavepeck 5 hours ago | root | parent | prev | next [\u2013]Yup. Is there a good/forgiving \"drunken JSON parser\" library that people like to use? Feels like it would be a useful (and separable) piece?replygolol 5 hours ago | root | parent | next [\u2013]Honestly, I suspect asking GPT-4 to fix your JSON (in a new chat) is a good drunken JSON parser. We are only scraping the surface of what's possible with LLMs. If Token generation was free and instant we could come up with a giant schema of interacting model calls that generates 10 suggestions, iterates over them, ranks them and picks the best one, as silly as it sounds.replyhhh 5 hours ago | root | parent | next [\u2013]I already do this today to create domain-specific knowledge focused prompts and then have them iterate back and forth and a \u2018moderator\u2019 that chooses what goes in and what doesn\u2019t.reply8organicbits 5 hours ago | root | parent | prev | next [\u2013]Wouldn't you use traditional software to validate the JSON, then ask chatgpt to try again if it wasn't right?replygirvo 4 hours ago | root | parent | next [\u2013]In my experience, telling it \"no thats wrong, try again\" just gets it to be wrong in a new different way, or restate the same wrong answer slightly differently. I've had to explicitly guide it to correct answers or formats at times.replycjbprime 21 minutes ago | root | parent | next [\u2013]Try different phrasing, like \"Did your answer follow all of the criteria?\".replywhateveracct 3 hours ago | root | parent | prev | next [\u2013]It forgets commas tooreplyztratar 7 hours ago | root | parent | prev | next [\u2013]Nah, this was solved by most teams a while ago.replybel423 4 hours ago | root | parent | next [\u2013]I feel like I\u2019m taking crazy pills with the amount of people saying this is game changing.Did they not even try asking gpt to format the output as json?replyworik 3 hours ago | root | parent | next [\u2013]> I feel like I\u2019m taking crazy pills....try asking gpt to format the output as jsonYou are taking crazey pills. Stopgpt-? is unreliable! That is not a bug in it, it is the nature of the beast.It is not an expert at anything except natural language, and even then it is an idiot savantreplysethd 4 hours ago | root | parent | prev | next [\u2013]I like to define a JSON schema (https://json-schema.org/) and prompt GPT-4 to output JSON based on that schema.This lets me specify general requirements (not just JSON structure) inline with the schema and in a very detailed and structured manor.replymuzani 3 hours ago | root | parent | prev | next [\u2013]It's fine, but the article makes some good points why - less cognitive load for GPT and less tokens. I think the transistor to logic gate analogy makes sense. You can build the thing perfectly with transistors, but just use the logic gate lol.replyseizethecheese 4 hours ago | root | parent | prev | next [\u2013]In a production system, you don\u2019t need easy to do most of the time, you need easy without fail.replypnpnp 4 hours ago | root | parent | next [\u2013]Ok, just playing devil's advocate here. How many FAANG companies have you seen have an outage this year? What's their budget?I think a better way to reply to the author would have been \"how often does it fail\"?Every system will have outages, it's just a matter of how much money you can throw at the problem to reduce them.replyjrockway 4 hours ago | root | parent | next [\u2013]If 99.995% correct looks bad to users, wait until they see 37%.replythrowuwu 2 hours ago | root | parent | prev | next [\u2013]Just end your request with\u2018\u2019\u2019jsonOr provide a few examples of user request and then agent response in json. Or both.replyclbrmbr 2 hours ago | root | parent | next [\u2013]Does the ```json trick work with the chat models? Or only the earlier completion models?replythrowuwu 2 hours ago | root | parent | next [\u2013]Works with chat. They\u2019re still text completion models under all that rlhfreplyreallymental 6 hours ago | root | parent | prev | next [\u2013]Is there any publicly available resource replicate your work? I would love to just find the right kind of \"incantation\" for the gpt-3.5-t or gpt-4 to output a meaningful story arc etc.Any examples of your work would be greatly helpful as well!replydevbent 2 hours ago | root | parent | next [\u2013]I have an open source project doing exactly this at https://www.generativestorytelling.ai/ GitHub link is on the main page!replySamPatt 6 hours ago | root | parent | prev | next [\u2013]I'm not the person you're asking, but I built a site that allows you to generate fiction if you have an OpenAI API key. You can see the prompts sent in console, and it's all open source:https://havewords.ai/replybradly 7 hours ago | root | parent | prev | next [\u2013]I could not get GPT-4 to reliably not give some sort of text response, even if was just a simple \"Sure\" followed by the JSON.replyavereveard 2 hours ago | root | parent | next [\u2013]Pass in an agent message with \"Sure here is the answer in json format:\" after the user message. Gpt will think it has already done the preamble and the rest of the message will start right with the json.replyrytill 6 hours ago | root | parent | prev | next [\u2013]Did you try using the API and providing a very clear system message followed by several examples that were pure JSON?replybradly 5 hours ago | root | parent | next [\u2013]Yep. I even gave it a JSON schema file to use. It just wouldn't stop added extra verbage.replytaylorfinley 4 hours ago | root | parent | next [\u2013]I just use a regex to select everything between the first and last curly bracket, reliable fixes the \u201csure, here\u2019s your object\u201d problem.replyNicoJuicy 4 hours ago | root | parent | prev | next [\u2013]Say it's a json API and may only reply with valid json without explanation.replybradly 4 hours ago | root | parent | next [\u2013]Lol yes of course I tried that.replydror 3 hours ago | root | parent | next [\u2013]I've had good luck with both:https://github.com/drorm/gish/blob/main/tasks/coding.txtandhttps://github.com/drorm/gish/blob/main/tasks/webapp.txtWith the second one, I reliably generated half a dozen apps with one command.Not to say that it won't fail sometimes.replymajormajor 8 hours ago | parent | prev | next [\u2013]GPT-4 was already a massive improvement on 3.5 in terms of replying consistently in a certain JSON structure - I often don't even need to give examples, just a sentence describing the format.It's great to see they're making it even better, but where I'm currently hitting the limit still in GPT-4 for \"shelling out\" is about it being truly \"creative\" or \"introspective\" about \"do I need to ask for clarifications\" or \"can I find a truly novel away around this task\" type of things vs \"here's a possible but half-baked sequence I'm going to follow\".replyfumar 4 hours ago | root | parent | next [\u2013]It is \u201cgood enough\u201d. Where I struggle is maintaining its memory through a longer request where multiple iterations fail or succeed and then all of a sudden its memory is exceeded and starts fresh. I wish I could store \u201clearnings\u201d that it could revisit.replyehsanu1 3 hours ago | root | parent | next [\u2013]Sounds like you want something like tree of thoughts: https://arxiv.org/abs/2305.10601replylbeurerkellner 7 hours ago | parent | prev | next [\u2013]It's interesting to think about this form of computation (LLM + function call) in terms of circuitry. It is still unclear to me however, if the sequential form of reasoning imposed by a sequence of chat messages is the right model here. LLM decoding and also more high-level \"reasoning algorithms\" like tree of thought are not that linear.Ever since we started working on LMQL, the overarching vision all along was to get to a form of language model programming, where LLM calls are just the smallest primitive of the \"text computer\" you are running on. It will be interesting to see what kind of patterns emerge, now that the smallest primitive becomes more robust and reliable, at least in terms of the interface.replyminimaxir 8 hours ago | parent | prev | next [\u2013]\"Trivial\" is misleading. From OpenAI's docs and demos, the full ReAct workflow is an order of magnitude more difficult than typical ChatGPT API usage with a new set of constaints (e.g. schema definitions)Even OpenAI's notebook demo has error handling workflows which was actually necessary since ChatGPT returned incorrect formatted output.replycjonas 7 hours ago | root | parent | next [\u2013]Maybe trivial isn't the right word, but it's still very straight-forward to get something basic, yet really powerful...ReAct Setup Prompt (goal + available actions) -> Agent \"ReAction\" -> Parse & Execute Action -> Send Action Response (success or error) -> Agent \"ReAction\" -> repeatAs long as each action has proper validation and returns meaningful error messages, you don't need to even change the control flow. The agent will typically understand what went wrong, and attempt to correct it in the next \"ReAction\".I've been refactoring some agents to use \"functions\" and so far it seems to be a HUGE improvement in reliability vs the \"Return JSON matching this format\" approach. Most impactful is that fact that \"3.5-turbo\" will now reliability return JSON (before you'd be forced to use GPT-4 for an ReAct style agent of modest complexity).My agents also seem to be better at following other instructions now that the noise of the response format is gone (of course it's still there, but in a way it has been specifically trained on). This could also just be a result of the improvements to the system prompt though.replydevbent 2 hours ago | root | parent | next [\u2013]For 3.5, I found it easiest to specify a simple, but parsable, format for responses and then convert that to JSON myself.I'll have to see if the new JSON schema support is easier than what I already have in place.replyjarulraj 2 hours ago | parent | prev | next [\u2013]Interesting observation, @swyx. There seems to be a connection to transitive closure in SQL queries, where the output of the query is fed as the input to the query in the next iteration [1]. We are thinking about how to best support such recursive functions in EvaDB [2].[1] http://dwhoman.com/blog/sql-transitive-closure.html [2] https://evadb.readthedocs.io/en/stable/source/tutorials/11-s...replyboringuser2 3 hours ago | parent | prev | next [\u2013]Do you people always have to overhype this shit?replythrowuwu 2 hours ago | root | parent | next [\u2013]What\u2019s your problem? There\u2019s nothing overhyped about that comment. People, including me, are building complex agents that can execute multi stage prompts and perform complex tasks. Comparing these first models to a basic unit of logic is more than fair given how much more capable they are. Do you just have an axe to grind?replydelhanty 1 hour ago | root | parent | prev | next [\u2013]Do you have to be nasty?That's a person you're replying to with feelings, so why not default to being kind in comments as per HN guidelines?As it happens, swyx has built notable AI related things, for example smol-developerhttps://twitter.com/swyx/status/1657892220492738560and it would be nice to be able to read his and other perspectives without having to read shallow, mean, dismissive replies such as yours.replyftxbro 7 hours ago | parent | prev | next [\u2013]> \"you can now trivially make GPT4 decide whether to call itself again, or to proceed to the next stage.\"Does this mean the GPT-4 API is now publicly available, or is there still a waitlist? If there's a waitlist and you literally are not allowed to use it no matter how much you are willing to pay then it seems like it's hard to call that trivial.replyTostino 7 hours ago | root | parent | next [\u2013]Not GP, but it's still the latter...i've been (im)patiently waiting.From their blog post the other day: With these updates, we\u2019ll be inviting many more people from the waitlist to try GPT-4 over the coming weeks, with the intent to remove the waitlist entirely with this model. Thank you to everyone who has been patiently waiting, we are excited to see what you build with GPT-4!replylondons_explore 6 hours ago | root | parent | next [\u2013]If you put contact info in your HN profile - especially an email address that matches one you use to login to openai, someone will probably give you access...Anyone with access can share it with any other user via the 'invite to organisation' feature. Obviously that allows the invited person do requests billed to the inviter, but since most experiments are only a few cents that doesn't really matter much in practice.replyTostino 5 hours ago | root | parent | next [\u2013]Good to know, but I've racked up a decent bill for just my GPT 3.5 use. I can get by with experiments using my ChatGPT Plus subscription, but I really need my own API access to start using it for anything serious.replybayesianbot 7 hours ago | root | parent | prev | next [\u2013]\"With these updates, we\u2019ll be inviting many more people from the waitlist to try GPT-4 over the coming weeks, with the intent to remove the waitlist entirely with this model. Thank you to everyone who has been patiently waiting, we are excited to see what you build with GPT-4!\"https://openai.com/blog/function-calling-and-other-api-updat...replyilaksh 7 hours ago | parent | prev | next [\u2013]The thing is the relevant context often depends on what it's trying to do. You can give it a lot of context in 16k but if there are too many different types of things then I think it will be confused or at least have less capacity for the actual selected task.So what I am thinking is that some functions might just be like gateways into a second menu level. So instead of just edit_file with the filename and new source, maybe only select_files_for_edit is available at the top level. In that case I can ensure it doesn't try to overwrite an existing file without important stuff that was already in there, by providing the requested files existing contents along with the function allowing the file edit.replythrowuwu 2 hours ago | root | parent | next [\u2013]Not sure that\u2019s true. I haven\u2019t completely filled the context with examples but I do provide 8 or so exchanges between user and assistant along with a menu of available commands and it seems to be able to generalize from that very well. No hallucinations either. Good idea about sub menus though, I\u2019ll have to use that.replynaiv 6 hours ago | root | parent | prev | next [\u2013]I think big context only makes sense for document analysis.For programming you want to keep it slim. Just like you should keep your controllers and classes slim.Also people with 32k access report very very long response times of up to multiple minutes which is not feasible if you only want a smaller change or analysis.replyfreezed88 4 hours ago | parent | prev | next [\u2013]100%, if the API itself can choose to call a function or an LLM, then it's way easier to build any agent loop without extensive prompt engineering + worrying about errors.Tweeted about it here as well: https://twitter.com/jerryjliu0/status/1668994580396621827?s=...replybel423 4 hours ago | root | parent | next [\u2013]You still have to worry about errors. You will probably have to add an error handler function that it can call out to. Otherwise the LLM will hallucinate a valid output regardless of the input. You want it to be able to throw an error and say I could produce the output given this format.replymoneywoes 6 hours ago | parent | prev | next [\u2013]Wow your brand is huge. Crazy growth. i wonder how much these subtle mentions on forums helpreplyTeMPOraL 6 hours ago | root | parent | next [\u2013]They're the only one commenter on HN I noticed keeps writing \"smol\" instead of \"small\", and is associated with projects with \"smol\" in their name. Surely I'm not the only one who missed it being a meme around 2015 or sth., and finds this word/use jarring - and therefore very attention-grabbing? Wonder how much that helps with marketing.This is meant with no negative intentions. It's just that 'swyx was, in my mind, \"that HN-er that does AI and keeps saying 'smol'\" for far longer than I was aware of latent.space articles/podcasts.replymemefrog 4 hours ago | root | parent | next [\u2013]Personally, I associate \"smol\" with \"doggo\" and \"chonker\" and other childish redditspeak.replyswyx 4 hours ago | root | parent | prev | next [\u2013]and fun fact i used to work at Temporal too heheh.replyswyx 4 hours ago | root | parent | prev | next [\u2013]i mean hopefully its relevant content to the discussion, i hope enough pple know me here by now that i fully participate in The Discourse rather than just being here to cynically plug my stuff. i had a 1.5 hr convo with simon willison and other well known AI tinkerers on this exact thing, and so I shared it, making the most out of their time that they chose to share with me.replybabyshake 6 hours ago | parent | prev | next [\u2013]What would be an example where there needs to be an arbitrary level of recursive ability for GPT4 to call itself?replyswyx 3 hours ago | root | parent | next [\u2013]writing code of higher complexity (we know from CICERO that longer time spent on inference is worth orders of magnitude more than the equivalent in training when it comes to improving end performance), or doing real world tasks with unknown fractal depth (aka yak shave)replykillingtime74 4 hours ago | parent | prev | next [\u2013]Who is Simon Willison? Is he big in AI?replyswyx 4 hours ago | root | parent | next [\u2013]formerly cocreator of Django, now Datasette, but pretty much the top writer/hacker on HN making AI topics accessible to engineers https://hn.algolia.com/?dateRange=pastYear&page=0&prefix=tru...replykillingtime74 3 hours ago | root | parent | next [\u2013]Oh wow, nice! Big fan of his workreplyXen9 5 hours ago | prev | next [\u2013]Marvin Minsky was so damn far ahead of his time with Society of Mind.Engineering of cognitively advanced multiagent systems will become the area of research of this century / multiple decades.GPT-GPT > GPT-API in terms of power.The space of possible combinations of GPT multiagents goes beyond imagination since even GPT-4 goes so.Multiagent systems are best modeled with signal theory, graph theory and cognitive science.Of course \"programming\" will also play a role, in sense of abstractions and creation of systems of / for thought.Signal theory will be a significant approach for thinking about embedded agency.Complex multiagent systems approach us.replySanderNL 1 hour ago | parent | next [\u2013]Makes me think of the Freud/Jungian notions of personas in us that are in various degrees semi-autonomously looking out for themselves. The \u201cangry\u201d agent, the \u201cchild\u201d agent, so on.replyminimaxir 9 hours ago | prev | next [\u2013]After reading the docs for the new ChatGPT function calling yesterday, it's structured and/or typed data for GPT input or output that's the key feature of these new models. The ReAct flow of tool selection that it provides is secondary.As this post notes, you don't even need to the full flow of passing a function result back to the model: getting structured data from ChatGPT in itself has a lot of fun and practical use cases. You could coax previous versions of ChatGPT to \"output results as JSON\" with a system prompt but in practice results are mixed, although even with this finetuned model the docs warn that there still could be parsing errors.OpenAI's demo for function calling is not a Hello World, to put it mildly: https://github.com/openai/openai-cookbook/blob/main/examples...replytornato7 9 hours ago | parent | next [\u2013]IIRC, there's a way to \"force\" LLMs to output proper JSON by adding some logic to the top token selection. I.e. in the randomness function (which OpenAI calls temperature) you'd never choose a next token that results in broken JSON. The only reason it wouldn't would be if the output exceeds the token limit. I wonder if OpenAI is doing something like this.replyManuelKiessling 8 hours ago | root | parent | next [\u2013]Note that you don\u2019t necessarily need to have the AI output any JSON at all \u2014 simply have it answer when being asked for the value to a specific JSON key, and handle the JSON structure part in your hallucinations-free own code: https://github.com/manuelkiessling/php-ai-tool-bridgereplylyjackal 1 hour ago | root | parent | next [\u2013]Would be nice if you could send a back and forth interaction for each key. This approach turns into lots of requests that reapply the entire context and ends up slow. I wish i could just send a Microsoft guidance template program, and process that in a single pass.replynaiv 8 hours ago | root | parent | prev | next [\u2013]Thanks for sharing!replysenko 9 hours ago | root | parent | prev | next [\u2013]It would seem not, as the official documentation mentions the arguments may be hallucinated or be a malformed JSON.(except if the meaning is the JSON syntax is valid but may not conform to the schema, but they're unclear on that).replysanxiyn 8 hours ago | root | parent | next [\u2013]For various reasons, token selection may be implemented as upweighting/downweighting instead of outright ban of invalid tokens. (Maybe it helps training?) Then the model could generate malformed JSON. I think it is premature to infer from \"can generate malformed JSON\" that OpenAI is not using token selection restriction.replyttul 2 hours ago | root | parent | prev | next [\u2013]I think the problem is that tokens are not characters. So even if you had access to a JSON parser state that could tell you whether or not a given character is valid as the next character, I am not sure how you would translate that into tokens to apply the logit biases appropriately. There would be a great deal of computation required at each step to scan the parser state and generate the list of prohibited or allowable tokens.But if one could pull this off, it would be super cool. Similar to how Microsoft\u2019s guidance module uses the logit_bias parameter to force the model to choose between a set of available options.replywoodrowbarlow 8 hours ago | root | parent | prev | next [\u2013]the linked article hypothesizes:> I assume OpenAI\u2019s implementation works conceptually similar to jsonformer, where the token selection algorithm is changed from \u201cchoose the token with the highest logit\u201d to \u201cchoose the token with the highest logit which is valid for the schema\u201d.replysanxiyn 9 hours ago | root | parent | prev | next [\u2013]Note that this (token selection restriction) is even available on OpenAI API as logit_bias.replynewhouseb 7 hours ago | root | parent | next [\u2013]But only for the whole generation. So if you want to constrain things one token at a time (as you would to force things to follow a grammar) you have to make fresh calls and only request one token which makes things more or less impractical if you want true guarantees. A few months ago I built this anyway to suss out how much more expensive it was [1][1] https://github.com/newhouseb/clownfish#so-how-do-i-use-this-...replyhave_faith 9 hours ago | root | parent | prev | next [\u2013]How would a tweaked temp enforce a non broken output exactly?replysanxiyn 8 hours ago | root | parent | next [\u2013]It's not temperature, but sampling. Output of LLM is probabilistic distribution over tokens. To get concrete tokens, you sample from that distribution. Unfortunately, OpenAI API does not expose the distribution. You only get the sampled tokens.As an example, on the link JSON schema is defined such that recipe ingredient unit is one of grams/ml/cups/pieces/teaspoons. LLM may output the distribution grams(30%), cups(30%), pounds(40%). Sampling the best token \"pounds\" would generate an invalid document. Instead, you can use the schema to filter tokens and sample from the filtered distribution, which is grams(50%), cups(50%).replyisoprophlex 8 hours ago | root | parent | prev | next [\u2013]Not traditional temperature, maybe the parent worded it somewhat obtusely. Anyway, to disambiguate...I think it works something like this: You let something akin to a json parser run with the output sampler. First token must be either '{' or '['; then if you see [ has the highest probability, you select that. Ignore all other tokens, even those with high probability.Second token must be ... and so on and so on.Guarantee for non-broken (or at least parseable) jsonreplyarbuge 2 hours ago | parent | prev | next [\u2013]They have something closer to a simple Hello World example here:https://platform.openai.com/docs/guides/gpt/function-callingThat example needs a bit of work I think. In Step 3, they're not really using the returned function_name; they're just assuming it's the only function that's been defined, which I guess is equivalent for this simple example with just one function but less instructive. In Step 4, I believe they should also have sent the function definition block again a second time since model calls in the API are memory-less and independent. They didn't, although the model appears to guess what's needed anyway in this case.replybehnamoh 8 hours ago | parent | prev | next [\u2013]What's the implication of this new change for Microsoft Guidance, LMQL, Langchain, etc.? It looks like much of their functionality (controlling model output) just became obsolete. Am I missing something?replylbeurerkellner 7 hours ago | root | parent | next [\u2013]If anything this removes a major roadblock for libraries/languages that want to employ LLM calls as a primitive, no? Although, I fear the vendor lock-in intensifies here, also given how restrictive and specific the Chat API.Either way, as part of the LMQL team, I am actually pretty excited about this, also with respect to what we want to build going forward. This makes language model programming much easier.replykoboll 6 hours ago | root | parent | next [\u2013]`Although, I fear the vendor lock-in intensifies here, also given how restrictive and specific the Chat API.`Eh, would be pretty easy to write a wrapper that takes a functions-like JSON Schema object and interpolates it into a traditional \"You MUST return ONLY JSON in the following format:\" prompt snippet.replylondons_explore 6 hours ago | root | parent | prev | next [\u2013]> Although, I fear the vendor lock-in intensifies here,The openAI API is super simple - any other vendor is free to copy it, and I'm sure many will.replyneuronexmachina 5 hours ago | root | parent | prev | next [\u2013]Langchain added support for `function_call` args yesterday:* https://github.com/hwchase17/langchain/pull/6099/files* https://github.com/hwchase17/langchain/issues/6104IMHO, this should make Langchain much easier and less chaotic to use.replygawi 3 hours ago | root | parent | next [\u2013]It's only been added to the OpenAI interface. Function calling is really useful when used with agents. To include that to agents would require some redesign as the tool instructions should be removed from the prompt templates in favor of function definitions in the API request. The response parsing code would also be affected.I just hope they won't come up with yet another agent type.replyemilsedgh 8 hours ago | prev | next [\u2013]Building agents that use advanced API's was not really practical until now. Things like Langchain's Structured Agents worked somewhat reliably, but due to the massive token count it was so slow, the experience was _never_ going to be useful.Due to this, the performance in which our agent processes results has improved 5-6 times and it does actually do a pretty good job of keeping the schema.One problem that is not resolved yet is that it still hallucinates a lot of attributes. For example we have tool that allows it to create contacts in user's CRM. I ask it to:\"Create contacts for top 3 Barcelona players:.It creates an structure like this\"1. Lionel Messi - Email: lionel.messi@barcelona.com - Phone Number: +1234567890 - Tags: Player, Barcelona2. Gerard Pique - Email: gerard.pique@barcelona.com - Phone Number: +1234567891 - Tags: Player, Barcelona3. Marc-Andre ter Stegen - Email: marc-terstegen@barcelona.com - Phone Number: +1234567892 - Tags: Player, BarcelonaAnd you can see it hallucinated email addresses and phone numbers.replypluijzer 8 hours ago | parent | next [\u2013]ChatGPT can be usefully for many things, but you should really, not use it if you want to retrieve factual data. This might partly be resolved by querying the internet like bing does but purely on the language model side these hallucinations are just an unavoidable part of it.replySpivak 6 hours ago | root | parent | next [\u2013]Yep, it's always always write code / query / function / whatever you need that you would parse and retrieve the data from an external system.reply037 8 hours ago | parent | prev | next [\u2013]I would never rely on an LLM as a source of such information, just as I wouldn't trust the general knowledge of a human being used as a database. Does your workflow include a step for information search? With the new json features, it should be easy to instruct it to perform a search or directly feed it the right pages to parse.replyedwin 8 hours ago | prev | next [\u2013]For those who want to test out the LLM as API idea, we are building a turnkey prompt to API product. Here's Simon's recipe maker deployed in a minute: https://preview.promptjoy.com/apis/1AgCy9 . Public preview to make and test your own API: https://preview.promptjoy.comreplyabhpro 4 hours ago | parent | next [\u2013]This is really cool, I had a similar idea but didn't build it. I was also thinking a user could take these different prompts (I called them tasks) that anyone could create, and then connect them together like a node graph or visual programming interface, with some Chat-GPT middleware that resolves the outputs to inputs.replywonderfuly 1 hour ago | parent | prev | next [\u2013]I own this domain: prompts.run Do you wanna it?replyyonom 7 hours ago | parent | prev | next [\u2013]This is cool! Are you using one-shot learning under the hood with a user provided example?replyedwin 7 hours ago | root | parent | next [\u2013]BTW: Here's a more performant version (fewer tokens) https://preview.promptjoy.com/apis/jNqCA2 that uses a smaller example but will still generate pretty good results.replyedwin 7 hours ago | root | parent | prev | next [\u2013]Thanks. We find few-shot learning to be more effective overall. So we are generating additional examples from the provided example.replythorum 9 hours ago | prev | next [\u2013]The JSON schema not counting toward token usage is huge, that will really help reduce costs.replyyonom 9 hours ago | parent | next [\u2013]I believe functions do count in some way toward the token usage; but it seems to be in a more efficient way than pasting raw JSON schemas into the prompt. Nevertheless, the token usage seems to be far lower than previous alternatives, which is awesome!replyblamy 3 hours ago | parent | prev | next [\u2013]But it does count toward token usage. And they picked JSON schema which is like 6x more verbose than typescript for defining the shape of json.replystavros 8 hours ago | parent | prev | next [\u2013]> Under the hood, functions are injected into the system message in a syntax the model has been trained on. This means functions count against the model's context limit and are billed as input tokens. If running into context limits, we suggest limiting the number of functions or the length of documentation you provide for function parameters.replyminimaxir 9 hours ago | parent | prev | next [\u2013]That is up in the air and needs more testing. Field descriptions, for example, are important but extraneous input that would be tokenized and count in the costs.At the least for ChatGPT, input token costs were cut by 25% so it evens out.reply037 8 hours ago | prev | next [\u2013]I'm wondering if introducing a system message like \"convert the resulting json to yaml and return the yaml only\" would adversely affect the optimization done for these models. The reason is that yaml uses significantly fewer tokens compared to json. For the output, where data type specification or adding comments may not be necessary, this could be beneficial. From my understanding, specifying functions in json now uses fewer tokens, but I believe the response still consumes the usual amount of tokens.replygregw134 18 minutes ago | parent | next [\u2013]That's what I'm doing. I ask ChatGPT to return inline yaml (no wasting tokens on line breaks), then I parse the yaml output into JSON once I receive it. A bit awkward but it cuts costs in half.replylbeurerkellner 7 hours ago | parent | prev | next [\u2013]I think one should not underestimate the impact on downstream performance the output format can have. From a modelling perspective it is unclear whether asking/fine-tuning the model to generate JSON (or YAML) output is really lossless with respect to the raw reasoning powers of the model (e.g. it may perform worse on tasks when asked/trained to always respond in JSON).I am sure they ran tests on this internally, but I wonder what the concrete effects are, especially comparing different output formats like JSON, YAML, different function calling conventions and/or forms of tool discovery.replyrank0 7 hours ago | prev | next [\u2013]OpenAI integration is going to be a goldmine for criminals in the future.Everyone and their momma is gonna start passing poorly validated/sanitized client input to shared sessions of a non-deterministic function.I love the future!replynextworddev 4 hours ago | parent | next [\u2013]In the \u201cfuture\u201d?replyjonplackett 6 hours ago | prev | next [\u2013]This is useful, but for me at least, GPT-4 is unusable because it sometimes takes 30 seconds + to reply to even basic queries.replym3kw9 6 hours ago | parent | next [\u2013]Also the rate limit is pretty bad if you want to release any type of appreplyjiggawatts 3 hours ago | root | parent | next [\u2013]More importantly: there's a waiting list.Also, if you want to use both the ChatGPT web app and the API, you'll be billed for both separately. They really should be unified and billed under a single account. The difference is literally just whether there's a \"web UI\" on top of the API... or not.replym3kw9 7 hours ago | prev | next [\u2013]It works pretty good. You define a few \u201cfunction\u201d and enter a description on what it does, when user prompts, it will understand the prompt and tell you which likely \u201cfunction\u201d to use, which is just the function name. I feel like this is a new way to program, a sort of fuzzy logic type of programmingreplySai_ 5 hours ago | parent | next [\u2013]> fuzzy logicYes and no. While the choice of which function to call is dependent on an llm, ultimately, you control the function itself whose output is deterministic.Even today, given an api, people can choose to call or not call based on some factor. We don\u2019t call this fuzzy logic. E.g., people can decide to sell or buy stock through an api based on some internal calculations - doesn\u2019t make the system \u201cfuzzy\u201d.replym3kw9 5 hours ago | root | parent | next [\u2013]If you feed that result into another io box you may or may not know if that is the correct answer, which may need some sort of error detection. I think this is going to be majority of the use casesreplySai_ 5 hours ago | root | parent | next [\u2013]Hm, I see what you mean. Afaict, only the decision to call or not call a function is up to the model (fuzzy). Once it decides to call the function, it generates mostly correct JSON based on your schema and returns that to you as is (not very fuzzy).It\u2019ll be interesting to test APIs which accept user inputs. Depending on how ChatGPT populates the JSON, the API could be required to understand/interpret/respond to lots of variability in inputs.replym3kw9 5 hours ago | root | parent | next [\u2013]Yeah I\u2019ve tested, you should use the curl example they gave as you can test instantly pasting it into your terminal. The description of the functions is prompt engineering in addition to the original system prompt, need to test the dependency more, it\u2019s so new.replykhazhoux 1 hour ago | prev | next [\u2013]I'm trying to experiment with the API but the response time is always in the 15-25second range. How are people getting any interesting work done with it?I see others on the OpenAPI dev forum complaining about this too, but no resolution.replymritchie712 9 hours ago | prev | next [\u2013]Glad we didn't get to far into adopting something like Guardrails. This sort of kills it's main value prop for OpenAI.https://shreyar.github.io/guardrails/replyswyx 9 hours ago | parent | next [\u2013]i mean only at the most superficial level. she has a ton of other validators that arent superceded (eg SQL is validated by branching the database - we discussed on our pod https://www.latent.space/p/guaranteed-quality-and-structure)replymritchie712 6 hours ago | root | parent | next [\u2013]yeah, listened to the pod (that's how I found out about guardrails!).fair point, I should have said: \"value prop for our use case\"... the thing I was most interested in was how well Guardrails structured output.replyswyx 3 hours ago | root | parent | next [\u2013]haha excellent. i was quite impressed by her and the vision for guardrails. thanks for listening!replyblamy 3 hours ago | parent | prev | next [\u2013]Guardrails is an awesome project and will continue to be even after this.replyBlahah 8 hours ago | parent | prev | next [\u2013]Luckily it's for LLMs, not openaireplycourseofaction 8 hours ago | prev | next [\u2013]Nice to have an endpoint which takes care of this. I've been doing this manually, it's a fairly simple process:* Add \"Output your response in json format, with the fields 'x', which indicates 'x_explanation', 'z', which indicates 'z_explanation' (...)\" etc. GPT-4 does this fairly reliably.* Validate the response, repeat if malformed.* Bam, you've got a json.I wonder if they've implemented this endpoint with validation and carefully crafted prompts on the base model, or if this is specifically fine-tuned.reply037 8 hours ago | parent | next [\u2013]It appears to be fine-tuning:\"These models have been fine-tuned to both detect when a function needs to be called (depending on the user\u2019s input) and to respond with JSON that adheres to the function signature.\"https://openai.com/blog/function-calling-and-other-api-updat...replyloughnane 6 hours ago | prev | next [\u2013]Just this morning I wrote a JSON object. I told GPT to turn it into a schema. I tweaked that and then gave a list of terms for which I wanted GPT to populate the schema accordingly.It worked pretty well without any functions, but I did feel like I was missing something because I was ready to be explicit and there wasn\u2019t any way for me to tell that to GPT.I look forward to trying this out.replyruneb 5 hours ago | prev | next [\u2013]The way openai implemented this is really clever, beyond how neat the plugin architecture is, as it lets them peek one layer inside your internal API surface and can infer what you intend to do with the LLM output. Collecting some good data here.replyswyx 4 hours ago | parent | next [\u2013]huh, i never thought of it that way. i thought openai pinky swears not to train on our data thoreplysmallerfish 7 hours ago | prev | next [\u2013]I will experiment with this at the weekend. Once thing I found useful with supplying a json schema in the prompt was that I could supply inline comments and tell it when to leave a field null, etc. I found that much more reliable than describing these nuances elsewhere in the prompt. Presumably I can't do this with functions, but maybe I'll be able to work around it in the prompt (particularly now that I have more room to play with.)replylasermatts 2 hours ago | prev | next [\u2013]I thought GPT-4 was doing a pretty good job at outputting JSON (for some of the toy problems I've given it like some of my gardening projects.) Interesting to see this hit the very top of HNreplysublinear 5 hours ago | prev | next [\u2013]> The process is simple enough that you can let non-technical people build something like this via a no-code interface. No-code tools can leverage this to let their users define \u201cbackend\u201d functionality.Early prototypes of software can use simple prompts like this one to become interactive. Running an LLM every time someone clicks on a button is expensive and slow in production, but probably still ~10x cheaper to produce than code.Hah wow... no. Definitely not.replysrameshc 3 hours ago | prev | next [\u2013]I've used GCP Vertex AI for a specific task and the prompt was to generate a JSON response with keys specified and it does generate the result as JSON with said keys.replytwelfthnight 1 hour ago | parent | next [\u2013]Issue is that's it's not guaranteed, unlike this new openai feature. Personally, Ive found Vertex AI's json output to be not so great, it often uses single quotes in my experience. But maybe you have figured out the right prompts? I'd be interested what you use if so.replybel423 4 hours ago | prev | next [\u2013]Did people really struggle with getting JSON outputs from GPT4. You can literally do it zero shot by just saying match this typescript type.GPT3.5 would output perfect JSON with a single example.I have no idea why people are talking about this like it\u2019s a new development.replybrolumir 4 hours ago | parent | next [\u2013]Unfortunately, in practice that works only most of the time. At least in our experience (and the article says something similar) sometimes ChatGPT would return something completely different when JSON-formatted response would be expected.replyblamy 3 hours ago | root | parent | next [\u2013]I've been using the same prompts for months and have never seen this happen on 3.5-turbo let alone 4.https://gist.github.com/BLamy/244eec016beb9ad8ed48cf61fd2054...replytornato7 3 hours ago | root | parent | prev | next [\u2013]In my experience if you set the temperature to zero it works 99.9% of the time, and then you can just add retry logic for the remaining 0.1%replychaxor 8 hours ago | prev | next [\u2013]Is there a decent way of converting to a structure with a very constrained vocabulary? For example, given some input text, converting it to something like {\"OID-189\": \"QQID-378\", \"OID-478\":\"QQID-678\"}. Where OID and QQID dictionaries can be e.g. millions of different items defined by a description. The rules for mapping could be essentially what looks closest in semantic space to the descriptions given in a dictionary.I know this should be able to be solvable by local LLMs and bert cosine similarity (it isn't exactly, but it's a start on the idea), but is there a way to do this with decoder models rather than encoder models with other logic?replyjiggawatts 3 hours ago | parent | next [\u2013]You can train custom GPT 3 models, and Azure now has vector database integration for GPT-based models in the cloud. You can feed it the data, and ask it for the embedding lookup, etc...You can also host a vector database yourself and fill it up with the embeddings from the OpenAI GPT 3 API.replyirthomasthomas 8 hours ago | prev | next [\u2013]It's a shame they couldn't use yaml, instead. I compared them and yaml uses about 20% fewer tokens. However, I can understand accuracy, derived from frequency, being more important than token budget.replyAdrienBrault 7 hours ago | parent | next [\u2013]I think YAML actually uses more tokens than JSON without indents, especially with deep data. For example \",\" being a single token makes JSON quite compact.You can compare JSON and YAML on https://platform.openai.com/tokenizerreplynasir 7 hours ago | parent | prev | next [\u2013]Its a lot more straightforward to use JSON programmatically than YAML.replyTeMPOraL 6 hours ago | root | parent | next [\u2013]It really shouldn't be, though. I.e. not unless you're parsing or emitting it ad-hoc, for example by assuming that an expression like: \"{\" + $someKey + \":\" + $someValue + \"}\"produces a valid JSON. It does - sometimes - and then it's indeed easier to work with. It'll also blow up in your face. Using JSON the right way - via a proper parser and serializer - should be identical to using YAML or any other equivalent format.replyriwsky 3 hours ago | root | parent | next [\u2013]Even if the APIs for both were equally simple, modules for manipulating json are way more likely to be available in the stdlib of whatever language you\u2019re using.replyblamy 3 hours ago | parent | prev | next [\u2013]JSON can be minified.replyIshKebab 7 hours ago | parent | prev | next [\u2013]I would imagine JSON is easier for a LLM to understand (and for humans!) because it doesn't rely on indentation and confusing syntax for lists, strings etc.replydang 8 hours ago | prev | next [\u2013]Recent and related:Function calling and other API updates - https://news.ycombinator.com/item?id=36313348 - June 2023 (154 comments)replyminimaxir 8 hours ago | parent | next [4 more]jamesmcintyre 9 hours ago | prev | next [\u2013]In the openai blog post they mention \"Convert \u201cWho are my top ten customers this month?\u201d to an internal API call\" but I'm assuming they mean gpt will respond with structured json (we define via schema in function prompt) that we can use to more easily programatically make that api call?I could be confused but I'm interpreting this function calling as \"a way to define structured input and selection of function and then structured output\" but not the actual ability to send it arbitrary code to execute.Still amazing, just wanting to see if I'm wrong on this.replywilliamcotton 9 hours ago | parent | next [\u2013]This does not execute code!replyjamesmcintyre 8 hours ago | root | parent | next [\u2013]Ok, yea this makes sense. Also for others curious of the flow here's a video walkthrough I just skimmed through: https://www.youtube.com/watch?v=91VVM6MNVlkreplyamolgupta 5 hours ago | prev | next [\u2013]I pass a kotlin data class and ask chatGPT to return json which can be parsed by that class. Reduces errors with date-time parsing and other formatting issues and takes up lesser tokens than the approach in the article.replyandsoitis 1 hour ago | prev | next [\u2013]having gpt-4 as a dependency for your product or business seems... shortsightedreplyimranq 7 hours ago | prev | next [\u2013]Wouldnt this be possible with a solution like Guidance where you have a pre structured JSON format ready to go and all you need is text: https://github.com/microsoft/guidancereplyiamflimflam1 7 hours ago | prev | next [\u2013]It\u2019s pretty interesting how the work they\u2019ve been doing on plugins has fed into this.I suspect that they\u2019ve managed to get a lot of good training data by calling the APIs provided by plugins and detecting when it\u2019s gone wrong from bad request responses.replyKiro 9 hours ago | prev | next [\u2013]Can I use this to make it reliably output code (say JavaScript)? I haven't managed to do it with just prompt engineering as it will still add explanations, apologies and do other unwanted things like splitting the code into two files as markdown.replyminimaxir 8 hours ago | parent | next [\u2013]Here's a demo of some system prompt engineering which resulted in better results for the older ChatGPT: https://github.com/minimaxir/simpleaichat/blob/main/examples...Coincidentially, the new gpt-3.5-turbo-0613 model also has better system prompt guidance: for the demo above and some further prompt tweaking, it's possible to get ChatGPT to output code super reliably.replywilliamcotton 9 hours ago | parent | prev | next [\u2013]Here\u2019s an approach to return just JavaScript:https://github.com/williamcotton/transynthetical-engineThe key is the addition of few-shot exemplars.replysanxiyn 8 hours ago | parent | prev | next [\u2013]Not this, but using the token selection restriction approach, you can let LLM produce output that conforms to arbitrary formal grammar completely reliably. JavaScript, Python, whatever.replyzyang 7 hours ago | prev | next [\u2013]Is it possible to fine-tune with custom data to output JSON?replyedwin 5 hours ago | parent | next [\u2013]That's not the current OpenAI recipe. Their expectation is that your custom data will be retrieved via a function/plugin and then be subsequently processed by a chat model.Only the older completion models (davinci, curie, babbage, ada) are avaialble for fine-tuning.replywskish 7 hours ago | prev | next [\u2013]here is code (with several examples) that takes it a couple steps further by validating the output json and pydantic model and providing feedback to the llm model when it gets either of those wrong:https://github.com/jiggy-ai/pydantic-chatcompletion/blob/mas...replyaecorredor 7 hours ago | prev | next [\u2013]Newbie in machine learning here. It\u2019s crazy that this is the top post just today. I\u2019ve been doing the intro to deep learning course from MIT this week, mainly because I have a ton of JSON files that are already classified, and want to train a model that can generate new JSON data by taking classification tags as input.So naturally this post is exciting. My main unknown right now is figuring out which model to train my data on. An RNN, a GAN, a diffusion model?replyilaksh 7 hours ago | parent | next [\u2013]Did you read the article? To do it with OpenAI you would just put a few output examples in the prompt and then give it a function that takes the class and the output parameters correspond to the JSON format you want, or just a string containing JSON.You could also fine tuned an LLM like Falcon-7b but probably not necessary and nothing to do with OpenAI.You might also look into the OpenAI Embedding API as a third option.I would try the first option though.replydarepublic 8 hours ago | prev | next [\u2013]I have been using gpt4 to translate natural language to JSON already. And on v4 ( not v3) it hasn't returned any malformed JSON iircreplyyonom 7 hours ago | parent | next [\u2013]- if the only reason you're using v4 over v3.5 is to generate JSON, you can now use this API and downgrade for faster and cheaper API calls. - malicious user input may break your json (by asking GPT to include comments around the JSON, as another user suggested); this may or may not be an issue (e. g. if one user can influence other users' experience)replynocsi 8 hours ago | parent | prev | next [\u2013]What if you ask it to include comments in the JSON explaining its choicesreplyadultSwim 8 hours ago | prev | next [\u2013]Running an LLM every time someone clicks on a button is expensive and slow in production, but probably still ~10x cheaper to produce than code.replyedwin 7 hours ago | parent | next [\u2013]New techniques like semantic caching will help. This is the modern era's version of building a performant social graph.replydaralthus 7 hours ago | root | parent | next [\u2013]What's semantic caching?replyedwin 6 hours ago | root | parent | next [\u2013]With LLMs, the inputs are highly variable so exact match caching is generally less useful. Semantic caching groups similar inputs and returns relevant results accordingly. So {\"dish\":\"spaghetti bolognese\"} and {\"dish\":\"spaghetti with meat sauce\"} could return the same cached result.replym3kw9 6 hours ago | root | parent | next [\u2013]Or store as sentence embedding and calculate the vector distance, but creates many edge casesreplycoding123 5 hours ago | prev | next [\u2013]We're not far from writing a bunch of stubs, query GPT at startup to resolve the business logic. I guess we're going to need a new JAX-RS soon.replyEGreg 8 hours ago | prev [\u2013]Actually I'm looking to take GPT-4 output and create file formats like keynote presentations, or pptx. Is that currently possible with some tools?replyyonom 7 hours ago | parent | next [\u2013]I would recommend creating a simplified JSON schema for the slides (say, presentation is an array of slides, each slide has a title, body, optional image, optional diagram, each diagram is one of pie, table, ... Then use a library to generate the pptx file from the content generated.replyEGreg 6 hours ago | root | parent | next [\u2013]Library? What library?It seems to me that a Transformer should excel at Transforming, say, text into pptx or pdf or HTML with CSS etc.Why don't they train it on that? So I don't have to sit there with manually written libraries. It can easily transform HTML to XML or text bullet points so why not the other formats?replyyonom 6 hours ago | root | parent | next [\u2013]I don't think the name \"Transformer\" is meant in the sense of \"transforming between file formats\".My intuition is that LLMs tend to be good at things human brains are good at (e.g. reasoning), and bad at things human brains are bad at (e.g. math, writing pptx binary files from scratch, ...).Eventually, we might get LLMs that can open PowerPoint and quickly design the whole presentation using a virtual mouse and keyboard but we're not there yet.replyEGreg 6 hours ago | root | parent | next [\u2013]It\u2019s just XML They can produce HTML and transform python into php etc.So why not? It\u2019s easy for them no?replystevenhuang 6 hours ago | parent | prev [\u2013]apparently pandoc also supports pptxso you can tell GPT4 to output markdown, then use pandoc to convert that markdown to pptx or pdf.replyedwin 5 hours ago | root | parent [\u2013]Here you go: https://preview.promptjoy.com/apis/m7oCyLreplyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Concerns expressed about the use of GPT-4 to construct SQL queries and summarize emails without proper human validation.\n- Worries about developers removing human review, increasing the risk of prompt injection and compromised agents.\n- Lack of clear documentation and education from OpenAI on secure app development and LLM security practices."
  },
  {
    "id": 36319652,
    "timestamp": 1686702729,
    "title": "Reddit Doubles Down",
    "url": "https://www.platformer.news/p/reddit-doubles-down",
    "hn_url": "http://news.ycombinator.com/item?id=36319652",
    "content": "Discover more from PlatformerNews at the intersection of Silicon Valley and democracy. On Monday, Tuesday, and Thursday at 5PM Pacific.Over 142,000 subscribersSubscribeContinue readingSign inReddit doubles downDelaying its API changes would benefit everyone \u2014 but users have other options, tooCASEY NEWTONJUN 13, 2023872ShareProgramming note: Barring big news, Platformer will be off Thursday as I take a personal day. Hard Fork will publish Friday as usual. Monday is the Juneteenth holiday, so expect to see us back in your inbox on Tuesday.When a platform\u2019s user base is in revolt, it generally has two choices. The company can make concessions to users, walking back an unpopular change or offering some other consolation. Or it can keep calm and carry on, betting that the furor will subside after a few news cycles and allow the company to return to business as usual.On Monday, I wrote about the revolt at Reddit, where plans to begin charging developers to use the company\u2019s formerly free API is expected to crush the most popular third-party clients \u2014 and might also put moderation tools, accessibility-focused apps, and other enhancements to the network at risk. In response, moderators have made thousands of the site\u2019s most popular forums private, essentially taking them offline. They have called on Reddit\u2019s leaders to reverse the changes and ensure that third-party development of the network\u2019s ecosystem can continue.Today we got our most solid indication to date of how Reddit plans to handle this revolt \u2014 and CEO Steve Huffman is making it clear that the company does not intend to offer any concessions. He said as much in a memo to employees that leaked to Mia Sato and Jay Peters at The Verge.Huffman told employees:There\u2019s a lot of noise with this one. Among the noisiest we\u2019ve seen. Please know that our teams are on it, and like all blowups on Reddit, this one will pass as well. The most important things we can do right now are stay focused, adapt to challenges, and keep moving forward. We absolutely must ship what we said we would. The only long term solution is improving our product, and in the short term we have a few upcoming critical mod tool launches we need to nail.Huffman is right that, in the end, the whole situation reflects a product problem: the native Reddit apps, both on desktop and on mobile, are ugly and difficult to use. (In particular, I find the nested comments under each post bizarrely difficult to expand or collapse; the tap targets for your fingers are microscopic.) Reddit didn\u2019t really navigate the transition to mobile devices so much as it endured it; it\u2019s little wonder that millions of the service\u2019s power users have sought refuge in third-party apps with more modern designs.On the whole, though, Huffman\u2019s bet against the sustained energy of the Reddit community appears to have misfired.Over the past day, the number of Reddits that have gone dark expanded from around 7,000 to more than 8,400. And in response to Huffman\u2019s dismissive memo, moderators of hundreds of communities now say they will extend the blackout indefinitely beyond its planned two days.Here\u2019s Peters again at The Verge:\u201cReddit has budged microscopically,\u201d u/SpicyThunder335, a moderator for r/ModCoord, wrote in the post. They say that despite an announcement that access to a popular data-archiving tool for moderators would be restored, \u201cour core concerns still aren\u2019t satisfied, and these concessions came prior to the blackout start date; Reddit has been silent since it began.\u201d SpicyThunder335 also bolded a line from a Monday memo from CEO Steve Huffman obtained by The Verge \u2014 \u201clike all blowups on Reddit, this one will pass as well\u201d \u2014 and said that \u201cmore is needed for Reddit to act.\u201dAhead of the Tuesday post, more than 300 subreddits had committed to staying dark indefinitely, SpicyThunder335 said. The list included some hugely popular subreddits, like r/aww (more than 34 million subscribers), r/music (more than 32 million subscribers), and r/videos (more than 26 million subscribers). Even r/nba committed to an indefinite timeframe at arguably the most important time of the NBA season. But SpicyThunder335 invited moderators to share pledges to keep the protests going, and the commitments are rolling in.Thousands of subreddits likely will come back online within the next day, if only out of a sense of obligation to their own communities. But the indefinite loss of forums with tens of millions of subscribers seems likely to sting. (Certainly it\u2019s stinging the quality of Google search results.)If Reddit hopes to de-escalate the situation, it seems to me that it has two clear options. One is that it could reduce the announced pricing for its API to ensure third-party developers can continue their work. But this seems unlikely: Reddit\u2019s clear objective here is to wind down third-party app development and push users to its own native app, which it has promised to improve.That leads to the second option, which is to simply slow down. One of the most upsetting things about the API changes, from developers\u2019 perspective, is that many of their users bought annual subscriptions, and Reddit\u2019s new pricing takes effect at the end of this month. That leaves them little time to make things right with their customers. One criticism I heard of my piece yesterday is that Reddit had given developers more than 30 days\u2019 notice, contrary to what some developers have complained about. But when Reddit first announced that it would charge for API access, it did not specify prices or what kinds of apps would be affected. The communication failure led to widespread confusion about how tools related to content moderation, accessibility, and independent research would be affected, and Reddit has been trying to dig its way out of that hole ever since.That leaves room for Reddit to grant developers another six months to a year before the API changes take effect. By delaying the move, developers would get the time they need to either figure out sustainable business models or shut down without stiffing their customers on months of expected service. Reddit, in turn, could use that same time to build the improvements to moderation tools and the core app that it insists are coming soon.Assuming not even that happens, though, there are other options.One possibility is that, in the grand tradition of forum drama throughout internet history, big subreddits will simply decamp for other hosting solutions. If that seems like a pipe dream \u2014 and I apologize for the unfortunate example \u2014 look at the story of TheDonald. The violent, racist subreddit was banned in 2020 for violating Reddit\u2019s content policies. But its membership quickly rebuilt elsewhere, at a site I will not link to, using an interface quite similar to Reddit\u2019s. Of course, it would have been better for the internet if TheDonald had simply disbanded. But the fact that it continued once being booted off Reddit illustrates how little Reddit itself brought to the community \u2014 and how easily other, more reputable subreddits might build new homes elsewhere, so long as their users have the will.On Monday, I mentioned that my favorite subreddit had gone dark; a commenter let me know that some members had already set up shop on Kbin, a decentralized Reddit alternative that is interoperable with Mastodon and other services on the ActivityPub standard. While the interface is rough even by the standards of Reddit, it works just fine. And if the Fediverse continues to develop at its current pace, it might soon work much better than that.Then again, of course, Huffman may be right. Statistically, the furor over Reddit\u2019s API changes will pass, and power users will resign themselves to the imperfect convenience of having all their favorite niche communities in a single place. But for now, at least, anger seems to be building. And given the rapid fragmentation of online social networking, what happens next seems increasingly hard to predict. It\u2019s true that most social media controversies eventually blow over. Other times, though, they blow up. On the podcast this week: Kevin and I debate Reddit\u2019s next move. Plus, Max Read joins to discuss the confounding character that is MrBeast, and why platforms are giving up on 2020 election lies.Apple | Spotify | Stitcher | Amazon | GoogleGoverningGoogle called on the U.S. government to distribute oversight of AI to multiple agencies in a \u201chub-and-spoke\u201d model instead of taking the suggestion of Microsoft and OpenAI and creating a single AI regulator. (Cristiano Lima and David DiMolfetta / The Washington Post)In a wide-ranging interview, Microsoft CEO Satya Nadella discussed the company\u2019s collaboration with OpenAI, the future of Bing, the prospect of AGI, and his thoughts on AI safety and regulation. Notably, Nadella said \u201cwe shouldn't allow\u201d AI to destroy humankind. (Steven Levy / Wired)Research into social media\u2019s effect on teenagers has produced mixed and imprecise results, complicating both genuine measures designed to protect children\u2019s mental health and the recent flurry of legislative attacks on platforms. (Kaitlyn Tiffany / The Atlantic)Indian Prime Minister Narendra Modi\u2019s administration said Jack Dorsey was lying when he claimed India threatened to shut down Twitter unless it restricted content critical of the government. Dorsey made the comments this week in an interview with YouTube show Breaking Points. I believe him! (Shilpa Jamkhandikar, Aditya Kalra and Kanishka Singh / Reuters)IndustryMicrosoft\u2019s relationship with OpenAI is causing tension between the two firms over how freely the startup should work with competitors, and whether Microsoft is moving too fast to integrate AI tech into products. (Tom Dotan and Deepa Seetharaman / WSJ)Meta unveiled I-JEPA, a new computer vision model that uses abstractions of images as opposed to relying on labeled data sets in a way that better mimics how humans learn new concepts. (Mike Wheatley / SiliconAngle)Meta is adding a text-based \u201cworld chat\u201d to Horizon Worlds to let any user message anyone else in the same session, but with the option to blur messages from strangers. The blur setting will be on by default for users aged 13 to 17. (Steve Dent / Engadget)Google\u2019s new Search Generative Experience often plagiarizes articles when summarizing, raising concerns about copyright, the open web and potential anticompetitive effects on news publishers. A very fun read, at least for media people preparing their lawsuits. (Avram Piltch / Tom\u2019s Hardware)Google\u2019s return-to-office push, which includes tracking employee badges for performance review purposes, is drawing the ire of workers, who say it makes them feel like schoolchildren. In fairness most of their questions at TGIF are about snacks. (Jennifer Elias / CNBC)YouTube is lowering the requirements to join its Partner Program, which includes improved monetization tools, from needing 1,000 subscribers to only 500. (Ivan Mehta / TechCrunch)Paul McCartney said he used AI to help finish a John Lennon song believed to be the 1978 track \u201cNow and Then\u201d and plans to release it later this year as the \u201cfinal Beatles record.\u201d (Mark Savage / BBC)Amazon confirmed that it quietly started using generative AI to summarize product reviews, but declined to say what underlying AI models it\u2019s using. (Annie Palmer / CNBC)Oracle founder Larry Ellison overtook Bill Gates as the fourth-richest person in the world \u2014 with a net worth of nearly $130 billion \u2014 thanks to the AI boom pushing Oracle stock to its all-time high. (Biz Carson / Bloomberg)Apple warned the creators of decentralized social media app Damus that it will remove the software if they don\u2019t update it to remove a Bitcoin tipping feature. Not because of the crypto element, but \u2014 of course! \u2014 because the tipping feature doesn\u2019t use in-app purchase and circumvents Apple\u2019s 30% cut. (Yogita Khatri / The Block)The hundreds of startups designed to support mid-level and rising influencers are pivoting or shutting down because the creator economy never materialized like the industry promised. (Kaya Yurieff / The Information)Netflix plans to enter the live sports streaming market later this year with a celebrity golf tournament combining high-profile names from its Formula One docu-series Drive to Survive and golf series Full Swing. (Sarah Krouse and Jessica Toonkel / WSJ)Those good tweetsFor more good tweets every day, follow Casey\u2019s Instagram stories.(Link)(Link)(Link)Talk to usSend us tips, comments, questions, and hidden subreddits: casey@platformer.news and zoe@platformer.news.Subscribe to PlatformerBy Casey Newton \u00b7 Thousands of paid subscribersNews at the intersection of Silicon Valley and democracy. On Monday, Tuesday, and Thursday at 5PM Pacific.Subscribe87 Likes\u00b710 Restacks872SharePrevious",
    "summary": "- Reddit is facing backlash from users and moderators over plans to charge developers to use its API, potentially impacting third-party clients and network enhancements.\n- CEO Steve Huffman made it clear that Reddit does not intend to offer any concessions and believes the controversy will pass.\n- Thousands of subreddits have gone dark and moderators are extending the blackout indefinitely, demanding that Reddit reverse the changes.",
    "hn_title": "Reddit Doubles Down",
    "original_title": "Reddit Doubles Down",
    "score": 395,
    "hn_content": "- Users on Reddit are revolting against the platform due to recent changes made by the CEO, Steve Huffman.\n- Reddit users are concerned that the changes will turn the platform into a clone of other popular sites, filled with low-quality content and devoid of the things that made it valuable to long-time users.\n- Some users believe that Huffman understands what Reddit is better than others and that the platform will be fine despite the protest.\n- There is a possibility of new clones of Reddit emerging in the near future, as users become more aware of the site's vulnerabilities.\n- The future of Reddit is uncertain, as the changes and user discontent could impact the platform's value and user base.\n- The CEO's response to dissenting users has been seen as dismissive and has further fueled the protests.\n- The decision to charge for the API has received criticism, as it disproportionately affects third-party apps and developers who have contributed to the platform's success.\n- Many users rely on Reddit for niche communities and specialized hobby information, which they fear may be lost in the midst of these changes.\n- The timing of these changes may be influenced by Reddit's plans to go public in an IPO, as the company aims to showcase multiple revenue streams.\n- There is debate among users about whether the changes are driven by financial considerations or the desire to maintain control over data and content.\n- Some users have expressed a desire to migrate to alternative platforms but acknowledge the difficulty of building a new community and replicating Reddit's wealth of information.\n\nOverall, the post highlights the discontent among Reddit users regarding recent changes and the potential impact on the platform's value and user experience. It also touches on the potential emergence of new clones and raises questions about the future direction of Reddit.- Reddit CEO advises employees to be cautious in wearing Reddit gear in public due to potential threats and frustrations from upset individuals.\n- There have been instances of violence and threats on major internet platforms, such as the YouTube Headquarters shooting.\n- Some individuals believe that the CEO's message is an attempt to create a sense of unity among Reddit employees.\n- There are concerns about the impact of proposed API changes on subreddit moderation and spam control.\n- The post discusses the history of platform changes and corporate control in social media platforms like Facebook, YouTube, and TikTok.\n- There is speculation about the future of Reddit and the potential for a new platform to emerge.",
    "hn_summary": "- Reddit CEO warns employees about potential threats and frustrations from upset individuals and advises caution in wearing Reddit gear in public.\n- Concerns about the impact of proposed API changes on subreddit moderation and spam control.\n- Speculation about the future of Reddit and the potential for a new platform to emerge."
  },
  {
    "id": 36325349,
    "timestamp": 1686748198,
    "title": "Always the same warning signs",
    "url": "https://www.science.org/content/blog-post/always-same-warning-signs",
    "hn_url": "http://news.ycombinator.com/item?id=36325349",
    "content": "STAT has a pretty wild story (for subscribers) about Laronde, a Boston/Cambridge area biotech firm that seems to have had some major problems reproducing the data that helped raise them hundreds of millions of dollars last year. It\u2019s quite a read, but at the same time you can\u2019t help but feel that you\u2019ve read this story before. Let\u2019s go into that.Without tearing up the paywall, the outline of the story is that Laronde had what looked like promising results for a circular-mRNA technology. The hope was that this \u201cendless RNA\u201d, as the company promoted it, would be more stable, have better distribution upon injection, and lead to longer-lasting protein expression as (in theory) a ribosomal complex might just keep circling around it translating all the way. There are other companies working in this area, but Laronde had spoken of some really strong results in animal model experiments, as generated in one of their research groups.But it looks like no one else could get this to work. And when colleagues pressed the lab head involved for more details and for a chance to go over the raw data (much of which appeared to be missing), she refused to share it. Key figures in management took the line, though, that any problems with replication were obviously the fault of those other losers who just didn\u2019t have what it took to bring the magic. Sadly, the story develops in just the way you think it does after hearing that part, and if I were an investor in the company\u2019s $440 million Series B round last year, I would be hopping mad to read about what was really happening while that money was being collected.At this point you may be reminded of the entire corporate culture of the late and unlamented Theranos, and with good reason. But that spectacular example is not the only one of its kind out there - Theranos differed in its scale and thoroughness, but the same habits of mind, the same research and managerial climate, those have come up many times before. They rarely get to the point of taking down an entire company, but the warning signs are all very similar, and here are some of them laid out in a handy reference format. You should start to check things out carefully if:Only one person can get this great stuff to work. Now, there are certainly a lot of funky procedures in both chemistry and biology work with ill-defined variables, and a lot of new stuff needs taming before it works reliably. I remember a tricky anion reaction years ago that One Guy could get to work the best; he seemed to have a feel for the stirring and rate of addition. But there\u2019s a limit to this sort of thing - the rest of us could make that alkylation work, albeit often in lower yield. A situation where no one else can get a great big career-and-company-altering result to happen again is an alarm bell. It demands attention, but (as can be seen with the STAT piece), sometimes the opposite happens. As in. . .Legitimate questions are met with stonewalling. People whose careers depend on the great stuff working as advertised may decide instead that they Simply Do Not Want To Hear anything disturbing about it and adopt a \u201cShoo, little people! Out of my way!\u201d attitude. That is not how to do science - hell, that\u2019s not how to do anything, and the number of times people have come to grief via that attitude are beyond counting. The questions at Laronde were random noise from disgruntled employees. These were questions like \u201cHey, we can\u2019t see that species at all by mass spec that\u2019s supposed to be in those blood samples\u201d or \u201cHey, we can\u2019t reproduce those ELISA results, not even a little bit\u201d These are legitimate scientific questions, pretty darn concerning ones, too, and they deserved real answers, not the high-handed brush-off.Important data are missing or kept secret. There\u2019s really no excuse for this, and there\u2019s especially no excuse for it in an industrial research lab. You\u2019re not making notes on paper towels; everything is damn well supposed to be documented electronically and to be accessible on demand, from the raw data on up. From the article, it seems that folks at Laronde had very sound reasons for wanting to see the data for these killer RNA experiments, because they weren\u2019t reproducing. Finding then that these results were missing from the electronic notebooks should have set off sirens, and the refusal of the lab head involved to share data should have set off even more. You\u2019re all working for the same company. I have never heard of an \u201cI don\u2019t want to show you that data\u201d situation that ended well.You\u2019d think that these points would all be obvious. They are obvious. But people will find all sorts of ways to believe what they want to believe, to avoid hearing things that they don\u2019t want to hear, and to avoid thinking about things that are too worrisome to contemplate. We all do that sort of thing once in a while; it\u2019s human nature. But you don\u2019t want to handle hundreds of millions of dollars that way. Nor your career.",
    "summary": "- Laronde, a biotech firm, has faced major problems reproducing data that helped raise them hundreds of millions of dollars last year.\n- The company's circular-mRNA technology, known as \"endless RNA,\" was expected to have better stability, distribution, and longer-lasting protein expression, but no one else could get it to work.\n- Colleagues were denied access to raw data, while management blamed others for replication issues, similar to the Theranos scandal.\n- Warning signs include only one person achieving successful results, stonewalling legitimate questions, and missing or hidden important data.\n- These warning signs should not be ignored, as they indicate potential problems within a company or research project, which can lead to financial loss and damaged careers.",
    "hn_title": "Always the same warning signs",
    "original_title": "Always the same warning signs",
    "score": 342,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginAlways the same warning signs (science.org)342 points by rossdavidh 15 hours ago | hide | past | favorite | 154 commentsbee_rider 10 hours ago | next [\u2013]Is it possible that computer tech was just weirdly susceptible to startup funding, and it is a really poor fit for biotech?Computers mostly are* well understood at every step (well, at least it was all designed by humans and the bits and bobs do what they say on the tin).* mostly involve producing some kind of output for everyday normal people to use, in the end.So they are easy to understand and evaluate. Even some investors can manage it.Biotech stuff seems to mostly involve making tools for other technicians and scientists. And the process by which is works is some ridiculous, quirk-laden byzantine madness that evolution happened to throw together. At least from an outsider point of view it seems like an absolute nightmare.replycivilitty 9 hours ago | parent | next [\u2013]It\u2019s actually the other way around: it\u2019s surprising software investing works so well compared to biotech.While biotech companies carry a lot of all-or-nothing R&D risk, their \u201cproduct market fit\u201d is all but guaranteed. Their addressable market size is well known based on patient numbers and how much they can charge nationalized healthcare agencies and insurance companies based on quality of life improvements is well understood. Once they have premarketing approval, they\u2019re all but guaranteed an exit to one of the pharmaceutical giants. The most promising ones get acquired in phase II before efficacy is even 100% demonstrated.Look no further than IPOs: on HN we lament all the unprofitable public tech companies but the average biotech IPOs pre-revenue! Before it\u2019s even legal for them to sell a product! That\u2019s increasingly been the case since the 80s due to the exhaustion of small molecules and other low hanging fruit.In practice, scientific due diligence is harder to fake than aspirational user growth numbers which are far easier to game (case in point: Reddits ongoing bullshit). The FDA isn't going to let anyone put a dozen people at risk of death in phase I trials without a level of due diligence that puts all VCs to shame.replyjes5199 54 minutes ago | root | parent | next [\u2013]I have a friend who plays the stock market by reading papers published by publicly traded biotech companies and shorting the ones that seem to be fabricating evidence. This works well enough that he doesn't need a job.replyjasfi 28 minutes ago | root | parent | next [\u2013]That's a really interesting approach. The trick would be knowing the indicators of fabricated data. Or perhaps just knowing when the data isn't good enough to pass the next clinical trial.replyjes5199 11 minutes ago | root | parent | next [\u2013]yeah, he says it's obvious but I've read some of the same papers and I just don't have the background to be confidentreplygetoffmycase 10 hours ago | parent | prev | next [\u2013]It is an absolute nightmare. Biology is fundamentally fuzzy and our knowledge is incomplete. Biological actors, DNA and RNA and proteins, can act in surprising ways in feedback loops that are extremely difficult to track and quantify.Imagine every time you needed to troubleshoot something in a computer, you had to break out the multimeter. But the multimeter only works for one specific thing, which is an indirect measurement of the phenomena you\u2019re actually interested in and trying to troubleshoot. Also the multimeter has some serious flaws and biases that make it seem like it\u2019s working, but everything you get out of it is wrong and leads you to misinterpreting your results. That\u2019s what its like to do biology.A lot of innovation and progress is made when new tools to probe what\u2019s going on in biology are invented. For example, cell viability assays used to be conducted by literally counting the number of live cells vs dead cells. Now, you can use a photometric test that\u2019s extremely easy and takes a lot of guesswork out of the assay and makes it routine.Researchers fundamentally need more of those types of assays to make life easier. And that\u2019s where the dream and the profit people in biotech are chasing after.replymwint 9 hours ago | root | parent | next [\u2013]Also, due to ethics rules, you aren\u2019t allowed to open a computer to probe it with your broken multimeter unless it has already died. With a lot of paperwork, you may be allowed to probe an abacus and extrapolate the results to a computer.replyrenox 8 hours ago | root | parent | prev | next [\u2013]This reminds me of a school project (building a sound card) where I noticed that when I plugged the oscilloscope at one point it changed the output at another point --> I threw out the board and decided to never do hardware again..replyHPsquared 8 hours ago | root | parent | prev | next [\u2013]Gold rushes and pickaxe sellers comes to mind.https://www.investopedia.com/terms/p/pick-and-shovel-play.as...replycortesoft 7 hours ago | parent | prev | next [\u2013]No, I think software companies work well with startup funding simply because of the strange effect that unit costs have on software profits.The way computer (and especially internet) companies work is that once you have a working product, you can sell it a practically infinite number of times for practically zero marginal cost.This means that the successful software/internet companies are INCREDIBLY profitable, since they can sell the same product millions of times.Are startup investors good at predicting which company is going to be successful? Oh god no, they are awful at it. 90% of the companies they invest in fail completely.It doesn't matter, though, because they only need one success to make all those failures worth it. The cost of investing in a failure is WAY lower than the cost for NOT investing in a success.This means they don't really care that they can't evaluate which companies will be successful, they just cast a wide enough net to not miss the successes.replyeapressoandcats 10 hours ago | parent | prev | next [\u2013]Lots of Biotech stuff does fine, and plenty of tech startups are basically frauds (WeWork for example). I don\u2019t think you can extrapolate that startup funding doesn\u2019t work for Biotech.replyAlexandrB 10 hours ago | root | parent | next [\u2013]I'm not sure what makes WeWork a tech startup. Renting short term office space is not a high-tech endeavor. But it's true that there are plenty of tech startup frauds, like Nicola.replyfullshark 8 hours ago | root | parent | next [\u2013]Their argument paraphrased from the failed S-1https://www.vox.com/recode/2019/8/14/20804029/wework-ipo-tec...replyd0gsg0w00f 4 hours ago | root | parent | prev | next [\u2013]FWIW, the WeWorks I've worked in have better tech than most traditional offices I've worked in. The printing and room booking experiences are pretty great.replykneebonian 10 hours ago | root | parent | prev | next [\u2013]Because we work isn't a short term office rental it is a company that aims to \"revolutionize global consciousness\" which is clearly a growth industry.replybee_rider 10 hours ago | root | parent | next [\u2013]Revolutionizing global consciousness sounds more like a religion or something, but whether it was a, uh, niche religion or a real estate company, surely neither of those things is tech.replywbl 8 hours ago | root | parent | next [\u2013]Tell that to Softbankreplybee_rider 10 hours ago | root | parent | prev | next [\u2013]I\u2019m sure there are other great examples, but WeWork doesn\u2019t really seem like one; they were a real estate company, right? Cryptocurrency stuff maybe could be a better example though.replyravi-delia 10 hours ago | root | parent | next [\u2013]I feel like Crypto generally delivers on what it promises in terms of technology. If I go to investors to found Holebucket to produce the worlds first bucket manufactured with a one inch hole straight through the bottom, it isn't exactly hard to accomplish my goal. Crypto startups have a product, it's just a really dumb product. But Theranos for instance just straight up never had a product in the first place.replypfisherman 9 hours ago | parent | prev | next [\u2013]It is just a way for large biotechs to offload some of the risk / cost of R&D to VCs in exchange for some of the upside. People are always willing to make those types of bets.replynamaria 7 hours ago | parent | prev | next [\u2013]I don't think it's about the type of tech. Calling both groups \"tech companies\" is misleading to start with. The California start-up ecosystem is based on applying tech to create consumer products and once market fit and growth potential are evidenced it's straightforward to scale it globally.Biotech companies are developing new technology, in a highly regulated environment where, like other comments point out, there's a predictable economic niche. They only share a denomination, the dynamics are wholly different.replymatthewaveryusa 7 hours ago | parent | prev | next [\u2013]It's susceptible for funding because the marginal cost is (typically) close to zero after the first unit is sold.replyrenewiltord 9 hours ago | parent | prev | next [\u2013]A few years ago, I posted an anecdote from my family on faked science in a biotech labhttps://news.ycombinator.com/item?id=25926188The problem appears to be that our present text conversation climate is such that you must either pick Team Science or Other Team, and should you mention that there are faked results hiding in plain sight, people get upset because they think perhaps what you're saying is \"Maybe vaccines do cause autism\" and \"Maybe HCQ does cure COVID-19\".But that's not the truth. There is no monolithic Science entity. It is a property of every organization that reward-alignment is a stronger long term mechanism than fact-alignment. And it is impossible to direct the two in the same direction. This means that among the science establishment, there will be those who have ruthlessly optimized for the reward.This is part of why the general Internet arguer's approach of \"There is some evidence that X is Y look at this study url://url.url/url.pdf\" is often the blind leading the blind.Non omnis scientia est scientia.replyburnished 6 hours ago | root | parent | next [\u2013]Yes. Most people bring it up because they have an interest in a specific study or result being wrong, which I suspect has trained people to be dubious of anyone questioning The Science.And some people treat it as a quasi belief system, which makes sense, with precepts like 'the world is deterministic, causes precede effects' and so on. You could do worse. But they aren't scientists and they don't generally grok that science is an activity whose output is sometimes useful models and not 'Truth'.My mental model here is that you thus get people who trust in science as a paradigm, who then see doubt or skepticism as aimed against the whole edifice that is part of their fundamental understanding of the world, resulting in discomfort and leading to expected results.In other words pretty normal stuff that resembles when you come across an argument whose implications are opposed to your principles, that you suspect of trickery, but lack the rhetoric to dismantle yourself.replytbrownaw 1 hour ago | root | parent | prev | next [\u2013]> The problem appears to be that our present text conversation climate is such that you must either pick Team Science or Other Team, and should you mention that there are faked results hiding in plain sight, people get upset because they think perhaps what you're saying is \"Maybe vaccines do cause autism\" and \"Maybe HCQ does cure COVID-19\".Assume that you consider yourself unable to evaluate the truthfulness of scientific claims.Being told that claims you'd thought were properly vetted are actually wrong, then means that you have no way to know if other claims are accurate or not.If your process doesn't work, then any knowledge based on that process is called into question.replyAlbertCory 12 hours ago | prev | next [\u2013]These VC's: they suffer from Reverse Imposter Syndrome (tm), commonly found in \"elite\" institutions, as I outlined in here:https://albertcory50.substack.com/p/when-talent-is-not-enoug...That's when you think you're smart enough to be there, but you're really not.replyanonymouskimmer 9 hours ago | parent | next [\u2013]I just started reading your article, and am down to \"What If You Really Are a Fraud?\". I think the more interesting thing is not people who have delusions of competency, but people who feel they have \"imposter syndrome\", but are actually imposters (not just newbies who are still learning), and convince themselves that they aren't after finding out about imposter syndrome.I don't know how much this happens, but in areas such as education I think it could happen, as the criteria for most tertiary, and some secondary, educators isn't competency in teaching, but competency in a subject. And teaching effectively, especially to a large class, is quite hard.replywcarss 9 hours ago | root | parent | next [\u2013]> people who feel they have \"imposter syndrome\", but are actually imposters (not just newbies who are still learning), and convince themselves that they aren't after finding out about imposter syndrome.I could be one of those. But the thing is: a) one can rarely tell. And b) one way to look at imposter syndrome isn't that everyone is actually great while feeling terrible; it's that most people are quietly struggling in a lot of ways, which they see in themselves, but which are hidden from others. We could mostly be (and likely are) mediocre.So I can be struggling for real, and be a real \"impostor\", and be doing fine relative to the average population of my peers, all at once. I see many ways I'm struggling with things my peers seem to breeze through, but I might not see the ways I'm succeeding where they're quietly struggling themselves, and vice versa.replybloaf 40 minutes ago | root | parent | next [\u2013]There was a lovely comic years ago, entitled \"the foolproof way\" which captures this feeling.https://www.deviantart.com/eldahast/art/Foolproof-way-155527...replyanonymouskimmer 9 hours ago | root | parent | prev | next [\u2013]Completely agree. You have a very healthy way of looking at this personally, and this is the larger lesson people need to take in. \"Imposter syndrome\" is more a rule of thumb to not be too hard on yourself. The bigger, and more difficult lesson, is to recognize what needs improvement, what you can improve, and what you can't, in yourself and other.May you find your proper niche!replyz3t4 8 hours ago | root | parent | prev | next [\u2013]The more you learn about a subject the more you areas you discover that you do not know about. Learning has three basic stages 1) You are new 2) You think you know everything 3) You think you know nothing. I think at stage 3 impostor symptom can kick in. The dangerous stage is stage 2 where you feel very confident.replybtilly 9 hours ago | parent | prev | next [\u2013]That's so good I submitted it as https://news.ycombinator.com/item?id=36331178 in the hopes that more people would wind up reading it.replyAlbertCory 8 hours ago | root | parent | next [\u2013]well, thank you, sir.I did actually Submit that when I wrote it. Getting to the front page is kinda a crapshoot, of course.replygarbagecoder 10 hours ago | parent | prev | next [\u2013]I enjoyed reading that.It was a huge climbdown for me when I went to college. In high school, I was in the top 25 of my class of almost 1000 and I never broke a sweat. I never developed study habits because I didn't need them. One semester my junior year, my friend and I just spent one week in early November doing the entire semester's work, some late, some early. The rest of the time I could spend doing dumb shit and also hacking away on my computers.I did so well I got into a college where I was annoyingly average. By the time I developed some semblance of study habits and realistic sense of my abilities, it was too late to get my GPA much above 3 (this was before grade inflation was much of a thing). In graduate school I finally got my shit together and learned to just work, but I wasn't in as elite of an environment anymore thanks to my performance in undergrad.I had wanted my whole life to be away from the normies in high school and once I got there, I didn't love it. It was humiliating. But that was good for me. Realizing you're 1 in 1,000 or 1 in 10,000 instead of 1 in a million is probably much more realistic. And also annoyingly, this is exactly what testing when I was like 7 years old told me, but the illusion of being in an exurban high school made me think otherwise.Now I read we are shaped more and more and more by our experiences at around age 18. That's the music you hang on to and even, I read this week, the politicians we hang on to. I love to think I'm different, but I really am part of Generation Clinton. I really am not 1 in a million or 1 in 100,000 even.I think a lot of the kinds of people drawn to tech had similar experiences in their formative years. You see a lot of posts here with ideas about reforming education, but schools need to get everyone through, not just the 1 in 10,000 or even 1 in 100 types. In the US, you don't get sorted like that until about age 18 when you're already having a lot of defining experiences.So my interpretation of what you're writing is that people just get used to being the smartest guy in the room. Some may like being around others like that, but if they're honest I bet most people don't. They should!The lamest possible source turned me around on this. I was listening to Howard Stern (not my parents, not my friends, not my teachers) rant about how when he did his movie he found the movie people interested in building stars up, but his background in radio was all about burning people down and recycling them. I decided I liked building people up more. The karma didn't take long to pay me back.When you're anonymous on the Internet, nobody knows if you're full of shit or really pack the gear, so we see a lot of bullshit words to add the kind of credibility you might see from a resume.replyanonymouskimmer 10 hours ago | root | parent | next [\u2013]The 1 in a million are either screwed over worse than you were, or are recognized early and perennially challenged to further their development.> In the US, you don't get sorted like that until about age 18 when you're already having a lot of defining experiences.Programs for regular and exceptionally gifted students do exist in the US, but this varies state-to-state and district-to-district.The best \"reform\" I've thought of to address almost everything you've mentioned is to teach kids, early on, about failure. That it isn't the end of the world, what they can do to try to identify it happening, and how they can recover from it. Though like anything else this has to be done in moderation, as people who keep failing eventually give up entirely.replyAlbertCory 8 hours ago | root | parent | next [\u2013]True story: one of my neighbors went to University of Chicago High School (\"Uni High\" as it's called). It was (and probably still is) a school for the extremely gifted. (I suppose they have some Reverse Imposters there, too, but I wouldn't know /s )My dad was against my going there; I wouldn't be able to talk to ordinary people if I was only ever around those \"gifted\" kids.I suppose there's something to that; I cited this article:https://theamericanscholar.org/the-disadvantages-of-an-elite...by a guy who didn't know what to say to the plumber standing in his kitchen, whereas I'd much rather be around people like that than the Reverse Imposters.replyanonymouskimmer 8 hours ago | root | parent | next [\u2013]Acceleration (universal or subject-specific grade skipping) can help with this. It challenges the gifted student appropriately while still allowing them to socialize with regular people.Naively it might seem that this could lead to bullying, but from what I read it tends to work really well. The older students aren't threatened by the prodigy.replymacintux 7 hours ago | root | parent | next [\u2013]I took geometry as a freshman in a class full of juniors and seniors. The bullying was frequent, and the teacher strategically refused to show up on time so I had to either wait around outside the classroom like a coward or go in and be hazed.replygarbagecoder 5 hours ago | root | parent | next [\u2013]I skipped mid 3rd to mid 4th. I wasn't really that much younger, but it was not good. It wasn't just that they were bigger or whatever, but at that age what you're going through is still pretty tightly coupled to your age. I didn't feel normalish until well into high school.I don't recommend it. I recommend letting kids accelerate, but right now the consensus seems to be accelerate most people who need it at 9th grade, not 7th, and definitely not before. As with most of these things the consensus goes back and forth, but that squares with my lived experience.replylmm 5 hours ago | root | parent | prev | next [\u2013]And in fact bullying is significantly worse on average when students are not allowed to be accelerated.replygarbagecoder 9 hours ago | root | parent | prev | next [\u2013]GATE programs are underfunded and to the extent they exist they only make it worse most of the time because they basically are telling you: you are elite! and in your school you probably are, but you're usually still in the same school. Most of the time it's just pull outs.Also, I wasn't screwed over. I live a charmed existence that I am thankful for every day. (=eta: 100% agree we need to teach kids about failure. I understand the concerns about too much, but right now I don't think they are exposed to enough.replyanonymouskimmer 9 hours ago | root | parent | next [\u2013]College instead of high school is a nice alternative in some states.There are some magnet schools for highly gifted or aptitudinally talented students, including an online one: https://www.davidsongifted.org/the-davidson-academy/But yeah, the situation for regularly gifted students is often as you say. And any school program that truly held them to higher standards would also end up penalizing them with lower grades that would make them look non-competitive to highly selective universities.> but right now I don't think they are exposed to enough.Except those in the bottom 25%. They are human too, and deserve a good, well-tailored education.replyAlbertCory 5 hours ago | root | parent | next [\u2013]Actually, in my college dorm we had a guy who was only 16 who'd been accelerated. I wouldn't exactly say he was \"bullied,\" but he didn't have a very easy time of it.replyuoaei 11 hours ago | parent | prev | next [\u2013]That's just called Dunning-Kruger and is a well-studied phenomenon.You see it all over HN too, for instance, people coming up with a \"new\" idea, writing a blog post about it, and self-promoting as if they've contributed something novel.replystbede 10 hours ago | root | parent | next [\u2013]The Dunning-Kruger effect is not well established. It often doesn't reproduce.Also the effect isn't that people misjudge their knowledge, it's that they misjudge their place within a distribution. Suppose I give an exam to 30 people, and the results are normally distributed around a score of 70 with a low of 40 and a high of 97. The bottom of the distribution may accurately predict that they scored about 40 on the exam, but if you ask them how they performed relative to their peers, they will believe that they are about average and guess that a sizable portion of the class performed worse than them. Alternatively, if you ask the top performer who scored a 97, they will say that they think they scored about 97, but they will think maybe a few other people scored higher and maybe that the average was in the high 80s. The Dunning-Kruger effect posits that people are actually pretty good at accessing their own knowledge without being a good judge of how knowledgeable others are.replybumby 7 hours ago | root | parent | next [\u2013]>Also the effect isn't that people misjudge their knowledge, it's that they misjudge their place within a distribution.Put differently, isn\u2019t this saying it\u2019s a misattribution of confidence? In the context of the original claim about investing, that seems very relevant.replyAlbertCory 10 hours ago | root | parent | prev | next [\u2013]If you actually read the article, it's not exactly the same.replyuoaei 10 hours ago | root | parent | next [\u2013]Cynically angling for click-throughs by trying to redefine words or introduce trivial distinctions is another classic move.replyAlbertCory 10 hours ago | root | parent | next [\u2013]Nothing you'd ever do, Mr. I'm The Expert and You All Should Show Respect?replyuoaei 10 hours ago | root | parent | next [\u2013]Look, Bob, I don't have a personal vendetta against you. I do find value in clarifying things that are obscured by pomp and rhetoric. What's more, I don't appreciate muddied conversations, particularly when the motivation for the introduction of such mud is purely self-serving, especially in monetary terms.It seems obvious to me that Substack assesses your quality as a writer by checking on click-throughs from various sources and I would wager good money that they pay out differently depending on the behavior of the users who follow those links, either algorithmically in realtime or whenever it comes time to renegotiate terms. It's not even 2+2 here, Bob.PS: morality is more than just \"would someone else do it\". Don't make me start quoting cliches typically reserved for 5 year olds.replyAlbertCory 10 hours ago | root | parent | next [\u2013]My Substack is free, so nix to that.Maybe you should try writing something people like to read. Come back and tell us how it went.replyuoaei 8 hours ago | root | parent | next [\u2013]Is free, perhaps. But that could be for many reasons, including that you haven't yet convinced Substack to monetize your offerings. Isn't that how it always is when publishing on platforms you don't own? That you must prove your worth to get the paying gig?replyAlbertCory 7 hours ago | root | parent | next [\u2013]For someone who doesn't have a personal vendetta, you sure spend a lot of time writing about me.Tell you what: all publicity is good publicity. Why don't you mention my book titles next time?replyuoaei 7 hours ago | root | parent | next [\u2013]About you? Where? I'm responding to your comments. Do you know of a popular blog that I write that I don't know about?Does spilling your secret sauce threaten you? I can't imagine why, you certainly don't need the money. Aren't you writing to write things people like, or was that an empty and hypocritical moralizing jab?Why are you, who has a public persona easily traced to your real personhood, and who aspires to uphold a reputation to make money writing under that persona, replying with schoolyard-style taunts?replyConscat 11 hours ago | root | parent | prev | next [\u2013]I suppose that the Dunning Kruger effect is \"well studied\" in that there have been many attempts to study it, which so far cannot find reproducible results, and suggest that it isn't a real psychological phenomenon.replyuoaei 11 hours ago | root | parent | next [\u2013]Those studies, which do consistently show significant effects despite your citation-unladen claim, explore averages across a general population and seek to explain society-wide phenomena through the lens of \"average\" humans. This implies an assumption of homogeneity within the general population. Such tests will of course be underpowered compared to case studies in specific circumstances, particularly those involving self-selection and a cohort-level cultural bias toward \"I'm smart and need to pick things up quickly for my day job which means that skill is equally accurate and transferrable to everything I read about\".replygarbagecoder 10 hours ago | root | parent | prev | next [\u2013]Look, I understand there's a lot of trouble in psychology in general and there has been some reproduction issues with that one. But the truth is, we all know instances of the guy who thinks he knows everything just because he's good at something else and just thinks everything people went through to get where they are was a mistake. Whether or not this is a psychological thing in reality, it's something most of us have experienced and that's the name people know it by.replyravi-delia 10 hours ago | root | parent | next [\u2013]That's not even what the original study claimed to find though! It caught on because it seems so intuitive, yes, but the specific curve of confidence vs. skill doesn't seem to look like that at all.replygarbagecoder 9 hours ago | root | parent | next [\u2013]This is how memes or memetics or just language works though. Things often get called something they aren't and if it sticks it sticks. I'm not saying it's correct or whatever, just that it stuck because it vaguely gave a name for something people experience and didn't have a name for before.Look through any etymological dictionary and you'll see this phenomenon. What does a computer have to do with \"to strike\" in PIE? Something! But it's not the literal meaning.replyverall 10 hours ago | root | parent | prev | next [\u2013]> we all know instances of the guy who thinks he knows everything just because he's good at something elseThat's _not_ Dunning-Krugerreplyuoaei 7 hours ago | root | parent | next [\u2013]No, but the behavior expressed by adopting such an attitude is. Yours is a nitpick that is probably worth mentioning but doesn't really change the analysis.replygarbagecoder 5 hours ago | root | parent | next [\u2013]We just need a name for that now. Replyguy? Ackshually guy? Sounds too memey. The Nelson-Poindexter Effect?replygarbagecoder 9 hours ago | root | parent | prev | next [\u2013]Again, I'm not saying that's what it SHOULD be called, I'm saying it's a useful term for something we experience. At some point the wrong definition becomes the correct one, that's most etymologies.It's why people say \"and I\" as an object and don't know what question begging is or whatever. It just doesn't matter in the long run.replyKye 10 hours ago | root | parent | prev | next [\u2013]It's an example of wikigenesis. It didn't exist before someone created a Wikipedia entry naming something based on some studies.https://en.wikipedia.org/w/index.php?title=Dunning%E2%80%93K...It started as a syndrome. I don't think it would survive Wikipedia's modern standards if it hadn't generated its own support by existing in a different era.replyAlbertCory 9 hours ago | root | parent | next [\u2013]> wikigenesisI like it. Better than \"reification.\"replycorwinstephen 11 hours ago | root | parent | prev | next [\u2013]Zingreplyzaptheimpaler 14 hours ago | prev | next [\u2013]The big takeaway here for me is to make liberal use of the phrase \"Shoo, little people! Out of my way!\" when they don't approve my code reviews.replytoast0 13 hours ago | parent | next [\u2013]I prefer the less disparaging, \"Well, I'm going to check it in anyway\" and as a bonus, it doesn't directly acknowledge the existance of other people.replybluGill 13 hours ago | parent | prev | next [\u2013]Arrgh, why didn't I.think of that? I just left for vacation with an open code review that should have been easy because some new junior found some issues that I couldn't resolve before packing my suitcase.Thanks junior, the issues you found were real, even if small, and things will be better when I return and fix them.replyIaldaboth 13 hours ago | parent | prev | next [\u2013]Already been doing it for years, implicitely, by making my code as unreadable as possible. But now I can justify it by saying I'm doing Science.replybrianmcc 13 hours ago | parent | prev | next [\u2013]Also, go right ahead and reject the feedback you Simply Do Not Want To Hear!(I just loved that use of capital letters!)replythrowaway202351 12 hours ago | root | parent | next [\u2013]Sounds like they're not Team Players if they give you feedback you Simply Do Not Want To Hear!replycratermoon 12 hours ago | parent | prev | next [\u2013]I had a co-worker who would reject feedback and then complain that it was the reviewers' fault that his PRs weren't merged.replydmbche 14 hours ago | prev | next [\u2013]Man how insane is it that these guys and gals raised 400 millions on tech without any raw data, nothing to show for it? It was never reproduced? They just said they got it?replyryandrake 13 hours ago | parent | next [\u2013]The more I live in this world, the more I realize that its winners are pretty much exclusively charismatic bullshitters. I used to think that professional investors actually were a little smarter than the rest. I mean, here they are making huge bets on particular numbers on the roulette wheel--they must know something we don't! But they keep getting fooled!They have gobs and gobs of money to invest. Rich people chasing ever riskier rewards just handing money to them! They have to find something promising to throw it at. But who is it going to? Evidently, a lot of it goes to founders whose primary skill is storytelling. I used to think, no matter how handsome and smooth and persuasive you are, you at least have to have a little substance behind your enchanting narrative and ivy-league mannerisms. But here we are with failure after failure (and a once-a-decade colossal failure like Theranos) where all the warning signs were visible to someone not under the spell, and these bullshitters are still getting funding shoveled at them.It's pretty sad that \"look like you know what you are doing and convince gullible people\" is probably the best future career advice I can give to my school-age daughter.replyJohnFen 13 hours ago | root | parent | next [\u2013]> I used to think that professional investors actually were a little smarter than the rest.It's been my experience that you can't tell who's smarter than who by what they do for a living. On the whole, no group is actually smarter than any other group.> It's pretty sad that \"look like you know what you are doing and convince gullible people\" is probably the best future career advice I can give to my school-age daughter.I don't agree with that takeaway. I think the takeaway is that confidence is the primary thing that people take as a proxy for competence. It's not really about gullibility as much as people engaging in a heuristic. So learn to fake confidence, but have the chops to back it up.replykriro 13 hours ago | root | parent | next [\u2013]I'd venture that professional concert piano players or chess professionals (just to pick two random ones that popped into my head) are on average more intelligent than other fields which I won't name.I suppose it depends on the definition of smart which I understand as intelligent/good rational decision making but maybe you mean somthing else.replyanonymouskimmer 12 hours ago | root | parent | next [\u2013]I think the point GP was trying to make was about individuals in the groups, not averages. There are some brilliant janitors, and some professional piano or chess players have had savant syndrome. You're unlikely to find unintelligent or savant biochemists, but I'm sure more than a few are hyperfocused on their discipline to the exclusion of competency in other areas.replyadrianmonk 10 hours ago | root | parent | prev | next [\u2013]> It's been my experience that you can't tell who's smarter than who by what they do for a living. On the whole, no group is actually smarter than any other group.I assumed they meant professional investors are smarter about evaluating potential investments. Not generally smarter, just smarter about what they put their money into.replyryandrake 9 hours ago | root | parent | next [\u2013]OP here. I guess rather than \"smarter\" I meant to convey: less gullible, less vulnerable to being influenced by silly signals like someone's mannerisms and confidence, less reliant on unexplainable gut feels.I guess when I think of professional investors picking some of these dogs, my mind imagines that scene in Moneyball[1] where the old timers are trying to pick baseball players by who \"looks good,\" \"has a good jaw,\" \"how the ball sounds when it pops off his bat, and \"what the player's girlfriend looks like.\"1: https://www.youtube.com/watch?v=pWgyy_rlmagreplypessimizer 10 hours ago | root | parent | prev | next [\u2013]> On the whole, no group is actually smarter than any other group.This is the law of averages. Almost never true.replyanonymouskimmer 10 hours ago | root | parent | next [\u2013]You're ignoring GPs first sentence: \"It's been my experience that you can't tell who's smarter than who by what they do for a living.\"This first sentence indicates that they are writing about individuals with a vocation, not a group average. Statistically, in developed countries, any given manual laborer is likely to be less smart than any given venture capitalist, but Elon Musk, for instance, has been both. If you'd randomly picked him, in December of 1989, from the pool of manual laborers, you would have been wrong.replyAndrex 9 hours ago | root | parent | prev | next [\u2013]I view investors like I view critics of media: necessary for society in small doses, but otherwise contributing little value of their own into the world.And my threshold for having \"too much\" of these is pretty low...replymhb 9 hours ago | root | parent | prev | next [\u2013]Even so, these people of the Power Elite were visibly much smarter than average mortals. In conversation they spoke quickly, sensibly, and by and large intelligently. When talk turned to deep and difficult topics, they understood faster, made fewer mistakes, were readier to adopt others' suggestions.https://www.lesswrong.com/posts/CKpByWmsZ8WmpHtYa/competent-...replyryandrake 9 hours ago | root | parent | next [\u2013]Nice find! The author, it seems, falls for the same sorts of things I mentioned. He talks about an \"executive-nature\" that sets these people apart. Their \"aura\". Whether they \"sparkle with extra life force.\" People who \"just came across as... formidable, somehow.\" And over and over through the article, he confuses these things with genuine competence and intelligence.replymhb 6 hours ago | root | parent | next [\u2013]The author, it seems, falls for the same sorts of things I mentioned.That was not my intent. The point of the essay was exactly the opposite. Maybe I fall for the same stuff, but Eliezer is a very smart guy who was predisposed (as he makes clear in the essay) to believe that the people he met were all fluff. He was surprised that they were not just demonstrably knowledgeable, but, in addition, had other appealing characteristics.replyrossdavidh 6 hours ago | root | parent | prev | next [\u2013]I sometimes think that the real reason ChatGPT scares/excites so many tech business types, is that it has automated the one skill they have and are looking for in startup founders, which is to BS convincingly.replyiamflimflam1 12 hours ago | root | parent | prev | next [\u2013]Having sat on the other side of the table reviewing pitch decks and proposals, most investment decisions seem to be taken on either a very obvious \"this is complete nonsense\", or on a completely gut feel of: does this sound reasonable, do the numbers look sensible, does the team look good.replyfeoren 10 hours ago | root | parent | next [\u2013]> a completely gut feel of: does this sound reasonable, do the numbers look sensible, does the team look good.That's really the only way you ever could do it. But the key words there are \"reasonable\" and \"sensible\". Reasonable and sensible things don't revolutionize the entire world. They're not brand new, unprecedented technologies. It's not sensible to claim you'll create a ten-billion-dollar+ market overnight. It's not reasonable to claim that a problem that 10,000 smart scientists have worked on for decades was just solved in an unexpected way by this twenty-something \"wunderkind\" upstart and no you can't see behind the curtain. And yet these people get hundreds of millions in investment anyway. That's the question: why the hell did that ever sound reasonable; why the hell did those numbers ever look sensible!?replyjuve1996 7 hours ago | root | parent | next [\u2013]To me it's a natural consequence of wealth inequality. When you have mega funds like the oil countries have, where even losses like this are not really relevant, you will have this behavior. They know it's a moonshot. It's high risk high reward. And many will fail - but in the end, it doesn't really matter that much.replybinkHN 12 hours ago | root | parent | prev | next [\u2013]A shrewd businesswoman once told me to \u201cfake it until you make it\u201d\u2014I think this applies here.replyreadthenotes1 12 hours ago | root | parent | next [\u2013]\"conniving\" or \"fraudulent\" might be more apt than \"shrewd\"replykevin_thibedeau 9 hours ago | root | parent | next [\u2013]But the turtlenecks lent such an air of authority and deep experience.replyarchgoon 13 hours ago | root | parent | prev | next [\u2013]> It's pretty sad that \"look like you know what you are doing and convince gullible people\" is probably the best future career advice I can give to my school-age daughter.I would like to think that you would want your daughter to get more out of life than just raw cash.replywnevets 42 minutes ago | parent | prev | next [\u2013]> Man how insane is it that these guys and gals raised 400 millions on tech without any raw data, nothing to show for it? It was never reproduced? They just said they got it?Got to stop thinking that people with money are smarter than anyone else.replyasylteltine 14 hours ago | parent | prev | next [\u2013]Whatever VCs invested in it deserve to lose their money. Theranos was a learning opportunityreplynotatoad 12 hours ago | root | parent | next [\u2013]we really need to stop talking about these situations with legitimate terminology. They aren't \"VCs\" or \"Investors\". They're marks, and they got scammed.\"you can't cheat an honest man\" definitely applies.replygostsamo 13 hours ago | root | parent | prev | next [\u2013]Not sure why you were flagged, but many people handling millions say that they can do it because they know how to do it. There is a case to be made that some of them actually don't.replymasswerk 13 hours ago | root | parent | next [\u2013]Also, a certain corrective factor is required to make the \"because\" in this argument work.replymalfist 12 hours ago | root | parent | prev | next [\u2013]I don't agree. A conman's mark may be foolish, but it is not their fault they were conned and they don't deserve to be punished. The conman does.replypessimizer 10 hours ago | root | parent | next [\u2013]VCs aren't marks. They're fencers, hoping to get rid of the product before anyone realizes it's worthless or stolen. The (possibly sometimes subconscious) reason they don't care to deeply investigate is because if they're convinced by a shallow inspection, they're pretty sure they'll be able to convince others.It's a greater fool shockwave, pretending to buy into something and betting that you can get someone else to buy into it before the bottom falls out. Not that you know for sure the bottom will fall out, but if you're going to buy in based on how marketable the pitch is, examining it too hard might weaken that pitch or make it fall apart. In that case you've wasted time and money and have to find something else. If you're committed, the last thing you want to do is examine the business; you're shortening your bullshit runway.reply11101010001100 12 hours ago | root | parent | prev | next [\u2013]You ask to see the data and agree to sign an NDA. If the company does not agree to this, then you walk.IF the company agrees, but then shows fraudulent data, then you are fucked.replydmbche 12 hours ago | root | parent | next [\u2013]Actually I think you can sue for damages since the defrauded you, so they probably wouldn't agree to the NDAreplytyingq 10 hours ago | root | parent | next [\u2013]Someone selling a pure bullshit idea may not have many resources to extract via a lawsuit.replyThe_Blade 9 hours ago | root | parent | prev | next [\u2013]I like the take of Joseph \"Yellow Kid\" Weil as well as the guy who sold the Eiffel Tower... twiceto conflate movie quotes, a fool and his money were lucky enough to get together in the first place, and we just can't help ourselvesreplyhef19898 13 hours ago | parent | prev | next [\u2013]I know of a company, in a totally different field, operating on the same principles, with the same warning signs. They raised close to one billion and are in the process of raising 200 million more. Happens all the time, but never to me (quoting a line from the classic Margin Call).replyCoastalCoder 13 hours ago | root | parent | next [\u2013]I'm pretty naive about investing, but IIUC there are ways to bet against the stock price of a publicly traded company.Is there a mechanism for betting against a pre-IPO company?replyScoundreller 13 hours ago | root | parent | next [\u2013]Yes, but not as easily. Just need to be accredited and find someone willing to take the other end of the trade, as with anything else.replyfeoren 10 hours ago | root | parent | prev | next [\u2013]That sounds a little bit like \"If I can tell this company is defrauding investors, how can I get in on the fraud?\" Whoever you borrow that stock from is now your mark that you are defrauding -- indirectly, of course, since you're not forging fake results or something. It still feels icky.replypessimizer 10 hours ago | root | parent | next [\u2013]It's not you that are doing the defrauding. You're betting that it's a fraud and not trying to convince anyone of anything.Lack of short-sellers increases fraud, it doesn't reduce it. Nobody spreads more anti-short seller animus that people trying to commit fraud.replyCoastalCoder 10 hours ago | root | parent | prev | next [\u2013]> That sounds a little bit like \"If I can tell this company is defrauding investors, how can I get in on the fraud?\"That's not how I meant it. I was thinking more generally about pre-IPO companies that you think (for reasons that you can legitimately use when investing in this manner) have dim prospects.replyanonymouskimmer 12 hours ago | root | parent | prev | next [\u2013]Invest in its publicly traded competitors.replyhef19898 12 hours ago | root | parent | prev | next [\u2013]Oh, that one is post-SPAC...replybonadrag 12 hours ago | parent | prev | next [\u2013]Look at the stock market and fixed income investments around you. There is nothing there, very modest growth. That explains in part why so many people shifted part of their pile of cash to VC investments. The pile is not growing fast enough. Too many suckers out there who have not realized that we are in a new normal: low growth, low productivity, an aging, less dynamic society.replyAerbil313 12 hours ago | parent | prev | next [\u2013]> how insane is it that these guys and gals raised 400 millions on tech without any raw data, nothing to show for it?Abolish Venture Capital.replyandrepd 11 hours ago | parent | prev | next [\u2013]Remember: capitalism is the best system for allocating resources.replyzoogeny 12 hours ago | prev | next [\u2013]I think that it is easier to spot warning signs in hindsight. Simply based on this article, it seems possible and even likely that the lab head was deceitful. And the article suggests that the company management was either naive to the point of negligence or possibly they were actively defrauding investors.No matter what is the case, legitimate mistakes made by egotistical scientists compounded by negligent management or outright deceit and fraud, it is amazing that hundreds of millions of dollars were invested before it was discovered.Sometimes I lament the fact that I feel nervous asking for a raise even though I have demonstrably provided value and delivered massive projects. One the other side of the spectrum is the gall to ask for 100 million with nothing to show. It sometimes feels like there is a missing middle.replyHelloNurse 10 hours ago | parent | next [\u2013]Witholding data, explanations and assistance from those who want to evaluate and reproduce an experiment is obvious and immediate hostile and antiscientific behaviour, not a flaw that is only recognized in hindsight.replyzoogeny 8 hours ago | root | parent | next [\u2013]It is easy to believe that is what happened based on the details in the article but what we are seeing is a filtered view in hindsight.It's like when you watch a movie with a twist that you didn't see coming. But then you go back and re-watch it knowing the ending and you gleefully point out all of the places the film makers put subtle clues which you didn't catch. Imagine telling the ending to a friend. He then watches the film and says: \"how could anyone not see the twist? it was so obvious the entire time!\"What seems in hindsight as \"withholding data\" might have been seen at the time in a completely different light.It reminds me of situations I heard stories about at two workplaces. Both were cases where a new hire was given a task to complete. They were giving excuses, showing partial progress, dodging inquiries. In both cases the new hire lasted over 3 months before it was realized they were doing absolutely no work at all. In all cases it was obvious in hindsight but during the course of the deception all of the excuses added up.replyanonymousiam 11 hours ago | parent | prev | next [\u2013]I wish we had more details, but something stinks. There's always a conflict with \"science\" when somebody tries to monetize it. A possible explanation here is a desire to keep some elements of the process proprietary, but I don't see how that could apply to sharing within the same organization.replymrandish 10 hours ago | root | parent | next [\u2013]> There's always a conflict with \"science\" when somebody tries to monetize it.Sadly, the replication crisis in science shows that the causes are equally present in purely academic settings as well. Status, power, job security or ego can be as powerful as money and the effects can corrupt someone subtlety and even entirely unconsciously. It's good to remember that no human is immune from confirmation bias or self-deception.replyanonymouskimmer 10 hours ago | root | parent | next [\u2013]> Status, power, job security or ego can be as powerful as money and the effects can corrupt someone subtlety and even entirely unconsciously.Yeah. How many times have any of us had what seemed like a good idea, tried it, and found it didn't work? It just takes a little more effort to try it a few more times thinking that something was wrong. Eventually you might get a result due to random chance. And at that point you've convinced yourself that your idea was a good one all along.replygetoffmycase 10 hours ago | root | parent | prev | next [\u2013]In that case I think the \u201cmonetization\u201d is in the form of misaligned incentives with scientific endeavors. The incentives are having a job, getting grants funded, and obtaining prestige.replybix6 12 hours ago | prev | next [\u2013]Everyone always decries these as failures of venture capital. There is fraud in every industry. You cannot conceivably check everything and there is a level of trust required. Even if someone sends you raw data you are taking their word that it\u2019s the true data. There can be deception at every level and smart people will be deceived by criminals. Where there is money there will always be crime so I am grateful to see our justice system working even if it takes many years.replyjgeada 12 hours ago | parent | next [\u2013]That's facile and ignores that VC is supposed to be a vetting gatekeeper: the reason they keep a fraction of all the money going through their accounts is because they're supposedly vetting the investment opportunities and have money and access to knowledge as necessary to validate claims, etc. If they're not doing this, what is the value add the VC company is providing, other than being a skimmer on the money flows?The reality is that as long as there is no liability for passing the buck (ie the scammer's and middemen's beloved caveat emptor), the system continues to encourage bad players.replybix6 8 hours ago | root | parent | next [\u2013]My point is that no matter how much due diligence you perform, there is still a chance to be deceived. No amount of money could get you to 100% diligence and cover every edge case.There is liability for knowingly passing the buck. VCs have been sued before.replyfeoren 10 hours ago | parent | prev | next [\u2013]> Even if someone sends you raw data you are taking their word that it\u2019s the true data.With hundreds of millions on the line, is it so much to ask that VC firms employ a couple statisticians to at least do a sanity check on the data? Fake data can often be identified as fake.replybix6 8 hours ago | root | parent | next [\u2013]VCs differ wildly. A small VC will certainly not earn enough in fees to employ multiple dedicated statisticians. They will likely have a CFO/other analysts who can check the data but there's no guarantee they will catch cleverly manipulated data. Obviously this is a much later stage investment so different diligence is expected but there are many ways to deceive. Certainly some VCs saw red flags while others did not.replyAlbertCory 12 hours ago | parent | prev | next [\u2013]Wrong. \"Due diligence\" is a term that's there for a reason.replybix6 8 hours ago | root | parent | next [\u2013]Due diligence and 100% complete due diligence that accounts for every single thing are drastically different.replycsours 11 hours ago | prev | next [\u2013]Related recommendation: Bobby Broccoli's documentarieshttps://www.youtube.com/watch?v=ett_8wLJ87U&list=PLAB-wWbHL7...https://www.youtube.com/watch?v=nfDoml-Db64&list=PLAB-wWbHL7...replysearine 10 hours ago | parent | next [\u2013]Love Bobby B videos. Second that recommendation.replyfasteo 10 hours ago | prev | next [\u2013]>>> Laronde, a Boston/Cambridge area biotech firm that seems to have had some major problems reproducing the data that helped raise them hundreds of millions of dollars last yearVCs: How the hell you put 100MM+ in a company without having a 3rd party verify that the \"thing\" works ?replycurrymj 9 hours ago | prev | next [\u2013]The level of fraud going on in life sciences seems absolutely astounding. I used to think that fraudulent research was mainly \u201cpaper mill\u201d stuff.But in the last couple years there are so many cases of outright data falsification from famous scientists\u2019 labs and in Science/Nature/Cell publications.It seems even worse than the social science replication crisis, and with worse consequences.replyz3t4 8 hours ago | parent | next [\u2013]It's like doping in sports, the cheaters get all the money and glory - until they get tested. The solution is more tests. If the study can't be replicated then there is a problem. There should be more tests in science, without tests it's not science.replypico303 9 hours ago | prev | next [\u2013]Is this what happens when research moves from universities to the private sector? Not sharing data and results seems par for the course for things like proprietary algorithms. Why would biotech be any different?replyjaneway 6 hours ago | parent | next [\u2013]In fairness, one good thing about commercialisation is that if they don\u2019t produce the goods in the end, it fails. In pure research it can go unnoticed much longer.replyProjectArcturis 13 hours ago | prev | next [\u2013]Derek Lowe is a treasure.replyrossdavidh 6 hours ago | parent | next [\u2013]Truth. The best thing about the pandemic is that it somehow brought his column to my attention.replyxnx 13 hours ago | parent | prev | next [\u2013]Agree. I didn't know who he was until I heard him in a piece of On the Media from WNYC and was immediately struck by how reasonable he was.replydeeg 12 hours ago | prev | next [\u2013]It would be interesting to know how many companies with these warning signs were legit. Is it possible that investors look at these as lottery tickets and hope that just a few hit?replythimkerbell 12 hours ago | prev | next [\u2013]\"Only one person can get this great stuff to work;... Legitimate questions are met with stonewalling;... Important data are missing or kept secret\"replyhinkley 10 hours ago | parent | next [\u2013]One of my managers had a rule of 2 (different from my rule of 2).  You haven't proven you know how to do something until you've done it twice.That was expanded by later managers to a more general sense of reproducibility, where 'we' don't know how to do it until two other people have done it.There are certain aspects of my life that are informed by a general dread that some day I will leave my house and never be seen again. For instance I try to tell tell people I love them when we part, even if I'm mad at them, in case those are our last words for a long while, or forever.If I really thought I was doing something at work that would forever change a corner of the world, I'd be super paranoid that the secret could die with me. That's the perfect recipe for me overworking. If I can't trust anyone with the information (eg, intellectual theft), then I positively vibrate. If I told people and they don't care, I have to finish it enough that I can demonstrate why they should care.replytoss1 10 hours ago | root | parent | next [\u2013]Yup. Like the saying I heard from a friend about how to treat engineering tests:\"The first test result is an error. The second is a coincidence. If the third lines up, then you might be getting a hint of a result.\"As in: if you can't reproduce it reliably, you have nothing.replyfsckboy 2 hours ago | root | parent | next [\u2013]in science, if you make a prediction from a hypothesis, conduct a test, and what you predicted is borne out, that's not nothing; for example, if you look at historical records and hypothesize a reappearance of, I dunno, let's call it Halley's comet, and decades later Halley's comet reappears, why... they might name the comet after you!replyprotonfish 11 hours ago | parent | prev | next [\u2013]Precisely - these aren't \"Warning signs\" that are only clear in hindsight. They are proof of fraud beyond a reasonable doubt. If a person or organization has these traits and you continue to trust them, it is not an honest mistake.replysebstefan 13 hours ago | prev | next [\u2013]This really shouldn't keep happening in 2023https://en.wikipedia.org/wiki/Sch%C3%B6n_scandalhttps://en.wikipedia.org/wiki/Hwang_Woo-suk#Official_probe_a...replyphotochemsyn 12 hours ago | parent | next [\u2013]Transparent audit protocols are the only solution - e.g. raw data should be immediately available upon publication, and even more rigorous protocols should be employed for grant application review (show us the daily log etc.), but those who oppose this approach say it'll expose intellectual property to outsiders causing the loss of competitive edge.Open-source research is thus the only kind of research that should be allowable with public funds, and closed-source proprietary research shouldn't be publishable in any research journal. If people want to invest in the latter they'll be the ones responsible for due diligence, I suppose.replyphs318u 6 hours ago | prev | next [\u2013]Yes. Always the same warning signs, because humans always ignore their senses when they are overwhelmed by the same greed. Always.replyackbar03 13 hours ago | prev | next [\u2013]Anybody have the actual Stat article?replyradicaldreamer 12 hours ago | parent | next [\u2013]not great formatting but available in the comments on reddit: https://www.reddit.com/r/biotech/comments/147o153/does_anyon...replyBSEdlMMldESB 13 hours ago | parent | prev | next [\u2013]Stat does, and sharing is caring: https://archive.ph/1vHlW (still paywalled)but they don't care, they don't share....replyreadthenotes1 12 hours ago | prev | next [\u2013]\"people will find all sorts of ways to believe what they want to believe, to avoid hearing things that they don\u2019t want to hear, and to avoid thinking about things that are too worrisome to contemplate\"Wizard's First Rule (Terry Goodkind)replypneumonic 11 hours ago | prev [\u2013]La Round, er, Laronde, seems to have a singular focus.replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- Computer tech is often seen as a better fit for startup funding compared to biotech because it is easier to understand and evaluate.\n- Biotech companies carry more R&D risk but have a guaranteed market size based on patient numbers and the potential to charge healthcare agencies.\n- The scientific due diligence in biotech is harder to fake compared to the more easily manipulable user growth numbers seen in software companies."
  },
  {
    "id": 36321843,
    "timestamp": 1686721034,
    "title": "Serotonin booster leads to increased functional brain connectivity",
    "url": "https://www.alphagalileo.org/en-gb/Item-Display/ItemId/234406?returnurl=https://www.alphagalileo.org/en-gb/Item-Display/ItemId/234406",
    "hn_url": "http://news.ycombinator.com/item?id=36321843",
    "content": "LoginRegisterPlease register to view contact detailsSerotonin booster leads to increased functional brain connectivity13/06/2023 ElsevierPro-cognitive agent could have therapeutic use, according to a new study in Biological Psychiatry: Cognitive Neuroscience and NeuroimagingPhiladelphia, June 13, 2023 \u2013 Cognitive deficits accompany mood disorders and other psychiatric conditions, often with debilitating effects. Limited treatments currently exist, but studies in animals and humans have pointed to drugs such as the laxative prucalopride that activate serotonin receptors as a potential therapeutic for the symptoms. It has remained unclear, however, how the medication affects resting brain activity. Now, a new study in Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, published by Elsevier, examines the drug\u2019s effects in healthy human adults.Serotonin receptors and the 5-HT4-type receptors in particular are found in areas throughout the brain, including the frontal cortex, basal ganglia, and hippocampus, that are known to mediate cognitive function and regulate mood. Serotonin receptors are the primary targets of antidepressant medications, but resolving mood disturbances often does not resolve cognitive symptoms.The researchers enlisted 50 healthy volunteers, half of whom received a six-day course of prucalopride, a highly selective agonist of the 5-HT4 type serotonin receptor, whereas the other half of the participants received a placebo. Participants underwent scanning with functional magnetic resonance imaging, including a \u201cresting scan,\u201d in which they relaxed in the scanner.Lead author Angharad de Cates, PhD, MRCPsych, at the University of Oxford, said of the work, \u201cOur previous studies on prucalopride demonstrated that even at low clinical doses it can improve cognition and memory in healthy volunteers. This latest research provides a neurological mechanism by which this might occur.\u201dParticipants who received the medication displayed more functional connectivity in their resting-state (rsFC) between major cognitive networks. This included more rsFC between the central executive network, a brain network used for processing thoughts, and the posterior and anterior cingulate cortex (ACC), brain areas that regulate information processing and attention in the brain. There was also more rsFC between regions of the ACC and the lateral occipital cortex, a region that helps us pay attention to objects that matter. In addition, medicated participants compared to placebo controls showed decreased rsFC in the default mode network, a brain network that is activated during mind wandering.Dr. de Cates added, \u201cThis provides further evidence that prucalopride is having an effect in areas of the brain that improve cognitive function \u2013 both by increasing and reducing connectivity between specific brain regions as required.\u201dSusannah Murphy, PhD, Associate Professor and joint senior author of the study, said, \u201cAppropriate connectivity between and within these brain networks is needed to think properly, and this connectivity has been shown to be abnormal in depression. Here, the participants taking prucalopride had better scores on cognitive tests the day of the scan compared to the placebo participants. That suggests that the changes in rsFC that we saw with prucalopride may serve as a \u2018signature\u2019 of a drug that improves cognition.\u201dDr. Murphy continued, \u201cUntreated cognitive problems have a significant impact on the quality of life of people with depression. This study adds to the growing evidence base that drugs affecting the 5-HT4 serotonin receptor hold promise as a novel way to treat depression and cognitive impairment.\u201dCatherine Harmer, PhD, Professor of Cognitive Neuroscience and joint senior author of the study, said, \u201cThis study adds to the evidence base that the common laxative treatment prucalopride can have important effects in the brain, particularly affecting circuits which are important for learning and memory. Together with previous data, this suggests that this drug might be useful as a pro-cognitive treatment in disorders such as depression.\u201dCameron Carter, MD, Editor of Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, said of the work, \u201cThese data, showing modulation of resting state connectivity in the brain by the 5HT4 receptor agonist and putative cognitive enhancer prucalopride, add to previous evidence that the agent modulates brain systems that are engaged during focused, higher cognitive activity and might have therapeutic potential.\u201dFull bibliographic informationAttached files13/06/2023 ElsevierRegions: Europe, Netherlands, United KingdomKeywords: Health, Medical, Well being, Science, Life SciencesLatest PublicationsSee MoreFilm shapes our understanding of the pastabout a month agoUniversity of Oslo, Faculty of HumanitiesConceptions of sexual harassment are challenged in Nordic anthology2 months agoUniversity of GothenburgBucherscheinung \u201cPhysics against cancer\u201d2 months ago\u00ab Paul Scherrer Institut (PSI) \u00bbPublication de l\u2019ouvrage \u201cPhysics against cancer\u201d2 months ago\u00ab Paul Scherrer Institut (PSI) \u00bbTestimonialsFor well over a decade, in my capacity as a researcher, broadcaster, and producer, I have relied heavily on Alphagalileo.All of my work trips have been planned around stories that I've found on this site.The under embargo section allows us to plan ahead and the news releases enable us to find key experts.Going through the tailored daily updates is the best way to start the day. It's such a critical service for me and many of my colleagues.Koula Bouloukos, Senior manager, Editorial & Production UnderknownWe have used AlphaGalileo since its foundation but frankly we need it more than ever now to ensure our research news is heard across Europe, Asia and North America. As one of the UK\u2019s leading research universities we want to continue to work with other outstanding researchers in Europe. AlphaGalileo helps us to continue to bring our research story to them and the rest of the world.Peter Dunn, Director of Press and Media Relations at the University of WarwickAlphaGalileo has helped us more than double our reach at SciDev.Net. The service has enabled our journalists around the world to reach the mainstream media with articles about the impact of science on people in low- and middle-income countries, leading to big increases in the number of SciDev.Net articles that have been republished.Ben Deighton, SciDevNetWe Work Closely With...HomeAlphaGalileo global reachLatest newsAll PublicationsLoginRegisterAll regionsAfricaAsiaCaribbeanEuropeLatin AmericaMiddle EastNorth AmericaOceaniaExtraterrestrialAll categoriesCovid-19ScienceHealthSocietyHumanitiesArtsApplied scienceBusinessAlphaGalileo eNewsAbout UsPricesHelpContact UsCopyright 2023 by AlphaGalileo Terms Of Use Privacy Statement",
    "summary": "- A new study published in Biological Psychiatry: Cognitive Neuroscience and Neuroimaging examines the effects of a serotonin booster called prucalopride on the brain.\n- Serotonin receptors, particularly 5-HT4 receptors, are found in areas of the brain that regulate mood and cognitive function.\n- The study found that participants who received prucalopride showed increased functional connectivity in the brain, specifically between cognitive networks and regions involved in attention and information processing.\n- These findings suggest that prucalopride may have therapeutic potential for treating cognitive deficits in mood disorders and other psychiatric conditions.\n- The study adds to the growing evidence that drugs targeting serotonin receptors could be a novel way to improve cognitive function in depression and other disorders.",
    "hn_title": "Serotonin booster leads to increased functional brain connectivity",
    "original_title": "Serotonin booster leads to increased functional brain connectivity",
    "score": 300,
    "hn_content": "- Commenters on the Hacker News article are discussing the issue of intelligent people overestimating their abilities in fields outside their own.\n- Some argue that the discussions on Hacker News are filled with authoritative-sounding content and comments that are actually complete nonsense when it comes to certain topics, such as medicine.\n- Intelligence in one area does not necessarily mean qualification to make assessments or reach conclusions in other fields.\n- The post discusses a study that suggests a serotonin booster leads to increased functional brain connectivity, but some commenters express skepticism about the research.\n- It is important to approach the suggestions and conclusions made in the comments with caution and skepticism, as they may not be accurate or reliable.\n- The field of psychiatry and neuroscience is complex, and not all commenters on Hacker News are qualified experts in these areas.\n- The effects of certain drugs, such as psychedelics, on the human brain are being discussed, but it is important to consider the limitations and potential risks associated with their use.\n- Longer-term studies are needed to fully understand the effects and potential benefits of certain treatments or substances.\n- It is acknowledged that discussions on Hacker News, or any online forum, can vary in quality and expertise.\n- The complexity of the brain and its functions makes it difficult for experts and non-experts alike to fully understand certain aspects.\n- The comment section of the post highlights the challenges of discussing complex topics on a platform with a varied range of expertise and opinions.- Prucalopride, a drug primarily used as a constipation treatment, has been found to improve memory and cognition by altering functional brain connectivity.\n- The study suggests that prucalopride is having an effect in areas of the brain that improve cognitive function.\n- This research provides further evidence of the potential therapeutic effects of drugs that target serotonin receptors.\n- Serotonin, often referred to as the \"happiness hormone,\" plays a complex role in neural signaling and is involved in a range of mental health conditions.\n- The study highlights the importance of understanding the specific mechanisms by which drugs interact with serotonin receptors to develop effective treatments.\n- Prucalopride has been noted to have both positive therapeutic effects and potential side effects, such as cardiac complications and intestinal effects.\n- It is important to approach the use of serotonergic drugs with caution and under medical supervision.\n- Further research is needed to fully understand the potential applications and limitations of drugs like prucalopride in treating various mental health conditions.",
    "hn_summary": "- Intelligence in one area does not necessarily mean qualification in other fields.\n- The study suggests that a serotonin booster leads to increased functional brain connectivity.\n- It is important to approach the suggestions and conclusions made in the comments with caution and skepticism."
  }
]
