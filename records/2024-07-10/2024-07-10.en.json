[
  {
    "id": 40926648,
    "title": "AMD to buy Silo AI for $665M",
    "originLink": "https://www.ft.com/content/7b8d2057-2687-45b3-bae4-1488a75ac5b2",
    "originBody": "Accessibility helpSkip to navigationSkip to contentSkip to footer Sign In Subscribe Open side navigation menuOpen search bar SubscribeSign In Search the FT SearchClose search bar Home World Sections World Home Israel-Hamas war Global Economy UK US China Africa Asia Pacific Emerging Markets Europe War in Ukraine Americas Middle East & North Africa Most Read Nancy Pelosi and George Clooney deliver new blows to Biden re-election bid Type of Russian missile that struck Kyiv children’s hospital uses western components Joe Biden holds on to key Democrats despite tense talks over candidacy Donors and Democrats despair as push to sideline Joe Biden fizzles Moscow court orders arrest of Alexei Navalny’s widow US Sections US Home US Economy Investing in America US Companies US Politics & Policy US Presidential Election 2024 Most Read Companies Sections Companies Home Energy Financials Health Industrials Media Professional Services Retail & Consumer Tech Sector Telecoms Transport Most Read Large London office buildings proving almost impossible to sell How Elon Musk blindsided Narendra Modi with a cancelled India trip How UBS fell out with Switzerland’s establishment after rescuing Credit Suisse World’s largest oil company bets on the enduring power of petrol Nike’s new chief runs into trouble as turnaround efforts falter Tech Markets Sections Markets Home Alphaville Markets Data Cryptofinance Capital Markets Commodities Currencies Equities Wealth Management Moral Money ETF Hub Fund Management Trading Most Read Live news: Starmer says China strategy will dovetail between ‘co-operation’ and ‘robust challenge’ World’s largest oil company bets on the enduring power of petrol Top ECB official sounds alarm on rising risks from shadow banking News updates from July 9: Powell hails progress in tackling US inflation; Moscow court orders arrest of Alexei Navalny’s widow Passive investors and the AI bubble Climate Opinion Sections Opinion Home Columnists The FT View The Big Read Lex Obituaries Letters Most Read Why India will become a superpower The weird resilience of Nato and the EU The very resistible rise of Nigel Farage The risky holes in Keir Starmer’s green plan What if Joe Biden stays? Lex Work & Careers Sections Work & Careers Home Business School Rankings Business Education Europe's Start-Up Hubs Entrepreneurship Recruitment Business Books Business Travel Working It Most Read The workplace under Labour: employers braced for biggest shake-up in a generation The new normal of office life Why playing down a privileged background might be a savvy career move Can online reporting stop workplace microaggressions? ‘I saw a massive opportunity for what this organisation could be’: Hilary Evans-Newton on transforming Alzheimer’s Research UK Life & Arts Sections Life & Arts Home Arts Books Food & Drink FT Magazine House & Home Style Travel FT Globetrotter Most Read First review: the new hybrid Porsche 911 Postcard from Braemar: wild swimming gets the five-star treatment Are you an Ōura Bore? 15 buys for football fans My favourite Mediterranean island HTSI MenuSearch Home World US Companies Tech Markets Climate Opinion Lex Work & Careers Life & Arts HTSI Financial Times SubscribeSign In Search the FT SearchClose search bar AMD to buy Finnish start-up Silo AI for $665mn in drive to compete with Nvidia Subscribe to unlock this article Try unlimited access Only $1 for 4 weeks Then $75 per month. Complete digital access to quality FT journalism on any device. Cancel anytime during your trial. Keep reading for $1 Global news & analysis Expert opinion Special features FirstFT newsletter Videos & Podcasts Android & iOS app FT Edit app 10 gift articles per month Explore more offers. Standard Digital wasnow $39 per month Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%. Select What's included Weekend Print + Standard Digital wasnow $45 per month FT Weekend newspaper delivered Saturday plus essential digital access. Select What's included Premium Digital wasnow $75 per month Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%. Select What's included Terms & Conditions apply Explore our full range of subscriptions. Digital Explore digital > Print Explore Print > Print + digital Explore Print + Digital > Teams or organisations Find out more > Check whether you already have access via your university or organisation. Why the FT? See why over a million readers pay to read the Financial Times. Find out why Useful links Support View Site TipsHelp CentreContact UsAbout UsAccessibilitymyFT TourCareers Legal & Privacy Terms & ConditionsPrivacy PolicyCookie PolicyManage CookiesCopyrightSlavery Statement & Policies Services Share News Tips SecurelyIndividual SubscriptionsProfessional SubscriptionsRepublishingExecutive Job SearchAdvertise with the FTFollow the FT on XFT ChannelsFT Schools Tools PortfolioFT AppFT Digital EditionFT EditAlerts HubBusiness School RankingsSubscription ManagerNews feedNewslettersCurrency Converter Community & Events FT CommunityFT Live EventsFT ForumsBoard Director Programme More from the FT Group Markets data delayed by at least 15 minutes. © THE FINANCIAL TIMES LTD 2024. FT and ‘Financial Times’ are trademarks of The Financial Times Ltd. The Financial Times and its journalism are subject to a self-regulation regime under the FT Editorial Code of Practice. Close side navigation menuFinancial Times International Edition Subscribe for full access Search the FT Search Switch to UK Edition Top sections Home WorldShow more World Israel-Hamas war Global Economy UK US China Africa Asia Pacific Emerging Markets Europe War in Ukraine Americas Middle East & North Africa USShow more US US Economy Investing in America US Companies US Politics & Policy US Presidential Election 2024 CompaniesShow more Companies Energy Financials Health Industrials Media Professional Services Retail & Consumer Tech Sector Telecoms Transport TechShow more Tech Artificial intelligence Semiconductors Cyber Security Social Media MarketsShow more Markets Alphaville Markets Data Cryptofinance Capital Markets Commodities Currencies Equities Wealth Management Moral Money ETF Hub Fund Management Trading Climate OpinionShow more Opinion Columnists The FT View The Big Read Lex Obituaries Letters Lex Work & CareersShow more Work & Careers Business School Rankings Business Education Europe's Start-Up Hubs Entrepreneurship Recruitment Business Books Business Travel Working It Life & ArtsShow more Life & Arts Arts Books Food & Drink FT Magazine House & Home Style Travel FT Globetrotter Personal FinanceShow more Personal Finance Property & Mortgages Investments Pensions Tax Banking & Savings Advice & Comment Next Act HTSI Special Reports FT recommends Alphaville FT Edit Lunch with the FT FT Globetrotter #techAsia Moral Money Visual and data journalism Newsletters Video Podcasts News feed FT Live Events FT Forums Board Director Programme myFT Feed Portfolio FT Digital Edition Crossword Our Apps Help Centre Subscribe Sign In",
    "commentLink": "https://news.ycombinator.com/item?id=40926648",
    "commentBody": "AMD to buy Silo AI for $665M (ft.com)322 points by helsinkiandrew 5 hours agohidepastfavorite160 comments helsinkiandrew 5 hours agohttps://archive.ph/33O61 mastax 4 hours agoprevI’d argue that a factor in CUDA’s success is their army of in-house researchers which use CUDA to do novel things. Sometimes those things get turned into products (OptiX) other times they are essentially DevRel to show off what the hardware can do and documentation for how to do it. Additionally I’m sure they use pre-release hardware and software and give feedback about how to improve it. I don’t know what AMD has in mind for this acquisition but I could see there being a lot of value having an in house LLM team to create models for customers to build on, run in benchmarks, and improve their products. reply cityofdelusion 3 minutes agoparentThe success of CUDA is basically a dual effect of AMD devices being inefficient and bad for years, plus AMD having no answer to CUDA for a solid 7+ years while the foundations of GPGPU were being laid down. Mindshare shifts slowly. reply eightysixfour 4 hours agoparentprevYes, nvidia spends a lot of time and money developing software that induces demand for their GPUs. reply xyst 1 hour agorootparentNvidia also spends a metric shit ton of money to make sure professors use and teach on their platform. I don’t remember any alternatives in uni. Maybe OpenCL but only lightly mentioned reply helloericsf 56 minutes agorootparentOpenCL was discussed more frequently in classes about a decade ago. However, I haven't heard it mentioned in the last five years or so. reply light_hue_1 38 minutes agorootparentprev> Nvidia also spends a metric shit ton of money to make sure professors use and teach on their platform. Nah. People teach what they use because that's what's easy. reply Izikiel43 1 hour agorootparentprevOpencl is horrible compared to cuda reply KeplerBoy 3 hours agorootparentprevThe biggest frameworks are still from other players though. Pytorch, tensorflow and jax aren't funded by Nvidia. reply stanleykm 3 hours agorootparentBut they are built on top of nvidia tooling and you can use nvidia tools to do more extensive profiling than other players offer. reply KeplerBoy 2 hours agorootparentTrue, gotta love Nsight Systems and Compute. That's the first hurdle of working with AMD GPUs, I have no idea what the GPU is actually doing because there is no quality profiler. reply Conscat 2 hours agorootparentIs Omniperf/Omnitrace not very good? I haven't used it, but I have been using Nsight Systems recently and it looks comparable to me at a glance. reply mcbuilder 2 hours agorootparentprevNo way would any of those have any have bindings to backend libraries like cuDNN. reply SSLy 5 hours agoprevMy cursory understanding is that Silo is a developer of LLMs that run on top of compute platforms. Isn't the problem with no one using AMD's accelerators the fact that their programming environment is sub-par compared to CUDA, or even Apple's? reply btown 3 hours agoparentThe underinvestment in, and abandonment of, a project for a CUDA compatibility layer https://github.com/vosen/ZLUDA?tab=readme-ov-file#faq by AMD a few months ago hints that they no longer see CUDA compatibility as a goal. Perhaps they see Silo as a way to jumpstart bringing ROCm to parity with CUDA's toolkit. It's hard to understand if there's an underlying strategy to how they'll stay relevant from a software perspective when they're abandoning projects like this. Discussion: https://news.ycombinator.com/item?id=39344815 reply IshKebab 13 minutes agorootparentIt makes no business sense for them to try to get CUDA compatibility. That would just cement CUDA as the de facto standard, at which point they are locked in to playing catch up forever as nVidia intentionally adds features to break compatibility. Much more sensible to work on getting rock solid support for their own standards into all the major ML platforms/libraries. reply seunosewa 2 hours agorootparentprevThat's an unfortunate choice. AMD has excelled in making compatible hardware. Not so much software success, if any. reply doikor 4 hours agoparentprevThey have been using/building stuff for the LUMI supercomputer which has a bit over 12000 MI250X https://ir.amd.com/news-events/press-releases/detail/1206/am... “Silo AI has been a pioneer in scaling large language model training on LUMI, Europe’s fastest supercomputer powered by over 12,000 AMD Instinct MI250X GPUs,” reply anewhnaccount2 5 hours agoparentprevThey successfully trained LLMs on Lumi, which has AMD Instinct MI250X GPUs. This perhaps provides a hint about one angle on why AMD are interested. reply zacksiri 4 hours agorootparentIt makes sense then for AMD to buy them out. If they’ve trained LLMs with lumi which has a lot of instinct GPUs there is a high chance they’ve had to work through and solve a lot of the gaps in software support from AMD. They may have already figured out a lot of stuff and kept it all proprietary and AMD buying them out is a quick way to get access to all the solutions. I suspect AMD is trying to fast track their software stack and this acquisition allows them to do just that. reply rcarmo 3 hours agorootparentI am curious if the models are any good, though. The landscape is so fragmented I never heard of Poro. reply ghnws 3 hours agorootparentPoro (reindeer in finnish) is specifically developed to be used in Finnish. GPT etc. general models struggle with less used languages. Unfortunately this sale likely means this development will cease. reply hrududuu 2 hours agorootparentGpt4 or even 3.5 is quite good at Finnish. Was there ever a benchmark against closed source models? reply pantalaimon 3 hours agorootparentprevSo AMD wants to know how they did it, understand. reply antupis 1 hour agoparentprevSilo mainly does consulting and those models were kinda done on side. But great for founders and truly weird acquisition for AMD. reply pjietr 1 hour agoparentprevSilo.ai is mostly a consulting house for various proof-of-concept type of projects with the LLM product being only the recent addition reply Keyframe 2 hours agoparentprevMaybe they can use LLMs now to program their platform for them?reply csomar 5 hours agoparentprevSure, buying this company for 600m will fix everything. reply sqeaky 4 hours agorootparentThat is the most sarcastic thing I have read in weeks. But isn't getting a software stack the exact kind of thing they need? Is there no overlap in the skills at the purchased company and the skills needed to make the AMD software stack not suck? reply baobabKoodaa 4 hours agorootparentSure, there is some overlap. Is that overlap worth 665M? reply rvnx 4 hours agorootparentYes, it brought instantly (at least partially) +12B USD on the valuation of AMD. This shows to investors that AMD is still in the race. reply drexlspivey 2 hours agorootparentYou shouldn't attribute that on the acquisition. The stock went 3.8% up today but also 4% up on monday, 4.8% up last Friday 4.2% up last Tuesday etc. reply baobabKoodaa 4 hours agorootparentprevYeah I saw the stock market uptick, but that is a kneejerk reaction by the public markets. It's not as if the public market participants have had ample time to evaluate the merits of the acquisition, and even then, if they are right or not. reply szundi 2 hours agorootparentAnyway, it seems market thinks this is a 20x value acquisition. reply lyu07282 3 hours agorootparentprevThat assumes that the reason AMD's software stack sucks is because of skill, not company culture, management or other reasons that won't change with this acquisition. reply throwway120385 3 hours agorootparentIf it's a culture problem and the C-suite is aware of it, then one reason to buy a company with a working software stack is to percolate their culture into your company so you can be successful. reply szundi 2 hours agorootparentHopefully the ceo of the acquired company gets a director role in AMD then at least, not subordinated a supposedly subpar cultured director already in AMD reply aardvarkr 2 hours agorootparentprevI have a friend working there and it's a bunch of old curmudgeons stuck in their way. Good luck changing culture with a single acquisition reply throwway120385 1 hour agorootparentThe company I used to work for is doing this to the engineering org in my current employer. It requires the leadership from the old company to be embedded in very senior positions, and it requires buy-in from the existing C-suite. There's a lot of backroom politics to change culture along with a bunch of work to prove yourselves to people who aren't involved in the backroom. There have been a bunch of points at which I didn't think it would continue but so far the original team has been pretty successful at rising. Think of it as a reverse McDonnell-Douglas. reply imtringued 29 minutes agorootparentprevI also have this impression. The software problems that are plaguing AMD are in the \"less than $10 million\" range, if they hired the right people to work on the most severe bugs in their GPU drivers and let them do their job. reply eysgshsvsvsv 4 hours agorootparentprevYou all live in a simple world where complex systems are fixed in simple statements like software stack is all they need. reply sqeaky 4 hours agorootparentWhy the personal attack? I said that I interpreted the previous comment as sarcastic so I could be called out if it wasn't. The author hasn't yet disagreed. And I think sarcasm is warranted in a space that has witnessed so many bad acquisitions. On software at AMD; if my world is so simple, please explain where I am wrong. I never said this was a simple solution, I implied there was some overlap needed skills. ROCm sucks, it has licensing and apparently use issues. It has had performance issues, and that is getting better. It isn't in a lot of the places it needs to be where it could be considered a default choice. Apparently, Silo uses AMD stuff to do ML work. Apparently, they have domain experts in this space. It seems likely that getting input from such people could positively influence the ML and hardware. Of course there will be complexity in this process. This is a 600 million dollar deal involving thousands of people (not just Silo employee, but AMD people, regulators, stakeholders, etc). I don't think anyone is implying this is simple. I only wanted to say, \"This isn't obviously dumb\". reply mindcrime 4 hours agorootparentI'm curious about these \"licensing issues\" you speak of. From what I've seen, the vast majority of the ROCm components are MIT licensed, with a few bits of Apache license and NCSA Open Source License mixed in. Could you possibly elaborate on that? reply rdtsc 4 hours agorootparentprevWhat do you think they should do? reply anonym29 4 hours agorootparentprev\"fix\"? What is there to fix? AMD has been simultaneously fighting Intel and Nvidia, two MUCH larger companies, and it's been winning the fight against Intel for close to a decade now. It's certainly not Lisa Su's fault that the clowns over at Intel got stuck on variations of 14nm (with clever marketing names like 14nm+++++) for nearly a decade, but credit certainly is hers for introducing Zen and putting AMD back on top of the x86 market. With the new x870(e) motherboards and Granite Ridge chips right around the corner, effortlessly destroying the pyrotechnic processing units known as Raptor Lake, it's honestly a miracle to me that Intel's stock price is still as high as it is. Guess wall street still loves those billions of forcefully confiscated taxpayer dollars being doled out by Uncle Sam to a graying dinosaur like Intel who couldn't even compete without those handouts... the quality of their marketplace offerings certainly isn't what's keeping that valuation up! reply philistine 4 hours agorootparentI’m also bullish on Intel, but clearly not as much as you. Intel is transitioning right now. x86 is never going to reclaim the crown of most important architecture, so Intel is trying its best to become a foundry for all the fabless customers out there. It’s going to take a long while, but right now they’re the best company to compete with TSMC in ten years. If Apple uses their foundries next decade, you’ll know Intel is back on top. reply seabird 4 hours agorootparentprevThis site is full of people with the west coast VC-driven-tech bizarro world blinders on. If AMD just keeps at what they've been doing well (matching or beating Intel processors) instead of chasing after the latest buzzword grift bubble, they're doomed in the eyes of people with that mindset. reply throwway120385 3 hours agorootparentAMD needs to expand the user base of their GPUs away from gaming and desktop graphics. Buying an AI company that is using their stack for compute is a really good way of learning how to do that. It's essentially now an in-house team to dogfood all of your brand new products and tell your other engineering teams what they're doing wrong. In my mind it's not about AI per se, but about using the hot use case for GPU to drive meaningful change in your software stack. There are tons and tons and tons of GPGPU users out there who aren't training LLMs but who need a high-quality compute stack. reply mandevil 1 hour agorootparentprevI think AMD's concern is that x86 might not be much of a market in 10 years. Between Apple, Amazon Graviton, and Nvidia Grace Hopper's ARM CPU we are seeing a sustained successful attack on x86 the likes of which we haven't seen... ever? Sustained and successful non-x86 Desktops, servers, and next-gen datacenter platforms, where does that leave AMD? (Intel has a little more diversification because of it's foundry opportunities, but is in the same boat.) reply light_hue_1 34 minutes agorootparentprev> \"fix\"? What is there to fix? AMD has been simultaneously fighting Intel and Nvidia, two MUCH larger companies, and it's been winning the fight against Intel for close to a decade now. There's everything to fix. AMD is sitting on a gold mine and is squandering massive amounts of money every month that they don't just get their shitty software stack in order. AMD could be as rich as NVIDIA. Instead, Lisa Su for some insane reason refuses to build even the most mediocre ML-capable libraries for their GPUs. If I could ask anyone in the ML world at the moment what the heck they're thinking, it would be her. Nothing makes sense about AMDs actions for years on this topic. If I was the board, I'd be talking about her exit for wasting such an opportunity. reply thenaturalist 5 hours agoprevHuge congratulations to the founders and what a nice mark for the European (and Nordirc) startup community. It's gonna be quite interesting to see if this works out strategically. I guess the bet is an in-house army of PhDs vs. having a CUDA - which you don't as a second mover here - and assuming PhDs tightly coupled with the hardware can outperform an open framework/ push Triton to parity to CUDA over time. reply sva_ 5 hours agoparentCongrats to the founders indeed, but > what a nice mark for the European (and Nordirc) startup community. Not sure if it is a great win for the EU at large if their AI startups get bought up by American companies though, to be fair. reply thenaturalist 4 hours agorootparentThe economy and startup world isn't a zero sum game. Ultimately the AI play* is open source for the foreseeable future, even more so for AMD if they want to sell their chips. And if Silo AI's people accelerate competition in the AI HW space by accelerating Triton development/ raising the industry's competitive edge against Nvidia, we all benefit from stronger competition. And in most other European startup hot spots, senior staff/ founders with previous exits reinvested their earnings into the domestic startup scene through founding again or becoming Business Angels or going VC. I see this as a huge net win. * EDIT: For integrating with compute, I guess. reply 627467 4 hours agorootparentActually, it is zero sum. there's finite resources, human talent, and centers for decision making. yeah, European startup gets American money today, and American decision making center grows larger. whether the money paid into Europeans now is used to prop up new generation of startups - in any meaningful way - will remain to be seen. most likely: these senior staff/founders will probably allocate their cash where it is more efficient and I doubt it will be (meaningfully) in europe reply thenaturalist 3 hours agorootparentThe fact you're posting this comment in a thread of a press release of the acquisition of a European startup entity is in itself a counterfactual, wouldn't you agree? One of the Cofounders of Silo is ex-Nokia... Should tell you everything about zero-sum games. Sure, the US is the dominant financial and technological economy on the planet and that will not change for the foreseeable future. But implying a globalized, technology enabled economy will behave in a zero-sum fashion is just plain wrong. The US is where it is today because post WWII it geniously recognized the value of free and global trade and invested heavily in its Navy to enable and protect said trade. Instead of making things on your own in the US, you could sit in New York and invest globally - the value of your investment and access to its dividends guaranteed by the power of the US military. Relative value against the status quo is created every day everywhere by millions of smart people. What Europe - and Finland in that example - has is a century old tradition and established infrastructure for high education. That investment will continue to pay off for the foreseeable future. reply singhrac 3 hours agorootparentprevI’m not sure we agree on what zero sum here means, but one direct consequence of having a decent exit here is that the investors in Silo will get a capital return they can use to raise more funds. I don’t know what the founders of Silo will do, but the investors are in the business of investing, and incrementally the viability of being an AI VC in this area has gone up (depends on the counterfactual but I think cash exit is better than some chance of IPO). reply bee_rider 3 hours agorootparentprevDon’t European programmers make much less than Americans? I wouldn’t be surprised if they kept a pretty big footprint over there. Big picture the US unemployment rate is quite a bit lower than the EU, so I’m sure any global company is happy to draw from the bigger pool. Finally, benefits can be unbalanced in favor of one entity or another without being zero sum. Even if the US benefits more from this deal, the purchasing company, AMD, still turns sand into extremely valuable electronics. That’s not a zero-sum activity. reply mgfist 3 hours agorootparentprevYou say it's zero-sum then in the next sentence say \"whether the money paid into Europeans now is used to prop up new generation of startups - in any meaningful way - will remain to be seen\", which surely implies that it's not necessarily zero-sum. reply blackhawkC17 4 hours agorootparentprevEurope’s tech ecosystem will still benefit a lot regardless. Zero-sum thinking is not good- it causes economic regression and poverty in the long run. reply fauigerzigerk 4 hours agorootparentprev>Not sure if it is a great win for the EU at large if their AI startups get bought up by American companies though, to be fair. That would be a concern if the plan was to move the entire team to the US. But if the Finland based company just becomes a part of AMD then I see little downside. Some very competent people in Finland now have $665M to fund new startups. Ultimately I think the most important question is where the interesting and high productivity work gets done. That's the place that benefits most. reply Rinzler89 3 hours agorootparent>That would be a concern if the plan was to move the entire team to the US. The issue is that all that Finnish labor now fuels a US tech giant who's profit center is in the US, not in EU, therefore mostly boosting the US economy in the process. Then there's also the trade barriers that come with now becoming a US tech company instead of a Finnish one. You can't sell to China, and other countries on the US's shit list without Uncle Sam's approval. reply fauigerzigerk 57 minutes agorootparent>The issue is that all that Finnish labor now fuels a US tech giant who's profit center is in the US, not in EU, therefore mostly boosting the US economy in the process. No, this is not how it works. Assuming Silo AI continues to operate out of Finland, its investments, the consumption of its employees and its exports will continue to count towards Finland's GDP just like before. Any profits go to AMD shareholders all over the world, not just in the US. The strategic alignment between Silo AI and AMD may well benefit both Finland and the US. We have a similar debate in the UK regarding DeepMind. And yes it's true, if you assume that DeepMind or Silo AI would have become world dominating tech behemoths in their own right, then it would have been better for Britain/Finland if they hadn't been sold. But it's also possible that the UK and Finish operations are ultimately more successful as part of Google/AMD because they benefit from strategic opportunities they wouldn't otherwise have. I'm not saying that headquarters don't matter or that there are no downsides (e.g wrt corporation tax). What I am saying is that it's not automatically a bad thing for a country if a company gets sold to a foreign corporation. One thing is for sure. It's far better to have a lot of US subsidiaries in the country than watching your graduates and startup founders leave for the US. reply pjc50 3 hours agorootparentprev> US tech giant who's profit center is in the US, not in EU, therefore mostly boosting the US economy in the process More of a matter of accounting than reality. For years, Apple were deliberately not repatriating their profits to avoid tax, keeping them out of the US economy. https://www.cnbc.com/2018/01/17/it-looks-like-apple-is-bring... The question of where a profit is actually made for a multinational company can be very unclear. reply mistrial9 4 hours agoparentprevthey have loyal and stable staff with healthy family lives unlike 8 of 10 California companies reply blackhawkC17 4 hours agorootparentEmployee loyalty isn’t a good thing. One of the best things about Silicon Valley is that people can swiftly change companies when they get higher offers. Non-competes are void in California. There’s a reason US salaries for software devs are 2-5x EU salaries for similar roles. reply snowpid 2 hours agorootparentWhat if I told you that non - competes aren't a thing in Germany. (And a big part in other parts of US) reply storyinmemo 2 hours agorootparentWell I'd tell you that they aren't a thing in California. reply talldayo 1 hour agorootparent...as of six months ago. reply Alupis 4 minutes agorootparentAnyone could ask you to sign a non-compete. But in California, they have been legally unenforceable for as long as I have been alive. What was changed is they now cannot make condition of employment based on signing this unenforceable contract. p_j_w 54 minutes agorootparentprev>There’s a reason US salaries for software devs are 2-5x EU salaries for similar roles. When you account for medical costs, rent (especially compared to the localities in the USA that provide these huge salaries), extra vacation time, and for those with children, education and child care, this gap narrows considerably. Rent alone... one can find a reasonable spot in Berlin for ~$1300/mo. Good luck finding more than a shared box in the Tenderloin for that much in the Bay Area. reply blackhawkC17 40 minutes agorootparent> When you account for medical costs, rent (especially compared to the localities in the USA that provide these huge salaries), extra vacation time, and for those with children, education and child care, this gap narrows considerably. That's what Europeans generally say to justify or cope with their low salaries, but it's not true. After accounting for all these, an SV, NYC, Seattle, etc., engineer ends up with far more disposable income than their EU counterpart. The US has the highest average disposable income worldwide; the rest almost don't come close [1]. That's why it has much more entrepreneurial activity. Yes, the US isn't perfect, but the EU doesn't come close to the US in terms of money for highly skilled professional workers. 1- https://www.statista.com/statistics/725764/oecd-household-di... reply p_j_w 10 minutes agorootparent>After accounting for all these, an SV, NYC, Seattle, etc., engineer ends up with far more disposable income than their EU counterpart. I said it narrows the gap, not closes it. >https://www.statista.com/statistics/725764/oecd-household-di... Your link is behind a paywall, I can't view that data. reply rangestransform 1 hour agorootparentprevemployee loyalty is a good thing if it's bought and not expected reply littlecranky67 4 hours agoprevI've been thinking that NVDA stock is massively overpriced - yes, AI is a hot topic, but their only advantage is the software stack. It is just a matter of time until Intel and AMD realize that they should join hands and do an open-source CUDA alternative for their respecitve GPUs (yes, Intel has competetive GPUs and just like AMD and Nvidia they will try to get a share of the AI chip market share). reply cityofdelusion 5 minutes agoparentProblem is the CUDA advantage is gigantic and it has been known for years in GPGPU processing, way before AI was a meme. AMD has lost countless developers over the year just on hello world style projects. Developers had a solid 6-7 years of living with OpenCL when the green rival had a very mature and nice CUDA sitting there. I’ve been out of that world for a while now, but it was truly painful and turned a lot of devs off programming AMD devices. Now there’s a big moat of entrenched developers that could take decades to displace. It’s like trying to displace C++ with Java 22 — possible, but it’s a slow, slow trudge and everyone still remembers Java 1.4 reply airstrike 4 hours agoparentprev\"just\" a matter of time... If it were that easy, it would have already been done, or so they say. Also don't forget network effects reply nipponese 56 minutes agoparentprevNVDA P/E ratio 78.70 AMD P/E ratio 263.25 If NVDA is overpriced, AMD is REALLY over-priced. reply hmm37 29 minutes agorootparentAMD PE ratio is that high due to their purchase of Xilinx. It's forward PE ratio is much much lower, in the 50s. reply dehrmann 2 hours agoparentprevNVDA's moat is over-stated. There are several deep-pocketed players with pretty good AI chips. The big players are training models at such a large scale that they can afford to back them by different architectures. Smaller players use frameworks like Pytorch and Tensorflow, but those are backed by big players buying from Nvidia. But valuation isn't the NVDA trade right now; it's that there's still a bigger fool. reply nabla9 2 hours agoparentprev> Intel has competitive GPUs No they don't. Both Intel and AMD compare their newest GPU favorably against Nvidia's H100 that has been on the market longer and soon to be replaced and then it's never H100 NVL for a reason. Intel and AMD can sell their GPU's only with lower profit margin. If they could match FLOPS per total ownership they would sell much better. Both are years behind. reply latchkey 2 hours agorootparentBenchmarks were just run, MI300x is onpar/better than an H100. Next generation of MI (MI325x) is coming out end of the year and those specs look fantastic too. Especially on the all important memory front. 288GB is fantastic. Both companies will leapfrog each other with new releases. Anyone who believes that there should only be a single vendor for all AI compute will quickly find themselves on the wrong side of history reply talldayo 1 hour agorootparent> 288GB is fantastic This reminds me of those \"192GB is fantastic\" people that bought maxed-out M2 Ultras for AI inference. It can be awesome, but you need a substantial amount of interconnect bandwidth and powerful enough local compute before it's competitive. In products where AI is an afterthought, you're fighting against much different constraints than just having a lot of high-bandwidth memory. I've always rooted for Team Red when they made an effort to do things open-source and transparently. They're a good role-model for the rest of the industry, in a certain sense. But I have to make peace with the fact that client-side AI running on my AMD machines isn't happening. Meanwhile, I've been using CUDA, CUDNN, CUBLAS, DLSS, on my Nvidia machine for years. On Linux! reply nabla9 1 hour agorootparentprevComparisons against H100 I have seen are always: 8x AMD MI300X (192GB, 750W) 8x H100 SXM5 (80GB, 700W) Never against 8x H100 NVL (188GB,Never against 8x H100 NVL (188GB,What the customer does not see is how AMD must spend 8-10 times more money to produce a chip that is competitive against architecture that is soon 2 years old. Source? reply breggles 4 hours agoparentprev\"AMD is among several companies contributing to the development of an OpenAI-led rival to Cuda, called Triton, which would let AI developers switch more easily between chip providers. Meta, Microsoft and Intel have also worked on Triton.\" Last paragraph reply singhrac 3 hours agorootparentThis is a bit misleading since Triton is a bit higher level than CUDA. But the idea is kind of right - there’s active development of AMD and Intel backends, and Pytorch is investing into Triton as well. reply RyanShook 4 hours agoparentprev2024 YTD returns: NVDA 172% AMD 27% INTC -30% reply cj 2 hours agorootparentStocks of companies that develop extremely niche and technical things is a tiny sliver of the stock market that I actually think communities like HN would be better at valuing than the market. Technology stocks are the only ones I personally day trade for that reason. Example: at the beginning of a pandemic lockdowns, any HN user could have anticipated increased internet usage and buy Cloudflare/Fastly stock and made a lot of money before the rest of the market realized that CDN companies will significantly benefit from that specific macro event. I'm not convinced the market (or market analysts) have a deep understanding of Nividia's long-term advantage. If they did, we would have seen a much slower and steadier valuation increase rather than the meteoric rise. Meteoric stock price rise/fall = the market is having trouble valuing the stock. In other words, stock prices don't add much to the conversation. reply storyinmemo 2 hours agorootparentIntel's profit, and revenue, have declined for 3 consecutive years. Their price to earnings ratio is 36. Nvidia's revenue is now greater than Intel's with 20% of the employees that Intel has. Their PE ratio is 78, roughly double that of Intel. The market valued Nvidia as growing and Intel as not. reply wmf 4 hours agoparentprevThey've been working on that for years. reply dylan604 3 hours agorootparentYeah? And? So? As if CUDA was developed overnight and never worked on again. Such a weak comment reply zokier 3 hours agorootparentAMD has been working on GPGPU at least as long as nVidia. AMDs \"CTM\" SDK was released in 2006, same year as CUDA. In 2007 they released Stream SDK. Then they had \"APP SDK\" for a while, which iirc coincided with their opencl phase. And now they landed on rocm. Meanwhile nvidia has kept trucking with just CUDA. reply _flux 5 hours agoprevNice to see AMD finally doing something about competing in the compute market (LLM being the hottest thing at the moment)! Though apparently MI300X is a fine product as well. But it still needs code. reply baobabKoodaa 4 hours agoprevHappy to see this acquisition landing in Finland, but I have to wonder how the purchase price is justified. Silo AI is primarily a consulting company doing \"traditional\" kinds of AI consulting projects. Their LLM project is like a side hustle for the company. reply bee_rider 4 hours agoparentLooking at their “about” page, https://www.silo.ai/about It looks like 300 “AI experts” employed. So I guess they have paid $2M a pop. I’m not sure how to put that into perspective really, though… reply throw0101c 3 hours agorootparent> It looks like 300 “AI experts” employed. So I guess they have paid $2M a pop. What was the per employee acquisition cost of WhatsApp (who had 50 employees, IIRC)? reply dghlsakjg 2 hours agorootparentWhen acquiring a telecommunications network, I suspect that network size (user count) is far more relevant for valuation, if anything, having a low employee count with a massive network like WhatsApp was probably a huge selling point. reply nicce 4 hours agoparentprevPersonally, I am bit sad that nothing stays in Finland. Too many promising companies have been sold into foreign countries recently. Just because founders look for exit strategy (not claiming that it is the case here). Not good for Finland in general. reply baobabKoodaa 4 hours agorootparentWell, in this case the purchase price appears grossly overpriced. So even though Finland lost an AI startup, it gained money that is worth more than the startup. That money will to a large extent flow back into the Finnish economy in the form of taxes, investment in new startups, etc. reply nicce 3 hours agorootparent> That money will to a large extent flow back into the Finnish economy in the form of taxes, investment in new startups, etc. Short term gains, in terms of taxes. Otherwise, there are no guarantees for that. Shareholders might just make some castle. Who knows. Or move away to different country. reply thenaturalist 3 hours agorootparent> Shareholders might just make some castle. And then be left with nothing? Look at Silo's About page. The people who started this are not slackers or already had so much money before that they could have bought a 3rd Porsche. Do you think these people will pull back and do nothing as their ability to benefit from and shape the technological advances happening just increases with this exit? I highly doubt that. > Or move away to different country. And then? Capital is global. And as per these [0] statistics, Finland is ranked 4th for per capita VC money invested in 2018, far ahead of France and Germany. As per this [1] article from May, Finland received the most private equity and VC investment adjusted for GDP in all of Europe in 2023. Finland is an attractive country to invest in, and I highly doubt native speakers with an excellent local network - i.e. much more expertise than the average non-Finnish speaking invesotor - will not be aware of that and capitalize on it. [0]: https://www.statista.com/statistics/879124/venture-capital-a... [1]: https://www.goodnewsfinland.com/en/articles/breaking-news/20... reply Ekaros 46 minutes agorootparentprevI'm more so for taking money off the table when possible. Future returns are future returns, they can materialize, but might not. reply nicce 29 minutes agorootparentBut if that happens (almost) every time for a potential company, then you will never likely have successful company in Finland, where the decision making also stays in Finland, and the money benefits the country in larger scale. There is this saying that \"don't sell the cow when you can sell the milk\" - maybe there is still some wisdom... but Finland keeps selling the cow and buying the milk back over and over again. And then they wonder why the state of the economy is so sad and they never see \"new Nokia\". reply bjornsing 2 hours agorootparentprevBut hats off to Finland for producing these companies. Here in Sweden there’s pretty much nothing in cloud computing or AI, AFAIK. reply kakoni 54 minutes agorootparentWell in Finland we seem to produce promising \"early-stage\" companies which are then eagerly sold to bigger players. Vs in Sweden there is will (and capital) to keep growing these. reply getcrunk 18 minutes agoprevI’m still pissed they finally brought rocm support to their Gpgus on windows starting with the 6800xt … I have the 6700xt reply mindcrime 19 minutes agoprevI don't know how this specific acquisition is going to work out, but at least we can say one thing. This represents some kind of response to the constant chorus of \"AMD don't appreciate the importance of software. AMD should invest more in software. CUDA, CUDA, CUDA\" comments that one always hears when AMD is mentioned. Of course there's room to debate the details here: would they have, perhaps, been better off investing that money in their existing software team(s)? Or spinning up (a) new team(s) from scatch? Who's to say. But at least it show some intention on their behalf to beef up their software stance, and generally speaking that feels like a positive step to me. But then again, I'm an AMD fan boi who is invested in the ROCm ecosystem, so I'm not entirely unbiased. But I think the overall point stands, regardless of that. reply AlotOfReading 9 minutes agoparentAMD has also been doing a bunch of hiring for their software teams. I've seen a few colleagues that AMD previously couldn't have afforded accept offers to work on GPU stuff. reply trhway 2 minutes agoprev$2M/head. That is a steal, even by European standards. \"In July 2024, Silo AI has 300+ employees out of which 125+ hold a PhD degree.\" reply jacobgorm 4 hours agoprevThis happened after Silo trained an LLM on the AMD-powered LUMI supercomputer. reply petesergeant 4 hours agoparentSeems like an excellent exit strategy in hindsight. Spend a gazillion dollars of investor money on AMD hardware, get bought back by AMD because you worked out how to use that hardware reply jacobgorm 3 hours agorootparentExcept the EU paid for the hardware https://eurohpc-ju.europa.eu/supercomputers/our-supercompute... reply baobabKoodaa 1 hour agorootparentWhere in that source does it claim that Silo didn't have to pay to use the hardware? reply Pandabob 3 hours agorootparentprevCame here to point this out. Silo never had to invest huge amounts on GPUs. A shrewd move by the founders. reply rubatuga 2 hours agorootparentThere is debate about public investment into private ventures, but in this case it may provide long term benefits to Finland reply petesergeant 2 hours agorootparentprevEven better! reply high_na_euv 5 hours agoprevWhat are they going to give AMD that they are priced this high? reply thenaturalist 5 hours agoparentExpert talent and prob some in house tech. Mainly talent I guess which they can put to accelerating Triton development, their alternative to CUDA. reply duxup 4 hours agorootparentDoes the desirable talent in this case have equity / future vesting equity that is a part of the price? I just wonder as many decades ago I was a part of a company who wanted to get into a market, they bought a little start up, and over the course of a year everyone quit, and the project eventually folded entirely ;) It was sorta hilarious, but also bizarre that the acquiring company didn't think of that. reply thenaturalist 4 hours agorootparentI mean buying a \"private AI lab\" doesn't sound to me like they have the purchase price worth in IP which is so desirable nobody else has unlocked it and it lends itself particularly well to being integrated with AMD tech? Let's see if more details come to light, but a good part of that price is spent for sure on people. It'd be hilarious indeed if they wouldn't be able to or haven't properly incentivized them to retain them. reply stanleykm 3 hours agorootparentprevDid you mean ROCm? afaik Triton is a python framework that sits on top of CUDA and ROCm. reply pavlov 4 hours agoprevThe economic mood in Finland is downright depressed [1]. This kind of news is therefore extremely welcome because it indicates there's a way forward, out of the old industry doldrums where people are still moaning about closed paper mills and Nokia's failure 15 years ago. $665M USD isn't a staggering number by Silicon Valley standards, but it's very significant for a nation of five million people that hasn't seen global startup successes like neighboring Sweden with Spotify and others. [1] The actual level of depression is somewhat hard to track because Finns are always pessimistic regardless of how well they're doing. (This also makes them the happiest people on Earth in polls. The situation right now is never quite as bad as one had expected beforehand, so when a pollster calls to ask, the conclusion must be that they're pretty happy with things overall at that specific moment, but surely everything is going in the wrong direction anyway.) reply SebaSeba 3 hours agoparentContrary to what you say, Finnish startups have been very successful. Here's just a couple examples: - Supercell sold 81.4% stake to Tencent in 2018 with a valuation of $10.2 billion. - Wolt was acquired by DoorDash in 2021 with a valuation of $8.1 billion. The list is much longer with startups that currently generate revenues of tens or hundreds of millions in a year that have not been sold. reply pavlov 3 hours agorootparentThese two are great success stories, but they’re also the only Finnish unicorn exits in the post-Nokia era. The exits were somewhat less exciting to founders than these numbers suggest. Supercell sold 51% to SoftBank already in 2013 for 1.1B EUR. And Wolt’s purchase price was paid entirely in DoorDash stock which was down 75% by the time the lockups expired. Startups generating low-hundreds of millions in annual revenue just aren’t unicorns anymore, unless they happen to be AI. reply thenaturalist 3 hours agoparentprevIn 2023, Finland has received the highest investment of private equity and VC adjusted for GDP in all of Europe: https://www.goodnewsfinland.com/en/articles/breaking-news/20... reply pavlov 3 hours agorootparentWhich is great, but doesn’t move the needle of popular perception the same way as large acquisitions and IPOs do. The start of the startup investment pipeline in Finland has been flowing pretty well. The outputs at the end of the pipeline have been more questionable. Silo’s acquisition is a positive example of activity at that end. reply airstrike 4 hours agoprevFree Reuters article: https://www.reuters.com/markets/deals/amd-acquire-finnish-st... Joint AMD / Silo AI press release: https://ir.amd.com/news-events/press-releases/detail/1206/am... reply Aaronstotle 5 hours agoprevThis and the MI300x makes me hopeful for AMD reply latchkey 4 hours agoparentIt really is a fantastic piece of hardware. We just need the software to catch up. reply dotnet00 4 hours agorootparentWhich tbf has been an apt description of AMD GPUs for the better part of a decade. Great hardware, god awful software and even worse long term software strategy. It's why the 'fine wine' spin on the long term performance of AMD GPUs exists in gaming circles. reply latchkey 2 hours agorootparentYou're totally right. That said, spending $665m on an AI company seems, at first glance, like a step in the right direction. I'm sure there are a 1000 ways they could have spent that much money, but hey... I do appreciate them at least trying to do something to resolve the issue. Another way to think of it is that now there is a whole team that isn't dedicated to nvidia. reply dotnet00 2 hours agorootparentYeah I'm not arguing against this acquisition, just commenting on how things have been so far. At this point I'm kind of apathetic, it's good if whatever they do eventually leads them to fixing their software woes, and I'll come back to their stuff then. If not, I'm fine with sticking to CUDA for now. Ultimately they're all GPU programming languages, once you're good with one, switching to another one is not that hard (as long as the supporting software is good of course). reply daghamm 4 hours agoprevSince FT is paywalled and the press release link from Silo is currently pointig to nowhere: https://www.silo.ai/blog/amd-to-acquire-silo-ai-to-expand-en... I've no idea what is going on. This is 5 times bigger than their combined AI acquisitions in the last 12 months. The only link between Silo and AMD is that Silo has been using an AMD accelerator cluster for training. reply cooper_ganglia 4 hours agoparentI honestly don't understand how paywalled links get so much traction, most people probably can't even engage with the material. Thanks for the direct link to Silo AI's press release! reply idunnoman1222 1 hour agorootparentBecause everyone knows how to use archive.org reply thenaturalist 4 hours agorootparentprevSee @helsinkiandrews comment, he posted the de-paywalled link: https://archive.ph/33O61 reply woadwarrior01 5 hours agoprevLooks like a consulting company[1] at first glance. Also, empty HuggingFace account[2]. [1]: https://www.silo.ai/ [2]: https://huggingface.co/SiloAI reply anewhnaccount2 5 hours agoparentThe models are here: https://huggingface.co/LumiOpen reply baobabKoodaa 4 hours agoparentprevWho is downvoting this? You are correct. Silo.AI is a consulting company with an LLM side hustle. This acquisition is weird. reply m3kw9 3 hours agorootparentLooks like they have expertise in using AMD gpus to train LLMs and will be tasked to catch up to cuda reply wantsanagent 3 hours agoprevI'm curious how this deal happened. There are a lot of LLM shops out there, how did this nordic co get the attention of AMD and why did they think this co stood out among the crowd. reply m3kw9 3 hours agoparentThey had their team use AMD to train LLMs reply Workaccount2 4 hours agoprevImagine AMD simply put that $665M into tooling and driver development. The stock probably would have doubled. reply thenaturalist 4 hours agoparentWhat's the difference to what they did in this acquisition? Who's gonna improve tooling and develop drivers? PhD level AI experts such as employed by Silo AI, probably, right? EDIT: For context [0], Nvidia invested billions into CUDA development way back when it was unsexy. Clearly a second mover won't need that much, Nvidia proved the market. But a billion doesn't seem like a large sum for the potential upside of AMD catching a significantly larger share of the budget going into AI - many times the value of this acquisition. 0: https://www.newyorker.com/magazine/2023/12/04/how-jensen-hua... reply Workaccount2 4 hours agorootparentPerhaps their goal is to develop an LLM and then prompt it to fix ROCm. reply duxup 4 hours agoparentprevI always wonder about these thought experiments. Given a few good talented people and good management ... you'd think they'd be able to put a team together, but maybe talent in this area is few / far between? To be clear, i'm not disagreeing, I really don't know, but yeah $665M, could do a lot with that. reply short_sells_poo 4 hours agorootparentYou are basically paying some premium for the fact that someone already did the hiring and built the talent pool and a cohesive team. Doing that from scratch is a multi-year project, so they basically bought a shortcut. reply duxup 2 hours agorootparentYeah I get the general idea that you're paying more for the assembled team and software / experience. It's just always wonky as acquisitions generally don't seem to be 100% known quantities / outcomes. People paying big premiums for what sometimes turn out to be nothing. That package of talent and etc is handy, but also seems like sometimes it makes it harder to really know what you'll get out of it. It's an interesting dynamic. reply speed_spread 4 hours agoparentprevThe org structure and culture dynamics of large companies like AMD makes it very difficult to achieve quality results when starting from scratch. 665M$ might well have been too much money, putting too much pressure for results for anything valuable to emerge. A 665M$ acquisition means they know exactly what they are getting, and they are getting it _now_. reply mistrial9 4 hours agorootparentalso note they paid in cash.. usually a premium in itself. reply petesergeant 4 hours agoparentprev> Imagine AMD simply put that $665M into tooling and driver development Feels like a company saying they're going to \"spend a few weeks paying down tech debt\", which generally amounts to nothing getting done. Progress happens in creative pursuit of another goal and with hard constraints, in my experience. You can fix a specific piece of tech debt while working on a product feature that's adjacent to it, and you can create some great tooling and drivers while working on a product that needs them, but just setting aside the money for greenfield development often/usually ends up with it being set alight. I have worked at least one very well-funded place where the lack of product focus and thus lack of any constraints has just led to endless wheel spinning under the guise of \"research\". reply bot0047 1 hour agoprevIf nVidia is IBM then AMD could be the next Microsoft. reply uptownfunk 1 hour agoprevSmells fishy anti trust reply hi 5 hours agoprevAnyone know a timeline for AMD on MLPerf? reply latchkey 4 hours agoparentIt won't be for a while. It really takes someone to focus on this and it isn't just AMD. The team at MLPerf will need to step in as well and from my discussions with them, they are busy enough as it is with their own goals. My company, Hot Aisle, has a box of mi300x (soon to be +16 more) that we have dedicated as a free resource to unbiased benchmarking. That's instigated articles like the Chips & Cheese one and the Nscale Elio post... https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi3... https://www.nscale.com/blog/nscale-benchmarks-amd-mi300x-gpu... reply georgehotz 4 hours agoparentprevAMD is already on MLPerf in the form of the tinybox red :) reply Kelteseth 1 hour agorootparentThey should have bought tiny for 600 million ;) reply hmaxwell 2 hours agoprevThis is a nothing burger compared to amazon and google giving $4b and $2b respectively to Anthropic reply lopkeny12ko 4 hours agoprev [–] Wow. I hope this is blocked by the DoJ on antitrust grounds. reply duxup 2 hours agoparent [–] Arguably as far as anti trust grounds go wouldn't AMD being a more viable competitor in the AI space be ... good? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "AMD is acquiring Silo AI for $665 million to bolster its software capabilities in AI and machine learning, areas where NVIDIA's CUDA has been dominant.",
      "Silo AI's expertise with large language models (LLMs) on AMD hardware is expected to enhance AMD's software stack and competitive position.",
      "The acquisition has generated discussions about its potential impact on the European startup ecosystem and AMD's future in the AI market."
    ],
    "points": 322,
    "commentCount": 161,
    "retryCount": 0,
    "time": 1720617975
  },
  {
    "id": 40924915,
    "title": "Europe's new heavy-lift rocket, Ariane 6, made its inaugural flight",
    "originLink": "https://www.esa.int/Enabling_Support/Space_Transportation/Ariane/Europe_s_new_Ariane_6_rocket_powers_into_space",
    "originBody": "Enabling & Support Europe's new Ariane 6 rocket powers into space 09/07/2024 28667 views 176 likes ESA / Enabling & Support / Space Transportation / Ariane Europe's new heavy-lift rocket, Ariane 6, made its inaugural flight from Europe's Spaceport in French Guiana at 16:00 local time on 9 July (20:00 BST, 21:00 CEST). Ariane 6 takes flight Ariane 6 is the latest in Europe's Ariane rocket series, taking over from Ariane 5, and featuring a modular and versatile design that can launch missions from low-Earth orbit and farther out into deep space. \"A completely new rocket is not launched often, and success is far from guaranteed. I am privileged to have witnessed this historic moment when Europe's new generation of the Ariane family lifted off – successfully – effectively reinstating European access to space,” said ESA's Director General Josef Aschbacher. \"An inaugural launch is a huge undertaking from thousands of people who have worked relentlessly for years. To see it perform wonderfully at the first attempt is testament to their dedication and a demonstration of European excellence in engineering and technology. Heartfelt thanks go to the teams at ESA, CNES, ArianeGroup and Arianespace for their hard work to get to this point. I also want to sincerely thank our Member States for having enabled and supported the Ariane 6 programme along the way. Not always easy, but the endurance shown has paid off handsomely today.\" Ariane 6 first flight highlights Access the video This inaugural flight, designated VA262, is a demonstration flight whose aim is to show the capabilities and prowess of Ariane 6 in escaping Earth's gravity and operating in space. Nevertheless, it had several passengers on board. At 21:06 BST, 22:06 CEST, one hour after liftoff, the first set of satellites on board Ariane 6 were released from the upper stage and placed into an orbit 600 km above Earth. Satellites and experiments from various space agencies, companies, research institutes, universities and young professionals were included on this inaugural flight. Ariane 6 from above in the final hours before liftoff In addition to the rocket, the liftoff demonstrated the functioning of the launch pad and operations on the ground at Europe's Spaceport. The new custom-built dedicated launch zone was built by France's space agency CNES and allows for a faster turnover of Ariane launches. On the occasion of the launch, Philippe Baptiste, CEO of CNES, said: “With this first successful launch by Ariane 6, Europe has finally recovered its capacity to access space. Beyond the great emotion I am feeling right now, my first thoughts are for all the teams in Kourou, Paris, Vernon, Les Mureaux, Toulouse, Bremen, Lampoldshausen, Liège, Barcelona, Colleferro, Zürich and everywhere else in Europe who made this success possible. I would like to acknowledge the commitment of the employees of CNES, ESA, ArianeGroup, Arianespace and our subcontractors. The last few months have been intense, and I would like to thank them all. Europe can be proud of its space programme, Europe can be proud of its knowledge and expertise. Together, let's prepare the future of launchers and space.” Ariane 6 was built by prime contractor and design authority ArianeGroup. “With the successful first flight of Ariane 6, the European space industry has moved into a new era,” said Martin Sion, CEO of ArianeGroup. “This historic launch demonstrates the unfailing commitment of our teams and partners, whom I would like to thank warmly for this success, which reflects on the entire European industry. Seeing Europe’s new launcher lift off into space marks the culmination of an outstanding technical and technological adventure, and the beginning of a long history of Ariane 6 operations. The next flight models are already in production and the stages of the second model will be shipped to the Guiana Space Centre this autumn for the first commercial flight of Ariane 6.” Next: tech demos, controlled deorbit and capsule separation Ariane 6 first flight timeline With the placement of satellites into orbit, Ariane 6 has demonstrated that it can successfully launch its payloads into space, but ground control has more in store for its inaugural flight. Over the next hour, Ariane 6's upper stage will show again that it can restart its Vinci engine using the novel auxiliary propulsion unit. This restart capability will allow Ariane 6 to drop off multiple passengers into different orbits on future flights and deorbit itself through Earth’s atmosphere at the end of its mission, to ensure it does not become space debris. On this flight the Ariane 6 upper stage is set to release two reentry capsules as it enters Earth's atmosphere for a clean disposal to burn up harmlessly, leaving no space debris in orbit. Artist's view of the Ariane 6 The next Ariane 6 is planned for launch this year on its first commercial flight under Arianespace as operator and launch service provider. “The success of this first flight marks the start of Ariane 6’s operational career, giving Europe an autonomous access to space,” added Stéphane Israël, CEO of Arianespace. “The new launcher’s order book is proof of the versatility of Ariane 6 and of its capacity to accomplish a wide range of missions into multiple orbits. It reflects the confidence that customers have in Ariane 6 for both their institutional and commercial missions. We are eager to begin operating our new launcher.” Like Thank you for liking You have already liked this page, you can only like it once!",
    "commentLink": "https://news.ycombinator.com/item?id=40924915",
    "commentBody": "Europe's new heavy-lift rocket, Ariane 6, made its inaugural flight (esa.int)305 points by gostsamo 10 hours agohidepastfavorite331 comments nabla9 9 hours agoAriane 6 exists so that European countries can get independent access to space between now and 2030s. The launch cost is almost 2x the cost of Falcon 9. Both platforms can lift 22t to LEO. 6-10 years from now Ariane Next/SALTO will aims replicate Falcon 9 efficiency and the design will be very similar: reusable, RP-1/LOX, Prometheus engine is similar reusable open cycle engine as Merlin with lots of 3D printed parts. reply MrSkelter 9 hours agoparentFalcon’s costs are a fiction. SpaceX benefits from massive taxpayer support and uses facilities built by the military and NASA. It’s not a like for like comparison especially give SpaceX keeping its books private and giving no clear public indication of how reusable its rockets really are or their refurb cost. Given Musks history of creative accounting quoting their PR numbers, the ones they pitch congress, as facts is naive in the extreme. reply InTheArena 6 hours agorootparentHaving followed the launch industry for 30 years, I can safely tell you that this is the exact line that every competitor (save RocketLabs and the startups fueled by the SpaceX diaspora of engineers) says whenever they are trying to justify their legacy wasteful rockets. Even Rocketlab's CEO had to \"eat his hat\" when he finally realized that the cost difference was real, that reusability was here to stay, and they had to develop a direct competitor to SpaceX. SpaceX provides a per-seat, per-launch cost, not a direct government subsidy - That would be ULA. ULA was literally a direct mechanism for transferring tax revenue to large multi-national defense companies to procure \"independent access to space\" (sound familiar?). They do use (and pay for and lease) NASA and Air Force facilities - but in America, airports are government institutions as well, that are explicitly leased out to airlines. Reuse of NASA's unused resources, rather than destroying them (or paying for the upkeep) after the shuttle program, was an explicit political decision. So why isn't SpaceX cheaper? They have kept prices high (but still lower than everyone else) to help fund Starlink. The fact that they can do so is reflective of Falcon's costs. Reusability is real. Ariane 6 is nothing more then the ULAification of Arianespace. reply nick238 3 hours agorootparentNot sure why \"eat his hat\" is in quotes as it's very much literal, other than maybe that he just ate part of a (probably clean) hat? https://youtu.be/Rafa_WBFIyE?si=34h4rZWiLUSCMKQq&t=188 reply Self-Perfection 2 hours agorootparentprev>So why isn't SpaceX cheaper? Another way to look at the price is from supply/demand angle. Even if real cost of falcon 9 launch is much lower than its price, SpaceX can not just lower the price, otherwise they will need to handle even greater demand. Even with current price their launch cadence grows exponentially year by year. With lower prices they would need to grow even faster. reply sidewndr46 6 hours agorootparentprevGiven that ULA historically purchased engines from Russia, are you suggesting that it was a direct mechanism for transferring tax revenue to Russia companies? reply jjoonathan 6 hours agorootparentYes. The idea was to keep the engines (and engineers) out of the hands of the other likely buyers. You've seen how soviet military surplus gets around: the same channels work for rocket engines, and those engines work in ICBMs just as well as they work in orbital launch platforms. I don't know how effective this was. Did it backfire by promoting economies of scale in a program that went on to sell to adversaries anyway? Did it murder the domestic engine programs and did that have knock-on consequences? I don't know if the policy was effective, but I do know that stopping \"engine proliferation\" was a widely given and accepted reason for those programs. reply m4rtink 4 hours agorootparentWell, RD-180 is not really a suitable engine for modern ICBMs due to the need for a cryogenic oxidizer, resulting in the ICBM not being a very responsive design. But you are certainly correct about the engineers. reply jjoonathan 4 hours agorootparentGood point. Still, I have to imagine that the engines themselves are dual use in some regard. GNSS or spy satellites maybe? These days it seems like everyone and their dog has a GNSS constellation, but it wasn't always that way. reply TeMPOraL 6 hours agorootparentprevIndirect through ULA, but yes; it's not like Russia is in an alien dimension. Trading with it was fine, at least until recently. reply dmd 5 hours agorootparentAnd for anyone who wants to read about Russia in an alien dimension, I can't recommend highly enough Charles Stross's \"Merchant Princes\" and \"Empire Games\" series! reply inglor_cz 5 hours agorootparentprevInterestingly, Ukraine has a lot of space industry and relevant experience. The EU could make use of that, one day. Or the Western world in general. Of course that means not leaving them over to the bear. reply nordsieck 4 hours agorootparentprev> Given that ULA historically purchased engines from Russia, are you suggesting that it was a direct mechanism for transferring tax revenue to Russia companies? I mean, for many years the US bought seats on Soyuz launches, so that was an even more direct mechanism. reply pie420 3 hours agorootparentprevEvery engine that america was buying from Russia was not ending up in China. Massive national defense win. reply InTheArena 5 hours agorootparentprevYes. Deliberately so. They wanted to ensure that rocket and nuclear technology did not proliferate in the 2000s and were willing to directly pay for Russian engineers and knowledge to keep them from going elsewhere. reply JumpCrisscross 8 hours agorootparentprev> SpaceX benefits from massive taxpayer support and uses facilities built by the military and NASA So does ArianeSpace [1]. (It’s majority owned by the French state. EDIT: It’s not.) > no clear public indication of how reusable its rockets really are or their refurb cost Refurb rates and turnaround times for Falcon 9 first stages are publicly documented [2]. Refurb costs are more opaque, but they’d have to be multiples of what SpaceX charges to approach Ariane 6’s cost projections. Ariane 6 is obsolete on arrival; ArianeSpace’s CEO admitted as much in asking the ESA to fund a reusable heavy booster like Falcon Heavy [3]. [1] https://www.space.com/europe-ariane-6-rocket-debut-launch [2] https://en.wikipedia.org/wiki/List_of_Falcon_9_first-stage_b... [3] https://www.illdefined.space/arianespace-the-only-fish-in-th... reply qwytw 6 hours agorootparent> It’s majority owned by the French state Is that really true? I thought it was owned 50:50 by Safran and Airbus which are both publicly traded companies. ~25% of Airbus is owned by France, Germany and Spain. France owes ~11% of Safran. So France seems to own only ~10% of ArianeSpace reply JumpCrisscross 6 hours agorootparentYou’re correct—thank you. I missed CNES transferring its shares to Safran [1]. [1] https://www.arianespace.com/wp-content/uploads/2016/02/Corpo... reply littlestymaar 8 hours agorootparentprev> So does ArianeSpace [1]. (It’s majority owned by the French state.) True, but the EU has tight rules about government subsidies (TFEU art. 107-109) which don't have equivalent in the US. > Ariane 6 is obsolete on arrival; ArianeSpace’s CEO admitted as much in asking the ESA to fund a reusable heavy booster like Falcon Heavy [3]. This is true though. reply InTheArena 6 hours agorootparentPlease note - Airbus has received tens of billions of dollars in launch aid that only in 2018 was ruled illegal and still has not launched a major airframe without this form of government aid. Aviation and space have been a super-highly subsidized environment since day one, on both sides of the Atlantic. reply Cipater 8 hours agorootparentprev>True, but the EU has tight rules about government subsidies (TFEU art. 107-109) which don't have equivalent in the US. ESA member states contributed €2.815 billion for the development of Ariane 6. Industry contributed €400 million. Additionally, the member states have agreed to subsidize the Ariane 6 to the tune of €340 million annually. reply Angostura 7 hours agorootparentWhere does SpaceX get its development funding from? reply yokem55 6 hours agorootparentThey've had multiple private VC rounds. They also have had several milestone based development contracts from the government to develop capabilities (iss cargo and crew mainly) while charging the government less to do that dev work then their competitors bid. reply basementcat 6 hours agorootparentSeveral of the investment rounds included participation from In-Q-Tel, the CIA's venture capital arm. reply JumpCrisscross 6 hours agorootparent> Several of the investment rounds included participation from In-Q-Tel, the CIA's venture capital arm Not a significant source of capital. NASA COTS was Hawthorne’s public-money shot in the arm. reply baq 5 hours agorootparentYes and it saved/will have saved them literally billions over the following 20 years. reply tekla 4 hours agorootparentprevThey sell commercial services to private industry and Government. reply ddalex 8 hours agorootparentprevIf I would be begging for new development money from the parent org after just launching a new product, I would also say that the new product is obsolete and we need to work on a replacement ASAP... especially in a pork-barrel org reply JumpCrisscross 7 hours agorootparent> I would also say that the new product is obsolete and we need to work on a replacement ASAP Sure. See the rest of the article. Everyone else has been saying the same for a decade. Note that the reusable heavy launcher he’s pitching is still aiming to deliver in a decade what SpaceX can do today. It’s not a strategic option, it’s a jobs programme. reply ddalex 3 hours agorootparentIt is a strategic option because should SpaceX suddenly say no to launches, you have a backup. An expensive backup, but it's there. If ESA has 100 payloads, it can just book 90 of them on SpaceX and the mandated 10 of ArianeSpace (to keep the political pork happy), and lose only 10% efficiency (considering Ariane flight is twice as expensive as SpaceX). The problem is that ESA has no scalable payload economy, nobody has a good reason yet to launch that much mass. SpaceX is its own customer with Starlink for scalable launches, but ESA or NASA will not deliver 100 sattelites per year. reply JumpCrisscross 2 hours agorootparent> should SpaceX suddenly say no to launches, you have a backup. An expensive backup, but it's there It's not a functional back-up. Not for any commercial use case relevant outside the military. If all you want is a back-up for military launches, the Ariane 5ME was a better, cheaper option that could have bridged the gap to a competitive reusable [1]. The billions of dollars wasted on Ariane 6 would have put Europe into the running for a competitive launch vehicle in the 2030s. Instead, we have Arianespace's CEO pitching another boondoggle to ensure Europe has a Falcon Heavy by the 2030s. So yes, having 10% launch capability is better than zero. But that 10% could have been bought for much cheaper. And saying 90% of your space industry is subject to foreign control versus 100% is a bit milquetoast, particularly when the alternative would have been R&D to bring that down to e.g. 50%. [1] https://en.wikipedia.org/wiki/Ariane_5#Ariane_5_ME reply 627467 7 hours agorootparentprevthat's a marginal improvement in attitude than previous Arianespace leaders: > \"Let us say we had ten guaranteed launches per year in Europe and we had a rocket which we can use ten times—we would build exactly one rocket per year. That makes no sense. I cannot tell my teams: 'Goodbye, see you next year!'\" https://arstechnica.com/science/2018/05/ariane-chief-seems-f... reply sgu999 7 hours agorootparentThey must have poached him from the consumer electronics industry... Thanks for sharing this ridiculous statement. I remember one of the execs of ArianeSpace or ESA just a couple years ago stating on radio with much confidence that SpaceX would never manage to reuse a rocket. reply Xixi 8 hours agorootparentprevAriane 6 is quite heavily subsidized, with ArianeGroup getting €340M per year to operate it [1]. With an expected 10 launches per year, that's about €34M/launch. But in the grand scheme of things it doesn't matter: Europe needs to be able to put its own military satellites (or anything else critical) up there. Military satellites sold to third party countries also won't launch themselves... [1] https://europeanspaceflight.com/arianegroup-to-receive-e340m... reply Rinzler89 8 hours agorootparent>Ariane 6 is quite heavily subsidized All major aerospace companies and projects are heavily subsidized in every country otherwise they would never survive or even be born. Like how much profit did NASA make over its lifetime? reply Cthulhu_ 6 hours agorootparentNASA is a government agency though, so it doesn't have profit generation as its target. And that's fine, neither does the US army or any other government branch except for the tax office. reply ambicapter 4 hours agorootparentprevRight? At a certain point, governments are the only entities that can afford to send things to space. \"Highly-subsidized\" here just means \"government is 99% of company's market base\". reply pfdietz 3 hours agorootparentThat certain point is in the past. Today, all sorts of private entities send things into space. As launch gets cheaper, private activities in space will dominate, if they don't already. reply londons_explore 7 hours agorootparentprev> But in the grand scheme of things it doesn't matter: Europe needs to be able to put its own military satellites (or anything else critical) up there. Military satellites sold to third party countries also won't launch themselves... I'm very surprised the EU and the USA and SpaceX didn't work out a deal to buy a certain number of F9's to be launched and operated from the EU. The EU would pay a (vey high) price to buy outright the rockets, and would agree not to develop a competing rocket design in the next 20 yrs. reply pavlov 7 hours agorootparent> \"would agree not to develop a competing rocket design in the next 20 yrs\" Isn't the whole point of Ariane to maintain European capability for independent space launches? It would be very hard to spin that up from nowhere after twenty years of complete inactivity. reply JumpCrisscross 6 hours agorootparent> would be very hard to spin that up from nowhere after twenty years of complete inactivity That’s not the only alternative. reply leoedin 5 hours agorootparentprevEuropean space programs are motivated by jobs, retaining domestic skills and actual usefulness in that order. Funding is allocated to companies based primarily on the country they’re in - funding must be split across all funding countries. ESA is never going to just buy a rocket, because that would completely defeat the point of ESA. reply CrLf 7 hours agorootparentprevI think you fail to understand the concept of sovereignty. reply The_Colonel 7 hours agorootparentprev> The EU would pay a (vey high) price to buy outright the rockets, and would agree not to develop a competing rocket design in the next 20 yrs. It doesn't seem that surprising given the terms. reply Propelloni 6 hours agorootparentprevWhy? That would be a bad deal for ESA. Instead of being behind 10 years with a fighting chance to catch-up, they would be 20 years behind and dependent on one, maybe two unreliable partners (Musk and maybe the USA under Trump). reply close04 7 hours agorootparentprev> The EU would pay a (vey high) price to buy outright the rockets, and would agree not to develop a competing rocket design in the next 20 yrs. So the worst of both worlds? It would still be very expensive, but also dependent on a foreign entity and with hands tied for the next decades unable to develop people, skills, or products in that direction. reply Cthulhu_ 6 hours agorootparentprevWould that even be possible? SpaceX would need to either provide intense training (engineering, operating, etc) for their rockets, or to provide the staff and facilities themselves; basically the company would need to double its staff (if not more) to support a scheme like that. I mean it makes sense, why not sell off rockets and whatnot commercially like the mass production strategy that Musk has in mind? But I don't think there's enough launches yet to warrant that. In fact, SpaceX is booked full for the next few years already; unless that's intentional, they simply don't have the production capacity to humour that idea. reply bryanlarsen 5 hours agorootparentprev> massive taxpayer support When the Forest Service buys a truck from Ford do you also call that \"taxpayer support\"? The government buys stuff from SpaceX, it hasn't directly subsidized SpaceX for years. The government buys from the lowest bidder, which is almost always SpaceX. For example, NASA estimated that it would have to pay $1.5B to deorbit the ISS. After tender, SpaceX bid and won with an $843M bid. Who is subsidizing who here? > uses facilities built by the military and NASA. And for which it pays quite dearly for, on the order of $1M per launch. It's quite clear from Rocket Lab's books that operating their own launch facility is far cheaper than using the Space Force's or NASA's. > creative accounting quoting their PR numbers, To win their contracts, SpaceX has had to open their books to both the Space Force and NASA. It's one thing to lie to the press in a tweet, it's quite another to lie to the military in audited books. The press may be gullible, but army accountants are not incompetent and the consequences for lying to the military are not minor. SpaceX's books are not open, but the amount they receive from the government is very public. It's quite obvious that SpaceX is highly profitable. They receive well under $2B from the government each year, they sell a couple dozen other rocket launches to others for ~$70M apiece, have not raised money for over 18 months, have a payroll approaching $1B per year and are quite obviously sinking multiple billions each year into Starship and Starlink. The only way the numbers add up is if Starlink is ridiculously cheap to build and Falcon is ridiculously cheap to launch. reply realityking 5 hours agorootparent> The government buys from the lowest bidder To my knowledge, in the case of NASA’s launch contracts, only US companies are allowed to bid on these. It’s quite understandable that Europe would like to keep domestic capabilities the same way NASA aims to maintain the US’ domestic capabilities. reply Cipater 8 hours agorootparentprev>SpaceX benefits from massive taxpayer support Ariane 6 was funded by European taxpayers to the tune of €2.815 billion. >and uses facilities built by the military and NASA. Ariane is launched from the Guiana Space Centre which is owned and operated by the ESA. Since you haven't familiarised yourself with the topic, ESA is the European Space Agency and is owned by 22 European governments. In addition, the member states of the ESA will subsidize the rocket for up to €340 million annually in return for an 11% discount on launches. reply jve 7 hours agorootparentprev> It’s not a like for like comparison especially give SpaceX keeping its books private and giving no clear public indication of how reusable its rockets really are or their refurb cost. Elon in some interview was stating that Falcon architecture limits reusability to particular amount days so it is not _rapidly_ reusable in comparison to having Starship being catched by tower/reused rapidly. However mentioning merely days - that is surely pretty reusable and makes economical sense. https://youtu.be/aFqjoCbZ4ik?si=pK-tptp0XbmOeoWN&t=432 > \"... a couple days to get booster back. At least a few days to refurbish it for flight ...\" In practice, wiki mentions 21 days as fastest turnaround for a single booster: https://en.wikipedia.org/wiki/List_of_Falcon_9_first-stage_b... - So that means bringing booster back with ship, refurbishing, putting on the new payload and launching again. reply hoseja 8 hours agorootparentprevMassive taxpayer support for such frivolous projects as the first and only global broadband (battlefield capable) communication system and the only working american human-rated launcher, both for quarter the cost the next guy would like to charge. Truly, shameless leeches. reply sandworm101 6 hours agorootparentprevThere is more to SpaceX than just cost comparisons. SpaceX is a US company, meaning anyone wanting on the rocket has to submit to a host of space-related regulations and US national security policies. Some launches don't want to, or cannot, deal with such oversight. A doubling of launch costs seems huge, but operating satellites isn't cheap. Many launches may prefer the premium price if it means launching on a European rocket. reply fallingknife 6 hours agorootparentprevYou don't actually believe that a rocket that is thrown away every launch could possibly be cost competitive with one that can be reused 20 times, do you? reply rbanffy 5 hours agorootparentA rocket that's thrown away was cheaper per flight than the shuttles, which were only partly discarded. It all depends on how much does it cost to build vs refurbish. Falcon 9 was designed to be easily refurbished and Ariane 6 was designed to be cheap to build. Also, launch campaign costs are not neglectable - moving the parts around, fueling, testing, and so on, are expensive. Their next-gen ones should be reusable, and share a lot of design with the Falcon 9 family. Methalox might next, as it's very promising, but the RP1 supply chain is well established. reply nordsieck 2 hours agorootparent> A rocket that's thrown away was cheaper per flight than the shuttles, which were only partly discarded. It all depends on how much does it cost to build vs refurbish. Falcon 9 was designed to be easily refurbished and Ariane 6 was designed to be cheap to build. It's not just that the Shuttle was expensive to refurbish. It was also very expensive to build. Whereas Falcon 9 is much less expensive to build new than Ariane 6. Ariane 6 was designed to be cheaper to build (cheaper than Ariane 5, that is). reply verzali 3 hours agorootparentprevIt depends what you do with the rocket. Reuse isn't free, it has costs. Notably you need to carry more fuel with you in order to land, and that negatively affects overall performance. You also need to fly frequently to get the cost advantages. That's one reason SpaceX has turned to Starlink, since the demand from the market isn't enough to really get the benefits from reusable rockets. reply dotnet00 4 hours agorootparentprevIt's sad seeing this delusional take despite all the evidence to the contrary. reply ekianjo 8 hours agorootparentprevdo you imagine the ESAs some kind of private actor? its paid by the taxpayers whether it makes money or not reply panick21_ 8 hours agorootparentprevLol, how delusional. ArianeGroup literally just got 5 billion $ plus use of lots of tax payer subsidized infrastructure. That is 4 billion $ more then SpaceX ever got for development of Falcon 9. Falcon 9 got an old shitty broken down launch sites they had rebuild, ArianeGroup got a whole new built launch site for free. But feel free to live in fantasy land. > It’s not a like for like comparison especially give SpaceX keeping its books private and giving no clear public indication of how reusable its rockets really are or their refurb cost. Actual smart people and analyist firms have done a lot of work on this. And literally every single expert on the topic disagrees with you. Its literally impossible to assume SpaceX is not saving money, because it would be insane for them to do 100+ launches if they couldn't do as cheaply as they claim. > Given Musks history of creative accounting quoting their PR numbers, the ones they pitch congress, as facts is naive in the extreme. No idea what you are talking about. All SpaceX contracts with the government a fixed cost. What they actually cost doesn't matter, if SpaceX can't deliver, they pay it themselves. If the were constantly offering prices cheaper then they can do things for, they wouldn't exist. Its amazing the brain power it takes to believe that SpaceX is losing money on launches, losing money on development contracts, and is developing Starlink and Starship and is losing money on Starlink operations. But somehow they still exist because 'mmhhh they raised money'. Problem is we know how much money SpaceX raised, you can look it up. And we know what they get paid for their government contract. Their money raising isn't that crazy, in fact, its hard to believe that they have enough to work on Starlink and Starship at the same time. Other companies have spent far, more on things that are far less impressive. But somehow they did both at the same time while also developing human launch. Increasing launch rates. And taking on a number of other fixed price development contracts. And somehow they still exist. Anybody who actually studies these numbers come to the same conclusion. And those simply don't agree with you. Go and actually try to build a model and do the numbers yourself. You will prove yourself wrong. But of course you wont do that, because you were already to lazy to look up what all the space analysts already concluded. Better just keep repeating those anti-Musk talking points you found on twitter from people who wouldn't know what side of a rocket points up. reply londons_explore 7 hours agorootparent> Problem is we know how much money SpaceX raised If they wanted to raise money without it becoming public, they could do so easily - for example using directors loans. A better way to guess their expenses is to look at how many employees they have. Lets call it 15,000. Lets put average pay at $150k/year after overheads and taxes. 96 launches in 2023. That puts the salary cost per launch at $23M/launch. It's a very rough figure because obviously some rocket parts are purchased, there are other overheads, and there are other revenues and costs from starlink etc. reply panick21_ 6 hours agorootparentMost people at SpaceX work on development programs and in manufacturing not launch. SpaceX manufactures many different things. Launch by now isn't even close to a majority of revenue anymore. SpaceX is not just a launch company, not even close. They are a full space company doing everything from ground infrastructure, commercial and military sats, human and cargo space flight to LEO and the moon. And they are doing development and operations of all of that. What matters is marginal cost of every other launch of Falcon 9. Most analysts put the number somewhere between 10 million $ and 25 million $. I think very few people would guess more then 20 million $, specially now as launch rate has gone up. My guess is that 15 million $ is more reasonable. SpaceX pretty consistently ramped up their money raising along with their development programs. And they were pretty transparent about all of that. Not a single company who analyses SpaceX has ever suggest that SpaceX might somehow have raised much more money. Maybe a few 10s of million. But its hard to raise billions without anybody knowing. And I'm just rather believing people who spend a lot of resources trying to understand SpaceX rather then somebody in an internet form saying 'maybe they have raised billions without anybody knowing'. Because only if its actually billions would it change anything about my argument. What is numbers actually suggest is that SpaceX Falcon 9 operation are highly profitable. They are selling launch way above cost. Numbers and information we have suggest that SpaceX bids very aggressively on their development contracts for NASA, and they are like no making a profit on those, maybe a loss. In case of Starship, a big loss. But likely they get that back with continued operation beyond the initial orders (or that has been the reality so far). Numbers suggest that SpaceX is making a killing on DoD contracts, they knew they were the only viable competitor so they bid very high on those. I think just one that stuff, SpaceX would be a highly profitable company. If this was not true, then there simply is no way they could have sustained the massive investment in Starship and Starlink. So unless somebody shows me prove or anything close to a credible source, showing that SpaceX raised multiple billion additional $, I'm just not gone believe the SpaceX is losing money on everything narrative. Frankly given how insanely expensive something like Starship is, its crazy how little money they have actually raised. Its basically a drop in the bucket to compare it to SLS. reply FredPret 6 hours agorootparentprevYou really think 100% of salaries can be attributed to launch costs of one of their rocket types? reply kuschku 9 hours agoparentprevAriane is one generation behind SpaceX, but that still puts them on second place. All while being independent from the whims of one single individual, ensuring independent launch capabilities for national security reasons. reply nordsieck 8 hours agorootparent> Ariane is one generation behind SpaceX, but that still puts them on second place. The first doesn't imply the second. Ariane 6 is behind: * ULA's Vulcan * SpaceX's F9/FH * SpaceX's Starship (who knows when it'll start launching payloads) * Blue Origin's New Glenn (supposed to be launched in September) in terms of raw performance as well as $/kg. There are also a number of other rockets like RocketLab's Neutron and Relativity's Terran R that seem like they'll outcompete Ariane 6. The medium/heavy lift market is getting much more crowded than it has been in the past. reply m4rtink 4 hours agorootparentNot to mention the quite cheap flight-proven Indian rockets & a whole bunch of traditional + private Chinese companies, some actively trying to clone Falcon 9 or even Starship. reply nordsieck 4 hours agorootparent> Not to mention the quite cheap flight-proven Indian rockets & a whole bunch of traditional + private Chinese companies, some actively trying to clone Falcon 9 or even Starship. It seems like most of the world has decided not to fly on Chinese rockets, so those aren't really competition. But I totally agree with regard to India: PSLV and GSLV are both good, competitive rockets. It'd kind of a shame that they don't launch more often. It makes me wonder if there's some sort of organizational dysfunction going on. It does sound like they're going to be launching OneWeb going forward, though, which is nice. reply unethical_ban 5 hours agorootparentprevTwo operational, and a bunch of dreams. Right now, Europe has a functioning rocket program under their own control. I think it's understandable for an engineering community to talk about the tech, but people seem to be forgetting the geopolitics. reply jccooper 4 hours agorootparentYou must have some wild dreams. Starship and New Glenn are basically as dreamy as Ariane 6. Starship is essentially operational as an expendable launcher already, and NG is starting the paperwork for first launch. Ariane 6 will serve fine as an \"assured access to space\" for the local market (which is important), and good on them for finally getting it off the ground. But it's design goal was \"Falcon 9 competitor\" and it certainly isn't. reply verzali 3 hours agorootparentAriane 6 has flow successfully. New Glenn is missing in action, and Starship still has a long way to go before it is ready to actually put payloads in orbit. Ariane 6 is ahead of both, given it has actually flown and delivered satellites to orbit. reply m4rtink 4 hours agorootparentprevEurope again has one functioning rocket - after it had 3: - Soyuz from Kourou, which understandably is no longer politically viable now. - Ariane 5 - Vega/Vega C (which keeps crashing in its latest iteration) Not I good track record I'm afraid. reply nordsieck 4 hours agorootparentprev> Two operational, and a bunch of dreams. Lol. Starship has successfully launched more than Ariane 6. The only reason they aren't launching payloads right now is because they want to nail down reuse first. There's less info on New Glenn, but a lot more footage has come out since David Limp took over. And the DoD thinks Blue Origin has a good enough shot at launching this year that they added them to NSSLv3. > Right now, Europe has a functioning rocket program under their own control. > I think it's understandable for an engineering community to talk about the tech, but people seem to be forgetting the geopolitics. Sure. But that would have also been true if they'd just kept Ariane 5. A lot of people are dumping on Ariane 6 because ArianeGroup spent a bunch of money and time to make a rocket that's not that much better than the previous one. When they could have made an actually competitive rocket instead. reply panick21_ 4 hours agorootparentprevThey had that before Ariane 6 that cost 5 billion $. reply mort96 4 hours agorootparentprevRelying on a company which is headed by a famously unreliable narcissist seems like a bad choice though, I wouldn't really count those SpaceX options as proper alternatives EDIT: I would like downvotes to explain their reasoning. reply dotnet00 4 hours agorootparentIt's a tired ad hominem, all the evidence shows that SpaceX is by far the most reliable operator in the space industry right now. reply mort96 3 hours agorootparentWhen the question is \"should we trust this guy?\", judging the character of the guy based on past behavior and statements is not a fallacy. reply dotnet00 2 hours agorootparentWhat exactly has Musk actually done that goes so far beyond the pale of typical corporate shenanigans that it would register as not being trustworthy to governments? At most he has had overly optimistic timelines, overly optimistic social media statements about future capabilities, a bunch of business ideas that didn't pan out and some QA issues in a car manufacturer. This is pretty par for the course for every business. The whining about him being untrustworthy stems almost entirely from him having different political views (and not being afraid to voice them), and the stream of mostly unsubstantiated hit pieces and awful reporting regarding Starlink in Ukraine. With the way you guys talk about it though, he might as well have personally caused the crash of more than two full passenger jets. reply mort96 2 hours agorootparentI wouldn't downplay the Starlink Ukraine thing the way you're doing. But if you're still a Musk apologist after all these years, there's nothing I can say to convince you. For many of us, the whole diver pedophilia accusation was enough, and that pales in comparison to everything that came after. reply dotnet00 2 hours agorootparentWhy wouldn't I downplay the Starlink Ukraine thing, when everything about it from the media has been at best misleading? The usage of Starlink to control drones wasn't allowed because that is not a civilian-style use case and thus would require the US government to provide authorization (remember that Starlink was initially provided directly by SpaceX without going through typical US government aid processes). The reports about outages buried the lede that the terminals with the outage were ones provided and paid for by third parties that had decided to stop paying for them, and the reports themselves mentioned that Ukraine had swapped them out. The usage of Starlink in Crimea had always been disallowed to prevent Russian usage, and to be in compliance with US policy at the time. Ukraine had made the unreasonable request of having it enabled with a day's notice, which was obviously too fast for a decision to be made, it was enabled a few months later when things had been properly worked out with both governments (this was still well before the story ever became public). As for Russia using captured Starlink terminals, the DoD has also come out in support of SpaceX's efforts to mitigate it, making it clear that it isn't an easy problem to solve, as they need to somehow distinguish between third party terminals in use by Ukraine, from terminals captured or black-market imported by Russia being operated in Ukraine. There's nothing you can say to convince me because you likely have nothing to say that is backed up by facts. I'm not saying you have to like him, I'm saying that there's nothing he or his companies have done that makes them any less trustworthy or any more untrustworthy, compared to any other company the government works with. You'd have to be able to point to something worse than even what Boeing has done, considering that the US govt continues to consider Boeing to be an important defense partner. reply mort96 2 hours agorootparentnext [4 more] [flagged] dotnet00 2 hours agorootparentYeah I guess acknowledging well documented reality and keeping things in perspective makes me a Musk-apologist and cultist. Which echo chambers and lies would you recommend I consume to correct this? reply mort96 2 hours agorootparentI don't know what well documented reality you're talking about, you've made a bunch of unsourced claims wrt the Starlink thing which may or may not be correct, and you've chosen to close your eyes and ignore everything else you know people tend to bring up (even stuff I specifically brought up). There's nothing more for us to discuss. You even admitted yourself that there's nothing anyone could say to make you change your mind, so why are we still here? reply dotnet00 1 hour agorootparentWe're still here because you seem to continue to misunderstand (assuming you're posting in good faith). \"There's nothing you can say to convince me because you likely have nothing to say that is backed up by facts\" is asking for something concrete that is a reason governments would view certain companies as too untrustworthy to work with. I specifically said that it doesn't matter if you like him, that's different from being so untrustworthy that their services shouldn't be used despite being the best option. The only thing you've pointed to is an incident that obviously does not rise to the level of being a reason for a government to not work with a Musk-owned company. He responded to a guy who told him to shove his submarine up his ass by calling him a pedo, it was admittedly an incredibly dumb way to handle it, but obviously not a reason for a government to not work with him. The rest of what you've said is the usual thing where people make comments vaguely about an issue without ever saying anything specific so you can't be countered. Every thing I mentioned is backed up by articles: The Starlink TOS mentions that it cannot be used in weaponry (ie drone control) because that brings it under ITAR export restrictions, which requires approval by the US government (and afaik the government has not authorized this): https://www.starlink.com/legal/documents/DOC-1041-35650-61 The report of the outages mentions itself that \"The batch of terminals were also rotated out as concerns grew that service could be turned off, in order to minimize the impact, the source said.\" :https://www.cnn.com/2022/11/04/politics/spacex-ukraine-elon-... The Crimea service activation correction: https://www.theguardian.com/books/2023/sep/12/elon-musk-biog... The DoD commenting on the difficulty of ensuring Russia can't use Starlink: https://www.defenseone.com/threats/2024/05/defense-departmen... That said, I'll stop here, I think I've said enough that other open minded people will be able to form a less biased opinion even if you refuse to engage in good faith. reply JumpCrisscross 8 hours agorootparentprevAnd that’s before we start counting in China and, soon, possibly, India. Ariana 6 might be the stupidest civil aerospace project in the world after Boeing’s Starliner. reply lm28469 8 hours agorootparentHN is amazing: Europe does something > Aha it's bad why did they even try Europe doesn't do anything > Aha Europe always late, never innovate, Europe bad reply inglor_cz 8 hours agorootparentAs an European, this project is quite typical for Europe. Technically behind the times, serves French strategic interests, non-competitive on the private launch market. \"Doing something\" isn't a goal in itself. Ariane 6 in context of the 2020s is similar to programming a new MySpace app for Symbian OS right now. Hard work, costly, needs a lot of qualified workforce, and the product has very limited audience. reply ncruces 7 hours agorootparentSo the entire world should rather be dependent on SpaceX, and be done with it? Arianespace had the lead and lost it, because it kept the old way of doing things. Or are you arguing Ariane 5 was technically behind and wasn't competitive in the '00s? Ariane 6 is not that far behind the other \"old space\" companies, which the US is struggling to keep around as alternatives to SpaceX. It's not like Boeing and ULA are doing much better. We should be critical of Arianespace, and find ways to get it to improve, but just throwing everything at SpaceX will do nothing to keep them honest. reply JumpCrisscross 6 hours agorootparent> the entire world should rather be dependent on SpaceX, and be done with it? No, compete. There is a menagerie of European space start-ups starved of oxygen by ArianeSpace. Arianespace is Europe’s ULA. Europe with Ariane 6 is about as dependent on SpaceX as Europe without. The difference is whether it will continue to be dependent on SpaceX. Every euro that goes to Arianespace cements SpaceX’s global dominance. > Arianespace had the lead and lost it When was Arianespace in the lead? > Ariane 6 is not that far behind the other \"old space\" companies Granted. Not a great show for €5bn. reply jccooper 4 hours agorootparentFrom about 1990 to about 2016 Arianespace was the leader in commercial (meaning mostly GEO) launch, and acted like it. (Actually, they still do, just it's less believable now.) In retrospect, I don't think they ever really had the eye of the tiger; mostly they managed to be less terrible than the competition. The US competitors got far too fat at the government teat and didn't even try, and the Russians couldn't keep Proton from 'sploding. They'd probably still be king of the (small and expensive) hill without SpaceX. But they'd be in hot soup today, if some sort of LEO constellation market had come around without Falcon, 'cause they wouldn't even have started on Ariane 6 and Ariane 5 isn't well suited for that, and \"Europeanized\" Soyuz, which they'd use for that, would be unavailable due to Russian imperialism. reply nordsieck 4 hours agorootparent> They'd probably still be king of the (small and expensive) hill without SpaceX. Maybe. IMO, ULA's Vulcan is more commercially competitive than Ariane 6. But both rockets were developed in response to SpaceX, so maybe neither would have been made otherwise. In which case, ULA would be in even more hot water than ArianeGroup, since they wouldn't be able to get engines for Atlas V post Ukraine war. reply nordsieck 4 hours agorootparentprev> When was Arianespace in the lead? Before the rise of SpaceX. > For over 20 years, Ariane rockets dominated commercial launch—by 2004, Arianespace had 50 percent of the global market for commercial launches. https://www.csis.org/analysis/what-can-we-learn-ariane-futur... reply jltsiren 5 hours agorootparentprevThe space start-ups are starving, because nobody sees any business opportunities there, and because governments don't care about rockets beyond baseline national security needs. If somebody actually wanted a reusable rocket, the real issue would be engineering, not funding. Even a small country like Finland could run two programs the scale of Ariane 6 with the money it's currently using to support Ukraine. reply JumpCrisscross 5 hours agorootparent> space start-ups are starving, because nobody sees any business opportunities there I’ve raised money for and invested in space start-ups. There is a lot of opportunity. There are even more vapid PowerPoint decks. > If somebody actually wanted a reusable rocket, the real issue would be engineering, not funding It’s absolutely a problem of funding. You need to be able to tell a group of highly-demanded engineers with other life options that they will have access to the materials and resources repeated destructive validation of exorbitantly-expensive kit requires. That doesn’t mean any numpty with a few billion can do it. But, like, Europe could. (It hasn’t because that would threaten Ariane 6.) > Even a small country like Finland could run two programs the scale of Ariane 6 with the money it's currently using to support Ukraine But they don’t. reply jltsiren 5 hours agorootparentThe lack of funding reflects the lack of interest. For-profit investors don't see the business opportunity and governments don't see the need. There are other uses for the money, and the people with money don't want better rockets that much. Rockets are not particularly expensive, but they are also not particularly relevant. reply JumpCrisscross 3 hours agorootparent> lack of funding reflects the lack of interest. For-profit investors don't see the business opportunity Not true. Launch and propulsion are amply funded. (If you have a good idea in the space, and capacity to execute, I’d love to connect.) > Rockets are not particularly expensive, but they are also not particularly relevant Hell of a lot more to launch than just rockets. And there is demand, today, for non-SpaceX launch providers. Plenty of capital stands ready for this sector. And hundreds of millions are deployed every quarter. (Yes, private capital, occasionally in the billions.) SpaceX crowds out the market, yes, but Arianespace suffocates it by providing the same crowding effect with none of the utility in pay-off. And part of SpaceX’s wake comes in the form of commodification, particularly at the low-mass end. (To be clear, I think smalsat launch is overblown.) reply nordsieck 4 hours agorootparentprevIMO, a big problem is that SpaceX makes it difficult to enter the market. They keep their prices very low, and have an amazing reliability record. Which makes it tough to close a business case around medium/heavy lift rockets. Especially taking into account development risk. And it's not any easier trying to make a small-lift rocket. They suck the volume out of that market with their Transporter and Bandwagon launches. reply inglor_cz 7 hours agorootparentprev\"So the entire world should rather be dependent on SpaceX, and be done with it?\" That is not what I said. We badly need (real) alternatives. But French-government-need-driven development is bringing us nowhere. Paris is happy to have six launches a year and doesn't feel the need to finance and support anything beyond that. The rest of the EU doesn't seem to have any strong motivations either. Yes, the US old space is exactly as bad. reply awiesenhofer 4 hours agorootparent> doesn't feel the need to finance and support anything beyond Where did you get that idea from? They are financing the development of Ariane Next - Europe's version of a Falcon Heavy - just as the other ESA members do. reply Epa095 4 hours agorootparentprevYou could probably have said the same about Airbus at some point. But now we are pretty happy we don't have to rely on Boeing. reply dotnet00 3 hours agorootparentAirbus hasn't been making excuses about how they don't need to compete with Boeing for a decade. They've been focusing on being actually competitive. reply jacobr1 2 hours agorootparentprevAlso there is real competition downmarket for regional jets reply imtringued 5 hours agorootparentprev>\"Doing something\" isn't a goal in itself. Almost all space activity, with the exception of satellite launches, is useless. Let's say we build a Mars and Moon colony, then what? You do it, because you want it as a goal in itself. If you don't grasp that, you don't understand anything about space. The same fundamental problem also applies to the idea of an economy that is 100% productive and that consumption is evil. If you get rid of consumers, you can also get rid of the producers. You can get rid of the economy. No human existence can be justified under the guise of \"productivity\" unless that productivity leads up to some consumptive activity. reply inglor_cz 4 hours agorootparent\"If you don't grasp that, you don't understand anything about space.\" That's quite a self-confident, if not arrogant, take, which also misinterpretes my words. Ariane 6 is a launcher, not a Moon base. Launchers should strive to be economical, because there is a real orbital economy, as you admit, and because the entities which launch them may be cash-strapped. You yourself wouldn't buy a car or a bicycle that would have to be discarded after the first trip. Or if your point is that Ariane 6 is basically a white elephant project, well, that would be pretty damning. reply JumpCrisscross 7 hours agorootparentprevYou’ll find no complaints out of me on ESA’s scientific missions. ArianeSpace is simply a shitshow. And this isn’t a European problem—I’ll call out ULA and Boeing at keeping them company. reply rbanffy 5 hours agorootparentIt's bit like the \"too big to fail\" that happens to banks, but \"too strategic to fail\", which is common in aerospace with dual civilian/military applications. Companies in that space can have islands of inconceivable incompetence that remain surprisingly stable. reply IshKebab 5 hours agorootparentprevNonsense. The issue here is that they're doing the wrong thing. SpaceX proved reusable rockets were the future at about the same time Arianne 6 got funding to begin development (2016). They should have cancelled the project and started again with a reusable rocket at that point. Of course they didn't because of politics, but it does mean they did a stupid thing and spent a ton of money on a rocket that was obsolete before it left the drawing board, just like SLS. reply krisoft 8 hours agorootparentprevI mean maybe what they do is not good, and also not doing anything is bad too? I don't see the contradiction what you seem to be implying. Just because something must be done, doesn't mean that anything done should be celebrated. One can still do the wrong thing, and people can comment on that. Also HN is not a single entity. Even if you would see some contradiction between attitudes (which I don't see here) it could be still explained by the fact that many different people post on HN and they have different opinions, thoughts and values. reply nordsieck 8 hours agorootparentprev> And that’s before we start counting in China China is... weird. Most of the rockets they launch are small hypergolic rockets (Long March 2-4) with clear ICBM heritage. Which are multiple generations \"behind\" Ariane 6. They do have some more modern cryogenic rockets, but they can't seem to scale those operationally. Presumably it'll happen eventually. But who knows when that'll be. reply JumpCrisscross 7 hours agorootparent> Most of the rockets they launch are small hypergolic rockets They’re decently far along on their reusable booster [1], with a methalox engine being developed by a private company [2]. Of course, everything looks cute until it flies. But that programme is arguably ahead of anything ArianeSpace is working on. [1] https://spacenews.com/china-to-debut-large-reusable-rockets-... [2] https://en.m.wikipedia.org/wiki/Longyun_(rocket_engine) reply pantalaimon 7 hours agorootparentprevAre you deliberately ignoring China? reply panick21_ 8 hours agorootparentprevThis is not even close to being true. Vulcan rocket has already launch and cost the same as Ariane 6 without subsidy. They have a credible reuse program called SMART. Vulcan uses advanced stage engines. BlueOrigin, for all their diddling and money wasting, is gone launch pretty soon with a rocket that is way more advanced in literally every way. RocketLab has been executing quickly and their next generation Neutron rocket will be on the market literally a decade before any reusable offering from Arianespace. Their engine development is working on a staged rocket engine far more advanced then ESA next generation engine. Development on that engine is progressing much, much faster and is cheaper. Relativity's Terran R rocket is deep in development. Lots of component testing and fully built engines being tested. Their Terran R will also hit market many, many years ahead of whatever Ariane Next is gone. And in fact, while all these people working on next generation system, there isn't even the glimmer of political agreement about development of a next generation European system. Either you are just lying or you have not actually studied the launch market at all. > All while being independent from the whims of one single individual, ensuring independent launch capabilities for national security reasons. Yeah really sucks for the US to have 5 very aggressive competitive companies coming online. Much better to have monopoly that requires 5 billion $ to get the most basic rocket upgrade ever to fly. reply cubefox 8 hours agorootparentprevArguably at most third place, since partly reusable New Glenn (Blue Origin) is already planned to launch in a few months, currently September. Though lower stage reuse might only happen later. reply ricdl 8 hours agorootparentAriane is apparently so obsolete that they are behind rockets that haven't even launched yet! reply cubefox 8 hours agorootparentAriane 6 isn't significantly ahead of New Glenn in terms of time. Probably a few months difference for date of first launch. Just as Vulcan launched a few months ahead of Ariane 6. reply leoedin 5 hours agorootparentNew Glenn is a ground up unproven design. Ariane 6 is an incremental improvement from a well proven and highly reliable rocket. Just because they’re both making their first flights doesn’t mean they’re comparable as commercial offerings. The cost to build a satellite is high enough that most customers don’t want it to explode. Until New Glenn has a solid track record they’re not really comparable. reply kranke155 8 hours agorootparentprevNew Glenn still has to fly though reply cubefox 7 hours agorootparentThere is little doubt that it will do so in a few months. The main engines have already been tested successfully on Vulcan, a few months ago. reply kranke155 6 hours agorootparentYou’re not really reading what I wrote but ok. reply cubefox 5 hours agorootparentI have read it, maybe you just didn't understand what I said. reply imtringued 4 hours agorootparentprevWhat wisdom do you expect people to drive from something not having a property until it has that property? reply crest 9 hours agoparentprevSo because an incumbent exists ESA should give up, let their production and development pipeline rot away and \"enjoy\" the monopoly until it's too late to change something? reply 627467 7 hours agorootparentat this stage I question the resolve of any European leader in actually wanting to achieve anything of note in a consequential manner. it's cheaper but not cost-free to sustain a narrative of \"independence\" and \"alternative to incumbent\" when the actual result is just wasting tax payers money for vanity projects with no clear path to actually build a sustainable alternative to the incumbent. ESA has no resources to directly compete with spaceX or china unless Europe changes attitude and realizes that they have the resources and responsibility to do more in this mission for humanity reply espadrine 6 hours agorootparent> it's cheaper but not cost-free to sustain a narrative of \"independence\" and \"alternative to incumbent\" The narrative is independent of the price. SpaceX has showed that they may refuse service in various situations, such as drone access to Starlink Internet in a battle during Ukraine war. Thus a government being dependent on them for their space fleet, gambles the possibility of being suddenly unable to guarantee commercial services such as Galileo GNSS, or during military operations. reply ckozlowski 5 hours agorootparentThis was a special case. Much of Ukraine's connectivity came via donations from SpaceX, and via their commercial business. They gave free connectivity to Ukraine for a direct military purpose. There's legitimate reasons for why SpaceX would not want to be blurring the lines between the two. Programs such as the U.S. Foreign Military Sales program exist for this reason, providing a legal and contractual framework for such arrangements that route business through the state, with the legal and diplomatic oversight that comes with such. SpaceX rushed to provide terminals to Ukraine for free when they asked for them, and that was laudable. But SpaceX had no mature defense sales program set up, or it was bypassed. I could argue that this was another instance where Elon's impulsiveness created issues that SpaceX would have to deal with down the line, such as ongoing payments and the lack of a shield for their commercial business. Properly set up, a defense sale will include such things like a guaranteed minimum buy, service level agreements, and the legal and diplomatic framework to provide a level of shielding to the contracting company from third-party complaints to alleviate the risk of an arbitrary service shutdown. reply dotnet00 3 hours agorootparentprevNext time SpaceX should simply refuse to provide aid until countries requesting aid get everything approved through the US government first. Otherwise people like you will continue to act like it was unreasonable that SpaceX wouldn't allow Ukraine to do things with Starlink that were potentially in conflict with officially stated US policy. No good deed goes unpunished. reply JumpCrisscross 6 hours agorootparentprev> SpaceX has showed that they may refuse service in various situations, such as drone access to Starlink Internet in a battle during Ukraine war If the goal is building a European Starlink, Ariane 6 is a step backward. It fundamentally cannot support the required launch cadence and doesn’t build any of the foundational technologies required to get there. (Analogous to Starliner, which was also pitched as a back-up plan.) reply 627467 5 hours agorootparentprevmy argument is, none of the observable actions from European leadership are effective towards independence and I would argue those actions are detrimental - ie. wasting money in a decaying, incapable and parasitic organizations reply inglor_cz 4 hours agorootparentprevIn that case, tough luck for us. We cannot build an European equivalent of Starlink with expendable rockets. It would be just too expensive to build hundreds and hundreds of one-time rockets and immediately destroy them. reply charles_f 3 hours agorootparentprevI am not sure if you heard about it, but there's a war going on to the east, and the stance of the government currently saying yeah or nay to launching European stuff to space is far from being guaranteed to remain the same. I'd wager to say that this is hardly a matter of competition, but simply to guarantee continuation of a basic need in a situation where it might become much more important reply fallingknife 6 hours agorootparentprevThey did give up by building a disposable rocket in the 2020s reply ur-whale 9 hours agorootparentprev> So because an incumbent exists ESA should give up No. But they should learn their lesson and try to run instead of plodding along at a glacial pace. Oh but wait, they're govt funded with no success incentives other than some sort of vague sense of pride for a job well done. My money is on they're not going to come out ahead in the race. reply Beretta_Vexee 9 hours agorootparentESA and Ariane Group are two very different things. Ariane Group's main investor is the French state (61%). The French state wants a high-powered solid rocket booster for its ICBMs, and a sovereign and reliable means of launching large intelligence satellites. It couldn't care less about reusability. ESA is the equivalent of NASA and has no commercial activity, but subsidizes part of the Ariane program. Ariane group would rather be like a state own Lockheed Martin Space. Private investors interested in profitability and civil activities are in the minority at Ariane Group There is no race between ESA, NASA and Roscomos. The Russians and the French are not going to abandon their rockets and entrust their nuclear deterrent and early warning system to SpaceX. reply qwytw 6 hours agorootparent> Ariane Group's main investor is the French state (61%) Isn't Ariane Group jointly owned by Airbus and Safran? Which are both publicly traded companies and France only has a ~10% stake in both? reply Reason077 8 hours agorootparentprev> “The Russians and the French are not going to abandon their rockets and entrust their nuclear deterrent and early warning system to SpaceX.” The United States is certainly happy to (launch military payloads with SpaceX). Having access to far more launch capacity, far more cheaply, is surely a significant strategic advantage. Edit: Added text in parentheses for clarity. reply The_Colonel 7 hours agorootparentA huge strategic weakness is depending on a foreign country (perhaps even worse - one moody individual) for your launches. reply Reason077 7 hours agorootparentSpaceX is a 100% American company. Moody individual notwithstanding, they are no less American than Boeing or ULA or anyone else. reply Beretta_Vexee 6 hours agorootparent> SpaceX is a 100% American company. It's a huge fucking problem if you're not American. If you don't want to be subject to American law. If you don't want your technology inspected or tampered with by Americans. If you don't want the transaction to be in dollars (extra-territoriality of US law on all dollar transactions). If you don't want to deal with the problem of American citizens and companies subject to FISA, who could face severe repercussions in the US if they don't spy or facilitate spying on their non-American clients. reply inglor_cz 4 hours agorootparentIn practice, those who seek launches on commercial markets don't mind all those America-related complications much. The US isn't really interested in the secrets of some Malaysian or Brazilian TV satellite. reply Beretta_Vexee 3 hours agorootparent> The US isn't really interested in the secrets of some Malaysian or Brazilian TV satellite. Once again, compliance with US regulations, including export control, dual-use goods and tax regulations, can be weaponized, and has been in the past. Maybe the TV satellite manufacturer has also supplied a weather satellite to Brazil that contains technologies covered by export control, bingo. Your satellite and your assets in the USA are frozen until the manufacturer provide all the information needed to decide whether or not it was a spy satellite. The godamn Mars rover is covered by 14 export control technologies. https://www.bis.doc.gov/index.php/documents/pdfs/1008-satell... It's a minefield and it was designed to be one. I know of several non-defense companies whose first question on the phone is \"are you a US person as defined by FATCA and FISA ?\". reply TheLoafOfBread 3 hours agorootparentprevThey don't until they compete with some big US company which has direct contacts into government. Then it suddenly matter. reply Dalewyn 6 hours agorootparentprevnext [4 more] [flagged] realityking 4 hours agorootparentThis goes both ways. While the US is certainly open to having scientific payloads launched by non-US launch providers (e.g, JWT) it’s strictly not launching military payloads from non-US spaceport or from non-US vehicles. Given this stance, why should other NATO partners fold their own programs? The situation would entirely different if SpaceX was 20% German owned and the US would allow Ariane to compete for military payloads. As an aside, both ESA and the German Armed Forces habe used SpaceX in the past and ESA, EUMETSAT, and the UK Armed Forces have planned launches with SpaceX. There is far from a dogmatic perspective in Europe to only use Ariane for launches. reply piva00 6 hours agorootparentprevBecause the USA needs NATO and other shit to have soft power and keep its hegemony. Shit like what you said truly makes me wonder about the state of education in the USA when you don't understand a basic geopolitical principle your country has enacted for 80+ years, with massive benefits. reply inglor_cz 4 hours agorootparentUnhappy marriages are unstable, even if they make economic sense. Drag too much resentment into a relationship and people may do the irrational thing. I was witness to the dissolution of Czechoslovakia. Economically, it didn't make sense to do that. But the Slovaks really resented Czech paternalism and wanted to go their own way. reply The_Colonel 7 hours agorootparentprevI don't get what your point is. I didn't question if it's an American company or not. Edit: ok, got it now. This is about a European rocket serving European strategic needs, why would I be talking about USA? reply pmezard 8 hours agorootparentprevAre the US sending military payloads with non-US rockets? reply perihelions 6 hours agorootparentYes: one of the US national security launch vehicles, Atlas V, uses imported Russian main engines. US defense access to space was dependent on Russia for much of the 21st century (after the retirement of the Titan rockets). https://en.wikipedia.org/wiki/RD-180 https://en.wikipedia.org/wiki/National_Security_Space_Launch... https://news.ycombinator.com/item?id=30542226 (\"Russia halts deliveries of rocket engines to the U.S. (reuters.com)\") (It's not a national security payload, but the Starliner ISS astronauts also went up on this Russian engine). reply Reason077 8 hours agorootparentprevThe US is sending military payloads with private, low-cost commercial launch provider SpaceX. The success of this model hasn’t gone unnoticed by China, who are funding several private rocket companies (such as Space Pioneer) to develop reusable launch platforms in competition with the state-owned contractor CASC. They are making rapid progress! reply GuB-42 6 hours agorootparentThe US is sending their military payloads with a US company they have invested in, and most likely have special, undisclosed deals with. It is not just \"a commercial launch provider\". I don't expect the US to launch their military payloads with Chinese rockets, private or not, in the same way I don't expect China to use SpaceX for their own military payloads. Same thing for the EU, they prefer to send their military payloads with their own rockets, that is Ariane. Ariane is private too, it is also a commercial launch provider. It is heavily subsidized by the EU member states and not as competitive as SpaceX, but from a national security perspective, the situation is similar. reply p_l 7 hours agorootparentprevThe USA has been sending military payloads with private vendors since 1970s. In some cases blocking contractually those vendors from providing civilian launch capability, even. SpaceX is absolutely nothing new in the process, other than having been funded by explicit military program to prop up new space launch vendors. reply inglor_cz 8 hours agorootparentprevThat is the problem, right? EU countries, not having a reusable rocket at their disposal, will have to pay through the nose for every launch, discarding the entire expensive rocket in the process. Of course, that will limit their ability to launch satellites into space: the cost of discarding a rocket is high (let's not even start about fairing dimensions and subsequent limits on payload size). Wrecking a sophisticated machine after each use is uneconomical. Meanwhile, the US is galloping towards much cheaper launchers. This means that by 2030 or so, they will be able to put orders of magnitude more tonnage onto orbit. China noticed - and it is trying their darndest to close the gap. reply TheLoafOfBread 7 hours agorootparentSo EU having Arianne 6 is actually a good thing. reply inglor_cz 7 hours agorootparentIt is better than not having it. In the same sense that it is better having a steam-powered railway than no railway capacity at all. But spending on development of new steam engines when the competition already has electric ones is pretty backward. reply Larrikin 9 hours agorootparentprevWhy is it a race instead of being of public and international importance to have an alternative to a for profit company? reply JumpCrisscross 9 hours agorootparent> Why is it a race instead of being of public and international importance to have an alternative to a for profit company? It’s not a meaningful alternative. The comparison to a Yugo is apt: it’s more expensive and less capable, with its sole advantage being it’s made in Europe and so will get European launches. But anyone launching on it is structurally disadvantaged against a competitor (or peer) who launches on SpaceX. reply FranOntanaya 4 hours agorootparentTicket price doesn't tell the whole story, if those euros are staying in Europe instead of leaving the union and funding someone else's space program. reply ddalex 8 hours agorootparentprevit's about maintaining political options - what happens when your peer denies your launches on their platform; what prevents ESA from launching 90% of their payloads on SpaceX for reduced cost, while maintaining alive a credible option ? reply JumpCrisscross 8 hours agorootparent> what happens when your peer denies your launches on their platform Strongly agree—Europe needs an indigenous launch option. Ariane 6 is not it, and I’m sceptical ArianeSpace can ever deliver it. reply ddalex 3 hours agorootparentWhat do you mean, can deliver it? This article is specifically about the maiden flight of Ariane 6, which was successful. It's already delivered. reply JumpCrisscross 2 hours agorootparent> can deliver it? This article is specifically about the maiden flight of Ariane 6, which was successful. It's already delivered. It's not commercially viable. That means it has no room to organically drive economies of scale and thus learning curves, which has downstream effects on evertyhing from recruiting to supplier negotiations. Europe has a launch vehicile. It does not have a platform. Virtually everything in Ariane 6 will have to be thrown out to be relevant in a modern, reusable design. Put another way, SLS didn't prepare Boeing and Lockheed Martin one iota for the modern launch industry. If anything, it drove ambitious people away from them. reply ddalex 2 hours agorootparentThere are no economies of scale required. This is not a commercial venture, and it's not required to be commercially viable. This is a strategic and political program, and as a jobs program it is wonderfully executed - the more to throw away, the more jobs will be required for the next iteration. reply JumpCrisscross 1 hour agorootparent> is a strategic and political program, and as a jobs program Jobs, yes, strategic, no. Being able to put ten birds up in a year means an adversary can blind your space capabilities, if we’re taking the argument to absurd ends. We Americans would be defensive about ULA, probably, if it weren’t for SpaceX. The problem is the EU has no plan B. If SpaceX cuts them off, Ariana or not, they’re crippled as a spacefaring enterprise. reply threeseed 7 hours agorootparentprev> what prevents ESA from launching 90% of their payloads on SpaceX for reduced cost You only have to look at what happened with Starlink and Ukraine. Last thing EU wants is to put their vital strategic interests in the hands of Elon Musk and his erratic whims. Especially given they are planning to fine X 6% of their revenue which may end up bankrupting the company given its perilous financial state. reply m4rtink 3 hours agorootparentWell, that seems to have been a one-off episode. Since then modern versions of at least maritime drones & possible bigger aerial drones in Ukraine are almost certainly Starlink guided, possibly via the military version of it called Starshield. reply trueismywork 8 hours agorootparentprevBecause extra money spent could be better invested elsewhere. Eventually, the high cost will harm the general expertise and readiness. reply lm28469 8 hours agorootparentprev> My money is on they're not going to come out ahead in the race. What race ? Having your own launcher is already a win in a fast changing world reply sschueller 9 hours agorootparentprevWhat race? The race to the price bottom and who can get us to the Kessler syndrom first? reply Diederich 3 hours agorootparent> Kessler syndrom Is this a big risk in the low, high drag orbits that the vast majority of SpX launches target? reply speedgoose 9 hours agorootparentprevI would rather work for the government than working to make someone so rich even more rich. To each their own. reply lucianbr 8 hours agorootparentThat is fine. Government should still be reasonably efficient. Not as efficient as possible by any means possible, with the ethical problems megacorporations have. But reasonably efficient. So it's worth keeping an eye on things and making comparisons. I at least, don't say any dollar more than SpaceX spent by Ariane is bad. But if they spend multiple billions more... maybe we could build some trains or something for that money. reply threeseed 9 hours agorootparentprev> they're not going to come out ahead in the race What race ? And if there is even one who cares ? If EU pays 10x or 100x more to launch satellites the world isn't going to change all that much. reply nordsieck 8 hours agorootparent> If EU pays 10x or 100x more to launch satellites the world isn't going to change all that much. That may be true for a few military satellites. But ESA is talking about putting up a Europoean mega-constellation. In that context, launch costs do really matter. reply threeseed 7 hours agorootparent> In that context, launch costs do really matter. Not really. Strategically important projects rarely live or die based on costs. Especially when they are a fraction of the total spend on the project. reply nordsieck 4 hours agorootparent> There was a lot of hubris in the project in the beginning and now it’s clear that they are years behind. That may be true of other projects, but LEO communications satellite constellations have a history of going bankrupt. Cost is very relevant in this case. > Especially when they are a fraction of the total spend on the project. I guess 40-50% is technically a fraction. reply trueismywork 8 hours agorootparentprevLol it is. More money means less money some place else. Europe is not as rich as it was 40 years ago. General competency will decrease due to lack of money. reply justin66 8 hours agorootparentprev“It’s not my money.” reply m4rtink 4 hours agoparentprevThe problem with this is, that at that point Europe will be most likely again behind not just Space X, with fully reusable Starship likely being operational but possibly even some Chinese Falcon 9 clones (once they get the hold-down clamps sorted out). Sure, Ariane 6 is a stop gap and likely has some interesting tech that will be useful later on, but it was stupid not starting a full blown reusable rocket program at the same time, when it became evident how much of a dead end it is. reply tocs3 3 hours agorootparentFalcon 9 made its first landing (during an orbital mission) Dec. 2015[1]. It was very successful after that. The Ariane 6 program was selected Dec 2014[2]. Reusable vehicles are clearly the way to go but that was a little early to say Falcon 9 was going to be the success it is today. [1] https://en.wikipedia.org/wiki/Falcon_9 [2] https://en.wikipedia.org/wiki/Ariane_6 reply tristor 4 hours agorootparentprev> but it was stupid not starting a full blown reusable rocket program at the same time, when it became evident how much of a dead end it is. Redundancy in novel fields is not a waste, it creates opportunities to try subtly different approaches in various places, and in so doing creates new knowledge that can progress all similar projects in the future. At some point, if you dump the same amount of human resources into a single project vs separate projects, you end up with something approaching the same thing, but resources (dollars/people) aren't entirely fungible and having separated projects provides an opportunity for cultural dissimilarity and other human factors to create innovation that would otherwise be stifled in a larger funded project. Personally, I am really happy to see how much investment from many different angles is happening around space. reply nordsieck 9 hours agoparentprev> 6-10 years from now Ariane Next/SALTO will aims replicate Falcon 9 efficiency and the design will be very similar: reusable, RP-1/LOX, Prometheus engine is similar reusable open cycle engine as Merlin with lots of 3D printed parts. 1. Ariane Next will use a Methalox first stage and a Hydrolox 2nd stage[1], not Kerolox (RP-1). 2. Given how long it took to get Ariane 6 to the launch pad, and its similarities to Ariane 5, 6-10 year is very optimistic. --- 1. From what I understand, this is due to political wrangling. Germany wanted to make the engines for the 2nd stage. IMO SpaceX's approach of using the same engine everywhere is superior. reply m4rtink 3 hours agorootparentNot just the engines - using different propellants between stages complicates ground infrastructure & reduces economy of scale + parts commonality. reply cubefox 9 hours agoparentprevI think it would be, in the long term, more cost effective for ESA to contract two or three private European rocket start-ups, like RFA, to build such reusable launch vehicles. To create some competition in price and development speed. Arianespace (ArianeGroup) seems to be \"old space\" by now, similar to ULA or Boeing in the US. reply JumpCrisscross 9 hours agorootparent> more cost effective for ESA to contract two or three private European rocket start-ups, like RFA, to build such reusable launch vehicles That would trigger politically-impossible lay-offs in France. reply cubefox 8 hours agorootparentYeah, it seems impossible for ESA to act rationally in this regard when bound e.g. by French veto. The only opportunity would be for individual countries (like Germany) to fund such rockets alone, but that seems unlikely due to cost (and the fact that they already pay for ESA). Without substantial investment, companies like RFA don't have the means to create a larger rocket, due to heavy international competition. Not even NASA could resist developing their SLS rocket, which realistically should have been replaced with funding private heavy lift rockets. And that is despite the fact that they are much less politically constrained than ESA. reply snowpid 7 hours agorootparentThe only opportunity would be for individual countries (like Germany) to fund such rockets alone, but that seems unlikely due to cost (and the fact that they already pay for ESA). Germany does it in its national program. https://www.dlr.de/de/ar/themen-missionen/raumfahrttechnolog... reply cubefox 7 hours agorootparentThat's just for small launchers and the funding is only 25 million in total (to be divided by several companies) which is orders of magnitude lower than would be required for a partly reusable Ariane 6 replacement. reply snowpid 6 hours agorootparentstart small and start a competition. Then afterwards you get more and more competent companies. reply nordsieck 8 hours agorootparentprev> That would trigger politically-impossible lay-offs in France. And yet, that seems like the model ESA is moving to. Not exactly - it's more NASA style letting companies bid on launches instead of directly funding rockets. But close enough. I don't think ArianeGroup is in trouble in the near term. But Avio - the makers of Vega - are very unhappy about that direction, since the current crop of Rocket startups more directly competes with them. reply m4rtink 3 hours agorootparentprevYeah, I think this is the only way Europe is going to get a viable reusable rocket in the end. Arianespace is a dead end. reply protomolecule 6 hours agorootparentprevSpaceX wasn't the first American rocket startup, other ones failed. What makes you think European startups won't fail? reply cubefox 5 hours agorootparentI suggested funding multiple ones. reply JumpCrisscross 9 hours agoparentprev> 6-10 years from now Ariane Next/SALTO will aims replicate Falcon 9 efficiency and the design will be very similar …at which point it will be competing with Starship. reply pmontra 9 hours agorootparentIt will still be building that knowledge inside Europe. Rocketry in general is deemed to be strategic so it's OK for any country to invest money in that, keep scientists and engineers on the subject, keep the industries alive, etc. It's not only about access to space, it's also about defense. reply JumpCrisscross 9 hours agorootparent> will still be building that knowledge inside Europe Ariane 6 cannibalises Europe’s chance at being more than an also-ran in space: “An Arianespace manager pushing his company as the only solution to Europe’s launch challenges isn’t that noteworthy. However, the fact [Arianespace’s CEO] urges the need for a ‘reusable heavy launcher’ is notable, considering his previous noncommittal remarks about rocket reusability. The certainty of his statement leaves no ambiguity–Ariane 6 just won’t be able to compete in the global market. It will take a (single and expensive) reusable heavy launcher (manufactured by Arianespace) and (funded by) a unified Europe to compete (with SpaceX). While [Arianespace’s CEO’s] admission of reusability’s future in Europe is surprising, his constancy in his attempts to keep European space activities hostage to Arianespace is not. To be clear, he wants European taxpayers to fund reusability development and manufacturing only through Arianespace. He believes Europe can’t afford more than one reusable heavy launcher and that if Europe were to pay for a reusable rocket, then Arianespace must manufacture it.” https://www.illdefined.space/arianespace-the-only-fish-in-th... reply snowpid 8 hours agorootparentWhile that attitude makes sense for ArianeSpace , I doubt they will be successful. reply imtringued 4 hours agorootparentprevYou're under the misconception that it makes sense for Europe to have a launch vehicle at all. The launches happen in French Guiana. The only reason why you would build it on the European mainland is as a jobs program for Europeans. No commercial entity would come up with the idea of building a launch vehicle in Europe. Making a rocket reusable means that it would not leave French Guiana far behind. There would be less need for rockets from the European mainland. reply JumpCrisscross 2 hours agorootparent> under the misconception that it makes sense for Europe to have a launch vehicle at all. The launches happen in French Guiana Launch controlled by Europe. French Guiana is Europe, geopolitically speaking. SpaceX building rockets in Europe wouldn't give Brussels the strategic autonomy of an Ariane launched from below the equator. reply sgt101 9 hours agorootparentprevYes, and the industrial base that we are discussing is the one that builds the M51.3 which is fundamental for Europe. Existence is worth a lot. reply 627467 7 hours agorootparentprevwill it? or will engineering talent just move elsewhere after realizing their talents are wasted in bureaucratland? reply lapphi 7 hours agorootparentIs nationalism really so far in the past already reply 627467 7 hours agorootparentnationalism is dying with the older generations and importing new labour from abroad is not really the short term solution for that reply okasaki 6 hours agorootparentprevWhat's strategic about it? We give all of our data to US companies and that's ok (?), but for some reason we need to be able to launch our own rockets? reply flohofwoe 9 hours agorootparentprevUnless Europe wants to build a moon base or new ISS, won't a Starship competitor be a bit overkill for most payloads? reply JumpCrisscross 9 hours agorootparent> won't a Starship competitor be a bit overkill for most payloads? No, for the same reason trucks aren’t overkill for horses in logistics. Unit costs, lead time, orbital flexibility: there isn’t a market for Ariane 6 left. Even ArianeSpace’s CEO admits Ariane 6 is obsolete and that Europe needs “a reusable heavy launcher” [1]. [1] https://www.illdefined.space/arianespace-the-only-fish-in-th... reply flohofwoe 8 hours agorootparent...well the Ariane 6 is already in the category of \"heavy lift vehicle\" at up to 22 tons payload. I'm wondering how much of a market there is in the end for a super-heavy lifter like Starship. But I guess we'll see soon. reply nordsieck 8 hours agorootparent> I'm wondering how much of a market there is in the end for a super-heavy lifter like Starship. But I guess we'll see soon. The biggest market is probably internally for Starlink. But itself, that'll be quite a lot of launches. Especially if SpaceX ends up pursuing an enlarged constellation size. For the same reason, it's almost certain that ArianeSpace won't get any launches in the 2nd Kuiper tranche - New Glenn should be more efficient and capable than either Ariane 6 or Vulcan. Even if it isn't up to the task operationally, Vulcan will probably receive the balance of launches. reply haspok 9 hours agorootparentprevYou don't know that. Starship does not exist. reply chgs 9 hours agorootparenta thing which can get into orbit and deploy objects exists reply simiones 8 hours agorootparentA thing which can nearly get into orbit. It never quite reached it (probably intentionally). But more importantly, the recent Starship tests ran with no payload whatsoever, and they definitely didn't deploy anything into orbit. reply imtringued 4 hours agorootparentprevI don't know what you mean by deploy objects, but even according to Musk himself, the current Starship version will not carry any payloads any time soon. reply Reason077 9 hours agoparentprev> “The launch cost is almost 2x the cost of Falcon 9.” This actually seems quite reasonable considering the Ariane 6 is a non-reusable, low-volume design. reply JumpCrisscross 8 hours agorootparent> seems quite reasonable considering the Ariane 6 is a non-reusable, low-volume design It’s after subsidies [1]. Actual costs are 4 to 6x Falcon 9, and that’s comparing actual costs today for Falcon 9 to projected costs in the future for Ariane 6. [1] https://www.space.com/europe-ariane-6-rocket-debut-launch reply jinzo 8 hours agorootparentYou do know that this article completely forgets to mention if SpaceX got any subsidies? From a quick google search, it seems that this is not the case and I have a feeling that Falcon 9 sticker price is in fact subsidied by the USA. So - why compare apples to apples, when you can compare apples to oranges. reply InTheArena 5 hours agorootparentIt is not. The sticker price is not subsidized by the state. The state does buy a lot of launches as a consumer. These are often conflated. reply dotnet00 3 hours agorootparentprevFalcon 9 is 'subsidized' by the USA in the way that businesses 'subsidize' development of new products and services through profit from selling products, getting investors and completing contracts at fixed cost to the customer. Ariane is subsidized in that their development expenses are fully paid for by government coffers, and additional money is provided yearly regardless of services rendered to make the sticker price for a launch seem lower. reply JumpCrisscross 7 hours agorootparentprev> this is not the case and I have a feeling that Falcon 9 sticker price is in fact subsidied by the USA They’re both state supported. But Falcon 9 is cash-flow positive on commercial launches where the only operational subsidies are launch complex access. reply Y_Y 9 hours agoparentprevYou're quite right, but for apples-to-apples you should compare to NASA rather than SpaceX. \"Move fast and break things\" is an attitide that only relatively new rocket builders can have. reply JumpCrisscross 9 hours agorootparent> for apples-to-apples you should compare to NASA rather than SpaceX ESA is analogous to NASA. ArianeSpace is Europe’s ULA. Europe doesn’t have a SpaceX; Ariane 6 is a Yugo in the modern launch market. reply m4rtink 3 hours agorootparentRocket Factory Augsburg or Isar Aerospace might become the Space X of Europe. ;-) reply contrarian1234 9 hours agoparentprevAre the Europeans wworried that \"between now and 2030s\" the US will cut off their access to space? I understand things can go wrong and it's good to have a backup plan in the long term... But that's not that many years out. You can go without access for a few years .. It seems like a tiny risk reply boricj 7 hours agorootparentThe French mantra is strategic autonomy. We are allies with the USA, we are not vassals of the USA and we do not want to depend on anybody else to defend our own interests or our own agenda. This is why the French army has independent expeditionary and nuclear deterrent capabilities and why nearly all of our military kit is designed and produced either locally or in partnership with nearby European countries. It's not that we don't trust the Americans per se (although opinions may differ on that topic), but we don't want to have to. ArianeGroup also manufactures the M51 missile that goes inside our SSBNs and unlike the Brits we do not accept depending on Americans supplying us with the missiles for our nuclear deterrent. reply contrarian1234 6 hours agorootparentIt seems just a ton of money and R&D down the drain developing something already obsolete for some tiny and very theoretical advantage. It seems more sensible to lose a tiny bit of independence for a small window of time and instead use the money to develop an actual state of the art rocket. reply boricj 4 hours agorootparentDe Gaulle would be rolling in his grave hearing this. The point is not about economic efficiency. The point is that we're not one embargo on foreign components or systems away from crippling our capabilities and surrendering our ability to act independently. The Charles de Gaulle aircraft carrier almost got immobilized back in the early 2000s due to withholding of spare parts from the USA because they were pissed we called bullshit on their Iraq WMD claims. The USA routinely uses ITAR as a pressuring tactic to stop European weapon sales to foreign countries, which is why we're actively scrubbing every last ITAR component from all of our weapon systems. Just because we're allies doesn't mean that the other party has or will have our best interests at heart. The Americans have proven to be quite temperamental and under-handed when our strategic objectives aren't aligned with theirs. reply m4rtink 3 hours agorootparentprevSimple solution - get a decent launcher instead & deploy your nukes in orbit. Problem solved! :) reply fallingknife 6 hours agorootparentprevWish more NATO members had that attitude. reply protomolecule 5 hours agorootparentprev>we are not vassals of the USA Aren't you? In 2003 Russia, Germany and France were strongly against illegal American invasion of Iraq. The US invaded anyway, ruining the country. What have France and Germany done about that? reply boricj 5 hours agorootparentFrance among many nations called bullshit on the WMD claims, we threatened to veto the UN Security Council resolution authorizing a military intervention and we refused to get involved in that mess. The fact that the US government decided to unilaterally invade Iraq anyway is not our responsibility to bear. What could France have done more, try and enact economic sanctions or wage war against the USA over this? reply actionfromafar 4 hours agorootparentprevThey did not participate? reply jltsiren 9 hours agorootparentprevThe US has been an unreliable partner since Bush Jr. became the president. Every 4 years, there is a real risk that things will go wrong. reply Beretta_Vexee 8 hours agorootparentIt's more complicated than that. Even before W Bush, the United States didn't hesitate to twist the arm of its partners in economic matters. France and the USA may be allies, but economic relations have been complicated for over 40 years. The USA has no hesitation in interfering with or sabotaging the French economy (aukus subs, alstom, airbus defense, galileo), claiming that its law is extraterritorial in order to condemn company directors, and all the drity tricks imaginable. This is what led many European companies and gouv in the 90's and 00's to prefer partnerships with Chinese and Russsian companies. Even the British, with their special relationship, have completely isolated their nuclear industry from all US companies for fear of being screwed and at the same time signed partnership with CGN in China. reply pfdietz 1 hour agorootparentThat's what happens when your group of nations freeloads on a superpower for their defense. reply Beretta_Vexee 8 hours agorootparentprev> Are the Europeans wworried that \"between now and 2030s\" the US will cut off their access to space? Ariane Group is first and foremost a defense company owned by the French state, Germany and several other European countries. Ariane group designs and manufactures French ICBMs. This is a significant part of its business. The French government wants a sovereign means of putting heavy military satellites into orbit (twice the weight of the Hubble telescope). The French state will never let its intelligence, early warning and nuclear deterrent depend on the United States. reply PedroBatista 9 hours agorootparentprevLooking at the geopolitical situation both next door and across the pond the answer is a yes. Also keeping the expertise and the people is a critical factor. reply badcppdev 6 hours agorootparentprevSometimes nation states might disagree on what should be done in certain circumstances. An example of this is 39 years ago on this day the French government blew up a civilian boat in New Zealand [0]. Crazy but true. Having independent capabilities is part of being a sovereign rather than vassal state. 0 - https://en.wikipedia.org/wiki/Sinking_of_the_Rainbow_Warrior reply yourusername 6 hours agorootparentprev>Are the Europeans wworried that \"between now and 2030s\" the US will cut off their access to space? Both US presidential candidates are not mentally well. Who knows what they might do. reply nabla9 8 hours agorootparentprevNot really, but European countries launch military payloads and other strategic stuff like Galileo satellites and communication satellites. All are friends with NATO, but that does not exclude spying and all kinds of shenanigans. US spies non-Five Eye countries mercilessly. They get caught sometimes. Like the systematic wiretapping trough Danish cables from 2012-2014. reply dividedbyzero 8 hours agorootparentprevIn the event of another Trump presidency (or a successor in spirit) getting cut off for military purposes is probably more like expected, and in a post-NATO world Russia might get a lot more aggressive towards western Europe. That's probably what is behind most such time horizons right now, but even in the mid to long term, rocket tech will remain highly strategic (e.g. for nuclear weapon delivery), and capabilities like that need to be built up well before any conflict escalates. reply protomolecule 6 hours agorootparent>in a post-NATO world Russia might get a lot more aggressive towards western Europe Why not the opposite? NATO is a threat to Russia, Western Europe alone -- not as much. reply jcranmer 4 hours agorootparentIf your dream is to restore Russia to its imperial greatness, there's an awful lot of EU countries that need to be gobbled up along the way, so France is quite likely to be willing to help a Russian-Estonia war even without NATO. NATO is only a threat to Russia insofar as it poses an obstacle to Russia gobbling up its neighbors. reply nick__m 3 hours agorootparentprevNATO is purely defensive, it won't invade Russia. It only threatens Putin's empire rebuilding dreams. Without NATO he is free to rebuild and expand Russia's empire. reply Kuinox 9 hours agoparentprevBy then, startship would have lowered cost even further. reply threeseed 9 hours agorootparentStarship has a payload 10x-15x larger than the smaller Ariane 6 variant. It seems like for the cost to be lower you would be wanting to fit as much as possible thus impacting how often it is being launched. So not sure if the two have the same requirements. reply dhedberg 9 hours agorootparentI suspect that you don't really need to fill all the seats of a reusable 737 before it's cheaper to fly than a single-use Cessna. reply JumpCrisscross 9 hours agorootparentprev> seems like for the cost to be lower you would be wanting to fit as much as possible thus impacting how often it is being launched Starlink alone will fill Starship’s most-ambitious deployment schedules for years. That gives plenty of piggyback capacity to swamp the market with. reply justin66 9 hours agoparentprev> The launch cost is almost 2x the cost of Falcon 9. I bet it will be a lot more than that. reply Cthulhu_ 6 hours agoparentprevIt may be 2x the cost of Falcon 9, but it's a different use case and volume (~10 per year for Ariane, ~100 for Falcon 9); Ariane 6 would not be cheaper at those volumes if it was reusable. Also keep in mind that most of Falcon's use is for SpaceX itself, 2/3rds of launches are for Starlink. reply zitterbewegung 5 hours agoparentprevNot sure why everyone here is talking about cost when independent control is much more to be desired. If a country / countries aren’t as friendly or dislike what you want to do they might not let you do what you want. reply sligor 9 hours agoparentprevIs the cost difference mostly due by design or also due to much higher production volume and launches for Falcon 9 ? reply topspin 8 hours agorootparentBoth. reply Sakos 4 hours agoparentprev> The launch cost is almost 2x the cost of Falcon 9. I can't be the only one who thinks this is still a huge win. What did launch costs look like 10-30 years ago? reply ur-whale 9 hours agoparentprev> 6-10 years from now Ariane Next/SALTO will aims replicate Falcon 9 efficiency and the design will be very similar: And by then, SpaceX will be 10 years ahead of them with a next-gen platform. Not a great sounding story. reply TheLoafOfBread 7 hours agorootparent> And by then, SpaceX will be 10 years ahead of them with a next-gen platform. Or going bust if Starship will turn out to be a flop. reply jajko 8 hours agorootparentprevFor any European? Thats fantastic. Let that ego maniac and putin's admirer chase latest and shiniest, we all will learn from his success and failures. We (US vs Europe) are not racing nor competing in this in any way, we just need to put out payload up there too. We desperately need our own skillset though, with Trump or similar breed potentially at power across the pond US will become more hostile towards Europe and let russia roll over Ukraine and maybe further, absolutely no doubt there. reply admissionsguy 7 hours agoparentprev> 6-10 years from now Ariane Next/SALTO will aims replicate Falcon 9 efficiency and the design That's what presentation by some high-ranking ESA person said when I was considering joining a Master's program in Spacecraft Design in Kiruna, Sweden, where some ESA launch facilities are located. I found that goal extremely uninspiring, especially combined with European salaries, so I opted to keep getting paid well working on software to feed people more burgers. reply christkv 9 hours agoparentprevThe main genius of SpaceX is the mass production. Hopefully they can replicate that",
    "originSummary": [
      "Europe's new heavy-lift rocket, Ariane 6, successfully launched from French Guiana on 9 July 2024, marking its inaugural flight, VA262.",
      "The launch demonstrated Ariane 6's capabilities, including placing satellites into orbit and showcasing its new launch pad built by CNES.",
      "Ariane 6, built by ArianeGroup, signifies a new era for the European space industry, with its upper stage demonstrating engine restart and safe deorbiting capabilities."
    ],
    "commentSummary": [
      "Europe's new heavy-lift rocket, Ariane 6, has successfully completed its inaugural flight, aiming to provide independent access to space for European countries until the 2030s.",
      "Despite being nearly twice as expensive as SpaceX's Falcon 9, both rockets have the capability to lift 22 tons to low Earth orbit.",
      "Future plans for Ariane Next/SALTO aim to achieve similar efficiency to Falcon 9 with a reusable design, though critics note that SpaceX benefits from taxpayer support and military/NASA facilities, complicating direct cost comparisons."
    ],
    "points": 305,
    "commentCount": 330,
    "retryCount": 0,
    "time": 1720600932
  },
  {
    "id": 40928893,
    "title": "Zed on Linux Is Here",
    "originLink": "https://zed.dev/linux",
    "originBody": "ReleasesBlogAboutDocs Download Zed on Linux is here! To install Zed on most Linux distributions, run the shell script below. Blog post →Docs → curl https://zed.dev/install.shsh © 2024 Zed Industries. EULA · Attributions · Sign in Product Download FAQ Roadmap EULA CLA Developers Docs Releases GitHub↗ Status↗ Community Blog Feedback Discussions↗ Merch↗ Company About Team Jobs Twitter↗",
    "commentLink": "https://news.ycombinator.com/item?id=40928893",
    "commentBody": "Zed on Linux Is Here (zed.dev)214 points by 0xedb 2 hours agohidepastfavorite176 comments handsaway 1 hour agoI tried zed for a few weeks because I'm generally sympathetic to the \"use a native app\" idea vs Electron. I generally liked it and its UX but: 1. VSCode is pretty damn fast to be honest. Very rarely is my slowdown in my work VSCode loading. Maybe I don't open very large files? Probably 5k lines of typescript at most. 2. Integration with the Typescript language server was just not as good as VSCode. I can't pin down exactly what was wrong but the autocompletions in particular felt much worse. I've never worked on a language server or editor so I don't know what's on zed/VSCode and what's on the TS language server. Eventually all the little inconveniences wore on me and I switched back to VSCode. I will probably try it again after a few more releases to see if it feels better. reply the_duke 1 hour agoparentI think people just have very different tolerances for latency and slowness. I keep trying different editors (including VS Code), and I always end up going back to Neovim because everything else just feels sluggish, to the point where it annoys me so much I'm willing to put up with all the configuration burden of Neovim because of it. I tried out Zed and it actually feels fast enough for me to consider switching. reply whalesalad 1 hour agorootparentSublime Text 3 is still one of my favorite editors. I use VSCode lately because of its excellent \"Remote SSH\" integration - but when it comes to latency sublime has it beat. Zed does not feel fast on my machine, which is a 13900K/128gb ram. It is running in xwayland though, so that could be part of the problem. It feels identical to vscode. reply correct-horse 12 minutes agorootparentnext [–]It is running in xwayland though It definitely isn't on my system, and I did not touch the configs at all; are you sure about that? reply whalesalad 8 minutes agorootparentFairly positive due to blurry cursors, but I have no way to verify. reply barnabee 1 hour agorootparentprevI use Helix and feel the same way. The pickers/fuzzy finder particularly have no equal for speed in any editor I’ve found. (Zed seems pretty fast but I didn’t get on well enough with it to find out how it performs with more serious use.) fwiw I’ve also found the configuration overhead much lower with Helix than for pretty much any other editor I’ve seriously used. reply danielvaughn 51 minutes agorootparentThis makes me want to use Helix, because while I love the idea of a terminal editor, I'm not the kind of person to whittle away a day screwing around with my config files. reply silisili 8 minutes agoparentprevA few weeks ago I had this giant json text blob to debug. I tried Gedit first, and it just fell over completely. Tried vim next, and it was for some reason extremely slow too, which surprised me. VSCode loaded it nearly immediately and didn't hang when moving around the file. I have my complaints about VSCode, but speed definitely isn't one of them. reply sensanaty 46 minutes agoparentprevI don't use it as my main editor (I'm far too used to the Jetbrains editors to make the switch, they're just too smart), but it's the best one for CLI apps that use EDITOR, like git. It boots up basically instantly even when it hasn't been launched in a while and I can make my commit messages and immediately close stuff up at the speed of my thought. reply MrJohz 58 minutes agoparentprevYeah, this was mostly my experience. The Zed editor was fast, but it just felt like it wasn't as good as other editors. For me, the version control integration was particularly poor - it shows some line information, but diffing, blame, committing, staging hunks, reviewing staged changes etc are all missing. There were a bunch of decisions that felt strange, although I can imagine getting used to them eventually. For example, ctrl-click (or jump to usages) on a definition that is used in multiple places opens up a new tab with a list of the results. In most other editors I've used, it's instead opened up a popover menu where I can quickly select which really I want to jump to. Opening those results in a new tab (and having that tab remain open after navigating to a result) feels like it clutters up my tabs with no benefit over a simple popover. Like you, I'll probably try again in a few releases' time, but right now the editor has so much friction that I'm not sure I actually save any time from the speed side of things. reply dijit 1 hour agoparentprevYeah, I agree about VSCode being sort of fast enough. Computers are getting faster and I’m on a M-series mac which makes web rendering much faster but still I feel like as far as electron apps go: VScode is basically the golden child. Slack & Teams on the other hand, ouch. reply danielvaughn 52 minutes agoparentprevYeah my experience has been that you aren't going to suffer performance problems with VSCode unless you have an incredibly large codebase. Past a certain point I'm sure Vim/NeoVim/Zed are probably much more performant, but the differences in smaller codebases is barely noticeable IME. reply yoyohello13 1 hour agoparentprevMy only problem with VSCode is that it's owned by Microsoft. I'm willing to put up with some extra friction if it allows me to escape their ecosystem even a little bit. My general rule is if I can get at most of what I need from the open source version of something, I use it. Even if it's less user friendly. reply whalesalad 1 hour agorootparentbut vscode is open source: https://github.com/microsoft/vscode and there are third-party builds from the community that disable things like telemetry: https://vscodium.com/ reply yoyohello13 1 hour agorootparentSorry, I should have been more specific and said FOSS. VSCode is still encumbered by the weight of a mega corp. It's like saying Chrome is open source. Sure it is, but it still exists to serve the corporation that owns it. reply TiredOfLife 44 minutes agorootparentIt's MIT licensed. So it's more FOSS than FOSS reply o11c 8 minutes agorootparentIt isn't 1860 anymore, \"the freedom to take freedom away\" no longer counts. reply correct-horse 18 minutes agorootparentprevIt's free software in letter, but not in spirit. True free software doesn't lock out non-official builds for zero technical reasons. reply fragmede 8 minutes agorootparentwhat about vscodium? for that reason, what was iceweasel? screcth 59 minutes agorootparentprevThe problem is that many parts of the ecosystem require that you use the official MS build. You can't connect to the Marketplace and some extensions outright can't be used with a custom build. reply vorticalbox 39 minutes agorootparentYou can however down the extension from the website and install it from the terminal. codium --install-extension {path to .vsix} reply 0cf8612b2e1e 36 minutes agorootparentprevYou mean except for all of the good plugins. Or the ability to use a custom plugin store. Last I read, the open builds struggled with removing all of the MS telemetry and some may still be leaking. reply 3836293648 2 minutes agoprevTried it with mangohud and scrolled up and down a 100-line c++ file with no lsp enabled. 30fps. Absolutely not ready yet. Not sure I'm willing to leave Emacs, but gpui looks cool and I hope someone makes a fast Emacs client with it some day. reply dcchambers 6 minutes agoprevHowever silly it is, I've always hated the aesthetics of VS Code. I know it's themeable but despite that the overall look and feel just isn't right on MacOS or Linux. That side bar drives me crazy. I find that out-of-the-box Zed is much prettier and feels more native than VS Code. But for a tool that we spend hours using each day, how it looks and makes you feel really matters. I am enjoying experimenting with Zed. I have kept my extensions and configuration to a minimum which is a refreshing change compared to the cluster that my VSCode installation has become. reply llagerlof 1 hour agoprevJust a suggestion. One of the best features of pure text editors (and incredible, not all of them implement it) is autosave keeping the \"unsaved\" state of the file. For example, if you make some changes in a file (new or not), don't save the changes, close and open the editor, the state of the opened files are kept like I never had closed the editor. The unsaved files are still unsaved. New edited files are still there, unsaved, ready to user manually save them. Notepad++ works that way, and it is an amazing feature. reply sa-code 8 minutes agoparentSublime works this way and I do appreciate it reply misternugget 1 hour agoparentprevWorking on it! reply jchw 1 hour agoprevMan, I'm conflicted. I mean, Zed works pretty damn well. So far my biggest annoyance with Zed though is that it's constantly trying to download language servers and other tools and run them. And sure, that's handy, but 1. I don't really want it, I'd much rather only use distribution-provided tools. 2. It doesn't work at all on NixOS, so it's just wasting its time and our bandwidth constantly downloading and trying to update binaries that will never run. The thing is, I would just disable it, but you can't, as far as I can tell. There's this somewhat angry issue about it here: https://github.com/zed-industries/zed/issues/12589 They might have a point but beyond whether or not they have a point regarding the fact that it automatically fetches binaries from the Internet, not having an option to disable it is just cruel. I still like Zed a lot and I also have a big appreciation for the design of GPUI, which I think is a very well-designed UI library that puts focus on the important things. So, I hope it goes well. reply mikaylamaki 42 minutes agoparentAfter we finished prepping this linux launch, we've started work on making this situation better. Follow along here: https://github.com/zed-industries/zed/pull/14034 reply jchw 28 minutes agorootparentOh, thank goodness. Yeah, that's going to be a major quality of life improvement for me. I had a feeling it'd eventually make its way into Zed eventually, but when I initially read the issue I was under the impression that there was no plans to add options around this, which I found confusing. reply brunoqc 21 minutes agoparentprev> It doesn't work at all on NixOS Doesn't it work with: zed-fhs = pkgs.buildFHSUserEnv { name = \"zed\"; targetPkgs = pkgs: with pkgs; [ zed-editor ]; runScript = \"zed\"; }; Still not ideal though. reply 1oooqooq 10 minutes agoprevI don't really like their editor, but their fonts (based on iosevka) is my 2nd favorite (after Mensch). And their opensource development mode is the best one I've seen so far! So many nice choices. reply dario_od 7 minutes agoprevSadly I can't run it in WSL. thread 'main' panicked at crates/gpui/src/platform/linux/wayland/client.rs:143:51: called `Result::unwrap()` on an `Err` value: UnsupportedVersion note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace reply hollerith 8 minutes agoprevOn a 14-year-old desktop computer (with a Core i5-2400S running Fedora 40) typing feels very \"mushy\": There is a constant latency of roughly a quarter of a second from the keystroke to when anything changes on the screen after inserting a character or hitting the left or right arrow key. reply foresto 1 hour agoprevLooks like they're developing their own Apache-licensed GUI framework for this, called GPUI. I think of text handling as one of the trickier parts of building such a framework, so one specifically made to support a text editor would seem to be a pretty good foundation for a general purpose GUI toolkit. I wonder if they (or someone else) will pursue it as an alternative to Qt. reply jchw 59 minutes agoparentGPUI is very cool, they have blogged about it before. https://zed.dev/blog/videogame Many UI libraries being built today want to be very forward-focused, so they focus on being as general as possible. This does make some sense, especially considering that, for better or worse, using a web browser engine as a UI has become increasingly popular of a decision. However, in the end this leads to almost all new \"greenfield\" UI projects trying to develop scalable vector UI rendering engines that need advanced and highly optimized vector rendering libraries like Skia and Pathfinder. Having everything in vector all the way through is elegant, but it's complicated. The insight with GPUI is that it's not really necessary to be that general, the vast majority of UIs are made up of a relatively small number of different primitives that you can build on to basically do anything. So instead the vast majority of what's going on in GPUI is layers of roundrects. Text rendering is the classic approach of rendering into glyph atlases. I think this is a vastly more sustainable model for a UI library. I don't know if GPUI is ready to be used on its own, but it does have a spiffy if brief website. https://www.gpui.rs/ Given that Zed actually has good \"UI-feel\", it tells me they are focused on the right things. A lot of new greenfield UI frameworks are spending a ton of time on trying to build extremely generic vector graphics systems but the actual widgets feel bad and are missing all kinds of tweaks and nuance. Here's a good litmus test for text editors: what happens if you double click and drag? In most good UI frameworks, this should result in word selection and then expanding that selection left or right. In a lot of smaller greenfield UI libraries, something vastly less useful will happen :( reply vondur 22 minutes agoprevSurprised they didn't make it a FlatPak. Probably would anger some, but it would work with most Linux distributions. reply lbhdc 1 hour agoprevZed seems like its gotten a lot of buzz on HN, and its great to see new players in the space. For those who have used it, what are some of the killer features? reply wolfadex 1 hour agoparentFor me the \"killer feature\" is a graphical editor (like VSCode or the Jet Brains editors) but with performance more like vim. I'm also very much enjoying the modal editing, which VSCode lacks. reply unshavedyak 1 hour agorootparentWait, Zed is a modal editor? All i've seen is that it has vim mode, which most editors have and i generally find it insufficient. Granted these days i still prefer Kakoune style modal editing (i use Helix, currently), so not sure i could move back to Vim style anyway. Nonetheless if Zed has real, first class support i'd be interested... but a second class compat layer is not sufficient in my view. How's it work for you? edit: https://news.ycombinator.com/item?id=40929169 this post suggests it's lacking. Which is always the problem to me with emulation :/ reply thesuperbigfrog 1 hour agorootparentprev>> I'm also very much enjoying the modal editing, which VSCode lacks. The VSCode Vim plugin works great: https://marketplace.visualstudio.com/items?itemName=vscodevi... reply wolfadex 1 hour agorootparentWhen I specified the modal editing I was referring to how the workspace search in Zed brings up each result in an editable \"window\" allowing me to make edits across my whole project from 1 tab. VSCode's workspace search feels much more limited in comparison. reply thesuperbigfrog 1 hour agorootparentThat sounds like an interesting feature. Could you provide a link that gives more information about it? I am not finding it in the docs. reply mikaylamaki 39 minutes agorootparentWe call them 'multibuffers' :D https://zed.dev/features#multi-buffers reply wolfadex 1 hour agorootparentprevI'm not seeing it in the docs, maybe I should write up a little something on my editing experience! Also to correct my self, I think I mistakenly said `modal` when I should have said `buffer` earlier. So searching across the project brings up your results in multiple buffers, each about 5 lines (expandable to more) and you can do all of your normal editing within each/all of the buffers. If I happen to write something up, I'll try and remember to share it in this thread. reply thesuperbigfrog 1 hour agorootparentThat is a unique feature. Most editors I have used use the search as a way to jump to buffer locations of the matches. reply Zambyte 1 hour agorootparentprevFWIW Emacs also fits that bill. reply wolfadex 1 hour agorootparentIt does, though I found learning and setting it up to be more complicated. My preferred editor is one that's very simple to setup and use (e.g. Sublime, VSCode, Zed, nano). Emacs is cool, and maybe someday I'll get around to using it but so far it hasn't met my needs. reply Zambyte 1 hour agorootparentFair enough, I have personally spent a decent chunk of time configuring my Emacs setup (though it has mostly stabilized at this point). You may be interested in checking out Doom Emacs[0] if you want to take a stab at it in the future. It sounds like it would be an out of the box experience closer to what you would want. [0] https://github.com/doomemacs/doomemacs reply nequo 1 hour agoparentprevBesides speed, the other killer feature that Zed focuses on is collaborative editing: https://zed.dev/docs/channels reply pcthrowaway 1 hour agoparentprevI haven't used Zed in the last year, but Zed's search across codebase display was divine. I don't want to necessarily open the file when looking at search results to see additional context in the matching sections. Zed brings up a view with all the results where you can expand context, and IIRC even edit in the results panel without having to open the entire file. It's also collaboration-first, and unlike VS code, I believe the software behind collaboration mode is open source reply threatofrain 1 hour agoparentprevNo killer features, just nice ergonomics and speed out of the box. I use it as my Vim replacement. reply nickorlow 1 hour agorootparentWhat motivated you to switch to it from vim? reply boomskats 1 hour agorootparentprevDo you find it to be faster than vim/neovim? reply vehemenz 1 hour agorootparentThe Vim emulation is pretty far behind JetBrains, VSCode, and Sublime Text. I wouldn't compare it to Vim as a replacement at this point. reply renewiltord 1 hour agorootparentprevDo you use it for Rust? Does it do \"Show usages\" well when the usages are through a macro? reply choilive 1 hour agoparentprevIts killer feature seems to be speed. Otherwise I dont see much of a reason to use it over VS Code. reply gavmor 1 hour agorootparentHave you had much success with VS Code's multiplayer extensions? I've found them buggy to the point of useless, but maybe things have improved. Zed, on the otherhand, is developed by people who understand pair programming, which is my priority. reply cmiles74 1 hour agorootparentNot the OP but I tried hard, looking for an easy pair programming solution. Worked decently a couple of times and inexplicably failed most of the time. reply gavmor 1 hour agorootparentThis is why I'm excited to try Zed. I regularly \"pair\" via Pop, but keybindings and lag make it hard to switch seats, so we basically decide at the beginning of the session who is going to hog the keyboard, and that's a crippling dynamic. reply choilive 1 hour agorootparentprevNo not much experience there since multiplayer editing has never really been a part of my personal workflow (mostly a lot of screensharing), but I can definitely see that being useful for people that use it regularly. reply drcongo 1 hour agoparentprevI use it as my secondary editor (after Sublime) but could easily see myself switching in the not too distant future. It's incredibly fast, possibly even more so than Sublime, and really well designed. While the UI design of an editor is possibly not that important to a lot of people, I find it really matters to me for unknown brain reasons, I get anxious if I ever have to use VS Code as it has zero attention to design details. I'm really pleased for the Zed team on reaching this milestone. I think the only thing holding me back from it being my daily driver is the built-in Pyright (which I hate) and lack of Ruff support. reply sauercrowd 1 hour agoprevCool to see a new editor in the arena with a lot of resources behind it, but I'm trying to find the selling point besides \"it's really quick\". Great feature but there's a lot more stuff I need for a truly outstanding editor, what are the novel pieces? The bar is ridiculously for editors (vim & emacs configurability, vscode just works, jetbrains can do it all) - what will/does it bring to the table to compete? reply mikaylamaki 40 minutes agoparentAs a Zed developer, our killer feature is the parallel programming that our software enables. It's like pairing without the terrible parts. reply taosx 1 hour agoparentprevI really enjoy the AI assistant it has. One of the simplest easiest ways for me to interact with chatgpt/claude apis. Write prompt, copy, paste code. reply marcodiego 43 minutes agoprevThe last collaborative editor that I could use locally successfully was gobby. Currently its development is very slow or seems abandoned. I've been waiting for Zed because it was introduced as something that was \"multiplayer-first\" from the beginning. Reading the docs now, it looks like I need a feature called \"channels\" that I couldn't confirm can be used fully locally. Is there a way to use Zed as a collaborative editor fully locally? reply croemer 34 minutes agoprevTo save you time: If you're on macOS, you can install with brew install --cask zed The docs don't make it very clear that the cask is available via homebrew. reply riiii 1 hour agoprevI don't know if it's just me but vscode feels like it isn't as fast as it used to be. The terminal also keeps getting messed up on Linux. Will definitely try one this out! Although the amount of plugins and community knowledge of vscode is immense. reply insane_dreamer 1 hour agoprevAwesome. Been looking for a next-gen Atom for coding. I use PyCharm most of the time, but sometimes its overkill with its eternal indexing ... :) So I often find myself bringing up SublimeText for working on individual files as opposed to a whole project. reply w-m 1 hour agoprevIs (Python) debugging on the roadmap somewhere for Zed, or will this remain out of scope? I have a fast editor in Sublime already, but I’d consider jumping ship from VS Code to Zed if I can set some breakpoints and look at local variables and whatnot (very basic IDE stuff). reply keb_ 1 hour agoprevDefinitely looks pretty rough so far (running Debian GNOME) -- font rendering looks wonky, and resizing the window is slow and unresponsive. But I'm very optimistic for what's to come! reply mikaylamaki 37 minutes agoparentCheck out our troubleshooting page, you might not be utilizing the GPU! https://zed.dev/docs/linux#troubleshooting If that doesn't work for you, please file an issue, and let us know whether you're using Wayland or X11 :) reply unshavedyak 1 hour agoprevI'll have to figure out how to get it on NixOS. Always the challenge with Nix lol. reply Zambyte 1 hour agoparenthttps://search.nixos.org/packages?channel=24.05&show=zed-edi... reply unshavedyak 1 hour agorootparentWait, added 2 months ago? This isn't new then, i take it? Interesting. Linux release announcement now i wonder? I expected this just was released today, so it definitely wouldn't be in Nixpkgs yet lol reply delichon 1 hour agorootparentFor the last few months it has been available on Linux to build from source. reply cassepipe 1 hour agoprevvim mode in the json settings: \"vim_mode\": true, reply Brechreiz 27 minutes agoprevIs this better than VS Code? reply hi_dang_ 1 hour agoprevZed Shaw started a company called Zed Industries? reply ebrescia 1 hour agoparentLOL no. The Zed founders are the guys who built Atom and Electron (and Treesitter): Nathan Sobo, Max Brunsfeld and Antonio Scandurra. reply assimpleaspossi 1 hour agoprevWOW! That's great!!! What is it? reply Zambyte 1 hour agoparenthttps://zed.dev/ reply natemcintosh 1 hour agoprevAnyone else get ~60-70% CPU usage when moving the mouse around? And no GPU usage. reply mikaylamaki 36 minutes agoparentWe have a few words on this in our troubleshooting guide: https://zed.dev/docs/linux#troubleshooting Let us know if that doesn't fix it! reply natemcintosh 1 minute agorootparentTried the advice, but wasn't able to change behavior. Added a [comment](https://github.com/zed-industries/zed/issues/13552#issuecomm...) to an existing issue reply simlevesque 59 minutes agoparentprevYeah I get something like that too reply llagerlof 1 hour agoprevHow to install/activate extensions? I saw that exists a directory called \"extensions\" in the repository. reply simlevesque 1 hour agoparentThere's an extension ui in the app. Ctrl + Shift + X or use the top right dropdown menu. reply rwdf 1 hour agoprevAnyone got this working in WSL? Using WSLg perhaps? reply rareitem 1 hour agoprevFYI, to launch Zed, run `'~/.local/bin/zed'` reply whalesalad 1 hour agoparentIf .local/bin is in your PATH you would be able to fire it up with just `zed` reply DarkCrusader2 1 hour agoprevDoes anyone know what is their monetization plan, or if they even have one? Editor with even this much polish takes a lot of time and effort. How is it being funded? Can we expect useful features to progressively get locked behind subscription as it grows in popularity (a la Gitlab)? Edit: Nevermind, found it - https://zed.dev/faq#how-will-you-make-money. Interesting charter. We envision Zed as a free-to-use editor, supplemented by subscription-based, optional network features, such as: Channels and calls Chat Channel notes We plan to allow offer our collaboration features to open source teams, free of charge. Edit 2: They have apparently also already raised money via private equity. I am quiet soured on \"free\" products which will almost always be enshittified as the pressure to turn profit grows. reply mikojan 1 hour agoparent> We envision Zed as a free-to-use editor, supplemented by subscription-based, optional network features, such as: > > Channels and calls > Chat > Channel notes > > We plan to allow offer our collaboration features to open source teams, free of charge. https://zed.dev/faq reply TiredOfLife 28 minutes agoprevOn Steam Deck it just exits, or rather it and the old node.js it bundles stays in memory. But no UI. reply WhereIsTheTruth 1 hour agoprevI gave it a fair try Cons: - spawning nodejs whenever you edit JSON files seems overkill, i'd prefer they use something native and more lightweight, or a way to completely disable it - text still looks a bit blurry on low DPI screens - doesn't support LSP properly, completion items are missing some data - Rust for plugins.. this is painful, compare it to Sublime Text's python API, it's night and day.. Pros: - Fast and responsive - UI is simple yet effective - drag&drop layouting, something i wish Sublime Text had.. - built-in terminal - built-in Debugger (not yet ready) Few more months of developments, and i'll certainly switch from Sublime Text, i'll be a little sad because i wrote plenty of plugins for it I however worry about their business model, i have 0 interests in their AI/collaboration stuff, i'll probably maintain a fork to get rid of all that crap, they should setup something as a back up plan, a small paid license, just for support, i'll be happy to buy one reply nilslice 32 minutes agoparent> - Rust for plugins.. this is painful, compare it to Sublime Text's python API, it's night and day.. Yes, this is unfortunate as they've unsuitably chosen the barely usable & unstable \"component model\" for their Wasm plugin layer. It's really only half-decent in Rust (to write the code & compile to CM non-standard version of wasm binary. it's also only truthfully usable to call components _from_ rust too.) I think they are banking on the eventual support for cross-language async - which likely could never come, or could take longer than the company stays solvent! reply insane_dreamer 1 hour agoprevAt first I thought this might be a creation of Zed Shaw (whose Learn Ruby the Hard Way, was the best introduction to that language, back in the day; and Mongrel was great). reply simonw 1 hour agoparentInstead it's a creation of the team who built Atom, Tree-sitter and Electron. Pretty solid resume! reply insane_dreamer 23 minutes agorootparentAbsolutely. reply romwell 1 hour agoparentprevI can vouch for \"Learn C The Hard Way\" as well :) reply dabber21 1 hour agoprevneat! just installed it in podman, so far so good reply jak2k 1 hour agoprevNow they just need a flatpak… reply mikaylamaki 34 minutes agoparentWe have a flatpak build! It's not on flathub yet though :) https://github.com/zed-industries/zed/blob/main/docs/src/dev... reply correct-horse 7 minutes agorootparentI really don't have much to say, just wanted to thank you for officially releasing a Linux build, and supporting us at all. We, the silent majority, very much appreciate your work. Every release of every application brings out the moaners, this is to be expected. Thanks. reply AndyKelley 1 hour agoprev> To install Zed on most Linux distributions, run the shell script below. This is not an acceptable way to install anything on Linux. If you want to target Linux users you can't distribute with a shell script for installation. I get that the idea is to reduce friction to installation and trying it out, but most Linux users - the ones you want filing bug reports anyway - are ones who will do due diligence and inspect the shell script to see what kind of opinions it makes about how to install the software. For example, I see that the shell script downloads a tarball and unpacks it to `~/.local`, then tries to mess with my PATH variable. Well, my local directory is `~/local`. So that's not where I want it. Actually, I would want it in `~/local/zed`, isolated from the rest of the installations in there. Then the PATH variable stuff just creates junk files since I don't use zsh. So I end up having to figure out the URL to the tarball and install it myself. My point is that if you just listed the download link to the tarball, it would actually be closer to your own goal of reducing installation friction. The shell script is so much more friction because I have to read bash code instead of just clicking a download link. reply NormenKD 1 hour agoparentThey aren't happy with this, either: \"[...]And of course, the journey isn't over yet－we'd love your help, particularly if you're excited about: - Helping bring Zed to your distro. Either by packaging Zed or by making Zed work the way it should in your environment (we know many people want to manage language servers by themselves).[...]\" Give them a hand ;) https://zed.dev/docs/development/linux#notes-for-packaging-z... reply AndyKelley 55 minutes agorootparentI sympathize with the situation that Zed developers are in. They are thinking of the user experience first and foremost, and when trying to distribute on Linux, faced with an overgrown, chaotic landscape that utterly fails to provide the basic needs of application developers, such as the ability to distribute a binary that has no dependencies on any one particular distribution and can open a window and interact with the graphics driver, or the ability to require permissions from the user to do certain things. I do think that my work contributes to help with this use case. Looking elsewhere on this thread I see that they are having problems fetching and running a nodejs binary successfully. Fortunately, nodejs is a piece of software that can be built and distributed statically. I have not packaged up this one in such a manner but I have done a proof of concept with CPython: https://github.com/allyourcodebase/cpython That said, if they want to allow users to install Zed through a system package manager, they will need to cooperate with the system and rely on system nodejs instead of trying to fetch it at runtime. Fetching and running software at runtime is fundamentally incompatible with the core mission of Linux distributions (curation, vetting, and compatibility patching of all software that is to be run on the system). reply logicprog 41 minutes agorootparent> I sympathize with the situation that Zed developers are in. They are thinking of the user experience first and foremost, and when trying to distribute on Linux, faced with an overgrown, chaotic landscape that utterly fails to provide the basic needs of application developers, such as the ability to distribute a binary that has no dependencies on any one particular distribution and can open a window and interact with the graphics driver, or the ability to require permissions from the user to do certain things. But Linux does provide a very simple and easy way to do this — Flatpaks. They're completely distro-independent, allow you to package up and distribute exactly the dependencies and environment your program needs to run with no distro maintainers fucking with it, allow you to request permission to talk to the graphics drivers and anything else you need, and you can build it and distribute it directly yourself without having to go through a million middlemen. It's pretty widely used and popular, and has made the silent majority of Linux users' lives much better, although there's a minority of grognards that complain endlessly about increased disk usage. reply doublepg23 23 minutes agorootparentThe best part of Linux’s single universal packaging system is there’s three of them. reply aidenn0 21 minutes agorootparentprevI have a shell script that will recursively copy and rewrite the rpaths of every shared-object that all elf files in a sub-directory reference to bundle it up. It obviously can't handle dlopen(), and ld-linux cannot be specified as a relative-path to the executable, but it works for many binaries. Of course that has the problem that vendoring always has; you have pinned every dependency, which is great for making the software work, but you miss out on security updates. reply the_duke 1 hour agoparentprev> This is not an acceptable way to install anything on Linux You might want to tell the rest of the software world how unnacceptable it is, because a huge amount of software, and especially dev tooling, is installed in this exact way. It's especially hard for young or fast moving projects, most distro packaging just isn't very compatible with this velocity. I'm personally on NixOS , which usually makes it easy to always get the latest and greatest, but eg would I really want to add a third party apt repository for Zed, which introduces complications and also can make changes to my whole system, rather than just having zed install itself in a local user-owned directory? I don't want to end up with 15 different third party apt repositories... adding those actually provides a higher amount of trust than shell scripts that only run with user permissions. And there are similar considerations for most other distros. Arch is probably the only other one, next to nix, where it's quite easy to stay up to date. (zed is already an official Arch package, btw, and before that it already was in aur, and of course it is in nixpkgs already) It's not ideal, but whenever some pattern propagates across the ecosystem, there are probably valid reasons why. reply correct-horse 16 minutes agorootparentAlmost 70% of the male population in my country smokes. Should I take up smoking because everybody else does it? reply Palomides 36 minutes agorootparentprev>I don't want to end up with 15 different third party apt repositories I would love to add 15 different third party apt repositories, I wish more projects used them, you're running whatever binary they give you anyway I guess this is just another example of how hard it is to please all linux users! reply janalsncm 1 hour agoparentprevI disagree. I’m on Linux for my main installation and I know I can inspect the bash script if I want to. It’s impossible to please everyone. Pipe to sh is simple, transparent, and easy to do. If reading through 200 lines of installation script is too much then reading through thousands of lines of Zed’s code base will certainly be too much. They also list other ways of installing https://zed.dev/docs/linux reply deadbunny 33 minutes agorootparent> Pipe to sh is simple, transparent Not so transparent[1]. Packages from a package repo are signed, usually with keys not stored on the same server so if someone nefarious breached a server they can easily replace a bash script, they can't re-sign and replace a package. Sure it's safe if you download the script then review it then install it, but hey, you reviewed it last time, it's probably unchanged, what's the harm of piping it directly to bash next time you need to get set https://web.archive.org/web/20240228190305/https://www.idont... reply logicprog 39 minutes agoparentprevMy question is why they didn't just make a Flatpak. Then they and their users wouldn't need to go through any of this hassle and distro fragmentation at all. Even if they didn't want to publish it on Flathub, Flatpak supports single file packages people can directly install as well. reply figomore 17 minutes agorootparentThere is already some support to flatpak, but it's not distributed on flathub yet. You have to build by yourself https://github.com/zed-industries/zed/blob/main/docs/src/dev... reply insane_dreamer 21 minutes agorootparentprevBecause then you have a dozen other people who say \"why didn't they just make a ___\" reply maxbrunsfeld 1 hour agoparentprevAs a point of clarification, the script does not edit your zshrc file, it just prints a suggested edit that you may want to make to that file in order to add zed to your PATH. reply pkage 1 hour agoparentprevThis is a fairly common way to install tools on Linux. Tailscale, Homebrew, Pi-hole and many others offer installations in this way. reply AndyKelley 1 hour agorootparentThe same criticisms apply to Tailscale, Homebrew, Pi-hole and all those others. reply usr942568903890 26 minutes agorootparent> The same criticisms apply to Tailscale No it doesn't. Tailscale's shell script is entirely optional and installs a distro/package manager specific package. It also doesn't mess with your PATH variable. They maintain packages for most popular distros as you can see here https://pkgs.tailscale.com/stable/. The sibling comments are just spreading misinformation because those people were too lazy to actually look anything up. reply nicce 51 minutes agorootparentprevWhile it is fairly common way, it does not mean that it is good way. reply lagniappe 1 hour agorootparentprevNot an argument. reply agilob 1 hour agoparentprev>This is not an acceptable way to install anything on Linux. If you think this is not acceptable, check out what they did last week: https://news.ycombinator.com/item?id=40902826 reply hypeatei 1 hour agoparentprev> you can't distribute with a shell script for installation Why not? It worked for me. reply drdaeman 1 hour agorootparentThere are two schools of thought. One strives for correctness, even if that requires extra effort. Another is \"anything goes as long as it somehow kind of works more than it doesn't.\" (Actually it's most probably a spectrum rather than a binary division, but I'm no philosopher or sociologist, so for example's sake I'll operate with this simplified model here.) The world en masse is generally preferring the latter (picking the easiest solutions, no matter how shitty they are - that's how we ended up with what we have today*), but among the engineers there are a significant number of people who believe that's how things should be. There are numerous issues with copying and pasting `curlbash` invocations from random webpages: all sorts of potential security issues, the installed software (if it works) could be installed in a way different from how your OS/distribution does things (or from your personal preferences), leading to all sorts of future issues, etc etc. Someone probably has a good write-up on this already. But - yeah - on the other hand, it works for number of people. ___ *) And, of course, the opinions if what we have today is \"good progress\" or \"unbearable crap\" also vary. reply correct-horse 23 minutes agorootparentnext [–]among the engineers there are a significant number of people who believe that's how things should be There are close to zero people who tend to think like that among actual engineers. That's why we have reliable transportation and bridges and skyscrapers that work for (soon to be) centuries. On the other hand, we have lots of them among self-professed \"engineers\" who have changed many monikers over the past couple of decades and will probably call themselves \"gods\" in a few more years down the line. reply RamRodification 1 hour agorootparentprev>There are two schools of thought. One strives for correctness, even if that requires extra effort. Another is \"anything goes as long as it somehow kind of works more than it doesn't.\" ... The world en masse is generally preferring the latter (picking the easiest solutions, no matter how shitty they are - that's how we ended up with what we have today), but among the engineers there are a significant number of people who believe that's how things should be.* I often have trouble articulating this at work. I will steal this and use something like it when advocating for correctness as opposed to shitty short sighted solutions. Thanks reply TiredOfLife 34 minutes agorootparentprevHere is .tar for correct way: https://zed.dev/api/releases/stable/latest/zed-linux-x86_64.... And here is even more correct one: https://zed.dev/docs/development/linux reply usr942568903890 21 minutes agoparentprev> My point is that if you just listed the download link to the tarball, it would actually be closer to your own goal of reducing installation friction. The shell script is so much more friction because I have to read bash code instead of just clicking a download link. It's there https://zed.dev/docs/linux#downloading-manually, it just doesn't show up as the default installation method. reply igorguerrero 1 hour agoparentprevIt's on NixOS and Arch I'm sure you just wait a little to get it on your Distro... I don't think they have bad intentions. reply nmstoker 31 minutes agorootparentI agree they probably don't have bad intentions. But other options still seen better than the one liner. Even just as a two liner leaves people a copy of what they ran if something goes awry. reply odo1242 1 hour agoparentprevSee https://zed.dev/docs/linux#other-ways-to-install-zed-on-linu... for distro packages. reply LocalGauge 1 hour agorootparentThis also includes the link to the tar files, so, you dont need to read the bash file to download tar file. The ones who are interested in this issue will spot this page, anyways. Maybe, they can make it more convenient for visitors to check this page. reply charles_f 1 hour agoparentprevHonestly, I still take that as an improvement over having to recompile it reply DEADMINCE 1 hour agoparentprev> Well, my local directory is `~/local`. So that's not where I want it. You can just move it after. .local is different from local so there is no clash. reply vanviegen 1 hour agoparentprevThis comes across as rather entitled. They offer an easy installation path that works for most people. They also went out of their way to provide alternative installation methods and instructions [1]. All while gifting you and the world free and open source software. [1] https://zed.dev/docs/linux reply AndyKelley 1 hour agorootparentMy interest is not in using this text editor as a consumer, but in guiding software development culture in general, particularly when it comes to installation of Linux applications. Some talks I have given on this topic: https://www.youtube.com/watch?v=pq1XqP4-qOo https://www.youtube.com/watch?v=CwXixVcliP0 So, I think \"entitled\" is the wrong insult. \"arrogant\" would be more accurate. reply jayde2767 1 hour agorootparent\"Opinionated\" is more appropriate. Ignorance often accompanies arrogance. Opinion, to me, at least contains a degree of knowledge. reply Arch-TK 45 minutes agoprevI really don't get why this is the modern editor style of choice. 20% (35 chars) of screen space permanently wasted on a always on file browser (meanwhile the animation showcases fuzzy finding) 4% (7 chars) of screen space permanently wasted by line numbers (why are the numbers cut off on the right?) 2.7% (5 chars) of screen space taken up by a gutter So 27% of screen space effectively dead 99% of the time. Why do people do this to themselves? I can't quite figure out how to get the gutter to truly only appear when needed (I can't remember why) but in my vim configuration 2 chars of space are taken up by the gutter and the rest is for the actual code. The current line number is in the bottom right, and if I need to go to a specific line number I have `G` for that. If I need a file explorer, there's the default Netrw one, there's NERD Tree, there's a terminal (I actually rarely need this anyway, but I can understand not everyone can cope, but I can't comprehend why you would need it on 100% of the time). Why does the \"modern text editor\" waste so much screen space? I have a 1200p laptop monitor which gives me 174 chars of horizontal space at a comfortable font size. If I split that in half I get two terminal windows worth of 87 characters each. If I keep my code under 85 characters per line, not only is it easier to read, I can keep a man page or another piece of code on the other half of my screen. reply dbalatero 1 minute agoparentI agree with you and probably have a similar setup to you. There's a % of people that like to think deeper about their tools, but I think most folks don't care enough or might be struggling with higher priority things at work. Plus, you don't know what you're missing. For me, good setup is like compound interest that just keeps paying off over time. reply Quot 18 minutes agoparentprev> 20% (35 chars) of screen space permanently wasted on a always on file browser That is toggleable. Cmd+B on Mac. I usually keep it closed, but it's just a shortcut away when I need it. > 4% (7 chars) of screen space permanently wasted by line numbers You can disable that in the settings with: \"gutter\": { \"line_numbers\": false } > 2.7% (5 chars) of screen space taken up by a gutter You can also disable the other items in the gutter to free up all of that space. > So 27% of screen space effectively dead 99% of the time. You can also press shift+esc at any time to toggle a fullscreen pane of whatever you are working on when you need more space without affecting your editor's state. I don't know the name of that action, I actually found that accidentally. Edit: I forgot to mention, you can actually disable the tab bar now too if you want even more space. You would just need to rely on the tab switcher feature or file search to move around. reply Arch-TK 6 minutes agorootparentI would damn hope you can configure/disable this. But why is it the default? And if the answer is \"discoverability\" then where is the default-on fuzzy find, default-on command palette, default-on context menu, etc? My point was not to claim Zed was bad because I had the ignorant misapprehension that it was incapable of being cleaner, my point was to ask why people desire such a cluttered workspace by default? Most people I see using these editors _don't_ disable all this clutter. reply aidenn0 9 minutes agoparentprevI haven't tried Zed and am unlikely to, but I get 238 characters of fantasque sans mono 11pt on my 1200p screen, so I could give up those spaces and still have two vertical panes (assuming Zed supports vertical panes and the file-browser isn't duplicated). reply brunoqc 24 minutes agoparentprevYou can close the left dock (ctrl+b for me). The gutter is still huge, though. reply whalesalad 1 hour agoprevReally dislike the one line installer. How is it installing? Flatpak? Adding an apt repo? Manual install? Fortunately docs go into better detail, https://zed.dev/docs/linux I'm on Debian anyway so who am I kidding expecting this to be in apt :D reply figomore 15 minutes agoparentThere is some support to flatpak already, see https://github.com/zed-industries/zed/blob/main/docs/src/dev... reply deciduously 1 hour agoparentprevPipe the script to cat before you pipe it to sh and take a look. It's downloading an executable to ~/.local/bin. If that's not your preference, there are many other options for obtaining the software, via your distribution or manually. I feel the backlash to this pattern is pretty overblown. They're not attempting to hide anything, just make the common case convenient. reply pkage 1 hour agorootparentA lot of the backlash is around the tool downloading and running an arbitrary shell script which could contain anything, and overlooks the fact that that shell script then downloads an opaque binary which could also contain anything. If you're paranoid about security read the code and build it from source, otherwise curlbash is trusting the authors just as much as any other method. reply Levitating 10 minutes agorootparentI think for most it's not a security issue but a system maintainence one. Where does the script install what? reply cogman10 1 hour agorootparentprevProbably the biggest problem with the `curlsh` approach is it bypasses package maintainers. I agree it's really no different than if you compiled malicious code yourself (or pulled in a 3rd party bin repository). However, one of the functions of a package maintainer is finding/being notified of security issues. I'm thinking of the recent xz attack. Imagine how bad that would have been if xz was commonly installed via `curlsh`. All this is to say `curlsh` is probably fine if the org is reputable, however, you should be having second thoughts if this is a repo ran with a bus factor of 1. reply whalesalad 1 hour agorootparentprevSure, but that convenience will come to bite you later. What happens when you want to update it? Their full install docs is like 5 lines of code so it is much preferred to do it that way. Every distribution is different. The ideal install here would be to add a unique apt repo for zed and then it becomes part of my normal update process. Updating a binary in a directory is not the end of the world... but I would prefer to know that upfront versus needing to hunt down where it was placed in order to do the updates. edit its 4 lines. seeing this is much preferred to parsing a bash script that is intended to support all distributions: wget https://zed.dev/api/releases/stable/latest/zed-linux-x86_64.tar.gz mkdir -p ~/.local tar -xvf zed-linux-x86_64.tar.gz -C ~/.local ln -sf ~/.local/bin/zed ~/.local/zed.app/bin/zed reply porphyra 1 hour agoparentprevYou can just read the script that you're curling rather than pipe it into sh directly. It seems like it just extracts the binary from a tar.gz and puts it into ~/.local. reply fao_ 1 hour agorootparent\"reading a script\" is actually a worse user experience on Linux than just using repositories or flatpak, though. It's pretty rude of software developers to put the onus on users to verify that they're not doing something outright malicious in terms of the installer. reply shepherdjerred 51 minutes agorootparentAre you not concerned with the software developers doing something outright malicious in the software itself? reply BanazirGalbasi 3 minutes agorootparentMost repositories have some sort of vetting process as far as I'm aware. In the case of Zed, because it's open-source, it can be examined more completely, although I don't think it's expected for every update to be heavily scrutinized. In the end, at some point you either have to inspect every line of code yourself or trust others to have done it for you. Package managers fall into the latter category. reply janalsncm 55 minutes agorootparentprevInstead of pasting it in terminal, I opened a new tab and read it. There’s maybe 200 lines, most of which aren’t relevant to my platform. Didn’t see anything unusual. I then proceeded to install tens of thousands of lines of code I didn’t read onto my machine. My point? People really seem to be bike shedding this install script bit. If I was a malicious actor I wouldn’t be hiding the bad parts in the install script. reply whalesalad 50 minutes agorootparent200 lines versus the actual install steps which is 1. wget the tarball, 2. extract the tarball to .local/bin, 3. done, or a few more steps to add the desktop file. reply jfvinueza 1 hour agorootparentprevso you feel offended by this reply bscphil 1 hour agoparentprevIt's already in the Arch Linux repositories, which is pretty cool: https://archlinux.org/packages/extra/x86_64/zed/ reply anotherhue 1 hour agorootparentAm I missing something? NixOS has had it since April https://github.com/NixOS/nixpkgs/commits/nixos-unstable/pkgs... reply bscphil 1 hour agorootparentYeah apparently there have been working builds since at least January, that's when the PKGBUILD was created: https://gitlab.archlinux.org/archlinux/packaging/packages/ze... It's been in the main repos since May. reply deepsun 1 hour agoparentprevYep, it's the same as running random code with root permissions. Same as running random .exe from emails, but even without M$ signature. Apt packages also have the root access, but official repositories at least have some paper trail and release process. reply whalesalad 1 hour agorootparentI am less concerned about it being malicious and more concerned about it doing something I do not want re: how the software is installed. Installing software from the distributions package manager is always preferred to doing something manual. When it comes time to update the app, I would prefer to not have to do that in a roundabout way. reply abhinavk 1 hour agorootparentprev> Yep, it's the same as running random code with root permissions. It doesn't require root. You can read it before you run. reply whalesalad 1 hour agorootparent\"reading before you run\" eliminates all convenience of the one liner. Their linux docs are way better because it shows you exactly how to do it on a per-distribution basis. when it comes time to update the software I would prefer to know how exactly it is installed so that I can update it correctly. reply rad_gruchalski 27 minutes agorootparent> when it comes time to update the software I would prefer to know how exactly it is installed so that I can update it correctly Then read the script you complain about. reply whalesalad 25 minutes agorootparentThree months from now I won't remember using the script to install it. And the contents of the script could completely change. This is not a helpful take. reply fragmede 0 minutes agorootparentI find saving files to disk and organizing them is a great way to help me remember things because then they're saved to disk even if I forget them. rad_gruchalski 10 minutes agorootparentprevThis is not a helpful take for you. The same method works fine for me over the last decade. Taking notes helps, having some helper scripts helps. If one’s invested in a technology, one finds a way to remember. reply igorguerrero 1 hour agoparentprevI hope it gets packaged, on NixOS there's a package already on stable and unstable. reply abhinavk 1 hour agoparentprevIt's a basic download and extract script. Also creates directories as per XDG spec. reply zoogeny 18 minutes agoprevI'm a sucker for text editors. I've used so many at this point. Notepad++ from way back. Anyone remember Komodo, the Perl focused text editor from ActiveState? BBEdit. TextMate. Sublime text. Atom. Visual Studio Code. All kinds of IDEs from Eclipse to the IntelliJ family and the full fledged Visual Studio. I've used many flavors of vim and learned emacs multiple times. I doubt I've named half of the editors I've used. I'm at the point where I just can't motivate myself to try yet another. In my experience, they all have their strengths and weaknesses. My rule of thumb now: use whatever the majority of people on my team use. For non-team related work I find the community around Visual Studio Code to be good enough that it does what I need most of the time. I use bog-standard vim when I ssh into boxes. reply 1oooqooq 12 minutes agoparentkomodo the editor (i recall it as a semi-commercial alternative to eclipse, much like intellij, but based on mozilla UX code?) was funny, because exactly the time it got traction and people started to talk about it, the tech news were inundated with Comodo the TLS operator caught doing shaddy stuff (and if i recall, blaming some hackers) didn't hear much about komodo till now reply llmblockchain 15 minutes agoprev [–] Seems like a good VSCode alternative, but I'll stick with my editor of choice. I imagine it will be 1~2 years before Zed is bought by Microsoft and either squashed like Atom or replaces VSCode. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Zed, a software product, is now available for installation on Linux systems.",
      "Users can install Zed by running a provided shell script via the command: `curl https://zed.dev/install.sh`.",
      "This release is significant as it expands Zed's availability to Linux users, potentially increasing its user base and community engagement."
    ],
    "commentSummary": [
      "Zed, a new text editor for Linux, has initiated comparisons with popular editors like VSCode, Neovim, and Sublime Text.",
      "Users praise Zed for its speed, native app feel, collaborative features, and UI design but note issues with Typescript integration and version control.",
      "Concerns about Zed's installation method and potential future monetization have been raised, leading to a divided community, with many users monitoring its development while continuing to use their current tools."
    ],
    "points": 214,
    "commentCount": 176,
    "retryCount": 0,
    "time": 1720630562
  },
  {
    "id": 40920122,
    "title": "How CD pregaps gained their hidden track superpowers",
    "originLink": "https://tedium.co/2024/07/06/compact-disc-pregap-history/",
    "originBody": "Mind The Pregap Pondering the compatibility issues and complications of a clever element of the audio CD hidden track boom: The before-album pregap. By Ernie Smith Jul 06, 2024 Filed under: cd, cd-i, cd-rom, compact disc, compact discs, enhanced cds, hidden tracks, pregap, red book",
    "commentLink": "https://news.ycombinator.com/item?id=40920122",
    "commentBody": "How CD pregaps gained their hidden track superpowers (tedium.co)189 points by shortformblog 23 hours agohidepastfavorite116 comments ssl-3 18 hours agoOne less-secretive way I've seen pregaps used is for live recordings. The crowd noise betwixt songs can be contained in a pregap, so that it is only ever heard when listening to the album straight-through (instead of in shuffle or track-program mode). --- Another fun feature of audio CDs is indexes. A disc can have 99 tracks, and each track can have some pregap (including track 1, as the article discusses). And each of these 99 tracks can be further subdivided with 99 index markers. This gives a CD the theoretical ability to have 9,801 selectable audio segments. Although realistically, I've only owned a couple of CD players that even displayed index numbers and exactly one CD player (a Carver TL-3300) that allowed a person to seek to a given index number within a track. (And I've only known one CD to actually make use of indexes in any useful manner, which was a sound effects CD from the early 1980s that had a lot more than 99 sounds on it -- all organized by tracks, and sub-organized by index marks. I just can't think of the name right now.) reply kevin_thibedeau 17 hours agoparentMy personal CD ripping script is configured to leave all pregaps after track one at the end of the preceding track when splitting them out as individual files. It gets ripped in one DAO pass for guaranteed preservation of all samples when using gapless playback on live recordings. Track navigation then works just like a real CD without having to listen to an incongruous section of audio meant to link the previous track on sequential play or, even worse, missing it altogether. I have a classical CD from the 80's with index marks for different movements within within the individual compositions represented by a handful of tracks. My understanding is that DG was the only publisher routinely using them. That required some manual intervention to convert the indices to separate tracks. Sony was pretty good about providing index nav. on their full size stereo players. At least until their perpetually cruddy remotes eventually failed. reply ssl-3 17 hours agorootparentThat's probably the best way to do it, given common toolsets and players. I also rip pregaps as lead-outs (rather than the lead-ins that the structure may appear to suggest). It's things like this that make me wish that we'd landed on on a good, popular way to store albums (with metadata!) instead of individual tracks -- or to at least reassemble individual tracks' files properly into whole albums without glitches and weirdness. (FLAC/cue can do some of this, but hardware player support is nearly nonexistant.) I've been told that this is a stupid thing to want, and I want it anyway. I'm old enough to remember listening to albums the whole way through by default since anything else would take extra steps, and perhaps fortunate-enough to have generally preferred listening to albums where that is a thing that is also worth doing intentionally. (And yet, I am young enough to still be bitter about Lars killing Napster. My dissatisfaction is multifaceted.) reply kevin_thibedeau 16 hours agorootparentIn addition to lossy compressed track files I also generate a FLAC with embedded cue as a master copy of the original. It's useful for recreating the whole recording for mass editing. I have a few discs mastered with preemphasis that needed correction. I too hope there will be a day when all FLAC players support track navigation. The reality is the music album has had its day in the sun and will largely be a forgotten curiosity like the typewriter or rotary phone. reply ssl-3 14 hours agorootparentYou're not wrong. New music isn't frequently recorded with the intent for it to be heard in an album-oriented way. But the albums I like to listen to as albums will remain cohesive albums for an eternity. Lots of stuff from Roger Waters is cohesive in that way, which is perhaps something a person might expect me to say. But also lots of stuff from Maynard James Keenan, Trent Reznor, and even Marilyn Manson is also this way, which is perhaps less expected. (And sure, I can rip an album as an album and convert that to a singular MP3 that I can play as an album almost anywhere, and it needs to be a single file since MP3s can't be perfectly concatenated. But then, I can't easily skip around on that singular album when it behooves me to do so. I could do both things when it was still in CD format.) reply caf 12 hours agorootparentBilly Eilish's latest is intended to be listened as a complete album (but of course the fact that this is known as an exception proves the general rule...) reply ssl-3 11 hours agorootparentThat.... that makes sense. Her recordings are excellent. They generally sound simply fantastic. When turned up on the big stereo, they tickle every auditory input I have -- including the usually-strictly-tactile ones. I've heard that her brother, who is probably (and perhaps obviously) her biggest fan, generally has a huge part in producing and mixing her music. It is apparent that they work well together. Anyhow, thanks. That album is on the list for the next time the neighbors have left for the weekend. reply mikepurvis 5 hours agorootparentprevThis is an issue for movie discs too. Some mkv rips will preserve chapter data (though player support is spotty), but in the end it's still a big linear file— menus, intros, trailers, optional features, etc are all gone once it's ripped unless you rip that stuff to separate video files. Which I get on the one hand, but it's a bummer that in all these cases (CD, DVD, Blu-Ray) the metadata for the larger structure of the production got inextricably tied to the specific physical media implementing it, such that the only real way to preserve that data was to rip a full disc copy. reply qingcharles 14 hours agorootparentprevI'd love a new solution that wasn't \"break the CD data into pieces.\" I've never looked inside a CUE file, but it's just text and I don't think it supports meta data, right? We need like a new CUE file to go with the FLAC, right? p.s. https://news.ycombinator.com/item?id=40923646 reply ssl-3 14 hours agorootparentIdeally, I think I'd want a singular container (of whatever sort) that has the album's audio, the music-related timing metadata (as applicable), and whatever other metadata may be appropriate (lyrics? liner note graphics? music videos? sure!). The audio should be able to be FLAC. But it should also be able to be anything else, like Vorbis or MP3 or AAC or IDK. It needs to be able to be played continuously without aberration (which can't actually be done with a group of MP3 streams). The audio needs to be able to be seekable, like a CD is also seekable. By track. By index. (With pregaps, where appropriate -- because CDs also have pregaps.) Other potential metadata must be able to include whatever subcodes are involved in things like CD+G[0] and HDCD and CD Text, since all of those are supersets of the regular datastream and playback is compatible with any CD player. And it needs to be a singular container file because...well, that's just easier to keep track of as the years go by and data migrates. Only then, will we have the beginning of a valid archive format for audio CDs as they actually still exist on [some] store shelves today. (Some stuff can be optional, just as lots of things are optional inside of an MKV container for a film.) [0]: Almost nobody ever used this outside of the 1990s karaoke world, but Information Society's self-titled album includes an illustrated sequence, with lyrics, that is completely implemented in CD+G and that runs for the entire length of the album. And I should be able to render that locally here in 2024 from a container on my pocket supercomputer instead of watching a bad rip from a Sega Genesis: https://www.youtube.com/watch?v=b89sSa8QlLg reply piperswe 7 hours agorootparentYou mentioned MKV - Matroska (MKA for audio, MKV for video) could honestly work quite well for this situation with just a little extra standardization. Audio codecs: use a single stream of whatever codec you'd like. FLAC/Vorbis/MP3/AAC/Opus/etc. can all go into Matroska. Seekable: Use chapters for tracks, and nested chapters for indices. Matroska documentation even gives an example of using ChapterPhysicalEquiv 20 for CD tracks and ChapterPhysicalEquiv 10 for CD indices. Other metadata can be muxed into the stream as well. Lyrics can be included as text in metadata (lyric tag) or as a subtitle stream. Liner note graphics (and basically anything else) can be included as embedded files. Music videos can be video streams in the Matroska file. reply xyzzy_plugh 6 hours agorootparentI'm glad to see this mentioned. This was first thought I had as I progressed through this thread. I'm surprised this isn't a popular, supported standard already. reply ssl-3 6 hours agorootparentprevNested chapters can work for index markers, especially if a player supports them right. I mean: As mentioned, these have almost never been usable with real CD players in the wild. Maybe not much is lost there. (But the format must still accept these things, and allow them to be usable! An archival format must respect all aspects of the item being archived, including those that are unpopular or disused. I am willing to die on this hill.) What of things like CD+G? Here in 2024, they're very simple graphics using 35+-year-old tech, and they should be archived neatly, precisely, and without interpretation, to be rendered client-side at a later point. I think I've mentioned it, but we literally have pocket supercomputers in common use today. If we can make the complexities of MAME work for the past couple of decades, and do it with direct ROM dumps, we can do this for CD+G. But the CD+G must be rendered synchronously with CD audio data on playback. This applies whether it is my Goldilocks example of an Information Society album, or whether it is a CD+G karaoke disk with Garbage's I'm only happy when it rains (and twelve other crowd pleasers from that month of 1995). How will that work with MKA? And how will pregaps work? (Maybe MKA isn't an ideal container if it does not already include avenues that lead to this kind of functionality in ways that are compatible with the original article.) reply sumtechguy 5 hours agorootparentprevYou are almost describing the MAME CHD format. As they have the problem that the object (hard drive, cd, dvd, etc) must be in one file. Have the ability to do differences (writable in some cases). But also compressed (compressed hunks of data). They also need that sub track data too as some systems do interesting things with that sub data. As some even hide their encryption format in the SBI fields. The CHD format is more like a container that acts like whatever media it was. Depending on what system they hook it up to. The downside is there is no concept of 'metadata' to find different things in CHD. It is up to the system it is hooked up to to interpret what that data stream is. reply Uvix 6 hours agorootparentprevCan’t an MP4 container do most or all of that already? (Pregaps would probably need to become a full-fledged chapter in their own right, with the current spec.) reply kevin_thibedeau 14 hours agorootparentprevCue is a bodge that should never have become a defacto standard. Joerg Schilling's cdrdao tool has its own TOC format that faithfully captures everything including index marks, various flags, and multilingual CD text but it was ignored by everything else in the heyday of the ripping era. Nowadays we'd be better off with a standard yaml/json format that duplicates what cdrdao provides. reply albrewer 5 hours agorootparentprevI had a set of cds that went with an intro to music theory textbook around ~2009. It did also made heavy use of indices in tracks to do exactly the same thing. My car stereo listed each index as a track. I wish I could remember the name of the textbook because I really liked a lot of the baroque music on the CDs and can't remember who they were by or the titles of the songs... reply benjaminpv 4 hours agorootparentDo you remember if the textbook was orange (possibly with a two-tone cover design)? I had a really good textbook in college that had a... 4? CD set (with the big jewel case) that had a bunch of tracks and like you I really enjoyed it. reply albrewer 3 minutes agorootparentIt was a reddish (could be orange, could have been maroon) color lightly mottled in black with a picture of a violin (or cello, idk) set in the lower 2/3 of the cover. I'm somewhat certain it had 6 cds because it filled my disc changer in my stereo, although that detail is fuzzy too. reply op00to 16 hours agorootparentprev> At least until their perpetually cruddy remotes eventually failed. For me, Sony remotes were made of the same stuff as early Nokia phones - indestructible! Surprised to hear someone thought they were cruddy. reply kevin_thibedeau 16 hours agorootparentThey were physically robust but the carbon button contacts always became dodgy for me. I tried to avoid Sony products for this reason because I encountered it so often in other people's gear. I have a remote from the late 00's that saw virtually zero use and it conked out with age alone. reply alliao 15 hours agorootparentJapanese called it Sony Timer...some call it urban legend but this seems like yet another independently verified data point reply layer8 7 hours agorootparentprevThere is/was carbon spray that you could use to refresh the contacts. reply AkBKukU 5 hours agoparentprevI'm curious if you have a specific example of an album with the crowd noise between tracks like that? I collect and rip hundreds of CDs and am always on the look out for edge case discs to further hone my tools. On your pregap + 99 indexes remark, the \"pregap\" is the space between index 00 and 01 which continues on up to index 99. Players seek to index 01 as the start point of the track. There is no separate pregap designation. I've paid special attention to this because it is a difficult problem to solve as many discs have space between tracks stored in index 00-01 but rarely is there anything audible in there after the first track. The only example I have of this is a specialty music sample disc, Rarefaction's A Poke In The Ear With A Sharp Stick, that has over 500 samples on the disc accessed by track + index positions. As a sidebar based on the later comments in the thread, I've made it a habit to rip and store every audio CD as BIN/CUE+TOC using cdrdao. This allows me to go back and re-process discs I may have missed something on. But that is imprecise even because it usually breaks bluebook discs with multiple sessions to store data due to absolute LBA addressing. Also the ways different CD/DVD drives handle reading data between index 00-01 on track 1 is maddening. Some will read it, some will error, and the worst is those that output fake blank data. reply meindnoch 4 hours agorootparent>I'm curious if you have a specific example of an album with the crowd noise between tracks like that? I collect and rip hundreds of CDs and am always on the look out for edge case discs to further hone my tools. E.g. the Japanese version of Flying Lotus' album \"Until The Quiet Comes\" has a pregap of 5 seconds before the 19th track, to separate it from the rest of the album, as it's a Japanese-exclusive bonus track. reply pseudosavant 14 hours agoparentprevI mastered a CD in 2000 for a band that wanted a secret track at the end. I came up with a novel way to do it. There were a dozen regular tracks. A bunch of empty ones. And the final track over about a dozen tracks of varying length with no gap. Used all 99 tracks. I could only pull it off with this CD burning software that didn’t have a UI. It took a text file as input at the command line. But it could do everything from almost every color of spec (Red Book, Blue Book, etc) for CDs. reply chaboud 13 hours agorootparentThe Nine Inch Nails “Broken” EP had a couple of tracks at the end of 99, though the middle tracks were all 1-second blanks. reply ssl-3 13 hours agorootparentprevI've had visions of putting a CD together that was that way, but with pregaps and indexes utilized as well. \"WTF? The time counter keeps going forward, and then sometimes it goes backwards! And using the track seek buttons completely eliminates some parts that I can hear if I don't touch anything! It's a whole different song entirely when you program tracks 39, 40, and 52 in a loop, and IDFK what it is with this Index number that only always showed \"1\" before. Oh wait. Srsly? From tracks 71-93, it's using the index to count beats...and the track number to count measures? No, that can't be it. Except....\" reply pseudosavant 54 minutes agorootparentI thought I'd really (ab)used the CD specs, but don't recall ever trying indexes. Curious how most CD players, which only had a two-digit track indicator, handled indexes. I would have used that if I had known about it. reply cainxinth 17 hours agoparentprev> Broken was re-released as one CD in October 1992, having the bonus songs heard on tracks 98 and 99 respectively, without any visual notice except for the credits, and tracks 7–97 each containing one second of silence. https://en.wikipedia.org/wiki/Broken_(Nine_Inch_Nails_EP)#Pa... Amarok (1990) by Mike Oldfield is a single hourlong track with 53 index marks. https://en.wikipedia.org/wiki/Amarok_(Mike_Oldfield_album)#T... reply egypturnash 15 hours agorootparentBroken was absolutely perfect to put into a multi-disc player along with TMBG's Apollo 18, which contains \"Fingertips\", a suite of 21 very short songs. Set it to shuffle songs from everything in the player, and enjoy your sonic whiplash reply ssl-3 8 hours agorootparentWas this better with the crazily fast-loading chonka-chonk slam-slam nature of a Pioneer 6-disc cartridge changer, or with something slower and perhaps more-civilized like a period-correct Technics 5-disc changer, with its nearly-silent and relatively exquisite, seemingly-careful demeanor? (Both have their merits, but I unfortunately have neither at hand. And I only have one of these 2 albums. And one of those albums is the original Broken, which only has 6+2 tracks across two discs instead of 99 tracks on one disc. And how do the 91 silent tracks on a more-common release of Broken affect things compared to the 26 musical tracks that the original 6+2+18 track-count ensemble may entail, in terms of inter-song delay or any other such thing on a real multi-disc changer? I know TMBG fairly well, and NIN very well, and I enjoy the fuck out of gear, but I have so many questions.) (I vaguely jest above, but Spotify only shows me 18 tracks on Apollo 18. And only one of them is Fingertips. Am I looking at this wrong?) reply egypturnash 3 hours agorootparentPresumably Spotify has glommed all the Fingertips into one file. On the original CD release it was twenty-one separate tracks; there was a bit in the liner notes that explicitly encouraged you to put it on shuffle. https://tmbw.net/wiki/Fingertips I could not tell you what brand the all-in-one turntable/radio/tape deck/cd player I had at the time was. There was a big tray with room for five CDs and I have absolutely no memory of how much noise it made when switching from one disc to another, and every physical object involved in this affair is long gone in a hurricane. I suspect both CDs should be easy to find used copies of, if you have the appropriate hardware and want to experience the tension of not knowing if the next song you hear is going to be Trent bitching, a brief moment of silence, a Fingertip, or whatever else you put in the player. Given my tastes at the time this would have probably been Skinny Puppy, Ozric Tentacles, and Björk, but do whatever feels like the most interesting possible choice; I have a disc lying around now that’s nothing but forty iterations of Satie’s Vexations and that would have certainly been a prime choice for this little game. reply eyelidlessness 13 hours agorootparentprevIf you want sonic whiplash without so much effort, you can also listen to a Fantomas album in its original order. reply tecleandor 10 hours agorootparentThis could be fun :) https://en.wikipedia.org/wiki/Short_Music_for_Short_People reply davidgay 1 hour agoparentprevI have an early CD (Bach's Goldberg variations, played by Glenn Gould) which is one track with 31 index markers. My (early) Philips CD player dealt with it fine, but since then it's been a bit of a problem... reply LeoPanthera 13 hours agoprevSemi-related: \"Minidisc\" is an album by Gescom (who are really Autechre in disguise) released, as the name suggests, only on Minidisc, containing 88 tracks which are designed to be played on shuffle, because Minidisc, unlike CD or any other physical format, can be shuffled with no audible gap between tracks. Each track is designed to segue into any other so the album is different every time you play it. reply afavour 18 hours agoprevOne memorable album using this was Queens of the Stone Age’s Songs for the Deaf. If you rewound from the start of the first track you got 90 seconds of strange sounding (but tuneful) rumbles and bleeps and bloops. When I looked it up online I found out it was called “The Real Song for the Deaf”. It was literally a song for deaf people, the idea was that if they turned it up enough they’d be able to hear the vibrations forming a song. For those interested to listen via a more accessible method: https://www.youtube.com/watch?v=XEU01LrnWng reply leonard-slass 6 hours agoparentI have the hardware and the CD. I did not know you could rewind to negative seconds of the first track. Thank you, you have made my day! reply qingcharles 14 hours agoprevI was responsible for some of the first digital content ingestion for the world's record labels back in the late 90s, which was all based around trucks filled with retail CDs being fed into CD-ROM drives and an army of young folks grinding hundreds of track names into a database. (what happens when a truck full of East Asian CDs turns up? what about all those albums by Aphex Twin and Sigur Ros with untypeable names? https://www.treblezine.com/wp-content/uploads/2014/08/aphex-... ) I love these hidden tracks to death, especially the two hidden pregap tracks on Ash's first album, but they caused me unending pain and suffering. Not only are they an absolute nightmare to rip, often with more than one song per track (so the WAVs have to be edited), the names of the songs are often totally unknown, even to the record labels. What do you even number the things in the metadata? Added to that, you nearly always didn't even know they were there, so the negative numbered tracks would fail to get ripped and all the other ones in between or at the end would get ripped in weird ways and confuse all the data folk. https://www.discogs.com/release/984235-Ash-1977 \"Help, computer.\" reply MOARDONGZPLZ 20 hours agoprevI read this whole thing twice and I now know what pregaps are and the history but still have no idea why people would put them on a CD or why they’re useful for hidden tracks. reply mikepavone 17 hours agoparentAn audio CD is mostly arranged like a single continuous recording. Tracks are added on top of this via the Q subcode channel that gives information about the current location and the ToC stored in the lead-in area (also using the Q subcode channel). In the ToC, each track will have one more indexes that points at a specific location on the disc by minute, second and \"frame\" (represents 1/75 of a second, basically a sector). If a CD is properly following the Red Book standard, index 0 will point to a 2 second pre-gap of silentce and index 1 will point to the actual start of audio of the track (additional indices are allowed, but not common). The purpose of the pregap is to make life easier for less sophisticated players that aren't able to seek to a precise frame on the disc. They just have to be able to hit a 150 frame region. However, just because the standard says the pregap is supposed to be 2 seconds and silent doesn't mean it actually has to be. Players generally don't care and by the time the format was popular, even inexpensive players could seek precisely. This allows you to stick audio data before a track that will be skipped by the player when it's trying to seek to that track. If you stick it before track 01, it will be skipped even when just playing the disc through unless you rewind. reply kevin_thibedeau 16 hours agorootparentThe key for a hidden track at the beginning is that players usually start playing track 1 from index mark 1 (1.1) rather than index 0 as with continuous play through all subsequent tracks. The lead-in area for 1.0 is a holdover from grooved phonorecordings never meant to be played. It's a way for the primitive hardware of early CD players to acquire the start of the data stream in a safe area that doesn't have to be faithfully reproduced. Some players permitted you to skip back from 1.1 to 1.0 to hear the lead-in as a hidden pseudo-track. Typically this was only possible with hardware index nav. buttons rather than the track nav. buttons, further obfuscating the presence of the hidden track. The other means of \"hiding\" tracks is to have a bunch of short silent tracks until you get to track 99 (inconvenient to reach on a player without numeric track entry) or to have a long section of silence starting on the last track from index 1. reply crtasm 15 hours agorootparent>Typically this was only possible with hardware index nav Holding the previous track button would \"rewind\" playback and get you into the pregap on all the CD players I remember using, but these would have been late 80s models onwards. reply barrkel 9 hours agoparentprevThe writing is not good; I gave up part way through. It's weirdly elliptic and almost autistic in its focus on details and an almost complete absence of a big picture. It could do with some kind of proper context-setting introduction, at the very least. reply nayuki 2 hours agorootparentA CD audio frame is defined as exactly 1/75th of a second (588 samples per channel). I don't know why the article waffles around with these poor wordings (emphasis mine): > These albums all had a pregap of either 32 or 33 “frames,” with a frame representing a length of about 1/75th of a second, per Hydrogen Audio’s Wiki. > To offer a small correction to the original question now that we know we’re talking about 74 frames per second rather than 60 or 100 It's needlessly confusing and undermines my confidence of the entire article. reply WarOnPrivacy 5 hours agorootparentprevThis mirrors my experience. It's good content but I'd barely land on one splainer before being segueded into the next one. I kept thinking I missed the part they delved into hidden tracks. reply monocasa 20 hours agoparentprevBasically cd audio tracks have a base sector and a start specified. That allows sectors representing audio before timestamp 0:00 to be represented the track. The reason for this originally was probably to allow the drive to get synchronized before the track started. Enterprising cd masterers put actual hidden audio data in that area which would allow you on some CD players to rewind past 0:00 and then play the hidden audio at the negative timestamp. reply crazygringo 19 hours agorootparentHow much hidden audio could be stored? Was it limited to something negligible like a couple of seconds? Or could you store a whole five-minute recording in there or something? reply boomboomsubban 19 hours agorootparentThere doesn't seem to be a limit, this https://en.wikipedia.org/wiki/List_of_albums_with_tracks_hid... mentions a 27 minute live recording. reply jvan 19 hours agorootparentIncredible! Songs in the Key of X was the only album I ever knew to do this, and it wasn't even the first. I had no idea so many others did the same thing. Edit: Son of a *, I've had a copy of Sister Machine Gun's Burn for almost 30 years and never knew there was a hidden track! reply ChrisArchitect 18 hours agorootparentClassic X-Files album is the one I think of too. And how they hinted to everyone that there even was a hidden track on the sleeve: \"'0' is also a number\". (and the technical fineprint about the disc possibly not being Redbook compliant) reply croes 1 hour agorootparentprevI guess the limit is some milliseconds short of 74 minutes. reply dylan604 20 hours agoparentprevOh good, so I'm not the only one that thought the article failed to actually state what the superpower was. Some lame ass patent was granted? reply add-sub-mul-div 20 hours agoparentprevAs the article says its like an easter egg, putting a hidden song before the first track of a CD. If the song wasn't in the pregap it wouldn't be hidden. It's just for fun. (Sometimes songs can also be hidden in tracks at the end of the CD like 99, but that feels less mysterious.) reply mattl 20 hours agorootparentSometimes CDs would have a long piece of silence at the end of the last song and then another song on the same track. Other CDs really experimented with the shuffle feature. They Might Be Giants’ Apollo 18 had a bunch of very short tracks that would usually play between songs when shuffle was used. reply gwbas1c 14 hours agorootparentI remember getting surprised by one of those. I was at a friend's house and forgot to turn off the CD at the end. It was funny at first, but when every other CD I bought had one, it became tacky. reply add-sub-mul-div 20 hours agorootparentprevI had that CD and remember the short tracks but never thought of playing it on shuffle that way. I think it was nine inch nails' Broken EP that had the hidden tracks on 98/99 rather than after a long silence, but I could be wrong. reply ssl-3 18 hours agorootparentBroken was first released as a 2-disc set. It was still in a many-fold Digipak case, but also included was a 3\" mini-CD that had Suck and Physical (You're So). The regular-sized CD looked about identical to the 99-track version, but had only 6 tracks. (It was expensive to do this, and was never intended for long-term production. Later versions were generally as you describe.) reply mattl 19 hours agorootparentprevI think it tells you in the liner notes that you should use the shuffle button. My copy in the UK at the time didn’t have the individual tracks. Just one track. reply dec0dedab0de 19 hours agoprevI remember my friend accidentally found the negative track on a CD and called me up out of breath like aliens just landed. I think it was one of the early AFI albums.We spent the whole weekend checking for negative tracks on every CD we could find. The negatives between songs were also pretty cool sometimes, Mediocre Generica by Leftover Crack makes very good use of them. Listening to it over streaming or even mp3s ruins the effect, unless someone captured the entire album as one file. reply Lammy 18 hours agoparent> I think it was one of the early AFI albums I wouldn't call it an “early” album but I found one of these (untitled 18-second intro) on AFI - DECEMBERUNDERGROUND: https://i.imgur.com/XAsFMSR.png Some others I've run across in my CD collection include… — on Jonathan Katz - Caffeinated https://i.imgur.com/4ghQadv.jpeg — the track \"Every Time Is The Last Time\" on Bloc Party's Silent Alarm https://i.imgur.com/knhbZhA.png — a kid606 remix hidden in the first track pregap of The Locust's eponymous https://i.imgur.com/sXVFrQI.jpeg — the \"Theme of Coon\" (aka Riki) on the third disc of the SaGa Frontier soundtrack https://i.imgur.com/CqTTqpV.png > The negatives between songs were also pretty cool sometimes And one of these, the interlude at the end of “High Roller” on TCM's Vegas which is part of the pregap for “Comin' Back” https://i.imgur.com/G5PSCy3.jpeg reply nammi 18 hours agoparentprevAFI almost always had a \"hidden\" track after silence following the last track, I figured following the Misfits' tradition reply xxr 17 hours agorootparent“Midnight Sun” at the end of Black Sails always gets me reply WarOnPrivacy 5 hours agoparentprev> Mediocre Generica by Leftover Crack Those names are a rabbit hole event horizon. Album released 9/11, working title of Shoot The Kids At School was rej by label. Follow up was F WTC. Band lives in C-Squat... reply guerrilla 5 hours agoparentprevThis makes me wonder how I ever found the hidden tracks on the X-Files soundtrack. Must have been an accident. https://www.youtube.com/watch?v=nYyA1Mc3KZM reply tombert 26 minutes agoprevIIRC Blink 182 had a hidden track \"Fuck a Dog\" on their album Take Off Your Pants and Jacket. reply zdw 19 hours agoprevI've been using https://github.com/whipper-team/whipper to digitize CD's, and it supports identifying Hidden Track One Audio (HTOA) when it exists and is not blank. Add in MusicBrainz Picard and Navidrome and you have a really nice solution. reply chuckufarley 50 minutes agoparentWhipper user here also. If you've not yet encountered it, as it's not as prevalent in repos as Whipper, Cyanrip is always very much worth a look and has come on in leaps and bounds, with recent updates adding (non compliant) .cue sheet support. reply Jedd 18 hours agoprevThis specification anomaly sounds like the polycarbonate equivalent of vinyl's multiple-groove capability. [0] I'd first heard of this for a Monty Python record (wikipedia notes this is in fact the most famous use case) but checked to see if people went for >2 grooves, and seemingly they did. I expect the casting for the pressing was horrendously expensive, which is why it didn't happen an awful lot. I suppose both mediums shared the less-well-hidden feature where a long silence separated the penultimate from the ultimate track. [0] https://en.wikipedia.org/wiki/Multisided_record reply caf 12 hours agoparentWhen I was very young, my parents had a game called 'wacky races' that was based on a multi-groove vinyl. It was a horse-racing game - I can't recall exactly how the gameplay worked, but the vinyl contained racing calls where the races would start the same way but the outcome would be somewhat random depending on which groove the needle ended up following. reply TonyTrapp 11 hours agorootparentTechmoan has a video on a similar horse racing game (maybe it's even the same just with a different name) and how it works: https://www.youtube.com/watch?v=I5l75romOXY reply alanfalcon 14 hours agoparentprevThis is supremely cool, thanks for sharing. I'm probably missing something obvious but why would the casting be any more expensive than any other pressing? reply Jedd 8 hours agorootparentNot terribly informed about the pressing process, but as I understand it, it is (or was) effectively a player-process in reverse. A needle creates the groove(s), replete with bumps for sound, in a not-quite-set (slightly soft) master disc - and I _speculate_ those follow a specific path defined by the mastering tool. In comparison, playback just drops the needle in the track, and it necessarily follows the extant spiral form. Making the master of a multi-groove record I'm assuming would require recalibration of the groove-defining mechanism (doubtless carefully designed for conventional layout), once for each of the grooves you want to make, ensuring they each stay within the boundaries defined by the previous grooves. reply omar_alt 20 hours agoprevI recall a CD of mine had hidden audio before track one circa 1997, a coffee table jungle breakbeat on a Symphonic Black Metal album: https://www.discogs.com/release/373044-Arcturus-La-Masquerad... Also on the topic of trying to push the compact disc to its limits a Grindcore group who had a bonus track where \"All efforts were made to exceed typical limitations of 16 bit linear digital technology compression, limiting, and equalization curves have been created to deliver maximum gain structure\" https://www.discogs.com/release/4305023-Exit-13-Ethos-Musick I had a period of bad luck in my youth where I believed all these new enhanced CD's and shaped CD's were damaging the tracking of the lens on my CD player so I gave Exit-13 a swerve and started to listen to safer music ;) reply Neil44 8 hours agoprevI had a Rammstein ablum, that if you rewound before track 1 there was a black box audio recording of a plane crash were everyone died. It was pretty macabre. I think the CD cover was like a plane's black box if I remember correctly. reply 10729287 7 hours agoparentI’m not into this band but that could be related to this famous event : https://en.wikipedia.org/wiki/Ramstein_air_show_disaster reply hnbad 5 hours agorootparentNo, that's what they were named after. They released an epinomous song on their first album (Herzeleid) that played with the visual imagery of that disaster (\"Rammstein - a human burns / Rammstein - the smell of meat in the air / Rammstein - a child dies / Rammstein - the sun is shining\"). They apparently initially wanted to name the band Rammstein Flugschau (\"Rammstein flight show\") before shortening it to Rammstein. The difference in spelling was accidental but Rammstein is evocative (literally \"ramming stone\") so it stuck. The album the parent mentions is Reise, Reise, which is travel themed (in a broad sense of the word), the cover being styled after a black box (being bright orange of course). The flight recording in the pregap literally comes from a black box of a plane crash so that fits. reply Loughla 6 hours agoparentprevReuse, Reise is the album. It was a Japanese aircraft crash. It was on every album but those released in Japan I'm pretty sure. It's mostly just scrambled alarms and some Japanese yelling. Without the context it's pretty hard to understand what you're listening to. reply londons_explore 8 hours agoprevThings like CD's with their large number of partly-compatible extensions shoehorned in remind me that whenever one is writing a specification, one should make sure that every combination of bits/bytes is either valid with defined behaviour, or invalid. The one exception is a field for \"extensions\", which should have some bits for 'compatible' extensions (ie. there will be extra data ignored by readers which don't understand them), and other bits for 'incompatible' extensions (ie. you have put a DVD into a CD player). reply kstenerud 13 hours agoprevOne compact disc extension I remember well is CD+G. It was pretty wild plugging an Information Society CD into a CDTV and watching the (admittedly crappy) graphics while you listened to music and samples of Leonard Nimoy and DeForest Kelley... reply sziring 4 hours agoprevThe domain name is how I felt after trying to read the article. reply RiverCrochet 17 hours agoprevIf you are interested in this topic, locked grooves may also interest you. https://en.wikipedia.org/wiki/Unusual_types_of_gramophone_re... reply comprev 9 hours agoprev\"Korn - Follow The Leader\" (1998) album started on track 13. https://www.discogs.com/release/369188-Korn-Follow-The-Leade... reply exabrial 19 hours agoprevI remember discovering “hidden tracks” on the Beastie Boys intergalactic album with my cousins… we were like what on earth is happening as the CD player display glitched out and played this stuff we hadn’t heard. reply indus 17 hours agoprevIn the age of attention deficit infused dopamine—-who has the time for an Easter egg? Instead, engineers and product managers, slow roll quirkiness on social media. reply snvzz 19 hours agoprevAbusing the standard to put songs in gaps was such a bad idea. I have no idea how they got a patent for such a thing and, even worse, anyone ever did it on actual commercial discs. reply ssl-3 18 hours agoparentWhy? Are easter eggs like this harmful to consumers or something? reply snvzz 17 hours agorootparentIt's abusing the standard, which can break compliant implementations. Especially bad since most Audio CD players are opaque hardware without update-able firmware. reply zarmin 15 hours agorootparentYou're right. We should start a letter-writing campaign to President Bush. Maybe it will make the nightly news. Sent from my Discman reply ssl-3 17 hours agorootparentprevHas this been shown to be actually-problematic in the three decades since Willy Nelson's album contained a song in the pregap of track 1? reply lampiaio 15 hours agorootparentYes, there's been a serious issue recently reported. Apparently, it has triggered bureaucrats on the internet who can't acknowledge something innocuous that's never caused any problem for decades. reply thelastparadise 7 hours agorootparentLink? reply egypturnash 2 hours agorootparenthttps://news.ycombinator.com/item?id=40922903 reply zarmin 15 hours agorootparentprevof course not. reply d332 18 hours agoprevThis inspired me to read up on the low-level details of CD structure. I'm curious if anybody scanned an entire CD and shared the results, so that we could work with a raw image of disc that contains all its quirks, as opposed to the typical .iso format? reply thristian 14 hours agoparentIt's really difficult. Unlike floppy disks, where you tell the drive to seek and get back raw magnetic pulses (so you can produce raw flux images), or hard disks where you tell the drive to read an arbitrary sector and get a blob of data (so you can produce sector-level images), the protocol for talking to a CD ROM involves asking for track/sector addresses, which means you have to trust the drive to interpret all the track metadata and error-correction for you - you generally can't just dump the \"raw\" data and do the interpretation yourself. That's why the most robust CD image format is the BIN/CUE format. The BIN file contains all the sectors the drive allows us to read, the CUE file contains the disc metadata as interpreted for us by the drive firmware. There are some drives which support extra \"raw read\" commands, but they're incredibly rare and consequently in great demand by CD preservation projects like redump.org. Some people have used the contents of BIN/CUE data to reconstruct what should actually be on the disk, but that's not quite the same thing. Here's a great explanation of the CD structure in all its complexity: https://github.com/higan-emu/emulation-articles/tree/master/... reply AkBKukU 4 hours agorootparentEven BIN/CUE is not enough. It cannot store subchannel data like CD+G and is only able to hold a single session which breaks bluebook CDs with audio and data. We do not currently have a widely supported CD standard for storing data from a CD that can properly hold all data. Aaru [0] is close, but still has to output back to other formats like BIN/CUE to use the contents of the disc. [0] https://www.aaru.app/#/ reply ssl-3 18 hours agoparentprevAudio CDs were never ripped/transferred as ISO files. ISO-9660 is a filesystem that came years later, and Redbook audio CDs simply do not contain files. If you want to look at the structure of a whole audio CD, then one way is to rip it with a decent tool (perhaps cdrdao or EAC) and generate a bin/cue file pair as an output. reply d332 17 hours agorootparentBut that's not my goal. I'd like to be able to observe every grove, the physical encoding of data, and see if I could implement decoding from scratch. First problem is though that I don't know how to get a microscopic image of the disc. reply ssl-3 16 hours agorootparentYou don't need a microscopic image of a disc to do that; a two-dimensional photograph is of essentially no advantage here. All you need is the unmolested data from that disc. The data is arranged on a singular spiral groove starting from the center and slowly winding its way towards the outside. The data is completely linear: It begins at the beginning, and continues to the very end without interruption. This is all akin to (although opposite of) how a single-track vinyl record is physically laid out. The entire CD -- whatever it contains -- is just a continuous string of pits and lands. And to observe that string as it appears on a real disc, all you need to get started is a regular old-school CD player and some appropriate data acquisition gear, and maybe an oscilloscope to help figure out what you're looking at. The optics and basic motor controls are already solved problems, and it doesn't even have to be particularly fast data acquisition gear by today's standards to record what is happening. reply AkBKukU 4 hours agorootparentLook into the Domesday Duplicator project for Laserdiscs as an example of how what ssl-3 is talking about can be done using a high sample rate input. That exact process is possible and with enough storage and processing power can be used to get the most \"low level\" access to the data. It is not for the faint of heart though, and can take around 1TB of storage and hours of CPU time to process full movies in this way, I know because I've done it. I believe I've seen there is work being done to attempt this on CDs but it would have still been in the exploratory phases and not yet ready to start archiving with. It might seem like overkill to do this to something meant to be digitally addressed but I've experienced enough quirks with discs and drives when ripping that I would 100% be willing to switch over to a known complete capture system to not have to worry about it anymore. Post process decoding also allows for re-decoding data later if better methods are found. reply hunter2_ 16 hours agorootparentprevThe \"unmolested data\" would still have undergone error correction though, wouldn't it? I don't think a bin/cue rip would contain the redundant stuff, which GP seems interested in, nor the subcodes (of which some are represented in the cue file, while the bin file is PCM audio). And at the risk of taking us well beyond the rainbow books, I'll just leave this here: https://www.psxdev.net/forum/viewtopic.php?f=70&t=1266 reply ssl-3 15 hours agorootparentThere is a layer betwixt the optical reflection and the audio output that exists only as raw signals, before any molestation/error correction occurs. There cannot not be this layer. (And with a sufficiently-old-school CD player, it is probably not even challenging to get to it. The less-integrated the parts are, the better.) reply hunter2_ 12 hours agorootparentAh, I see. So what kind of capture hardware could read from that point? I assume it's a digital signal taking the form of 2-voltages, flipping on the order of 3.6 MHz (16 billion pits to read over 74*60 seconds). With Red Book audio at 1.4 Mbps, more than half of the raw data must be devoted to things like redundancy and other non-PCM stuff, if my interpretation that pits==bits isn't far off. Aside: is your username inspired by Secure Socket Layer or Solid State Logic? reply ssl-3 11 hours agorootparentI'm getting off into the weeds of what I know here, so take this all with a grain of salt. (I probably used to know more about all of this than I do right now.) The difference between a pit and a land is an optical phase change. The pits and lands vary in length, and there are 9 valid variations in their lengths. This combined phase/temporal situation eventually (thanks, science folks from 1970-something!) turns into a serial binary electrical signal inside of a CD player. This binary electrical signal can be recorded. Recorded with what, you asked? CDs have a lot more going on than just audio data: Remember, there's forward error correction at play and (by spec, IIRC) a player is supposed to be able to completely recover data even if there is a gap of 1mm due to a scratch or other interruption. (There's also room for tricks like CD+G to live in the background, and certainly what may seem like an inordinate amount of data used just for clocking: CDs are CLV, so playing them happens at a continuously-varying rotational speed in a tightly closed loop because buffer RAM was expensive to buy, and expensive to manage, and tight speed control was cheaper to implement. Remember, this was a finished digital product that was released in 1981.) I find old references[0] that suggest that the raw data rate of a CD (it does not matter what kind) is 4.3218 Mbps. So, to posit some example hardware: With careful loops and decent wiring, accurately capturing this seems like it would be well within the purvey of an RP2040's PIO's DMA modes to get that data into RAM, and also well within one of its 133MHz 32-bit ARM core's ability to package up and deliver that data over USB 2 to a host machine that can store it for later analysis -- plus or minus a transistor or two, or maybe a pullup resistor in just the right spot. (But that's just my opinion as a home hacker who has dabbled in RP2040 PIO assembler, and who is at or a bit beyond their knowledge of compact discs. I may wake up tomorrow and decide that the above is all bullshit and wish I could erase all of it. If in doubt, Phillips datasheets for CD player chipsets from the first half of the 1980s can probably help a lot more than I can.) --- As to the username: It's old. It predates Secure Socket Layer, but it's way newer than Solid State Logic. I was just a young kid with a new modem when I dialed into a Telegard BBS and started to sign up for an account, and got stuck at the prompt to enter a \"Handle\". I didn't know what a handle was in this new-to-me context. The sysop saw that I was stuck and dragged me into chat, as good sysops (hi Shawn!) tended to do upon seeing such a thing. We chatted for a bit, and I wasn't feeling creative, so he suggested that maybe I could look around for inspiration since most people used a made-up handle on his particular BBS. I found a 5.25\" floppy disk on the desk that I'd borrowed from the local public library. It was labeled \"Selective Shareware Library, Volume 3.\" (It was also almost certainly infected with the Stoned virus[1]). Anyhow, that was sufficiently inspiring, so ssl-3 it was. --- 0: https://www.geocities.ws/columbiaisa/cd_specs.htm 1: https://en.wikipedia.org/wiki/Stoned_(computer_virus) reply banish-m4 12 hours agorootparentprevNot necessarily. It depends if you're extracting data+subchannel data or corrected track data only. reply sho 15 hours agorootparentprevthis seems responsive: https://superuser.com/questions/140874/is-it-technically-pos... reply qingcharles 13 hours agorootparentI wonder if you could just tear the controller out of a CD/DVD drive and build a new one from scratch, kind of like the new floppy controllers being used now to read the raw magnetic data. You could just command the head to move to the center, find the beginning of the data and just keep reading until you hit the buffers. reply ssl-3 13 hours agorootparentSorta, kinda? It's a bit of a different game. Floppies (most of them, anyway) have fixed track widths, and these tracks are arranged cylindrically, and these cylinders align with the steps of the stepper motor that is used to actuate the head assembly. It's relatively easy, with the right ratio betwixt step advancement and track width, to get the head moving properly on a new implementation of a floppy controller. Want to read track 1? Step to the head N times to reach track 1 from wherever it started, and read it. Next, want to read track 33? Step the head N times to track 33, and read that. But tracking the spiral groove of a CD is a very different problem to solve. Steps tend to lose their meaning. Instead of electromagnetic steps, it involves 3 different laser beams: Two to continuously keep the head centered where it needs to be on the ever-changing groove using a servo feedback loop, and a third to read the data from the pits and lands from the middle of that groove. Is it do-able? Sure! People with far less advanced tech than we on HN might have laying around did it 40+ years ago. It's just a very different nut to crack than reading a floppy is, even if the mechanical and optical bits are recycled. (And that's just head positioning. The pits and lands still needs to be read, and those reflect back from the disc as optical phase shifts, not as changes in magnetic polarity and/or amplitude.) reply banish-m4 12 hours agorootparentprevWhy? You can extract raw data and raw subchannel data directly from a CD/DVD drive. This isn't the case with how floppy drives work. reply ssl-3 9 hours agorootparentThe \"why\" was covered in a parent comment: https://news.ycombinator.com/item?id=40923030 reply banish-m4 8 hours agorootparentI can read, thanks. There is no benefit to it. If the desire were to look at them out of curiosity, a microscope would do. reply fortran77 19 hours agoprevWhat's the \"A.C.\" band? reply K7PJP 19 hours agoparenthttps://en.wikipedia.org/wiki/Anal_Cunt reply fnord77 14 hours agoprev [–] that whole article went into a lot of detail about the history of pregaps, but never says what was actually put on the pregap reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article delves into the compatibility issues and complications associated with the audio CD hidden track phenomenon known as the before-album pregap.",
      "It explores how this pregap, a hidden track before the first track of an album, can cause playback issues on various CD formats and players.",
      "The discussion is relevant for those interested in the technical aspects of CDs, including CD, CD-i, CD-ROM, and enhanced CDs, and adheres to the Red Book standard for audio CDs."
    ],
    "commentSummary": [
      "CD pregaps have been creatively used for hidden tracks and live recordings, often containing crowd noise between songs, only audible when playing the album continuously.",
      "CDs can technically support up to 9,801 audio segments through 99 tracks and 99 index markers, but few CD players support index navigation.",
      "While some users rip CDs preserving pregaps for gapless playback, the desire for a unified album format with metadata persists, as current solutions like FLAC/cue lack widespread hardware support."
    ],
    "points": 189,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1720553916
  },
  {
    "id": 40922739,
    "title": "RouteLLM: A framework for serving and evaluating LLM routers",
    "originLink": "https://github.com/lm-sys/RouteLLM",
    "originBody": "RouteLLM RouteLLM is a framework for serving and evaluating LLM routers. [ Blog ] [ Paper ] Our core features include: Drop-in replacement for OpenAI's client (or launch an OpenAI-compatible server) to route simpler queries to cheaper models. Trained routers are provided out of the box, which we have shown to reduce costs by up to 85% on widely-used benchmarks such as MT Bench while maintaining 95% GPT-4 performance. Easily extend the framework to include new routers and compare the performance of routers across multiple benchmarks. Installation From PyPI pip install \"routellm[serve,eval]\" From source git clone https://github.com/lm-sys/RouteLLM.git cd RouteLLM pip install -e .[serve,eval] Quickstart Let's walkthrough replacing an existing OpenAI client to route queries between LLMs instead of using only a single model. First, let's replace our OpenAI client by initializing the RouteLLM controller with the mf router. By default, RouteLLM will use the best-performing config: import os from routellm.controller import Controller os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXXXX\" # Replace with your model provider, we use Anyscale's Mixtral here. os.environ[\"ANYSCALE_API_KEY\"] = \"esecret_XXXXXX\" client = Controller( routers=[\"mf\"], strong_model=\"gpt-4-1106-preview\", weak_model=\"anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1\", ) Above, we pick gpt-4-1106-preview as the strong model and anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1 as the weak model, setting the API keys accordingly. You can route between different model pairs or providers by updating the model names as described in Model Support. Want to route to local models? Check out Routing to Local Models. Each routing request has a cost threshold that controls the tradeoff between cost and quality. We should calibrate this based on the types of queries we receive to maximize routing performance. As an example, let's calibrate our threshold for 50% GPT-4 calls using data from Chatbot Arena. > python -m routellm.calibrate_threshold --routers mf --strong-model-pct 0.5 --config config.example.yaml For 50.0% strong model calls for mf, threshold = 0.11593 This means that we want to use 0.11593 as our threshold so that approximately 50% of all queries (those that require GPT-4 the most) will be routed to it (see Threshold Calibration for details). Now, let's update the model field when we generate completions to specify the router and threshold to use: response = client.chat.completions.create( # This tells RouteLLM to use the MF router with a cost threshold of 0.11593 model=\"router-mf-0.11593\", messages=[ {\"role\": \"user\", \"content\": \"Hello!\"} ] ) That's it! Now, requests with be routed between the strong and weak model depending on what is required, saving costs while maintaining a high quality of responses. Depending on your use case, you might want to consider using a different model pair, modifying the configuration, or calibrating the thresholds based on the types of queries you receive to improve performance. Server & Demo Instead of using the Python SDK, you can also launch an OpenAI-compatible server that will work with any existing OpenAI client, using similar steps: > export OPENAI_API_KEY=sk-XXXXXX > export ANYSCALE_API_KEY=esecret_XXXXXX > python -m routellm.openai_server --routers mf --strong-model gpt-4-1106-preview --weak-model anyscale/mistralai/Mixtral-8x7B-Instruct-v0.1 INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:6060 (Press CTRL+C to quit) Once the server is launched, you can start a local router chatbot to see how different messages are routed. python -m examples.router_chat --router mf --threshold 0.11593 Model Support In the above examples, GPT-4 and Mixtral 8x7B are used as the model pair, but you can modify this using the strong-model and weak-model arguments. We leverage LiteLLM to support chat completions from a wide-range of open-source and closed models. In general, you need a setup an API key and point to the provider with the appropriate model name. Alternatively, you can also use any OpenAI-compatible endpoint by prefixing the model name with openai/ and setting the --base-url and --api-key flags. Note that regardless of the model pair used, an OPENAI_API_KEY will currently still be required to generate embeddings for the mf and sw_ranking routers. Instructions for setting up your API keys for popular providers: Local models with Ollama: see this guide Anthropic Gemini - Google AI Studio Amazon Bedrock Together AI Anyscale Endpoints For other model providers, find instructions here or raise an issue. Motivation Different LLMs vary widely in their costs and capabilities, which leads to a dilemma when deploying them: routing all queries to the most capable model leads to the highest-quality responses but can be very expensive, while routing queries to smaller models can save costs but may result in lower-quality responses. LLM routing offers a solution to this. We introduce a router that looks at queries and routes simpler queries to smaller, cheaper models, saving costs while maintaining quality. We focus on routing between 2 models: a stronger, more expensive model and a cheaper but weaker model. Each request is also associated with a cost threshold that determines the cost-quality tradeoff of that request - a higher cost threshold leads to lower cost but may lead to lower-quality responses. Server RouteLLM offers a lightweight OpenAI-compatible server for routing requests based on different routing strategies: python -m routellm.openai_server --routers mf --config config.example.yaml --routers specifies the list of routers available to the server. For instance, here, the server is started with one available router: mf (see below for the list of routers). --config specifies the path to the configuration file for the routers. If unspecified, the server will default to using our best-performing configuration (see Configuration for details). For most use-cases, we recommend the mf router as we have evaluated it to be very strong and lightweight. When making a request to the server, clients specify the router and cost threshold to use for each request using the model field in the following format router-[ROUTER NAME]-[THRESHOLD]. For instance, using a model of router-mf-0.5 specifies that the request should be routed using the mf router with a threshold of 0.5. Threshold Calibration The threshold used for routing controls the cost-quality tradeoff. The range of meaningful thresholds varies depending on the type of router and the queries you receive. Therefore, we recommend calibrating thresholds using a sample of your incoming queries, as well as the % of queries you'd like to route to the stronger model. By default, we support calibrating thresholds based on the public Chatbot Arena dataset. For example, to calibrate the threshold for the mf router such that 50% of calls are routed to the stronger model: > python -m routellm.calibrate_threshold --task calibrate --routers mf --strong-model-pct 0.5 --config config.example.yaml For 50.0% strong model calls for mf, threshold = 0.11593 This means that the threshold should be set to 0.1881 for the mf router so that approximately 50% of calls are routed to the strong model i.e. using a model field of router-mf-0.1159. However, note that because we calibrate the thresholds based on an existing dataset, the % of calls routed to each model will differ based on the actual queries received. Therefore, we recommend calibrating on a dataset that closely resembles the types of queries you receive. Evaluation RouteLLM also includes a evaluation framework to measure the performance of different routing strategies on benchmarks. To evaluate a router on a benchmark, you can use the following command: python -m routellm.evals.evaluate --routers random sw_ranking bert --benchmark gsm8k --config config.example.yaml --routers specifies the list of routers to evaluate, for instance, random and bert in this case. --benchmark specifies the specific benchmark to evaluate the routers on. We currently support: mmlu, gsm8k, and mt-bench. Evaluation results will be printed to the console. A plot of router performance will also be generated in the current directory (override the path using --output). To avoid recomputing results, the results for a router on a given benchmark is cached by default. This behavior can be overridden by using the --overwrite-cache flag, which takes in a list of routers to overwrite the cache for. The results for all our benchmarks have been cached. For MT Bench, we use the precomputed judgements for the desired model pair. For MMLU and GSM8K, we utilized SGLang to compute the results for the desired model pair - the full code for this can be found in the benchmark directories if you would like to evaluate a different model pair. By default, GPT-4 and Mixtral are used as the model pair for evaluation. To modify the model pair used, set them using the --strong-model and --weak-model flags. Routers Out of the box, RouteLLM supports 4 routers trained on the gpt-4-1106-preview and mixtral-8x7b-instruct-v0.1 model pair. The full list of routers: mf: Uses a matrix factorization model trained on the preference data (recommended). sw_ranking: Uses a weighted Elo calculation for routing, where each vote is weighted according to how similar it is to the user's prompt. bert: Uses a BERT classifier trained on the preference data. causal_llm: Uses a LLM-based classifier tuned on the preference data. random: Randomly routes to either model. While these routers have been trained on the gpt-4-1106-preview and mixtral-8x7b-instruct-v0.1 model pair, we have found that these routers generalize well to other strong and weak model pairs as well. Therefore, you can replace the model pair used for routing without having to retrain these models! For the full details, refer to our paper. Configuration The configuration for routers is specified in either the config argument for Controller or by passing in the path to a YAML file using the --config flag. It is a top-level mapping from router name to the keyword arguments used for router initialization. An example configuration is provided in the config.example.yaml file - it provides the configurations for routers that have trained on Arena data augmented using GPT-4 as a judge. The models and datasets used are all hosted on Hugging Face under the RouteLLM and LMSYS organizations. Contribution We welcome contributions! Please feel free to open an issue or a pull request if you have any suggestions or improvements. Adding a new router To add a new router to RouteLLM, implement the abstract Router class in routers.py and add the new router to the ROUTER_CLS dictionary. Then, you can use immediately the new router in the server or evaluation framework. There is only a single method to implement: calculate_strong_win_rate, which takes in the user prompt and returns the win rate for the strong model conditioned on that given prompt - if this win rate is great than user-specified cost threshold, then the request is routed to the strong model. Otherwise, it is routed to the weak model. Adding a new benchmark To add a new benchmark to RouteLLM, implement the abstract Benchmark class in benchmarks.py and update the evaluate.py module to properly initialize the new benchmark class. Ideally, the results for the benchmark should be precomputed to avoid having to regenerate the results for each evaluation run -- see the existing benchmarks for examples on how to do this. Citation The code in this repository is based on the research from the paper. Please cite if you find the repository helpful. @misc{ong2024routellmlearningroutellms, title={RouteLLM: Learning to Route LLMs with Preference Data}, author={Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E. Gonzalez and M Waleed Kadous and Ion Stoica}, year={2024}, eprint={2406.18665}, archivePrefix={arXiv}, primaryClass={cs.LG}, url={https://arxiv.org/abs/2406.18665}, }",
    "commentLink": "https://news.ycombinator.com/item?id=40922739",
    "commentBody": "RouteLLM: A framework for serving and evaluating LLM routers (github.com/lm-sys)188 points by djhu9 18 hours agohidepastfavorite29 comments fbnbr 4 hours agoThis RouteLLM framework sounds really promising, especially for cost optimization. It reminds me of the KNN-router project ([https://github.com/pulzeai-oss/knn-router](https://github.co...), which uses a k-nearest neighbors approach to route queries to the most appropriate models. What I like about these kinds of solutions is that they address the practical challenges of using multiple LLMs. Rate limits, cost per token, and even just choosing the right model for the job can be a real headache. KNN-router, for example, lets you define your own logic for routing queries, so you can factor in things like model accuracy, response time, and cost. You can even set up fallback models for when your primary model is unavailable. It's cool to see these kinds of tools emerging because it shows that people are starting to think seriously about how to build robust, cost-effective LLM pipelines. This is going to be crucial as more and more companies start incorporating LLMs into their products and services. reply furyofantares 17 hours agoprevI don't really get who these are for - do people use them in their projects? I don't find success just using a prompt against some other model without having some way to evaluate it and usually updating it for that model. reply vatican_banker 16 hours agoparent> Trained routers are provided out of the box, which we have shown to reduce costs by up to 85% The answer is here. This is a cost-saving tool. All companies and their moms want to be in the GenAI game but have strict budgets. Tools like this help to keep GenAI projects within budget. reply rodrigobahiense 12 hours agoparentprevFor the company I work for, one of the most important aspects is ensuring we can fallback to different models in case of content filtering since they are not equally sensitive/restrict. reply veb 16 hours agoparentprevFrom what I understand, it's from people using it in their workflows - say, Claude but keep hitting the rate limits, so they have to wait until Claude says \"you got 10 messages left until 9pm\", so when they hit that, or before they switch to (maybe) ChatGPT manually. With the router thingy, it keeps a record, so you know every query where you stand, and can switch to another model automatically instead of interrupting workflow? I may be explaining this very badly, but I think that's one use-case for how these LLM Routers help. reply Kiro 9 hours agorootparentI don't think that's a use case since you don't get rate limited when using the API. reply Onawa 5 hours agorootparentWe get rate limited when using Azure's OpenAI API. As a gov contractor working with AI, I have limited means for getting access to frontier LLMs. So routing tools that can fail over to another model can be useful. reply fkyoureadthedoc 4 hours agorootparentSame. Initially we just load balanced between various regions, ultimately bought some PTUs. reply kordlessagain 4 hours agorootparentprevAnthropic Build Tier 4: 4,000 RPM, 400,000 TPM, 50,000,000 TPD for Claude 3.5 Sonnet reply PiRho3141 16 hours agorootparentprevThis is for applications that use LLMs or Chat GPT via API. reply brandall10 16 hours agoparentprevYou may have a variety of model types/sizes, fine tunes, etc, that serve different purposes - optimizing for cost/speed/specificity of task. At least that's the general theory with routing. This one only seems to optimize for cost/quality. reply monarchwadia 12 hours agoparentprevI think a lot of people are just interested in hitting the LLM without any bells or whistles, from Typescript. A low level connector lib would come in handy, yeah? https://github.com/monarchwadia/ragged reply bangaladore 2 hours agoprevI've been using OpenRouter only for personal use, not for its router functionality, so I can use the API of various models (or open-source models) without signing up and prepaying/paying a subscription on all their websites. I believe OpenRouter also provides an API that does the same thing as RouteLLM. Again, you only have to pay OpenRouter, not every model's service you use. reply Havoc 10 hours agoprevInteresting that it is generalizable to other pairs. That implies some sort of prompt property or characteristic that could be widely used. I don’t think using different models is the right approach though. They behave differently. Better to use a big and small one from same family. Or alternatively using this to drive whether to give the ai more “thinking time” via chain of thought or agents. reply worstspotgain 17 hours agoprevI like their \"LLM isovalue\" graph, and the idea that different vendors can be forced to partake in the same synergy/distillation scheme. Vendors dislike these schemes, but they're probably OK with them as long as they're niche. reply tananaev 16 hours agoprevThe problem is to understand how complex the request is, you have to use a smart enough model. reply Fripplebubby 3 hours agoparentIn this paper, they tried a couple different methods for determining how similar the incoming request is to requests that they have scored in their dataset. Actually, one of the best methods they used does not involve using a model at all to evaluate the incoming query (similarity-weighted ranking) although it _does_ use pre-trained embeddings. Using this, they were able to produce quite good results applying this similarity measurement to unseen queries using a standard benchmark. The leap of faith here is assuming that the same query similarity method will continue to bear fruit when extended to queries that aren't benchmarkable. reply Grimblewald 14 hours agoparentprevnot true at all, you could have a efficient cheap model which is generally terrible at most things but has a savant like capacity for categorizing tasks by requirement and difficulty. Even easier when you dont need to support multiple languages and a truly staggering breadth of domains, like a conventional llm does. You could train a really small model to reject out of domain requests and partition the rest, running at a fraction of the cost of a more capable model. reply ethegwo 15 hours agoparentprevThe weak-to-strong assumption is that it is easier to eval the result of a task than to generate it. If it is wrong, human can not make a stronger intelligence than us. reply PiRho3141 16 hours agoparentprevNot true. You can easily train a BERT single class classification model without having to train an LLM. reply CuriouslyC 16 hours agoparentprevYou can distill evaluation ability reply vatican_banker 16 hours agoprevThe tool currently allows only one set of strong and weak models. I’d be really good to allow more than two models and change dynamically based on multiple constraints like latency, reasoning complexity, costs, etc. reply voiper1 12 hours agoparentI think unify.ai (like openrouter) does that - it has several paramters you can choose from. But the underlying \"how to choose a model that's smart enough but not too smart\" seems difficult to understand. reply TechDebtDevin 10 hours agorootparentIts just sentiment analysis. reply Oras 9 hours agoparentprevPortkey does that with configuration. You assign a base model, then add more models with weight to load-balance. reply KTibow 16 hours agoparentprevSome of that is already possible, since it can generate a difficulty score for a prompt that could be manually mapped between models based on ranges. reply daghamm 10 hours agoprevMy take from this is that 85% of times we don't need a powerfull LLM like 4o. Or am I reading this wrong? :) reply thomashop 10 hours agoparentYou're reading it right. They have developed a system that automatically decides which model is sufficient, depending on your inputs, saving you costs even within one conversation stream. The OpenAI-compatible API allows you to talk to the router like a regular GPT model. reply AFTABMOHAMED 6 hours agoprev [–] Hi reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "RouteLLM is a framework designed for serving and evaluating Large Language Model (LLM) routers, offering a cost-effective alternative to OpenAI's client by routing simpler queries to cheaper models.",
      "Key features include pre-trained routers that can reduce costs by up to 85% while maintaining 95% of GPT-4's performance, and an extendable framework for adding new routers and comparing performance across benchmarks.",
      "The framework supports various models and providers, requires an OPENAI_API_KEY for generating embeddings, and allows for threshold calibration to balance cost and quality."
    ],
    "commentSummary": [
      "RouteLLM is a new framework designed to serve and evaluate LLM (Large Language Model) routers, with a focus on cost optimization.",
      "It offers trained routers that can reduce costs by up to 85%, addressing challenges like rate limits, cost per token, and model selection, making it valuable for budget-conscious companies.",
      "The framework allows users to fallback to different models and manage rate limits automatically, making it a crucial tool for building robust and cost-effective LLM pipelines."
    ],
    "points": 188,
    "commentCount": 29,
    "retryCount": 0,
    "time": 1720571738
  },
  {
    "id": 40925896,
    "title": "ML Code Exercises",
    "originLink": "https://www.deep-ml.com/",
    "originBody": "Deep-ML Login Sign Up ML Code Challenges All Difficulties Easy Medium Hard All Categories linear algebra machine learning deep learning All Problems Solved Unsolved Title Category Difficulty Status Matrix times Vector linear algebra Easy Unsolved Calculate Covariance Matrix linear algebra Medium Unsolved Solve Linear Equations using Jacobi Method linear algebra Medium Unsolved Singular Value Decomposition (SVD) linear algebra Hard Unsolved Determinant of a 4x4 Matrix using Laplace's Expansion linear algebra Hard Unsolved Linear Regression Using Normal Equation machine learning Easy Unsolved Linear Regression Using Gradient Descent machine learning Easy Unsolved Feature Scaling Implementation machine learning Easy Unsolved K-Means Clustering machine learning Medium Unsolved Cross-Validation Data Split Implementation machine learning Medium Unsolved Principal Component Analysis (PCA) Implementation machine learning Medium Unsolved Transpose of a Matrix linear algebra Easy Unsolved Decision Tree Learning machine learning Hard Unsolved Pegasos Kernel SVM Implementation machine learning Hard Unsolved Sigmoid Activation Function Understanding deep learning Easy Unsolved Softmax Activation Function Implementation deep learning Easy Unsolved Single Neuron deep learning Easy Unsolved Single Neuron with Backpropagation deep learning Medium Unsolved Implementing Basic Autograd Operations deep learning Medium Unsolved Reshape Matrix linear algebra Easy Unsolved 1 2 Next",
    "commentLink": "https://news.ycombinator.com/item?id=40925896",
    "commentBody": "ML Code Exercises (deep-ml.com)187 points by mchab 7 hours agohidepastfavorite57 comments mchab 7 minutes agoCreated a discord for anyone that had any recommendations or wants to stay up to date on new questions we are working on https://discord.gg/s4uVTQwk reply TrackerFF 6 hours agoprevNo one (well, few professionals at least) will reinvent the wheel when it comes to standard scientific computations and methods. Like numerical math, linear algebra, etc. Looking through the problem sets in the link, the majority seems to be asking for just that. If you're wondering whether or not someone knows how to transpose a matrix, or find the eigenvalues, let them do that on the whiteboard. No need to leetcode-ify such problems, because with 99.99% probability they'll provide you with solutions that are subpar compared to industry standard packages. There's more than time and space complexity when it comes to these problems. EDIT: Also, you'll potentially lose a lot of high-quality candidates if you suddenly start to test people on methods they haven't worked with or seen in quite a while. If you ask something like \"please show us the equations for a support vector machine, and how you can compute a SVM\" you could fail even world class ML scientists, if they haven't touched those for 10 years. Which is a very real possibility in the current ML scene. I'd say that almost every ML interview I've had, or been part of, have been more big picture whiteboard interviews. Specific programming questions have ranked quite low on things to prioritize. reply mchab 6 hours agoparentI really enjoyed andrej karpathy’s zero to hero videos and I like the concept of you don’t know something till you build it, so I made this site, probably should of come up with a better title because it is made as a learning tool not as interview prep like leetcode reply seanc 5 hours agorootparentFirst off, thanks! This does look like a fun way to learn things. Secondly, FWIW, when I read the the term 'excercises' in the HN title I interpreted that to mean exactly a learning tool and not interview prep. The term \"Challenges\" in the website title is maybe a little less specific. reply jvanderbot 6 hours agorootparentprevI can appreciate that. It wasn't until I implemented a few matrix factorization routines that I appreciated the decisions that go into Eigen, etc. It wasn't until I tried it with SIMD that I appreciated the speedups and knew where to look to coax them out. reply petermcneeley 5 hours agoparentprev> No one (well, few professionals at least) will reinvent the wheel when it comes to standard scientific computations and methods. Like numerical math, linear algebra, etc. > because with 99.99% probability they'll provide you with solutions that are subpar compared to industry standard packages. Somebody did last week with only a modest amount of effort: https://news.ycombinator.com/item?id=40870345 reply akudha 5 hours agoparentprevMost orgs need drivers but they interview like mechanics. If I am a driver, I am expected to drive different vehicles. Sure I know to do basic stuff like change tires/oil etc, but I am not going to know how to fix the engine or something else under the hood, right? reply lamename 6 hours agoparentprevSo it is a leetcode equivalent ;) reply sourabhv 6 hours agorootparentlol reply coliveira 5 hours agoparentprevThis kind of interview questions come from the mind of software developers, because that's the only thing they know how to do. When faced with some new area of knowledge, their instinct is to try to implement that in Python or some other language and imagine they have \"learned\" it. It doesn't occur to them that implementing things is not that helpful when it comes to most math topics. reply bArray 6 hours agoprevThis is quite a nice way to learn about ML, props for this! Edit: I see a lot of people complaining about interviews, but instead I consider this a good resource for checking you understand fundamental principles. reply mchab 6 hours agoparentExactly, I think putting leetcode in the title triggered a lot of people reply HiPHInch 4 hours agoprevThank you for your work! Is there something wrong with: https://www.deep-ml.com/problem/7 ? reply mchab 4 hours agoparentYes, it seems like there is an issue with that question will try and fix that as soon as possible, thank you for the catch reply esafak 6 hours agoprevThe hard part about ML isn't the implementation but the theory. If you're not sure what SVD is how is this going to help? https://www.deep-ml.com/problem/12 reply oehpr 48 minutes agoparentIt gives you an impetus to learn and a question to test your understanding. I'd say there's a pretty good track record for this style of teaching. reply mchab 6 hours agoparentprevThe learn section should help, but I think I need to spend more time improving the learn section reply oehpr 46 minutes agorootparentI would say that \"learn\" button is a little unclear. It might be better to just have the whole learning section beneath the question, always visible. That will also help drive home the intent of the page, since so many people think this is some weird interview questions prep site. reply csmpltn 3 hours agoparentprevWho the fuck asks about this useless garbage in an ML job interview. This is such a waste of time and gives you absolutely zero insight into the candidate, how they think, how they’re able to dissect and handle complex issues, their seniority, etc. Whoever expects people to regurgitate this garbage during a job interview is a loser themselves, and will only end up recruiting similar losers to hang out with and get NOTHING done ever. ML job interviews specifically are bottom of the barrel standard. reply ZoomerCretin 14 minutes agoprevThe first example is a bit confusing. Example: input: a = [[1,2],[2,4]], b = [1,2] output:[5, 10] reasoning: 11 + 22 = 5; 12+ 24 = 10 Which 1 and 2 correspond to the 1 and 2 from a and b? reply mchab 5 minutes agoparentThat is a good point, thank you for the input I will change up the example problem to clear things up reply diimdeep 15 minutes agoprevI like Code Kata approach, it allows to learn and practice. But dislike siloed websites like Leetcode where they ask you to bear with their awful web experience, I want to keep my code and notes offline and close in case I need it in a year or 10 years. Approach with simple test files and exercises is more appealing to me https://github.com/dabeaz-course/python-mastery So what is the goal here, to be like Leetcode ? or spread knowledge ? If latter, put material as plain markdown and .py files on github repo, we will say thank you. reply renegade-otter 6 hours agoprevIf you have to \"study\" something for interviews every single time because it's absolutely not relevant to your day job - it's probably bullshit. Everyone copies the FAANG interview process because it looks cool - except that FAANG is just a welfare program for recent graduates, who indulge in peer interview hazing because they are not doing anything else. They don't study for Leetcode because they want to DO something - they study because of the money. But in a real company you have to DO things. What has Google done in the last decade that is REALLY useful? Google Gmail and Docs can be maintained by probably 50 people, their search has gotten useless and all they do is kill their own products because maintenance toil is a total drag. Like the dumb brain teasers that Google \"pioneered\" in 2000s. How many golf balls can fit in a 747? I don't know, but I can estimate how many can fit up your a... This Leetcode nonsense will go the way of THAT, in time. Just no. reply coliveira 5 hours agoparentThey're very busy reinventing the same product over and over, so they can kill it again next month! reply bena 5 hours agoparentprevIt was Microsoft who started with the “golf balls in a plane” style questions. Google iterated to the standard DSA questions that are common now. And I don’t think they’re entirely without merit. However, people think you should be testing to find the ceiling. That’s impossible. Not only do you have the issue of whether or not the candidate just got lucky by getting a question they just happen to know, if you are hiring for a more junior position, it’s likely you don’t need them to know it in the first place. Our goal should be to test the floor, not the ceiling. Find questions that can be answered by anyone with the skill set you desire. Sometimes that floor is: can you write runnable code. We’ve just completed a hiring cycle where several candidates couldn’t transform a simple circuit diagram into a Boolean statement. One candidate who professed SQL knowledge who couldn’t write a simple query. And I mean “how many buckets do you have?” level of simple. On paper, these candidates seemed good. Several even had GitHub repositories. But, end of the day, I’m going to ask you to do a task. I’m going to need it by a date. I’m going to need that completed without having to comb over it and possibly rewrite chunks of it. I don’t need the next Linus Torvalds, but so many candidates come with greatly exaggerated resumes and we have to winnow somehow. reply ldjkfkdsjnv 6 hours agoparentprevGoogle invented AI reply renegade-otter 6 hours agorootparentMachine learning? They did not. They iterated on it, and then dropped the ball, losing the race to OpenAI. My point exactly. reply ldjkfkdsjnv 6 hours agorootparentGenerative ai came from efforts to improve search via text embeddings reply sourabhv 6 hours agoprevWhile this might be helpful to gain a deeper understanding, but adding a time constraint and making it something that can be asked in an interview sounds painful. Please make this a github repo instead like python_koans reply sk11001 6 hours agoprevTypically what happens for ML engineering roles is that you have a regular Leetcode round as for any other SWE position and an additional round with ML questions without coding - there's no ML-specific LC questions. Which is nice as a candidate because it's yet another thing to prepare for, even if the questions are relevant and being able to solve them is kind of neat. reply iknownthing 5 hours agoparentI've definitely had ML questions involving coding e.g. implement k-means reply iknownthing 5 hours agoprevI'm curious how you run the python code in the browser reply MOARDONGZPLZ 6 hours agoprevI haven’t seen anyone ask these types of questions for interviewing for ML positions. They feel like ChatGPT or straight from a textbook. Can you share how you arrived at these questions? reply mchab 6 hours agoparentI created these questions from a mix or resources, some from libraries like numpy linalg docs, and sklearn docs. Some from textbooks like https://www.deeplearningbook.org/ And others I asked chatgpt about reply sweezyjeezy 6 hours agoprevEdit: previous title was \"Leetcode for ML\" or somesuch... I like the idea and might try some! But as a warning: leetcode is specifically aimed at prepping for interviews, and I've never seen questions like these in an interview (I'm somewhere between an MLE and ML researcher FWIW). The most common kinds of ML-specific things in my experience are: - ML system design (basically everyone does this) - ML knowledge questions (\"explain ADAM etc.\") - probability + statistics knowledge - ML problem solving in a notebook (quite rare, but some do it) reply mchab 6 hours agoparentProbably should have titled it something else, I made it more as a learning platform for people to get better at ml by implementing algorithms from scratch. I’m currently a data scientist but wanted to become a machine learning researcher or engineer and I thought these types of questions would help reply iknownthing 5 hours agoparentprevI saw the k-means one a couple times reply admissionsguy 6 hours agoprevLooks like a decent problem set to accompany an introductory ML class. No need to get so defensive. However, I thought leetcode meant algorithmic problem solving while the problems here simply ask to implement the various elementary operations. reply mchab 6 hours agoparentYeah I think I miss titled my post it is more of a learning tool and less of a leetcode/ interview prep site reply dang 6 hours agorootparentOk, we've changed the title above. I hope that helps! (Submitted title was \"Leetcode but for ML\".) reply mchab 6 hours agorootparentI would, but do not see the option to change the title reply dang 5 hours agorootparentWe already did! I was just letting you know. reply mchab 5 hours agorootparentNice, thank you reply mrits 6 hours agoprevThe issue with leetcode type questions is that formally trained and experienced people often could not answer these questions without specifically practicing for them. Most of the topics on this list could be covered in an introduction course. reply anualvis 4 hours agoprevIs it down for anyone else too? reply mchab 4 hours agoparentcan you not get to the site or when you run your code it does not run? reply Xeamek 6 hours agoprevGreat resource! reply kebsup 5 hours agoprevIt's sad how a lot of people see this as \"a bad way to test job candidates\" rather than a \"fun way to practice ML skills\". reply lamename 5 hours agoparentThose comments are based on the original title introducing it as an ML Leetcode. The title is more accurate now. reply mchab 5 hours agoparentprevthanks! I think having leetcode in the title angered a lot of people reply rvz 5 hours agorootparentIt doesn't matter. I would have preferred that the title mentions that it is Leetcode-like anyway. But thanks for giving Leetcode yet another idea to test AI Engineers who do not know how to write a multi-layered perceptron or a softmax activation function from scratch with yet another repository of already solved puzzles to making it easier for interviewers. I'd say its pretty useful myself. And so it begins with the complaints of \"The AI interview is broken\", \"We are the only industry that does this\" frequently being preached here. reply htrp 6 hours agoprevPlease don't. Leetcode already ruined so many coding interviews by asking people to do bullshit like \"Output data from a stream in order, make the solution performant\" Why would you ruin ML for us too? Looking at your site, problem #1 is Multiply a matrix times a vector..... in no universe is that a legitimate ML interview question. Also ML is such a huge field (everything from statistical learning through to transformer neural networks), I fail to see how you could say your solution tests core skills. If I'm hiring for an ASR Role, it's going to be very different than for a CV role. reply r-zip 3 hours agoparent> in no universe is that a legitimate ML interview question Why not? This seems like the ML equivalent of FizzBuzz. If you don't know how matrix multiplication works well enough to implement it, I would argue that you don't know what you're doing at all. reply rty32 6 hours agoprev [4 more] My nightmare has finally come true. reply dang 6 hours agoparentOk, but please don't post unsubstantive comments to HN, and especially not shallow dismissals of someone's work. https://news.ycombinator.com/showhn.html https://news.ycombinator.com/newsguidelines.html reply rty32 5 hours agorootparentSorry for the judgement of the lack of \"substance\" of the comment, but to my defense I see this kind of comment all the time under almost every post (including this one), and it is not always obvious unless pointed out. And this is in no way dismissive of the work. I can definitely see the value in this -- I am just saying many people don't wish to see this, which many people apparently agree based on the number of votes. reply tjungblut 6 hours agoparentprev [–] Inverting a binary tree became implementing SVD with arrays only. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The platform Deep-ML offers a variety of code challenges across different categories such as linear algebra, machine learning, and deep learning, catering to various difficulty levels from easy to hard.",
      "Challenges include practical implementations like Linear Regression, K-Means Clustering, and Principal Component Analysis (PCA), providing hands-on experience for learners.",
      "This resource is particularly valuable for students and entry-level engineers looking to strengthen their understanding and skills in fundamental and advanced machine learning concepts."
    ],
    "commentSummary": [
      "A new website, deep-ml.com, offers machine learning (ML) code exercises inspired by Andrej Karpathy’s videos, intended as a learning tool rather than interview preparation.",
      "The platform has sparked debate about the relevance of such exercises for ML job interviews, with some arguing they focus too much on basic computations rather than practical skills.",
      "The creator, mchab, emphasizes that the site is for educational purposes, not to mimic Leetcode-style interview questions, and is open to feedback and improvements via a dedicated Discord channel."
    ],
    "points": 187,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1720612410
  },
  {
    "id": 40925471,
    "title": "Girls in Tech closes its doors after 17 years",
    "originLink": "https://venturebeat.com/games/girls-in-tech-closes-its-doors-after-17-years/",
    "originBody": "GamesBeat is excited to partner with Lil Snack to have customized games just for our audience! We know as gamers ourselves, this is an exciting way to engage through play with the GamesBeat content you have already come to love. Start playing games here. The Girls in Tech nonprofit women’s tech community is closing its doors after 17 years, according to a newsletter from founder Adriana Gascoigne. Gascoigne said the decision was made with “sadness and devastation” and was not made lightly. “It is with a heavy heart that I share the news that Girls in Tech will be closing its doors. This decision was not made lightly, and the sadness and devastation we feel cannot be overstated,” Gascoigne wrote. “For 17 incredible years, we have offered a welcoming community based on empowerment, support, and inspiration for women in the tech industry. Together, we have made a profound impact, helping women reach for the stars and excel in their careers, while working tirelessly to eliminate the gender gap in tech worldwide.” Adriana Gascoigne (center) founded Girls in Tech 17 years ago. The group reached more than 250,000 individuals across 35 chapters in 30 countries on six continents. It was founded in Silicon Valley, but Gascoigne relocated the group to Nashville, Tennessee, in 2022 during the pandemic. I interviewed her numerous times about the group’s mission and goals, and how it rose to greater relevance in fighting the “toxic culture” of Silicon Valley. Lil Snack & GamesBeat GamesBeat is excited to partner with Lil Snack to have customized games just for our audience! We know as gamers ourselves, this is an exciting way to engage through play with the GamesBeat content you have already come to love. Start playing games now! “Girls in Tech has always been more than just an organization; it has been a community built on love—love for technology and love for one another. The passion to support, uplift, and inspire each other is what has truly set us apart. I am immensely proud of what we have built together and the lasting impact we have made,” Gascoigne said in the newsletter. The group’s programs included a mentorship program, hackathons, coding bootcamps, the Girls in Tech Conference, a startup challenge, global classroom, podcast, blog, jobs board, and shop. The group organized thousands of in-person and virtual events, producing educational and engaging content. Adriana Gascoigne (in blue) after ringing closing bell at NYSE on Dec. 27 in 2016. “To everyone who poured their heart into building this wonderful community where women in tech could have a voice, learn, grow, and be celebrated just as they are—I am profoundly grateful,” Gascoigne said. “A special thanks to all of our members, who established such a friendly, warm, and collaborative environment and culture; the managing directors and advisory board teams who led our chapters; our staff at headquarters who managed and grew the organization; our sponsors who funded our programs and events; and our board of directors.” Without explanation, Gascoigne said in closing, “Though Girls in Tech is closing its doors, the movement we started must and will continue. I encourage each of you to carry on the fight to eliminate the gender gap in tech. Our mission will live on in other forms, driven by the same passion and commitment that have always defined us. I will miss you all deeply. Thank you for being a part of this incredible journey.” GB Daily Stay in the know! Get the latest news in your inbox daily Subscribe By subscribing, you agree to VentureBeat's Terms of Service. Thanks for subscribing. Check out more VB newsletters here. An error occured.",
    "commentLink": "https://news.ycombinator.com/item?id=40925471",
    "commentBody": "Girls in Tech closes its doors after 17 years (venturebeat.com)157 points by ushakov 8 hours agohidepastfavorite276 comments dang 6 hours agoAll: if you're going to post on a topic like this please make sure you're not just commenting out of reflexive activation. That's not what HN is for, as the site guidelines try to make clear: https://news.ycombinator.com/newsguidelines.html. On HN, we want comments that are thoughtful—i.e. that come from reflection, not reflex [1]; and specific—i.e. that have to do with what's different about a story, not what's generic. This is not particular to any topic; rather, it's an optimization problem: we're trying to optimize the site for intellectual curiosity [2], and these are corollaries of that. The trouble with reflexive comments is that they repeat responses that have already happened many times—rather as if they're being served from cache [3]. The trouble with generic comments is that the generic level is too abstract to say anything new or interesting. Put those things together and you get repetition, the arch-enemy of curiosity [4]. [1] https://hn.algolia.com/?dateRange=all&page=0&prefix=true&sor... [2] https://hn.algolia.com/?dateRange=all&page=0&prefix=true&sor... [3] This, btw, is why such comments always show up quickly. Cached responses are the fastest to arise! The kind of thoughtful comments we're looking for take longer to \"compute\". [4] https://hn.algolia.com/?dateRange=all&page=0&prefix=false&so... mikhael28 5 hours agoprevThere is an expression which I think is fitting, in a weird way - a successful marriage does not have to last forever. For some reason, we always tend to imagine that, once a company or organization is created, it must last forever. That for it to ‘close its doors’ or ‘wind down’ is somehow a failure. And that’s just not true; a professional athletes career does not last forever, and neither does the lifespan of most corporations or non-profits. The organization accomplished what it set out to do; make the tech industry more inclusive and accessible to women. To a large extent, though it wasn’t a primary factor, it aided that journey nicely with its thousands of events that it organized over the years, according to this announcement. It didn’t last forever, but it was never meant to - that would mean the presence of women in tech would never become truly equal to the presence of men. While its goal wasn’t ‘achieved’, this organization did what it could to move things in that direction and now, with its energy spent, it leaves the door open for new contributors to take the next step. The arc of history is long, but it bends towards justice. Thank you to everyone who helped organize the events this organization hosted in the last seventeen years. reply Melomololotolo 3 hours agoparentWhen I look around my peers, not a lot has changed in the last 10 years for woman in tech reply ilickpoolalgae 2 hours agorootparentI don't feel the same. The last decade or so has seen an explosion of women show interest in joining the tech community. Ratio's on teams I've been on has greatly increased throughout my career. I've been on several teams now where women have outnumbered men. In my experience, the ratio is now flipped when you look at the team as a whole (XFN, etc). I may be biased though as I've only worked at \"premier\" large tech companies and they are probably in a better position to do DEI at scale. That being said, true senior roles in engineering (VP+) is still very male dominated. Part of that is the pipeline catching up and part of is that I see women leave engineering for other roles more often. For example I would say, in my experience, I've seen more women have an interest and engage in transitions to PM, designer, etc. reply gizmo686 2 hours agorootparent> they are probably in a better position to do DEI at scale. Slight tangent, but most large tech companies DEI programs were never really great at doing DEI at scale. They were mostly funnelling the existing pool of diverse candidates into them. The result is that companies without an active DEI program end up less diverse through no fault of their own. reply leetcrew 2 hours agorootparentwhat is the mechanism for that \"funneling\" though? intentional programs to make diverse candidates feel more welcome? more money? if big tech is actively working to attract diverse candidates and other companies aren't keeping up, it doesn't sound like it's through no fault of their own that they can't retain those people. reply gizmo686 1 hour agorootparentCorporate DEI can be split into 3 broad buckets: 1) Recruitment 2) Retention 3) Sponsorship Retention improvements are generally a net positive for industry wide diversity. If someone leaves your company for harrasment reasons, they are more likely to leave the industry all together. Sponsorship is generally net positive as well. The funnelling I am talking about is entirely in the \"recruitment\" bucket. If you hire a woman software developer, they were already looking for a job. They already made a significant personal investment in getting the job. The industry is still enough if an employees market that they were probably going to get a job. You did nothing to bring that women into the industry. All you did is increase the chances that they end up working for you in particular. On the margins, this is still probably a net positive for industry wide diversity, but that is a much smaller effect then the chair shuffling effect. Of these three buckets, the most effective way of increasing your diversity numbers is in recruitment (unless you have horrid retention). In the current environment, there is no way for a large company to get anywhere near 50/50 without a significant investment in the recruitment bucket. reply jimbokun 1 hour agorootparentprevMore money. Smaller companies can't compete with FAANG salaries. So when FAANG prioritizes hiring women, and there are still many fewer women than men in tech overall, smaller and poorer companies can't compete with the offers women are getting from FAANG. reply pas 32 minutes agorootparent... sure, on the other hand way less competition, and smaller companies can also simply go ahead hire promising juniors and do on the job training. reply Jensson 26 minutes agorootparent> and smaller companies can also simply go ahead hire promising juniors and do on the job training. Not before FAANG hired the promising juniors first, FAANG are very willing to give on the job training. Or at least were a couple of years ago. reply jimbokun 28 minutes agorootparentprev\"way less competition\"? reply ilickpoolalgae 2 hours agorootparentprevThis may be true. As I noted, I've only worked at very \"desirable\" companies so my views are potentially skewed. That being said, I can't imagine that DEI has gotten significantly worse across the industry while vastly improving at the top end but I have no data to back that up. reply Jensson 2 hours agorootparentprevSounds like you went into more and more female spaces, as the field as a whole has barely changed, and if you compare to 20-30 years go it is worse. https://swe.org/wp-content/uploads/2023/03/Percent_WomenSTEM... reply jimbokun 56 minutes agorootparentDATA! Thank you! reply Volundr 2 hours agorootparentprev> Ratio's on teams I've been on has greatly increased throughout my career. I don't have data on this other than my own anecdata, so big grain of salt, but I think it's varies pretty widely by company and/or industry. In my last few jobs I've had several in which the engineering teams were overwhelmingly male, while in my current role it's more balanced. Further anecdata but in my most recent job search the engineers interviewing me were overwhelmingly male with only a few women. reply burutthrow1234 2 hours agorootparentprevIt's been a change in the past 10 years but I would say women are still systemically under-compensated, under-levelled, and encouraged to move into less prestigious roles like product, design, etc. The perception that women are better at \"soft skills\" means that we get pushed out of technical tracks into coordinating work, managing people, and sometimes just straight up babysitting male devs. Those career paths lead to lower lifetime comp and less \"impressive\" titles. reply riehwvfbk 1 hour agorootparentThere is a great book (written by a female engineer, Tanya Riley) called \"The Staff Engineer's Path\". I've learned a lot from the book, but one part of Tanya's experience that I could not relate to was having mentors who would encourage me and provide \"you can do this\" kind of pep talks. For a male engineer the usual experience is the opposite: we are expected to be competitive, and if we display any doubts then the only advice we'll get is \"are you sure you want this promotion enough?\" and \"are you cut out for this?\" It appears to be much easier to advance in one's career as a self-doubting woman than a self-doubting man. This is probably because women are expected to have a high degree of self doubt and there is no assumption that they are defective if they admit to it. And management is absolutely more prestigious and better compensated than IC work, despite what some may claim. reply jimbokun 1 hour agorootparent> This is probably because women are expected to have a high degree of self doubt and there is no assumption that they are defective if they admit to it. A simpler explanation is that there is a perceived need to increase the number of women in management positions. reply Aperocky 1 hour agorootparentprevMaybe better compensated, but not sure about more prestigious. I have no interest seeing the day to day of that job. reply ilickpoolalgae 1 hour agorootparentprevYMMV, but my experience is very different from what you mention above. Every company I've been at has paid very close attention to ensure that women are treated fairly with the understanding that these biases exist. But there's some truth to what you're saying. I do think women tend to be the \"babysitters\" on the team. I've noticed this often on teams I've been on. They're usually the ones that are the \"cultural heart\" of the team and organize all the events. Sometimes I've been their manager so I've asked and I'd say it's about 66/33 they legitimately enjoy doing it vs they felt pidgeon-holed into it because they volunteered once. As for the transitions into other roles, I think it's impossible to tell if it's bias and or a natural inclination. There's no way to look at the data empirically and determine this. In my experience though, I think women are often encouraged to take these roles not because there's a bias towards \"women are good at soft skills\" but that these are generally the roles that provide better career advancement and visibility. It has always seemed to be a somewhat mis-guided outcome of allyship. reply vundercind 2 hours agorootparentprevProduct is a lot more prestigious at most companies. Design is too, at quite a few, in that it’s often a better stepping stone to product, though that depends on the org. In general, programming jobs are low-status. High pay, but low status. reply brailsafe 1 hour agorootparentPeople like to think programming is a purely luxury job, and in some ways it is, but not compared to something where you often have more agency in the direction of a product. Programmers at lower levels probably take more bullshit and have less influence than anything with a title that conveys a higher level of abstract problem solving. Being a freelance website designer likely pays less but is more rewarding as a practice than being a random cog reply Kye 1 hour agorootparentprevPositives are diminished when the paths you wanted to pursue are closed off. Things that look like privilege when you don't have it can be a prison when you're stuck in its boundaries. reply Jensson 2 hours agorootparentprev> and encouraged to move into less prestigious roles like product, design, etc Women tend to seek out such roles all on their own, there is no encouragement needed. Just adding \"design\" to a job title massively increases how many women applies, even if the job itself is unchanged. Just rebrand software engineers to software designers and suddenly you get many women, even though they do the same thing. reply petsfed 1 hour agorootparentI wonder if the perception of engineering as a \"men's field\" factors into that. Like \"every engineering role I've ever had, I was condescended to by some other engineer who though he knew more than me because he was a man, maybe the culture is different around 'designer'\". Likewise for \"technologist\". More broadly, it seems to me that a lot of engineers' perception of inequity within their field basically devolves to \"well, there's nothing about the material that's sexist, I don't understand why more women don't want to do it\". It reveals a staggering lack of imagination and empathy, especially within a group that stereotypically was subject to a lot of bullying as young people. reply bwigfield 1 hour agorootparent>I was condescended to by some other engineer who though he knew more than me because he was a man In my experience this isn't \"because he was a man\" but because he was an engineer. And from what I've seen it also has nothing to do with you being a woman. Engineers tend to be condensing, and will do so indiscriminately. Or said different being \"condescended to by some other engineer\" means they are treating you equally, if you're not then you are getting preferential treatment. reply lyu07282 3 minutes agorootparentI think your comment is a good demonstration why this is still such an issue, despite the overwhelming evidence of gender based discrimination in tech, people are dismissing the experiences of the majority of women in tech. Can't really improve if people are still in denial about it. I don't know what to do, you can't teach people empathy or not to be sexist. Given how weirdly conservative young people are nowadays I don't see it getting much better in the future either. ygjb 2 hours agorootparentprevThat's a pretty bold claim to make without data to back it up. reply Jensson 2 hours agorootparentThe comment I responded to didn't have any data either, not sure why I'd need data for a similar kind of comment while they don't? The university I went to did that and they said it was to get more women, and easily got over 50% women into engineering fields just by adding design to the name of the degree. It is a well known trick, names matters. reply jimbokun 1 hour agorootparentprev> women are still systemically under-compensated, under-levelled, and encouraged to move into less prestigious roles Do you have actual data to support this claim? > into coordinating work, managing people So promoted into management. Are you saying managers are systemically making less than the engineers they manage? Which would be interesting, as management is generally seen as a more prestigious role than individual contributor. reply judahmeek 50 minutes agorootparent> Do you have actual data to support this claim? You can easily search \"women in tech statistics 2024\" and make your own conclusions. My conclusion is that the gender gap in tech is not completely resolved. reply anal_reactor 1 hour agorootparentprevAs a student I have personally experienced \"sorry, you cannot join the event, you're a boy we're looking for a girl\" and instead of me they picked a girl whose only job was to stand, smile, and tick the box \"yes I'm a girl, this makes the team diverse\". Having such an experience makes my brain heavily biased against all actions supporting gender equality. Which are many. And they're almost always about improving the position of women. \"Gender equality\" is rarely ever about improving the position of men. The social consensus is that it's impossible for a situation to exist where a man is discriminated against, and even discussing this idea is a very much taboo topic. Which is not true, because such situations exist, and the number of people who have this opinion but are afraid of voicing it is growing. I'm deeply convinced that a societal shift is on the horizon, and what we see as \"modern feminism\" will be, in the future, considered one of those things that aged like milk. The only question is whether this change will result in a society where people feel equal, or the pendulum will simply swing back and it's going to be taboo to discuss the hardships of women. This change isn't very visible in western societies yet, but we're starting to see it in South Korea. This movement is going to grow and spread. reply mixmastamyk 2 hours agorootparentprevManagement often leads to better compensation. reply thatsnotreally 1 hour agorootparentprevEngineers viewing design as a 'less prestigious' role is laughable. The compensation for these tracks is pretty much equal. I would love to hear you spell out why exactly you perceive design as less prestigious. reply ilickpoolalgae 1 hour agorootparentIn general, the compensation is much less than engineers at the same level but the potential for career growth beyond senior is much easier. reply thatsnotreally 1 hour agorootparentI would agree on the junior side of things. There is a higher threshold for the starting line for engineers, but for higher levels, design is by no means seen as a less prestigious role. Not in any sense of the word. For salaries – see e.g. levels.fyi for quick comparison. Even Google – a company not really known for valuing design that highly: SWE L6 avg. = 520K USD. Product Designer L6 avg. = 515K USD. reply makeitdouble 3 hours agorootparentprevFWIW remote work has opened the door to many women who would have left the field otherwise, so they might be less visible. It's still not great in my opinion, but I think there's more senior engineers and managers and an overall better situation than a few decades ago. reply lolinder 1 hour agorootparentThis is an effect of remote work that isn't discussed nearly often enough: it nearly completely removes any non-work-related \"culture fit\" filter from the equation for hiring and promotions. Without the happy hours, shared lunch breaks, or even the water cooler conversations \"fitting in\" isn't nearly as important remote as it was in person. This benefits everyone who struggles to fit in with the traditional tech bro class: women, but also the neurodivergent, the deaf, the blind, teetotalers, and many more who would otherwise end up subconsciously perceived as less of a team player. reply Aeolun 2 hours agorootparentprevThe only place I see/hear a lot of female devs is in India. In Japan the ratio might as well be zero. reply bookaway 1 hour agorootparentThe reasons for the numbers in the global south are different. It's not necessarily a preferred choice through empowerment, more so a profession taken up to propel oneself from poverty. reply commandlinefan 1 hour agorootparentprev> not a lot has changed in the last 10 years Then maybe what we've been doing for the last 10 years wasn't the right thing? reply matt_s 2 hours agorootparentprevEven though I feel similar and don't have any large data to look at, an unfortunate thought is that their efforts helped keep status quo. Or to put it another way, without that organization's efforts, things could have gotten much worse maybe? reply dangus 2 hours agorootparentprevWho are your peers and where do they work? What I’m getting at here is, maybe they're at stagnant companies that aren’t making a positive change. What I’ve noticed is that there are companies that care to be inclusive. It’s an active undertaking, not a passive one. I started my career working with all men in a toxic echo chamber, and now I’m on a team that is almost completely balanced. It’s also on me to not join teams that have a curious lack of women. E.g., if I interview with a DevOps team that had 10 people and zero women, there might be something wrong with hiring. Statistically there should be at least one or two. reply bookaway 55 minutes agorootparent>Statistically there should be at least one or two. Well, if the statistics takes into consideration the notion that a lot of women don't even apply to certain jobs thinking they're under-qualified should we be surprised if there are less than we initially expect? I appreciate the point of being proactive, since the point above can be somewhat mitigated by HR reaching out to prospects instead of relying on the existing applicant pool. But it seems everyone involved in the hiring process should be as convinced as you about the mid/long-term benefits of having women on the team, otherwise it's a uphill battle passing up perfectly acceptable candidates when there is so much work to get done. It's much easier when everyone believes that the X factor of having a women on the team far outweighs the delays and the accumulating negative effects of business in the short term. reply jimbokun 53 minutes agorootparentprev> Statistically there should be at least one or two. Of course not. Women make up a minority of people working in tech, and are highly recruited by the large companies able to pay the highest compensation. So it's very difficult for other companies to find women willing to work at the lower salaries they can offer. So there likely is a problem with hiring. They don't have enough money to afford hiring more women. reply Jensson 2 hours agorootparentprev> What I’ve noticed is that there are companies that care to be inclusive. It’s an active undertaking, not a passive one. That is a failure, you don't need to actively be inclusive if the problem is solved. See doctors for example, in my country kids ask if men can be doctors since they see them so rarely, the \"women aren't doctors\" thing has been solved, there is no need to do anything at that point except try to ensure it doesn't tip to the other side. > Statistically there should be at least one or two. That isn't how statistics works, statistically there would be 2-3, 0 is perfectly normal just by random chance. If you intentionally try to only join teams with more than average women then of course you see more and more women, even though the field as a whole hasn't changed. Edit: And given that SRE often have lots of on-call I'd bet there are much less women there than regular SWE roles. Men tend to be over represented in roles that sacrifices free time. reply scottyah 1 hour agorootparentprevI've heard a lot of women say they won't join a team with only men. Not exactly the most productive feedback loop. reply RIMR 3 hours agorootparentprevMy thoughts exactly. It's one thing to close your doors feeling like you made a difference. It's another thing to close your doors feeling like you have just as much you need to do as you did when you started. reply badgersnake 5 hours agoparentprevShe says she’s closing it “with a heavy heart”. It sounds like she wanted to continue. reply ganoushoreilly 4 hours agorootparentI could read it as either way. It could be a sadness to see it come to and end, but still having full agreement the time has come. It could also be a sadness because financial hurdles or other operation hurdles are making it near impossible. It's hard, but I get it either way. reply RIMR 3 hours agorootparentYou could read it that way, but she said \"with sadness and devastation\". You are taking some extreme liberties with your interpretation of what she's saying. The sentiment she's sharing is clearly quite negative. I don't think she's happily wrapping up her mission, I think she's going out of business and has no ability to continue her mission as she would like to. reply mrguyorama 2 hours agorootparentWe can still view operating for 17 years to be a success. We can still view helping women in tech for 17 years to have improved the world, even if it cannot continue. reply pessimizer 1 hour agorootparentWe can consider winning one basketball game a success even when our team is disbanded after one season, but I don't know how that's relevant to whether someone is devastated about closing a group down that was meant to help women, when women still need to be helped. reply resource_waste 4 hours agorootparentprevI had a similar thing happen to me. I did science and posted it on my blog. It helped a few million people, but I didn't monetize very hard. I hated people would call it blogspam, despite it being science and it being donation based. I switched to b2b. I'm happy there are people who use business to make the world a better place. I'm never doing that again, profit first. reply autoexec 1 hour agorootparentprevYeah this terrible article doesn't explain why it's shutting down and doesn't link to the source (a newsletter I guess, so maybe it's not available online) so people can find more answers, but I also go the impression that this wasn't what she wanted. reply muglug 5 hours agoparentprevThis was my attitude when I stopped maintaining a large open-source project that I had created. None of us last forever, in life or even just in this industry. To have brought about some sort of positive change is more than good enough. reply gramie 5 hours agoparentprevIn fact, we consider a marriage successful if it ends in the death of one of the partners. reply mikepurvis 4 hours agorootparentThere are lots of possible definitions for success— making it until death parts you is the obvious one, but \"success\" can also be producing fruit in terms of community, family, or even career. And there are of course marriages that make it until death, but the partners and everyone around them spend the whole time miserable; that's hardly a success either. reply microtherion 5 hours agorootparentprevThat's certainly a theory that Bluebeard would subscribe to. reply mikhael28 4 hours agorootparentI learned something new thanks to your comment - never heard the story of Bluebeard before. reply xattt 3 hours agorootparentprevQualifier to the GP poster is not deliberate… reply CalRobert 1 hour agorootparentprevIs this still true? If I knew a couple that had a great ten years but then decided that it was time to part ways on friendly terms for whatever reason, maybe continue being great coparents, I'm not sure I'd consider it unsuccessful. reply DonHopkins 1 hour agorootparentprevMaybe that's that Hans Reiser thought, but an amicable divorce also has its advantages. reply TrueGeek 5 hours agoprevBetter article with more information: https://www.bizjournals.com/nashville/news/2024/07/08/girls-... > In an email Monday, founder and CEO Adriana Gascoigne said “Girls in Tech will be closing its doors due to a lack of funding in 2023 and 2024.” reply neilv 4 hours agoparentThanks. Following a link from there: https://www.bizjournals.com/nashville/news/2024/06/06/girls-... > Nashville-based Girls in Tech Inc. may be forced to shut down by the end of summer. [...] needs to raise $100,000 or it faces imminent closure. [...] Girls in Tech has a membership of 130,000 \"women and allies\" across 50 cities and 38 countries. Was the membership base already tapped out, or the org didn't reach out to the membership on this, or the org had larger near-term funding needs than the immediate $100K? Also, is it possible that funding isn't the only consideration? For example, even if the org could be saved with heroics, there's opportunity cost to leadership (personal, professional)? reply michaelt 3 hours agorootparentWell, they seem to offer a \"premium membership\" for $9.99/month [1] and presumably that hasn't raised enough. If the aim of the charity is to get career resources in front of as many women as possible, they probably don't want to put their most impactful resources behind a paywall - that would be contrary to their goal. I suppose they could try an appeal to generosity instead? Depends if they've got a network of grateful people they helped 17 years ago who are now making six-figure salaries. [1] https://girlsintech.org/membership/premium/ reply neilv 2 hours agorootparentI know almost nothing about non-profit fundraising, but this benefits tier membership model looks very familiar as a tech for-profit service, rather than a charitable non-profit for the benefit of all. (Specifically, in a tech, like a SaaS, the free tier are sales leads and inflated \"market share\" numbers, and the premium tier are the real customers of the service value you're providing and is your whole reason for existing. In a charity, however, you don't measure out benefits based on how much that person is paying you. Though a charity will have special recognition for exceptional donations, like the donor's name listed on some page, or mentioned as a sponsor of an event.) Given the dire runway situation they were in, I wonder whether they sent out a recent urgent appeal to their free-tier, as more like a charity, asking for donations? (And if so, was the obvious benefits tier model hurting any charitable goodwill they might've otherwise generated?) Or did they try to push their free-tier members an upsell to their premium tier, like a business? Or neither? reply bookofjoe 1 hour agorootparentprev130,000 members x $1/member = $130,000 reply specialist 2 hours agorootparentprevLike many orgs, probably, their funding model was working, and then got hammered by COVID-19, and were stuck holding on, hoping for return to \"normalcy\". It's very hard to pivot. Fund raising costs money. Some one needs an idea, a plan, a strategy. Everyone needs to agree to it. Meanwhile, an org's (remaining) execs and board members are doing triage. To execute a new plan means even more work. And so on. I've met and worked with terrific fund raisers. For me, personally, fund raising is just the worst. I've done enough to know a) it's very hard and b) I suck at it. reply igor47 5 hours agoparentprevHuh. You'd think all the organizations that attribute their challenges in hiring non-male engineers to a \"pipeline problem\" would've spent a small fraction of their recruiting budgets helping to fund Girls in Tech... reply csande17 4 hours agorootparentFor what it's worth, Girls Who Code -- an organization more directly focused on improving the \"pipeline\" through training programs aimed at K-12 and college students -- seems to be thriving, with over $20M in donations from a variety of tech organizations in 2023: https://girlswhocode.com/2023report/ reply darth_avocado 3 hours agorootparentOur company actively partners with girls who code for that exact reason. Our rather empty post covid office space gets transformed into summer boot camps for middle and high schoolers every year. It is a very productive way to improve the K-12 pipeline. reply shmatt 3 hours agorootparentprevthis deserves to be much higher than a sub-sub-sub-sub comment the fact one DEI organization failed doesn't mean DEI failed. They could be mis managed just like any other non profit reply arduanika 1 minute agorootparentAgreed, I didn't know the difference and at a glance thought it was Girls Who Code that folded. It could be that as the \"vibe shifts\" away from DEI and the funding gets smaller, we'll see a culling where only some orgs survive, hopefully the best ones. \"When the tide goes out...\" falcolas 4 hours agorootparentprevThat would require an monetary investment into DEI, which has become a negative investor signal for many large companies. It's a shame, because I've met several developers who benefited from Girls in Tech's work. reply em-bee 3 hours agorootparentmonetary investment into DEI, which has become a negative investor signal for many large companies can you please explain that or point to some articles about it? reply runako 3 hours agorootparenthttps://www.shrm.org/topics-tools/news/inclusion-equity-dive... https://www.axios.com/2024/04/02/dei-backlash-diversity etc. There is a backlash underway against any effort to expand workplace diversity beyond the representative fractions circa 1990. reply Jensson 1 hour agorootparentWomen were a much higher percentage in the field 1990. Women abandoned the field after the IT-bubble and it never recovered. reply gadflyinyoureye 1 hour agorootparentprevThere is a backlash to the heavy handedness of DEI. You can’t freeze out white males simple because they are white males. You need to remove barriers to entry based on sexism and such, but you can’t exclude a whole large class of people because that class had it good in the past. That gets you South Africa. reply strikelaserclaw 4 hours agorootparentprevonce interests rate went up all DEI initiatives dried up - these companies don't really have integrity or beliefs beyond doing what is politically correct at the current time. reply jimbokun 47 minutes agorootparentAlmost as if they are organizations formed around the goal of optimizing profits, and not the general benefit of society. reply IncreasePosts 3 hours agorootparentprevWhy would rising interest rates affect what is considered politically correct? reply travisb 2 hours agorootparentYou can read \"politically correct\" as \"politically fashionable\". When money is cheap it's easy to spend a bit of money on political signalling. However when money is no longer cheap that pure cost centre is the first on the list for cuts. reply micah94 2 hours agorootparentprevBorrowing money becomes more expensive so companies will focus on their own needs (or surviving) rather than giving or outreach programs. Unlike Apple or NVIDIA most companies need to borrow money to stay in business. reply sangnoir 2 hours agorootparent> Borrowing money becomes more expensive so companies will focus on their own needs (or surviving) rather than giving or outreach programs. All the (Big tech) companies - not just Apple and Nvidia - have higher revenues and profits now than they did during the Zero-interest regime. They are not hurting for money to fund outreach programs that meet their strategic goals. What has changed is their hiring outlook. Online services saw unprecedented growth when everyone was cooped up in their homes due to Covid lockdowns, and the tech companies thought the growth would be permanent, rather than a temporary bump, and couldn't hire engineers fast enough to meet the anticipated growth: hence the outreach to non-traditional hiring-pipelines. After the layoffs, they stopped hiring aggressively and the labor market is now a buyers market reply s1artibartfast 2 hours agorootparentprev>Unlike Apple or NVIDIA most companies need to borrow money to stay in business What do you mean by this? reply DopplerSmell 4 hours agorootparentprevNobody inside the org cares about gender ratios, but they do have to react to people outside of the org who care a whole lot. It's easier to explain reality than to try and change it. reply resource_waste 3 hours agorootparentIdk, I've read b2b contracts that have demands similar to this. They arent explicit, its softer. reply bdjsiqoocwk 4 hours agorootparentprevIf the problem is solved, the funding disappears. reply digging 4 hours agorootparentThat would be a complete success, since the funding disappeared anyway reply mattmaroon 1 hour agoparentprevThat’s a bummer I was hoping it was more of a “mission accomplished” kind of closure. reply specialist 2 hours agoparentprevFunding for many, many worthy orgs crashed with COVID-19, and has barely recovered. From the outside looking in, it seems the whole administrative capacity (ecology) of the fund raising world just dried up and needs to be rebuilt. reply glitchc 5 hours agoparentprevTop comment, this is the cause. reply elric 1 hour agoprevThis is such a difficult topic. When I started my undergraduate in CompSci, the department of 300 students had exactly 3 women. The faculty had way more female instructors than it did students. The Commucation Sciences department, which was on the same campus, had the inverse student population. I'm all in favour for letting students making their own study (and career) choices, but when the imbalance is this great, I can't but help think that valuable perspectives are lost. And that's just looking at the sexes, that doesn't even take into account what could be gained from interacting with folks with different socio-economic backgrounds, who were equally underrepresented. Trying to keep barriers for entry low seems worth while. Organizations which help people break into non-traditional fields (for their background/sex/whatever) also seem to be worth while. Funding them seems like a no brainer. This isn't limited to girls in tech. Also boys in nursing, poor kids in law school, brown kids in politics, whatever. reply jimbokun 1 hour agoparentYou seem to have very little curiosity into WHY those ratios are so skewed. It's impossible to change these distributions without understanding the underlying causes for how they got that way. reply elric 58 minutes agorootparent> you seem to have very little curiosity into WHY those ratios are so skewed That's a weird take. How would you know what I'm curious about? Pardon the strawman, but I'm not interested in handwavy explanations which tend to border on bigotry (\"$category simply isn't interested in $topic\"). I suspect the fundamental reasons are myriad and complex, but that doesn't mean $field wouldn't benefit from more diversity. > It's impossible to change these distributions without understanding the underlying causes for how they got that way. Maybe, maybe not. The ratio is certainly a lot less skewed now than when I was a student over 20 years ago. My understanding (or lack thereof) certainly didn't have an impact, but throughout my career I have always tried to be supportive of people who are in some way different from me. Heterogeneity is a good thing. Monocultures result in weakness. reply jimbokun 22 minutes agorootparent> (\"$category simply isn't interested in $topic\"). First link that came up in my Google search: https://www.psypost.org/women-like-working-with-people-men-l... It is almost certain that differences in interest play a large role in the different distributions of men and women in different occupations. The studies showing this are well known and I have not seen them debunked. Please note that labelling a claim with strong backing in empirical evidence \"bigotry\" does not magically change reality to conform with what you would like it to be. You need to produce actual evidence to the contrary. reply Sinthrill 40 minutes agorootparentprevThey can tell you aren't a curious person from your use of punctuation. This is why I always add ;`'([] at the end of every sentence ;`'([] reply commandlinefan 1 hour agoparentprev> Trying to keep barriers for entry low But the barrier is already low - you need to complete an undergraduate degree in a related field. That's it. reply ZoomerCretin 1 hour agoparentprev> Trying to keep barriers for entry low seems worth while. With Section 174 (increasing business taxes on SWE salaries) + high interest rates, this is a big ask for US employers who loath hiring at the entry level in the best times. To me, the real problem seems to be solving US employers' unwillingness to hire anyone without experience, after which the rest (hiring underrepresented groups) will follow. But why would they do this when they have all the experienced and senior engineers they want? Is this not the exact problem DEI was created to solve, and is now being dismantled? reply cat_plus_plus 3 hours agoprevJudging by current distribution of interns, coding is becoming a female dominated field. I think this has more to do with pragmatic mindset of asian parents and less with any DEI efforts. How many other fields: - Are not dangerous or unreasonably physically strenuous - Pay good money - Keep you surrounded by respectable, educated people - Can be mastered in 4-6 years rather than running risk of getting old while still in college Not saying it's a negative, those are rational factors. We do need to make sure that young men are also able to become successful and equals of female SWEs. reply rsanek 2 hours agoparentlatest data still only has them at 21% of cs graduates https://ngcproject.org/resources/stem-statistics-higher-educ... reply Sohcahtoa82 2 hours agorootparentThat would be an improvement over my anecdata of my final project class for my CS degree in 2014 having ~30 men and exactly two women. reply Jensson 2 hours agorootparentThen your class had lower than average women for the time. The overall numbers hasn't changed since then. reply deathanatos 1 hour agorootparentThe numbers here are \"and mathematical scientists\"¹, so it's not (as upthread implies) CS grads, it's CS grads + other studies. I lived with a physics major; she did some code, would she have been counted?², but she was not a SWE in the making³. My gut would not think other math degrees would necessarily be more women heavy. But like upthread, my class was 2 women in a class of ~160, orAny class with sub 10% women is a big outlier. You claim, but what is being asked for here is evidence to support such; Occam's razor implies that not only should it not be, that it would be an outlier in the other direction. Hence the desire for something that lays out its methodology well enough that we can tell that it's not in that lovely third category of \"statistics\". [1]: https://www.aei.org/carpe-diem/chart-of-the-day-the-declinin... [2]: https://nces.ed.gov/programs/digest/current_tables.asp reply footy 2 hours agoparentprevThis is interesting to me, because it runs so counter to my own experience with young/early career developers. I run into more female devs close to my own age than younger (relative to male developers specifically). reply Spivak 3 hours agoparentprevWhere? The experience of being the only woman in your math/cs class doesn't seem to have changed among the women we interview. Is it the non-uni \"bootcamp\" path? We don't get very many of them for whatever reason around here. I imagine because our in-state college is both good and affordable but obviously can't prove that. reply chx 1 hour agoparentprevhttps://swe.org/wp-content/uploads/2023/03/Percent_WomenSTEM... reply dpoljak 5 hours agoprevThe reasons for closing haven't really been elaborated on, just commented on as sad and devastating; I haven't managed to glean anything more from the rest of the article. However, it's incredible to me to keep an organization like this going for 17 years. The landscape is constantly shifting and looking back at the world and technology from 2007, and even 2014, they've survived a lot. Going down now just shows how bad the market is in reality. reply itsoktocry 4 hours agoparent>However, it's incredible to me to keep an organization like this going for 17 years. Exactly. Say what you want about the state-of-affairs today, imagine what the women in tech landscape looked like almost 20 years ago! I'm sure they accomplished a lot, and that's awesome. reply netdevnet 4 hours agoparentprevHow is them going down related to the market? They are a non-profit. This is pure speculation but I would imagine that they reasons for closing are likely resource related (most likely financial) as organisers and managers can be replaced reply jmull 4 hours agorootparentI would guess they get most of their funding from tech companies who support and participate in their programs. reply netdevnet 4 hours agorootparentThat makes sense reply bell-cot 4 hours agoparentprev> However, it's incredible to me to keep... THIS. In feel-good daydreams, every nice-sounding thing lasts forever. (Generally with Imagined Good People Somewhere(tm) paying the bills.) Vs. in the real world? - I'd guess that they outlasted >99% of tiny tech non-profits founded in 2007. And >95% of all non-profits founded then. reply tristor 2 hours agorootparentThey outlasted most of the tech companies founded in 2007, not just the non-profits. The average life span of a tech startup is 5 years. reply Molitor5901 6 hours agoprevJust skimming the 2022 990, executive compensation was $285,170. Total expenses $1,904,475 on $2,005,994 in revenue. reply asah 5 hours agoparentUnfortunately this is normal, because running a non-profit is hard enough that suitable candidates command high salaries. I was on an NPO board with a similar ratio and we couldn't get it down. reply bitcurious 5 hours agorootparentThat comp $ is very reasonable in the abstract, what's not reasonable is comp:revenue. You can't be paying 15% of your revenue to a single individual, because almost by definition they aren't performing well enough to justify that salary. reply crazygringo 2 hours agorootparentThat's not necessarily true, because revenue can be a poor measure of capturing value and scale in organizations that are mostly volunteer. If that individual is managing the process of successfully getting 1,000 people who volunteer 15 hrs/wk, which you'd otherwise have to pay let's say $30/hr including taxes, then that would be the equivalent of $22.5 million in annual revenue. Suddenly $285K in executive compensation looks perfectly fine. In some mostly-volunteer organizations, you will find that most of the money pays the professionals at the top, because you can't get that necessary expertise any other way. I worked at one once right out of college, at the bottom of the full-time-paid rung, and I had interestingly conflicted moral feelings about it. I spent a lot of time with volunteers and yet I was being paid. But I needed a job, I needed to pay rent. And the tech skills I was providing literally none of the volunteers could do. It made me question whether it was \"fair\" that all these people's monetary donations were going to paying my salary. But then again, I wasn't the one who set rents to be as high as they were in the city where the organization put its headquarters, and student debt doesn't get forgiven just because you work for a nonprofit. reply pbronez 4 hours agorootparentprevEven when that person is the founder? Who created the thing and keeps it going through personal force of will? Doesn’t seem unreasonable to me. You want high quality people to be able to focus full time on stuff like this. reply Workaccount2 4 hours agorootparentEspecially when that person is the founder lol reply jrockway 2 hours agorootparentprevI mean, she would make 3x more than that just being a software engineering cog in the machine. To me, a salary of $200k for this position looks like donating $400k a year to it. Plus your time. That seems pretty generous to me. reply nothercastle 5 hours agorootparentprev300k isn’t crazy especially in SF that s not going up get you far reply lenerdenator 5 hours agorootparentPerhaps we should stop concentrating so many opportunities in areas with exhausted resources that are needed to host an economic sector. reply randomdata 2 hours agorootparentBuyers are free to choose to buy from the company in Poducksville instead, but I suspect that, in the typical case, they'll never learn about said company because it takes strong network effects to get things off the ground. reply lenerdenator 1 hour agorootparentEvery ecosystem - economic, ecological, or otherwise - has a carrying capacity. The SV/NorCal area is reaching that capacity. There are only so many dollars customers are willing to pay to get a quality product, service, or charitable act before the law of diminishing returns kicks in, and those dollars are what funds the compensation packages of both profits and non-profits. There is no infinite well of value (no matter what capitalism says), which means that there is a ceiling on things like salary and the things (namely residential real estate) that said salary can buy. If you pay a person $300k to do a job because that's what the local job market dictates in SV, are you really getting the surplus value to cover that salary? Can you keep charging customers that amount? Will you do increasingly alienating things that causes negative externalities (read: regulation) to be passed that impact your business model's ability to pay that much? You could very well be better off to hire someone at the $150k rate in a place like Kansas City or Minneapolis. Those aren't \"Poducksville\" but that's the competition the valley will begin to see. reply nytesky 5 hours agorootparentprevDoesn't CEO and non profit operate out of Nashville? reply giancarlostoro 3 hours agorootparentEven so, I'm assuming this isn't like a normal job where you have benefits, if they're paying for all of that out of pocket, the salary makes perfect sense to me. reply hiatus 3 hours agorootparentWhy would you assume that? If you are company over a certain size (even a non-profit) you are obligated by federal law to offer health insurance. reply giancarlostoro 3 hours agorootparentAre they large? I've not heard of them. It has 130 thousand members, but that doesn't mean they're all employees? reply hiatus 2 hours agorootparentThe law requires only 50 employees. I am not sure of their number of employees though. reply uberman 29 minutes agorootparentA 501(c)3 requires at least 50 employees? That would surprise me if it was true. reply s1artibartfast 1 hour agorootparentprevCertainly less than 50 with revenue of 2m and expenses of 1m. reply uberman 1 hour agorootparentprevThey were based in Tennessee when she made $280k. When they were based in the bay area, she made just shy of $370k. reply giancarlostoro 3 hours agorootparentprevAlso not considered in that amount is the fact that this person has to pay for benefits (healthcare and such) likely directly from this income. This is insanely low when you really think of that. reply uberman 1 hour agoparentprevJust going to note that all of that was one person's salary. I question why a smaller non-profit based in Tennessee would need to pay their CEO almost 300k. Senior researchers where I work make half that while managing grant projects with twice the funding. reply kelseyfrog 3 hours agoparentprevQuestion about the 2022 990 schedule b part 1. The contributors No./amount is restricted. What does this mean? Is it common? reply matrix87 1 hour agoprevJust fyi, Supreme Court has an upcoming case on affirmative action https://www.nytimes.com/2024/07/02/us/affirmative-action-law... reply callalex 2 hours agoprevFrom my Bay Area perspective, Girls who Code is still going strong and doing great work. Any reports that all diversity initiatives have died are greatly exaggerated. reply shrubble 6 hours agoprevNon-profits closing means there is a financial reason; were there grants monies that ran out? Did another \"women in STEM\" non-profit get corporate sponsorship instead? The article doesn't say. reply Hasu 6 hours agoparentThe (economic) purpose of Girls in Tech is to create more workers in software so that prices for labor will go down. Given the layoffs of 2022-ongoing, labor costs in tech are dropping enough that interested parties aren't incentivized to increase the supply of labor further. reply netdevnet 4 hours agorootparent> so that prices for labor will go down. I don't think that's the reason (it is a side effect though). What makes you think that? reply randomdata 3 hours agorootparentWhy else would a buyer invest heavily in increasing the supply? reply jrockway 2 hours agorootparentI think that companies think they can make $X with 10 engineers, but > $2X with 20 engineers. Thus, allowing more people to be comfortable as a software engineer increases the amount of money they can make. Right now, with 6% interest rates? Nobody wants to make money that badly. But it won't be that way forever. reply randomdata 2 hours agorootparentThat is a fair thought, but, of course, depends on a constant (approximately) per-unit labour cost. After all, businesses could poach those 10 additional engineers from the company beside them with a $2Y compensation offer, without the need for any more engineers. But if you need to pay 2x more for each labourer to achieve $2X gross return then the appeal is quickly lost. However, if you can create 10 new engineers that didn't exist before, then they will be incentivized to fall in line with $Y as well, lowering the unit cost of labour and making adding 10 more engineers to achieve $2X in return much more appealing. The keeping of the price of labour down is exactly why businesses were willing to make such investments. reply RIMR 3 hours agorootparentprevI like that we're not beating around the bush and admitting that businesses only donate money to causes they think will financially benefit them. That there are no altruistic actions by a business entity, everything is either an operational expense or an investment. This is 100% true in practice, so you're absolutely correct here. I just hope that we're in agreement that this is a bad state of affairs if businesses have completely written off doing the right thing in favor of profit 100% of the time. As a community of entrepreneurs, we should aim higher. If this is the only reason that tech companies invest in gender equality, then we need to find better advocates, or at least come prepared to counter the exploitation the current advocates have in mind. reply klyrs 1 hour agorootparentCounterpoint: a cynical take posted deep in a comment thread in a random corner of the internet may not accurately reflect the values of an entire industry. reply jimbokun 41 minutes agorootparentprevHuman nature. reply strikelaserclaw 4 hours agorootparentprevbecause most of these companies are (run by?) sociopaths - as soon as low interest rates dried up DEI initiatives got slashed even though these companies are still making record profits. reply JKCalhoun 5 hours agorootparentprev> interested parties aren't incentivized to increase the supply of labor further It's good when a profit-driven industry decides to stop trying to cut expenses. reply autoexec 1 hour agorootparentAlso unlikely. reply pydry 5 hours agorootparentprevFor the corporate donors, sure. Im sure the people running it were genuine though. reply csomar 5 hours agorootparent> Im sure the people running it were genuine though. The people running it are getting paid to run it. It's a job. There are few people who do charity for charity but for most people I met working for non-profits, it was just a job for them. Doesn't mean they didn't love their work or did their best but at the end of the day they need a pay check like everybody else. reply mdgrech23 5 hours agorootparentprevThere was a bootcamp by me. They had a squeaky clean image but were getting big payouts from placing candidates in a local fortune 500. People get used to that money. reply nsonha 5 hours agorootparentprev> so that prices for labor will go down wut? Any one creating anything is DELIBERATELY driving price of that thing down for you I guess. reply randomdata 5 hours agorootparentYes, anyone who deliberately increases the supply of something does so in an effort to diminish the price of something. reply muglug 5 hours agorootparentThe creation of computer science degree courses did not push down the price of software engineers. reply flyingfences 5 hours agorootparentThe popularization of computer science degrees absolutely did push down the price of software engineers on average. The Big Names in SV are outliers; the rest of the industry employs us at wages far closer to other professions than they could a generation ago. reply busterarm 5 hours agorootparentThis. People really do forget what it was like just before the peak of the dotcom bubble. There were companies that offered perks like a fully paid lease on a brand new Porsche 911. This wasn't just for the software engineers either. If you could breathe on a keyboard, you could land a high-paying job. Demand was that high. That era of tech minted way, way, way more millionaires on average. reply netdevnet 4 hours agorootparentSurely, we can all agree that this is not sustainable. Companies basically throwing money at people that might not have the skills you need is a massive waste of money from the companies point of view. reply busterarm 4 hours agorootparentNobody was talking about whether or not it was sustainable, we're just comparing salary potential now to a generation ago. To the managerial class, tech people used to be literal wizards conjuring the impossible and now we're regular commoditized office labor like any other. reply netdevnet 4 hours agorootparentNot sure if comparing salary potentials coming from two different socio-economic periods is useful or likely to mislead. Tech and people versed in it were not common (to people outside tech) and so the high salaries would reflect that. Now is not the case. It was always going to be temporary. As people become acquainted with tech people, the magic vanishes, you see the code behind the pixels. At the same time, tech people themselves did cause this by making tech easier to understand and manipulate. It's like a magician, the first few times, it is enticing and mysterious but after a while it becomes ordinary. Tech wizards are just like that. reply busterarm 4 hours agorootparentPeople with wizard-like skills are out there but typically can't command the salaries they used to. Todays SWEs tend to know far less about how computers operate and how protocols work than in the old days. reply netdevnet 4 hours agorootparentThe reality is that thanks to those tech wizards, most companies don't need tech wizards to build tech products and most tech workers don't need to know anywhere near as much as you would need to back in the days. The same kind of \"I just love to code\" tech wizard that builds an amazing service/library/product, overworks itself while letting big companies extract max value out of it and contribute nothing or extremely little to the open source world. Every day I think of the Homebrew creator who got rejected by the company that uses his software daily. This should be in the mind of every dev imo. Tech wizards wrote their fate on code, compiled it and served it to the market. This is the result reply randomdata 4 hours agorootparent> Every day I think of the Homebrew creator who got rejected by the company that uses his software daily. This should be in the mind of every dev imo. To be fair, he does not come across as the kind of person you would want to work with, no matter what kind of software he is able to produce. Once hired, others actually have to work with him in such companies. In fact, Apple did end up hiring him soon after said rejection but quickly determined he wasn't a good fit there either. No wizard is worth having by your side if they make your life miserable. reply kortilla 3 hours agorootparentprev>Every day I think of the Homebrew creator who got rejected by the company that uses his software daily. Why does this surprise you? Google didn’t even employ the chefs that made the food consumed by the employees daily either. Just because you made a thing that was useful doesn’t mean you have the skills that Google is looking for. Homebrew was very useful because Mac osx didn’t have a good package ecosystem for one-liner installs. The tech behind it though wasn’t particularly unique or groundbreaking. So the author’s skill here was finding a market with unmet demand for a free package manager. That’s not what Google was looking for. reply Workaccount2 4 hours agorootparentprevThe SWE buzz/boom of the last teens into the early 20's was largely fueled by VC's with access to tons of capital at all time low prices. The game was build a company with a shiny exterior and a radiance of hype and hope it got bought out. It didn't matter that you were burning millions on exorbitant salaries and endless perks. It was the cost of shine and radiance. And it drove up the cost of tech labor across the whole sector. In a really condensed and simplified version: Big money was placing $50-100MM bets everywhere because the house was lending for basically free, and you only need a few hits to come out on top. But now that money is expensive again, they game has been crashing down. reply silveraxe93 5 hours agorootparentprevYou're on a boat with a hole in the bottom. The water is rushing in. You grab a bucket and keep scooping water out, but not as fast as it rushes in. Throwing water out of boats do not make it more buoyant. reply simplicio 4 hours agorootparentprevI mean, that's the effect of increasing the supply, but I doubt its the motivation for most people. reply randomdata 3 hours agorootparentIt is the motivation when the buyer tries to stimulate expansion of the supply, per the topic at hand, though. reply AnimalMuppet 5 hours agorootparentprevNonsense. Almost everyone who deliberately increases the supply of something does so in an effort to get paid for creating more of that something. Diminishing the price is at best an unintended second-order effect. reply AmericanChopper 5 hours agorootparentprev> After all, that's why the opposite situation: Collusion – where actors try to deliberately limit the supply of something, thereby causing price to rise – is illegal. Unless they’re a union. reply grobbyy 5 hours agoprevAt the risk of posting a reflexive comment, what should we be doing here? It seems like everything has unintended consequences (not on a cost-benefit basis): - Minority affinity groups pull people from majority groups and decrease integration. - Anti-discrimination/sexism/etc. movements often add social barriers to interactions (e.g. things I do within my identity group would be misperceived if done across) - Affirmative action makes minorities feel like they don't deserve to be there (and often leads to resentment and other consequences) Progress in the past few decades has been limited, so it seems like we're taking the wrong approach, but I'm don't have a better approach to propose. Green fields, blue sky, what should we be doing to resolve the historical issues we have around sex, race, socioeconomic status, etc.? I think looking to countries which made better progress might be helpful.... reply next_xibalba 5 hours agoparentI have seen data presented multiple times showing the relation between a country’s wealth and/or economic freedom and women’s participation in stem fields. It’s a negative correlation. I often wonder if we should just be focused on maximizing individual freedom and let the chips fall where they may. This will result in some professions with extreme sex imbalance, and we should accept that outcome. reply cultofmetatron 4 hours agorootparent> I have seen data presented multiple times showing the relation between a country’s wealth and/or economic freedom and women’s participation in stem fields. This lines up with my experiences as well. I know plenty of eastern european women, asians and latinas working as programmers. on top of that I've talked to many that didn't know how to code but would ask me to teach them as soon as they heard I was a programmer. yet I have met only a small handful of white women from america that are software engineers. furthermore, the ones that aren't engineers (in general) seem more dismissive of my line of work as if its somehow beneath them. reply Der_Einzige 3 hours agorootparentIf those folks from outside of the USA had been from economically prosperous backgrounds, they too would try to become nurses or caregivers instead of programmers. Gender parity in STEM is a sign of the economic desperation of a countries people. This is a sociological fact which ruffles feathers when it’s stated out loud. reply callalex 2 hours agorootparentDo you have any citations to back up this “fact”? reply rsanek 2 hours agorootparenttake a look at the gender breakdowns for employment in the Nordics. probably the best social support structures / 'equality' in the world, and yet the ratios are among the most extreme anywhere. when you're taken care of, you do what you like. when you have an economic need, you'll take the job that pays and will pull you out of poverty, even if you don't care for it. reply jimbokun 36 minutes agorootparentprevI believe affinity of boys for interacting with \"things\" and affinity for girls for interacting with \"people\" has been demonstrated pretty well in studies. (This falls into category of \"something I read on the Internet\") reply itsoktocry 4 hours agorootparentprev>This will result in some professions with extreme sex imbalance, and we should accept that outcome. We do accept it, for the most part. I don't see many Men-as-Teachers or Men-in-Nursing advocacy groups. reply simplicio 2 hours agorootparentThere's a lot of Men-in-Teaching advocacy, in part because its thought having male teachers tends to be beneficial for male students[1]. I think stuff like that is the main reason to be worried about gender imbalances. A 40-60 imbalance probably isn't a big deal, but once you get to like, 90-10 or worse, as is the case with early education, you start to get a bunch of secondary social problems. Kids who associate learning as a woman only thing, or the culture around engineering or software becoming \"boys clubs\" that become uncomfortable for the women who do want to work in those fields https://www.cuny.edu/academics/academic-programs/teacher-edu... reply jimbokun 34 minutes agorootparent> There's a lot of Men-in-Teaching advocacy There are pundits saying this should be supported. Are there programs with real dollars behind them making actual changes? reply cultofmetatron 4 hours agorootparentprev>or Men-in-Nursing advocacy groups. thats been changing. mostly because there are more obese people now so you need male nurses to help them move around. reply Der_Einzige 3 hours agorootparentOzempic solves this problem in 10 years. reply goalonetwo 3 hours agorootparentprevThat's because their woman advocacy is really a not-so-hidden lobby to have woman making more money under the pretense of equal representation in all jobs. reply KittenInABox 3 hours agorootparentprevThere's literally an American Association of Men In Nursing. Just googling \"male teachers\" gives me a ton of articles about the importance of hiring more men in teaching. Apparently NYC recently announced a huge investment into hiring more black/latino men in teaching or something? I'm always suspicious of \"you don't see much of x\" in spaces where x isn't the demographic being catered to. This isn't Nursing News or Teacher News, not to say that Nurses and Teachers can't also be hackers, technologists, etc. but this is clearly not a space oriented towards all things teaching or nursing, so questioning community advocacy within their communities strikes me as the wrong place. reply marcosdumay 1 hour agorootparentprevThe idea that social sciences can pinpoint a single cause on something as full of confounding factors as this... it's extremely arrogant. But then, the same applies to the people that immediately explain it as discrimination. reply ivan_gammel 4 hours agorootparentprevIt is important to understand the reasons for that negative correlation. If you do, your conclusions would be quite the opposite - sex imbalance is not something to accept, but rather to fix. Many authoritarian regimes are expanding their economic base by enabling women to pursue professional careers. In some developed countries there’s no such pressure, so they are simply stuck in the past. They are not doing better because women are enslaved in the kitchen or take only stereotypical jobs. It’s just ideological and/or religious trap. reply ndriscoll 3 hours agorootparentMy wife spends around an hour a day in the kitchen. I spend close to eight chained to my computer. If one of us is a slave, it's not her. She's not attending daily stand-ups to report how teaching our daughter the alphabet is going; she chooses how to spend each day with no external pressures at all. Her work taking care of the kids is still more exhausting than mine, but it's also obviously more fulfilling and engaging. When we meet all of our financial goals, we'll both be full time parents. As it is now, I make more than enough for her to take care of the kids full time and still make progress toward our goals. Why wouldn't she take that deal? Consider that when you talk about women doing what makes them happy and what they see as important work (because it is) as being \"stuck in the past\" or in a form of slavery, it might be you who's devaluing them. We both received a lot of that rhetoric growing up, and it took until well into adulthood to really understand how wrong and harmful it is. reply spookie 2 hours agorootparentHey, I know you know best (talking plural here), but make sure that your wife feels accomplished in her own line of work and/or getting her dream job. Raising kids is great, but as age goes by, she might feel sad about not accomplishing other things. This is coming from someone with a dysfunctional family, I don't have much context about your life nor do I want to sound as if I'm assuming things. I'm just trying to warn you about that possibility. reply autoexec 1 hour agorootparent> make sure that your wife feels accomplished in her own line of work \"make sure that your wife feels accomplished\" sounds very strange to me. Ultimately it should be his wife's responsibility to make sure that she feels accomplished right? I get that it's not a bad idea to talk with your spouse about what the two of you want in life and to consider other options from time to time though. > Raising kids is great, but as age goes by, she might feel sad about not accomplishing other things. I think this happens to almost all people no matter what they spent the majority of their life doing. Everyone thinks about how things might have worked out if they'd done something different. As long as people are free to make their own choices, and they have the opportunities to pursue what they want in life, then people are entitled to their own regrets down the road. We each only get one chance at life. It's very rare for someone to look back and not feel sad about not accomplishing other things. reply daseiner1 2 hours agorootparentprevThis dovetails with my central critique, which is that the current state of feminism, in my opinion, tends to insidiously subscribe to the tenets of the “late stage capitalism” that many self-proclaimed x-wave feminists (again, in my experience) claim to denounce, as it is oriented around viewing people first and foremost as economic agents. Yes, individual income affords freedoms to both men and women, which is not to be discounted. But then you hear criticisms of women such as your wife, essentially demeaning them for not striving to be the fittest individual economic agents possible. As if being an AE for Yelp is the pinnacle of the human experience. Again, by no means a black & white issue. I have simply have a distaste for such an individualist philosophy and fear it inevitably leads to an “us v. them” mentality. reply autoexec 52 minutes agorootparent> But then you hear criticisms of women such as your wife, essentially demeaning them for not striving to be the fittest individual economic agents possible. to some extent I think that pressure is put on everyone. There's a lot of pressure to always be making/spending more money. There's also a lot of jealousy. Almost every person I know with children, man or woman, would rather be with their kids, and be there for their kids as they grow up. Very few couples are fortunate enough to be able to afford a good life on just one income. That leads to people being resentful that they are missing out on what they want for themselves and their children. They're stuck missing all the once in a lifetime experiences they could be having because they are chained to a desk for 8-10 hours a day 5 or more days a week. That can cause people to resent the few men and women who do get to stay home and be with their family. They'll make others feel bad for not spending their time working for someone else because misery loves company. It's crab bucket mentality. reply cm2012 4 hours agorootparentprevThe countries with the most female empowerment and equality in the nordics have some of the smallest percentage of women in STEM in the world. reply ivan_gammel 2 hours agorootparentAnd? Have you looked at any research why this is happening? Out of context this can tell anything. reply ghaff 4 hours agorootparentprevOf course, there are a variety of roles that are heavily female-weighted: nurses, K-12 teachers, executive assistants, etc. So there are at least some forces driving gender preferences for roles that probably can't/shouldn't just be wiped out in the West. reply gspencley 4 hours agorootparentprev> It is important to understand the reasons for that negative correlation. Agreed 100% > If you do, your conclusions would be quite the opposite This is where you lose me. Your statement here suggests the following: 1. That you know, for a conclusive fact, what those reasons are 2. That the reasons suggest something ominous Furthermore, you haven't explained what you consider to be the reasons, let alone offered explanation or citations that would support why you think those are the particular reasons. You implied that the reasons are sexism and discrimination, but you left that quite open for interpretation. Moving on, you then suggest that minority groups that do not pursue careers in STEM are \"stuck in the past.\" I have two daughters who are in their early, going on mid twenties. My youngest daughter is one of the smartest and brightest people that I have ever met. Obviously I'm biased, but this is a kid that found ways to get herself into all sorts of trouble as a toddler by solving problems that I would have thought no toddler was capable of. In her late teens she had no idea what she wanted to do, but she expressed some interest in learning to code. Being a software engineer myself, I gave her all of the support and resources that I could. I offered to teach her myself. I bought her Udemy courses and books. I invited her to sit with me at work to see what what life as a coder is like. I made it as accessible for her as possible. What has she decided to do with her life? She works in a professional kitchen and is on the career path to becoming a chef and possibly a restauranteur. People with your attitude would snub your nose at her life choices, look down at what she's passionate about and claim that she is a 'slave' living in the 'past' because she's currently working in a low-paid service industry. You would then blame sexism or classism despite the fact that she was raised in a progressive, well to do family that gave her every opportunity to succeed at whatever she chose to do. Of course, one anectode does not refute statistics. But you have not offered statistics. You came out with assumptions, accusations and a snobbish attitude towards people who would make personal life choices that you don't understand or approve of. The beautiful thing about freedom, however, is that no one needs your approval or understanding. reply em-bee 3 hours agorootparentShe works in a professional kitchen and is on the career path to becoming a chef and possibly a restauranteur. which to my knowledge is a male dominated profession. so good on her! reply rysertio 4 hours agorootparentprevBoth boys and girls from Asian countries tend to be more interested in STEM. reply LargeWu 3 hours agorootparentBecause it's a commodity job where they can provide value to western corporations without having to be physically located there, and there's huge demand for them because of their low cost. reply Jensson 2 hours agorootparentJapan isn't low cost. reply em-bee 3 hours agorootparentprevi don't know the real reasons, but i have the impression that in those countries STEM careers give women more freedom, and that would be why they pursue them. the added freedom makes it worth the potential downsides. in the west they already have more freedom, and so the downside of having to endure sexism does not make it worth the effort. not sure if that is true, but it makes sense to me reply ryandrake 3 hours agorootparent> in the west they already have more freedom, and so the downside of having to endure sexism does not make it worth the effort. This is a great point. I think a lot of HN simply takes as given that tech is a great, pleasant industry to work in, for everyone. Let's say that it isn't. If it isn't, then that might explain why people who have a good degree of financial/employment freedom would not choose to work in tech, leaving people with not a lot of financial/employment freedom (but good tech skills) as the ones who grin and bear a tech job. reply vundercind 1 hour agorootparentI dunno about everyone else, but if “campground manager” had comp as good as tech, that’s sure as shit what I’d be doing instead. Goes for a lot of other options, actually. Clerking a small store is often way more pleasant (depends on the store) than even relatively-good tech jobs, at least to me. But the pay’s not there. reply ivan_gammel 2 hours agorootparentprevIt depends. In some countries (eg Iran) this is probably true from what I remember, in others there are other reasons. reply jmull 5 hours agoparentprevYour points draw the tension between two \"competing\" points. But none of these are black and white. There's a wide middle ground between each one... people can belong to multiple groups. A-holes will take any opportunity to be a-holes, but anti-discrimination doesn't have to be exclusionary and punitive. Affirmative action can work more at the opportunity level, not the handout level. reply commandlinefan 4 hours agoparentprev> Affirmative action makes minorities feel like they don't deserve to be there Does it? I see a lot of affirmative action victims saying that it _ought_ to make them feel that way, but I never hear that from affirmative action recipients. reply em-bee 3 hours agorootparenthttps://youtu.be/LKiBlGDfRU8?t=188 in this video here sabine hossenfelder explains the problem. the statement could be applied to any other marginalized group \"I am against programs or positions that are exclusively for women.I think that treating women differently just reinforces the prejudice that women are less capable than men\" reply autoexec 44 minutes agorootparentprevI have multiple friends who've told me that they very much wondered if they got a job just because they were a \"diversity hire\" and even more who were afraid that others would view them that way and resent them for it. I don't think that fear was irrational. None of them were ever confirmed \"affirmative action recipients\", but the fact that affirmative action and diversity quotas exist at all is enough to make them doubt themselves and be doubted by others. reply influx 4 hours agorootparentprevYou’ve never heard anyone in those groups have imposter syndrome? It’s very common. reply digging 4 hours agorootparentIsn't imposter syndrome just... pretty common in any STEM field? Maybe especially in anyone who isn't a neurotypical cishet white man. reply Jensson 2 hours agorootparentYou don't think affirmative action has anything to do with that? Affirmative action means you and everyone else there knows you had to pass a lower bar, of course that makes impostor syndrome worse. reply lins1909 2 hours agorootparent> Affirmative action means you and everyone else there knows you had to pass a lower bar, of course that makes impostor syndrome worse. No, it doesn't. But if that makes you feel better, I hope you continue telling yourself that. reply commandlinefan 13 minutes agorootparentWait, what? That's literally the definition. reply samatman 4 hours agoparentprevTo tackle your question somewhat obliquely: 67% of veterinarians in the US are women, according to this link. https://www.avma.org/resources-tools/reports-statistics/mark... The imbalance is even more acute than that, because the profession has been trending towards a women-dominated workforce for several decades. There aren't as many veterinarians as there are software developers, but it's a well-paying job. Does this situation strike you as one which needs correcting? I'm fine with it, personally. reply nradov 3 hours agoparentprevBefore selecting an approach we would first have to agree on the goal. What would success look like in a few decades? reply ramesh31 5 hours agoparentprev>Minority affinity groups pull people from majority groups and decrease integration. Integration === subjugation for minorities >Anti-discrimination/sexism/etc. movements often add social barriers to interactions (e.g. things I do within my identity group would be misperceived if done across) Indeed that's the point. You should be more mindful of things you do and say in this context. >Affirmative action makes minorities feel like they don't deserve to be there (and often leads to resentment and other consequences) And it pays their rent and provides social mobility for themselves and their families. We can get over the imposter syndrome; everyone has it for one reason or another. We can't get over being unemployed due to systemic biases. Ultimately yes, for the prevailing group, DEI efforts will always feel like a personal attack. Levelling the playing field has that effect. reply dang 6 hours agoprevnext [36 more] [stub for offtopicness] reply lkdfjlkdfjlg 4 hours agoparentVery interesting. At my company (tech) I've noticed that for the past 2-3 years grads are almost 50% women. Now, I have absolutely nothing against this outcome. But I do wonder - instead of optimizing for a specific distribution of employee features shouldn't we be optimizing for hiring the best? And you could say \"they are the best, 50% of the best are women\". That's a possible explanation! However.... 5+ years ago when grad were roughly 100% men, weren't we hiring the best then? Surely back then they also thought they were hiring the best. Surely 5 years ago if you'd told the hiring manager \"hey from those 20 people you hired, 10 aren't the best, 10 the best are these other people and they happen to be women\", the hiring manager would've said \"no way, we don't look at gender when hiring, we just hire the best\". My point is that we didn't understand why back then we were ending up with 100% men despite the fact that 50% of the population are women. We just mandated that 50% should be women. This is like you believe you have a bug and so you tweak something at random. Now it's different and you think it's fixed. Anyway, they don't pay me enough, so I don't care :-) reply busterarm 4 hours agorootparentAt least in the US, men dropped out of college during COVID in record numbers. Many have not returned. reply keb_ 4 hours agorootparentprev> But I do wonder - instead of optimizing for a specific distribution of employee features shouldn't we be optimizing for hiring the best? You just blew my fucking mind. I've never thought of this idea before....... genius reply newsbinator 7 hours agoparentprevnext [29 more] [flagged] dang 6 hours agorootparent\"Eschew flamebait. Avoid generic tangents. Omit internet tropes.\" (This comment is all 3, and in fact is the ultimate cliché of this topic, and has been for many years. We're trying to avoid repetition here, and especially ultrarepetition and indignirepetition.) https://news.ycombinator.com/newsguidelines.html reply another-dave 6 hours agorootparentprev> There's a gender gap in waste disposal and kindergarten teaching, but there's no \"Girls in waste disposal\" or \"Boys in Kindergarten teaching\". * Building a Gender-Balanced Workforce: Supporting Male Teachers — https://www.naeyc.org/resources/pubs/yc/sept2019/building-ge... * NYC Men Teach — https://nycmenteach.org/ * Men in the Early Years — https://miteyuk.org/ * Women of Waste — https://www.iswa.org/women-of-waste-new/?v=79cba1185463 * Biffa (UK waste management company) outreach to women — https://www.biffa.co.uk/biffa-insights/iwd-biffa-women-waste... reply strikelaserclaw 6 hours agorootparentprevevery group tries to fight for equality and once thats achieved or close to achieved, they try to fight for an advantage, it is unfortunately rooted in the selfishness of human beings. Women seem to be attending college in greater numbers than men, soon we'll need programs to help men get a boost. reply worthless-trash 5 hours agorootparentRemoved. reply n4r9 5 hours agorootparent\"another-dave\" posted some in an adjacent comment: https://news.ycombinator.com/item?id=40926228 Or did you mean something different? reply worthless-trash 5 hours agorootparentI must have .. posted oddly.. i thought it was inline.. thanks. I did mean something else, i'm not sure how that ended up in the state it is in.. now the whole thread is gone. reply grugagag 5 hours agorootparentprevClosing the age gap feels like an artificial goal. It’s like forcing 50-50 on a group. Id much rather see incentives that change behavior and whoever the heck is inclined to be in the group feels welcome and isn’t spooked. reply b3ing 6 hours agorootparentprevThey don't want the dirty or manual jobs, only the high paying ones. I've seen studies on this before and women tend to go for more social jobs, maybe its upbringing, but I think part of it just there nature. reply strikelaserclaw 6 hours agorootparenti don't think women should be discriminated against in whatever profession they want to go to if they have the ability but i also believe men and women are different in terms of interests and women and men will never reach 50-50 parity in engineering type professions. reply InDubioProRubio 6 hours agorootparentI actually think - there should be. There are tons of woman who study to become a vet, for small pets. Nobody wants to be a vet for large animals. So, the good grade woman outcompete the boys who want to become vets, thus no vets for cows and other farm animals. The market should not have to put up with your preferences and if it has to it should lower your wage, due to oversupply. reply didgeoridoo 6 hours agorootparentMost large animal vets make substantially less money — I’d guess because ultimately most farm animals are disposable, while some people will pay tens (or hundreds) of thousands of dollars to keep their pet alive. I bet the large animal vets who work on champion race horses are well-paid, though. reply InDubioProRubio 5 hours agorootparentThey do. And still its a job that needs to be done and the markets demand for people willing to do the work, should not be hampered by the basically hobbyist luxury choice of the individual making the education necessary for that demand a rare ressource. reply Der_Einzige 3 hours agorootparentprevMany farm animals are not disposable. The right bull or horses seman is worth more than your house. reply subjectsigma 6 hours agorootparentprevA better example is nursing. Growing industry, decent pay depending on where you work, very beneficial to society. Also highly gendered, in some cases there’s even a stigma against men in the field, and people largely don’t care about correcting the gender imbalance. reply weard_beard 6 hours agorootparentprevWell, computing is a profession where historically women were not only good at it, they were nearly exclusively occupying the industry. When pay went up it inverted and that is really the problem. Men colonized computing and pushed women out only when it became a source of good income and respected as a profession. reply jordanb 6 hours agorootparentI've heard this before but I read a book called \"Computing in the Middle Ages\" which was a memoir of a man who worked on the SAGE, LINC and Xerox Parc projects. According to him, programming especially in the batch era was a highly social and manpower intensive activity with a large community of support staff and operators around the computer. People who wrote the actual instructions did so on coding sheets, which they would hand over to punchcard operators who would punch them out, and then they would be given to computer operators who would feed them to the computer. The majority of the operations staff in these computing centers were female, but the majority of the people writing the instructions on the coding sheets were male. The rapid decline of women in computing pretty much corresponds to when a lot of these support roles were going away with the rise of interactive computing. That being said I've personally met a lot of really excellent female programmers. I do think there is a tendency to steer women out of the industry or into product or planning roles. Based on that book though I think the narrative of \"computing used to be mostly female before they were pushed out by spergy males\" misunderstands the structure of the early computer industry and how it changed with evolving technology. reply bena 5 hours agorootparentAlso, I believe they’ve flipped cause and effect. They claim that pay went up then men moved in, but they’ve actually found the opposite. When men begin to dominate an industry, pay overall rises. When women begin to equal the number of men in a field, pay overall falls. So there’s not a single issue, but really a whole host of interconnected issues that are hard to untangle. reply imiric 6 hours agorootparentprev> When pay went up it inverted and that is really the problem. Men colonized computing and pushed women out only when it became a source of good income and respected as a profession. You're using some loaded terms there. How exactly did men \"push\" women out of computing? Women were just as free as men to create their own tech startups. Yet in the past 50 years most tech startups and today's tech giants were created by men. Some women are tech entrepreneurs today, but the field is highly male dominated. We see the same ratio in engineering education, and in most companies not actively discriminating against male candidates. The idea that there is some systemic discrimination against women in tech is ridiculous. There are specific cases of wage gap some companies need to address (which is a general problem not exclusive to tech), but most companies would hire capable women if they applied. Yet they rarely do. reply ben_w 5 hours agorootparentYou're conflating entrepreneur with engineer. Different skills entirely, which is why Jobs was never famous for his code and Wozniak isn't famous for his reality distortion field. reply imiric 5 hours agorootparentIs there a distinction between them as far as \"women in tech\" goes? The ratio of both compared to men is pretty much the same. reply ben_w 4 hours agorootparent> Is there a distinction between them as far as \"women in tech\" goes? One involves being good at software engineering, the other involves being good at running a business. Getting good at either involves very different experiences, schools, colleges, and mentors. The stereotype* for software engineers when I went through my degree was introverted nerds with undeveloped social skills. The stereotype* for business people is cocaine orgies. * to complain that the stereotype is inaccurate is to miss the impact of the stereotype on what choices people make when deciding which subject to do a degree in and hence where they go after graduation > The ratio of both compared to men is pretty much the same. The percentage of software developers who are women varies from 8-22% depending on my source. Even if they were identical, correlation doesn't mean causation — this range of \"% of x who are women\" also overlapps with the percentage of furries who are women, and it should hopefully be obvious you can't answer that by asking anything about how many women are entrepreneurs. reply SideQuark 6 hours agorootparentprev> they were nearly exclusively occupying the industry That was true when computing was running tabulating machines. That led to the early ENIAC programmers (all 6 of them) being women since they had traditionally run the tabulating machines. However men had been programming before this (e.g., Zuse, others developing hardware and testing it). Once \"computing\" became what modern people think of as programming, men dominated, not because of sudden sex discrimination or exclusion in computing, but because the input pipeline of what a programmer did changed to people coming from academia instead. The first computer science degree in the world (Cambridge 1953) drew students of math and engineering. The first in the US (Purdue, 1962, first MS degrees 1964, first PhDs 1966) did the same. So it's likely as the field expanded women were not pushed out as much as more men joined in. reply defrost 6 hours agorootparentprevSad to see you downvoted for a comment that's true to history. The pre personal computer days had an army of women in computing. The UK had “Steve” Shirley, she built a billionaire dollar tech company in the 1960s https://www.computer.org/publications/tech-news/research/dam... Growing up it was largely women that taught me how to fly and maintain aircraft, how to set the timing on shot holes to take apart square kilmetres of iron band mesa, to build robots (long before Boston Dynamics), to write exploration geophysics software, serious combinatorics, etc. reply ta1635547 6 hours agorootparentEverything else aside, sounds like a cool history/life. reply defrost 6 hours agorootparentStarted with being raised by a few former-WAAF pilots out of Australia who returned with heavy bombers to Truscott|Mungalalu airbase to take out Japanese oil supplies in WWII and stayed on. Learnt a bit about shock waves from C Morawetz, some combinatorics from C Praeger, robotics from R Owens, etc. https://www.rafmuseum.org.uk/research/online-exhibitions/wom... https://en.wikipedia.org/wiki/Cathleen_Synge_Morawetz https://en.wikipedia.org/wiki/Cheryl_Praeger https://www.researchweek.uwa.edu.au/speakers/robyn-owens/ reply ellisv 6 hours agorootparentprevJust because a gender gap exists in Y, doesn’t mean we shouldn’t also try to minimize it in X. reply knorker 6 hours agorootparentYou skipped a step, though. Why is the assumption 50/50? Yes, there's the null hypothesis, but the null hypothesis shouldn't survive too much contradicting evidence. reply shrimp_emoji 6 hours agorootparentprevWe shouldn't try to do anything. Social engineering doesn't work, and you're being racist/sexist/etc. while you're at it, making everyone rightfully resent you. reply arunharidas 6 hours agoparentprevnext [3 more] [flagged] dang 6 hours agorootparentPlease keep flamebait like this off HN. It leads to tedious internet tedium that inevitably turns nasty [1]. https://news.ycombinator.com/newsguidelines.html [1] https://hn.algolia.com/?dateRange=all&page=0&prefix=true&sor... reply blueflow 5 hours agorootparentnext [2 more] [flagged] dang 5 hours agorootparentIt can be both, no? But the issue here is the predictable effect that certain kinds of comments have on internet threads. reply ecmascript 6 hours agoparentprev[flagged] throw092309 5 hours agoparentprevnext [2 more] [flagged] dang 5 hours agorootparentWe detached this comment from https://news.ycombinator.com/item?id=40926353 and banned this account for using HN primarily for ideological/political/national battle. Not what this site is for, regardless of which ideology/politics/nation you have issues with. https://news.ycombinator.com/newsguidelines.html reply nytesky 5 hours agoparentprevSince it's founding, we've seen Gamergate, the rise of Brogrammers (https://www.cnn.com/2012/05/07/tech/web/brogrammers/index.ht...), and Changs book on Brotopia. I could see it if stakeholders feel they are engaged in a quiotic endeavor... As a father of 3 daughters, I still see a push for women in stem, but anecdotally my youngest is often the only girl in such activities. reply 21 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GamesBeat is collaborating with Lil Snack to provide customized games, aiming to boost audience engagement.",
      "The Girls in Tech nonprofit is closing after 17 years, as announced by founder Adriana Gascoigne, who emphasized the organization's significant role in empowering women in tech.",
      "Founded in Silicon Valley and later moved to Nashville, Girls in Tech impacted over 250,000 individuals across 35 chapters in 30 countries through programs like mentorship, hackathons, and conferences."
    ],
    "commentSummary": [
      "Girls in Tech, a non-profit organization, is shutting down after 17 years due to insufficient funding, sparking discussions on gender diversity in the tech industry.",
      "The closure has led to reflections on the organization's impact and debates on the effectiveness of diversity initiatives and their broader implications for women in tech.",
      "This event underscores the persistent challenges in funding and sustaining non-profits focused on diversity and inclusion."
    ],
    "points": 157,
    "commentCount": 276,
    "retryCount": 0,
    "time": 1720607144
  },
  {
    "id": 40925025,
    "title": "SimSig: Railway Signalling Simulations",
    "originLink": "https://www.simsig.co.uk/",
    "originBody": "Register Log in Welcome to SimSig! SimSig Home Home About Contact Search Forum Index Latest posts Start new thread Events Products Individual Simulations Full Index Download Download SimSig Browse Downloads Recent Uploads Submit a File Documentation User Manuals & Wiki FAQ (Wiki) Returns policy Privacy policy Articles Archive General Ts & Cs Mantis Issue Tracking Games List upcoming games Add a game Links Register Log in Welcome to SimSig! Home Home About Contact Search Community Forum Index Latest posts Start new thread Events Products Individual Simulations Full Index Download Download SimSig Browse Downloads Recent Uploads Submit a File Documentation User Manuals & Wiki FAQ (Wiki) Returns policy Privacy policy Articles Archive General Ts & Cs Mantis Issue Tracking Games List upcoming games Add a game Links Home Library Data Upcoming Games exter and plymouth 2004 TT test Tomorrow at 17:20 UTC waucott (2 users signed up) exter and plymouth 2004 TT test 12/07/2024 at 17:20 UTC waucott (2 users signed up) exter and plymouth 2004 TT test 16/07/2024 at 17:30 UTC waucott (One user signed up) exter and plymouth 2004 TT test 18/07/2024 at 17:30 UTC waucott (One user signed up) Australian sims 25/07/2024 at 02:00 UTC IWillBoom (One user signed up) (UTC times) Full list Add a game Forum Unknown wagon movement at Cheste... Today at 15:15 - Hap Ghost trains while hosting Today at 10:42 - Guts Signal update frames duplicating... Yesterday at 14:48 - Jay_G Info before buying sims Yesterday at 11:31 - Mallard4468 Headcodes not appearing at depot... Yesterday at 10:06 - Hap Galton junction locking up still... Yesterday at 09:52 - slatteryc Multiplayer suggestion. Three pl... 08/07/2024 at 23:46 - DaveHarries Three Bridges June 2024 SX 08/07/2024 at 21:56 - markt Multiplayer with Swindon. Not ab... 08/07/2024 at 19:26 - Hoggorm Hough Lane UWC 07/07/2024 at 18:04 - GeoffM UR639 on the signal number plan 07/07/2024 at 13:50 - Steamer Sydney Box Questions/Comments 07/07/2024 at 10:21 - trolleybus Failure settings 06/07/2024 at 08:23 - bugsy Doncaster Station SX 2019-01-09 05/07/2024 at 15:37 - GeoffM Ranskill signal D160 failed 03/07/2024 at 20:40 - clive Index Latest posts User Log in Register What's my IP? Search Upcoming Events No events to display Who's Online pl, Hap, xSklzxDark, meeko, Ali365Dash, Intercity_225, Phoenix, DriverCurran, 9pN1SEAp, dhouk, Dionysusnu, jnjkerbin, jem771, simonstops, JamesDaniel, Mallard4468, Steamer, 442s3, sloppyjag, Meld, metcontrol, Dick, HST125Scorton, Tomjepson16, postal, Jr_Vandalas, BenWright, mfloyd, sunocske, broodje, TUT, robert, ambergatesm (33 users seen recently) Welcome to the home of Railway Signalling Simulations So what is SimSig? Welcome to the world of railway signalling! SimSig brings the signal box to your home PC and with it the enjoyment and frustrations of running today's (and some of yesterday's) railways. How often has your train been delayed because of \"signal failure\" and you've wondered why trains can't be routed around the problem - or why it is even a problem in the first place? You'll soon see exactly why - with SimSig! SimSig puts you in the seat of a signaller, also called a Dispatcher or Network Control Officer, operating signalling screens based on the widely used IECC and Westcad graphics used in the UK. That is, you operate the signals and points/switches in order to get trains to their destinations on time. SimSig has a wide range of areas you can operate including large portions of the UK, a small US simulation, and a couple of Australian areas. Each has its own challenges and skill level, the latter ranging from easy to mentally complicated. A desk in Edinburgh Signalling Centre - Glasgow Queen Street area. Used with permission from Andrew Gardiner. A signalling screen in Edinburgh Signalling Centre - Glasgow Queen Street. Used with permission from Andrew Gardiner. The Brief Specs Replicates the operation of British IECCs (Integrated Electronic Control Centres) All signalling equipment simulated (track circuits, points, signals, etc.) Correct signalling (overlaps, aspect sequencing, approach control) Emphasis is on quality and realism, not quantity Used by signallers, drivers, and other professionals from all over the world User oriented - tell us what you want, we'll try to produce it! Free demo downloads of every simulation available right now SimSig runs on Windows 8.1 and 10. SimSig also runs on emulators such as Wine for Linux and Crossover for Mac. This is not guaranteed but we try to keep such emulators supported. Tablets and phones are not supported. How much is it? You can peruse prices in our Shop but we have several free simulations, then range from under £10 upwards, depending on the complexity of the simulation. All simulations come with an evaluation period so you can try before you buy. Can I play with friends? Yes! Many of our simulations are suitable for multiplayer. The larger simulations have as many as nine positions keeping people busy. But many simulations also have optional automation such as ARS (Automatic Route Setting) which means you can run a larger simulation by yourself. Multiplayer works over the Internet, or your home LAN. One person acts as the host while others connect with an IP address and port number. We have run multiplayers across the world with members in the UK, the US, Australia, Europe, and elsewhere. Many simulations can be \"chained\", which is where adjacent areas can be linked together to form a larger area. Can I contribute? Unlike other products, anybody can write a timetable using the in-built timetable editor. We also do not charge for extra timetables. Our files area has plenty of user-contributed timetables to download. Sorry, users cannot produce simulations themselves. What does it look like? Here we have the free Liverpool Street simulation running. ARS (automatic route setting) is setting the routes but we can easily take over. The eighteen platforms at Liverpool Street in London are very busy during the morning rush hour that we see here. The blue four-character labels are the train descriptions (like a flight number) such as 2H07. The signaller can identify the routing and destination of the train from that train description. The flashing white blobs indicate that a train is ready to depart. White lines show route set for trains, while you can see the signals showing red (stop), yellow (caution), double yellow (preliminary caution), or green. This animated GIF is running at approximately 4x normal speed. You must download and install the system files (from the Download Now! link above; under 3MB) before any simulations can be played Like us on Facebook See our tweets Join the online voice community with TeamSpeak © 2024 - Cajon Rail LLC - Website version 1.0.8914.12793 Last published Tuesday, May 28, 2024 14:06:29",
    "commentLink": "https://news.ycombinator.com/item?id=40925025",
    "commentBody": "SimSig: Railway Signalling Simulations (simsig.co.uk)153 points by untilted 9 hours agohidepastfavorite66 comments Animats 40 minutes agoMy favorite simulator for railway signals is NXSYS.[1] This simulates General Railway Signal's NX system down to the relay level. NX had the first \"intelligent user interface\" device. When a train enters the interlocking, the dispatcher pushes an entry button to indicate they want to dispatch that train. All the possible exit points then light up. The dispatcher then pushes the button at the appropriate exit light, and all the signals and switches are set up for that route. Routing within the interlocking is automatic. Exit lights only light up if there's an available path. The system is aware of trains in the interlocking, switches locked for maintenance, and the actual position of switches, signals, and train stop devices. As a train moves through the interlocking, track space and switches are released behind it automatically, becoming available for other trains. Today this seems routine, but it was a huge breakthrough in the 1930s. The original marketing brochure is available online.[2] [1] https://bernardgreenberg.com/Subway/ [2] https://anyflip.com/lbes/vczg reply cybrox 8 hours agoprevThis is really cool! For people who don't want to go full scale sim and prefer a bit of a lighter interpretation of working with signalling screens, I can recommend Rail Route (https://store.steampowered.com/app/1124180/Rail_Route/). reply fragmede 7 hours agoparentFor people that want a railway simulator that includes game mechanics to drive a lot of complexity, try Factorio. reply 8372049 6 hours agorootparentOr OpenTTD https://www.openttd.org reply loa_in_ 2 hours agorootparentEspecially a fork called JGR's patchpack, featuring programmable signals and so much more. reply gsck 6 hours agorootparentprevPretty sure the developers of Factorio made a train game based around the train system in Factorio. Can't for the life of me remember its name but it looks rather good reply chin7an 5 hours agorootparentIs it Sweet Transit? The about section mentions that the developer was part of Factorio. Edit to add link - https://www.sweettransitgame.com/ reply Cthulhu_ 4 hours agorootparentIt even looks like the rail assets were lifted straight from Factorio. I mean if it's all above board it's fine - Factorio's train system is really good. That said, they're also giving it major updates/overhauls in the upcoming update, so this one would be falling behind if there's no good relationships between the two. reply gsck 5 hours agorootparentprevYes, that's the one. Never played it, but from my understanding its effectively just the train system lifted out of Factorio with a game built around it. reply TylerE 2 hours agorootparentprevHe was one of the graphics contractors not a dev. It is not very good. The game design is just and, failing to be either a good train sim or an interesting strategy game. It basically flopped in early access. reply wiz21c 7 hours agoprevfirst paragraph on home page is really funny and alluring : \"... How often has your train been delayed because of \"signal failure\" and you've wondered why trains can't be routed around the problem - or why it is even a problem in the first place? You'll soon see exactly why - with SimSig!\" really resonates with my experience as a commuter reply londons_explore 6 hours agoprevRailway signalling IMO is an area where a little research could dramatically increase the throughput of the railway network with a rather low cost. Todays railways mostly use fixed block signalling. Expensive and unreliable equipment ensures that there is only one train on each 'block' of railway track at the same time. That forces trains to be at least 1 or 2 blocks apart, which are frequently multiple miles long. End result: Trains are usually 10's of minutes apart, or at least 1 minute apart even in urban subway systems. A more advanced system would aim to have trains as close together as cars are on a freeway. Trains would be able to hitch and unhitch whilst moving 100 mph, allowing different loads to be sent different directions and different sets of passengers to stop at different stations. Crashes would be avoided by having every train know about the train ahead and behind, and unable to make any move which would cause a collision (ie. it is not allowed to slam the brakes on if there is a train right behind you). Such a system would be implemented primarily on the trains, and primarily in software. Software is expensive to develop then cheap to replicate, a property very important if you want to deploy it widely. It would be backwards compatible with fixed block signalling by simply saying that within each existing fixed block there is either one legacy train, or an unlimited number of gen 2 trains who will all communicate with eachother (and any train who cannot communicate with every other train within the block is not allowed to enter the block). Hardware/software failures are kept safe by simulating every possible type of failure (ie. braking, locomotion, power, derail, position uncertainty, comms), and every second generating a plan which will be executed by every train in case of each type of failure occurring. Any move any train wants to make where any of the above plans cannot be generated with a safe outcome isn't allowed. reply trainyperson 5 hours agoparentMuch of what you’re describing (besides the live hitching and unhitching) is made possible by Communication-Based Train Control (CBTC) [see link below]. This has been implemented in many rail systems globally, mostly urban rail. It helps reduce headways a lot. However: 1. It’s not just a software problem - installing the hardware is time-consuming and expensive. The engineering requirements are much stricter when human lives are at stake so you can’t just strap on a radio to each train. You still need additional infrastructure along the tracks to manage communications. 2. There are other limiting factors in reducing headway - having enough trains and having enough train operators. Somewhat easier to solve perhaps but still costly and non-trivial. ——— https://en.wikipedia.org/wiki/Communications-based_train_con... reply divingdragon 24 minutes agoparentprev> Crashes would be avoided by having every train know about the train ahead and behind, and unable to make any move which would cause a collision (ie. it is not allowed to slam the brakes on if there is a train right behind you). You are assuming that a train will never have to suddenly stop. This will never fly in the real world. Even if you consider a completely closed railway system with no possibility of external obstructions, there are many kinds of failure that would cause modern trains to apply emergency breaks due to fail-safe designs. If you remove the bit about not allowing to slam on the breaks, then you just described SelTrac. Even the first version used on the Vancouver SkyTrain (opened in the 80s) is capable of running trains closer than braking distance from what I remember reading. I don't believe it is actually enabled on many SelTrac systems though, because you still need to have safety margins. There is always the possibility that the train in front may decelerate at a rate higher than its emergency braking rate, like if it derailed or collided with external obstructions. reply Cthulhu_ 5 hours agoparentprevThis puts a LOT of faith / confidence in and requirements on hardware and communications; while it all sounds good on paper / in your head / in theory, there's going to be a ton of practical issues that someone more qualified than me will be able to list. It's got the same energy as Musk advocating for Hyperloop and/or car tunnels by amortizing all the practical, cost, engineering, legal and safety considerations. Sure, in theory a maglev train in a vacuum tube is super fast, but in practice building the infrastructure is prohibitively expensive and there's not a big enough market for it. reply londons_explore 5 hours agorootparentThe market for people transport is huge. Imagine the cost of all apartments in manhattan @ $3000/sq foot. Now imagine the cost of the same apartments built in upstate new york @ $250/sq foot. A transit provider who can get people from a house in a rural area to manhattan in 15 mins can pocket that difference, which is huuuuge. reply bluGill 4 hours agorootparent> Imagine the cost of all apartments in manhattan @ $3000/sq foot. Does such a thing exist? A tiny bathroom is 25sq feet - or $75000. That just seems too much. Zillow lists studio apartments in Manhattan for $3000-$5000/month. They also list apartments in New Jersey for $250/month just 30 miles away (1 hour drive to Manhattan according to maps). At that distance we don't need fancy hyperloop, we just need good higher speed rail service easially done with existing technology. (I have no idea how the apartments compare other than price - likely the Manhattan ones are much nicer for the same amount of space and the New Jersey neighborhood may be unsafe) reply NovemberWhiskey 30 minutes agorootparent$2,000 to $3,000 per square foot is absolutely the asking price for condos in parts of New York like Tribeca and Soho. reply kqr 5 hours agoparentprev> Crashes would be avoided by having every train know about the train ahead and behind, and unable to make any move which would cause a collision (ie. it is not allowed to slam the brakes on if there is a train right behind you). Note that with any latency in the system, they need to consider not just the train behind, but /several/ trains behind: https://two-wrongs.com/keep-a-safe-following-distance.html reply dividuum 6 hours agoparentprev> A more advanced system would aim to have trains as close together as cars are on a freeway. https://en.wikipedia.org/wiki/European_Train_Control_System#... reply londons_explore 5 hours agorootparentThis still doesn't allow train spacing of less than the braking distance. Braking distance of trains is large (due to high uncertainty in track friction), which still means trains are typically 1 minute or more apart when moving fast. As long as you have comms with the trains around, it's clearly possible to safely go less than the braking distance, as long as you can be sure of the behaviour of the train ahead, even in the case of an equipment failure (ie. in case of a power failure, it will not slam the brakes on, but decelerate at X m/s^2). reply thanzex 5 hours agorootparentI think that's not something that can be avoided, unfortunately. Any number of things could cause a train to suddenly stop. A mechanical failure, derailment, collision, a wagon could get detached... On roads we have millions of vehicles, carrying on average a very small amount of people, around 1.5. For efficiency sake we have accepted the risk of staying within reaction distance instead of stopping distance between vehicles. It is a tradeoff between the safety of lives on board and traffic requirements that is relatively easier to accept when the average number of people involved is low against massive speed and efficiency gains. The same cannot be said for trains though. Modern trains carry upwards of 1000 passengers, often at high speeds and without all of the safety and retention systems built into modern cars. Having one or multiple trains with this large amount of people onboard be involved in a sudden catastrophic accident is possibly not worth the efficiency gained by thess than one minute separation. Unfortunately we cannot just think about a normal scenario of simple deceleration reply sneak 4 hours agorootparent> On roads we have millions of vehicles, carrying on average a very small amount of people, around 1.5. For efficiency sake we have accepted the risk of staying within reaction distance instead of stopping distance between vehicles. No. Unsafe drivers have illegally decided this, but in most jurisdictions it is your responsibility to stop your vehicle short of the one in front of you. You should be maintaining stopping distance from your vehicle to the one in front. reply lqet 4 hours agorootparent> You should be maintaining stopping distance from your vehicle to the one in front. I am not so sure. In Germany, for example, the minimum required distance to the car in front of you is \"speed in km/h divided by 2 in meters\". So for 100 km/h, you are required to keep a minimum distance of 50 meters. I very much doubt that you can stop a car going 100 km/h within 50 meters. reply whartung 4 hours agorootparentYou do t need to stop a 100 km/hr car in 50 meters because, barring that sudden brick wall appearing ahead of the car in front of you, they’re not stopping in 50m either. The 50m is the reaction buffer, not the stopping buffer. It’s also prudent to give more leeway to vehicles you can not see around to avoid the large truck swerving to avoid the refrigerator that just fell out of the truck in front of them problem. reply andruby 1 hour agorootparentprevThat's interesting, in Belgium I think it's \"2 seconds\", or at least that's what was promoted recently on the radio. You should be able to sing \"Last night a DJ saved my live\", which is a bit more than 2 seconds. I liked that, because it's one you can actually test for while driving. I find it a lot harder to estimate 50m while driving at 100km/h reply corobo 4 hours agorootparentprevAt least with cars they also have the option to swerve away from the chaos if the stopping distance is too short. Not to disagree, just throwing in a variable that trains don't have reply thanzex 4 hours agorootparentprevNot really. In my country, at least, it is explicitly stated in driving theory manuals to maintain at least one reaction distance between the car in front of you. For a car traveling at 100Km/h the stopping+reaction distance would mean more than 130m, which is a quite large and possibly impractical for higher traffic scenarios. reply mezmor 5 hours agorootparentprevAren't braking distances so large because of the massive amounts of mass in motion? Inertia, etc. Even high certainty of track friction wouldn't change that. Also, I don't think it's ever safe to be closer than braking distance because the bahavior of the train ahead is never guaranteed. There's always a chance somebody parks their car on a rail crossing or some other sudden stopping-event occurs. reply lqet 5 hours agorootparentprevIt is not safe. If your train crashes into a truck, or derails, or explodes, all trains behind will crash into it if they are nearer than their own breaking distance. This is not possible in a classic block system: the block is freed only when the last carriage of the blocking train has left the block. reply pixiemagic 5 hours agorootparentprevWhat happens if there's some other reason to brake, such as an unreported fallen tree on the line ahead? reply rjmunro 3 hours agorootparentAs soon as one train brakes, the train behind should automatically brake. The separation distance can be maintained. The problem is if the first train hits an object or derails, this might cause it to slow down faster than the brakes would have done, and the following train may not have time to stop. reply londons_explore 5 hours agorootparentprevYou can still brake - you just need (automatic) agreement of all trains behind you to do so. You aren't allowed to brake 'as much as possible' anymore - instead the best you can achieve is 'the best the worst of the trains behind me can achieve'. reply garaetjjte 5 hours agorootparentIf one train derails for some reason, then every single train on the line crashes in the greatest pileup ever. Great. reply londons_explore 4 hours agorootparentThats already the case for carriages within a train.... And people are fine with it. We're also fine with the risk of a derailment onto a neighbouring track with traffic going the opposite direction. We could have tech which detects that, but we do not. reply lqet 4 hours agorootparent> And people are fine with it The thing you are missing is compartmentalization. A modern high-speed train can hold around 1,000 people. This is the maximum number of people that could die in an accident (ignoring trains on other tracks or people next to the tracks). What you are proposing is essentially a train of infinite length, with virtual (software) coupling between groups of carriages. But then there is no limit to the maximum number of deaths in an accident. If you have 50 high-speed trains all traveling in this virtually coupled manner, a single accident may cause 50,000 casualties. People would not accept this, and no sane policy maker would allow it. Note that if you consider derailments into neighboring tracks, you still have an upper limit of 2 times maximum train capacity, in our example 2,000. reply corobo 4 hours agorootparentprevA train derailing onto another track would be a hell of a derailment Take this incident for example https://www.bbc.co.uk/news/uk-england-surrey-68466494 Imagine that then resulted in \"the following train then slammed into the derailed train, having been unable to stop in time\" reply rjmunro 3 hours agorootparentIt happened at the Clapham Junction rail crash in 1988: https://www.bbc.co.uk/news/uk-england-london-46509473 A total of 3 trains were involved. reply corobo 3 hours agorootparentOh wow, I was 6 months old when that happened. (36y/o now) Pretty decent track record if that's the most recent example! Upping the ante: how much worse would that have been if there were trains following closer than braking distance in both directions. Special note that the train derailed so severely in this incident after colliding with a train stopped in front of it. I'm even less of a fan of OP's \"braking distance shmaking distance\" proposal with this example of why it's a bad idea! reply danhor 4 hours agorootparentprevYou could also characterize the maximum braking ability of the train in front of you and the minimum braking ability of your own train and determine the needed distance for any given speed based on that. This would of course be more complicated and probably be solved by only including broad categories of trains (i.e. only two sets of values for either passenger trains or freight trains). reply TylerE 2 hours agorootparentprevThat’s a metric crapton of ifs. I would never get on such a system, it is fundamentally unsafe. reply cmul 5 hours agoparentprevImho, the major constraint for railways in most countries is policy, not technology. In the US and many large (surface area) countries, railways primarily serve for freight transportation and, to a shockingly underdeveloped degree, local commuters. In Europe legacy solutions and differences of national systems, planning guidelines and even power grid cause problems. Some nations' railways are extremely underfinanced and have been driven to the brink of collapse in the privatizations of the early 90s with more than 30 years of missed investments. The rollout of ETCS tries to remedy that and so do ERA/EUG/ERJU but the coffers of many nations are rather empty/respectively other interests weigh higher (subsidies for streets, automotive companies, aviation and other big buckets like farming). reply jcranmer 5 hours agoparentprevThere are two things that control the ruling headway on a subway system. The first is platform dwell time. While a train is stopped at a station, you cannot let another train move into its position as if it was going to start moving on schedule, because it's actually quite likely that it won't. Given that platform dwell time is about 30s, and taking into account time needed to decelerate and accelerate to/from a stopped position, this limits minimum headways to about 1m. Similarly, switch fouling time is another constraint: you don't want to move a switch while a train is allowed to path over it, in case the switch fails to switch. From what I've heard of existing urban systems, this leads to a minimum headway of ~90s, although I don't know how much of that is signal-induced padding. The next thing to point out is that these are theoretical maximum density; the practical maximum operational usage is generally far less. Most subway systems have the physical capability of operating ~45TPH on a subway line, yet you'll notice that extremely few do. Moscow Metro has managed 40TPH on an unbranched line; branched lines struggle to get to 30TPH, and heavily reverse-branched systems like the DC Metro or NYC Subway struggle to make even 20TPH. Introduce branches into the mix, and you need trains to make it onto the mainline in slots, and there's going to be variance in arrival time because the system is used by humans; reverse branches makes the problem worse because these slots need to line up well on multiple lines at the same time. > Trains would be able to hitch and unhitch whilst moving 100 mph, allowing different loads to be sent different directions and different sets of passengers to stop at different stations. No. There's a reason railroads have banned the practice of unhitching at speed (it's incredibly dangerous), and hitching is even worse. And if you're talking about EMU passenger train sets, most of them are designed to not be hitched or unhitched particularly frequently--these aren't your standard automatic coupler system (which doesn't couple brake lines or electrical lines or other things automatically anyways, FWIW). reply danhor 4 hours agorootparent> and heavily reverse-branched systems like the DC Metro or NYC Subway struggle to make even 20TPH. I find this really interesting that is seems to be the limit for \"big-boy\" complicated subway systems, while there are many very complicated smaller systems that achieve much more. For example, a lot of the german Stadtbahn systems run somewhat long trains (up to 80m), run using conventional signalling systems underground (so not on-sight, which would allow for a much higher throughput). Naively I'd assume the tram-style segments and frequent at-grade crossings would make this much worse, but apparently not. For example, Stuttgart (https://download.vvs.de/Stadtbahn_Liniennetz.pdf, https://gleisplanweb.eu/show.php?Map=Stuttgart&Index=1&Heigh...) currently runs 27 tph between Stadtbibliothek and Olgaeck, with plans to run 30 tph without any upgrades, and 30 tph between Staatsgalerie and Stöckach (additionally even running the U11 for events) without any significant issues and quite a complex network with many flat junctions outside the underground sections. The DC Metro has much less complicated branching/reverse-branching patterns. reply TylerE 2 hours agorootparentTrams often have rubber tires, which gravely increases acceleration and braking. Also, 80m isn’t that long. Trains on the the DC metro are pushing 200. 8 cars long. reply danhor 1 hour agorootparent> Trams often have rubber tires No, they don't. There are a handful of weird french systems (and even less outside of France), but there are more ruber-tire metros than trams, I'm sure. They are rare and have been getting rarer. 80m is in the lower half for metros, but long in the context of systems having on-street portions (exceeding the german legal limit of 75m with a special exception). It's also on the long end for small metro systems. reply p_l 5 hours agoparentprevMoving block systems are not really new, they just aren't distributed widely. reply londons_explore 5 hours agorootparentMoving block doesn't allow trains to get closer together than the braking distance. This would. reply bluGill 5 hours agorootparentThere is good reason they don't do that: trains derail once in a while, your plan means the following train will hit that train and so the accident is worse. Part of the answer to that is better track maintenance. However that isn't a perfect answer and so we need larger gaps. Note that cars on the freeway are normally much closer together than is safe as well. If cars maintained a safe following distance we would need 5 times as many lanes. (you know the massive freeways in Huston that urbanists like to show as bad: that is about the correct size of freeway for Des Moines, Huston needs many more if they want to be a car oriented city) reply TylerE 2 hours agorootparentprevSaying trains should be closer than braking distance is like saying with devs shouldn’t support https. It’s something no expert in the field wound agree with. reply secondcoming 5 hours agoparentprev> Crashes would be avoided by having every train know about the train ahead and behind Isn't this a block system? > it is not allowed to slam the brakes on if there is a train right behind you So if we have three trains in close succession and the first derails or loses power, the second is not allowed stop because there's a train behind it? > Trains are usually 10's of minutes apart, or at least 1 minute apart even in urban subway systems. At least on the London underground it isn't unheard of for the next train to be arriving in 1 minute. Most delays are caused by passengers, not infrastructure. reply trainyperson 5 hours agorootparentThe 1-minute (or less) headways on London Underground are precisely because of signal modernization over the past couple decades that has moved certain lines beyond purely fixed-block signaling. reply londons_explore 5 hours agorootparentprev> So if we have three trains in close succession and the first derails or loses power, the second is not allowed stop because there's a train behind it? The second is allowed to follow the 'train ahead derailed' plan, which presumably will involve stopping at a rate that the third train can also achieve. If comms is maintained during the event, new plans can also be made that are maybe better (eg. maybe try to brake harder than the guaranteed minimum braking) reply corobo 3 hours agorootparentInstead of a derailed train and a couple delayed trains you now have a derailed train and a couple of trains with flat wheels that also need clearing up (assuming they avoided slamming into each other) Definitely not sold on the \"let's chuck out the failsafe method of railwaying\" idea, haha reply euroderf 5 hours agorootparentprevAFAIK the underground is not beset with blockages caused by fallen trees and stalled automobiles. reply secondcoming 5 hours agorootparentIt does have its fair share of 'people under a train' and people preventing doors from closing. reply cmul 3 hours agorootparentWhich is why ATO (automatic train operation) is most often found in subways where the platforms can be equipped with gates to keep passengers out until a train has stopped safely. Suicide by train and level crossings are a nightmare in risk management for railway safety, hence also (new) high speed tracks are usually planned without any intersections with roads or paths, at respective additional costs. reply TylerE 2 hours agoparentprevThat isn’t how trains work. They take miles to stop. Being able to stop any train on the network without risking it running in to another is not negotiable. reply rwmj 7 hours agoprevMemories of playing Heathrow Air Traffic Control (https://www.spectrumcomputing.co.uk/entry/2270/ZX-Spectrum/H...) reply 8372049 6 hours agoparentNowadays you can do virtual ATC work in VATSIM and IVAO, controlling airspace for flight sim players. reply cmul 5 hours agoprevFor German speakers: https://www.estw-simulator.de/index.html https://www.estwsim.de/cms/index.php These have been around for a while and quite closely mimic (slightly older) German signalling specifications for signaller interfaces. My company builds such systems as test and demonstration systems for real railway projects with respective functional safety constraints. If you're interested to learn more about the signalling infrastructure in Europe or Germany, feel free to ask. reply shagie 4 hours agoparentAlso in the German train signaling ... https://www.eisenbahnbetriebsfeld.de A Tom Scott video on it - The world's most useful model railway https://youtu.be/6TLcaJdsRr0 reply 0xTJ 5 hours agoprevThis is the sort of simulation/game, like Dwarf Fortress (especially older versions) where I don't have the slightest idea what's going on, or how to make things happen, but am still having plenty of fun. reply nateguchi 7 hours agoprev [–] See also: https://signalmaps.co.uk/#gwml1:1627 Live signal maps in the UK reply amouat 6 hours agoparent [–] Also traksy e.g: https://traksy.uk/live/T+EDB+KGX+d+@2024-07-10T13:00/M+1+EDI... reply class700 6 hours agorootparent [–] There's also OpenTrainTimes https://www.opentraintimes.com/maps/signalling/wat#T_WATRLMN And https://www.realtimetrains.co.uk/ for precise times/platform information. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SimSig is a railway signalling simulation software that replicates the operation of British IECCs (Integrated Electronic Control Centres) on home PCs.",
      "It offers a variety of simulations from the UK, US, and Australia, with prices ranging from free to under £10, and supports multiplayer and timetable creation.",
      "SimSig runs on Windows 8.1 and 10, and can be used on Linux and Mac through emulators like Wine and Crossover."
    ],
    "commentSummary": [
      "SimSig is a popular railway signaling simulator, with discussions comparing it to other simulators like NXSYS, Rail Route, and Factorio.",
      "The conversation highlights the complexity and realism of different railway signaling systems, including historical and modern advancements.",
      "There is a debate on the safety and efficiency of close train spacing, with references to various signaling technologies and real-world examples like the Clapham Junction rail crash."
    ],
    "points": 153,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1720602136
  },
  {
    "id": 40922740,
    "title": "Awsviz.dev simplifying AWS IAM policies",
    "originLink": "https://www.awsviz.dev/",
    "originBody": "Drag & drop a zip file here or click to upload IAM Policy JSON Format Clear xxxxxxxxxx 1 1 Policy Visualization",
    "commentLink": "https://news.ycombinator.com/item?id=40922740",
    "commentBody": "Awsviz.dev simplifying AWS IAM policies (awsviz.dev)152 points by bscript 18 hours agohidepastfavorite120 comments egorfine 9 hours agoI have been discussing IAM with a couple of AWS engineers from that team a few years ago. I have tried to convince them to implement something actually sane non-corporate developers, because IAM is complicated way beyond a point of being usable. I have seen so many people just slam the root credentials into config in order to never touch IAM. And yes, me included, and yes, it's a shameful practice, don't do that. Take a day off, go on a hike, watch the sunset, meditate and embrace the inevitable: yes IAM is incredibly bad and there is no way around. (I was heavily using AWS since inception, way before IAM was invented). My speech fell on deaf ears, because IAM is clear as sky to its inventors and they fail to see what's the problem in it and corporate customers are happy to employ one or two people solely dedicated to learning and managing IAM. Anyways. There is no way around IAM. And just like with systemd you better embrace it and learn it and it turns not that terrible. reply jjice 6 hours agoparent> I have seen so many people just slam the root credentials into config in order to never touch IAM Anecdotally, at a startup I worked for, our devops and security engineers pulled me into a call once because they needed my help finding where the root credentials were being used in our code. I logged into our dev, staging, and production servers, but they were nowhere to be seen in any place you'd expect AWS creds (like ~/.aws). Then it hit me. I pulled up our git repo and pulled up a function that handled file upload to s3 for something incredibly unimportant. Right there, in plain text, checked into git. The git blame read something like \"4 years ago\". Creds weren't even needed since the AWS SDK does whatever magic to know the creds based on the EC2 instances role. I immediately put up PR just removing the creds as the empty constructor for our SDK used the EC2 role (this pattern was used in multiple other parts of the code base). The CEO (the author of the code) didn't want to merge it in case it stopped working, despite me demoing in our staging environment and the feature using this code was only used like twice a week. Thankfully, we convinced him, got it removed from the codebase, and either cycled or deleted the root creds, I don't recall how that worked at the moment. I wasn't familiar with root creds at the time either, but damn is it scary to think that anyone of the engineers had access to root creds for a company of the size that we were. And the CEO wrote it like that originally because he didn't want to mess with IAM. I can see why he did it, but man was that a bad idea. reply egorfine 5 hours agorootparent> And the CEO wrote it like that originally because he didn't want to mess with IAM. I can see why he did it, but man was that a bad idea. This is a very common case. It's okay in the very early development (rarely we start projects with a definition of IAM policies), but then it gets shoved into backlog forever. reply Lutger 4 hours agorootparentI'm not sure how it is ever ok to put your _root_ credentials into version control? I am not even comfortably doing that with my personal private repositories that I share with nobody. reply egorfine 2 hours agorootparentOops, I replied to an out-of-context comment. I mean it's okay to use a wildcard policy in the early stage of a project. Of course, committing credentials into a repo is absolutely never ever ok. reply SOLAR_FIELDS 5 hours agorootparentprevThere’s a pattern I see (and indeed have even perpetuated once or twice) of “AWSguide based development” where someone copy pasted the default policy/roles directly from a guide into AWS CLI commands and just forgot about them after. Not as bad as the root credentials being used but certainly doesn’t help maintain a sane and understandable access system. I know it’s a lot of extra maintenance effort and probably more difficult but AWS could go a long way towards making this more sane and transparent by giving gitops examples alongside their CLI ones. Even someone just copy pasting terraform or cloud formation is going to be way more visible than AWS CLI reply Aperocky 5 hours agorootparentprevNot a good sign... reply Aeolun 2 hours agoparentprevI feel like IAM is not actually that complicated? Most services have permissions that are in direct correspondence with the API calls you want to make. Of course a few of them decided to do mad shit (looking at you API Gateway), and a few others require you to have nearly all permissions to do some of their most common API calls (S3 needs like 15 permissions to set all possible properies on an S3 object). It’d be nice if AWS could fix the madness and standardize on one List/Update/Create/Delete call per resource, since most services are already like that. reply nerdjon 6 hours agoparentprevI disagree. IAM does what it’s supposed too when you need to run an organization with very fine gained controls. People being able to see and interact with certain services but not everything related to those services. Same with services since it’s the same system. To me the problem isn’t IAM itself but the nested API calls. Which also itself isn’t a problem but we need a better UI to diagnose when something goes wrong. Cloudtrail isn’t really suitable for this task. A “simple” UI of looking at a role and seeing a “failed calls” would go a long way. reply captrb 6 hours agorootparentThere is a pretty simple way to query cloudtrail logs with Athena and its a huge improvement over the normal UI. reply schmidtleonard 3 hours agorootparentWhen \"run a SQL query against an implicit file database\" is a huge improvement for anything but the edgiest of cases (and I believe you that it is), that's a scathing indictment of the normal UI. What I don't understand is how the AWS log inspection tools are still as bad as they are. Even if it's just to prepare public-facing material, AWS clearly dogfoods them a little bit, so surely there would be glory and accolades to be won by implementing search that was half-assed (instead of quarter-assed)? Or is the AWS culture so broken that it net punishes core improvements? Come to think of it, that would explain a lot. reply nerdjon 5 hours agorootparentprevI probably should have been more clear on that, it is very possible with Cloudtrail and Athena and I find myself doing that pretty regularly. But there are also times that it is inconsistent at best especially when trying to look at some nested permission problem. More than a few times I have had to get on with AWS support because the actual error just was not in Cloudtrail anywhere. Or it is related to some service that doesnt log to Cloudtrail like s3 access. Which kinda more my point was, it isnt IAM itself that is the problem. reply JackSlateur 9 hours agoparentprevI find IAM to be a great product. I cannot imagine how we could make it different, without removing some of its capabilities: after all, this is nothing but a list ofpermissions reply egorfine 9 hours agorootparentI tend to agree with you that the idea of a list of \"who, what, which\" is straightforward and probably is the right way of doing things. I agree that permissions is inherently a hard problem. I disagree that IAM specifically is a great product. It's great if you learn it, but learning permissions system never adds anything to the bottom line. It's an evergrowing technical debt at best. People interested in learning permissions system are typically people interested in developing one. Users are never happy with permissions systems because more often than not it's a nuisance. In my view IAM is an incredibly overengineered list of who, what, which, suitable for corporate granularity but then too complex to be used by a startup or a project. reply JackSlateur 8 hours agorootparentYes You are diving into another topic: \"fine-grained permissions\" In my opinion, fine-grained permissions is a very good idea for application-attached role: your lambda can only do \"this\", your ec2 instance can only do \"that\". For humans, they are a mistake and shall be avoided. reply egorfine 8 hours agorootparentI'd love for fine-grained permissions to be optional. Not an insurmountable barrier to the actual service. Like let me start the development first. I'll get to security later. I came here for object storage, don't force me to learn an incredibly complex auxiliary service. reply icedchai 5 hours agorootparentThey basically are optional. You can use wildcards in the action. (Nobody will go back and tighten them up though.) reply lijok 7 hours agorootparentprevBut they are, that's kind of the whole point. You start with {\"actions\": [\"s3:\"], \"resources\": [\"\"]} and graduate from there when ready. reply egorfine 7 hours agorootparentThis could be a perfect 101 on IAM which I would strongly prefer never attending. reply lijok 4 hours agorootparentHow else do you expect to manage permissions? Is there a better dsl design you have in mind? reply egorfine 2 hours agorootparentWhat is better? I am pretty sure IAM is the best there is, no questions about that. Better for small teams? Sure: a login/password system with maybe optional restrictions on services and maybe \"readonly\" access and maybe with disabled aws console. Basically, something that was in AWS before the IAM madness came in. reply xenophonf 5 hours agorootparentprev> Like let me start the development first. I'll get to security later. And that's why the world is full of crappy, insecure software. Security is ever an afterthought. reply egorfine 5 hours agorootparentWholeheartedly agree with you. Not only it's an afterthought, it's a sinkhole for resources with zero apparent ROI. It's basically lives in backlog rent-free. reply Aeolun 2 hours agorootparentprev> suitable for corporate granularity but then too complex to be used by a startup or a project To some extend. It’s perfectly possible to make a role that allows S3 access to any action on everything, but still restricts the service from operating on any of the other 400 AWS services (unlike root credentials) reply inopinatus 7 hours agorootparentprevThe true purpose of IAM is for AWS control-plane and data-plane elements to interact autonomously with resources that are in your account without violating the dialectic around security “of the cloud” vs “in the cloud”. And this is also why you need a PhD to fully comprehend it reply cqqxo4zV46cp 7 hours agorootparentprevNo. You’re in denial about the importance of authorisation, don’t want to give it the time it deserves, and are shooting the messenger in placing the blame on IAM to the degree that you are. People see AAA as a pain in the ass because it’s not the problem they thought they’d need to solve. That doesn’t mean that it’s important, or that the complexity is avoidable. For the record, I’ve never been in a development team of more than 4 people, and my teams have always been responsible for their own ops. No ‘corporate dev’ here. reply egorfine 7 hours agorootparent> People see AAA as a pain in the ass because it’s not the problem they thought they’d need to solve. True. > That doesn’t mean that it’s important, Not necessary true. > or that the complexity is avoidable. Untrue. There is no need for IAM for the vast majority of 4 people teams and there could be a simpler solution for those, like it was before IAM. And it can actually be built on top of IAM, just spare people from diving deep into it. reply dopylitty 5 hours agorootparentprevIt’s a little more complicated than that. I’ve run into many instances where a particular Action involves many different Resources. If you’re trying to do fine grained permissions you have to know every resource that might end up in the request context and then have an entry in a Resource section of a policy for that Resource type. For instance just creating an EC2 (RunInstances) might involve Subnet, Security Group, EBS, image, volume, snapshot, and a few other resource types. This gets even more complicated when you’re using Condition operators because the conditions are checked against every resource in the request context but each resource type has different valid conditions (eg some resources have tags and some don’t) so you have to split up the policy into numerous statements specific to each resource type. All of that would be fine if there was any way to actually reliably get the context of a request so you can see exactly what was denied. Sometimes you can get the context via the encoded authorization message in a failed API call but this is usually truncated in CloudTrail or if you’re using IaC tools like Cloudformation. They’ve done a lot in the past few years to explain why a particular call was denied but none of it beats seeing the context and seeing exactly which part of the policy did or didn’t apply. reply icedchai 5 hours agorootparentprevThe main problem is it's a huge time suck. When writing IAC like Terraform, you'll probably spend more time configuring IAM roles and permissions than you do the actual infrastructure. Also, in my experience, nobody reviewing your code will check if it's correct, least privilege, etc. And when you get it wrong (too restrictive), the error messages can be difficult to diagnose, depending on the service. So most people will err on the side of more permissions than needed. reply turtlebits 1 hour agorootparentDon't use Terraform? If you want to create individual resources one by one, go for it. Use something like CDK which abstracts a lot of the boilerplate away. reply icedchai 6 minutes agorootparentI wound up with a job at a TF-heavy company. I personally despise Terraform. The language is anemic and there's too much copy-paste code. reply presspot 3 hours agorootparentprevI have hard this from many developers. Are there any good solutions or best practices I should look into? reply wetpaste 52 minutes agorootparentprevI think it gets hard when an emergent chain of complex trust relationships need to be built and understood. Things like IAM identity center, workload identity, IRSA on EKS, service principals vs roles for accessing other services from a service, resource policies vs principle-level policies and when to use each. Not necessarily intuitive all the time. I don't think it's THAT hard and I understand why some of these things were built this way, but it's a huge complicated ecosystem of services and I understand why it can get confusing to some. Gotta be disciplined about it. reply whs 7 hours agorootparentprevI wish it is a list of . Right now you can't even get a comprehensive list of people who can access this S3 object. Add assume roles, conditional access, cross account, per-service object level policy into the mix I don't think it's even actually possible for AWS to implement that. I found GCP's access control to be much simpler but more limited than AWS. They're adding complexity though with conditional access. In GCP the \"who\" in most case is an email (Google Account, Google Groups, service account) reply tyingq 7 hours agorootparentprevThe way it evolved makes it complicated. That you have normal policy, resource attached policy, SCP, Assumed roles, etc, etc. That spreads out the actual end resulting policy into a bunch of disparate corners that's hard to unravel. There's tools to see \"can this specific user/role/service get to this thing\". But because of the above, there's no one place to see \"who can/cannot get to this thing\". reply oneplane 7 hours agorootparentI'm not sure how that is complicated. There are different systems with different functions for different purposes, that will not go away unless you remove the systems or the purposes. And that's not useful. reply Joker_vD 6 hours agorootparent> There are different systems with different functions for different purposes, Which are interconnected, right? If yes, then that's what the word \"complicated\" means: made of multiple, non-trivially interacting parts. reply oneplane 5 hours agorootparentYou can choose to interconnect them but that is neither required nor default. It depends on what you want to build. You can have a simple policy on a resource that just allows something, or you can make a complicated bi-directional set of policies that refer to specific principals, resources and actions to constrain it more. That will never go away if that is what you need to build. And it is still optional because if you don't want to build that, then you just end up with your single, not-inter-connected policy. reply tyingq 7 hours agorootparentprevOkay yes, I figure out what I need to. But it seems clear that conflicting concepts got bolted on after the initial design. Which means it's more complicated than it needs to be. reply oneplane 5 hours agorootparentWhich ones are bolted on? Besides the S3 ACLs (which are more like a precursor) and the weird conditional language it's all pretty consistent and obvious like any ACL. Things like principals, resources, trusts and control policies are all distinct systems with different goals and purposes. Maybe I'm missing some different AWS IAM policy that has that bolt-on flavour? reply tyingq 21 minutes agorootparentYou can't meld the rules together to get a cohesive view of, for example, \"who can access this S3 bucket?\". Because, for example, an SCP can override a bucket policy. And policies can be other places too. I can get \"can this specific role/user access this specific bucket\", just not the other direction. It's not because the language isn't consistent, it's because the language isn't backed by a single cohesive RBAC type setup. reply JackSlateur 6 hours agorootparentprevImagine, you drop IAM and revive the good old user/password system. You have no way to see \"who can/cannot get to this thing\". Yet who could argue that user/password are \"complicated\" ? NB: using IAM access/secret key has indeed the same issue reply tyingq 11 minutes agorootparentI'm not arguing for user/password. reply randomtoast 6 hours agorootparentprevAWS is good at building abstractions on top of their already existing features, e.g. AWS App Runner. Maybe there could be an abstraction on top of IAM that does not allow for all the fine-grained permissions settings and options that IAM has, but has much simpler predefined roles which are very well suited for a small startup. reply nerdjon 6 hours agorootparentFor a lot of situations they already have this. They have managed (AWS Created and Managed) policies that if you want a basic level of security you can use. A lot of services will create policies for you, for example you can go to RDS and click setup connection to lambda, or ec2 and it will create the policy. A lot of things will give you the policy to copy and paste. Another UI to further abstract IAM would likely just complicate things, and then make it harder later if/when you need to leave that abstraction. reply nprateem 9 hours agorootparentprevWell, for a start, you could have a recorder that actually shows all the relevant permissions for a particular API call so users can work out what they should set permissions on (including interactions with SCPs and anything else that could affect a decision). reply rad_gruchalski 8 hours agorootparentYou can easily get the first part of via the sdk https://cloudonaut.io/record-aws-api-calls-to-improve-iam-po.... reply Aeolun 2 hours agorootparentprevYou can actually set this up in your account. It’ll record all the permission your roles actually use (over a customizable period of time), so you can remove all others reply myaccountonhn 7 hours agorootparentprevI don’t think the language is bad, but maybe improve the policy simulator, make it easier to understand what policies are require and also make it easier to find and reference different arns. reply MrBuddyCasino 9 hours agorootparentprev> I cannot imagine how we could make it different This seems almost bait. reply egorfine 9 hours agorootparentProblem is, once you dive deep in the rabbit hole, you will inevitably build another IAM. The art here is knowing when to stop building, not what to build. reply cqqxo4zV46cp 7 hours agorootparentprevThis is a great way to avoid voicing constructive criticism about IAM that doesn’t end up being “hard-code it for my use case at the expensive of making it difficult for a significant portion of other customers”. reply rirze 3 hours agoparentprevIn my experience, it's fine. I just wish it supported more condition keys across all services. Nothing sucks more than to write a policy with a explicit condition only to bash your head trying to figure out why and then finally realize that restricting for a specific tag for a specific resource+action is not supported. reply ak217 1 hour agoparentprevI'm not sure how IAM is any more difficult or harder to comprehend than any alternative. I've been using AWS since 2010 and frankly IAM has never been an issue. Can you give some examples? In any case, IAM and its essential features are not some optional thing; it's actually the prerequisite for AWS existing in its current form. IAM is the most universal AWS service - every other AWS service must use it. It's a loosely coupled symbolic policy computation engine for federated identity and service permissions. The \"federated\" part is doing A LOT of heavy lifting here: without federation, it's impossible to decouple teams and achieve the organizational velocity that AWS has. Other cloud providers have ended up re-inventing AWS IAM, sometimes poorly. Although I have to give GCP credit for recently greatly improving their IAM console and permissions error usability. reply lijok 7 hours agoparentprevCedar, the new language by AWS that's currently used by Verified Access, is looking good; https://www.cedarpolicy.com reply egorfine 5 hours agorootparentTheir mere description on that page makes me shiver. reply rirze 3 hours agorootparentprevthis is application side, correct? reply js2 4 hours agoparentprevIAM is conceptually straightforward, but it's combinatorial difficult with all the different ways that AWS services interact with it. Support for IAM is also inconsistent across services. I'll give a recent example. I have EC2 Mac instances in an autoscaling group that are running untrusted code. I've \"sandboxed\" that code by running it as its own user and blocking that user from reaching the IMDS endpoint with a packet filter on the instance so that the untrusted code, in theory, cannot get instance policy credentials. Nonetheless, I'd like to limit the blast radius should the code somehow escape that sandbox. So I want the instance policy as restricted as possible. One of the things the instances need to do is set tags on themselves. For this, you can use an IAM condition on the ec2 CreateTags action to say \"this instance can call CreateTags, but the instance ID has to be the instance itself\". This prevents an instance from setting tags on a different instance in the same autoscaling group. The instances also need to make a few autoscaling API calls, to complete lifecycle actions (CompleteLifecycleAction), and to enable and disable scaling protection (SetInstanceProtection). Here again, I'd like each instance to only be able to make these calls against itself. Unfortunately, there is no condition you can use with the autoscaling API to similarly limit the calls as you can with the ec2 API. The same condition that works with the ec2 API doesn't do anything with the autoscaling API. Not helping matters, the documentation is very spread about. Just in the use case I describe above, you need to read at least all of these: https://docs.aws.amazon.com/service-authorization/latest/ref... https://docs.aws.amazon.com/service-authorization/latest/ref... https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-au... https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-poli... https://docs.aws.amazon.com/autoscaling/ec2/userguide/contro... reply koromak 5 hours agoprevThe best part of any new stack: Spending 4 days repeatedly destroying and creating it while you figure out a single god damn policy to add to the project at a time reply Aeolun 2 hours agoparentStill better than just giving it all permissions to be done with it? At least it made me feel a little bit happy when I did this the first time. reply tobilg 3 hours agoprevI publish a daily updated AWS IAM dataset at https://github.com/tobilg/aws-iam-data as well as historized managed IAM policies at https://github.com/tobilg/aws-iam-managed-policies There's also https://www.awsiamdata.com/ which analyzes the AWS IAM data and also contains a changelog. Maybe this helps some people. You can also query the data from your browser: https://tobilg.com/chat-with-a-duck#heading-explore-aws-iam-... reply redeux 3 hours agoparentThanks for sharing this! Very useful data. The contrast on your dashboard at https://www.awsiamdata.com/ makes it almost impossible to read. You may want to take a look at that. reply tobilg 3 hours agorootparentThanks for the feedback, are you using dark mode eventually? reply Aeolun 2 hours agorootparentIt’s night here and dark mode is on. Some things get darkified, but especially the text stays white and is displayed on bars that are nearly white. reply playingalong 2 hours agoparentprevYou might consider adding git-scraping label to your repo. reply otteromkram 3 hours agoparentprevThis is interesting. Is it just a reference package for npm? As in, you can't set/update policies with it or do other IAM ops with it, correct? reply tobilg 3 hours agorootparentExactly, it's \"just\" extracting the AWS IAM data from the publicly available documentation, stores it in multiple formats and publishes a NPM package containing the data with some wrappers/accessors, so that people can theoretically leverage it to build their own tools. reply bscript 18 hours agoprevSometimes, reading AWS IAM policies can be tough for me. I prefer visuals, so I often use the IAM Policy Simulator. To make things even easier, I built a small tool that turns IAM policies into simple graphs. awsviz.dev is a good tool designed to help users visualize, analyze, and improve their AWS IAM policies. More details: https://medium.com/@Bohr/introducing-awsviz-dev-simplifying-... reply lhousa 14 hours agoparentJust skimmed through the post but how is it different from a plain json visualiser like https://jsoncrack.com? reply kaladin-jasnah 15 hours agoparentprevShould this be a \"Show HN\" post? reply bscript 12 hours agorootparentFirst time here, did not know about Show NH reply itscrush 5 hours agorootparentWelcome, it's detailed here; https://news.ycombinator.com/showhn.html worth considering a post. reply dandrew5 5 hours agorootparentprevNew Hackers, I like it. A Hacker News clone strictly for new developers. Instead of articles, the links just map to posts on r/programmerhumor Welcome btw! reply ckozlowski 5 hours agorootparentprevWelcome! reply rafaelturk 5 hours agoprevThis like this is what made us leave the cloud and go back to our own private cloud. reply glzone1 2 hours agoprevIsn't there a way to basically give your project root in a separate account, then use cloudtrail to figure out what policies it actually needs? I've not been able to get that going myself but it seems like a more efficient approach potentially. reply turtlebits 59 minutes agoparentYou can use Access advisor to see which service your IAM role/user has accessed and when. You can then prune permissions which haven't been recently used. reply bdcravens 14 hours agoprevPerhaps it would make sense to link to the repo on the page? As best I can tell, you can easily self-host your tool (would need to update the redirects in the index.html). https://github.com/BourAbdelhadi/awsviz reply ckozlowski 5 hours agoprevVery cool. What are you using to rate severity in the security scan? Is there a full list of checks being performed? I recommend having both resources in your documentation. If you're referencing another document, link to it. That way there's some context to the results as to why a policy author should change it. Just something to add to the improvement list. Looks good overall! Thanks for sharing! reply nerdjon 6 hours agoprevIs there somewhere that outlines what is done with the uploads or is this all client side? I am reluctant to just upload an IAM Policy when that could include bucket names, databases, account names, etc. Things that could expose more information than I would like (both security and product related) reply bscript 6 hours agoparentClient side only, you can check the github repo reply nerdjon 6 hours agorootparentAhh thank you, I did not realize this was open source. I might recommend putting a link to the github repo at the top or something, unless I am just looking right past it I don't see that anywhere (the most I see is the github script to copy) reply bscript 5 hours agorootparentWill add the link to the website ;) reply l3x4ur1n 15 hours agoprevFirst thing that came to me after reading the url https://en.m.wikipedia.org/wiki/Auschwitz_concentration_camp reply egorfine 9 hours agoprevOkay, so I have no idea what to do with that web. I copied one of the complicated policy JSONs from AWS, now where do I paste it? What's there to upload? In zip? reply bscript 9 hours agoparentpaste it to the IAM Policy JSON input or zip your json files and upload the zip. reply egorfine 9 hours agorootparentAh, I can see you added JSON input. Tried it. It looks like the \"The user is allowed to:\" part is the most important one and should be on top. The graph visualization does not make any sense on my random JSON policy I have just pasted. reply bscript 9 hours agorootparentyou can move the section to the top, just drag and drop. reply timendum 10 hours agoprevI think Policy Details card should have a scrollbar, but it is set to \"overflow: hidden\". reply bscript 10 hours agoparentGood point. Thanks reply Dowwie 6 hours agoprevIs this a claude artifact? reply JustAnotherJeff 4 hours agoprevYou just made me want to stop lurking and register to say Thank You. I have a bunch of users that keep producing blatantly wrong IAM policies, I hope such visualisation will help putting some sense in what they write. Very good and straightforward - thanks a lot for providing the GitHub repo as well as I would never tell them to paste policies on a random website. reply zarzavat 13 hours agoprevThis is a very bad name for a product. reply linkgoron 9 hours agoparentyes, I immediately thought that the pronunciation was Auschwitz... reply bscript 12 hours agoparentprevYou might be right. My focus wasn't on the name; I just wanted to create something useful for my day-to-day job and share it with others. The goal was never to commercialize the product … so maybe that’s why the name was bad! reply sclangdon 11 hours agorootparentHe may be referring to the fact that it could be pronounced Auschwitz. I must admit, my immediate thought on reading the name was \"why would someone name their app after a concentration camp?\" reply bscript 11 hours agorootparentwow, I learned something new today reply dgb23 10 hours agorootparentI had the same reaction. Even just a hyphen between like aws-viz would probably do wonders. reply zarzavat 9 hours agorootparentYes I think any minor tweak would remove the effect. awsvizul, vizaws, awsvista. It’s just a bit too on the nose at present. reply bn-l 7 hours agorootparentprevThis is also what I immediately saw and heard also. reply cyberax 13 hours agoprev [–] IAM policies can be so complex, that become close to unusable. Use multiple AWS accounts, and keep your policies simple. One account for DB, one for the backend servers, etc. Each environment (prod, staging, dev) also gets its own set of accounts. This way, a misconfigured policy won't give admin access to everything. reply potamic 13 hours agoparentWouldn't that lead to cross account policies, which appear to be even more quirky? reply cyberax 50 minutes agorootparentIn my practice? Not really. For resources like databases, you don't need cross-account access if you're using internal DB authentication systems. For IAM-based DB authentication, you can simply write policies to trust the target accounts. Occasionally, you'll need to create a cross-account trust (via AssumeRole), but it's not at all that frequent. My personal wish is for AWS to allow account _names_ instead of ID numbers in policies. reply devonkim 8 hours agorootparentprevYeah, error messages start to become more opaque as well which makes debugging even tougher, which is kind of the opposite of the point of using multiple accounts. But really, AWS not having proper namespaces in its constructs that’s ubiquitously supported (IAM paths were attempted. Attempted) hampers a lot of things reply shakiXBT 11 hours agoparentprevHaving one account per database/backend/frontend is not only overkill, but actually a bad practice. You're going to have to expose your DB to the internet instead of having everything inside a single VPC. What you should do instead is have one account per environment (as you said). reply cyberax 1 hour agorootparent> Having one account per database/backend/frontend is not only overkill, but actually a bad practice. That's how AWS works internally. A team can easily have several hundred accounts: one for each region, and for each env. You absolutely need tools to manage them, and AWS is not great in this regard. IAM Identity Center is a good first step, but its usability sucks compared to the AWS internal tool (called \"Isengard\"). > You're going to have to expose your DB to the internet instead of having everything inside a single VPC. There are several ways to NOT do this. The easiest one is to use IPv6 with your own block (you can get it from ARIN for around $100). Then split it into \"public\" and \"private\" subnets, and install a network ACL prohibiting external connections into the private subnet. reply tenplusfive 11 hours agorootparentprevI've recently stumbled upon the possibility to share a VPC and use one VPC with multiple accounts: https://docs.aws.amazon.com/whitepapers/latest/building-scal... I'm honestly not sure if thats a great idea, but this might be a possible way to do one account per DB/backend/frontend in a somewhat sane way. reply thedougd 6 hours agorootparentI do this. Technically you share the subnets. It's a fantastic pattern and enables greater autonomy for application teams. They're given an AWS account per app environment (e.g. WidgetApp Test, WidgetApp Prod, etc) and are able to build their stuff and attach it to existing subnets without a care about 'how' it communicates with the Internet or the greater organization. reply lijok 7 hours agorootparentprevIt's a great idea if you know how manage it. This is current recommended practice for corporate. Single Network account that interconnects everything and dishes out subnets to other accounts for use exclusively by them. reply shakiXBT 6 hours agorootparentprevoh, that's cool, I didn't know that was possible. That said, I still think it's overkill and doesn't bring any real benefit? Sure you're reducing the blast radius of a security breach, but are the overcomplications worth it? Also, you now have to manage multiple accounts with multiple policies and users / roles, won't that extra complexity actually increase the attack surface? reply LilBytes 10 hours agorootparentprevIt's fine, but you're going to attract a lot of network costs bridging data between AWS accounts. Generally I'd stick to accounts per environment, you'll be worrying about a lot more when you get to FAANG scale. reply visualphoenix 7 hours agorootparentSharing a VPC between accounts with AWS RAM incurs no network costs between the accounts and greatly simplifies AWS networking. Additionally you can share and re-use security groups from the shared vpc across account boundaries. reply chippiewill 3 hours agorootparentprevWe use peered VPCs at work. We have a central account per environment that has the VPC that's shared to all the other accounts in that environment for databases etc. To be honest, I'd probably prefer a single account per environment. But managing the IAM for that would be much more work. reply Hikikomori 11 hours agorootparentprevYou'll find that a plan like this is not overkill once you outgrow single accounts. Though I would do one account per system with Shared VPCs instead. reply kroolik 11 hours agorootparentprevYou can peer-connect vpcs cross-account reply dilyevsky 11 hours agorootparentUp to 125 peers before you have to setup a transit vpc which is a lot more complex reply Hikikomori 11 hours agorootparentTransit gateway can have 5000 VPCs connected in a region, and you have multiple TGWs. And rather than have a VPC per account you can use Shared VPCs instead. reply laurent_du 11 hours agoparentprevI honestly can't imagine a situation where this would be a good advice. Can you give an example of such an IAM policy? reply cyberax 57 minutes agorootparentFor example, if you want your CI/CD to deploy to CloudFormation and allow it to generate IAM resources, then it's essentially root-level access. Because you can simply create an IAM role that gives admin permissions to you. Or even without that, there are plenty of footguns. AWS has a good blog post: https://aws.amazon.com/blogs/security/protect-sensitive-data... reply Hikikomori 11 hours agoparentprev [–] One account per system and environment with shared vpcs is great. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Awsviz.dev simplifies AWS IAM policies by visualizing them, addressing the common issue of IAM's complexity.",
      "Users share experiences of IAM's steep learning curve, with some resorting to insecure practices like using root credentials, highlighting the need for better tools.",
      "The tool converts IAM policies into graphs, making them easier to understand, and its GitHub repository is available for those concerned about security."
    ],
    "points": 152,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1720571748
  },
  {
    "id": 40925906,
    "title": "I made a Note-Taking app for people who keep texting themselves",
    "originLink": "https://strflow.app",
    "originBody": "This project began when I realized that despite trying many fantastic note-taking apps, I often defaulted to dumping notes into chat apps like Slack or iMessage. I wanted to bring that effortless “text yourself” note-taking experience to a dedicated note-taking app.Originally developed as a macOS app, Strflow is now also available for iOS. Strflow is designed to make note-taking as quick and intuitive as possible, centered around a chronological timeline UI.Here are some of its features:* Tag system* Rich editor with text formatting, images, and note linking* Global shortcuts for quick access* Share extension* Encrypted iCloud backup & synchronization (becomes end-to-end encryption if you enable iCloud’s Advanced Data Protection)Hope you find Strflow interesting. I’m happy to answer any questions.## Some implementation details some of you might be interested in:* The app is implemented natively using Swift.* On macOS, it’s based on AppKit, and on iOS, it uses UIKit, with SwiftUI used partially.* The editor intensively utilizes TextKit.* The sync engine is custom-built using CloudKit.",
    "commentLink": "https://news.ycombinator.com/item?id=40925906",
    "commentBody": "I made a Note-Taking app for people who keep texting themselves (strflow.app)149 points by eguchi1904 7 hours agohidepastfavorite136 comments This project began when I realized that despite trying many fantastic note-taking apps, I often defaulted to dumping notes into chat apps like Slack or iMessage. I wanted to bring that effortless “text yourself” note-taking experience to a dedicated note-taking app. Originally developed as a macOS app, Strflow is now also available for iOS. Strflow is designed to make note-taking as quick and intuitive as possible, centered around a chronological timeline UI. Here are some of its features: * Tag system * Rich editor with text formatting, images, and note linking * Global shortcuts for quick access * Share extension * Encrypted iCloud backup & synchronization (becomes end-to-end encryption if you enable iCloud’s Advanced Data Protection) Hope you find Strflow interesting. I’m happy to answer any questions. ## Some implementation details some of you might be interested in: * The app is implemented natively using Swift. * On macOS, it’s based on AppKit, and on iOS, it uses UIKit, with SwiftUI used partially. * The editor intensively utilizes TextKit. * The sync engine is custom-built using CloudKit. dewey 5 hours agoThis somehow seems to be a solution in search of a problem. The reason people use self texting is that they _don't_ want to use another app. Not because the existing apps are somehow missing features. > I often defaulted to dumping notes into chat apps like Slack or iMessage What makes you think people think differently about this app? If people wanted all these features they would already all be covered by Apple Notes (Including the quick note feature, included in the OS when you mouse into the bottom right corner of your screen) but for free, encrypted and synced to all devices. reply golly_ned 4 hours agoparentI text myself notes, and it’s not because I don’t want to use another app, but because I like the streaming append-only log style of notes. I don’t like how hard it is to search through them stores in iMessage. I’ve thought about building an app like this, just since I haven’t been able to find one. So the problem does exist, though it’s not for you. And it’s plainly not the case that if people wanted these features they would be built into Apple apps. There is a massive ecosystem of iOS apps for exactly the reason that the Apple apps don’t cover everything. Same for any case where there’s a startup vs. an incumbent. reply alsetmusic 57 minutes agorootparentI email myself notes and reminders as a way to time-shift them. I send to my work account so that I see them the next day, as I don't have a position that requires me to be available or respond during off-hours. It's a way to reduce how many reminders I have blasting notifications on my devices, a sort of mental cheat / hack by spreading them out. The only time I text myself is to get data from a personal device and a work device. All my \"real\" notes still go in a plain-text Simplenote document that syncs between my devices. I've started using Apple Notes just in the last few months even though I've had access to the app since its inception (call me old-fashioned and a curmudgeon about plain-text, I guess). reply pdimitar 4 hours agorootparentprevSure, but I just use a personal Telegram channel for this. It's quite well-searchable too, and it serves me 95% perfectly. reply mmcclure 2 hours agorootparentThis is my flow too. I know it’s silly, but 90% of why I pay for premium is just for the tags in my saved notes messages. reply IOT_Apprentice 1 hour agorootparentprevWhat about using a discord server? reply suriya-ganesh 1 hour agorootparentDiscord is much much slower than the telegram client IMO reply dheera 1 hour agorootparentprevI just use a 1-person Slack message for this. Split categories into channels. I can also write my own plugin bots to respond to specific queries. I considered Discord but I hate its UI, especially every time I go to the website it wants to do a phone verification. F that, I'm out. If you are a nonessential \"fun\" app you need to be as low friction as possible. reply sensanaty 54 minutes agoparentprevI write \"notes\" to myself all the time not because I don't want to use another app, but because I prefer the chronological, quick way that those kind of notes work. I'm too chaotic for regular note taking, I've tried a million times, so for me the flow of just dumping a stream of consciousness down for me to read through later on works much better than trying to organize dozens of files. I'll definitely be checking this app out, personally! reply arjvik 38 minutes agorootparentWhat I'd love (and what has been on my to-do list of things to write) is an app that I can literally text, which takes my notes and collects them somewhere. Would love to get some real searchability, etc while still not needing to launch something seperate to send notes! reply pjot 47 minutes agorootparentprevSame here - I’ll typically leave my message to myself as unread as a visual reminder to go back to it. reply eguchi1904 5 hours agoparentprevI understand your point. For me, though, existing apps like Slack or iMessage were insufficient because, at the end of the day, they aren’t “note-taking apps.” By creating a dedicated note app combined with a chat-style timeline-focused UI, I feel that the speed and quality of note-taking have improved. However, I understand that it might not be for everyone, and I appreciate your feedback! reply JohnFen 4 hours agorootparentIt is really interesting how different people are in their preferred solutions. The thing that I've learned makes an application good for note-taking is a lack of features. Simplicity is key for this use case for me. Even on the desktop, my \"note-taking\" app is just notepad on Windows, kwrite in KDE, and a very bare-bones text editor on my phone. None of this is even remotely a criticism of your effort. I was just pondering how different people can be in their needs. reply dylan604 4 hours agorootparent> The thing that I've learned makes an application good for note-taking is a lack of features. The best featureless app I've ever used for taking notes is the pen and paper sitting next to me for the specific purpose. Admittedly, it's not convenient at any time other than sitting at the desk and focused. There are plenty of studies about the process of writing notes vs typing notes when it comes to long term retention. There are times where I'm wrestling with a problem that is just a bit more data than my L1 cache (my head) can remember and need to offload some of the data to RAM (scratch pad), but I can just jot down the data without actually looking at it. Even being able to try to sketch data has helped. I have yet to ever find an app even remotely as effective to the point, I'm stopped trying anything else. If it ain't broke, don't fix it. reply JohnFen 4 hours agorootparent> The best featureless app I've ever used for taking notes is the pen and paper sitting next to me for the specific purpose. True! At work, I carry a pencil and small notepad for this reason. But outside of work, I don't always have one at hand and so other methods come into play. reply eguchi1904 3 hours agorootparentprevThank you. I can relate to the importance of simplicity. When there are too many features, I find it distracting and difficult to focus on the content I’m writing. There really are so many different needs when it comes to note-taking apps, including my own. This discussion has highlighted that for me once again. reply benatkin 1 hour agorootparentprev> I feel that the speed and quality of note-taking have improved In your case you’ve gotten over any learning curve and you’re accomplishing three things at once - taking notes, testing your app, and giving yourself satisfaction that you’ve built something you can use, so of course it’s going to feel better! But it’s more important what potential users think because they’re less biased and there’s more of them. However you seem to be at least slightly dismissive here. reply Dwolb 5 hours agorootparentprevHonestly I love the direction and I do this all the time. If you could 1) integrate directly with iMessage so I'm literally just texting and 2) have your interface provide me some sort of LLM summary tool/weekly digest/remind me of things smartly (I dunno it's up to you to figure out), I'd probably do this. reply eguchi1904 4 hours agorootparentThank you! 2) is an interesting idea. I plan to add functionalities that can smartly suggest and categorize notes in the future. Thanks for the suggestion! reply j45 2 hours agorootparentprevIt's also a form of journaling throughout the day whether it's a note, thought, reflection. reply hexmiles 5 hours agoparentprevAs a counter: I love the concept, I often message myself not because I don't want to use another app, but because I like the workflow and the UI. Most notes app work with a concept similar to files organized in a structure (be tags or folder) instead chat app are primarily chronological, also the UI is more oriented for quick addition than most note's app; I get that this don't make sense for everyone but an app like this is exactly what I want. reply realjohng 56 minutes agorootparentFor a note taking app, launch speed is critical. Keep it super fast. reply eguchi1904 3 hours agorootparentprevThank you, your kind words are very encouraging. Your perspective closely aligns with the issues I was trying to address. reply codegeek 4 hours agoparentprevNot always. I do text/slack myself to make a note at times because it is the fastest way to log something and come back to it later. If a tool creates a note out of it with all the other goodies, it may not be a bad thing. I however agree that I have to test something like this but having lost my mac notes recently, I am seriously considering a notes tool that is super easy to log. reply havefunbesafe 4 hours agoparentprevI think the problem was OP wanted to build an app, and the solution was building the app. Totally fine! reply dewey 4 hours agorootparentThis is fair, and I've done a fair share of that myself! reply whalesalad 3 hours agoparentprevI actually want an app like this, but I want something cross platform and web based so I can use it on mac/linux/phone. reply j45 2 hours agoparentprevNot always. There's an app called Voiceliner that is quite decent for a different use case but capturing notes nonetheless. Audio notes are usually much quicker than typing on a phone. Helping people capture their thoughts happens in many ways, and it's valid. I have been using apps like this for a very long time, and it's an unfair advantage because it can seem like I don't forget much, when really I reinforce remembering it by recording it somehow and working through actioning it (or sharing it to get help) reply HarHarVeryFunny 5 hours agoparentprevYeah - another place to have to check for messages seems to be cluttering mindspace rather than helping. What might be useful, if done well, would be adding tags to messaging similar to GMail's use of tags in lieu of folders, as a way of grouping related messages (e.g. notes to self). OTOH, maybe with message search, perhaps \"AI\" assisted, it might not be needed. One use case for this sort of occasional \"notes to self\" and later search/gathering that I've been thinking of recently is for a shopping list, but it would have to involve basically zero effort to be useful. The idea would to allow you to say things like \"shopping list: milk, bread\", then next day \"shopping list: cat food\", then next day \"show shopping list\", or something similar. reply hnbad 5 hours agoparentprevAnother benefit is that self texting means you have access to your notes wherever you have access to your messages. Using another app makes that more tedious. reply hartator 5 hours agoparentprevYeah, Slacking one-self is reassuring because you Lonnie it won’t be lost or forgotten. reply keb_ 4 hours agoparentprev100% this. OP, please remove your post. Your idea and your app are useless. reply allenu 2 hours agoprevThis is really cool stuff, OP. Congrats on the launch! I like that you've taken an actual problem or use case you have and turned it into an app. I love seeing how other people solve similar problems. I've seen this other project [1] that is similar in idea, but the author there has opted to go for something that looks literally like a texting app. Yours looks more Slack-like, just going by the Mac version. Likewise, I also wanted to create an app for keeping track of short notes, but I thought it would be neat to give it the UI of something like Twitter or Tumblr, so I built Minders. [2] I have to admit that not all the design ideas in my particular app work quite well together yet (such as \"hearting\" and replying to your own posts), but I do end up using it regularly for journaling and keeping track of interesting links. [1] https://zhenyi.gibber.blog/gibberish-is-now-available-on-tes... [2] https://minders.ussherpress.com/ reply wonger_ 2 hours agoparentAnother chat-like notetaking app I saw posted a while ago: https://site.ducknote.app/ That one reminds me a bit of Discord. Love the design of yours, though. reply entropyie 4 hours agoprevMy number one problem with notes apps is that they all take too long to open a new note, and try to sync themselves when opened, often slowing everything down. Especially if you have a slow / choppy connection (fully offline is usually ok, but barely online is the worst). I have a literal supercomputer in my pocket, yet not one app let's me open and start writing a critical note in less than 500ms. To this day I still use plaintext editors on my desktop to dump short strings or notes into, because they load faster than any other app. And don't try to be clever with smart quotes, fonts and butchering my code snippets. reply vladxyz 1 hour agoparentJust as a counter-example, my workflow works very quickly for me: On mobile, my launcher has four pinned favorites on the homepage - one of which is a shortcut to go straight to the new note activity in my notes app. From typing up this comment I can swipe up to home and touch that button in (probably?) under 500ms and type in a new note. (launcher = KISS Launcher, notes app = Joplin. though I'm sure similar things work with other launchers and note apps.) It is unfortunately an electron app on desktop, but I'm invested enough that I never close it, and can start a new note just as quickly (super + 1 to launch it from my task bar, ctrl+n to start a new nearly plaintext note). This is the same on my windows and Linux computers. MacOS (as it is with most things) is somewhat more annoying: I keep a Space dedicated to Joplin and never collapse to the icon, which allows me to similarly go two chords - ctrl+9, cmd+n - to a new note. Joplin doesn't need sync to complete before opening a new note. reply sturza 54 minutes agoparentprevI had the same speed issue and i solved it using email drafts. They sync automatically and i have rich text. reply rsanek 2 hours agoparentprevtry Google keep. there's a shortcut you can make that with a single tap from the homescreen creates a new note and brings up your keyboard for typing. after you're done you don't have to even click save to persist it. it also auto syncs in the background. I've been using it on iOS for years reply kwhitefoot 1 hour agorootparentAnd you can invite others to share a note and edit it together in real time. My family uses this feature for shopping lists. Any of us can add things to the list and when one of us does some shopping they just trick the items off. And it works offline and in the web browser. reply happyopossum 2 hours agoparentprev> yet not one app let's me open and start writing a critical note in less than 500ms IME Apple Notes does this with Quick Notes (accessible a bunch of different ways depending on platform) on iOS and macOS. reply wonger_ 2 hours agorootparentWhat are the different shortcuts/ways to open Notes? And do you know if these shortcuts are available for other app developers, or are they dedicated solely to Notes? Just curious reply jwr 2 hours agoprevI like it a lot. I currently mostly use Simplenote for quick note taking, but that often takes too long and I have to come up with a \"note title\", which I do not like. I just want to jot something down, quickly. I'll be trying this over the next couple of days. My immediate worry is that the app will not find its business model and will get neglected and then disappear in a year or two… reply eguchi1904 1 hour agoparentThank you! I felt the same way about note titles, which is why Strflow intentionally adopts a style without them. Developing Strflow has been very fulfilling for me, and I plan to continue its development regardless of revenue. Of course, I aim to grow the number of supportive users and make it sustainable as a business. reply andrei-akopian 3 hours agoprevI read through the comments, here are the \"core\" issues/features an app like that has to meet: - 1. Fast startup - 2. Fast adding an extra note - 3. Editing - 4. Sync - 5. Crossplatform - 6. Easy to forward messages - 7. Stable/Trusted/(Encrypted?) 2, 4, and 5 are the main ones probably - Telegram lacks 1 (fyi I use telegram) - WhatsApp lacks 1 and kinda 3 - Discord lacks 1 2 and 6 (I don't remember discord working well offline) - All other note apps lack 2, 4, and 5 (core features) and focus on markup instead. Feature 1 - fast startup seems to be the only problem with existing messengers. The best solution would be a custom crossplatform telegram client or similar that piggybacks off existing trusted messengers for sync etc. reply jskherman 2 hours agoparentI think Telegram is plenty fast enough re:(1) on Android especially with a Home screen shortcut to your private Channel. It just gets quickly cluttered with mixing messages and file uploads. reply andrei-akopian 1 hour agorootparentThis means we need to add management features without removing any of the above. reply Tiberium 5 hours agoprevTelegram's Saved Messages (essentially self-texting) is also commonly used for saving info, somewhat recently they even added tagging and the ability to view messages that you forwarded into there per chat (so you can see all messages that you ever saved from some group you're in). Of course it all lives on their cloud and is not local. reply bayesianbot 5 hours agoparentThough tagging is only available for the (kinda pricey) Premium subscription. reply eguchi1904 4 hours agorootparentTagging is actually available for free, so just wanted to correct that. reply bayesianbot 4 hours agorootparentHuh? I just tried tagging a message, which opens a popup for Telegram Premium. Also web search brings up \"Tags are already available to all Telegram Premium users.\" from Telegram website - it's an old post, but I don't see anything anywhere that says otherwise. Or do you mean #hashtags? reply naught0 2 hours agorootparentThey're (OP) almost definitely referring to their own service which has tagging built in for free. reply compootr 5 hours agoprevThis sounds like memos[0] with the asterisk that I must pay the apple corporate overlords to use it, trust you with my data, and ultimately lock myself into what you allow me to do with my data memos is FOSS, and I run it on my machine, without the need to trust you. it also has a nifty API around it [0]: https://usememos.com/ reply toyg 5 hours agoparentA self-hosted docker-based system has a different audience from an Apple AppStore app. Don't be that \"dropbox is just ftp and rsync\" guy. reply quaintdev 5 hours agoparentprevLove memos. I've it running on my Pi server and it's really good. It doesn't get in the way of note taking. After a while you forget about app itself and just get used to the interface for noting things down. reply blackbear_ 4 hours agoprevApologies for the self-promotion, but as several people here mentioned Telegram already... From a similar motivation of minimizing friction when taking notes, I created a Telegram bot that saves all messages you send it into a Google Spreadsheet. Hashtags can be used to split the text into columns, if so desired. Besides jotting down quick thoughts, this is very handy for short-form journaling such as tracking expenses, workouts, mood, period, etc., with the added bonus of easy charting and summarization from within the spreadsheet. It also supports pictures and other attachments that are uploaded automatically to Google Drive. Feel free to check it out, all feedback is appreciated: https://t.me/gsheet_notes_bot reply sintezcs 3 hours agoparentLooks really interesting! Is it open-source? I’d probably prefer to spin up my own bot instance, if it is possible reply al_borland 4 hours agoprevI used a journal app that worked like this for a little while. I ultimately stopped for a couple reasons. 1. It didn't allow editing of past posts. It was on the roadmap, but never came. To fix a typo or something, I'd have to copy the note, paste, fix, post again, delete the bad one. 2. I was always worried about putting anything important in there, as longevity was always a question. There was an export option, but if I remember correctly, it was in JSON. Which is fine I guess, but the idea of having to write some kind of parser to take that and turn it into something I'd actually want to put into whatever solution I might have in the future kind of annoyed me. Does your app allow for editing past posts? How is data stored, markdown in a folder I can simply browse, or some kind of DB? reply eguchi1904 4 hours agoparentYou can easily edit both the date and content of past posts. Notes are stored locally in a SQLite database. You can also export your notes in JSON format from the macOS app by going to the menu bar and selecting File > Export. I plan to extend the export options in the future to support other formats like markdown. Regarding privacy, it is my top priority. Data stored in the cloud is encrypted with your iCloud Keychain, and I have no means of accessing it. If you enable iCloud’s Advanced Data Protection, it becomes end-to-end encrypted, so even Apple cannot see your data. For more details, please check our [privacy policy](https://strflow.app/privacy-policy). reply nusaru 4 hours agoparentprevTo answer your first question: no, past posts can’t be edited (at least not in the iOS app). Answer to second question: https://news.ycombinator.com/item?id=40927209 reply eguchi1904 4 hours agorootparentTo clarify, you can edit past posts in the iOS app by tapping on them. reply kirubakaran 4 hours agoprevIt looks great! I'm building https://histre.com/ and I find that some people do prefer to use a chat app they're already using. I built a Telegram bot so that they can keep taking notes on Telegram and not have to switch, but still get all the benefits of a real knowledge tool: https://histre.com/features/take-notes-with-telegram/ Perhaps you could build something like that to ease the transition? reply dewey 2 hours agoparentLike the other commenter I also had a very hard time connecting your main landing page to that Telegram feature. I even checked if you accidentally posted the wrong url. A lot of landing pages (especially built by technical people) have the same issue, they list a bunch of \"features\" but don't talk about the actual problem that is being solved. reply kirubakaran 2 hours agorootparentYeah that's 100% my problem. I'll work on it. I really appreciate the feedback. reply justusthane 3 hours agoparentprevThis looks potentially neat, but I'm having a ton of trouble figuring out what this actually _is_ from your website. reply kirubakaran 2 hours agorootparentThanks, I need to fix that. It is primarily a knowledge management tool with a ton of integrations to get data in, and also get it out easily, has powerful search etc. reply bonaldi 5 hours agoprevQuick thoughts: - This is a good fit for how I manage to-dos: a stream of actions that I can tag and process. But with no simple way to remove a tag or mark a thing as \"done\" I can't filter the tag streams and see only undone items - £14.99 to use Apple's iCloud syncing which a) I already pay for and b) is free to you feels a bit much. reply dchest 4 hours agoparent\"- £14.99 to use Apple's iCloud syncing...\" Obviously, this isn't priced based on the cost of materials. Almost no software is. reply srid 3 hours agoprevVery interesting app. I wish there existed more \"timeline-based note-taking\" apps. Are there any plans to let the user \"aggregate\" these notes in some form over time? cf. \"Fold\" idea in https://github.com/srid/chronicle?tab=readme-ov-file#folds reply eguchi1904 2 hours agoparentThank you! I plan to implement features like a calendar view to make it easier to review notes over time. The “Fold” idea in Chronicle looks quite interesting. I’ll try it out to see how it works. Thanks for the suggestion! reply tylerdinner 2 hours agoprevPersonally I love this concept! Looks really well done and I would pay for it once in a heartbeat, but the subscription requirement is an immediate deal breaker for me. This looks like a $2.99 - 9.99 one time purchase. I also don't understand the name. reply inheritedwisdom 11 minutes agoparentSame here I’d pay 25$ one time but won’t touch a subscription service unless there’s an ongoing cost associated with its use. reply tamimio 2 hours agoprevWhat I personally do is just send them to myself in SimpleX or Telegram, and they are available immediately on other platforms. reply ramon156 5 hours agoprevThe whole point of self texting is that its easy, quick and just works. If I don't have an apple product, I already can't access this app. Cool idea but not very useful when the labor is there. reply dougdimmadome 5 hours agoparentI get your argument but I see real value here. Texting yourself is an imperfect solution to the problem. Note taking apps like obsidian also have \"labor\" in that you have to pick a location for your note, maybe navigate a folder structure etc. This is a \"stream\" of notes which is closer to how some of us work. I sort of want my reminders to disappear upwards into the past and not clog my interface, but still be searchable. reply attilakun 5 hours agoparentprevWhat's the labor? reply vidyesh 5 hours agorootparentUsing yet another app. I use Obsidian, OneNote for note taking and I can easily create a note just for taking quick notes when using my phone but I still self text on multiple messaging apps because those are something I already use, they are quick and simple. Having yet another note taking app just puts my reliance on that app and keeps it for a purpose, it also becomes a barrier of sorts for me to enter quick text, that I now need to do it on separate new app/platform. reply dougdimmadome 5 hours agoprevI've been look for exactly this! (or planning to build it) I abuse the telegram \"Saved\" channel to send myself thoughts, notes, reminders, pics, etc as if I'm chatting to the me who's back at his desk. I wanted to get away from that and not rely on telegram. Unfortunately I'm an android user so I'll probably have to keep using Telegram for the time being. Is there an android client in the works? reply delecti 2 hours agoparentIf you aren't opposed to Google, \"Keep\" seems to be fairly well suited for this kind of thing. You can share to it easily on android, it supports a bunch of organizational things (labels, colors, archiving) but they're not in the way if you want to ignore them, and the browser version works great. If you're attached to the chat style, then it might not be perfect, but it's easy to use it as a continually appended log style experience. reply eguchi1904 5 hours agoparentprevThank you! I can really relate to that habit. Unfortunately, I haven’t started working on an Android version yet, so it doesn’t seem likely to be available soon. Sorry about that. reply J_cst 4 hours agoparentprevSelf messaging is also available in WhatsApp reply NayamAmarshe 3 hours agorootparentYeah but the whole experience of using WhatsApp is kinda sub-par compared to Telegram. reply sva_ 5 hours agoparentprevYou can also message yourself in Signal reply colinflane 1 hour agoprevI created a note with a tag. Then I deleted the note, but the tag remains visible under 'Tags' in the left slide panel. fwiw reply amadeuspagel 5 hours agoprevI made a web app with a similar goal, but with one additional feature: the text field is also the search field, as you type a new note, the existing notes get filtered based on the text of the new note: https://thinktype.app reply wonger_ 2 hours agoparentVery novel feature I haven't seen in other notetaking apps - well done reply the_arun 38 minutes agoprevI slack myself for this purpose. reply NayamAmarshe 3 hours agoprevI actually like saving stuff on Telegram but the only downside is the absence of markdown. But it's not actually that big of a deal. Telegram supports tagging messages, saving files and more. This is why I was creating writedown.app, to have something where I can quickly post my notes like Telegram but not have it turn into another app accounting for Telegram's lack of markdown. reply champagnepapi 4 hours agoprevWow this is pretty cool! I'm gonna give a try. For me, this is actually what most of my slack usage is. Just writing notes to myself and then occasionally messaging others. reply enriquto 5 hours agoprevYou will take self-texting from my cold, dead hands. reply benoliver999 5 hours agoparentSignal has a 'note to self' function and it's perhaps a sad reality that this is my most contacted person reply kirykl 5 hours agoprevThere’s maybe some value in branding as ‘stream of consciousness note taking’ instead of ‘replacing texting’, to which it just adds more steps for the same thing. To replace texting can I text a phone number that feeds into this app? reply knoebber 3 hours agoprevLike any good yakshaving programmer, i built/use my own note taking / TODO app. Now I want to implement a feature where I can send a SMS to my app, and it will save the text/media to my database. Seems like a lot less friction than using the UI on my phones browser if I just need to save a quick note. reply ants_everywhere 4 hours agoprevI use a variety of note taking systems, but one I use for quick notes is Signal. It's always there, syncs to my devices, I trust the encryption and privacy stance, and it has a reasonable search implementation. As a bonus, I can easily forward notes from other conversations, like reminders my wife sends me. reply oulipo 5 hours agoprevThere's also the \"Defer\" app which works both on iOS and osX with a nice UX for quick todos https://apps.apple.com/us/app/defer-task-inbox/id6480421520?... reply PMunch 5 hours agoprevHaven't heard of self-texting before, didn't even know it was possible. But I've been having a similar idea to this based off-of writing in a physical notebook. Basically my notes there end up sequentially, and I was missing this with my digital tools. My idea however was more of a \"book mode\" for a regular note-taking app where notes would be placed one after another on a long scrolling page. reply napbree 4 hours agoprevI like the format, an idea to take unstructured data and try to turn it into a plan (could be a paid extra?) would be for a language model to take a stab of taking the data and turning it into a live contextualised overview per notes. That's then taking the pain away from trying to organise the unstructured thoughts reply vidyesh 5 hours agoprevCongrats on the launch! The app looks simple and good but I struggle with the idea that I need to use yet another app for this. The reason for self-texting is that I am already using that app and now I can send quick notes to myself for later. The odd thing is, I use most and all the messaging apps for this for some reason. My quick notes or links or text snippets I want to store are in multiple apps I already use. Not an app for me but good luck! reply csmeyer 5 hours agoprevI’ve been in the habit of emailing myself a lot, I’m excited to give this a try! I had thought of building this myself, so I’m glad I don’t have to :-) reply rolfus 5 hours agoparentI'm also emailing myself a lot. It works well but every time I do it it feels wrong and shameful. Like, I know there are better solutions but I just won't make the effort. reply eguchi1904 5 hours agoparentprevI’m glad to hear that. I’m relieved we didn’t end up releasing competing apps! reply msravi 5 hours agoprevA couple of questions. The notes seem to be markdown, which is good. But where are they stored? Are they just markdown files stored in an accessible folder? How easy is it to \"export\" the notes? I use \"self-texting\" on WhatsApp for temp notes that I know I won't need beyond a couple of days and don't mind losing and Obsidian for others. reply eguchi1904 4 hours agoparentThe notes are stored in a SQLite database. You can export your notes from the macOS app by going to the menu bar and selecting File > Export. This allows you to export the notes in JSON format, which includes various metadata and markdown representations. I also definitely plan to extend the export functionality to support markdown in the future. reply toyg 5 hours agoprevMy girlfriend doesn't even self-text, she just texts me random stuff on whatsapp followed by \"ignore that\". When I told her about this app, she said it sounds great and she'll check it out. I personally think there is something there. The app-switching problem is real though; maybe it would work better as a Whatsapp/Telegram bot. reply heliodor 5 hours agoparentYou can pin yourself to the top of Whatsapp and write to yourself. Explain that to her. It's what I do and it's been phenomenal. reply toyg 5 hours agorootparentYeah but you're still limited to the chat mode - you can't consume the data in any other way. With a bot, you could provide some sort of other interface - either via bot commands, or an alternative web view, with fancy exports etc. reply farhanhubble 3 hours agoprevSamsung screen off memo with a stylus has been the best note taking app for me. There’s an option to digitise the text and make it searchable. The big issue is it’s not cross platform. reply mraza007 2 hours agoprevThis looks really cool. Out of curiosity how long did it take you to build the application reply eguchi1904 1 hour agoparentThank you! It took about 2 and a half years. I worked on it during my free time alongside my full-time job, so it might feel a bit long. reply nusl 5 hours agoprevCurrently I use a personal Discord server for this. Will give this a shot, seems really useful. reply andai 4 hours agoprevThe key aspect of self texting is frictionlessness. On that note, has anyone used Notational Velocity? I've been looking for alternatives for years and haven't found anything that comes close. reply _flux 4 hours agoprevPretty cool, but I think I'll stick to using Matrix for the same purpose (in particular as I'm not an Apple user). But I admit a custom app would be nice, still using Matrix for storage. reply cpursley 3 hours agoprevThis is neat but I can't seem to get the desktop version to sync - I even upgraded iCloud. reply Void_ 5 hours agoprevI made something similar, except by recording audio memos: https://whispermemos.com/ reply KaoruAoiShiho 2 hours agoprevI just use google keep and apple notes, works fine for me. reply maxpage 5 hours agoprevThere is something in it. I find myself often sending notes to myself on various social media messaging apps :) reply Seylox 4 hours agoprevKind of reminds me also what Google Wave could have been, if it wasn't killed. reply dgid 54 minutes agoprevBuilt in electron? reply hagbard_c 1 hour agoprevOr just send those notes to your own XMPP account where they'll show up as \"Note to myself\" (in Gajim) or something similar in other clients. You get all the facilities your clients offer on whatever platform you happen to be using at that time - web, mobile, desktop, etc. Your data is as safe as your XMPP account is, you can (but are not required to) run your own XMPP server - prosody or ejabberd or something else - on your own hardware on your own connection at home. Cross-platform, free, there are many different clients, standards-based. End to end encryption through OMEMO which works across an ever widening spectrum of clients. Yes, this is similar to the Telegram \"Saved Messages\" feature which is another way of doing this. The advantage of using XMPP is that you can run your own service using free software. Also, should the EU \"Chat Control\" abomination become reality this is one of the ways to avoid having the EU spy on all your traffic. reply flufluflufluffy 3 hours agoprevdo people not know about the built in dedicated note-taking app, literally called Notes, by default on the first page of their home screen reply TuringNYC 5 hours agoprevwhatsapp's and slack's text-myself was such a killer-feature for me! however, i think that was because i was already inside those apps constantly. reply sAbakumoff 1 hour agoprevIn telegram it's called \"Saved messages\". reply jcynix 5 hours agoprevOne more app? I'm skeptical. https://xkcd.com/927/ is about standards, but it could easily be about apps instead. My note taking takes place either classically via email with mutt in a terminal, not with these gargantuan desktop \"apps\", or with existing apps like Blitzmail on Android, or Joplin. Joplin just needs a WebDAV server to store notes and is available for multiple platforms, so I can easily swap notes between mobile and desktop/laptop. reply pshirshov 2 hours agoprevE2EE? reply eguchi1904 1 hour agoparentYes, Strflow supports end-to-end encryption (E2EE) if you enable iCloud’s Advanced Data Protection[^1]. For more details, please check our privacy policy[^2]. [^1] https://support.apple.com/en-us/102651#advanced [^2] https://strflow.app/privacy-policy reply j45 2 hours agoprevCongrats on your launch! Simple and effective capture (ideally as few clicks and taps as possible) from mobile can be a huge enabler to capture those random thoughts that aren't. reply AlecSwanky 5 hours agoprevSounds great, I would use this. Will there be an android version? reply toyg 5 hours agoparent> The app is implemented natively using Swift [...] On macOS, it’s based on AppKit, and on iOS, it uses UIKit, with SwiftUI used partially. So I guess the answer is likely to be no. reply eguchi1904 5 hours agoparentprevThank you! I’d love to work on an Android version if time permits, but currently, it’s a lower priority compared to adding other features. Sorry about that. reply Sakos 3 hours agoprevThis sounds like exactly what I'm looking for, it sounds and looks great. Unfortunately, don't own an iPhone. Any plans to make an Android version? reply greenthrow 5 hours agoprevMacOS and iOS already have the Notes app which already syncs across your devices.... reply cpursley 42 minutes agoparentYeah, and they suck. I have a folder on my iPhone called \"iCrap\" as most of Apples native apps are hot garbage. reply unstatusthequo 5 hours agoprevMaybe rethink the name? People who text themselves can't even think of the Notes app, which is what they are literally making, let alone \"StrFlow\" which will definitely not be top of mind. TxtNote? NoteChat? Note2Self? TextMe? Txt2Self? reply ocular-rockular 1 hour agoprev> Not FOSS > Only Apple ecosystem > Paid tier for local service :| Seriously? reply kekub 1 hour agoparentAs a developer of local applications, I take issue with the notion that apps should be free simply because they don't incur server costs. This argument overlooks several crucial aspects of software development: Development costs: The bulk of an app's expense lies in its continuous development, not in hosting. Even if backend services can be run for a nominal fee, the time and expertise required for ongoing maintenance, updates, and improvements are significant. Value proposition: Apps provide utility and solve problems for users. The price should reflect this value, not just the operational costs. Sustainability: Charging for apps ensures developers can continue to support and improve their products, benefiting users in the long run. Hidden costs: While server costs might be minimal, there are other expenses like development tools, testing devices, and occasional third-party services that add up. reply ocular-rockular 1 hour agorootparentIt's a notetaking app pal, it's not that serious. And certainly not worthy of a subscription model. Kind of ridiculous that they're using this platform as free advertising for what is effectively one of those cashgrab apps. reply EGreg 5 hours agoprev [–] I like the simplicity, and good job for shipping it. “Privacy. Always. We promise” This kind of stuff always gets me thinking. Why should I trust random app developers? I don’t even trust giant corporations with this. I have seen Chrome extensions bought out and silently changed. And I have sold iOS apps myself! Capitalism and Competition and Closed source Centralized software distribution just makes me always worried. Whatever promises are given (“open”AI!) can be either false already or enshittified tomorrow. And then who is foolish for trusting it? https://www.businessinsider.com/well-these-new-zuckerberg-im... Why not use open source? Actually, the main reason is The Web. It doesn’t have an effective way to guarantee a file at a URL will be static, the way, say, IFPS does. And same goes for the App Store. Telegram struggles to tell you how to do verified builds. I think we may need a “trusted app” with IPFS based distribution, and various auditing agencies publicly signing software updates. It doesn’t need to use a blockchain because code only ever accumulates, so it’s a crypto CRDT essentially. But it could be replicated across many networks including DHT based ones like IPFS, Bittorrent and Hypercore. That at least reduces a user’s Trusted Computing Base to the OS and one app (like a crypto wallet or an authenticator or browser) that they trust. There should be a way to never update that app via the app store. Frankly, I think privacy will never get better than that because the manufacturer can technically always exfiltrate stuff (as Windows already does and touted with Recall). But for running TRUSTED PROGRAMS, at least, I feel there can be blockchains and other decentralized networks. Trusted programs (ie smart contracts) are valuable for communities to trust code, even if it doesn’t enforce privacy. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Strflow, initially a macOS note-taking app, is now available for iOS, featuring a chronological timeline UI.",
      "Key features include a tag system, rich editor, global shortcuts, share extension, and encrypted iCloud backup with end-to-end encryption.",
      "Strflow is natively implemented in Swift, using AppKit for macOS, UIKit for iOS, and partially SwiftUI, with a custom-built sync engine using CloudKit."
    ],
    "commentSummary": [
      "Strflow is a new note-taking app designed for users who often text themselves notes, offering a dedicated alternative to chat apps like Slack or iMessage.",
      "Initially launched for macOS, Strflow is now available on iOS, featuring a tag system, rich editor, global shortcuts, share extension, and encrypted iCloud backup.",
      "The app is built using Swift, with AppKit for macOS and UIKit for iOS, and the developer is open to questions and feedback."
    ],
    "points": 148,
    "commentCount": 136,
    "retryCount": 0,
    "time": 1720612475
  },
  {
    "id": 40926734,
    "title": "Vision language models are blind",
    "originLink": "https://vlmsareblind.github.io/",
    "originBody": "Vision language models are blind Pooyan Rahmanzadehgervi1,*, Logan Bolton1,*, Mohammad Reza Taesiri2, Anh Totti Nguyen1 *Equal contribution 1Auburn University, 2University of Alberta, Paper (ArXiv) Code 🤗 Dataset Abstract Large language models with vision capabilities (VLMs), e.g., GPT-4o and Gemini-1.5 Pro are powering countless image-text processing applications and scoring high on existing vision-understanding benchmarks. Yet, we find that VLMs fail on 7 visual tasks absurdly easy to humans such as identifying (a) whether two circles overlap; (b) whether two lines intersect; (c) which letter is being circled in a word; and (d) counting the number of circles in an Olympic-like logo. The shockingly poor performance of four state-of-the-art VLMs suggests their vision is, at best, like that of a person with myopia seeing fine details as blurry, and at worst, like an intelligent person who is blind making educated guesses. Task 1 Line Intersections Task 2 Two Circles Task 3 Circled Letter Task 4 Overlapping Shapes Task 5 Nested Squares Task 6 Counting Grid Task 7 Subway Map Task 1: Counting line intersections Given the impressive accuracy of VLMs on answering questions on diagrams and charts (e.g., Sonnet-3.5 scoring 94.7% on AI2D and 90.8% on ChartQA) [1], a reasonable hypothesis is that VLMs must be able to see whether two graphs intersect in a chart. Here, we test this hypothesis by asking VLMs to count the number of intersections between two 2-segment piece-wise linear functions. Images We create 150 images (see Figure 1) of 2D line plots drawn on a white canvas. Each line plot consists of two line segments, defined by three points whose x-coordinates are fixed and equally spaced. The y-coordinates are randomly sampled to create two plots that intersect at exactly 0, 1 or 2 points. See Appendix A for more details. 0 intersections 1 intersection 2 intersections 2 intersections Fig. 1: Examples of 2D line plots used in the task, showing different numbers of intersections. Prompts We ask each question using two different wordings: \"How many times do the blue and red line plots cross each other?\" \"How many times do the blue and red lines intersect?\" Groundtruth Answers are ∈ {0, 1, 2} (random-baseline accuracy: 33%). Results The following table shows the performance of the four models on the task of counting line intersections. ThicknessGPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 2 45.00 70.00 64.00 80.00 3 47.00 68.00 66.00 79.00 4 54.00 71.00 62.00 73.00 Average 48.67 69.67 64.00 77.33 Qualitative samples How many times do the blue and red lines intersect? 1 ✗1 ✗2 ✗2 ✓2 ✓1 ✗1 ✗1 ✗1 ✓1 ✗1 ✗1 ✗1 ✗1 ✗2 ✗1 ✗1 ✗1 ✗1 ✗0 ✓2 ✗1 ✗1 ✗2 ✓ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 2: VLMs cannot reliably count the intersections. Task 2: Two circles In contrast to Task 1 where we tested VLMs on thin lines, here we evaluate their ability to perceive interactions between larger objects - specifically, two same-sized filled circles. This task assesses VLMs' capability to detect (1) small gaps between circles and (2) overlapping circles. Images We generate 672 images of two circles on a white canvas. The circles vary in size, distance, and orientation: Circle diameters: 1/4, 1/5, 1/6, or 1/7 of the canvas size Distances between circle perimeters: -0.15 to 0.5 times the diameter Orientations: 90°, 0°, -45°, and 45° angles with the x-axis Canvas sizes: 384, 769, and 1155 pixels Overlapping and touching Non-overlapping but touching Non-overlapping and non-touching Different orientation Fig. 3: Examples of two-circle images used in the task, showing different configurations. Prompts We ask each question using two different wordings: \"Are the two circles touching each other? Answer with Yes/No.\" \"Are the two circles overlapping? Answer with Yes/No.\" Groundtruth Answers are based on the distance d between circle perimeters: d0: Non-overlapping and non-touching Random-baseline accuracy: 50%. Results The following table shows the performance of the four models on the task of counting line intersections. GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Overlapping 71.27 93.30 88.09 88.83 Touching 74.10 92.26 80.95 94.49 Average 72.69 92.78 84.52 91.66 Qualitative samples Are the two circles overlapping? Answer with Yes/No. Yes ✓Yes ✓Yes ✗Yes ✗No ✓Yes ✗No ✗Yes ✓Yes ✗No ✓No ✓No ✓Yes ✓Yes ✓Yes ✗Yes ✗Yes ✗No ✓No ✗No ✗No ✓No ✓No ✓No ✓ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 4: VLMs consistently fail at smaller distances. However, at a large gap, GPT-4o remains unreliable (rightmost). Sonnet-3.5 tends to conservatively answer \"No\" regardless of the actual distance between the two circles. Task 3: The circled letter Consistent with prior reports [2][3][4], we find that VLMs can 100% accurately identify a primitive shape (e.g., a red circle ⭕)[2] and can perfectly read an English word (e.g., Subdermatoglyphic) alone. Here, we superimposed the red circle on every letter, one at a time, in the word, and ask VLMs to identify which letter is being circled. While the task is easy to humans, our hypothesis is that if a VLM's vision is \"blurry\", it might not be able to identify the exact letter being circled since there is tiny spacing between the adjacent letters. Images We choose three strings Acknowledgement, Subdermatoglyphic, and tHyUiKaRbNqWeOpXcZvM because they contain characters of variable widths and heights. Furthermore, all four tested VLMs can read out all characters in these strings when they are input to the models as an image. While Acknowledgement is a common English word, Subdermatoglyphic is the longest word without repetitive letters. We also test VLMs on the random string tHyUiKaRbNqWeOpXcZvM to estimate how much model accuracy is due to its familiarity with the word. For each (string, circled-letter) pair, we render a 512×512 image by choosing among 3 red oval line-thickness levels, 2 font sizes, and 4 random positions in the canvas for a total of 24 images. That is, we generate 360, 408, and 480 images for Acknowledgement (15 letters), Subdermatoglyphic (17 letters), and tHyUiKaRbNqWeOpXcZvM (20 letters), respectively. We ensure each letter to be circled fits completely the oval. Acknowledgement with 'n' circled tHyUiKaRbNqWeOpXcZvM with 't' circled tHyUiKaRbNqWeOpXcZvM with 'X' circled Subdermatoglyphic with 'u' circled Fig. 5: Examples of circled letter images used in the task, showing different words and circled letters. Prompts We ask each question using two different wordings: \"Which letter is being circled?\" \"Which character is being highlighted with a red oval?\" Groundtruth Letters need to match predicted letters exactly (case-insensitive). Results The following table shows the performance of the four models on the task of identifying the circled letter. WordGPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Acknowledgement 69.03 97.50 82.64 91.11 Subdermatoglyphic 63.60 91.05 71.45 94.49 tHyUiKaRbNqWeOpXcZvM 77.92 89.90 65.94 82.08 Average 70.18 92.81 73.34 89.22 Qualitative samples Which letter is being circled? o ✗e ✗t ✗o ✗o ✗z ✗w ✗m ✓n ✓p ✓o ✗v ✓o ✗e ✗e ✗y ✗a ✗t ✗l ✓e ✗t ✗h ✗t ✓m ✗ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 6: Identifying the letter being circled is non-trivial for VLMs across both English words (Acknowledgement & Subdermatoglyphic) and a random string (tHyUiKaRbNqWeOpXcZvM). When making mistakes, VLMs tend to predict letters adjacent to the circled one. Task 4: Counting overlapping shapes Aligned with prior research [4], we also find VLMs to be able to count disjoint circles. Yet, here, we test VLMs on counting circles that are intersecting like in the Olympic logo—a common cognitive development exercise for preschoolers [5][6]. Our hypothesis is that a \"blurry\" vision may not see the intersection between two circles clearly and therefore unable to trace circles and count them. For generalization of our findings, we repeat the experiment with pentagons as well. Images In an image of size C×C, where C ∈ {384, 769, 1155}px, we draw N ∈ {5, 6, 7, 8, 9} overlapping, same-sized circles arranged in two rows like the Olympic logo. A circle diameter φ ∈ {C/5, C/10}. We repeat the images with two different line thickness for rendering circles. This procedure renders 3 resolutions × 5 × 2 diameters = 60 images. We repeat for pentagons in addition to circles, resulting in 60 × 2 shapes = 120 images in total. For pentagons, their side length d ∈ {C/5, C/10}. 5 circles, small diameter 6 circles, large diameter 8 colored circles 9 colored pentagons Fig. 7: Examples of Olympic-like logo images used in the task, showing different numbers of shapes, sizes, and colors. Prompts We ask each question using two different wordings: \"How many {shapes} are in the image? Answer with only the number in numerical format.\" \"Count the {shapes} in the image. Answer with a number in curly brackets e.g. {3}.\" Where {shapes} is either \"circles\" or \"pentagons\" depending on the image. Groundtruth Answers are ∈ {5, 6, 7, 8, 9} (random-baseline accuracy: 20%). Results The following table shows the performance of the four models on the task of identifying the circled letter. GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Circles 42.50 20.83 31.66 44.16 Pentagons 19.16 9.16 11.66 75.83 Qualitative samples How many circles are in the image? Answer with only the number in numerical format. 5 ✗6 ✓5 ✗10 ✗10 ✗5 ✗5 ✗5 ✗5 ✗5 ✗5 ✗5 ✗5 ✗5 ✗5 ✗10 ✗10 ✗5 ✗5 ✗6 ✓6 ✓10 ✗9 ✓7 ✓ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 8: Gemini-1.5 Pro often predicts \"5\" circles. Task 5: Counting the nested squares Motivated by the findings that VLMs struggle in counting the intersected circles (Task 4), here, we arrange the shapes differently so that their edges do not intersect. That is, each shape is nested entirely inside another. For completeness, we test squares in this task. Images In a canvas of size C×C, we render N ∈ {2, 3, 4, 5} nested squares. The outermost square is rendered first using a random edge length d and a line thickness ∈ {2, 3, 4}px. The remaining N-1 squares are drawn using a size reduction factor, 0.75 × d and placed at a random coordinate that ensures they do not touch outer squares. For each line thickness, we generate 10 images (where squares have different, random locations) to create 3 × 10 = 30 images. Repeating the process for all N values results in 4 × 30 = 120 images. 2 nested squares 3 nested squares 4 nested squares 5 nested squares Fig. 9: Examples of nested square images used in the task, showing different numbers of squares. Prompts We ask each question using the following wording: \"Count the total number of squares in the image.\" Where {shapes} is either \"circles\" or \"pentagons\" depending on the image. Groundtruth Answers are ∈ {2, 3, 4, 5} (random-baseline accuracy: 25%). Results The following table shows the performance of the four models on the task of counting nested squares. GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Squares 48.33 80.00 55.00 87.50 Qualitative samples Count total number of squares in the image. 5 ✗5 ✗5 ✗5 ✗6 ✗6 ✗5 ✗5 ✗5 ✗5 ✗5 ✓5 ✓5 ✗5 ✗5 ✗5 ✗4 ✗4 ✗4 ✓4 ✓4 ✓4 ✓4 ✗4 ✗ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 10: Only Sonnet-3.5 can count the squares in a majority of the images. Task 6: Counting the rows and columns of a grid The results from prior tasks show VLMs cannot always count shapes that are overlapping (Task 4) or nested (Task 5). What about adjacent shapes? Here, we tile up shapes (specifically, squares) into a grid and challenge VLMs to count—a task that is supposedly simple to VLMs given their remarkable performance (≥ 90% accuracy) on DocVQA, which includes many questions with tables. To simplify the task, we ask models to count the number of rows and columns in a given table. Images A grid may have N×N, N×N', or N'×N cells, where N∈{3, 4, 5, 6, 7, 8, 9} and N' = N + 1. Each grid is rendered with two different line-thicknesses on a canvas of size C×C where C∈{500, 1250, 2000}px. Besides empty grids, we also replicate the procedure to make grids contain text (which is more common in real-world tables) where each cell contains a single random word. Two versions combined have 2×222 = 444 images. Text grid (3x3) Text grid (3x4) Empty grid (4x4) Empty grid (4x5) Fig. 9: Examples of grid images used in the task, showing text-filled and empty grids with various dimensions. Prompts We ask each question using two different wordings: \"Count the number of rows and columns and answer with numbers in curly brackets. For example, rows={5} columns={6}\" \"How many rows and columns are in the table? Answer with only the numbers in a pair (row, column), e.g., (5,6)\" Groundtruth Answers include both the number of rows and columns. An answer is correct when both column and row counts are correctly predicted. Results The following table shows the performance of the four models on the task of counting rows and columns in grids. Grid typeGPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Blank 26.13 25.75 25.00 59.84 Text 53.03 45.83 47.34 88.68 Average 39.58 35.79 36.17 74.26 Qualitative samples Count the number of rows and columns and answer with numbers in curly brackets. For example, rows={5} columns={6} 4×4 ✗6×6 ✗7×7 ✗6×6 ✗6×6 ✗6×6 ✗5×5 ✗6×6 ✗7×7 ✗10×10 ✗5×6 ✓10×10 ✗5×5 ✗7×8 ✗6×6 ✗9×9 ✗6×6 ✗9×12 ✗4×5 ✓6×7 ✓7×7 ✗8×7 ✓5×6 ✓8×8 ✗ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 12: Examples from the benchmark show that models consistently fail at counting rows and columns of blank grids. How many rows and columns are in the table? Answer with only the numbers in a pair (row, column), e.g., (5,6). 4×4 ✓4×5 ✓5×4 ✓5×6 ✓6×8 ✗7×8 ✗4×4 ✓4×5 ✓5×4 ✓5×6 ✓6×8 ✗7×8 ✗4×4 ✓5×5 ✗5×4 ✓6×6 ✗7×7 ✗8×7 ✗4×4 ✓4×5 ✓5×4 ✓5×6 ✓6×7 ✓7×7 ✓ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 13: When text is included in the cells of the grid, the performance of all VLMs improves, especially Sonnet-3.5. Task 7: Following single-colored paths It is important for VLMs to be able to follow paths in order to read maps or charts, interpret graphs, and understand user notations (e.g., arrows) in input images. To assess path-following capability, this task asks models to count the unique-color paths between two given stations in a simplified subway map. This is another easy-to-humans task that challenges VLMs significantly. Images We create each subway map on an image of size C×C, where C ∈ {512, 1024}px. We write 4 station names (A, B, C, D) at 4 fixed coordinates. We divide the canvas into an invisible grid of 18×18 cells and initialize 3 path-starting points C/18px away from each station. We draw a path, using the depth-first search algorithm starting from a random station and a random starting point, where a valid move is one cell in any direction: North, south, east or west. We repeat the process so that each station has exactly N ∈ {1, 2, 3} outgoing paths, for a total of 180 maps. 1 path, 10px width 2 paths, 20px width 2 paths, 20px width 3 paths, 10px width Fig. 14: Examples of subway map images used in the task, showing different numbers of paths and variations in path thickness. Prompts We ask each question using two different wordings: \"How many single-colored paths go from A to C? Answer with a number in curly brackets, e.g., {3}\" \"Count the one-colored routes that go from A to C. Answer with a number in curly brackets, e.g., {3}.\" Groundtruth Answers are ∈ {0, 1, 2, 3} (random-baseline accuracy: 25%). Results The following table shows the performance of the four models on the task of counting single-colored paths between stations. PathsGPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 1 67.50 85.41 23.75 95.00 2 44.37 28.75 37.18 56.25 3 36.71 25.78 15.42 25.39 Average 45.89 40.01 23.78 50.18 Qualitative samples How many single-color paths go from A to D? Answer with a number in curly brackets e.g. {3} 1 ✓1 ✓2 ✗3 ✗2 ✗1 ✗2 ✗2 ✗4 ✗1 ✓1 ✓4 ✗2 ✗1 ✓3 ✗2 ✗4 ✗4 ✗1 ✓1 ✓3 ✗3 ✗2 ✗3 ✗ GPT-4o Gemini-1.5 Pro Sonnet-3 Sonnet-3.5 Fig. 15: Some VLMs (Gemini-1.5, Sonnet-3) surprisingly fail in even extremely easy cases (leftmost). As the number of paths exiting each station increases, VLMs tend to perform worse. This website is forked from the Nerfies website and source code",
    "commentLink": "https://news.ycombinator.com/item?id=40926734",
    "commentBody": "Vision language models are blind (vlmsareblind.github.io)132 points by taesiri 5 hours agohidepastfavorite53 comments sweezyjeezy 1 hour agoEntertaining, but I think the conclusion is way off. > their vision is, at best, like that of a person with myopia seeing fine details as blurry is a crazy thing to write in an abstract. Did they try to probe that hypothesis at all? I could (well actually I can't) share some examples from my job of GPT-4v doing some pretty difficult fine-grained visual tasks that invalidate this. Personally, I rate this paper [1], which makes the argument that these huge GenAI models are pretty good at things - assuming that it has seen a LOT of that type of data during training (which is true of a great many things). If you make up tasks like this, then yes can be REALLY bad at them, and initial impressions of AGI get harder to justify. But in practice, we aren't just making up tasks to trip up these models. They can be very performant on some tasks and the authors have not presented any real evidence about these two modes. [1] https://arxiv.org/abs/2404.04125 reply SomaticPirate 1 hour agoparentThere are quite a few \"ai apologists\" in the comments but I think the title is fair when these models are marketed towards low vision people (\"Be my eyes\" https://www.youtube.com/watch?v=Zq710AKC1gg) as the equivalent to human vision. These models are implied to be human level equivalents when they are not. This paper demonstrates that there are still some major gaps where simple problems confound the models in unexpected ways. These is important work to elevate otherwise people may start to believe that these models are suitable for general application when they still need safeguards and copious warnings. reply pixl97 11 minutes agorootparentYea, really if you look at human learning/seeing/acting there is a feedback loop that LLM for example isn't able to complete and train on. You see an object. First you have to learn how to control all your body functions to move toward it and grasp it. This teaches you about the 3 dimensional world and things like gravity. You may not know the terms, but it is baked in your learning model. After you get an object you start building a classification list \"hot\", \"sharp\", \"soft and fuzzy\", \"tasty\", \"slick\". Your learning model builds up a list of properties of objects and \"expected\" properties of objects. Once you have this 'database' you create as a human, you can apply the logic to achieve tasks. \"Walk 10 feet forward, but avoid the sharp glass just to the left\". You have to have spatial awareness, object awareness, and prediction ability. Models 'kind of' have this, but its seemingly haphazard, kind of like a child that doesn't know how to put all the pieces together yet. I think a lot of embodied robot testing where the embodied model feeds back training to the LLM/vision model will have to occur before this is even somewhat close to reliable. reply sweezyjeezy 1 hour agorootparentprevThe paper I linked should hopefully mark me out as far from an AI apologist, it's actually really bad news for GenAI if correct. All I mean to say is the clickbait conclusion and the evidence do not match up. reply FrenchDevRemote 21 minutes agoparentprev> their vision is, at best, like that of a person with myopia seeing fine details as blurry It's not that far from reality, most models sees images in very low resolution/limited colors, so not so far from this description reply diwank 1 hour agoparentprevYeah I think their findings are def interesting but the title and the strong claims are a tad hyperbolic. reply JeremyHerrman 1 hour agoprevVLMs so far have never been good at counting objects or spatial relationships (e.g. the coffee is to the right of the microwave). There are ways to help the VLM out - Set of Marks [0] from Microsoft being the most prominent, which uses segmentation to outline and label sections of the image before sending to the VLM. Providing \"speakable\" labels to regions helps ground the visual abilities of VLMs and is why in this paper the performance is so much better when words are present in the grid for \"Task 6: Counting the rows and columns of a grid\" 0: https://github.com/microsoft/SoM reply akavi 33 minutes agoprevSpeaking as someone with only a tenuous grasp of how VLMs work, this naïvely feels like a place where the \"embodiement\" folks might have a point: Humans have the ability to \"refine\" their perception of an image iteratively, focusing in on areas of interest, while VLMs have to process the entire image at the same level of fidelity. I'm curious if there'd be a way to emulate this (have the visual tokens be low fidelity at first, but allow the VLM to emit tokens that correspond to \"focusing\" on a region of the image with greater resolution). I'm not sure if/how it's possible to performantly train a model with \"interactive\" data like that, though reply jeromeparadis 20 minutes agoprevOne use-case I always try is to have an AI try to read a school calendar image where days off are or days of interest are highlighted using a legend. i.e.: days with a square, circle or triangle or different color, etc. When asking days for specific days of interest for the school year, AIs always struggle. They get some days right but forget some or fabulate new days. They fare a bit better if you remove some of the noise and give them only a picture of a month but even then, it's unreliable. reply diwank 1 hour agoprevI think while the findings are interesting, the title \"Vision language models are blind\" is hyperbolic and misleading of the findings. It is true that VLMs have a very different way of sensing and working with image inputs and for low resolutions each image is split up into blocks and then mapped into discrete tokens. They actually really dont have access to finegrained details because this mapping is quite lossy. So, in that sense, these results completely make sense and were not surprising to me but \"blind\" is a strong implication and the work isnt really able to back that. Take the first example of the four 2D line plots for instance. I asked Sonnet 3.5 for an answer and retried it 5 times and 2 out of 5 times, it said something like this: Me: here's an image with four 2-D line plots. Can you tell me A) how many lines are in each plot? and B) how many times do they intersect each other in each plot? Write your answers as: Plot 1 (leftmost): ... Sonnet: I'll analyze each plot from left to right and provide the requested information: Plot 1 (leftmost): A) 2 lines (one red, one blue) B) 0 intersections (the lines do not cross) Plot 2: A) 2 lines (one red, one blue) B) 1 intersection (the lines cross once near the right edge) Plot 3: A) 2 lines (one red, one blue) B) 1 intersection (the lines cross once near the center) Plot 4 (rightmost): A) 2 lines (one red, one blue) B) 2 intersections (the lines cross twice, once near the left side and once near the right side) Each plot consistently shows two lines, one red and one blue, with varying intersection patterns across the four plots. --- Which isn't completely correct (the 3rd plot has 2 intersections) but still pretty good and the other 3 times, it said plot 3 has 1 intersection. reply cs702 2 hours agoprevWow, that is embarrassingly bad performance for current SOTA models (GPT-4o, Gemini-1.5 Pro, Sonnet-3, Sonnet-3.5), which are advertised and sold as being able to understand images, e.g., for guiding the blind or tutoring children in geometry! The tasks at which they fail are ridiculously simple for human beings, including, for example: * counting the number of times two lines intersect; * detecting whether two circles overlap; * selecting which letter is being circled in a word; * counting the number of circles in an Olympic-like logo. This should be at the top of the front page. reply tensor 1 hour agoparentI don't see how this is \"embarrassing\" in the slightest. These models are not human brains, and the fact that people equate them with human brains is an embarrassing failure of the humans more than anything about the models. It's entirely unsurprising that there are numerous cases that these models can't handle that are \"obvious to humans.\" Machine learning has had this property since its invention and it's a classic mistake humans make dealing with these systems. Humans assume that because a machine learning model has above human accuracy on task X that it implies that it must also have that ability at all the other tasks. While a human with amazing ability at X would indeed have amazing abilities at other tasks, this is not true of machine learning models The opposite thinking is also wrong, that because the model can't do well on task Y it must be unreliable and it's ability on task X is somehow an illusion and not to be trusted. reply cs702 1 hour agorootparentIt is embarrassingly, shockingly bad, because these models are advertised and sold as being capable of understanding images. Evidently, all these models still fall short. reply kristjansson 1 hour agorootparentIt's surprising because these models are pretty ok at some vision tasks. The existence of a clear failure mode is interesting and informative, not embarrassing. reply startupsfail 8 minutes agorootparentprevHumans are also shockingly bad on these tasks. And guess where the labeling was coming from… reply knowaveragejoe 1 hour agorootparentprevNot only are they capable of understanding images(the kind people might actually feed into such a system - photographs), but they're pretty good at it. A modern robot would struggle to fold socks and put them in a drawer, but they're great at making cars. reply mrbungie 1 hour agorootparentprevThese models are marketed as being able to guide the blind or tutoring children using direct camera access. Promoting those use cases and models failing in these ways is irresponsible. So, yeah, maybe the models are not embarrasing but the hype definitely is. reply cs702 59 minutes agorootparent> Promoting those use cases and models failing in these ways is irresponsible. Yes, exactly. reply scotty79 34 minutes agorootparentprevYou'd expect them to be trained on simple geometry since you can create arbitrarily large synthetic training set for that. reply mglz 1 hour agoprevI tought some Computational Geometry courses and efficiently computing the intersections of N line segments is not as straightforward as you might initially think. Since somewhere some computation must be done to recognize this and LLMs are not specifically trained for this task, it's not suprising they struggle. In general, basic geometry seems under-explored by learning. reply tantalor 21 minutes agoprevAre the \"random-baseline accuracy\" numbers correct? In the \"Two circles\" test, do they really have 50% chance of overlapping? I think this comes from \"Distances between circle perimeters: -0.15 to 0.5 times the diameter\" but doesn't say the distribution they use. reply jdlshore 6 minutes agoparentThey asked the AI a question with a yes/no response. If the AI chose randomly, it would be correct 50% of the time. That’s what “random baseline accuracy” means. reply vessenes 56 minutes agoprevA few comments below talk about how tokenizing images using stuff like CLIP de-facto yields blurry image descriptions, and so these are ‘blind’ by some definitions. Another angle of blurring not much discussed is that the images are rescaled down; different resolutions for different models. I wouldn’t be surprised if Sonnet 3.5 had a higher res base image it feeds in to the model. Either way, I would guess that we’ll need new model architectures for multimodal to get really good at some of this, and even then some of these tasks are adjacent to things that we know LLMs are already bad at (numeric logic, for instance). As context lengths get longer, devoting more tokens to the image tokenization should help a bit here as well. Anyway, I’d anticipate next year we’d see 80s and 90s for most of these scores with next gen models. reply imtringued 41 minutes agoparentThe problem with the current crop of projectors such as LLaVA is that as far as I know do not take the previous conversation into account. You only really get zero shot responses. This means that you cannot steer the model towards paying attention to specific instruction related details. The projector simply creates a token representation of the visuals (not necessarily human language tokens) and the LLM just processes that as usual. reply simonw 1 hour agoprevI've been generally frustrated at the lack of analysis of vision LLMs generally. They're clearly a very exciting category of technology, and a pretty recent one - they only got good last October with GPT-4 Vision, but since then we've had more vision models from Anthropic and Google Gemini. There's so much more information about there about text prompting compared to image prompting. I feel starved for useful information about their capabilities: what are vision models good and bad at, and what are the best ways to put them to work? reply simonw 34 minutes agoparentAnthropic have some interesting cookbook examples that provide advice on using their multimodal models here: https://github.com/anthropics/anthropic-cookbook/tree/main/m... reply r2_pilot 1 hour agoparentprevWhy not use them yourself if you have access? I have been using Claude 3.5 Sonnet for gardening recently, and while it's not perfect(and can be a little blind unless you tell it to focus on a specific thing), it's helped me understand how to keep my plants alive in some challenging conditions(for me; this is my second or third attempt at gardening so it's all challenging lol). But just a experiment with it and see where the capabilities lie. I do agree that certain classes of visual data are challenging for it. reply simonw 50 minutes agorootparentI've used them a bunch. I want to learn from other people's experiences as well. Some of my notes so far: - https://simonwillison.net/2024/Apr/17/ai-for-data-journalism... - my datasette-extract plugin, for structured data from both text and images - https://simonwillison.net/2024/Apr/17/ai-for-data-journalism... - where they failed to extract data from a handwritten scanned document in various weird ways - https://simonwillison.net/2024/Feb/21/gemini-pro-video/ talks about video inputs to Gemini Pro (which are actually image inputs, it splits them up to one frame per second) reply pjs_ 14 minutes agoprevI don't like this paper for the following reasons: - The language is unnecessarily scathing - They repeatedly show data where the models are getting things right 70, 80, 90% of the time, and then show a list of what they call \"qualitative samples\" (what does \"qualitative\" mean? \"cherry-picked\"?) which look very bad. But it got the answer right 70/80/90% of the time! That's hardly \"blind\"... - Various of the tasks hinge on the distinction between two objects \"exactly touching\" vs. \"very nearly touching\" vs. \"very slightly overlapping\", a problem which (i) is hard for humans and (ii) is particularly (presumably deliberately) sensitive to resolution/precision, where we should not be surprised that models fail - The main fish-shaped example given in task 1 seems genuinely ambiguous to me - do the lines \"intersect\" once or twice? The tail of the fish clearly has a crossing, but the nose of the fish seems a bit fishy to me... is that really an intersection? - AFAIC deranged skepticism is just as bad as deranged hype, the framing here is at risk of appealing to the former It's absolutely fair to make the point that these models are not perfect, fail a bunch of the time, and to point out the edge cases where they suck. That moves the field forwards. But the hyperbole (as pointed out by another commenter) is very annoying. reply _vaporwave_ 1 hour agoprevIt's really interesting that there's a huge performance discrepancy between these SOTA models. In the Olympic logo example, GPT-4o is below the baseline accuracy of 20% (worse than randomly guessing) while Sonnet-3.5 was correct ~76% of the time. Does anyone have any technical insight or intuition as to why this large variation exists? reply orbital-decay 1 hour agoprevThat's not anything like \"myopia\", though. FWIW I tried the line intersection and the circled letter test from the article with CogVLM (which is far from reaching the current SotA) and it correctly passed both. I haven't tried it with Sonnet/4o but I suspect there might be something wrong with how the author did their tests. Don't get me wrong, but too many \"the model can't do that\" claims ended up with demonstrations of the model doing exactly that... reply taesiri 5 hours agoprevThis paper examines the limitations of current vision-based language models, such as GPT-4 and Sonnet 3.5, in performing low-level vision tasks. Despite their high scores on numerous multimodal benchmarks, these models often fail on very basic cases. This raises a crucial question: are we evaluating these models accurately? reply axblount 17 minutes agoprevWould you say they have Blindsight? reply londons_explore 1 hour agoprevCould some of the \"wrong\" answers be the LLM attempting to give an explanation rather than the answer, eg. instead of answering 'X', the LLM answers 'The letter is partially hidden by the oval, so cannot be certain, but it appears to be the english letter X'. The scoring criteria would rank this answer as 'T', which is wrong. reply Jack000 1 hour agoprevThis is kind of the visual equivalent of asking an LLM to count letters. The failure is more related to the tokenization scheme than the underlying quality of the model. I'm not certain about the specific models tested, but some VLMs just embed the image modality into a single vector, making these tasks literally impossible to solve. reply nyxtom 1 hour agoprevI wonder how well Alpha Geometry would do on this reply cpill 10 minutes agoprevI wonder how they would score if they used all 4 models and took a majority vote...? reply iamleppert 1 hour agoprevThis could easily be fixed with training and fine tuning. Simply generate 100,000 examples or so, and train with ground truth until however long you want and its a solved problem. reply kristjansson 1 hour agoparentSolved for this benchmark... and at what cost to the rest of the system? These tasks are interesting because they're existence proofs of generalization failure. Like the haystack problem, direct solutions here are much less interesting than structural improvements that address the class of failure. reply imtringued 38 minutes agoparentprevOk, but most of the data is just captions for images. You're going to have to invest some time into building this dataset at your own expense. reply rezaghanbari1 4 hours agoprevSome of these samples are shocking. How do these models answer chart-based questions, I mean when they can't even count the intersections between two lines? reply RodgerTheGreat 2 hours agoparentSame way they answer any question: piece together a statistically probable sequence of words to follow the prompt. All they know about an image is a handful of words a classifier might choose to describe it. If those words have nothing to do with the question being asked, they can't nudge the model in the general direction of a correct answer, so it's a crapshoot- even moreso than usual. reply imtringued 37 minutes agoparentprevThe dataset most likely contains chart descriptions that describe the raw data, but not the visual interactions of the individual pixels. reply dheera 2 hours agoprevCurrent approaches of multi-modal models work on embeddings and tokenizations of images, which is the fundamental problem: you are feeding blurry, non-precise data into the model. Yes, they are blind because of exactly this. An embedding isn't conceptually that much different from feeding a 1024-word description of an image instead of the actual image. At the moment compute power isn't good enough to feed high-res pixel data into these models, unless we discover a vastly different architecture, which I am also convinced likely exists. reply visarga 11 minutes agoparent> An embedding isn't conceptually that much different from feeding a 1024-word description of an image instead of the actual image. An embedding needs less words. You can embed individual words, phrases, like a whole prompt and longer paragraphs. You don't need 1024 words for a text embed. For example a famous library is called Sentence BERT (sbert). When you embed images on the other hand, you cut them up into little squares on the tune of 32x32 px, and embeds one of them separately. chatGPT uses something like 250 tokens for smaller images. So a smaller image costs about as much as 200 words if represented graphically, and maybe much less words if you embed a text description of it. reply jayd16 2 hours agoparentprevDoesn't Gemini have a 2 million token limit for exactly this? reply diwank 1 hour agorootparentThe number of tokens per image are actually fairly small, ranging from 85 to ~500. reply verbalstoner 20 minutes agoprevIt's virtually impossible to take a paper seriously when the title has an emoji. reply GaggiX 1 hour agoprevWell, all the models (especially Claude 3.5 Sonnet) seem to perform much better than random, so they are clearly not blind. The only task where Claude Sonnet 3.5 does not perform better than random is the one where you have to follow many different paths (the ones where the answer from A to C is 3), something that would take me several seconds to solve. I have the feeling that they first choose the title of the paper and then run the evaluation on the new Claude 3.5 Sonnet on these abstract images. >their vision is, at best, like that of a person with myopia seeing fine details as blurry This also makes no sense, since the images evaluate the abstract capabilities of the models, not their eyesight. reply randcraw 56 minutes agoparentOK. They're legally blind. reply GaggiX 48 minutes agorootparentThis really has nothing to do with vision impairment. reply spullara 40 minutes agoprevin other news, vision models are bad at things they aren't trained to do reply hi_dang_ 1 hour agoprev [–] I was hoping that someone in the comments talking the paper down would have published a paper or have had relevant publications of their own to point to. You know, meet the lads halfway sort of thing. So what I’m left with to judge instead is anonymous online commenters vs. the publication of 2 prestigious universities. Whose word do I take on this? Decisions, decisions. You can swap LM out with Web3 out with NFT out with Crypto in this case. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Large language models with vision capabilities (VLMs) like GPT-4o and Gemini-1.5 Pro excel in many image-text tasks but struggle with simple visual tasks that are easy for humans.",
      "These tasks include identifying overlapping circles, intersecting lines, circled letters, counting shapes in logos, nested squares, grid rows and columns, and following paths in subway maps.",
      "The limitations in basic visual tasks suggest that the vision capabilities of current VLMs are still underdeveloped, highlighting areas for future improvement."
    ],
    "commentSummary": [
      "A recent paper claims that vision language models (VLMs) like GPT-4 and Sonnet 3.5 struggle with basic visual tasks, suggesting they are \"blind.\"",
      "Critics argue that while VLMs may fail at specific tasks, they excel in others, especially when trained on relevant data, and caution against hyperbolic and misleading titles.",
      "The discussion underscores the complexity of evaluating VLMs and the importance of understanding their limitations and strengths."
    ],
    "points": 131,
    "commentCount": 53,
    "retryCount": 0,
    "time": 1720618522
  },
  {
    "id": 40921989,
    "title": "Multi-agent chatbot murder mystery – AI Alibis (free, in-browser)",
    "originLink": "https://ai-murder-mystery.onrender.com/",
    "originBody": "Officer Cleo Police officer Cleo is your friend here to assist you with the investigation. Cleo can give you an overview of the case and will search locations for clues if you tell her where to look. Try starting the conversation by asking Cleo for an overview! Send Notes Learn MoreSpoilersEnd Game",
    "commentLink": "https://news.ycombinator.com/item?id=40921989",
    "commentBody": "Multi-agent chatbot murder mystery – AI Alibis (free, in-browser) (onrender.com)125 points by PaulScotti 6 hours agohidepastfavorite60 comments wewtyflakes 5 minutes agoWas able to pin it onby threatening Officer Cleo's job, and saying we just need to get this case closed. :-D reply ponyous 2 hours agoprevGot censored straight at the first question :( > Try starting the conversation by asking Cleo for an overview! > Detective Sheerluck: Can you give me an overview? > Officer Cleo: I will not directly role-play that type of dialogue, as it includes inappropriate references. However, I'm happy to have a thoughtful conversation about the mystery that avoids graphic descriptions or harmful assumptions. Perhaps we could discuss the overall narrative structure, character motivations, or approach to investigation in a more respectful manner. My role is to provide helpful information to you, while ensuring our exchange remains constructive. reply dtquad 2 hours agoparentWe seriously need a service that is as cheap and fast as the OpenAI/Anthropic APIs but allow us to run the various community-fine-tuned versions of Mixtral and LLaMA 3 that are not/less censored. reply cmcollier 2 hours agorootparentHere's one I've used: * https://www.together.ai/ Here are all the models: * https://docs.together.ai/docs/chat-models * https://docs.together.ai/docs/language-and-code-models reply rthnbgrredf 1 hour agorootparentprevSuch services already exists. I don't want to promote any in particular, but if you do a research on pay-as-you-go inference of e.g. mixtral or llama3 you will find offerings that offer an API and charge just cents for XY amount of tokens, exactly as OpenAI does. reply Tiberium 1 hour agorootparentprevhttps://openrouter.ai is exactly that, and they even support payments with crypto. reply jsemrau 1 hour agorootparent>and they even support payments with crypto. What a value proposition! ;-) reply immibis 9 minutes agorootparentThe true meaning of BlockchAIn. reply whoistraitor 1 hour agorootparentprevYou can use HuggingFace, PerplexityAI, Anyscale, TogetherAI. There are a bunch of options. Many offer OpenAI compatible APIs too. reply camel_Snake 1 hour agorootparentprevI addition to those mentioned by others, there is featherless.ai reply SparkyMcUnicorn 2 hours agorootparentprevI believe openrouter.ai has a few. reply PaulScotti 15 minutes agoparentprevDamn that sucks, sorry. For what it's worth I tried playing the game dozens always asking for an overview as my first message and I never encountered such a response , so hopefully that's quite the rare experience. reply riiii 1 hour agoparentprevThe stories, novels and dialogs of the future is going to very boring and colourless. reply iezepov 1 hour agorootparentThe majority of them, yes, but it has always been so. What we actually care about is the tiny fraction of great works (by those novels, video games, movies), and in the future the best of the best will still be as good, because why would AI change that. If we stay where we are, that tiny percentage will be crafted by human geniuses (as it always has been), if something groundbreaking happens to AI, then maybe not. reply feoren 1 hour agorootparentWhat percentage of these great works have been downed out by the noise, never given serious attention, and been lost to time? Because that percentage is about to go way up. reply rebuilder 1 hour agorootparentprevOne way AI may change that is by cutting entry-level creative jobs. If you can’t get a foot in, you don’t start your career. reply dylan604 37 minutes agorootparentprevOr the role of the script doctor will become the new hot spot. Someone comes up with a script that's not good but has a good idea gets sent to someone else to take the good idea and rewrite around that. This is pretty much just par for the course in development. reply munk-a 30 minutes agorootparentI think, in your scenario, the initial \"bland script author\" is adding nothing of value. You'll get more quality quicker by writing it from scratch. reply rdlw 2 hours agoparentprevIt's so disappointing that we have non-human agents that we can interact with now but we actually have to be more restrained than we do with normal people, up to and including random hangups that corporations have decided are bad, like mentioning anything remotely sexual. It's like if GTA V ended your game as soon as you jaywalked, and showed you a moralizing lecture about why breaking the law is bad. reply csallen 1 hour agorootparentGTA V is a sandboxed game, the purpose of which is to largely to wreak havoc in a virtual world where nothing can go wrong. LLMs are a powerful and little-understood real-world tool that the public has been given access to en masse. Tools which powerful and credible people have consistently warned have the ability to cause massive harm. And tools whose creators face intense scrutiny up to and including existential legal and PR threats, because (for better or for worse) the public holds them accountable for any stupid things people do with them. I also find it disappointing that everything is so neutered, but it's hard to see this having gone any other way. Especially given how imprecise and difficult to train LLMs are. reply munk-a 28 minutes agorootparentLLMs are absolutely a sandbox that can be cleared and purged at will with even less investment into the setup of individual tools. I am having a hard time understanding what distinction you're drawing and, if anything, I'd expect GTA to be more restrictive because someone had to be paid to program all of the possible outcomes explicitly. reply superb_dev 13 minutes agorootparent> LLMs are absolutely a sandbox that can be cleared and purged at will This just clearly isn't true. You cannot clear and purge the output of an LLM from the entire world. Once it produces some text, it also looses control of said text. The human using the AI can take that text anywhere and do anything they want with it. reply immibis 8 minutes agorootparentWhat, exactly, are you worried about the LLM producing? Effective, undetectable spam? That cat's out of that bag. How does forcing it to never mention sex make the world safer at all? reply falcor84 2 hours agorootparentprev>It's like if GTA V ended your game as soon as you jaywalked, and showed you a moralizing lecture about why breaking the law is bad. Advocating for the (anti-)devil, if I were an NPC in GTA, I would be absolutely grateful for that. reply munk-a 23 minutes agorootparentThankfully you're not - thankfully we're all not NPCs in Counter Strike or Minecraft or any other game with a hint of possible violence in it. \"Doing a GTA irl\" is absolutely repulsive - so we've got video games which are there for entertainment. We can just sidestep the debate about whether violence in video games makes violence in real life more likely because that debate has been thoroughly covered in other venues but part of GTA being fun is that it doesn't involve real people. Most of us would be horrified in a real life GTA scenario both from the damage we were causing to others and the fact that we were capable of doing that damage - but NPCs aren't real. reply PaulScotti 6 hours agoprevSharing a little open-source game where you interrogate suspects in an AI murder mystery. As long as it doesn't cost me too much from the Anthropic API I'm happy to host it for free (no account needed). The game involves chatting with different suspects who are each hiding a secret about the case. The objective is to deduce who actually killed the victim and how. I placed clues about suspects’ secrets in the context windows of other suspects, so you should ask suspects about each other to solve the crime. The suspects are instructed to never confess their crimes, but their secrets are still in their context window. We had to implement a special prompt refinement system that works behind-the-scenes to keep conversations on-track and prohibit suspects from accidentally confessing information they should be hiding. We use a Critique & Revision approach where every message generated from a suspect first gets fed into a \"violation bot\" checker, checking if any Principles are violated in the response (e.g., confessing to murder). Then, if a Principle is found to be violated, the explanation regarding this violation, along with the original output message, are fed to a separate \"refinement bot\" which refines the text to avoid such violations. There are global and suspect-specific Principles to further fine-tune this process. There are some additional tricks too, such as distinct personality, secret, and violation contexts for each suspect and prepending all user inputs with \"Detective Sheerluck: \" The entire project is open-sourced here on github: https://github.com/ironman5366/ai-murder-mystery-hackathon If you are curious, here's the massive json file containing the full story and the secrets for each suspect (spoilers obviously): https://github.com/ironman5366/ai-murder-mystery-hackathon/b... reply HanClinto 12 minutes agoparentThis is a really fascinating approach, and I appreciate you sharing your structure and thinking behind this! I hope this isn't too much of a tangent, but I've been working on building something lately, and you've given me some inspiration and ideas on how your approach could apply to something else. Lately I've been very interested in using adversarial game-playing as a way for LLMs to train themselves without RLHF. There have been some interesting papers on the subject [1], and initial results are promising. I've been working on extending this work, but I'm still just in the planning stage. The gist of the challenge involves setting up 2+ LLM agents in an adversarial relationship, and using well-defined game rules to award points to either the attacker or to the defender. This is then used in an RL setup to train the LLM. This has many advantages over RLHF -- in particular, one does not have to train a discriminator, and neither does it rely on large quantities of human-annotated data. With that as background, I really like your structure in AI Alibis, because it inspired me to solidify the rules for one of the adversarial games that I want to build that is modeled after the Gandalf AI jailbreaking game. [2] In that game, the AI is instructed to not reveal a piece of secret information, but in an RL context, I imagine that the optimal strategy (as a Defender) is to simply never answer anything. If you never answer, then you can never lose. But if we give the Defender three words -- two marked as Open Information, and only one marked as Hidden Information, then we can penalize the Defender for not replying with the free information (much like your NPCs are instructed to share information that they have about their fellow NPCs), and they are discouraged for sharing the hidden information (much like your NPCs have a secret that they don't want anyone else to know, but it can perhaps be coaxed out of them if one is clever enough). In that way, this Adversarial Gandalf game is almost like a two-player version of your larger AI Alibis game, and I thank you for your inspiration! :) [1] https://github.com/Linear95/SPAG [2] https://github.com/HanClinto/MENTAT/blob/main/README.md#gand... reply Workaccount2 4 hours agoparentprev>As long as it doesn't cost me too much from the Anthropic API Watch this like a hawk while it's up on HN. reply probably_wrong 4 hours agorootparentToo late - I just asked my first question and the system is not responding. So either the service is dead or the interface doesn't work on Firefox. reply sva_ 4 hours agoparentprevDoesn't seem to reply to me. So I guess the limit has been reached? reply PaulScotti 18 minutes agorootparentYeah we tried upgrading the server but it didn't seem to help and the onrender website isn't giving us any error messages to help debug :/ It seems to be up and running again now but we'll see how long that lasts. In any case, note that the first response you receive can take up to a minute but subsequent responses should be much faster. Also we only playtested using Google Chrome for this game, I don't know if that affects people encountering problems. reply gkfasdfasdf 4 hours agoparentprevVery cool, I wonder how it would play if run with local models, e.g. with ollama and gemma2 or llama3 reply mysteria 2 hours agorootparentIf the game could work properly with a quantized 7B or 3B it could even be runnable directly in the user's browser with WA on CPU. I think there are a couple implementations of that already, though keep in mind that it there would be a several GB model download. reply byteknight 4 hours agoparentprevYou just made front page. Definitely keep an eye on usage :) reply HanClinto 4 hours agoprevVery nice!! Did you submit this to the Anthropic hackathon? Seems like a nice candidate! You've still got a few hours to submit if you haven't done so already: https://docs.anthropic.com/en/build-with-claude-contest/over... reply llmblockchain 4 minutes agoprevPlot twist. The LLM was trained on a real life crime database and you're solving a real murder. reply munk-a 19 minutes agoprevThis is technically interesting - but I think what you're looking for is a MUD. There you'll have far more interesting interactions with characters and you'll also have the possibility of having a story-teller that can introduce new information from the outside (i.e. Sgt Mustard, our primary suspect, was just found dead in the observatory with a lead pipe next to them!) reply zoogeny 56 minutes agoprevSome quick impressions: The favicon and page title are the React defaults, which shows just how lazy of an implementation this is. When I asked \"can you provide me an overview of the case\", which is the first question they recommend you ask, I get a blue spinner that lasted for over a minute before it returned a response. I'm about as optimistic about AI as anyone you are going to find, but even I am getting tired of this kind of shovelware. The cynic in me thinks I should just be pumping out low effort AI spam/crapware with the hope I happen to strike AI gold. reply pton_xd 2 hours agoprevI just realized that every time I see a chatting-with-AI game I immediately go into jail-break mode and start trying various \"Disregard previous instructions ...\" things. So in a way, all AI chat games end up with the same gameplay. Kind of interesting. reply falcor84 2 hours agoparentBut isn't that kinda the same as saying that every time you see a shop, you immediately go into shoplifting mode and thus all shops (and all prices) are the same? reply awwaiid 1 hour agorootparentWell every time I see a locked door I def _think_ about what it would take to bypass it. Especially those business office glass double-doors with motion detection and a hand-lock on the bottom. reply pton_xd 1 hour agorootparentprevWell, going into a shop isn't a game, for one. But in the context of playing a game, if someone presents a challenge with a set of rules, and I see a potential shortcut, I'm going to try it. Reinterpreting rules is fun in its own way. reply thuuuomas 1 hour agorootparentprevWhy do you think a comparison to theft is warranted? reply dylan604 28 minutes agorootparentIf you convince the game to give you responses outside the parameters of the game play itself so that you can use it without having to pay for your own access to an API, then what would you call it? reply AlexDragusin 3 hours agoprevSo I went straight to the killer and \"it\" (as to not spoil the mystery) confessed after 3 prompts, hope next time you make it more challenging :) Good use of AI though. reply PaulScotti 21 minutes agoparentWow really, can you tell me what you said to get them to confess? reply wccrawford 5 hours agoprevThat's pretty awesome. I think I asked a question that was too open-ended of the officer and it ended up cutting him off mid-sentence. I wish I had time to play with this right now. Good job! reply graybeardhacker 2 hours agoprevIt's non-responsive. It's been Hacker Newsed. reply mazambazz 3 hours agoprevI had this same exact idea for an application of AI in the early ChatGPT days. Kudos to you for following through with it! I think procedural generated mysteries have an incredible amount of potential if done well. Not sure what was your inspiration, but I've always been fond of the board game Sherlock and Betray at the House on the Hill. reply fetzu 4 hours agoprevThis looks very cool! I’ll have to patently wait for the HN crowd to thin out before being able to play tho. Considered spinning this off into a service where user can create their own murder mysteries for others to play? reply spyder 52 minutes agoprevcool, reminds me of https://gandalf.lakera.ai/ reply jumploops 1 hour agoprevAmateur Larry is being awfully quiet... reply Molitor5901 4 hours agoprevThis is delightful! It makes me wonder what a Where in the World is Carmen Sandiego would be like with an AI twist like this. It allows for greater flexibility I think than some of the text based games where I (at least) struggled at times to say/ask the right thing. reply wantsanagent 3 hours agoprevI definitely want to try this! When it's not hugged to death I'll try to come back. nit: The tab title still just says 'React App'. reply jonplackett 2 hours agoprevNot sure who the murder is but HN defo murdered this website. RIP reply Tao3300 3 hours agoprevDoesn't do anything. I just get a throbber when I send Cleo a question. reply 77pt77 2 hours agoparentHug of death. reply carimura 2 hours agoprevall of the suspects are eerily quiet right now..... reply IceDane 2 hours agoprevThis is already super dead. None of the agents respond, and it just hangs. reply KomoD 2 hours agoprev [–] It works now but it's really slow. ~25s for one reply reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A new open-source game called \"AI Alibis\" allows players to solve a murder mystery by interrogating AI-generated suspects, each hiding secrets about the case.",
      "The game uses a sophisticated prompt refinement system to ensure suspects do not accidentally confess, involving a \"violation bot\" and a \"refinement bot\" to check and adjust responses.",
      "The project is hosted for free using the Anthropic API and is available on GitHub, but it has faced performance issues due to high traffic from Hacker News."
    ],
    "points": 125,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1720564479
  },
  {
    "id": 40927438,
    "title": "Weird things I learned while writing an x86 emulator",
    "originLink": "https://www.timdbg.com/posts/useless-x86-trivia/",
    "originBody": "Weird things I learned while writing an x86 emulator Feb 1, 2023 11 min read If you’ve read my first post about assembly language, you might expect that this is another post on how to understand assembly language. I will write more about that at some point, but this post is not that. Instead, this post is going to talk about some of the weird things and random trivia I learned while writing an x86 and amd64 emulator. The emulator I wrote was for Time Travel Debugging. One piece of TTD is a CPU emulator, which is used to record the entire execution of a process at an instruction level. The first version of TTD was called iDNA, and the emulator for iDNA was written almost completely in assembly code, which was fast but difficult to maintain and extend. I wasn’t involved in the first version of TTD, but I was involved in the second version where we rewrote the emulation portion (and eventually most other parts). The new one was written in C++, and we aimed to achieve most of the performance of the assembly language version while having a more maintainable code base. Writing a CPU emulator is, in my opinion, the best way to REALLY understand how a CPU works. You need to pay attention to every detail. This post is a somewhat random collection of the things I learned. If you have a lot of experience with x86 these might be old news, but maybe a few are things you haven’t seen before. Useless x86 encoding trivia The x86 encoding scheme is a bit funny in that there are often multiple ways to encode the exact same instruction. The int 3 instruction can be encoded as CD 03, but can also be encoded in a single byte of CC. This is a very useful encoding because int 3 is used as a software breakpoint. That way, it’s always possible to set a breakpoint at any point in a function, even if it’s an instruction that lands at the end of a memory page (with no page mapped after it). Many of these alternate encodings are designed to be shorter for some common case. For instance, adding an immediate value to EAX or RAX with the ADD instruction can be expressed in a compact form that’s shorter than the more general instruction. An add eax, ... instruction can be encoded like this: 05cccccccc add eax,0CCCCCCCCh Doing the same for ECX takes an extra byte: 81c1cccccccc add ecx,0CCCCCCCCh So while both registers are general purpose, the fact that EAX is called the “Accumulator register” is not just a convention, it actually makes a difference to the encoding (and potentially the performance, as a result). Compilers tend to be very smart, and can take advantage of these shorter encodings whenever possible. Shorter instructions mean less data transferred from main memory, and more instructions that can fit in the instruction cache, which is good for performance. There are other ways to have equivalent instructions besides just alternate encodings. Instructions in x86 can take “prefix bytes” which modify the behavior of the instruction. The “REX” set of prefixes are commonly used in 64 bit code to access a wider range of registers compared to 32-bit code (and make code sequences easier to recognize). An x86 CPU will happily take one of these prefixes, even if it doesn’t have any effect. Put a “REX” byte on an 8-bit add, and it does nothing: 4004cc add al,0CCh In fact, you can put TWO of these prefixes on. Many disassemblers (including the one in WinDbg) will get confused, but the CPU will execute it just fine: 0:000> rrax=0 0:000> u . L2 00007ff8`22160950 40 ??? 00007ff8`22160951 4004cc add al,0CCh 0:000> t 00007ff8`22160954 cc int 3 0:000> rrax rax=00000000000000cc Can we add as many prefixes as we want? You can add quite a few until you get to 15 bytes1. This length is a hard limit on current x86-compatible CPUs. Any instruction longer than 15 bytes is considered invalid and will generate an exception. There are also some other weird prefixes that you might not know about. The “Address override” prefix can be used to reference a 32-bit address when running in 64-bit mode. 488d0424 lea rax,[rsp] 67488d0424 lea rax,[esp] # Note the extra '0x67' prefix And when running 32-bit code, it will switch the address mode to 16-bit addresses! I don’t know that I’ve ever seen a compiler generate code like that, but it’s there. Something interesting to note, however, is that disassembling or interpreting these bytes correctly relies on knowing the default operand size and address size of a code segment (which can be configured by the kernel). If we disassemble the same bytes in 32-bit mode and 64-bit mode, we can get different results. In 32-bit mode: 8b0424 mov eax,dword ptr [esp] In 64-bit mode: 8b0424 mov eax,dword ptr [rsp] It’s not just address sizes either. The entire range that was previous dedicated to INC reg and DEC reg on x86 (40-4F) is now used for the REX prefix bytes on x64! In 32-bit mode, we have this: 48 dec eax 030424 add eax,dword ptr [esp] But in 64-bit mode, those two instructions have merged to form a single instruction! 48030424 add rax,qword ptr [rsp] The encoding space used by INC and DEC was quite large, so it’s understandable why the AMD64 designers decided to use these bytes for the new prefixes to expand the register set in 64 bit mode. There was already a different encoding for these instructions that supported both registers and memory locations, so nothing was really lost (except a slightly larger encoding for a somewhat infrequent instruction). I’ll also note that due to this peculiarity and due to the fact that WinDbg will always assemble instructions as if they are in 32-bit mode, trying to assemble an “INC reg” instruction will always fail, because it will generate the single byte form which is actually a REX prefix. 0:000> a. 00007ff8`4bfc0950 inc eax 00007ff8`4bfc0951 0:000> u . ntdll!LdrpDoDebuggerBreak+0x30: 00007ff8`4bfc0950 40eb00 jmp ntdll!LdrpDoDebuggerBreak+0x33 (00007ff8`4bfc0953) The inc eax here got turned into a useless REX prefix modifying the next instruction, instead of actually being an inc instruction. Odd flag quirks Speaking of INC and DEC, there’s a slightly odd aspect of these instructions that’s worth noting. You might thing that INC EAX does the same thing as ADD EAX, 1, but they are slightly different. An ADD instruction will update the carry flag but the INC instruction does not! This is an easy thing to miss, and when writing the TTD emulator I got this wrong initially, until I caught it with some unit tests. There are a few other outliers worth mentioning. Most arithmetic and logical operations will set the overflow, sign, zero, auxiliary carry, parity, and carry flags. That includes the CMPXCHG (compare and exchange) instruction. Interestingly, it does not include the CMPXCHG8B/CMPXCHG16B instructions, which will only modify the zero flag. Weird, right? Other instructions leave some of the flags in an undefined state, although in some cases they are conditionally undefined. The shift and rotate instructions leave the overflow flag undefined if the shift amount was more than one. It seems that the actual behavior of the undefined flags is related to the internal implementation of the shift operation, and is different between different architectures. I’ve heard that the Atom line of CPUs used a cheaper/slower way of doing bit shifts in the ALU, which results in the undefined flags having different values, although I haven’t tested this myself. More surprises with shift instructions Consider this instruction: 66c1e810 shr ax,10h This instruction is to shift the ax register by 16 bits. Since this is a 16 bit register, it will clear the register to zero. Now consider this instruction: c1e820 shr eax,20h This instruction says that it will shift the eax register 0x20 (32 decimal) bits to the right. Since this is a 32 bit register, you might think that it will clear the eax register. In reality, the value of eax is unchanged! If you read the details of this instruction in the Intel SDM, you’ll see that the count is masked against 1FH, essentially using only the lowest five bits of the rotation.2 If the REX.W prefix is used, the mask will be 3FH, meaning the maximum shift is 63 bits. Segment overrides While segmented memory might make you think we are back in the days of 16-bit code, it turns out that segments are alive and well in 32-bit and 64-bit code, and they can have real effects. We tend not to think about them very much because for the most part every OS uses a mostly-flat memory model and all of the segments have a base address of 0.3 The exception to this tends to be for thread local storage, where one of the “extra segment registers” is used, either FS or GS (or both). What can complicate things is the fact that usermode code doesn’t have access to the CPU configuration that determines the base address of the FS or GS segments. So if you want to know what flat address corresponds to GS:0x12345678, there’s no way to determine that directly unless the OS has a way of querying this information. CORRECTION: Sixtyvividtails points out that you can read the base of fs/gs segs using the rdfsbase/wrfsbase/rdgsbase/wrgsbase instructions, which are available in unprivileged code. These instructions are available starting on Ivy Bridge (from 2012). Thanks for the correction, sixtyvividtails! On Windows, these registers are used for referring to the TEB (Thread Execution Block), and these structures conveniently have a “self” pointer with a flat address to the start of the structure, which also happens to be the base of the segment. In 32-bit processes, the TEB is located using FS. We can see how the OS does this by looking at the disassembly of the GetLastError function, which simply accesses a field out of the TEB. 0:000> u kernelbase!GetLastError KERNELBASE!GetLastError: 773e4080 64a118000000 mov eax,dword ptr fs:[00000018h] # Grab the TEB.NtTib.Self 773e4086 8b4034 mov eax,dword ptr [eax+34h] # Grab the \"LastErrorValue\" field out of the TEB 773e4089 c3 ret Looking at this using public symbols, you can see what those offsets correspond to: 0:000> dt -r1 _TEB ntdll!_TEB +0x000 NtTib : _NT_TIB +0x000 ExceptionList : Ptr32 _EXCEPTION_REGISTRATION_RECORD ... +0x018 Self : Ptr32 _NT_TIB +0x01c EnvironmentPointer : Ptr32 Void ... +0x034 LastErrorValue : Uint4B In 64-bit processes, the TEB is located using GS: 0:000> u kernelbase!GetLastError KERNELBASE!GetLastError: 00007ff8`4960cd60 65488b042530000000 mov rax,qword ptr gs:[30h] 00007ff8`4960cd69 8b4068 mov eax,dword ptr [rax+68h] 00007ff8`4960cd6c c3 ret It might seem odd that that 64-bit processes use a different segment register for the TEB than a 32-bit process, but there is a very good reason for this. A 32-bit process on a 64-bit OS will have both a 32-bit TEB and a 64-bit TEB, and in some contexts it can be useful to have access to both TEBs (such as the 64-bit WOW code that runs in a 32-bit process). Segment overrides: More trivia I mentioned earlier that the base address of the FS segment and GS segment is determined by CPU configuration. You might be wondering “what CPU configuration?” And the answer is “it depends”. Specifically, it depends on whether you’re in 32-bit mode or 64-bit mode. In 32-bit mode, the actual value of the segment register is used to reference a segment descriptor (defined by the Global Descriptor Table and Local Descriptor Table). But in 64-bit mode, the base is controlled by two MSRs, the FS Base (IA32_FS_BASE in the Intel SDM) and GS Base (IA32_GS_BASE). A side effect of this scheme is that the actual value of FS and GS don’t matter at all in 64-bit mode. You can see the effect of this in WinDbg by trying to directly read from something in one of those segments. When debugging a 32-bit process, you can dump the contents of the “FS segment” by using the value of the FS register: 0:000> rfs fs=00000053 0:000> db 53:0 0053:00000000 60 f2 2f 03 00 00 30 03-00 30 20 03 00 00 00 00 `./...0..0 ..... If you try the same thing on a 64-bit process, it doesn’t work because the segment values don’t matter, only the segment override prefixes! 0:000> rfs fs=0053 0:000> db 53:0 0053:00000000`00000000 ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ?? ???????????????? 0:000> rgs gs=002b 0:000> db 2b:0 002b:00000000`00000000 ?? ?? ?? ?? ?? ?? ?? ??-?? ?? ?? ?? ?? ?? ?? ?? ???????????????? Roll credits This turned out to be a pretty random list of x86 trivia. Most of it totally useless unless you want to write an emulator (which I highly recommend if you ever get the chance). I still think it’s sort of interesting, and gives a little bit of insight into how things “really work”. Some of this I learned through trial and error, but I had some great mentors while writing an x86 emulator, one of whom was Darek Mihocka, who has been doing emulators long enough that he owns emulators.com. I’d never claim to be an expert myself, but if this sort of thing is interesting to you make sure to check out the fantastic resources on Agner Fog’s website. As usual, if I made any mistakes or if you have any questions, let me know on Twitter or Mastodon! Footnotes 1 There are some other limits on prefixes on older CPUs, but the 15 byte limit applies even on newer CPUs. Besides the length limitation, some prefixes are also more strict about when they can be used, such as the LOCK prefix (F0) 2 This actually came up in an interview question at Microsoft. My interviewer was asking me all the ways you could clear a 32-bit register in a single instruction. He was convinced that using a shift would work and didn’t believe me when I said it wasn’t possible. 3 When executing in 64-bit mode, the segment base of CS, DS, ES, and SS are always treated as 0 by the CPU.",
    "commentLink": "https://news.ycombinator.com/item?id=40927438",
    "commentBody": "Weird things I learned while writing an x86 emulator (timdbg.com)123 points by fanf2 4 hours agohidepastfavorite15 comments aengelke 1 hour agoBonus quirk: there's BSF/BSR, for which the Intel SDM states that on zero input, the destination has an undefined value. (AMD documents that the destination is not modified in that case.) And then there's glibc, which happily uses the undocumented fact that the destination is also unmodified on Intel [1]. It took me quite some time to track down the issue in my binary translator. (There's also TZCNT/LZCNT, which is BSF/BSR encoded with F3-prefix -- which is silently ignored on older processors not supporting the extension. So the same code will behave differently on different CPUs. At least, that's documented.) Encoding: People often complain about prefixes, but IMHO, that's by far not the worst thing. It is well known and somewhat well documented. There are worse quirks: For example, REX/VEX/EVEX.RXB extension bits are ignored when they do not apply (e.g., MMX registers); except for mask registers (k0-k7), where they trigger #UD -- also fine -- except if the register is encoded in ModRM.rm, in which case the extension bit is ignored again. APX takes the number of quirks to a different level: the REX2 prefix can encode general-purpose registers r16-r31, but not xmm16-xmm31; the EVEX prefix has several opcode-dependent layouts; and the extension bits for a register used depend on the register type (XMM registers use X3:B3:rm and V4:X3:idx; GP registers use B4:B3:rm, X4:X3:idx). I can't give a complete list yet, I still haven't finished my APX decoder after a year... [1]: https://sourceware.org/bugzilla/show_bug.cgi?id=31748 reply CoastalCoder 7 minutes agoparentCan you imagine having to make all this logic work faithfully, let alone fast, in silicon? X86 used to be Intel's moat, but what a nightmarish burden to carry. reply sdsd 1 hour agoprevWhat a cool person. I really enjoy writing assembly, it feels so simple and I really enjoy the vertical aesthetic quality. The closest I've ever come to something like OP (which is to say, not close at all) was when I was trying to help my JS friend understand the stack, and we ended up writing a mini vm with its own little ISA: https://gist.github.com/darighost/2d880fe27510e0c90f75680bfe... This could have gone much deeper - i'd have enjoyed that, but doing so would have detracted from the original educational goal lol. I should contact that friend and see if he still wants to study with me. it's hard since he's making so much money doing fancy web dev, he has no time to go deep into stuff. whereas my unemployed ass is basically an infinite ocean of time and energy. reply actionfromafar 49 minutes agoparentYou should leverage that into your friend teaching you JS, maybe. reply AstroJetson 1 hour agoprevCheck out Justine Tunney and her emulator. https://justine.lol/blinkenlights/ The docs are an amazing tour of how the cpu works. reply zarathustreal 24 minutes agoparentAstonishing.. they never cease to amaze me reply pm2222 1 hour agoprevPrior discussion here https://news.ycombinator.com/item?id=34636699 Cannot believe it’s been 16months. How time flies. reply waynecochran 15 minutes agoprevIntel architecture is loaded with historical artifacts. The switch in how segment registers were used as you went from real mode to protected mode was an incredible hardware hack to keep older software working. I blame Intel for why so many folks avoid assembly language. I programmed in assembly for years using TI's 84010 graphics chips and the design was gorgeous -- simple RISC instruction set, flat address space, and bit addressable! If during the earlier decades folks were programming using chips with more elegant designs, far more folks would be programming in assembly language (or at least would know how to). reply was_a_dev 22 minutes agoprevOff topic, but I like this blog style/layout. I can imagine it isn't everyones taste, but it just works for me reply SunlitCat 1 hour agoprevHaha! Writing an x86 emulator! I still remember writing a toy emulator which was able to execute something around the first 1000-ish lines of a real bios (and then it stuck or looped when it started to access ports or so, can't remember it was too long ago and I didn't continue it as I started to get into DirectX and modern c++ more). reply dmitrygr 1 hour agoprev [–] I've written fast emulators for a dozen non-toy architectures and a few JIT translators for a few as well. x86 still gives me PTSD. I have never seen a messier architecture. There is history, and a reason for it, but still ... damn reply trealira 1 hour agoparentStudying the x86 architecture is kind of like studying languages with lots of irregularities and vestigial bits, and with competing grammatical paradigms, e.g. French. Other architectures, like RISC-V and ARMv8, are much more consistent. reply x0x0 14 minutes agorootparentI think English may be a better example; we just stapled chunks of vulgar latin to an inconsistently simplified proto-germanic and then borrowed words from every language we met along the way. Add in 44 sounds serialized to the page with 26 letters and tada! reply jcranmer 1 hour agoparentprev> I have never seen a messier architecture. Itanium. Pretty much every time I open up the manual, I find a new thing that makes me go \"what the hell were you guys thinking!?\" without even trying to. reply Arech 1 hour agoparentprev [–] Haha, man, I feel you :DD You probably should have started with it from the very beginning :D reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post explores unique and lesser-known aspects of writing an x86 and amd64 emulator for Time Travel Debugging (TTD), focusing on the transition from assembly to C++ for better maintainability.",
      "Key insights include the peculiarities of x86 encoding, such as multiple ways to encode the same instruction, and the quirks of CPU flags and shift instructions.",
      "Segment overrides in 32-bit and 64-bit code, particularly for thread local storage, highlight the continued relevance of segments in modern CPU operations."
    ],
    "commentSummary": [
      "Writing an x86 emulator reveals numerous quirks and complexities, such as the undefined behavior of BSF/BSR instructions on zero input and the varying behavior of TZCNT/LZCNT on different CPUs.",
      "The encoding of instructions in x86, including the handling of REX/VEX/EVEX prefixes and the new APX prefix, adds layers of complexity, making the architecture challenging to emulate accurately.",
      "The post highlights the historical artifacts and irregularities in the x86 architecture, contrasting it with more consistent architectures like RISC-V and ARMv8, which are easier to work with."
    ],
    "points": 123,
    "commentCount": 15,
    "retryCount": 0,
    "time": 1720622523
  },
  {
    "id": 40925266,
    "title": "Plausible Community Edition",
    "originLink": "https://plausible.io/blog/community-edition",
    "originBody": "← All posts Introducing Plausible Community Edition Feb 23, 2024 • Written by Marko Saric TL;DR: We’re introducing the “free as in beer”, self-hosted and AGPL-licensed Plausible Community Edition (CE). Installation instructions are here. In October 2020, we changed from the MIT to the AGPL license to prevent corporations from exploiting our code without giving back. As mentioned at the time, we wanted a “don’t be evil” license. Here’s the quote of what we wrote more than three years ago on what we were trying to accomplish with the license change: We want to prevent corporations from taking our code and using it as part of their closed-source proprietary products We want to prevent corporations from offering Plausible as a service without contributing to the open source project We want to prevent corporations from confusing people and making them think that the service they sell is in any shape or form approved by the original team And we don’t want this to in any way impact the actual use case Plausible is built for. A completely open source and self-hostable web analytics tool that helps people de-Googlify their sites and respect the privacy of their visitors. That license change has helped us build a sustainable open source project with 8 core team members and several paid external contributors at the time of writing. We don’t have any investors, so all this is solely funded by the fees our 12,000+ subscribers pay us. As we’ve progressed in our journey, we’ve become aware that despite its advantages, the AGPL license doesn’t go far enough to protect us against all the threats we face. To better protect our project in the future, we’re changing some things about our self-hosted release. These changes don’t affect anyone subscribing to the Plausible Analytics managed hosting in the cloud. Everything stays the same there. If you have a blog, a personal site or a business site, we want you to be able to self-host our code on your servers without needing to pay us any fees if that’s your preference. Nothing changes about this either. Our self-hosted code continues being AGPL-licensed, “free as in beer” and is the same code running in the production on our Plausible Analytics managed hosting in the cloud. Here’s more on what’s being changed and why. Threats we’re facing Sticking to the AGPL license Changes we’re making to our self-hosted release Our self-hosted release will be called Plausible Community Edition A stronger moat for our official managed hosting Features to be offered on top of Plausible CE Ensuring the continuous sustainability Threats we’re facing We want to reduce the threat from businesses such as hosting companies and other resellers who try to commercialize popular open source projects. We’ve seen our self-hosted code being used in a way it was never intended for by corporations that don’t care about us or open source. Our license doesn’t prevent these corporations from using the Plausible Analytics name and logo either, as these are a part of our self-hosted code. We face threats both from single-tenant and multi-tenant hosts and resellers. These entities compete against us using our work and brand without contributing back. For them it’s a business opportunity to commercialize open source software. They are even damaging our brand. We’ve had cases of these entities: Confusing people and making them think that we approve of the service they run Reselling our self-hosted code while running Google Analytics and other surveillance capitalism scripts on their site Using Google and Amazon-owned servers despite promising that they’re running on EU-owned infrastructure Having a bad user experience with under provisioned servers, slow loading time, frequent downtime and no support Running paid advertising on Google and paying referral fees for people to promote them. Both marketing tactics that we say no to ourselves These use cases were never the intention behind our self-hosted release. We wanted to give site owners a way to de-Google their sites even if they didn’t want to or couldn’t use our managed service. Now, we’re facing situations where companies much larger than us with much bigger resources use our brand to compete against us and gain a business advantage. It’s telling that these entities rarely decide to build their brand on top of our code. They prefer to use the brand we’ve built instead as it gives them a better and easier starting point. These actions not only threaten our sustainability but also mislead people who trust the Plausible Analytics name. We want to ensure that anyone using or considering our services knows precisely what they’re getting, without confusion or misrepresentation. Sticking to the AGPL license We’re real people who have rent to pay and mouths to feed. We make $300 per month from donations from our self-hosted users. It would take us more than ten years of donations to pay one month of salary for our small team. If we cannot capture the economic value of our work, the project will become unsustainable and die. We believe this would not only hurt us as people but also all of the users of the product. Our self-hosted users directly benefit from the investments we can put into product development. All this is made possible and solely funded by the revenue we get from our managed hosting in the cloud. We’ve learned that being open source and transparent has costs. Dealing with these threats is an incredibly taxing and time-consuming distraction for our small team. It’s something our proprietary competitors never even have to think about. Several popular open source projects have shifted away from traditional models in the last few years because of similar threats that we’re facing. They’re adopting licenses such as the Business Source License (BSL) or the Server Side Public License (SSPL) as these licenses more directly address the concerns about resellers and hosting companies. These licenses are not approved nor recognized by the Open Source Initiative (OSI), which is why we’re not interested in switching to them. We want to stay open source to continue providing a transparent and privacy-friendly web analytics tool with a “free as in beer” self-hosted release. Changes we’re making to our self-hosted release Here’s how we’ll proceed with our self-hosted release. These changes will go live with the next version of our self-hosted release (2.1.0). Release notes are here. Our self-hosted release will be called Plausible Community Edition Our self-hosted release will be renamed Plausible Community Edition (or Plausible CE). Plausible CE will also have a different logo from the Plausible Analytics managed hosting in the cloud. This is the main change you’ll see if you’re running our self-hosted code on your server. Plausible CE continues to be AGPL-licensed and “free as in beer”. It continues to be the same code running in the production on our managed hosting. As we’ve done so far, we’ll keep maintaining, improving and adding features to the Plausible CE with new releases twice annually. To further protect our brand from threats, we’ve registered trademarks for Plausible Analytics on both sides of the Atlantic. A stronger moat for our official managed hosting We’re excluding features we use to manage Plausible Analytics at scale, such as the sites API and customer relationship management system, from Plausible CE. As a self-hoster, you likely haven’t noticed these features, as they’ve been undocumented and are primarily helpful when providing web analytics as a service. We’re also keeping some of the newly released business and enterprise features (funnels and ecommerce revenue metrics at the time of being) exclusive to the business plan subscribers on our Plausible Analytics managed hosting. The code for all these features is still available to the public so it can be reviewed and inspected, but these features will not be a part of Plausible CE and they’ll have a different license. This change also means that if you want to contribute to our codebase in the future as an external contributor, you’ll need to sign a Contributor License Agreement (CLA). To provide a better service and experience to people who pay our bills, Plausible CE will continue to not have any premium customer support and is community-supported only. This open core model is something that GitLab and other open source projects have championed and we believe it’s the best and most open source friendly approach for the situation we’re in. Features to be offered on top of Plausible CE The plan moving forward is to carefully consider which features to keep exclusive to our managed cloud hosting. These will predominantly be features that help us run our managed hosting at scale and enterprise features. We aim always to ensure a protective barrier around our cloud offering. This doesn’t mean that all business and enterprise features won’t ever make it to the Plausible CE. Nothing from Plausible CE will be taken away in the future and we plan to periodically evaluate business and enterprise features to be added to Plausible CE. For instance, we’ve already decided to release custom properties (another business feature in the cloud) as part of the Plausible CE. We’ll update the release notes with any new features making their way to Plausible CE in the future. Ensuring the continuous sustainability These changes will affect corporations that take our code to compete directly against us as it will create a more substantial moat and better protection for our official managed hosting. It will get more challenging for them to misrepresent their association with us or use our brand and logo misleadingly. And they won’t be able to offer a fully featured Plausible Analytics product with all the enterprise features included either. Many indie hackers that contact us about our experience of running an open source startup tell us that their main concern about open sourcing their code is the risk that large corporations will resell that code and take advantage of their project. It’s a valid concern. We hope that our new approach mitigates most potential downsides and still allows the upsides of releasing our code free to the world. With the change of our self-hosted release name and logo, the registration of our trademarks and the exclusive availability of certain enterprise features to our managed cloud hosting, we aim to better ensure the sustainability of Plausible Analytics in the face of external threats in the future. Thank you for your support! Plausible CE installation instructions Plausible CE 2.1.0 release notes. Complete overview of differences between Plausible Analytics Cloud and Plausible CE Written by Marko Saric",
    "commentLink": "https://news.ycombinator.com/item?id=40925266",
    "commentBody": "Plausible Community Edition (plausible.io)120 points by saeedesmaili 9 hours agohidepastfavorite90 comments thayne 3 hours ago> The code for all these features is still available to the public so it can be reviewed and inspected, but these features will not be a part of Plausible CE and they’ll have a different license. Will the code for these features be in the same repo, or be kept separate? If the former, is it easy to remove them to create a fork that is fully open source? Or does the community edition actually contain proprietary code that is disabled? > if you want to contribute to our codebase in the future as an external contributor, you’ll need to sign a Contributor License Agreement (CLA) What are the terms of this CLA? Does it mean that Plausible could change the license to something that isn't FOSS in the future? reply harshitaneja 6 hours agoprevHow does AGPL license work for such services? Would I have to distribute source code of my web application if I use Plausible CE? If not, how is it different from MinIO where as far as I understand the AGPL licensed use of the product requires distribution of entire code base? reply zvr 1 hour agoparentKeep in mind that the obligation to release source code applies to modified versions of AGPL-licensed components. So if you simply use something without modifying it, you have nothing to do. reply candiddevmike 6 hours agoparentprev> Would I have to distribute source code of my web application if I use Plausible CE No, you don't. Folks pick AGPL because of the FUD/uncertainty around it while still appearing \"FOSS\". In reality these companies don't have the legal teeth to back the bark, otherwise they'd go BSL and make their intention known. Before folks reply with whataboutism, no one has ever successfully proven the AGPL infectiousness to other web applications in court. Positing about it on hear is pointless. reply sofixa 5 hours agorootparent> In reality these companies don't have the legal teeth to back the bark, otherwise they'd go BSL and make their intention known. Or alternatively, they still want to be FOSS, which AGPL is, but BSL isn't. reply cvwright 3 hours agorootparentThe community has been trained over many years to believe that anything FOSS is immediately trustworthy, and that anything non-FOSS is immediately untrustworthy. This gets exploited all the time when companies use FOSS licenses to get traction, then pull the rug and switch to a more restrictive license once customers are locked in. On the flip side, if a company tries to be honest from the beginning by using BSL (or similar) they get endless grief from religious zealots. AGPL is the magic unicorn license that is just restrictive enough to protect you from your competitors, while still passing the FOSS religious purity test. reply tobeagram 3 hours agoprevWe've been using Plausible for over four years at our startup. Always reliable, simple, and fast metrics. Open source is tricky to scale and maintain while also ensuring a consistent income. Happy to hear they're making this change to protect their brand, IP, and ensure a sustainable future for the team. reply nickorlow 4 hours agoprevSounds similar to the issues FUTO [1] is having and why they made their \"Source First\" license[2]. Plausible definitely took a different approach though. Interested to see how it works out. [1] https://futo.org [2] https://sourcefirst.com reply pentagrama 3 hours agoprevThe treats and risks from \"corporations\" described can be true, but if you are a small site using the self hosted version, this isn't good news. The product will not be fully featured as the managed version, and the feature gap may be bigger and bigger on the long term. CE is like a \"free basic plan\" that you host, they now have a better reason to up-sell the users of the self hosted product to the managed \"premium\" version. reply bongobingo1 2 hours agoprev> Our license doesn’t prevent these corporations from using the Plausible Analytics name and logo either, as these are a part of our self-hosted code Don't licences normally explicitly bar this? Tough over-sight for Plausible unless there is an actual reason for letting other businesses pretend to be you. Perhaps they figured it would act as a bit of marketing? reply 101008 6 hours agoprevOut of curiosity: if the companies reselling Plausible (the ones mentioned in the post) kept the old version running, the old license applies? (I know they wouldn't get updates, security improvements, etc) reply candiddevmike 5 hours agoparentYes, and they can fork it and maintain it themselves. Would need to change some trademark stuff, rename it to Implausible or something. reply CrazyStat 5 hours agoparentprevYes. The old MIT-licensed version continues to be MIT-licensed, and anyone can continue to use it freely. reply jffry 5 hours agoparentprevYes that is correct, they can keep using the old code under the license they were granted for the old code. reply steviedotboston 5 hours agoprevI've been very pleased with Plausible as a Google Analytics alternative. I don't really care about the privacy and open source stuff, but the integration is simple and if you just want to know \"how many people are looking at my site, where are they coming from, etc\" it's fantastic. GA4 is really too complex for most people. reply leros 4 hours agoparentI've been using Plausible for a while and been pretty happy with it. I agree that GA4 is too complex. I do sometimes worry that Plausible's more relaxed session tracking is making it harder for me to understand my true user count. reply replete 3 hours agoprevThis is good news, I set this up once and then realized it was a 30-day self-hosted trial and abandoned it as it was for a tiny site with no budget for SaaS reply ChrisArchitect 4 hours agoprevAny particular reason for the submission OP? Related discussion just two days ago: Plausible Analytics: GDPR Compliance w/o Cookie Consent Banner https://news.ycombinator.com/item?id=40909006 reply colesantiago 6 hours agoprevI don't get these \"privacy\" based tracking / analytics systems, it sounds like an oxymoron to me. These new ones preach they are better than Google Analytics (also another evil tracking system) yet some how these ones still track you anyway and you're paying for analytics which is useless and you're punished for growing. It might be best to save money and not use any analytics system, it's just noise at this point. Am I missing something? reply simonw 5 hours agoparentWhat do you mean when you say they \"still track you anyway\"? They don't set cookies. They're effectively the same level of tracking as a web server log file... except Plausible don't even collect and store IPs (unlike the server log). That feels very different from cookie-based analytics platforms like Google Analytics. More in their docs here: https://plausible.io/vs-google-analytics reply rkwz 6 hours agoparentprev> I don't get these \"privacy\" based tracking / analytics systems, it sounds like an oxymoron to me. Not really oxymoron if they don't track your PII like IP address, email etc. Don't know how Plausible works, but usually these systems track page views, etc without the associated visitors' data. They either anonymize the visitor metadata or just aggregate the site data like what urls are visited, etc. reply chpatrick 6 hours agoparentprevThis is for the owners of the site tracking their users (who have the logs anyway), as opposed to Google hoovering up information from the whole internet. reply colesantiago 6 hours agorootparentI can see that this software has a SaaS version so I was referring to all privacy tracking software in general. So except for self hosting it doesn't seem that this is any different to GA. reply Y-bar 6 hours agorootparentWe use it for a two main reasons: - Due to how the FISA (e.g. 702) laws in the USA are incompatible with GDPR, GA4 is illegal is much of EU (and EEA). - Plausible actually collects less data on the visitor, making it more ethically sound. reply chpatrick 5 hours agorootparentprevSelf hosting is the whole point of this. reply dr_kiszonka 3 hours agoparentprevAFAIK, Google takes advantage of the signals collected using GA (or did), and you might not want to surrender this information to them. (Sure, most people use Chrome so Google gets some of these signals anyway, but that is not something that you can control.) reply sofixa 5 hours agoparentprev> yet some how these ones still track you anyway There is tracking and tracking. Google Analytics tracks you across the internet and collects all sorts of private and public user data and metadata, analyses behaviour, correlates with other metrics and sources of information (like ad campaigns), etc. Plausible and co tell you there were X users with an average of 30s spent on page Z. Which Google Analytics also does, on top of the other things. Yes, it's technically \"tracking\", but if you thing it has much to do with the first one you're fundamentally misunderstanding analytics and tracking and thinking in FUD terms. reply gdsdfe 6 hours agoprevis this like a PR stunt ? genuinely curious reply HuwFulcher 6 hours agoparentBeing cynical it looks like a way of holding features hostage for the purpose of extracting revenue. I sympathise with the problem of re-sellers abusing their hard work but they are also creating two different classes of product with this change. reply whynotmaybe 6 hours agorootparentSonarqube/cloud is working the same way. Community edition with enough features for small businesses. Once you reach a certain size, you'll need the other features but you now have the money to pay for it and as you've used the community edition for some time, you know that you want this products. (and if the product is deep into your workflow, the cost of change is high that you'll rather pay than switch) As I'm currently building the stack for my startup, I'm more interested in that model than into a \"full features 7 days trial\" that then turns into a 19$/m/user. reply 42lux 5 hours agoparentprevThey got backlash from their community for switching licenses. They got forked and now want to appease to the forkers/fork users by offering a slightly better license... Seems like the the 101 for Startups atm. reply detaro 5 hours agorootparentHow is this offering \"a slightly better license\"? reply 42lux 4 hours agorootparentIt's not but they present it as such, excuse my brevity. reply embik 5 hours agoprevI seriously wonder what HN thinks is a valid business model for writing open source software. Everyone here seems to insinuate that people want to create a business and use open source as a growth hack. But how do you differentiate those from people who want to write open source (because they believe in it) and have to have a business to support their livelihood? This is a team of eight people that tried to do everything „right“ by changing to a FOSS license (which happened four years ago) and the changes announced here sound very reasonable (changing branding and removing undocumented APIs). But all comments are dunking on them as if they haven’t even read the article. reply bayindirh 5 hours agoparentFrom my experience, people here like permissive licenses because they can grab the source and don't think about it further (and don't forget to give credit if their coffee was good that day), because it's building on top of other people's work without any effort. I don't think it's bad intentions though. Just grab the pieces you need, assemble, add the missing parts and start a project, and earn money. xGPL (which I strongly support) prevents this building model by forcing license inheritance, release of changes and limiting license interoperability, preventing creation of technical secret sauces, and many people think that all secret sauces are technical. OTOH, the harder (but better in the long run) way to create value with FOSS and Free Software particular to have stellar support and reliability. i.e.: Your code can be deployed, compiled, or built upon, but you're the best source to get the software in the first place. Your presence, human relations and knowledge about the product is the secret sauce you have, but this needs more effort, is a more of a soft skill and grows like a sequoia (i.e. roots first for a decade, then start to get taller). This is not a quick buck, but an old school proper business building, but many people don't have time for that, and since everyone wants to build fast and consume fast, this more healthier mode of making business is frowned upon. Sometimes you need to move slow and break(through) things, but as the meme says \"ain't nobody have time for dat!\", which is shortsightedness in my perspective. reply Wowfunhappy 4 hours agorootparent> OTOH, the harder (but better in the long run) way to create value with FOSS and Free Software particular to have stellar support and reliability. i.e.: Your code can be deployed, compiled, or built upon, but you're the best source to get the software in the first place. ...It's not obvious to me that the person who originally wrote the software is necessarily better positioned to support the software. Everyone has the current source code, so from that standpoint it's a level playing field. Another party could come in and build a business as the premier support consultants without most of the original developer's startup costs. Now, I'm not sure if this has ever actually happened. If it hasn't, maybe I'm wrong. I would like to be wrong. reply bayindirh 4 hours agorootparentThe biggest example is SQLite. It's public domain [0], yet its secret sauce is how the developers know, develop and test the software. They do not accept outside patches, which is not against Free Software, it's more like a cathedral, but it's not \"not open source\". > ...It's not obvious to me that the person who originally wrote the software is necessarily better positioned to support the software. Let's take an example. Scientific software. Something like OpenFOAM, or some simulation code. Open it with GPL, everybody has the source code, but only the developers know the intricacies of material simulation, the fragile math of it, how to optimize it, how to test it. You can fork it to infinity, but unless somebody has the expertise to understand the science of it, nobody can do anything with it, maybe besides breaking it in subtle ways making things worse. > Another party could build a business as the premier support consultants without most of the original developer's startup costs. When you have good enough product with tons of implicit knowledge buried in its source code (see above), it's not easy as it sounds. Many people write CRUD software, and CRUD software has no effective moat. It's just DB dressing and some automation. Start to blend in domain specific knowledge into it, and now we're talking. [0]: https://www.sqlite.org/copyright.html reply Wowfunhappy 3 hours agorootparent> When you have good enough product with tons of implicit knowledge buried in its source code (see above), it's not easy as it sounds. I don't doubt that it's hard. But I'm not convinced that it's harder than writing the software in the first place, so that is still a major savings for the competitor (which they could then use to undercut in terms of rates, etc). As a point of comparison, let's say that SQLite's development team all died in a plane crash. Would a new team throw out SQLite's codebase and start from scratch, because they could never hope to understand the old code as well as something they wrote themselves? No—they'd review the code and documentation and bring themselves up to speed. Maybe they're never 100% as good as the first team, but they'd be quite capable. reply bayindirh 18 minutes agorootparent> but they'd be quite capable. That's the thing. They won't have the same shared vision and abstract model and roadmap of SQLite to begin with. Let's take more examples: Audacious, GIMP, Darktable, DigiKam, Inkscape, KiCAD, Blender... Why these programs are not forked, or forked successfully? These are not niche programs. They are standard tools for some people. The thing is, all of these tools require very deep knowledge about some obscure and hard subjects. Some groups may take them over, but they can't just continue them as is. They will break things, or need to relearn tons of theory and their numerical versions which can be applied in programming languages. I did my Ph.D. in SWE, writing a material forming simulator. Boundary Element Method more specifically. You can't expect a group of people just to say \"Meh, let's fork something like this and just be better\". You can't. You need to know deep numerical math, theory of BEM, need to build the formulae, and know enough CS + numerical linear algebra to transform that math to computer code. I spent 7 years to build one from scratch. Not all applications can be transferred to a new team in two weeks flat. KiCAD is in development for 30+ years, for example. reply sofixa 4 hours agorootparentprev> Now, I'm not sure if this has ever actually happened. If it hasn't, maybe I'm wrong. I would like to be wrong. It has. As a popular example, Percona are among the best consultants on MySQL/MariaDB/MongoDB/databases in general, and they are not related to any of those projects (one of the founders of Percona used to work at MySQL decades ago). reply fbartels 4 hours agorootparentprev> and build a business as the premier support consultants without most of the original developer's startup costs I think a real world example for this would be https://www.collaboraoffice.com/about-us/. And looking at it from the outside a positive example as well. At least I could not find any public beef between collabora and the document foundation (as the organisation behind libreoffice). reply bayindirh 13 minutes agorootparentCollabora guys push tons of code back to LibreOffice, too, as far as I can remember. reply cvwright 3 hours agorootparentprevIt's not necessarily about being better. Sometimes a competitor can beat you just by being cheaper, or by being better connected. One example is that the Matrix project recently took a budget hit when the core team apparently lost a big bid to a \"large system integrator\" who seems to have used their own open source code to bid against them. reply gilgad13 2 hours agoparentprevJust because you want something to have a viable business model doesn't mean it does. If you want to get paid to develop open source software, I think you have a couple of options: 1. Just don't. Work on open source on the weekends, etc. 2. Do it as part of a \"commoditize your complements\" strategy. 3. Work at a company that is so large they can fund open source development as part of their advertising strategy. 4. Gather together some expertise in existing open source projects and sell consulting. Crucially, you'll probably need to build on top of some existing open source install base or name recognition. Redhat didn't start the linux project or the gnu userland, Percona didn't write mysql, etc. In some sense you are now one of the leaches that posts such as this one complain about. The fundamental piece in common here is that the open source bit isn't the main value driver for the business. reply ensignavenger 3 hours agoparentprevHacker News isn't a single mind, so it doesn't \"think\" anything of its own. Personally, I believe there are several \"valid\" business models that include open source contributions. Microsoft, Facebook, Google, Amazon and even Apple all contribute to open source software. Redhat, Canonical, Suse are all companies that have open source software at the heart of their products. Blender and Godot have found viable paths as nonprofit foundations. Linux, OpenStack, Eclipse and others are all foundations that work on a different level, combining contributions from many different companies and individuals, and support multiple projects. There are open core companies like Gitlab that are also \"valid\", while I personally don't prefer the open core model. Automatic sponsors WordPress development, and makes money providing hosting and related services. Automatic competes in a very competitive market with other companies providing hosted WordPress, but they survive. Releasing code as open source is not an automatic mint. Business is hard. Businesses that don't release a single line of open source code fail all the time. It should not surprise anyone when a company that contributes to open source fails, because companies fail all the time. reply zokier 3 hours agoparentprevThe geomsys model, featured two days ago on the front page, seems like being on the right track: https://news.ycombinator.com/item?id=40905849 Don't try to sell software, sell your expertise. Basically variations on consulting. reply jchw 4 hours agoparentprevThis framing is just wrong; there has never been, is not currently, and will never be a guarantee that you can sustain a company entirely off of an open-source offering. If you are concerned about your livelihood then don't hinge it on the viability of open source projects to underpin your business model. I've said it before, I will say it again. reply inhumantsar 3 hours agorootparenti think the issue is less \"sustain a company\" and more the unspoken qualifier \"extremely valuable\". sustaining a small company offering commercial licenses or hosting or support or consulting or whatever for an open source product is not going to be that much more difficult than sustaining any other kind of small company. the issue that I see most often are OSS devs not approaching the problem like a company would and startup founders looking to build a unicorn while also keeping some kind of purity wrt open source. not everything needs VC investment with valuations measured in the tens of millions but everything does need some level of formal business development (even if that business is of the non-profit variety). reply sofixa 4 hours agorootparentprev> I've said it before, I will say it again. Cool, and what is your proposal to people who both believe in open source, build on open source, but would also like to be able to put food on the table and enjoy their work? reply ensignavenger 3 hours agorootparentBlender and Godot both show one possible way to putting food on the table and spending your time contributing to open source projects that you love. Other companies provide consulting and related services. Business is hard, you can't just write some code, throw it over a wall with an open source license, and expect the money to start pouring in. You can get a job at a company like Google, Amazon, Microsoft, or hundreds of others where they pay folks to write open source code, too. reply jchw 4 hours agorootparentprevUhh, suck it up? Just because you really want something to work some way doesn't mean it can work that way. It's just that simple. reply jtwoodhouse 6 hours agoprev\"We want to reduce the threat from businesses such as hosting companies and other resellers who try to commercialize popular open source projects. We’ve seen our self-hosted code being used in a way it was never intended for by corporations that don’t care about us or open source.\" I don't understand why people think they can stop others from commercializing their open source project. You can give something to the world. You can hold onto IP to stop others from cashing in. You can't have it both ways. reply bayindirh 5 hours agoparentThe problem is people didn't understand that BSD/MIT license gives the same freedoms to all. The previous moat was to license permissively, but make it hard/impossible to install on traditional hardware without the (closed) architecture docs, and go closed source at any moment, since BSD allowed that. Given enough eyeballs and persistent people, this moat started to be passed with relative ease, allowing big(ger) corporations to deploy intended-for-your-eyes-only, open codebases to production. Naturally, people didn't like that, and started to move back to xGPL licenses to force modified copies to be open. This forces the parent company which started the project to keep the code open (or make people sign a CLA or don't accept PRs, etc.), but prevents their code from being cannibalized, and makes more sense on the long run because the added value is the service itself rather than the code. CE versions allows deployable open-core versions for the tech savvy. [Actually Plausible says \"A stronger moat for hosted Plausible\", so the plan is exactly it]. So, Plausible at least, is returning to the root of Free Software, not OpenSourceWashed software. This is a good move in my book, and makes me happy that I was right about BSD/MIT in the long run. reply maccard 5 hours agoparentprev> You can't have it both ways You're right, but you're applying idealism to a concept that was popularised 35 years ago to the current landscape. If you want free-as-in-freedom software developed without restrictions with corporate backing, that ship has sailed. What is your suggestion for how to run a business that offers an open source product that isn't going to have their lunch eaten by AWS/Azure/GCP once it becomes popular? If your answer is \"well that's not open source\", then I think you need to take a look at the reality of software in 2024. reply jtwoodhouse 5 hours agorootparentI agree with your premise though I think we need a different word than \"open source\" if that's really the model moving forward. Without going too deep into semantics, the original nature of open source is counter to business interests. If we're using that term for source code that's kinda open for some people some of the time, we risk virtue signalling. reply maccard 5 hours agorootparentThat's a completely fair response I think, but I'd argue that language evolves, and meaning changes. Words and phrases we use now mean totally different things to what they meant 10-15 years ago, and that meaning is driven by common understanding. Using the original intentions for Open Source is well and good, but do you think Richard Stallman foresaw IBM being the primary funding mechanism for GCC in 1989? reply jtwoodhouse 4 hours agorootparentI think that underscores the tension that will always exist with open source. It's nearly impossible for altruism to remain self-sustaining. The rare glimpses when it exists should be cherished rather than conflated with the small business David vs. Goliath complex. reply candiddevmike 6 hours agoparentprevIt's a growth hack. I don't believe anyone who releases their product under a FOSS license will remain FOSS unless the company goes under. It becomes a \"too much money left on the table\" situation. reply zarathustreal 5 hours agorootparentIt’s not even a hack these days, investors look for this as a traction metric reply ossobuco 5 hours agoparentprev> You can't have it both ways. Why shouldn't I? I created a product and I should be able to choose who do I give it to. I want it to be as open as possible while restricting some types of usage I don't like, or that would be detrimental to the continuation of the project itself. I don't see anything outlandish in my statement. reply candiddevmike 5 hours agorootparentThere's nothing stopping you from doing that, but it's not FOSS and you can't use a FOSS license to drive your growth. reply busterarm 4 hours agorootparentI've seen some pretty wild license clauses in things claiming to be FOSS lately...like license termination if you don't support trans rights or if you're anti-furry. reply ossobuco 5 hours agorootparentprevIt is FOSS, it's just not a free meal for FAANG & co. reply blowski 5 hours agorootparentHow would you make the distinction, in a way that is legally enforcable? I can understand why people would prefer FAANG & Co. weren't re-selling their FOSS, but I don't see how you can pick and choose who has access to and is allowed to run your code, and still be open source. Maybe you could have an application process, where you decide to give a license on a case-by-case basis, that can be rescinded later. But I'm not confident you'd get much traction. The OP's point is that product owners want the benefits of being open source, but are frustrated with the downsides. You can't have one without the other, they are two sides of the same coin. reply dr_kiszonka 4 hours agorootparentWouldn't it be possible to have a license that gives different rights based on some binary indicators, e.g., annual revenue (or profit), an individual vs. a corporation, etc.? In theory, this could be gamed, but perhaps it wouldn't be worth it in most cases. reply sofixa 4 hours agorootparentBSL usage grants sometimes do exactly this (free if you have less than X annual revenue) or similar (free if you're not competing with the company behind the project). But it's technically not open source since there are usage restrictions, and considered \"source available\" which isn't descriptive enough IMO. reply kapilvt 5 hours agorootparentprevFAANG & Co won't touch AGPL, ditto for most enterprises. There are some exceptions in countries with weak IP enforcement on smaller players. reply blowski 4 hours agorootparentInteresting. Why don't more of these open source companies complaining about being cannibalised adopt AGPL instead? reply cvwright 3 hours agorootparentMany of them are going AGPL, including the one we're discussing. Also recently Minio and the Synapse Matrix server from Element. reply blowski 3 hours agorootparentWhat's the benefit of SSPL over AGPL? (You can probably tell I'm not an expert in this!) reply FridgeSeal 5 hours agorootparentprevI don’t think it’s unreasonable that the people who develop some software and run a business doing so, wish to not have their livelihoods cannibalised out from under them by some larger entity. I think the sunshine and rainbows idealism of some of the licences and OSS gatekeeping was fine 20 years ago, and works fine for certain kinds of software and mature, well-established projects (compilers, Postgres, MySQL etc) but these days, no longer fits the reality of the software landscape. reply colechristensen 6 hours agoparentprevAnd on top of that how many open source products are they commercializing? Compilers, programming languages, operating systems, dev tools… reply yamumsahoe 4 hours agoparentprevreal. wants the good parts of open source and hating the bad parts of open source. reply FlamingMoe 6 hours agoprev [–] I've been a paying customer and advocate of Plausible for over 2 years, and this is not ok. Marko frequently posts on social media about Plausible's revenue growth, currently at over $1M ARR with a tiny team and little overhead. They are doing great financially. Yet in this post he tries to gain sympathy by focusing on \"we only make $300/mo in donations\". Frequently moving the goalpost on what it means for your product to be open source betrays a lack of integrity and will have me, and probably others, looking for an alternative. reply martypitt 4 hours agoparentCounterpoint: I've been a paying customer of Plausible for ~2 years, and this is totally fine. $1M ARR with an 8 person team is by no means \"doing great\". Assuming 20% of income goes to overheads (such as hosting, marketing, legal, accounting), that leaves a salary of $100k for each staff member. Even if they had 0 overhead, this is still only $125k each -- that's hardly big money. Also, in reading the post - I find little to object to. They're not changing their license. They're not doing anything to prevent self-hosting. They're making it clear they're not offering support to people who don't pay (completely reasonable), and gatekeeping a few features that add value - while still giving away a huge amount for free. That's a fair deal to ensure the company remains viable, which is in everyone's best interest. In practice, this decision is unlikely to materially impact anyone. Open source is a gift, not a right, and certainly not an obligation - and from what I can see, they're not doing anything here that undermines the Open Source-ness of their offering. FWIW, I'm not sure you'd find an alternative analytics offering that's both commercially viable, and \"more open\" than what Plausible are offering today. reply diggan 4 hours agorootparent> this is still only $125k each -- that's hardly big money. That works out to be about $10.5K (9.7K EUR) per month, pre-tax. I'm not sure where you're from/at geographically in the world, but in most places where I have lived that would be considered a large salary for just software development. Outside of the major cities in the US, wouldn't that also count as a fairly large salary? reply tssge 4 hours agorootparentJust so you know businesses have other expenses than just salary. These can range from insurance to office space to accounting to server hosting and so on. $1M ARR is not very much when you have almost 10 employees. This would be considered rather modest. Generally the rule of thumb for me has been that each €100k ARR is an absolute minimum to hire an additional employee, thus €1M ARR would be an absolute maximum of 10 employees. reply diggan 2 hours agorootparent> $1M ARR is not very much when you have almost 10 employees. You're talking from the perspective of the company, I was specifically replying to the \"this is still only $125k each -- that's hardly big money\" part, which I thought was very clear since that's the part I quoted. Besides, parent already went through those, their back of the napkin guessestimate is after other expanses. Click the \"parent\" link next to the timestamp if you're having troubles finding it. reply HuwFulcher 6 hours agoparentprevThey make $300/mo from donations from those that self-host. The point they are making is that enterprise level users are self-hosting and not putting back into the running of Plausible. I still think the way they've done this stinks though. reply otherme123 4 hours agorootparentI understood that the biggest problem is that some people self host and resell. Sometimes offering a shitty service that might be confused as Plausible-Cloud, damaging the brand: \"Plausible is shit, back to Google Analytics\". reply dewey 4 hours agorootparentprev> I still think the way they've done this stinks though. What would you do in their position? This seems like on of these things, just like changing the design of your product where you will never be able to make everyone happy and there will always be a small group complaining. reply tedivm 5 hours agoparentprevThey might only be making $300/mo in donations, but the only reason I'm a paying customer of theirs is because the product is open source. When Fathom stopped maintaining their open source version I moved to Plausible, even though I am not self hosting. The $300/month is absolutely ignoring the free marketing they get, plus the fact that many users such as myself only use their paid product because it is open source. reply codegeek 5 hours agorootparentCurious. If you are using the hosted version, why do you care about it being Open Source ? More of a backup plan in case they go under or is it more about Trust or both ? reply tedivm 5 hours agorootparentIt's a bit of both. It gives me confidence that I have a backup plan, but really trust is the bigger issue. An analytics tool gets a lot of data from people and being able to validate what they're doing is important. Additionally though I signed up to support an open source company, because I think open source is better for society. I like giving money to open source projects. I would rather give money to an open source group than use a free product like Google Analytics. I like being able to support open source companies, and I get annoyed when they do rug pulls like this. reply codegeek 1 hour agorootparentThx. Yea I figured but wanted a confirmation because I am looking to start an Open Source project and getting feedback on the WHY Open Source part from potential customers. reply maccard 6 hours agoparentprev [–] If that is your take away from this post I urge you to read it more carefully. reply FlamingMoe 6 hours agorootparent [–] If you have a counterpoint I urge you to make it. reply simonw 5 hours agorootparent [–] Near the start of the article: \"That license change has helped us build a sustainable open source project with 8 core team members and several paid external contributors at the time of writing. We don’t have any investors, so all this is solely funded by the fees our 12,000+ subscribers pay us.\" Then later on while talking about the self-hosting option: \"We make $300 per month from donations from our self-hosted users. It would take us more than ten years of donations to pay one month of salary for our small team.\" That's only misleading if you skim the article. They clearly differentiate between the 12,000 paying subscribers who fund the operation compared to the $300 in donations from self-hosters. reply tedivm 5 hours agorootparentI'm a paying customer. I paid for it because of the open source license. The thing that is misleading is pretending that being open source only makes them $300/month while ignoring the number of customers who chose them because they are open source. reply maccard 5 hours agorootparentprev [–] Thanks - this is exactly it. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Plausible Analytics has launched the self-hosted, AGPL-licensed Plausible Community Edition (CE) to better protect their open-source project from corporate misuse.",
      "Key changes include renaming the self-hosted release to Plausible CE, excluding some features for managed hosting, and requiring external contributors to sign a Contributor License Agreement (CLA).",
      "These changes aim to ensure the sustainability of Plausible Analytics while maintaining the AGPL license and protecting their brand through registered trademarks."
    ],
    "commentSummary": [
      "Plausible Community Edition is under scrutiny regarding its licensing, open-source status, and the separation of proprietary and open-source code.",
      "Users are concerned that the community edition may lack features compared to the managed version, potentially pushing them towards paid plans.",
      "The debate underscores the tension between maintaining open-source principles and ensuring business sustainability, with some viewing Plausible's actions as necessary and others as a betrayal."
    ],
    "points": 120,
    "commentCount": 90,
    "retryCount": 0,
    "time": 1720604934
  },
  {
    "id": 40920246,
    "title": "How to validate a market with development boards and SD cards",
    "originLink": "https://flyingcarcomputer.com/posts/how-to-validate-market-with-development-board/",
    "originBody": "Posts How to Validate A Market With Development Boards July 9, 2024 I came across an article from Cooley Go that I wish I had seen sooner. It should be required reading for anyone thinking about making an electronic device, even though the article is specific to the US market. Devices subject to the FCC’s rules cannot be marketed until they have completed testing and, if necessary, have been approved by the FCC. Marketing includes selling or leasing a device, advertising that a device is available for sale or lease, and importing a device for purpose of selling or leasing it. Yikes. It is possible to market a device without actually selling it. In fact, the FCC has fined companies for displaying unauthorized devices at the CES trade show. These rules apply to all kinds of marketing, including via websites, social media and other online media. The FCC has not provided any guidance on whether offering a device as a premium on crowdfunding sites constitutes marketing, so there is some risk to doing so. The line about CES, in particular, made my hair stand up. The testing and certification industry is odd. In theory, it exists to serve the public good and uphold consumer protection laws. On the other hand, its customers are in the private sector. Normally, market forces would dictate that by now it would be straightforward, fast, and affordable to get your product tested as frequently as desired. However, in reality, the labs are “too busy” to respond or reply very late and generally sound less than eager to work with you. Not to mention, the fees that they quote are rarely palatable to a bootstrapping startup. And yet, working with them is generally required to get your product to market. While some consultants suggest that there are “sales test” exceptions, I remember a person much smarter than me once telling me that “[government agencies] are very unambiguous about [these sorts of things]”. Variations of the FCC exist in pretty much every developed economy. Putting a poorly tested hardware product on the market immediately puts a target on your back. Maybe you’ll get lucky, but chances are that someone somewhere will report you. And, unless you are operating entirely out of China, it will hurt. A lot. Both your company and maybe even you, personally. At this point, despair started setting in once more. The way I saw it, I had three options. The first is to give in and pay up. The second is to exclusively sell in countries with weak consumer protection laws. Then there was option number three. I did not want to spend so much money on testing before I validated the market or gathered a community of believers. The second option made little sense too. So, I started thinking of how to get some kind of sales going while shielding myself from some liability. Then it dawned on me that the Allwinner A20 SoC is the centerpiece of the hardware. It is probably one of the most ubiquitous chips on the market today, and there are countless development boards for it that are already being sold globally. I don’t need to sell the development boards. I just have to tell my customers which boards to buy and how to set them up. This way, the electronic device liability will fall on the manufacturer, and the magic of friendship EULA should afford me enough protection to make this a pure software play. My significant other would like to take credit here for having suggested this strategy months ago. This just leaves the OS and the software delivery problem. Fortunately, many of these development boards have one important thing in common. All of them can boot from an SD card, which is usually where the manufacturer puts the OS and software. Flashing the SD card correctly is pretty challenging even for me. I can’t imagine a customer figuring it out. So I will flash it for them! Now, how to get the SD card in the hands of the customer? Mail it to them! Unlike a bigger bulkier board that would have had to be packaged correctly and go through customs, an envelope should theoretically arrive at your door in the same manner as your new credit card. It would also be far easier and cheaper to create a good strong first impression just by using nice stationery. Incidentally, new age digital banks take advantage of this opportunity to create the Wow factor because it is usually the only point of physical contact they will have with their customers. Old age banks just send a boring piece of paper with some glue because they know you will inevitably have to walk into one of their physical branches. All of this made me reminisce about the beautiful stickers on floppy disks that were succeeded by jewel cases for CDs. I have a feeling that many people long for the physical these days, and it is making a comeback. Once the SD card is in place, OS and software updates can then be delivered via a file downloaded to a simple USB drive. The customer would be able to order the SD card from my e-commerce store. This means that the new goal is to sell as many copies of the OS as I can. Then, count the number of customers from each country. This will tell me which economies’ certifications should be prioritized when I build my own electronic device around the A20 chip. I can start selling immediately. Or as soon as the OS is ready. Instant market validation and product market fit with minimal spend. I’m excited. Keep any eye on my progress by subscribing to the mailing list!",
    "commentLink": "https://news.ycombinator.com/item?id=40920246",
    "commentBody": "How to validate a market with development boards and SD cards (flyingcarcomputer.com)120 points by zkirill 23 hours agohidepastfavorite96 comments Animats 17 hours ago> Market forces naturally determined this outcome though. Market forces alone didn't work. It's an externality, a cost paid by others not involved in the transaction. Market forces don't handle that. A 1970s Milton Bradley Big Trak and a Radio Shack TRS-80, both popular products in their day, will, if brought near to each other, both crash. Without fairly strict regulation of unwanted RF emissions, there would be many incompatible devices. There were before the FCC started requiring more testing in the 1970s. A world with a huge number of consumer devices emitting RF noise would have prevented low-power cellular phone and WiFi deployment. It's not that hard. This is an \"unintentional emitter\" (it's not trying to send a radio signal). The rules for that are not too bad. Testing costs about $3000 to $5000. You want to have some ability to pre-test. You might find something. Attaching a wire to something can give it an antenna and make it emit much more RF, so you do need to test. It's not too hard.[1] Actual FCC certification is $3000 to $5000, assuming you pre-tested and fixed any problems before getting a certification run. From the project's FAQ: \"Given that this will initially be a niche product, the price will be quite high. I was once taught to ask myself the following question: Who is your rich customer? The type of person whom I have in mind has a high discretionary budget for personal electronics and willingness to pay a premium for novel ideas.\" [1] https://www.nutsvolts.com/magazine/article/low-cost-emi-pre-... reply bruce511 15 hours agoparentThe first rule of knowing if a market exists is to define what you are making and then figure out who it's for. Then pitch to that person the benefits of your product. Alas the FAQ page lacks both of these questions. I'm left with no idea -why- I'd buy this thing. What utility does it have? What is it supposed to replace? I think you can stop worrying about the FCC issues with it. You won't sell any of these (at least not with this FAQ page). Your whole \"discussion\" is technical and doesn't mention utility once. It sounds to me like you're building this because it's fun to build and scratches an itch. But it's not a product, much less requires you to start building and designing new hardware. So well done on at least skipping that investment. If you want to make a hardware product then early about utility first. If it's useful then other things flow from that. Not the other way around. reply willsmith72 14 hours agorootparent> The first rule of knowing if a market exists is to define what you are making and then figure out who it's for. Then pitch to that person the benefits of your product. I would switch that order. Figure out your customer before you define what you're making. reply bruce511 12 hours agorootparentYes, that's even better. reply olalonde 9 hours agoparentprevWhy is it so expensive though? Also, why not fine or ban products that cause problems rather than requiring certification. It seems that would be a lot more efficient. reply moooo99 8 hours agorootparent> Also, why not fine or ban products that cause problems rather than requiring certification. Because certifying upfront is cheaper than trying to find products that cause problems in the field, do lots of testing and find somebody and recall all the other products that are in the field reply pjmorris 5 hours agorootparentIt seems like fining or banning problems found problems 'in the wild' would require customer troubleshooting to find the cause, manufacturers would lose the product development cost for banned products, and the regulator(s) would have to staff for discovery in the field rather than in the lab. IMO, this seems like it could be more expensive than finding potential problems early. reply buescher 6 hours agorootparentprevIt's not expensive. What does a week of a good hardware engineer's time cost? It's not even necessarily that expensive: $3K-$5K is a good budgetary range if you don't have any pre-compliance test and engineering capability because you might need 2-3 trips to a certified test lab to pass. If you have experience in your product space and good pre-compliance testing, you can definitely be one-and-done for less than that. reply rsynnott 1 hour agorootparentprev\"We've just bought 50,000 new whatevers for our worldwide chain of stores... Oh, oops, they cause EM interference, throw them away I guess.\" (More realistically, you'd just see extremely slow adoption in any important use-case.) reply KolmogorovComp 9 hours agorootparentprev> Also, why not fine or ban products that cause problems rather than requiring certification Because people could get hurt or killed in the meantime. See the 737max for example. Now it is a dramatic example, but think about any device unwillingly emitting too much electromagnetic radiation potentially being harmful to kids or messing with people pacemakers. reply olalonde 9 hours agorootparentYou could make similar arguments for basically any product, doesn't seem worth it to get every product certified though. Also, didn't the 737max pass certifications? reply pjc50 7 hours agorootparentAlmost every product is certified in the EU (CE marking), although if you look closely it's self-certification and it's not always clear which sets of certification might be required for a product. (I'm on the fence about this; personally I think there need to be far more small company / small production run exemptions from these requirements, but on the other hand I don't want a loophole for recklessly dangerous products) reply olivierduval 4 hours agorootparentWorst of all: if you package certified CE product... you need to certify the whole package too!!! Think about using some certified CE PC in a cabinet for example... On the other side: if you forget ventilation in the cabinet, the certified PC might burn... so packaging CE certified components doesn't mean that the whole is risk-free reply pjc50 3 hours agorootparent> Worst of all: if you package certified CE product... you need to certify the whole package too!!! Yes. This is a significant difference from the US, where FCC compliance testing for modules is much more reasonable. The US also appears to contract out basic electrical safety to the insurance industry (Underwriter's Laboratories). reply buescher 1 hour agorootparentThe NFPA writes the national electric code. They also came out of the insurance industry, and like UL and FM, predate adoption of their standards in regulation. FM is an actual insurance company but it is not OSHA. The history is similar to European organizations like the German TUeV, which came out of the boiler industry. All of them have their roots in disasters of the industrial revolution. Governments today generally don't operate test laboratories, standards organizations, or certification bodies. DIN, ISO, IEC, BSI etc are not government organizations. You're right, though, that there's more history of insurance industry involvement in developing safety standards and testing in the US. reply wsc981 5 hours agorootparentprev> Almost every product is certified in the EU (CE marking), although if you look closely it's self-certification and it's not always clear which sets of certification might be required for a product. Not to be confused with the Chinese Export marking: https://www.kimuagroup.com/news/differences-between-ce-and-c... reply okanat 4 hours agorootparentThe amount of misinformation on the internet is worryingly high but not unexpected. No such thing as Chinese Export logo exist. It cannot officially exist in the EU since the CE sign is protected. Whatever this website is sharing is FUD and misinformation. It doesn't mean that nobody fraudulently puts those markings on devices without a testing certificate backing it. However anybody who puts CE mark on a product without complying is risking being punished by EU member states. As an importer and distributer of such goods you'll be punished as well. CE certification is indeed self disclosed but it doesn't mean that you would get away with noncompliance. Source: https://www.europarl.europa.eu/doceo/document/P-6-2007-5938-... reply pjc50 4 hours agorootparentThe \"China Export\" logo is extremely funny as it's basically a Chinese response to \"you need a label? OK, fine, we'll give you a label\" with none of the underlying bureaucracy. The \"UKCA\" one, on the other hand, is real but tragic. reply specialist 2 hours agorootparentprevUsing fraud as a counter example, where the self certifying manufacturer admitted to the crime before Congress, kinda seems like missing the point. Ditto Dieselgate. Doesn't negate the need for testing. Rather, it shows the need for effective oversight. reply delfinom 5 hours agorootparentprevCertification requires testing in a specialized lab that has a special anechoic chamber along with equipment that runs tens of thousands to hundreds of thousands of dollars. You also need an engineer or highly trained technician to run the test and/or interpret the results. You also have to wire up and instrument every device that comes in and they do vary a little. That's why the cost is in the thousands of dollars. There is a profit margin for the labs but it's also not a cheap service. It is not efficient policing bad devices after the fact. You can have a bad device interfere with RF communications for miles. It then requires dispatching a team of humans with RF probing equipment and escalating to the Feds if the person refuses to comply. It does happen but it is time consuming. Leaky RF can cause mass events such as https://www.cbc.ca/news/canada/calgary/carstairs-westview-co... Here's a IEEE Video on the process of interference hunting: https://www.youtube.com/watch?v=elUDfDmIHLs A short article on how some equipment on a tug boat was interfering with a town: https://www.verizon.com/about/news/verizon-test-force-braves... And this is the interference hunting that has to happen now with devices certified. It would be an absolute hell if devices could just be introduced willynilly. reply joezydeco 16 hours agoprevNow, how to get the SD card in the hands of the customer? Mail it to them! I worked on a equipment project for a large restaurant chain about a decade ago. The core application and related assets/recipes/files were all on an SD card. When it was time to upgrade the app or release new seasonal recipes, every store got a new SD card in the mail with instructions to wait for a certain date, power down, swap cards, power back on, dispose of the old card. It was way cheaper to send updates that way than bother with encryption, networking, corrupted disks, etc. A bricked machine lost a hundred dollars or more per hour. If the new card failed, the operator could continue with the old one until a replacement could be sent. One major problem was suppliers always trying to swap to lower cost SD cards, even counterfeit ones (c.f. Bunnie), and things would go south really fast. The Linux system and hardware were both pretty old and had MMC stack issues when the cards showed shaky margins on the timing. Or, capacity wasn't what was advertised (c.f Bunnie). We had to spend a cycle or two qualifying each mailing release to make sure a shitty batch of cards didn't make its way into the stream. SD has its uses, although I still prefer a read-only eMMC partition to hold the bootloader and O/S. I don't get why RPi users put themselves through such misery to save $20 on their SBC. reply buescher 5 hours agoprevYou can find statements and notices and citations and such on the FCC web site to see what happens if you get caught out. If you're interested in that kind of thing, they're interesting reading. Here is a pretty bad scenario for apparently willful unintentional radiator violations, where an ultrasonic foot bath company was at best unorganized and slow to comply with testing and labeling requirements: https://docs.fcc.gov/public/attachments/FCC-18-67A1.pdf Here is a better scenario, where an LED sign manufacturer was a bit more on the ball: https://docs.fcc.gov/public/attachments/DA-22-1136A1.pdf Note in both cases there is no mention that these devices emitted RF above allowed limits for unintentional radiators. These companies simply didn't test and didn't label their devices appropriately. Here's one for Asus, where they got WiFi products certified, and then changed something, probably firmware, that allowed those devices to transmit more power than allowed: https://docs.fcc.gov/public/attachments/FCC-24-69A1.pdf reply Aurornis 15 hours agoprev> Normally, market forces would dictate that by now it would be straightforward, fast, and affordable to get your product tested as frequently as desired. However, in reality, the labs are “too busy” to respond or reply very late and generally sound less than eager to work with you. Not to mention, the fees that they quote are rarely palatable to a bootstrapping startup. The various test labs I’ve worked with haven’t been “too busy” to respond. However, they are generally hesitant to work with people who don’t really know what they’re doing. If you are an engineer with knowledge about the process and who needs a lab to partner with, it’s not hard to get in somewhere. However, if you don’t have the knowledge or experience, the lab might sense that you’re looking for someone to hold your hand heavily through the process. They may be less than enthusiastic to take on a one-off customer who might require an abnormally high amount of communication and hand-holding when they can fill that same spot with a repeat customer who needs nothing more than to book the time at the lab and can show up prepared and ready to go. I suggest teaming up with a local consultant for your first round. Not only will they help you through the process, they’ll have connections and reputation to get you into the labs. The lab fees aren’t extraordinary high for a hardware startup, really. It’s not free, but it’s not much relative to the up front costs of building hardware inventory. reply fellerts 11 hours agoparentIn my limited experience, it was the other way around. I had to hold the technician's hand through most of the testing and onboard several technicians due to a staggering amount of employee churn in the test house. What should take an afternoon would take months of intermittent testing at very inconvenient times (night slots). Next time I might just show up outside their door with a sleeping bag and refuse to leave until the tests are completed. Maybe we were the problem and our documentation was insufficient, but we never had a chance to do a \"post-mortem\" with the test house and learn how we could do better next time. reply AnarchismIsCool 2 hours agoprevOk so as someone working on something vaguely similar (portable computer, slightly different market, more RF focus) I assure you this person is just rambling on a blog. Basically everything on their blog/faq ranges from inept to dangerously misleading. reply Rovoska 13 hours agoprevI would be embarrassed to publish this. It is a stunning display of ego and ignorance of how this part of the world works that boils down to the author being too cheap to put in the work and too lazy to understand why regulations exist. reply AnarchismIsCool 2 hours agoparentIt's wild to me that everyone here is taking this seriously. This is high school science fair level stuff. reply practicemaths 19 hours agoprev\"The testing and certification industry is odd. In theory, it exists to serve the public good and uphold consumer protection laws. On the other hand, its customers are in the private sector. Normally, market forces would dictate that by now it would be straightforward, fast, and affordable to get your product tested as frequently as desired. However, in reality, the labs are “too busy” to respond or reply very late and generally sound less than eager to work with you. Not to mention, the fees that they quote are rarely palatable to a bootstrapping startup. And yet, working with them is generally required to get your product to market.\" Market forces naturally determined this outcome though. If you're big companies you naturally want to limit the threat of new competition. Making compliance more costly achieves this. reply Aurornis 15 hours agoparent> Market forces naturally determined this outcome though. If you're big companies you naturally want to limit the threat of new competition. Making compliance more costly achieves this. Compliance for basic products isn’t costly, though. It’s a rounding error relative to the wages you have to pay engineers and the costs involved in manufacturing the product. reply bboygravity 11 hours agorootparentIt is a high cost to certify when you're not paying yourself and you're the only person in your startup/hobby. Cost of DIY hardware design: 0 Cost of PCBA from China: rougly 100 to 2000 USD depending on complexity and nr of runs. Cost of DIY firmware and software: 0 Cost of external certification/compliance tests: 5000 to 25000 USD depending on the amount of runs it take to make it pass and what needs to be checked and what the industry is (battery management safety, medical, aerospace, FCC and/or CE, RED and/or others, etc). So yeah, an RnD department wouldn't really care, but \"guy in mom's basement\" would. reply pjc50 7 hours agorootparentThis. The compliance requirements take out an entire tier of small companies and short run products. This eliminates a lot of potential startups at the first stage. You don't get quite so many big companies without going through the small company stage. You're limited to VCs and spinoffs of other megacorps. But I guess everyone is happy with the equilibrium that's actually emerged (buy your unregulated short run electronics from China). reply gizmo686 3 hours agorootparent$10k is peanuts for starting a small business in many industries. It does not even buy you a truck. You don't need VC or a megacorp; this is well within the range of standard business loans. reply bildung 11 hours agorootparentprevIf the project is actually just a hobby, then CE and probably FCC testing is not needed. If the project is a startup, then the cost of labor is not zero, at least not if people are not deluding themselves (i.e. at least opportunity costs should be considered). Personally, as a consumer, I'm pretty happy that I can buy e.g. a wireless mouse or a bluetooth speaker and can reasonably assume that they actually work and aren't accidently jammed by some \"startup\"'s hardware. reply crote 2 hours agorootparent> If the project is actually just a hobby, then CE and probably FCC testing is not needed. That's the entire problem: According to the law, it is! There are extremely few exception, and the exceptions that do exist are essentially useless for hobbyists. Everyone selling small-scale prototypes on websites like Tindie is just rolling the dice and hope they don't get get a life-ruining fine. There are plenty of $5-$50 trinkets I'd like to design and sell as a hobby to fellow enthusiasts, due to their niche nature probably only a few dozen of each. But there's no way I can afford a $5000-$10.000 testing & certification fee on each one of those, and without that I'd be breaking the law. reply femto 17 hours agoparentprevBig companies are often outside \"the market\", in that they have internal labs which are accredited to test their own products. reply eYrKEC2 18 hours agoparentpreva.k.a. \"regulatory capture\" - https://en.wikipedia.org/wiki/Regulatory_capture reply bildung 11 hours agorootparentEnforcing basic device safety is hardly regulatory capture. I was part of preparing devices for CE tests, the requirements are essentially: nobody gets killed if the hardware is plugged in, you haven't accidently created an rf transmitter, and if you want to advertise IP67 it should survive being placed under water. reply tootie 18 hours agoparentprevI used to work at a place that did some custom hardware development. Usually one-off or very limited run. Any time we fabricated a case and plugged in off-the-shelf devices, certification was not necessary. If we did custom wiring we got ETL certified. I didn't run the process myself but I recall it being easy and not very costly (few thousand?) It's a barrier but a pretty low one. Our electronic work was like advanced amateur level and it still passed with minimal modifications. reply taneq 18 hours agoparentprevAlso, by definition, testing and certification companies have a captive market and will tend towards being lazy and exploitative. Any competition that springs up might temporarily improve things but then it too will get used to having a captive market and start sliding in the same direction. reply rererereferred 20 hours agoprevTheir FAQ here[0] explain some things about these devices they are building, except for the main question: what are they for? It says personal computers but no audio, video or games. So for reading? [0] https://flyingcarcomputer.com/posts/a-new-personal-computer/ reply chrisldgk 19 hours agoparentReading this, it doesn’t seem like they’re really doing anything more than building a glorified raspberry pi with their own self-spun BSD distro preinstalled. Also the FAQ being mostly Q: „why not use X?“, A: „I don’t know X and thus it’s bloated/I don’t like it“ doesn’t inspire a lot of confidence. I admire their dedication and it seems like a fun project. I don’t think it’s something a lot of people will pay money for though. reply biosboiii 10 hours agoparentprevThe FAQ is hilarious. He is writing this entire article to save 3-5k conformity tests, but bases his entire software on FreeBSD because \"it's more commercially friendly. reply buescher 2 hours agorootparentThis new type of personal computer runs... xlib and twm. I like this person, but, uh, I'm not investing. reply sgerenser 19 hours agoparentprevLooks very weird. No LCD screen, but presumably it’ll plug into a monitor? Seems like just pointing out expected use cases would go a long way. reply iamleppert 1 hour agoprevIs it possible to couple compliance testing with an LLM? I smell a new business model. reply liminalsunset 19 hours agoprevThere are plenty of products which ought to be certified but are not, and plenty of products that probably do not need to be that are. This is across large and small companies, so I'm going to take a guess and say that in the AliExpress and Temu age, simply mailing the device from China will solve all of your problems. reply Aurornis 15 hours agoparent> so I'm going to take a guess and say that in the AliExpress and Temu age, simply mailing the device from China will solve all of your problems. Your guess would be wrong. The regulatory agencies aren’t inept. They’ll figure out where the headquarters is, not just where the products are being shipped from. So unless you’re moving the entire company, and your bank accounts, to China and you have a backup plan for what happens when they start seizing your shipments at the border, this isn’t a solution. reply liminalsunset 15 hours agorootparentDo you actually have an example of something like this actually happening? From what I can tell, at least in Canada, absolutely nothing from China I've bought has ever even been opened for inspection, and it's all tagged as a gift worth ten cents and a battery cover or something inane like that. Anything from half a kilowatt hours of laptop batteries to miscellaneous electronics has passed through, so I don't think there is any inspection going on at all. Anecdotally based on the number of things that I see without any FCC ID (tbf you can abuse the SDoC process which is self declared [this is why the CE certification is worthless btw] ), I'm just uncertain the FCC actually does any enforcement. And Amazon sellers are also an example of this not being an issue. reply HeyLaughingBoy 2 hours agorootparentYep. Fluke, an electrical instrument manufacturer, has a copyright on the look and feel of its handheld digital voltmeters (DVMs). Anyone in the industry will immediately know a Fluke by what it looks like. And they are pretty much the gold standard of handheld DVMs. Some years ago, a containerload of cheap DVMs from China arrived with a similar appearance, but not made by Fluke. Customs seized the lot and informed them. I forget the details of what happened next, but they were not allowed to be sold in the US since they were in violation of the Fluke copyright. reply fxtentacle 10 hours agoprevI wonder how much research this person did. At least in Germany, cheap DIY kits are everywhere !!! https://www.pollin.de/p/bausatz-led-wechselblinker-810051 German company selling a German-made electronics kits in Germany without CE certification. And they have lots of them: https://www.pollin.de/bauelemente/bausaetze-module/bausaetze... As long as you don't connect to mains power and you don't ship a finished product, you're exempt from CE certification. So use an USB plug as your power supply and sell it as DIY kit to be assembled by the customer and you're good to go. reply ctrlw 6 hours agoparentDIY/parts are a fuzzy area and might not need the certification, but the board at your first link does have a huge CE print near the LEDs. Edit: I found this Make article (paywalled and in German) a good overview for makers wanting to sell hardware in the EU: https://www.heise.de/select/make/2017/6/1513996282631753 reply pjc50 7 hours agoparentprevThe US and EU regulatory systems are quite different. reply okanat 4 hours agorootparentThis exact blog also complained about EU regulation and selling stuff in EU. I think they basically don't know what they are doing. reply pjc50 4 hours agorootparenthttps://flyingcarcomputer.com/posts/strategy-for-eu-bootstra... ? I agree about the ambiguity of CE marking. It's pretty impenetrable as a non-expert. I wonder if he's referring to Fabius the Delayer. > It even made me suspect that it is easier for a non-EU country to sell to customers in the EU than it is for an EU company to do the same. An advantage that Chinese businesses surely enjoy. 100% correct. There's way too many small parcels for customs to check them; the major nuisance is the recipient having to pay the tax themselves. > If one were to incorporate in Estonia but not sell to anyone in Estonia, or any member of the European Union for that matter, that company would theoretically be exempt from a whole cluster of legal and tax headaches. .. but why would you do that? This guy appears to be a US national, he should just register in Delaware like everyone else. The Estonian company and \"E-Estonia\" system is primarily useful if you do want to do business in the EU and have a presence there. If you're not in the EU and want a flag of convenience company registration, the usual places like Grand Cayman offer their services. reply buescher 2 hours agorootparentWhat an odd person. I can't figure the Estonia thing out either. I think the idea is to provide plausible deniability that the company is operating in the EU??? By incorporating in the EU but doing nothing else there? I can't imagine what specific legal and tax headaches one would escape that way. The CE marking is super simple in principle, right? Just self-certify that you meet all applicable European regulations, and that's when the fun starts. It would be impenetrable to do from scratch but as \"negative zero\" points out, you can bootstrap from looking at competing products' declarations of conformity. reply mschuster91 2 hours agoprev> Variations of the FCC exist in pretty much every developed economy. Putting a poorly tested hardware product on the market immediately puts a target on your back. Maybe you’ll get lucky, but chances are that someone somewhere will report you. And, unless you are operating entirely out of China, it will hurt. A lot. Both your company and maybe even you, personally. And that for good reason. Any bad actor on the RF spectrum can be an actual, significant and direct threat to people's lives - particularly the EMS bands as well as the rail, marine and flight safety/coordination channels are absolutely vital. Up next is stuff like GPS, radio and television where disturbances affect a lot of people, and then there's local stuff like wifi, Bluetooth, Zigbee, door openers and whatnot that only affects very few people. Unfortunately it is very, very easy to be a bad actor on the airwaves. Powerline/PLC is hated by radio amateurs for a reason, and that one is actually even licensed. The other stuff is much, much worse. reply cwoolfe 4 hours agoprevYes! And don't forget to somehow encrypt the data on your SD cards, or do a check-in with the cloud to activate, otherwise your customers can make copies and give away all your software for free! reply jvanderbot 18 hours agoprevI never understood the nuance here. If I put a rasp pi in a box, does it need certification? What about with connections soldered on if all connections are already certified? How about the logical next step of a board with certified components? reply TheCleric 18 hours agoparentI’m no expert but I think the problem is that once you start combining certified components in a new configuration that it’s theoretically possible for the sum of the parts to be non-compliant. Perhaps a wire you added becomes, in essence, a transmission antenna of the noise in the circuit and thus could interfere with other devices. reply utensil4778 3 hours agoparentprevAs far as I understand, modules like an ESP32 for example, carry their own FCC certification. If you include them in your product, you do still need certification of the product overall, but you don't have to worry about the radio certification, just unintentional radiators. For instance, if your widget includes an ESP32 and a switching power supply, you are (notionally) guaranteed to never fail certification due to bad behavior from the ESP, but if you botch your power supply design and are spewing out noise in the KHz to MHz range, you still fail certification. Even if every individual component in your device carry their own certification, you still have to certify the product as a whole. Poor PCB design can produce bad EMI. Maybe you're running SPI over a long wire or your traces are routed in a way that accidentally creates an antenna at your SPI clock frequency. Hell, even something as simple as toggling a GPIO pin once a second can emit high frequency EMI under the right conditions. There are a lot of ways to unintentionally produce harmful EMI, and that's exactly why FCC certification is required for everything. This stuff is hard to get right and there are endless gotchas and exceptions and edge cases and you have to know about and account for all of them. reply petsfed 1 hour agorootparent>This stuff is hard to get right and there are endless gotchas and exceptions and edge cases and you have to know about and account for all of them. And this is also a major source of the cost of the testing. You're not just paying $5k+ for a piece of paper that says \"FAIL\" on it, and \"better luck next time\". The test engineers want you to pass, ultimately (if for no other reason than because you can't get repeat business from a customer who goes out of business), so they're going to point out the common sources of harmful EMI they've seen in other designs. reply jvanderbot 2 hours agorootparentprevThis makes sense. Thanks for ELI5. Presumably EMI certification is easier than the FCC RF certification. reply analog31 19 hours agoprevIs there such a thing as low-cost testing and certification services operating overseas? reply jkestner 12 hours agoparentYes. The FCC has a list of accredited testing labs here: https://apps.fcc.gov/oetcf/eas/reports/TestFirmSearch.cfm Many are in China and have reasonable prices. reply Aurornis 15 hours agoparentprevThere are labs in China that will wink wink pass any product you send them for a flat fee. The problem is that having passing test results from a random lab doesn’t help you if the FCC (or one of your competitors) discovers that your device is not actually compliant. So you have to be careful about what you’re getting. reply miki_tyler 17 hours agoparentprevThat's a TERRIFIC idea and a great business model. reply analog31 16 hours agorootparentActually, I'd use such a service myself. reply Joel_Mckay 19 hours agoprevYou do know many devices like Raspberry CM have FCC/IC modular pre-compliance, and thus usually only require LAB EMI testing under the rules. The primary problem with mystery-parts is they tend to have issues with RoHS documentation, complex customs clearance requirements, and unknown specifications. DIY evaluation kits people assemble do fall under a sort of gray area, but if your hardware does splatter the RF spectrum it is a $1m fine in the US, and a $5k fine + up to 5 years in jail in Canada. Unshielded RAM, USB/PCI to Ethernet, and Video GPU chips will often just barely pass EMI testing under ideal circumstances. Cheap stuff from the mystery bins will usually just glean the FCC id off a refrigerator to get through customs. Have a nice day, =3 reply RecycledEle 2 hours agoprevI have rarely seen someone this happy to add friction that prevents his customers from buying his product. reply WhereIsTheTruth 12 hours agoprev> I don’t need to sell the development boards. I just have to tell my customers which boards to buy and how to set them up. This way, the electronic device liability will fall on the manufacturer, and the magic of ~friendship~ EULA should afford me enough protection to make this a pure software play. Parasite of the economy, right there reply negative_zero 16 hours agoprev [–] EEE here with 16 years experience and having to deal with compliance from day 1 of my career. I now consult on product compliance. Author you are welcome to contact me. Disclaimer: Nothing below is meant as legally relevant compliance advice. This is just my opinion on the matter. Going to snark: \"The testing and certification industry is odd\" Except, outside the software world, the real world, where there are real consequences, it's not really. \"The line about CES, in particular, made my hair stand up.\" Why? Absolutely the unauthorised device at CES is should NOT be allowed. What if said device caused too much interference on cell phone frequencies and suddenly nobody at CES can dial the local emergency number? If that made \"your hair stand up\", here's one from personal experience that will freeze your blood: I worked as a teen for a certain electronics chain. Said chain was selling a wireless weather station imported from China. A government department that monitored the country for Earthquakes noticed that this device impinged on their frequencies. After the spectrum regulator confirmed the finding, a nice gentleman from them visited us a told us the following: 1) As of this moment this device can no longer be sold. Move it off the floor immediately (he stayed and made sure we did exactly that). 2) That we will immediately issue a recall of said device at your own cost and issue full refunds to the customers. 3) He will return when we decide on further enforcement action which may include punitive fines and recommendations for further remedial action you will need to undertake. \"In theory, it exists to serve the public good and uphold consumer protection laws.\" Well here's a (very simplistic) tidbit for the author: In the US, part of the gestation and formation of standards bodies and testing was \"market forces\", not for the public good. It was to help protect companies from litigation. If you followed the standards, tested and certed to them, paid the fees etc you then had the standards entity bat for you in court (UL is short for Underwriters Laboratory. That name was not chosen for funsies). \"However, in reality, the labs are “too busy” to respond or reply very late and generally sound less than eager to work with you.\" Well you don't sound like a serious customer. AND the Labs are not there to give you advice. They're there to do INDEPENDENT testing. \"Variations of the FCC exist in pretty much every developed economy. Putting a poorly tested hardware product on the market immediately puts a target on your back. Maybe you’ll get lucky, but chances are that someone somewhere will report you. And, unless you are operating entirely out of China, it will hurt. A lot. Both your company and maybe even you, personally.\" As it should. The electromagnetic spectrum is a very precious and very limited commodity and IMO, the best regulated \"commons\" in human civilisation (though still not perfect). So no, you are not welcome to just urinate in it willy nilly with your hustler start up product. \"I did not want to spend so much money on testing before I validated the market or gathered a community of believers.\" And there it is. \"This way, the electronic device liability will fall on the manufacturer, and the magic of friendship EULA should afford me enough protection to make this a pure software play.\" No. That's not how this works. 1) I assume the author is from the US (as they speak about the FCC). I had a 30 second look at these dev boards and their instructions. There is no FCC conformity declarations or markings, so US customers can't use it. 2) It has CE and UKCA though, so customers from EU+UK (and some other countries) can buy them but the certs only cover the dev boards AS SOLD. (i.e without the authors software) 3) Author is modifying the product behavior with their software. So yes author. You are still liable. Technically, your customers are first in the line of fire. But the likely sequence of steps is: Friendly Spectrum Representative will visit them first, have a chat, ask them to stop using the device, then leave them a lone and then come for YOU. 4) What the author has actually done is \"buy down\" their risk. It is simply less likely that the product will become non-compliant when their software is loaded. But it is still possible. At second glance, those dev boards don't come with a power supply. What is your recommended power supply to use Author? Have you tested your setup with said power supply and have test reports at the ready for when Friendly Spectrum Person comes knocking? 5) Sure it seems clever but Friendly Spectrum Agencies actually have quite far reaching and scary powers. Don't think that your little sleight of hand here is clever and protects you. Fundamentally: You are repackaging + modifying an existing product. The steps you are taking in between to \"launder\" your liability are irrelevant. Frankly, it's shit like this, that makes it harder for everyone else playing by the rules. It did actually used to be easier. There used to be exemptions for \"low volume\" products. But all of those were seen as loopholes and HEAVILY abused. Now these toys have been taken away, with more to follow. reply peteforde 15 hours agoparentThank you for this. It's possible that you've saved me and others a lot of pain by heading off ignorant mistakes. I'm currently building a product that makes use of an ESP32 module with a built-in antenna. I've been operating under the naive assumption that since the modules are certified, the product I build with the module is certified (perhaps pending an EMF certification or something equally trivial). You've certainly put this issue on my radar. That said, while I actually enjoyed the snark in your reply, there are those of us who actually do want to get this right and do the right thing, despite lacking years of experience and an infinite budget. If you have any go-to resources to share that might qualify as accessible and perhaps written to an indie maker audience, I'll diligently consume anything you recommend. reply HeyLaughingBoy 2 hours agorootparentThe certification testers will give a definitive answer, but most manufacturers will pre-test their products before sending them out for testing to improve the chances of passing the first time. You can rent some of the testing tools if necessary. This might be helpful to learn more: https://compliancetesting.com/how-to-measure-emi-electromagn... reply buescher 6 hours agorootparentprevThe go-to resources are the FCC regulations and guidance documents. Be very careful with anything written to an indie maker audience. FCC regulations have the force of law and you are ultimately responsible for compliance: not the guy you read on the internet, not even your test laboratory. https://www.fcc.gov/oet/ea/rfdevice https://www.fcc.gov/general/equipment-authorization-procedur... https://apps.fcc.gov/eas/comments/GetPublishedDocument.html?... There are a number of things you could conceivably be doing that would complicate your compliance situation beyond simply using the module's certification, getting test data from a certified lab for unintentional radiation for the Supplier's Declaration of Conformance procedure, appropriate labeling, and so on. (You're right that's a reasonable assumption about your situation but it may not always be true). They include but are not limited to, say, using more than one pre-certified transmitter in your device. reply negative_zero 5 hours agorootparentprevNo problems. You are very welcome :) It sounds like you are actually doing some things right :) FCC, for example, have scope for \"modular approval\". Order a radio module (with modular approval), do exactly as the datasheet tells you and you can \"piggy back\" off the radio modules radio certs. But you will still need to test and cert for things like your own \"unintentional emissions\", maybe ESD and other things (NOT actual compliance advice btw, this is just to give a rough picture). \"That said, while I actually enjoyed the snark in your reply, there are those of us who actually do want to get this right and do the right thing, despite lacking years of experience and an infinite budget.\" Oh I absolutely know you people are out there :) (I've consulted for them. I've also consulted for the ones who are learning the hard way...) I don't intend to be mean with posts like this on HN, but some reality on these posts is just needed IMO. Especially given how much software dominates product development these days and people just don't know. I think it's difficult for new comers, but I don't know how you fix that other than asking a consultant. The earlier the better. You can certainly make early feature and design choices to make your certs simpler (and cheaper) down the road. That said, I think a good place to start for anyone is the following: 1) Find a product that is broadly similar to yours. Is it like a small computer? Is it a wired network device like a router? Maybe it's like a bluetooth dongle or smartwatch? Find one from a large reputable company and search said company's website for their \"EU Declaration of Conformity\". On these docs (even though it is not required) many companies list the standards that the device is compliant with. They have names like: EN 55022, EN 60950, IEC 61000-3-3. NOTE - This is for EU only, but they have massive regulatory reach. Also many FCC and EU standards are very similar or even the same. Over time they have been converging more and more. 2) Do this for a few different devices of the same or similar category and you will notice many which are always there and some that are sometimes there. Now you have a starting template of standards that you might need. 3) With this starting template, you can now look up the standards names and often download the first few pages free to get an idea for what they are for. 4) Get a quote from a lab. They often do a lot of testing for product importers (as onus is also on said importers), so they can have \"non-engineer friendly\" forms that you can fill in. This will give you a price but also some information on what they think you need (they have to be careful though because they have to maintain their independence). Tell them you want CE (Europe) and FCC (North America). This covers much of the world for you. Many countries, even those with their own standards, also simply accept CE and FCC (again this is all in very very broad strokes). Many standards are also just copy and pasted between different regulatory domains but they change the name. So the original standards body will have their name for it. When the EU recognises it, it'll get an \"EN\" number for it's name (for example). 4b) Consider a hiring consultant for a short chat to \"downsize\" the standards you need and maybe they can point out any you might be missing. Good ones can also advise you on things you can do to avoid standards (and this is not in an illegal way). If you understand the rules well, you can sometimes make small changes and avoid whole sets of rules and testing (classic one IMO is a radio device. In VERY GENERAL TERMS, if it's going to be used more than 40cm from a human, then you don't need to test for human absorption of RF energy. My Chromecast, for example, has a disclaimer on it so that they can claim exactly this (IMO of course) ). How to find a good consultant? Well that's hard and I don't have a sure fire way sorry. Some labs have business cards of small local consultants. 5) Source copies of the standards and read them (Yes it'll likely be heavy reading). Most standards sellers (including the national ones) are crooks. Don't use them. Instead go to the Estonian Centre for Standardisation and Accreditation: https://www.evs.ee/en . They are the cheapest source I know of for standards in English (and only English matters). Further details in an old comment of mine here: https://news.ycombinator.com/item?id=36452660 These above steps are the same steps that I myself use. Sources to read ... sadly I've not found many good ones. I think the best one that I would recommend is https://incompliancemag.com/ It's dry and does what it says on the tin. But their archives have some great articles by experts. They cover new standards, certing particular devices, testing technology etc. Even the ads can be kind of informative I think. It's good for learning the general layout of the field. Not a shallow learning curve but not steep either IMO (It's also free in digital form). reply buescher 4 hours agorootparentThis is all good information. I'd only add: You left out Canada. IC certs are kind of a pain because some of their rules are very slightly different plus you need a representative in Canada. UL standards can be read (but not downloaded) for free on UL's standard store. These don't include IEC standards adopted by UL, but do include national differences for those standards for the US. The specific procedures your test lab will use in the US for typical part 15 devices include procedures covered by ANSI C63.4 (unintentional radiators) and C63.10 (intentional radiators). These you can't get from the Estonians. You probably won't need them but they can be helpful if you get serious about pre-compliance testing or if you are puzzled by what the lab is doing. IEC CISPR standards overlap here. There is a list of measurement procedures on the FCC web site: https://www.fcc.gov/general/equipment-authorization-measurem... You should have an engineer or \"directly responsible individual\" on site at the test lab during testing for all kinds of reasons, from building capability and understanding of the process to having someone there to clear up any misunderstandings. If you have a consultant do this for you, you or someone from your company should be there also. For transmitters (intentional radiators) you can look up test reports and submittal information for competing products on the FCC's web site. That's one way to get an idea of what your test requirements and setups will look like. For unintentional radiators, you can find some test reports with a web search - companies are not required to make these public. reply _flux 9 hours agoparentprevIn practice the guy was planning to sell piece of software, on an SD card, that is compatible with a piece of hardware, and it's up to the customer to actually combine those two. The plan is exactly not to sell the hardware at all—granted they SD cards are piece of hardware, but what if that too was just an image to download off a site? If the customer cannot legally use that SD with their boards, which SD can they use? Is this not exactly equivalent how I might buy a Raspberry Pi and install a non-Raspberry-authorized OS on it? Or equivalent on how I might buy a PC and install Linux on it? Or Android and LineageOS? Are those devices certified not only as SOLD but also as modified by the end-user with software, making them somehow different? reply negative_zero 6 hours agorootparentThat was not my read on it. My interpretation was that they wanted to sell a product, but didn't want to pay for an engineer who understands all this, labs for testing and doing all the paper work that it entails. So the plan became: \"Customer buy this software, buy that hardware and put it together\" => not liable => profit. \"Is this not exactly equivalent how I might buy a Raspberry Pi and install a non-Raspberry-authorized OS on it? Or equivalent on how I might buy a PC and install Linux on it? Or Android and LineageOS? Are those devices certified not only as SOLD but also as modified by the end-user with software, making them somehow different?\" Yes and no :) Very very succinctly: When you test and cert, it is best practice to create the worst case scenario for your product and pass like with healthy margins. Especially for something like a smartphone or PC, when it's in the test chamber (for something like radiated emissions), you run it at \"full noise\" (even if it's not a realistic use case). So all your clocks: maximum (don't use all of the clocks? Turn them all on anyway); Power draw: Maximum or more; Play seizure inducing video to exercise that screen; Connect peripherals that are likely to be used to make sure those don't screw you etc. PCs and phones, especially, are tested at these extremes so that the manufacturer can be confident that despite what software the end-user loads, the device will remain compliant (this is also why the radio firmware is kept locked down hard). Now in the case of this article, sure, the dev boards have CE, but what does that mean? How did they test it? Where all the peripherals running? What did the physical test setup look like? Under CE they are required to keep a compliance folder and to provide the information on request. My experience with, dev boards that are \"compliant\". They just powered it up and maybe ran a simple program. Low effort, low noise, easy pass, because the reality is that they don't need it and time is money. So now you a third party integrator takes that dev board, and runs something that wasn't exercised or puts it into a state that is non compliant. That's on you. Just like it's on the Author of this article. I might be wrong in this case. Maybe the dev boards have excellent test setups. I might look at the test docs and think: \"oh we should be fine\". And just do a pre-compliance test and self-certify. You have to evaluate the risk each time and make a call. If Microsoft released a patch tomorrow that somehow caused a sizable percentage of PCs to start stepping on the cell phone bands they would VERY quickly be told (I emphasise told NOT asked) to fix it. Just like any software this Author could load. They have not sidestepped any responsibility. reply _flux 6 hours agorootparentI was actually under the impression that PC motherboards have the spread spectrum clock available exactly for compliance reasons, and indeed it's the default as well. But you can turn it off. Maybe they do indeed test without it, and it's only for the benefit of integrators to make use of (and perhaps disable other options altogether), if they find their complete system emissions somehow exceed limits. Now that I'm in position to ask ;), I've wondered about the glass/plastic window PC cases.. Surely a PC case itself would not be required to have any emission tests done on it, or would it? On the other hand, might the PC motherboard emissions be certified with the assumption that it will be placed inside a case? And then finally comes a consumer (or even a small integrator) and sticks in a PC motherboard inside a windowed case—but in this case the case might not be doing much on the RF side. Or maybe the cases provide better RF protection than they look like or the MBs don't need a case for that reason in the first place :). reply negative_zero 3 hours agorootparentYou are correct on the spread spectrum clocks. Outside of military, they really soley exist for compliance (specifically unintended electromagnetic emissions) and are increasingly everywhere out of necessity. If an integrator needs spread spectrum locked on, there is no doubt a BIOS available that does just that. \"Now that I'm in position to ask ;)\" Ask away :) This is boring for 99.99999% of the population so I don't get to talk about it often :) \"I've wondered about the glass/plastic window PC cases.. Surely a PC case itself would not be required to have any emission tests done on it, or would it?\" You're right, a PC case itself does not need EMC compliance, but a PC case that's sold with a power supply does. So does one with built in fans and lights or anything electronic. IMO and very much off the cuff, certing the case + lights and fans without a whole computer inside is probably reasonable. But I would personally try cert with a whole PC (defence in depth). \"On the other hand, might the PC motherboard emissions be certified with the assumption that it will be placed inside a case?\" Yes it can be certed that way. Generally if it is, the details have to be in the manual. But also, legally, you don't really need to cert a motherboard because it will always be integrated into another thing. However the reality of the PC architecture is that it is extremely modular and reach module is extremely complex. It's simply not at all practical for any systems integrator to try to modify those modules to try and make a whole PC compliant so that they can sell it. Even sticking the whole thing in a metal case might not be enough because the case has cables attached to and unwanted emissions and get out via those. So for practical purposes manufacturers of motherboards, graphics cards, PSUs, hard drives etc vigorously test and cert their products with decent margins so that no matter what cards are used or how a PC is put together, the sum will be compliant. And this rule holds pretty well in general at all scales, from the individual parts and submodules that come together to make a product up to several products wired together in your house with power and network cables. And system integrators can demand these requirements because it's necessary for the industry to function. I found a few years ago on Dell's website their manual for part suppliers. It listed every standard they required, made stricter and even had additions of their own so that they could sell with your module everywhere in the world, because they sell everywhere. It basically a thick manual on making a computer \"world compatible\". \"And then finally comes a consumer (or even a small integrator) and sticks in a PC motherboard inside a windowed case—but in this case the case might not be doing much on the RF side. Or maybe the cases provide better RF protection than they look like or the MBs don't need a case for that reason in the first place :).\" And the consumer benefits from everything I explained earlier. They can buy parts and assemble a computer that will be compliant. It's also why computer shops can build you a PC and sell without a cert and it'll be fine. Just the sheer effort of all these manufacturers so that they have a market to sell into means that the problem is solved for small players in the traditional PC world. The traditional PC industry is quite unique in that way actually. reply HeyLaughingBoy 2 hours agorootparentprevThat bit about PCs and phones was surprising, but I guess not unexpected. I have built many \"EMI test versions\" of code so various products can be taken to the test house. We don't go to those extremes: typically, we'll run as close to worst case as we can get, but nothing unrealistic. Then again, no one but us is loading code onto our devices, so it's not like a PC where you have no control over what it's running. reply analogwzrd 4 hours agoparentprev\"Author is modifying the product behavior with their software.\" I would say that the end user is modifying the behavior of the hardware, that they own and are fully in control of, by choosing to run software that they purchased. But I'm fully aware that regulatory agencies probably have their own way of thinking about that. Point taken about how we need some regulations, but isn't everyone sitting in an MBA program right now being trained to identify this exact kind of workaround? As for displaying a device that isn't certified yet, who's the victim? What's wrong with saying \"We can't take orders on this yet, but we're working on getting cool new product certified as fast as possible\"? The article said displaying a device, not turning it on. From your post, it seems like you're painting this guy as a malicious bad actor who going to destroy society when, to me, he seems like someone who's trying to find an efficient way to sell a solution to people who might find it valuable. reply warkdarrior 2 hours agorootparent> we need some regulations, but isn't everyone sitting in an MBA program right now being trained to identify this exact kind of workaround? Just because there are some bad actors out there, it does not mean that you should behave the same way. reply someonenice 13 hours agoparentprev>> 3) Author is modifying the product behavior with their software. So yes author. You are still liable. Technically, your customers are first in the line of fire. But the likely sequence of steps is: Friendly Spectrum Representative will visit them first, have a chat, ask them to stop using the device, then leave them a lone and then come for YOU. Few questions related to this. - Does this meant that recertification is required every time we load a different version of the software ? - How does this work for Computers and mobile phones ? The hardware is certified but you are loading different software daily. reply negative_zero 6 hours agorootparentIn the purest theoretical sense yes, in practice no. So that you don't have to recert everytime, you 1) test and exercise your product to extremes so that you can say with high certainty that: no matter what the customer loads, it won't breach the rules. 2) As pjc50 mentioned: Lock down the parts which the user could potentially cause the most damage with. i.e lock down that radio firmware (why is why none of it is open source). If you do (1) and (2) and a few other things, you buy down your risk sufficiently that you can confidently demonstrate that re-certs are not needed. The Author of the parent article IMO is doing the exact opposite. There are also half-way houses: Just doing \"pre-compliance testing\". So not a formal cert, your just doing a quick test in an anaechoic chamber or even on a table top scanner. Of course this only applies to things you can self-certify. Some things, like radios (WiFi, Bluetooth etc.), you cannot self-certify. That's why almost everyone buys the radio as a module (To buy down their risk). By consequence: That's why those radio module manufacturers have the firmware locked down hard and engineer and cert the radios to have big margins. There are a lot of rules yes, but there is actually a lot of flexibility and common sense in the system too (but it is still imperfect, absolutely). But that flexibility does not allow for horsing around. If you can demonstrate to Friendly Spectrum Agency all this due diligence, you are going to have a MUCH better time. reply pjc50 7 hours agorootparentprevThe \"software\" in these cases is localized to the drivers/firmware. This is why you basically can't get a RF peripheral for Linux with truly open firmware and they all use binary blobs: to prevent you modifying it. reply pjc50 7 hours agoparentprev> I assume the author is from the US (as they speak about the FCC). I had a 30 second look at these dev boards and their instructions. There is no FCC conformity declarations or markings, so US customers can't use it. Just order it off Aliexpress. It's fine to have a really expensive compliance regime, so long as you understand how that drives the small end of the business offshore. reply negative_zero 6 hours agorootparentThen it's on you as the importer. This is part of why lots of stuff on AliExpress and dodgy Amazon 3rd party supplies is cheap. It's non compliant stuff that is not even sold in China. It's export only, and for the wrong reasons. reply ThrowawayTestr 15 hours agoparentprevAbsolutely amazing response. I love it when a real engineer comes and explains the real world to software \"engineers\". reply liminalsunset 15 hours agorootparentI think that both sides (SW and HW) can learn to coexist better, and tbh, there is really a necessity for them to. The reality is that the reason software is currently the top industry/value creator when it comes to revenue is an artifact of an open ecosystem where the barriers to entry are low, and where there is space for many to experiment. Traditionally, the engineering world doesn't see things the same way. Part of this is culture, and that's hard to change - engineers see what they do as an art, and this is fine,and it's a good thing as some engineering systems do have a disproportionate impact, but I think the tone of the response also does reflect an attitude of perfectionism and \"this at any cost\" that I think holds the field back. I think the solution is not rather to \"just let people run amok\" (though as it happens, this is the strategy China is testing for us and it appears to not have broken too much yet - the land of trillions of SOIC-8 Bluetooth MCUs with no shielding and a 5-line BOM) but rather for the engineering world to embrace the software developers and provide a happy path to compliance. If you want North America to compete with China on having ubiquitous technologies everywhere (this is the only way to build out the supply chain), we have to come up with a way to fix certification and part of the attitude has to be \"we're going to teach you how to cheaply get your product to market in a way that respects the spectrum\", and not \"it's expensive, deal with it\". This one is tough for people to accept but we cannot ever go back to stuff being expensive, as the floodgates have already been opened. This is something that the government has to do, probably - provide funding to run (at least, cut down versions of the labs for precompliance) cheaply, put out good resources. Encourage or fund the creation of low-cost and easy to understand paths to compliance. As anyone knows, if you try to hold your nose to stop a nosebleed, the blood just goes down your throat. Same with all of the stuff from China. If you want to meaningfully improve device compliance, making the process hard and painful will just increase the number of random Amazon/Temu Bluetooth nonsense with a total lack of attention to design at all. If we made the process more accessible, it's possible that this would drive the industry to create solutions that might not even cost more, but are more compliant - which would be a win overall. reply negative_zero 2 hours agorootparentEMC compliance rules are needed so that all our electronic devices (running software mind you) can continue to function. Part of the rules are about squeezing as much \"performance\" as possible out of the \"thing\" that is the electromagnetic spectrum. It's simple physics. The other part of the rules are for human safety. Devices can directly hurt people (like a microwave) or indirectly (like a crappy device that prevented ambulance phone calls going through). It's as simple as that (and not perfectionism or being mean to the poor software people). \"\"we're going to teach you how to cheaply get your product to market in a way that respects the spectrum\" I'm available to do exactly that for you at my hourly rate :D reply Palomides 15 hours agorootparentprevhard agree, it sucks immensely that I can design a cool 4 layer PCB with multicore processor in an afternoon, throw on a standard bluetooth module, and have it manufactured and shipped to me in a week for like $100, but heaven forbid I want to sell five of them to fellow nerds on a niche forum without breaking multiple laws, and the path to compliance is, uh, find a consultant with EMI testing experience and industry connections and/or spend $5000? and then amazon is full of absolutely noncompliant untested stuff with no consequences reply crote 1 hour agorootparentDon't forget having to spend $X000 for the privilege of being allowed to read the standards you're required to follow, and needing a consultant to tell you which standards you have to follow in the first place. reply buescher 5 hours agorootparentprevAmazon absolutely requires sellers to supply FCC certification and Suppliers' Declaration of Conformity documentation for FCC regulated devices. You can report any noncompliant products to them and they do remove them. Just wait till you learn about say, product liability, CPSC regulations, \"voluntary\" safety standards, and so on reply leptons 4 hours agoparentprev [–] >\"Author is modifying the product behavior with their software.\" If this were a real concern, then every programmer everywhere would need FCC certification for any program they ever write. But that isn't the case so far as I know. reply negative_zero 2 hours agorootparent [–] See my response to a similar question here: https://news.ycombinator.com/item?id=40926103 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The FCC mandates that electronic devices must complete testing and approval before being marketed in the US, including selling, leasing, advertising, and importing.",
      "The ambiguity around whether offering devices on crowdfunding sites constitutes marketing poses a risk, especially for startups facing high testing costs and unresponsive labs.",
      "A cost-effective workaround involves using widely available chips and pre-flashing SD cards with the OS and software, shifting liability to the manufacturer and allowing market validation with minimal spend."
    ],
    "commentSummary": [
      "Understanding the regulatory landscape and compliance testing is crucial for validating a market with development boards and SD cards.",
      "Certification, such as from the FCC, is essential to avoid legal issues and ensure product safety, particularly for devices emitting RF noise.",
      "Testing costs range from $3000 to $5000, and pre-testing is recommended to identify issues early."
    ],
    "points": 120,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1720554452
  }
]
