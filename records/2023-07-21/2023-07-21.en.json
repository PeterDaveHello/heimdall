[
  {
    "id": 36800297,
    "timestamp": 1689860475,
    "title": "Apple says it'll remove iMessage & FaceTime in UK rather than break encryption",
    "url": "https://9to5mac.com/2023/07/20/apple-imessage-facetime-remove-security-law/",
    "hn_url": "http://news.ycombinator.com/item?id=36800297",
    "content": "iPhone 15 Pro: Will we ever see another S model?Zac HallJul 19 2023",
    "summary": "- The article discusses the possibility of Apple discontinuing the \"S\" model of the iPhone and whether or not we will see another version in the future.\n- The \"S\" model of the iPhone refers to the incremental upgrades Apple usually makes to the previous iPhone version, focusing on improving performance and adding new features.\n- The article explores the idea that Apple may move away from the \"S\" model and instead release major updates and redesigns with each new iPhone version.",
    "hn_title": "Apple says it'll remove iMessage and FaceTime in UK rather than break encryption",
    "original_title": "Apple says it'll remove iMessage and FaceTime in UK rather than break encryption",
    "score": 1410,
    "hn_content": "Summary:\n- People feel that the battle for privacy is being lost and that governments can read messages at will.\n- Arguments are made about the importance of privacy in upholding personal freedoms.\n- The debate centers around whether electronic conversations should be treated the same as in-person conversations.\n- Advocates for privacy argue that historical norms have always given individuals the right to privacy.\n- The concept of encryption backdoors is discussed, with some arguing that they would weaken security for everyone.\n- The potential loss of iMessage and FaceTime in the UK is seen as an example of the ongoing battle between privacy and government access to communications.\n- Some readers are interested in the topic because privacy is an increasingly important conversation in the tech world.\n- The role of encryption in protecting personal freedoms is highlighted as a significant aspect of the article.- The UK government is pushing for increased access to encrypted messages, which has raised concerns about privacy and security.\n- Signal, WhatsApp, and iMessage have threatened to leave the UK if the bill passes, indicating that it may be unreasonable.\n- The debate surrounding encryption often centers around the argument of \"If you have nothing to hide, there shouldn't be a problem.\"\n- The lack of a written constitution in the UK means that it may be easier for the government to pass laws like this without checks and balances.\n- The issue of government access to encrypted messages is not unique to the UK, as other countries like China and Russia also have similar data collection practices.\n- Apple has taken a strong stance in favor of maintaining end-to-end encryption, particularly in regards to iMessage.\n- The media landscape in the UK has a significant influence on the national conversation, which may contribute to public support for increased government access to encrypted messages.\n- It's important for individuals to be aware of and consider the potential implications of government access to encrypted messages on their privacy and security.",
    "hn_summary": "- The ongoing battle between privacy and government access to communications is highlighted, with concerns about the potential loss of iMessage and FaceTime in the UK being seen as an example.\n- The role of encryption in protecting personal freedoms is emphasized, with advocates arguing that historical norms have always given individuals the right to privacy.\n- The potential implications of government access to encrypted messages on privacy and security are highlighted, urging individuals to be aware and consider the potential consequences."
  },
  {
    "id": 36801491,
    "timestamp": 1689865225,
    "title": "FedNow Is Live",
    "url": "https://www.federalreserve.gov/newsevents/pressreleases/other20230720a.htm",
    "hn_url": "http://news.ycombinator.com/item?id=36801491",
    "content": "Skip to main contentStay ConnectedRecent PostingsCalendarPublicationsSite MapA-Z indexCareersFAQsVideosContactSearchSubmit Search ButtonAdvancedBoard of Governors of the Federal Reserve SystemThe Federal Reserve, the central bank of the United States, provides the nation with a safe, flexible, and stable monetary and financial system.Aboutthe FedNews& EventsMonetaryPolicySupervision& RegulationFinancialStabilityPaymentSystemsEconomicResearchDataConsumers& CommunitiesHome News & Events Press ReleasesPress ReleaseJuly 20, 2023Federal Reserve announces that its new system for instant payments, the FedNow\u00ae Service, is now liveFor release at 10:00 a.m. EDTShareThe Federal Reserve on Thursday announced that its new system for instant payments, the FedNow\u00ae Service, is now live. Banks and credit unions of all sizes can sign up and use this tool to instantly transfer money for their customers, any time of the day, on any day of the year.\"The Federal Reserve built the FedNow Service to help make everyday payments over the coming years faster and more convenient,\" said Federal Reserve Chair Jerome H. Powell. \"Over time, as more banks choose to use this new tool, the benefits to individuals and businesses will include enabling a person to immediately receive a paycheck, or a company to instantly access funds when an invoice is paid.\"To start, 35 early-adopting banks and credit unions, as well as the U.S. Department of the Treasury's Bureau of the Fiscal Service, are ready with instant payments capabilities via the FedNow Service. In addition, 16 service providers are ready to support payment processing for banks and credit unions.When fully available, instant payments will provide substantial benefits for consumers and businesses, such as when rapid access to funds is useful, or when just-in-time payments help manage cash flows in bank accounts. For example, individuals can instantly receive their paychecks and use them the same day, and small businesses can more efficiently manage cash flows without processing delays. Over the coming years, customers of banks and credit unions that sign up for the service should be able to use their financial institution's mobile app, website, and other interfaces to send instant payments quickly and securely.As an interbank payment system, the FedNow Service operates alongside other longstanding Federal Reserve payment services such as Fedwire\u00ae and FedACH\u00ae. The Federal Reserve is committed to working with the more than 9,000 banks and credit unions across the country to support the widespread availability of this service for their customers over time.A list of early adopters with instant payment capabilities is attached. Additional information is available on the Federal Reserve Financial Services website.For media inquiries, please email media@frb.gov or call 202-452-2955.Attachment (PDF)Related ContentFedNow\u00ae ServiceFrequently Asked QuestionsAdditional Questions and AnswersLast Update: July 20, 2023BOARD OF GOVERNORS of the FEDERAL RESERVE SYSTEMAbout the FedNews & EventsMonetary PolicySupervision & RegulationFinancial StabilityPayment SystemsEconomic ResearchDataConsumers & CommunitiesTOOLS AND INFORMATIONContactPublicationsFreedom of Information (FOIA)Office of Inspector GeneralBudget & Performance | AuditNo FEAR ActEspa\u00f1olWebsite Policies | Privacy ProgramAccessibilitySTAY CONNECTEDLink to Federal Reserve Facebook PageLink to Federal Reserve Twitter PageLink to Federal Reserve YouTube PageLink to Federal Reserve Flickr PageFederal Reserve LinkedIn PageSubscribe to RSSSubscribe to EmailBOARD OF GOVERNORS of the FEDERAL RESERVE SYSTEM20th Street and Constitution Avenue N.W., Washington, DC 20551",
    "summary": "- The Federal Reserve has launched a new system called the FedNow Service that allows banks and credit unions to instantly transfer money for their customers.\n- The FedNow Service aims to make everyday payments faster and more convenient, providing benefits for individuals and businesses.\n- Currently, 35 banks and credit unions, as well as the U.S. Department of the Treasury's Bureau of the Fiscal Service, have adopted instant payment capabilities through the FedNow Service.",
    "hn_title": "FedNow Is Live",
    "original_title": "FedNow Is Live",
    "score": 1009,
    "hn_content": "- FedNow, a new service by the Federal Reserve, has gone live.\n- It utilizes IBM MQ for message queueing and a bespoke version of the ISO 20022 specification.\n- From a software development perspective, the process is similar to normal development.\n- The development environment can be any OS and IDE.\n- The system is designed to enable real-time push payments and has a processing time of a few seconds.\n- The primary use case is person-to-person payments, similar to Venmo or Zelle.\n- There is no support for pull payments or Request for Payment (RFP) at the moment.\n- The FedNow service is 24/7/365, providing instantaneous transfers.\n- Security is a key consideration, with messages being cryptographically signed.\n- The service is subject to an end-to-end payment timeout of 20 seconds.\n- The implementation is under NDA, and information that is not publicly documented is protected.\n- The system aims to streamline payment processes and reduce transaction times.\n- IBM's involvement in the project contributes to its credibility and reliability.\n- This implementation is a significant step forward for the US financial industry.\n- It may open up possibilities for innovative payment solutions and cost savings for businesses like Netflix.\n- The feedback suggests that the system is a positive development, although challenges still remain.- Postgres or other ACID-compliant databases are recommended for data in the range of ~1TB, but there are no known petabyte-scale ACID databases.\n- BigQuery is ACID compliant and can handle petabytes of data, but it may not be suitable for OLTP workloads.\n- ACID compliance and support for a high volume of transactions are important for banking systems.\n- Financial institutions generally use SQL databases like Oracle instead of Postgres for their core databases.\n- DuckDB and SQLite are suitable for handling terabytes of data but may not be ideal for cloud-based apps or multiuser environments.\n- The implementation of a universal SDK or API for payments could disrupt the payments industry and increase competition.\n- Open Banking in Europe has limitations on who can actually use the APIs, making it less accessible for small startups.\n- FedNow is a new payment system administered by banks that supports instant transfers between participating financial institutions.\n- It is unclear if FedNow will be widely adopted or if it will replace credit cards, but it could offer more competitive fees for transactions.\n- The implementation of FedNow could be seen as a prerequisite for a Central Bank Digital Currency (CBDC) in the future.\n- FedNow is not mandatory and will likely be limited to federal and state government usage.\n- Companies like Moov and Column are building APIs for integration with FedNow.\n- There might be a need for additional services provided by banks that utilize FedNow for instant transfers.\n- There are concerns about the governance and fraud prevention aspects of implementing FedNow.\n- The potential impact of FedNow on the payments industry and competition is uncertain at this point.",
    "hn_summary": "- FedNow, a new service by the Federal Reserve, has gone live, enabling real-time push payments.\n- The system is designed for person-to-person payments and operates 24/7/365 with a processing time of a few seconds.\n- The implementation of FedNow is a significant step forward for the US financial industry, potentially leading to innovative payment solutions and cost savings."
  },
  {
    "id": 36799776,
    "timestamp": 1689857823,
    "title": "No-more-secrets: recreate the decryption effect seen in the 1992 movie Sneakers",
    "url": "https://github.com/bartobri/no-more-secrets",
    "hn_url": "http://news.ycombinator.com/item?id=36799776",
    "content": "Like this project? Consider tipping me: https://github.com/sponsors/bartobriNo More SecretsThis project provides a command line tool called nms that recreates the famous data decryption effect seen on screen in the 1992 hacker movie Sneakers. For reference, you can see this effect at 0:35 in this movie clip.This command works on piped data. Pipe any ASCII or UTF-8 text to nms, and it will apply the Hollywood effect, initially showing encrypted data, then starting a decryption sequence to reveal the original plain-text characters.Also included in this project is a program called sneakers that recreates what we see in the above movie clip. Note that this program requires the user to select one of the menu options before it terminates.By default, this project has no dependencies, but it does rely on ANSI/VT100 terminal escape sequences to recreate the effect. Most modern terminal programs support these sequences so this should not be an issue for most users. If yours does not, this project also provides a ncurses implementation which supports non-ANSI terminals, but at the expense of losing the inline functionality (ncurses will always clear the screen prior to displaying output).Table of ContentsDownload and InstallUsageThe NMS LibraryLicenseDownload and InstallMore and more Unix/Linux platforms are including this project in their package manager. You may wish to search your package manager to see if it is an installation option. If you install from a package manager, please check that you have the latest version (nms -v). If not, I suggest installing from source by following the instructions below.To install this project from source, you will need to have the tools git, gcc, and make to download and build it. Install them from your package manager if they are not already installed.Once you have the necessary tools installed, follow these instructions:Install:$ git clone https://github.com/bartobri/no-more-secrets.git$ cd ./no-more-secrets$ make nms$ make sneakers       ## Optional$ sudo make installUninstall:$ sudo make uninstallInstall with Ncurses SupportIf your terminal does not support ANSI/VT100 escape sequences, the effect may not render properly. This project provides a ncurses implementation for such cases. You will need the ncurses library installed. Install this library from your package manager. Next, follow these instructions:$ git clone https://github.com/bartobri/no-more-secrets.git$ cd ./no-more-secrets$ make nms-ncurses$ make sneakers-ncurses   ## Optional$ sudo make installUsagenms works on piped data. Pipe any ASCII or UTF-8 characters to it and enjoy the magic. In the below examples, I use a simple directory listing.$ ls -l | nms$ ls -l | nms -a      // Set auto-decrypt flag$ ls -l | nms -s      // Set flag to mask space characters$ ls -l | nms -f green   // Set foreground color to green$ ls -l | nms -c      // Clear screen$ nms -v          // Display versionNote that by default, after the initial encrypted characters are displayed, nms will wait for the user to press a key before initiating the decryption sequence. This is how the it is depicted in the movie.Command Line Options-aSet the auto-decrypt flag. This will automatically start the decryption sequence without requiring a key press.-sSet a flag to mask space characters. This will only mask single blank space characters. Other space characters such as tabs and newlines will not be masked.-f <color>Set the foreground color of the decrypted text to the color specified. Valid options are white, yellow, black, magenta, blue, green, or red. This is blue by default.-cClear the screen prior to printing any output. Specifically, it saves the state of the terminal (all current output), and restores it once the effect is completed. Note that when using this option, nms requires the user to press a key before restoring the terminal.-vDisplay version info.The NMS LibraryFor those who would like to use this effect in their own projects, I have created a C library that provides simple interface and can easily be used for any program that runs from the command line.See LibNMS for more info.LicenseThis program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License. See LICENSE for more details.",
    "summary": "- The project \"No More Secrets\" is a command line tool that recreates the famous data decryption effect seen in the 1992 hacker movie Sneakers.\n- Users can pipe ASCII or UTF-8 text to the tool, and it will apply the Hollywood effect of initially displaying encrypted data and then revealing the original plain-text characters through a decryption sequence.\n- The project provides options for auto-decrypting, masking space characters, setting foreground colors, clearing the screen, and displaying version info. It also includes a C library for developers who want to use the effect in their own projects.",
    "hn_title": "No-more-secrets: recreate the decryption effect seen in the 1992 movie Sneakers",
    "original_title": "No-more-secrets: recreate the decryption effect seen in the 1992 movie Sneakers",
    "score": 917,
    "hn_content": "- A developer has recreated the decryption effect from the 1992 movie Sneakers in a open-source GitHub project called \"No-more-secrets\"\n- The project allows users to recreate the Sneakers decryption effect on their own machines\n- The decryption effect is achieved through the use of ANSI escape sequences and ASCII art\n- Users can download and install the project by following the instructions in the project's README file\n- The project has gained popularity among developers and tech enthusiasts\n- The project has a nostalgic appeal for those who remember the movie Sneakers\n- The project is well-documented, making it accessible for developers of all levels\n- The simplicity and effectiveness of the project make it a valuable tool for users interested in coding and encryption- There is a discussion about a potential remake of the movie Sneakers with the original cast.\n- The original movie is considered to hold up well despite its age.\n- The conversation includes various comments about unrelated topics such as astronomy and peace.\n- The post mentions a tool called \"no-more-secrets\" that allows users to recreate the famous decryption scene from the movie Sneakers.\n- Some users express interest in using the tool with their preferred programming languages or platforms.\n- The post also includes comments about other movies and TV shows that portray technology and encryption.\n- One user suggests using the tool in conjunction with a BBS ASCII-based door for added fun.\n- There is a request for a JavaScript version of the tool.\n- A user humorously mentions hacking into the FBI.\n- The tool is described as a neat and cool way to visualize encryption.\n- One user suggests using the tool in a terminal browser for a funny effect on every opened page.\n- A comment about including the tool in Homebrew, a package manager for macOS, is made.\n- It is noted that the tool is already available in Homebrew.\n\nThe most important thing people should know about this post is that there is a tool called \"no-more-secrets\" that allows users to recreate the famous decryption scene from the movie Sneakers. The tool is described as neat and cool, and various users express interest in using it in different contexts. Additionally, there is some discussion about the movie Sneakers itself and other related movies and TV shows.",
    "hn_summary": "- The tool \"no-more-secrets\" allows users to recreate the decryption effect from the movie Sneakers\n- The tool has gained popularity among developers and tech enthusiasts\n- There is some discussion about the movie Sneakers and other related movies and TV shows"
  },
  {
    "id": 36798593,
    "timestamp": 1689847484,
    "title": "Docuseal: Open-source DocuSign alternative",
    "url": "https://github.com/docusealco/docuseal",
    "hn_url": "http://news.ycombinator.com/item?id=36798593",
    "content": "DocuSealOpen source document filling and signingDocuSeal is an open source platform that provides secure and efficient digital document signing and processing. Create PDF forms to have them filled and signed online on any device with an easy-to-use, mobile-optimized web tool.Live Demo | Try in CloudFeaturesPDF form fields builder (WYSIWYG)10 field types available (Signature, Date, File, Checkbox etc.)Multiple submitters per documentAutomated emails via SMTPFiles storage on AWS S3, Google Storage, or AzureAutomatic PDF eSignaturePDF signature verificationUsers managementMobile-optimizedEasy to deploy in minutesDeployHeroku RailwayDigitalOcean RenderDockerdocker run --name docuseal -p 3000:3000 -v.:/data docuseal/docusealBy default DocuSeal docker container uses an SQLite database to store data and configurations. Alternatively, it is possible use PostgreSQL or MySQL databases by specifying the DATABASE_URL env variable.Docker ComposeDownload docker-compose.yml into your private server:curl https://raw.githubusercontent.com/docusealco/docuseal/master/docker-compose.yml > docker-compose.ymlRun the app under a custom domain over https using docker compose (make sure your DNS points to the server to automatically issue ssl certs with Caddy):HOST=your-domain-name.com docker-compose upLicenseDocuSeal is released under the GNU Affero General Public License v3.0.",
    "summary": "- DocuSeal is an open-source platform for digital document signing and processing.\n- It allows users to create PDF forms that can be filled and signed online on any device.\n- The platform offers features such as PDF form field builder, multiple submitters per document, PDF eSignature verification, and users management.",
    "hn_title": "Docuseal: Open-source DocuSign alternative",
    "original_title": "Docuseal: Open-source DocuSign alternative",
    "score": 570,
    "hn_content": "- DocuSeal is an open-source alternative to document signing solutions like DocuSign.\n- It offers features such as PDF form fields builder, multiple field types, automated emails, and more.\n- DocuSeal can be self-hosted or used in the cloud for free.\n- Users have provided feedback on improving the user interface and adding features like embedding the signing interface in an iframe and pre-filling values via the query string.\n- Some users have expressed interest in using DocuSeal for non-profit digital signatures and have offered help to bootstrap the project.\n- There is a discussion about the legal validity and trustworthiness of self-hosted digital signature systems compared to third-party solutions.\n- The need for a trusted third party and the importance of trust in the document signing process are highlighted.\n- People value the convenience and reliability provided by established platforms like DocuSign, but also seek alternatives that are more affordable and flexible.\n- The potential trademark similarity between DocuSeal and DocuSign is brought up as a concern.\n- The importance of legal requirements and business processes in the document signing space is emphasized.\n- The existence of alternative open-source projects like Documenso is mentioned, but it's noted that DocuSeal offers more features and is already more robust.\n- Users appreciate the availability of a live version of DocuSeal for testing without a signup wall.\n- The possibility of integrating DocuSeal with other software applications through a REST API is mentioned and planned for release in the future.\n- The pricing of commercial solutions like DocuSign is criticized, which further highlights the appeal of a free and open-source alternative like DocuSeal.- Embedding feature will be available in August, allowing developers to bring the PDF document form into apps.\n- Questions about compliance with eIDAS regulations in the EU/UK.\n- Importance of integration/plugins with popular PDF viewers and editors.\n- Questions about the API and its ease of embedding into applications.\n- How electronic signatures work and concerns about storage and proof of authenticity.\n- Utilization of PandaDocs' free tier for third-party reputation.\n- Mention of the potential reaction from Docusign's legal team.\n- Discussion about the limitations of the Alfredo license.\n- Interest in redaction capabilities and alternatives to Adobe Acrobat.\n- Mention of potential inclusion of docsend functionality.\n- Positive response to the new efforts in the electronic signature space.\n- Refusal to use Docusign due to objectionable clauses in their Terms and Conditions.\n- Explanation of specific objectionable clauses found in Docusign's Terms and Conditions.\n- Ruby backend plan for 2023.",
    "hn_summary": "- DocuSeal is an open-source alternative to document signing solutions like DocuSign, offering features such as PDF form fields builder, multiple field types, and automated emails.\n- Users are interested in using DocuSeal for non-profit digital signatures, and some have offered to help bootstrap the project.\n- There is a discussion about the legal validity and trustworthiness of self-hosted digital signature systems compared to third-party solutions."
  },
  {
    "id": 36808296,
    "timestamp": 1689896530,
    "title": "Fly.io Postgres cluster down for 3 days, no word from them about it",
    "url": "https://webcache.googleusercontent.com/search?q=cache:2T9NpG8thZgJ:https://community.fly.io/t/service-interruption-cant-destroy-machine-deploy-or-restart/14227&cd=9&hl=en&ct=clnk&gl=au",
    "hn_url": "http://news.ycombinator.com/item?id=36808296",
    "content": "This is Google's cache of https://community.fly.io/t/service-interruption-cant-destroy-machine-deploy-or-restart/14227. It is a snapshot of the page as it appeared on 21 Jul 2023 09:07:13 GMT. The current page could have changed in the meantime. Learn more.Full versionText-only versionView sourceTip: To quickly find your search term on this page, press Ctrl+F or \u2318-F (Mac) and use the find bar.Fly.ioService Interruption: Can't Destroy Machine, Deploy, or RestartQuestions / HelprailsfinntechnzJuly 17, 2023, 8:07pm1Hey team, the health checks on our fly app were failing this morning and so I\u2019ve logged in to diagnose this. I can see the machine has the \u201cstopped\u201d state, and there is a little banner saying:Service Interruption 3 hours agoWe are performing emergency maintenance on a host some of your apps instances are running on.and no other information. I can\u2019t see an issue on the status page and not sure where else to look for resolution steps or ETA?I\u2019m unable to restart or destroy the stopped machine instances (it times out), and trying to re-deploy the app throws an error:Error: found 1 machines that are unmanaged. `fly deploy` only updates machines with fly_platform_version=v2 in their metadata. Use `fly machine list` to list machines and `fly machine update --metadata fly_platform_version=v2 <machine id>` to update individual machines with the metadata. Once done, `fly deploy` will update machines with the metadata based on your fly.toml app configurationNot sure what else to try at this point short of re-creating a new app or putting it up on another host. Any info you can provide?2 LikesmfwgenericsJuly 18, 2023, 3:44am2We also experienced this. One of our machines seems to have gone zombie mode, reporting unreachable for all fly machine commands with \u201cError: could not get machine.\u201dI\u2019ve been able to restore availability to our app by using fly scale to allocate more VMs. However, the bad VM continues to exist in an indeterminate state, can\u2019t be destroyed or removed from the account. fly machine list shows invalid data for the VM such as creation date of \u201c1970-01-01T00:00:00Z\u201dI would appreciate any advice on how to remediate this.sevenseacatJuly 18, 2023, 6:41am3We\u2019re seeing the same issue in our app, as of nearly 14 hours ago - and ours is for the database container, so it\u2019s not as simple as scaling up to restore accessWe have a paid plan so I emailed support several hours ago, but no reply as of yet.For the record, our app is hosted in syd, so maybe one or two hosts are having issues there?sudojoshJuly 18, 2023, 8:23am4I\u2019m also getting this - just like @mfwgenerics, I worked around this by scaling to create a new machine, but still have the original machine in a state where it can\u2019t be destroyed:Error: could not get machine [machine ID]: failed to get VM [machine ID]: unavailable: dial tcp [ipv6]:3593: connect: connection refusedMy staging environment is in the same state, but until I\u2019m not adding more VMs that I\u2019m surely going to be billed for until I know I can clean up the zombies.Just like OP, I see the same error in the dashboard about emergency maintenance. That\u2019s been there for 15 hours, with no other information.This is the second time I\u2019ve had this kind of issue with Fly, where my service just goes down, Fly reports everything healthy, and there\u2019s literally no information and nothing I can really do other than wait and hope it comes back up sometime (hours later, probably).I appreciate the convenience that Fly offers, but these kind of problems erode my trust in this platform completely. Heroku had it\u2019s faults, but I was never left scouring a forum trying to get my service back up - if a host was unhealthy, my dyno would be automatically moved, no worries. I\u2019m running a small-scale golden path Rails app with Postgres, I can\u2019t imagine trying to fix these kinds of problems on a more complex app.1 LikefinntechnzJuly 18, 2023, 8:44am5Adding some more information here since I\u2019m also surprised that this is still ongoing 12 hours later with no response.We had four machines (app + Postgres for staging and production) running yesterday, and three of the four (including both databases) are still down and can\u2019t be accessed. I can replicate the issues others have mentioned here.This is our company\u2019s external API app and so the issue broke all of our integrations.Our team ended up setting up a new project in fly to spin up an instance to keep us going which took a couple of hours (backfilling environment variables and configuration etc, not a bad test of our DR ability).There is no way I can find to get the data from the db machines. Thank goodness this isn\u2019t our main production db and we were able to reverse engineer what we needed into there.Very keen to hear what\u2019s happening with this and why after so many hours there\u2019s no more info or updates.sevenseacatJuly 18, 2023, 8:49am6As an aside, it\u2019s kind of a kick in the teeth to see the status page for our organization reporting no incidents - the same page that lists our apps as under maintenance and inaccessible!1 LikemfwgenericsJuly 18, 2023, 9:56am7Confirming my deployment is in syd too. I\u2019m still seeing the zombie VM and observing failing CLI commands against the machine.south-pawJuly 18, 2023, 10:02am8We have syd deployments as well for all our apps tooI\u2019m feeling very lucky that none of our paid production apps or databases are affected currently (only our development environment is), but also really surprised that the issue has been ongoing for 17 hours now with no status page update, no notifications (beyond betterstack letting us know it was down) and one note on the app with not much info as to whats going on.It really worries me what would happen if it was one of our paid production instances that was affected - the data we\u2019re working with can\u2019t simply be \u2018recovered\u2019 later, it\u2019d just get dropped until service resumed or we migrated to another region to get things running againKeen to know whats wrong and whats being done about it1 Likesouth-pawJuly 18, 2023, 1:02pm9Message has now been updatedService Interruption (20 hours ago)We are continuing to investigate an infrastructure related issue on this host.Still no incidents listed on status page though for SYD region1 LikeTutelloJuly 18, 2023, 1:32pm10not sure if connected but had a redis app in lhr fall into suspended status overnight, killed an important demomachine is a zombie\u2026machine [id] was found and is currently in a stopped state, attempting to kill\u2026Error: could not kill machine [id]: failed to kill VM [id]: failed_precondition: machine not in known state for signaling, stoppedsevenseacatJuly 19, 2023, 1:26am11I got a response from support a few hours ago -Unfortunately this host managed to get into a extremely poor state, and a fix is taking longer than expected. We have a team continuing to work on it, but no estimated resolution time to share right now. As soon as we have an update we will let you know.So I guess we just wait\u20261 Likejl1July 19, 2023, 1:55am12Same issue here for me, on a host in syd. It\u2019s completely broken a pg cluster.The absence of any proactive status updates on this issue has been really poor.south-pawJuly 19, 2023, 4:26am13Thank you for sharing that update, surprised there is no status update from Fly yet thoughI can appreciate the issue might be taking up a lot of time and they want to focus on fixing it first - but even just a message from the staff here earlier would put me at ease for our production apps that are runningsevenseacatJuly 19, 2023, 5:14am14We worked out we could create a new Postgres cluster from one of the snapshots of the currently-down app - so we\u2019re back up and running for our app.(We had to create it with a different name, and then when we tried to make another one with the previous name, flyctl put the cluster on the same currently-down host! Oops)mplattsJuly 19, 2023, 6:49am15Also having this issue. Scale worked for the Phoenix server, but the Postgres server is also dead.And I can\u2019t even restore the Postgres one:Error: failed to create volume: Couldn't allocate volume, not enough compute capacity left in yyzsevenseacatJuly 19, 2023, 9:04am16There\u2019s a known incident listed on the status page for YYZ, might be related. Fly.io Status - We are undergoing emergency vendor hardware replacement in YYZ region.Still crickets for the down host in SYD thoughmplattsJuly 19, 2023, 10:44am17Yes, mine has been fixed.south-pawJuly 19, 2023, 12:45pm18Really weird how radio silent it\u2019s been on it we\u2019re coming up on 48 hours nowsudojoshJuly 19, 2023, 10:36pm19Just a note that the status update for me now states that the service interruption was resolved 7 hours ago:Service Interruption resolved 7 hours agoWe are continuing to investigate an infrastructure related issue on this host.I still had to manually restart the machine to actually bring my app back up, but I\u2019ve been able to actually interact with machines now, so I guess it is resolved.Never heard anything from Fly, just complete silence. No status page updates either. I\u2019m sympathetic to the problems I can imagine Fly having to scale their service and support, but the takeaway I have from this experience is that if something outside my own control happens with Fly, there\u2019s nothing I can do to find out what\u2019s going on, when it\u2019s going to be resolved, and if there\u2019s anything I can do to resolve the issue. It sounds like even the paid email support has a multi-hour response, and even then it\u2019s just going to be a \u201cwe\u2019re working on it\u201d. I can\u2019t recommend Fly professionally with that kind of experience, and I\u2019m not sure if I can even tolerate it for personal apps.3 LikesmfwgenericsJuly 20, 2023, 2:40pm20Update: my bad VM has finally been restored after a couple of days.I am concerned about the lack of clarity and communication around what happened but I\u2019m happy to put this situation down to growing pains on Fly\u2019s part. I think I\u2019ll be sticking to non-critical, non-stateful workloads for the near term though.1 Likenext page \u2192Home Categories FAQ/Guidelines Terms of Service Privacy PolicyPowered by Discourse, best viewed with JavaScript enabled",
    "summary": "- The Fly.io Postgres cluster experienced a service interruption for 3 days, causing machines to become unresponsive and unable to restart or be destroyed.\n- Users reported issues with their apps and databases hosted on Fly.io, with no resolution steps or ETA provided by the company.\n- Some users were able to work around the issue by scaling their apps or creating new instances, but there was a lack of communication and updates from Fly.io throughout the incident.",
    "hn_title": "Fly.io Postgres cluster down for 3 days, no word from them about it",
    "original_title": "Fly.io Postgres cluster down for 3 days, no word from them about it",
    "score": 500,
    "hn_content": "- Fly.io, a cloud infrastructure provider, experienced a major outage in their Postgres cluster that lasted for three days.\n- Users reported instances going down and being unable to access their data during the outage.\n- Fly.io acknowledged the issue and apologized for the lack of communication regarding the downtime.\n- Some users expressed frustration with the reliability and support of Fly.io, leading them to switch to other providers like DigitalOcean or Hetzner.\n- There are concerns about Fly.io's ability to handle mission-critical applications and provide reliable service.\n- The outage highlights the importance of choosing a cloud provider that offers reliable and secure infrastructure, as well as effective communication during downtime.- Users discuss their experiences with various cloud hosting providers like Hetzner, OVH, Digital Ocean, and Fly.io.\n- Some users appreciate providers like Hetzner and OVH for their straightforward VPS offerings without buzzwords.\n- Fly.io is criticized for poor support and unreliable infrastructure, particularly with regards to their database services.\n- Alternatives to Fly.io are suggested, including render.com, railway.app, and using managed Kubernetes clusters on platforms like GCP.\n- Some users express disappointment with AWS and its complexity, while others mention the high cost.\n- CockroachDB is recommended as an alternative to Postgres for improved reliability.\n- Concerns are raised about Fly.io's technical approach, suggesting that it sacrifices stability for pushing technical boundaries.\n- Users emphasize the importance of reliability and highlight the lack of monitoring and communication from Fly.io during outages.\n- Suggestions for alternative hosting providers include DO, Hetzner, and fl0.com.\n- Some users express hesitation to try Fly.io due to the reported issues and downtime.\n- Criticisms are made about Fly.io's handling of status page updates and lack of respect for users.\n- Users are encouraged to switch away from Fly.io if they value reliability and respect.",
    "hn_summary": "- Fly.io experienced a three-day outage in their Postgres cluster, resulting in users being unable to access their data.\n- Users expressed frustration with Fly.io's reliability and support, leading them to switch to other providers like DigitalOcean or Hetzner.\n- The outage highlights the importance of choosing a reliable and secure cloud provider with effective communication during downtime."
  },
  {
    "id": 36803124,
    "timestamp": 1689871270,
    "title": "TypeChat",
    "url": "https://microsoft.github.io/TypeChat/blog/introducing-typechat/",
    "hn_url": "http://news.ycombinator.com/item?id=36803124",
    "content": "Introducing TypeChatJuly 20, 2023 by Anders Hejlsberg, Steve Lucco, Daniel Rosenwasser, Pierce Boggan, Umesh Madan, Mike Hopcroft, and Gayathri ChandrasekaranIn the last few months, we've seen a rush of excitement around the newest wave of large language models. While chat assistants have been the most direct application, there's a big question around how to best integrate these models into existing app interfaces.In other words, how do we augment traditional UI with natural language interfaces? How do we use AI to take a user request and turn it into something our apps can operate on? And how do we make sure our apps are safe, and doing work that developers and users alike can trust?Today we're releasing TypeChat, an experimental library that aims to answer these questions. It uses the type definitions in your codebase to retrieve structured AI responses that are type-safe.You can get up and running with TypeChat today by runningnpm install typechatand hooking it up with any language model to work with your app.But let's first quickly explore why TypeChat exists.Pampering and ParsingThe current wave of LLMs default to conversational natural language \u2014 languages that humans communicate in like English. Parsing natural language is an extremely difficult task, no matter how much you pamper a prompt with rules like \"respond in the form a bulleted list\". Natural language might have structure, but it's hard for typical software to reconstruct it from raw text.Surprisingly, we can ask LLMs to respond in the form of JSON, and they generally respond with something sensible!User:Translate the following request into JSON.Could I get a blueberry muffin and a grande latte?Respond only in JSON like the following:{  \"items\": [    { \"name\": \"croissant\", \"quantity\": 2 },    { \"name\": \"latte\", \"quantity\": 1, \"size\": \"tall\" }  ]}ChatBot:{  \"items\": [    {      \"name\": \"blueberry muffin\",      \"quantity\": 1    },    {      \"name\": \"latte\",      \"quantity\": 1,      \"size\": \"grande\"    }  ]}This is good \u2014 though this example shows the best-case response. While examples can help guide structure, they don't define what an AI should return extensively, and they don't provide anything we can validate against.Just Add Types!Luckily types do precisely that. What we've found is that because LLMs have seen so many type definitions in the wild, types also act as a great guide for how an AI should respond. Because we're typically working with JSON \u2014 JavaScript Object Notation \u2014 and because it's is very near and dear to our hearts, we've been using TypeScript types in our prompts.User:Translate the following request into JSON.Could I get a blueberry muffin and a grande latte?Respond only in JSON that satisfies the Response type:type Response = {  items: Item[];};type Item = {  name: string;  quantity: number;  size?: string;  notes?: string;}ChatBot:{ \"items\": [  {   \"name\": \"blueberry muffin\",   \"quantity\": 1  },  {   \"name\": \"latte\",   \"quantity\": 1,   \"size\": \"grande\"  } ]}This is pretty great! TypeScript has shown that it's well-suited to precisely describe JSON. But what happens when a language model stumbles and makes up a response that doesn't conform to our types?Well because these types are valid TypeScript code, we can validate the response against them using the TypeScript compiler itself! In fact, the error feedback from the compiler can even be used to guide repairs. When put together, we can get a robust process for getting well-typed responses that our apps can further massage, validate with a user, etc.In other words, types are all you need.Enter TypeChatThe technique of combining a human prompt and a \"response schema\" is not necessarily unique \u2014 but it is promising. And as we've focused on translating user intent to structured data, we've found that TypeScript is very well-suited for the task. We've grown more confident with this approach, and in order to prove it out, we're releasing a library called TypeChat to help make it easier to use in your apps. TypeChat is already on npm if you want to try it now, and provides tools for prompt prototyping, schema validation, repair, and more.Here's the basic code to hook TypeChat up to an LLM and decide if a sentence is negative, neutral, or positive.// ./src/sentimentSchema.ts// The following is a schema definition for determining the sentiment of a some user input.export interface SentimentResponse {  /** The sentiment of the text. */  sentiment: \"negative\" | \"neutral\" | \"positive\";}// ./src/main.tsimport * as fs from \"fs\";import * as path from \"path\";import dotenv from \"dotenv\";import * as typechat from \"typechat\";import { SentimentResponse } from \"./sentimentSchema\";// Load environment variables.dotenv.config({ path: path.join(__dirname, \"../.env\") });// Create a language model based on the environment variables.const model = typechat.createLanguageModel(process.env);// Load up the contents of our \"Response\" schema.const schema = fs.readFileSync(path.join(__dirname, \"sentimentSchema.ts\"), \"utf8\");const translator = typechat.createJsonTranslator<SentimentResponse>(model, schema, \"SentimentResponse\");// Process requests interactively.typechat.processRequests(\"\ud83d\ude00> \", /*inputFile*/ undefined, async (request) => {  const response = await translator.translate(request);  if (!response.success) {    console.log(response.message);    return;  }  console.log(`The sentiment is ${response.data.sentiment}`);});TypeChat can be used in a number of different ways. The way we've discussed here so far is all about using a \"data schema\" to turn some user intent into a structured response; however, TypeChat also makes it possible to use an \"API schema\" to construct basic programs. We have some docs and examples to get a sense of the different ways you can use TypeChat.Open and PluggableFirst of all, TypeChat is open-source. We're MIT-licensed and you can find us on GitHub where we're eager to hear your thoughts, share our ideas, and build with you.Second, TypeChat is built in a way that is meant to be model-neutral. While we have some very basic integration with the OpenAI API and the Azure OpenAI service for convenience, this approach should work for any chat completion-style API that you want to use \u2014 though note that at the moment, TypeChat works best with models that have been trained on both prose and code.Try It Today!We'd love to know if TypeChat is something that's useful and interests you! As we mentioned, we'll be welcoming you on GitHub if you have any question, suggestions, and more.Happy Hacking!",
    "summary": "- TypeChat is an experimental library that aims to integrate large language models into existing app interfaces by using type definitions to retrieve structured AI responses.\n- It allows developers to translate user requests into JSON that satisfies specific type definitions, providing a robust process for obtaining well-typed responses.\n- TypeChat is open-source and model-neutral, making it flexible for use with various chat completion-style APIs.",
    "hn_title": "TypeChat",
    "original_title": "TypeChat",
    "score": 450,
    "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginTypeChat (microsoft.github.io)450 points by DanRosenwasser 17 hours ago | hide | past | favorite | 142 commentsverdverm 13 hours ago | next [\u2013]I don't see the value add here.Here's the core of the message sent to the LLM: https://github.com/microsoft/TypeChat/blob/main/src/typechat...You are basically getting a fixed prompt to return structured data with a small amount of automation and vendor lockin. All these LLM libraries are just crappy APIs to the underlying API. It is trivial to write a script that does the same and will be much more flexible as models and user needs evolve.As an example, think about how you could change the prompt or use python classes instead. How much work would this be using a library like this versus something that lifts the API calls and text templating to the user like: https://github.com/hofstadter-io/hof/blob/_dev/flow/chat/llm...replybwestergard 13 hours ago | parent | next [\u2013]The value is in:1. Running the typescript type checker against what is returned by the LLM.2. If there are type errors, combining those into a \"repair prompt\" that will (it is assumed) have a higher likelihood of eliciting an LLM output that type checks.3. Gracefully handling the cases where the heuristic in #2 fails.https://github.com/microsoft/TypeChat/blob/main/src/typechat...In my experience experimenting with the same basic idea, the heuristic in #2 works surprisingly well for relatively simple types (i.e. records and arrays not nested too deeply, limited use of type variables). It turns out that prompting LLMs to return values inhabiting relatively simple types can be used to create useful applications. Since that is valuable, this library is valuable inasmuch as it eliminates the need to hand roll this request pattern, and provides a standardized integration with the typescript codebase.replyBoorishBears 11 hours ago | root | parent | next [\u2013]Here's a project that does that better imo:https://github.com/dzhng/zod-gptAnd by better I mean doesn't tie you to OpenAI for no good reasonreplysemiquaver 9 hours ago | root | parent | next [\u2013]How does TypeChat tie you to OpenAI more than zod-gpt does? The interface required of a chat completion model is as simple as it gets, and you can provide your own easily (as the linked post makes clear)https://github.com/microsoft/TypeChat/blob/4d34a5005c67bc494...replyBoorishBears 9 hours ago | root | parent | next [\u2013]The ergonomics of most of these AI libraries are built around using whatever models they provide integrations for: according to the file you linked retries won't even work unless you go and roll them in your implementation.I'm sure someone will open a PR for Anthropic/Cohere/etc. but a quick glance made it pretty clear they made it with OpenAI-first in mind, or even low hanging fruit like retries would have been abstracted away at a higher level.replyLordDragonfang 11 hours ago | root | parent | prev | next [\u2013]I don't know where all you people work that your employer would prefer a random git repo (that has no support and no guarantee of updates) over a solution from Microsoft. (Alternatively: that you have so much free time that you'd prefer to fiddle with your own validation code instead of writing your actual app)Open source solutions are great (which this still is, btw), but having a first-party solution is also a good thing.replymsp26 9 hours ago | root | parent | next [\u2013]You're overrating the influence of the name Microsoft here. It's just some devs from the company working on this with no proper guarantee backing the project.I've been through this whole song and dance already with Microsoft's Guidance (another LLM project) and could not justify using it further in production at work. We built some tools and wrappers ourselves and it wasn't even that difficult. These libraries are often more trouble than they're worth.replysambroner 6 hours ago | root | parent | next [\u2013]I\u2019m pretty sure Anders, Steve Lucco, and Daniel Rosenwasser worked on this. So inventors + current lead PM of typescript.Should lend some credibility to the project.replyBoorishBears 11 hours ago | root | parent | prev | next [\u2013]I don't know which employer is hiring the people who make logical leaps like this but I thank them for their sacrifice.At the end of the day the repo I linked is grokkable with about 10 minutes of effort, and has simple demonstrable usefulness by letting you swap out the LLM you're calling.Both are experimental open source libraries in an experimental space.replyverdverm 13 hours ago | root | parent | prev | next [\u2013]these are trivial steps you can add in any script, as your link demonstrates.Why would I want to add all this extra stuff just for that? The opaque retry until it returns valid JSON? That sounds like it will make for many pleasant support cases or issuesPersonally, I have found investing more effort in the actual prompt engineering improves success rates and reduces the need to retry with an appended error message. Especially helpful are input/output pairs (i.e. few-shot) and while we haven't tried it yet, I imagine fine-tuning and distillation would improve the situation even morereplybwestergard 12 hours ago | root | parent | next [\u2013]There are many subtleties to invoking the typescript type checker from node. It's nice to have support for that from the team that maintains the type checker.replyverdverm 10 hours ago | root | parent | next [\u2013]Is the team working on typescript in a good position to be making LLM libraries, interfaces, and abstractions? Do they have the background and context to understand how their library fits into AI workflows? Could they have provided the same value with a blog post and sample code?replyicholy 8 hours ago | root | parent | next [\u2013]Your coworkers must love you.replybehnamoh 8 hours ago | root | parent | prev | next [\u2013]agreed. not to mention we're talking about Microsoft here. the same company that gave us \"guidance\", a defunct LLM framework.replylayoric 8 hours ago | root | parent | next [\u2013]I\u2019ve used guidance, why is it defunct? I found it was powerful at templating, really decent for generating synthetic datasets.replypolitelemon 13 hours ago | parent | prev | next [\u2013]Pretty much all the LLM libraries I'm seeing are like this. They boil down to a request to the LLM to do something in a certain way. I've noticed under complex conditions, they stop listening and start reverting to their 'default' behavior.But that said it still feels like using a library is the right thing to do... so I'm still watching this space to see what matures and emerges as a good-enough approach.replyTechBro8615 11 hours ago | parent | prev | next [\u2013]Where's the vendor lock-in? This is an open source library and the file you linked to even includes configs for two vendors: ChatGPT and Bard.replyverdverm 10 hours ago | root | parent | next [\u2013]vendor lock in to a library and the design choices they makebasically, since it reduces the user input space, you are giving up flexibility and control for some questionably valuable abstractions, such as a predefined prompt, no ability to prompt engineer, CoT/ToT, etc...if anything, choose a broader framework like langchain and have something like this an extension or plugin to the framework, no need for a library for this one little thingreplyTechBro8615 10 hours ago | root | parent | next [\u2013]Weird, I would suggest the opposite - LangChain is a nuke that was hastily assembled to crack a peanut, almond, and whatever other nuts were hype driven into the framework. It's a mess of spaghetti - which is nothing against the Langchain authors - it was just the first iteration in a new problem space. But adopting it in a new codebase is a big commitment that locks you into complexity you'll almost certainly want to shed at some point.Whereas this library is a much more focused approach that does one small thing well, and could be integrated into your own homerolled frameworks (or probably even langchain itself, assuming you use langchain.js).replyquickthrower2 3 hours ago | parent | prev | next [\u2013]You can probably define the python language grammar as a typescript type though!replyparentheses 9 hours ago | parent | prev | next [\u2013]The value is turn unstructured data into structured data and ensure it satisfies schema constraints.For example: you have 1000 free-text survey responses about your product, building a schema and for-each `TypeChat`ing them would get you a dataset for that free-text. It's mind-bogglingly useful.replywhimsicalism 12 hours ago | parent | prev | next [\u2013]Yes as the abstractions gets better it becomes easier to code useful things.replyverdverm 10 hours ago | root | parent | next [\u2013]the debate is about how valuable the abstraction here is to warrant a library, and the fact that it predefines the prompt and api call flow, so you cannot prompt engineer or use something like CoT/ToTreplyjameshart 6 hours ago | root | parent | next [\u2013]This amounts to saying \u2018how dare someone publish some code that they wrote!\u2019Is it your impression that this is being pitched as some grand solution?That this was published as a way to shut out other people from doing the same thing in other ways?Can\u2019t we just look at a cool thing someone did, and released for other people to play with, and say \u2018huh! That\u2019s neat!\u2019 And get inspired?replypizza 9 hours ago | root | parent | prev | next [\u2013]People can debate till the cows come home. But it's worth remembering that hacker news is about stimulating intellectual curiosity.There's no reason for this to have a fixed flow, either - it's got a hint of diagonalizability to it - by which I mean, you can get the model to build a schema for dynamic flows, given a 'bootstrapping' schema. No different than what has always had to happen for someone to write a compiler for a programming language in the language itself.replynfw2 11 hours ago | parent | prev | next [\u2013]It\u2019s essentially prompt engineering as a service with some basic quality-control features thrown in.Sure, your engineers could implement it themselves, but don\u2019t they have better things to do?replyverdverm 10 hours ago | root | parent | next [\u2013]the quality of the prompt does not look that good from my experience reaching flexible structured output based on a schemaThere are other questionable decisions and a valuable use of engineering time is indeed to evaluate candidate abstractions and think about the long-term cost of adopting them. In this case, it does not seem like it saves that much effort and in the long run means a lot of important LLM knobs are out of your control. Not a good tradeoffreplyofslidingfeet 11 hours ago | parent | prev | next [\u2013]Getting these models to reliably return a consistent structure without frequent human intervention and/or having to account for the personal moral opinions of big tech CEOs is not trivial, no.replyverdverm 10 hours ago | root | parent | next [\u2013]There are multiple ways to get structured output, and what this library is doing is not really that interesting. The concept is interesting and has had multiple implementations already, the code (and abstraction) here is not interesting and creates more issues than it solvesreplyofslidingfeet 9 hours ago | root | parent | next [\u2013]Tell me how to get reliably structured output. I'm all ears.replyrefulgentis 9 hours ago | root | parent | next [\u2013]I have a prompt from February pre chatgpt and now I just use the models functions support, it's built for exactly thatreplyandy_xor_andrew 6 hours ago | prev | next [\u2013]Here's one thing I don't get.Why all the rigamarole of hoping you get a valid response, adding last-mile validators to detect invalid responses, trying to beg the model to pretty please give me the syntax I'm asking for......when you can guarantee a valid JSON syntax by only sampling tokens that are valid? Instead of greedily picking the highest-scoring token every time, you select the highest-scoring token that conforms to the requested format.This is what Guidance does already, also from Microsoft: https://github.com/microsoft/guidanceBut OpenAI apparently does not expose the full scores of all tokens, it only exposes the highest-scoring token. Which is so odd, because if you run models locally, using Guidance is trivial, and you can guarantee your json is correct every time. It's faster to generate, too!replydonfotto 19 minutes ago | parent | next [\u2013]I agree that sampling only valid tokens is a very promising approach.I experimented a bit with finetuning open source LLMs for JSON parsing (without guided token sampling). Depending on one's use case, 70B parameters might be an overkill. I've seen promising results with much much smaller models. Finetuning a small model combined with guided token sampling would be interesting.Then again, finetuning is perhaps not perfect for very general applications. When you get input that you didn't anticipate in your training dataset, you're in trouble.replyzarzavat 6 hours ago | parent | prev | next [\u2013]It\u2019s like the story of the brown M&Ms[0]. If the model is returning semantically correct data, you would hope that it can at least get the syntax correct. And if it can\u2019t then you ought to throw the response away anyway.Also I believe that such a method cannot capture the full complexity of TypeScript types.[0] https://www.snopes.com/fact-check/brown-out/replytonyonodi 15 minutes ago | root | parent | next [\u2013]That's a great analogy! I'd been wondering for a while whether that's a problem with this approach; to be honest I still don't know whether it is, so it would be good to see someone test it empirically.replyrolisz 3 hours ago | parent | prev | next [\u2013]> when you can guarantee a valid JSON syntax by only sampling tokens that are valid? Instead of greedily picking the highest-scoring token every time, you select the highest-scoring token that conforms to the requested format.Yes, you can guarantee a syntactically correct JSON that way, but will it be a semantically correct? If the model really really really wanted to put another token there, but you are forcing it to put a {, maybe the following generated text won't be as good.I'm not sure, I'm just wondering out loud.replygeysersam 3 hours ago | root | parent | next [\u2013]Well, if the output doesn't conform to the format it's useless. If the model can't produce good and correct output then it's simply not up to the task.replyIanCal 1 hour ago | root | parent | next [\u2013]That really strongly depends on your task. Lots of tasks can accept a non-zero failure rate in return for better results on the successful cases. I'm not sure I can think of any off the top of my head where you'd use a LLM and can never deal with a failure, particularly if you're using an external service where you're guaranteed to have to deal with errors or downtime at some point.replycsomar 4 hours ago | parent | prev | next [\u2013]The LLM will be able to handle more complex scenarios. I could imagine a use-case: If you are ordering from a self-vending machine, instead of having to go through the whole process you just say your order out loud. You can say, for example, a couple chocolate bars and the LLM tries to guess from inventory.Of course, if you are on the web, it makes no sense. It is much easier to use the mouse to click on a couple of items.replyCGamesPlay 5 hours ago | parent | prev | next [\u2013]OpenAI doesn\u2019t expose this information because it makes it vastly easier to train your model off theirs.replypaxys 15 hours ago | prev | next [\u2013]I swear I think of something and Anders Hejlsberg builds it.Structured requests and responses are 100% the next evolution of LLMs. People are already getting tired of chatbots. Being able to plug in any backend without worrying about text parsing and prompts will be amazing.replyunshavedyak 14 hours ago | parent | next [\u2013]> Structured requests and responses are 100% the next evolution of LLMs. People are already getting tired of chatbots. Being able to plug in any backend without worrying about text parsing and prompts will be amazing.Yup, a general desire of mine is to locally run an LLM which has actionable interfaces that i provide. Things like \"check time\", \"check calendar\", \"send message to user\" and etc.TypeChat seems to be in the right area. I can imagine an extra layer of \"fit this JSON input to a possible action, if any\" and etc.I see a neat hybrid future where a bot (LLM/etc) works to glue layers of real code together. Sometimes part of ingestion, tagging, etc - sometimes part of responding to input, etc.All around this is a super interesting area to me but frankly, everything is moving so fast i haven't concerned myself with diving too deep in it yet. Lots of smart people are working on it so i feel the need to let the dust settle a bit. But i think we're already there to have my \"dream home interface\" working.replypsyphy 8 hours ago | root | parent | next [\u2013]I just published CopilotKit, which lets you implement this exact functionality for any web app via react hooks.`useMakeCopilotActionable` = you pass the type of the input, and an arbitrary typescript function implementation.https://github.com/RecursivelyAI/CopilotKitFeedback welcomereplysdwr 13 hours ago | root | parent | prev | next [\u2013]I was thinking about this yesterday. ChatGPT really is good enough to act as a proper virtual assistant / home manager, with enough toggles exposed.reply9dev 13 hours ago | root | parent | next [\u2013]ChatGPT isn\u2019t the limiting factor here, a good way to expose the toggles is. I recently tried to expose our company CRM to employees by means of a Teams bot they could ask for stuff in natural language (like \u201esend an invite link to newlead@example.org\u201c or \u201ehow many MAUs did customer Foo have in June\u201c), but while I almost got there, communicating an ever-growing set of actionable commands (with an arbitrary number of arguments) to the model was more complex than I thought.replyJ_Shelby_J 12 hours ago | root | parent | next [\u2013]https://github.com/ShelbyJenkins/LLM-OpenAPI-minifierI have a working solution to exposing the toggles.I\u2019m integrating it into the bot I have in the other repo.Goal is you point to an openapi spec and then GPT can run choose and run functions. Basically Siri but with access to any API.replysdwr 5 hours ago | root | parent | next [\u2013]Good shit!replyunshavedyak 11 hours ago | root | parent | prev | next [\u2013]Care to share what made it complex? My comment above was most likely ignorant, but my general thought was to write some header prompt about available actions that the LLM could map to, and then ask it if a given input text matches to a pre-defined action. Much like what TypeChat does.Does this sound similar enough to what you were doing? Was there something difficult in this that you could explain?Aside from being completely hand-wavey in my hypothetical guess-timated implementation, i had figured the most difficult part would be piping complex actions together. \"Remind me tomorrow about any events i have on my calendar\" would be a conditional action based on lookups, etc - so order of operations would also have to be parsed somehow. I suspect a looping \"thinking\" mechanism would be necessary, and while i know that's not a novel idea i am unsure if i would nonetheless have to reinvent it in my own tech for the way i wanted to deploy.replykrehl 2 hours ago | root | parent | prev | next [\u2013](How) did you solve this?replypizza 8 hours ago | root | parent | prev | next [\u2013]How about unix's (and plan9's more extreme version of) \"everything is a file\" philosophy? The gift that won't stop giving..replyparagraft 7 hours ago | parent | prev | next [\u2013]Tell me about it - I implemented this just yesterday except with a focus on functions rather than objects.reply_the_inflator 12 hours ago | parent | prev | next [\u2013]This as a dynamic mapper in a backend layer can be huge.For example, try to keep up with (frequent) API payload changes around a consumer in Java. We implemented a NodeJS layer just to stay sane. (Banking, huge JSON payloads, backends in Java)Mapping is really something LLMs could shine.replytylerrobinson 12 hours ago | root | parent | next [\u2013]It could shine, or it could be an absolute disaster.Code/functionality archeology is already insanely hard in orgs with old codebases. Imagine the facepalming that Future You will have when you see that the way the system works is some sort of nondeterministic translation layer that magically connects two APIs where versions are allowed to fluctuate.replyjacamera 10 hours ago | root | parent | next [\u2013]I think it's ironic that some people are saying the likes of Chat GPT will make software engineers obsolete when in reality there will be huge demand for the humans that will eventually be needed to clean up messes just like this.replysidnb13 11 hours ago | parent | prev | next [\u2013]Maybe worth looking into: https://news.ycombinator.com/item?id=36750083replysidnb13 11 hours ago | parent | prev | next [\u2013]maybe worth looking into: https://news.ycombinator.com/item?id=36750083replybottlepalm 14 hours ago | prev | next [\u2013]How does no voice assistant (Apple, Google, Amazon, Microsoft) integrate LLMs into their service yet, and how has OpenAI not released their own voice assistant?Also like RSS, if there were some standard URL a websites exposed for AI interaction, using this TypeChat to expose the interfaces, we'd be well on our way here.replynathan_f77 11 minutes ago | parent | next [\u2013]I'm really looking forward to something that I can use to control Home Assistant. I'm just really nervous about using any cloud-based API for this, so I would like to get something running on a server in my own house. But I would also want the voice recognition and response times to be extremely fast so I don't feel like I'm ever waiting for anything. I've seen a few DIY attempts at a personal assistant but there's always a significant delay that would become very annoying if I used it regularly.replydbish 12 hours ago | parent | prev | next [\u2013]OpenAI is pretty likely working on their own (see Kaparthy's \"Building a kind of JARVIS @ O\u0440\u0435\u0578\u0391\u04cf\"), and Microsoft of course is doing an integration or reinterpretation of Cortana with OpenAI's LLMS (since they are incapable of building their own models nowadays it seems - \"Why do we have Microsoft Research at all?\u201d-S.N.), but there's a lot less value in voice driven LLM then there is in actually being able to perform actions. Take Alexa for example, you need a system that can handle smart home control in a predictable, debuggable, way otherwise people would get annoyed. I definitely think you can do this, but the current system as built (and others like Siri and to a lesser use Cortana) all have a bunch of hooks and APIs being used by years and years of rules and software built atop less powerful models. They need to both maintain the current quality and improve on it while swapping out major parts of their system in order to make this work, which takes time.Not to mention that none of these assistants actually make any money, they all lose money really, and are only worthwhile to big companies with other ways to make cash or drive other parts of their business (phones, shopping, whatever), so there's less incentive for a startup to do it.I worked on both Cortana and Alexa in the past, thought a lot about trying to build a new version of them ground up with the LLM advancements, and while the tech was all straight forward and even had some new ideas for use cases that are enabled now, could not figure out a business model that would work (and hence, working on something completely different now).replybottlepalm 7 hours ago | root | parent | next [\u2013]It's July, they just needed to put a voice interface on ChatGPT, it'd easily help them sell more pro licenses as well. I'm not a conspiracy person, but this just seems so obvious it feels like there's something else going on here.replythrowaway290 3 hours ago | root | parent | next [\u2013]No big company wants their appliance to accidentally talk customer's child into suicide or spouse into a divorce. Bad for image.replynonethewiser 8 hours ago | parent | prev | next [\u2013]> How does no voice assistant (Apple, Google, Amazon, Microsoft) integrate LLMs into their service yetWhen I first learned what ChatGPT was my thought was \"oh so like what Siri is supposed to be.\"replyzitterbewegung 14 hours ago | parent | prev | next [\u2013]Microsoft is doing that to replace Cortana in windows 11reply9dev 13 hours ago | parent | prev | next [\u2013]Seriously, it feels like there\u2019s some collusion going on behind the scenes. This is the most obvious use case for the technology, but none of the big vendors have explored it.replymavamaarten 2 hours ago | root | parent | next [\u2013]I think it's because it turns out that taming a generative language model is really difficult. It's what we need to support more than some hardcoded simple questions, but companies like Google who are known for search want to keep their image of \"use us to find what you're looking for\". In the current state, their models (especially Bard in my experience) simply return bullshit and want to sound confident. They need to get beyond that stage.But I feel you. My Google Assistant doesn't even seem to look for answers to questions anymore. All I get, even for simple queries, is a \"sorry, I don't understand\".replyjomohke 13 hours ago | root | parent | prev | next [\u2013]It takes a while to develop a product, and the world only woke up to them mere months agoreplyCOGlory 13 hours ago | parent | prev | next [\u2013]Willow, and the Willow Interference Server have the option to use Vicuna with speech input and TTSreplyperryizgr8 5 hours ago | parent | prev | next [\u2013]Talking to Alexa is laughable now, after having interacted with ChatGPT and Bing. It's so frustrating to see capable hardware being let down by crappy software for years upon years.replydvt 11 hours ago | prev | next [\u2013]This is my hot take: we're slowly entering the \"tooling\" phase of AI, where people realize there's no real value generation here, but people are so heavily invested in AI, that money is still being pumped into building stuff (and of course, it's one of the best way to guarantee your academic paper gets published). I mean, LangChain is kind of a joke and they raised $10M seed lol.DeFi/crypto went through this phase 2 years ago. Mark my words, it's going to end up being this weird limbo for a few years where people will slowly realize that AI is a feature, not a product. And that its applicability is limited and that it won't save the world. It won't be able to self-drive cars due to all the edge cases, it won't be able to perform surgeries because it might kill people, etc.I keep mentioning that even the most useful AI tools (Copilot, etc.) are marginally useful at best. At the very best it saves me a few clicks on Google, but the agents are not \"intelligent\" in the least. We went through a similar bubble a few years ago with chatbots[1]. These days, no one cares about them. \"The metaverse\" was much more short-lived, but the same herd mentality applies. \"It's the next big thing\" until it isn't.[1] https://venturebeat.com/business/facebook-opens-its-messenge...replyJSavageOne 10 hours ago | parent | next [\u2013]Hard disagree on AI being just a bubble with limited applicability.> It won't be able to self-drive cars due to all the edge cases, it won't be able to perform surgeries because it might kill people, etc.You literally just cherry-picked the most difficult applications of AI. The vast majority of peoples' jobs don't involve life or death, and thus are ripe for automation. And even if the life or death jobs retain a human element, they will most certainly be augmented by AI agents. For example a surgery might still be handled by a human, but it will probably become mandatory for a doctor or nurse to diagnose a patient in conjunction with an AI.> We went through a similar bubble a few years ago with chatbotsAre you honestly comparing that to now? ChatGPT got to 100 million users in a few months and everyone and their grandma has used it. I wasn't even aware of any chatbot bubble a few years ago, it certainly wasn't that significant.> even the most useful AI tools (Copilot, etc.) are marginally useful at bestSure, but you're literally seeing them in their worst versions. ChatGPT has been a life-changer for me, and it doesn't even execute code yet (Code Interpreter does though, which I haven't tested yet)By 2030 humans probably won't be typing code anymore, it'll just be prompting machines and directing AI agents. By then most peoples' jobs will also be automated.AI isn't just some fad, it's going to change literally every industry, and way faster than people think. The cynicism here trying to dismiss the implications of AI by comparing it to the metaverse are just absurd and utterly lacking in imagination. Yes there is still a lot of work that needs to be done, specifically in the AI agent side of things, but we will get there, probably way faster than people realize, and the implications are enormous.replyhnlmorg 2 hours ago | root | parent | next [\u2013]> By 2030 humans probably won't be typing code anymore, it'll just be prompting machines and directing AI agents. By then most peoples' jobs will also be automated.Eventually, perhaps. But by 2023? Definitely not.I think both you and the GP are at opposite ends of the extreme and the reality is somewhere in that gulf in betweenreplycoffeemug 11 hours ago | parent | prev | next [\u2013]When I use ChatGPT I feel like I'm looking at a different technology than other people. It's supposed to be able to answer every question and teach me anything, but in practice it turns out to be a content-farm-as-a-service (CFaaS?) Copilot is similar, it's usually easier for me to write the code than iterate through it to find the least bad example and then fix the bugs.That said, AlphaGo went from \"hallucinating\" bad moves to the best player in the world in a fairly short period of time. If this is at all doable for language models, GPT-x may blow all this out of the water.replydvt 10 hours ago | root | parent | next [\u2013]> That said, AlphaGo went from \"hallucinating\" bad moves to the best player in the world in a fairly short period of time. If this is at all doable for language models, GPT-x may blow all this out of the water.I think the state space when looking at something like Go v. natural language (or even formal languages like programming languages or first/second order logic) is not even remotely comparable. The number of states in Go is 3^361. The number of possible sentences in English, while technically infinite, has some sensible estimates (Googling shows the relatively tame 10^570 figure).replynotRobot 11 hours ago | parent | prev | next [\u2013]I feel like this is actually a very sensible take. AI has many uses, and it can be really good at some things, but it's not the hail mary it's being treated as.replyphillipcarter 10 hours ago | parent | prev | next [\u2013]> DeFi/crypto went through this phase 2 years ago.A key difference is that these things, no matter how impressive their technical merits, required people to completely reshape whatever they were doing to get the first bit of benefit.Modern AI (and really, usually LLMs) has immediate and broad applicability across nearly every economic sector, and that's why so many of us are already building and releasing features with it. There's incredible value in this stuff. Completely world-changing? No. But enough to create new product categories and fundamentally improve large swaths of existing product capabilities? Absolutely.reply33a 15 hours ago | prev | next [\u2013]Looks like it just runs the LLM in a loop until it spits out something that type checks, prompting with the error message.This is a cute idea and it looks like it should work, but I could see this getting expensive with larger models and input prompts. Probably not a fix for all scenarios.replyosaariki 14 hours ago | parent | next [\u2013]I'm not familiar with how TypeChat works, but Guidance [1] is another similar project that can actually integrate into the token sampling to enforce formats.[1]: https://github.com/microsoft/guidancereplyJ_Shelby_J 12 hours ago | root | parent | next [\u2013]It\u2019s logit bias. You don\u2019t even need another library to do this. You can do it with three lines of python.Here\u2019s an example of one of my implementations of logit bias.https://github.com/ShelbyJenkins/shelby-as-a-service/blob/74...replybehnamoh 12 hours ago | root | parent | prev | next [\u2013]except that guidance is defunct and is not maintained anymore.replyhuac 9 hours ago | root | parent | next [\u2013]did they announce that anywhere? it does appear like progress has slowed down quite a lot.replybabyshake 14 hours ago | parent | prev | next [\u2013]At least with OpenAI, wouldn't it be better if under the hood it was using the new function call feature?replyakavi 14 hours ago | root | parent | next [\u2013]Typescript's type system is much more expressive than the one the function call feature makes available.I imagine closing the loop (using the TS compiler to restrict token output weights) is in the works, though it's probably not totally trivial. You'd need:* An incremental TS compiler that could report \"valid\" or \"valid prefix\" (ie, valid as long as the next token is not EOF)* The ability to backtrack the modelIdk how hard either one piece is.replyrezonant 12 hours ago | root | parent | next [\u2013]For the TS compiler: If you took each generation step, closed any partial JSON objects (ie close any open `{`), checked that it was valid JSON and then validated it using a deep version of Partial<T>, that should do the trick.replyakavi 10 hours ago | root | parent | next [\u2013]Not for even the simplest schemas.Eg, given even the type:  {\"aLongerKey\": \"value\"}The generation prefix:  {\"awould by your algorithm produce the following invalid output:  {\"a}replyrezonant 5 hours ago | root | parent | next [\u2013]That's why I mentioned you check the JSON validity first. You'd obviously need to continue letting it generate tokens until you can parse the JSON to check if the type is partial. You could of course close even the quotes but then you'd get \"not valid\" signals from TS when the AI is like \"just let me finish!\" :-)replyjust-ok 9 hours ago | root | parent | prev | next [\u2013]But that isn\u2019t valid JSONreplyakavi 7 hours ago | root | parent | next [\u2013]Right, it would fail even before hitting the typing check.replySkyPuncher 13 hours ago | parent | prev | next [\u2013]I suspect most products are concerned about product-market fit then they can wrangle costs down.There's also a good assumption that models will be improving structured output as the market is demanding it.replyjoefreeman 15 hours ago | prev | next [\u2013]> It's unfortunately easy to get a response that includes { \"name\": \"grande latte\" }  type Item = {    name: string;    ...    size?: string;I'm not really following how this would avoid `name: \"grande latte\"`?But then the example response:  \"size\": 16> This is pretty great!Is it? It's not even returning the type being asked for?I'm guessing this is more of a typo in the example, because otherwise this seems cool.replyDanRosenwasser 14 hours ago | parent | next [\u2013]Whoops - thanks for catching this. Earlier iterations of this blog post used an different schema where `size` had been accidentally specified as a `number`. While we changed the schema, we hadn't re-run the prompt. It should be fixed now!replygraypegg 14 hours ago | parent | prev | next [\u2013]Their example here is really weak overall IMO. Like more than just that typo. You also probably wouldn\u2019t want a \u201cname\u201d string field anyway. Like there\u2019s nothing stoping you from receiving  {    name: \u201cthe brown one\u201d,    size: \u201cthe espresso cup\u201d,  \u2026 }Like that\u2019s just as bad as parsing the original string. You probably want big string union types for each one of those representing whatever known values you want, so the LLM can try and match them.But now why would you want that to be locked into the type syntax? You probably want something more like Zod where you can use some runtime data to build up those union types.You also want restrictions on the types too, like quantity should be a positive, non-fractional integer. Of course you can just validate the JSON values afterwards, but now the user gets two kinds of errors. One from the LLM which is fluent and human sounding, and the other which is a weird technical \u201coops! You provided a value that is too large for quantity\u201d error.The type syntax seems like the wrong place to describe this stuff.replymynameisvlad 15 hours ago | parent | prev | next [\u2013]I feel like that's just a documentation bug. I'm guessing they changed from number of ounces to canonical size late in the drafting of the announcement and forgot to change the output value to match.There would be no way for a system to map \"grande\" to 16 based on the code provided, and 16 does not seem to be used anywhere else.replyhirsin 15 hours ago | parent | prev | next [\u2013]The rest of the paragraph discusses \"what happens when it ignores type?\", so I think that's where they were going with that?replyparentheses 10 hours ago | prev | next [\u2013]I'm very surprised that they're not using `guidance` [0] here.It not only would allow them to suggest that required fields be completed (avoiding the need for validation [1]) and probably save them GPU time in the end.There must be a reason and I'm dying to know what it is! :)Side-note, I was in the process of building this very thing and good ol' Misrocoft just swung in and ate my lunch.. :/[0] https://github.com/microsoft/guidance[1] https://github.com/microsoft/TypeChat/blob/main/src/typechat...replytlrobinson 9 hours ago | prev | next [\u2013]  const schema = fs.readFileSync(path.join(__dirname, \"sentimentSchema.ts\"), \"utf8\");  const translator = typechat.createJsonTranslator<SentimentResponse>(model, schema, \"SentimentResponse\"); It would have been much nicer if they took this an an opportunity to build generic runtime type introspection into TypeScript.replyxigoi 2 hours ago | prev | next [\u2013]Why are we trying to get structured output out of something that was specifically designed to produce natural-language output?replyungerik 1 hour ago | parent | next [\u2013]Because we can ;-)replyZaheer 13 hours ago | prev | next [\u2013]It's not super clear how this differs from another recently released library from Microsoft: Guidance (https://github.com/microsoft/guidance).They both seem to aim to solve the problem of getting typed, valid responses back from LLMsreplyDanRosenwasser 12 hours ago | parent | next [\u2013]One of the key things that we've focused on with TypeChat is not just that it acts as a specification for retrieving structured data (i.e. JSON), but that the structure is actually valid - that it's well-typed based on your type definitions.The thing to keep in mind with these different libraries is that they are not necessarily perfect substitutes for each other. They often serve different use-cases, or can be combined in various ways -- possibly using the techniques directly and independent of the libraries themselves.replygarrett_makes 12 hours ago | prev | next [\u2013]I built and released something really similar to this (but smaller scope) for Laravel PHP this week: https://github.com/adrenallen/ai-agents-laravelMy take on this is, it should be easy for an engineer to spin up a new \"bot\" with a given LLM. There's a lot of boring work around translating your functions into something ChatGPT understands, then dealing with the response and parsing it back again.With systems like these you can just focus on writing the actual PHP code, adding a few clear comments, and then the bot can immediately use your code like a tool in whatever task you give it.Another benefit to things like this, is that it makes it much easier for code to be shared. If someone writes a function, you could pull it into a new bot and immediately use it. It eliminates the layer of \"converting this for the LLM to use and understand\", which I think is pretty cool and makes building so much quicker!None of this is perfect yet, but I think this is the direction everything will go so that we can start to leverage each others code better. Think about how we use package managers in coding today, I want a package manager for AI specific tooling. Just install the \"get the weather\" library, add it to my bot, and now it can get the weather.replymahalex 13 hours ago | prev | next [\u2013]So, it's a thing that appends \"please format your response as the following JSON\" to the prompt\", then validates the actual response against the schema, all in a \"while (true)\" loop (literally) until it succeeds. This unbelievable achievement is a work of seven people (authors of the blog post).Honestly, this is getting beyond embarrassing. How is this the world we live in?replyjlnho 13 hours ago | parent | next [\u2013]It's because not everyone can be as gifted as you.I think the (arguably very prototypical) implementation is not what's interesting here. It's the concept itself. Natural language may soon become the default interface for most of the computing people do on a day to day basis, and tools like these will make it easier to create new applications in this space.replyEdes 12 hours ago | root | parent | next [\u2013]I'm gonna love trying to figure out what query gets the support chatbot to pair me with an actual human so that I can solve something that's off scriptreplyjlnho 4 hours ago | root | parent | next [\u2013]Ideally you would jutst click the \"talk to a human\" button, but what do I know?replyTeeWEE 5 hours ago | parent | prev | next [\u2013]Yeah it\u2019s basically a retry loop. I\u2019m curious about the average response time and the worst case amount of iterations.At best, all these \u201cretry until successfully\u201d are just hacks to bridge the formal world with the stochastic. It\u2019s just useless without some stats on how it performs.And even if it conforms. Your not sure the data makes sense. Probably .. but exactly that probablyI would not recommend using this in production.replylsh123 12 hours ago | parent | prev | next [\u2013]Hm... so how do we know that the actual values in the produced json are correct???replymahalex 3 hours ago | root | parent | next [\u2013]As with anything output by \u201cAI\u201d: you don\u2019t.replysiva7 13 hours ago | parent | prev | next [\u2013]One of the authors is Anders Hejlsberg, the guy behind c# and delphireplyrob74 3 hours ago | root | parent | next [\u2013]I think he's probably more of an author in the way that the leader of a research team is always credited on any paper by the team, even if he didn't personally do any actual work on it?Anyway, TIL that Hejlsberg is also involved with TypeScript...replymahalex 13 hours ago | root | parent | prev | next [\u2013]That\u2019s what makes it even more embarrassing.replykatamaster818 13 hours ago | prev | next [\u2013]Hang on, so this is doing runtime validation of an object against a typescript type definition? Can this be shipped as a standalone library/feature? This would be absolutely game changing for validating api response payloads, etc. in typescript codebases.replytehsauce 13 hours ago | parent | next [\u2013]maybe this function?https://github.com/microsoft/TypeChat/blob/4d34a5005c67bc494...replykatamaster818 13 hours ago | root | parent | next [\u2013]yup, just found that, super neat, I am 100% interested in using this for other runtime validation...It's interesting because I've always been under the impression the TS team was against the use of types at runtime (that's why projects like https://github.com/nonara/ts-patch exist), but now they're doing it themselves with this project...I wonder what the performance overhead of starting up an instance of tsc in memory is? Is this suitable for low latency situations? Lots of testing to do...replyjacamera 10 hours ago | root | parent | next [\u2013]Great point. They're against it unless you're running it in a loop and paying for every API call!replyabhinavkulkarni 3 hours ago | prev | next [\u2013]There already are techniques to guade LLMs into producing output that adhere to a schema. For e.g. forcing LLMs to stick to a Context-Free Grammar: https://matt-rickard.com/context-free-grammar-parsing-with-l...Just like many similar methods, this is based on logit biasing, so it may have an impact on quality.replyhuac 9 hours ago | prev | next [\u2013]I've written a version of this in Golang (tied to OpenAI API, mostly): https://github.com/stillmatic/gollum/blob/main/dispatch.goDefine a struct and tag it with golang's json comments. Then, give it a prompt and ...  type dinnerParty struct {    Topic    string  `json:\"topic\" jsonschema:\"required\" jsonschema_description:\"The topic of the conversation\"`    RandomWords []string `json:\"random_words\" jsonschema:\"required\" jsonschema_description:\"Random words to prime the conversation\"`  }  completer := openai.NewClient(os.Getenv(\"OPENAI_API_KEY\"))  d := gollum.NewOpenAIDispatcher[dinnerParty](\"dinner_party\", \"Given a topic, return random words\", completer, nil)  output, _ := d.Prompt(context.Background(), \"Talk to me about dinosaurs\")and you should get a response like  expected := dinnerParty{    Topic:    \"dinosaurs\",    RandomWords: []string{\"dinosaur\", \"fossil\", \"extinct\"},  }replycanadaduane 5 hours ago | prev | next [\u2013]\"Using Zod to Build Structured ChatGPT Queries\"[1] is a pattern I found useful. This doesn't seem too different.[1] https://medium.com/@canadaduane/using-zod-to-build-structure...replyrobbie-c 12 hours ago | prev | next [\u2013]This is funny, I have something pretty similar in my code, except it's using Zod for runtime typechecking, and I convert Zod schemas to json schemas and send that to gpt-3.5 as a function call. I would expect that using TypeScript's output is better for recovering from errors than with Zod's output, so I can definitely see the advantage of this.replytrafnar 15 hours ago | prev | next [\u2013]It's not clear to me how they ensure the responses will be valid JSON, are they just asking for it, then parsing the result with error checking?replyesafak 12 hours ago | parent | next [\u2013]Yes. https://github.com/microsoft/TypeChat/blob/main/src/typechat...replydavnicwil 14 hours ago | parent | prev | next [\u2013]seems like they run the generated response through the typescript type checker, and if it fails, retry using the error message as a further hint to the LLM, until it succeeds.replyanonzzzies 13 hours ago | root | parent | next [\u2013]I would expect that, if it doesn\u2019t do that even, why bother\u2026 that is also trivial to do anyway.replyverdverm 13 hours ago | root | parent | prev | next [\u2013]also some very basic prompt engineeringreplysandkoan 11 hours ago | prev | next [\u2013]Relevant: Built this which generalizes to arbitrary regex patterns / context free grammars with 100% adherence and is model-agnostic \u2014 https://news.ycombinator.com/item?id=36750083replygeysersam 10 hours ago | prev | next [\u2013]Anyone knows in what situations this approach is superior to jsonformer (https://github.com/1rgs/jsonformer) and vice versa?Or are they solving different problems?It seems jsonformer has some advantages such as only generating tokens for the values and not the structure of the JSON. But this project seems to have more of a closed feedback loop prompt the model to do the right thing.replyjensneuse 12 hours ago | prev | next [\u2013]This looks quite similar to how were using OpenAI functions and zod (JSON Schema) to have OpenAI answer with JSON and interact with our custom functions to answer a prompt: https://wundergraph.com/blog/return_json_from_openaireplyTillE 9 hours ago | prev | next [\u2013]I wish Copilot did something like this. I've found it'll regularly invent C# methods which don't exist, an error which seems trivial to catch and hide from the user. No output is better than bad output.replydavrous 15 hours ago | prev | next [\u2013]This is a fantastic concept! It's going to be super useful to map users' intent to API / code in a super reliable way.replyobiefernandez 10 hours ago | prev | next [\u2013]If I can use this instead of functions, it's gonna save me a buttload of API usage, because the Typescript interface syntax is so concise. Can't wait to try it.replyphillipcarter 13 hours ago | prev | next [\u2013]I'd love to see a robust study on the effectiveness of this and several other ways to coax a structured response out:- Lots of examples / prompt engineering techniques- MS Guideance- TypeChat- OpenAI functions (the model itself is tuned to do this, a key differentiator)- ...others?replyianzakalwe 12 hours ago | prev | next [\u2013]I am not sure why this exist, maybe I am missing something, and it does not seem like there is much value past \u201chey check this out this is possible\u201dreplyameyab 15 hours ago | prev | next [\u2013]Here's a relevant paper that folks may find interesting: <snip>Semantic Interpreter leverages an Analysis-Retrieval prompt construction method with LLMs for program synthesis, translating natural language user utterances to ODSL programs that can be transpiled to application APIs and then executed.</snip>https://arxiv.org/abs/2306.03460replybestcoder69 15 hours ago | prev | next [\u2013]Why this instead of GPT Functions?replyverdverm 13 hours ago | parent | next [\u2013]it's basically the same thing, but uses a more concise spec for writing the schema (typescript vs jsonschema)In the end, both methods try to coax the model into returning a JSON object, one method can be used with any model, the other is tied to a specific, ever changing vendor APIWhy would one choose to only support \"OpenAI\" and nothing else?replyyanis_t 14 hours ago | prev | next [\u2013]TL;DR: This is ChatGPT + TypeScript.I'm totally happy to be able to receive structured queries, but I'm also not 100% sure TypeScript is the right tool, it seems to be an overkill. I mean obviously you don't need the power of TS with all its enums, generics, etc.Plus given that it will run multiple queries in loop, it might end up very expensive for it abide by your custom-mage complex typereplynchase 9 hours ago | prev | next [\u2013]this is going to create space for some hilarious and funky input attacks.replynurettin 8 hours ago | prev | next [\u2013]This is rather trivial. The real challenge would be to make it choose what type to return. The function api does that, but then natural conversations sometimes involve calling multiple functions, and there isn't a good schema for that.replygigel82 9 hours ago | prev | next [\u2013]I agree with comments saying this is basically a 10-line \"demo script\" everyone could write and it is weird to have big names associated with it.But I heard from MS friends that AI is an absolute \"need to have\". If you're not working on AI, you're not getting (as much) budget. I suspect this is more about ticking the box than producing some complex project. Unfortunately, throughout the company, folks are doing all kinds of weird things to tick the box like writing a \"copilot\" (with associated azure openai costs) fine-tuned on a handful of documentation articles :(replyarc9693 13 hours ago | prev | next [\u2013]TL;DR: It's asking ChatGPT to format response according to a schema.replyrvz 15 hours ago | prev [\u2013]Someone should just get this working on Llama 2 instead of O\u0336p\u0336e\u0336n\u0336AI.com [0]All this is it's just talking to a AI model sitting on someone else's server.[0] https://github.com/microsoft/TypeChat/blob/main/src/model.ts...replyDanRosenwasser 14 hours ago | parent | next [\u2013]Hi there! I'm one of the people working on TypeChat and I just want to say that we definitely welcome experimentation on things like this. We've actually been experimenting with running Llama 2 ourselves. Like you said, to get a model working with TypeChat all you really need is to provide a completion function. So give it a shot!replyjoelmgallant 14 hours ago | parent | prev [\u2013]The most recent gpt4all (https://github.com/nomic-ai/gpt4all) includes a local server compatible with OpenAPI -- this could be a useful start!replyGuidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
    "hn_summary": "- TypeChat is a library developed by Microsoft that allows developers to interact with language models and receive structured JSON responses.\n- It focuses on ensuring that the responses conform to a predefined TypeScript schema, providing type-checking and validation.\n- The library simplifies the process of working with language models and eliminates the need for manual parsing and validation of responses."
  },
  {
    "id": 36798854,
    "timestamp": 1689850359,
    "title": "The past is not true",
    "url": "https://sive.rs/pnt",
    "hn_url": "http://news.ycombinator.com/item?id=36798854",
    "content": "from the book \u201cUseful Not True\u201d:The past is not true2023-07-20When I was 17, I was driving recklessly and crashed into an oncoming car. I found out that I broke the other driver\u2019s spine, and she\u2019ll never walk again.I carried that burden with me everywhere, and felt so horrible about it for so many years that at age 35 I decided to find this woman to apologize. I found her name and address, went to her house, knocked on the door, and a middle-aged woman answered. As soon as I said, \u201cI\u2019m the teenager that hit your car eighteen years ago and broke your spine\u201d, I started sobbing - a big ugly cry, surfacing years of regret. She was so sweet, and hugged me saying, \u201cOh sweetie, sweetie! Don\u2019t worry. I\u2019m fine!\u201d Then she walked me into her living room. Walked.Turns out I had misunderstood. Yes she fractured a couple vertebrae but it never stopped her from walking. She said \u201cthat little accident\u201d helped her pay more attention to her fitness, and since then has been in better health than ever. Then she apologized for causing the accident in the first place. Apologized.I said, \u201cWell, no, it was my fault for ignoring the yield sign.\u201dShe said, \u201cNo, it was my fault because I was eating while driving and not watching the road. You didn\u2019t hit me. I hit you.\u201dSeems we had both thought the accident was our fault, and had spent eighteen years feeling bad about it. This time she started crying, sniffled, grabbed a tissue to wipe her eyes and said, \u201cIt\u2019s so stupid - these stories.\u201dAim a laser pointer at the moon, then move your hand the tiniest bit, and it\u2019ll move a thousand miles at the other end. The tiniest misunderstanding long ago, amplified through time, leads to piles of misunderstandings in the present.We think of the past like it\u2019s a physical fact - like it\u2019s real. But the past is what we call our memory and stories about it. Imperfect memories, and stories built on one interpretation of incomplete information. That\u2019s \u201cthe past\u201d.You can change your history. The actual factual events are such a small part of it. Everything else is perspective, open for re-interpretation. The past is never done.photo by Ashley Jonathan Clements\u00a9 2023 Derek Sivers.Copy & share: sive.rs/pnt",
    "summary": "- The author shares a personal story about a past accident and how it affected both their and the other driver's perspective.\n- The story highlights the importance of understanding that the past is not always an accurate reflection of reality.\n- It emphasizes the idea that memories and stories about the past are subjective and can be reinterpreted, allowing individuals to change their history.",
    "hn_title": "The past is not true",
    "original_title": "The past is not true",
    "score": 402,
    "hn_content": "- The article emphasizes that our perception of the past can change over time.\n- The example given is about a man who believed he had paralyzed a woman in a car accident, only to find out years later that she was not permanently disabled.\n- The man's story shifted as he learned the new information, highlighting the malleability of our narratives.\n- The lesson is that we should be open to revisiting and reevaluating our past experiences based on new information.\n- The article encourages self-reflection, acknowledging the impact our actions can have on others and the importance of making amends when necessary.\n- It also touches on the concept of forgiveness and the idea that some actions cannot be undone or forgotten.\n- The article challenges the notion that the impact of our actions may not be as severe as we think, asserting that we should take responsibility for the harm we cause.\n- Ultimately, the most important message is that we have the power to change how we perceive and engage with our past experiences.- The post discusses the concept of memory and how it can be fallible and subject to interpretation.\n- The author shares a personal story about a car accident and the guilt they carried for years, only to realize later that their belief about what happened was incorrect.\n- The post highlights the importance of seeking out the actual facts and not relying solely on personal interpretations or beliefs.\n- It suggests that history is not a fixed truth, but rather a collection of narratives and interpretations.\n- The author encourages readers to question their own beliefs and interpretations and to be open to changing their stories based on new information.",
    "hn_summary": "- The article emphasizes the malleability of our narratives and encourages revisiting and reevaluating our past experiences based on new information.\n- It highlights the importance of seeking out the actual facts and not relying solely on personal interpretations or beliefs.\n- The post encourages readers to question their own beliefs and interpretations and to be open to changing their stories based on new information."
  },
  {
    "id": 36800151,
    "timestamp": 1689859796,
    "title": "Accidentally Load Bearing",
    "url": "https://www.jefftk.com/p/accidentally-load-bearing",
    "hn_url": "http://news.ycombinator.com/item?id=36800151",
    "content": "- Understanding the original purpose of a system or component is important when making changes.\n- However, it is equally important to consider any additional roles or purposes that it may have taken on over time.\n- Complex computer systems often have a change history and original design documents which can provide valuable context.\n- It is essential to consider how a component integrates into the system today and the potential consequences of making changes.\n- Different development teams may have varying approaches to making changes to software systems, such as using flags and A/B testing.\n- Testing is crucial in identifying issues and ensuring changes do not break the system.\n- It is common for developers to lack knowledge about why something was implemented in a certain way, but it is possible to learn and adapt.\n- Some developers work in environments with legacy untested code that lacks automated feedback mechanisms, making changes more challenging.\n- Documentation and logging can play a crucial role in understanding the purpose and impact of code changes.\n- It is important to strike a balance between understanding the original purpose of a system or component and considering its current state and role.- The concept of \"accidentally load bearing\" applies not only to physical construction but also to complex computer systems.\n- Understanding the original purpose of a component is important, but it's equally important to consider how it currently integrates into the system.\n- Tests are crucial in software development to ensure that changes do not have unintended consequences.\n- Documentation, such as comments and commit messages, can provide valuable context for understanding the rationale behind certain decisions.\n- Good test coverage and monitoring tools can help catch issues before they become critical.\n- Over time, dependencies can form between components, making it difficult to remove or change them without affecting other parts of the system.\n- Through a combination of testing, documentation, and analysis, developers can mitigate the risks associated with accidentally load bearing components.\n- In some cases, software developers may choose to transition into security consulting for better career opportunities and higher salaries.\n- The importance of good testing practices and robust QA processes cannot be overstated.\n- It's crucial to have clear design requirements and specifications, as tests alone cannot capture all aspects of functionality.\n- Organizations often face challenges in maintaining tests and ensuring their accuracy as systems evolve over time.\n- Automated tools could potentially assist in capturing the context and rationale behind system components, aiding in the understanding and maintenance of complex systems.",
    "summary": "- Understanding the original purpose and current role of a system or component is crucial when making changes to complex computer systems.\n- Testing, documentation, and analysis are essential in mitigating the risks associated with accidentally load bearing components.\n- Good testing practices and robust QA processes, along with clear design requirements and specifications, are crucial in ensuring system functionality and accuracy over time.",
    "hn_title": "Accidentally Load Bearing",
    "original_title": "Accidentally Load Bearing",
    "score": 398,
    "hn_content": "- The post discusses the importance of understanding why certain code exists in software systems.\n- It highlights the need for documentation and comments to explain the rationale behind code decisions.\n- Examples are given of how code comments can provide valuable context for future developers.\n- The author emphasizes the importance of trust in coworkers and the need to consider the intentions behind code before making changes.\n- The importance of thorough testing and monitoring tools to catch any potential issues is mentioned.\n- The concept of accidentally load-bearing code is compared to physical structures where a component takes on more responsibility than intended.\n- The author suggests that automated systems could help generate documentation based on the context of code changes.- Complex systems often require explicit explanation or external design documents to ensure understanding and prevent unintended side effects.\n- Consulting with developers can help unwind the effects of years of patches to make safe changes.\n- Walkthrough analysis during code alterations helps uncover unintended side effects, ensure design requirements are met, and discover non-obvious relationships.\n- Documentation, such as diagrams or tests, is crucial to understanding the why and what of code changes.\n- Uncovering the original intention of a code component can aid in evaluating its necessity.\n- Sometimes, removing a component is the best way to understand its purpose and impact on the system.\n- Accidentally load-bearing components in software can cause unexpected failures and challenges in refactoring.\n- Understanding load-bearing components is analogous to understanding the structural integrity of a building.\n- Accidental load-bearing components can arise due to changes and dependencies in the system.\n- Building software with minimal components and avoiding unnecessary code can help prevent accidental load bearing.",
    "hn_summary": "- The post emphasizes the importance of understanding the rationale behind code decisions and the need for documentation and comments to provide valuable context for future developers.\n- It highlights the significance of trust in coworkers and considering the intentions behind code before making changes.\n- Automated systems could potentially help generate documentation based on the context of code changes, preventing unintended side effects and challenges in refactoring."
  },
  {
    "id": 36804710,
    "timestamp": 1689878128,
    "title": "IRS moves forward with a new free-file tax return system",
    "url": "https://www.pbs.org/newshour/politics/irs-moves-forward-with-a-new-free-file-tax-return-system-that-has-both-supporters-and-critics-mobilizing",
    "hn_url": "http://news.ycombinator.com/item?id=36804710",
    "content": "",
    "summary": "- The IRS is implementing a new system called free-file tax return, which allows taxpayers to file their tax returns for free through selected online platforms.\n- The new system aims to simplify the tax filing process for individuals and ensure they have access to reliable resources to complete their returns accurately.\n- Taxpayers need to be aware of the eligibility criteria and choose the right online platform to take advantage of the free-file tax return system.",
    "hn_title": "IRS moves forward with a new free-file tax return system",
    "original_title": "IRS moves forward with a new free-file tax return system",
    "score": 390,
    "hn_content": "- The IRS is moving forward with a new free-file tax return system.\n- Intuit, H&R Block, and other tax preparation companies have spent significant amounts on lobbying to prevent the development of a government-run tax filing system.\n- The spokesman for Intuit argues that an IRS direct-to-e-file system would be redundant and costly to implement and operate.\n- Some commentators suggest that an IRS direct filing system could be efficient and effective, potentially saving taxpayers money.\n- Many individuals express frustration with the current tax system and complicated tax filing process, including issues like incorrect tax assessments.\n- Some readers mention the simplicity of tax systems in other countries and express a desire for a similar approach in the US.\n- The debate over tax complexity centers around the trade-off between simplicity and tax deductions, with some arguing that reducing complexity should be accompanied by tax cuts across the board.\n- Suggestions for tax reform include providing taxpayers with pre-filled forms that include known financial information, minimizing the need for external tax preparation services.- The post discusses the potential for the IRS to develop a free e-file software that would pre-fill standard tax information, similar to systems already in place in other countries.\n- Some commenters express skepticism about the government's ability to create a user-friendly and cost-effective system, while others are hopeful for the potential benefits.\n- The existing complexity and size of the US tax code is mentioned as a barrier to easy tax filing.\n- The post references previous discussions on HN about tax filing systems, lobbyism, and the potential impact on tax preparation companies.\n- Critics argue that the system may not cover more complex tax situations involving investments, rental income, or non-US income, while others highlight that much of this information is already automatically filed with the IRS.\n- The potential for reduced reliance on tax preparation companies is mentioned as a positive outcome of a government-developed system.\n- The post also touches on broader political themes, such as campaign financing and lobbying influence.",
    "hn_summary": "- The IRS is implementing a new free-file tax return system despite lobbying efforts by tax preparation companies like Intuit and H&R Block.\n- Some commentators believe that an IRS direct filing system could save taxpayers money and simplify the tax filing process.\n- Suggestions for tax reform include pre-filled forms and reducing complexity in the tax code."
  },
  {
    "id": 36799548,
    "timestamp": 1689856231,
    "title": "Anytype \u2013 local-first, P2P Notion alternative",
    "url": "https://anytype.io/?hn",
    "hn_url": "http://news.ycombinator.com/item?id=36799548",
    "content": "",
    "summary": "- \"Anytype\" is a new software that works like a popular app called Notion.\n- It is special because it is a local-first and P2P alternative to Notion.\n- It allows users to store and organize their information offline on their own devices while also collaborating with others.",
    "hn_title": "Anytype \u2013 local-first, P2P Notion alternative",
    "original_title": "Anytype \u2013 local-first, P2P Notion alternative",
    "score": 371,
    "hn_content": "- Anytype is a local-first, P2P alternative to Notion, a note-taking app.\n- It has many of the features of Notion, but also offers some improvements.\n- However, without features like sharing and collaboration, it is in a smaller market compared to other similar apps.\n- Google Docs has solved E2E encryption with safe sharing and collaboration, but it has limitations like disabled grammar check in encrypted documents.\n- People are discussing the idea of operating systems providing spellcheck to textboxes everywhere.\n- Users are discussing the importance of interconnectivity and compatibility between software applications.\n- Some users are interested in self-hosting options for Anytype.\n- There are discussions about the definition of \"open-source\" and whether Anytype's license qualifies.\n- Users have questions about the functionality and purpose of Anytype.\n- The UI and landing page design of Anytype are receiving mixed reviews.\n- Users are interested in the security and privacy features of Anytype, but also express skepticism.- The post discusses the concept of \"source available\" licenses and how they differ from traditional open source licenses.\n- The Anytype project is mentioned as an example of a software using a \"source available license\".\n- The debate centers around the use of the term \"open source\" and whether it accurately describes software with source available licenses.\n- The importance of clear definitions and terminology in the open source community is highlighted.\n- Readers unfamiliar with the nuances of open source licensing may find this discussion informative and thought-provoking.",
    "hn_summary": "- Anytype is a local-first, P2P alternative to Notion, offering similar features but with some improvements.\n- Discussions revolve around the challenges of sharing and collaboration in Anytype compared to other similar apps like Google Docs.\n- The debate focuses on the definition of \"open-source\" and whether Anytype's license qualifies, highlighting the importance of clear definitions and terminology in the open source community."
  }
]
