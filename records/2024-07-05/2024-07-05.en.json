[
  {
    "id": 40877337,
    "title": "Batteries: How cheap can they get?",
    "originLink": "https://aukehoekstra.substack.com/p/batteries-how-cheap-can-they-get",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"aukehoekstra.substack.com\",cType: 'non-interactive',cNounce: '20649',cRay: '89e99b564a3afaaa',cHash: '98641a127bcf8f7',cUPMDTk: \"\\/p\\/batteries-how-cheap-can-they-get?__cf_chl_tk=InmKQOaUulPcNzdVbm_tWB.ZSEaKxzRHxOOvxLZuxV4-1720206119-0.0.1.1-3732\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '120000',cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/p\\/batteries-how-cheap-can-they-get?__cf_chl_f_tk=InmKQOaUulPcNzdVbm_tWB.ZSEaKxzRHxOOvxLZuxV4-1720206119-0.0.1.1-3732\",md: \"rWh_szM.g9J3U6kXdf5SDIDoyESoKmsqCifkCKazYe8-1720206119-1.1.1.1-rpiJ_9IVEzdPt0Fj.mbzMWgZckX2MVrnXDUrve5HL8pRqyfUpUQft_bbBnhtvmHwHra5tEshcQlxeFr2WfSOszmFQG7fjTJyL5Pp0TnfQ8JnbP3OiAb.80HW8I0TJU9mjvsg1wcrdU7W80YRq2mG_3xOXw1QCrVyk35BW8hPDA4bJ1Wuh_vrSvgdj0mq9k8awr4C7GiGlm1Yrzd1JhQkfCU02xnUqZo82x31r71ssM3KqzwBwIWy5Fq1CR_PDz2PjNBDP3t7onxBN.asJu_dy5Lde0xPpMXMlBhXS0e5kNlIWg67VRwbnAnyQ6mY1qq1NtZvjJAKN5Xi2cPaRUkUCEKXyMV3KgD5H4zU9acexN4HSdMojIBo7xKIs_.nuPOWZAXva3U_26o7B2tEiDUTWaUksGDHZ3yo4j7xOBf4RN8YOshgpLmssSgfANo_fEDV0ylNhW9Az47ThE5JOIz.heEeDtzYYLxQCDUKb2XiKbuJTgGwOrmbEajxr9ByAGe91QMeq0f_CfLzCm.5iUcpI_IJzBnKb4obd4mzkYDMuSak.UYCYeqywuh0vLVoVqyBEw67HblgAs8yTTwLP29_kLSLBF__cEmD8A3sg4PaoLjreK6NdEF123CLi5Dd4M1PsGU7QYLRGc.JhPY3vyOzJda.UlcapNeIyRiW0k64DQfCK0XNi35bEIXtPA_nSc8D53WwHozZ2Vp3cEIrejsHPNhOXlvpeCFvyoYaibYuGkp2_vjTuO2AZe4idpRlv_SM1QUmnUW7JvIEYOqHenza7yf4D3lPPe8_uosAt342F8PH2iSx0WC5BS0rI9q3H.7j9T8egsJVm07c_DIk_HLFj.pCUaJOYKgcT6v1Uvwwn.avIQCjHRViBfzCsiYWt1y4yOvgVcF_w.vMUlkmR5Vep_Ep9gufq8EzfpVkdcQnrEu8jaqZSr8vlhx_kPTRz8UTYIsXqNpNnvI.U1jmBme_puNt9lAd_bvdbofAzU492ETcIQucyXvUxiFKwUb5TriLRQaGkdyIQBkOmUJO1y6f3vidG.hQdARQQJr2bEo2zYOMuMCtGfnwwDE6fSLq3Hf5q49KjpDSkwMTr1pgOAP537ZRx01sLxW2MVLjUCV.Hqo9E6tpF2rV43hwYW8yXOyKgg38T8M1x.ltLAaUMZDw5qp8p06YYOUladFQRhmvkzP4loWH9_P2NW24FQ68OQBXsndrSRbqh8RaYLoQWGcBWw8bU5OaxjsCiV.4S2B.2mA\",mdrd: \"m_UVvtjkyR8.jQUiONA3T1DkawdZhS4NSwbOflsVq7M-1720206119-1.1.1.1-ik.q2fNY2Jgdz.6nmJDxX9docdJGLE5zwOB3c_s_.V_PzYRp2BbIHFr3Qj9THivxnOE5_P3egrNULS2jhxr2h54P05gMU_dULs1sXbCYUNJqt.._E2VUs_Gq1uxJ3IQTEkNIQ4C2q1eDqYel8c1Qs_0k_iXVIhAHi0HMYuUwTEepBhIw9Oi3JBefw6mKW.sIBhatofczRl0vd9xZkkfCxsCTIIiMwBk43ohev_H0tC7dDHgxankWlkNmD5D2gyvJVpib2jJpsS5AfvoRqJw_7da0NWXCYRqup160sqlCCb8O7BhicuxBf9JXTrb6M0LuTDOPPZXXrxhXxHDXgDvQh6bQ9YBOhS1Gl0VANVu0ScPbJHUn.qwOj8TsDoRCDNMqMVfIqMwqmj7M..2J9U9sZbH24h3OIkpf5.L7rFy1gmCa7PzTzGTcNNbJtgkbW70W2JlOi3snLY2mqLHFssrSZhxWsUM2uRgY_doTXsMBbRp_yC5ug_8Jp6PASvV60NXyJOIHYvrEo91BekyTABoxz7.JYWBqREicVVGVdydpGuWZklUnnlpYdGSm9bOE7.XNPgXPvRvz52.iycfQPEbjPPoivq6ml5E2BTyE77DjkeoX.syB7xbJF4okCvBN_R9JRZfLmcEBUcZJ1xUaaQXtXs_sxFGyY0Xug0ZlYEPyLT_A86why6c8LoysNT6I2FTYgqrj6byqLywAqZ.M2wndTSrp.ncNcAnsBhcD2.h6xA8WKNHv.Xf8wOvuqROgduoIhvEh_iSWE8hw.allTQcikJyfeyLpIOz4unktOV7bj.oSQjceXgS8GPj5oF6K2XI1zeRfQHhyBYiY_5.FUd4fy6aZv8nfu52w.oKpz9D4XptaLk5BKo2MxaFsJ5w0Efkf1P15.Lzwy22xEvcC06nU7Nxuj0HglV9HttcBlNPdYH9zKXTu6lQW6tsq8Xpe7_5h0mromksqX_XA_XaVqSXC.VzRUuZPnHBEAMP5rVIsQe6TfhcW70tXQKFK.7103sKirKibFY7iEXSrCA7PJZU3hUaf1QWDSof93W5nMgXGSLuy5Us2rPaVh2ioA23okBz9c7d8HkVFRSbXqD4Y5PwzRaDxnMuExEDea4iiltuC6CLGCBSniFnVmwUMJnp5GYOqhCQRWdgLYpINllxdQjs0_xqAhw2bCoKiGkEbLdqlwaN_NVZcnoZWg493v8Lbh1sn1K4BHaaEq0qfkVFZ2HBMC7Pr41pGTpoNWPXQd.idsuUKKe.M6IomTg24oYp9CTpX6PwgjTFMWJu4H9yt6JXSQeae5.qw9shhdpr2txR5TT3fc_xuDVAbPXvKzGPmiM8T7Y4bHx8dFUSVzUdPBEykuN6ohJQrAgAxmgbagacry5epy.UButCwyOWKYXPfLsAhUnjeWo0X_1Vv_YGhwk134TWnclm2YD4clOCA8ax3PEs00Z0TonbtcUVwO7SLQOV2FPhqegGlBY5DKCwTrrgOQOJn_BSMe61f20TZttupzIvUlLmh24sso.X7V9taDx2qmsMso4JMF_zxcLO9E3LfgX65zuW2HZxOUYGWz0bF6dzx7qXUT7F3febdOb1L6A.Gx3Gb4StYfkfWlkgjP7JEsfjw68iDTsKMG.Ak5rZfsSyh.ld64UoAZoT0P.UFbZcHSfs67_QnhbfNkfc0.80SsKRbgqle4yglUUiDq.OeYJlIi1sbNDvVGmXwwXUN9xkWLiw2vGonHhTZbgKanoRK0qjObbHcuh1LKQJwiL9UsV7QAoTjcCKgH00vuTKmwh.OSAQ8o5NEE5UQrx2ZK7q6rLmU8X4II2Wl_Ot0jznCpey9UfNwXRpH1NyiXiEMaZzS6l7CsXxcOGUeS8Q7DcxAR_Uy6atSTriFW31.Jq4XCcvs0PIVDXlQZGN9ocTGaDwZfVvoQhZvnDE5Z.vX3qx170of1tSayT1ao7O2fmM0Lcti9VGQB87BLxvSMj9oSO3I_F2iYhzCHJpVnYY6RMFYyNVWzPedfSpRVn8WQKPF3hpXjVIXAfm4_LR0NaeODpoYNNHd98EQq.uT7HTwGCtYzChmfKiHLNvHoedj8jPf11mlwHG1Wmc2LjaanSkHflXOFVwvtf0xVjHughp64Saodk_mHQLNCJPiZJewQTl0d.vUBYu3uNIH0mPFEDqLKRFRZbniWaJXnmg8Vb5pEDf3JZUF2JXw7Oxx8zGZBvnPvyfySedDttHiXrheauFdd3OmJRR3_6pz4yd5hyBQcy.ogL4H1H8C.6ArOIcpZHMkiIYYP6SdDw_tifEt8u6a1sI54bq6WREAzyJafgmCtb6hsxvSG2tPcob5_ayRxFc6UV4\",cRq: {ru: 'aHR0cHM6Ly9hdWtlaG9la3N0cmEuc3Vic3RhY2suY29tL3AvYmF0dGVyaWVzLWhvdy1jaGVhcC1jYW4tdGhleS1nZXQ=',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: '0mOBcxoqlIhcyxV7LIkO2rud6hzR127IK+TCHvtwchqabuuqMFt/TpW8WNgWYaBwDjElsIRizI5pPhiikjSfg8+Dth9fPvKPwtOYvKC2ffGTDEayls0FGv8XnUE3qqu5kAoLvg+hf7Pl4b/QpY9640FwJvfa4OC+i+JzF33ATqvxB/OIEkYlesA0latjjxQ0QMUEFIcPAMpI/KX07qZMIjNRt2YCgf1C/J4kT5KSpZMYV5z7XeCL6CEpgXJ/OqqDwKNJk0MN40kG2Vt7vRwIgs2HPZ0FVXHN9lrRCABXtApYUtIcEWD1PmzdTbmdkuHbrrNMEOnbGiGQZXbeH2/DYHey38BTYoRapGHHdUMC5cxvqwVkkBVvgbP2F9CBq0+023HwNNnytt/3tOorN2rINF8U6iLHuxQOn7rRKMaEckulMkg8iVHz1b/6UyMv6VQBbgnyEtvMxmtdLxggK1C5TuPP6AZvLOyA2x+B1ZIm9gNEGDS/6FCmuCbX3BJ5LooobhB/HS90Ej5vhK35e9u+aQ==',t: 'MTcyMDIwNjExOS4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: '/rX8Bc8HhSWTzHR7Z5KgPUDeYNrGzOlpt8s6bO09WRQ=',i1: 'XpQm62F6KbY+grLeAEqk0w==',i2: 'GxX9SNhEEY2oWs+FcUh9iQ==',zh: 'o01jypKJQ++/gkxUTvC40nYpXBhuMc66cm0hd/Tc920=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'nmgk7wRXBgon5zXNwdTF1tEstqq1Qf2tKkBKjNnrL70=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=89e99b564a3afaaa';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/p\\/batteries-how-cheap-can-they-get?__cf_chl_rt_tk=InmKQOaUulPcNzdVbm_tWB.ZSEaKxzRHxOOvxLZuxV4-1720206119-0.0.1.1-3732\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=40877337",
    "commentBody": "Batteries: How cheap can they get? (aukehoekstra.substack.com)276 points by hoerensagen 23 hours agohidepastfavorite268 comments duffpkg 22 hours agoLifepo4 (lithium iron phosphate) batteries for the home are pretty cheap as of today. Power storage for residential use in a 48v metal rackable linkable system with battery management system (BMS) is $89/kwh shipped/duty paid from reputable chinese suppliers CATL/Seplos etc. You have to wait for sea shipping, add $30/kwh if you want to buy it in the US today. From the same suppliers sodium batteries are currently $130/kwh and about 26% less efficient in the same form factor. I look forward to this changing. Due to rising power costs I moved one of my homes completely to solar and battery (lifepo4) and haven't had any problems. I can't imagine ever going back to the power company. Panels have gotten to the point of being ridiculously cheap. I have a lot of space. I purchased pallets of used panels for more or less the cost of transportation ($34 per panel 270w). They produce about 85% of their nominal rating. I mention this because other comments mention costs that are much much higher. reply blacksmith_tb 22 hours agoparentSounds great, but are there actual businesses who will come to your home and do an install, or do you need to to become a mad-scientist electrician and DIY? I got quotes on getting an LG system a few years ago and it was 4X these prices (also for me a problem is that my 'ancient' panels from 2013 use a single inverter instead of microinverters, so if I touch the system I have to replace it all). I keep hoping there will be a bunch of small businesses electrifying everything, I'd love to see - good, practical, safe - EV conversions driving around too, but it just doesn't seem to be materializing. reply duffpkg 22 hours agorootparentAll of the quotes and interactions I had with the local solar installers were reminiscent of the used car lot if not outright fraud. I was able to do what was permissible myself and a regular licensed electrician did the rest. The equipment is UL listed. There was some learning curve but I found the diysolarforum.com to be a pretty good resource to learn what I didn't know. I ran the whole setup standalone for about 6 months before switching the house over to it. The only problem that happened was a loose battery cable connection which the BMS and inverter alerted to and handled correctly. reply iamthemonster 19 hours agorootparentThis approach may vary by country. Not a single sparky in Australia will sign off on someone else's solar/battery install. reply fouc 18 hours agorootparentIsn't there a distinction between the house wiring and the solar/battery stuff? P.S. I've never heard of sparky being used as slang for an electrician, sounds very aussie. reply selcuka 18 hours agorootparent> P.S. I've never heard of sparky being used as slang for an electrician, sounds very aussie. When I moved into a new house in Australia I asked the real estate agent if I could extend the fence, and he said I'd need a cheapie to do that. I said ok but scratched my head as to why it needs to be cheap, only to find out later what he actually said was chippy, slang for a carpenter. reply marcus_holmes 16 hours agorootparentChippies are also known as \"wood butchers\" apparently. Amused me ;) reply unwind 11 hours agorootparentprevWhy, though? Is there some kind of requirement that only fully trained carpenters can build fences? reply roygbiv2 10 hours agorootparentJust about everything in Australia needs a license to do. Even down to network cabling. reply gambiting 7 hours agorootparentThe rule is - if it's going inside the wall, only a licenced electrician can do it. Yes it also extends to things like speaker or HDMI cables. It's mad. reply whatevaa 1 hour agorootparentHDMI cables? Sounds like protectionism. Invent rules to make yourself more work. reply LorenPechtel 1 hour agorootparentAren't there power delivery versions of HDMI? I can understand requiring a license for any power wires behind walls. I could also see the possibility that it's just an old law that doesn't consider data-only cables which don't have the safety issues that wires carrying power do. reply qubitcoder 5 hours agorootparentprevMad, indeed. It's hard to imagine those rules are followed, especially for speaker wires and HDMI cables. reply Scoundreller 13 hours agorootparentprevNext you’ll need a roofie reply old_hat 17 hours agorootparentprevYeah, it's all fun and games until you're at Macca's and someone says, \"Oi, can you pass me a chippy?\" and they get real confused when you go find a carpenter. reply soci 13 hours agorootparentprevin Spain we call them “chispas”, which literally means sparks. An electrician is someone who knows the home electrical wiring stuff, while a chispas is someone who is skilled in repairing home appliances. reply happymellon 12 hours agorootparentprevWe use sparky in the UK for an electrician too. reply lelanthran 11 hours agorootparentprev> P.S. I've never heard of sparky being used as slang for an electrician, sounds very aussie. I'm surprised to find out it's aussie slang; I always thought it was slang local to South Africa :-/ reply Lio 9 hours agorootparentWe say the chippie in the UK too. We also use sparkie for electrician. reply SideburnsOfDoom 4 hours agorootparentprevIt's local to UK and more recent British colonies ZA and AUS included. USA less so. reply throwaway81523 18 hours agorootparentprevSparky=electrician is common in the US too. I had previously thought of it as meaning a radio operator e.g. on a ship. reply nicoburns 18 hours agorootparentprevIt will, but I suspect this will get a lot easier everywhere as more of the problem gets packaged as units that you can just buy off the shelf (and the prices of such units come down). reply grecy 18 hours agorootparentprev> All of the quotes and interactions I had with the local solar installers were reminiscent of the used car lot if not outright fraud. I had exactly the same experience. They absolutely would not tell me the actual system cost, only how much I would save on my current bill per month. It felt exactly like a car salesman only talking about monthly payments, and it was horrible. reply LorenPechtel 50 minutes agorootparentYeah. Talked to a couple of solar companies. They were utterly focused on costs vs utility costs and very opaque about how that was being modeled. And it was based on the rules back then--which of course could not hold. Net metering is a huge subsidy that is already being walked back. The true value of solar or wind is the cost of the fuel it saves. Nothing more. Even if his numbers come true there's a big problem--bad weather could deplete your batteries. You want to turn to the electric company in that case? You are once again in the situation that the value is only the fuel. reply lazide 15 hours agorootparentprevYup. I’ve (US) also talked to a few local ones to just see if they had a couple panels I could buy off them for close to wholesale for a personal project - which if they were actually involved in installation would be trivial - and just got blank stares. They were clearly just doing lead generation for some other company they had no direct connection with, and didn’t even have any idea who to talk to that could even answer my question. I had way better luck just looking online and paying shipping, which is absurd given how they were presenting themselves. So not even as good as a used car salesman on an actual car lot, more like door to door used car salesman. reply Workaccount2 4 hours agorootparentThese companies are the equivalent of people who received a free product to review and then post a referral link for it in the details. Of course, they glow about how amazing the product is and how you should drop everything and buy it. reply GaggiX 21 hours agorootparentprevWhat voltage are you running your solar strings at? I was wondering what would happen if the loose cable was a cable from the solar panels instead of the low voltage battery. reply cyberax 20 hours agorootparentIf you want a DIY-friendly option, it's best to look towards DC optimizers. They are installed on each panel and they provide a steady 48V output. They also do MPPT tracking on the panel level, so you get the best possible performance if you have some shading. Unlike microinverters that are notoriously unreliable, DC optimizers so far have excellent long-term reliability. reply nanomonkey 11 hours agorootparentAre you suggesting using a DC Optimizer from your solar panels to charge 48V batteries directly? This would be interesting. It's the first I've heard of optimizers being used for anything other than prior to an inverter. reply cyberax 1 hour agorootparentYou absolutely can do that. You still need a charging controller and a BMS, obviously. But you can avoid the AC round-tripping. reply duffpkg 21 hours agorootparentprevThe panel strings are at ~500v so there are safety, fusing and grounding considerations. Pretty common electrical equipment and cable is rated for use at 600v. There are special locking water resistant connectors for solar panels called MC4. reply GaggiX 21 hours agorootparentAre the hybrid inverters you are using be able to detect arc faults (in series) from the strings? Running 500V DC is probably by far the most dangerous thing in your setup, fortunately your solar panels are mounted on the groud. reply derefr 3 hours agorootparentprevYou might need to DIY, but \"mad scientist\" is doing a lot of work in your statement that I don't think applies. You just need to follow some very-thoroughly-detailed online tutorials. It's one of those things like baking, where as long as you're good at faithfully following directions, everything turns out great. > I keep hoping there will be a bunch of small businesses electrifying everything There are a few of these per large city; but they serve companies with large budgets for \"becoming carbon negative\", not residences trying to do things cost-effectively to lower their electric bills. reply nuancebydefault 2 hours agorootparentI really like the baking analogy! I've installed a set of 10 PV panels with full electric installation including optimizers myself, and in fact the hardest part is finding out which mechanical adaptor parts fits your type of roof, which screws to use etc. The rest is following recipes indeed. reply Ayesh 21 hours agorootparentprev> do you need to to become a mad-scientist electrician and DIY? I did my own a couple years ago, and it worked quite well on the first go. I got someone else to build the LiFePo4 battery pack (16 CATL cells for 48v with a JK BMS). It was fairly easy to build. Mount panels on the roof, and wire everything (PV, battery, grid electricity if you want it, and the output) to the inverter. I added some extra steps to monitor usage and output, and a smart MCB. I also have a small shop that I can feed from solar power if the battery is almost charged and the sunset time hasn't reached yet. See if you quotation is to export electricity to the grid. Those kinds of setups usually require a certified company to do the installation (to make sure the inverter syncs with the grid), but for off-grid setups, you can definitely DIY. reply Aurornis 21 hours agorootparentprev> but are there actual businesses who will come to your home and do an install, or do you need to to become a mad-scientist electrician and DIY? A lot of the costs of a real install come from the permitting, doing proper upgrades (you might need a new electrical panel), the warranty, the labor, and other costs. Every time I browse the DIY solar forums it feels like I see 1 person doing things by code for every 10 people cutting corners or playing loose with the rules. YMMV, but take the DIY cost estimates with a huge grain of salt. reply T3OU-736 21 hours agorootparentprevYou do not necessarily have to become all these things. There are whole communities around this sort of a thing - Will Prowse's DiY Solar Forum (https://diysolarforum.com/) is an awesome source for learning as an example. The setup you describe - lacking microinverters - I think there are options there short of wholesale replacement [disclaimer: I, too, am a self-taught in this field, and so am likely wrong in non-trivial ways] reply ChumpGPT 18 hours agorootparentprevIf you're in the US, I don't think you need to pull a permit if it's not on your house. So you could build a small installation in your backyard and hook it up without too much trouble. This channel on youtube is an excellent resource and explains everything for anyone one who is a DIYer. https://www.youtube.com/@WillProwse reply zdragnar 11 hours agorootparentMake sure you have a good understanding of what your insurance company will and won't cover for DIY projects. Insurance companies can be skittish about unlicensed electrical work. For something like this, a worst case scenario is an electrical fire during a drought or a kid gets electrocuted. If you do the work yourself, you're likely on the hook if something goes wrong, even if it's due to a faulty part and you have an umbrella policy that covers liability. reply denkmoon 20 hours agorootparentprevSome people cold knocked on my dad's door and 3 weeks later he's got a wall of batteries in the garage. Rural Australia. So yeah, there are businesses that'll do it. reply iamthemonster 19 hours agorootparentAustralia has become SO competitive for solar and battery installation you can actually be fairly safe nowadays just picking any old supplier that has >4.7* on google and there'll almost definitely beOne wrong poke with a screwdriver I'm not sure where you're jamming the screwdriver, but certainly any wrenches/tools you use should be insulated if you're dealing with very high current and/or high voltage. Enclosures, insulated wires, conduits, terminal covers should be used to avoid short circuits. Also proper earthing and circuit isolation with RCBOs to protect from electric shock and overcurrents frying the wires/you, all which should be switched to the off position when you're poking your screwdriver, eh? ;) > And they’re big enough, no portable fire extinguisher is going to make a dent either. If you aren't doing basic safety things and somehow manage thermal runaway on LiFePo4 (pretty hard), you're probably going to melt some copper. Probably best not to put your battery assembly near flammable things, unless you want to see the world burn like this guy (though at low voltage/high current) https://www.youtube.com/watch?v=ywaTX-nLm6Y reply defrost 12 hours agorootparentprevSure, you're saying some people shouldn't DIY. Where I live many people DIY as a great many people have mad skills (lots of FiFo workers making a good living from O&G installions and big mining projects). They build their own houses, their own planes, off grid power systems, water proof EV's to drive across harbour floors, etc. If you've got a big (shipping container sized) battery pack you need a big thermal blanket to cut off the oxygen or a wide enough fire break about it. Speaking of DIY home builds, here's a good use of black builders plastic: https://www.youtube.com/watch?v=1ILbQHnHPnY reply lazide 11 hours agorootparentNo, you’re talking about building structures. I’m talking about assembling a bomb. A 5kwh battery contains about 18MJ of energy, equivalent to 4.3KG of TNT. Short that out or puncture on of its component pouches, and it’s going to be very dramatic. One of them requires a different degree of care than the other. reply defrost 10 hours agorootparentYou're still making the same irresponsible and frankly silly generalisation about \"average\" people. Most people, full stop, don't build houses, metal work shops, treat their own sewerage, build their own power systems, etc. So \"average\" people just don't start fires or set off bombs because they're not doing anything that dangerous. Of the people that do, say, build their own glass furnaces, annealing ovens, laying out gas lines and installing small truck sized propane tanks with more energy than a 5kwh battery .. easily less than half, well below the \"average\" number of people that do such things, have accidents. Sure, some people do watch Forged in Fire and have a go at knife making in a home built furnace, and then set fire to their barnhouseshed. Most people don't try, and of those that do have a go most of them don't screw it up. The point being, this: > Also prone to average people setting themselves or their houses on fire, eh? is just silly. Average people don't attempt this, and of the people that do attempt such things most don't cock it up. Perhaps your personal experience differs. Maybe you can't dig your own septic system and fit it out without shit running back into your house. reply lazide 9 hours agorootparentNear as I can tell, you literally never even read my comment. So seriously, WTF? You’re doing on this weird rant, when I literally just said average people shouldn’t be assembling their own multi-kWh lithium battery packs unless they want to burn their houses down. Which is, indeed, good advice. And pertinent to the discussion. Where this bizarre tangent you keep going off on is not. reply defrost 7 hours agorootparentNear as I can tell, you literally never even read my comment. Consider that I explicitly stated: * They build their own ... planes * They build their own ... off grid power system(s) * They ... water proof EV's to drive across harbour floors and you responded that \"No, you’re talking about building structures. I’m talking about assembling a bomb.\" Let me remind you that aircraft are bombs, off grid power systems are bombs, water proof EV's with battery packs large enough to drive 7 km's underwater have the same issues you're talking about. You apparently didn't pause to read the content of my comment before launching into a \"Yes, but ...\" I've already linked to locally built ground effect plane (with builders plastic for wings), here's a locally built EV: https://www.abc.net.au/news/2023-07-30/nt-world-record-darwi... Average people are quite capable of doing extraordinary things and not burning down their houses - you just have a low opinion of \"average\". Idiots that can't read manuals and installation guides should avoid house grade battery packs, sure. reply h0l0cube 8 hours agorootparentprev> average people shouldn’t be assembling their own multi-kWh lithium battery packs unless they want to burn their houses down Average goofs shouldn't be assembling their own solar system and battery setups. Even an average person will apprise themselves of the know-how to proceed safely, and are legally obliged to do so. If average person is not interested in doing that, they'll call on a professional, and in some places, that is the only legal option. But perhaps there are contradictory stats out there to show that there's a real widespread phenomenon of well-meaning Average Joes and Janes that are burning down houses with DIY batteries. reply 10u152 8 hours agorootparentprevFUD. This isn’t running a nuclear reactor it’s following some basic rules and common sense. Lifepo4 is much more stable than you seem to think. reply samatman 18 hours agorootparentprevProblems with the BMS can become problems with the cells very quickly. reply h0l0cube 18 hours agorootparentYeah, but I would just buy the cells and spend more on a BMS. Or you can just use a low voltage cutoff and an active balancer for a smaller setup reply jauntywundrkind 13 hours agorootparentprevI buy that the bms aren't very good and are drastically hurting your system. Much lower key stakes, but I have an Andis Supra trimmer I rely on a lot, but it's charger has basically no low key mode: it will pump 10W+ power into these 2S cells forever. It's criminally bad battery management, will absolutely nuke the heck out of these high end cells, if you forget to pull it off the charger. To me, the main thing is observability. Too many people trust their systems. We need to see how things are going. As the voltage converges to peak, we should be seeing the amps level out. We can't just trust the machines, ever. We need to be observant. Ultimately I think we'd be able to review & get rid of bad equipment more effectively, but we should be in tune with what these systems are doing, should be aware that - oh hell - we are at peak voltage and still pushing power in, and we need to stop. These systems need to report what they are doing. Being blind consumers makes the economic system weaker; these systems should all report what they are doing. reply oulipo 11 hours agorootparentprevThis is why at https://gouach.com we've built the first easy-to-repair, easy-to-swap-cell battery! We're launching a Kickstarter soon, stay tuned (on our newsletter!) reply reaperman 22 hours agoparentprev> Due to rising power costs I moved one of my homes completely to solar and battery Were you able to disconnect that home from the grid? Most places you're required to maintain a grid connection unless the home is in an exceptionally remote location. While pricing tends to be usage-based, true costs tend to be dominated by the capital expense of building base-load capacity for the few days your home might need to run fully on grid power. So as long as you're connected to the grid, you're still forcing the utility to spend about the same amount of money even if you only use grid power a few days out of the year. reply duffpkg 22 hours agorootparentYes. Totally disconnected, zero power bill. That home is in a jurisdiction where that is permissible. reply ManuelKiessling 22 hours agorootparentHow do you get through winter? I’m asking in good faith, I‘m using a PV installation myself and cannot see how I could realistically get off the grid. reply dgacmu 22 hours agorootparentOver provision the panels by a good margin and have them at a more southerly angle (for northern hemisphere). You can play around on nrel pvwatts to see what configuration produces the most even expected monthly output: https://pvwatts.nrel.gov/pvwatts.php Most solar charge controllers allow a certain amount of PV overprovisioning. reply kolinko 21 hours agorootparentIn central/northern Europe in january solar goves 10% of the output of summer, and you need 3-4x power to heat compared to cooling down in summer. reply eichin 21 hours agorootparentIt is often surprising that most of the US is south of most of Europe (the common reference is that Chicago and Rome are both 42N. The jet stream complicates the effect on overall climate, but latitude is pretty much the only thing that matters for solar power.) reply gpm 20 hours agorootparentSolar panels are mildly more efficient when colder, the same latitude in an area with similar cloud cover in north America is probably generally slightly better for solar than Europe because it is colder, not sure if it would ever be more than a rounding error though. reply taneliv 12 hours agorootparentThe difference between surface solar radiation levels in the US and Europe are wild[1], fully agree on the rounding error view. Anchorage seems to receive the same level of watts per area as Germany and Poland. [1] https://1.bp.blogspot.com/-I5kzJIeV4Ds/VFSHUX3374I/AAAAAAAAA... reply Gibbon1 10 hours agorootparentAmusing southern California is getting more watts per m2 then A lot of North Africa. This is a good source, population by latitude. http://www.statsmapsnpix.com/2021/11/world-population-by-lat... reply taneliv 6 hours agorootparentIt's missing the \"most population in smallest (circular) area\" view, as defined in https://en.wikipedia.org/wiki/Valeriepieris_circle . reply Scoundreller 13 hours agorootparentprevI’ve been in northern France for a couple weeks in a January and didn’t see the sun once… Not really a thing in Toronto. reply maigret 4 hours agorootparentSolar panels don’t need sunshine they need light. reply Retric 20 hours agorootparentprevNorthern Europe is much further from the equator than most of the rest of the world. To the point where rooftop solar stops being a great option. That said there’s a few ways to boost that 10%. PS: Geothermal can also slash energy needed for heating. Ground sourced heat pumps are the only reasonable small scale solution, but in urban areas going a little deeper starts to make a lot of sense. reply nicoburns 18 hours agorootparent> To the point where rooftop solar stops being a great option. Perhaps as a complete energy solution. But it is already the case today that a domestic rooftop solar in Europe (maybe not in the very north) has payback timesTotally disconnected, zero power bill. Great job! Over the last half a year my feelings about rooftop grid-connected solar (net energy metering, feed in tariff which are subsidised by the electricity bills of others) have changed somewhat, but going off-grid you've put in the investment to be energy independent. reply MichaelNolan 21 hours agoparentprevWhen you say $89/kwh, are you talking about just cells, or assembled packs? I’m just about to buy a 5kw Lifepo4 server rack battery from EG4 for a diy project. It’s closer to $220/kwh This is what I’m planning to buy, but you know something better I’d love to take a look. https://signaturesolar.com/eg4-lifepower4-lithium-battery-48... reply duffpkg 21 hours agorootparentIt would be for the completed battery units with BMS. You would have to install the batteries into the battery cases. It is a bit tedious but it was otherwise straightforward. The batteries are extremely heavy. I have always had good experiences with signature solar. My inverters are EG4 and I am very happy with their product after trying A LOT of others. I think the primary reasons for the price difference is that you are purchasing US inventory (it's already here), it's preassembled and warrantied as a unit, they provide pretty decent support and their battery packs use 100ah cells instead of 280ah+ cells. So you are buying ~3x as many BMSs, connecting cable ($$$$) and cases for the same power. Their rackable units are not light but can be moved by a capable person without too much fuss. A fully loaded 280ah unit in it's case is over 250lb so you really need a lift cart or such. The 280ah units and now maybe 320ah are more economical. reply cyberax 20 hours agorootparentprevDo you know if these batteries be used as a replacement for batteries of a lead-acid UPS? I have a Tripp-Lite rack-mount UPS with an extension battery, but its battery has degraded and it can only sustain my computing load for 3-4 hours. It'd be great to replace it with an LFP battery. reply jseutter 15 hours agorootparentYou can't use LFP batteries as a direct replacement in your UPS, no. The voltages and charge characteristics are different. What you can do is replace the UPS with a portable battery solution, like another poster suggested. I believe the Anker units are one of the few that can function as a UPS. Most sorta-can, but the key difference most of them lack is that they don't turn on automatically after fully discharging when the mains power comes back on. It's up to you if you need this particular feature. Will Prowse on youtube I think has some videos comparing and contrasting the different units for this purpose. reply Dylan16807 12 hours agorootparentThe Anker units that are at minimum $600 per kWh? At that point we've completely lost the cheap factor. reply lazide 13 hours agorootparentprevAlso, most of those power banks don’t switch between power sources fast enough to avoid causing problems. That said, something I can confirm works on that front is getting one of those power banks, plugging the UPS in, and then plugging whatever into the UPS. I had several days of uptime on Starlink that way, running it 10 hrs or so at a time on a battery bank, the remainder on a cheap generator. reply duffpkg 19 hours agorootparentprevFor that low a power need Anker and some others make ready to go units you can buy off of amazon that are pretty reasonable. reply jauntywundrkind 13 hours agorootparentprevThere's some very significant additional costs of bus bars & holding racks, but holy heck man EVE LF280K batteries are amazing. Usually 300Ah cells/ There needs to be some backup capacity I think they're talking about the situation where you're still connected to the grid, in which case you don't need to handle the backup capacity. reply Dylan16807 10 hours agorootparentprev> Hmm yes super cheap, might impulse buy later. It's part of a house. Of course it's not an impulse buy. That's not a useful basis for comparison. reply ValentineC 13 hours agoparentprev> Lifepo4 (lithium iron phosphate) batteries for the home are pretty cheap as of today. Power storage for residential use in a 48v metal rackable linkable system with battery management system (BMS) is $89/kwh shipped/duty paid from reputable chinese suppliers CATL/Seplos etc. I'm probably not the only one wondering: does ordering from these Chinese suppliers require reaching out to them over email? I looked at both websites, and while Seplos asks to write in, CATL doesn't even have battery listings or sales contact information. I'd love to order LiFePo4 batteries to put in some old UPSes of mine. reply jjeaff 13 hours agorootparentyou can order through Alibaba, but there are so many suppliers and not all are reputable, so it's a good idea to search around on some of the solar forums for recommendations. reply callmemclovin 12 hours agorootparentprevYeah I think if you want to order from CATL directly, your chances for a reply are better if your order is worth some billions :-) EVE cells are very famous in the DIY scene, you can get them via Alibaba/Aliexpress, or if you're in Europe from nkon.nl, they have a very good reputation. reply luke541 6 hours agoparentprev89$/kWh seems way too low. If I'm mistaken please point out where I could buy them cause I'll gladly buy some. On well known Chinese market places the price is 5x to 10x that (I live in Europe) reply hippich 12 hours agoparentprevCan you share places the I can get 1kwh if batteries for 89/kw shipped? I am waiting for a 14kw diy build set at 122/kw, that's the best I could find on Alibaba reply dzhiurgis 22 hours agoparentprevWhy tesla charges 5x for their Powerwall? I know their software is excellent, but I haven’t seen prices like that anywhere. reply rootusrootus 20 hours agorootparentBecause there's value in a brand name, they are using more expensive batteries (or they were, I think just recently they started shipping LFP), and you're paying for the plug-and-play convenience. Buying cells from CATL, adding a BMS, and putting all in a case is easy but still not trivial. Definitely not plug and play. You can absolutely get dirt cheap LFPs (like other people, I hang out on diysolarforum.com too), but it is not a competitor with the Powerwall unless you want something to tinker with or are simply too budget constrained to buy the brand name product. reply dzhiurgis 15 hours agorootparentI think OP mentioned battery rack (not cells) with BMS, not pure cells. reply specialist 21 hours agorootparentprevMy guess: to throttle demand. Installers are generally in short supply and huge demand. So why not charge a premium? reply GaggiX 22 hours agoparentprev>I purchased pallets of used panels for more or less the cost of transportation ($34 per panel 270w) For comparison, I've seen pallets of new 24 410w panels at 58€ per panel (transportation included), hopefully I'll see similar deals in the future when I will ready to jump into solar. Edit: I'm mostly worried because I don't know how sustainable the industry is when you can buy solar panels at such dirt cheap prices. reply davedx 22 hours agorootparentIt’s not sustainable. Solar panel producers are going to be in big trouble in 8-10 years I think. reply DaoVeles 21 hours agorootparentThis is a controversial hypothesis that is merely from a idiot, being myself. I don't truly believe this but it something I have throught about. Energy costs are THE driving force of prices. The cost of materials is essentially the energy it takes to squire/process/ship them. If energy was free, we would just dig up random patches of dirt and sift it for every material we wanted even in trace amounts. But its not because unfortunately, we are still primarily a fossil fuel economy for many reasons (legacy, price, chemical properties) and their cheap price relative to labour is acting as a subsidie to renewables pricing. So if the availability of fossil fuels deminishes it seemed logical that the price of inputs goes up and so too would renewable manufacturing. We would then see an inverted bell shaped curve on pricing over time. I have long suspected we would see this trend of lowering prices revert around the 2020s. So far I have been pleasantly wrong. But fossil fuels like almost all minerals is fighting an uphill battle on availability and ore quality as we used the best stuff first. The US isnt fracking at the pace it is because they just wanted a laugh. It is due to the primary \"conventional\" stuff couldnt keep up. But that is a whole different issue. If renewables were offsetting fossil fuel usage, this wouldnt be a problem but it is merely being added on top of it. Thus Jevons paradox in full swing. If we can over come that then this whole idea can be thrown in the recyling bin. When we can make a solar panel with the outputs of a solar panel, then that is the escape velocity moment. And I don't just mean counting the joules and ignoring the energy fungability. I am much more optimistic about this in the last few years but im not sure we are there yet. It is looking reasonable now. reply deadfoxygrandpa 15 hours agorootparentthere is a name for this \"hypothesis\" and other people have worked on the idea. it's called the \"energy theory of value\" reply jauntywundrkind 13 hours agorootparentCore belief of Howard Scott's Technocracy Now movement, > At the core of Scott's vision was \"an energy theory of value\". Since the basic measure common to the production of all goods and services was energy, he reasoned \"that the sole scientific foundation for the monetary system was also energy\", and that by using an energy metric instead of a monetary metric (energy certificates or 'energy accounting') a more efficient design of society could be made https://en.wikipedia.org/wiki/Technocracy_movement If nothing else it's a fascinating lens to view modernity through. reply imtringued 4 hours agorootparentprevhttps://en.m.wikipedia.org/wiki/Nicholas_Georgescu-Roegen reply Gibbon1 14 hours agorootparentprevI've read some heretic economists that say that instead what orthodox economists claim that energy contributes 10% to GDP it's much higher closer to 100%. You get outside economics into accounting and as you chase the supply costs down you run into energy and scarce resources as the driver of cost. Maybe 20 years ago I had the thought that ever never was enough supply of fossil fuels to lift the remaining 2/3rds of humanity out of poverty[1]. But there is enough solar and wind to give people a low energy middle class life. And the cost reduction since I think can do better than that. [1] China I think burned half it's coal reserves in last 40 years. Modern China is basically built on coal. And much of the world doesn't have anything like that. reply defrost 13 hours agorootparent> China I think burned half it's coal reserves in last 40 years. As a point of nomenclature isn't that always the case for any resource? Given that \"reserves\" are drill tested known quantities that are tested, proven, modelled, and queued up for mining .. most reserves having been taken past \"economic feasibility\". Hasn't the usual pattern in mining for some three thousand years since the oiriginal Rio Tinto Gold Mine been that reserves are mined and as they are exhausted, an exploration phase ramps up to prove inferred resources and raise them to reserve status? eg: https://www.ga.gov.au/digital-publication/aimr2021/australia... reply Workaccount2 4 hours agorootparentprevEverything society does is aimed at (locally) reducing entropy, and energy is the only way to do that. reply Retric 21 hours agorootparentprevI can see why 8-10 years looks like a wall in terms of how much total solar we want. However panels age which costs ~1% of capacity per year even before they need to be replaced, and global electricity demand tends to increase 2+%/year. So the more solar you install the more you need to install every year just to keep providing the same percentage of total electricity. On top of this lower prices mean you it's still worthwhile even if a larger percentage of output gets wasted. Similarly, as storage gets cheaper (inflation adjusted) there's going to be more demand to cheaply charge it thus raising the demand for panels. reply plorkyeran 15 hours agorootparentprevIn 2011 solar panel producers were in trouble because China was flooding the market with panels sold below cost, which prompted a new set of tariffs. Those panels were around $1/watt in 2022 dollars. Since then, price per watt has apparently dropped _85%_. It's an industry that's been driving down prices at an absolutely bonkers rate the entire time it's existed, and any time a company falls behind on that they're immediately in very deep trouble. I think it's basically impossible to make predictions about what an industry like that will be in 8-10 years. reply oezi 21 hours agorootparentprevIn the 8 to 10 years panels will be even cheaper. Probably half of today. The price trajectory is still falling. reply GaggiX 21 hours agorootparent>Probably half of today. A 410W solar panel at 29€? I really doubt that honestly. Cheaper than plywood. reply DaoVeles 21 hours agorootparentThis is not shade on the original comment. But I do find it funny when economists that extrapolate out to infinity. Comely divorced from the real world materials and ecology. reply Retric 21 hours agorootparentprevEfficiency going up is one way to reduce instillation costs which grid scale solar really cares about. 470W + even cheaper inverters seems likely. reply bufferoverflow 20 hours agorootparentprevThin-film solar panels will be much cheaper than that. They will be printed in huge quantities. reply oezi 21 hours agorootparentprevEconomies of scale baby. Another 10x more in production another 30% less in price. reply coldtea 19 hours agorootparent>Economies of scale baby. That's what they said about regular electric grid power too - that it \"soon\" would be so cheap as to be unmetered. That was half a century ago and it didn't pan out... reply samatman 18 hours agorootparentThe reasons for this are entirely political. Technology, left to its own devices, would have followed the usual maturity curve on fission power, which would be universal, ubiquitous, abundant, and cheap. Solar power has neither the geopolitical problems nor the squishy 'environmentalist' ick factor of fission. There's no reason not to expect another halving or two of PPP dollar per Watt to follow. reply pshirshov 21 hours agoparentprev> $89/kwh shipped/duty paid Sorry what? Currently I'm happy to buy 5 kWh units for €1300. reply pineaux 22 hours agoparentprevHow is this cheap? How much did you pay for the whole package? reply duffpkg 22 hours agorootparentThat does not include the costs for inverters and other electrical system parts. I am not endorsing these vendors but I am happy with the result. My system paid for itself in less than 18 months. I have many years of experience buying from China in industry. I purchased batteries from Docan Power and BMS/battery housings from EEL Battery. My inverters are from EG4 and UL listed. You can see current pricing on their respective websites. I would say there is some learning curve for a complete novice. The diysolarforum.com is a good vendor neutral and honest resource for information. reply tgsovlerkhgsel 22 hours agorootparentprev> How is this cheap? It's $900 + inverters for 10 kWh. A Tesla Powerwall 2 (14 kWh) is $10k (inverter included). I doubt the inverters cost more than $1k. reply kkfx 21 hours agoparentprevWell, here, France, LFP batteries now cost MUCH MORE than just three years ago (final customer price) and... ~1000€ per kWh, while just 3 years ago they was a bit less than 700€ per kWh, the battery alone (with BMS etc) but we also need an inverter witch as well is not much more expensive and I talk about self-assembled systems, here legal, but not legal in large slice of the EU, because retail price of a complete installed system by some p.v. companies are so high that there is no economical reason to install them. My system is 5kWp/8kWh @11.500€ three years ago, it would be now a bit different (400V batteries instead of 48V and a hybrid inverter instead of a p.v. string inverter AC coupled with a battery inverter) @~ the same price due to a single inverter and slightly cheaper p.v. modules (@~100€ for a 415Wp). If done by third parties the cheapest proposal back than was ~30.000€. At this prices given current electricity prices and local grid stability it's a nonsense, it's even cheaper a diesel generator. I know prices in China are FAR lowers, and I've read also on far lower Thailand prices, but compared to local cost of life I can't quantify how much. reply callmemclovin 12 hours agorootparentWell with the DIY route that's not a problem - nkon.nl is shipping to France as well, I guess? So there you can get EVE 280 Ah cells for about 100 €/kWh: https://www.nkon.nl/fr/rechargeable/lifepo4/prismatisch/eve-... reply kkfx 11 hours agorootparentUnfortunately DIY is limited to what is certified in France, Victron MultiPlus are certified all, Quattro so far are not, the sole battery from this shop allowed for a grid-connected system are the Pylontech. Still MUCH cheaper than what I've found from French shops anyway so a big thanks :-) reply oulipo 11 hours agorootparentprevThis is why at https://gouach.com we've built the first easy-to-repair, easy-to-swap-cell battery! We're launching a Kickstarter soon, stay tuned (on our newsletter!) reply Aurornis 22 hours agoprevThis blog post is all over the place. The 2030 price projections are taken from extrapolations of Lithium battery costs, but he’s assuming Sodium chemistry batteries will take over and become ubiquitous at rock bottom prices. The first Sodium batteries barely became available within the past year. He’s also treating batteries like the only component of the system. The associated charging, inverter, and physical structure components aren’t going to follow the same downward curve. Those are fixed costs on top of the battery itself. Finally, there’s a lot of vague futurist writing mixed in, from congratulating himself on predicting in 2017 that EV trucks would be a thing some day to something about the blockchain for coordinating power grids: > I think this is also an area where distributed ledgers with low energy requirements (so not Proof of Work but Proof of Stake) could shine by creating an ‘trustless’ system (meaning the system justs works, also if there is no ‘trusted’ party that plays the boss). This statement doesn’t even make sense when you read it. He defines “an [sic] ‘trustless’ system” as meaning a system that “just works” which suggests to me that he doesn’t really know what he’s talking about but has been led to believe that blockchain is the future for everything. Fun read, but I didn’t get much out of this article other than “prices are going down” reply Animats 21 hours agoparent> This blog post is all over the place. Which is sad. He has something useful to say, but destroys his credibility by not focusing. Here's the \"poster wall\" of the organization he claims to head.[1] \"Disciplinary convergence through creative story telling\". For a much better summary of the subject, see the cover story in this week's Economist. OK, how cheap can batteries get, really? Well, the price of lithium dropped 80% in the last year.[2] Overproduction at the moment. Exxon has a lithium production unit, and they're expanding. New, large lithium mines under construction in Nevada, Sonora (Mexico), five new mines in Western Australia, Quebec, Zimbabwe... Plus, of course, recycling old batteries, a far more concentrated source than anything in the ground. Lithium supplies do not look like a problem. The prices do go wildly up and down because the price of raw lithium doesn't affect car sales much in the short term. That's normal behavior for minor commodities. This also means that sodium batteries will probably be unnecessary. This is good, because of the fire risk. For fixed installations and low end car, lithium iron phosphate is cheap, not subject to thermal runaway, and in most of BYD and CATL products right now. (APS, please get with the program and start shipping small UPSs with LiPoFe batteries so those things last 10 years.) Coming along next are solid state batteries. Huge hype, a few samples, and production cost problems.[3] Here's the manufacturing process at lab scale, at the Franuhofer Institute.[4] Works in the lab. Here it is at production test scale.[5] The IEEE consensus is that solid-state battery production technology is about 10 years behind existing lithium-ion production. With production in test everywhere from Shenzhen to Belgium to Maryland, progress is being made rapidly. This is the kind of process that gets cheaper as it scales up. Solid-state batteries are important because 10-minute charging is needed to increase consumer acceptance rates. Between solar and battery technology, fossil fuels are going to be crushed. Soon. [1] https://neonresearch.nl/poster-wall/ [2] https://www.reuters.com/markets/commodities/lithium-producer... [3] https://spectrum.ieee.org/solid-state-battery-production-cha... [4] https://www.youtube.com/watch?v=j5SVrp8N-1M& [5] https://www.youtube.com/watch?v=_eZGuDaqZAE reply gpm 21 hours agorootparent> Well, the price of lithium dropped 80% in the last year.[2] Overproduction at the moment. ... > This also means that sodium batteries will probably be unnecessary. If we're overproducing this doesn't follow. Lithium prices will rise back to the price of production. I'm not an expert but quickly glancing at the futures market and it looks to me like there is only a small rebound predicted ($13.30 -> $17.00/contract over a few years, highly illiquid market so take prices with a grain of salt) so the actual story might be \"lithium production has become much cheaper\". It also doesn't really matter if you're trying to estimate \"it will cost at most this\" by looking at sodium ion batteries. I don't think the author really cares if the batteries are sodium or lithium based, just that they don't cost more than sodium based batteries would cost. > This is good, because of the fire risk One of the selling points for Sodium ion has pretty consistently been that they are non-flammable. Admittedly this is a function of the electrolyte they use and not a fundamental property of sodium vs lithium, so it might change in the future, but I don't believe it has/it is in anticipated to? reply ksec 15 hours agorootparentAgree on every point. Sodium is also so abundant it will likely not have the same price fluctuations as lithium. For stationary battery like the use case describe for in house. I would assume sodium has a much better chance of winning over. reply dyauspitr 21 hours agorootparentprevChinese manufacturing seems insanely advanced based on link 5. reply stephen_g 13 hours agoparentprevI agree that applying anything to do with blockchain to electricity is dumb - these are already just regular markets, so an inverter/charger could already take price signals from the existing market and do whatever the homeowner wanted, with zero need for blockchain or central control at all. With smart meters (which are becoming more ubiquitous) it's already simple to incentivise using battery power in peak periods when the price is high... But on inverter/chargers - they will absolutely will follow a downward trend. Maybe not as quickly as batteries but downward all the same. Wide-bandgap semiconductor FETs are getting cheaper and better all the time (higher current and voltage per device), and they allow for power topologies that are more efficient, so cooling gets easier, weight of heatsinks and the amount of material in those goes down, power per unit volume increases and unit mass will decrease, etc. Production volumes will also increase which should lead to economies of scale too. I can get a 48V DC/230V AC, 8000VA Victron Multiplus 2 inverter/charger for $1.8K USD at the moment (I'm about to buy one for a system I'm DIYing from 31 kWh of AGM batteries I managed to get basically free from a test site of a company that closed down). I wouldn't be surprised if I could get the same capacity inverter/charger for something nearer to half the price by 2030, and a few percent more efficient to boot (this is 95% max efficiency but hopefully 97-98 will be more common by then). You probably can get plenty of cheaper ones from China already but I want to be absolutely sure it'll meet Australian Standards since this will be grid tied for backup (but able to operate independently during outages), and since it's going under my house I want to know it's safe! Victron have a good track record, especially with a lot of use in maritime and caravan applications where you really don't want them catching on fire so that gives me confidence! reply SCUSKU 22 hours agoparentprevAs someone who knows little about battery technology I was interested and trusted the author. But once I read the part about blockchain PoW vs PoS it seemed so off base that it threw the entire article into doubt... reply sanxiyn 21 hours agoparentprev> The associated charging, inverter, and physical structure components aren't going to follow the same downward curve. I agree not the same downward curve, but it also has been on the downward curve, although different. Learning rate is rather a common phenomenon. Estimating the learning curve of solar PV balance–of–system (2018) estimates 11% learning rate for BOS compared to 20% learning rate for module. https://doi.org/10.1016/j.jclepro.2018.06.016 reply DaoVeles 21 hours agoparentprevNarrow boundary analysis can be useful but problematic. The additional components is a great example. Remember a large part of your electrical bill is paying for the grid, not just the energy it transports. reply jsnell 12 hours agoprev> If we start with 2410 GWh in 2023 and grow with 59% per year that gives us 61.917 GWh in 2030. That would mean almost exactly 8 doublings in 2030. There's an order of magnitude error here. That's an increase of about 26x. 8 doublings would require an increase of 256x. Now, anyone can make a simple math error. But, like, it should be totally obvious to anyone that 7 years of 60% annual growth can't possibly be anywhere near 8 years of 100% annual growth? Or if not anyone, then at least for someone like the author who spends the first page of the article bragging about their credentials in reasoning about exponential growth. Edit: and this isn't just nitpicking, this faulty result is then used as the basis of the cost reduction estimates. reply ppsreejith 6 hours agoparentI think the unit is off. Starting from 2410 GWh & a compound increase of 59% per year gives us: 61,915 GWh (2410 * 1.59^7) which is about 61.915 TWh. So perhaps the author meant 61.915 TWh instead of GWh. No way is this in anyway close to 8 doublings though. That would take 12 years or by 2035. (1.59^12 = 261x) reply jsnell 3 hours agorootparentI think it's rather that they're using the dot as a thousand separator, not as a decimal separator. reply jvanderbot 22 hours agoprevI would love a 5-20kwh battery backup in my home, I even have a place for it. But when I called my local solar/battery installer they said that it was illegal to install grid-charged battery backups in home. I live in Minnesota. They even told me the power from a hypothetical solar rig is sold to the grid utility, not stored, and they give a discount on future winter rates as payment. This seems like a lousy deal. reply murkt 22 hours agoparentI have a 3.5 kWh battery backup in my apartment, since December 2022. Which is proving to be immensely helpful right now. I’m living in Kyiv, Ukraine and we haveAlso due to load shedding, I don’t get full use of my batteries. But your batteries will last much much longer at the lower cycle depth reply Tade0 22 hours agorootparentprevIf it's any consolation your battery will at least last longer than one which is always doing full cycles. reply jonathanlydall 21 hours agorootparentIf the battery is only ever charged from solar and I uncharge it to the lowest safe level in the evenings, it lets me get the best possible return on my capital expense. How long it lasts doesn’t matter in this regard. But in terms of using it for UPS purposes, it lasting longer would mean I won’t need to expend capital again as soon. So I guess it depends on what you want out the battery. I did some math when I bought the battery and it seemed it would probably pay itself back before needing to be replaced, but it was questionable at our energy prices. I bought the system mostly for UPS reasons though, especially as I work from home and on a personal note, sitting in the dark several evenings a week or being unable to make coffee when you want, sucks. reply suoduandao3 7 hours agorootparentprevI'm sure benefitting energy companies is the real reason... but if everyone had a battery backup and they all started charging at the same time, I suppose it could make it harder to reboot the system after an outage. reply throwawayffffas 8 hours agorootparentprevI am pretty sure it's a fire safety thing. > illegal to install grid-charged battery backups in home. I don't know but I am guessing the objections is with the \"in home\" not the battery backup. reply ridgeguy 20 hours agoparentprevPerhaps you could circumvent the regulatory inconvenience by getting your \"battery\" in the form of a Ford F150 Lightning pickup truck. It can power your home during grid outages, and of course can be charged from solar and/or the grid. One vendor is here: https://www.sunrun.com/ev-charging/ford-f150-lightning reply throwaway81523 17 hours agorootparentOuch, starting price $57k (98 kwh battery) and around $70k for the recommended model with 131 kwh. It's a rather large vehicle with poor \"gas mileage\" of about two miles per kwh. A normal sized electric car gets around 2x that, giving higher grid bills or needing bigger solar arrays (thus, more real estate). Idk if the Ford uses LFP batteries these days. Certainly most of us who think of buying electric vehicles would want to actually drive them around. reply BenjiWiebe 22 hours agoparentprevIs a grid-charged battery backup different than a UPS? I guarantee there's UPSs in use in Minnesota. reply jvanderbot 22 hours agorootparentI asked and they said \"yeah it's the same and yeah it's still illegal.\" The difference is what side of the electrical box your equipment is on. reply syntaxing 22 hours agoparentprevThere’s been some pretty big deals from Ecoflow (I don’t own any of their products nor affiliated). The Delta Ultra was on sale at Home Depot for $2800 before tax, 6 kWh battery, 7kWH continuous supply, with 21kWH peak wattage. Everything is built in including inverter. You can install their smart panel (probably requires a permit) and it’ll switch between grid and battery for you. I’ll be surprised these are illegal in your town but there’s but some crazy local laws. reply Firaxus 14 hours agorootparentAs someone who is interested in getting some kind of back up battery at some point, ty for making a recommendation. But could you clarify what you mean by the kWH unit you used on 7 and 21? Seems like those should just be kW, a unit of power rather than kWh, a unit of energy. reply kccqzy 21 hours agoparentprevYou might as well just buy an electric vehicle with V2L or V2H functionality, and then add a generator outlet to your electric panel. The added benefit is that well, it's a battery strapped to a car. So if you have an extended power outage, you simply drive your car to a charger elsewhere and come back with a full charge. I'm sure Minnesota wouldn't be stupid enough to outlaw EV charging. reply throwaway81523 17 hours agorootparentThere have been weather events and suchlike where it has been impossible to charge an EV, though gas was still available. reply vel0city 5 hours agorootparentAnd I've been in weather events where I had electricity at home and yet all the gas stations around didn't have electricity to run their pumps. reply kccqzy 16 hours agorootparentprevYou charge the EV before the weather event. Not during. Then when the weather event comes, you still get electricity at home supplied by your car. If the weather event is localized, drive your car to a place with electricity and charge it there and drive back. It's the best. reply edmundsauto 14 hours agorootparentMy concern would be draining the fuel reserves in a vehicle to power my home reduces my mobility. It seems like mixing objectives and in an emergency, I want to keep my super spare backup if I needed to flee. reply Dylan16807 9 hours agorootparentSo you're worried about a weather emergency that takes out your power, followed a few days later by a second emergency that requires you to evacuate a long distance? I don't think I'd do very much to prepare for that scenario. reply vel0city 5 hours agorootparentIt can be the same emergency. It doesn't have to be a second one. You might plan on riding out a storm, thinking utilities might be out a day or two max. Day 5, still no utilities, no known date for resumption of services, and supplies are running extremely low. How do you get out? reply ssl-3 2 hours agorootparentIn the best case: Just deal with it proactively. Watch supplies, try to stay informed. You mitigate what you can to stretch things out (making French toast in a skillet outside on the BBQ grill in the aftermath of a winter storm may be the best way to use available energy and feed people a tasty meal, even if it does seem absurd). Plan to leave before things become unmanageable, and adjust that plan as things change, and be willing to resolutely execute that plan before things go from bad to worse. If you forecast that your supplies will be very slim on day 5, and you haven't left for greener pastures by day 3 or 4, then the the worst case is already unfolding. GTFO before the worst-case ever happens. But in that worst case: One can call on someone else for help. This is one of those situations where it's time to cash in some favors, and/or where it pays off to always be friendly and helpful with to the neighbors even if they really seem like a bunch of assholes. (The time to start being friendly with the neighbors is right now, by the way.) (My own backup plan only keeps me rolling both semi-comfortably and independently for about 24 or 48 hours without power in the winter, so I'm leaving after the first night or ASAP. I don't have the complications and niceties offered by something like an F-150 Lightning, but finite resources remain finite no matter their form.) reply vel0city 28 minutes agorootparentYou're either not going to have much meaningful backup power or you're not going to have much usable range if your plan is based on consuming the energy on your car while holed up and also using that energy to potentially drive a couple hundred miles. That's my real point here. reply weberer 6 hours agoparentprev>it was illegal to install grid-charged battery backups in home So it would be legal if it were only charged by your house's solar panel? That doesn't sound like a big problem to me. reply lazide 22 hours agoparentprevKeep in mind, they also might be lying. reply jvanderbot 21 hours agorootparentThis is totally reasonable. I can't find any confirmation of this anywhere. reply vitaflo 20 hours agoparentprevMight want to check with a diff installer. Lots of solar installers in MN advertise battery backups. In fact a new law signed recently (and goes into effect in the next couple months) adds tax incentives for battery backups in homes. reply dzhiurgis 22 hours agoparentprevBecause grid use (transport) costs 2-3x more than the power itself. Now imagine you produce 95% yourself. Instead of typical 15kw installation you only need 500w for when sun doesn’t shine. Thats a reduction of 30x! Far cheaper inverters, thinner lines, etc. Unfortunately no one in the supply chain has wants this because thats lost profit. reply worstspotgain 22 hours agoprevAs a layperson, the first thing the title made me think of is \"How safe can they get?\" Let RESCI be the Risk of Explosion/Surge/Combustion/Inhalation. Here are some measures that are interesting to me that I can't really approximate when evaluating products: - Incremental RESCI when buying from the cheapest 25% of vendors - Incremental RESCI when drawing from the product population that shouldn't have passed QA - Incremental RESCI when buying on AliExpress or random sites - Incremental RESCI when dropping, hitting with a hammer, leaving in the sun, subjecting to a power surge - Incremental RESCI from living in a dense neighborhood where dense people are buying from the cheapest 25% of vendors on AliExpress, occasionally dropping or hitting with a hammer, etc. In the West, we have about a buck's worth of experience with residential electric service. By many measures, it's still much more dangerous than it should be. reply DaoVeles 21 hours agoparentWith a lot of new chemistry the risk of fire is greatly reduced. It seems to be an issue mostly with lithium based systems. Things like Iron or sodium based are much safer, energy density is also lower because of this but it is a reasonable trade off. Also tend to have much greater life time charge cycles. Potential to go tens of thousands of cycles rather than just a thousand or so. reply rootusrootus 20 hours agorootparent> an issue mostly with lithium based systems. Things like Iron or sodium based are much safer The iron battery you are thinking of is a lithium battery. It is not the lithium that is a fire risk; lithium ion batteries do not contain metallic lithium. In an LFP battery the phosphate-oxide bond is much more stable and not subject to thermal runaway compared with e.g. cobalt-oxide. reply DaoVeles 16 hours agorootparentThat sounds much better than the dribble I was spouting. Thanks! reply DennisP 4 hours agorootparentThere's also someone building a factory to make iron-air batteries for grid storage. They're way cheaper than lithium or even sodium, with one of the most common materials on the planet, but only about 50% efficient. They're too heavy for vehicles, and have lower power output so aren't much good as peakers, but if you want four days of grid backup like we'd need with a 100% wind/solar grid, they're great. https://formenergy.com/technology/battery-technology/ reply ChuckMcM 13 hours agoprevI really appreciate folks who include their reasoning with their argument as it makes it possible to evaluate their conclusions through external sources. So hats off here. One of the things that helped solar take off in California (besides subsidies) was being 'grid tied' relieved you have having to manage all the battery technology. Initially this led to some effective rate plans (trading watts for watts) but once the power companies realized the lack of profit on selling power was affecting their ability both maintain infrastructure AND pay off their monetary judgements levied by courts for blowing up towns and burning down forests they managed to get the CPUC to switch to a model that turns home owners with Solar into sharecroppers for the power company[1]. On the plus side this is rekindling the interest in being 100% \"off grid\" as that removes the power company leverage and puts pricing control back into the market/consumer's hands. What I find interesting is that now I am starting to hear rumbles about how the power company wants to use consumer and commercial building \"whole building\" power systems as back up for the grid in peak power consumption emergencies that would mandate being tied to the grid even if you didn't \"need\" to be. I have been writing diligently to representatives that I refuse to let the CPUC tell me what I have to sell power back to the power companies to sustain the grid in emergencies and reserve the right to charge what ever the market will bear. It's a bit Texan in its dysfunctionalness but my goal is to encourage zero carbon emission home power grids faster, and driving the existing power companies out of business will assist in that endeavor. Batteries are a huge part of that and if the author is correct that we can get to $1/kWh batteries by 2030 I feel like I will live to see it which makes me happy. [1] Am I bitter? What make you say that :-) reply icapybara 22 hours agoprevI'd rather hear a projection from an engineer/scientist/operations person in the industry. This kinda reads like it's written by an armchair expert who thinks about batteries a lot, but doesn't have much to do with building that future being described. Sometimes the technical details matter and projected scaling trends aren't an inevitability. reply tux3 22 hours agoparentIt does seem to be written by someone who's very far above the ground — even managing to throw the blockchain in there at the end. But the point they're making is reasonable. Just because the author isn't deeply technical doesn't mean they can't fit an exponential and extrapolate correctly. Exponential growth always has to stop somewhere, but that's not in and of itself a reason to think this year is the year that it will. The napkin math about sodium and battery cost is at least reasonable, it's worth considering seriously rather than handwaving the author away as not an engineer. reply icapybara 22 hours agorootparentFair. I guess I have an issue with technology projections that assume the technology will follow some fit, because it always has. Every bit of progress is made with tons of risky work and breakthroughs, and none of it is guaranteed like you would think it is just by looking at a fit. reply XorNot 15 hours agorootparentprev> they can't fit an exponential and extrapolate correctly. Anyone fitting an exponential isn't extrapolating correctly pretty much by definition. As you note: > Exponential growth always has to stop somewhere, but that's not in and of itself a reason to think this year is the year that it will. This is a god of the gaps argument. There's no reason it should stop this year, there's also no reason it shouldn't. Fitting the curve is only useful if you're actually presenting an argument as to why for the relevant interval it should continue. reply Dylan16807 9 hours agorootparentThere's plenty of reasons it shouldn't end this year. Go look at the battery sizes that we need to switch halfway to electric cars and to stabilize the electrical grid. Looking at what happens if growth continues until we get into that range is quite reasonable. reply iSnow 7 hours agorootparentprev>Fitting the curve is only useful if you're actually presenting an argument as to why for the relevant interval it should continue. Which he actually does by looking at sodium batteries. reply mcswell 18 hours agoparentprev> projected scaling trends aren't an inevitability Reminds me of a projection I read back in the early 1960s (I think). The author charted the rise in speed of human beings over ten or twenty thousand years, where that speed had increased when horses were tamed, clipper ships were built, steam trains invented, automobiles, airplanes, and then rockets. (Assuming this was just after Gagarin, that got \"us\" to 5 miles per second.) He pointed out that the acceleration was (ahem) accelerating, with thousands of years between humans running and horses being domesticated, vs. about sixty years between the Wright brothers and Gagarin. Extrapolating, it was clear we would exceed the speed of light (using a warp drive or something) by the year 2000. Of course the current record speed was set in 1968 at about seven miles per second, and not even equaled since 1972. So much for extrapolation. reply jtbayly 22 hours agoparentprevHe claims the expert estimates have been wrong every year (too conservative). reply marcosdumay 22 hours agorootparentTo the extent that have been expert estimates out there, they do have been consistently wrong. The same happens to solar and wind generation. But well, I haven't seen any that don't have a conflict of interest into claiming fossil fuels will continue to be required. And that's a large part of the problem: you just won't find uninterested experts publishing estimates. reply XorNot 15 hours agorootparentWell the other issue though is that people looking for predictions want conservative predictions because they're investing. Over-estimate and you lose money, under-estimate and you leave money on the table but don't trade away future possible gains. reply marcosdumay 3 hours agorootparentHum... People investing in renewables and batteries do not use predictions. Those have at most some 3 years of building time, usually a few months. People investing in fossil fuel plants need predictions, and despite they wanting to see conservative numbers, that bias means complete doom for them. They need the opposite bias if they want to survive. Things get a lot more complex once you start to look at components industries. But then, it's not clear they use predictions for anything. reply jillesvangurp 22 hours agoparentprevAnd sometimes an exponential is staring you in your face and you just don't realize it. This has happened before. Early computer scientist did not imagine anything like you and I take for granted and put in our pockets without thinking about it every day. That's only a generation or so ago. Two if you are half my age (50). IMHO, the theme of this century is making cheap, sustainable energy so ridiculously abundant that we'll be wondering what the hell we were doing before and how we managed without it. There are so many technological breakthroughs converging on making that happen that IMHO this is just going to happen. It's a question of when, not if. The timelines are uncertain, but not really. The author of this article is extrapolating a few trends over a time scale that is rather short. He could be wrong. Even by a factor 5. And it would still happen on a reasonable timeline. And I don't think he's going to be that far of the mark. 2030-2035 it will be RIP ice engines and fossil fuels. You'd be out of your mind to use anything else than dirt cheap electrons stored in dirt cheap batteries. At 50$ per kwh, it's a no brainer. At 5$/kwh, you'd have to be bat shit crazy to use anything else. That's 'only' a 10x improvement. Assuming all innovation grinds to a halt in 2024 and that no technical progress will happen beyond 2024 seems like the naive point of view when there's so much happening that is well funded and seemingly on track to get some kind of results. The opposite view on this is of course that progress is a foregone conclusion. Some things will taper off and other things we haven't even thought off might pick up the slack. Between now and 2030, you can make a few educated guesses though. Which is what this author is doing. Anyway, cheap, clean energy is transformative. Most of the major challenges right now are directly or indirectly bottle necked on energy. Making energy cheaper matters. 2x is nice. 10x is nicer. 100x is what we might actually see in a few decades. Anything in between would be transformative. Anything beyond that is hard to imagine but yet not unlikely. We might actually nail fusion at some point. Who knows? It might even become cheap to do it. But we have a nice fusion plant that we orbit around beaming down orders of magnitude more energy than we actually need. We're learning how to harvest it using solar panels; a trick plants and trees have of course mastered ages ago. This article is about leveraging batteries for storage. The two things combined are a thing of beauty. The point about sodium ion is that there are no exotic/scarce materials in there. The materials are cheap. And we're not going to run out of them. How many twh. of battery could we need. Tens, hunders, thousands? We only use about 25pwh per year worth of electricity right now. That number is going to go up of course. What would you do with 25000 twh of battery? Annual production is about to cross the 1twh/year. And most of these batteries last a few decades. 25pwh of charged batteries is a lot of power. And yet we might have that sitting around in a few decades. reply pfdietz 23 hours agoprevHe projects (at current growth and experience rates) that battery cells will reach $8/kWh by 2030. Wow! reply DennisP 4 hours agoparentBut with several math errors, which make him off by a decade. He multiplies by 1.59 annually and gets a 25X increase in total battery in seven years. That actually takes eight years, but whatever. Then he says that's eight doublings, but eight doublings is a 256X increase. That would take nine years at 100% annually (first year to go from 1 to 2, then 2^8=256). But we only have a 59% annual increase so getting to 256X takes about 13 years. He also seems to be off by one in the cost reduction. At 25% per doubling it takes nine doublings to get to 10% of the current price. So add another year or two to get to $8. It's still interesting that we could get to $8/kWh by 2040 or so, especially since it seems physically plausible that sodium batteries could get that cheap, and that we could build several days of grid storage using them. And by 2030 we still get a cost drop of almost two-thirds, down to $28/kWh if we accept his claim of $80/kWh in 2023. reply pfdietz 3 hours agorootparent> He multiplies by 1.59 annually and gets a 25X increase in total battery in seven years. That actually takes eight years, but whatever. (1.59)^7 = 25.69 But yeah, not eight doublings. I guess we'll have to wait another four years then :). reply ss64 23 hours agoprevThe cost of 50AH Li-Ion batteries is getting close to the point where they may start to compete with Lead acid for gas powered cars. reply Aurornis 22 hours agoparentLithium batteries still have limitations with charging at low temperatures. OEMs can design systems that will warm the battery up to a temperature where it can be charged after the car is started, but it’s not nearly as simple as dropping a lead-acid battery in. reply ssl-3 22 hours agorootparentIt isn't that simple today, but it can be. Integrate the new-fangled battery (of whatever specific chemistry), the BMS, and the heater into a box with just two posts on top (just like lead acid batteries have had for over a century). It can be designed to take care of itself. And if it's cheap enough to produce and sell, and offers good enough performance over its normal usable lifespan, then it doesn't need a diagnostic interface for sorting out issues any more than a lead acid car battery does today. reply mcswell 18 hours agoparentprevMost (not all) EVs still have a 12 volt lead-acid battery: https://www.caranddriver.com/features/a38537243/electric-car.... I understand 12 volts, but why not a 12 volt Li battery? I don't know. reply silverquiet 22 hours agoparentprevI looked at it and couldn’t find any that offered enough cranking amps. I’m not sure how easy it would be to design a lifepo4 battery for the application. reply Panzer04 19 hours agorootparentLithium batteries are more than capable of starting cars, and at a fraction of the size (just look up \"car starters\" and the like on Amazon - those are usually a tiny lithium battery that you pull 50c from). The thing is they are usually much pricier for an equivalent size battery and have problems in the cold that make them unsuitable in some climates. reply rootusrootus 20 hours agorootparentprevThere are some out there. The one that comes to mind is Dakota Lithium. They have a few options with 1000 CCA. reply rgmerk 18 hours agoparentprev“The cost of gasoline is coming down to the point where gasoline-powered lanterns may become the lighting of choice for carriages”. reply catlikesshrimp 23 hours agoparentprevThe environment be damned: Regarding price / energy density, yes. They even have weight / energy density advantage. But Lithium batteries can't be recycled. Saying \"We are almost there\" and \"The future looks bright about it\" is \"moving fast and breaking things\" again reply mrob 22 hours agorootparentRecovering lithium from batteries is not cost effective compared with mining new lithium. However, battery recycling is possible and still worth doing, because it recovers more valuable metals such as cobalt or copper. reply oulipo 11 hours agorootparentAnd before recycling, reusing! This is why at https://gouach.com we've built the first easy-to-repair, easy-to-swap-cell battery! We're launching a Kickstarter soon, stay tuned (on our newsletter!) reply philipkglass 22 hours agorootparentprev\"Green Li-ion Marks the Opening of its First Commercial-Scale Lithium-Ion Battery Recycling Plant in Oklahoma\" https://www.businesswire.com/news/home/20240618645137/en/Gre... reply catlikesshrimp 21 hours agorootparentI was wrong for posting what really means \"technically not possible\" The real barrier for recycling waste is sustainability. This is the reason why e.g. TETRABRIK is considered recyclable, but it is actually not (I am posting about this parallel because it has been completely understood for several years) Anything can be recycled if we are pedantic. But will it actually stop generating waste? (or will they be silently exported ignored?) Will subsidies be sustainable? (not it even asking if it can be profitable) In reality, the \"recyclable\" brand is for the most part greenwashing. Now, the business ad about a venture capital bussiness you posted is nothing new. Last year there were 5 such touted recycling plants in Latin America, already. One of them is located in Costa Rica. Costa Rica doesn't have a Lithium battery waste issue. There, the electric cars are very few (and people who got them already want out), there are no electricity storage facilities. I am guessing here that they will import a ton (hundreds of tons) of waste from \"Somewhere else\" I am including an article on battery recycling that is easy to read. It is only 40 pages long. https://archive.ph/wip/XB8hw And, for more downvotes: Lithium batteries are as recyclable as a TETRAPAK: still generating waste, most of the time all of it ends up as waste. reply bryzaguy 22 hours agorootparentprevI thought they could be recycled but at the moment it’s cheaper to mine. Is that not true? reply robocat 22 hours agorootparentprevLead Acid batteries must get replaced every few years. An equivalent LiIon battery would not need to be replaced so quickly. So at some crossover point the environmental cost of X * recyclable Lead acid batteries is higher than LiIon batteries. reply catlikesshrimp 21 hours agorootparentAbsolutely. Lead acid will be replaced with another chemistry. My concern is only about the environment. I developed the post some more https://news.ycombinator.com/item?id=40878252 reply justahuman74 22 hours agorootparentprevThey can be recycled, its just currently more expensive than the post-product reply jjoonathan 22 hours agorootparentprevThey can absolutely be recycled, lol. reply xbmcuser 17 hours agoprevI have been predicting over the last year that with many US and European manufacture suddenly giving up on ev growth rate and feed in tariff for solar not getting a good price. The next big thing is going to be home batteries. Looking at what Tesla is charging for powerwall and the actual materials cost which are still dropping people will start trying to get in on these margins. reply richardw 21 hours agoprevI think this underestimates the benefits of focus and serendipity and new materials. There’s a non zero chance that grid scale fixed batteries get made from things like sand or liquid metal or (insert cheap thing you can heat here). Claims of 10 euros/kwh, months of energy storage: https://thenextweb.com/news/startup-sand-battery-funding-pol... How big a battery can you make when it’s made from sand? The trick with grid is that because you’re building at scale, you can give the benefits to many in one shot and you can build it out of town. Think Australia’s original big battery from Tesla in 90 days vs. messing with installing lots of little ones in houses, with all the maintenance, education and dangers that brings. reply ZeroGravitas 9 hours agoprevThe mention of Blockchain threw me off but I generally agree with this analysis. Worth remembering that even enthusiastic supporters of the energy transition have underestimated the historical trends in wind, solar and batteries. It's just hard to comprehend the S-curve ramp. reply k8sagic 19 hours agoprevI thought a few years back already that owning a bigger house will be cheaper than ever due to the progress of cheap renewable energy, cheaper and cheaper heat pump technology and batteries. Nice to see blog reply aitchnyu 12 hours agoprevTangential, whats the low energy distributed ledger tech he's talking about? reply iSnow 7 hours agoparentProbably he wasn't talking about a concrete solution, but Powerledger on the Ethereum chain or EWT token on Gnosis. reply tuatoru 17 hours agoprevOnce material costs fall far enough, other costs start to dominate. Design and permitting, sales and marketing, transport, finance and insurance, installation, support structures, safety systems, interconnections (wires), converters and so on. $11/kWh seems optimistic for 2030. reply bilsbie 17 hours agoprevI think it would be cool if appliances started coming with batteries. You could give them times of day to charge, and to not use the outlet. And they could work in power outages. reply ineedaj0b 17 hours agoprevthis might not be the right thread to ask this question, but I have an older car and the battery inside went. In the past the battery was $50 to replace. Post-COVID, it runs for a whopping $250 at most automotive places... sometimes cheaper on sale. So why not swap it out for a lithium battery (which still run around $50)? Are there any downsides beyond rewiring the connector types I'm not aware of? *the battery type is 51R reply shagie 17 hours agoparenthttps://camelcamelcamel.com/product/B0013ZGZ9Q?context=searc... The price jump from $150 to $250 was in 2017. --- I have a hybrid car - it has both a traditional lead acid battery and a lithium ion battery. And while I also have a lithium ion jump starter battery, they have issues in many situations that make them ill-suited for a cranking starter battery. https://www.batteriesplus.com/blog/power/lithium-starting reply JumpCrisscross 22 hours agoprev“…this is also an area where distributed ledgers with low energy requirements (so not Proof of Work but Proof of Stake) could shine by creating an ‘trustless’ system (meaning the system justs works, also if there is no ‘trusted’ party that plays the boss).” What? This bit at the end has nothing to do with the thesis! Carthago delenda est much? reply sholladay 20 hours agoprevLowering cost per kWh is great, but if power demand increases at about the same rate or faster, then the impact is minimal. Cost per bit of internet plans has also gone down a lot in the past decade, but you’d be forgiven for not noticing on account of all the new JavaScript, ads, and other website bloat. Using less exotic materials is exciting, though! Regardless of whether the cost feels different. reply louwrentius 20 hours agoprevI have 4 x 230Ah LiFePo4 cells in a 12 volt setup to power my solar powered blog during the night. It also runs my computer setup at 90W for many hours using an inverter. People should really understand how cheap these cells have become and how feasible it is to setup your own battery storage system. I’m now on a variable (next-day / day-ahead) dynamic electricity tariff that changes by the hour. On some days there are multiple hours where I get Paid to use electricity, it’s crazy that we have such an abundance of wind and solar. It’s such fun to play with the Tiber API + Python and using those cheap hours to charge my battery a bit, while leaving room for solar. reply SergeAx 10 hours agoprev> stormy electricity grid For me (living in Europe), stable 220V 50Gz from any wall socket is one of the traits of civilization, like potable water tap and flush toilets. \"Stormy grid\" is something from a rural village lifestyle, with a water well and a cold basement to keep winter food supply. Is it really that huge problem in parts of US? reply throwawayffffas 7 hours agoparentThere were a couple of large scale very long outages in Texas due to very bad weather in the last few years that made the news even on this side of the Atlantic. reply gorgoiler 23 hours agoprevWhat level of subsidy do we give to batteries? reply bee_rider 22 hours agoparentSurely it depends on what country you live in. Battery subsidies are mostly local at least. How do we even calculate the subsidy paid to fossil fuel companies by letting them externalize the cost of their mess onto the planet? Oh well that’s for young people and future generations to care about! reply gorgoiler 21 hours agorootparentThanks for fleshing out my quickly written question. I didn’t really mean anything by it, just that I think it’s an important factor that’s overlooked in the linked article. The most useful idea to think about here, for me, is not what the raw market of economics batteries might be. Rather, the societal good that there would be if the state stepped in and just made batteries infinitesimally cheap for everyone. The state provides a lot of things that lubricate society: just as they send electricity to our homes, provide a central bank for the economy, schools for our children, and courts to mete out justice — so too could they potentially ensure every citizen has X number of 18650 cells (or future equivalent) available to them to use as they see fit. reply sanxiyn 21 hours agorootparentprev> How do we even calculate the subsidy paid to fossil fuel companies by letting them externalize the cost of their mess onto the planet? I know this was rhetorical, but the standard method in the literature is Optimal Taxes on Fossil Fuel in General Equilibrium (2014). https://doi.org/10.3982/ECTA10217 reply epups 20 hours agoprev> If we start with 2410 GWh in 2023 and grow with 59% per year that gives us 61.917 GWh in 2030. That would mean almost exactly 8 doublings in 2030. For context, the global electricity consumption in 2019 was around 23 TWh [1]. [1] https://www.iea.org/reports/electricity-information-overview... reply drozycki 19 hours agoparent23000 TWh, or 23 PWh according to your link reply martythemaniak 23 hours agoprevCurrent prices are kinda nutty and are largely determined by the size of your buy. Retail prices for home batteries (a few kWhs) are roughly $1000/kWh. A Model 3 gets you about $700/kWh (with two free motors and an ipad). A Tesla megapack is $290/kWh, but you have to spend $1000000 to get that price. Tesla probably gets cells from the factory at round $80-$90/kWh. Long-term it seems pretty reasonable that retail prices should be a small multiple of the factory price (which keeps decreasing), so I think $1000 for a 20kWh battery is totally reasonable. reply justahuman74 23 hours agoparentAt $1k for 20kw/h, I'd be very tempted to massively over-panel the roof and front/back yard on pergolas, install 200kwh of battery and never deal with pg&e again reply huijzer 22 hours agorootparentExactly. This is what Tony Seba is talking about for 10 years already! He talked about this in his 2014 book Clean Disruption of Energy and Transportation. reply NooneAtAll3 22 hours agorootparentprevwhat's pg&e? reply oblio 22 hours agorootparentUtility company somewhere in the US. reply fragmede 22 hours agorootparentprevThey are the utility company that covers most of California. They recently raised rates and customers are unhappy. They are a for-profit and their lack of spending on maintenance has caused a number of fires which has killed people, leading them to be unpopular, among other reasons. reply lanstin 21 hours agorootparentThey killed people thru giant fires exacerbated by climate change then get sued and pay billions of dollars in restitution and then raise the rates for the regular folks. reply mperham 21 hours agorootparentprevA source of very expensive electricity in California. reply jonathanlydall 22 hours agoparentprevUSD 1,000 per kw/h seems very high to me. A couple of years ago here in South Africa I paid about ZAR 30,000 (USD 1,650) as a consumer for a 5kw/h battery, and I just checked online now, I can apparently get a similar battery for half that: https://www.ecohub.co.za/shop/solar-power/lithium-batteries/... reply hgomersall 22 hours agoparentprevIn the UK you can buy a battery at £160/kWh, complete with BMS and thermal management: https://www.fogstar.co.uk/collections/solar-battery-storage/... For less than £130/kWh if you're willing to build it yourself, you can get a slightly less capable setup: https://www.fogstar.co.uk/collections/solar-battery-storage/... reply foobazgt 21 hours agoparentprevAt $6343 [1] for 13.5kwh [2], seems closer to $500/kwh? The federal rebate does help substantially, but most folks should qualify. This # is closer to $400/kwh if you buy with solar, and $300 if you're buying a few instead of just one. Re: car batteries, the difference between the rear-wheel drive and long range is about 20kwh (60kwh vs 80kwh), for $8K. That's $400/kwh and doesn't even include all the other trim differences like having dual motors instead of single. So, it looks like reality is closer to $300-$400/kwh, depending. Not close to your ideal of $50/kwh, but still much better than $1000/kwh. 1) https://www.tesla.com/energy/design/overview 2) https://service.tesla.com/docs/Public/Energy/Powerwall/Power... reply XorNot 15 hours agorootparentThis is asking the wrong question. The question is what is the cost per kWh of electricity delivered from that battery, which is not the cost per kWh of capacity installed (though it is related). You have to charge the battery with electricity (which you could sell or have to buy), and then when you discharge it you are either offsetting electricity you would buy, or selling it. Throughout the process you're losing some of it (~8%), and the battery is degrading in capacity towards eventual replacement. You also have black swan events - i.e. an early battery death due to manufacturing defects. i.e. my rooftop solar array sells power at 7c / kWh. When I run the numbers on various offset scenarios, the cost per kWh delivered after all expenses and life time costs that I can find tends to be about 7 - 8 c / kWh. Which honestly makes perfect sense to me: the electricity company, at much more massive scale, can install and run batteries more cheaply then I can. reply rootusrootus 20 hours agoparentprev> Retail prices for home batteries (a few kWhs) are roughly $1000/kWh. Do you mean the installed price? Including inverters and such? $1000/kWh is more than 4x what you can buy LFP batteries for off Amazon. reply GaggiX 23 hours agoparentprev>Tesla probably gets cells from the factory at round $80-$90/kWh. Where I live there is a warehouse where you can withdraw new MANYI Lifepo4 cells at around 97€/kwh (a single cell) after contacting the seller on Alibaba, so I'm guessing Telsa is getting them at 80 or even less. reply 9 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Lithium iron phosphate (LiFePO4) batteries for home use are currently priced at $89/kWh from reputable Chinese suppliers, with an additional $30/kWh if purchased in the US.",
      "Sodium batteries are available at $130/kWh but are 26% less efficient compared to LiFePO4 batteries.",
      "The post highlights the affordability and efficiency of solar panels and batteries, with some users successfully transitioning their homes to solar power and battery storage, reducing reliance on traditional power companies."
    ],
    "points": 276,
    "commentCount": 268,
    "retryCount": 0,
    "time": 1720120825
  },
  {
    "id": 40880932,
    "title": "I have no constructor, and I must initialize",
    "originLink": "https://consteval.ca/2024/07/03/initialization/",
    "originBody": "Jul 3, 2024•c++ I Have No Constructor, and I Must Initialize It has been three days. The room is cold and dark, but your screens are blinding. You feel disoriented as you come in and out of dissociative episodes. Now and again, you laugh, to no accompaniment. Why are you here? Was this your fault? Your first mistake was to engage—this much is clear. Back when I took a first course in C++ a few years ago, I was taught that, under certain circumstances, the compiler would provide some kind of defaulted constructors in case we don’t provide our own. Curious to know more, my primary concern was with cases like this: struct T { /* ... */ }; T t; T s{}; T r{arg1, arg2, ...}; I became interested in the particulars of what this meant. Most of my focus fell on the first two—for the third, I felt satisfied with a hand-wavy explanation of “if T is simple enough, it’ll do component-wise initialization.” The first two are where the danger lies, after all: what if some objects are left uninitialized? The search looked something like what follows. Primarily, there are two kinds of initialization of concern: default-initialization and value-initialization. The rules given in the standard look roughly like this: For any type T, T t; performs default-initialization on t as follows: If T is a class type and there is a default constructor, run it. If T is an array type, default-initialize each element. Otherwise, do nothing. For any type T, T t{}; performs value-initialization on t as follows: If T is a class type… If there is no default constructor (i.e., if the user has declared any non-default constructors) or if there is a user-provided or deleted default constructor, default-initialize. Otherwise, zero-initialize and then default-initialize. Otherwise, if T is an array type, value-initialize each element. Otherwise, zero-initialize. You can see each of these in action here: struct Pair { int x, y; Pair() : x{0}, y{1} {} }; struct SimplePair { int x, y; }; int x{}; // value-initialized => zero-initialized int y; // default-initialized (to garbage) Pair p; // default-initialized => default-constructed Pair q{}; // value-initialized => default-initialized => default-constructed SimplePair r; // default-initialized => default-constructed to garbage (more on this later) This leaves for discussion the default constructor, i.e., the zero-argument constructor overload. What does the compiler provide us and when? It’s generally common knowledge that, so long as you don’t declare any of your own constructors, the compiler will declare and (possibly) provide its own. But, the devil’s in the details after all—and C++ has a terrifying quantity of details, which bears some implication on the exorcist’s nightmare contained therein. The Default Constructor When you don’t declare any constructors, the compiler will declare a default constructor for you: this one is called implicitly-declared. There’s also the almost-identical “defaulted on first declaration” constructor—almost-identical in that they’re mostly interchangeable in the standard, it looks like this: struct T { T() = default; }; These constructors don’t necessarily do anything by virtue of being implicitly-declared or defaulted on first declaration—after all, they’re only declared so far—but there are knock-on effects which will affect what they do. In particular, if a default constructor is implicitly declared or explicitly defaulted (and not defined as deleted), an implicitly-defined default constructor will be provided by the compiler. In terms of implementation, it’s guaranteed to be equivalent to a constructor with an empty body and empty member initializer list (i.e., T() {}). So, if we did something like this: struct T { int x; T() = default; }; T t{}; std::coutconstructor overload—recall that such overloads take priority in overload resolution, and a braced-init-list of Ts can be interpreted as std::initializer_list. struct T { T(std::initializer_list) { std::coutconstructor overload is defined (like above), in which case GCC uses it instead of eliding—I understand this to be a single corner case where GCC does the right thing. I expect this whole thing will be cleared up eventually—see CWG issue 2311. Anyway, for a parenthesized initializer, if this elision provision doesn’t apply, constructors are considered as you would expect; if there are none and T is an aggregate class, it’ll do per-element copy-initialization as discussed earlier. One last nugget: elements of parenthesized initialization lists have no guaranteed evaluation order, whereas braced initialization lists evaluate elements strictly from left to right. That should be most of it. I mean, there are special initialization rules for static variables (constant initialization included), but, like, do you really care? In my humble opinion, here’s the key takeaway: just write your own fucking constructors! You see all that nonsense? Almost completely avoidable if you had just written your own fucking constructors. Don’t let the compiler figure it out for you. You’re the one in control here. Or is it that you think you’re being cute? You just added six instances of undefined behaviour to your company’s codebase, and now twenty Russian hackers are fighting to pwn your app first. Are you stupid? What’s the matter with you? What were you thinking? God. ❦",
    "commentLink": "https://news.ycombinator.com/item?id=40880932",
    "commentBody": "I have no constructor, and I must initialize (consteval.ca)240 points by cyber1 10 hours agohidepastfavorite122 comments marton78 7 hours agoAfter almost 20 years of experience with C++, there are still some gnarly details I wouldn't have imagined. What a God awful language! Kudos to that author for the great, eye catching title and the in depth detail! reply wavemode 6 hours agoparentAlways obligatory https://mikelui.io/img/c++_init_forest.gif reply CoastalCoder 5 hours agorootparentThanks, I'd never seen that one! So horrifyingly true. reply fouronnes3 3 hours agorootparentIf you enjoy this, a few years ago I made the \"C++ iceberg\" meme (with clickable links!). I've been thinking about making an updated V2 with all the \"you forgot about X\" messages I've been getting. https://fouronnes.github.io/cppiceberg/ reply CoastalCoder 16 minutes agorootparent> If you enjoy this Well, I do appreciate your work, and the information is certainly helpful. But it's a bit like a urologist explaining what it will be like when you pass a kidney stone. And then find out that the C++ standards committee is working on a new kidney-stone shape that's backwards compatible, but adds more jagged spikes. reply throwup238 2 hours agorootparentprevGod bless you for making this. I plan to incorporate several of these features at work in the hope of summoning Cthulu and killing the company once and for all. What's your favorite \"you forgot X\"? You should definitely make an updated v2 because every link I've opened from the bottom half has been absolutely bonkers. Three dimensional analog literals drawn using ASCII? What the flying hell was the standards committee thinking. reply java-man 1 hour agorootparentprevelse while is perfectly fine, not only in c++. reply unwind 6 hours agoparentprevIn case it's not known to everyone, the title is an obvious nod to \"I Have No Mouth, and I Must Scream\" [1], a 1960s US sci-fi story by Harlan Ellison. 1: https://en.wikipedia.org/wiki/I_Have_No_Mouth,_and_I_Must_Sc... reply bookofjoe 4 hours agorootparenthttps://talesofmytery.blogspot.com/2018/10/harlan-ellison-i-... reply _vaporwave_ 1 hour agorootparentprevThat plot summary is... dark. Does anyone know how long the story is? Most of the copies I found online are collections of short stories. reply neckro23 1 hour agorootparentIt's a short story, a brief one (~32 kB): https://gist.github.com/neckro/0f3a9ec60be34e3164c6677d4ecc1... CW though, it is pretty grim. Very early example of the \"AI takes over the world, decides humans are redundant\" trope though. (Maybe the first?) reply GuB-42 4 hours agoparentprevC++ is a popular multi-paradigm language that is both cutting edge and 40 years old (more if you count C), there is simply no way around that level of complexity. You have \"C with classes\" that coexist with the \"modern\" way, full of smart pointers and functional programming. It is popular in embedded systems, video games, servers, and GUIs (mostly Qt). And if you look at the code, it is as if it was a different language, because the requirements are all very different. Embedded system need low level hardware access, video games are all about performance, servers want safety, and GUIs want flexibility. There are less awful alternative to C++. For example C on one end of the spectrum and Rust on the other end. But none of them cover every C++ use case. reply bee_rider 2 hours agorootparentC++ needs a different name from multi-paradigm. Java is a multi-paradigm language. C++ is an omni-paradigm language. If there’s a paradigm, - There’s at least an ugly library to do it in C++ - There might be support baked directly into the language - Or you could do it in Lisp, but that would be too easy reply codeflo 57 minutes agorootparentAnd if you dare to combine two of the paradigms it supports, you get UB. reply marcosdumay 2 hours agorootparentprev> multi-paradigm Well, it does unstructured imperative, structured imperative, and OOP imperative! Except if you count template programming, because that one is pure functional, but only runs at compile time. reply slashdave 1 hour agorootparentprevI would sort of agree, except when c++ was invented, it was even more awful in practice (does anyone remember the chaos around STL and template caches?). So, age isn't really a factor. reply aaroninsf 1 hour agorootparentprev> But none of them cover every C++ use case. Literal lol... this is not an argument in favor of C++. reply hu3 2 hours agorootparentprevZig looks promising too. reply ghosty141 4 hours agoparentprevI've been working with C++ at my job for 2.5 years now and I've already come to this conclusion. Wouldn't wanna use it if there is any other way. The fact that you can do almost anything IS pretty cool, but without having at least one C++ wizard at hand it can drive you nuts. reply philsnow 3 hours agorootparentI don’t think I’ve ever gotten paid for a line of c++ but Google has a “style guide” for internal c++ code that omits something like 3/4 of the language, and people seemed pretty happy with it overall. Maybe not “happy” but “grudgingly accepting because it beats the Wild West alternative”. reply marcosdumay 2 hours agorootparentC with classes and text-template generics would be an ok subset of the language, if external concepts didn't keep creeping into its semantics. The problem is that they do. Almost every part of C++ creeps into almost every other part, and C was already complex enough... and let's just ignore that C++ is not completely compatible with C. reply fsckboy 3 hours agorootparentprevis google's \"internal\" style guide this? https://google.github.io/styleguide/cppguide.html reply JasonSage 3 hours agorootparentNit: parent didn't call it an internal style guide, but a style guide for their internal C++. (I'm sure it is.) reply fsckboy 14 minutes agorootparentNit nit: I don't accept your quibble, I think my usage was well within English usage standards; I even put \"internal\" in quotes! Consider this hypothetical conversation: \"Is the style guide they use for internal projects the same as this style guide that they have published externally?\" \"could you clarify which ones you're talking about?\" \"Is the internal style guide you described the same as this one I found in google's account on github?\" \"oh, I see what you mean\" will you send your second, or shall we simply pistols-at-dawn? reply ryandrake 4 hours agorootparentprevJust another person’s opinion: I’ve been using C++ for my entire career, and to be honest, if I’m starting a new solo project, I reach for it unless there is some major technical reason not to. Yes, it can be messy. Yes, there are footguns. But as a developer, you have the power to keep it clean and not shoot the footguns, so I’m still ok with the language. If I was starting a new work project with a lot of junior team members, or if I was doing a web project, or a very simple script, fine I’ll use a different language. There can definitely be good reasons not to use C++. But I’m at the point in my expertise that I will default to C++ otherwise. I’m most productive where I am most familiar. reply kmoser 3 hours agorootparent> Yes, there are footguns. But as a developer, you have the power to keep it clean and not shoot the footguns, so I’m still ok with the language. With all due respect to your expertise, the whole idea of a footgun is that it tends to go off accidentally. The more footguns a language contains, the more likely you are of accidentally firing one. reply jeffbee 2 hours agorootparentI think what he's saying is that C++ users don't need to go to the Footgun Outlet Mall and wantonly brandish each of their credit cards. You can leave the subtle parts of the language on the shelf, in many cases. reply alex_lav 1 hour agorootparentprev> I’ve been using C++ for my entire career, and to be honest, if I’m starting a new solo project, I reach for it This is “I use the language I always use because I always use it”, and not actually a praise or C++ specifically. reply 725686 2 hours agorootparentprev\"you have the power to keep it clean and not shoot the footguns\". Really? Do you think footguns are intentionally shot? reply bee_rider 2 hours agorootparentWhat even is a footgun supposed to be? The analogy doesn’t really make sense, in that… I mean the first thing anybody learns about guns is that they are “always loaded” (even when you know they aren’t) and you only point them at things you want shot. Is a footgun a gun that only aims at feet? Because that seems like a dumb thing to invent in the first place. Or is it a gun that happens a to be aiming at feet? That seems like something that could only exist by user error. I think “enough rope to hang yourself” is a more accurate description of almost every programming languages, since rope is at least intended to be useful (although it is a bit more morbid of an analogy). reply rmwaite 1 hour agorootparentImagine that you had a gun and one of the features of the gun was that if you had sunglasses on and something in your left pocket, holstering the gun would cause it to immediately fire. You could argue that the gun shouldn’t behave this way, but it’s also possible that others are dependent on this behavior and you can’t remove it. This is a footgun - the way to avoid the holster firing is to simply not wear sunglasses, or keep something in your left pocket, and then it would never fire. But the problem is that both of those things are extremely common (for good reason). It’s a poorly thought out feature because it has severe consequences (potentially shooting your foot) for extremely common situations (wearing sunglasses and using your left pocket). reply bee_rider 1 hour agorootparentI basically don’t agree that anybody could depend on this holstering-causes-it-to-fire behavior. Or at least, their use-case requires design compromises that are so unthinkably ridiculous as to make the gun they want something that no reasonable person without that use-case would use. It is possible that the entire field of programming is full of ridiculous people. But it seems more likely that C++ is like a gun with no safety, or something along those lines. reply wvenable 53 minutes agorootparentprevYeah I don't think that's a good analogy. Instead, you have guns that don't let you point at your feet. So you can never shoot yourself there. However, if you ever need to shoot straight down for a legitimate reason, you're out of luck. In C++, you can shoot everywhere without restrictions and sometimes that means shooting yourself in the foot or the head. reply FreezerburnV 4 hours agoparentprev“There are only two kinds of languages: the ones people complain about and the ones nobody uses.” - Bjarne Stroustrup Not disagreeing that C++ is awful in a lot of ways and super difficult though. But I still weirdly like it, personally. I find it a fun challenge/puzzle to work with. reply diffxx 2 hours agorootparentI truly loathe that quote. It is a tautology that is used to deflect legitimate criticism. reply RogerL 38 minutes agorootparentAnd it is not true (for any reasonable reading of the quote). There are very popular languages that don't get the deserved hate that C++ does. Sure, Python is slow, packaging/versioning is painful, but it is nothing like C++ complaints. I mean, a standard (and stupid IMO) interview question is rate your C++ expertise from 1-10, and if you answer more than about 5-6 you get bounced for lying or not recognizing your limitations, while they gleefully point out Stroustrup wouldn't answer 9-10. reply umanwizard 3 hours agorootparentprevI think we can say Rust is beyond the “nobody uses” stage by now, and it’s much simpler and easier than C++. (And people who use it tend to like it, proving Bjarne wrong). reply saurik 2 hours agorootparentI'm sorry; you think people don't complain about Rust? There are tons of articles posted here from people complaining about Rust in various ways. Bjarne wasn't saying whether most people like it... that's orthogonal: I actually like C++, yet I have been complaining about it--at times quite bitterly--since before it was even standardized! reply tomjakubowski 56 minutes agorootparentIndeed, I am a huge proponent of Rust and have been using it since before 1.0 (even contributed to it, in the past) -- and I complain about Rust a lot, too. Trying to restate Bjarne's point here: if I wasn't using Rust, then I wouldn't have any reason to complain about it. reply dgfitz 28 minutes agorootparentprevRust is neither simple nor easy. Full stop. reply fiddlerwoaroof 3 hours agorootparentprevOr, because there’s so many languages around now, they just use something else. I really don’t like working with Rust myself and so I use other languages. reply alex_lav 1 hour agorootparentprevSaying people complain about something is not the same as saying nobody likes it… reply catlifeonmars 1 hour agorootparentprevI feel that if the language is a challenge to work with, it better give you your money’s worth. In 2024, there are plenty of other languages with better ROI, if you want a challenge. In any case, I think the primary goal of any programming language is to get out of your way and let you tackle more interesting problems related to the problem domain that led you to start writing a program in the first place. reply zarathustreal 4 hours agorootparentprevI find it annoying to have to solve a puzzle to make progress solving my intended puzzle (i.e. whatever I’m computing) reply queuebert 5 hours agoparentprevI should print this and put it on my wall for all those times when I'm frustrated with Rust lifetimes. reply amluto 1 hour agoprevI’m surprised there were no snarky comments about: > So, here’s the glue between list-initialization and aggregate initialization: if list-initialization is performed on an aggregate, aggregate initialization is performed unless the list has only one argument, of type T or of type derived from T, in which case it performs direct-initialization (or copy-initialization). The word “unless” is even bold. We have fancy syntax: T t{v0}; And we also have: T t{v0, v1}; And so on. But the one-element case does not reliably work like the 2+-element case. And this is in a language that increasingly works toward making it straightforward to create a struct from a parameter pack and has support for variable length array-ish things that one can initialize like this. And the types can, of course, be templated. So you can write your own constructors, and you can initialize a tuple or array with only one element supplied, and you might trip over the wrong constructor being invoked in special cases. I remember discovering this when C++11 initializer lists were brand new and thinking it was nuts. reply TinkersW 1 hour agoparentInitializer lists is irreverent, nobody uses it anyway. Other than a few standard containers that use it, you can completely ignore the silly thing. reply alex_lav 1 hour agorootparentAs is the nature of bad design, “nobody uses it other than some people sometimes” is a silly sentiment and indicative of a problem. reply hwc 4 hours agoprevI'm so glad I use Go more than C++ these days. In Go, all values are always zero-initialized if you don't explicitly assign a value. If you need a constructor, you write a regular function that returns an explicitly assigned object. I like keeping the rules of the language simple enough that there is never any confusion. reply javierhonduco 4 hours agoparentPersonally I’m not a fan of Go’s default zero-initialisation. I’ve seen many bugs caused by adding a new field, forgetting to update constructors to intialise these fields to “non-zero” values which caused bugs. I prefer Rust’s approach where one has to be explicit. That being said it’s way less complex than C++’s rules and that’s welcomef. reply kccqzy 24 minutes agorootparentThe problem you are describing in Go is rarely a problem in C++. In my experience, a mature code base rarely has things with default constructors, so adding a new field will cause the compiler to explain there's no default constructor for what you added, therefore avoiding this bug. Primitive types like `int` usually have a wrapper around them to clarify what kind of integers, and same with standard library containers like vector. However I can't help but think that maybe I'm just so fortunate to be able to work in a nice code base optimized for developer productivity like this. reply maccard 3 hours agorootparentprevI spent a year and a half writing go code, and I found that it promised simplicity but there an endless number of these kinds of issues where it boils down to \"well don't make that mistake\". reply gizmo686 3 hours agorootparentIt turns out that a lot of the complexity of modern programming languages come from the language designers trying to make misaked harder. If you want to simplyfing by synthesising decades of accumulated knowledge into a coherent language, or to remove depreciated ideas (instead of the evolved spaghetti you get by decades of updating a language) then fine. If your approach to simplicity is to just not include the complexity, you will soon disciplinary that the complexity was there for a reason. reply dgfitz 26 minutes agorootparentprevWouldn’t it just be considered bad practice to add a field and not initialize it? That feels strongly like something a code review is intended to catch. reply javierhonduco 18 minutes agorootparentIt’s easy to miss this in large codebases. Having to check every single struct initalisation whenever a field is added is not practical. Some folks have mentioned that linters exist to catch implicit initialisation but I would argue this shouldn’t require a 3rd party project which is completely opt-in to install and run. reply catlifeonmars 1 hour agorootparentprevFWIW there is a linter that enforces explicit struct field initialization. reply ErikBjare 4 hours agorootparentprevHaven't written Go in a long time, but I do remember being bit by this. reply crowdyriver 2 hours agorootparentprevYou can always use exhaustruct https://github.com/GaijinEntertainment/go-exhaustruct to enforce all fields initialized. If you care, the linter is there, so this is more of a skill issue. reply zarathustreal 4 hours agorootparentprevYea this can be problematic if you don’t have sum types, it’s hard to enforce correct typing while also having correct default / uninitialized values. reply thowruasdf 3 hours agoparentprevThe downside is now all types must dogmatically have a nullary constructor. The Default typeclass (or trait) as seen in Haskell and Rust, is a far better design, as this makes the feature opt-in for data types that truly support them. reply kccqzy 24 minutes agorootparentDon't even need to go that far. In C++ it is common to delete the default constructor anyways. So that achieves the opt-in. reply jeffbee 2 hours agoparentprevGo makes a completely reasonable tradeoff, giving away performance to gain ease of use. C++ also makes a tradeoff that seems reasonable or necessary to its users, that it makes it possible to not be forced to write to the same class member twice, in exchange for a more complex language. Any language that attempts to offer this property unavoidably adopts the complexity as well. See, for example, Java. reply gpderetta 5 hours agoprev> [...] The printed result would be 0. This is because we value-initialize t and, since T has a non-user-provided default constructor, the object is zero-initialized (hence t.x is zero-initialized) then default-initialized (calling the implicitly-defined default constructor, which does nothing). T̶h̶a̶t̶ d̶o̶e̶s̶n̶'t̶ s̶e̶e̶m̶ c̶o̶r̶r̶e̶c̶t̶:̶ a̶ d̶e̶f̶a̶u̶l̶t̶e̶d̶ c̶o̶n̶s̶t̶r̶u̶c̶t̶o̶r̶ s̶t̶i̶l̶l̶ d̶e̶f̶a̶u̶l̶t̶-̶i̶n̶i̶t̶i̶a̶l̶i̶z̶e̶s̶ t̶h̶e̶ m̶e̶m̶b̶e̶r̶s̶, n̶o̶t̶ v̶a̶l̶u̶e̶ i̶n̶i̶t̶i̶a̶l̶i̶z̶e̶. I̶ d̶o̶n̶'t̶ t̶h̶i̶n̶k̶ t̶h̶e̶r̶e̶ i̶s̶ a̶n̶y̶ d̶i̶f̶f̶e̶r̶e̶n̶c̶e̶ b̶e̶t̶w̶e̶e̶n̶ d̶e̶f̶a̶u̶l̶t̶i̶n̶g̶ i̶n̶l̶i̶n̶e̶ a̶n̶d̶ o̶u̶t̶ o̶f̶ l̶i̶n̶e̶. G̶C̶C̶ s̶e̶e̶m̶s̶ t̶o̶ a̶g̶r̶e̶e̶:̶ h̶t̶t̶p̶s̶:̶//g̶c̶c̶.g̶o̶d̶b̶o̶l̶t̶.o̶r̶g̶/z̶/r̶4̶r̶e̶5̶T̶E̶5̶a̶ edit: I missed that the author is actually value-initializing x!!! The result definitely violates expectations! Generally, the details of the rules are arcane and sometimes have non-sensical dark corners having been extended and patched up for the last 40 years. But 99.9%[1] of the time you get what you expect. I big improvement would be making default initialization explicit, and otherwise always value initialize. Explicit value initialization is so common that the very rare times I want default initialization (to avoid expensively zeroing large arrays) I need to write a fat comment. Writing \"std::array = void;\" (or whatever the syntax would be) would be much better. [1] I had an extra 9 here... I hedged. reply adrianN 4 hours agoparentOnce every thousand lines you don’t get what you expect? Rip reply gpderetta 4 hours agorootparentOnce every 1000 initializations. But hey, I would sign up for only one bug every 1000 lines. reply jakewins 7 hours agoprevMan I get vertigo reading this. Reminds me of trying to understand Java constructors and object initialisation. It’s been a while now, and at least in my experience so far Go and Rusts choice of not having special constructors really simplifies a lot. Is there anyone that’s had the experience of missing constructors once you swapped away from them? reply masklinn 6 hours agoparentThere are a few somewhat esoteric cases where constructors working in-place allow magic which can be hard to replicate otherwise e.g. Rust is still missing guaranteed “placement new” type behaviour. Unless you want to `ptr::write` individual fields by hand into a `MaybeUninit`, which you can absolutely do mind but that… is not very ergonomic, and requires structs to be specifically opted into this. reply wongarsu 6 hours agorootparentWhich can be an issue if you want to initialize a 2MB large heap-allocated object (e.g. heap-allocating a large nested struct or a big array). Without guaranteed “placement new” that can mean that your 2MB object gets constructed on the stack and copied to the heap. And while Linux defaults to a 4MB stack, Windows defaults to 1MB and will crash your program. Or it might work if the compiler optimizes in your favor. It's not something you encounter frequently, it can be worked around, and Rust will eventually solve it ergonomically without introducing constructor hell (probably with just a keyword). But finding the best language-level solution isn't straightforward (efforts to fix this for rust are ongoing for 9 years) reply godshatter 3 hours agorootparent>Which can be an issue if you want to initialize a 2MB large heap-allocated object (e.g. heap-allocating a large nested struct or a big array). >Without guaranteed “placement new” that can mean that your 2MB object gets constructed on the stack and copied to the heap. And while Linux defaults to a 4MB stack, Windows defaults to 1MB and will crash your program. Or it might work if the compiler optimizes in your favor. C gets a lot of hate, often for good reasons, but at least you know where your memory is coming from when you are allocating it yourself. If you're allocating a large heap-allocated object, you're grabbing the memory directly from the heap. reply wongarsu 41 minutes agorootparentMemory allocation is one of the areas where currently C/C++ has or had genuine advantages over Rust. Custom allocators took Rust years, and giving standard library constructs like a Vector a custom allocator that isn't the global allocator is still experimental (=opt-in nightly-only). Similarly while Rust gives you good control over where the data ends up being stored, there is no way to make sure it isn't also put on the stack during function execution. One of the implicit assumptions underlying the language seems to be that the stack is cheap and effectively infinite while the heap is expensive. So you have a lot of control over what touches the heap, but less control over what touches the stack. Those are temporary pains that have remedies in the works. Rust is a fairly young language, and a lot of good-enough solutions get thrown out before ever getting beyond the experimental stage. But if you are writing software today then needing absolute control over where exactly your data touches is a good reason to prefer C/C++ today. Not that that's a very common need. reply bennettnate5 5 hours agorootparentprevIt can also be an issue if you want to wrap any API that requires fixed memory locations for objects (such as POSIX semaphores). It's UB to call a POSIX semaphore from any other memory location than where it was initialized, so making a `Semaphore::new()` API is just asking for trouble. You can deal with it by `Box`ing the semaphore, but then you can't construct the semaphore in a shared memory segment (one of the stronger use cases for process-shared semaphores). I have a hunch this is why there's no Semaphore implementation in the Rust standard library, though it could be due to fundamental inconsistencies in semaphore APIs across OSs as well ¯\\_(ツ)_/¯ reply masklinn 3 hours agorootparentNo, Rust doesn't have semaphores in the stdlib[0] because it was not clear what precise semantics should be supported, or what purpose they would serve since by definition they can't mitigate exclusive and thus write access to a resource and mitigating access to code isn't much of a rust convention. And nobody has really championed their addition since. Furthermore, they still present a fair amount of design challenges in the specific context of Rust: https://neosmart.net/blog/implementing-truly-safe-semaphores... [0] technically they were there, added in 0.4, never stabilised, deprecated in 1.7, and removed in 1.8 reply _ZeD_ 6 hours agoparentprevdude, java constructor are easy... that C++ stuff is really black magic and from what I understand rust constructors are basically the same as java, no? reply DougBTX 6 hours agorootparentInside a constructor you can access a partially initialised \"this\" value, and even call methods on it, which leads to rules like: \"Do not call overridable methods in constructors\"[0], as they can lead to surprising, non-local, bugs. Rust has functions associated with types which are conventionally used like constructors, but critically the new objects must have all their fields provided all at once, so it is impossible to observe a partially initialised object. [0] https://learn.microsoft.com/en-us/dotnet/fundamentals/code-a... reply titzer 4 hours agorootparentVirgil solved this a little differently. The initialization expressions for fields (outside of constructors) as well as implicit assignment of constructor parameters to fields happens before super constructor calls. Such initialization expressions cannot reference \"this\"--\"this\" is only available in _constructor bodies_. Initializing fields before calling super and then the chaining of super calls guarantees the whole chain of super constructor calls will finish before entering the body of a constructor, and all fields will be initialized. Thus by construction, virtual methods invoked on \"this\" won't see uninitialized fields. https://github.com/titzer/virgil/blob/master/doc/tutorial/Cl... reply zozbot234 4 hours agorootparentprevYou can most likely use session types to soundly observe a partially initialized MaybeUninit in Rust. The proper use of session types could ensure that the object is only assumed to be initialized after every field of it has been written to, and that no uninitialized fields are ever accessed in an unsound way. The issue though is that this is not automated in any way, it requires you to write custom code for each case of partial initialization you might be dealing with. reply masklinn 6 hours agorootparentprevRust does not have constructors at all[0], it uses factory functions (conventionally named `new_somethignsomething`) but those are not special to the language. [0] except in the more generalised haskell-ish sense that structs or enum variants can be constructed and some forms (“tuple structs” and “tuple variants”) will expose an actual function reply collinvandyck76 4 hours agorootparentI've often longed for first class constructors in Go and Rust. It was more of a problem for me with Go because you can omit a struct field when building a value, something you can't do in Rust unless it has an explicit Default impl and even then you have to explicitly add ..Default::defualt() when you're building the value. I never thought that constructors were that burdensome and therefore do not understand the omission in other languages like Go and Rust that followed. Quite the opposite really -- knowing that a type always went through a predefined init was comforting to me when writing Java. reply mmaniac 6 hours agorootparentprevRust doesn't have constructors. By convention, a static method called new returns a struct - no magic. reply jakewins 6 hours agorootparentprevI think if you think constructors in Java are easy, you are much, much smarter than I am or have missed some really, really subtle footguns. Eg: - Java constructors can return the object before they complete construction, finishing at a later time; this is visible in concurrent code as partially constructed objects - Java constructors can throw exceptions and return the partially constructed object at the same time, giving you references to broken invalid objects - Just.. all the things about how calling super constructors and instance methods interleaved with field initialization works and the bazillion ordering rules around that - Finalizers in general and finalizers on partially constructed objects specifically I don't in any way claim it's on the same level as C++, but any time I see a Java constructor doing any method calls anymore - whether to instance methods or to super constructors - I know there are dragons reply cvoss 5 hours agorootparent> bazillion ordering rules There are 3 which pertain to object initialization in Java. 1. super is initialized in it's entirety by an implicit or explicit call to `super()` 2. All instance initializers of the present class are invoked in textual order. 3. Constructor code following the `super()` call is executed. The only awkward thing here is the position of #2 in between #1 and #3, whereas the text of a constructor body suggests that #1 and #3 are consecutive. It gets easier to remember when you recognize that, actually, there's a defect in the design of the Java syntax here. A constructor looks like a normal function whose first action must be a `super()` call. It's not. The `super()` call is it's own thing and shouldn't rightly live in the body of the constructor at all. Edit: Tweaks for clarity. reply marcosdumay 2 hours agorootparentprevThose are the normal issues inherent to constructors as a concept (except for the finalizer one). Any language that has constructors has some complex rules to solve those things. And it's always good to check what they are when learning the language. Java has one of the simplest set of those rules that I know about. reply SpaghettiCthulu 5 hours agorootparentprev> - Java constructors can return the object before they complete construction, finishing at a later time; this is visible in concurrent code as partially constructed objects > > - Java constructors can throw exceptions and return the partially constructed object at the same time, giving you references to broken invalid objects Java constructors do not actually return the object. In Java code, it would appear to the caller as though the contructor returns the new instance, but that is not really the case. Instead, the new object is allocated and then the constructor is called on the object in (almost) the same manner as an instance method. Additionally, Java constructors can only leak a partially initialized object if they store a `this` reference somewhere on the heap (for example, by spawning a thread with a reference to `this`). The assertion that this gives you a reference to a \"broken invalid object\" is only potentially correct from the perspective of invariants assumed by user-written code. It is perfectly valid and well-defined to the JVM. > - Just.. all the things about how calling super constructors and instance methods interleaved with field initialization works and the bazillion ordering rules around that This is a gross mischaracterization of the complexity. There is only a single rule that really matters, and that is \"no references to `this` before a super constructor is called\". Until very recently, there was also \"no statements before a super constructor is called\". > - Finalizers in general and finalizers on partially constructed objects specifically Finalizers are deprecated. reply vips7L 3 hours agorootparentprevI think you’re exaggerating the complexity here. There are corner cases yes, but the compiler will warn you about them. reply bookofjoe 4 hours agoprev>I Have No Mouth, and I Must Scream (1967) https://talesofmytery.blogspot.com/2018/10/harlan-ellison-i-... reply AlexandrB 4 hours agoprevFor more C++ wackiness, I recommend the C++ FQA: https://yosefk.com/c++fqa/ It's 15 years out of date now, but also timeless since C++ rarely/never removes old features or behaviours. reply jolj 3 hours agoprevIs there a C++ tool that adds/shows all the implicit stuff that happens behind the scenes? Such as all the constructors that are being added, implicit copy constructor and all the other surprises? reply fouronnes3 3 hours agoparentBest you're gonna get is a combination of godbolt and cppinsights. reply jolj 30 minutes agorootparentcppinsights looks like what I was looking for, there's even a vscode extension thanks reply gattilorenz 6 hours agoprevWhat an beautiful blog theme, obviously inspired by the DEC-era computers but also clean and minimal. Refreshing! reply georgestagg 32 minutes agoparentI like how the rules to the right of the headings react to the page width and how many lines are used. reply imperialdrive 1 hour agoparentprevDitto reply kazinator 6 hours agoprev> Otherwise, zero-initialize and then default-initialize. That can't be right ... is it? Things cannot be initialized twice. Isn't it more like \"Otherwise, recurse the value-initialization over the bases and members\". Then, those that are not classes or arrays get zero-initialized. reply leni536 4 hours agoparentBoth \"zero-initialize\" and \"default-initialize\" are terms that have precise definitions. In this context if you substitute the definitions it just means first zero-initializing the non-static data members (and zeroing the padding), then calling the default constructor. It doesn't mean that the lifetime of the object starts twice, or anything weird like that. reply SpaghettiCthulu 5 hours agoparentprevI think it would be perfectly legal to zero-initialize the entire thing and then default-initialize, because initialization assumes the value is undefined. reply bregma 5 hours agorootparentnext [–]You can only initialize once. After it's been initialized you're just assigning values, and that's not what happens during initialization. It's either a misunderstanding on behalf of the author or the words as written are not conveying the correct idea. reply wateralien 7 hours agoprevUpvote for the title. reply sixtram 3 hours agoprevGreat link, I'm going to add this to my list of favorite interview questions. (^_-) reply vsgherzi 1 hour agoprevthis has got to be one of my favorite blog names i've seen on this site reply 3l3ktr4 6 hours agoprevThis is the best title, OP. reply jeffbee 2 hours agoprevI agree there is a lot of complexity in C++ in the year 2024, however I feel that much of the appearance of complexity around initialization is due to the pedantic, dogmatic use of the word \"default\" by the committee to mean \"not\". reply echelon 7 hours agoprev [–] A language shouldn't be this complicated. This is dangerous and impossible for teams full of juniors and busy people with deadlines. We're only human. reply dataflow 6 hours agoparentThey can't pull the rug out now, but I highly recommend making your own clang-tidies to flag confusing constructs (like defaulted out-of-line constructors) and preventing them from being committed. reply bun_terminator 6 hours agoparentprevTrue, however in practice this is rarely an issue. You usually only use a tiny subset of construction rules. And if you ever make a mistake, they are easily caught by static analysis tools. reply smackeyacky 5 hours agorootparentIt’s quite a big issue. It’s actually a bit worse than the article makes out if you throw static objects into the mix and get race conditions where you don’t know which objects get constructed first. C++ has to be approached with caution even by experienced devs. reply maccard 3 hours agorootparentI agree with the parent - global initialisation order is a once-bitten-never-again, and the reality is that working in most codebases doesn't require understanding all of these rules - knowing the quirks is usually only required by one or two people and the rest can work with what they've got. reply TinkersW 3 hours agorootparentprevthat is a novice issue, it is easily avoided reply bun_terminator 4 hours agorootparentprevexperienced (and even the not so much) devs know the perils of static initialization and avoid it. reply 082349872349872 6 hours agoparentprevI believe those teams just use constructors; this is a corner case, not SOP. reply echelon 6 hours agorootparentC++ should start pulling things out of the language with new editions. It would improve quality of life dramatically. reply pjmlp 6 hours agorootparentRust style editions don't work with binary libraries, across compilers, or template code across editions, with semantic differences. That is why the epochs proposal was rejected. Additionally, the main reason many of us, even C++ passionate users, reach out to C++ instead of something else, is backwards compatibility, and existing ecosystem. When that is not required for the project at hand, we happily reach out to C#, D, Java, Go, Rust, Zig, Swift, Odin,.... instead. reply estebank 3 hours agorootparent> don't work with binary libraries, None of the edition changes that Rust has made have any effect on the ABI. It also has no stable Rust ABI, so there wasn't an effort to formalize that, but 1) ABIs should always be versioned (to avoid getting stuck with a bad ABI) and 2) you can use editions for other kinds of change in the meantime. > across compilers, This is almost tautological. Yes, having two C++ compilers agree to their support of editions is the same as them agreeing to their support of concepts. I don't see how this is a critique of the strategy. > template code across editions, with semantic differences. Rust defines editions at the compilation unit level: the crate. But it has macros (which are akin to templates) and editions are handled at that boundary (you can have code in one edition invoke macros in another) because the compiler tracks editions at the token level (the information is attached to their Span). There's no reason editions in C++ can't work with templates. You would have to specify the edition of the template, and given C++ semantics you might have to have an opt-in scope to say \"use this edition here, override the rest of the file\", but it would be possible. reply pjmlp 1 hour agorootparentRust editions are very conservative, expect everything to be built from source, with the same compiler, and don't touch semantic changes across versions, mostly grammar changes. Example, there is no story for scenario, where a callback defined in one version, is used in another crate version, calling into code, using yet another version, while passing a closure with a specific type with semantic changes across all versions. I am not yet convinced they will scale at the size of industry use cases for C and C++, with a plethora of compilers, and mixing several editions on a 30 year old codebase. reply jamincan 6 hours agorootparentprevIf Rust style editions can work across modules, why couldn't they work across binary libraries and so forth? The whole point is to allow the language to progress while maintaining backward compatability. reply dathinab 5 hours agorootparentthey don't work with a backward compatible application binary interface or more specifically they only work with ABI stability if they ABI doesn't change between epochs which isn't a issue for Rust because: - it is cleanly modularized - it build a whole module \"at once\" - it doesn't have a \"stable\" ABI (outside of \"extern/repr C\" parts which don't contain non reprC parts rust doesn't even guarantee ABI compatibility between two builds in exactly the same context*(1)) - tends to build everything from source (with caching) - a lot of internees are intentionally kept \"unstable\" so that they can change at any time on the other side due to how C/C++ build things, doesn't have clean module isolation, how it chooses build units, how all of that is combined, how it's normal to include binaries not build by your project (or even you), how such binaries contain metadata (or don't) and how too much tooling relies on this in ways which make changes hard, how it doesn't have build-in package management, how it you specify compiler options and how compiler defaults are handled etc. come together to make that impossible in a certain way how you specify that you use C++11,17 etc. is the closest C++ can get to rust editions like initially it might seem easy to introduce syntax braking changes (which most rust edition changes boil down to) but then you realize that build units using other editions have to be able to read the header file and the header file e.g. in context of templates can contains any kind of code and that header includes aren't that much different too copy pasting in the header and that you don't have a standard package manager which can trace which edition a header has and endless different build systems and you kinda give up purely technically it _is fully possible to have rust like editions in C++_ but practically/organizationally in context of e.g. backward compatibility with build systems it's just way to disruptive to be practical reply 0xffff2 5 hours agorootparentprev> When that is not required for the project at hand, we happily reach out to C#, D, Java, Go, Rust, Zig, Swift, Odin,.... instead. Which is all well and good for us, the application developers. But if C++ wants to exist in the future as a thriving language (as opposed to moving in to the nursing home with Cobol and Fortran), then it needs to come up with some solution to remove cruft. reply Someone 4 hours agorootparentIt has a solution: obsoleting features and then removing them. For examples, see https://en.wikipedia.org/wiki/C%2B%2B17#Removed_features https://en.wikipedia.org/wiki/C%2B%2B20#Removed_and_deprecat... https://en.wikipedia.org/wiki/C%2B%2B23#Removed_features_and... Part of their ‘problem’ is that they have lots and lots of users with long-living code bases. That means that, if they move fast and break things, their users won’t move to newer versions of the language. Another part is that they want to be able to generate the fastest code possible. That leads to such things as having all kinds of constructors (‘normal’ ones, copy constructors, move constructors), and giving developers the ability to tweak them for maximum performance. In addition, a lot of this was invented after the language was in use for decades. I think that makes the constructor story more complicated than needed. reply pjmlp 4 hours agorootparentprevUntil those languages decide to be fully bootstraped, alongside Khronos and OpenGroup being welcoming to them for newer standards, C++ won't go away. reply falcor84 6 hours agorootparentprevHow about (C++)-- ? reply Joel_Mckay 6 hours agorootparentThere was a C--, and it was an Assembly macro C like syntax based compiler. https://en.wikipedia.org/wiki/C-- The GNU gcc/g++ was far more important to standardization than most people like to admit. Have a great day, =) reply gosub100 6 hours agoparentprevMy guess is all these details are necessary to provide C++ \"strong exception guarantee\" against partially constructed objects. Perhaps if your member objects can throw exceptions, some of these pedantic initialization rules can come to the rescue and allow, say, a library implementor to limit initialization code to places where exceptions can be handled. reply dathinab 5 hours agoparentprev [–] it being this complicated can be fine (if there isn't too much of it) but only if not knowing how the complicated parts work doesn't create any subtle issues and has reasonable compiler time errors and isn't fundamental needed to write any code Because then you can use the language without needing to know how exactly that complexity works and if you get it wrong you get a reasonable compiler error. And then decide to either spend some time to learn what you didn't know or you just write the code differently. But in either case you don't have a situation with a unexpected runtime error which should be impossible and where you have no good way to know where to even start looking. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In C++, if constructors are not provided, the compiler may generate default ones, potentially leading to uninitialized objects.",
      "Default-initialization does nothing for non-class and non-array types, while value-initialization zero-initializes non-class types and then default-initializes.",
      "Relying on compiler-generated constructors can result in undefined behavior; it's recommended to write custom constructors to avoid these issues."
    ],
    "commentSummary": [
      "C++ is complex due to its multi-paradigm nature, supporting various applications like embedded systems, video games, servers, and GUIs.",
      "Alternatives like C and Rust do not cover all use cases of C++, making it a unique but challenging language.",
      "While C++'s complexity is necessary for performance and flexibility, it can be overwhelming for less experienced teams."
    ],
    "points": 240,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1720168947
  },
  {
    "id": 40877648,
    "title": "Japan introduces enormous humanoid robot to maintain train lines",
    "originLink": "https://www.theguardian.com/world/article/2024/jul/04/japan-train-robot-maintain-railway-lines",
    "originBody": "View image in fullscreen West Japan Railway has introduced a 12-metre high robot mounted on a truck to perform maintenance work on rails, including trimming tree branches and painting. Photograph: Reuters Japan Japan introduces enormous humanoid robot to maintain train lines The 12-metre high machine has coke bottle eyes and a crude Wall-E-like head, as well as large arms that can be fitted with blades or paint brushes Agence France-Presse Thu 4 Jul 2024 01.05 EDT Share It resembles an enormous, malevolent robot from 1980s sci-fi but West Japan Railway’s new humanoid employee was designed with nothing more sinister than a spot of painting and gardening in mind. ‘How can such a tiny woman drive a big truck?’ Japan’s labour shortage forces it to rethink gender stereotypes Read more Starting this month, the large machine with enormous arms, a crude, disproportionately small Wall-E-like head and coke-bottle eyes mounted on a truck – which can drive on rails – will be put to use for maintenance work on the company’s network. Its operator sits in a cockpit on the truck, “seeing” through the robot’s eyes via cameras and operating its powerful limbs and hands remotely. With a vertical reach of 12 metres (40ft), the machine can use various attachments for its arms to carry objects as heavy as 40kg (88lb), hold a brush to paint or use a chainsaw. View image in fullscreen Japan’s giant robot fixes railway power lines. Photograph: Reuters For now, the robot’s primary task will focus on trimming tree branches along rails and painting metal frames that hold cables above trains, the company said. The technology will help fill worker shortages in ageing Japan as well as reduce accidents such as workers falling from high places or suffering electric shocks, the company said. “In the future, we hope to use machines for all kinds of maintenance operations of our infrastructure,” and this should provide a case study for how to deal with the labour shortage, company president Kazuaki Hasegawa told a recent press conference. Explore more on these topics Japan Robots Asia Pacific news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=40877648",
    "commentBody": "Japan introduces enormous humanoid robot to maintain train lines (theguardian.com)211 points by thunderbong 22 hours agohidepastfavorite89 comments maxglute 21 hours agoIt's still user controlled like a surgical robot but for construction. I'm guessing it's eventually going to be run remotely by a bunch of japanese operators too old to work in the field. Also disappointingly small for \"enormous\", was hoping for a gundam. reply anigbrowl 20 hours agoparentGotta start somewhere, once the initial bugs are sorted out we can start forcing ambivalent high schoolers into existential crisis situations. reply anotherhue 18 hours agorootparent...all's right with the world. reply Fire-Dragon-DoL 14 hours agorootparentprevLol reply analog31 18 hours agoparentprevI think putting it in a reptile suit would not be too much to ask. reply nashashmi 19 hours agoparentprevBy enormous I was expecting something that could lift a rail car. reply ocodo 8 hours agorootparentHonestly, I thought it would be towering above Docomo Tower. reply core_dumped 21 hours agoparentprevEh, the classic Gundam is around 18 m tall. This comes close at 12 m. The upper body and arms certainly invoke mobile suit aesthetics though reply maxglute 21 hours agorootparentIt reaches 12m on a telescoped crane, the actual scale of the robot body looks pretty small, smaller than the cab of the truck. Pretty human scale all things considered, makes one wonder if it's goign to be mounted on treads or legs one day for indoor use. It does look very cool indeed. reply bobthepanda 15 hours agorootparentin the context of a train line, you may not want it any taller, since there are things like overhead wires to deal with if it gets any taller. reply krisoft 6 hours agorootparentI don't think the argument is that it should be bigger. Just that if it's not enormous we should not describe it as enormous. reply jncfhnb 19 hours agorootparentprevPerhaps this can serve as just a single leg of a larger combination though reply ThrowawayR2 14 hours agorootparentprevThe AV-98 Ingram from the Patlabor anime is 8 m tall, so I wouldn't count this robot out. reply Izkata 33 minutes agorootparentAnd the Knightmare Frames from Code Geass are around 4-6 meters tall. reply Fire-Dragon-DoL 14 hours agoparentprevAs if having a big human conttolled robot could never trigger the dreams of many mecha addicts, right? Lol reply ano-ther 22 hours agoprevHere is a video of it in action: https://www.youtube.com/watch?v=owSJK7vMSLk Interestingly, humans come very close to it during operation. reply dugditches 21 hours agoparentNot much different than everyday on sites everywhere with boom cranes. Which are arguably much more dangerous due to being less dexterous and no video. Notably 1:23 where it's similar to working with a crane. reply roughly 20 hours agoparentprevThat looks incredibly cool, and also instantly nausea inducing - I can’t imagine the video feed and the head gyros are fast enough to avoid that little bit of lag and judder that turn VR into a vomit machine. The feedback on the arm is very cool, though. reply gpm 20 hours agorootparentFPV drone hardware has commercialized very cheap very low latency video feeds to headsets. Not with headtracking though. Not sure that's reasonably possible. reply yial 19 hours agorootparentFPV headsets can have head tracking. I don’t know cost now, but it was possible even in 2012/2013/2014 when I worked in that industry. reply unrealhoang 16 hours agorootparentWhat's the advantages of head tracking though? I don't see it's in anyway better than just joystick to control robot head movement. reply SoftTalker 15 hours agorootparentIt's a completely natural movement for the operator, that will require almost no practice or training, and also leaves the operator's hands free to operate other controls. reply gpm 19 hours agorootparentprevHuh, so there is, with physical servos moving a camera. Any idea what latency numbers might look like? Seems unlikely the physical movement can be especially low latency. reply enva2712 9 hours agorootparentprevResponses so far say to optimize neck latency or use a joystick but why not use a 360 camera and handle it in reprojection. First pass could literally be a gopro or insta360 streaming to the headset and you could eventually integrate cameras and do the stitching yourself. The tech already exists and works, and it removes moving parts and actuators reply PoignardAzur 19 hours agorootparentprevI wonder if it wouldn't be easier / more comfortable for the worker to just get a low-poly reconstructed 3D rendering of the environment. That way at least they could move their head as much as they want and still get a read-time feed in their goggle without the usual VR tricks. reply pixl97 14 hours agorootparentBecause said low res rendering will remove very important cues that workers repairing stuff need to see, like potential things cracks in materials. reply namibj 19 hours agorootparentprevWhy not? There's no need for the neck to have more than 1~5 ms of lag, and about 5~10 ms photon lag even with a framebuffer involved (if you align the rolling shutter of the camera to the row-by-row multiplexed display, say OLED @ 240Hz, you should manage 4~5 ms). reply fragmede 19 hours agorootparentprevjust over so it on the cameras so there isn't a latency because you're not actually moving the giant robot head reply omoikane 16 hours agoparentprevI like how the robot head motion is linked to the operator's head motion, such that the robot is able to nod its head near 2:15. I also like the feedback control near 0:35. reply downboots 12 hours agoparentprevnow start collecting user movement data with the visual recordings and we can eventually automate all the things reply l1n 22 hours agoprevhttps://www.jinki.jp/ their website is banger reply cbm-vic-20 17 hours agoprevIt seems that in many cases, Japanese robot designers prefer humanoid form over a more practical design. Watching the video linked by ano-ther, it seems that many of the demonstrated tasks could benefit from cameras that are placed more closely to the tool. Accurately placing parts, inspections, and the tree limb removal tasks are examples of this. reply pixl97 14 hours agoparentYa it's not a human, you're not limited to binocular vision and can have multiple sets of cameras pretty easily of you wanted. Who knows what the designers are thinking. reply fragmede 13 hours agorootparentI'm pretty sure they're thinking \"giant robots are awesome!\" reply p_l 5 hours agorootparentThe ball-like robots from Gundam literally had a speech about them in Japanese parliament, so... :D reply krapp 5 hours agorootparentprevI doubt it. Boston Dynamics creates humanoid robots as well, and makes design decisions which aren't always maximally efficient, but no one makes such an infantilizing assumption about American engineers. reply DEADMINCE 13 hours agorootparentprevMaybe that kind of childish decision-making is why Japan is failing as a country. reply elzbardico 5 hours agorootparentHow many homeless fentanyl addicts you saw in your last trip to Osaka or Tokyo? reply DEADMINCE 4 hours agorootparentYou're not making the point you think you are, or at least not remotely well. Look at big picture stats to draw a conclusion instead of pointing out a pretty obscure US problem that has no bearing on the claim made. reply a-french-anon 10 hours agorootparentprevSoulless comment of the year award material. reply rkagerer 20 hours agoprevThey weren't kidding about it looking like an awesome 80's robot! Resembles Johnny 5 (from 1988): https://static.wikia.nocookie.net/robotics/images/4/49/Johnn... reply jolmg 19 hours agoparentHuh. Robot with denim jacket in Chromium, but placeholder image (mountain and sun icon) in Firefox. Can view in Firefox if cb query param is removed. Weird. reply rkagerer 10 hours agorootparentWeird, sorry about that queryparam I didn't see it there or would have stripped it. reply ASalazarMX 19 hours agoparentprevI wasn't sure if it was justified, but was instantly sold when it nodded with its little head. reply johnwalkr 8 hours agoprevWhat is it with media that attributes everything to \"Japan\"? Here we have a private company trying out a robot made by a much smaller private company, in Japan. It's not like the government of Japan is rolling out gundams across the nation. reply harha_ 7 hours agoparentWell it is a japanese startup company working for JR-West. reply hnbad 3 hours agoparentprevThe average Guardian reader never heard of that private company and definitely never heard of that much smaller private company. \"Company in Japan\" is also longer than simply \"Japan\". Plus there's still some latent orientalism at play. But while the government of Japan likely isn't particularly involved in this project, states still like to claim tech advances (or gimmicks) happening in their country. There's a reason you often see politicians at opening ceremonies even when their government contributed nothing to what is being opened. reply znyboy 16 hours agoprevThis particular robot was revealed back in 2022. https://news.ycombinator.com/item?id=31190875 reply crooked-v 21 hours agoprevThis seems like a decent force multiplier, though I have to wonder how efficient the results are compared to just having a small crew of workers with a boom lift and a good toolbox. There are also the attention-splitting issues you can't cover with just one person in a cab, like marking off areas and directing traffic/pedestrians. reply Tade0 21 hours agoparentTheir problem appears to be that they don't have that small crew to work with. Median age in Japan is already 48+ and creeping up. reply SoftTalker 15 hours agorootparentSounds like they need immigrants. reply pixl97 14 hours agorootparentThat would work for a bit, but at current trends that won't last long worldwide either. reply standardUser 14 hours agorootparent84% of the global population are in low and middle income countries, and the vast majority of those people could have a significantly higher quality of living in a place like Japan if they were given the neccesary political protections. 6 billion people is not infinity people, and not all of those people are willing or able to move to a place like Japan to try their luck. But the idea that immigration is anywhere close to an end is preposterous. reply pixl97 4 hours agorootparentPopulations growth rates have fallen very fast around the world sometimes with in the span of one or two generations. The global fertility rate has fallen to 2.3. Sub Saharan Africa is one of the few places left with what we would consider large growth rates. Increased standards of living in these places we typically imported people from can quickly cut off this flow and put western nations at risk, whereas we thought this flow was unlimited. Add to this the cost of living in western countries has spiraled out of control recently, the idea that \"Just move to X, things will be better\" is fading from what it used to be. reply 123yawaworht456 1 hour agorootparentprevand will Japan remain Japan once their population gets replaced with a vibrant stew of MENA immigrants, friend? reply scotty79 10 hours agorootparentprevBut the immigration seems to have triggered resurgence of fascism and populism worldwide. So while economically sustainable in theory it might be unsustainable for cultural reasons. reply 0dayz 6 hours agorootparentThis is mainly due to blind trust in ideals instead of hard facts when it comes to immigration. European countries who took in a lot of Mena people have issues because they believe naively in a form of laissez faire. reply falcor84 6 hours agorootparentprevCulture can change. It's not an easy fight, but I would bet on economics beating culture in the long term. reply jalk 21 hours agoparentprevI guess they will have to put old people at the controls, to overcome \"the worker shortage in aging Japan\" reply StarterPro 15 hours agoprevHuh, is this what it looks like when taxes are used appropriately? reply fabiospampinato 20 hours agoprevEnormous humanoid robots for everything! Have you ever watched one of those videos where somebody makes a mini concrete building in a few days? I'd be cool to just scale that up, if it's possible, perhaps with faster-setting concrete or something. reply falcor84 6 hours agoparentBad idea of the day: Perhaps you could \"Ender's Game\" it, to have a kid playing with legos control a giant robot, building a full-sized version of that set remotely. What could go wrong. reply langsoul-com 15 hours agoprevSurely it'd be better to make specialised tools instead of a humanoid robot? Human robots are super complex, and not fully utilised if the object was trimming trees. reply SoftTalker 15 hours agoparentIt's very general purpose. Now it's used for trimming trees, but could potentially do a lot of other jobs. reply pineaux 22 hours agoprevThis is the most Japan thing I have seen here in a long time. Immediate throwback to all the cool mecha anime stuff... reply cellularmitosis 18 hours agoparentI was about to say, isn’t this how the plot of Patlabor starts? reply Barrin92 16 hours agorootparentPatlabor is criminally underrated, in particular Patlabor II by Oshii. Often neglected given how popular his other stuff like GitS is but probably one of the best animated films when it comes to post WWII Japan's military/political questions. reply exclipy 15 hours agoprevWhy does it have a swivelling head? I would have just mounted a 360 camera there. Then the operator can turn their head in any direction as fast as they want without the latency of waiting for a mechanical head to catch up. reply Ancapistani 15 hours agoparentThis is likely safer - an onlooker can easily tell where the operator is looking, and therefore know if they are likely to be seen. reply fragmede 15 hours agorootparentif the operator gets sick from the latency, even if they see someone they're more likely to have issues though reply scotty79 9 hours agoparentprevHow would a 360 camera with stereoscopic vision work? reply enva2712 9 hours agorootparentGood point, the sensor count exponentiates and the optics get a lot more complicated if you want a fully integrated system. Nothing on the market I know of but with where we are on the scaling curves now might be the time to try something like it - you could put together a basic proof of concept with a load of commercial sensor elements and wide angle lenses on a sphere. Eventually you can consolidate the central sensors and lenses into concentric hemispheres. You can reduce the data volume by narrowing the camera angles eventually too Not sure there’s a market but maybe with VR stereo 360 becomes more valuable, who knows. Technologically doable though reply enva2712 9 hours agorootparent(It would look like kind of like a dragonfly eye) reply scotty79 6 hours agorootparentMind blown. Can insects get depth perception with just one eye? reply aitchnyu 13 hours agoprevWill it hold died (sorry) sheet metal things softly and heavy things without dropping? How does it control the force it exerts? reply tsudonym 16 hours agoprevThis will especially useful for struggling rural Japanese train lines in the future. Nice. reply 6510 22 hours agoprevThis has a video https://www3.nhk.or.jp/nhkworld/en/news/20240702_14/ reply lemoncookiechip 21 hours agoprevThis is so cool, leave it to Japan. reply Hobadee 20 hours agoprevI've seen this movie before. It ends badly for the humans. reply hobscoop 20 hours agoparentStrong echoes of the Onion's reporting on Dr. Lester Mordock's giant crabs: https://www.youtube.com/watch?v=-Uq9pp586AE reply pjs_ 7 hours agoprev> chainsaw yes… YES reply Woshiwuja 11 hours agoprevgetting closer the the mecha dream day by day reply atum47 20 hours agoprevSo... how long until Daileon? reply andrewstuart 21 hours agoprevYes. Japan delivering the future we were promised. reply bitwize 22 hours agoprevHell yes. The age of Japanese mechs foretold by anime is upon us. reply Izikiel43 21 hours agoparentIs this how gundam started? reply shawn_w 20 hours agorootparentThis is more Patlabor than Gundam. reply shermantanktop 19 hours agoprev [–] Robot? It’s more like a remote-control exoskeleton. reply bhaney 16 hours agoparent [–] > remote-control exoskeleton So like a robot? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "West Japan Railway has unveiled a 12-metre high robot mounted on a truck for rail maintenance tasks such as trimming tree branches and painting.",
      "The robot, which can be operated remotely, features large arms that can carry up to 40kg and reach vertically up to 12 metres, aiming to address worker shortages and reduce accidents.",
      "The company plans to expand the robot's use for various maintenance tasks in the future."
    ],
    "commentSummary": [
      "Japan has unveiled a large humanoid robot for maintaining train lines, controlled remotely similar to a surgical robot.",
      "The robot, capable of reaching 12 meters on a telescoped crane, is designed for tasks like tree limb removal and inspections.",
      "This innovation aims to address Japan's aging workforce and labor shortages, despite some skepticism about its efficiency compared to traditional methods."
    ],
    "points": 211,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1720123378
  },
  {
    "id": 40883277,
    "title": "Put the DVD logo in the corner (2023)",
    "originLink": "https://eieio.games/game-diary/game-6-get-the-dvd-logo-into-the-corner/",
    "originBody": "Game 6: Put the DVD logo in the Corner Jul 3, 2023 This game was linked from New York Times Watching newsletter on Friday September 8, 2023. This was super cool for me! Margaret Lyons I have no idea how to get in touch with you but thanks for mentioning my game! Basics Genre: Uh. Arcade action game / childhood dream achievement simulator (?) Links: play it on itch or check out the code on github Engine: PICO-8 Time Spent: 4 days (June 27th - June 30th) Other Stuff: I built this game at Recurse Center, a magical place that functions like a writers retreat for programmers. Consider applying! Gameplay Video My favorite part was adding manual 'particle effects' by drawing individual pixels to the screen High level thoughts This game is tiny! It takes 45 seconds, has no ambitions to be longer, and is based on a joke. I love it. After the UI complexity and lack of a theme in ReShape it was refreshing to make something so limited. The scope of the game was perfect for learning a bit about the PICO-8 (and the PICO-8 probably pushed me to make a game of this scope, which is also great). I think the gameplay itself is…fine? It’s kinda hard, but not that hard, and the strong theme + short length means that you’re probably gonna finish the game if you start it. This is the most arcadey game that I’ve built and it’s been really fun to get messages from friends with their high scores. At the time of writing the high score from a friend is 21 (mine is 26 but that was a freak accident). This is also my first PICO-8 game! I loved some parts of the PICO-8 experience and did not like some of the others. But on the whole I’m happy that I gave it a try and I’m excited to make some more PICO-8 games this year. Wait, the PICO-what? A tl;dr of the PICO-8: it’s a “fantasy console1” with restrictions on graphics, sound, code size, and processor speed that mimic the consoles of the 80s. You can create sprites/music/sound effects and write code straight from the console. A comfy little PICO-8 terminal The tools that the PICO-8 gives you are pleasantly simple but also primitive relative to modern game engines; if you want collision or particle effects you’re gonna have to manually handle collision on a pixel-by-pixel basis and draw your particles by hand. This simplicity is the point - constraints breed creativity and all that. And a fun side effect of these limitations is that PICO-8 games have a distinct and relatively consistent feel. The most well-known PICO-8 game is likely the original version of Celeste, which was made in the PICO-8 for a gamejam. The PICO-8 version of Celeste is playable as an easter egg in the real game! Check it out if you haven’t. The PICO-8 environment: tooling The PICO-8 comes with some built in tools: A sprite editor. I found myself missing Aseprite a bit, but being able to edit sprites directly from the PICO was great! I may try using Asperite with the PICO in the future but it’s not a sure thing. A sound effect editor. I found the editor wildly unintuitive until I watched this Gruber video and then got the hang of it pretty quickly. It’s neat and I’m excited to play with it again. A music editor. I am too used to playing the keyboard to find it super pleasant, but the editor is relatively intuitive (and would be hard to swap out with how the PICO does music). A code editor that I absolutely cannot stand oh my goodness2. The lines don't get longer if you make the editor wider. The font just grows. Fortunately to swap out the code editor I just: Installed the pico8-ls extension for vscode, which gave me nice syntax highlighting and an API reference. Changed the code in my main pico8 file to just be include code.pb and wrote all of my code in code.pb Step 2 is necessary because the PICO-8 stores sprite / music data in the same file that it stores code - I didn’t want to be editing the same file from vscode and the PICO-8. I ended up pretty happy with this setup. My only gripe is that I need an easier-to-search PICO-8 language reference; this manual is hard to search because there’s no way to limit your search to, say, just function names. The PICO-8 environment: vibes It felt super natural to ship a game this small on the PICO-8. I loved that! During development I considered all sorts of extensions - for example, maybe you could collect tokens that gave you more time, or you could upgrade your TV / your DVD logo to make it easier to score points, or maybe there could be enemies that were trying to bump the logo. Maybe this game was actually meant to be a Vampire Survivors clone! And I think if I was writing in Godot I might have given into more of those impulses (or at least tried them out). This game is so simple! Games are meant to have decisions and complexity and choices! It’d be silly to put the game up on itch in this state! But the PICO-8 is so simple that it felt totally natural to ship this game as-is; I felt as though the simplicity of the console gave me permission to do something simple. Of course I’ve always had that permission. But sometimes it’s nice to have a push. I’m excited to revisit the PICO-8 and that push is a big reason why. It’s great to have a theme again As a game player I sometimes skip through themes to get to mechanics. As a kid I’d skip cutscenes; I’ve played hundreds of hours of Path of Exile but absolutely cannot explain the story. This isn’t always true - my favorite game is easily Outer Wilds and that’s as much due to the story as the mechanics - but it’s often true. And so when making games I sometimes talk myself into thinking that a theme isn’t that important. This was certainly true with ReShape TD and probably also with click, click, trick. Both games have some neat mechanics but it’s hard to explain what the games are about. “Put the DVD Logo in the Corner” is the exact opposite and I think that’s great. There is a single mechanic in this game and it is “make a square land in the corner of a bigger rectangle.” Not a very exciting mechanic! But I’ve had more fun telling folks about this game than anything else I’ve made - and that’s all because of the theme. I’ll do my best to keep that in mind for future games. Wrapping up That’s it! I had a lot of fun making this game and working with the PICO-8. I’m interested in building some more small arcade-feeling games and looking forward to returning to the PICO. Right now I’m toying with a game that relies entirely on an (ab)use of the OpenSearch spec to build something that runs entirely from the Firefox address bar. I’ll probably get back to something more, uh, traditional next. An update from the future (2024-07-05): I ended using OpenSearch to run Wordle in the Firefox address bar. And I can’t say I’ve made a lot of traditional stuff since then :) That is, an emulator for a console that doesn’t actually exist ↩ This is not meant to disparage the PICO-8 devs! I think they were going for a very specific feel for the console and the editor and nailed it; the editor is just a little past what I can handle D: ↩ get new posts via twitter, substack, rss, or a billion other platforms or subscribe to my newsletter right from this page!",
    "commentLink": "https://news.ycombinator.com/item?id=40883277",
    "commentBody": "Put the DVD logo in the corner (2023) (eieio.games)190 points by EndXA 4 hours agohidepastfavorite34 comments bluedays 1 hour agohttps://youtu.be/QOtuX0jL85Y?si=Kwo8OZSYOVzoI-Uh Obligatory The Office reference. reply bookofjoe 59 minutes agoparentHuh. And here I thought it was a reference to \"Saturday Night Fever.\" reply fsckboy 3 minutes agorootparent\"nobody puts the DVD logo in the corner!\" Dirty Dancing reply smokel 2 hours agoprevAmazing to read about the Recurse Center [1]. It seems to be some kind of artist-in-residence, but for programmers. I've spent some time in residencies as an artist, and it's amazing how much it helped me to open up new perspectives. It'd be nice if there were more of these opportunities to do nonsensical (i.e., non-commercial and non-competitive) things in science. I'm sure it's beneficial to society or at least for the lucky individuals who get accepted there. [1] https://www.recurse.com/ reply eieio 1 hour agoparent(post author here) If Recurse sounds fun and magical to you - it is! And you should consider applying :). You can always defer your acceptance until the timing works out. It's free (they make money via job placements, but when I applied I was clear that I wasn't looking for work). I've been meaning to write a blog about my time there - here's what I would want to say: The best thing that Recurse (RC) did for me was help me get in touch with my own taste. When I arrived I was making games that were pretty \"normal\" - Flash-style games with high scores and weak themes. While there I got weird. One of my first projects was an abuse of the OpenSearch spec to make a version of Wordle that ran in the Firefox address bar[1]. It was the perfect place to build something like this - folks were encouraging and supportive and interested; it made me realize that people were interested in the type of thing I actually wanted to do. I think I shipped 8 games during my 12 weeks at RC. I wouldn't have started making the types of things I now make without RC. I think plenty of folks have similar experiences across all sorts of techy things, not just games. Kinda like finding product-market fit but for your own interests. RC also connected me with a bunch of folks that were doing similar things. The community is huge and kind and weird in the best way. It is like a writers' retreat but for people that want to program (and become better programmers). I am probably coming off as shilling RC hard and I suppose I am (although I'm not being paid for this - I'm just a grateful alum). I'm literally typing this from the RC space right now (I occasionally stop by to chat with people in batch and work). [1] https://eieio.games/nonsense/implementing-wordle-in-the-fire... reply guessmyname 6 minutes agoparentprevI also attended years ago, but didn’t work much for me. Some of the residents/alumni are relatively famous in our industry — https://www.recurse.com/residents reply zellyn 1 hour agoparentprevCheck out https://sfpc.study/ too! The School for Poetic Computation is an experimental school in New York City and online supporting interdisciplinary study in art, code, hardware and critical theory. It's a place for learning and unlearning. reply eieio 2 hours agoprevdev here, fun surprise to see this on the front page (I'm glad it's resonating! give the pico-8 a try!) happy to answer q's if anyone has one. I haven't built a full pico-8 game since this (my stuff got...weirder...[1]) but I miss it + have been toying around with playdate and picotron ideas. [1] https://news.ycombinator.com/item?id=40800869 reply robin_reala 1 hour agoprevWorth mentioning this tale of the psychological and social suffering brought about by the DVD logo never quite hitting the corner of the screen: https://www.youtube.com/watch?v=_ws0QtAiiXQ reply EGreg 1 hour agoparentJazz Emu fan! reply davikr 10 minutes agoprevFantasy consoles would make for interesting programming learning environments for aspiring school or even CS students, I think. reply tombert 3 hours agoprevStuff like this makes me utterly adore Pico-8. It's one of the most fun coding environments I've used since I first discovered the ActionScript in Macromedia Flash MX. reply Waterluvian 2 hours agoparentThe retro IDE is a huge attractor for a lot of people but for me I just love the limited constraints at runtime. I wish I had a high resolution modern editor for code/sound/graphics to work with, but was still limited by resolution, cpu power, API, etc. reply hbn 2 hours agorootparentCreating within set constraints breeds unprecedented innovation and some really interesting stuff. For about 25 years there's been a small but dedicated group of people making romhacks for Super Mario World, and the early stuff was pretty quaint -- mostly rearranging tiles and enemy placements to make new levels. But over the years people have done some incredible hacks with custom graphics, enemies, mechanics, you name it. I've played some of them on real Super Nintendo hardware with a Super Everdrive which allows you to load rom files to the cartridge memory from an SD card. It's amazing what some people have made. reply eieio 1 hour agorootparentHave you played with Mario Builder 64? I did a game jam with it last month and found it really delightful. You're pretty restricted in what you can do - practically no coding, just pulling in components from the Mario 64 base game - but in exchange it's really simple to get a whole level up and running in like an hour (our whole game jam was 2 hours long). My level design skills are pretty weak. Being able to partially compensate for that by getting built-in nice character movement, enemy design, etc for free was really really nice. If I wanted to do more 3D stuff right now I'd almost certainly be using something like Mario Builder (I think stuff like Doom custom maps get at a similar idea). reply tombert 2 hours agorootparentprevExtremely tangential but I think relevant: some of the DOOM mods that are still being made are utterly phenomenal. It's easy for people to think \"Why would you constrain yourself to a DOOM engine when you could use Unity/Godot/Unreal/whatever and have better graphics and more freedom?!\", but that's kind of missing the point. The point is figuring out how far you can stretch something, and how to get the most out of something limited. Blade of Agony, for example, exclusively runs on GZDoom, which while more advanced than the vanilla DOOM engine, is still a lot more limited than Unreal or something, but I think that what they did to really stretch that engine to its fullest extent has made something that's extremely fun, charming, and gives it a distinct look and feel that you simply wouldn't have if you used a \"modern\" engine. reply whou 1 hour agorootparentSelaco is also another jaw dropping example of a modern game using the GZDoom engine! reply tombert 1 hour agorootparentI am surprised I haven't heard of this one, doing a quick search it looks downright incredible and hard to believe that they managed to stretch GZDoom to handle it. reply Waterluvian 1 hour agorootparentprevI love the SMW romhack that’s an entire game just in the over world. reply galleywest200 2 hours agorootparentprevCheck out Lexaloffle's new project, Picotron. You can _almost_ think of it as a \"Pico-64\" with desktop environment. Comes with a tracker, larger text editor, etc. https://www.lexaloffle.com/picotron.php reply tombert 2 hours agorootparentprevYeah I agree. Being constrained to a relatively low resolution and memory makes everything a lot more approachable and more fun for me. Obviously I could have as much flexibility as I want if I learned Vulkan and wrote all the graphics calls myself, but of course that's really hard and time consuming. Pico-8 being restricted makes it easy for me to quickly hack something together just for fun. reply chrisstanchak 1 hour agoprevMade this a while ago if you just want to look at the screensaver. https://stanchak.github.io/dvd/ reply shortrounddev2 4 minutes agoprevI love these little fantasy consoles. I think this is how coding should be taught, with small runtime requirements and simple tools which let people start adding graphics and movement on the screen immediately reply tyronepalmer 3 hours agoprevThis would be a blast on the Playdate, perhaps even using its little crank to advance time (and additional points for keeping the right rhythm?) reply nosrepa 1 hour agoparentStars Of the Screen has a DVD attract screen game. reply frakt0x90 3 hours agoprevThat was really fun and a good explanation of the PICO-8 environment. Well done! I got 19 but think I got lucky towards the end. reply SebastianKra 1 hour agoprevSomehow got 19 by hitting a lucky streak at the end. Now I can rest easy knowing I'm not gonna beat that. reply onemoresoop 2 hours agoprevI absolutely love PICO-8. Never been a hardcore gamer but started playing PICO-8 games on my commute after buying a Myioo mini. The games are simple but are extremely playable and fun. reply sureglymop 11 minutes agoparentSame here and I highly agree! My favorite games are simple (e.g. Suika Game Demake) but so fun and addicting. reply pseudosavant 1 hour agoprevObligatory post to my DVD screensaver done in all CSS and inline SVG. https://dvd-player-screensaver.glitch.me/ reply rylittle 1 hour agoparentIs there an easy way to actually make this my screensaver? (on mac) reply jimbosis 52 minutes agorootparentThere is this Rust program to display a bouncing DVD logo in a terminal: https://github.com/pythops/bouncinamation https://news.ycombinator.com/item?id=35785932 [2023] I haven't used a recent macOS in years, but I use the following command to get a fullscreen screensaver and locked screen on (Devuan GNU+) Linux. It's probably about as secure as a cheap padlock and flimsy chain or cable to lock a bike. xtrlock -f & xterm -fullscreen -e 'sleep .05 ; /path/to/file/bouncinamation' You can skip the 'xtrlock -f &' part to just run 'bouncimation' in a fullscreen xterm. 'Esc' exits. If running with 'xtrlock' you must enter your password first to unlock 'xtrlock', and then 'Esc' to exit 'bouncinamation'. The 'sleep .05' is to make it work better or more reliably. I don't remember exactly what, but there was some kind of issue that was fixed when I did 'sleep .05' before running 'bouncinamation'. reply pseudosavant 1 hour agorootparentprevI’ve never used it but it seems like this would do the trick. https://github.com/liquidx/webviewscreensaver reply make3 1 hour agoprev [–] it would be fun to make an open-ai gym wrapper on this & train an rl agent to hit the corner every single time reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Game 6: Put the DVD Logo in the Corner\" is an arcade action game created by Margaret Lyons, developed in just 4 days using the PICO-8 platform.",
      "The game was created at the Recurse Center and is available on itch.io, with its code accessible on GitHub. It is a short game (45 seconds) based on a joke.",
      "PICO-8 is a \"fantasy console\" that mimics 80s consoles, with limitations on graphics, sound, and code size, making it ideal for small, simple game projects."
    ],
    "commentSummary": [
      "The post discusses the Recurse Center, a free residency program for programmers that fosters creativity and personal growth, with the author sharing their experience of creating 8 games in 12 weeks.",
      "There is a notable interest in fantasy consoles like Pico-8, which are praised for their constraints that encourage innovation and quick, fun coding projects.",
      "The conversation includes various references to retro gaming and programming environments, highlighting the community's appreciation for creative coding within limitations."
    ],
    "points": 192,
    "commentCount": 35,
    "retryCount": 0,
    "time": 1720190894
  },
  {
    "id": 40882243,
    "title": "Space Age release date",
    "originLink": "https://factorio.com/blog/post/fff-418",
    "originBody": "Factorio.comForumsWikiMod PortalAPI Docs Log inSign up 🇺🇦 We support the Ukrainian Red Cross. Game Screenshots Videos Content Artwork About us Buy Demo Merch Blog Support Help FAQ Presskit Contact Friday Facts #418 - Space Age release date Posted by Factorio team on 2024-07-05 Hello, Today we want to share some exciting news! Factorio: Space Age - Release date We plan to release Factorio: Space Age expansion on October 21st 2024. The reasoning for this date is that it will give us enough time after summer vacations to polish the release, while also leaving enough time afterwards if we need to do bugfix patches before the Christmas holidays. The price of the Space age expansion will be $35.00, the same price as the current base game. You can wishlist the game now over on Steam. Factorio: Space Age - Content Factorio: Space Age continues the player's journey after launching rockets into space. Discover new worlds with unique challenges, exploit their novel resources for advanced technological gains, and manage your fleet of interplanetary space platforms. Space platforms - FFF-381 The backbone of planetary logistics and the first foray into space. Space platforms are flying factories that act as the means of transportation between planets. Build defenses to shoot down incoming asteroids which threaten to smash your platform. Catch asteroid chunks, crush them and process them into thruster fuel and turret ammunition. Use the Platform hub and Cargo bays to shuttle cargo between planets. Vulcanus - FFF-386, FFF-387 Blazing volcanic mountains, imposing geological landforms, plains blanketed in ash, and thick yellow sulfuric fog that burns your lungs and etches your eyes. Extract and refine tough unbreakable Tungsten to craft big mining drills and foundries. Pull lava from the pits to produce an abundance of molten iron and copper. Research advanced metallurgic technologies to build an industrial forge-world. Fulgora - FFF-398, FFF-399 A lifeless and desolate place. The thin air is freezing cold but bone dry. A distant sun twinkles in the dull purple of the sky. Wispy clouds race by as a gale whips up sand that grates against your armour. Protect yourself from the nightly lightning storms, harness their unrelenting power for your own electricity needs. Reclaim the high-tech scraps and ruins of a long-forgotten civilization and recycle them into usable products. Unlock the advanced electromagnetic and superconducting powers of Holmium. Gleba - FFF-413, FFF-414 A vibrant multi-coloured swampy landscape shrouded in a light mist. The air is thick and humid, carrying the muffled cries of unseen animals from far away. Discover exotic plants, cultivate and harvest their fruits with Agriculture towers. Cook, crush, and process your produce before they rot and turn to spoilage. Venture into a new realm of biochemical engineering. Elevated rails - FFF-378 Take your trains to the next level! Elevated rails bring a whole new dimension of challenge and possibility to your rail networks. Heavy-duty rail ramps and supports to elevate your rails. Cross over any obstacles, build supports on the water to cross oceans. Design advanced multi-level intersections to optimize your train system. Quality - FFF-375 Make high tiers of quality of all your items, machines and equipment. Every Item, Entity, and Equipment has 5 possible qualities, from Normal to Legendary! Research the new Quality modules, use them to craft higher quality items and intermediates. Each level of quality gives a greater bonus, machines craft faster, equipment is more powerful, turrets have increased range, etc. And Beyond... The journey doesn't end there, there is a lot more coming with Factorio: Space Age, and a lot more left to be revealed: Space Age Music - Each new planet is accompanied by a unique soundtrack by Czech composer Petr Wajsar - FFF-406 New enemies and defenses - Some new planets are inhabited by unique and dangerous creatures you will need to defend against. An enigmatic 5th planet - promises some of the most unique gameplay but it remains shrouded in mystery. It's the furthest planet from the sun so it's dark and cold. Factorio 2.0 But thats not all. Factorio: Space Age will also coincide with the release of Factorio version 2.0 which will be a free upgrade for all users. Version 2.0 has a wide range of game changes and improvements: Smarter worker robots - FFF-374 New rails - FFF-377 Remote view - FFF-380 Combinator and circuit network improvements - FFF-384, FFF-405 Train control improvements - FFF-389, FFF-395 New fluid system - FFF-416 Overhauled Nauvis terrain generation - FFF-401 And more each week! Get the latest updates If you want to keep up with the latest news be sure to check our weekly development blog or you can subscribe to our newsletter. You can also wishlist the Factorio: Space Age expansion on Steam, so you will be notified when it releases. As always, release your thoughts at the usual places. Discuss on our forums Discuss on Reddit Subscribe by email Terms of Service|Privacy|Imprint|Presskit|Contact|RSS|Jobs Copyright © 2015 - 2024 Wube Software - all rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=40882243",
    "commentBody": "Space Age release date (factorio.com)183 points by franknord23 6 hours agohidepastfavorite64 comments AndrewOMartin 5 hours agoIf you're wondering whether to get involved in this game, and you've ever suspected you're a little vulnerable to getting addicted, then I'd suggest keeping a very cautious exclusion zone around Factorio. Alternatively, if you do get ensnared, then installing a mod which allows you to edit and experiment freely might help you \"see the matrix\" behind the game and dispel the enchantment somewhat. The jokes about losing days, months, sleep, relationships, and jobs are not always jokes. reply blueflow 5 hours agoparentI bought it for myself Christmas 2023. I spend the first week of 2024 playing in 36-hour streaks, did not show up to friends and relied on SO to supply me with food. Second week in January i went back to work, but spent most of my time outside of that playing. I restarted social activity in February, around May the addiction had largely burned out and playing increasingly didn't give \"the kick\" anymore. I had around 500 hrs of Gameplay at that point. These weeks i still plan to waste every other evening with Factorio, but usually i end up programming or doing housewife stuff instead. I think i would do that again. Thanks to SO for supporting me when doing silly things. reply ffsm8 4 minutes agorootparentYou might want to check out Dyson sphere program if you haven't already. The fixation will likely go away much quicker then factorio's, but its another take that has its own charm reply input_sh 2 hours agorootparentprevThe way I stopped myself is by launching the rocket to space once and then never opening the game again, as I have seen everything it has to offer. I think my worst nightmare would be if Factorio and Civ had a baby, as in the same Factorio gameplay, but with a bunch of playable characters that essentially just tweak the numbers a bit. reply tarsinge 5 hours agoparentprevI think I fall on the vulnerable camp but after a very intense phase I fortunately lost interest after a few weeks. Refactoring is not fun, and I prefer to be payed for it. So for me long term addiction is not a risk , but short term you better have nothing else to do. reply Ekaros 4 hours agorootparentI like to tinker, but at some point it all just becomes overwhelming and I just loose the feeling. As next step would be having to rebuild everything again. And that would mean setting up the production for bots, parts, and so on with big enough scale... I just don't have that in me... reply nmeofthestate 5 hours agoparentprev\"If you think you'd really love playing this computer game, please consider avoiding it\" - I'm sure Wube will be delighted to see this advice at the top of the HN comment thread! reply seneca 5 hours agorootparent> \"If you think you'd really love playing this computer game, please consider avoiding it\" Addiction isn't equal to \"really lov[ing]\" something, and it's childish to equate them. Video games are incredibly addictive and ruin a lot of lives. That's not to say they're not valid or good forms of entertainment. Some people just can't handle them. reply athorax 4 hours agorootparent100% agree. My friends and I have played WoW on and off since release, and I never thought much of it. I could easily step away from it and used it mostly as a way to keep in touch with that group. We recently found out how much of a toll it has taken on one of ours friends lives who has pretty much always played even while the rest of the group was taking breaks. reply nmeofthestate 3 hours agorootparentprevOK - call me childish, but Factorio is a one-off payment of £35. There's no danger of spending more money than that, so the only thing you'll be wasting is your own time playing it. It's an over-reaction to characterise it as posing some kind of life-threatening danger. Play a lot of Factorio and yep - you've wasted a bunch of your time (ask me how I know :-) ). reply nmeofthestate 3 hours agorootparent(of course there's the Space Age expansion - that's another £35) reply Lichtso 4 hours agoparentprevI have found that procedural generation tools such as Blender are a good substitute for (single-player) Factorio. Especially the node DAGs such as shaders and now geo-nodes feel a lot like belts, inserters and assemblers. Plus in the end you are not just increasing some game item count, but get beautiful scenes to marvel at: https://www.youtube.com/watch?v=vW9pCT5ouZ8 reply dark-star 4 hours agoparentprevMan I wish I could have gotten into Factorio the same way other people have. I bought it very early and have been trying to play it at least once every 6 months or so since then, but somehow it just didn't \"click\" with me. I think it's because of the graphics, while they look cool in close-up, they are just a bit too cluttered and \"washed out\" when zooming out, making it hard to see the whole picture of your factory. I will probably try this one as well but I don't have very high hopes... reply giancarlostoro 5 hours agoparentprevI mostly just leave it running in the background and tweak as things happen. I don't rush it, but the game has a tendency to try to rush itself on me, thankfully you can make settings changes. reply louwrentius 5 hours agoparentprevMore than 3000 hour in. Although I’m not playing currently, I feel like I have to take the last quarter off work. reply 93po 4 hours agoparentprevI got sucked into Satisfactory for weeks and as much as I want to try Factorio, I am heeding your advice reply rawrgrr 1 hour agorootparentI am curious what draws you to Satisfactory. I played a decent amount of Factorio and thought Satisfactory would scratch the same itch, but could not get into it reply pixl97 3 hours agorootparentprevCracktorio, Satisfactory, Captain of Industry, Workers & Resources: Soviet Republic... Who needs drugs when you have these. reply franknord23 5 hours agoprevIf you want to pass the time until October, i would recommend the Ultracube: Age of Cube mod [0]. It does not stretch out the base game with additional tedious steps, instead it gives a big twist to what you knew about factories. Here is a good let's play introduction to the early game: [1] [0]: https://mods.factorio.com/mod/Ultracube [1]: https://www.youtube.com/watch?v=eOOANJhv2MU&pp=ygUJdWx0cmFjd... reply moconnor 5 hours agoprevPushes back the timeline for AGI by a good 3 months! reply pqdbr 5 hours agoparentLol. But yes, every productivity hack blog article should start with “never install Factorio”. The only worse offender is Factorio. But it was so worth it. reply kelthuzad 5 hours agoprevI always feel like \"I should rather do real work instead\" while playing such complex games that almost feel like work to learn. maybe that's just a byproduct of a \"toxic productivity\" mindset I developed reply bavell 5 hours agoparentSame here. I played a lot more games in my teens and 20's than I do now. I also prefer games with less of the \"you need to read the guides and watch tutorials before really groking things\" type of games these days. reply atrus 5 hours agorootparentFactorio is actually really well designed that you don't need guides or tutorials to \"beat\" the game imo. Sure, there's guides and tutorials if you want to reach peak efficiency, but that's true for any game. reply db48x 5 hours agorootparentprevFactorio is extremely approachable. There’s no need to refer to outside materials or guides at all. There’s nothing hidden. All the information you need is right there in the UI. reply fabian2k 4 hours agorootparentAnd it's getting improved in 2.0 further with regards to the inline documentation of all the recipes (https://factorio.com/blog/post/fff-397). reply lokar 4 hours agoparentprevI have a similar feeling playing sudoku and others where I can “see” the algo to solve it right in front of me. But I love factorio. It’s like programming something fun without all the meetings. reply smithrj 5 hours agoprevPairing in Factorio for an hour could replace a round (or two) in an interview loop. I'm convinced it would produce much stronger signals for engineering teams on how folks approach solving problems in a collaborative/team setting. reply fragmede 4 hours agoparentI agree with you, but then you risk losing the whole team to Factorio. reply bloopernova 5 hours agoprev\"Includes Factorio 2, which is a free upgrade for all users.\" Honestly, Factorio is one of those games I would pay extra to keep going. Kudos to them for making the base game upgrade free. reply lokar 4 hours agoparentThey just put out a bug fix patch, almost 4 years after the 1.0 release. Very rare in the industry today. reply schnitzelstoat 5 hours agoprevI can't wait. I played it years ago and it was a lot of fun. Recently I've been playing Workers & Resources which has a similar focus on logistics so it'll be fun to go back to the OG. reply franknord23 5 hours agoparentI am debating whether i should take time off work. Though the release date may still slip by a week or more, i guess. reply herpdyderp 5 hours agoprevThe incoming bot, blueprint, and train updates are so good I can’t play 1.0 anymore :( I’m still not sure how I feel about the planet stuff though reply bloopernova 4 hours agoparentI'm a big fan of rail networks in Factorio, I am really looking forward to the new changes. They're going to improve quality of life a lot, it's very exciting! I'm also looking forward to whatever happens with the Angel's and Bob's mods, because I really enjoy the vast web of materials I can create. Pic of my previous playthrough's rail network: https://imgur.com/a/XcamKQB It kind of looks like a CPU to me. reply db48x 5 hours agoprevOh, how odd. That’s exactly the day I am catching the flu! reply teractiveodular 5 hours agoprevIf you don't want to wait, the rather stupendous Space Exploration mod to Factorio is available now: https://mods.factorio.com/mod/space-exploration Warning: this is stupidly time consuming (as in, hundreds of hours just to get to orbit) and you'll need to already be proficient in Factorio to make any headway. reply tylervigen 5 hours agoparentWube hired the creator of that mod to develop this expansion, and he says that they are nothing alike (except for the “going to space” part).[0] [0] https://factorio.com/blog/post/fff-373 reply moritonal 5 hours agoparentprevFun fact for those that didn't know. The dev's hired the author Earendel to come convert said mod into a full DLC. It's interesting seeing how the different dynamics of making a polished and widely playable DLC changes what does and doesn't make the cut from mod -> DLC. I hope some of Earendel's love of secrets do make it. reply delichon 5 hours agoparentprevIs it harder than Sea Block? That's the one that was finally too much for me to finish, after doing other big ones like Bobs Mods, AngelBob, Pyanodon, etc. I've got a Sea Block attempt with hundreds of hours in it, my largest base ever, before I fell off. If Space Exploration is more complex I'm a little afraid of it. reply 12345hn6789 5 hours agorootparentMuch easier than seablock. But it's a chore. The end game is a grind instead of a challenge like sesblock reply nrjames 5 hours agoprevI always bounce off of Factorio because I want to be able to play with the default settings but I always end up getting killed by bugs/aliens not long after starting the game. reply corobo 5 hours agoparentI turn them off entirely. I'm playing Factorio to make trains and things to make the trains train about the place. Ain't got no time for random critter waves. reply slowmovintarget 1 hour agorootparentWell... When you level up a bit, your trains become an unstoppable bug-mashing barrier around the perimeter of your base. The bugs try to cross the tracks and SQUISH! No more bugs. No need for turrets or ammo, just trains. It's the Factorio equivalent of the mine cart blender room trap in Dwarf Fortress, certified to kill even clown invasions. reply blueflow 4 hours agoparentprev- Generate new random seeds until you spawn in a forest / grassland area. Greener areas absorb more pollution so the pollution travels less across the map. - Set spawn area to largest. Earliest biter nests get generated farther away, making it more difficult for your pollution cloud to reach them This way you can play largely in peace without having achievements disabled. reply franknord23 4 hours agoparentprevStarting in a forest/grassland area will give you more time until the biters come. Or just play in peaceful mode, there is still so much good gameplay left even without the challenge of biters. reply franknord23 4 hours agoprevHmm, looks like some Hacker News mod did not like this post :/ (title was edited (OK, it was not strictly following the rules) and post moved to bottom of the front page) reply delduca 5 hours agoprevThe first time I played was right at the beginning. I bought it on Friday afternoon and spent the entire weekend playing. I did almost nothing else, and I must have spent over than 50 hours that weekend. After that, I kind of avoid the game, but if you are a controlled person, I highly recommend it, especially if you are familiar with Kafka or other queues. Setting up the assembly lines is basically the same thing. reply bluelightning2k 5 hours agoprevI really dislike the idea of \"quality\" in the context of Factorio. reply db48x 4 hours agoparentFor myself I am holding off on forming an opinion. They have already said that you can play the whole game without ever using it, if you want. reply makin 3 hours agoparentprevI think quality is fine, the issue is the strings, having \"Legendary Wire\" in a serious factory game. reply nebulous1 5 hours agoprevPerhaps I'll be finished my K2SE run by then. Probably not. reply sambaumann 5 hours agoparentI started my K2SE run in march and I've come to accept I'm not going to finish by the time Space Age comes out. reply bloqs 5 hours agoprev [–] I was really put off by the pricing fiasco. Was that unreasonable? reply squigz 4 hours agoparentWhen I initially heard that the dev doesn't do sales, I felt similarly, but it makes sense for a lot of people (as other commenters point out) reply goda90 5 hours agoparentprevWhat pricing fiasco? reply arandomhuman 5 hours agorootparentiirc the developer doesn’t do sales? idk it was never a fiasco, just bad if you like sales I guess. reply teractiveodular 5 hours agorootparentHow is that a fiasco? Per hour played, Factorio is stupendously good value, you pay once and you can play forever. reply Jyaif 4 hours agorootparentprevThe absence of sales is a big win for me. It made it a no-brainer purchase for me. reply pixl97 3 hours agorootparentYep, having sales makes a fair number of people wait until there is a sale. Without sales you're pushed back to a (more) binary decision, do I want the game or not, rather than do I want the game at $X price. Also with sales you get some portion of people that buy things because they are on sale rather than knowing if they really want the game or not, which can lead to complaints on forums. reply jasonlotito 4 hours agoparentprevThere is no pricing fiasco. It was respecting their customers. If \"pricing fiasco\" is how you describe respecting your customers, than yes, you are being unreasonable. For those unaware, It's always the best time to buy Factorio. You dont' have to worry about buying it and then it going on sale. You can buy it, and know what you are buying and that you are getting the best deal. It's a wonderful game and 100% worth the price. If you don't like those types of games, no reason to buy it. That's fine. No reason to pretend that there is some fiasco. No customer feels that way. reply lokar 4 hours agorootparentOne possible valid criticism is they charge the same price (in USD) everywhere in the world. Many (but certainly not all) games are effectively discounted in poorer countries when converted to the local currency. reply jasonlotito 3 hours agorootparentThey do charge regional pricing. They don’t on their website where it’s always the same price. But they do regional pricing on Steam. reply db48x 4 hours agoparentprev [–] Yes, you are unreasonable. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Factorio: Space Age\" expansion is set to release on October 21, 2024, priced at $35.00, the same as the base game.",
      "New features include space platforms, multi-level rail networks, and planets with unique resources and challenges, such as Vulcanus, Fulgora, and Gleba.",
      "\"Factorio 2.0\" will be a free upgrade, offering game improvements like smarter robots, new rails, and enhanced terrain generation."
    ],
    "commentSummary": [
      "The release date for Factorio's Space Age expansion has been announced, generating excitement and discussions about the game's highly addictive nature.",
      "Users shared personal experiences, warning about the potential for the game to consume significant time and impact daily life, while also recommending similar games and mods.",
      "The community discussed Factorio's pricing strategy, appreciating the consistent value due to the absence of sales, and expressed both excitement and caution about the immersive gameplay."
    ],
    "points": 183,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1720183629
  },
  {
    "id": 40881836,
    "title": "I’ve made a cheaper SEO research tool",
    "originLink": "https://withtelescope.com",
    "originBody": "In the last 13 months I&#x27;ve spent total $1297 for Ahrefs subscription. Sounds like a little too much so I&#x27;ve build my own Keywords Research tool - Telescope.While building it my total bill was $51 for 2 months and 41k+ keywords found. Every page of keywords costs $0.03 - $0.05. 2 payment options - usage-based subscription or just top up your balance with the amount you&#x27;d like to.Telescope includes a couple of things:- Keywords Explorer - finding keywords based on seed phrase and filters- Keywords Ideas - keywords on interception on provided keywords- Ranked Keywords - keywords a domain you specified with their positions and change since last DB update- Saved Keywords - to store found keywords and plan the SEO strategyI&#x27;ve put a lot of love into it and would love to get some feedback. IMPORTANT: every new account gets some free balance to start with. Appreciate it!",
    "commentLink": "https://news.ycombinator.com/item?id=40881836",
    "commentBody": "I’ve made a cheaper SEO research tool (withtelescope.com)168 points by kulhavy 7 hours agohidepastfavorite81 comments In the last 13 months I've spent total $1297 for Ahrefs subscription. Sounds like a little too much so I've build my own Keywords Research tool - Telescope. While building it my total bill was $51 for 2 months and 41k+ keywords found. Every page of keywords costs $0.03 - $0.05. 2 payment options - usage-based subscription or just top up your balance with the amount you'd like to. Telescope includes a couple of things: - Keywords Explorer - finding keywords based on seed phrase and filters - Keywords Ideas - keywords on interception on provided keywords - Ranked Keywords - keywords a domain you specified with their positions and change since last DB update - Saved Keywords - to store found keywords and plan the SEO strategy I've put a lot of love into it and would love to get some feedback. IMPORTANT: every new account gets some free balance to start with. Appreciate it! scientific_ass 6 hours agoThis is super cool and I would love to try it out. We use SEMrush and they are basically charging us +$1000 dollar for the basic plan, with every other feature as an add-on for addition $200 - $400. Question: Do you have (or plan to provide) features like - -- Questions around the seed keywords -- Keyword exports for external analysis with details like volume, difficulty, etc, -- Can I tag keywords if I save them in a particular list? In my work, I do SEO research almost every day and have a very extensive keyword strategy. So above features are what's keeping me stick to SEMrush. reply kulhavy 6 hours agoparentHey, Thank you! We're planning to add premade filters for \"Questions\" and \"Long tail\" and a couple of others filtersets. Keywords Export is coming for sure. You can't tag just yet, but we will add this to backlog and implement according to our roadmap. reply vivzkestrel 5 hours agoparentprevwhat would it take to build a SEMRush alternative? reply kulhavy 5 hours agorootparentQuite some time but we'll get there one day reply weinzierl 6 hours agoprevHow important do you think this kind of tool is in the age of massive amounts of LLM generated text everywhere? While content mills that could crank out any keyword optimized content very cheaply existed for a long time it is now basically free. Whereas producing deep and well researched articles maybe doesn't need that razor sharp focus on specific keywords? Since you made this tool, you probably think otherwise, but I would like to hear your opinion. reply heresie-dabord 5 hours agoparent> the age of massive amounts of LLM generated text everywhere I would say that meaningless, soulless inputs had already inundated the WWW thanks to the economics of Search Engine Optimisation. reply maxencecornet 3 hours agoprevFor OP: Would you say this is a drop-in replacement from ahref's lite plan ? What would I miss from ahref ? reply foragerdev 1 hour agoprevwhoever is wondering about the website home page design, it looks direct copy paste from here: https://tailwindui.com/components/marketing/elements/headers... reply throwaway425933 15 minutes agoparentI hate that, on the linked page, most of the good ones are paid templates. :( Is there a repository of high quality but free templates. I hate to use bait and switch websites/frameworks. reply foragerdev 5 minutes agorootparentLet me know if you find one. You can design your website yourself by taking inspiration from other different websites but as a person who is not a web designer gaining consistency in your design is tough. Usually a template is not enough, it may help you with some scaffolding (such as setting a theme or fonts) but you need to have some knowledge about web design to at least make it look consistent. reply wcedmisten 29 minutes agoparentprevThis is funny to me because it also looks just like Plausible Analytics' design. (They also used Tailwind). I guess both took heavy inspiration from the tailwind example design https://plausible.io reply baxtr 6 hours agoprevWhat I learned recently was that all the SEO tool basically query the same back end provider. So I guess it makes sense that there is innovation on the pricing model side of things. We use ubersuggest which has a lifetime pricing, quite neat. reply mikkom 6 hours agoparentPlease enlighten us about the backend provider, I'm interested. It seems the OP of this thread is using the same backend as he's not willing to tell it. edit: Ubersuggest mentioned by someone says in dev blog https://neilpatel.com/blog/ubersuggest-update/ > My data feed from SEO Power Suite, Data For SEO, and Shared Count totaled $75,253 for January. Is this the backend mentioned? Some direct links for others interested in this https://www.link-assistant.com/backlink-api.html https://dataforseo.com/ https://www.sharedcount.com/ reply weinzierl 6 hours agorootparentAt first glance these look like sources for backlink data to me, which is the easy part. I think the real value of a keyword tool like ahrefs lies in the estimated search volume which comes from different sources than the backlinks. Is this about a monopolistic provider of backlink data or search volume estimates? reply 55555 5 hours agorootparentThe search volume estimates come from creating massive amounts of accounts that scrape Google Keyword Tool. reply nickfromseattle 5 hours agorootparentAhrefs says \"and other third party data sources to find keywords\" [0] Pretty sure they buy data from software tools like free anti-virus scanners, toolbars, chrome extensions, VPNs, etc that resell their user's web browsing history. This is called \"click stream data\". [0] https://help.ahrefs.com/en/articles/78119-where-do-you-get-t... reply weinzierl 5 hours agorootparentprevThis would be funny, because the sales pitch of some prominent keyword tools is, that Google Keyword Tool can't be trusted. reply baxtr 6 hours agorootparentprevI casually read it on twitter, I can't find it anymore. Bummer. I should have bookmarked it reply mikkom 6 hours agorootparentI fortunately found some details myself too (edited the parent), thanks anyway reply RamblingCTO 6 hours agorootparentprevGreat, thanks for sharing! reply weinzierl 6 hours agoparentprevInteresting! I always thought, this kind of data was collected from a plethora of borderline shady browser plugins (SEO plugins amongst them, ironically), toolbars and alt-browsers. This is also, why I think the data must be heavily biased. For example the HN demographic must be severely underrepresented, because most of us are careful what we install. reply nickfromseattle 5 hours agorootparent> why I think the data must be heavily biased. This is correct, but you can estimate the bias. B2B keywords typically have 2-5x higher search volume/month than the popular tools estimate, for exactly the reason you provided. More sophisticated searchers aren't installing random anti-virus, VPNs, and plugins the SEO tools rely on to calculate keyword search volume. reply knuckleheads 6 hours agoparentprevWould that happen to be Majestic by chance? reply matrik 6 hours agoparentprevwhat’s the name of the backend provider? reply glenngillen 6 hours agorootparentMajestic reply kulhavy 6 hours agorootparentI can say it's not that one, if it's that important to know - DataForSEO is our provider for every aspect at the moment. reply nprateem 5 hours agorootparentWhat's the rough pricing if you don't mind my asking? Their pricing is buried behind contact forms. reply kulhavy 5 hours agorootparentIt depends. ~$0.01-$0.03 per query reply kulhavy 6 hours agorootparentprevI'd prefer not to tell, thank you for understanding! reply alangibson 6 hours agorootparentThat just confirmed that you're using \"the same backend provider.\" Buy itself that's not bad. The problem is that if you're doing what everyone else is doing, then you're probably not realizing any efficiencies. That means your prices will eventually mirror everyone elses. reply weinzierl 5 hours agorootparentprevI am confused. I always thought keyword tools use both: backlink data and estimated search volumes. For example ahrefs has, to the best of my knowledge, its own crawler for backlink data but mostly buys search volume estimates. Does your tool offer search volume estimates at all and does it come from the same provider as the backlink data? reply kulhavy 6 hours agoparentprevYou're right, that's exactly what out though process was. Thank you! reply mceoin 16 minutes agoprevHi - is there an API? reply raimille1 6 hours agoprevAwesome!! Congrats on the value prop and landing!! Very clear. I run a marketplace in Brazil (kwara.com.br) and we happen to be focusing on SEO at the moment! What's your coverage in Portuguese / Brazilian market keywords? Or is it US only at the moment? (Ps, I don't mind the tool itself being in english) reply kulhavy 6 hours agoparentThank you! We have 150M+ keywords for Brazil (PT) and 30M+ for Portugal (PT) and tons of other countries/languages too reply tethys 6 hours agoprevDo you offer an API? My issue with most keyword tools is that their APIs suck, with tight limits that force you to only request data in bulk, and so on. reply kulhavy 6 hours agoparentHey! No, and we don't plan to have an API yet. Thank you! reply tethys 2 hours agorootparentThat's unfortunate! I would immediately pitch this tool to my SEO colleagues if it had a (fairly priced) API :) reply dsmurrell 4 hours agoprevI don't know that much about SEO. Are you planning on adding a blog section maybe with a few article about how someone might use a tool like this to optimise their own SEO? reply hnrodey 4 hours agoparentsearch SEMRush or Ahrefs on YouTube. I assume usage of this tool is comparable to other established SEO tools. reply kulhavy 4 hours agorootparentYes, usage is comparable with other SEO tools that does Keyword Research reply cchance 3 hours agoprevThe question mark on the \"KEYWORD DETAILS\" on the pricing page... says... HEY ..... lol reply kulhavy 3 hours agoparentHi! I forgot to update it, will fix soon, thank you! reply Bewelge 6 hours agoprevThe background-color and content is missing when pressing the little question mark next to keyword details on the pricing page. Also thank you for sharing and congratulations on shipping. Will definitely try this out in the coming days! reply kulhavy 6 hours agoparentThank you for feedback! We'll fix this asap reply JourneyJourney 6 hours agoprevHow to understand the meaning of what I'm seeing on screen. I'm not versed into SEO but I'd like to. Your tool is very nice to use. reply edweis 6 hours agoprevYour logo is very similar to https://insomnia.rest/ reply weinzierl 6 hours agoparentBoth are similar to the Lua programming language logo, which is probably the oldest of the three: https://www.lua.org/ reply kulhavy 6 hours agoparentprevHaha you're right. Wasn't thinking about Insomnia while making a logo. Thanks for the reference! reply weinzierl 5 hours agoprevDo you provide keyword popularity and is it based on Google Keyword Tool data or clickstream data? reply kulhavy 5 hours agoparentHey! It comes from Google Ads (different tools) reply abdellah123 6 hours agoprevThis is something I've been looking for for a while !! What about keywords for France? and in Arabic? reply kulhavy 6 hours agoparentThank you! 18M+ keywords for France. Arabic is supported, but not for France reply cmer 6 hours agoprevVery nice! Awesome landing page! FYI, the `www` version of your domain doesn't resolve. You might want to add a redirect. reply kulhavy 6 hours agoparentThank you! Oh, you're right! We'll fix this one asap reply davidkuennen 6 hours agoprevThank you! This is great. Do you happen to know keyword tools that specialize on app store and play store search? reply kulhavy 6 hours agoparentHey! Our data provider has data from these marketplaces and if you stick for long enough with us we will add them for sure as current solutions are sooooo expensive. reply merlindru 7 hours agoprevInstantly bookmarked! Great landing page, will definitely check this out. Keep up the great work :) reply kulhavy 6 hours agoparentThank you! We're working right now on adding On Page + Backlinks into the app so Telescope becomes go-to solution for SEO reply iambateman 6 hours agoprevThanks for sharing! There’s so much opportunity to build lower cost tools here. Very cool. reply kulhavy 6 hours agoparentThank you! Our main goal is to make it affordable for makers like us. Paying $140\\m doesn't seem like a good idea and not many has such a budged, so here is our solution reply p3rls 3 hours agoprevThese are the products that are being used to destroy the internet. It's like selling meth at a school playground to applause. Nice UI execution I guess. reply TecoAndJix 6 hours agoprevFYI - Your FAQ at the bottom of each use-case page does not expand reply kulhavy 6 hours agoparentThank you! We'll try to fix this asap. reply samlinnfer 2 hours agoprev>Base your SEO strategy on higly precice and detailed data >higly precice reply newbie578 4 hours agoprevWhat is the difference between this and Google Keyword Planner? I am asking this as someone with minimum experience in SEO reply kulhavy 4 hours agoparentTelescope comes with more details on the data - Keyword Difficulty, Historic Search Volume, Ability to preview google results for different countries, Keywords for your specific domains and your position. Soon we'll have backlink data and it'll open up even more details on Keywords, SERP Preview, Domain Overview reply weinzierl 5 hours agoprevEmail sign-up would be nice. reply kulhavy 5 hours agoparentHey! Yes, you're right. We plan to add magic link sign up and a couple of other providers reply BubbleRings 6 hours agoprevclicking FAQ from your hamburger menu button is busted fyi. good luck! reply kulhavy 6 hours agoparentThank you! reply j45 3 hours agoprevHi, congrats on the launch! Are searches cached locally in my account? I accidentally reload a page, it seems to run the search again and charge the (free and provided) balance. Thanks reply cranberryturkey 7 hours agoprevlooks cool do you have a trial version? reply kulhavy 6 hours agoparentThere is no trial version, but there is a \"trial\" balance you get after a sign up to try the application. Feel free to contact me on X (Twitter) @ilyakulhavy if you need a little more, thank you! reply rexreed 6 hours agorootparentAre you also on LinkedIn? I stopped using X a while back and I have a bunch of questions on keywords and the site. reply kulhavy 6 hours agorootparenthttps://www.linkedin.com/in/keksonov/ here I'm too @kulhavy in telegram reply hyperfuturism 6 hours agorootparentprevYou don't have DMs open on Twitter, I think. I have some questions! reply kulhavy 6 hours agorootparenthttps://www.linkedin.com/in/keksonov/ here I'm too @kulhavy in telegram reply nickreese 6 hours agorootparentprevDropped you a note. reply twapi 4 hours agoprev [–] - No option to download as excel sheet - No option to sort by columns reply kulhavy 4 hours agoparent [–] Yes, you're right, it's not available just yet, but on our roadmap Thank you for feedback! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author built a custom Keywords Research tool named Telescope, spending $51 over 2 months, compared to $1297 on an Ahrefs subscription over 13 months.",
      "Telescope offers features like Keywords Explorer, Keywords Ideas, Ranked Keywords, and Saved Keywords, with payment options including usage-based subscription or top-up balance.",
      "New accounts receive a free balance to start, and the author seeks feedback on the tool."
    ],
    "commentSummary": [
      "A new, cost-effective SEO research tool named Telescope has been launched, offering significant savings compared to competitors like Ahrefs and SEMrush.",
      "Telescope's features include Keywords Explorer, Keywords Ideas, Ranked Keywords, and Saved Keywords, with flexible payment options and a free starting balance for new accounts.",
      "User discussions highlight the high costs of existing tools, the potential of Telescope as a SEMrush alternative, and inquiries about backend providers, API availability, and specific market data."
    ],
    "points": 168,
    "commentCount": 81,
    "retryCount": 0,
    "time": 1720178830
  },
  {
    "id": 40877992,
    "title": "NexDock turns your smartphone into a laptop",
    "originLink": "https://nexdock.com/",
    "originBody": "NexDock turns your smartphone into a Laptop Wired or Wireless… Learn More NexPad transforms your smartphone into a tablet Learn More Meet NexDock XL Coming Soon… Learn More Learn more about NEX devices and order yours today NexDock NexDock XL NexPad",
    "commentLink": "https://news.ycombinator.com/item?id=40877992",
    "commentBody": "NexDock turns your smartphone into a laptop (nexdock.com)166 points by Bluestein 22 hours agohidepastfavorite201 comments Jach 18 hours agoI wanted to like it but it's mostly been a paperweight in the closet for two years now... My problem is ultimately that none of the smartphones I've used or tried (a few androids and a librem) offer a desktop/laptop experience that's any good. In theory I still like the concept, upgrade a phone every N years but don't have to get a new laptop form factor, but the execution from all sides (even if mostly on the phone sides) isn't there. A few months after being disappointed I got an older Lenovo laptop from ebay that was $100 cheaper and obviously a lot more capable, being a full computer I could throw Mint onto, and have a nicer screen/keyboard as well as a better experience remoting into my home workstation. (NoMachine mostly, though it can also do games via steam's remote streaming or Moonlight/Sunshine. Natively the laptop can run some games but its limits are roughly unreal engine 4 tier on low-to-medium settings.) Since my usage is probably 90-95% on my home desktop, I really just wanted a travel laptop, and it serves that job just fine. More recently I've been impressed with my steam deck's desktop mode that's a fairly no-frills Linux distro, its use of flatpaks everywhere is kind of annoying though. When it's good enough to make a game for steam deck on the steam deck with e.g. godot and blender, it's good enough for a lot of other things. I've been chucking it in with my travel laptop for trips, but one of these times I'm going to have to try just taking it alone with just a mouse and keyboard to complement. reply nicoburns 17 hours agoparentIt's a crying shame that Apple don't offer a desktop mode on iPhones. The chips are more than powerful enough to give a no-compromises experience (for most use casual use cases at least), the disks are large enough to store 2 OSs, and they have a full desktop OS sitting around ready for use. It'd make it a lot harder to sell macs, but it would be an absolutely killer device. reply jsheard 17 hours agorootparentPeople have been begging for a real desktop mode on the iPad forever, if Apple won't even do it for a device which uses the same processor as their laptops and even has an official laptop-style keyboard accessory then they're certainly not going to do it for the iPhone. reply whycome 17 hours agorootparentThey’re really going at it from a weird angle. iOS 18 features the ability to screen share your iPhone to your desktop. They seemingly want to make sure you have a main Mac desktop always. I could see Mac doing something like the Surface Book form factor. Basically an iPad MacBook hybrid with more power. reply gumby 16 hours agorootparent> They seemingly want to make sure you have a main Mac desktop always. I’m willing to believe in this case it’s because they want the Mac to survive. I’m sure every Mac is profitable (in accord with one of Apple’s core values) but Mac sales are pretty tiny compared to other products. Even when Apple fans say “St Stephen would be rolling in his grave if they got rid of the Mac”, he famously said he’d milk the Mac for all it was worth while doing the next thing. Separately, there’s already a ton of writing on why iPad and Mac won’t completely converge reply 1123581321 15 hours agorootparentMac, iPad and Home/Wearables all bring in similar revenue. iPhone is the hardware category that dwarfs the rest. Software revenue is roughly equal to Mac/iPad/Wearables combined. reply iterateoften 16 hours agorootparentprevWith any new technology with apple don’t look at how it is used now but what products it will enable in 3-4 years. The iPhone streaming to Mac is most likely much more about improving AR inthe future than anything to do with Mac. Mac is just an easy platform to get more users using it. reply theshrike79 12 hours agorootparentThis is what people _always_ forget. Just like the new iPhone coming out this year isn't for the people who upgrade every year. It'll feel like a \"spec bump\". BUT it's for the people whose phone is dropping out of support after 5-7 years of major version upgrades. For them it's a massive leap of performance and features. Just imagine jumping from an iPhone XR to an iPhone 16? Same with the Vision Pro. Apple finally releases a Pro device that's just for Pro(sumer)s and people complain it's too expensive. It's the first version, they see what 3rd party devs can and want to do with it and release a new one. There's a rumoured patent about headphones with an external camera for hand tracking, which is a clear evolution of the one in the Vision Pro. reply Bluestein 11 hours agorootparentprev> They seemingly want to make sure you have a main Mac desktop always. At some point it might even become a \"licensing\" proposition: If you are registered (or once-connected) or some such as having a desktop, you will get Desktop features on your other devices ... (Of course once you buy the very expensive Apple brand docks, and keyboards and dongles and cables and adapters and (perhaps) extra monthly fees that you will need ... Maybe they might couple this with their AI efforts, in making their whole \"AI product\" into a hardware \"box\" that you need (even if the box is \"dumb\" and \"Amazon-echo like\" ... ... I am guessing Apple will be the first to \"commoditize\" AI. Perhaps via hardware. Expensive hardware. Apple hardware ...) reply naikrovek 8 hours agorootparentwhat in the world are you talking about? none of these things exist, or show any hint of existing. i'd love apple to make an apple dock. they don't because they don't need to; apple hardware uses thunderbolt 4, so thunderbolt docks work. (i do wish apple would support MST in their laptops though, so I can get multiple monitors connected via a single dock without that silly DisplayLink nonsense, but not even an apple dock could get around this limitation.) your paranoia about apple-proprietary docks, keyboards, dongles, cables, adapters and (perhaps) monthly fees, are completely off-base from what I've seen out of apple. ...and i'm not even an apple fan. reply Bluestein 8 hours agorootparentMight have overdone it a bit for sake of exposition, but Apple killed the headphone jack. Their accessory ecosystem is a thing ... reply refulgentis 16 hours agorootparentprevForgive me, I've been hearing that since 2010. I've been through at least a couple cycles of \"but they are this time, seriously!\" myself personally -- this most recent cycle was the first one the Apple inteligentsia widely agreed it wasn't worth even talking about. reply wraptile 15 hours agorootparentprevApple will never cannibalize themselves like this. There isn't event multi user support on iPad which would be something trivial to do and everyone know ipad is a family device yet here we are. reply sitkack 10 hours agorootparentApple should be forced to enable multiuser on iPad and iPhone. reply carlosjobim 5 hours agorootparentOr you're going to kick their asses? reply sitkack 2 hours agorootparentLet's do this! Next time Jon Stewart talks to Lina Khan, they discuss enabling the multiuser support in all the Apple OSes. Lina then does discovery against Apple where it turns out that product managers inside of apple have been trying to do this for years, esp in markets where a device per person doesn't work, but a shared device would. Bootlicking MBAs say that news of this would get back to high margin markets and rich families would be pissed because they just bought ipads (baby sitters) for all their children. While we are at it, once a device goes out of support, it should be fully unlocked for the user with sufficient documentation so that alternative OSes can be installed. The hardware that is my gen1 iPad still functions perfectly. reply kingkongjaffa 12 hours agorootparentprevI love having different devices for different things. Macbook pro for coding and designing in figma and light gaming, web browsing iPad mini for reading, travelling, sketching with apple pencil. iPhone for doing phone things. Sure I buy 3 devices (4 if you count apple watch) but they last several years and have decent resale value. reply diffeomorphism 11 hours agorootparentI dislike having to charge 3 or 4 different things. Also the sync is far from seamless, e.g. to annotate a pdf from the laptop, I have to send it to the tablet, annotate, then send it back. Same reason I am not carrying a point-and-shoot, a phone, a navigation system and a pda. Same reason I use a laptop instead of multiple desktop computers. Related question: on the pixel phones you could just run full windows in a VM, but for other devices it was \"coming soon\". What happened to that? I don't need convergence right now, if I can just run the desktop OS in a VM. reply beAbU 4 hours agorootparentprev\"Just buy an iPad/Mac\" - Tim Cook probably. reply Bluestein 11 hours agorootparentprevI am thinking Apple would not want to cannibalize some lower end notebook sales ... reply rchaud 17 hours agoparentprevSamsung Dex is incredible, I use it with a lapdock the way I would a real laptop. Multiple windows on screen, Kb shortcuts to navigate, plus drag and drop functionality with a mouse that is unheard of in regular Android. reply jeroenhd 11 hours agoparentprevHas one of those Androids been capable of running Samsung Dex? I've used it on my tablet (without an external screen) with a USB dongle and I found it surprisingly competent for a lot of desktop work, if I weren't for the lack of RAM in my device. reply Jach 11 hours agorootparentYes, though my current phone is a red magic 8 pro, so no DeX (or other things, good and bad). I wasn't really impressed like another comment, but admittedly I didn't spend too much time trying it since it wasn't my phone that had DeX. Though I still think I got enough data. On android, the biggest issue for me is probably the android apps themselves, what's effectively a glorified launcher that's still not quite there is a side issue. I know some people have managed to root their phones and get some sort of real linux on there (emulated?) but the actual experiences when you dig into it don't sound that great (i.e. very bad performance). reply jeroenhd 7 hours agorootparentI see. I don't have that many problems with apps anymore now that Google is trying to push the tablet market again. Samsung used to support running real Linux instead of Dex but that project was cancelled unfortunately. I don't have many problems with modern Android Dex, though, at least not ones that I also have with Windows on laptops. reply fsflover 10 hours agoparentprevDepending on your typical tasks, convergence can work fine today: https://puri.sm/posts/my-first-year-of-librem-5-convergence/ reply Jach 9 hours agorootparentYeah, I'm glad some people are able to live the dream. Not for me though, the issues being terribly obsolete hardware leading to poor performance and also terrible feature parity on phone-side table stakes. I should boot and fully update my librem to see how things have progressed, it's been another paperweight in the closet. Honestly while I could rant about it, this thread's not really the place, and I'm actually not all that disappointed anyway because from the time when I pre-ordered it I convinced myself to treat it more like a donation to the cause and have zero expectations for anything personally useful to come out of it. reply akira2501 16 hours agoparentprevMeanwhile my NUC fits in my back pocket. reply antifa 4 hours agorootparentA device with the NUC's power and size that could have it's own battery (if external, not too huge) would be awesome. reply hollerith 4 hours agorootparentI've always wanted a small battery in my mini PC so I could move it from place to place without a reboot of the OS. If I had that, I probably wouldn't also get a battery-powered monitors, so I'd still need electricity to interact with the mini PC. reply 650REDHAIR 3 hours agorootparentprevWhich model? Would you recommend? reply Hamuko 12 hours agorootparentprevThose are some large back pockets. I'm thankful that my preferred model of jeans has pockets deep enough for an iPhone 14 Pro. reply akira2501 12 hours agorootparent4\" x 4\" x 1.5\". Or, if it's your fancy approximately, 100mm x 100mm x 40mm. reply segasaturn 21 hours agoprevI've seen these before and I always loved the idea of \"convergence\" even though its never been successful. I remember in at least 2013 when the Ubuntu Edge had a convergence feature that would blow your phone up into a (very slow) desktop PC over DisplayPort that you would then control via the phone touch screen [1]. I suspect the reason that mobile convergence hasn't been successful is that people like owning multiple devices that fit the mood you are in. My phone is for social stuff, my tablet is for entertainment stuff and my laptop is for work stuff. The thought of cramming all of those head-spaces into one device feels stressful, like putting all my eggs into one basket. I'm always very happy when I hear about updates to DeX or new convergence docks though 1:https://youtu.be/bk9-v8Sl4yU reply gumby 21 hours agoparentA scooter, motorcycle, car, and delivery van all serve different purposes, though there is a little crossover between each stage. The same is true about these devices: yes, in a pinch you can grab that document and search for something but really when editing it you want not just a keyboard and larger display, but a bit more horsepower and different apps. So I use to think a fancy dock like this would be good, but their continued failure has taught me a lot. reply bluGill 20 hours agorootparentA basic phone blows away the early computers. 40mhz one core cpus (spark, mips, 80486...) used to do a lot of work and be fast. What has changed is bloat. reply Xylakant 20 hours agorootparentWe also seem to have picked up a few features along the way. Rendering screen resolutions beyond 640x480, network speeds above 9600 baud, video, displaying images that each would fill one of the hard drives of that age, video and music editing, running programs that were unthinkable in terms of features set. Clearly, inefficiencies have crept in, but it’s not as if the software today wasn’t way more capable than what we had at that time. reply Bluestein 11 hours agorootparent> images that each would fill one of the hard drives of that age This really puts things in perspective ... reply mixmastamyk 20 hours agorootparentprevWe had much better specs than this available at an aerospace company in the mid 90s, not to mention LAN storage and direct T1 to the internet. reply nox101 19 hours agorootparentlan storage at 10mbs? T1 is only 1.544 Mbps. Those are incredibly slow by today's standards reply mixmastamyk 18 hours agorootparentWe often had 100baseT and it was quite snappy for text heavy coms and reasonably sized images from the net. 9600 was already faster than you can read, this was an order of magnitude faster. Quake deathmatch was incredible, I remember getting almost twenty folks on a server once. :D At some point I procured a 1600x1200 monitor… but not until a later job after 2k with an SGI was my computer able to handle that resolution comfortably. reply Bluestein 11 hours agorootparent> was already faster than you can read, You make an interesting point: This *is* some sort of breakthrough point: When \"average human textual input bandwidth\" was matched ... (This might be comparable to AI: Now we are trying to match \"average human processing capacity\" ... reply elliottkember 19 hours agorootparentprevI bet those cost more than today’s cellphones… reply mixmastamyk 18 hours agorootparentCouple thousand per, in the 90s. reply SoftTalker 20 hours agorootparentprevSo much this. I could edit documents on my first 8088 PC with 512K memory. And people wrote novels on computers like this. reply azinman2 12 hours agorootparentPeople also used to write novels on pen and paper, later typewriters, then word processors. What we have now is far, far better in every conceivable way. I think nostalgia gives rise colored glasses when if you were to put these things side by side you’d never actually go back. reply input_sh 20 hours agorootparentprevNo, what changed is our expectation of what such a device should be capable of doing. You're not gonna load a 1080p YouTube video on 400 MHz. reply tambourine_man 20 hours agorootparentThe parent wrote 40mhz. You could probably do 1080p on 400mhz if you’re clever reply galdosdi 17 hours agorootparentWe could and did. DVDs played on 400mhz machines reply jacob019 17 hours agorootparentDVDs are 480p reply ozim 20 hours agorootparentprevSome would say 1080p is bloat when you can watch videos perfectly fine in lower resolution ;) reply skeledrew 19 hours agorootparentI remember when I got a 1080p monitor and watched some slightly old content (~480p) on it. The experience was very lackluster. Now I'm getting a similar feeling with a recently-bought 4k-capable laptop, and watching 720p content that looked perfectly fine on the 1080p monitor. I don't even want to think about the 480p archives. Almost makes me not want to upgrade devices. reply Bluestein 10 hours agorootparent(Can totally sée some AI-based solutions performing some heavy \"interpolation\" to \"upsample\" content in realtime ...) reply input_sh 9 hours agorootparentThat's already a thing: https://nvidia.custhelp.com/app/answers/detail/a_id/5448 reply Bluestein 10 hours agorootparentprevI would, perhaps ... PS. I quite distinctly remember the point in time when I finally said my then desktop machine couldn't move video, and it really was time to consider an upgrade ... (My 500 Mhz K6 II - DAE remember those AMD chips? - had finally become too slow. Video was 'unstoppable' ... reply signaru 12 hours agorootparentprevSometimes I still find the need to write a lot on a phone and it's thumb typing in a touch mobile device that frustrates me the most. I believe a good add-on keyboard, preferably just as portable as the phone, would have more use cases than a hollow laptop that can be just as big (and similarly less convenient) as a normal laptop. reply Bluestein 11 hours agorootparent> believe a good add-on keyboard, preferably just as portable as the phone, Sure.- (But \"good\" and \"portable\" [keyboard] are antagonistic here ... ... maybe, perhaps, someday, one of these \"newfangled\" projected keyboards, chord keyboards, one-handed keyboards, foldable keyboards ... ... will hit the mainstream.- reply bee_rider 20 hours agorootparentprevWe need different types of vehicles for all those things because they cover use cases with different storage capacity and performance requirements. This seems less true for cellphones now. reply lmm 20 hours agoparentprev> I suspect the reason that mobile convergence hasn't been successful is that people like owning multiple devices that fit the mood you are in. My phone is for social stuff, my tablet is for entertainment stuff and my laptop is for work stuff. Nah, I used to think the same thing about desktop vs laptop but turns out once laptops got good enough to be a true desktop replacement it was much better to just have one device. Phones aren't there yet, even if the raw processor speed numbers suggest they should be. reply weitendorf 16 hours agoparentprev> people like owning multiple devices that fit the mood Agree this is a big factor, but with peripherals to extend your smartphone into a laptop you do still have to own multiple “devices” (discrete units of physical hardware). If you’re already gonna have to lug around a dongle/adapter and one or more pieces of hardware (mouse, keyboard, screen) to get the laptop experience, you might as well just lug around an entire laptop. Also, “cloud” software (not just things like Google docs, but the widespread use of web applications allowing you to log in to some app from anywhere) has solved a lot of the biggest problems in this space. You can easily access all the important things on your phone from a laptop, unless you go out of your way to not upload something somewhere. So being able to convert a smartphone into a laptop is mostly about saving money on hardware (which may not be that much. Do you pay $200 for peripherals to get an underpowered laptop powered by a phone, or a mid-like laptop?) or addressing a very niche UX need. reply DaoVeles 18 hours agoparentprevThe last generation of Windows Phone had convergence that provided a version of this. Allowed you to run UWP apps on a Windows desktop. But like many things in the Windows phone universe, it was simultaneously 10 years ahead and 10 years behind. I miss the thing all the time. reply Bluestein 10 hours agorootparent> was simultaneously 10 years ahead and 10 years behind. This is a great way to put it. \"Recipes\" were ahead of their time, but half-baked ... reply coredog64 13 hours agorootparentprevThere was also a dock for your Windows Phone that granted a desktop UI and allowed for light MS Office usage. Used it a couple of times in a pinch. reply obscurette 21 hours agoparentprevI see a an increasing number of people around me using phone only for stuff they absolutely need to carry around – payment/banking, loyalty cards, 2FA, maps. Maybe also some pure messaging app, some puzzle game, but that's it. No any social media, news, work etc. reply MikeTheGreat 18 hours agorootparentNow that you mention it, that's a good way to think about it. Of all the things on my phone, the only thing I feel like I absolutely can't live without (in my phone) is my OneBusAway app that tells me when my next bus is coming. Also: /shameless-plug-for-free-and-awesome-app :) reply Bluestein 21 hours agorootparentprevTwo (diverging, yet simultaneous) tendencies: \"The phone as a glorified wallet\" and \"The phone as your life\". Both at play ... reply treflop 20 hours agoparentprevFor me, it’s that I don’t have a monitor on hand to plug my phone into. And if I’m going to plan to bring a monitor, shit, I’ll just bring my laptop anyway. reply RachelF 21 hours agoparentprevYes, Samsung has had their \"Dex\" which looks just like NexDock. Modern Motorola phones have a similar feature. VNC has been around for a long time. It just seems like something people don't want to use. I'm not sure why, though? reply Bluestein 20 hours agorootparentPrice point might be an issue ... reply antifa 4 hours agorootparentYou can get an external monitor and seperate keyboard for about $100. The issue for me at least, is that I don't want to to put android apps on a monitor, I want a real Linux desktop experience when I plug my phone into a monitor. reply type0 18 hours agoparentprevthe real convergence will happen eventually, when Google merges Android with ChromeOS and we will get the worst of both worlds reply diffeomorphism 4 hours agorootparentLuckily, it will include FSL-Fuchsia Subsystem for Linux. Enabling it will block Netflix and YouTube though. reply zozbot234 18 hours agoparentprevConvergence should work fine from modern desktop Linux: you should be able to attach a tiny, phone-sized screen to any SBC or mini-PC and run a mobile-focused experience (such as Phosh or Gnome-Mobile) and it should just work. Attach a bigger external monitor and apps should just scale up seamlessly. This will get quite interesting with the newer device form factor of handheld consoles running x86-64 hardware, since they too have a roughly phone-sized screen that usually supports touch input, as well as analog sticks that might be readily usable for pointer movement or scrolling, and lots of physical buttons that might be usable for gestures or chorded input. reply yjftsjthsd-h 18 hours agorootparent> Convergence should work fine from modern desktop Linux: you should be able to attach a tiny, phone-sized screen to any SBC or mini-PC and run a mobile-focused experience (such as Phosh or Gnome-Mobile) and it should just work. Attach a bigger external monitor and apps should just scale up seamlessly. My Pinephone Pro runs Plasma Mobile and yeah you can just plug it in to a USB-C dock with HDMI out and a mouse+keyboard plugged in and it scales up into a slightly odd desktop:) reply maccard 20 hours agoparentprevThere was a meme a while back - my most millennial trait is that big purchases must happen on a big screen”. My brother is a zoomer and the only computing device in his house is his mobile phone and work laptop. He does absolutely everything on his phone. I think we’re moving away from separated devices, honestly reply gwervc 20 hours agorootparentI feel like it highly depends on what people are doing with a device: if there're only a consumer (of digital content or physical product), only owning and using a smartphone is fine. However for creating things (writing a PhD thesis, making a game, editing horizontal video) a PC is still required. reply maccard 9 hours agorootparentIf we want to quantify every exception sure. We've moved away from mainframe devices but that doesn't mean none exist. We've moved away from Windows XP but that doesn't mean that they don't exist. reply maxglute 21 hours agoparentprevIt wouldn't be hard to trigger DEX/desktop enviroment to load a different profile. I feel like most hardware companies don't want to eat away at different segments. reply Bluestein 21 hours agorootparent(Along those lines, some phones have a \"second\" or \"secret\" profile/mode that is accessible through a different PIN code at the lockscreen, for example ...) reply kristopolous 20 hours agoparentprevNot really. Let's look at Bell's Law from 1972 to understand this: \"Roughly every decade a new, lower priced computer class forms based on a new programming platform, network, and interface resulting in new usage and a new industry.\" So we can say, generally, mainframes, minicomputers, workstations, microcomputers, laptops, smart phones, and now wearables (watches, rings, wallets, bracelets, glasses, etc) Next we'll have something I'll call the Mckenzie corollary (that's me I guess): \"Roughly a decade or two after introduction, the lower price computer class will subsume the upper price computing class.\" So the minicomputers took on mainframe tasks. The workstations took on the minicomputer tasks. The microcomputers took on the workstation tasks. Laptops took on the micros. All this happened with a significant lag time. And now, the smartphones are vying for the laptops. These are superstructural transformations and take years because a bunch of new things need to be invented, developed, mastered and widely deployed for it to happen. We are roughly in the wearables and phones-become-laptops epoch. reply card_zero 20 hours agorootparentLet's look at The Poverty of Historicism from 1944 to understand why you can't predict societal change with laws. \"[The evolution of] human society, is a unique historical process ... Its description, however, is not a law, but only a singular historical statement.\" reply kristopolous 20 hours agorootparentKarl Popper was being a logician about it. People aren't claiming supernatural powers with market trend analysis like some Helena Blavatsky of electronics or that these \"laws\" hold like thermodynamics. If it's been good for 60 years so that might continue or maybe something unexpected will happen. Popper's piecemeal alternative predicts nothing. The market trend analysis is at least accurate > 0% of the time. It's a non-scientific process with unquantifiable accuracy but it is empirically non-zero. For instance, Geofferey Moore's adoption curves proposed in 1991 are widely found but, every now and then, the galloping animal is a zebra. This doesn't mean you shouldn't plan for horses. Presuming a decade or two from now people will connect their wearables powered by kinetic charging to foldable e-paper with a transparent solar panel layer is just a bet. Maybe something radical will happen instead: The public payphone will come back as a public computer that people will biometrically log into after shunning personal electronics as toxic spy machines ruining society. Eh, probably not, but maybe. reply Bluestein 10 hours agorootparent> every now and then, the galloping animal is a zebra. This doesn't mean you shouldn't plan for horses. With permission, I am going to put that on a t-shirt :) reply kristopolous 8 hours agorootparentI'm not that brilliant! I borrowed it from medical slang https://en.m.wikipedia.org/wiki/Zebra_(medicine) So steal away reply sitkack 10 hours agorootparentprev> The low end always eats the high end. reply kristopolous 7 hours agorootparentThe low end eventually becomes a satisfiable alternative for price sensitive consumers and may become the majority market if _consumer preferences follow_. That's important. Even more expensive brands in the purely functional space like Tektronix, DeWalt and Zojirushi can still command a preference and not for the same reason as Patek Philippe or Christian Louboutin. Also when preferences aren't considered, the base observation can become rather risky. For example, it implies a majority of American cars will eventually be electric microcars like the Wuling Hongguang Mini EV or Chery QQ Ice Cream because: 1. Most cars on the road were bought used and these cars cost less than a used car. 2. The battery efficiency of the smaller vehicle means you can charge it without special hardware in reasonable time. 3. The vehicle speed and range are increasingly adequate to satisfy most consumers needs. Do I think an EV microcar revolution is coming to the US? No. There's zero evidence of that. American consumer preferences would need to change first. Fickle human behavior is an X factor in any market. Preferences can change however. Pretend Apple comes out with iCar, a sleek electric microcar or Costco introduces Kirkland CarTwo, a practical second car that charges in a few hours on a normal outlet. Perfect for teenagers and easy to park in small spaces. Cost? $89/month for 48 months. I basically just pitched the Geely Panda Mini EV or a number of similar cars which have been in production for years. The tech is here. The American preferences are not. Not yet. reply sitkack 2 hours agorootparentI like your analysis. I'd like to ignore American Consumer Preferences and talk about engineering examples. Linux/OSS/MySQL: These were seen as toy alternatives to the real thing. Linux eventually displaced all the proprietary Unix operating systems. And it still isn't at feature parity with some of those OSes decades later. Same goes for X86 and Arm. High margin stagnant businesses often get consumed by a toy entrant that crosses that inflection point where it does what it needs to do for 20% of price. When the cost of something is less than your margin, you are screwed. On the ACP in regards to vehicles. Americans have been conned into liking low-end vehicles wrapped in a high-end sheen. SUVs are high margin vehicles partially because they are cheap pickup trucks. US auto manufacturers got their asses handed to them imports from Japan, where people did prefer smaller, lighter more efficient vehicles. There was then an effort across all auto companies to change the tastes of US car buyers so that foreign vehicles couldn't compete. # Semantic Scholar links for the paper, \"Experimental evidence for tipping points in social convention\" https://www.semanticscholar.org/paper/Experimental-evidence-... https://www.semanticscholar.org/paper/Supplementary-Material... ---- Evolution of opinions on social networks in the presence of competing committed groups https://pubmed.ncbi.nlm.nih.gov/22448238/ reply Bluestein 10 hours agorootparentprev> and widely deployed for it to happen. (And, don't forget, \"mass adopted\" ...) reply Narhem 21 hours agoparentprevSuper book was another example of these type of devices which never got to market. Had the chance to play with the foldable devices and thought they are actually pretty great. I think these type of formats are decent for travelers. reply xattt 21 hours agoparentprevI've got a Samsung Android phone that I tried with a DisplayLink dock for browsing. It was able to use the Ethernet OOTB, but browsing was PAINFUL. The responsiveness is/was not there. reply Lerc 20 hours agoparentprevI always liked the idea that rather than your phone being the powerhouse for a laptop or desktop environment that it instead be a receptacle for data. If only there were a standardized protocol enabling browsers (could be any smart terminal protocol, but browsers exist now, and would mostly work) to securely connect to nearby devices, maybe even require a physical connection if you want extra safety. Then instead of a specific dock you could use just about any capable laptop or desktop as an environment. I don't think it can be done at the moment without an on-internet intermediary. A local discovery and connection system that the terminal(browser) could be aware of. Maybe this could be shoehorned into existing systems like Bluetooth. You could get an absurd usb connection working if the phone appeared as both a file store as well as a keyboard that types in the commands to launch itself. I see no potential pitfalls with that approach. reply fragmede 10 hours agorootparentavahi/bonjour for discovery, vnc served up over http for UI. Intel proposed a box with Ethernet over USB for this a long time ago but it never caught on. reply wkat4242 21 hours agoparentprevMeh, it works fine for me. You can also use work profile (island app) to segment your phone a bit further. I really love DeX and I just spent a whole week working with it as my primary computing device. I don't have a mobile dock though. The reason being that they're not an awful lot cheaper or lighter than a real laptop so what's the point. reply Bluestein 21 hours agorootparent> they're not an awful lot cheaper or lighter than a real laptop so what's the point. True. Probably one of the biggest obstacles to adoption. Their price point pretty much overlaps with an entry-level laptop.- reply Bluestein 21 hours agoparentprev> that people like owning multiple devices that fit the mood you are in Sounds reasonable.- PS. As a counterpoint to that, many will I am sure remember how one PC *was* everything and one did everything on it. One per household, even ... reply wkat4242 21 hours agorootparentHaha. * counts 4 in the living room, about 10 servers in the lab, probably 20 computers in total in my single person home not including raspberry pis, mobiles or tablets :) reply Bluestein 21 hours agorootparentInsane.- (Yet, I am sure, not atypical nowadays - if a bit above the mean ...) reply vasco 19 hours agoparentprevConvergence happened already, I'm logged into the same apps from any device and have access to mostly the same files and functionality through the cloud. reply egypturnash 19 hours agoprevHuh. It's a lot cheaper than I expected it to be. Only $300. Might be kinda useful if the pendulum swings back towards actually storing all your data on your own devices instead of in the clown. And if anyone starts writing actual tools for Desktop Android. reply a1o 19 hours agoparent> clown That's the best typo ever, I had an extension for chrome many years ago that allowed to replace \"cloud\" with a different word for funsies because it was used everywhere, might ressurect it using clown. reply DaoVeles 18 hours agorootparentI'm not sure it is a typo. I have been calling it 'the clown' or 'the clod' for years. So I suspect others have been too. reply adamomada 17 hours agorootparenthttps://github.com/apage43/cloud-to-clown reply arcanemachiner 15 hours agorootparentThis is like the nerd version of rule 34. reply egypturnash 17 hours agorootparentprevDeliberate. I’m working on a comic set in a dystopia run by AIs that have decided that “cartoon clowns” are the best way to tell humans what to do. reply Bluestein 10 hours agorootparentDo post links, previews, etc. :) reply Bluestein 10 hours agorootparentprevGosh. \"Clown Devices\" :) PS. Actually, it might be a good word for \"self hosted cloud\" setups, where you \"[c]loud [own] (as in, 'ownership')\" your data and infra is under user control ... reply zoom6628 15 hours agoparentprevI have 7\" touch screen waiting me to attach a pi4 to make a proper portable Linux device I can travel with. Laptops too big and the GPD tiny ones too expensive for me. I can't use anything smaller than 7\" and don't want bigger than 10\" for convenience. Less than $200 can have \"ideal\" setup. reply Bluestein 10 hours agorootparent7''/8'' is indeed some sort of sweet spot.- (I was doing \"portable\" using a then-huge 8'' 'generic android phablet' with a foldable Bluetooth keyboard a few years back ...) reply theshrike79 12 hours agoparentprevYou can swing your own pendulum any time you want, there are very few services (email being one IMO) that aren't worth self-hosting. You can easily sync your media to a server you own (Immich or NextCloud), Notes can live in Obsidian, which syncs to a place you control etc. reply Zambyte 21 hours agoprevI've had a NexDock for about 7 years or so. Definitely a nice tool to have. I don't really have a normal laptop besides my work laptop anymore. I primarily just use my NexDock with either my phone or my Steam Deck. I've also used the dock with Raspberry Pis in the past. The older model that I have has a pretty terrible trackpad, does not have a touch screen, and does not fold back (I normally use my ergonomic keyboard with it). I think these are all resolved in newer models though. reply pony_sheared 18 hours agoparentI have one of the originals too, I only use it in an emergency (e.g. maintaining a Raspberry Pi) because the trackpad is so awful - I can't type on it because the cursor jumps all over the place. That basically shattered my dream of leaving my work laptop at home on short business trips. Well, that and it weighs as much as a laptop anyway so there wasn't actually a benefit. reply thebruce87m 21 hours agoparentprevHadn’t thought of the steam deck as an option, how do you find it? reply capitainenemo 21 hours agorootparentI've just been using a small folding bluetooth keyboard and a mini-bluetooth mouse. Both are easy to carry around and fit in pockets. I find the steam deck's screen large enough to use on its own, although sometimes I plug it into an external monitor over HDMI. I use an overlay of /usr to add things to make the steam deck more useful. reply Zambyte 21 hours agorootparentCan you elaborate on your /usr overlay? I haven't gone very far with modifying my software setup on the Steam Deck, but I have been considering it for a while. reply capitainenemo 20 hours agorootparentUmmm sure. Basically I didn't want to irrecoverably screw up my steam deck. So, I setup a partition on the SD card and pointed a /usr overlay at it. mount -t overlay -o \"lowerdir=/usr,upperdir=/run/media/OVERLAY/overlay/usr,workdir=/run/media/OVERLAY/workdir/usr\" none /usr Personal choice, I didn't set it to automount, since I really wanted to ensure boot process was same. I just mount it later. Idea being that every once in a while I pop out the SD card, run the standard steam update, then wipe the overlay and reinstall the stuff I was using (I have a script to make that more convenient). If it seems I really did somehow mess up their setup beyond repair I can just remove the card, reboot (I did do that once, but I don't think it was my fault). Main issue I've run into is the fact that Valve upstream repo is a hackish snapshot of Arch that is not maintained and was not entirely consistent at time of creation and is using old gpg keys. So, while 95% of stuff installs using it, there's 5% that requires installing while ignoring the signature and just trusting valve's server, or pulling in an older lib (I symlinked in one from valve's steam runtime once). The other not-ideal thing about Valve is they really don't prioritise security patching, at all. It's astounding given the device does have an sshd running. Not to mention older problems like wifi vulnerabilities. Fortunately the recent ssh cve has a config workaround, or I'd probably just force-install an sshd from arch instead, or disable starting at boot. ... oh and pulling in new signatures for people does help sometimes. pacman -S archlinux-keyring , pacman-key / --populate / --refresh-keys /-r exact@name.org ... and since /etc persists during updates, sometimes you have to tell pacman to --overwrite since a prior install might still exist there. You could work around that by backing up /etc but, eh, it hasn't been a problem so far :D - there were no collisions on first install to /etc for any of them, so I assume everything was playing nice with existing valve /etc. And, well, valve did make that directory writeable ... reply hexmiles 20 hours agorootparentprevNot op, I have the previous model with the keyboard, and it works well but a bit janky: the screen and the keyboard are pretty good, the combination of touch screen e touchpad make it usable without a mouse for most workload. I use it for anything, gaming, web surfing, developing and sometimes even work (it does raise a few eyebrows when I take it out of the bag) The big problem is the connection between nextdock and steamdeck: if I connect it directly via single usb-c cable I lose the ability to charge the steamdeck (the nextdock does not supply enough energy for keeping the steamdeck charged) and I also lose a lot of io (next dock as only one fullsize usb 3.0 port) so instead I use the steam-deck-dock and connect it to the nextdock with two cable (hdmi e usb) so that I can keep the steamdeck fully charged. I would love to find an usb-c cable splitter so that I can have a device simultaneously connected to an usb-c pd charger and a second connection only for usb data, there are some but none of them support usb alt mode necessary to use external screen. reply capitainenemo 5 hours agorootparentWRT splitter. I've just been using a mini hub from Anker with pass-through charging. I keep it in the battery bag for my steam deck case. Also handy if I need to plug in an extra SD card. reply Zambyte 21 hours agorootparentprevI can obviously only use it with ample desk space for both the dock and the Deck, but for my use case (usually visiting family or my local maker space) desk space is not an issue. As for the experience of using it, it just feels like it's a reasonably spec'd gaming laptop when I use it with the Deck. reply Bluestein 21 hours agorootparentprev> use my NexDock with either my phone or my Steam Deck. Indeed. What a combo ... reply userbinator 18 hours agoprevMore like \"turns your smartphone into a smartphone with a keyboard and a bigger screen.\" No matter how much RAM, storage, or CPU power it has, a smartphone is ultimately still a locked-down media consumption device. reply theshrike79 11 hours agoparentIf your criteria of \"not locked down\" is being able to run a full-ass IDE on your phone, then maybe. But if using a Web-IDE via a browser[0] is enough for you, we're already there. You do need to adjust how you work, and that's a huge sticking point for some people. [0] https://vscode.dev reply userbinator 5 hours agorootparentBut if using a Web-IDE via a browser ...and be constantly tied to the clown? No thank you. reply LinuxBender 5 hours agorootparentExactly this. I want an x86_64 phone with a completely open motherboard and modem that permits any version of Linux. The modem must be accessed by a kernel module that is reviewed and approved by Linus without triggering a harsh email. No telemetry, back doors, lawful intercept, talking to the cloud without my explicit request to do so. SELinux policies and a policy generator and sandbox that profiles applications on the fly and gives me exactly what the app is asking to do in detail, not what the developer says it does or needs. If the app changes behavior, the profile generator and sandbox alert me to the change and will not permit the change until I review and approve it. reply theshrike79 4 hours agorootparentprevUnless you’re a paranoid luddite, your phone is tied to the clown every day anyway. The clown can be your own computer in this case, you can self-host the vscode server if you want. The you’re the clown. reply yjftsjthsd-h 18 hours agoparentprevThat's not universal; mine runs termux or a chroot in a pinch. reply neals 16 hours agorootparentMust be annoying in Google maps reply yjftsjthsd-h 12 hours agorootparentWhat? Termux sits next to the normal Android system, it's completely orthogonal to using Google apps. reply fsflover 5 hours agoparentprevExcept if it's a GNU/Linux phone already running a desktop OS, like Librem 5. reply tempest_ 21 hours agoprev15 years ago something like this was sold for my Moto Atrix https://en.wikipedia.org/wiki/Motorola_Atrix_4G#Accessories Never bought but seemed interesting at the time. reply ThatPlayer 13 hours agoparentI got one of the lapdocks for the Atrix a few years after the Atrix because you could hook it up to a Raspberry Pi and it'd work. Broke the HDMI port at some point though, mini HDMI is just too fragile. reply boffinAudio 9 hours agorootparentI still have one that I use as a raspberry Pi workstation, and yeah .. you have to maintain those cables. Still, a great device to have around a pile of rPi's. Although, I do prefer to just use my external LCD monitor .. far less likely to destroy the cables. reply xeromal 13 hours agoparentprevI wanted an Atrix so bad when I saw it announced. Alas, I was a broke college student reply DaoVeles 18 hours agoparentprevLook at the UI on that thing! Right before we started to flatten all UI design into bland shapes! reply Bluestein 21 hours agoparentprevActual buttons :) Nice phone.- reply jwells89 21 hours agoprevI understand the limitations resulting from differences in form factor between different smartphone models that make the idea impractical, but it's too bad these docks aren't designed for the phone to slot into them, Duo Dock[0] style. That'd be super slick. [0]: https://en.wikipedia.org/wiki/PowerBook_Duo#Docking_stations reply ClassyJacket 19 hours agoparentI don't see why it's impractical. Just have a soft spring loaded clamp, like universal car phone mounts. Maybe it would be hard to line up the USBC port? reply tambourine_man 19 hours agoprevThis appeals to us hackers, but it doesn’t really make that much practical sense, I think. The SOC and storage you’re saving by using your phone aren’t the most expensive items. A good 14” screen, keyboard, trackpad and battery aren’t cheap. And if you’re paying $300 for them, you might as well throw in a few hundred dollars more and get a full laptop. reply ranger_danger 19 hours agoparentFor low-income users who don't already own a desktop, I think it can make quite good sense. A \"good\" keyboard/mouse/monitor/etc. are not strictly necessary, and if you can't afford new ones, used ones can be had for extremely cheap or even free often times, like from garage sales, thrift shops, friends etc. And most of those people have a phone already, so adding the peripherals is not a big cost for them, but a full size desktop likely would be. I can get a working LCD screen, keyboard and mouse from my local thrift shop for $20, whereas the cheapest new laptop is at least $200. reply fbdab103 17 hours agorootparentI am curious how many people even own a personal desktop/laptop anymore. I imagine that more and more people do everything on a phone or maybe a tablet. Are past peak PC? reply tambourine_man 17 hours agorootparent> Are past peak PC? Very much so. For a number of years already. reply Bluestein 10 hours agorootparentprev> used ones can be had for extremely cheap or even free often times, like from garage sales, thrift shops, friends etc. And most of those people have a phone already What you described is actually an use case. Hadn't considered the 'second hand' peripheral options ... reply wenc 20 hours agoprevI've just been using a Samser Bluetooth foldable keyboard/trackpad with my iPhone (or iPad). It's great. https://www.amazon.com/gp/product/B0C1VSRZ59/ You don't get the large display, but you get a full keyboard/trackpad for $50 at Amazon. It's great when I'm on the road or traveling and need to write stuff on Google Docs. I don't bring my laptop when I travel -- just my phone, iPad and a keyboard like the above. I get to travel really light. reply anonzzzies 14 hours agoparentI have the same setup but for large screen I have the xreal glasses. Still travel very light but big screen when I need one. reply MrDrMcCoy 17 hours agoprevI would use mine a lot more if it supported power delivery passthru. That it doesn't kind of limits it's uses to an emergency kvm for my homelab and SBCs. reply RainaRelanah 9 hours agoparentI've been bothering them about this since Steam Deck first launched, if it could actually pass thru full USB-C PD it would be insanely useful. Portable gaming device that can be converted into a fully functional laptop easily (with a second screen!) is a long time dream of mine. But it can't do the ~40w charging the Deck needs. Also the touchpad is complete garbage as it was designed for use with phones. Sadly, NexDock doesn't design their own products and has little influence over engineering decisions of their partners. They're just slapping their logo on it and reselling it. There's a dozen other brands selling the exact same product on Alibaba/Taobao. reply hi-v-rocknroll 10 hours agoprevA few times, I've considered if Apple would make a turducken iPhone sleeve becomes an iPad, and then an iPad with a magnetic base, telescoping laptop hinge, and battery becomes a MBP with touch interface. For profit and usability reasons, it ain't ever gonna happen in that garden. In Android or DIY, sure it makes sense to offer a keyboard and possibly a bigger battery and more hardware resources as a dock. The only downside is now there's only 1 device that can be used instead of 2 discrete devices that can be used simultaneously and independently. reply EVa5I7bHFq9mnYK 10 hours agoprevXL version weights 1910 g and has 1920 pix resolution. I have a $300 15 inch laptop with 2560 resolution, its own processor, disk and everything, that weights 1655g including the charger. It's good for movies, web and remote desktop. I can also install samsung dex app on it. The only reason that thing might be useful, is if it were lighter, thinner and cheaper than the laptop, and it isn't. Another reason to avoid these toys is because phones are not built for desktop-like work - they just overheat. reply Bluestein 9 hours agoparent> if it were lighter, thinner and cheaper than the laptop, and it isn't. This. I am afraid it comes down to price point and physical specs ... (And beyond some point they economically cannot get any better, for, as a manufacturer, you'd be almost rebuilding a notebook (as far as parts anyway) with a (decent) screen, keyboard, (some) electronics, etc.).- reply Bluestein 9 hours agorootparentPS. Only option would (perhaps) come if and when (mostly, when) display technology makes a breakthrough enabling very oh so ever extremely cheap manufacture to occur where you can put a screen on anything for the price of ... paper? And, at that point, of course ... reply skeledrew 19 hours agoprevReminds me of the Neptune Duo[0], which sadly never became a thing. And the ASUS Padfone[1] which barely did. Would've loved to get my hands especially on the former. Actually still would even today, as it would really reduce the waste of having multiple smart devices that inevitably reach EoL with lots of still-working parts. Looking at my nonfunctional ASUS Transformer[2] that served me so well in college years ago, with its phenomenal battery life (keyboard dock also has a battery), and I still have hope I can get it repaired and use it again, even if only as an e-reader. [0] https://www.cnet.com/reviews/neptune-duo-preview/ [1] https://m.gsmarena.com/asus_padfone-3965.php [2] https://m.gsmarena.com/asus_transformer_tf101-3936.php reply laweijfmvo 18 hours agoprevIs Samsung still supporting Dex well? I remember a few years ago when I had a sudden [work] laptop fail during the pandemic and couldn’t get a new one until it was shipped out. My work phone was a Galaxy S20 and I was able to Dex my way into the corpnet and basically get by for a week. It was shocking and amazing, and yet I’ve never used it since… reply antifa 4 hours agoprevIME 99.9% of android apps have no hotkeys or mouse support, firefox shockingly has no hotkeys, and chrome is missing enough things (like mouse middle click, which currently works consistently windows+mac+linux) that the experience is completely broken. How bad the android desktop experience is really holds back these awesome devices. reply BLKNSLVR 13 hours agoprevTangential: I followed the rabbit hole to Bliss OS, which I now want to try installing on one of my old laptops. https://blissos.org/ reply srinathkrishna 18 hours agoprevFor the most part, one should also likely get a compatible phone and Samsung phones that support DEX are not cheap! I have a Pixel and have owned Pixel phones for a while and it's a shame that Google is only just opening up HDMI external display on the Pixel 8! It's a neat idea but I find it hard to succeed at scale. reply RainaRelanah 10 hours agoprevThese make great KVMs for homelab solutions. You'll need a VGA to HDMI adapter, but I am very thankful I no longer have to lug a monitor/keyboard/mouse into my closet when a server without IPMI won't boot. reply Ezhik 9 hours agoparentOh wow, I was actually worried about this - right now I have a small USB-powered display and a TrackPoint keyboard and was wondering about whether I could get a laptop shell that would just combine the two, but all I can find are either these phone docks or heavy server rack KVMs. What's your setup like for this? reply RainaRelanah 9 hours agorootparentThe NexDock came with an HDMI (output) to mini-HDMI (input) cable, and a USB-B to USB-C cable (for mouse/keyboard), which is all you need to connect to anything modern. I bought an $8 VGA to HDMI adapter for use with my older enterprise equipment without HDMI. I just keep all of them next to my rack, and connect the HDMI and USB as needed. The NexDock has a basic OSD that let's you switch between USB-C or HDMI video inputs. I already owned a NexDock so this is just what I've stuck with. These days I'd probably recommend a PiKVM with a networked KVM switch, if you have like 4+ physical servers it can be cheaper + give networked access. With added complexity and failure points. reply figmert 12 hours agoprevI've been on the verge of buying one of these for a while, but I think my biggest problem is they don't offer international keyboards. Only US qwerty. It's not a huge problem, but definitely not preferable. reply Bluestein 10 hours agoparentYou need an external non-US keyboard for your dock :) reply nullify88 14 hours agoprevI still wish Samsung hadn't killed Linux on Dex. reply forgotacc240419 20 hours agoprevBought an S8 a few years back cheap and Dex basically replaced my desktop and Android box until the phone stopped working. Think with some better communication to older people the format could have taken off because it did do all the basic functionality you'd need from a larger screen if you're not very technical reply donatj 19 hours agoprevI am genuinely surprised none of the attempts at this sort of things over the last 10+ years have gained much traction. On it's face, merging the device we have in our pocket and on our desk makes so much sense. The biggest difference being screen size. reply karteum 19 hours agoprevReminds me of Razer project Linda (https://www.youtube.com/watch?v=5gKu-T13vXs ) reply laconicmatt 20 hours agoprevWild that I'm seeing this on Hacker News. I just found out about the Dex capablilties of my zfold phone. I've been using it pretty much all week and have been considering going all in on this format. I love that I can just use my phone for virtually everything I use my laptop for (developing probably being the only obsticle). I've been considering some of the other options out there for portable monitor/keyboards and these seem (so far) the most affordable option. I wonder how the build quality it. reply bergie 19 hours agoparent> I love that I can just use my phone for virtually everything I use my laptop for (developing probably being the only obsticle). I used to write software on my phone using termux (usually via DeX). reply figmert 12 hours agorootparentWhat was your setup? I'm currently going on that journey. reply shortformblog 20 hours agoprevI like the idea of using a mini PC with one of these and then swapping that out while keeping the display and keyboard. The Khadas Mind, which has been controversial in tech reviewer circles, kind of carries itself like that: https://www.khadas.com/mind The pricing is all off, but the model has potential. reply rcarmo 20 hours agoparentYou can get a nice N100 mini-PC for much less than $200 (I got a nice compact one for my electronics bench for EUR 150: https://taoofmac.com/space/blog/2024/07/04/2200), and those pack enough computing power to be seriously useful… Especially when compared to ARM SBCs. reply perryh2 20 hours agorootparentI came across this which fits an Intel N100 in your pocket: https://store.minisforum.com/products/minisforum-s100 reply 627467 21 hours agoprevshame that Samsung handicapped their flip product line by removing dex reply Bluestein 20 hours agoparentReally a missed opportunity there ... reply a-dub 20 hours agoprevwill be interesting to see if google ships a decent desktop mode for the pixel line in the next revision. reply da768 20 hours agoparentLooks like it's finally getting somewhere in the latest Android beta, but definitely not read for production. NexDock 360 works pretty well with the Pixel 8a in desktop mode so far reply crooked-v 21 hours agoprevThis website is pretty badly designed. The home page should be selling me on what phones this works with, and why I should trust these people to pull it off when a bunch of other projects have come and gone that failed to do the same thing. reply arghwhat 21 hours agoparenthttps://nexdock.com/compatible-smartphones/ And while the site is badly designed, it does not have to explain why you should \"trust these people\". They should tell you what the product is, and for you to decide whether you like this product enough to buy it. Unless you suspect they'll run with your money (this isn't a kickstarter) or that the product claims are untruthful, trust is irrelevant. The reason companies in this space fail is just because too few people have been interested in this class of product. Maybe one day, when smartphones are more powerful and these products are convenient enough. reply nulld3v 21 hours agoparentprevAgreed that the website is mid but I don't get the part where you say: > when a bunch of other projects have come and gone that failed to do the same thing This has been \"pulled off\" successfully for a long time now. Nexdock themselves have been around and shipping different \"convergence\" products since at least 2016. reply Zambyte 21 hours agoparentprev> The home page should be selling me on what phones this works with Anything that can be connected to an external display, keyboard, and mouse. > why I should trust these people to pull it off when a bunch of other projects have come and gone that failed to do the same thing. My NexDock has served me well for 7 years. Even if the company flopped tomorrow, it would continue to serve me for years. I don't see the risk here even if you don't trust the company to continue to thrive. reply Bluestein 21 hours agorootparentI'd be (am) curious about the quality of the keyboard ... reply Zambyte 21 hours agorootparentIt's reasonable as far as membrane laptop keyboards go imo. It feels solid (along with the rest of the build quality), and has a pretty good travel distance. reply marcogarces 19 hours agoprevI've said this for years, since I owned a Samsung Galaxy something with the dock that had USB, ethernet and HDMI; you put your phone in and you have a desktop... This will be the future, but only when Apple does this to their iPhones lineup; the experience will be consistent and seamless; I'm not a fan boy, but one thing i'm sure is that they will release this and it will be like working on macOS, but you have it in your pocket. reply bdcravens 19 hours agoparentThat would be amazing, but history suggests Apple would never do this. reply Bluestein 9 hours agorootparent(Unless they can charge you extra. Several times, preferably, for it ... ... and - methinks - couple it with JobsAI :) ... somehow, maybe through a \"token hardware\" AI device. \"AIOT\" (?).- reply praveen9920 19 hours agoparentprevIsn’t it against their self interest? If my iPhone is acting as my laptop with just an additional screen, why would I buy a Mac book. reply Euphorbium 19 hours agoparentprevI totally want to lose all of my desktop computer stuff when I smash my phone. “But you are not supposed to have anything locally, everything you do has to be in The Cloud”. You will own nothing and you will be happy. Not even any data. reply Bluestein 9 hours agorootparentTotally the next thing: \"Diogenes Computing\" :) reply fsflover 9 hours agorootparentprevDid you hear about backups? reply solardev 20 hours agoprevDoes anyone know if the Pixel phones will ever support this? reply da768 20 hours agoparentPixel 8a works just fine. It's still using mirror mode by default. There's a Desktop mode you can enable in developer settings which works well with the NexDock hardware, but the desktop mode UI is still pretty buggy at the moment. reply solardev 17 hours agorootparentGood to know, thanks! reply ianburrell 19 hours agoparentprevGoogle only recently enabled USB-C display mode recently. It is only the Pixel 8 and later. Don't know if earlier phones will get it, it depends on having the hardware and getting the OS update. reply solardev 17 hours agorootparentDarn, thanks. I only have a 7, will have to see if that ever happens. reply dcchambers 17 hours agoprevPeople have been trying to make this a reality for over a decade. Remember the Motorola Atrix + \"Lapdock\" from 2011? It seems like it's something the consumer just doesn't want. They want separate computing devices for different functions. Ironically we're finally at a point now where phones have the power to run desktop-class applications without compromise. Most flagships phones are more powerful than the average laptop sold these days. reply miffe 21 hours agoprevI've wanted to try one of these together with my steamdeck for a long time. Do they offer international key layouts yet (Swedish specifically)? Also i find the dimensions a bit funny, 320x240 :) reply Bluestein 9 hours agoparent(Somebody upthread - aptly - mentioned non-US keyboard layouts were a problem for these sort of setups [so far] ...) reply naikrovek 8 hours agoprevThis device is much less about phones, for me. I've never used mine with a phone. It's a type-c monitor with an integrated keyboard and pointing device. it's like a portable physical console in a laptop form factor. I carry it around and plug it into Raspberry Pis (via HDMI, not type-c alone) so I can get a physical console. I have a few smaller single board computers that I occasionally use it with as well. It folds completely backwards so you can use it as a monitor alone, if you want, and I do that with my MacBook so it's a 2nd monitor (or 3rd depending on where I am) and it's great. It's just a single type-c cable to give the Steam Deck a keyboard and a larger, higher resolution screen, for games that don't do well with controller inputs. Plug in a mouse, turn off the trackpad, and you're gold. This is far more than just a \"turn your phone into a desktop\" thing. reply LoganDark 10 hours agoprevI love the idea of lapdocks. I've just never found one that has a good keyboard, trackpad, and screen, at the same time. There are those with good keyboards, and those with good screens, but not both, and never a good trackpad. (I guess I've been spoiled by using Apple Force Touch trackpads for years.) My use case is actually accessing my desktop from bed. I ended up using something called an \"overbed table\" (with tilt adjust!) with a monitor arm on it. Monitor goes on the arm, peripherals go on the table. That way, I can mix and match into something I like. But it's not really the same as a real lapdock, because it depends on the table. I can't easily move it around the room or anything. I can't use it in my lap, only on the table that floats above me. (I prefer the table in most cases, but the lap is sometimes useful.) It'd be nice if I could easily move it between my bed and a real desk, for example. If on the table there were a lapdock I could simply pick it up, but with separate peripherals I cannot. reply jauntywundrkind 21 hours agoprevI started using my new 18\" monitor attached to my phone. I just need a second phone so I can control my phone now. The Samsung remote control alas doesn't work with Linux, otherwise maybe I could try that (although I doubt it's really be all that.for this remote control case). reply j45 17 hours agoprevI’ve bought so many of these types of devices and just want one that is real and works and stays working and has new versions. Maybe someone like framework will make it happen. Samsung is not an option because they don’t security update their phone quick enough with the latest 0 day patches. If there’s monthly releases it’s full of patches a few months in the past. reply ThinkBeat 20 hours agoprevI have bought two different earlier generations of these and I never got either to work properly. The second should also be able to operate as a terminal, (Monitor and keys) for a computer, which was basically impossible to get working. The user experience to operate / change modes was exceptionally poor. I figure plug in the HDMI from the computer plug in the provided USB cable and it's smooth sailing. but that was not the case at all. Connecting a device was difficult to get working but it varied by which device. I hope they are better now. It is a great idea. reply localfirst 19 hours agoprevLooks like they pissed off a lot of ppl when they couldnt deliver on 120hz reply vsuperpower2021 21 hours agoprevThis looks like a neat idea but the marketing for this is scummy. Adding a keyboard and screen does not like a \"gaming PC\" just because you can run cloud games on it. It advertises plugging a raspberry pi into it for a \"fully functional computer at a revolutionarily low cost\" which isn't true. You also can't turn your phone into a windows 10 laptop by running cloud services. reply zer0zzz 20 hours agoprev [–] I’m convinced the only reason Apple invented continuity is so that people don’t realize that they only need one or two devices total. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NexDock allows users to convert their smartphones into laptops, either through wired or wireless connections.",
      "NexPad enables smartphones to function as tablets, providing a versatile use case for mobile devices.",
      "NexDock XL, an upcoming product, promises to expand the range of NEX devices, enhancing mobile productivity."
    ],
    "commentSummary": [
      "NexDock aims to transform smartphones into laptops, but users report dissatisfaction due to poor desktop/laptop experiences on smartphones.",
      "Despite the concept's appeal of upgrading only the phone and not the laptop form factor, execution issues, particularly on the phone side, hinder its success.",
      "Alternatives like older laptops from eBay or devices like the Steam Deck offer better performance and user experience for similar or lower costs."
    ],
    "points": 166,
    "commentCount": 201,
    "retryCount": 0,
    "time": 1720126672
  },
  {
    "id": 40882077,
    "title": "I was at AMD in the mid-late 2000s helping design CPU/APU/GPUs",
    "originLink": "https://twitter.com/mohapatrahemant/status/1809135345683841050",
    "originBody": "So now that Nvidia has far outstripped the market cap of AMD and Intel, I thought this would be a fun story to tell. I spent 6+yrs @ AMD engg in mid to late 2000s helping design the CPU/APU/GPUs that we see today. Back then it was unimaginable for AMD to beat Intel in market-cap… pic.twitter.com/bYCS5vY0QO— Hemant Mohapatra (@MohapatraHemant) July 5, 2024",
    "commentLink": "https://news.ycombinator.com/item?id=40882077",
    "commentBody": "I was at AMD in the mid-late 2000s helping design CPU/APU/GPUs (twitter.com/mohapatrahemant)158 points by jxub 6 hours agohidepastfavorite106 comments mkl 6 hours agohttps://threadreaderapp.com/thread/1809135345683841050 unyttigfjelltol 6 hours agoparentnext [4 more] This should be the article link. As a non-X user the message thread in the original post doesn't work. numpad0 5 hours agorootparentIt's insane how Twitter of late is weaponizing \"doesn't exist\" and \"cannot display\" messages as loginwall and impressions control. It won't reproduce at the side of first class citizens with industrialized means of buzzing, so posters won't notice until subhuman class gather and speak up outside of the system. Crazy stuff. galdosdi 4 hours agorootparentYeah, it's so disrespectful, typical of Elon's whole personality. For example, if you try to load Twitter in Firefox incognito, it will say \"Error\" and then lower say \"Firefox incognito is known to cause issues with X.com\" as if to move the blame away from themselves, when in actuality they are specifically detecting and blocking browsers in order to deter privacy. jxub 6 hours agorootparentprevApologies - it didn’t cross my mind! basilgohar 6 hours agoprevI love this insider view into this interesting point in computing history, especially about AMD. However, I was a little put off by the glorification of nVidia's shady practices and lock-in policies as key to their current leading position. While technically true, I dislike \"ends justify the means\"-style thinking. All this as the OP glorifies AMD's engineering and grit-based culture to drive through all though tough missteps and missed opportunities. To expand on that, I really do feel AMD has great engineering culture but they keep falling to the same traps. They do not invest strongly enough in software support nor vendor relationships. Neither of these necessitate the more evil monopolistic practices of vendor lock-in and proprietary, non-free (as in libre) software. If they can navigate that without turning evil, they'd be a company for the ages. And I can't close with mad respect to Dr. Lisa Su for her admirable leadership, itself bookworthy. Also, quick fact, she and Jensen are cousins! reply gymbeaux 3 hours agoparentOn the other hand, AMD was on the brink of bankruptcy and Lisa Su led them out of it and into a triple-digit share price. Most companies with that much debt and that little revenue would have gone bankrupt. Lest we forget the Intel IPC advantages over comparable AMD CPUs was due to some shortcuts that exposed major vulnerabilities in Intel CPUs made from ~2011 to 2019. I’d be curious to see how a Spectre and Meltdown-patched Intel CPU fares against its AMD competitor NOW. Some of the performance hits were brutal- 20%+ in some workloads. Nvidia was pushing AMD out of the GPU market back when GPUs were effectively only used for gaming and while GameWorks was predatory, you can’t really blame them for having the cooler-running, quieter, more energy-efficient GPUs going back to the Maxwell line (GTX 9x0). CUDA didn’t screw AMD until recently… but in 2014, people were picking Nvidia because the GPUs were considerably “better”. AMD had the best bang for buck back then, but you’d have more power consumption and heat output, and the drivers tended to be buggy. The bugs would be fixed, but it really sucked for people trying to play games on release day. reply woooooo 5 hours agoparentprevNvidia was pushing CUDA forward for over a decade before it started getting serious commercial traction. It's not like they blocked anyone else from developing viable GPGPU tech, they were just the only ones pushing it. For like 8 years their drivers on Linux were a nightmare and AMD could have come in and done better. reply CoolGuySteve 4 hours agorootparentAMD and Apple tried to push OpenCL but the design of it, a C-like kernel compiled to the GPU with LLVM and managed by the Khronos consortium, tended to lag in absolute performance to CUDA which was able to take advantage of evolutions in GPU design more closely. Nowadays almost nobody cares about OpenCL. reply jjoonathan 3 hours agorootparentThe feature lag wasn't the problem, the bugs were the problem: the only reliable OpenCL implementation was the one from Nvidia, but this meant it tended to drive people towards Nvidia rather than steal them away. reply pjmlp 3 hours agorootparentprevAlso apparently the reason behind Apple's cut with Khronos seems to be related to how OpenCL was managed by them. reply talldayo 2 hours agorootparent\"Hey Khronos, can we tweak the OpenCL spec to be even more restrictive and higher-level, then rebrand it under our proprietary 'Metal' architecture so we can license it out to our competitors?\" \"...no, but you could expand on OpenCL or Vulkan compute if you wanted. There are other spec stakeholders, we can't give you carte-blanche control, Apple.\" \"Why do you insist upon mismanaging the industry's APIs? Screw you guys!\"reply shmerl 1 hour agorootparentprev> For like 8 years their drivers on Linux were a nightmare and AMD could have come in and done better. AMD eventually did while Nvidia's drivers remained a nightmare almost until these days. But sure, AMD could have done it sooner. reply paulmd 1 hour agorootparent> AMD eventually did while Nvidia's drivers remained a nightmare and yet that trillion-dollar valuation built over the last decade is built with customers almost entirely running on those \"nightmare\" linux drivers, while AMD's linux drivers crash running the sample app on supported hardware+OS, and nobody at AMD cared until finally a tech-bro with a loud enough platform shamed them into fixing it... ... and this is something like AMD's third crack at the apple, and the first three sets of drivers (one of which is literally a Vulkan-branded spec) are just as non-functional today as rocm was a year ago. (OpenCL, Fusion HSA/AMD APP, Vulkan Compute/SPIR-V... all still broken so badly that Octane called them out for being unable to successfully compile their renderer and for lack of vendor support, so badly that Blender pulled support after years of turbulent and poorly-performing attempts to work with AMD, etc) reply shmerl 25 minutes agorootparentNvidia only cares about a specific market. I.e. it doesn't care about desktop users. That's what I was talking about. So despite their pools of cash, Nvidia is a trash company when it comes to Linux support. reply luyu_wu 5 hours agorootparentprevThe obvious issue with both your points is that NVidia's competitors did do as such. AMD has had workable Linux drivers for many years now and there were numerous alternatives to CUDA pushed. reply AlexandrB 5 hours agorootparentA common talking point is that CUDA is a formidable moat for Nvidia, but - as someone who has never done AI dev - I'm curious to understand what makes CUDA so sticky. From an outsider perspective it looks like a re-run of DirectX vs. everything else but AI is not like gaming and end users often don't have to run the model themselves. So it seems like the network effects should be less than that for a graphics APIs. reply badsectoracula 4 hours agorootparentI don't know how it is nowadays but i remember trying CUDA back when GeForce GTX 280 was still a high end GPU. I didn't do anything fancy, i just tried to write a simple raytracer to get a feel of how it'd work. The experience was incredibly simple: write C like usual but annotate a few C functions with some extra keywords and compile using a custom frontend/preprocessor/whatever-nvcc-was instead of gcc (i was on Linux - and BTW i heavily contest the notion that Nvidia drivers on Linux were \"nightmare\", they always worked just fine with both performance and features comparable to their Windows counterparts while ATi/AMD had buggy and broken drivers for years). Again, the experience was very simple, i even just copy/pasted a bunch of existing C code i had and it worked. Later i tried to use OpenCL which was supposedly the open alternative. That one felt way more primitive and low level, like writing shaders without the shading bits. In a way, as you wrote, it was kinda like DirectX: that is, CUDA was like using OpenGL 1.1 with its convenient and straightforward C API and OpenCL was like using DirectX 3 with its COM infested execute buffer nonsense. After that i never really used CUDA (or OpenCL for that matter) but it gave me the impression that Nvidia did put way more effort on developer experience. reply disgruntledphd2 4 hours agorootparentprevNvidia have invested a lot in CUDA, and they have C & Fortran bindings for a lot of scientific stuff, apart from all the DL/Gen AI stuff that's super hot right now. Like, I started using CUDA (through frameworks) over ten years ago, and basically nobody has come up with anything competitive since then. reply kkielhofner 4 hours agorootparent> Nvidia have invested a lot in CUDA, This is a significant understatement. For quite some time Jensen has been saying repeatedly that 30% of their R&D spend is on software. With the money-printing machine that is Nvidia if that holds they're going to continue to rocket ahead of competitors in terms of delivering actual solutions. The \"What are you talking about? AMD/Intel runs torch just fine!\" crowd clearly haven't seen things like RIVA, Deepstream, Nemo, Triton Inference Server/NIM, etc. Meanwhile AMD (ROCm) still struggles with flash attention... What these hardware-first (only?) companies like AMD don't seem to understand is that people buy solutions, not GPUs. It just so happens that GPUs are the best way to run these kinds of workloads but if you don't have a wholistic and exhaustive overall ecosystem you end up in single digit market share vs Nvidia at ~90%. reply pjmlp 3 hours agorootparentprevTooling. Since CUDA 3.0, NVidia has embraced a polyglot stack, with C, C++ and Fortran at the center, and PTX for anyone else. Followed by changing CUDA memory model to map that of C++11. Khronos never cared for Fortran, and only designed SPIR, when it became obvious they were too late to the party. So not only has CUDA first level tooling for C, C++, Fortran, with IDE integration in Visual Studio and Eclipse, graphical GPU debugger with all the goodies of a modern debugger, it also welcomes any compiler toolchain that wants to target PTX. Java, Haskell, .NET, Julia, Python JITs, .... there are plenty to chose from, without going through \"compile to OpenCL C99\" alternative. Finally, the myriad of libraries to chose from. CUDA is not only for AI, by the way. reply deredede 4 hours agorootparentprevThe difference is not just about APIs; CUDA has a single source file model that is dead easy to use whereas last I checked every competitor still had an outdated manual loading process that adds significant friction. reply zozbot234 3 hours agorootparentDoesn't SYCL also allow for a single-source-file model these days? reply deredede 2 hours agorootparentIt is supposed to, yes. I was never able to set it up (admittedly I have not tried in a couple of years since I am not working with GPUs anymore) so I don't know how well it holds up. reply belter 5 hours agoparentprevOn the GPU area AMD lost, and will continue to lose to Nvidia, because they don't seem to get a grip on Software and Drivers. And that does not bode well for their long time CEO. reply latchkey 5 hours agorootparentMI300x is doing quite well. https://chipsandcheese.com/2024/06/25/testing-amds-giant-mi3... https://www.nscale.com/blog/nscale-benchmarks-amd-mi300x-gpu... reply belter 4 hours agorootparentJust the first link review you posted reinforces my argument: \"...But we must now talk about the elephant in the room, and that is AMD’s software stack. While it is absolutely night and day from where it was when we tested MI210, ROCm is nowhere near where it needs to be to truly compete with CUDA...\" reply tapoxi 5 hours agorootparentprevI mean for gaming workloads AMD GPUs are doing fine in the Xbox, PlayStation, and Steam Deck consoles. reply sorenjan 2 hours agorootparentAnd in PC AMD has 15.6% of the market, compared to Nvidia's 76.4% according to Steam. https://store.steampowered.com/hwsurvey/Steam-Hardware-Softw... reply diamond559 4 hours agorootparentprevThe more this is blindly repeated the more you know it's bs reply jjoonathan 5 hours agoparentprevShe turned the company around and got it on the right path, but in interviews I get the feeling that she might also be responsible for the \"Hardware 1st, 2nd, 3rd, 4th.... eh, maybe software can be 5th\" culture and AMD's deep denial that it has a problem. https://news.ycombinator.com/item?id=40790924 That was OK for the CPU turnaround, but on the GPU front it completely shut them out of the first rounds of the AI party and maybe a trillion in market cap. reply bavell 3 hours agorootparentI'm hopeful and optimistic for AMD but if anything were to make me bearish on their prospects, it'd be this. reply doix 5 hours agoparentprevYeah, I really feel like AMD is struggling with the software aspect. Even back when they were ATI and AMD bought them, the ATI drivers were garbage compared to Nvidia (from my PC gaming experience). After a few AMD and ATI cards, I just accepted the Nvidia tax, where my cards are more expensive and on paper worse, but in practice worked better. I'm really surprised AMD isn't throwing a whole bunch of money on emulating CUDA. If they could \"just\" make CUDA work on AMD cards, it feels like Nvidia's position would be severely weakened. Kind of like how Valve invested heavily into Proton and now gaming on Linux is pretty much fine. reply luyu_wu 5 hours agorootparentI'm not sure emulating CUDA would be legal, you can look at ZLUDA as an example. It was originally funded by AMD, but got cut for what I presume would be legal reasons. ZLUDA does work amazingly well though from my experience! reply mook 3 hours agorootparentprevAMD also doesn't understand that CUDA got big because they worked on cheap consumer cards; once things were working people got interested in expensive specialized cards. Their stack is still focused on the high end only, but there's no ecosystem to support it. reply rcleveng 2 hours agorootparentTo me, this is the most important point and what AMD is missing out from their current strategy. I can take an off the shelf, easy to get 4070 or 4080 and use it with CUDA to learn. AMD's strategy for people wanting to learn, is basically no strategy. It's always been the software holding them back, still is, need to invest in the ecosystem and not just the things easy to justify as a revenue driver. reply pjmlp 4 hours agorootparentprevThat is what ROMc and HIP were supposed to be somehow, but even that isn't really CUDA, as in the polyglot programming language environment, with C, C++ and Fortran first, plus others, followed by Python JIT, libraries, IDE, and a GPU graphical debugger. reply DEADMINCE 5 hours agoparentprev> However, I was a little put off by the glorification of nVidia's shady practices and lock-in policies as key to their current leading position. While technically true, I dislike \"ends justify the means\"-style thinking. Personally, I have no issue with \"ends justify the means\"-style thinking as a blanket rule, often it's perfectly appropriate. I would argue it is, in this case, where Nvidia was playing a game by the rules. If there is an issue with how they played, then government should change the rules. The people in power in the US don't want that though. reply AlexandrB 6 hours agoprev> SUPERIOR PRODUCTS LOSE TO SUPERIOR DISTRIBUTION LOCK-INS & GTM. This takeaway was a little odd to me in the context of 2008. I had been an AMD stalwart in my PCs since about 2000 (Athlon Thunderbird), but IIRC in 2008 Intel had the better processor. Better single core performance, better performance/watt, and I think AMD processors tended to have stability issues around this time. I remember I built a PC in 2009 with a Core processor for these reasons. Obviously this is a niche market (gaming PC) perspective. But I don't think it was so clear cut. reply BirAdam 3 hours agoparentUntil the later Core 2 Quad CPUs, AMD’s stuff was “technologically” better in the multi core workloads. The problem with that is that multi core workloads were uncommon at the time. This is where the “AMD Fine Wine” meme originated. By the time people had moved on to better things, the greatness of AMD’s technologies became apparent. Personally, I’ve always liked Intel for stability reasons. Running Intel chipsets and CPUs, I’ve just had fewer issues. I’m an enthusiast, so I do spend more than I should on both Intel and AMD rather frequently… but now, I’m hungry for an Ampere system. My wallet is crying. reply tails4e 4 hours agoparentprevAgree. It took a truly superior product at lower cost to make a dent in Intel's dominance in server, all the while Intel tried their best to flex their lock in muscle. That happened well after 2008, with the advent of Zen and chiplet bases tech and better perf/W reply treprinum 2 hours agorootparentRyzen 1 was far from superior, performance-wise it was already behind Intel at around Haswell-level but it brought the first reasonably-priced octacore x64 for the masses. reply difosfor 5 hours agoprev> I seriously wish Nvidia and AMD could merge now – a technology cross-licensing that takes advantages of each other’s fab capabilities is going to help a lot in bringing the cost of GPU cycles down much furthe. Given Nvidia's track record I'd sooner imagine them just slacking off and overcharging more for lack of competition. I wish AMD would actually compete with them on GPUs (for graphics, not AI). Interestingly Intel seems to be trying to work up to that now. reply paulmd 1 hour agoparentthe reason NVIDIA has a lead right now is largely because they didn't slack off during the Maxwell era and kept iterating even after the 22nm/20nm node fell though. AMD decided that hey, we can't really afford this right now, and NVIDIA can't shrink either, right? But NVIDIA slipped in a major architectural iteration that was basically a full node worth of efficiency gains, and that really has put them in the position they are today. Being able to take a trailing-node strategy during the Turing/Ampere years, being able to run a full node behind RDNA1/2 and use dirt-cheap Samsung crap and last-gen TSMC 16FF/14FFN while still fighting AMD to a standstill on efficiency is entirely the result of AMD slacking off. AMD themselves have said they slacked off. Lost focus, is the quote. https://www.youtube.com/watch?t=1956&v=590h3XIUfHg reply gpderetta 6 hours agoprev> We did launch a “true” dual core, but nobody cared. By then Intel’s “fake” dual core already had AR/PR love. Practicality beats purity 100% of the time. This echoes \"Worse is better\". reply btouellette 5 hours agoprevIs he really trying to say that AMD had a superior product in the Core 2 Duo era and Intel was only dominating due to marketing? It's hard to take any of the rest of his opinions seriously when he starts with that take reply luyu_wu 5 hours agoparentI'm not sure if you're familiar with CPU history, but this is roughly true. Intel's catchup to multicore offerings was trippy and severely lagged behind AMD. I think it's often forgotten that CPU leadership has fluctuated between different companies many times in the past! reply btouellette 4 hours agorootparentI'm quite familiar as I worked for Intel for over a decade as an engineer. It's absolutely true that leadership has fluctuated a lot but the 2003-2010 era had fairly clear cut leaders for each generation. AMD was the choice for just about everything through the Athlon 64 single core era but the Core 2 Duo run had them relegated to superiority in the very bottom end of the market only for a long time. https://www.anandtech.com/print/2045/ reply adrian_b 2 hours agorootparentCore 2 as an individual core was significantly better than AMD's competing core (e.g. by being able to issue 4 simultaneous instructions vs. 3 instructions for AMD). Nevertheless, the integration of multiple cores into an Intel multiprocessor was very inefficient before Nehalem (i.e. the cores were competing for a shared bus, which prevented them from ever reaching their maximum aggregate throughput, unlike in the AMD multiprocessors, which had inherited the DEC Alpha structure, with separate memory links and peripheral interfaces and with an interconnection network between cores, like all CPUs use now). However this was noticeable at that time mostly in the server CPUs and much less in the consumer CPUs, as there were few multithreaded applications. Core 2 still lagged behind AMD's cores for various less mainstream applications, like computations with big integers. Only 2 generations later, after Core 2 and Penryn, with Nehalem (the first SKU at the end of 2008, but the important SKUs in 2009) Intel has become able to either match or exceed AMD's cores in all applications. reply highfrequency 2 hours agorootparentprevThanks for the color! From the article you linked, it looks like the Twitter thread is quite misleading in claiming that Intel simply slapped two cores together to achieve superiority over AMD. Your article notes a big process improvement (65nm vs 90nm) which allowed for 2x the transistors on a smaller die size along with faster clock and lower memory latency. Curious to get your take. reply adrian_b 2 hours agorootparentIntel's 90 nm CMOS process was a disaster, at least in its variant for desktop or server CPUs, all of which had an unbelievably high leakage power consumption (the idle power consumption of a desktop could be more than a half of its peak power consumption). On the other hand, AMD's 90 nm CMOS process has been excellent. With its 65 nm process, Intel has recovered its technological leadership, but that was not the most important factor of success, because AMD's 65 nm process was also OK and it became available within a few months of Intel's process. AMD has lost because they did not execute well the design process for their \"Barcelona\" new generation of CPUs (made also in 65 nm, like Core 2). While Intel has succeeded to deliver Core 2 even earlier than their normal cadence for new CPU generations, AMD has launched Barcelona only after several months of delays and even then it was buggy. The bugs required microcode workarounds that made Barcelona slow in comparison with Core 2, and that started the decline of AMD, after a few years of huge superiority over Intel. reply creativeSlumber 4 hours agorootparentprevIs it possible that maybe your view point is biased against AMD since you worked for for Intel during that time? reply btouellette 54 minutes agorootparentThe benchmarks for all these CPUs that my personal view point is based on are all out there. Anandtech was my favorite source for this at the time due to relatively detailed testing and a clear understanding of the implications of architecture decisions. The complete history of their contemporaneous reviews are still online and userbenchmark.com has independent data on these older CPUs as well although obviously with less control over potential mitigating factors. AMD was struggling to release CPUs that were competitive against year old Intel Core 2 Duos which remained the status quo through their Bulldozer architecture. Things started turning around with Ryzen when a combination of architecture improvements and typical workloads taking more advantage of multicore flipped the script. The bits about \"true\" multicore are also sketchy considering Bulldozer was using shared L2, fetch/decode, and floating point hardware on each module and calling a module two \"cores\" for marketing purposes. https://www.anandtech.com/show/4955/the-bulldozer-review-amd... reply keyringlight 3 hours agorootparentprevK7/K8 were great, and while the follow-on K10 Athlon2/Phenom/etc were definitely not bad, they weren't great and they were competing against Conroe/Core2 onwards. That kind of tag-team trading places highlights how (mostly) good the CPU market is now, both AMD and intel are putting out some really nice products with variety so you can pick the most suitable for you, but there's no default \"just pick [company]\" reply wmf 3 hours agorootparentprevNah, btouellette is correct. AMD only led for a few years around 2003-2005. reply Delk 2 hours agorootparentAMD did become at least competitive in high end CPUs with the original Athlon or Athlon XP. Not sure whether they were faster than the Pentium 3 but they weren't trailing. So perhaps a bit more than a couple of years, but my impression is also that they fell behind on (single-thread) performance for a long time after that. I've also understood that in more ancient history AMD CPUs sometimes beat contemporary Intel parts in performance, although releasing their parts later than Intel. I'm not sure that's relevant to any remotely recent developments anymore though. reply alphabeta2024 2 hours agorootparentprevThe OP is right. Pentium D was a single generation in which Intel offering was worse that Athlon 64 X2 . But Intel quickly shifted to Core 2 Duo architecture and it was much better than AMD. reply adrian_b 1 hour agorootparentSince the introduction of Opteron at the beginning of 2003 until the introduction of Core 2 at the middle of 2006, the AMD CPUs were vastly superior to any kind of Pentium 4, not only to Pentium D. This was much more obvious in servers or workstations than in consumer devices, because the kinds of applications run by non-professionals at that time were much more sensitive to the high burst speeds offered by Pentium 4 with very high clock frequencies, than to the higher sustained performance of the AMD CPUs. In 2005, I had both a 3.2 GHz Pentium 4 (Northwood, 130 nm) and a 3.0 GHz Pentium D (Prescott, 90 nm). With any of them, the compilation from sources of a complete Linux distribution took almost 3 days of continuous work of 24 hours per day. After I bought an Athlon X2 of only 2.2 GHz, the time for performing the same task has been reduced to much less than a day. Even for some single-threaded tasks, but which contained many operations that were inefficient on Pentium 4, like integer multiplications or certain kinds of floating-point operations, the 2.2 GHz AMD CPU was several times faster than the 3.2 GHz Pentium 4. At work, the domination of the AMD CPUs was even greater. Each server with Opteron CPUs that we bought was faster than several big racks with Sun or Fujitsu servers that were used before. Intel did not have anything remotely competitive. At the beginning of 2006, on my laptop with an AMD Turion I could run professional EDA/CAD programs much faster than on the big Sun servers normally used for such tasks. Intel had nothing like that (i.e. the 32-bit Intel CPUs could not use enough memory to even run such programs, so the question whether they could have run such programs fast enough was irrelevant). Of course, half of year later the competition between Intel and AMD looked completely different. reply modeless 2 hours agoprev> In fact, AMD almost bought Nvidia but Imagine the wealth destruction if they had merged way back then! I don't love the way mergers are regulated today but I do feel like preventing companies from growing too big through mergers is desirable. reply Zambyte 4 hours agoprev> I seriously wish Nvidia and AMD could merge now – a technology cross-licensing that takes advantages of each other’s fab capabilities is going to help a lot in bringing the cost of GPU cycles down much further! It's interesting that they see such a monopoly as something that would bring costs down. It seems more to me like competing with AMD does much more to keep Nvidias costs down (if they can be described as \"down\") than combining resources would. reply tambourine_man 5 hours agoprevI never worked at a large company and he was right there, but there are so many outstanding things in this thread, it’s hard not be surprised. Not understanding the importance of GPUs in 2006, or of being first-to-market, while confusing OpenGL with OpenCL (twice), survival bias (BELIEVE IN YOUR VISION)… reply andruby 4 hours agoprevIt's unbelievable that INTC market cap is only 133B, AMD is only 274B and NVDA is 3,130B. That's 23x INTC and 11x AMD. reply drexlspivey 4 hours agoparentOn the latest quarter, NVDA’s net profit was 3 times AMDs revenue reply andruby 3 hours agorootparentThat is jaw dropping. reply alberth 1 hour agoprev> I spent 6+yrs @ AMD engg in mid to late 2000s helping design the CPU/APU/GPUs that we see today. Is that a far statement to make, given ~20-years has passed? reply JonChesterfield 30 minutes agoparentIt seems a bit dubious since there's the trainwreck of Bulldozer on x64 sitting between then and the ryzen cores that managed to dethrone intel. I'm pretty sure the GPUs were VLIW without direct access to system memory too. I think one could sketch a lineage from the PS4 processor through to el capitan with a bunch of handwaving but that also seems to be after that time period. reply nickpeterson 6 hours agoprevPeople keep yelling about nvidia stock but that feels like a huge bubble. AI disillusionment will hit and the stock will implode. Nvidia hasn’t made any inroads on producing actual systems, just gpus. Once Apple or Microsoft have a fast enough chip (TOPs wise), nobody will care about nvidia lead except in the datacenter. Seems like a failing position to me. reply eitally 5 hours agoparentI think I'm not adequately understanding your comment. Nvidia has huge software teams building accelerators that optimize application of their GPUs for all kinds of applications. They also now offer their own \"cloud\" and have partnered with the hyperscalers for integration as well as GTM. Those same hyperscalers are also almost unilaterally driving Nvidia's growth the past few years. The cloud market is still growing and will continue to do so. Nvidia's consumer business almost doesn't matter anymore. reply bob1029 5 hours agorootparentI think much of this boils down to perspectives some of us have regarding the value of in-house manufacturing capabilities relative to design time & software capabilities. I get arguments that maybe one fab is better than the other, but what about all of them combined? All of our modern chipmaking capability all at once. Nvidia has no factories. You can ship their output on a USB flash drive. Valuation: ~3.1T. Intel, TSMC and Samsung have all the factories. Every modern chip made on earth in this circle. Combined valuation: ~1.1T This is simple napkin math for this arbitrary retail investor. I don't know when the music will stop but it absolutely will. reply wormlord 4 hours agorootparentI agree with this sentiment overall, but we have to remember that for valuations, profit and growth is really all that matters. Even if an industry is irreplacable. I think I read this from Warren Buffett, but basically as of the early 2000s the airlines, in their entire history, had only managed to break even. If you had bought an airline company in 1940 and held it until 2000, you would have never profited from it. The business itself would be worth significantly more, but your only exit strategy would be to sell. I haven't looked at any of these company's balance sheets, but it might be that semiconductor fabbing is less profitable and has less room for growth. In the short term that's all that matters. The question is if Nvidia can hold on to its current growth and margins (I don't think it can). reply _zoltan_ 1 hour agorootparentprevhard depreciating assets (factories) + selling chips are way worse than actually selling an ecosystem. NVDA is just getting started :-) reply matwood 4 hours agorootparentprevAre you saying a software company has less value for some reason? See MS. Or are you saying a hardware company that doesn't own their production has less value? See Apple. I think we've seen over many years at this point that there is huge value in the final product. reply CoastalCoder 5 hours agoparentprevI've worked on AI-hardware software stacks for several well known companies. It's impossible to overstate to advantages that CUDA, it's documentation, toolchain, and nSight software provide to outside developers. The closest thing I've seen to nSight Systems software is Intel's VTune. But that's just one piece I'm a much larger puzzle, and last I checked, VTune was only for Intel CPU. AFAICT, Nvidia's software seriously reduces the ramp-up time for new developers to write kernels or apps that make good use of the available hardware. E.g., nsys-ui (like VTune) recognizes anomalous profile results, and makes solid suggestions for next steps. I don't know of other software that does this (well), although maybe I'm just uninformed. reply Jlagreen 4 hours agoparentprevThis is wrong, please check what DGX is. DGX is a complete data center from Nvidia where Nvidia is the supplier of everything themselves: - CPU+GPU from Nvidia - Rack from Nvidia - Interconnects + networking from Nvidia - SW from OS to application framework from Nvidia The only thing Nvidia really needs partners with DGX is memory (RAM + SSD). One reason Nvidia's margins are so high is because they provide the whole data center so while competition has to split margins (AMD/Intel + SMCI/DELL + Broadcom/Arista + Cray/HPE). reply _zoltan_ 1 hour agorootparentno, this is not true. DGX is (right now) a 4U box with 8xH100 on a daughterboard. Don't believe me? Do you believe nvda? https://www.nvidia.com/en-sg/data-center/dgx-h100/ reply edward28 1 hour agorootparentThere's also the dgx nv72 reply redleader55 5 hours agoparentprevNvidia doesn't only produce GPUs. They have their hands in all sorts of interesting technologies from high speed, performance NICs to switches. The GPUs in the data centers don't just function as an individual unit, but they are able to use the \"backend\" NICs of the server, in conjunction with their proprietary NCCL library to send data with as close as possible to \"zero-copy\" from GPU to GPU with very good horizontal scalability. As you can imagine the network fabric behind this is quite important, and Nvidia having one the best Infiniband switches helps keep this monoploy. There are many companies working on alternatives at the moment, but it will be a while until Nvidia can be replaced. reply htrp 5 hours agoparentprev>Once Apple or Microsoft have a fast enough chip (TOPs wise), nobody will care about nvidia lead except in the datacenter. thats gonna take a while reply imtringued 3 hours agoparentprevGoogle has powerful TPUs. The real question is, why isn't Meta building their own? reply theandrewbailey 5 hours agoprev> We didn’t want a GPU company so much that the internal joke was AMD+ATI=DAMIT. I remember reading that on places like the Register, but they kept the second A, so DAAMIT. reply chollida1 5 hours agoprevMinor curiosity point.... Does anyone know why engg has two g's here? I'm sure it mean engineering but i've never seen that abbreviation, he motioned he's from India, is that where this comes from or is it just an individual quirk? reply sfifs 4 hours agoparentYes in India we abbreviate as Engg. I never noticed till now that perhaps other countries don't :-) reply ecuaflo 5 hours agoparentprevBritish English https://www.merriam-webster.com/dictionary/engg reply dooglius 5 hours agoprevDupe of https://news.ycombinator.com/item?id=40696384 no idea why that was flagged reply sorenjan 2 hours agoparentSame guy on Twitter posted the same story today as he did in 2020. https://threadreaderapp.com/thread/1285234687267356672.html reply OliverGuy 6 hours agoprevWhy is AMD green on that graph and Nvidia red....... reply amlib 5 hours agoparentAMD used to be green and nVidia... idk, maybe because they are more like dealing with the devil nowadays :) reply garaetjjte 3 hours agorootparentAMD was green, ATI red, so... yellow? reply _zoltan_ 1 hour agoprevSince we're talking about nvidia... :) is there anybody here who has access to a B200 NVL72 with working external nvlink switches and wants to share non-marketing impressions? reply washedup 5 hours agoprevhttps://threadreaderapp.com/thread/1809135345683841050.html reply carlsborg 5 hours agoprevBack in 2015, AMD was trading at $2.40 and Nvidia at about 50 cents (accounting for stock splits). 1000 USD invested then would be ~$70,000 and ~$256,000 respectively today. reply elzbardico 5 hours agoparentLet's be frank. Nobody invests on the market nowadays, the correct verb is BET. reply ant6n 5 hours agorootparentI INVESTED maybe 5% of my portfolio on AMD at around 2.5$, I think I sold it at 20x or so. I should‘ve BET 50% my portfolio. reply J_Shelby_J 4 hours agorootparentSame. I wish I held. At the time it was such an obvious play with Zen, but I never for saw it running for a decade of growth. reply lotsofpulp 5 hours agorootparentprevI have been reading this comment since early 2000s. If I was old enough, I probably would have heard this comment being made in the late 1990s. As well as the 1980s. And probably before that too. reply polymatter 4 hours agorootparentThat doesn’t make it less true! It’s a bet because it’s risky “capital is at risk”,“value of investments can go down as well as up” etc. As opposed to a savings account which is far far less risky enough that it’s not really a bet. reply prewett 4 hours agorootparentPedantically, any storage of money is a bet, because it could change in value. However, to the Buffett-style investor, you think about whether you want to buy the entire company, even if you can only afford one billionth of it. You look at a reasonable projection of earnings growth--and don't buy companies that are unpredictable (like early stage tech companies). You try to buy at a discount (\"margin of safety\") in case you are wrong in some fashion. And so forth. So for example, Coca-Cola (KO) is pretty predictable. Absent any major blunders by management, KO is going to grow roughly the size of the economy, and it's going to put out 3% a year in dividends. So the fair market price of KO is reasonably determinable, and you wait until you can buy it at or less than it's fair price. This is usually contrasted against technical traders, momentum traders, etc., who are not investing in the fundamentals of the business and assuming the price will follow good fundamentals, but rather they are betting on how the price will change. So \"investing\" is seen as buying fundamentals and \"betting\" (or \"gambling\") is seen as buying on expected price changes. reply quesera 4 hours agorootparentprevNo, it's just wordplay. Capital is always at risk in financial investments. If there is a semantic difference, I'd say you \"invest\" when you have a historical expectation of future positive returns, and you \"bet\" when you're taking a contrarian approach or just going with a gut feeling when data isn't available or known. Anecdotally, and personally, I've had better luck with \"bets\" than \"investments\". But they're fundamentally the same thing. reply lotsofpulp 4 hours agorootparentprevThat use of bet would make it a meaningless comment. Presumably, elzbardico’s use of “bet” meant something akin to betting in a casino or lottery, where the goal is to get high from the rush of sudden, big, improbable wins. reply Apreche 3 hours agoprevI predicted years ago they would make a CPU and you would be able to buy an All-NVidia PC. I think the reason that hasn't happened is because of the failed purchase of ARM. And looking at the market dominance of NVidia, it seems they were right to block that acquisition. reply JonChesterfield 21 minutes agoparentThere was an arm CPU from nvidia branded \"Tegra\" from circa 2010. I remember a laptop (or maybe a mini pc style thing) based on that and power consumption being shameful but my recollections are hazy. Vaguely interesting side note, yandex found that from poor search terms very easily and google abjectly failed to. I hope google are tracking how frequently people use their engine to find yandex, while remembering bing being mostly used to find google and maybe the death of yahoo. reply alphabeta2024 2 hours agoparentprevSupercomputers are now Nvidia-only with Grace Hopper chips. reply lotsofpulp 6 hours agoprev> a technology cross-licensing that takes advantages of each other’s fab capabilities is going to help a lot in bringing the cost of GPU cycles down much further! What does this mean? I thought neither have any “fab” (manufacturing) facilities. reply sublinear 6 hours agoprev> We were always engineering-led and there was a lot of hubris... So, long story short is that most engineers, especially ones as fanboyish as this, are wildly out of place in decision making and can't see the forest for the trees? It doesn't seem that surprising. reply aleph_minus_one 5 hours agoparent> So, long story short is that most engineers, especially ones as fanboyish as this, are wildly out of place in decision making and can't see the forest for the trees? My experience is rather that people who are passionate about engineering simply have a very different \"taste\" in hardware and buying decisions than other groups. So they see the forest insanely well, but they see very different paths through this forest than other people (say analysts or the general population) do. reply paulmd 1 hour agoprev [–] > We did launch a “true” dual core, but nobody cared. By then Intel’s “fake” dual core already had AR/PR love. We then started working on a “true” quad core, but AGAIN, Intel just slapped 2 dual cores together & called it a quad-core. How did we miss that playbook?! it is wild the way AMD engineers can't stop themselves from throwing stones when their entire product strategy in 2024 now rides on gluing together these cores. people forget that Intel saying that AMD was gluing together a bunch of cores comes after years of AMD fans whining that Intel was gluing together a bunch of cores - that was always an insult to Intel users that pentium D wasn't a real chip, that core2quad wasn't a real chip (not like quadfather, that's a real quad-core platform!). And you see that play out here, this guy is still salty that Intel was the first to glue together some chips in 2002 or whatever! and the first time AMD did it, they rightfully took some heat for doing it... especially since Naples was a dreadful product. Rome was a completely different league, Naples really was glued-together garbage in comparison to Rome or to a monolithic chip. You can argue that (like DLSS 1.0) maybe there was a vision or approach there that people were missing, but people were correct that Naples was a dogshit product that suffered from its glued-together nature. Even consumer ryzen was a real mixed bag, vendors basically took one look at naples and decided to give AMD 2 more years to cook. frankly I find it very instructive to go back and read through some of the article titles and excerpts on semiaccurate because it just is unthinkable how blindly tribal things were even 10 years ago, but this shit is how people thought 10 years ago. Pentium D is bad, because it's glued-together! Core2Quad is bad because it's glued-together! And that from the actual engineers who have the perspective and the understanding to know what they're looking at and the merits, with 20 years of retrospect and distance! If you instead look at what the discourse of this time was like... https://www.semiaccurate.com/tag/nvidia/page/6/ \"NVIDIA plays games with GM204\" \"how much will a GM204 card cost you!?\" \"Why mantle API will outlive DX12 [as a private playground for API development outside the need for standardization with MS or Khronos]\" \"GP100 shows that NVIDIA is over four years behind AMD in advanced packaging\" \"NVIDIA profits are up in a fragile way\". reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Nvidia has surpassed the market capitalization of both AMD and Intel, a significant milestone in the tech industry.",
      "Hemant Mohapatra, a former AMD employee, reflects on the unexpected nature of this achievement, given AMD's historical position relative to Intel."
    ],
    "commentSummary": [
      "The author, a former AMD engineer, highlights AMD's strong engineering culture but notes shortcomings in software support and vendor relationships.",
      "Nvidia's success is attributed to aggressive, sometimes controversial, business practices and a robust software ecosystem, particularly with CUDA.",
      "Dr. Lisa Su's leadership at AMD has been crucial, and there is ongoing debate about whether Nvidia's dominance is sustainable or if competitors like AMD and Intel can close the gap."
    ],
    "points": 158,
    "commentCount": 106,
    "retryCount": 0,
    "time": 1720182189
  },
  {
    "id": 40878765,
    "title": "Is there any software you only made for your own use but nobody else?",
    "originLink": "https://news.ycombinator.com/item?id=40878765",
    "originBody": "Just wondering if any of you has created any software that is meant for your use only and will never see the light of the day for anyone else.What does it do? How did you make it? How much time you spent making it? How often do you use it?",
    "commentLink": "https://news.ycombinator.com/item?id=40878765",
    "commentBody": "Is there any software you only made for your own use but nobody else?155 points by Crazyontap 6 hours agohidepastfavorite312 comments Just wondering if any of you has created any software that is meant for your use only and will never see the light of the day for anyone else. What does it do? How did you make it? How much time you spent making it? How often do you use it? chaosharmonic 1 minute agoI've been tinkering on crawlers to doomscroll job boards for me, and a skeletal hybrid of a CRM and Tinder for swiping through the various results and then tracking them. I eventually want this to be usable enough to share with others for local use, and to demo on my portfolio, but for now I'm just trying not to spend more time building the tools than I am using them (and harvesting the redirect links is already enough to solve a lot of what makes the search process miserable). In the meantime it's mostly a cluster of experiments that range from teaching myself Web scraping, to generally aiming for a leaner tech stack than my prior full-stack experiences, to specifically asking myself \"how much of this can I do in pure CSS?\" While I'm not sure I want the support burden of maintaining the scraping code in public (and anyway it makes more sense imo to just enable bulk upload so you can bring your own sources), I do have a massive beast of a writeup[0] documenting a lot of what went into that, and the API code is at least presentable (see my GitHub) even if the UI is too skeletal for that as of now. [0] https://bhmt.dev/blog/scraping (fair warning: this is 10000 words not including code samples) reply rowofpixels 3 hours agoprevI built a hydroponic garden as a covid hobby. I wrote software to maintain the garden, water it on schedule, apply ph changes to the water, turn lights on / off, humidify, as well as monitor statistics (temperature, humidity, water temperature, water ph, water conductivity). Rough guess would be that I spent 50 hours actually working on the software. There's a handful of raspberry pis involved. I wrote everything in elixir and used https://nerves-project.org. The dashboard is written with phoenix live view. One of the raspberry pis is the \"brain\" and basically runs the dashboard and controls devices. The devices are all in an elixir cluster. I also run timescale db for some basic history of metrics. Once I start a grow I don't use it that much actively, but it passively runs all the time. I check in every few days or week to make sure nutrients are looking good. I've grown strawberries, lettuce, jalapenos, and cayenne peppers. reply aperrien 1 hour agoparentWhat do you use for valve automation? Is it a commercial or custom part? I've been wanting to do the same myself, but I hear there's all sorts of quality issues with automatic valves. reply rowofpixels 1 hour agorootparentI originally bought some solenoid valves to experiment with, but ended up simplifying my approach. I use a submersible pump that is plugged in to power. I can just automate turning on/off power to that outlet (I have two TP-link / Kasa HS300 strips). The nutrients / water are in a tank below the tray of plants, so when the power is \"off\", gravity brings the water back through the pump into the tank again. reply whitehexagon 34 minutes agorootparentWhat a clever and simple solution, I love it. I have been thinking about such a grow system for a long time for my chilli plants, and after having had a few split solenoid valves on a different irrigation project I was very hesitant. Thanks for the inspiration. reply throwup238 1 hour agorootparentprevNot OP but I use motorized ball valves from Amazon [1] which are hooked up to a four way water hose manifold to create four different zones. It's wired up to an ESP32 that controls them with relays via GPIO, using the ESPHome sprinkler controller module (which does pretty much everything OP's code does). I've never had a problem with them and the last time I even touched them was over a year ago. They're pricey but you can DIY them. The usual sprinkler valves at hardware stores need quite a bit of water pressure to change state which is probably what most people have a problem with, especially if they're trying to feed them with the kind of pumps they get at hydroponic stores. [1] https://www.amazon.com/Motorized-Stainless-Electrical-U-S-So... reply samtho 1 hour agorootparentprevNot OP, but I made one of these for my partner and I’s bonsai garden. I use standard 3/4” sprinkler valves from the big box stores, connected to a manifold via unions on each side. This enables me to swap if needed, but these are ruggedized and will last a while. They do take 12VAC, so you need a transformer and use relays to turn them on, but they work very well. reply Gormo 2 hours agoparentprevAny chance of making your code public? I'm thinking of dabbling in aquaponics in the near future, and what you've built sounds almost exactly like what I would end up working on myself. reply neoecos 2 hours agoparentprevDid you published this project, sounds interesting just to see the basics of nerves in a real small thing ? reply sloaken 2 hours agoparentprevThat is AWESOME! I would love to see what you did for this. Even more I would love to build the same. reply stoneman24 2 hours agorootparentI agree, a blog post or other description would be great and really inspiring for my own projects. reply robxorb 2 hours agoparentprevHow does it automate ph changes to the water? reply rowofpixels 59 minutes agorootparentI use two pumps from Atlas Scientific - one for a jar of base and one for a jar of acid. I have a sensor for PH so I can see in the live dashboard, and can click a button on the dashboard to disperse a set number of ml to the tank. I should have been clearer - PH is the one thing I didn't \"close the loop on\" because it'd be a little volatile. For instance when you first add nutrients to the water the PH drops steeply but stabilizes over hours or a day, I didn't want to respond too constantly to those changes. I should spend more time on this aspect though and maybe just have notifications for when it makes decisions. reply throwup238 1 hour agorootparentprevNot OP but I use aquarium peristaltic dosing pumps that pump General Hydroponics pH Up/Down solution controlled by a Raspberri Pi with an Atlas Scientific pH sensor. reply j45 1 hour agoparentprevThis sounds like a great project to reconnect one with growing food… with some perks. Appreciate you sharing, helps share others are thinking about it too. Is there a reason you went with hydroponics vs aeroponics? reply rowofpixels 53 minutes agorootparentI know next to nothing about aeroponics - I did read about aquaponics a bit when I started, but hydroponics seemed the most accessible for me. I've loved making my own crushed red pepper. And there's something fun about growing plants in the middle of a cold snowy winter in the basement. reply throwup238 57 minutes agorootparentprevIn practice aeroponics is very fragile. All it takes is a failure for a few hours for roots to irrecoverably dry out and kill the plants. Most hydroponic methods give you a safety margin of days or even weeks. reply rtcode_io 2 minutes agoprevhttps://RTCode.io : Try: Code → New… ↓ deploys to https://RTEdge.net : interactive map --- I use it daily, nowhere else lets me build full-stack apps with nothing but the web platform APIs, while preserving (front- & back-end) state between edits! The playground just lets me code service workers (https://sw.rt.ht) which deploy with one click and run as edge workers! reply 65 3 hours agoprevAlmost all of the software I make in my free time is for my own use. My most used tool I have is a note taking web app that automatically saves markdown files to S3. The most important feature I added was a little button that would automatically make a note for the current day, and put it in the daily notes folder, all sorted and organized. I also have full text search which is very helpful for finding old notes. I also use an RSS reader I made. Instead of just showing you the text of the page like a standard RSS reader, it proxies the web page so you can read the article directly from the website, but with the added benefit that since it's a proxy, I can control all the HTML, CSS, and Javascript on that page. Another daily one I use is a random background music playlist for Spotify that is auto generated daily. Using the Spotify API you can find random music, then find random instrumental music from that random music. I use this to discover new songs to listen to while working. Basically, making your own software is fun. Making production software is much less fun. I don't need to worry about a million things when I make my own software. Sure, I make $0, but if I spent months making, for example, my notes app production ready, and tried marketing it, I'm guessing I'd still be sitting at $0. reply newsbinator 3 hours agoparent> Using the Spotify API you can find random music, then find random instrumental music from that random music. For this, I made a Spotify playlist with 41 hours of instrumental soundtrack music that helps me focus. It's not random like yours, but with that many hours, there's enough variation if you put it on shuffle. It's mostly epic and uplifting movie scores. Or suspenseful and building up to something... none of that 8-bit video game beep boop shrill stuff. https://open.spotify.com/playlist/31buZEaVGW9f5Y4cEcKtbt?si=... reply dougdimmadome 3 hours agoparentprev> My most used tool I have is a note taking web app that automatically saves markdown files to S3. The most important feature I added was a little button that would automatically make a note for the current day, and put it in the daily notes folder, all sorted and organized. I also have full text search which is very helpful for finding old notes. I have a very similar thing, mine uses a dropbox folder as a backend so I can easily browse on laptop and use whatever. I like the daily notes idea though! reply dudus 1 hour agorootparentSounds like you'll be better served by obsidian. The free plan covers all those use cases and more reply meiraleal 46 minutes agorootparentDid you read the title of this thread? reply positr0n 3 hours agoparentprevHow does the full text search work? On-device copy of all the notes? Text index in another database? Just download them all from s3 when you search? reply 65 3 hours agorootparentText gets indexed in another database every time a note gets saved/deleted/created. There might be better solutions with AWS Athena but using a simple MySQL database was by far the easiest (and quickest in terms of querying) way to add full text search. My database is paid via usage so I don't have to spend much money, if any, to index my notes. reply co0lster 3 hours agoparentprevI’m stealing Spotify random instrumental music idea! Why I cannot come up with similar ideas by my own? Thats the hardest part I think… reply 65 3 hours agorootparentI actually stole the idea from a guy named Max Hawkins who made a Spotify Daily Random playlist. I made it to be just instrumental music since I wanted it for working. https://maxhawkins.me/ reply SushiHippie 2 hours agoparentprev> Using the Spotify API you can find random music, [...] Which API endpoint do you use for this? reply 65 2 hours agorootparentThere is no endpoint for random tracks. The method I found that works the best is to search for two random letters, e.g. \"fq\", pick a random result, and then use the API to find recommendations based on that track that have a minimum instrumentalness of, say 0.9, then pick a random recommendation from the results. I store all the songs that have been added to the playlist in a DynamoDB database and make sure no song gets added twice. reply JensenKarlsson 3 minutes agoprevI made a PWA for Miniflux because I'm a doomscroller deluxe and wanted a similar experience for my feeds [1]. It's nice to be able to tailor something for my needs specifically. 1. https://github.com/wolfhechel/sidor reply fardinahsan 2 hours agoprevYes. I made two recently. - TalkToYoutuber[1]: Download the transcripts from a youtube channel and hook it up to gtp4 with RAG to let me \"talk\" to youtubers. There's a bunch of youtubers who have useful knowledge to share, but no blog or wiki, so semantic searching their video transcripts is the next best thing. - YoutubeThumbnailSearch[2] - Embded all of a youtube channels thumbnails using CLIP and search them using text. I often need to search through news channels with 10k+ videos, often in foreign languages, so not having to rely on the title or transcript but the video thumbnail helps. This is a much more niche usecase tbf. I am thinking of making a scaled down version of [1] so I can \"talk\" to long videos, like conference speeches or university lectures. Should take an hour or two to cook it up since it will reuse most of the code from [1]. --- [1] https://github.com/FardinAhsan146/TalkToYoutuber [2] https://github.com/FardinAhsan146/YoutubeThumbnailSearch reply magicpin 2 hours agoparentSomething like talktoyoutuber would also be very useful for certain discord servers. They'll have a lot of knowledge on something but will gatekeep it with \"just use the search.\" and they'll refuse to build a wiki or really engage in any kind of organization. reply fardinahsan 2 hours agorootparentI can cook it up if it would actually get some users. Ultimately, I want to make a tool where you can plug in any arbitrary document store/scraper to an LLM with RAG. But I think we are still not there yet in terms of all purpose scrapers. reply floydianspiral 2 hours agoparentprevthis is a really cool project, you should send it to people at youtube, get a job there and implement this in their sidebar... reply fardinahsan 2 hours agorootparentThe projects are dead simple. I think if Youtube wanted to, the would have implemented this long back. It's probably a legal landmine and financial tar pit. But thanks nevertheless. reply roughly 1 hour agorootparentYou’d be shocked at how hard it is to fund, start, and ship even a basic project at a company the size of YT or anything else in the Google/Alphabetaverse. It’s probably also a legal landmine and all that, but organizational friction’s more than sufficient to explain simple useful features failing to ship. reply jpc0 9 minutes agoprevI work in live production and have made tons of little apps to make my life easier. A lot of them are little web apps with basic buttons calling http endpoints on gear /apps or doing basic OSC commands etc. People usually use something like a streamdeck for this but I find being able to throw up a slider or something in there so much easier. And many times it might even be single use for a specific event and a lot of time I'm just throwing up a single html page with no styling and a script tag so it really takes a minute or two. reply mikelevins 1 hour agoprevYep. I wrote bard, a Lisp that combines features of Dylan, Common Lisp, and pure-functional languages purely as a long-running experiment in what I could do to make programming more fun for myself. I subsequently used two versions of it in client projects (to prototype some solutions and to compile them to data used by the delivered product; nothing delivered to the clients depended on my weird Lisp dialect). I wrote a tool called nym to help generate names for characters and other things in games and stories. It's enough fun in itself that I sometimes just play with it. I wrote another tool called model-namegen to generate names with stricter constraints for science-fiction stories. Those names are mapped uniquely and reversibly to 64-bit integers used in the story to generate names for machine intelligences. I also wrote a prototype for a 3D multiplayer game called The Fabric set in the world of those stories, and wrote code to generate clusters of colored cubes for use as avatars representing the AIs. Each character's unique ID is mapped to a unique name and also to a unique 8x8x8 configuration of lighted cubes. An example name is Ixion Eleven Chrysotile, the name of the autonomous robot who is the narrator of my Fabric stories. Following is a link to a very short movie of the avatar for the character Miriam Five Bittersweet Earth: https://evins.net/downloads/miriam-5-bittersweet-earth-2-2.m... I wrote a couple of versions of a library for Common Lisp to make certain functional programming idioms I like more convenient for me in Lisp. They're called folio and folio2. I wrote a library called taps that similarly makes use of Richard Waters' SERIES package for Common Lisp a bit more convenient for me. Actually, taps started as part of folio and I ended up wanting to use it on its own often enough that I broke it out separately. I've written several little tools for calculating and keeping track of information that's useful for friends-and-family gameplay. I've written several other libraries and applications purely for the purpose of exploring some idea or other that interests me. For example, beasties was a pond-life simulation that I used as a playground for recreational genetic programming. Panels was an experiment in user interface that used a constraint solver for laying out windows and widgets, and an append-only log of all UI events together with a query engine and a knowledgebase. Panels could display graphic representations of recent user activity and retroactively define mappings from sequences of events to user-defined handlers. It operated on the principle that everything detectable that a user did potentially had some purpose, even if we don't know what it is, so we should remember all the user's actions and offer them the opportunity to define what they meant. I've also written a few little things primarily for the purpose of helping friends and family with this or that task. I've spent a lot of time over the years on things like these. As you would expect, they've taken varying amounts of time and I don't really keep track of how much. I use some of them (e.g. taps and other pieces of folio) almost every day, and others intermittently. A few of them (such as beasties and panels) I haven't really touched in years now. reply galdosdi 4 hours agoprevReminds me of a classic story that makes a good programming parable: Back in 2011, my girlfriend was working at a catering company that announced shifts via a webpage and workers had to sign up for them. Other workers tended to pick them up very quickly, so it was hard to get too many shifts. I wrote a quick web scraper to automatically accept any shift offered and email her. For a couple weeks it was great, suddenly she had all the work she needed. Then one day she woke up late to find a voicemail telling her she was fired. Earlier that morning the script had detected a last minute job announced just an hour before start time and immediately accepted it, resulting in her not showing up to it. I had not accounted for the possibility they would announce a job so last minute, since it had never happened before. reply roughly 1 hour agoparentAs they say, Unix gives you enough rope to shot yourself in the foot. reply joseph_b 52 minutes agoprevCirca 2018, I went deep into investigating ADHD and whether I had it or not. I ended up \"interviewing\" a rather diverse group of people, from authors, teachers, and ADHD coaches to psychologists and other doctors. During this time, I was reaching out to many people, managing schedules and appointments, and eventually publish the interviews. The \"reach out\" to \"interview\" ratio was something like 100:1 and took a lot of management. This was my part-time hobby, I guess. My full-time gig is a software engineer at a bio-tech company. So, I wrote some basic web software (PHP/Symfony) to manage and track the whole process. It took around 3 months to write the code, though there was no set beginning and no set end. The code was started when I became overwhelmed with the manual aspect of tracking everything. The code was done when I figured I had done enough to manage and automate the process. Talking with a few people after the fact indicated very high interest in the software I had written. And thus began the journey to convert it to multi-user. I started on the multi-user conversion and, maybe because I tried to make it do everything and then some, have not since finished it. The code is on my private GitHub, partially converted to multi-user, slowly rotting away (needs library and core updates). What does it do? Manage the process of cold lead acquisition, follow-up interactions and onboarding, and eventual publishing of the resulting interviews. How did I make it? PHP/Symfony. How much time spent making? About 3 months in my spare time. How often do I use it now? No longer used. reply BoppreH 3 hours agoprevI have a 3-letter domain that I use as my personal playground (think \"xyz.com\"). It features: - One-click anonymous upload of text, clipboard, and files. So from any computer, I can visit xyz.com + ctrl+v to upload the clipboard, write notes to myself, drag and drop a file, etc. It's a risky feature, but there's nothing to attract attention and you don't even get a URL back. - Authenticated sessions see a list of uploaded files, with buttons to copy link, download, delete, or generate QR code. There's also real-time notifications for each upload. - Simplified RSS feed reader[1]. It scans my feeds every 10 minutes, and displays the URLs of new items. It has one button, that opens all URLs in new tabs and marks them as read. - A Server-sent-events channel[2], and a UI that displays visitors in real time. The channel allows me to send redirects/file downloads to any visitor, so I'm constantly asking people to visit xyz.com when I need to hand them something digitally. Visitors are color coded with randomized backgrounds for identification. - Youtube video downloader (powered by yt-dlp), along with audio extractor and pitch+speed correction for songs. - Authentication is by approval from an already authenticated session (usually my phone). In the worst case I can edit the text file via SSH. I add or remove widgets according to my needs. At one point I had chat integration with Facebook+WhatsApp+Telegram (got me banned from WhatsApp), radio player (replaced with Spotify), and even balances by scraping my bank accounts, credit cards, and Steam (removed after a bank started asking questions). The whole thing runs in custom pair of Go and Python servers, developed slowly over the last ten years, and I use it multiple times a day. Feels like a digital tree house, messy but fun and useful. [1]: https://github.com/boppreh/feeder [2]: https://github.com/boppreh/server-sent-events Edit: people have found it and started spamming uploads of \"HELLO FROM HN\". One IP looks Swedish. Well, Hi! But I'm taking it down for a few days to avoid tempting more people. And shoutout to the Go team, that server has been rock solid and 100% backwards compatible over the past ten years. reply Manozco 3 hours agoparentThis is like 90% of what I need to setup on a server for my personal usage. Issue is I don't do front dev at all so I never really start working on it. Any chance you've open sourced it ? (Or if not opensourced but you're willing to privately share the code, you can reach me at hn [at] manoz [dot] co) reply BoppreH 2 hours agorootparentI sent you an email with the code and instructions. I won't share it openly because I don't want to tempt people into finding security flaws for fun. It's definitely not code that I'm proud of, but it's been serving me well for many years, and might help you get started. reply ycuser2 1 hour agoparentprev> ..., along with audio extractor and pitch+speed correction for songs What do you mean with pitch+speed correction? Have songs on youtube false pitch or speed? reply BoppreH 1 hour agorootparentI often have to download songs for children to sing, but they have trouble with fast or low-pitched songs. It destroys the audio quality, but they don't seem to mind. reply liamYC 1 hour agoparentprevCool projects, I’d definitely like my server to be able to do all these things. What have you used to deploy it? reply BoppreH 1 hour agorootparent- Oracle Cloud Free Tier[1] for a Ubuntu VPS (4 ARM cores, 24 GB RAM). Surprisingly pleasant and reliable, given who's offering and for how much ($0). It used to be on DigitalOcean, until they kept screwing up their FreeBSD support and bricked my machine twice. - Caddy[2] web server with Let's Encrypt certificates, working as reverse proxy. The rest is a very lazy 2010's solution: - A Go server for HTTP (static files, uploads, maintaining server-sent-event channels). It also reads and writes events in a custom format to a local socket, for the interactive parts. - A Python server for the widgets, communicating with the Go server. - Source code edited manually in-place (SSH or SSHFS[3], with Git) and restarted as needed. I know, I know, awful practice. But as I'm the only user, uptime during development is not a concern. - Startup is handled by a @reboot cronjob and a bash one liner. - Text files for \"structured storage\" (RSS feed items, authenticated sessions, mapping of uploaded file names). As horrible as it might all sound, it has survived ten years and two cloud vendors. Nowadays I might containerize it, or rewrite as one Rust server, but I think I made the right choices at the time. 8/10 given the unusual requirements. [1] https://www.oracle.com/cloud/free/ [2] https://caddyserver.com/ [3] https://github.com/winfsp/sshfs-win reply boricj 4 hours agoprevOver the past two years I've been working on tooling that allows me to delink programs back into object files. What started out as a bunch of Jython scripts is nowadays a full-blown Ghidra extension that can export working object files from a program selection in two mouse clicks. I'm using it as part of a video game decompilation project, but it also enables a whole bunch of other use cases I've documented on my blog. It's not that it is meant for my use only (any capable reverse-engineer familiar with Ghidra should be able to pick it up and use it) nor that it will never see the light of the day (it's open-source). However, it is such an esoteric capability and outright heresy according to computer sciences that I'm having a hard time just finding people who can wrap their heads around the concept, let alone people who would actually want to use this. Simply put, it's so far out there that I don't even know where or how I could even advertise it in the first place, which makes it de facto for my own use only. A couple of people did end up reaching out to me in the last couple of weeks about it, so it might be on the cusp of sprouting a very tiny user base. Still, I've made it for my own use and until very recently I've never expected anybody else would use it. If someone wants to check out the dark magic: https://github.com/boricj/ghidra-delinker-extension (disclaimer: might give nightmares to linker developers). reply jart 2 hours agoparentSomething like that really deserves to be written in C so you don't need to install Ghidra to use it. The way I imagine it working is if I want the function `foo` then I'd say `objsuck -ffoo -ofoo.o prog.elf` and it'd look at the elf symbol table to find the `.size` of `foo` and copy that symbol into the .o. I guess you would then need to use xed to disassemble the opcodes to see what other symbols it jumps into or calls, and grab those too, along with any memory references, and then emit relocations. Overall I support this, since it'd be the easiest way to expropriate content from open source codebases whose source code is too byzantine to let me extract one teensy tiny little feature without the bloat. To me this is perfectly normal. You'd also be smart to only support COFF if the person uploads the binary to a hosted service you control and pays you money. In fact this would be even better if it could generate .s files from the object content, so no one would get triggered by binaries. reply boricj 54 minutes agorootparent> Something like that really deserves to be written in C so you don't need to install Ghidra to use it. I think there's the Witchcraft Compiler Collection if you want a freestanding option [1], although I haven't looked into it too closely. The problem is that object files are made up of section bytes, a symbol table and a relocation table. You can't just rip bytes out of a program and call it a day, you need to recreate all that information in order to actually delink code into relocatable object files. Doing that isn't a trivial problem, it requires a lot of analysis and metadata, especially if you don't have debugging symbols or symbols at all. Leveraging Ghidra allows me to concentrate on the specifics of delinking, which can get very tricky depending on the platform (MIPS in particular is a nightmare to deal with). I'm also trying to solve delinking in general and not just for one platform/ISA pair, so reinventing the wheel for every architecture out there is a nonstarter in that context. [1] https://github.com/endrazine/wcc reply vintagedave 3 hours agoparentprevI know a linker developer, I'm going to send this to him :) Not sure about heresy according to computer science. Sure, it's not intended, but it's a very clever thing to be able to do. reply boricj 1 hour agorootparentDelinking by itself isn't a heresy (no more than disassembly or decompilation), but what I do with it definitively is. Ripping out MIPS code from a PlayStation video game and shoving it into a Linux program, dismembering a x86 Linux program and turning it into a native Windows program... It's when you get creative and throw ABIs out the window in order to create some cursed chimeras that this really becomes heresy. reply nrr 49 minutes agorootparentOne person's heresy is another person's sickos.png. This sounds exactly like my favorite sort of object code vivisection. reply liamYC 1 hour agorootparentprevTechnology like this will create huge selection pressures against desktop apps if it becomes easy for people to reverse engineer, remove payment mechanisms, and then freely distribute. Wouldn’t you think? reply pmontra 14 minutes agorootparentFreely redistribute, I don't know. If a program can extract code from another one, a program can detect that code. It looks similar to virus signatures. A company with some IP would run the detector on the software of competitors. reply aranchelk 26 minutes agoprevAssistive technology, I made a head-tracking mouse replacement. I’ve now used it almost every day at work for a decade. It’s open source but AFAIK no one else is using it: https://github.com/aranchelk/headmouse reply 5pzv1kn3 2 hours agoprevI’ve developed several webapps to help our family and personal life: * Vehicle Maintenance Tracker: Logs all vehicle maintenance and sends reminders based on time or mileage for upcoming tasks. This one is probably one of the most used and useful of everything I have made. Lend/Borrow Tracker: Keeps track of items we've lent or borrowed, to/from whom, and when. We use it most for books, but it can be used for anything. Library Book Manager: Lists all the books we checked out from local libraries, displaying their cover images and ISBNs. Using a barcode scanner, we can quickly \"check in\" books on return day, accompanied by an adorable \"ding ding!\" sound recorded by one of my kids. Really beats manually searching the paper printout. It can be used on multiple devices at the same time - the checkin status of each book is synced live between all users, so each kid can find and check in their own books. School/Home Lunch Manager: Displays the school lunch menu alongside each of my kids’ names. We mark school/home lunch days at the start of the week for easy morning prep. Sickness Documentation: Tracks sickness details like symptoms, medication, temperatures, and timelines, helping us coordinate how we are going to take care of the kids when they are sick. These apps, along with a few others not listed here, run on a server in my home, accessible only within our network (in home of via a VPN). reply mzronek 22 minutes agoprevI reviewed hardware back in the day and was tired of all the repetitive tasks necessary to measure the performance of CPUs, GPUs and storage devices. So I wrote a benchmark automation tool, that did the work for me. CINEBENCH and the likes where easy, but I also automated games without using their integrated benchmark. I needed a scripting language to load settings, go through the game's menu and load a save game. To avoid any kind of load from the automation, it offloaded the input data to an Arduino-based USB device, that simulated the benchmark run with previously recorded input. It worked pretty well, but small latency issues could of course result in small variations of the run. And bouncing into NPCs was generally a bad idea. Here is a video of the system in action that completely automated a custom CS:GO run with additional streaming load as it would occur when streaming PC gaming: https://youtube.com/watch?v=ZpSPyd9f4cg I get asked once in a while if the software can be downloaded or bought, but I am not going to do it. Writing software for yourself has the neat advantage that you never need to deploy it, upload it, write a change log, answer questions or fix bugs at any given time. It is just about solving the task at hand and nothing else. reply seemack 59 minutes agoprevI wrote an app to log mileage while doing deliveries, etc for my small business. It gives me a small tax benefit at the end of the year. To make it more fun, I gave the UI a \"terminal\" flair. I wrote it over the course of a week or so and I use it frequently. It's not that it won't see the light of day for anyone else but it's a very specific niche so I doubt anyone would even find it on the app store If anyone's curious: https://play.google.com/store/apps/details?id=io.thisischris... reply shkurski_ 54 minutes agoprevIt's hard to call it \"software\", but the last one was a script to merge multiple Google Calendars into one, born out of frustration with juggling them manually. It runs on Google Apps Script, reacts on triggers, so once an event is created/modified/removed in one of the calendars, the change is reflected in the main calendar automatically. [Edit] In the opposite direction as well: if modified in main, it reflects in the original one. AFAIR, it was the feature I missed, since Google only supports (-ed?) one-way mappings. reply ycuser2 2 hours agoprevI made a small tool that takes a screenshot all 5 minutes and stores it in a password protected zip file, but only if something has changed on screen. Sometimes I go through the old screenshots and get nostalgic as the oldest are 10 years already. I spend so much time of my life on my computer, so why not take photos of it? reply robxorb 34 minutes agoparentThat is so cool! It'd be amazing to see a timelapse of the past ten years of someones computer life. Assuming 8 hours/day average of active screenshots every 5 minutes, would be (8*60)/5 = 96 shots per day. Times 3650 for ten years is 350,400. Divide by 60fps is 5840 seconds, by 60 is 98 minutes. So a decent movie length, as a single video. Though, I imagine it'd be unfeasible to go through every screenshot and remove sensitive information. (At a rough ballpark: if it took 20 seconds on average, to analyse and either bin or selectively-censor each screenshot, it'd take about a full working year, 8 hours per day.) reply 0xfeba 2 hours agoparentprevHa, MS has Recall which is like this ... but obviously it's had problems. reply barrenko 1 hour agoparentprevHmm. reply acheong08 30 minutes agoprevI have a bunch of random scripts, executables, Python files, etc scattered all over my computer. Some more often used ones: - A script that manages my Music files (add/rm/search) and syncs them with my phone when connected via ifuse+rsync - a CLI to really easily deal with port forwarding because I run a lot of stuff on my raspberry pi and old laptop which goes out to the internet via WireGuard & forwarded from my VPS I also have local forks of a few abandoned projects with a few bug fixes or minor added features. Ought to find alternatives but too lazy reply arnaudsm 3 hours agoprevAs a freelancer I invoice in multiple currencies, and I couldn't find a program to generate them that wasn't an overly complex $100/mo SaaS. So I build a little cli to generate my invoices. 100 loc and super simple. I miss the 70s when programming was the default way to solve problems. Excessive abstractions and proprietary software often slow us down. reply epolanski 3 hours agoparentMy (polish) bank gives invoicing software for free and obviously you can put whatever currency you want. Bank is called millenium bank. reply 6510 2 hours agoparentprev> I miss the 70s when programming was the default way to solve problems. When you get deep enough into writing a custom tool it starts doing things a generic tool would never accomplish (or it would have to be bloated with features no one needs) Hard coding values and constraints for personal use makes such elegantly simple interfaces. For example, my agenda is a beutiful boulderdash-like grid of icons. The data is a set of arrays [1,2,1,0,0,1,1] and an object for special days. There are no setting, it has zero buttons to press. I've made countless silly things other people could use if only they knew it existed. https://go-here.nl/real-salary-calculator.html https://title-spider.go-here.nl https://salamisushi.go-here.nl endless things I've made for personal use. I think something like 60% needs one or two lines of love to work in 2024. reply hansonkd 3 hours agoparentprev> I miss the 70s when programming was the default way to solve problems. I'm not sure I follow. You can cancel your ISP and have the same experience if you are missing it. reply 7thaccount 2 hours agorootparentThat's obviously not what they meant. I think they're more referring to several decades ago when someone had a software need they wouldn't get some off the shelf proprietary tool that costs $$$$ and is crazy bloated and locks you in. Instead they'd hire someone and that person would work with them to deliver exactly what they need and that solution would last for decades and the eventual off the shelf software that replaces it is widely seen as inferior by the employees. There are famous stories of this. A highschool once had a student write their entire automated HVAC system on a C64 for free. It has worked really well for 3 decades, but they struggle to find replacement parts. They asked for bids to replace it from several companies and were flabbergasted to learn it would costs them an insane amount of money. So instead, they call up the kid (now an adult who still lives nearby), to occasionally do maintenance. Which solution is better? The OP is just talking about how they miss the times when a lot more people were going for the custom in-house C64 option. reply Gormo 2 hours agorootparentThere's still a huge consulting market for this kind of work. You just have to target the right market segments. Large enterprise firms either have in-house teams or contracts with big enterprise-scale providers, so don't do this a lot, and tiny mom-and-pops tend to use off-the-shelf SaaS, and don't have the budget or internal skillset to manage these kinds of projects. But there are many medium-scale businesses that are structured enough to have specialized use cases that the off-the-shelf stuff isn't optimized for, and which have enough cash to invest in custom solutions. reply cellularmitosis 3 hours agorootparentprevCancelling your ISP doesn't leave you surrounded by peers who default to solving problems from scratch. reply smeej 2 hours agorootparentThis is the same problem that comes with my desire to give up a smartphone. Getting rid of my phone doesn't make other people know how to give me directions to their house without GPS (among other problems). reply guessmyname 2 hours agoprevFinancial Tracking Application. I’ve been developing this app for five years. During this time, I’ve integrated it with all my bank accounts to automatically fetch data needed for creating daily graphs and analyzing trends. This allows the app to generate predictions for long-term net worth growth. Additionally, I’ve integrated the app with Yahoo Finance, Fidelity, and Morgan Stanley to monitor my Restricted Stock Units (RSUs) and Employee Stock Purchase Plan (ESPP). This functionality helps manage tax responsibilities on capital gains and compare growth with other job offers that include RSUs from different companies. For instance, I can answer questions like, “What if I had chosen to work at Facebook instead of Apple?” The app also extensively utilizes data from credit card transactions. It includes charts listing new restaurants visited in the last month, tables tracking monthly subscriptions, algorithms to detect discrepancies, and numerous other features. While I’ve considered turning this into a business, my current job keeps me very busy. reply arjvik 20 minutes agoparentWould love to see how this works, or at least hear about how you're able to pull this off! I've been carefully keeping double-entry-accounts of my personal finances in GNUCash, but I don't have anything hooked up to my accounts file. I was originally hoping that GNUCash would have some way of letting me sum up a certain combination of accounts to calculate i.e. \"how much float I have currently,\" but even that doesn't seem to exist... so my first order of business is probably that sort of simple custom repoting. But would love to make use of the data and create some more actionable reports! reply jeffreyrogers 2 hours agoprevI wrote a script that looks at C++ files, figures out the dependencies (by looking at what headers they include) and automatically compiles and links out of date files. It makes programming in C++ sort of like programming in a modern language like Go. It took me a couple of days to implement and I use it any time I am working on my own C++ projects. I eventually want to add package management features to allow integration with external libraries, but this isn't a priority for me currently. I have also worked on trading algorithms that used publicly available info about crypto order books to make profitable trades, which will obviously not be published since then they would stop working. reply atlgator 1 hour agoparentBill of Materials (BOM) software for identifying dependencies along with versions that are out of date or vulnerable is a growing market in Government. reply polivier 1 hour agoprevMy wife is an optometrist (so, an independent worker), and she needs to check the list of patients she has seen (and the types of care they were given) to make sure that it matches correctly with the clinic's records. It is a tedious job, something that takes about 20 minutes per day. With a little scripting, I was able to bring that down to about 5 minutes per day. The time I saved her has added up to several dozens of hours now, and will amount to several hundreds of hours saved as the years go by. reply dllthomas 38 minutes agoprevI have a webapp for tracking chores that need to be done periodically (but not on a fixed schedule). It just lists all chores sorted by how due they are (period / time since last completion) and surfaces a short history of who did what. I've rebuilt it a few times and played around with extra features, but the basics didn't take long. I have a utility (dklocs) that'll turn git-formatted diffs into location-prefixed changed lines. It lets me do things like `git diff mastergrep thatThingvim - -c cbuffer!`. I built it for me (and probably use it multiple times a day) but threw it on github (along with another tool for intersecting a diff with code coverage that I don't think I've used since the motivating use case - where it did prove helpful). I don't know if it quite counts as \"creating software\" but I've got some scripts and configuration to maintain separate context in named screen/tmux sessions, setting shell variables and aliases, adjusting the prompt, starting in some particular directory. Most useful there is segregating history by context, so ctrl-r when I'm coding doesn't step through system administration stuff. I have a general project to decompose applications into utilities, and a pattern for dealing with the long-running bits that's been somewhat successful. I once wrapped up libpurple in a client that worked that way, and (in a separate project) it's how I get errors from `cargo watch` into vim. reply kibae 35 minutes agoprevA note-taking app that is similar to Obsidian where I can link notes to each other. Some differences include no naming rules (a lot of my note titles have a colon) except uniqueness, custom clusters so my knowledge graph is manageable. I’m going to add different note types (i.e. not every note is .md, but have .csv and .ical as well) that can be expanded and linked within a note. It’s written in React, hosted on AWS (so not an Electron app… yet), and CodeMirror for the editor. I’ve spent probably 100 hours making it so far. reply costco 3 hours agoprev40 lines of C to control brightness on Linux in the way I like (Pressing brightness up key should make it go up more than pressing brightness down key makes it go down). It took 20 minutes to make. Used as a keyboard binding. TODO list program and the list is periodically printed on my desktop with conky Software to automatically book reservations at good restaurants on Resy. Supported proxies, multi account, automatically running every day and getting reservations in a certain time range, and even something with a USB GSM modem to respond to the confirmation texts you get a day before. Used it until I got banned from Resy :\\ Family photo search using CLIP (actually uform) and face labels from Synology NAS. So you can search “winter +christopher” and it will only show pictures of me and sort by the most winter related ones. You can also filter out certain names, search multiple names, click on an image to get images most like it, filter by year, or any combination thereof. Took a couple days to make with Flask, pgvector, and some code to scrape data from the Synology web interface. My family uses it sometimes too though. reply walthamstow 2 hours agoparentLove the Resy one! reply explorigin 3 hours agoprevI once ripped the corner of my windows install code sticker. I was missing the last 2 characters. I wrote a script in SikuliX to bruteforce the remaining 2 characters. It took about 4 hours to run but in the end, I got the full valid code. reply metadat 3 hours agoparentSikuliX looks quite useful. http://sikulix.com/ reply rstat1 40 minutes agoprev2 of my most used web apps are ones I made (technically 3 but the 3rd is a platform service that handles stuff common to all of the services that run on it, there's 5 currently) 1 is a sort of a virtual notebook where I put things I want to remember. Things like guides for setting up new services on top of that platform service. Or random 1 line commands that I don't quite use enough to remember but still need to. Page content in this app is stored in encrypted Markdown files, the metadata (ie the title, publish date, etc) is stored in a local MongoDB instance. It has a feature where you share individual pages publicly if you want, but otherwise pages are viewable only by their original creator. Server is Go, frontend is Angular 10. I don't remember how long it took to build as it started as something else and I kinda reset the development half way through. Probably a few weeks, but I also wasn't constant working on it, so probably longer. 2 is a thing I built out of frustration with my self-hosted Gitlab instance constantly OOM-ing the VM it was on and crashing. It has like a tenth or less of the functionality of Gitlab, but also uses substantially less memory and CPU and does exactly what I want so hasn't seen much if any further development. Also Go for the server and some even older version of Angular for the frontend. reply mr_mitm 1 hour agoprevA TUI client for Confluence A script that does a speed test of my Internet connection once an hour and plots a graph A financial analysis webapp that barely works I call it meware: works for me, and hopefully for someone else, too, but it's not polished. reply andrewjmyers 58 minutes agoparentI would really love to learn more about your TUI for confluence. reply mr_mitm 54 minutes agorootparentSure, it's public: https://github.com/AdrianVollmer/Congruence reply unsupp0rted 3 hours agoprevI was selling an apartment in a developing country. I wanted to know, given the constantly updating property sales tax and rapidly worsening exchange rate, how much I’d end up pocketing in USD, if I sold for X vs X - 5% vs X - 10%, etc That would inform my “I’m willing to go as low as” selling price. So I built myself an app to scrape the current tax from the government’s online calculator and assemble a dozen what-if scenarios, given the current exchange rate. When I found one that would let me break even, cash in hand after all fees and taxes, that became my price floor. It worked. Now I don’t need my app anymore. reply thiagoperes 4 hours agoprevI created my own translation app using llama3-80b, I call it \"expat translator\": I live outside of my home country and always struggled with using translators like Google Translate because they don't tell you if the way you're writing something feels natural in the other language. It gives me some pretty good results and I also instruct it to give me rewrites for informal and professional use, so I don't sound weird on WhatsApp for example. It uses an on-device model for language detection and results are sub 0.3s thanks to groq If someone wants to try: https://testflight.apple.com/join/GBxPMw2h reply aadhavans 4 hours agoparentAs a sort-of-expat myself, I can definitely relate to this struggle. Out of curiosity: does the language you're translating to have a non-latin script? I've found that llama often struggles with those. reply dathos 4 hours agoparentprevSo this app would not be for regular immigrants or travellers? reply AlbinoDrought 3 hours agoprevI would add videos I liked to the \"Liked Videos\" or other playlist areas on my YouTube account. I'd return to find the video months or years later, only to see that it may have been removed (usually due to copyright or other channel closure). This video removal issue also extended to other platforms. I found this annoying. To avoid this, I made an extremely simple video platform. I save all my videos there instead. It's still my hobby project that I use the most. The code is at https://github.com/AlbinoDrought/creamy-videos There's an optional youtube-dl importer UI at https://github.com/AlbinoDrought/creamy-videos-importer (separated for easier updates) The importer repo also contains a Firefox extension so any target can be right-clicked -> Import to Creamy Videos -> Select a set of tags -> sent to the importer UI, youtube-dl, and then eventually video storage: https://github.com/AlbinoDrought/creamy-videos-importer/tree... reply monitron 3 hours agoprevI wrote my own home automation platform. I started >10 years ago when the existing options were pretty disappointing to me. It’s a web app that runs on wall mounted tablets in my house as well as on my and my family’s phones and computers. It handles lights, fans, cameras, sensors, locks, doorbells, speakers and TVs, HVAC and more. It runs automations based on time, weather, presence of people, and other events. It tracks energy consumption, sends alerts, etc. There’s a strong focus on local control (as opposed to cloud). My favorite thing about it is that the client and server run from the same codebase and share state over a WebSocket connection. I’m still working on it occasionally but mainly it just runs quietly and my people seem to like it. The whole thing is configurable (connectivity, behavior and interface) so theoretically it could be used by someone else, but for many reasons I doubt it ever will :) reply burlingplane 26 minutes agoprevI've been incrementing on a Next.js app for three years now, which helps me tracks all sorts of things that used to be scattered across different apps. It holds stuff like: - A daily journal, plus a curated photo for each day that I can put on a calendar - Random habits I want to track, like how many cups of coffee I had, did I do my morning stretches, etc. - Fill-ups and mileage on my car, time to next oil change - Restaurants I've visited, plus ones I want to visit (I use the Google Places API to search for restaurants) - Books I've read/want to read - Movies/TV shows I've watched, and ones I want to watch (I use TMDB to pull in metadata about movies/shows). I also sync my watchlist from Letterboxd - Strength exercises I do, plus runs + bike rides that I pull in from the Strava API I used to use several proprietary apps to track these things (Letterboxd, Goodreads, etc), but it's great having them in one place, and with tight control over the database. It's amazing how useful it is to have a log of everything you've done to look back on. Even simple stuff like, last time I was at this restaurant was 2 years ago. What did I order and did I like it? reply octopoc 19 minutes agoparentThis hits close to home. I have something similar, except it's not as featureful and it's ridiculously purpose-built for me. E.g. I have one page in this app for generating PDFs of a very specific type that I need. I have another page that parses CSVs from my bank. These aren't tools I use regularly, I just need them occasionally, but they're all in one repo in one project. There are of course apps that do each of these, but when you start integrating them together, with their different ways of doing auth, different kinds of APIs, etc. things get so complicated. I worked in a company that integrated with some third parties and those integrations were easily 50% of the workload for the dev team and maybe 90% of the workload for support. There is so much effort being wasted on having different systems for different things. I feel like there's an idea out there that will solve all this for open source--maybe involving stitched GraphQL APIs, OIDC+JWT for auth, etc. Something kind of like Sandstorm[1] except with Sandstorm the different apps weren't necessarily built with Sandstorm in mind. In this system there would be a centralized identity management system like Keycloak that manages concepts like users, roles and apps, and everything else delegates auth to that centralized system. [1] https://sandstorm.io/ reply SimpleCaveman 30 minutes agoprevThe last thing I made exclusively for myself and nobody else was a shopping list calculator that added tax to the shopping list as a kid on my TI-83 graphing calculator. Programmed in Basic, and I would use it to add up the items going I to the shopping cart while my parents shopped at Sams club as a kid. And I'd tell them what the final total would be when we were standing in the checkout line. Very small and basic, but I thought it was the coolest thing in the world as an 11 year old back in 1996. reply makz 20 minutes agoprevI'm currently writing my own hashmap implementation. The goal is to make something small, simple, reliable, and that anybody can quickly integrate into their own projects. So far it has taken me around 40 hours and it's 95% done. reply ww520 2 hours agoprevLots of my software are for myself. To algorithmically generate wallpapers for my phones and computers, I hacked up a forth-like mini language running on GPU to make generative arts easier. Some samples https://news.ycombinator.com/item?id=40413433. To make recalling my web browsing easier, I built a browser extension that shows my browsing related information on one page. Pressing the shortcut key Alt-L brings up a page showing my frequently visited sites, my open tabs, my bookmarks, and my history visits. Searching and navigation are super easier. Searching can combine terms with logical operators. The hardest part of the project was getting fast performance when rendering a lot of data. I use this extension daily, and I put in some effort to polish it as a releasable software. https://chromewebstore.google.com/detail/one-page-favorites/... https://microsoftedge.microsoft.com/addons/detail/one-page-f... https://addons.mozilla.org/en-US/firefox/addon/one-page-favo... reply kredd 1 hour agoprevMade a simple app to put all my Apple Watch walks on the same map, so I can walk every street in my city. Surprisingly there wasn't anything available that was free or straightforward, despite it being an easy app to develop. Honestly, it's extremely fun to use something of your own every day, and patch it up when you come up with some other ideas. I did release it on AppStore (https://apps.apple.com/us/app/mapcut/id6478268682), but mostly for my friends so they can use it as well. reply WillAdams 47 minutes agoprevCouldn't find any CAM software which works as I want, so I've been working on implementing G-code and DXF export (so as to match tool movement) from OpenSCAD for a while now --- got a big boost when a Python-enabled version was made: https://pythonscad.org/ and now have a pretty much workable tool: https://github.com/WillAdams/gcodepreview (Re)wrote it using Literate Programming techniques, probably hundreds of hours (I've been at this for years and am not a particularly good programmer) and I use it on pretty much every project I make which isn't just drawing stuff in a Bézier curve drawing program. reply WoodenChair 1 hour agoprevYes, I run a daily hyper-local email newsletter that is custom built. It's called BTV Daily: https://btvdaily.com I wrote the newsletter generator in Python. It uses all kinds of different APIs (news, social media, MailChimp, scraping, weather, even some LLM for summarizing some of the news, etc.). It runs every day at 8 AM on a little server. It's not a super long script, but I've changed and refined it over the years many times. It's like I've spent many dozens of hours editing the samelike convert PDF bank statements into CSV transaction files I've tried this recently and it's surprisingly difficult. Any pro-tips? Extracting pdf tables, while respecting the cell position, seems almost impossible in a way that works in all cases (think borderless tables, whitespace cells, etc) reply linsomniac 1 hour agoprevI've been a huge proponent of ALWAYS writing software just for yourself. But I'm also a fan of releasing that software. I have a couple notable stories about that: I had a friend that wanted to scan his album cover, and I'd always wanted a scanner, so I bought one and wrote some command-line software to do it. Then I applied that as an extension to the venerable Xv image software. Wrote it entirely for myself, ended up selling something like a thousand copies of it. Recently, I was tired of Spotify so I wrote a Python program to export my playlists into YouTubeMusic. Released it on Github and it now is by far my most-starred project, I figure it's helped at least a thousand people move away from Spotify, I've had a bunch of contributions to it and have had several people throw money my way. Write for yourself, give to the world. reply racl101 3 hours agoprevIf you count a bunch of individual shell scripts for text processing then yeah. A bunch. I still use a lot of scripts I built like 15 years ago. Every now and then I make tiny changes but yeah I still use them a lot. I'd say 40% of the software I've ever built has been for me. I'd say it's a rite of passage to write software for yourself: 1) It gives new programmers some practice. 2) It can help you understand software development better. 3) It reinforces the concept of dogfooding what you create (even though in this case others won't get to use your software). Again, making you better developer. You'd be surprised how many people write programs that they barely use or test. Never really knowing how useful it is or isn't to others. reply Sancty 1 hour agoprevI got really into breathwork a few years ago. For the longest time I struggled to find an app that had anything more than basic functionality. Also, I found it absurd that most wanted to charge a subscription fee. I ended up creating my own application that lets me create advanced, multi-stage exercises. I spent time building the trimmings that I felt other applications were also lacking such as: background visuals with procedurally generated shaders, easy gestures, etc. I think one day I'll publish it to the app stores so other people who had similar desires have something. reply heuermh 1 hour agoprevAll the time! My most recent were tools to improve the AWS commandline experience for s3 and Athena https://github.com/heuermh/cooper https://github.com/heuermh/sea-eagle Both are available via Homebrew https://github.com/heuermh/homebrew-parquet-tools I would next like to improve the TUI experience for tabular data, e.g. using the Charm_ Bubbles/Gum table component, but I have yet to investigate how the JVMGo interaction might work. reply ryandrake 3 hours agoprevI made a macOS/iOS tournament clock for live poker games. I just wasn't happy with the few existing applications, so built and use my own. It is client/server so other people in the tournament can connect their devices and have the clock synchronized and shown on their own device, including phones and watches. It can also run dedicated/headless on Linux. I use a command line client to integration-test the networking and synching. I never released it because 1. it's perpetually 98% done and 2. I don't feel like offering technical support for it and dealing with people who don't like it or find bugs. I may just open source it, but then I get to be a maintainer which is an even more thankless job. reply owlglass 4 hours agoprevI wrote some PowerQuery functions and VBA macros to facilitate client invoicing that cut down ~2 hours of work to ~10 minutes (and shrinking, as I toy around with the scripts to delegate more of the work to the machine each time). The billing data is pulled from an external vendor's portal. The contact data is pulled from our internal CRM. Both sets of data are then cleaned up and merged with PowerQuery, and then VBA is used to send emails out to clients. I probably spent in the range of 3-4 hours getting a working version going and ~20 hours optimizing during downtime at work. I genuinely find it enjoyable to work on—there is something immensely satisfying about automating rote work away. I use this once per month (a billing cycle). It will probably never see the light of day for anyone else, at least in its current state, because I work in a low-tech, nonprofit environment and using this kind of tool would be daunting for my co-workers (for reference, mail merging is sometimes intimidating at my workplace). reply hiAndrewQuinn 4 hours agoprevBasically everything I have at https://github.com/hiAndrewQuinn at least started this way, before I polished it up for external use. But, no, if it really is meant for my own eyes only, it lives and dies as a shell script. reply sloaken 2 hours agoprevSeveral - My most recent was to manage dumbbell work outs. Problem: 1) I hated changing weights in the middle of a session 2) Wanted to manage progression Situation - I have 4 metal sets of dumbbell handles, a plastic set, some individual 3 - 5 pound pairs. A single, dial the weight dumbbell. Plates in metal range from 10 lbs to 0.25 lbs. The SW: 1) using SQLite for DB 2) One application to calculate optimum weight settings - typical run takes 100 to 200 tries to get the best set. 3) Another application to present / track sessions. It was a BIG timer display to ensure I do not do the workout too fast (goal is 45 sec a set) 4) A tracking report. Complexity issues: Not all dumbbell handles weigh the same - even the tightening nuts vary. Solution was to weigh everything and pair up the nuts so that each dumbbell handle with nuts matched its pair - oh I color coded the metal dumbbell handles. First algorithm took too long - my first version would calculate ALL combinations of all weights. Then select the optimal solution - before adding the 0.25, 0.5, 0.75 and 1 pound plates would take between 15 to 30 minutes to run. This was solved with a slightly more complex algorithm. I calculated the all combinations for each dumbbell. Merged those lists into a big list, Found the perfect setting for each exercise. Check for conflicts. When a conflict occurred, found the exercise with the least delta from optimal and changed it to the next weight setting.... Check for conflict. Now it takes no more than 20 sec and reports 100 to 200 times it hit conflict before solving. reply rsaarelm 2 hours agoprevIt's more \"nobody else is interested\" than \"it's not out in the open\", but I've made my own structured data format implemented as a Rust serializer https://github.com/rsaarelm/idm and am using it for a growing collection of command-line tools for managing personal notes written as outline files https://github.com/rsaarelm/idm-tools and to run a static site generator https://github.com/rsaarelm/blog-engine . I'm also writing a game that uses IDM as the data serialization format. Idea for the format was that you can write structured data with a really minimal syntax if you have an external type schema running the parsing, and the syntax emerged from the line-and-indentation based outline note files I'd started writing for myself. It took some months of work and planning and a couple rewrites to get the core IDM library working right. The tools and site generator were simple and straightforward in comparison. reply audiodude 2 hours agoprevI built a headless CMS to generate the static site, https://bestalbumsintheuniverse.com. The key feature is that you can put in a Wikidata ID (https://www.wikidata.org/wiki/Q1536639) and it will auto populate the name, artist, release date, and Spotify ID. It will then grab covert art from https://coverartarchive.org/, which it resizes and mirrors to S3 (previous versions of this project used images manually uploaded to imgur, but broke when they changed their secret API). So basically all I have to do is write the description and I've got a new entry on the site. reply codingdave 1 hour agoprevQuite a few, but the one that may be unique is a tool that scrapes the location data from an eBird list of rare birds sightings in my area and pops up a map for me, so I can see if any birds have been sighted near me that I don't already have on my personal birding list. It only took about 15 minutes to throw together into a bookmarklet, so it was a really low effort, but I use it daily. reply sawaali 1 hour agoprevI made a music app for iOS for myself, after not finding anything that did what I wanted as a non-streamer: visualization, audiobooks support, section loops, bookmarks, sleep timers, import from any source, etc. In the end, I did put it on the App Store (after months of cleanup!) but it's easily the most used app on my phone. reply cardamomo 1 hour agoprevI wrote a little Swaybar script that displays the current weather. When I hover over it, I can see the hourly forecast and a few other details. It's not perfect, but I prefer the simplicity over a fully-fledged application. reply kitallis 1 hour agoprevYes! The two most used ones in the past few years: WAP – a small utility to control my balcony-local drip irrigation system https://github.com/kitallis/WAP hisaab – expense tracking and categorizing because my bank doesn't do apis and sends credit card reports in PDFs https://github.com/nid90/hisaab-clj reply bengarney 3 hours agoprevI wrote a tool to do automated QA on internet video (HLS/DASH, tech used for Netflix, YouTube, Twitch, etc.). It evaluates streams against a database of 100 or so \"quirks\" that identify either general issues or issues that will only manifest on certain player libraries. For instance, specific \"in spec\" encodings which are actually non-standard in practice get flagged. Built on TypeScript/node/Docker over the course of maybe 18 months. Used it fairly often when I was working in the space, not at all these days. Originally the plan was to license it as an enterprise vid tool. (I've been considering open-sourcing it - would YOU use it if so?) reply xoxxala 3 hours agoprevI write little Python scripts (or use Excel) to simulate computer/video game mechanics and quickly iterate over them before passing them off to a real programmer. I also design boardgames, so often write die rollers to calculate probabilities (it's faster for me to write something that generates hundreds of thousands of results than to actually do the math, especially if I want to tweak in real time). My bad habit is not properly archiving these little programs, so I invariably end up recreating them from scratch each time. reply mmphosis 3 hours agoprevLots. They mostly perform automation, shortcuts: hotkeys, commands, scripts, aliases, functions, AutoKey, ... They've taken anywhere from years to minutes. The software gets used frequently or it gets deleted. For example: p will do cat (or hexdump or ...) or ls depending on file (type) or directory. Let me show you shebang which is just a memory aid: $ show shebang .../bin/shebang #!/usr/bin/env sh head -n1 \"$0\" reply ChrisMarshallNY 2 hours agoprevDepends. I have written a lot of software, but each one is done as a full-fat production library (most are SPM modules). They are of top-shelf Quality, and fully open to all. I'm my best (and only) customer, for most (if not all) of them. That's actually fine, with me. Publishing them, the way that I do, ensures they are \"fugheddaboudit\" quality, so I don't have to be worrying about my dependencies, and I reuse them, in lots of shipping stuff. You can find links to all of them, in a couple of the orgs I manage on GH: https://github.com/ChrisMarshallNY#here-on-github reply gwbas1c 2 hours agoprevI have a lot of DVD-Audio and BluRay audio disks that I rip to play in Kodi. I wrote a utility that scans through audio files to generate a list of track names, and script to encode images for each track into a video (without sound) to multiplex with the audio. Years ago, I wrote a .exe to change screen resolution, and then revert when closed. I used it when my old laptop had a composite out, and I would watch moves that I downloaded on a TV. A few years ago I wrote a grid-scale battery simulator, scraped some publicly-available cost of electricity data, and calculated how long it would take for grid-scale batteries to break even when buying and selling power to-from the grid. Short answer: About 18 months. Long answer: Permitting a power plant takes a few years, and the permitting process only recognizes buyers or sellers. The permitting process doesn't recognize \"storage\" yet. More recently, I wrote a quick-and-dirty utility to restart explorer.exe, because it has some really silly multi-monitor bugs that require restarting the process every once in awhile. reply xolox 3 hours agoprevOver the years I've built lots of small and large tools for personal use, some of them I'm still planning to release as open source \"one day\", others I have no intention of ever releasing. One of the biggest and most useful of those tools is a Django web interface that accepts JPG/PNG/PDF file uploads of scanned documents and in case of images (JPG/PNG) it will run \"tesseract\" to OCR extract text from the images (in case of PDF it will pdf2txt). The extracted text is stored in an SQLite database which enables keyword search in the uploaded documents. I use this as my (digital) archive of important documents, e.g. mortgage, bank statements, insurance, medical files, etc. I just checked and I now have 1129 documents in there ranging all the way back to 2006 . It's super useful to be able to go back in time digitally, without having to dive into the collection of physical binders with the real documents (ordered by year and month but nothing beyond that, given that there are usually only a handful of documents per month, and I can use the web interface as an index into the physical archive, if I ever need it). reply doubled112 3 hours agoparentI use paperless-ngx but the concept is the same. It is hard to understand how much easier this makes dealing with all of the paper in your life until you have it. reply smeej 2 hours agorootparentOnce a quarter, I scan all my accumulated paper with a similar setup and tag it all in Logseq. I almost never need the archived docs, but when I do, it's a breeze. reply arusahni 1 hour agoprevI wrote a series of scripts that parse song names from my music blog RSS feeds, match them against my music service of choice, and then build 200-track playlists for me to consume. It's a great way for me to eliminate some of the drudgery of music discovery, especially in niche fields. It's a series of Python scripts backed by SQLite and reverse-engineered API clients for various music services. Over the years I've switched the backends from Google Play Music/Youtube Music, to Apple Music, to Tidal. reply julianlam 1 hour agoprevMy blog (devnull.land) — I stood it up in a day or two, could run on a potato, and uses GitHub Gists as its data store. (More info: https://devnull.land/github-gist-blog) My VoIP provider supports SMS, and exposes an API. The community-made app wasn't performant enough, so I cobbled together my own interface in a couple evenings. Then one day some dependencies shifted and it wouldn't start on the latest Node :\\ Oh well. reply hdjY28 42 minutes agoprevI built a macOS app to securely encrypt my personal files. My password is converted to a key that’s used to decrypt files reply ceritium 26 minutes agoprevkeepthis.site its open, i did It for me, there are some signip but i think i am the only active user. Also consumebefore.jose.gr and a few small tools you can find on my blog. reply smokel 1 hour agoprevI've written a fully functional emulator for the Philips P2000T, my first true love [1]. As I still haven't found a way to legally ship it with a ROM (partially copyrighted by Microsoft), I'll keep it to myself. If anyone happens to know someone who knows someone at Microsoft willing to help me with this, please let me know. [1] https://en.wikipedia.org/wiki/Philips_P2000 reply RelentlessOpt 2 hours agoprevI wrote an app to analyze my Wordle play - I tell it my guesses (with the answer last) and it tells me how many possible answers were left after each turn, what the best next play was, and how my play compares to my current strategy. I use it every day. https://scottlouvau.github.io/pwa/wordle-analyze/ I wrote the code over a few months, along with code to find optimal guesses, simulate games, and do earlier versions of game analysis. It's written in Rust, originally as a console app, but now wrapped up with a very basic interface. I figured out how to get it running as a WebAssembly Progressive Web App so that I can use it on my iPad without connectivity and without having to submit to the App Store. reply piloto_ciego 1 hour agoprevI have a notepad I built in Python that I really like. I keep a running list of notes in it that’s always available by typing “notepad” into the command line. I have soil moisture sensors for my wife’s plants (and an air quality sensor) that’s generating a constant stream of sensor readings. I wrote my own OTA updating code for that because I was frustrated at having to plug in sensors to update the code. I have a few calculators too. reply piloto_ciego 1 hour agoparentOh I forgot, I’m building our own version of that Life360 app for my family. That code will likely never see the public light of day. reply qznc 4 hours agoprevThe static site generator for my website: http://beza1e1.tuxen.de/gen.py A news bot: https://github.com/qznc/mrktws-news (the output is public, does it count?) A TiddlyWiki server: https://github.com/qznc/tiddlywiki-py Such stuff usually costs me a few frantic evenings to build the first version and then minor maintenance. reply Leftium 3 hours agoprevI made an app for my brother's wedding so all invitees could easily upload and view photos in a shared slideshow (displayed in real-time on a big TV at the event). Dismantled as soon as the event was over. It took less than a day to create with SvelteKit, Dropbox, and https://slidesome.com Some more: - https://weather-sense.leftium.com: weather app with the trendcast just the way I like it. WIP, but already using it on daily basis. - https://multi-launch.leftium.com: quick link launcher; can launch multiple links at the same time. I use this multiple times a day. - https://tt.leftium.com: tool to streamline conversions I frequently need. When the input type is detected on paste the converted value is automatically put into the clipboard. Also paste works from anywhere on the page. A super-niche hidden feature is if I paste the outerHTML of my SoFi relay accounts list, it will transform it into a TSV format for pasting into a Google sheets balance sheet. I use it a few times a month. - https://ff.leftium.com: tool to calculate the time I needed to do something in a game I used to play. Automatically updated a calendar event with notifications. - https://orbs.leftium.com: another tool to help with planning in the game I used to play. reply pimlottc 3 hours agoparentYou made a marketing page for your one-off shared photo collection app? reply Leftium 2 hours agorootparentNo marketing was needed. The app was specifically made just for that single event. reply mayanraisins 2 hours agoprevI was upset with YouTube ads, so I made my own client. It is a Vue frontend that talks to a Supabase backend. The database has a list of channel IDs, and a serverless endpoint makes a request to the YouTube API to get a list of videos and returns them back to be displayed in a chronologically ordered list as embedded videos as to avoid ads. It could be configured for others to use, but I haven’t created a signup page, and I want to avoid YouTube API rate limiting, so I’m the only user now. It took me a day to make and I’ve used it daily for 3 years. reply undefined_user6 2 hours agoparentThis is genuinely cool, but, just curious, why not use an ad-blocker like uBlock? reply mayanraisins 2 hours agorootparentThanks! uBlock works great when I’m on the PC, but not so great on my iPhone unfortunately. I’ve tried running Pihole and AdGuard servers too, but they don’t do well against YouTube ads. The small additional benefit of having my own UI is that I’m not distracted by channels that I’m not subscribed to, and just presented with a chronological list of videos from the channels I want to follow. reply drewbuschhorn 3 hours agoprevI run a small Dwarf Fortress podcast, and I didn't like the transcription options when we started a few years ago, so I wrote some python glue to do diarization (separate out speakers) and transcription using a torchaudio project, and either whisper or openai depending on how I'm feeling that day. Works surprisingly well, with timestamps and clean-up: https://github.com/drewbuschhorn/a_strange_mood_podcast_tran... vs https://astrangemoodpodcast.com/2023/01/17/episode-1-is-dwar... reply FractalParadigm 2 hours agoprevNot necessarily my own use, but I built a few tools (that I volunteer free for use on a perpetual license) for my day job to make life a little easier in a few departments. Nothing impressive imho, they're mostly 'basic' calculators for various parts of the wiredraw process, from basic reduction-of-area to full-blown multi-pass die calculators (all fairly basic math and algorithms). In all honesty they're the kinds of semi-basic tools that the company should already have after >50 years of continuous operation, but stubborn blue-collar workplaces can be set in their old-fashioned ways, no matter how inefficient (honestly it's somewhat nice seeing others using and appreciating something I built). reply halotrope 4 hours agoprevYes many things actually. - A mac app to generate to read text as playlists from openai tts api (my gf can't use the api) - A automatic visual scraper that can get arbitray information from any website (e.g go to target and get the top 3 milk prices or get the licensing information from this opensource project) - An ETL tool (called tabmaster) that can sync arbitrary json apis into postgres tables. with automatic schema inference and deduplication logic - A really good OCR tool that enriches scanned PDFs with accurate words and not the bs that adobe ships all really useful and used daily. EDIT: formatting reply johnisgood 3 hours agoparent> A automatic visual scraper that can get arbitray information from any website (e.g go to target and get the top 3 milk prices or get the licensing information from this opensource project) Sounds interesting. How does this work exactly? How do I input that I want the top 3 milk prices, and how does it retrieve that data? reply halotrope 1 hour agorootparentit works with a llm/visual model and is integrated with a control for the browser. it works surprisingly well i might do a shown if its interesting for other people reply RBerenguel 2 hours agoprevWeave: https://github.com/rberenguel/weave It's hard to explain what it is. Think personal knowledge manager text editor inspired by Acme. The readme and video there are very outdated, I add features faster than I update that (as the only user this is what I get). I post videos of new features on twitter though, as a reminder to myself of where I passed through reply mutantgn0me 3 hours agoprevI've got a...very large...Bash script I wrote in 2009 for interacting with my MP3 collection via email and icecast (there were more reliable email clients than Web browsers embedded in devices back in the day.) It's basically a queue manager for ices(1), with playlists, \"programs\", special handling for audio books, and regular radio DJ-like chatter delivered via Swift (weather updates, track info, inside jokes among my friends, that sort of thing.) A cron job keeps it going with random tracks. I've even added some old 50s and 40s radio commercials because hilarious. It is madness in script form which will never see the light of day, but I've never succeeded in rewriting it or making a nice Web interface for it 'cause what I've got Just Works for me. I interact with this script almost every day, making it the single most-used software I've ever written, either professionally or personally. It's great having a self-hosted streaming service. Run via Bash. Mwuahahahaha. reply eternityforest 1 hour agoprevAt various times I've made apps for my own use. I tried a few times to do a DIY notes app. But I usually find that the hassle of having to maintain it at random times whenever some platform changes happens, or else not be able to use some important feature,vis just not worth it. reply utensil4778 4 hours agoprevSeveral years ago, I picked up an old SmartBoard projector. The thing has no buttons, it's meant to be plugged into a remote control module attached to the board, or controlled over serial as part of a room system, or through its Ethernet connection. I don't remember how I got started initially, there was some investigation of the network protocol it used. It was some crusty old standard that used an odd command scheme, but I managed to divine what magic packets to send to wake it up and select an input. I ended up rolling it all into my first and only Android app. It eventually became a full remote control for the thing, including a sleep timer that would turn it off after an hour. It was extremely basic and horribly ugly. I never looked into automatic discovery of the device on the network, so it had a hardcoded IP address. But it worked well enough to get a free projector running. Apart from that, every programmer has thrown together innumerable scripts and throwaway programs for one-off tasks. My most recent was a thing that takes in a Diablo 2 save, then sets the version number and recalculates the checksum. My pirated copy is a bit old and won't accept saves made with modern editors. I don't know how many scripts I've written that walk through a file system to find or change something in the contained files. I also have a version of Klondike solitaire written in C++ with SFML. I initially wanted to build a neural network to play solitaire, but after building the game itself, I found in my research that solitaire is actually a very difficult problem and far beyond my skills. reply philip1209 3 hours agoprevI run a little Rails app for myself. I end up putting some random things in it. Here's a partial list: - My blog mailing list (Sendy) was having a bot signup problem. I wanted to deploy a captcha, but the mailing list software didn't support it. So, I put a simple proxy that validates the captcha before inserting the record to the software. - Wanted a way to apply an email template to the Sendy mailing list, so I wrote a software that consumes my RSS feed, applies a template, and creates a draft in my mailing list software. - Wrote a \"Scoreboard\" that aggregates MRR across Stripe accounts into a graph, and sends auto-emails to friends when I cross thresholds. - Wrote a script that emails me when the HN \"whoishiring\" job goes live every month. (Simple crons like Zapier don't work) There are a few other things in there, too. reply shtack 4 hours agoprevI have a lot of examples but a funny one that comes to mind is: in the early 2000s when IM clients were all the rage, I wrote a VB6 application to go through my MSN Messenger logs and rank my friends by how much I talk to them. Kind of like a MySpace top 10 prior to MySpace. I spent a decent amount of time tweaking the UI, improving performance, adding filters, providing different file output formats, etc. Never shared it with anyone. reply WalterBright 1 hour agoprevI wrote a program \"syncdir\" that will synchronize two directories. I use it every day for making backups. I originally wrote it for DOS eons ago. reply pipes 1 hour agoparentThis reminds me of Microsoft's sync toy: https://en.m.wikipedia.org/wiki/SyncToy reply applesauce004 4 hours agoprevOh man. Do i have a list for you! I am very self-conscious of publishing my work. So over the years i have made many software games and utilities that will never be published. My wife thinks i am being silly and i shoud publish it. Anyway, here goes.... MP3Renamer(2002) - The age of music piracy is still rife and i have downloaded my share from napster, university file shares, etc. However, most filenames are horrendous and not clean. So, my first utility was a java program that would analyse file names based on common garbled patterns and rename it into [Artist] - [Songname].mp3. It worked surprisingly well for 90% of the use cases, CombatLogAnalyzer(2008) - Me and my wife are in the throes of World of Warcraft arena which is a competetive dueling system. We only play 2v2 and we both suck at it. So, i enabled combatlogs in WoW and then wrote a parser, analyser and visualizer for every arena game and that shows which spells were used, where did damage come up, highest contributer of damage and this was by each playable class. By the end, we learnt what was killing us and the statistics showed our strengths and weaknesses. Suffering high latency and poor skills we managed to crawl from 800 rating to 1800 rating! We just couldnt go beyond that! (I was the crutch). This was done in .NET WinForms and i really learnt how to use linq. Space Commander (2019) - My daughter is almost 4 years old and i think she is ready for computer games. I decide to learn MonoGame and i make a Space Commander clone. It is a HIT! HappyMrsChicken (2019) - From my smash hit game above, i make a clone of HappyMrsChicken except this is in a forest where you have corn that the chicken has to eat and there is competetion from a mysterious goblin creature who also goes after the corn. Who will win?? Turns out, i cheated and gave the chicken a boost. My daughter won a lot!! OptionsTrading (2020) - It is covid and i am locked in a quarantine facility for 28 days. Like a lot of retail noobs, we are getting into trading stocks and options. I decide IBKR interface sucks and I can do better. While spending those 28 days in isolation from family, i learn react to write a frontend and python to write a backend that displays all our trades, statistics, UIs, loss calculators, PnL, etc. My wife and I use this to date but i am too chicken-shit to publish it. My personal favourites are: CombatLogAnalyser, OptionsTrading and HappyMrsChicken in that order reply uptownfunk 32 minutes agoprevwhy does everyone make their own note taking app - is it easier to specify the app in code than to build an app that gives you what you want? reply mlfreeman 4 hours agoprevMany years ago I partially cloned the old iGoogle homepage because I liked it (and Google was killing it off). It's gone through a few experimental rewrites in various technologies for personal educational purposes. Right now, it's ASP.NET/.NET 8 on the backend and still plain jQuery on the frontend. I display RSS feeds, US National Weather Service data, and comics in it. I also have it send some things to friends and family as emails periodically. Hangfire works on the backend to actually fetch new data at appropriate intervals. I occasionally have to modify something and manually push a new build because something remote changes but it feels fairly stable right now (knock on wood). I want to redo it to use ASP.NET AssemblyParts and work towards essentially giving each little box its own DLL as a sort-of-plugin-system so that I feel more comfortable adding more types of boxes (stocks, different weather data, etc) and maybe one day can open-source it. (I'd like to so I can point prospective employers at it and say \"see, i can actually write reasonable real world code.\") reply croisillon 48 minutes agoprevmost software i created were made in a couple of weeks for mostly one person (with me dogfooding as mus as possible of course): - text format conversion for a former coworker - bookmarking for my sister - calendar & bank account \"manager\" for my gf - local weather log for my former boss reply osigurdson 1 hour agoprevI recently made a cli chatgpt interface. Quick hack in Rust, always planned to clean it up, not entirely sure where the source code is for it anymore but I use the compiled binary all the time. The regular chatgpt interface is nice but sometimes don't want to break out of the terminal. reply liamYC 1 hour agoparentDid you get ChatGPT to help you write this and is one of your main use cases generating bash commands? (Code writing code, there’s a total feedback loop happening here) I did too but wrote mine in Python. A compiled language would be much faster and using their streaming function I’m yet to implement. Any other ways you can increase the speed? reply osigurdson 1 hour agorootparentI don't think language would matter much as the primary delay is getting a response from OpenAI apis. The advantage of Rust (or other similar language) is you get a simple single executable. Otherwise Python is completely fine. I basically use this any time that I am in the terminal already and have a question that I think could reasonably be formatted fine there. I'd say, I use it for 30% (conservatively) of my ChatGpt queries. Naturally the web interface is way better for lots of stuff, but sometimes breaking out of a terminal session is jarring. reply RegW 3 hours agoprevA long time ago - may be 15 years ago, I got really bored of listening to an hour of drive-time news on the radio twice a day. I then discovered podcasts, so I bought an MP3 player and wired it through my car stereo. I found downloading podcasts manually a bit of a faff. So I wrote a bash/curl/xsd script to rattle through a list of RSS feeds, download new episodes and create a playlist. It ran on my laptop at home or work and plonked the result on my MP3 player via USB. Now, years later, the script is essentially the same. Except it runs under termux on my phone, and VLC broadcasts the playlist direct to my car or home stereo via bluetooth. reply jamesfinlayson 5 hours agoprevI've open-sourced most of my stuff, but one thing I haven't is a gambling simulator - I feed in odds and results for a season of sport and I can tune some parameters to try different strategies. Someone once told me that apparently some local sports reporters' weekly tips are used with some seed money and the proceeds are given to charity and I was intrigued enough to spend a few days building something that could test that out. reply KaiMagnus 3 hours agoprevI wanted to say my Figma plugins that I made for myself, but I published them so it doesn't count. When I was around 15 I wanted to try out Win Forms. I also used to play a lot of Dota 2 so I created this app to calculate how many Techies mines would to take down a hero with X HP. Complete with sliders, input field, radio buttons and checkboxes to select ability levels and items. Pretty sure it will never get published, but the .exe is still sitting on my desktop. https://liquipedia.net/dota2/Techies reply pridkett 4 hours agoprevI’ve got two great examples of this. Both I use to help control DNS on my local network. They’re open source, but I doubt anyone else is using it, and I’m fine with that. unifi-dns-scraper[0]: a simple tool that logs into my Unifi console to get all the hosts and then creates a hosts file that my local DNS servers can use. unifi-doh-blocker[1]: as part of my efforts to better control my network, I don’t want random devices ignoring my local DNS by using DoH. This gets various lists of public DNS over HTTPS servers and updates a blocklist on my Unifi Dream Machine Pro. With a few other firewall rules this essentially forces all my DNS through local servers which then do encrypted DNS queries to a third party DNS service. These tools make me happy and were fun to write. [0] https://github.com/pridkett/unifi-dns-scraper [1] https://github.com/pridkett/unifi-doh-blocker reply shred45 4 hours agoprevI built an OAuth proxy (only Auth0 currently works) hosted on Cloudflare workers. I'm a big fan of the self-hosted OAuth Proxy [1], but some projects don't lend themselves to hosting a container, sometimes you just want to set up a simple app on Heroku, Fly, Workers, etc. and have an auth proxy sit in front of it. My solution also manages SSL via Cloudflare and integrates with Stripe for simple fixed-price subscription billing models. The idea here is to be able to iterate on product ideas quickly without spending a day each time figuring out authentication and billing. I did set up a marketing site at the time so that others could use it, but I don't have any users, and I'm happy to maintain it just for my own projects (half a dozen now). It took me 2-3 weeks to make so on net I have probably not saved much time, but it really helps reduce the friction of launching things which I think is valuable. [1] - https://github.com/oauth2-proxy/oauth2-proxy reply vintagedave 3 hours agoprevI wrote a static site generator. It was the first \"real\" Python app I wrote (many files, classes, etc and actively using Python features.) The code is _terrible_ in the way that code can be when you're learning a language. You can definitely see the progress of understanding Python as you see the project develop. However, it's robust and is used to generate my site right now. It supports Markdown plus a custom template language to convert Markdown-plus-more documents into a website, which allows me to add footnotes, sidenotes, images with specific formatting, custom markers, etc. It has specific support for parsing English and splitting sentences, so each one is in their own span in the resulting HTML. This is used for specific typographic layout. reply cobodobo 2 hours agoprevI built fake iOS for my baby. Recreated most of the apps, phone, music, videos, notes, wallet, maps, etc.. but simple versions with giant icons. Also added a ton of 'soundboards' which are their own apps for things like animals, food, family, home. I have like 20+ apps in there now. reply silvanocerza 3 hours agoprevYup, it's a stupid tool in Rust to keep my soundbar alive. Turns out that JBL thought it's a good idea to completely cut sound when there's nothing playing and ramp it back up in a perceptible fraction of second so that you miss some part of whatever you're listening to. This is especially annoying when watching anything with people talking. Here's the code for anyone interested, it also contains a more thorough rant in the README.md. https://github.com/silvanocerza/orpheus reply airstrike 3 hours agoprevI wrote an app that takes all localized strings in an Xcode project, turns it into a json, batch translates it with the OpenAI API, validates the json, and then converts it back into a .xcstrings file that you can drop into your project. I was writing an app that I wanted to translate into X different languages, of which I only spoke a couple and not perfectly, and this was the solution. It turned out pretty good. I've considered putting a little bit more elbow grease and turning into a packaged product but I'm not sure if there's demand for it out there. reply ogisan 4 hours agoprevWhile not exactly software per-se, I created a system of multiple text files to manage todos, long term goals, and various reminders (eg, IOUs, deadlines, etc). This was inspired initially by Jeff Huang’s blog post [1] but then grew to a complex collection of different files. A problem I ran into was building an interface for displaying and editing these text files (each file has a different width and for some files I want to have different heights when editing them). Ultimately I settled on multiple vim tabs in a terminal window. Been using this for close to five years now and I couldn’t be happier with it. However, at this point the system of files (and the terminal “user interface”) is completely customized to my life and would likely never fit someone else’s requirements. [1] https://jeffhuang.com/productivity_text_file/ reply mstipetic 2 hours agoprevI got annoyed at all the invoice generators so I recently built my own in a weekend. I put the data in Airtable and a python script generates the pdfs using typst. Much more flexible than any of the solutions I found and it took me less to build it than the time i spent trying out the available solutions. reply k310 5 hours agoprevI did mostly scripting as in sysadmin work. No FT programming per se. I found no free optical design software that would run on Mac, so I coded something up to do some paraxial ray tracing ( maybe more, I'd have to dig up the code) and (this is the good part) draw lens diagrams from the specifications. Pretty simple, but it was fun to do. Very little available for Linux either. Physics and optics people want to have fun, too. Much of it was just parsing the input data. I do recall a design and/or analysis program written in Basic, but it wanted a particular basic interpreter, and I forgot if it had porting problems. Must have. I don't recall using the program. Oddest bit was something I did on my own for Sun flex office. I would get the list of scheduled occupants and their office choice and overlay that on a map of the office suite, for a \"who is where\" map. On a \"real\" work task, I learned how to write graphics commands in Illustrator 3 format. I may have used that on this project. But more generally, tacking the AI header code to the file made it va",
    "originSummary": [],
    "commentSummary": [
      "Users have created various software tools for personal use, ranging from productivity aids to complex automation systems.",
      "Examples include a job board crawler, hydroponic garden manager, personal note-taking app, and a Spotify playlist generator.",
      "These projects often aim to solve specific problems or enhance daily tasks, with some users planning to share their tools eventually."
    ],
    "points": 155,
    "commentCount": 312,
    "retryCount": 0,
    "time": 1720134610
  },
  {
    "id": 40878222,
    "title": "The Snapdragon X Elite's Adreno iGPU",
    "originLink": "https://chipsandcheese.com/2024/07/04/the-snapdragon-x-elites-adreno-igpu/",
    "originBody": "chipsandcheese.com Verifying you are human. This may take a few seconds. chipsandcheese.com 89e99b812899980f",
    "commentLink": "https://news.ycombinator.com/item?id=40878222",
    "commentBody": "The Snapdragon X Elite's Adreno iGPU (chipsandcheese.com)150 points by pella 21 hours agohidepastfavorite58 comments dagmx 20 hours agoIt’s been interesting seeing the difference in architecture play out in benchmarks. For context, there was a lot of hullabaloo a while ago when the Adreno 730 was posting super impressive benchmarks, outpacing Apple’s GPU and putting up a good fight against AMD and NVIDIA’s lower/mid range cards. Since then, with the Snapdragon X, there’s been a bit of a deflation which has shown the lead flip dramatically when targeting more modern graphics loads. The Adreno now ranks behind the others when it comes to benchmarks that reflect desktop gaming, including being behind Apple’s GPU. It’ll be interesting to see how Qualcomm moves forward with newer GPU architectures. Whether they’ll sacrifice their mobile lead in the pursuit of gaining ground for higher end gaming. reply chaorace 1 hour agoparentI'm not surprised the Adreno numbers didn't hold up as well as the rest of the Snapdragon benchmarks. Back in 2013 the Dolphin team blogged about their terrible experiences with the Adreno drivers and vendor support[1]. Ten years later in 2023, the same team blogged about how those same continuing issues led them to completely replace the official Adreno driver with a userland alternative[2]. As it stands today, the only credible names in ARM SOC GPUs seem to be Apple (M chips) & Nvidia (Tegra chips). [1]: https://dolphin-emu.org/blog/2013/09/26/dolphin-emulator-and... [2]: https://dolphin-emu.org/blog/2023/08/13/dolphin-progress-rep... Kudos to the Dolphin website developers for keeping 10+ years of blogs & hyperlinks fully functional and properly tagged. They always produce great reading material! reply eropple 31 minutes agorootparent> As it stands today, the only credible names in ARM SOC GPUs seem to be Apple (M chips) & Nvidia (Tegra chips). I've been out of this space for years, so my knowledge is definitely stale, but have Mali GPUs fallen out? reply segasaturn 16 minutes agoparentprevIs there any reason why these ARM iGPUs are so much worse than iGPUs from Intel and AMD? My 11th gen Intel CPU's Xe graphics completely outpaces my M1 Mac's and something like a Ryzen 5 5600G destroys both. reply swatcoder 19 hours agoparentprev> Whether they’ll sacrifice their mobile lead in the pursuit of gaining ground for higher end gaming. It's hard to imagine why they'd distract themselves with that, except perhaps with a token small-run demo for pure brand marketing purposes. Because of Apple's strict vertical integration, there's so much market for them as the de facto manufacturer delivering parts to pretty much every competitor making products that want a high performance/power ratio. reply dagmx 19 hours agorootparentWell it depends which space they want to be taken seriously in. Currently the 741 is very poor when compared to any dGPU or Apple. It only favourably compares to iGPUs. I believe they have three options 1. Say it’s meant to be like an iGPU, and work on supporting dGPUs to complement it. 2. Say that they want to compete with dGPUs/Apple and risk losing their mobile crown. Which is what Apple did in exchange for one design across all products. 3. Say they want to have a split product portfolio. A more desktop focused GPU for Snapdragon X with a more mobile centric one for 8xx reply silisili 18 hours agorootparentI think it's going to be 3, but a split between mobile and laptop/desktop without any concern for competing with dGPUs. It makes no sense at all for them to. If they can give good enough, on par or better with current iGPUs, with a lower power usage and potentially even fanless, they're going to sell a billion of them. They'll be in every Chromebook in the world. reply pjmlp 8 hours agorootparentChromebooks are basically the US school systems, Google employees, and little else. reply hypercube33 16 hours agorootparentprevThey aren't gunning for Chromebook deployments...these are currently in business laptop models and AMD may have already beaten them in all fronts on some of these per dollar other than ultralight and video playback duration. Lenovo has a A model that can do 16 hours and light gaming. more importantly it runs x86 apps full speed. I agree these likely will take over the sub $1000 market if given the chance but they are shooting at $1500-2000 reply silisili 14 hours agorootparentInteresting. Seems like a huge missed opportunity there, as those outsell everything else by quite a margin. Perhaps they'll expand into both ends like they do phones, eg the 4xx on the low end and 8xx on the high end. reply RussianCow 11 hours agorootparentPresumably the margins on Chromebook are terrible compared to those of mid to high end laptops. I don't blame them for wanting to start with the higher margin market and eventually work down. reply dagmx 14 hours agorootparentprevThey aren’t fighting for Chromebook territory with this though. All their comparisons are to the MacBook Air and mid-high end windows laptops because that’s the market they’re gunning for. These are meant to be $1k-2k devices. reply HeWhoLurksLate 1 hour agorootparentprevIIRC, on the LTT video on the topic they mentioned that there were like 8 extra PCIe lanes that could theoretically get run to a dGPU reply benreesman 16 hours agorootparentprevI grew up in San Diego and at the time being involved with technology meant living in Qualcomm’s shadow in one way or another. So I tend to agree that being the reference mobile SoC vendor outside of Cupertino is pretty on brand for their absolute top priority. At Qualcomm if it doesn’t make dollars it doesn’t make sense as we used to say. And good for them! After a brief flirtation with the idea of becoming a pure play CDMA patent troll they seem to have gotten back to their roots and started doing engineering again. It’s a cool company. reply InDubioProRubio 6 hours agorootparentprevI think there is a market for a dual-world architecture, with loads of dark silicon in a low battery setting (and suffering performance being acceptable) and a high power mode, that is able to compete with regular desktop gpu architectures. reply a-dub 12 hours agorootparentprev> It's hard to imagine why they'd distract themselves with that, except perhaps with a token small-run demo for pure brand marketing purposes. haven't google and samsung started making their own socs? reply djmips 12 hours agoparentprevThe Mobile lead and gaining ground for higher end gaming are aligned in many areas so you have to do both. reply hajile 5 hours agorootparentHALF of X1's compute is F16 only which is absolutely wasted silicon for most desktop games. Their entire tiling setup is great for simple mobile games, but (as shown in the article) is also an inefficient approach for desktop games. 64-wide SIMD works well in simple games and offers a FAR better theoretical compute per area, but when things get more complex, it's hard to keep everything filled. This is why Intel is 8-wide, Nvidia is 32-wide, and AMD is 32/32x2/64-wide (and is one reason why the second SIMD didn't improve performance like the theoretical flops said it should). With the release of the M-series chips, Apple's GPUs stopped ramping up performance as quickly on the simple mobile benchmarks. This is very clear with A17 in Aztec not only falling behind the SD8gen3, but the SD8gen2 too. At the same time, GPU perf/watt has also lagged behind. However, when you switch to something like the somewhat more complex Solar Bay, the Apple GPU pulls ahead. This is similar to the AMD/Nvidia swap from gaming to hard compute then slowly back to gaming after they split into server and gaming designs. reply dagmx 12 hours agorootparentprevIn some areas sure, but it’s really down to what you’re dedicating silicon to in terms of capabilities. reply jayd16 11 hours agorootparentHow so? I'm fairly confused about what you're implying. Is Apple sacrificing mobile capabilities for better desktop capability, for example? reply dagmx 5 hours agorootparentYes. Assuming that a GPU size and node is similar between different GPUs, then different features which require silicon do it at the expense of other features. It’s always a balancing act. That’s effectively the big rub between NVIDIA and AMD today with raytracing + tensor support vs pure raster+compute throughput. Apple just went through a major GPU architecture change [1]. They focused a ton on maximizing for AAA game usage and followed the NVIDIA route to bias towards where they think things are going. At least according to the simplified architecture diagrams for both Apple graphics and Adreno, Apple has more raytracing silicon than Adreno. It also supports stuff that doesn’t require silicon but does have effects on GPU design like mesh shading or their new dynamic caching that improves occupancy for high draw count games with large uber shaders. Compared to Adreno that focused more on raw triangle throughput instead, but doesn’t scale as well with complexity. It performs much better on mobile benchmarks that fit that usage pattern, but falls behind with desktop benchmarks that follow Apple’s priorities. [1] https://developer.apple.com/videos/play/tech-talks/111375 reply jayd16 1 hour agorootparentI think the tail is wagging the dog here. Those mobile workloads are tuned towards what currently works. If Apple or Qualcomm pull off desktop features in a mobile power envelope then the industry would happily adjust. reply LegitShady 12 hours agoparentprevTo me it seems as if the selling points of these latest snapdragon chips is high efficiency/battery life and competitive performance, so given the efficiency angle it makes less sense to try to make gaming machines out of them right now. Maybe in the future there will be a gaming oriented snapdragon less concerned about battery life. reply benreesman 16 hours agoprev“In Adreno tradition, Adreno X1’s first level cache is a dedicated texture cache. Compute accesses bypass the L1 and go to the next level in the cache hierarchy. It’s quite different from current AMD, Nvidia, and Intel GPU architectures, which have a general purpose first level cache with significant capacity. On prior Adreno generations, the GPU-wide L2 cache would have to absorb all compute accesses. Adreno X1 takes some pressure off the L2 by adding 128 KB cluster caches.” People have been tinkering with L1 cache conditionality since the L1i and L1d split in 1976 but the Qualcomm people are going hard on this and the jury seems out how it’s going to play. The line between the L1 and the register file has been getting blurrier every year for over a decade and I increasingly have a heuristic around paying the most attention to L2 behavior until the profiles are in but I’m admittedly engaging in alchemy. Can any serious chip people as opposed to an enthusiastic novice like myself weigh in on how the thinking is shaping up WRT this? reply rys 10 hours agoparentIn practice, what gets labelled as the L1 cache in a GPU marketing diagram or 3rd party analysis might well not be that first level of a strict cache hierarchy. That means it’s hard to do any kind of cross-vendor or cross-architecture comparison about what they are or how they work. They’re highly implementation dependent. In the GPUs I work on, there’s not really a blurred line between the actual L1 and the register file. There’s not even just one register file. Sometimes you also get an L3! These kinds of implementation specific details are where GPUs find a lot of their PPA today, but they’re (arguably sadly) usually quite opaque to the programmer or enthusiastic architecture analyst. reply pjmlp 10 hours agoprev> DirectX 12 Ultimate: Disabled That right there is already a reason not to buy this in 2024. DirectX 12 Ultimate is 4 years old by now, and with DirectX 12 the best it can do is a 10 years old 3D API. This is basically a GPU for Office work. reply cubefox 10 hours agoparentMost games still don't use DX12 Ultimate features. Some use some ray tracing, but as the article says, this is expensive and should be left off for laptop devices anyway. As for mesh shaders, there is currently one (1) game I know of that uses them. Alan Wake part 2. I think the other features like sampler feedback are also not really used in practice. reply pjmlp 9 hours agorootparentYeah, but I don't buy hardware for what I can do today with technology from years ago, rather for something that lasts 5 to 10 years. reply talldayo 1 hour agorootparentIf it supports Vulkan 1.2, then it basically supports most of DX12 as well. Very famously Intel's ARC GPUs had terrible DirectX drivers, but good enough Vulkan support that DXVK simply ran better: https://youtu.be/wktbj1dBPFY As time goes on it feels like native and up-to-date DirectX drivers aren't necessary, even on Windows itself. The era of kowtowing to a d3d9.dll is over; the SPIR-V recompilation era has begun. reply Synaesthesia 7 hours agorootparentprevDepends on what you want to do. This GPU is impressive for a thin and light laptop with long battery life. It obviously doesn't compare well to large power hungry dedicated GPUs. reply pjmlp 6 hours agorootparentAs mentioned on my original comment, > This is basically a GPU for Office work. reply cubefox 1 hour agorootparentBut why would anyone need a GPU that can run Baldur's Gate 3 for office work... reply pjmlp 1 hour agorootparentThat is why this is the only thing this GPU is good for. reply theandrewbailey 3 hours agoparentprevDirectX 12 not ultimate still supports most (every?) every game out there. As for \"GPU for office work\", that's a question left up to specific in-game benchmarks. reply gary_0 19 hours agoprevRe: the manual driver updates. Recently I put a clean Win11 install on an ASUS Meteor Lake laptop for someone, and Windows downloaded and installed all the latest drivers automatically (along with a bunch of fresh bloatware, natch). Maybe Qualcomm is working with Microsoft so their drivers will get updated the same way? reply LegitShady 12 hours agoparentI assume they are given the launch of snapdragon copilot laptops, and your witnessing it get drivers from windows update. reply daviddever23box 8 hours agorootparentYes - and it is certainly possible to export the \"final\", up-to-date set of drivers via DISM, then build an orthogonal set that you can recursively install via a single one-click pnputil batch file in Audit Mode (Ctrl-Shift-F3 at the top of OOBE). This is the easiest way to validate benchmarks across neutral, bloatware-free OS versions (at least the ones supported by that SoC, anyway). reply jeroenhd 11 hours agoprevI wonder if there's performance being left on the table because of the way programs and games are designed. It's no secret Qualcomm's mobile chips will run like shit when you try to use desktop code on them, because they're designed differently. I wonder if we're seeing aspects of that here. It would explain why Qualcomm convinced their press team of impressive numbers that nobody in the real world has been able to replicate. There was a whole comic about design differences when porting desktop style games qnd shaders to mobile (I can't find it for the life of me) which was a pretty good beginner's guide to porting that stuck with me. reply mandarax8 11 hours agoparent> There was a whole comic about design differences when porting desktop style games qnd shaders to mobile This one from arm? https://interactive.arm.com/story/the-arm-manga-guide-to-the... reply jeroenhd 8 hours agorootparentThat's the one! Guess it came directly from ARM, no wonder I couldn't find it. reply mirsadm 13 hours agoprevWith my own use case I've noticed very poor compute shader performance on the Snapdragon GPUs. Even worse the drivers are completely unpredictable. The same shader will sometimes run 2x slower for seemingly no good reason at all. I didn't realise games these days relied so much on compute shaders. It's no suprise it doesn't perform as well as it should. reply bhouston 8 hours agoprevNice! What are the comparisons with Apple’s you in the latest M-series chips? reply rubymamis 12 hours agoprevWhy is there no comparison with Apple's iGPU? reply elabajaba 35 minutes agoparentA lot of their testing is running custom OpenCL and Vulkan code, both of which are essentially unsupported on macOS (moltenvk exists, but kinda sucks and adds overhead that would make the comparisons invalid anyways). reply nomercy400 10 hours agoparentprevBecause you cannot compare between an Apple's iGPU and this chip, while using the same software stack. Because you cannot buy a laptop with this chip and use MacOS. If they would compare it iwth an Apple iGPU, they'd be comparing two things: the hardware AND the OS, which makes it less clear what is contributing to your benckmark results. reply zozbot234 8 hours agorootparent> Because you cannot compare between an Apple's iGPU and this chip, while using the same software stack. Apple Silicon hardware can run Linux (with unofficial GPU support as of late, although still lacking support for the NPU), and official support for Linux on Snapdragon laptop platforms is supposedly in the works. So we should be able to do a proper comparison as soon as official support is added for both platforms as part of a single mainline kernel release. reply nuccy 9 hours agorootparentprevGenerally this is a correct argument - to compare hardware one needs to use the same OS/software stack. But the argument works the other way around also, if there is no identical software stack possible does it really matter how raw hardware compares? The end user running a game or an application would experience hardware+OS rather than just hardware. reply criddell 7 hours agoparentprevIf I had to bet, I would say it's because they don't beat Apple. If they had a benchmark result that showed a big win over Apple's design, it would be at the top row of the chart. reply luyu_wu 4 hours agoparentprevThis is a hardware deepdive by a couple of uni students and enthusiasts... Some people are interested in things that aren't as shallow as fluctuating performance leads ! reply mbs159 9 hours agoparentprevThey would have to run the same software, e.g. install Linux on both machines. reply perdomon 15 hours agoprevHow soon can I buy a handheld console with one of these inside, and can it run God of War? reply izacus 12 hours agoparentThere's plenty of consoles using AMD SoCs that perform better than this and run God of War. Get one of those. reply 3abiton 14 hours agoparentprevApparently the Minisforum V3 is aiming for that market. Although not super great on battery autonomy. reply jauntywundrkind 13 hours agoprevARM remains a shitty backwater of unsupportable crap ass nonsense being thrown over the wall. Qualcomm bought Imageon from AMD in 2009. Sure, they've done some work, made some things somewhat better. But hearing that the graphics architecture is woefully out of date, with terrible compute performance is ghastly unsurprisingly. Trying to see thing thing run games is going to be a sad sad sad story. And that's only 50% the translation layers (which would be amazing if this were Linux and not a Windows or Android device). reply smusamashah 19 hours agoprev [–] That's a mouthful of a name reply dagmx 19 hours agoparent [–] Not really any more than any other brand. The Intel Meteor Lake Arc iGPU The AMD Ryzen Radeon iGPU Apple are pretty much the only major SoC company who don’t brand the CPU and GPU independently reply bigyikes 17 hours agorootparent [–] “Ultimately, it comes down to taste.” - Steve Jobs reply pmontra 9 hours agorootparent [–] Apple build GPUs for their own hardware and nothing else. They could even do without names, it's just another inevitable component that's inside the box. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The Snapdragon X Elite's Adreno iGPU initially outperformed mid-range GPUs from Apple, AMD, and NVIDIA in benchmarks but now struggles with modern graphics loads, including desktop gaming.",
      "Qualcomm faces a strategic decision between maintaining its dominance in mobile graphics or pursuing higher-end gaming performance, with persistent issues in Adreno drivers noted by the Dolphin team.",
      "ARM SOC (System on Chip) GPUs from Apple and NVIDIA remain strong, while Intel and AMD integrated GPUs (iGPUs) outperform ARM counterparts, indicating Qualcomm's need to balance mobile and desktop GPU performance without directly competing with discrete GPUs (dGPUs)."
    ],
    "points": 150,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1720128782
  },
  {
    "id": 40879541,
    "title": "Moving to a RTOS on the RP2040",
    "originLink": "https://blog.brixit.nl/moving-to-a-rtos-on-the-rp2040/",
    "originBody": "Electronics Moving to a RTOS on the RP2040 As projects get more complicated the tooling has to improve. Outgrowing the arduino-ide is easy on the Pi Pico with the excelent pico-sdk but what if things get even more complicated... Martijn Braam I do computer stuff More posts by Martijn Braam Martijn Braam 2024-05-06 15:58:55.483807 I've been working on a bunch of small projects involving microcontrollers. Currently a lot of them are based around the Raspberry Pi Pico boards because I like the development experience of those a lot. They have a decent SDK and cheap hardware to get started and the debugger works with gdb/openocd so it just integrates in all IDEs that support that. One of my current projects is making a fancy hardware controller for a bunch of video equipment I use. The main things that will be controlled are two PTZ cameras (those are cameras that have motors to move them). One stationary camera and the video switching equipment that that's hooked up to. Currently the control of the control of the PTZ cameras is done with an unbranded panel that looks suspiciously like the Marshall VS-PTC-200: (Image from marshall-usa.com) The performance of this controller is simply not very great, especially for the price. It was a €650 device several years ago and for that money it has very annoying squishy buttons and the cheapest analog joystick you could find. Most of the buttons are also not functional with the cameras in use since this seems to be optimized for security cameras. This connects to the cameras over an RS-485 bus. The second thing I want my panel to do is very basic ATEM video switcher control. Currently that's fully done using the software panel on the computer because the panels from Blackmagic Design are very expensive. There's a tiny cheaper one now though. (from blackmagicdesign.com) After a bit of designing I figured the most minimal design I can get away with is 9 buttons, the joystick and a display for the user interface. The hardware design has gone through several iterations over the last year but I now have some PCBs with the 9 RGB buttons on it, the $10 joystick that was also in the Marshall-clone panel and to interface with the outside world it has the TP8485E to communicate with the cameras over RS-485 and a Wiznet W5500 module to communicate with the video switcher over ethernet. This includes a bunch of \"oops-the-wrong-pinout\" fixes... After a lot of fixing of the board I had made I now have all the hardware parts functional, but the difficult part of this project is the software. Initial software I first started creating the software like I do all the RP2040 based projects. A cmake project that pulls in the pico-sdk. To make anything work at all I dedicated the second core of the pico to dealing with the Wiznet module and the first core then handles all the user interface I/O. This worked fine to blink some leds and I did implement a DHCP client that ran on the second core. It did make implementing the rest of the system a lot more complicated. There's simply a lot of things that need to happen at once: Draw an user interface on the display that's somewhat smooth Send out VISCA commands over the RS-485 interface Respond to button presses Keep the entire network stack alive with multiple connections There's a bunch of things that need to happen on the network, the first of which is some actually standards complicant DHCP support. This would require keeping track of the expire times and occasionally talk to the DHCP server to keep the lease active. The second background task is making mDNS work. The ATEM video switcher IP can be autodiscovered using DNS-SD and it would be great to also announce the existence of the control panel. The ATEM protocol itself is also one of the harder parts to get right, the protocol itself is pretty simple but it does involve sometimes receiving a lot of data that exceeds the buffer size of the Wiznet module and the protocol has a very low timeout for disconnection for when you stop sending UDP datagrams to the ATEM. This all made me decide that it's probably better to switch to an RTOS for this project. FreeRTOS The first project I've looked into is FreeRTOS. This is technically already bundled inside the pico-sdk but all tutorials I've found for this download a fresh copy anyway so that's what I did. FreeRTOS seems to be the simplest RTOS I've looked at from this list, the main thing it provides is the RTOS scheduler and some communication between tasks. The simplest way I can show it is with some code: #include \"FreeRTOS.h\" TaskHandle_t button_task = NULL; TaskHandle_t led_task = NULL; QueueHandle_t led_queue = NULL; void buttonTask(void *param) { while (1) { bool state = get_button_pressed(); xQueueSend(led_queue, &state, 0); } } void ledTask(void *param) { while (1) { bool state; if(xQueueReceive(led_queue, &state, portMAX_DELAY)) { gpio_put(LED_PIN, state); } } } int main() { xTaskCreate(buttonTask, \"Button\", 128, NULL, 2, &button_task); xTaskCreate(ledTask, \"Led\", 128, NULL, 2, &led_task); vTaskStartScheduler(); // Code will never reach here return 0; } Both the buttonTask and the ledTask function will seem to run in parallel and there's a few IPC systems to move data between the various tasks. The code above is not functional but I stripped it down to get the general usage across. I've used this for a few days to make an enormous mess of my codebase. I have created several tasks in my test project: The buttonsTask that polls the i2c gpio expander to check if buttons have been pressed and then put a message on the button queue. The ledTask that sets the right RGB color on the right button by putting a message on the ledQueue; The mainTask that runs the main loop of the project that updates the state based on the button presses. The networkTask that communicates with the Wiznet module. The dhcpTask that is spawned by the networkTask when a network cable is plugged in. The mdnsTask that is spawned by the dhcpTask once an ip address is aquired. the atemTask that is spawned by the mdnsTask when it gets a response from an ATEM device. the viscaTask that does nothing but should send data out the RS-485 port. This is a lot of tasks and the hardware doesn't even do anything yet except appear on the network. I ran into a few issues with FreeRTOS. The main annoying one is that printf simply caused things to hang every single time which makes debugging very hard. Sure the gdb debugger works but it's not neat for dumping out DHCP traffic for example. The FreeRTOS also doesn't seem to provide any hardware abstraction at all which means all the code I wrote to communicate with the various chips is not easily re-used. After a few days I created a new clean FreeRTOS project and started porting the various functionalities from the previous version over to try to get a cleaner and more manageable codebase but ended up giving up because blind debugging because there's no serial output is quite annoying. I decided to look what the alternatives have to offer. Apache NuttX Another seemingly popular RTOS is NuttX. This project seems a lot closer to what you'd expect from a regular operating system. It makes your microcontroller look like an unix system. First thing the tutorial tells me to do is fetching the pico-sdk and set the environment variable. No problem, I already have the sdk in /usr/share and that environment variable already exists on my system. Suprisingly this made the build fail because NuttX decides that it really needs to overwrite the version.h file in my pico-sdk for which it doesn't have permissions... why... After doing the initial setup of building a minimal NuttX firmware for my board I connected to the serial port and was greeted by an actual shell. nsh> uptime 00:01:34 up 0:01, load average: 0.00, 0.00, 0.00 nsh> uname NuttX nsh> uname -a NuttX 12.5.1 9d6e2b97fb May 6 2024 15:18:54 arm raspberrypi-pico It looks like I'd just be able to write an app for this operating system and have it auto-launch on boot. Since this tries to do the Unix thing it also has a filesystem of course so the hardware has FS abstractions like /dev/i2c0 and /dev/adc0. One thing I liked a lot was that it's build around menuconfig/Kconfig which I'm already used to for Linux development. This also means there's an actual hardware driver system and the GPIO expander chip I've used for the buttons already had a driver. The menuconfig system also allows me to configure the pin muxing of the rp2040 chip so I don't have to keep constants around with pin numbers and do a bunch of hardware setup to make my i2c bus work. I can just go into the menuconfig and tell it that i2c0 of the pico is used and that it's on two specific pins. I've also enabled the i2c testing utility as one of the apps that will be build into the firmware. nsh> i2c dev 0 79 0 1 2 3 4 5 6 7 8 9 a b c d e f 00: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- 70: -- -- -- -- -- -- -- -- -- -- nsh> Well uuuuh... yup the basics aren't working. I've spend a bit of time going through the rp2040 setup code and the various i2c related menuconfig options but it seems like this just doesn't really work... I also have not figured out yet how I can tell NuttX that my gpio buttons are behind the gpio extender, or how to actually link the gpio extender to my non-functional i2c bus. Another thing that annoyed me is that I had to re-clone the nuttx repository multiple times simply because sometimes one of the configure.sh commands would fail which would leave the repository in an inconsistent state and the distclean command wouldn't work because the repository was in an inconsistent state. Really the classic \"configure.sh: you are already configured; distclean: you are not configured yet\" Unix-like seems great at first glance, but I don't really want to deal with filesystem paths on a microcontroller for a pretend filesystem. I also don't need a shell in my production system, it should just run my code. Zephyr So next on the list is Zephyr. This provides a python utility to set up a project which should make things a bit easier, or it's a sign something is terribly overcomplicated. The very first thing this project does is pull in 5GB of git repositories which includes the entire HAL library for every chip under the sun. The second thing it does is for some reason mess with my user-wide cmake stuff on my system. After that the tutorial told me to install the Zephyr SDK: The Zephyr Software Development Kit (SDK) contains toolchains for each of Zephyr’s supported architectures, which include a compiler, assembler, linker and other programs required to build Zephyr applications. It also contains additional host tools, such as custom QEMU and OpenOCD builds that are used to emulate, flash and debug Zephyr applications. Yeah no thanks, I have already several perfectly fine ARM toolchains and I don't really want to either build or fetch precompiled compilers for every architecture Zephyr supports, lets see if I can get away with not installing this. After some messing around I figured out how to get away with it. There need to be two command line options set for cross compiling: $ export ZEPHYR_TOOLCHAIN_VARIANT=cross-compile $ export CROSS_COMPILE=/usr/bin/arm-none-eabi- $ west build -p always -b sparkfun_pro_micro_rp2040 samples/basic/blinky One thing I also found out is that the Raspberry Pi Pico is not actually supported, only other boards that have the same SoC. No worries, these boards are practically the same. The very second issue I hit is that the blinky demo doesn't build because it requires led0 to be defined to have something to blink. It turns out the Sparkfun pro Micro RP2040 does not actually have a simple gpio led to blink but a ws2812B adressable led. So I started following the custom board manual which told me to copy a random other board because that's how it always goes. Maybe if you already have a meta tool to set-up a project make it create this scaffolding. In the end I did not manage to build for my board because it simply wouldn't start to exist after fixing all the errors and warnings in the build. Conclusion Well at least with FreeRTOS I managed to building some of my own application. I guess I have to follow the online instructions of replacing printf with another printf implementation and make sure to call the different function everywhere. I'll probably continue on trying to get FreeRTOS to do the things I want since it's the only one that can be simply integrated in your own environment instead of the other way around.",
    "commentLink": "https://news.ycombinator.com/item?id=40879541",
    "commentBody": "Moving to a RTOS on the RP2040 (brixit.nl)149 points by lupyuen 16 hours agohidepastfavorite85 comments DannyBee 10 hours agoThis author seems like they are expecting an RTOS to be the same as Arduino environment, or at least, susceptible to just hacking around and hoping it works. Most are not. Given a lot of Arduino these days have mbed or freertos under the covers, with some way to expose it, that may have been a better route for the author's style. Zephyr is easy to use (Clion also has good support for it), but like, you can't just choose not to install the toolchain and expect it to all work. It also definitely supports the Pi Pico - i've used it on it before, no issues. A simpler rundown of these RTOSen would be: 1. FreeRTOS - supported by roughly everything, but drivers and such are mostly per-SOC/device, which is a pain in the ass. The APIs are not very user friendly, but you get used to it. To give a sense of level - if you wanted to use bluetooth with FreeRTOS, you get to find your own stack. 2. Zephyr - supports real hardware abstractions and supports most SOC. You may have to do a little board work. If you wanted to use bluetooth with Zephyr, it has a bluetooth stack you can use, you may have to add a little support for your HCI. 3. NuttX - not great support, but very cool if you can get it working - not really highly supported by industry yet. I never got far enough into NuttX to try bluetooth in NuttX. There is also mbed, but we'll skip it. In practice, people in the RTOS world will usually go with what the SOC vendor supports. So if you are using Nordic stuff, you are probably on Zephyr. If you are using NXP stuff, probably FreeRTOS, etc. That is how they get good support. reply bborud 7 hours agoparentQuick question: do you develop for prototyping boards or do you write firmware for OEM devices? I have never encountered a single project where we had to do firmware for an OEM device where developers didn't struggle with Zephyr. Not once. Nor have I actually met any of those mythical developers that do actual firmware work on shipping products who think Zephyr hardware abstractions actually help. I'm not denying they exist. I just haven't encountered any in the past 5 or so years. reply TickleSteve 7 hours agorootparentAgree... As an embedded developer for over 25 years, I would never use the provided hardware abstractions from one particular vendor. Typically, you use your own abstraction layer over multiple vendors BSPs/OS/libraries. One of the driving principles behind embedded software is minimalism because you pay real money for every byte and cycle. That leads you to creating minimal abstractions for your particular use case that still gives you the flexibility that is also often required (multiple sources for processors for example). reply DannyBee 6 hours agorootparentprevPrototyping boards - I can totally believe trying to do firmware on a shipping product with real constraints in zephyr would be a pain in the ass because you don't have enough control. I often use C++ with zephyr, which also pretty much immediately disqualifies me from that club :) Though i've done it plenty of times with C only and nordic boards. Amusingly, I got into it years ago because I was porting my dust collector controller to an RTOS, and it was very easy to port to zephyr (I had to hack up the C++ threading support, but the hardware was very easy to make work). But i've since used it for everything from the \"the keypad and receiver that is on the gate to my house\" to embedded devices that transmit flow data, etc. I have had to fix bugs in the hardware abstractions for LoRa (interrupt based packet reception did not work on all chips), and do things like add hardware acceleration for LVGL, but overall the abstractions work pretty well for me. Having had to build themselves in FreeRTOS, it's just not worth my time. I view it as more of a \"less hacky arduino\" than \"serious thing i would base my life on\". At most, i would use it for nordic boards to develop bluetooth stuff (because they have such good support for this). Anything that requires real serious guarantees i'll use PLC hardware, not zephyr. But i'm in the machine world, so this is like \"make sure spindle has stopped moving before allowing tool release\" type stuff that needs to be deterministic, but is also fairly simple. It does not require more than PLCOpen or ladder. reply johnwalkr 5 hours agorootparentGlad you mentioned PLCs. I keep seeing more and more young engineers reinventing wheels with raspberry pi and arduinos, especially for things like test jigs. It’s almost like PLCs are a secret in some industries. reply mardifoufs 4 hours agorootparentIt's not that they are a secret. It's that they are sometimes cost prohibitive and lock you into a proprietary, rigid ecosystem regardless of which PLC you chose. PLCs are awesome for what they are intended for, and they work very well with each other/equipment made with PLCs in mind. but they are an immense pain to \"integrate\" into an existing non-industrial system. They are basically in their own world, with tooling that's specific to the PLC world, with very little open source support. I agree that for some one off things like controlling a CNC, they might be more useful than a Frankenstein esp attached to some servo controllee though. reply DannyBee 4 hours agorootparentI agree on both counts. You can easily get locked in. For anyone else who is just sort of lurking (you already know what i'll say). Codesys is basically the standard here, and the way to \"avoid\" lock in - it has the most hardware support, and lots of vendors use it under the covers. This gives you some standard. It supports IEC 61131-3, happy to export it as text or whatever, and i've actually moved code between implementations. You can use Codesys Control RTE on anything that runs windows or linux to get soft-realtime support. Twincat is similar (it was based on codesys at one point but no longer). Integration is, as you say, a pain outside of industrial land. But i will admit i am amazed that i have an entire CNC machine built out of ethercat servo drives, I/O, VFD, vacuum pump, pneumatic valve actuators, limit switches, etc. They all are from different manufacturers. But damned if it doesn't work perfectly, and i only have an ethernet cable running between 99% of things where it used to require a metric ton of cables and you were just flinging bits and analog current around between things. 6 If i bothered to update the spindle to ethercat, the only real physical I/O would be brake power relays (unavoidable) and emergency stop. I do have one modbus thing (dust control flow monitor) i use as well. It also is pretty good at hiding complexity - I can link a variable to an I/O input or analog value or VFD status word, know that it will deterministically update. I can set up a structure of bits for each pneumatic valve and map it to the manufacturer's single I/O word and again, get deterministic two-way updating and not worry about it. Now, can i get status out of this thing? Well, no, to your point, either something else needs to speak modbus, ethercat, profinet, ethernet/ip, pure digital i/o to it. These days i could publish status to MQTT, but something like \"expose an HTTP port that outputs a bunch of JSON\" is totally uncommon, and will net you strange looks. It's like you are asking about cold fusion. Don't even get started on controlling it from the other side through something like that. But yeah, otherwise paying 500 bucks for a license to ladder program a PLC is not a pleasant thing. reply vvanders 3 hours agorootparentIt's not Ardunino cheap but I've been a fan of Automation Direct, they've got a couple fairly capable PLCs and they don't try and charge you on the software and/or support. reply mardifoufs 1 hour agorootparentprevYeah honestly, I'm in awe of how... weirdly well PLCs work? Yes they aren't exactly super complex usually, but they just work together. You can know exactly what your Plc will work with, you can see what it does in its vendor supplied GUI, it can be basically plug and play. In a way that would be impossible without the insular ecosystem that the PLC world has, but that really doesn't matter considering how well they do the job. And yeah, I think the reason why it hides complexity pretty well is that they are meant to be field repairable by regular technicians who don't necessarily know a lot about the underlying systems. That also makes it super easy to use... once you set up everything that is haha. Thank you for the pointers, I heard about codesys but I always assumed that vendors all used their own proprietary islands of standards and only paid lip service to Interop. I'm only passably familiar with Siemens PLCs so not super knowledgeable either! reply bborud 6 hours agorootparentprevHave you tried ESP32 and ESP-IDF (FreeRTOS?). I'd be interested in your take on that after using Zephyr :-) reply DannyBee 4 hours agorootparentI have tried ESP32 a bunch, ESP-IDF itself less. I mainly used ESP32 through platformio (which used the arduino compatibility layer of ESP-IDF), and then through the rust support. I did use ESP-IDF directly for one project, but only for a small time. For that application, it was just way too high power and too finicky (it was easy to crash it by doing normal things - admittedly, it could be that there are just a lot of crappy ESP32 boards out there) I did find ESP-IDF a lot nicer than either platformio, or the rust support, for sure. It was nice having regular old cmake and stuff that just worked for you, without worrying about it. For a simple app, i would use it over zephyr, no issue. But zephyr's abstractions have bought me stuff. For example, I have learned how to make zephyr's MCU management subsystem do OTA over bluetooth across any device that supports mcuboot (IE everything). So like, i don't worry about needing to use each manufacturer's OTA support. It also works with nuttx if i ever go that way. It's hard to give stuff like that up for my use cases. I can walk near my gate transmitter/receiver, or near a machine, or near anything else i've built, and using the same tools, make sure the device is working and update the device with an image, without needing to worry about or keep 75 types of OTA tools and keys around :) (I could make it work over wifi or lora or ... easily too, but i don't really need to). These devices do not all use the same SOC - the gate transmitter is a very low power sleep device (small battery will last about 21 years at current rate). The gate receiver is not. The embedded sensors on machines are yet a different SOC (nordic), with other types needing a little more power being higher power STM's. There is even an NXP device around somewhere from when i was experimenting with LVGL. It is possible to make this kind of thing work with freertos (they have a 3 year old not-updated labs project to support mcumgr, for example). But i don't want to have to combine my own pieces, etc. This, of course, is basically the point of FreeRTOS, so it's not a surprise i don't go that way :) ESP-IDF obviously provides it's own OTA layer, though it leaves transmitting data and management to you. I did build an OTA over bluetooth impl that worked pretty well (updates at about 50-200k/s) before i moved entirely to the zephyr one. reply dayjaby 3 hours agorootparentDo you by chance have an example repo with mcu management working? I always struggled with that in Zephyr :) reply anymouse123456 9 hours agoparentprev\"Zephyr is easy to use\" That has not been my experience. From where I sit, Zephyr has very pretty marketing material. Behind all that snazz, Zephyr is outrageously bloated, extremely slow to compile and wildly difficult to get up and running. reply DannyBee 6 hours agorootparentI dunno, maybe i got lucky. It takes me maybe 10 minutes to get clion + zephyr started and working for a new project. If there is board work, at that point i'm playing with making the board work. I started with platformio's zephyr support and then moved to clion as platformio kind of died. I have never, and would never, try to use west as the main build system of my project directly. As for bloat/compilation speed, i guess it all depends on what you are trying to use it for. As per the other thread - if you are trying to use it as \"an RTOS that is a less hacky version of arduino stuff\", i think it works great. If you are trying to use it for \"i have meaningful hardware constraints and need to keep track of every byte\", i doubt it would work well compared to FreeRTOS. I think the limit is probably \"i am using nordic boards to develop bluetooth stuff\". I do agree they try to sell it for a lot of things. reply anymouse123456 5 hours agorootparentThanks for the thoughtful response. I was really frustrated by Zephyr, but I'm glad to see it's helping some folks. reply einsteinx2 6 hours agorootparentprevWhat do you mean by “platformio kind of died”? I used to use it a lot but haven’t done any microcontroller projects in a while. reply bborud 4 hours agorootparentI can't speak to what he meant, but if I were to guess, Zephyr isn't necessarily that easy to wrangle into shape for PlatformIO so despite a lot of initial enthusiasm and optimism, progress has been a bit disappointing. As for why, it is probably because MCU makers are a bit nearsighted when it comes to the software side so you get little or no help from there. The strategic decision makers don't understand software. (That's not my assessment, by the way, but that of people I know who either work for one of the major MCU makers or has worked there). So they do their own thing, they don't do it particularly well, they don't see that they don't do it particularly well or why it is even their problem. I also think that they are a bit afraid of common tooling - possibly because they think it is giving up control or robbing them of the opportunity to differentiate themselves (which is tragically funny since most can, at best, hope to be no worse than the competition). You'd think that if lots of players can agree on using Zephyr it shouldn't be hard to make them agree on supporting sensible common tooling (akin to PlatformIO), but then again, these companies don't really get software. (I was tempted to say \"modern tooling\", but then I remembered that I hate it when people use the word \"modern\" so Dobby had to iron his hands and delete it). reply DannyBee 4 hours agorootparentprevMost manufacturers seem to have abandoned trying to support them, their community has slowly disappeared, and you can see it. They seem to only care about Espressif these days. Zephyr support has not been updated in ages (2021) Patches submitted to platformio arduino to add Giga R1 support have gone unreviewed for years (I get poked every so often because i did some work on it, so i see the github comments). The only things that seem to be in okay shape these days are ESP and STM32. Given the other options at this point, it is nowhere near as useful as it used to be. reply shadowpho 7 minutes agoparentprevWhy skip mbed? That’s the “best” part! reply bborud 10 hours agoprevHaving toolchains installed system-wide in the traditional UNIX way is painful, and dare I say it, not the smartest of approaches. If it works for you: great, but if you work on a project with multiple developers, sometimes working on multiple projects that have different targets, you will spend a lot of time trying to figure out build and configuration problems. It also doesn't help that people keep using Python for tooling. Why would you want to insist on using a language that brings its own versioning problems and which will behave differently on each developer's computer? I've done embedded development for about a decade now (both as a hobby and professionally) and it is puzzling that people think it is okay to spend a week trying to make everyone's setup do the same thing on a project and then not see how this is a problem. It is a problem. It is annoying. It does waste time. It is unnecessary. Tools should be statically linked binaries. I don't care what language people use to write tools, be it Rust, Go, C, C++. I just wish people would stop prioritizing ad-hoc development and start to make robust tools that can be trusted to work the same way regardless of what's installed on your computer. Python doesn't do that. And it doesn't help that people get angry and defensive instead of taking this a bit more seriously. That being said, things like PlatformIO are a step in the right direction. I know it is a Python project (and occasionally that turns out to be a problem, but less often that for other tools), but they have the right idea: toolchains have to be managed, SDKs have to be managed, libraries have to be managed, project configuration has to be simple, builds have to be reproducible and they have to be reproducible anywhere and anytime. I wish more of the embedded industry would realize that it would be better to have some common efforts to structure things and not always invent their own stuff. I know a lot of people who work for some of the major MCU manufacturers and I am always disheartened when I talk to them because they tend to be very near-sighted: they are mostly busy trying to solve their own immediate problems and tend to not have a great deal of focus on developers' needs. reply naitgacem 27 minutes agoparentWorking with Android app developement has got me spoiled in this area. One needs to just run a command and everything is set up and works the exact same way whether be it locally or on CI with the same version of both build tools and the libraries. It still pains me when I go back to dealing with CMake and Make and trying to get libraries installed, as opposed to say, compile 'library-name-here'. reply bschwindHN 8 hours agoparentprevI refuse to use anything with python tooling now. I just don't. It is just so extremely rare that things work on the first try with it. I have a keyboard project that runs on an RP2040, and the firmware is in Rust. Here are the steps to flash it if you're starting with just the repo and no Rust toolchain: (install rustup) $ curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rssh $ rustup target add thumbv6m-none-eabi $ cargo install elf2uf2-rs * Put the keyboard in bootloader mode * $ cargo run --release This is relying on rustup and Cargo to do the heavy lifting of toolchain management and building, which they are fantastic at. Python projects don't even come close. reply bborud 8 hours agorootparentThat looks quite lovely. I really hope that MCU manufacturers invest in Rust and that they both manage to do so in mechanical sympathy with the Rust community and that they realize they have to cooperate on common tooling. reply franga2000 4 hours agorootparentprevYou're comparing the \"traditional Linux approach\" to curl-pipe-bash, not comparing the actual environments/toolchains. Platformio: curl https://.../get-platformio.pypython3 && pio run Pipx: apt install pipx && pipx [build-script.py] Pipenv: pip install --user pipenv pyenv && pipenv run [build-script.py] reply LtdJorge 8 hours agoparentprevWouldn't Docker (or other container tools) be a good candidate? Instead of installing the toolchains locally, do the build on a container based on an image with the exact toolchain you need. reply bborud 8 hours agorootparentYes, I used to do that for a couple of projects, but it wasn't as smooth as I had hoped. For instance I had a bunch of challenges getting USB stuff to work properly. And there were some tools that still required me to lug around a windows laptop for parts of the process. I'd much rather have proper tooling to begin with rather than have to pull out everyone's favorite roll of duct tape (Docker) to hide the mess. reply vvanders 3 hours agorootparentprevDocker is great if you don't care about your build performance across a wide range of hosts, it's probably fine for small projects but I've seen incremental build times climb quickly where docker support wasn't the best(i.e. OSX). reply amluto 7 hours agorootparentprevIt is indeed possible to make a nice container that contains a program, offers a clean interface to that program, and doesn’t package a whole pile of largely irrelevant, guaranteed-to-be-quickly-outdated crap with it. But being possible doesn’t mean that anyone does it. Most containers I’ve ever seen are big messes. Possibly GPL-violating messes if the payload isn’t appropriately licensed. Certainly maintenance and provenance disasters. Unquestionably not reproducibly buildable and possibly not buildable at all. reply yjftsjthsd-h 4 hours agorootparent> and doesn’t package a whole pile of largely irrelevant, guaranteed-to-be-quickly-outdated crap with it. > Possibly GPL-violating messes if the payload isn’t appropriately licensed. Certainly maintenance and provenance disasters. Unquestionably not reproducibly buildable and possibly not buildable at all. If static binaries are on the table then none of these things can possibly be disqualifiers. reply buescher 6 hours agorootparentprevFor professional embedded development, where reproducible-in-the-future builds are frequently valued, it's common, when possible, to set up your whole toolchain in a vm that's kept under version control. reply anymouse123456 9 hours agoparentprevJust want to second this entire post. It feels like I wrote it myself. reply drrotmos 13 hours agoprevPersonally, I've begun switching over my RP2040 projects to Rust using Embassy. Rust did take some getting used to, but I quite like it. Not an RTOS, but it satisfies a lot of the same requirements that'd lead you to an RTOS. reply bschwindHN 11 hours agoparentIf you go this route, I would recommend starting off with the rp2040-hal crate and once you hit a pain point of managing multiple tasks, look into embassy or RTIC. Rust and Cargo take the pain out of building and flashing to the RP2040 (or STM32, for that matter) - it's the most pleasant embedded setup I've ever used. reply lulf 6 hours agoparentprevThat is what I've observed too. My impression is that people go to RTOS for libraries and dependency management, which you kinda just get out of the box with Rust, cargo and crates.io. A lot of applications simply don't use the MPU. And then consider what you get from Rust memory safety and the reduction in overall complexity of the firmware without the RTOS. reply eloycoto 11 hours agoparentprev100%, Embassy is great and I'm in love with it. If you add the PIO interface for RP2040 the setup makes code super simple and beatiful and difficult to achieve with another processor. reply stockhorn 11 hours agoparentprevI can totally second this. Embedded rust in general has been an excellent experience for me. And async with embassy-executor works really well and takes a lot of pain off the whole rtos design process. reply chappi42 12 hours agoparentprevWow that looks cool. Thanks for the mention! reply lloydatkinson 12 hours agoparentprevI believe this has come up before but what are some of the differences between RTIC and Embassy? reply lulf 6 hours agorootparentOne of the things not immediately apparent for people coming to Embassy is that you can mix and match RTIC with the Embassy HALs. So the more appropriate comparison is RTIC vs the Embassy async executors. reply Katzenmann 11 hours agorootparentprevRTIC is really simple and doesn't use it's own HALs. Also it's macro system makes it hard to modularize your code since all tasks need to be in one module. I've played around with it a bit and it seems like it could be great in the future, but currently not really. Embassy has it's own HALs which makes it better at async and has also nicer ergonomic IMO reply liamkinne 11 hours agorootparentImportantly for RP2040 users, RTIC 2.0.0 is currently single-core only. I’m using RTIC for the firmware on my STM32H7 based product (https://umi.engineering) and it has been a joy. reply jamesmunns 1 hour agorootparentprev> Embassy has it's own HALs which makes it better at async and has also nicer ergonomic IMO Worth noting, you don't HAVE to use the embassy HALs with the embassy executor. However, AFAIK, the only mainstream non-embassy HALs that supports async is the ESP32 HALs. There's no technical lock in, it's just that everyone I've seen implementing async support (outside ESP32) tends to do it within the Embassy project today. That may change over time. reply rkangel 2 hours agoprevI really want to get ve Hubris a try on a proper project (https://hubris.oxide.computer/reference/). As an architectural approach it aligns closely with what I am going for in embedded land, but in C with more pain. And is not dissimilar to what you do in Erlang/Elixir in hosted land. Embassy looks to be a good choice in more memory constrained situations where you can't afford multiple stacks. reply 5ADBEEF 13 hours agoprevthe pi pico is 100% supported in Zephyr. https://github.com/zephyrproject-rtos/zephyr/tree/main/board... Did the author not check the docs? https://docs.zephyrproject.org/latest/boards/raspberrypi/rpi... Additionally, you aren't intended (for many situations) to use a single \"main\" Zephyr install, but to include what external modules you need in your project's west.yml. If you have a number of projects sharing the same Zephyr install that's a separate discussion but installing every possible toolchain/HAL is not the only way to do things. reply introiboad 9 hours agoparentAlso it should be trivial to build using the GNU Arm Embedded toolchain if the author did not want to install the Zephyr SDK, not sure why this did not work for them. reply RossBencina 13 hours agoprevNo mention of ThreadX, which is open source these days https://github.com/eclipse-threadx/threadx/ reply pantalaimon 5 hours agoparentRIOT would be another alternative https://github.com/RIOT-OS/RIOT reply chrsw 7 hours agoparentprevI don't know why ThreadX isn't mentioned more frequently in these lists. It's relatively simple to use and understand. reply bangaladore 2 hours agorootparentBy and far my favorite RTOS from a source code and API perspective. It's just elegant. And it has a POSIX API layer if you really need that. reply joezydeco 28 minutes agorootparentI'm looking to William Lamie's next project after ThreadX, the PX5 RTOS. The POSIX API won't be an afterthought. https://px5rtos.com/ reply bangaladore 0 minutes agorootparentYes, I have seen this. Looks interesting. Its certainly targeting a more enterprise audience (much like ThreadX was originally) You have to pay to use it, price unknown other than maybe >= 5k$ per year?, and it looks like it will be prohibitively expensive (for my usecases at least) to have source access. To me, those make it nonstarters. GianFabien 13 hours agoprevGreat comparison of RTOS choices. Personally I find microPython to be an easier path. async/await based cooperative multi-tasking works well for me. Latest project driving 6 stepper motors and a variety of LEDS and scanning buttons - all in what appears to be real-time to the user. reply pjmlp 11 hours agoparentThese mini computers are much more powerful than the 8 and 16 bit home computers, microPython is more than capable to replace BASIC use cases from those early systems. It is still surprises me how many don't grasp how little we had available to us, and still managed to use high level languages. reply nick__m 13 hours agoparentprevFor a PTZ controller (No hard real-time requirements, minimal application memory usage) microPython look like productive choice. When I tried microPython (on the esp32 but i assume that the rp2040 is equally supported) I was pleased by it's pythonic supports of interrupts handlers ! reply dekhn 6 hours agoparentprevI have to assume in this case the stepper motor signals are generated by a hardware peripheral (like RMT on the ESP32), rather than using python code to generate the stepper signal? In my microscope, I run a FluidNC board that's doing near real-time stepper motor control, and control it with a lightweight serial protocol, but I'm looking at https://pypi.org/project/micropython-stepper/ which seems to be using python code with hardware timers. reply matt_trentini 7 hours agoparentprevAbsolutely, this would be a straightforward MicroPython project :) reply anymouse123456 8 hours agoprevI've had similar experiences to the OP. I went ahead and rolled a simple green thread timer. It doesn't support actual process management like a real kernel, and doesn't make any guarantees about anything, but it has gotten me further than bare metal scheduling and helped me avoid the shit show that is RTOSes. Think JavaScript timer callbacks with an optional context struct (in C) It has allowed me to interrogate a variety of sensors, process inbound signals, make control decisions and emit commands, all at various frequencies. I highly recommend folks try something like this before ruining your life with these slow, abstract architectures. reply bangaladore 2 hours agoprevI think Eclipse ThreadX is a great option (https://github.com/eclipse-threadx/threadx) Its might be the most used ThreadX on the market in the professional space (due to its history), but its quite frankly stupid simple to use. It was initially developed by Express Logic, then partnered tightly with Renesas, Then sold to Microsoft, and then transferred to the Eclipse foundation for good. They also provide NetX(duo), FileX, LevelX, UsbX and GuiX with full source and the same licensing afaik. Personally I don't care for UsbX or GuiX. reply sgt 11 hours agoprevCan't go wrong with FreeRTOS. It's basically an industry standard at this point. reply alextingle 11 hours agoparentWhat's the solution to his problem getting printf() to work? That does sound like a PIA. reply klrbz 4 hours agorootparentThe Pico SDK has a plugin based stdio, they give you two implementations: UART and USB CDC, but you can add new ones by implementing a few callback functions. The UART plugin provided with the SDK can be disabled and replaced, the default implementation is very simplistic and will block. The USB CDC version is much faster but may not always be appropriate for your project. I implemented one that uses a buffer and an interrupt to feed the UART in the background, and then I disabled the plugin the Pico SDK provided. I'm not using an RTOS. The SDK example [uart_advanced](https://github.com/raspberrypi/pico-examples/blob/master/uar...) [github.com/raspberrypi] shows how to set up UART interrupts using the Pico SDK reply retSava 7 hours agorootparentprevIf I understood it correctly, it was that the compiler suite shipped with newlib, which have or can have printf supporting re-entrant use (several threads can call printf in async manner), or not supporting that case (typically sync usage, blocking across I/O). The re-entrant ones use malloc/free for, iiuc, a per-thread buffer. In many cases when you have smaller systems, you actually don't want your OS to do dynamic memory allocation, since it opens up for all kinds of bugs related to eg double-free, or use-after-free, or running out of heap, or too defragmented heap. It's also easier to calculate memory usage (and thus be fairly certain it will be enough) if you allocate as much of the memory as possible as static memory. Hence why some coding standards such as MISRA-C disallows use of dynamic memory allocation. Exactly what caused the lock-up here isn't delved deeper into, but it might be that there was not enough heap, or not a working malloc-implementation linked into the compiled binary (could be a stub), or could be that a non-re-entrant printf was linked in while they tried printf from several threads. reply not_the_fda 6 hours agorootparentprevEmbedded is a PIA, its not web development and shouldn't be treated as such. Printf isn't re-entrant, and they are calling it from multiple threads. There are solutions with trade offs: https://interrupt.memfault.com/blog/printf-on-embedded Everything in embedded is a tradeoff of space, performance, or cost. If you come at it as web development with IO you are going to have a very bad time. reply roland35 4 hours agorootparentprevMy best luck for printf is to use a segger debugger with RTT. It streams data over jtag or swd and is very fast reply TickleSteve 10 hours agorootparentprevFreeRTOS has nothing to do with printf, thats a toolchain/standard library thing for his particular board. reply rcxdude 10 hours agorootparentYou will need your printf to be written with FreeRTOS in mind: it's often not re-entrant at all, let alone actually blocking on IO instead of busy-waiting. reply TickleSteve 7 hours agorootparenttrue, my point being that \"printf not working\" is nothing to do with FreeRTOS. reply constantcrying 10 hours agorootparentprevUnlikely to be a software problem. If I had to guess the serial communication bus is misconfigured. reply roland35 4 hours agoprevZypher is indeed a pain in the neck to learn. I have lots of experience with freertos, setting up tool chains, etc, but just getting a basic project with zephyr is confusing. reply taunus 12 hours agoprevIf you want to look into Rust RTIC https://rtic.rs/2/book/en/ has rp2040 support and is very lightweight reply mordae 7 hours agoprevRolling your own swapcontext() is not that hard on Cortex-M0 and Pico SDK let's you override couple macros to hook into its locking code. reply huppeldepup 13 hours agoprevNo mention of ChibiOS, unfortunately. I checked and the port still has problems installing on flash, so runs on RAM only. I’d also like to suggest uC/OS. It doesn’t take much more than setting a timer in asm to port that rtos but I haven’t had the time myself to try it. reply stephen_g 3 hours agoparentI really like ChibiOS, it’s HAL and drivers are really nice. I used it in a project back when it was GPL with a linking exception (basically LGPL except you can’t really do shared libraries on microcontrollers). reply dTal 6 hours agoparentprevI've heard of uC/OS and always wondered - is it pronounced \"mucous\"? reply huppeldepup 18 minutes agorootparentThe author mentioned this somewhere in his book: competitors pronounced it mucous as a joke/jab. I believe it’s pronounced micro-cos as in microcosmos. reply boffinAudio 9 hours agoprevAlways, always, always start your new embedded project in a Virtual Machine. NEVER MIX TOOLS ON THE SAME SYSTEM. This has been the #1 cause of quality issues for my (commercial) projects. If you start a project with a new chipset, with a new vendor - build a new VM, install the vendors tools (and only the vendors tools) in that VM, and do your builds from there. Do your hacking on your own (non-VM) machine, sure. That's perfectly fine. But ALWAYS use the VM to do your releases. And, for the love of FNORD, KEEP YOUR VM IN SYNC WITH YOUR DEV WORKSTATION. Disclaimer: currently going through the immense pains of dealing with a firmware build that absolutely has to be fixed while the original dev is on vacation - nobody can get into their workstation, the VM prepared for the task is 6 months out of date, and the customer is wondering why they should pay for the whole team to do something that one very special programmer is the only one on the planet can do .. grr .. reply matt_trentini 7 hours agoparentOr, better still, use containers. Haven't used virtual machines in years - and I don't miss them one bit! reply jononor 6 hours agoparentprevI feel your pain. Releases should be built by CI system, imo. Tag a release in git, and binaries plop out (after tests have passed). reply ptman 8 hours agoparentprevDoes nix and flakes help with a reproducible build environment? reply a-dub 10 hours agoprevhm. haven't seen camelCase hard real-time task definitions since the vxworks days! reply demondemidi 4 hours agoprevGave up on freertos because printf doesn’t work? someone didn’t have the patience to read the documentation. reply snvzz 13 hours agoprev [–] AIUI seL4 runs on that chip. It would likely not be a bad option. reply rmu09 10 hours agoparentDo you have more information? seL4 seems to run on raspberry pi 3/4, but I didn't find any mention of cortex-m class CPUs being supported. reply snvzz 10 hours agorootparentNevermind, I did not realize rp2040 is M0+ thus ARMv6. ARMv7 is the minimum, and MMU is required. RISC-V is recommended. reply TickleSteve 10 hours agoparentprev [–] This is a microcontroller (Cortex-M) not an application processor (Cortex-A). reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "As projects grow in complexity, the Raspberry Pi Pico often surpasses the capabilities of the Arduino IDE, necessitating more advanced tools like an RTOS (Real-Time Operating System).",
      "Martijn Braam is developing a hardware controller for PTZ cameras and video switchers, requiring an RTOS due to software complexity; he evaluated FreeRTOS, Apache NuttX, and Zephyr.",
      "Despite initial challenges with FreeRTOS, such as printf causing hangs and lack of hardware abstraction, it remains the most viable option due to its integration with the pico-sdk."
    ],
    "commentSummary": [
      "The post discusses transitioning to a Real-Time Operating System (RTOS) on the RP2040 microcontroller, highlighting various RTOS options and their suitability.",
      "Key RTOS options mentioned include FreeRTOS, Zephyr, and NuttX, each with its own strengths and weaknesses in terms of support, user-friendliness, and hardware compatibility.",
      "The discussion also touches on alternative development environments like Rust and MicroPython, emphasizing their benefits for embedded development on the RP2040."
    ],
    "points": 149,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1720148365
  },
  {
    "id": 40878895,
    "title": "Bone tissue reparation using coral and marine sponges",
    "originLink": "https://web.stanford.edu/group/mota/education/Physics%2087N%20Final%20Projects/Group%20Gamma/bone.htm",
    "originBody": "Introduction In the modern medical world, bone tissue reparation is becoming an increasingly feasible process. The technique most commonly used for this operation is a bone graft[1], where surgeons place existing, gathered bone mass from another source and graft it to the section of bone being repaired. However, it is very difficult to amass the amount of bone necessary for such an operation.[1] Fortunately, a new method of repairing bone damage has emerged. New Frontiers Through biomimicry, researchers have developed a novel method of repairing bone structure using coral and marine sponges as scaffolds, or frames for bone tissue to regenerate onto.[2] These materials prove ideal for this type of operation because they are easily integrated into existing bone structure and greatly resemble bones in terms of porosity and composition (all are similarly constructed with calcium carbonate).[1],[3] The Process In order to repair bone tissue using these methods, surgeons must prepare the coral or marine sponge scaffolds. The scaffold is crafted to form-fit the area desired to be repaired.[1] They must also prepare substances such as marrow stromal cells (MSC)[1] or stem cells (cells capable of becoming any other cell within the body).[3] During the operation the scaffold and cells are inserted into the damaged bone section (Fig. 1). Over time, bone tissue either expands from the existing bone onto the scaffold[1] or stem cells are converted into bone cells directly on the scaffold[3], depending on whether MSC or stem cells were implanted with the scaffold. As the bone heals, the coral or marine sponge scaffold is integrated into the bone structure; that is, they become part of the bone.[1],[3] This becomes possible because of the similarities between bone and coral/marine sponges already stated. By the end of the recovery period, the scaffold area has effectively become identical to the rest of the bone (Fig 1).[1] Figure 1 The Advantages Typical implants for this procedure, usually ceramics or alloys, prevent stress on the bone structure they are grafted to, a process known as stress-shielding. In this process, the much stronger metals or ceramics absorb all of the stress applied to the bone. This prevents bone, which uses stress as an indication to produce more bone cells, from healing and growing properly, causing the bone to atrophy and possibly die.[4] Coral and marine sponges, on the other hand, are not stronger than bone, and simply provide the framework for the bone cells to build around. They avoid the problem of stress-shielding.[4] Conclusion In conclusion, repairing bone tissue with the use of coral and marine sponges represents an immense breakthrough, made possible through biomimetics, that has revolutionized bone surgery. [1] Petite, H., Viateau, V., Bensaïd, W., Meunier, A., Pollak, C., Bourguignon, M., Oudina, K., Sedel, L., Guillemin, G. [2] Guillemin, G., Patat, J.L., Fournié, J., Chétaul, M. [3] Green, D., Howard, D., Yang, X., Kelly, M., Oreffo, R. [4] Cassidy, A.",
    "commentLink": "https://news.ycombinator.com/item?id=40878895",
    "commentBody": "Bone tissue reparation using coral and marine sponges (stanford.edu)130 points by alexandrehtrb 19 hours agohidepastfavorite49 comments birriel 8 hours agoFrom a cosmetic point of view, almost everybody exclusively focuses on the skin to counter aging, when they should be at least as concerned with bone density. Lots of people have perfect skin, but they still look old. Why? Bone morphology. The zygomatic bone erodes, and the orbital gaps widen. The mandible degrades and pivots down and backwards (jaw rotation). Issues like resorption are currently very challenging. Skin is comparatively much easier. Also (and besides well-known interventions like collagen, retinoids, HA, and dermarolling), Epidermal and Keratinocyte Growth Factors are already very cheap, and showing much promise. reply Luc 7 hours agoparentThis interested me, but I had to look up some of it: Zygomatic bone: cheeck bone, https://en.wikipedia.org/wiki/Zygomatic_bone Orbital gaps: hollow areas around the eyes Mandible: lower jaw, https://en.wikipedia.org/wiki/Mandible Resorption: a process in which a substance is lost by being destroyed and then absorbed by the body. HA: hyaluronic acid reply utensil4778 2 hours agorootparentFor anyone else wondering: your body is continually pulling calcium from your bones for metabolic processes. Usually it gets replaced when you consume something with calcium in it. It makes sense to have somewhere to store extra nutrients so you can keep functioning for a long time between taking in those specific nutrients again. Your body does this with a lot of your organs. Fat is obviously calorie storage, but muscles can also be resorbed for energy under starvation conditions (or just when they're under used). Your kidneys can resorb water from stored urine, and your intestines pull most water out of what you consume. Most neurotransmitters and hormones get recycled at various rates and turned into new molecules. I'm sure there's more, but that's all I know of offhand. reply dustypotato 7 hours agorootparentprevThank you. I thought i was dumb reply Xenoamorphous 7 hours agoparentprevAnd what be done about bone density? I guess exercise would help but not with the bones in the head? reply arthur2e5 2 hours agorootparentresistance training is indeed the recommendation for non-head bones, if you’re looking for a confirmation: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6279907/ reply amelius 6 hours agorootparentprevFrom [1]: > Animal and human studies suggest that high-frequency, low-magnitude vibration therapy improves bone strength by increasing bone formation and decreasing bone resorption. So you could apply vibration to the head bones. Not sure about any side effects. [1] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4458848/ reply smallerize 1 hour agorootparentYou can get a concussion pretty rapidly from vibrating your head. https://twitter.runhello.com/mcclure111/status/8374813399893... https://twitter.runhello.com/mcclure111/status/1108808351150... reply arghwhat 5 hours agorootparentprevBefore you apply vibrations to your skull, note that it contains other things than bones that might be less thrilled about said vibrations. Or more thrilled, who knows - be careful out there, and if you do something stupid, take notes and share the results for our entertainment^W learning! reply amelius 4 hours agorootparentWell, I apply a vibrating device to my skull every morning and evening (indirectly). It's my electric toothbrush :) reply lemonberry 3 hours agorootparentprevHumming?? No mention of bone density in this article, but there may be some benefits: https://theconversation.com/is-humming-healthy-mmm-heres-wha... reply hinkley 4 hours agorootparentprevI have been getting ads lately for an aerobic step with a vibrating motor built into it, for this very purpose. It might have been on Peacock, and if so it was during Tour de France footage. It’s a small effect but real, and it’s passive from the patient’s standpoint and we always seem to find that to be a selling point. This research was, if I recall, originally done for NASA and studied sheep. Shake a Sheep for Science! reply aszantu 3 hours agorootparentprevvibration does something, secret tip for migraines is massage wand to the face, almost as good as using it in other places reply User23 30 minutes agorootparentprevBone density is definitely an adaption from resistance exercise. I don't know any specific studies, but I would expect that the bone density improvements are in some sense systemic in that the metabolic changes that increase bone density will have spillover effects to bones not directly involved in some given movement. reply entropyie 10 hours agoprevI suspected this page was written in MS FrontPage, and a quick peek at the source code seems to confirm it! I love to see old pages still online. Netscape Composer got me through the 90s/00s reply skhr0680 4 hours agoparentFrontpage 2002 or 2003 to be exact. I didn't know that it A) lasted that long and B) used that much CSS reply failrate 2 hours agoprevMy left thumb was reconstructed with coral fragments about 27 years ago. The bone exploded due to the growth of a benign cyst. 6 weeks in a cast to stabilize, then surgery to scoop out the cyst and replace the material. Then 6 more weeks in a cast. When discussing replacement materials, my doctor offered cadaver graft or self transplant (surgically removing bone from my wrist or hip to build a graft). I was deep into Steve Haworth at the time, who was experimenting with implant materials including coral, so I asked about coral. Without missing a beat, the doctor said they could definitely do that. I asked if it was expensive, and he said no. I asked if it had a high rate of rejection, and he said it was comparable to self transplant. Why was it not the first suggestion? Why did he not even mention it in the first place? Sadly, I forgot to ask these questions. Tl;dr I had a coral graft, and it worked great. reply alexandrehtrb 1 hour agoparentThat's very interesting! Good to hear it! reply hinkley 14 hours agoprevI lost a tooth after the pandemic. To seat an implant they pack the void with one of several things, including sterilized cadaver bone, then wait for the oocytes to colonize and make new bone. I got a synthetic bone sand. Little bits of it migrated like glass slivers would but otherwise it wasn’t bad and at least I didn’t have dead people in my mouth. Obviously this is a bit of a different scenario given the fairly substantial differences in the shape of the wound, but I wonder how much longer we will need to use naturally occurring materials versus synthesized ones, made in a sterile environment. reply hinkley 4 hours agoparentYes, that was supposed to be “osteocyte” but it’s far too late now. reply Scoundreller 13 hours agoparentprevI uhhh, don’t think oocyte is the right word. Osteoblast maybe? reply jlund-molfese 13 hours agorootparentOP probably meant to type osteocyte and it got autocorrected to something else reply shiroiushi 12 hours agorootparentAutocorrect is one of the biggest misnomers in all of history, I think; in fact, it's downright Orwellian. It should be called \"auto-incorrect\". reply TeMPOraL 8 hours agorootparentRight. It's all fun and games until it decides to \"correct\" drug names in your doctor's notes. reply WilTimSon 6 hours agorootparentI highly doubt software that doctors use for patient notes and prescriptions would even have the option to enable autocorrect. If it does, that’s a giant oversight on the devs’ part. reply TeMPOraL 4 hours agorootparentGlobal autoincorrect in MacOS supposedly did that in recent years, according to some post by Scott Alexander I read a while ago. reply hinkley 4 hours agorootparentprevI’ve seen some dumb shit in my days. But I’m glad you still see good in the world. reply hinkley 4 hours agorootparentprevIf I could find the motherfucker who replaces “its” with “it’s” every goddamned time I mean its, his mother fucking days would be over. reply throwway120385 1 hour agorootparentWe should also defenestrate whoever corrects the previous word or phrase based on what you just typed in iOS. The amount of times I've meant something very technical or specific to a field that a programmer in silicon valley has never heard of and then had that corrected to something else totally meaningless by the second or third word is an infuriating waste of time. reply 0cf8612b2e1e 51 minutes agorootparentThat behavior is so infuriating! Especially since I frequently fail to notice it because I am focused on the current word, not the one I had already confirmed as correct. reply yieldcrv 11 hours agorootparentprevgenerative grammar reply hinkley 4 hours agorootparentprevTyping on phone, late at night. Always a gamble. reply throwup238 12 hours agorootparentprevThis is why I don't eat out. reply hinkley 4 hours agorootparentI already made the “dead people in my mouth” comment so I can’t exactly fault you for this. But someone else can! reply 77pt77 13 hours agorootparentprevdefinitely not oocyte reply hggh 7 hours agoprev(2014) [0] [0] https://web.archive.org/web/20141013021330/https://web.stanf... reply jwilk 6 hours agoparent(2005) according to the HTTP headers: Last-Modified: Fri, 09 Dec 2005 22:37:30 GMT reply whizzter 5 hours agorootparentThese kinds of ideas to use stem-cells with foreign materials seemed in vogue back then, no idea how feasible they are in reality but an improvised similar technique for tracheae was how Paolo Macchiarini first got hyped and then convicted (He went on to try it on humans despite skipping animal trials of the technique). https://en.wikipedia.org/wiki/Paolo_Macchiarini reply hinkley 4 hours agorootparent> Macchiarini was convicted of unethically performing experimental surgeries, even on relatively healthy patients, resulting in fatalities for seven of the eight patients who received one of his synthetic trachea transplants. Fuuuuck. I think I heard about this guy before he went mad scientist, but not after. reply whizzter 4 hours agorootparentYeah, the early hopeful news spread widely but the scandal and fallout certainly kept things in the news over here for a long time. There's a Netflix pop-documentary called \"Bad Surgeon\" with a that does cover the viewpoint of the colleagues that turned whistleblowers (and the persecution they endured before media and prosecutors started looking into it) even if much of the focus is on his many concurrent women (the main one believing she's going to be wed by the pope). reply warmedcookie 15 hours agoprevPart of the crew. Part of the ship. reply tuatoru 13 hours agoprev\"Reparation\"? That means the act of paying back, making amends, compensating a second party for a wrong done them. What happened to \"repair\" as a noun? \"Bone tissue repair\". reply HPsquared 9 hours agoparentIt is in Wiktionary as an archaic usage. It makes sense, I think, just an uncommon usage. Singular Vs plural. reply ImHereToVote 13 hours agoparentprevOP is Scandinavian. reply tuatoru 11 hours agorootparentYes, but OP is using a word and phrase taken directly from the introduction to the article. I expect better from Stanford.edu. reply viciousvoxel 9 hours agorootparentIt's not a major error -- the words are etymological siblings and it's clear what was meant. Repair translates to something resembling \"reparation\" in most romance languages so it's an easy translation mistake to make. reply hinkley 4 hours agorootparentI worked recently with a guy who learned all of his big words from books. Very, very old books. It was exhausting. And English is my first language. I felt sorry for my Indian coworkers. Jesus man, stop trying to look smart and just talk like a normal person. The intelligence is in the ideas not the words used to convey them. reply db48x 8 hours agoprevs/reparation/repair/g reply nonameiguess 4 hours agoprev [–] It's a shame Nature seems to keep these articles locked up forever. I found the first reference, which is a study from 2000, which is still paywalled and I can't read it. I'd be curious to know how state of the art has changed since this. I had a two level lumbar interbody fusion seven years ago, the procedure in which discs are removed and replaced by metal spacers that get seeded with a bone graft. Within about 18 months, you've got one solid bone. They seeded it with my own bone, sawed off of my pelvis, plus some kind of growth-stimulating protein. Beats me whether that was coral-derived or synthetic or what. I didn't think to ask. In any case, it certainly worked. It takes a while, but x-rays today look ridiculous. The bone is enormous, effectively growing around the original screws and rods that held everything in place while the bone was growing. I guess the scaffold matrix in me must have been of the coating variety. As far as I was told, the spacers were just the same titanium alloy as the screws and rods, which for some reason don't set off metal detectors, which makes me wonder why nobody makes knives and guns out of the same material. It'd be nice if they put a date on this page. The other references I could find were from 2011 and 1987. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Researchers have developed a new method for bone tissue repair using coral and marine sponges as scaffolds, leveraging their porosity and calcium carbonate composition.",
      "This method involves preparing the scaffolds to fit the damaged area and using marrow stromal cells (MSC) or stem cells to promote bone regeneration.",
      "Unlike traditional materials like ceramics or alloys, coral and marine sponges avoid stress-shielding, providing a framework that supports proper bone healing and integration."
    ],
    "commentSummary": [
      "Researchers are exploring the use of coral and marine sponges for bone tissue repair, highlighting an innovative approach in medical science.",
      "The discussion includes personal anecdotes about successful bone repairs using coral fragments, suggesting these materials are effective and cost-efficient alternatives to traditional methods.",
      "The conversation also touches on the importance of bone density and various methods to improve it, such as resistance training and vibration therapy, providing a broader context for bone health maintenance."
    ],
    "points": 130,
    "commentCount": 49,
    "retryCount": 0,
    "time": 1720136541
  },
  {
    "id": 40880322,
    "title": "Why Vivaldi won't follow the current AI trend?",
    "originLink": "https://vivaldi.com/blog/technology/vivaldi-wont-allow-a-machine-to-lie-to-you/",
    "originBody": "Why Vivaldi won’t follow the current AI trend? Web browsers are integrating the current AI trend with Large Language Model (LLM) functionality. But there are fundamental issues with it. We addresses them here. By Julien Picalausa February 5, 202413609 views Read this article in español, 日本語. ChatGPT came into the public eye a year and a few months ago. Ever since then, there has been an increasing trend in many sectors to try to put it to use to replace some of the things that people do, or to provide a new way to help people find answers to whatever they may wonder. The world of web browsers has not been spared by this trend with multiple examples of web browsers integrating LLM (Large Language Model) functionality in one way or another. Yet, even as they do so in the name of building the future, none of them seem to consider the glaring flaw in these features: The LLMs themselves are simply not suited as conversation partners, as summarization engines, and are only able to help with generating language with a significant risk of plagiarism. In order to understand why all of those are fundamental problems, and not problems that are eventually going to be solved, we should examine the very nature of LLMs. We do not want to get into a very long-winded explanation of the intricacies of LLMs here. Instead, we will settle for a shorter explanation. It might leave out some caveats, but everything said here does apply to the big popular generic LLMs out there. Many experts in the field have already done an excellent job of this. Here is an interesting read: “You are not a parrot. And a chatbot is not a human“. What are LLMs? LLMs are just a model of what a written language looks like. That is a mathematical description of what it looks like. It is built by examining a large variety of sources and focuses on describing which word is the most likely to follow a large set of other words. There is a bit of randomness added to the system to make it feel more interesting and then the output is filtered by a second model which determines how “nice” that output sounds. In several cases, this second stage model was made by having many (underpaid) people to look at what comes out of the first stage and choose whether they liked it or not and whether it sounded plausible. This has two fundamental issues: Copyright and privacy violations In order to have a good idea of which word is likely to follow a set of words, it is necessary to look at a lot of text. The more text, the better as every bit of text allows to tweak the model to be a more accurate representation of a language. Also, much of the text fed into it needs to be relatively recent to reflect the current usage of the language. This means there is a tremendous incentive to consume text from all recent sources available, from social media to articles and books. Unfortunately, such text being baked into the model means that it is possible to cause it to output the same text verbatim. This happens if, for a given input sequence, there is no better choice than regurgitating this original text. As a result, these models will in some case just repeat copyrighted material, leading to plagiarism. Similarly, the mass of text coming from social media and other user-provided sources may well contain sensitive, private information that can similarly be regurgitated. Some clever people have found ways to trigger this sort of behavior, and it is unlikely that it is possible to protect fully against it. Being clearly aware of the risk posed by exposing private information, we have never been thrilled by the idea of it possibly getting baked into those models. Plausible-sounding lies Since the text that an LLM is built out of originates in large part from the Internet in general, that means that a lot of it is complete trash. That goes from mere poorly written prose to factual error and actually offensive content. Early experiments with the technology would result in chatbots which quickly started spewing out offensive language themselves, proving that they are unfit for purpose. This is why modern LLMs are moderated by a second stage filtering their output. Unfortunately, as written above, this second stage is built by people rating the output of the first stage. To make this useful, they need to examine huge amounts of outputs. Even the most knowledgeable people in the world could not hope to check everything for accuracy and even if they could, they cannot know every output that will ever be produced. For those, all the filter does is help set the tone. All this leads to favoring the kind of output that people like to see, which is confident-sounding text, regardless of accuracy. They will be right for the most part on widely known facts, but for the rest, it’s a gamble. More often than not, they will just give a politician-grade lie. The right thing to do So, as we have seen, LLMs are essentially confident-sounding lying machines with a penchant to occasionally disclose private data or plagiarise existing work. While they do this, they also use vast amounts of energy and are happy using all the GPUs you can throw at them which is a problem we’ve seen before in the field of cryptocurrencies. As such, it does not feel right to bundle any such solution into Vivaldi. There is enough misinformation going around to risk adding more to the pile. We will not use an LLM to add a chatbot, a summarization solution or a suggestion engine to fill up forms for you until more rigorous ways to do those things are available. Still, Vivaldi is about choice and we will continue to make it possible for people to use any LLM they wish online. Despite all this, we feel that the field on machine learning in general remains an exciting one and may lead to features that are actually useful. In the future, we hope that it will allow us to bring good privacy-respecting features to our users with a focus on improving discoverability and accesibility. We will keep striving to provide a featureful and ethical browsing experience. Share article Facebook Mastodon X Reddit Hacker News Written by Julien Picalausa Software developer at Vivaldi since January 2017. When I'm not at work, I play video games or maintain my servers. I'm also a dungeon master, mostly playing DnD 3.5.",
    "commentLink": "https://news.ycombinator.com/item?id=40880322",
    "commentBody": "Why Vivaldi won't follow the current AI trend? (vivaldi.com)124 points by botanical 12 hours agohidepastfavorite154 comments pprotas 11 hours agoSeems like a reasonable and thought-out decision to me. Not sure why the comments here are so negative. Clearly LLMs don’t fit into Vivaldi’s vision and the features they’d like to provide to their users. reply stavros 10 hours agoparentFor me I think it's because the article appears biased. It's not just \"we can't think of any problem it'd solve\", it's \"LLMs are bad and you should feel bad for liking them\". reply pprotas 10 hours agorootparentI don't really have that feeling. The author says that LLMs make stuff up and are often wrong about non-widely known facts. They present hallucinations in a confident way, which makes them come across as liars. This is true. That is exactly what the most popular LLMs do. They don't say that you should feel bad. The author simply says that the characteristics and unreliability of LLMs make them unfit to be implemented in the Vivaldi browser at this moment. They even close off the article with a positive sentiment about the future of the ML field. They don't burn any bridges there. reply KoolKat23 10 hours agorootparentHe went on a tangent about plagiarism, may as well disable the copy text feature in the browser. reply WA 9 hours agorootparentCopying isn't plagiarism. Copying and then publishing the same thing is plagiarism. reply KoolKat23 9 hours agorootparentYes, I agree with you. The author made the point about LLM's facilitating plagiarism not me. My point is, if that is his argument, then copying is the same thing (which is ridiculous of course). reply plasticchris 4 hours agorootparentThe plagiarism argument is not necessarily directed at the user of the browser. Ask yourself who is doing the publishing? And how would you cite the output of an LLM if you did publish the output? reply KoolKat23 2 hours agorootparentI could ask the same for the copy function, don't see how this would ever be an issue? reply stavros 10 hours agorootparentprevThis doesn't sound biased to you?: > While they do this, they also use vast amounts of energy and are happy using all the GPUs you can throw at them which is a problem we’ve seen before in the field of cryptocurrencies. reply pprotas 9 hours agorootparentThis is written in a way that makes it clear that the author does not like the energy usage aspects of LLMs. But is he wrong? reply stavros 9 hours agorootparentYes. Cars use more energy than LLMs, we don't mind those. What does \"a lot of energy\" even mean? It's meaningless. Do they use too much energy for their usefulness? If they did, people wouldn't be using them. reply nunez 2 hours agorootparentI'm not sure if cars use more energy than LLMs; huge \"citation needed\" there. But for the sake of argument, let's assume that they do. Cars use more energy than LLMs because most of the world is built around requiring a car to get to places. It's not that we don't mind it; quite the contrary, in fact, as we're always reminded of when the price of gas/petrol shoots upwards. When the cost of living forces you to live 45 minutes away from your job by car because living within walking distance is astronomical, many folks are conditioned to want a house with a garage \"for the kids\" because apartments are \"for the poor,\" and EVs, in their current state, are not financially feasible yet (though that is changing!), it's more that we're forced to tolerate it. reply stavros 1 hour agorootparentThat's about the cost of energy, not about the consumption. If you don't think the cost of gas is worth it, you don't use a car. If you don't think the cost of electricity is worth it, you don't use an LLM. It's literally priced in. I know people don't mind the cost relative to the value they're getting, because if they did, they wouldn't use LLMs. reply timeon 9 hours agorootparentprev> we don't mind those. Like with LLMs, some of us do. But still there are places in the world where one is imprisoned without car. Which is not case with LLMs (yet). reply minasmorath 5 hours agorootparentReally hit the false equivalence nail on the head. Cars enable long-distance travel, which in many parts of the world is now essential for survival, and often that is, ironically, a result of climate change. LLMs do nothing to aid human survival. In a post-apocalyptic world, cars would be sought after for both transport and shelter, but nobody would give a care that we lost ChatGPT. reply maniflames 9 hours agorootparentprevNot sure if it’s biased, it’s a serious limitation of the technology. Some countries are already struggling with their energy grid and water demands as is. I think it’s fair to ensure that you create something that isn’t subject to possible quotas in the future reply rsynnott 6 hours agorootparentprev... But I mean this is the case. What do you mean by 'biased' here? Is it 'biased' to mention bad things about a thing? To be truly unbiased, must one praise everything while glossing over the problems? reply minasmorath 10 hours agorootparentprevI took it as more of a recognition of the downsides to LLM tech that the hype train tends to ignore, as well as the legal / moral / ethical gray areas that exist in both training those models and determining who is liable for what they output. reply stavros 10 hours agorootparentI don't know, this sounds weird: > While they do this, they also use vast amounts of energy and are happy using all the GPUs you can throw at them which is a problem we’ve seen before in the field of cryptocurrencies. reply minasmorath 10 hours agorootparentHow is that weird? Current energy consumption levels for LLMs are definitely problematic. That's not to say they can't improve, but at the moment it's definitely bad. The estimate of ongoing power consumption for Google's AI summary feature, if it was made available for every search result, is roughly equivalent to the consumption level of the entire country of Ireland. That's not awesome given most of the world is not powered by renewable energy sources. reply stavros 9 hours agorootparentDon't look at what it says, look at how it's written: > While they do this, they also use vast amounts of energy and are happy using all the GPUs you can throw at them which is a problem we’ve seen before in the field of cryptocurrencies. \"Vast amounts of energy\", \"happy using all the GPUs you can throw at them\", and then the random cryptocurrency reference to evoke all the bad stuff associated with those. reply minasmorath 9 hours agorootparentThat's how a lot of folks write when they want to make a shorthand comparison and they trust their readers to understand what they're doing. The author is making a comparison of the current cost / benefit of LLM tech to the cost / benefit of Crypto. I don't necessarily agree with that comparison, but using an evocative writing style that can say quite a lot with very few words isn't a problem to me, especially given what this post is intended to convey. Edit: I do think you're making a fair observation, I just feel there are a few reasons not to draw too strong of a conclusion from it reply rubslopes 7 hours agorootparentprevBut they said: > Despite all this, we feel that the field on machine learning in general remains an exciting one and may lead to features that are actually useful. In the future, we hope that it will allow us to bring good privacy-respecting features to our users with a focus on improving discoverability and accesibility. reply kachapopopow 7 hours agoparentprevIt's likely because people enjoy the benefits AI brings in their current form. I honestly cannot imagine my life now without gpt4/claude as it saves me hours writing shell scripts and transforming vaguely structured data. Edit: yes it does make mistakes, but it takes vastly shorter amount of time to find them rather than writing something from scratch. reply KronisLV 4 hours agorootparent> Edit: yes it does make mistakes, but it takes vastly shorter amount of time to find them rather than writing something from scratch. To me, it feels like there will definitely be features or even entire products out there that wouldn’t exist without something that lowers the barrier of entry far enough for someone to overcome the zone of proximal development: https://en.m.wikipedia.org/wiki/Zone_of_proximal_development Just the other day I was able to introduce some custom ESLint rules into the project to make the import names match the filename (e.g. when someone renames a Vue component but the import names don’t change or you don’t notice those usages, so you end up with bunches ofall over the place). I wouldn’t have had the time to do so without ChatGPT/GitHub Copilot nudging me in the right direction and giving me examples to work off of, because frankly my searches for about 15 minutes didn’t turn up anything either. Clearly that counts for something because nobody in any of my projects had done that previously, now it’s obvious that basically we need a local package added to the project (in package.js) but also that we can store it in the file system and just use the file: syntax. It was much the same story with some .cjs Node prebuild scripts that remind the developers that they should make examples of the new components they make in a development showcase page and so on. Aside from that, LLMs are useful for boilerplate stuff (hello, ASP.NET and Spring Boot), as well as simple one shots when you don’t want to rack your brain coming up with a particular RegEx, amongst other cases. If someone wants an LLM in the browser, good for them! If someone doesn’t want to add them to their browser project, that’s their rightful choice. reply joduplessis 10 hours agoprevLLM's are not useful enough to me to want them integrated with my daily-drivers (web browser, email client, etc.) - so this is a great take & one that I personally identify with. reply pyeri 10 hours agoparentThis very much. I think folks should center around a couple of dedicated LLM web apps like chatgpt.com (plus maybe gemini.google.com for a second opinion) but that should be it. If every company and their dog started churning out their own LLM as a business or revenue model, one can easily see the supply overwhelming demand here apart from many other problems. reply benbristow 10 hours agorootparent> If every company and their dog started churning out their own LLM as a business or revenue model, one can easily see the supply overwhelming demand here apart from many other problems. This certainly seems the case on the iOS/Play stores. Primary AI apps from the big hitters (OpenAI/Gemini/Copilot etc.) but then loads of knock-off ones from those riding the AI hype train. All the knockoffs being basically wrappers around APIs from the big hitters with ads/in-app purchases. reply imiric 10 hours agoparentprevI don't want them in my browser either, but if implemented correctly, it would just be another feature you wouldn't use. So Vivaldi deliberately not having this feature only hurts people who _would_ find it useful, and thus the adoption of their browser. This is not a good strategic decision. reply Dr4kn 10 hours agorootparentLLMs are difficult to run and very few people have the hardware to run a big enough model to be useful. This means you have to integrate LLMs over an API, which costs you money. LLMs are to expensive for a free browser to just give away free usage. Implementing APIs that you can login with an account and use a specific LLM is a lot of work and difficult to communicate the privacy nightmare that comes with sending that data to some LLM. You don't have to cater to every user. Focusing on things you do better for a huge portion of potential users is a much better decision. If features turn out to be so useful that everyone needs to integrate them to not be left behind you have to do it. LLMs are not there yet. They are to unreliable, expensive and difficult to run locally. In a few years when most users might be able to run decent models locally you can reevaluate that decision reply trog 10 hours agorootparentprevThe opportunity cost of it though, like every major feature decision in a browser, is presumably very significant. What could they be doing that their users actually want? As a dyed in the wool Firefox user, I am of course very used to disappointment about how they direct their development effort. There are a million things I'd rather see them work on than strapping in an LLM. I don't know much about the Vivaldi community but I assume they took this into account when making this decision. reply timeon 9 hours agorootparentprevAnyone who wants that feature can choose from number of other chrome-based browsers. reply imiric 10 hours agoprevI dislike the trend of baking LLMs into browsers as well, but this is not a good strategic decision. LLMs still provide features that users find useful, even if they're not perfect. So if Vivaldi doesn't provide these features based on some philosophical stance, users will just choose another browser. Not that Vivaldi had a significant user base to begin with, but this decision won't help them. reply bubblyworld 10 hours agoparentTheir marketed stance might be philosophical, but it also costs time, money and energy to add LLM-backed features (someone's got to do the inference, for instance). So it could definitely make sense to them for other reasons too, right? reply karmakaze 6 hours agoparentprevWith so many LLMs I thought the least they would do is let the search bar redirect to an LLM of your choosing (preferably with search keyword shortcut). Instead I read this: > So, as we have seen, LLMs are essentially confident-sounding lying machines with a penchant to occasionally disclose private data or plagiarise existing work. While they do this, they also use vast amounts of energy and are happy using all the GPUs you can throw at them which is a problem we’ve seen before in the field of cryptocurrencies. Odd to compare to crypto which only has \"store of value\" as a use. It would be interesting to compare the energy of an LLM doing research tasks vs other means (e.g. a human working 8 hours a day). reply lm28469 6 hours agoparentprev> based on some philosophical stance, users will just choose another browser Aren't most people using vivaldi for philosophical reasons in the first place ? reply linza 10 hours agoparentprevCan you name a few LLM-based features in browsers that users find useful? reply gostsamo 10 hours agorootparentIt is in my screen reader, but it is used mainly in the browser - accessible description of an image without alt text. Translation of languages which I don't know is also nice. Generally, I thing that the llm should be its own service and everything else should have an easy way to connect to it, but I'm a lowly user, not a product manager. reply Dr4kn 10 hours agorootparentFor accessibility it is truly awesome. Yes it can be wrong and isn't perfect, but the alternative is having no knowledge of the image at all. Alt descriptions are often missing or not detailed enough to be useful for vision impaired. Having much better text to voice could also be nice for the blind. While screen readers are fine I don't know how bothersome that robot voice is for longer texts. reply gostsamo 7 hours agorootparentI'm okay with robot voices, tbh. The neural voices need modern hardware, and there is latency even then, together with some artifacts. Especially when speeding through a known screens I prefer responsiveness over fidelity or other nicities. reply ikari_pl 10 hours agorootparentprevone: in Arc browser, if your Ctrl-F find window doesn't find and exact match, it turns into a LLM question box that will try to answer based on the page content reply Dr4kn 10 hours agorootparentcan you at least switch that, because if that is the default behavior I would hate it so much reply maniflames 9 hours agorootparentYes you have full control over when you use ai and when you don’t reply timeon 9 hours agorootparentprevCtrl-F without match is often useful result in itself. I've been burned by LLMs several times where it always came-up with some answer while it was either misleading or there should be no answer at all. reply gherkinnn 10 hours agorootparentprevRename tabs based on website content /s reply stranded22 10 hours agoprevPersonally, I’m not interested in LLM in a browser as a chat bot. I do like Arc with their summary, but I’m not interested in asking questions etc - I’ll use ChatGPT/Perplexity for that. In fact, I’d prefer it not to be included as it’s bloatware. reply benbristow 11 hours agoprevWas using Vivaldi on Android, quite a solid browser. Unfortunately, the lack of AI functionality has made Edge a more attractive browser. Very useful to let AI summarise a large wall of text when browsing Hacker News for example. If only they'd add a 'close all tabs but this one' feature. reply nunez 2 hours agoparent> Very useful to let AI summarise a large wall of text when browsing Hacker News for example This right here is why I'm against LLMs big time. Walls of text are long for a reason. Yes, many of them might have filler. But sometimes there is nuance in the filler that a summarizer will happily throw away. I don't want long form to be Instagrammified --- condensed into a ten-second paragraphs with 40% of the details that perfectly fits an endless consumption model that's perfect for advertising. reply KronisLV 4 hours agoparentprev> Unfortunately, the lack of AI functionality has made Edge a more attractive browser. To be perfectly honest, it’s a good browser. Being able to explain console errors with a click and them adding some resource limit functionality (like Opera GX) are all welcome. I even tried it on my MacBook and it works without issues. I did go back to Firefox later though since I prefer those DevTools otherwise and because a recent update no longer makes Firefox fail to do DNS through my VPN. reply LM358 10 hours agoparentprev>If only they'd add a 'close all tabs but this one' feature. ??? Right click tab -> O ? Edit: oh, you're talking about Edge, not Vivaldi reply benbristow 10 hours agorootparentOn Android reply timeon 10 hours agoparentprevSeems strange that people were damning algorithmic social media walls but are now welcoming preprocessed reality. reply imadj 10 hours agorootparent> Seems strange that people were damning algorithmic social media walls but are now welcoming preprocessed reality. Are they the same people? The vast majority of users are consumers, they don't even think about these stuff, they only complain when the product degrade. I don't see the privacy crowd who were conscious about their data and algorithmic feeds, are treating commercial LLMs products differently. reply benbristow 10 hours agorootparentprevIt's different though, isn't it? Social media walls are the social media sites giving you what they want to show you. AI tools are (mostly) you asking for what you want - albeit you're at the mercy of whatever the AI gives you back, but usually it's what you ask for. reply philipwhiuk 10 hours agorootparent> AI tools are (mostly) you asking for what you want - albeit you're at the mercy of whatever the AI gives you back, but usually it's what you ask for. For now. reply timeon 10 hours agorootparentprevYou have point but still, it is modified reality. reply vidarh 10 hours agorootparentReality is \"modified reality\". There's no reliable way for you to get an unfiltered view of anything. This has been one of the large issues of philosophy since pretty much forever. reply terhechte 10 hours agorootparentprevAll reality is constructed, has been since the invention of media reply Animats 11 hours agoprevLLMs in the browser come across as too much like Microsoft Clippy. Still, things in the Siri/Alexa class have to have some kind of language model. reply Lucasoato 10 hours agoprevI understand this point of view; it's a reasonable action to stop going in this direction if some valid concerns are still unanswered by the industry. At the same time, I suspect that a good part of the people who complain about LLM hallucinating underestimate the human rate of hallucinations/errors. Of course, there are a lot of other considerations linked to topics like accountability, etc.. but take autonomous driving as an example: we don't need self-driving cars to be perfect and do exactly 0 incidents to be a better solution than human driving. They just need to be significantly better than us to be a very useful technology for mankind and let's hope this happens soon. reply Ekaros 10 hours agoprevHonestly, I see no reason why AI should be part of browser itself. If user wants those capabilities they should be free to choose extensions that add them. So they get to choose which AI or LLM model they use. reply redox99 10 hours agoparentIt's pretty nice that a web developer can leverage an offline local LLM, without leaking data, instead of piping stuff through their servers and then OpenAI servers. reply wtcactus 7 hours agoprevI don’t mind for AI helping me browsing. Besides, all other got in the hype anyway. Maybe this way Vivaldi can finally allocate resources to workspaces sync across devices. Only 2 browsers do that: Edge and Arc. And Arc doesn’t work in Linux unfortunately. reply cglong 10 hours agoprevFor people in agreement with Vivaldi, how are you summarizing articles today? I often find content that's not important but also too verbose, and having an LLM summarize it for me is perfect. Right now, I'm doing this very manually, but am actually thinking of switching my browser just to have this capability baked in. EDIT: Since everyone is asking why and how I use summaries, here's an example: https://news.ycombinator.com/item?id=40881021 reply LM358 10 hours agoparent>For people in agreement with Vivaldi, how are you summarizing articles today? I fucking read, like absolutely everyone and their dog did two years ago before this pest stole everyone's attention. reply Ukv 9 hours agorootparentFor fictional/narrative content, sure; reading the Cliff notes version is missing out on the full experience. But for a lot of non-fiction content, I think it's perfectly legitimate and common to have some specific piece of information you're looking to extract, or want a rundown of key highlights. For both, I'd say it could also help in choosing which content to read. Books already typically have a form of summary on the back. If you're researching something, you're going to have to determine which articles are relevant before reading every article top to bottom - and a summary seems helpful for that. reply KoolKat23 8 hours agorootparentprevTo be fair most people don't read it, they read the headline and move on, the oft heavily editorialized clickbait headline. At least there's some semblance of neutrality, on the assumption that the article is correct and the LLM correctly summarizes it. reply pverghese 10 hours agorootparentprevWith summarization, you still read, but have to read less. These days a lot of articles have a lot of verbose content, just to keep a person on the page for a long time. Reminds me of students writing essays just to get to a word or page count. reply philipwhiuk 10 hours agorootparent> With summarization, you still read, but have to read less. Sure, and 10% of the time you get something that's lies which you don't get from actual reading. reply sussmannbaka 10 hours agorootparentprevThese articles provide a better summary than the LLM ever could: they are not worth reading in the first place. reply pprotas 10 hours agoparentprevThe way you ask that question implies that an article summary is some kind of necessity. What happened to just... reading the article? Most of the time, I don't want a summary of an article. If the article is really good and I want to know the most important details, then I should read the article. Maybe I can write a summary myself, so that I can use it for future reference. If an article is bad, then why would I care about a summary? I wouldn't read it either way. There is a a possibility that an article is actually really good, but it's badly written, or way too verbose, or I don't understand the language/terminology/topic. In these cases, a simpler summary written by someone else (or an LLM, I guess...) would be useful. Domain-specific articles or scientific papers would fall into this category for me. Even for this subset of articles, if I don't really understand the topic being discussed, would a summary really give me any benefits? I still don't understand the topic well enough for it to be useful to me. I would get more out of actually trying to read the article and studying the material being discussed. reply cglong 10 hours agorootparentHow do you know if an article is good or not? You have to waste your time reading at least some of it. I've found it useful to have ChatGPT generate a summary, then if the summary sounds interesting, then I read it. reply MrVandemar 8 hours agorootparentPretty easy. Is the headline/topic interesting? Read the introduction. That's interesting? Read the next paragraph. Losing interest? Skim a few para's, pick out interesting headings, illustrations or keywords or skip to the end and see what the conclusion is. This is active reading, not some robo-moron digesting an article, shitting it out and then spoon-feeding the contents of the toilet-bowl back to you. reply agshcxv 9 hours agorootparentprevThere are heuristics developed over time for determining if an article is worth it. Far harder to tell whether ChatGPT is just making things up (it does all the time). reply netmare 10 hours agoparentprevYou are using LLMs to summarize bloated articles probably generated by LLMs. Maybe stop paying attention to such \"articles\" and cut the middleman? reply psini 10 hours agoparentprevCall me old-fashioned but I read the article top to bottom :^) reply comex 10 hours agoparentprevIf I don’t feel like reading the whole article then I skim it. reply monsieurbanana 10 hours agorootparentThat's what most people do I imagine, me included, but we might have to adapt. If more and content out there is just a bit of information padded with unholy amounts of LLM lorem lipsum, there won't be a choice. reply rkwz 10 hours agoparentprevIf you have Mac and Ollama, you can use AppleScript to add summarization to any application - https://www.sheshbabu.com/posts/system-wide-text-summarizati... reply cglong 9 hours agorootparentThank you for actually answering my question :) reply PhilipRoman 10 hours agoparentprev>content that's not important I just don't read it in the first place. reply fileeditview 10 hours agoparentprevOne solution to this problem is to just consume less articles. Just only pick what seems really interesting to you. Will you miss some cool stuff? Yes Will you still encounter time wasters? Yes We are consuming too much and not doing enough productively ourselves. reply lionkor 10 hours agoparentprevWhat kind of articles are you reading where this is useful? I either read articles that are 1) fun to read and silly, or 2) fun to read and informative. If they're not fun to read, it's unlikely that the content is any good. Good educators often know how to write in an engaging way. If the content is difficult to read, or super lengthy, it's probably shit content. How do you judge quality of the information you're given when you have it summarized? How do you make sure the LLM didn't misunderstand something, like sarcasm, or a quote, etc.? reply cglong 10 hours agorootparentHere's the most recent article I summarized: https://daringfireball.net/2024/06/wwdc24_apple_intelligence Gruber has always been loquacious, but this one seemed excessive to me. Still, I was curious for his overall impressions on Apple Intelligence. The summary sounded interesting to me, so I then dedicated time to read the source. To your credit, ChatGPT's summary was much more critical than the actual article. reply lionkor 1 hour agorootparentfair, thank you! reply postexitus 9 hours agoparentprevSkim read, like normal people? reply wildpeaks 9 hours agoparentprevBy choosing data sources that respect its readers, the same way I pick lean code architectures rather than pile on more and more layers that require additional tools to deal with the bloat. reply gherkinnn 10 hours agoparentprevcmd+w for rubbish articles and I read the good ones in full because I enjoy the prose. reply Mistletoe 10 hours agoparentprevI just skim the article if I need a summary. reply JumpCrisscross 10 hours agoparentprev> how are you summarizing articles today? I often find content that's not important but also too verbose Then why are you reading it? You’re conditioning yourself to have a mental corpus of uninteresting, unimportant drivel. At best, that’s a waste of time. reply rsynnott 6 hours agoparentprevI mean, I simply don't read poorly-written needlessly-long articles. This is an option! reply surgical_fire 8 hours agoprevVivaldi user here. I also use LLMs - I subscribed for ChatGPT for a while, now I mostly play around with ollama. I also played around with Stable Diffusion extensively. I think the article is excellent in its analysis and conclusion. As much as I like the recent advancements in Generative AI, I don't think it should be hamfisted in every software, and I also don't think they come nearly close to all the hype surrounding it. It is a useful tool when you understand its shortcomings, and there is a long way to go until they are ready for more widespread use. Good on Vivaldi for taking this stance. reply swed420 3 hours agoparentAgreed. As a long time Firefox user, I replaced FF with Vivaldi on Android and haven't looked back, since FF has failed to address the battery drain issues that so many people are experiencing: https://connect.mozilla.org/t5/discussions/firefox-for-andro... No way bundling a LLM is going to help that matter. I am pleasantly surprised how snappy Vivaldi feels. reply surgical_fire 2 hours agorootparentI use Vivaldi because I used to be an Opera user a long time ago. Absolutely loved it, and Vivaldi leans a bit on the same interface. Firefox is my backup browser. I really like it on desktop, but I agree that on mobile it feels clunky. I see no reason to hamfist LLM into the browser itself yet. A lot of the ideas surrounding LLM seem to be more on the style of devs trying to latch on the latest trend without any proper thought of how useful/desirable LLMs can be on their product. Also, while I don't share the ethical concerns surrounding how LLMs highjacked intellectual property, I think those are legitimate concerns. I have no issues with a dev taking a stance based on it, especially on a product I use for free. reply KoolKat23 10 hours agoprevHave no problem with them not following the trend, maybe even a good thing. Their reasoning is shoddy. Misunderstands LLM's and plagiarism is of no practical concern to a browser, may as well remove the copy function from the browser if that's the view, theres also use cases where hallucinations don't matter such as the AI tab sorting and semantic search. He should've just said they don't see the value in it and left it at that. reply kolinko 10 hours agoparentNot sure why you get downvoted. The article indeed has only very shallow critique of LLMs. reply KoolKat23 9 hours agorootparentI've noticed lately many people here tend to hate on LLM's and downvote any dissenting opinion into oblivion without a reply. Could be the copyright-LLM-bad crowd or luddites, who knows. /s reply egorfine 10 hours agoprev> such text being baked into the model means that it is possible to cause it to output the same text verbatim unlike humans, of course. reply krapp 7 hours agoparentI don't know what this is meant to prove or disprove, I can only assume the constant urge to compare human beings with LLMs has simply become a pathological drive at this point. Yes, humans are capable of reproducing copyrighted text verbatim, as are LLMs, and when they do, as with LLMs, it is copyright infringement and plagiarism. An irreducible and unavoidable tendency towards committing copyright infringement and plagiarism are not features one generally wants in either a human author or a piece of software. reply egorfine 6 hours agorootparentIt means that if LLMs mimic humans in learning and creating, then we should probably apply similar standards to LLMs. It is impossible to create an LLM without training it on copyrighted text. Just like in humans. Should the world refuse to use LLMs because of that? reply chad1n 10 hours agoprevI don't use Vivaldi, but I think it's fine on their side to avoid falling into this AI trap. You have to consider that there were 2 possibilities, they used their API key to send requests to openai/claude or they did what Mozilla did and integrated gemini/chatgpt at the expense of the user data, both of which are pretty scummy and barely help the end user. The only way to integrate AI fine into browser is to ship a model to run local, but that would require the user to have the computing power to run it. Google is trying this with chrome by integrating gemini mini in the browser as a 100mb blob. reply pantulis 10 hours agoprevI think this is the correct move. The correct one (and I'm not sure if this is feasible) would be integrating the OS level LLM facilities. AS an independent browser vendor, trying to chase the AI trend mirage is like trying to empty the ocean with a bucket. Still, there is some marketing damage control dismissal of LLMs in the note that could have been avoided. reply langsoul-com 10 hours agoprevSmart. There's already llm extensions so anyone who wants it can add it. reply quotemstr 10 hours agoprevMy browser should be my user agent, not my user nanny. I don't want it depriving me of features or working against my interest, ever, on the grounds that the browser author's personal opinions on the social impact of various technologies. reply OccamsMirror 10 hours agoparentWhat features are Vivaldi depriving you of by not including an LLM? reply lionkor 10 hours agorootparentBS (business speak) generation reply LocalH 5 hours agoparentprevIf you really want generative AI in your browser, go use one of the many browsers that are chomping at the bit to get in on the AI fad. reply asmor 10 hours agoprevThe AI hype relies on most common people misunderstanding what's in front of them. I've seen business people write prompts. They don't understand the limitations or strengths. They tell the model it has a degree in something, they tell it not to hallucinate, they anthropomorphize it so far that they greet it in the morning \"to get into the mindset that you have a virtual colleague\". All the people who fearmonger about AGI really don't help, because it implies our LLMs are anywhere close to sentience. They're not. reply jabrown 11 hours agoprevWhy the word order in this sentence is weird? reply bool3max 10 hours agoparentI guess the question mark at the end makes it weird, with a period it would make more sense, to me. Why Vivaldi won't follow the current AI trend(.) ---> the article explains why Vivaldi will not follow the trend. Why (won't) Vivaldi follow the current AI trend(?) ---> someone's wondering and asking why Vivaldi will not follow the trend. reply julienmarie 10 hours agoparentprevAuthor is francophone (Belgian). This explains the order of the words. The french order would be the same \"Pourquoi Vivaldi ne va pas suivre l'actuelle tendance IA\" reply jabrown 8 hours agorootparentI figured as much, but is English proficiency no longer a requirement for writing articles on an organization's official English-language website? reply nhinck3 10 hours agoparentprevIt's the question mark that is messing it up. reply jebronie 11 hours agoprevThank you for protecting me from \"misinformation\", said no thinking person ever. reply DarkNova6 11 hours agoparentMaybe that’s the problem. reply bottled_poe 11 hours agorootparentWe’re trying to deprecate the brain. reply DarkNova6 10 hours agorootparentI'd be curious to hear how you guys are trying to achieve this. reply exe34 10 hours agorootparentprevYes, I want somebody else to control my intake of information for my own good, because I am not intelligent enough. /s, because this is the internets. reply DarkNova6 10 hours agorootparentStatistically speaking, maybe you are not in the minority. Given that the vast amount of people get their information from social media and take it verbatim. reply arunharidas 11 hours agoparentprevInformed individuals prefer not to have corporations shield them from potential misinformation. reply nhinck3 10 hours agorootparentDoing your own research has lead to an incredible advance in public intelligence. reply JumpCrisscross 10 hours agorootparent> Doing your own research has lead to an incredible advance in public intelligence The situation is analogous to war reporting. War hasn’t become more brutal (holding scale constant). We just see it more clearly. Similarly, I don’t see evidence we have more morons. They’re just given more attention. reply notachatbot1234 10 hours agorootparentprevYet there are too many non-experts thinking they \"did research\" and then go on to ignore medical or political facts. Those people are easily influenced by adversarial misinformation to incite hate and anger for political warfare. reply nhinck3 10 hours agorootparentI agree, I guess I could have made my reply more sarcastic. reply arunharidas 10 hours agorootparentprevNo! we should trust the government and the corporations to guide us to the truth. reply UrineSqueegee 11 hours agoprevthat just screams \"I don't know what this technology is and I am too afraid to use it\" to me personally. Don't use it as a source of information if you don't want it to spew hallucinations to the user? There's about a million other uses for LLMs. reply pjerem 10 hours agoparent> There's about a million other uses for LLMs. Ok. But in browsers ? reply _flux 10 hours agorootparentSummarizing web contents without requesting the summarization from a cloud service? reply KoolKat23 10 hours agorootparentprevSemantic search, browser tab sorting are two examples of use cases. reply surfingdino 10 hours agorootparentHahaha... search is essentially a solved problem if you are literate and work with well-structured data sets. The market for a tab sorting solution is zero. reply KoolKat23 10 hours agorootparentI didn't say there aren't alternatives. Search datasets still are not really semantic search, and I'd wager many require online search if they required a well structured dataset, or a dumbed down query. You only have to look to the relative popularity of something like Arc browser to determine there is a market for such things. reply philipwhiuk 10 hours agorootparent> You only have to look to the relative popularity of something like Arc browserwas made by having many (underpaid) people to look \"underpaid\". I wonder what this has to do with the discussion on how LLMs work. I'd like to know more why does Vivaldi team thinks these people were underpaid, how do they know how much per hour they were paid and what would be a fair price for the job according to Vivaldi's evaluation of the scope. I'm really interested to know how did the Vivaldi team conclude that OpenAI forced unwilling people to do the work while paying less than what these people expected to receive for their time. And most importantly. What does this have to do with LLM integration in browser? reply minasmorath 10 hours agoparentAt a glance, it feels more likely to me that they're criticizing training LLMs on content without compensating the original creators, not the salaries of OpenAI engineers. It's a pretty common moral / ethical stance to take now. reply pleurotus 9 hours agorootparentI think this is what they are referring to: https://time.com/6247678/openai-chatgpt-kenya-workers/ reply minasmorath 9 hours agorootparentThat seems more likely than my initial interpretation, in which case the moral and ethical implications just so you can have a \"Summarize with AI\" button or other such features in your web browser are obviously much worse. reply egorfine 9 hours agorootparentprev> It feels more likely to me that they're criticizing training LLMs on content without compensating the original creators, No, the phrase they have written specifically talks about the RLHF workers and they do evaluate the pay of these people and somehow bring this issue into the discussion of how LLMs are useful to browsers. And because I'm being downvoted for asking a simple logical question whether this has anything to do with LLM features in browser, I logically conclude that there are some things in current American culture that I literally (literally!) don't understand. reply novaRom 11 hours agoprev [–] A perfect place for multimodal Assistent would be in Operating System's GUI. So that it sees and hears the same as its human user. reply diffeomorphism 11 hours agoparentThat is called windows recall and it flopped so hard that it was not even launched. reply redox99 10 hours agorootparentThat's because it NEEDS to be local. reply freeqaz 10 hours agorootparentprevGot a source? Would love to get the tea! reply diffeomorphism 8 hours agorootparentLots of news articles about that, e.g. https://www.theverge.com/2024/6/13/24178144/microsoft-window... reply quotemstr 10 hours agorootparentprevIt was killed by fear-mongering, a common cause of death for new technologies. (Remember the press fomenting a moral panic over Google Glass?) The idea is sound and will be part of our normal day-to-day computing experience in the future. reply 9dev 10 hours agorootparentRight. Having a plain SQLite database with everything you do on your computer accessible to any program you or Microsoft run on your machine isn’t a problem at all? That open source utility you installed and forgot about that can now gleefully compile statistics on your porn usage and threaten you to send them to your spouse, whose email address and phone number it was able to pull from that same database, unless you pay a few bitcoins-that isn’t an issue at all? The fact that this was enabled for professional users handling your patient records, insurance details, personal finance, or your stock trades and make all that available at a whim, that is nitpicking? The TLS-encrypted API calls Windows computers make to Microsoft servers multiple times per day, any of which could include data from that database as anyone at Microsoft sees fit, they are paranoia? Just because we can doesn’t mean we should. reply quotemstr 10 hours agorootparent> Right. Having a plain SQLite database with everything you do on your computer accessible to any program you or Microsoft run on your machine isn’t a problem at all? We're way beyond the days when every program you run has equal access to all your data. These days, different programs have different levels of data access. reply 9dev 2 hours agorootparentAre we, though? If I run an application as a normal user on Windows, it will run with my user account's privileges. And even if Microsoft put special care into the permissions on the database file—it's not like your typical Windows user wouldn't carelessly accept any UAC dialog they are presented with… reply diffeomorphism 1 hour agorootparentprevYeah, about that... https://www.zdnet.com/article/ethical-hacker-says-his-window... reply Barrin92 10 hours agorootparentprevThere was no fear mongering involved. Google Glass was an objective privacy nightmare just like Recall and in fact not just to the user, which could theoretically be defended as choice, but importantly to others. You're basically exporting surveillance as an externality with recording technologies that by design collect everything around them. These technologies were basically multi-modal keyloggers. reply freehorse 11 hours agoparentprev [–] Like learning your passwords? reply drd0rk 10 hours agorootparent [–] So you don't have to anymore! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Vivaldi has decided not to integrate Large Language Models (LLMs) like ChatGPT into their web browser, citing concerns over plagiarism, privacy violations, and the generation of inaccurate information.",
      "LLMs analyze vast amounts of data, which can lead to the unintentional regurgitation of copyrighted material and the disclosure of private information.",
      "Vivaldi aims to provide a feature-rich and ethical browsing experience, remaining open to future machine learning advancements that prioritize privacy and usability."
    ],
    "commentSummary": [
      "Vivaldi's decision to avoid integrating AI, specifically Large Language Models (LLMs), has generated significant debate among users.",
      "Supporters of Vivaldi's stance highlight concerns about LLMs' reliability and high energy consumption, while critics argue that LLMs provide valuable features that could benefit users.",
      "The article explaining Vivaldi's decision has been criticized for appearing biased and dismissive of the potential benefits of LLMs, with many advocating for AI integration to be an optional feature in browsers."
    ],
    "points": 124,
    "commentCount": 154,
    "retryCount": 0,
    "time": 1720161984
  },
  {
    "id": 40879899,
    "title": "“Technical” Skills",
    "originLink": "https://sashalaundy.com/writing/technical-skills/",
    "originBody": "A recent example in the wild. The specific tweet doesn't matter, this language is everywhere in Silicon Valley The practice of dividing human beings into \"technical\" or \"not technical\" has annoyed me for more than ten years, but I've struggled to articulate why. It took a movie about rock climbing, a historic run by the Golden State Warriors, a broken sewing machine, and a serendipitous Slack comment, but I finally put my finger on it. And it's probably not what you think. I'm going to define \"technical\" skills and then make the case that they're everywhere and severely underrated. Handwaving over them allows us to dismiss the work of wide swaths of the population. And noticing them will light up your life and unlock new worlds. ❧ The specific moment that forever changed how I saw this came right at the end of the movie Free Solo. It's about the first person to climb up El Capitan without any kind of rope or safety device. As the credits rolled, my friend Sam said something offhand like \"it was so cool to see the technical details.\" I must have looked blank, because they elaborated: \"you usually never get to see behind the scenes and exactly what it takes to prepare to do something that hard—the mental prep, what he eats, even how he positions each finger.\" This was a major 🤯 moment. Like the arrow in the Fedex logo, it's one of those things that you just can't unsee. See the arrow hidden in the Fedex logo? Photo by Obi - @pixel8propix on Unsplash We usually see the finished, polished work. Or a sanitized \"making of\" montage. But you so rarely get to see what goes into the final work. That's discussed behind closed doors, between practitioners and their coaches, off the record. Which is such a shame, because it's so darn interesting. For instance, the Steph Curry mystery. He is electric: he's been league MVP twice, lead his team to four championships, and is so good at shooting that he's changing the way modern basketball is played. The mystery is that he didn't start out that way. Sure, he was good enough to get drafted into the NBA, but he was drafted seventh—after two other point guards! Even his dad didn't see it coming: “In Chicago the other day I saw LaMelo Ball's dad at the game wearing a hat that said: I Told You So,” said Dell [Curry], mentioning the bombastic father of LaMelo and Lonzo. “Well, my hat would say: I Had No Idea.” So how did Steph Curry go from a decent NBA shooter to the best all time? Sure, his dad was a pro, he played from a young age, and he had access to coaches—but so do lots of other players who stayed average, including (sorry, Seth Curry!) his brother. What factors and tactics go into that kind of breakthrough? Also consider that movie, Free Solo. I admit, I thought it was going to be a boring movie. It's about an incredibly risky climb, and I already know the ending: he did the climb and he did not die. But reader...I was riveted and my palms were sweaty. How on earth did the filmmakers do that? So many technical elements must have gone into it—pacing, music, graphics, etc—but I can't even point to them, let alone know how to do them myself. ❧ In software, we have this tempting verbal shorthand. We find ourselves saying things like \"she is really technical\" or \"he is not a technical manager\" or \"they didn't pass the technical screen.\" But we only ever use these terms to refer to some underspecified cluster of computer programming or software engineering skills. And people without these skills are labeled \"not technical.\" But if \"technical skills\" are the skills we use to produce our work (good software) then by extension, every field has \"technical\" skills. They're simply the skills used to produce the work. Do you know how to frame the story of your product so it resonates, how to figure out what customers want, where and how to put something in a customer's path, and how to tell if it worked? Marketers do. Do you know how to tell if someone is a good prospect, which people to call first, and what words to use when they're giving you the runaround? Sales people do. Do you know how to defuse an entrenched argument between coworkers, help a burned out coworker get out of a rut, or tell someone they're not doing a great job without making them furious? Managers do. Even something as squishy as \"good conversationalist\" can be broken down into component technical skills, that can then be noticed, admired, emulated, and honed. For instance, great conversationalists know how to: prepare before conversations ask really good questions make others feel heard (note: this not the same thing as \"listen accurately\") handle a conversation partner who doesn't ask you questions back Just like any other skill, it's one you can break down into pieces to learn and practice. ❧ There are a few major benefits to noticing and unpacking others' technical skill sets. It makes your world more colorful Seeing great work is nice, but seeing great work and understanding how hard it was to make is sublime. It lets you appreciate the excellent song, jump shot, or sales call at a new level. Ignoring the technical skills all around you leads to a duller, more impoverished life. It's simply more interesting to look around with these glasses on. It helps you learn To learn a new thing you have to know there is something to learn. If you think that being a good conversationalist is something you just weren't born with, why would you ever try to improve? And if you can't see someone else's greatness, why would you ever think to learn it too? Noticing new skills is a key component of a growth mindset and a prerequisite to learning. You won't unwittingly reinforce unpleasant power dynamics We often dismiss skills that are not societally valued by pretending they are not skills. Or, sure, maybe they're skills, but they're mysterious and ineffable! You reinforce this idea each time you say \"soft skills\" instead of working to enumerate them. Perhaps you mean \"interpersonal skills,\" \"leadership skills,\" or \"communication skills.\" These are all technical skills, and they all have names. You're part of this dynamic if you've ever used strategic incompetence, which is when you let yourself believe that doing laundry, taking meeting notes, or organizing a birthday card for a coworker are things that some people \"are naturally good at\" and you are \"just not good at.\" Real talk: no one is born knowing how to do these things. They just figure it out and ship it, and you can too. And consider the \"maker movement,\" which, in my most frustrated moments, I call \"arts and crafts, but for boys.\" The \"movement\" has been careful to highlight its technical skills to position itself apart from similarly technical fields, like sewing. You can probably list the \"maker\" technical skills: electronics, power drilling, cool robots, etc. But can you list the technical skills for sewing? There are a lot. Let's look at only structural choices, not even going into aesthetic and design skills. You need to pick the right pattern, then pick the fabric that will work structurally for your particular garment. You need to understand the body you are making it for, and the exact complex 3D shape that will fit and flatter them (which in turn requires a 4D understanding of how they'll move, the physics of gravity, and how all that interplays with your fabric selection). Then you need to set up your sewing machine, an inscrutable piece of technical machinery that comes with mineral oil, a screwdriver, a parts catalog for repairs, and a detailed technical manual with lots of component diagrams. When your thread gets tangled, you need to reason about how the machine works to debug it. Then you need to cut things to exactly the right size and assemble them in the right order, and do it skillfully so they hold together while being worn and washed and otherwise under duress. And there are advanced technical details that make the difference between \"where did you get that?\" and \"oh, did you make that?\" And if you want to make something out of t-shirt fabric, that's an entirely different set of equipment and techniques—so much so that the majority of sewists avoid it entirely. My point is: sewing is very technical. And we can ONLY write sewing off as \"just arts and crafts\" and unimpressive compared to the Maker movement if we choose to ignore that sewing is very technical. Likewise, we can ONLY write off marketing, sales, management, design, product, HR, etc etc etc etc as less important because \"they're not technical\" if we choose to ignore that they are very technical. This distinction isn't just about semantics. It's also about value. Erasing technical skills lets you erase value. Erasing technical skills lets you erase value So where does this leave us? Please let me know in the comments if you have ideas for terminology options to replace \"he is not technical\" or \"technical skills\" when we're really talking about software skills. I got feedback from a few readers that they like this argument, but it was useful shorthand, and now they're sad because they're not sure how to be more specific. Fair! Let's brainstorm some options. ❧ Thanks to early readers for their encouragement, feedback, and critique, including a Slack user named Angélique, Laura Duane, Nick Seguin, Laura Lindzey, Fabian Tamp, Zach Lipp, Mindy Preston, Adam Kelly, Alex Chen, Stephanie Losi, Aditya Athalye, Emily Vomacka, Erika Rowland, Marilyn Cole, and probably others that I am forgetting now three months after its original writing. I've heard from so many people that they loved and continue to reference this piece, and I'm not sure I would have left it up without your early reactions. Thank you! This article was first published in April 2024, and edited for examples, tone, conceptual precision, and structure in July 2024. Its main points have not changed. COMMENTS",
    "commentLink": "https://news.ycombinator.com/item?id=40879899",
    "commentBody": "“Technical” Skills (sashalaundy.com)102 points by todsacerdoti 14 hours agohidepastfavorite104 comments skrebbel 12 hours agoWhen a coder asks another coder whether a boss is technical, it just means “can they code?”. There’s not much more to it. You may not like this, but it’s how the word is used, and language is defined by usage. I don’t like that y’all use the word “crypto” for get rich quick schemes either, but I suck it up, the ship has sailed. This whole hair splitting about the real meaning of the word “technical” adds little. Yes, people who are good at what they do, whatever it is, are good at it and thus have technical skills. This doesn’t change anything about what the coder means when they ask if the boss is technical. We all know what they mean. They mean “can they code?” reply ericmcer 11 hours agoparentIt’s not even a tech thing, there has always been a distinction between a leader who climbed the ranks and someone who jumped directly into leadership (whether from education, nepotism, whatever). It is important to know which kind you are working under. reply jrs235 16 minutes agorootparentFor example the military: enlisted vs commissioned officers. reply eru 11 hours agoparentprevAt least that's the meaning in a generic software company context, yes. More generally, I would declare anyone who does anything with engineering or numbers in it to be 'technical' in this vague sense. But details depend on context. Eg if you work in a bank, some quants might be very technical (and be seen as such) without necessarily programming. reply leonth 9 hours agoparentprevThe same mentality everywhere, really, not just software. Doctors ask \"have you ever treated a patient?\" Pilots ask \"how many flights have you flown?\" reply satisfice 6 hours agorootparentWith pilots it’s flight hours, type ratings, kinds of planes flown. reply DasIch 10 hours agoparentprevI would also add that what the question really really means is \"Do they understand what we and I are doing here? Do they understand what they are asking of me? Can they emphasize with me?\" That's really important. It's annoying to constantly have to explain and justify basic things because people in power don't understand what the workers are doing. I'm also pretty sure that's true regardless of who you are, which company or industry you work in and what you do, you'd prefer to be lead by people who understand what you are doing. reply smackeyacky 9 hours agorootparentIt’s important for a technical manager to be able to effectively advocate for their programmers. Otherwise you just get constantly railroaded by the high priests of sysadmin or devops into technical decisions that make no sense. My manager is not technical. The work environment is shit. Just a constant stream of brotherhood decisions that don’t work you are supposed to deliver systems into. The whole thing is bloody stupid but if our manager had a clue it wouldn’t happen. Before you ask, yes we try but the stupid bugger can’t stick to a script despite how easy we make it because the other managers constantly pull him into the suck of what suits everybody else rather than what works. I hate the bastard. reply netdevnet 8 hours agorootparentprevYes, this is it. The goal of the question is \"Do they understand what we and I are doing here? Do they understand what they are asking of me? Can they empathize with me?\". And the meaning is simply if they have programming skills. The article makes it sound like it the usage implies some devaluing of those who are not technical which is not the case (outside tech bro culture) reply kiernan 5 hours agoparentprevHave they been in your trenches, and lived to tell the tale? reply sergiotapia 12 hours agoparentprevcorrect. I've always used and heard other people use this word with this meaning. reply danielovichdk 10 hours agoparentprevIn this context I have seen more than once that it's more often a cargo cult thing \"is this person one of us or is he an outsider not understanding how great we are, and how do we make sure we convince him our skills are better than his\". Programmers are often very proud. Too proud to accept other people's skills. That's arrogant and unintelligent. Stupid even. reply wisty 10 hours agorootparentNon-programmmers are also often very proud, and also devalue things they can't do, so even if there's no technical issues that the boss needs to understand (e.g. if there's conflict or trade-offs) then this could be an issue. reply jchw 13 hours agoprevTo be honest, I don't really think it's actually that deep. Usually, the purpose of the distinction in this context is just useful to convey if someone is skilled in software engineering specifically. For example, when I hear \"technical manager\" in the context of programming, I think of \"the type of manager that weighs in and leads 'technical' decisions directly\". This distinction is pretty important for the expectations to be set right, so throwing ourselves into another euphemism treadmill feels like a bad idea, this always leads to a lot of confusion for questionable gain. I'd rather we just tried to make people value \"soft skills\" more if the problem is that people do not. reply lucianbr 12 hours agoparentSeems like the author just doesn't understand what people mean when they talk about a manager being technical or not. I don't think anyone means \"this person has no depth of knowledge about anything\". We just mean \"they don't know programming\", more or less. Lots of words making a point nobody contested. reply qsort 13 hours agoparentprev> we just tried to make people value \"soft skills\" more if the problem is that people do not. If reply xnickb 11 hours agorootparentIf this is meant sarcastically, I'm happy to report that most places I worked at valued \"soft skills\" much more than \"hard skills\" during hiring. The rationale was: there is no use in your hard skills in our environment if you can't communicate and collaborate. reply qsort 11 hours agorootparentI meant it semi-sarcastically but you don't seem to disagree? It doesn't seem to me like \"soft skills\" are particularly in need to be valued more than they currently are. I would argue that the opposite is often true -- perfectly good developers being undervalued because they aren't assertive enough to \"sell themselves\". reply johnnyanmac 11 hours agorootparentprev>I'm happy to report that most places I worked at valued \"soft skills\" much more than \"hard skills\" during hiring. varies a lot per company. But places lately have definitely skewed towards \"hard skills\". Training in my industry was always a joke, but they basically want 5YOE out of college these days. IDK if I would have gotten hired at any of my previous roles if this mentality was present 8 years ago. reply Jensson 8 hours agorootparentThat is because the people with soft skills that are paid well need people to get things done, so they go and hire cheap people with hard skills. That is how it works at every single company, the people with soft skills are paid the best and rule over those with hard skills. reply danaris 7 hours agorootparentprevThe problem is, so many \"soft skills\" are things you can claim to have—and maybe even think you have—but can't actually be meaningfully tested in an interview setting. Things like leadership, creativity, collaboration, ability (and drive) to learn new things quickly. Basically the only ones you have a chance at demonstrating in an interview are communication (within limited parameters) and problem-solving (assuming the hiring team knows how to put together a problem that's well-calibrated for the type of candidate they actually want). And even those can easily be thrown off by the extremely high pressure of an interview. reply Terr_ 13 hours agoparentprevYeah, it's not that I don't believe the hidden fractal nature of human knowledge where all modern problems are deeper than they first appear--It just happens to be the established jargon among software companies for software stuff. reply DarkCrusader2 12 hours agoprevThese kinds of articles which endlessly dissect semantics give me similar energy to the trite gymnastics many speakers do like assigning numbers of letters of a words and adding them to make a point. Or finding substrings in a word (leadership is a ship). Context of our language matters. I wouldn't call my engineering manager technical in my software company just because he is really good at sewing. When program managers are called PM or TPM, there is a reason and function to it. Also felt weirdly sexist tones in the article, if men do it it's making but if women do it is not technical? Who is saying this? Where is the straw man coming from? Non technological skills are definitely called technical in every field from film making, arts, painting, music construction, cooking, wood working, metallurgy, industrial production etc. Is the article based on solely on opinion of few ignorant people? It goes both ways. No one is denying that things like sewing, crocheting, hell even putting on makeup takes skill and practice. People similarly are ignorant of \"technical\" skills too. I have been asked so many times about what is so special about typing colorful text in a window all day. Or why I can't hack their ex's facebook. reply fargle 1 hour agoprevdisagree with this. there is clearly a difference between \"technical\" and \"non-technical\" people. the definition \"technical people\" are using when they make that distinction is close enough to 1a of Webster: \"having special and usually practical knowledge especially of a mechanical or scientific subject\" now, it's fine to be non-technical. but don't try redefine \"people-people\" as \"technical, but in a different way\". part of being a good manager of technical people is to understand the distinction and the different way they think. i've had great managers and leaders that were technical people that became managers. and the very best managers i've had were non-technical people that were extremely skilled leaders. they grew to understand, trust, and manage technical people. they knew the difference and thrived by providing complementary viewpoints and skills. but i've seen a whole lot of amateur politicians that didn't really understand people as well as their supposed expertise was touted to. they don't have strong technical skills or even the right mindset, so the recast themselves as being good at other things instead (if not good at engineering, they must be good at management, right?). they chafe at people calling it \"soft-skills\" or \"non-technical\". they use analogies like basketball a lot (and sewing, and rock climbing). to try to equivalate a technical engineering mindset to the way the author thinks is a tell that they don't understand the difference at all. the attempts to change the reality by changing language. mis-ascribing phrasing as some kind a value judgement or slight. all of this tells me this person is not as skilled in technical fields OR with people as they think they are. [1] https://www.merriam-webster.com/dictionary/technical reply AttakBanana 12 hours agoprevI agree with most of the article. There's a part of the world that makes a distinction between \"technical\" and \"creative\" which bothers me even more. Putting yourself or someone else in a bucket of \"technical\" or \"non-technical\" creates a subconscious barrier to expanding your skills beyond your label while also giving you an excuse, and others the same low expectations. It is also a gray area I feel. Is writing efficient code a technical skill, while keeping maintainable or readable a soft skill? The difference seems similar to me. I might be totally off here, but having a distinction has always felt weird to me. reply krisoft 9 hours agoparent> There's a part of the world that makes a distinction between \"technical\" and \"creative\" which bothers me even more. Depends on context of course. In game dev someone who is \"technical\" can be asked to make the FPS higher during the boss fight, but can't be expected to re-sculpt the boss to make them look more muscular. Someone who is \"creative\" goes the other way around. Someone who is \"creative\" uses blender/maya/z-brush/photoshop to solve problems, someone who is \"technical\" uses a text editor/compiler/debugger/profiler. It is a very different role. Some can do both, which is great of course, but pretending that everyone is a unicorn will not make happy outcomes. > Putting yourself or someone else in a bucket of \"technical\" or \"non-technical\" creates a subconscious barrier to expanding your skills beyond your label while also giving you an excuse, and others the same low expectations. Or describing someone's skills accurately they can figure out what they could be improving on. reply atoav 12 hours agoparentprevAs a guy with an MA in fine Arts who now leads a technical job I think this is an arbitrary decision. I would draw the line differently. The line needs to be between people who have to care about how things work and people who are not willing to or don't have to care. If you are in a tech company ideally everybody cares to some degree about the product. And caring about the product means understanding the different alternate-reality versions of that product and comparing them. And that requires some technical knowledge. If you're the janitor or the security at that company that does not apply to you. If you are running a team, guess what. reply surfingdino 12 hours agoprevMy heart sinks every time a \"non-technical\" manager has opinions on technical matters and makes decisions based not on the case presented by the technical team but on made up stories told by other managers, architects, and consultants. I spent a decade fighting with those types to deliver good work and do the right thing, but they have worn me out so I switched to pure dev work. At this point I am undecided as to whether a non-technical manager is worse than a \"slightly technical\"() one. () - has a iPhone and an X-Box which in his mind qualifies him to make decisions on backend architecture designs. reply pm90 11 hours agoparent> but on made up stories told by other managers, architects, and consultants. Even more annoying: blog posts. Sometimes I wonder how is it that these folks are unable to see how fundamentally wrong and clueless they are. What I've noticed is that many of these folks aren’t very good listeners. Im currently working under such a manager and it’s really exhausting to have to have the same arguments repeatedly. reply koonsolo 11 hours agoparentprevA good manager is at the service of the team, not the boss of the team. The main reason is that the expertise is at the bottom layer, not the top. Any good manager realizes this and know (s)he will have to trust the team. reply grose 12 hours agoprevAgreed that sewing is \"technical\". Imagine you're an artisan seamster and your clueless boss (zero sewing experience) says stuff like \"go faster, it's just putting the needle in the hole isn't it?\" or \"can't you just tape this part together to meet the sprint deadline and do the sewing stuff later?\". reply jaggederest 12 hours agoparentWeaving is even more technical. The origin of computer science. I have a significant fondness for warp and weft and remembering which iteration you're on through the pattern Similarly with knitting, to a slightly lesser degree. Arguably using even more spatial reasoning since you're working with an entirely soft medium. reply changexd 11 hours agoparentprevI have always been a fan of fashion, but I just think those designer clothes are too expensive, one day I thought \"huh I should probably make my own thing, it couldn't be that hard?\", I was wrong, DEAD WRONG!, I had no clue how to sew, after digging a bit deeper of \"pattern making\", I realized that being a consumer is good enough :) I don't mind spending 200 USD on something that may take me years to make and design reply lomase 9 hours agorootparentIt is like software, the hardest part is to learn all the related skills you need. reply Ekaros 11 hours agoparentprevI have zero experience in tailoring, but I have seen some patterns and they are not straight... You cannot just ask so can we get square piece of fabric and cut hole in it? And then later demand answers why you did not get fitted suit... There are reason why things are done in specific way and in specific order. And understanding those are technical skills. reply lifeisstillgood 13 hours agoprevI am writing a book the premise of which is “software Literacy” - the ability to code is a major inflection point. You may, 100 years ago have been a brilliant solider / seamstress/ sailor / sushi chef but if you were illiterate you were at significant disadvantage - and I believe the same is true today for software. The “technical skill” everyone talks about is coding - and it matters. The desire to arrange the world so it can be iterated over, the … I don’t know the difference between someone who understands a three act structure and story arc and someone who has never read a novel is a big gap reply a-dub 12 hours agoparent> The “technical skill” everyone talks about is coding not really necessary or sufficient in many cases. the real question is whether or not someone has the background and interest to understand the details at hand and how they fit together. reply atoav 11 hours agorootparentI would say so as well. I would take a manager who can't code, but is a car mechanic nut in his spare time over one who can code a bit, but has no private interest in anything vaguely techological 7 days a week. The important bits about technological choices translate somewhat well between domains. A shitty overly complex motor looks impressive on the blueprint, but it is a shitty overly complex motor. reply gabesullice 11 hours agoparentprevHmm, only if 'coding' is very broadly defined? I suppose you feel you could understand the technical details of another software engineers architecture if they explained it you, even if it were written in a programming language you don't know and without reading the code? If so, it's probably because you understand the features and limitations of volatile memory, persistent storage, networking, and parallelization. Which suggests its not necessarily 'coding' that matters. Learning and writing lots of code is a surefire way to become familiar with those things, but I think it's possible to become familiar with them by different means. reply satisfice 6 hours agoparentprevThe ability to code is not generally important, and in no way is comparable to literacy. Coding skills are different depending on the language and the kind of language, but what they all have in common is the ability and patience to think algorithmically: step by step, in terms of relevant primitive operations. You don’t need ever to have written code to be able to think algorithmically, and the ability to think algorithmically does not translate into the ability or willingness to think critically about complex systems. reply acureau 4 hours agorootparentAgreed, actually I'd say the practical value of learning to code for the average person has been declining for some time. It is easier than it ever has been to get computers to do what you want. I think it will continue to get easier. The whole idea that programming is a life skill may have had some merit years ago, but I don't see it anymore. reply shalmanese 12 hours agoprevTo me, \"technical\" in this context simply means how many layers of abstraction are you capable of piercing together with me? I'm 20 years removed from any deep technical work at this point but I'm quite thankful that my CS degree's philosophy was that by the end of the program, you should be able to sketch out conceptually what's happening on a computer from electrons on a wire to how users react to your UI (basically, Nand2Tetris before Nand2Tetris). I've forgotten the fine details but that conceptual stack still exists in my head and it's an asset I'll always have. There absolutely are many amazing managers of tech teams that are deeply non-technical and rely on their mastery of the abstraction layers they can grok to drive effective team performance. But there's also many times where the details do matter and the ability to dive deep into the guts of minutiae is an enormously valuable tool in your toolbelt. Management is a diverse set of skills and every manager rolls a different set of attributes on your character sheet and nobody is a 10 across the board. The art of management is to figure out what differentiated management style works with your character stats and build a team/environments to buff your strengths and make up for your weaknesses. But the kind of technical knowledge you get from a solid CS education is too time inefficient to learn on the job and so there's real value to in absorbing it as much as you can in an collegiate setting. reply fhd2 11 hours agoparentI tend to use \"conceptional skills\" to describe someone's ability to understand a complex system. When hiring - especially for roles like \"technical product manager\", I could care less about \"coding experience\". CS education is a plus for sure, 1-2 years coding too. But beyond that, I feel the conceptual skills are far more relevant. How much modelling can someone do in their head? How quickly? How honed is that ability in them? Sounds like your university trained your conceptual skills, that's awesome. Other people train them through other means, consciously or not. Hiring even developers with lots of experience but low conceptual skills has mostly been a disaster for me in the past. The same goes for \"technical something\" roles. Programming experience can be a bit of a red herring for those actually. For the most part, my \"technical\" interviews go into conceptual skills and motivations. That's the stuff I really need to know to decide whether to hire someone. Some language/tool/framework, they can learn quickly, given conceptual skills, motivation and _some_ programming experience. (Disclaimer: I primarily hire generalists as FTEs. For specialist skills, I prefer to hire freelancers temporarily, where I focus on what exactly they can do today.) reply shalmanese 11 hours agorootparentTo me, the two ideas are slightly orthogonal. Conceptual skills are cross-domain applicable and is a good measure of your ability to gain new technical skills whereas \"technical\" in the context I'm using it refers purely to your ability to pierce abstractions in the domain you're working in. eg: I would be confident stepping in as a technical manager in a software team but if I were to work in eg, aerospace, I'd still have strong conceptual skills but I'd be distinctly non-technical. There's a pretty shallow set of abstraction layers beyond which, I just don't have the education. If I were to go back to school for aerospace engineering, I'm sure my strong conceptual foundation would mean I could master the material 4x faster than anyone else but it would still be a lot of grinding work doing the math and using the software and building prototypes and testing so I could learn. And like, at this stage in my life, the ROI simply cannot pencil out, which is why it's so important to build the foundation when you're young. I'd say almost every strong non-technical manager is strong on the basis of their strong conceptual skills but that still makes them a non-technical manager and there is a distinct difference. reply fhd2 11 hours agorootparentTrue! I'd still argue when people want something like a \"technical product manager\", it often means \"someone who can dive into the details of some complex system\", at least from what I've seen. Hiring someone who did some programming a few years ago isn't necessarily going to give them that. reply fhd2 12 hours agoprevIt's bothered me every now and then that the word \"technical\" is quite ambiguous. In German, we have a separate word for skills relating to any particular field, which is called \"fachlich\" (\"field-y\"). And then we have \"technisch\", which primarily means \"relating to technology\". Both translate to \"technical\". In the software world, I tend to express the former as \"domain expertise\", but it's not an exact match of what I mean usually. Though in the first example given in the post, relating to technique, it's even ambiguous in German. The joys of natural language I suppose. reply cloogshicer 12 hours agoparentI find that English often lacks words to express the same thing I can say in German. There might be a word that's close but it's often subtly different or lacking in nuance. Of course this also happens the other way around from time to time, but much less often. I wonder if it's because I'm biased as a German native speaker or because there really is a difference in the languages. reply bravetraveler 12 hours agorootparentAs someone who only learned enough German to insult, I'd say it's part of the identity in the languages. English borrows from everyone. German borrows from itself (to create elephant words). Many of the phrases in German are single words that amount to sentences. English has some of the same, but it doesn't feed on/into itself reply User23 12 hours agoparentprevYou have (or had?) the realschule too. In German society \"technical\" skills of that sort were considered second class really behind the gymnasium. reply fhd2 12 hours agorootparentWell, those are slightly separate concepts I think. I went to a \"Realschule\", and those still exist. It's a school form that ends after grade 10, where the majority of students moves on into an apprenticeship, to work in either some kind of trade/craft, or low to mid-level white collar work. OTOH, \"Gymnasium\" is the common path towards A levels and then university. It is, however, also pretty common to go on to do your A levels and then study after Realschule like I did (at a computer science focused \"technical high school\" (!) for grades 11-13, yet another eccentric thing we have, but I'm a fan). For what it's worth, I do think our society has a comparatively high appreciation for these apprenticeship type jobs. There can be pretty good money in it, often more agency, and a lot of them are obviously needed - far more obviously than most jobs folks study for. Maybe I live in a bubble, but I feel that's appreciated here. All of that technical (!) stuff aside, the word \"fachlich\" is, from my perspective, mainly used to describe white collar knowledge or skills. I don't think I've heard it in the context of baking, plumbing etc, and I'd say it has a positive connotation, hinting at education and experience. But I'm neither a linguist nor a statistically relevant sample of Germany, so YMMV. reply constantcrying 11 hours agorootparentprevThe distinction between Realschule and Gymnasium is whether the student will learn a trade or go on to university. Both can learn technical skills, the person from the Gymnasium can become an engineer and the person from the Realschule can become a tradesman. Besides that I think a recent change in German culture, correlating with a moderate decline in the importance of German engineering firms, has been to look down on all kinds of technical work. General social work, preferably working directly for the government, is now the in vogue field. reply proc0 13 hours agoprevI think the main reason there is a distinction between technical and non-technical skills, is because usually technical skills require a lot of time and effort, and depending on the subject matter it could takes months, if not years, to be competent. That is not the case with note-taking, managing or planning, etc. These non-technical skills are usually something you can \"pick up\" and also there is a huge factor of context where these skills depend on how the organization does things and how people work together. This is why they're also referred to as soft skills. There is a lot of variability in how they can be practiced and learned which depends on many factors that change from team to team and org to org. . I understand the article is trying to make a point of appreciating these other skills, however at least in the software industry today, I think technical skills have been undervalued and engineers are expected to spend a lot of time and effort on \"soft skill\" tasks, which I think is a waste of expertise. reply zdragnar 13 hours agoparent> in the software industry today, I think technical skills have been undervalued Is there a particular niche in the industry that you've seen this? I've almost universally seen the opposite. The closest thing I can think of is that someone who truly only has technical skills will usually be limited to IC levels, whereas someone who also has soft skills becomes a better candidate for senior and staff positions. The thing is, that's because soft skills are an actual requirement for those roles. The purpose to them is to herd cats, and someone who communicates poorly or doesn't seek out opportunities to do so won't get them. With that said, I don't think I've been in any tech focused company where technical skills aren't valued, and continued growth unappreciated. It's more a case that they're considered table stakes, and having strong soft skills is where you stand out. reply proc0 13 hours agorootparentI am mostly talking about what you just pointed out. The fact that soft skills are required to move up is evidence that technical skills are required less the more responsibility you get. There is a minimum bar requirement at entry level, and maybe one or two more levels before it gets taken for granted and rarely becomes an expectation for the higher positions that pay more. The more experienced engineers spend less time on code, and this is justified because they want people to be a \"force multiplier\" by becoming managers, essentially. Engineers get a tiny slice of the app and the majority of the time is spent on tasks that could be done by anybody else who didn't spend 10+ years studying and practicing computer science. Promotions are about managing a bunch of engineers that each get a tiny slice of the engineering. I would love to see promotions based on learning more technical skills and for this \"track\" to go all the way up the chain of responsibilities until you are responsible for coding hundreds of thousands of lines of code at a time. Ironically if I tried to build a company like that I would end up doing exactly what I am complaining about. reply zdragnar 11 hours agorootparent> The more experienced engineers spend less time on code, and this is justified because they want people to be a \"force multiplier\" by becoming managers, essentially. I think this is a fundamental misunderstanding of what the higher level roles are (or ought to be). Experienced engineers spend less time on code because the code doesn't live in a vacuum. Changes require planning. Requests for features usually come from people who either don't understand what they're asking for, or don't realize there's a different and better way to achieve the same outcome with less effort. Junior developers need mentorship and review to grow. If those things don't appeal, that's fine. They still need doing, and the people doing them need a good amount of technical skill- usually the more the better, though the phrase architecture astronaut comes to mind. There are some organizations that revolve around pure technical competency, but none of the ones I can think of are businesses- mostly, it's open source projects run by their BDFL founders like Linux, that sort of thing. reply proc0 10 hours agorootparentI agree to a certain extent, mainly that it is a matter of appeal and it's about finding the right match, etc. That said, I can't help but think there is value being lost by thinking engineers need to scale their productivity by managing more people rather than by managing more software. Software is inherently about automation and abstraction, and the possibilities are limitless as we are witnessing with recent AI breakthroughs. If more engineers had the opportunity to optimize their expertise throughout their career they could produce advanced solutions adding orders of magnitude more value. It has to do with the nature of software and how you can build an intricate system with whatever properties you want, but instead companies like to use popular frameworks and slice their product into tiny fragments that they can divide among their army of low level engineers, so of course they need a proportional amount of managers as well. reply intelVISA 12 hours agorootparentprevUnless you're RMS level weird orgs use \"soft skills\" as cover in the same vein as \"bad culture fit\" for likeability, politik and empire building. That said, imo the \"technical skills are required less the more responsibility you get\" mindset is the root of much dysfunction in tech companies... it's how we ended up suffering the car assembly line cargo cult in an industry where ~10 engineers can make Whatsapp ($$$$) when not laden with ceremony and theater. reply eschneider 13 hours agoparentprevHmm...programming is also one of those skills you can \"pick up.\" Lots of people do. To _really_ be successful, most folks need to develop a combination of \"hard\" and \"soft\" skills. The \"soft\" skills are neither easier nor less important. And strong \"soft\" skills make it SO much easier to leverage those \"hard\" skills. reply proc0 12 hours agorootparentBy that measure almost anything could be picked up, but then it loses all meaning. I'm sure people can just pick up quantum physics if you just get the books and start reading. I think the distinction here is the difference between learning how to use Jira or your calendar app, versus learning C++. One will take you years to achieve to a degree of professional competency while the other is a matter of just doing it a few times and getting into the habit of it. I agree you need both soft and hard skills though, to me it's just a matter of how much time your spending your 8 hours on, and it seems so many software companies are happy having their engineers spending less than 20% of their time on technical matters. reply eschneider 5 hours agorootparentYeah, learning JIRA or your calendar app is straightforward. Learning to work effectively with other people, whether as a member of a team or leading a team, can be remarkably nuanced and can take years of work and improvement to get really effective at it. Working on large projects is a team sport. Expect to spend as much time (or more) working with others as just writing code. I mean, it's ok to not worry about soft skills and focus your time and effort entirely on coding, but ultimately that limits the scope of what you can do. reply antupis 12 hours agoparentprevI would say that being \"ok\" at managing or planning is easy but being very good at both those skills is extremely hard, so hard that you cannot achieve it with effort alone. reply hi-v-rocknroll 10 hours agoprevThere's an unfortunate distinction between people who are very curious and possibly have formal training in a technical field, and those who do it because it makes lots of money. Orthogonally, there are project managers (PMs) and architects (they need an acronym) who either A. recently had or B. distantly had serious technical chops, and those who C. were the latter of the first sentence. C'est la vie; the anti-pattern of the corporate machine operating with the efficiency of the Peter principle. Perhaps the only and irreducible way to discern A. above is to work with someone else on something meaningful for longer than the pop quiz bullshit of 20-30 minute technical interviews. Possibly, project managers can be effective without technical knowledge if they both check their egos and communicate efficiently and effectively to reduce and consolidate external comms. Architects also need to defer to people digging away at the problem rather than mandating a vision or some equally ineffective pretend work. Architects and PMs can be extremely effective if they know their limitations, are honest, understand human nature and the natures of their team, and how to manage external expectations. reply charlie0 12 hours agoprev\"Technical\" skills just means a person has or can switch to a \"technical\" mindset, which I find to be quite different from non-technical people. Not to say that one is better than the other, but I do find it much, much easier to communicate with other people who have \"technical\" skills than those who do not. Mainly because I also happen to think in similar way. In that regards, it's a very useful heuristic. reply edg5000 12 hours agoprevAnother way to look at it, is that there are people and there are things. Humans will inevitably have to interact with each other, at least in order to mate to prevent the species from dying out. Arguably, everything involving people is communication overhead, the larger the organisational structure, the more communication overhead. Anything non-people related are \"things\". This includes anything from planning, math, engineering, logistics, marketing. reply constantcrying 11 hours agoprevWhat people mean by \"technical\" is whether a person has a background and education in some field related to what they are doing now. No doubt that conversations and sewing require specific skills and techniques. Certainly they are \"technical\" on some level, it just isn't what is meant. \"Technical\" in the context it is used means what level of specifics you can communicate on. Which is why it can be total nightmare to have to work with \"non-technical\" people, as there often is a relatively easy low level explanation, but that is useless to the other person, so communication starts to break down. reply victorbjorklund 12 hours agoprevI agree. But one thing that I think the author should have talked about more (or eloborated on in case I missed it) is the natural followup to the articles conclusion. Yes, there are technical skills in pretty much all fields. But if we recognize this fact it still does not address the starting point of the article. Is it better to have a manager with deep technical skills in the field of the people they manage? Should a basketball coach be a good basketball player? Should the project manager of a software team be a good programmer? Yes, there are seperate technical skills in the area of project management and sports coaching. But does the manager also need the technical skills of the people they manage? reply surfingdino 12 hours agoparentI used to work with someone who thought of themselves as a technical manager, because in his years after college he managed a couple of devs who mage Flash games. Then, by some skilled office politics and association with non-technical blow-hards he managed to become a manager on a complex greenfield project where he was managing a team of 30+ and had to work within an organisation of 150+ people who thought he was the person to answer technical questions. He mismanaged the team causing a lot of people to suffer mental issues and leave. Every time there was a technical question he'd pick the most idiotic solution you could think of. There was no way of fixing this problem, because the management above him were even more clueless. I have no respect for non-technical managers. reply ozim 11 hours agorootparentI have seen those people in wild. I have respect for non-technical managers but the ones that know their limitations. reply TrackerFF 10 hours agoprevLike everything in life, these things fall on a distribution, and usually have more hidden variables than the visible ones. I've worked with people like the following: A) Excellent systems and architecture/big picture knowledge, but hadn't done actual coding in ages, and likely wouldn't be much help if placed in a team to produce code. B) Terrific coder, but not too interested in the process. Ad-hoc type that would much rather spend time on iterations, than planning. \"Get shit done\" type. C) Very good people person, but with fading technical knowledge. D) Extremely enthusiastic person that came from the business side, but with limited technical knowledge. Would happily spend time on reading and learning about new technical stuff, but didn't necessarily have the foundational knowledge to lead a project alone. And many more. If asked \"Is [x] technical?\" I'd have answer \"Yes, but...\" or \"No, but...\" reply dgb23 10 hours agoparentAccountants, admins etc. are often very technical. Similar to developers who program every day. For one, they are proficient with what are essentially high level programming environments and platforms like Excel, Filemaker, some CRM and CMS software etc. They also automate tasks. They just typically don’t know how to turn a simple text file into a program, like we do, but they do program. Secondly and perhaps more importantly, they can do technical work for extended amounts of time. They know how to stare at a screen for hours, use the mouse and keyboard very effectively and quickly, spot mistakes and irregularities at a glance, and solve mistakes/issues in a structured manner. That mechanical aspect of being technical is often overlooked. But I think it’s important and fundamental. Someone who never developed these skills lacks the intuition and sensibilities that are required to make sensible technical decisions. reply flappyeagle 5 hours agoprevI wish self conscious insecure people would stop policing language. It means what it means when people use it. reply gabesullice 11 hours agoprevAt first I wanted to suggest: 'will he or she understand the technical details of our work?' instead of 'is he or she technical?' But then I realized it doesn't make a lick of a difference. Those who find the distinction meaningful will have already internalized the point of the author's article. Those who feel superior when they themselves are 'technical', while someone else isn't, think that the ability to understand the technical details of their work is proof that they are smarter, more passionate, and more interesting than the other person. That person will not be enlightened by your word choice. In other words, a monad is not a burrito [1]. [1] https://news.ycombinator.com/item?id=40556699 reply Blackarea 11 hours agoprevBit biased, but I'd say this is an non-technical article about overthinking terminologies. As others already mentioned, we use techie /non-techie to quickly categorize people into coders and non-coders, but techie also works for the embedded-guy or the kick ass devop or Linux neckbeard. \"Tech\" has also become an allegory of topics that we can discuss where there is a clearer right and wrong. It's still subjective and opinionated of course but at the moment when your mind is really soaked into tech, everything feels so simple and ultimatively true. It's probably part of the God-complex/imposter-syndrome that so many coders experience, but that's another topic... reply Animats 11 hours agoprevGo back to C.P. Snow's \"two cultures\".[1] This is not new, but it's not that old, either. The concept appeared in the 20th century when tech started being important. Don't have time to recap the history of technology right now. [1] https://www.cambridge.org/core/journals/european-review/arti... reply SPBS 12 hours agoprevHard disagree with the premise. It's disingenuous to pretend there isn't a difference between knowing how to resolve an interpersonal conflict vs knowing the calculations needed to build a bridge. Yes, the skill ceilings may be high, but the skill floor is clearly different. I'm not downplaying soft skills, by the way. Soft skills are what get you successful in life. And the disdain some people have for soft skills vs hard skills is uncalled for, but that's a separate issue. Technical skills clearly mean something technical. reply AttakBanana 12 hours agoparentI would argue that skill floors are subjective, and so maybe there isn't as much difference as we think between the two skills? reply ozim 11 hours agorootparentThere is a chasm of difference between the two skills - it is time. We have limited time in life - I do like to spend time fooling around with computers, other people like to spend time fooling around with other people. I am never going to be as good in small talk as someone hanging out with people all the time. The same the other way someone dealing with technical issues all the time will just be so much better at fixing them. I am also not that much interested in other people, well I have my close friends and family, but if I am in group with strangers I cannot crack a joke - even though I know the structure of a good joke and I can make my friends or coworkers laugh (it is much easier to get correct timing to drop a joke with people you meet on daily basis). Then there are those people who just own the room after 5 minutes mostly because they practiced it. Yes taking it down to some steps looks like there is no difference - but there is difference on what I am spending my time on. There is also this gap where you can learn and train javelin throwing for all your life but still you might not even get close to starting in the Olympics - even if you have all the steps of \"how to throw a javelin\" worked out. So I don't agree you can break something into steps and say \"well that's the same thing just do XYZ and it works\". reply chilling 10 hours agoprevSuch a breeze! I love to remind myself that some things I take for granted require extraordinary skills that I just don't have the time or willingness to process and understand. I think that's the reason why I love to watch Real Engineering/Practical Engineering channels on YouTube. I watch what seems like a \"simple\" task, such as pouring concrete, and then suddenly realize that it's actually not that easy. Or \"How It's Made\" - Chips? Easy, right? Well, no, lol! reply matrix87 12 hours agoprev> Do you know how to defuse an entrenched argument between coworkers, help a burned out coworker get out of a rut, or tell someone they're not doing a great job without making them furious? Managers do. Ehh, maybe if you're lucky. But I wouldn't count on it. Frankly I'd just be happy with not getting a stick in the eye > Likewise, we can ONLY write off marketing, sales, management, design, product, HR, etc etc etc etc as less important because \"they're not technical\" if we choose to ignore that they are very technical. Design requires a lot of hard skills... how many people here could open up photoshop or indesign and not get overwhelmed by the magnitude of features? Seems like a really lazy example The real distinction is between people who actually work on real products and all the auxiliary people who exist to facilitate business process. Like the difference between a professor and a uni administrator. The former rightfully deserves more props than the latter reply morgante 11 hours agoprevThis article starts with a false premise that non-technical skills are undervalued then works backwards to try to defend them. > We often dismiss skills that are not societally valued by pretending they are not skills. The truth is that \"non-technical skills\" are valued far more than technical skills. The people who run our world didn't get there from \"technical\" skills. Non-technical skills are less legible so it's harder to deliberately practice them and there are many people running around in non-technical roles who are simply not good at the role. Tons of salespeople can't sell. Lots of product managers have no product vision. etc. People who are actually good at non-technical jobs don't need to be lionized. They already have the money and power. reply FearNotDaniel 11 hours agoparentI'm not sales person myself, but I think it's pretty obvious to spot the difference between a sales person who is actually achieving sales, and one who is not. Perhaps much more legible than arguing whether a Dev team is creating or destroying value by deciding whether to refactor the mess or keep piling up technical debt. Listen to any sales podcast for five minutes, you'll see it's full of people deliberately practising specific skills, and lots of things we would probably characterise as \"technical\" activities once we have the language to identify and classify such techniques. reply morgante 11 hours agorootparentIt's obvious/quantifiable once you are in the role. I don't understand the obsession with calling all skills \"technical\" though. Why do you feel that need? reply GianFabien 13 hours agoprevI have learnt over the years, that rather than calling a specific skill \"soft\" or \"non-technical\" to actually learn it and get good at it. Along the way I have learnt a great deal about the unknown unknowns. We have a progression: unconscious incompetent -> conscious incompetent -> conscious competent -> unconscious competent. And it is completely context and domain specific. reply ukuina 12 hours agoparent> unconscious incompetent -> conscious incompetent -> conscious competent -> unconscious competent This is a fascinating observation. Can you elaborate on the difference between the last two stages? Doesn't mastery involve knowing what you are good at? reply teractiveodular 12 hours agorootparentThese are the standard four stages of competence in psychology: https://en.wikipedia.org/wiki/Four_stages_of_competence reply ianbutler 12 hours agorootparentprevNot OP but let me try to define by example. I've been programming for 19 years give or take, starting as a kid I'm now 29. There are many parts of software engineering in several domains that are just second nature to me at this point, I don't think deeply about how to write or structure the code, it's simply an intuitive action and it's usually somewhat solid code when I finish producing it. I just write good code without having to think about how to write good code. I've also become competent in several other domains as I've continued in the field and I can write good code in those domains, low level systems engineering as an example, however, I have to think through systematically how to structure the code and how to avoid memory issues etc etc. I'm competent, but it takes a bit longer and I'm actively considering structure etc, checking papers, reading docs more deeply. I can say I'm competent and even good in those differing areas, but the amount of effort needed to achieve the perception of being good is a lot different between them. Some areas are basically effortless and some are effortful. That's the distinction between unconscious competent and conscious competent as I would define it. reply treme 12 hours agorootparentprevhaving to stay conscious to do the task vs being able to do it on auto-pilot. reply paulmooreparks 12 hours agorootparentThis concept is also covered in a Taoist story about The Dexterous Butcher: https://www.bopsecrets.org/gateway/passages/chuang-tzu.htm reply xyzzy123 9 hours agoprevAre you responsive to selection pressure? Are you accountable for anything? Is your employment coupled in any way to the success of the organization? How, exactly? Are you playing the game? Do you have to play the game? reply globular-toast 11 hours agoprevOk, we get it, you can do your job. But when I ask a fellow engineer if someone is technical I'm asking if they can do my job. So yeah, feel free to call me non-technical in conversations with other sewers. reply GoToRO 8 hours agoparents/he is a coach reply ajuc 12 hours agoprevChanging the name changes nothing. The distinction will remain useful and people will invent a new word. If what we currently call technical skills is unfairly overvalued - the evaluation needs to change, not the name. Similarly you don't fix racism by replacing one word with another. That's just magic thinking. BTW I think technical skills in IT are overvalued, mostly because of outdated perception of rarity. And over time the hordes of people pivoting to IT and the improving generative AI will change that. reply mouzogu 12 hours agoprev> every field has \"technical\" skills. > they're simply the skills used to produce the work. it's contextual, words can mean different things in different context. in my work technical skills just means that you are a manager who progressed through engineering. you understand our problems and speak in the same terms. non-technical is just someone from a different contextual background. although in their own context of dealing with humans (\"soft skills\") is also a \"technical\" skill in that it require specific skills which we engineers may not have. reply sneak 12 hours agoprev“technical” is just shorthand for “has ever once used a text editor to read or write code professionally before”. There are a bunch of people who work in tech who have technical skills who don’t know anything about code. That’s a bright line skill boundary and it is an important practical distinction. reply ozim 11 hours agoparentThere are people that even if you would try to force them to learn how to operate computer properly they would straight out refuse. I don't think they have a place in SaaS/IT/Tech or any other thing like engineering or finance - but they are there. reply krisoft 9 hours agoprev> And consider the \"maker movement,\" which, in my most frustrated moments, I call \"arts and crafts, but for boys.\" The \"movement\" has been careful to highlight its technical skills to position itself apart from similarly technical fields, like sewing. I call bullshit on this. Sewing is making. Simple as that. The \"maker movement\" is not distinct from sewing but encompasses it. At our hack space we have people doing woodworking, people doing machining, people doing 3d printing, and people doing various fiber-arts (sewing, knitting, crocheting, embroidery). Very often they are the same people, because it is all just making. reply est 9 hours agoprevOK I kinda get what author is trying to say here. In the first screenshot, \"were the Project Managers technical\", the asker means \"does the PMs understand technical details\" Then the author argues that marketing, sales, management, design, product, HR people were also \"technical\" if you pay enough attention. This article is arguably a very nice write-up, but it misses the main point. In an emerging field, \"technical\" means decision makers can adapt very quickly with the know-hows and gets an advantage, but for mature business with tons of off-the-shelf technical solutions, soft-skills means a lot. It all depends what kind of business you are in. They are not contradictive. reply bjornsing 11 hours agoprevThis is a bit hard to digest for me who have lived most of my life in a culture where technical skills are not valued but soft skills are (Sweden). It has turned around to some extent over the last 15 years, but I still fondly remember how I “destroyed” my manager back at Ericsson by interrupting a long rant about how little she understood about engineering and pointing out that her title was in fact “technical manager”. If a look could kill I wouldn’t be here today. I can understand that the Silicon Valley culture can be frustrating if you’re “not technical”. But just remember that the opposite culture (i.e. the old Swedish one) is a road to serfdom for everyone involved. If you don’t believe me, just compare e.g. Ericsson’s and Google’s market capitalizations over time. reply satisfice 13 hours agoprev [–] I like the term soft skills. I find it relevant and meaningful. To me, soft skills are skills for which we have no strong evaluation mechanism. Are you good at communication? It's hard to tell. A lot of judgement and context is involved. That makes it a soft skill. Programming might be a soft skill under this definition, except it isn't: because programming tends to be judged on results, which are easier to see and harder to argue with. The definition of \"technical\" in this article is overly broad. Although I agree that sewing is a technical skill. I'd suggest this definition \"A technical skill is the ability to create technology of some kind.\" A knitted cap is technology, therefore knitting is a technical skill. When we are speaking of projects in IT, \"non-technical\" specifically means skills other than those of fashioning hardware and software. reply GoToRO 8 hours agoparent\"It's hard to tell.\" Did they put meetings without agenda? They are not good at communication. Did they took decisions that impact multiple teams but never inform the teams that were not present? They are not good at communication. Do they interrupt people when they hear things they don't like? They are not good at communication. Do they hide important (bad) information because they are ashamed of what they did? They are not good at communication. reply shermantanktop 12 hours agoparentprev“Programming tends to be judged on results” - I’ve seen plenty of very skilled programmers spend oodles of time on complex things that don’t matter to anyone except to them. Are those results? reply krisoft 9 hours agorootparent> Are those results? No. And I'm judging them on that. reply rahkiin 12 hours agoparentprevI like the term ‘people skills’ for things like communication, leadership, convincing, negotiation, etc reply Terr_ 12 hours agoparentprev [–] Yeah, the \"softness\" refers to epistemology, rather than emotional content. > A knitted cap is technology, therefore knitting is a technical skill. To offer a converse example, consider the creation and delivery of devastating rage-inducing insults. It isn't kind nor necessarily desirable on your team... but it's still a \"soft skill\" because it is hard to evaluate or formalize. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The traditional labeling of individuals as \"technical\" or \"not technical\" in Silicon Valley undervalues the diverse technical skills across various fields.",
      "Examples like the movie \"Free Solo\" and Steph Curry's basketball career highlight intricate technical details often overlooked, similar to skills in marketing, sales, and management.",
      "Recognizing and accurately describing these skills can enrich our understanding of different professions and prevent the perpetuation of power dynamics that undervalue important work."
    ],
    "commentSummary": [
      "In software companies, when coders ask if a boss is \"technical,\" they are inquiring if the boss can code.",
      "The distinction between technical and non-technical roles is common across various fields, emphasizing practical knowledge in specific contexts.",
      "Understanding technical work is crucial for managers to effectively advocate for and make decisions regarding their team's work."
    ],
    "points": 102,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1720154883
  },
  {
    "id": 40882133,
    "title": "Programming in Unison",
    "originLink": "https://lwn.net/Articles/978955/",
    "originBody": "LWN .net News from the source Content Weekly Edition Archives Search Kernel Security Events calendar Unread comments LWN FAQ Write for us Edition Return to the Front page User: Password:| Subscribe / Log in / New account Programming in Unison This article brought to you by LWN subscribers Subscribers to LWN.net made this article — and everything that surrounds it — possible. If you appreciate our content, please buy a subscription and make the next set of articles possible. By Daroc Alden June 25, 2024 Unison is a MIT-licensed programming language, in development since 2013, that explores the ramifications of making code immutable and stored in a database, instead of a set of text files. Unison supports a greatly simplified model for distributed programming — one that describes the configuration of and communication between programs in the same language as the programs themselves. Along the way, it introduces a new approach to interfacing with programming languages, which is tailored to its design. Every programming language, especially one that is just starting out, needs a niche. Unison's chosen niche is cloud computing — making it easier to build modern distributed systems, by radically simplifying some of the rough edges of existing technologies. While it is certainly possible to throw together simple, local scripts using the language, the core developers' focus is on making the development of distributed systems and web-based applications as seamless as possible. In support of this mission, the language employs a number of unusual features. Naming The feature that fundamentally sets the language apart is the way code is stored. Unlike most other programming languages, which store programs as text, Unison stores programs in a machine-readable format. There are other languages that have done this, including languages like Smalltalk with image-based persistence, or visual languages like LabVIEW. Unlike those languages, Unison programs are stored in an append-only, content-addressed database. The code is still displayed to the user for editing as text, using the editor of their choice, but it is only parsed once, and then stored internally in the database. Consider the following implementation of the factorial function: factorial : Nat -> Nat factorial n = match n with 0 -> 1 _ -> n * factorial (n - 1) This function has the hash #in3bl5u64l (rendered in Unison's default base-32 hash format), using Unison's custom structural hash function. The hash is based on the structure of the code, not the variable names or formatting used to express it. Internally, the abstract syntax tree (AST) of the code is stored in Unison's database under that hash. If another person wrote the same function but decided to call it fac, it would have the same hash. When editing some other function that referenced it, Unison would display whatever name the user had defined for it; so one person might see factorial and the other might see fac. In this way, Unison names are a lot like Git tags: a human-readable name for an object that is primarily identified by a hash. In general, the programmer interacts with Unison using an editor side-by-side with a terminal running the CLI interface, or a browser window running the graphical interface. When writing new code, the user types it in their editor, like any other language. On save, Unison is alerted by a filesystem watch, reads the code, and then presents any problems with it, or offers to update the database with it. When editing an existing function, Unison pretty-prints the stored definition into the user's editor, and watches for changes. This has the interesting effect of doing away with code formatting as a separate step — code is always formatted when the programmer goes to read or edit it. Overall, the approach ends up feeling much more like a collaboration with the compiler than conventional languages do: it asks for definitions, suggests changes, points out problems and failing tests, etc. Here's what it looked like when I added the above definition to my code: I found and typechecked these definitions in /tmp/scratch.u. If you do an `add` or `update`, here's how your codebase would change: ⍟ These new definitions are ok to `add`: factorial : Nat -> Nat Unison's approach to naming may seem like an interesting curiosity, but it has a few practical ramifications. For one thing, renaming a function, variable, or type can never break anything. Even causing a name collision won't cause problems — Unison tracks the underlying code by hash, so two items that are both named foo might be displayed to the user as foo#hash1 and foo#hash2, but the program would still compile and run without any problems. Another consequence is the ability to use different versions of the same library without issue — different versions of the same function have different hashes, so they can be treated just like different functions with the same name. This also means that the hash of a function encodes not only its code, but also its exact dependencies, which makes sharing code between computers much simpler. Claiming that Unison code is immutable raises the question of how a function could actually be updated, once it has been written. Since Unison code is stored in a database, the language always knows exactly which code references a particular function. If an edit to a function does not change the type signature, the language can automatically produce a new version of each function that depends on the changed function. The old versions are not removed, but the names of any functions are updated to point to the new ones. This makes it possible to write behavior tests that compare one implementation to another, by referring to the old version of a function, for example. If the changes to a function do not preserve its type, Unison uses the same knowledge to produce a \"to do\" list for the programmer, which it will track and automatically remove items from as conflicts are solved. Since the old code is still present in the database, there is never a moment where the code is \"broken\" by a change. The old version still exists, and can be run, built, inspected, and so on, while the programmer works on the new version. Once the new version has been completed, the programmer can switch over to it all at once. Abilities Unison's unique approach to naming may handle dependencies, but as the pervasive use of containers shows, there is more to getting program to run on many computers than just ensuring that dependencies are bundled with a program. Code does not just depend on library functions or types, but also on the state of the computer outside of the program. Unison can't solve that problem entirely, but it does have a solution to help manage the complexity of code that relies on interfacing with the outside world: abilities. Abilities are a kind of effect system — a way to track in the type system what a given piece of code needs in order to run. The most general ability is called IO, and represents the ability to do arbitrary I/O, including reading and writing files, opening network connections, or reading information about the state of the computer. Programmers could write their programs with every function requiring the IO ability, but the more usual approach would be to consider which concrete things each part of the program will need to be able to do, and then declare smaller, more restricted abilities. Programs with custom abilities can be run by providing a \"handler\" function that describes how to implement the ability, usually in terms of another ability. For example, a programmer might provide a ReadEnvironment ability that lets a program fetch the value of environment variables. In normal use, a handler would translate that into the IO ability, but there can be multiple handlers for an ability, so a test suite might use a handler that supplies pre-defined test values instead. Since abilities are tracked by the type system, it is impossible for a function to use an ability it has not declared. This means that the programmer can get a list of every interface with the outside world that a piece of code expects to use by looking at the type signature, and mock them for testing by specifying a different handler. Overall, abilities can make writing testable distributed programs much simpler, since everything is described in one flexible language. The guarantees of the type system also mean that it is theoretically possible to run untrusted code, and be sure that it only accesses abilities that the programmer gives it. In practice, Unison is still in development, and there may be some lurking holes in the security guarantee. Funding The founders of Unison Computing — Paul Chiusano, Rúnar Bjarnason, and Arya Irani — have enough faith in Unison's security properties to make them the basis for a cloud computing offering. Unison Cloud is a platform that allows running Unison programs that use a custom Cloud ability on managed hardware for a monthly fee. That money goes to Unison Computing, a public benefit corporation that employs the core Unison developers, to keep working on the language. The project does accept outside contributions, however, and the language itself will remain open source. The Cloud ability has facilities for storing arbitrary Unison values to a typed database, handling HTTP(S) requests, deploying new services, and other operations necessary for a program running in the cloud. Since it is an ability like any other, the Unison Cloud library provides mock handlers that can test the entire process of deploying multiple services, running health checks and integration tests, and tearing down the resulting deployment locally. Drawbacks Unfortunately, Unison's unique design comes with its share of problems. For one thing, modern programs are often not written in just one language, but Unison's greatest benefits only come when an entire program is written in it. Unison doesn't even have a stable foreign-function interface (FFI) that could be used to wrap libraries written in other languages. Because of this, existing Unison programs need to reimplement a lot of functionality that is already present in other languages. Unison Share is a cross between a package registry, a code forge, and a code browser. Since Unison code is not stored as text files, but rather as a database, the community can't really reuse existing tooling. Tools like Unison Share must be written from scratch. There is support for pushing code to a Git repository, but since it isn't human-readable, it can't really be viewed without either using the local Unison tools, or hosting an instance of Unison Share. The community is actively encouraging people to develop and post new libraries there, but there's a long way to go to catch up with other languages. Still, Unison's ideas around dependency management make using libraries that do exist quite easy — just pull them into your local database and start calling functions, with no worries about dependency conflicts or where to obtain the code. That approach does prompt the question of how upgrades to libraries are handled. The process described above for updating dependent code when a function changes relies on all of the affected code being locally available for development. There are three partial answers to this question: small libraries, abilities, and patches. Since Unison makes it easy to seamlessly depend on a library, many of the existing libraries are quite small; it is easier to break out some small functionality into a separate library than it would be in another language. Smaller libraries require less frequent updates, and may even become completely finished. Larger libraries can present their interface as an ability. This makes upgrading to a newer version of the library as simple as changing to a newer version of the handler. Finally, for cases where neither of those approaches apply, Unison produces a special kind of value called a patch — really, a record of what changes the developer of a library made while developing the new version, including a mapping of which new functions were produced by editing old ones. Unison uses that information to do the same kind of upgrade as during local development. Unison is in active development, not yet having reached a 1.0 release. So quite aside from throwing out the familiar text-based workflow, it also has the normal challenges that any language must face: performance problems, occasional bugs in the runtime, unstable interfaces, etc. Despite that, the documentation is already quite comprehensive, and the project has a policy of not breaking existing programs on upgrade. In fact, the standard library is managed using the same process as other libraries, so it is quite possible for a program to use different versions of the standard library internally without conflict. Unison is not yet widely packaged, but downloads are available from the project's releases page. Running ucm, the Unison codebase manager, will set up a database for the user's code in ~/.unison and provide some quick-start guidance on starting a project in Unison. It remains to be seen whether Unison will overcome the hurdles necessary to become a widely-used, productive language. Even if it does not, however, it at least illustrates that a different approach to software development is possible — one that builds collaboration with the computer directly into the language itself, and provides an alternative to the many text-based programming languages. (Log in to post comments) -EEXIST Posted Jun 25, 2024 19:16 UTC (Tue) by grawity (subscriber, #80596) [Link] (11 responses) Running ucm, the Unison codebase manager, will set up a database for the user's code in ~/.unison Ah, so not only does it add to the ~ clutter with more hidden directories, it also uses the exact same ~/.unison where the Unison file synchronization software stores the user's sync configuration and state… -EEXIST Posted Jun 25, 2024 19:18 UTC (Tue) by grawity (subscriber, #80596) [Link] (I seem to faintly remember that both the programming language and the file sync tool might share the same roots? Or something? That doesn't stop me from expecting ucm to accidentally nuke the other program's configuration one day.) -EEXIST Posted Jun 25, 2024 19:22 UTC (Tue) by daroc (editor, #160859) [Link] (2 responses) Unfortunately, yes. I actually use the Unison file synchronization software as well, so I did notice that it was putting the database alongside my existing configuration files. Stuff like this is why I keep everything I actually care about on a separate Btrfs subvolume, wipe out my home folder every week, and then symlink the set of config files I've approved back into place. There is a lot of software that will put things in your home directory without permission. -EEXIST Posted Jun 28, 2024 22:25 UTC (Fri) by karkhaz (subscriber, #99844) [Link] (1 responses) chmod u-w ~ solves this problem permanently, both for dotfiles that ought to be written under ~/.config, and other directories like \"Downloads\" and \"Documents\" that certain programs insist on trying to create. -EEXIST Posted Jul 1, 2024 12:08 UTC (Mon) by daroc (editor, #160859) [Link] Yes, I did try running with an immutable home directory for a while. It worked alright, but some software that I wanted to use just completely refused to cope with being unable to create files there. Eventually I decided it was easier to let it create files and then clean up afterwards. -EEXIST Posted Jun 26, 2024 7:18 UTC (Wed) by epa (subscriber, #39769) [Link] (2 responses) Maybe it's time to abolish the idea of hidden files and display filenames that begin with a . by default, apart from the special directories . and .. Get rid of hidden files? No thanks. Posted Jun 27, 2024 23:20 UTC (Thu) by edgewood (subscriber, #1123) [Link] (1 responses) So the solution to too much clutter is to ... show things that were previously hidden? Get rid of hidden files? No thanks. Posted Jun 28, 2024 4:47 UTC (Fri) by intelfx (subscriber, #130118) [Link] > So the solution to too much clutter is to ... show things that were previously hidden? I'm assuming the GP's idea was to do this as a way to put pressure on the clutter-generating programs (i.e., via making their users annoyed). Not sure if I agree with using human emotions as leverage, though. -EEXIST Posted Jun 27, 2024 3:49 UTC (Thu) by ranger207 (✭ supporter ✭, #134731) [Link] Maybe Unison the programming language should store its config files in a directory named after the hash of its contents -EEXIST Posted Jun 27, 2024 6:52 UTC (Thu) by zdzichu (subscriber, #17118) [Link] (2 responses) Having read only the title, I somehow expected this article to be about file-syncing software growing scripting capability. Now I see this is completely different. -EEXIST Posted Jun 27, 2024 22:43 UTC (Thu) by koh (subscriber, #101482) [Link] (1 responses) I agree that titles, in general, contain too little information. This seems to be by design. Maybe it's time to get rid of them all together? -EEXIST Posted Jun 28, 2024 5:16 UTC (Fri) by cpitrat (subscriber, #116459) [Link] Or just put the content of the article in the title and the title in the content? Copyright © 2024, Eklektix, Inc. This article may be redistributed under the terms of the Creative Commons CC BY-SA 4.0 license Comments and public postings are copyrighted by their creators. Linux is a registered trademark of Linus Torvalds",
    "commentLink": "https://news.ycombinator.com/item?id=40882133",
    "commentBody": "Programming in Unison (lwn.net)95 points by sohkamyung 6 hours agohidepastfavorite13 comments sp33der89 5 hours agoPleasant surprise to see Unison mentioned! The developer experience in Unison(and Unison Cloud) has been wonderful for me. I try to write as much in it as possible, for hobby projects or side projects for friends and family. Abilities(what Unison calls algebraic effects) are really ergonomic too use in practice, the learning curve is a lot lower than a IO monad datatype, and it reads just like Python when putting it to practice! Code-in-a-database means I don't have to fumble with long compilation times and Git, it brings joy to just hacking on to something in the weekend, because I just get to write code. The article mentions its drawbacks, and they are real, especially FFI imo. The Unison team mentioned they are planning to include FFI, and it's going to be interesting to see what gets compromised. But no other language (currently) hits this sweet spot of abstractions(not too little not too much) with an enjoyable DX, for me. Docs being first class, go-to-definition and all that is one of my favorite things to show off when mentioning Unison: https://share.unison-lang.org/@unison/base reply klabb3 5 hours agoparent> with an enjoyable DX How is the tooling? Usually these paradigm shift ideas fail on interop even if they’re amazing in theory. The ambition level of Unison seems to be absolutely gigantic, so my first thought is that interop with anything outside their idealized world would be poor. reply sp33der89 4 hours agorootparentThe tooling is surprisingly good for such a \"young\" language. I've had experience with other budding languages, like Nim, Zig, ReasonML throughout the years(not comparing these languages, just their tooling, they have tradeoffs), and Unison is slick. But expectations should probably be managed, it's not IntelliJ or VS Studio. I'd describe the tooling as \"zen like\". When I sit down on weekends to write some Unison, I'll pop up my editor in a left tab, and on the right there's ucm. Since the LSP is included in the codebase manager, I didn't have to setup much. The LSP works good, could use some more code actions to control ucm though. I'll write some code, throw in a `> ` eval expression to quickly mimic a REPL. I'll see the evaluation on the right. Eventually I'll switch to the right side and add my pieces. or write a `test>` and expression, which I can add as well to my codebase. Push my changes, create a branch, or switch project also happens. Maybe I'm not sure what the name was of a piece of code? Or I'd like to be able to search based on function signature. Both can be done in the right tab(ucm) with the command `find`. Documentation is first class, I can browse the doc comments attached to variables/functions/types, I can link other terms(pieces of code) in those docs and they are discoverable as well, as soon as you add it to your codebase. I believe a big part of why this is all possible, is that when your code is stored like this, it makes tooling around it a lot less complex. No need make ad-hoc parsers, compilation caches, syntax checkers. I'm no tooling expert, but for example making a visual editor based on the terms in your codebase sounds a lot easier than making a visual editor for TypeScript, the mental gymnastics is a lot less. reply binary132 2 hours agorootparentISTM that packing all that goodness (?) into the compiler stack itself is moving away from what I want where the compiler is a plain-Jane source transform and its inputs and outputs are very well specified and predictable. That’s where the ecosystem of tools comes in, and when done right I think tools should be very easy and straightforward to use and create. I often feel modern languages get this wrong by “including” too many “batteries” instead of specifying and documenting their build / dependency semantics clearly and providing good tools or libraries for working with and composing those elements of build. Far too few language ecosystems provide any kind of libraries for it whatsoever, even for working with syntax / AST. I really can only think of Clang and Go, and Go’s tool libraries aren’t very accessible IMO. reply sp33der89 1 hour agorootparentThis is a good point, and deserves a lot more discussion about it. I personally don't mind that my code is somewhere else than in a text file, because as it now I have to ductape a huge array of tools to make it to production in languages like TypeScript and Elixir(languages we use at $WORK). I don't want to deal with that anymore than I need to. I hope modern languages get to the level of swiftness like Unison, but until then I'm really happy with Unison, because code-in-database is only one of the several aspects I like about it(no dependency conflicts being another huge part of it!). Clang is a good example I know, and Scala(https://www.chris-kipp.io/blog/an-intro-to-the-scala-present...) also has some nifty stuff. But even in Scala things aren't as seamless as in Unison. Unison does things very differently, and it might not be everybody's cup of tea. But I do hope that popular languages take the good bits and help programmers do less chores and more fun stuff. > I often feel modern languages get this wrong by “including” too many “batteries” instead of specifying and documenting their build / dependency semantics clearly Do you have some examples? Nix somewhat aims to solve this, but it has its own drawbacks. A lot of people these days _expect_ a battery included environment: package manager, build tooling, linting, formatting, a language server, documentation generators. Unison solves a lot of these in one go because of the way it handles code, I think that's elegant and worth exploring. reply EdiX 4 hours agoprevI've never used unison but I've used other, more traditional, REPL-based languages (think, Mathematica or Common Lisp with SLIME). To me one of the biggest problems with that style of programming is that sometimes code that you have changed on disk persists in the memory image, in the form of closures, creating unexplainable \"ghost bugs\" that disappear when you restart the REPL (or worse, that will only appear after you restart the REPL). This system with making code immutable and storing it into a database makes me think somebody noticed how much of a footgun this behavior of REPLs is and thought... \"mmmmhh what if we added a second barrel to the gun so that you can be sure to always shoot your own feet?\" reply pchiusano 3 hours agoparentI know what you mean with those other tools, but this doesn't happen in Unison. The reason those systems are somewhat flaky is that the cache of what's in memory can diverge from the \"source of truth\" which is a bag of constantly mutating text files. Maybe put another way, cache invalidation is hard in those systems. When the source of truth is instead a database, content-addressed by hash, cache invalidation is simple - if the hash has changed, a cached result is invalid and needs recomputing. If the hash is the same, you're good. We use this approach in many places throughout Unison and it's quite robust. reply nerdponx 3 hours agoparentprevThis is why I never fully embraced to the REPL-driven development style espoused by CL users. Even if I am using hot reloading during my development workflow, I never keep a long-running development image and I never expect to distribute or run that image as the finished product. I always build a fresh clean image/executable (eg via ASDF) and run a separate test suite. Interestingly this problem has arisen more recently in the Jupyter notebook ecosystem, and is being rediscovered by a generation of non-programmer data analysts / scientists and the programmers that need to support them. Some interesting solutions like \"reactive\" notebooks have arisen out of that. It would be very interesting to have something like that for Common Lisp. Maybe Mathematica already has it. reply pchiusano 3 hours agoprevHi there, I'm one of the creators of Unison, feel free to AMA! reply LegionMammal978 4 hours agoprev [–] Suppose that a codebase has two different functions with two different purposes, but they currently have the same implementation. (Say, the \"factorial\" function is used to implement that operator in a user-facing REPL, but also some growable-array implementation happens to use a factorial function for its allocation policy.) Then if one function starts needing a different implementation (e.g., a new allocation policy), then how do you reliably separate the two in this model? It would seem like there is no way to disambiguate a function apart from its current implementation. reply pchiusano 3 hours agoparentIf I understand your question, this would work much the same way as any other language. Suppose you have: allocationPolicy = 23484 -- two usages of allocationPolicy foo = allocationPolicy + 1 bar = allocationPolicy + 99 You then later realize you want different allocation policies to be used in different parts of your app. You first might want to rename the existing `allocationPolicy`: move.term allocationPolicy defaultAllocationPolicy At this point, all the code still references that hash, which now has the name `defaultAllocationPolicy`. Next if (say) you wanted `foo` to reference a different definition, you'd `edit foo`, and introduce: fooAllocationPolicy = 283 foo = fooAllocationPolicy + 1 Then `update` and you're done. The new version of `foo` references `fooAllocationPolicy` while `bar` continues to reference `defaultAllocationPolicy`. A couple other notes - * It's very rare for independent implementations to end up with the same hash. It probably only happens for some very simple defintions that exist in base. (Like the identity function, say) * If a hash has multiple names in your project because you've used `alias.term` to do so explicitly, the pretty-printer picks one using a deterministic rule (it prefers names you've given that hash in your project, then it consults library dependencies). If you really want to give two definitions different hashes even though they are functionally the same, you can introduce a minor change, like an unused binding. * The type of a definition is part of its hash, so sometimes you might specialize a more generic function with a more narrow type signature, and this gets its own hash. * The OP is slightly out of date re: patches. We use something simpler now for updates and merges. When you update, we compare the new and old namespace to obtain a diff, which is applied to the ASTs in the namespace. If the result typechecks, you're done. If not, we make a minimal scratch file for you to get typechecking - it will contain the minimal transitive dependents of the change. reply DatoClement 3 hours agoparentprevMy understanding is that the unique hash is really the true identifier of the implementation. So when you change the implementation, the two functions will have two different hashes? I am not sure if this is exactly your problem. reply carapace 2 hours agoparentprev [–] > two different functions ... have the same implementation Then they are not different functions. > It would seem like there is no way to disambiguate a function apart from its current implementation. Right, that's the whole point. In Unison the name of a function is a hash of its implementation. Change the implementation and you change the identity. > how do you reliably separate the two in this model? There is no way to confuse the two in this model. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Unison is an MIT-licensed programming language that stores code in a database rather than text files, simplifying distributed programming.",
      "It uses a unique naming system based on hashes, enabling seamless renaming and versioning, and features an abilities system to track code dependencies and interactions.",
      "Designed for cloud computing, Unison offers managed services through Unison Cloud, but faces challenges like the lack of a stable Foreign Function Interface (FFI) and the need for custom tooling."
    ],
    "commentSummary": [
      "Unison programming language is noted for its ergonomic design and code-in-database approach, which simplifies coding by eliminating long compilation times and the need for Git.",
      "Despite being a young language, Unison offers robust tooling, including Language Server Protocol (LSP) integration and first-class documentation, which enhances the developer experience.",
      "Unison's method of handling immutable code stored in a database addresses common issues in traditional REPL-based languages, though some users are concerned about modern languages incorporating too many built-in tools."
    ],
    "points": 95,
    "commentCount": 13,
    "retryCount": 0,
    "time": 1720182687
  }
]
