[
  {
    "id": 37985176,
    "title": "Software disenchantment",
    "originLink": "https://tonsky.me/blog/disenchantment/",
    "originBody": "Blog Talks Projects Logos Patrons Software disenchantment Translations: Chinese French Hungarian Italian Korean Portuguese Russian Spanish I’ve been programming for 15 years now. Recently, our industry’s lack of care for efficiency, simplicity, and excellence started really getting to me, to the point of me getting depressed by my own career and IT in general. Modern cars work, let’s say for the sake of argument, at 98% of what’s physically possible with the current engine design. Modern buildings use just enough material to fulfill their function and stay safe under the given conditions. All planes converged to the optimal size/form/load and basically look the same. Only in software, it’s fine if a program runs at 1% or even 0.01% of the possible performance. Everybody just seems to be ok with it. People are often even proud about how inefficient it is, as in “why should we worry, computers are fast enough”: @tveastman: I have a Python program I run every day, it takes 1.5 seconds. I spent six hours re-writing it in rust, now it takes 0.06 seconds. That efficiency improvement means I'll make my time back in 41 years, 24 days :-) You’ve probably heard this mantra: “Programmer time is more expensive than computer time.” What it means basically is that we’re wasting computers at an unprecedented scale. Would you buy a car if it eats 100 liters per 100 kilometers? How about 1000 liters? With computers, we do that all the time. Everything is unbearably slow Look around: our portable computers are thousands of times more powerful than the ones that brought man to the moon. Yet every other webpage struggles to maintain a smooth 60fps scroll on the latest top-of-the-line MacBook Pro. I can comfortably play games, watch 4K videos, but not scroll web pages? How is that ok? Google Inbox, a web app written by Google, running in Chrome browser also by Google, takes 13 seconds to open moderately-sized emails: It also animates empty white boxes instead of showing their content because it’s the only way anything can be animated on a webpage with decent performance. No, decent doesn’t mean 60fps, it’s rather “as fast as this web page could possibly go”. I’m dying to see the web community answer when 120Hz displays become mainstream. Shit barely hits 60Hz already. Windows 10 takes 30 minutes to update. What could it possibly be doing for that long? That much time is enough to fully format my SSD drive, download a fresh build and install it like 5 times in a row. Pavel Fatin: Typing in editor is a relatively simple process, so even 286 PCs were able to provide a rather fluid typing experience. Modern text editors have higher latency than 42-year-old Emacs. Text editors! What can be simpler? On each keystroke, all you have to do is update a tiny rectangular region and modern text editors can’t do that in 16ms. It’s a lot of time. A LOT. A 3D game can fill the whole screen with hundreds of thousands (!!!) of polygons in the same 16ms and also process input, recalculate the world and dynamically load/unload resources. How come? As a general trend, we’re not getting faster software with more features. We’re getting faster hardware that runs slower software with the same features. Everything works way below the possible speed. Ever wonder why your phone needs 30 to 60 seconds to boot? Why can’t it boot, say, in one second? There are no physical limitations to that. I would love to see that. I would love to see limits reached and explored, utilizing every last bit of performance we can get for something meaningful in a meaningful way. Everything is HUUUUGE And then there’s bloat. Web apps could open up to 10 times faster if you just simply blocked all ads. Google begs everyone to stop shooting themselves in the foot with the AMP initiative—a technology solution to a problem that doesn’t need any technology, just a little bit of common sense. If you remove bloat, the web becomes crazy fast. How smart do you have to be to understand that? An Android system with no apps takes up almost 6 GB. Just think for a second about how obscenely HUGE that number is. What’s in there, HD movies? I guess it’s basically code: kernel, drivers. Some string and resources too, sure, but those can’t be big. So, how many drivers do you need for a phone? Windows 95 was 30MB. Today we have web pages heavier than that! Windows 10 is 4GB, which is 133 times as big. But is it 133 times as superior? I mean, functionally they are basically the same. Yes, we have Cortana, but I doubt it takes 3970 MB. But whatever Windows 10 is, is Android really 150% of that? Google's keyboard app routinely eats 150 MB. Is an app that draws 30 keys on a screen really five times more complex than the whole Windows 95? Google app, which is basically just a package for Google Web Search, is 350 MB! Google Play Services, which I do not use (I don’t buy books, music or videos there)—300 MB that just sit there and which I’m unable to delete. All that leaves me around 1 GB for my photos after I install all the essential (social, chats, maps, taxi, banks etc) apps. And that’s with no games and no music at all! Remember times when an OS, apps and all your data fit on a floppy? Your desktop todo app is probably written in Electron and thus has a userland driver for the Xbox 360 controller in it, can render 3D graphics and play audio and take photos with your web camera. A simple text chat is notorious for its load speed and memory consumption. Yes, you really have to count Slack in as a resource-heavy application. I mean, chatroom and barebones text editor, those are supposed to be two of the less demanding apps in the whole world. Welcome to 2018. At least it works, you might say. Well, bigger doesn’t imply better. Bigger means someone has lost control. Bigger means we don’t know what’s going on. Bigger means complexity tax, performance tax, reliability tax. This is not the norm and should not become the norm. Overweight apps should mean a red flag. They should mean run away scared. Everything rots A 16GB Android phone was perfectly fine 3 years ago. Today, with Android 8.1, it’s barely usable because each app has become at least twice as big for no apparent reason. There are no additional features. They are not faster or more optimized. They don’t look different. They just...grow? The iPhone 4s was released with iOS 5, but can barely run iOS 9. And it’s not because iOS 9 is that much superior—it’s basically the same. But their new hardware is faster, so they made software slower. Don’t worry—you got exciting new capabilities like...running the same apps with the same speed! I dunno. iOS 11 dropped support for 32-bit apps. That means if the developer isn’t around at the time of the iOS 11 release or isn’t willing to go back and update a once-perfectly-fine app, chances are you won’t be seeing their app ever again. @jckarter: A DOS program can be made to run unmodified on pretty much any computer made since the 80s. A JavaScript app might break with tomorrow’s Chrome update Web pages working today would not be compatible with any browser in 10 years time (probably sooner). “It takes all the running you can do, to keep in the same place”. But what’s the point? I might enjoy occasionally buying a new phone and new MacBook as much as the next guy, but to do so just to be able to run all the same apps which just became slower? I think we can and should do better than that. Everyone is busy building stuff for right now, today, rarely for tomorrow. But it would be nice to also have stuff that lasts a little longer than that. Worse is better Nobody understands anything at this point. Neither do they want to. We just throw barely baked shit out there, hope for the best and call it “startup wisdom”. Web pages ask you to refresh if anything goes wrong. Who has time to figure out what happened? Any web app produces a constant stream of “random” JS errors in the wild, even on compatible browsers. The whole webpage/SQL database architecture is built on a premise (hope, even) that nobody will touch your data while you look at the rendered webpage. Most collaborative implementations are “best effort” and have many common-life scenarios in which they lose data. Ever seen this dialogue “which version to keep?” I mean, the bar is so low today that your users would be happy to at least have a window like that. And no, in my world, an app that says “I’m gonna destroy some of your work, but you get to choose which one” is not okay. Linux kills random processes by design. And yet it’s the most popular server-side OS. Every device I own fails regularly one way or another. My Dell monitor needs a hard reboot from time to time because there’s software in it. Airdrop? You’re lucky if it’ll detect your device, otherwise, what do I do? Bluetooth? The spec is so complex that devices won’t talk to each other and periodic resets are the best way to go. And I’m not even touching the Internet of Things. It’s so far beyond the laughing point I’m not even sure what to add. I want to take pride in my work. I want to deliver working, stable things. To do that, we need to understand what we are building, in and out, and that’s impossible to do in bloated, over-engineered systems. Programming is the same mess It just seems that nobody is interested in building quality, fast, efficient, lasting, foundational stuff anymore. Even when efficient solutions have been known for ages, we still struggle with the same problems: package management, build systems, compilers, language design, IDEs. Build systems are inherently unreliable and periodically require full clean, even though all info for invalidation is there. Nothing stops us from making build processes reliable, predictable and 100% reproducible. Just nobody thinks its important. NPM has stayed in “sometimes works” state for years. @przemyslawdabek: It seems to me that rm -rf node_modules is indispensable part of workflow when developing Node.js/JavaScript projects. And build times? Nobody thinks compiler that works minutes or even hours is a problem. What happened to “programmer’s time is more important”? Almost all compilers, pre- and post-processors add significant, sometimes disastrous time tax to your build without providing proportionally substantial benefits. You would expect programmers to make mostly rational decisions, yet sometimes they do the exact opposite of that. E.g. choosing Hadoop even when it’s slower than running the same task on a single desktop. Machine learning and “AI” moved software to guessing in the times when most computers are not even reliable enough in the first place. @rakhim: When an app or a service is described as “AI-powered” or “ML-based”, I read it as “unreliable, unpredictable, and impossible to reason about behavior”. I try to avoid “AI” because I want computers to be the opposite: reliable, predictable, reasonable. We put virtual machines inside Linux, and then we put Docker inside virtual machines, simply because nobody was able to clean up the mess that most programs, languages and their environment produce. We cover shit with blankets just not to deal with it. “Single binary” is still a HUGE selling point for Go, for example. No mess == success. And dependencies? People easily add overengineered “full package solutions” to solve the simplest problems without considering their costs. And those dependencies bring other dependencies. You end up with a tree that is something in between of horror story (OMG so big and full of conflicts) and comedy (there’s no reason we include these, yet here they are): Programs can’t work for years without reboots anymore. Sometimes even days are too much to ask. Random stuff happens and nobody knows why. What’s worse, nobody has time to stop and figure out what happened. Why bother if you can always buy your way out of it. Spin another AWS instance. Restart process. Drop and restore the whole database. Write a watchdog that will restart your broken app every 20 minutes. Include same resources multiple times, zip and ship. Move fast, don’t fix. That is not engineering. That’s just lazy programming. Engineering is understanding performance, structure, limits of what you build, deeply. Combining poorly written stuff with more poorly written stuff goes strictly against that. To progress, we need to understand what and why are we doing. We’re stuck with it So everything is just a pile of barely working code added on top of previously written barely working code. It keeps growing in size and complexity, diminishing any chance for a change. To have a healthy ecosystem you need to go back and revisit. You need to occasionally throw stuff away and replace it with better stuff. But who has time for that? We haven’t seen new OS kernels in what, 25 years? It’s just too complex to simply rewrite by now. Browsers are so full of edge cases and historical precedents by now that nobody dares to write layout engine from scratch. Today’s definition of progress is either throw more fuel into the fire: @sahrizv: 2014 - We must adopt #microservices to solve all problems with monoliths. 2016 - We must adopt #docker to solve all problems with microservices 2018 - We must adopt #kubernetes to solve all problems with docker or reinventing the wheel: @dr_c0d3: 2000: Write 100s of lines of XML to \"declaratively\" configure your servlets and EJBs. 2018: Write 100s of lines of YAML to \"declaratively\" configure your microservices. At least XML had schemas... We’re stuck with what we have, and nobody will ever save us. Business won’t care Neither will users. They are only learned to expect what we can provide. We (engineers) say every Android app takes 350 MB? Ok, they’ll live with that. We say we can’t give them smooth scrolling? Ok, they’ll live with a phone that stutter. We say “if it doesn’t work, reboot”? They’ll reboot. After all, they have no choice. There’s no competition either. Everybody is building the same slow, bloated, unreliable products. Occasional jump forward in quality does bring competitive advantage (iPhone/iOS vs other smartphones, Chrome vs other browsers) and forces everybody to regroup, but not for long. So it’s our mission as engineers to show the world what’s possible with today’s computers in terms of performance, reliability, quality, usability. If we care, people will learn. And there’s nobody but us to show them that it’s very much possible. If only we care. It’s not all bad There are some bright spots indicating that improving over state-of-the-art is not impossible. Work Martin Thompson has being doing (LMAX Disruptor, SBE, Aeron) is impressive, refreshingly simple and efficient. Xi editor by Raph Levien seems to be built with the right principles in mind. Jonathan Blow has a language he alone develops for his game that can compile 500k lines per second on his laptop. That’s cold compile, no intermediate caching, no incremental builds. You don’t have to be a genius to write fast programs. There’s no magic trick. The only thing required is not building on top of a huge pile of crap that modern toolchain is. Better world manifesto I want to see progress. I want change. I want state-of-the-art in software engineering to improve, not just stand still. I don’t want to reinvent the same stuff over and over, less performant and more bloated each time. I want something to believe in, a worthy end goal, a future better than what we have today, and I want a community of engineers who share that vision. What we have today is not progress. We barely meet business goals with poor tools applied over the top. We’re stuck in local optima and nobody wants to move out. It’s not even a good place, it’s bloated and inefficient. We just somehow got used to it. So I want to call it out: where we are today is bullshit. As engineers, we can, and should, and will do better. We can have better tools, we can build better apps, faster, more predictable, more reliable, using fewer resources (orders of magnitude fewer!). We need to understand deeply what we are doing and why. We need to deliver: reliably, predictably, with topmost quality. We can—and should–take pride in our work. Not just “given what we had...”—no buts! I hope I’m not alone at this. I hope there are people out there who want to do the same. I’d appreciate if we at least start talking about how absurdly bad our current situation in the software industry is. And then we maybe figure out how to get out. September 17, 2018 · Related Good times create weak men · Discuss on HackerNews More HackerNews Reddit More Reddit Hi! I’m Niki. Here I write about programming and UI design Subscribe I also create open-source stuff: Fira Code, DataScript, Clojure Sublimed and Humble UI. If you like what I do and want to get early access to my articles, you should support me on Patreon.",
    "commentLink": "https://news.ycombinator.com/item?id=37985176",
    "commentBody": "Software disenchantmentHacker NewspastloginSoftware disenchantment (tonsky.me) 526 points by InsiderTesla 20 hours ago| hidepastfavorite390 comments nologic01 18 hours agoLeaner, cleaner, less buggy, more secure, more performant, longer-lived code is obviously entirely possible. If people managed to do it at the dawn of the information age surely they can do it today, with multiple decades of massive experience, not to mention the incredibly powerful tools developed in the meantime.If its not done its because there is no money in it. In fact the opposite.The counter-incentives to wasting time on high quality software are numerous and affect all sorts of teams. VC funded startups must get to market first or die. Fake-it-till-you-make-it is their religion. For more mature organizations too, cost and bloat is not an issue. Its a feature. The bigger the team more prestige for the managers etc. The costs are passed on to clients anyway.How come \"ruthless market forces\" don&#x27;t rectify this wastefulness? You&#x27;d think that codebases of superior quality will earn the keys to the kingdom. They might, eventually. In a competitive environment that is less prone to pathologies, hypes etc. reply freediver 16 hours agoparentKagi is not VC funded, yet we have code that is sub-optimal, a ton of bugs and odd performance issues here and there. Knowing what I know about software development, I do not think this is avoidable, regardless of the source of funding or size of the company. It is a factor of complexity of the software, resources available and incentives in place.What we can do though, that perhaps VC funded companies can not as easilly, is alocate time to refactor code and deal with tech debt. In fact that is what we are currently doing and we basically pulled a handbreak on all new feature developement for 45 days to deal with our main tech issues. Ability to do this requires a long term thinking horizon. Very difficult to make that kind of investment if you expect to get acquired next year and tech debt becomes somebody else&#x27;s problem.Also worth noting, as long as the product is being actively developed it will aways have new bugs and issues. &#x27;Perfect code&#x27; is achieveable only in a closed context scenario, where new features are not added any more. (which randomly bring this weird thought to my head, that the only human that does not do any mistakes any more is a dead one; perfection in human actions is only achieved in the absence of life... ok need to stop there) reply thenobsta 14 hours agorootparent> which randomly bring this weird thought to my head, that the only human that does not do any mistakes any more is a dead one; perfection in human actions is only achieved in the absence of life... ok need to stop thereLove a good philosophical tangent! Wish you expanded :) reply oddly 2 hours agorootparentLet’s hope this doesn’t get taken up by a sentient AI in the future :-) reply gtowey 17 hours agoparentprev> If its not done its because there is no money in it. In fact the oppositeThis bears repeating. It&#x27;s the disease that has consumed software and is making all modern software the worst possible version of itself.I think it&#x27;s the VC funding model which has driven the industry this way. Startups get millions in funding, then it&#x27;s a race to make enough money to pay back those investors which leads to this. The companies have to squeeze dollars from their app as fast as possible which means anything that doesn&#x27;t have a ROI metric attached to it will not get a second of anyone&#x27;s attention. reply smith7018 17 hours agorootparentHonestly, there are many reasons for our current situation. One is that companies aren&#x27;t (usually) run by engineers; they&#x27;re run by product or business people. Those types don&#x27;t care about performance, website footprints, smooth scrolling, etc. They care about adding new features, getting users, and doing so as fast as possible. Another reason is that many web developers were taught that software engineering is mashing together a mixture of Node, Ionic, Bootstrap, Vue.js, Angular, jQuery, etc. to quickly make a website. No one was taught how to do things on their own so they just bundle framework after framework into their projects just to do simple things. Finally, it&#x27;s not like people built highly performant software in the 90s because they genuinely embodied this article&#x27;s spirit; they did so out of necessity. As soon as computers got fast enough, we stopped having to focus on micro-optimizations just to get our products to run. reply webdood90 16 hours agorootparent> Those types don&#x27;t care about performance, website footprints, smooth scrolling, etcthey don&#x27;t care because their _users_ don&#x27;t care.I find these discussions are always led by engineers, shaking their fists at clouds. nobody cares! it doesn&#x27;t make any money so you&#x27;re just whining into the void. reply jack_h 16 hours agorootparentThat&#x27;s like saying only engineers care about appliances that work long past the warranty expiration; users don&#x27;t so business people value engineer it and everyone except the engineers are happy.Except that&#x27;s not true. Users do care they just don&#x27;t have a choice in the matter. I have listened to many, many laypeople who have expressed frustration with software. They may not be able to articulate it to the extent that the quote does, but when they&#x27;re stuck on 3G and they need to load a webpage that keeps timing out they get frustrated even if they don&#x27;t know its because of the footprint, it&#x27;s a poorly made SPA, or whatever. reply lelanthran 15 hours agorootparentprev> they don&#x27;t care because their _users_ don&#x27;t care.I respectfully disagree. I think the users care, but they don&#x27;t make their own choices - their choices are made for them by people who don&#x27;t care!Was MS Teams chosen by their end-users? Nope.Come to think of it - was Slack chosen by their end-users? No, again.End-user&#x27;s aren&#x27;t given an option, usually:1. For B2B the choice rests with one (or a few) people.2. For B2C the choice is made purely because some product got some traction for reasons unrelated to its quality, and that was enough to force the rest of the users to follow or be left out of the network (Slack, Facebook, major shopping sites, etc).The majority of end-users did not exercise any choice. reply el_memorioso 15 hours agorootparentprevI think often users do care but they have no meaningful way to tell anyone this or otherwise cause change. I hate the banking web app (from a major US bank) that I have to use. It is incredibly slow, buggy, poorly laid out, and occasionally just decides to put up a spinner forever. Who do I complain to about this. If you call and tell a customer service rep they&#x27;ll just tell you to refresh and try again, often sympathetically. They know its terrible and hear many complaints themselves, but also have no power to do anything about it. reply taeric 16 hours agorootparentprevThis gives engineers a bit too much credit. We have a tendency to heavily over index on last year&#x27;s problems. That or exploring edge cases that also make no bloody sense.Indeed, the very existence of so many frameworks is also very easy to blame on errant engineering. reply lelanthran 15 hours agorootparent> This gives engineers a bit too much credit. We have a tendency to heavily over index on last year&#x27;s problems. That or exploring edge cases that also make no bloody sense.When I was in university (a long time ago, shortly after the big bang :-)) the informal motto of the computer science faculty and students was Computer Science: Solving Yesterdays Problems, Tomorrow!Now that I think about it, I don&#x27;t find it that funny anymore. reply VladimirGolovin 17 hours agorootparentprev>> It&#x27;s the disease that has consumed softwareThis is another example of Scott Alexander&#x27;s Moloch: https:&#x2F;&#x2F;www.slatestarcodexabridged.com&#x2F;Meditations-On-Moloch\"companies in an economic environment of sufficiently intense competition are forced to abandon all values except optimizing- for-profit or else be outcompeted by companies that optimized for profit better and so can sell the same service at a lower price.\" reply duckmysick 15 hours agoparentprevI don&#x27;t think software used to be more secure. As computer users we were more trusting, if not to say naive. As more machines connected to networks, we learned a thing or two.Open access by default. No passwords [1] or short passwords. Then insecurely stored passwords. Everything in plaintext. Input sanitation? Why bother, only I can input data, I trust myself. Don&#x27;t get me started on telnet.I suspect that&#x27;s another reason why software is more bloated. We started noticing things, how they interact with each other. And once you see something, you can&#x27;t unsee it. The edge cases we have to account for are growing, not decreasing. There&#x27;s more hardware to support too.I&#x27;m sure the whole process of writing performant code can be improved. At the same time the bar is being raised faster than we can (or want to) reach it.1 - And now we&#x27;re inching towards no passwords again. reply nologic01 14 hours agorootparentSecurity is indeed an important dimension because it holds the key (pun) for ever more important applications. I agree that a more detailed, like-for-like comparison of software qualities across decades needs to be very careful. Applications have exploded in all domains. But then also the ranks of software engineers and their tools and ability to exchange best practices has exploded.The trouble with exponential curves is that a small difference in rates can create dramatic discrepancies. reply cosmic_quanta 17 hours agoparentprev> If its not done its because there is no money in it. In fact the opposite.Exactly my thought. Incentives are not aligned. There are industry sectors where performance and correctness have value. If you care about the software craft in the same way as the aithor (as I do!) then the best way to enjoy work is to move to such industry sectors. reply ardi11 16 hours agorootparentCare to provide examples of such sectors? Thanks. reply l0b0 12 hours agorootparentNot GP, but IME researchers often run big, complex simulations, and often have to care deeply about performance. Correctness, less so, unfortunately. A lot of research software is written by researchers themselves with very little understanding of good software development principles and practices, and end up messy, overly complex, and buggy. That said, being a software developer within research can be the best of both worlds. You should be able to demonstrate (using perf tools, and comparing with existing comparable software) that you&#x27;re squeezing a lot out of the hardware, while being able to construct maintainable, tested software. reply cosmic_quanta 15 hours agorootparentprevThe only one I have hands-on experience with is financial trading. My workplace is expanding into a new asset class and we&#x27;re using Haskell for this. The company next door from us is a crypto-trading company using Rust.I can only speculate about other sectors where it might make sense: - Hardware synthesis (i.e. the software used to design silicon chips); - Aerospace; - Defense; - Smart city devices; reply lelanthran 15 hours agorootparentprev>> There are industry sectors where performance and correctness have value.> Care to provide examples of such sectors? Thanks.I worked for years developing munitions control software.Never once killed anyone by accident. reply eastbound 16 hours agorootparentprevAnything involving hardware.Except car manufacturers. reply p00f 15 hours agorootparentWhat makes car manufacturers different? reply _TwoFinger 13 hours agorootparentNot PP, but I used to work for an automotive subcontractor company, and I&#x27;ve heard a few stories about fatal car accidents that lead to lawsuits, which proved that the car design was the reason for the accident, yet the car manufacturer just payed \"damages\" to the relatives (or settled out of court, maybe) and never bothered to change the design. Apparently, it was more expensive to reconfigure their production pipelines than pay for an occasional death.That said, this is probably what any big enough company would do. So your point still stands, maybe car manufacturers are no different. reply eastbound 3 hours agorootparentprevThe infotainment system, it’s basically as safe as a web stack (and on the CAN bus). replycurrymj 16 hours agoparentprevi think ordinary people frequently feel frustrated with low-quality software, but it seems to me not necessarily in a way they can consciously articulate. that is, they probably can tell when software is frustrating to use, but they don&#x27;t notice a clear difference between:- slow, high-latency software- poor resource usage slowing down the whole machine, including from unrelated software- bad user interface design- bugs- intentionally bad&#x2F;manipulative patternsif the customers can&#x27;t even really perceive what it is they are buying, it&#x27;s not surprising that market forces aren&#x27;t solving the problem.i&#x27;m not a user interface designer or researcher so of course this could be totally wrong -- just an impression from informal observation reply nologic01 15 hours agorootparentyour comment made me think that despite the main thrust of my comment, this trajectory is not completely money driven [1]. the incredible journey of the hardware side of technology (cpu speed, memory size, network bandwidth etc) has also played a role in this profligacy because it can cover for a lot of less optimal designthis is something that happens more widely in the use of resources: you build more highways and instead of relieving congestion you get more people commuting[1] my open source and volunteer-built linux distribution (will not name names) routinely (like almost daily) prompts for GB sized system updates. reply benrutter 16 hours agoparentprevI&#x27;m not sure how well \"ruthless market forces\" are allowed to operate in software. You definitely get some disrupters but for the most part I think a lack of competition is part of the problem.Microsoft Teams is one of the most buggy, unreliable pieces of software I know, but it&#x27;s still the market leader in terms of share because of Microsoft&#x27;s near monopoly of the office suite software world. reply Kalium 16 hours agorootparentIt may be worth considering that the market is not for messaging and workspaces, but mainly for integrated business communications systems. If the integration is more valuable to customers than Slack or Zoom&#x27;s smooth operation, Teams is going to win out. reply xigoi 16 hours agorootparentprevThis is why we need stronger anti-monopoly enforcement. reply agentultra 17 hours agoparentprevAt a data-centre scale they might still. Even marginal gains in efficiency translate to large savings in power consumption, heat management, and waste. If tech companies are properly taxed and regulated for these externalities, like say consuming billions of litres of fresh water during a drought in order to train a ML model, there would be a lot more pressure for this sort of efficiency. reply iinnPP 17 hours agorootparentThis is where I normally end up in the software is way too slow today discussion.Everyone claims to care about the environment until it impacts them even slightly. It&#x27;s not even hard&#x2F;time consuming to write good code. People are just overwhelmingly selfish and lazy.Software devs consistently contribute to the environmental problems that many software devs then complain about and pretend is only a redneck issue. The reality is that we have an incredibly serious idiot issue and there isn&#x27;t a solution due to the scale of the problem and the corruption preventing meaningful change.An article the other day pointed out the problem well as well. Though it was related to the increasing lack of people who understand the code underneath the current flavour of the month bullshit framework. reply eastbound 15 hours agorootparent> Software devs consistently contribute to the environmental problemsIt doesn’t help that schwabists try to provide indexes such as “Java consumes more than JS”.This kind of sentences, measuring the immeasurable like a square meter takes more energy than a liter, communicates “We’ll dominate you with power while understanding nothing of what you do, and tax you for using Java”. I bet it’s Facebook’s PHP lobbyists who came up with that.If heating is a problem, then by all means, tax CPU time. But I already know the tax won’t matter because software provides such an immense value to society. We already pay average engineers $800 a day! But we shouldn’t try to get rid of a language.If they knew what they were doing, they’d certainly ban NPM. But of course there are already GitHub actions and Sonar extensions publishing the CO2 consumption index of Java programs... reply nologic01 17 hours agorootparentprevyep. but also mundane and cyclical factors like the much higher cost of money after decades of ZIRP are likely to \"encourage\" people to do more with less. reply MarkusWandel 17 hours agoparentprevThere&#x27;s hardware bloat too. Old fart example: In the days of analog SD TV, the \"foolproof\" way to feed video into your TV was an RF modulator. The \"proper\" way was via direct video input of some sort. The \"even more proper\" way was an RGB type interface.Except by the end it hardly mattered any more. RF modulators and tuners had gotten so good, that perfectly adequate video resulted from the RGB -> composite -> RF -> composite -> RGB chain. Bloat, but who cares?In an automobile, the \"proper\" way to charge a phone is to have a 12VDC->USB type of adapter plug. The \"bloat\" way is to have a 12VDC->120VAC inverter and then plug the phone&#x27;s existing wall charger into that. More circuitry, but it gets the job done and it&#x27;s cheap.If you like designing electronic gadgets, the \"proper\" way to flash an LED is two transistors and a couple of resistors and capacitors to build an astable multivibrator. The modern way is to program up a small 8-pin microcontroller. A CPU running thousands of lines of code just to blink an LED? Who cares.If your computer&#x2F;tablet&#x2F;phone are reasonably recent it&#x27;s the same for software. It&#x27;s only when your gadget is a few years old that you really see the bloat as formerly performant software \"degrades\" in later versions. reply tuna74 15 hours agorootparent\"Except by the end it hardly mattered any more. RF modulators and tuners had gotten so good, that perfectly adequate video resulted from the RGB -> composite -> RF -> composite -> RGB chain. Bloat, but who cares?\"Eh, no it didn&#x27;t. That would just look horrible. reply MarkusWandel 9 hours agorootparentThis was with a DVD recorder unit. Composite or RF? It really didn&#x27;t look that different (and both looked good, by SD video standards). reply ulizzle 11 hours agoparentprevI think software is so complex that the house of cards eventually falls and ruins the company. Then everyone is mad and the workplace becomes toxic. Most companies fail so eventually the market does rectify it but it can be a long slog until that happens, at least when there was so much money being thrown around.But the quality of the codebase definitely had less effect in the company’s success than you’d expect, like you said. The costs are just shuffled down to the customers and developers while everyone else gets rich. reply danielovichdk 17 hours agoparentprevAsk yourself whether you want to be remembered for selling millions of copies next year, or leaving behind something that in time might be cherished by generations.Look outside software and see what things has been deemed quality and why.Usually the people doing quality make very few comprises and often they don&#x27;t do it on purpose.Quality solely starts with yourself. Only you can guarantee within your own merits and experience what quality is.Explaining quality is thereby difficult because it is so determined by the personal traits and experience. reply chairhairair 16 hours agorootparentMy personality trait: I need to feed my family. reply foooorsyth 17 hours agoparentprevQuite simply: you don’t ship code, you ship features. You don’t ship automated dependency injection. You don’t ship elegant abstractions. You don’t ship cool compiler tricks. You ship new stuff for customers that they’ll pay for. Your high unit test coverage that makes any refactor a painful slog gets in the way of shipping features far more often than the TDD zealots are willing to admit. Most of the “best practices” in the industry is unrealistic dogma created by people in post PMF, entrenched companies that no longer need to do much to print money. reply jimbokun 16 hours agorootparent> Your high unit test coverage that makes any refactor a painful slogHuh? Unit tests are critical to be able to perform a major refactor without breaking everything. reply foooorsyth 14 hours agorootparentOnly when your refactor only touches business logic underneath the public API. If you do a true rewrite that breaks tests, getting your coverage back up to what it was before the refactor just delays your ship date. And many engineers WILL get green bar syndrome once that coverage % goes down, losing sight of real business goals (staying alive and making payroll). I’ve seen lots of codebases where obsession over unit tests lead to tests that were orders of magnitudes more complex than the system under test. This is incredibly common in multiple process or multi device software, where there’s some sort of custom protocol over an IPC or network or RF layer. You’ll invariably see massive amounts of effort put into mocking complementary parties inside a unit test framework, when the sane thing to do is to just write a 5 line bash script for an integration level test. Or — brace yourself — just do a manual test and ship it today. reply uoaei 17 hours agorootparentprevThat&#x27;s how MBAs talk, not how engineers talk. reply mjr00 16 hours agorootparentEngineers understand that the entire discipline is about tradeoffs. It would be extremely easy to build reliable, secure, performant, robust, etc software given infinite time and infinite budget. Engineering is about working in the real world, where you don&#x27;t have infinite time or budget.Is it correct to build a piece of software that runs 50% slower, but can be built in 6 months instead of 12? The answer is \"it depends\" and good engineers will seek to understand the broader context of the business, users, and customers to make that decision. reply batshit_beaver 16 hours agorootparentprevA conflict as old as time. Unfortunately, it&#x27;s the MBA thinking that pays the company&#x27;s bills.An ideal world isn&#x27;t one in which either the MBAs or the engineers win. It&#x27;s one in which they coexist and find a reasonable balance between having more useful features than the competition and not expending too much effort to build and maintain those features. reply foooorsyth 16 hours agorootparentprevNo, it’s how anyone that’s actually worked in an SMB &#x2F; non F-1000 &#x2F; non household name company talks. Most “regular” companies need to focus on getting features out the door.I’m a software engineer, not an MBA. reply uoaei 16 hours agorootparentYou are not anything until you act as something. Acting like an MBA makes you virtually indistinguishable from one. I don&#x27;t care what you studied, it&#x27;s what you&#x27;re doing (or not) with it. reply foooorsyth 16 hours agorootparentYour entire stance is no true Scotsman with ad hominem. You realize almost every YC company operates in the way I described until they become entrenched in their domain, right? Do you think pre PMF companies are bickering about unit test coverage? If they are, they’ll fail reply uoaei 16 hours agorootparentIt&#x27;s really a basic point that I can call myself whatever I want, but if I walk and quack like a duck, I&#x27;m a duck.YC is a VC firm which is a very specific context that demands things like revenue and growth to be so prioritized as to be implicit and core features of the working ideology. That&#x27;s not really a good model for software engineering when it comes to social benefit -- it prioritizes something else. It can demonstrate incidental social benefit but that&#x27;s not actually an incentive that&#x27;s built into the system that YC operates in and reflects internally.There are Scotsmen out there, they&#x27;re just not part of this discussion. That doesn&#x27;t make anything I said a \"no true Scotsman\" argument. reply foooorsyth 16 hours agorootparentHere&#x27;s a repo for you with no test coverage and no auto-generated DI. They&#x27;re using unsafe pointers all over the place, too!https:&#x2F;&#x2F;github.com&#x2F;id-Software&#x2F;DOOMShall I prepare the postage for the letter in which you&#x27;ll call John Carmack an MBA? Should we send another to Chris Sawyer? I heard he didn&#x27;t even write a formal design doc for Roller Coaster Tycoon! reply uoaei 12 hours agorootparentYou&#x27;ve either intentionally cast my argument as something it&#x27;s not or you need to read a little deeper before replying.Nowhere did I say sloppy code is the problem, what I said was justifying it in terms of profitability is the problem. There&#x27;s a difference between cranking something out because you&#x27;re excited to show it and rushing through an implementation because of this or that externally defined money-based KPI. replyjrm4 12 hours agoparentprevAnd the answer is the same as the answer has always been. When the market fails, you need to look to law and policy. It&#x27;s really that simple.We&#x27;ve done it a bit, Apple&#x27;s little wrist-slap for slowing down the iPhones, for example.We just need more of it. I know it&#x27;s all anti-Libertarian or whatnot, but \"more regulation\" has worked quite a bit in the past and present. Just do that. reply gherkinnn 16 hours agoparentprevI agree. And this is why I believe most of the points made by Jonathan Blow don’t matter. reply auiya 15 hours agoparentprevIf the goal is to make money, you will make money. If the goal is to make quality software, you will make quality software. Sometimes those two goals are in alignment, most of the time they are at odds. reply natoliniak 14 hours agorootparentin my experience, when it comes to picking two out of: quality, cost, or speed to delivery, businesses always choose speed and cost. I dont&#x27; like it, but I just grew to accept that. The reason why physical engineering seems focused on delivering quality is because of strict regulatory oversight, which for better or worse, we lack in software. reply nologic01 14 hours agorootparentgood quality software (say, based on well designed, documented, tested etc. building blocks) can lower costs and improve speed to delivery in the longer run (less need to refactor, fewer bugs, easy to reuse, extend etc. etc.)the trouble, empirically speaking, is that this \"longer run\" is not close enough to weigh on decisions :-) reply dustingetz 16 hours agoparentprevZIRP is how come the market forces don’t rectify it. Market is mis-allocating capital on purpose, result is “Zombie firms” reply MarkusWandel 18 hours agoprevI have a still barely usable HP MS200 all-in-one machine. I got it cheap at a garage sale in 2017. It wasn&#x27;t fast, but with Linux on it, once Google Chrome was finally loaded, it was OK, even to the point of running the web version of Skype for fullscreen video chats, certainly for watching fullscreen Youtube. It went off to the in-laws as a Youtube watching and Gmail station.Recently it came back to me. And with the old, 2017 vintage software on it, still worked as it did then. But before making it a kiddie computer, I installed FC38 and the current version of Chrome.But Youtube videos were now \"slide shows\". No amount of fiddling with the settings made them play right. Finally gave up and changed the RAM from 2GB to 3GB - I just happened to have the right (laptop) memory card to do that.And that brought it back to the old, barely adequate (720p fullscreen without noticeable skips) performance. 1.5x as much memory, an extra gigabyte, to do the same thing as six years ago.\"So get with the program and buy an adequate machine! Don&#x27;t you know that 16GB is the absolute minimum to get anything done these days?\" Sure - I have machines with 16GB+ in them. Even on the crappy machine though, Google Chrome is showing a memory footprint on the order of 30GB. I&#x27;m sure most of that is mmap&#x27;ed files; it sure isn&#x27;t RAM. But 30GB. For a mostly idle web browser. reply jeroenhd 18 hours agoparentYoutube is a great example of the performance difference. Videos have risen in quality because of modern codecs, but old or cheap machines need to decode them in software (sometimes in Javascript, which is terribly wasteful but works on every machine) because they lack a modern GPU. On the other hand, for most devices, the increased battery life, lower temperatures, and smaller RAM&#x2F;disk space requirements are obvious improvements. Youtube could leave duplicate files with the old encoding on their servers (if you use an alternative frontend for Youtube, you can often see the old file formats still being available for old content!) but that&#x27;s just wasted space with most of the world visiting from more recent devices.Most RAM usage increases in Chrome have come from advancements in the sandboxing architecture. Shared memory and process space could be used to attackaand bust out of sandboxes, so more isolation was added. I&#x27;m sure there are some more useless features leading to a jump in RAM usage as well, but the really big ones always seem to be the fact Chrome spawns a new, independent process for every tab&#x2F;extension.I&#x27;ve also noticed how much impact ad blockers have these days. With the web becoming ever shittier, effective adblockers have become harder to make and need more resources to do their job.Software doesn&#x27;t get slower just to make your day harder. In many cases, slow software is a result of replacing dangerous hacks by good implementations and changing requirements. FLV videos just don&#x27;t cut it anymore, and I doubt h264 will be around in five years with h265 and AV1 making it&#x27;s way to more and more devices. reply smikhanov 17 hours agorootparentExcellent remark. For each \"I needed an extra gigabyte of RAM in my computer to do the same thing as six years ago\" complaint there is normally a valid reason like this. It&#x27;s always not exactly the same thing as six years ago, really.Oh, and the same applies to the original blog post, too. reply Culonavirus 15 hours agorootparentprevAV1 is a massive flop in my opinion. What was supposed to be the be all end all open source video format of the future just recently barely starts to pop up here and there. There are tech demos and talks of Youtube etc. using AV1, but in the same breath they say it&#x27;s mostly for really low bitrate where the AV1 gains the most. Also I&#x27;m sure no one is looking forward to burn CPU time (or very lately, GPU time) on encoding 4k+ streams. Is that even financially viable? You save 30% on bandwith and spend 10000% more on server HW time. (I&#x27;ll admit that these numbers are pulled from my ass, but they&#x27;re based on a few years old knowledge of AV1 encoders being like 350-3500 times slower than h264 encoders, depending on optimization.)The entire \"there was no usable encoder and no hw decoder for years\" thing didn&#x27;t help and even now it&#x27;s still all slow and complex, who has time and money for that?AV1 is just too complex for what it produces in comparison with the good old h264 or vp9. reply jeroenhd 11 hours agorootparentAV1 performs just fine, the problem is that it started gaining popularity at a time that new hardware has exploded in cost, especially for computers. h265 has been in computer hardware for a while, but as I have found out trying to play some special h265 stream on my laptop in the train, software decodes will easily peg the CPU as much as AV1 does.h265 hardware decoding came out in 2015 with Nvidia&#x27;s 9xx series, while AV1 took until the unaffordable Nvidia 30xx&#x2F;Intel Xe&#x2F;RDNA 2 generation to become available. Encoding support took even longer (RDNA3&#x2F;Xe 2&#x2F;Arc&#x2F;40xx). In a few years, I&#x27;m sure it&#x27;ll be as popular a format as h265 is today. reply aaaronic 18 hours agoparentprevWeb browsers in particular have become operating systems unto themselves. The \"modern web\" has so many features, often implemented in half a dozen competing ways... Just text rendering on modern hardware can be a HUGE lift.Modern toolchains are all about \"not reinventing the wheel\" -- but when each dependency has picked a different version of said wheel, just pulling in a few dependencies leads to 6 different implementations of the same low-level features. reply chankstein38 17 hours agorootparentThis is one of the reasons the announcements about WebGPU made me cringe. Yeah, just what I need, more unnecessary complexity added to webpages. Especially when there&#x27;s seemingly a chance people will use them to mine crypto on my GPU while I&#x27;m on their page. reply MarkusWandel 18 hours agoparentprevI forgot to mention this: Every time I install a new Linux system, I give the \"factory\" UI a chance before, inevitably, giving up and switching to MATE. Well, Gnome Shell was actually pretty crisply responsive on this clunker. And it has an \"app store\". And that has Chrome in it. Well well! But that installed a FlatPak. Bloat, bloat, bloat. Luckily Chrome is still directly \"natively\" installable as an RPM that actually uses the OS&#x27;s shared libraries. reply WesolyKubeczek 18 hours agorootparentSure it’s using system ones and not the vendored ones? I mean chrome as packaged by Google, not, say, Fedora’s Chromium (which is bent and coerced to use system libraries as much as possible). reply MarkusWandel 17 hours agorootparentGood point, so I checked. It has a few private libraries but for the most part uses the system ones. I think I can paste this output without leaking anything personal...linux-vdso.so.1 (0x00007ffd353a6000) libdl.so.2 => &#x2F;lib64&#x2F;libdl.so.2 (0x00007f852c4ea000) libpthread.so.0 => &#x2F;lib64&#x2F;libpthread.so.0 (0x00007f852c4e5000) libgobject-2.0.so.0 => &#x2F;lib64&#x2F;libgobject-2.0.so.0 (0x00007f851eba4000) libglib-2.0.so.0 => &#x2F;lib64&#x2F;libglib-2.0.so.0 (0x00007f851ea69000) libnss3.so => &#x2F;lib64&#x2F;libnss3.so (0x00007f851e92b000) libnssutil3.so => &#x2F;lib64&#x2F;libnssutil3.so (0x00007f852c4b2000) libsmime3.so => &#x2F;lib64&#x2F;libsmime3.so (0x00007f851e8ff000) libnspr4.so => &#x2F;lib64&#x2F;libnspr4.so (0x00007f851e8bc000) libatk-1.0.so.0 => &#x2F;lib64&#x2F;libatk-1.0.so.0 (0x00007f851e892000) libatk-bridge-2.0.so.0 => &#x2F;lib64&#x2F;libatk-bridge-2.0.so.0 (0x00007f851e859000) libcups.so.2 => &#x2F;lib64&#x2F;libcups.so.2 (0x00007f851e7ba000) libgio-2.0.so.0 => &#x2F;lib64&#x2F;libgio-2.0.so.0 (0x00007f851e5e0000) libdrm.so.2 => &#x2F;lib64&#x2F;libdrm.so.2 (0x00007f852c498000) libdbus-1.so.3 => &#x2F;lib64&#x2F;libdbus-1.so.3 (0x00007f851e58d000) libatspi.so.0 => &#x2F;lib64&#x2F;libatspi.so.0 (0x00007f851e550000) libexpat.so.1 => &#x2F;lib64&#x2F;libexpat.so.1 (0x00007f851e51f000) libm.so.6 => &#x2F;lib64&#x2F;libm.so.6 (0x00007f851e443000) libX11.so.6 => &#x2F;lib64&#x2F;libX11.so.6 (0x00007f851e2fb000) libXcomposite.so.1 => &#x2F;lib64&#x2F;libXcomposite.so.1 (0x00007f852c491000) libXdamage.so.1 => &#x2F;lib64&#x2F;libXdamage.so.1 (0x00007f852c48c000) libXext.so.6 => &#x2F;lib64&#x2F;libXext.so.6 (0x00007f851e2e6000) libXfixes.so.3 => &#x2F;lib64&#x2F;libXfixes.so.3 (0x00007f851e2dd000) libXrandr.so.2 => &#x2F;lib64&#x2F;libXrandr.so.2 (0x00007f851e2d0000) libgbm.so.1 => &#x2F;lib64&#x2F;libgbm.so.1 (0x00007f851e2bf000) libxcb.so.1 => &#x2F;lib64&#x2F;libxcb.so.1 (0x00007f851e292000) libxkbcommon.so.0 => &#x2F;lib64&#x2F;libxkbcommon.so.0 (0x00007f851e249000) libpango-1.0.so.0 => &#x2F;lib64&#x2F;libpango-1.0.so.0 (0x00007f851e1e2000) libcairo.so.2 => &#x2F;lib64&#x2F;libcairo.so.2 (0x00007f851e0c6000) libasound.so.2 => &#x2F;lib64&#x2F;libasound.so.2 (0x00007f851dfb7000) libgcc_s.so.1 => &#x2F;lib64&#x2F;libgcc_s.so.1 (0x00007f851df9c000) libc.so.6 => &#x2F;lib64&#x2F;libc.so.6 (0x00007f851dc00000) &#x2F;lib64&#x2F;ld-linux-x86-64.so.2 (0x00007f852c512000) libffi.so.6 => &#x2F;lib64&#x2F;libffi.so.6 (0x00007f851df8f000) libpcre.so.1 => &#x2F;lib64&#x2F;libpcre.so.1 (0x00007f851df17000) libplc4.so => &#x2F;lib64&#x2F;libplc4.so (0x00007f851df10000) libplds4.so => &#x2F;lib64&#x2F;libplds4.so (0x00007f851df0b000) libgssapi_krb5.so.2 => &#x2F;lib64&#x2F;libgssapi_krb5.so.2 (0x00007f851deb2000) libavahi-common.so.3 => &#x2F;lib64&#x2F;libavahi-common.so.3 (0x00007f851dea4000) libavahi-client.so.3 => &#x2F;lib64&#x2F;libavahi-client.so.3 (0x00007f851de8f000) libgnutls.so.30 => &#x2F;lib64&#x2F;libgnutls.so.30 (0x00007f851d800000) libz.so.1 => &#x2F;lib64&#x2F;libz.so.1 (0x00007f851de75000) libgmodule-2.0.so.0 => &#x2F;lib64&#x2F;libgmodule-2.0.so.0 (0x00007f851de6e000) libmount.so.1 => &#x2F;lib64&#x2F;libmount.so.1 (0x00007f851de27000) libselinux.so.1 => &#x2F;lib64&#x2F;libselinux.so.1 (0x00007f851dbd5000) libsystemd.so.0 => &#x2F;lib64&#x2F;libsystemd.so.0 (0x00007f851db03000) libXi.so.6 => &#x2F;lib64&#x2F;libXi.so.6 (0x00007f851de15000) libXrender.so.1 => &#x2F;lib64&#x2F;libXrender.so.1 (0x00007f851daf6000) libwayland-server.so.0 => &#x2F;lib64&#x2F;libwayland-server.so.0 (0x00007f851dae0000) libstdc++.so.6 => &#x2F;lib64&#x2F;libstdc++.so.6 (0x00007f851d400000) libXau.so.6 => &#x2F;lib64&#x2F;libXau.so.6 (0x00007f851de0d000) libfribidi.so.0 => &#x2F;lib64&#x2F;libfribidi.so.0 (0x00007f851dac0000) libthai.so.0 => &#x2F;lib64&#x2F;libthai.so.0 (0x00007f851dab5000) libharfbuzz.so.0 => &#x2F;lib64&#x2F;libharfbuzz.so.0 (0x00007f851d729000) libpixman-1.so.0 => &#x2F;lib64&#x2F;libpixman-1.so.0 (0x00007f851d67d000) libfontconfig.so.1 => &#x2F;lib64&#x2F;libfontconfig.so.1 (0x00007f851da66000) libfreetype.so.6 => &#x2F;lib64&#x2F;libfreetype.so.6 (0x00007f851d335000) libpng16.so.16 => &#x2F;lib64&#x2F;libpng16.so.16 (0x00007f851da2d000) libxcb-shm.so.0 => &#x2F;lib64&#x2F;libxcb-shm.so.0 (0x00007f851da28000) libxcb-render.so.0 => &#x2F;lib64&#x2F;libxcb-render.so.0 (0x00007f851d66d000) libkrb5.so.3 => &#x2F;lib64&#x2F;libkrb5.so.3 (0x00007f851d257000) libk5crypto.so.3 => &#x2F;lib64&#x2F;libk5crypto.so.3 (0x00007f851d655000) libcom_err.so.2 => &#x2F;lib64&#x2F;libcom_err.so.2 (0x00007f851d64e000) libkrb5support.so.0 => &#x2F;lib64&#x2F;libkrb5support.so.0 (0x00007f851d63d000) libkeyutils.so.1 => &#x2F;lib64&#x2F;libkeyutils.so.1 (0x00007f851d636000) libcrypto.so.1.1 => &#x2F;lib64&#x2F;libcrypto.so.1.1 (0x00007f851ce00000) libresolv.so.2 => &#x2F;lib64&#x2F;libresolv.so.2 (0x00007f851d622000) libp11-kit.so.0 => &#x2F;lib64&#x2F;libp11-kit.so.0 (0x00007f851d125000) libidn2.so.0 => &#x2F;lib64&#x2F;libidn2.so.0 (0x00007f851cdaf000) libunistring.so.2 => &#x2F;lib64&#x2F;libunistring.so.2 (0x00007f851cc2a000) libtasn1.so.6 => &#x2F;lib64&#x2F;libtasn1.so.6 (0x00007f851d10d000) libnettle.so.8 => &#x2F;lib64&#x2F;libnettle.so.8 (0x00007f851cbd7000) libhogweed.so.6 => &#x2F;lib64&#x2F;libhogweed.so.6 (0x00007f851cb94000) libgmp.so.10 => &#x2F;lib64&#x2F;libgmp.so.10 (0x00007f851caf1000) libblkid.so.1 => &#x2F;lib64&#x2F;libblkid.so.1 (0x00007f851cab9000) libpcre2-8.so.0 => &#x2F;lib64&#x2F;libpcre2-8.so.0 (0x00007f851ca1d000) liblzma.so.5 => &#x2F;lib64&#x2F;liblzma.so.5 (0x00007f851c9f1000) libzstd.so.1 => &#x2F;lib64&#x2F;libzstd.so.1 (0x00007f851c942000) liblz4.so.1 => &#x2F;lib64&#x2F;liblz4.so.1 (0x00007f851c91e000) libcap.so.2 => &#x2F;lib64&#x2F;libcap.so.2 (0x00007f851d103000) libgcrypt.so.20 => &#x2F;lib64&#x2F;libgcrypt.so.20 (0x00007f851c7e2000) libdatrie.so.1 => &#x2F;lib64&#x2F;libdatrie.so.1 (0x00007f851d0fa000) libgraphite2.so.3 => &#x2F;lib64&#x2F;libgraphite2.so.3 (0x00007f851c7c1000) libxml2.so.2 => &#x2F;lib64&#x2F;libxml2.so.2 (0x00007f851c637000) libbz2.so.1 => &#x2F;lib64&#x2F;libbz2.so.1 (0x00007f851c624000) libbrotlidec.so.1 => &#x2F;lib64&#x2F;libbrotlidec.so.1 (0x00007f851c616000) libgpg-error.so.0 => &#x2F;lib64&#x2F;libgpg-error.so.0 (0x00007f851c5f0000) libbrotlicommon.so.1 => &#x2F;lib64&#x2F;libbrotlicommon.so.1 (0x00007f851c5cd000) reply dunham 17 hours agoparentprevI remember needing 8MB to run a graphical web browser with Linux&#x2F;X11 (I believe it was Netscape Navigator). 8MB was sufficient, 16MB a bit more comfortable. reply city41 19 hours agoprevThis article doesn&#x27;t even touch on the main pain point: bugs. Virtually all software is just as buggy as can be. I dread every time I need to take a piece of software down a non-happy&#x2F;non-common path. It almost always fails. Working around and dealing with bugs is just a normal, every day part of modern society now.Simple example, I sold my car to Carvana the other day and just baaaarely pulled it off using Chrome and Firefox. In Chrome the upload image wizard would get a JS exception. That part of the app miraculously worked in FF, but virtually the entire rest of the site was mired in issues as it&#x27;s obvious Carvana devs don&#x27;t test in FF. I pulled off the transaction by bouncing between the two.Even worse, most non-technical people think they did something wrong when they encounter a bug.Software that is bloated and slow but stable and rock solid? I&#x27;d gladly take it at this point. reply spacemadness 19 hours agoparentOn one hand I cannot believe what we have actually works as well as it does. Duct tape and bubblegum everywhere at all levels and it actually still works. I’m amazed everyday at what humanity has accomplished with that in mind. On the other hand I can’t help but notice just how damn buggy everything is, and I’m not sure if everything is actually more buggy or if I’m just losing patience with big business software development as I age having seen how the sausage is made. I can’t help being angry at some illusory product person telling people to ship feature X or else with it having a glaring bug in the UX that is easily caught. reply kayodelycaon 17 hours agorootparentThe vast majority of humanity has always run on duct tape and bubblegum. :)There are still computer systems designed with high reliability and accuracy. See flight control systems.New technology typically doesn&#x27;t work on duct tape and bubblegum. So it has to be good. Current technology is going to be just right enough to work. reply syndicatedjelly 16 hours agorootparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Speed_tapeIt can be hard to tell what is \"duct tape\" and what is \"speed tape\" in software these days. An aircraft mechanic doesn&#x27;t need to know the structural differences between the two - just use speed tape to be safe. Similarly, a pure programmer doesn&#x27;t have to know the difference between ufw and Windows Firewall - just use the latter and move on.However, an engineer (mechanical or software) better understand the differences in both situations reply ohwellhere 19 hours agoparentprevYou&#x27;re 100% right. Ever since watching the Jonathan Blow talk on the end of the world I have started paying attention to it and it&#x27;s amazing how many absolutely shitty software experiences we just accept on the daily.I understand all the points about financial costs and opportunity costs and pragmatism and the rest, and I partially agree with it, but it&#x27;s hard not to sometimes feel like we&#x27;ve accepted living in a half built world. reply tayjohno 17 hours agoparentprevAgreed. I remember as a teenager when the first generation Macbook Airs came out, my friend realized you could reliably crash them (brand new, the demo models sitting out at the mac store) just by opening all the apps on the dock in quick succession. Took just a few seconds of clicking and the machine would crash and reboot.And it&#x27;s not like things have gotten any better, now I&#x27;m an adult with young children and if one of them gets their hands on my phone or laptop, they seem to be just as reliably be able to lock up, crash, freeze modern devices all the same. These kids are not physically damaging the phone in any way, they&#x27;re just pushing buttons too quickly or in unexpected orders. That&#x27;s the state of modern tech that we&#x27;re in.To be honest, I can understand why this hasn&#x27;t been fixed. As mentioned in the article and throughout these comments, we&#x27;ve just come to expect to need to restart every now and again. In this case, people are likely to blame such a problem on the child, and a restart fixes the issue anyway. I just would&#x27;ve hoped for better by now in the lifecycle of these operating systems. reply brandly 14 hours agoparentprevhttps:&#x2F;&#x2F;danluu.com&#x2F;everything-is-broken&#x2F; reply manicennui 18 hours agoparentprevI don&#x27;t think software is anywhere near as buggy as it was in the past. Some of us had to support Windows machines in the late 90s and early 2000s. reply city41 18 hours agorootparentThat may be true. But software is also much more ubiquitous and essential these days. At least in the 90s you could be confident your car wasn&#x27;t buggy. reply manicennui 17 hours agorootparentAmerican cars in the 90s were terrible. The domestic automakers wouldn&#x27;t be in business today if people actually bought based on reliability. Now you can buy almost any brand and reasonably expect it to last over 100k miles. reply city41 17 hours agorootparentSure, but that had very little to do with software. reply datavirtue 17 hours agorootparentprevYeah, and I shit you not, many vehicles have had software updates to solve oil consumption issues. People walk away from those service encounters just shaking their head wondering how in the fuck software was causing their car to lose&#x2F;burn oil. Truth is, several different reasons.The number of vehicle software updates are staggering. reply datavirtue 17 hours agorootparentprevWhen the networking stack got worked out by Windows 98, everything was pretty smooth sailing. Until the drive-bys started. Then we moved to Windows NT and complexity, and albeit security, increased significantly. Windows XP was stable as fuck until the root kits started flowing. We moved through Vista, hopefully avoiding it all together until we landed at the fucking dream that was Windows 7. I would have stopped right there and been happy.Then something got pushed over the cliff. Windows 10 and the UWP...like seriously WTF!? Satan&#x27;s very own dumpster fire. reply livrem 13 hours agoparentprevBut if the software keeps getting modified and expanded it will not be stable. Bugs will be added. And that also causes bloat. I think they go very much hand in hand (and very much correlates with the frequency of upgrades... usually upgrades that no user asked for anyway). reply city41 13 hours agorootparentNot sure I agree with that. It&#x27;s possible to add new features with minimal or even no bugs. It requires good engineering, good test coverage, and often good manual QA and even alpha&#x2F;beta rounds. But it can be done. Is it done today? Sure, some organizations absolutely follow this approach. I would guess, especially in the commercial space, these things are often lacking. reply chankstein38 16 hours agoparentprevHeck, half the time even the happy path is bug filled. reply throwawaysleep 18 hours agoparentprevThe upload wizard wasn&#x27;t an adblock problem? Anecdotally, I have encountered several cases where that has been the issue.Not testing on Firefox just makes sense given how niche it has become. Not worth the effort to go beyond Chromium. reply city41 18 hours agorootparentI disabled my ad blocker and cleared out all caches and it still persisted. Even if it was, the JS exception was unhandled. Carvana is built in React, the absolute bare minimum would be an ErrorBoundary at the top of all flows (in this case, a modal). reply gavinhoward 19 hours agoprevI didn&#x27;t say it in the post I wrote about C [1], but this is a big reason why I use C: I will have a hard time bloating my software. I can add features, yes, but adding a singular feature struggles to add even 100 kb to the executable.I don&#x27;t work for anyone right now, but I do have a \"work\" machine. This machine is beefy.But I still run Neovim and tmux instead of an IDE. [2]I don&#x27;t run a typical Linux distro; I use a heavily-modified Gentoo, and that includes using OpenRC over systemd. [3]I don&#x27;t use a full desktop; I run a TWM called Qtile. [4]All of this is so my machine is not bloated. When my machine boots up, and I just barely log in, it is running only 40 processes (including the terminal and htop I use to check).As of right now, I&#x27;m engineering software. Truly engineering; I am spending the effort to effectively mitigate all of C&#x27;s problems, while keeping the software lean and fast. I hope to someday build a business on that software.I guess I&#x27;ll see if there even is a market for non-bloated, sleek software anymore.[1]: https:&#x2F;&#x2F;gavinhoward.com&#x2F;2023&#x2F;02&#x2F;why-i-use-c-when-i-believe-i...[2]: https:&#x2F;&#x2F;gavinhoward.com&#x2F;2020&#x2F;12&#x2F;my-development-environment-a...[3]: https:&#x2F;&#x2F;gavinhoward.com&#x2F;2023&#x2F;06&#x2F;an-apology-to-the-gentoo-aut...[4]: https:&#x2F;&#x2F;gavinhoward.com&#x2F;2023&#x2F;09&#x2F;lessons-learned-as-a-user-3-... reply jasode 18 hours agoparent>, but this is a big reason why I use C: I will have a hard time bloating my software.Your perspective is interesting because I&#x27;m old enough to remember when the C Language was considered bloat compared to just writing it in assembly language.Examples of 1980s programs in assembly was WordPerfect, Lotus 123, MS-DOS 1.0. SubLogic Flight Simulator (before Microsoft bought it) was also in assembly.Back then, industry observers were saying that MS Word and MS Excel being written in \"bloated\" C was a reason that Microsoft was iterating on new features faster and porting to other architectures sooner than competitors WordPerfect and Lotus 123 because they stayed with assembly language too long. (They did eventually adopt C.)I see this \"bloat-vs-lean\" tradeoff in my own software I write for my private use. I often use higher-level and \"bloated\" C#&#x2F;Python instead of the leaner C&#x2F;C++ because I can finish a particular task a lot faster. In my case I&#x27;m more skilled in C++ than C# and prefer leaner C++ executables but those positives don&#x27;t matter when C# accomplishes a desired task in less time. I&#x27;m part of the bloated software problem! reply gavinhoward 18 hours agorootparentFor your own private use, I see no problem with that.It&#x27;s all tradeoffs; and finding the sweet spot for every particular insurance.I believe the article is complaining that people just blow past the sweet spot.In your case, C# is the sweet spot. In my case, I expect customers will want speed; I&#x27;m building an interpreter for a programming language. reply dijit 18 hours agorootparentprevis there not, a minor hint of irony here, that when I think of bloated software my mind goes almost immediately to everything Microsoft creates (except VSCode, which is somehow the most performant software they&#x27;ve created despite being written in a language that is theoretically slow) reply BirAdam 18 hours agorootparentThere was a time when Microsoft wrote extremely lean code, and BillG in particular. Best example: TRS-80 Model 100. reply kagakuninja 16 hours agorootparentYes, DONKEY.BAS was legendary... &#x2F;s reply caskstrength 12 hours agorootparentprev> Your perspective is interesting because I&#x27;m old enough to remember when the C Language was considered bloat compared to just writing it in assembly language.Both perspectives are correct for their respective times. Compilers were much dumber in 80. These days your GUI desktop program written in assembly language would probably run slower than written in C and compiled with modern gcc O2. reply wredue 17 hours agorootparentprevC probably was bloated then. But today it’s the backbone of everything, whereas python will never be that, at least on hardware at the levels we can foreseeable build.Languages like C brought a massive benefit to accessibility. Devolving “software is slow” to “yeah but C vs assembly” is such a ridiculous crutch argument. Assembly is not remotely approachable to the majority of programmers. C, rust, zig, c++, Java, C# are all approachable languages that are fast and have great fast libraries and frameworks to work with.All I can see in the “I can finish the see sharp program faster” argument is that “python vs c++.jpeg” from the 2000’s where half the python was importing libraries, but they wrote the C++ from scratch, and everyone who knew nothing about C++ moved this image around like it was some hilarious joke of C++. reply usrnm 19 hours agoparentprev> but adding a singular feature struggles to add even 100 kb to the executableTry supporting unicode reply gavinhoward 19 hours agorootparentHeh, that is probably the exception that proves the rule! reply bheadmaster 19 hours agoparentprev> As of right now, I&#x27;m engineering software. Truly engineering; I am spending the effort to effectively mitigate all of C&#x27;s problems, while keeping the software lean and fast.Can you expand on that?Which exact problems of C&#x27;s are you working on solving? Do you mean the language itself (writing a new dialect of C), or the ecosystem (e.g. impossibility of static linking with glibc)? Or something else entirely? reply gavinhoward 19 hours agorootparentUnsafety.My blog post about C has a blurb about how I&#x27;m really writing in a partially memory-safe portable dialect.I have bounds checks, structured concurrency (to mitigate use-after-free and double-frees), and a bunch of other stuff. reply trealira 16 hours agorootparentSince you care about these things, why not try a language that has scoped threads and bounds checking built in, like Rust or Ada?Actually, I had written more about Rust and Ada, but then I read your blog, and it says you like C better anyway because you find it more fun, so nevermind.You might also like to use D in its \"Better C\" mode, which at least offers bounds-checked arrays and sliced, as well as some other features, while being very similar to C.https:&#x2F;&#x2F;dlang.org&#x2F;spec&#x2F;betterc.html reply eternityforest 13 hours agoparentprevI think there might be a market mostly with other engineers like you. Lots of people seem to really love this stuff, look at the forth crowd and how much they adore the language.For me... I don&#x27;t notice any slowness or excessive battery drain in VS Code, so I just use that. Perhaps there&#x27;s something deeply wrong with my psychology, but I&#x27;m just not very interested in simplicity for its own sake. It&#x27;s cool, but not an approach I&#x27;d want to use every day in real life. reply commandlinefan 12 hours agoparentprev> I will have a hard time bloating my softwareI wonder how much of this is just because when a project manager comes along and says \"as a system administrator, I want to be able to log all of the keystrokes of the users and reports who&#x27;s slacking to the boss\", you say, \"ok, that feature will take about two weeks to implement\" and they can&#x27;t argue with you because it&#x27;s C so they just go away and leave you alone. reply vbtemp 19 hours agoparentprev\"I&#x27;ve turned down job offers because they were in C++\"Yep reply nine_k 19 hours agorootparentC++ is huge and highly interconnected. No matter whether you like it or dislike it, and how experienced you are with software development, you either invest years into becoming good at it, or stay away from C++ jobs. reply jrockway 18 hours agorootparentprevIf I was going to go back and time and offer younger myself career advice, I would probably say \"just stick with C++\". It was the most popular programming language when I started my career. It will be the most popular programming language when I end my career.Think about it. Is there any widely-deployed OS not written in C&#x2F;C++? Any web browsers? Spreadsheets? CAD software? Text editor? reply giraffe_lady 19 hours agoparentprevI would say truly engineering would be contextualizing these decisions along a spectrum of tradeoffs and positioning your project on that spectrum according to the constraints of its creators and users. That may put you to one extreme of the continuum, but that doesn&#x27;t mean people whose constraints land them elsewhere are not doing \"true engineering.\"\"I am going to build the strongest, lightest bridge in the world\" is a marvel. \"I am going to build a light-enough strong-enough bridge for a cost my client can afford\" is engineering. reply kayo_20211030 18 hours agorootparentHear! Hear! Engineering is a practical discipline - and it is a discipline. It&#x27;s building for purpose. I appreciate Tonsky&#x27;s point, and agree with much of it, but engineering means turning out into the world things that are fit for purpose, however that&#x27;s defined. Purpose is +100 and all the rest is something of less than 100. Mathematics is mathematics, science is science and engineering is engineering. reply gavinhoward 18 hours agorootparentI agree, except that engineering is\"fit for purpose at the smallest cost.\"For me personally, I am banking on having multiple business customers for my software. If I consider the cost amortized, I can spend a little more to engineer something better.But yes, it still has to be fit for purpose. My customers will provide a document that explains what they want to do with my software and on what platforms. If I sign a contract, that means I am committing to supporting their purposes on those platforms. reply gavinhoward 19 hours agorootparentprevSure, if they are considering tradeoffs.But a sign of considering tradeoffs is that every project seems to be just a little different because every circumstance is just a little different.When you have a software monoculture or monocultures, it&#x27;s likely that tradeoffs are being ignored. reply anjel 18 hours agorootparentThe problem is it&#x27;s trade-offs on top of trade-offs, all the way down. reply Nasrudith 16 hours agorootparentprevTrade-offs also get a bit meta with \"standardization\" one way or another. Sure you could get peak performance if you made custom length and width screws but it boosts costs and makes it harder to maintain with the one-offs. Going with trade-offs is itself a tradeoff which means monoculture breeds a pattern of ignoring the tradeoffs. reply ethanwillis 18 hours agorootparentprevThe ethical considerations and professional obligations that go into creating a bridge aren&#x27;t exactly translated into the act of creating software. If we mirrored those in a bridge building analogy the \"cost my client afford\" would mean the engineers would often find themselves greenlighting a bridge that would fail in sensible conditions in our current world. reply kayo_20211030 18 hours agorootparentNo. A civil engineer&#x27;s response would (should?) be immediately that the client cannot build the bridge for that cost, simply because it will kill someone as a first order effect. That&#x27;s the ethical consideration. The downsides of janky rendering or poor memory management aren&#x27;t quite the same unless you actually add up the power wastage and apply it as an impact on global warming. But, those are not a first order effect, and although they should be, they don&#x27;t have the same influence on the solution. reply AnimalMuppet 17 hours agorootparentThere&#x27;s plenty of software that can kill someone as a first-order effect. If you allow second-order, there&#x27;s even more.Avionics. Air traffic control. Industrial control. Automotive software. 911 dispatch. Medical instruments. Medical information. Military command and control. Mechanical engineering analysis software.Lots of software can kill people. reply kayo_20211030 17 hours agorootparentThat&#x27;s not what I&#x27;m saying. If a web page takes 2s to render rather than a theoretical minimum of \"immediately\", for most software that most people write, no one will die, or be hurt, or even feel too bad as a first-order effect. Obviously, if one is writing flight control software, or somesuch, then the stakes are higher, and one ought to be aware of that. That&#x27;s the practicality calculation. If you&#x27;re going to kill&#x2F;hurt&#x2F;really upset someone, then what you&#x27;re doing is not fit for purpose (unless that is the purpose :) ) reply supriyo-biswas 17 hours agorootparentprevFWIW, the embedded domain usually has a little more focus on efficiency and correctness compared to enterprise software. reply giraffe_lady 17 hours agorootparentprevI don&#x27;t understand this position, sorry. A bridge that would fail under expected conditions is straightforwardly not strong enough for its purpose? reply ethanwillis 8 hours agorootparentthe assumption youre making is that strong enough for purpose is always true for any value of \"cost my client can afford.\"that&#x27;s what i was trying to draw attention to. reply benkillin 19 hours agoparentprevHeh... > ... I use a heavily-modified Gentoo ...Need not say more :) reply gavinhoward 19 hours agorootparentHey, it works for me.Besides, I struggled with sysadmin-type tasks until I bit the bullet and installed Linux from Scratch and then Gentoo. It was one of my best educational investments. reply j-krieger 18 hours agoparentprevAll this work and you don&#x27;t earn money with your style of engineering. Have you maybe stopped and wondered why you don&#x27;t? reply dangrigsby 18 hours agorootparentI would find it very satisfying to do what he’s doing. I’m not sure it needs be judged against making money. reply gavinhoward 18 hours agorootparentprevI know exactly why: I haven&#x27;t started marketing yet. :)After I get to MVP and actually try marketing, we&#x27;ll see what happens. reply danenania 17 hours agorootparentNot to pick on you—this is something I and most other engineers also struggle with—but I think this sums up the reason for most of the complaints in this thread. That is: builders who prioritize marketing outcompete those who prioritize engineering quality.Making something people want enough to pay for is very difficult; if you are trying to do that while also imposing a bunch of other constraints on yourself that have no clear marketing benefits, your odds of success go down a lot.Engineering excellence can sometimes be used successfully as a form of marketing in itself and you could well pull this off, as your content is super engaging and well-written.But I would suggest to every engineer to consider Chesterton’s fence. Why is all the winning software in every category slow and bloated and seemingly unconcerned with engineering excellence? Is it because everyone involved, the engineers that build it and the customers that buy it, are all technical philistine morons? Or is it because the products that win in the market prioritize… winning in the market, and all their competitors that don’t prioritize that for whatever reason fall by the wayside? reply gavinhoward 16 hours agorootparentYou are right on many levels, and I know it.> But I would suggest to every engineer to consider Chesterton’s fence.I agree.In fact, I believe I have considered Chesterton&#x27;s Fence; I have a plan.I&#x27;d like your opinion on my plan.> Making something people want enough to pay for is very difficult.Yes, absolutely.To fight this, I have spent years, 3.5 years, figuring out what people hate about build systems, and I have designed mine to address those.While that doesn&#x27;t guarantee success, I think it may improve my odds. Do you agree?> That is: builders who prioritize marketing outcompete those who prioritize engineering quality.Yes, and it sucks.I hate marketers. I hate marketing. I hate the fact that I&#x27;m going to do it. But I have to.So my marketing with be focused on giving people something for just paying attention.> Engineering excellence can sometimes be used successfully as a form of marketing in itself and you could well pull this off, as your content is super engaging and well-written.Thank you for your compliment! I hope so, and my plan is to emphasize this.I&#x27;m going to post four articles on HN, each a week apart, and each will be designed to give readers something substantial, with a blurb about marketing at the end that will be clearly marked as marketing.* The first will be new FOSS licenses designed to better protect contributors from legal liability.* The second will be a post on language design and psychology.* The third will be a deep dive into Turing-completeness and what it means.* The fourth will be the source code as a Show HN, along with an offer for early adopters.> Or is it because the products that win in the market prioritize… winning in the market, and all their competitors that don’t prioritize that for whatever reason fall by the wayside?It&#x27;s awful, but you are right.So this marketing push is all I will do for four weeks: preparing and posting, and responding to comments. This is when I will \"prioritize winning in the market.\"Does this have a chance of working? reply danenania 16 hours agorootparent\"Does this have a chance of working?\"It&#x27;s a start for sure. But personally I&#x27;d suggest changing your mindset a bit from the idea that you&#x27;ll come out of the code cave for a month to grit your teeth and do marketing. Granted, this is much better than just staying in the cave. But really to run a successful business I think you need to accept at a deep level that marketing, making money, and growing the business is now your main job, and you will permanently need to spend at least as many thought cycles on that as you do on programming.To wit, while posting those articles and a Show HN sounds like a good plan and you should definitely do that, what will you do if they all fall flat and get no traction? It&#x27;s a distinct possibility, and I hope you won&#x27;t just give up.I&#x27;d think more about what you&#x27;re going to do every week for the next year to get users rather than putting all your chips on an HN launch that may or may not pan out. Even if you do rock the HN launch, you&#x27;re probably going to have the \"trough of sorrow\"[1] to contend with after, so I&#x27;d think more about how you can make marketing a repeatable part of your rhythm in the long run.1 - https:&#x2F;&#x2F;andrewchen.com&#x2F;after-the-techcrunch-bump-life-in-the... reply gavinhoward 14 hours agorootparentThank you so much for your answer!> while posting those articles and a Show HN sounds like a good plan and you should definitely do that, what will you do if they all fall flat and get no traction?You got me. I was planning on giving up. :PI am in a place where the only cost to switching projects and trying again in three years is the opportunity cost, so because I&#x27;m bad at constant marketing, that&#x27;s what I was going to do if I got zero traction.If I got only some traction, I&#x27;d weigh my options.I was only going to worry about long-term weekly marketing if the launch went well enough.Because I&#x27;ll be frank: I have no idea how to do constant marketing that doesn&#x27;t bother people or waste their time. If I would waste their time, I&#x27;d rather just throw my own time away and switch projects.> Even if you do rock the HN launch, you&#x27;re probably going to have the \"trough of sorrow\"[1] to contend with afterGood blog post, and yes, I agree. I am expecting the trough as I build up the MVP. reply danenania 10 hours agorootparentThe issue with your strategy imho is that failing to get traction with an HN launch is not that much of a negative signal. Getting to the front page is a bit of a crapshoot and not achieving it doesn&#x27;t necessarily mean no one is interested in your product--it could mean you got unlucky or just need to iterate on your messaging.If you haven&#x27;t gotten it in many users&#x27; hands yet, it might be a good idea to try recruiting like 50-100 users first, either one-by-one through email reachouts or in smaller communities where it&#x27;s less hit-or-miss, like niche subreddits. If some of these users like the product and stick with it, start giving you feature requests, etc., that tells you that you&#x27;re on to something. Conversely, if you can&#x27;t get even a small group of users to try it and stick with it using that approach, it&#x27;s much more of a negative signal than a failed HN launch and probably indicates that something needs to change.Whatever route you decide to take, I wish you the best with it!Also:\"I have no idea how to do constant marketing that doesn&#x27;t bother people or waste their time. If I would waste their time, I&#x27;d rather just throw my own time away and switch projects.\"That&#x27;s noble of you, but I would cut yourself some slack. Ideally you would market in a way where you don&#x27;t bother people or waste their time, but getting users often requires trying things where you risk getting close to that line. Sometimes you might cross over it, but that&#x27;s just something to learn from.Trying to market a product while never bothering anyone the least little bit is a bit like trying to be a comedian without offending anyone or to find a romantic partner without enduring some awkward dates. I think it just goes with the territory. reply gavinhoward 9 hours agorootparentAs sad as it makes me, I believe you.I&#x27;ll think about what to do. reply jimbokun 16 hours agorootparentprevI think if you succeed, it will be because other developers are investing in you personally. Because they like what you write and how you think, and thus trust you to write good software.I think patio11 is someone who has used a similar marketing strategy to great success. People hire him because of the quality of his writing demonstrating his understanding. reply gavinhoward 14 hours agorootparentI think you are absolutely right.I also think I can&#x27;t replicate patio11&#x27;s success! He&#x27;s a much better marketer and writer than me. reply uoaei 17 hours agorootparentprevHere is how the main factor incentivizing this sloppy engineering behavior is justified: everything is cast in terms of making money. Revenue is good -- fine. Therefore no revenue is bad -- doesn&#x27;t follow and you need to justify that somehow. reply danenania 16 hours agorootparentNo revenue generally means the project eventually gets abandoned or relegated to spare time because people gotta eat. So yeah I&#x27;d say it&#x27;s a bad thing.I&#x27;m all for quality engineering. I&#x27;m just saying that if your whole plan for a new product is \"quality engineering\", then you have no plan at all. The horse needs to come before the cart. reply uoaei 16 hours agorootparentEven couching the output as a \"product\" begs the question. It comes with a whole set of connotations around what&#x27;s expected in and from such an effort.What you&#x27;re describing is a tragedy of the commons from the perspective of social and civilizational benefit. I agree that&#x27;s what it is, but I think we should be more careful before justifying it. reply danenania 16 hours agorootparentThat&#x27;s fine for theoretical discussions. The poster I was replying to implies that their goal is to sell a product and make money, so I was speaking to that. replymortallywounded 18 hours agoparentprevEver tried HolyC? reply ho_schi 17 hours agoparentprevUsing Arch with GNOME, VIM&#x2F;NEOVIM. Happy value between usability and resource usage. The programmers on Linux usually care about efficiency. Christian Hegert is improving recently a lot in GNOME. This allows me to use a ThinkPad X220 which is running circles around some modern laptops with Windows. I understand that people prefer the small footprint of C. I like C. My personal preference is C++ (low- and high-level, more safety and flexibility).The problem is greed - i.e. capitalism. The blog mentions Electron and therefore Chrome and JavaScript. They are awful combination and allow companies to save on programmers. Programmers which handle C, C++, Rust or Python are a small group. Java, C# and JavaScript consume more resources, allow using a lot more stuff quicker (like a drug) and most importantly are forgiving mistakes. So the industry decides to waste the resources on our computers because they don’t need to buy and maintain them. The customer pays twice, for the software and the next computer with more soldered main-memory. The key point is - the software companies don’t pay for hardware or the environmental damage! I’m doing myself a little JavaScript and some Java. Efficiency? Nobody ask for that and I should not spend time on it. There is now law stating that managed languages need to waste resources but a side-effect.Remember Steve Jobs? I don’t appreciate what Apple does. But he banned Flash for a reason. Resources! Okay. Also bugs. And for the same reason they should ban Electron. Apple devices run faster with less resources because Apple saves on hardware. Why build devices with huge batteries, when you can achieve more runtime with less material and take the same money? The EU needs to enforce side-loading on the iPhone. But I also think Apple should be allowed to keep Blink (and therefore Electron) banned from AppStore. I don’t want see my battery dying because some corporate manager decided to drain it. But if you need Blink? Side load. reply Karellen 16 hours agorootparentWhat usability features of Gnome do you find indispensable that prevent you from moving to a lighter-weight DE, like LXDE, XFCE or Cinnamon? reply paulryanrogers 16 hours agorootparentprevJobs also said native apps were unnecessary and we can all just use web apps. (Despite working on an app store at the time.) So even the prophet himself isn&#x27;t such a great example. reply JoshuaRogers 18 hours agoprevAdmittedly, I stopped reading just over half way, but the crux of the argument appeared to be that software should be fast, though I don&#x27;t recall any justification for that philosophy other than suggesting that it is basically a truth. The article did acknowledge the counter point that in some cases the efficiency gains will never make up for the time spent chasing this efficiency, but it hand-waved that away without interacting with the argument.The other key trait of the article was cherry-picking data and over simplifying domains. Several times the article alluded to the emotional plea that \"what could the software possibly be doing that takes up that time&#x2F;space\" (my paraphrase) but it didn&#x27;t place any serious attempt to answer that question, using their lack of provided answer as if it were an indication of an invalid answer and comparing various bits of software that do not have feature parity looking as if their only practical difference were performance. (Edit: Updated wording of previous sentence to be more clear.)There&#x27;s definitely alot to be said about how software could be more efficient as well as the social, environmental, and business costs of inefficiency, but there is also much to be said about how modern software empowers people that otherwise might not be able to write anything to write something \"bad\" that does what they need or to discuss how modern software developeres tend to aim to be \"fast enough\" in the way that an structural engineer would choose \"strong enough.\"There&#x27;s much rich debate to be had, but this article didn&#x27;t include it, instead going for an emotional rant, and failing to engage with actual reason. There is, in my opinion, truth to parts of the argument, but the article made itself clear that it didn&#x27;t want a discussion. reply Xeamek 18 hours agoparent>Admittedly, I stopped reading just over half way, but the crux of the argument appeared to be that software should be fast, though I don&#x27;t recall any justification for that philosophy other than suggesting that it is basically a truth.But it is the truth, and all we have to do is simply look at software from the point of users.What device did You use to write this comment? Iphone4, or 14? What device do You use as your workstation, some pentium with 4gbs of ram?Heck, even going outside the software itself, but to related branch - What network did your device talked to servers? 5G&#x2F;fiber counted in hundreds of Mbps or 2g counted in few kbs?At the end of the day, actions speak louder then words. And you can pretend all You want that \"wanting faster software\" is unproven axiom, but if the axiom is followed by literally all of society, it might as well be taken as truth....especially since it originates from the exact same place as the \"developer time is worth more\" one. Only difference is who&#x27;s time we are saving reply IggleSniggle 17 hours agorootparentIt&#x27;s only truth because no great alternative is provided. My best devices are ones from the past. I gave them up only because software rendered them obsolete, not because I wanted the newer model.If half of society is speaking a new language AND an old language, it doesn&#x27;t really matter if the old language is superior. You need to be able to speak the new dialect just to navigate society, even if the new language only exists as a mechanism to differentiate the new generation from the old. reply JoshuaRogers 13 hours agorootparentprev> What device did You use to write this comment?Actually? An old iPad on WiFi that is stationed on the other side of several walls.Honestly, a lot of people don’t mind waiting a second for actions to complete. (For some of us, it’s the only pause we get to take during the day.)There are enough low-end phone sales that we should be able to accept that some people really don’t mind taking an extra moment if it saves a dollar.This really isn’t to say that software should be slow, but I think we should acknowledge that speed is not the sole value that users concern themselves with when using software. Many times it isn’t even a primary value. reply developer93 18 hours agorootparentprevEspecially since there&#x27;s 1 developer and thousands to millions of users.. reply wredue 17 hours agorootparentprevFor the record -There is no evidence what-so-ever that “performance trades with developer time”. 99% of the time, reasonable performance is a skill issue, not a developer time issue.In actual fact, if you look at “clean abstractions” and other nonsense, you can see that higher developer time actually seems to equate to lower performance. As we all also know, the best indicator of bug count is lines of code, so adding in all these abstractions that adds lines of code not only make code slower, but also results in more bugs.That is to say, all current evidence points to the exact opposite of their claim:Higher dev time = lower performance and more bugs (assuming higher dev time is coming from trying to abstract) reply Capricorn2481 17 hours agorootparent> There is no evidence what-so-ever that “performance trades with developer time”. 99% of the time, reasonable performance is a skill issue, not a developer time issue.I think this is reductive. There are lots of things people can do in Python that would be slower to write in C, and no amount of skill is gonna close that gap.> In actual fact, if you look at “clean abstractions” and other nonsense, you can see that higher developer time actually seems to equate to lower performance. As we all also know, the best indicator of bug count is lines of code, so adding in all these abstractions that adds lines of code not only make code slower, but also results in more bugs.I understand the argument against bad abstractions, but what abstraction is adding lines of code? I think we can agree that most of the time abstractions are to reduce lines of code, even if they may make the code harder to read.> Higher dev time = lower performance and more bugs (assuming higher dev time is coming from trying to abstract)I&#x27;m sure there are lots of projects that are buggy with little abstractions. reply wredue 14 hours agorootparent>I think this is reductive. There are lots of things people can do in Python that would be slower to write in C, and no amount of skill is gonna close that gap.Write python without import statements and then try to make this claim again.C using libraries is often as easy, or easier than python with imports. You don’t get to let python use someone else’s prewritten code while C has to do it from scratch and then say “see”. It’s a false equivalence.>I understand the argument against bad abstractions, but what abstraction is adding lines of code? I think we can agree that most of the time abstractions are to reduce lines of code, even if they may make the code harder to read.I don’t agree with this claim. I’d say go check out YouTube video from people like Muratori who tackle this claim. We have no measurements one way or another, but if I was putting money down, I would bet that nearly all abstraction that occurs ends up adding lines instead of saving them.>I&#x27;m sure there are lots of projects that are buggy with little abstractions.I’d tend to agree that the evidence shows this, given that the vast majority (and it’s not even close) of bugs are measurably logic errors. reply Capricorn2481 12 hours agorootparentBut we&#x27;re not talking about Python using libraries and C using libraries. We&#x27;re talking about pythons basic language features and what C patches in with libraries. Which makes a huge difference to me.> I don’t agree with this claim. I’d say go check out YouTube video from people like Muratori who tackle this claim. We have no measurements one way or another, but if I was putting money down, I would bet that nearly all abstraction that occurs ends up adding lines instead of saving them.We may not have measurements of the trend, but we can measure it on each abstraction fine. How many lines of code is your abstraction and how many lines would you have to duplicate if it wasn&#x27;t for your abstraction? If you&#x27;re not saving that much, don&#x27;t make the abstraction.Again, this isn&#x27;t talking about maintainability. I still question the claim that less lines of code means less bugs, but I know it&#x27;s a popular one. In my experience, it&#x27;s the terse code that&#x27;s doing a lot that winds up being buggy. I prefer things to be longer and explicit, so you&#x27;re talking to someone that doesn&#x27;t even like abstractions that much unless they&#x27;re necessary.> I’d tend to agree that the evidence shows this, given that the vast majority (and it’s not even close) of bugs are measurably logic errors.I don&#x27;t think this premise you propose is obviously false, but we have lots of evidence that memory bugs are the cause of most bugs. reply wredue 8 hours agorootparent>pythons language featuresThe standard library is still a library. Python doesn’t provide very much as a language feature.There are pros and cons to standard libraries. If we were talking about brand new C with not a massive community of quality libraries, then yeah. But we’re not. We are talking about a language with a half century of great libraries and frameworks being provided.>memory bugs cause most bugsYeah no. Not even close. You’re thinking of Microsoft’s citation that 50% of their security bugs are memory safety, but that’s not 50% of all bugs.Basic standard logic bugs are far and away the largest contributor to bugs.The way we know this is that language choice virtually doesn’t matter. On the whole, developers write 20-30 bugs per 1,000 lines of code regardless of language, so memory errors simply cannot be the largest contributor to bugs. reply Xeamek 17 hours agorootparentprevI kinda agree, but skill issue can be easily extended to time issue.Because it takes time to skill up.And also, if you put higher bar on require skill level, you inherently get less developers, which means more work per developer which then converts to time issue. Obviously it&#x27;s not a one to one, because great dev will spend less time doing good job then a clueless one making a mess, but still reply kayodelycaon 17 hours agorootparentprevIf that was true, we should all use assembly because C is too inefficient. Abstraction layers are necessary. reply flohofwoe 18 hours agoparentprev> to be that software should be fast, though I don&#x27;t recall any justification for that philosophy other than suggesting that it is basically a truthThe gist is that if your code takes just a couple of seconds to complete on your fancy M1 Mac, there will be a pretty big chunk of your potential audience who will have to wait for minutes (and there&#x27;s that surprising character trait in many non-technical users that they simply accept such bullshit, because they don&#x27;t know that performance could be drastically improved without them having to buy new hardware).But unless devs test their code also on low-end devices they will be completely oblivious to that problem.And the actual problem isn&#x27;t even the technical aspects, but that some devs are getting awfully defensive when confronted with the ugly truth that their code is too slow and start arguing instead of sitting down with their product mangager and making time for some profiling and optimization sessions to see what can be done about the performance problems without having to start from scratch. reply throwawaysleep 18 hours agorootparentWhat percentage of your target customers are going to have low end devices? And what is their estimated value compared to people who upgrade their tech (like most people with money would)?Is it a problem or are those people simply not worth serving? reply sillysaurusx 18 hours agorootparentGamedev quantified this. The answer is: many more then you think.And sure, they’re not worth serving, as long as you’re not worth their money. Meanwhile a competitor will.Don’t be fooled by the browsers. Most products aren’t browsers. And if you don’t snap up the long tail, someone else will. reply blitz_skull 17 hours agoparentprevI liked the emotional rant. Sometimes data just obscures what you know to be true. I don&#x27;t need data to tell me that I should try my best to make the best software, and that&#x27;s what this article reminded me. reply koonsolo 12 hours agoparentprevThere is one paragraph at the start where I thought \"yep, the author just answered his own question here\":Only in software, it’s fine if a program runs at 1% or even 0.01% of the possible performance. Everybody just seems to be ok with it.So yeah, everybody is ok with it. Move on. reply abhaynayar 18 hours agoparentprevI didn&#x27;t know how to put my thoughts about the article into words so decided not to, but thankfully this comment does it better than I could have.Really annoying how the author brings up counter points and comparisons but does not deeply engage with them, as if they&#x27;re absolute truths and only rhetorical, when they&#x27;re far from that. reply geodel 17 hours agorootparentHuh, the author feels the pain with endless crappy and slow software. If you feel all his points either superficial or wrong you could easily come up with counter arguments better than author. But it seems all you are saying is I don&#x27;t like it because I don&#x27;t like it. reply abhaynayar 5 hours agorootparent> Huh, the author feels the pain with endless crappy and slow software.If that was all, it would&#x27;ve been fine... if he was only listing bugs and saying he&#x27;s tired of crappy software. But he has framed the article in a way as if he&#x27;s describing the \"why\" and how the problem can be solved. In fact I&#x27;ve been following the author and he has a place where he lists all bugs he finds in software, and that in my opinion is a great initiative, but this article just opens too many threads and tangents and only appears to explain the root cause.I could come up with a few examples like:- trying to compare cars, buildings, and planes with software and not diving deeper into how much different they are and why. - or saying everybody seems to be ok with inefficient software without diving deeper into why everyone&#x27;s ok with it. - or mentioning a tweet about a guy who spent more time trying to make something faster than he will ever gain back without going further into if it&#x27;s a good&#x2F;bad thing and why.> If you feel all his points either superficial or wrong you could easily come up with counter arguments better than author.I never said his points were superficial or wrong, just that he does not deeply engage with the threads he opens up. For that reason, I have no counter arguments to come up with, since he is just complaining about his issues and also does not come up with a good solution as such. Of course everyone would like nicer software, that&#x27;s not new. Why is software different than other industries in the first place? Is it worth improving it? What are the trade-offs? What is the effort required at scale? What would we lose if we made software more like manufacturing? What would we gain? If he knows a path forward, does he have a better way to express it than the last \"manifesto\" paragraph? Etc. reply cstrahan 18 hours agoparentprev> Admittedly, I stopped reading just over half way, but the crux of the argument appeared to be that software should be fast, though I don&#x27;t recall any justification for that philosophy other than suggesting that it is basically a truth.Are you suggesting that maybe users (including you and me) should have to put up with painfully slow, stuttering software? I don’t see why his claim requires any justification - to my mind, it should be just as self evident as the fact that inflicting physical pain upon others should be avoided.> […] modern software developeres tend to aim to be \"fast enough\" in the way that an structural engineer would choose \"strong enough.\"But they don’t aim to make software fast enough. My experience last week: Windows 10 file Explorer took ~2.5 seconds to open. Close it and re-open it: same thing. Open it, right mouse click another folder to open a new Explorer window: same thing. Fresh install of Windows 10 on a top of the line workstation-type laptop with 64gb of RAM.Not all, but a frustratingly large proportion of modern software is dog shit slow.The reason doesn’t need to spelled out in the article: if the developers of these slow apps cared, they could figure it out. From my experience, it usually looks something like this:Some developer has an emotional attachment to Protocol Buffers, and will stop at nothing to see its adoption within the org. But their software is pretty heavily invested in JSON. So they rewrite the software to read the existing JSON files from disk (or REST web service response bodies, whatever), and reserialize them to protobuf in memory. Tada! Now we’re using protobufs, great. Of course, nothing meaningful was actually achieved here - they already had a perfectly fine, ready to use, deserialized, in-memory data structure before they added protobuf to the mix. Oh, and that plain struct in memory was faster than traversing a protobuf: the former had small substructures laid out in the same allocation as the parent, whereas substructures in protobuf involves multiple allocations and chasing pointers. Next step: realize that REST is lame, and gRPC is hip. But it’ll be practically impossible to rewrite everything from REST to gRPC, so they do the only reasonable thing: create proxies that sit between the client and server that translate REST requests&#x2F;responses to&#x2F;from gRPC! Now that we have that in place, we can add an additional proxy to the mix: Envoy. Envoy is a super popular layer 7 proxy, so it’s gotta be good. What functionality will be used? Any load balancing? RBAC policies? TLS termination? Nope. None of it. But because Envoy is “good”, adding it to the stack with no justification must also be intrinsically “good”, right? Right!(Edit: do you see how long winded and boring this example is? This is precisely why the author shouldn’t expound on the “why” - anyone involved in the development of needlessly slow software (who isn’t blind to the problem because they are part of it) can recount similar craziness. Adding this to their blog would make for boring reading, and distract from the aim of their article.)Buzzword&#x2F;resume driven development, unwarranted layers of indirection (for no gain), absolution of responsibility via appeal to authority (if the top 10 software companies created and&#x2F;or use some software, then surely we can blindly use that software too and enjoy the same success, despite not giving any consideration to whether it’s even remotely the right tool for the problem at hand), cargo culting, etc.The reason software is painfully slow usually boils down to lack of critical, rational thought: either out of laziness and&#x2F;or deferral of responsibility, or because of some emotional attachment to some type of software component. reply JoshuaRogers 14 hours agorootparent> Are you suggesting that maybe users (including you and me) should have to put up with painfully slow, stuttering software? I don’t see why his claim requires any justification - to my mind, it should be just as self evident as the fact that inflicting physical pain upon others should be avoided.I&#x27;m suggesting that the blanket assertion doesn&#x27;t hold true that slow software is painful software. Software can be so slow that it&#x27;s painful but \"slow\" from the point of view of absolute does not immediately make something painful.A counter-example that the author used when describing people with a pride in inefficiency was to quote:> @tveastman: I have a Python program I run every day, it takes 1.5 seconds. I spent six hours re-writing it in rust, now it takes 0.06 seconds. That efficiency improvement means I&#x27;ll make my time back in 41 years, 24 days :-)I&#x27;m also asserting that slow and painful software that does what I want is better than fast software that doesn&#x27;t or that I can&#x27;t afford.Heck, I empathize with the author: when I run Slack there is a perceptible delay when I type. Do I want them to fix it? I mean, no, not really. I&#x27;d personally rather they provide an offline search mechanism or a way to write direct CSS for theming. It&#x27;s something that is annoying but it is less annoying that missing new features or the price going up. Likewise, I could use Vim for editing if I really wanted to, but I&#x27;d rather have the featureset of IntelliJ. reply crabbone 14 hours agorootparentprevI mostly see bloat created for other reasons. Think about situations like Docker containers replacing single applications (and dragging entire Linux userspace installation with them). Deploying in Kubernetes with its own CNI as well as DNS server and a bunch of other networking-related stuff while the network in your datacenter already does all of that. Packaging the whole Python virtual environment into a DEB or RPM package instead of shipping just the library you want users to install.This bloat is harder to deal with, on organization level, because people creating it justify it by saving on development effort necessary to make the product leaner. There&#x27;s no financial incentive to not use Docker for deployment (and spend developer&#x27;s time ensuring the code works on different platforms with different libraries).And software industry isn&#x27;t the only victim of this situation. First time I ever encountered this was in a... church. American missionaries coming to the former Soviet republics would bring with them pocket Bible for free handouts. Since I studied printing, to me this pocket Bible was strange in many ways. It was printed on paper lighter than 20 g&#x2F;m^2. This was unheard of in Soviet printing industry. If it ever tried to produce such paper it would simply fall apart because they didn&#x27;t have access to the technology necessary to produce plastics that held this paper together. Because the paper was too thin, it required a lot of \"filler\" (again, more plastic). And that made it worse for recycling. It was printed using offset machine. Soviet industry didn&#x27;t print literature using offset machines. They didn&#x27;t have the technology for making precise high-resolution plates necessary for such printing, so letterpress printing would be the way to do it. But, letterpress makes a noticeable difference in texture of the page, it also pretty much prevents you from using \"unorthodox\" font sizes, ensuring that the font&#x27;s author could see exactly how letters are going to look on a page, making the overall experience much more pleasant.All in all, it was kind of a technological marvel I knew I couldn&#x27;t achieve with what I had &#x2F; knew, on the other hand, all this technology was intended to decrease cost at the expense of marginal drops in quality. In truth, at the time, I didn&#x27;t think this way. I saw the technological marvel part, and didn&#x27;t notice the drops in quality. The realization came a lot later. reply crabbone 15 hours agoparentprev> how modern software empowers people that otherwise might not be able to write anything to write something \"bad\"What&#x27;s so special in the modern software? How do you tell if software is modern?Few points to illustrate the difficulties with your descriptions: BASIC and SQL were meant to empower people ... to write something \"bad\" a very long time ago. So did Fortran, as well as some other languages &#x2F; technologies that didn&#x27;t survive to the present day.Python or Java can be called \"conservative\" if you are very generous, but, really, in truth, should be called \"anachronistic\" considering programming language development that happened in the 70. Languages like J or Prolog are conceptually a lot more advanced than Rust or Go, but have been created much earlier. Many languages are actually collections of languages that have been created over time, eg. C89 through C23 -- does this make C a modern language? Only the C23? Is there really that much of a difference between C89 and C23?Is there some other way to define modernity? I.e. not based on time of creation nor based on some imaginary evolutionary tree? reply JoshuaRogers 13 hours agorootparentI’ll be honest here, time got away from me. I had Node and Python in mind simply having forgot how old Python was (And Node not exactly being the new guy anymore.) :p reply jclardy 19 hours agoprevI&#x27;ve noticed a similar trend in my current organization. In the beginning, when we were smaller, the details mattered. Things couldn&#x27;t be slow, animations had to be smooth, scrolling speed mattered, loading times mattered. We aimed to build the most efficient product, anything to increase user efficiency.Then as the team grew, the values changed to favor anything that improved developer efficiency. More abstractions, more layers, more frameworks. The tradeoff of saving one day of developer work was worth the cost of millions of user seconds collectively. I think the difference was just the visibility - management can see the costs of things on the development side, but they can&#x27;t see the benefits of a slightly faster launch time, or better caching, or smoother scrolling. They aren&#x27;t measurable, and once an org gets",
    "originSummary": [
      "The author criticizes inefficiency in the software industry, pointing to issues of slow and bloated software. They express concern over the practice of prioritizing faster hardware over optimizing software.",
      "The author advocates for better software architecture and programming practices, with an emphasis on stability and quality, as a response to the observed errors and instability in web applications.",
      "Aimed at initiating discussion and improvement in the industry, the author supports the contribution to and adoption of open-source projects for better software solutions."
    ],
    "commentSummary": [
      "The article raises questions regarding the impact of financial incentives, market pressures, and VC funding on software quality, in the context of pushing rapid product releases.",
      "It discusses trade-offs between profitability and software quality, with emphasis on aspects like complexity, performance, the prevalence of bugs, and the challenges of using languages like C++.",
      "The piece also challenges the prioritization of developer efficiency over user efficiency, with specific mention of the lack of financial motivation to refrain from using Docker for deployment."
    ],
    "points": 526,
    "commentCount": 390,
    "retryCount": 0,
    "time": 1698067043
  },
  {
    "id": 37990031,
    "title": "Google pulls up the ladder on open internet, pushes unconstitutional regulation",
    "originLink": "https://www.techdirt.com/2023/10/23/google-decides-to-pull-up-the-ladder-on-the-open-internet-pushes-for-unconstitutional-regulatory-proposals/",
    "originBody": "TECHDIRT GREENHOUSE FREE SPEECH ERROR 402 DEALS JOBS SUPPORT TECHDIRT Daily Deal: The Lean Six Sigma Career Advancement Bundle Supreme Court Asked (Again!) To Rule That Recording Cops Is Protected By The 1st Amendment Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals Policy from the not-cool dept Mon, Oct 23rd 2023 10:53am - Mike Masnick It’s pretty much the way of the world: beyond the basic enshittification story that has been so well told over the past year or so about how companies get worse and worse as they get more and more powerful, there’s also the well known concept of successful innovative companies “pulling up the ladder” behind them, using the regulatory process to make it impossible for other companies to follow their own path to success. We’ve talked about this in the sense of political entrepreneurship, which is when the main entrepreneurial effort is not to innovate in newer and better products for customers, but rather using the political system for personal gain and to prevent competitors from havng the same opportunities. It happens all too frequently. And it’s been happening lately with the big internet companies, which relied on the open internet to become successful, but under massive pressure from regulators (and the media), keep shooting the open internet in the back, each time they can present themselves as “supportive” of some dumb regulatory regime. Facebook did it six years ago by supporting FOSTA wholeheartedly, which was the key tide shift that made the law viable in Congress. And, now, it appears that Google is going down that same path. There have been hints here and there, such as when it mostly gave up the fight on net neutrality six years ago. However, Google had still appeared to be active in various fights to protect an open internet. But, last week, Google took a big step towards pulling up the open internet ladder behind it, which got almost no coverage (and what coverage it got was misleading). And, for the life of me, I don’t understand why it chose to do this now. It’s one of the dumbest policy moves I’ve seen Google make in ages, and seems like a complete unforced error. Last Monday, Google announced “a policy framework to protect children and teens online,” which was echoed by subsidiary YouTube, which posted basically the same thing, talking about it’s “principled approach for children and teenagers.” Both of these pushed not just a “principled approach” for companies to take, but a legislative model (and I hear that they’re out pushing “model bills” across legislatures as well). The “legislative” model is, effectively, California’s Age Appropriate Design Code. Yes, the very law that was just declared unconstitutional just a few weeks before Google basically threw its weight behind the approach. What’s funny is that many, many people have (incorrectly) believed that Google was some sort of legal mastermind behind the NetChoice lawsuits challenging California’s law and other similar laws, when the reality appears to be that Google knows full well that it can handle the requirements of the law, but smaller competitors cannot. Google likes the law. It wants more of them, apparently. The model includes “age assurance” (which is effectively age verification, though everyone pretends it’s not), greater parental surveillance, and the compliance nightmare of “impact assessments” (we talked about this nonsense in relation to the California law). Again, for many companies this is a good idea. But just because something is a good idea for companies to do does not mean that it should be mandated by law. But that’s exactly what Google is pushing for here, even as a law that more or less mimics its framework was just found to be unconstitutional. While cynical people will say that maybe Google is supporting these policies hoping that they will continue to be found unconstitutional, I see little evidence to support that. Instead, it really sounds like Google is fully onboard with these kinds of duty of care regulations that will harm smaller competitors, but which Google can handle just fine. It’s pulling up the ladder behind it. And yet, the press coverage of this focused on the fact that this was being presented as an “alternative” to a full on ban for kids under 18 to be on social media. The Verge framed this as “Google asks Congress not to ban teens from social media,” leaving out that it was Google asking Congress to basically make it impossible for any site other than the largest, richest companies to be able to allow teens on social media. Same thing with TechCrunch, which framed it as Google lobbying against age verification. But… it’s not? It’s basically lobbying for age verification, just in the guise of “age assurance,” which is effectively “age verification, but if you’re a smaller company you can get it wrong some undefined amount of time, until someone sues you.” I mean, what’s here is not “lobbying against age verification,” it’s basically saying “here’s how to require age verification.” A good understanding of user age can help online services offer age-appropriate experiences. That said, any method to determine the age of users across services comes with tradeoffs, such as intruding on privacy interests, requiring more data collection and use, or restricting adult users’ access to important information and services. Where required, age assurance – which can range from declaration to inference and verification – should be risk-based, preserving users’ access to information and services, and respecting their privacy. Where legislation mandates age assurance, it should do so through a workable, interoperable standard that preserves the potential for anonymous or pseudonymous experiences. It should avoid requiring collection or processing of additional personal information, treating all users like children, or impinging on the ability of adults to access information. More data-intrusive methods (such as verification with “hard identifiers” like government IDs) should be limited to high-risk services (e.g., alcohol, gambling, or pornography) or age correction. Moreover, age assurance requirements should permit online services to explore and adapt to improved technological approaches. In particular, requirements should enable new, privacy-protective ways to ensure users are at least the required age before engaging in certain activities. Finally, because age assurance technologies are novel, imperfect, and evolving, requirements should provide reasonable protection from liability for good-faith efforts to develop and implement improved solutions in this space. Much like Facebook caving on FOSTA, this is Google caving on age verification and other “duty of care” approaches to regulating the way kids have access to the internet. It’s pulling up the ladder behind itself, knowing that it was able to grow without having to take these steps, and making sure that none of the up-and-coming challenges to Google’s position will have the same freedom to do so. And, for what? So that Google can go to regulators and say “look, we’re not against regulations, here’s our framework”? But Google has smart policy people. They have to know how this plays out in reality. Just as with FOSTA, it completely backfired on Facebook (and the open internet). This approach will do the same. Not only will these laws inevitably be used against the companies themselves, they’ll also be weaponized and modified by policymakers who will make them even worse and even more dangerous, all while pointing to Google’s “blessing” of this approach as an endorsement. For years, Google had been somewhat unique in continuing to fight for the open internet long after many other companies were switching over to ladder pulling. There were hints that Google was going down this path in the past, but with this policy framework, the company has now made it clear that it has no intention of being a friend to the open internet any more. Filed Under: aadc, age appropriate design code, age assurance, age estimation, age verification, duty of care, for the children Companies: google 33 CommentsLeave a Comment If you liked this post, you may also be interested in... KOSA Won’t Just Silence LGBTQ Voices; It Will Also Be Used To Hide Abortion Info From The Internet New York Pushing Yet Another Unconstitutional Social Media Age Verification Bill A Reagan Judge, The First Amendment, And The Eternal War Against Pornography The Weird Legal Posture Of Bounty Laws Strikes Again: Porn Age Verification Lawsuit In Louisiana Dismissed Co-Sponsor Of Unconstitutional AADC Law Completely Misrepresents Court’s Ruling, Showing His Lack Of Attention To Detail Comments on “Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals” Subscribe: RSS Leave a comment Filter comments in by Time Filter comments as Threaded Filter only comments rated Insightful Filter only comments that are Unread 33 Comments Collapse all replies This comment is new since your last visit. This comment has been deemed insightful by the community. Anonymous Coward says: October 23, 2023 at 11:13 am I see a plan which is very attractive to an adverting giant, provide age verification services to all sites, and gain universal tracking identifying people across time and the Internet space. Bring up a new device, and the first age verification ties that device to your previous history. Collapse replies (4) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Autrach Sejanoz says: October 23, 2023 at 12:31 pm Re: DON’T GIVE THEM IDEAS, GODDAMN YOU!!! Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 12:45 pm Re: Re: Project Dragonfly was a thing, this is probably a refinement of the blasted thing, so… They probably had this in the backburner the whole time. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 1:00 pm Re: ok then show us your real name and your search history Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 1:52 pm Re: Re: Where did I indicate that I greed with that plan? Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Somewhat Less Anonymous Coward (profile) says: October 23, 2023 at 11:13 am From wiki: “Don’t be evil” is Google’s former motto. The rest is just boring specifics. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. This comment has been deemed insightful by the community. Anonymous Coward says: October 23, 2023 at 11:19 am More data-intrusive methods (such as verification with “hard identifiers” like government IDs) should be limited to high-risk services (e.g., alcohol, gambling, or pornography) Goody. Mandating porn ID and, by association, tying porn use with that ID. Sounds like Google is advocating for, among other things, government mandated collection of adults’ fetishes tied to their names. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. blakestacey (profile) says: October 23, 2023 at 11:21 am So, objecting to age verification is now the way to Stand Up Against Big Tech. Collapse replies (10) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 11:30 am Re: So, from where did you get that? Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 11:40 am Re: No, its standing up for your right to remain anonymous, and have an Internet that no made so child safe as to cease to be interesting and useful, other than online shopping and video streaming. Collapse replies (2) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] freakanatcha (profile) says: October 23, 2023 at 12:14 pm Re: Re: Fun while it lasted... Keep in mind GOP politicians are calling for cancelling visas of foreign nationals who support Hamas and deporting them back to their home countries. Freedom of speech…go to know ya Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [4] Anonymous Coward says: October 23, 2023 at 1:54 pm Re: Re: Re: The GOP viewpoint is that only they and their supporters should have any freedoms, and everybody else should be forced into slavery, or the crematorium. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] blakestacey (profile) says: October 23, 2023 at 12:10 pm Re: To clarify: time and time again, politicians trot out “we need to fight back against Big Tech” to support some terrible idea or other. Sen. Blumenthal, for example, seems to operate in a continual “a noun, a verb, Big Tech” mode. But with Google now endorsing some form of these bad ideas, there has been an ironic turnabout. One can now legitimately say that the California AADC and its ilk are what Big Tech wants. The question is now just how eager the government is to give it to them. (Very eager, I suspect.) Collapse replies (5) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 12:37 pm Re: Re: While Google pushes the narrative they are still against it… Hopefully there huge backlash to this. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [4] Anonymous Coward says: October 23, 2023 at 3:21 pm Re: Re: Re: Same. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 3:23 pm Re: Re: Tell that to Facebook (They supported FOSTA) Collapse replies (2) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [4] Anonymous Coward says: October 23, 2023 at 4:20 pm Re: Re: Re: Atleast Facebook is willing to tell you straight to your face where Google is trying to gaslight everyone. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [5] Anonymous Coward says: October 23, 2023 at 4:41 pm Re: Re: Re:2 Good point. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 11:26 am I wonder if this has anything to do with (possible) growing discontent with the way Chrome is headed. I don’t use Chrome or track is usage numbers, so maybe Google has nothing to worry about on that front. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 2:11 pm Re: Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 11:29 am “using the political system for personal gain and to prevent competitors from having the same opportunities.” More like corruption than entrepreneurial. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. blakestacey (profile) says: October 23, 2023 at 11:34 am Both of these pushed not just a “principled approach” for companies to take, but a legislative model (and I hear that they’re out pushing “model bills” across legislatures as well). The text of those model bills would be very interesting to see. I expect that they would make clear a great deal of what the “policy framework” obscures with vague sales-talk. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Cat_Daddy (profile) says: October 23, 2023 at 11:36 am Google: “I oppose age verification except when it’s done by me.” Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 11:55 am Oh no who could’ve seen this coming aside from everyone? Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 12:02 pm I don’t know why we still have Danes! We supported the “Pay Dane-geld Policy” proposals. I have no idea what went wrong… Google legislative appeasement committee Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 12:26 pm So Google came out with the narrative saying they are against mandated age verification while secretly saying they do support it… Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 1:42 pm The EU is drafting a “Voluntary” code of conduct for age appropriate design under the DSA. Maybe Google tries to align obligations. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 1:59 pm Re: age appropriate design What is age appropriate design other than styles of presentation and content attractive to the target age group? It seems to me by that logic, age appropriate design will the increase engagement of children, whale adult orientated design will cause children to look elsewhere for their entertainment, Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. That One Guy (profile) says: October 23, 2023 at 2:57 pm 'Our enemies are supporting our actions, do they know something we don't?' Politicians meanwhile will continue to pretend that their unconstitutional bills are aimed are reigning in Big Tech, even as the same companies they are name-dropping as the enemy back and support their efforts. Collapse replies (2) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 3:09 pm Re: Sad, but true thing is this will continue until there’s 1 left. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 3:20 pm Re: Re: Sad, but true thing is this will continue until there’s 1 left. My bet’s on Connor MacLeod! Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. This comment has been flagged by the community. Click here to show it. This comment is new since your last visit. Iain Corby (user link) says: October 24, 2023 at 2:53 am Age verification is not rocket science You are right to point out that Google is not arguing against online age assurance, rather it is proposing appropriate, proportional methods that suit each use-case. The comments on this article again focus on the fear that age assurance will be the death of online privacy. But if we can put a man on the moon, we can prove your age online without disclosing your full identity. The French data protection authority, CNIL, has developed a cryptographic method which guarantees anonymity. Facial age estimation can be conducted on-devie, with your image never touching a server, and no personally identifiable information being transmitted beyond a simply “yes” or “no” in answer to an age condition question. (A point California’s Attorney-General will doubtless make forcefully at the appeal hearing, as the judge who provided the injunction against the CA AADC clearly did not appreciate this point, and that was a fundamental basis of her judgement.) The Internet was never designed for children, and as we spend more of our lives online we need to make it age – not identity – aware. This can be achieved anonymously, and through interoperable solutions such as http://www.euCONSENT.eu at very little inconvenience to the user. Reply View in chronology Make this comment the first word Make this comment the last word Add Your Comment Your email address will not be published. Required fields are marked * Have a Techdirt Account? Sign in now. Want one? Register here Name Email Subscribe to the Techdirt Daily newsletter URL Subject Comment * Comment Options: Use markdown. Use plain text. Make this the First Word or Last Word. No thanks. (get credits or sign in to see balance) what's this? Daily Deal: The Lean Six Sigma Career Advancement Bundle Supreme Court Asked (Again!) To Rule That Recording Cops Is Protected By The 1st Amendment Follow Techdirt Essential Reading The Techdirt Greenhouse Read the latest posts: Winding Down Our Latest Greenhouse Panel: The Lessons Learned From SOPA/PIPA From The Revolt Against SOPA To The EU's Upload Filters Did We Miss Our Best Chance At Regulating The Internet? Read All » Trending Posts Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband Math Problem For Linda Yaccarino: If 90% Of The Top Advertisers Have Come Back, But Are Only Spending 10% Of What They Used To, How Screwed Are You? Techdirt Deals BUY NOW Cisco CCNA 200-301 Exam: Complete Course with Practical Labs Techdirt Insider Discord The latest chatter on the Techdirt Insider Discord channel... John Roddy: Did you know that you're not allowed to criticize the EU's actions unless the US is exactly perfect? mildconcern: Yes. This is a more general rule though, applies to a lot of ingroups vs outgroups, of course. Mike Masnick: lol. i've wasted so much of today on this mildconcern: And apparently the peasants out there in web-comment land have noticed our sandbox here. Hello, peasants. In other news I have to do a feature demo today which I was late in delivering. so as a \"sorry\" type bonus I also coded up a separate feature this group of people had been asking for, but wasn't part of this contract as such. and I thought \"I can do a Steve Jobs style 'and one more thing...' for them.\" And I looked down at myself, and realized: I am wearing a black sweater. Sometimes, the stars just align. Mike Masnick: yes, but is it a mock turtleneck? mildconcern: I'm not that cool, alas. I don't have any. But I do have scruff and no hair, so? I'm taller than Steve was though. maybe that makes for more dominance. He was.... not that nice the one time I met him (I was in the same dorm in college as his daughter) candescence: So apparently exTwitter has now purged NSFW content from the \"for you\" feed John Roddy: > The State Action Doctrine Can Apply When Google Looks to the Government to Decide What Information to Censor on YouTube lol > Google Is Not a Publisher, So It Does Not Have a First Amendment Right to Censor Speech Based on Its Viewpoint ell, oh, and furthermore, ell. > It is also worth noting that California courts view the Internet “as a classic public forum” in cases involving the state’s anti-SLAPP statute. Chaker v. Mateo, 209 Cal. Kennedy is even dumber than Fyk. imo, courts need to start seriously considering imposing sanctions on any lawyer who tries the \"cannot have it both ways!!!!\" argument in response to 230. Mike Masnick: the fyk case has been hilarious to watch. the belief that he's playing 4th dimensional chess or whatever. his \"we cannot lose, because either way we win\" argument is... um... quite something John Roddy: I view it from the perspective of six-dimensional quantum phase space. And frankly, he needs more dimensions. Well, I'm sure his lawyers are making absolute bank from it. candescence: Of course Newsom signed AB 1394 into law. The guy's been rather selectively signing and vetoing bills because he obviously wants to look good for a future presidential run. tomacamot: Courts need to start more seriously imposing sanctions in general, too many bad faith plaintiffs and lawyers who enable them. John Roddy: Also, as the record has shown, Mike Masnick is vehemently against *any* kind of regulations on anything ever. Apparently. I don't remember him saying that, but apparently that's what criticizing the EU's approach to things implies. Mike Masnick: I need to learn to stop engaging with idiots though, as i've said many times, to me it's kinda like batting practice. when i do engage with policymakers or people who are actually important, i've already heard every possible argument they can make, and have my response clear and ready. John Roddy: My favorite is the comparison to climate change when arguing in support of government regulation Mike Masnick: Uh, yup John Roddy: Because that has definitely worked out well All right, so what happens more often: Military secrets leaked on War Thunder forums, or Arma 3 gameplay footage gets passed off as credible footage of [current conflict here]? I've lost count of both. mildconcern: If I had a nickel for every time someone asserted companies have no choice but to defend copyright or patents or risk losing them ... Mike Masnick: we'd be worth more than the entire copyright/patent system. John Roddy: Need more people like Vino from All of Garden, imo. mildconcern: I think the idea that it's more or less compelled for trademarks appeals to the sort-of-knowledgeable as a way to sound Wise and Informed about the world when someone else is talking about a moral failure or something. It's very NYT reader. But jesus christ people, read a friggin book about it or something. It's not hard. tomacamot: If somebody's just giving you nickels each time I can repeat it over and over for a 50% cut of the income Mike Masnick: So @John Roddy someone took our exchange here, which was about the people yelling at me on Bluesky... and falsely claimed I was complaining about a perfectly nice interaction I had on Mastodon, so that's fun. John Roddy: ...I am not even on mastodon. Mike Masnick: This person was pretty sure it was about a discussion on mastodon. John Roddy: Hey person on mastodon! This wasn't about you. Our conversation about your *extreme* flatulence was held privately. I actually sympathize. It must be irritating to be unable to use public transport without making all the other passengers desperately bail out the windows. But please, *please,* do not attempt to fly. Mike Masnick: Sorry, just booked five more flights before the end of the year. Watch out. Samuel Abram: Using public transportation is much more preferable (to me) than owning and maintaining a car, at least in a city like NYC. I mean, I'm 41 and I don't even have a driver's license. pyrex: I'm subtooting somebody _RIGHT NOW_. Samuel Abram: @Mike Masnick, don’t you have an announcement to make to everyone in the chat? Mike Masnick: ? Samuel Abram: I mean, aren’t you the _tycoon_ of TechDirt? Mike Masnick: hahah. the post is at the top of the site, I figure people can see it there... Samuel Abram: Ah. It’s just that some people access this chat through discord Anyway, will there be a subsequent podcast about _Trust & Safety Tycoon_? Mike Masnick: yes, there will be a podcast about trust & safety tycoon. possibly even two podcasts. we'll see. but, anyway, for those in discord and not checking out techdirt: [article] John Roddy: When's the ray tracing update going to land? I paid an embarrassing amount of money for this overpowered water cooled computer, and I expect to be maxing it out. TIL. One of the nutjobs I'm following tried sending Google an arbitration notice that held if they don't respond within 24 hours, he owns all of Google's IP forever and they need to pay him $500 billion. The court did not find it convincing. [link] Well I'll be. So uhh, the last comment on there... Mike Masnick: John Roddy: I've brought this guy up a few times recently. He's the one who just got formally declared a vexatious litigant in that court. candescence: [article] Labor already confimed they plan to implement truth in political advertising laws in Australia some time ago, but the demand for it only got louder after the failed voice referendum, which was flooded with fearmongering and misinformation Sure, the Yes campaign didn't do a good job, but the No campaign's bad-faith campaigning was just _disgusting_ The government have acknowledged that there needs to be a balance between freedom of speech and the need to crack down on blatant misinformation, at least. mildconcern: Even still, that requires the government to judge what is true and what is not. That type of decision is at best fraught. BentFranklin: Related [article] Samuel Abram: BTW, remember how someone on twitter (before the amuskalypse) quoted The Princess Bride and got flagged for a death threat? I did the same thing for quoting the Simpsons on instagram It was in former Simpsons showrunner Bill Oakley's post on how there's an actual Moe's Tavern in Austin, TX Somebody mentioned that there wasn't \"Chowder\" on the menu and I said > It's pronounced \"Chowdah!\" I'LL KILL YOU! I'LL KILL YOU ALL!! Anyone with any deep Simpsons knowledge would've recognized that quote from the episode \"The boy who saw too much\" but obviously, I got flagged for a death threat Oh well, I take responsibility for it Cathy Gellis: I wonder if adding #SimpsonsQuote would have forestalled the flag? Samuel Abram: or even an emoji? In any event, I can still use instagram mildconcern: A friend of mine posted about finding a love note from a teacher to a high school student while using their classroom for a competition. asking how to turn it in. I gave suggestions and then said \"and then consider washing your eyes with bleach or something I guess.\" Twitter flagged me for encouraging self harm or suicide. .... In retrospect it was hardly shocking that the subtleties were lost on the bots, but it brought home how much the \"appeal\" is just another bot. John Roddy: I'm pretty sure the reason my discord got flagged for \"piracy\" is because I do openly mock some people who engage in it. Samuel Abram: It'll be kinda hard to pirate my works though, as I license them with a creative commons license The only works I make which are all rights reserved are works I don't actually own, such as covers and remixes (excluding those in the public domain, of course) (and covers and remixes where I comply with other peoples' creative commons licenses) Become an Insider! Recent Stories Monday 19:45 The Utah Cookie Wars Are Over: Crumbl Settles Trademark Suit With Dirty Dough (2) 15:37 Clearview Gets $10 Million UK Fine Reversed, Now Owes Slightly Less To Governments Around The World (8) 13:34 Peering Through The Fog Of War With Open Source Intelligence (6) 12:02 Supreme Court Asked (Again!) To Rule That Recording Cops Is Protected By The 1st Amendment (9) 10:53 Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals (33) 10:48 Daily Deal: The Lean Six Sigma Career Advancement Bundle (0) 09:37 LAPD Releases Recording Two Cops' Decision To Pursue Pokémon Rather Than Robbery Suspects (11) 05:29 Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband (9) Sunday 13:10 Funniest/Most Insightful Comments Of The Week At Techdirt (32) Saturday 12:00 This Week In Techdirt History: October 15th - 21st (0) More Tools & Services Twitter Facebook RSS Podcast Research & Reports Company About Us Advertising Policies Privacy Contact Help & Feedback Media Kit Sponsor / Advertise More Copia Institute Insider Shop Support Techdirt Brought to you by Floor64 Proudly powered by WordPress. Hosted by Pressable. This site, like most other sites on the web, uses cookies. For more information, see our privacy policy",
    "commentLink": "https://news.ycombinator.com/item?id=37990031",
    "commentBody": "Google pulls up the ladder on open internet, pushes unconstitutional regulationHacker NewspastloginGoogle pulls up the ladder on open internet, pushes unconstitutional regulation (techdirt.com) 338 points by WarOnPrivacy 15 hours ago| hidepastfavorite238 comments dleslie 14 hours agoCynically, Google may be supporting this legislation because it believes that it will mandate that Browsers be secured from modification that could undermine the efficacy of the legislation.They have that Chrome change, whose name eludes me, which provides secure Browser validation to the host; this legislation would make use of that feature ubiquitous and mandatory. reply zerojames 14 hours agoparentWeb Environment Integrity? https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Web_Environment_Integrity reply dcow 13 hours agorootparentSay a site uses WEI to block Google’s crawlers. If Google actually respected that then maybe it’s a fair playing field. But knowing Google they’ll issue their crawlers valid certs and create a huge dystopian nightmare. reply mymacmachine 13 hours agorootparentI&#x27;d imagine a different dystopian nightmare.Google don&#x27;t care if an individual site blocks them (in my experience they are one of the better crawlers at obeying robots.txt) because they know - given their search monopoly - that the vast majority of the internet would never dare to cut them out. WEI is a way to cement their current position further without needing to play dodgy games with special Google certs.If they put out WEI and start encouraging sites to use it for better SEO, the majority of the internet will do it (and wont put in the same effort to support other crawlers because those search pages are onlythe harm they inflict makes a pretty strong case that they&#x27;re net negativesDo you really think a private legal system would be better? That is the alternative, you can&#x27;t enforce laws without a police force. reply delecti 11 hours agorootparentMost of Europe is a good example of how much better policing can be done than we do it here.A pretty huge part of the problem is that our police act as vastly inferior substitutes to just proper social services. An incredibly simple and good example of how this could be done better is being demonstrated in Denver, where they have unarmed mental health first responders, because most of the time someone is in crisis they&#x27;re only a threat to themselves, so being armed only makes the situation worse.They&#x27;re also trained to view the public as the enemy (warrior training), making them a walking threat. Our police kill people at a rate many times higher than other comparably developed nations; about 60x the UK, for reference. Yes our gun ownership is higher, but the relatively low rate of police deaths shows that their readiness to resort to violence is unjustified.If we allocated even half of our police budgets towards social services, we&#x27;d live safer lives. reply Jensson 11 hours agorootparentYour argument says that we can improve the police, not that the police is net negative. You said that there are strong arguments for the police being net negative, that is very extreme.Net negative means that society would improve if we just removed it without replacing it with anything. Can you defend that? reply ineptech 10 hours agorootparentIt can simultaneously be true that X causes more problems than it solves, and that the disappearance of X would cause even worse problems. Also, this is a common strawman: almost no one advocates police abolition over police reform, but discussions about police reform very often involve someone who advocates reform being asked to defend abolition anyway. reply Jensson 10 hours agorootparent> It can simultaneously be true that X causes more problems than it solves, and that the disappearance of X would cause even worse problemsNo it can&#x27;t, if removing X causes more problems then having X prevents those worse problems.> Also, this is a common strawman: almost no one advocates police abolition over police reformThe person I responded to argued just this. This is what police being net negative means, that society would improve by removing the police. I wouldn&#x27;t have said anything if he just thought that the police could use a budget cut or a reform. reply delecti 11 hours agorootparentprev\"The police are a net negative\" does not mean that they are irreparably terrible, and \"net negative\" even makes it clear that I think they have some benefits.But yes, I think freeing up that enormous amount of budget for almost any other purpose would be an improvement. reply Jensson 11 hours agorootparent> But yes, I think freeing up that enormous amount of budget for almost any other purpose would be an improvement.Do you have good arguments for this? For example, if we dismantled the entire police force to reduce the government deficit, or to increase healthcare spending, or to reduce taxes, do you really think society would improve?Your examples above didn&#x27;t dismantle the police entirely and had a very small set of alternative spending. It isn&#x27;t consistent with what you said in this post. You need to explain why you think that dismantling the entire police force would be a net positive, how do you think that society would work without a police force? reply gs17 11 hours agorootparentprevThere&#x27;s more possibilities than \"corrupt, abusive police\" and \"corrupt, abusive private security\". The police, in the US at least, are in clear need of some reform. reply Jensson 11 hours agorootparentYeah, the US police probably needs to change, but it is a long stretch to argue they are net negative to society. reply landemva 9 hours agorootparentprev> you can&#x27;t enforce laws without a police force.You can in USA. Inform the grand jury and they can investigate and indict. Most anyone can do this by, for example, mail to the grand jury foreperson. I pulled up a big State for you:\"DUTIES OF GRAND JURY. The grand jury shall inquire into all offenses subject to indictment of which any grand juror may have knowledge or of which the grand jury is informed by the attorney representing the state or by any other credible person.\"https:&#x2F;&#x2F;statutes.capitol.texas.gov&#x2F;Docs&#x2F;CR&#x2F;htm&#x2F;CR.20A.htmThe district attorney can present, and so can \"any other credible person.\" reply Jensson 9 hours agorootparentInforming a court isn&#x27;t enough to enforce a law. Who is going to carry out the punishment of that jury if not for the police? I don&#x27;t think you understand how society works, without the police the courts doesn&#x27;t have power to punish you.Police are called law-enforcement for a reason, it is because they are how we enforce laws. reply landemva 8 hours agorootparentIn USA, grand jury is not court - they are the grand jury and can indict. In USA, court decides punishment like prison or fine and that (punishment for a crime) is defined by Legislature. Sublime sang about a specific criminal code of California: https:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;codes_displaySectio...edit: A criminal defendant may be tried in front of a jury. A grand jury is something completely different - regular people who meet in private, can review information, and can indict. replyButtons840 13 hours agoparentprevI haven&#x27;t seen any direct attacks on general purpose computing, but it sure seems like its enemies are starting to surround it. reply codedokode 13 hours agoprevThere is an easier way to protect everyone from kids. Make an OS-level setting (\"show safe content only\") that only parents can change. With this setting, the browser would open only pages that declare that they are safe for kids, by using an HTTP header (safe-content: yes). Any other websites are blocked by the browser.Make it a legal requirement for parents to set up this option for their children on every device they use. Make it illegal to send invalid \"safe content\" headers.Also, with \"safe content\" setting OS should allow running and installing only apps that are verified to be safe (for example, it should not allow installing messengers like Telegram or browsers that do not respect safe content settings).This way there is no need to verify anything and make life complicated for adult people. reply afavour 13 hours agoparentWhat does “safe for kids” mean, though? How do you imagine that being codified in law? What about different age ranges? Or does it all flip from off to on at age 18?There are obvious examples of unsuitable content like pornography but there’s also a wide variety of content out there at varying levels of suitability. And a lot of people with different opinions about what is suitable (e.g. non pornographic nudity). Good luck finding universal agreement on that. And how would anyone act on a violator? Would the police have access to a universal blocklist in all ISPs?There are already a number of voluntary systems that operate the way you describe. Legally mandating it would be very difficult. reply saltminer 12 hours agorootparentMy thoughts exactly. While there are some categories which are easy to agree on as being unsuitable for kids (and some adults, for that matter), you will inevitably find such content restrictions used to attempt to legislate morality.Look at Florida and their \"don&#x27;t say gay\" bill. They want kids to remain oblivious to the existence of LGBT people, using \"think of the children\" rhetoric, and I have no doubt they would use \"child friendly internet\" legislation to ban even the most milquetoast acknowledgment of our existence, because they see it all as \"indoctrination\" and \"grooming.\" As a lesbian, I find this abhorrent, but even if you&#x27;re not LGBT, you should be afraid of these kinds of laws, because the Christian right will inevitably use them against you, too. If you&#x27;re atheist (and if you use HN, you probably are), believe in the theory of evolution, believe in climate change, are a person of color...you get the picture.And then there&#x27;s the fact that the internet is international. Content about women&#x27;s suffrage, for instance, would likely be deemed \"inappropriate for children\" in much of the Arab world, both because most of those nations are not democratic, but also because they want to avoid empowering women.The suggestions to \"just use the MPA rating system\" are bad because, even if those ratings were objective (they&#x27;re not), the good thing about them is that they&#x27;re not legislatively enforced. If a child wants to see an R-rated movie, the theater won&#x27;t sell them a ticket directly, but if they&#x27;re accompanied by a parent, they can see it, and that&#x27;s probably the best system we can hope for: a voluntary system where parents can allow their kids access to what they feel is appropriate. And for all the flaws that has, it&#x27;s better than having CPS take your kids because you let them read the wikipedia page about being trans. reply codedokode 12 hours agorootparentThe point is that either there will be locked-down child devices or there will be total surveillance, ban of encryption and much worse things in the name of children safety.Regarding foreign countries, they already block the content they don&#x27;t like, but for everyone, so this plan won&#x27;t change anything there. reply account42 1 hour agorootparent> The point is that either there will be locked-down child devices or there will be total surveillance, ban of encryption and much worse things in the name of children safety.Why is that a given? reply codedokode 13 hours agorootparentprev> What does “safe for kids” mean, though?There are ratings for movies and games, just use any of them, for example, \"General Audiences\" rating. reply JohnFen 13 hours agorootparentThose ratings are only advisory, though, which allows parents who disagree with how the ratings are determined to ignore them. If we&#x27;re going to use a rating system that has teeth, then we still smack directly into \"who gets to decide what &#x27;safe for kids&#x27; means\". reply lowbloodsugar 9 hours agorootparentprevSpeaking as someone who was once a 15 year old, why is pornography \"unsuitable\" and why in the world would you think we couldn&#x27;t and didn&#x27;t get hold of it?Same for alcohol, which amazingly isn&#x27;t legal in US till 21!!!So let&#x27;s be clear. We aren&#x27;t talking about good policy or maximizing safety and minimizing harm. We&#x27;re talking about trigger issue to make pro and con demographics vote along party lines on this issue instead of having the freedom to vote on relevant issues which would positively impact society. reply afavour 4 hours agorootparentI’m talking about societal norms.Yes, yes, I know teenagers get ahold of porn, I was also a teenager once. But the OP was talking about passing a law for this stuff. You think a politician that stands up and says “porn for 15 year olds is cool by me!” is going to last more than five minutes? Of course they won’t. reply codedokode 13 hours agorootparentprev> And how would anyone act on a violator? Would the police have access to a universal blocklist in all ISPs?Another user suggested that there should be an organization that issues or revokes the cryptographic signatures after verifying website&#x27;s content. The site displays the signature proving that it was checked to be safe, in HTTP headers. reply gs17 12 hours agorootparentGreat, but then the content on the site has to be relatively static. Maybe social media is inherently \"unsafe\", but what about a news site? Do kids only get to see yesterday&#x27;s news? reply codedokode 12 hours agorootparentYou do not need to verify every single page. You verify that owner and operator are not foreign entities (so you can catch them and put in jail), review the moderation policies and get a written promise to follow the law. reply gs17 12 hours agorootparentBut if you did, you gain protection from defaced sites (in addition to making \"show safe content only\" actually true). Most of the worst things I saw online as a kid were on otherwise okay sites attacked in whatever way to show shock images. reply codedokode 12 hours agorootparentI cannot remember when I saw a defaced website last time. This is very rare nowadays. reply gs17 11 hours agorootparentI can&#x27;t see this system not giving more motivation to deface websites. replyZardoz84 11 hours agorootparentprevI see how this could be uses to censor any website that talk about LGTBQIA+, racial rights, etc... in the name of \"safety for kids\" reply zffr 13 hours agoparentprevHow do you define \"safe\"? What is the process for amending this definition in the future? What if different countries have different definitions? At what point is a person allowed to view not \"safe\" web content? How do you enforce this policy? How do you identify violations of the policy? What is the penalty for violating the policy?... and this is just the tip of the icebergIMO a policy like this would not be easy to pull off at all. reply codedokode 13 hours agorootparent> How do you define \"safe\"?There are ratings for movies and games, we can use them.> What if different countries have different definitions?Then browser will refuse to open pages from that countries. For example, there could be an organization assigning rating to websites and issuing them a cryptographic signature as a proof. The browser will refuse to open any page without this signature, including pages from countries with different standards.> How do you enforce this policy?With jail terms.> At what point is a person allowed to view not \"safe\" web content?At the age of 18. reply l33t7332273 11 hours agorootparent>There are ratings for movies and games, we can use themThese are provided by a private entity. What we clearly need is an official government morality commission. reply thisgoesnowhere 11 hours agorootparentprev> IMO a policy like this would not be easy to pull offProbably would be a lot of work, but if it&#x27;s important then we could definitely do it. reply Kinrany 13 hours agoparentprevThis may very well be worse: children would have no access to internet except for websites designed with the single goal of extracting money from parents. reply codedokode 12 hours agorootparentMajority of websites are made with sole purpose to extract money. reply makeitdouble 9 hours agorootparentDon&#x27;t we just call those \"businesses\" ? reply darkarmani 13 hours agoparentprev> Make it a legal requirement for parents to set up this option for their children on every device they use.Why? Let the parents decide -- they now have the controls they need.> Make it illegal to send invalid \"safe content\" headers.Just make them cryptographically signed. Anything without a valid signed header is \"adult\". reply codedokode 13 hours agorootparent> Just make them cryptographically signed.Yes this is better, let some organisation issue these signatures. reply mr_toad 9 hours agorootparentFor a ‘reasonable’ fee of course. reply brvsft 12 hours agoparentprevI&#x27;m not against this, but I do believe such a header would give parents a false sense of security in what they can allow their children to do on the internet.Then again, for those of us who are skeptical that such a program can work, I&#x27;m guessing we already aren&#x27;t or do not plan to allow our kids on the internet without supervision, so it&#x27;s a bit of a moot point for me.I&#x27;m just annoyed that there is a certain set of incentives that allow for people to ignorantly trust the security and safety of various websites and applications, and then get some sort of reward&#x2F;handout in the form of a class-action lawsuit against these services when they&#x27;re finally caught failing to live up to the proposed safety regulations. So every idiot who had an account can line up for $20, and I get zero reward for correctly avoiding the situation by not signing up. These are perverse incentives IMO, and I&#x27;ll just continue to be annoyed with all solutions that continue to allow this sort of thing to happen.Under your proposal, there&#x27;s an inevitable lawsuit where a bunch of people get paid out for allowing their children to get goatse&#x27;d because &#x27;kidpxrn.biz&#x27; falsely put on the safe-for-kidz header. Sure, they got sued, but a bunch of kids got goatse&#x27;d in the process, and their parents got $20. Cool future, I guess. reply codedokode 12 hours agorootparent> Under your proposal, there&#x27;s an inevitable lawsuit where a bunch of people get paid out for allowing their children to get goatse&#x27;d because &#x27;kidpxrn.biz&#x27; falsely put on the safe-for-kidz headerThere could be an organization that reviews site content and moderation policies, ensures that site operator and owner are not foreigners (so that they can be put to jail) and issues cryptographic proof of verification that the website would display in an HTTP header. As website owners are not anonymous they will not risk a jail term to put unsafe content on the site. reply hedora 12 hours agoparentprevHere&#x27;s a simpler, equally effective solution:The parents buy a laptop, and they have the admin password. You need the admin password to change the setting.If parents want to enable this or not for their kids, it&#x27;s up to the parents to decide. Also, if adults want to enable the filters for their own personal use, that&#x27;s fine too.There&#x27;s literally an entire industry doing a bad job of this right now. If Google actually cared about improving the status quo, then instead of trying to mandate adults use cryptographically signed advertising identities to browse the web, they could use their web crawl and influence over web standards to improve the quality of opt-in content filters (by producing better site ratings lists, in the style of adblock lists, for example).Device-level protection doesn&#x27;t work for kids that can break into the bootloader or jailbreak the machine their parents got for them, but not many things realistically will.Also, the scheme&#x27;s failure to work against sophisticated users is a feature: at some point, kids turn into adults. These mechanisms shouldn&#x27;t be capable of censoring adults&#x27; internet feeds. reply autoexec 3 hours agorootparentHere&#x27;s an even simpler solution: Parents parent their children and pay attention to what they do online instead of letting third parties decide what is or isn&#x27;t appropriate for their children to see, but I guess we&#x27;ve decided to abandon that idea for some reason.> Device-level protection doesn&#x27;t work for kids that can break into the bootloader or jailbreak the machine their parents got for them, but not many things realistically will.Kids that are clever enough to hack their devices to get around those kinds of restrictions are probably old enough and smart enough to not need the censoring. reply codedokode 12 hours agorootparentprevToday there is no legal requirement for laptop manufacturers to implement \"safe content\" setting and, as I am aware, there is no such OS-level settings in any OS.iOS seems to have \"parental controls\", but they are implemented in the worst way possible. For example, to restrict access to websites, you have to manually enter the domains into black or white lists [1]. It seems like Apple tried to comply with some kind of regulations the cheapest way.There should be just a single checkbox, because I don&#x27;t think there are many people who are ready to manually compile white lists of websites and browse through those complicated settings.[1] https:&#x2F;&#x2F;www.internetmatters.org&#x2F;parental-controls&#x2F;smartphone... reply g-b-r 11 hours agoparentprevOk the long message I wrote got lost, great.In short people, there&#x27;s no need for cryptography certification security etc, what the governments push for would require websites and services to make at most exactly the same decisions!!!There&#x27;s no certification required that I&#x27;m aware about, websites operators are required to make the decisions themselves exactly like in this proposal !!Conundrums with user content, hosted services, legal responsibility, same!!!The only difference is that with age verification the website would have to decide if he needs to prompt the age verification system, with this if he wants to send the header!Once there&#x27;s a header (good old PICS) in a tls connection that&#x27;s it!(of course the huge difference with this system is that here only the services that explicitly want to be offered to minors would need to do something, as opposed to everyone - and as an aside this would limit immensely what&#x27;s accessible to minors) reply notfed 12 hours agoparentprevSounds like we need to bring back the Evil Bit:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Evil_bit reply npteljes 12 hours agoparentprevHere&#x27;s the fail in your plan: I&#x27;ll register \"mommylookaway.com\", make it a simple web proxy like proxysite.com, and set the content flag to child safe. Making it illegal does nothing, just as law doesn&#x27;t stop spreading other illegal material over the internet, right at this moment.Telegram etc can also have web frontends that do the same.There&#x27;s no easy way around this, and that&#x27;s because of a totally different reason. The reason being that the cause for all this is control, namely government control and surveillance over the populace. Companies profit from this and governments can increase their power with this, so they are natural allies in this scenario - government has the will and power over law, and companies have the know-how and the technical means, and of course a similar thirst of power.Situations like this must not be mistaken for the technicalities that they present. It&#x27;s simply the next step in the power grab. reply codedokode 12 hours agorootparentYes, this part wasn&#x27;t thought out well enough. Let there be an organization that verifies site owners (to verify that they are not abroad and can be put in jail if needed), content and moderation policies and issues a cryptographic signature. The website displays the signature in HTTP headers. reply JohnFen 13 hours agoparentprev> the browser would open only pages that declare that they are safe for kidsSafe according to who? There is no actual consensus outside of a core of extreme things about what is \"safe for kids\" and what is not. reply codedokode 13 hours agorootparentThe government will decide what is safe of not. There already are ratings for movies, for example \"General Audiences\" rating. reply dotnet00 12 hours agorootparentYou keep repeating this, but those ratings are not government issued and are not all that useful when it comes to general information. A movie can be made to be sufficiently sanitized for the target audience as there&#x27;s plenty of flexibility in the topic and objectivity is often just a secondary goal. Eg since the movie is targeted at families, it&#x27;ll avoid explicit depictions of sex. On the other hand, you can&#x27;t just change the reality of what a scientific article on sexual reproduction is going to show, yet that information is not necessarily problematic for people under 18 to access (and of course you&#x27;ll have a hard time balancing what is socially healthy with what is acceptable to parents).On top of all that though, we don&#x27;t need to make even more things be behind this absurd age gate. I remember how ridiculous it felt turning 18, going from legally being a child to being a mostly free adult just on a specific day, despite obviously not having suddenly changed as a person in 1 day and having already been living independently at university thousands of miles away from home. Same again upon turning 21.This idea of sharp limits defined by age is just an intellectually lazy approach which is not how we should be treating access to general information for a fifth of a person&#x27;s life. Tech companies love this kind of intellectual laziness, and similar thinking is responsible for why said tech companies are responsible for so many current social issues. reply gs17 11 hours agorootparentI wouldn&#x27;t even worry about how useful the rating systems are, I&#x27;d worry about how arbitrary they are even if you accept their standards. E.g. the \"one fuck\" rule for PG-13 films, except a film like The Martian can say it twice without being rated R because the raters vote on what they think American parents would think about the film in that case. reply ikekkdcjkfke 4 hours agorootparentprevI would rather have a generative device that fakes all content but steers the user into topics and ideas that would be a positive influence.Done dealing with unfilteres 3rd parties as they are always not to be trusted. Generate everything reply oxygen_crisis 10 hours agorootparentprev\"The government will decide what is safe or not\" is an extremely frightening phrase to me when it comes to issues of morality.I recognize the importance of having the government decide what foods are safe, what industrial byproducts are safe, and so forth when it comes to matters of objective science but when they start policing content like books and websites it starts stepping into some serious authoritarianism... reply polski-g 12 hours agorootparentprevThose movie ratings are not performed by the government. reply codedokode 12 hours agorootparentProbably they are made to comply with some laws or regulations (or to avoid being regulated by laws), so the government has a say here anyway. reply polski-g 10 hours agorootparentIt would be unconstitutional for the government to regulate film content. So no. replyThinkBeat 12 hours agoparentprevWe need this for tv content as well.A tv should show zero content until it has fully verified the identity &#x2F; age of the viewer(s) and sense if someone new arrives and then stop programming until that person is verified.This could also be done by transmitting scrambled content, that can only be fixed by wearing identity ensured glasses genetically locked to the wearer. reply gs17 12 hours agorootparentDon&#x27;t forget refusing to continue showing content if you look away from ads! reply makeitdouble 9 hours agoparentprev> no need to make life complicated for adult people.I like that it&#x27;s the main goal for all these huge and pervasive legal changes.I know there&#x27;s all the cultural \"can&#x27;t show a nipple to my pure innocent girl\", but it still amazes me our societies as a whole have to deal with the radicalism of a few. reply _Algernon_ 13 hours agoparentprevIt&#x27;s trivial to boot from a live USB to circumvent this. reply codedokode 12 hours agorootparentIf you are a programmer. reply gs17 12 hours agorootparentNo, if you even know anyone tech savvy enough (within several degrees of separation) to figure it out. Kids are very good at getting around things like this and the solutions go viral. You would have to restrict a lot more than just the browser. reply codedokode 12 hours agorootparentYes but kids who do not want to see porn (or people cut in pieces) will not see it accidentally. Isn&#x27;t that good? reply gs17 12 hours agorootparentBut now the promise goes from \"kids can only see safe things\" to \"kids can only see safe things unless they want to see a single unsafe thing, then they see everything\". With \"safe things\" being a government-created whitelist, it&#x27;s going to be pretty easy for almost every kid to want \"unsafe things\" that aren&#x27;t porn or gore. They&#x27;ll want to play games (by your standards, even a T rated game is unsafe since it&#x27;s T for Teen, not T for Twelve-Year-Old), watch whatever videos (zero anime&#x2F;cartoon&#x2F;whatever streaming sites would be deemed safe), and use social media. This whole filter would be pointless if you accept it being easy to get around. reply codedokode 11 hours agorootparentWhat you are describing are small issues. Of course there will be those who try to circumvent the regulations (like children who drink alcohol or smoke). Does it mean that we should sell alcohol without age verification?Instead of one \"safe mode\" there could be several, for example \"safe for all\", \"safe for teens\" etc.Regarding movie sites, there are paid sites where you can legally watch anime or cartoons, and I am sure they will pass the certification for safe content. reply gs17 11 hours agorootparent>Does it mean that we should sell alcohol without age verification?That has an objective standard and a clear harm to children (and adults, but we&#x27;re not able to prevent it). Meanwhile, there would definitely be a wide range of relatively harmless content arbitrarily not on your whitelist.>Instead of one \"safe mode\" there could be several, for example \"safe for all\", \"safe for teens\" etc.This is a good improvement on your idea, but it won&#x27;t fix a lot of the issues people have with it.>I am sure they will pass the certification for safe content.Not the anime or cartoons I would have wanted to watch as a minor. The Simpsons, Family Guy, do I need to go on to South Park or Rick and Morty? Banned, there&#x27;s sexuality and violence. Kids want these and will work around it. reply_Algernon_ 12 hours agorootparentprevBooting a live usb (or even creating one) has very little to do with programming. I bet anyone who wants to (especially horny teens who want to access porn) can figure it out in an afternoon. reply Belopolye 12 hours agorootparentprevI was doing that as a ten year old. reply ok123456 13 hours agoparentprevDidn&#x27;t this already exist with PICS on Windows 98? reply adverbly 13 hours agoparentprevInteresting idea... Opt in to opting out of adult content... Some potential issues:1. Might be hard to enforce the safe content header... They have a hard enough time with copyright content, and there&#x27;s a much larger financial incentive in that case.2. Need to agree on what is safe and what isn&#x27;t. Bit of a can of worms there... reply jaco6 13 hours agorootparentYou&#x27;re right. Safe content header is a relatively weak solution. Strongest solution is either Microsoft or Apple stepping up to develop a child designed device from the ground up. It would have access to a limited walled garden of the Internet. The device itself is marketed specifically to children and has no advertising allowed on it. It also incorporates health guidelines and screen time limits, etc. that cannot be changed by the device owner or user, only by Apple&#x2F;Microsoft. It is essentially a fascist phone. Admittedly, this would make an adult, unlocked smart phone a hot item on the youth black market, but hopefully most kids will be too lazy to save up the money needed to buy a black market unlocked phone before they&#x27;re ready to watch porn and be inundated with endless advertising and doomscrolls. reply codedokode 12 hours agorootparentNeither MS nor Apple will want to spend lot of money for designing devices where they cannot even show ads. reply l33t7332273 11 hours agorootparentI agree with the former but I definitely wonder about the latter.If anyone can do a secure, child-safe device that’s so expensive they don’t need to show ads to be profitable, it’s them. reply Jensson 11 hours agorootparent> so expensive they don’t need to show ads to be profitableYes, but there is no company that feels they are profitable enough so they still shows ads. Apple shows ads and makes decent profits from it, they are just a massive company like all the others. reply codedokode 13 hours agorootparentprev> Might be hard to enforce the safe content header...You don&#x27;t need to enforce it. Sites without this header will not be accessible from a browser when \"safe content\" setting is active.> Need to agree on what is safe and what isn&#x27;tThere are ratings for games and movies, let&#x27;s consider \"safe content\" to be a content which a 12-year old can watch. reply JohnFen 12 hours agorootparent> There are ratings for games and movies, let&#x27;s consider \"safe content\" to be a content which a 12-year old can watch.The existing ratings are terrible, though, and as a parent I think they allow things that I very much object to my children seeing, and prohibit things that I don&#x27;t. reply codedokode 12 hours agorootparentHaving imperfect restrictions for children is better than having none. reply JohnFen 12 hours agorootparentThat&#x27;s a bit of a false dichotomy. The choice doesn&#x27;t have to be between blanket restrictions that are bad or no restrictions at all. There&#x27;s also the option of giving some sort of mechanism to allow parents to set the restrictions they consider appropriate. reply gs17 13 hours agorootparentprevAnd when sites outside of the jurisdictions that can take legal action put \"safe-content: very yes\" on whatever non-safe content? reply codedokode 12 hours agorootparentLet there be an government-assigned organization that verifies website owner, content and issues a cryptographic signature proving that the site has been verified. The browser shall not open any page without the signature. reply jaco6 13 hours agoparentprevSafe content header is a relatively weak solution. Strongest solution is either Microsoft or Apple stepping up to develop a child designed device from the ground up. It would have access to a limited walled garden of the Internet. The device itself is marketed specifically to children and has no advertising allowed on it. It also incorporates health guidelines and screen time limits, etc. that cannot be changed by the device owner or user, only by Apple&#x2F;Microsoft. It is essentially a fascist phone. Admittedly, this would make an adult, unlocked smart phone a hot item on the youth black market, but hopefully most kids will be too lazy to save up the money needed to buy a black market unlocked phone before they&#x27;re ready to watch porn and be inundated with endless advertising and doomscrolls. reply codedokode 13 hours agorootparentI agree it would be nice but it requires more investment than my plan and companies really do not want to spend an extra cent for children safety. reply jaco6 12 hours agorootparentIt is an investment. You build brand loyalty by selling a safe device. Train kids to only use your OS. Then when they&#x27;re 18 hopefully they stick with your OS.Furthermore, OS makers could lobby for additional age gates. I.e. a child phone for ages 15 and under, a teenager phone for ages 16-17, an adult phone for 21. reply codedokode 12 hours agorootparentI doubt that. For example, look at iOS \"parental controls\". Judging by screenshots [1] here, it is a complicated system that requires a parent to be a system administrator not to get lost in hundreds of settings. For example, you might have to manually compile a white list of websites, white list of apps etc.The system is so complicated that I think many parents simply get confused and do not want to use it.Instead there should be a single checkbox: \"allow safe content only on this device\". That&#x27;s all (and you can leave detailed settings for system administrators).[1] https:&#x2F;&#x2F;www.internetmatters.org&#x2F;parental-controls&#x2F;smartphone... reply miohtama 12 hours agorootparentpreviPhone &#x2F; iPad already has this reply codedokode 12 hours agorootparentDo they provide a complete solution (you only need to tick a checkbox) or parents need to be power users and manually set up whitelist for websites and apps? Do they prevent children from using for example Telegram in locked mode? reply miohtama 1 hour agorootparentYes.- Web browser, both Safari and embedded app browsers honour these settings- You can disable apps that do not have parental controls integratedI do not know if there are generally available whitelists for websites, and I assume this would depend on the cultural context like the nationality and religion of the parents. Please correct me if I am wrong. reply jaco6 13 hours agoparentprevThis solution is the lowest cost solution and I am in favor. Will OS developers (because their market power is obviously more relevant here than the viewpoint of web developers) see it the same way? reply codedokode 13 hours agorootparentEvery computer, laptop or smartphone imported, or sold, must have this setting. If OS developers do not want their OS to be pre-installed they don&#x27;t need to implement the setting. reply jaco6 13 hours agorootparentApologies, my above remark was a bit unclear. When I said \"will OS developers see it the same way\" what I meant was whether OS developers will lobby against this law or be in favor. reply npteljes 12 hours agoparentprev>There is an easier way to protect everyone from kids.Love the phrasing. reply bsder 12 hours agoparentprev> With this setting, the browser would open only pages that declare that they are safe for kidsWhat is safe content?Is the Bible safe content? Is the Koran? etc.What about news stories about Israel? Hamas? etc. reply babypuncher 12 hours agoparentprevI like some aspects of this approach, but two points don&#x27;t work well with me.1. It shouldn&#x27;t be a legal requirement for parents to enable this on their kids devices. This should mearly be an option available to parents. Do not tell me how to raise my kids.2. \"Safe for kids\" is pretty nebulous, and you already know certain dumpy states would abuse the hell out of this (i.e. declaring content \"unsafe for kids\" if it features a man with effeminate characteristics).Maybe a solution to the latter problem would be to use content descriptors instead of a blanket \"safe for kids\" flag. i.e. individual flags for pornography, graphic violence, naughty words, etc. reply godshatter 11 hours agorootparentI like the idea of a set of tags that can be used to filter content, if so desired. It would need a set of agreed-upon tags with the option to add others. And yes, voluntary would have to be a requirement. reply codedokode 11 hours agorootparentprev> Do not tell me how to raise my kids.The government is already doing it, depending on the country, you can get prosecuted if for example you buy alcohol for children or let them do something dangerous.> Maybe a solution to the latter problem would be to use content descriptors instead of a blanket \"safe for kids\" flag. i.e. individual flags for pornography, graphic violence, naughty words, etc.Maybe, but this increases possibility for fingerprinting. reply babypuncher 9 hours agorootparent> The government is already doing it, depending on the country, you can get prosecuted if for example you buy alcohol for children or let them do something dangerous.The difference is that alcohol can cause immediate and even irreversible harm to anyone, especially children. Alcohol is heavily regulated even for use by full grown adults, specifically because of its capacity for harm. Evidence that seeing nudity or hearing dirty words does the same is incredibly sketchy at best. But even then, in most states, it is perfectly legal to let your own kids drink alcohol on your own private property.> Maybe, but this increases possibility for fingerprinting.Maybe, I think that depends on the implementation. But either way, I doubt it is much of a concern for parents who just want better control over what their kids see and do online. reply tenebrisalietum 11 hours agoparentprev> Make an OS-level setting (\"show safe content only\") that only parents can change.> Also, with \"safe content\" setting OS should allow running and installing only apps that are verified to be safeThis is hard to do on PCs where you can install your own operating system and have full control, but they&#x27;re not the dominant Internet device anymore. You would have to make those illegal or illegal for children to have. But this is effectively possible on modern phones.> Make it illegal to send invalid \"safe content\" headers.A. This requires all states and all countries to agree what is and is not safe contentB. Enforcement across national borders will be inefficient unless the two countries are tightly coupled. Disagreements could be leveraged for political ends (just think of current conflicts).C. Unless a site that hosts user-generated content reviews every single item of content before allowing it to be published, it can&#x27;t guarantee that all content on its platform is safe. Therefore it would have to be marked unsafe unless a special provision is made here. reply codedokode 11 hours agorootparent> This requires all states and all countries to agree what is and is not safe contentThere could be an organization that reviews site content and moderation policies and assigns a rating, issuing a cryptographic signature to the website.> Enforcement across national borders will be inefficientThe rating will not be assigned to foreign-owned websites. Also, the enforcement is pretty efficient, there are police raids on sites with illegal content, and people get arrested for it.> Unless a site that hosts user-generated content reviews every single item of content before allowing it to be published, it can&#x27;t guarantee that all content on its platform is safe.Then it doesn&#x27;t get a \"safe\" rating. reply yedava 13 hours agoprevThere&#x27;s an easy solution to \"protecting\" children on the Internet. Let people and not companies decide what to view on a platform. Like Youtube can provide an option to whitelist channels or let users programmatically define rules on what kind of content they want in their feed. The downstream effect of this is that if some parents want to control what their kids see, they can just setup an account with rules on what content is allowed. Google doesn&#x27;t need to appoint itself as a nanny.But then, such super easy technological solutions come in the way of selling people to advertisers. So here we are. reply 93po 11 hours agoparentI find it really sad that we no longer hold parents and communities responsible for just not. letting. their. kids. on. the. internet.Don&#x27;t give your kid a smart phone. Don&#x27;t let them use a computer unsupervised.Worried about them seeing shit from classmates? I think most schools these days don&#x27;t allow phones during school hours, so just pick your kid up immediately as school ends and at worst they&#x27;re gonna see 10 minutes of hardcore pornography per day but that&#x27;s a pretty ridiculous assumption.Alternatively, instill good values and behaviors in your kid so that they will choose to avoid this. reply avery17 11 hours agorootparentJust hide your kids in the basement. reply Smoosh 10 hours agorootparentI think the term is \"home schooling\". reply 2OEH8eoCRo0 11 hours agorootparentprevWhen there was one PC and one TV in the house it was a lot harder to hide what you were doing and parenting was easier. reply makeitdouble 9 hours agorootparentThe big part of it though: the PC was basically a novelty, at a lower importance than the TV.3 or more people could just take turn using it, no big deal. That ship has sailed. reply javajosh 11 hours agorootparentprevI find it really sad that we no longer hold parents and communities responsible for just not. letting. their. kids. smoke. cigarettes.Don&#x27;t give your kid a pack of smokes. Don&#x27;t let them buy things unsupervised.Worried about them seeing classmates smoke? I think most schools these days don&#x27;t allow smoking during school hours, so just pick your kid up immediately as school ends and at worst they&#x27;re gonna see 10 minutes of smoking per day but that&#x27;s a pretty ridiculous assumption.Alternatively, instill good values and behaviors in your kid so that they will choose to avoid smoking. reply makeitdouble 9 hours agorootparentprev> I find it really sad that we no longer hold parents and communities responsible for just not. letting. their. kids. on. the. internet.As a parent, I&#x27;m willing to take all the blame in the world for letting my kid on the internet if you&#x27;re willing to live with no internet for 10 years.Should be simple enough, right ?Oh, I&#x27;ll help you find what you need anytime, just tell me what to search for and I&#x27;ll print and send you the results whenever I have some spare time.Kids are supposed to become adults, and for that they need to actually interact with the actual workd, do adulty things and process the reality.It&#x27;s a delusion to think you can live in a school shaped faraday cage for 10+ years and just become a balanced and productive member of the society when the door unlocks at 18. reply 93po 9 hours agorootparentI did live with no internet for 10 years as a kid. I turned out perfectly fine and now have a successful career in software.If I had all my living expenses paid for, didn&#x27;t have to work, and basically just got to learn all day, I&#x27;d love to leave the internet behind for a decade. reply makeitdouble 6 hours agorootparent> If I had all my living expenses paid for, didn&#x27;t have to work, and basically just got to learn all day, I&#x27;d love to leave the internet behind for a decade.Of course not. You&#x27;re still working, keep a computer at work with all the filtering and surveillance coming with it (just like kids have internet access at school), but no access outside that. You pay your bills at the counter, buy everything in brick and mortar, short of asking me to order them for you online.This is how it feels to have a 12yo kid needing a new backpack, or looking for a new game, but they can&#x27;t just go to the store because brick and mortar stores just became ridiculously limited if they still even exist, and looking for it online means having your parents over your shoulders with very limited time and nowhere to ask online, because you&#x27;re not the age that is allowed to talk to people yet.PS: it&#x27;s a really good exercice to imagine leaving your teenage life now, with or without internet. The gap between what we remember being kids, and what it actually feels like right now is pretty eye opening. As adults we remodeled a lot of our life around the internet, but many still assume kids live in the 80&#x27;s worlds. reply extraduder_ire 12 hours agoparentprevI&#x27;m sad there&#x27;s no other sites I know of, certainly not mainstream ones, that do moderation like HN does. I&#x27;m glad to see the [dead] comments on here, so I know what&#x27;s current in not allowed and spam content.I think Scott Alexander wrote up a blogpost about the difference he saw between moderation and censorship. It&#x27;s similar to what you suggested. reply SanderNL 13 hours agoprevThis might be a threat, but I see weakness: Google is faltering. I haven&#x27;t been impressed by them - and especially what they produce (their research looks cool, but is not going places) - in years and they are holding on for dear life. Producing new and interesting products is apparently no longer a viable avenue. They literally cannot do anything else but try and survive by throwing out the toys so nobody can play.It&#x27;s a big boat and it takes a while to sink, but it will. reply sva_ 13 hours agoprevSo they&#x27;re really going for that web environment integrity bullshit? And they&#x27;re marketing it to politicians as &#x27;protecting children&#x27;? Absolute scumbags if that is the case. reply mycall 12 hours agoparentWill Microsoft Edge support it? reply teeray 11 hours agoprevI guarantee this will do nothing to achieve its stated goals. Kids are far more resourceful than adults give them credit for and have an abundance of time to apply to obstacles put in their way. Never underestimate a hard drive of torrented porn circulating on the bus. reply mcmoor 9 hours agoparentActually given recent reports on how kids these days only know how to tap at mobile and nothing else, we may need to stringent these restrictions just to teach them how to hack network like good old days. reply throwaway237289 13 hours agoprevThis is one of those things where it&#x27;s cold practicality. A company realizes the political headwinds and has decided that it&#x27;ll do its best with a bad hand. This is what leaders want? We&#x27;ll throw our support behind the least bad option.But articles like this complain about the company, instead of the politicians. What a load of crap. reply tikimcfee 13 hours agoparentAre we forgetting who is paying the politicians and writing their bills? reply SpaceManNabs 13 hours agorootparentGovernment has legislature and litigation focused on big tech right now on multiple fronts. reply sobkas 13 hours agorootparent> Government has legislature and litigation focused on big tech right now on multiple fronts.If corporation gets a fine that&#x27;s lower than their profits from breaking the law, then it&#x27;s not a punishment but government getting its cut. Prosecuting few low hanging fruits doesn&#x27;t make this administration any less neoliberal than previous ones, also remember that they will get prosecuted mostly for stealing from richer. reply tzs 12 hours agoprevIt is possible to do an age verification system with the following properties:1. The site that wants to verify your age learns that your age meets their criteria but does not learn anything else from the verification system except as noted in #2.2. The site that you present ID information to in order to prove your age does not learn what site the verification is for. The site in #1 will learn what site you presented ID to but not when you presented it.3. Someone who obtains all the records from both sites is not able to tell whether or not you visited the site in #1.It seems inevitable that age verification is going to become a requirements at many sites. Instead of just trying to stop that from happening those who want to maintain the ability to browse anonymously should probably also put some effort into trying to insure that if&#x2F;when it does happen sites are required to accept a system with those three properties. reply cmiles74 13 hours agoprevMaybe Google thinks that \"age assurance\" is a product they can sell? If it&#x27;s required by state or federal law, other companies will have to pay for the service. reply sva_ 13 hours agoparentIt seems like a bridge towards being able to pitch their Web Environment Integrity so that they can ensure the verification is not being tampered with. Coincidentally, that will also prove beneficial to their advertising business. Or maybe I&#x27;m overly cynical? reply extraduder_ire 12 hours agoparentprevThey already have to do it for age-gating youtube videos in some regions, like the EU. AFAIK, they want a CC number or phone number, neither of which really confirms your age. reply 23B1 13 hours agoparentprevNaturally yes. Glue this to WEI and you have a perfect funnel into the forthcoming verification wars. reply skybrian 13 hours agoprevSeems like this article spends more time telling you what to think than explaining what&#x27;s actually going on. Is there a better explanation? reply g-b-r 10 hours agoparentThe actual Google document is not very long or hard, just read that reply k310 8 hours agoprevI couldn’t see where to put this in the thread, so let me reply to the OP.SOME parents think that some literature, as in book bans, is harmful, and this, in the opinion of very many, including myself, is wrong.Kids deserve the opportunity to access books of all kinds if they are to grow.Let’s not forget about this, and let’s not think that violent and hateful material is “OK” for parents. Kids kill almost entirely by accident. Parents kill almost entirely by intent. (And drunk driving) reply gamesbrainiac 13 hours agoprevI might be a little dumb, but I genuinely found the article confusing. I have some questions nonetheless.What exactly is \"Age Assurance\"? Secondly, why would Age Assurance hinder new companies that want to create content platforms? reply darklycan51 13 hours agoprevGoogle has lost all semblance of good faith from me, they are just intent on making the web their ads-infested playground reply moffkalast 13 hours agoparentWhen a company has a motto of \"Don&#x27;t be evil\" and then changes it to something else... what are they thinking there exactly eh?Just saying. reply akomtu 11 hours agorootparentThese \"don&#x27;t be evil\" and \"do the right thing\" must have been taken from the well known buddhist story: \"When a disciple approached the buddha, he asked to explain buddhism in one verse; the buddha answered: stop doing evil, start doing good and clean your heart - that&#x27;s the religion of buddhas.\"However google here is that junkie who tattoed buddhists scriptures on his arms, but never bothered to live by them. He did the \"don&#x27;t do evil\" tattoo when he was devising a plan to rob a monastery. That was his inner self tried to stop him. When he decided to take hostages, he added \"learn to do good\". Shortly before he decided to build a torture chamber, his inner self made the final attempt and made him do the \"clean your heart\" tattoo. Corporations are soulless creatures, and can&#x27;t tell what&#x27;s good and what&#x27;s evil. reply firtoz 13 hours agoprevTrying to look at the bright side:Raised barriers of entry means there will be improvements for services which can \"help lift smaller companies up\". For example, for finance, AML&#x2F;KYC companies. Now I guess, for some internet services, \"age verification\" companies. This way age verification services may have some competition between each other and that can make it easier for people to do, and also cheaper for everyone to use. reply nathias 13 hours agoprevGoogle has been going down that path for a long time, they won&#x27;t stop until the web looks like cable tv, every part infested with adds with content reduced to target the lowest denominator among the greatest number of people. It should have been broken up in smaller companies 20 years ago. reply gxs 13 hours agoparentI’ve been avoiding them like the plague.Thinking back years, going back to my first Debian install in 2000, in retrospect this is where things were always heading.It’s the same path every other industry has gone down, to ultimately yield all power to a few large corporations.The main issue with this is that even if you have a group of people passionately defending against this, googles attempts will likely persist long after any one person or group is no longer able to work against.On a side note, this is part of the reason why corporations were never intended to be allowed to exist as long as they do today, they were supposed to come with an expiration date.Not sure dismantling a company like Google is the right play, it just amazes me how much foresight people had 100 years ago and that we still let a bunch of those things happen. reply narag 13 hours agoprevLet me quote Nietzsche.\"The newspaper reader says: this party will ruin itself if it makes errors like this. My higher politics says: a party which makes errors like this is already finished —it is no longer secure in its instincts.\" reply avery17 11 hours agoprevRepeat after me. Personal responsibility. reply dclowd9901 12 hours agoprevCan any modern journalist please just read the really quick AP style guidelines? It took me like 5 graphs before I actually understood what action google was taking. The initial bullshit hemming and hawing was excruciating. reply snek_case 11 hours agoparentI still don&#x27;t understand what exactly is being proposed. Can you summarize? reply jiveturkey 13 hours agoprev> the company has now made it clear that it has no intention of being a friend to the open internet any more.It did that awhile ago with amp.> just because something is a good idea for companies to do does not mean that it should be mandated by law.like forcing use of USB-C connectors. reply mistrial9 14 hours agopreva fundamental question is \"who, when and why can adults use the Internet while anonymous\" .. followed closely by \"who provides, checks and verifies identity including age\" reply shafoshaf 13 hours agoparentI feel like anonymity is just a band-aid. Ideally we would have freedom and accountability. If everyone knew that I watched porn but respected by right to do so, that&#x27;s the ideal. Without anonymity we would know that account is run by a bot or a foreign state. It goes to how homosexuals were forced to be underground for so many years (and still today for many) and if they were out of sight they were out of mind. That isn&#x27;t equality if you have to have a really good way to hide.However, the penchant for people to be complete assholes to each other over things that are none of their business is real and a huge problem. So, yes it makes sense to be able to hide but, sadly, it doesn&#x27;t advance the social contract. reply abvdasker 13 hours agorootparentAnonymity is not a band-aid, but a fundamental component of privacy. Privacy is an important right which people often take for granted and its erosion makes people less free in a multitude of ways. Even the expectation that one might be surveilled can change a person&#x27;s behavior in profound ways (Foucault&#x27;s panopticon has never been more relevant).It comes down to the fact that other people may do things which we find distasteful or even offensive. You will never, ever be able to get a large group of people to conform to standards of personal behavior to the extent that this is not true, and so privacy becomes a necessity. But as long as those things aren&#x27;t causing real harm then they simply aren&#x27;t my business or that of the government.In my opinion the only worthwhile discussion when it comes to privacy is what constitutes harm and whether a given harm is possible to prevent without causing even greater harm through restriction of privacy and anonymity. In many cases when it comes to safety and privacy, the cure can be worse than the disease. reply raxxorraxor 1 hour agorootparentprevThat is not possible though. You cannot refrain from being judged and if you are honest you are also judging others. This is true for clothing and much more so for more intimate proclivities. Also, a certain amount of inhibition might be quite healthy.Additionally I don&#x27;t want to share even trivial stuff like interest in music or movies with everyone. If I do, it is on my own terms. I don&#x27;t want to share who is in my social circle either. My social media presence is highly curated and shallow for professional reasons (although by being shallow it doesn&#x27;t contrast other online presences too much).I hide stuff and that is completely fine and something I want to do. If people are interested, they can ask me.Anonymity isn&#x27;t just a band-aid here, it is a tool and I value it quite highly. Nothing to do with equality or advancing rights. reply toolz 13 hours agorootparentprevIn an ideal world we respect that what other people do is largely none of our business. I don&#x27;t agree with any ideal that thinks everyone should agree on some set of rules and we respect anything that doesn&#x27;t violate those rules.I think an ideal society has rich disagreement and a wide diversity of thoughts and opinions. With that diversity comes conflict which provides us all with opportunities to more deeply reflect on our own beliefs. reply JohnFen 12 hours agorootparentprev> If everyone knew that I watched porn but respected by right to do so, that&#x27;s the ideal.I disagree completely. I think that privacy is an essential component of having a free society. It&#x27;s not really about porn. reply dogleash 13 hours agorootparentprev> That isn&#x27;t equality if you have to have a really good way to hide.It&#x27;s still better that they were forced to hide, than a world where they couldn&#x27;t hide.> I feel like anonymity is just a band-aid.The norms of a society are nether stable over time nor across members at a single point in time.There is no stasis point, there is no right answer. There is only entropy. reply hooverd 10 hours agorootparentprevThe difference is people will still be complete assholes but they also know where you work. reply cvccvroomvroom 13 hours agoprevThink of the children! Fuck Google and their inverted totalitarianism imposing regulator capture and Big Mommy. reply oh_sigh 13 hours agoprevJust a general note, but everyone has their own view of what is unconstitutional, but really there are only 9 people with opinions that really matter. reply raxxorraxor 26 minutes agoparentIf a set of basic laws can only be interpreted by professional judges, the laws are more or less useless. On the contrary basic laws should be a foundation of a social contract that hopefully most within a society agree upon. reply 23B1 13 hours agoparentprevWhile I appreciate the spirit of your comment, that&#x27;s actually not true! There&#x27;s an (admittedly winding and untested) route for The People to alter the constitution called an Article V Convention or &#x27;convention of states&#x27;:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Convention_to_propose_amendmen...I&#x27;m posting because a lot of people are unaware of this part of the American constitution, similar to how jury nullification is something &#x27;they&#x27; don&#x27;t want you to know about ;-) reply coding123 14 hours agoprevWhat are we protecting our kids from?If we coddle people too much we risk people not... talking to other people. That&#x27;s already happening. Maybe instead of tech the world should be focused on physical things, like new innovations in building technology. We have so many homeless people, in my opinion, because we&#x27;re constantly focusing our attention on tech - which is a skill that a smaller percentage of the population has a brain for.The trades need to come back, we need to beat SA in projects like \"The Line\" - and in the words of Joshua Weissman - But Better.We&#x27;re at risk for just continued class divisions and potentially a war because we&#x27;re turning a bunch of coddled spoiled kids into a millionaires that are being looked at with massive disdain.Maybe the internet should move back to being a background resource, not a precursor to ADHD. reply mattstir 13 hours agoparentThere are certainly things that may be worth trying to protect children from online, like extremely targeted advertising that gets presented like legitimate content. Kids won&#x27;t necessarily be able to differentiate between the two, and it&#x27;s definitely not okay for companies to be tracking and profiling them like they do (but pretend to not be doing). A great example is reddit or instagram using the same algorithms that recommend content in their main feeds to also inject advertising. They&#x27;ll claim all of that data collection is just to provide a \"better experience\", but advertising companies love it.I&#x27;m really not sure what else you&#x27;re on about though. reply autoexec 3 hours agorootparent> There are certainly things that may be worth trying to protect children from online, like extremely targeted advertising that gets presented like legitimate content.It&#x27;s better to block targeted advertising from adults too. Blocking ads for everyone in the household is only going to benefit everyone. reply falcolas 13 hours agorootparentprev> There are certainly things that may be worth trying to protect children from online, like extremely targeted advertising that gets presented like legitimate content.I&#x27;m reminded strongly of cartoons which were created to sell toys. Still happens today. reply ipaddr 13 hours agorootparentprevKids already see tons of ads at movies, billboards, clothes people wear. Those superhero movies are made to sell toys and games. Stores are setup for kids to pressure parents.Why are targeted ads the thing we should fear for our kids? Are we inventing problems? Kid watches superman movie and is shown an ad for batman vs here is an ad for a random movie. Adults and tracking is bigger issue, kids don&#x27;t have positions in society to lose or secrets to keep or money to lose.What are we fooling ourselves into believing we are protecting again? reply mattstir 12 hours agorootparentThis sort of willful ignorance is disparaging to see. Surely you must see a difference between an ad block that&#x27;s clearly differentiated from the main program (ads before a movie plays, ad breaks during TV) and an endless feed of content that has no clear delineation between &#x27;content&#x27; and &#x27;product sponsership&#x27;. You might well be fine believing that billboards are the pinnacle of advertising, but there&#x27;s been about 160 years worth of progress in the ad space since those were the big thing.> Why are targeted ads the thing we should fear for our kids?Again, you seem to be either defensive or intentionally misconstruing the point. These types of problems shouldn&#x27;t invoke fear in people. I think you&#x27;re getting yourself too mixed up in the idea that [X modern issue] is fearmongering and that nothing bad ever happens.Kids are dumb and impressionable. If they spend 8 hours a day scrolling through an endless feed of cool posts featuring cool products being worn &#x2F; used by cool people, they will absolutely get attached to the idea that it&#x27;s normal and expected to have that thing. That&#x27;s manipulative and disgusting marketing, and it&#x27;s genuinely worrying that you don&#x27;t seem to care at all.> Kid watches superman movie and is shown an ad for batman vs here is an ad for a random movieAgain, intentionally misconstruing the idea... it&#x27;s more like \"kid spends 2&#x2F;3 of their time awake being mined for data and having every interaction across every platform cross-correlated to ensure that *a company* can profit off of them\". I suppose that&#x27;s perfectly healthy and normal to you, that a company can know more about a child and exactly what they do and what they like than any human does. reply mcpackieh 12 hours agorootparentprevAd targeting identifies a lonely person with self esteem issues. Tells them that they&#x27;ll be more popular and attractive if they consume product. They consume product and of course it doesn&#x27;t actually help, but more advertisements are already lined up to explain that they&#x27;re still feeling bad because they need to consume even more product. The ads show unrealistically happy and attractive people, to reinforce the self esteem issues and encourage the consumption of even more product.This is a standard business practice for the advertising and marketing industry. It&#x27;s evil. reply Tostino 13 hours agoparentprevArguing we should spend more on housing the homeless, fine. But spending more resources on vanity projects like \"the line\"??? You lost me. reply coding123 6 hours agorootparentI mean we can spend billions building the next facebook, or billions building something that will last, is physical - incredible.Now I don&#x27;t know if \"the line\" will ever exist, but if it does get built, it will likely be the most impressive thing to exist.If we compete, not only are we making homes, but an entirely new set of jobs for probably hundreds of thousands for potentially 20 years. Past that? Do the next build.We&#x27;ve gotten to this amazing place with computers and... then we just figure out a billion ways we can flip bits and strings in a database endlessly and call it work... bleh.We need to move on from Tech. reply dcow 13 hours agoparentprevI imagine this technology would be deployed to prevent kids from visiting porn, drugs & alcohol, etc. sites. Which TBH seems fine, we already ID people at bars and adult shops. reply JohnMakin 13 hours agorootparentThe onus at that point is on the business to verify your age say, at the bar. This is like requiring every single person who gets into a car to prove they are of age enough to visit such establishments, regardless of whether or not they are even going to them. reply hiatus 13 hours agorootparentWe have the technology, might as well make the cars verify that we have a valid license to drive before we can use them. reply falcolas 13 hours agorootparentThere are limits to where a valid driver&#x27;s license is required to drive a vehicle though. For example, offroad or on private property. You can even cross a road without having to have a drivers license. reply ipaddr 13 hours agorootparentprevLets only allow the car to drive to government approved locations after requiring a government permit with approved route for the trip. reply gs17 12 hours agorootparentIt would cut down on traffic! reply ipaddr 13 hours agorootparentprevWe don&#x27;t ID everyone only those who are borderline age wise. This would be everyone and remove privacy for all. reply JohnFen 12 hours agorootparentIn my area, it&#x27;s been an increasing trend that establishments that must verify age are doing so for all customers, even those who are obviously old enough.And I don&#x27;t have a problem with that. I&#x27;d have a problem if the age verification leaves a record in a database or is performed by a central entity rather than the employees of the establishment. reply archgoon 13 hours agorootparentprevBut we aren&#x27;t writing down people&#x27;s IDs when they enter a bar&#x2F;adult shops and sending it to a database that can later be queried by governments. reply InitialLastName 13 hours agorootparentThere are a meaningful number of event security providers who are attempting to do exactly that.They would also very much like you to install their venue app on your phone so they can track your location as you approach and exit the venue. reply codedokode 13 hours agorootparentprevI have a better plan which 100% protects kids but doesn&#x27;t require any verification: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37991197 reply _Algernon_ 13 hours agorootparentSpamming this everywhere in this thread does nothing to strengthen your argument (which has a number of weaknesses you&#x27;ve neglected to address). reply Belopolye 13 hours agoprevIt looks like the direction we’re headed is a two-tiered Internet. The first layer will require your real world identity (more than simply your ISP knowing who you are because of billing) to access, post, download, upload, etc, which I suppose will first be required to access banking, social networks, etc, destroying anonymity.The second will be more or less what we have now, but my fear is that access to this layer will be restricted further and further until it goes the way of Usenet and ISPs either willingly (or by regulation) turn off access to it. reply poisonborz 13 hours agoparentIt will become more like how it already is: the \"\"open\"\" internet with a need for registration&#x2F;real names everywhere, and the \"\"dark\"\" net with zero rules and the usual cat and mouse of police raids&#x2F;honeypots vs technical advancements in obfuscation. And seeing how this repeated so many times in tech and other industries, I think that&#x27;s the best we as humanity can do for the near future. reply JohnFen 13 hours agoparentprevThe first layer is unacceptable to me, so I guess I just wouldn&#x27;t access that at all. If the second layer goes, then that&#x27;s the whole game. The internet would be closed off to me entirely. reply theturtletalks 13 hours agorootparentI always joked with my friend that if the internet was created today, it would be a walled garden. Jokes on me cause that&#x27;s happening anyways. reply pixl97 12 hours agorootparentMaybe the joke was always on us techies thinking that the wild west internet could survive in this world?I mean the internet at first got away being what it was, because it was small, and because it didn&#x27;t affect outside of the internet that much.But now that the net is big, and connected to &#x27;real things&#x27; that suddenly being a degree of separation from the \"Genocide power hour forum\" is actually quite unpleasant and has many risks. Businesses will gladly move to some walled garden to avoid this, they don&#x27;t care about freedom, they care about profit. And while your aunt and uncle say they care about freedom, they mean \"Freedom to be exactly like them and any other degenerates get nailed to a cross\".Your average voter will get tired of the crime and harassment online will vote in the next authoritarian that says they have an simple easy solution for the internet problem. Us techies will say \"but the authoritarian is wrong, this isn&#x27;t simple or easy\". The authoritarian knowing how propaganda works will tell the lie twice as big and twice as often and win the next election. reply JohnFen 11 hours agorootparent> Businesses will gladly move to some walled garden to avoid thisI support this entirely. One of the largest reasons why the internet is getting much worse with time is that businesses want to use it. Getting them off the open internet would eliminate a fair amount of nastiness and might return some of what we&#x27;ve lost. reply fidotron 12 hours agoparentprevHonestly I think we&#x27;re close to there already, with the Play Store and App Store leading the charge.The giveaway is the amount of traffic generated by users in the second category is much lower than it used to be, while the first category grows. Just look at how much everyone here complains about their inability to find interesting things in this second tier today. Now that the VC money isn&#x27;t going to prop up free stuff, or the ecosystem of dev tools to support free stuff, it&#x27;s hard to see how the second lives on.What will be left is P2P, torrents, and psyops masquerading as organic meme wars, everything else will evaporate or migrate to the first tier. reply thomastjeffery 13 hours agoparentprevAll of this hinges on the notion that moderation and curation must be done by a centralized party, not by the users themselves.The foundation of this bullshit idea is intellectual property. Let&#x27;s just go ahead and get rid of that, and let the people manage their network. reply nonrandomstring 10 hours agorootparentThis comment caught my eye more than all the others.As I get older and live through this amazing ride, I am increasingly of the mind that the total abolition of \"intellectual property\" in all its manifest forms would not only be the saving move for humanity, but that it&#x27;s more or less inevitable.Climate change is going to put so much pressure on us to innovate very rapidly, and patents and copyright now form such obvious impediments, nobody except Disney is going to give a care about enforcing intellectual property within 20 years. These are the last desperate days of the old order trying to bury its spoils through centralisation and locking-down.As an author, coder, inventor and creator I also see that generative \"AI\" - or rather the emergence of a portable semiotic&#x2F;literary digital collective consciousness - will spell the end for ego-driven protection rackets that make us say \"Think of the creators who need food!\"New tools will provide such abundance to creativity. We will still create of course, and enjoy it very much.\"The Internet\" is such a fascinating story. Just at the point when we think all is lost, quite by surprise, and suddenly, we win. So in the 22nd century I imagine we will look back on the days when one couldn&#x27;t freely share any digital artifact as we look back on slavery and witch hunting today.And in that richness and abundance people will stop seeking out what is harmful to them to nurse their empty, depressive desperation and hopelessness. And those that profit from pushing misery at others will have no place the table.I am only sad I won&#x27;t get to live in that time - but watching the death of such rotten conceits as \"intellectual property\" and the \"advertising industry\" will be satisfaction enough. reply Belopolye 12 hours agorootparentprevAgree with your sentiment, but I see the future I expect at the confluence of a lot of different parties&#x2F;positions (domestic politics, geopolitics, advertising, anti-piracy, “save the children,” anti-terrorism, etc) who have the money, vested interest, and ideological motivation to accomplish this.For myself, if this plays out as I’ve described it just means it’s time to…go read a book or something, I don’t know. reply thomastjeffery 12 hours agorootparent> I expect at the confluence of a lot of different parties&#x2F;positions (domestic politics, geopolitics, advertising, anti-piracy, “save the children,” anti-terrorism, etc) who have the money, vested interest, and ideological motivation to accomplish this.That is their leverage, yes, but the tool at hand is copyright. reply nonameiguess 12 hours agoparentprevPossibly where we&#x27;re headed is an expansion of the first layer, but it already exists. You currently need to use your real identity to do things like access banking and file taxes. You also need to provide your age to access services like porn and gambling.The complaint here isn&#x27;t the use of age and&#x2F;or identity verification for anything at all. It&#x27;s using it to access social media. There isn&#x27;t much in the way of a good legal reason to do this and previous attempts have seemingly been shut down by courts. Children are currently allowed to enter and occupy congregation spaces also used by adults, i.e. churches, parks, community centers, libraries. Private clubs are allowed to ban children if they want to, but have never been legally required to unless they specifically provide adult services like strippers and booze.This also, of course, seems way less workable than real-world versions. At least in person, if a child presents a fake ID, a bouncer can sanity check that they look like the photo and look like they might actually be an adult. 12 year-olds with pocket change to spare can pretty trivially pay a poor person who doesn&#x27;t give a shit to scan their retinas in Sam Altman&#x27;s world coin face reader and hand over their private keys and now they&#x27;ve got a fake ID that no website can call bullshit on. Even without that, a kid can easily get an older sibling or friend to share a login, just like my wife&#x27;s younger sister used to borrow my wife&#x27;s ID to get into clubs and bars or I used to buy cigarettes and liquor for my friends because I had the earliest birthday.Policymakers don&#x27;t want to admit it, but it is ultimately up to parents to police what their children do on the Internet. There is no automated system that can&#x27;t be beaten until they figure out a way to hook up a blood prick to your computer and check telomere length to estimate your genetic age, assuming we don&#x27;t figure out how to reverse that, and even that can&#x27;t prevent a child from shoulder-surfing an adult. reply hooverd 10 hours agoparentprevTechies will post about how draconian that North Korean Ullim tablet is and then try to recreate it at home, for the children of course. reply gjsman-1000 13 hours agoparentprevI think there are actually several reasons why this is a likely direction:1. Children (duh, this article)2. Misinformation (accountability, no astroturfing)3. Misinformation Robots (age verifying robots is a difficult task)4. Malicious Robots (do you need Cloudflare if you have an Age ID Firewall?)5. Scraping Robots (nothing prevents scraping like knowing who to sue...)6. Hackers (nothing prevents hacking like knowing who to sue, even if it&#x27;s only 80% of the time...)7. AI Use &#x2F; Abuse (anonymity is a dangerous thing with AI)Etc. To be honest, if I was an Age ID verification company, I&#x27;d be calling around to my competition to figure out how to develop some kind of interoperability standard; in the hopes that would make age-restricted services much more convenient and thus widespread. Now if they could get Billing integrated into the system as well, then we&#x27;re cooking with gas. reply Belopolye 13 hours agorootparent8. Industry is desperate to destroy piracy.On top of all of your reasons. reply hooverd 10 hours agorootparentIndustry is desperate to destroy general purpose computing. reply gjsman-1000 13 hours agorootparentprevTragically, it works both ways.8. Destroy privacy of anonymous users.9. Increase privacy by preventing reposting (by robots or trolls) of information that a court has ordered suppressed. (Example from the near future: AI-generated revenge porn.)10. Increase privacy by preventing companies like Clearview AI from legally getting away with murder of privacy.Edit for Belopolye&#x27;s response below: Very good point; but that would require all websites to be in on it and not just a partial implementation. But the movie and video game industries would love that... reply Belopolye 13 hours agorootparentAutocorrect got me- I meant to type piracy. Updated my comment :) reply codedokode 13 hours agoparentprevNo I have a better plan which guarantees full 100% safety for children but doesn&#x27;t require verification or identification: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37991197 reply belthesar 12 hours agorootparentQuestions I have to this proposal:* A site must be certified by some board in order to be accessible. At what level is a site certified? Root level? Page level? Individual content item.* A site hosts user generated content. This could be as small as comments on an article, or as large as YouTube. How is the site certified? If each piece of content must be certified, who assumes responsibility for certification?* A site is certified as appropriate for all ages. The owner of the site then puts content that would have caused to to fail certification. At what interval is a site expected to recertify? What is the ramification for certification and then hosting of objectionable content?* You have a process that is onerous for site administrators to comply with in order to host content for children. What incentive is for them to comply vs. not host a site that requires certification?* As a parent, you install a compliant operating system that enforces this system. Sites comply with the program and it works without exception. Kids talk, as they do, and share how to get around this system by using a Linux live environment to boot into an OS that does not enforce the parental control header. How do you prevent this?* As a parent, you install a compliant operating system that enforces this system. Your kid either does not know how, or is prevented from circumventing these access controls. They have one or more friends that have computers that are not blocked from accessing this content. How do you prevent them from accessing content in this system? reply codedokode 12 hours agorootparent> A site must be certified by some board in order to be accessible. At what level is a site certified? Root level? Page level? Individual content item.There could be an organization that verifies that the owner and operator of the site are not foreign (so they can be taken to court if needed), reviews the content policy and moderation policy to ensure that no unsafe content can be published, and issues a cryptographic signature to the website. The website displays a signature in HTTP headers.> How is the site certified? If each piece of content must be certified, who assumes responsibility for certification?There should be moderation policy guaranteering safety, for example, all comments must be reviewed by moderators.> The owner of the site then puts content that would have caused to to fail certificationThen they can get into jail if they do it intentionally.> What incentive is for them to comply vs. not host a site that requires certification?They can have paid content or show ads.> by using a Linux live environment to boot into an OS that does not enforce the parental control header.Requirement to install Linux will stop majority of children. reply conception 13 hours agorootparentprevThe problem with your solution is laws&#x2F;regulations are not really enforceable internationally. reply throwanem 13 hours agorootparentThe other problem with that solution is that it&#x27;s impossible. Sounds great aside from that implementation detail, though! reply codedokode 13 hours agorootparentWhat exactly is impossible? reply throwanem 12 hours agorootparentYou&#x27;re assuming perfect authorization to flip the \"safe mode\" switch. reply codedokode 13 hours agorootparentprevDo not allow accessing foreign websites (from countries which did not join the convention) when \"safe content\" setting is active. reply superq 12 hours agorootparentHow long before \"safe content\" becomes the default?.. and then the requirement.. and then the law?I&#x27;ll take my Internet unsafe, thank you very much. reply afavour 13 hours agorootparentprevHow do you define “foreign website”? reply codedokode 13 hours agorootparentA website which is hosted (physically located) in a country not participating in Safe Content Marking Agreement or owner of which is anonymous or is from a foreign country.Basically any site whose owner or operator you cannot put to jail. reply mschuster91 13 hours agorootparentprevThey are, see the international cooperations on CSAM. Literally every state with a barely functioning government agrees that this kind of conduct is inacceptable. reply conception 12 hours agorootparentOh, so there&#x27;s no CSAM on the internet? Cool. It works! reply thomastjeffery 13 hours agorootparentprevInstead of expecting every web service to present the appropriate headers, let&#x27;s decentralize this work: Create a web of trust where users authoritatively declare content to be safe&#x2F;unsafe&#x2F;nsfw&#x2F;etc. Then just restrict your browser to the curated web of your choice. reply Terr_ 12 hours agorootparentprevI half-agree in that I&#x27;d like to see the inverse: Devices support a parental-lock, and that setting ensures the device sends metadata outward.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37330234 reply codedokode 11 hours agorootparentThis means that every site in the world must interpret the headers, while with my proposal sites need to opt-in (and pass certification) to be available on children&#x27;s devices. reply Belopolye 13 hours agorootparentprevI don’t agree with what I expect. reply Spooky23 13 hours agoparentprevWell TBH the open internet provided a ton of benefit, but has metastasized into a force of misery and evil.The near collapse of democracy in the United States, the various nasty impacts of social media, the death of professional journalism, the emergence of automated propaganda bots, etc are all negative impacts of open internet that are destroying society.This may not be the answer, but neither is that status quo. We can&#x27;t go back to 2003 or 1993.The older people here live like it&#x27;s 2003. It&#x27;s not. HN is a throwback to those days, but we live in a world shaped by anonymous actors performing in bad faith. reply raxxorraxor 21 minutes agorootparent> a force of misery and evil.My internet happy place is pretty dandy. Trust in media and democracy wasn&#x27;t destroyed by the internet, on the contrary, it was destroyed by people that didn&#x27;t want to accept different perspectives anymore, tried to silence others and consolidate the content on previously free internet platforms. reply chmod775 13 hours agorootparentprev> The near collapse of democracy in the United States, the various nasty impacts of social media, the death of professional journalism, the emergence of automated propaganda bots, etc are all negative impacts of open internet that are destroying society.So which of these is a walled-garden internet going to fix?Actually which of these are even a consequence of the internet being open in the first place?Pretty sure the answer to both is: none. These (perceived) issues are completely tangential and have absolutely nothing to do with the internet being open or closed.This sounds a lot to me like: \"People I don&#x27;t like are using this thing, so let&#x27;s ruin it for everyone.\"You&#x27;re still not going to like these people afterwards, nor are going to change them for the better by antagonizing everyone. reply tbrownaw 13 hours agorootparentprev> The near collapse of democracy in the United States,Banning anonymous speech would make it more dangerous to advocate against current policy, and speed up this collapse you&#x27;re worried about. reply peyton 12 hours agorootparentOctogenarians saved democracy by mailing everybody ballots with their names on them. Controlling distribution channels is probably more important than anonymity, which is why the article points to things like “impact assessments” and other blockers to free distribution. reply setr 13 hours agorootparentprevthe death of journalism has nothing to do with the open internet; it mostly has to do with their complete failure to find a functional online business model outside advertising. I&#x27;m pretty sure propaganda bots are largely a result of the death of journalism -- given that the trusted sources of information have become largely and obviously untrustworthy, then your only option is to go to the \"community\", where conspiracy and propaganda can reign freely.Social media is the only thing you could possibly blame on the open internet, but it has more to do with the same incentive problem as internet journalism -- advertising is money, and advertising needs \"engagement\". Social media, like journalism, needs propaganda and conspiracy and flamewars to thrive in order to exist. They have no real incentive to reduce it, except to make it sure it doesn&#x27;t cross the point where it goes a little too far and they start getting accused of \"causing the near collapse of democracy in the united states\" reply poisonborz 12 hours agorootparent> Social media, like journalism, needs propaganda and conspiracy and flamewars to thriveAbsolutely not, you are perhaps caught in the 2023 notion of social media. Early social sites thrived without any ads and company or celeb profiles even, just like early FB. Social media is and should be about common user interactions, most importantly the inner circle of acquaintances and then interest groups. Everything else was just made up to drive clicks and ad revenue. reply raxxorraxor 16 minutes agorootparentDepends what you describe as social media. Forums and boards are different than Twitter or TikTok. Usually social media is associated with wanting to present yourself while other platforms are focused around topics. One type might leak into the other, but usually the behavior and content is vastly different.I keep my opinion that Instagram is for idiots for example. Yes, probably an ignorant perspective and it isn&#x27;t exclusively the case, but an opinion I can very much live with. reply dogleash 12 hours agorootparentprev> has metastasized into a force of misery and evil.Has much is metastasizing, and how much is it just perceived to have done so because of failing media literacy about the internet? Basic late 90s&#x2F;early 2000s internet safety was to assume untrustworthyness for everything. And regardless of how well a source proves itself, you keep giving it the side-eye.But, where would people learn that media literacy today? The people and institutions that are branded as \"serious\" in our society don&#x27;t have any financial incentive to want their audience to know critical reading&#x2F;listening. Quite the opposite actually. reply nradov 13 hours agorootparentprevThe status quo is acceptable. Some of the younger people here alarmists. Not every problem needs to be solved. Negative impacts can be tolerated. reply akomtu 12 hours agorootparentprevIt&#x27;s the other way around: Internet was a tool to share knowledge and now it&#x27;s turning into a tool of oppression. reply hooverd 10 hours agorootparentprevThe open internet was fine, it&#x27;s all the centralized orgs that done exactly that. reply mcpackieh 13 hours agorootparentprev> The near collapse of democracy in the United StatesSo you propose a controlled demolition? That&#x27;s what abolishing the right or opportunity to speak anonymously amounts to. Professional journalists don&#x27;t need to be protected from anonymous jeers, if anything is killing their industry it&#x27;s their failure to monetize and maybe you can blame adblockers for that, but not anonymous speech. And frankly, professional journalists have always predominantly been the mouthpieces of wealthy. Need I remind you that professional journalists working for the likes of William Randolph Hearst cynically provoked the Spanish-American War for profit? The glory days of journalism are an illusion that appears when you look back at the past through rose-tinted glasses. Whatever the answer is, it isn&#x27;t to silence those who already have the least power, those who can only speak anonymously without corporate apparatuses to back them up. reply gjsman-1000 13 hours agoprevHere&#x27;s a better compromise, if we must find a compromise, that Google won&#x27;t be so in favor of:\"No parent, or guardian, shall permit their children under the age of 13, to possess or easily have access to any device, which provides unfiltered and unrestricted access to the internet in such a way that said parent, or guardian, is not fully aware of each and every website that the child may access with said device.\"[As for anyone like, what about the vulnerable? There&#x27;s this thing called a library, and don&#x27;t tell me public schools don&#x27;t have resources.] reply flenserboy 13 hours agoparentAh, yes, the reintroduction of 3-channel TV. Progress! reply jrockway 13 hours agoprev [–] I&#x27;m fine with age assurance. If you&#x27;re under 13, you go to the post office to prove that you&#x27;re under 13, they digitally sign some token on your phone, and then your access is restricted according to the law. If you are an adult who wishes to remain anonymous, take no action. Problem solved!It would be interesting to see how the reverse of this system is implemented; adults must prove they&#x27;re adults before being able to access certain websites. What technical measures would allow this? Information can leak in HTTP requests and responses, i.e. \"curl -H &#x27;User-Agent: help me i am trapped at the bottom of the ocean&#x27; https:&#x2F;&#x2F;example.com\" before any authentication has taken place. Is an adult allowed to send that request to a child? Probably not! This would mean the system has to be implemented at a lower level layer; websites would only be served on private IP ranges, and you&#x27;d have to setup an IPSec tunnel or similar first to prevent that out-of-band leakage. (You can get more absurd; everyone has a &#x2F;64 of IPv6 space for themselves, so you can use your source address as a form of intentional information leakage; 1:2:3:4::1234 is a 1, 1:2:3:4::4321 is a 0. This means that, legally, you would have to be careful about how you do the TCP 3 way handshake, because, as a middlebox, you can&#x27;t prove that sending a SYN in reply to a SYN is not actually someone requesting adult content.)All in all, this seems technically impossible to implement, prone to making identity theft even more lucrative than it already is (don&#x27;t reuse your ID.me password anywhere else, or some kid is going to use it to cheat in a video game and get you sent to jail a la South Korea), and unconstitutional (\"prior restraint\"). reply johncolanduoni 12 hours agoparent [–] I think you&#x27;re overthinking this. You can just put the age-restricted portion of the website (which for some websites might be 99% of their content, but I think that&#x27;s fine) behind a login page that verifies whatever age token you come up with. If the only information you can send to the website is your credentials, and the website can&#x27;t send any \"unsuitable\" information to you, I&#x27;m not sure what the issue with allowing HTTP access is. reply jrockway 6 hours agorootparent [–] Well, the government has to take action against you, the site operator, if you aren&#x27;t enforcing the rules correctly. That means they have to think of every possible way to monitor the traffic, both in-band and out-of-band. They then have to do this for every site on the Internet. (Or sure, just selectively enforce it against whoever X says is a",
    "originSummary": [
      "Google has established a new policy framework aimed at protecting children online, introducing steps like age verification and enhanced parental supervision.",
      "Critics state this policy might adversely affect smaller businesses and restrict internet freedom, reflecting concerns about corporate motivations and potential political influences.",
      "The conversation also extends to topics like NSFW content, governmental regulation, and censoring on social media, while other tech news reports on a trademark lawsuit settlement, a fine reversal, and plans for citywide broadband."
    ],
    "commentSummary": [
      "The debate details topics associated with web regulation and child safety, highlighting concerns surrounding potentially censorious actions of Google through secure browsers.",
      "Suggestions to protect children online include the initiation of a \"safe content\" setting on operating systems, mandation of parental internet filters, and verification of children's website safety.",
      "Notable challenges in implementing these solutions are also raised, encompassing aspects relating to age verification measures, website certifications, and balancing technology with other societal factors."
    ],
    "points": 338,
    "commentCount": 238,
    "retryCount": 0,
    "time": 1698087495
  },
  {
    "id": 37993575,
    "title": "SumatraPDF Reader",
    "originLink": "https://github.com/sumatrapdfreader/sumatrapdf",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up sumatrapdfreader / sumatrapdf Public Notifications Fork 1.6k Star 11.3k Code Issues 517 Pull requests Discussions Actions Security Insights sumatrapdfreader/sumatrapdf master 8 branches 27 tags Go to file Code Latest commit kjk add and use AllocArrayTemp() ad67e64 Git stats 14,785 commits Files Type Name Latest commit message Commit time .github update github actions to latest versions; downgrade builds to use fre… .vscode update c_cpp_properties.json appx start on appx bin new way embedding fonts that supports arm64 (for #2566) do remember invert colors setting in advanced settings docs annotation can only be selected if edit annotations window is opened (f… ext update mujs, lcms2, zlib gfx add epub / cbx specific icons mupdf update mupdf packages/Microsoft.Web.WebView2.1.0.992.28 add WebView SDK src add and use AllocArrayTemp() tools update translations translations update translations vs2022 update mupdf .clang-format remove no longer used MenuDef.flags .clang-tidy clang-tidy: fix some readability-make-member-function-const .editorconfig refactor LabelWithCloseWnd .gitattributes disable git's LF normalization .gitignore add help / Keyboard Shortcuts (for #3768) AUTHORS website: cloudflare pages doesn't deal with HTML files with '.' in th… BACKERS.md update backers COPYING use correct license file COPYING.BSD allow seeking in Rar file (and add IStream support) TRANSLATORS Update TRANSLATORS with Corsican asan.supp add asan.supp (even though they don't seem to work) doit.bat add separate x32_xp target drmem-sup.txt add -drmem to run drmemory on rel 64 build to find memory leaks go.work remove toolchain from go.work for github actions go.work.sum update go deps premake5.files.lua update mupdf premake5.lua remove un-necessary DELAYLOAD:version.dll (fixes #3772) readme.md Fixed build status badge code in readme.md readme.md SumatraPDF Reader SumatraPDF is a multi-format (PDF, EPUB, MOBI, CBZ, CBR, FB2, CHM, XPS, DjVu) reader for Windows under (A)GPLv3 license, with some code under BSD license (see AUTHORS). More information: website manual developer information About SumatraPDF reader www.sumatrapdfreader.org Topics c pdf c-plus-plus pdf-viewer win32 Resources Readme License GPL-3.0, Unknown licenses found Activity Stars 11.3k stars Watchers 311 watching Forks 1.6k forks Report repository Releases 12 3.5 release Latest + 11 releases Packages No packages published Contributors 59 + 48 contributors Languages C 60.1% C++ 18.2% Assembly 12.3% Python 2.1% Makefile 1.4% Hack 1.2% Other 4.7% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37993575",
    "commentBody": "SumatraPDF ReaderHacker NewspastloginSumatraPDF Reader (github.com/sumatrapdfreader) 330 points by quyleanh 9 hours ago| hidepastfavorite148 comments Helmut10001 1 hour agoSumatraPDF is among the OSS PDF tools I use.Since Adobe is pushing a more aggressive stance for monetization of Acrobat, I am trying to replace selected PDF workflows with OSS. Here are some of the tools I use. qpdf removing passwords, unlocking PDFs, conversion install in WSL with apt-get install qpdf remove password with qpdf --decrypt --password=\"\" input.pdf output.pdf PDF4QT - Open Source PDF Editing Deleting, Sorting, Extracting Pages Currently, no choco release available, must be installed manually from PDF4QT&#x2F;releases Inkscape, LibreOffice Draw editing PDFs, adding text Mupdf Command line tool and Python package for parsing, filling forms, adding text SumatraPDF Viewing of PDFs pdfplumber Awesome python package to extract tables from PDFs into data pipelines. Use with Jupyter Lab reply mkl 27 minutes agoparentPDFTK and pdfjam are two other useful command line tools. I use PDFTK for merging PDFs, extracting&#x2F;deleting&#x2F;duplicating pages, and decompressing so I can extract and manipulate text&#x2F;data in raw PDF commands. I use pdfjam for n-up and adjusting page size and margins. reply dustypotato 1 hour agoparentprevFYI, you can use firefox for viewing,signing, and adding text to PDFs. You can also use it to remove password (just do print to PDF after unlocking it). reply beagle3 1 hour agorootparentAt least as of Firefox 109, support for non Latin languages was broken to the point of being completely unusable. reply Steve44 45 minutes agoparentprevFor extracting to tables I&#x27;ve been using http:&#x2F;&#x2F;tabula.technology&#x2F; for a couple of years. It seems to do a pretty good job even with some fairly complex tables and I&#x27;ve not had any problems with it. reply quyleanh 1 hour agoparentprevActually SumatraPDF is using MuPDF now. But there is some limitation on rendering PDF and eBook files. For example, formatting PDF file or displaying Unicode characters in epub file. reply commandersaki 7 hours agoprevGreat retrospective of SumatraPDF from the author: https:&#x2F;&#x2F;blog.kowalczyk.info&#x2F;article&#x2F;2f72237a4230410a888acbfc... . reply arp242 4 hours agoparentLessons learned from 15 years of SumatraPDF, an open source Windows app - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27968900 - Jul 2021 (133 comments)Lessons learned from 15 years of SumatraPDF, an open source Windows app (2021) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35065785 - Mar 2023 (173 comments) reply mvonballmo 1 hour agoparentprevFrom the retrospective.> And yet I do know that you can write complex, relatively bug free code without tests, because I did it.> I do know that you can write complex, relatively bug free code without anyone looking over your code, because I did it.> If no one uses your app then who cares if it crashes.> If many people use your app and it crashes, they’ll tell you and then you’ll fix it.Those four statements are contradictory. What they&#x27;re saying is not that you don&#x27;t need testing or code reviews, but that you can get your users to test for you.I figure the author probably does test their code (everybody tests, even if that just means running the app), but not rigorously or in a way that you could say gives one the security of regression tests.No-one worth discussing the issue with claims that it&#x27;s impossible to write complex code without automated testing. I&#x27;m a huge proponent of automated testing, and I wrote a relatively large, cross-platform renderer without a single automated test back in the late 90s&#x2F;early 00s ... it just took a long time, and I became increasingly terrified of making changes.Edited for formatting. reply zerr 2 hours agoparentprev> The problem is that Gtk is ugly, Qt is extremely bloated and WxWidgets barely works.Seems like the author didn&#x27;t look at cross-platform toolkits since 90s. reply pjerem 2 hours agorootparentWhat changed exactly ? Gtk is still ugly on anything that is not Linux, Qt is still bloated and wxWidgets, well here I don’t know. reply OvbiousError 2 hours agorootparentWhat does \"Qt is bloated\" even mean. It&#x27;s a big framework, split into separate libraries, you include only what you use. Qt is free (most parts are LGPL) and is developed by 100+ professional developers. The quality of the implementations, API and documentation is very very good.Discarding it out of hand by \"qt is bloated\" just feels disingenuous to me. You can add to that the fact that qml on the desktop if finally maturing into a viable alternative for widgets, and UI development with qml is such a breath of fresh air. reply LinAGKar 21 minutes agorootparentSumatra is know for being small, with the portable version currently being 15.3 MiB. QtCore and QtGui together is some 11 MiB (checking the DLLs used by KDE programs on Windows), so those alone would increase the size significantly. reply dspillett 39 minutes agorootparentprev> What does \"Qt is bloated\" even mean.From a user perspective I remember that being a big thing some time ago when people didn&#x27;t have anything already using Qt install did an “apt install” or “yum install” on something that did and saw the small tool they were wanting was going to drag half a desktop environment in with them as dependencies. The same could likely be said for GTK in reverse, I&#x27;m not sure what their relative sizes for similar features are these days.Some use bloated to mean the memory footprint. IIRC GTK has more of a reputation for eating RAM than Qt, but again maybe people notice a single Qt app using a lot of resource (that would be shared if running multiple apps against the same libs) when it is the only one they run.As you suggest, just stating that “ is bloated” without reference to some details of what is meant by that, sounds a bit like someone parroting old information and&#x2F;or group-think rather than having looked into it recently.Having said that the author has a minimal dependency stance in order to try to maintain a small footprint for the app (“I avoid unnecessary abstractions.” in the section about keeping things small) so any framework that isn&#x27;t little more than a cosmetic wrapper could legitimately be called more bloated than using nothing at all and talking more directly to the standard OS libs. Also in context (discussing why the product is not cross-platform and is never likely to be) this is not the only reason being given and probably not the most significant one (there may be significant selection of cross-platform issues beyond the UI framework).The key to a lot of what is in that document is the “It’s my project and I act like it” part. All too often we forget this very important side of things, especially with one-man or small-team projects, and people comment on project decisions as if using the product gives some automatic expectation that the creator will mould it around the needs&#x2F;wants of a given user or someone&#x27;s idea of “the community”. For an open source project the community has the option of forking the project or offering to fund the changes they want that aren&#x27;t otherwise on the creator&#x27;s roadmap (though obviously the larger the project, the less practical these options may be)… reply KRAKRISMOTT 2 hours agorootparentprevFlutter is decent, most of the browser&#x2F;Skia based UI kits are more consistent and made by people who have an appreciation for design and aesthetics. But I think Sumatra predates most, if not all of them. reply Sakos 1 hour agorootparent> appreciation for design and aestheticsSure, but not accessibility or UX design. There&#x27;s more to a good UI than looking pleasant. Far more. I wish we hadn&#x27;t unlearned that in the past decade, because Flutter and browser-based UI kits throw all of that out the window. reply whizzter 2 hours agorootparentprevHonestly, this is a guy who uses GDI, so most of the above options will feel bloated already when looking at the source tarball sizes.That said, has there been any fundamentally groundbreaking crossplatform classic UI toolkits released since the 90s? (IMGui is the only one that has seemed interesting but that&#x27;s specialized and not a general one really) reply jcparkyn 5 hours agoparentprevInteresting read. I was very surprised by the mention of adding editing features at the end. That sounds like a proverbial black hole of potential feature requests and \"bloat\". reply ivraatiems 3 hours agoprevWow, I just installed this for the first time and its performance blows both Adobe Reader (not an achievement) and Foxit (something of an achievement) out of the water! Nice work by these devs. And its install footprint is around 10% of those programs.What the hell is Adobe doing, I wonder, that makes their software so unbearably slow and painful to use? reply dagw 2 hours agoparentWhat the hell is Adobe doingProbably supporting 100% of the PDF spec. plus addressing all those obscure feature requests that 6 companies in this one very niche industry really really need. Sumatra is fantastic and basically the only PDF reader I use on Windows, but it does have maybe 10% of the features Adobe acrobat has. It is however the 10% that that basically everybody needs. reply Xerox9213 2 hours agorootparentAcrobat Pro is pretty incredible. One of my favourite features is the following: on a scanned PDF after performing OCR you can edit the text and it will match the font. As in, it will create a new font based on the characters it found in OCR.I’m a high school math teacher and scan dozens of textbooks every year. Adjusting a few words before printing to match what we did in class is a huge time saver for me.Somehow my school division was able to buy me a one time fee perpetual license. I’m very happy with it. reply soco 34 minutes agorootparentprevFor me even Sumatra or Foxit have too many features. I only ever open PDFs to read and print, maybe zoom, but all those other buttons there only distract me - if there&#x27;d only be a way to hide them... But yeah first world problems. I&#x27;m happy they exist. reply yoyohello13 3 hours agoparentprevEven more impressive is I believe it’s a solo dev. SumatraPDF is one of my go to examples of a great software project. Something to aspire to. reply CodeCompost 2 hours agoparentprevI got burned by Foxit when they started shipping spyware with it, so I&#x27;m hesitant now to try anything else. reply tayo42 3 hours agoparentprev> What the hell is Adobe doingMaybe they&#x27;re handling every posts feature wish list?Like every comment so far here is Sumatra is nice but... is missing reply ykonstant 49 minutes agoprevI implore all developers of PDF readers to implement sioyek&#x27;s overview feature[0]. When you hover on a cross-referenced entry, it opens a little preview window with the contents of the reference. It is an absolute game-changer for reading textbooks and technical papers; I cannot overstate its utility.[0] https:&#x2F;&#x2F;github.com&#x2F;ahrm&#x2F;sioyek#overview reply mattegan 6 hours agoprevLike others have mentioned, Sumatra is one of a few Windows-only utilities that I routinely miss when on Mac or Linux, primarily due to two simple interactions which I miss every day viewing schematics, mechanical&#x2F;technical drawings or datasheets -- Alt + Scroll == Zoom and Right Click + Drag == Pan.Does anyone know of any viewers on Mac or Linux that provide these two features? Skim on Mac implements Option + Scroll and Left Click + Drag Pan, but it&#x27;s not reconfigurable to any other keys or mouse buttons. reply plumeria 4 hours agoparentI really like Okular (especially with the theme that allows me to read PDFs with dark red background and yellow text), but haven&#x27;t been able to run it on my Mac Mini with Apple silicon. The brew formula appears to be broken for newer macs. reply vladvasiliu 5 hours agoparentprevZathura does that under Linux, with the difference that zoom is achieved with Ctrl instead of Alt. Right-Click dragging = pan.One feature I absolutely love is that Page Down goes to the top of the next page. It&#x27;s very practical when you want to skim something quickly, with a zoom level that doesn&#x27;t fit a page size perfectly. reply TylerE 5 hours agoparentprevFoxIt does zoom on Ctrl+Scroll, and Pan on Left Click+Drag. Runs on Mac and I&#x27;d assume linux.Close enough?I assume if you REALLY want to go nuclear on it, there is some shareware app that will let you do per-app keyboard emulation and rebind inputs \"in flight\" or something.I believe https:&#x2F;&#x2F;www.keyboardmaestro.com&#x2F;main&#x2F; is the standard solution. reply eviks 4 hours agoparentprev> Skim on Mac implements Option + Scroll and Left Click + Drag Pan, but it&#x27;s not reconfigurable to any other keys or mouse buttonsYou can use Karabiner Elements + BetterTouchTool to rebind that when Skim is in the foreground? reply viraptor 6 hours agoparentprevEvery browser pdf reader I&#x27;ve seen handles the alt+scroll for zooming (since the browser itself does it) Not sure about panning shortcut. reply cmplxconjugate 3 hours agoparentprevI&#x27;m in the same boat. It&#x27;s almost the only application I miss! I use Okular but I think Sumatra just has the right UI for me. reply keehun 6 hours agoparentprevI use three-finger drag on Mac (with a magic trackpad) and find that better than any combination of click & drag. Have you tried it? reply mattegan 6 hours agorootparentThat&#x27;s fair! I&#x27;m just not a big trackpad person since I find doing ECAD or MCAD with a trackpad to be not so enjoyable :) reply andrepd 3 hours agoparentprevI use qpdfview and I&#x27;m very happy. Loads of customisability. reply Izkata 6 hours agoparentprevevince (linux) does Zoom with Ctrl + Scroll, maybe yours does too? I don&#x27;t think it has Pan, but I&#x27;m keyboard-heavy and use horizontal scroll with Shift + Scroll. reply joveian 3 hours agorootparentMiddle button and drag moves the text wherever you drag it.The evince feature I can&#x27;t live without is the find, which shows a side panel with all matches in the document along with a bit of context. I wish all document find everywhere did this. reply barbs 3 hours agorootparentprevEvince uses middle-click to pan reply ww520 6 hours agoparentprevCan it run under Wine on Linux? reply app4soft 4 hours agorootparentYes, it runs under Wine or CrossOver on Linux and Mac. reply quyleanh 7 hours agoprevThe big update of SumatraPDF was out yesterday [1]. There are a lot of bugs fix and improvement in the backlog [2].[1] https:&#x2F;&#x2F;github.com&#x2F;sumatrapdfreader&#x2F;sumatrapdf&#x2F;releases&#x2F;tag&#x2F;...[2] https:&#x2F;&#x2F;github.com&#x2F;sumatrapdfreader&#x2F;sumatrapdf&#x2F;issues&#x2F;3672 reply puika 2 hours agoparentthis is my \"dark mode\" via advanced options, e.g. warmer page and dark background: MainWindowBackground = #191919 FixedPageUI [ TextColor = #282828 BackgroundColor = #ebdbb2 SelectionColor = #2d938f ... ]what I have been doing so far is switch between other modes with autohotkey by overwriting `SumatraPDF-settings.txt`. I&#x27;d share the little script but it suddenly broke a while back reply lencastre 4 hours agoparentprevDark mode and tab switching with the keyboard are 2 great additions to the best lightweight PDF reader EVER!!! reply nuxi 4 hours agorootparentTab switching with the keyboard was already possible previously, IIRC you can use Alt+ (or maybe Ctrl+) to switch to the N-th tab. reply puika 2 hours agorootparentyes, CTRL+TAB and ALT+, I use them all the time. reply Sakos 1 hour agoparentprevDid they ever fix the issues around printing? I always ended up using a different PDF viewer just because of that. reply user3939382 7 hours agoprevBless the heart of whoever looked at the PDF spec and said to themselves, \"Nice, I&#x27;d like to writer a parser for this.\" reply mkl 17 minutes agoparentI think writing a parser for in-spec PDF files probably isn&#x27;t too hard (though writing a complete renderer and interface certainly is), but many PDF files don&#x27;t match the spec, so your parser has to be tolerant of invalid PDF files, because Adobe&#x27;s is. reply viraptor 6 hours agoparentprevEven once you have a parser itself, actually figuring out what to display and where is... interesting. Especially in generated rather than hand-created documents. What&#x27;s the element&#x27;s position? Grab your math library, we&#x27;re multiplying matrices! What does this text say? Let&#x27;s write another parser for the table of very custom codepoints! reply VMG 0 minutes agorootparentmapping coordinates via projection matrices pretty common tbh reply hu3 7 hours agoparentprevNo joke. Yesterday I found out PDFs can have forms with JavaScript.https:&#x2F;&#x2F;tcpdf.org&#x2F;examples&#x2F;example_014&#x2F;How does this even work? reply somat 4 hours agorootparentThe stupidest part of the whole thing is that pdf is basically a neutered postscript. The problem with postscript as a document format, is that there is no good way to do metadata, jump to a specific page, count pages, etc. So pdf uses the rendering engine of postscript with all that annoying turing complete behavior torn out. Then at some point they wanted some computational capability in the document[1], but instead of reintroducing postscript into the mix they went with a third language, a wierd poorly designed one invent for browser scripting.1. Yes we all know how stupid this was. but they wanted fillable forms and validating those forms made sense at the time. Really it was because they were trying to compete with the web. reply viraptor 6 hours agorootparentprevI hope I can amuse you further: PDF embedded 3d models https:&#x2F;&#x2F;helpx.adobe.com&#x2F;mt&#x2F;acrobat&#x2F;using&#x2F;displaying-3d-model... and interaction https:&#x2F;&#x2F;www.astrobetter.com&#x2F;blog&#x2F;2012&#x2F;03&#x2F;07&#x2F;tutorial-for-emb...You can also do animated page transitions like PowerPoint, but I don&#x27;t have the right link available... reply hu3 5 hours agorootparentYou did amuse me! Thanks!To me this is the kind of scope creep that causes a \"simple\" PDF renderer department to end up with 50 devs working in it full-time.I wonder... can a PDF have an iframe that opens itself? Causing an infinie loop of it loading itself? reply elashri 3 hours agorootparentThat&#x27;s a nice idea. Can we call that PDF bomb? reply baal80spam 3 hours agorootparentprevI remember someone wrote a game in a PDF document... reply jimjimjim 2 hours agorootparentprevbadly reply lost_tourist 7 hours agorootparentprevbecause some viewers have built in javascript interpreters. In the pdf it&#x27;s just text labelled as a script reply grishka 5 hours agoparentprev...in a memory-unsafe language! reply isatty 1 hour agorootparentWhy is this comment under every post? Low quality bait. reply pixelpoet 8 hours agoprevWhat&#x27;s super handy about SumatraPDF is that it will auto reload normal image files if they&#x27;re modified, so it&#x27;s an easy way to get some sort of windowed graphics output by saving image files. reply Semaphor 4 hours agoparentNot just images. Whole PDFs as well. I do some PDF generation for work, and running the update command and instantly seeing the changes when it’s done, is great. reply globular-toast 2 hours agorootparentYep. Pretty standard workflow when using LaTeX or something. reply teleforce 2 hours agoprevIs there any open source seamless PDF editor available given how pervasive is the PDF document nowadays? I really think that we need one and it has been long overdue.What I meant by seamless is that all of the open source software that currently able to edit PDF document is dong it in a clunky way at best for example Krita and LibreOffice Draw. The resulting edited output document also is also looks distinct, in a bad way, from the original document unlike the output from Adobe PDF editor. reply Zufriedenheit 14 minutes agoparentI have done extensive research in past when i was considering switching from mac to linux. Came to the conclusion that there is no viable open source alternative for the mac preview app unfortunately. My requirements where: - Fill forms. - Add text and markup. - Reorganize&#x2F;add&#x2F;remove pages. - Redact parts of the document. (should also safely delete underlying text data, without rasterization of the whole document) - Add image of signature without rasterization of the whole document. This [1] is a long discussion i found about the topic.[1] https:&#x2F;&#x2F;unix.stackexchange.com&#x2F;questions&#x2F;85873&#x2F;how-can-i-add... reply pelalmqvist 2 hours agoparentprevMaybe not exactly what you are looking for, but take a look at Stirling-PDF. https:&#x2F;&#x2F;github.com&#x2F;Frooodle&#x2F;Stirling-PDF reply teleforce 10 minutes agorootparentThanks for the link will try it out, apparently this app was initially made by ChatGPT, whatever that means>This locally hosted web application started as a 100% ChatGPT-made application and has evolved to include a wide range of features to handle all your PDF needs reply mesebrec 2 hours agoparentprevHave you tried the latest version of OnlyOffice? reply fithisux 2 hours agoparentprevThe spec is very complex. there are some, here and there but nothing coherent.Even worse PDF is not \"open source\", it should have been accompanied by LaTeX source. reply teleforce 1 hour agorootparentThe PDF is now standardized as ISO 32000, it&#x27;s open for everyone to create compatible tools.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;PDF reply looperhacks 22 minutes agorootparent\"Open\" for the cheap price of ~$230 reply Ghostt8117 7 hours agoprevI love SumatraPDF. I&#x27;ve used it for years and it is wonderful. I have been writing Latex in vim and I compile with the document open in sumatra side by side for instant updates. Very smooth workflow with the instant reload of the page. reply fiforpg 7 hours agoparentYep. An obligatory hat tip to lervag — his vimtex plugin* is a beast.*Which you are most likely using, since it integrates with Sumatra out of the box. And with MuPDF. And Skim, etc. It&#x27;s cool like that. reply bee_rider 7 hours agoparentprevEvince does this as well. It is a completely necessary feature in my opinion.I tried Sumatra a while ago, before switching over to Linux. It seemed pretty decent, nice and snappy. reply HKH2 2 hours agoparentprevAtril automatically reloads too. reply esalman 8 hours agoprevSumatra PDF was my go-to tool for viewing PDF changes in real time while writing manuscripts and thesis during PhD. Acrobat (paid) and foxit (free) have more features but locks the file undergoing changes. reply Zuiii 7 hours agoparentGood example of how the implementation of unnecessary restrictions, without proper consideration of how such restrictions would impede users, can harm your product. I hope all software doing the same on android (safetynet, prevent screenshots, etc) follow Acrobat reader into irrelevance. reply lxgr 5 hours agorootparentExclusive locking is simply the default on Windows. reply pbmonster 2 hours agorootparentSure, but for a viewer, deviating from that default makes a lot of sense.I started using Sumatra years ago exclusively because of that feature. Exports&#x2F;compiles failing, just because the PDF is still open somewhere is just unbelievably annoying. reply urlwolf 2 hours agoprevIf you are on linux and miss the snappiness of sumatra, try llpp. They use the same renderer. In fact, llpp has more features, like a better overview mode where you can get 3 pages on screen. Search does suck. llpp is written in Ocaml and a fantastic piece of software. reply aragonite 4 hours agoprevSumatra is great, though occasionally I wish it were possible to have something like Firefox&#x27;s wrapped scrolling [1] where more than 2 pages can be shown side by side. On a reasonably large monitor, being able to quickly zoom out to see e.g. 30 pages (sometimes all the pages of a journal article) at the same time can be very useful. You can be on p. 20, then go and quickly look up a definition on p.2, then frictionlessly switch back to p. 20. Having to remember a page number to go back to, or a key word to search for, or to worry about where the \"back\" button might take you (as with most PDF readers) is just too much friction.[1] https:&#x2F;&#x2F;superuser.com&#x2F;questions&#x2F;1365482&#x2F;how-to-view-a-pdf-wi... reply urlwolf 2 hours agoparentLove this view. I can&#x27;t get pdf display on FF to invert colors. Is there a way? Then it would replace okular for me (which also does this overview mode) reply throwaway2037 3 hours agoparentprevSubmit a patch? reply davikr 8 hours agoprevI really love SumatraPDF but I wish it&#x27;d fare better on the search story: there&#x27;s no widget to show all search matches, afaik, and searching can be slow on really big files with thousands of pages.To be fair, most PDF readers struggle with this, and I suspect only Acrobat attempts to cache or index files (as a Pro feature). reply mahdi7d1 5 hours agoparentI remember reading a blog post from the author of sioyek boasting about search performance.Haven&#x27;t personally compared the options but for me sumatra zathura and sioyek all feel fast enough to not notice any problems.https:&#x2F;&#x2F;ahrm.github.io&#x2F;jekyll&#x2F;update&#x2F;2022&#x2F;09&#x2F;11&#x2F;pdf-viewer-t...\"Now I must admit, the reason sioyek is so fast is because it creates a search index when you open the document.\" reply sammy2255 7 hours agoprevLove SumatraPdf, completely no-bs software unlike Adobe. If I ever need to sign a PDF Microsoft Edge works wonderfully reply Mengkudulangsat 6 hours agoparentI still need Adobe to sign and fill forms. Wish Sumatra can do those too :( reply autoexec 4 hours agorootparentI&#x27;m really glad that they don&#x27;t. I&#x27;d much rather have a safer PDF viewer that only supports a limited subset of what adobe&#x27;s shitware does to handle 99% of my PDF file needs so that I only need to risk opening Adobe software 1% of the time. That&#x27;s so much better than turning Sumatra into the same bloated mess of risky features that is Adobe Acrobat. reply Steve44 43 minutes agorootparentprevI&#x27;m not sure, one thing I like about Sumatra is that it&#x27;s very light and clean.When we need to sign or view some complex documents then I&#x27;ll use Acrobat. reply nip 2 hours agorootparentprevNo need for Adobe: https:&#x2F;&#x2F;simplePDF.euDisclosure: I’m the developer behind it reply leeman2016 5 hours agoparentprevXournal++ is nice too reply rtpg 1 hour agoprevIt&#x27;s kinda frustrating how by default, most major OS setups now are \"open PDFs inside the browser\". It&#x27;s kinda nice that browsers can handle PDFs smooth-ish now, but Preview on Mac is nice, and SumatraPDF is as well. reply timvdalen 3 hours agoprevI&#x27;ve been using Sumatra for what feels like a decade, and it&#x27;s definitely the best PDF reader out there. I mostly started using it for the auto-refresh when I&#x27;m working on a LaTeX document. reply sinuhe69 8 hours agoprevI have the bad habit of keeping many PDF files in the reader open (yeah, I keep reading long books). The thing is when I open Sumatra for a new file (maybe only for a quick glance) Sumatra will reload all my files and slowed the startup significantly. I wish I can set the option which will load only if I’ve actually switched to the tab, just like Firefox. reply hans_castorp 4 hours agoparentThis can be controlled when use the \"Advanced Options\". It opens a config file where you can set:RememberOpenedFiles = falsehttps:&#x2F;&#x2F;www.sumatrapdfreader.org&#x2F;settings&#x2F;settings3-4-6 reply generationP 8 hours agoparentprevIt seems to have a bug where if you load a file from the app using the quick-load 1,2,...,10 keys in the File menu, then the next time you open another file in SumatraPDF from the explorer, it immediately opens several other files. This may be related. reply throwaway2037 3 hours agoprevA more accurate title would be: SumatraPDF: multi-format reader for Windows reply afterburner 1 hour agoparentYes, I love it for comics (CBZ files). reply lazycouchpotato 5 hours agoprevI haven&#x27;t really felt the need for a dedicated PDF reader ever since Firefox upped their PDF support. It works pretty well and recently added support for form filling, text box and drawing [1].SumatraPDF does support other file formats, which is nice.[1] https:&#x2F;&#x2F;www.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;features&#x2F;pdf-editor&#x2F; reply HKH2 2 hours agoparentIs there a dual page view? Can you change whether the first page is left or right? reply erremerre 2 hours agoprevOn the other side of the spectrum you have Calibre, a program that uses a multiplatform abstraction, with a myriad of options, a myriad of icons, plenty of features...In my opinion, I prefer the Sumatra way of doing things. But if you need to transform data... there is no other option that fighting against the multiple features of Calibre. reply piokoch 1 hour agoprevThis is amazing piece of software. You click the icon and it starts. Immediately. It does what you expect it to do, it just displays PDF file on the screen. reply elromulous 7 hours agoprevWhat&#x27;s the SumatraPDF for Android?It used to be Repligo, but it got removed from the Play store ages ago. I still had access to it, but since it wasn&#x27;t being maintained, it became harder to use with each android os update. reply alisonatwork 7 hours agoparentI use MuPDF, which SumatraPDF is built on top of, I think. It is extremely no-frills, but it does the job. reply DANmode 5 hours agoparentprevhttps:&#x2F;&#x2F;github.com&#x2F;GrapheneOS&#x2F;PdfViewer reply app4soft 4 hours agorootparentIt does not work on Android 6 reply carlos22 3 hours agorootparentWell Android 6 is like Windows 95 ;-) reply bronlund 3 hours agoprevI got a love&#x2F;hate relationship with PDF readers, and I find myself constantly switching from one to the other in hope of a better experience. All I want is to set my own exact colors and to use a hand-tool if I so wish. You wouldn&#x27;t think that such simple wants should be an issue or, if what you did was making PDF-readers, that it may cross your mind to implement one or two of those. reply anjel 7 hours agoprevSumatra is one of the (few) win apps I miss since recently converting to linux. Running it under wine seems like overkill, but I wish for a debian port... reply natrys 6 hours agoparentI thought I would too. But Zathura had been adequate over the years (similarly mupdf based). And I have been using sioyek[1] for few months and I probably like it the best.[1] https:&#x2F;&#x2F;sioyek.info&#x2F; reply dramtech 6 hours agoparentprev> but I wish for a debian port...Sumatra makes heavy use of the win32 API so a port is not possible. This design is why it&#x27;s so good (light, fast, well integrated) and the author refused to lessen his software by using a cross platform framework. reply dysoco 7 hours agoparentprevOkular is really good and probably has more features than Sumatra; though I still run Sumatra in Windows. reply thrillgore 4 hours agorootparentI actually use Okular on Windows and Linux, it is quite good. reply fiforpg 6 hours agoparentprevQpdfview is my daily driver for reading documents on Linux. Supports tabs, search, highlighting.If you want something still more lightweight, Zathura would be the way to go. It can be a tad too minimalistic, but great for LaTeX with vimtex, and for an occasional quick document, the startup times are phenomenal. reply vladvasiliu 4 hours agorootparentI love Zathura under Linux. Bonus points for not attempting to do its own window management (tabs and whatnot) and leaving that to the window manager.But one thing I really hate with it is that if you rename a file while it&#x27;s open, it&#x27;ll stop displaying it. Not sure if this is related to zathura itself or to the backend I&#x27;m using (mupdf). reply bee_rider 6 hours agoparentprevEvince is pretty decent. It auto-reloads PDFs like Sumatra (IMO this is what draws the line between good and bad PDF readers, haha). reply HKH2 2 hours agoparentprevI&#x27;m a Sumatra user when I&#x27;m forced to use Windows. Atril might be a bit feature-light for you, but it is stable and fast. reply red_admiral 1 hour agoprevEven in the software world we can, sometimes, have nice things. SumatraPDF is one of them. Kol HaKavod to Krzysztof Kowalczyk! reply vermaden 4 hours agoprevI use SumatraPDF daily but an older version 2.5.2 - before the &#x27;larger&#x27; rework.Works very well under WINE on FreeBSD and does not have display issues with taskbars etc. reply luismedel 5 hours agoprevExtremely good software. Always on my _bat-belt_.The author was one of the most active members of the old Business Of Software forums, IIRC.I always wondered how he could make money from a free PDF viewer. reply lukeholder 4 hours agoparentSounds like he doesn’t make money. reply luismedel 2 hours agorootparentYes. It seems so :-) reply psnehanshu 2 hours agoprevGreat app, but never tried it. I am wondering why people just don&#x27;t use Chrome or Firefox or Edge as their PDF reader? reply afterburner 1 hour agoparentWell, here&#x27;s a really weird reason: it&#x27;s a great comic CBZ reader! reply guilamu 2 hours agoparentprevMaybe it&#x27;s just me, but they all happen to have issues when printing. No idea why or if it has been fixed recently, but I never had this kind of issue with Sumatra or Acrobat obviously. reply puzzlingcaptcha 3 hours agoprevI have been using Sumatra for years and my only issue is that it sometimes takes a _very_ long time to get it to start printing a complex document (at least on Windows). I still keep Adobe Reader around just for printing. reply urlwolf 2 hours agoprevIs there any way to click on an image to magnify? in many books figures are too small. Ctrl + scroll does magnify the entire doc, but the img is pixelated. reply mahdi7d1 6 hours agoprevThis piece of software is one of the few joys I have when using Windows. While reading ebooks you almost forget how bloated and slow Windows is. reply realPtolemy 8 hours agoprevUsing it for windows, good and lightweight, much more convenient than Adobe for basic usage.But I wish that I was able to ”drag and open in new window” tabs of different opened PDF files.But I must say that skim for Mac is the best! reply quyleanh 7 hours agoparentYou mean \"ability to drag out a tab to open it in new window\"?If so, you can do in latest update [1][1] https:&#x2F;&#x2F;github.com&#x2F;sumatrapdfreader&#x2F;sumatrapdf&#x2F;releases&#x2F;tag&#x2F;... reply realPtolemy 4 hours agorootparentExcellent! Will update today then :) reply dimmuborgir 2 hours agoprevDark mode finally!!! This was the only bummer for me all these years. Not anymore! reply jszymborski 7 hours agoprevProbably one of the only bits of software I miss from when I ran Windows. reply bradrn 7 hours agoparentAgreed. SumatraPDF is still one of my favourite programs, and I wish there was a Linux PDF reader which approached it. (Okular is probably the best, but it can’t remember opened tabs.) reply alberth 7 hours agoprevPreview.appAm I the only person who has Preview.app constantly hang and&#x2F;or freeze my Mac, even on the smallest of PDFs (< 3 slides)I’m on M1 with latest macOS. reply n9 7 hours agoparentI use preview all day, every day, often with dozens of files open, including full scans of the full OED (each pdf 100s of MB). It occasionally will hang when I \"print to PDF\" with a large document, but other than that no issues to report for a couple years now on M1 and M2. reply Quiark 7 hours agoparentprevPreview also supports reloading the PDF on changes so you can have a similar workflow to Sumatra:open - edit - reload - edit - reload - edit - Preview crashes - reopen - edit - reloads - edit - Preview crashes etc. reply helf 7 hours agoprevI adore Sumatra. I have used it for decades. Used to run it on my Windows 95 laptop even :) Super fast. Just. Works. Rarely have any issues with it. reply bdhcuidbebe 4 hours agoparentcool story bro reply njharman 8 hours agoprev [–] Stopped using cause the author can&#x27;t comprehend that scrolling &#x2F; scrollbars could apply to document as a whole (like every other editor&#x2F;viewer ever allows).https:&#x2F;&#x2F;forum.sumatrapdfreader.org&#x2F;t&#x2F;display-scrollbar-in-si... reply jchw 7 hours agoparentHmm? I don&#x27;t think \"every other editor&#x2F;viewer ever\" does this. Okular doesn&#x27;t do this for example, I just checked: If I use \"Fit Page\" and uncheck \"Continous\", the vertical scrollbar disappears.I&#x27;d also find it confusing, because it seems like that means if you zoom in, the scrollbar would be for the current page, but then if you zoom out, it would be for the entire document. Is that how other viewers actually work, or is it more elaborate than that?Obviously this isn&#x27;t a model interaction with an open source project either way. Although I don&#x27;t think how they responded was ideal, I don&#x27;t think I would&#x27;ve enjoyed communicating with you on that thread if I were the maintainer, either. Nobody&#x27;s perfect, but all in all, I&#x27;d hope you agree that this has thusfar not been very productive on either side. reply move-on-by 8 hours agoparentprevYou can always submit a PR to implement the feature you want. Maybe showing the author what you want via PR is the best way to explain what you are asking for. reply gorjusborg 7 hours agorootparentYou can even fork it for your own use. reply adityamwagh 8 hours agoparentprevYou should try https:&#x2F;&#x2F;www.pdfgear.com&#x2F; . It’s also free. reply dooglius 7 hours agoparentprevHe does, document level scrolling is the default behavior? Link looks like someone put it in a non-default view mode and doesn&#x27;t like the specifics of how that mode works. reply rahimnathwani 7 hours agoparentprev [–] Which of the comments in that thread are by the author? reply isatty 1 hour agorootparent [–] None, AFAIK. Canonical: https:&#x2F;&#x2F;github.com&#x2F;sumatrapdfreader&#x2F;sumatrapdf&#x2F;issues&#x2F;191 replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SumatraPDF is an open-source reader that supports multiple file formats like PDF, EPUB, MOBI, CBZ, and more.",
      "Made available for Windows, it operates under the (A)GPLv3 and BSD licenses.",
      "It boasts a significant presence on GitHub with over 11k stars, 1.6k forks, and contributions from 48 diverse contributors."
    ],
    "commentSummary": [
      "The thread focuses on the merits and drawbacks of SumatraPDF Reader, positioning it as an alternate to Adobe Acrobat for PDF processing. This includes its platform compatibility, lightweight footprint, and recent enhancements.",
      "The conversation also covers the need for seamless open-source PDF editing tools and the challenges of parsing and rendering PDF files, indicating the complexity of PDF workflows.",
      "While SumatraPDF is lauded for its performance and ease in navigating pages, users have encountered issues with printing and freezing on Mac. Additional features like the ability to drag tabs into new windows are also desired."
    ],
    "points": 330,
    "commentCount": 148,
    "retryCount": 0,
    "time": 1698107895
  },
  {
    "id": 37990990,
    "title": "Mazda slaps developer with cease-and-desist for DIY smart home integration",
    "originLink": "https://www.thedrive.com/news/mazda-slaps-developer-with-cease-and-desist-for-diy-smart-home-integration",
    "originBody": "NEWS CAR REVIEWS FEATURES THE GARAGE THE WAR ZONE NEWSLETTER SIGNUP News → News by Brand → Mazda News Mazda Slaps Developer With Cease-and-Desist for DIY Smart Home Integration Mazda owners were making their connected SUVs a little smarter with open-source code. Then the automaker stepped in. BY ADAM ISMAILPUBLISHED OCT 20, 2023 2:30 PM EDT NEWS Mazda SHARE ADAM ISMAIL View Adam Ismail's Articles Modern cars are indeed very smart, though no car is perfect. One enterprising developer decided to make his Mazda a little smarter through code and share his work with others like him online. Unfortunately, the automaker took issue with his improvements, and hit the project with a Digital Millennium Copyright Act (DMCA) claim, forcing it to be taken down. Developer Brandon Rothweiler authored Mazda-specific integrations for Home Assistant, an open-source platform that can be used to run and establish interoperability between a variety of connected devices. Rothweiler's code plugged into Mazda's Application Programming Interface or API, allowing owners to create and share a number of seemingly inoffensive, convenience-minded functions, like checking and alerting fuel levels before a daily commute, or remotely unlocking and firing up the car when outside temperature drops below a certain threshold, as Ars Technica summed up in its coverage. Mazda caught wind, however, and served Home Assistant, GitHub (where the software was hosted), and Rothweiler cease and desist orders, citing a number of infringements. The automaker argued that Rothweiler's work contained code that violated its copyrights; used its \"proprietary API information\" to create more code; and that the integrations provided functionality identical to what currently exists in Mazda's own mobile apps. The Drive reached out to Mazda to clarify its position on these claims, and will update this story should we learn anything. Interior of the Mazda CX-90 SUV. Mazda Rothweiler promptly pulled his work and told Ars that he was ultimately left with little choice. \"My options were to either comply or open myself up to potential legal risk,\" the developer told the publication. \"Even if I believe that what I'm doing is morally correct and legally protected, legal processes still have a financial cost. I can't afford to take on that financial risk for something that I do in my spare time to help others.\" Responses to Home Assistant's own takedown announcement, as well as posts on a Mazda SUV forum, make the owner community's frustration clear. One such user dismayed at the news wrote that the features he had been using for his CX-60 \"make Home Assistant more useful, save money, and make me happier about my Mazda ownership.\" It's unclear what legal basis Mazda has to order a DMCA takedown, as one GitHub user highlighted that they weren't able to locate any copyrighted code in Rothweiler's work, and the Electronic Frontier Foundation believes that reverse engineering for the purposes of interoperability can qualify as fair use. Regardless, maximizing the convenience of connected cars in a manner that doesn't sacrifice the safety or security of those vehicles, or steal software that legally belongs to an automaker is an undeniable facet of car modification in the modern age. In fact, many manufacturers appear to be OK with especially resourceful owners optimizing their cars in this way. Home Assistant's integration library features at least six automakers, including BMW and Volvo, while Tesla recently published details of its new, official, open API for third-party developers to employ. Carmakers can pretend all they like that electrification and ever-more connected vehicles will offer the same degree of room for personalization and independence as cars always have, but until they start backing that up with real action and back down from their litigious ways, it'll all be insincere. CAR TECH MAZDA NEWS NEWS BY BRAND Sign Up For Our Newsletters The chronicle of car culture, delivered to your inbox. SIGN UP The Drive Team Contact Us Privacy Policy Terms & Conditions Sitemap © 2023 Recurrent Ventures. All Rights Reserved. Articles may contain affiliate links which enable us to share in the revenue of any purchases made. Some benefits of our Car Shopping program may not be available in your area. Please see terms for details.",
    "commentLink": "https://news.ycombinator.com/item?id=37990990",
    "commentBody": "Mazda slaps developer with cease-and-desist for DIY smart home integrationHacker NewspastloginMazda slaps developer with cease-and-desist for DIY smart home integration (thedrive.com) 292 points by heshiebee 13 hours ago| hidepastfavorite155 comments mirkules 11 hours agoI&#x27;ve worked for a large OEM, dealing with a large Japanese megacorp that is not Mazda for about two years (actually Mazda was one of our customers too, but I didn&#x27;t get to work with them directly). This does not amaze me anymore.We spent months agonizing over an interior temperature sensor, which was only used to display the information to the user on a smartphone app. We built both the hardware and software, and it was offered as an add-on at the dealerships. After months of negotiations, after the hardware was already built and the packages assembles, they decided temperature sensors were too inaccurate (+&#x2F;- 5 degrees F) to use, and that it could present a legal liability. Again, this was nothing else but displaying the information on the app - and the user could then make a decision whether to remote start the car to cool it or heat it (no automatic process took place either).This was at the height of \"unintended accelerator\" issue in Toyotas, so everyone was walking on egg shells playing it ultra safe to not invite any more lawsuits.What surprises me is that this culture of \"playing it safe\" remained to this day, some 10 years later (but maybe it shouldn&#x27;t). reply wutwutwat 10 hours agoparentIdk about everyone else but when it comes to anything running in my car, _anything_, there is no such thing as excessive \"playing it safe\". It&#x27;s a 2 ton mass of steel barreling down the highway at 70+ mph next to other unpredictable 2 ton masses, please for the love of God, fight to maintain that culture of \"playing it safe\", regardless of what you&#x27;re working on and for what purpose. reply kazinator 3 hours agorootparent> It&#x27;s a 2 ton mass of steel barreling down the highway at 70+ mphSo good thing it&#x27;s connected to the internet and has four screens. reply wutwutwat 2 hours agorootparent> good thing it&#x27;s connected to the internet and has four screensNot any of my cars that I&#x27;ve owned reply ipaddr 9 hours agorootparentprevWould you be willing to pay millions for your car to make it safer? The pope has bullet proof glass, different body materials can protect your life. How would you define excessive? reply wutwutwat 8 hours agorootparentR&D is already baked into the final price of everything we buy so that has no argument.And the bullet proof glass thing I shouldn&#x27;t even respond to because of the ridiculous extreme you&#x27;ve had to go to, trying to argue against me saying the companies should play it safe, but I&#x27;ll reply this one time. I&#x27;m not asking the car company to protect me from an assassin&#x27;s bullets. That is not something they control. I&#x27;m asking them to \"play it safe\" when developing components for the car so the car doesn&#x27;t kill me while I&#x27;m in the car. They are responsible for their domain and are not producing armored vehicles for war time. So ridiculous lol reply ipaddr 4 hours agorootparentYour comment was nothing is too excessive. The truth is, everything has a level where we try to balance cost&#x2F;safety. Having Mazda spend millions more puts the base stickier price up. It might be $100, $500, $5000, $50,000 $5,000,000. How much more are you willing to pay and if you really cared wouldn&#x27;t you buy a Volvo over a Mazda? reply xctr94 3 hours agorootparentThis really isn’t helping. Cars are very safe at the moment, with the driver being the key factor in accidents. They are very safe at the current price point. GP was arguing we should keep fighting to keep them safe. That means we keep doing whatever it is we’re doing, which is making cars safe, at a reasonable cost. reply shiroiuma 8 hours agorootparentprevIf you live in the US, getting shot while driving (or at school, or at work) at is something that happens from time to time, so if you value safety, you really do need armor and bullet-resistant glass on your car to drive in America. reply gottorf 9 hours agorootparentprevYeah, everything is a tradeoff that should have a coherent risk-benefit analysis attached to it. \"X at all costs\" isn&#x27;t realistic. reply wutwutwat 8 hours agorootparentNever said \"X at all costs\" but thanks for trying to speak for me. Going forward, please note that my preference is to speak for myself, as should you. reply gottorf 7 hours agorootparentI&#x27;m not sure why you took such offense; it&#x27;s a reasonable interpretation of the words you spoke for yourself:> there is no such thing as excessive \"playing it safe\"As you noted in your other comment:> I&#x27;m asking them to \"play it safe\" when developing components for the car so the car doesn&#x27;t kill me while I&#x27;m in the car.As in the old adage in computing (\"the only unhackable computer is one that isn&#x27;t connected to anything\"), there&#x27;s no way to ensure that the components of a car don&#x27;t fail, even while in routine use. There is only more or less likely that they won&#x27;t fail, and of course, less and less likely to fail is more and more expensive.We might say that the only uncrashable car is one that sits in the garage and never goes anywhere. Obviously, that would be playing it safe excessively, since it would defeat the purpose of having a car to begin with. But what about less obvious cases? Toyota recalled millions of cars for their \"unintended acceleration\" issue. The merits of that particular case aside, how much more would someone pay for a Corolla that would be progressively less likely to have safety issues? At some point before infinity, it would be considered excessive.I think the sliding scale of how safe is playing it too safe is a discussion very much worth having. reply Spivak 9 hours agorootparentprevYes, I just don&#x27;t want to pay all of it myself. I just want to pay the marginal cost of making it. Let the automaker invest said millions (really billions over all the individual components) into the design and manufacture. reply lost_tourist 6 hours agorootparentprevIt should always be tempered with common sense. The older I get the more I just want a basic car. I just need gauges and a radio with bluetooth. I don&#x27;t need to integrate everything into my car or have an 18\" center console. A reliable car (electric or gas), decent interior space, with no surveillance and just basic features and I&#x27;ll walk into your dealorship and pay cash. Closest I&#x27;ve gotten so far is my base model corolla with 4G antenna disabled (after market). reply glimshe 15 minutes agoparentprevI&#x27;ll be honest here... +&#x2F;- 5F isn&#x27;t useful to me as an add-on temperature sensor, that would have pissed me off as a consumer. reply mardifoufs 11 hours agoparentprevWoah I&#x27;d have guessed that temperature sensors would be more accurate than that! Is it just an issue of cost, or are most affordable temp sensors that inaccurate and I&#x27;ve never realised it? That would explain a lot though! reply AlotOfReading 11 hours agorootparentNo, it&#x27;s pretty easy to get better sensors than that. E.g. a cheap-ass SHT20 will do +-0.3C. In fact, my own automotive parts recommendations are the next grades up (SHT21&#x2F;SHT3x) as standard for my employer&#x27;s boards because the cost difference is justified.Never underestimate the ability of a manufacturer to select subpar parts to save 25 cents on the BOM and spend 6 figures elsewhere trying to fix the resulting issues though. reply _nalply 1 hour agorootparentI think the problem is not the accuracy of the sensors themselves but that its difficult to have a placement inside the car such that the measurement is minimally influenced. Many factors influence temperature: heat from the motor, from heating and from the sun shining on the car and perhaps others.And it also depends what exactly you want to measure: air, motor or inside temperature? People might get confused. And inside temperature might differ a lot: behind the windscreen it might be a lot hotter than at the floor. reply throwaway837367 11 hours agorootparentprevNo, you read the datasheet wrong. It&#x27;s +&#x2F;- 3C. reply AlotOfReading 11 hours agorootparentI&#x27;m looking at the datasheet right now. Relative humidity accuracy tolerance is +-3.0, temperature is +-0.3. Different tables. reply chris_va 10 hours agorootparentI imagine the temperature gradient across the car might be +&#x2F;- 3degC, ignoring the actual sensor. reply AlotOfReading 9 hours agorootparentIt&#x27;s undoubtedly more than that, depending on where you measure. The gradient between e.g. the roof lining and the AC vent could easily be 20C+ degrees on a hot day. Most boards on a vehicle will have their own temperature sensors to measure enclosure temps, and there will be zonal sensors at various points in the cabin as well. The climate control loop will be defined in terms of those zonal sensors. reply HankB99 9 hours agorootparentprevMeasuring temperature is not trivial. There&#x27;s convective, conductive and radiative heat transfer and they all factor into the measurement. And that may not accurately reflect the \"cabin temperature,\" particularly in a parked car. reply mardifoufs 9 hours agorootparentprevBut the weird part is that OEM seem to be fine with that variation when it comes to climate control. Do they use multiple temp sensors? replythrowaway837367 11 hours agorootparentprevIf you just buy a bare sensor, yes, it&#x27;s going to be +&#x2F;-5. They also have a non-linear response which needs to be dealt with as well.If you are only concerned about a 20 or so degree temperature range it&#x27;s not an issue, but if you are trying to read over a 100 degree range, you&#x27;ll want to account for non-linearity as well.Also, accurate and precise to 10ths of a degree isn&#x27;t really attainable unless you do fancy math as the sensor will heat each time you read it. The idea is to take multiple readings and average them but unless you are accounting for the heating of the sensor, your numbers will be garbage.This is for consumer grade sub $50 sensors. Of course you can go fancier but you have to pay for it. reply maxerickson 10 hours agorootparentThis isn&#x27;t something I know anything about, but I know that 1-Wire exists and so on so am able to locate something like https:&#x2F;&#x2F;www.analog.com&#x2F;en&#x2F;products&#x2F;max30207.html pretty easily. $2 in quantity, reports a temperature digitally, accurate to 0.3 C between 0 and 70 C.What is it about that device (or similar) that would put it out of scope? reply Charon77 9 hours agorootparentprevIt&#x27;s probably not that the sensor is bad. It&#x27;s the location of the sensor that is tucked away in the interior foam so that it&#x27;s not reading the air inside the cabin reply junon 11 hours agorootparentprevDepends on the sensor, depends on its calibration (or its lack of such functionality). Often a function of cost and&#x2F;or size, as well as the means by which it measures temp.Scientific sensors are highly accurate and can also be small, but you have a steep cost increase of course. reply johnmaguire 11 hours agoparentprevI wonder if they were concerned someone would use the data to make a decision about leaving a living creature in the vehicle. reply PvtGleb 11 hours agorootparentor medications or food. I can totally understand the legal liability angle 5° F is not a small margin of error. reply Aeolun 11 hours agoparentprevLiterally all of corporate Japan is built on playing it safe. Any innovation that comes out of it seems more like a happy little accident. reply Affric 10 hours agoparentprev5 Rankine is 2.55555555... Kelvin for anyone wondering which is there or thereabouts in the range of an average air conditioner. reply rainbowzootsuit 9 hours agorootparentHenceforth I will be making my fill of liquid helium in my car.&#x2F;s reply Affric 6 hours agorootparentlol… it’s also a hint that google will evaluate the reported conversion as one of pure scaling without any of the transformation that occurs in converting 5 Fahrenheit to 5 Celsius. reply jdjdjdhhd 11 hours agoparentprevIt should remain, at least for mega corps reply hirundo 11 hours agoparentprevMy cheap home thermostat has that frustrating +&#x2F;- 5 degrees F accuracy. Is it very difficult to build an inexpensive 1 degree sensor? reply vGPU 11 hours agorootparentApparently +&#x2F;- 2 degrees is fairly common.One of the problems is the heat from the device itself, as well as limited airflow creating localized hotspots. reply jacquesm 10 hours agorootparentprevIt is if you don&#x27;t want a calibration step. If you do calibrate then it&#x27;s no longer an inexpensive part... reply harrisonjackson 11 hours agorootparentprevI am curious what an \"expensive\" one would actually cost, too... It is a car so already a large purchase. I&#x27;d pay a bit more for an accurate thermostat. reply gnabgib 12 hours agoprevThis has been discussed a couple of times: \"Removal of Mazda Connected Services integration\" (270 points, 78 comments, 10 days ago)[0], \"Mazda&#x27;s DMCA takedown kills a hobbyist&#x27;s smart car API tool\" (83 points, 27 comments, 6 days ago)[1] - the first being the original blog post on Home Assistant, the second referencing that blog post, maybe adding more content and this article referencing both sources (but adding little)[0]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37874220 [1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37921584 reply blorenz 11 hours agoparentThank you for the links. I&#x27;ve been traveling recently and missed those previous discussions. I&#x27;m glad this one was in my purview as the topic at hand is near to me. reply madrox 12 hours agoprevI can only imagine Mazda&#x27;s stake in this is that the OSS project is doing something that Mazda would like to monetize. Otherwise why limit a project that&#x27;s making people fell better about their car purchase?The worst thing to happen to home automation was companies trying to lock customers into their ecosystem without greater interoperability. reply Nextgrid 11 hours agoparentIt&#x27;s not about monetization - that can be done just fine with this third-party client as it calls the same APIs as the official mobile app (thus if the mobile app requires a paid account for a certain action, so will this).This is about \"engagement\". There are a lot of oxygen wasters out there whose careers and paychecks depend on \"engagement\" metrics aka how much time has been collectively wasted wading through the cesspool that their software is. The annoyance and wasted time is the point, and an alternative client (or other way of automating it) goes against that.People often talk about \"bullshit jobs\" around here, but what everyone overlooks (or refuses to acknowledge as it&#x27;s uncomfortable) are all the bullshit jobs in the tech&#x2F;software industry who derive their careers out of end-user annoyance and misery. reply 1-more 11 hours agorootparent> but what everyone overlooks (or refuses to acknowledge as it&#x27;s uncomfortable) are all the bullshit jobs in the tech&#x2F;software industry who derive their careers out of end-user annoyance and misery.I think this is because Graeber had little familiarity with this industry so it doesn&#x27;t appear in the source text. reply jampekka 12 hours agoparentprevWhy almost all companies make their systems difficult to customize and introperate with?Lately I&#x27;ve been fighting with things like iOS, Chromecast, \"smart\" lightbulbs, vacuum robots and smartwatches and all of these go out of their way to lock these down and force their shitty and buggy and probably illegal spyware on me.I&#x27;m honestly asking why this is the default. What do the companies have to lose in people making their products suck less? reply account-5 11 hours agorootparent> Why almost all companies make their systems difficult to customize and introperate with?On purpose, or from incompetence. reply Fauntleroy 11 hours agorootparentprevIt&#x27;s unfortunately more profitable to make it this way, otherwise they wouldn&#x27;t. reply sophacles 11 hours agorootparentIf they all interoped well, then IoT companies would have to compete on quality. A whole market segment would just disappear overnight. reply lost_tourist 6 hours agorootparentprevThere is no incentive to interoperate as it will only cost them profits. Something like that has to be government mandated. reply Angostura 10 hours agorootparentprevWhat spyware does iOS force on you? reply V__ 12 hours agoparentprevMazda (and any big company for that matter) isn&#x27;t a single entity, but thousands of people, teams and interests. Maybe this is a long term business decision, maybe legal doesn&#x27;t differentiate between an open source or an commercial product, or maybe one manager is an idiot. The result is often something incomprehensible from the outside. reply akira2501 12 hours agorootparentIt&#x27;s amazing to me that companies can control their messaging so tightly when it comes to marketing and publicity, but suddenly can&#x27;t get the horse in front of the cart when it comes to legal processes.It&#x27;s understandable, but it fails to be an excuse for the behavior. reply chiefalchemist 11 hours agorootparentI typically view these things as setting a precedent in a KISS sorta way.That is, it&#x27;s easier (and quicker and simpler) just to say no than do things case by case. It also mitigates any possible future fiction.I&#x27;m not saying it&#x27;s right. But knowing how these Big Incs operate it makes sense. reply pwillia7 11 hours agoparentprevI can&#x27;t even use the android auto touchscreen in my miata because you can&#x27;t make it disabled enough at speed so they just disabled the entire thing. Even the android auto dongles that hack that kind of thing I haven&#x27;t had success with.I would bet this is some overzealous safety executive somewhere. reply giobox 11 hours agorootparentND2 Miata owner here, exact same complaints. I believe there are several models in Mazda&#x27;s range with the frankly staggeringly annoying behaviour of disabling the touch screen once the car is moving.In lieu of the touchscreen while cars wheels are rolling, Mazda expect you to use this odd rotary controller in the center console, on the assumption it will be safer.It&#x27;s not safer at all though - you have to turn the rotary controller and watch CarPlay or android auto do the equivalent of a tab key in the browser until it highlights the correct field, then press it in to select. It genuinely takes my eyes off the road longer than just stabbing a touch screen with my finger, as you have to make sure you have got the rotary controller to highlight the right button etc - you can overshoot just like tab in a browser.What&#x27;s even funnier to me is that Mazda have no qualms about putting a switch to disable stability and traction control instantly right next to the steering wheel on a light weight rear wheel drive sports car; burnouts and oversteer are apparently perfectly acceptable usecases for a Miata, but selecting a song from the touch screen while moving? No way guys... reply izacus 10 hours agorootparentDisabling the distracting touchscreens is one of the things that Mazda does right. Pecking at the screen while driving is stupidly dangerous.Pretty much everything you need can be done with at most a few steps of the commander interface which are easy to learn. reply solardev 10 hours agorootparentI just rented a Mazda with one of those terrible rotary dials. Something as simple as finding the nearest gas station, which takes like 2 touches on a touch screen, takes several pushes and inaccurate turns of the dial. It turns a 3-second affair into a 30 second nightmare requiring constant distractions and squinting to see which button or field is currently highlighted. It&#x27;s the worst car UX I&#x27;ve ever experienced, even worse than a Tesla. I&#x27;ll never buy a car with a system like this. It&#x27;s suicide. reply izacus 4 hours agorootparentWhat are you talking about? It&#x27;s like push down to select search box, select gas station icon (first in like, one rotation), press again.If there&#x27;s an active route, you rotate the dial twice quickly to select the search icon.That&#x27;s on Android Auto on my Mazda. It&#x27;s very similar in the built-in nav system.And in no case do you have to lean forward to peck for small touch boxes - the controls are naturally at your hand and each move has a tactile click.Touchscreens are \"souicide\" as more and more distracted driving research shows. reply lost_tourist 6 hours agorootparentprevjust use your phone&#x27;s integration with the dash and use siri or google ? reply busterarm 9 hours agorootparentprev> Miata, but selecting a song from the touch screen while moving? No way guys...It&#x27;s a Miata. You should be listening to the sound the car makes. Car speakers sound like shit with the top down at highway speeds anyway.The AC in my RX7 hasn&#x27;t been charged in 20 years either and I live in the southeastern US. Driving these cars is a full experience... reply sliken 12 hours agoparentprevMazda is likely jealous of BMW for charging monthly for seat heaters, OSS tools to control the car threaten that. reply salzig 12 hours agorootparentBMW doesn&#x27;t anymore: https:&#x2F;&#x2F;techcrunch.com&#x2F;2023&#x2F;09&#x2F;07&#x2F;bmw-feels-the-heat-stops-c...Looks like the pain was big enough. reply mikestew 11 hours agorootparentToo late, BMW was already in our blindspot when we bought a new car. Just like how no one reads the newspaper retraction, no one sees you walk back a bad decision once they&#x27;ve written you off. So don&#x27;t make dumb decisions in the first place, even if it&#x27;s \"just to see if it sticks\".As a result of the BS in TFA, I&#x27;d put Mazda in the same corner, except they were never a contender because they don&#x27;t build cars that I might buy (well, okay, maybe a Miata). reply BHSPitMonkey 12 hours agoparentprevExcept that this library just calls the same APIs as the official app, using the user&#x27;s own credentials. Any subscription-gated features would just surface through the API as they would in the app, i.e. \"this operation isn&#x27;t supported on your plan\" etc. so there is no paywall bypass going on here. reply quickthrowman 12 hours agoparentprev> The worst thing to happen to home automation was companies trying to lock customers into their ecosystem without greater interoperability.It’s not just home automation, commercial automation is full of single source vendor ‘solutions’.Building automation: Johnson Controls, Carrier, Siemens, Honeywell, Trane (and others) all provide proprietary controllers and software. There are some ‘open’ systems where multiple dealers sell a product line, Distech and Alerton are the big ones that I’ve seen.Fire alarm: Johnson Controls (Simplex), Siemens, Honeywell, Bosch. Honeywell has their own internal product line that they sell, as well as two other lines that they have dealers sell (Notifier and Silent Knight).Nurse call, duress, security, surveillance (and probably other low-voltage&#x2F;control systems I’m not familiar with) have the same problems with proprietary systems. reply _kb 11 hours agorootparentThe same also extends into media systems and commercial AV. There’s a disturbingly large portion of the product space across domains that’s actively hostile to any form of integration outside of their own shambles of a product ecosystem. reply quickthrowman 10 hours agorootparentAh yes, Crestron is the one I am most familiar with in that segment. reply Dalewyn 12 hours agoparentprev>Otherwise why limit a project that&#x27;s making people fell better about their car purchase?It could be argued Mazda doesn&#x27;t want to be on the hook for end-user customizations that may potentially jeopardize safety.Now yes, if a driver modifies his car&#x27;s code or the results of that code and causes an accident that&#x27;s on him and not Mazda. But you and I and everyone here all know the media will jump at the chance to plaster sensational headlines for click monies. reply bobsmooth 12 hours agorootparentIf the API can do something to make the car unsafe that&#x27;s on Mazda. reply klyrs 11 hours agorootparentIf you void the warranty by touching the API, they&#x27;ve put it back on you. reply Dalewyn 9 hours agorootparentprevThanks for beautifully proving my point. reply otikik 12 hours agoprevI am now pissed that I have a Mazda. Mission accomplished, legal team, you undid all the efforts of the engineering and marketing departments in one single action. reply hermitcrab 12 hours agoparentI&#x27;ve had 2 Mazdas in the past. A bit less likely to buy another one now. reply liquidpele 11 hours agoparentprevYou say that like they weren’t told to do this by the executive team. reply lallysingh 11 hours agorootparentI think you&#x27;re assuming more awareness and communication between groups than probably exists. reply sli 11 hours agorootparentExecutives are necessarily responsible for the people under them, that&#x27;s part of the job. reply aksss 11 hours agoparentprevWhich is ironic for Mazda, because at least like model year 2019 and prior you could literally telnet into the CMU and do all sorts of hacks to it. Whether it was intentional or not, Mazda has enjoyed a bit of a sheen of being kinda hack&#x2F;maker friendly if you play in that space.https:&#x2F;&#x2F;mazdatweaks.com&#x2F;serial&#x2F; reply wuuza 11 hours agorootparentThey didn&#x27;t intend it, but they should have since they&#x27;d probably end up with a better end-user experience ala Rockbox&#x2F;LineageOS. The community added some cool features and worked around some glaring bugs until Mazda clamped down by specifically nuking the mods on updates. God forbid anyone embarrass them by making their crappy software better, like pausing a stream when \"Mute\" was hit instead of letting the stream run while muted. How about this? If you used a USB stick full of music it showed the files in FAT order, not sorted by filename or ID3 tags. It would also just randomly forget the resume point, and revert to playing the \"first\" file on the disk. So instead of Amon Amarth blasting my ears in this case, I had to both create a file named \"0000Silence.mp3\", and run a special command after every disk update to rewrite the FAT so the FAT order equaled alphabetical order. reply daleswanson 8 hours agorootparent> It would also just randomly forget the resume point, and revert to playing the \"first\" file on the disk.Is there any hack that fixes this? It&#x27;s my number 1 annoyance with my Mazda. reply vsareto 11 hours agoparentprevIt doesn&#x27;t make sense to let one fuck up from a non-core part of the business destroy your entire perception of them. reply ImPostingOnHN 10 hours agorootparentThis sets the precedent that if you find a way to improve your life using Mazda, you have to worry about Mazda going out of their way to break you.Like, the literal least Mazda could have done to support their users here was nothing, and they found a way to do worse than that. reply tommek4077 11 hours agoprevJust dont put your name on projects like this. Had to learn myself the hard way 15 years ago. Just do it, fly under the radar, stay pseudonymous, go the hacker way. reply asynchronous 11 hours agoparentYou’re right but I’m sad that that is the world we live in. reply m4jor 11 hours agoparentprevCan&#x27;t stop the signal! reply j1elo 11 hours agoprevHow can they really stop this development?I mean, if I were the author, had put my effort and time into solving my own itch and released it as FOSS, only to receive a Cease and Desist, my itch would still probably be there, but GitHub would probably comply and close the repo.So I&#x27;d just cease, desist, and my project would suddenly appear again in some other Git server. Surely, without my name on it, and hosted from whatever country seeming less likely to follow up on similar requests. reply kazinator 4 hours agoprev> GitHub (where the software was hosted)I.e. actually GitHub took the stuff down, not Mazda.Self-host your shit for Pete&#x27;s sake. reply Tabular-Iceberg 12 hours agoprevDMCA? Does Mazda think we&#x27;re going to start downloading cars because of this? reply steve_adams_86 12 hours agoparentI mean, we wouldn’t do that, would we? reply sobkas 11 hours agoparentprev> DMCA? Does Mazda think we&#x27;re going to start downloading cars because of this?Or do something even worse, have functionality we didn&#x27;t paid Mazda to have. reply activescott 11 hours agoprevI just happen to read about DMCA exemptions legalities recently (which I submitted at https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37961007). Turns out that exemptions to DMCA are recommended every three years. I noticed one especially relevant to this one under the section category of \"Proposed New or Expanded Exemptions\":> Proposed Class 7: Computer Programs— Vehicle Operational Data > MEMA petitions for a new exemption to ‘‘access, store, and share vehicle operational data, including diagnostic and telematics data’’ from ‘‘a lawfully acquired motorized land vehicle or marine vessel such as a personal automobile or boat, commercial vehicle or vessel, or mechanized agricultural vehicle or vessel.’’ 182 The petition limits circumvention to ‘‘lawful vehicle owners and lessees, or those acting on their behalf.’’ > The Office encourages proponents to develop the legal and factual administrative record in their initial submissions, including describing with specificity the relevant TPMs and whether their presence is adversely affecting noninfringing uses, whether eligible users may access such data through alternate channels that do not require circumvention, and the legal basis for concluding that the proposed uses are likely to be noninfringing. In general, the Office seeks comment on whether the proposed exemption should be adopted, including any proposed regulatory language.- From Page 14, of October 19, 2023 – Notice of Proposed Rulemaking at https:&#x2F;&#x2F;www.govinfo.gov&#x2F;content&#x2F;pkg&#x2F;FR-2023-10-19&#x2F;pdf&#x2F;2023-2...The US Copyright Office goes on to say *they want feedback on this potential exemption*:> The Office encourages proponents to develop the legal and factual administrative record in their initial submissions, including describing with specificity the relevant TPMs and whether their presence is adversely affecting noninfringing uses, whether eligible users may access such data through alternate channels that do not require circumvention, and the legal basis for concluding that the proposed uses are likely to be noninfringing. In general, the Office seeks comment on whether the proposed exemption should be adopted, including any proposed regulatory language.Note that final sentence! reply teeray 11 hours agoprevHopefully this triggers a Streisand Effect of this code appearing everywhere. Something like “this JPG is also a git repo” reply matheusmoreira 7 hours agoprev> It&#x27;s unclear what legal basis Mazda has to order a DMCA takedownThere&#x27;s probably none. They&#x27;re probably just leveraging the high costs of a legal defense to bully individuals into submission. Corporations have armies of lawyers and can afford to spend years fighting in court, this guy can&#x27;t. The threat of lawsuits is equivalent to a threat to set his money on fire.Check out their \"justifications\":> The automaker argued that Rothweiler&#x27;s work contained code that violated its copyrights; used its \"proprietary API information\" to create more codeSeriously doubt that. It&#x27;s not like they gave this guy access to their source code or internal documents.> and that the integrations provided functionality identical to what currently exists in Mazda&#x27;s own mobile appsNot protected by copyright. reply lfmunoz4 11 hours agoprevThings like this just make me think, if you write code and aren&#x27;t making money no point in hosting it in US. I.e, just put it on Gitee reply senorrib 8 hours agoprevMan, this enrages me so much. But I&#x27;m glad I live in a third world country where access to legal defense is relatively cheap. Here I would just tell them to piss off and get on with my life. reply lovemenot 11 hours agoprevI suspect this decision would have been almost a no-brainer for Mazda execs in Japan.Japanese culture tends to white-list permitted activities.The API was designed for a purpose other than what this developer used it for. Therefore his code is proscribed. reply walterbell 12 hours agoprevCue TV commercial from Mazda competitors: Own The Road with shots of winding scenic roads, auto dashboard and tripped-out Home Assistant dashboard. Many manufacturers appear to be OK with especially resourceful owners optimizing their cars in this way. Home Assistant&#x27;s integration library features at least six automakers, including BMW and Volvo, while Tesla recently published details of its new, official, open API for third-party developers to employ. reply daft_pink 12 hours agoprevI would never purchase a Mazda after this. reply xbar 11 hours agoprevThe marketplace for autos is still broad enough for me to purchase a car that meets my needs.No Mazda does. reply givemeethekeys 11 hours agoparentNot anymore, thats for sure. reply jms703 10 hours agoprevI&#x27;m in the market for a new car and I&#x27;m deciding between Mazda, Acura, and Toyota. I&#x27;m quite curious to see how these other manufacturers are treating developers. reply izacus 10 hours agoparentEven worse. I mean... What developers? Did you see any? reply quantum_state 10 hours agoprevThe car maker can void some warranty but it has no right to do what it did. The car is the property of its owner who can do whatever with it. reply hanszarkov 11 hours agoprevI&#x27;m one engineer that won&#x27;t be buying a Mazda reply jonoc 12 hours agoprev\"Even if I believe that what I&#x27;m doing is morally correct and legally protected, legal processes still have a financial cost. I can&#x27;t afford to take on that financial risk for something that I do in my spare time to help others.\" - this is very logical and exactly what I would have done but it still makes me very sad that this is the way the world works right now :( reply all2 12 hours agoparentThe process is the punishment. Average Joe cannot go toe-to-toe in the legal system as it stands right now. The one with the most money nearly always wins, and - as in this case - the threat of financially ruinous litigation is enough. reply akudha 12 hours agorootparentThe one with the most money nearly always winsThis is true in American elections too. I can’t remember the exact number, but something like 80% (or more) of elections are won by the candidate with more money.When everything is tied to money like this - legal, democracy etc, the little guy is always going to lose reply liquidpele 11 hours agorootparentCareful there because it’s more likely that the already more popular person also happens to be the person that gets the most donations. reply ronsor 12 hours agorootparentprevAnd the solution is to nerf copyright into the dirt like you&#x27;d nerf an overpowered item in a game. reply AceJohnny2 12 hours agorootparentAre you aware that copyright law is the foundation of FOSS licenses? reply jimnotgym 12 hours agorootparentYou wouldn&#x27;t need it if copyright didn&#x27;t exist in the first place reply AceJohnny2 12 hours agorootparentOf course you would. For example, thanks to copyright law, Linksys was forced to share their Linux customizations to run on router hardware, which led to the creation of the OpenWRT project.Without copyright law, any actor can take your open system and close it. reply Filligree 11 hours agorootparentA lot of people are fine with that. Look at everyone who uses the BSD or MIT license. reply AceJohnny2 10 hours agorootparentThe fact that they have the option to choose it is different than it being the only possibility. reply aleph_minus_one 10 hours agorootparentprev> You wouldn&#x27;t need it if copyright didn&#x27;t exist in the first placeNo popular open source license that I am aware of attempts to emulate a no-copyright situation:If there was no copyright, you could not force anybody to provide the source code of any derivative work (situation for copyleft licenses). On the other hand, in a no-copyright situation, you are not able to sue anybody who attempts to reverse-engineer such a derived binary blob and publish the reverse-engineered source code.Thus, an open-source license that attempts to emulate a no-copyright situation would in my opinion have clauses like the following:- you are allowed to create binary-only derived works, and are allowed to sell copies of it- you must not sue anybody who redistributes these copies (even for money)- you must not disallow any licensees to reverse-engineer these executables- you must not disallow any owner of a copy to create any derivative work (even using reverse-engineering techni, as long as this work is licenses under this license. This in particular means that, if you create a derivative work, you have to take care that you cannot redistribute copies that (statically) link the work with parts for which this is disallowed reply maxerickson 12 hours agorootparentprev\"Free Software\" requires making source code available to users. If copyright didn&#x27;t exist, there would not even be a hypothetical mechanism to require that of publishers. reply JumpCrisscross 12 hours agorootparentprev> Average Joe cannot go toe-to-toe in the legal systemThis is sort of the point of arbitration. reply ceejayoz 12 hours agorootparentIn theory.In practice, the company still has a big advantage in arbitration.https:&#x2F;&#x2F;www.gsb.stanford.edu&#x2F;insights&#x2F;why-binding-arbitratio...> The problem is that companies generally know more than customers about an arbitrator’s record and thus are likely to strike out arbitrators who are more inclined to rule in favor of consumers. On average, each securities firm in the study had been involved in 81 other arbitrations. In non-securities disputes, such as those with cellular carriers, the average company had been in 133 hearings. By contrast, most consumers have never been involved in a previous arbitration and tend to strike arbitrators randomly. As a result, the firms’ informational advantage leads to systematically biased outcomes. reply JumpCrisscross 12 hours agorootparent> the company still has a big advantage in arbitrationNot as big as in litigation. Yes, companies have familiarity. But the win rates in arbitration are way more favourable. Because you can’t starve your opponent as a strategy. reply ceejayoz 11 hours agorootparentWin rates are one aspect. Win amounts are another. reply JumpCrisscross 11 hours agorootparent> Win rates are one aspect. Win amounts are anotherFor JAMS and AAA, compared to federal courts, after accounting for litigation costs, on average, no. (At the tails, yes. But this doesn&#x27;t apply if you can pull off federal litigation.) Do you have research to the contrary? reply ljm 12 hours agorootparentprevIf the arbiter is publicly funded and therefore without bias, sure. In the UK that is ACAS. If the business you have a problem with is paying for its own arbitration service then you are automatically on the back foot. reply JumpCrisscross 10 hours agorootparentThe problem is more firms having a voice in selecting the arbitrator than them paying for it [1]. TL; DR If you&#x27;re going into arbitration, don&#x27;t be passive about the selection process.[1] https:&#x2F;&#x2F;www.hbs.edu&#x2F;ris&#x2F;Publication%20Files&#x2F;19-046_6706ef32-... reply akira2501 12 hours agoparentprevThe DMCA has been a net negative for America. It didn&#x27;t actually afford any of the intended protections to the industries that bought it and it has destroyed the concept of \"ownership\" in an increasingly digital world. reply Waterluvian 12 hours agorootparentAnd America didn’t just harm itself with DMCA. We all suffer from this mistake. reply alphazard 12 hours agoparentprevI think we&#x27;ve made a mistake by linking our real world identities to the software we write. If the author released this under a pseudonym, and hosted the git servers in a country without strong copyright enforcement, there&#x27;s very little Mazda could do to take it down. It&#x27;s too late for that now since Mazda knows who he really is. reply shiroiuma 5 hours agorootparentIt&#x27;s not too late for that; the author just doesn&#x27;t want to be bothered. If he really wanted to, he could move the code to that other country, and put it up under a pseudonym. If anyone asks, he can just claim he doesn&#x27;t know who that person is, and he has nothing to do with it: how can they disprove him without literally spying on him? The code is open-source: literally anyone could have made a fork of the repo while it was still up, and then posted it somewhere else. reply pdonis 12 hours agoparentprevThis seems like a case where an organization like the EFF could help. Does anyone know if they are aware of this specific incident? reply thomastjeffery 12 hours agorootparentThe EFF would still need a defendant to defend. It sounds like that person is not interested in pursuing a legal battle, so we have already met the end of this road. reply happytoexplain 12 hours agorootparentI see this attitude a lot where legal is involved (which is a lot of places). It&#x27;s a very peculiar sort of \"if this then that\" which seems to subvert normal human communication. E.g. in this case, a standard human train of thought would be that, because one of the reasons given for not pursuing it is funding, the EFF might offer to fund this person, who, circumstances now being different, might then agree to be the defendant. Now maybe there is a problem with that, but my point is that your response seems to choose not to acknowledge it. I don&#x27;t think it&#x27;s malicious - I think there is just something about the way legal works that trains people to think and speak in this slightly non-human way. reply thomastjeffery 12 hours agorootparentIn my perspective, it&#x27;s less about the presentation, and more about the motivations involved.If the EFF is motivated to reach out to the original DMCA recipient, then they could definitely present this avenue. That leads us to the next question, is the original DMCA recipient interested in pursuing a (now funded) defense? If not, are they interested in handing it off to someone else? Who? Would that person be an effective defendant?Really, what we are doing here is speculating on one person&#x27;s level of disinterest in pursuing the legal defense of their work. reply tough 10 hours agorootparentWhat about another person willing to continue with a fork?What about a DAO specifically built for that purpose exclusively?Just looking how to fuck back those lawyers reply thomastjeffery 9 hours agorootparentI would love to see that happen. I also, unfortunately, doubt it will. reply tough 5 hours agorootparentSeems it would require to fork the whole home assistant repo https:&#x2F;&#x2F;github.com&#x2F;home-assistant&#x2F;core&#x2F;pull&#x2F;101849#issuecomm... replyandix 12 hours agorootparentprevThey could transfer the ownership of the code to someone else. This person&#x2F;entity could put it back up and wait for Mazda attacking them. reply evan_ 12 hours agorootparentWouldn&#x27;t Mazda then go after both parties? reply andix 11 hours agorootparentUsually you can&#x27;t go after people for creating content, even if it&#x27;s a copyright violation. They also can&#x27;t \"uncreate\" it, they can&#x27;t delete the concepts from their brain. You can only stop them from publishing&#x2F;selling it.In this case the code was on GitHub before, so they wouldn&#x27;t even need to give the code to the new target entity, this entity could just copy it from an undisclosed person who has a copy. reply thomastjeffery 12 hours agorootparentprevThe tool Mazda is using is DMCA. That applies explicitly to whomever is hosting the content. More specifically, it applies to whomever Mazda sends the DMCA notice to. reply oh_sigh 11 hours agorootparentprevTransfer of ownership isn&#x27;t even required, since it was open source code hosted on github. All someone needs to do is re-host the files, and wait for the DMCA notice to push back on it. reply andix 11 hours agorootparentTrue. It should also be possible to maintain it outside of the US, where the DMCA doesn&#x27;t apply. In some European countries Mazda probably wouldn&#x27;t have a lot of options to take it down. reply pdonis 8 hours agorootparentprevThey could reach out to him and offer to pay his legal expenses. They could even offer the services of lawyers they are familiar with. IIRC they have done that in similar cases in the past. reply j1elo 10 hours agoparentprev> this is very logical and exactly what I would have doneI made a comment regarding this, before realizing yours, so I&#x27;m kinda repeating myself here, but it&#x27;s something that piques my curiosity:What would stop you from just continuing in a different repo (even different host like Gitee), with a pseudonymous, and claim that you have no idea who&#x27;s that mysterious person that forked and continued working on the project? reply dtgriscom 11 hours agoparentprevRight or wrong, the legal system (in the US and elsewhere) is to be feared and avoided. I&#x27;ve served jury duty several times in the US, and each time it looked like we might be empaneled, the defendant settled with the DA. I&#x27;ve no idea if they were actually guilty of what they were accused of, but in any case they decided that being deemed guilty was less onerous than going through (and paying for counsel in) a jury trial. reply prepend 12 hours agoparentprevI wish GitHub would do more to protect developers from this bullshit.I know they aren’t required to, but I remember the olden days when more companies would fight dmca requests. But I suppose they were much less common then.The EFF might help, but even expecting individuals to appeal to the EFF is probably too much work and too much risk.I’d like to see GitHub partner with EFF to have first look at these requests and choose to fight ones that seem invalid. I’d donate to they cause. reply maxerickson 11 hours agorootparentWhat&#x27;s it look like? The next step to fight this is for the user of the Github service to file a counter notice and wait to see if Mazda files a copyright infringement lawsuit against them.It probably doesn&#x27;t make sense for Github to indemnify them, and short of that, there&#x27;s not really a lot of convincing they can do if someone isn&#x27;t interested in engaging in litigation with some huge company. reply prepend 10 hours agorootparentThey could auto file a counter notice. They could provide free legal council to help the user file. They could route to EFF or others to file counter notices.They could even sue for damages from false claims since API can’t be copyrighted.There’s tons they could do. Microsoft has immense resources and far greater than Mazda. reply maxerickson 10 hours agorootparentThey don&#x27;t have standing to auto file a counter notice. And then if someone accidentally publishes something copyrighted to github, they probably don&#x27;t want to go through a lawsuit.I looked at the code some, there are some app secrets stored and used, so they probably have at least a thin claim. reply throw_a_grenade 12 hours agoparentprevHe should have added \"I believe buying Mazda was a mistake and I encourage everyone to avoid this brand until they get their Legal together\".They need to be deterred. They should know that every time they do this, people will start recommending their competition. reply Dalewyn 12 hours agoparentprevAs President Andrew Jackson once said, \"John Marshall has made his decision, now let him enforce it.\"As it turns out, you need both the piece of paper underwriting your rights and the force necessary to exercise them. reply cooper_ganglia 12 hours agorootparentMy freedom and financial future aren&#x27;t the kinds of things I&#x27;d like to test their enforcement with. We need laws that prevent this type of bullying behavior. reply Dalewyn 9 hours agorootparentYou&#x27;re back to square one: You have to exercise the laws preventing that bullying.Lines of ink on plant fiber by themselves have never stopped anyone. reply shiroiuma 5 hours agorootparentSo why don&#x27;t you do this then? The author doesn&#x27;t have to be the one to take the risk: YOU can do it yourself! Just get a copy of the code and post it up on your own account, under your own name. reply0xbadcafebee 12 hours agoprev> Mazda has invested tremendous time and resources to develop confidential and proprietary information including computer code used by company. Recently certain Mazda Information, including proprietary API information, was used to create code and information posted to GitHub.com identified in repository of bdr99 ([private]). This repository contains code developed in python (https:&#x2F;&#x2F;github.com&#x2F;bdr99&#x2F;pymazda) and javascript (https:&#x2F;&#x2F;github.com&#x2F;bdr99&#x2F;node-mymazda), and appears to have been uploaded and used to create computer code associated with home-assistant.io and mobile applications. MNAO analyzed some of the code and determined that the code provides functionality same as what is currently in Apple App Store and Google Play App Store. We are requesting immediate removal of code from Github, brd99.Since when is an API call proprietary information? Can they even claim a DMCA against it? That&#x27;s like claiming DMCA for telling someone how to flick a light switch. reply liquidpele 11 hours agoparentIt’s almost certainly not a legal takedown request, but this is always been an issue with the DMCA… it’s far too easy to make fraudulent requests, and there is almost never real punishment for them because they require financial harm, which is going to exclude anything except other companies. reply deepsun 12 hours agoparentprevAnd I believe Oracle vs. Google re. Java API ruled out that APIs cannot be copyrightable either. reply a2xd94 12 hours agoprev [–] Hey loyal Mazda fan,That money you could be making, yeah we don&#x27;t like you getting it instead of us, so cough it up! Also, while we&#x27;re at it, cool idea...thanks for the work! Here&#x27;s nice thankful lawsuit for your hard work. We&#x27;ll go ahead and privately fork that repo and totally not rip your functionality off and somehow manage to mess it up while overcharging for it! :)Worst regards, thx for the moneys and screw you,Mazda replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Mazda issued a cease-and-desist order to a developer who created open-source code that enhanced the functionality of Mazda cars, stating it violated copyright and replicated existing features.",
      "The developer complied with the order to avoid legal action, which has led to disappointment amongst Mazda owners who used the code to elevate their driving experience.",
      "This incident induces debates over the balance between cybersecurity, copyright laws, and the concept of fair use, along with an automaker's potential disregard of customer preferences for customization and autonomy in their vehicles."
    ],
    "commentSummary": [
      "Mazda has faced incidents of controversy due to their reluctance to permit customization and third-party access to their vehicles, by sending cease-and-desist letters and DMCA takedown notices to developers who created various integrations.",
      "The auto company justified its actions by citing legal, safety, and copyright reasons, but critics argue that it is limiting customization for profit and liability reasons.",
      "The discussion underscores the difficulties of interoperability and diminishing sense of ownership in the digital world, with commenters expressing displeasure at DMCA and suggesting alternative ways to safeguard developers and open-source code."
    ],
    "points": 292,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1698092326
  },
  {
    "id": 37983903,
    "title": "Woman wins 12-year legal battle against Google",
    "originLink": "https://www.abc.net.au/news/2023-10-23/janice-duffy-wins-12-year-legal-battle-against-google/103008954",
    "originBody": "This site uses cookies The ABC uses cookies to improve your experience. Learn more about how we use cookies ACCEPT ALL COOKIES ABC REQUIRED COOKIES ONLY SKIP TO MAIN CONTENT ABC News Homepage Sydney Change location 28°C Celcius Max Min of 14° Celcius Search Log In Log In More from ABC Just In Watch Live Voice Referendum Politics World Business Analysis Sport Science Health Arts Fact Check More ABC News Homepage Adelaide woman receives settlement after a lengthy battle against tech giant Google SHARE News Ticker BUSHFIRE WARNING An Emergency Warning is in place for Cypress Gardens and Millmerran Downs in Queensland. Keep up to date with ABC Emergency 2 / of 2 Adelaide woman receives settlement after a lengthy battle against tech giant Google By Evelyn Leckie Posted Yesterday at 8:30pm Dr Janice Duffy sued Google twice, mostly unrepresented, and won.(ABC News) Share this article abc.net.au/news/janice-duffy-wins-12-year-legal-battle-against-google/103008954 Link copied COPY LINK SHARE A line has finally been drawn under an Adelaide woman's 12-year legal battle against global tech giant Google after she sued the company twice, mostly unrepresented, and won. Key points: Dr Janice Duffy successfully argued in 2015 and 2023 that Google published defamatory extracts She reached a confidential settlement with the company which would pay her damages and legal costs She said it's never been about the money, but holding Google accountable. Dr Janice Duffy successfully argued in 2015 and 2023 that Google published defamatory extracts from American website RipOff Report on its search engine page, despite her notifying the company and asking for the posts to be removed. She was set to start her damages trial on Monday for her most recent case but reached a confidential settlement with the multibillion-dollar company, which would pay her damages and legal costs. It is the second time the company will be coughing up, after she received more than $100,000 in damages in 2015. The former SA Government researcher said it had never been about the money, but holding Google accountable. \"Google made me feel like I was worth nothing,\" Dr Duffy said. \"They just made me feel like I was this nothing human being – because I stood up to them.\" A dark place Dr Duffy said the nightmare began after first discovering defamatory information about her on the widely-used platform. \"I found it very difficult to leave the house, I used to lay on the couch and watch documentaries about serial killers to make me feel normal,\" she said. She joined a volunteer dog rescuing network during that dark time. \"I started it because, basically I wanted someone to look after my dog – if I didn't survive it and I honestly didn't think I was going to survive it.\" Janice Duffy successfully sued the Internet giant Google for defamation.(ABC News: Candice Marcus) She contemplated taking her life, saying it destroyed her career in research. But she said she pulled together all the strength she had ahead of her first trial, when she realised she would have to represent herself with dwindling finances to afford legal fees. \"It was just horrific — truly horrific — when I realised I had to do the trial myself … the only things that I had was an old printer and my research skills,\" she said. Google used the defence of innocent dissemination, but even after her David and Goliath-like feat, similar defamatory information continued to appear on the site after her first case. Fighting back Paul Heywood-Smith KC helped Dr Duffy after her initial proceeding. \"[Google] lost the case, but in their arrogance they continued to broadcast it and Janice Duffy wasn't prepared to accept that.\" Paul Heywood-Smith KC assisted Janice Duffy in some of her legal proceedings.(ABC News: Lincoln Rothall) Mr Heywood-Smith said her triumphs after fighting the giant, mostly unrepresented, were remarkable. \"Google has the capacity to deep pocket anyone –make their legal costs and the costs of litigating so expensive that most people couldn't even contemplate it,\" he said. The recently retired KC said Dr Duffy's landmark wins could assist other potential plaintiffs. \"When somebody goes into their solicitor and asks, 'have I got a case?' and the solicitor goes to the law on defamation — they will see the case of Duffy against Google and it's clear cut — and so she's done a wonderful service.\" Emotional toll Independent expert in technology and law, Joel Lisk from Flinders University, said there may not be a large amount of similar proceedings in Australia — given the expense, time and emotional toll it would take on potential plaintiffs. \"It should be the approach of last resort – you should be able to settle these matters or request Google to remove them – but it does strengthen the defamation position here in Australia.\" He says Dr Duffy's case could put more responsibility on search engine companies to monitor what appears on its websites more closely. \"Following this proceeding, Google will likely look at the judgement and take steps and look at how it manages and produces data – but there's only so many things you can do without significant technological innovation.\" Google did not respond in time to the ABC's request for comment on Dr Duffy's case. Posted Yesterday at 8:30pm Share Related Stories Adelaide woman wins second defamation case against Google over search results Google ordered to pay researcher more than $100k for defamation Adelaide woman sues Google for defamation More on: ADELAIDECOURTS AND TRIALSINTERNETLAW, CRIME AND JUSTICESAUNITED STATES Top Stories RBA 'will not hesitate' to increase rates if inflation takes longer to return to target than forecast, Bullock warns NDIS providers banned and fined $1m, independent review ordered after ABC investigation LIVE Four Australians safely evacuate West Bank via Jordan, dozens more remain 'Living a lie': Family of Australian trapped in Gaza say they are helpless and frustrated at Australia's response Search underway for woman missing in Kakadu National Park for almost a week 'I thought I was going to burn': Kings Park closed to public as firefighters battle five separate bushfires Homes lost as 10m tall flames engulf bushland in southern Queensland Fossil fuels to peak within the decade, according to International Energy Agency A coronial inquest into the Christchurch attack will look at what NZ 'may learn from this atrocity' What are 'long dogs' and why are they driving adult Bluey fans crazy? Herald Sun cartoonist defends nude catwalk depiction of Premier Jacinta Allan The Rock says French wax figure needs 'updating' over skin tone Plan to light Opera House in Israel colours caused senior police concern over escalating tensions, documents reveal 'Staggeringly unlikely': Outback newsagent's six division one lotto winners a statistical phenomenon I want to have a baby but can't afford to, and that hurts Popular Now Don't miss news that matters to you. Log in to ABC today to get a more personalised experience tailored to your preferences. GET STARTED 1. NDIS providers banned and fined $1m, independent review ordered after ABC investigation 2. 'I thought I was going to burn': Kings Park closed to public as firefighters battle five separate bushfires 3. What are 'long dogs' and why are they driving adult Bluey fans crazy? 4. The Rock says French wax figure needs 'updating' over skin tone 5. Herald Sun cartoonist defends nude catwalk depiction of Premier Jacinta Allan 6. RBA 'will not hesitate' to increase rates if inflation takes longer to return to target than forecast, Bullock warns Top Stories RBA 'will not hesitate' to increase rates if inflation takes longer to return to target than forecast, Bullock warns NDIS providers banned and fined $1m, independent review ordered after ABC investigation LIVE Four Australians safely evacuate West Bank via Jordan, dozens more remain 'Living a lie': Family of Australian trapped in Gaza say they are helpless and frustrated at Australia's response Search underway for woman missing in Kakadu National Park for almost a week Just In Rarely seen ephemeral cloud iridescence appears above WA country town 54m ago 54 minutes ago 'I thought I was going to burn': Kings Park closed to public as firefighters battle five separate bushfires 1h ago 1 hours ago Plan to light Opera House in Israel colours caused senior police concern over escalating tensions, documents reveal 1h ago 1 hours ago RBA 'will not hesitate' to increase rates if inflation takes longer to return to target than forecast, Bullock warns 1h ago 1 hours ago More Just In Back to top Footer ABC News homepage More From ABC NEWS We acknowledge Aboriginal and Torres Strait Islander peoples as the First Australians and Traditional Custodians of the lands where we live, learn, and work. SECTIONS ABC NEWS JUST IN WATCH LIVE VOICE REFERENDUM POLITICS WORLD BUSINESS ANALYSIS SPORT SCIENCE HEALTH ARTS FACT CHECK CORONAVIRUS OTHER NEWS IN LANGUAGE 中文 BERITA BAHASA INDONESIA TOK PISIN CONNECT WITH ABC NEWS FACEBOOK TWITTER INSTAGRAM YOUTUBE APPLE NEWS MORE FROM ABC NEWS Contact ABC NEWS This service may include material from Agence France-Presse (AFP), APTN, Reuters, AAP, CNN and the BBC World Service which is copyright and cannot be reproduced. AEST = Australian Eastern Standard Time which is 10 hours ahead of GMT (Greenwich Mean Time) Editorial Policies Accessibility Help Contact Us About the ABC Privacy Policy Terms of Use © 2023 ABC",
    "commentLink": "https://news.ycombinator.com/item?id=37983903",
    "commentBody": "Woman wins 12-year legal battle against GoogleHacker NewspastloginWoman wins 12-year legal battle against Google (abc.net.au) 264 points by defrost 23 hours ago| hidepastfavorite183 comments testplzignore 22 hours agohttps:&#x2F;&#x2F;globalfreedomofexpression.columbia.edu&#x2F;cases&#x2F;duffy-v... has some actual details of what this is about. reply adriand 22 hours agoparentThis is an interesting detail - Google&#x27;s autocomplete suggestions for the plaintiff&#x27;s name were found to be defamatory:> Dr. Duffy became aware that when people searched her name on Google’s search engine, the Google search bar provided an autocomplete suggested search term of “janice duffy psychic stalker”. [...] Google was also found [by the court] to be the “publisher” of autocomplete suggestions that came up when a user began to type the individual’s name in its search barBe careful with your UI! reply unsupp0rted 21 hours agorootparentIt&#x27;s not so much \"be careful with your UI\" as \"when you&#x27;re actually notified that your UI is treading on somebody, you better stop (treading on that particular person)\". reply code51 21 hours agorootparentBut how can you notify Google of anything?Even when you report an important bug, bots and \"product experts\" just shrug it off. The only \"notification\" for Google is a lawsuit it seems. reply lesuorac 20 hours agorootparent> Woman wins 12-year legal battle against Google> But how can you notify Google of anything?Clearly with a lawsuit. Per the other article in this thread [1], Google did nothing when she notified them but de-indexed the webpage following her initial lawsuit.[1]: https:&#x2F;&#x2F;globalfreedomofexpression.columbia.edu&#x2F;cases&#x2F;duffy-v... reply braiamp 18 hours agorootparentThat&#x27;s the most expensive way. Wonder why should it be that way? reply BartjeD 17 hours agorootparentSo that 99.999% percent of folks won&#x27;t bother them. reply lesuorac 14 hours agorootparentprevWell their contact us also lists an address and a phone number [1].But also, I mean if your qualm is small there&#x27;s a thing called \"small claims court\" where you can get it settled probably cheaper than otherwise if you put a value on your time.[1]: https:&#x2F;&#x2F;about.google&#x2F;intl&#x2F;ALL_us&#x2F;contact-google&#x2F; reply wahnfrieden 17 hours agorootparentprevBecause it&#x27;s the cheapest way for Google.What else would motivate them to do something? Externalities that harm others are just gravy for business until it threatens their profit. Awful externalities can even be a sign of competitive edge if they manage to avoid them bring priced in - social responsibility is anti growth. reply munk-a 21 hours agorootparentprevIf a few people pursue a lawsuit against them I&#x27;m pretty sure they&#x27;ll get more responsive. TBH Google is notoriously awful to communicate with - I don&#x27;t know if you&#x27;ve ever dealt with one of their B2B products but they even hate talking to companies that pay them 10k a year. reply justinbaker84 18 hours agorootparentThey also hate talking to people who manage $200K per month advertising budgets. Even at that level advertisers just get very low wage support staff in India who can&#x27;t do much. reply p3rls 10 hours agorootparentI thought the 3:30AM emails were just because they missed me and couldn&#x27;t sleep:( reply ezoe 19 hours agorootparentprevThe civil lawsuit by individual victims won&#x27;t be effective. If it does, Alphabet and other US-based tech companies should have been behaved better decades ago. For them, this civil case means nothing. Think about it. Are you and all the people you know going to boycott Alphabet just for this particular civil case? No way.The better solution is make a regulation which makes Alphabet and its boards criminal if they ignored it. But it looks like defamation isn&#x27;t more important than copyright infringement in US. reply munk-a 19 hours agorootparentI didn&#x27;t say anything about boycotting - I suggested that repeated lawsuits like this one will force a change. Regulation is absolutely the ideal way forward but the US is horrible about effective regulation so the legal system is probably the most practical enforcement method we have. reply kozikow 15 hours agorootparentprevThat&#x27;s not just external facing problem. Even when internally you want to figure out something - e.g. get a quota for something it&#x27;s very hard to locate who could get things done for you.There is this attitude that humans shouldn&#x27;t ever talk to other humans, but to systems. So if your use case is not handled by how the system was designed, talking to humans would take many months, so better just give up.The problem may be even worse internally tbh. You want to use some project, there&#x27;s old teams page, one email, you email person there and after 3 pings weeks later they reply they work now on a different team. reply matsemann 20 hours agorootparentprevChrome has had a bug for ~6 months where for certain TLDs, it searches instead of going to the typed url. It happens for .no. Google isn&#x27;t incentivized to fix it, since they now most likely get a visitor on their search page and earn some money.Combined with a different issue, this is fairly dangerous: Google allows fake scam websites to pay to get the top ad. Above the URL you ended up searching for.There are cases of people writing skatteetaten.no (our IRS) in Chrome, ending up in google search instead, and they then click the top result which is a phishing site stealing their credentials. reply soco 19 hours agorootparentThat, and also the plethora of search suggestions like 192.168.O.1 (notice anything wrong?) happily presented up there. No, DDG doesn&#x27;t show them, so yes IT IS possible. reply nolist_policy 19 hours agorootparentprevChrome has a public bug tracker.I can&#x27;t find any bug report for your issue.Please post a link to your bug report, otherwise it seems like you didn&#x27;t even try. reply matsemann 18 hours agorootparentWhy should I try? I don&#x27;t use Chrome. I don&#x27;t care about jumping through hoops to do free work for a big scummy company. I only knew of it from news reports recently after it finally got fixed.https:&#x2F;&#x2F;www.kode24.no&#x2F;artikkel&#x2F;derfor-googler-chrome-no-nett... reply nolist_policy 17 hours agorootparentGreat, it has a link to the bug: https:&#x2F;&#x2F;bugs.chromium.org&#x2F;p&#x2F;chromium&#x2F;issues&#x2F;detail?id=148880...Fix was commited 7 days after the report was filed. reply doctorpangloss 15 hours agorootparentHere&#x27;s an example of Google bug tracking being pretty dysfunctional: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32380769Anyway, Chrome&#x27;s responsiveness on some random issue isn&#x27;t at all representative of Google as a whole, which of course, it is impracticable for laypeople to communicate with a real person there. replykrisoft 21 hours agorootparentprev> But how can you notify Google of anything?Same way you notify any other company about anything. Registered letter sent to the corporate headquaters. reply KomoD 21 hours agorootparentHave you tried that with Google? Or are you just guessing? reply Retric 20 hours agorootparentLegally it counts as notification even if they never open the letter. reply dhimes 16 hours agorootparentI&#x27;m not even sure it has to be registered. In at least one court case I know of (a local landlord case) the court assumed that a mailed letter was delivered properly. reply krisoft 9 hours agorootparentprev> Or are you just guessing?There is no guessing involved. That is how you notify a company.I believe you are confused about what I am saying. I’m not saying that google will change anything just because you sent a registered letter. You send a notice, and they might change things or they might not. The notice in and of itself does not compel them to do anything.What power does such a notice have then? In a court case you can say “your honour, we sent notice on day x, by registered mail, here is our retained copy of the content of the letter”. And the courts generaly assume that such notices were received and read (consult with your lawyer about any possible edge cases, of course). This is not generaly true if you send your notice via carrier pigeon, or shout it at their air vents, or stuff it in a teddy bear and flush it down the toilet. Those are less legitimate channels in the eye of the law.So what then? They received your notice and you can prove it. What will that change? Maybe nothing. Maybe everything. If you have some legally colorable argument, it can help you paint their action or inaction following the notice as willfull. In some circumstances that increases damages, or makes them liable.In practice what it wins you is that it will be read by some lawyer kind of person, and if that person reads it and says “uhh, this person could sue us and that would be bad” then they usually have the clout to change things. That of course depends on what you are giving them notice about. If you wrote some rambling with no actionable ask and no chance of a succesfull lawsuite they will ignore it. They probably get plenty of those. reply dkjaudyeqooe 17 hours agorootparentprevSomeone could make Google more responsive by publishing a guide on how to sue Google while representing yourself.Some basic information about court procedure and submissions, and a guide to the relevant law, such as defamation, would let a thousand litigants bloom, and Google would soon have a very real problem on their hands.Most likely you&#x27;d get Google&#x27;s attention at the first step, and a probably solution. reply gshubert17 15 hours agorootparentIf Google didn&#x27;t index this guide, how would people find it? reply dkjaudyeqooe 14 hours agorootparentThe original internet: word of mouth. reply jsnell 20 hours agorootparentprevThat&#x27;s just a lazy meme take, there&#x27;s obviously a documented process to request removal of content from their products, including Search.https:&#x2F;&#x2F;support.google.com&#x2F;legal&#x2F;troubleshooter&#x2F;1114905?sjid... reply soco 19 hours agorootparentThe request process is indeed easy enough. Now, if you also expect it having results, guess what. reply jsnell 18 hours agorootparentThe GP&#x27;s complaint was about not being able to notify Google at all, not at not getting the right outcome. I&#x27;m pretty sure submissions to that form will have (trained) human eyes on them after some trivial spam filtering, it&#x27;s not just redirected to &#x2F;dev&#x2F;null.As for whether one could expect results, there are stats on how often this functionality is used in the EU (about 200k requests per year) and how often it is successful (about half the requested URLs are delisted):https:&#x2F;&#x2F;transparencyreport.google.com&#x2F;eu-privacy&#x2F;overview?hl... reply tadfisher 16 hours agorootparentNot correct, the original lawsuit (from 2015) was predicated on the fact that she had indeed opened a removal request, and Google denied it, saying they could do nothing without the cooperation of the website owner (RipoffReport). reply lazyasciiart 16 hours agorootparentWhat is &#x27;not correct&#x27; in the comment you&#x27;re replying to? replyshelled 17 hours agorootparentprevAt least that’s a thing in Australia or western countries. Here in India, where TrueCaller is very famous, TrueCaller is a platform for abuse.Even after you use their delisting the customer care duty-fully informs you that your number can still be named and tagged on their platform.After a while in my case they just didn’t respond. reply tempodox 19 hours agorootparentprevThat&#x27;s just it. This one time, Google got slapped for this kind of behavior. reply jeroenhd 20 hours agorootparentprevYou can&#x27;t notify Google of anything, that&#x27;s probably why Google needed to settle in the first place. It&#x27;s their choice that they don&#x27;t do any customer support. reply mbrumlow 19 hours agorootparentprevI think that is the point. The bots and “product experts” failed to do their job. And as agents for working for Google failed Google. reply theptip 18 hours agorootparentprevGDPR&#x27;s \"Right to be forgotten\" has been a thing for 5 years now, this isn&#x27;t a new concept:https:&#x2F;&#x2F;support.google.com&#x2F;legal&#x2F;answer&#x2F;10769224?hl=enThis doc explains the tools available and links to a \"Personal Data Removal Request Form\". Now, what they do with that in non-EU territories is another question. reply edgyquant 20 hours agorootparentprevJust shrugging it off implies you’ve notified them. Then not caring is why they lost this lawsuit. reply 6510 19 hours agorootparentprevThe fascinating thing here imho is that until recently it was pretty expensive to communicate with customers at that scale. You would have to staff some XXL call centers and find some way to process the communications in the context of the technologies used.We&#x27;ve seen the many useless chat bots attempt to remedy the puzzle but the situation is rather different with LLM&#x27;sI for example reported on yt that the subtitle font-size is to small to read. I didn&#x27;t bother to investigate what drives the inconsistency but the font is much smaller than everything else on the page.If humans have to read this, write a report, put it in a bug tracker etc it will never be important enough to do something about it.An LLM could figure out which line of code determines the font size. It could establish if it is indeed smaller than the other fonts and when. Then it could combine many similar reports into a simple easy to read list of tweaks with code examples.I hardly ever use subs and normally I sit closer to the screen I didn&#x27;t bother to search for the issue on google. Writing this I find an article on a 3rd party website that explains there are settings for the subtitles. There is a warning on this menu that says the settings are not persistent and will only work for this video but after changing the font size it works for all videos.Should I report that as well? If nothing will be done with it why bother? reply amalcon 20 hours agorootparentprevThat&#x27;s a particularly weird one, because it&#x27;s just populated with phrases people search often (as befits an autocomplete box). The point of search is to find things you don&#x27;t know, though! I search for e.g. \"XYZ scam\" to find information to help me conclude whether XYZ is a scam, not to register my belief that it is in fact a scam.I guess that goes to your point, though: maybe Google needs to make that clearer? reply csunbird 22 hours agoparentprev> Dr. Duffy posted a web report on the website “Ripoff Report” complaining about her dissatisfaction with the services she had received from the psychics on the Kasamba site. She also commented on the reports of others about the psychics. She created a chat group “kasambavictims” on Yahoo. Dr. Duffy also posted messages under a pseudonym, and began to email the site complaining that her friend’s wife had committed suicide due to bad advice given by the psychics. This was untrue.Very interesting part. Later in the article:> In relation to justification (truth), the Court found no evidence supporting Google’s argument that Dr. Duffy stalked or persistently and obsessively harassed any of the psychics.Am I missing something important here? Dr. Duffy clearly defamed a business with a lie, and some other people (other site users) pointed this up, in a very cruel way, to her in a forum with user submitted content. Then Dr. Duffy sues Google instead of the Ripoff Report forum? reply arp242 21 hours agorootparentPosting messages and making up that a friend&#x27;s wife committed suicide is not really \"stalking\" or \"persistently and obsessively harassing\". Immoral and possibly illegal? Perhaps. But that&#x27;s not the same thing.Also, Duffy was ripped off by Kasamba.I think the crux of the matter is: even if you did something wrong, do things like that really need to be preserved on the internet under your real name for the rest of your life? Probably not. And do we really want Google to be suggesting this content years after this minor spat, guaranteeing that people will find it?\"Right to be forgotten\" is really about this kind of stuff IMHO: okay, you&#x27;ve had your five minutes of shame and that&#x27;s all fine, and now lets all move on instead of keeping this prominent for years or even decades. reply jeroenhd 20 hours agorootparent> Also, Duffy was ripped off by Kasamba.Can you really be ripped off by psychics? It&#x27;s not like you can sue a church because your prayers haven&#x27;t been answered, so I&#x27;m not sure of religion or spiritualism can be a \"rip-off\".If someone tells you they&#x27;ll talk to your dead ancestors for money and you don&#x27;t believe them, who&#x27;s to say who&#x27;s speaking the truth? The best you can do is use reasoning like \"there&#x27;s no scientific basis for an afterlife\" but that&#x27;s not a great defence if you&#x27;re honestly trying to speak to the dead.I agree with your other points, of course. I&#x27;m just amused at the idea of suing psychics for not telling the truth. reply gspencley 19 hours agorootparent> Can you really be ripped off by psychics? It&#x27;s not like you can sue a church because your prayers haven&#x27;t been answered, so I&#x27;m not sure of religion or spiritualism can be a \"rip-off\".Well, I would suggest that both are a \"rip off\" in the sense that they offer claims without evidence.But a distinction that I see between religious services and psychics is that religious services are not offering financial transactions in direct exchange for services. They ask for donations, and they may make claims such as \"God answers all prayers\", but you are typically not offering a religious leader money in exchange for some sort of quid pro quo like having a prayer answered.A lot of \"psychics\" offer their \"services\" as \"entertainment\" in order to avoid claims of fraud. But the fact remains that a lot of people still believe.My wife and I are performing magicians, and we make it clear that what we do are parlour tricks. And yet I&#x27;ve performed \"mind reading\" tricks for people in the past who were absolutely convinced that what I did was not a trick even though I presented everything as \"magic tricks.\" It&#x27;s fucking insane and deeply uncomfortable. I totally get why Penn & Teller stay away from mentalism entirely. And I think this is your point: if someone is determined to accept a faith based belief system, can they really be \"ripped off\" when reality doesn&#x27;t deliver their fantasy.In my opinion, it depends what you offering and the audience &#x2F; demographic that you are targeting. Magic tricks for entertainment presented as tricks is one thing. A \"psychic\" (even one that offers a \"disclaimer\" that it is entertainment) who knows full well they are catering to people that want to believe it is \"real\" know what they are doing. It gets particularly heinous when these con artists prey on grieving people who just lost a loved one. It&#x27;s hard not to view a con artist presenting bullshit to a mother who just lost her 12 year-old daughter in a car accident as not ripping them off. reply Karellen 19 hours agorootparent> But the fact remains that a lot of people still believe.But also, a lot of people still believe in professional wrestling. Are pro wrestlers ripping people off?Were pro wrestlers ripping people off worse in the &#x27;80s and earlier, when they tried really hard to maintain kayfabe, including denying the existence of kayfabe?If you pay money to psychics and they tell you the sorts of things you paid them to tell you, is it really different from pro wrestlers or stage magicians? Or should that be \"psychics\", \"wrestlers\" or \"magicians\"? reply pixl97 16 hours agorootparentAnswers to things don&#x27;t have to be black and white, yes or no. You can also start a process up front saying it&#x27;s entertainment then manipulate people to the point the initial statement no longer holds. reply arp242 20 hours agorootparentprev\"Ripped off\" in the colloquial sense, not in the strict legal sense.Most psychics don&#x27;t actually believe what they&#x27;re selling, whereas most priests do.Prayer also works very different: a psychic will tell you \"higher powers told me this man is a {good,bad} match for you\", whereas a priest will tell you to \"pray and ask God for guidance\" and&#x2F;or offer you some general advice, but they won&#x27;t say \"God told me to relay that [..]\".Should they be sued for it? Probably not. But I do think most psychic \"customers\" get ripped off by people who are essentially little more than confidence tricksters, but I don&#x27;t think most people who go to church get ripped off (outside of the \"send me your money and go to heaven\" kind of twattery). reply rescbr 16 hours agorootparentprev> It&#x27;s not like you can sue a church because your prayers haven&#x27;t been answeredAh! You totally can! Every now and them there are news articles about lawsuits against the Universal Church of the Kingdom of God. reply mcpackieh 15 hours agorootparentprev> Can you really be ripped off by psychics?Once I went to a psychic who offered to read my fortune out of a crystal ball. Later I found out the ball was actually glass. Glass! That&#x27;s an amorphous solid, the exact opposite of a crystal. How can you divine any truth such a chaotic structure? The very premise is ludicrous; she may have a large glass ball but clearly she had lost the rest of her marbles. reply AdrianB1 15 hours agorootparentpreveven if you did something wrong, do things like that really need to be preserved on the internet under your real name for the rest of your life? Probably notWhy not? It is a historical record of sort, like Nero burning Rome. Does Nero has a right to be forgotten? Also where is the freedom of speech of telling people that Nero burnt Rome? reply arp242 5 hours agorootparentNero is dead and dead men don&#x27;t suffer from a bad reputation. Nero was also emperor, whereas this person is not a public figure. It needs to be proportionate, and \"rest of your life\" sounds disproportionate for something like this.It also depends on how unique your name is how badly you will get \"punished\". My name is unique; as far as I know I&#x27;m the only person on the planet with my name. People named \"John Smith\" have an easier time being anonymous.(aside: it&#x27;s not clear that Nero actually started the fire by the way, the sources on it are rather thin and recently some historians have begun to suspect that a lot of what we \"know\" about Nero was essentially propaganda from his opponents. This is actually another point of consideration here: not everything that&#x27;s reported is necessarily accurate, fair, or balanced.) reply xyst 21 hours agorootparentprevWhether the plaintiff defamed another business or not is not the subject of this case. The case is about Google continuing to publish defamatory statements generated from “Rip off Reports” content despite being forced to comply with the request in 2011.Now I do agree the plaintiff can also be sued for damages by the psychic company for defamation.That’s my take on this. I do agree the premise of the case is odd. The in depth case review doesn’t seem to mention if she actually went through the process of having the primary publisher (Rip-off reports) remove the defamatory information. reply munk-a 21 hours agorootparentprevGoogle was not a party to this interaction until they voluntarily chose to be. That&#x27;s a huge thing to remember with aggregators and the like - they&#x27;re voluntarily reposting information and accept the benefits along with the liability of doing so. Platform immunity does exist for a lot of the common situations - but it doesn&#x27;t cover everything. reply kikokikokiko 21 hours agorootparentprevI find it amusing that I feel no empathy at all to ANYONE involved in this case. The \"psychics\" are just low-life scammers that prey on the stupid&#x2F;mentally ill, and things like this case are bound to happen to them from time to time. Google is Google, everything that makes the evil tech lords suffer a little bit is a plus for mankind. And this woman seems to be just an insufferable crazy cat lady, so good riddance to all involved. It&#x27;s a win-win-win for humanity. reply carlosjobim 20 hours agorootparentprev> Am I missing something important here? Dr. Duffy clearly defamed a business with a lie...What you&#x27;re missing is that you can&#x27;t defame a business. Only if that business is very strongly connected to a single person. reply anon84873628 16 hours agoparentprevThe most interesting sequence of the decision to me:>The Court reasoned that only once Google acquired knowledge of the paragraphs by reason of Dr Duffy’s notifications and failed to remove them within a reasonable time thereafter would the necessary mental element be present for Google to be a “secondary publisher”.> ...>The Court then turned to look at the notice given by Dr. Duffy, to ascertain whether it was sufficient to fix Google with the relevant mental element. The Court concluded that Dr Duffy’s communications with Google comprised adequate notification to them of the allegedly defamatory material, this was despite the fact that some of the URLs were incomplete in these communications. The Court also implied that a reasonable time for removal of content would be one month, which had not been met by Google.>...>The Court rejected Google’s defenses of innocent dissemination, qualified privilege, and justification (truth). In dismissing the innocent dissemination defense, which required that the publisher be a subordinate distributor who did not know or ought not to have known that the matter was defamatory, the Court stated that the defamatory nature of the content was self-evident from an examination of it.Emphasis on the last line.It&#x27;s not like she had to go to Google and say, \"here is a court judgment showing this content is defaming me\" to have it removed. She simply had to notify Google that this \"self-evident\" defamatory content was being served by them.That seems like a significant precedent to set. I don&#x27;t really think it is fair to expect Google to determine which content is \"self-evidently\" defamatory (edit to add: amongst all the takedown requests they will receive) reply TimPC 16 hours agorootparentI think it&#x27;s a fair precedent. If Google feels the content is not defamatory they can take that position in court with consequences if they are wrong. The downside is this ends up like the DMCA where companies are likely to take down all content complained about because of the risk&#x2F;reward tradeoffs but if we already do that for alleged copyright violations doing it for alleged defamation seems much more reasonable to me. They also don&#x27;t have to remove all self-evidently defamatory content, just all self-evidently defamatory content they are notified they are serving. reply kulahan 12 hours agorootparentprevThe court case seemed to hinge largely on the fact that she TOLD them the info was there, that it was defamatory, and they chose to keep it up anyways. Had they taken it down, they would&#x27;ve been fine.So this doesn&#x27;t seem like much of a precedent at all: If you are told you have defamatory content, you need to remove it. They don&#x27;t really have to change much (anything?) about their search engine to make this happen. Maybe a link for \"need content removed?\" or whatever. reply chaostheory 16 hours agorootparentprevThis will continue the trend for more censorship in search. reply kedean 13 hours agorootparentCensorship is not and cannot be a blanket defense for companies to get away with not moderating their content, and for Google this information is content.Google in particular left behind the excuse of \"we just serve what&#x27;s already available\" when they started weighting results for political and commercial gain and labelling things as factual. They clearly do not act as a dumb pipe for information gathering.IMI, as soon as they started exercising editorial privilege on data they serve, they became responsible for this kind of thing. Uncensored search results can only come from an engine that isn&#x27;t censoring for their own benefit anyway. reply barbazoo 15 hours agorootparentprevHow will this add to \"censorship\"? reply l33t7332273 15 hours agorootparentGoogle and others will likely prefer to take a hardline stance on what is “self evidently” defamatory, and when you combine heavy handedness with automation, you will almost surely be censoring legal content. reply AdrianB1 15 hours agorootparentprevSimilar to that quote, it is self-evident. If you can be punished for stuff that you index (as a search engine), you will start to self-censor to avoid punishment. reply Popeyes 22 hours agoparentprevCrazy story, so she shit-posted on a dubious forum, they shit-posted back and then she sued Google for defamation. reply aardvarkr 21 hours agorootparentThat’s my take too. It’s pretty ludicrous reply Retric 20 hours agorootparentSo as is often the case the details are what matter. Google failed to remove defamatory content from their systems after being informed it was defamatory. That’s the case, and they lost because it’s their responsibility to respect such notifications.It’s like that hot coffee lawsuit. They were held 80% liable because the coffee was served at a seriously unsafe temperature, which isn’t total liability. She got 3rd degree burns on 6 percent of her skin and lesser burns over 16 percent, spent 8 days in the hospital and needed skin grafts. But everyone seems to think coffee = hot and not that dangerous when ignoring the possibility it can be made more dangerous. reply fastball 17 hours agorootparentI think the thing people are surprised by is that auto-complete searches count as defamation, not that Google didn&#x27;t take them down. reply Retric 17 hours agorootparentA distinction is this wasn’t automated once a human looked at the complaint. reply anon84873628 16 hours agorootparentprev>In dismissing the innocent dissemination defense, which required that the publisher be a subordinate distributor who did not know or ought not to have known that the matter was defamatory, the Court stated that the defamatory nature of the content was self-evident from an examination of it.It&#x27;s not like the plaintiff went to Google with a prior legal judgment against the RipOff website telling Google to take it down. Apparently the court expects Google to remove (within one month) \"self-evident\" defamatory content if alerted to it.That&#x27;s a pretty interesting precedent to set. What makes defamation\"self-evident\"? reply caf 13 hours agorootparentPrimary publishers have to make that judgement all the time. If you get a book published by Harper Collins they&#x27;re not going to let you put \"anything not specifically already ruled defamation by a court\" in it. reply nullifidian 20 hours agorootparentprevThat&#x27;s UK&#x2F;Australian legal&#x2F;cultural norms for you. reply Euphorbium 21 hours agoprevYou probably need to go into 12 year legal battle against google to get some human response from them. reply arp242 21 hours agoparentYou&#x27;re in an optimistic mood today. reply rvba 21 hours agoparentprevDoes a response from lawyers count as \"human\"? reply HHC-Hunter 11 hours agorootparentFor Google, yes. They&#x27;re the official mouthpieces reply flavius29663 21 hours agoparentprevNot even that, google didn&#x27;t show up> A line has been finally been drawn under an Adelaide woman&#x27;s 12-year legal battle against global tech giant Google after she sued the company twice, mostly unrepresented, and won. reply StevenWaterman 21 hours agorootparentThat line doesn&#x27;t say that Google didn&#x27;t show up. It says that she acted as her own lawyer. reply Zarel 19 hours agorootparentprevYou&#x27;re misinterpreting that sentence. This overview of the case was posted:https:&#x2F;&#x2F;globalfreedomofexpression.columbia.edu&#x2F;cases&#x2F;duffy-v...And in it, it talks about Google&#x27;s defenses (innocent dissemination, qualified privilege, and justification), so clearly Google did show up. reply Andrex 19 hours agorootparentprevThat sentence implies to me that she represented herself, not that Google was without representation. reply colonwqbang 22 hours agoprevNot a single scrap of information about the facts of the case. We should just infer that Google are evil and did something wrong that they deserve to pay for. reply cwillu 22 hours agoparentAs far as I can tell, the problem is that google surfaced posts claiming she was a stalker, when she merely lied about a psychic having caused her friend to commit suicide in posts about that psychic. Or something. reply Y-bar 22 hours agorootparentGoogle appears to be still allowed to surface content which is defamatory, but they still have a publisher&#x27;s duty to remove it once notified, I think this is key from the summary (linked elsewhere in the discussion):> […] because [Google] was on notice that the material was defamatory and refused to remove the information, it could not be found to have innocently circulated the information reply cool_dude85 21 hours agorootparentIt seems like under Australian law there&#x27;s a concept of a \"secondary publisher\" of defamatory content, which would typically be a bookstore or library. So, the actual publisher, author, etc. can be held liable for defamation, but also, if the bookstore has been notified that it is selling a defamatory book and does not take it off the shelf, it too can be held liable.In this case, the woman notified Google that their search results for her were defamatory, Google did not take them down, and Google was held to be a secondary publisher because their algorithm actively determined what URL to show, what snippet to show, etc. reply lesuorac 20 hours agorootparentWell a bit more than that.The second lawsuit was about the auto-complete where ever time you searched her name it&#x27;d suggest appending \"psychic stalker\" to it. So it&#x27;d be more akin to every time you ordered coffee from startbucks they wrote down \"Dude, Physic Stalker\" on your cup every time. reply fasthands9 18 hours agorootparentI don&#x27;t think that would be speech that you could sue over, in the US or Australia.You are allowed to insult people personally, just there are restrictions if you publish defamatory speech. reply Symmetry 21 hours agorootparentprevI don&#x27;t think it&#x27;s reasonable for Google to remove content whenever someone just says its defamatory, in the absence of a court finding that it&#x27;s actually defamatory. Otherwise we&#x27;d quickly lose every reference to Biden winning the 2020 election once it was widely known that the rule existed. reply caf 13 hours agorootparentThey don&#x27;t have to remove content whenever someone just says its defamatory.They have to remove defamatory content once someone has told them it&#x27;s defamatory. Essentially the ball is put into Google&#x27;s court at the point, with the question: are you willing to defend this as non-defamatory? Which is the same question all primary publishers face. reply colonwqbang 20 hours agorootparentprevBut the court did find that it was defamatory.There is a world of difference, legally, between disparaging a powerful politician like Biden and a normal private person. replydonatj 22 hours agoprevGoing after Google rather than the company actually making the remarks seems… incorrectDoesn’t seem like it should be Googles job to fact check the internet. Go after the liar, not the search engine.Google seems no more responsible than your ISP for sending it to you or your monitor manufacturer for displaying it. reply jeroenhd 20 hours agoparentGoogle made the situation a bit harder for themselves with their info boxes (that just repeat the first result, but in an authoritative Google voice) but the \"secondary publisher\" argument used in the lawsuit makes sense to me.They weren&#x27;t required to know the truth from the get go, but they had to remove the libel on notice. Perhaps Google disagreed that there was anything wrong with the assertion that this person was a stalker, but that&#x27;s a rather risky position to take without any criminal convictions to base their claim off, and a stupid one from a business sense.Furthermore, their autocomplete is entirely their product, you can&#x27;t go after anyone else for that.I imagine this approach wouldn&#x27;t work in other countries, but if the lawsuit really was baseless in Australia, Google would&#x27;ve won a long time ago, rather than settle now. reply petee 21 hours agoparentprevPerhaps if it was someone else&#x27;s title, but they are constructing their own auto-complete strings, essentially divining it, so their fingers are in fact in the pie.Auto-complete also gives the impression that other people have searched or found it, so it must be valid, despite having little correlation. If an employer starts typing your name and google says you&#x27;re pedo, you&#x27;re probably not getting the job reply tinus_hn 16 hours agoparentprevSeems the court disagrees with you to the tune of $100000.Seems it is the opinion of the court that Google is rebroadcasting and amplifying slander and refuses to stop when notified and when ordered to do so. reply AdrianB1 15 hours agorootparentSo is every ISP serving Australia. reply crobertsbmw 22 hours agoprevThere’s a difference between “settles” and “wins”. Sounds like they settled, but then they talk like she won… reply petee 21 hours agoparentAfaik a settlement against a company like google is essentially win for a couple reasons -- if Google could win on merit, they can afford to do so; but if they were going to lose, the cost of completing the trial would be even higher than a settlement.Particularly, if she got the redactions and compensation she was looking for, thats certainly a win. reply jfarina 20 hours agorootparentI don&#x27;t know about that. Even with a company like Google, 12 years is a long time. What if the responsible attorney retired? I&#x27;ve never worked in a legal setting, but I could imagine that causing their work being reevaluated for cost effectiveness. reply 34679 20 hours agorootparentprevShe&#x27;s quoted as saying it&#x27;s not about the money, just holding Google accountable. A settlement is money in lieu of accountability. A judgement would deter them from doing it to countless others. reply rtkwe 17 hours agorootparentSettlements can include promises to change practices and actions not just money. reply computerfriend 21 hours agoprevI&#x27;m sure that Janice Duffy, the publicly named claimant, will now forever be unassociated with this case and the defaming material by search engines. reply ourmandave 21 hours agoprevI&#x27;m just wondering how the Google internal legal dept handled this for 12 years.I&#x27;m imagining they called it the Duffy file and gave it to interns every year.Or maybe assigned it personnel with low annual reviews. \"Dave, we&#x27;re giving you the Duffy case until you get your numbers up.\" reply HPsquared 22 hours agoprevSeems to be about Google making something from \"Ripoff Report\" available, on which were defamatory statements about the plaintiff.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Ripoff_ReportAn interesting business model, to be sure... And a clash of two legal regimes, one in which Ripoff Report can operate and another in which Google can be sued for indexing &#x2F; linking to them.It&#x27;s like, pick your poison... reply Lacerda69 22 hours agoparenti find it mindboggling that criminal records are so accessible in the US - so that something like ripoff report is a legal business there does not surprise me in the least reply travoc 21 hours agorootparentYou think secret courts and prisons are better than public criminal records? reply mftrhu 14 hours agorootparentYou can have courts and sentences be public (or at least, public enough) while giving people their privacy and keeping their criminal record private (or at least, not publicly disseminated and accessible to random people). It&#x27;s how it works in most of the civilized world. reply shadowgovt 22 hours agorootparentprevThere&#x27;s a lot of historical reasons overlapping here. One is that the country is so large that having that information be public is one of the ways the public protects itself from predatory behaviors... Otherwise, somebody can skip over to another jurisdiction and continue the behaviors they used to cheat people the next town over. In the era before mass communication that was a real problem (the \"traveling snake oil salesman\" is one iconic example), So making records public to anyone willing to go search them was the least protection the governments could provide.The calculus changes in the era of ubiquitous communication and digital search, but broadly speaking Americans still feel they should be protected from the snake oil salesman. reply arp242 21 hours agorootparentI&#x27;m highly skeptical of this explanation because most countries are large enough to do that, and historically \"accessing public records\" was not easy so it doesn&#x27;t seem all that useful.In my observation a far more likely explanation is that US culture sees \"criminals\" as subhuman monsters hardly worthy of consideration. I&#x27;m exaggerating a bit here, but I find general US attitudes towards crime and criminals unhealthy – there are many data points for this: felony disenfranchisement, non-violent criminals routinely shackled by the hands and feet in many jurisdictions, \"prison rape lol\", death penalty, draconian punishments even for simple things, the state of the prisons, death penalty FOR MINORS until 2005, many minors are prosecuted as adults, the number of people in prison, stand your ground laws, a police force with long-standing ... issues, that \"kids for cash\" not only was a thing but managed to go undetected for many years (many of the sentences were idioticly draconian and even a single one of them should have set off all sorts of red flags), obsession with crime on TV news and such, routine administration of drug testing, etc. etc. etc.And, of course, the mug shot racket, most of which are taken after arrest and not conviction – sucks to be you in cases of mistaken identity or other harmless arrests where nothing much was going on.A few of these: okay. All combined: a pattern. reply eckza 22 hours agoprevRead another way,> Woman loses 12 years of her life to a legal battle against Google reply Lacerda69 22 hours agoparentnah she won and did a great service to her fellow human beings. this was not lost or wasted time. people spend decades on far more \"useless\" things - not that there is anything wrong with that reply eckza 20 hours agorootparentOh, I&#x27;m not saying that she didn&#x27;t do a great thing.Have you ever spent years of your life tied up in litigation?It&#x27;s not fun. It&#x27;s very frustrating, to feel as though a resolution will never happen. It feels indeterminate; indefinite.It&#x27;s a shame that she should have to spend twelve years of her life pursuing justice. What about the thousands or millions that simply won&#x27;t try, because they can&#x27;t rationalize the effort? reply mattstir 17 hours agorootparentprev> she won and did a great service to her fellow human beingsShe didn&#x27;t win, they settled out of court. The article definitely does its best to avoid mentioning even a single detail about the case beyond the outcome, and even that it misconstrues.Dr. Duffy left a bad review for some psychics on the site \"RipOff Report\" and lied about her friend’s wife committing suicide due to bad advice given by the psychics. A few unsavory posts based on her behaviour ended up being published there as well. The big crime that Google committed was providing the most common autocompletes on search terms like it does for every other search query. In this case, it showed the search term “janice duffy psychic stalker” after typing in \"janice duffy\".I don&#x27;t see how any of this insane story counts as a \"great service to her fellow human beings\". reply HPsquared 22 hours agorootparentprevIndeed, society needs such people. Heroic, in a way. reply dghughes 21 hours agorootparentDid you read what started it all? She&#x27;s in no way a heroic. reply hn_go_brrrrr 22 hours agorootparentprevHeroic, but also pyrrhic. reply bbarnett 21 hours agorootparentGood grief, she hardly spent every waking moment on it.Court actions are bursts of \"lots of work\", followed by months of waitng. To hear you people talk, it&#x27;s all she did!It&#x27;s like she had a hobby. The way some are talking, she destroyed her life?!? replym4jor 13 hours agoprevI think the only ones who came out on top of this were the lawyers. reply jeffbee 22 hours agoprevA person wrote articles that another person felt were defamatory, second person sued Google for indexing them. reply dekken_ 22 hours agoparentyep, while I agree defamation is bad, I find the whole \"publisher\" argument somewhat obsolete. If everyone can be a publisher, then no one is. reply jeffbee 22 hours agorootparentThe first party is not even the first party, since this \"Ripoff Report\" site is user-contributed content. It looks like this plaintiff and some American woman were shitposting on that site, and Google indexed it, and the Australian woman sued Google.Full Streisand. https:&#x2F;&#x2F;www.ripoffreport.com&#x2F;reports&#x2F;janice-duffy-psychic-st... reply dekken_ 22 hours agorootparentAnd it&#x27;s only defamation if it&#x27;s false, which I&#x27;m not sure was investigated. reply logicalmonster 21 hours agorootparent1) IANAL, but there are circumstances and legal jurisdictions where truth is not necessarily an ironclad defense against defamation claims.2) Ironically, I think the stronger the defamation laws, the worse the problem of defamation becomes because more people become likely to believe dumb random claims they hear are true or otherwise nobody would risk saying it. I believe that a hypothetical society with no defamation laws would be the safest from people believing false random claims. reply_trampeltier 18 hours agoprevAnd the court needed 12 years for this? Really? reply sdfghswe 18 hours agoparentMy rudimentary understanding of law is that there are a lot of \"procedural\" elements that expensive lawyers can fiddle with in order to delay the case (and try to make the plaintiff give up).It&#x27;s not necessarily that the decision was conceptually difficult. Altho it might be! I don&#x27;t know anything about the case. reply _trampeltier 16 hours agorootparentYes, but please. If the law&#x2F;court works like this .. thats almost worthless. reply kriro 22 hours agoprevIf I&#x27;m Google I&#x27;d just stop indexing this site after the ruling and also talk to my competitors and suggest they do the same because it&#x27;s bad for them. Seems like they index it but downweight already.Pretty interesting ruling that a search engine is basically liable for autocomplete (and thus the content they index). The original website seems pretty shady and not being indexed should basically destroy their business model long term. reply acdha 21 hours agoparent> If I&#x27;m Google I&#x27;d just stop indexing this site after the ruling and also talk to my competitors and suggest they do the same because it&#x27;s bad for them. Seems like they index it but downweight already.That’s what they refused to do after losing the previous case on appeal. That means they no longer have any way to claim they didn’t know about it, since they spent large sums of money fighting it in court. reply kriro 20 hours agorootparentI get that and I&#x27;d accept the ruling (going to the highest possible court because this is kind of important for them). I&#x27;d just use it as a good opportunity to de-index a troubling site without any of the potential legal issues that could come with that (unfairly discriminating against said site or whatever). reply acdha 19 hours agorootparentI think the underlying issue is that Google strenuously avoids taking responsibility for their services. This kind of thing could be handled quickly by a modest customer service group but they don’t want to set the precedent that they do that sort of thing short of a lawsuit. reply tgv 21 hours agoparentprevThe auto-complete is of Google&#x27;s own making. They built and added it, they can improve or remove it. There&#x27;s no reason to assume an automated prompt has to repeat defamatory or deceitful statements just because they appear somewhere online. reply phendrenad2 22 hours agoprev> The Court went on to note that the mental element depends on whether the defendant is a “primary publisher” or a “secondary publisher”. A “primary publisher” may be held liable for defamation regardless of whether it knows of the defamatory material, whereas a “secondary publisher” is only held liable if it knows that what it was publishing contains the passage in question or is reckless or careless as to its containing such a passageWhy stop there? Hacker News is now a \"tertiary publisher\" because it links to Google.com, which links to defamatory content! Hell, the judge, in the act of commenting on this case, is a 5th-level publisher! For shame!Anyway, Australia is ranked dead last in my personal ranking of countries that \"get it\". The cluelessness train keeps rolling over there. We get silly internet laws and even sillier interpretations of silly internet laws every day. reply Nasrudith 20 hours agoparentIts not cluelessness. It is deliberately obtuseness. They were the patient Zero of the Murdoch media infection. reply logicalmonster 22 hours agoprev> Dr Janice Duffy successfully argued in 2015 and 2023 that Google published defamatory extracts from American website RipOff Report on its search engine page, despite her notifying the company and asking for the posts to be removed.Personally, I don&#x27;t easily see how Google could be liable for defamation here under any reasonable standard.Their search services generally don&#x27;t say the equivalent of \"Bob murdered a woman in 1989\".Their search services generally say the equivalent of \"Joe says that Bob murdered a woman in 1989\".If anybody is guilty of defamation in that contrived example, it&#x27;s Joe.Regardless of whether the story about Bob murdering somebody is true or false, Google&#x27;s service remains entirely factual when they pass along the word that \"Joe says that Bob murdered a woman in 1989\". That statement is 100% factual.I wish the article went into more detail about the actual impact on this woman&#x27;s career (not sure if they risk lawsuits reporting the details), but as the posted article reads right now, it&#x27;s not really clear if she was fired because of some boss Googling her, or if she just had a mental break when she fixated on the Google search results to a possibly unhealthy degree. reply viraptor 21 hours agoparent> Google&#x27;s service remains entirely factual when they pass along the word that \"Joe says that ...That&#x27;s not what they do though. This is a case about autocomplete in the search bar which gave the phrase \"psychic stalker\" after her name without any context or source. You could expect people to know this is just a random phrase from the index, but: 1. People don&#x27;t understand how Google works. 2. It doesn&#x27;t change the result of the negative association for a name used in business. reply GuB-42 21 hours agoparentprevDefamation laws are complicated. In some countries you can be purely factual and still commit the crime of diffamation. An example is talking about someone&#x27;s involvement in some criminal activity, implying the person in question is a himself a criminal when he is in fact a victim. It is true, but it is still using deceptive tactics (lying by omission in this case) to damage someone&#x27;s reputation.Here, what I understood made it defamation is that Google autocompleted the defendant name to “janice duffy psychic stalker”. No \"Joe says\" here.Victim aside, I think it is an important case, and probably the reason why it took so long. By autocompleting, Google puts up information without context, and I think it is normal to hold the company responsible more than for regular search results. In my opinion, Google simply shouldn&#x27;t autocomplete people names with accusations, true or not. Not only it opens them to defamation, like in this case, but there is enough negativity in this world that I feel like having autocomplete say bad things on people, even assholes, is doing the world a disservice. reply varjag 21 hours agoparentprevThe problem begins when you are Bob and anyone typing your name in the search engine gets \"Bob murdered a woman in 1989\", without any reference to particular Joe. reply kkielhofner 21 hours agoprevAs other commenters have noted this is a classic pyrrhic victory.If nothing else I have to respect her because I cannot imagine the tenacity it took to pursue this. I can&#x27;t speak to the merits or substance of the case but I know I don&#x27;t have it.It&#x27;s clear from the article she&#x27;s a fighter with her initial reaction to discovering this:\"She contemplated taking her life, saying it destroyed her career in research.\"To pull yourself together and come back from that is fairly remarkable.On the other hand, you have to really feel sorry for her. She took what seems to be a slight and spent 12 years of her life putting the time and effort into this while incurring the stress, emotional toll, expense, and what I&#x27;m sure are plenty of other sacrifices elsewhere in her life.She seems to be happier as a result of these \"victories\" but I wonder how much better things could have been for her if she spent the last 12 years focusing her energies elsewhere in her life and career. reply account42 19 hours agoparentThe woman made up shit about some psychics (after finding out the hard way that there is no such thing as a psychic) and then got mad again when she was served some of that same medicine. Sounds more like someone that wanted to avoid the consequences of her own choices rather than a courageous fighter standing up to the big evil corporation. reply kkielhofner 19 hours agorootparentI wasn&#x27;t commenting on any of these points, I specifically said \"I can&#x27;t speak to the merits or substance of the case\". I certainly didn&#x27;t say anything about going up against an \"evil corporation\".I&#x27;m trying to reference the humanity aspects of the situation, which I&#x27;ve found time and time again seems to be completely lost on HN (see: downvotes). It&#x27;s called empathy. reply mattstir 17 hours agorootparent> It&#x27;s called empathy.I suppose it&#x27;s just hard for many to feel empathy for someone who would go to such great lengths to avoid the consequences of their own actions. The timeline of events is just insane: Dr. Duffy consults with psychics about a romantic partner, gets upset when the psychics don&#x27;t guess the true outcome, proceeds to lie about her friend&#x27;s wife committing suicide due to the psychics, has a few posts about her stalking these psychics published on some no-name website, then spends 12 years getting upset at Google for indexing that website and autocompleting search terms instead of getting upset with the authors of the defamatory posts?Empathy is the ability to understand and share the feelings of another, but it&#x27;s hard for most people to see that chain of events and understand them. reply kkielhofner 9 hours agorootparentTo me this sounds like reason for more empathy.These are not the actions of someone who is well. replyherodotus 22 hours agoprev [–] >\"In dismissing the innocent dissemination defense, which required that the publisher be a subordinate distributor who did not know or ought not to have known that the matter was defamatory, the Court stated that the defamatory nature of the content was self-evident from an examination of it.\" (extracted from https:&#x2F;&#x2F;globalfreedomofexpression.columbia.edu&#x2F;cases&#x2F;duffy-v...)I am no fan of Google, but this seems bizarre to me, since it seems to imply that some human has to read every web page linked by Google. Even to suggest that Google must respond to every complaint of content on third party websites just cannot possibly scale.On the other, there is a party that is responsible for the defamatory content, namely whatever web app had collected and posted the comments. The claimant should have pursued them, not Google. reply numbsafari 22 hours agoparentJust because it can’t scale, doesn’t mean it isn’t wrong.There is no right to a scalable business model. If you can’t figure out how to do your business without doing it right, you shouldn’t be doing it.Our local coal fired power plant has been yelling for decades that they can’t possibly make a profit and meet all the environmental obligations. Well… guess what. reply mszcz 22 hours agorootparent> Just because it can’t scale, doesn’t mean it isn’t wrong.That. I&#x27;m so tired of this excuse being used which basically amounts to complaining that you wouldn&#x27;t been able to get so big and fat if you didn&#x27;t break the rules. reply tap-snap-or-nap 21 hours agorootparentMove fast, break things is basically don&#x27;t get caught when you break social contracts and regulations. reply Symmetry 21 hours agorootparentprevThat&#x27;s true in principle, but in this case I think that the existence of search engines is a net social good and I think it would be a big loss for all of us if they disappeared. Not that the days of web rings and hand-curated website lists didn&#x27;t have their own charm but I think that the net effect would be a huge increase in the power of walled gardens. reply MichaelZuo 22 hours agorootparentprevThat would also imply that there is no right for individuals to have a productive life with plenty of free time per day.Since burdensome, long-lasting, legally required procedures can also be imposed by a court on an individual.Seems like a slippery slope to be honest. reply bluGill 21 hours agorootparentThere is no right to that. Things that make it impossible should be looked on with suspicion, but the right does not exist.If you were willing to live like 1930 you could have plenty of free time, but 1930 means electric was a luxury most people didn&#x27;t have. reply MichaelZuo 20 hours agorootparentIf there is no right for individuals to have a productive life with plenty of free time per day than a huge number of HN comments on topics such as politics, housing, social welfare systems, healthcare, transportation, etc... are obviated.Which doesn&#x27;t seem like an appealing proposition to accept. reply jeroenhd 19 hours agorootparentThere are specific laws indirectly governing work-life balance, such as maximum hours worked consecutively, certain contract stupilations being null and voice because of general law, regulations regarding sick pay, and protections against discrimination, but I don&#x27;t think there are many countries that explicitly state the right to a productive life with free time.Rights to housing, welfare, and healthcare are generally handled independently. I&#x27;m not sure if there is a \"right to transportation\". Most rights originate from a basic \"right to a happy life\" ideal, but are split up and spelt out in particular sub-rights that are easier to enforce in court.Article 8 of the ECHR and similar human rights conventions seem to come close, but that&#x27;s mostly used against governments and laws.I don&#x27;t think it&#x27;s a bad idea to introduce such a right, but it needs to be carefully worded or it will cause a lot of trouble. reply numbsafari 20 hours agorootparentprevI think your calculation is wrong.There are plenty of things you can do in life that are productive and provide you with leisure time that don’t also mean you can destroy the lives of others.You might as well argue for slave labor. Because that’s certainly one way to be productive and have a lot of leisure time. But it’s wrong. None of this exists in a vacuum. Why should other people suffer so you can have free time?Find a better way. reply MichaelZuo 19 hours agorootparentHave you gotten confused about the topic?The court can already do this if the ruling holds which is why we are discussing it in the first place. Your phrasing it as if it&#x27;s up to individual members of society to decide to impose on each other. If you think this is relevant, can you describe how? reply bluGill 19 hours agorootparentprevYes, everyone wants a better life for themselves and they don&#x27;t want to consider all the trade offs of consequences of that. In particular they often want to force their own ideals on someone else. reply ballballball 21 hours agorootparentprevAhhh... The old \"corporations are people\" equivocation. reply pmontra 21 hours agorootparentWe had a post about that a few months agohttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36732729 reply true_religion 20 hours agorootparentIn the US, corporations have the same rights as people because they are collectively made up from people.In the EU, corporations have fewer rights than the individuals that collectively make them up.In other countries, different rules apply de jure or de facto.People’s main complaint about corporations is that no one personally gets hit with a civil charge and civil charges never seem to change the behavior of corporations. reply omnimus 21 hours agorootparentprevNo? Because corporations&#x2F;companies are not individuals? (no matter how they sometimes try to be) reply DannyBee 21 hours agorootparentprevThis is a fun quip, but are you literally suggesting that someone should have to read every webpage indexed by a search engine?That is what the comment you are responding to suggests doesn&#x27;t scale.If so, that seems, way off the deep end to me, and you know, slightly different from your local coal plant killing everyone through pollution.If not, what precisely is your okay (If non-scalable) solution to the problem presented here? reply numbsafari 19 hours agorootparentIt&#x27;s not just a fun quip: it&#x27;s a moral principle that I really think more people in our industry should come around to.What we do has consequences. Often times, profound consequences on vast numbers of lives. We have a responsibility, as individual contributors, managers, leaders, and \"founders\", for the outcomes of our work.If Google is as smart as they&#x27;d like us all to believe, they can find a way to make their business work. Sure, the margins might not be quite as fantastic, but society doesn&#x27;t owe them maximum return to its own detriment.It&#x27;s not my job to solve Google&#x27;s scalability problems, that&#x27;s their job. It&#x27;s my job to hold them just as accountable as my local coal power plant for the choices they make. If Google wants me to love their brand, and support their work, then they should stop being a social and intellectual polluter. It&#x27;s a lot easier to see and sense the danger of toxic fumes from a power plant than to see and sense the toxic danger of massive social media and tech companies, but they are no less real and no less lethal. reply arp242 20 hours agorootparentprevIf I put something defamatory on my website I can get sued.Why should it be different for Google?\"We cannot have someone response to every complaint!\" – okay, I understand. Then maybe don&#x27;t do whatever you&#x27;re doing at all then if you can&#x27;t handle the responsibility? reply jeroenhd 19 hours agorootparentprevIf you can&#x27;t build your product within the bounds of laws and morals, your product sucks or you don&#x27;t have what it takes to build such a product. reply SturgeonsLaw 22 hours agoparentprev> because it was on notice that the material was defamatory and refused to remove the information, it could not be found to have innocently circulated the informationThis is the second case she launched against Google. The first one determined that Google was publishing defamatory information, they settled, but continued to publish the information.So this is probably a situation where they should have had a human looking over it.\"Looking at every page\" doesn&#x27;t scale, but \"looking at every page we lost a court case over\" should be doable, you would think. reply viraptor 21 hours agorootparentEven looking at every page they get a legal complaint about shouldn&#x27;t be impossible for Google. reply Lutger 22 hours agoparentprevWell, the summary states:> and, because it was on notice that the material was defamatory and refused to remove the information, it could not be found to have innocently circulated the information.So in very least this is not just about linking to something, but about not removing defamatory content when being put on notice. The obligation to respond to requests and remove certain content from a search engine sounds a lot less unreasonable than merely being guilty of linking to something. reply glimshe 22 hours agoparentprevIrrespective of this specific ruling, the laws don&#x27;t need to make Google&#x27;s business scale or even be viable. Google should only exist if its business can comply with the rules we created for our society. reply postingawayonhn 21 hours agorootparentBut if Google adds a lot of value to our society should we not consider amending our laws to make the business viable? reply glimshe 21 hours agorootparentHow would that work? Business becomes big by breaking the laws then we change the laws so business stays big? reply postingawayonhn 20 hours agorootparentIt&#x27;s not exclusive to big business.Often laws are drafted without considering business models that have yet to be thought of. When those businesses start operating it&#x27;s common for laws to be changed to ensure they are properly regulated. reply Nasrudith 20 hours agorootparentprevHow did opening up dispensaries work after marijuana was legalized? People complain en-masse&#x2F;lobbied \"this law is fucking stupid\" and it gets amended. reply arp242 20 hours agorootparentprevThat&#x27;s quite literally Uber&#x27;s business model for large parts of the world.It&#x27;s rather sad that these kind of \"businesses\" aren&#x27;t just banned and prosecuted as criminal conspiracies. I really think that&#x27;s the appropriate classification for an organisation that goes in to a country, sets up a business it knows is illegal, stokes up violence, and reaps in profit (well, \"profit\", because it still doesn&#x27;t actually make a profit). reply unmole 19 hours agorootparent> stokes up violenceWhat now? reply arp242 18 hours agorootparentFrom https:&#x2F;&#x2F;www.theguardian.com&#x2F;news&#x2F;2022&#x2F;jul&#x2F;10&#x2F;uber-files-leak...Amid taxi strikes and riots in Paris, Kalanick ordered French executives to retaliate by encouraging Uber drivers to stage a counter-protest with mass civil disobedience.Warned that doing so risked putting Uber drivers at risk of attacks from “extreme right thugs” who had infiltrated the taxi protests and were “spoiling for a fight”, Kalanick appeared to urge his team to press ahead regardless. “I think it’s worth it,” he said. “Violence guarantee[s] success. And these guys must be resisted, no? Agreed that right place and time must be thought out.”The decision to send Uber drivers into potentially volatile protests, despite the risks, was consistent with what one senior former executive told the Guardian was a strategy of “weaponising” drivers, and exploiting violence against them to “keep the controversy burning”.It was a playbook that, leaked emails suggest, was repeated in Italy, Belgium, Spain, Switzerland and the Netherlands. reply unmole 17 hours agorootparentAh, so it&#x27;s the French Taxi drivers and far right thugs who were indulging in violence.But it&#x27;s clearly Uber&#x27;s fault. They were asking for it. &#x2F;s reply arp242 14 hours agorootparentThis is not \"pff, violence won&#x27;t happen\". That&#x27;s a subjective assessment. It&#x27;s \"okay, violence could happen, that would be fantastic for us! Let&#x27;s send our employees so that we can use that as an argueing point!\" (always good to make the other guy look like a violent thug).All in the context of Uber intentionally breaking the law (which is not my assessment, it&#x27;s their own, and that of the French authorities). reply ImPostingOnHN 15 hours agorootparentprevthe part about Uber using their employees as expendible pawns and encouraging them to go into harm&#x27;s way sounds pretty damning replyZambyte 21 hours agorootparentprevBy what metric do you claim Google \"adds a lot of value to our society\"? reply tyingq 22 hours agoparentprevWhat about this bit, though? Feels like they made their own bed to me.\"Google continued to publish the defamatory content in Australia for two years after it was found to be defamatory. In 2022, again self-represented, I endured another trial. Further details are on this page.\"https:&#x2F;&#x2F;drjaniceduffy.com&#x2F; reply Zambyte 22 hours agoparentprev> Even to suggest that Google must respond to every complaint of content on third party websites just cannot possibly scale.Must everything scale? reply almostnormal 21 hours agorootparentThe amount of human workers to process the requests definitively must scale with the requests.What may be desirable is cases where cost does not scale with revenue. But that should be no guarantee for long-term gains, because it provides room for competition that could make a cheaper offer at the same internal cost. reply Zambyte 19 hours agorootparentGonna be real with you, I have no idea what you mean. My point in asking was that scaling Google to infinity might in fact not be a good thing. reply almostnormal 16 hours agorootparentI agree with you.Just the use of \"scaling\" seemed a bit too narrow.Produce x pieces and earn y. Produce 1000 times x pieces and earn 1000 times y. That&#x27;s scaling in the traditional sense. \"Everything\" (+&#x2F;-) scales.Produce once at fixed cost and earn infinite - that&#x27;s something beyond just scaling. Maybe leverage? If it would provide the same quality and lower prices it would be good for society. If prices stay high and there is an indirect cost in degraded quality for the sake of huge gains something might not be right. reply SnorkelTan 22 hours agoparentprevThe view cached page link on google is a copy of a website stored on googles servers. IANAL but using automated software to blindly ingest everything under the sun and then redistribute it does not seem like an argument any court would accept for why they shouldn&#x27;t be liable for what they&#x27;re publishing. Also it seems like the issue in the article is that she specifically went through their take-down process and they still didn&#x27;t remove it. reply shadowgovt 22 hours agoparentprev [–] Google has a takedown process and it failed. At that point, Safe Harbor no longer applies and we&#x27;re in this category of \"What standard would a newspaper be held accountable to?\" replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Dr. Janice Duffy of Adelaide concluded her 12-year legal fight against Google, having won two defamation lawsuits against the tech giant.",
      "The case centered on Google's publishing of defamatory content from a website to its search engine page, even after Duffy's requests for the content's removal.",
      "Though the settlement details are confidential, this case emphasizes the emotional and financial strain of such proceedings and may lead to more responsibility for search engine companies to monitor their content more vigilantly."
    ],
    "commentSummary": [
      "A woman has won a 12-year lawsuit against Google over defamatory autocomplete suggestions, determining Google's responsibility for these suggestions and establishing a precedent for their removal upon notification.",
      "Various cases, including another in Australia, reflect the ongoing debate about search engine liability for defamatory content, the \"right to be forgotten,\" and the balance between freedom of speech and reputation protection.",
      "The discussion extends to issues of public criminal records and privacy, further questioning the responsibility and regulation of search engines in handling potentially defamatory content."
    ],
    "points": 264,
    "commentCount": 183,
    "retryCount": 0,
    "time": 1698058210
  },
  {
    "id": 37984404,
    "title": "Java implementation of a quantum computing resistant cryptographic algorithm",
    "originLink": "https://github.com/mthiim/dilithium-java",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up mthiim / dilithium-java Public Notifications Fork 6 Star 145 Code Issues Pull requests Actions Projects Security Insights mthiim/dilithium-java main 1 branch 0 tags Go to file Code Latest commit mthiim Merge pull request #3 from cjgulledge/patch-1 … 3ea149b Git stats 7 commits Files Type Name Latest commit message Commit time src First commit with code .gitignore First commit with code .travis.yml First commit with code LICENSE First commit with code README.md Update README.md pom.xml First commit with code README.md CRYSTALS - Dilithium This is a Java implementation of Dilithium, based on the C reference implementation and documentation. Further, I've wrapped it into a JCE provider, making it easy to use via a standardized interface. So what is Dilithium? The cryptographic algorithms RSA and ECC have long been known to be vulnerable to attacks using quantum computers via Shor's algorithm. While quantum computers of the prerequisite size do not yet exist in practice, there's an ongoing search for algorithms that don't have this vulnerability. In fact, NIST has been running a competition for over 6 years in order to identify quantum-safe alternatives. On July 5th NIST announced the three picks for Post-quantum digital signature schemes. Dilithium was among the three and was in fact recommended as the primary algorithm. Big congratulations to the authors! I wanted to study this new algorithm, and what better way than to try and implement it. This is what you are looking at :-) Dilithium is part of the CRYSTALS suite of algorithms and is based on algebraic lattices. Think linear algebra but where the matrix/vector entries are polynomials in the ring 𝑅 𝑞 = 𝑍 𝑞 [ 𝑋 ] / ( 𝑋 𝑛 + 1 ) . For much more information (including the specification and C reference implementation I used), see their page. Like the reference implementation, this implementation supports all three documented security levels (levels 2, 3 and 5), all using the deterministic signature scheme. It passes all the KAT tests from the package. It supports serialization and deserialization using the documented formats. I have a dependency on Bouncy castle, which provides the SHAKE128/256 algorithms used internally in Dilithium. IMPORTANT! This is a \"for fun\" implementation written in a couple of days. It's not intended to be production-grade code. No warranty or support of any kind is provided. However, it can be useful for diving into and experimenting with post-quantum algorithms. Use it at your own risk. If you don't like those terms, you must refrain from using this software. Loading the security provider DilithiumProvider provider = new DilithiumProvider(); Security.addProvider(provider); If you wish, instead of adding the provider using addProvider(), you can omit this line and explicitly provide the provider-object when calling the .getInstance() methods (see below). Key pair generation To generate a key pair you use: SecureRandom sr = new SecureRandom(); KeyPairGenerator kpg = KeyPairGenerator.getInstance(\"Dilithium\"); kpg.initialize(DilithiumParameterSpec.LEVEL2, sr);KeyPair kp = kpg.generateKeyPair(); Note that you must provide an algorithm parameter spec representing the desired security level - the above example uses level 2, but you can select 3 and 5 as well. The three parameter spec objects are declared as static fields on the DilithiumParameterSpec class. Alternatively, a static method, getSpecForSecurityLevel(), is provided on DilithiumParameterSpec, allowing you to easily retrieve the spec for a given level at runtime. Signing Having generated a key pair, signing works just the same as for other JCE providers. The example below signs a byte representation of \"Joy!\". Signature sig = Signature.getInstance(\"Dilithium\"); sig.initSign(kp.getPrivate()); sig.update(\"Joy!\".getBytes()); byte[] signature = sig.sign(); Signature verification Just as for signing, verification works as for other JCE providers Signature sig = Signature.getInstance(\"Dilithium\"); sig.initVerify(kp.getPublic()); sig.update(\"Joy!\".getBytes()); boolean b = sig.verify(signature); The boolean variable b now contains the outcome of the verification. Note that exceptions may be thrown in case of malformed signatures (as opposed to signatures that are merely incorrect). Key serialization/deserialization You can use the .getEncoded() method on the public and private key objects to obtain a byte representation of the key. The formats are compatible with the reference implementation. In order to instantiate the keys from the byte representation, a key factory is provided. You can use this with the provided DilithiumPublicKeySpec and DilithiumPrivateKeySpec classes. They are constructed using two parameters, namely the parameter spec (same as used for generating) and the byte representation. Note that the parameter spec is not encoded into the byte representation, and I decided to make the parameter choice explit rather than trying to infer it from length. In the future, I anticipate that ASN.1-based formats with OID's etc. will be standardized, and they will then explcitly encode the parameters. Of course, the serialization format could change as well as the standardization process moves along. byte[] pubkeyBytes = kp.getPublic().getEncoded(); // This is our bytes to be instantiated KeyFactory kf = KeyFactory.getInstance(\"Dilithium\"); PublicKey reconstructedPublicKey = kf.generatePublic(new DilithiumPublicKeySpec(spec, pubkeyBytes)); The private key may be reconstructed in the same fashion, using the DilithiumPrivateKeySpec class. Low-level use As an alternative to the low-level interface you can also use the static methods in the Dilithium class directly to generate, sign and verify. See e.g. how the JCE classes do it. Running the known-answer tests The official Dilithium package contains a known-answer test generator that generates a request and response file. I've provided a Java utility in KAT.java that can read the request file generated by the reference implementation, run through the tests and generate a corresponding response file. You can then compare this response file to the one generated by the official known-answer test generator and verify that they are byte-identical. The KAT.java program is run with parameters:Note that the desired security level (2, 3 or 5) must be provided as the 3rd argument. This must match what is configured in the config.h file in the C implementation when generating the response file used for comparison. DISCLAIMER This library is available under the Apache 2.0 license (see LICENSE). Note that the code has not been examined by a third party for potential vulnerabilities and as mentioned was not made to be used for production use. No warranty of any kind is provided. If you don't like those terms, you must refrain from using this software. References For more information on the CRYSTALS project, see their website. Contact Mail: martin@thiim.net About Experimental Java implementation of post-quantum crypto algorithm Dilithium (including JCE provider) Resources Readme License Apache-2.0 license Activity Stars 145 stars Watchers 3 watching Forks 6 forks Report repository Releases No releases published Packages No packages published Contributors 3 mthiim Martin Thiim winfamy Grady Phillips cjgulledge Jason Gulledge Languages Java 100.0% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37984404",
    "commentBody": "Java implementation of a quantum computing resistant cryptographic algorithmHacker NewspastloginJava implementation of a quantum computing resistant cryptographic algorithm (github.com/mthiim) 248 points by mooreds 22 hours ago| hidepastfavorite48 comments mthiim 15 hours agoHello everyone! I&#x27;m thrilled to see my project trending here on Hacker News. It&#x27;s a pure toy implementation inspired by the paper and its reference. While it aligns with all the provided test cases, I wrote it primarily for fun and to see it work seamlessly with the standard JCE interfaces. If you have any questions or feedback, please don&#x27;t hesitate to ask. Thanks for checking it out! Best regards, the author. :-) reply pjmlp 3 hours agoparentIt looks great piece of work, and you even took the extra effort for JCE integration, congratulations. reply mooreds 15 hours agoparentprevHeya, what would it take to productionize it? Are you aware of any java libs for quantum proof cryptography that are production ready? reply mthiim 14 hours agorootparentI&#x27;m not aware of any production-grade libs of these algorithms, but they might exist. While NIST did pick Dilthium as among the winners in summer 2022, it still hasn&#x27;t been fully standardized yet. The mathematical principles are final, of course, but they still need to be documented in the form of a standard, with many other details specified, such as the ASN.1&#x2F;binary encodings of keys, signatures, etc., so they can be used in the context of a broader PKI and certificates. Some of this is specified in the Dilithium submission (primarily because some of the values need to be encoded and processed as part of the algorithms themselves), but it doesn&#x27;t cover everything and doesn&#x27;t specify other details like OIDs, etc. This specification is also necessary before validation programs like FIPS 140-2 can get off the ground. reply simpaticoder 20 hours agoprevMost of the \"meat\" of this toy implementation of Dilithium can be found at https:&#x2F;&#x2F;github.com&#x2F;mthiim&#x2F;dilithium-java&#x2F;blob&#x2F;main&#x2F;src&#x2F;main&#x2F;... reply calibas 11 hours agoparentHere&#x27;s the Dilithium specifications too: https:&#x2F;&#x2F;pq-crystals.org&#x2F;dilithium&#x2F;data&#x2F;dilithium-specificati... reply rany_ 21 hours agoprevIs it a good idea to use quantum resistant crypto algorithm on-top of more established&#x2F;widespread algorithms like RSA&#x2F;ECDSA? I don&#x27;t feel comfortable using quantum resistant crypto due to how cutting edge it all is. reply timenova 20 hours agoparentIt seems that&#x27;s exactly what the community is doing.Cloudflare recently enabled post-quantum cryptography, in which they&#x27;re using X25519+Kyber [0]. Similarly, Signal&#x27;s post-quantum cryptography also uses the same [1].I&#x27;m guessing this spawned from the fact that a post-quantum algorithm was broken on classical computers a few years ago [2].So now any attacker would have to break both the classical algorithm and the post-quantum algorithm.[0] https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;post-quantum-to-origins&#x2F;[1] https:&#x2F;&#x2F;signal.org&#x2F;blog&#x2F;pqxdh&#x2F;[2] https:&#x2F;&#x2F;www.quantamagazine.org&#x2F;post-quantum-cryptography-sch... reply cbeach 19 hours agorootparentI&#x27;ve probably missed an important detail here, but if the post-quantum algo can be broken on classical computers, what use is it, vs. a combination of classical and quantum computers? reply mthiim 15 hours agorootparentThat algorithm was never chosen as a final candidate, unlike Dilithium and Kyber. Nevertheless, it remains intriguing because it advanced significantly in the competition until this vulnerability was identified, which allows for it to be cracked in just a few minutes on a standard computer. This underscores the inherent risk of rapidly introducing new algorithms, whether quantum or not. While RSA might become vulnerable to future quantum computers, its resilience since its public introduction in 1977 (aside from the need to increase key sizes) is quite an achievement. This is why new algorithms should always be paired with trusted classical algorithms to get the best of both worlds: if the new post-quantum component is flawed, at least you&#x27;re not worse off than if you had used classical algorithms. On the other hand, if quantum computers capable of breaking practical sizes of RSA or ECC emerge, there&#x27;s still the hope that the post-quantum element remains intact. reply hannob 19 hours agorootparentprevThe algorithm that was broken is of course no longer used.The point is: Many of these algorithms are rather new. The fact that multiple post quantum algorithms have been broken that were seen as promising shows that there is a risk with these new algorithms.However, it should be said that the broken algorithms were in, let&#x27;s say, more experimental subfields of post quantum cryptography. reply insanitybit 19 hours agorootparentprevAt this point quantum computers aren&#x27;t breaking anything. Adding protections against them is nice because we&#x27;re theoretically safe in the future. We don&#x27;t want to compromise our safety now by choosing algorithms that are less battle tested though, so it&#x27;s best to layer them.If it turns out that both the classical and quantum hard algorithms are weak we&#x27;re just screwed, yes. That said, at this point it&#x27;s not even clear, as far as I know, that many classical algorithms are event going to be broken under QC. reply mthiim 14 hours agorootparentAgreed. While manufacturers do show an impressive increase in the number of noisy qubits, we still have yet to see a demonstration of quantum error correction at anywhere near the levels needed to pull of a QC that breaks e.g. RSA. reply insanitybit 11 hours agorootparentIt&#x27;s also unclear (to me, perhaps not to others!) if the conversion from O(2^n) -> O(2^n&#x2F;2) means it will be faster in practice on quantum hardware.https:&#x2F;&#x2F;eprint.iacr.org&#x2F;2017&#x2F;811> Reassessing Grover&#x27;s AlgorithmThe proposal of this paper is that Grover&#x27;s does not mean we need to double the size of symmetric keys to account for QM but that just a few extra bits are enough to prevent it from being efficient.Of course, there may be new QM algorithms that don&#x27;t suffer and, again, it&#x27;s best to start preparing now and not later. But I think it&#x27;s noteworthy for the discussion about quantum preparedness. reply tptacek 15 hours agorootparentprevSecure transports are built out of asymmetric key agreement and symmetric bulk encryption, glued together with symmetric hashes. The symmetric cryptography isn&#x27;t meaningfully threatened by any QC we&#x27;re yet aware of. Hybrid PQC&#x2F;classical schemes do two key agreements (an ECC kex and a LWE kem), and then plug both results into HKDF (conceptually: a symmetric hash) to derive a shared secret.In that scheme, you have to compromise both the PQC and ECC key agreements, independently. reply aardvarkr 18 hours agorootparentprevIt was “a” post quantum proposed algorithm, not “the” post quantum algo. Don’t judge an entire field because of one proposal that didn’t work. reply mratsim 18 hours agorootparentprevIt was broken because of a mathematical breakthrough using theory lurking in the dark corners of math. The protocol itself was also using some somewhat dark corner of math.Which is why having as many eyes as possible is important.Now it&#x27;s very well possible that it comes back with mitigations.And even the still OK candidates are using a young area of math. reply Deukhoofd 21 hours agoparentprevAs far as I&#x27;m aware, Shor&#x27;s Algorithm is still unfeasible because it requires far more qubits than currently available to execute in any reasonable time. It&#x27;d require several million qubits, while the most cutting-edge devices currently only have a couple of hundreds at best.I wouldn&#x27;t worry too much about post-quantum algorithms for any production code in the next couple of years (decades?) myself. reply japanuspus 19 hours agorootparentQuantum factoring may not be quite as far distant as you might thinkMost importantly, Shor is not the algorithm of choice for first-gen hardware where the central challenge is likely to be circuit depth due to error correction overhead. The current front-runner is a probably proposal by Regev [0] with a space-optimization by Ragavan et al. [1], which factors an n-bit integer with O(n log n) logical qubits and a circuit depth of O(n).What you should be looking for when studying quantum computing press releases is \"fault tolerance\": A central problem in QC is that the underlying hardware needs to be better than an (architecture-specific) threshold, before error-correction can be applied without introducing more errors than it corrects.Nobody has really crossed the threshold yet with scalable hardware, and when someone does, the overhead will be abysmal (2 or 3 layers of error correction, each with a factor ~100 overhead in space and time). Still, there are two reasons to be optimistic:One reason is that once a system crosses the threshold, any improvement in hardware will result in exponential improvements in the encoded operations, meaning that there will be a Moore-style exponential development.Another reason is that there are several \"dark mode\" VC-funded companies working towards intrinsically scalable systems based on optical QC: If any of these achieve fault tolerance, they will be scalable from day one.[0]: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2308.06572 [1]: http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2310.00899 reply hypeatei 20 hours agorootparentprevI&#x27;d probably be looking at a shorter timeline, just because of the Harvest Now, Decrypt Later strategy[0].[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Harvest_now,_decrypt_later reply Frost1x 20 hours agorootparentI&#x27;d say it ultimately depends on the information you&#x27;re encrypting. Information and secrecy around it often has some sort of temporal&#x2F;time relationship tied to the information and surrounding context. If it&#x27;s something you wish to protect indefinitely or for a long time into the future, it&#x27;s important to consider now. If n the other hand it&#x27;s some rotating fairly randomly generated password that expires monthly, quarterly, whatever or say session information that expires after a period then you don&#x27;t need to worry so much about this. Context of the information you&#x27;re protecting is important to determine time periods you wish to protect it for and you should already be considering this today when choosing protection strategies, IMO. reply rainsford 18 hours agorootparentThat&#x27;s an approach that makes sense in theory, but in practice you&#x27;re almost certainly better off assuming a long time horizon for protecting everything.For one thing, it&#x27;s not always obvious what&#x27;s short term vs long term information and you could end up applying short term protection to information that has long term value in a scenario you didn&#x27;t consider. For example, encrypted session information that expires might not be useful in gaining access to an account, but it could potentially be used to track you in historical data.The other problem is that most systems (and people) aren&#x27;t great at segregating information that needs short term vs long term protection, so it&#x27;s hard in practice to have a strategy based on applying different cryptographic protection to different information. Most encrypted protocols and systems deal with a mix of information that ranges from inconsequential if revealed even now to requiring long term confidentiality because it&#x27;s much harder to try to deal with that information separately. There&#x27;s also the practical argument that once I have a protocol or system to protect high value, long term info, why wouldn&#x27;t I just use that for everything? Modern HTTPS is ridiculous overkill for the vast majority of things it protects, but there&#x27;s really no reason to use something worse even if you could get away with doing so.This is basically the premise of HTTPS everywhere and similar encrypt all the things concepts. It makes a lot more sense to just protect everything instead of trying to figure out what needs protection and what doesn&#x27;t and hoping you didn&#x27;t get it wrong or that nothing changes over the years. Same goes for post-quantum crypto. You might be OK not adopting it for things you think don&#x27;t need protection beyond the time a practical quantum computer comes around (good luck guessing that time horizon btw), but it&#x27;s both easier and less error prone to just post quantum all the things. reply Cthulhu_ 19 hours agorootparentprevIf it&#x27;s a password, sure, rotating it every once in a while should secure your account if someone has stored a copy of the encrypted (usually hashed) version; that said, rotating passwords is no longer a recommended practice, and second, it&#x27;s more important for encrypted data, like hard drives, online e2e-encrypted chats, internet usage, images&#x2F;files, etc. You can change the password &#x2F; key on those too, but if someone already has a copy of the old password encrypted data it may be cracked later on.In practice this is probsbly reserved for important people I suppose. reply Strilanc 16 hours agorootparentprevYou also probably want post-quantum crypto if you&#x27;re making anything that can be updated, and there&#x27;s a chance the thing may sit in a drawer for 10 years before being connected to the internet. The crypto you use to authenticate an update&#x27;s origin needs to still be secure at take-out-of-drawer time. reply mthiim 14 hours agorootparentprevTrue - on the other hand, that fear&#x2F;principle could be applied to all algorithms that could theoretically be broke in the future. There&#x27;s a lot of uncertainty concerning the scalability of quantum computers and quantum error corrections. In the neare future it seems more likely that the post-quantum algorithms might be broken (even on normal computers) compared to quantum computers cracking RSA&#x2F;ECC (so one should at least combine to get the best of both worlds) reply anticrymactic 20 hours agorootparentprevThis exact sentiment is why passwords are still hashed Unding md5. While I wouldn&#x27;t exactly worry about Post-Quantum right now, it&#x27;s important to implement and be ready to switch. reply KMag 19 hours agorootparentEncrypted data is almost certainly being recorded now in anticipation of quantum computers being able to break it later. reply pests 8 hours agorootparentThe NSA&#x27;s Utah datacenter has to store something! reply Workaccount2 19 hours agorootparentprevI think the fear people have is an attacker storing captured encrypted data and decrypting it later. It may be five or ten years out of date by the time it is decrypted, but even then it could still prove to be fruitful for the attacker.I&#x27;m sure many oppressive regimes would love to know what their citizens where privately talking about, even if it was ten years ago. I think its a valid concern that quantum computing might take off, and in ten years you could run shores algo on an AWS instance. Long con attackers could MITM chats for juicy blackmail in the future. reply kvathupo 15 hours agorootparentprevI&#x27;d agree. I&#x27;d say adversaries are unlikely to steal data now, wait a decade or two, and then decrypt on a quantum computer for _most_ private company ip. It&#x27;s only relevant to government at this stage, yet Congress is, unsurprisingly, out-of-touch (or perhaps age?) in this regard.Fun fact: I emailed my senator, chair of the foreign relations committee, on concerns over China&#x27;s heavy investment here. I got a reply from an overworked intern about banning Tiktok ! reply jedberg 16 hours agorootparentprev> I wouldn&#x27;t worry too much about post-quantum algorithms for any production code in the next couple of years (decades?) myself.For data in transit that&#x27;s probably fine, but for data at rest, you have to consider how long that data might remain at rest. If you have 30 year old encrypted data that is now breakable, is that a problem? It depends on the use case.Also keep in mind that any data in transit could be tapped and saved and become data at rest.So really you have to ask yourself, is it critical that this data remain encrypted in 20 years? reply billti 9 hours agorootparentprevThis recently released page might be of a lot of interest to this discussion regarding crypto algorithms and the size of the quantum hardware needed. (Disclaimer, I work on the Azure Quantum team that builds this).https:&#x2F;&#x2F;quantum.microsoft.com&#x2F;en-us&#x2F;experience&#x2F;quantum-crypt... reply sesm 20 hours agorootparentprevAlso, some interpretations of Quantum Mechanics, like Dioshi-Penrose objective collapse interpretation, imply a physical limit on the number of qubits.However, whether you should worry about post-quantum crypto or not is a risk assessment question, not a physical one. reply notfed 14 hours agorootparentDo any interpretations not have such a limit? reply mthiim 14 hours agorootparentMany-worlds etc. does not have such a limit. There are interpretations that posit that collapse is triggered by the system reaching a certain size (also GRW theory etc.). Such interpretations would preclude big quantum computers. Note that such interpretations aren&#x27;t purely interpretations because they actually do posit measurable new physical phenomena. But since the relevant experiments are not currently possible to carry out and since they do have significant interpretational consequences, they are often called intepretations. reply HillRat 16 hours agoparentprevYes, the current generally-but-not-universally-accepted standard is \"hybrid encryption\" (not the same \"hybrid\" as KEM&#x2F;DEM, though you&#x27;d generally use hybrid encryption with a hybrid KEM&#x2F;DEM cryptosystem), which ensures that you&#x27;d have to break both classical and post-quantum algorithms to get at your plaintext. Whether you simply wrap encryptions or use a hybrid KEM combiner (see, e.g., Campagna and Petcher for examples) is a more subtle question better suited for more subtle minds than mine. reply colmmacc 16 hours agoparentprevIf quantum computers become more practical in our lifetimes, we don&#x27;t want our current secrets vulnerable to that analysis. Scaling a quantum computer definitely isn&#x27;t as simple as the evolution from valves and transistors was to integrated circuits ... but estimates from experts on the difficulty vary from \"this is very very very difficult\" to \"this will remain physically impossible\". Either way that&#x27;s still more likely than brute-forcing an encryption key with modern standards; so there&#x27;s a rationale for prioritizing post-Quantum security today.That said, you are right to be wary; if there is a side-channel or implementation vulnerability in a PQ algorithm ... then you are much worse off using it. Worst-case; imagine an RCE in the PQ implementation. So it&#x27;s a good idea to be cautious and check the code rigorously. reply johncolanduoni 20 hours agoparentprevThere’s no real risk to schemes that use both post-quantum and conventional crypto in such a way that a break in either is insufficient to bring down the combination. For key exchanges that’s quite easy; you can just XOR or concatenate the outputs depending on the scheme. reply dwheeler 18 hours agoparentprevYes, I think so. More widespread algorithms have been far more thoroughly studied; they&#x27;ve been studied for longer and stood the test of time. Their weaknesses, and how to counter them, are better understood. They&#x27;re busted by general-purpose large scale quantum computers, though, if those ever happen. Combining their strengths sounds like the best approach where data is very sensitive and the overhead is acceptable. reply slim 18 hours agoprevA few days ago Daniel Bernstein warned about effort by NSA to spread flawed implementations of post quantum crypto (can&#x27;t find the link) reply chasil 16 hours agoparentHere is the article you mentioned, although it addresses Kyber, not Dilithium.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37756656 reply pests 8 hours agorootparentThere have been two posts by djb in the month of October on this topic. I&#x27;m not sure which slim was talking about but the newest one was published today:https:&#x2F;&#x2F;blog.cr.yp.to&#x2F;20231023-clumping.htmlI believe there is an HN submission on it already. reply victor106 9 hours agoprev> The cryptographic algorithms RSA and ECC have long been known to be vulnerable to attacks using quantum computers via Shor&#x27;s algorithm.If this is true and quantum computers of that size do come into existence how does it impact Bitcoin? reply Salgat 9 hours agoparentThey would get migrated before it became an issue. And even if it happened, they&#x27;d just fork it with a quantum resistant encryption at the point of first known attack. reply rullelito 36 minutes agorootparentHow on earth would they patch all the historical blocks? reply ianopolous 10 hours agoprevI wrote&#x2F;ported a single file Java implementation of another of the post quantum signature schemes - sphincs+ here:https:&#x2F;&#x2F;github.com&#x2F;Peergos&#x2F;sphincsplus reply mooreds 21 hours agoprev> This is a \"for fun\" implementation written in a couple of days. It&#x27;s not intended to be production-grade code. No warranty or support of any kind is provided. However, it can be useful for diving into and experimenting with post-quantum algorithms. Use it at your own risk. If you don&#x27;t like those terms, you must refrain from using this software. reply andai 16 hours agoprev [–] Thought it was gonna be OTP ;) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This text discusses a Java implementation of the Dilithium algorithm, a post-quantum cryptographic alternative to RSA (Rivest–Shamir–Adleman) and ECC (Elliptic-curve cryptography).",
      "This implementation supports three security levels and includes functions for generating keys, signing, verifying, as well as serializing/deserializing keys.",
      "It's explicitly stated that this implementation is not meant for production use and carries no warranty, but the code is freely accessible under the Apache 2.0 license."
    ],
    "commentSummary": [
      "The article focuses on the development of a quantum-resistant cryptographic algorithm in Java, with an emphasis on the current absence of production-ready libraries and promising prospects.",
      "Long-term data protection challenges and potential risks associated with implementing these new algorithms due to quantum computing advancement are discussed.",
      "Hybrid encryption, a combination of post-quantum and traditional cryptography, is suggested as a potential solution, albeit with concerns about its reliability and effects on digital currencies like Bitcoin."
    ],
    "points": 248,
    "commentCount": 48,
    "retryCount": 0,
    "time": 1698062052
  },
  {
    "id": 37987573,
    "title": "UK government surveilling social media of teaching assistants",
    "originLink": "https://reclaimthenet.org/uk-government-caught-surveilling-social-media-of-teaching-assistants-and-librarians",
    "originBody": "Menu Defend free speech and individual liberty online. Push back against Big Tech and media gatekeepers. Email Subscribe now Issue: October 23, 2023 UK Government Caught Surveilling Social Media of Teaching Assistants and Librarians Monitoring dissent. By Christina Maas Posted 11:44 am If you're tired of censorship and dystopian threats against civil liberties, subscribe to Reclaim The Net. A startling revelation indicates that the UK government has substantially amplified its surveillance of the online activity of educators. Ranging from leading education experts to teaching assistants and librarians earning modest salaries, the magnifying glass of surveillance closely monitors posts critiquing education policies. The discovery was made by The Observer, revealing that the Department for Education is keeping extensive records of such posts, something that we’ve previously covered. This revelation highlights the burning issues of free speech and censorship, causing widespread disquiet among the educational community. The surveillance of educators’ online activity portrays a scenario where dissent or criticism of government policy is not only surveilled but also cataloged, potentially affecting the educators’ professional careers. Educators across the UK have demonstrated a wave of shock and anger in response to the discovery. Many have submitted Subject Access Requests [SARs], a Right to Access provision within the General Data Protection Regulation, requiring the Department of Education to disclose the information it holds under their names. These educators found file lengths spanning up to 60 pages, documenting their tweets and comments opposing the government’s policies and criticizing the schools inspectorate, Ofsted. Nikki Cleveland, a higher-level teaching assistant and primary school librarian, was astounded to find that even her tweets concerning issues such as inadequate funding for school libraries and criticisms of Ofsted had been flagged and stored by the Department. Her discovery has only raised her cynicism towards the government and the Department of Education, questioning their apathy towards the challenges schools face daily. This disturbing surveillance operation extends to more than just educators. Jon Biddle, a primary school teacher and English lead, reported that “dozens of other teachers” he knew had also discovered their accounts were under scrutiny. The scope and depth of this surveillance has led to growing skepticism about the Department’s priorities and resource allocation. Cases have also surfaced of the Department attempting to silence voices critical of government policy. Early years specialists Ruth Swailes and Aaron Bradbury have previously faced attempts from the Department to cancel their conference due to their earlier critiques. Similarly, Dr. Mine Conkbayir, a renowned early childhood author, was allegedly threatened with funding withdrawal for a conference she was scheduled to keynote, due to her criticisms. As she recounts, the Department also attempted to curtail her talk duration and verify her speech contents, pulling the strings of academic dialogue. In response to these revelations, the Department has chosen to remain largely opaque, stating that it would not be appropriate to comment on individual cases. If you're tired of censorship and dystopian threats against civil liberties, subscribe to Reclaim The Net. Defend free speech and individual liberty online. Push back against Big Tech and media gatekeepers. Email Subscribe now Load comments Americans’ Trust In News Media Falls To New Lows October 23, 2023 Read » New York AG Letitia James Backtracks on Censorship Demands of Rumble October 22, 2023 Read » Al Jazeera Could Be Removed From Israel Under Proposed New Law October 22, 2023 Read » Big Tech alternatives: VPN Providers Private Search Engines Free Speech Friendly Discord Alternatives Private Web Browsers Free Speech Friendly and Privacy-focused Social Networks Free Speech Friendly Video Sharing Platforms Login Home Merch Donate Contact Sitemap RSS Privacy Light Dark Defend free speech and individual liberty online. Push back against Big Tech and media gatekeepers. Email Subscribe No thanks > Login",
    "commentLink": "https://news.ycombinator.com/item?id=37987573",
    "commentBody": "UK government surveilling social media of teaching assistantsHacker NewspastloginUK government surveilling social media of teaching assistants (reclaimthenet.org) 226 points by LinuxBender 18 hours ago| hidepastfavorite115 comments nanna 15 hours agoURL should be changed to source [1] and title changed to reflect that the UK govt is also surveilling TAs, not only.[1] https:&#x2F;&#x2F;www.theguardian.com&#x2F;politics&#x2F;2023&#x2F;oct&#x2F;21&#x2F;uk-governme... reply ThePowerOfFuet 46 minutes agoparent> title changed to reflect that the UK govt is also surveilling TAs, not only.I mean, does this actually need to be said? Would anyone think TAs are the only citizens under surveillance? reply echelon_musk 15 hours agoprevIt&#x27;s certainly chilling to have confirmed what I&#x27;ve long suspected is being done.If OpenAI are scraping public tweets for their LLM then it&#x27;s hard for me to believe this government isn&#x27;t also scraping for their own power and control.Perhaps unsurprisingly this seems to be about as high quality as the track & trace system that looted £37 billion from the tax payer [0].It makes one think about the importance of anonymous donations to NGOs who are trying to hold the government accountable for fear of future targeted surveillance for valuing \"freedom\".[0] https:&#x2F;&#x2F;committees.parliament.uk&#x2F;committee&#x2F;127&#x2F;public-accoun... reply mellosouls 12 hours agoprevOP is summary link to original Guardian article, which itself is an update of the original from a couple of weeks ago:https:&#x2F;&#x2F;www.theguardian.com&#x2F;education&#x2F;2023&#x2F;sep&#x2F;30&#x2F;revealed-u...None of the articles seem to have proof or clarity of the claims in the form of actual documents and direct quotes from them. Not to say they don&#x27;t exist, it&#x27;s clear they do from the witness statements, but there is no detail to support the claim of some policy of active monitoring.This seems like a serious overreach of government so the lack of meat here is curious. reply injidup 14 hours agoprevWhat one posts on public social media sites is public. Is this surveillance? reply happytiger 2 hours agoparentYes. It’s data collected from public sources of information but it is surveillance.It may be legal, it may be public information, but this is a government collecting information on its citizens: government surveillance.Consider the effects:> Government monitoring of social media can work to people’s detriment in at least four ways: (1) wrongly implicating an individual or group in criminal behavior based on their activity on social media; (2) misinterpreting the meaning of social media activity, sometimes with severe consequences; (3) suppressing people’s willingness to talk or connect openly online; and (4) invading individuals’ privacy.Now if you’re cool with those effects, rock on. I’m not keen.https:&#x2F;&#x2F;www.brennancenter.org&#x2F;our-work&#x2F;research-reports&#x2F;soci... reply rudasn 13 hours agoparentprevDunno... If I followed you around while in public and recording everything you said and did, in public, is that surveillance? reply grecy 11 hours agorootparentIt is very much legal, and law enforcement don&#x27;t need a warrant to do so. reply jpsouth 10 hours agorootparentI think by sheer definition it would be surveillance though. reply theptip 9 hours agoparentprevIs installing a CCTV camera to record a public park surveillance? Yes of course, it is clearly and unambiguously labeled as such.Surveillance is orthogonal to whether the subject is in public or in private. reply kbelder 13 hours agoparentprevYou know, I think this sounds like a horrible overreach by the UK government, but your point is at least worth considering. This isn&#x27;t reading emails or tapping phone calls, this is public info. reply peyton 13 hours agorootparentIs there a public list of UK teachers I can use to conduct my own dragnet surveillance of dissidents? If not, surely combining both private and public information on people to track dissent is an overreach. reply none_to_remain 12 hours agoparentprevI think it counts as surveillance when it&#x27;s published material, but surveillance of public material does not seem so troublesome to me.For ex. if these teachers had instead published their complaints in old-fashioned letters-to-the-editor in print newspapers, I don&#x27;t think anyone would be complaining that the government reads the newspapers. You could still complain about the chilling of dissent and the waste of resources. reply ryandrake 12 hours agorootparentBut, posting publicly to social media is almost exactly like a letter to the editor. You send your message to a company, the company reviews it, and then usually publishes it publicly for all to see.I would not feel \"chilled\" if someone (an employer, government, or whoever) trawled through my HN posts and made some kind of judgment or took action over what I post. I would expect it. It&#x27;s public after all. I certainly moderate what I say here knowing this (maybe that&#x27;s the chilling effect you mention?) reply bluefirebrand 11 hours agorootparent> I certainly moderate what I say here knowing this (maybe that&#x27;s the chilling effect you mention?)Yeah that is the chilling effect.Yes, it&#x27;s likely there are some things that are better to be \"chilled\". For instance if you were advocating for violence against public figures.But imagine the day your credit rating gets dinged because you post online that you disagree with some new tax reform bill being proposed. This happens because the agency managing your credit score is also lobbying for this tax reform.Or you criticize a government official online and the police show up at your door, which is something that absolutely has happened throughout history.The fact they are watching your social media isn&#x27;t the problem. It&#x27;s how they can (and eventually probably will) abuse that surveillance. Or whoever replaces them next time there is an election. reply mecha_ghidorah 11 hours agorootparentprevI&#x27;d definitely feel chilled, because what I post here isn&#x27;t under my meatspace identity. I don&#x27;t think they should have a right to pass judgement over something I&#x27;m doing under a pseudonym that can&#x27;t be attached to me easily reply corobo 9 hours agorootparentprevWell sure, but what if you throw in the possibility of mistaken identity?Might not be too chilling.. as long as they get the right person. Best hope other Ryan just parties it up a bit and nothing more sinister if you want to become a teacher. reply creer 6 hours agoparentprevCollecting and judging everything is. It&#x27;s legal sure - perhaps because it&#x27;s new that it can be done at scale (aside from the old East Germany). And it&#x27;s because it&#x27;s new that it&#x27;s a question now worth asking. I mean it was always done for political reasons. See CIA &#x2F; FBI dossiers (and harassement) of people they didn&#x27;t like. Again not at scale and not of everyone before even any reason to not like anyone. reply vfclists 13 hours agoparentprevIf it is targeted, tracked, stored and analyzed it is surveillance. reply mandmandam 12 hours agorootparentDon&#x27;t forget &#x27;acted on&#x27;.They&#x27;re using this data to make sure people who criticise them can&#x27;t acquire influence.And it&#x27;s all in secret, short of canny SAR&#x27;s.People can question if this is technically surveillance, but in context, that question is basically misdirection. reply kakoni 14 hours agoprevWhats the latest on Palantir and National Healh Service deal? reply mandmandam 14 hours agoprevA lot of people here seem to be missing a critical point: the government are actively using this information to alter the narrative and create a chilled environment.> Cases have also surfaced of the Department attempting to silence voices critical of government policy. Early years specialists Ruth Swailes and Aaron Bradbury have previously faced attempts from the Department to cancel their conference due to their earlier critiques. Similarly, Dr. Mine Conkbayir, a renowned early childhood author, was allegedly threatened with funding withdrawal for a conference she was scheduled to keynote, due to her criticisms. As she recounts, the Department also attempted to curtail her talk duration and verify her speech contents, pulling the strings of academic dialogue.... People here seem to think all this creepy data is just getting shipped into a box, rather than being deliberately acted upon.But it&#x27;s very clear that is not the case. The reality is far more disturbing. We&#x27;re looking at primary school teachers suffering in their career (!!!) for the &#x27;crime&#x27; of criticising policy. That&#x27;s insane. reply nxobject 15 hours agoprevNote that people requesting information collected on themselves was enabled by the GDPR&#x27;s information-related-to-me provisions, as retained after Brexit. I look forward to the Conservatives dismantling it after realizing that it&#x27;s used against them. reply rahimnathwani 12 hours agoparentThose provisions were introduced by the Data Protection Act 1984. At the time the legislation was introduced and passed, the Conservatives were in power.Search for &#x27;Part III&#x27; and read the first item here: https:&#x2F;&#x2F;www.legislation.gov.uk&#x2F;ukpga&#x2F;1984&#x2F;35&#x2F;enacted reply nxobject 10 hours agorootparentI stand corrected! Thank you so much. I think I&#x27;ll let my wrong assumptions above speak for themselves about my biases. reply some_random 13 hours agoprevI remember getting in arguments like a decade ago with British people who insisted that their lack of actual rights didn&#x27;t matter and it was actually better to have privileges bestowed upon them by decree of their Queen as chosen by God. I wonder if any of them think differently now. reply Symbiote 11 hours agoparentThey were obviously joking, it was probably funny to watch an American (?) believe all that.More seriously, more people should be concerned about the Conservative party&#x27;s disdain for the Human Rights Act and suggested intention to withdraw from the European Convention on Human Rights: https:&#x2F;&#x2F;www.theguardian.com&#x2F;law&#x2F;human-rights-act(So you&#x27;ll see the UK does have a list of rights, but like everything else it&#x27;s a normal law that can be changed by Parliament in the usual way -- there&#x27;s no special constitutional law requiring more effort to change, and&#x2F;or a special court to uphold it.) reply DiscourseFan 10 hours agorootparentThe greatest difference between the US and the UK is just that: the US is a far more chaotic, violent, and generally unpleasant society compared to the UK, but it has an extraordinarily robust legal system and institutions that balance each other&#x27;s power so that nobody is ever really in full control. The UK is a fairly pleasant place to live--at the moment. But things are starting to go downhill a bit, the government is becoming, ever so slowly, more authoritarian, and there is no legal backstop: in the end, the UK is an absolute monarchy with an embodied sovereign power, everything goes back to the Crown. If a far-right party comes to power and parliament becomes effectively dissolved, there is no telling how far and how rapidly they could change society.That is simply not the case in the US, where, in fact, a right wing populist did come to power, did try to subvert the election process, did try to (indirectly) eliminate congress, and failed on every front. And he failed so hard that people might re-elect him since they don&#x27;t think he could succeed the second time around anyway. Yes, people shoot each other all the time, the violent crime rate per capita is incredibly high, and society in general is plagued by inequality and racial tension. But the chaos drives the country forward. The UK is quiet, calm, comfortable (workers schedule their strikes!) There is no room for real organized dissent. It would take the dissolution of the monarchy for real change to come about, but they aren&#x27;t going to do that here. They aren&#x27;t going to do anything. reply graemep 11 hours agoparentprevI have never heard any British person say anything remotely like that.I have not heard any British person say the Queen was chosen by God.I THINK people may have been talking about the value (or not) of written constitutional guarantees. reply ecommerceguy 14 hours agoprevAnd yet we have 60 Minutes GLORIFYING these scumbags. \"It&#x27;s a big club and you ain&#x27;t in it\" reply pydry 15 hours agoprevJust like Russia.I wish the UK would spend a bit less effort trying to provoke and fight Russia to the death and a bit more effort trying not to become Russia.I also wish that wasn&#x27;t a controversial opinion. reply hermitcrab 13 hours agoparentYes. The direction and velocity of travel is very worrying. We&#x27;ve already lost a lot of our rights for peaceful protest. Inconveniencing people with your protest? That&#x27;s the whole point of protesting isn&#x27;t it? Fuck the Conservative party. I hope they are destroyed at the next election. reply deadfish 12 hours agorootparentNo need for hope. At this point surely it is a given? reply hermitcrab 12 hours agorootparentThe UK Labour Party have a long history of snatching defeat from the jaws of victory. And Starmer, while a much better human being than any of the current Tory leadership, appears to be lacking in political instincts. reply pydry 11 hours agorootparentHe&#x27;s no different : https:&#x2F;&#x2F;skwawkbox.org&#x2F;2023&#x2F;03&#x2F;02&#x2F;starmers-labour-abstains-on... reply hermitcrab 7 hours agorootparentHe has made some worrying decisions. Including much sitting on the fence on important issues, such as Brexit. I&#x27;m not wild about him getting in with a massive majority. reply mcpackieh 13 hours agorootparentprev> We&#x27;ve already lost a lot of our rights for peaceful protest. Inconveniencing people with your protest? That&#x27;s the whole point of protesting isn&#x27;t it?Meanwhile in Canada: truckers honking is literally terrorism because it hurts my ears :( reply ClumsyPilot 14 hours agoparentprev> a bit more effort trying not to become Russia.I frequently tell people we are becoming like Russia, and they get worked up. Then I ask them why the \"Russia report&#x27; was supressed and they get even more worked up reply happytiger 15 hours agoprevRemember this is “keeping files on posts that criticise education policies” — tracking political dissenters who don’t like the government’s policies but have done nothing wrong or illegal.While we’re off focusing on encryption debates and the online safety bill, the UK government isn’t waiting around.Just what is “accredited technology”? As defined in that bill, and how much does encryption play a role when monitoring policies in general cause a general chill in what people are willing to talk about online?I wonder what other aspects of normal behavior are being tracked? It must be extensive. reply bluescrn 15 hours agoparentMeanwhile, when groups of activists surveil dissenters&#x2F;wrongthinkers on social media, actively make lists of them and try to get them fired or worse for their speech&#x2F;thoughts, many still defend that as &#x27;perfectly reasonable consequences of unacceptable speech&#x27; reply gretch 15 hours agorootparentThis is the government doing it, which is clearly wrong because they are supposed to be protecting your speech rights.If someone robs a corner gas station, you think “dang that’s a shame”.If the military robs a gas station, you think “umm wtf?” reply jlawson 14 hours agorootparentNo, if someone robs me at a corner gas station, I think \"my government should have done a better job protecting my rights\".Having your human rights violated is not like stubbing your toe. reply space_fountain 15 hours agorootparentprevI think regardless of what you think of policing speech generally it just is clearly worse when the entity controlling the police does it reply notahacker 14 hours agorootparentprevYes, because obviously the only possible options are a state surveillance program to flag up any teaching assistants who criticise any aspect of government policy and teaching bureaucracy, or the sort of \"free speech absolutism\" that concludes that literally nothing a teacher could say could ever render them unsuitable for a teaching job.No middle ground is possible. reply robertlagrant 13 hours agorootparentGood to get the sarcastic straw man out of the way, so we can get back to the actual conversation. reply partitioned 14 hours agorootparentprevBut that activism is free speech itselfalways funny when the free speech absolutist gets mad when people use free speech to cancel someone reply robertlagrant 12 hours agorootparentPeople conspiring to raise up hatred of an individual, and people of the same mind in HR departments green lighting the acquiesence to that hatred, is the problem. Someone shouting a swear word at me while killing me is unpleasant, but I&#x27;ll allow it. It&#x27;s the killing that&#x27;s the problem. reply anigbrowl 10 hours agorootparentThat kind of depends on the individual and what they&#x27;re doing, no? reply robertlagrant 5 hours agorootparentNot the individual, no. Only what they&#x27;re doing. reply hamhock666 13 hours agorootparentprevYes it’s free speech, I think the issue here is that companies care what their employees say about politics outside of work, enough to fire them if they find out.Not really in the spirit of free speech. reply bluescrn 59 minutes agorootparentIt&#x27;s not so much that the companies care about the individual &#x27;wrongthinkers&#x27;, they&#x27;re worried about what the activists could do to the reputation of their company&#x2F;brand.The activist behaviour is close to blackmail - &#x27;punish this person for us now, or we&#x27;ll hurt your company&#x27;. reply oooyay 15 hours agorootparentprevEveryone across the spectrum does it. It&#x27;s a way of reinforcing the power of a particular political camp. There&#x27;s a way to fix that though, make it very difficult to fire people. Then companies will need to be incredibly clear about what conditions they&#x27;re choosing to terminate under. reply gs17 14 hours agorootparent>make every state a right to work state instead of at willIn the US, \"right-to-work state\" likely refers to the opposite of what you mean. It&#x27;s \"right to not join a union and not pay dues\". reply oooyay 14 hours agorootparentI changed the terminology as suggested and was immediately down voted to -4. reply mcguire 14 hours agorootparentprevThe United Kingdom is not a state in the United States. reply tick_tock_tick 14 hours agorootparentI mean technically you&#x27;re right. England, Scotland, Wales and Northern Ireland are each oversea territories of the United States instead of the UK itself being a state. reply comprev 14 hours agorootparentprevThanks to Brexit it&#x27;s also becoming less \"United\" &#x2F;s reply Wildgoose 43 minutes agorootparentNo, that&#x27;s thanks to unbalanced Devolution which grants Parliaments and self-government to everyone except the English who are still (over-)ruled by the Union Parliament in Westminster. reply ClumsyPilot 14 hours agorootparentprevThe problem is hypocrisy - UK government applied pressure to universities and other institutions to stop DE platforming, but itself bans industry experts from conferences when they disagree with government ministers. reply tenebrisalietum 12 hours agorootparentprevThese groups can&#x27;t secretly compel telecom companies to record or give you a copy of all your communications. It&#x27;s not surveillance if it&#x27;s public, it&#x27;s sousveillance. reply lmm 12 hours agorootparent> These groups can&#x27;t secretly compel telecom companies to record or give you a copy of all your communications.In practice they can. The method they use isn&#x27;t the force of law, but the result is the same. reply krisoft 12 hours agorootparent> In practice they can.How would a group of private citizens get a copy of all communications of an other private citizen?Are there any documented cases of this ever happening? reply superb_dev 12 hours agorootparentprevWhich telecom company specifically is releasing people&#x27;s records? reply kypro 13 hours agoparentprevI&#x27;ll be more specific about what I suspect the actual intentions are behind the online safety bill.A few months back the UK charged five retired police officers with hate crimes because they had a private WhatsApp group in which the police found content racist[1] comments about the Duchess of Sussex (Meghan Markle).In the UK it is illegal to say something online that could be considered hateful. But the issue is that in most cases when people are saying hateful things they do so in private, so most of the time offenders like these retired police offers go unpunished.People in the UK are very concerned about hate speech, and unlike these surveillance stories, this is something that UK media obsessively report on.The issue is that although the government can arrest your kids for saying hateful things in public[2][3] they cannot do this when they&#x27;re being hateful in private. If we genuinely believe we need to stop hate speech, then it follows that we also need to do something about the large amount of hate speech which occurs in private.I suspect this is the primary reason why the government wants to know what content you have on your device and what you&#x27;re saying to your friends because it&#x27;s likely some of it is hateful, and if you have said something hateful in private then they want to know.[1] 100,000 people were charged with racist hate crimes last year, and around 1 in every 400 people are charge with some form of hate crime each year. I&#x27;m providing this context because these are extremely unlikely to be highly racist messages on par with what you might hear from say a neo-Nazi. More often than not it&#x27;s simply something negative which could be classed as hateful.[2] Police arrest autistic child for commenting that an officer looked like her lesbian nana, https:&#x2F;&#x2F;www.bbc.co.uk&#x2F;news&#x2F;uk-england-leeds-66462895[3] 17 year old arrest for tweeting Olympic driver, \"You let your dad down i hope you know that\". It was deemed \"malicious communications\" because the divers dad died the year before, https:&#x2F;&#x2F;www.express.co.uk&#x2F;news&#x2F;uk&#x2F;336534&#x2F;Teenager-arrested-o...----Legal note: I do not agree with hate speech in any form. My comment is not intended to downplay the seriousness of hate speech or question our need to enforce hate crimes, but simply to note that a lot of hate speech currently goes unpunished due to E2E encryption and the governments lack of visibility into what we do on our private devices. reply itronitron 12 hours agorootparentWow, I didn&#x27;t realize just how messed up the UK is. Whatever happened to the childhood axiom, sticks and stones can break my bones but words will never hurt me? reply account-5 12 hours agorootparentThat stopped when speech people didn&#x27;t like became \"violence\". Unfortunately a lot of this is imported from America. reply kypro 13 hours agoprev> The scope and depth of this surveillance has led to growing skepticism about the Department’s priorities and resource allocation.Lol. That about sums it up.Whenever a dystopian UK government surveillance thread makes it to the front page of HN I generally try to remind people of two things:1. This will not make headlines in the UK.2. People in the UK do not care about privacy.The fact that the person they spoke to in this article was more concerned about how much the surveillance was costing is exactly the problem. No one will say, \"I have a right to free speech\", or \"I have a right to privacy\", because culturally we don&#x27;t believe in free speech or privacy.Do no feel sorry for us. This is largely what people here want. And I&#x27;m not saying that cynically, people here genuinely believe the government wants to (and should) protect us from our own dangerous opinions. reply Symbiote 11 hours agoparent> 1. This will not make headlines in the UK.https:&#x2F;&#x2F;www.theguardian.com&#x2F;politics&#x2F;2023&#x2F;oct&#x2F;21&#x2F;uk-governme... reply frozenlettuce 12 hours agoparentprevThe thing is, it is much more confortable for government officials to run after low-level citizens than fighting actual crime. If you paint a scary enough picture (\"encryption enables exploitation of children!\"), the public might even be more afraid of people those \"agitators\" than gang wars or robbery. reply itronitron 12 hours agorootparentI used to think that the general public is safer when there is a dangerous criminal element around because the state will focus it&#x27;s policing on the criminal activity and leave most of the public alone. But if the state is just too risk averse to police hardened criminals then the general public is at risk. reply zimpenfish 11 hours agoparentprev> 1. This will not make headlines in the UK.That probably needs some qualification since it was the Guardian which broke the story (and the prequel story two weeks prior) and that&#x27;s two headlines right there.If you check the front page of The Observer for 2023-10-01[1], the prequel (\"Education ministry keeps secret files on critics of schools policy\") is fully a third of the front page. Which is also a headline.[1] https:&#x2F;&#x2F;www.tomorrowspapers.co.uk&#x2F;observer-front-page-2023-1...(Oddly, no-one seems to have The Guardian front page for 2023-09-30 that I can find.) reply adhesive_wombat 11 hours agoparentprevIt will make headlines, in Private Eye. Which means it&#x27;ll be forgotten in days because there&#x27;s no searchable archive of them unless you are or know a hoarder with a spare few feet of shelf space or find and travel to a library with a back archive longer then a few months.Of all the publications with the power to string together a long-term narrative account of local and national government malfeasance, it&#x27;s the one the most needs a historical index and least has one. reply HeckFeck 13 hours agoparentprev\"An Englishman&#x27;s home is his castle\" used to be a well known saying.We once did, but it looks like times have changed for the worse. reply robertlagrant 5 hours agorootparentGrowing up, people used to respond to challenges to what they said with \"it&#x27;s a free country\". I haven&#x27;t heard that phrase in decades. reply bradley13 15 hours agoprevWrongthink must be stamped out!Seriously, what kind of dystopia are UK politicians trying to create?Also, that&#x27;s a lot of tax money that could, I dunno, be used to improve the schools? reply cjbgkagh 14 hours agoparentAFAIK a lot of the depictions of dystopias are based on the UK government as opposed to the other way around. For example Terry Gilliam and George Orwell. The machinations were more overt in those times and a return to these dystopian circumstances is a more of a reversion to the mean than anything new or unique. reply teddyh 13 hours agoparentprevThere’s a reason that 1984, V for Vendetta, Judge Dredd, etc. are all created by people in the UK. reply potatopatch 12 hours agorootparentReading the article, I was actually thinking of Winston&#x27;s girlfriend Julia and how wonderfully well she would do at Ofsted. reply tick_tock_tick 13 hours agoparentprevThey saw V for Vendetta and strive for it. reply Hamuko 13 hours agorootparentDidn&#x27;t that movie end with the explosion of the Palace of Westminster? reply Pixie_Dust 13 hours agorootparent> Didn&#x27;t that movie end with the explosion of the Palace of Westminster?“Who Really Runs Britain?: The Private Companies Taking Control of Benefits, Prisons, Asylum, Deportation, Security, Social Care and the NHS”https:&#x2F;&#x2F;www.amazon.co.uk&#x2F;Who-Really-Runs-Britain-Deportation...\" reply ClumsyPilot 14 hours agoparentprev> Seriously, what kind of dystopia are UK politicians trying to create?One where they constantly talk about conservative values of freedom while creating the most oppressive anti-protest laws and government surveillance in the western world. reply Belopolye 12 hours agorootparentThe argument that I often read is that protecting democracy and democratic values often requires methods contrary to those democratic values (or not, as long as a democracy does it). reply lazzurs 15 hours agoparentprevSimple FOI request to find out how much the program is costing. I doubt it’s cheap. reply switch007 14 hours agorootparentThe Ministry of Truth intervenes in FOI requests:> In 2020, the openDemocracy website published a report on the FOI Clearing House. The report described the Clearing House as \"Orwellian\" and found that it requires government departments to send it requests that are potentially sensitive or too expensive to answer. The report also found that the Clearing House sometimes requires departments to provide it with drafts of responses to FOI requests for vetting. According to the report, government ministers were hindering FOI requests in \"disturbing\" ways and the number of FOI requests granted by departments had decreased. The Cabinet Office said the Clearing House was designed to \"ensur[e] there is a standard approach across government in the way we consider and respond to requests\".https:&#x2F;&#x2F;www.theguardian.com&#x2F;politics&#x2F;2020&#x2F;nov&#x2F;24&#x2F;orwellian-g... reply robertlagrant 5 hours agorootparentA chap I know worked for comms at a government-adjacent state-funded org - he mentioned the same thing there. They just have an internal performance metric of around 80% of FOI requests they should answer, and they use the remaining 20% for awkward or expensive queries. reply HPsquared 14 hours agoparentprevDifferent meanings of \"improve\", I guess. reply cortesoft 16 hours agoprev> In response to these revelations, the Department has chosen to remain largely opaque, stating that it would not be appropriate to comment on individual cases.Ok, then talk about the program as a whole. reply leosanchez 16 hours agoprevWow. UK surveillance is reaching Black Mirror levels. reply mickelsen 10 hours agoparentThe UK has always had that surveillance state thing wrapped in a friendly \"frontend\". Cops can visit you in your hometown because they are concerned about your posts or likes on social media, where such content doesn&#x27;t have to be anything terribly offensive. And everyone ends up processed in their system. Reminds me a bit of Germany, except germans have more checks and balances, and many things like CCTV-everywhere of the UK, just wouldn&#x27;t be legal there.In both countries, low-level bureaucrats have extensive access to information about individuals, as well as broad attributions on what they can do with it, unlike the much maligned US, where these powers are much more separated. reply brnt 16 hours agoparentprevCCTV capital of the world for a decade or two was an indication perhaps. reply IshKebab 12 hours agorootparentAnyone that brings up this factoid instantly gives away the true depth of their knowledge.The US and China have over twice as many CCTV cameras per person than the UK does.https:&#x2F;&#x2F;www.precisesecurity.com&#x2F;articles&#x2F;top-10-countries-by... reply gambiting 11 hours agorootparentAnd vast majority of CCTV cameras in the UK are privately owned and are not part of the state surveilance aparattus. Try having your car stolen in London, despite there being several cameras visible on every corner police will tell you(truthfully) that they don&#x27;t have access to any of them. reply akomtu 3 hours agorootparentI&#x27;m sure if that car had a sticker on it saying where Charles 3 belongs, the police would have suddenly gained access to those cameras and tracked the car with sub-millimeter precision. reply gambiting 3 hours agorootparentI know, it&#x27;s weird like that reply itronitron 12 hours agorootparentprevIt would be interesting to do some sort of analysis based on geography and population density. If someone travels 40 kilometers per day as part of their usual routine then more CCTV cameras will be needed to record their activities. Both the US and China are significantly larger than the UK. reply tokai 11 hours agoparentprevReached that years before Black Mirror was a thing.https:&#x2F;&#x2F;flic.kr&#x2F;p&#x2F;4iRTN8 reply gustavus 15 hours agoprevGood evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone&#x27;s death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat. There are, of course, those who do not want us to speak. I suspect even now, orders are being shouted into telephones, and men with guns will soon be on their way. Why? Because while the truncheon may be used in lieu of conversation, words will always retain their power. Words offer the means to meaning, and for those who will listen, the enunciation of truth. And the truth is, there is something terribly wrong with this country, isn&#x27;t there? Cruelty and injustice, intolerance and oppression. And where once you had the freedom to object, to think and speak as you saw fit, you now have censors and systems of surveillance coercing your conformity and soliciting your submission. How did this happen? Who&#x27;s to blame? Well, certainly, there are those who are more responsible than others, and they will be held accountable. But again, truth be told, if you&#x27;re looking for the guilty, you need only look into a mirror. I know why you did it. I know you were afraid. Who wouldn&#x27;t be? War, terror, disease. They were a myriad of problems which conspired to corrupt your reason and rob you of your common sense. Fear got the best of you, and in your panic, you turned to the now high chancellor, Adam Sutler. He promised you order, he promised you peace, and all he demanded in return was your silent, obedient consent. Last night, I sought to end that silence. Last night, I destroyed the Old Bailey to remind this country of what it has forgotten. More than four hundred years ago, a great citizen wished to embed the fifth of November forever in our memory. His hope was to remind the world that fairness, justice, and freedom are more than words; they are perspectives. So if you&#x27;ve seen nothing, if the crimes of this government remain unknown to you, then I would suggest that you allow the fifth of November to pass unmarked. But if you see what I see, if you feel as I feel, and if you would seek as I seek, then I ask you to stand beside me, one year from tonight, outside the gates of Parliament, and together we shall give them a fifth of November that shall never, ever be forgot. V&#x27;s Speech To England reply teddyh 14 hours agoparentThat’s the stupid speech from the movie.The actual speech, from the comic:⁂Good evening, London. I though it time we had a little talk.Are you sitting comfortably?Then I’ll begin…I suppose you’re wondering why I’ve called you here this evening.Well, you see, I’m not entirely satisfied with your performance lately… I’m afraid your work’s been slipping, and……and, well, I’m afraid we’ve been thinking about letting you go.Oh I know, I know. You’ve been with the company a long time now. Almost… let me see. Almost ten thousand years! My word, doesn’t the time fly?It seems like only yesterday…I remember the day you commenced your employment, swinging down from the trees, fresh-faced and nervous, a bone clasped in your bristling fist… “Where do I start, sir?” you asked, plaintively.I recall my exact words: “There’s a pile of dinosaur eggs over there, youngster,” I said, smiling paternally the while.“Get sucking.”Well, we’ve come a long way since then, haven’t we? And yes, yes, you’re right, in all that time you haven’t missed a day.Well done, thou good and faithful servant.Also, please don’t think I’ve forgotten about your outstanding service record, or about all your of the invaluable contributions that you’ve made to the company…Fire, the wheel, agriculture… It’s an impressive list, old-timer, a jolly impressive list. Don’t get me wrong.But… Well, to be frank, we’ve had our problems, too. There’s no getting away from it.Do you know what I think a lot of it stems from? I’ll tell you…It’s your basic unwillingness to get on within the company. You don’t seem to want to face up to any real responsibility, or to be your own boss.Lord knows, you’ve been given plenty of opportunities…We’ve offered you promotion time and time again, and each time, you’ve turned us down.“I couldn’t handle the work, guv’nor,” you wheedled. “I know my place.”To be frank, you’re not trying, are you?You see, you’ve been standing still for far too long, and it’s starting to show in your work…And, I might add, in your general standard of behaviour.The constant bickering on the factory floor has not escaped my attention……nor the recent bouts of rowdiness in the staff canteen.Then of course there’s…Hmm. Well, I didn’t really want to have to bring this up, but…Well, you see, I’ve been hearing some disturbing rumours about your personal life.No, never you mind who told me. No names, no pack drill…I understand that you are unable to get on with your spouse. I hear that you argue. I am told that you shout. Violence has been mentioned.I am reliably informed that you always hurt the one you love……the one you shouldn’t hurt at all.And what about the children? It’s always the children who suffer, as you’re well aware.Poor little mites. What are they to make of it?What are they to make of your bullying, your despair, your cowardice and all your fondly nurtured bigotries?Really, it’s not good enough, is it?And it’s no good blaming the drop in work standards upon bad management, either……though, to be sure, the management is very bad.In fact, let us not mince words… The management is terrible!We’ve had a string of embezzlers, frauds, liars and lunatics making a string of catastrophic decisions. This is plain fact.But who elected them?It was you! You who appointed these people! You who gave them the power to make your decisions for you!While I’ll admit that anyone can make a mistake once, to go on making the same lethal errors century after century seems to me nothing short of deliberate.You have encouraged these malicious incompetents, who have made your working life a shambles.You have accepted without question their senseless orders.You have allowed them to fill your workspace with dangerous and unproven machines.You could have stopped them.All you had to say was “No.” You have no spine. You have no pride. You are no longer an asset to this company.I will, however, be generous.You will be granted two years to show me some improvement in your work. If at the end of that time you are still unwilling to make a go of it…you’re fired.That will be all. You may return to your labours.Normal service will be resumed as soon as possible. reply varispeed 16 hours agoprevnext [10 more] [flagged] ipaddr 16 hours agoparentYou need to read the article before you comment. They include the source material: https:&#x2F;&#x2F;www.theguardian.com&#x2F;politics&#x2F;2023&#x2F;oct&#x2F;21&#x2F;uk-governme...What evidence are you using to tar and feather the guardian with your false conspiracy theories? reply colpabar 14 hours agorootparentI believe the point is that even suggesting that a western government is surveilling its dissenting citizens would get you labeled a conspiracy theorist nutjob. And with this revelation, we are now supposed to believe that this was the only instance of this happening, it&#x27;s definitely not happening anywhere else, and you&#x27;re still just a dangerous conspiracy theorist if you have trouble believing these institutions that lie over and over and over again about things like this until they get caught and aren&#x27;t held accountable. It&#x27;s tiring.It&#x27;s a low effort comment for sure. But it&#x27;s pretty spot on if you have ever expressed doubt in the mainstream narrative online. reply varispeed 11 hours agorootparentprevI forgot to add &#x2F;s reply swarnie 16 hours agorootparentprevIgnoring using the Guardian as a source for now.....If any of us openly criticised our employer on social media what would we expect? A round of applause? reply worik 15 hours agorootparent> If any of us openly criticised our employer on social media what would we expect? A round of applause?We do not expect our employers to start files on us.We do not expect them to do it when they are desperately short of cash and morale is lowWe expect them to acknowledge there are problems (there are) and show some humility reply lazzurs 14 hours agorootparentLow on cash. There’s a difference between not having the cash and just refusing to spend it on education. reply dylan604 15 hours agorootparentprev>We do not expectI seem to have discovered the problem. Expect the worst, be surprised when it doesn&#x27;t happen. reply southernplaces7 15 hours agorootparentprevYou must be rather dense. Flatly disregard a provided source that counters your claim of \"conspiracy theories\" and then compare something like this to employers responding to employee criticisms. The two things are categorically different. The state spying on and punishing private citizens (even if they&#x27;re government employees) for their criticisms of its policies is far ahead in danger from corporate employee monitoring bullshit. reply swarnie 15 hours agorootparentWhen did i claim \"conspiracy theories\" ?Sorry i stopped reading after that because i think you&#x27;ve responded to the wrong person. replyhunglee2 15 hours agoprevit is critical for national security and public order to monitor the activity of subversive elements. These &#x27;teaching assistants&#x27; may well be spies for foreign governments or unwitting pawns manipulated by those governments. As a democracy, UK government represents the will of the people. The government and the people are one reply johnnyworker 15 hours agoparent> State is the name of the coldest of all cold monsters. Coldly it lies; and this lie slips from its mouth: \"I, the state, am the people.\"-- Friedrich Nietzsche reply jjgreen 14 hours agoparentprevIronically, irony is no longer possible here ... reply hsbauauvhabzb 13 hours agoparentprevSo guilty until proven…. Ahh screw it, just suck up all their data anyway. reply vorpalhex 15 hours agoparentprevI for one think this does not go far enough. Teachers have access to children, and so we should monitor children as well.Whike they may not tweet, we should involve investigators to catalog what words and babyspeech the children say, their tastes in toys, how they arrange their blocks and perhaps even their food preferences.While tracking the food preferences of every toddler across the UK may be involved, we must remember this is for the safety of those children and the country as a whole and there can be no greater use of government employees time. reply ClumsyPilot 14 hours agorootparentIt is really difficult to create parody now, no matter how absurd it is, someone will think this is a good idea and an instruction manual. reply hcrean 14 hours agoprev [–] Animal Farm taught us that the educators of the next generation wield some of the greatest power in society; It is possibly a bit naive not to expect some level of automated surveillance directed towards them.A social media movement sweeping though the education system could potentially be just as destructive to society as an economic cold war or a poor foreign policy. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The UK government's Department for Education has been monitoring and documenting social media activity of educators who voice criticism towards education policies.",
      "These records could have potential impacts on the professional careers of teaching assistants, librarians, among other educators.",
      "The surveillance measures extend beyond just educators, with attempts made to quiet critics of the government's policies. The Department is yet to comment on individual cases."
    ],
    "commentSummary": [
      "The UK government is reportedly monitoring social media accounts of teaching assistants, sparking debates around privacy and freedom of expression concerns.",
      "Critics perceive the surveillance and alleged punitive actions against those critiquing government policies as an overreach.",
      "Discussions in the thread also touch on the nation's stance towards privacy and free speech rights versus its surveillance emphasis, and the necessity of surveillance cameras for national security, reflecting differing opinions."
    ],
    "points": 226,
    "commentCount": 115,
    "retryCount": 0,
    "time": 1698076732
  },
  {
    "id": 37988483,
    "title": "Cleveland launches plan to provide cheap broadband",
    "originLink": "https://www.techdirt.com/2023/10/23/tired-of-being-ripped-off-by-monopolies-cleveland-launches-ambitious-plan-to-provide-citywide-dirt-cheap-broadband/",
    "originBody": "TECHDIRT GREENHOUSE FREE SPEECH ERROR 402 DEALS JOBS SUPPORT TECHDIRT Funniest/Most Insightful Comments Of The Week At Techdirt LAPD Releases Recording Two Cops’ Decision To Pursue Pokémon Rather Than Robbery Suspects Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband Broadband from the do-not-pass-go,-do-not-collect-$200 dept Mon, Oct 23rd 2023 05:29am - Karl Bode Cleveland has spent years being dubbed the “worst connected city in the U.S.” thanks to expensive, patchy, and slow broadband. Why Cleveland broadband sucks so badly isn’t really a mystery: consolidated monopoly/duopoly power has resulted in a broken market where local giants like AT&T and Charter don’t have to compete on price, speeds, availability, customer service, or much of anything else. Data also shows that despite billions in tax breaks, regulatory favors, and subsidies, companies like AT&T have long refused to upgrade low-income and minority Cleveland neighborhoods to fiber. These companies not only engage in this deployment “redlining,” but data also makes it clear they often charge these low income and minority neighborhoods more money for the same or slower broadband. Last week I spent some time talking to Cleveland city leaders and local activists about their plan to do something about it. On one hand, they’ve doled out $20 million in COVID relief broadband funding to local non-profit DigitalC to deliver fixed wireless broadband at speeds of 100 Mbps for as little as $18. On the other hand, they’ve convinced a company named SiFi Networks to build a $500 million open access fiber network at no cost to taxpayers. SiFi Networks will benefit from a tight relationship with the city, while making its money from leasing access to the network to ISPs. We’ve noted (see our Copia report on broadband competition) that such open access networks routinely lower the cost for ISP market entry, boost competition, and generally result in lower prices. Monopolies like AT&T, of course, have long opposed the idea, even if they would technically benefit from lower access costs, because it chips away at their consolidated monopoly power. Local activists like DigitalC CEO Joshua Edmonds tell me they hope the project teaches U.S. towns and cities that there are alternatives to being feckless supplicants to regional telecom mono/duopolies: “This is a major victory, and I hope that people don’t look at it as just a major victory for Cleveland. Every city where there’s a prevalent digital divide, where there’s political will and ability to execute, people should be paying close attention to what happens in Cleveland, paying close attention to how DigitalC was able to fight and navigate with our coalition of stakeholders.” We’ll see what the finished network looks like. And now that Cleveland is challenging monopoly power, it will be interesting to see if local monopolies focus on challenging Cleveland. Big ISPs like AT&T and Charter want to have their cake and eat it too; they don’t want to uniformly upgrade their broadband networks to next-gen speeds, but they genuinely don’t want others to do so either. It’s a lot easier and cheaper to throw a bunch of campaign contributions at corrupt policymakers (remember with the GOP wanted to ban all community broadband networks country-wide during the peak of the pandemic? or how the telecom and GOP worked in concert to pass laws in 20 states effectively banning towns and cities from making these choices for themselves?). Community-owned broadband networks aren’t a magical panacea. Such efforts are like any other business plan, and require competency in design and implementation. But the community-owned and operated networks in more than 1,000 U.S. cities can (and routinely do) prompt a very broken and federal government-coddled status quo to actually try for once, much to its chagrin. Filed Under: broadband, cleveland, community broadband, digital divide, digitalc, high speed internet, municipal broadband, telecom 9 CommentsLeave a Comment If you liked this post, you may also be interested in... Comcast Takes Heat For Misleading '10G' Cable Broadband Branding Astronomers Say Starlink, Amazon Light Pollution Keeps Getting Worse Big Telecom Allied GOP Lawmakers Pretend New FCC Net Neutrality Push Is 'Unlawful' Every Year Like Clockwork The Telecom Industry Lies And Claims Broadband Prices Are Dropping Everything T-Mobile, Sprint Merger Critics Predicted Has Come True Comments on “Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband” Subscribe: RSS Leave a comment Filter comments in by Time Filter comments as Threaded Filter only comments that are Unread 9 Comments Collapse all replies This comment is new since your last visit. Dave says: October 23, 2023 at 8:21 am And just watch as, like clockwork, AT&T and Charter file a lawsuit against the city of Cleveland for billions of dollars in an attempt to maintain their oligopoly in the city. Collapse replies (2) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Bruce C. says: October 23, 2023 at 9:12 am Re: They can try…but “at no cost to the city” means they can’t complain about “boondoggle” spending (at least with any credibility). The main avenues they have to obstruct will be in the permitting process and denying right of way access or pole access for cables. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [3] Anonymous Coward says: October 23, 2023 at 11:25 am Re: Re: They can complain about boondoggle spending all they want. It’s called lying and they are very good at it. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 8:58 am Cleveland has spent years being dubbed the “worst connected city in the U.S.” You’re telling me Cleveland is #1 at something? Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] Anonymous Coward says: October 23, 2023 at 3:28 pm Re: That’s really hard to nail down and define, because Cleveland can’t even win for losing. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 23, 2023 at 9:32 am Broadband opposition This is only tangentially related but I came across this group running ads in the local school board election https://www.accountabilityprojectinstitute.com/about. The goals of the organization is to disparage the Democratic candidates and limit governments who want to establish public internet utilities. This seems like two completely different and specific goals and since the ads are showing up in Ohio I thought I would share it here. I can find any information on the group but I suspect they will be voices agains the Cleveland project. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. ECA (profile) says: October 23, 2023 at 10:01 am depending on whats there The REAL problems are going to Popup as soon as a few things are found out. #1, Any cable lines RUN, Should be shared between the cable/ISP/TV corps. WOULD BE GREAT. But wont happen. #2 HOW far have the current purveyors gotten on Installing FIBER? Odds are, NOT very. At the MOST only the main line to the hubs. LOTS of digging ahead(yes digging) #3 Who here has ever seen the MEAN spirited outcome of a Company REALLY getting pissed off? Random Sabotage? Its NOT that hard when you have Builtin hardware. If they go Wireless, that will mean a Startup price for the customer. Probably $200-500 per location. And Wireless has problems. Always has, always WILL. As well as Promises that cant be reached. Collapse replies (1) Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Threaded [2] ECA (profile) says: October 23, 2023 at 10:02 am Re: The interesting part of this Is that a Solid system, if not broken into pieces, is a job for bill collectors and installers. Reply View in chronology Make this comment the first word Make this comment the last word This comment is new since your last visit. Anonymous Coward says: October 24, 2023 at 12:09 am ComcastCares is $10 a month. Reply View in chronology Make this comment the first word Make this comment the last word Add Your Comment Your email address will not be published. Required fields are marked * Have a Techdirt Account? Sign in now. Want one? Register here Name Email Subscribe to the Techdirt Daily newsletter URL Subject Comment * Comment Options: Use markdown. Use plain text. Make this the First Word or Last Word. No thanks. (get credits or sign in to see balance) what's this? Funniest/Most Insightful Comments Of The Week At Techdirt LAPD Releases Recording Two Cops’ Decision To Pursue Pokémon Rather Than Robbery Suspects Follow Techdirt Essential Reading The Techdirt Greenhouse Read the latest posts: Winding Down Our Latest Greenhouse Panel: The Lessons Learned From SOPA/PIPA From The Revolt Against SOPA To The EU's Upload Filters Did We Miss Our Best Chance At Regulating The Internet? Read All » Trending Posts Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband Math Problem For Linda Yaccarino: If 90% Of The Top Advertisers Have Come Back, But Are Only Spending 10% Of What They Used To, How Screwed Are You? Techdirt Deals BUY NOW Cisco CCNA 200-301 Exam: Complete Course with Practical Labs Techdirt Insider Discord The latest chatter on the Techdirt Insider Discord channel... John Roddy: Did you know that you're not allowed to criticize the EU's actions unless the US is exactly perfect? mildconcern: Yes. This is a more general rule though, applies to a lot of ingroups vs outgroups, of course. Mike Masnick: lol. i've wasted so much of today on this mildconcern: And apparently the peasants out there in web-comment land have noticed our sandbox here. Hello, peasants. In other news I have to do a feature demo today which I was late in delivering. so as a \"sorry\" type bonus I also coded up a separate feature this group of people had been asking for, but wasn't part of this contract as such. and I thought \"I can do a Steve Jobs style 'and one more thing...' for them.\" And I looked down at myself, and realized: I am wearing a black sweater. Sometimes, the stars just align. Mike Masnick: yes, but is it a mock turtleneck? mildconcern: I'm not that cool, alas. I don't have any. But I do have scruff and no hair, so? I'm taller than Steve was though. maybe that makes for more dominance. He was.... not that nice the one time I met him (I was in the same dorm in college as his daughter) candescence: So apparently exTwitter has now purged NSFW content from the \"for you\" feed John Roddy: > The State Action Doctrine Can Apply When Google Looks to the Government to Decide What Information to Censor on YouTube lol > Google Is Not a Publisher, So It Does Not Have a First Amendment Right to Censor Speech Based on Its Viewpoint ell, oh, and furthermore, ell. > It is also worth noting that California courts view the Internet “as a classic public forum” in cases involving the state’s anti-SLAPP statute. Chaker v. Mateo, 209 Cal. Kennedy is even dumber than Fyk. imo, courts need to start seriously considering imposing sanctions on any lawyer who tries the \"cannot have it both ways!!!!\" argument in response to 230. Mike Masnick: the fyk case has been hilarious to watch. the belief that he's playing 4th dimensional chess or whatever. his \"we cannot lose, because either way we win\" argument is... um... quite something John Roddy: I view it from the perspective of six-dimensional quantum phase space. And frankly, he needs more dimensions. Well, I'm sure his lawyers are making absolute bank from it. candescence: Of course Newsom signed AB 1394 into law. The guy's been rather selectively signing and vetoing bills because he obviously wants to look good for a future presidential run. tomacamot: Courts need to start more seriously imposing sanctions in general, too many bad faith plaintiffs and lawyers who enable them. John Roddy: Also, as the record has shown, Mike Masnick is vehemently against *any* kind of regulations on anything ever. Apparently. I don't remember him saying that, but apparently that's what criticizing the EU's approach to things implies. Mike Masnick: I need to learn to stop engaging with idiots though, as i've said many times, to me it's kinda like batting practice. when i do engage with policymakers or people who are actually important, i've already heard every possible argument they can make, and have my response clear and ready. John Roddy: My favorite is the comparison to climate change when arguing in support of government regulation Mike Masnick: Uh, yup John Roddy: Because that has definitely worked out well All right, so what happens more often: Military secrets leaked on War Thunder forums, or Arma 3 gameplay footage gets passed off as credible footage of [current conflict here]? I've lost count of both. mildconcern: If I had a nickel for every time someone asserted companies have no choice but to defend copyright or patents or risk losing them ... Mike Masnick: we'd be worth more than the entire copyright/patent system. John Roddy: Need more people like Vino from All of Garden, imo. mildconcern: I think the idea that it's more or less compelled for trademarks appeals to the sort-of-knowledgeable as a way to sound Wise and Informed about the world when someone else is talking about a moral failure or something. It's very NYT reader. But jesus christ people, read a friggin book about it or something. It's not hard. tomacamot: If somebody's just giving you nickels each time I can repeat it over and over for a 50% cut of the income Mike Masnick: So @John Roddy someone took our exchange here, which was about the people yelling at me on Bluesky... and falsely claimed I was complaining about a perfectly nice interaction I had on Mastodon, so that's fun. John Roddy: ...I am not even on mastodon. Mike Masnick: This person was pretty sure it was about a discussion on mastodon. John Roddy: Hey person on mastodon! This wasn't about you. Our conversation about your *extreme* flatulence was held privately. I actually sympathize. It must be irritating to be unable to use public transport without making all the other passengers desperately bail out the windows. But please, *please,* do not attempt to fly. Mike Masnick: Sorry, just booked five more flights before the end of the year. Watch out. Samuel Abram: Using public transportation is much more preferable (to me) than owning and maintaining a car, at least in a city like NYC. I mean, I'm 41 and I don't even have a driver's license. pyrex: I'm subtooting somebody _RIGHT NOW_. Samuel Abram: @Mike Masnick, don’t you have an announcement to make to everyone in the chat? Mike Masnick: ? Samuel Abram: I mean, aren’t you the _tycoon_ of TechDirt? Mike Masnick: hahah. the post is at the top of the site, I figure people can see it there... Samuel Abram: Ah. It’s just that some people access this chat through discord Anyway, will there be a subsequent podcast about _Trust & Safety Tycoon_? Mike Masnick: yes, there will be a podcast about trust & safety tycoon. possibly even two podcasts. we'll see. but, anyway, for those in discord and not checking out techdirt: [article] John Roddy: When's the ray tracing update going to land? I paid an embarrassing amount of money for this overpowered water cooled computer, and I expect to be maxing it out. TIL. One of the nutjobs I'm following tried sending Google an arbitration notice that held if they don't respond within 24 hours, he owns all of Google's IP forever and they need to pay him $500 billion. The court did not find it convincing. [link] Well I'll be. So uhh, the last comment on there... Mike Masnick: John Roddy: I've brought this guy up a few times recently. He's the one who just got formally declared a vexatious litigant in that court. candescence: [article] Labor already confimed they plan to implement truth in political advertising laws in Australia some time ago, but the demand for it only got louder after the failed voice referendum, which was flooded with fearmongering and misinformation Sure, the Yes campaign didn't do a good job, but the No campaign's bad-faith campaigning was just _disgusting_ The government have acknowledged that there needs to be a balance between freedom of speech and the need to crack down on blatant misinformation, at least. mildconcern: Even still, that requires the government to judge what is true and what is not. That type of decision is at best fraught. BentFranklin: Related [article] Samuel Abram: BTW, remember how someone on twitter (before the amuskalypse) quoted The Princess Bride and got flagged for a death threat? I did the same thing for quoting the Simpsons on instagram It was in former Simpsons showrunner Bill Oakley's post on how there's an actual Moe's Tavern in Austin, TX Somebody mentioned that there wasn't \"Chowder\" on the menu and I said > It's pronounced \"Chowdah!\" I'LL KILL YOU! I'LL KILL YOU ALL!! Anyone with any deep Simpsons knowledge would've recognized that quote from the episode \"The boy who saw too much\" but obviously, I got flagged for a death threat Oh well, I take responsibility for it Cathy Gellis: I wonder if adding #SimpsonsQuote would have forestalled the flag? Samuel Abram: or even an emoji? In any event, I can still use instagram mildconcern: A friend of mine posted about finding a love note from a teacher to a high school student while using their classroom for a competition. asking how to turn it in. I gave suggestions and then said \"and then consider washing your eyes with bleach or something I guess.\" Twitter flagged me for encouraging self harm or suicide. .... In retrospect it was hardly shocking that the subtleties were lost on the bots, but it brought home how much the \"appeal\" is just another bot. John Roddy: I'm pretty sure the reason my discord got flagged for \"piracy\" is because I do openly mock some people who engage in it. Samuel Abram: It'll be kinda hard to pirate my works though, as I license them with a creative commons license The only works I make which are all rights reserved are works I don't actually own, such as covers and remixes (excluding those in the public domain, of course) (and covers and remixes where I comply with other peoples' creative commons licenses) Become an Insider! Recent Stories Monday 19:45 The Utah Cookie Wars Are Over: Crumbl Settles Trademark Suit With Dirty Dough (2) 15:37 Clearview Gets $10 Million UK Fine Reversed, Now Owes Slightly Less To Governments Around The World (8) 13:34 Peering Through The Fog Of War With Open Source Intelligence (6) 12:02 Supreme Court Asked (Again!) To Rule That Recording Cops Is Protected By The 1st Amendment (9) 10:53 Google Decides To Pull Up The Ladder On The Open Internet, Pushes For Unconstitutional Regulatory Proposals (33) 10:48 Daily Deal: The Lean Six Sigma Career Advancement Bundle (0) 09:37 LAPD Releases Recording Two Cops' Decision To Pursue Pokémon Rather Than Robbery Suspects (11) 05:29 Tired Of Being Ripped Off By Monopolies, Cleveland Launches Ambitious Plan To Provide Citywide Dirt Cheap Broadband (9) Sunday 13:10 Funniest/Most Insightful Comments Of The Week At Techdirt (32) Saturday 12:00 This Week In Techdirt History: October 15th - 21st (0) More Tools & Services Twitter Facebook RSS Podcast Research & Reports Company About Us Advertising Policies Privacy Contact Help & Feedback Media Kit Sponsor / Advertise More Copia Institute Insider Shop Support Techdirt Brought to you by Floor64 Proudly powered by WordPress. Hosted by Pressable. This site, like most other sites on the web, uses cookies. For more information, see our privacy policy",
    "commentLink": "https://news.ycombinator.com/item?id=37988483",
    "commentBody": "Cleveland launches plan to provide cheap broadbandHacker NewspastloginCleveland launches plan to provide cheap broadband (techdirt.com) 222 points by rntn 16 hours ago| hidepastfavorite79 comments sxg 14 hours agoI just moved back to Cleveland, and I signed up for Cleveland Broadband (clevelandbroadband.com), which is incredible! I pay $50&#x2F;mo for 1 Gb&#x2F;s download and upload speeds with no contract or temporary introductory pricing. The best part is the customer service, which I&#x27;ve only had to use twice while initially setting it up, but it&#x27;s a direct line to a person who physically came to my place within an hour and was super knowledgeable! We had a lengthy discussion about Ubiquiti networking gear.I previously had Comcast&#x2F;Xfinity, which was reliable, but felt absolutely scammy due to constantly changing pricing with multi-year contracts. Talking to a human for basic tasks like upgrading or canceling service was nearly impossible. Apparently their chatbot is capable of these tasks, but I could never get it to work. reply 1-more 13 hours agoparentI had municipal broadband in a town I lived in and it was the same experience: you get the feeling that everyone involved really cared about it because it&#x27;s our town, not just an account number somewhere. reply sarchertech 10 hours agoparentprevMunicipal fiber in Chattanooga is the same way and it’s nearly 15 years old at this point.Customer service and speed hasn’t declined and prices haven’t gone up (they haven’t even kept pace with inflation) like the naysayers predicted. reply tshaddox 13 hours agoparentprevFor what it&#x27;s worth, I have Frontier in Los Angeles County and I have the same positive experience, other than that my gigabit connection is $70&#x2F;month (it&#x27;s possible that&#x27;s reasonable given overall cost of living differences). reply p1mrx 12 hours agoparentprevDo they provide an IPv4 address or CGNAT? An IPv6 prefix or sadface? reply waldothedog 6 hours agoparentprevDamn, got my hopes up but this is for large apartment buildings only :&#x2F;Enjoy your gig, I’ll be here waiting for spectrum to arbitrarily raise my rates againWelcome back btw! reply beeburrt 10 hours agoparentprevI&#x27;m considering moving there. How are you liking it? How is the tech jobs market there? reply vineyardmike 10 hours agorootparentNot OP, but Cleveland is kinda great kinda terrible. I spent a few years there in my early adulthood.It was once one of the nicest richest cities in America, and it has some of the best cultural institutions in the country as a result. It has every major sports franchise. It has some great architecture. It’s extremely affordable. The food is much better than comparable midwestern cities.There’s a reason it’s so affordable. Jobs are not plentiful. The weather is terrible. Infrastructure is lackluster. It’s somehow a city of townies, not somewhere like SFBA&#x2F;NYC that’s full of people that have big goals and ambitions and worldly experiences. Good and bad.It does really seem like a city on the rise. At least when I was there last. They’re really investing in themselves, but the population has a really gloomy self image that honestly got me down. reply tuckerconnelly 8 hours agorootparentI just visited a few days for a surgery and this seems pretty accurate.The food weirdly was the same at every restaurant, regardless of the cuisine: super oiled up. Usually mayonnaise and something pickled on top. Like preparing me to go to a factory for 14 hours.Nearly every Uber had a sports station on.Everyone seemed pretty gloomy there. \"What&#x27;s a must-do before we leave?\" \"Umm...yeah it&#x27;s too cold for a Brown&#x27;s game, so not much. Yeah.\"A strange obsession with Taylor Swift \"bringing money into the city\" because of the sports guy she&#x27;s dating now from Cleveland. reply justin66 5 hours agorootparentA Clevelander told you it was too cold for a Browns game? In October? reply nickpeterson 9 hours agorootparentprevI currently live in Toledo and it’s amazing. They feed me well and there are no beatings. reply stevehawk 8 hours agorootparentprev> The food is much better than comparable midwestern cities.whew that&#x27;s a low bar :-P reply bratsche 8 hours agorootparentprevIf you&#x27;re into music, they also have one of the best orchestras in the country. reply OnACoffeeBreak 12 hours agoprevI wish ARSTechnica would pick up this story and do a deep dive. They have done an amazing job keeping up with all of the shenanigans that incumbent telcos pulled in the case of the town&#x2F;city of Wilson in North Carolina back in the day rolling out their Greenlight fiber muni broadband network:- https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2010&#x2F;11&#x2F;the-price-of-mun...- https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2011&#x2F;03&#x2F;cable-backed-ant...- https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2015&#x2F;02&#x2F;fcc-o...- https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2016&#x2F;09&#x2F;muni-...- https:&#x2F;&#x2F;arstechnica.com&#x2F;information-technology&#x2F;2016&#x2F;10&#x2F;city-... reply llsf 15 hours agoprevWould it make sense for the municipality to own the pipes that run in the city ? Like some cities own the sewer pipes. Could it be an infrastructure that the city builds, owns, maintains and rents to ISP ? The city would have a full control on how many houses are connected. That is the type of investments that a city is suited for (i.e. large upfront cost financed by bonds). AT&T, Charter, Comcast, they have no incentive to invest a lot upfront. And they might duplicate the infrastructure. At the end the customer pays for the piecemeal fiber deployment, and redundancy. reply ExoticPearTree 13 hours agoparentIn my part of the globe the city is in the process of finishing installing fiber ducts to all addresses in the city (currently around 3.5M people) and ISPs run microfiber to any residential area, event apartment buildings. The effect is that you can get service from whatever provider you want without the hassle of \"we don&#x27;t have the infrastructure to do it\". ISPs rent the fibers on a per distance price, but it is pretty much negligible.When I say installing fiber ducts, I mean trenches with ducts that have exits on every address. And the microfibers are blown through those and you have a fiber optic cable to your door. reply thomastjeffery 14 hours agoparentprevThat&#x27;s what they do here in Utah: UTOPIA (the municipality) runs its own fiber lines, and leases its network to private ISPs. That way, there is a single physical network with competitive pricing.Of course, that doesn&#x27;t stop Comcast, Centurylink, Google Fiber, etc. from running their own networks, and UTOPIA&#x27;s coverage generally doesn&#x27;t overlap where these other ISPs already have infrastructure. reply p1mrx 12 hours agoparentprevIdeally the municipality should provide a \"dumb pipe\" to a point of presence, where the customer chooses an ISP. That way the municipality doesn&#x27;t have to deal with IPv4&#x2F;IPv6 addressing, or DMCA notices. reply WarOnPrivacy 9 hours agorootparentThat&#x27;s what OpenInfra does. They lay the fiber infrastructure and a bunch of ISPs are available to buy service from. They&#x27;re still trenching around here. Our ONT is installed by the fiber won&#x27;t be lit until New Years. reply p1mrx 7 hours agorootparenthttps:&#x2F;&#x2F;us.openinfra.com&#x2F; seems available in various parts of Texas. I wonder if they&#x27;ll expand to other states?Edit: it looks like there are other \"open access fiber\" deployments, e.g. Utopia, SiFi, and Gigapower. reply gooseyman 9 hours agoparentprevAnd Cleveland already has Cleveland Public Power!Cleveland Public Power is the City of Cleveland&#x27;s municipally-owned electric company and is a Division of the Department of Public Utilities. The Department provides water, sewer, and electricity to the residents and businesses in the City of Cleveland.Edit - link https:&#x2F;&#x2F;www.cpp.org&#x2F;index.php&#x2F;About reply oooyay 13 hours agoparentprevBeing NAASCO certified and having seen a lot of sewer pipe that&#x27;s owned by a city, that&#x27;s probably a terrible idea. Cities are also partially responsible for the bribing scheme required to open a Telco in a town.There are already backbone providers, having communities band together as last mile providers would likely be far more optimal. It may seem like a minor distinction, but to me theres a big gap between \"co-op\" and \"city owned\". reply jpk 14 hours agoparentprevPart of me likes this approach, but another part of me is hesitant putting the local government in control of all of the network infrastructure. It could conceivably allow local officials to turn it all off during a protest or something; similar to what we saw during the Arab Spring events. reply patmorgan23 8 hours agorootparentI mean where the ISP that was shutdown during the Arab spring state owned?Also having one municipal network doesn&#x27;t prevent others from building their own infrastructure. reply xenospn 13 hours agorootparentprevThey can already do that with ease by instructing the companies that own it to shut it down. I’d argue that having local officials in charge offers more transparency than a nameless corporation. reply jpk 3 hours agorootparentSure, but the company has an incentive to resist such an order. So there&#x27;s a check there. I guess all I&#x27;m saying is there should be a check, and transparency about when that check is tested. reply gooseyman 9 hours agorootparentprevCleveland has a public owned utility for power that does publish an annual.https:&#x2F;&#x2F;www.cpp.org&#x2F;About&#x2F;Annual-ReportsThe non-Cleveland owned utility data is also available, it’s just not as “Cleveland specific” reply AnotherGoodName 6 hours agoparentprevAs a general rule of thumb utilities is a mode of market failure for capitalism. No one&#x27;s going to run multiple power&#x2F;water&#x2F;communication&#x2F;sewer lines to your house and compete. At the very least they&#x27;ll want to share poles&#x2F;pipes.Anyway the solution is easy and exactly as you suggested. No idea why people find this hard to comprehend. reply eviks 3 hours agorootparentFor the broadband topic at hand there are places where exactly this \"no one&#x27;s going to run multiple ... lines\" happens and results in lower prices due to the market failure of capitalism reply pottertheotter 12 hours agoparentprevIt&#x27;s what happens in a lot of places with open access networks. And it&#x27;s what we do with a lot of infrastructure, such a streets. reply jrgifford 15 hours agoprevIt&#x27;ll be interesting to see if they can do this better than previous attempts. I remember in 2009 when OneCommunity tried[1], 2014 when OneCommunity launched everstream, their for-profit arm (and didn&#x27;t change much)[2], or the 2018 Old Brooklyn&#x2F;Ward 13 project[3].Somewhere in there, there was an initiative (probably 2009 or so?) that included public wifi in Cleveland Heights along much of Cedar Road, where One Community had a wifi SSID \"OneCommunityPublic\" (or something similar). That got shut down quickly.[1] https:&#x2F;&#x2F;www.cleveland.com&#x2F;business&#x2F;2009&#x2F;07&#x2F;onecommunity_seek...[2] https:&#x2F;&#x2F;everstream.net&#x2F;press-releases&#x2F;onecommunity-launches-...[3] https:&#x2F;&#x2F;connectyourcommunity.org&#x2F;cdjc-program-four-points&#x2F;fr... reply CSMastermind 13 hours agoparentMy buddy was at Case Western back in 2007&#x2F;8ish and worked on that One Community project. He called it &#x27;porn for the poor&#x27;.There were all these utopian ideas getting floated about how revolutionary the idea was and that basically lack of high speed internet access was the only thing keeping all these people in poverty.If we just gave the poor fast internet access as a public service then they would all learn to code, get remote jobs, and raise themselves out of poverty.Months into the experiment they discovered that no one used the free job training features that came with the internet access and instead they were just using it for porn and piracy. reply sangnoir 12 hours agorootparentMaybe puritans would have objected to the poor using the internet to get their rocks off in 2007. However, in 2023 - I cannot imagine anyone applying for a job without using the internet in some fashion. Could one discover job openings in a newspaper and mail their resume by post and wait for a phone call? Perhaps, but even McJobs have QR codes now.I have no doubt that anyone in the US who doesn&#x27;t have internet access is severely disadvantaged on the job market (or even accessing Khan academy). Yes, they may use most of the bandwidth for entertainment,but gatekeeping what poor people should do with their resources seems a tad paternalistic, this includes policing what should be in the shopping baskets of SNAP beneficiaries. reply _jal 10 hours agorootparentprev> There were all these utopian ideas getting floatedFunny how the sales pitch and reality collide, eh?The sad part is that stupid sales pitches like that are required to get movement. Internet access is 21st century dial tone, the vast majority of people need it to function in normal society. Universal Service was the sort of socialism a fast-growing capitalist society needed; internet service is the same now.People seem to think of it as a luxury. They&#x27;re wrong: it is a control mechanism that comes with access to videos of naked people. To the extent you want the machinery of society to keep working, you should want everyone attached, including those smut-loving poor people you seem to want to judge. reply BreadPants 15 hours agoparentprevI remember that and did contact Everstream for internet service. It was 1000&#x2F;1000, but they wanted $500 for running the lines from across the street and then $500 per month after that. Insane. reply zdragnar 15 hours agorootparent$500 for running the lines under a street isn&#x27;t too far out of the ordinary (I paid $300 for a longer run, but there was nothing to go under, so the job was easy).That said, $500&#x2F;month for service is insane. reply gottorf 9 hours agorootparentThat sounds like pricing for a \"business-class\" Dedicated Internet Access service, with meaningful SLAs and no oversubscription. reply markofzen 15 hours agoparentprevThere&#x27;s actually an existing initiative that provides cheap wireless across parts of lower income areas run by PCs for people and pretty large nonprofit. So there&#x27;s definitely hope with expansion from wireless to fiber I think. reply atdrummond 11 hours agoprevReally frustrating that this article focuses so much on the partisan attacks in the back half.When I lead the (successful) effort to build a city wide FTTH network in Quincy, IL, our most fervent supporters were all Republicans. We got far more support from the IL GOP than the IL Democratic Party. (The former helped us, at the federal level, secure additional funding for the local telco coop that runs Adams County’s fiber lines.) Despite this, I wouldn’t promote our success as the story of one party beating another and it really diminishes the hard work of people from both sides of the political divide. reply thelastgallon 16 hours agoprev> despite billions in tax breaks, regulatory favors, and subsidies, companies like AT&T have long refused to upgrade low-income and minority Cleveland neighborhoods to fiber.There is a very easy solution to this. Electric utilities should be required to lay fiber along with electric. They can choose to offer internet (better) or offer fiber with a choice of carriers.EPB in Chattanooga has been providing fiber to homes for decades. reply nerdponx 16 hours agoparentImagine that: company gets free money from the government to do such-and-such thing but isn&#x27;t strictly required to do it, then they take the free money and don&#x27;t do the thing. It&#x27;s almost like corporations are self-interested and un-altruistic. reply parineum 15 hours agorootparentI don&#x27;t know why you&#x27;d be railing against the company here for acting in it&#x27;s best interest (exactly as you&#x27;d expect) rather than the state for giving away money with no strings attached.A private business sure as hell wouldn&#x27;t be so foolish as to sign such a contract. reply bigstrat2003 13 hours agorootparentOne can blame both parties. It was foolish (or corrupt, take your pick I guess) for the government to give out money without formal strings attached. It is unethical for the companies to take that money knowing it&#x27;s intended for $thing, without ever intending to do $thing. Neither is good. reply parineum 12 hours agorootparentThis is a classic example of the scorpion and the frog though.The government is ostensibly giving them money and saying, \"We hope you choose to do the thing we want with this money but you don&#x27;t have to, no pressure.\"Exactly what you&#x27;d expect happened, they took the money and did nothing. I honestly have a hard time finding that nearly as unethical as the government being incredibly irresponsible with our money, either through naivety or corruption. reply bigstrat2003 5 hours agorootparentI don&#x27;t understand how you can think the government is the more unethical party here. Should they do better? Yes. But in the scorpion and the frog story, the scorpion is the bad guy. You don&#x27;t get to go \"sorry it&#x27;s just how I am bro\" after you take advantage of someone. reply JumpCrisscross 4 hours agorootparent> don&#x27;t understand how you can think the government is the more unethical party hereThey aren’t saying that. They’re saying the ethics are functionally irrelevant. It’s not dastardly enough to provoke a standard. It’s just monumentally stupid on the government’s part. reply dd36 15 hours agorootparentprevIt is in a company’s best interest to make sure corruption is legal? reply vineyardmike 10 hours agorootparentprevThere’s a real physical human being making that decision. Corporations aren’t amorphous blobs. What a scum, to abuse the society they live in.Corporations exist to make a profit and that’s fine, but they don’t need to claw and steal every penny they can find. Why do we perpetuate this idea that the appropriate behaviors for an organization are these horribly antisocial actions. reply dvdkon 14 hours agorootparentprevI think you misread the parent comment, I&#x27;d say they are blaming the government for not covering their \"investments\" legally, same as you. reply Fauntleroy 10 hours agorootparentprevIt&#x27;s not mandatory to lick the corporate boots stepping on us, you know. reply bombcar 16 hours agoparentprevIt&#x27;s the obvious solution, so of course it won&#x27;t be done.I now have four separate companies&#x27; fiber running through my property, of which I am connected to only one, but I could switch to two others anytime I wanted to, and then they&#x27;d run the \"last connection\" to my house. It&#x27;s kinda silly.(The fourth is a business line, which I could connect to but that involves more work as it is older.) reply Spivak 16 hours agorootparentI&#x27;m not saying it&#x27;s right but I&#x27;m predicting the argument against will be that it will increase the cost of running electric which you think would be \"who cares\" but homeowners end up footing that bill and are more let&#x27;s say more price-sensitive than governments.It&#x27;s crazy we still haven&#x27;t won the fight of \"if you build a house the literally state controlled electric company has to hook you up\" but here we are. reply tw04 15 hours agorootparentElectric companies already run fiber with every new power line in most places. They simply use it as dark fiber for internal purposes. The cost to string a couple more strands for public use would be a rounding error for them. reply zrail 16 hours agoparentprevIf the municipality owns the poles and the power company this is comparatively easier. In places that own both, like Traverse City in Michigan, Chattanooga TN, or Longmont CO, this model can be incredibly effective. The problem, at least in my part of the world (Michigan) is that most municipalities do not own the poles or the power company. The power company is instead a large publicly traded corporation, albeit with strong regulation.Adding regulation to force power companies to run dark fiber on new runs only addresses part of the problem. You still have to deal with the millions of miles&#x2F;kms of installed grid that sees proactive maintenance _maybe_ once a decade.Not to mention the state laws in dozens of states that place onerous rules on municipalities installing their own broadband service, or even outright forbid the practice entirely. These laws are often the result of ILECs lobbying state governments or using their lobbying groups to directly write \"model legislation\" that state governments subsequently adopt. reply mfer 16 hours agorootparentIn Michigan only telecommunications companies, power companies, cable companies, and municipalities can be on the poles. So, an Internet only company is excluded.Michigan also has one of the most unique laws here. A municipality needs to put out an RFP to build the broadband network. If it gets three or more qualified bids it cannot proceed. reply jshier 15 hours agorootparentSorry, but if it gets more bids it can&#x27;t proceed? What? reply zrail 15 hours agorootparentYep. It&#x27;s messed up. reply ForkMeOnTinder 15 hours agorootparentI&#x27;d love to hear the rationalization for this one reply rootusrootus 14 hours agorootparentThe wording could be more clear. Written another way:\"a public entity may provide telecommunication services within its boundaries after issuing a request for competitive sealed bids to provide telecommunication services and receiving less than 3 qualified bids from private providers.\"If you get enough bids, the assumption is that the price is competitive and therefore it&#x27;s cheaper to use a private company and not have the gov&#x27;t itself do the infrastructure work. reply sokoloff 14 hours agorootparentprevHow is internet not a subset of telecommunications? reply arrosenberg 16 hours agorootparentprevRarely does a situation so desperately cry out for the use of eminent domain. reply beauzero 14 hours agorootparentprevAdd Carroll County, GA to this list. Carroll EMC which covers three counties on the border of Georgia and Alabama overlapping I-20 (all three counties Carroll, Haralson, and Heard) are getting \"on pole\" fiber provided by the electric company. reply chasd00 16 hours agorootparentprevisn&#x27;t \"pole ownership\" and access to those poles what doomed google fiber? In some cases it&#x27;s easy to run fiber yourself in other cases it&#x27;s completely impossible. reply mfer 16 hours agorootparentI would suspect access more than ownership. Lots of places legally limit access and Internet companies are excluded. reply gs17 15 hours agorootparentprevIn some places they seem to be working around it. Here in Nashville they cut into every street&#x2F;alley to run fiber (it isn&#x27;t available at my apartment, but they did run it down our street, which is not a main street at all). reply ourmandave 16 hours agoparentprevGiven the way things go, there&#x27;ll be a line item charge on every bill:Connection to AT&T backbone surcharge..............................$39.99 reply selimthegrim 10 hours agoparentprevCPP is city owned, doesn’t sound like anyone is stopping them. reply ralph84 15 hours agoprevToo little too late. Comcast is running ads trying to scare people into not dropping their home internet service. That’s a pretty clear sign that a lot of people are doing just that and relying solely on mobile. reply gs17 15 hours agoparentI doubt it&#x27;s so much \"no one wants home internet anymore\" but more \"Comcast is so expensive and annoying that mobile is nicer\". reply jrochkind1 8 hours agoprevI&#x27;d love it if Baltimore City could get it together. 90% of Baltimore has only one wired broadband provider, Cocmast -- who charges like 50% more for the same service than in markets with competition.(Some tiny portion of Baltimore has verizon fiber available. Some growing portion has the new T-mobile 5G wireless home internet; apparently not enough to get Comcast to reduce prices to what they charge in markets with competition) reply taylorbuley 13 hours agoprevFor anyone who wishes this post was, in fact, about a plan by data guru William Cleveland, I&#x27;m with you. reply amiga386 11 hours agoparentIt&#x27;s a post about Moses Cleveland, he&#x27;s the guy who invented Cleveland YEAH! https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ysmLA5TqbIY reply spandextwins 16 hours agoprevWe need that! The Internet should actually be free given the value they all get from me. reply qup 16 hours agoprev\"Cheap\" to be determined reply gs17 15 hours agoparentIt&#x27;s very likely to be cheaper and better than Comcast at least. reply qup 13 hours agorootparentIf they&#x27;re not aiming to clear that bar, I think we should bin it.I was actually really interested to hear what kinds of numbers they can pull off. I hate Comcast, and I hate my local provider even worse. reply rtkwe 14 hours agoparentprevIt&#x27;s been much cheaper than the local mono&#x2F;duopoly providers in all the other cities it&#x27;s been done in so far your skepticism is unearned. reply qup 13 hours agorootparentI&#x27;m not skeptical. I should have said \"How cheap*...\"Given that it&#x27;s the whole goal of the project, you&#x27;d think they might have come up with a number. reply doublerabbit 12 hours agoprev [–] Cool, goodluck. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cleveland is investing $20 million in COVID relief funding for affordable broadband and has partnered with SiFi Networks to establish a $500 million fiber network free of charge to taxpayers.",
      "These initiatives aim to challenge the dominion of large ISPs, such as AT&T and Charter, who have frequently overlooked low-income and minority areas.",
      "While community-owned broadband networks could potentially lower costs and increase competition, possible hurdles include lawsuits from existing providers."
    ],
    "commentSummary": [
      "Cleveland has initiated a new affordable, high-speed broadband service, contributing to the broader conversation about municipal broadband initiatives and government control of network connections.",
      "This initiative has sparked a debate around the advantages and disadvantages of government network control, where some see it as a means to enhance service and transparency, while others express concerns about potential power misuse.",
      "This discussion underscores the necessity for increased competition in the broadband market and the government's role in securing affordable broadband access, as evidenced by frustrations in Baltimore with Comcast's high prices and lack of competition."
    ],
    "points": 222,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1698080723
  },
  {
    "id": 37991295,
    "title": "How does macOS manage virtual cores on Apple Silicon?",
    "originLink": "https://eclecticlight.co/2023/10/23/how-does-macos-manage-virtual-cores-on-apple-silicon/",
    "originBody": "THE ECLECTIC LIGHT COMPANY MACS, PAINTING, AND MORE Downloads M1 & M2 Macs Mac Problems Mac articles Art Macs Painting hoakley October 23, 2023 Macs, Technology How does macOS manage virtual cores on Apple silicon? One of the most distinctive features of Apple silicon chips is that they have two types of CPU core, E (Efficiency) cores that are energy efficient but slower than the P (Performance) cores, which normally run much of the code in the apps we use. Apps don’t decide directly which cores they will be run on, that’s a privilege of macOS, but they register their interest by setting a Quality of Service, or QoS, which is then taken into account when they’re scheduled to run. With the introduction of Game Mode in Sonoma, CPU scheduling can now work differently, with E cores being reserved for the use of games. This article looks at another atypical situation, when running a macOS virtual machine (VM) assigned a set number of virtual cores. How does macOS Sonoma handle that? CPU cores M-series chips contain different types and numbers of CPU cores, depending on the model: Base models contain 4 E and 4 P cores; for the M1, those are Icestorm and Firestorm respectively, while the M2 has Blizzard and Avalanche. These are configured in two clusters, one containing the E cores, the other the P cores. Within each cluster, all cores are run at the same frequency, and they share L2 cache. Pro and Max models contain 2-4 E and 6-8 P cores, in one E cluster and two P clusters, again running at a common frequency within the cluster, and sharing L2 cache. Ultra models contain 4 (M1) or 8 (M2) E and 16 P cores, their clusters having common frequencies and L2 caches. In broad terms, allocation of executable threads to different cores depends on: The QoS assigned to each thread. Those given low values for background and maintenance tasks, including Time Machine backups and Spotlight indexing, are run on E cores, and have no external control to allow their rescheduling to P cores. Those with higher QoS can be run on either P or E cores, and external controls can restrict them to E cores alone, although they’ll normally be run on P cores when they’re available. Clustering. Because all cores in a cluster run at the same frequency, it’s more efficient to recruit additional cores in the same cluster, as they’ll already be running at a higher frequency, rather than a core in a different cluster, whose frequency may then need to be increased. Clusters are normally recruited in sequence too: in Macs with two P clusters, threads are normally run on the first of those (P0), and only when additional cores are required is the second (P1) recruited. Running with a light load, P0 is therefore likely to be more active than other P clusters, which may spend long periods idling. Order within a cluster. Although applied more loosely than other principles, there is an observed tendency to recruit cores in order within a cluster. Where the P0 cluster contains cores P2, P3, P4 and P5, threads tend to be loaded onto P2 first, and P5 last. However, running threads are often relocated within a cluster, following which P2 may be left idle, while P5 bears the brunt. Thread scheduling and dispatch contains many more subtleties, but those influences normally dominate what you see in practice. Virtual CPU cores Under macOS lightweight virtualisation, virtual machines (VMs) are allocated a number of virtual CPU cores, all of which are the same type, equivalent to a P core. There is thus no option to allocate threads running in the VM to E cores on the host. This is illustrated in the following examples shown in Activity Monitor’s CPU History window. Two different loads were applied to the M1 Max shown here: the two long peaks seen on the E cores were floating-point threads at a QoS of 9 for a background task, while the shorter peaks on four P cores were the same threads at a QoS of 33 for priority user tasks. When the same sequence was run on a VM with 4 virtual CPU cores, the QoS made no difference to the performance or core allocation seen in the VM. On the host, both thread loads were run similarly on the first cluster of P cores. This might suggest that the host simply hands over the cluster of P cores to be scheduled and dispatched by the VM. If you rely on what you’re shown in Activity Monitor, you could be tempted to reach that conclusion. Methods To assess core allocation for VMs, I used a Mac Studio M1 Max running Sonoma 14.0. A Sonoma 14.0 VM was built using Viable, and run during tests using that virtualisation app. Test loads were applied from the VM using my app AsmAttic, each thread running 5 x 10^8 tight loops of purposeless assembly code performing floating point arithmetic using registers alone. I detailed this here. Each thread typically takes about 3.2 seconds to complete, and serves here as an in-core load, not a benchmark. During each of those runs, powermetrics was run on the host to log cpu_power measurements over 0.1 second sampling periods. Frequency and active residency for all the cores was then extracted and analysed using DataGraph. Test runs included the same VM configured with 3 and 4 virtual cores, and with 1-6 threads, all at a QoS of 33. Single threads Running a single thread on three or four virtual cores resulted in the expected rapid change in P0 cluster frequency (above), and in active residency (percentage of available processor cycles that aren’t idle), shown below. As this gives total active residency for the whole cluster of four cores, its maximum is 400%. Although there are small peaks above the expected 100% for a single thread, those were probably threads from other processes. Multiple threads As the number of threads run on the VM increases, so the number of cores running them rises to the limit imposed by the number of virtual cores. Looking first at the effect on host clusters, these might imply that VM threads are confined to the single P cluster, P0. This chart shows cluster frequencies for the three clusters in the M1 Max. The test load was applied just after 1 second, and was completed at about 4 seconds, matching the reported elapsed time of about 3.2 seconds. P0 frequency (solid line) rose rapidly to just over 3,000 MHz, and was sustained at that until completion. The other P cluster (P1) was run much of that time at its idle of 600 MHz, with short peaks up to 2,500 MHz. The E cluster was run throughout at about 1,000 MHz, with fewer and smaller peaks. Here, to enable easier comparison, cluster active residency is shown with a scale maximum of 100% for each of the three clusters. The effect of the load on P0 active residency (solid line) dominates much as it did for frequency, but there are also many smaller and briefer peaks. To unravel what those represent, you need to analyse individual core responses. Individual P cores A simple starting point is analysing the active residency in P0 by individual core, for a single thread test. This bar chart shows just the test period, here as sample number rather than time (each sample representing approximately 0.1 second). Active residency for the first core, P2, is shown in red, P3 in orange, P4 in blue, and P5 in purple. The bulk of the test thread was run on P2 to begin with, swapped over to P4, then brought back to P2 to complete. There are, though, significant contributions made by P3 as well. Extending this analysis to other thread numbers, and 4 virtual cores, demonstrated that all cores in the P0 were used to run the test threads, which were moved around not infrequently during each test run. It’s only when you look at active residency across all P cores that the picture becomes clear: when the second P cluster is active, it appears to be handling some of the test load. This shows active residency for all eight P cores, when running 4 threads on 4 virtual cores. To maintain the 400% required to complete the threads on time, there are several sample periods in which P6 and P7 take significant load, for example in samples 12 and 27, about 1 and 2.5 seconds into the test. Core allocation of threads being run on virtual cores thus appears to follow the same general rules as host threads running at high QoS, and shows no particular affinity for clusters or cores. Thus virtualisation isn’t a different mode, as far as core allocation is concerned. Conclusions Threads from VM virtual cores are invariably run at high QoS, and are scheduled and dispatched by the host macOS in accordance with its normal rules. Virtualisation doesn’t bring any special core allocation or CPU performance mode. Those threads are mobile across cores as with any other thread. There’s no evidence that macOS makes any attempt to allocate virtual cores to physical cores. Software in a VM has no means of designating that any of its threads should be run at lower QoS, or on host E cores. VMs thus lack energy efficiency and background performance advantages of macOS running on an Apple silicon host. Share this: TwitterFacebookRedditPinterestEmailPrint Loading... Related Making the most of Apple silicon power: 7 Virtualisation and core use October 27, 2022 In \"Macs\" Virtualisation on Apple silicon Macs: 4 Core allocation in VMs July 18, 2022 In \"Macs\" Virtualisation on Apple silicon Macs: 3 Configuration, VM and boot July 12, 2022 In \"Macs\" Posted in Macs, Technology and tagged Apple silicon, CPU, macOS, scheduling, thread, virtualisation, VM. Bookmark the permalink. iThere are no comments Add yours Leave a Reply This site uses Akismet to reduce spam. Learn how your comment data is processed. Quick Links Downloads Mac Troubleshooting Summary M1 & M2 Macs Mac problem-solving Painting topics Painting Long Reads Search Monthly archives October 2023 (56) September 2023 (77) August 2023 (72) July 2023 (79) June 2023 (73) May 2023 (79) April 2023 (73) March 2023 (76) February 2023 (68) January 2023 (74) December 2022 (74) November 2022 (72) October 2022 (76) September 2022 (72) August 2022 (75) July 2022 (76) June 2022 (73) May 2022 (76) April 2022 (71) March 2022 (77) February 2022 (68) January 2022 (77) December 2021 (75) November 2021 (72) October 2021 (75) September 2021 (76) August 2021 (75) July 2021 (75) June 2021 (71) May 2021 (80) April 2021 (79) March 2021 (77) February 2021 (75) January 2021 (75) December 2020 (77) November 2020 (84) October 2020 (81) September 2020 (79) August 2020 (103) July 2020 (81) June 2020 (78) May 2020 (78) April 2020 (81) March 2020 (86) February 2020 (77) January 2020 (86) December 2019 (82) November 2019 (74) October 2019 (89) September 2019 (80) August 2019 (91) July 2019 (95) June 2019 (88) May 2019 (91) April 2019 (79) March 2019 (78) February 2019 (71) January 2019 (69) December 2018 (79) November 2018 (71) October 2018 (78) September 2018 (76) August 2018 (78) July 2018 (76) June 2018 (77) May 2018 (71) April 2018 (67) March 2018 (73) February 2018 (67) January 2018 (83) December 2017 (94) November 2017 (73) October 2017 (86) September 2017 (92) August 2017 (69) July 2017 (81) June 2017 (76) May 2017 (90) April 2017 (76) March 2017 (79) February 2017 (65) January 2017 (76) December 2016 (75) November 2016 (68) October 2016 (76) September 2016 (78) August 2016 (70) July 2016 (74) June 2016 (66) May 2016 (71) April 2016 (67) March 2016 (71) February 2016 (68) January 2016 (90) December 2015 (96) November 2015 (103) October 2015 (119) September 2015 (115) August 2015 (117) July 2015 (117) June 2015 (105) May 2015 (111) April 2015 (119) March 2015 (69) February 2015 (54) January 2015 (39) Tags APFS Apple AppleScript Apple silicon backup Big Sur Blake bug Catalina Consolation Console Corinth diagnosis Disk Utility Doré El Capitan extended attributes Finder firmware Gatekeeper Gérôme HFS+ High Sierra history of painting iCloud Impressionism iOS landscape LockRattler log logs M1 Mac Mac history macOS macOS 10.12 macOS 10.13 macOS 10.14 macOS 10.15 macOS 11 macOS 12 macOS 13 malware Mojave Monet Monterey Moreau MRT myth narrative OS X Ovid painting Pissarro Poussin privacy realism Renoir riddle Rubens Sargent scripting security Sierra SilentKnight SSD Swift Time Machine Turner update upgrade Ventura xattr Xcode XProtect Statistics 15,718,601 hits Blog at WordPress.com. About & Contact Macs Painting Language Tech Life General Downloads Mac problem-solving Extended attributes (xattrs) Painting topics Hieronymus Bosch English language LockRattler: 10.12 Sierra LockRattler: 10.13 High Sierra LockRattler: 10.11 El Capitan Updates: El Capitan Updates: High Sierra and later LockRattler: 10.14 Mojave SilentKnight, silnite, LockRattler, SystHist & Scrub DelightEd & Podofyllin xattred, Spotcord, Metamer & xattr tools 32-bitCheck & ArchiChect XProCheck, T2M2, Ulbow, Consolation and log utilities Cirrus & Bailiff Taccy, Signet, Precize, Alifix, UTIutility, Sparsity, alisma Revisionist & DeepTools Text Utilities: Nalaprop, Dystextia and others PDF Keychains & Permissions LockRattler: 10.15 Catalina Updates Spundle, Cormorant, Stibium, Dintch, Fintch and cintch Long Reads Mac Troubleshooting Summary LockRattler: 11.0 Big Sur M1 & M2 Macs Mints: a multifunction utility LockRattler: 12.x Monterey VisualLookUpTest Virtualisation on Apple silicon LockRattler: 13.x Ventura System Updates LockRattler: 14.x Sonoma Search Painting the blustery wind 2 Solutions to Saturday Mac riddles 226 Begin typing your search above and press return to search. Press Esc to cancel. Comment Follow",
    "commentLink": "https://news.ycombinator.com/item?id=37991295",
    "commentBody": "How does macOS manage virtual cores on Apple Silicon?Hacker NewspastloginHow does macOS manage virtual cores on Apple Silicon? (eclecticlight.co) 207 points by todsacerdoti 13 hours ago| hidepastfavorite140 comments ta8645 4 hours agoIt&#x27;s interesting to see AMD&#x27;s take on big-little. The only difference between their Zen 4 core (big) and Zen 4c (little) cores is the speed and thermal characteristics. Owing to the same architecture (RTL) being implemented by both, with only the layout and cell density differing. https:&#x2F;&#x2F;youtu.be&#x2F;h80TB8K-Rfo?t=260 reply Aardwolf 2 hours agoparentI like this approach (especially because it supports AVX-512), however even not counting the Zen 4c, AMD 3D v-cache CPU&#x27;s have cores that are sufficiently heterogeneous (those with and without 3D cache) that some special scheduling is desired for some use cases (gaming on Windows) reply kfreds 3 hours agoparentprevGreat video! Thanks for the link.By the way, I was confused by how you equated architecture and RTL. In this context I use \"architecture\" to mean ISA. I use \"microarchitecture\" to refer to how e.g. its performance characteristics are realized, like IPC.You seem to know more than I do and would love you to comment. Thanks! reply Waterluvian 11 hours agoprevWas the industry ready for this concept of a computer having a number of meaningfully different kinds of cores? Has this happened before? Or did application developers just get cores as an integer count and that was it? reply Kon-Peki 7 hours agoparent> Was the industry ready for this concept of a computer having a number of meaningfully different kinds of cores?The industry didn’t have a choice. The market was demanding higher performance within the same thermal envelope and the same energy consumption. These are mobile devices, you can’t put a bigger heat sink on it and then crank up the power.You can find tons of academic literature discussing the necessity of this development (along with many other things that have come to pass), how it would work, etc. in the decade leading up to the introduction. ARM didn’t just release it to the world and say “Surprise!”We knew it was coming, we just didn’t do the best job of preparing for it. reply adastra22 9 hours agoparentprevHeterogeneous computing is as old as computer science itself. There are well-known algorithms for dealing with this. reply yjftsjthsd-h 8 hours agorootparentOTOH I&#x27;d question whether we as an industry are up to using it effectively, given that we couldn&#x27;t even handle symmetric multiprocessing very well:) reply xcv123 11 hours agoparentprevIt&#x27;s been around since 2011 on Android. Nothing new. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ARM_big.LITTLE reply astrange 11 hours agorootparentGeneral term is asymmetric multiprocessing, which goes back a few more decades:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Asymmetric_multiprocessingIIRC big.LITTLE implementations tended to have cores that didn&#x27;t support the same instruction sets, meaning you couldn&#x27;t migrate tasks between them if you needed to. Kind of like how laptops could switch between integrated and discrete GPUs, but some users would need to switch to the discrete GPU to use an external monitor even if they didn&#x27;t want the power hit.Also, \"big.LITTLE\" is a pretty strange brand name. reply reanimus 9 hours agorootparentI think the term you&#x27;re going for here is heterogeneous multi-processing&#x2F;computing, not asymmetric multiprocessing:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ARM_big.LITTLE#Heterogeneous_m...https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Heterogeneous_computingIt even lists big.LITTLE there as a typical example in the second article. big.LITTLE itself never had different ISAs as far as I could tell, just scheduling caveats that lead to efficiency tradeoffs, like the first article mentions. reply astrange 7 hours agorootparentMy understanding of \"heterogenous computing\" is that it&#x27;s more about splitting a task across a CPU and coprocessors, or writing the same code to target both. Asymmetric means there&#x27;s multiple CPU cores but they&#x27;re not equally performant. reply repiret 9 hours agorootparentprevbig.LITTLE is typically cores with the same architectural features, just different performance due to different microarchitecture. A7&#x2F;A15&#x2F;A17, or A53&#x2F;A57&#x2F;A72, or A55&#x2F;A76.This let them run the same code, even the same system level code. The scheduler only had to optimize performance, without tasks being pinned to one core or another for correctness. reply lights0123 6 hours agorootparentprevThis is the case in Intel 12th gen: P cores support AVX512, E cores do not. Instead of allowing OS-level support, you could gain back AVX512 by disabling E cores. Intel ended up disabling that feature in hardware later though. reply MobiusHorizons 4 hours agorootparentThis was honestly a pretty surprising mistake for a big player like Intel. Quite a big oversight in my opinion. The fact that the OS will migrate processes from big cores to little cores should not be a surprise, given that it is basically necessary for the power savings to be realized. That effectively necessitates having the same ISA on both the big and little cores. It&#x27;s not like desktop class operating systems haven&#x27;t been running on these types of cores for over a decade. reply jasonjayr 8 hours agorootparentprevNot to be confused with Little Big - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Little_Big_(band) reply ClassyJacket 6 hours agorootparentNot to be confused with LittleBigPlanet. reply wmf 11 hours agorootparentprevYet nobody in the Windows&#x2F;Mac world was ready (if you think they should have to care which maybe they shouldn&#x27;t). reply wutwutwat 11 hours agorootparentNobody in the Windows&#x2F;Mac world writing software should have to care about the change, or even know about it. That&#x27;s the beauty of an OS scheduler, it is optimized to execute your instructions where it sees fit, and higher level programs don&#x27;t need to know how it works, where it executes your instructions, or that it even exists. Sometimes abstraction and separation of concerns can be beautiful thing. I&#x27;d argue that most programs shouldn&#x27;t make any decisions about where to run, I know I don&#x27;t want random engineers for some mac app controlling my power consumption or setting priority above anything else I run. The kernel developers with the data stream of health and performance info from the intimately connected hardware (on apple) is who I want to make the call on where to run. In the very few situations where E or P core assignment matters (games and VMs are all that I can think of and even that is arguable imo), there has been the ability to inform the OS scheduler where to run for a very long time.Tangent: With today&#x27;s insanely powerful hardware you should not ever be constrained in your programs to ever have to consider setting core affinity and if you go down that road you might want to reevaluate what you&#x27;re doing, because you&#x27;re probably doing something wrong and blaming it on the OS scheduler. Even constrained to the E cores (which are still plenty fast), your programs should perform well. I think more developers need to start writing software on slow machines on purpose because too many apps are written on machines that cost $4000+ with the newest chip and gpu innovations and then are never tested on slower more commonly used hardware, and things end up being dog slow on those machines and get no attention. If more apps were built on slow hardware and were still fast, they&#x27;d be even more so on the $4k machines. The macbook air was great for this because it was fanless and every core was essentially an \"E\" core, forcing you to optimize the code you wrote for the selfish reason of it not being annoying to run the code you were writing. Even if selfish, the net result was production code that was blazing fast once deployed on server grade hardware. reply yjftsjthsd-h 5 hours agorootparentAbstractions leak. Many devs don&#x27;t need to care, but anyone particularly concerned with performance or power consumption will want to know the details. (Just like many devs don&#x27;t need to know about CPU cache, how GPUs work, etc.) reply adev_ 5 hours agorootparentprev> today&#x27;s insanely powerful hardware you should not ever be constrained in your programs to ever have to consider setting core affinityThat is wrong in HPC environment.Most programs tailored for HPC will set core affinity manually. And they have very good reason to do so (cache affinity, memory bindings).The correct abstraction depend of your domain. There were indeed very little incentive up to know to play with core affinity and the scheduler in a classical desktop environment.The story is different on systems with strong constraints on efficiency. reply dwattttt 8 hours agorootparentprevIf instructions don&#x27;t run the same between heterogenous cores, i.e. one core supports instructions the other doesn&#x27;t, unless this information is available to the scheduler, there&#x27;s no way it can make that decision. AVX512 was such an example, and sadly it ended up getting locked off from the P cores. reply wutwutwat 8 hours agorootparentSomething made the decision if it got \"locked off from the P cores\", what was it if not the OS scheduler? reply wtallis 8 hours agorootparentWhat got locked off was the P-core&#x27;s AVX512 instruction support, not some process&#x27;s core affinity. Intel didn&#x27;t have an E-core design ready to support AVX512 in Alder Lake. They initially allowed AVX512 to be enabled on the P-cores if all the E-cores were disabled at boot, but they later switched to fusing off AVX512 support permanently. reply wutwutwat 2 hours agorootparentInteresting, but what does this have to do with what my original comment was about? replyxcv123 11 hours agorootparentprevOn Mac they have used the Grand Central Dispatch library since 2009. So if developers already used that, they were ready for M1 https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Grand_Central_Dispatch reply astrange 11 hours agorootparentGCD was actually not designed for this scenario and it&#x27;s easy to mess up with it.It was designed for a large number of equal cores (aka SMP), meaning people did dispatch_async to the default concurrent queues all over the place, which is a bad pattern when you have to shrink down to phone size. Also, dispatch_semaphore has priority inversions and a lot of other features (like dispatch_group) are semaphores in disguise.It does work if you use it carefully, but Swift concurrency is a different design for a reason. reply xcv123 11 hours agorootparentAccording to Apple developer documentation GCD is currently designed for this scenariohttps:&#x2F;&#x2F;developer.apple.com&#x2F;documentation&#x2F;apple-silicon&#x2F;tuni...\"On a Mac with Apple silicon, GCD takes into account the differences in core types, distributing tasks to the appropriate core type to get the needed performance or efficiency.\" reply astrange 11 hours agorootparentIt is now, but that&#x27;s mostly from evolution in the iOS era. But like I said, it&#x27;s not perfect. reply krackers 9 hours agorootparentprevthat&#x27;s probably assuming you set the qos correctly. reply astrange 2 hours agorootparentAnd dispatch_async loses QoS while dispatch_sync keeps it, but people often used to async unnecessarily. replym3kw9 9 hours agorootparentprevAndroid likes to do things to check off boxes and in mediocre ways reply ryanschneider 8 hours agoparentpreviPhones and iOS have had this for quite awhile. My iOS dev knowledge is rather dated now but IIRC Grand Central Dispatch let you indicate the type of workload your task needed and thus which core type it was typically scheduled on. reply mobilio 3 hours agorootparentGCD first appear on OSX 10.5 or 10.6 as i remember. reply stiGGG 3 hours agorootparentGCD first appeared on 10.6 Snow Leopard, which was marketed as a bug-fix only release and is due to this romanticised until today, but in reality included major changes under the hood and wasn’t very stable in his first versions. reply bombcar 8 hours agoparentprevI mean ever since very early on the GPU was a \"separate CPU with different kinds of cores\" compared to the main CPU. reply panzi 7 hours agoparentprevGame consoles had different kinds of cores&#x2F;processors. reply samjord0n 7 hours agoprevBig.Little is a good architectural innovation, although I don&#x27;t think MacOS and Android have been making good use of it. It is tricky hw feature to manage in software overall. Virtualization adds even more complexity. reply aurareturn 7 hours agoparentDo you have a reason for why macOS doesn&#x27;t make good use of big.Little?As far as I know, it allocates background&#x2F;low priority tasks to little cores such as OS housekeeping tasks. When you&#x27;re on low powered mode or low battery mode, it automatically switches to little cores to save energy. When you need extra multithread power, it uses all cores. reply miohtama 12 hours agoprevSounds like this explains why Docker eats thru Mac battery so fast reply wutwutwat 11 hours agoparentCheckout App Tamer[1] to control the priority of processes as well as core assignment on the M series chips:> App Tamer can take special advantage of Apple Silicon powered Macs, which have two different types of processor cores. Use it to automatically run busy background apps on the M1 or M2&#x27;s efficiency cores to save power, leaving the performance cores for the apps you want to run fastest.1. https:&#x2F;&#x2F;www.stclairsoft.com&#x2F;AppTamer&#x2F; reply amazingman 12 hours agoparentprevI get 6h or so running quite a few workloads in Kubernetes on Docker For Mac on Apple Silicon. Intel wasWith the introduction of Game Mode in Sonoma, CPU scheduling can now work differently, with E cores being reserved for the use of games.- shouldn&#x27;t that be &#x27;P cores&#x27;? reply samtheprogram 12 hours agoparentThat was my first impression too, but it actually makes sense. According to a linked article by the same author:> it’s apparent that during Game Mode, the game was given exclusive use of the two E cores, and threads from other processes fixed at low QoS, which would require them to be run on the E cores, were kept waiting. The game’s threads were run on a combination of E and P cores, with much of their load being concentrated on the E cores. This appears to be energy-efficient, and ideal for use on notebooks running on battery power.So: the E cores are resevered for the use of games, but the game still makes use of some P cores.https:&#x2F;&#x2F;eclecticlight.co&#x2F;2023&#x2F;10&#x2F;18&#x2F;how-game-mode-manages-cp... reply chongli 11 hours agorootparentI like the sound of this! I play a lot of older games on my MacBook Air and one of my biggest annoyances is when the game gets the machine to heat up (and in previous iterations spin up the fan) despite being a very graphically undemanding game.I think there are a lot of otherwise graphically simple games that poll or sit there in busy wait loops or render more frames than the display can show. It’s like they’ve been built for a resource starved environment and don’t know how to properly handle abundance. It’s really frustrating! reply dimask 9 hours agorootparentI did notice that my MBA M1 running Baldur&#x27;s Gate 3 heats up much less under Sonoma, which moreover makes the performance more consistent (it would heat up and throttle however the resolution&#x2F;settings, which meant it was better to run in low power mode actually). I had no idea it was because of the OS update. reply withinboredom 10 hours agorootparentprevOn my PC, I limit my FPS to 24 (via graphics card settings). It uses far less power, and runs considerably cooler. reply Alupis 10 hours agorootparentThis is bad, in a gaming setting, for several reasons.You should at least make your frame limit be equal to your screen refresh rate. reply dimask 3 hours agorootparentI has to be a divisor of the frame rate, not necessarily equal. Eg with 30fs in a 60fps screen you will do fine. But with a high refresh rate screen and gsync&#x2F;freesync on top of that, most probably it does not matter at all because the refresh rate of the screen should adjust. reply withinboredom 10 hours agorootparentprevMeh, gsync keeps it sane. But no, my screen refresh rate is 165hz. If it were to be running that many fps, it would result in ~200 watts of power be utilized. Maybe this is \"good\" for gaming, but it is def bad for my wallet who has to pay the power bill. Maybe when electricity prices go back down, I&#x27;ll turn it up. reply Alupis 9 hours agorootparent> Meh, gsync keeps it sane.GSync isn&#x27;t magic. It can only do so much. In this situation, where you&#x27;ve tied your frames to 24 (for some reason?) and your monitor refresh rate is 165Hz, GSync isn&#x27;t going to save you. GSync will help you if there are sudden, brief drops in FPS below the refresh rate and keep things in sync. It will not save you if your refresh rate is 165Hz and your frame rate is 24...> Maybe when electricity prices go back down, I&#x27;ll turn it upI don&#x27;t think you&#x27;ll notice the extra $5 a month it costs to run that a couple hours a week.We should at least use a real reason why you&#x27;d do this. Saving a smidge of power is not one of them.You should, instead, under-clock your monitor refresh rate to something low, like 75 or 60Hz, then frame-limit to that number as well. reply bpye 8 hours agorootparentGsync&#x2F;variable refresh rate should be able to make that work. Even if the display doesn’t go down to 24Hz, it only needs to drop to 144Hz to be an integer multiple of 24Hz - you’d just get each frame being displayed for 6 frames. reply neurostimulant 3 hours agorootparentprevHow high the electricity cost in your area for you to notice an extra 200 watts during gaming? Assuming $0.3&#x2F;kwh, if you play 8 hours everyday (which is a lot), you&#x27;ll increase your bill by $14.4. If you only play 2 hours everyday on average, the increase is only $3.6. reply withinboredom 1 hour agorootparentAs I mentioned in another comment down-thread, my costs (after taxes + fees) is €0.60 a kWh. reply adastra22 9 hours agorootparentprevOutside of networked multiplayer games, I can’t think of any reason this would be “bad.” reply Alupis 9 hours agorootparentEven slow paced games will experience tearing. Here, the parent post has inadvertently made their setup beyond non-ideal.They picked a random 24 FPS target (maybe based off old movies for some reason?), but their monitor refreshes at 165Hz. The mis-match of frames and refreshes is so off, they will experience tearing even with mostly-static backgrounds.Basically, nothing the parent poster is doing makes sense. Neither for power savings nor viewing pleasure. reply wutwutwat 2 hours agorootparent> They picked a random 24 FPS target (maybe based off old movies for some reason?)Not random, and not \"old movies\". Modern day movies are still 24fps, it&#x27;s part of what makes movies look the way they do, motion blur.> but their monitor refreshes at 165HzSo? It refreshes the image 165 times a second, regardless of video framerate. It just so happens that many of those 165 refreshes in this case will be the same image over and over. Pause a video, so 0 fps, or 1 fps depending on your take, the monitor is still refreshing 165 times a second because it doesn&#x27;t have anything to do with the video in this case. reply adastra22 8 hours agorootparentprevNot tearing. It can still utilize vertical sync. If done naïvely the time between frames would jitter a bit though. At 165Hz it wouldn’t be too bad. reply AvesMerit 6 hours agorootparentprevHow much money could it possibly save? It might be more worth it to sell your GPU & buy a cheaper one. You might even be able to run at a higher framerate with those savings! reply withinboredom 4 hours agorootparent10-20 Euro per month, just from gaming. From all things, it makes a difference of about 50-100 Euro a month.20fps uses 70 watts, full speed is 200 watts. Times 5 hours, times 30 days, times €0.60. reply ClassyJacket 6 hours agorootparentprevThat&#x27;s kinda like saying to save money you eat only plain rice, uncooked. Like yes it will technically work but most people would not be willing to subject themselves to that. reply perryizgr8 8 hours agorootparentprevThat sounds horrifying. I can&#x27;t comfortably watch video at 24 fps, let alone play an interactive game. But to each his own, who am I to dictate your preferences? reply bigstrat2003 6 hours agorootparentI&#x27;m not the GP, but it makes sense to me. I can&#x27;t even see a difference between 24 and 60 FPS. It has to get down into the teens before I can tell. I haven&#x27;t capped my graphics like that, but that&#x27;s more because it never occurred to me than because it would bother me. reply d_k_f 3 hours agorootparentHonest question, not intended to be disparaging: do you not see a difference between the various animations on [1], for example? To me, they are very apparent.[1] https:&#x2F;&#x2F;www.testufo.com&#x2F; reply bigstrat2003 3 hours agorootparentThe bottom one looks different. Like I said, I can tell once the FPS gets into the teens. The top two look exactly the same to me. I realize they are different, but I can&#x27;t see it. reply Sakos 1 hour agorootparenthttps:&#x2F;&#x2F;www.testufo.com&#x2F;framerates#count=4&background=stars&...This is better, because we&#x27;re talking about the lower range right now anyway.That said, I think the difference between 144Hz and 72Hz is a lot more subtle and can&#x27;t be seen if you try to glance at them directly. Try viewing them with peripheral vision and there&#x27;s a difference in smoothness. That shows up in things like moving a window around (or even just moving a mouse). It makes a huge difference in input latency&#x2F;response, but the difference can&#x27;t be seen easily by just staring directly at a moving image. reply withinboredom 3 hours agorootparentprevAbout 10 fps is my lower limit. I can’t tell the difference for anything higher than 18 fps. replyAngostura 11 hours agorootparentprevAh excellent. Thaks for correcting my erroneous correction attempt reply btown 11 hours agoparentprevBrings a whole new meaning to “idle” games! reply a-dub 7 hours agoprevwhat&#x27;s the difference between a P-core and an E-core? special machinery for caching, branch prediction and speculative execution?i still have the antiquated view that performance and efficiency are essentially the same metric and these are the only kinds of ideas i can come up with that would separate them.. reply ip26 5 hours agoparentA semi truck is a very efficient way to move a lot of packages across the country very quickly. It is a terribly inefficient way to move a single envelope.Deeper speculation, larger out of order window, more accurate branch prediction, larger caches, more execution pipes, larger register files… reply zamadatix 6 hours agoparentprevSpeculative architecture is one thing but plain ol&#x27; superscalar architecture can make things run faster by simply executing more instructions per cycle, given you dedicated the die space to additional execution units to do more things at the same time. reply MBCook 7 hours agoparentprevE-cores are physically smaller and have fewer execution units and what they do have are more likely to be shared, I think.So they simply can’t process as much clock for clock. reply monocasa 7 hours agorootparentThey also have smaller resources like reorder buffers so they can&#x27;t speculatively keep nearly as much in progress work around, leading to more stalls. reply caycep 12 hours agopreva bit OT, but has anyone had the opportunity to compare how Vimy feels vs. UTM? reply infamouscow 12 hours agoprevI don&#x27;t think macOS allows a userspace program to set thread affinities.Not only are the functions commented out, there&#x27;s this note THREAD_AFFINITY_POLICY: This policy is experimental. This may be used to express affinity relationships between threads in the task. Threads with the same affinity tag will be scheduled to share an L2 cache if possible. That is, affinity tags are a hint to the scheduler for thread placement. The namespace of affinity tags is generally local to one task. However, a child task created after the assignment of affinity tags by its parent will share that namespace. In particular, a family of forked processes may be created with a shared affinity namespace.https:&#x2F;&#x2F;github.com&#x2F;apple-oss-distributions&#x2F;xnu&#x2F;blob&#x2F;main&#x2F;osf... reply wutwutwat 11 hours agoparentHere&#x27;s one example of userspace programs assigning affinity to specific cores> Use it to automatically run busy background apps on the M1 or M2&#x27;s efficiency cores to save power, leaving the performance cores for the apps you want to run fastest.https:&#x2F;&#x2F;www.stclairsoft.com&#x2F;AppTamer&#x2F; reply krackers 9 hours agorootparentUnfortunately you can&#x27;t do the reverse, pin to p core reply mef 8 hours agoprev> QoS is a control set and changed in the code launching a process, and can only be altered by the user if the app exposes a control, a feature which remains exceptionally uncommon. Neither is there any easy way for a user to know the QoS of any given process unless the app reveals that.That... sucks reply brianpan 6 hours agoparentDoes it? I buy my MacBook to use it, not manage process performance. When I launch a game, I get a popup that tells me that it will be prioritized while it is fullscreen. And there&#x27;s a menu icon to turn off \"game mode\". Ok, fine, but I don&#x27;t really care and I doubt I&#x27;ll ever touch the setting.It&#x27;s there to be exposed if the developer thinks it should. That seems like the right balance to me. reply MBCook 10 hours agoprevSince we’re talking the scheduler, has it gotten better at not ping-ponging processors around?I seem to remember years ago I could open activity monitor and watch processes migrate back-and-forth between cores for seemingly no reason instead of just sticking in places.I haven’t watched to see what happens recently. Is that still an issue? reply kiririn 10 hours agoparentReason for it is thermals reply krackers 9 hours agoparentprevHow can you see which core a process in on from activity monitor? Only way I know of is via instruments? reply MBCook 7 hours agorootparentI think it was back when I ran a utility called MenuMeters which no longer exists.iStatMenus is a similar utility that still exists and is far more popular. reply krackers 7 hours agorootparentistat menus doesn&#x27;t show you _which_ core a given process is running on though? It only shows you total core activity? reply3cats-in-a-coat 10 hours agoparentprevAside from cosmetics, is it really an issue? And why? reply serf 9 hours agorootparentIt causes latency issues on SMP machines with multiple processors for sure; I don&#x27;t know whether or not that same issue translates to a similar scheduling problem across the same die, although I imagine it would, the context switch and scheduler itself isn&#x27;t costless.gamers have been binding to single processors&#x2F;cores for years for that reason, it&#x27;s a huge cause of microstutter type behaviors -- but who knows if its perceivable with all the magic going on with processors nowadays. reply aeadio 5 hours agorootparentProcesses get interrupted and rescheduled between tens and hundreds of times per second (depending on OS, the scheduler may take over somewhere between 100 and 2000 Hz, although it doesn&#x27;t necessarily deschedule every time). This is how SMP works at its most fundamental level. Every time that happens, it involves a full flush from the hardware perspective. It&#x27;s always context switching, savings the registers, clearing the buffers, etc.When a process gets descheduled and then later rescheduled, there is no particular reason to reschedule it on the same core it was on previously. Desktop class hardware doesn&#x27;t have NUMA. Last level caches might have locality-dependent performance characteristics, but this is usually pretty nuanced, wildly variable between hardware microarchitectures, and not accounted for &#x2F; not worth accounting for in the OS&#x27;s scheduler, since there&#x27;s a good chance that data won&#x27;t be around next timeslice anyway.Binding a processor to a single core affinity-wise is not changing any of this.If you really have a throughput-bound process that needs to squeeze every single microsecond of compute and&#x2F;or you&#x27;re super latency bound for some reason, you schedule a process with what&#x27;s called realtime priority, which changes the scheduling decision of WHEN to deschedule it. Not every operating system has equivalent mechanisms for this, but that&#x27;s more in line with the phenomena that you&#x27;re describing. But a process may well cause itself to be descheduled anyway by doing something that puts it to sleep. You have no control over this.In reality, looking at which core a process is on is mostly the wrong way to be thinking. You&#x27;re looking at this on a 1-2 second window (the amount of time it takes for Activity Monitor &#x2F; Task Manager to update its UI). A full second of time is an absolute eternity to a process. Large amounts of work happen on the order of microseconds and quicker. And in that 1-2 second snapshot that Activity Monitor or Task Manager gave you, the process probably spent time on EVERY core -- and you&#x27;re just seeing wherever it was in the brief moment when Activity Monitor &#x2F; Task Manager updated its UI.> gamers have been binding to single processors&#x2F;cores for years for that reason, it&#x27;s a huge cause of microstutter type behaviorsIt wouldn&#x27;t be the first time gamers prescribed placebo tweaks because of magical type thinking. reply sroussey 4 hours agorootparentDesktops have mini-numa (core complex et al), and a scheduler might take this into account, but I think the cache lines are emptied anyhow on context switch, but otherwise multi threaded apps might be able to share some cache. Or it might not, and it will thrash the cache and be better in different complexes. Easy to contemplate opposite scenarios. reply MBCook 10 hours agorootparentprevDepending on which cores it’s moving between it could be a performance issue if they don’t share a cache. I don’t know if it actually is or was. reply ge96 11 hours agoprevI&#x27;m not a \"hater\" of Apple, I think they were just too expensive for me long time ago.I will say since I use them for work, their ability to keep running despite opening so much crap is amazing. Browser tab wise. Not just limited to a specific silicon either as I use both intel&#x2F;m2. reply hypercube33 11 hours agoparentHow so? I usually have 200-600 browser tabs open for weeks on Windows&#x2F;ryzen 5000 reply TomK32 10 hours agorootparentHave you heard of bookmarks? And if you need a little bit of help with that, Tab Stash comes to the rescue https:&#x2F;&#x2F;addons.mozilla.org&#x2F;en-US&#x2F;firefox&#x2F;addon&#x2F;tab-stash&#x2F; reply giancarlostoro 10 hours agorootparentFrom someone who sometimes becomes a tab hoarder... Bookmarks get lost, tabs are things you want to keep around until you are done with it. Every now and then I say \"eff it\" and clear all my tabs and start over, but most of the time I leave them up. It makes it easy to talk to friends about recent stories I just read if its still there in my tabs. reply jwells89 10 hours agorootparentBookmarks also have considerable management overhead if one wants to keep them usable, largely thanks to browser vendors having either phoned in the design of their bookmark managers or left them stuck in 1999. For some reason an Nth cosmetic toolbar redesign is more important than making bookmark management not terrible. reply NavinF 10 hours agorootparentExactly. You can&#x27;t even search within just one bookmark folder in chrome or do fuzzy search. Bookmark manager UX is hot garbage. reply charlie0 8 hours agorootparentprevThis argument has never made any sense to me. Once you get past 30-40 tabs, all that appears on screen is just a series of icons, and repeating icons at that as most tab hoarders I&#x27;ve seen from screen sharing have multiple tabs of the same site open in random locations. Unless you have some sort of photographic memory, it&#x27;s certainly much easier to bookmarks stuff and organize it than haphazardly scan through a long series of icons to find the right page. reply ta8903 5 hours agorootparentVertical&#x2F;tree-style tabs are a must if you&#x27;re a tab hoarder, I can&#x27;t imagine living without them. reply ge96 10 hours agorootparentprevThat&#x27;s where you make a browser extension to dump your tabs before closing all reply JoBrad 9 hours agorootparentprevI save all of my open tabs into a folder.But now there are built in ways to manage tab groups, which I haven’t used yet, but look neat. reply isatty 8 hours agorootparentprevI have ADHD. None of these work. reply NavinF 11 hours agorootparentprevThat&#x27;s not a lot tbh. I&#x27;m usually at ~1500 tabs (13 windows across 3 win+tab desktops) per machine on both my desktop (64GB 5800x3d) and macbook (32GB M2 Pro). reply stouset 10 hours agorootparentWhy on earth would you do this? Genuine question. reply giancarlostoro 10 hours agorootparentI don&#x27;t go quite that excessive, but you can keep various projects and activities tracked pretty well. Instead of regretting closing a few stackoverflow pages (which will be a nightmare to search for even with local history) you can leave up the useful ones, so you don&#x27;t lose them, and close it all once the current task &#x2F; project is no longer needing them.I used to make fun of people who hoarded them, but honestly sometimes just keeping that one tab open until you&#x27;ve exhausted its use is worth it. reply kagakuninja 8 hours agorootparentI can&#x27;t even imagine trying to locate that \"useful tab\" amongst 1500 open tabs. My bookmarks by contrast are nicely organized into folders. I can also open an entire folder of links at once, for example, my favorite blogs. reply cle 10 hours agorootparentprevI do something similar, because I can. Why waste time organizing & pruning them when I don&#x27;t need to? I can just search for open tabs that I need, jump to windows to resume sessions I was working on earlier, etc. At some point it gets too much and I use OneTab to save all my open tabs and start over. reply NavinF 10 hours agorootparentprevEach project has its own window. Ctrl+tab moves down the call stack and ctrl+shift+tab moves up the call stack. Exploring a topic often requires depth first search and a lot of ctrl+w and clicking \"close tabs to the right\" after researching subtopics. I&#x27;ve used this approach for over a decade and I&#x27;ve always been able to upgrade my machine fast enough to keep up.Of course I also use ctrl+e (QuickTabs) to jump faster with intellij-like fuzzy search. It&#x27;s kinda like Chrome&#x27;s built-in ctrl+shift+a, except better. reply pests 8 hours agorootparentprevBragging rights. reply 3c6bYDXLMj 11 hours agorootparentprevIt’s quite clearly a lot. Just not as much as you. reply NavinF 10 hours agorootparentI meant that for a modern machine 1500 is nowhere close to the maximum amount you can have before TLB misses (and later page faults) slow down the entire machine. If a machine with similar specs can&#x27;t handle that many tabs, something is misconfigured. Eg maybe memory timings are way too conservative or the wrong power profile is in use. reply astrange 10 hours agorootparentRemember a website can do anything it wants, and that includes leaking 32GB memory.Browsers have been implementing background tab killing recently though, so just because you have a tab doesn&#x27;t mean the process is actually backing it anymore. reply NavinF 10 hours agorootparentI&#x27;ve seen the occasional memory leak from Youtube and Twitter, but only once a month. Not a big deal since I try to reboot for security updates every 3-6 months anyway. reply brigade 10 hours agorootparentprev1500 tabs easily touches enough RAM that average computers will keep swapping if that&#x27;s actually your working set. Which is why any good browser should be completely freezing tabs that haven&#x27;t been active in a while so their memory can remain swapped out, or even completely unloading them.Though, 1500 tabs in one window is beyond the point at which it impacts Safari&#x27;s responsiveness, but that&#x27;s completely unrelated to the contents of the tabs and is instead the fault of taking way too long to update every NSView in the tab bar. reply smilespray 10 hours agorootparentprevGood lord. Now I&#x27;m hesitantly curious to know how many unread messages and unopened emails you have. reply NavinF 10 hours agorootparent0 unread replies on the sites I use regularly (HN, reddit, twitter, messenger) and 0 unread emails in the Primary tab on gmail.I used to be inbox-zero in all gmail tabs a couple of years ago and I will be yet again some day. The main limitation I&#x27;m running into is that a lot of useless emails (\"We&#x27;re making some changes to our PayPal legal agreements\") have unpredictable subject lines and are sent from the same address that sends useful emails. I already have hundreds of gmail filters that auto-archive useless emails with predictable addresses or subject lines (\"Your statement is ready\") that I can&#x27;t unsubscribe from without closing the account. LLMs should solve this problem some day. reply solardev 10 hours agorootparentprevYeesh. I have a 32GB M2 Max and if I hit 15 (that&#x27;s fifteen) tabs, I&#x27;ll habitually quit the browser and restart it, if not the whole computer. Any apps in the background get force quit after the last window is closed.Windows 98-brain is hard to get rid of... reply Fnoord 2 hours agorootparentMy Windows 9x brain opens as many Netscape&#x2F;Opera&#x2F;MSIE windows as I want till &#x27;it&#x27; crashes. Nowadays swapping heavily just slows down the machine. reply vGPU 11 hours agorootparentprevI have one specific TradingView tab that will crash the browser if I try to interact with it. Been that way for weeks. reply ge96 11 hours agorootparentprevYeah my comment is more on memory management in this case 16GB range.edit: I&#x27;m gonna get dinged for OT comment again ha reply theGnuMe 11 hours agorootparentprevWeird, chrome freezes daily for me. reply NavinF 10 hours agorootparentOn what machine? As I mentioned up thread, if a machine with similar specs can&#x27;t handle that many tabs, something is misconfigured. Eg maybe memory timings are way too conservative or the wrong power profile is in use.If you open Resource Monitor before the freeze, you can usually see what happened on the graphs. If you&#x27;re fast enough, you can also click \"analyze wait chain\" to see something that looks like a stack trace. The graphs and trace should make it pretty obvious why an app is frozen. Eg maybe it&#x27;s trying to save the history sqlite database and your SSD ran out of SLC cache. reply teaearlgraycold 10 hours agorootparentprevSeek help reply charlie0 7 hours agorootparentI&#x27;m convinced the neurology of these people is setup in a way that they feel physically rewarded from combing through random hoarded stuff to find what they are looking for vs organizing things. It would make for an interesting scientific study as to why some users feel so compelled to keep so many tabs open. Is it FOMO, excellent recall (the only way I can see this being truly useful), or actual hoarding disorder gone digital???As a person who has terrible short-term memory, I&#x27;m genuinely curious. I never hoard my tabs past a certain point 10-20 tabs, it actually slows me down in finding what I&#x27;m looking for. If I&#x27;m working on specific projects and need to save the tabs for later, I just use tab groups in Chrome and associate with a task so when I context switch, I just open up an existing tab group and close my other non-related ones.https:&#x2F;&#x2F;www.google.com&#x2F;chrome&#x2F;tips&#x2F;#:~:text=You%20can%20grou.... reply Sakos 7 minutes agorootparent1) Why so judgmental?2) As somebody with ADHD, there&#x27;s an unacceptable level of mental overhead required for organizing things. I simply don&#x27;t have any spare bandwidth to add organizing tabs into bookmarks and organizing bookmarks or whatever else into my daily functioning as a human being. It has nothing to do with feeling rewarded. reply1-6 11 hours agoprev [–] I read virtual cores on a Processor, got excited for a bit but realized it’s not the same as a soft core processor.I hope FPGAs take off one day and software can compile hyper-optimized processors that do very specialized tasks. reply ta988 11 hours agoparent [–] FPGAs are pretty slow clockwise compared to a cpu, their main advantages is that they can work with many different kind of clocks and somewhat massively parallel. Do you have any specialized task you are thinking about? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This article deals with the management of virtual cores by macOS on Apple's silicon chips, introducing two types of CPU cores: Efficiency (E) cores and Performance (P) cores.",
      "macOS allocates these cores according to the Quality of Service (QoS) settings of an app, determining how the cores can be used to optimize app performance.",
      "It discusses the challenges with using virtual machines (VMs) on Apple silicon hosts, namely the inability to allocate cores effectively and a lack of associated energy-efficiency benefits."
    ],
    "commentSummary": [
      "The article scrutinizes how macOS manages virtual cores on its Apple Silicon and how AMD and ARM implement big-little processing, which suggests a discussion about the tech industry's readiness for heterogeneous computing.",
      "It emphasizes the significant role of Operating System (OS) schedulers in determining core allocation; this could be linked to issues such as gaming performance and Docker problems on macOS.",
      "The article also discusses thread affinities in userspace programs, bookmark and tab management in web browsers, Chrome's use of tab groups, and the capacity for FPGAs in specialized processors, highlighting the efficiency of core architecture."
    ],
    "points": 207,
    "commentCount": 140,
    "retryCount": 0,
    "time": 1698093739
  },
  {
    "id": 37989875,
    "title": "How to run 50% faster without external energy (2020)",
    "originLink": "https://www.science.org/doi/10.1126/sciadv.aay1950",
    "originBody": "ADVERTISEMENT NEWS CAREERS COMMENTARY JOURNALS LOG IN BECOME A MEMBER Current Issue First release papers Archive About Submit manuscript GET OUR E-ALERTS HOME SCIENCE ADVANCES VOL. 6, NO. 13 HOW TO RUN 50% FASTER WITHOUT EXTERNAL ENERGY OPEN ACCESS RESEARCH ARTICLE APPLIED SCIENCES AND ENGINEERING Share on How to run 50% faster without external energy AMANDA SUTRISNO HTTPS://ORCID.ORG/0000-0003-3586-3300 AND DAVID J. BRAUN HTTPS://ORCID.ORG/0000-0002-3672-3847 Authors Info & Affiliations SCIENCE ADVANCES 25 Mar 2020 Vol 6, Issue 13 DOI: 10.1126/sciadv.aay1950 6,291 15 Metrics Total Downloads 6,291 Last 6 Months 1,215 Last 12 Months 2,330 Total Citations 15 Last 6 Months 2 Last 12 Months 4 Abstract INTRODUCTION RESULTS DISCUSSION MATERIALS AND METHODS Acknowledgments Supplementary Material REFERENCES AND NOTES eLetters (0) Information & Authors Metrics & Citations View Options References Media Tables Share Abstract Technological innovations may enable next-generation running shoes to provide unprecedented mobility. But how could a running shoe increase the speed of motion without providing external energy? We found that the top speed of running may be increased more than 50% using a catapult-like exoskeleton device, which does not provide external energy. Our finding uncovers the hidden potential of human performance augmentation via unpowered robotic exoskeletons. Our result may lead to a new-generation of augmentation devices developed for sports, rescue operations, and law enforcement, where humans could benefit from increased speed of motion. SIGN UP FOR THE SCIENCEADVISER NEWSLETTER The latest news, commentary, and research, free to your inbox daily SIGN UP INTRODUCTION The top speed of human running, 12.3 m/s (1), is near half the top speed of cycling, 21.4 m/s (2), despite both motions being human powered. The lower speed of running suggests that humans have untapped energy-supplying capability, which can be used in cycling but cannot be used for faster running. Cycling is faster than running partly because (i) the rolling motion of the wheels prevents collisional energy losses from stepping (3) but also because (ii) wheels can support the weight of the body in place of the legs (4, 5), while (iii) pedals enable the human to supply energy continuously in the air (5) instead of intermittently when the leg is on the ground (6). These three features enable the bicycle to double the top speed of running, despite supplying no external energy and adding weight to the human. The same features may lead to novel augmentation devices that could increase the running speed using untapped human power, without wheels or external energy. Humans have attempted to surpass their natural running capability using springs for at least a century (7, 8). Springs cannot provide external energy but have been shown to reduce the energy cost of walking by 7.2 ± 2.6% (9), running by 4% (10) to 8 ± 1.5% (11), and jumping by 24% (12). However, the current top speed of augmented running, 11 m/s, achieved using a spring prosthesis in series with the legs (13), is 10% below the top speed of natural running. A spring in series with the legs can mitigate collisional energy losses but requires the legs to provide a large force to support the body, unlike the wheel of a bicycle (10, 13, 14). A spring in parallel with the legs can support the body and therefore enable the human to use all the leg force to push against the ground and accelerate (15, 16). However, regardless of whether a spring is used in series or in parallel with the legs, the ground contact time is reduced to 0.1 s at the top speed of natural running (1), which severely limits the amount of energy the legs can supply in high-speed running (6, 17–20). This fundamental limitation necessitates a different use of springs to bypass the top speed of natural running. We conceive an unconventional means of running, which could allow the human to maximize top running speed by supplying energy in the air instead of on the ground (Fig. 1). This may be achieved by augmenting the human with variable stiffness springs attached to the limbs. In the air, the limbs supply energy by simultaneously compressing and increasing the stiffness of the springs (Fig. 1A). Upon touchdown, the stiff springs redirect the vertical motion of the human instead of the legs, while the energy stored in the springs is released to increase the horizontal running speed (Fig. 1B). In the proposed augmented running, (i) the energy supplied by the limbs is no longer limited by the short ground contact time, (ii) the springs support the body instead of the limbs, and (iii) the springs mitigate collision energy losses like the wheel of a bicycle. Therefore, the proposed means of augmented running confers defining features of cycling, which may enable humans to go beyond the top speed of natural running (movie S1). Fig. 1 Augmented running. The augmentation device is a robotic exoskeleton represented by a variable stiffness spring. (A) Swing. The leg is coupled to the spring. As the leg extends, the spring is compressed and the stiffness of the spring is increased. The latter can be achieved by a variable stiffness mechanism, which increases stiffness by decreasing the effective length of the spring [see (28, 30–32), Materials and Methods, and movie S1]. The exoskeleton provides mechanical advantage to the human such that large leg extension, small leg force, and small leg stiffness provide small spring compression, large spring force, and large spring stiffness. (B) Ground contact. The leg is decoupled from the spring and the mechanism that changes stiffness is locked. As the leg flexes, the spring extends while the stiffness of the spring stays constant. (C) Spring-mass model of augmented running. OPEN IN VIEWER RESULTS Building exoskeleton devices (8) and performing human-in-the-loop experimental exploration (9, 21) are the mainstream and state-of-the-art approaches to develop novel human augmentation paradigms, although theoretical investigations may also be useful to uncover the benefits of previously unexplored augmentation methods (22). Simple spring-mass models (18, 19) have been previously used to provide useful theoretical predictions of the biomechanics of natural running (23, 24). These models use a point mass to represent the body and a spring to represent the biological limb, and assume symmetric ground contact while neglecting air resistance in natural running. Here, we use a similarly simple model (Fig. 1C) to explore the theoretical benefits of augmented running. In our model, the spring represents the augmentation device instead of the biological limb, we consider asymmetric ground contact motion, and we assume that air resistance is nonnegligible in high-speed running (17). Our spring-mass model (Fig. 1C) discovers stable augmented running (fig. S2) and provides the following analytical predictions beyond the top speed of natural running (see Materials and Methods): (i) The peak force F and the stiffness k of the spring on the ground increase nonlinearly with the running speed (c is a constant) 𝐹 ∝ 𝑘 ∝ 1 1 + 𝑐 𝑣 − 2 (ii) The ground contact time is inversely proportional to the running speed, while the time available to swing the leg approaches the step duration T at high speeds Δ 𝑡 g ∝ 𝑣 − 1 and Δ 𝑡 s ≈ 𝑇 According to these predictions, (i) surpassing the top speed of natural running requires a spring to provide force and stiffness beyond human limb capability and (ii) the time available for the legs to supply energy in the air approaches the continuous limit of cycling. The model also predicts that the runner may supply energy during 96% of the step time (T = Δtg + Δts) at the top running speed. If this were possible, the speed limit of running due to air resistance would be 97% of the air resistance limit in cycling 22.6 m/s. This prediction assumes the energy supply rate of 18 W/kg for the biological limb in running (25), which is slightly below the estimated energy supply rate of world-class sprint cyclists (26). The theoretical top speed of augmented running is lower than the aforementioned air resistance limit and can be predicted by extending the model to account for the most substantial energy losses in addition to the biological limitation of the limb. Considering the collisional energy losses upon ground contact (27) due to the mass of the spring (Fig. 1C), the kinetic energy required to swing the stance leg with nonnegligible rotational inertia, and the limited stepping frequency of the current world record holder sprinter Usain Bolt (1), the model predicts 20.9 m/s. This speed is 2.4% below the current world record cycling speed (Fig. 2). Fig. 2 Top speeds of human-powered locomotion. World records in natural running (12.3 m/s) (1), running with a spring blade prosthesis (11 m/s) (13), ice-skating (15 m/s) (52), and cycling (21.4 m/s) (fig. S7) (2) and the top speed predicted for augmented running (20.9 m/s). There is a linear empirical relation vmax ∝ ΔtE/T between the world record speeds and the relative time available for each leg to supply energy in running, ice-skating, and cycling. The air resistance limit is given by a cube-root relation vmax ∝ (ΔtE/T)1/3 (see Materials and Methods). This relation is calculated assuming that the energy supply rate of each leg is 18 W/kg (25), which is near to what has been measured for world-class cyclists (26). OPEN IN VIEWER Figure 3 provides a detailed account of augmented running predicted by the model (solid lines) compared to the estimated and measured data from natural running and cycling (dashed lines) (fig. S7) (1, 2, 17). According to these predictions, the augmented running may reach the top speed of natural running 𝑣 max N ≈ 12.3 m/s in 10 steps and may require 150 steps to reach vmax ≈ 20.9 m/s. At the top speed, the time available to supply energy in the air Δts ≈ 533 ms is six times longer than the ground contact time in natural running Δ 𝑡 g N ≈ 90 ms and 1.5 times longer than the swing time in natural running Δ 𝑡 s N ≈ 354 ms, while the ground contact time in augmented running Δtg ≈ 19.3 ms is more than four times shorter than the ground contact time in natural running (Fig. 3B). On the ground, the spring exerts a maximum force of F ≈ 21 kN, which is six times the maximum force exerted by the human FN ≈ 3.6 kN (Fig. 3C), while the stiffness of the spring k ≈ 234 kN/m is 11 times the stiffness of a human leg at the top speed of natural running kN ≈ 21 kN/m (Fig. 3D). The physical requirements in augmented running are beyond the capability of a biological limb but may be achieved using a robotic variable stiffness spring exoskeleton. Fig. 3 Augmented running. (A) Running speed. (B) Swing and stance times. (C) Ground reaction force at touchdown. (D) Spring stiffness during ground contact. The top speed predicted by the model (20.9 m/s, black) is approximately 96% of the air resistance limit (21.9 m/s, blue). The average acceleration of the body is within safely tolerable accelerations (fig. S3). The parameters used to obtain these predictions are taken from the current world record holder sprinter Usain Bolt (table S1). OPEN IN VIEWER DISCUSSION Emerging human augmentation technologies (22, 28, 29) promote active variable stiffness springs, where the stiffness is adjusted using an actuator that requires external energy (30–33). In augmented running (Fig. 2), the variable stiffness spring is an energetically passive device where the stiffness of the spring is adjusted by the human, without using external energy. In addition, the variable stiffness spring enables the human to supply energy when the legs are in the air, which makes the energy supplied by the legs independent of the short ground contact time. In this way, the spring could enable the human to bypass the fundamental physical limitation of natural running (6), despite providing no external energy. The energy supplied by the human per step is the product of the average energy supply rate of the limbs, and the time available to supply energy 𝐸 = 𝐸 ¯ · Δ 𝑡 𝐸 . Assuming that the average energy rate of the limbs 𝐸 ¯ · is maximized by the human to achieve the top speed, the only way to provide more energy is to increase the time to supply energy 𝐸 𝐸 max = Δ 𝑡 𝐸 𝑇 According to Fig. 3B, the proposed augmented running could theoretically enable the human to provide energy 96% of the total step time (black triangles), similar to what is analytically predicted by the spring-mass model (blue line). If that was possible, the time to supply energy in augmented running could be more than the 20% in natural running and 50% in ice-skating and would be close to the continuous limit of 100% in cycling (Fig. 2). In addition to increasing the time available for the human to supply energy, the variable stiffness spring is used as a catapult to release energy faster than the energy supply rate of the biological limb. To make use of the catapult action, an energy-storing element, for example, tendon in animals (16) or spring in robots (34), is first preloaded in the air by an actuator, muscle, or motor, and then used to push against the ground faster than the actuator could alone do. While a typical catapult that uses a fixed stiffness spring may amplify both the power and the force of a limb, it could not change its stiffness as required to redirect vertical motion and accelerate horizontal motion of the human at different speeds (Fig. 3A) (19, 20). Therefore, augmented running necessitates the use of a variable stiffness catapult (Fig. 3D). To predict the top augmented running speed of 20.9 m/s (Figs. 2 and 3), we have assumed that (i) the human can supply energy during the entire swing phase, i.e., 96% of the step; (ii) the energy supply rate of a human, 18 W/kg per leg (25), is comparable to the energy supply rate of world-class cyclists (19 W/kg) (26); and (iii) the spring transfers all the energy supplied by the legs in the air to accelerate the forward motion of the body on the ground. If these assumptions are not met, then the amount of energy provided by the legs will be reduced and the top speed will be lower than 20.9 m/s. However, even if energy is supplied only 60% of the total step time, the reduced top speed of augmented running, 18 m/s, remains 50% above the current top speed of natural running (Fig. 2). To reach the theoretical top speed of 20.9 m/s in Fig. 2, the spring should (i) store 930 J energy and (ii) weigh no more than 1.5 kg and (iii) the stiffness of the spring should reach one order of magnitude beyond the maximum stiffness of the leg in natural running (Fig. 3D). Variable stiffness springs may be designed with a wide stiffness range (31), and carbon fiber–reinforced polymers or air-springs have high energy capacity while being lightweight (35). However, state-of-the-art fixed stiffness running springs made from carbon fiber offer only about 150 J/kg (36), which is an order of magnitude less than what is required to reach the predicted top speed of augmented running. A novel high-energy density variable stiffness spring design will be required to realize high-speed augmented running. Current running exoskeletons use fixed stiffness springs in parallel with the legs to support the body (7) but require the human to supply energy while pushing against the ground, as in natural running (37, 38). The limitation of these exoskeletons, in reducing the metabolic energy cost of running, has been attributed to (i) the energy required to swing the legs with the added mass of the exoskeleton and (ii) the inefficient energy transfer between the human and the exoskeleton. These findings suggested that engineering innovations are required to improve the performance of exoskeletons developed for human augmentation (39). However, even if we hypothesize an ideal massless exoskeleton and consider perfect energy transfer between the human and the exoskeleton, the air resistance speed limit of the human augmented with a fixed stiffness spring remains 65% of the air resistance speed limit in cycling (see Materials and Methods). This is because the human augmented with a fixed stiffness spring could supply energy no more than 30% of the total step time when pushing against the ground as in natural running, which is less than the 96% in the proposed augmented running or the 100% in cycling (Fig. 2, dashed blue line). A fixed stiffness spring in parallel with the legs is similar to a bicycle without pedals; it helps to support the body in the vertical direction but does not help to accelerate the body in the horizontal direction (5). The variable stiffness spring supports the body, but it also provides an equivalent pedaling mechanism as it enables the human to supply energy beyond what is possible in natural running. Historical data (fig. S7) show that the world record average speed in the 100-m sprint has increased 6% in the past 70 years, while the world record average speed in the 500-m speed skating and 200-m track cycling have increased as much as 23% in the same time period. The relatively large increase in skating and cycling speeds has been attributed to engineering advances, as decades of technical innovations were required before clap skates (40) allow the human to go considerably beyond the world record running speed, and racing bicycles (5) allowed the human to double the world record running speed (fig. S7). The development of variable stiffness spring exoskeletons for high-speed augmented running could follow a similar path. MATERIALS AND METHODS In this section, we first present the variable stiffness spring-mass model of augmented running, which takes into account air resistance, collision losses, and the limited power of the biological limb. We use this model to numerically predict the top speed of the augmented running motion. Subsequently, we derive an approximate spring-mass model of running to analytically predict the relations between the running speed, spring stiffness, spring force, and the ground contact time in high-speed running. Next, we provide a stability analysis of the augmented running motion using both of the previously derived models. Last, we derive (i) the air resistance speed limit of augmented running where the human does work in the air, as in cycling, and (ii) the air resistance speed limit of augmented running where the human does work on the ground, as in natural running. Spring-mass model of augmented running The spring-mass model of augmented running is depicted in Fig. 1C and fig. S1. The differential equations governing the flight phase and ground contact phase motions are given by ( 𝑀 + 2 𝑚 ) 𝑥 ¨ = − 𝐹 air , 𝑦 ¨ = − 𝑔 (1) and θ θθ ( 𝑀 + 𝑚 ) ( 𝑙 ¨ − 𝑙 θ · 2 ) = − ( 𝑀 + 𝑚 ) 𝑔 cos θ + 𝑘 ( 𝑙 0 − 𝑙 ) − 𝐹 air sin θ (2) θ θ θθ ( 𝐽 + ( 𝑀 + 𝑚 ) 𝑙 2 ) θ ¨ + 2 ( 𝑀 + 𝑚 ) 𝑙 𝑙 · θ · = ( 𝑀 + 𝑚 ) gl sin θ − 𝐹 air 𝑙 cos θ (3) where (x, y) are the Cartesian coordinates of the body, l is the length of the spring, θ is the rotation angle of the leg and the spring, M is the total mass of the human, m is the mass of the spring attached to one of the legs, J is the rotational inertia of the leg, Fair is the force due to air resistance, k is the stiffness of the spring during the ground contact phase, F is the force exerted by the spring against the ground, and g is the gravitational acceleration. We assume that the spring mass is concentrated at the foot, which is the worst-case mass distribution of the spring. Furthermore, we assume that air resistance is proportional to the squared running speed (17) 𝐹 air = 𝑐 air 𝑥 · 2 (4) where cair is an empirical constant. All parameters in Eqs. 1 to 4 are given in table S1. The transition between the flight phase and the ground contact phase occurs at touchdown θ 𝑦 td = 𝑙 td cos θ td where ltd represents the length of the spring at touchdown, while θtd is the touchdown angle. We assume ideally plastic collision between the foot and the ground; therefore, based on momentum conservation, the velocity of the body changes according to the following relations θ θ θ θ θ θ θ 𝑙 · td + = 𝑥 · td − sin θ td + 𝑦 · td − cos θ td , θ · td + = θ · td − − ( 𝑀 + 𝑚 ) 𝑙 td 2 𝐽 + ( 𝑀 + 𝑚 ) 𝑙 td 2 ( θ · td − + 𝑦 · td − sin θ td 𝑙 td − 𝑥 · td − cos θ td 𝑙 td ) where (·)− and (·)+ denote the pre-impact and post-impact velocities, respectively. We assume that the human does not supply energy to increase the angular velocity of the leg in swing; the angular velocity at touchdown θ θ · td − in the current step is the same as the angular velocity upon takeoff in the previous step. Because the mass of the spring is concentrated at the foot, the impact of the leg with the ground gives the highest energy loss at touchdown (27). The transition between ground contact and flight occurs at the maximum length of the spring due to a hard stop (fig. S1) that prevents extension of the spring 𝑙 to = 𝑙 0 where lto is the length of the spring at takeoff. When the hard stop is reached, a plastic collision takes place and the velocity of the body changes due to momentum conservation θ θ θ θ 𝑥 · to + = ( 1 − 𝑚 𝑀 + 2 𝑚 sin θ to 2 ) 𝑥 · to − − 1 2 𝑚 𝑀 + 2 𝑚 𝑦 · to − sin 2 θ to , 𝑦 · to + = ( 1 − 𝑚 𝑀 + 2 𝑚 cos θ to 2 ) 𝑦 · to − − 1 2 𝑚 𝑀 + 2 𝑚 𝑥 · to − sin 2 θ to The spring-mass model of augmented running accounts for air resistance, the rotational moment of inertia of the leg, the mass of the spring concentrated at the foot, and the collisional energy loses at touchdown and takeoff. These features extend prior spring-mass models of natural running (18, 19, 24, 41–43). Touchdown angle of the human We allow asymmetric ground contact with vertical and forward leaning leg touchdown (Fig. 1B) θθθ θ td ≠ − θ to , θ td ≥ 0 (5) Forward leaning touchdown (θtd > 0) is required in the initial steps when the motion resembles the start of a sprint (44). Forward leaning or vertical leg touchdown can be used to avoid the braking phase (θtd0 (Eq. 5) until a feasible spring compression 1 2 𝑙 0 ≤ Δ 𝑙 td ≤ 𝑙 0 is found. In our simulations, vertical leg touchdown was feasible for high-speed augmented running, including the top speed of natural human running (fig. S6C). On the other hand, the legs had to be tilted forward during the starting steps to ensure feasible leg compression at low speeds (fig. S6B). Spring-mass model of high-speed augmented running Assuming that (i) the effect of air resistance is negligible during the short ground contact phase compared to the effect of air resistance during the substantially longer aerial phase of running, (ii) collisional energy losses are negligible compared to the kinetic energy at touchdown, (iii) the change in kinetic energy of the stance leg is negligible compared to the change of the translational kinetic energy of the body, and (iv) the mass of the spring is negligible compared to the mass of the body, the nonlinear model (Eqs. 2 and 3) reduces to the spring-mass model of natural running (18, 19, 24, 41, 42) 𝑀 Δ 𝑥 ¨ = 𝐹 𝑥 ( Δ 𝑥 , 𝑦 ) = 𝑘 ( 𝑙 0 Δ 𝑥 Δ 𝑥 2 + 𝑦 2 − Δ 𝑥 ) (15) 𝑀 𝑦 ¨ = 𝐹 𝑦 ( Δ 𝑥 , 𝑦 ) = 𝑘 ( 𝑙 0 𝑦 Δ 𝑥 2 + 𝑦 2 − 𝑦 ) − Mg (16) where Δx is the horizontal distance between the body and the foot during ground contact. Equations 15 and 16 have no known analytical solution, and nonlinear approximations have been previously used to facilitate in-depth analysis of these equations when considering natural running (42). In what follows, we present a nonlinear approximation of Eqs. 15 and 16 to investigate the essential physics of high-speed augmented running. First, we assume that the vertical position of the body is approximately constant in high-speed running 𝑦 ( 𝑡 ) ≈ 𝑦 td = const (17) Under this assumption, the forces in Eqs. 15 and 16 simplify to 𝐹 𝑥 ( Δ 𝑥 , 𝑦 ) = 𝐹 𝑥 ( Δ 𝑥 , 𝑦 td ) + 𝑂 ( 𝑦 − 𝑦 td ) (18) 𝐹 𝑦 ( Δ 𝑥 , 𝑦 ) = 𝐹 𝑦 ( Δ 𝑥 , 𝑦 td ) + 𝑂 ( 𝑦 − 𝑦 td ) (19) Next, we apply a first-order Fourier series approximation of Eqs. 18 and 19, subject to three conditions (i) The condition of vertical leg touchdown (Eq. 6) Δ 𝑥 ( 0 ) = 0 (20) (ii) The conditions at touchdown and takeoff 𝐹 𝑥 ( 0 , 𝑦 td ) = 0 , 𝐹 𝑦 ( 0 , 𝑦 td ) = 𝑘 ( 𝑙 0 − 𝑦 td ) − Mg , 𝐹 𝑥 ( Δ 𝑥 max , 𝑦 to ) = 0 , 𝐹 𝑦 ( Δ 𝑥 max , 𝑦 to ) = − Mg (21) (iii) The energy balance during ground contact 𝐸 kx , to − 𝐸 kx , td = ∫ 0 Δ 𝑥 max 𝐹 𝑥 ( Δ 𝑥 , 𝑦 td ) 𝑑 Δ 𝑥 = 𝐸 spr (22) The last condition is obtained from Eq. 11 by assuming that the energy loss during ground contact is negligible. This assumption is consistent with Eqs. 15 and 16. Using the first-order Fourier series approximation of Fx(Δx, ytd) and Fy(Δx, ytd), together with Eqs. 20 to 22, we obtain an approximate spring-mass model of augmented running π π 𝑀 Δ 𝑥 ¨ = 𝐹 ̂ 𝑥 ( Δ 𝑥 ) ≈ π 𝐸 spr 2 Δ 𝑥 max sin ( π Δ 𝑥 Δ 𝑥 max ) (23) π 𝑀 𝑦 ¨ = 𝐹 ̂ 𝑦 ( Δ 𝑥 ) ≈ 𝑘 ( 𝑙 0 − 𝑦 td ) cos ( π 2 Δ 𝑥 Δ 𝑥 max ) − Mg (24) According to fig. S4, the relative error between the forces in Eqs. 18, 19, 23, and 24 is no more than 10% beyond the top speed of natural running. Next, we use the approximate model (Eqs. 23 and 24) to derive scaling laws for high-speed augmented running. Spring stiffness and spring compression The ground phase stiffness is given by Eq. 13 𝑘 = 2 𝐸 spr Δ 𝑙 td 2 (25) where Eq. 14 defines the spring compression at touchdown Δltd. Using Eq. 17, Eq. 14 reduces to 𝐸 ky , td − 𝐸 ky , to ≈ 1 2 𝑀 𝑦 · ( 0 ) 2 − 1 2 𝑀 𝑦 · ( Δ 𝑥 max ) 2 = 0 (26) To derive the analytical expression of Eq. 26 as a function of Δltd, we will derive 𝑦 · ( Δ 𝑥 ) using Eqs. 23 and 24. First, we integrate Eq. 23 to obtain the relation between the horizontal velocity and the horizontal position π Δ 𝑥 · ( Δ 𝑥 ) = 𝑥 · ( Δ 𝑥 ) ≈ 𝑥 · td [ 1 + 2 𝐸 spr 𝑀 𝑥 · td 2 sin ( π 2 Δ 𝑥 Δ 𝑥 max ) 2 ] 1 2 (27) Next, we use Eq. 27 to integrate Eq. 24 and obtain the relation between the vertical velocity and the horizontal position π π 𝑦 · ( Δ 𝑥 max ) ≈ 𝑦 · td + 2 1 2 𝑘 Δ 𝑙 td Δ 𝑥 max π 𝑀 1 2 𝐸 spr 1 2 sinh − 1 [ ( 2 𝐸 spr 𝑀 𝑥 · td 2 ) 1 2 ] − 2 1 2 𝑀 1 2 𝑔 Δ 𝑥 max π 𝐸 spr 1 2 sn − 1 [ 1− 2 𝐸 spr 𝑀 𝑥 · td 2 ] (28) where sn(*∣*) is the Jacobi elliptic sine function Δ 𝑥 max ≈ ( 2 𝑙 0 Δ 𝑙 td − Δ 𝑙 td 2 ) 1 2 (29) is the horizontal position of the center of mass with respect to the foot at takeoff 𝑦 · td 2 = 2 𝐸 𝑦 𝑀 − 2 𝑔 ( 𝑙 0 − Δ 𝑙 td ) (30) is the vertical velocity at touchdown, while Ey is the total energy of the vertical motion. Using Eqs. 25 to 30, we obtain the approximate analytical expression of Eq. 26 π 𝐹 ( Δ 𝑙 td , 𝑥 · td ) = ( 2 𝐸 𝑦 𝑀 − 2 𝑔 ( 𝑙 0 − Δ 𝑙 td ) ) 1 2 − ( 2 𝐸 spr ) 1 2 ( 2 𝑙 0 − Δ 𝑙 td ) 1 2 π ( 𝑀 Δ 𝑙 td ) 1 2 sinh − 1 [ ( 2 𝐸 spr 𝑀 𝑥 · td 2 ) 1 2 ] + 𝑔 Δ 𝑙 td 1 2 ( 2 𝑙 0 − Δ 𝑙 td ) 1 2 𝑥 · td sn − 1 [ 1− 2 𝐸 spr 𝑀 𝑥 · td 2 ] = 0 (31) The approximate spring compression at touchdown Δ 𝑙 td = Δ 𝑙 td ( 𝑥 · td ) is the solution of Eq. 31. Scaling laws We derived closed-form relations between (i) the stiffness of the spring during ground contact k, (ii) the force of the spring at touchdown F, (iii) the ground contact time Δtg, and the forward speed at touchdown 𝑣 = 𝑥 · td . We assume that the horizontal kinetic energy of the body is much greater than the energy stored in the spring in high-speed running 𝑒 = 2 𝐸 spr Mv 2 ≈ 𝑒 min = 2 𝐸 spr Mv max 2 ≪ 1 (32) Using Eq. 32, we transform Eq. 31 into ( Δ 𝑙 td 𝑙 0 ) 2 − ( 𝑏 0 + 𝑏 1 𝑒 ) ( Δ 𝑙 td 𝑙 0 ) − 𝑐 1 𝑒 = 𝑂 ( 𝑒 Δ 𝑙 td 3 𝑙 0 3 ) (33) where b0, b1, and c1 are constants dependent on the top speed. We assume that the third-order term in Eq. 33 is negligible because the deformation of the spring Δltd is smaller than the length of the leg 1 2 𝑙 0 ≤ 𝑦 td = 𝑙 0 − Δ 𝑙 td ≤ 𝑙 0 ⇒ 0 ≤ Δ 𝑙 td 𝑙 0 ≤ 1 2 (34) and because Δltd reduces as the running speed increases (fig. S6). Consequently, Eq. 33 can be analytically solved to predict the largest deformation of the spring at touchdown Δ 𝑙 td ( 𝑒 ) 𝑙 0 ≈ ( 𝑏 0 + 𝑏 1 𝑒 ) + ( 𝑏 0 + 𝑏 1 𝑒 ) 2 + 4 𝑐 1 𝑒 2 (35) Substituting Eq. 35 into Eq. 25, we obtain the lowest stiffness that satisfies Eq. 31 and the maximum ground contact time when running at speed 𝑣 = 𝑥 · td . Near to saturation e ≈ emin, the compression of the spring obeys the following approximate relation Δ 𝑙 td ( 𝑒 ) 𝑙 0 ≈ Δ 𝑙 td ( 𝑒 min ) 𝑙 0 + 𝑑 de ( Δ 𝑙 td ( 𝑒 ) 𝑙 0 )𝑒 min ( 𝑒 − 𝑒 min ) (36) Using Eqs. 35 and 36, we obtain the scaling laws for high-speed augmented running (i) The stiffness of the spring (Eq. 25) is given by 𝑘 ∝ Δ 𝑙 td ( 𝑒 min ) Δ 𝑙 td ( 𝑒 ) ∝ 1 1 + cv − 2 (37) where αα 𝑐 = 𝑣 max 2 α ( 1 − α ) − 1 and α α = 𝑒 min ( Δ 𝑙 td ( 𝑒 min ) 𝑙 0 ) − 1 𝑑 de ( Δ 𝑙 td ( 𝑒 ) 𝑙 0 )𝑒 min = 2 𝐸 spr Mv max 2 [ Δ 𝑙 td 𝑙 0 ( 2 𝐸 spr Mv max 2 ) ] − 1 𝑑 de ( Δ 𝑙 td ( 𝑒 ) 𝑙 0 )2 𝐸 spr Mv max 2 (ii) The force of the spring at touchdown F = kΔltd is given by 𝐹 ∝ Δ 𝑙 td ( 𝑒 min ) Δ 𝑙 td ( 𝑒 ) ∝ 1 1 + cv − 2 (38) (iii) The ground contact time is given by Δ 𝑡 𝑔 ∝ ( 𝑒 𝑒 min ) 1 2 ∝ 𝑣 − 1 (39) To derive Eq. 39, we computed the ground contact time by integrating Eq. 27 π Δ 𝑡 g = 2 1 2 𝑀 1 2 Δ 𝑥 max π 𝐸 spr 1 2 𝑒 1 2 sn − 1 ( 1− 𝑒 ) (40) and assuming Eqs. 29, 32, 36, and 40, together with e ≪ 1 (Eq. 32), such that sn−1(1∣ − e) ≈ π/2. Stability of the augmented running motion The stability of the augmented running motion is characterized by a one-dimensional Poincaré return map (15, 47) of the forward velocity at subsequent touchdowns 𝑣 𝑛 = 𝑥 · td , 𝑛 and 𝑣 𝑛 + 1 = 𝑥 · td , 𝑛 + 1 𝑣 𝑛 + 1 = 𝑃 ( 𝑣 𝑛 ) (41) The existence of a fixed-point vmax = P(vmax) implies the possibility of augmented running. The stability of the fixed point is characterized by the linear approximation of Eq. 41λ ( 𝑣 𝑛 + 1 − 𝑣 max ) = ∂ 𝑃 ∂ 𝑣𝑣 = 𝑣 max ⏟ λ ( 𝑣 𝑛 − 𝑣 max ) (42) which implies locally asymptotic stability if the magnitude of the eigenvalue is less than unity, ∣λ∣<1. Local stability of the fixed point implies local orbital stability of augmented running (15, 47). For the simplified spring-mass model, the composition of the swing and ground contact phase maps provides the relation between the vertical position and the horizontal velocity at subsequent touchdowns 𝑃 sg = 𝑃 s ∘ 𝑃 𝑔 : ( 𝑦 td , 𝑛 , 𝑣 𝑛 ) → ( 𝑦 td , 𝑛 + 1 , 𝑣 𝑛 + 1 ) (43) We reduced this two-dimensional map to a one-dimensional map using the analytical relation between the spring compression and the horizontal velocity at touchdowns ℱ(Δltd, v) = ℱ(l0 − ytd, v) = 0 (Eq. 31) 𝑃 = 𝑃 sg ∣ 𝐹 ( 𝑙 0 − 𝑦 td , 𝑛 , 𝑣 𝑛 ) = 𝐹 ( 𝑙 0 − 𝑦 td , 𝑛 + 1 , 𝑣 𝑛 + 1 ) = 0 : 𝑣 𝑛 → 𝑣 𝑛 + 1 This one-dimensional map is represented by the following equation 𝐺 ( 𝑣 𝑛 , 𝑣 𝑛 + 1 ) = 𝐺 ( 𝑣 max , 𝑣 max ) + ∂ 𝐺 ∂ 𝑣 𝑛𝑣 𝑛 = 𝑣 𝑛 + 1 = 𝑣 max ( 𝑣 𝑛 − 𝑣 max ) + ∂ 𝐺 ∂ 𝑣 𝑛 + 1𝑣 𝑛 = 𝑣 𝑛 + 1 = 𝑣 max ( 𝑣 𝑛 + 1 − 𝑣 max ) + 𝑂 [ ( 𝑣 𝑛 − 𝑣 max ) 2 , ( 𝑣 𝑛 + 1 − 𝑣 max ) 2 ] = 0 Using this equation, we define λ λ = − ∂ 𝐺 ∂ 𝑣 𝑛𝑣 𝑛 = 𝑣 𝑛 + 1 = 𝑣 max ∂ 𝐺 ∂ 𝑣 𝑛 + 1𝑣 𝑛 = 𝑣 𝑛 + 1 = 𝑣 max Figure S5 summarizes the result of our stability analysis. The figure shows the set of feasible perturbations that would lead to orbitally stable augmented running, i.e., ∣λ∣<1. Air resistance limit of the top speed in augmented running The upper limit of the top running speed occurs when the average energy supply rate of the human equals the average rate of energy dissipation due to air resistance 𝐸 ¯ · hum = 𝑐 air 𝑣 max 3 (44) The average energy supply rate of the human is 𝐸 ¯ · hum = 2 𝐸 ¯ · leg Δ 𝑡 𝐸 𝑇 (45) where 𝐸 ¯ · leg = 𝐸 leg / Δ 𝑡 s is the average energy supply rate of one leg, while ΔtE is the time used by the leg to provide energy during the total step time T. According to Eqs. 44 and 45, the air resistance limit of the top speed of human-powered motion depends on the time available for the legs to supply energy (Fig. 2, dashed blue line) 𝑣 max = ( 2 𝐸 ¯ · leg 𝑐 air ) 1 3 ( Δ 𝑡 𝐸 𝑇 ) 1 3 (46) The time available for the legs to supply energy in augmented running is the time to swing the leg Δ 𝑡 𝐸 𝑇 = Δ 𝑡 𝑠 𝑇 = 𝑇 − Δ 𝑡 𝑔 𝑇 = 1 − 1 2 𝑓 Δ 𝑡 g (47) where f denotes the stepping frequency. The ground contact time is inversely proportional to the forward speed and is upper bounded by Δ 𝑡 g ≈ 𝑥 to − 𝑥 td 𝑣 max ≤ Δ 𝑥 max 𝑣 max ≤ 3 2 𝑙 0 𝑣 max (48) because Eqs. 5 and 34 imply 0 ≤ Δ 𝑥 max 2 ≤ 𝑙 0 2 − 𝑦 min 2 ⇒ 0 ≤ Δ 𝑥 max 𝑙 0 ≤ 3 2 Consequently, Eqs. 47 and 48 lead to Δ 𝑡 𝐸 𝑇 ≥ 1 − 3 4 𝑙 0 𝑓 𝑣 max (49) According to Eqs. 44, 45, and 49, the air resistance limit of augmented running can be approximated by the solution of the following equation 2 𝐸 ¯ · leg ( 1 − 3 4 𝑙 0 𝑓 𝑣 max ) = 𝑐 air 𝑣 max 3 (50) The approximate solution of Eq. 50 is given by 𝑣 max run ≈ ( 2 𝐸 ¯ · leg 𝑐 air ) 1 3 − 3 12 𝑙 0 𝑓 (51) The difference between Eq. 51 and the exact solution of Eq. 50 is 0.1% for the parameters in table S1. Following the same derivation, the air resistance limit in cycling is given by 𝑣 max cyc ≈ ( 𝐸 ¯ · leg 1 2 𝑐 air ) 1 3 (52) where we assume that the air resistance coefficient in cycling is approximately half the air resistance coefficient in running (48), and the legs only supply energy during extension and do not supply energy during the flexion phase of pedaling (49). On the basis of Eqs. 51 and 52, we conclude that the air resistance limit of the top speed in augmented running is near to the air resistance limit of the top speed in cycling 𝑣 max run 𝑣 max cyc ≈ 1 − 3 12 ( 𝑙 0 𝑓 max N 𝑣 max cyc ) ( 𝑓 𝑓 max N ) ≥ 1 − 3 12 ( 𝑙 0 𝑓 max N 𝑣 max cyc ) ≈ 0.97 (53) Last, we derive the air resistance limit of augmented running, assuming that the human supplies energy on the ground as in natural running, while the legs are augmented with fixed stiffness springs. In that case, the energy for the running motion is supplied on the ground, and therefore, the time available for the legs to supply energy is the ground contact time. To obtain the upper bound of the ground contact time, we permit running with negative touchdown angles, without assuming that such running technique would impede the motion of the runner. This assumption doubles the maximum distance moved by the body during the ground contact phase of the running motion and consequently doubles the ground contact time compared to running augmented with the proposed variable stiffness spring Δ 𝑡 𝐸 𝑇 = Δ 𝑡 𝑔 𝑇 = 1 2 𝑓 Δ 𝑡 g = 1 2 𝑓 2 Δ 𝑥 𝑣 max ≤ 3 2 𝑙 0 𝑓 𝑣 max (54) According to Eqs. 46 and 54, the air resistance limit of natural running augmented with a fixed stiffness spring is given by 𝑣 max FS run = ( 3 2 𝑙 0 𝑓 ) 1 4 ( 2 𝐸 ¯ · leg 𝑐 air ) 1 4 (55) On the basis of Eqs. 52 and 55, we conclude that the air resistance limit of the top speed when the human does work on the ground cannot exceed 65% of the air resistance limit in cycling 𝑣 max FS run 𝑣 max cyc = ( 3 2 𝑙 0 𝑓 max N 𝑣 max cyc ) 1 4 ( 𝑓 𝑓 max N ) 1 4 ≤ ( 3 2 𝑙 0 𝑓 max N 𝑣 max cyc ) 1 4 ≈ 0.65 (56) The reduced air resistance limit (Eq. 56) compared to the air resistance limit of the proposed augmented running (Eq. 53) is because the maximal duration for the legs to supply energy on the ground is less than 30% of the total step time ΔtE/T ≤ 0.3 (Eq. 54) compared to the more than 96%, ΔtE/T ≥ 0.96 (Eq. 49), in the proposed augmented running. Acknowledgments Funding: The authors received institutional support from Vanderbilt University in support of this research. Author contributions: D.J.B. and A.S. conceived the method, developed the theory, derived the supporting equations, and wrote the manuscript. A.S. performed the numerical simulations. D.J.B. reviewed the manuscript. Both authors approved the final manuscript. Competing interests: D.J.B. and A.S. are inventors on a pending patent related to this work filed by Vanderbilt University (no. 62/950,641, filed on 19 December 2019). The authors declare no other competing interests. Data and materials availability: All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials. Supplementary Material Summary Fig. S1. Spring-mass model of augmented running. Fig. S2. Stable augmented running. Fig. S3. Acceleration and ground contact time. Fig. S4. Approximate spring force. Fig. S5. Stability of augmented running. Fig. S6. Motion of the body in augmented running. Fig. S7. Average world record speed. Table S1. Estimated physical parameters of the 100-m world record holder sprinter Usain Bolt. Movie S1. Augmented running. References (50–53) Resources File (aay1950_movie_s1.mp4) DOWNLOAD 9.00 MB File (aay1950_sm.pdf) DOWNLOAD 2.92 MB REFERENCES AND NOTES 1 M. J. D. Taylor, R. Beneke, Spring mass characteristics of the fastest men on Earth. Int. J. Sports Med. 33, 667–670 (2012). CROSSREF PUBMED ISI GOOGLE SCHOLAR 2 UCI Track Cycling World Cup, Men’s 200 m qualifying (2013). Accessed on 23 August 2019; https://www.uci.org/docs/default-source/about--discipline/about-track-cycling/men-elite-world-records.pdf?sfvrsn=244fc916_28. GOOGLE SCHOLAR 3 A. Ruina, J. E. A. Bertram, M. Srinivasan, A collisional model of the energetic cost of support work qualitatively explains leg sequencing in walking and galloping, pseudo-elastic leg behavior in running and the walk-to-run transition. J. Theor. Biol. 237, 170–192 (2005). GO TO REFERENCE CROSSREF PUBMED ISI GOOGLE SCHOLAR 4 R. Kram, C. R. Taylor, Energetics of running: A new perspective. Nature 346, 265–267 (1990). GO TO REFERENCE CROSSREF PUBMED ISI GOOGLE SCHOLAR 5 A. E. Minetti, J. Pinkerton, P. Zamparo, From bipedalism to bicyclism: Evolution in energetics and biomechanics of historic bicycles. Proc. R. Soc. Lond. B 268, 1351–1360 (2001). 6 P. G. Weyand, R. F. Sandell, D. N. Prime, M. W. Bundle, The biological limits to running speed are imposed from the ground up. J. Appl. Physiol. 108, 950–961 (2010). 7 N. Yagn, Apparatus for facilitating walking, running, and jumping, U.S. Patent 420179 (1890). 8 A. M. Dollar, H. Herr, Lower extremity exoskeletons and active orthoses: Challenges and state-of-the-art. IEEE T. Robot. 24, 144–158 (2008). 9 S. H. Collins, M. B. Wiggin, G. S. Sawicki, Reducing the energy cost of human walking using an unpowered exoskeleton. Nature 522, 212–215 (2015). 10 W. Hoogkamer, S. Kipp, J. H. Frank, E. M. Farina, G. Luo, R. Kram, A comparison of the energetic cost of running in marathon racing shoes. Sports Med. 48, 1009–1019 (2018). 11 R. Nasiri, A. Ahmadi, M. N. Ahmadabadi, Reducing the energy cost of human running using an unpowered exoskeleton. IEEE T. Neur. Sys. Reh. 26, 2026–2032 (2018). 12 A. M. Grabowski, H. M. Herr, Leg exoskeleton reduces the metabolic cost of human hopping. J. Appl. Physiol. 107, 670–678 (2009). 13 P. G. Weyand, M. W. Bundle, C. P. McGowan, A. Grabowski, M. B. Brown, R. Kram, H. Herr, The fastest runner on artificial legs: Different limbs, similar function? J. Appl. Physiol. 107, 903–911 (2009). 14 P. G. Weyand, D. B. Sternlight, M. J. Bellizzi, S. Wright, Faster top running speeds are achieved with greater ground forces not more rapid leg movements. J. Appl. Physiol. 89, 1991–1999 (2000). 15 P. Holmes, R. J. Full, D. Koditschek, J. Gückenheimer, The dynamics of legged locomotion: Models, analyses, and challenges. SIAM Rev. 48, 207–304 (2006). 16 M. Ilton, M. S. Bhamla, X. Ma, S. M. Cox, L. L. Fitchett, Y. Kim, J.-s. Koh, D. Krishnamurthy, C.-Y. Kuo, F. Z. Temel, A. J. Crosby, M. Prakash, G. P. Sutton, R. J. Wood, E. Azizi, S. Bergbreiter, S. N. Patek, The principles of cascading power limits in small, fast biological and engineered systems. Science 360, eaao1082 (2018). 17 A. V. Hill, The air-resistance to a runner. Proc. R. Soc. Lond. B 102, 380–385 (1928). 18 R. Blickhan, The spring-mass model for running and hopping. J. Biomech. 22, 1217–1227 (1989). 19 T. A. McMahon, G. C. Cheng, The mechanics of running: How does stiffness couple with speed? J. Biomech. 23, 65–78 (1990). 20 A. Arampatzis, G.-P. Brüggemann, V. Metzler, The effect of speed on leg stiffness and joint kinetics in human running. J. Biomech. 32, 1349–1353 (1999). 21 J. Zhang, P. Fiers, K. A. Witte, R. W. Jackson, K. L. Poggensee, C. G. Atkeson, S. H. Collins, Human-in-the-loop optimization of exoskeleton assistance during walking. Science 356, 1280–1284 (2017). 22 A. Sutrisno, D. J. Braun, Enhancing mobility with quasi-passive variable stiffness exoskeletons. IEEE T. Neur. Sys. Reh. 27, 487–496 (2019). 23 W. J. Schwind, D. E. Koditschek, Approximating the stance map of a 2-DOF monoped runner. J. Nonlinear Sci. 10, 533–568 (2000). 24 H. Geyer, A. Seyfarth, R. Blickhan, Compliant leg behavior explains basic dynamic of walking and running. Proc. R. Soc. B 273, 2861–2867 (2006). 25 J.-B. Morin, M. Bourdin, P. Edouard, N. Peyrot, P. Samozino, J.-R. Lacour, Mechanical determinants of 100-m sprint running performance. Eur. J. Appl. Physiol. 112, 3921–3930 (2012). 26 S. Dorel, C. A. Hautier, O. Rambaud, D. Rouffet, E. Van Praagh, J.-R. Lacour, M. Bourdin, Torque and power-velocity relationship in cycling: Relevance to track sprint performance in world-class cyclists. Int. J. Sports Med. 26, 739–746 (2005). 27 M. Garcia, A. Chatterjee, A. Ruina, M. Coleman, The simplest walking model: Stability, complexity, and scaling. J. Biomech. Eng. 120, 281–288 (1998). 28 D. J. Braun, V. Chalvet, T.-H. Chong, S. S. Apte, N. Hogan, Variable stiffness spring actuators for low-energy-cost human augmentation. IEEE T. Robot. 35, 1435–1449 (2019). 29 E. M. Glanzer, P. G. Adamczyk, Design and validation of a semi-active variable stiffness foot prosthesis. IEEE T. Neur. Reh. 26, 2351–2359 (2018). 30 T. Sugar, K. Hollander, Adjustable stiffness Jack-Spring actuator, U.S. Patent 7992849B2 (2011). 31 V. Chalvet, D. J. Braun, Criterion for the design of low-power variable stiffness mechanisms. IEEE T. Robot. 33, 1002–1010 (2017). 32 D. J. Braun, V. Chalvet, A. Dahiya, Positive–negative stiffness actuators. IEEE T. Robot. 35, 162–173 (2019). 33 H. F. Lau, A. Sutrisno, T. H. Chong, D. J. Braun, Stiffness modulator: A novel actuator for human augmentation, in 2018 IEEE International Conference on Robotics and Automation (ICRA) (IEEE, 2018), pp. 7742–7748. 34 S. Collins, A. Ruina, R. Tedrake, M. Wisse, Efficient bipedal robots based on passive-dynamic walkers. Science 307, 1082–1085 (2005). 35 S.-Y. Fu, B. Lauke, E. Mäder, C.-Y. Yue, X. Hu, Tensile properties of short-glass-fiber- and short-carbon-fiber-reinforced polypropylene composites. Compos. Part A Appl. Sci. Manuf. 31, 1117–1125 (2000). 36 G.-P. Brüggemann, A. Arampatzis, F. Emrich, W. Potthast, Biomechanics of double transtibial amputee sprinting using dedicated sprinting prosthesis. Sports Technol. 1, 220–227 (2008). 37 G. Elliot, G. S. Sawicki, A. Marecki, H. Herr, The biomechanics and energetics of human running using an elastic knee exoskeleton, in 2013 IEEE 13th International Conference on Rehabilitation Robotics (ICORR) (IEEE, 2013), pp. 1–6. 38 M. S. Cherry, S. Kota, D. P. Ferris, Running with an elastic lower limb exoskeleton. J. Appl. Biomech. 32, 269–277 (2016). 39 J. L. Pons, Wearable Robots: Biomechatronic Exoskeletons (John Wiley & Sons, 2008). 40 L. Li, How can sport biomechanics contribute to the advance of world record and best athletic performance. Meas. Phys. Ed. Exerc. Sci. 16, 194–202 (2012). 41 A. Seyfarth, H. Geyer, M. Günther, R. Blickhan, A movement criterion for running. J. Biomech. 35, 649–655 (2002). 42 H. Geyer, A. Seyfarth, R. Blickhan, Spring-mass running: Simple approximate solution and application to gait stability. J. Theor. Biol. 232, 315–328 (2005). 43 M. Srinivasan, A. Ruina, Computer optimization of a minimal biped model discovers walking and running. Nature 439, 72–75 (2006). 44 P. E. di Prampero, S. Fusi, L. Sepulcri, J. B. Morin, A. Belli, G. Antonutto, Sprint running: A new energetic approach. J. Exp. Biol. 208, 2809–2816 (2005). 45 K. P. Clark, P. G. Weyand, Are running speeds maximized with simple-spring stance mechanics? J. Appl. Physiol. 117, 604–615 (2014). 46 S. H. Patterson, Bicycle gear shifting method and apparatus, U.S. Patent 4900291 (1990). 47 J. Gückenheimer, P. Holmes, Nonlinear Oscillations, Dynamical Systems and Bifurcation of Vector Fields (Springer-Verlag, 1983). 48 C. Capelli, F. Schena, P. Zamparo, A. D. Monte, M. Faina, P. E. di Prampero, Energetics of best performances in track cycling. Med. Sci. Sports Exerc. 30, 614–624 (1998). 49 R. P. Patterson, M. I. Moreno, Bicycle pedalling forces as a function of pedalling rate and power output. Med. Sci. Sports. Exerc. 22, 512–516 (1990). 50 C. E. Clauser, J. T. McConville, J. W. Young, Weight, volume, and center of mass of segments of the human body (Report AD-170 622, Wright-Patterson Air Force Base, 1969). 51 R. V. Brulee, Engineering the Space Age: A Rocket Scientist Remembers (Air Univ. Press, 2008). 52 Speed-skating world records, Men’s 500 m (2015). Accessed on 23 August 2019; . 53 R. Hymans, I. Matrahazi, Progression of IAAF world records (2015). Accessed on 23 August 2019; . SHOW ALL REFERENCES (0) eLetters eLetters is a forum for ongoing peer review. eLetters are not edited, proofread, or indexed, but they are screened. eLetters should provide substantive and scholarly commentary on the article. Embedded figures cannot be submitted, and we discourage the use of figures within eLetters in general. If a figure is essential, please include a link to the figure within the text of the eLetter. Please read our Terms of Service before submitting an eLetter. LOG IN TO SUBMIT A RESPONSE No eLetters have been published for this article yet. Recommended articles from TrendMD Improving the energy economy of human running with powered and unpowered ankle exoskeleton assistance Kirby A. Witte et al., Science Robotics, 2020 Magnetomicrometry C. R. Taylor et al., Science Robotics, 2021 Topological liquid diode Jiaqian Li et al., Sci Adv, 2017 A wearable textile-based pneumatic energy harvesting system for assistive robotics Rachel A. Shveda et al., Sci Adv, 2022 How adaptation, training, and customization contribute to benefits from exoskeleton assistance Katherine L. Poggensee et al., Science Robotics, 2021 Democratizing interactive, immersive experiences for science education with WebXR Fabio Cortés Rodríguez et al., Nature Computational Science, 2021 3D direct printing of mechanical and biocompatible hydrogel meta-structures Lei Zhang et al., Bioactive Materials, 2022 Detection of quantitative trait loci from RNA-seq data with or without genotypes using BaseQTL Elena Vigorito et al., Nature Computational Science, 2021 Rewards, risks and responsible deployment of artificial intelligence in water systems Catherine E. Richards et al., Nature Water, 2023 A Hybrid Power System for a Permanent Colony on Mars Daniel Vázquez Pombo, Selections from Space: Science & Technology, 2021 Powered by CURRENT ISSUE From green to red: Urban heat stress drives leaf color evolution BY YUYA FUKANO WATARU YAMORI ET AL. CHEK2 signaling is the key regulator of oocyte survival after chemotherapy BY CHIHIRO EMORI ZACHARY BOUCHER ET AL. Genetic adaptations of sea anemone to hydrothermal environment BY YANG ZHOU HELU LIU ET AL. TABLE OF CONTENTS ADVERTISEMENT Sign up for ScienceAdviser Subscribe to ScienceAdviser to get the latest news, commentary, and research, free to your inbox daily. SUBSCRIBE LATEST NEWS SCIENCEINSIDER24 OCT 2023 Prominent journal editor fired for endorsing satirical article about Israel-Hamas conflict SCIENCEINSIDER23 OCT 2023 U.S. urges DNA synthesis firms to ramp up screening for biosecurity threats SCIENCEINSIDER23 OCT 2023 First detailed U.S. scientific integrity draft policies get mixed responses NEWS23 OCT 2023 Mice thrive at 6700 meters up—higher than any mammals were thought able to live SCIENCEINSIDER20 OCT 2023 Women leaders at six top research universities urge more diversity in semiconductor workforce NEWS19 OCT 2023 When birds gorge on cicadas, caterpillars go unchecked and chomp their way through oak forests ADVERTISEMENT RECOMMENDED RESEARCH ARTICLEMAY 2020 Chemotaxis strategies of bacteria with multiple run modes PERSPECTIVESSEPTEMBER 2005 Harvesting Energy by Improving the Economy of Human Walking RESEARCH ARTICLEMARCH 2020 Improving the energy economy of human running with powered and unpowered ankle exoskeleton assistance 16 MAR 2005BY JOHN BOHANNON Vampires on the Run ADVERTISEMENT View full textDownload PDF Skip slideshow NEWS All News ScienceInsider News Features Subscribe to News from Science News from Science FAQ About News from Science CAREERS Careers Articles Find Jobs Employer Hubs COMMENTARY Opinion Analysis Blogs JOURNALS Science Science Advances Science Immunology Science Robotics Science Signaling Science Translational Medicine Science Partner Journals AUTHORS & REVIEWERS Information for Authors Information for Reviewers LIBRARIANS Manage Your Institutional Subscription Library Admin Portal Request a Quote Librarian FAQs ADVERTISERS Advertising Kits Custom Publishing Info Post a Job RELATED SITES AAAS.org AAAS Communities EurekAlert! Science in the Classroom ABOUT US Leadership Work at AAAS Prizes and Awards HELP FAQs Access and Subscriptions Order a Single Issue Reprints and Permissions TOC Alerts and RSS Feeds Contact Us FOLLOW US GET OUR NEWSLETTER © 2023 American Association for the Advancement of Science. All rights reserved. AAAS is a partner of HINARI, AGORA, OARE, CHORUS, CLOCKSS, CrossRef and COUNTER. Science Advances eISSN 2375-2548. Terms of Service Privacy Policy Accessibility Reference #1",
    "commentLink": "https://news.ycombinator.com/item?id=37989875",
    "commentBody": "How to run 50% faster without external energy (2020)Hacker NewspastloginHow to run 50% faster without external energy (2020) (science.org) 207 points by beefman 15 hours ago| hidepastfavorite152 comments holri 3 hours agoMy father built a prototype of such a device 20 years ago. He abandoned the project after trying the prototype, because it accelerated dramatically and he could not brake. He jumped sideways into the gutter and was really scared.My personal opinion is that the bicycle is already invented and its excellent energy efficiency is hard to beat. reply karmakurtisaani 1 hour agoparentThose springs look like a great way to get rid of any unnecessary teeth. Can&#x27;t achieve that with a bicycle. reply tiffanyh 14 hours agoprevNike Vaporfly.I&#x27;m surprised it wasn&#x27;t mentioned that 2 recording breaking marathon runs were by athletes wearing the Nike Vaporfly shoe.The shoe was ultimately banned due to the giving too much \"bounce\" (free energy) to the runners.https:&#x2F;&#x2F;www.reuters.com&#x2F;article&#x2F;us-athletics-shoe&#x2F;nike-proto... reply mikestew 14 hours agoparentMmmm, not quite. The ones you and I can buy have a single plate, and stack height of 36mm. The ban was for shoes (like the VaporFly prototype) with >40mm stack height and&#x2F;or multiple plates. Not that this article clears the matter a whole lot, but there is more information (sorry, couldn&#x27;t find a succinct article on the topic): https:&#x2F;&#x2F;www.cbsnews.com&#x2F;news&#x2F;nike-vaporfly-running-sneaker-n...I&#x27;ve used them (as a ~3:00 marathoner). They probably are good for a few minutes off your time. But what I noticed most was that the next day I said to my wife, \"I don&#x27;t think I ran hard enough.\" Oh, I ran hard enough, but the shoes do so much better at keeping the legs from getting trashed. Normally, I&#x27;d take the day off the day after a marathon. Instead, I said, \"screw it, I&#x27;m going for a short run.\"And the VaporFly has little to do with this proposition, other than using a spring-like device. reply moron4hire 10 hours agorootparentI wonder if that would do anything for my plantar fascitis...I made a mistake in shoe choice for a vacation one year, before I knew how much my wife absolutely insists on walking at least 10 miles a day. That was 8 years ago and I still have pretty severe pain almost every morning. reply dmos62 7 hours agorootparentTake this with a bag of salt, but I&#x27;ve heard people get notable improvements in joint, feet, leg health from switching to barefoot shoes. They also tend to be extremely comfortable. I&#x27;ve been using them exclusively ~5 years and ran a half-marathon in them. For what it&#x27;s worth, a physical therapist told me my feet are remarkably muscular. I like the UK manufacturer Freet, btw. reply Enginerrrd 6 hours agorootparentConsider my perspective: I switched to barefoot shoes to prevent problems I didn&#x27;t have and wrecked my knee to where I had to quit running entirely for ~6-7years. I&#x27;m finally able to run now again though but I&#x27;m never trying that experiment again. reply tuatoru 4 hours agorootparentPeople go too hard. If you&#x27;re in your 20s, starting at ten minutes a day and working up to 90 minutes over the course of 18 months is a reasonable rate of change.Tendons and ligaments do not adapt at the same rate as muscles. Nor do articulation patterns. reply senkora 5 hours agorootparentprev+1. I gave them a try during the pandemic and it led to some knee pain. Thankfully I switched back before causing serious damage. I’m sure that they work well for some people but they can also hurt. reply xctr94 3 hours agorootparentprevMy god, yes. I had knee and ankle pain while running, then also while walking. Too much padding was allowing me to walk incorrectly. After being ‘prescribed’ flat, flexible, low-stack shoes, all the pain went away. My toes are more spread out and my abductors are thicker. Nice gains!(Still, your mileage may vary, I included lots of exercise specifically for the transition. And still run in Altras.) reply scns 1 hour agorootparentIn Born To Run they cite a study that surprised it&#x27;s own authors. The more expensive the running shoe, the higher the rate of injuries i.e. the better the damping the weaker the foot and legs. And another one that showed the impact on the leg is 7 times higher in running shoes than barefoot. On mobile may provide links later.[edit] Unable to find the one i searched but found this article claiming a 2-3x times bodyweight impact on the legs when wearing shoes.https:&#x2F;&#x2F;news.harvard.edu&#x2F;gazette&#x2F;story&#x2F;2010&#x2F;01&#x2F;barefoot-runn...[edit]Another great study found while searching> A large majority (68%) of runners participating in the study experienced no new injuries after starting barefoot running. In fact, most respondents (69%) actually had their previous injuries go away after starting barefoot running.https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S209525461... reply scns 1 hour agorootparentprev> I like the UK manufacturer Freet, btw.Thanks for the recommendation, might give em a try. Tested some brands so far, stayed with Vivobarefoot.[edit] Disclaimer: Repeat customer reply dotancohen 3 hours agorootparentprevI am not an avid runner or hiker, but I do both occasionally. I find that I am far more comfortable after a day of walking or hiking on level ground if I&#x27;m barefoot. However running barefoot on any surface other than sand is painful in both my feet and knees.I suppose that different activities require different footwear. reply arcanemachiner 10 hours agorootparentprevI beat the shit out of my plantar fascia when I took to longboarding one summer.I basically had to stop any recreational walking for a year. I tried the Vibram FiveFingers and I think they helped (yes, I know about the lawsuit: https:&#x2F;&#x2F;www.bbc.com&#x2F;news&#x2F;business-27335251), but my equation for recovery is rest + time then gentle strengthening (and luck I guess, in the case of my plantar fasciitis). And ergonomic everything wherever possible to prevent future issues before they occur. reply moron4hire 8 hours agorootparentI have one particular pair of dress shoes that are the most comfortable for me right now, even more so than my sneakers. I think it might be the rise of the heel, plus they were always pretty comfortable getting the start. I basically heal over the week while I&#x27;m sitting at work and then redamage over the weekend when I&#x27;m taking my kids out to parks. reply mikestew 10 hours agorootparentprevI am NOT anyone with relevant credentials, just a lot of running over the last 40 some years in a lot of shoes. That said, I no reason to think that VaporFlys would help with plantar fasciitis. I hypothesize that it&#x27;s the energy return (which is energy not pounding the legs) is what saves the legs, and I don&#x27;t know that help plantar problems. And the shoes are designed around running, not walking.Mainly, though, is they&#x27;re $250 a pair. That&#x27;s a pretty pricey experiment without some bit of evidence, even if anecdotal, that they might work for your problem.Good luck, though. I know plantar fasciitis is a tough one to treat. reply moron4hire 8 hours agorootparentMy thinking is that a spring that can provide power also absorbs power. Basically a low-pass filter, like a capacitor. IDK. I&#x27;ve tried the socks, the boots you wear while you try to sleep but can&#x27;t because they itch too much, and all kinds of shoes. Honestly, I&#x27;m at the point where I&#x27;ll try just about anything. reply selcuka 3 hours agorootparent> My thinking is that a spring that can provide power also absorbs power.An ideal spring (or a capacitor) should not absorb any energy. reply asimpletune 1 hour agorootparentWhile an ideal spring may not exist, the foot itself might be the next best thing suited to that goal. It’s full of nerves that allow the brain to make micro adjustments, as well as muscles for executing those compensations in real time, based on feedback thats coming from the ground. reply jraby3 7 hours agorootparentprevI had it for years, even had to get cortisone shots in the bottom of my feet.The only solution that worked for me was stretching. When you are standing on a step, let your heel hang down as low as possible one foot at a time. Do this for both feet and do it with straight legs and bent knees multiple times a day. It only takes about a minute and does an amazing job of curing plantar. reply hooloovoo_zoo 5 hours agorootparentThis worked for me too but I do it as a calf raise instead of a stretch. reply muststopmyths 6 hours agorootparentprevwhen I had plantar fascitis the only thing that helped was finding the right running&#x2F;working out shoes. It was like magic in how quickly that fixed it.In my case, I needed shoes with more support around the mid-foot so the feet didn&#x27;t rotate in or out too much. The flip side is that as soon as I wear the wrong kind of shoes my feet let me know within a couple of workouts.I also wear superfeet insoles in all my casual shoes.The brand that works for you may not be the same as mine but Hokas work well right now and Saucony ProGrid Omnis worked really well too in the past. Saucony unfortunately keeps changing the names of their shoes but I think the current \"Grid\" type shoes are similar.Asics, Mizunos, Brookes, etc. were all useless to me.So, I would say keep trying different pairs of shoes.I&#x27;m usually a big fan of sports medicine and physical therapy, but in this case those fields were pretty clueless about deducing the cause beyond general platitudes.Edit: To add, my symptoms were first caused by wearing the wrong kind of shoes because Saucony stopped making the ones I was used to and I tried another brand on someone&#x27;s advice. reply planaerfasci 7 hours agorootparentprevThis is not medical advice but two of my friends fixed that problem with these: https:&#x2F;&#x2F;www.hoka.com&#x2F;en&#x2F;us&#x2F; reply mmanfrin 6 hours agorootparentMe as well. They&#x27;re the only shoe I wear now. reply BolexNOLA 7 hours agorootparentprevHey there! I don’t know what you’ve done to treat it so far, but I am somebody who went through a year and a half of very painful plantar fasciitis after a few years of moderate pain. I tried every single solution under the sun and am actually “cured”! Some unsolicited input, if you want:1) Kuru tennis shoes with an insert for PF are excellent. 2) Oofos slippers by my bedside even today. They provide such good relief 3) aleve > other pain meds 4) the PF splint which stretches out your foot cN work wondersI ultimately had to get my plantar fascia released, my inflammation had just become so severe there was no other option. I’m really glad I did it though, it’s been completely gone ever since. My foot feels fantastic now, though the recovery was a little long. I was walking around after a few weeks but I didn’t feel 100% until probably eight or 10 months out. I still use all of the above and it has yet to return. But they were also incredibly effective at managing my pain&#x2F;inflammation. I just had them recommended too late in the process. reply solumunus 2 hours agorootparent> ultimately had to get my plantar fascia releasedWhat does this mean? reply rotskoff 14 hours agoparentprevIn fact, the shoe was not banned and it is one of the most widely used marathon racing shoes out there. Nearly all other running shoe companies followed suit and made more efficient racing flats with carbon plates and high energy return foams. Some restrictions did come out, including limits on the \"stack height\" racing shoes and more stringent restrictions on the track. The current generation of these, the alphafly 3, were just used to break a world record in the Chicago Marathon by Kelvin Kiptum. Those are unreleased as of yet. reply WestCoastJustin 14 hours agorootparentLooks like initially was then wasn&#x27;t re: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Nike_Vaporfly_and_Tokyo_2020_O... reply seattleman 14 hours agoparentprevThe specific version of the Nike Alphafly shoe that Eliud Kipchoge wore for his sub 2 hour marathon (out of competition) was banned, but subsequent versions of the Alphafly and Vaporfly are legal and still being used to break records today. As a result of Kipchoge&#x27;s sub-2 marathon run, some rules were set on shoe design, namely:1. Max stack height of 40 mm 2. Only one carbon plate allowed per show (Kipchoge&#x27;s had 3) reply ge96 11 hours agoparentprevWell I&#x27;ll be... that ugly design has a purpose reply asoneth 13 hours agoprevTheir model seems to predict a theoretical top speed of 18-20.9m&#x2F;s (or 40.0-46.8mph, 64.8-75.2kph): https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;sciadv.aay1950#F2As much as I want to imagine people chasing down cheetahs, without empirical testing I have to admit I am skeptical of their claims. reply pixl97 11 hours agoparentEh, I&#x27;m not worried about their top speed claims... I&#x27;d be far more concerned that you could reach those speeds, and the hospital bills incurred by the inevitable accidents. You&#x27;re going to have to have a massive amount of safety gear weighing you down (thereby losing speed) to keep you from busting your head open like a rotten cantaloupe moving that fast. Velocity squared is a bastard. reply ntonozzi 10 hours agorootparentPeople bike and ski that fast every day with no protection other than a helmet. reply evilduck 9 hours agorootparentAnd people occasionally die biking and skiing from their own accidents hitting unmovable objects — something virtually unheard of with runners. reply whywhywouldyou 9 hours agorootparentSo what? These people will no longer be your run of the mill \"runner\". They will be augmented, much the way we&#x27;re augmented by using bicycles and skis, etc.The original claim that if someone were to be able to move at these speeds that they would suddenly need to be heavily bogged down in safety gear is flat out ridiculous. Comparing it to other sports where we move at similar speeds should be more than enough evidence of that. reply Retric 9 hours agorootparentPeople do ski faster than that but low friction means slower deceleration which is a huge reason it’s even possible to learn reasonably safely. This applies to basically all high speed winter sports and is under appreciated by most viewers. Similarly landing from a jump or fall on a hill the force vectors mean people are mostly sliding on the surface resulting in significantly less forceful impacts.Biking at 45-48 MPH is rare, dangerous, and free of tripping hazards which I think are a much larger concern. Further, people also add extra protection for downhill MTB such as a back protector, thick gloves, goggles, helmets with neckbrace, padded clothing, and knee pads. Yet it also has similar benefits from being on steep hills. reply lloeki 1 hour agorootparent> Biking at 45-48 MPH is rare, dangerous, and free of tripping hazards which I think are a much larger concernTwo decades ago I was doing downhill MTB. On a road section it was quite frequent for me to reach those speeds†; and that&#x27;s with a MTB (tuned to that end), friends†† with road bikes reached these speeds with ease, some of them regularly hit 80-90kph on specific sections.One of the wide hairpin turns happened to be littered with gravel, and as I was banking for the turn the bike wheels started zipping off laterally as it the ground was ice, propelling both of us sideways at full speed towards the downward outer bank.Luckily a) I had slowed down to approach the turn so I was going more like 45-50kph and b) the bike had much less ground grip than my body so it flied away while body-ground friction (painfully) slowed me down to a stop before I hit any tree or rock down the bank. Sheer luck had it that I walked away from the event with only a few bruises and a lot of scratches (one of my elbows still bears burn scars)† Top recorded speed ever was 74 kph, at which point gear ratio was such that `cat pedalling > &#x2F;dev&#x2F;null`†† c.a 1995-1999 they biked regularly with the then young Julien Absalon (I only biked with him once): https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Julien_Absalon. reply Lio 2 hours agorootparentprev> Biking at 45-48 MPH is rare, dangerous,Not sure where you get that from. Amateur road cyclists can pretty easily reach 50MPH given a long enough hill and do so pretty uneventfully.That&#x27;s dressed in just shorts, jersey, helmet and fingerless gloves.A professional racing cyclist could easily break 60MPH on closed roads and even 80MPH on occasion.For someone like Tom Pidcock who knows[1]. In the linked video he&#x27;s topping out at about 100kph (60mph) but it&#x27;s worth noting that that&#x27;s without being allowed to sit on the top tube of this bike. They banned that (even though it wasn&#x27;t linked to any crashes).The bike manufactures will eventually just add dropper posts to all pro road bikes and those speeds will go up again.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=3f4Pp4oYh28 reply loeg 9 hours agorootparentprevBike crashes at 40 mph are brutal. The vast majority of fast, competitive cyclists in races are topping out at or below 25-30 mph in flat ground riding. reply namelosw 6 hours agoparentprevWow that&#x27;s fast. But it sounds dangerous.The last time I attempted to run at full speed after not running for years, I struggled to keep up and lost my balance. I started tilting forward slowly and eventually fell then slide on the ground for a while, resulting in multiple scratches on my face, front pelvis, etc. reply davidw 8 hours agoparentprevI&#x27;m envisioning the movie version, where there&#x27;s a montage of the scientists crashing time and time again before they get it right. reply chrisweekly 10 hours agoparentprevstill slower than cheetahs reply helsinkiandrew 14 hours agoprevHaven’t similar devices been around for ageshttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Jumping_stilts reply tech_ken 14 hours agoparentNo, the difference is when&#x2F;how you load the springs. This proposal seems to be that you load the spring with your leg in the air before it makes contact with the ground (achieved by attaching the top of the spring up the leg), then land the loaded spring and unload. Their argument is that this allows for higher overall energy output from the human body (akin to cycling). In a jumping stilt you&#x27;re loading the spring when you put your foot on the ground and unloading immediately, so the energy output only really occurs during that period of foot contact, which presumably lowers overall output. reply DropPanda 14 hours agoparentprevNo, the article specifically talks about a device where the legs perform work continuously, as in cycling. The device you linked to only lets the legs work during ground contact. reply euroderf 4 hours agoparentprevI guess these are about the same as \"kangaroo shoes\".I wonder, do these things add endurance ? Or do they maybe require the use of otherwise-little-used muscles, reducing endurance ? reply oldbbsnickname 6 hours agoparentprevYep. I think I saw these on the TV show \"Beyond 2000\". reply scotty79 13 hours agoparentprevI think it&#x27;s about having you being hanged in harness on the hips while you are running. This way you don&#x27;t have to extend energy for your muscles to keep you upright. Springs do that. Then all the energy generated by your muscles can go towards creating motion. reply layman51 10 hours agoprevThis post really reminds me of Keahi Seymour. I forget where I first learned of him, but it may have been an HN post because he was the subject of an article about pursuing a dream for 30 years and failing. But basically, the story is that he wants to produce and sell “bionic boots”. I forget the exact challenges he has faced in getting his goals met, but apparently he does have a working prototype of some sort that is used in a YouTube video. reply Someone 12 hours agoprevI couldn’t find a mention of oxygen usage. Given that running at speed is aerobic past 800m or so (for Olympic-level athletes. Mortals hit that point way earlier), would athletes actually be able to make the extra effort? reply wolverine876 9 hours agoparentMy understanding is that a species&#x27; maximimum speed depends simply on muscle mass. The reason elephants don&#x27;t outrun cheetahs is that they accelerate more slowly and run out of energy before hitting the top speed their muscles could produce.Look up allometry for more. There are formulas for calculating top speed based on mass. reply Someone 1 hour agorootparent> My understanding is that a species&#x27; maximum speed depends simply on muscle massIf so, that doesn’t mean that they would get faster if only they got more muscle. I would expect that species evolve towards not having more muscle than they can effectively use. I think looking at elite human runners supports that. At longer distances, they get less muscular.> The reason elephants don&#x27;t outrun cheetahs is that they […] run out of energy before hitting the top speed their muscles could produce. > Look up allometry for more. There are formulas for calculating top speed based on mass.I think our best knowledge is that adding more muscle only works for a limited time. https:&#x2F;&#x2F;news.cgtn.com&#x2F;news&#x2F;3d51544f7767444e&#x2F;share.html:“If muscles were all that mattered \"elephants would reach maximum speeds of about 600 kph (370 mph),\" she told AFP.Instead, tuskers peak at about 34 kph (21 mph).Big beasts, in other words, run out of so-called anaerobic energy, supplied by the muscles, before being able to reach their theoretically maximum speed.“ reply ummonk 8 hours agoprevOr you could ride a bicycle. reply thiht 3 hours agoparentThat might be frowned upon in a running competition reply cryptonym 29 minutes agorootparentTo be fair, using other mechanical devices might also be frowned upon. reply lr4444lr 14 hours agoprevIsn&#x27;t this why Oscar Pistorius was considered to have an unfair advantage by many? reply kibwen 14 hours agoparentNo, this is a different sort of spring-loaded mechanism that allows you to put energy into it when you retract a leg, then unleash that stored energy when your foot next hits the ground.\"However, the current top speed of augmented running, 11 m&#x2F;s, achieved using a spring prosthesis in series with the legs (13), is 10% below the top speed of natural running. A spring in series with the legs can mitigate collisional energy losses but requires the legs to provide a large force to support the body, unlike the wheel of a bicycle (10, 13, 14).\" reply oezi 14 hours agoparentprevThe article says that the Paralympic running top speed is below the non-paralympic top speed. reply oh_sigh 13 hours agorootparentWhich doesn&#x27;t mean that blade-runner type people don&#x27;t have an advantage. reply Etheryte 14 hours agoparentprevRoses are red, violets are glorious, don&#x27;t try to surprise Oscar Pistorious. Sorry, I&#x27;ll see myself out. reply bee_rider 12 hours agoprevThis seems fairly buildable, I wonder why nobody gave it a try. reply karmakurtisaani 1 hour agoparentThey probably needed their teeth too much. reply quickthrower2 13 hours agoprevNow you just need to poles for the arms to get those triceps helping out, with springs so your biceps can preload them. reply anotheryou 14 hours agoprevStep 1: become a kangaroo reply ChatGTP 11 hours agoparentKangaroos are freaking awesome to see when they’re in a hurry. I’ve seen one practically “gap” a road. reply Titan2189 6 hours agorootparentUsername doesn&#x27;t check out reply ChatGTP 5 hours agorootparentIf you don&#x27;t use a joke in the right context it loses it&#x27;s humor :) reply ck2 14 hours agoprevInline skates on flat ground are technically \"no external energy\".And they can race a marathon in under an hour, so that&#x27;s 26+ mph (42 kph) reply DropPanda 14 hours agoparentThe proposed device is predicted to allow almost double that speed. I think it’s pretty cool. reply chongli 11 hours agorootparentWhat? That’s faster than track cycling world records! The 200m flying start record is 9.1s which translates to 79km&#x2F;h. The makers of this device are proposing to let humans run faster than a world record track cyclist! reply kibwen 14 hours agoparentprevYes, skating is mentioned in a graph near the end. reply fwip 14 hours agoparentprevPresumably there are areas&#x2F;applications where \"running\" is important - otherwise we can just use a bicycle. reply 303uru 13 hours agorootparentHistorically, human survival. No other animal can cover ground the way we can. We&#x27;ve evolved to be highly efficient, one example; we cool ourselves better than any other animal we can maintain a fairly high power output almost indefinitely due to sweating. reply ck2 7 hours agorootparentPronghorns would like a word.Not only could they race an entire marathon, they would beat those inline-skaters. 30mph for hours and 150 miles in some journeys.They evolved a different cooling system than sweating.https:&#x2F;&#x2F;journals.biologists.com&#x2F;jeb&#x2F;article&#x2F;211&#x2F;5&#x2F;749&#x2F;18118&#x2F;... reply endisneigh 14 hours agoprevIf you change run to travel you can do the same thing with a kick scooter reply hinkley 14 hours agoparentIf you used this with a kick scooter you’d go even faster. reply aghilmort 10 hours agoprevinteresting — looks like would feel like running on pair of slanted pogo sticks, like juggling springs with feet reply renewiltord 14 hours agoprevI considered using jumping stilts to run to work rather than skating or cycling. However, the skill level required to master them sufficiently to run required more training than I was willing to put in.I eventually ended up buying some shift.io moonwalkers, which do have quite a speed-up effect. The problem is that they&#x27;re quite heavy and the walking motion required to use them effectively ended up requiring my anterior tibialis muscle to have more endurance than it does currently. Additionally, at higher speeds they&#x27;re dependent on your foot stepping direction, which I have slightly outwards rather than in-line forwards, which causes a slightly skating motion when walking.The quest continues on. reply oezi 14 hours agoparentWhat are you trying to achieve? Keep weight&#x2F;volume of the device low?Or is about training running but being bicycle-fast? reply renewiltord 13 hours agorootparentI want to get somewhere faster with portable tools. Used to skate, but annoying to take skateboard everywhere. I live in SF, so bike gets stolen. Currently use Lyft e-bike rental but ideally have similar speed but backpack-able portability.Honestly, maybe I wear cooling vest and just jog to work. Walking too slow: 15+ min &#x2F; mile. reply bee_rider 12 hours agorootparentWhat about roller blades? reply paddy_m 11 hours agorootparentI am an excellent ice skater and decent, not great rollerblader. Rollerblades are difficult to control and stop quickly (haven&#x27;t mastered the sliding turn quick stop). They are much more sensitive to surface imperfections and slick surfaces than a bicycle. Finally, rollerblades are heavy and still require you to bring extra shoes, putting them on and taking them off takes about 5 minutes... All of this makes them impractical for commuting. replydandanua 12 hours agoprevAm I correct that they propose to bend your leg (while it&#x27;s in the air after a ground contact) with an additional force, which is used to conserve energy in an attached spring. Upon a next contact with ground this energy will be released, which gives a better boost than ordinary jumping stilts, since they are loaded only at the moment of contact? reply justinator 14 hours agoprevAh! Moon boots - had those as a kid. reply swayvil 14 hours agoprevI&#x27;m looking for pictures of a guy with the exoskeletal running augmenter strapped on. reply tech_ken 14 hours agoprevITT: people who read scientific articles by skimming the pictures.The proposal isn&#x27;t \"springs under your feet\" it&#x27;s \"springs along your legs that you load while your leg is in the air\". The point is that by loading the spring with a leg which is otherwise not doing anything you&#x27;re able to increase the overall energy output of the body. Their Fig. 2 shows exactly the (theoretical) difference between the naive \"jumping stilts\" approach and what they&#x27;re suggesting.> Cycling is faster than running partly because (i) the rolling motion of the wheels prevents collisional energy losses from stepping but also because (ii) wheels can support the weight of the body in place of the legs, while (iii) pedals enable the human to supply energy continuously in the air instead of intermittently when the leg is on the ground .Super interesting to see that they still can&#x27;t outperform cycling. Presumably their proposal resolves most or all of point (iii), so the difference is from (i-ii). I would assume that, of these, (ii) would be the hardest to replace with any kind of leg attachment reply hinkley 14 hours agoparentOne of the reason pro cyclists clip their feet to their pedals is so they can load the “other” leg through the back of the stroke, and across the bottom as well by pulling back on the loaded leg. Come unclipped in a sprint and you’re fucked.Sounds like this is the same thing for running. reply rottencupcakes 13 hours agorootparentThe idea that your muscles have enough strength on the upstroke to contribute meaningfully to cycling is actually a bit of a misunderstanding. Your leg muscles for lifting are much much much weaker than your leg muscles for pushing - they&#x27;re designed to only lift up the weight of your leg and not much more.The main advantage of the clips is to keep your leg in contact with the pedal throughout the cycle and make sure the ball of your foot is optimally placed on the pedal. With a traditional pedal you have to keep some downward force on the pedal to create friction to avoid slipping off, so even when that leg is rising up, you can&#x27;t completely unload the pedal. With clips you can completely unload the pedal. reply stouset 13 hours agorootparent> The idea that your muscles have enough strength on the upstroke to contribute meaningfully to cycling is actually a bit of a misunderstanding.Absolutely not, and there are plenty of easy counterexamples.If you&#x27;ve ever raced track, team pursuits start from a dead standstill. You have to expend a ton of force to turn a huge gear, and the contribution of the lifting leg is crucial to getting up to speed. Of course it&#x27;s not going to contribute as much as your lead leg, but all four of your limbs are at maximum exertion getting the bike up to speed. Even not racing at a track, you can test this on any road bike. Shift into high gear, come to a standstill, and time yourself getting up to speed.Another trivial counterexample that anyone (with clipless pedals) can test is a hill climb. Being able to lift on the upstroke is an enormous additional benefit and the difference can be easily measured and proven. Perform a lengthy climb with and without involving your trailing leg, at a given level of intensity. Repeat this multiple times, and it will be patently obvious that your trailing leg is performing significant useful work. The steeper the climb, the more important this is.Sprint finishes are another place where this is critically important, but it&#x27;s harder to set up a simple test.What all of these have in common are situations where outputting a higher force is more important than long-term endurance. Lifting on the upstroke is difficult to do at high pedal speeds, but at medium or low pedal speeds, it&#x27;s a clear differentiator. reply jdietrich 9 hours agorootparent>the contribution of the lifting leg is crucial to getting up to speedThis might feel true, but it isn&#x27;t. Buy or borrow a dual-sensing power meter (Garmin Rally, SRM X-Power etc) and you can see for yourself - there&#x27;s practically no useful power in the upstroke. Toe clips or clipless pedals can extend the power stroke, but only by a few degrees at the bottom of the stroke.https:&#x2F;&#x2F;bythlon-pedal.myshopify.com&#x2F;pages&#x2F;the-myth-of-the-up...The intuition of cyclists is a very bad indicator of actual performance. For decades people thought that hard, narrow tyres were faster, but nobody had actually tested it properly. Narrow tyres have lower rolling resistance on a smooth steel drum in a test lab, but they have much higher rolling resistance on real roads with bumps and ruts. When paired with suitable rims, the reduction in rolling resistance of wider tyres more than compensates for the penalty of increased weight and drag. reply ordu 6 hours agorootparentMy cyclist&#x27;s intuition says that leg clipping allows you to extort greater force on a down stroke. Without clipping the force is limited by your body weight, with it the only limit is your muscles.Thinking about it your hands and a back leg allow you to apply a lot of downward force to your body and your lead leg can add all this force to a stroke. It doesn&#x27;t matter that your hands or back leg individually are not so strong when pulling, because their efforts are combined.In situations when you need not to extend as much force as you can, probably clips do not add much, though I do not know. I tried at some point to ride a bicycle without clips and nearly failed. My back leg tries to pull and leave a pedal.> https:&#x2F;&#x2F;bythlon-pedal.myshopify.com&#x2F;pages&#x2F;the-myth-of-the-up...They are saying that with high rpm cyclists do not pull. I can believe that, high rpm is beneficial exactly because you need to apply a relatively small force. reply stouset 6 hours agorootparentprevI strongly encourage you to actually test this yourself. Having personally done so myself, all I can say is that you will be surprised.Time yourself on a max-effort sprint in a high gear from a standstill. Don’t pull up on half your efforts. Pull up on half your efforts.The effect isn’t subtle.I’m not particularly convinced by power meters not showing much here. The biggest reason being that pulling up has the effect of allowing you to push even harder down. Without pulling on the handlebars or pulling up on the rear pedal, the maximum force you can exert on the pedal is a function limited by your weight. By pulling up on those three points, your ability to push down harder is significantly greater.Another simple counterexample is hills. There exist hills in my city that are physically impossible to climb without clipless pedals. You can stand on the pedal all you want, but your body weight is not enough to overcome the downward pull from the slope. On clipless pedals, while pulling up, you can climb the hill. reply hinkley 12 hours agorootparentprev> but all four of your limbs are at maximum exertion getting the bike up to speed.Oh goodness yes. When you’re going full out it’s like you’re trying to wring water out of a steel towel. Pull up on left handlebar while using right arm to prevent oversteer.Another fun failure mode is when you don’t quite trust your handlebars. I’m either not going to pull on these or I’m gonna stop before the Big Hill to find an Allen wrench and tighten these stupid things. I think the new design is meant to prevent a lot of that. reply stouset 10 hours agorootparent> trying to wring water out of a steel towelI’m stealing this! Spot on. reply jeffbee 12 hours agorootparentprevWe have a large amount of power meter data demonstrating that elite and pro cyclists do not, in fact, exert much force on the rising stroke when in the saddle. They maintain a net downward force on the pedal most of the time. The benefit of clipless pedals is repeatable positioning and the ability to start the downstroke right at top dead center, without slipping off the pedal. The benefit is not from powering the backstroke. reply hinkley 12 hours agorootparentPersonally outside of dramatic moments like the Big Hill or the club smartass trying to drop everyone for giggles, driving through the bottom of the stroke was the only thing that felt like it 1) mattered and 2) could be sustained.But I think you have to go to triathletes to really see that effect more pronounced. Since they like to sit tilted a couple degrees farther forward on the bike, the hamstring is more accessible.At the end of the day a pro is 5-10% better than a serious cyclist at five different things. Even before you get to diet and genetics (and doping, sorry) they’re already outputting more watts and getting more of them to the wheels than I could hope to. Technique adds up. reply stouset 10 hours agorootparentprevYet cycling events are frequently won out of the saddle on the slopes or out of the saddle in the sprint.And yes, sometimes they’re won by someone time trialing away from the pack while in the saddle. But even then, most of the time it’s a breakaway pack which fights for the podium in an all-out sprint. reply hinkley 8 hours agorootparentThe breakaway pack also typically sprints away from the peloton. Because drafting is 30% easier than riding at the front. If you don’t catch a wheel as it goes past, you’re dropped.I’m looking around at all this ”data that we have about pedal strokes” and nobody mentions sprinters or climbing specialists. If they don’t know it’s important they won’t test for it. Sounds like “science” being done by domain neophytes and called objective.What is interesting though is that one claimed that advanced amateurs have higher peak stroke torque than pros. Pros are spreading more power out over a larger arc of the circle. Now that could still be 130° of the stroke for all I know but that still sounds like circularizing to me.I also haven’t found anyone yet who says LeMond was wrong about driving through the bottom of the stroke, which is how I rode. reply rhn_mk1 13 hours agorootparentprevThose are not necessarily examples of lifting. Those could as well be explained by the contribution of not pressing on the opposite pedal (to keep the foot from sliding).And not pressing doesn&#x27;t shine any light on the force of lifting. reply louthy 12 hours agorootparent> to keep the foot from slidingThe foot doesn’t slide with clipless peddles. The foot is locked in position. And you can absolutely use lifting and pushing combined - I have done this many times on long sportives (~100 miles); it can give respite to the ‘pushing’ muscles reply stouset 10 hours agorootparentprev> Those are not necessarily examples of lifting.They are, and this is trivially demonstrable by literally just trying it on a bike. Seriously. Go put a road bike in the highest gear and try to get up to speed from a standstill. Not only will you be pulling up on the rear pedal, but you’ll be using your arms to try and wrench the handlebars off the stem too.Go climb a steep hill. Same thing occurs. It’s not like this is subtle. The contribution of your rear leg very clearly contracting will be impossible to miss. reply tourist2d 12 hours agorootparentprev> to keep the foot from slidingSo you obviously have never used clip in bike pedals before. Why are you trying to argue this point if you know nothing about what you&#x27;re talking about? reply hinkley 8 hours agorootparentWe are perhaps not the best group on the internet for discussing biomechanics... reply onetimeuse92304 13 hours agorootparentprevAny muscle is trainable. To some extent. If you cycle enough, you will develop muscles necessary to pull the pedal up.Additionally, the goal isn&#x27;t to double your power output. It is to be better than the other cyclist. Even by just a tiny bit.I personally think that clipping the feet helps more with left right stability. Also, if you are pulling with one leg, you can potentially push more with the other. Normally you can only push as much as you weight, but with the other leg clipped you can push your weight plus the force you use to pull the other pedal. reply justsocrateasin 13 hours agorootparentThis is true for certain metabolic zones but not others. If you&#x27;re sprinting then yes, you get a higher power output while pulling up on the pedal. However if you&#x27;re going for any kind of endurance (longer than a minute) the limiting factor is not muscular but cardiovascular&#x2F;aerobic, and using less efficient muscles (the ones used for pulling up) will actually hinder your performance since you&#x27;ll need to be supplying those with oxygen, thus decreasing total cycling economy. reply ip26 13 hours agorootparentYour goal in endurance conditions is to maximize the aerobic pathway, which means maximizing the number of active mitochondria. Recruiting more total mitochondria from more total muscle fiber will give you greater aerobic power output. reply discreteevent 11 hours agorootparentLike the parent said, the goal is efficiency not maximum power. And as another comment said, in practice the pros do not pull up. If there were even a minute gain in doing so, they would train themselves to do it (in fact some of them used to in the past before they figured out that it was a waste of time) reply ang_cire 12 hours agorootparentprevAh yes, the Powerhouse of the Cell. reply onetimeuse92304 13 hours agorootparentprevI am not versed with cycling economy. But yeah, it makes sense.On a bike, if you want to put up more power you have options to push harder or spin faster. If you had to push harder than your weight, you could always change your gears to rather spin faster. reply BobaFloutist 9 hours agorootparentprevI would assume that just your hands being on the handlebars would let you push more than you weigh. reply hermitcrab 49 minutes agorootparentprev>Your leg muscles for lifting are much much much weaker than your leg muscles for pushingAnd yet Thai boxers appear to be able to generate at least as much force using upward knee strikes as push kicks. reply hinkley 12 hours agorootparentprevI think you’re imagining the hip muscles pull the entire leg up, but you’re pinning a double hinge between your body weight above and the pedal below. There are a lot of different muscles in the leg that you can activate to stay upright, but outside of yoga or tai chi most of us lock a bunch of them up and don’t think about them. Which is both a shame and a route to injury.Similarly there as a few different muscles that can bring your knee up if it’s pinned between your hip and a pedal. The hamstring being one of them. Though personally (as an enthusiast rather than a pro) I always felt like I had more stamina from just driving through the bottom of the stroke. I only pulled up on hills and when someone tried to drop us. reply andy99 12 hours agorootparentprevI&#x27;m not disagreeing with the above comments though I am curious about the factor of how much energy output a person is actually capable of. Running isn&#x27;t leisurely and you can reach (as far as I know) maximum physical (cardiac?) output running. My point being it&#x27;s not like there is unused capacity to work harder when you&#x27;re running that&#x27;s making you slower. So there must be more to it than just doing more at times you&#x27;d otherwise be idle. reply Someone 13 hours agorootparentprev> Come unclipped in a sprint and you’re fucked.Not necessarily :-)See https:&#x2F;&#x2F;www.eurosport.com&#x2F;cycling&#x2F;famenne-ardenne-classic&#x2F;20... for an example where that happened and the sprinter still won. reply hinkley 7 hours agorootparentJesus.Well momentum can be your friend or your enemy.It looks like not only did he pull his foot out, he also clipped his chain or front derailleur with his foot and popped himself down into the small chainring. reply pharmakom 13 hours agorootparentprevI believe this was disproven actually. The real reason is security under heavy power output. reply criddell 13 hours agorootparentprevHave you ever used an elliptical chainring? reply jph 13 hours agorootparentYes, elliptical chainrings are great IMHO, especially if you train for elliptical continual exertion. Added 2km to my speed. reply jackmott42 13 hours agorootparentNo it did not. reply hinkley 7 hours agorootparentIt&#x27;s not that far above what some people were claiming when they were new. There were people claiming 1mph improvement. I was... skeptical. Placebo effect? Who knows.I don&#x27;t think I ever got around to trying one. I was the youngest regular member of our club. Power output was not my primary problem. reply bee_rider 12 hours agorootparentprevIt is hard to say if it is implausible without the time unit. 2km&#x2F;day? I believe it. 2km&#x2F;s? Seems unlikely. reply jph 10 hours agorootparentHa! Yes you&#x27;re right, units matter. For me it was 2 km&#x2F;hour, on rides for an hour or so typically above 20 km&#x2F;hour, on a hybrid bike, on long streets in Marin. The ellipticals worked especially well, for me, in combination with bar ends. replyjackmott42 13 hours agorootparentprevThis is false, even cyclists who think they pull up and pull back do not, and it is less efficient to do so. However it is a VERY common misconception that you should do this. reply hinkley 7 hours agorootparentWhen the only American who won the Tour de France without drugs tells people to do something, a lot of people are going to do it.Anyway, I can&#x27;t find any of these so-called studies that admits to knowing what a sprinter is let alone a green jersey, so I&#x27;m going to keep my eye out for less flawed studies.In fact, get me one by a team medic or physiologist, and then we can talk. Until then it&#x27;s nerds in coats coatsplaining things to people actually doing the work. reply Ericson2314 13 hours agoparentprevReverse running, that sure sounds like a lot of tripping and falling!The power leg and the stability&#x2F;control leg being opposite not the same really boggles my mind. reply Ericson2314 13 hours agorootparentIf we&#x27;re getting really transhuman with this, assuming the brain is more malleable than the leg, I think it would actually be easier physiologically to run backwards than forwards with this.Real shape rotators will know what I mean ;) reply scythe 13 hours agoparentprevThe next question, following this framework, is that in order for a suspended leg to load a spring, it will be necessary to apply a force against some other part of the body -- so where does it go? On a bicycle this is the other foot, which is made possible by the pedals. But with a spring affixed to the leg, the most likely result is a force against the dorsal surface of the thigh -- not exactly a pleasant idea (try pushing two fingers into the back of your leg if you&#x27;re curious). So then you are inventing something of an exoskeleton to manage this.Cycling is extremely efficient -- around 80% of the energy expended by the body is converted to forward motion, even in the simplest configuration, and this can be enhanced further under some circumstances. reply oezi 14 hours agoparentprevIt is a bit sad that the article doesn&#x27;t explain what the motion would feel like similar to. Would it be like walking stairs? reply ramses0 13 hours agorootparentIn the \"clipped to cycling pedals\" example, the description I was recommended to aim for was \"rolling a log in a circle\" as opposed to pushing&#x2F;pulling.It makes a big difference to be able to have both legs \"inputting\" energy into the system at the same time. I would say \"non-linear response\" but that&#x27;s probably inaccurate... but maybe not? Basically once you&#x27;ve overcome rolling resistance to _start_ going up a hill, being able to continue it with \"both legs\" instead of one feels like you&#x27;re not overcoming the \"zero-to-one\" hurdle as much and instead staying in the \"one-to-two\" zone. Like you&#x27;re not \"starting over\" every downstroke, but instead transitioning your power from one leg to the other.Given a pretty basic commuter bike that I&#x27;d upgraded over time, it felt like moving from ~35 to ~20 tires (basic to \"road bike\") felt like \"gaining a gear\" (what used to need 1st gear, I could now do in 2nd), and same with clips, also \"gaining a gear\" (cumulative: now I could be in 3rd instead of being in 1st). reply tech_ken 13 hours agorootparentprevI don&#x27;t think they have a functional prototype, so probably difficult to predict a qualitative comparison to other types of motion. Honestly my guess is that it&#x27;s not directly comparable to anything else really, because you typically don&#x27;t have to output energy during the \"off-phase\" of walking. Maybe like having a rubber band around the bottom of your foot which you&#x27;re also holding in your hand? reply make3 13 hours agoparentprevyeah also bike speeds keeps mechanical difficulty optimal, vs having to move your legs very fast at minimal difficulty reply Tade0 14 hours agoprevI thought this would be about the Young Shuffle:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Cliff_Young_(athlete)It&#x27;s actually surprisingly easy to do because you feel you&#x27;re using less energy when doing it. reply p00dles 14 hours agoparentincredibly interesting, thank you reply checkyoursudo 14 hours agoprevNaruto run. Don&#x27;t even need to read the article.\"Without external energy (but with external device attached)\" is ... a bit disappointing. At what point does it cease to be running and start to be run-assisted catapulting? Or catapult-assisted running? It seems like more than just running. reply LeifCarrotson 13 hours agoparentAs the father of a 6 year old who&#x27;s never (yet) shared Naruto with my son, it&#x27;s remarkable to observe that small children innately know how to do the Naruto run. Tragically, most children seem to forget the truth sometime around middle school age.To be serious, though, the article suggests:> Cycling is faster than running partly because the rolling motion of the wheels prevents collisional energy losses from stepping, but also because wheels can support the weight of the body in place of the legs, while pedals enable the human to supply energy continuously in the air instead of intermittently when the leg is on the ground.but I think they miss the point by focusing on the last element rather than the first. I have lots of experience with running (where reducing ground contact time is often advantageous for efficiency), with cycling with clipless pedals where I can supply energy continuously, and with cycling with flat pedals. On the bike, I can sprint on the flats to about 16 m&#x2F;s or 36 mph while clipped in. I don&#x27;t do hard workouts nearly as often on flat pedals, so the data is more spotty, but I know I can reach at least 14 m&#x2F;s or 32 mph; I&#x27;m just about spun out but typically not in my highest gear. I&#x27;ve never specifically tried to do a short-duration time trial on flat pedals, it might be higher than that, but it&#x27;s not more than a 10% differential between intermittent and continuous connection to the pedals.But running? In my prime, I could barely hit 9 m&#x2F;s or 20 mph (I&#x27;m not and have never been a sprinter). If you tied a rope to my chest and towed me to 36 mph (using the rope to eliminate energy loss to air resistance) I&#x27;d be road pizza after a single step.I can go faster on a pair of roller blades or ice skates, with one foot at a time providing an inefficient combination of sideways and rearward thrust, or a kick scooter using only one foot, than I could ever hope to run. The problem is not about the intermittent application of force, it&#x27;s all about the need to convert angular velocity of your joints which has a very limited effective range into linear velocity over the ground. It turns out that cranks and chains over sprockets of various tooth counts are a great way to do this. reply beltsazar 12 hours agoparentprevWhat you said is probably similar to what they said at the early invention of shoes.Professional runners today already use an \"external device,\" aka running shoes. If they ran barefoot or even wore mediocre shoes, they would perform worse. As long there&#x27;s no external energy powering the device, I&#x27;d still consider it running. reply gorkish 14 hours agoparentprevWith respect to the way this article presents efficiency, I would actually expect Naruto running to be slightly more energy efficient than regular running -- the further forward that one can lean while running, the more that gravity will contribute to forward momentum. reply nvy 14 hours agoparentprevI googled \"Naruto run\" and it&#x27;s just... Anime characters running with their arms outstretched behind them.That&#x27;s not what TFA is discussing, you should probably read it. reply altairTF 13 hours agorootparentI found strangely amazing your inability to realize it was a joke the moment you googled \"Naruto run\" reply hombre_fatal 12 hours agorootparentThe problem is that confidently wrong comments are posted to social media like HN and Reddit so frequently that you&#x27;d actually be wrong assuming sarcasm most of the time.So now you&#x27;re just admonishing someone for trying to engage a comment instead of identifying the epic \"anime run funny\" humor.IMO the sanest policy is to just allow people to respond earnestly to posts even if it might be a joke. reply nvy 11 hours agorootparentprevThe top hit for \"Naruto run\" was some random anime video. It was not at all clear that it&#x27;s a meme and the joke went way over my head.Just as a heads up, not everybody watches anime. reply jc2jc 13 hours agorootparentprevThe person you are replying to was (probably) making a joke. Naruto run is an old meme. I think they get the idea of what the article is describing going off of the full comment. reply swader999 11 hours agorootparentprevIt was used in 2019 to storm Area 51.https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=Dhfx0bR7Zx4 reply sgarrity 14 hours agoprevIf even one of those many mathematical formulas had been a YouTube video of a person running in super-space-boots... reply tromp 14 hours agoparentUnder Resources at the bottom you can download a 9MB File (aay1950_movie_s1.mp4) of movie S1, but it only shows an animation of a disc running on blue, green, and red springs... reply swader999 12 hours agoprevI want these for mogul skiing. reply bongwater_OS 14 hours agoprev [–] Who could have guessed - attaching springs to your feet makes you run faster. This is the kind of genius scientific insight that&#x27;s going to ensure the long term survival of the human race. reply tech_ken 14 hours agoparentI mean yeah it&#x27;s not exactly a novel observation, but there is some subtlety in &#x2F;how&#x2F; you attach springs to your legs which seems to be the primary contribution of the paper. The two naive options - referred to as \"in series and in parallel\" - don&#x27;t see the same results as their proposal (which they discuss at some length in the intro). Their proposal is more about making the \"springs on your legs\" idea as effective as possible by using a hip attachment to adjust the loading&#x2F;unloading cycle. By loading the spring with your leg while it&#x27;s in the air you can improve the overall energy throughput of your gait. Other \"springs on your feet\" concepts (mentioned throughout the comments section) use a loading&#x2F;unloading cycle that&#x27;s 180 degrees out of phase with this (leg on the ground is doing the loading).Snark is kind of the enemy of critical thought reply ben_w 14 hours agoparentprevNot only is that not entirely obvious at first glance, it sounds like the kind of paper-thin plot device used in a Loony Tunes cartoon.That it actually works is moderately surprising. reply zellyn 14 hours agoparentprev [–] Would you have guessed that attaching springs to your feet would make you run faster? I certainly would not have guessed that. reply WalterBright 14 hours agorootparent [–] Didn&#x27;t Wile E Coyote try that out? reply rocketbop 14 hours agorootparent [–] Yes with mixed results. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study shows that a catapult-like exoskeleton device can improve running speed by over 50%, signifying the potential of unpowered robotic exoskeletons in enhancing human performance.",
      "The researchers suggest an innovative approach with variable stiffness springs attached to the limbs, potentially allowing humans to exceed natural running speed.",
      "Discussions about the physical requirements and limitations of augmented running indicate a need for more engineering innovations for running exoskeletons. Further, various articles and patents mentioned provide a multitude of sources for extended research on this technology."
    ],
    "commentSummary": [
      "The article delves into the idea of using spring-loaded devices to improve running speed and efficacy, discussing popular models such as the Nike Vaporfly and Alphafly shoes.",
      "It discusses potential treatments for plantar fasciitis, a painful foot condition that affects many athletes.",
      "The piece further debates the validity of pulling up on pedals to improve cycling performance and references a study on enhancing running efficiency by attaching springs to the feet."
    ],
    "points": 207,
    "commentCount": 152,
    "retryCount": 0,
    "time": 1698086767
  },
  {
    "id": 37993702,
    "title": "1Password detects \"suspicious activity\" in its internal Okta account",
    "originLink": "https://arstechnica.com/security/2023/10/1password-detects-suspicious-activity-in-its-internal-okta-account/",
    "originBody": "SKIP TO MAIN CONTENT BIZ & IT TECH SCIENCE POLICY CARS GAMING & CULTURE STORE FORUMS SUBSCRIBE SIGN IN FALLOUT — 1Password detects “suspicious activity” in its internal Okta account 1Password CTO says investigation found no compromise of user data or sensitive systems. DAN GOODIN - 10/23/2023, 3:56 PM Enlarge 1Password 54 WITH 1Password, a password manager used by millions of people and more than 100,000 businesses, said it detected suspicious activity on a company account provided by Okta, the identity and authentication service that disclosed a breach on Friday. “On September 29, we detected suspicious activity on our Okta instance that we use to manage our employee-facing apps,” 1Password CTO Pedro Canahuati wrote in an email. “We immediately terminated the activity, investigated, and found no compromise of user data or other sensitive systems, either employee-facing or user-facing.” Enter your email to get the Ars Technica newsletter Join Ars Technica and Get Our Best Tech Stories DELIVERED STRAIGHT TO YOUR INBOX. SIGN ME UP By signing up, you agree to our user agreement (including the class action waiver and arbitration provisions), our privacy policy and cookie statement, and to receive marketing and account-related emails from Ars Technica. You can unsubscribe at any time. Since then, Canahuati said, his company had been working with Okta to determine the means that the unknown attacker used to access the account. On Friday, investigators confirmed it resulted from a breach Okta reported hitting its customer support management system. FURTHER READING Okta says hackers breached its support system and viewed customer files Okta said then that a threat actor gained unauthorized access to its customer support case management system and, from there, viewed files uploaded by some Okta customers. The files the threat actor obtained in the Okta compromise comprised HTTP archive, or HAR, files, which Okta support personnel use to replicate customer browser activity during troubleshooting sessions. Among the sensitive information they store are authentication cookies and session tokens, which malicious actors can use to impersonate valid users. Security firm BeyondTrust said it discovered the intrusion after an attacker used valid authentication cookies in an attempt to access its Okta account. The attacker could perform “a few confined actions,” but ultimately, BeyondTrust access policy controls stopped the activity and blocked all access to the account. 1Password now becomes the second known Okta customer to be targeted in a follow-on attack. Monday’s statement from 1Password provided no further details about the incident, and representatives didn’t respond to questions. A report dated October 18 and shared on an internal 1Password Notion workspace said the threat actor obtained a HAR file a company IT employee had created when recently engaging with Okta support. The file contained a record of all traffic between the 1Password employee’s browser and Okta servers, including session cookies. Advertisement 1Password representatives didn’t respond to a request to confirm the document's authenticity, which was provided in both text and screenshots by an anonymous 1Password employee. According to the report, the attacker also accessed 1Password’s Okta tenant. Okta customers use these tenants to manage the system access and system privileges assigned to various employees, partners, or customers. The threat actor also managed to view group assignments in 1Password’s Okta tenant and perform other actions, none of which resulted in entries in event logs. While logged in, the threat actor updated what’s known as an IDP (identity provider), used to authenticate to a production environment provided by Google. 1Password’s IT team learned of the access on September 29 when team members received an unexpected email suggesting one of them had requested a list of 1Password users with admin rights to the Okta tenant. Team members recognized no authorized employee had made the request and alerted the company’s security response team. Since the incident came to light, 1Password has also changed the configuration settings for its Okta tenant, including denying logins from non-Okta identity providers. A summary of the actions the attacker took are: Attempted to access the IT employee’s Okta dashboard but was blocked Updated an existing IDP tied to 1Password’s production Google environment Activated the IDP Requested a report of administrative users On October 2, three days following the event, the attackers logged back into 1Password’s Okta tenant and tried to use the Google IDP they had previously enabled. The actor was unsuccessful because the IDP had been removed. Both the earlier and subsequent accesses came from a server provided by cloud host LeaseWeb in the US and used a version of Chrome on a Windows machine. The Okta breach is one of a series of attacks in recent years on large companies that provide software or services to large numbers of customers. After gaining entry to the provider, attackers use their position in follow-on attacks targeting the customers. It is likely that more Okta customers will be identified in the weeks to come. READER COMMENTS 54 WITH DAN GOODIN Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene. Advertisement Channel Ars Technica Unsolved Mysteries Of Quantum Leap With Donald P. Bellisario Today \"Quantum Leap\" series creator Donald P. Bellisario joins Ars Technica to answer once and for all the lingering questions we have about his enduringly popular show. Was Dr. Sam Beckett really leaping between all those time periods and people or did he simply imagine it all? What do people in the waiting room do while Sam is in their bodies? What happens to Sam's loyal ally Al? 30 years following the series finale, answers to these mysteries and more await. Unsolved Mysteries Of Quantum Leap With Donald P. Bellisario Unsolved Mysteries Of Warhammer 40K With Author Dan Abnett SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 Steve Burke of GamersNexus Reacts To Their Top 1000 Comments On YouTube Modern Vintage Gamer Reacts To His Top 1000 Comments On YouTube How The NES Conquered A Skeptical America In 1985 Scott Manley Reacts To His Top 1000 YouTube Comments How Horror Works in Amnesia: Rebirth, Soma and Amnesia: The Dark Descent LGR's Clint Basinger Reacts To His Top 1000 YouTube Comments The F-35's next tech upgrade How One Gameplay Decision Changed Diablo Forever Unsolved Mortal Kombat Mysteries With Dominic Cianciolo From NetherRealm Studios US Navy Gets an Italian Accent How Amazon’s “Undone” Animates Dreams With Rotoscoping And Oil Paints Fighter Pilot Breaks Down Every Button in an F-15 Cockpit How NBA JAM Became A Billion-Dollar Slam Dunk Linus \"Tech Tips\" Sebastian Reacts to His Top 1000 YouTube Comments How Alan Wake Was Rebuilt 3 Years Into Development How Prince of Persia Defeated Apple II's Memory Limitations How Crash Bandicoot Hacked The Original Playstation Myst: The challenges of CD-ROMWar Stories Markiplier Reacts To His Top 1000 YouTube Comments How Mind Control Saved Oddworld: Abe's Oddysee Bioware answers unsolved mysteries of the Mass Effect universe Civilization: It's good to take turnsWar Stories SITREP: DOD Resets Ballistic Missile Interceptor program Warframe's Rebecca Ford reviews your characters Subnautica: A world without gunsWar Stories How Slay the Spire’s Original Interface Almost Killed the GameWar Stories Amnesia: The Dark Descent - The horror facadeWar Stories Command & Conquer: Tiberian SunWar Stories Blade Runner: Skinjobs, voxels, and future noirWar Stories Dead Space: The Drag TentacleWar Stories Teach the Controversy: Flat Earthers Delta V: The Burgeoning World of Small Rockets, Paul Allen's Huge Plane, and SpaceX Gets a Crucial Green-light Chris Hadfield explains his 'Space Oddity' video The Greatest Leap, Episode 1: Risk Ultima Online: The Virtual EcologyWar Stories More videos ← PREVIOUS STORY NEXT STORY → Related Stories by Taboola Windows 8 privacy complaint misses the forest for the trees Ars Technica Cops wanted to keep mass surveillance app secret; privacy advocates refused Ars Technica Decrypted: Westworld goes full blackhat Ars Technica Warrantless surveillance lawsuit thrown out Ars Technica EFF calls Ubuntu's Amazon search result feature a \"major privacy problem\" Ars Technica Pornhub attacks states for passing “unsafe” age-verification laws Ars Technica Today on Ars STORE SUBSCRIBE ABOUT US RSS FEEDS VIEW MOBILE SITE CONTACT US STAFF ADVERTISE WITH US REPRINTS NEWSLETTER SIGNUP Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox. Sign me up → CNMN Collection WIRED Media Group © 2023 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 1/1/20) and Privacy Policy and Cookie Statement (updated 1/1/20) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy. Your California Privacy RightsCookies Settings The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices",
    "commentLink": "https://news.ycombinator.com/item?id=37993702",
    "commentBody": "1Password detects \"suspicious activity\" in its internal Okta accountHacker Newspastlogin1Password detects \"suspicious activity\" in its internal Okta account (arstechnica.com) 191 points by simonpure 9 hours ago| hidepastfavorite94 comments jon-wood 9 minutes agoI think something people are missing here is that outsourcing your SSO isn&#x27;t just about whether it&#x27;s technically easier to do so, or having the competence to run it. A significant factor is also being able to say on contracts with clients that you use a reputable provider for SSO, who are then on the hook for dealing with all the documentation around precisely how they do that, and how they ensure key material is secured.In the case of 1Password its a bit more interesting, since they presumably already have all that sorted because that is literally the product that they&#x27;re selling, but in most cases it&#x27;s easier to say \"no one in the organisation has access to keys\" rather than \"no one has access, except Bob, because he runs the SSO server, but we really trust him you know\". reply varjag 2 hours agoprevIt&#x27;s remarkable how C memory safety vulnerabilities are the most talked about. But the most impactful ones are due to insight collapse from over-complexity caused by following so-called best design practices. reply CGamesPlay 3 minutes agoparentOrganizational bugs can be very impactful to the organization that has them. But the memory safety bugs are typically exploitable via automatic methods and affect all organizations using the software. For example, Heartbleed was so talked about because it was so impactful. reply c0balt 1 hour agoparentprevWhat can be measured tends to get optimized. We have numerical, easily gatherable data on software vulnerabilities. However we, imo, lack information on how (and sometimes even when) organizations get data stolen. The reasons behind the latter are most likely complex, as they pertain to humans and as auch it&#x27;s easy to look for a rescue in technology. reply badrabbit 36 minutes agoparentprevIt&#x27;s just complexity. Stuff gets missed, stuff gets updated but the cascading effect it will have on other logic gets overlooked,etc... complexity breeds vulnerability. But scdlt, layered security defenses and countermeasures can reduce risk. I like to think our inability to grasp vast levels of complexity is the root cause. reply usrbinbash 2 hours agoprevAnd people keep asking me why I use a self-hosted, self synced, password manager instead of using one of those super-easy, super-helpful online services to do it for me.For the same reason why I don&#x27;t throw my apartment keys into the local train stations safebox. reply mirzap 1 hour agoparentYou may feel safer that way, but it is not. If a dedicated attacker can breach Okta, they can surely breach your self-hosted, self-synced password manager you manage, which you forgot to update on time, or you don&#x27;t get an update on time.Remember, these organizations fix the issues weeks, sometimes months, before they release the statement.If you use open-source and a critical bug is found, you&#x27;ll get a patch with a press release, while all other large services fixed that already. For average Jane or Joe, the risk-benefit ratio favors services against self-hosted solutions. reply offices 44 minutes agorootparent>If a dedicated attacker can breach Okta, they can surely breach your self-hosted, self-synced password manager you manageThey can&#x27;t and they won&#x27;t because these are different threat models with vastly different incentives. reply leokennis 29 minutes agoparentprevI understand your point, but if my password vault was a self hosted piece of software and a self hosted vault file, I&#x27;d be nervous every day of losing data. reply trumpeta 0 minutes agorootparentI think the self-hosted bit is just for syncing, as long as you have multiple devices its not likely to lose data even if you don&#x27;t follow the 3-2-1 backups. reply bmikaili 2 hours agoparentprevIrrelevant. 1password passwords are encrypted with a key only you have. I HIGHLY doubt that you can keep your homeserver more secure than 1password can its servers. reply SCHiM 1 hour agorootparentSecurity is not an absolute measure. It&#x27;s a cost&#x2F;benefit tradeoff. 1Password may have customers that make it economical for an adversary to spend $$$$ to breach it despite \"better\" security, whereas your \"less\" secure home setup may not be worth the effort. reply offices 41 minutes agorootparentprevIrrelevant. The risk of a targeted attack is much lower than the risk of being part of an online attack. I doubt there&#x27;s anyone on this site who hasn&#x27;t been part of one of the latter but for someone to decide that I have something worth stealing they must first know that I exist. reply vladvasiliu 32 minutes agorootparentprev> 1password passwords are encrypted with a key only you have.Are they? How does the vault password recovery work, then? reply usrbinbash 1 hour agorootparentprev> 1password passwords are encrypted with a key only you have.So is my password store.> I HIGHLY doubt that you can keep your homeserver more secure than 1password can its servers.I also highly doubt that my trousers pockets are harder than the 1.5cm thick hardened-steel-doors of the storage lockers at the local train station, or that my pyhsical constitution is superior to those of the trained security guards they have there.And yet, guess where the keys to my apartment are kept. Hint: Not at the train station. reply realusername 2 hours agoparentprevSame, I use the pass command line + git (since it&#x27;s integrated with it) and I never had a single problem until now.Additionally I can even use it in scripts.There&#x27;s no server breach, no web extension exploit, no server errors making me lose me all my passwords, it just works. reply fofoz 2 hours agoparentprevI&#x27;m curious. Which one are you using? reply usrbinbash 2 hours agorootparenthttps:&#x2F;&#x2F;www.passwordstore.org&#x2F; reply DanielHB 2 hours agoparentprevwhat do you think about Brave password manager? It seems to fit your bill reply usrbinbash 1 hour agorootparentNever used it, so can&#x27;t say anything about it. I prefer `pass`. It certainly fits my bill, and is easy for me to audit myself. reply insanitybit 7 hours agoprev> The IT team member’s credentials for all systems were rotated, switched to only using a Yubikey for MFA,I hope this spurs them to switch all employees to use Yubikeys for 2FA. Anything less than FIDO2 is really weak.Can someone explain why people still choose Okta? I personally feel way more comfortable using GSuite as an IDP. Okta suffered a pretty terrible breach and, candidly, I hadn&#x27;t heard great things about their security practices before that. reply Nextgrid 7 hours agoparentYubikey or other browser-based MFA would not have mitigated this attack - the attacker obtained a valid administrative session token from _after_ any MFA would&#x27;ve been completed. MFA or not, this attack would&#x27;ve happened regardless.Enforcing hardware-based MFA is good practice and may protect against future attacks (the attackers might be back with a spear-phishing campaign?) but is completely irrelevant to what&#x27;s actually happened here.> Can someone explain why people still choose Okta?Nobody&#x27;s been fired for buying IBM. Also blame outsourcing - if your run your own Keycloak and get pwned it&#x27;s on you, if it&#x27;s Okta then it&#x27;s not your problem. reply jakobson14 6 hours agorootparentClassic observation about security: any amount of damage is acceptable so long as you&#x27;re not culpable. All you have to do is get insurance to cover it and&#x2F;or tell your data-breach&#x27;d users to suck it up. reply insanitybit 6 hours agorootparentprev> MFA or not, this attack would&#x27;ve happened regardless.Yeah sorry, I shouldn&#x27;t have implied otherwise&#x2F; should have been clearer about that. I just thought it was notable that admins were not using stronger 2FA. This is a company that owns password management, it seems like having proper auth should be a number one priority.Of course, once a session token is created you are past the initial point where a 2FA mechanism like a Yubikey would help.> if your run your own KeycloakSure but I think most people would consider Google to be a far safer company than Okta, no? If not I think that they should be. TBH I feel like \"session token used from a totally different computer&#x2F;UA&#x2F;IP&#x2F;Region\" is something Google may actually have caught. reply psidebot 3 hours agorootparentprevFIDO2 wouldn&#x27;t have helped the customers&#x27; accounts since valid session tokens were obtained. However, hardware tokens for the Okta customer service accounts may have blocked the threat actor&#x27;s access depending on the (undisclosed) method of attack. reply hnlmorg 1 hour agoparentprev> I hope this spurs them to switch all employees to use Yubikeys for 2FA. Anything less than FIDO2 is really weak.The session cookies were stolen. 2FA has nothing to do with this.> Can someone explain why people still choose Okta? I personally feel way more comfortable using GSuite as an IDP. Okta suffered a pretty terrible breach and, candidly, I hadn&#x27;t heard great things about their security practices before that.Have you actually used Google Workspace for anything serious? It&#x27;s one of the least capable IDPs out there, with Okta being one of the most capable. Comparing the two is like comparing a bicycle to a motor bike because they both have two wheels. Frankly, I&#x27;m surprised to read anyone on a technical forum recommend Google Workspace as an IDP. reply dkobia 11 minutes agorootparentI’ve used and implemented both. A case can be made for Google Workspace as an IDP if you don’t need all the bells and whistles. It is extremely secure and generally, engineering practices at Google give me much more confidence than Okta.I’ve spent quite a lot of time interacting with Okta support over system issues and frankly that experience does not leave me assured. My sense is that perhaps they’re wrangling software that has grown exponentially in size and complexity as they try to accommodate the myriad use cases. reply lopkeny12ko 4 hours agoparentprevHardware keys do not prevent session hijacking. If your IT department is empty-headed enough to share active session cookies, you are toast no matter what MFA you use. reply rbut 3 hours agorootparentTying sessions to the user&#x27;s IP would help prevent this, but it comes with it&#x27;s own issues.Even better don&#x27;t put admin tools on the open internet, put them behind a VPN like wireguard. Then if the session cookies are stolen, they can&#x27;t even access them anyway. reply g_p 2 hours agorootparentI wonder if we will see \"zero trust\" going full circle, and back to isolating privileged systems from the internet, on the basis of endpoint compromises stealing user session cookies.Just making the authentication and service endpoints inaccessible online significantly reduces the attack complexity. reply DanielHB 2 hours agorootparentprevto be fair session cookies at least expire at some point. You can&#x27;t completely hijack the users account with them. reply usrusr 42 minutes agorootparentIf you have a hardware second factor that does not require user interaction (or that has a low-security tier that does not require user interaction), couldn&#x27;t that be used to transparently re-validate existing sessions with zero inconvenience cost? Keep challenging that factor with the existing session and a nonce. Am I missing something?And even if you don&#x27;t have that, when authentication is your core business you might want to harden your sessions against transmission contents getting in the wrong hands by setting up an additional factor in the browser&#x27;s local storage that gets challenged without putting the key on the wire. Sure, that local storage is no secrets vault, but you don&#x27;t write some existing secret there, you set up an additional key that would protect e.g. from a .HAR playback. That&#x27;s the nature of multi-factor tiered defense, protection from just one angle is protection nonetheless, perfect must not be the enemy of good. reply paranoidrobot 6 hours agoparentprev> Can someone explain why people still choose Okta? I personally feel way more comfortable using GSuite as an IDP.GSuite as an IDP is very very limited. Sure, it checks that box as \"Yes, is IDP\"However if you want to do much beyond \"can connect\", it&#x27;s either difficult or impossible.Take for example you&#x27;re an organisation that has all employees in GSuite.You also have an AWS organisation, and need to provide access - well, AWS SSO[1] is the recommended way to do this. I set up the connection, and people can now connect.However there&#x27;s some gaps:There&#x27;s no automatic user [de]provisioning into AWS SSO, based on GSuite user groups. (You could write some code to do this via the SCIM support in SSO, but you have to maintain it)There&#x27;s no way on either the GSuite or AWS SSO side to enforce an MFA check when the SSO session is being set up.GSuite doesn&#x27;t let you require an MFA check before authenticating to SAML applications.AWS SSO doesn&#x27;t allow forcing MFA check when using an IDP, even though it does if you use it&#x27;s internal Directory.Okta, and similar products (can) do those things for you, and allow some of those MFA checks to be based on what endpoint is being used. At least according to their marketing materials and sales people. I&#x27;ve never actually done it myself.I guess the tl;dr is that Okta provides a lot more options for automation and security glue between the identity provider and consuming application(s).[1] When I say AWS SSO, I mean specifically the AWS product: \"AWS IAM Identity Center (Successor to AWS Single Sign-On)\" reply insanitybit 5 hours agorootparentInteresting, thank you! I&#x27;ll note is that GSuite does allow for you to enforce Context Aware Access checks on every SSO, though that does not include a separate 2FA in the traditional sense.Lack of auto-provisioning seems like the biggest issue to me.> There&#x27;s no way on either the GSuite or AWS SSO side to enforce an MFA check when the SSO session is being set up.I don&#x27;t know what you mean here but I&#x27;m curious if you wouldn&#x27;t mind?Much of what you&#x27;re talking about seems to be when a 2FA is forced. With GSuite it&#x27;s forced on login, and CAA is forced on SSO, and that&#x27;s it. If you want other 2FA prompts (such as with AWS) those are configured through that service. I think you&#x27;re saying that Okta would allow you to force the 2FA on login to and also then when you want to access some other system via SSO it would ask you to 2FA again? reply paranoidrobot 5 hours agorootparent> Context Aware Access checks on every SSOIt&#x27;s only available in the Enterprise plan levels.> I don&#x27;t know what you mean here but I&#x27;m curious if you wouldn&#x27;t mind?Using the prior example where GSuite is my IDP. If I want to require an MFA check before granting access to AWS SSO - I&#x27;ve got no way of doing this.CAA might help, but if I want to be explicit \"Hey, this has access to customer data - we&#x27;re always going to do an MFA check on this access\", there&#x27;s no good way of doing this.Using an intermediary like Okta would allow you to do that additional level of checking.e: To be clear, I&#x27;m using AWS SSO as the destination application as an example. There&#x27;s other applications that you might want to control access to that also have particularly sensitive data where you want to re-verify that someone else hasn&#x27;t just walked past an unlocked laptop and decided to poke around. reply StressedDev 4 hours agoparentprevDo you have any proof Okta is better or worse than any other solution? Measuring security is very hard.Here is the evidence I have seen regarding Okta&#x27;s security: 1. The had a breach last year. 2. They just had another breach. The breach was in their customer service department&#x2F;system. 3. They may or may not have been slow to disclose the breach (remember, they may not have realized they were breached because they may get a lot of false breach reports and they may not have found evidence of a breach until recently). 4. They did not give credit to the customer who first reported the breach. 5. They may not have communicated with the customer after the customer reported the breach.Here is what we don&#x27;t know:A. How skilled was the attacker. Skilled attackers are better at covering their tracks and harder to catch.B. How many breaches has each ID provider had?C. How many breaches has each ID provider detected?D. How many breaches has each ID provider detected and covered up?E. How many security bugs are in each provider&#x27;s service? How serious are the bugs? How easy are they to find?F. How good is the provider at detecting breaches?G. How well are the provider&#x27;s employees trained?H. What percentage of the ID provider&#x27;s employees care about security. A lot of people in the tech industry (software engineers, IT&#x2F;sys admins&#x2F;devops, managers, etc.) claim they care about security but their actions say otherwise. Examples include using easily guessed passwords, not patching software&#x2F;dependencies, writing insecure code (buffer overflows, SQL injection, cross site scripting errors, etc.).My main point is bashing Okta because they reported a breach does not prove Okta&#x27;s product is any worse than any other product because we just don&#x27;t have the information. We don&#x27;t know how good other products are and it is even possible Okta is better than some or all of its competitors (it could also be worse). reply CalRobert 5 hours agoparentprevI use Okta because I used Auth0 years ago and it&#x27;s a pain to switch. reply bsder 7 hours agoparentprev> Can someone explain why people still choose Okta?Most people don&#x27;t choose Okta. Somebody at the executive level chooses Okta and everybody else gets to deal with it.Yubikeys mean that your IT department now does customer support for every single password issue instead of handing it off to the outsourcing company.MFA has two problems: the technical one (technical security aspects of implementing keys, fobs, phones, SMS, whatever) which is almost irrelevant and the social one (customer support, forgotten passwords, key through the wash, can&#x27;t get email, etc.) which is the gigantic one.Everybody wants to outsource the gigantic, dumbass customer support role of security. The problem is that everybody is also incentivized to cut corners once having done so.Which gives you Okta ... reply ghshephard 7 hours agorootparentAren&#x27;t Yubikeys for MFA and Okta for iDP somewhat orthogonal? A common pattern that I&#x27;ve seen is companies use both. reply insanitybit 6 hours agorootparentYes, they are unrelated. I brought up Yubikeys just because it was an interesting tidbit in the report. reply bsder 6 hours agorootparentprevThey are, my point (which wasn&#x27;t very clear) was that somebody needs to do the customer support.If you just do YubiKeys but not Okta, your staff takes all the calls. Yubi sure isn&#x27;t going to do the customer support when Employee #46 can&#x27;t log into Office 365 today.That&#x27;s why people outsource this to Okta and its ilk. reply ghshephard 5 hours agorootparentSo - I work for a company that uses Okta. Our Infosec&#x2F;IT group also rolled out Yubikeys. I need to work with IT when I&#x27;m having problems with my Yubikeys.When we SSO to Okta - they will for some applications (VPN, Github, etc..) require us to MFA with our Yubikey. But for some other, lower risk applications, MFA isn&#x27;t required.When an employee has difficulty connecting to one of the 84 applications that we SSO via Okta - they file a ticket with IT, not Okta. There is no way any employee would even know how to contact Okta, and there isn&#x27;t any way that Okta could troubleshoot for the employee anyways - the source of truth for their password (first factor) would be the corporate Active Directory server.Okta doesn&#x27;t (to my knowledge) provide any customer support (I guess they might work with IT if there is a service-outage) to our employees. It&#x27;s just an IdP SaaS. reply cdchn 4 hours agorootparentprevCan Okta actually manage your enterprise&#x27;s Yubikeys for you? I wasn&#x27;t aware that was a thing since I&#x27;ve never heard anybody use it - everybody just endured the burden of managing their Yubikeys themselves. reply insanitybit 5 hours agorootparentprevI think your point is still confusing. No one is suggesting replacing Okta with a Yubikey, so whether one chooses Okta to offload support requests or not has no bearing on Yubikeys. reply latchkey 7 hours agoparentprev> Can someone explain why people still choose Okta?Or 1password for that matter... do you really trust them as well?\"we are continuously enhancing our security measures\"How about not using Okta to begin with? reply ghshephard 7 hours agorootparentWho would you recommend as an iDP if not Okta? reply johnmaguire 6 hours agorootparentI&#x27;m partial to Duo SSO because I helped build it (though I haven&#x27;t worked there for years now.)There&#x27;s also OneLogin, Jumpcloud, or you can use Google Workspace and I think Azure AD too. reply vladvasiliu 38 minutes agorootparent> and I think Azure AD tooNot sure that \"security\" should be the top reason for switching from Okta to AzureAD.Also, as a \"user\" (in IT), AAD is a royal PITA to use, with stupid limitations, such as not supporting group hierarchies. And don&#x27;t even get me started on the horrid UX of the Azure portal. I&#x27;ve never used Okta in any capacity, though, so I don&#x27;t know if it&#x27;s any better. reply latchkey 7 hours agorootparentprevPersonally, I&#x27;m fine with Google Workspace. IMHO, their track record for corporate auth, over the last what... decade... has been very good. reply x0x0 2 hours agorootparentTheir security record is fantastic, but afaik they don&#x27;t do what okta does.Okta: comprehensive scim allowing your IT instead of random application admins throughout your company to manage user provisioning &#x2F; deprovisioning. Start pages that don&#x27;t require users to remember urls but instead show them a list of applications they can use. Adaptive MFA with IT-administered settings (though Google&#x27;s super-enterprisey solutions may have sth here.) reply Nextgrid 7 hours agorootparentprevAt this point any self-hosted option would do just as well. Not perfect, but not only it would require a targeted attack to pwn, but if you do end up pwned at least you weren&#x27;t paying tens of thousands a year for the privilege. reply thephyber 7 hours agorootparentThis is not a serious answer. It’s very unlikely that “any self-hosted option” actually competes with Okta’s IDP solutions, has really decent security, has very good logging features, has behavior analysis features to detect login&#x2F;session anomalies, and has security staff to respond to those threats quickly.Saying “just self-host anything” makes a massive assumption that your company can afford to compete against Okta&#x2F;Google for the same talent. Some companies can, but the vast majority of Okta’s user base can’t. You would be fighting against specialization and comparative advantage.It might be possible that there are significantly better options than Okta, but I have yet to find them. reply Nextgrid 7 hours agorootparent> has really decent securityOkta has a major insider threat problem though (either their employees&#x2F;subcontractors get pwned like last time, or their infra gets pwned like now). I would expect much better from a \"security\" vendor, and since they consistently fail at it, I wonder what else they fail at that we don&#x27;t (yet) know.> has behavior analysis features to detect login&#x2F;session anomaliesThis is what baffles me. Given the description of the attack some attacker reused a stolen session token from a different IP address (not sure if they bothered to spoof the UA) - how was this not immediately challenged, especially for a high-value account? I indeed expected this to get flagged immediately.> that your company can afford to compete against Okta&#x2F;Google for the same talentNot sure about Google, but given the (repeated!) breaches, Okta can&#x27;t compete for talent either, or that talent isn&#x27;t actually everything.A big advantage of self-hosting is that you reduce your exposure to opportunistic and \"for the lulz\" attacks - if someone breaches Okta, it&#x27;s trivial for them to automatically pwn everyone. If you self-host, they&#x27;d have to know you exist and target you specifically - that doesn&#x27;t scale. Plus you can layer extra security on top such as VPN and then your IdP is invisible from the outside and a potential attacker would first need a VPN exploit before they can even do the initial recon to find out what&#x27;s your IdP and its vulnerabilities. Can&#x27;t do that with Okta.The consistent pattern of breaches and their nature makes me believe they are not a serious vendor worthy of the price or the trust people put in them, and missing a better option I&#x27;d rather self-host - all else being equal, at least it would save on the fees. reply lopkeny12ko 4 hours agorootparentprev> Saying “just self-host anything” makes a massive assumption that your company can afford to compete against Okta&#x2F;Google for the same talent.I have always found this argument so interesting. I host tens of services myself on a Raspberry Pi, with better uptime than many of your favorite cloud services. If a company cannot find even one person, earning a software salary, to host an open source IDP for tens or hundreds of employees, either something is deeply wrong with the company, the sysadmin talent pool, or both. reply bostik 3 hours agorootparentThe problem isn&#x27;t hosting, it&#x27;s the maintenance and plumbing.Companies learn the same lessons painfully when it comes to build-vs-buy. There is no such thing as \"buy\". There is \"build\", and there is \"buy-and-build\". Purchasing and deploying (or in executive speak, \"implementing\") a particular solution is at best 30% of the work - and less than that of the cost. The remainder goes into integrations, maintenance, customisations, ongoing configuration, adapting to ongoing user behaviour changes, adapting to ongoing development needs, etc.Running an IdP is one of the very few ventures where four nines of reliability is still inadequate. Once you have a centralised auth, it CAN NOT break. reply m1keil 4 hours agorootparentprevAlso when you self host, you don&#x27;t need to \"compete\" with alternatives. Your goal isn&#x27;t to provide service on the same scale as the commercial alternatives, but to provide a service to solve your local problem. reply ghshephard 7 hours agorootparentprevI guess I&#x27;m curious as to how someone self-hosting would be able to perform their security better than a Tier 1 iDP. It would be the equivalent of trying to self-host email.Also - never having worked for a company that hosted their own - what&#x27;s the experience like - with Okta, you can essentially SSO onto hundreds (thousands?) of different cloud service providers. Similiar if you self-host? reply Nextgrid 7 hours agorootparent> I guess I&#x27;m curious as to how someone self-hosting would be able to perform their security better than a Tier 1 iDP.Not saying you can do better, just saying that you can get the same level of quality for free without paying for an incompetent & expensive snake-oil vendor.But if you want a non-exhaustive list, there are a few lessons we can learn at Okta&#x27;s expense:Not outsource support to low-wage boiler rooms could be a good start - that&#x27;s what got them their previous breach some time ago, and the current breach isn&#x27;t that far off although it seems more down to the support infrastructure than the people themselves.If you can, restrict access per IP address. Even better, if everyone works out of the office or VPNs into it, don&#x27;t expose the service publicly in the first place. Defense in depth, something we seem to have forgot in the process of putting everything on the public internet.If you see an existing session token suddenly show up with a different user-agent and IP address (not matching previous usage patterns or expected wifi-to-mobile handover), invalidate the session and ask the user to reauth again.If possible, high-value accounts need to be IP restricted in the first place to known IPs or at least subnets (if the employee is on a dynamic IP). reply mike_d 6 hours agorootparentprev> I guess I&#x27;m curious as to how someone self-hosting would be able to perform their security better than a Tier 1 iDP.If you use Okta, every single Okta support person is a super-admin in your environment with access to every role in every app. It is trivial to do better than that. reply nixgeek 5 hours agorootparentIt’s extremely unlikely that every Okta Support employee has this level of access, much less on a persistent ongoing basis.It would be nearly impossible to achieve this level of compliance certification if it were this simple and this broken.https:&#x2F;&#x2F;www.okta.com&#x2F;trust-page&#x2F;compliance&#x2F; reply Veserv 2 hours agorootparentWhy do you have a link: https:&#x2F;&#x2F;www.okta.com&#x2F;trust-page&#x2F;compliance&#x2F;to the list of Okta certifications in your bookmarks? You absolutely did not do a search for it just now because that is a stale link so there is no way you even clicked through that link before pasting it and you already knew what was supposed to be on that page.This is the current link: https:&#x2F;&#x2F;trust.okta.com&#x2F;compliance&#x2F;And anyways, yeah, those certifications are useless box checking garbage that a totally broken system can get.Solarwinds has most of those same certifications: https:&#x2F;&#x2F;www.solarwinds.com&#x2F;trust-centerand they are a total clown show. In fact, basically all of the clown shows have those because all most of those standards amount to is verifying your paperwork is consistent. reply_a9 8 hours agoprevhttps:&#x2F;&#x2F;blog.1password.com&#x2F;okta-incident&#x2F;Original Incident Report: https:&#x2F;&#x2F;blog.1password.com&#x2F;files&#x2F;okta-incident&#x2F;okta-incident... reply jrockway 6 hours agoparentThat is fascinating:> A member of the IT team was engaged with Okta support, and at their request, created a HAR file from the Chrome Dev Tools and uploaded it to the Okta Support Portal. This HAR file contains a record of all traffic between the browser and the Okta servers, including sensitive information such as session cookies. In the early morning hours of Friday, Sept. 29th, an unknown actor used the same Okta session that was used to create the HAR file to access the Okta administrative portalLike your bank tells you, don&#x27;t give the support person your password. reply tjoff 4 hours agorootparent> Like your bank tells you, don&#x27;t give the support person your password. Sure, but was the user aware what the HAR-file actually contained?At the least all active sessions should be cleared after sharing something like that. But that hinges on you knowing about it. Support should also make it mandatory&#x2F;automatic. reply thayne 3 hours agorootparentprevIt seems to me like the browser should not include cookies in HAR files by default. Sure, have a way to enable including cookies, but it should be behind a scary warning informing the user that the cookies likely contain sensitive data. reply usrbinbash 2 hours agorootparentHow about: People shouldn&#x27;t send around HAR files that contain sensitive information, or at least make sure the information contained is no longer sensitive (eg. by flushing active sessions)?HAR files are a debug tool. If I have to debug a problem with a webservice, I require them to contain all the information that was sent&#x2F;received by the browser. The browser arbitrarily deciding to delete part of that information, would make it worthless to me as a debug tool. reply usrusr 1 hour agorootparentReminds me of that banner Facebook writes to the browser console to warn people of pasting stuff that will hand over their session to third parties. Handing over a HAR is just as bad if there is any form of session involved.Browsers could add even more nag screens between the user and the tools, but those have zero effect once the assumption \"I&#x27;m talking to a person from the hoster\" is established. It&#x27;s the old \"put on a safety vest and a hardhat and you can walk anywhere\" hack that only training can protect you from. And even with the best training, you&#x27;ll never reach 100%. That&#x27;s why you need many tiers of your operation is as sensitive as selling a trust store.It&#x27;s well possible that 1Password are still far from being breached thanks to tiers, but it&#x27;s interesting to see even people working full-time on the conflict between authentication and convenience struggle with that balancing act. reply hunter2_ 3 hours agorootparentprevThis sounds to me like the correct way to plug this leak. It will benefit additional use cases involving the HAR export beyond individual support portals sanitizing it before storage.The \"Copy as cURL\" feature has the same issue. As does highlighting and copying request&#x2F;response headers to the clipboard.However, less sensitive data should ideally remain easily transferred, without much effort on the part of the user. reply delive 6 hours agorootparentprevI thought so too, but then was surprised to see: Based on the activity logs provided by Okta for their Support Portal, the HAR file had not been accessed by their support engineer until after the events of the incident reply fernandotakai 33 minutes agorootparent>Oct 21, 2023: Okta confirmed publicly that their internal support systems were compromised. This answers how the HAR file was accessed by the attacker and that the initial compromise was not through the employee’s laptop.how can \"the industry\" trust okta?! reply StressedDev 4 hours agorootparentprevThat tells me either the attacker either removed the access from the logs OR the attacker figured out how to access the HAR file without having the access recorded in the logs. reply dannyw 42 minutes agorootparentAll this says is that the support engineer didn&#x27;t access the file. It doesn&#x27;t say the attacker wasn&#x27;t logged accessing it. reply lelanthran 3 hours agorootparentprev> Like your bank tells you, don&#x27;t give the support person your password.Sure, but they uploaded it to the okta portal, not to any random support person. Most users would expect that people getting files from the company portal would be cleared to see confidential and sensitive stuff.Obviously not passwords, but still ... reply x0x0 2 hours agorootparentIdeally, okta would clear those sessions when someone uploads a har file. That way, you don&#x27;t have to trust users did the right thing... reply HtmlProgrammer 5 hours agoprevNow, will 1Password pull a Lastpass and slowly and silently keep updating their blogpost, each time growing from “a lil bit compromised” to “oopsie we lost all your data through negligence but we care about your privacy we swear” reply hn_throwaway_99 5 hours agoparentThis is am unwarranted comparison. First, one only need to look at the respective issue reports to see that 1P is much more operationally mature than LP.More importantly, 1Password&#x27;s architecture is fundamentally more secure than LastPass&#x27; given how password vaults are encrypted with essentially master password + uncrackable random string, vs LastPass&#x27; sole use of the master password when generating the encryption key. Not saying there aren&#x27;t other avenues for attack (e.g. supply chain attacks in the 1P apps), but if 1P reported that there was a big theft of encrypted vaults, I wouldn&#x27;t even bother changing my passwords, as opposed to what happened with LastPass. reply trvz 1 hour agorootparent> 1P is much more operationally mature than LP.Oh, is that why they removed Wi-Fi sync in 1Password 8?As a customer since version 4 I&#x27;m disappointed they use cloud crap like Okta and Notion. While those have their uses, if there&#x27;s any company that shouldn&#x27;t be doing so, 1Password is it. reply NegativeK 4 hours agorootparentprevI took it entirely as an opportune dig at Lastpass, not an actual expectation that 1Password will actual fall that low.That said, I am happy that 1Password&#x27;s salespeople will (hopefully) finally stop saying \"we haven&#x27;t been hacked like that other company.\" reply AceJohnny2 5 hours agoparentprevIn this case, Okta deserves more of your scorn. They&#x27;re the ones who&#x27;ve been slow to disclose their failures.For example: https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;how-cloudflare-mitigated-yet-ano... reply schainks 4 hours agorootparentThis. Okta leadership is asleep at the security wheel because printing money is the name of their game. reply FBISurveillance 3 hours agorootparentThey print money at -111M loss per quarter; I wouldn&#x27;t say they are succeeding at that either, technically speaking!Edit: when time comes rolling their debt at a higher interest rate (post-ZIRP) I expect them to trim down their workforce and start costcutting. They currently have 6k+ employees. reply trvz 1 hour agorootparentprev1Password shouldn&#x27;t be using Okta in the first place. reply Thorrez 6 hours agoprev>1Password now becomes the second known Okta customer to be targeted in a follow-on attack.Is Ars not aware that Cloudflare was also a victim?https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;how-cloudflare-mitigated-yet-ano... reply nixgeek 5 hours agoparentBeyondTrust reported the issue. Cloudflare is the first known Okta customer targeted, and 1Password is the second known. I think that’s what Ars is saying? reply cdchn 4 hours agorootparentMakes sense - those are the two juiciest customers I bet Okta has, also the best equipped to detect any potential problems vectoring via Okta. reply evanjrowley 6 hours agoprevWhy wouldn&#x27;t 1Password implement their own SSO rather than use Okta? reply StressedDev 4 hours agoparentWriting a SSO system is very hard. They have very high up time requirements and very high security requirements.1Password might select a different vendor or self-host an open source or commercial SSO system. Still, there are no perfect answers, and each choice has tradeoffs. Even worse, the new system is not guaranteed to be any better than the old system.One thing which frustrates me when reading a lot of these posts is a lot of people assume that security is easy, organizations should be perfect, and breaches only occur if an organization or service is terrible. None of these are true. reply m1keil 4 hours agorootparentTrue, but in this case we are literally dealing with a company that claims they are really good at data security and it is the reason why the users are paying them.It is one thing to outsource a monitoring solution. But outsourcing your SSO to a third party? They can only guarantee how well 1Password works, they cannot guarantee how well Okta works. reply pantulis 26 minutes agorootparentI am also baffled by this. It&#x27;s not like 1Password doesn&#x27;t have the chops to roll their own SSO in a secure way specially given that resorting to use Okta puts you just on top of their attack surface. reply clwg 2 hours agorootparentprevYou&#x27;re absolutely correct. Identity and SSO are hard and require a high degree of competency to do well, and they&#x27;re massively impactful when they go wrong.I think the problem is trust. So the question is, why would 1Password trust Okta? reply taspeotis 7 hours agoprevDid they detect it again?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37991863 reply ChrisArchitect 7 hours agoprev[dupe]https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37991863 reply azifali 3 hours agoprevMaybe it is time for a decentralized vault. We&#x27;ve built this for Privileged access - https:&#x2F;&#x2F;authnull.com.Demo video here: https:&#x2F;&#x2F;authnull.com&#x2F;videos&#x2F;2023-07-01-passwordless-auth-dem... reply computerfriend 1 hour agoprev [–] Centralised authentication is a mistake. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "1Password, a password manager, has noticed suspicious activity on an internal account provided by Okta, an identity and authentication service that recently had a security breach.",
      "Despite the suspicious activity, 1Password confirmed there was no breach of user data or vulnerable systems; investigations are underway to ascertain how the attacker accessed the account.",
      "This incident is the second known targeted attack on Okta's customer and hints at the possibility of more customers being involved in the near future."
    ],
    "commentSummary": [
      "The summary delves into a security breach in Okta's internal accounts, igniting concerns about the security measures implemented by the company.",
      "The conversation debates thoroughly on the merits and demerits of password management via online services, the complexities in software vulnerabilities, and weighs in on self-hosting versus using third-party identity providers.",
      "It brings attention to a security breach via Okta affecting 1Password, a widely used password manager, promoting a discussion on the necessity of a decentralized vault for password management and criticism of centralized authentication."
    ],
    "points": 191,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1698108956
  },
  {
    "id": 37991746,
    "title": "Marcel the Shell",
    "originLink": "https://www.marceltheshell.org",
    "originBody": "Skip to Main Content marcel About Examples Tutorial Try Blog Participate A Modern Shell Marcel is a shell. The main idea is to rely on piping as the primary means of composition, as with any Unix or Linux shell. However, instead of passing strings from one command to the next, marcel passes Python values: builtin types such as lists, tuples, strings, and numbers; but also objects representing files and processes. To explore marcel, read this tutorial.",
    "commentLink": "https://news.ycombinator.com/item?id=37991746",
    "commentBody": "Marcel the ShellHacker NewspastloginMarcel the Shell (marceltheshell.org) 188 points by jdblair 12 hours ago| hidepastfavorite123 comments mpweiher 5 minutes agoMarcel the author here. Didn&#x27;t know I was also a shell, though I do also have one that is somewhat similar in concept.While taking an existing programming language like Python is an obvious choice (and one that&#x27;s been made a bunch of times), I think that ultimately you need a language where something like a pipe (of objects or text) is not bolted on, but a natural consequence of a more general view of programming based on architectural interconnection.\"Pipes and filters\" is an architectural style. And it is itself a polymorphic style, meaning there can be substyles that pass objects and substyles that pass bytes, substyles where the filters are processes and substyles where filters are components within a process.So: good direction, more of this! reply larodi 4 hours agoprevFirst of all - Linuxes and alike desperately need something like this shell becoming standard. And second - I always wonder how all these great minds who where throwing rubbish at Microsoft ever since... somehow forgot to mention that same company created important product called PowerShell like 20 years ago. And you know PowerShell is so good already you can easily drop it in any OS&#x2F;X, Linux and it actually works. No one, except for Jeffrey Snover figured it out on time, there is great interview here - https:&#x2F;&#x2F;evrone.com&#x2F;blog&#x2F;jeffrey-snover-interview.But for PowerShell to become Python on Perl steroids on top of all the .NET and COM+ there is, well, of course it took years, and top engineers to work on it, but also was needed an unified interface (API) to the underlying OS magic. Which is not there in Linux the same sense .NET became \"available\". OS&#x2F;X has something similar to COM+ called CORBA which was left half-baked at best. Python is not .NET, sorry. Not anywhere near.Someone may say the UNIX ideology is about your programs doing one thing at time, and having this STDIN->munch->STDOUT approach. But these streams never got any structure, and ppl out there been creating great tools to fill this gap, tools such as - jq, mlr, xidel to name a few. perhaps we should include ack, ag and rg in the list.You know, guys, you hard-loving bash die-hards and sed+awk magicians, you should give this PowerShell thing a try before inventing the wheel again. And before legacies you wrote 20 years ago become as difficult to support as COBOL. Oh yeah, and PoSH is open source, based on open-source runtime, and available in brew&#x2F;apt&#x2F;yum...Disclaimer: I do not work, and have never worked for MS (Guido does now!). Have used DOS since 6.22, FreeBSD since 8th version, Debian since v5, and Windows since v3.1. I did Perl for 20 years, actually I gave Perl classes in some university, still doing fair amount of Python, and accidentally discovered PowerShell 3 years ago. I&#x27;m not a .NET advocate, although I can tell the good parts. reply skrebbel 3 hours agoparentIn defense of the Microsoft-haters, powershell is a fantastic idea with terrible ergonomics. When they first released it I was very excited but, well, it’s just awful to use.Terrible Get-Finger-Twister -Recurse -Awfully commands, quirky aliases (you can type “curl” but it takes none of curl’s parameters because it’s an alias for Get-WebRequest-Annoyingly or whatever they called it), simple scripting things such as “include file relative to current script” (and not relative to current working directory), etc etc: anything that should’ve been simple and easy was neither.I’ve stopped paying attention, so maybe they fixed this since then but it really wasn&#x27;t a very well done system during its first decade or so. reply pjmlp 2 hours agorootparentAlias, code completion and nice IDE tooling is the trick, not being stuck in UNIX like CLI mentality. reply jampekka 1 hour agorootparentNeeding an IDE for a shell!?\"Tooling\" is a design smell. It&#x27;s building hacks on hacks to make bad design and lack of understanding somewhat manageable.For better systems all you need is a shell and a text editor.That said, we do need a better shell. But definitely one with UNIX and CLI mentality. reply 9dev 46 minutes agorootparentEmulating a printer connected to a typewriter is a design smell. reply jampekka 25 minutes agorootparentI agree. It maybe wasn&#x27;t design smell when it was designed but 50 years later it definitely is a design&#x2F;culture smell.Doesn&#x27;t make \"tooling\" any less smelly though. reply 9dev 1 minute agorootparentMaybe it is time to rethink what a terminal is, and get rid of the restriction to be text-only? There is really no reason for that, other than Typewriter heritage. pjmlp 11 minutes agorootparentprevWelcome to the world of Lisp Machines, Xerox PARC and ETHZ.Unfortunely taken away due to UNIX&#x27;s free beer offerings. reply 9dev 1 hour agorootparentprevThat is the key. I will never understand why we’re stuck in a world of TeleType emulators, while having all the technology available to make Terminals with proper autocomplete, suggestions and inline widgets possible.And we’re probably not getting there if people insist on cryptic shortcuts instead of semantic naming, just because they’re inclined to type everything out manually. It’s like those developers writing their code in Notepad++ and pretend that’s the way. reply vetinari 1 hour agorootparentprevAnd yet, there&#x27;s no code completion for powershell so nice, as fish provides. In this area, Powershell (plus addons, like oh-my-posh) just mimimcs existing popular bash&#x2F;zsh capabalities. reply pjmlp 8 minutes agorootparentFish isn&#x27;t UNIX, and stating that Powershell just mimics existing popular bash&#x2F;zsh means your not aware of Powershell capabilities versus bash&#x2F;zsh.Since when do bash&#x2F;zsh offer a full sane programming language, not relying in external executables, a full blown language framework ecosystem, ability to load shared objects and importing public symbols as functions, and interoperate with D-BUS (as COM counterpart) as if client bindings were functions (again withouht external processes)? reply hug 1 hour agorootparentprevThe verbosity is a positive, so long as you understand the constraints in which it works. Cmdlets are specifically Verb-Noun, where the list of verbs is restricted to an approved list (Get, Set, Add, Remove…) and the noun naturally follows what you might expect.Want to get an organisational unit from Active Directory? Turns out the command is Get-AdOrganizationalUnit. Discoverability is built in. All of the switches are the same. Is it -R or -r for recurse on the Unix command to list OUs from LDAP? What is the command name, anyway? I dunno, but I know the flag I need is -Recurse on Powershell.Want to dump your DNS zones? Get-DnsServerZone is too verbose, obviously, so “cd &#x2F;var&#x2F;named&#x2F;data && grep &#x27;\\\\(. *A *[0-9][0-9]*\\\\)\\\\|\\\\(..*CNAME..*\\\\)&#x27; db.*” is a much better option (‘scuse the escaping on that regex). Glad we could avoid the long command names.Born of experience, maybe. Don’t know what the command might be? Get-Command dnszone* saves the day. I suppose I could ask GPT-4 for the regex for the bind dbs, otherwise. These are all things I can teach juniors in about fifteen minutes flat. You don’t need to learn three different Turing complete languages, all of which overload the same set of flags with different operations, just to run an operation against a bunch of files. Familiar, shorthand, and obtuse is not better just because it’s familiar. reply anticrymactic 2 hours agorootparentprevWhile I tend to agree, a lot of commands also have pretty good aliases.For example `iwr` for Invoke-Web-Request.Also the full names are only expected to be used in scripts to maintain readability. No one types that in the console. Also ALL Parameters can be abbreviated if they are unique. If no other Parameter starts with R then -R is enough for -Recurse. (there are some quirks with this, but generally pretty intuitive)And using select or for-each on actual types is magical, instead of grepping&#x2F;shedding&#x2F;parsing a maybe standardized string, with completely unsensical names (like grep or sed)If you give bash and pwsh the same time and love, they will become both pretty ergonomic reply Maken 2 hours agorootparent>Also ALL Parameters can be abbreviated if they are unique. If no other Parameter starts with R then -R is enough for -Recurse. (there are some quirks with this, but generally pretty intuitive)So, adding a new parameter starting with R to any command is a breaking change that will crash every script using it? Sounds like a terrible idea. reply Pet_Ant 1 hour agorootparent> So, adding a new parameter starting with R to any command is a breaking change that will crash every script using it?In a script, write it out in full. When manually typing it’s okay to take shortcuts. There is always a tension between ergonomics and safety. reply porridgeraisin 41 minutes agoparentprevToday, we use json. How do we integrate it into our shell scripts? That&#x27;s right, we simply make a tool (jq, miller) that takes stdin json, and _continue_ to use the agnostic, untyped tools alongside it, because they are just that, agnostic.In 20 years when we use BGHY or whatever other format, we can use it alongside existing tools by simply... Making a tool that takes stdin in that format. reply kunley 2 hours agoparentprevAm I the only one who actually gave Poweshell a try and found it to be a nightmare? reply pjmlp 2 hours agoparentprevFor all the praise it gets, PowerShell is basically the REPL environment from Xerox PARC (Smalltalk&#x2F;Interlisp-D&#x2F;Mesa&#x2F;Cedar), ETHZ(Oberon), Lisp Machines, finally making into mainstream computing.On OS&#x2F;X you would need to look into Apple Scripting, XPC and Objective-C runtime, for a similar COM like experience, by the way. reply Tabular-Iceberg 3 hours agoparentprevI hear you, and I have tried it, but the commands feel gratuitously different to me.Also they squandered the opportunity to make the output interactive like with the Lisp machines. That would also have helped smooth the learning curve. reply buildartefact 2 hours agorootparentThe worst part of it is they aliased a bunch of common posix command names to their power shell equivalents but then they have different flags or semantics. Works fine until it trips you up destructively. reply Tabular-Iceberg 2 hours agorootparentThey even made their own broken curl, which to me is straight up trademark infringement (ethically speaking at least, IANAL)Making alternative implementations of the core utilities is only customary, but the curl name is is directly tied to the reputation of Daniel Stenberg, which is one of exceptional skill, integrity and attention to quality and security. reply vetinari 1 hour agoparentprevNo.Powershell structured pipe might look beautifully to architecture astronauts, but it is a step back.The value of the component is the higher, the more components it can communicate with. Pure stream pipes in unices are the universal language; object pipes in powershell break the language in many incomprehensible fragments, and each component there needs \"translator\" for each specific fragment it can understand on input or output. Yes, it means that in the unix environment you may need some tool to be a middleman to extract only few things from the bigger stream; but these tools are also universal, unlike the need to understand specific piped object in the powershell world.CORBA wasn&#x27;t left \"halfbaked\". It was too complex for its own good, and unlike COM, there was nobody interested in pushing it further, so it was left behind. For a more lightweight messaging, there are XPC (macOS) or dbus (linux). reply eviks 2 hours agoparentprevYou&#x27;re right on the text vs structure point, but then pwsh is unfortunately slow and unergonomic enough that makes the transition from a better modern shell (so, not bash) harder, especially with a better and more common language like python reply bayesianbot 2 hours agorootparentHave to agree with the slowness, I just used powershell for a month or two and thought it&#x27;s great.. Until one day I accidentally started fish and it felt so blazingly fast that I couldn&#x27;t go back to pwsh anymore.. reply riedel 3 hours agoparentprevI was immediately thinking powershell. I have been doing some Powershell scripting for building chocolatey packages: it weirdly did not feel like shell though and my muscle memory of POSIX commands fails me on the terminal I guess.What I was wondering though: can you easily access Powershell data types from python? reply mgaunard 1 hour agoparentprevsed and awk are simple tools; choosing an entirely different non-standard tool just because you can&#x27;t learn them seems a bit overkill. reply geophile 10 hours agoprevHi, I’m the author of Marcel. If you like it and want to work on it, I can use volunteers, for developing features, debugging, doc, porting, improving the website, you name it. reply greenreptar 5 hours agoparentSurely there is some copyright infringement here? reply metabagel 3 hours agorootparentYou’re thinking trademark infringement. IANAL, but I wouldn’t worry about it. Worse comes to worst, you could rename it. That’s what Firefox did. reply benatkin 3 hours agorootparentThe likelihood of confusion is low. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_trademark_law#In... reply vetinari 1 hour agorootparentprev\"Marcel\" is a common male name in some parts of the world. That would make a trademark infringement claim somewhat difficult. reply sebstefan 1 hour agorootparentprevWhat&#x27;s the other thing named Marcel? reply fdgjgbdfhgb 43 minutes agorootparentMarcel the Shell with Shoes On [1], a recent Oscar-nominated film[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marcel_the_Shell_with_Shoes_On... reply kampanosg 1 hour agoparentprevHi! Happy to help&#x2F;contribute if you need an extra pair of hands :) reply linsomniac 5 hours agoparentprevCan I ask what you are using for the docs? reply dark-star 7 hours agoprevFor those who are wondering: The name is a reference to the 2021 movie \"Marcel the Shell with Shoes on\" https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Marcel_the_Shell_with_Shoes_On... reply eli 6 hours agoparentNo it was a bunch of cute little web videos by Jenny Slate at least a decade before there was a real movie. reply irjustin 6 hours agorootparentBook too! I read it to my kids all the time. Wish I could do the voice though. reply throwawaaarrgh 4 hours agorootparentprevWell aren&#x27;t we the little correctionist reply benatkin 3 hours agorootparentIt is a useful correction. This project predates the release of the movie: https:&#x2F;&#x2F;github.com&#x2F;geophile&#x2F;marcel&#x2F;commit&#x2F;bb6adacbb6b3a683ce... reply t43562 1 hour agoprevTo me the interest in this would be as a replacement for bash in makefiles with the hope that it could be cross platform and not require most of the utilities like sed&#x2F;awk etc. It&#x27;s an enormous pain to write x-platform builds with make because of shell issues - even with cygwin.For this to work one would probably want to embed python and have a pool of interpreters so as not to pay the startup cost of python on every job invocation.\"That Said\" I think passing around structures is not that useful to me - one is often trying to automate programs that are not written that way.Python&#x27;s pipe handling is complicated and horrible compared to bash and that&#x27;s the thing I&#x27;d really want to \"buy\" from this - together with more shell-like ways to copy, search, touch files that are platform independent. reply omgwtfusb 1 hour agoparentfor this purpose Just[1] with a python shebang line works great[1] https:&#x2F;&#x2F;github.com&#x2F;casey&#x2F;just reply abnry 12 hours agoprevHow does this compare to nushell? I am in the market to learn something other than bash and right now nushell seems like the best candidate. reply geophile 11 hours agoparentI wrote marcel. In my view, nushell and marcel are very similar. nushell has tabular output, which I haven&#x27;t thought was all that useful.Marcel is python-based. The nushell guys have had to invent a lot of language. By basing marcel on python, I don&#x27;t have to invent language. Any logic to be added is expressed in python. E.g, do a recursive listing of files and find those that changed in the last 3 days: ls -frselect (f: now() - f.mtime() 1){print \".\"$NF}; (NF==1){print \"\"}&#x27;sortuniq -cThat said, every time I look into one of these shells, I end up sticking with bash. When it gets to the point that I need something more powerful than bash and the Unix command line environment, I&#x27;d just as soon write a stand-alone program which I can check into version control, use on remote systems that don&#x27;t have one of these fancy shells installed, add proper tests, etc.This is a neat project though. I&#x27;ll keep an eye on it. reply Too 5 hours agorootparentUsing the output of find into another program is not safe due to risk of file names containing delimiters. You need to use find -exec.Good example of why machine readable output is important. Agree that the tutorial should showcase more and larger such examples. reply js2 4 hours agorootparentYes, I know that, but it&#x27;s also exceedingly rare for a filename to contain a newline and using -exec is extremely inefficient. I also wrote that on my iPad. Typically I&#x27;d use a combination of -print0 and xargs -0 for anything more formal than a one-liner on the command line.The larger bug in my example is that it fails if any of the directories in the path contain a \".\" in their name! reply eviks 2 hours agorootparentSo then why are you using such buggy examples as counterarguments? reply js2 2 hours agorootparentIt&#x27;s one example. I didn&#x27;t realize the mistake when I wrote it. I wrote my comment in good faith. What&#x27;s with the interrogation? reply rmwaite 4 hours agorootparentprevYou can always use -print0. I suppose there is some risk of a null slipping into a filename but I’ve never come across it myself. reply gnosek 4 hours agorootparent> some risk of a null slipping into a filenameOnly in some fairly esoteric environments: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Filename#Comparison_of_filenam... reply geophile 10 hours agorootparentprevAlmost forgot: I also switch from bash to Python at a low threshold. In that case, I find Marcel’s API useful. I can then do shell-like piping inside of Python. reply geophile 10 hours agorootparentprevI actually agree with most of this. I tend to use Marcel for ETL sorts of processing, quick database access with data munging on either side, cluster access, etc. it works fine for basic shell usage though.As for a more complex example: yes, the website has better examples, but they are also more involved to explain. reply lars512 1 hour agorootparentprevMarcel looks really interesting.As someone who&#x27;s leaned into Nushell deeply, I can tell you that the tabular and hierarchical data output is the major selling point of Nushell. For me and my team, who work with data and metadata constantly, it&#x27;s an incredible productivity boost.The major pains with Nushell are debugging pipelines that are too slow, having to learn the new language constructs, and process overhead for going in and out of Python for other pieces. reply prometheon1 4 hours agorootparentprevIn that case, is it even more similar to xonsh?https:&#x2F;&#x2F;xon.sh&#x2F; reply mito88 10 hours agorootparentprevmarshell the cell....sorry couldn&#x27;t resist.:) reply geophile 10 hours agorootparentMarcel is open source, so no. reply mito88 10 hours agorootparentI meant cell. reply geophile 10 hours agorootparentBut … but it’s a shell! reply mito88 10 hours agorootparentshure, of course.OK, enough!( ´ー`) ( ￣ー￣)ﾉ replyachenet 1 hour agoparentprevI&#x27;ve been using fish for a while myself, and I absolutely love it. The autocomplete is magic. reply hprotagonist 11 hours agoparentprevweird to say, but powershell should also be on your list. reply chaps 11 hours agorootparentYep. It&#x27;s a very clean, powerful and well thought out API. And I&#x27;m saying that coming from a place of love towards unix and its pipes. I&#x27;d almost argue it&#x27;s better than the unix model. Almost.Been able to give poweshell commands in FOIA litigation and its power is on full display with one liners where it&#x27;s hard for a gov agency to say no to something so simple. reply bee_rider 11 hours agorootparentThat’s really interesting; how do you use powershell in that context? I’m assume it isn’t justHere’s FOIA request for the output of the commandfind &#x2F;home&#x2F;jbiden -name “*secret*doc”haha. reply chaps 10 hours agorootparentIt was most notably helpful in litigation against the White House Office of Management and Budget. Was suing for one week of email metadata records (to, from, CC, bcc, time, date) in the last week of Jan 2017. They said that they had no way to complete the request. So we sent them multiple one liners that extracts the info from outlook 365, which pipes it to a csv export command. They told us that they didn&#x27;t run that sort of command as a routine practice, but we found a separate lawsuit that found emails of the exact command we were asking them to run. reply plugin-baby 4 hours agorootparentThis deserves a thread of its own! Is there any coverage of this case? reply chaps 3 hours agorootparentI need to write about it ;). We won that case just before the last election and unfortunately other things took priority at the time. But it&#x27;ll happen. Just first need to write about my IL supreme Court loss... reply wodenokoto 6 hours agorootparentprevThat sounds like a joke from archer:White House: We can’t do that.Litigator: Can’t or won’t?White House: either! reply galaxyLogic 6 hours agorootparentprevCool replybesnn00 11 hours agoparentprevHonestly any interactive shell + unix tools + any scripting language you feel comfortable with should cover the majority of things you may want to do on the command line. reply rbanffy 11 hours agorootparentFor a lot of 8-bit computers, BASIC was the default operating system shell. reply jw_cook 9 hours agoprev> A more powerful form of scripting can be done from Python, using the `marcel.api` module. With this module, you have access to the operators of marcel, neatly integrated into Python.This looks like an appealing feature! Having some more coreutils-like functions available in python (i.e., stuff that I wish was in the `os` module) would simplify some cases where I otherwise might have to resort to `subprocess` calls. The GPL license definitely narrows the number of situations where I would realistically be able to add this as a dependency, though. reply geophile 9 hours agoparentI&#x27;m not a license connoiseur. Why does GPL present a problem? (Not trying to be conentious, it&#x27;s a genuine question.) reply jw_cook 8 hours agorootparentGPLv3 is a \"strong copyleft\" license. It comes with some significant pros and cons compared to more permissive licenses like MIT and BSD. You can find more about the philosophy behind it here: https:&#x2F;&#x2F;www.gnu.org&#x2F;philosophyAs the author, a benefit it offers you is protection against someone selling your work or a derivative of it, or redistributing it with added restrictions.From a user&#x27;s perspective, the main downside is that using GPL software as a dependency makes the user&#x27;s project a derivative work, which requires them to license their own project with the GPL (or from a selection of other compatible copyleft licenses).In that sense it&#x27;s considered a \"viral license,\" i.e. everything downstream of the GPL software needs to adopt GPL. This is less of a problem for an application, but is more troublesome for a library (with many dependents of its own, with dependents of their own, and so on). It also means that if you use it in commercial software, you essentially need to open-source all of it.So in your case, just using Marcel as a shell with GPL doesn&#x27;t put any licensing obligations on the user, but using it as a library does.I hope that helps! Someone else feel free to chime in if I misrepresented any of that. reply qwertyzxcvmnbvw 7 hours agorootparentAnyone is welcome to sell GPL&#x27;d work, also someone else&#x27;s GPL&#x27;d work, as long as the license remains GPL and source code is available to the buyers of the work, under the GPL, if you distribute the software to them. If you don&#x27;t (i.e. SaaS, you run the software, it is never distributed further) then you don&#x27;t have to give the source to anybody! This is what the AGPL was created to address. reply jampekka 1 hour agorootparentprevGPL is about the freedom of the user.Anti-copyleft is about taking these away. Sad how so many have eaten this corporate proaganda campaign.https:&#x2F;&#x2F;www.gnu.org&#x2F;philosophy&#x2F;free-sw.en.html reply happymellon 4 hours agorootparentprevYes, in this scenario the LGPL was created so that I could create a library, and if anyone modified my library they had to share the improvements however using my library does not then apply the GPL to your code. reply rbanffy 11 hours agoprevI’m not sure this would be the way to go, but it’d be awesome if most Unix command-line tools had a way to accept and output JSON objects. reply geophile 11 hours agoparentThis is a place where marcel&#x27;s python grounding is really useful. Reading json, marcel generates a stream of nested dicts and lists. That stream can be turned back to json for output.Similar for CSV. reply all2 11 hours agoparentprevI will note that Powershell has typed inputs and outputs and that can be very powerful. Now if it weren&#x27;t so verbose... reply jen20 6 hours agoparentprevlibxo has gone some way towards making that a reality in FreeBSD. reply galaxyLogic 6 hours agoprevThis seems like obviously inspired by PowerShell. No? reply rahimnathwani 10 hours agoprevnext [–]However, instead of passing strings from one command to the next, marcel passes Python values: builtin types such as lists, tuples, strings, and numbers; but also objects representing files and processes.The bit before the semicolon sounds like what you&#x27;d do in a functional language like Elixir.It would be cool to be able to do this in regular Python programs. I know some libraries (like pandas) fake it by having a method return an object of the same class, allowing method chaining, but that doesn&#x27;t work universally. reply geophile 10 hours agoparentThat works. There is a Marcel API for Python that allows shell-like usage within Python programs. See this for an example: https:&#x2F;&#x2F;www.marceltheshell.org&#x2F;scripting-1 reply sriram_malhar 5 hours agoprevI like this a LOT.Not only don&#x27;t I have to get used to another language, I can lean on Python&#x27;s rich ecosystem. reply ubermonkey 11 hours agoprevIt&#x27;s cute, but I suspect the rightsholders for the character won&#x27;t be thrilled about the name appropriation. reply rbanffy 11 hours agoparentThey are two very different products in completely different markets. In many jurisdictions any such lawsuit would have no standing. reply hn_throwaway_99 10 hours agorootparentThat&#x27;s not correct. In fact, there was a relatively recent Supreme Court case where a \"joke products\" maker (I don&#x27;t remember the exact products, I think they were dog toys or something) basically made them look like Jack Daniels products. They argued it was a spoof, so should be protected. The court ruled against them, saying that even though they were selling in a totally different arena, they were still coasting on the public&#x27;s familiarity with the Jack Daniels brand, and someone might think that JD themselves had authorized the spoof products.I&#x27;m not sure that all applies here, but \"Marcel the Shell\" obviously belongs to and is associated with one specific brand, and the author of this nix shell is riding on that. It&#x27;s not like when someone tries to trademark \"Apple\" in 2 different contexts. reply gnopgnip 10 hours agorootparentThe Supreme Court case didn&#x27;t find the dog toy satirizing Jack Daniels was infringing, just that it was possible and a jury should decide rather than the case being dismissed. reply mistercheph 4 hours agorootparentRight, the court&#x27;s holding simply held that a trademark infringement claim concerning the commercial use of a trademark as a trademark was outside the scope of the Rogers threshold test (\"the claim must be dismissed unless the complainant can show either (1) that the challenged use of a mark “has no artistic relevance to the underlying work” or (2) that it “explicitly misleads as to the source or the content of the work.”\") and is moved directly to the next step which is the Lanham Act&#x27;s \"likelihood of confusion\" analysis.A trademark claim here might not be dismissed under Rogers, but I don&#x27;t think there is any jury that could ever find that consumers were likely to become confused about whether or not the command line tool Marcel the Shell was affiliated with the independent film cartoon character, and even if that could be established, unlike Jack Daniels, what $$$ damages were caused in trademark dilution? 3 figures? reply chaps 11 hours agorootparentprevBeing legally right and being morally right are often two very different things though. Like, they even have the full domain name of the original thing. If I were the owner of the original video and the subsequent film, I know I&#x27;d be, at least, annoyed. reply beeburrt 10 hours agorootparentWhat&#x27;s the original thing? Sorry, I don&#x27;t know the reference. reply 98codes 10 hours agorootparenthttps:&#x2F;&#x2F;www.google.com&#x2F;search?hl=en&q=marcel%20the%20shell reply dopidopHN 7 hours agoparentprevMarcel is just a name. Like Julien or Kevin. reply CharlesW 9 hours agoparentprevOn the bright side they&#x27;re unlikely to ever see it, since this one will never appear on the first few pages of search results without additional search terms. reply jawns 10 hours agoparentprevJust using the name \"Marcel the Shell\" probably isn&#x27;t enough to be legally actionable.Plenty of books, films, and TV shows have the same titles, which indicates that titles alone typically don&#x27;t enjoy the protection of exclusivity.Copyrighted characters and trademarks have a better chance of that, but those aren&#x27;t being appropriated here, just the name.\"Marcel\" is also a common first name, which makes it less likely that the creators of the film can claim any exclusive use of it, and \"the Shell\" is completely descriptive in this context, so unlikely to cause copyright issues. reply canucker2016 9 hours agoprevfor some reason I was singing the title to the Beatles&#x27; tune, \"Michelle\"...surprisingly works well.now i can&#x27;t stop doing it reply dopidopHN 7 hours agoparentMichelle, the sheeel.Yeah. It works. reply 1attice 10 hours agoprevI haven&#x27;t kept up on my Python-flavoured shells. How is this different with xonsh? What similarities does it have with xonsh?Looking for a compare&#x2F;contrast, not a ranking. Diversity is usually goodKudos to author, this looks really good reply geophile 10 hours agoparentThank you!Integration with Python: Xonsh defines a language that is a superset of Python and shell, as I understand it. Marcel takes a different approach, defining only a bash-like shell language. Any customization is done in Python, delimited by parens. The separation between shell and Python is much stricter. Also, Marcel provides a Python API so that you can write shell-like marcel commands inside of a Python program. Shelling out from Python is notoriously ugly; the marcel API fixes that.Sublanguages: In bash, there are lots of sublanguages, e.g. the arguments to &#x27;date&#x27;, awk, find, sed, and so on. Marcel&#x27;s idea is to use Python as the sublanguage, because so many people already know it. I guess xonsh has a similar approach here.Pipes: I think that xonsh, like more familiar shells, pipes strings. Marcel pipes python values in streams. So if you run ls, you don&#x27;t get a stream of filenames, you get a stream of File objects, and you can operate on them downstream.Database access: A stream of Python tuples is very similar to database query output. So database access is simple. There is an sql command which produces a stream of Python tuples. And a stream of tuples can be piped into the sql command, e.g. to populated a database.Remote access: If you have a cluster, you can use marcel to upload a file to all nodes of the cluster, download from the nodes, or to execute the same command on each, streaming results back as streams of python tuples, each with an element identifying the node from which the data originated. I don&#x27;t think xonsh does this.https:&#x2F;&#x2F;marceltheshell.org has lots of information and examples of all this. reply eviks 4 hours agorootparent> Marcel pipes python values in streamsThat&#x27;s indeed much better, all those untyped strings in shells in a bad old designThough hopefully xonsh will implement this as well https:&#x2F;&#x2F;github.com&#x2F;xonsh&#x2F;xonsh&#x2F;issues&#x2F;3967 reply 1attice 10 hours agoprevThis is very cool but it needs a nix package. :) I may try my hand at packaging it for Nix(OS) later this week reply geophile 10 hours agoparentIm the Marcel author. Get in touch, I’d love to do what I can to assist. reply besnn00 11 hours agoprevMessage to the person responsible for the site: they should use code blocks instead of images for their code. I say this because I can&#x27;t read the text inside the images from mobile. It&#x27;s way too small. reply geophile 11 hours agoparentI&#x27;m responsible.I need to revise those, and images seemed like the way to get colorization right. I&#x27;ll try to figure out how to do it with code blocks, it will hopefully be more maintainable. Cutting&#x2F;pasting images is ridiculous. reply petepete 6 hours agorootparentI suspect Pygments will be to your liking.https:&#x2F;&#x2F;pygments.org&#x2F; reply beeburrt 10 hours agorootparentprevyou could try Carbon:https:&#x2F;&#x2F;carbon.now.sh&#x2F; reply rahimnathwani 10 hours agorootparentprevWould highlight.js do what you need? reply chaps 11 hours agoprevHate to be \"that guy\", but it&#x27;s kinda sad that they pretty much stole the name... especially when the (fantastic!) movie with the original character came out recently in 2021.https:&#x2F;&#x2F;youtu.be&#x2F;k98Afd7Nf3Y reply geophile 11 hours agoparentI wrote marcel. I picked the name because of the short that preceded the movie! reply chaps 11 hours agorootparentOut of curiosity, did you reach out to them? I think the project is neat, just feels a bit like you&#x27;re leaning on an established (and extremely creative) piece of work instead of creating your own brand. Hope I&#x27;m wrong. reply geophile 11 hours agorootparentActually, I did. My daughter loves marcel the shell, I was writing a shell, so it&#x27;s an obvious choice. It is far enough afield that I can&#x27;t believe they would care. But I reached out to them, and explained what I was going. They were amused, said they might want to object later, but they never have. reply chaps 10 hours agorootparentThanks! That&#x27;s a relief. replymousetree 12 hours agoprevMy name is Marcel and I’m partially a shell, as you can see from my body. reply jfax 11 hours agoparentWhen I watched that in cinema I couldn&#x27;t help divert my attention to a family of two adults and two children in the rows ahead of me who left a third the way through. Wonder what they were expecting. reply adaml_623 11 hours agorootparentMight have felt sick. Or both kids got hungry and started whining. You can never tell from the outside reply rbanffy 11 hours agorootparentprevOh no! It’s a delightful movie. I watched with my wife and daughter and loved it. reply cryptoz 11 hours agoparentprevI saw Marcel&#x27;s movie in theaters probably 7 times at least. Top, top movie. The YouTube shorts a great of course, but the movie is next-level. reply mgaunard 12 hours agoprevNice. reply mgaunard 1 hour agoparentwhy is this modded -1? reply defrost 1 hour agorootparentAt least two other HN users chose to downvote a comment that effectively had no content (beyond \"yep\", \"nice\", \"upvoted\", \"w00t!\", etc).No HN mods were involved. reply shanti2001 1 hour agoprev [–] Nice replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Marcel is a contemporary shell that enhances composition by piping Python values instead of strings.",
      "It enables users to pass between commands built-in types and objects which stand for files and processes.",
      "More information and user guidance can be obtained from their tutorial."
    ],
    "commentSummary": [
      "The tech community is actively debating the necessity for a fresh shell in Linux, with suggestions such as PowerShell and Marcel surfacing.",
      "Marcel emerges as a focal point in the discussion; it's a Python-based shell known for its user-friendly attributes and compatibility with Python objects.",
      "Users exhibit curiosity over packaging Marcel for Nix and advise enhancements for the Marcel website, indicating active participation and shared interest in the project's development."
    ],
    "points": 187,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1698095985
  },
  {
    "id": 37985777,
    "title": "MSW 2.0 – Mock Service Worker",
    "originLink": "https://mswjs.io/blog/introducing-msw-2.0/",
    "originBody": "Search / Docs Blog Sponsor Back to Blog Introducing MSW 2.0 October 23, 2023 Artem Zakharchenko @kettanaito This November marks five years since Mock Service Worker has been first added to a package.json. Over that time, I have learned a lot about building libraries, designing APIs, and cultivating communities, which makes today’s announcement all the more special. Version 2.0 marks a monumental chapter for MSW. A year in development, dozens of contributors, and thousands of lines changed, this update brings a refined public API with the first-class support for Fetch API primitives and all the features and bug fixes that it unlocks as a side effect. Let’s have a quick look at what changed and why. If you prefer consuming changes hands-on, feel free to dive into the Migration guide for version 2.0. But if you’d like to learn more about the motivation, the challenges, behind-the-scenes, sweat and tears, and all that, then keep on reading. The beginnings If you’ve been using MSW, you are well familiar with this call signature: (req, res, ctx) => res(...) This is a function called response resolver, and it acts as a callback that receives the intercepted request and decides how to handle it. The shape of the response resolver hasn’t changed a bit since I first wrote it in 2018. Back in the day, I was rather inspired by functional programming paradigms and function composition in particular, which you can clearly see in the way you declare mocked responses using the res function: // Constructing a response is a matter of // composing various response utilities, // like \"ctx.status\" and \"ctx.json\". res( ctx.status(201), ctx.json({ id: 'abc-123', title: 'Introducing MSW 2.0', }) ) From the practical standpoint, the res() composition API achieves its goals: it allows for response declaration, it’s readable, it scales and abstracts well. But years of shipping open-source software have taught me there are more aspects to your code than practicality. Despite its apparent benefits, this composition API failed to achieve a rather important characteristic. It failed to educate. The degree of abstraction in the res() function is far too high to teach you, the developer, anything about actual responses on the web. As a maintainer with thousands of projects depending on the software I build, I feel it’s my responsibility to care about what developers learn from that software. I want them to achieve their goals but I also want them to learn concepts and APIs they can apply even outside of MSW because I firmly believe that’s what a good software does. The essence MSW allows you to treat each response as a function of request, and that has been precisely what was going on under the hood. // An abstract representation of the request -> response flow. responseSource.on('request', (request) => { const isomorphicRequest = toIsomorphicRequest(request) const response = resolver(isomorphicRequest, responseComposition, context) return respondWith(response) }) While in the browser we receive the Fetch API Request instance to represent a request, things become more tangled once we step into Node.js. Before version 2.0, MSW supported Node.js v14 - v16, which is a huge spectrum of versions. There is no fetch present in those versions, which means we couldn’t rely on the Fetch API to represent outgoing requests. To account for that request class difference, the library coerced all requests to a single isomoprhic request instance, and that is precisely what you got as the req argument in the response resolver. But that isomorphic request is entirely contrived. Worse still, extending it or adding new features required to manually implement them for every request module the developer could have used in Node.js. That was extremely tedious and led to all sorts of bugs. The effort behind v2.0 is precisely to eradicate those contrived APIs and fully embrace JavaScript standards. Polyfills Why won’t you just use a fetch polyfill? That’s precisely what I tried at first. It wasn’t long until I realized relying on polyfills won’t work at all. See, as a developer, you can polyfill fetch in your project in many ways, most likely relying on third-party packages. You may be using whatwg-fetch, or node-fetch, or isomorphic-fetch, or undici. But MSW had to use just one package. And it’s not a problem of choice but a problem of interoperability. Every fetch polyfill locks the identity of its internal classes like Request, Response and Headers. This means that none of those classes would pass the instanceof check, as one example, unless both you and MSW use the same polyfill, which is virtually impossible to predict. // somewhere/in/msw.js import { Request } from 'polyfill-that-msw-uses' function isRequest(request: Request) { // This will produce a lot of false negatives // if you provide a `request` constructed by // a different polyfill than \"polyfill-that-msw-uses\". return request instanceof Request } Inferring the polyfilled classes isn’t a reliable route either. It implies that the polyfill is set globally but it may not be the case. It also makes TypeScript definitions insanely difficult to get right as some polyfills deviate from the specification. I’ve spent almost a month fighting this to arrive at the simple conclusion: this was clearly not the way forward. The way forward I made the call to deprecate support for Node.js ≤ v16 with the new version of MSW and I am glad I did that. By the time I was finished with the rewrite, Node.js v14 has already reached the end-of-life, Node.js v16 reaches the end of life this fall, and Node.js v18 itself goes into maintenance. The day I removed Node.js v14 support from MSW will go in history as one of my happiest days as an engineer. Node.js evolves fast, and it is thanks fo that evolution that MSW can rely on the standard Fetch API both in the browser and Node.js to represent requests and responses from version 2.0! The new API Starting from 2.0, the way you declare request handlers (and response resolvers) will change. Here’s how the new API looks like: import { http } from 'msw' http.get('/resource', async ({ request }) => { const user = await request.json() return new Response(`Hello, ${user.name}`) }) And you’ve guessed it, both request and Response are the standard Fetch API instances! This means feature-rich, standard way of handling requests and defining responses, end-to-end. This may not look like a big deal at first but that changes once you dive deeper. Let’s say you wish to read the intercepted request’s body as FormData. This used to be a big point of friction in the past, but it’s a matter of using the platform now: http.post('/user', async ({ request }) => { const data = await request.formData() const email = data.get('email') }) This change also means that MSW (and you!) doesn’t need to rely on any polyfills to get all that functionality. It doesn’t have to keep internal request/response representations or contrive support for features that have been present in the platform for years. This is indeed the future and it has never been brighter. To make this point stick, let me show you a request handler that emulates a video stream and injects server-side latency between each individual chunk of that stream. import { http } from 'msw' http.get('/movie', async () => { // Fetch a video stream. const response = await fetch( 'https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4' ) const videoStream = response.body // Create a transform stream that will delay // each chunk before writing it back to stream. const latencyStream = new TransformStream({ read() {}, async transform(chunk, controller) { await new Promise((resolve) => setTimeout(resolve, 500)) controller.enqueue(chunk) }, }) // Pipe the original video stream through the latency stream. return new Response(videoStream.pipeThrough(latencyStream), response) }) There is a lot going on in this request handler! But you know what’s the best part about it? The only MSW-specific part of this entire code snippet is this: http.get('/movie', async () => {}) Everything else is standard JavaScript API. You can literally copy-paste that entire response resolver to your browser’s console and it will fetch the video and return you the transformed response. I hope you begin to realize how powerful this is. MSW has already set a new threshold of reusability by allowing you to use the same request handlers across any environment and any tool. With 2.0, that threshold has been pushed through the roof. Use the platform, learn the platform, write code that makes sense even outside of request handlers. One more thing Well, honestly, quite a bunch of things! The Fetch API support may be in the spotlight with this release but it also includes a dozen of bug fixes and improvements. MSW now ships with full compatibility with ESM, has proper code splitting, improves its internal architecture and refines its interception algorithm in Node.js. You can see the full list of changes in the Release notes. Migration guide This release contains quite a number of breaking changes as the public API of the library has been reworked and improved. I know it will take you some time to adopt those changes but, trust me, you will absolutely love how your request handlers will look once you do. Please follow these detailed migration guidelines to address each and every breaking change relevant to your setup: 1.x - 2.x Migration guidelines for version 2.0 Closing thoughts MSW went a long way from an overweekend prototype to one of the most used API mocking solutions in JavaScript. Today, it becomes the first solution to fully rely on the Fetch API primitives. I can’t wait for you to explore all the possibilities that unlocks. To many of you, MSW is already an inseparable part of their testing and development workflow, and with this release it will become the same for many more. Working on the library full-time would be my dream. Unfortunately, it is quite far from becoming the reality. But you can change that. If you believe in what I’m doing, if you want to see MSW improve and evolve, please Sponsor the project. Every contribution brings me a step closer to my dream. Thank you. Special thanks This release would not be possible without the incredible contributors who submitted issues, tried out the release candidate versions, shared their feedback, and believed in MSW. I will do my best to list everyone involved in this release below, in alphabetical order. Rest assured, these are the true heroes. 95th, Kosai106, TeChn4K, WesleyYue, Xayer, alawiii521, christoph-fricke, cmolina, colinsullivan, committomaster, committomaster, csantos1113, cwagner22, danny-does-stuff, dbritto-dev, ddolcimascolo, dkobierski, dxlbnl, ealejandrootalvaro, elliotgonzalez123, felipefreitag, jonnedeprez, jonnedeprez, koddsson, laryro, lee-reinhardt, lee-reinhardt, lemcii, luisr-carrillo, markwhitfeld, mattcosta7, mattrodak, mscottnelson, negabaro, nickrttn, piotr-cz, ricardocosta, skvale, the-ult, thepassle, thomasbertet, thw0rted, tomdglenn91, tsteckenborn, wKovacs64, weyert, xmlking, xxleyi, zkochan. © 2023 Mock Service Worker Created with by kettanaito LIBRARY Home Documentation Blog RESOURCES Getting started Best practices Examples COMMUNITY GitHub Twitter Discord",
    "commentLink": "https://news.ycombinator.com/item?id=37985777",
    "commentBody": "MSW 2.0 – Mock Service WorkerHacker NewspastloginMSW 2.0 – Mock Service Worker (mswjs.io) 180 points by milkers 20 hours ago| hidepastfavorite52 comments dcre 17 hours agoAt my job we&#x27;ve found working with MSW + OpenAPI to be near miraculous. I work on a web frontend and do most of my development against a mock API powered by MSW. This live preview runs against the mock API running fully in-browser.https:&#x2F;&#x2F;oxide-console-preview.vercel.appMore details:https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;oxide.tshttps:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;consolehttps:&#x2F;&#x2F;oxide.computer&#x2F;podcasts&#x2F;oxide-and-friends&#x2F;1426644Really excited about this next step for MSW — we&#x27;ll be upgrading soon. Building on web standards buys you so much.(Reposted at top level because the parent got flagged.) reply t1mmen 9 hours agoparentReally cool setup, thanks for sharing!After buying in to OpenAPI as the fundamental source of truth (generated via https:&#x2F;&#x2F;www.ts-rest.com contracts in my case), I have radically changed how I think about web development.At this point, it&#x27;s frankly absurd to me how many people out there make it so hard for themselves by manually building&#x2F;typing&#x2F;validating both client & server-side responsibilities in most typical REST setups. I get it -- I spent >2 decades in that reality, but no more. I will die on this hill.I am likely understating the impact when I say I&#x27;m 2x as productive whenever I touch API related functionality&#x2F;validation on client or server-side.MSW, Zod, react-hook-form+ZodResolver and several other tools in the OpenAPI ecosystem are simply incredible for productivity. The project I&#x27;m on now is certainly the most fun I&#x27;ve ever built because of these amazing tools. reply adamontherun 12 hours agoparentprevwe started using (and now contributing to) https:&#x2F;&#x2F;orval.dev&#x2F; this year which both generates the mocks using MSW as well as the client-side networking code (React Query in our case). It removes so much boilerplate its amazing.wrote up the basics of our workflow few weeks ago https:&#x2F;&#x2F;betaacid.co&#x2F;blog&#x2F;api-contracts reply jcullen 11 hours agorootparentOrval is great, I also recently wrapped up a project with Orval, React Query, and MSW. Generated my typescript models, helped me track changes in the API each time I updated against the swagger spec and let me test and demo the UI before our API team had a server running. Such a time-saver. reply wdb 12 hours agoparentprevYeah, @msw&#x2F;source is pretty sweet for that :) Use a .har or OpenAPI spec to create mock handlers reply berziunas 16 hours agoparentprevIs it ok if I see I am logged in as as Hannah and can launch new instances after clicking the first link? reply jonchurch_ 16 hours agorootparentIt&#x27;s all mocked, so you&#x27;re not really Hannah, and you&#x27;re not really launching instances. Their console is open source, and when you run it in dev mode locally this is also what you see. reply gregschlom 16 hours agorootparentAlso, worth pointing out that Hannah Arendt (the name that shows up as the logged in user) is a famous historian and philosopher (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hannah_Arendt) reply refulgentis 16 hours agorootparentprevJust when I think I get the whacky web kids, hell, that maybe I&#x27;ve even one of them, an article like this and functionality like this comes along.I don&#x27;t know how a mock library enables a revolution of having test data.I don&#x27;t know why the library couldn&#x27;t change it&#x27;s favorite method signature because a subset of versions of one JS framework couldn&#x27;t...fetch?or why the mock library can only have one dependency......and I feel _really_ out of the loop because I can&#x27;t understand the tone, hinting at years of sweat and though that I&#x27;m more used to from a consumer product launch.But that&#x27;s why I respect the web more than ever. The reaction is real, and it means something, even if I don&#x27;t understand it. People put _years_ into making (gestures) this work, so millions of developers can benefits, so billions, hell, _humanity_ can benefit. All in the open.Shine on, you crazy diamonds. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=54W8kktFE_o reply dcre 15 hours agorootparentWorth noting that in my experience it&#x27;s the combination of MSW and code generated from an OpenAPI spec that really makes it special, not just MSW alone.The other reply covers it but I want to slice it slightly differently. I see two things that are different here. One is mocking at the HTTP boundary rather than mocking, e.g., function return values or modules or whatever. That&#x27;s certainly not revolutionary (I know people do it with rspec and I&#x27;m sure plenty of test frameworks do it too), and in theory you could build your mock server with any tool that lets you build a server. But people don&#x27;t usually do this, and when they do they tend to do it bit by bit for each test rather than thinking about it as mocking the entire API. So for example, in my mock API, my POST creating a project actually creates a project in a mock database, and then when I list projects, I can see what I just created. So I can test the UI by doing exactly what you would do manually — create the thing and see that it shows up where it&#x27;s supposed to. All of that is built independently of my test for that feature, and it works for all the tests I write — I don&#x27;t have to think about mocking API bits for a particular test.Worth a read: https:&#x2F;&#x2F;kentcdodds.com&#x2F;blog&#x2F;stop-mocking-fetchThe other thing that&#x27;s unusual is running this mock in a Service Worker, which means it can run in the browser. That&#x27;s pretty cool and pretty unique to this tool. But the Mock part is about running the same server outside of the browser i.e., in Node (or now Deno or Bun), which means you can use it for unit tests. So I think the thing you have to see here is the synthesis of all that in one thing — it&#x27;s one mock server that (because it&#x27;s written in JS) can run both in the browser and on the server. I admit it doesn&#x27;t sound that great until you try it, but it enables some cool and surprisingly useful stuff like the live preview I linked. reply refulgentis 12 hours agorootparentThank you __very__ much, I went a bit long to try to signal I was serious and thought I wouldn&#x27;t get any substantive reply. This is beyond my wildest dreams. Thanks again. reply afavour 15 hours agorootparentprev> I don&#x27;t know how a mock library enables a revolution of having test data.From my understanding this isn’t (just) mock data, it’s an entire mock backend that runs inside the browser. To be able to simulate that with zero dependencies outside the browser does simplify a lot of testing scenarios. reply ushakov 16 hours agoparentprevAmazing. At Step CI we’re currently working on a tool that will do the conversion automatically (OpenAPI > MSW)Feel free to email me at mish@stepci.com if you want to hear more! reply dcre 15 hours agorootparentWe more or less did that too. We generate typed wrappers for every handler, and then we manually implement the internal logic for each endpoint. I doubt reliably generating 100% of the logic is possible, but even if it is, I would guess it&#x27;s more work to do that than to do it manually.Generator: https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;oxide.ts&#x2F;blob&#x2F;64401fa2&#x2F;gene...Generated output: https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;console&#x2F;blob&#x2F;8e74accf&#x2F;libs&#x2F;...Manually implemented endpoint behavior: https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;console&#x2F;blob&#x2F;8e74accf&#x2F;libs&#x2F;... reply zellyn 14 hours agorootparentI&#x27;m so glad to see all of your comments here. I&#x27;ve been fascinated by your setup ever since hearing about it on the Oxide and Friends podcast. The part that I&#x27;m most curious about is the part where you weave together auto-generated interface code with hand-implemented mock implementations… I&#x27;ll have to go read your code and see how that happens.[Edit, after reading a bit of the code]Am I correct in understanding that the generated code maps API calls to a typed interface, and then the hand-built implementation simply implements that interface?So rather than complex weaving where you want hand-coded function bodies but generated signatures, you have generated signatures, where each function body calls a method on a generated interface. reply dcre 14 hours agorootparentYeah, basically. We do it with a function call where the argument to the function is that interface representing all the API endpoints. `makeHandlers` handles parsing path params, query params, and request body and passes them to each endpoint handler. So the runtime validation of request bodies is also generated — we generate a zod schema for each request body in the OpenAPI definition and use it to parse the actual request body that comes in. So it&#x27;s not just a generated interface — there is also generated runtime behavior that is endpoint-specific.big function call https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;console&#x2F;blob&#x2F;bd65b9da7019ad...automatic body parsing and argument passing: https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;console&#x2F;blob&#x2F;bd65b9da7019ad...When an endpoint gets added to the spec, we can rerun the generator and get type errors in the `makeHandlers` telling us endpdoints are missing. reply wdb 12 hours agorootparentprevWhy not use @mswjs&#x2F;source? reply adam_beck 7 hours agorootparentI&#x27;ve seen you mention this a few times but can&#x27;t seem to find any information on it. I&#x27;m very interested in being able to use HAR files with MSW. reply candylifter 18 hours agoprevNice to see more and more tools adopting standard Fetch API Request&#x2F;Response interfaces. reply flakes 16 hours agoparentAgreed. The more non-intrusive your APIs are, the better the overall experience is going to be for developers. Diverging from official&#x2F;standard APIs means higher chance framework lock-in, which has kept me away from a lot of tooling.Always try to ask myself when adding tooling: What&#x27;s the chance I&#x27;ll want to remove this later, and how painful is that going to be? reply scottlamb 11 hours agoprevHow do folks test timing-related stuff with MSW? AFAIK, MSW doesn&#x27;t get along with jest.useFakeTimers. It drives me nuts; I have a bunch of disabled tests in an open-source project and at least one that is flaky because it uses real timers where I&#x27;d like to be using fake timers. [1, 2]I&#x27;ve been thinking about ripping out MSW from my tests in favor of my own API-level mock for this reason. But it seems like many other folks are happy with MSW. I have to assume there&#x27;s something I&#x27;m not getting. I&#x27;m a fish out of water with frontend stuff in general...[1] https:&#x2F;&#x2F;github.com&#x2F;scottlamb&#x2F;moonfire-nvr&#x2F;blob&#x2F;5ea5d27908f1a...[2] https:&#x2F;&#x2F;github.com&#x2F;scottlamb&#x2F;moonfire-nvr&#x2F;blob&#x2F;5ea5d27908f1a... reply IggleSniggle 17 hours agoprevSuper excited to see this land. I&#x27;ve been following this closely and experimenting with the beta branch; the ability to swap out real network requests with mocked ones in process is a huge upgrade for any kind of work you might have wanted to do with a proxy.Congrats on the release! reply danwee 16 hours agoprevOff-topic: I think I&#x27;ve seen this page layout before https:&#x2F;&#x2F;mswjs.io&#x2F;docs . Did they use a css-html template&#x2F;framework for it? reply dargy 16 hours agoparentLooking through the page source + some Google landed me here: https:&#x2F;&#x2F;docs.astro.build&#x2F;en&#x2F;getting-started&#x2F; reply milkglass 18 hours agoprevWhy does the site need us to allow ads? On the getting started page I see this:\"Please enable ads on this website. Thank you.\" reply ranting-moth 15 hours agoparentThey&#x27;re probably trying to make some money for their work that people take for granted. I don&#x27;t like ads, but I can&#x27;t blame them. reply wccrawford 16 hours agoparentprevIf I enable ads, it shows an ad for an ad service to target developers. reply ok123456 16 hours agoprevWhat is the benefit of using MSW over mocking a service with a small express server? reply ljm 16 hours agoparentYou can generate TS from an OpenAPI spec and then create type-safe mocks of network calls.Basic mocks and fake servers run the risk of falling out of sync and giving false positives, or just being outright wrong to short-cut some of the work. It&#x27;s also less code to maintain when a service worker can intercept the call, instead of orchestrating a load of mock APIs.It won&#x27;t stop you making breaking changes on the API but it will keep you honest on consuming the API on the client. reply Klaster_1 5 hours agorootparentToo bad this only gets you so far. Last time I checked, the OpenAPI specs are not as flexible as TS types and the people who author these - probably the team members responsible for the backend - won&#x27;t necessarily even be able to list all the invariants due to framework and host language constraints. And OpenAPI does not support WebSockets. The project I work on has a frontend written in TypeScript, a Java backend, an Express-based dev-server that shares same types with FE, but none of the solutions the team evaluated enables the type sharing across all three beyond simple \"an object can have these fields\" - no algebraic data types, no WebSocket support. In the end, we resorted to agreeing on as much as possible in plain text before greenlighting the new endpoint, and then double checking the implementation and client usage for unexpected behaviors. reply szines 5 hours agoparentprevOne of the biggest advantages of MSW, is that you can use the same mock server in your unit tests (jest) on Node.js environment and run the full frontend in the Browser for development and preview.The best if you have totally the same mock data, so super easy to debug your tests.Also, you can use this trick to have scenarios, so you can demo different behaviours just by passing a query param. QA loves it as well.https:&#x2F;&#x2F;github.com&#x2F;zoltan-nz&#x2F;meetup-contacts-app-2021&#x2F;blob&#x2F;m... reply dcre 8 hours agoparentprevFor me, the fact that every dev server tab I open is its own fresh server instance is really useful. We can run our tests in parallel with no server. We can deploy a live preview as a static site.https:&#x2F;&#x2F;oxide-console-preview.vercel.app&#x2F;projects reply abalashov 8 hours agoparentprevI have the same question. I just use a small local container fleet (Docker Compose) and have my actual API server running, and have never seen this to be a problem. I can do all this local development without depending on connectivity, etc. reply meiraleal 16 hours agoparentprevNo need to run a small express server? MSW runs in the browser so you can develop against a mocked API. reply orthecreedence 17 hours agoprevFor a second I thought it was Magic Seaweed 2. RIP. reply smallerfish 14 hours agoparentGuess we are stuck with surfline. I&#x27;d be interested in creating a competitor if I knew more about the data sources though - fun problem. reply codybontecou 12 hours agorootparentStormsurf provides tutorials and public data source links if you are genuinely curious: http:&#x2F;&#x2F;stormsurf.com&#x2F;page2&#x2F;tutorials&#x2F;menu.html reply smallerfish 8 hours agorootparentCool, thanks. Bookmarked for a weekend. reply revskill 17 hours agoprevnext [7 more] [flagged] michaelmior 17 hours agoparentI&#x27;m not sure what you&#x27;re getting at here. Not all open source projects are trying to turn users into products. A lot of open source projects derive value from getting external contributions that they wouldn&#x27;t otherwise if something was kept closed source and in-house. Paying for software isn&#x27;t always necessary.That said, the project also has several sponsors: https:&#x2F;&#x2F;github.com&#x2F;sponsors&#x2F;mswjs reply revskill 17 hours agorootparentIt&#x27;s always like that.I can&#x27;t find any exception, sorry.It&#x27;s natural right ? You can&#x27;t just have your cake and eat it, too. reply Uehreka 17 hours agorootparentSo when I use, say, ffmpeg: In what sense am I their product?They don’t collect telemetry, they don’t serve me ads, the output can be used with any other tool so there’s no lock in, there’s no FFmpeg Pro (TM) with features withheld from the base version.This seems a little silly I know, but GP was talking about open source projects and you literally said “I can’t find any exception”. reply morbicer 17 hours agorootparentprevEnlighten us how exactly are we products of Linux, Python, PostgreSQL and myriad of other open source which I am pretty sure you are using as well. reply skrebbel 17 hours agorootparentprevIf you can’t find any exception then you’ve missed like 80% of the FOSS ecosystem. Incl every BSD, most linuxes, most python libs and so on and so forth. reply ElectricalUnion 16 hours agorootparentprevStuff like Blink, it&#x27;s designed to be a free-as-possible, scorched-earth-tactics moat so anyone trying to be \"funny\" and locking down&#x2F;monetizing the platform in other ways other that the major contributor \"blessed ways\" are screwed up.In a way, the \"freeest\" tech around is the one that promotes \"commoditize your complement\", as that is the most capitalist incentive one has to have your cake and eat it, too.> Along the way, I noticed something interesting about open source software, which is this: most of the companies spending big money to develop open source software are doing it because it’s a good business strategy for them, not because they suddenly stopped believing in capitalism and fell in love with freedom-as-in-speech.> (...) All else being equal, demand for a product increases when the prices of its complements decrease.> Let me repeat that because you might have dozed off, and it’s important. Demand for a product increases when the prices of its complements decrease.> https:&#x2F;&#x2F;www.joelonsoftware.com&#x2F;2002&#x2F;06&#x2F;12&#x2F;strategy-letter-v&#x2F; reply sph 17 hours agoprev [9 more] [flagged] dcre 17 hours agoparentSure, it&#x27;s a lot of fanfare, but at my job we&#x27;ve found working with MSW + OpenAPI to be near miraculous. I work on a web frontend and do most of my development against a mock API powered by MSW. This live preview runs against the mock API running fully in-browser.https:&#x2F;&#x2F;oxide-console-preview.vercel.appMore details:https:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;oxide.tshttps:&#x2F;&#x2F;github.com&#x2F;oxidecomputer&#x2F;consolehttps:&#x2F;&#x2F;oxide.computer&#x2F;podcasts&#x2F;oxide-and-friends&#x2F;1426644 reply michaelmior 17 hours agoparentprev> a library to make Javascript testing a little bit easierDepending on the environment you&#x27;re working in, it makes testing a lot easier. MSW isn&#x27;t for everyone, but it can make things a lot more painless. reply teaearlgraycold 17 hours agoparentprev [–] I don&#x27;t think they have VC money. I think the people building it just know what they&#x27;re doing. Do you see anything that indicates this is a VC-funded project? It looks to me like they&#x27;re only getting a little bit of money from Github Sponsors (https:&#x2F;&#x2F;github.com&#x2F;sponsors&#x2F;mswjs). reply sph 17 hours agorootparent [–] That&#x27;s a lot of time and effort, for people earning next to nothing, for an open-source library. I&#x27;m not saying it&#x27;s bad they have a beautiful website to rival any small SaaS, but how is even possible they have the time and energy to spend on that, rather than on the code itself? What would Linux or GNOME or leftpad look like with a proportional amount of marketing effort?Last time I checked, testing libraries did not have custom iconset and a testimonial section to rival the Stripe homepage. reply ngruhn 17 hours agorootparentI think this is actually pretty common in the JavaScript ecosystem. Presumably, because contributors are very skilled in building websites and maybe also because users have higher expectations when it comes to presentation. I mean checkout https:&#x2F;&#x2F;vitest.dev&#x2F; https:&#x2F;&#x2F;jestjs.io&#x2F; https:&#x2F;&#x2F;webdriver.io&#x2F;de&#x2F; https:&#x2F;&#x2F;playwright.dev&#x2F; (all testing related stuff). reply codybontecou 12 hours agorootparentI agree. Beautiful documentation helped me a lot early on when getting into the JS ecosystem. reply CPLNTN 17 hours agorootparentprevI don’t understand, your complaint is that the project is too well done? reply teaearlgraycold 17 hours agorootparentprev [–] A few things:1. It&#x27;s actually pretty easy to get a pretty site these days. The SaaS layout is so standardized you can just buy a template to get your React site up and running and looking professional for a couple hundred dollars and a few hours of work. The site overall definitely took more time than that.2. This is a library for front-end developers. It&#x27;s made by front-end developers who probably have some design skills of their own. That makes it easier for them than Linux&#x27;s kernel hacker team to set up a nice website.3. Is this just a matter of insecurity on your part? I&#x27;m sure you have plenty of dev skills but maybe they don&#x27;t extend to UI and you don&#x27;t like that this team can throw together a beautiful site for something that&#x27;s merely a side-project? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author is introducing MSW 2.0, an important update to the Mock Service Worker library, which includes significant improvements such as a refined public API along with Fetch API primitives support.",
      "The update renders the need for polyfills obsolete and enhances Node.js compatibility, making MSW request handlers more reusable and adaptable.",
      "The release includes not only bug fixes and enhancements, but also some breaking changes; however, detailed migration guidelines are provided. The author warmly acknowledges contributors and encourages further sponsorship to boost future project development."
    ],
    "commentSummary": [
      "The post revolves around the beneficial experiences with MSW (Mock Service Worker) and OpenAPI in web development, including improved productivity and simplified development process.",
      "Users praise MSW's ability to generate code and create mock APIs, streamlining their workflow.",
      "Another unique, appreciated feature is MSW's capability to run the mock server in both browser and server environments."
    ],
    "points": 180,
    "commentCount": 52,
    "retryCount": 0,
    "time": 1698069707
  },
  {
    "id": 37985450,
    "title": "Was any Starfighter postmortem ever published?",
    "originLink": "https://news.ycombinator.com/item?id=37985450",
    "originBody": "About seven years ago, HN veterans &#x27;elptacek, &#x27;patio11 and &#x27;tptacek launched an hiring startup called Starfighter. Their approach aimed to shift away from traditional interviews and instead employ a CTF&#x2F;Microcorruption kind of test, inspired by &#x27;tptacek experience at Matasano. Unfortunately, Starfighter eventually wound down.Was there ever any post-mortem written on Starfighter? If not, would &#x27;elptacek, &#x27;patio11 and &#x27;tptacek be willing to provide any details?",
    "commentLink": "https://news.ycombinator.com/item?id=37985450",
    "commentBody": "Was any Starfighter postmortem ever published?Hacker NewspastloginWas any Starfighter postmortem ever published? 178 points by xoranth 20 hours ago| hidepastfavorite141 comments About seven years ago, HN veterans &#x27;elptacek, &#x27;patio11 and &#x27;tptacek launched an hiring startup called Starfighter. Their approach aimed to shift away from traditional interviews and instead employ a CTF&#x2F;Microcorruption kind of test, inspired by &#x27;tptacek experience at Matasano. Unfortunately, Starfighter eventually wound down.Was there ever any post-mortem written on Starfighter? If not, would &#x27;elptacek, &#x27;patio11 and &#x27;tptacek be willing to provide any details? itslennysfault 17 hours agoI have no relation to Starfighter, but I was part of a similar startup almost a decade ago, and learned a few things that are likely similar to what they faced.We started with this dream of completely revolutionizing the way people hire in tech (with hopes of expanding to other fields).First of all, we learned that for 99% of companies they don&#x27;t have a screening problem, but they have a sourcing problem. Our original company was along the lines of HackerRank &#x2F; LeetCode &#x2F; etc, and created due to the founder&#x27;s experience as a manager at Amazon where he&#x27;d get 1000s of resumes that needed to be screened and the process was eating up too much dev resource. A product that solves this problem is appealing to companies that get 1000s of resumes per posting, but basically useless to most companies who get very few candidates, and even less appealing to recruiters who care much more about top of the funnel than the screening process.After that we pivoted to an event format. The idea being that we could attract 100s of applicants to do a challenge in realtime. This reduces cheating risk and allowed us to act as a means of sourcing candidates (instead of just a screening platform). The idea was 100s of candidates would enter and the companies we got to sign up would compete for the top applicants. It sorta worked. The platform was good, companies were interested, and we got some people placed.HOWEVER, the profile of people that will do a multi-hour open ended challenge for the chance to maybe get hired by some companies largely leans toward entry-level people. We had some experienced people that did it because they were bored or just curious, but generally seasoned engineers aren&#x27;t going to waste their time, and forget about \"passive job seekers\" which is what all recruiters want most of all.Ultimately, the company ended due to a lot of personal issues between the founding team, but the product itself was good, and the market fit was decent, but far from perfect. I&#x27;m pretty sure if we would&#x27;ve kept it together we would&#x27;ve eventually became very similar to HackerRank just offering a platform where people can conduct the same crappy tech interviews we&#x27;ve been using forever. reply elptacek 9 hours agoparentAttracting entry level hires is part of the point, but the problem remains that most companies lack the resources and&#x2F;or desire to train entry level hires. Heck, most of the ones I&#x27;ve worked for didn&#x27;t really train me at a senior level. But definitely yes on the personal issues. reply markus_zhang 7 hours agoparentprevWhat about career switchers? I&#x27;d definitely want to do some sort of challenges to prove that I&#x27;m OK for a different career path...ah nvm I&#x27;m actually not ready for those. reply ska 16 hours agoparentprev> the profile of people that will do a multi-hour open ended challenge for the chance to maybe get hired by some companies largely leans toward entry-level people.Wasn&#x27;t this assumed to be the case going it to it when you discussed the business cases? It&#x27;s hard to imagine any other result would be likely. reply danielvf 18 hours agoprevStarfighter was a blast to play, and taught me a lot about the back end of stock trading.I did a lot of silly things after winning the initial play through.- Solving the final challenge using a basysian spam filter on trade directions triples.- Live 3D market visualization in Minecraft- Buddy of mine built a stock exchange stack, speaking the same protocol, and we had PvP contests on who could market make the best on it. I won with a PHP powered marketing making bot with live code reloading.- Built a cardboard box out of scrap electronics from adafruit that would let me adjust a market maker bots net position by tilting the box from side to side.- Was either #2 or #3 to solve all the challengesOn the business side, if I recall correctly, most companies wanted to just shove the winners down their existing bad hiring pipeline process, and a lot of successful contestants who showed up already had great jobs, and so weren&#x27;t actually looking. reply clusterhacks 17 hours agoparentTotally agree it was a blast. I learned a ton about trading just reading various recommended resources (Harris Trading and Exchanges was a solid intro) and then solving the levels.I don&#x27;t think very many players did all the Starfighter trading challenges. patio11 or tptacek might be able to confirm, but I vaguely recall being one of like 100 or so to do all six levels of out of 10,000 that started. But I also had free time for playful coding and was nerding out on online challenges back then.When Starfighter came out, I was energized and hopeful that hiring would go in this direction for programmers or that it would open doors to me as a job seeker that I couldn&#x27;t every push through. No such luck.From the hiring side, I have been on two hiring committees this year. Most applicants lacked any meaningful programming projects they could use to demonstrate skills. Something like completing a series of online challenges would be a difference maker.That said, one candidate mentioned doing HackerRank challenges to learn Python and SQL, but totally flamed out on being able to even talk through a for loop in Python or come up with a simple select against a table in the in-person interview. Maybe nerves, but it also felt like the candidate&#x27;s experience was 100% as just a warm body in various cubicle farms. It was very awkward. Several non-developers on the hiring committee felt like the candidate had actively lied about previous experience . . . reply acdha 13 hours agorootparentI hate the way cheaters spoil the well for people with legitimate issues. I always want to be considerate of people with anxiety, processing issues, etc. but I have also seen multiple candidates where everyone thought they were using someone else’s resume (e.g. 10+ years of experience, couldn’t describe _anything_ they did) and were trying to pass it off as ESL issues (our interview panel included a fluent speaker of that language who did not find this credible), and I wish they appreciated that they are making it harder for everyone whose resume looks like the one they used reply sam_lowry_ 16 hours agorootparentprevSometimes I flip on obvious intreview questions while solving same problems during the flow of programming almost instinctively. reply aleph_minus_one 10 hours agorootparentprev> I don&#x27;t think very many players did all the Starfighter trading challenges. patio11 or tptacek might be able to confirm, but I vaguely recall being one of like 100 or so to do all six levels of out of 10,000 that startedAs far as I remember, at the beginning and for quite some time the Stockfighter trading challenges had reliability and performance issues (server capacity). So I decided to wait a little bit for the product to become more stable, and then get into the challenges. Unluckily, at that time Stockfighter was already decided to become shut down. reply elptacek 9 hours agorootparentInvisible, forgotten third partner here... more made it through all of them than you might think. They even set up their own Slack community to help each other out. reply ApolloFortyNine 14 hours agorootparentprevThe number of cs majors I&#x27;ve had fail a for loop function floors me. The company I was at was paying 105k starting at that time 4 years ago for junior devs fresh out of college, so not FANG tier but plenty good for the area.At least 30% bombed writing a for loop and if statement though. And we let them pick any language they wanted, so that wasn&#x27;t it. reply toast0 14 hours agorootparentI&#x27;ve only done interviewing for high tier companies, so my bar was pretty high, I wanted candidatws to be able to demonstrate knowledge and ability of a loop with a loop inside.Our screening was pretty good, so most (but not all) candidates could demonstrate one loop, but an unfortunate number couldn&#x27;t do the nested loop. shrug reply nonameiguess 12 hours agorootparentprevThey&#x27;re not necessarily \"lying\" in the strictest sense. I&#x27;ve seen this problem in very large defense contractors like Lockheed and Raytheon that combine two things: 1) a need to hire a lot of cleared developers very quickly when a new contract is won and 2) internal HR processes that make it nearly impossible to fire someone. The former makes it possible for underqualified or even flat-out incompetent people to get hired in the first place just because they&#x27;re cleared and live close enough to a SCIF and the latter means they stick. At best, they&#x27;ll do literally nothing and just silently sit through meetings and complete extremely menial tickets a toddler could do in their sleep. At worst, management insists they need to do real work to justify charging for their labor hours, but then they suck so much energy out of everyone else who has to hold their hand and cover their mistakes that their net contribution becomes negative. Nonetheless, it is very easy to transfer them to another team or another project that doesn&#x27;t know any better and has to take whoever some higher layer of management tells them to take, and much harder to take the time building up the case to fire them, so they stick with the company for a long time. In doing so, they can build quite a long list of bullet points in terms of projects they&#x27;ve worked on, technologies they&#x27;ve used, and what not, even though they never actually learned anything useful from any of them and could not explain what any of the software they worked on actually did or how.This tends to be especially bad in companies that use a matrix organization where your department or career manager is in a totally separate hierarchy from the project-level managers you actually receive taskings from because the latter know your performance traits but the former decide where you get assigned to work and whether you can be fired or not, and they tend to have a huge incentive to staff critical programs, even if \"staff\" means fill in with net-negative warm bodies, because that&#x27;s at least faster than filling with new hires, which also may not even be possible when you have very specific location and security requirements. reply elptacek 9 hours agoparentprevYes to \"existing bad hiring pipelines.\" In at least one case, the in-house recruiter was obviously offended that she had to speak to us at all. The one placement we made was with an old pal and I had to yell at him to even give the guy a chance. Six months after we&#x27;d shuttered for good, he contacted me to ask me if I had any more Bens. Nope. reply lmm 6 hours agorootparentMaybe that company should&#x27;ve sponsored the next BenConf. reply danielvf 14 hours agoparentprevHey! I found a gist with my level solutions for all the levels! Some elegant code, if I do say so myself.https:&#x2F;&#x2F;gist.github.com&#x2F;DanielVF&#x2F;d43e079050d1cf3c05d6 reply lylejantzi3rd 11 hours agorootparentThanks for posting this! I always learn something from reading your code. I remember the post about your halite bot. Good stuff. reply armitron 17 hours agoparentprevSounds like fun. To founders: Any plans to open source it so that it’s not lost in the sands of time? reply clusterhacks 17 hours agorootparentIt was fun! I did all the stock trading challenges but none of the embedded device challenges.patio11 once said that the code wasn&#x27;t in an open-source ready state.There were some folks who went so far as re-implementing&#x2F;duplicating the backend trade simulator in other languages. Some of those were on github . . . reply dinp 19 hours agoprevIn case the founders read this post: what would you do differently if you could start over and would this idea work today?Slightly OT: everyone feels hiring is broken, can you list some things that are annoying from the employee and employer perspective? Here are some points:- the process often stretches out over weeks and often months- job posts often get 100s of applications, a lot are low effort applications, it just muddies the water for both sides- ATS systems&#x2F;job boards are annoying with the need to create an account on many sites, some forms have more than 20 questions, often asking what&#x27;s already there in the resume.A question to everyone: What would a good application process look like? For me, it should just solve the above mentioned problems. I send an email with my resume, a few sentences about why I might be a good fit for the role&#x2F;what interests me about the company. The jobs@.com email address could be linked to some Saas product which makes it easy for the employer to go through the applications and further communication about video calls or take home assignments or whatever are all in this email thread. The employer can set the stage of the application such as 2&#x2F;5 or whatever, they can mark it as rejected or accepted after all rounds to trigger automated emails etc. Is there any Saas like this? (I can build this in a week if it doesn&#x27;t exist, but no clue how to market it&#x2F;get users, any pointers in case me or someone else builds this?) reply romanhn 18 hours agoparentYou&#x27;re describing basically every ATS (applicant tracking system). The problem is that those are all internal-facing, so there&#x27;s no incentive to make your life easier as a candidate. I&#x27;m trying to tackle this with https:&#x2F;&#x2F;rolepad.com, a job application tracking system that can be connected to an employer portal and provide greater transparency and just make the whole candidate experience much better (the employer part is still under development though). reply scarface_74 16 hours agorootparentI found LinkedIn’s Easy Apply to be remarkably easy to spam a hundred or so applications in a week and it lets you see if your application has been viewed or resume downloaded.Unfortunately hundreds of other people found it just as easy.This is why I never blindly submit my resume to an ATS. I only did it this time because I was unemployed (for two weeks) and had nothing better to do.The five opportunities that led to interviews were still based on good old fashion networking1. A full time offer (didn’t accept) and a side contract (did accept) based on referrals from former managers2. Two interviews based on reaching out to the internal recruiter for positions I was objectively the best person on the market for - I was a major contributor to an open source official “AWS Solution” they were implementing and modifying. I accepted an offer.3. Responding to a recruiter he reached out to me. There was some miscommunication about the role. The team thought the client wanted someone “local” to the US since their whole team was in India. They wanted someone local to the city - I declined.Out of the 100 applications I randomly spammed, most didn’t get around to even looking at my application and only four actually downloaded my resume. reply IMTDb 18 hours agorootparentprev> so there&#x27;s no incentive to make your life easier as a candidateEspecially because lowering the barrier usually means getting more low effort application.People either put a lot of effort on few applications and invest significant amount of time in each one hoping to increase the chance they get picked up; or they put a lot of effort on reaching out as much as possible, knowing they have a very small chance on each application but playing on volume.Most recruiters are only interested in the first category of candidates. Having a long initial process is a feature. The goal is that the second category considers that given their chance of getting picked up, it&#x27;s not worth filling the form. reply indymike 16 hours agorootparent> Having a long initial process is a feature.Reality is:1. Screening tools (background check, skills analysis and testing) are really good. There&#x27;s really no reason to put someone through a six-week gauntlet just to find out if they can do the job.2. Interviews are really a tool for seeing if coworkers and managers get along with the candidate, and the candidate gets along with their future coworkers and managers. In many companies interview == where manager has discretion to hire the people they want. Lots of interviews usually means lots of managers who all want to put their stamp on the hire.3. Being good at getting hired is a function of experience getting hired. The skills needed to be a good candidate do not align with the skills needed to be a good worker in most roles. reply ska 16 hours agorootparentIn my experience: (1) just isn&#x27;t true. It&#x27;s at best a mixed bag. (2) is somewhat true. Team fit is pretty hard to figure out without interactions, and agree sometimes managers just want to get their oar in. (3) is oversimplification. There are definitely people who are better a getting hired than doing the job, and they are hard to weed out early in their career. If you aren&#x27;t able to identify good candidates in front of you though (e.g. the FN, not FP) there are problems in your process, not the candidates. reply indymike 15 hours agorootparent1. I&#x27;m pretty sure that background checks work beyond doubt. I&#x27;m pretty sure that skills tests work beyond doubt. I&#x27;m less confident in AI resume&#x2F;profile analysis and skills matching tools - both are getting better.3. Agree, it&#x27;s simplified, but for most companies, field and \"hiring\" managers are barely able to do an effective interview, let alone smoke out someone lacking interview skills from one lacking communication skills. reply ska 11 hours agorootparentAgree both background checks and skill tests can work very well in an ideal form, but it&#x27;s expensive (in time, mostly). As practised, they are very much a mixed bag. The latter is a problem past early career stuff anyway, as you aren&#x27;t going to learn much in a couple hours. replyeuos 8 hours agoparentprev> A question to everyone: What would a good application process look like?I work in a top company with infamously difficult interview. I made major contributions to several opensource projects that modern tech runs on. I can easily show a clean standalone pull request attributed to me that introduces complex multithreaded code. That code runs daily on millions instances.Why the hell do I need to spend hours answering “what a mutex is”? Also, understand that a lot of stuff is much less obvious and clear cut (e.g. how HTTP protocol works) for me than for your engineer. They only saw the basic case. For me the answer will be “it depends”.Please, respect the candidate time and experience. reply lmm 6 hours agorootparent> I work in a top company with infamously difficult interview. I made major contributions to several opensource projects that modern tech runs on. I can easily show a clean standalone pull request attributed to me that introduces complex multithreaded code. That code runs daily on millions instances.A lot of applicants will lie or bullshit something similar. How would you suggest an employer distinguish someone like you from someone pretending to be someone like you? reply michaelt 17 hours agoparentprev> A question to everyone: What would a good application process look like?A complete overhaul of credentialing, so that when I have a degree in computer science from a top university and decades of industry experience, employers don&#x27;t need to independently confirm that I know how to reverse a string or traverse a tree or define what XSS is.Also, make a time machine so we can make this change 30 years in the past, if you wouldn&#x27;t mind. reply ghiculescu 17 hours agorootparentThe problem with credentialism is that lots of people with degrees from reputable universities can’t code.Similarly lots of people with significant industry experience… also can’t code. reply mprovost 15 hours agorootparentWhat does \"reputable\" mean in this case when these universities are handing diplomas to graduates who can&#x27;t code? Somehow we&#x27;ve gotten ourselves into the situation where we force someone with a CS degree from Stanford write some leetcode, even when the people on the hiring panel themselves have degrees from Stanford. Do they still not trust their own university?And yet, when scanning resumes, people often look for prestigious&#x2F;\"reputable\" universities as a filter. Is the assumption that if they have a degree from Stanford and can reverse a string then that is a positive signal, but if they can&#x27;t reverse a string that is somehow a personal failing and not a failure of the university to educate (and then evaluate) the candidate? reply jfim 15 hours agorootparent> What does \"reputable\" mean in this case when these universities are handing diplomas to graduates who can&#x27;t code? Somehow we&#x27;ve gotten ourselves into the situation where we force someone with a CS degree from Stanford write some leetcode, even when the people on the hiring panel themselves have degrees from Stanford. Do they still not trust their own university?What&#x27;s the alternative? Just give leetcode tests to people who didn&#x27;t go to the same university as the hiring panel?The fact that we have the same tests for everyone no matter where they studied at is a good thing and prevents nepotism in hiring decisions. reply michaelt 14 hours agorootparentA professional organisation like the ACM which &#x27;accredits&#x27; college courses, making sure that 3.5 GPA from MIT is equivalent to a 3.5 GPA from Podunk University. reply throwaway2037 5 hours agorootparentAs someone who attended two different universities for my undergrad, the first was way harder than the second. Basically, I failed out of my first, and cruised through my second. I intentionally selected a much lower ranked university for my second attempt. I felt like I was buying a university degree at my second place. And, yes, both were ACM accredited. It means little.What I am noticing on all threads about HN hiring: Hiring knowledge workers is fundamentally a difficult, fuzzy process. Few want to admit it. And, there are some people are naturally much better at it because they can control themselves very well during an interview. People who are very strong at solving puzzles will nearly always outperform during interviews for hands-on roles. More than anything, interviewing feels like dating. Everyone hates it until you find what you are looking for... then it becomes: \"Oh, it worked fine for me.\" reply michaelt 14 hours agorootparentprevThe reform I&#x27;m proposing is that reputable universities should only issue CS degrees to people who can, in fact, code.That&#x27;s why the time machine is so important - to get back any CS degrees issued to people who can&#x27;t code.So I think you are actually agreeing with me? reply vunderba 10 hours agorootparentThis sounds more like a PE Exam equivalent for software engineering which I honestly think should be put into place since most traditional engineering industries have this already. reply __turbobrew__ 6 hours agorootparentYea, I think that is the alternative. A professional body which accredits its members. It is a system which is known to work for other disciplines. reply red-iron-pine 15 hours agorootparentprevthis has been solved -- with take home coding or whiteboarding.in the networking side of these we used to have a couple of Cisco 2960s with slightly borked configs and our interviewees had to log in and tell us what&#x27;s wrong. 5 minute activity, but often took some folks 30 minutes. reply ghiculescu 15 hours agorootparentYeah I think that’s what Starfighter did. And we are discussing how it failed, so… reply zo1 17 hours agorootparentprevSeparate to solving hiring, maybe we should solve this instead first?In my part of the world specifically, the reason you get this is largely due to quota pressures by government. Government actively economically disadvantages white-privilege companies that don&#x27;t fill unreasonable DEI quotas, effectively making an educational deficiency in the government&#x27;s programs as a problem that the \"private sector\" has to fix 15-years too-late whether at University or in the workplace.So everyone just passes the buck because they can&#x27;t fix it nor can they speak the truth about the real cause, until at the end of chain the company making widgets&#x2F;products&#x2F;things has to take a hit and passes this problem on to the consumer in the form of hidden crapflation. But hey, government said they&#x27;re fighting inequality, universities can say they are promoting education, companies can tick the DEI quota box, we all blame it on the \"White Man\" that can&#x27;t say anything, DEI groups \"get jobs\" and the DEI grifter consultant machine makes mega-bucks. Win&#x27;s all around, right. reply nemothekid 16 hours agorootparentThe FizzBuzz test came about for similar reasons in 2007 - long before government pressures for DEI quotas[1].The problem is computer science university degrees aren&#x27;t enterprise training academies. \"Computer Science is no more about computers than astronomy is about telescopes.\" Universities aren&#x27;t incentivized to fix this because universities are research institutions - they don&#x27;t make money from placing students in jobs, so trying to solve this is a dead end.[1] https:&#x2F;&#x2F;blog.codinghorror.com&#x2F;why-cant-programmers-program&#x2F; reply thaumasiotes 10 hours agorootparent> The FizzBuzz test came about for similar reasons in 2007 - long before government pressures for DEI quotas[1].Government pressure for hiring quotas goes back to the 1970s. reply nemothekid 7 hours agorootparentIt&#x27;s moreso I don&#x27;t believe there was a ton of government pressure being applied to startups with 15 people. reply thaumasiotes 6 hours agorootparentThat&#x27;s also still true today. reply ghiculescu 16 hours agorootparentprevThat happens too but I think the underlying reasons are simpler.Everyone involved in hiring should read “The Case Against Education” by Caplan. reply quesera 14 hours agorootparentprev> a degree in computer science from a top university and decades of industry experience> know how to reverse a string or traverse a tree or define what XSS is.In my experience, it is absolutely not safe to assume a correlation between these two sets of traits. reply enraged_camel 17 hours agorootparentprevI used to share your opinions, until I sat at the other end of the table and interviewed candidates. The problem is that people lie constantly about their credentials, experience and knowledge. They lie on their resumes, they make up fake references (sometimes going so far as to pay their friends to lie for them), they might even have someone create fake portfolio websites for them and showcase those as their own. There will never be a way to detect such deception without asking candidates basic questions as a way to at least \"smoke test\". reply scarface_74 16 hours agorootparentI’ve been interviewing people as either just another person in the loop or the person who could give the thumbs up about whether I wanted someone on my team and the manager just rubber stamped it for over 20 years - no coding just conversations.I’ve never regretted a single person I hired and they have always been able to do the simple CRUD work that most of the 2.7 million developers are doing.And before the gate keeping starts. I’ve been through the “Making Great Hiring Decisions” training and have conducted behavioral and system design interviews at AWS. reply lmm 6 hours agorootparent> I’ve been interviewing people as either just another person in the loop or the person who could give the thumbs up about whether I wanted someone on my team and the manager just rubber stamped it for over 20 years - no coding just conversations.Sounds like a good way to filter for the right class background. (Which, given how well that&#x27;s correlated with intelligence, is probably as good a hiring method as any) reply scarface_74 5 hours agorootparentWhat do you mean by the right class background? If you think I’m a white guy who graduated from a prestigious school, I can guarantee you that’s a far from accurate assumption.Let’s just say when I walk through my neighborhood I’ve read comments about me in my own NextDoor group about someone “suspicious” and realized they were talking about me or my son… reply lmm 5 hours agorootparent> What do you mean by the right class background? If you think I’m a white guyThis is why I find it so frustrating to talk to Americans.> Let’s just say when I walk through my neighborhood I’ve read comments about me in my own NextDoor group about someone “suspicious” and realized they were talking about me or my son…So you&#x27;re a member of the class that lives in \"good\" neighbourhoods where it&#x27;s suspicious for certain types of people to be? I think you&#x27;ve proved my point. reply wombatpm 17 hours agorootparentprevA resume is not just a piece of paper. It’s a piece of paper with lies on it. And it can be the difference between not getting a job and not even coming close.-Dave Barry reply aleph_minus_one 9 hours agorootparentprevI ask myself whether this problem is also part of the US mentality: in Germany, one would rather be tempted to treat even white lies as fraud, and thus compare (culturally, though not legally) such liars with criminals.On the other hand, in my experience such fraudsters are in most cases easy to detect: just ask them some hard questions (where the candidate will either know the answer or not, thus rhetorics or charisma won&#x27;t help) about the topics that the candidate claims to have expertise in (choose the question in a way that even very capable candidates will only be able to answer a fraction of them - this is fine and intended).Typically, after 30-45 minutes you are either sure that the candidate tells the truth about his capabilities or is a liar (hardly ever anything inbetween happens). reply scarface_74 16 hours agorootparentprevIt still doesn’t tell me whether you kept up with what the market wants, you have the specific skills I care about or whether you have the behavioral traits I am hiring for. reply VirusNewbie 14 hours agorootparentprev>A complete overhaul of credentialing, so that when I have a degree in computer science from a top university and decades of industry experience, employers don&#x27;t need to independently confirm that I know how to reverse a string or traverse a tree or define what XSS is.But &#x27;top universities&#x27; don&#x27;t know how to teach CS. That&#x27;s the point. Don&#x27;t waste your time there.Maybe we should have a &#x27;bar exam&#x27; type system, but the university system is a joke at this point, and there&#x27;s no point trying to put lipstick on a pig. reply VirusNewbie 14 hours agorootparentprev>A complete overhaul of credentialing, so that when I have a degree in computer science from a top university and decades of industry experience, employers don&#x27;t need to independently confirm that I know how to reverse a string or traverse a tree or define what XSS is.But &#x27;top universities&#x27; don&#x27;t know how to teach CS. That&#x27;s the point. Don&#x27;t waste your time there.Maybe we should have a &#x27;bar exam&#x27; type system, but the university system is a joke at this point, and there&#x27;s no point trying to put lipstick on a pig. reply markus_zhang 7 hours agoparentprev> What would a good application process look like?As a data engineer I&#x27;d like to have a chat about the pain points of the current team and contribute. I think a coding test is OK too as long as it is just one round and actually test something meaningful. reply VirusNewbie 16 hours agoparentprevNetflix was pretty great, I recommend everyone apply there. I don&#x27;t even work there.Their live coding questions were1. Either practical , or core CS stuff. No fancy algorithms, just basic stuff you&#x27;d get in a CS 101 DS&A class.2. Collaborative. No one cared about perfect code or syntax, it was very relaxed and dare I say fun (if it wasn&#x27;t for the nerves).3. System design was practical and a good back and forth.The interviews were challenging overall, but nothing they asked seemed unfair or about memorization either.Certainly coding under pressure sucks, but I don&#x27;t think there&#x27;s a better way. reply tptacek 18 hours agoprevNope. We always meant to, but got sucked into new stuff shortly after. reply fragmede 17 hours agoparentNo time like the present! The platform itself seemed like it worked great, so the question is what did it look like on the other end - were you able to get any companies to actually take on candidates who passed the test? The software&#x27;s the easy part, it&#x27;s everything else that&#x27;s the problem. reply elptacek 9 hours agorootparentThe way I remember it, the general experience was that companies reached out to us and were very excited by the idea, but when we actually sent a candidate, they scotched it. I did make exactly one placement where I waived the fee (because friends). They were super happy with him but it was too little, too late. reply ufmace 18 hours agoprevReading between the lines a bit on the existing postings about it, I&#x27;m guessing that they were unable to persuade any businesses to actually relax their interviewing standards for candidates who passed the Starfighter tests.Which then puts any candidates in the position of, why should I spend time and effort on this little game if it doesn&#x27;t lead to any advantage at all in actually getting good positions?And so, the only people who messed with it were developers who had the free time to play with stuff like this and didn&#x27;t particularly care that it wouldn&#x27;t lead to any advantage in getting jobs.Which means, it&#x27;s a cool toy that was high-effort to build and probably to maintain, but had no viable path to earn money from anybody. reply thaumasiotes 17 hours agoparent> I&#x27;m guessing that they were unable to persuade any businesses to actually relax their interviewing standards for candidates who passed the Starfighter tests.> Which then puts any candidates in the position of, why should I spend time and effort on this little game if it doesn&#x27;t lead to any advantage at all in actually getting good positions?This is the same position TripleByte was in. They advertised themselves to developers as \"show us you can code\", but they advertised themselves to companies as \"we will find candidates who pass your existing hiring process\". And when pressed on which of those things they were actually trying to do, they admitted it was the second one. reply aleph_minus_one 9 hours agorootparent> but they advertised themselves to companies as \"we will find candidates who pass your existing hiring process\"If TripleByte really succeeded with this, the customer companys could save quite some money by simplifying their hiring processes. The problem in my opinion rather is that most company&#x27;s hiring processes have an official and a hidden agenda, and TripleByte only attempted to find candidates that might succeed in the official agenda. reply thaumasiotes 9 hours agorootparent> If TripleByte really succeeded with this, the customer companys could save quite some money by simplifying their hiring processes.No, that&#x27;s what happens if TripleByte succeeds at their fake goal of finding candidates who are good candidates. That&#x27;s the goal they claimed to have without actually having.If all TripleByte does is find candidates who pass your process, you can&#x27;t simplify your hiring process without affecting the quality of the candidates you hire through references from TripleByte. reply aleph_minus_one 8 hours agorootparent> If all TripleByte does is find candidates who pass your process, you can&#x27;t simplify your hiring process without affecting the quality of the candidates you hire through references from TripleByte.If TripleByte is capable of finding candidates who would pass a specific, described process, you theoretically can omit the whole process because by definition, you know that the candidate is able to pass it. In practise, for good reasons, you don&#x27;t want to do this, but it already save quite some money to shorten the process or just do plausibility checks.If these plausibility checks make you realize that TripleByte was overselling (or to put it much more directly: are fraudsters), this should hopefully cause sufficient reputation damage for TripleByte that they go bust; thus TripleByte hopefully has a strong incentive not to oversell. reply thaumasiotes 8 hours agorootparent> If TripleByte is capable of finding candidates who would pass a specific, described processIf you (as a hiring company) can describe your hiring process accurately enough that it&#x27;s possible to specify it, you don&#x27;t need recruiting at all. You can just take applications directly. What you&#x27;re imagining is not related to the problems TripleByte faced.If your goal is, as TripleByte&#x27;s was, to find people who can pass a particular company&#x27;s hiring process, the only way for you to know what that process is like is by experimenting with it empirically.> you theoretically can omit the whole process because by definition, you know that the candidate is able to pass it.Once again, you (aleph_minus_one) are describing the goal of \"find candidates who are good at the job\", not the goal of \"find candidates who will pass the hiring process\".> If these plausibility checks make you realize that TripleByte was overselling (or to put it much more directly: are fraudsters)No, that&#x27;s just what it looks like to you (the company trying to fill spots). The problem people are attempting to address is that the company&#x27;s hiring process is unrelated to what the company wants in a candidate. You are the fraudster; TripleByte in this scenario is the scapegoat for the bad job you do at candidate evaluation. replykevin_nisbet 19 hours agoprevThere is a small blurb about it in patio11&#x27;s year in review.https:&#x2F;&#x2F;www.kalzumeus.com&#x2F;2016&#x2F;12&#x2F;30&#x2F;kalzumeus-software-year...I think I might&#x27;ve been the one referred to as submitting the excel file with the explanation... as I think that was how I solved the last problem on the stockfighter thing. reply tptacek 16 hours agoprevPostmortem:* Our go-to-market was contingency recruiting; we&#x27;d get paid for placements. Our CTF and HN calling cards easily got us added to the recruiting funnels of big tech companies (I&#x27;m assuming any of you could have done that too; I&#x27;m just saying, we never had to cold call). But it didn&#x27;t change anything about how those companies qualified candidates, so to make that business successful we&#x27;d have had to do the same dialing-for-dollars matchmaking work any recruiter does, with comparable results.* We took things very personally. You build relationships with your earliest users (candidates, in our case). Recruiting funnels at our clients had no such connection. The impedance mismatch was demoralizing; our lived experience was that every time a candidate we presented to a client got rejected, we had ourselves failed (I mean, really, we had!). Similarly, the idea that we were just another hoop that candidates had to hop through (but only the non-name-brand candidates who didn&#x27;t know how to skip us to get an interview at a client) grated on us.* A lot of second-system-syndrome on the implementation side; we&#x27;d done successful recruiting CTFs before, and set what was in retrospect a completely bizarre goal of outdoing ourselves at that job. That mistake is all me.* Japan&#x2F;Chicago remote founding team was very difficult, most especially for Patrick. There are teams that could handle that, but their members are more punctual about routine meetings than I am. Both the US and the Japan side felt checked out to each other. This didn&#x27;t kill us; other things did, and we could have pushed through this problem. But it made things miserable for everyone. Again: this is all me.* Erin & I were self-funding the company, which was expensive (just in terms of paying everybody&#x27;s personal bills). Towards the end, it had become clear that we weren&#x27;t going to drive 3 FTE worth of revenue on contingency placements in the next 12 months. We could have switched up the business model, driven user growth metrics, and gone out for seed funding, but none of us at that point were convicted enough of the business to stake our reputations on that. For all 3 of us, our time was worth too much. I think we made the right call.It&#x27;s been almost a decade since we did this, and those years haven&#x27;t been especially kind to recruiting startups. There are knobs we could have turned to keep things chugging, and probably chugging comfortably, for many more years. But ultimately, I don&#x27;t think there were any significant rewards to win by building a tech-company-specific recruiting firm. I think the company was ultimately fated to wind down sooner or later. If you&#x27;re in that situation, sooner is always the better option! Life is short!The underlying idea behind Starfighter, about the right way (or, at least, a right-er way) to hire people, has proven out repeatedly since then. We hired resume-blind and with work-sample challenges at Latacora, the next company me and Erin started, and we hire resume-blind and with work-sample challenges at Fly.io. Recruiting this way is a competitive advantage. The degree of advantage varies with the market; when the market is weak you can hire good people with terrible processes. But the advantage is never marginal, because bad hires are expensive, and there&#x27;s so much hidden talent out there. reply JSeymourATL 16 hours agoparent> But it didn&#x27;t change anything about how those companies qualified candidates...Turns out, finding&#x2F;discovering hidden tech talent is relatively easy.Finding the \"Economic Buyer\", a true hiring executive with budget and authority to make timely hiring decisions gets worse every year.Bureaucratic Red Flag, when HR Bozos start &#x27;adding value&#x27; to the process.As companies grow, they mindlessly get in their own way. reply neilv 16 hours agoparentprevExcellent thoughts, thank you.> We took things very personally. You build relationships with your earliest users (candidates, in our case). Recruiting funnels at our clients had no such connection. The impedance mismatch was demoralizing; our lived experience was that every time a candidate we presented to a client got rejected, we had ourselves failed (I mean, really, we had!). Similarly, the idea that we were just another hoop that candidates had to hop through (but only the non-name-brand candidates who didn&#x27;t know how to skip us to get an interview at a client) grated on us.That sounds rough.If you could do it over, do you see a way you could get more buy-in from some clients, such that they commit to \"advanced placement\" in their process, to candidates you provide? Or are pretty much all companies going to have their entire hiring process set in concrete?What about interfacing at the hiring manager level, at companies where the hiring manager normally has some discretion to vouch for the candidate and bypass a lot of process? Could you get sufficient trust with those? Still the rejection problem? reply tptacek 15 hours agorootparentNo, I don&#x27;t think we could ever have \"fixed\" hiring at companies with enough scale to be lighthouse customers for a business like Starfighter, which was I think a conclusion all 3 of us simultaneously landed on. The engineering team has to be committed to doing things that way. For instance: prior to Starfighter, I hadn&#x27;t had the misfortune of working in a \"leveled\" engineering team (I&#x27;d worked at big tech companies before, but \"levels.fyi\"-style leveling, which is universal now, wasn&#x27;t a thing back when I was still working at bigcos). Work-sample hiring doesn&#x27;t just impact how you make yes&#x2F;no decisions on candidates, but also how you level them.If I was going to do it over again --- and, again, I wouldn&#x27;t, because I feel like I also learned this just isn&#x27;t a great business to be in --- I would have done something much closer to \"Stack Exchange, but for CTFs\". Run a couple of pure investment years, build up a base of users and some public profile, and then do lightweight recruiting stuff (probably just curated job ads for awhile) on top of that. reply zaphar 15 hours agoparentprevI remember you and Patrick hosting a meetup of HN folks once where we talked about Starfighter. I remember thinking that it was an excellent way to hire but every place I&#x27;ve been I&#x27;ve had trouble getting management and HR to buy into it as a strategy. Even when I made it up to VP I still made little to no headway.It&#x27;s very hard to shift companies that are eigher larger or with more internal history than a startup to try something like this. reply clusterhacks 16 hours agoparentprevThanks!! No surprises here from what I read, but definitely appreciate your thoughts.Got a short list of companies in addition to Fly.io that are using a hiring process you like or love? reply clavoie 8 hours agoparentprevFor those of us that missed out, were the CTFs ever documented? Or otherwise recorded somewhere to see what the hoopla was all about? Curious minds inquire ;) reply danielvf 5 hours agorootparentYou basically got Stripe level documentation (high praise) of an API endpoint that would let you get open trade offers, and place trade offers. There was a minimal UI that you could manually operate the system with. Actually understanding what was happening in the markets required you to write something to visualize it with data from API calls.Each level had an increasing level of what you needed to do, with the first level being to buy some stock (which you could do from the UI).Most levels had you operating some kind of marketing making system, where you had to constantly update passive positions that made money as bots traded against them, and the prices shifted.The last level required you to \"hack\" the system to get info you weren&#x27;t supposed to have, in order to identify the insider trader in the middle of 50 other bots. It was quite different from all the other levels.Here was the level solving code from my second run through:https:&#x2F;&#x2F;gist.github.com&#x2F;DanielVF&#x2F;d43e079050d1cf3c05d6 reply neilv 15 hours agoprevThey had a great name.For anyone who didn&#x27;t see the &#x27;80s light sf movie, The Last Starfighter, the premise is appealing and classic: (minor SPOILERS) young adult kid stuck living and working in a trailer park, wants more, there&#x27;s a Starfighter video arcade game set up in the park, one day he goes for the record on the game, and turns out the game was a recruitment tool for something much bigger than his humble trailer park, and he passed, rises to subsequent challenges, and becomes a hero.(Co-stars Robert Preston, as a very enterprising and scrappy recruiting headhunter, a bit like his The Music Man film character, but without the musical numbers.) reply elptacek 9 hours agoparentI think if we&#x27;d survived there would have come a day when we got a letter from somebody&#x27;s lawyer. But as a kid who grew up below the poverty level, the idea of an epic escape remains near and dear to my heart. I&#x27;ve probably seen it 50x. reply toomuchtodo 13 hours agoparentprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4Q-Qs3loKochttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Last_Starfighterhttps:&#x2F;&#x2F;www.imdb.com&#x2F;title&#x2F;tt0087597&#x2F;\"Greetings, Starfighter. You have been recruited by the Star League to defend the Frontier against Xur and the Ko-dan Armada.\" reply ghostpepper 14 hours agoparentprev> without the musical numbersJust imagine how good that could&#x27;ve been though reply tjansen 19 hours agoprevSee also this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=12415786 reply thaumasiotes 19 hours agoparenttptacek&#x27;s comments there repeatedly state that he is (seven years ago) about to publish a postmortem on Starfighter.https:&#x2F;&#x2F;www.kalzumeus.com&#x2F;2016&#x2F;12&#x2F;30&#x2F;kalzumeus-software-year... says the same thing.Did that ever happen? reply tptacek 18 hours agorootparentNope. There&#x27;s a lot of stuff I&#x27;ve meant to write! reply fwungy 18 hours agoprevHere for the F-104 discussion. Fascinating plane. reply MadnessASAP 17 hours agoparentAh yes, the ol&#x27; Lockheed Lawndart. All the fun of flying supersonic at low altitudes and none of that turning nonsense. A masterpiece of flying by the seat of your pants, especially since you definitely wouldn&#x27;t want to take your eyes off the windshield to actually look at your instruments. reply nocoiner 14 hours agorootparentApparently a developer is releasing an F-104 module for DCS. I cannot imagine that taking off, flying in a straight line and crashing somewhere in Germany could be in any way “fun” (even accounting for possibly distorted DCS definitions of “fun”.)I’ll almost certainly buy it, though. reply WA 16 hours agoprevIt was called Stockfighter, not Starfighter. I played a few levels and then it got taken down unfortunately. Would love to try again.Edit: patio11 called it Stockfighter, but others didn’t? Here’s the original launch post: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10724592 reply tptacek 16 hours agoparentNo, Stockfighter was one of two CTFs we ran at Starfighter. reply jacquesm 15 hours agoparentprevIt was named Starfighter after the movie &#x27;The Last Starfighter&#x27; iirc:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Last_Starfighter reply weinzierl 14 hours agoprevI always wanted to play it but my life was quite busy back then. Is there any chance we could have it released as purely a game? reply cushychicken 19 hours agoprevSeen some of patio11’s comments and they suggest there was some part of the business that wasn’t working. What it is exactly was never said. Could have been a myriad of things: financials, product market fit, founder relationships. reply monero-xmr 18 hours agoprevNo one can ever \"solve\" the recruiting issue. We are exactly where we were 15 years ago - not one thing has changed except certain screen-share coding tests, which are basically the same as white boards.Can you reduce hiring an airplane engine designer to a set of tests? Or a custom home builder? If so, why is there not just a stack ranking of best ones, or an algorithmic way of hiring one?Software engineering at elite levels is an art. It is conducted by master craftsmen. On top of it the best people are often quirky &#x2F; weird and the social aspect when communication of needs is so essential makes it even more difficult to hire \"the best\".The business models of recruiting is always either like sales (recruiting firms) or marketing (LinkedIn). I would stay away from the recruiting industry as a software startup - difficult to make any money here in a novel way. reply solardev 18 hours agoparentI wish we had industry-standard certifications that actually meant something, and were widely accepted. The closest I&#x27;ve seen in the real world is just \"degree in comp sci\". Other orgs have tried to come up with various certs, but they never seem to have any sticking power.I guess it&#x27;s a hard thing to certify when the landscape itself is constantly evolving and skills are obsoleted in 3-4 years. It seems even the pace of change is itself speeding up, and every year I see more technologies come to popularity (if not quite maturity) than I can even remember, much less learn. And it&#x27;s not just languages and frameworks, but entire architectures... today&#x27;s best practices are tomorrow&#x27;s tech debt.There should always be room for innovators to push the bleeding edge forward, but many businesses don&#x27;t really need that. Instead, if there was just some shared certification for \"good enough engineering\" that can deliver a reliable, maintainable product somewhat on time, reproducibly, hiring and job-hunting would be so much easier. I&#x27;m so tired of trying to charm recruiters, impress managers, placate HR, all while hoping against hope that the actual dev 2 or 3 interviews later happen to have some overlap in languages, toolsets, shared pain points, etc. It&#x27;s all such a dog and pony show, with many teams having ill-fitting skillsets and cultures between members because nobody really knows what they&#x27;re signing up for or getting. reply arp242 17 hours agorootparentCredentialism is not good either.And in general I&#x27;ve seen little correlation between credentials and quality, both in the software industry and elsewhere, so I don&#x27;t think any such certifications will really solve anything either. reply solardev 17 hours agorootparentI think a more nuanced take on this is that very few companies need top quality, but nobody wants bottom quality.Top-end devs make a name for themselves and don&#x27;t really have to worry about hiring. Companies compete for them with crazy high offers.Bottom-end devs try to make up for their lack of experience or skill by \"hacking\" the application or interview process somehow.In between, \"good enough\" devs power the world&#x27;s bog-standard apps. They&#x27;re not going to win any awards or lead any talks, but they can do the jobs well enough to make the company money. They know they aren&#x27;t top-end and can&#x27;t just say \"I&#x27;m quitting, who&#x27;s hiring?\" on twitter, but they are also competing with the hordes of less-skilled devs because there&#x27;s no easy way to tell them apart.I&#x27;ve never heard of \"credentialism\", but why doesn&#x27;t it work in this instance, when it does for doctors, lawyers, engineers, etc.? reply arp242 15 hours agorootparent> I&#x27;ve never heard of \"credentialism\", but why doesn&#x27;t it work in this instance, when it does for doctors, lawyers, engineers, etc.?There are loads of bad doctors though, and bad lawyers, and bad engineers.\"Credentialism\" refers to over-reliance on credentials, rather than just looking at what someone can do. I&#x27;m not against education, but education is not the same as credentials. People that can hack the interview process can also hack the credentials.I&#x27;ve seen people with college degrees in IT employed as programmers that literally cannot program. I&#x27;m not talking \"bad programmers\" or \"brain fart moment\", I&#x27;m talking \"consistently being unable to grasp even basic control flow over a period of months or years\". Also some good programmers can be hard to work with for reasons other than their programming ability.[1] Plus not every programmer is suitable for every position or every type of programming or \"jibes\" with every other programmer in their sensibilities and approach.[2] The hiring process is just as much about that as testing basic skills.No one thinks credentials are a guarantee of quality (people will always slip through the cracks no matter what), but I&#x27;m not sure they&#x27;re even a strong indicator of quality either, certainly not for programming. This is hard to quantify of course, and just based on my own observations over my career.[1]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21585958[2] Simple example: I&#x27;m firmly in team \"short names\", but I know some people really hate it, but I&#x27;m pragmatic if nothing else and don&#x27;t mind doing whatever works well for the entire team. On one extreme end I&#x27;ve worked in a team that insisted on the longest possible name for everything: every variable had to spell out the full name of the class where it came from, often >20 chars, otherwise people considered it \"unclear what anything refers to!\" I once added a mkdir() function, this was considered \"obscure\" so it had to be \"CreateDir()\", then someone said it may not be clear what \"dir\" is so \"CreateDirectory()\", and then another remarked it actually makes all intermediate directories too, so we ended up with \"CreateRecusiveDirectoryTree()\" – I&#x27;m not saying this is \"wrong\", but it does not jibe well with my sensibilities. Several other things also didn&#x27;t, so I didn&#x27;t last too long). reply tl 13 hours agorootparent> I&#x27;ve seen people with college degrees in IT employed as programmers that literally cannot program. I&#x27;m not talking \"bad programmers\" or \"brain fart moment\", I&#x27;m talking \"consistently being unable to grasp even basic control flow over a period of months or years\". Also some good programmers can be hard to work with for reasons other than their programming ability.Your link talks about \"good programmers that lack social skills\". In my experience, politeness is a finite resource and dealing with people on a regular basis fully unable to do their listed job is a severe tax on mine. reply arp242 5 hours agorootparentI wasn&#x27;t talking about people who are well-intentioned but a bit abrasive if they&#x27;re having a bad day, I was talking about people who are so unpleasant they \"completely crush morale for the rest of the team or company\". reply solardev 14 hours agorootparentprevI hear ya. Essentially, credentials aren&#x27;t a good way to measure -- much less guarantee -- quality? That makes sense.I&#x27;ve encountered several doctors, etc. who weren&#x27;t very good, including one who shouldn&#x27;t have been allowed to practice, IMO. Point taken.Anyway, in your experience, what actually WOULD be a good indicator of candidate quality? reply aleph_minus_one 9 hours agorootparentprev> Top-end devs make a name for themselves and don&#x27;t really have to worry about hiring. Companies compete for them with crazy high offers.Those who don&#x27;t have to worry about hiring are not (necessarily) top-end devs, but good self-promoters and networkers. Not every top-end dev is a good self-promoter or good at networking. reply solardev 8 hours agorootparentFair point. reply monero-xmr 18 hours agorootparentprevIt’s simply too free-form and the industries software is used in are… all of them. I believe it is better to certify the outputs (product features, uptime SLAs, security) than the inputs and how the sausage is made.Software engineering is building a factory. The inputs are data. The outputs are data. All of the stuff inside the application are the different conveyor belts, elevators, gears, rollers, pounders, etchers, etc. to move and manipulate the data to make the output valuable. The factory can be constructed infinite ways without any care about physical dimensions, and the raw material can be duplicated to infinite amounts. The situation is beyond regulation and it should not be regulated. Only the product output should be regulated. reply xyzzy_plugh 17 hours agoparentprevIndeed. I think tptacek&#x27;s perspective on hiring is quite radical, certainly for established shops where doing things differently than the rest of the industry just adds friction elsewhere.My read on the approach is that it works very well for certain types of engagements, but other types, such as where you are trying to build a solid team of peers, requires something _closer_ to the traditional methods. That being said the Starfighter approach is probably right most of the time -- teams are almost certainly never stable, management usually treats ICs as fungible cogs and moves them around, in which case individual value should trump things like team fit or culture. But we&#x27;re human.Appropaches like Google&#x27;s work better (n.b. I am far from a proponent of what they do) because the interviewers are human and despite the whole blind-panel thing if the interviewer and interviewee can&#x27;t get along the interview won&#x27;t go well. So culture and team fit _is_ evaluated significantly more than something like Starfighter. People care a lot about that implicit bit, in my experience. reply wglb 11 hours agorootparentI used this approach at a company of about 750 folks, bending HR to bypass some of their stuff. E.g., they insisted on collecting resumes, but I generally discarded them. Instead, I did a one-on-one phone call for the purpose of them to ask me questions--not to grill them, and to ask them if they would like go to the next step and do a work sample test.I tailored the work sample test to the role. I did it for the compliance hires and for the project manager. The results were unexpectedly excellent.As a result of this process, and having a solid company culture, there are around ten or twelve folks that have a new career in the security field that would likely not have had another opportunity in the classical hiring scheme.I think the state of the industry with respect to hiring and evaluating folks is broken across the whole spectrum. It is like once someone becomes established in a field, they invent all manner of gatekeeping tests that they didn&#x27;t pass to get where they are. The whole story of sabermetrics is another example. reply tptacek 16 hours agorootparentprevFly.io is several solid teams of peers, built on resume-blind work-sample hiring. reply xyzzy_plugh 16 hours agorootparentFor sure! But the company was built that way. An existing 1000 person corp works differently.Everyone has to be on board for it to work, I&#x27;d wager. reply dmoy 17 hours agoparentprevYea it&#x27;s a problem. You&#x27;re trying to hire from a pool that includes very competent people, and also people who legitimately can&#x27;t write any code at all and are just trying to sneak in for 6mo to get $100k before they get fired, or think that \"fake it til you make it\" is a real thing. But at the same time, unlike other engineering disciples there&#x27;s no PE licensing exams (or whatever the FAA does, I forget), no equivalent degree requirements (for good reason - one can learn to code without it, and a huge portion of a CS degree is very theoretical), but at the same time is qjite difficult, nothing like a plumber&#x2F;electrician&#x2F;etc certification level with accompanying work requirements and an apprenticeship program, and has very high pay and demand.For very small shops willing to incur legal risk or limit the application pool, you can do take home tests and&#x2F;or lean on side projects, with an hour of explaining the nitty gritty details and choices. At scale it becomes untenable, because you open yourself up for discrimination lawsuits, and you can&#x27;t convince a lot of people who already have jobs and families to do lengthier take home stuff.If I had to bet, I&#x27;d bet some day it ends up like plumbing. You work as an apprentice, learn real stuff on the job, and then there&#x27;s some kind of state certification which itself is a joke, but requires you to have gone through an apprenticeship program already where all the real shit happens.Companies trying to hire \"the best\" or whatever are still going to have problems, so as long as there&#x27;s not much regulation increasing cost of dev and uniformity by an alarming degree, we&#x27;ll still have insane hiring (and insane pay too, regs will make it unprofitable eventually). reply fdye 17 hours agorootparentSo my $0.02 from being on both the hiring and trying to get hired side of the fence. Also I can&#x27;t do a whiteboard interview to save my life, never could. I mostly think the process everyone is running makes a bit more sense for entry-level applicants. You are dealing with a candidate pool exactly like what you describe above. However, for anything above a junior dev it is horribly inefficient.Instead I&#x27;m always surprised more places don&#x27;t rely on references and prior experience. Yes people lie, but in my experience its relatively easy to tell the difference with a simple glance at their LinkedIn. If I look at a candidate that spent 2-3 yrs as a Software Engineer at some company that I&#x27;m relatively familiar with, and they seem to have 2nds and thirds to people I know in the industry, then pretty good chance they aren&#x27;t lying. Same for people taking the time out to write recommendations for them. Even bigger signal if they want setup some calls with their prior co-workers who can vouch for them, to me that means they stand by their work and reputation.I recently went through about seven rounds for a senior role. During that time I repeatedly offered to setup some time with my prior coworkers from those I directly managed, to peers, to those I reported to (executive team). My thinking being that they could hear from the horses mouth how I lead a team, my work ethic, etc. They did not take me up on the offer, which to me was crazy. Yes, I could be running some machiavellian scam with 2-3 people who also made a fake LinkedIn, I also could have put up fake articles in PR Newswire announcing my last position, could have spoofed all those blogs I co-authored from the company I worked at 2 jobs ago, etc. But really, wouldn&#x27;t it be a better signal for a candidate to offer and have all these things?Instead you see an industry that puts someone with ~10 yrs experience through a whiteboard interview. It makes no sense. reply eldavido 16 hours agorootparentI think this is more in line with how hiring works for senior jobs. I&#x27;ve been part of 50+ hiring decisions and do it like this.Social stuff is absolutely the first thing I&#x27;m checking. It&#x27;s a quick test to spot total lies, e.g. you claim you worked somewhere but are connected with zero people on any social network, or claim attendance at a school with zero connection to anyone. If nothing else, it helps to build rapport for the interview.I would 100%, absolutely trust a personal recommendation over a dumb whiteboard interview. reply aleph_minus_one 8 hours agorootparent> Social stuff is absolutely the first thing I&#x27;m checking. It&#x27;s a quick test to spot total lies, e.g. you claim you worked somewhere but are connected with zero people on any social network, or claim attendance at a school with zero connection to anyone. If nothing else, it helps to build rapport for the interview.There exist quite a lot of people who have no account on any social network for privacy reasons. reply aleph_minus_one 8 hours agorootparentprev> If I look at a candidate that spent 2-3 yrs as a Software Engineer at some company that I&#x27;m relatively familiar with, and they seem to have 2nds and thirds to people I know in the industry, then pretty good chance they aren&#x27;t lying.The problem is: there exist a lot of companies - you can only be familiar with a very small fraction of them. Also, for many big companies, the differences between departments or groups can be a lot larger than between companies of similar size and sector. reply bluecheese452 8 hours agorootparentprevIf you could credibly spoof all that most companies would love to hire you. Would likely be your most valuable skill. reply relaxing 14 hours agorootparentprevSeven rounds! What questions was this company asking you for seven rounds?Every time I’ve had a company go longer than 2 rounds, another company got me an offer first. reply gedy 12 hours agorootparentNot the OP, but Elastic and Glassdoor had me do 6-7 rounds.Glassdoor had the gall to just ghost me after the 6th! Never again. reply relaxing 10 hours agorootparentWhat questions were they asking you over so many rounds? Like how much more information about a candidate could one possibly need? reply gedy 9 hours agorootparentI think they were stringing me out while interviewing others. I should have seen through it, but wanted it to work out at the time. replyfragmede 17 hours agorootparentprevDay to day, how much code do you think principle and staff engineers write? Senior architects and team leads? The problem is I don&#x27;t think we, as an engineering discipline and career path, are willing to recognize that the job of being a coder stops being about writing code! Yes there are deadbeats who don&#x27;t contribute (some of them can code just fine), as there are in every industry, but until you&#x27;ve been in a project that failed because there was no senior architect, someone getting paid a comfortable salary to be the \"senior architect\" and not write code sounds like a waste of the company&#x27;s money to the intern.At the start of a SWE career, I don&#x27;t think things broken. Study up some leetcode and write code on a whiteboard to prove that you, as a candidate, are smart and motivated enough to play the game. It&#x27;s after that, that things get out of sync and you get absolutely amazing people who have written world changing software who can&#x27;t pass your stupid puzzle of a whiteboard interview. And then what do you do? This person failed your test but you want to hire them. Here&#x27;s the part where we fail, where we are too stuck on following the rules.They failed the test so you can&#x27;t make an offer? No. Move heaven and Earth to bend the rules, and make them the offer anyway. Don&#x27;t hide behind corporate handbooks and the HR or the legal department.Obviously this power can be abused, but I don&#x27;t take it as a given that it must be, given a hiring panel.Google could have made an offer to Homebrew&#x27;s Max Howell but chose not to, which speaks volumes. reply aleph_minus_one 7 hours agorootparent> Google could have made an offer to Homebrew&#x27;s Max Howell but chose not to, which speaks volumes.Programming is divided into a multitude of various cultures with their own (often incompatible) rules. Not without reason, you tend to talk of a \"Java shop\", \"C# shop\", \"Python shop\", ...So, when looking for a good programmer, you either look for a beginner who is still \"malleable\" into your desired culture, or has the same right pedigree as your company.In this sense, I a priori have no doubt that Max Howell is a decent programmer, but I do believe that he comes from and is attached to a very different programming culture than Google&#x27;s; thus he would likely not be a good fit. reply lmm 5 hours agorootparentprev> Yes there are deadbeats who don&#x27;t contribute (some of them can code just fine), as there are in every industry, but until you&#x27;ve been in a project that failed because there was no senior architect, someone getting paid a comfortable salary to be the \"senior architect\" and not write code sounds like a waste of the company&#x27;s money to the intern.Oh, if only the worst was not contributing. I&#x27;ve been at a company full of brilliant programmers that was just driven into the ground by the senior architect, who wasn&#x27;t necessary. Hiring someone who can&#x27;t Fizzbuzz for that position (and giving him the authority to overrule the development leads) was absolutely the single decision that sank that company. reply Alex3917 17 hours agorootparentprev> For very small shops willing to incur legal risk or limit the application pool, you can do take home tests and&#x2F;or lean on side projects, with an hour of explaining the nitty gritty details and choices. At scale it becomes untenable, because you open yourself up for discrimination lawsuits, and you can&#x27;t convince a lot of people who already have jobs and families to do lengthier take home stuff.At the end of the day, programming is just a writing job. So if you apply for non-technical writing jobs, e.g. to be a columnist at The New York Times or The New Yorker, do they not read any of your preexisting work on the grounds that it could open them up to discrimination lawsuits? Similarly, do folks who hire designers typically not look at their portfolios? reply dmoy 13 hours agorootparent> So if you apply for non-technical writing jobs, e.g. to be a columnist at The New York Times or The New Yorker, do they not read any of your preexisting work on the grounds that it could open them up to discrimination lawsuits?If you work in an industry where nothing is published publicly, and then demand to see people&#x27;s side blogs and use that for hiring decisions, then yea that&#x27;ll make lawyers at a big company a little skittish.It&#x27;s a different thing when your job is to write things that everyone can see, vs having your company own everything you do. reply scarby2 17 hours agorootparentprev> or think that \"fake it til you make it\" is a real thing.Fake it to you make it is actually a real thing. Though you actually have to be able to make it. You can overstate qualifications and experience but not competence. I don&#x27;t lie about anything but i&#x27;ve definitely known people who have lied in order to get hired who have gone on to perform extremely well. reply dmoy 12 hours agorootparentSure I mean the extreme form, as in \"literally cannot write any code at all\" yet getting interviewed at XYZ tech company, and then being shocked when there&#x27;s a coding interview. Bonus points when they&#x27;ve somehow talked there way all the way onsite, wasting 10+ hours of engineering time, and 48&#x2F;72+ hours of their own time, before it&#x27;s discovered that they can&#x27;t in fact write code at all in any language. (I mean like 1 variable for-loop pseudocode, think fizzbuzz except without any conditional logic, even easier).People absolutely embellish and get away with it. reply jvickers 17 hours agorootparentprev> because you open yourself up for discrimination lawsuitsIs that because when looking to make a possibly subjective judgement on the performance in a test and especially what a side project shows, it then becomes more difficult to prove that the judgement was not instead made because of some protected characteristic of the candidate? reply dmoy 12 hours agorootparentThat, and a big chunk of it is kids. In the same way you can&#x27;t decline to hire someone because they&#x27;re pregnant or may soon become pregnant (or are the father side of that equation) - requiring side projects is a very thin&#x2F;loose proxy for \"doesn&#x27;t have kids\". It&#x27;s not a big enough problem to really stop people, but a big company&#x27;s lawyers will stop it internally. reply Apocryphon 16 hours agorootparentprevThe threat of litigation does not actually exist in terms of software engineering interviews:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22258113 reply dmoy 12 hours agorootparentBut people have absolutely sued, successfully, for discrimination. Just not in the context of being treated like an adult by an interviewing system that gives actual feedback.Notably virtually no big companies will give feedback by policy, because of their own lawyers. All the engineers on the other side would freaking love to give constructive feedback. Their own lawyers prevent them from doing so. reply Apocryphon 12 hours agorootparentSource? Which tech companies? Or is it just the amorphous possibility of suits? reply dmoy 11 hours agorootparentYes tech companies get sued for discrimination in hiring on a routine basis. The issue with giving feedback is the you hand evidence to the opposing side in a future lawsuit. There&#x27;s very little benefit for the company, and a lot of risk.Microsoft settled three years ago on a race discrimination in hiring thing. And two years ago for discriminating against non-citizens (and in some twist, Facebook settled the same year for discriminating against citizens, so... damned either way).Just this year Workday got sued for discrimination in hiring, which is mildly hilarious because they&#x27;re the HR-as-a-service company.> Or is it just the amorphous possibility of suits?It&#x27;s mostly this, driven by the lawyers. They&#x27;ve seen a few previous settlements and just decide \"well, none of that here\".I don&#x27;t know if you&#x27;ve ever done hiring at a big company, or sat through the legal training things, but even if you don&#x27;t draw a lawyer who tells it to you straight, it&#x27;s pretty easy to infer what&#x27;s going on. reply dmoy 9 hours agorootparentRight, to be specific, the worry isn&#x27;t:Give feedback -> get sued due to something in the feedbackThe worry is:Give feedback -> ??? -> get sued for discrimination-> feedback is used as evidence that the hiring decision wasn&#x27;t for a concrete&#x2F;justifiable reason once its torn apart by a lawyer in front of a jury of 12 random people, only 7 of whom you need to convince. replytracerbulletx 16 hours agoparentprevSoftware interviews feel more like an audition which isn&#x27;t necessarily a bad approach, except we&#x27;re using random people sometimes with two years of experience or who do not even want to be there as casting directors. reply slater 18 hours agoprevOT, but what&#x27;s with the weird apostrophe&#x2F;tick before each name in OP? reply quesera 14 hours agoparentOne of the founders of Starfighter wanted to popularize the leading tick as the HN-equivalent of the @ on other social networks.I read it as an homage to HN days of yore. reply tptacek 13 hours agorootparentIt&#x27;s better than @! @tptacek isn&#x27;t me! reply kristjansson 18 hours agoparentprevI read it as a LISP-y (and therefore HN-y) version of @ reply solardev 18 hours agorootparentI read it as an unterminated string and kept looking for the end =&#x2F; reply password4321 17 hours agorootparentprevI vote for ƛ reply wkat4242 16 hours agoprev [–] Lol I thought this was about the infamous F-104 Starfighter that killed hundreds of pilots in Europe.And it was only purchased because Lockheed paid millions in bribes to officials for which AFAIK none of them (nor the company) were ever punished.So in terms of post-mortem I was thinking of something official like that :)Ps its successor the F-16 was a lot better though and is still going strong today. reply Miraste 15 hours agoparent [–] >killed hundreds of pilotsWow, I thought you must be exaggerating, but it was literally hundreds. Some air forces lost nearly half the planes! reply wkat4242 12 hours agorootparent [–] Yeah it was basically the G version for export, the plane was originally designed as a fast interceptor. But it was converted to a fighter&#x2F;bomber for NATO allies that needed one. With its tiny wings it was just not great for low & slow bombing runs in poor visibility.Added to that were inexperienced crews and well, disaster ensued :P They called it the lawn dart or widowmaker in Germany.I think this is why the F-16 was so much more popular in Europe, it was actually designed as multirole and was and is good at it. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Starfighter, a hiring startup founded by HN veterans, utilized a CTF/Microcorruption style test for recruitment purposes.",
      "The company has, unfortunately, closed down. The reasons behind this closure remain unspecified as no post-mortem analysis appears to have been written.",
      "The use of a Capture The Flag (CTF) or Microcorruption style test in recruitment is an innovative approach, demonstrating the company's unique perspective in the hiring process."
    ],
    "commentSummary": [
      "The debate revolves around hiring process challenges in the tech industry, citing issues with credential reliability and inefficacy of certain screening methods.",
      "Participants stress the need for alternative evaluation methods, emphasizing the importance of personal recommendations and previous experience in candidate assessment.",
      "The discussion brings up the possibility of apprenticeship programs and changes to the hiring process to correspond better with senior roles, reflecting on the difficulties startups face in the industry."
    ],
    "points": 178,
    "commentCount": 141,
    "retryCount": 0,
    "time": 1698068387
  },
  {
    "id": 37995119,
    "title": "NASA just sent a software update to a spacecraft 12B miles away",
    "originLink": "https://bgr.com/science/nasa-just-sent-a-software-update-to-a-spacecraft-12-billion-miles-away/",
    "originBody": "Subscribe News Reviews Best Guides Deals More TRENDING: Nintendo Switch 2 iPhone 15 Amazon Gift Card Deals Connect AirPods Best Deals New on Netflix New on Hulu No Caller ID Free Streaming Apps iOS 18 If you buy through a BGR link, we may earn an affiliate commission, helping support our expert product labs. Home Science Space NASA just sent a software update to a spacecraft 12 billion miles away By Joshua Hawkins Published Oct 23rd, 2023 9:09PM EDT Image: NASA/JPL-Caltech Voyager 2 is over 12 billion miles from Earth, making its way through interstellar space. Along its almost 50-year journey, the probe has seen more of the universe than we ever will. Now, NASA has completed a critical software update for Voyager 2 that will help keep it running even longer. Tech. Entertainment. Science. Your inbox. Sign up for the most interesting tech & entertainment news out there. Email: SIGN UP By signing up, I agree to the Terms of Use and have reviewed the Privacy Notice. The update, which took almost 18 hours to complete, was transmitted to help Voyager 2 avoid the same problem that its sibling, Voyager 1, experienced last year. Back in 2022, NASA reported issues with readings from Voyager 1’s AACS, which stands for attitude articular and control system. The telemetry data that NASA was getting didn’t make sense, and NASA was concerned it had lost the probe forever. Thankfully, the issue doesn’t seem to have caused any lasting issues with Voyager 1, but NASA wants to avoid the same thing happening with Voyager 2, so it just sent out this huge software update. The patch is essentially an insurance policy that NASA hopes will project the probe for future interstellar space exploration. An older image showing Voyager 1 and Voyager 2 both outside of the Heliosphere. Image source: NASA/JPL-Caltech Because the space probe is so far away, the data it sends back is exceptionally unique and important. And, since it took so long to send the update, NASA scientists are carrying out a readout of the AACS memory to ensure that it is in the right place for the update. If there aren’t any issues, it will trigger the Voyager 2 update on October 28. Considering NASA lost contact with Voyager 2 briefly earlier this year, the test has many people on the edge of their seats, waiting to see where things go. NASA plans to use Voyager 2 as a testbed for the update. If all goes according to plan, it will also send the patch to Voyager 1, which is currently more than 15 billion miles away from Earth, thus making its data even more valuable than that of Voyager 2. The space agency says it is also allowing both probes to turn more before reorienting them in an attempt to slow the build-up of propellant residue in the fuel lines. Either way, both probes will hopefully get the update, allowing them to run for several more years before NASA has to worry about either of them giving out. Don’t Miss: AI detected a supernova without help from humans This article talks about: NASA VOYAGER 2 Joshua Hawkins Writer Josh Hawkins has been writing for over a decade, covering science, gaming, and tech culture. He also is a top-rated product reviewer with experience in extensively researched product comparisons, headphones, and gaming devices. Whenever he isn’t busy writing about tech or gadgets, he can usually be found enjoying a new world in a video game, or tinkering with something on his computer. Joshua Hawkins's latest stories REVR is a low-cost kit that makes gas cars electric BitLocker in Windows 11 Pro could be slowing your SSD down Someone just overclocked Intel's Core i9-14900KF to a record-breaking 9GHz Wild Moments Luckily Captured By Elevator Cameras Here's What Happens When People Forget There Are Cameras In Elevators UnPastedSponsored Learn more What is USB-C, and why does it matter so much? Not sure why everyone is so worried about USB-C? Here are a few important reasons why USB-C matters so much. BGR When You Eat Avocado Every Day, This Is What May Happen GundryMDSponsored Learn more Chuck Norris In His 80s Says Try This Once a Day for More Energy Americamorningsupply.comSponsored Watch now Forget Retinol, Use This Household Item To Fill In Wrinkles Beverly Hills MDSponsored Learn more Top Doctor: If You Eat Oatmeal Every Day, This Is What Happens GundryMDSponsored Learn more Here Are the Coolest Gifts Of October TheWalletGuruSponsored Learn more No More Free Returns? Amazon Releases New Fees Americans, you'll want to check this out ASAP Online Shopping ToolsSponsored New Electric SUVs Come with Tiny Price Tags (Take a Look) CommonSearchesSponsored Most Windows Users Didn’t Know They Can Block Ads (Do It Now) Chrome users can now block all ads and speed up their browsing; not only will you reduce your data usage but also protect against malicious links. It's now easier than ever! Smart Security TipsSponsored Learn More Benefits Seniors Are Entitled To In CA, But Often Forget To Claim TheWalletGuru.comSponsored 2 Steps To Tell When A Slot is Close To Hitting The Jackpot Join Online Casino and Get a Match Bonus Buzzdaily WinnersSponsored Play Now Prime Is Now $179, But Few Know This Free Savings Hack Online Shopping ToolsSponsored Learn More This New Device Is Leaving Neuropаthy Experts Bаffled Health Insight JournalSponsored Learn More The Jet That Escorts Air Force One, Explained This is something most never knew... LivestlySponsored More Science A dwarf planet close to Mars could have what it takes to sustain life Science Joshua Hawkins AI detected a supernova without help from humans Science Joshua Hawkins We have a very small opportunity to save Greenland’s ice sheet, study claims Science Joshua Hawkins James Webb spots ultra-powerful jet stream on Jupiter Science Joshua Hawkins Latest News Microsoft’s Project Silica turns glass into futuristic data storage Tech Chris Smith New on Max: November 2023 Entertainment Jacob Siegal Xbox announces surprise Partner Preview event for October 25 — here’s how to watch Entertainment Joe Wituschek Ryan Reynolds wants Deadpool to lose in Deadpool 3 Entertainment Chris Smith Tech. Entertainment. Science. Your inbox. Sign up for the most interesting tech & entertainment news out there. Email: SIGN UP By signing up, I agree to the Terms of Use and have reviewed the Privacy Notice. News & Reviews You Can Trust BGR’s audience craves our industry-leading insights on the latest in tech and entertainment, as well as our authoritative and expansive reviews. We guide our loyal readers to some of the best products, latest trends, and most engaging stories with non-stop coverage, available across all major news platforms. Editorial Standards How We Test Products Founded in 2006 Over 2 billion visitors 100K+ articles published Millions of readers helped GREENWICH, CT Our Mission Statement Honest news coverage, reviews, and opinions since 2006. - Jonathan S. Geller, Founder News Tech Entertainment Science Reviews Deals Guides About BGR Advertising Contact Us Privacy Policy AdChoices Terms Of Use California Privacy Rights Your Privacy Choices BGR is a part of Penske Media Corporation. © 2023 BGR Media, LLC. All Rights Reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=37995119",
    "commentBody": "NASA just sent a software update to a spacecraft 12B miles awayHacker NewspastloginNASA just sent a software update to a spacecraft 12B miles away (bgr.com) 176 points by quyleanh 4 hours ago| hidepastfavorite99 comments qrybam 3 hours agoThis is incredible. Not just because of the engineering that went into such a long lived machine, but also because of the ingenuity of the teams that have looked after this mission and those currently working on it.Half a century of operation. Bits of data, like gold dust, peppering our radio telescopes with telemetry from the edges of our protective solar shell, and beyond.Not only is the technical achievement something to be celebrated, but the pushing of boundaries of our understanding is awe inspiring. It carries the symbolism of some of the best parts of humanity’s desire to explore.This sort of news, at least for me, is an antidote to the darker side of our species. It reinvigorates my hope in what we can achieve when working together.Thank you to NASA and the scientific community at large. reply pantulis 2 hours agoparent> Not only is the technical achievement something to be celebratedOnly the _documentation_ effort must be monumental. reply quietpain 2 hours agorootparentLets hope the _archival_ effort can match or in 50 years time we’ll have another one of these:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Apollo_11_missing_tapeshttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Stolen_and_missing_Moon_rock... reply shiroiuma 1 hour agorootparentEven with those problems, those are still far better than the (complete lack of) documentation I see in software workplaces these days. reply OldGuyInTheClub 2 hours agorootparentprevYes, and JPL makes it available.Voyager Telecom: https:&#x2F;&#x2F;descanso.jpl.nasa.gov&#x2F;DPSummary&#x2F;Descanso4--Voyager_n...A lot more at the top-level site and the links on the right-hand side: https:&#x2F;&#x2F;descanso.jpl.nasa.gov&#x2F; reply Aardwolf 2 hours agoparentprevAlso the fact that this CPU is still running at all, after such long time in such hostile environment (radiation, temperatures)! reply shiroiuma 1 hour agorootparentThese spacecraft don&#x27;t have CPUs, at least not the way we think of them, in the sense of a single microprocessor IC. Their \"CPUs\" are built from discrete logic gates on CMOS and TTL ICs, the way the earliest digital arcade games were.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Voyager_program#Computers_and_... reply varjag 1 hour agorootparentThe concept of CPU predates micro-processors. They were cabinet sized originally. reply coldtea 1 hour agoprevBefore:In 1994 JPL started working on the Remote Agent (RA), an autonomous spacecraft control system. RA was written entirely in Common Lisp despite unrelenting political pressure to move to C++. At one point an attempt was made to port one part of the system (the planner) to C++. This attempt had to be abandoned after a year. Based on this experience I think it&#x27;s safe to say that if not for Lisp the Remote Agent would have failed.We used four different Common Lisps in the course of the Remote Agent project: MCL, Allegro, Harlequin, and CLisp. These ran in various combinations on three different operating systems: MacOS, SunOS, and vxWorks. Harlequin was the Lisp that eventually flew on the spacecraft. Most of the ground development was done in MCL and Allegro. (CLisp was also ported to vxWorks, and probably would have been the flight Lisp but for the fact that it lacked threads.) We moved code effortlessly back and forth among these systems.The Remote Agent software, running on a custom port of Harlequin Common Lisp, flew aboard Deep Space 1 (DS1), the first mission of NASA&#x27;s New Millennium program. Remote Agent controlled DS1 for two days in May of 1999. During that time we were able to debug and fix a race condition that had not shown up during ground testing. (Debugging a program running on a $100M piece of hardware that is 100 million miles away is an interesting experience. Having a read-eval-print loop running on the spacecraft proved invaluable in finding and fixing the problem. The story of the Remote Agent bug is an interesting one in and of itself.)The Remote Agent was subsequently named \"NASA Software of the Year\".https:&#x2F;&#x2F;flownet.com&#x2F;gat&#x2F;jpl-lisp.html reply rich_sasha 2 hours agoprevThey are doing it all wrong. Who runs on-prem hardware these days??? They should put it all in the cloud, they can replicate and have many instances of virtual Voyagers, not the measly 2. CDN should help with latency too, I hear their latency is measured in many hours, and is getting worse every day! Also, software update, big deal - use CI&#x2F;CD!They probably don&#x27;t have a Kanban board either... Dinosaurs! reply kzrdude 1 hour agoparentThey are hard at work putting it in the Oort cloud. reply sgt 1 hour agoparentprevTheir latest patch was actually converting the entire app to use npm. Let&#x27;s hope the poor probe has enough memory. reply rahen 1 hour agorootparentWith npm, 64GB ought to be enough for everyone. reply kosolam 1 hour agorootparentA rust rewrite from scratch is already in process reply rahen 16 minutes agorootparentGreat, I&#x27;ll take the Web Assembly version. reply gorbachev 46 minutes agorootparentprevA Go rewrite from scratch soon to follow. reply jtvjan 0 minutes agorootparentA rewrite in Scratch is in the early planning stages. girafffe_i 1 hour agorootparentprevLol reply fredsted 1 hour agoparentprevI bet it doesn&#x27;t even run Kubernetes. reply imdsm 1 hour agoparentprevRun it in the nebula! reply tjrgergw 58 minutes agorootparentI was gonna say \"run it in the stars\", but yours is funnier for some reason :-) reply worthless-trash 1 hour agoparentprevI both love and hate it at the same time, well done. reply zelphirkalt 4 minutes agoprevI guess their code for signal correction for the case of package loss or data loss on in transit has to be fascinating. Or it is some simple, yet always working method. Anyway, would be cool to read about the details of that logic&#x2F;implementation. reply fuzzythinker 2 hours agoprevTo put the 12B miles in an easier grasp, Pluto&#x27;s average distance is 3.7B miles. So Voyager 2 is a hair under 3.3 Plutos away, and Voyager 1 at 15B miles is slightly over 4 Plutos away.Another point of reference is the heliosphere, at 100AU. 1AU (earth to Sun) is 93M miles, so the heliosphere is around 2.5 Plutos away. reply physicles 1 hour agoparentOn some other YouTube channel, I recently saw a diagram where the width was 0.01 light-year. That’s “only” about 59 billion miles; surely we can’t be too far from the moment we can conceive of Voyager 1’s distance in light-years.Nope. At its current speed, we’ve got another 129 years. That’s an underestimate because the spacecraft will continue to decelerate a bit as it pulls farther away from the sun.That’s about 60,000 years to the nearest star. reply amelius 1 hour agoparentprevA more relevant measure (for software updates etc.) would be light-years or light-seconds etc. reply shiroiuma 1 hour agoparentprevI thought I read more recently that they&#x27;re no longer sure about where the heliosphere ends, because of the data returned from the V&#x27;ger probes. reply shmde 53 minutes agoparentprevMuricans will use anything but metric. reply badrabbit 49 minutes agorootparentMetric doesn&#x27;t let people grasp large numbers. reply martin_a 43 minutes agorootparent19.312.128.000 km is a pretty big number, people can grasp that. reply jdblair 26 minutes agoprevIf you want to learn about how the Voyager flight data system is designed, read Nasa&#x27;s historical document Chapter 6: Distributed Computing On Board Voyager and Galileo [1].The whole read is gripping, but the most interesting part for me is the section \"Developing Voyager&#x27;s Flight Data System Computer \" describes the choice to use CMOS memory and DMA from instruments.[1] https:&#x2F;&#x2F;history.nasa.gov&#x2F;computers&#x2F;Ch6-2.html reply jdblair 25 minutes agoparentIt was a different world in 1975: After determining requirements, Wooddell examined possible hardware and software tradeoffs. In an insightful memorandum, John Morecroft explained the concept of \"soft logic\" as a complement to the \"hard logic\" in the Flight Data System44. Writing in 1975, when the actual flight software began to be prepared, Morecroft pointed out that the program for the computer was actually a soft representation of hard-wired circuits. Conceptually, the memo stands as an explanation of the essential meaning of firmware in general. reply deepGem 2 hours agoprevWhat got me intrigued was how did they send the update and what was the size of the update. Sadly no mention of those aspects in the article. Is there any way to find out ?I was feeling so low today that I just switched to HN to tune things off of my mind, saw this headline and right off the bat, am in a better mood.What an incredible feat of engineering ! reply perilunar 2 hours agoparenthttps:&#x2F;&#x2F;eyes.nasa.gov&#x2F;dsn&#x2F;dsn.html reply kaptainscarlet 3 hours agoprevI hope this update doesn&#x27;t come with ads and data collection to \"improve my experience\" reply leokennis 15 minutes agoparentVoyagerOS Updated yesterday 529BBugs fixes and improvements, watered the plants, took out the trash.Keep VoyagerOS up to date to always have the best experience! reply donmcronald 2 hours agoparentprevSometimes I wonder if the Win11 start menu search is running on something 12B miles away. Lol. reply misja111 31 minutes agoprevFrom Wikipedia:> There are three different computer types on the Voyager spacecraft, two of each kind, sometimes used for redundancy. They are proprietary, custom-built computers built from CMOS and TTL medium-scale CMOS integrated circuits and discrete components, mostly from the 7400 series of Texas Instruments.[34] Total number of words among the six computers is about 32K.32K memory to manage such a complex device for 46 years .. Nowadays the size of an OS is measured in GB&#x27;s. reply xbmcuser 2 hours agoprevIt takes around 22+ hours for 1 way communication to Voyager if I recall correctly. It takes 8 min for light to reach earth from the Sun. The closest star is 4.24 light years away. These kinds of distances are hard wrap your mind around. reply imdsm 1 hour agoprevIs this considered OTA given space is a vacuum?Also, I&#x27;ve had some scary deployments in my time but this would take the biscuit! reply seydor 28 minutes agoprevPeople jest the quality of our current software, but it&#x27;s a real concern. The programmer of the &#x27;2023 update&#x27; is conditioned to bundle too much unneccesary bloat to the update that could eventually slow down and obsolete the device. reply andyp-kw 3 hours agoprevWere unit tests a thing back when the probes were built?I wonder how new engineers learn about the intricacies of such ancient tech, without breaking them. reply perilunar 2 hours agoparentUnit tests — probably not.They likely have a &#x27;test article&#x27; though. See: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Test_article_(aerospace) reply wannacboatmovie 2 hours agoparentprevSadly the \"megabytes of JavaScript to &#x27;hello world&#x27;\" culture of today could not even begin to comprehend how this even works reply hef19898 1 hour agorootparentIt funny, usually people on HN diss NASA et all hard for being those big, inept governkent agencies, with SpaceX being so so mich better because SpaceX get SW\"engineering\". And then NASA does something like this, and all of sudden it so cool! Coupd it be that those orgs aren&#x27;t even nearly as incompetent as people have a tendency to think? reply skissane 1 hour agorootparent> It funny, usually people on HN diss NASA et all hard for being those big, inept governkent agencies, with SpaceX being so so mich better becauseMany of NASA’s problems aren’t the fault of NASA, they are the fault of Congress. NASA didn’t come up with SLS+Orion all by themselves, the high-level design was dictated to them by Congress and NASA was left with the job of fleshing out the details and making it all work somehow. SpaceX needs NASA as a customer and a source of valuable expertise, it just wants it freed from being forced by Congress to spend billions on super-inefficient projects such as SLS+Orion, when SpaceX has a solution which can do more for less (Starship+SuperHeavy) and is likely to be available soon (bureaucratic delays due to the FAA and environmental agencies such as the FWS being under-resourced being the current biggest obstacle to that) reply hef19898 1 hour agorootparentSo SpaceX wants NASA to be able to spend all those billions with them instead of a competitor? Shroud business move, that says nothing about capabilities.Just one question, what will be avaiable first, FalconHeavy and a fully certified Starship (which has to launch without blowing up for that), Tesla FSD or Tesla&#x27;s humanoid robot?Regarding SLS, they launched successfully last year and aim for a manned launch in 2024. SpaceX has to beat that timeline, assuming this whole thing being a race, which it isn&#x27;t. reply somenameforme 26 minutes agorootparentFalcon Heavy has been launching commercial, government, and military payloads successfully for years now. [1] I&#x27;d strongly encourage checking out their first successful test launch of it, from 5 years ago. [2] Skip to about 29 minutes in for the money shot. Still gives me goose bumps!So let&#x27;s compare the two! Falcon Heavy was developed with completely private funding, at a cost of ~$500 million. The prices of the launches are listed in Wiki. They start at $117 million, as NASA paid in 2023 to launch their Psyche craft. The SLS has been in development for more than a decade now, fully paid by the taxpayer, at a cost just about to break the $30 billion mark. The nominal cost per launch is still unknown but will almost certainly top a billion dollars. The last NASA administration gave an estimate of $800-$900 million per launch in 2019 dollars. And SLS cost estimates only go one way.And what do you get for $30 billion, and then another billion per launch? Ideally up to almost twice the capacity of a Falcon Heavy. The reason people are so cool on the SLS is that it&#x27;s already a very poor value against existing technologies. And will be completely obsolete by the time Starship comes to pass which should not only be able to launch for a fraction of the cost of Falcon Heavy (which is already a fraction of the cost of SLS), but also launch well over the ideal launch capacity of SLS.[1] - https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Falcon_Heavy#Launches_and_payl...[2] - https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wbSwFU6tY1c reply hef19898 8 minutes agorootparentWe do not have any reliable financials from SpaceX, just advertized launch costs and PR releases. SLS on the other hand has, as does e.g. Ariane-6, public budgets and a lot more bureaucracy.For Starship to make things like SLS obsolete, it has to be available first. Until then, it is just pure speculation. Is SLS more expensive than Starship development wise? Yes. But it is not the goal of a government to be profitable, nor is it to hand technologocal monopolies to eratic billionaires. Supporting alternatives is always good, and it maintains know-how and technology at different companies, which is also a good thing. somenameforme 55 minutes agorootparentprevPersonally, I&#x27;d tend to give most credit for something like this to the era that created it. I mean building something that can be reasonably expected to operate and maintained in some of the most hostile conditions known to man, for half a century? It&#x27;s just borderline magical. And NASA of that era did everything just perfectly, nailing all the gravity assists (obviously using computational&#x2F;telemetry tech of the time), and more.And that applies to everything from that era. We hadn&#x27;t even put a man in orbit in 1962. 7 years later, we would be walking on the Moon!!! The degree of competence and capability of that era of NASA is something that I think is probably unmatched in the entire history of our species. reply schiffern 48 minutes agorootparentprev>It funny, usually people on HN [insert tribal \"sports team\" logic], and then all of sudden [actual technology discussion]I sure hope this doesn&#x27;t come to be considered &#x27;usual&#x27; on HN.If so, it just becomes a race to the bottom. reply thiago_fm 1 hour agorootparentprevIt definitely doesn&#x27;t, maybe there are some jerks that think badly of NASA, but I doubt they make the majority of us. They do a lot of engineering and science, but have been underfunded for so many years, with the government siding with private companies.For many, like me. It would be a dream to work at NASA, whatever the salary or bureaucracies it might involve.It was my childhood dream, but given I wasn&#x27;t American, that would never happen. reply hef19898 1 hour agorootparentDepending on where you live, ESA would be an alternative. The quite constantly look for people at their Oberpfaffenhofen site near Munich, if memory serves well they do some Galileo related work there. replyzakki 1 hour agoprevWhat will be more ... (I don&#x27;t know the word in English) is, once Voyager 2 completed the update it sends the same update to Voyager 1 (I read online it has the same computer system). reply asicsp 2 hours agoprevAnother discussion on the same story: https:&#x2F;&#x2F;arstechnica.com&#x2F;space&#x2F;2023&#x2F;10&#x2F;nasa-wants-the-voyager...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37993969 reply pyeri 35 minutes agoprevThat&#x27;s cool. My Redmi phone makers won&#x27;t even send it a few miles across this same planet! reply bhaak 3 hours agoprevHow much is that in metric units? reply OnlyMortal 2 hours agoparent1931256466260489.5 centimetres or, if you prefer, 3167950339119.439 giraffes. reply bhaak 2 hours agorootparentI doubt that giraffes are metric. But maybe they are some obscure SI unit?Fun fact. 1 billion km is almost 1.1 light hours. 1 billion miles is almost 1.5 light hours with less error margin. So you can easily calculate that Voyager 2 is about 18 light hours from Earth. reply darkwater 1 hour agorootparentSo hwo it \"just\" took 18 hours for the update to complete, according to the article? Shouldn&#x27;t be at very least 36 hours, given that you need feedback from Voyager? reply bhaak 48 minutes agorootparentIt took 18 hours to transfer the data to the probe.According to the article the update hasn&#x27;t been activated yet but they are still checking if everything is okay.> NASA scientists are carrying out a readout of the AACS memory to ensure that it is in the right place for the update. If there aren’t any issues, it will trigger the Voyager 2 update on October 28. reply karmakurtisaani 2 hours agorootparentprevYeah, but how many football fields for us common people?! reply giantrobot 2 hours agorootparentMetric or freedom football? reply BoxOfRain 46 minutes agorootparentRugby football, which went metric some decades ago. reply karmakurtisaani 2 hours agorootparentprevYes. reply hef19898 1 hour agorootparentSoccer, football? And how much is this in Empire State buildings, depending on the average soze of a giraffe?Either way so, that SW update of Voyager is some seriously impressive stuff! reply MaxikCZ 1 hour agorootparentprevHow many minicoopers filled with pingpong balls, if all pingpong balls were put in line? reply PostOnce 2 hours agoparentprevIt&#x27;s in space, so we can say 129 Astronomical Units.Easier to read than 19300000000km reply midasuni 2 hours agoprevSee also https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37993969 reply kristopolous 2 hours agoprevit really illustrates just how incredibly empty space is that these probes have survived operational and unmolested for this long. reply vasco 3 hours agoprevTo a spacecraft and to whoever else was listening. reply matrix12 1 hour agoprevKnowledgeWorks update most likely. reply autoexec 1 hour agoprevI really have to hand it to NASA. Voyager 2 was launched in 1977 and it&#x27;s still getting updates but we&#x27;re supposed to be okay with the cell phones that launched 5 years ago no longer being updated. reply coldtea 1 hour agoparentLong-term updated devices might be OK for your wallet and the environment, but they&#x27;re not good at making profits. They also slow down \"innovation\", and what would we be without 100s of useless (\"necessary\") functions in our modern phones? We&#x27;d have to (gasp) talk to each other at restaurants or also use proper dedicated devices like a camera and would miss some selfies! reply jen729w 1 hour agorootparentOld mobile phones aren’t transmitting priceless scientific data.Long-term updates to old devices are a drain on the people updating them. You start a hardware company and let’s see how long you and your little team of really expensive engineers keep updating last year’s product. reply coldtea 1 hour agorootparent>Old mobile phones aren’t transmitting priceless scientific data.No, they just have (Apple 2022 iPhone revenues alone vs 2023 NASA budget) 10x the amount of money of NASA&#x27;s budget (or 3x, if we stick to net profit), and around 1000x more money are depended on them.>You start a hardware company and let’s see how long you and your little team of really expensive engineers keep updating last year’s product.As long as the law mandates updates and bugfixes for older products, which, in a civilized society that actually did care for waste and the environment would be decades. reply autoexec 1 hour agorootparentprev> Old mobile phones aren’t transmitting priceless scientific data.Aren&#x27;t they though? Clearly it&#x27;s not on the same scale, but a 5 year old phone is still perfectly capable of transmitting very valuable data and providing utility to the user. reply randomdata 1 hour agoparentprevIf you have Voyager 2&#x27;s budget, I&#x27;m sure someone would be quite happy to sell you a phone that receives updates for decades. reply autoexec 1 hour agorootparentIt&#x27;s not just an issue of money. Apple made a lot more money last year than NASA did. reply randomdata 1 hour agorootparentAnd Apple would have made a lot more money if you spent the equivalent of Voyager 2&#x27;s cost on your iPhone.It is just about money. Cheap out and buy a budget phone and you will also get budget support. reply saberdancer 34 minutes agorootparentI think it&#x27;s better to say - if your phone was 12 billion miles from Earth and used to send sensitive scientific data - it would get updates as well. reply randomdata 30 minutes agorootparentNot when you only paid on the order of $1,000 for it. For so little, nobody is going to bother to support your device for decades, no matter how near or far away it is from you or what you happen to be doing with it.The original Voyager budget was $865 million (~$5 billion today), and has paid out even more for maintenance and operation since. Spend that much money on an iPhone and not only will updates be available for decades, but someone from Apple will come and personally install the updates for you. reply autoexec 1 hour agorootparentprevYou&#x27;re right, I misspoke. I should have said it wasn&#x27;t about the costs. NASA can keep updating their hardware after all this time with far fewer resources than apple has, so it isn&#x27;t that it&#x27;s prohibitively expensive to keep supporting old devices, it&#x27;s just that ultimately \"It is just about money\" and cell phone companies would rather have people throw out their old devices and buy new ones. reply2rsf 2 hours agoprevAssembly software, Launched in 1977 with link speed of a few hundred bps reply tjrgergw 59 minutes agoprevAnyone else disappointed they didn&#x27;t mention the actual number of bytes in the update? reply imranhou 3 hours agoprevThis is simply dope! I know this comment doesn&#x27;t add value, but still, Pluto is \"only\" 4.5 billion miles away from sun at its farthest point and it takes 247 years to loop around the sun. reply speps 3 hours agoparentPluto is 3.7 billion miles away, not \"light years\". New Horizons probe wouldn&#x27;t have taken \"only\" 11 years to reach Pluto otherwise. reply imranhou 2 hours agorootparentYup, effect of late night posting. reply nso 3 hours agoparentprevPretty sure you got one of those measurements horribly wrong reply robertlagrant 2 hours agorootparentI&#x27;ll have you know that commenter was units lead on the Mars Climate Orbiter[0] mission![0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mars_Climate_Orbiter reply pxeger1 3 hours agoparentprevI think you mean 4.5 billion miles. reply tguvot 3 hours agoprevi wonder if NASA is the first \"company\" ever that implemented OTA updates ? (ok, not exactly air, mostly, space) reply skirge 2 hours agoprevTested on staging? reply thanatos519 1 hour agoparentSent to Voyager 2 first, since Voyager 1 is further out so its readings are more valuable.So... testing in production in a secondary market. reply atemerev 1 hour agorootparentThey have staging too (an on-Earth copy of the Voyager probe, with all relevant parts fully duplicated). reply atleastoptimal 3 hours agoprev [–] Windows 11 reply robertlagrant 2 hours agoparentSir, we&#x27;ve just had a response for Betelgeuse! They say...can they have the old Start Menu back? reply atemerev 1 hour agorootparentAh, so that’s what Betelgeuse dimming was about, a few years ago reply fevangelou 3 hours agoparentprev [–] The cumulative patch. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NASA has transmitted a software update to Voyager 2, located over 12 billion miles from Earth, hoping to avoid the same issues Voyager 1 faced last year.",
      "The update, which took 18 hours to conclude, is intended as an insurance policy to extend the probe's lifespan.",
      "NASA has plans to use Voyager 2 as a trial. If successful, the same patch will be applied to Voyager 1."
    ],
    "commentSummary": [
      "NASA has successfully transmitted a software update to the Voyager 2 spacecraft, situated 12 billion miles from Earth, showcasing the engineering prowess and teamwork involved in this 50-year-long mission.",
      "The specific nature of the update and its size are not disclosed, but it's noted that Voyager 2 operates on custom-built computers with limited memory, indicating significant technical challenges.",
      "The post underlines the impressive ongoing maintenance of the Voyager 2 spacecraft post-40 years and introduces a broader space-related discussion including NASA's capabilities and comparisons with other entities like SpaceX."
    ],
    "points": 169,
    "commentCount": 97,
    "retryCount": 0,
    "time": 1698125632
  }
]
