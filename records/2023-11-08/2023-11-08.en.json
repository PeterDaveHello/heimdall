[
  {
    "id": 38180477,
    "title": "Improving Banks' Operational Efficiency Through Technology: An Analysis of Current Challenges and Potential Improvements",
    "originLink": "https://www.bitsaboutmoney.com/archive/seeing-like-a-bank/",
    "originBody": "Seeing like a Bank Patrick McKenzie (patio11) • Nov 7th, 2023 The New York Times recently ran a piece on a purported sudden spate of banks closing customer accounts. Little of it is surprising if you have read previous issues of Bits about Money. The reported anecdotal user experiences have a common theme to them. Banks frequently present to their users as notably disorganized, discombobulated institutions. This is an alarming and surprising fact for the parts of society that are supposed to accurately keep track of all of the money. Why does this happen? Why does it happen across issues as diverse as bank-initiated account closures, credit card or Zelle fraud, debit card reissuance, and mortgage foreclosures? Why does it happen in such a similar fashion across many institutions, of all sizes, who exist in vicious competition with each other and who know their customers hate this? Banks are extremely good at tracking one kind of truth, ledgers. They are extremely bad at tracking certain other forms of truth, for structural reasons. In pathological cases, which are extremely uncommon relative to all banking activity but which nonetheless happen every day and which will impact some people extremely disproportionately, the bank will appear to lack object permanence. Every interaction of the user with it feels like being Bill Murray in Groundhog Day: the people you’re talking to remember literally nothing of what they’ve promised before, what you’ve told them, and the months or years of history that lead to this moment. How did we end up here? Recordkeeping systems Like every bureaucratic system, banks run on a formal system of recordkeeping which requires an unrecognized, illegible shadow system to actually function. The interactions between those systems, and what they are optimized for tracking and not optimized for, cause a lot of the pathologies that people see. The seminal text on this, focused on government bureaucracies, is Seeing like a State. Because banks are filled with extremely creative people, we call the primary system banking is conducted on a “core.” The largest banks in the world have complicated bespoke subsystems for this, but most banks are not in the software development business, and instead license a system from a so-called core processor like Jack Henry or Fiserv. One could fill a book with architecture diagrams for a mid-sized financial institution. The key thing that non-specialists need to understand is a) the “core” does a lot of what you think of banking as, b) the core interfaces with many other systems which make up a bank, c) in particular, the core interfaces with the ledgers of the bank, and d) all of these systems together cannot represent reality nearly as well as you’d hope. They typically grow over the years by accretion, caused by the normal processes of software development, regulatory changes, and competitive pressures. No system will ever be able to answer all interesting questions about a user; that is formally undecidable in computer science. Banks are extremely, painfully aware that the ordinary operation of the business of the bank will occasionally drop things on the floor. They have long-since automated the fat head of customer issues, and the long tail is kicked over to operational and customer support teams. Every time responsibility moves between subsystems, be they different organizations, different computer systems, or different groups within the bank, some percentage of cases will simply break. The boundaries of systems are responsible for a huge percentage of all operational issues at banks. (They’re also where most security vulnerabilities live: systems A and B usually agree on reality, but a bad actor can sometimes intentionally get them to disagree, in ways which cause the bad actor to gain value before A and B reconcile their view of reality.) A major technological advance over the course of the last few decades has been ticketing systems, which strikes many technologists as being crazy, because they’re almost the simplest software that you can describe as software. All a ticketing system does is enforce an invariant: if there is a problem with a case number assigned to it, and it goes between Group A and Group B, Group A needs to know it no longer is responsible and Group B needs to know it is now responsible. Then you can do can’t-believe-they-pay-us-for-this computing and observe things like “Group B is now working on 10,342 cases”, “There are 76 cases which Group B has not acted on within the last month”, and “Ginger seems to be anomalously unproductive at closing out cases relative to her nearest coworkers.” So why didn’t ticketing systems solve this problem? Part of it is that the problem is self-referential: the ticketing system is not the core. The ticketing system is not the subsystem that is directly responsible for anything of interest to you. The ticketing system is an entirely new system, which requires integration with other subsystems and which will frequently need to do handovers to them. This interface is frightening, unexplored territory where new classes of issues that you’ve never seen before can spring up. Bank systems are an interesting combination of designed and accidental. They accrete like sedimentary layers. A particular force which affects banks more than most institutions is that the banking industry has undergone decades of consolidation. When banks merge, one bank doesn’t simply eat the other and digest its balance sheet and people. They end up running their systems in parallel for years while working out an integration plan. That plan will, almost inevitably, cause one of the systems to mostly “win” and the other system to mostly “lose”, but for business reasons, something of the loser will be retained indefinitely. It now has to be grafted onto the winner, despite frequently being itself decades out of date, having its own collection of grafted acquirees partially attached to it, and needing expert input from people who are no longer with the firm. Users can watch this play out in real time. For example, I banked at First Republic and also bank at Chase, which now owns First Republic. In something which sounds unimpressive and would blow the mind of bank CTOs from as recently as ten years ago, both sides of the bank understand that the same person has an account on the other side. (You wouldn't think testing Social Security Numbers for equality requires any high-tech wizardry, and you'd be right. The thing which was actually hard was building a process to allow complex ad hoc bidirectional synching of systems that were not built in tandem with each other.) Chase paid tens of billions of dollars over the years to get to the point where one engineer could bang this in-app banner out in 30 minutes. But because that integration is ongoing and will take years to resolve, neither part of the bank knows consequential things the other part knows about me, even where it strikes most people as obvious that they should. Chase eagerly communicates timelines for transitioning the home loan that First Republic very definitely never wrote. It is utterly clueless about the Line of Credit that they factually did extend. And it will require a lot of midnight oil from hundreds or thousands of people for most of another year before I can walk into a Chase branch and ask what the balance is on an account serviced by First Republic's core. Human accountability and its malcontents So let’s talk about how banks spackle over the infelicities in their systems. First, the bank builds many subsystems which interface with its core processing systems and ledgers. These systems are built so internal bank staff can see what a customer has done in their accounts and, perhaps, act upon those accounts on their behalf. For those keeping score: yep, this interface boundary is another place which can cause the bank to fail to agree with reality. Relatively simple programming issues can cause the staff-exposed view of an account to fail to agree with reality known to the bank. For example, they not infrequently fail to show some staff transactions which are “pending.” In many cases, “pending” has consequences which are extremely similar to being finalized from the perspective of the user, but a particular system might simply not show them. You’d think that is a confusing choice to make and often underrate the possibility that no one ever made this choice, not really. Sure, it exists (inarguably in this case) in code, and that code might be described in a requirements analysis document that someone handwaved together 18 years ago, but nobody ever said “Nah, exclude pending transactions”. This was a simple oversight, projected into the future indefinitely, to the enduring annoyance of old hands among staff and the continued surprise of non-specialist users. You might assume that senior members of operational staff have the ability to write a memo to engineering or procurement to tell them that the software that makes up the bank is broken. That is a thing which exists at surprisingly few firms. (A repeated experience of my time at Stripe was watching engineers embed with Ops teams for a day, then run back to their laptops while saying “I’m so sorry! I can’t believe we did that to you! I will drop everything I am doing and fix it immediately!” In many cases, those bugs had existed for months or years. I watched senior engineering leadership ask senior Ops leadership why they had never been asked to fix them. Ops replied that their long experience in the financial industry had taught them that Ops never gets to use software which isn’t broken and that complaining about this is like complaining about gravity.) Banks aggressively partition staff based on job duties and levels within those duties. The most relevant silo for retail consumers is actually a series of parallel silos which staff front-line phone support for the bank. Often, each line of business gets its own silo, which accounts for much of the Your Princess Is In Another Castle that happens when you call a bank with a seemingly straightforward question and then get passed between various departments. Most products offered to retail consumers and small businesses are relatively low margin, in absolute dollar terms. To be able to offer these, banks use various methods to cram down their support costs. Offshoring is often the face of these initiatives, but stratification by skill levels and powers granted is probably more important to understand. A fairly typical setup for a financial institution will have the retail bank support teams stratified into Tier One, Tier Two, and Tier Three. Each has management located with them, who may or may not be shared across tiers. You truly haven’t lived until you’ve tried paying for your college education by being a Tier One customer service representative, like your humble correspondent did. (Not at a bank, thank goodness; I might have stayed in a field with that many interesting problems presented.) The reason Tier One exists is that the median problem, so-to-speak, from a retail user is not actually a problem. That retail user is extremely unsophisticated about the bank account, finance in general, and frequently many other things in life. Tier One exists to handhold this individual in getting something very straightforward done, or to pass the call off to Tier Two. Many people in our social class want to be extremely compassionate in explaining challenges that some people endure. Sometimes this compassion extends to believing that people with substantial challenges don’t exist or don’t exist in any large numbers. It is extremely important to understand that those challenges exist and that they will dominate your frequent fliers for support. Some people have only emerging competence in English but will want services from a bank which does business in English. Some people, frequently with large account balances and long successful histories with you, are experiencing age-related decline in their faculties and need to be protected, frequently without that being a capital-F Fact within the system yet. Some people are crooks. Some people have a very interesting relationship with the truth, and say many things to banks which probably felt true to them in the moment. (Is that fraud? Eh, it’s complicated.) But to zoom into one particular way people can differ from each other: Some people are not as intelligent as you are. That is uncouth to say. In the United States, almost every large organization will institutionally tamp down on any explicit discussion of it. They all must structure their affairs to deal with the reality of it, though. Think of the person from your grade school classes who had the most difficulty at everything. The U.S. expects banks to service people much, much less intelligent than them. Some customers do not understand why a $45 charge and a $32 charge would overdraw an account with $70 in it. The bank will not be more effective at educating them on this than the public school system was given a budget of $100,000 and 12 years to try. This customer calls the bank much more frequently than you do. You can understand why, right? From their perspective, they were just going about their life, doing nothing wrong, and then for some bullshit reason the bank charged them $35. The reason you have to “jump through hoops” to “simply talk to someone” (a professional, with meaningful decisionmaking authority) is because the system is set up to a) try to dissuade that guy from speaking to someone whose time is expensive and b) believes, on the basis of voluminous evidence, that you are likely that guy until proven otherwise. And so every Tier One rep will talk to dozens of folks a day. Many of those calls are… fairly aggravating, from the perspective of the agent. Tier One has limited ability to do anything useful; this depends on the firm and the silo within the firm, but they are largely read-only interfaces to money. They have a few pre-programmed buttons to push which get 90%+ of people they talk to to not call again. They execute scripts and flowcharts, written by people better paid than them, which gate your access to Tier Two. In the best operated systems in the world, Tier One gets about one tweet worth of context to pass over to Tier Two when doing a handoff to them. (“Cust didn’t rec new debit card to Japan plz next day air + waive fee.”) Most financial institutions are not the best operated systems in the world. The bank “forgets” about your issue as soon as you’re off the line with Tier One, and needs to be told it entirely de novo when you speak to Tier Two. Tier Two typically spent a few years in Tier One and has begun to specialize in a subfiefdom of banking. They have emerging competence into the nitty gritty of operations at their institution, at least with regards to that subfiefdom. They’re paid more, though not by much. They’re typically given more ability to do what my shop called “accommodations”, which means self-authorizing a resolution for a customer which costs money. Tier Two might be able to, for example, credit an account a small amount of money for an arbitrary reason and have the bank charge it off as an operations loss. Your humble correspondent had a soft limit of approximately $200, below which no number was worth trifling my management chain or a specialist about. An interesting observation about the physics of money is that Tier Two could conceivably cost the bank more by authorizing accommodations than they earn in salary. A line manager apprised of this probably will not investigate it for more than five minutes before deciding that the bank is satisfied. Then you have Tier Three, which at some firms sits in Customer Service and at some firms sits in Operations. There exist some ambiguity and spectral ranges here, but at some point the job changes in character from “low-wage peon reciting a script” to “professional who has a career doing this and is no longer managed on a tickets-closed-per-hour basis.” Tier Three, let’s call them for simplicity, engages in constant firefighting, because at the volume of transactions (and other sources of cases) in all-but-the-tiniest financial firms, something is always on fire. Sometimes you’re covering for hiccups in the technical systems of your institution or counterparties. Sometimes someone has found themselves in an odd edge case or been passed around for ages between departments. Sometimes you’ve received an escalation, about which more later. A user of the banking system will often have to redundantly explain themselves when they hit Tier Three, for the same reason as they did when they hit Tier Two. However, because they’re no longer operating in time-starved tickets-per-hour crunch mode, Tier Three has richer access to systems at the bank and more ability to forensically reconstruct procedural history, including history that is not ledgered. They will frequently do this both to do their jobs and to do the legwork for other professionals at the bank who might have decisionmaking authority in some cases but do not have the access or acumen to pull together a view of a case from disparate systems. The gaps in experience between getting passed around tiers are replicated for being passed around departments. Say, for example, that the bank owes you a check and you do not receive it in the mail. The vast majority of checks sent through the mail arrive without issue, but the bank knows that it will have to reissue some of them. There is a process for doing this. Unfortunately, because this is a relatively infrequent issue, Tier 2 does not have a Reissue Check button available to them. Instead, their interface to this process is likely “Raise a ticket with Ops and tell the customer someone will call them.” There is no system available to Tier 2 which can verify that that call was actually made. The agent has no basis in their training or experience to know whether the bank routinely makes that call. It is quite possible that success rates on that call being placed are quite low, even if you ask for it three times consecutively, and that the bank is entirely institutionally unaware of this. And so the customer will feel frustrated and they have been lied to, Tier 2 certainly doesn’t feel like they’ve lied to anyone (they read the script, it’s a Tuesday), Ops feels like the world is on fire because the world is always on fire, and senior bank management cannot detect this problem because no metric available to them is capable of disaggregating it from the complex monster that is the financial system. Two embedded surprises about bank staffing Many traditionally-minded users of banks assume that someone at their branch can likely help them with issues. Due to the deskilling of the bank branch, the people at a bank branch, including the branch manager in many firms, can only offer solutions to relatively straightforward problems. For the other ones, they also have to call into a support phone tree. Sometimes the bank will have ability to e.g. share context between their screen and the Tier 2 rep; sometimes they’re literally incapable of proving to the bank that they work there. (You might think I’m joking. To beat a drum: the level of technical sophistication across the spectrum of U.S. financial institutions varies wildly.) The other surprise is that substantially every financial institution has a parallel way to reach decisionmakers in every area it operates in, which skips most or all of the tiering system and the technical and organizational scar tissue that it carries. This goes by different names in different places but “escalations” is a fairly common one. Much like the United States has decided, in its infinite wisdom, that caseworkers for immigration and passport services should be staffed in every Congressman’s office and not at the agency that actually handles immigration or passport issuance, there very likely exist people at the bank whose job is working the bank more than it is working for the bank. A number of functions which are not ordinarily customer-facing are given the contact information for that group, with the instruction “In case of emergency, skip Tier Everything and talk immediately to the highly-placed troubleshooting team.” If you are a reporter and call a bank for comment about a widow on the cusp of being improperly foreclosed upon, you will (fairly reliably) find your words forwarded to the troubleshooting team within a few minutes. If you’re a regulator and intervene on behalf of an individual, same result. You can absolutely achieve this as a civilian, too; a paper letter to the VP of Retail Banking, Office of the President, or Investor Relations will often cause the bank to swing into motion in the same way. (I wrote a few hundred letters like that as a hobby back in the day.) These folks are professionals who are capable of keeping paper notes and having day-to-day recollection of things they have done in complex cases. They are managed and incentivized in a way which allows them to have agency. The formal customer support organization is very, very bad at this, at every tier. It is very difficult to do in a model where you’re constantly bouncing cases around individual reps and between departments. Is this because banks are malicious? Are they willing to grind retail users to bonemeal in the pursuit of another cent of earnings per share? The truth is a bit more mundane: supporting people with can-do-anything-you-throw-at-them professionals is ridiculously expensive and getting moreso over time. The per-case cost for the troubleshooting team can be more than 100X that of the tiering system. Retail customers have relationships where they pay highly-educated high-agency jacks-of-all-trades to provide professional services in arbitrarily complex situations. They hate the experience of those relationships. They hate their medical bills. They are incredulous that lawyers bill hundreds of dollars per hour (in six minute increments). You can get something approaching this level of service out of a bank, too, and the private bank generating $150,000+ in annual revenue per client would be happy to make your acquaintance. But if you want phone calls to the bank to be both answered at 2 AM and absolutely free, you want the tiering system. Society wants the tiering system. It is why a high school student with a paper route can open a checking account, get a debit card, and start buying things on Amazon. It is why bank branches can be operated in working class neighborhoods. As a sophisticated user of the banking system, a useful skill to have is understanding whether the ultimate solution to an issue facing you is probably available to Tier Two or probably only available to a professional earning six figures a year. You can then route your queries to the bank to get in front of the appropriate person with the minimal amount of effort expended on making this happen. You might think bank would hate this, and aggressively direct people who discover side channels to Use The 1-800 Number That Is What It Is For. For better or worse, the side channels are not an accident. They are extremely intentionally designed. Accessing them often requires performance of being a professional-managerial class member or otherwise knowing some financial industry shibboleths. This is not accidental; that greatly cuts down on “misuse” of the side channels by that guy. It is also much more institutionally palatable to the bank and other stakeholders like e.g. regulators. No financial institution can say “We offer differential service levels to our community based on their education level, perceived social class, and perceived capability to bring power to bear on their behalf.” Every financial institution factually does that. The successful way to phrase it is “We offer contextually appropriate services to the entire range of customers, who come from all walks of life, and also we respond with alacrity to any issues impacting our important stakeholders via a variety of programs.” Society has goals which conflict with banks being good at banking I hate sounding like a conspiracy theorist about banks, which for whatever reason seem to attract a disproportionate amount of attention from people who believe the Illuminati and lizardmen are conspiring to corrupt the free peoples of the world. And so ordinarily I do not want to say crazy things like “Sometimes banks suck because we want them to suck.” Sometimes banks suck because we want them to suck. In the specific case of “Why did the bank close my account, seemingly for no reason? Why will no one tell me anything about this? Why will no one take responsibility?”, the answer is frequently that the bank is following the law. As we’ve discussed previously, banks will frequently make the “independent” “commercial decision” to “exit the relationship” with a particular customer after that customer has had multiple Suspicious Activity Reports filed. SARs can (and sometimes must!) be filed for innocuous reasons and do not necessarily imply any sort of wrongdoing. SARs are secret, by regulation. See 12 CFR § 21.11(k)(1) from the Office of Comptroller of the Currency: No national bank, and no director, officer, employee, or agent of a national bank, shall disclose a SAR or any information that would reveal the existence of a SAR. Any national bank, and any director, officer, employee, or agent of any national bank that is subpoenaed or otherwise requested to disclose a SAR, or any information that would reveal the existence of a SAR, shall decline to produce the SAR or such information, citing this section and 31 U.S.C. 5318(g)(2)(A)(i)... If the United States brings its subpoena power to bear against a bank teller and asks them about a SAR, they’re supposed to say nothing. That is the law! (Regulation, well, if one wants to be technical.) It is designed to be enforced against the interests of the United States of America! Customers have far less access than the U.S. awards to the U.S.! So does the teller, incidentally: to avoid constantly violating this, Compliance at most functioning institutions has long-since decided that SARs will live in their own walled garden of a subsystem, seen only by the people responsible for drafting them and sending them to FinCEN. That subsystems’ interactions with every other system are, of course, a site for extremely painful hilarity to happen. If, for example, a SAR is misfiled because that subsystem doesn’t share the same view of account ownership as another part of the overall system, investigating that problem might require telling the customer that they were investigated, which you cannot do. And because this is insufficiently Kafkaesque, at some financial institutions, you can get a SAR filed for knowing what a SAR is, because “advanced knowledge of anti-moneylaundering procedure” is a characteristic only of financial professionals and terrorists. Compliance training can tell e.g. personal bankers to please look at the Know Your Customer questionnaire and see if “Professional background: I work in finance” is bubbled in and then draw the appropriate inference. You might think I am joking. I am utterly not joking. Most of the times infelicities in the world have a logical explanation to them, a structural cause where each individual link in the chain sounded good at the time and the result just happens to be suboptimal. And sometimes the world is absolutely batshit insane. So what can be done about this? Like many structural problems, banks lacking object permanence didn’t happen overnight and can’t be fixed overnight. A lot of the fix is technical. In the not-too-distant past, there were zero—zero—financial institutions which were competent at software. There are now a handful of them, after the expenditure of many tens of billions of dollars. That was the price of getting without-loss-of-generality Chase to the point where in-house engineers can cause the retail web app to react to me having an account at First Republic less than a year after their purchase of that bank. Although it certainly doesn’t feel like it to people who hit edge cases, the tiered support model is a technology which took us decades to popularize and which made the world much better. It brought down the cost of financial services and supported product innovation which would have been impossible under the mid-century bank staffing model. We could not have credit cards or discount brokerages without the tiered support model. The biography of Charles Schwab makes this point persuasively at considerable length: competent telephone operations were instrumental to bringing equity ownership to the middle class. You should prefer a world with credit cards and discount brokerages to one which doesn’t have them, even as you listen to hold music occasionally. It will similarly take decades to roll out the best-functioning refinements on customer service at scale to the entirety of the financial system. Partly this will happen through continued consolidation; the more banks Chase ends up owning, the higher the average operational competence in the U.S. financial system is. (And that’s… saying something.) Partly this will happen as banks increasingly tap external providers for technology where the right things are recorded automatically and actioned appropriately. Partly, I continue to expect Operations to come further into its own as a high-status discipline, and to rewrite the internal structure of banks just as engineering has done over the last two decades. Partly this will happen as banks increasingly partner with firms that impose a tech-inflected view of the customer experience. Google is, for example, a legendarily hostile organization to attempt to get customer support from. Google is also beloved by users because of overwhelming competence in shipping products that work almost all of the time. If you think that talking to a compassionate human is a core part of the banking experience, there are many banks in Iowa who will sell that service to you. If you simply want to access your money on your phone and have that almost always work, Cash App will happily operate as a front end over Lincoln Savings Bank to make that happen. (There are many layers to that onion. No particular equilibrium is necessarily the “right” one!) And partly, we as a society have to make some tradeoffs. We want something from 12 CFR § 21.11(k)(1) . It was not written by accident or because the drafters were stupid. Every future with 12 CFR § 21.11(k)(1) in it will include many Americans whose bank accounts are closed for no reason that can be disclosed to them. Many of them will have done nothing wrong. Plausibly, we should decide to stop doing the thing that no one wants us to do. And, as a particular thing which could help unlock that: if one cares a lot about the experience of people at the socioeconomic margins, one should perhaps spend less time fulminating about greedy capitalists and spend more time reading Requests For Public Comment by relatively obscure parts of the administrative state. A review of Number Go Up, on crypto shenanigans → Want more essays in your inbox? I write about the intersection of tech and finance, approximately biweekly. It's free. Get a biweekly email Great! Check your inbox (or spam folder) for an email containing a magic link. Sorry, something went wrong. Please try again.",
    "commentLink": "https://news.ycombinator.com/item?id=38180477",
    "commentBody": "Seeing like a bankHacker NewspastloginSeeing like a bank (bitsaboutmoney.com) 519 points by arkadiyt 15 hours ago| hidepastfavorite373 comments RationalDino 15 hours agoPatio11 is the best resource that I&#x27;m aware of to understand how our institutional world works. And its biases. Over and over again it is built in a way that incentivizes some behaviors, and doesn&#x27;t incentivize others. One behavior that is always incentivized is that the professional and managerial classes should always have prioritized access.This article walks through it in how banks work internally. Much more painful is https:&#x2F;&#x2F;www.bitsaboutmoney.com&#x2F;archive&#x2F;the-waste-stream-of-c..., which shows how rules that supposedly protect poor people from abuse, in practice only help those with access to the skills of the professional and managerial classes.I wish there was a way to summarize his point of view and explain it to people. Part of the problem is that every system where it happens is very complicated. And the complications are exactly why you need professional and managerial class skills to get priority access. reply Terretta 7 hours agoparent> patio11 is the best resource that I&#x27;m aware of to understand how our institutional world works.As a former CTO for the Americas region of one of the world&#x27;s largest banks&#x27;, which owns consumer banks and divested one recently, I couldn&#x27;t comment here on the prior article that he&#x27;s writing about, but I have linked this particular patio11 discussion to a few people.Take from that what you will.&#x2F;&#x2F; Caveat: @patio11 has published some takes this year that are less forwardable (mostly asserting reasons or rationales for things that ring true at several layers down in a bank, but are not actually what&#x27;s at play). I suspect it&#x27;s partly from the level or siloing of who he&#x27;s interacting with, and partly from the nature of some types of banks he may have spent more time with, rather than other types of banks, such as G-SIFIs:https:&#x2F;&#x2F;www.fsb.org&#x2F;work-of-the-fsb&#x2F;market-and-institutional...That said, industry executives interested in improving things would do well to read all of it, because \"perception is reality\", as seen by @patio11 through a different lens than usual.Even if differently attributed, you can likely derive what you&#x27;d need to work on to alter that perception, leaving your bank the better for it. reply orangesite 14 hours agoparentprevIt&#x27;s absolutely great how @patio11 managed to recreate exactly the same system within stripe despite being fully aware of it.(I save up my karma points precisely so I can burn them on comments like this.) reply e63f67dd-065b 14 hours agorootparentMy impression of what he wrote is that it&#x27;s an explanation of the status quo, not a denunciation of it. In his conclusion:> Although it certainly doesn’t feel like it to people who hit edge cases, the tiered support model is a technology which took us decades to popularize and which made the world much better. It brought down the cost of financial services and supported product innovation which would have been impossible under the mid-century bank staffing model. We could not have credit cards or discount brokerages without the tiered support model. The biography of Charles Schwab makes this point persuasively at considerable length: competent telephone operations were instrumental to bringing equity ownership to the middle class. You should prefer a world with credit cards and discount brokerages to one which doesn’t have them, even as you listen to hold music occasionallyTiered support is here to stay because tiered support is cheap and resistant to the \"unintelligent customer DoS\" (my words, not his). As he points out, you can have professional troubleshooters with the capability, authority, and expertise to troubleshoot the problem, but their labour costs in the hundreds of dollars an hour.I personally think there is a reasonable model of the world where customers explicitly pay a hundred dollar fee to have a highest-tier escalation to the office of the CEO&#x2F;equivalent troubleshooting team and have them take a look at your case, but this is a model that has not yet been developed or in wide use anywhere. reply krisoft 47 minutes agorootparent> there is a reasonable model of the world where customers explicitly pay a hundred dollar fee to have a highest-tier escalation to the office of the CEO&#x2F;equivalent troubleshooting teamIt is tricky. On a first order I agree with you, but then i think about second order consequences: What if the escalation route becomes profitable? Will that incentivize the company to keep the pain points, or perhaps even engineer more of them?Also, would it be clear what does the money pays for? Imagine a situation where the computer says no (that is the system makes a decision adverse to the customer’s interest, such as closing an account, not approving a loan, security freezing assets etc), and the costumer pays the fee to get it escalated. The CEO office person reads the case, applies their troubleshooting skills, and they independent of the computer come up with the same answer. Now from the point of view of the costumer it feels they paid hundreds of dollar for nothing. From the point of view of the company they gave the customer what they promised: spent valuable resources on escalating the customer’s complaint. If they give the fee back to the customer they are loosing money, if they don’t they further antagonise a bad situation. Which can have reputational effects, and or wasting even more resources.And this might sound like an edge case, but if the system is well operating these kind of cases will be dominating. Simply because if the CEO’s office overrides the normal processes too often then either they are profiting from the escalation route (see first point) or the normal system is faulty.How would you dodge these two bullets? reply zarkenfrood 30 minutes agorootparentprev>I personally think there is a reasonable model of the world where customers explicitly pay a hundred dollar fee to have a highest-tier escalation to the office of the CEO&#x2F;equivalent troubleshooting team and have them take a look at your case, but this is a model that has not yet been developed or in wide use anywhere.This already exists in a sense. High net worth clients&#x2F;well established business clients with long term relationships do get priority remediation and troubleshooting. The cost is just much higher than $100. reply boilerupnc 13 hours agorootparentprevI’ve been having a fun ride reading “QualityLand” [0] .In that world - those who have QualityPoints can exert far more escalation force on all parts of their life (change the traffic signal now for 10 units) than lower level folks. Your comment reminds me of a world where paying fees gets you faster and better access. Sadly - Sounds familiar.[0]https:&#x2F;&#x2F;www.bookbrowse.com&#x2F;reviews&#x2F;index.cfm&#x2F;book_number&#x2F;406... reply Sebguer 13 hours agorootparentThis sounds like effectively the same premise as Doctorow&#x27;s Down and Out in the Magic Kingdom. reply andrewflnr 4 hours agorootparentprevAre you confusing Patrick Collison, who cofounded Stripe, with Patrick McKenzie, who joined years later to work on documentation? reply RationalDino 14 hours agorootparentprevI&#x27;m not sure which part you are referring to by \"exactly the same system\", or to what extent patio11 is personally responsible for it.However listen to his explanations of the incentives, benefits, and downsides. Then remember that he was working within a company that had the exact same incentives (eg same regulatory regimes), who was going to be hiring people out of the same financial system. And remember that there are parts of this that he think really make the world better.Therefore the expected result really should be, \"Somewhat better iteration on the basic thing that everyone else does.\" And so it is no surprise that it would include enough of what you don&#x27;t like that you&#x27;d see it as \"exactly the same system\". reply throwawaaarrgh 6 hours agorootparentprevHuman organizations are, strangely enough, natural systems, which are notoriously hard to control without making them worse. It&#x27;s one thing to know how a beaver dam works; it&#x27;s another to muck about with the river hoping to come up with a better dam. reply throwawayyhbd 1 hour agorootparentSeriously someone should create Kubernetes - but for company-building. reply libraryatnight 3 hours agorootparentprevThis was my thought. This write-up is for understanding a system not to fix it, but to abuse it and profit from it. It&#x27;s sort of black hat in a way. reply orliesaurus 14 hours agorootparentprevwhat he do? reply lmm 2 hours agoparentprevI&#x27;ve found these blog posts of his to be like Moldbug&#x27;s - compelling in a way, consisting mostly of true statements, but also trying to aggressively push a very particular worldview on you. I would advise mixing him with other sources and taking care to be sceptical. reply user_named 1 hour agorootparentIt&#x27;s very verbose and self assured. You might enjoy it the first few times but I don&#x27;t anymore. reply aeturnum 4 hours agoparentprevI also love Patio11&#x27;s writing - but the formal thinking in this space is generally within the bountiful sub-disciplines that exist between and within Anthropology and Sociology. James C. Scott is, among other things, an Anthropologist[1].Social scientists of various stripes write about these kinds of things quite often. I don&#x27;t know much about the banking sector, but there are lots of authors writing accessible, detailed books that look into the intersection of politics, technology, society, identity, and other factors.I think part of what makes Patio11&#x27;s writing so attractive to the HN crowd is that he writes with technical rigor in a way few social scientists can manage. A lot of social science is, in my opinion, nibbling around the edges of a lot of the \"stuff\" in digital worlds - but there is a lot to get through and it&#x27;s not a huge field! So reading a lot of the source texts can be kind of frustrating: good stuff, but if they&#x27;re describing a field you work in there will probably be parts it seems like they got wrong. Patrick, on the other hand, does get the details right - and the general sociology.[1] He&#x27;s also been a CIA asset! A man of contradictions (or patterns - there are a surprisingly large number of good Anthropologists who are arguably bad humans). reply archon1410 13 hours agoparentprevTangential: the lead picture in the article linked in this comment immediately came across as AI generated, whereas the one in OP&#x27;s article did not: I had to go back and look at it again to realise that it too is AI generated. It is quite complex, similar to the human drawn abstract art one might find in an Atlantic or Wired or New Yorker article, the garbled text nearly the only thing giving it away. The article in the comment is from August 2023, so the difference in quality represents only a few months of progress (DALL-E 3?).Or maybe they&#x27;re from the same source, and the author just chose different aesthetics for the different articles. Quite nice, in any case. reply walr000s 12 hours agoparentprev> which shows how rules that supposedly protect poor people from abuse, in practice only help those with access to the skills of the professional and managerial classes.Maybe the world&#x27;s problems and solutions are inherently too complex for someone without those skills to have any hope of navigating. Maybe the only real solution is to use Patrick as an example for everyone and ask&#x2F;demand that professionals spend some amount of time advocating for people less fortunate&#x2F;educated&#x2F;knowledgeable than themselves? reply T1tt 2 hours agoparentprevagreed, he has a great piece on japans system reply bernardlunn 2 hours agoprevI used to work in a company selling core banking systems and yes they are a mess. I never imagined they would still be running in 2023. I could write a book full of horror stories. What amazes me is how so many banks do ok despite a massive failure to delight customers or innovate. Banks are literally “a license to print money”. reply eyphka 2 hours agoparentOut of curiosity, was it metavante? reply bernardlunn 2 hours agorootparentNo, Misys reply yboris 14 hours agoprevThe book Seeing Like a State referenced in the article is an amazing read:https:&#x2F;&#x2F;www.amazon.com&#x2F;Seeing-like-State-Certain-Condition&#x2F;d...Highly recommend, though glance at summary to confirm you&#x27;ll enjoy &#x2F; benefit:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Seeing_Like_a_State reply Symmetry 13 hours agoparentIt&#x27;s a great book but one sided in its analysis. I&#x27;d recommend pairing it with a book about a case where High Modernism worked great, like The Ghost Map or something.https:&#x2F;&#x2F;www.goodreads.com&#x2F;book&#x2F;show&#x2F;36086.The_Ghost_Map reply nomat 11 hours agoparentprevIt would be cool to map the relationship between a book getting linked on HN and its checkout rate at the local public library. That&#x27;s usually the first place I head when I see something I want to read on here. reply spicymapotofu 11 hours agorootparentYour local library has a much better offering of niche non-fiction than mine. Many of the texts I see here aren&#x27;t even available through my school&#x27;s cross country academic network. I did read this book that way, but I had to wait for it to come quite a distance.My city&#x27;s newest library is an art piece with less books than any other here, to be fair. reply _Algernon_ 9 hours agoparentprevCurrently reading this book and was wondering if the title was a reference. Gonna read the article now. reply somsak2 9 hours agoparentprevI&#x27;ve heard alot of great reviews of this book but personally found it pretty disappointing. reply RachelF 13 hours agoparentprevand if you want some rather funny videos on this topic: https:&#x2F;&#x2F;www.youtube.com&#x2F;results?search_query=reasontv+uninte... reply tomjakubowski 14 hours agoparentprevone of the great books on understanding corporate management too. reply orliesaurus 14 hours agoparentprevty bought it reply EZ-E 3 hours agoprev> Then you have Tier Three, which at some firms sits in Customer Service and at some firms sits in Operations. There exist some ambiguity and spectral ranges here, but at some point the job changes in character from “low-wage peon reciting a script” to “professional who has a career doing this and is no longer managed on a tickets-closed-per-hour basis.”As a developper I do this on the side of regular dev work for my job at company with a lot of technical debt and antiquated systems. This is my guilty pleasure to act on very weird edge cases or escalations. Sometimes it&#x27;s aggravating looking at what the customers go through as CS agents are obviously confused when the case they are handling goes out of the norm. reply csours 15 hours agoprevThere is something about this that I&#x27;d like to be able to communicate better [0]:Organizations are made of teams. That sounds super obvious, but it means that any change request is going to go to a team (or teams).From the outside, it looks like a corporation has effectively unlimited resources; on the inside, any particular team has very limited resources. The team may have just been downsized, lost a lead, been reorganized, etc.0: Better than I currently can, not better than Patrick.Funny quote:> That retail user is extremely unsophisticated about the bank account, finance in general, and frequently many other things in life. reply pixl97 14 hours agoparentLarge organizations are made of \"money saving entities\".I work with a lot of large corporations and we have constant problems with the software I support because the imperative is to continually drop operational costs. We&#x27;ll have a team we work with that is well trained, understand the software well, and keeps the software working at near 100% capacity.Then suddenly one day they are all gone and you get the offshoring team that knows nothing about the specialist software they are attempting to support, if they have the capability to actually turn a computer on is surprising. Software availability drops significantly having direct impact on deliveries, costing god knows how much in some of these companies. Support on the vendor side (my side) turns into a huge expensive mess because now you&#x27;re now writing instructions to the level of \"when you take a poopy, remember to flush and pull your pants back up\". reply csours 11 hours agorootparent> Large organizations are made of \"money saving entities\".Working for a cost center vs. a profit center will make a huge difference in your professional life. reply TeMPOraL 1 hour agorootparentNot everyone is wired for a sales&marketing job, and twisting themselves to fit in that role would also make a huge difference in life, in a more Faustian kind of way. reply kccqzy 13 hours agoparentprevI simply cannot upvote this enough.I also believe this is a hard problem to solve. The partitioning of an organization&#x27;s resources into teams is inherently messy and inefficient. One has to consider internal politics, egos of middle managers, or preferences of individuals when staffing teams within an organization. The end result is often far from what&#x27;s the best for the organization overall. reply aidenn0 15 hours agoprev> I watched senior engineering leadership ask senior Ops leadership why they had never been asked to fix them. Ops replied that their long experience in the financial industry had taught them that Ops never gets to use software which isn’t broken and that complaining about this is like complaining about gravity.I see this everywhere not just at banks. A common workflow is horribly broken with dozens of habitual workarounds and the developer could fix it in a day if they knew about the issue. I even see it between engineering teams when there are cross-team dependencies. It is really hard to train people to not put up with chronic pain in their workflows! reply pixl97 14 hours agoparentI work with banks on, um issues, without disclosing too much. Occasionally we find issues with their software workflows, and this isn&#x27;t related directly to monetary stuff. We&#x27;re not allowed to have the end result change in any way most of the time. \"But we&#x27;re getting a wrong answer\", or \"This is costing XX person hours per day\" isn&#x27;t up for consideration. Nothing must change.Ugh, and on the subject of banks computer operations. Every single department is in deep blame avoidance mode. It&#x27;s not \"find and identify problems\" mode, it&#x27;s \"It wasn&#x27;t me\" mode. We had our application performance drop to almost zero (like we dropped to disk operations per minute IOPM) I spent hours telling the customer, this is your infrastructure. So we got infrastructure teams on the call trying to figure out where it was. Not a single one of them were helpful \"Everything fine, it&#x27;s not us\" was the first thing out of their mouths and the second was \"We didn&#x27;t change anything\".It took 10 hours of sitting on a call over 2 days to get the NAS team to admit they turned on anti-virus on the NAS side and that the machines were in meltdown mode because the CPU was off the charts. The preceding people didn&#x27;t even look at the metrics before coming back with a \"it&#x27;s not my problem, everything is fine\" response. reply rkagerer 14 hours agorootparentEncountered a challenge like this once. Infrastructure team kept telling us it wasn&#x27;t anything on their end. I coordinated with the business unit VP to serve their entire QA environment from four VM&#x27;s on my laptop for a day, and performance went from slow as molasses, to purring like a kitten. A couple days later their infrastructure team finally identified storage latency issues on their multi-million dollar cluster and let me help them fix it. reply pixl97 14 hours agorootparentI swear IOPS&#x2F;request latency is one of the least understood things in these huge companies. \"But we have 40bazillion GB and 100GB LAN\", cool story bro, your disk queue latency is pegged at your depth limit and your fs response latency is over a second, everything is going to suck till you deal with that. reply RajT88 13 hours agorootparentI have had customers say this when not getting desired throughput cross-continent. \"But the pipes! They are fat!\" Yes but also your window needs to scale... 6 figure network engineers not knowing about window scaling, who do not know how to analyze a packet trace.I recently had someone suggest that they needed 1ms latency cross-continent. I explained patiently that the laws of physics have to change for them to hit that number.I am not even a network engineer! reply xelxebar 1 hour agorootparentprev> your disk queue latency is pegged at your depth limit and your fs response latency is over a secondYou said words. And I totally, 100% understand them. But, like, for the plebs that are totally not me, could you elaborate on what you&#x27;re talking about here? I^WThey would like to understand. reply NovemberWhiskey 12 hours agorootparentprevTruth. I literally have a signal on one of my monitoring dashboards which indicates \"database is currently undergoing online backup\", because it is the single most important performance signal I have. This doesn&#x27;t come to me as a signal from the database team; I have to poll the database for it myself.Noisy neighbor in inadequately-isolated, shared-tenancy models is just the worst. reply broast 12 hours agorootparentprevI find it very hard to tolerate teams that say an issue isn&#x27;t on them if they aren&#x27;t pointing to evidence that indicates where they think the issue is. If you think it&#x27;s not on you but it affects something within your responsibility, you&#x27;re still on the hook until you prove it. reply Scoundreller 11 hours agorootparentNothing more fun than troubleshooting a fax machine incompatibility.“It’s you, we’re receiving faxes from everyone else” (how would they know?)“Nooo, it’s you, everyone else is receiving our faxes” reply aidenn0 14 hours agorootparentprev> I work with banks on, um issues, without disclosing too much. Occasionally we find issues with their software workflows, and this isn&#x27;t related directly to monetary stuff. We&#x27;re not allowed to have the end result change in any way most of the time.I think this is a good constraint in general for banks to have, and its definitely harder to change a workflow under these constraints.> Every single department is in deep blame avoidance mode. It&#x27;s not \"find and identify problems\" mode, it&#x27;s \"It wasn&#x27;t me\" mode.This tends to happen in large organizations, and is incredibly toxic to productivity. The most extreme form is when you get fired (or otherwise censured) for fixing something because \"You were in charge of the thing that was causing all this trouble?!\" reply madeofpalk 14 hours agoparentprevA while back I worked at a digital media company. For developers, the process of setting up ads for new mini sites was a big pain and required lots of back and forth and approvals with Ads team. I asked other developers, and they say \"This is just the process that tyhe Ads team needs\".I go talk to the Ads people about this specifically and they say \"yeah it&#x27;s a pain, but this is the way the developers need it\".Turns out both parties had been wanting a better way which was pretty easy (3 different page&#x2F;ad placement templates), but neither had bothered to express this to each other. reply sib 8 hours agorootparentCongratulations - you just became a Sr Product Manager! reply quercusa 13 hours agoparentprevI moved to a role supporting a team that had been told that huge numbers of things were \"impossible\" by a brilliant guy given to migraines. If you asked him on a good day, he could do anything. But on a bad day he just wanted you out of his office. By his demonstrated competence, they took what he said as gospel.I spent an hour or two a week dragging \"impossible\" things out of them and fixing them. They were very happy and ascribed wizard-level powers to me. reply MichaelZuo 15 hours agoparentprevA lot of the times, the &#x27;correct&#x27; workflow isn&#x27;t even documented enough to recreate it.Often not even enough to identify that there ever was one in the first place. reply throwawaaarrgh 6 hours agoparentprevThis is why I believe it&#x27;s critical to occasionally rotate people into a different team for a few weeks to a month. Every time I&#x27;ve seen it happen, there are subtle things learned which can lead to big improvements. It&#x27;s not a magic bullet, but it&#x27;s much more likely to lead to discovering things nobody knew than if everybody stays in place forever. reply rco8786 12 hours agoparentprevOn a previous team every eng would shadow and Ops person for a day, once a year. We fixed so much stuff. reply Terr_ 12 hours agoparentprevIt sounds like the psychology of \"Learned Helplessness\" [0] among employees and teams.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Learned_helplessness reply supportengineer 11 hours agoparentprevDon&#x27;t get me started. I&#x27;ve seen many cases where one PHP page doing one occasional SQL query against one prod database, could drive massive efficiency improvements in the organization. In a minority of these cases, I was allowed to do such a thing. reply ctoth 15 hours agoprev> You should prefer a world with credit cards and discount brokerages to one which doesn’t have them, even as you listen to hold music occasionally.The problem with this is, we&#x27;ve known for 30 years that a system that calls you back is better than a system you wait on hold for. If they can&#x27;t even get something this basic right, then I guess it&#x27;s good that banks will eventually, someday be software competent, but I&#x27;ll be long-since dead. reply janus 14 hours agoparentIt depends on where you live. In my country I would never take a call from a bank at face value and would always expect they give me a phone number to call back, and that better be an institutional number. Phone fraud is rampant. reply bluGill 12 hours agorootparentWhich in turn depends on where you live: some places a call is not ended until both sides hang up. Fraudsters use that to call you, give you a number and then when you call back pretend to be answering the phone (complete with ring noises).If someone like a banks calls you, you need to call back from a different phone line, using a number that you look up before giving private information.Note that most of the time the above doesn&#x27;t matter, as banks rarely need to call you to get private information. \"did you buy X\" isn&#x27;t private - whoever is asking already knows you did: even if they are a scammer you have already lost - if you didn&#x27;t you need to hang up and call the bank to arrange getting a new account now that your old one is compromised. The only other time that matters is why you know who will call and why (if you just applied for a mortgage you expect the loan officer to call but you also know exactly who that is) reply someplaceguy 3 hours agorootparent> some places a call is not ended until both sides hang up. Fraudsters use that to call you, give you a number and then when you call back pretend to be answering the phone (complete with ring noises).WTF? That&#x27;s completely insane! Where is that?And please tell me that you can hang up the call if you reboot your phone, at the very least! reply landedgentry 15 hours agoparentprevI am not really convinced of Patrick&#x27;s framing of the supposedly inevitable trade-offs. I&#x27;ve lived in other countries with credit cards and discount brokerages, and in my opinion, the U.S. is uniquely bad at servicing customers. reply rootusrootus 14 hours agoparentprev> a system that calls you back is better than a system you wait on hold forBut a lot of customers don&#x27;t actually want that. An established connection feels safer than a promise of a future connection which may fail to happen for various reasons. reply notahacker 1 minute agorootparentOr the waiting for an hour listening to hold music happens on your lunch break, whereas the callback inevitably takes place when you&#x27;re in a meeting or driving... reply toomuchtodo 14 hours agorootparentprevThere is also no recourse when you never get called back. Better to just leave the call on hold until a human appears. reply tomjakubowski 14 hours agorootparentWhat is the recourse if nobody picks up the hold? reply krallja 13 hours agorootparentOr, as has happened more times than I can count, someone picks up and then the line goes dead? reply bluGill 12 hours agorootparentIn both those cases you know something happened. If they never pick up - at least you know when you gave up. If they hang up you know and can restart. Both are bad, but better than wondering if you are forgotten. replycreer 10 hours agoprevThe fine article mentions \"Banks are extremely good at tracking one kind of truth, ledgers.\" In some cases that&#x27;s - alarmingly - not even true. Or at least they are running their ledgers in ways that are so counter-intuitive and undocumented that they don&#x27;t make sense to their customers. I.E. it&#x27;s self-serving at best.This is a problem from banks that are supposed to pay attention to large chunks of your money. No? Obviously? A little? Yeah it is.Similarly alleging savage competition is self serving once you move beyond the most common low-balance checking account. FATCA for example took care of competition when it comes to running european bank accounts for US residents. Or try to borrow money against your financial assets - in the US - and find out how much competition there is there.And yet, there we are. An actual mainstream (among the top largest on the planet) bank where 1-3 times a year, I roll my eyes, spend time reassuring myself that it&#x27;s okay-enough, figure out how to present that nonsense to the IRS, make a note for my own tax reporting purposes and so that I don&#x27;t have to do the research again after I forgot, and fiinaallyyy move on with my life. I&#x27;m sure that ledger works out for the bank. reply cjmcqueen 1 hour agoprev\"If you think that talking to a compassionate human is a core part of the banking experience, there are many banks in Iowa who will sell that service to you. If you simply want to access your money on your phone and have that almost always work, Cash App will happily operate as a front end over Lincoln Savings Bank to make that happen.\"As someone living in Iowa, I can confirm this is true and also less effective. I bank at Chase because a straight forward \"no\" or clear process is so much more efficient and effective than a \"nice person trying to help\". People in Iowa hate that truth, but waste so much time listening and passing people around to solve a problem that should be resolved with a clear answer. reply woodruffw 14 hours agoprev> Sometimes the bank will have ability to e.g. share context between their screen and the Tier 2 rep; sometimes they’re literally incapable of proving to the bank that they work there.I&#x27;ve experienced this one directly: I ran into an issue with a large transfer between banks a few years ago, and watched with a mixture of amusement and anxiety as the branch employee was unable to prove his identity to his counterpart on the line. He was supposed to share some kind of OTP to prove that he was in front of a branch computer, but whatever microservice was responsible for generating and&#x2F;or delivering the OTPs was offline. reply jampekka 14 hours agoprevI&#x27;d wager the reason a lot of bank systems suck is that them sucking doesn&#x27;t matter to the banks, and the suck can be even beneficial to them.It&#x27;s rather difficult to change one&#x27;s bank, and banks actually put up hurdles to make the change difficult. E.g. moving loans can have huge \"rearrangement fees\", loan guarantees may be almost impossible to transfer and the bank account info is in quite a few places and having it wrong can cause missed payments.A good example is that when it was proposed that one should be able to transfer their account number to another bank (as telecoms have to do for phone numbers here in Finland at least), the bank lobbyists said this is technically impossible, which is of course ridiculous. And that we still this day and age have to wait for days for a bank transfer to clear.There are some new banks (e.g. Monzo) that once you use them, it really shows that most banks just suck.When you have literally a license to create money out of thin air, you can be really incompetent (except in lobbying of course) and still make hand over fist. reply abdullahkhalids 14 hours agoparent> A good example is that when it was proposed that one should be able to transfer their account number to another bank (as telecoms have to do for phone numbers here in Finland at least), the bank lobbyists said this is technically impossible, which is of course ridiculous.If you mean the bank account numbers used within Finland, sure, they can be changed. In the new system, there will be country-wide database which will now indicate which bank each account number is associated with. But your account also has an IBAN number, which has country and bank&#x2F;institution identifiers. Those will have to change if a customer moves banks, absent an international finance law change.And my understanding is that its quite common to use IBAN everywhere. So you won&#x27;t really solve the problem. Just add another layer of complexity. reply jampekka 14 hours agorootparentI mean&#x27;t that you can&#x27;t change the bank and keep your old account number. IBAN is just the \"Finnish\" number with FI prefixed and check digits appended. Though probably the old numbers too have per-bank allocated prefixes. BIC identifies the bank.As far as I and a quick web search know, you can&#x27;t make any of these refer to an account in another bank.Is IP over MAC or DNS over IP just another layer of complexity? reply abdullahkhalids 13 hours agorootparentThe point is that in your proposed system in which the customer keeps their local bank account number when moving banks, there will still be places where the customer will have to change their number - i.e. everywhere where their IBAN is stored. The IBAN cannot remain the same, because international institutions need to know which institutions they are dealing with. Not all institutions are legally allowed to or want to transact with all institutions.So the added layer of complexity is that customers will have to change their number in some places but not in others. And banks will have to have a system of ensuring they match the right IBAN with the right local account number. Whenever this fails, there will be problems such as delays or money being deposited in wrong accounts etc.This is unlike DNS over IP, which is universally&#x2F;internationally agreed protocol which has 100% coverage. But even in that system, whenever you change your DNS settings, it takes a while to propagate, and in this time there are all sorts of weird errors. Cat picture websites can tolerate those sorts of errors. Financials institutions should not. reply immibis 12 hours agorootparentCan&#x27;t Finland register the whole FI prefix as institution \"Finland\"? If other countries&#x27; institutions need to know the actual institution, well... it wouldn&#x27;t be the first time two countries had conflicting requirements, and politicians had to get together and yell at each other a bunch and suddenly a law was passed to solve it. reply jampekka 12 hours agorootparentprevYou mean universally&#x2F;internationally agreed protocol and maybe a set of laws like e.g. IBAN?The bank numbering system was indeed a static routing code, like phone numbers were in old landlines. Why the former can&#x27;t be changed but the latter could? reply abdullahkhalids 11 hours agorootparentOf course the IBAN system can be changed. It will just require a revision of international treaties, which will require dozens of countries agreeing to it. Finland has little control there. replyxcrjm 12 hours agoparentprev> A good example is that when it was proposed that one should be able to transfer their account number to another bank (as telecoms have to do for phone numbers here in Finland at least), the bank lobbyists said this is technically impossible, which is of course ridiculous.This comparison doesn&#x27;t make a ton of sense. Of course you can transfer your phone number - every phone number is mandated to be unique across all carriers. Bank account numbers are entirely internal to each bank and made up based on various arbitrary factors. What if the bank you want to move to already has an account with the same number as your account at your existing bank? How would that work? reply jampekka 11 hours agorootparentMay depend on the country, but at least in Finland the account numbers have been unique across banks for ages. The first part refers to the bank (actually a branch at least back in the day) and the last part to the account within the bank. There was and is no need to specify the bank separately.The mobile phone numbers had the same system. Three first numbers signified the operator, but the whole number it can now be transfered to another operator.This is not hard stuff. The numbers aren&#x27;t magic, they&#x27;re just identifiers. We&#x27;re not bound to mechanical routers or card sorting machines anymore. reply namdnay 13 hours agoparentprev> When you have literally a license to create money out of thin airThis is a common but slightly misleading interpretation of fractional reserve banking.If I lend you 100 bucks and you lend those 100 bucks to someone else, you’ve “created 100 bucks” in a monetary sense. But it’s not coming from thin air, from an accounting perspective it’s just a debt moving from one person to another reply jampekka 10 hours agorootparentThere are no fractional reserve requirements anymore. And (almost) all money is debt anyway, even by definition with some definitions.\"As announced on March 15, 2020, the Board reduced reserve requirement ratios to zero percent effective March 26, 2020. This action eliminated reserve requirements for all depository institutions.\"https:&#x2F;&#x2F;www.federalreserve.gov&#x2F;monetarypolicy&#x2F;reservereq.htm reply astrange 7 hours agorootparentThere are lots of reserve and stress testing requirements on banks, and banks are usually public companies whose finances their investors can read, and they often fail when the investors decide the finances look bad.https:&#x2F;&#x2F;www.investopedia.com&#x2F;terms&#x2F;b&#x2F;basell-iii.asp reply kaibee 11 hours agorootparentprevYes, but when I deposit $100 with @Bank (ie, effectively lending $100 to the bank), they aren&#x27;t loaning out $10 to a couple people, they&#x27;re lending out $100 to a couple people, because they did the math and figured that they can get most of those people to pay them back before I ask them for my $100 back. This is all well and good, but they really are creating money out of thin air when they&#x27;re loaning out more money than they actually have on hand. reply cipheredStones 5 hours agorootparentThis makes no sense. If the bank lends $100 each to two people, it has to be prepared for them to take that money and spend it more or less immediately - on a house, or payroll, or whatever. When you put your $100 into the ATM, and two people get $100 bills from the ATM, where does the second bill come from? reply desas 3 hours agorootparentOnly something like 10% of the world&#x27;s money are physical bills and coins. The rest is electronic, just numbers in reputable databases.The bank can rely on this fact. It only needs enough notes to support a likely amount of physical cash withdrawals each day. reply mrkeen 14 hours agoparentprev> When you have literally a license to create money out of thin airWell, you can loan out some amount of money that you don&#x27;t have, hopefully get it returned to you with some interest. reply skybrian 13 hours agorootparentThat&#x27;s not how it works. When a bank makes a loan, the customer will use it to buy something (say, a house), and probably the money will be put in a different bank. So the money definitely needs to be there, to pay the other bank.There&#x27;s a deposit in the other bank, along with the payment. Both of which are \"money.\"So, a bank can create money from thin air by making a loan, but typically not for themselves. It happens in a different bank. reply immibis 12 hours agorootparentprevI want to make it a point that EVERYONE CAN DO THIS. Everyone can make a loan, everyone can count their un-returned loans as money if they want to, and everyone can accept transfers of other people&#x27;s un-returned loans as payment if they want to. The only special power banks have is that most people accept them doing this. If your whole friend circle accepts un-returned loans from each other as payment, then you&#x27;re all doing fractional reserve. reply jampekka 11 hours agorootparentThe special power is the banking license they get from the government. Try to do it without and you&#x27;ll find yourself in prison quite soon. Especially if you do it in official currency. reply immibis 10 hours agorootparentNo, I don&#x27;t need a banking license to loan my friend $10. reply desas 3 hours agorootparentThe difference is that licensed and regulated banks can scale it. Retail customers can trust them due to their long-standing reputation, their banking licence and linked to that, the FDIC insurance. reply jampekka 14 hours agorootparentprevIf enough doesn&#x27;t get returned, the gov&#x2F;centeral bank gives it to you as a bailout. And for many loans you automatically get it from the gov if the debtor can&#x27;t pay. reply vkou 14 hours agorootparent> If enough doesn&#x27;t get returned, the gov&#x2F;centeral bank gives it to you as a bailout.No, the gov&#x2F;central bank will give it to the people you borrowed money from as a bailout.Your equity will be zeroed out, your executives will all be fired, and your customer accounts will be fed to another bank. reply immibis 12 hours agorootparentNo, that&#x27;s not how it works. They did this a few times, even a few high-profile cases, but the vast majority of times they just gave money to the struggling bank. reply astrange 7 hours agorootparentThat money comes from the FDIC insurance fund, which comes from other banks. It&#x27;s not printed or coming from taxpayers.Anyway, a \"bailout\" is when you give money to equityholders. They often lose money in situations people call \"bailouts\" even though they&#x27;re literally the opposite. reply jampekka 14 hours agorootparentprevCitibank was bailed out, the stock rose over 50% overnight and the CEO got paid hundreds of millions. reply alexb_ 13 hours agorootparentYou realize bailouts are loans, right? They aren&#x27;t just free money. reply jampekka 11 hours agorootparentThere were many forms of bailout for Citibank (and others). Some were (extremely favorably termed) loans, some government backing of their bad assets and some were buying stock that the market didn&#x27;t want to touch.May or may not be technically free money, but for sure Citibank doesn&#x27;t hand out loans to bankrupt customers on such terms.The gov could have e.g. let Citibank go bankrupt and just take it for free. Like banks do to their customers. reply vkou 13 hours agorootparentprevCitibank shareholders got diluted, and Citibank paid back for that bailout, with the taxpayers profiting ~12 billion in total.If the money couldn&#x27;t have been paid back, the shareholders wouldn&#x27;t have been diluted.They would have been wiped out. reply jampekka 11 hours agorootparentIf the gov wouldn&#x27;t have bailed out Citibank the shareholders would have been wiped out in the first place. And gov would have gotten it for essentially free if wanted. It was not like they saw that here&#x27;s a great investment opportunity to make profit for taxpayers. reply vkou 10 hours agorootparent> If the gov wouldn&#x27;t have bailed out Citibank the shareholders would have been wiped out in the first place.And also the entire economy would have collapsed, and we&#x27;d all be trading ammunition for bottlecaps, instead of merely living through a nasty recession.Which is why they backstopped it. Yes, it would have been cheaper to let Citi fail and nationalize it, but it wouldn&#x27;t have been cheaper to then have to deal with all the contagion and all the other businesses that would have exploded because of it. replyempathy_m 8 hours agoprevThe corollary to this \"if your account was abruptly closed with no explanation, it was a pile of SARs, so sorry\" story is that when you&#x27;re at an airport and weird stuff happens, the best boogeyman reason is air marshals.Did your seat assignment abruptly change and the gate agent is evasive or outright refuses to say why? Nod knowingly. Say \"oh, right, must be a FAM.\" Ask for what you want: \"I&#x27;ll just take the next flight for free\", \"I understand if there are upgrades available on my return\", or just nod and wink. The GA won&#x27;t be able to say whether or not you guessed right and it&#x27;s much funnier that way. reply gniv 14 hours agoprevInteresting read, as usual.\"You can understand why, right? From their perspective, they were just going about their life, doing nothing wrong, and then for some bullshit reason the bank charged them $35.\"I&#x27;m not sure it&#x27;s quite right to blame this on math illiteracy. I think some people are still in denial on bank fees. reply immibis 12 hours agoparentThe reality is the person also got paid $500 on the same day, but even though the paycheck arrived early in the morning, the bank chose to process it late at night to collect that $35 overdraft fee in the meantime. reply astrange 7 hours agorootparentDown significantly.https:&#x2F;&#x2F;www.consumerfinance.gov&#x2F;data-research&#x2F;research-repor...Payroll ACH transfers usually get deposited two days faster than they used to as well (1 day instead of 3 days). reply cafebee 14 hours agoprev> For better or worse, the side channels are not an accident. They are extremely intentionally designed. Accessing them often requires performance of being a professional-managerial class member or otherwise knowing some financial industry shibbolethsWhat is meant by side channels here? Is it writing \"a paper letter to the VP of Retail Banking\", as mentioned elsewhere in the article? That doesn&#x27;t seem \"intentionally designed\", so the author must be referring to something else, but I don&#x27;t have the imagination to guess it reply RationalDino 14 hours agoparentThat is an example of a side channel.That&#x27;s the kind of thing done by people who the bank really doesn&#x27;t want to offend. The bank decided it wants that to work for them. Therefore the bank created a way of making sure it works.That it is not documented or advertised is a feature. reply timerol 13 hours agoparentprevThe \"intentionally designed\" part isn&#x27;t just the mail, it&#x27;s the process that comes after receiving mail. The VP of Retail Banking does not read their own mail. Who does read that mail? How are various letters delegated to appropriate teams? What letters are discarded or given a canned response? How does the bank make sure that it doesn&#x27;t ghost people (most of the time)? It basically needs an entire support system, which may or may not rely on parts of the official support system reply seraphine 13 hours agoparentprevNot sure if this is what he meant but you can call a bank or visit a branch, get a phone number for a specific department and call them directly and get almost VIP levels of helpful service in my experience.Something that would entail hours of phone support thru official channels cut down to 15 minutes. Once you discover this there&#x27;s no going back and it all depends on who you ask, and how you ask. reply TacticalCoder 10 hours agoprev> And partly, we as a society have to make some tradeoffs. We want something from 12 CFR § 21.11(k)(1) . It was not written by accident or because the drafters were stupid. Every future with 12 CFR § 21.11(k)(1) in it will include many Americans whose bank accounts are closed for no reason that can be disclosed to them. Many of them will have done nothing wrong.I totally dispute that and there&#x27;s a contradiction in there. If many of them will have done nothing wrong, then the drafters were plain stupid.Typically senile, dumb, stupid, out-of-touch people.There&#x27;s nothing for the people in there and it wasn&#x27;t the result of a democratic process.It is also a complete and utter failure, costing $180bn worldwide for a mere $12bn frozen (not even seized but temporarily frozen, some being actually legit money that&#x27;ll eventually be unfrozen).In other words: it&#x27;s yet another pointless law that is not having the intended effect and that is costing business and taxpayers money and time while making people feel they live in a dystopian madness.And there&#x27;s more drugs than ever sold both in, say, the EU and the US. And there&#x27;s still child pornography. And there&#x27;s still 3% to 5% of the world&#x27;s GDP that is tied to criminal activities.\"The more numerous the laws, the more corrupt the state\" (Tacitus thousands of years ago) reply astrange 7 hours agoparent> It is also a complete and utter failure, costing $180bn worldwide for a mere $12bn frozen (not even seized but temporarily frozen, some being actually legit money that&#x27;ll eventually be unfrozen).Selection effect (the question is how many illegal activities it prevents in the first place)> And there&#x27;s more drugs than ever sold both in, say, the EU and the US.Base rate effect (population and disposable income are going up, and who does market research on drug sales anyway?) reply bob1029 15 hours agoprev> Due to the deskilling of the bank branch, the people at a bank branch, including the branch manager in many firms, can only offer solutions to relatively straightforward problems. For the other ones, they also have to call into a support phone tree. Sometimes the bank will have ability to e.g. share context between their screen and the Tier 2 rep; sometimes they’re literally incapable of proving to the bank that they work there.This is essentially the central value proposition of our SaaS product - Providing less-skilled employees the ability to accurately conduct complex account and customer management activities in the branch environment. An \"on-rails\" style application experience that more-or-less forces you to take legal actions with the end customer.Our most popular workflows from the perspective of bankers are the ones used most rarely - IRA rollovers, conversions, etc. The ones you cannot possibly hope to memorize because they happen so rarely. But, from a board room perspective, the focus is much stronger on the efficiency&#x2F;correctness gains for the happy-path consumer product stacks.I&#x27;d say it&#x27;s a dragon of a space. Borderline cursed. It took us half a decade just to get core interfaces working well enough and that is only like 20% of the puzzle. Documentation, regulations, back office processes, etc are way more important and involve super nasty conversations with people who might sense that you are trying to replace them. reply dcminter 15 hours agoprev\"No system will ever be able to answer all interesting questions about a user; that is formally undecidable in computer science.\" What? Are they talking about the halting problem? This seems like a stretch without defining what constitutes \"interesting\" in a very weird way. reply patio11 15 hours agoparentPlease accept this as a handwavy gesture at the halting problem for an audience which has on average something like 0.2 engineering degrees. reply dcminter 12 hours agorootparentSo what particular banking customer data management software do you have in mind that&#x27;s adversely affected by the halting problem? (Edit: Ha, didn&#x27;t notice you were the author!) reply immibis 12 hours agorootparentHello, Mr Bank Manager, I have enrolled into a game show which will cost me half my account balance if it&#x27;s even, otherwise they will triple it and add one... reply DamonHD 15 hours agoprevInsightful and nicely written. I spent decades in finance including investment banking and as a director&#x2F;founder of a small retail operation. A lot of this really rings true. reply A4ET8a8uTh0 15 hours agoparentIt also managed to hit home some issues I experienced recently. Long time ago, I was a teller&#x2F;banker and I was still selling, but the recent experience of in person account opening was just bad ( no rate quote, disclosures thrown at the end for the sake of compliance, and promise of a call back for an issue I raised that I never actually got.. come to think of it ). The poor kid did not know anything about what he was selling and that was basic UTMA savings.Anyway, what I am saying is that is well worth the read; especially the bit about constant firefighting. reply pdntspa 12 hours agoprevI didn&#x27;t read the article as it appeared to go off on tangents that don&#x27;t really get to the heart of the matter: SARs and everything else are super super secret and there are severe penalties for even cluing someone in about them. There is a lot of bullshit clockwork that is hidden from consumers under the guise of anti-money-laundering and anti-organized-crime stuff. If I recall the training correctly, you aren&#x27;t even allowed to acknowledge there is this whole secret process!Which is stupid. All of this is because FinCEN has banks by the balls reply jdblair 11 hours agoprevIt has been instructive to experience banking in the Netherlands after living in the USA most of my life. Transferring money to any other IBAN number, even large sums? Ridiculously easy, and available immediately in the recipient’s account.Transferring large sums between the US and my Dutch account? Wise.com makes this much simpler, but its not easy. I can use ACH transactions, but that is limited to 20k at a time. Wire transfers provide a way, but my US bank limits daily transfers initiated online to a pretty small amount (good to combat fraud, inconvenient if buying a house). I can travel to the US and initiate the transfer in person, but you may recall that travel was difficult in 2020.I had to send a paper form, with proof of identity provided by a Dutch notary (more like a paralegal than a US notary, to a central office for the bank in the US. Maybe this is ok? It’s not like I need to do it very often.I do hope FedNow makes the usual European experience more common in the US. reply techsupporter 14 hours agoprev> And, as a particular thing which could help unlock that: if one cares a lot about the experience of people at the socioeconomic margins, one should perhaps spend less time fulminating about greedy capitalists and spend more time reading Requests For Public Comment by relatively obscure parts of the administrative state.For what it&#x27;s worth, there are a staggering number of people doing political advocacy who follow these sorts of things. The main problem is, unless you are inside that system, there is no (scalable) way to know which relatively obscure parts are about to do something that you want to comment on. And, as patio11 wrote out, it&#x27;s a massive system that has been layered on top of layers.Part of the reason why spend \"time fulminating about greedy capitalists\" is because those \"greedy capitalists\" are the ones inside the system. Hell, a good amount of time, advocates are having to spend time pushing back against \"greedy capitalists\" because the status quo is already known and understood, but a change would cost money even if it is beneficial so the change must be opposed.What advocacy could really use is more people who have this deep understanding and can write out lengthy articles like this explaining all of the ins-and-outs to come along with the advocates as a guide. The problem is, the economic and cultural incentives don&#x27;t work like that. reply nologic01 11 hours agoprevThere should be more of this. Much more. From different angles and view points but with the same clarity and directness.Banking is in a deep, existential crisis for decades now and the march of digitization only increases the pressure to find a way forward.In response techno-solutionists imagine all sorts of replacements, whether it is \"fintech\", or \"banking-as-a-service\" or \"crypto\" but all are hopelessly shallow and incomplete, almost insultingly crude.What is entirely missing from these neobanking movements is any straight definition of what is the purpose of banking and bankers. What is their irreducible value proposition that cannot be delegated to machines and algorithms. What is their role in society. Are they allies or enemies of surveillance capitalism? Are their users clients or products? Can there be an honest relation with the sovereign monetary system and the lender of last resort or is private banking a scheme to privatize profits and socialize losses? Last but not least, what role, if any, should they play towards environmental sustainability.The questions and challenges are pilling up and there are no breakthroughs worth mentioning. In a parallel universe we might have something like BN (banking news), where all sorts of individuals, teams small or large, would pimp their blogs, radical ideas, open source solutions or fancy software products, but above all a positive, forward looking vision for a crucial sector. reply vkou 9 hours agoparent> what is the purpose of banking and bankers.To borrow money from you, paying you a low interest rate, but allowing you to withdraw it at a drop of the hat, while lending money to someone else, at high interest rates, but on a fixed, multi-year repayment schedule.Borrow short, lend long. It&#x27;s socially useful, and if the bank does it well, it stands to make a lot of money. reply nologic01 3 hours agorootparentThats a rather incomplete business model description of banking.There are at least three distinct elements and largely unrelated to core banking: payments infrastructure &#x2F; gatekeeping the private&#x2F;public monetary system, managing interest rate risk (which is what you describe) and managing credit risk.Add to that countless \"non-core\" intermediation activities which nevertheless, depending on the type of bank can be major revenue sources.Maximazing social utility is indeed the key question but how to do it in a sustainable and future proof way is hardly ever seriously asked. reply astrange 7 hours agorootparentprevAnd the purpose of this is to increase money velocity by providing loans. \"Narrow banking\" (having the government provide bank accounts) wouldn&#x27;t work unless the government also provided business loans, which doesn&#x27;t really make sense. reply nologic01 3 hours agorootparentAny references to narrow banking been tried and \"not working\"?Separating the issue of private money from providing commercial credit risk insurance (ala CDS) should be possible. reply creeble 12 hours agoprevFunny comment about First Republic and Chase.I too have&#x2F;had a mortgage at FR and I now see it in my existing Chase account (maybe the balance is even correct, pretty hard for me to know), but I have no idea whether they are going to still take the payment out of my FR checking account, despite their official transition page saying \"all automatic payments will be transferred as well.\"I guess I can&#x27;t take the money out of my FR account until I know. reply numlocked 12 hours agoparentToo funny. I am in the exact same boat. For what it&#x27;s worth I spoke to their customer service (Chase) yesterday who indicated that the auto-payment would continue to work as it always had, but will process \"10 days late\". So I&#x27;m expecting it to come out of my FRB account on the 10th or the 13th.I was also caught totally off-guard when I logged into FRB and it informed me my mortgage had been closed. If I didn&#x27;t have a Chase credit card (and saw my mortgage there when I went to pay the credit card) I&#x27;d probably still be baffled. reply creeble 11 hours agorootparentI think I also saw that only this _first_ auto-payment will work -- after that you have to set it up at Chase if you want to continue auto-payment.One thing I found out about mortgage auto-payments at FRB was that they wouldn&#x27;t take the money out unless there was enough in the account within the first 6 days of the month. They would automatically check every day, and if the balance was high enough, they would take it out. On the 7th day I guess they would send you an overdue notice (and maybe keep checking? no idea). They could only do this because they owned both accounts.Edit: Okay, TMI but this is just so... interactive right now.I looked up the transfer balance in my FRB account, and the account balance at Chase was $6k higher. So I called Chase Mortgage.The wait was only about 3m (after the touch-tone gauntlet), and I talked to a very nice dude who welcomed me to Chase... and then promptly told me he&#x27;d have to transfer me because I am a \"Premium Customer\" coming from FRB. I&#x27;ve been on hold the last 15m. Premium I guess means \"wait more\". reply sherlock_h 14 hours agoprevGreat article. Explains the chalenges that I just had with having all money frozen with Marcus.com. It is literally impossible to break through these layers of support in order to get your case heard &#x2F; solved. The biggest challenge is that it‘s so intransparent with very little communication from the bank as to how a support case is actually moving through and how close it is to getting resolved. reply astrange 7 hours agoparentDid you read the article carefully enough? It gives you several ways to get to the \"useful\" support. But besides his way of writing the right kind of letter, you can make a CFPB complaint. reply lainga 15 hours agoprevI found the article answered most of the questions it posed, but this one came and went unexplained...> Banks aggressively partition staff based on job duties and levels within those duties.Why? reply orangesite 14 hours agoparentEfficiency fallacy.\"We can generate more throughput in the system as a whole by negatively incentivizing each component to work itself to death.\"See Goldratt, Eli. reply adolph 14 hours agoparentprevOne phrase that comes up is \"segregation of duties\" meaning things like \"if one person can do X and Y then they can commit fraud without being caught.\" So the principle of \"segregation of duties\" means that the people who can do X are on different teams than those who can do Y. reply NovemberWhiskey 12 hours agorootparentLike, specifically: please don&#x27;t let your operations people in books and records have access to your treasury and reconciliation systems. Or, don&#x27;t let front-office people have access to middle-office systems. See: Leeson, Nick; Kerviel, Jérôme. reply immibis 12 hours agorootparentprevIt doesn&#x27;t only happen at banks, though. reply shermozle 4 hours agoprev\"Your Princess Is In Another Castle\" made me snort. Nice work @Patio11 reply kylehotchkiss 14 hours agoprevMy very very naive take on this: why don&#x27;t banks have more common operating systems and data structures? Why is it this hard for acquisitions to work? They&#x27;re a guaranteed part of business so a common software stack could help Chase integrate First Republic without two parallel systems? (I welcome any responses on why this will never happen though!) reply patio11 14 hours agoparentThere is a famous joke about standards: the great thing about common standards is that you have so many to choose from. A corollary to it: if none of the existing common standards meets your need, how about letting some of your senior staff get promoted by successfully creating and popularizing a new common standard? reply cowthulhu 10 hours agoparentprevMy two cents from the perspective of smaller financial institutions - cores do not care about making it easier for you to move off of them. They probably wouldn’t mind making it easier to move on, but core conversions are such a nightmare that they have dedicated onboarding teams for this with lots of tooling and knowledge, and since everyone else’s data structures are different, there’s no point standardizing your own.Additionally, there are, like, three big players in the space (at our level, at least). When you’re choosing a core, you’re probably going to be more concerned by questions such as “what percentage of our total revenue will go to this one application” and “what features can we use to save us tons of work and money” and “will this make us more money”. You probably won’t be too concerned with whether converting off the core fifteen years down the line is super difficult or “just” pretty difficult. If you do ask, all three will give you the same answer anyways. reply mrkeen 14 hours agoparentprevEvery problem you solve takes time away from solving other problems, and this one is a particularly difficult coordination problem with very little payoff.You might be imagining two banks coordinating together, now scrap that and imagine ALL banks coordinating, because you don&#x27;t know which two are going to merge.Banks have been born at different times (think centuries - or even millenia). So they&#x27;d all have to move in lockstep from clay tablets to papyrus to printing press to typewriter before they even decide whether or not they want to bet on computers as a way forward.To some degree banks already have &#x27;a shared operating system&#x27; in the form of clearing houses and central banks. I don&#x27;t know enough about that stuff. But it&#x27;s the reason why bank transfers have mostly taken days to complete, rather than seconds, in the past few decades.Come to think of it, there&#x27;s a huge incentive not to stay in lockstep with all the other banks if you can offer customers instantaneous transfers when other banks make you wait for days. reply Kalium 10 hours agoparentprevPick any two small businesses in the same niche. Grow them for three or four decades. How identical do you think their evolved business practices will be?My very very naive take is that they will have had to solve similar problems over time and will have practices and systems that work analogously. I would bet they will probably not use identical software packages or data structures and will have had little reason to structure their internal operations around someone else&#x27;s standards. This is especially likely to be true of standards that came along well after the companies already solved the problems the standards are aimed at. reply CamouflagedKiwi 11 hours agoparentprevWhy don&#x27;t software companies have more common operating systems and data structures? Why is it hard for acquisitions of software companies to work? They are a common part of business in that industry too. reply gravitate 11 hours agoprevWhat about &#x27;neo banks&#x27;? I am with Revolut free tier and I know why they have a free tier&#x2F;basic tier, because I know they monetize my bank statements and purchase habits for &#x27;market research&#x27; and other insights. reply ponector 9 hours agoparentRevolut is a EU bank and has the same regulations, AML, KYC rules as other banks. There are tons of stories about closed accounts by revolute.It is even worse than \"regular\" bank because you can&#x27;t go to the branch or call the support number. You can get help via chatbot from the application and I doubt you can use it without active account. reply grishka 11 hours agoprevI don&#x27;t know what banking is like in the US, but having to deal with a UAE bank was a culture shock for me. This article made me understand why it&#x27;s so shitty. No one seems to want to do their job. Everything — I mean everything — takes ages. The branch employees are utterly powerless. The only thing they can do right there and right now is cash transactions, everything else requires a form to be filled and signed and sent \"to the back office\" for the thing you asked for to maybe happen in \"3 to 5 working days\". I have only tried calling them once. They use a toll number, but then still try their hardest to \"solve your issue\" through an automated voice menu before you have any chance to talk to a real human. Writing to the right person directly to their work email sometimes gets your problems solved very quickly though.It was a culture shock because I&#x27;m Russian and banks don&#x27;t play as important of a role in our society because of the Soviet past. Yes, most of our population has a bank account these days. Yes, most people are paid by transfers to that account. But — our entire banking system was built from scratch in the 90s. Banks had to sell the whole idea of banking to people to begin with. So if you have an issue and you go to a branch to get it sorted, you do get it sorted on the spot by a branch employee. It probably also helps that many Russians \"don&#x27;t trust banks\" so they&#x27;d go to an ATM on their payday and withdraw their entire salary and use cash for all their transactions. We&#x27;ve also never had checks, we skipped that entirely. We also have this nifty СБП system that allows you to instantly make a transfer from any bank to any other bank using just the recipient&#x27;s phone number. Very useful for things like splitting bills. I was shocked to find out that most other countries don&#x27;t have anything like this and even sending someone money within one bank is quite a process. reply ponector 9 hours agoparentPassage about checks is simply not true.Other countries in EU have similar systems where you can use phone number instead of IBAN. It is convenient for small sums.Also you can do free SEPA wire transfer in any EU currency to any account in EU or abroad. Big difference to how expensive is to move money from pre-war Russia or USA. reply grishka 9 hours agorootparent> Passage about checks is simply not true.The only time I&#x27;ve seen checks used it was for a company account. That is in contrast with some countries where checks are still in wide use by regular people for large personal expenses like rent.About EU, yes, I heard about this. Also India has a similar system. reply donalhunt 13 hours agoprev> Ops feels like the world is on fire because the world is always on fireThis gave me a chuckle. :) reply cratermoon 13 hours agoprevThis could also apply to the way airlines see passengers. In my experience, passenger information is scattered across different systems and representation. One system tracks the reservation itself, which has information 1 or more passengers. Another system tracks the fare and various feeds paid or due. Another tracks check-in status. Yet another has seating information. Bags checked live somewhere else. There&#x27;s not a common key. There are of course confirmation numbers (those 6-character codes), but only after a reservation is confirmed. If a person has a frequent flyer code, that&#x27;s another key.As the passenger moves through the system, each different subset of attributes is attached only to the system in which it lives, and cross-correlating a passenger across systems is done in numerous ad-hoc ways.The customer service folks have a lot of tribal knowledge, and if you happen to get an experienced one, they can really smooth the way. During the pandemic, though, a lot of people left the industry, and a lot of knowledge just walked out the door. reply iamleppert 11 hours agoprevTreat bank accounts like an unreliable host. You wouldn’t have a single database instance running your entire business like you shouldn’t have a single bank running your business.Open multiple accounts and when one starts acting up change it out for another. Always have several bank accounts at the ready.Every transaction you make has risk, counter party risk extends to your financial institution as well.You should be running drills every quarter and randomly switching up your bank. Don’t be a victim when you have engineering solutions to these problems!If you have money in an account at a bank for business operations, keep that in a completely separate bank and legal entity than the one with a risky transaction profile. Use an intermediary bank to receive deposits from the likely to close bank account that transfers money out immediately to your operational account, and make sure it’s at a competitor. Banks don’t share info and you can take advantage of slow processes and communication delays to give enough time to fix problems with a flaky bank before they impact your business. Think of it like a firewall for your business. reply avn2109 10 hours agoparentBy far the most pro comment in this thread, should be much higher. reply rdtsc 14 hours agoprev> at some financial institutions, you can get a SAR filed for knowing what a SAR is, because “advanced knowledge of anti-moneylaundering procedure” is a characteristic only of financial professionals and terrorists.That is messed up. You ask about a SAR or indicate you know about them in general, you get a SAR slapped on you, and they close your account. You&#x27;re one of hundreds of thousands, why bother handling a SAR-ed user when they can just move on without you.Are individuals allowed to have a public forum to discuss and share notes of what they did in their account to learn and prevent this from happening in the future? It seems in a lot of cases it&#x27;s using these payment systems like Zelle or have anything associated with phrases resembling black-listed countries or organization. reply tlb 14 hours agoparentPeople are massively dishonest about this, though. Like there are occasional Ask HN posts where someone is outraged that their bank&#x2F;payment account was closed for “no reason”, but eventually it comes out that they’re in North Korea selling cannabis to Iran or something.But it does seem like the world lacks a manual on How Not To Get In Trouble With Your Bank. “Structuring” in particular is something someone might innocently do just because they like round numbers. reply boilerupnc 14 hours agorootparentFunny enough. Whenever possible, I round all my tips to cause the total to generate a particular two digit cents amount - so that I can easily detect fraud when I scan my statements. It’s my low tech error code check. reply aembleton 11 hours agorootparentI get a notification on my phone when any money is deposited or withdrawn from my account. If its not something I&#x27;ve just done or an unexpected amount, then its probably fraud and I can tell my bank. reply cj 6 hours agorootparentIn the US, restaurants immediately charge the price of the meal (without tip). Then the next day the restaurant updates the amount of the original charge to add on the amount you added as a tip.That means shady restaurant could change your tip the next day if they wanted to pull a fast one on you.In other words, it’s not possible to get an immediate notification of the total amount charged including tip until 1-2 days after the meal.(Don’t ask me why the system works this way, makes no sense to me) reply throwanem 5 hours agorootparentIt works that way because in the 1980s that was the only way to make it work at all, and it still works that way because being able to do the equivalent of an HTTP OPTIONS preflight for money is actually quite useful. reply jdadj 13 hours agorootparentprevI use palindromes. Easy to check and will catch extra dollars added. reply velcrovan 13 hours agorootparentprevHas this ever turned up anything suspicious? reply boilerupnc 12 hours agorootparentIt actually did. At a wings place I noticed a total that wasn’t my usual last two digits. I called up the place and they confirmed they had an employee who had been altering tip amounts and also skimming cards. They advised me to call my credit card company and ask for a new card. It is now a well defined muscle memory for me. Therefore for very little effort I get a desirable side effect of easy detection. My teen son currently rolls his eyes when I fill out the receipt but I suspect he’ll adopt the habit in some form over time. reply bravura 11 hours agorootparentWhat about routine credit card transactions that you don’t tip on? Isn’t that the bulk of purchases ? reply SpaceNoodled 11 hours agorootparentHe&#x27;s the guy that tips at grocery stores. reply throwanem 5 hours agorootparentprevTransactions that don&#x27;t involve latency in knowing the final amount also don&#x27;t offer the same opportunity for chicanery. reply eadler 12 hours agorootparentprevI track almost all of my expenditures. At a restaurant I used to visit fairly regularly I noticed that my costs were often off by approximately ±25 cents. This was inconsistent and not always in one party&#x27;s favour. Upon reporting and investigation it turned out that (a) I routinely wrote &#x27;math&#x27; along with a total instead of a tip and (b) one of the waiters only approximated the math required.Nothing nefarious and I&#x27;m not even sure if I won or lost out of this - but it was interesting to catch. reply topherclay 12 hours agorootparentI had to reread this because it didn&#x27;t make sense to me the first time because it&#x27;s so insane. reply ska 12 hours agorootparentprevNot surprising, right? I don&#x27;t know what you expected implicitly asking them to do the arithmetic for you, but I would&#x27;ve assumed not much care would be taken. reply pdntspa 12 hours agorootparentprev> I routinely wrote &#x27;math&#x27;Why would you do this? reply dboreham 10 hours agorootparent1+ bottle wine? reply JohnFen 10 hours agorootparentprev> I routinely wrote &#x27;math&#x27; along with a total instead of a tipI, too, am dying to know why you do this. I assume that you didn&#x27;t intend it to be punitive, but that&#x27;s what it looks like to me. reply gurchik 10 hours agorootparentprevI&#x27;ve heard that half the time a restarant&#x27;s POS is configured to ask the waiter to enter the number written on the tip line, but the other half of the time, it&#x27;s configured for the them to enter what&#x27;s written on the total line. Meaning, in the first case, writing \"math\" means more work for the waiter, and in the latter case, you better be careful the amount you wrote on the total line is accurate. reply PKop 11 hours agorootparentprevCatch what? Why would you do something so silly reply Fatnino 10 hours agorootparentprevIs it 69?It&#x27;s 69. reply workfromspace 9 hours agorootparentMy guess is 42. reply AussieWog93 13 hours agorootparentprevAnecdata, but I&#x27;ve had both my bank account and Stripe account closed for basically \"no reason\".I still don&#x27;t know why Stripe closed my account (I was selling cheap USB oscilloscopes online, never had a complaint. Couldn&#x27;t get in contact with them at all when it happened.)My bank account was closed because I filled in a KYC form incorrectly, and they didn&#x27;t have a process in place to follow up properly when this had occurred. reply throwaway2037 8 hours agorootparentnext [–]My bank account was closed because I filled in a KYC form incorrectly, and they didn&#x27;t have a process in place to follow up properly when this had occurred.I&#x27;m tired of HN anecdata about \"bank account was closed because of silly reason X\". I sincerely doubt we are getting the full story. Step 1: Send a written complaint to the bank and use mail tracking. Then they cannot deny it was not received. Step 2: Report this to your local banking regulator. reply idiotsecant 7 hours agorootparentYou seem very emotionally invested in the idea that banks don&#x27;t make mistakes. What is that all about? reply jonathanlydall 5 hours agorootparentI’m pretty sure that they absolutely know that banks make mistakes.But if you’ve never been on the other side providing customer service, you may be astonished at the systemic fraud&#x2F;illegal attempts happening constantly.When I did CS at Blizzard for WoW at least half our work was dealing with compromised accounts (essentially by gold sellers), and then a good deal of “I’ve been hacked!” tickets were by the thieves trying to double steal from an account.To put that in perspective, it was $100,000s or $1,000,000s in CS costs per month (at just Blizzard) to help customers who were victims of a large scale full time industry (not individuals, organisations) which compromises accounts to make a living.People banned for confirmed cheating with 3rd party programs would make support requests repeatedly in the hope they’d come across an agent who “makes a mistake and accidentally unbans them”, occasionally you would see lots of them trying the same strategy or telling the same story since they saw a forum post of someone who said “this worked for me”.Legitimate mistakes happen, but they’re like 1% of the time, the rest of the time it’s systemic attempted fraud.So the person you’re replying to is most likely aware of this reality and says that “complaining on forums” is most often by people who aren’t telling the full story.Hence them saying, if your story is legit, take it to the right place to get help, otherwise you’re looking like a just another fraudster (who do this systematically) trying to game the system in some way. reply opportune 14 hours agorootparentprevCompletely agree that banks should provide prescriptive guides.IME they really don’t like when you work around their eg 50k&#x2F;day ACH transfer limit by initiating 50k ACH transfers on 4 consecutive days to move an account of 200k. But they don’t tell you what they actually want you to do if you want to move 200k - and for obvious reasons they probably don’t want to make these transfers fully frictionless. They just assume you’ll know to show up at a branch in person or get on a phone to ask about it and treat you like a criminal if you don’t. reply creer 11 hours agorootparentPart of the problem is a bank training you on recognizing that they have countless silly obscure rules for their own purposes - for example in what your password may be and how messages to their employees might be (mine limits the messages to be very short - no space to explain anything.) So you are quickly trained to make do with the silly rules. I.E. multiple ACH over several days and move on with your life... Or in the case of messages, I just continue my explanation in multiple messages.Either way, the bank has trained the customer to work around limits. They can&#x27;t have it both ways. reply xvilka 10 hours agorootparentAnd people are surprised why so many were excited to use cryptocurrencies. The current banking system is broken to the root. reply someplaceguy 6 hours agorootparentAnd getting progressively more broken, due to increasingly stricter and more numerous laws, and more effective enforcement.Hell, in Spain you can&#x27;t even legally pay anything in cash if it costs more than 1,000 EUR. In Greece, the limit is 500 EUR. reply JohnFen 10 hours agorootparentprev> I.E. multiple ACH over several days and move on with your life...Surely, just picking up the phone and speaking to them is faster and easier than engaging in structural transactions like that. reply creer 9 hours agorootparentIs it? Usually no, it&#x27;s not. At one bank, they want me to always talk to the same person - who is generally competent but also usually not available and sometimes outright on vacation with no warning. At another bank, they want me to go through the basic 800 number - where the person who answers usually knows much less than I do. Picking up the phone is usually not a good solution. reply opportune 6 hours agorootparentprevOne, this isn’t structuring. Just because you read what structuring is 5m before you read my post doesn’t make this structuring. 50k is way over reporting limits.And also no it isn’t faster to pick up the phone, even if I don’t get out on hold at all. An ACH transfer takes seconds, it’s like writing a digital check. Doing it 4 times takes very little time. reply dmurray 13 hours agorootparentprevIs that even \"working around\" the restriction? Surely moving 50k on each of 4 days is what you&#x27;re expected to do in that case. It still means the maximum a fraudster can get away with is 50k if the fraud is discovered in one day.My last bank had limits like 20k&#x2F;day and 50k&#x2F;week, so it seems like yours could have 50k&#x2F;day and 60k&#x2F;week if they \"really don&#x27;t like\" you using it like this. reply opportune 13 hours agorootparentOne of the reasons banks have these restrictions (besides the obvious thing of making it difficult to take large sums of money out because it hurts their business) is to prevent fraud. They want to prevent the case where some criminal gets physical access to my computer, or my login credentials, and drains my account without my knowledge. So they want you to initiate a manual verification that you really do intend to move such a large sum to prevent that fraud.If you do what I did, you usually get a temporary hold on your account and some very skeptical bank employee calling you to grill you on what you’re doing.On one hand I get it. For every story like mine, where this is just a temporary frustrating inconvenience, there’s probably a story where grandma lost her life savings after talking to the nice man from Microsoft on the phone. But also they don’t make it clear at all what you are supposed to do as non-criminal to work around their restrictions, which is just bad for customers. reply someplaceguy 6 hours agorootparent> So they want you to initiate a manual verification that you really do intend to move such a large sum to prevent that fraud.Yes, it&#x27;s hilarious.One of my banks requires me to do the transaction over the phone if it&#x27;s above a certain limit.At which point, you talk to someone in a call center, and they proceed to ask you exactly the same information which you needed to introduce in their web interface to make the wire transfer yourself, and nothing else.This includes giving your web interface credentials over the phone, which could be heard by someone inadvertently or even phished if you happened to have misdialed accidentally. Or stolen by the call center employee.It&#x27;s also great fun to have to spell out 20+ account digits, the names of the other people&#x2F;companies, phone numbers and email addresses to receive confirmations and even a description of the transaction (fortunately I don&#x27;t always buy sex toys).Gosh, how I love to spell out all this information, digit by digit, letter by letter, over a phone call! But since it&#x27;s for my protection it makes it OK, right? Right? Hello? reply patmcc 13 hours agorootparentprevNo, you&#x27;re expected to call and set up an appointment with a banker who can sell you on some kind of business account that has appropriate services for moving money in that way.And yes, this will cost more and take more time than the spreading-it-out method. reply alright2565 13 hours agorootparentno, this is too cynical. just give them a call, authenticate yourself, and they&#x27;ll happily raise the limit for you.maybe if you&#x27;re moving 50k&#x2F;week they&#x27;ll try and get you on a business account, but at that point you&#x27;re already not using the account for the purposed you claimed when you opened the account. reply sidewndr46 11 hours agorootparentprevworking around a restriction is called \"Structuring\" in the US:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Structuring reply dmurray 11 hours agorootparentThis is not true. Structuring is much more narrowly defined, including in that Wikipedia article. It requires you to be working around a legal or regulatory reporting requirement. reply xeckr 13 hours agorootparentprevBanks have an incentive to create as many roadblocks as possible to prevent you from transferring out large sums of money. reply cturner 3 hours agorootparentYou may be surprised at how difficult the regulators make life for the banks.Read this case-study from the UK. https:&#x2F;&#x2F;www.financial-ombudsman.org.uk&#x2F;decisions-case-studie...\"We thought the spending on Marta’s account was very unusual for her and – after the first few payments – the pattern of transfers from her account should have caused the bank some concern meaning that it ought to have intervened. We thought that if the bank had asked Marta about the transactions she would have told it what she was doing.\"Consider the implications of this.It gets worse, \"In deciding fair compensation, we also considered if would be fair for Marta to bear any additional responsibility for what happened. However, as we thought the trading platform and correspondence with the fraudsters was very convincing, we decided against that on the facts of this case. So we asked the bank to refund all the transactions which took place after the point we thought it should have intervened.\"This regulator does not respect the concept of personal responsibility.These problems are also downstream of systematic public policy failure. We have had telephones for about a century. Yet in 2023, it is still routine for pensioners to receive calls from organised fraudsters. There is no reliable way to trace the source of these calls, to block ranges of numbers, to prevent scam call centres, to issue pensioner-friendly forms of telephone with higher safeguards. These problems are not technically difficult to solve. All could be fixed if the telcos behaved responsibly. That work should have been done thirty or more years ago.Since that work was not done, there is now a fraud crisis. In response, regulators have forced controls to the last point possible, which is with the banks. Huge inefficiencies follow. reply astrange 8 hours agorootparentprevIf you&#x27;re the largest customer at a small bank they&#x27;ll be happy to see you move it out because that much money can make them nervous. reply xeckr 6 hours agorootparentUnless they&#x27;re so small that you taking out your money results in them experiencing liquidity issues. reply astrange 5 hours agorootparentThat&#x27;s the situation that makes them nervous. reply usefulcat 5 hours agorootparentprevIn which case they already have bigger problems. reply dan-robertson 11 hours agorootparentprevIn particular in the US, they are on the hook for almost all of it if the money was fraudulently moved out. reply xeckr 10 hours agorootparentThey&#x27;ll try to dissuade you even if they know the transaction is legitimate. reply darkwater 2 hours agorootparentprevDon&#x27;t know where you live but where I leave this thing is pretty common when you are buying some property. The goal in this case should be pretty obvious. reply slavboj 6 hours agorootparentprev\"But they don’t tell you what they actually want you to do if you want to move 200k\"They will tell you to use a wire transfer. reply hef19898 11 hours agorootparentprevThere are some systems, banking for example, where \"hacking\" them and trying to be smarter than others can, and actually does, backfire. reply nick222226 13 hours agorootparentprevYou do a wire transfer. reply opportune 12 hours agorootparentYes, my point is that banks don’t make it clear that maxing out their ACH quotas will get your account frozen and that you should do a wire transfer. You shouldn’t have to learn this the hard way by getting your account frozen (which is very stressful when it happens to you for the first time), and banks should make it clear what you should do, which is my point reply JohnFen 11 hours agorootparentWhenever I&#x27;ve been moving amounts at that scale, I&#x27;ve already had a close working relationship with my bank as a natural side-effect of my business activities. As a result, I&#x27;d be doing those sorts of transfers by talking to my account manager at the bank.I suspect that&#x27;s the norm that banks are expecting. reply ska 11 hours agorootparentprevIt&#x27;s a pretty niche problem though, so I guess not surprising they aren&#x27;t great about communicating it (it probably was communicated, on page 30 of your agreement in small confusing text). reply Scoundreller 10 hours agorootparentprobably not communicated. Banks usually don&#x27;t like to say: \"your account will totally get frozen if you do this thing up to the limit of what we said you&#x27;re allowed to do\".They like to keep the impression that account freezes are discretionary not automatic. reply nick222226 9 hours agorootparentprevOk with this context I understand what you are getting at. reply sib 8 hours agorootparentprevFor which they kindly charge you a fee reply leetcrew 8 hours agorootparentschwab doesn&#x27;t charge a fee to wire from a brokerage account. by the way, there&#x27;s no minimum balance or fees required to open an account with them. you pick up the phone, get connected with an intelligent person who understands exactly how to help you, and wire the money. usually you don&#x27;t even wait for an agent.I&#x27;m gonna sound like a shill, but 99% of the problems people are writing about in this thread would be solved by opening an account at schwab. unless you routinely deposit&#x2F;withdraw large amounts of cash, there&#x27;s no reason to waste time with other banks. reply quartz 13 hours agorootparentprevCouldn&#x27;t you just send a wire? reply opportune 13 hours agorootparentYes, but that involves talking to someone and waiting on hold. If there’s no rush, doing 4x ACH is easier, if you don’t know it’ll get you flagged. All I’m saying is banks need to be more prescriptive about telling you “we’ll put a hold on your account if you move large sums without telling us” rather than giving you some fake limit that actually utilizing will raise red flags. This is a common failure mode reply VBprogrammer 11 hours agorootparentI presume the argument some middle management type makes is that exposing their security protocols makes it trivial for a fraudster to work around. Obviously this is a fallacy because any genuine fraudsters has the incentive to work this all out by trial and error, if the information isn&#x27;t freely available to them on some dark corner of the internet. reply Kalium 10 hours agorootparentTrial and error takes time. Potentially a great deal of time. A motivated fraudster will likely get caught and stopped several times along the way if they&#x27;re attacking a particular bank.It&#x27;s worth bearing in mind that most financially motivated criminals are after easy marks. If you&#x27;re too hard or expensive to hit, they&#x27;ll find another target. If you&#x27;re seeing like a bank, that&#x27;s a victory and the protocols are doing their job by reducing fraud. reply callalex 12 hours agorootparentprevThose typically have huge fees. reply gosub100 11 hours agorootparent$25 to move $50k in an atomic, irreversible way isn&#x27;t a huge fee IMO. when you&#x27;re dealing with that amount of money, the risk of it getting frozen or flagged for fraud is > $25. A lot of banks will let you send wires for free if you have a large enough balance. reply ska 11 hours agorootparentprevNot int the context of these amounts.$20-ish to move 200k safely is nothing. If you are doing it internationally, it&#x27;s typically tiny compared to the FX cost. reply Scoundreller 11 hours agorootparentI’d be happier keeping the $25 tyvm. reply hef19898 11 hours agorootparentAnd risk getting your account frozen \"for no reason\", really smart. reply ska 11 hours agorootparentprevSure, write a personal check then and expect a lengthy hold. Or something else on the risk vs. PITA vs. cost framework.Point is, wires are cheap for what they do. They aren&#x27;t your only option, but all options have tradeoffs. reply Scoundreller 10 hours agorootparentThis is a debate between sending 4x ACHs over 4 days (presumably from the comfort of your own web browser) vs a wire (often requiring a visit or phone time). reply ska 10 hours agorootparentright, and the trade off there is you may get flagged for structuring and locked out, right?As I said, there is a range of cost&#x2F;risk&#x2F;PITA options available. This is niche enough I don&#x27;t think it&#x27;s particularly worrying the banks don&#x27;t support it easier. reply Scoundreller 10 hours agorootparentWhat structuring? Both are way over mandatory SAR thresholds. replystouset 13 hours agorootparentprevI&#x27;ve also heard repeatedly in conversation people frequently admit to structuring financial transactions for a variety of reasons, completely unaware that doing so is a felony. reply immibis 12 hours agorootparentIs it illegal to round up your transaction to $10,001 for the purpose of making the bank file the form so you can&#x27;t be accused of structuring to avoid it? reply creer 11 hours agorootparent(the problem with these ideas is that they make you responsible for knowing all these things - which ideally is what you pay the bank for.) reply xur17 10 hours agorootparentprevDoes the bank have a human look at &#x2F; file the form, or is it automatically generated? (Unless they are required to do it manually, I can&#x27;t imagine they do) reply PrimeMcFly 12 hours agorootparentprevlol, no. Why would it be? reply sicromoft 12 hours agorootparentprevIt’s only illegal if you’re intentionally doing it to avoid reporting reply stouset 11 hours agorootparentThey are intentionally doing it because of mostly imagined consequences of having the transactions be reported. And committing a felony as a consequence. reply teemur 12 hours agorootparentprevSorry, what does \"structuring financial transactions\" mean in this context? reply sidewndr46 11 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Structuring reply mminer237 14 hours agorootparentprevCTRs are required for $10,000+. Structuring is more like if you&#x27;re depositing $9,999, which is kind of the opposite of a round number. reply idontpost 13 hours agorootparentIt would also be two deposits of $5k or 10 $1k deposits, etc. reply acheong08 10 hours agorootparentprevAnecdote: I hade my Revolut account suspended for 24 hours for a reason they refused to disclose yet admitted as their mistake last week reply throwaway2037 8 hours agorootparentThe solution is simple: Stop \"banking\" with entities that don&#x27;t have a banking license. reply acheong08 8 hours agorootparentSometimes you don’t get a choice, especially when only just moving to a new country. reply mdekkers 8 hours agorootparentprevRevolut has a banking license, at least in Europe reply rendaw 6 hours agorootparentprevI&#x27;m ready to believe this, but IIRC on previous posts people accused the poster of doing shady things but I don&#x27;t remember seeing it ever coming out that they actually did. Do you have some links? reply ackbar03 6 hours agorootparentprev>but eventually it comes out that they’re in North Korea selling cannabis to Iran or something.I only do this on the occasional Wednesday though when things are quiet at work reply AmericanChopper 14 hours agorootparentprevThe only way to get any assurance about staying out of trouble with your bank is to have enough money that they start to not care so much about the risk of doing business with you, and to pay a lot of money to an expert to do the AML compliance for you. reply JohnFen 10 hours agorootparentThe other way is to communicate with the bank. Talk to them. If you&#x27;re doing something involving a larg",
    "originSummary": [
      "Patrick McKenzie criticizes banks for their operational inefficiencies due to a disorganized structure and ineffective communication between subsystems, leading to problems like account closures and credit card fraud.",
      "He points out how the tiered customer service system, intended to save banks' time and resources, often exacerbate customer frustration and inefficiencies. Additionally, he calls out certain legal obligations, like non-disclosed Suspicious Activity Reports, that can lead to abrupt account shutdowns and add confusion for customers.",
      "McKenzie suggests technological improvements could enhance banking operations and customer service, but acknowledges the time needed for its system-wide adoption. He also asks for a reassessment of some regulations generating unnecessary harm to customers."
    ],
    "commentSummary": [
      "Patrick McKenzie scrutinizes banks for operational inefficiencies resulting from poor communication and organization within subsystems, leading to issues like account closures and credit card fraud.",
      "He points towards banks' tiered customer service structure and certain confusing legal obligations such as non-disclosed Suspicious Activity Reports as part of the problem.",
      "McKenzie believes improved technology could enhance banks' operational competence and customer experiences, but acknowledges implementation throughout the financial system might be gradual. He also emphasizes the need to reconsider specific regulations that inflict unnecessary harm and confusion on customers."
    ],
    "points": 519,
    "commentCount": 373,
    "retryCount": 0,
    "time": 1699380475
  },
  {
    "id": 38180846,
    "title": "Enhancements in Northlight Technology to Boost Gaming Experience in Alan Wake 2",
    "originLink": "https://www.remedygames.com/article/how-northlight-makes-alan-wake-2-shine",
    "originBody": "News Careers 23 GamesNorthlight How Northlight makes Alan Wake 2 shine Northlight 6.11.2023 Showcasing new Northlight technology in Alan Wake 2 The Northlight team is super-excited to have Alan Wake 2 out there. We've created and polished off a lot of new tech so that Alan Wake 2 looks great and plays great. Here are the key highlights of the new features and tools that we'd like to give a moment in the spotlight. We're keeping the description to a fairly high level here; our engineers will be back with more in-depth topics in due course. Core engine: New data-oriented game object model Northlight switched to a completely new data-oriented game object framework during the development of Alan Wake 2. The new entity component system (ECS) based model enables memory-efficient storage and makes parallel execution efficient and safe. This means that the engine can support a varying number of target hardware cores efficiently, enabling bigger, more dynamic and fuller worlds. ECS also played a supporting role for our tools development, simplifying the building of the new Scattering tool for mass-authoring vegetation - ECS allowed us to simply have a lot more entities without the need to invent any custom solution for scattering objects in the world. The ECS framework also made it to our gameplay programmers' \"favorite tech\" list as it helped implement the Case Board - Saga's visual storyboard for gathering evidence. ECS meant that iteration was quick because adding new or modifying existing systems or game objects was easy, and performance gains were clear when saving and loading the Case Board. Voxel-Based Character Controller Alan Wake 2 called forth reimagining character control in Northlight. We built a new Voxel-Based Character Control that enables smooth navigation in cramped, complex and dynamic environments; it makes character movement more natural and fluid. Our marketing folks would say the characters are more responsive and lifelike than ever before; our internal dev notes described it as \"the characters won't bump or get stuck into objects in tight spaces\". Character path visualization showing predicted path (white) as the character tries to reach the movement target (yellow). Reworked NPC locomotion Our animation tech made some major changes into how Non-Player Characters (NPC) move. The revamped NPC locomotion means that in Alan Wake 2 all NPCs utilize animation-driven movement combined with new distance-based Motion Matching. This new tech improves movement quality and gives us more control over how and when animations are used. Realistic wind More realistic wind was on the must-have tech list for Alan Wake 2 - and that's we have, wind that realistically affects physics, particles, and cloth. For example, game designers can now easily define indoor and outdoor areas that have different wind speeds, with smooth, stateless transitions between the two types of areas. The indoor vs. outdoor area definitions are used, for example, to ensure that there's no wind inside the car that Saga and Casey are driving. This is done through defining a moving \"wind box\" that specifies that the inside of the car is a wind-free indoor area. Northlight Wind Debugger showing wind box that defines indoor vs. outdoor area. Block edge shows the transition. The wind system tech is built on Signed Distance Fields (SDF) methods where wind boxes are used as primitives that define a smooth, global wind strength field. The wind boxes act like basic building blocks that define how strong the wind is in different areas, creating realistic and smoothly varying wind patterns between indoor and outdoor areas. Scattering tool We developed a new Scattering tool to allow for mass-authoring vegetation and propping environments on a grand scale. In Alan Wake 2 it was used to create denser, richer and more life-like environments with the longer-than-before draw distances (i.e. what defines how far the player can see objects and details in the game world). Luau We switched our scripting language from a proprietary language into Luau, embeddable scripting language derived from Lua by our friends at Roblox. It exposes a comprehensive set of engine functionality and supports live-editing. Luau is used for level scripting and also for various gameplay systems such as the weapon upgrade system. Luau allowed the game team to prototype and implement various game features and VFX effects without needing help from engine programmers. We've also cooked up our own VS Code language server extension, so that it all integrates seamlessly into Remedy’s development pipelines. And adopting Luau helped us boot out some 80 000 lines of code we no longer need to maintain. VFX team used Luau to implement a weather system - The different weather conditions can be quickly tested through a debug panel. Graphics and rendering New GPU-driven rendering pipeline Alan Wake 2 showcases Northlight's brand-new GPU-driven rendering pipeline. It allows us to push more geometry into the world without sacrificing performance. With GPU-driven rendering using mesh shaders, we can now do occlusion culling down to a single-pixel precision and use everything in a scene as an occluder. This ability to only draw what is visible means that the world of AW2 has more geometric detail than we’ve ever shipped before. Diving a bit deeper into how it works: we also cull meshlets, in addition to the mesh. Meshlets are smaller, more optimized, groups of triangles extracted from the mesh. In the images below you can see what meshlets look like around Cauldron Lake's convenience store location. What the player sees... ...vs. what's fed into the renderer (silly amount of geometric detail!). Colors represent clusters. Character-style rigs on foliage - Large scale procedural GPU animation The expansive primordial forest environments of Alan Wake 2 are brought to life through our new shader-based vegetation system. It's based on a new skinning system that runs entirely on GPU and supports \"art-driven\" bone shader animations. In Alan Wake 2 it enabled us to use full character-style rigs on all the foliage visible in the environments. We're calling the new system art-driven here because the bone shaders expose an API with which artists can write their own shader code that hooks into the underlying system. So technically artists could use it to animate anything they'd like: foliage, objects bobbing up and down on water, power cables wobbling in the wind, etc. GPU bone visualization - The skeleton rigs animating all vegetation. Each line is one bone, with almost 300,000 bones in Cauldron Lake being processed every frame. GPU bone visualization OFF GPU bone visualization ON HDR support Alan Wake 2 fully supports HDR. We've made sure that the game looks great out-of-the-box with default settings, regardless of whether your display supports SDR or HDR. On the tech side, adding HDR support could almost be said to have been a simple 'let's change the output format' operation; the more significant effort was done on the creative side. Alan Wake 2 is authored in HDR, meaning that the color grading was done by actual human colorists to ensure that the unique art styles and aesthetics, the storytelling and mood of Alan Wake 2 is amplified in both HDR and SDR. Transparency and atmospheric effects The pervasive fog scenes in Alan Wake 2 are built upon improvements into how we render transparency. We're using MBOIT (Moment-Based Order-Independent Transparency) to make see-through surfaces blend together smoothly, even when they have different levels of detail. During Alan Wake 2's development, Northlight did a complete overhaul of transparent rendering. We now draw transparency in three resolutions with MBOIT, which makes it possible to blend fog, transparent geometry and effects seamlessly. In addition to better blending of fog and other transparent elements, we’ve improved pipelines to allow more fine-grained control over fog placement in the world. Combining all this to per-pixel transparent lighting and fog-affected reflections makes opaque and transparent elements fit together better than in our previous projects. Our fog also approximates multiple light scattering, giving it a thick and realistic look that improves atmosphere. Note how the water refracts correctly and supports non-uniform blur for realistic looking water. Transparent Rendering - A perfect blend of different transparent effects: fog, particles and water all use MBOIT. VFX Effects are an essential part of Alan Wake 2’s visuals and expand on what we achieved in Control. The node-based VFX tools in Northlight have evolved significantly in terms of supported features and runtime performance. Visual effects artists are now able to author complex and dynamic effects like rain, wetness, water simulation, and character wounds. VFX tools also benefit from GPU-driven rendering and can push a lot of geometry through the GPU. This is required, for example, when rendering rain blocker objects to a dynamic mask that prevents rain from appearing indoors or under cover. Screenshot of Dark Place with visual effects OFF. Screenshot of Dark Place with visual effects ON. 'Fade Out' enemies and weather effects are key parts of the visual identity Ray tracing We have added support for fully ray-traced direct lighting and combined this with improved denoising and indirect lighting algorithms with Nvidia. Ray tracing in Alan Wake 2 is more accurate and robust than what has been seen in Control. Ray tracing also makes the animated foliage look amazing, now that all the geometry animation (foliage) is authored and simulated using skinning. With Alan Wake 2, PC players can experience (GPU and CPU setup permitting) the latest Nvidia DLSS innovations - DLSS Frame Generation, DLSS Ray Reconstruction, Path Traced Indirect Lighting - all the things that enable us to say 'never before' once more. Related articles All news All news Developing Northlight: OpenUSD content workflows Northlight in 2023 About game engines Join us All open positions All open positions Technology 9 Art & animation 7 Project management 2 Design 2 Other 3 Games Northlight Career Studio News Contact Playtest Community Store Investors Instagram YouTube Vimeo Facebook Twitter LinkedIn Copyright 2023 Remedy. Terms & Conditions Privacy Policy Cookie Settings",
    "commentLink": "https://news.ycombinator.com/item?id=38180846",
    "commentBody": "Northlight technology in Alan Wake 2Hacker NewspastloginNorthlight technology in Alan Wake 2 (remedygames.com) 398 points by vblanco 15 hours ago| hidepastfavorite198 comments SirMaster 13 hours agoIn the first example it&#x27;s still really jarring how much their feet slide around on the ground, or sliding in place as they walk into an object without moving. I wonder when this will ever be solved.Don&#x27;t get me wrong, the engine is incredible and the visuals and systems are some of the best we have seen. reply ux-app 11 hours agoparentIt&#x27;s always a tradeoff between responsive movement and realistic movement. RDR2 has very realistic animations, with the tradeoff being slightly \"floaty\" controls.Personally I prefer snappy movement i.e. when I press left the screen character moves left immediately. A more realistic looking animation system introduces a delay while you wait for the feet animation to \"catch up\" to player input. reply jordanthoms 11 hours agorootparentI guess the problem there is pretty fundamental - in reality you&#x27;d be tensing muscles and shifting your weight etc before the snappy movement, but the game only knows that you want to move when you move the stick or push a button - so it either has to show that realistic motion after your button press and introduce latency, or sacrifice the realism in the animations. reply lukeholder 9 hours agorootparentCorrect, this is an issue in nba2k but it’s become a fundamental part of the game. As they made movements more realistic they introduced a delay. So when you try and get around you opponent you direct half a second before you move, but your defender also has to move their player - not in reaction to the screen but also in anticipation of your move in order to defend you. I actually think this is more like real life which makes the game better, but a lot less frantic than basketball arcade games of the past. reply josephg 5 hours agorootparentGuild wars 2 does something similar. When you’re running around on your own, the game responds instantly. But all of the in-game mounts take a moment to react to your steering. Responsiveness, jump height, horizontal speed and turning radiuses all differ massively depending on the mount you’re using. As a result, long distance navigation is a complex puzzle requiring you to choose a good mount and a good route at the right time and manage your energy bars and cooldowns. Do you try to hop up this ledge with the griffin you’re already on, or take the time to swap to the springer and clear it in a big charged bounce? Was there a better way around this ledge? It’s shockingly fun. reply mitthrowaway2 3 hours agorootparentprevThis is also why 2D jump platformers like Megaman have triangular jump trajectories instead of parabolic trajectories. For snappy controls you leave the ground at the instant of the downpress and peak when you let go of the button. As the game can&#x27;t know how high you intended to jump at the time the jump begins, the trajectory can&#x27;t be parabolic. (At least, not on the way up.)You could instead have the button downpress \"charge up\" energy and then begin the jump when the button press ends, which would allow for more realism, but also introduce a delay. reply ux-app 10 hours agorootparentprev>I guess the problem there is pretty fundamentalyes absolutely, you can&#x27;t have both realism and snappy response times. reply _kulang 10 hours agorootparentConsidering you walk around and don’t have a problem with it, I’d wager that putting a more realistic walk model into a game and changing the control scheme to be a bit more natural would lead to a learnable system for control that would achieve both goals. Say ZMP reply itishappy 10 hours agorootparent> Considering you walk around and don’t have a problem with it...I think humans are worse than this than you might think. Give it a try! Walk around and try to change directions on the fly, maybe have a friend shout suggestions to you. I can make maybe 2 or 3 adjustments per second, which gives about 400ms response time. That&#x27;s about where RDR2 sits, and players criticized it for being unresponsive. reply JohnBooty 9 hours agorootparentTangential but a lot of sports drills are along these lines.A great tennis drill is when your coach hits the ball to you and randomly yells \"LEFT!\" \"RIGHT!\" or \"MIDDLE!\" after you&#x27;ve begun your swing. Then you have to hit the ball in that direction. Helps hone your reaction time and helps you to have a \"neutral\" swing that doesn&#x27;t telegraph your intentions to an opponent.One can imagine variations in many sports. reply Aeolun 6 hours agorootparentprevBut if you take 400ms to respond, and the game takes 400ms to respond after that, the actual response delay is 800ms, which is quite a lot. reply hoseja 2 hours agorootparentLikely not solvable until we have a BCI working. reply notjoemama 10 hours agorootparentprevI played RDR2 and was very happy to walk away from the molasses like movement once finished. It was realistic in both its behavior and cadence and I can emphatically say, give me fantasy (better&#x2F;faster) movement in a playable fantasy world. Imagine waiting for a real time washer and dryer cycle in a video game because it’s “realism”. There are limits… reply simbolit 9 hours agorootparentprevHave you played \"Death Stranding\"?There you &#x27;actively&#x27; walk and &#x27;manually&#x27; keep balance. It&#x27;s an interesting experience, but it makes walking a conscious act, it becomes something you do.Arguably that is less realistic than just moving an analog stick, for most people walking is just telling your body to move in direction x. reply beenBoutIT 1 hour agorootparentAmazing game. Goes in the rare category of truly singular games that have no peer. Manhunt(PS2 version) is another. reply firecall 9 hours agorootparentprevOf course there is already measurable lag from when your brain tells your hand and fingers to move, to when they actually move!An interesting personal anecdote I have:I damaged my back with bulging disc, which caused horrific sciatica nerve pain.When I was able to walk again, I had some nerve damage.This meant I had lag in my left leg!I’d tell the leg to move instinctively when walking and there would be a delay. The entire walking movement of the leg was present, but just with a noticeable lag!It was weird!Eventually it healed fully, or I adjusted. Not sure which! :-) reply GreymanTheGrey 7 hours agorootparentComplete tangent, but how did you treat your injury? Coming back from bulging discs and sciatica is rare, to my understanding. reply askonomm 6 hours agorootparentYeah a friend of mine had this and he had to get surgery to not lose his left leg to permanent numbness due to the disc pressing on the nerves. I know one other person with the exact same issue and solution, and am also under the impression that without surgery only bad things happen. reply ncallaway 9 hours agorootparentprev> Considering you walk around and don’t have a problem with itYour brain is hiding a lot from you. reply 4hg4ufxhy 10 hours agorootparentprevIt would still feel unresponsive in comparison. Just like normal physics would feel if you got a taste of breaking them in real life. reply ux-app 10 hours agorootparentprev>changing the control schemeControllers use analog input for the sticks. I guess you could create a system which uses a dead zone where the player \"signals\" their intention by partially moving the stick in their desired direction.This would be incredibly cumbersome though, and the payoff would not be worth it. reply Arrath 8 hours agorootparentprevFull body control input it is!Like those arcade shooters where you duck and lean to dodge bullets, or a full fledged whole-body VR setup on an infinite omni-directional treadmill. reply kylebenzle 10 hours agorootparentprevI can&#x27;t see how zero moment point (ZMP) is relevant here? I think what you are saying is why don&#x27;t we use the same algorithms to control game characters as robots? If its a robot or game character the issue is the same. You can try and predict the next movement but if you are wrong you again have the same problem and the response time suffers even more.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Zero_moment_point reply thomastjeffery 7 hours agorootparentprevTo elaborate on this, there is a third aspect being glossed over: the correctness of the animation itself.They could alter the animation such that feet don&#x27;t slide across the ground and keep responsive movement. The result would be a worse quality animation, because the movement of the legs would not appear to be pushing the rest of the body around. Instead, it would look more like the feet are following the rest of the body retroactively, while holding onto the ground.A good example of this is Factorio&#x27;s spidertron. When the spidertron moves, the legs follow with a walking motion that perfectly tracks the ground below. In this case, it&#x27;s a great-looking tradeoff, probably because there are so many legs, and not much animation done to the body itself. reply larschdk 35 minutes agorootparentprevI think there is also a difference between realistic and believable. The original Half-Life had IMHO more believable leg&#x2F;feet movement. In HL, the feet were much more \"stuck to the ground\" compared to most modern games where they just slide around.It appears much more believable to me than the character pathing demo, where the character moonwalks 1&#x2F;2 the time. The entire pedal structure is extremely stiff compared to how humans move (feet, thigh and torso can all turn nearly 90 degrees, but they hardly turn at all in the demo). The other demos are better, but their bodies still appear stiff, like they are suffering from hernia. reply darzu 10 hours agorootparentprevI’ve always preferred the Wolfire approach[0]: animation should “do no harm” to player control, it’s only there to add flavor, never at the cost of game responsivity[0] https:&#x2F;&#x2F;youtu.be&#x2F;LNidsMesxSE?si=W7xnQfXt5ulfHklR reply ordinaryradical 6 hours agorootparentHis proposition of a Hippocratic oath for animation is a beautiful and succinct way to frame a game design thesis. Great talk. reply iamcreasy 9 hours agorootparentprev> Personally I prefer snappy movementI do too, but also think it greatly depends on the game. For example, Hollow Knight designed to have snappy response to player input from the start and I loved it. In RDR2, I find the floaty behaviour adds another layer of realism. reply dagmx 2 hours agoparentprevIt’s a solved problem already. Various IK systems will tackle it properly and some games will have your feet IK follow the terrain and hands IK push up against surfaces.However it’s a trade off of performance (the constant ray casting and IK solves aren’t free) but also responsiveness.Many games opt for faster locomotion and responsiveness instead.At the end of the day, it’s a technically solved issue and has been for years, but as with every single thing in game design, it’s a choice and trade off. reply modeless 2 hours agorootparentIK doesn&#x27;t \"solve\" the core problem of realistic character motion. Sure you can tweak foot positions to stop them from sliding but the farther they get from the original animation data the worse the result will look. It&#x27;s no panacea.There are new approaches to generating realistic character motion being shown at SIGGRAPH every year, getting better and better, but the best ones are largely too expensive for games to adopt. Plus, for player-controlled characters, at a certain point you run into a fundamental tension between control responsiveness and physical realism of animations.I recently saw a great article on the topic which even comes with a WebGL demo: https:&#x2F;&#x2F;theorangeduck.com&#x2F;page&#x2F;code-vs-data-driven-displacem... reply dagmx 1 hour agorootparentIMHO IK provides enough to counter the issues the person I was replying to was mentioning.Now of course you can go above and beyond that for more realistic motion and , but having worked in the space, I would Serguei that is also solved without requiring recent research. Most recent motion research is about novel motion generation but the general problem of dynamic adjustment to authored animation has been solved by several systems already. But just like my original comment, there’s both a development and runtime cost to all of this. reply wilg 9 hours agoparentprevAlan Wake II actually does have the best approach to this animation issue that I am aware of – motion matching, which is mentioned in the blog post. Used by Naughty Dog and many others. But as the other comments point out, there is still a fundamental tension between responsiveness and animation accuracy. reply 015a 6 hours agoparentprevProbably a pretty critical aspect; typically, the camera is angled in a way where you do not see your character&#x27;s feet [1]. This was less true in Northlight&#x27;s previous title, Control [2].[1] https:&#x2F;&#x2F;youtu.be&#x2F;jQb07FHJ-bQ?t=628[2] https:&#x2F;&#x2F;youtu.be&#x2F;fcDK6tnx4vM?t=6700 reply Tade0 13 hours agoparentprevI&#x27;ve seen a demonstration of a solution on the YouTube channel Two Minute Papers - it was actually about an algorithm that blended animations so that the transitions looked natural. reply wilg 9 hours agorootparentI think you may be referring to motion matching, which this game uses and is discussed briefly in the article. reply jay_kyburz 12 hours agorootparentprevI wonder how long it will be before we stop using animation and switch to an actual bipedal physics simulation where the agent actually knows how to walk and jump and run. reply Keyframe 11 hours agorootparentWe were there over a decade ago with Euphoria, but I think they&#x27;ve stopped selling&#x2F;developing it? GTA 4 used it. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HauN98naZ9U reply ajdoingnothing 9 hours agorootparentGTA IV&#x27;s tech was quite ahead of its time (2008), with the integration of Euphoria (which had to be integrated in-house by NaturalMotion engineers inside Rockstar&#x27;s studio @ Edinburgh). The other comment correctly pointed out that NaturalMotion was acquired by Zynga, who in turn got acquired by Take-Two (parent of Rockstar Games).. So who knows, perhaps we&#x27;ll still see an updated version in the sixth major instalment of the franchise. reply midnightclubbed 7 hours agorootparentEuphoria was used for a subset of animations, for the most part traditional mocapped animations (and a lot of them) were used to drive character movements. I don’t know if motion matching was used on GTA4 but it was on other Rockstar games at the time and subsequently.Characters blended to the hand written, custom, euphoria behaviors in certain situations… it handled falls, stumbles, deaths, etc. Generally it replaced ragdoll physics but wasn’t used during most character movement behaviors. reply ingenieros 10 hours agorootparentprevThey were acquihired by Zynga of all companies which then promptly proceeded to kill off all their products. reply dymk 10 hours agorootparentprevThe keywords you&#x27;re looking for are \"procedural animation\" and \"inverse kinematics\" - Overgrowth was doing this in 2009.The developer did a presentation at GDC 2014 on it: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=LNidsMesxSE reply ekianjo 10 hours agorootparentprevIt seems like never because we had the tech before and everyone seems to be lazy about using it reply ReactiveJelly 12 hours agoparentprevI&#x27;m surprised it&#x27;s still a problem. Years ago a basketball game franchise bragged that the PS3 allowed them to do foot planting with inverse kinematics. Years before that, Shadow of the Colossus shipped on PS2... with IK foot planting. reply fulafel 3 hours agorootparentConflicting requirements stemming from the psychological illusion of movement spontaniety.People don&#x27;t want the realistic, slow response. Normally people aren&#x27;t aware of how early their body starts a movement, the conscious brain has the illusion of just having decided it but it&#x27;s actually started much earlier. reply Cthulhu_ 13 minutes agorootparent> People don&#x27;t want the realistic, slow response.That&#x27;s it, there&#x27;s the tradeoff; if they want legs to move naturally, they have to fight against what the user inputs. There&#x27;s a setting in the Witcher 3 so that the character can turn on a dime &#x2F; instantly, less realistic but more fun &#x2F; responsive: https:&#x2F;&#x2F;www.escapistmagazine.com&#x2F;difference-between-standard... reply kylebenzle 10 hours agorootparentprevInverse kinematics is used but, again, that does not solve the problem of the trade off between response time and realistic movement. It simply \"snaps\" the feet to the ground. reply alpaca128 9 hours agorootparentA lot of the problems occur during movement, when responsiveness doesn&#x27;t even matter. I still have yet to see a game where it&#x27;s impossible to get randomly stuck at a fence or rock that instantly stops one&#x27;s movement for example. Making the character dynamically avoid such minor obstacles would make the game more responsive, not less.And games with fancy animations are often not just less responsive, but also less controllable in general: in Witcher 3 the character cannot walk backwards or turn in place, so you can literally fall off a cliff in front of you by trying to walk away from it. In terms of movement the only difference between Geralt and his horse is the turning radius. reply kylebenzle 7 hours agorootparentI don&#x27;t play any video games but it seems like you might be discussing a separate issue. A developer must choose between responsiveness and fluidity. replyholoduke 14 hours agoprevIts refreshing to see something different than another unreal engine based game. It must be extremely challenging to have your own inhouse engine. The engine is one thing. The tooling to build levels, animations etc is maybe even harder. I guess it also gives some advantages. More control over low level architecture gives you more opportunities to optimize. Harder with a all purpose engine like Unreal. Cant wait to play this game. reply dundarious 11 hours agoparentThe continued legacy of demoscene. reply jamesfinlayson 4 hours agoparentprev> It must be extremely challenging to have your own inhouse engine.Agreed - there are so many off-the-shelf engines with big communities that you&#x27;d really have to need full control to do it yourself. reply soulbadguy 1 hour agoprevI find it interesting that they switch to using lualu from roblock as the scripting environment.I am always curious why so many games techs use Lua for scripting. Especially when designed from scratch reply softfalcon 1 hour agoparentIt’s pretty much free to integrate Lua into a game at this point. Anything that can consume a C runtime can embed Lua scripting into itself.As such, we’ve been seeing it as a go to scripting environment for everything from Baldur’s Gate 1, to Warcraft III, to modern titles like Roblox. reply maccard 1 hour agoparentprev> am always curious why so many games techs use Lua for scripting.It&#x27;s fast (relative to other scripting languages), familiar, and stupidly easy to embed in a C++ program. reply kaetemi 1 hour agoparentprevNo additional dependencies, full control over what libraries get included, and no insane folder structure requirement. reply simbolit 14 hours agoprevLove the tone of the article.Example:Our marketing folks would say the characters are more responsive and lifelike than ever before; our internal dev notes described it as \"the characters won&#x27;t bump or get stuck into objects in tight spaces\". reply wilg 14 hours agoparentThe perennial problem with marketing language seems to be that everything needs to be reworded to \"make sense\" to someone who doesn&#x27;t know anything about the actual product that is being marketed. reply mpalmer 14 hours agorootparentNot nearly as big a problem as the positive spin they feel compelled put on everything. When everything sounds like a win, nothing does. reply Nition 8 hours agorootparentAlways funny how Product 1 will be perfect, but when Product 2 comes out, Product 1 suddenly has obvious flaws which Product 2 corrects. reply aydio 13 hours agorootparentprev“Winflation”? reply Smoosh 13 hours agorootparentHype~r~inflation reply m463 3 hours agorootparentprevirl: small cramped houserealtor: cozy charmer! reply drstewart 4 hours agorootparentprevIs the product marketed here a video game or a video game engine? Why do you expect every video game player to understand graphics programming? reply h4ch1 3 hours agorootparentI don&#x27;t see a harm in learning at least minor terminology to better bridge the communication gap between developers and consumers. reply rickstanley 13 hours agoprevI would love to know how they feel today about using D in their ecosystem, that is, if they still are, and see what challenges they have faced during AW2 development.For reference:- Using an Emerging Language in Quantum Break (https:&#x2F;&#x2F;ubm-twvideo01.s3.amazonaws.com&#x2F;o1&#x2F;vault&#x2F;gdceurope201... );- DConf 2016: Quantum Break: AAA Gaming With Some D Code -- Ethan Watson (https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7YjLW7anNfc). reply ferbivore 11 hours agoparentI don&#x27;t think it was ever officially confirmed, but word is they excised all the D from their codebase after Quantum Break. They&#x27;re certainly not looking for D programmers now.Possible starting point if you want to dig for sources: https:&#x2F;&#x2F;forum.dlang.org&#x2F;post&#x2F;lymybpygzfalbdgoaizr@forum.dlan... reply daemin 42 minutes agoparentprevAs with many things at games studios using a different language (or unique technology) is usually driven by a single person. Once they leave or move out of the place where they could contribute and maintain it, unless it has support and buy in from the rest of the team and studio, it starts to gets replaced.From the grapevine I heard there was one person that advocated for writing in D, though I&#x27;m not sure if they are still there or not any more. reply dom96 11 hours agoparentprevSame. My guess is that they no longer use D, seeing as the person doing those talks no longer works there and other big places like Facebook have ceased using it. But I&#x27;d love to be proven wrong! reply spookie 12 hours agoparentprevSame, would love to know more about it! reply jebarker 7 hours agoprevI always think glimpses of the custom tools used in game dev are really cool. I work in large scale ML systems and I wish there was similar effort put into tools for observability and debugging of neural networks.I&#x27;d be tempted to work on game dev tooling one day if there were more remote work opportunities. reply lukasb 3 hours agoparentIsn&#x27;t that https:&#x2F;&#x2F;wandb.ai&#x2F; ? reply sa-code 2 hours agorootparentHow is WanDB different from postgres? reply ugh123 4 hours agoparentprev>I wish there was similar effort put into tools for observability and debugging of neural networks.So do it. Then show it to your team and boss then boss&#x27;s boss. reply spywaregorilla 13 hours agoprevthe team behind some of the best content on the unreal marketplace did work on this game iirc.https:&#x2F;&#x2F;mawiunited.com&#x2F;Wonderful content. I hope we see more shops like this building content for ue5 reply Archelaos 13 hours agoprevSomehow the movement of the characters feels still quite uncanny to me. In the video about the \"voxel-based character controller\" the walking looks more like gliding. And in the first few second in \"NPC locomotion\" the walking just does not seem right. I think it is the fact that each step looks exactly the same and everyone uses the same step size. So the character are awkwardly tightly coordinated. One can see more variety later in the video, when the characters change individually between walking and running. That looks much more realistic. -- I wonder what makes it so difficult to generally achieve more variety in the movement details. reply ljm 12 hours agoparentA lot of it becomes un-noticeable when you’re in the middle of the action. You’re too busy looking at other things.Although to support your point, pretty much every friendly NPC is stationary. Once the hostile zone in on you you’re not looking at how they walk - they’re shrouded in mist anyway.IMO control was a tech demo for all of this and it also supports why the enemy count is much lower and framed as a horror story. reply m463 3 hours agoparentprevI wonder if someday there will be a walkgpt with normal or zombie modes. reply kevingadd 14 hours agoprevConsidering their size (a few hundred people for the whole studio AFAIK), Remedy consistently punches above their weight when it comes to graphics. Off the top of my head only Remedy and CD Projekt Red are able to compete with the big dogs (Unreal, Unity, EA Frostbite) when it comes to image fidelity and performance. Their GDC&#x2F;siggraph&#x2F;etc presentations are fantastic for anyone interested in computer graphics or technical art.Alan Wake 2 is easily one of the most beautiful (from a technical perspective - IMO also from an artistic one but that&#x27;s a 100% subjective thing) games ever released and it still looks good even when you turn all the settings down, which is a true achievement. It&#x27;s hard to make a game scale down to older hardware while still looking good.Though as commentators like Digital Foundry have noted, the game runs really badly if your GPU doesn&#x27;t support Mesh Shaders (they mention the use of those for culling in the article). Mesh Shaders in this case enable a lot of really smart culling and dynamic level of detail so that things like coffee cups or tires can be perfectly round without having the &#x27;every NPC has 10k-poly teeth in their mouth&#x27; problem that&#x27;s currently sabotaging Cities Skylines 2&#x27;s performance, and this is one of the big advantages offered by Unreal 5&#x27;s Nanite. reply Centigonal 13 hours agoparentRemedy was started by Demoscene hackers, including a bunch of Future Crew folks.You can draw a pretty clean line from the incredible Second Reality demo[1] in 1993 to Alan Wake 2 thirty years later.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iw17c70uJes reply pixelpoet 11 hours agorootparentNot to mention crucial middleware like Umbra visibility, the development of Nvidia&#x27;s RTX, an AI revolution or two, ...As I&#x27;ve commented before on HN, honestly I could write a small book about these Finnish demoscene gods. reply pjbeam 11 hours agorootparentIf you do please advertise it on HN. I&#x27;ll buy a copy. reply dharma1 11 hours agorootparentprevyou should! reply capableweb 14 hours agoparentprev> without having the &#x27;every NPC has 10k-poly teeth in their mouth&#x27; problem that&#x27;s currently sabotaging Cities Skylines 2&#x27;s performanceSad to see an otherwise good comment end with a misconception. The problems with the performance is much grander than just \"teeth rendered but not visible\" (https:&#x2F;&#x2F;blog.paavo.me&#x2F;cities-skylines-2-performance&#x2F;), although I guess it&#x27;s a illustrative point. Missing LODs and lack of culling are the grander issues. reply Sharlin 12 hours agorootparent\"Teeth rendered but not visible\" is just saying \"missing lods and lack of culling\" in a rhetorically more effective way. I don&#x27;t think anybody thinks it&#x27;s the teeth specifically causing the perf issues, they&#x27;re merely a concrete example. reply lloeki 13 hours agorootparentprev> Missing LODs and lack of cullingThat is the exact start of the sentence of which you quoted the end of:> Mesh Shaders in this case enable a lot of really smart culling and dynamic level of detail reply dymk 9 hours agorootparentprevThe article you linked specifically points out how expensive and unoptimized the teeth are. I&#x27;m not sure why you linked it, if it undermines the point you&#x27;re trying to make? reply sundvor 8 hours agorootparentprevThis article was just discussed here, might be a better link?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38153573 reply dharma1 14 hours agoparentprevSome extremely good GPU devs in Finland, demoscene prob has a lot to do with it. Remedy rocks.Isn’t CD Projekt Red moving to UE5 for future titles? Shame, Cyberpunk was gorgeous - would have loved a multiplayer game with that engine. reply rstat1 12 hours agorootparentOnly for the next Witcher series. Cyberpunk 2 (w&#x2F;e it ends up being called) is still on their in house engine.(Don&#x27;t ask me for a source, I don&#x27;t remember where I saw that info) reply justinclift 12 hours agorootparent> Cyberpunk 2 (w&#x2F;e it ends up being called) is still on their in house engine.How sure of that are you?There are several reports that the sequel to Cyberpunk 2077 will be using UE5 as well.As in, CD Projekt Red have purposely switched all future projects to UE5.* https:&#x2F;&#x2F;screenrant.com&#x2F;cyberpunk-2077-phantom-liberty-dlc-la...* https:&#x2F;&#x2F;kotaku.com&#x2F;cyberpunk-2077-phantom-liberty-expansion-... reply daemin 39 minutes agorootparentI can confirm that all future games at CD Projekt RED will be using Unreal Engine.Unless of course something changes during the development of the next Witcher game and they decide to go back to RED Engine. reply rstat1 12 hours agorootparentprevOk then they changed it. At one point it was still on the in house engine. reply justinclift 12 hours agorootparentNo worries. :) reply capableweb 14 hours agorootparentprevFunnily enough, both Colossal Order (Cities: Skylines 2 devs) and Remedy are Finnish companies, yet only one suffers from GPU performance issues. reply dharma1 14 hours agorootparentOne is a small company developing a city builder in Unity, the other are ex demoscene GPU gods building a custom state-of-the-art engine themselves. Nuff said! reply spywaregorilla 13 hours agorootparentprev> would have loved a multiplayer game with that engine.this strikes me as an extremely silly statement. Their engine doesn&#x27;t seem to have multiplayer. reply xu_ituairo 13 hours agorootparentYour reply would have been a lot nicer without the first sentence reply spywaregorilla 12 hours agorootparentthat&#x27;s ok reply dharma1 13 hours agorootparentprevREDengine doesn’t do multiplayer at the moment, but it could in the future if they kept developing it &#x2F; more games with it. I’m sure they’ll make great games with Unreal too reply simbolit 14 hours agoparentprevRemedy has 360 employees.CDPR has 1236 employees.DICE (makers of Frostbite) has 714 employees.Epic has 2200 employees (before the recent layoffs).all numbers from Wikipedia. reply jguegant 12 hours agorootparentFrostbite is its own sub-company within the E.A umbrella. While Frostbite is used by the titles from DICE and we share parts of our offices, the two companies are rrally distinct for a couple of years now.Frostbite had roughly 300 employees when I joined 2 years ago. reply simbolit 11 hours agorootparentThanks for correcting me, I am just an idiot with a Wikipedia addiction. reply treprinum 14 hours agoparentprevRemedy are basically Future Crew famous for Unreal&#x2F;Second Reality (demo). Who else should push GPU to its limits than the ones who defined&#x2F;popularized modern computer graphics? reply Centigonal 13 hours agorootparentIf you haven&#x27;t seen Second Reality, it&#x27;s definitely worth a watch, even as a historical artifact. Pushing the limits of what was possible in 1993.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rFv7mHTf0nA reply Flow 13 hours agorootparentHere&#x27;s a 60fps video of the same demo. The demo-sceners work really hard to make everything 60fps(1 vbl), so watching it in any other frame-rate feels wrong.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iw17c70uJes reply phs2501 11 hours agorootparentNitpicky: for a lot of parts that would have actually been 70Hz (from the 320x200 VGA mode 13h), and having run the demo back in 1993 it definitely was not as smooth as in the video above on my 486&#x2F;66MHz (and the Pentium had only been out for a few months at the time). reply Cu3PO42 13 hours agoparentprevInsomniac Games (Spider-Man (2), Ratchet&Clank: Rift Apart) and Guerilla Games (Horizon Forbidden West) also both have amazing looking engines. reply jdance 2 hours agorootparentFrom Software (souls games)Rockstar with the GTA seriesValve, Blizzard? reply imbnwa 11 hours agorootparentprevAlso Naughty Dog reply Sharlin 12 hours agoparentprevYou don&#x27;t exactly need Mesh Shaders or any other state-of-the-art techniques to cull 99% of C:S2&#x27;s polys. Just some simple stuff that games have done since the 90s. reply boppo1 14 hours agoparentprev>Alan Wake 2 is easily one of the most beautiful (from a technical perspective - IMO also from an artistic one but that&#x27;s a 100% subjective thing) games ever releasedI just don&#x27;t see it. Looks like RE2make to me. And as far as art direction Dishonored 2&#x2F;DOTO are dramatically better looking reply stuckinhell 13 hours agorootparentCapcom&#x27;s engine is extremely impressive especially the fact it can handle extremely beautiful triple AAA games then they can also go around and port old nintendo DS games as well. reply wilg 14 hours agorootparentprevI see it! reply katbyte 14 hours agoparentprevShame I won’t be able to play it as it’s only on the epic game store, which I refuse to use reply kevingadd 14 hours agorootparentThe console versions are quite good reply squidsoup 14 hours agorootparentI usually can&#x27;t stand playing anything at 30fps, but the combat and pacing are deliberately slow in Alan Wake II, and I&#x27;ve been surprised how little it has bothered me (quality mode on PS5). reply eddythompson80 14 hours agorootparentprevwhy? reply p1necone 14 hours agorootparentNot OP, but after getting used to Steam and GOG I don&#x27;t really want to use anything that doesn&#x27;t have text reviews. reply eddythompson80 13 hours agorootparentThat&#x27;s fair, as it&#x27;s your preference. It&#x27;s my preference too to use steam just because it&#x27;s where I have the most games and I like keeping things tidy and in 1 place. Though it&#x27;s not an ideological stance, which \"refuse\" leads me to believe. I&#x27;m genuinely curious about the reason an adult would take that position. Last time I asked (a couple of years ago) on Reddit I didn&#x27;t get, ummm, mature responses.If there is a game I&#x27;m interested in, I&#x27;d use whatever is cheaper&#x2F;available for it. reply rstat1 12 hours agorootparentMy reason for refusing to give the Epic store money is pretty simple: Paid exclusives are bullshit. Especially when they&#x27;re used as fodder to promote \"competition\", when such things are anything but. reply ThatPlayer 10 hours agorootparentThe FTC would disagree with you. Generally exclusives improve competition unless it&#x27;s a monopolist doing it. Which is not Epic in this case.https:&#x2F;&#x2F;www.ftc.gov&#x2F;advice-guidance&#x2F;competition-guidance&#x2F;gui...As long as storefronts have to compete for games, this is what that looks like. There&#x27;s not really any way to get rid of exclusives without hurting competition. Would you want a law passed for games to be required to be put on certain storefronts? For storefronts to be required to accept all games submitted to it? Either one would hurt competition by giving too much power to either the game publisher or the storefront. reply rstat1 9 hours agorootparentNo I think what I want is pretty obvious. No exclusives. I don&#x27;t honestly care what shitty storefront something is on, as long as its not limited to one. That&#x27;s literally my only gripe.Besides publishers are already free to decide where the games they publish go or don&#x27;t, so I&#x27;m not sure where the \"too much power to publishers\" thing is coming from. reply ThatPlayer 9 hours agorootparent>I don&#x27;t honestly care what shitty storefront something is on, as long as its not limited to one.But that&#x27;s not unique to paid exclusives. That&#x27;s not even unique to Epic, Valve&#x27;s own games are exclusive to a single storefront. You should boycott them for the same reason.There is a cost to releasing games on multiple storefronts, forcing games to release on multiple stores only hurts smaller developers. Some smaller developers also skip storefronts altogether. Minecraft and Factorio were initially sold without any storefront. Is that still considered limited to one and therefore an exclusive?>Besides publishers are already free to decide where the games they publish go or don&#x27;t, so I&#x27;m not sure where the \"too much power to publishers\" thing is coming from.I&#x27;m talking about cases where the storefront doesn&#x27;t want to sell the game. Say the game has adult content, or the game has is just unfinished and not good. If storefronts are required to carry games. Otherwise games that only get accepted to a single store will continue to be exclusive to that single store.Same thing with smaller developers, are they expected to cater to the whim of multiple storefronts to be able to release a game? One of my favorites, Zachtronic&#x27;s Opus Magnum was rejected from GoG initially. reply rstat1 8 hours agorootparentI&#x27;m strictly talking about the ones that are paid timed exclusives, nothing else. No where did I say anything about being anyone being required to do anything. You added that.If a publisher chooses to do a single store front, then fine w&#x2F;e. I don&#x27;t have a problem with that. Its when a storefront bribes a publisher to keep a product exclusive to one store, in an attempt to force consumers on to that store that they likely otherwise wouldn&#x27;t have used, that I have problem with. reply zirgs 47 minutes agorootparentAW2 was funded by Epic. They are thr publisher in this case. reply ThatPlayer 8 hours agorootparentprevI was going off your initial point of what you want: No exclusives. Not just paid timed exclusives.>Its when a storefront bribes a publisher to keep a product exclusive to one storeThat&#x27;s not a bribe, that&#x27;s a business transaction. Do you bribe a store to give you a product?>If a publisher chooses to do a single store front, then fine w&#x2F;e.This contrasts with your previous: \"as long as its not limited to one\"So now publishers are allowed to choose one storefront, but somehow they can&#x27;t be paid to make that choice? How should they be making that choice if not by how much each storefront is offering? replyeddythompson80 12 hours agorootparentprevThat’s fair. I view it as just business. It certainly doesn’t affect me or any consumer. It only affects Valve, which I don’t care about. Maybe valve should pay developers more. Epic takes far less than steam does from developers, so I definitely understand the appeal to developers. reply therouwboat 11 hours agorootparentIt does affect some consumers, without valve and proton, I would probably not be playing many games. reply zirgs 46 minutes agorootparentProton works for non-steam games too. reply rstat1 12 hours agorootparentprevIt does effect you. Its a reduction of choice that benefits no one.And since there&#x27;s a vastly bigger audience on Steam vs the Epic Store, I don&#x27;t really think that split matters as much as people would have you believe. reply doikor 11 hours agorootparentprevThis usually applies but for Alan Wake 2 Epic is the publisher. So your argument is like getting angry at Valve for not releasing their games (dota, cs, half life, etc) on Epic store or GOG. reply rstat1 11 hours agorootparentWell I wasn&#x27;t specifically thinking about Epic the publisher there, because yes I agree that is dumb and I didn&#x27;t actually know that Epic was the publisher here. I thought it was just another dumb exclusivity thing. reply thaumasiotes 9 hours agorootparentprevA lot of games are exclusive to Steam. People are currently pretty angry about Sea of Stars, which explicitly committed to a GOG release, and then decided not to have one.Return to Monkey Island also released as a Steam exclusive. reply shinymark 13 hours agorootparentprevI agree with you. I want to play Alan Wake 2 on PC and since it is only sold on the Epic Store I will buy it there.If it was on Steam I would have likely bought it on Steam. But it’s not. So in my case at least, this exclusive is effectively driving me to buy on the Epic Store.I find it sort of funny that many (not all) complaints about the Epic Store are the same things gamers complained about when Steam was released 20 years ago. reply 0cf8612b2e1e 12 hours agorootparentI think it is only fair to compare the Epic vs modern Steam. That Steam had the same issues 20 years ago, is kind of irrelevant if expectations have risen. reply katbyte 2 hours agorootparentprevSame reason I don’t want to have a half dozen streaming providers. I don’t want to have a bunch of different stores and launchers with different games on each.Plus it’s a terrible store front from all I’ve heard and I do not wish to support it reply ben-schaaf 7 hours agorootparentprevNot OP, but because EPIC is anti-linux. reply LarsDu88 6 hours agoprevWait, so they have an ECS game engine with a AAA renderer and nanite-like tech along with a lua based scripting engine and Hollywood level facial animation?They should release the engine. It&#x27;s a solid competitor to Unreal (more scalable due to ECS, easier to write with Luau) reply a2128 2 hours agoparentEpic Games funded the development of Alan Wake 2 and the game is also an Epic Games Store exclusive (which I painfully found out wanting to buy the game but being on Linux), so I assume competing with Unreal would burn some bridges there reply Cu3PO42 1 hour agorootparentEpic Games-compatible launchers exist for Linux, so you can still buy and play the game (it seems to work fine with Proton). reply zirgs 58 minutes agorootparentprevEpic Store works on Linux too. Tried it with steam deck. reply starcraft2wol 5 hours agoparentprevLots of studios do. Turning internal software into a product for others is a different thing. reply jamesfinlayson 4 hours agorootparentYeah, even Valve have (maybe surprisingly) chosen not to license the Source 2 engine. reply paavohtl 59 minutes agorootparentThat&#x27;s technically not true – they&#x27;ve licensed it out to Facepunch to create a sequel to Garry&#x27;s Mod (which was one of the most popular Source 1 games): https:&#x2F;&#x2F;sbox.facepunch.com&#x2F;about&#x2F;. It is the only one we are aware of though. reply dixie_land 5 hours agoparentprevWhen I got my 3090 back when it was first released, I was excited to finally play Control with ray tracing on, no luck. Now with Alan Wake 2 it barely runs High with ray tracing off.It&#x27;s a visually stunning engine but it&#x27;s just too demanding IMO. reply pragmatick 3 hours agoprevThe page is impossible to zoom. In my firefox the view doesn&#x27;t change at all when I zoom out or in and on Chrome it only changes minimally. reply rolfus 1 hour agoparentJust checked in my browser (Vivaldi) and it zooms in and out just fine. On my phone Opera with the \"force zoom\" setting enabled also works. reply debugnik 13 hours agoprevYet another team that switches to Luau for scripting; they even made their own VS Code extension.I gave Luau a try recently but the syntax for external type declarations is undocumented and unstable, which made it awkward to test properly, and the available VS Code extensions default to a Roblox environment until you mess with their settings.So mixed feelings for now, I guess this is why they built their own tooling for it. reply jdance 2 hours agoparentI also have my own vscode extension for luau debugging, still have not moved to the type system due to lack of any decent class typingBut the debugger is so good, I dont know any other debugger with such low overhead in any language reply hipadev23 12 hours agoparentprev> but the syntax for external type declarations is undocumentedhttps:&#x2F;&#x2F;luau-lang.org&#x2F;typecheckhttps:&#x2F;&#x2F;luau-lang.org&#x2F;grammar reply debugnik 11 hours agorootparentThat&#x27;s not it, I mean the \"declare\" statements that aren&#x27;t even listed in the grammar, but are needed to give the type checker information about C API exports; I had to discover them by digging through source code. The analyzer even hardcodes a bunch of them.luau-lsp for example ships this globalTypes.d.lua file[1] for Roblox development and lets you configure your own.[1]: https:&#x2F;&#x2F;github.com&#x2F;JohnnyMorganz&#x2F;luau-lsp&#x2F;blob&#x2F;4b7872349d9b8... reply d--b 13 hours agoprevThe rendering is really impressive. Character animation is not great. It&#x27;s really an area where video games need to improve. Hopefully AI will help... reply Cloudef 3 hours agoprevWhen will northlight integrate libsm64 support? reply Pr0ject217 11 hours agoprevI want to read it, but I don&#x27;t want any spoilers (or, remove any surprise). I&#x27;ll check it out after I&#x27;ve played the game! reply Strom 11 hours agoparentThere are no spoilers in the article. It&#x27;s less revealing than the trailer. reply goimonkeen 2 hours agoprevHi I want to go reply Asooka 10 hours agoprevMan, all these graphical enhancements and they still can&#x27;t design a proper camera. Off-centre camera systems, aka \"over the shoulder\" cameras make me motion sick. I need the player to be in the centre of the screen or everything feels lopsided. By all means, do the RE4 zoom thing when the player aims a gun or similar, but while moving the camera should be horizontally centred. Halo tried something similar with giving the crosshair a vertical offset and while it didn&#x27;t bother me personally, a lot of people complained it made them sick, so they added an option to move it back. The visual system in a lot of folks really doesn&#x27;t like being off-centre compared to the body it&#x27;s tasked with moving. reply 59nadir 2 hours agoparent> Man, all these graphical enhancements and they still can&#x27;t design a proper camera.There&#x27;s absolutely nothing wrong with the camera, it&#x27;s just not to your taste. They&#x27;ve made zero risky or offensive choices with the camera.> Off-centre camera systems, aka \"over the shoulder\" cameras make me motion sick. I need the player to be in the centre of the screen or everything feels lopsided.This is a you problem, though, and an extremely rare problem overall (rare enough for me to literally never hear about it in 25+ years of gaming). I don&#x27;t think it&#x27;s reasonable for you to expect the world of game development to cater to your very niche, specific issue. reply sherry-sherry 8 hours agoparentprev>and they still can&#x27;t design a proper cameraThey did, it&#x27;s just not one you like.Most games that position the camera behind and centred have to zoom out or go weirdly high so you can still see what the character is looking at&#x2F;heading towards. The off-centre camera allows you to be at the same height&#x2F;viewpoint as the character and still see what&#x27;s in front.Look at the Red Dead Redemption 2 camera position when walking vs Alan Wake 2, totally different viewpoints. Both are different artistic choices, I&#x27;d say both work well for each game. reply badsectoracula 7 hours agoparentprevYeah i agree but i think this ship has long sailed - over the shoulder cameras are pretty much everywhere these days. I avoided several 3rd person perspective games for this reason alone (some even had me feel nauseous) and eventually had to force myself to get used to it since i wanted to play some games that switched to it (e.g. Mass Effect 3). Nowadays i can play a game using it without feeling off but i still prefer it when games put the character at the center of the screen.(also i yelled at more than one game that had an option to switch shoulder but not put the character at the center - if you are bothering to implement this why not also add the center option? :-P) reply squidsoup 14 hours agoprevTechnical achievements aside, this game is delightful, particularly if you&#x27;re a fan of Twin Peaks or scandi noir. Highly recommended if you have a penchant for the weird or macabre. A milestone in interactive storytelling. reply imiric 13 hours agoparentI&#x27;m a few hours in, and it&#x27;s enjoyable, but I&#x27;m not blown away by the gameplay as much as the graphics and sound design. It&#x27;s a fairly linear affair with a lot of backtracking, and I find the Mind Place system tedious. It&#x27;s a glorified menu system that blocks off progression until you&#x27;ve pinned some notes to predetermined places on the board, or watched some cutscenes where the character miraculously figures out what to do next. It&#x27;s not engaging in any way, and just takes me out of the core game loop.But I love the numerous references to Control and Max Payne, and how they&#x27;ve integrated it into the same universe. I can&#x27;t wait for the Max Payne remakes, and hopefully the next installment in the series. I just wish it could be done without association with Rockstar. They ruined the experience of MP3, which was a solid game, but Rockstar&#x27;s Social Club launcher is a garbage piece of software. reply squidsoup 13 hours agorootparent> watched some cutscenes where the character miraculously figures out what to do nextSome of your criticisms are fair I think, but this is actually deliberate and explained as the story continues. Saga is clearly doing more than \"profiling\". reply Night_Thastus 14 hours agoparentprevI think it deserves a lot of praise, but also some criticism:* While it may keep their creative vision \"pure\", the lack of lower graphical settings makes it run pretty terribly on an RTX 3080, which is very frustrating. You can brute-force this problem away with DLSS, but I like native resolution and I&#x27;m sick of DLSS being used as a crutch.* The difficulty is all over the place. \"Story\" mode is likely too easy, while \"Normal\" varies between being reasonable and damn near impossible. A weaker enemy can take 2 bullets in Story, and 10 in normal. That&#x27;s frustrating when ammo is so tight early on. In general, the game lacks a good \"progression\" of difficulty. It&#x27;s a roller-coaster instead of a curve.* To add on to the difficulty, the mechanics do not feel as consistent in AW2 as AW1. Why do some enemy types have a shield you need to burn away, while others don&#x27;t? (Despite looking similar) For others, it&#x27;s unclear which ones will vanish with a little light and which ones require an intense light - and what exactly gets them to disappear. Why can&#x27;t the flashlight have a bit more grace when a target leaves the crosshair for 0.1 seconds? Why do so many enemies have extendo-reach and teleporting? Why isn&#x27;t dodging timing better telegraphed? Etc.* The story, at least so far, hasn&#x27;t hit the same highs for me. It feels a little like we&#x27;re doing the same thing over again, and it doesn&#x27;t hit as hard the second time after the reveals and twists from AW1 are already used up. reply Geee 13 hours agorootparentJust use DLSS. It looks great and the graphics settings are designed around it. I&#x27;m not sure if the earlier DLSS versions were crappy, but this latest one doesn&#x27;t seem to have any weird artifacts.I much prefer setting DLSS on performance and playing with medium settings and raytracing on a 3090. The game looks way better that way. reply wilg 13 hours agorootparentprevDoesn&#x27;t make much sense to me to be OK with lower graphical settings but not DLSS. Just use DLSS. reply Night_Thastus 13 hours agorootparentI don&#x27;t like the kind of artifacts or presentation that DLSS creates. It&#x27;s a different kind of image than one with native, but say - lower foliage density or a lower-resolution mesh, etc. reply zaptrem 13 hours agorootparentprevI&#x27;ve found DLSS Quality mode actually looks better than no DLSS at all in most games. reply MaxikCZ 13 hours agorootparentThat&#x27;s because DLSS2 actually also antialiases the game fairly well and cheap, compared to other methods commonly used. reply kevingadd 13 hours agorootparentprevI&#x27;m on a 3080 and it ran fine for me. Did you turn off ray-traced direct&#x2F;indirect lighting? Those really require a 40 series, even at low quality levels. Is your native resolution 4K? At 4K I needed to turn on DLSS, but I was also able to set most of the quality knobs (other than RT) to medium or high, not low. I wonder if maybe you&#x27;re running into some sort of driver problem. reply Night_Thastus 12 hours agorootparentI turned everything to the lowest available setting, except textures, which I kept on high. I checked and that setting doesn&#x27;t seem to make any difference on my card.Native resolution is 1440p.Most of the time it hovers around 60-ish, but it dips into the 40&#x27;s occasionally and is overall inconsistent. To me, at 1440p, that&#x27;s not acceptable.Drivers are the latest Nvidia offers, but I didn&#x27;t scrape the old ones out with DDU - hopefully that&#x27;s not necessary. reply add-sub-mul-div 14 hours agoparentprevIs this reasonably okay for someone who hasn&#x27;t played Control or AW1, if they&#x27;re not strict about needing to know all the backstory? reply anaisbetts 13 hours agorootparentStart here: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=309aaFblCJI, then watch the next few videos in the series until the end of Control (Control Pt. 1 => Alan Wake Pt. 1+2 => Control Pt. 2) and you will be completely thoroughly caught up reply wilg 14 hours agorootparentprevYeah I played it without playing either. I did watch an AW1 recap halfway through. But its basically all so crazy its fun not knowing stuff too. reply lfkdev 13 hours agorootparentprevAlan Wake has nothing todo with Control. AW1 is not important to know, but you&#x27;ll miss some details. reply SketchySeaBeast 13 hours agorootparentControl had a whole DLC devoted to the link (haven&#x27;t played AW2 yet).https:&#x2F;&#x2F;control.fandom.com&#x2F;wiki&#x2F;AWE_(expansion) reply rickstanley 13 hours agorootparentprevIt has though. There are hints \"everywhere\" (not to be specific, otherwise I&#x27;ll spoil it) in the game, but it&#x27;s not vital to play AW2, I would add what you said about AW1, \"you&#x27;ll miss some details.\"AW2 is a step forward to the shared universe of Remedy. reply squidsoup 13 hours agorootparentprevThe Alan Wake and Tom Zane characters are mentioned in Control a number of times, and the FBC make several appearances in Alan Wake II. reply anaisbetts 13 hours agorootparentprev...did we play the same game? reply wilg 13 hours agorootparentprev> Alan Wake has nothing todo with Control.Interesting theory. reply antiterra 13 hours agoprev> \"the characters won&#x27;t bump or get stuck into objects in tight spaces\".After playing the first ‘boss’ in AW2, this is an amusing claim to read. The controls and environment interaction are maddening. reply beenBoutIT 1 hour agoparentI would label AW2 as garbage - a schizophrenia sim paired with a dull board game where you arrange post-it notes.Remedy&#x2F;Sam Lake dropped the ball.Instead of making another game cut from the same brilliant Alan Wake cloth they botched it and took out most of what makes the original game great. reply throwaway879423 13 hours agoprevAm I the only who have no interest in graphics fidelity, but would like to see more physics engines created to play with? Like a fully destructible world would be fun. reply cubefox 13 hours agoparentThere was actually a regress in this respect. Some ten years ago there was a \"destructible physics\" boom in many big games, but nowadays most games abandoned it. There seems to be a trade-off between graphical fidelity and the opportunity for physics-based manipulation of the environment. reply Geee 12 hours agorootparentRemedy&#x27;s previous game, Control, had probably one of the most impressive destructive environments.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=12NORuGfcLc reply ClimaxGravely 7 hours agorootparentNot to take anything away from Control. That game is a absolute masterpiece but the destruction in that game is largely cosmetic and often inconsequential to gameplay. So much that it could be pre-fractured offline. reply cubefox 12 hours agorootparentprevThe game seems to use relatively simple flat geometry, like concrete walls and large glass windows. I would be surprised if they kept the destruction physics with the intricate geometry of Alan Wake 2. reply schmorptron 1 hour agorootparentprevDidn&#x27;t that happen because Nvidia bought physx when it was the cool new promising tech around and gimped it on anything non-Nvidia? reply wilg 9 hours agorootparentprevIt&#x27;s also a whole game design challenge. It has to actually offer something fun and improve the gameplay. reply roboror 13 hours agoparentprevYou should check out Teardown, very impressive physics engine made mostly by a single developer. reply dymk 9 hours agorootparentI remember seeing this game a long time ago, and your comment reminded me to check it out again. It&#x27;s got a console release next week - what timing! reply smolder 12 hours agoparentprevThe game \"The Finals\" has an impressively destructible world, and good quality graphics to boot. It just completed an open beta period, but will return soon for a full release. reply nathants 12 hours agoparentprevtry fortnite solos on performance mode with a 240+ hz monitor. reply mcbrit 10 hours agoprevFrom the first few sentences of the article:\"ECS meant that iteration was quick because adding new or modifying existing systems or game objects was easy, and performance gains were clear when saving and loading the Case Board.\"and there&#x27;s an accompanying screenshot with perhaps 20 objects on a case board.I scanned through the rest of the article with one question in mind: what the hell? ECS is not a solution to putting 20 photos on a case board. You&#x27;re pushing 100Ks or Ms of objects and need performance and are willing to suffer for performance = ECS. Not this.So, despite world class developer, I did not find the article credible. The main cause of the lack of credibility is the author of the article did not anticipate the reader glancing at the case board and the ECS claim and saying: bullshit. Alternatively, they did anticipate the claim, and were told to ship the article anyways. reply mcbrit 10 hours agoparentThe next section isn&#x27;t better:We built a new Voxel-Based Character Control that enables smooth navigation in cramped, complex and dynamic environments; it makes character movement more natural and fluid.Fluid movement can be a problem, but \"Voxel\" is not what you did here, it&#x27;s a marketing term. Maybe start with how a 2d collider for a 2d game should perhaps be a sphere smaller than the character (not a square, they get stuck on corners), and then say sth interesting about how you solved 3d. I am fairly certain that \"voxel\" isn&#x27;t what happened, esp with the prior of \"ECS\". reply LarsDu88 6 hours agoparentprevECS isn&#x27;t just useful for performance. It&#x27;s a better way to architect games and other sorts of software in a more data-oriented (rather than OOP oriented) way. reply beefsack 6 hours agoprev [–] ECS architectures are used in a number of young open source game engines, such as Bevy[1]. I haven&#x27;t done game development for a long time, but hearing about an architecture that does away with the heavy and complex OOP you often see in games makes me want to dip my toes in again and check it out.[1]: https:&#x2F;&#x2F;bevyengine.org&#x2F; reply fulafel 3 hours agoparent [–] There&#x27;s also a history in applying ECS in older things, it started taking off in early 2000&#x27;s, it&#x27;s been bread and butter (though not universal) for long now, also in some open source engines. See eg https:&#x2F;&#x2F;github.com&#x2F;Adelost&#x2F;entity-component-systems-study#re... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Northlight development team for Alan Wake 2 has introduced several technology improvements like a new data-oriented game object model for better memory efficiency and faster performance, and a Voxel-Based Character Control for improved navigation.",
      "Developers have adopted Luau, a language derived from Lua by Roblox, eliminating about 80,000 lines of superfluous code. They also introduced a new wind system for authentic physics effects and a Scattering tool for large-scale environment designs.",
      "The sequel features a new GPU-driven rendering pipeline, HDR support, and enhanced transparency rendering and VFX tools for better artistic flexibility. Also, it includes support for ray-traced direct lighting."
    ],
    "commentSummary": [
      "The Northlight development team for Alan Wake 2 has made several technological improvements, such as a memory-efficient data-oriented game object model and a Voxel-Based Character Control for a smoother navigation experience.",
      "A new wind system for realistic physics effects was introduced, along with a Scattering tool for large-scale environment design. Also, the proprietary scripting language was replaced with Luau (derived from Lua by Roblox), reducing around 80,000 lines of unnecessary code.",
      "The sequel features a fresh GPU-driven rendering pipeline for richer game world details, improved transparency rendering and VFX tools. It also supports HDR and ray-traced direct lighting, granting artists more creative flexibility."
    ],
    "points": 398,
    "commentCount": 198,
    "retryCount": 0,
    "time": 1699381976
  },
  {
    "id": 38176750,
    "title": "ESA's Euclid Space Mission Unveils First Detailed Color Images of the Cosmos, Preps for Universe's Largest 3D Map",
    "originLink": "https://www.esa.int/Science_Exploration/Space_Science/Euclid/Euclid_s_first_images_the_dazzling_edge_of_darkness",
    "originBody": "Science & Exploration Euclid's first images: the dazzling edge of darkness 07/11/2023 174114 views 204 likes ESA / Science & Exploration / Space Science / Euclid In brief Today, ESA’s Euclid space mission reveals its first full-colour images of the cosmos. Never before has a telescope been able to create such razor-sharp astronomical images across such a large patch of the sky, and looking so far into the distant Universe. These five images illustrate Euclid's full potential; they show that the telescope is ready to create the most extensive 3D map of the Universe yet, to uncover some of its hidden secrets. In-depth Euclid, our dark Universe detective, has a difficult task: to investigate how dark matter and dark energy have made our Universe look like it does today. 95% of our cosmos appears to be made of these mysterious ‘dark’ entities. But we don’t understand what they are because their presence causes only very subtle changes in the appearance and motions of the things we can see. To reveal the ‘dark’ influence on the visible Universe, over the next six years Euclid will observe the shapes, distances and motions of billions of galaxies out to 10 billion light-years. By doing this, it will create the largest cosmic 3D map ever made. What makes Euclid’s view of the cosmos special is its ability to create a remarkably sharp visible and infrared image across a huge part of the sky in just one sitting. The images released today showcase this special capacity: from bright stars to faint galaxies, the observations show the entirety of these celestial objects, while remaining extremely sharp, even when zooming in on distant galaxies. Euclid’s view of the Perseus cluster of galaxies Euclid’s view of spiral galaxy IC 342 Euclid’s view of irregular galaxy NGC 6822 Euclid’s view of globular cluster NGC 6397 Euclid’s view of the Horsehead Nebula 1 2 3 4 5 Previous Next “Dark matter pulls galaxies together and causes them to spin more rapidly than visible matter alone can account for; dark energy is driving the accelerated expansion of the Universe. Euclid will for the first-time allow cosmologists to study these competing dark mysteries together,” explains ESA Director of Science, Professor Carole Mundell. “Euclid will make a leap in our understanding of the cosmos as a whole, and these exquisite Euclid images show that the mission is ready to help answer one of the greatest mysteries of modern physics.” “We have never seen astronomical images like this before, containing so much detail. They are even more beautiful and sharp than we could have hoped for, showing us many previously unseen features in well-known areas of the nearby Universe. Now we are ready to observe billions of galaxies, and study their evolution over cosmic time,” says René Laureijs, ESA’s Euclid Project Scientist. “Our high standards for this telescope paid off: that there is so much detail in these images, is all thanks to a special optical design, perfect manufacturing and assembly of telescope and instruments, and extremely accurate pointing and temperature control,” adds Giuseppe Racca, ESA’s Euclid Project Manager. “I wish to congratulate and thank everyone involved with making this ambitious mission a reality, which is a reflection of European excellence and international collaboration. The first images captured by Euclid are awe-inspiring and remind us of why it is essential that we go to space to learn more about the mysteries of the Universe,” says ESA Director General Josef Aschbacher. Euclid's first images: the dazzling edge of darkness Access the video Zoom into the Universe through Euclid’s eyes Euclid’s view of the Perseus cluster of galaxies The Perseus Cluster of galaxies This incredible snapshot from Euclid is a revolution for astronomy. The image shows 1000 galaxies belonging to the Perseus Cluster, and more than 100 000 additional galaxies further away in the background. Many of these faint galaxies were previously unseen. Some of them are so distant that their light has taken 10 billion years to reach us. By mapping the distribution and shapes of these galaxies, cosmologists will be able to find out more about how dark matter shaped the Universe that we see today. This is the first time that such a large image has allowed us to capture so many Perseus galaxies in such a high level of detail. Perseus is one of the most massive structures known in the Universe, located ‘just’ 240 million light-years away from Earth. Astronomers demonstrated that galaxy clusters like Perseus can only have formed if dark matter is present in the Universe. Euclid will observe numerous galaxy clusters like Perseus across cosmic time, revealing the ‘dark’ element that holds them together. Read the full story about this image Euclid’s view of spiral galaxy IC 342 Spiral galaxy IC 342 Over its lifetime, our dark Universe detective will image billions of galaxies, revealing the unseen influence that dark matter and dark energy have on them. That’s why it’s fitting that one of the first galaxies that Euclid observed is nicknamed the ‘Hidden Galaxy’, also known as IC 342 or Caldwell 5. Thanks to its infrared view, Euclid has already uncovered crucial information about the stars in this galaxy, which is a look-alike of our Milky Way. Read the full story about this image Euclid’s view of irregular galaxy NGC 6822 Irregular galaxy NGC 6822 To create a 3D map of the Universe, Euclid will observe the light from galaxies out to 10 billion light-years. Most galaxies in the early Universe don’t look like the quintessential neat spiral, but are irregular and small. They are the building blocks for bigger galaxies like our own, and we can still find some of these galaxies relatively close to us. This first irregular dwarf galaxy that Euclid observed is called NGC 6822 and is located close by, just 1.6 million light-years from Earth. Read the full story about this image Euclid’s view of globular cluster NGC 6397 Globular cluster NGC 6397 This sparkly image shows Euclid’s view on a globular cluster called NGC 6397. This is the second-closest globular cluster to Earth, located about 7800 light-years away. Globular clusters are collections of hundreds of thousands of stars held together by gravity. Currently no other telescope than Euclid can observe an entire globular cluster in one single observation, and at the same time distinguish so many stars in the cluster. These faint stars tell us about the history of the Milky Way and where dark matter is located. Read the full story about this image Euclid’s view of the Horsehead Nebula The Horsehead Nebula Euclid shows us a spectacularly panoramic and detailed view of the Horsehead Nebula, also known as Barnard 33 and part of the constellation Orion. In Euclid’s new observation of this stellar nursery, scientists hope to find many dim and previously unseen Jupiter-mass planets in their celestial infancy, as well as young brown dwarfs and baby stars. Read the full story about this image New discoveries, soon Euclid’s first view of the cosmos is not only beautiful, but also immensely valuable for the scientific community. Firstly, it showcases that Euclid’s telescope and instruments are performing extremely well and that astronomers can use Euclid to study the distribution of matter in the Universe and its evolution at the largest scales. Combining many observations of this quality covering large areas of the sky will show us the dark and hidden parts of the cosmos. Secondly, each image individually contains a wealth of new information about the nearby Universe (click on the individual images to learn more about this). “In the coming months, scientists in the Euclid Consortium will analyse these images and publish a series of scientific papers in the journal Astronomy & Astrophysics, together with papers about the scientific objectives of the Euclid mission and the instrument performance,” adds Yannick Mellier, Euclid Consortium lead. And finally, these images take us beyond the realm of dark matter and dark energy, also showing how Euclid will create a treasure trove of information about the physics of individual stars and galaxies. Getting ready for routine observations Euclid launched to the Sun-Earth Lagrange point 2 on a SpaceX Falcon 9 rocket from Cape Canaveral Space Force Station in Florida, USA, at 17:12 CEST on 1 July 2023. In the months after launch, scientists and engineers have been engaged in an intense phase of testing and calibrating Euclid’s scientific instruments. The team is doing the last fine-tuning of the spacecraft before routine science observations begin in early 2024. Over six years, Euclid will survey one third of the sky with unprecedented accuracy and sensitivity. As the mission progresses, Euclid’s bank of data will be released once per year, and will be available to the global scientific community via the Astronomy Science Archives hosted at ESA’s European Space Astronomy Centre in Spain. About Euclid Euclid is a European mission, built and operated by ESA, with contributions from NASA. The Euclid Consortium – consisting of more than 2000 scientists from 300 institutes in 13 European countries, the US, Canada and Japan – is responsible for providing the scientific instruments and scientific data analysis. ESA selected Thales Alenia Space as prime contractor for the construction of the satellite and its service module, with Airbus Defence and Space chosen to develop the payload module, including the telescope. NASA provided the detectors of the Near-Infrared Spectrometer and Photometer, NISP. Euclid is a medium-class mission in ESA’s Cosmic Vision Programme. For more information, please contact: ESA Media Relations Email: media@esa.int Like Thank you for liking You have already liked this page, you can only like it once!",
    "commentLink": "https://news.ycombinator.com/item?id=38176750",
    "commentBody": "Euclid&#x27;s First ImagesHacker NewspastloginEuclid&#x27;s First Images (esa.int) 382 points by perihelions 20 hours ago| hidepastfavorite92 comments semireg 15 hours ago\"This figure shows an overlay of an image of the Moon on top of an image of the sky recorded simultaneously by the 36 detectors of Euclid’s VIS instrument.\"https:&#x2F;&#x2F;www.esa.int&#x2F;ESA_Multimedia&#x2F;Images&#x2F;2023&#x2F;11&#x2F;Euclid_s_w...Worth a click. reply d--b 1 hour agoparentVery nice, it’s one of the only image that gives some feeling about how much stuff there is in the universe. reply dylan604 12 hours agoparentprevI have a wide field telescope at home that yields a similar field of view when I image the moon. Too bad my scope doesn&#x27;t have the same imaging abilities as this. I&#x27;m guessing a few more 0s and a couple additional commas added to the price tag helps. reply hn8305823 12 hours agorootparentEuclid has a 1.2m primary mirror. For $600k you can have a 1m telescope in your backyard. You will still have to deal with the atmosphere, clouds, and Moon, however. Especially clouds.https:&#x2F;&#x2F;planewave.com&#x2F;product&#x2F;pw1000-1-meter-observatory-sys... reply sjackso 4 hours agorootparentAh, yes-- but if you shop around, you can find a telescope of that aperture for less. Here&#x27;s one for a mere $132k!https:&#x2F;&#x2F;explorescientificusa.com&#x2F;collections&#x2F;optiques-fullum... reply p-e-w 6 hours agorootparentprevSix hundred thousand dollars for a 1m telescope? That&#x27;s a crazy price tag. What&#x27;s the expensive part here? That&#x27;s the price of 10 upper-tier cars. Is it so insanely difficult to make that mirror, or are they just gouging because they have little or no competition? reply dylan604 6 hours agorootparentThat&#x27;s like asking why a Ferrari costs so much, it&#x27;s just a car. There&#x27;s a big difference from a mass produced car with automated processes compared to a product that is pretty much one offs and are made by hand. Pretty much every industry has the equivalent mass produced vs hand made. Leica makes camera lenses for the masses, but they also have a very expensive line of lenses that they only start the hand made process when you&#x27;re check clears. Clothing, homes, etc all have versions of it.So unless you can tell me that you&#x27;ve hand ground a telescope mirror of any size to have direct knowledge of the experience, I&#x27;d suggest taking a look at the process while considering the size of the mirror discussed. Even the base and the trusses for the assembly will have required design time and iterating through changes. Not sure why this seems so strange compared to all of the other things in life with \"accepted\" price tags. reply baq 8 minutes agorootparentSpot on, for a concrete example check this one out - there&#x27;s a slight chance these are mass producedhttps:&#x2F;&#x2F;www.usa.canon.com&#x2F;shop&#x2F;p&#x2F;rf1200mm-f8-l-is-usm-lensbut the f5.6 version... doesn&#x27;t seem to be:https:&#x2F;&#x2F;www.the-digital-picture.com&#x2F;Reviews&#x2F;Canon-EF-1200mm-... reply braydenm 8 hours agorootparentprevFor those looking for something large but still a little bit more realistic, for Also, the Lagrange point is where Webb and some other stuff is located — is it getting crowded up there?For stability reasons, spacecraft orbit around L2 rather than sitting at its center. Here&#x27;s a diagram of JWST&#x27;s orbit: https:&#x2F;&#x2F;i.stack.imgur.com&#x2F;sBH2i.png It&#x27;s a bent ellipse that&#x27;s 1.6 million km in length along the long axis, considerably larger than the orbit of the moon. You could put three million telescopes on that orbit and they&#x27;d each be a kilometer apart. reply superposeur 7 hours agorootparentThanks and great diagram — I’d imagined a tiny orbit around L2, not one the size of the entire earth! reply sbierwagen 5 hours agorootparentThe diagram does not make this clear at all, but the big circle is the orbit of the Moon. The Earth is only 12,756 km in diameter, and the tick marks are 200,000 km apart. If drawn to scale on that diagram, it would be 2.7 pixels wide. reply Anotheroneagain 3 hours agoparentprevIt images a large patch of sky in 600megapixels at once. It&#x27;s an overwhelmingly more valuable telescope by how much it gathers at once, JWST only captures a tiny dot, in similar resolution. reply chpatrick 15 hours agoparentprevSpace is big. Really big. You just won&#x27;t believe how vastly hugely mind-bogglingly big it is. I mean, you may think it&#x27;s a long way down the road to the chemist, but that&#x27;s just peanuts to space. Listen... reply dylan604 14 hours agoparentprevthe word point used with Lagrange is bit misleading if you&#x27;re thinking of it as an actual point. The satellites at a Lagrange \"point\" are actually orbiting the point like it is a NULL pointer in a 3D app (if you have familiarity with that concept). Also, space is big. reply giantrobot 16 hours agoparentprevEuclid has visible imager and near-infrared spectrometer and photometer. Webb is all infrared. So they have non-overlapping missions even when observing the same structures and objects.Also space is very large. The L2 orbit is gigantic and the probes are teeny tiny in relation. So it&#x27;s hardly crowded in any sense. reply flockonus 16 hours agorootparentI&#x27;m sure crowded is far off, but it&#x27;s still interesting to think how they interfere with each other&#x27;s instrumentations (given the field of vision is immense in comparison to their size), is there some type of space control traffic involved? reply giantrobot 15 hours agorootparentThe L2 point is about 1.5 million kilometers from Earth. The various probes like Webb and Euclid orbit around that point at (IIRC) about a million kilometers. The various probes in that orbit will effectively never interfere with each others instruments.As for coordination, at that orbit, it&#x27;s going to likely be the individual agencies coordinating with one another. Every probe&#x2F;satellite launch gets COSPAR IDs and other tracking IDs through various national and international agencies. reply jjgreen 15 hours agorootparentMore on L2 orbits https:&#x2F;&#x2F;webbtelescope.org&#x2F;contents&#x2F;media&#x2F;images&#x2F;01F4STZH25YJ... reply giantrobot 13 hours agorootparentGood find, I was looking for a similar (or maybe that) image for illustration. It&#x27;s a good description and illustration of Lagrange orbits. replythread_id 8 hours agoprevI never cease to be blown away by images of the Perseus cluster - planet earth is but a tiny spec in one solar system in an enormous spiral galaxy. In this single image there are scores of galaxies.“It’s hard to talk about the Cosmos without using big numbers. I said “billion” many times on the Cosmos television series, which was seen by a great many people. But I never said “billions and billions.” For one thing, it’s too imprecise. How many billions are “billions and billions”? A few billion? Twenty billion? A hundred billion? “Billions and billions” is pretty vague. When we reconfigured and updated the series, I checked—and sure enough, I never said it.” ― Carl Sagan, Billions & Billions: Thoughts on Life & Death at the Brink of the Millennium reply euroderf 10 minutes agoparentPerhaps somebody misquoted him saying \"billions of billions\" ? reply ahazred8ta 4 hours agoparentprevThe running gag was \"we&#x27;ll travel through billions and billions of cubic kilometers of star-stuff\". reply h1fra 15 hours agoprevI started saying \"this image is so noisy\" but all the dots are actually stars, it&#x27;s incredible! reply taylorlapeyre 15 hours agoparentThey aren&#x27;t stars, they&#x27;re galaxies! reply adonovan 5 hours agorootparentIt blew my mind when I realized that all but about a dozen of the points of light that you can see at night with the naked eye are actual stars... but nearly every point of light in the Hubble deep field is a galaxy of 10^8 stars. reply mr_mitm 15 hours agorootparentprevDepends on which picture you&#x27;re looking at reply dylan604 14 hours agorootparentDepends on which dots you&#x27;re looking at reply ySteeK 13 hours agorootparentDepends on which post u are refering it replynologic01 15 hours agoprevIs there some sort of citizen science we could engage-in with these datasets? When zooming in on Euclid’s view of the Perseus cluster of galaxies I see some very strange stuff :-) reply dylan604 12 hours agoparentA popular citizen science is writing a classic hacker script with wget&#x2F;curl to download all of the images and then stack them together. Numerous comets have been found this way as the comet will be the only thing moving once all of the images are aligned. I guess it doesn&#x27;t have to be a comet, as asteroids and Planet X could be found this way as well. If the dot changes course&#x2F;speed in your research, it could be Aliens!!!!The fun thing is that when a group gets scope time, it&#x27;s typically for a specific purpose so the images are initially studied specifically for that purpose. It&#x27;s possible there&#x27;s more treasure in those images beyond the original intent that just needs more time being studied or added to other imagery&#x2F;collections that come together to reveal something.So depending on what you might be interested in, you can find all of the images from every scope imaginable of the same object to do some fun stuff, or you could find a time series from one scope that might reveal something. reply SushiHippie 15 hours agoparentprevDo you maybe mean this?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38177815 reply _a_a_a_ 15 hours agoparentprevgo on.... reply taway1237 12 hours agoprev>Astronomers demonstrated that galaxy clusters like Perseus can only have formed if dark matter is present in the Universe.Any MOND people here to comment what they think about Euclid? I always enjoy reading MOND speculation here on HN (even though I don&#x27;t know enough to have an informed opinion myself). reply pcrh 18 hours agoprev.... even the smallest dots are huge... reply zoeysmithe 17 hours agoparentI&#x27;ll never be able to comprehend the idea of \"Oh those many oblong glowing things in the background that are easy to miss? They&#x27;re all galaxies of their own.\"The Perseus cluster contains thousands of galaxies. Every little thing in that photo is incomprehensibly large. reply mbivert 11 hours agorootparent> Every little thing in that photo is incomprehensibly large.And that&#x27;s just a small portion of what we can perceive, as humans. It&#x27;s mindblowing; daily concerns are so trivial in comparison. It&#x27;s so sad we can&#x27;t see the night sky clearly anymore, that must have been fantastic, especially with an understanding of what those little specks of light are. Probably more fulfilling than watching screens. reply chrsw 6 hours agorootparentMaybe we had to think our problems were important so we can surivive. I get your point though, we&#x27;re due to revisit our priorities. Especailly as science continues to show us what&#x27;s possible, and what&#x27;s at stake. Turns out the universe is bigger than anyone imagined and we&#x27;re probably not going to be visited by Little Green Men any time soon eager to tell us the meaning life, the universe and everything in between. reply Ringz 15 hours agorootparentprevAnd what also makes me think again and again is the fact that we see their state from 240,000,000 years ago. Some of these huge little dots may no longer exist in the form now observed. reply dylan604 14 hours agorootparentprevby the reverse of the incomprehensibly large realization is how incomprehensibly small we are. kind of humbling. of all of the petty animosity within human civilization, it doesn&#x27;t mount to a hill of beans to the cosmos. reply Jzush 18 hours agoprevWhat&#x27;s up with all the purple dots, why are they all the same size? reply SiempreViernes 18 hours agoparentAre you referring to what they describe as \"ghosts\" in the image description?> Another signature of Euclid special optics is the presence of a few, very faint and small round regions of a fuzzy blue colour. These are normal artefacts of complex optical systems, so-called ‘optical ghost’; easily identifiable during data analysis, they do not cause any problem for the science goals. reply Jzush 13 hours agorootparentAh, yup those are the things I was referring to. They seems a little too uniform so it&#x27;d make sense that it&#x27;d be an optical artefact. reply xioxox 18 hours agoparentprevhttps:&#x2F;&#x2F;twitter.com&#x2F;akira_doe&#x2F;status&#x2F;1721886699863834770 reply deanCommie 12 hours agoprevNot sure I&#x27;m understanding how to match the images here against Euclid&#x27;s stated purpose \"to investigate how dark matter and dark energy have made our Universe look like it does today.\"How is the data being presented here helping us investigate dark matter&#x2F;energy, which is not in the data? reply mkesper 10 hours agoparentThese are first demonstration images. Euclid had a hard start but now it&#x27;s ready to be used. reply sergiotapia 16 hours agoprevAt this point there has to be other civilizations out there right? There&#x27;s just too many systems for us to be the only ones. reply namanyayg 15 hours agoparentRather than just carbon-based organisms confined to rocky planets, I am more interested in the possibility of how life might look outside of that viewpoint.For example, how about interplanetary scale lifeforms akin to boltzmann brains, where each analogue to a human neural impulse takes minutes or even days to zoom across empty space?What about dark-matter based life? If dark matter composes of 95% of our universe, could there be a whole different set of dark matter based physics, life, and technology, where the intelligent dark-matterians speculate about the mysterious 5% of the universe which interacts with these strange oscillating electric and magnetic fields?I know it&#x27;s unlikely and that given our sample size of n=1 we can only be confident about organic lifeforms, and it&#x27;s our best bet to search for similar life -- but I like to imagine that thousands (millions?) of years in the future when we find other kinds of life, it&#x27;ll be obvious to everyone that life exists in all possible ways and they&#x27;ll laugh at us 21st century folks for believing that just carbon could self replicate and think. reply mr_mitm 15 hours agorootparentOne of the defining properties of dark matter is that it interacts only weakly at most, or else we would see an entirely different distribution. Ordinary matter can dissipate heat because of electromagnetic interaction and thus collapse into galaxies. Dark matter can&#x27;t, so it only forms diffuse, homogeneous halos.The idea of \"dark chemistry\", whole not whacky enough to be immediately discarded, is highly exotic.https:&#x2F;&#x2F;www.space.com&#x2F;21508-dark-matter-atoms-disks.html reply ordu 13 hours agorootparentprev> the intelligent dark-matterians speculate about the mysterious 5% of the universe which interacts with these strange oscillating electric and magnetic fields?They would have a hard time figuring out the existence of electic and magnetic fields. They wouldn&#x27;t feel them. And their devices wouldn&#x27;t feel them.They would be able to notice 5% of mass by gravitational interactions only. They wouldn&#x27;t be able to see how magnetic fields reconnect on a surface of a star and conclude that it means there is some unknown field at work.So to think, they probably have their own dark versions of magnetic and electric fields. reply pixl97 15 hours agorootparentprevLots of people try to jump on the \"silicon based life isn&#x27;t possible\", but even on that I take a different viewpoint.As we are watching AI with concern on our own planet, what if that is a common bootstrap. Carbon based life creates silicon&#x2F;metallic &#x27;life&#x27;. And if that is possible, who knows what that would bootstrap itself into in the future. reply tekla 12 hours agorootparentprevDark Matter based life is probably impossible. Dark matter doesn&#x27;t interact with electromagnetism so have fun with that. reply mr_mitm 15 hours agoparentprevA seductive thought, but without knowing the probability for life, this question simply has no answer. We only know that 0 I consider life outside of the planet to 100% be a thing.Show your math? reply dylan604 12 hours agorootparentIs partial credit available for showing work even if the incorrect answer was derived? reply sheepscreek 15 hours agoparentprevEither that or as Elon once said, maybe life is just that special. I would still love for someone to do a Bayesian analysis of finding life on a planet&#x2F;in a galaxy. It sounds pretty crazy when I say it out loud. We’re staring into infinity essentially.So yeah, life must be out there. But maybe “there” is very very far. Possibly many million light years away. In other words, in a universe with billions of galaxies containing billions of stars, life is likely not very plentiful. I imagine encountering any element besides H&#x2F;He is usually a discovery (more so if the element is higher up in the periodic order, such as the ones needed for our kind of life).Then again, there is so much we don’t know. Like dark matter (anti-proton&#x2F;electron&#x2F;neutron&#x2F;*). Maybe there is life that exists in anti-everything - (anti-carbon, etc). It won’t be very good if we ever encounter them (our carbon based bodies and anti-carbon based one will collapse on encounter, emanating a staggering amount of energy). reply ladams 15 hours agorootparentA minor correction: anti-matter is actually regular matter. We understand it quite well, and are even able to create anti-atoms in the lab. On the other hand, dark matter is much more poorly understood: essentially the only evidence we have for its existence are observations of \"weird\" gravitational effects in the universe. reply hwayne 13 hours agorootparentAlso we have pretty strong evidence that, at least in the observable part of the universe, almost all visible matter is regular matter. reply 8bitsrule 8 hours agorootparentprev> maybe life is just that special.It appears from spectra that the chemical elements produced by stars are the same everywhere. If so, then the possibility of material life exists everywhere in the universe ... where conditions permit. It&#x27;s down to the presence and concentrations of the various elements, the temperature and stability of some fluid medium that can bring the endless potential combinations into contact, and a lot of time. (Calculating the odds is an exercise left for the student.) reply BurningFrog 14 hours agoparentprevTrue, but maybe we just happen to be first?That would explain why we don&#x27;t see anyone else. reply thriftwy 14 hours agoparentprevIt is quite possible that we are one of the first ones. The universe as we know it is rather new. Our planet exists for a significant chunk of its total lifetime, and it needed heavier elements to be produced before it could coalesce.The universe is expected to be teeming with purposeful matter eventually. reply dylan604 14 hours agorootparentRelatively in the total lifetime of the Earth, there are theories that Earth possibly is a second generation planet within Sol&#x27;s lifetime. reply thriftwy 13 hours agorootparentWhat happened to the first one? Where did they go and how old were they? reply gwerbret 15 hours agoprevSince the article is low on details about Euclid [0]:> The objective of the Euclid mission is to better understand dark energy and dark matter by accurately measuring the accelerating expansion of the universe.> Euclid will [...] measure the redshift of galaxies out to a value of 2, which is equivalent to seeing back 10 billion years into the past.> During its nominal mission, which will last at least six years, Euclid will observe about 15,000 deg2 (4.6 sr), about a third of the sky, focusing on the extragalactic sky (the sky facing away from the Milky Way).> About 10 billion astronomical sources will be observed by Euclid, of which one billion will be used for weak lensing (to have their gravitational shear measured) with a precision 50 times more accurate than is possible today using ground-based telescopes.> After Russia withdrew in 2022 from the Soyuz-planned launch of Euclid, the ESA reassigned it to a SpaceX Falcon 9 launch vehicle, which launched on 1 July 2023.> In total, nine Science Data Centres spread over countries of the Euclid Consortium will process more than 170 petabytes of raw input images over at least 6 years> The telecommunications system is capable of transferring 850 gigabits per day. It uses the Ka band and CCSDS File Delivery Protocol to send scientific data at a rate of 55 megabits per second during the allocated period of 4 hours per day to the 35 m dish Cebreros ground station in Spain, when the telescope is above the horizon. Euclid has an onboard storage capacity of at least 300 GB.[0]: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Euclid_%28spacecraft reply jacquesm 14 hours agoparent> The telecommunications system is capable of transferring 850 gigabits per day. It uses the Ka band and CCSDS File Delivery Protocol to send scientific data at a rate of 55 megabits per second during the allocated period of 4 hours per day to the 35 m dish Cebreros ground station in Spain, when the telescope is above the horizon.To put this feat in perspective: it can be a pretty difficult job to install working WiFi in a warehouse a few hundred meters on a side. And the transfer rate at that distance is really mind boggling. reply Ringz 15 hours agoparentprevThanx! reply aaroninsf 16 hours agoprev [–] 2&#x2F;5 too many nearfield stars, would not travel through cosmos again reply twic 14 hours agoparent [–] Damn the Solar System. Bad light; planets too distant; pestered with comets; feeble contrivance; could make a better myself.-- Francis Jeffery replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "ESA's Euclid mission has unveiled its first full-colour cosmological images, exhibiting unparalleled clarity over a large sky portion.",
      "The Euclid telescope is set to generate the most comprehensive 3D Universe map and scrutinize dark matter and dark energy, which constitute 95% of our cosmos.",
      "Euclid's initial images demonstrate its unique ability to produce sharp visual and infrared images across extensive sky sections in one go. The mission epitomizes European excellence and global collaboration."
    ],
    "commentSummary": [
      "The European Space Agency's (ESA's) Euclid space mission has disclosed its first full-colour images of the cosmos with remarkable clarity over a substantial part of the sky.",
      "The Euclid telescope, designed to generate the most comprehensive 3D map of the Universe, will delve into investigating dark matter and dark energy that constitute 95% of our cosmos.",
      "Over the next six years, Euclid will scrutinise billions of galaxies up to 10 billion light-years away, demonstrating its unique ability to deliver sharp visible and infrared images across a large sky portion in a single session."
    ],
    "points": 382,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1699365532
  },
  {
    "id": 38186190,
    "title": "Interactive Game Tests Knowledge of Antidepressants and Tolkien Characters",
    "originLink": "https://antidepressantsortolkien.vercel.app/",
    "originBody": "Antidepressants or Tolkien Can you guess if the word is an antidepressants drug or a Tolkien character? Play",
    "commentLink": "https://news.ycombinator.com/item?id=38186190",
    "commentBody": "Antidepressants or TolkienHacker NewspastloginAntidepressants or Tolkien (antidepressantsortolkien.vercel.app) 381 points by mdturnerphys 7 hours ago| hidepastfavorite80 comments blooalien 6 hours agoI&#x27;m really surprised at what a challenge that turned out to be. I was certain I was gonna have no problems distinguishing drugs from Tolkien characters, but I only got 15&#x2F;24 in the end. Recognized a few obvious brand names and characters, but half the time I had to resort to straight-up guessing. Some of those drug names totally sound like Tolkien characters. reply ren_engineer 5 hours agoparentit&#x27;s actually a due to a research field created&#x2F;popularized by Tolkienhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Phonaestheticsall about studying pleasant sounding words, big pharma uses it for naming drugs. \"Cellar door\" was one of Tolkien&#x27;s favorite phrases, you can see variations and modifications of it in many fantasy settings>Tolkien, Lewis, and others have suggested that cellar door&#x27;s auditory beauty becomes more apparent the more the word is dissociated from its literal meaning, for example, by using alternative spellings such as Selador, Selladore, Celador, Selidor reply retrac 2 hours agorootparentThere&#x27;s a related field, phonosemantics, about the inherent meaning of a word because of how it sounds. (Words which sound like what they should sound like are, I would guess, pleasing.) Onomatopoeia fall in this category: bang, crash, pow, glug-glug.Teensy eensy tiny itty bitty little bit. All &#x2F;e&#x2F; and &#x2F;i&#x2F; front vowels. The mouth is literally closed up. Grand large vast ginormous expansive gargantuan. All &#x2F;a&#x2F; back vowels. The mouth is literally relaxed and open. There are of course exceptions (big, small being notable) but English has a strong tendency in this way with size terms. Big = back and open vowel. Small = front and close vowel. This tendency isn&#x27;t restricted to English; it shows up across languages in unrelated language families.One of the classic linguistics experiments is Bouba and Kiki [1]. One of these shapes is called Bouba, and one is called Kiki. As you probably already instinctively know, the one on the right is Bouba, and the one on the left is Kiki. Arabic, Japanese, English, Swahili speakers all agree on this, with like 90% or greater concord across cultures being typical.And one thing I noticed myself I haven&#x27;t seen written about elsewhere. Take a look at the letter forms for how we write these sounds. In English: Bouba, Kiki. In Japanese: ボウバ and キキ. In Arabic: بوبا and كيكي. Bouba is written with round glyphs that enclose spaces. Kiki is written with sharp straight lines. Maybe that is just a coincidence. I haven&#x27;t done a larger sampling than those three writing systems.Other patterns tend to show up within a language, but not cross-linguistically, and are probably arbitrary associations formed simply because of existing patterns. For example with English:* gl- : related to light -- glance, glare, glass, gleam, glimmer, glint, glisten, glitter, gloaming, gloom, gloss, glow* sw- : related to a long movement - sway, sweep, swerve, swing, swipe, swirl, swoop, swooshThe last three are very fun: swirl, swoop, swoosh. Swirl ends in -rl which literally curls (oh, there&#x27;s that rl again) the tongue. A swoop ends with a stop consonant. Accordingly, it has more finality, suddenness, than swoosh. So: a bird swoops in to grab its prey. And a bird swooshes by, when it misses that prey.[1] https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;e&#x2F;e7&#x2F;Booba-Ki... reply adastra22 1 hour agorootparent\"slithering snakes\" reply Semaphor 4 hours agorootparentprev> \"Cellar door\" was one of Tolkien&#x27;s favorite phrasesOh cool, so that is where Donnie Darko got it from (\"the most beautiful word in the English language\") reply misstuned 3 hours agorootparentprevThere is, or was, a radio&#x2F;TV company in Europe called Celador - I always wondered where the odd-sounding name came from. reply collaborative 1 hour agorootparentAlso means jail keeper in Spanish reply jltsiren 5 hours agoparentprevNone of the drug names sounded like Tolkien characters to me. I guess native English speakers are at a disadvantage, because they are more likely to consider the names as they would be pronounced in English. The intended pronunciation is usually close to Classical Latin, which means that pronouncing the names in any other European language is likely closer to the truth. And when you pronounce the names in that language, Tolkien characters and drugs tend to sound different. reply sspiff 4 hours agorootparentI&#x27;m European and I studied Latin for 6 years in high school and yet I found the test very challenging. reply dawatchusay 4 hours agorootparentprevSo you were 100% correct on the test? reply jltsiren 4 hours agorootparentI got 23&#x2F;24 this time, as I guessed one Tolkien character wrong. The last time I saw this test, maybe a couple of years ago, I got 24&#x2F;24. reply steve_adams_86 5 hours agoparentprevYeah, wow. It’s been years since I read and watched, but I expected this to be challenging for the uninitiated. That crushed me. I guess I just lost a bunch of nerd cred.It’s bizarre that I did about as well at getting drug names correct, and I can’t say I’m well versed in those. reply BerislavLopac 2 hours agoparentprev24&#x2F;24 here :P reply saghm 6 hours agoprevTwo of my favorites of this genre are \"Ikea Furniture or Metal Band\" and \"Drug or Pokemon\". I did terribly at the first one since I don&#x27;t know enough metal I guess, but I aced the latter, despite realizing that \"Remoraid\" actually does sound more like some sort of join pain cream or something than a pokemon. reply crypto29 6 hours agoparentLet&#x27;s not forget one of the first in the genre - \"Programming Language Inventor or Serial Killer\" https:&#x2F;&#x2F;vole.wtf&#x2F;coder-serial-killer-quiz&#x2F; reply modeless 4 hours agorootparentThe first one I saw, and still my favorite, was \"Pokemon or Big Data\" https:&#x2F;&#x2F;docs.google.com&#x2F;forms&#x2F;d&#x2F;e&#x2F;1FAIpQLScRsfRHXPTuEXdNvUcI... reply akdor1154 2 hours agorootparent&#x27;Hadoop is a distributed system for counting words&#x27; ahaha. reply MalcolmDwyer 5 hours agorootparentprevMy favorite was \"North Korean propaganda or TED talk soundbite?\"There are a few articles about it but the actual quiz doesn&#x27;t seem to be up anymore. reply tkgally 6 hours agorootparentprevExcellent! The first one I remember seeing—and enjoying—was “Prof or Hobo”:https:&#x2F;&#x2F;www.proforhobo.com&#x2F; reply lIl-IIIl 1 hour agorootparentprevMy first and favorite was cheeseorfont.com, which is unfortunately has been taken over by something completely unrelated.But that at least had an explanation: both cheeses and type foundries seem to come from Switzerland. reply pigeons 4 hours agorootparentprevI failed Filesystem Driver Author or Murderer\". reply ekianjo 5 hours agorootparentprevNot really insightful since you only have pictures to guess. You can make any murderer look nice and friendly with the right picture reply AndrewStephens 5 hours agoparentprevYou might enjoy my Planet From Dr Who or Hair Care Product game[0].[0] https:&#x2F;&#x2F;sheep.horse&#x2F;2019&#x2F;5&#x2F;quiz_-_planet_from_doctor_who_or_... reply esprehn 5 hours agoparentprevikeaordeath.com doesn&#x27;t seem to work anymore but the game still works on the waybackmachine which is fun:https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20180126014527&#x2F;https:&#x2F;&#x2F;ikeaordea...Even the sound effects work! reply second_brekkie 5 hours agoprev21&#x2F;24 That was fun, also surprised by the difficulty.Kept slipping up on the less known Gondorian kings.Also if your a filthy casual like me and cba to re-read the Silmarilion, Nerd of the Rings is a, solid YT channel.https:&#x2F;&#x2F;m.youtube.com&#x2F;channel&#x2F;UCW0gH2G-cMKAEjEkI4YhnPA reply geuis 5 hours agoprev23 of 24. Missed the last one due to a miss click.(I&#x27;ve read the Silmarillion too much it seems.) reply gymbeaux 5 hours agoparentSo 24&#x2F;24 reply whalesalad 4 hours agoprevI’ve often wondered - who are the Madison Avenue don Draper crews of the prescription drug world? How do they all create these terrible names, and terrible commercials around them? There’s clearly some consistency and yet it’s all insane. reply frutiger 6 hours agoprevIf you’ve read The Silmarillion it’s not too difficult, as Elvish names have common construction patterns and sounds. reply philsnow 3 hours agoparentI&#x27;ve read the Silmarillion several times, read through [0] and [1] each once, and I still mostly got tripped up on all the kings of Gondor who sound apparently a lot like antidepressants (I got 18&#x2F;24).[0] https:&#x2F;&#x2F;www.amazon.com&#x2F;Introduction-Middle-Earth-Published-W... [1] https:&#x2F;&#x2F;www.amazon.com&#x2F;Languages-Tolkiens-Middle-Earth-Compl... reply jonny_eh 6 hours agoparentprevThis comment, its content and tone, is why I came here. reply diarrhea 5 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=9224 reply WXLCKNO 5 hours agorootparentThank you for this lol reply chongli 6 hours agoparentprevI’ve read the Silmarillion and I got 12&#x2F;24. Granted, I read it about 25 years ago, so I probably didn’t pick up all the details of Elvish languages. reply frutiger 6 hours agorootparentAbout 15 years ago for me and I got 23&#x2F;24. I guess YMMV. reply ulizzle 6 hours agorootparentI read it six months ago or so and I got 9&#x2F;24My consoling idea is that the medical big brother establishment lizards are huge Tolkien fans reply gpderetta 2 hours agoparentprevRead the Silmarillion, but only managed 20&#x2F;24! reply nevster 5 hours agoparentprev20&#x2F;24 - some of the choices near the end were tricky. Have read Silmarillion, Unfinished Tales, History of Middle Earth 1-3 reply vaxintar 5 hours agoprev23&#x2F;24but there was a few I just got lucky, Clédial got me because I didn&#x27;t expect a drug to have an accent. reply xenophon 4 hours agoprevAnother classic of this genre, brought to you by McSweeney&#x27;s: https:&#x2F;&#x2F;www.mcsweeneys.net&#x2F;articles&#x2F;armed-band-of-thugs-or-m... reply erickhill 3 hours agoprevReminds me of the classic Sporcle quiz: \"Drug or Pokemon?\" https:&#x2F;&#x2F;www.sporcle.com&#x2F;games&#x2F;LinkinMarc&#x2F;drug_or_pokemon(and just as baffling) reply lIl-IIIl 1 hour agoprevFrom the tweet that inspired this game:\"Three rings to block reuptake of neurotransmitters And to the post-synaptic receptor bind them.\" reply isoprophlex 6 hours agoprevI never knew sildenafil (marketed as viagra) acted as an antidepressant too, lol reply rconti 6 hours agoparentYep that was the first one i slapped my forehead at missing, because I actually knew what it was but figured it must ALSO be a tolkien character since I was sure it wasn&#x27;t an antidepressant. reply elmerfud 6 hours agoparentprevIt&#x27;s a curious link that they made. Many antidepressants can cause performance issues, which can be a big deal for a lot of people. Using sildenafil with it can restore that part of the vitality. reply jonny_eh 6 hours agoparentprev> Antidepressant-like activity of sildenafil following acute and subchronic treatment in the forced swim test in mice: effects of restraint stress and monoamine depletionhttps:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC5031750&#x2F; reply mjfl 6 hours agoparentprevNow I&#x27;m thinking of an elf named Sildenafil. reply debo_ 5 hours agorootparentSire of Erecthelion, who slew Gothmog the High Captain of the Balrogs at the battle of Gondolin. reply xarope 5 hours agorootparentif I saw Erecthelion, I might have clicked on Tolkien...! reply rossdavidh 6 hours agoprev21&#x2F;24, and I have to say that there were a lot more tough calls than I expected. One wonders if reading JRRT&#x27;s works has been tested as an antidepressant. I think \"Farmer Giles of Ham\" was pretty upbeat... reply d0odk 5 hours agoprevNardil is unfair reply stargazer-3 2 hours agoparentYes, Nárdil (or Nárndil?) could&#x27;ve been a Tolkien name meaning fire friend in Quenya. reply PlunderBunny 6 hours agoprevThe wonderful McSweeney&#x27;s Internet Tendency [0] has a lot of this type of humour.1. https:&#x2F;&#x2F;www.mcsweeneys.net reply edgarvaldes 6 hours agoprevLike that classic Pokemon or Big Data reply ivraatiems 5 hours agoprevFor anyone who is looking for information on the different kinds of antidepressants mentioned in this game (which I failed most completely despite being broadly familiar), here is a great article from Dr. Scott Siskind (aka Scott Alexander of SlateStarCodex&#x2F;AstralCodexTen): https:&#x2F;&#x2F;lorienpsych.com&#x2F;2021&#x2F;06&#x2F;05&#x2F;depression&#x2F;I am not a huge fan of Siskind on all things but he has a great ability to explain complex topics simply when he is an expert, and he is on this. reply ChrisArchitect 6 hours agoprev(2020)From it&#x27;s previous home on https:&#x2F;&#x2F;antidepressantsortolkien.now.sh&#x2F; reply dividendpayee 6 hours agoprevDid anyone do worse than me? I got 11&#x2F;24 :S reply rconti 6 hours agoparent10&#x2F;24. Wow. You&#x27;d think it would be hard to do worse than a coin flip. On the other hand, I guess many coin flip sets are going to end up \"worse than a coin flip\" :D reply diarrhea 5 hours agorootparentJust shy of 50% of coin flips will be worse than a coin flip. reply officehero 3 hours agoparentprevRead most of Tolkien&#x27;s books as audiobooks and this is certainly an area where audio is a much worse medium than paper. You just don&#x27;t get any bells ringing from the looks of words. reply missedthecue 6 hours agoparentprev10&#x2F;24It got to the point that I was saying \"ok this one has to be a trap\" reply AdamJacobMuller 6 hours agoparentprevI felt bad about getting 12&#x2F;24 which is basically \"randomly guessing,\" somehow you did worse than random :D reply xivzgrev 3 hours agoprev18&#x2F;24 - at some point there was a certain pattern to the medications. But then it broke and I got 4 in a row wrong reply g-b-r 5 hours agoprevHow not finishing the Silmarillion comes back to bite you reply bigmattystyles 6 hours agoprevReminds me of this https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=UPx_X3DjXy8 reply throwanem 5 hours agoprevSildenafil isn&#x27;t an antidepressant. reply nwienert 5 hours agoparentSide effects may be though ;) reply kstrauser 3 hours agorootparentCall a doctor if it lifts your spirits for more than 4 hours. reply afarviral 5 hours agoprevIf you got a good score, was it due to drug or tolkien knowledge? Or evenly both? reply CodeMage 5 hours agoparentTolkien, in my case. In fact, I was a bit bummed out that I got 23&#x2F;24. reply cl0ckt0wer 6 hours agoprevCledíal got me reply munchler 5 hours agoparentMe too, although it&#x27;s actually \"Clédial\". I was certain no one would market a drug with an accented character in the US. reply nindalf 5 hours agoprev21&#x2F;24.I’ll atone by re-reading now. reply hdhdhegdv 6 hours agoprevWtf I got sildenafil which isn’t an antidepressant or tolkien reply redox99 5 hours agoparentFunny you got flagged by what I assume is a viagra spam bot check. reply asimpleusecase 4 hours agoprev20 out of 24 not too bad. reply TOGoS 5 hours agoprevHaving recently listened to the Lord of the Rings audiobooks (the read by Andy Serkis ones) I thought this was going to be about escaping into fantasy novels as a way of keeping oneself sane without having to resort to drugs. I also found them to be one of the only effective means of occupying my mind as I was trying to fall asleep so that I didn&#x27;t ruminate myself into insomnia, which of course would leave me in a worse mood the next day. reply trs83 6 hours agoprevThis is beautiful. reply speed_spread 6 hours agoprevWhy not both? Speedrun the damned ring back to fucking Mordor. Up yours, Sauron! reply leed25d 6 hours agoprev [–] Enigma replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The game challenges players to distinguish whether a given word is an antidepressant medication or a character from J.R.R. Tolkien's works.",
      "It underscores an intersection of literature and pharmaceutical nomenclature, giving players a unique learning experience.",
      "The game's peculiar concept stands out, making it an interesting topic for both Tolkien enthusiasts and those intrigued by pharmaceutical terms."
    ],
    "commentSummary": [
      "The article discusses an interesting game centered around the challenge of distinguishing between names of antidepressant medications and characters from J.R.R. Tolkien's works.",
      "It serves as a quirky yet compelling examination of both pop culture and pharmaceutical terminologies.",
      "It draws an unexpected parallel between two vastly different realms: literary fantasy and medical science."
    ],
    "points": 381,
    "commentCount": 80,
    "retryCount": 0,
    "time": 1699412000
  },
  {
    "id": 38181346,
    "title": "Optimizing Go Applications in Containers: The Role of Linux Scheduler and CPU Limits",
    "originLink": "https://www.riverphillips.dev/blog/go-cfs/",
    "originBody": "Nov 4, 2023 Last updated on Nov 7, 2023 Go, Containers, and the Linux Scheduler Like many Go developers my applications are usually deployed in containers. When running in container orchestrators it’s important to set CPU limits to ensure that the container doesn’t consume all the CPU on the host. However, the Go runtime is not aware of the CPU limits set on the container and will happily use all the CPU available. This has bitten me in the past, leading to high latency, in this blog I’ll explain what is going on and how to fix it. How the Go Garbage Collector works This is going to be a pretty high level overview of the Go Garbage Collector (GC). For a more in depth overview I recommend reading the go docs and this excellent series of blogs by Will Kennedy. The vast majority of the time the Go runtime performs garbage collection concurrently with the execution of your program. This means that the GC is running at the same time as your program. However, there are two points in the GC process where the Go runtime needs to stop every Goroutine. This is required to ensure data integrity. Before the Mark Phase of the GC the runtime stops every Goroutine to apply the write barrier, this ensures no objects created after this point are garbage collected. This phase is known as Sweep Termination. After the mark phase has finished there is another stop the world phase, this is known as Mark Termination and the same process happens to remove the write barrier. These usually takes in the order of tens of microseconds. I created a simple web application that allocates a lot of memory and ran it in a container with a limit of 4 CPU cores with the following command.The Source code for this is available here. docker run --cpus=4 -p 8080:8080 $(ko build -L main.go) It’s worth noting the docker CPU limit is a soft limit, meaning it’s only enforced when the host is CPU constrained. This means that the container can use more than 4 CPU cores if the host has spare capacity. You can collect a trace using the runtime/trace package then analyze it with go tool trace. The following trace shows a GC cycle captured on my machine. You can see the Sweep Termination and the Mark Termination stop the world phase on Proc 5 (They’re labelled STW for stop the world). This GC cycle took just under 2.5ms, but we spent almost 10% of that in a stop the world phase. This is a pretty significant amount of time, especially if you are running a latency sensitive application. The Linux Scheduler The Completely Fair Scheduler (CFS) was introduced in Linux 2.6.23 and was the default Scheduler until Linux 6.6 which was released last week. It’s likely you’re using the CFS. The CFS is a proportional share scheduler, this means that the weight of a process is proportional to the number of CPU cores it is allowed to use. For example, if a process is allowed to use 4 CPU cores it will have a weight of 4. If a process is allowed to use 2 CPU cores it will have a weight of 2. The CFS does this by allocating a fraction of CPU time. A 4 core system has 4 seconds of CPU time to allocate every second. When you allocate a container a number of CPU cores you’re essentially asking the Linux Scheduler to give it n CPUs worth of time. In the above docker run command I’m asking for 4 CPUs worth of time. This means that the container will get 4 seconds of CPU time every second. The Problem When the Go runtime starts it creates an OS thread for each CPU core. This means if you have a 16 core machine the Go runtime will create 16 OS threads - regardless of any CGroup CPU Limits. The Go runtime then uses these OS threads to schedule goroutines. The problem is that the Go runtime is not aware of the CGroup CPU limits and will happily schedule goroutines on all 16 OS threads. This means that the Go runtime will expect to be able to use 16 seconds of CPU time every second. Long stop the world durations arise from the Go runtime needing to stop Goroutine on threads that it’s waiting for the Linux Scheduler to schedule. These threads will not be scheduled once the container has used it’s CPU quota. The Solution Go allows you to limit the number of CPU threads that the runtime will create using the GOMAXPROCS environment variable. This time I used the following command to start the container docker run --cpus=4 -e GOMAXPROCS=4 -p 8080:8080 $(ko build -L main.go) Below is a trace captured from the same application as above, now with the GOMAXPROCS environment variable matching the CPU quota. In this trace, the garbage collection is much shorter, despite having the exact same load. The GC Cycle took under 1ms and the stop the world phase was 26μs, approximately 1/10 of the time when there was no limit. GOMAXPROCS should be set to the number of CPU cores that the container is allowed to use, if you’re allocating fractional CPU round down, unless you’re allocating less than 1 CPU core in which case round up. GOMAXPROCS=max(1, floor(CPUs)) can be used to calculate the value. If you find it easier Uber has open sourced a library automaxprocs to calculate this value for you from your container’s cgroups automatically. There’s an outstanding Github Issue with the Go runtime to support this out the box so hopefully it will be added eventually! Conclusion When running Go in a containerised application it’s important to set CPU limits. It’s also important to ensure that the Go runtime is aware of these limits by setting a sensible GOMAXPROCS value or using a library like automaxprocs.",
    "commentLink": "https://news.ycombinator.com/item?id=38181346",
    "commentBody": "Go, Containers, and the Linux SchedulerHacker NewspastloginGo, Containers, and the Linux Scheduler (riverphillips.dev) 295 points by rbanffy 14 hours ago| hidepastfavorite107 comments otterley 4 hours agoThis sort of tuning isn&#x27;t necessary if you use CPU reservations instead of limits, as you should: https:&#x2F;&#x2F;home.robusta.dev&#x2F;blog&#x2F;stop-using-cpu-limitsCPU reservations are limits, just implicit ones and declared as guarantees.So let the Go runtime use all the CPUs available, and let the Linux scheduler throttle according to your declared reservations if the CPU is contended for. reply ithkuil 2 hours agoparentI don&#x27;t set limits because I&#x27;m afraid of how a pod is going to affect other pods. I set limits because I don&#x27;t want to get used to being able to tap on the excess CPU available because that&#x27;s not guaranteed to be available.As the node fills up with more and more other pods, it&#x27;s possible that a pod that was running just fine a moment ago is crawling to a halt.Limits allow me to simulate the same behavior and plan for it by doing the right capacity planning.They are not the only way to approach it! But they are the simplest way to so it. reply eloisant 1 hour agorootparentThat&#x27;s why you use monitor and alerting, so you notice degraded performances before the pods is crawling to a halt.You need to do it anyway because a service might progressively need more resources as it&#x27;s getting more traffic, even if you&#x27;re not adding any other pod. reply ithkuil 20 minutes agorootparentSure you need monitoring and alerting and sure there are other reasons why you need to update your requests.But having _neighbours_ affecting the behaviour of your workload is precisely what creates the kind of fatigue that then results in people claiming that it&#x27;s hard to run k8s workloads. K8s is highly dynamical, pods can get scheduled on a node by chance sometimes and on some clusters; pagers will ring, incidents will be created for conditions that may solve them selves because of another deployment (possibly of another team happening).Overcommit&#x2F;bursting is an advanced cost saving feature.Let me say it again: splitting up a large machine into smaller parts that can use the unused capacity of other parts in order to reduce waste is an advanced feature!The problem is that the request&#x2F;limits feature is presented in the configuration spec and in the documentation in a deceptively simple way and we&#x27;re tricked to think it&#x27;s a basic feature.Not all companies have ops teams that are well equipped to do more sophisticated things. My advice for those teams who cannot setup full automation around capacity management is to just not use this advanced features.An alternative is to just use smaller dedicated nodes and (anti)affinity rules, so you always understand which pods go with which other pods. It&#x27;s clunky but it&#x27;s actually easier to reason about what&#x27;s going to happen. reply yipbub 3 hours agoparentprevInteresting. This is not true for Memory, correct? The OOMKiller might get you.You also cannot achieve a QoS class of Guaranteed without both CPU and Memory limits, so the pod might be evicted at some point. reply dilyevsky 3 hours agorootparentCorrect regarding memory - not true for memory because it&#x27;s non-fungible unlike CPU shares> You also cannot achieve a QoS class of Guaranteed without both CPU and Memory limits, so the pod might be evicted at some point.Evicted due to node pressure - yes (but if all other pods also don&#x27;t have limits it doesn&#x27;t matter). For preemption QoS is not factored in the decision [0][0] - https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;scheduling-eviction&#x2F;pod-... reply iTokio 2 hours agorootparentprev> Memory is different because it is non-compressible - once you give memory you can&#x27;t take it away without killing the process reply kubiton 2 hours agoparentprevI run a few things on 128 core setups and I set CPU limits to much higher than request but still set them to make sure nothing runs ammok.I would be curious to see this discussed but your article only states that people think you need limit to ensure CPU for all pods. reply dekhn 13 hours agoprevThe common problem I see across many languages is: applications detect machine cores by looking at &#x2F;proc&#x2F;cpuinfo. However, in a docker container (or other container technology), that file looks the same as the container host (listing all cores, regardless of how few have been assigned to the container).I wondered for a while if docker could make a fake &#x2F;proc&#x2F;cpuinfo that apps could parse that just listed \"docker cpus\" allocated to the job, but upon further reflection, that probably wouldn&#x27;t work for many reasons. reply dharmab 12 hours agoparentPoint of clarification: Containers, when using quota based limits, can use all of the CPU cores on the host. They&#x27;re limited in how much time they can spend using them.(There are exceptions, such as documented here: https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;tasks&#x2F;administer-cluster&#x2F;cpu-mana...) reply dekhn 12 hours agorootparentMaybe I should be clearer: Let&#x27;s say I have a 16 core host and I start a flask container with cpu=0.5 that forks and has a heavy post-fork initializer.flask&#x2F;gunicorn will fork 16 processes (by reading &#x2F;proc&#x2F;cpuinfo and counting cores) all of which will try to share 0.5 cores worth of CPU power (maybe spread over many physical CPUs; I don&#x27;t really care about that).I can solve this by passing a flag to my application; my complaint is more that apps shouldn&#x27;t consult &#x2F;proc&#x2F;cpuinfo, but have another standard interface to ask \"what should I set my max parallelism (NOT CONCURRENCY, ROB) so my worker threads get adequate CPU time so the framework doesn&#x27;t time out on startup. reply Volundr 11 hours agorootparentIt&#x27;s not clear to me what the max parallelism should actually be on a container with a CPU limit of .5. To my understanding that limits CPU time the container can use within a certain time interval, but doesn&#x27;t actually limit the parallel processes an application can run. In other words that container with .5 on the CPU limit can indeed use all 16 physical cores of that machine. It&#x27;ll just burn through it&#x27;s budget 16x faster. If that&#x27;s desirable vs limiting itself to one process is going to be highly application dependent and not something kubernetes and docker can just tell you. reply FridgeSeal 58 minutes agorootparentIt won’t burn through the budget faster by having more cores. You’re given a fixed time-slice of the whole CPU (in K8s, caveats below), whether you use all the cores or just one doesn’t particularly matter. On one hand, it would be would nice to be able to limit workloads on K8s to a subset of cores too, on the other, I can only imagine how much catastrophically complex that would make scheduling and optimisation.Caveats: up to the number of cores exposed to your VM. I also believe the later versions of K8s let you do some degree of workload-core pinning and I don’t yet know how that interacts with core availability . reply dharmab 8 hours agorootparentprevThat interface partly exists. It&#x27;s &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;(cgroup here)&#x2F;cpu.maxI know the JVM automatically uses it, and there&#x27;s a popular library for Go that sets GONAXPROCS using it. reply status_quo69 12 hours agorootparentprevhttps:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;65551215&#x2F;get-docker-cpu-...Been a bit but I do believe that dotnet does this exact behavior. Sounds like gunicorn needs a pr to mimic, if they want to replicate this.https:&#x2F;&#x2F;github.com&#x2F;dotnet&#x2F;runtime&#x2F;issues&#x2F;8485 reply vbezhenar 10 hours agorootparentprevYou generally shouldn&#x27;t set CPU limits. You might want to configure CPU requests which is guaranteed chunk of CPU time that container will always receive. With CPU limits you&#x27;ll encounter situation when host CPU is not loaded, but your container workloaded is throttled at the same time, which is just waste of CPU resources. reply dekhn 8 hours agorootparentIt&#x27;s complicated. I&#x27;ve worked on every kind of application in a container environment: ones that ran at ultra-low priority while declaring zero CPU request and infinite CPU limit. I ran one or a few of these on nearly every machine in Google production for over a year, and could deliver over 1M xeon cores worth of throughput for embarassingly parallel jobs. At other times, I ran jobs that asked for and used precisely all the cores on a machine (a TPU host), specifically setting limits and requests to get the most predictable behavior.The true objective function I&#x27;m trying to optimize isn&#x27;t just \"save money\" or \"don&#x27;t waste CPU resources\", but rather \"get a million different workloads to run smoothly on a large collection of resources, ensuring that revenue-critical jobs always can run, while any spare capacity is available for experimenters, up to some predefined limits determined by power capacity, staying within the overall budget, and not pissing off any really powerful users.\" (well, that&#x27;s really just a simplified approximation) reply jeffbee 8 hours agorootparentThe problem is your experience involves a hacked up Linux that was far more suitable for doing this than is the upstream. Upstream scheduler can&#x27;t really deal with running a box hot with mixed batch and latency-sensitive workloads and intentionally abusive ones like yours ;-) That is partly why kubernetes doesn&#x27;t even really try. reply dilyevsky 5 hours agorootparentThis. Some googlers forget there is a whole team of kernel devs in TI that are maintaining patched kernel (including patched CFS) specifically for Borg reply lovasoa 10 hours agorootparentprevAccording to the article, this is not true. The limits become active only when the host cpu is under pressure. reply vbezhenar 9 hours agorootparentI don&#x27;t think that&#x27;s correct. --cpus is the same as --cpu-period which is cpu limit. You can easily check it yourself, just run docker container with --cpus set, run multi-core load there and check your activity monitor. reply pbh101 8 hours agorootparentCFS quotas only become active under contention and even then are relative: if you’re the only thing running on the box and want all the cores but only set one cpu, you get all of them anyway.If you set cpus to 2 and another process sets to 1 and you both try to use all CPUs all out, you’ll get 66% and they’ll get 33%.This isn’t the same as cpusets, which work differently. reply ecnahc515 6 hours agorootparent> CFS quotas only become active under contentionThat&#x27;s not true at all. Take a look at `cpu.cfs_quota_us` in https:&#x2F;&#x2F;kernel.googlesource.com&#x2F;pub&#x2F;scm&#x2F;linux&#x2F;kernel&#x2F;git&#x2F;glo...It&#x27;s a hard time limit. It doesn&#x27;t care about contention at all.`cpu.shares` is relative, for choosing which process gets scheduled, and how often, but the CFS quota is a hard limit on runtime. reply usr1106 4 hours agorootparentYes, there are hard limits in the CFS. I have used them for thermal reasons in the past, such that the system remained mostly idle although some threads would have had more work to do.Not at my work environment right now, don&#x27;t remember the parameters I used. replywutwutwat 9 hours agorootparentprev`gunicorn --workers $(nproc)`, see my comment on the parent reply wutwutwat 9 hours agoparentprevI only use `nproc` and see it used in other containers as well, ie `bundle install -j $(nproc)`. This honors cpu assignment and provides the functionality you&#x27;re seeking. Whether or not random application software uses nproc if available, idk> Print the number of processing units available to the current process, which may be less than the number of online processors. If this information is not accessible, then print the number of processors installedhttps:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;coreutils&#x2F;manual&#x2F;html_node&#x2F;npro...https:&#x2F;&#x2F;www.flamingspork.com&#x2F;blog&#x2F;2020&#x2F;11&#x2F;25&#x2F;why-you-should-... reply telotortium 9 hours agorootparentThis is not very robust. You probably should use the cgroup cpu limits where present, since `docker --cpus` uses a different way to set quota: if [[ -e &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;cpu.cfs_quota_us ]] && [[ -e &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;cpu.cfs_period_us ]]; then GOMAXPROCS=$(perl -e &#x27;use POSIX; printf \"%d\\n\", ceil($ARGV[0] &#x2F; $ARGV[1])&#x27; \"$(cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;cpu.cfs_quota_us)\" \"$(cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;cpu.cfs_period_us)\") else GOMAXPROCS=$(nproc) fi export GOMAXPROCSThis follows from how `docker --cpus` works (https:&#x2F;&#x2F;docs.docker.com&#x2F;config&#x2F;containers&#x2F;resource_constrain...), as well as https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;65554131&#x2F;207384 to get the &#x2F;sys paths to read from.Or use https:&#x2F;&#x2F;github.com&#x2F;uber-go&#x2F;automaxprocs, which is very comprehensive, but is a bunch of code for what should be a simple task. reply fn-mote 6 hours agorootparentA shell script that invokes perl to set an environment variable used by Go. Some days I feel like there is a lot of duct tape involved in these applications. reply jeffbee 12 hours agoparentprevThat&#x27;s not what Go does though. Go looks at the population of the CPU mask at startup. It never looks again, which of problematic in K8s where the visible CPUs may change while your process runs. reply sethammons 10 hours agorootparentWe use https:&#x2F;&#x2F;github.com&#x2F;uber-go&#x2F;automaxprocs after we joyfully discovered that Go assumed we had the entire cluster&#x27;s cpu count on any particular pod. Made for some very strange performance characteristics in scheduling goroutines. reply jeffbee 9 hours agorootparentMy opinion is that setting GOMAXPROCS that way is a quite poor idea. It tends to strand resources that could have been used to handle a stochastic burst of requests, which with a capped GOMAXPROCS will be converted directly into latency. I can think of no good reason why GOMAXPROCS needs to be 2 just because you expect the long-term CPU rate to be 2. That long-term quota is an artifact of capacity planning, while GOMAXPROCS is an artifact of process architecture. reply n3t 9 hours agorootparentprev> which of problematic in K8s where the visible CPUs may change while your process runsThis is new to me. What is this… behavior? What keywords should I use to find any details about it?The only thing that rings a bell is requests&#x2F;limit parameters of a pod but you can&#x27;t change them on an existing pod AFAIK. reply djbusby 8 hours agorootparentEven way back in the day (1996) it was possible to hot-swap a CPU. Used to have this Sequent box, 96 Pentiums in there, 6 on a card. Could do some magic, pull the card and swap a new one in. Wild. And no processes died. Not sure if a process could lose a CPU then discover the new set. reply jeffbee 9 hours agorootparentprevIf you have one pod that has Burstable QoS, perhaps because it has a request and not a limit, its CPU mask will be populated by every CPU on the box, less one for the Kubelet and other node services, less all the CPUs requested by pods with Guaranteed QoS. Pods with Guaranteed QoS will have exactly the number of CPUs they asked for, no more or less, and consequently their GOMAXPROCS is consistent. Everyone else will see fewer or more CPUs as Guaranteed pods arrive and depart from the node. reply n3t 6 hours agorootparentIf by \"CPU mask\" you refer to the `sched_getaffinity` syscall, I can&#x27;t reproduce this behavior.What I tried: I created a \"Burstable\" Pod and run `nproc` [0] on it. It returned N CPUs (N > 1).Then I created a \"Guaranteed QoS\" Pod with both requests and limit set to 1 CPU. `nproc` returned N CPUs on it.I went back to the \"Burstable\" Pod. It returned N.I created a fresh \"Burstable\" Pod and run `nproc` on it, got N again. Please note that the \"Guaranteed QoS\" Pod is still running.> Pods with Guaranteed QoS will have exactly the number of CPUs they asked for, no more or lessWell, in my case I asked for 1 CPU and got more, i.e. N CPUs.Also, please note that Pods might ask for fractional CPUs.[0]: coreutils `nproc` program uses `sched_getaffinity` syscall under the hood, at least on my system. I&#x27;ve just checked it with `strace` to be sure. reply jeffbee 6 hours agorootparentI don&#x27;t know what nproc does. Consider `taskset` reply n3t 5 hours agorootparentI re-did the experiment again with `taskset` and got the same results, i.e. the mask is independent of creation of the \"Guaranteed QoS\" Pod.FWIW, `taskset` uses the same syscall as `nproc` (according to `strace`). reply jeffbee 5 hours agorootparentPerhaps it is an artifact of your and my various container runtimes. For me, in a guaranteed qos pod, taskset shows just 1 visible CPU for a Guaranteed QoS pod with limit=request=1. # taskset -c -p 1 pid 1&#x27;s current affinity list: 1 # nproc 1I honestly do not see how it can work otherwise. reply n3t 5 hours agorootparentAfter reading https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;tasks&#x2F;administer-cluster&#x2F;cpu-mana..., I think we have different policies set for the CPU Manager.In my case it&#x27;s `\"cpuManagerPolicy\": \"none\"` and I suppose you&#x27;re using `\"static\"` policy.Well, TIL. Thanks! replydekhn 12 hours agorootparentprevWhat is the population of the CPU mask at startup? Is this a kernel call? A &#x2F;proc file? Some register? reply EdSchouten 12 hours agorootparentOn Linux, it likely calls sched_getaffinity(). reply dekhn 12 hours agorootparenthmm, I can see that as being useful but I also don&#x27;t see that as the way to determine \"how many worker threads I should start\" reply jeffbee 12 hours agorootparentIt&#x27;s not a bad way to guess, up to maybe 16 or so. Most Go server programs aren&#x27;t going to just scale up forever, so having 188 threads might be a waste.Just setting it to 16 will satisfy 99% of users. reply dekhn 12 hours agorootparentThere&#x27;s going to be a bunch of missing info, though, in some cases I can think of. For example, more and more systems have asymmetric cores. &#x2F;proc&#x2F;cpuinfo can expose that information in detail, including (current) clock speed, processor type, etc, while cpu_set is literally just a bitmask (if I read the man pages right) of system cores your process is allowed to schedule on.Fundamentally, intelligent apps need to interrogate their environment to make concurrency decisions. But I agree- Go would probably work best if it just picked a standard parallelism constant like 16 and just let users know that can be tuned if they have additional context. reply jeffbee 12 hours agorootparentYes, running on a set of heterogenous CPUs presents further challenges, for the program and the thread scheduler. Happily there are no such systems in the cloud, yet.Most people are running on systems where the CPU capacity varies and they haven&#x27;t even noticed. For example in EC2 there are 8 victim CPUs that handle all the network interrupts, so if you have an instance type with 32 CPUs, you already have 24 that are faster than the others. Practically nobody even notices this effect. reply loxias 10 hours agorootparent> in EC2 there are 8 victim CPUs that handle all the network interrupts, so if you have an instance type with 32 CPUs, you already have 24 that are faster than the othersFascinating. Could you share any (all) more detail on this that you know? Is it a specific instance type, only ones that use nitro? (or only ones without?) This might be related to a problem I&#x27;ve seen in the wild but never tracked down... reply jeffbee 8 hours agorootparentI&#x27;ve only observed it on Nitro, but I have also rarely used pre-Nitro instances. replyrrdharan 9 hours agoparentprevContainers are a crappy abstraction and VMware fumbled the bag, is my takeaway from this comment… reply sofixa 2 hours agorootparent> VMware fumbled the bagOh they did, they&#x27;re a modern day IBM.> Containers are a crappy abstractionThey&#x27;re one of the best abstractions we have (so far) because they contain only the application and what it needs. reply dilyevsky 13 hours agoprevThis is subtly incorrect - as far as Docker is concerned CFS cgroup extension has several knobs to tune - cfs_quota_us, cfs_period_us (typical default is 100ms not a second) and shares. When you set shares you get weighted proportional scheduling (but only when there&#x27;s contention). The former two enforce strict quota. Don&#x27;t use Docker&#x27;s --cpu flag and instead use --cpu-shares to avoid (mostly useless) quota enforcement.From Linux docs: - cpu.shares: The weight of each group living in the same hierarchy, that translates into the amount of CPU it is expected to get. Upon cgroup creation, each group gets assigned a default of 1024. The percentage of CPU assigned to the cgroup is the value of shares divided by the sum of all shares in all cgroups in the same level. - cpu.cfs_period_us: The duration in microseconds of each scheduler period, for bandwidth decisions. This defaults to 100000us or 100ms. Larger periods will improve throughput at the expense of latency, since the scheduler will be able to sustain a cpu-bound workload for longer. The opposite of true for smaller periods. Note that this only affects non-RT tasks that are scheduled by the CFS scheduler. - cpu.cfs_quota_us: The maximum time in microseconds during each cfs_period_us in for the current group will be allowed to run. For instance, if it is set to half of cpu_period_us, the cgroup will only be able to peak run for 50 % of the time. One should note that this represents aggregate time over all CPUs in the system. Therefore, in order to allow full usage of two CPUs, for instance, one should set this value to twice the value of cfs_period_us. reply cpuguy83 13 hours agoparent> \"Don&#x27;t use Docker&#x27;s --cpu flag and instead use\"This is rather strong language without any real qualifiers. It is definitely not \"mostly useless\". Shares and quotas are for different use-cases, that&#x27;s all. Understand your use-case and choose accordingly. reply dilyevsky 11 hours agorootparentIt doesn’t make any sense to me why —cpu flag is tweaking quota and not shares since quota is useful in tiny minority of usecases. A lot of people waste a ton of time debugging weird latency issues as a result of this decision reply the8472 11 hours agorootparentWith shares you&#x27;re going to experience worse latency if all the containers on the system size their thread pool to the maximum that&#x27;s available during idle periods and then constantly context-switch due to oversubscription under load. With quotas you can do fixed resource allocation and the runtimes (not Go apparently) can fit themselves into that and not try to service more requests than they can currently execute given those resources. reply dilyevsky 8 hours agorootparentAnd how is that different from worse latency due to cpu throttling from your users’ perspective? reply the8472 47 minutes agorootparentFixed queue, so it&#x27;ll only take as many as it can process and reject the rest, which can be used to do scaling, if you have a cluster. With shares it would think it has all the CPU cores available and oversize the queue. reply cpuguy83 8 hours agorootparentprevThese two options are not mutually exclusive.When you want to limit the max CPU time available to a container use quotas (--cpus). When you want to set relative priorities (compared to other containers&#x2F;processes), use shares.These two options can be combined, it all depends on what you need. reply mratsim 13 hours agoparentprev> Don&#x27;t use Docker&#x27;s --cpu flag and instead use --cpu-shares to avoid (mostly useless) quota enforcement.One caveat is that an application can detect when --cpu is used as I think it&#x27;s using cpuset. When quota are used it cannot detect and more threads than necessary will likely be spawned reply cpuguy83 13 hours agorootparentIt is not using cpuset (there is a separate flag for this). --cpus tweaks the cfs quota based on the number of cpus on the system and the requested amount. reply dilyevsky 12 hours agorootparentprev—cpu sets the quota, there is is a —cpuset-cpu flag for cpuset and you can detect both by looking at the &#x2F;sys&#x2F;fs&#x2F;cgroup reply riv991 13 hours agoparentprevHi I&#x27;m the blog author, thanks for the feedbackI&#x27;ll try and clarify this. I think this is how the sympton presents but I should be clearer. reply Thaxll 13 hours agoparentprevPeople using Kubernetes don&#x27;t tune or change those settings, it&#x27;s up to the app to behave properly. reply dilyevsky 13 hours agorootparentFalse. Kubernetes cpu request sets the shares, cpu limit sets the cfs quota reply Thaxll 13 hours agorootparentYou said to change docker flags. Anyway your post is irrelevant, the goal is to let know the runtime about how many posix threads should it use.If you set request &#x2F; limit to 1 core but you run on 64 cores node , then you runtime will see that which will bring performance down. reply dilyevsky 13 hours agorootparentOriginal article is about docker. That’s the point of my comment - dont set cpu limit reply riv991 12 hours agorootparentI intended it to be applicable to all containerised environments. Docker is just easiest on my local machine.I still believe it&#x27;s best to set these variables regardless of cpu limits and&#x2F;or cpu shares reply dilyevsky 12 hours agorootparentAll you did is kneecapped your app to have lower performance so it fits under your arbitrary limit. Hardly what most people describe as “best” - only useful in small percentage of usecases (like reselling compute) reply riv991 11 hours agorootparentI&#x27;ve seen significant performance gains from this in production.Other people have encountered it too hence libraries like Automaxprocs existing and issues being open with Go for it. reply dilyevsky 3 hours agorootparentGains by what metric? Are you sure you didn&#x27;t trade in better latency for worse overall throughput? Also, sure you didn&#x27;t hit one of many CFS overaccounting bugs which we&#x27;ve seen a few? Have you compared performance without the limit at all? replyntonozzi 14 hours agoprevI&#x27;ve been bitten many times by the CFS scheduler while using containers and cgroups. What&#x27;s the new scheduler? Has anyone here tried it in a production cluster? We&#x27;re now going on two decades of wasted cores: https:&#x2F;&#x2F;people.ece.ubc.ca&#x2F;sasha&#x2F;papers&#x2F;eurosys16-final29.pdf. reply the8472 11 hours agoparentThe problem here isn&#x27;t the scheduler. It&#x27;s resource restrictions imposed by the container but the containerized process (Go) not checking the OS features used to do that when calculating the available amount of parallelism. reply donaldihunter 13 hours agoparentprevhttps:&#x2F;&#x2F;kernelnewbies.org&#x2F;Linux_6.6#New_task_scheduler:_EEVD... reply rickette 13 hours agoprevBesides GOMAXPROCS there&#x27;s also GOMEMLIMIT in recent Go releases. You can use https:&#x2F;&#x2F;github.com&#x2F;KimMachineGun&#x2F;automemlimit to automatically set this this limit, kinda like https:&#x2F;&#x2F;github.com&#x2F;uber-go&#x2F;automaxprocs. reply gregfurman 13 hours agoprevDiscovered this sometime last year in my previous role as a platform engineer managing our on-prem kubernetes cluster as well as the CI&#x2F;CD pipeline infrastructure.Although I saw this dissonance between actual and assigned CPU causing issues, particularly CPU throttling, I struggled to find a scalable solution that would affect all Go deployments on the cluster.Getting all devs to include that autoprocs dependency was not exactly an option for hundreds of projects. Alternatively, setting all CPU request&#x2F;limit to a whole number and then assigning that to a GOMAXPROCS environment variable in a k8s manifest was also clunky and infeasible.I ended up just using this GOMAXPROCS variable for some of our more highly multithreaded applications which yielded some improvements but I’ve yet to find a solution that is applicable to all deployments in a microservices architecture with a high variability of CPU requirements for each project. reply linuxftw 12 hours agoparentYou could define a mutating webhook to inject GOMAXPROCS into all pod containers. reply jeffbee 12 hours agoparentprevThere isn&#x27;t one answer for this. Capping GOMAXPROCS may cause severe latency problems if your process gets a burst of traffic and has naive queueing. It&#x27;s best really to set GOMAXPROCS to whatever the hardware offers regardless of your ideas about how much time the process will use on average. reply irogers 4 hours agoprevThere are also GC techniques to make the pause shorter, for example, doing the work for the pause concurrently and then repeating it in the safepoint. The hope is that the concurrent work will turn the safepoint work into a simpler check that no work is necessary. Doubling the work may hurt GC throughput. reply Ayushmishra23 11 minutes agoprevTest reply ImJasonH 13 hours agoprevThanks for sharing this!And as a maintainer of ko[1], it was a pleasant surprised to see ko mentioned briefly, so that&#x27;s for that too :)1: https:&#x2F;&#x2F;ko.build reply perryizgr8 22 minutes agoprevIsn&#x27;t this a bug in the Go runtime and shouldn&#x27;t they fix it? It looks like they are using the wrong metric to tune the internal scheduler. reply bruh2 12 hours agoprevAs someone not that familiar with Docker or Go, is this behavior intentional? Could the Go team make it aware of the CGroups limit? Do other runtimes behave similarly? reply eloisant 1 hour agoparentYes, I&#x27;ve experienced the same problem with the JVM (in Scala). reply yjftsjthsd-h 11 hours agoparentprevI&#x27;m fairly certain that that .net had to deal with it and Java had or still has a problem, I forget which. (Or did you mean runtimes like containerd?) reply richdougherty 5 hours agorootparentSupported in Java 10 (and backported to Java 8) since 2018. Not sure about .NET.- \"The JVM has been modified to be aware that it is running in a Docker container and will extract container specific configuration information instead of querying the operating system. The information being extracted is the number of CPUs and total memory that have been allocated to the container.\" https:&#x2F;&#x2F;www.oracle.com&#x2F;java&#x2F;technologies&#x2F;javase&#x2F;8u191-relnot...- Here&#x27;s a more detailed explanation and even a shared library that can be used to patch container unaware versions of Java. I wonder if the same could be done for Go?\"LD_PRELOAD=&#x2F;path&#x2F;to&#x2F;libproccount.so java \"https:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;64271429https:&#x2F;&#x2F;gist.github.com&#x2F;apangin&#x2F;78d7e6f7402b1a5da0fa3abd9381...-There are more recent changes to Java container awareness as well:https:&#x2F;&#x2F;developers.redhat.com&#x2F;articles&#x2F;2022&#x2F;04&#x2F;19&#x2F;java-17-wh... reply jpolidor 8 minutes agorootparentThen in Java, if you don&#x27;t set the limits, it gets the CPU from the VM via Runtime.getRuntime().availableProcessors()... this method returns the number of CPUs of the VM or the value set as CPU Quota. Starting from Java 11 the -XX:+PreferContainerQuotaForCPUCount is by default true. For JavaOSes are still better than container runtimes at managing competing processes on the same host.OSes and container runtimes are the same thing reply marcus_holmes 2 hours agorootparent> OSes and container runtimes are the same thingFor a subset of OSes reply marcus_holmes 2 hours agorootparentprev [–] Go binaries tend not to be that lightweight, because we have goroutines for that.And yes, setting up a separate VM for each instance of a process is perfectly feasible. That&#x27;s what all this cloud business was about in the first place. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post highlights the necessity of setting CPU limits in container orchestrators when running applications to avoid utilizing all the CPU power of the host.",
      "In-depth information about the Go Garbage Collector process, the role of the Linux Scheduler, and the importance of controlling CPU threads through the GOMAXPROCS environment variable is provided.",
      "Uber has introduced the 'automaxprocs' library, which automatically calculates the GOMAXPROCS value from the container's cgroups, simplifying its setup while running Go in containerized applications."
    ],
    "commentSummary": [
      "The Go developer in the blog stresses the importance of setting CPU limits in container orchestrators to avoid high CPU consumption on the host, since Go runtime tends to use all available CPU power, potentially causing high latency.",
      "The author advises controlling the number of CPU threads the Go runtime can create by using the GOMAXPROCS environment variable, which aligns with the CPU quota.",
      "Uber has created the 'automaxprocs' library that computes this environment variable value from the container's cgroups automatically, catering to the necessity of sensible GOMAXPROCS assignment when running Go in containerized applications."
    ],
    "points": 295,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1699384204
  },
  {
    "id": 38183454,
    "title": "Introducing Gleam: A Concurrent, User-friendly Programming Language on Erlang Runtime",
    "originLink": "https://gleam.run/",
    "originBody": "The power of a type system, the expressiveness of functional programming, and the reliability of the highly concurrent, fault tolerant Erlang runtime, with a familiar and modern syntax. import gleam/io pub fn main() { io.println(\"hello, friend!\") } Kindly supported by Reliable and scalable Running on the battle-tested Erlang virtual machine that powers planet-scale systems such as WhatsApp and Ericsson, Gleam is ready for workloads of any size. Thanks to a multi-core actor based concurrency system that can run millions of concurrent tasks, fast immutable data structures, and a concurrent garbage collector that never stops the world, your service can scale and stay lightning fast with ease. fn spawn_task(i) { task.async(fn() { let n = int.to_string(i) io.println(\"Hello from \"n) }) } pub fn main() { // Run loads of threads, no problem list.range(0, 200_000) |> list.map(spawn_task) |> list.each(task.await_forever) } Ready when you are Gleam comes with compiler, build tool, formatter, editor integrations, and package manager all built in, so creating a Gleam project is just running gleam new. As part of the wider BEAM ecosystem, Gleam programs can use thousands of published packages, whether they are written in Gleam, Erlang, or Elixir. ➜ (main) gleam add gleam_json Resolving versions Downloading packages Downloaded 2 packages in 0.01s Added gleam_json v0.5.0 ➜ (main) gleam test Compiling thoas Compiling gleam_json Compiling app Compiled in 1.67s Running app_test.main . 1 tests, 0 failures Here to help No null values, no exceptions, clear error messages, and a practical type system. Whether you're writing new code or maintaining old code, Gleam is designed to make your job as fun and stress-free as possible. error: Unknown record field ┌─ ./src/app.gleam:8:16 │ 8 │ user.alias │ ^^^^^^ Did you mean `name`? The value being accessed has this type: User It has these fields: .name Multilingual Gleam makes it easy to use code written in other BEAM languages such as Erlang and Elixir, so there's a rich ecosystem of thousands of open source libraries for Gleam users to make use of. Gleam can additionally compile to JavaScript, enabling you to use your code in the browser, or anywhere else JavaScript can run. It also generates TypeScript definitions, so you can interact with your Gleam code confidently, even from the outside. @external(erlang, \"Elixir.HPAX\", \"new\") pub fn new(size: Int) -> Table pub fn register_event_handler() { let el = document.query_selector(\"a\") element.add_event_listener(el, fn() { io.println(\"Clicked!\") }) } Friendly 💜 As a community, we want to be friendly too. People from around the world, of all backgrounds, genders, and experience levels are welcome and respected equally. See our community code of conduct for more. Black lives matter. Trans rights are human rights. No nazi bullsh*t. Lovely people If you enjoy Gleam consider becoming a sponsor (or tell your boss to) You're still here? Well, that's all this page has to say. Maybe you should go read the language introduction! Let's go! Wanna keep in touch? Subscribe to the Gleam newsletter We send emails at most a few times a year, and we'll never share your email with anyone else. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.",
    "commentLink": "https://news.ycombinator.com/item?id=38183454",
    "commentBody": "Gleam: a type safe language on the Erlang VMHacker NewspastloginGleam: a type safe language on the Erlang VM (gleam.run) 266 points by ljlolel 12 hours ago| hidepastfavorite138 comments xixixao 6 hours agoI&#x27;m really impressed by the syntax. I have yet to find a piece of syntax I wouldn&#x27;t like. Labelled arguments for example are delightful: pub fn replace( in string: String, each pattern: String, with replacement: String, ) { &#x2F;&#x2F; The variables `string`, `pattern`, and `replacement` are in scope here } replace(in: \"A,B,C\", each: \",\", with: \" \") reply 698969 4 hours agoparentThe only part that rubs me the wrong way is,> The pipe operator will first check to see if the left hand value could be used as the first argument to the call, e.g. a |> b(1, 2) would become b(a, 1, 2).Optimizing for one less _ typed is a really bad trade-off in terms of clarity here. reply xixixao 2 hours agorootparentI actually agree, this is the most questionable piece. I prefer (and have argued for in JS) Hack-style pipes, where the value \"placement\" always has to be specified.That allows arbitrary expressions on the RHS of the pipe, so for example this would be valid Gleam:pub fn main() { io.println( \"Hello\" |> (_\" world\") ) } reply pharmakom 2 hours agorootparentGleam has curried functions by default so F# style pipes make sense imo. reply hayleighdotdev 1 hour agorootparentGleam doesn&#x27;t have auto currying! Often folks find this (currying) a bit confusing to wrap their head around when learning functional programming and we don&#x27;t feel like it really affords you much that couldn&#x27;t already be achieved with just a little bit more work by the programmer. Applicative builder APIs are the only thing we&#x27;ve found would be much much better if we had auto currying. reply pharmakom 14 minutes agorootparentAh my mistake. So this is a deviation from Elm? replyal_be_back 39 minutes agoparentprevswift has that - it&#x27;s smart. helps with documentation, and simplifies refactoring. I&#x27;m up for any features that reduce changes upstream. reply vips7L 4 hours agoparentprevHow does this work if you rename a variable? Does it break all callers? reply tczMUFlmoNk 3 hours agorootparentIn this example, the local variables are `string`, `pattern`, and `replacement`, and are implementation details; only the names `in`, `each`, and `with` are part of the public API. Renaming the local variables doesn&#x27;t break anyone. Renaming the labels would break callers, just as changing the names of keyword arguments in other languages. reply hota_mazi 5 hours agoparentprevFYI Swift did this years ago. reply wiml 5 hours agorootparentSwift probably did it for ObjC compatibility, and ObjC got it from Smalltalk. reply troupo 3 hours agoparentprevFor me personally that&#x27;s the part of syntax I don&#x27;t like and don&#x27;t understand the value of. reply danappelxx 3 hours agorootparentGenerally stems from the philosophy that code is read more than written, and this helps readability. reply troupo 56 minutes agorootparentDoes it? Instead of a single parameter you now have two names, and a type info to boot pub fn replace( in string: String, each pattern: String, with replacement: String, ) { &#x2F;&#x2F; The variables `string`, `pattern`, and `replacement` are in scope here } replace(in: \"A,B,C\", each: \",\", with: \" \")vs pub fn replace( in: String, each: String, with: String, ) { } replace(in: \"A,B,C\", each: \",\", with: \" \") reply dylukes 2 hours agorootparentprevIt separates \"names as public-facing API design decisions\" from \"names as developer conveniences for expressing intent and clarifying their code\".These are often very at odds. And if you don&#x27;t want to repeat yourself twice with two identical names... you don&#x27;t have to.And unlike Smalltalk, in Swift at least, externally unnamed but internally named is easy (just make the external name _). reply troupo 55 minutes agorootparent> It separates \"names as public-facing API design decisions\" from \"names as developer conveniences for expressing intent and clarifying their code\"How often is this an issue?> And unlike Smalltalk, in Swift at least, externally unnamed but internally named is easy (just make the external name _).So, visual clutter for very little gain. IMO reply christophilus 10 hours agoprevLooks decent. I somehow missed the previous thousand discussions.I’d love to hear from anyone running it in production.I have always been BEAM-curious, but never felt comfortable running it in production, as it feels like a big black box, and I’m not confident that I’d be able to diagnose problems as readily as I can in .NET, Go, or Node. I’m not sure why I feel that way about BEAM. reply bmitc 10 hours agoparentI think it might actually be easier to inspect the BEAM over those other VMs. For one, it is much older and stable. And secondly, the BEAM has a lot of self-introspection features.I highly recommend the talk The Soul of Erlang and Elixir by Sasa Juric which shows off the essence of the BEAM.https:&#x2F;&#x2F;youtu.be&#x2F;JvBT4XBdoUE reply mikeurbach 9 hours agorootparentSince you brought up Sasa Juric, I will second that and also mention their book Elixir in Action. It really helped me get from toy examples to feeling confident running the BEAM in production. This is of course Elixir-centric, but the parts about OTP, inspecting running applications, etc. are really about the BEAM. reply cpursley 10 hours agorootparentprevDefinitely way easier than tracing Node for any type of async exceptions. reply mikercampbell 9 hours agorootparentI transferred from Node.js to elixir for that reason.Uncaught throws, hanging errors - while someone much smarter than I could have done it better, I was doing a lot of async&#x2F;retry of APIs with high failure rate and the BEAM just made it easy. reply pjmlp 3 hours agorootparentprevWhat is BEAM&#x27;s version of Visual VM, JDK Flight Recoder or ETW? reply di4na 3 hours agorootparentTo extend, the answer is the BEAM itself. It ships with these tools built in.From the whole zoo of system probing stuff or the downright amazing dynamic tracing.Have a quick look at https:&#x2F;&#x2F;www.erlang-in-anger.com&#x2F; reply mattbaker 3 hours agorootparentprevGreat question, check out Erlang’s “Observer”, it’s incredibly powerful, one of my favorite parts of the BEAM :) reply chii 10 hours agoparentprev> I’m not sure why I feel that way about BEAM.unfamiliarity? Plus the problem of &#x27;nobody ever got fired for running IBM&#x27; plaguing your work. reply dudul 10 hours agoparentprevI&#x27;m not sure either why you feel that way. The BEAM has amazing tools to debug at runtime and explore&#x2F;modify your system while it&#x27;s running.Yeah you&#x27;d need to learn it, but it&#x27;s like any other tool. reply avtar 10 hours agoparentprevSome comments about the prospect of using Phoenix with Gleam:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38037082 reply fbn79 1 hour agoprevI was wondering if it&#x27;s Hindely-Milner, and yes it is according to this interview:https:&#x2F;&#x2F;blog.lambdaclass.com&#x2F;an-interview-with-the-creator-o.... reply alilleybrinker 9 hours agoprevGleam is written in Rust and is a nice example (besides Rust itself) of what it looks like to write a language in Rust. By my own tracking (https:&#x2F;&#x2F;github.com&#x2F;alilleybrinker&#x2F;langs-in-rust) Gleam is one of the most popular languages written in Rust and is one of the few top languages in that list which isn&#x27;t a reimplementation of an existing language! reply saghm 9 hours agoparentI feel like making programming languages is an area where Rust can really make use of its advantages without the commonly cited pitfalls. You won&#x27;t be dealing with any I&#x2F;O other than filesystem APIs (outside of making a standard library or something), so you can entirely avoid needing to decide whether to use async or not, and you can go pretty far just using value types and copying without it being a likely performance bottleneck. Most languages won&#x27;t use much concurrency in their compiler either; Rust itself parallelizes builds per crate with Cargo, which invokes rustc separately for each compilation unit.I&#x27;m sure some people might read all this and conclude that they might as well just use OCaml or Haskell, and those are really good languages for compilers too! The tooling and ecosystem make Rust more appealing to me personally though, and I suspect that there are probably others who would find Rust&#x27;s ecosystem a bit more approachable as well. reply nindalf 7 hours agorootparent> Rust itself parallelizes builds per crate with Cargo, which invokes rustc separately for each compilation unit.Rust’s frontend now has support for running in parallel on nightly (they haven’t announced on the blog yet). But your point stands, Rust got pretty far all these years while keeping things simple and single threaded. reply sitkack 9 hours agorootparentprevModern compiler tooling that supports IDEs are almost all incremental, so all that async machinery and multithreading can be put to use there as well. reply cmrdporcupine 8 hours agorootparentprevI think Haskell or OCaml would do a better job on the ADTs for a parse tree. When doing this, I found Rust&#x27;s enums... anemic... and got very annoyed by the awkwardness of having to Box recursive types. I was reaching for the ability to continue to be able to pattern match on nodes while attaching common attributes (line numbers, etc.) and ended up having to bury everything 1 level deep in a struct which ended up feeling awkward.That and Rust&#x27;s iterators are terrible at introducing ownership agony.In any case, I&#x27;ve ... done it (https:&#x2F;&#x2F;github.com&#x2F;rdaum&#x2F;moor&#x2F;blob&#x2F;main&#x2F;crates&#x2F;compiler&#x2F;src&#x2F;...) but can&#x27;t say I liked it.I do really like \"pest\" as a parser generator though. In general, yes, the Rust ecosystem is bigger&#x2F;richer, and growing. reply di4na 3 hours agorootparentYou are not wrong on that level, i have been slowly writing a language in Rust anc all these point are deeply felt.And yet... The Rust ecosystem win. Easily. For a simple reason.Salsa. Oh and also clap. Lsp bindings. Ungrammar. Miette. Clap. Parsers. EtcAt every level the Rust packages are far better and allow to drastically reduce the cost of building this stuff. reply throwaway858 1 hour agorootparentHaskell has equivalents to all of those libraries, and much more. And they are probably easier to use and more powerful. replyMarkMarine 6 hours agoprevThis hits the mark for me, good type system, backed by Erlang and BEAM, access to Phoenix live view, but doesn’t have (imho Terrible) ruby syntax reply whitepoplar 6 hours agoparentAs someone who loves ruby syntax, I&#x27;d be very interested to hear which parts of it you don&#x27;t like. reply philwelch 2 hours agorootparentI haven’t used Elixir but I used Ruby as my main programming language for a few years and my biggest complaint with Ruby syntax is decision fatigue. There’s almost never a single clear and obvious way to do something. Overall I find Ruby syntax to prioritize cutesy aesthetics over practicality. reply tokamak-teapot 3 minutes agorootparentIf you use Elixir for a while you may find that there is a lot more consistency, and almost no ‘cutesy’ code around. Elixir’s syntax only looks a little like Ruby at first glance. reply Alifatisk 3 hours agoparentprevWhat’s wrong with Ruby syntax? reply nologic01 2 hours agorootparentOne day humanity will recognize that people have divergent tastes in programming languages syntax that have no obvious rational basis.Me curly brackets, you no curly brackets. Etc.Today is not that day. reply pmontra 7 hours agoprevI browsed the docs and found no mention of OTP. I might have missed it but it would be strange to have a language on BEAM with no native interface to those modules. I looked for examples of supervision trees and gen servers. reply Ndymium 5 hours agoparentOTP is a work in progress available in the gleam_otp [0] package, supplemented with the lower level gleam_erlang [1]. Or you can call OTP things manually with FFI.[0] https:&#x2F;&#x2F;hexdocs.pm&#x2F;gleam_otp&#x2F;index.html[1] https:&#x2F;&#x2F;hexdocs.pm&#x2F;gleam_erlang&#x2F;index.html reply ungamedplayer 5 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;wmealing&#x2F;gleam-otp-design-principals&#x2F;blob...This is what I wrote regarding using otp in gleam. One of the issues I&#x27;m working on next is to send typed messages to processes, which has me a little stumped.At the moment the typed channels work, you can&#x27;t register () a channel or a pid.I will likely continue working on this document once I have my current project completed. reply kimi 1 hour agoparentprevThey seem to have rewritten&#x2F;wrapped OTP, but it&#x27;s not production ready. https:&#x2F;&#x2F;github.com&#x2F;gleam-lang&#x2F;otpYMMV, but a BEAM language without OTP severely limits its appeal and usability. reply rbjorklin 6 hours agoprevIf this piqued your interest you might also be interested in: https:&#x2F;&#x2F;github.com&#x2F;leostera&#x2F;riot reply dang 11 hours agoprevThings I like about Gleam&#x27;s Syntax - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38031342 - Oct 2023 (54 comments)Gleam v0.29 – Gleam gets autocompletion - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36044484 - May 2023 (1 comment)V0.28 released of Gleam, a type safe Erlang-family language - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35425855 - April 2023 (4 comments)Gleam v0.25 – Introducing use expressions - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33731871 - Nov 2022 (4 comments)The Gleam Language Server - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31143792 - April 2022 (1 comment)Gleam v0.18 Released (gleam language on the erlang vm) - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=29464307 - Dec 2021 (1 comment)Gleam 0.16 compiles to JavaScript - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27538919 - June 2021 (24 comments)Gleam 0.15 - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=27061500 - May 2021 (78 comments)Phantom Types in Gleam - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26284976 - Feb 2021 (11 comments)Gleam 0.14 – Type-safe language for the Erlang VM - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26185690 - Feb 2021 (51 comments)Lean HTTP Server for Gleam - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=24265936 - Aug 2020 (5 comments)V0.10 of Gleam, a statically typed language for the Erlang VM, is out - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23706211 - July 2020 (1 comment)Gleam: A statically typed language for the Erlang VM - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22902462 - April 2020 (109 comments)Hello, Gleam - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19686413 - April 2019 (1 comment)An interview with the creator of Gleam: an ML like language for the Erlang VM - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=19547418 - April 2019 (0 comments) reply CooCooCaCha 10 hours agoprevI really hope gleam takes off. We need more typed scripting options. reply bmitc 10 hours agoparentYou could use F# for that purpose. reply CooCooCaCha 10 hours agorootparentI want something more like rust or typescript. Not Haskell. reply bmitc 10 hours agorootparentThen F# it is. :)Rust was partially inspired by F# and OCaml and actually had a much more ML-like syntax early on. Probably something similar goes for Typescript. And actually, the same for Gleam as well.F# doesn&#x27;t really relate to Haskell at all. They are very different languages. F# is a multiparadigm language that easily supports concise code in the imperative, OOP, and functional styles.It sounds like you maybe don&#x27;t know much about F# if you think it&#x27;s like Haskell, which is okay. But that&#x27;s also why I would recommend checking it out. reply hannofcart 5 hours agorootparentprev+1 to this.Love Rust and everything about it.However, to script something small&#x2F;casual I would like all the rest of Rust but with automatic garbage collection, without having to worry about lifetimes. reply xupybd 9 hours agorootparentprevF# is not Haskell at all. If you want to write non functional code you can. It&#x27;s functional first but it has side effects, mutable variables and a host of features you get in other languages. I really recommend trying it. reply giraffe_lady 8 hours agorootparentprevI use ReScript for this. Bindings for node are very complete and for deno they&#x27;re enough for the most common uses. reply cpursley 10 hours agorootparentprevDoes F# compile to distributed Erlang? reply Conscat 1 hour agorootparentCaramel is a very similar language (ML dialect) that builds for BEAM.https:&#x2F;&#x2F;caramel.run&#x2F; reply sshine 9 hours agorootparentprevNot practically.There are some one-person attempts at compilers from F#&#x2F;OCaml to BEAM, but they haven’t seen an update for some years. reply singularity2001 3 hours agoprevrelated: what is the state of the Erlang VM in Wasm? reply bcardarella 11 hours agoprevGleam is awesome reply m8s 9 hours agoparentIt really is. A typed BEAM language (that also compiles to Javascript), a fantastic community, and a growing ecosystem. I’m really excited for the future of Gleam! reply tines 10 hours agoprevCan anyone comment on Gleam&#x27;s type system? Is it similar to Haskell&#x27;s? reply turboponyy 10 hours agoparentNo, it is not. It has no plans to introduce type classes and allows for impure (effectful) functions. It is perhaps most similar to OCaml. reply Jeff_Brown 7 hours agoparentprevHaskell&#x27;s is much deeper but Gleam gives you algebraic types, generics and type aliases.I believe Gleam offers deeper pattern-matching facilities. That is of course not the type system, but feels closely related to me. reply m2lb2912 5 hours agoprevGleam is looking to be a nice alternative to Rescript.The docs are a little sparse on this (being initially focused on BEAM), but the discord & community is very helpful which makes up for it.It&#x27;s a very neat and well thought out language. reply lkjaldfwltjohw 9 hours agoprevAt a glance the type system is quite barebones and nominative.I&#x27;d like to see Gleam add support for structural types and maybe set theoretic [1][1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2302.12783 reply m8s 9 hours agoparentFor what purpose? Is Gleam today unable to do things you’d like to be able to do? reply dudul 10 hours agoprevnext [38 more] [flagged] pvg 10 hours agoparentPlease don&#x27;t pick the most provocative thing in an article or post to complain about in the thread. Find something interesting to respond to instead.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html reply jrsj 6 hours agorootparentthe actual effect of enforcing this rule in this circumstance is basically to say that implicit political loyalty tests are a normal thing to have on a website for a programming languageon a surface level the statement isn’t controversial in any way, but the particular language that’s used signals something else entirely reply pvg 6 hours agorootparentNo, the rule is about not going on irrelevant tangents and not dingleberrypicking stuff from submissions. Its actual effect is that such diversions get moderated by users and moderators, just like this one did by users. reply jrsj 6 hours agorootparentFair, you’re probably right reply rkangel 10 hours agoparentprevIt&#x27;s some way down, in a section about community.An important recent learning about programming adoption is that a good community is absolutely key to drive growth. Makes sense to establish the principles. reply jrsj 7 hours agorootparentthis has nothing to do with community or even inclusivity and everything to do with signaling political allegiance & telling people who don’t agree that they aren’t welcomeIt is quite literally the opposite of what you and others supporting this are claiming it to beAll you have to do is remove the weird bit about “nazis”, which is irrelevant and adds nothing of value to the statement anyways, and you’re not really going to scare any normal person off. But this is just over the top and literally the only purpose it could serve is as an exclusionary political signal. reply pvg 6 hours agorootparentwho don’t agreeWho are the excluded people here and what do they not agree with? reply jrsj 6 hours agorootparentCasually using “Nazi” like this in context of American politics just means “anyone to the right of me”it’s ambiguous but the implications are clearIf you are a Christian, someone who would use this phrase would likely call you a Nazi. If you don’t want to abolish the state of Israel, they might call you a Nazi. It could be any issue really. But to actually be “safe” in an environment like this you have to align yourself roughly to the politics of the DSA or you aren’t welcome.I guess you could say at this point that “Nazi” has devolved into being a sort of a political slur referring to anyone who is not sufficiently leftist. reply pvg 6 hours agorootparentThat&#x27;s a lot to bring to a random footer on a web page about something else. I get the distaste for sloganeering but the suggestion that &#x27;the implications are clear&#x27; that this is.... the DSA? feels like a more than a bit of a reach. reply jrsj 6 hours agorootparentIt is a reach and that’s kind of the issue I guess. You have no idea whether or not people involved would call you a Nazi or what for, only that they might.I am probably overreacting to this because I have encountered it in the workplace before. Politics constantly being brought up inappropriately & the only safe move was to go out of your way to signal to the right people that you were on their “team”. The occasional political witch hunt over nothing would happen. A good portion of the company spent most of the day talking politics instead of working but I assume nothing was done out of fear of retaliation. A lot of really bizarre things, but hopefully not the norm. reply pvg 6 hours agorootparentYou have no idea whether or not people involved would call you a NaziYou have no idea of that whatever footer they put on their page, short of one that is &#x27;we like to call people Nazis&#x27;. The reaction is as if someone&#x27;s already called you personally a Nazi and the footer doesn&#x27;t do that.Again, I get the discomfort with the perception you might have different political views from whoever wrote that footer. But that&#x27;s the discomfort of difference that comes with everyday life. Nobody has called anyone a Nazi, that&#x27;s not a reasonable extrapolation from either the footer or your unpleasant personal experience combined with the footer. replytadfisher 4 hours agorootparentprev\"Black lives matter\", \"trans rights are human rights\" and \"no Nazi bullshit\" are completely uncontroversial positions though. Like, if you disagree with those, then there&#x27;s something fundamentally wrong with how you view the world and interact with other human beings. reply ylor 10 hours agoparentprev“No politics” is implicitly political and supportive of the status quo. reply daedalus_j 9 hours agorootparentNo, it just means take it to the right forum.The daily standup is not the right forum, for example. The pub after work? maybe.The previous part of the community statement gets the \"we&#x27;re going to be nice, and not discriminate, and focus on the language itself\" point across just fine.Signaling that you want to inject politics into an inappropriate context signals that you may be the type of project that will do unpredictable things when the political mood strikes and makes it less viable to depend on you. reply sbuttgereit 9 hours agorootparentI couldn&#x27;t agree more. Injecting personal political advocacy into a professional context is itself unprofessional and raises large numbers of questions about fly.io and the Gleam project&#x27;s ability to operate in solely professional context.It&#x27;s this \"turn everything into activism\" bullshit that people across the the political spectrum engage in on social media that got me to cancel all my social media accounts some years ago (present company excluded). reply subarctic 7 hours agorootparentThe other problem with these statements is they can never get rid of them, because the people that like them will freak out if they do that. It&#x27;s like the land acknowledgements we have in Canada that keep getting longer and longer and will never go away unless the pendulum eventually swings reply flir 8 hours agorootparentprevThe moment someone raises a ticket that says \"hey, maybe we should put &#x27;no nazis&#x27; in the FAQ\", you, as the FAQ maintainer, have to make a choice. Whatever you choose is a political choice, even ignoring the ticket. Fencesitting is a political choice too. It&#x27;s just unavoidable. reply LAC-Tech 8 hours agorootparentWell sure, if weirdo runs up to me and starts asking me what I think of Nazis, anything I say or don&#x27;t say could definitely be looked at with a political lens. Doesn&#x27;t mean I&#x27;m being anywhere as political as the weirdo.Suggesting to mention Nazis in the FAQ is extremely political. Closing, ignoring or fencing the ticket is much less political.It&#x27;s up to everyone whether you want to raise or lower the levels, keeping in mind what you actually want to accomplish. reply LAC-Tech 9 hours agorootparentprev\"No politics\" means not having to deal with &#x27;debates&#x27; between two people who want to alter the status quo in complete opposite directions reply fastball 2 hours agorootparentprevWell isn&#x27;t that fine then? Because those three things are already the status quo. reply onthecanposting 7 hours agorootparentprevThe status quo is the progressive theology. If billionaires fund your advocates, you have most of the elected representation, and the state-sanctioned press amplifies your views, then you&#x27;re not challenging anything. reply galaxyLogic 9 hours agoparentprevYou may dislike that but I can&#x27;t see how anybody could disagree with those 3 slogans either. So they can&#x27;t do any harm to anyone, can they? reply magicalhippo 5 hours agorootparentThey&#x27;re not very specific and quite open to interpretation. As a left leaner here in Norway, I find at least the last two to be quite problematic and a huge red flag. They make me feel significantly less welcome. reply aslilac 3 hours agorootparentwhat about “trans people deserve rights” and “nazis need not apply” is problematic to you?if those sentiments make you feel less welcome, maybe it’s for a reason reply magicalhippo 2 hours agorootparentTrans rights are not well defined (ie what do the Gleam team put under that umbrella), and I&#x27;ve seen several statements in that context that I find problematic at best.And they say \"No nazi bullsh*t\", which to me is a very loose phrasing with avtivist vibes, meaning I get unsure what exactly they put under the Nazi banner. Is it just actual Nazis or anyone they don&#x27;t like, or something inbetween? reply omginternets 8 hours agorootparentprevAre we just going to pretend they’re not political slogans?The statement was perfect until that last line. reply jrsj 6 hours agorootparentIt really shouldn’t be controversial to suggest that calling people nazis on the official website for your programming language is unprofessional, but here we are… reply tadfisher 4 hours agorootparentprevThe line that says \"no Nazi bullshit\"? That has to be the safest political position you can hold as long as you&#x27;re not friends with Kanye West. reply drannex 10 hours agoparentprevExistence is political. If you want to foster a positive community, this is how you do it. reply galaxyLogic 9 hours agorootparentYes, nothing funny about Peace Love and Understanding(https:&#x2F;&#x2F;youtu.be&#x2F;lhol3zIoynE) reply claytongulick 10 hours agorootparentprevSome of us prefer to just focus on technology and not have politics injected into everything we do.This kind of thing is clearly virtue signaling and flag waving.You may as well have a banner that says \"conservatives not welcome\".It&#x27;s their project, and their choice. I just find the whole thing tiresome. reply m8s 10 hours agorootparentFeel free to ignore it then? reply _dain_ 9 hours agorootparentprevlook up havel&#x27;s greengrocer reply jrsj 7 hours agorootparentprevYou foster a positive community by accusing the person reading your webpage of potentially being a Nazi? lmaoAll this sort of thing tells me is to avoid this community because accusations of bigotry are going to start flying over the smallest of arguments and I have no interest in having people try to ruin my life because of their unhealthy obsession with politics reply LAC-Tech 9 hours agoparentprevI always take these things as a kind of warning. They&#x27;re telling you what their politics are, and that they&#x27;re upfront about it. If you agree with that or can at least ignore that, you&#x27;ll be alright. If not, don&#x27;t interact.Personally I&#x27;ll use any technology regardless of the politics, but engaging with people is another matter. reply omginternets 8 hours agoparentprevPeople are ignoring (or pretending not to know?) that these are political slogans. They signal allegiance to a rather prickly segment of the political left. reply jrsj 6 hours agorootparentpretending not to know is how you signal your own alignment reply andrewstuart 8 hours agoprevI know a company that has built their entire technology stack on some Erlang VM based language.There was really no reason to do so at all - it&#x27;s an ordinary company building an ordinary application. But some CTO or dev lead years ago thought it important to use whatever the fancy tech of the day was to build a fairly ordinary business application.But now they have trouble hiring people because there&#x27;s a tiny pool of people who know that language. And it is years down the track and all their technology is built with whatever that language&#x2F;framework is - too expensive to easily bail out, but probably necessary anyway.In 2023 you&#x27;ve got to have really good reasons for not using C#, or Java, or Python, or TypeScript for building your web project. Maybe Golang - it&#x27;s getting some good traction in the DevOps space.If you make decisions about technologies and this latest thing appeals to you - maybe use it for your personal projects. The CEO has employed you to make responsible decisions not play toys. reply inopinatus 7 hours agoparentYou&#x27;re posting on a website built in its own Lisp variant and inhabited by people who think it&#x27;s fun to write compilers. reply kgeist 4 hours agoparentprev>But now they have trouble hiring people because there&#x27;s a tiny pool of people who know that language>In 2023 you&#x27;ve got to have really good reasons for not using C#, or Java, or Python, or TypeScript for building your web project. Maybe GolangIn my country, very few people know Go, so we hire devs without requiring them to know Go - we teach them the language, and after a few weeks, they already feel pretty confident with it. In fact, most devs are actually interested in trying something new, some new language.Maybe your employer&#x27;s problem is that they are only looking for CVs where the language is mentioned as a keyword, and don&#x27;t consider anything else? reply throwawaymaths 6 hours agoparentprevThis is completely insane because at the same time go on any elixir forum and you will find lots of highly talented developers looking for jobs.As usual the problem is that leadership has no fucking clue how to hire. reply andrewstuart 6 hours agorootparent>> go on any elixir forum and you will find lots of highly talented developers looking for jobsSure, in a downturn after a year of waves of layoffs, and maybe in San Francisco, but the non-mainstream tech will live longer than a few economic employment ups and downs. reply sarchertech 6 hours agorootparentLast 2 companies I’ve worked at have been elixir shops. Both of them had no trouble at all hiring elixir devs. At my previous company we hired close to 30 in a 6 month period in 2021. At my current bigco job we had more elixir devs pass the interview process than we have open slots (and we had a ton of slots).I’ll also add that over many years of doing this, the elixir devs I’ve interviewed tend to be far above average, which makes up for the lower number of candidates.If you want to hire thousands of fresh grads each year and don’t want to spend any time on training, sure go for something they teach in school. reply throwawaymaths 4 hours agorootparentprevNo it&#x27;s been pretty much that way for years. reply zem 6 hours agoparentprevi&#x27;ve shared this story on here before, but years ago i worked for a startup where we had a janky homegrown distributed system cobbled together from a mix of python, rabbitmq and state stored in postgres tables. four of us, two senior and two junior engineers, decided to see if we could learn erlang and build a more coherent and well-engineered replacement for it. it took us four months, starting from never having used the language, to learn our way around it and set up a proof of concept that was both more performant and more stable than the existing system. and this was all while doing our regular work as well. erlang is an extremely simple language to learn and become productive with, especially if the task you&#x27;re trying to do fits the grain of the language and beam environment.(ironically, the erlang solution never went anywhere because management decided they did not want to take a chance on a lesser-used language. but from a getting employees standpoint it&#x27;s perfectly feasible to hire people who are simply good engineers in whatever language and give them a month to learn erlang.) reply girvo 8 hours agoparentprevIt’s very easy to teach a good developer a new language. We use Nim for embedded firmware development at my work, and have been expanding our team. It’s been simple: hire good C&#x2F;C++ devs who are interested in learning something new but related, and teaching them. Takes about two weeks before they’re comfy, sometimes less (python experience seems to help a little due to some surface level syntactic similarities) reply andrewstuart 8 hours agorootparentYou are describing the honeymoon period of choosing a non mainstream approach.In time, it starts to become clear that this non mainstream thing hasn&#x27;t really picked up the steam to become mainstream. Your developers are starting to realise there are no jobs advertised for Nim, so this isn&#x27;t good for their career. Then the Nim project starts to stagnate. But you&#x27;ve written so much code in it that it&#x27;s hard to turn back. But the person who decided on the non-mainstream technology - if they are still there they are defending it to avoid losing face. if they have moved on and left you the problem then the new CTO is explaining to the CEO the bind the company is in. Time to start planning the budget for a complete rewrite in the language that is standard practice for the industry for this sort of thing.At this point, C++ ain&#x27;t looking so bad for this sort of project. reply AlchemistCamp 4 hours agorootparentYou are describing programming as if the language being used is the primary work skill and as if devs are somehow “trapped” by the language they happen to be paid to use at the time.I live in a very different world and over the past 13 years have been paid to write Obj. C, Python, PHP, CSS, JS, Ruby, Elixir, Golang and a small amount of Rust. All are still useful skills that I’m likely to encounter again.In a few cases, I used languages that later lost steam (Flash, CoffeeScript and Elm). It wasn’t a disaster, though. I just took what I’d learned and moved on. reply carl_dr 1 hour agorootparentprevWhereas not a single shop has gone down the road of picking some Javascript framework which stagnates or significantly changes over major versions and requires a lot time&#x2F;money&#x2F;effort to migrate.These types of problems are pretty common. reply ttymck 8 hours agorootparentprevWhat if you can&#x27;t find an expert to teach the other developers? reply chefandy 7 hours agorootparentWhere did the rest of the code come from, or who made the decision to start that way? They should at least be able to spearhead it. Obviously it&#x27;s different for tiny organizations, but generally, if someone inexpertly made architectural decisions without building the institutional knowledge to continue without them, the language they chose will just be one of many big problems. reply troupo 3 hours agorootparentPeople who build things are not necessarily able to teach things. These are two different skill sets. reply rad_gruchalski 7 hours agorootparentprevYou are hiring too late. reply ttymck 7 hours agorootparentSo if you end up joining one of these companies, run for the hills, no? reply siwatanejo 8 hours agoparentprevI hire based on ability&#x2F;intelligence, not knowledge. reply drzaiusx11 5 hours agorootparent\"Ability\" by itself is a bit vague here, but I will say that having a proven trackrecord in their ability to learn is something I specifically look for in a candidate. Not only learning new tech, but also learning from mistakes and experiences over time.However, I don&#x27;t think raw \"intelligence\" is the right metric for hiring. Unless you specifically mean emotional intelligence, which can curtainly contribute to improving communication skills on the team.I&#x27;ve also found that when hiring someone with mostly expertise outside your current stack it&#x27;s critical to provide good feedback loops and mentoring early on so they can \"get up to speed\" and contributing valuable, idiomatic code as fast as possible without feeling as though your entire onboarding experience is trial by fire. This mentoring takes up extra resources and is a net drain on your team in the short term, but pays off in the long term. reply andrewstuart 8 hours agorootparentprev>> I hire based on ability&#x2F;intelligence, not knowledge.Well, yeah that&#x27;s really your only choice if the experience you need is not easily available.Don&#x27;t tell me, you are the guy who puts in the not mainstream technology and needs to defend that with justifications such as \"when we use (non mainstream technology X) we get super motivated job applicants because anyone with an interest in non mainstream technologies is inherently passionate and interested\".That&#x27;s not a sound hiring strategy. reply inopinatus 7 hours agorootparentAnd you are the guy who left Visual Basic, COBOL, Perl, and FORTRAN off their \"obviously safe choices for hiring in the future\" list, despite them all having once been perceived as such.These inconvenient counterexamples blow up the entire thesis. In practice, the \"safe choice\" for longevity is only evident in hindsight.If anyone is hiring for TypeScript in 2050 I&#x27;ll eat my hat reply h0l0cube 7 hours agorootparentI&#x27;m in sympathy with your main argument, but given that people still, in 2023, hire for COBOL, a language made in 1959, makes me think you&#x27;ll be eating your hat. reply inopinatus 7 hours agorootparentNotwithstanding that I&#x27;m effectively forecasting the decline & fall of TypeScript as javascript-flavour-of-the-month, note that I shrewdly also granted myself the better part of three decades to launch an edible headwear startup reply calvinmorrison 8 hours agorootparentprevThis sounds fun until your entire stack is on Perl in 2023 (which, is fine-ish when your CTO was the perl project lead). But then you have a bajillion dependencies that aren&#x27;t really updated anymore, you end up owning most of the Mail::Toolkit libraries, etc. and nobody really knows perl that well. I mean, a lot of us can jimmy around in Perl, but of the real Perl Gurus in the world, you will end up hiring 50% just to keep your company going reply ttymck 8 hours agorootparentprevI think I&#x27;m rather able and intelligent, but there are just so many footguns in golang that my team doesn&#x27;t have the knowledge to avoid. reply drzaiusx11 6 hours agorootparentJust curious, what are some of those footguns your team is encountering? Only thing that comes to mind is the somewhat tedious error handling imposed by the language. Which language would you say had _less_ footguns than go? Or was this sarcasm and it went straight over my head? reply ttymck 2 hours agorootparentI guess I am just bad at golang.Loop variable pointer and nil struct is not nil interface are the two that continue to hound us. reply sbrother 5 hours agoparentprevAre you talking about WhatsApp? Discord? reply sergiotapia 8 hours agoparentprev>There was really no reason to do so at allPlease - I can do a ton of stuff in Elixir without having to reach for some weird&#x2F;paid third party service. https:&#x2F;&#x2F;twitter.com&#x2F;ryanrwinchester&#x2F;status&#x2F;15806523244057763...Now with Liveview I can even ditch the grotesque React toolchain entirely.Also, in my experience as defacto CTO of a unicorn YC company (Papa), hiring was not insanely difficult. I hired about ~45 engineers Great Ruby&#x2F;Go devs translated pretty easily into Elixir after minimal training. The language is beautiful and simple. reply mattbaker 3 hours agorootparentAgreed, it’s been so easy to onboard people onto Elixir we’ve just looked for raw talent knowing they’d be up on Elixir quickly.As long as you have one experienced elixir engineer to guide the people learning I think it’s easy to move fast. reply ecmascript 28 minutes agoprev [–] > People from around the world, of all backgrounds, genders, and experience levels are welcome and respected equally.Except that if you don&#x27;t agree with the authors political opinions:> Black lives matter. Trans rights are human rights. No nazi bullsh*t.Yet another project run by people who shoves politics into unnecessary spaces. I would never dare to use a project run by people that pushes their personal agendas on their website for a programming language.I do believe that there is only two genders, man and female. Am I a nazi now or what do Gleam mean by this message? Don&#x27;t use projects like this. reply s0l1dsnak3123 24 minutes agoparentPersonal projects are driven by personal agendas. Also water is wet. If you don&#x27;t like it and you can&#x27;t find the motivation to build something better, perhaps that&#x27;s because your agenda doesn&#x27;t drive you enough. reply ecmascript 20 minutes agorootparentWhy would I build something better? I am maybe not in the business nor have the interest of making a programming language.I don&#x27;t really care that they have this message (except that I find it to be pretty insulting), I just think it&#x27;s an unnecessary thing to do if you want people to use what you&#x27;ve made. I won&#x27;t and I will encourage people not to use it just because of this. reply lawn 16 minutes agoparentprev [–] > Am I a nazi now or what do Gleam mean by this message?There is a dot there, so they&#x27;re separate issues. reply ecmascript 13 minutes agorootparent [–] That is not how I read that and I do think you&#x27;re wrong.I read it as \"if you don&#x27;t approve of $our_opinion then you are a nazi\" because that is usually how these people argue. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Gleam is a robust program based on the Erlang runtime, featuring a modern syntax and a powerful type system, equipped to handle workloads of any size with its concurrency system and fast immutable data structures.",
      "The program supports multi-core operations, uses a concurrent garbage collector, and offers its own compiler, build tool, formatter, editor integrations, and package manager. It is interoperable with packages from other BEAM languages like Erlang and Elixir.",
      "Beyond core features, Gleam compiles to JavaScript, generates TypeScript definitions for efficient external interactions and prioritizes user-friendly error messages, aiming for multicultural inclusivity."
    ],
    "commentSummary": [
      "Gleam is a robust program based on the Erlang runtime, featuring a modern syntax and a powerful type system, capable of handling workloads of any size due to its concurrency system and fast immutable data structures.",
      "It comes with its own compiler, build tool, formatter, editor integrations, and package manager, and can interact with packages from other BEAM languages like Erlang and Elixir. It also compiles to JavaScript and generates TypeScript definitions for efficient external interactions.",
      "User-friendly error messages and multicultural inclusivity are high-priority aspects of Gleam, as it aims to be accessible and efficient for diverse user groups."
    ],
    "points": 266,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1699394009
  },
  {
    "id": 38182869,
    "title": "Apple's 'Scary Fast' Event, Shot on iPhone 15 Pro Max, Showcases Professional Camera Capabilities",
    "originLink": "https://prolost.com/blog/scarybts",
    "originBody": "View fullsize A still from Apple’s “Behind the scenes: An Apple Event shot on iPhone” video What Does and Doesn’t Matter about Apple Shooting their October Event on iPhone 15 Pro Max November 07, 2023 Apple Shot Their “Scary Fast” October Event Video on iPhones And We Had Feelings You’re somewhere on the spectrum of occasionally shooting video on your iPhone to a professional-ish video maker with some gear, and you see at the end of Apple’s October “Scary Fast” event announcing new Macs with M3 silicon that the entire event was “Shot on iPhone.” This makes you feel a certain way. View fullsize Actual footage of me watching the event. Then Apple posts a behind-the-scenes video showing how this was done, revealing a rare and imposing glimpse into the scale and scope of their industry-leading launch videos. At the center of it all, instead of their customary Arri Alexa (a digital cinema camera costing $35–150K before you even add a lens, used to shoot everything from Avengers: Endgame to Barbie), was an off-the-shelf iPhone 15 Pro Max, gripped into truckloads of professional support gear. At this point, some folks felt differently about what was implied by “Shot on iPhone.” There have been bad takes on this, and good takes on those bad takes. Anyone who knows the tiniest bit about video production knows that the camera is a small, but important, but small, part of the overall production picture. “Shot on iPhone” doesn’t promise “and you can do it too” any more than Stanley Kubrick lighting Barry Lyndon with candlelight means anyone with candles can make Barry Lyndon. But when the camera is the least expensive piece of gear on the set after clothespins and coffee, it does feel strange. I’ve been on a lot of productions like this, having played an active role in the DV filmmaking revolution of the late ’90s-to-early-2000s. It was an odd feeling to scrounge for the adapter plates required to mount a $3,000 DV camcorder purchased at Circuit City to a Fisher dolly that literally has no purchase price. Apple, of course, has no burden of best-practices logic for their decision to shoot their “Scary Fast” event on iPhone — it’s a marketing ploy, a cool stunt, and a massive flex. A thing to do for its own sake. In the filmmaking community, it was the mic drop of the year. We greedily soaked up all the details in the behind-the-scenes video, and made a hundred tiny calculations about which aspects of this lavish production actually mattered to the question of the iPhone 15’s validity as a professional camera, and which did not. With all that gear and production support, which aspects of the event really matter to you, the iPhone-curious filmmaker? What can you learn, and which aspects can you safely ignore? Let’s take it one at a time: That They Did It: Does Matter As camera features have played a larger and larger role in Apple’s marketing for new iPhones over the years, you might have begun to feel a bit of cognitive dissonance. Apple tells you about how great, and even “pro,” these new iPhone cameras are — but would never have dreamt of using them to shoot their own videos or product stills. Apple was effectively saying “pro enough for you, but not for us.” Valid, but a bit dissatisfying. View fullsize A still frame from Apple’s October 30 “Scary Fast” event video, shot on iPhone 15 Pro Max. Apple has set the aesthetic bar impossibly high with these pre-recorded events. They’re not just executives teleprompting in front of Keynote slides — they feature “slice of life” moments shot on huge sets and real locations. Elaborate visual effects transition between locations and settings that might be partially virtual. These videos have looked great ever since Covid pushed Apple to find an alternative to executives-on-stage-in-front-of-slides, and even as Apple is now once again able to welcome guests to in-person product launches, these lavishly-produced videos are the new gold standard in pitching the world on a new iThing. With “Scary Fast,” Apple repeated their now well-established high-production-value playbook, but yoinked out the professional cameras and lenses, and dropped in a commodity consumer telephone in their place. And crucially, none of us noticed. It’s a big deal. They Shot ProRes Log: Matters So Much It Would Be Impossible Without It There is one single feature of the iPhone 15 Pro that made this stunt possible: Log. As I detailed here in words and video, the “iPhone video look” is designed to win consumer popularity contests, not mimic Apple’s own marketing videos, nor plug into professional workflows. It may be hard to imagine that a slightly different bit of signal processing when recording a video file from a tiny sensor can make the difference between consumer birthday-cam and professional viability, but that is exactly the power of log. Apple Log has catapulted the iPhone into filmmaking legitimacy. Apple Log footage looks flat and low-contrast, until you color correct it, as I’ve done here using my free Prolost Apple Log LUTs. They Used Big Lights: Does Matter, With An Asterisk Apple’s event was set at night, with a dark, Halloween-inspired look. It takes a lot of professional lighting gear to illuminate a wide shot of Apple’s campus, and professional skill to balance this lighting with the practical sources on the building itself. You can do this for cheaper than it looks. Lighting matters more than any camera, more than any lens. As I wrote in 2009: Photos are nothing but light — it’s literally all they are made of. Timmy’s birthday and Sally’s wedding are reduced to nothing but photons before they become photographs. So getting the light right is more meaningful to a photo than anything else. Should you look at the giant lights in Apple’s video and feel dejected that your own productions will never afford this level of illumination? I say no, because a) you’re probably not lighting up the whole side of an architectural marvel, and b) you’re probably not designing your production around one of the world’s highest-paid CEOs. For Tim Cook’s appearance, Apple’s production had their giant LED light panels on camera dollies, which is not typical. The two reasons I can image they did this are to be low-impact on the campus itself (rubber wheels instead of metal stands), and to be able to adjust the lighting quickly out of respect for Cook’s valuable time. It makes the lighting rigs seem more complex than they really are. What they really are is big, bright, and soft. And rather minimalistic — mostly key, a bit of fill. Big, soft LED lighting is actually quite affordable these days. I have two medium-power bi-color lights from Aputure, and together they cost less than my iPhone 15 Pro Max. I couldn’t cover Cook’s opening wide shot with them, but I could get close. View fullsize That big softbox overhead? Now that’s expensive. I might also be willing to compromise on my ISO settings to work with a smaller lighting package, where Apple seemingly was not. More on this below. So the lighting is important, but the quantity of it and the support gear it’s on is specific to this rarified type of time-is-money, night-exterior production. Don’t be distracted by the extra equipment, focus on the fact that the lighting itself is actually rather spare. They Attached the iPhone to Cranes and Gimbals and Drones and Dollies: Does Not Matter, Except for One Little Thing View fullsize The behind-the-scenes video is almost comical in its portrayal of the iPhone gripped into all manner of high-end support gear. You do not need any of this stuff. I mean, every filmmaker needs a crane shot — but this is why small cameras are so empowering: everything is a crane when your camera weighs less than a Panavision lens cap! Check out this video from filmmaker Brandon Li. He uses a gimbal on a hand-held pole to create a perfect crane shot for the opening of his action short. Toward the end, he achieves a nifty top-down shot by... standing on a railing. All with a camera substantially more cumbersome than a phone. View fullsize Director Brandon Li is his own crane. View fullsize Get your kicks without sticks. Apple used cranes and remote heads designed for big cameras because that’s how they know how to shoot these videos. Apple’s marketing department is large, and knows exactly what they need on these productions. One thing they need is for a dozen people to watch the camera feed, making sure everything is committee-approved perfect. View fullsize This is just the DIT cart, not even the client monitor. This kind of client-driven support gear compounds on its own requirements. As Tyler Stalman points out in his excellent breakdown video, some of what’s bolted to the iPhones is simply a metal counterweight so that a gimbal head, designed for a much larger camera, can be properly balanced. You can plug an external drive into the USB-C slot on the iPhone 15 Pro Max, or you can plug in an HDMI adapter for a clean client feed. If you want to do both, you need a USB-C hub, which at that point requires power. So now you’ve got an Anton-Bauer battery pack mounted to this tangle of gear. When you don’t have clients, you can skip all that and just shoot. This means you can replace most of the gear you see here with a cheap consumer gimbal — or a tripod. And here’s the key takeaway for this point: Apple achieved optimal image quality from the iPhone in a number of ways, and one, I’m betting, was by turning off image stabilization — which is only advisable when this tiny camera is physically stabilized. So you don’t need all the stuff Apple used, but if you want comparable results, you need a way to mount your iPhone to something solid. Maybe not a whole powered cage, but certainly a simple tripod mount. Then you can eek out that last bit of extra image quality by turning off image stabilization — which brings us to our next point: They Used the Blackmagic Camera App: Matters as Much as Log I don’t think this exact rig was used to capture what we saw in the video, but I believe the settings are representative. The Blackmagic Camera app has the option to turn off image stabilization, yes, and also like a million other features. Manual, locking exposure control is the top of the list, but there’s a ton more. The app includes a false-color mode to help match exposure from shot to shot. It can load a preview LUT, so you can shoot log but view something closer to what the audience will see. It’s silly to be grumpy with Apple for not offering this power in their own camera app when they clearly worked with Blackmagic Design to have this app available day-and-date with the iPhone 15. Oh, and it’s free. They Used a 180º Shutter: Matters More Than You Think View fullsize One slick feature of the Blackmagic Camera App is that you can choose to express the shutter speed in degrees, like a cinema camera, rather than fractions of a second, which is more typical in stills. A 180º shutter — where the shutter is open for half the duration of a single frame, e.g. 1/60th of a second at 30 fps — is important for a pro look. Anything slower and you get smeary blur and a camcorder look. Anything faster and your footage looks like you shot it on a phone, because 99% of the time our iPhones are using insanely fast shutter speeds to handle typical daylight. Look at any of your own daytime iPhone video — I’d be surprised if you see any motion blur at all. Compare Apple’s motion blur to mine. 180º shutter vs. probably something more like 1º. Relatedly: They Shot at ISO 55: Matters to Apple’s Goal of Maximum Image Quality Here’s where the level of professional control over the lighting starts to really matter: If Apple decided that they must shoot at ISO 55 (the lowest, although possibly not the native ISO of the 1x camera) for the highest image quality, and with a 180º shutter for the most pro-camera look, that means they have no other control over exposure. The iPhone 15 Pro 1x lens does not have a variable aperture, so shutter speed and ISO are your only exposure controls. When shooting in uncontrolled environments, the typical method of limiting the amount of light entering the lens is via ND filters, sometimes variable ND filters. I don’t see any evidence that Apple used filters on this shoot, which would fit with their overall prioritization of image quality over all else. So this goes back to lighting — Apple’s team controlled that lighting perfectly, because they opted out of any exposure control they might have had in-camera. I'm curious to learn more about this setting though. YouTubers Gerald Undone and Patrick Tomasso did some tests and found that the best dynamic range from the iPhone 15 Pro came from ISO 1100–1450, with 1250 being their recommended sweet spot. Did Apple prioritize low noise over dynamic range? They shot 30p: Doesn’t Matter Apple has used 30 frames-per-second for these pre-recorded keynotes since they started in September of 2020. They’re not trying to be “cinematic,” they’re trying to make a nice, clean video that can take the place of a live event. 30p is a choice, and a fine one for an on-stage presentation. You might choose 24 or 25 fps for a more narrative look, and that’s great too. Note that Apple’s native Camera app offers 30.0 and 24.0 fps, but the Blackmagic Camera app adds support for 29.97 and 23.976 fps, which are the actual broadcast frame rates Apple uses for their productions. They Focused Manually: Doesn’t Matter The Blackmagic Camera app truly has a dizzying set of features, some seemingly part of an attempt to win some kind of bizarre bet. Like support for wireless external follow-focus controls? I mean, wow, but also, really? Sure makes for a cool behind-the-scenes shot, but I bet you can live without this. View fullsize They Used a Matte Box: Does Matter While Apple did not attach any additional lenses to their production iPhones, they did put stuff in front of the built-in lenses — notably teleprompters, of course, and comically-large matte boxes. Matte boxes might feel like affectations in this context, but shielding that tiny lens from glare is actually a significant way to improve overall image quality. Luckily, you don’t really need a full-on matte box to do this. A French flag will do it, as will your hand. If a bright light is dinging your little lens, you’re leaving a ton of image quality on the floor. They Exclusively Used the 1x Camera: Does Matter — to Apple The 1x camera, with image stabilization turned off, gives the highest-quality image available from the iPhone 15 Pro Max. Are you detecting a theme here? Apple imposed a number of limitations on how they used the iPhone camera, seemingly always in the name of maximizing image quality. As we’ll discuss below, you may or may not share this priority. They Edited in Premiere Pro? Doesn’t Matter Real editor, fake set. Eagle-eyed viewers noticed that an Adobe Premiere Pro timeline appears behind the editor of “Scary Fast.” But we’re not in a real edit suite here — we’re actually on one of the sets from the production. Did Apple really edit in Premiere? I have a feeling that this and Stefan Sonnenfeld’s interview were staged on Apple's standing sets rather than in real studio environements to keep the production close to home, for cost, control, and secrecy reasons. So let’s assume Apple really did cut in Premiere. This means next to nothing. All editing software does the same job, and it’s unlikely Apple would impose a workflow on the production company they hired to both shoot and post-produce the video. Other than of course to ensure that it be cut on a Mac. It’s interesting to note that Apple’s Pro Workflows Group, representatives from which are interviewed in the behind-the-scenes video, are a part of the hardware division at Apple. Their charter is to promote and support professional use of Apple devices, regardless of which software they’re running. Should FCPX users be nervous that Apple might send it to live on a farm with Shake and Aperture? It’s hard to regain our trust here, but Apple did just release a very nice version for iPad a few months ago, and substantial updates to that and the Mac version just yesterday. So there’s really nothing to see here. Move along. They Colored in Resolve: Doesn’t Matter Apple hired Company 3 to produce this video. Company 3 is best-known as a color house. In my VFX and commercial directing career. I’ve worked with several amazing colorists there, from Dave Hussey to Siggy Ferstl to their CEO, Stefan Sonnenfeld, who is prominently featured in the behind-the-scenes. Stefan is one of the most prolific, talented, and well-known colorists working today. I modeled half the presets in Magic Bullet Looks after his famous grades on films like Transformers, 300, John Wick, Man on Fire, and hundreds more. Real colorist, not his real office. If you can get Stefan to color your video, that’s what matters — not the tool he uses. Resolve is “free” (with many asterisks), but a session at Company 3 is four-figures per hour. Whether you use Resolve, Magic Bullet, or whatever else, what matters here is that shooting log means color grading is not just possible, but essential, and great care was taken with this part of the process. This All Makes Sense. Why Do I Still Feel Weird About it? As much as I might disagree with an accusation that Apple was disingenuous to say “Shot on iPhone” about a massive production with seemingly unlimited resources, I understand where this feeling comes from. “Shot on iPhone” carries with it the implication of accessibility. We are meant to be inspired by this phrase to use a tool that we already carry with us every day to capture videos that might transcend mere records of our life’s moments, and become part of our artistic pursuits. And we should absolutely feel that way about the iPhone 15 Pro and Pro Max. The reason we feel slightly disconnected from Apple’s impressive exercise is not that they were dishonest — it's that their priorities were different from ours. Apple wants to sell iPhones, and to accomplish this, they spared no expense to put the very highest image quality on the screen. As a filmmaker, you care about image quality, but you care about other things too — probably more. Sticking to the 1x lens gives the best image quality, sure, but choosing the right lens for the story you’re telling might matter more to a filmmaker. You’ll probably use all the focal lengths Apple supplied. As much as you might value the clean image that comes from shooting at ISO 55, you might get more production value for your budget by using smaller lights (or available light!) and accepting some noise at higher ISOs. You might truly appreciate the value of a 180º shutter, and simply not always have a camera case/cage that allows you to mount a variable ND filter to your telephone. I ordered one from PolarPro the day the iPhone 15 was released and it still hasn’t shipped, so I’ve shot next to no 180º shutter footage so far. You might well understand that turning off image stabilization will improve your image — unless your shot is now wobbly, because you’re shooting handheld out the window of a moving car. So maybe you’ll leave stabilization on, and be a human crane, or gimbal, or dolly, or all of the above. Never use the 5x lens. Never use image stabilization. Never shoot through a dirty windshield. And never get this dope-ass shot. Let’s be honest: If image quality is your top priority, there are much better options for your next production than a consumer telephone. You’d probably choose the iPhone for accessibility, nimbleness, ubiquity, and cost. Those are great reasons, and when you pair them with image quality that can be mistaken for high-end cinema camera footage by a veteran colorist, you’ve got something magic. Give It To Me In Bullets You Long-winded Monster So we may well ignore much of Apple’s implied advice, but we would do well to follow some of it if we can: Use camera support. Not crazy camera support, but some. Use lights. Not crazy lights, but some. Use a camera app that allows manual control, like Blackmagic Camera Use 180° shutter, if you can (ND filters will help) Keep light off of the lens using a $8,000 matte box or a bit of black tape Hire literally the world’s most famous colorist. Or just do some color correction. And most importantly, shoot in log, with a good preview LUT The incredible production apparatus of my helicopter tunnel shot from my last post. Shot on iPhone Means What it Means to You All of this is academic if you don’t go put it into practice. If you got this far and feel empowered to wring the most out of your iPhone 15 Pro with just the right amount of gear, that’s great. If you actively forget all of this and occasionally flip on the Log switch so you can play with the color of your iPhone videos in post, that’s great too. Because here’s the thing: movies have already been shot on phones. No production’s decisions validate any camera for all other production needs. You decide what “Shot on iPhone” means to you, if anything. And the way you decide is by getting out there and shooting something. View fullsize I went to Peru with nothing but my iPhone 15 Pro Max. I shot some stuff with zero gear, and I’m having a blast color grading it various ways. Tags: Apple, Blackmagic Camera App, Magic Bullet, Color, Filmmaking, iPhone",
    "commentLink": "https://news.ycombinator.com/item?id=38182869",
    "commentBody": "What does and doesn&#x27;t matter about Apple shooting their October event on iPhoneHacker NewspastloginWhat does and doesn&#x27;t matter about Apple shooting their October event on iPhone (prolost.com) 263 points by robenkleene 12 hours ago| hidepastfavorite131 comments user_7832 12 hours agoI think there are 2 parts to this:One is \"iPhone camera sensors are competitive with commercial offerings in some cases\". I think this is what Apple was trying to go for with the entire thing including the behind the scenes.The other is \"If you (edit: just) have an iPhone you too can make such a video\". Which is what anyone who isn&#x27;t affiliated with the film industry (aka 99% of the population) might think, especially if they didn&#x27;t see the behind the scenes.\"Shot on iPhone\" hence has 2 perspectives. reply tshaddox 11 hours agoparent> The other is \"If you have an iPhone you too can make such a video\". Which is what anyone who isn&#x27;t affiliated with the film industry (aka 99% of the population) might think, especially if they didn&#x27;t see the behind the scenes.I honestly don&#x27;t think it&#x27;s a reasonable takeaway for anyone who is at all interested in creating highly produced video with their iPhone. Even if you&#x27;re an absolute beginner, it&#x27;s abundantly clear that these Apple videos are serious productions.It&#x27;s not significantly different than hearing that an accomplished journalist wrote a column on their iPad, or a successful entrepreneur manages their schedule with their iPhone calendar, or a famous musician uses GarageBand for songwriting (or even full production).The point in all of these examples is never that you can accomplish these things with an iPhone and don&#x27;t need talent, creativity, years of practice, other gear, etc. The only point is that the iPhone is not a significant limiting factor on the quality of results you can achieve. reply rchaud 10 hours agorootparentYep. As any photographer or videographer will tell you, it&#x27;s not the camera that makes the difference, it&#x27;s the person operating it. Do they understand the importance of lighting? Can they get around the technical limitations of the device?We all know that Apple demos take place under the most regimented of conditions. Jobs&#x27; iPhone demo had full reception bars hard-coded into it. I imagine the iPhone cameras were used in similarly generous conditions. reply klodolph 10 hours agorootparentI think beyond “it’s not the camera that makes the difference” we need to have a discussion about lighting.A shitty camera and shitty lens in fantastic lighting will give good results. The best camera with the best lens in awful lighting will give bad results.Kind of like microphones, that way. Like how the Apple video was shot on an iPhone (except it had great lighting and a ton of production work), there are hit songs with parts recorded on iPhone. They aren’t advertised like that. But it happens. The advantage of the iPhone is that it’s already in your pocket, and for something as intimate as singing, that proves to be a major, major advantage. Your producer may try to get you to recreate that beautiful performance in the studio, but audio quality doesn’t matter as much when you compare the recording of a good performance to the recording of a much better performance. reply Retric 9 hours agorootparentThe amount a good camera can tolerate bad lighting has significantly improved over time, as has the minimum quality of an average camera.Not that long ago you needed a great camera and great lighting to get a great result, now there’s a lot more flexibility available. Decent camera + great lighting or decent lighting + great camera both work well enough for the general public not to notice anything wrong. reply crazygringo 7 hours agorootparentI think people are using \"lighting\" two different ways in this conversation.Assuming there are decent light levels to begin with, \"lighting\" means the play of light and shadow that makes your subject pop, that makes their face look like it has depth, then generally makes everything look attractive. This has nothing to do with your camera, and cameras have not gotten better at this, because cameras are irrelevant to it. When TV shows are lit well today, this is the lighting that&#x27;s usually being talked about.The other thing \"lighting\" means is \"light that isn&#x27;t too low\". This was harsh studio lighting in the 1920&#x27;s for example, and why even in the 1960&#x27;s studio scenes couldn&#x27;t be \"naturally\" lit -- and which was a major focus of lighting TV shows well in the 1960&#x27;s, for example. But which we don&#x27;t worry about anymore -- TV shows are generally shot at \"real life\" brightness levels today.The larger point is that today, when we say that it&#x27;s the lighting that matters for a shot more than the camera, we&#x27;re usually referring to the first type I&#x27;m describing -- the artistic lighting. Cameras have not gotten any \"better\" at that. What has happened is that they&#x27;ve enabled shots at low lighting that weren&#x27;t possible before, but that&#x27;s only relevant in low-light conditions -- and you still need to distinguish between good&#x2F;bad artistic lighting even when the light is low. reply Retric 4 hours agorootparentLight levels and “artistic Lighting” are linked through a camera’s dynamic range.Harsh studio lighting wasn’t just about the total amount of light it was also attempting to compensate for limited dynamic ranges. Getting everything evenly lit was an exacting process which has simply become less demanding.The artistic side of lighting is just as complex and relevant as it ever was. However, as sensors get closer to human capabilities setting things up gets closer to what you see is what you get, which is extremely helpful. There is still a disconnect which must be accounted for to get the best results, and plenty of new options to play with. But fewer gotchas mean decent lighting is generally fine. reply Puts 1 hour agorootparentprevI think what probably confuses people is that since everything was so dark they think that \"wow the iPhone handles low light really well\", but actually that only has to do with exposure. If you look at the behind the scenes shots they still had massive LED panels lighting the scenes. reply Espressosaurus 8 hours agorootparentprevA lot depends on how you&#x27;re viewing the content too. Lots of stuff that looks good on a tiny phone screen looks like trash on a monitor.And forget about printing, not that anyone other than dedicated photographers do that these days. reply guappa 3 hours agorootparentprev> Your producer may try to get you to recreate that beautiful performance in the studio, but audio quality doesn’t matter as much when you compare the recording of a good performance to the recording of a much better performance.Nobody is going to keep your iphone recorded song in their playlist. reply nimbleal 7 hours agorootparentprevLighting is also over-emphasised, in my opinion. The unfortunate truth is that it&#x27;s everything. Production design and talent are HUGELY important. If you have an amazing art department, costume design and beautiful people your camera and lighting team can be on autopilot and it will still look pretty great.Grip is also huge for high production value camera movement — and you&#x27;ll see on the BTS video Apple absolutely don&#x27;t skimp here. Pretty funny putting a $1000 phone on a $200,000 (at least! I&#x27;m not a grip guy, but that&#x27;s the region) crane. reply Puts 1 hour agorootparentI think the point here is not the effort it takes to make good lighting - but the cost. A normal person will not have 10x2000w ARRI panels. But they will look at this production and think that they will get the same result because hey it was shot on an iPhone. reply nimbleal 36 minutes agorootparentAbsolutely. I suppose what I was commenting on was a pattern I’ve observed that goes something like:1. My videos don’t look good, it must be because I don’t have a good camera&#x2F;lens 2. I have a good camera lens, but my videos still don’t look good, it must be because I don’t have good lightsAnd a lot of people just stop there because lighting is a lot more work and a lot less fun (for most people) than buying expensive cameras, but for those that do pursue lighting, there’s a third stage:3. I’ve got a good camera, good lights AND I know how to use them AND STILL my video looks a bit underwhelmingThat’s when you realise location, art, talent etc are massively important too.Ie you could have a truck full of Arri lights and if you have bad production design and inappropriate talent it will still look bad. reply Puts 29 minutes agorootparentTrue true :) replyyreg 7 hours agorootparentprev>it&#x27;s not the camera that makes the difference, it&#x27;s the person operating itMostly yes, but the phone cameras are easier to operate (in a way to get really nice photos) than more traditional cameras. My mom had this exact remark about her iPhone (and her ability to take nice photos) on a recent vacation. reply chrisweekly 11 hours agorootparentprev\"musician uses GarageBand for songwriting (or even full productionSergeant Peppers Lonely Hearts Club Band (The Beatles&#x27; masterpiece, one of the most highly-regarded and influential albums of all time) was recorded on an analog 4-track. reply 20after4 10 hours agorootparentAn extremely high quality analog 4 track. Not to be confused with (not even in the same universe as) the cheap 1980s or 90s tascam 4-track cassette tape recorder that people are much more likely to have encountered. reply edmundsauto 2 hours agorootparentAny idea how much the device cost at the time? reply Shinchy 34 minutes agorootparentNot sure about at the time, but I have had the opportunity to record onto one of the tape machines they used (they had multiple) and the studio had paid around £30,000 for it. reply mixmastamyk 10 hours agorootparentprevNot really if you compare it the 1969&#x27;s Abbey road, which sounds quite a bit better. American productions were sounding much better though the mid to late 60s as well. reply emchammer 8 hours agorootparentAbbey Road sounds clearer because it was the first Beatles to be produced with a transistorized mixer. The mixer used in Sgt. Pepper had vacuum tubes. reply jkaptur 11 hours agorootparentprevAt the time it was recorded, that was cutting edge tech, wasn&#x27;t it? reply jcrawfordor 11 hours agorootparentYes, in that everything was being recorded on analog tape in that era because it was the best quality recording format available.The album is a little unusual in that by 1967 tape recorders with larger channel counts were becoming more common, allowing separate recording of most of the original channels. But linear editing of audio was very difficult, recording engineers still did the mix as live, so there were recording studios that hadn&#x27;t seen a reason to make the upgrade or were attached to older equipment that they were very familiar with. Especially with analog equipment prominent recording engineers were often averse to new equipment since they would learn how to get the best results out of their particulat setup - and things like frequency response could vary noticeably from one model to another. reply jauntywundrkind 11 hours agorootparentprev>2 track recording is still a rare & deluxe feature in most consumer gear!Even in professional gear, it&#x27;s usually a ridiculous jump in price - often double - to much fancier hardware to get more channels.It makes sense as few people do need it, but I do wish there were more assorted consumer electronics that would throw in more channel recording just because. Rather than as an upsell to way more expensive gear. reply ksherlock 10 hours agorootparentprev... and no amount of money or technology can make \"Now and Then\" a good song. reply onion2k 2 hours agorootparentprevI honestly don&#x27;t think it&#x27;s a reasonable takeaway for anyone who is at all interested in creating highly produced video with their iPhone.That isn&#x27;t who this marketing is aimed at though. Apple are acutely aware that &#x27;camera quality&#x27; is a key selling point for consumers. People want to point their phone at something and take a good looking photo. That isn&#x27;t &#x27;people interested in creating highly produced video&#x27;; it&#x27;s people who want their selfies to look nice. By showing a professionally shot production where the camera is an iPhone and everything else is pro video production Apple make people believe their non-pro photos will be much higher quality than other people&#x27;s photos.The fact Apple released a behind the scenes video should tell you that they&#x27;ve thought about a scenario where someone makes a video with an iPhone to show it&#x27;s not as good as Apple&#x27;s marketing demonstrates. The behind the scenes video is Apple covering their ass because they know as well as we do that buying an iPhone isn&#x27;t going to get you pro video quality footage.If anything Apple&#x27;s marketing makes me think that selfies on a Google or Samsung phone are probably better than an iPhone just because Google and Samsung don&#x27;t seem to need to tell me \"you can make this video with our phone! (but wait, not like that..)\" reply grujicd 1 hour agorootparentWell, Samsung did hire Ridley Scott to make a short movie using S23 Ultra. reply matwood 10 hours agorootparentprev> The only point is that the iPhone is not a significant limiting factor on the quality of results you can achieve.Which is a big deal. reply user_7832 11 hours agorootparentprev> I honestly don&#x27;t think it&#x27;s a reasonable takeaway for anyone who is at all interested in creating highly produced video with their iPhone. Even if you&#x27;re an absolute beginner, it&#x27;s abundantly clear that these Apple videos are serious productions.I agree that that&#x27;s how it is in reality, but that&#x27;s not something many people really know or understand. Apple also likes to sell their products as \"see how good our x product is that we used in-house\" which likely further may make some people think an iPhone is enough to make a high quality video.(I think the funny thing is that even without extra hardware an iPhone can shoot very good&#x2F;near professional quality video but this debate is only about Apple using very fancy hardware. I also made a small edit to my comment.) reply gumby 10 hours agorootparentYes, but did you make the edit with an iphone? reply philistine 8 hours agorootparentThe behind the scenes video had lavish scenes of the editor working on the footage shot on iPhone ... with Adobe Premiere. reply nimbleal 7 hours agorootparentLots of shots of Davinci Resolve, didn&#x27;t spot any Premier at a quick glance? But it&#x27;s not unusual for both to be used on the same production replyfsckboy 7 minutes agoparentprev> \"Shot on iPhone\" hence has 2 perspectives.Apple&#x27;s perspective is that they want to sell a lot of iPhones. They don&#x27;t care what 1% who have access to professional gear do. There are a huge number of young people who can afford iPhones and can&#x27;t afford much additional gear, and want to be \"creators\". They&#x27;ll do all the learning and work they have to do.This will sell more iPhones, whether it makes better content or not (it will because more people trying, but that&#x27;s not Apple&#x27;s business) reply threeseed 11 hours agoparentprev> If you have an iPhone you too can make such a videoYou can though.What it showed was that the real limitation to making high quality content is skill and knowledge. You can get away with just your iPhone, iPad and cheap lighting from AliExpress for 99% of the shots.Having expensive equipment simply allows you to deliver that quality fast and at a consistent level. Which is what commercial clients demand. reply WillPostForFood 11 hours agorootparenthttps:&#x2F;&#x2F;www.apple.com&#x2F;newsroom&#x2F;images&#x2F;2023&#x2F;10&#x2F;behind-the-sce...iPhone, knowledge, skill, another half million in fancy equipment, and you are good to go!Seriously though, there was an astounding amount of cool gear in the behind the scenes. If it was just a guy shooting handheld iPhone using his skill and knowledge, that&#x27;s one thing. It seems to be a different value proposition to take all the equipment, and crew, from a multi million dollar production company, and just swap the camera for an iPhone. It is extremely impressive quality demonstration, but not clearly accessible to the typical iPhone purchaser. reply threeseed 11 hours agorootparentThere is an astounding amount of cool gear. None of it is mandatory.You will be surprised what a DJI gimbal, duct tape and house hold objects could accomplish.The limiting factor is now very much creativity and passion. reply kbf 9 hours agorootparentI was just on a poorly planned shoot where the iPhone saved us. The camera we used was too big and heavy to actually get the camera movements we had planned. We had just gotten a new DJI phone gimbal to test and we ended up using it with the iPhone. This was on a green screen stage so we didn’t want character from the lens or a shallow depth of field. All the shots were within the focal range of the phone too. I’m guessing about 70% of the final shots were shot on the phone. And because it’s LOG and ProRes, the footage fits right into the pipeline. Now even though we shot on a phone, we didn’t turn off the lights or send the actors home so maybe that’s cheating… reply joemi 10 hours agorootparentprevMy takeaway from the article was that most of that gear either wasn&#x27;t necessary or was only necessary because of Apple&#x27;s specific self-imposed production requirements. And also due to the fact that they just hired a production team like they always do for these things, but this time they had them slap the iphone into the usual equipment in place of their regular camera. reply ska 11 hours agorootparentprevProfessional photography and videography gear has always only been about that though. It broadens the range of shots you can get and&#x2F;or the efficiency of the process (and usually puts up with more abuse). reply Aurornis 9 hours agorootparentNot completely. You could always make certain types of excellent creative works with cheap gear, but cheap gear would limit you to more lo-fi aesthetics. It also requires more careful attention to everything else from lighting to acoustics to work around deficiencies of the gear.For example, cheaper camera gear would have worse low light sensitivity, meaning you’re either getting grainy images or you need extra lighting. As cameras improved, fewer compromises need to be made and you can get the result you want.With infinite creativity and luck you can always get something get if you try long enough, but great gear really does open the door to more options and opportunities to catch a good shot.Another good example is sports photography, where fast imaging is mandatory for capturing movement shots. With slower cameras your only option would be to catch slower, more stationary moments. reply amluto 9 hours agorootparentI’m not even remotely close to being a professional photographer or videographer, but I’ve used camera phones (including old iPhones) with amazingly poor performance in anything but the brightest light. Careful attention to lighting might have involved lighting scenes painfully brightly, which causes its own problems.Modern phone cameras seem to perform at least as well as I remember early fancy digital cameras performing, and they really are good enough for a lot of purposes. (But they still can’t do a good job of blurring the background. I keep expecting ML advances to improve this, but even latest-generation iPhones produce pretty bad results IMO in portrait mode.) reply ska 8 hours agorootparentprev“Broadens the range of shots”We aren’t disagreeing. But it’s mostly at the fringe where you can’t do anything at all with meh gear. reply BobaFloutist 10 hours agorootparentprevYeah like while getting a good shot is obviously a skill, there are shots of, for example, wildlife, that I fully can&#x27;t capture because it&#x27;s just too far away and I don&#x27;t have a zoom lens.Gear matters for things like that. reply tjmc 8 hours agorootparentprevThe professional gear can also be too good. I remember when the first Hobbit film came out the picture was so crystal clear it was distracting - like a very high end BBC drama. reply ShadowBanThis01 4 hours agorootparentThat wasn&#x27;t the issue. The Hobbit was shot at 48 FPS in true 3-D. While it might have seemed \"too clear,\" it was a truly remarkable movie experience that set a new standard of quality that we should get used to. It was higher-quality motion.I hate the fake interpolated frame rates on recent TVs. But if we started legitimately shooting at 48 FPS, I think we&#x27;d get over the \"video\"-ness of it. reply whyenot 10 hours agorootparentprevIt can. But sometimes the important thing is not the gear, but rather being in the right place and having the skill to frame a good composition or get good footage. reply chiefalchemist 11 hours agorootparentprevIt helps, sometimes. There are plenty of shooters running around with elite gear and getting slightly above average images of the classic (read: cliche) sunset, etc.Scarcity is the spark that ignites creativity.Put another way, look how many shite films Hollywood makes, and they have top gear.Great gear will never save a lack of creativity, lack of vision, etc. reply autoexec 7 hours agorootparent> look how many shite films Hollywood makes, and they have top gear.You can&#x27;t even judge the output of the gear by what Hollywood puts out. Maybe the gear does make a huge difference. For all we know every shot out of the camera is breathtaking, but it doesn&#x27;t matter if by the time it gets to the screen they&#x27;ve barfed orange and teal all over it, darkened it to the hide bad CGI, and edited it to assault the viewer with a muddy blur of special effects and fast cutting. reply ska 11 hours agorootparentprevOther than robustness, &#x27;pro&#x27; gear mostly expands the range of parameters you can push and still get a decent shot. It&#x27;s not going to give you an eye.Elsewhere in thread it&#x27;s correctly noted that in a lot of cases lighting is more important that cameras anyway. But similarly, you have to know how to set up - same applies though, the gear can&#x27;t do the setup for you. reply notatoad 9 hours agoparentprev>The other is \"If you (edit: just) have an iPhone you too can make such a video\". Which is what anyone who isn&#x27;t affiliated with the film industry (aka 99% of the population) might thinkno, 99% of the population doesn&#x27;t watch iphone launch events, and doesn&#x27;t care whether it was shot on iPhone or not. they have literally no opinion about this. of the 1% who cares that it was shot on iPhone, i&#x27;d guess roughly 95% understand that a professional photo shoot requires more than a camera, and the 5% who didn&#x27;t saw the behind the scenes video. nobody was mislead into thinking that Tim Cook&#x27;s assistant just pulled their phone out of their pocket and shot the launch video.the whole discussion around this video being shot on iPhone seems to have imagined a huge class of people who both care about this, and are dumb. presumably for the sole purpose of feeling smug about having the special insight of knowing the things communicated by the behind the scenes video that apple published and heavily promoted. those people you&#x27;re imagining might have been misled by this do not exist. reply dimask 9 hours agoparentprev> \"If you just have an iPhone you too can make such a video\"I do not think that most people before thought that if they got a professional camera they could just start shooting professional movies. reply ghaff 11 hours agoparentprevI agree on both points.From a still photos perspective, unless you&#x27;re using very wide or very long lenses, and&#x2F;or otherwise have relatively specific requirements that require burst shooting&#x2F;a viewfinder&#x2F;etc. phones can handle a lot. No-brainer ISO range is good enough for most things these days--and would have been unthinkable in the film era.I increasingly think about whether I really need anything other than my phone traveling even given I have a couple of good cameras and a lot of glass. I&#x27;ll still bring (mostly my mirrorless) camera if I&#x27;m doing a relatively photogenic \"exotic\" trip but often I don&#x27;t. reply matwood 10 hours agorootparentSame. I&#x27;ll often use my iPhone for general shots and leave a zoom on my z5 for other shots.When I was a kid just having a camera at all was a big deal. Now, every person has a great camera in their pocket almost 100% of the time. It&#x27;s pretty amazing to be honest. reply happytiger 11 hours agoparentprevIt’s broader than that, but simpler: it’s just what you can get out of a platform VS what you can get out of a platform under controlled conditions.It is no different than Intel or AMD benchmarking their chips, car companies and their mpg, electric cars and their ranges, etc.This is much ado about nothing. It’s just journalistic framing that has caused this discussion.If this is PR, which it’s likely not, it’s brilliant. reply 20after4 10 hours agorootparentI thought that everything apple does is PR (well mostly, everything else is a secret) reply willsmith72 11 hours agoparentprevThis is why this whole thing felt like a loss for Apple. They&#x27;re 100% right, it was shot on an iPhone, but they also had 99% of the population believing something which seemed really cool, and then turned out to \"appear\" misleading.Maybe this whole stunt was aimed at the 1%, and if so good for them, they succeeded. From a branding and PR perspective, I wouldn&#x27;t be happy if that was how my company was perceived to the general public. reply kergonath 11 hours agorootparentThere have been people shooting terrific pictures and great movies on phones for years now. Nobody is under the illusion that your holiday pictures will be great as well just because you used the same camera phone as a famous hip videographer.It does not appear misleading unless you really want it to. reply user_7832 11 hours agorootparent> Nobody is under the illusion that your holiday pictures will be great as well just because you used the same camera phone as a famous hip videographer.Unfortunately (fortunately?) that kind of marketing does work though. Going slightly tangential but collaborations with Leica&#x2F;Zeiss etc often are major marketing points in phone sales. reply astrange 9 hours agorootparentMy vague understanding is those are often real, ie Leica&#x2F;Zeiss actually do collaborate on lenses, coatings and camera tuning.And while they do say the camera isn&#x27;t the most important thing for a photo, one reason for that is the lens is more important :) replyjkepler 7 hours agoprevBack in 2010, these two stop-motion shorts were each shot on the Nokia N8: Dot [1] Gulp [2]Then in 2011, a short film and a feature-length were shot on the Nokia N8: Splitscreen: A Love Story [3] Olive [4]Oh, and back when Apple announced their first iPhone, Steve Lichfield was already filming his Phone Show episode 22 on a smartphone, the Nokia N93. [5] For years he filmed with an N8, then a Nokia 808, and eventually Apple&#x27;s camera tech caught up and he finished out his Phone Show filming on an iPhone.[1] https:&#x2F;&#x2F;www.aardman.com&#x2F;short-form-commercials&#x2F;nokia-dot&#x2F; [2] https:&#x2F;&#x2F;aardman.com&#x2F;short-form-commercials&#x2F;nokia-gulp&#x2F; [3] https:&#x2F;&#x2F;vimeo.com&#x2F;25451551&#x2F;description [4] http:&#x2F;&#x2F;blog.gsmarena.com&#x2F;olive-is-the-first-full-length-feat... [5] https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=7FMHcG-M_FY. reply mortenjorck 11 hours agoprevI previously had a rudimentary understanding of log, but the author&#x27;s other recent piece devoted to it in the context of the iPhone 15 pro (https:&#x2F;&#x2F;prolost.com&#x2F;blog&#x2F;applelog) gave me a much better appreciation of its importance to professional-looking video. From that article:> But with this iPhone 15 Pro Max footage shot in Apple Log, I can recover all the detail — or just let it overexpose gracefully into this ACES output transform, for a smooth, film-like look. This soft highlight rolloff in the log-to-video conversion is called a “shoulder” in film, describing the upper part of the classic s-curve. A nice shoulder for your highlights is a big part of what makes footage look “pro” — especially when your grading happens underneath it. reply helf 11 hours agoparentLog does improve things a lot. Being able to do proper 10bit&#x2F;14bit+ video recording is also a bonus. But you have had the ability to use various color spaces and various non-linear recording formats for awhile on various devices (multiple androids have had this from stock for years plus 3rd party software really unlocks the sensor potential).But Apple markets it better :P reply shalmanese 4 hours agoprevI&#x27;m almost certain that everyone has this story entirely backwards because people are used to thinking in a linear sequence of this happened, then that happened. Apple famously works backward from that process.Reading the story behind the story, I think what happened is that several years ago, Apple execs were looking at a range of plausible technologies that were becoming feasible and were trying to find some kind of coherence among them through the story they wanted to tell. The story that was really speaking to them, as Gruber identified [1], was that finally the professional and consumer market were about to merge in really interesting ways.I think what happened was at that point in time, they decided that the iPhone 15 Pro was going to be used to film the keynote for the iPhone 15 Pro and that this was the target given to all teams to give them clarity and focus to deliver a coherent end product.Even tiny things like, why did they delay the introduction of USB-C for so long? Start making sense under this framework. If you&#x27;re not used to this mode of thinking, a lot of the things I&#x27;m saying can sound like a stretch but if you adopt the framework, a lot of tiny things they mention suddenly make sense.People are focusing on the specific output which is a single video but the power comes not from the output but from understanding the process that resulted in that output. Apple knows that other companies will always struggle to reproduce their exact process which is the core source of a durable sustaining advantage.[1] https:&#x2F;&#x2F;daringfireball.net&#x2F;linked&#x2F;2023&#x2F;10&#x2F;31&#x2F;downplaying-sho... reply atleastoptimal 3 hours agoparentIt doesn&#x27;t seem that complicated. It&#x27;s as simple as \"The camera is pretty good now, what if we marketed its quality by shooting our event with it and hyping it up that way?\"Likewise USB-C: \"We can make more money if we have a special proprietary charger\". It&#x27;s never that complicated really, it&#x27;s all in execution. reply makeitdouble 3 hours agoparentprevAnother variation of this approach is the Amazon Press release method, where internal product pitches start with what the press release would look like, and they walk through the step backwards to see what is needed to make that happen.PS: A summary of the method https:&#x2F;&#x2F;www.productplan.com&#x2F;glossary&#x2F;working-backward-amazon... reply soulofmischief 4 hours agoparentprevSo under this framework, why did they delay the introduction of USB-C for so long? reply shalmanese 3 hours agorootparentPrior launches had more important priorities to include so it was easy for teams to push this feature back knowing that the only mandatory launch date for it to hit was the iPhone 15 Pro launch.Having the clarity over what&#x27;s important allows teams to perform rather than endlessly debate over tradeoffs. reply Aloha 4 hours agorootparentprevBecause they promised thr connector wouldn&#x27;t change again quickly when they introduced lighting. reply reqo 11 hours agoprev>“Shot on iPhone” doesn’t promise “and you can do it too” any more than Stanley Kubrick lighting Barry Lyndon with candlelight means anyone with candles can make Barry Lyndon.What a beautiful way of describing the fallacy of the converse! reply drexlspivey 11 hours agoparent> anyone with candles can make Barry LyndonAnyone with candles and NASA lenses reply m463 10 hours agorootparentI vaguely remember reading about special low f-stop lenses.Here it is:Kubrick was \"determined not to reproduce the set-bound, artificially lit look of other costume dramas from that time.\" After \"tinkering with different combinations of lenses and film stock,\" the production obtained three super-fast 50mm lenses (Carl Zeiss Planar 50mm f&#x2F;0.7) developed by Zeiss for use by NASA in the Apollo Moon landings, which Kubrick had discovered. These super-fast lenses \"with their huge aperture (the film actually features the lowest f-stop in film history) and fixed focal length\" were problematic to mount, and were extensively modified into three versions by Cinema Products Corp. for Kubrick to gain a wider angle of view, with input from optics expert Richard Vetter of Todd-AO. The rear element of the lens had to be 2.5 mm away from the film plane, requiring special modification to the rotating camera shutter. This allowed Kubrick and Alcott to shoot scenes lit in candlelight to an average lighting volume of only three candela, \"recreating the huddle and glow of a pre-electrical age.\" In addition, Kubrick had the entire film push-developed by one stop.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Barry_Lyndon#Cinematography reply Clamchop 9 hours agorootparentprevLight sensitivity of modern digital sensors is far superior to any film, especially for the quality delivered. Like, really far. You won&#x27;t be able to get every characteristic of that lens, such as the absurdly shallow depth of field, but you can get close with a much less exotic (but still rare) lens around f&#x2F;1.People were admiring how closely you could reproduce the look of the candlelit scene all the way back when Canon inadvertently kicked off the low-cost ciné phenomenon with the EOS 5D Mark II.I think most know that the major barrier to making a movie proper is the hundreds of thousands or millions of dollars spent on everything else. Even ignoring paying for talent, the outrageous budgets of even lower-tier films are widely publicized.But many are also tickled pink to make something out of ordinary life that has some of that Hollywood look. reply throw0101a 8 hours agorootparentprev> Anyone with candles and NASA lensesIt isn&#x27;t the 1970s anymore: Robert Eggers was able to shoot candle-list scenes for The Witch without NASA lenses:* https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=qtb0qAu-Hjc* https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Witch_(2015_film)The entire movie cost US$ 4M, which was less the $6M for Wiseau&#x27;s The Room. reply astrange 9 hours agorootparentprevVery good lenses are more accessible than they sound; there are decent cheap f0.95 mirrorless lenses out there, and even if you want an expensive one you can rent it. Just don&#x27;t drop it. reply drexlspivey 9 hours agorootparentKubrick used f&#x2F;0.7 in 1973 reply foldr 11 minutes agorootparentThat&#x27;s only about half a stop brighter. The increased sensitivity of digital sensors more than makes up for that. replyGeekyBear 11 hours agoprevThe biggest takeaways:> There is one single feature of the iPhone 15 Pro that made this stunt possible: Log.> They Used the [free] Blackmagic Camera App: Matters as Much as Log> Lighting matters more than any camera, more than any lens... Big, soft LED lighting is actually quite affordable these days. [with a specific product mentioned]Apple used the myriad options in the Blackmagic Camera App to prioritize image quality above everything else.> Apple decided that they must shoot at ISO 55 (the lowest, although possibly not the native ISO of the 1x camera) for the highest image quality, and with a 180º shutter for the most pro-camera lookApple had the log footage they shot professionally color graded. reply jojobas 10 hours agoparentThe lighting&#x2F;ISO bits are where I&#x27;d call it \"deception\". You use the same phone to snap your lil Johnny having breakfast and end up with just as grainy&#x2F;blurry denoised picture as any other mom. Proper cameras with thousands of times the lens area are at least not trying to make you believe it&#x27;s that cheap and easy. reply mplewis 10 hours agorootparentThey were never claiming that the lens and sensor were magic, though. reply jojobas 9 hours agorootparentYep, deception by omission. reply berkut 11 hours agoprevOne thing I&#x27;m curious about is how they avoided lens flair from small bright lights - the iPhone&#x27;s lenses in my experience produce multiple very pronounced lens flares when shooting bright lights (and older iPhones used to produce one large green flare as well, but I think that&#x27;s been reduced in the 14 and 15 - I&#x27;m sure other phones do as well, I&#x27;m just only familiar with iPhones these days).Very large light sources likely helped (as did the matte boxes), but maybe they carefully chose the camera angles as well to minimise this? reply kergonath 11 hours agoparent> Very large light sources likely helped (as did the matte boxes), but maybe they carefully chose the camera angles as well to minimise this?All of it, I think. In my experience these ugly flares come mostly from point sources (things like streetlights), so large, soft light sources should help. Also, the matte boxes help controlling where the light that hits the lens comes from, so in effect it makes it easier to have a good angle, on top of making sure that nothing hits the glass at a small angle. reply ChrisMarshallNY 11 hours agoprevThat was an excellent explanation of doing a pro video shoot&#x2F;post-prod.As they noted, the camera, itself, was almost irrelevant (except for that ProRes Log thing).It shows how much work goes into video&#x2F;movie production.The formula I heard from a video editor, was that every second of final, is about a half hour of post. reply GeekyBear 10 hours agoparent> As they noted, the camera, itself, was almost irrelevant (except for that ProRes Log thing).As mentioned, the \"ProRes Log thing\" was the single most important feature for enabling professional use cases.A prior post from the same author explaining the whole \"ProRes Log thing\" in more detail:https:&#x2F;&#x2F;prolost.com&#x2F;blog&#x2F;applelog reply ChrisMarshallNY 8 hours agorootparentI know. I was being a bit \"tongue in cheek\" about it.I used to work for a camera company. I&#x27;m familiar with it. reply FireBeyond 10 hours agoparentprevAnd yet, while almost irrelevant, Apple fawned over that aspect of it. As did all the other usual sites, including this one, that decided that any negative take on the topic was \"a bad one\". Thanks, Prolost. reply Animats 4 hours agoprevMuch classical production equipment is bulky. You need stability, but not support for fifty kilos at the camera end.[1] Here&#x27;s a Louma crane from 2012. It&#x27;s beautifully controlled, but huge. It looks like something you&#x27;d use to move bricks to an upper floor of a building site. That was needed with a Panavision camera and a TV camera for aiming at the business end. Now you can lighten up.Half of those Louma crane shots could be done today with a DJI Mini 4 drone.What do pros use today when you need a precisely controlled boom for quiet indoor use and the camera only weighs a few hundred grams? There must be something more compact than the Louma monsters.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=-q_Dam9nD0E reply linsomniac 8 hours agoprev> They Used the [free] Blackmagic Camera App: Matters as Much as LogOne thing I&#x27;m really excited about from this is timecode. I only dabble in videos, things like my kids performances, but I always like to have a couple cameras (gives some variety, in case someone walks or stands in front of one of the cameras). I&#x27;ve been using cheap action cams and syncing them is the bane of my existence. Being able to get timecode out of a couple iPhones would be fantastic!I&#x27;ve been eyeing the GoPros, they have \"labs\" firmware that can do time sync, and the latest camera has that built in. But it also sounds like they have overheating problems and can&#x27;t really record more than ~20 minutes without a break. reply system2 3 hours agoparentI doubt you can shoot 20+ minutes on iphone when everything is maxed out. My iphone 14 was overheating after 10 minutes of 4k recording. reply shepherdjerred 11 hours agoprevReally interesting blog post!It seems like iPhones really can do serious filmmaking (with the help of the equipment mentioned in the blog post). I&#x27;m curious how this translates to photography.How much would you need to spend on a dedicated camera to shoot better photos than an iPhone can? reply mannyv 9 hours agoparentIt depends on what kind of photographs you&#x27;re taking and the conditions.If you&#x27;re going to be taking pictures of people indoors with bad lighting you need a lens with an aperture of 2.8 or less, probably a 1.4.If you&#x27;re going to be taking group pictures indoors you&#x27;ll probably need a wider angle 2.8 lens.If you&#x27;re going to be doing indoor sports a 70-200mm 2.8 is probably the minimum.If you&#x27;re going to be doing outdoor sports with good lighting a 4.0+ is probably fine.If you&#x27;re doing outdoor landscapes you just need a wide lens, like 10-30mm and a tripod.I&#x27;m not a pro by any means, so take this with as much salt as you want.Any camera that can handle this will do fine. There are tons of cheap full-frame cameras out there now. But lenses generally don&#x27;t drop in price, even if they&#x27;re really old - which is quite aggravating. reply mannyv 9 hours agorootparentOh, the great thing about 1.4 lenses is you don&#x27;t need a flash - but smaller apertures get weird because the depth of focus gets really short, so you have to learn out how to deal with that.Example: with a 1.4 lens if you focus on the G key on your keyboard the T and B keys will be out of focus. Some 1.4 lenses have back&#x2F;front focus issues, where you focus on G but the picture is actually focused on T (back focus) or B (front focus). This gets more complicated the further away you are from your subject, since the DoF will be small; you might accidentally focus on someone&#x27;s nose instead of their chin, etc.OTOH you can take great pictures with a 1.4 in 1 lumen (essentially 1 candle). reply _tik_ 5 hours agoparentprevI was deliberating between purchasing a new iPhone or a camera. I opted for a camera because of its more affordable price and longer lifespan. Bought an almost new, second-hand Sony full-frame camera complete with a lens, It was less than $1.5k. reply xuhu 10 hours agoparentprevWedding photography costs $600 to $1000 over here, the equipment is typically 4 to 8 years old and costs about $1500 (body + 24-70mm lens + flashes, MPB.com prices). reply stephen_g 9 hours agorootparentWhere is over here? I’ve done a few weddings back in the day, the lenses I’d use (24-70 f&#x2F;2.8 and 70-200 f&#x2F;2.8) each cost over $2000 new in today’s US dollars… Then you have backup lenses, backup SLRs, etc. (but I’d usually borrow gear (still pro gear) as backup from people I knew which made things a bit cheaper, and I’d lend stuff to them when they needed) reply vouaobrasil 8 hours agoparentprevAs a pro photographer, I can say that an iPhone would be useless for 95% of my work. Even a used $500 camera would be more suitable.... reply tapanjk 3 hours agorootparentCan you please elaborate? What is it that a used $500 camera can do which an iPhone cannot? This is a genuine question, not a challenge. reply yieldcrv 10 hours agoparentprevI only use certain other cameras to get into some rooms and be taken seriously to photograph peopleI don&#x27;t need them for anything at the moment, I haven’t taken a dedicated camera on a sightseeing tour or hike in 12 years despite my enthusiast interest in camera gear and my ability to appreciate focal lengthsinterestingly, if you do to the trendiest hipster hangouts, people have point and shoots now, having graduated from polaroids in the most contrived “Y2K” rerun possible reply mrbonner 11 hours agoprevI don’t know how the pros use the iPhone to shoot such amazing photos. I have the iPhone 12 Pro and the photos I shoot are mediocre at best and out of focus or weird lightning at worst. Did they use a tripod everywhere they go? reply CharlesW 10 hours agoparent> Did they use a tripod everywhere they go?Yep, there&#x27;s a whole world of tools designed to avoid camera shake¹: Tripods, monopods, gimbals, dollies, suction mounts, etc.¹ Unless that&#x27;s what you&#x27;re going for, e.g. Blair Witch Project reply matwood 10 hours agoparentprevThe classic shot on iPhone 3GS! behind the scenes.https:&#x2F;&#x2F;fstoppers.com&#x2F;commercial&#x2F;iphone-fashion-shoot-lee-mo... reply macintux 9 hours agoparentprevI&#x27;d be curious what subjects you pick.I&#x27;ve been very happy with my iPhone photographs for the last 10+ years, to the point that I stopped using my DSLR. But, and it&#x27;s a big but, lighting and subject and distance matter a great deal. reply dheera 8 hours agoparentprev> out of focus or weird lightning at worstYep that&#x27;s the problem. Not the camera.Fix your focus and fix your lighting. That&#x27;s 95% of professional-quality footage, in most cases.Good indoor lighting, by the way, isn&#x27;t cheap, and that&#x27;s the part they didn&#x27;t tell you they probably spent tens of thousands on.Yeah, if you shoot with your IKEA lights and your bedroom mess in the background, it&#x27;s going to look like it was \"shot on a shitty phone\" even if you have an Arri camera.Oh and here&#x27;s the other killer thing pros don&#x27;t tell you -- broad sunny daylight looks like shit on any camera. But it&#x27;s the time 95% of the population likes to go outdoors.You want some dramatic clouds? Chase a storm. You want that crack of dawn effect? Get up 2 hours before the crack of dawn to set up. reply yieldcrv 10 hours agoparentprevHave you taken a photography class?You don’t need an MFA or much experience, just a set of guidelines, how to conform to them and knowing when to break them reply duxup 12 hours agoprevI thought this was going to be similar to all the hot take stuff it references at the start about the event being shot on an iPhone... but rather this is a nice technical walk through on some features and what they mean. Very good read. reply tehnub 11 hours agoprevGreat article! I&#x27;ll definitely try playing with some of these settings in the blackmagic camera app. His practical examples like blocking the light with his hand are quite inspiring! reply great_psy 11 hours agoprevOf course there is more to it than just the phone.If I gave you a 100k Alexa camera, could you make the apple event without all the other gadgets?Sure the camera is capable, but there’s so much more around it. I think this tech allows the currently 18 year old next Spielberg to shot some cool video with relatively low budget.For 99% of people buying this phone they were not even thinking of making a film of the keynotes quality to start. So talking about the extra gear is a moot point.For the few that want to accomplish something like that, know they can buy a 1.5K phone, and film something that will look decent. Maybe not like the keynote, but good enough to be comparable with the quality of a movie shot 10 years ago. Which is pretty good especially if you’re not projecting it on a huge screen.The other thing that will be coming in the not too distant future is ai enhanced filming. You film in questionable quality, and you feed that to the machine model to spit out something in higher resolution( both pixels per inch, but also color&#x2F;light depth) in which case this phone quality will be plenty. reply simbolit 11 hours agoparent> ai enhanced filming. You film in questionable quality, and you feed that to the machine modelthat is a promised \"coming soon\" feature of the new google phone. as it is \"coming soon\" nobody knows whether it delivers on that promise. reply great_psy 9 hours agorootparentThat’s ok.Even if Google phone does not deliver, there will be software that will deliver, if not next year in the next five.We already have the technology to do it for a single photo. Making it possible for a whole movie is just an optimization problem. I have no doubt we will get there. reply matwood 10 hours agoparentprevSomeone who is into making movies can also build cheap lighting. High end photography&#x2F;videography is more accessible than ever before. reply great_psy 9 hours agorootparentYes it is, see YouTube, TikTok etc. some of those videos are high quality. reply nerdbert 7 hours agoprevOne question: couldn&#x27;t the 180° look be created algorithmically after the fact, freeing them up to use a wider ISO range? reply JKCalhoun 6 hours agoparentFake motion blur? Seems challenging. reply tehnub 2 hours agorootparentI&#x27;ve heard that it is indeed challenging: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34065048 reply incognition 6 hours agoprevWhere&#x27;s the ablation chart. Desk reject reply seydor 4 hours agoprevAnd yet i find the videos entirely cheesy.But Apple will probably release the iCrane, for only $99999 reply yieldcrv 10 hours agoprev> Lighting matters more than any camera, more than any lens.Was essentially my comment, the log processing is pretty awesome though reply RIMR 11 hours agoprevHonestly surprised that none of these conversations have yet pointed out that Apple was one of the first large businesses to publicly engage in \"dogfooding\" with their February 1980 decision to purge all typewriters from their offices in favor of their own computers, and that this event nearly 34 years later continues the tradition of eating their own dog food quite successfully. reply ramesh31 10 hours agoprevRegardless of the camera, these things have started to have such a bizarre visual quality to them. Like some kind of tech-bro fever dream of an AI imagined utopia. So far gone from the days of Steve standing on a stage and actually talking to people. Kudos to folks like Zuckerberg not doing product announcements from an alien spaceship orbiting earth. Just look at the contrast: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4CpHrNNIzs4 reply simbolit 12 hours agoprev\"Lighting matters more than any camera, more than any lens.\"This. reply ghaff 11 hours agoparentBut often lighting is what it is. I can use a camera (and lenses) to compensate for a lot of crappy lighting that would otherwise make it tough to get a decent shot.I sometimes shoot photos at corporate events and the difference between \"real\" cameras and photos shot on phones is often pretty obvious. Sometimes it&#x27;s a matter of the phones being too far from the subjects or not optimally used but not always. reply adamredwoods 7 hours agoprevThis is all just marketing. Many cameras use log profiles, and Hollywood has been using non-traditional cameras for decades.Black Swan used a Canon 7D: https:&#x2F;&#x2F;nofilmschool.com&#x2F;2010&#x2F;12&#x2F;darren-aronofskys-black-swa...The funny part is I would not want to shoot a professional film with a phone. How would I recharge it? Dedicated cameras offer pop-out batteries and storage. iPhone won&#x27;t let you do that. reply al_borland 7 hours agoparentWasn&#x27;t that part of the selling point of USB-C. Hook it right up to whatever other equipment to offload video as you shoot, hook up external batteries that can be swapped out whenever mid-shot. How is swapping a USB-C battery back any different than a pop-out battery, other than having a cable? reply strunz 7 hours agoparentprevMagsafe batteries make it pretty easy actually reply amelius 12 hours agoprev [8 more] [flagged] endisneigh 12 hours agoparentNobel prize in medicine is certainly possible if they figure out scalable accurate glucose monitoring with an Apple Watch but other than that, seems like a stretch reply chollida1 12 hours agoparentprev [–] > Makes you wonder. When will someone in Apple finally win a Nobel prize?Win what specific version of the Nobel? reply caycep 12 hours agorootparenthistorically, the Nobels seem to prefer basic research and stuff; an applied science&#x2F;engineering company like Apple probably isn&#x27;t on their radar.They would have to fund a basic science blue sky division like Bell Labs or one of the old IBM pure research centers to really be a player in the game; but those things rarely play well with corporate interests.W the media arm of the company, I think they do have a few oscar contenders, so a nobel lit prize if they ever get into written content creation is not a stretch... reply simbolit 12 hours agorootparentprev [–] Economics is not actually a Nobel Prize, which leaves us with 5:Literature - unlikelyPeace - I can construe some scenario, but - again - unlikely.Physiology or Medicine - For the Apple Watch?Chemistry - unlikely, they don&#x27;t do fundamental researchPhysics - same reply culi 11 hours agorootparent [–] Nobody still knows why they gave Obama the Peace prize. Makes me think that&#x27;s the most likely one reply willsmith72 11 hours agorootparentOn the other hand, they also didn&#x27;t anticipate the negative reaction to that, so I doubt they&#x27;d do the same thing again knowingly. reply simbolit 11 hours agorootparentprev [–] Henry Kissinger won the Peace Prize 1973 for ending the Vietnam War.The Vietnam War ended in 1975. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple used its iPhone 15 Pro Max to film the entire \"Scary Fast\" event in October, which unveiled new Macs with M3 silicon, demonstrating its professional video recording capability.",
      "Apple's Pro Workflows Group encourages the professional use of Apple devices and showcased the quality by filming an action short using specialized apps and techniques.",
      "The \"Shot on iPhone\" campaign aims to inspire creativity and shows that the decision to utilize these tools aligns with an individual's intentions and needs."
    ],
    "commentSummary": [
      "Apple utilized its iPhone 15 Pro Max to film the entire \"Scary Fast\" event in October, demonstrating the phone's professional-level camera capabilities. The event introduced new Macs with M3 silicon.",
      "In addition to shooting the event, Apple also recorded an action short using various tools like the Blackmagic Camera App and special shutter techniques to achieve high-quality results.",
      "The \"Shot on iPhone\" campaign, backed by the Apple Pro Workflows Group, aims to inspire users to leverage their iPhones for creative endeavors, highlighting that the choice to use such tools is dependent on a person's creative intentions and requirements."
    ],
    "points": 263,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1699391338
  },
  {
    "id": 38176113,
    "title": "GodotCon 2023: Deep Dive into Future of Rendering, Indie Game Development and more",
    "originLink": "https://media.ccc.de/c/godotcon2023",
    "originBody": "NewsRSS, last 100Podcast feed of the last two years SD quality Podcast audio feed of the last yearPodcast archive feed, everything older than two years SD quality Podcast feeds for godotcon2023 mp4 SD quality webm SD quality opusmp3NewsRSS, last 100Podcast feed of the last two years SD quality Podcast audio feed of the last yearPodcast archive feed, everything older than two years SD quality Podcast feeds for godotcon2023 mp4 SD quality webm SD quality opusmp3browse godotcon2023 GodotCon 2023 Full playlist: Video / Audio name duration date view count 54 min Paying my Debt to Society: SwiftGodot Fixing the Multi-million dollar mistake Talks godot 54 min 2023-11-04 3063 Miguel de Icaza 53 min The Future of Rendering in Godot Keynote godot 53 min 2023-11-04 1024 Clay John 25 min From watercolors to mechs: Stylized rendering and asset pipelines in Godot Talks godot 25 min 2023-11-05 862 Panagiotis Tsiapkolis 49 min GDScript: Past, Present, and Future Keynote godot 49 min 2023-11-05 643 George Marques 28 min Running an indie game dev studio based on Godot: the good, the bad and the ugly Talks godot 28 min 2023-11-04 625 Senad Hrnjadovic 25 min Godot GIS - We Ain't Playin' Talks godot 25 min 2023-11-04 353 Paul Schrum 24 min Viewports: An Overview Talks godot 24 min 2023-11-05 302 Raffaele Picca 54 min The Making of Abandoned Spaceship Demo Scene Talks godot 54 min 2023-11-04 283 Jaanus Jaggo 48 min Fireside Chat godot 48 min 2023-11-05 276 Emilio Coppola, Rémi Verschelde and Krystof Klestil 55 min How a C/C++ noob ported DOOM to run in Godot using GDExtension Talks godot 55 min 2023-11-04 267 Adam Scott 51 min Looking good! Achieving the best graphical quality in Godot Sponsor godot 51 min 2023-11-05 225 Fernando Spina and Lisandro \"NoidEXE\" Lorea 47 min Next-Gen Multiplayer Game Development with The Mirror Sponsor godot 47 min 2023-11-05 164 Jared McCluskey and Wojtek Pe 24 min (Simplified) Flight Simulation Library Talks godot 24 min 2023-11-05 157 Fernando \"Vela\" Cosentino 6 min Opening Remarks godot 6 min 2023-11-04 151 Johannes Ebner and Emilio Coppola 25 min Super-charging content production with Godot addons Talks godot 25 min 2023-11-05 144 Miguel Gonzalez Sanchez 26 min The journey to Godot 4: what can you expect? Talks godot 26 min 2023-11-04 136 Miskatonic Studio 22 min Powering your Godot Game with Steam Talks godot 22 min 2023-11-04 131 GP Garcia 25 min Bending wires: Deconstruction of Robot Detour's main mechanic Talks godot 25 min 2023-11-05 125 Ivan Bushmin 25 min Building Automotive HMI with Godot & RenderCore Sponsor godot 25 min 2023-11-05 119 Harsha Padmanabha 51 min In-house editor plugins and tooling Talks godot 51 min 2023-11-04 115 Sander Vanhove 51 min How to publish your game on Xbox Sponsor godot 51 min 2023-11-04 93 Neil Holmes 21 min Volumetric Video in Godot: The Making of Strange Light, an Extended-Reality Experience Talks godot 21 min 2023-11-05 90 JLS Gangwisch 59 min Lightning Talks Sunday godot 59 min 2023-11-05 79 41 min About Ramatak Sponsor godot 41 min 2023-11-04 69 HP van Braam 40 min Lightning Talks Saturday godot 40 min 2023-11-04 68 7 min Closing Remarks godot 7 min 2023-11-05 58 by Chaos Computer Club e.V –– About –– Apps –– Imprint –– Privacy –– c3voc",
    "commentLink": "https://news.ycombinator.com/item?id=38176113",
    "commentBody": "Videos of Godotcon 2023Hacker NewspastloginVideos of Godotcon 2023 (ccc.de) 242 points by mdtrooper 21 hours ago| hidepastfavorite43 comments Kelteseth 19 hours agoI gave a lightning talk about Godot as a wallpaper engine replacement via ScreenPlay[1]. I hacked this together the week before the convention and I hope to release it by the end of the month.[1] https:&#x2F;&#x2F;screen-play.app&#x2F; reply addandsubtract 18 hours agoparentI want to love an app like this, but the burning question for me is, how CPU intensive is it to run? Is it comparable to running a video in QuickTime or more like keeping a website open? reply Kelteseth 17 hours agorootparentGood question! There are several ways I want to combat this:- Query all windows and check if a full screen or maximized window exist, and then pause the wallpaper. I have a prototype for handling this on Windows.- Limit frame rate via Godots Engine.max_fps. Also in general it does 100% depend on the wallpaper of resource intensive it will be. reply sorenjan 14 hours agorootparentI haven&#x27;t done any Windows GUI programming in a long time, but can&#x27;t you use GetDesktopWindow and IsWindowVisible instead of querying all other Windows? Apologies if this is obvious and doesn&#x27;t work. reply Kelteseth 13 hours agorootparentI haven&#x27;t tried this method, thanks I will check it out! reply abdusco 12 hours agoparentprevLooks really cool. Is there a way to download this for MacOS without having to go through Steam? reply Vespasian 19 hours agoprevI&#x27;m absolutely thrilled using Godot and Bevy for hobby projects.And with Blender you have a competitve 3D modelling solution.Good times for open source gamedev right now. reply baq 18 hours agoparentAnd midjourney&#x2F;dalle can generate passable dev art for textures, sprites and mostly anything 2d.And proton makes you not really have to worry about cross compiling if you don&#x27;t want to.&#x27;Good times&#x27; is underselling it. reply Hortinstein 16 hours agorootparentDo you have any good resources on how to make consistent characters or art styles? I have been meaning to dig into it for a while. I&#x27;m sure it&#x27;s a combination of prompts and image2image training....been thinking about building a workflow tool for this for a while but haven&#x27;t had time to dedicate to it.Even my naive prompts are getting impressive results with midjourney and dalle3...I imagine waiting a few months to a year this problem will be solved in a much better fashion than I would be able to hack together reply nylonstrung 15 hours agorootparentFor that kind of consistency you&#x27;d create LoRAs reply Vespasian 17 hours agorootparentprevGenAI for art is indeed godsend for this humble software developer without any skills in that field. reply capableweb 17 hours agoparentprev> Godot and BevyI&#x27;m guessing you&#x27;re using these separately right? Not together? reply Vespasian 17 hours agorootparentYes. I&#x27;m rapidly switching between Techs in my free time.A nice contrast to regular work ;) reply rcfox 16 hours agorootparentThe great thing about working with Bevy is it forces you to finish a project within a few months before the APIs all change again.(I kid! It&#x27;s great that Bevy is developing so quickly.) reply capableweb 16 hours agorootparentprevHeh, yeah, my work is the opposite, so I&#x27;ve been sticking with Bevy for quite some time at this point. Tried Godot, but I really enjoyed ECS so hard to change now... reply nylonstrung 15 hours agorootparentYou can use ECS in Godot with the use flecs.dev ECS library if you compile as Gdextension, or use Bevy ECS with the rust bindings replyaplummer 20 hours agoprevReally interesting talk at the top of the list, https:&#x2F;&#x2F;media.ccc.de&#x2F;v&#x2F;godotcon2023-57866-swift-godot-fixing...… of all the strange places to find a good summary of nice swift features. reply dfc 20 hours agoparentIt&#x27;s Miguel from Ximian! reply valyagolev 19 hours agorootparentthe man has a whole career out of pushing corporate-controlled languages into wider and more open use reply horplomplope 17 hours agorootparentThank you for pointing this out. It&#x27;s not a problem for a lot of people but the fundamental ethics driven FOSS user should at least be made aware that he sided with Microsoft during the worst Linux is cancer era of MS PR. reply nomel 17 hours agorootparentWhat year was this? reply horplomplope 17 hours agorootparentCancer quote is Balmer in 2001. That same year Miguel started Mono. But he did other things that held back the FOSS movement like support Microsoft for OOXML.\"Advocacy of Microsoft open technologies editDe Icaza endorsed Microsoft&#x27;s Office Open XML (OOXML) document standard,[15][16][17] disagreeing with a lot of the widespread criticism in the open source and free-software community.He also developed Mono – a free and open-source alternative to Microsoft&#x27;s .NET Framework – for GNOME.[18] This has raised much disagreement due to the patents that Microsoft holds on the .NET Framework.De Icaza was criticized by Richard Stallman on the Software Freedom Day 2009, who labeled him as \"Traitor to the Free Software Community\".[19] Icaza responded on his blog to Stallman with the remark that he believes in a \"world of possibility\" and that he is open for discussions on ways to improve the pool of open source and free software.[20]\"Complicated man. I wouldn&#x27;t want his legacy. reply rcarmo 19 hours agorootparentprevYep. He&#x27;s been hacking away at this for a while - it&#x27;s been fun to keep tabs. reply mrtksn 19 hours agoprevI wonder if Godot can be analogous to Blender in the sense of their impact on the respective industries. I got my feet wet in the 3D design world and my impression is that Blender already won and the established commercial products began adopting Blender conventions and ideas to stay relevant. I&#x27;m not professional in any means and I&#x27;m sure there&#x27;s much more than I&#x27;ve been exposed to but the power of Blender was mind boggling, is there a chance of Godot becoming the game engine? reply Thaxll 18 hours agoparentNot sure it will, maybe, but with Unreal and Unity, Godot is still far behind in 3d. As where with Blender there is no other alternative.Godot is like years behind modern engine for 3d. And there is not a single chance it can keep up with Unreal which is used by everyone.It can be an industry standard for indie &#x2F; mobile game. reply jtolmar 15 hours agorootparentI think Godot catching up to Unity is pretty likely within the next 2-3 years. Unity is a mess of tech debt, mismanaged, and has just burned all their good will. Godot should be able to improve much faster due to the lack of tech debt, and a lot of indie devs are motivated to help.I agree that catching up to Unreal is not going to happen any time soon; they&#x27;re way further ahead on rendering features, and constantly improving. reply pjmlp 13 hours agorootparentDepends how well they manage to provide the same .NET development experience for game consoles, including AOT toolchains, debugging and profilers. reply Arcanum-XIII 18 hours agoparentprevFor Blender it’s more the other direction: they’re moving to the way of working of other tool. Before this change (2.8 ?), it was a pain for someone used to navigate any of the big player to drop into Blender.The fact that Autodesk has since bought nearly every big package (notable exception: SideFX Houdini, Maxon Cinema4D and the Foundry Modo) helped a lot. They’re not exactly well loved, be it in special effects, architecture or CAD (though for CAD they’re all bad at the end of the day)I like that Blender is a credible option. I would have loved to have this kind of option when I was younger - way simpler than finding Maya, 3Ds or other big package… with, erhmm, free licence let’s say. reply mrtksn 18 hours agorootparentOh yes, I was first exposed to version 3.0 and all the tutorials that were a bit old were hard to follow and even the infamous Doughnut tutorial was re-filmed for the new UI but I also recall about some commercial pro software taking the Blender route as its popularity among the certain creatives exploded. reply prox 18 hours agoparentprevIt’s certainly possible, I am an early adapter of Godot. It’s one of the talks we used to have on the social platforms back then. They certainly seem to manage things in the same style.In time Godot could be quite formidable, and I argue in many ways 4.x already is. One thing is that rapid prototyping in Godot is actually fun reply nologic01 19 hours agoprevThe GIS in Godot vision talk a bit unlucky, but amazing food for thought nevertheless. The combinatorial repurposing of open source platforms, apps, libraries etc for use cases beyond what they designed for is one of the most fascinating possibilities opening up with FOSS. It is helped alot if people adopt open standards for data exchange. reply cyberax 20 hours agoprevAt least we didn&#x27;t have to wait too long for them! reply Finnucane 20 hours agoparentExpected to see videos of a couple of guys sitting on a bench. reply stuckinhell 20 hours agoprevI really want Godot to succeed. Good luck all! reply IX-103 17 hours agoparentIt&#x27;s still for a ways to go though. Much of the documentation I&#x27;ve read (2D physics) is incorrect or outdated. It also kind of assumes you already know everything, which is somewhat annoying.Still, it&#x27;s making good progress. reply wpietri 17 hours agoprevFor those like me familiar only with the play, \"Godot is a cross-platform, free and open-source game engine released under the permissive MIT license. It was initially developed by Argentine software developers Juan Linietsky and Ariel Manzur for several companies in Latin America prior to its public release in 2014.\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Godot_(game_engine) reply Karsteski 18 hours agoprevHurray I love getting Godot news. Lots of conference content for me to listen to over the next few days :) reply metalliqaz 20 hours agoprevAny comments about how the team is going to spend the Unity-incident windfall? reply fhd2 19 hours agoparentNot sure they need to do much in terms of marketing at least. When I started using Godot in earnest last year, only a few nerds seemed to know it. In the past few months I haven&#x27;t come across a single indie developer not aware of it. reply 10xDev 19 hours agoprev [–] Gave a look into Godot, find out the engine is deeply integrated with some custom scripting language that leads to performance issues [0] (Unreal learnt from this and got rid UnrealScript), support object-oriented design over ECS [1] and are still trying to support OpenGL when the rest of the industry is dropping it in favour of focusing on modern APIs like Vulkan [2] but progress is at least being made with Godot 4.[0] https:&#x2F;&#x2F;sampruden.github.io&#x2F;posts&#x2F;godot-is-not-the-new-unity...[1] https:&#x2F;&#x2F;godotengine.org&#x2F;article&#x2F;why-isnt-godot-ecs-based-gam...[2] https:&#x2F;&#x2F;forum.unity.com&#x2F;threads&#x2F;opengl-deprecation-and-remov... reply matsemann 18 hours agoparentA great reply to your [0] is this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37598985 reply szappetx 18 hours agoparentprevOpenGL support is currently necessary for targeting web and certain other platforms. The industry might be trending away from it, but it is still very much used. reply imtringued 17 hours agoparentprev [–] >Gave a look into Godot, find out the engine is deeply integrated with some custom scripting language that leads to performance issues>Godot API is designed around GDScript: This is also not true. In fact, until Godot 4.1, typed GDScript did calls via \"ptrcall\" syntax, and the argument encoding was a bottleneck. As a result, we created a special path for GDScript to call more efficiently. [0][0] https:&#x2F;&#x2F;gist.github.com&#x2F;reduz&#x2F;cb05fe96079e46785f08a79ec3b0ef...I don&#x27;t have to write anything new, since you didn&#x27;t bother to write anything new either. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text provides an extensive catalogue of discussions and podcast feeds from the GodotCon 2023, focusing on future rendering in Godot, running an independent game development studio, and technical aspects of game development in Godot.",
      "Recordings from the conference are available in various formats like mp4 and webm, catering to a wide array of preferences.",
      "Highlighted talks include 'From watercolors to mechs: Stylized rendering and asset pipelines in Godot' and 'Super-charging content production with Godot addons', showcasing the diversity of topics discussed."
    ],
    "commentSummary": [
      "The text provides a comprehensive overview of podcast feeds and talks from GodotCon 2023, a convention dedicated to the Godot game engine.",
      "Topics discussed range from the prospective developments in Godot's rendering, to the dynamics of operating an independent game development studio, and technical discussions on game development within Godot.",
      "Various recorded discussions including 'From watercolors to mechs: Stylized rendering and asset pipelines in Godot' and 'Super-charging content production with Godot addons' are accessible in formats such as mp4 and webm."
    ],
    "points": 242,
    "commentCount": 43,
    "retryCount": 0,
    "time": 1699360951
  },
  {
    "id": 38176592,
    "title": "Maine 2023 Election Ballot to Include Proposal for Full Print of Original State Constitution",
    "originLink": "https://www.mitsc.org/news/maine-2023-election-ballot-question-6-fact-sheet",
    "originBody": "AboutLIBRARYRESOURCESContact September 15, 2023 Maine 2023 Election Ballot Question #6 Fact Sheet Do you favor amending the Constitution of Maine to require that all of the provisions of the Constitution be included in the official printed copies of the Constitution prepared by the Secretary of State? A “yes” vote on Question 6 would restore certain original sections of the Maine Constitution to printed copies. Although these sections have always been part of the Maine Constitution as originally adopted in 1820, an amendment in 1876 prevented those sections from being printed in copies of the Constitution. Part of the redacted material pertained to Maine’s treaty obligations to Wabanaki people. Why are we voting on this? In 1820 when Maine separated from the Commonwealth of Massachusetts and became a state, its new Constitution included Article X, Section 5 that said, in part: The new State shall, as soon as the necessary arrangements can be made for that purpose, assume and perform all the duties and obligations of this Commonwealth, towards the Indians within said District of Maine, whether the same arise from treaties, or otherwise . . . This is the only section of Maine’s Constitution that mentions the “duties and obligations” Maine inherited as regards the Wabanaki people within its borders. In 1876, the Constitution was amended to remove that language from printed copies. Maine’s current Constitution reads, in part:  Sections 1, 2 and 5, of Article X of the Constitution, shall hereafter be omitted in any printed copies thereof prefixed to the laws of the State; but this shall not impair the validity of acts under those sections; and said section 5 shall remain in full force, as part of the Constitution, according to the stipulations of said section, with the same effect as if contained in said printed copies. A “yes” vote on Question 6 would cancel the 1876 amendment and restore the language of original Sections 1, 2, and 5 of Article X to printed copies of the Constitution. What is the history behind Question 6? For Maine to become a state, Massachusetts first had to pass legislation called the Articles of Separation. That legislation divided and allocated public property and certain obligations as between Maine and Massachusetts once they became separate states. As part of that division, Maine assumed all the “duties and obligations” Massachusetts had as regards the “Indians within said District of Maine.” The Articles also required that its terms and conditions “be incorporated into, and become and be a part of any Constitution, provisional or other, under which the Government of the said proposed State, shall, at any time hereafter, be administered; subject however, to be modified, or annulled by the agreement of the Legislature of both the said States; but by no other power or body whatsoever.\" The Articles of Separation were included in the Maine Constitution as Section 5 of Article X. This was one of the Sections redacted from printed copies in 1876. Sections 1 and 2 of Article X were also redacted in 1876. They covered when the first Maine legislature would meet, when initial elections would be held, how Senate and House seats would be allocated as between the counties and towns, and what the initial terms of Maine’s elected and appointed officers would be. These Sections would also be restored to printed copies of the Constitution if Question 6 passes. What would be the legal effect of a “yes” vote on Question 6? The only legal effect would be that printed copies of the Maine Constitution would henceforth contain the language redacted in 1876, including the full Articles of Separation. Passage of Question 6 would not change the “duties and obligations” Maine has always had as regards the Wabanaki Nations. Those “duties and obligations”, despite the redaction, remained “in full force, as part of the Constitution . . . as if contained in said printed copies.” Although there would be no substantive legal changes, passage of Question 6 would give citizens of Maine easy access to the original language in our Constitution. How will Question 6 appear on your ballot? QUESTION 6: RESOLUTION, Proposing an Amendment to the Constitution of Maine to Require All Provisions in the Constitution to Be Included in the Official Printing. Do you favor amending the Constitution of Maine to require that all of the provisions of the Constitution be included in the official printed copies of the Constitution prepared by the Secretary of State? Read the MITSC Report on Article XREAD MORE HERE ← View All MITSC News P.O. Box 35 Whiting, ME 04691 (207) 271-7762 AboutLIBRARYRESOURCESCONTACT The Maine Indian Tribal-State Commission (MITSC) is an inter-governmental entity created by the Maine Implementing Act of 1980. Six members are appointed by the State, two by the Houlton Band of Maliseet Indians, two by the Passamaquoddy Tribe, and two by the Penobscot Indian Nation. The thirteenth, who is the chairperson, is selected by the other twelve. Read More about MITSC Here",
    "commentLink": "https://news.ycombinator.com/item?id=38176592",
    "commentBody": "Maine&#x27;s constitution has unprintable sectionsHacker NewspastloginMaine&#x27;s constitution has unprintable sections (mitsc.org) 228 points by dsr_ 20 hours ago| hidepastfavorite223 comments rayiner 17 hours agoI hate how this article is written. The article makes it seem like the redaction in 1876 was done for purposes of hiding the treaty obligations to Indians. But it never proves that implication. Instead, it admits halfway through that the entire text of the provisions inherited from the Articles of Separation were also redacted:> Sections 1 and 2 of Article X were also redacted in 1876. They covered when the first Maine legislature would meet, when initial elections would be held, how Senate and House seats would be allocated as between the counties and towns, and what the initial terms of Maine’s elected and appointed officers would be.In reality it seems like the redaction was done to eliminate from the printed copies provisions specific to the implementation of Maine’s separation from Massachusetts. reply _moof 16 hours agoparent> In reality it seems like the redaction was done to eliminate from the printed copies provisions specific to the implementation of Maine’s separation from Massachusetts.Sounds like a great way to sell \"hey let&#x27;s not talk about that whole Wabanaki thing\" without having to come right out and say \"hey let&#x27;s not talk about that whole Wabanaki thing.\" A political tactic as old as the hills: package your unpalatable agenda in something that sounds totally reasonable on its face. I&#x27;m not saying that&#x27;s definitely what happened here, but I am saying that just because they also stopped printing other sections and billed it as something benign doesn&#x27;t necessarily mean that was the actual motivation. reply rayiner 15 hours agorootparentAmong other things, you’re projecting modern sensitivities onto people in 1876. At the time, I doubt anyone was talking about it in 1876 or the public would have cared if the relevant text was more visible. reply zen928 13 hours agorootparentAny reason why your doubts have any higher validity than their suppositions? If you want to shut down their viewpoint, you could augment your statement with examples backing the level of confidence you seem to display about your stance despite it being a assertion based entirely on your personal feelings.I doubt you can make a claim on the self imagined apathetic response of a faceless group of people 150 years ago. You \"doubting\" isn&#x27;t any more valid. I don&#x27;t see it as unreasonable that institutional discrimination existed in 1876. reply s1artibartfast 12 hours agorootparentI think that the burden lies with those making a positive claim of intent.As far as the facts: 1) The legislature and courts in Maine were ignoring the treaty obligations long before this change.2) There is no evidence that this made it easier to ignore treaty obligations3) The change had no bearing on actual application of the law with respect to treaties4) The vast majority of the content marked for redaction is procedural, describing the how the state of Maine would be formed. When elections happen, who gets the guns, and who has the treaty obligations.5) Treaty obligations are not typical contents of constitutions, nor do they need to be to be binding.I dont think that you need to deny the existence of institutional discrimination to make this case reply eesmith 11 hours agorootparent> 1) The legislature and courts in Maine were ignoring the treaty obligations long before this changeThe change took place one month before the courts decided against the Passamaquoddy Tribe in a land ownership case. The state would have been under treaty obligation to compensate them for losing the case - except that you are right, and Maine never really felt obliged to uphold those treaties.Instead, the courts found that the Passamaquoddy Tribe has to pay compensation for Granger’s costs and damages (he won his land claim).> 2) There is no evidence that this made it easier to ignore treaty obligationsCorrect. There is no direct evidence, only inferences based on the people involved and how it benefited Maine over the Passamaquoddy Tribe.In any case, those treaty obligations are still valid now, so continued redaction would suggest that relationships between the state and tribes still isn&#x27;t that important or worthwhile.> 5) Treaty obligations are not typical contents of constitutions, nor do they need to be to be binding.That point seems irrelevant. Maine&#x27;s obligations do exist, and they are binding, due to the Articles of Separation that were incorporated into Maine’s constitution.\"As part of that division, Maine assumed all the “duties and obligations” Massachusetts had as regards the “Indians within said District of Maine.” The Articles also required that its terms and conditions “be incorporated into, and become and be a part of any Constitution, provisional or other, under which the Government of the said proposed State, shall, at any time hereafter, be administered; subject however, to be modified, or annulled by the agreement of the Legislature of both the said States; but by no other power or body whatsoever.\" The Articles of Separation were included in the Maine Constitution as Section 5 of Article X. This was one of the Sections redacted from printed copies in 1876.\" - https:&#x2F;&#x2F;www.mitsc.org&#x2F;library&#x2F;research-report-on-the-1876-re... reply s1artibartfast 9 hours agorootparentRe 1) this point is diminished by the fact that Maine had been ruling against tribes for since formation. The Passamaquoddy case represented more of the same, not a change.Re 2) see 1Re 5) I agree, but You missed my point. My point was that you don&#x27;t need an alternative motive explanation for reacting them. They were binding either way, and this type of content normally isn&#x27;t in constitutions, so redaction as simplification seems entirely plausible. They didn&#x27;t need the parts about voting days and how Maine and mass will split militia guns either. reply eesmith 3 hours agorootparentSo what is your hypothesis for why the text was redacted?1) negligence? (\"Oh, we didn&#x27;t see the text was there\")2) the belief it was historical cruft of no importance (so why say it was still in effect?)3) the belief it was a minor thorn that could be swept under the rug, but of no current impact4) the belief it was a thorn with near-term impact on a pending case - and a case the redactionists likely knew about.5) something else?You seem to be saying that #2 is the most likely, so #4 should be dismissed.My point was the relationship between the Passamaquoddy and Maine have changed since the 1800s - and certainly improved since the Carter era. Why continue with the redaction given that points 1-4 would seem to put a chill on that relationship? replyeesmith 11 hours agorootparentprevThere was an ongoing trial, \"Joseph Granger v. Peter Avery in 1874, a case related to the Passamaquoddy Tribe’s 1794 Treaty with Massachusetts. The case began over a dispute whether the Tribe or Calais lawyer Joseph Granger owned Grass Island in the St. Croix River.\" - https:&#x2F;&#x2F;www.mainememory.net&#x2F;sitebuilder&#x2F;site&#x2F;3283&#x2F;page&#x2F;5208&#x2F;...Granger has been trying to get the courts to recognize his claim since 1855. https:&#x2F;&#x2F;legislature.maine.gov&#x2F;backend&#x2F;app&#x2F;services&#x2F;getDocume...Several of the people involved in the redaction were in a position to know about the lawsuit (see \"Mocikuwin mawi (Passamaquoddy for: Old Boys Club Decisions)\" at https:&#x2F;&#x2F;www.mainememory.net&#x2F;sitebuilder&#x2F;site&#x2F;3283&#x2F;page&#x2F;5208&#x2F;... )As https:&#x2F;&#x2F;mainemorningstar.com&#x2F;2023&#x2F;10&#x2F;09&#x2F;a-matter-of-not-hidi... says, \"The reason officials had for redacting sections of the Constitution are still being debated due to sparse historical evidence\", but there are enough connections that surely people were talking about it then. reply rayiner 8 hours agorootparentHow common were these Indian cases in the 50 years before the redaction? Is there any reason to believe it’s not a coincidence? Especially since the redaction, by its own terms, has no legal effect on any obligations to the tribe. reply eesmith 5 hours agorootparentYou will need to do that research yourself. My comment was to highlight how &#x27;At the time, I doubt anyone was talking about it&#x27; is likely incorrect. replypard68 19 hours agoprevInteresting strategy. Can&#x27;t amend a legal document? Just make the portions you dislike illegal to print! reply CoastalCoder 19 hours agoparentAnd require readers to agree to arbitration if they feel that part of the constitution isn&#x27;t being obeyed. reply NewJazz 17 hours agorootparentI think most constitutions do this? They pick&#x2F;invent the court. reply rsynnott 17 hours agoprev> What is the history behind Question 6?I feel like this section doesn&#x27;t really _answer_ that. Like, it has the _what_, but not the _why_.Very odd. I was expecting it to either be some sort of particularly arcane issue with actually printing (maybe characters not representable in Unicode?), or, at an outside chance, obscene material.Vaguely reminded of Charlie Stross&#x27;s Laundry Files, where Section 3 of the Official Secrets Act is itself secret, because it self-classifies under Section 2. reply returningfory2 17 hours agoparentAgreed, though I&#x27;m guessing the \"why\" is that those parts of the constitution are not considered relevant anymore. It&#x27;s like the part of article 1 section 2 of the Federal Constitution that describes the initial apportionment of seats in the House [1]. It makes sense it was put in there, but nowadays it&#x27;s irrelevant.[1] \"until such enumeration shall be made...\" https:&#x2F;&#x2F;www.archives.gov&#x2F;founding-docs&#x2F;constitution-transcri... reply ooterness 19 hours agoprevHow long is the section in question? Are we talking about 2-3 paragraphs or 100 pages of text? reply anony123 19 hours agoparentAbout 2-3 pages.You can find the text at https:&#x2F;&#x2F;www.legislature.maine.gov&#x2F;lawlibrary&#x2F;sections-of-the... reply jaywalk 18 hours agorootparentIf I print that page, should I stay out of Maine unless&#x2F;until this amendment passes? reply mrcwinn 18 hours agoprevOf note: another ballot question would restore Maine&#x27;s constitution to using spaces. reply karaterobot 17 hours agoparentNext year: \"If approved, this amendment would mandate the use of Unix-style slashes (hereafter &#x27;forward slashes&#x27;, or &#x27;&#x2F;&#x27;) in place of whack ass Windows-style backslashes.\" reply smegsicle 16 hours agorootparentor a restrained middleground of ¥ reply xcdzvyn 16 hours agorootparentHahahaha reply h2odragon 16 hours agorootparentprevget my vote reply CDRdude 17 hours agoparentprevWhich ballot question is that? I haven’t found it in a quick search, and I’m intrigued. reply thatcherc 17 hours agorootparentAlso curious. I don&#x27;t see anything like that listed on the Ballotpedia page [0].[0] - https:&#x2F;&#x2F;ballotpedia.org&#x2F;Maine_2023_ballot_measures reply realo 16 hours agorootparentprevMaybe an amendment was voted earlier making it illegal to print that ballot? reply Filligree 18 hours agoparentprevSpaces? As opposed to? reply jaywalk 18 hours agorootparentTabs. reply djbusby 18 hours agorootparentprevVarious Unicode chars, that are like space - theres a bunch. reply jxramos 17 hours agorootparentwhat&#x27;s going on there? Why would someone do that? Accidental copy paste from some weird encoding or deliberate obscuring? reply Aardwolf 18 hours agoprevSo how is it preserved now? By word of mouth? reply Kranar 18 hours agoparentAs has been pointed out, there are copies of it that contain the unprintable sections.With that said it&#x27;s worth mentioning that many laws, even in the U.S., aren&#x27;t exactly printed or documented per say. Plenty of countries have unwritten constitutions; for example in Canada there is no mention of the Prime Minister in any constitutional document, it exists by legal convention. reply codexb 18 hours agorootparentI think it would be more accurate to state that the Prime Minister&#x27;s power and authority exist at the pleasure of the British Monarchy. Legally, the British Monarch, and by extension, the Governor General of Canada has ultimate authority over the Canadian government.I&#x27;m amazed Canada has retained this system of government for so long. reply someotherperson 18 hours agorootparentThis is the case in almost all Commonwealth countries no?The system works because the country is still relatively healthy. Nobody really cares at the end of the day what leadership style the country has, as long as the leadership ensures that the laws represent the ethics, that there is some concept of justice, and general healthy HDI (whether it&#x27;s safety, work opportunities, housing, education, whatever).Democracy is usually seen as some way to achieve this, but there is also a sharp difference between healthy democracies and democracies that start and end at the ballot. You can equally have dictatorships that are just as healthy, if not healthier, than many democracies (for example the UAE or Oman). reply asvitkine 18 hours agorootparentprevCanada has it&#x27;s own monarchy, legally separate from the British one. Except the monarch is the same person and the rules of succession are the same. But King of Canada is a separate title. reply rootusrootus 18 hours agorootparentprevI thought Canada was legally distinct, and only the person Charles III is shared with the UK? I.e. he&#x27;s the King of Canada. It seems like it&#x27;s primarily tradition at this point which makes this happen, rather than a hard requirement. reply bawolff 17 hours agorootparentprevThis is sort of misleading.First off its the king of canada, which technically is a separate position that just happens to be held by the same person (personal union), with same succession rules, and also a treaty where everyond is supposed to agree before changing succession rules.More importantly it is a constitutional monarchy. The crown can&#x27;t just do what it pleases but is bound by the constitution.A big part of that is the king must listen to the advice of the prime minister&#x2F;the privy council, and that the prime minister must have the confidence of the legeslative branch.In practise the king lacks pretty much all power. There are a couple edge cases (fire the governor general maybe) and still a lot of soft power, but he is essentially a distant figurehead. reply FFP999 16 hours agorootparentExcept that the Governor General actually does have some power and it&#x27;s come up in practice: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;1975_Australian_constitutional.... So the ability to hire and fire the Governor General at will is actually a pretty major power, even if it&#x27;s only been used that one time. reply bawolff 14 hours agorootparentI wouldn&#x27;t say just that one time - well it didn&#x27;t get to the level of the australia one, there have been recent times where governor general has mattered in canada.E.g. https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;2020%E2%80%932021_Rideau_Hal... when it was unclear if payette would resign willingly or have to be fired.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;2008%E2%80%932009_Canadian_p...Still nonetheless i would consider these edge cases that only happen rarely. reply FFP999 12 hours agorootparentI guess whether Canada or Australia want to be constitutional monarchies or not is up to them, and not my business being neither Canadian nor Australian, but it just seems strange to me for them to allow the monarch anything more than symbolic power.Then again, I live in Massachusetts, and historically we&#x27;re...not huge on kings here. reply bawolff 8 hours agorootparentI mean, personally i kind of like it because it helps stop cults of personalities a little bit - when everything is done in the name of the (absent) king, people are less likely to form a cult around the PM who has real power.However i think most canadians just dont really care and it would be a big fuss to remove the king. Anytime anyone tries to change the canadian constitution everyone tries to get their interests in so its easier to just let sleeping dogs lie. See also https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Meech_Lake_Accord replymacspoofing 17 hours agorootparentprev>I&#x27;m amazed Canada has retained this system of government for so long.Why? What current problems would changing this fix? reply boomboomsubban 18 hours agoparentprevNew Hampshire can print whatever copy of Maine&#x27;s constitution that it wants. reply bell-cot 18 hours agoparentprevAbout the same as any government document which contains secret &#x2F; sensitive &#x2F; obsolete &#x2F; too-long sections. There are two separate versions - one is \"anybody can see this\", and the other is \"restricted distribution only\". reply masswerk 17 hours agorootparentThis generally applies to executive documents. I fail to see how the same could apply to a constitution. (E.g., one might imagine a secret section that nullifies the publicly visible constitution in its entirety and substitutes it by a secret one. What would be the base of government and law?) reply bell-cot 17 hours agorootparentWhy can&#x27;t it apply to a constitution? Actual government is in the minds and actions of the people; it is not some \"you are never allowed to skip a step\" mathematical proof that gets printed in a research journal. There are nations with constitutions which are not merely unprinted, but unwritten. And plenty of nations (the U.S. included) which simply ignore clearly-printed parts of their own constitutions, when they find it convenient to do so. reply masswerk 15 hours agorootparentIn positive law, it&#x27;s literally \"nothing exists outside the constitution\". So, if the constitution is an unknown quantity, there is no rule of law. Now, if there is a constitution, but it is not to be known, it may be a positive system or not – either way, you can&#x27;t tell…Also, considering the case of a secret substitution: You&#x27;re appealing to the supreme court, referring to the publicly known constitution, but your case is dismissed based on the notion that your appeal refers to an invalidated section, but you&#x27;re not allowed to know, what the actual, valid section is. This is Kafka at his best. reply AnimalMuppet 18 hours agoparentprevBy printed copies from before 1876. I&#x27;m sure the state government has some copies in archives somewhere. reply rrrrrrrrrrrryan 17 hours agoparentprevHandwritten copies? reply justrealist 18 hours agoprevThe redacted section is on wikipedia fwiw https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Constitution_of_Maine reply DonHopkins 18 hours agoparentDoes it include css to prevent it from printing? reply h2odragon 16 hours agorootparentThat would only be required in state, no? reply moron4hire 20 hours agoprevOne wonders what the motivations were in 1876 to redact this portion of Maine&#x27;s constitution. reply boomboomsubban 19 hours agoparentJudging by the other two sections redacted, it seemed more to get rid of the establishment cruft than any nefarious purpose. The full text of section 5 is rather long and contains a lot of things not really relevant after they were an established state. See https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Constitution_of_Maine#Text_of_... reply eigenket 19 hours agoparentprev> Part of the redacted material pertained to Maine’s treaty obligations to Wabanaki people.The motivation is very obvious - they wanted to conveniently forget their treaty obligations. reply boomboomsubban 19 hours agorootparentIf they wanted to renege on their treaties with Native tribes, they likely would have openly done so. That&#x27;s what was happening in most of the US around 1870. reply enragedcacti 18 hours agorootparentThis is the relevant piece I believe:> The Articles also required that its terms and conditions “be incorporated into, and become and be a part of any Constitution, provisional or other, under which the Government of the said proposed State, shall, at any time hereafter, be administered; subject however, to be modified, or annulled by the agreement of the Legislature of both the said States; but by no other power or body whatsoever.\"They couldn&#x27;t remove the sections because the terms of their statehood had them inherit obligations from Massachusetts that supersede their state constitution. reply boomboomsubban 18 hours agorootparentI don&#x27;t think needing Massachusetts to sign off on your reneging would be a meaningful barrier. reply enragedcacti 17 hours agorootparentAs far as I can tell the historical context around the decision is lost, but I wouldn&#x27;t be surprised if Massachusetts could have been a legitimate barrier to actually eliminating the sections. One piece of historical context we do have is this:> In 1967, Maine’s first Indian affairs commissioner, anthropologist Edward Hinckley, discovered Maine had received $30,000 from Massachusetts in compensation, but the state never actually set aside new land for the tribes.If you&#x27;re Mass. and you created those articles for a reason then I wouldn&#x27;t find it surprising if you didn&#x27;t want to help Maine throw them out after they&#x27;ve already violated your will at least once.All of that is secondary to the fact that they did renege on their promises repeatedly and unabashedly for the next century. Hiding the sections from print could have been an attempt to stop legal challenges before they started, it could have just been out of spite. Who knows, maybe they were very eco-friendly and were worried about all that wasted paper! I find it quite silly to extend such extreme benefit of the doubt to the state government that we already know wanted to escape those treaties and successfully did so before, during, and after passing this amendment. reply boomboomsubban 17 hours agorootparent>If you&#x27;re Mass. and you created those articles for a reason then I wouldn&#x27;t find it surprising if you didn&#x27;t want to help Maine throw them out after they&#x27;ve already violated your will at least once.If you created those articles, you were probably dead by 1870, and definitely dead by 1967. Any generation of lawmakers would have been willing to renegotiate the terms if it benefited them.>find it quite silly to extend such extreme benefit of the doubt to the state government that we already know wanted to escape those treaties and successfully did so before, during, and after passing this amendment.I said that the US at that point cared so little about honoring treaties with Native tribes that I doubted they&#x27;d bother formally amending a constitution to do so. That&#x27;s not giving them the benefit of the doubt. reply enragedcacti 16 hours agorootparent> I said that the US at that point cared so little about honoring treaties with Native tribes that I doubted they&#x27;d bother formally amending a constitution to do so. That&#x27;s not giving them the benefit of the doubt.I see where you are coming from here, but I see actions like this as one of many that contribute to creating the environment where they can pursue the goal of violating the spirit of the law. They probably could have gotten away with much the same without any one anti-native action including this one, but the collective effect is a government system and electorate that endorses and upholds an unjust status quo. replyethbr1 19 hours agorootparentprevIt was nice to see the Supreme Court reverse the quiet abrogation trend 3 years ago: https:&#x2F;&#x2F;www.npr.org&#x2F;2020&#x2F;07&#x2F;09&#x2F;889562040&#x2F;supreme-court-rules...The 5-4 ruling, Gorsuch writing for majority, is a really interesting read: https:&#x2F;&#x2F;www.supremecourt.gov&#x2F;opinions&#x2F;19pdf&#x2F;18-9526_9okb.pdfEssentially, both liberals and conservatives can agree that... if the United States entered into a treaty... and the United States government never explicitly overrode that treaty... then it still stands.Which, fair, but still nice to see recognition even when the question has repercussions for the eastern half of Oklahoma, the state is opposed, and the facts are inconvenient. reply enragedcacti 18 hours agorootparent> Essentially, both liberals and conservatives can agree that... if the United States entered into a treaty...I think it would be more accurate to say that liberals and Gorsuch, who is uncharacteristically liberal on native american issues, can agree. Gorsuch&#x27;s footnotes do a good job imo of making clear that the four conservative dissenting votes have very little respect for the treaties and promises made. reply rsynnott 17 hours agorootparentI mean, I get why, but it&#x27;s very odd that people think of this as a liberal vs conservative issue; it is a rule of law issue. reply enragedcacti 17 hours agorootparentI agree that I&#x27;m playing kind of fast and loose with the terms. I think you could definitely make an argument that Gorsuch argues the position from a small-c conservative \"rule of law\" perspective. In my view the dissent is operating on a very different rule-of-law, one that Gorsuch is happy to dabble in with most other issues:> Conservatism consists of exactly one proposition, to wit: There must be in-groups whom the law protects but does not bind, alongside out-groups whom the law binds but does not protect.It&#x27;s satisfying to raise issues above the partisan or ideological divide, but if the people that call themselves conservative consistently find ways make the law protect their own while restraining others, as four of them try to do here, then its naive to assume that the issues are really transcendent of that. reply rayiner 15 hours agorootparentWhat I find quite interesting is that smart conservatives do a pretty decent job of articulating the liberal position, even if they disagree. But smart liberals have great difficultly articulating the conservative position. reply rsynnott 15 hours agorootparentDo you mean on this specific issue? I don&#x27;t think that&#x27;s surprising at all, because, a decade ago, \"we should abide by treaties\" was pretty much a consensus idea in the US. The \"smart conservative\" (I don&#x27;t particularly buy that there&#x27;s anyone smart left in the US Republican Party, but YMMV) may keep quiet about it now because Dear Leader has contempt for treaties as a concept, but a decade ago they&#x27;d have been publicly pretty horrified by the idea of doing this, and maybe they still are, privately. reply rayiner 10 hours agorootparentConservatives have always chaffed at treaties because they’re generally hostile to the idea of international law, and they’re skeptical of giving the government in the present the power to bind the flexibility of the government in the future. The general rule is that what one Congress does today, a different Congress can undo tomorrow.And of course there are smart people in the Republican Party. Conservatives make up maybe 10% of lawyers, but over the last 40 years have been rolling back a generation of liberal jurisprudence. For example, they have made the case for textualism so strongly that even liberal judges feel the need to fight on that turf. As a result, the arguments made by liberals a generation ago wouldn’t fly with liberal’s of today’s generation. (Credit also goes to Justice Ginsberg, who despite her left of center bent made an entire career advancing a textualist construction of the 14th amendment.) You saw this with Roe, where the left could offer no real argument that Roe has been decided correctly on the merits to begin with, and resorted instead to emphasizing how long ago it was decided. That happened because over 50 years, conservatives completely chipped away the intellectual underpinning that made Roe defensible in the first place. reply enragedcacti 13 hours agorootparentprevI don&#x27;t really see that personally, do you have an example of each? reply adgjlsfhk1 17 hours agorootparentprevwell as Trump&#x27;s repeated attempts to overturn the election show, preserving democracy and the rule of law are somewhat divided along party lines reply throwaway167 19 hours agorootparentprevPerhaps they sought to hide it so those that sought to renege couldn&#x27;t, making it a forever obligation. reply eigenket 17 hours agorootparentGiven that about a month or so after the redaction they renaged on their obligations over Grass Island that seems unlikelyhttps:&#x2F;&#x2F;www.mainememory.net&#x2F;sitebuilder&#x2F;site&#x2F;3283&#x2F;page&#x2F;5208&#x2F;... reply s1artibartfast 18 hours agorootparentprevThis is a cynical take that I don&#x27;t think can be made honestly by anyone who has read the sections reply enragedcacti 18 hours agorootparentIt&#x27;s just a coincidence that Maine has repeatedly reneged on its responsibilities stemming from those sections:> If the constitutional commissioners who proposed the 1875 suppression of Section 5 intended to ensure the state’s obligations were forgotten, they were successful. Rather than protecting the Indians’ trust lands, Maine authorized some tracts to be flooded by dams, others to be annexed for the laying out of highways, and thousands more acres transferred to white owners. In no case was compensation given to the Indians, in violation of treaty obligations. In 1893, Maine courts even ruled that the Passamaquoddy tribe didn’t exist because it lacked sovereign powers.https:&#x2F;&#x2F;www.pressherald.com&#x2F;2015&#x2F;06&#x2F;01&#x2F;legislation-would-put... reply s1artibartfast 17 hours agorootparentYes, it is just a coincidence, in that Maine, as every other State (AFAIK) have reneged on their responsibilities.\"The forgetting\" has nothing to do with the constitutional change. Most people don&#x27;t know or care about the contents of their state constitutions.Redaction wasnt useful legally or generally in the violation of indian treaties. reply eigenket 18 hours agorootparentprevIt is interesting that the redaction happened one month before the final judgement in the Granger v. Avery court case.https:&#x2F;&#x2F;www.mainememory.net&#x2F;sitebuilder&#x2F;site&#x2F;3283&#x2F;page&#x2F;5208&#x2F;... reply s1artibartfast 17 hours agorootparentThe redaction had and has no bearing on the law, because the redacted portion is still fully binding.What exactly is the meat of this conspiracy theory. That The judges were duped with misleading constitutions? That it was some sort of government psyop to influence public sentiment in the long run by distributing misleading documents? reply eigenket 16 hours agorootparentIts not really a conspiracy theory. I think Maine would have ignored its obligations regardless of whether they were written in the documents or not so I don&#x27;t think there is any influence or duping there. Essentially my view is that they were knowingly ignoring their treaty obligations, and so it was convenient for them to remove them from the constitution.This essay is a good summary of the situationhttps:&#x2F;&#x2F;www.academia.edu&#x2F;60751074The whole thing is worth reading, but I&#x27;ll copy and paste a relevant portion here.> It is likewise remarkable that the court did not rule on Granger until after the legislature agreed to the put the redaction before voters and that final judgement did not come until after voters had given the redaction final approval, ensuring that the part of the constitution con-taining Maine’s responsibilities regarding Native treaties was no longer being printed right when Maine became liable for paying the tribe for its lost treaty land and covering the costs of safe-guarding that land. After the redaction officially took effect on January 1, 1876, Maine never compensated the tribe for the fifteen islands it lost due to the ruling. It also charged Granger’s damages to the Passamaquoddy Trust Fund in defiance of the unprintable Article X, Section 5. In 1878 the Committee on Indian Affairs strongly suggested that these actions violated the terms of Article X, Section 5, but the government remained silent. The redaction of Article X, Section 5 all but authorized the existing and ongoing practice of disregarding Maine’s constitutional obligations regarding Wabanaki treaties made with Massachusetts. reply eesmith 18 hours agorootparentprevLooks like you are right: https:&#x2F;&#x2F;www.mainememory.net&#x2F;sitebuilder&#x2F;site&#x2F;3283&#x2F;page&#x2F;5208&#x2F;...There was a 1874 court case where Granger claimed he owned the land by a deed granted the same year Massachusetts signed a treaty with the Passamaquoddy Tribe. The court decided for Granger. Under the treaty obligation, \"it was Maine’s duty to compensate the Passamaquoddy for the value of the lost land, and to pay the Tribe&#x27;s court costs and damages—neither of which happened.\"Maine couldn&#x27;t simply change its constitution as the Articles of Separation requires \"bars Maine from altering the Articles of Separation without the consent of Massachusetts and requires their inclusion in the Maine Constitution.\"To be clear, it appears there is no smoking gun which explicitly says this is the reason, but the people involve knew, or likely knew, about the case when developing the 1876 change.There is a 2022 paper on the topic titled “‘It May Be Questionable’: Granger v. Avery and the Redaction of Article X, Section 5 from the Maine Constitution“ at https:&#x2F;&#x2F;www.academia.edu&#x2F;60751074&#x2F;_It_May_Be_Questionable_Gr... which may have more. reply anovikov 19 hours agoparentprevGiven how 1876 elections went, that time was probably more politically crazy that today, so a lot of things could happen. reply earthboundkid 19 hours agoparentprevTFA makes it pretty clear: to make it less likely for Wabanaki to win court cases. reply OskarS 19 hours agorootparent\"pretty clear\" is an overstatement, I read it and I didn&#x27;t understand it. I&#x27;m not a lawyer, but the article could have included... you know... your exact comment somewhere. reply broken-kebab 19 hours agorootparentprevCould you please quote that part? I can&#x27;t find anything like it there reply s1artibartfast 17 hours agorootparentprevhow would it make it less likely? Is seems like you are making some logical jumps reply rpbiwer2 19 hours agoprevSeeing as how this is Hacker News, I thought this was going to be about how the constitution contains non printable characters or something. reply MiddleEndian 18 hours agoparentI was expecting a saved picture of their constitution that somehow triggered a counterfeit deterrence system on a govt printer. reply 1970-01-01 18 hours agoparentprevI thought the same! Some non-English writing, perhaps native Indian writing or something was stuck in the physical books. Nope, just omitted legal text. reply johnobrien1010 18 hours agorootparentYeah, IMHO title should probably be has unprinted sections, not unprintable sections reply umanwizard 18 hours agorootparentOr rather “not officially printed”. I’m sure some lawyer somewhere has printed them. reply rob74 17 hours agoparentprevThe title is a little misleading: the sections are not \"unprintable\" due to technical reasons, they are just currently not printed because the constitution itself says they shouldn&#x27;t be printed... reply CalRobert 17 hours agoparentprevToss in some ANSII color escape sequences, perhaps! reply tiahura 19 hours agoprevTribal entitlements should be dismantled around the world. reply agent327 18 hours agoparentMy great-grandmother and her sister were the last two women who wore the tribal clothing of the tribe I suppose I belong to. That tribe no longer exists; we are all Dutchmen in the nation of the Netherlands now. Is that bad? I don&#x27;t think so: cultures evolve, humanities&#x27; future seems to be aimed towards larger groups, and trying to stick to a tribal structure that would have largely rejected the progress made in the outside world, had they had the chance, would have been a miserable existence. Instead of doing silly dances for tourists I&#x27;m a software engineer working for a major space agency, and I&#x27;m fine with that. Something unique may have been lost (a language, a clothing style, and a harsh way of life), but so much more has been gained (access to all the world has to offer).The tribal structures that still exist in many parts of the world aren&#x27;t really about preserving culture or identity anymore; to me they seem to be mostly about preserving the power of a handful of tribal elders, and upholding discriminatory practices both inside and outside the tribe. Those structures are a relic that wouldn&#x27;t have survived anyway, European colonists or not, and casting them aside now, and joining the rest of the world in the 21st century is neither shameful nor bad.Just to be clear: I applaud anyone who wishes to celebrate their culture and their identity, and I think having those preserved enriches our world. But staying within the confines of a preserve, where life is hard and opportunities are few, just because you were born there, makes no sense to me. You can be both proud of your heritage and a citizen of the 21st century.So the question, then, is this: are tribal entitlements necessary for the preservation of something worthwhile, or are they merely tools to further disadvantage a group that is already severely lacking in opportunities? If it&#x27;s the first, there is a place for them. If it&#x27;s the second, it&#x27;s time they were dismantled. reply Brian_K_White 18 hours agorootparent\"Something unique may have been lost (a language, a clothing style, and a harsh way of life), but so much more has been gained (access to all the world has to offer).\"I mostly agree with your overall gist, but I will poke a little hole here just for completeness: What does all the world have to offer? A spectrum of other cultures? Today yes, but only because the process of loss and homogenization you just said was a good thing has not yet completed. Give that same process a few more generations and the whole world will be the same, and any differences won&#x27;t matter at all. It&#x27;s already almost like that today. When I go on vacation on the other side of the world, it&#x27;s hardly any different. If it weren&#x27;t for the history and the interesting ancient structures, there would hardly be any point in travelling from any place to any other place.The process is not complete, and so today, sure, there is still a lot of point to travel. But that is merely mass and inertia and it&#x27;s eroding away.Life is getting better in certain material ways, which are undeniably valuable, but it is not getting richer. It WAS getting richer for a while when communication and travel gave more people more access to the wide varied world than was possible before, but now, that wide varied world is becoming less varied, and so the richness is decreasing. reply crazydoggers 17 hours agorootparentWhat place do entitlements play in preserving such diversity, and would other means perhaps play a better role? There are examples that indicate they might cause the opposite to occur, such as with casinos. What are the examples or arguments for how they help? reply Brian_K_White 16 hours agorootparentI made no statements or implications about entitlements. reply clbrmbr 17 hours agorootparentprevCould there be value in cultural diversity analogous to value of biodiversity?I think of Andrian Berry’s warnings about a world state. I fear a world monoculture is one step in that direction. (Just googled him, seems time has been unkind to his books and reputation. Still, his Next 10,000 Years was so inspiring to me, not so much for the specifics but for the vision and the first-principles thinking around how we may get stuck.) reply fluoridation 16 hours agorootparentBiodiversity is important because a diverse population is less likely to get wiped out by an event that kills all individuals matching some criteria. For cultural diversity to have value analogously there would need to be some threat to cultures that is separate from biology (because we&#x27;re still all human). I can&#x27;t imagine what that could be. reply ToValueFunfetti 15 hours agorootparentAs a theoretical example, if the internet eroded attention spans in first-world-liberal-democracy type cultures to a degree that eventually lead to their extinction, the Amish would be immune and our species would survive. reply TimTheTinker 17 hours agorootparentprev> The tribal structures that still exist in many parts of the world aren&#x27;t really about preserving culture or identity anymoreThat&#x27;s not strictly true. There are real tribes in the jungles of South America and southeast Asia, for example, who still live in the forests, cook food they raise, and live in thatch&#x2F;mud&#x2F;bamboo houses.I would argue that these tribes&#x27; rights (especially property ownership of land where they have houses and raise food right now) matters more than arguments about things that happened more than a hundred years ago in developed countries. reply pjc50 18 hours agorootparentprev\"Entitlements .. tool to disadvantage\" feels deep in doublespeak. If it&#x27;s a disadvantage, it&#x27;s not an entitlement. Entitlements are things one can take up or leave voluntarily. reply crazydoggers 17 hours agorootparentAn example is the entitlement of sovereign land use that promotes disadvantage. Many Native American reserves suffer from chronic poverty, alcoholism, drug use, etc. Entitled to land use, the US government holds final title, resulting in an inability for people living on the land to do things like collect taxes, private land development, mortgage of assets, etc.So in this way, the “entitlement” of land use reserved for native Americans actually results in chronic disadvantage.A more complete assessment:https:&#x2F;&#x2F;www.americanbar.org&#x2F;groups&#x2F;crsj&#x2F;publications&#x2F;human_r... reply crazydoggers 18 hours agorootparentprevThis is a thoughtful and insightful comment, and brings up issues I wouldn’t have thought about or understood.Even though the parent comment was terse, this comment shows why we shouldn’t be downvoting &#x2F; flagging opinions into oblivion. Free speech and listening to opposing views can bring about meaningful discussions and help is all understand the world better.Flagging uncomfortable topics because they violate modern wokeism is a disturbingly Orwellian practice. reply ebiester 19 hours agoparentprevSo long as you give them their entire claim to land as a sovereign nation, including water, mineral, and air space rights…And at that point you don’t have much space for the colonial powers left. reply ImJamal 18 hours agorootparentWho are we going to give it to? Tribe A who the colonists took it from? What about the Tribe B that had their taken by the Tribe A? Should they be screwed over? reply maxwell 18 hours agorootparentWithout the European conquest, the Wabanakis may have actually been crushed by the expanding Iroquois Confederacy. Hence they, along with other Algonquin nations, joined the Americans in the Revolution, while many Iroquois sided with the British.The Penobscots, one of the member nations of the Wabanaki Confederacy, have never been displaced from Indian Island (since settling there ~11k years ago), and acquired significant additional land holdings since the 1970s. reply ImJamal 17 hours agorootparent>The Penobscots, one of the member nations of the Wabanaki Confederacy, have never been displaced from Indian Island (since settling there ~11k years ago), and acquired significant additional land holdings since the 1970s.How do you know that? If they took land from another tribe 9k years ago do you think we would have a record of it? What if another tribe took the land from them 8k years ago and 7k years ago they took it back? Do you think we can actually determine if that happened? reply maxwell 17 hours agorootparentUh, what do you think we can \"actually determine\" from before recorded history?https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;9th_millennium_BCI used to live on the next island over (French Island), and your clueless questioning of Penobscot sovereignty is disappointing. Would you also suggest that maybe Natufians should control the Levant? reply ImJamal 16 hours agorootparent>Uh, what do you think we can \"actually determine\" from before recorded history?That is my point. You made a claim but have no evidence to prove it.>I used to live on the next island over (French Island), and your clueless questioning of Penobscot sovereignty is disappointing.I don&#x27;t think you understand what my point even is if you think I am doubting anybody&#x27;s sovereignty.>Would you also suggest that maybe Natufians should control the Levant?I don&#x27;t think being the earliest inhabitants of an area gives permanent ownership. My issue is we are told we need to give back land to the previous owners. It just seems ridiculous that we should do that when many of the tribes we took the land from did the exact same thing we did. reply maxwell 13 hours agorootparent> That is my point. You made a claim but have no evidence to prove it.I&#x27;m not claiming anything, it&#x27;s right there on https:&#x2F;&#x2F;penobscotnation.org. Reach out to Chief Francis or the council if you have questions on their assertions.> I don&#x27;t think you understand what my point even is if you think I am doubting anybody&#x27;s sovereignty.Good to hear, that doesn&#x27;t really seem to be the case among Mainers. Note that the Penobscot River has legally been a citizen of the Penobscot Nation since 2018. The State of Maine has repeatedly disputed their claims and legally challenged their sovereignty, finally losing their battle to control pollution in the river last year: https:&#x2F;&#x2F;www.nrdc.org&#x2F;stories&#x2F;22-year-court-battle-ends-justi...> I don&#x27;t think being the earliest inhabitants of an area gives permanent ownership.Okay, so who should control the Levant then?I understand how one could extrapolate from other geopolitical tensions, but there doesn&#x27;t seem to be much uncertainty in this case regarding Penobscot claims. Yes they lost most of their wider territory through illegal treaties, but they never lost their \"capital\" on Indian Island. I&#x27;m not aware of any other New World peoples who weren&#x27;t displaced from their ancestral headquarters by European settlers and have maintained continuity of government since before Columbus set sail.The Penobscots asserted their claim on over half of the land in Maine in the 1970s, and reached a settlement for over $80M in 1980, which they&#x27;ve used to acquire more territory [1]. The only question has been over sovereignty, specifically in terms of environmental rights, with the State of Maine taking on both the tribe and the feds in their failed battle for control over the river.1. https:&#x2F;&#x2F;generationallandscapesblog.wordpress.com&#x2F;sugar-islan... replys1artibartfast 15 hours agorootparentprevWith rule of law, you would give it to whichever tribe which the government made a binding agreement with, thereby honoring your word and contractual obligations.The scope of government is to uphold the agreements it makes, not unravel the interactions of other parties going back to the dawn of humanity. reply ImJamal 14 hours agorootparentThat could easily violate the rule of law though. Knowingly trading stolen property is often times a crime. If we know the land was stolen by the tribe we are giving it to we aren&#x27;t really following the rule of law. reply s1artibartfast 13 hours agorootparentIn that hypothetical, Why are we changing the mind about if it is stolen or not?We didn&#x27;t consider it stolen when we first made the agreement. reply yawpitch 13 hours agorootparentprevConsidering the \"we\" in this case only have possession of the (allegedly and &#x2F; or only hypothetically stolen) property because \"we\" engaged in genocide, it&#x27;s kind of rich for \"us\" to worry about violating the rule of law. reply zamalek 18 hours agorootparentprevThat is certainly something the tribes should sort out, after getting the land back. reply ImJamal 17 hours agorootparentWhich tribe would get the land back? reply zamalek 16 hours agorootparentThe one last in possession - the point of my comment is that it is not the responsibility of colonialists to decide who the land belongs to. The only certainty is who last had it. reply ImJamal 15 hours agorootparentIf we don&#x27;t have a responsibility to determine who the land belongs just who last owned it then it seems like the colonists should retain it. The last people to control the land are the colonists after all.Let&#x27;s look at this from a normal legal situation. You own an item that was stolen by thief A. Thief B then steals it from thief A. Should your item be returned to you or to thief A? Your logic would indicate thief A. Nobody thinks that would be the right solution and yet when it comes to native lands nobody cares. I just want some consistency. reply s1artibartfast 15 hours agorootparentIf you make a binding contract with thief A, you should honor it.If you recognize them as the rightful owner at the time, make an agreement for exchange, then the burden of consistency is on you. Buyers remorse is not sufficient to unwind your obligations while retaining the property.Another way of resolving this is simply recognizing that conquest does not create obligation, but diplomatic agreement does. It is a matter of integrity and honor, literally, in the sense of do you honor you commitments or are you a liar.While repugnant to some, I think this is quite clear. In the cases where settlers simply took land by force of arms, they created no legal or honorable obligation. Where they took land by legal agreement, they have created an obligation. reply ToValueFunfetti 15 hours agorootparentSo if I am lead to believe that a thief has rightful ownership of an item and rent it from them, I&#x27;m obliged to return it to the thief instead of the rightful owner? reply zamalek 7 hours agorootparent\"What&#x27;s best for the aboriginals\" is a pondering that originates from a colonial mindset. It implies that one&#x27;s opinion about the best course of action is more important, or superior, than those who&#x27;s opinion actually matters. Furthermore, colonialists don&#x27;t exactly have a good track record of making morally sound choices regarding land.Not only is our opinion irrelevant; our opinion has been abundantly demonstrated to be awful in every single way. We need to stop.Giving it to the last inhabitant, yes possibly conquerer, is really the only choice we have (apart from doing nothing and stealing the land) - to put things back the way they were. reply s1artibartfast 14 hours agorootparentprevno, im not saying that.Im saying that if you fully acknowledge someone to be the rightful owner and something, you dont get to change your mind about paying them, and call them a thief with no new information, and then keep it for yourself.IF the US somehow discovered evidence that it bought stolen land, and chose to pay or return it to the original holder, that would be one thing.Simply not paying and keeping something for yourself make YOU the thief and a liar too. reply ToValueFunfetti 13 hours agorootparentI think the fact that we now know the land was stolen was conceded much higher up in this thread (\"That is certainly something the tribes should sort out, after getting the land back.\") Conceding that we know the land was already stolen and arguing that our responsibility is still to give it to the immediately previous thieves and let them figure it out is what I take issue with. If we don&#x27;t know whether it was stolen, that&#x27;s another matter. reply s1artibartfast 13 hours agorootparentFair enough. I lost track of that conceit in the hypothetical. If there is a clear victim, then yes it should go back to them, not the thief.Because individual actors and even nations are discontinuous over the thousands of years we are talking about, we are stuck with treating racial and ethnic lineages as the actors, blurring the lines. The Thief and victim can be the same. Lets say a deceased grandfather (A) was robbed by a now deceased son (B), depriving the living grandchild (C) of their ancestral property. Living Indians, party C, are the decedents of both the thief and victim. It still makes more sense that the stolen goods should go back to them, than stay with recipient of the stolen goods.Anchoring back to reality, I think the whole thief analogy is bogus. At the time treaties were made with Indians, possession by conquest was considered a valid means of acquisition, and Indians were held to be in sufficient standing to enter agreements.Rationales which try to retroactively invalidate the historic land ownership by natives, and thereby invalidate contractual obligations, are logically bankrupt if they dont also attempt to identify a rightful owner to return the property to. reply zamalek 14 hours agorootparentprevThe thing is that some of these treaties are expiring (e.g. one of the tribes in Snohomish county, I forget which) and, per the treaty, the land must be returned to them. This is why these treaties are seen as problematic.Once these treaties expire, assuming they are ignored, the land does become stolen.I don&#x27;t expect the tribes to be unreasonable about the land and take up land-grabs, it will likely just be a matter of taxes going to one entity instead of another. reply s1artibartfast 14 hours agorootparentThat&#x27;s the problem with having rule of law, integrity, and honor. Sometimes it&#x27;s inconvenient and costly.Something being costly does not absolve you of your moral, legal, and honorable obligations. It is not a justification for ex post facto recontracting.I would like to see the government uphold it&#x27;s obligations, stop acting weird exceeds these obligations, I work towards permanent Solutions where advantageous. This may include buying out of contractual obligations for purchasing Indian land and rights replymaxwell 16 hours agorootparentprevIn this case, the nations of the Wabanaki Confederacy. reply ImJamal 14 hours agorootparentWhy? They killed various tribes to obtain at least some of their land. If it was wrong for the colonists then we shouldn&#x27;t reward tribes who did the exact same thing? Taking land from oppressor A just to give it to oppressor B is just dumb. reply lapetitejort 18 hours agorootparentprevSounds like a tribal matter, and not something for colonists to answer. reply ImJamal 17 hours agorootparentIt matters to us since if we are going to give land back we have to know who to give it to. reply yawpitch 13 hours agorootparentprevThis isn&#x27;t the strong question you seem to think it is. Assuming we&#x27;re the colonists who stole from A then our ethical responsibility is to return the stolen property to A. If A in turn had stolen the property from B then it&#x27;s A&#x27;s ethical responsibility to return the stolen property to B. It is ABSOLUTELY not the colonists&#x27; responsibility (or right) to keep screwing over both A and B by waffling over the chain of custody when they&#x27;re the ones whose hands hold the stolen property. reply nemo44x 10 hours agorootparentLand can’t be stolen, only conquered when sovereigns are involved. Whichever sovereign has physical possession (rule and defense) of the land has a stronger claim to it than the other who simply says it’s theirs but are unable to rule it.You aren’t a sovereign if you don’t rule within your claimed borders. reply yawpitch 9 hours agorootparentConquering land is, definitionally, taking possession of a real asset by force from another who had prior possession of that same asset… in other words it’s identical in meaning to theft, hence conquered land is stolen land, unless that land had no prior occupants. QED.This is, of course, notwithstanding the fact that wars of conquest are illegal in our modern system of international law precisely because they represent an act intended to steal another nation’s sovereign territory… you seem to thing such wars become legal if the invaded party doesn’t successfully prevent the invasion from starting at all.Yes, the de facto situation is that successfully prosecuting a genocide means successfully stealing land, as happened in what became the USA, but it doesn’t alter the fact that the land was very definitely (in the case of the USA both de facto and de jure) stolen. reply DrThunder 19 hours agorootparentprevName one other nation in the history of the world that has given any consideration at all to the people who&#x27;s land they took. Indians were stealing land from each other for generations before \"colonialism\" was a thing. It&#x27;s just part of human history. Time to move on, they&#x27;re certainly not getting much societal benefit from government gifted land. It&#x27;s only served to isolate them more and impoverish their communities. Instead of integrating they continue to live in a past that no longer exists. Either they&#x27;re Americans or they&#x27;re not. reply nemo44x 18 hours agorootparentprevWhy would anyone give up land they conquered if they want to live on it? No one has a right to land outside of borders they can&#x27;t defend. If you can&#x27;t defend a border then you aren&#x27;t a sovereign nation. You&#x27;re a group of people that need to work with the sovereign nation to allow you to live on the land they conquered. reply JohnFen 18 hours agorootparent> Why would anyone give up land they conquered if they want to live on it?To avoid being evil? To be the sort of people who keeps promises? reply maxwell 18 hours agorootparentprevWabanakis also fought the British and maintained their freedom.https:&#x2F;&#x2F;www.penobscothistory.com&#x2F;historic-preservation&#x2F;12-tr...The Penobscot Nation, the oldest government in the Western hemisphere, has never been conquered. reply GlassOwAter 18 hours agorootparentprevWhere do you live? I bet I can conquer your house. reply potatolicious 18 hours agorootparentSo many people have this delusion that, in a Mad-Max-ian world they&#x27;d be a badass sitting on the bones of their enemies when in fact they&#x27;d just be dead in a ditch somewhere.There&#x27;s a pretty vocal minority on HN (and in tech generally) that are unapologetic supporters of might-makes-right and wholly against the rule of law. It&#x27;s at least a bit refreshing from the usual set of people who are against the same but too mealy-mouthed to say it outright. reply nemo44x 17 hours agorootparentThe rule of law is might makes right. Who makes the law? Who enforces it? reply maxwell 16 hours agorootparentThe people, in the U.S. We can strike down any federal statute, call a convention, and simply dissolve the federal government and create a new one whenever popularly desired.There&#x27;s no monopoly on arms in this country. Every able-bodied male between 17 and 45 is in the militia and we keep a gun behind every blade of grass. reply nemo44x 17 hours agorootparentprevI’m sure you can’t. The sovereign nation I live under has laws and the ability to enforce them that protect my property. If you tried to take my house then I’d have a tort against you. The nation would find in my favor and imprison you. My home would remain my property. reply jaywalk 18 hours agorootparentprevA house is not a sovereign nation. reply yawpitch 18 hours agorootparentprevThe concept of all three of borders, nations, and sovereignty as you’re using it are relatively recent innovations that haven’t survived for anywhere near as long as, for example, feudalism did as an organizing structure, and just as feudalism died this latest iteration of “my might makes me right” will, eventually, die as well.If it takes the species with it, so be it. reply fluoridation 16 hours agorootparentIt seems to me that might makes right is at least as old as humanity itself. I don&#x27;t see many animals organizing to resolve disputes peacefully. When it comes to relations between groups that do not engage socially with each other, might makes right seems like the default means to come to agreements. reply yawpitch 14 hours agorootparentChild molestation is also at least as old as humanity itself... you have not made a sensible or reasoned argument for continuing to do what we did in the past. reply fluoridation 12 hours agorootparentIt&#x27;s not an argument in favor of continuing to do it. It&#x27;s an argument against the idea that it will stop happening in the future. reply yawpitch 11 hours agorootparentIt will absolutely stop happening in the future… the only question is will it have stopped because we finally outgrew thinking with our genitals, or will it have stopped because we failed to do so? reply fluoridation 10 hours agorootparentYes, it will only stop when there no longer people to do it. We are in agreement in that. reply yawpitch 9 hours agorootparentNo longer people or no longer stupid people. I’m an optimist, just not very much of one. reply nemo44x 10 hours agorootparentprevWe use force to prevent and punish child molestation. Another win for might. reply yawpitch 9 hours agorootparentRealistically we prevent virtually no child molestation by force (or by any other means)… we’re far too busy loudly pretending to care about keeping children safe from imaginary stranger dangers to actually do anything whatsoever to keep them safe from the real dangers represented by their family and other trusted adults.On average it takes two decades for a victim of childhood sexual abuse to disclose their abuse… successful victories of your imaginary “might” at that remove are virtually non existent relative to the number of victims. replyCoastalCoder 19 hours agoparentprevIt&#x27;s hard to discuss that assertion unless you also provide an argument. reply mr_inspector 19 hours agoparentprevinteresting take. Could you elaborate why you think so ? reply jstanley 19 hours agorootparentAssuming a tribal entitlement entitles you to something based on what tribe you&#x27;re born into, it seems pretty obviously discriminatory. reply Uehreka 19 hours agorootparentSome would argue that the colonialism that created the status quo was pretty obviously discriminatory. Removing the last vestige of their sovereignty would be like saying “now that we’ve undemocratically seized your land, changed how it was governed and moved in enough people to vastly outnumber you, come join in our democratic process where you’ll be overruled by our superior numbers!” reply hattmall 19 hours agorootparentThat&#x27;s how conquest, war, and societal progress works. Should we go back and create entitlements for all the European tribes folded into monarchies over the last two millennia?Entitlements are antithetical to equality. Continually attempting to right wrongs from the past simply carries them forward. reply janosdebugs 18 hours agorootparentIn a lot of places in Europe minorities have varying degrees of autonomy, protections and special rights (use of language, schools, sometimes more). History and legal systems are complicated and a lot of it doesn&#x27;t make sense without the historical context. reply _jal 18 hours agorootparentprevIf the tribes had been corporations and the treaties governed under an ISDS scheme, would you find that less objectionable?( https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Investor–state_dispute_settlem... ) reply nemo44x 18 hours agorootparentprev> “now that we’ve undemocratically seized your land, changed how it was governed and moved in enough people to vastly outnumber you, come join in our democratic process where you’ll be overruled by our superior numbers!”That&#x27;s sort of how the world works. If you can&#x27;t defend it (through power and&#x2F;or political will - you have strong friends that you have a mutually beneficial relationship with) then it&#x27;s not your land. There&#x27;s literally no group of people that have lived on some piece of land since the dawn of humanity. In fact there have been untold thousands of groups of people wiped off the earth because another group decided they wanted to live on the land they once lived in.C&#x27;est la vie?! reply cool_dude85 18 hours agorootparent>That&#x27;s sort of how the world works.Is that what you&#x27;d say if a few guys with guns came and pushed you out of your home, so that they can live there? Historically, it&#x27;s correct: that&#x27;s how the world works. reply sillysaurusx 17 hours agorootparentWell, yes. It’s why national defense is important. As well as laws to prevent that from happening within the nation. reply cool_dude85 17 hours agorootparentJust to make sure - it&#x27;s fine to ignore legal treaties, etc., because if \"they\" aren&#x27;t willing to take up arms to defend what&#x27;s theirs, that&#x27;s how the world works. But when I run you out of your house because I&#x27;d prefer to sleep there, then laws and the legal system are a perfectly reasonable avenue to expect to save you?Hey, at least you&#x27;re honest. reply sillysaurusx 16 hours agorootparentHmm? I said the opposite - that the law is all we can rely on. Without the law, we’re left with might makes right, which is precisely how the world works. reply nemo44x 14 hours agorootparentprevCorrect which is why we formed tribes which allowed groups of people to form a common culture and bond which protected each other. And tribes would firm alliances with other tribes and work together to destroy rival tribes. These groups of tribes became nations which have evolved into the political organization of the nation state we see today.Now if a few guys with guns pushed me out of my home my nation state would send more guys with better guns to remove them and my property would be back in my possession. reply cool_dude85 12 hours agorootparentWhat happens when your \"nation\" doesn&#x27;t have a state, or the state youre in isn&#x27;t made up of your \"nation\", or you just have a phony rump state, as in the case here? Those guys get to get pushed around? replybroken-kebab 18 hours agorootparentprevI often see \"discriminatory\" used as if it proves something irrefutably. When I don&#x27;t go to a shop where employees are rude, I certainly do practise discrimination on the basis of communication culture. Also I enjoy my customer&#x27;s rights, and do the right thing by creating incentives for politeness. There are discriminations which are legal, and illegal, moral, and immoral, pragmatic, and useless. And everything in between. reply paxys 18 hours agorootparentprevYou are entitled to a lot of things by virtue of being born in the USA. Is that discriminatory? reply ethbr1 19 hours agorootparentprevLike birthright citizenship? reply jstanley 19 hours agorootparentSure! I&#x27;m on board. Let&#x27;s abolish the concept of citizenship while we&#x27;re at it. reply denton-scratch 17 hours agorootparentCitizenship is a modern institution; yeah, the Athenians had it, if you&#x27;re OK with a notion of citizenship that extended only to a small percentage of the population. But even in ancient Athens, the majority of the population were slaves.In feudal Europe, most people were serfs or vassals; they came with the land, a bit like trees and game. The only people with rights were aristocrats, and then only really if they had land. Poor people might have had some rights in law, but the judge was the local baron; it was meritorious for the sovereign to promulgate \"the King&#x27;s justice\", but it didn&#x27;t happen much.The change came with the Age of Revolutions; rights are something you have to seize. To my fury, I remain not a citizen, but a subject, because the English Revolution was led by landed gentry, not by the populace.The idea of universal rights is a fine idea; but not having been seized, they don&#x27;t exist. reply smaudet 19 hours agorootparentprevSo....you&#x27;re into anarchy?Sorry to say, discriminatory behavior is fairly common in anarchic systems (see, evolution, mating impulses).You need a bit of discrimination in order to not discriminate.Don&#x27;t like it? Rewrite the laws of physics! (maybe fix the whole good and evil thing too while you&#x27;re at it) reply shepherdjerred 18 hours agorootparentThe parent did not mention anarchy. Abolishing the concept of citizenship is not exclusive to having a functioning government. reply smaudet 18 hours agorootparentHow so? A government must have those it governs, those must be then members of the set of people whom it governs.You can call it something besides \"citizenship\", but maybe we&#x27;re talking about different terms, or you have a more technical definition implying more than simply membership under a governing party?Either way, this is the basic definition of a citizen, so trying to divorce the two seems futile to me:\"A citizen is a member of a political community who enjoys the rights and assumes the duties of membership.\"https:&#x2F;&#x2F;plato.stanford.edu&#x2F;entries&#x2F;citizenship&#x2F; reply jsnell 18 hours agorootparentThey govern over non-citizens as well, e.g. over residents and visitors to the geography where the government has&#x2F;claims sovereignty, but the non-citizens tend to get fewer rights than the citizens. reply smaudet 16 hours agorootparentI understand your distinction I think...however the parent comment (about abolishing citizenship) is still (on the face of it) advocating anarchy. Degrees of citizenship must exist always, even when the \"official\" line is that none do - as you state even in the case of \"equal citizenship\" there is still the degree of citizen, and non-citizen, so really you can never remove that (without also removing government).Being in the position of abolishing _birthright_ citizenship is a very different stance than abolishing the practice of citizenship outright. I think you are speaking of \"second class citizenship\" e.g. immigrants or temporary who do in fact benefit from and are expected to follow the laws of the land, but who do not get e.g. voting rights.I.e. perhaps the view is the equalize all practical citizens under the law (which is possible but difficult to do wrt to land ownership and community security, especially). reply shepherdjerred 15 hours agorootparentprevMy interpretation of the parent comment was that citizenship should not be restricted by the circumstances of birth.Countries would still be governed by those who live within their borders, but you wouldn&#x27;t be discriminated against based on your place of birth, e.g., you could move around freely.Or, maybe more practically, greatly ease the requirements of immigrating and becoming a citizen of countries. reply isilofi 18 hours agorootparentprevIt pretty much is. A government does govern two things, a population and a corresponding land area. You may try to have one without the other, but that would lead to massive problems because of the way humans and their home area interact.If you govern a population without a land, you are practically instantly at war with some other population because both populations will want their way of life as well as their property rights enforced around the place they call \"home\". For a current example, see the palestinian exile population, who have a government but no land of their own, thus leading to constant conflict with their host countries.If you govern a land without a population, you are lacking any kind of compass and attachment to values. Land alone is a dead thing, and a government cannot just be recruited from land, it has to be people doing the governing. Basically, there is nothing to govern without a society.Citizenship can have a number of definitions, but the loosest one is something like \"currently inhabiting the land area of that corresponding government\". You may change those definitions, introduce various classes of citizenships, modify the ways in which it can be obtained. But for the aforementioned reasons, any definition that doesn&#x27;t involve something like \"a citizen is strongly associated with a land area and comes from a corresponding populace (governed by a corresponding government)\" is a weak and fragile definition that will not last the test of time and human interactions. Note that the government part is in parentheses, because actually governments are far more interchangeable than population and land area. reply ethbr1 15 hours agorootparenthttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Sovereign_Military_Order_of_... reply smaudet 13 hours agorootparent\"Its two headquarters buildings in Rome enjoy extraterritoriality\".The article claims they have no territory, but what they mean is there is no territory capable of supporting a military + institution. I don&#x27;t know this is a practical counterexample.Nevertheless, it is interesting to note that clubs and private militaries, and independent autonomous intelligence agencies exist, even if they are on the extreme end of what could be considered a \"government\". reply isilofi 12 hours agorootparentThe catholic church in general is kind of a counterexample in certain aspects, but only because of reasons. The Maltese Order is just one aspect of the general weirdness of the church organisation overall, there are also the separate international legal entities \"Holy See\" and the Vatican state. Of those three, only the Vatican state actually has any sovereign land area, but of a rather symbolic size. The Vatican also has a kind of citizenship, but it is only awarded for the duration of being part of the churches government. But in all those things you only see shadows and fragments of the past that are in slow and steady dissolution. The dissolution would be far quicker if e.g. Italy were hostile to them, but the opposite is true, probably because of the popular support and gain in international influence for Italy. replyeverybodyknows 17 hours agorootparentprevCouldn&#x27;t the same argument be advanced against inheritance from family, who after all differ from tribe only in selecting by narrower genetic criteria? reply vbezhenar 19 hours agorootparentprevI thought americans won war against indians. Why would they have any obligations? It&#x27;s the other way around, those who lost the war pay contributions. reply knome 18 hours agorootparentThe native peoples of north american were not a contiguous group. Plenty of first nations were allies of the US. Of those that were variously at war with the US, conflicts resolved in treaties dictating new borders, not some form of abject right stripping subjugation or medieval rent seeking.The idea that as victors, the treaties you entered into with the opposing side are somehow not meant to be upheld is not a righteous notion. The US&#x27; repeated violation of promises made to the various first nations is a detestable part of our nation&#x27;s history. That modern jurisprudence has starting to uphold treaties our country entered into and never formally revoked is a good thing. A nation should be its word, not merely a bludgeon. reply peyton 18 hours agorootparentNever heard of first nations but as somebody who grew up around Indian country I think we should approach this area with a little more scholarship and learn about what actually happened instead of jumping to conclusions. reply JohnFen 18 hours agorootparentYou grew up in such an area and yet you&#x27;ve never heard the term \"first nations\"? reply vodkadin 18 hours agorootparentIsn’t it a more Canadian term? First time I heard it as an American was in relation to Canadian tribes. reply JohnFen 18 hours agorootparentI don&#x27;t know. I grew up in the US (Pacific NW) and it&#x27;s been a common term for at least my whole life. Same with its synonym, \"First Peoples\". reply jaywalk 17 hours agorootparentprevYeah, I thought it was a Canadian thing as well. Coming from an area that was heavily populated by Indians, it was a relatively large part of the curriculum back in my younger days. And I never heard that term in relation to Native Americans. reply daveslash 17 hours agorootparentprevI&#x27;d be a bit reluctant to quickly judge someone&#x27;s exposure to the various terminology around this topic. CGP Grey has a good video on the terminology as used in the US [0]. From the video: \"Talking to people over the last [sigh] 5 years revealed a strong correlation: the closer a person had ever been to a reservation, the more likely they would be to use the word &#x27;indian&#x27;. The farther, the more likely they would be to use the word &#x27;Native American&#x27;.\" and also \"At the time of writing [this video&#x2F;2019], &#x27;Indian&#x27; is used by Indians on Indian reservations to describe themselves\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=kh88fVP2FWQ reply knome 18 hours agorootparentprevI hate this kind of disingenuous bullshit response. reply saalweachter 19 hours agorootparentprevFirstly, I actually have no idea if there was a war with this particular tribe that resulted in this particular treaty. That&#x27;s not always the way it went; sometimes it was just diplomacy and trade (with the odd group of assholes sprinkling violence in for fun; it was rarely 100% peaceful, even when it was mostly peaceful).Second, what do you think winning a war means?It&#x27;s not always -- usually? almost never? -- a matter of one side eliminating or crushing the other to the point of abject subjugation. Rather, once there&#x27;s a clear \"winner\", the losing side is usually willing to accept a unfavorable treaty that gives the victor whatever land or trade benefits they were after, and in return for the losing side not saying \"fuck it\" and trying to take as many people as possible with them, the winning side generally agrees to leave existing power structures largely intact and leave them some part of what&#x27;s theirs. reply nemo44x 18 hours agorootparent> It&#x27;s not always -- usually? almost never? -- a matter of one side eliminating or crushing the other to the point of abject subjugation.If you decide they&#x27;re going to live then yes. You need to show them that if they can&#x27;t or won&#x27;t unconditionally surrender and change their ways then they will in fact be abjectly subjugated and their lives will be miserable. Eventually enough of them will agree that it&#x27;s not worth it. That was more or less the the USA approach with Japan in WW2. The thought being that they will fight to the death if they feel there&#x27;s any sliver of hope. So nukes were dropped which showed there was not and that it wasn&#x27;t worth fighting anymore.The other option is to just slaughter them. This has been used more frequently throughout history. reply saalweachter 17 hours agorootparentWhile the Potsdam Declaration called upon Japan to surrender unconditionally, it did, in fact, lay out the conditions for the surrender, including that the armed forces of Japan would be permitted to disarm and return home, they would retain sovereignty of their four principal islands, and that the Japanese people would not be enslaved or destroyed as a nation.After the atomic bombings -- and the Soviet advance -- Japan accepted these conditions, unconditionally, instead of holding out for better terms, like retaining conquered territory.(Edit: Now, if you want unconditional surrender, the German Instrument of Surrender, now there&#x27;s an unconditional surrender.) reply michael1999 18 hours agorootparentprevWars often end in treaties. Is the USA a country that abides by treaties, or not?https:&#x2F;&#x2F;www.supremecourt.gov&#x2F;opinions&#x2F;19pdf&#x2F;18-9526_9okb.pdfJUSTICE GORSUCH delivered the opinion of the Court.On the far end of the Trail of Tears was a promise. Forced to leave their ancestral lands in Georgia and Alabama, the Creek Nation received assurances that their new lands in the West would be secure forever. In exchange for ceding “all their land, East of the Mississippi river,” the U. S. government agreed by treaty that “[t]he Creek country west of the Mississippi shall be solemnly guarantied to the Creek Indians.” Treaty With the Creeks, Arts. I, XIV, Mar. 24, 1832, 7 Stat. 366, 368 (1832 Treaty). Both parties settled on boundary lines for a new and “permanent home to the whole Creek nation,” located in what is now Oklahoma. Treaty With the Creeks, preamble, Feb. 14, 1833, 7 Stat. 418 (1833 Treaty). The government further promised that “[no] State or Territory [shall] ever have a right to pass laws for the government of such Indians, but they shall be allowed to govern themselves.” 1832 Treaty, Art. XIV, 7 Stat. 368. reply ojbyrne 17 hours agorootparentprevThis didn&#x27;t even apply in World War II. You should google \"Marshall Plan.\" reply mikrl 19 hours agorootparentprevIn the case of Canada, the ‘war’ was won&#x2F;avoided by giving them concessions and treaties, that were reneged on and violated by the colonial government.The current government tend towards ‘truth and reconciliation’ is an attempt (or at least a gesture) to investigate and rectify these wrongs and treaty violations.I’m sure the same holds in the US in areas where there was not a wholesale genocide. reply cyberlurker 18 hours agorootparentAnd the results in Canada offer positive and negative examples to choose from when it comes to the current governments approach to indigenous issues.I only say that to caution advocating for other countries to adopt the approach Canada has taken. I am of the view there were a lot of classic examples of well intentioned policies with disastrous results.At the same time, I don’t know enough about the issue to offer alternative policy without worrying about the sensitivity of the issue. reply mikrl 17 hours agorootparentI was neither praising nor deriding Canada’s approach, I was providing context for the parent.The logic of ‘conquest->hegemony’ does not quite work in parts of North America because the ‘conquest’ was not a traditional one, but rather because of duplicity and breaking treaties, which- in a rules based order- typically have methods of restitution.Parts of the USA, like the Russian conquest of Eurasia, were traditional conquests where the invaders drove out the inhabitants by force, but that is not a universal narrative in the European colonization of North America. reply skywhopper 18 hours agorootparentprevThere&#x27;s not one single way to end a war, and not all treaties are the result of war. Regardless, the US, and the colonies before the US existed, fought wars with many Indian tribes. But in most cases, either to end wars or to avoid them, treaties were made between the United States government and the various Indian tribes to define how the entities would deal with each other. Those treaties, like any international treaty, give obligations and responsibilities to both parties. If the tribe still exists, then the obligations still exist. reply Eumenes 19 hours agorootparentprevwhite guilt reply paxys 18 hours agoparentprevAs long as people who stole their land restore them and go home, yeah. reply Eumenes 18 hours agoparentprevAgreed. Its just a money laundering front for casinos and sports betting at this point. reply hdivider 19 hours agoprevEven better approach: do it like the British. An &#x27;unwritten&#x27; constitution. No need to even have a document for the plebs to read and criticize. Whatever gets a majority in Parliament ends up being the so-called constitution. reply omnicognate 19 hours agoparentThere&#x27;s rather more to it than that: https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Constitution_of_the_United_K... reply sgjohnson 18 hours agorootparentWhile that is true, there&#x27;s a parliamentary sovereignty doctrine, which makes it just about impossible to judicially overturn primary legislation. reply omnicognate 18 hours agorootparentYes, that&#x27;s one of the principles, but I&#x27;d strongly dispute the characterisation in the post I replied to that this is to prevent the \"plebs\" having something to \"criticise\". On the contrary, it helps ensure that elections are meaningful, as there are no constraints on what the legislature thus elected can do. They are not bound by the actions of previous parliaments. The UK could far more easily repeal its gun laws than the US could repeal the 2nd amendment, were the population to want that.Not that I&#x27;m claiming the US model is inferior in some way, of course. Constitutional questions are complex and heavily dependent on a country&#x27;s history and culture. One apparent weakness of the US system is that enormous power is placed in the hands of a group of unelected officials, appointed and approved by the current executive and legislature, who then wield that power for life. I could make that point by pointing out that the law on one of the most contentious issues, abortion, has been determined for decades by the partisan composition of the supreme court rather than by public opinion. I could say something like \"the US constitution is there to prevent the hoi polloi having a say\" but it wouldn&#x27;t make any point worth making or lead to a reasoned discussion. The issue is rather more nuanced than that. reply wizzwizz4 18 hours agorootparentprevExcept for all the times that happened – like when the High Court ruled that this passage of the Crime and Courts Act 2013 (amending section 76 of the Criminal Justice and Immigration Act 2008: marked F3 and F4), creating a new category of “grossly disproportionate force”:> [F3 (5A) In a householder case, the degree of force used by D is not to be regarded as having been reasonable in the circumstances as D believed them to be if it was grossly disproportionate in those circumstances.]> (6) [F4 In a case other than a householder case,] the degree of force used by D is not to be regarded as having been reasonable in the circumstances as D believed them to be if it was disproportionate in those circumstances.does not “give householders carte blanche in the degree of force they use against intruders in self-defence” (ref: https:&#x2F;&#x2F;www.bbc.co.uk&#x2F;news&#x2F;uk-43652308) – in essence, making the legal situation basically the same as before this amendment was made. (Apparently the lawmakers didn&#x27;t quite understand how a “self-defence” legal defence worked in court, when they were writing this one up.) As I understand, as of the ruling, there&#x27;s no legal distinction between “disproportionate force” and “grossly disproportionate force”.Sure, the High Court didn&#x27;t overturn it… except for the part where they basically did. They also “quashed with prospective effect” an amendment to primary legislation (the Copyright Designs and Patents Act 1988) made by a statutory instrument (The Copyright and Rights in Performances (Personal Copies for Private Use) Regulations 2014). There are many other instances of primary legislation on the books that manifestly say one thing, but that according to the High Court mean something different. reply omnicognate 17 hours agorootparentYes, and I believe the authority of courts to do such things hinges on the difference between \"legal sovereignty\" (which parliament has) and \"political sovereignty\" (which it does not). Long article on that here [1] which I&#x27;m still reading.[1] https:&#x2F;&#x2F;ukconstitutionallaw.org&#x2F;2021&#x2F;10&#x2F;18&#x2F;michael-foran-par... reply AnimalMuppet 19 hours agoparentprevI don&#x27;t think you&#x27;re being fair to the British here. Their constitution, though not written as a single constitutional document, has at least parts that are written (most notably, the Magna Carta). The whole functions as something significantly more rigid than what a majority in Parliament decides. reply testfoobar 18 hours agorootparentGrammar police. It is \"Magna Carta\" - \"the\" is incorrect.\"This is because Latin doesn’t have articles; as a result, the Latin phrase “Magna Carta” doesn’t require a “The” in front of it. \"https:&#x2F;&#x2F;huntington.org&#x2F;verso&#x2F;magna-charta reply Clamchop 17 hours agorootparentI&#x27;m amused at the brash confidence that the laws of the language the word was borrowed from override the laws of the language it was borrowed into.Seems to me the grammar police are overstepping their jurisdiction and we&#x27;re going to have to get the interlingual grammar courts involved to sort this out.Hope they do it soon, because English lets its speakers participate in government and this Latin sounds like a threat to democracy. reply denton-scratch 17 hours agorootparentBut OP is correct; the name of the document (and the law it encodes) is Magna Carta. No article is used. reply Clamchop 16 hours agorootparentSure, but that&#x27;s a different justification rooted in English conventions (and even then, not perfectly reliable) rather than Latin ones. It would be as true for Harry Potter, no appeal to a foreign grammar needed. reply NoboruWataya 18 hours agorootparentprevRigid maybe, but still rather pointless (or at least, much weaker than the constitutions of countries such as the US). Parliament is sovereign in the UK - I&#x27;m not aware of any act of Parliament being struck down in recent history for violating the Magna Carta, nor could such a thing happen as I understand it. reply denton-scratch 17 hours agorootparent> I&#x27;m not aware of any act of Parliament being struck down in recent history for violating the Magna CartaNo. What happens is that successive acts of Parliament overrule more and more of Magna Carta, until there&#x27;s only one or two clauses still in effect.When we say \"The UK doesn&#x27;t have a constitution\", we mean that there are no laws governing what legislation Parliament can enact, other than international treaties; and those can be repudiated even without any act of Parliament - a treaty can be revoked by stroke of the executive pen. reply HeckFeck 18 hours agorootparentprevA shame it is. With the state of the current government and its power creeping over more and more of our lives, Magna Carta could do with a comeback. I see it now:Magna Carta II: It&#x27;s Time For Payback. reply gustavus 19 hours agorootparentprevApparently it includes allowing for sending people to prison because they criticize politicians and jailing people who are carrying a chisel or pair of scissors though.EDIT: And because I watched it on Sunday. Remember as always ENGLAND PREVAILS! reply NeoTar 18 hours agorootparentYep. One of the strengths of the British Constitution is also one of its weaknesses - under the concept of Parliamentary Sovereignty \"[the parliament] may change or repeal any previous legislation and so it is not bound by written law or by precedent. \"So, the things you like in a constitution are not set-in-stone and can be overturned, but so can the things you don&#x27;t like. reply HeckFeck 18 hours agorootparentIt all depends on the rulers respecting the spirit of the law more than twisting and revising the letter until it becomes oppressive.Unfortunately we&#x27;ve not had anyone who respects our liberty for some time. It&#x27;s a shame - I think the &#x27;loose arrangements&#x2F;don&#x27;t be legal-heavy&#x27; approach is what brings the most freedom, you&#x27;re let alone and the common law governs interactions only when necessary. I am sure someone can point out why it isn&#x27;t perfect but it is much more preferable to many other governments.Now that feeling that the government is more on our backs is growing. (Online \"safety\" bill? What in Blighty!? Who asked you to decide what was \"safe\" for me??)Interesting to see how it plays out conversely in the US, where it was all written down in what the founders thought was unambiguous language, but now the goal is to stuff the Supreme Court with judges who will interpret the constitution with a bias towards the way your side prefers. reply maxwell 18 hours agorootparentprevYeah, in the U.S. the people retain sovereignty instead, and our Constitution, the first codified constitution in history, provides a narrow set of powers for the federal government that serves us, written after we defeated the most powerful empire up to that point near the peak of their power in the first successful war of independence.Statutes can always be tossed or repealed, but our rights may only be overturned via amendment (Gödel&#x27;s hack). replyidlewords 19 hours agoprev [–] Few people know the modern Maine constitution was drafted by Ken Thompson. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The state of Maine proposes to amend its Constitution through a legislative proposal in the 2023 Election Ballot, ensuring that all its provisions appear in official printed copies created by the Secretary of State.",
      "A 'yes' vote would reinstate the original sections of the document omitted due to an 1876 amendment, such as Maine's treaty obligations to the Wabanaki people.",
      "The proposal intends not to alter existing commitments to the Wabanaki Nations, but to give citizens comprehensive access to the Constitution's original language."
    ],
    "commentSummary": [
      "Maine will feature a legislative proposal (Question #6) on its 2023 Election Ballot to amend the state Constitution, ensuring all provisions be included in official printed copies prepared by the Secretary of State.",
      "Voting \"yes\" would restore original sections omitted in printed copies due to an 1876 amendment, including Maine's treaty obligations to the Wabanaki people. These clauses have remained in effect despite their printed absence.",
      "The proposal seeks to enhance citizens' access to the complete original language of the Constitution, without altering Maine's existing \"duties and obligations\" towards the Wabanaki Nations."
    ],
    "points": 228,
    "commentCount": 223,
    "retryCount": 0,
    "time": 1699364592
  },
  {
    "id": 38181114,
    "title": "eIDAS 2.0's Article 45: A Potential Setback for Web Security Standards in the EU",
    "originLink": "https://www.eff.org/deeplinks/2023/11/article-45-will-roll-back-web-security-12-years",
    "originBody": "The EU is poised to pass a sweeping new regulation, eIDAS 2.0. Buried deep in the text is Article 45, which returns us to the dark ages of 2011, when certificate authorities (CAs) could collaborate with governments to spy on encrypted traffic—and get away with it. Article 45 forbids browsers from enforcing modern security requirements on certain CAs without the approval of an EU member government. Which CAs? Specifically the CAs that were appointed by the government, which in some cases will be owned or operated by that selfsame government. That means cryptographic keys under one government’s control could be used to intercept HTTPS communication throughout the EU and beyond. This is a catastrophe for the privacy of everyone who uses the internet, but particularly for those who use the internet in the EU. Browser makers have not announced their plans yet, but it seems inevitable that they will have to create two versions of their software: one for the EU, with security checks removed, and another for the rest of the world, with security checks intact. We’ve been down this road before, when export controls on cryptography meant browsers were released in two versions: strong cryptography for US users, and weak cryptography for everyone else. It was a fundamentally inequitable situation and the knock-on effects set back web security by decades. The current text of Article 45 requires that browsers trust CAs appointed by governments, and prohibits browsers from enforcing any security requirements on those CAs beyond what is approved by ETSI. In other words, it sets an upper bar on how much security browsers can require of CAs, rather than setting a lower bar. That in turn limits how vigorously browsers can compete with each other on improving security for their users. This upper bar on security may even ban browsers from enforcing Certificate Transparency, an IETF technical standard that ensures a CA’s issuing history can be examined by the public in order to detect malfeasance. Banning CT enforcement makes it much more likely for government spying to go undetected. Why is this such a big deal? The role of a CA is to bootstrap encrypted HTTPS communication with websites by issuing certificates. The CA’s core responsibility is to match web site names with customers, so that the operator of a website can get a valid certificate for that website, but no one else can. If someone else gets a certificate for that website, they can use it to intercept encrypted communications, meaning they can read private information like emails. We know HTTPS encryption is a barrier to government spying because of the NSA’s famous “SSL added and removed here” note. We also know that misissued certificates have been used to spy on traffic in the past. For instance, in 2011 DigiNotar was hacked and the resulting certificates used to intercept emails for people in Iran. In 2015, CNNIC issued an intermediate certificate used in intercepting traffic to a variety of websites. Each CA was subsequently distrusted. Distrusting a CA is just one end of a spectrum of technical interventions browsers can take to improve the security of their users. Browsers operate “root programs” to monitor the security and trustworthiness of CAs they trust. Those root programs impose a number of requirements varying from “how must key material be secured” to “how must validation of domain name control be performed” to “what algorithms must be used for certificate signing.” As one example, certificate security rests critically on the security of the hash algorithm used. The SHA-1 hash algorithm, published in 1993, was considered not secure by 2005. NIST disallowed its use in 2013. However, CAs didn't stop using it until 2017, and that only happened because one browser made SHA-1 removal a requirement of its root program. After that, the other browsers followed suit, along with the CA/Browser Forum. The removal of SHA-1 illustrates the backwards security incentives for CAs. A CA serves two audiences: their customers, who get certificates from them, and the rest of the internet, who trusts them to provide security. When it comes time to raise the bar on security, a CA will often hear from their customers that upgrading is difficult and expensive, as it sometimes is. That motivates the CA to drag their feet and keep offering the insecure technology. But the CA’s other audience, the population of global internet users, needs them to continually improve security. That’s why browser root programs need to (and do) require a steadily increasing level of security of CAs. The root programs advocate for the needs of their users so that they can provide a more secure product. The security of a browser’s root program is, in a very real way, a determining factor in the security of the browser itself. That’s why it’s so disturbing that eIDAS 2.0 is poised to prevent browsers from holding CAs accountable. By all means, raise the bar for CA security, but permanently lowering the bar means less accountability for CAs and less security for internet users everywhere. The text isn't final yet, but is subject to approval behind closed doors in Brussels on November 8.",
    "commentLink": "https://news.ycombinator.com/item?id=38181114",
    "commentBody": "Article 45 of eIDAS 2.0 will roll back web security by 12 yearsHacker NewspastloginArticle 45 of eIDAS 2.0 will roll back web security by 12 years (eff.org) 226 points by agwa 15 hours ago| hidepastfavorite118 comments ShakataGaNai 14 hours agoIt just doesn&#x27;t make sense to me why anyone tries these things. The reality of the situation would be very obvious. Just because everyone in the EU is in the EU, doesn&#x27;t make them one big happy family. Do the French want the Germans to be able to spy on their citizens? Seems unlikely. And at a larger scale, the US isn&#x27;t going to go with that. So the browsers will simply be updated to distrust all of these CA&#x27;s whom no longer can be trusted and... those EU CA&#x27;s are out of business. Poof. Hell, if it were reverse you&#x27;d see the EU up in arms. \"Why should we trust the USA?\" - And rightly you shouldn&#x27;t. That&#x27;s why Galileo exists.But on the Internet, it doesn&#x27;t work that way. You can&#x27;t just do your own thing, lest you kneecap your citizens. How will the Europeans citizens react if their own \"free and democratic\" governments take away their access to Wikipedia? Or Facebook? Or Tiktok?Using known suspect TLS Certs would also violate basically every B2B contract. When businesses sign contracts for SaaS applications, it involves some verbiage about encryption and best practices and data security in transit and at rest. What business will WANT to sign a deal that says \"Yes, it&#x27;s ok to use a TLS cert that we know our government can intercept\" when they have the option to use a cert from someone else that&#x27;s secure? Cool, shoot your own businesses in the foot too, while you&#x27;re at it.Freaking politicians. Can&#x27;t be bothered to do anything about the issues we citizens ACTUALLY want, but instead are too busy meddling in shit that no one wants. reply graemep 14 hours agoparent> The reality of the situation would be very obvious. Just because everyone in the EU is in the EU, doesn&#x27;t make them one big happy family.The EU thinks they should be reply nonrandomstring 13 hours agorootparent> The EU thinksI understand that it helps to have a name for something like this, but there is no \"EU\". \"It\" cannot think.Heed the Meehan quote; \"Men are at war because each man is at war with himself\". It&#x27;s not just that human minds are one psychotic insight away from seeing our dissociative identity disorder just beneath the surface... evey institution and collective is the same. What is wrong in the \"EU\" (principally the Commission) is that it&#x27;s large and disparate enough for some extraordinary bad actors to hide within it and exercise undue toxic influence. It is by lack of transparency that they cannot easily be rooted out, named, shamed and dislodged.Meanwhile much of the \"EU\" functions very well, and cares for its citizens. reply graemep 11 hours agorootparentI need to clarify. I was using \"the EU thinks\" as shorthand for \"the strong consensus view of the people running the EU\". I thought (obviously wrongly) that this was obvious because an organisation cannot think.I think it is safe to assume that the majority of people running the EU share the aim of \"ever closer union\" enshrined in EU treaties, which implies aiming to put the interests of the EU above national interests, which I took to be what the comment I was replying to meant by being \"one big happy family\" reply nonrandomstring 10 hours agorootparent> I was using \"the EU thinks\" as shorthand for \"the strong consensus view of the people running the EU\".Understood. And I was questioning the concept of \"consensus\" in that frame.> I thought (obviously wrongly) that this was obviousNot at all. I don&#x27;t think that is obvious. Interestingly some are raising GPT as a metaphor for emergent organisational \"thinking\". Is it a good analogy? I don&#x27;t know, but we do see similar phenomena in networks whether they be human brains, machines or other organisms. And one feature is that we are not sure how to locate \"consensus\". There&#x27;s lot more than weighted sums at play. And despite official structures and protocols, that&#x27;s not really how things work, I think we all know.Thus the emergent identity gets a lot attributed to it, which it may not be \"aware of\" in large parts of itself. For minds we have the concept of the unconscious. Perhaps in neural networks we will come to recognise something similar. But the concept seems sadly lacking in organisational dynamics where it might help us to stop talking about ideas such as \"What Google says\" or \"What the market demands\".> because an organisation cannot think.And yet we so often talk as if they can. We see Searle&#x27;s \"Chinese Room\" everywhere and wish to encapsulate and name too readily.The \"EU\" is \"mentally unhealthy\" in that sense. in that it&#x27;s simply too big and disparate to be coherent and consistent. The article about snooping on web TLS certificates could not more clearly contradict other strongly held \"beliefs\" within the organism about \"privacy\". reply gfodor 13 hours agorootparentprevThe EU thinks in the same way GPT-4 does. In a way we really don&#x27;t have a good way to describe, but it does do something close. reply etiam 12 hours agorootparentThat might have be more helpful if it was clear that there is actually anything like thinking going on in GPT-4, but to the extent there is I don&#x27;t believe it&#x27;s a good analogy for EU-the-organization.It&#x27;s multiple regular humans doing regular human thinking (in various quantities) and otherwise acting, and interacting, subject to social pressures.Calling that an organization thinking might be a convenient shorthand, but as I far as I&#x27;m concerned the utility stop right there, and forgetting that it is merely a shorthand is potentially badly misleading (which, I take it, was one major point of https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38182349 ) reply WarOnPrivacy 12 hours agoparentprev>Do the French want the Germans to be able to spy on their citizens?They might. It&#x27;s how the US intelligence agencies route around laws that prohibit spying on US citizens. They spy on a 5-eyes nation&#x27;s citizens (often the UK) who is spying on US citizens. Then they trade connections. reply mike_d 6 hours agorootparentThis is an often parroted conspiracy theory rooted in novices looking at leaked documents and not really understanding the context. Just because GCHQ shares data with NSA it does not mean the program lacks controls that protect American citizens. Partner data is still filtered for US nexus and tagged appropriately as to require multiple layers of approvals and oversight to query or view. reply WarOnPrivacy 6 hours agorootparent> This is an often parroted conspiracy theory rooted in novices looking at leaked documents and not really understanding the context.No. Sorry.> Just because GCHQ shares data with NSA it does not mean the program lacks controls that protect American citizensThis restates my point - how sharing takes place in spite of those controls. At least we can agree on something. reply mike_d 4 hours agorootparent> how sharing takes place in spite of those controlsSharing takes place because countries have mutual data sharing agreements. It is up to the receiving country to comply with domestic laws.For example if GCHQ has a dish pointed at a foreign communications satellite and receives all downlink communications, they might share that stream of raw data with partner countries. If NSA receives that stream the first thing that happens is it gets decoded into call data and parsed for any hint of US nexus communications at which point it gets tagged USPER and is not accessible to analysts. reply owlbite 4 hours agorootparentBut there&#x27;s presumably little to stop the NSA asking GCHQ \"can you give us a list of US citizen that match profile X\", so does the fact that they strip it out of their local copy make a big difference? reply mike_d 2 hours agorootparentAside from being fired and going to jail, of course there is nothing to stop them. It is kind of an illogical argument. reply fragmede 1 hour agorootparentThese are the same government agencies that the Snowden leaks informed about. How many people in the government were fined or went to jail because those were revealed to the public?You&#x27;ll forgive me if I remain skeptical. replyEGreg 14 hours agoparentprevWho remembers this? And how it ended?https:&#x2F;&#x2F;www.f5.com&#x2F;labs&#x2F;articles&#x2F;threat-intelligence&#x2F;kazakhs...But unlike Kazakhstan, the EU can actually ORDER browser makers to keep approving their backdoored certificates. And then mandate that anyone serving their own citizens use them.Look at what the UK has already done with its “think of the children” bills. The UK is weaker than the EUhttps:&#x2F;&#x2F;www.wired.com&#x2F;story&#x2F;the-uks-controversial-online-saf... reply ShakataGaNai 4 hours agorootparent> the EU can actually ORDER browser makers to keep approving their backdoored certificatesBut they can’t. Maybe they can order some companies to do so, those companies which would fight tooth and nail in court, whom cumulatively have more money than the EU (probably).. . and certainly more lawyers.But at the end of the day, they couldn’t force every browser. No company would accept a website that doesn’t work with 30% of the internet. It would, once again, knee cap that company.And while I’m not sure of every browser, I’m fairly sure you can delete CA’s in most browsers today. You certainly can on an OS level. So as soon as one CA get’s p0wned by the government, the techies would just run around and “help” all their friends and family delete the CA from being trusted. reply alwayslikethis 9 hours agorootparentprevHow? Mozilla can just get out of the EU. Google can spin off its browser to a nominally independent project (Chromium) and offer plugins for Google functionality. I don&#x27;t see how they will win this. reply account-5 13 hours agorootparentprevDon&#x27;t say that to any Brexit people... reply sroussey 11 hours agorootparentprevMozilla should get out of the EU and soon Firefox will be #1 there. reply prognu 13 hours agoprevThe logical solution for browser vendors is to also roll back the URL bar by 10 years, where we had different indicators for extended validation, normal certificates and plaintext. I guess a blue EU-logo whenever Article-45 compliant CAs are used would make sense. Then we just have to teach people: blue is for \"government snoop mode\". reply agwa 12 hours agoparenteIDAS in fact forces browser vendors to do that, but there are two problems with what you&#x27;re suggesting:1. Good luck teaching 99% of people to be wary when they see the blue address bar. People generally do not understand address bars, which is a large part of why browsers removed the EV indicator.2. There is a strong possibility that a future version of eIDAS will force businesses in the EU to get certificates from an eIDAS CA. At that point, people in the EU will be seeing the blue address bar constantly, and most of the time the certificate will in fact be legit. reply prognu 11 hours agorootparentTeaching users is of course the tricky part, and I&#x27;m not trying to excuse the insane draft regulation here. That said, eIDAS doesn&#x27;t force browser vendors to visually distinguish Article 45-forced CA certificates from traditional CAB CA certificates, and I doubt they considered the possibility. So re-adding the distinction is a valid band-aid. Your second point can be addressed relatively easily by businesses getting multiple certificates. Then, the browser can show &#x27;trusted&#x27; only if one of the certificates is not from a Article 45-forced CA. reply immibis 10 hours agorootparentprevI thought the blue address bar would have a person&#x27;s name and country in it. That person has a good lawsuit case against the government if it&#x27;s faked. Or, are we worried the DE government will make up a fake Larry Ellision and MITM oracle.com with it? Larry Ellision would easily win that lawsuit. reply immibis 12 hours agoparentprevI thought that was the whole intention of eIDAS. Everyone gets a government approved certificate they can use to sign their websites if they want to, and then the URL bar shows their identity. They don&#x27;t have to sign websites with their identity, but they have the option to. reply vkaku 13 hours agoprevI&#x27;ve talked about TLS before, it is a bane on the Internet in its current form.Here is what users need from any browser that cares about the user:- An option to not use OS supplied root certificates. Instead, to customize and set up user allowed certificates on the first run&#x2F;first site use.- An easy UI for trusted certificates that give categories and what each certificates scope means.E.g. &#x27;This certificate is issued by a telco provider on behalf of the Government of Canada, is a blanket certificate for all domains, can let the government see all your encrypted traffic.&#x27;&#x27;This certificate is issued by the IT department of your organization and let&#x27;s them see all encrypted traffic&#x27;- It should appear as a warning when a user sees these blanket certificates used on general purpose websites (like Google services) and have a way to tell whether there is a potential MITM happening.&#x27;Normally this website would use a certificate provided by Google.com Inc but it seems your Government issued certificate is being used to see all encrypted traffic you are sending to Gmail.com&#x27;- Warn meaningfully about algorithm usage choices: &#x27;The algorithm strength is 2048 bits and the year is 2023, and governments already have capable computers that can break this encryption with this strength.&#x27; reply graemep 15 minutes agoparentI think something more like ssh which exchanges certificates on first connection would be better, maybe with expiry, pinning, and sending new certs before an old one expires. On top of that some way of sending certificates, maybe offline, for really critical things like banking. reply woodruffw 13 hours agoparentprevRequiring users to manage their own root bundle is a recipe for disaster for ordinary users. You shouldn’t need to understand path building to securely initiate a connection with a website.(Besides, macOS and Windows do let you tweak the trust store from their respective GUIs. There’s nothing stopping you from doing so.) reply whoopdedo 12 hours agorootparentAnyone who would suggest putting security decisions in the face of users should be reminded of Windows Vista and its User Account Control. Dialog fatigue is not to be taken lightly.See also, cookie consent banners. reply vkaku 8 hours agorootparentThen a first time setup may be okay. People assume everything is safe because there&#x27;s a green lock icon but the situation must change for improving the actual users privacy.While dialogue fatigue is true, browsers can take care of offloading the cookie dialogues if there were a standard for it.Doing what&#x27;s necessary for privacy is no excuse to throw bad UI at a user. There has to be a way to customize our transit security and subsequently privacy. It&#x27;s a step in the right direction. reply vkaku 12 hours agorootparentprevI disagree with the current approach.Corporate users do not have a control over this, nor will people where governments try to propose a law forcing people to accept crony CAs to the trusted list. reply woodruffw 12 hours agorootparentThese are orthogonal issues: it’s not enough for governments to have CAs in trusted roots, as this attempted regulation demonstrates. OS-supplied roots exist because ordinary users can’t and shouldn’t be expected to make PKI policy decisions to use the Internet securely.If you’re trying to circumvent your corporate laptop’s MITM, you’re playing a lost game. It’s also a game that has nothing to do with ordinary users on ordinary, non-work computers. reply choko 12 hours agorootparentprevCorporate users don&#x27;t generally have control period. Keep your personal stuff away from the work laptop. TLS is useless on a machine you don&#x27;t control. reply immibis 10 hours agorootparentprevGovernment crony CAs are already in the trusted list. How does this change anything? reply vkaku 8 hours agorootparentThis prevents them from actually misusing their certificate on blanket spying programs. Every browser that allows you to configure your trusted list in a more manageable way is one more hurdle these CAs have to cross. reply immibis 7 hours agorootparentThe default trusted list has many government CAs on it which can be used for blanket spying programs. reply vkaku 7 hours agorootparentYes - and the point of adding this is to ensure that the user is warned when this happens. replyagwa 12 hours agoparentprevWarnings like that would likely violate eIDAS&#x27; requirements for \"user-friendly\" recognition, as well as its prohibition against \"mandatory requirements\".This is why eIDAS is so nuts - it forbids browsers from rolling out pro-user security measures. reply Buttons840 13 hours agoparentprev> &#x27;This certificate is issued by the IT department of your organization and let&#x27;s them see all encrypted traffic&#x27;I&#x27;m a bit out of the loop on modern security implementations. In theory though, I thought the purpose of certificates and certificate authorities was to certify that you&#x27;re actually talking to who you think you&#x27;re talking to?A browser can still communicate security with any computer out there, regardless of corporate certs, etc. Or do the corporate firewalls block communications that they cannot inspect? reply tonyarkles 12 hours agorootparent> A browser can still communicate security with any computer out there, regardless of corporate certs, etc. Or do the corporate firewalls block communications that they cannot inspect?Yes, you’ve got it. Many corporate firewalls require you to install their own root CA certificate and “transparently” intercept and rewrite traffic leaving the network. It looks like you’re negotiating with the external site, but you’re actually doing TLS negotiation with an on-prem proxy that connects to the destination site on your behalf.I say “transparently” in quotes because it definitely, in practice, breaks things here and there. reply Buttons840 9 hours agorootparentI&#x27;m sure it&#x27;s well established practice, and the courts would find it legal, but it seems like fraud. My computer says \"I want to connect to my bank, are you my bank?\" and the corporate firewall says \"yes, I am your bank\". reply tonyarkles 8 hours agorootparentI think the loophole and why it&#x27;s legal is this:> My computer saysIt&#x27;s not your computer. It&#x27;s the company&#x27;s computer and they installed the root certificate on it. For any non-provisioned machine you&#x27;d get a certificate error because the corporate-issued certificates are signed by the corporate CA that isn&#x27;t browser-approved by default. reply NovemberWhiskey 11 hours agorootparentprevYour IT department owns a certificate authority. They add its self-signed, root certificate to the trust stores of all the machines in your firm using group policies or whatever. They then install something like a Bluecoat browsing proxy, which they configure your browsers to use using group policies or whatever. The Bluecoat terminates the TLS connection by transparently providing certificates for the sites that you&#x27;re trying to access, which your browser trusts. It then makes the outbound connection to the actual site, if appropriate.It&#x27;s called TLS interception. reply alfons_foobar 13 hours agorootparentprevYour understanding is correct, but if your IT department puts a wildcard cert on your machine, it can MitM all your traffic (e.g. your company&#x27;s firewall can say \"Hi I am $SITE, here&#x27;s a certificate to prove it\" and your browser will accept it). Traffic between you and the firewall, as well as between the firewall and the actual site is still encrypted. reply immibis 10 hours agorootparentprevUser-friendly recognition means some way to say this is a certificate from John Doe, France. Probably a green box in the URL bar like EV certificates used to be, but maybe blue instead.Someone has to explain the threat model to me better. If I go to google.com and the certificate says the site is owned by John Doe (France) I should be suspicious. Is the problem that the certificate validates something other than the domain name? Any government can already easily get a domain certificate for google.com. reply vkaku 13 hours agorootparentprevIn theory, you know whom you are talking to. In practice though, every company and authoritarian government wants to sniff, be it through https proxies or enterprise-wide certificates. reply 20after4 13 hours agorootparentprevTL;DR:The certificate is associated with a private key which can decrypt the traffic for a session established using the cert. The issue is that, given a bogus certificate from a trusted authority, someone can impersonate any site they want, then proxy the traffic to the real site and spy on your session.Longer explanation:If an organization is able to obtain a certificate that the browser trusts, which matches the domain name you are visiting, then they can easily terminate the TLS at the organization&#x27;s server, then make a new request to the site, where the encrypted session is between the site and the organization&#x27;s proxy server. They get an effective man-in-the-middle attack and your browser pretends like everything is secure because there is a trusted certificate matching the domain name you visited. The browser doesn&#x27;t throw up any red flags because it doesn&#x27;t differentiate between certificates, only certificate authorities.So if a 3rd party can acquire an arbitrary certificate for some domain, and the 3rd party has the private key associated with that cert, and the same 3rd party can intercept the traffic between you and the domain in question, then they can get your traffic in the clear and there are no obvious signs that they did it.Given the current state of TLS and the way browsers deal with certs, the only way for a user to discover that something is amiss is to investigate the details of the cert. Then they might notice that it was issued by a suspicious certificate authority. Unfortunately, the proposed EU law is attempting to prohibit browser vendors from withholding trust (or otherwise scrutinizing) the state-controlled (or state-influenced) certificate authorities, with the intention of preventing browsers from interfering with government&#x27;s ability to issue illegitimate&#x2F;insecure (but you must trust them, or else!) certificates. reply immibis 10 hours agoparentprevWait, your government issued certificate? That makes no sense. You think the hypothetical government MITM device will identify who&#x27;s connecting to it, then sign google.com with their personal identity certificate? Instead of just signing all of them with a specific real or fake person&#x27;s? reply vkaku 8 hours agorootparentStuff like this comes up regularly, more folks should pay attention.https:&#x2F;&#x2F;www.securityweek.com&#x2F;turkish-ca-issues-fraudulent-ce... reply hlandau 13 hours agoprevThe correct move here is not to try and plead with the EU or do other things which implicitly recognise their authority to make such regulation. The correct move here is to hold such regulations in contempt and expressly refute any claim the EU makes to regulating web browsers as illegitimate.I may as well add that web browsers are generally open source software and their source code thus a form of speech. Recent actions by the EU have made it clear they are trying to start to exert control over web browsers, which they presumably see as prime estate for exerting control over the internet. The correct answer to this is to distribute web browsers from jurisdictions with strong freedom of speech (code) protections, remove any assets from the EU which the EU might try to take hostage to extort compliance, and respond to the EU&#x27;s frequent attempts to assert \"if anyone in the EU uses your product, you have to comply with our rules\" with \"you and what army.\" reply immibis 10 hours agoparentOf course. Nobody&#x27;s going around arresting people who solder Lightning connectors back into their new iPhones. That isn&#x27;t how regulations work. reply charleyablaze 12 hours agoprevScott Helme has leaked the secret text of Article 45! (scroll down)https:&#x2F;&#x2F;scotthelme.co.uk&#x2F;what-the-qwac&#x2F; reply ospray 14 hours agoprevI don&#x27;t understand how they think they can force EU citizens to use only approved browsers. What&#x27;s to stop anyone who wishes to from using a non EU one and changing the user agent. reply kstrauser 14 hours agoparentThey can&#x27;t, and nothing.This is all based on the incorrect assumption that they can legislate how software is written, both inside and outside their borders. reply immibis 12 hours agoparentprevThey can&#x27;t and won&#x27;t. Just like nothing stops an EU citizen from taking the USB-C charging port out of their new iPhone and changing it to a Lightning port... reply cubefox 13 hours agoparentprevThe companies offering browsers will probably be punished with harsh fees by EU courts if they don&#x27;t implement things like IP based discrimination. You would get around only with a VPN. reply philipkglass 12 hours agorootparentOr it will be circumvented by anyone out of EU reach mirroring the good software versions and offering them for download to all. There are thousands of people with their own web hosts who would probably be willing to do that, myself included.EDIT: I wrote the above thinking of desktop operating systems. It&#x27;s much worse on e.g. iOS if the only way to get a browser is through the store, and the store isn&#x27;t allowed to provide the good browser version in some regions. reply ajross 13 hours agoparentprevWell, the law[1] stops them, if they feel like following the law is important. And to the extent they don&#x27;t, enforcement provisions in the same might compel them. Same as \"what&#x27;s to stop anyone who wishes to from shoplifting\", really.But this misunderstands the situation anyway. The overwhelming majority of web clients that interpret CA data are provided by default in devices sold by companies with a clear interest in following the law; because if they don&#x27;t they can&#x27;t sell products.[1] Which I won&#x27;t engage on, except to say that this seems a lot more like \"dumb mistake in the legislation\" than \"evil plot by an unelected metagovernment\" to me. The hyperbole on issues like this gets out of control sometimes, and the EFF seems to be getting worse about it and not better over time. They used to be pretty cerebral. reply EGreg 14 hours agoparentprevSimple, they’ll also mandate that the web sites use WEI and check for approved browsers. They will also lean on software distributors to not distribute unapproved browsers or be fined, jailed or lose their ability to distribute software to Europeans. Think of how they tighten the screws on crypto and end-to-end encryption — same playbook!At every step those that don’t follow the EU’s rules will get fined by the same apparatus as GDPR violators reply immibis 12 hours agorootparentThere is exactly zero evidence or even conjecture to support this. reply donmcronald 14 hours agoprev> This upper bar on security may even ban browsers from enforcing Certificate Transparency, an IETF technical standard that ensures a CA’s issuing history can be examined by the public in order to detect malfeasance.I don&#x27;t quite understand that. How does a browser enforce CT? Even if a browser queries CT logs, they&#x27;re not that helpful without any context, right? How would a browser get anything useful from the logs beyond knowing a certificate was published to the logs?Isn&#x27;t it the job of the domain owner to monitor those logs since they&#x27;re the only one that&#x27;s going to know definitively if a certificate is illegitimate? reply agwa 14 hours agoparentBrowsers enforce Certificate Transparency by rejecting certificates which aren&#x27;t published in CT logs. A certificate that is published in CT logs isn&#x27;t necessarily legitimate, but at least it&#x27;s public so domain owners can detect it and raise the alarm if the certificate is illegitimate.Unfortunately, Article 45 states that certificates issued by EU-mandated CAs \"shall not be subject to any mandatory requirements other than the requirements laid down in paragraph 1\" and paragraph 1 does not allow browsers to reject certificates not published in CT logs.Thus, EU-mandated CAs will be able to issue undetectable MitM certificates. reply donmcronald 5 hours agorootparent> A certificate that is published in CT logs isn&#x27;t necessarily legitimate, but at least it&#x27;s public so domain owners can detect it and raise the alarm if the certificate is illegitimate.Oh yeah. I can&#x27;t believe I didn&#x27;t put that together. Thanks for spelling it out :-) reply gcbirzan 13 hours agorootparentprevDo you happen to have the full text you&#x27;re referring to? I cannot find that on Google and the one I&#x27;m reading says something else. I also couldn&#x27;t find it on eff&#x27;s post reply agwa 12 hours agorootparentUnfortunately, the text is being drafted in secret and the latest version has not been released publicly. I have seen a leaked copy but I don&#x27;t have permission to post it. I can attest that the various posts and letters speaking against eIDAS are accurately representing the text.I know this isn&#x27;t a satisfying answer, but blame the EU for drafting legislation in secret. reply immibis 10 hours agorootparentWhy are we arguing about something still in the drafting stage, then? If they&#x27;re still working on it, they&#x27;re still working on it. It&#x27;s not even finished to the stage where the public or the parliament can review it. There&#x27;s probably stuff in there they&#x27;re still thinking through and will eventually delete.Laws don&#x27;t go from secret drafting, straight to law. They get public comments, the parliament has to vote on them, the commission has to vote on them (I think - something like that), they go back to drafting to make an amended version that&#x27;s more acceptable, etc etc... of course the unfinished draft version isn&#x27;t acceptable.This isn&#x27;t the first time everyone&#x27;s got upset about an unfinished EU law. All previous times, it was shot down by the EU Parliament, who are supposed to represent the citizens. reply sleevi 7 hours agorootparentBecause this is not the “start of drafting” but roughly “final text that is largely a rubber stamp approval.” This is the output of having been through the the trilogue process - where the Parliament would&#x2F;has shut things down before - and not been shut down.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Formal_trilogue_meeting reply thedaly 12 hours agorootparentprevI can&#x27;t seem to find it anywhere. This line leads me to think it isn&#x27;t public, which is crazy:> The text isn&#x27;t final yet, but is subject to approval behind closed doors in Brussels on November 8. reply zlg_codes 13 hours agorootparentprevAh, so every CA in Europe just lost trustworthiness due to their government.Delist European CAs until they get their shit together. reply ls612 12 hours agorootparentWhen Kazakhstan tried pulling this the browser vendors did that to them and were able to because Kazakhstan couldn’t imprison their executives and employees to compel compliance. The EU on the other hand can and will. reply zlg_codes 12 hours agorootparentHow would the EU punish Google, who is an American company? At most, the EU affects things within its borders. They have no say on the greater Internet.The EU had better invest in its own browser if it intends to outlaw encryption. reply spacebanana7 10 hours agorootparentA better example would be Brave or another smaller organisation.Big multinationals have employees and assets everywhere that can be threatened.However smaller organisations operating from a single jurisdiction can only be threatened by their local government (or at least with the consent of their local government). reply zlg_codes 1 hour agorootparentI thought about Brave, but because they repackage Blink, the EU could choose to go upstream and target the engine rather than the browser, and Google ends up part of the equation anyway.Firefox is in the US, right? Pale Moon is too iirc and they forked Gecko to make Goanna. reply ls612 12 hours agorootparentprevBy locking up it&#x27;s executives in Europe or seizing it&#x27;s property in Europe. Both of which it has in far greater quantities than Kazakhstan did. reply zlg_codes 11 hours agorootparentAh, I see. So at minimum, they&#x27;d need strategies to move assets out of the region while complying to some degree, until the assets were safe. replyvanchor3 13 hours agoparentprev> How does a browser enforce CT?The certificate contains signatures from the CT logs. The browser can either accept those signatures or check the CT log itself. This \"enforces\" CT for the certificate of the site you&#x27;re accessing, but not necessarily the CA. Of course if a certificate comes up that fails CT logging, that can raise scrutiny of the CA. reply layer8 12 hours agoprevRead the ESD response to the Mozilla statement here: https:&#x2F;&#x2F;www.european-signature-dialog.eu&#x2F;ESD_experts_support... reply jsmith45 10 hours agoparentMuch of that response is misleading.It does make a technically correct claim that QWACs are currently accepted by browsers. However, the reality is that QWACs are only accepted by browsers if the issuer fully complies with both CAB Forum baseline requirements, and Root program rules. The entire purpose of the clause in question is effectively to ensure an EU Bureaucracy is responsible for for setting rules instead of CAB Forum and Root programs.Another example it is absolutely true that the eIDAS 2.0 regulars impose some certain weaker security requirements than current browsers.A trivial example is that the response claims QWACs will comply with Brower&#x27;s Certificate Transparency standards, but those standards are not in the regulation, and the regulation makes it clear that a browser cannot reject QWACS for other reasons not listed in the regulation.Another example, Mozilla has found that CAs who simply request audits done to ETSI standards (the standards imposed by this regulation) will often end up with audits that are incomplete (unable to audit all relevant controls). This can happen for legitimate reasons, but the audit results don&#x27;t provide enough details here, hence Mozilla added a requirement for an ETSI Audit Attestation Letter (AAL) that explains these limitations. Even worse, once the impediments are no longer in place, by often ETSI auditors do not re-audit the previously un-auditable controls for the last time period. Mozilla needed to impose additional rules including explaining what if any controls could not be audited, and also rules that the next audit must cover previously un-auditable controls for the previously issued audit, in addition to auditing for the that time period. Describing how to do this audits properly within in the ETSI context is complicated because the ETSI audit standards were not really designed to make such rules (Full audit of all controls over all timespans, re-auditing later if some controls could not be evaluated for any reason the first time) easy. reply zlg_codes 13 hours agoprevThe Internet is a place where governments have very little power.Even if this passes, it will not affect anyone who cares about hosting things correctly.Governments hide much more from people, and they have much less moral reasov to do so! If anything, it&#x27;s inside gov&#x27;t comms that don&#x27;t deserve protection.Pissbabies mad that they can&#x27;t spy and want to abuse policy to force it.Good luck reverse engineering math, govs. Y&#x27;all can&#x27;t win this one. reply lom 12 hours agoprevThis is like the third attempt by the EU to break encryption in a short timespan. This is getting ridiculous. reply immibis 10 hours agoparentThis isn&#x27;t an attempt to break encryption. Can you show how it is? The EFF has just posted a load of FUD in this article - governments already control CAs, so giving them another one wouldn&#x27;t give them any new interception capabilities. Actually eIDAS would give them less interception capability, since the browser would have to display some icon saying it&#x27;s an eIDAS certificate, which it doesn&#x27;t do for other CAs.Their claims center around \"the current language is imprecise\" and I&#x27;m having a really hard time seeing why that&#x27;s a problem for a bill that hasn&#x27;t even finished being written yet. reply dang 11 hours agoprevRelated ongoing thread:What the QWAC? an EV Certificate all over again - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38183259 - Nov 2023 (3 comments) reply mk89 12 hours agoprevIncredible that in 2024 the most downloaded software on bittorrent will be Firefox-US-134.1.exe :) reply anticensor 11 hours agoparentFirefox-unEIDAS-Iceweasel-134.1.exe &#x2F;swh reply phendrenad2 13 hours agoprevThis won&#x27;t stop here. Whoever in the EU government is willing to suffer the bad PR optics of outlawing Firefox, is willing to go further I&#x27;d wager. How long before Linux is banned in the EU on personal devices? reply immibis 12 hours agoparentCan we stop the FUD? Your comment is the equivalent of saying the EU government is willing to outlaw iPhones: No they&#x27;re not, they&#x27;re just saying they have to have USB-C charging ports. reply kstrauser 12 hours agorootparentPerhaps, but USB-C is arguably the equivalent of the Lightning port. Broken TLS is not the functional equivalent of working TLS. reply immibis 12 hours agorootparentYou think if the government issues certificates this breaks TLS? I had no idea it was so fragile.Here&#x27;s what&#x27;s happening - the government wants a unified framework for digital identity. They&#x27;re not saying you have to use it, but they want the framework to be there.Part of the framework is that you can get a certificate with your name on it, signed by the government saying this is officially you, and you can put this on a website to digitally sign the website.Obviously the government-issued certificate is going to have certain parameters, and they want browsers to accept these parameters so these websites will work.How else would you possibly do this, than publishing the certificate parameters and saying browsers must accept these? I don&#x27;t think they prohibited the browser from saying \"this is an EU identity certificate\", did they? I imagine it appears as an EV green box showing the person&#x27;s name and country code.I don&#x27;t know why I&#x27;d ever want that to appear on my website, but I guess some people do. reply kstrauser 11 hours agorootparent> You think if the government issues certificates this breaks TLS? I had no idea it was so fragile.Nice strawman. The actual situation is that the government wants to require browsers to accept signatures from CAs that the government selects, and ban them from validating the security of the certs signed by those CAs. In other words, they want the ability to be able to issue their own cert for example.com and forbid the browser from telling you that it&#x27;s signed by a .gov rather than, say, Comodo.With this idiotic, mandated arrangement, it would be impossible for an end user to tell whether they were speaking directly to example.com or to the government&#x27;s MITM proxy. reply immibis 10 hours agorootparentWell, yes? Part of the government issuing certificates for people is that those certificates shall be accepted as proof of identity, including in browsers. I&#x27;m not sure how else you&#x27;d like to do that. Maybe they issue certificates but nobody accepts them? No, that way is madness.> and ban them from validating the security of the certs signed by those CAs.I&#x27;m going to need a source on that one, chief. Are you talking about this part?> To that end, web-browsers should ensure support and interoperability with Qualified certificates for website authentication pursuant to Regulation (EU) No 910&#x2F;2014. They should recognise and display Qualified certificates for website authentication to provide a high level of assurance, allowing website owners to assert their identity as owners of a website and users to identify the website owners with a high degree of certainty.Maybe you are talking about this?> For those purposes web-browsers shall ensure that the identity data provided using any of the methods is displayed in a user friendly manner.Frankly, displaying the fact that a government issued identity certificate is used seems to me to be the exact opposite of a MITM, but what do I know?Where does it say that if google.com has Angela Merkel&#x27;s personal certificate instead of Google&#x27;s one, the browser shall present it as a secure connection? reply immibis 12 hours agorootparentprevGovernment-issued identity verification is at least as good as private-entity-issued identity verification, since, you know, the government is the one with the databases of identities. reply redder23 11 hours agorootparentprevIt&#x27;s not FUD it&#x27;s the truth, they OBVIOUSLY want to control everything and remove privacy and enable government surveillance. They have just proven that by trying over and over again. They just know they can not blatantly outlaw Linux or things like that, that is why they try to sneak in shit like this with some buried text on the legislation. If they could at the flip of a finger outlaw Linux and things like that and impose total control, they would for sure do it instantly. It&#x27;s just that it&#x27;s too established, too common so there would be too much outrage, so they try to break encryption this way instead. If they had their way, they would have a total control! reply immibis 10 hours agorootparentThis is the bill, right? There may be a newer version I didn&#x27;t find. https:&#x2F;&#x2F;eur-lex.europa.eu&#x2F;legal-content&#x2F;EN&#x2F;TXT&#x2F;HTML&#x2F;?uri=CEL...Can you indicate which parts are objectionable on the grounds of leading to a totalitarian surveillance dystopia? reply Saline9515 4 hours agorootparentIt&#x27;s a slippery slope. In my language (french), we call it \"sausage politics\", where you take small slices of your freedom one by one. This regulation is unwanted by anyone in the EU, creates security risks, and relies mainly on \"trust me I won&#x27;t do anything bad\", that we all know is not going to happen.Also, laws can&#x27;t be reverted in the EU semi-dictatorial regime, so, such things are really dangerous. Each year that goes, I&#x27;m thinking of a plan to leave, as our freedoms get lower and lower. Recently, the digital services&#x27; EU gauleiter declared that \"content calling for rebellion\" should be deleted from social media.Same goes with AML, and with the digital ID, where your government will have a single key allowing to know every service you&#x27;re registered to. And let&#x27;s not speak about the CBDC. reply redder23 2 hours agorootparentprevI will not do what you ask because you will not believe it anyway. You are desperately clinging on to some failed mindset that they are out for you because you like that they force Apple to use USB-C or whatever.You also seem not to read the actual point of the objection everyone has. They want to SPY ON EU citizens! WTF are you not understanding about this? Its all explained in the EFF article and countless others that are on top of HN right now. If you not see the INTENTIONS and the slow creeping dystopia you are blind. I am not going to search some specific text part out for you that proves that, its perfectly obvious for people who follow just a little bit of news and have common sense. replyfoota 12 hours agoprevThe EU: Google is going to spy on us and sell all our data!Their governments, cackling: Yes, Google is the issue. reply Puts 12 hours agoprevIsn&#x27;t this a new Schrems situation? Just because the commission can make a law doesn&#x27;t mean that it&#x27;s legal. Seems like it would certainly interfere with the European Convention on Human Rights that grants everyone right to privacy of it&#x27;s personal life and correspondence – meaning the CJEU would overthrow this law in an instance? reply asadotzler 12 hours agoparentWhat are the practical steps to this outcome. Presume this becomes law. Then do we need a person with standing to bring a case? Is there some other mechanism? Does CJEU rule without a case? How does this happen and more importantly, how long does it take. If the process is weeks or months, we may stand a chance. If it&#x27;s years, the damage will have been done with a generation of compliant (broken) products and hundreds of millions of people deprived of privacy. reply buildbot 14 hours agoprevHow does CALEA work in the USA (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Communications_Assistance_for_...)Does it fail on HTTPS communications or is a similar \"rogue\" CA that allows law enforcement to decrypt traffic as they need? reply mminer237 14 hours agoparentIt doesn&#x27;t really have anything to do with the Internet. CALEA only applies to phone calls. VoIP calls are only encrypted to and from the carrier, so they can tap them there with pre-existing telephony hardware if they have a warrant to do so. reply buildbot 12 hours agorootparentIt applies to broadband, in the second paragraph of the wikipedia article: \"it has since been extended to cover broadband Internet and VoIP traffic. Some government agencies argue that it covers mass surveillance of communications rather than just tapping specific lines and that not all CALEA-based access requires a warrant.\" reply mminer237 10 hours agorootparentOh, wow. Wikipedia&#x27;s statements are uncited so I kinda ignored it, but a DC court did okay that rule even though the statute says it doesn&#x27;t apply to the Internet. That is worrying. Still it only allows the police to have switches forward packets to them. It doesn&#x27;t have any ability to decrypt traffic. reply buildbot 1 hour agorootparentI also know of someone who worked on an implementation of it for an Internet service provider ;) reply TheIronMark 14 hours agoparentprevI don&#x27;t believe CALEA has any provisions for requiring CA providers to allow decrypt. reply buildbot 12 hours agorootparentThanks! reply java-man 15 hours agoprevThey never stop trying, don&#x27;t they? reply HPsquared 14 hours agoparentA \"no\" is temporary; a \"yes\" is permanent.Is there any way to enact a permanent \"no\"? reply mminer237 14 hours agorootparentNo, any law can be changed. The closest you can come is to make a Constitution hard to change and embed a right to free speech, including encrypted speech, therein. Anything beyond that has to be a cultural conservation. reply Saline9515 4 hours agorootparentEU laws can&#x27;t be changed unfortunately. The unelected European Commission is the only one that has the right of initiative. reply LightHugger 14 hours agorootparentprevin the US, constitutional amendments. Not sure about the equivalent in the EU reply contravariant 14 hours agorootparentBit trickier in the EU. The countries themselves have constitutions that can be amended, with varying ways in which they can be enforced.In theory this should give sufficient protection, but it becomes a bit complicated if the EU enacts regulations that contradict national laws or even the constitution.The EU derives its power not from a constitution but from its founding treaties. As best I can tell the EU claims these treaties have precedence, but honestly it&#x27;s a bit unclear how it could overrule the constitutions that gave the signatories the power to ratify the treaties. I do know that the EU wasn&#x27;t happy when Poland ruled some parts of these treaties unconstitutional (which is really part of a much bigger political fight, but is illustrative). reply toyg 13 hours agorootparentMost postwar constitutions explicitly allow for transfer of sovereignty to structures necessary to maintain peace among nations. They were originally meant for UN-like organisms and apply equally to the EU. reply tonyarkles 12 hours agorootparentCanada’s “constitution” explicitly creates a back door right in section 1. I’ve heard Canadian legal scholars comment that the only part of the Charter that would likely completely stand up against a section 1 challenge is section 12: “the right not to be subjected to any cruel and unusual treatment or punishment” replyjauntywundrkind 14 hours agoparentprevAlas, there&#x27;s just so many people with so many reasons for wanting to grab & coerce the noosphere&#x27;s thoughpaths to route through their specific power grabs. The move would spring up spontaneously in so many ways.Thanks again EFF for so vigilantly watching against encroachment. reply tomjen3 13 hours agoparentprevNot when they don&#x27;t suffer for trying.An unfortunately there is no good way, no technology board of overseers, who takes away their (smart)phone priviledges when they don&#x27;t behave. reply zlg_codes 13 hours agorootparentFingerprinting technology could be used to isolate state officials and deny them access based on that &#x27;profile&#x27;. reply redder23 11 hours agoprevIf this passes, I will keep an eye on Browsers and if they actually help people mitigate the problem in some way. Like will not new CAs spawn outside the EU like in Switzerland and sites will begin to advertise they that is a certificate from Switzerland where we have at least a bit more trust in that the EU will not spy on?I am really curious on how this will play out. Will they mandate a certificate for sites that server the EU that they have control over? This is fucking insane.We need some new tech that is decentralized, where they just can&#x27;t do this kind of thing. Hopefully this spawns something. SSL seems to be outdated and unfit for this job, as this clearly shows. reply jiripospisil 14 hours agoprevIf anything, this shows how absolutely idiotic the whole certificate authority system is. reply extraduder_ire 14 hours agoprev [–] Is there even a reason given for this? Like, why it might be a good idea to enforce? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The European Union (EU) is discussing eIDAS 2.0, a new regulation that might permit governments to work with certificate authorities in monitoring encrypted traffic.",
      "This regulation could impact certain certificate authorities' modern security requirements without the approval of an EU member government, raising potential privacy issues.",
      "Specifically, Article 45 of this regulation is causing particular concern, as it may decrease web browser security standards for European internet users. The formal text is expected to be finalized on November 8."
    ],
    "commentSummary": [
      "The European Union is planning to ratify a new regulation, eIDAS 2.0, allowing governments to cooperate with certificate authorities to potentially monitor encrypted traffic.",
      "The regulation could undermine contemporary security prerequisites on certificate authorities without the consent of an EU member government.",
      "Article 45 included in the regulation is causing privacy worries, mainly for European internet users, as it could lead to a decrease in web browser security standards. The final text of the regulation will be confirmed on November 8."
    ],
    "points": 226,
    "commentCount": 118,
    "retryCount": 0,
    "time": 1699383141
  },
  {
    "id": 38182461,
    "title": "Decoding the Complexity of Compiler Writing with x86-64 Assembly Code",
    "originLink": "http://sebmestre.blogspot.com/2023/11/en-writing-compiler-is-surprisingly.html",
    "originBody": "[EN] Writing a Compiler is Surprisingly Easy (part 1) November 06, 2023 Ever since I was a teenager I wanted to create my own systems programming language. Such a programming language would certainly have to be compiled to native code, which meant I'd have to write a compiler. Even though I managed to write several half-working parsers, I'd always fail at the stage of generating assembly code, as the task turned too complex. In this blog I intend to show my teenage self how writing a code generator is, in fact, not complex at all, and it can be fully done in a couple of weekends. (As long as we make some simplifying assumptions) I will that assume you already know that representing programs within a program is surprisingly easy Where do we even start? The goal today is to translate a high level language to x86-64 machine code. Our high-level language will have integer literals, variables, negation, and addition. To make our job simpler, we will translate the high level code to x86-64 assembly code, and use a pre-existing assembler (like the one inside GCC) to translate that to machine code. Let's get started. Here is how we will represent integer literals: struct int_literal {int value; }; Compiling them is straightforward: void compile_int_literal(struct int_literal* e) {printf(\"mov $%d, %%rax\\n\", e->value); } printf uses the % character to denote formatting commands, so a double %% is used to print the character verbatim. Here I used the x86-64 mov instruction. This instruction moves data from one place to another. In the notation used in this blog, the flow of data is left-to-right (i.e. the instruction is works as mov source, destination) In this case we are moving an immediate value (a numeric constant written directly in the code, notated with a $ preceding it) into the \"a\" register (a little space of data that lives directly inside the CPU, written as %rax) The x86-64 mov instruction can be used in several ways (\"addressing modes\"): immediate-to-register (the one we just used), register-to-memory, memory-to-register, register-to-register, etc. We will see some of these later on. I want to note that, at this point, many design decisions have already been made. Most notably: Our compiler will output AT&T-style assembly code to stdout, using printf The result of compiling an expression will be assembly code that computes and stores the value of that expression in %rax The last point is in no small part responsible for making the compiler so simple, but it also means that the code we'll generate is not very efficient. For the initiated, some obvious things that we could add to mitigate this are a peephole optimizer and a register allocator. But these would force us to implement some intermediate representation and make our compiler a lot more complicated, so we are not going to. Let's move on. How can we implement variables? The way we will represent variables in our compiler is with an integer. Yes, not with a string that corresponds to the name of the variable, but an index that represents where that variable will live in memory. Indeed, all variables will be stored in our computer's main memory. In particular, they will live in a place called the stack. The stack is a wonderful mechanism that allows us to quickly store some values in memory and safely discard them once we don't need them. In memory, it is simply laid out like an array of 64 bit integers. The way it works is extremely simple: the CPU has a register -- known as the stack pointer %rsp -- that always tells us the first slot in the stack that is available to be used. Every slot after will be free, and every slot before will be occupied. As with everything low-level, this doesn't happen magically, and we will be responsible for keeping that register up to date. We are going to be a bit naughty and not update the stack pointer for now. This is mostly okay as long as our code does not perform any function calls. With this in mind, we can represent variables using an index that tells us how many slots *after* the first available slot the variable is stored. struct variable {int slot; }; In a more complete compiler there would be a previous step that takes care of assigning a stack slot to each declared variable, and translating variable names to stack slots. We wouldn't expect the language user to type in the slots by hand. Compiling them is simple enough, but we do need to learn some more x86-64 assembly to fully grasp it. void compile_variable(struct variable* e) {int slot = e->slot;printf(\"mov %d(%%rsp), %%rax\\n\", -8 * (slot + 1)); } Here we use a different version of the mov instruction. This one looks like mov number(register1), register2, and it means \"take the value at address number+register1, and store it in register2\". (mem-to-reg mode) This is how we implement access into the stack. The stack pointer holds the address of the first free slot, and we add an offset to to access the slot that holds the desired variable. Besides that, there is a funny looking bit of math up there. There are two things to know about the stack: each slot holds a 64-bit value. This equals 8 bytes, which is why we multiply by 8 the stack grows downwards. This means that the occupied slots are at higher addresses than the free slots. This explains why the 8 is negative instead of positive there is a +1 in there because I lied. The stack pointer actually points at the last occupied slot, instead of the first free slot. Negation The representation of negation is similarly straightforward, and should be apparent to those who read the previous blog. struct negation {struct expression* target; }; I will omit the definition of struct expression for now, as it would distract from the main points of this section. To compile negations we will take advantage of the fact that compiling an expression will produce code that stores its result in %rax. This means that if we emit some code that negates %rax right after the code that computes the value to be negated, we will have succesfully computed the desired negation. Luckily, x86-64 has an instruction that does just this. void compile_negation(struct negation* e) {compile_expression(e->target);printf(\"neg %%rax\\n\"); } But just to get used to the kind of puzzles we have to solve to compile some more complicated operations, let's avoid using neg. x86-64 has a sub instruction that subtracts one operand from another. Let's try using that. In particular, let's: compute the target expression (leaving the result in %rax) put a zero into %rcx substract %rax from %rcx (leaving the negated result in %rcx) put the negated result in %rax void compile_negation(struct negation* e) {compile_expression(e->target);printf(\"mov $0, %%rcx\\n\");printf(\"sub %%rax, %%rcx\\n\");printf(\"mov %%rcx, %%rax\\n\"); } We use %rcx instead of %rbx because %rbx is a callee-saved register in x86-64, meaning we are not allowed to use it without first storing its old content in the stack, and later restoring its value. This is mandated by the x86-64 calling conventions. This is too cumbersome, so we just use the nearest non-callee-saved register. While not too complicated, this ilustrates the kind of hoops we will sometimes have to jump through in order to compile more advanced operations. I don't think this makes compiling hard, but it can get pretty tedious. Also, note the use of the reg-to-reg addressing mode Addition Like in the previous blog, we will represent additions as follows: struct addition {struct expression* left_term;struct expression* right_term; }; The general idea here will be to first compile the left term, then the right term, then emit an add instruction that adds their results. The main problem that arises is that the result of the the left term will be lost while we compute the right term. A simple fix might be to move the result to a different register, like this: void compile_addition(struct addition* e) {compile_expression(e->left_term);printf(\"mov %%rax, %%rcx\\n\");compile_expression(e->right_term);printf(\"add %%%rcx, %%rax\\n\"); } Unfortunately, this will not work when the right term also stores something in %rcx in an intermediate step. Instead, we will get some help from to our good friend, the stack. We will store that intermediate value in the stack, and read it back after the right term is done computing. If we take care that the code we generate for the right term doesn't write into the same stack slot, then we can be sure that the value will be preserved. The mechanism to prevent re-using the same stack slot is a simple counter. Since we also store variables in the stack, its value must be greater than any slot that's been assigned to a variable. For now let's just initialize it with some large number, like 10. int temp_counter = 10; void compile_addition(struct addition* e) {compile_expression(e->left_term);int slot = temp_counter++; // allocate a new slotprintf(\"mov %%rax, %d(%%rsp)\\n\", -8 * (slot + 1));compile_expression(e->right_term);printf(\"add %d(%%rsp), %%rax\\n\", -8 * (slot + 1));temp_counter--; // restore the counter } Here we finally see a mov that uses reg-to-mem addressing mode. Also, note that add can also use mem-to-reg mode. Putting it All Together The final piece of the puzzle, for now, is the struct expression data type, and its corresponding compile_expression function. These are pretty much trivial given what we've seen so far, but I'll type them out for completeness' sake. enum expression_tag {EXPRESSION_INT_LITERAL,EXPRESSION_VARIABLE,EXPRESSION_NEGATION,EXPRESSION_ADDITION, }; struct expression {enum expression_tag tag;union { struct int_literal as_int_literal; struct variable as_variable; struct negation as_negation; struct addition as_addition;}; }; void compile_expression(struct expression* e) {switch (e->tag) {case EXPRESSION_INT_LITERAL: compile_int_literal(&e->as_int_literal); break;case EXPRESSION_VARIABLE: compile_variable(&e->as_variable); break;case EXPRESSION_NEGATION: compile_negation(&e->as_negation); break;case EXPRESSION_ADDITION: compile_addition(&e->as_addition); break;} } Testing it out At this point, we are capable of compiling simple arithmetic expressions. To test this out, we can write a small program like this one: int main() {// var0 + (-var1 + 42)struct expression* e = addition(variable(0),addition( negation(variable(1)), int_literal(42)));compile_expression(e); } int_literal, variable, negation and addition are some helpers that build up the corresponding expressions. Which produces the following output: mov -8(%rsp), %rax mov %rax, -88(%rsp) mov -16(%rsp), %rax neg %rax mov %rax, -96(%rsp) mov $42, %rax add -96(%rsp), %rax add -88(%rsp), %rax Then, to be able to run it, we can just add some assembly that will take two arguments and store them in stack slots 0 and 1, and return after executing the code. .global foo foo:mov %rdi, -8(%rsp)mov %rsi, -16(%rsp)mov -8(%rsp), %raxmov %rax, -88(%rsp)mov -16(%rsp), %raxneg %raxmov %rax, -96(%rsp)mov $42, %raxadd -96(%rsp), %raxadd -88(%rsp), %raxret Finally, we hook into this code from C, and check that it returns the right thing: #include#includeint64_t foo(int64_t a, int64_t b); int main() {for (int i = 0; i < 10; ++i) { for (int j = 0; j < 10; ++j) {printf(\"expected: %d, got: %ld\\n\", i-j+42, foo(i, j)); }} } To do this we compile using GCC and run it in a terminal: $ gcc main.c foo.s -o main $ ./main expected: 42, got: 42 expected: 41, got: 41 expected: 40, got: 40 ... and so on ... Conclusion Writing a compiler is not as hard as it seems if we are willing to keep it simple. If we avoid introducing complexity ourselves, its main source is understanding the target architecture, and not the compilation process itself. In the next parts we will look at how to compile classic control flow constructs such as if and while, as well as function calls and pointers. Comments",
    "commentLink": "https://news.ycombinator.com/item?id=38182461",
    "commentBody": "Writing a Compiler is Surprisingly Easy (part 1)Hacker NewspastloginWriting a Compiler is Surprisingly Easy (part 1) (sebmestre.blogspot.com) 209 points by mmphosis 13 hours ago| hidepastfavorite83 comments carra 43 minutes agoI can agree with that approach, because I used it to write a C compiler for a fantasy console I made (Vircon32). Since it has a fully custom ISA and set of chips I could not use something like LLVM, so I wrote it more \"manually\".The first versions were very barebones (they supported little more than variables, expressions and if&#x2F;else), but over time I expanded it to support loops, arrays, pointers, structures... nowadays it&#x27;s still not a full C compiler but it has been good enough for me to write several full games reliably, and even a few people have been using it too. reply ww520 10 hours agoprevWriting a compiler is not too difficult. Most of the techniques and procedures are well researched and documented. The best thing is that you can pick the parts that are useful and stop instead of implementing the full blown end to end pipeline.Recently in an app, instead of supporting the bare minimum I wanted to support a bit more sophisticated search expression, like embedded commands and compounded conditional expression. I just hand-rolled the lexical tokenizer and the parser, and stopped without going the full mile. The tokenizer used simple regex to break up the terms and tagged them with token types. Came up with a grammar for the mini language. The parser used the standard recursive descent parsing technique on the grammar production. It&#x27;s simple to handle errors and do auto-completion of the missing syntax because the parser knew what to expect at the point of error and could fill in the default nodes in the tree as needed. The generated AST was enough to implement the search tree and the embedded commands. The whole thing was only couple files and done in couple days, but it&#x27;s very useful for the app. reply 13of40 7 hours agoparentI wrote a parser&#x2F;interpreter for VBA a few years back, and even though the core concepts were straightforward, conforming to a language that had been in development for decades turned out to be brain-wreckingly tedious. One of the biggest parts of it was a block of thousands(?) of conditional statements to figure out the result type of every combination of type+operator+type. At the end of the ordeal, though, I threw the engine into a test app that looked like GWBASIC, and got a little nostalgia kick from being able to run BASIC like it was 1983. reply luismedel 24 minutes agorootparentSame boat here. I wrote a VB to C++ transpiler to make VB6-like IDE for PalmOS (basically a clone of the existing Handheld Basic++). The type system was a mess.After one year of development on my free time I had the compiler and a form editor, but lots of out of memory errors when running the code on the simulator (and real devices) :-|At the same time, Palm sold the OS licenses to ACCESS inc., IIRC, and the future of the platform was sealed. Long story short, I shelved the project and I lost it during one of my cyclical \"move backups to to a bigger disk\" migration. reply ww520 5 hours agorootparentprevThat&#x27;s amazing to implement a full interpreter for VBA.I would imagine a lot of the type resolution are redundant. E.g. +, -, *, and &#x2F; would have the same type resolution for numbers. Those can reuse the same type resolver. May be + also work on string. Then call the string type resolver on it in addition to see if it can be resolved.Anyway, kudos for the amazing work. reply userbinator 5 hours agorootparentprevOne of the biggest parts of it was a block of thousands(?) of conditional statements to figure out the result type of every combination of type+operator+typeThis is not something uncommon for a dynamically typed language; I think the simplest approach is a multidimensional array lookup. reply pests 6 hours agorootparentprevDid you need thousands of conditionals? Couldn&#x27;t you map types and operators into an efficient representation for a single lookup?! reply tomcam 6 hours agorootparentprevThat and there were never official grammars published for any version of any basic from Microsoft afaik reply makeset 5 hours agorootparentI doubt they ever existed.I had to write a VBScript parser some 25 years ago (to syntax-check ASP files before they would crash live) and to get it to parse valid syntax correctly, I ended up with a messy patchwork of logic which was also letting through some really pathological edge cases. While trying to fix it, to my utter delight, I found that Microsoft’s parsers also allowed the exact same cases which looked nothing like valid code otherwise. I don’t recall specific examples anymore, but they were far from obvious without looking at the parser code, and I made and won bets with other programmers on whether those snippets would throw syntax errors or not. reply jakobson14 4 hours agorootparent> I doubt they ever existed.Probably right, since Microsoft&#x27;s BASIC interpreter is probably derived from the one that Bill Gates wrote as a teenage slacker. He wrote it, tried to sell it at the homebrew computer club, and then threw a hissy fit when people kept copying his paper tapes for their friends. Thus, Microsoft was born. (He got lucky later when Microsoft were chosen by IBM to develop a DOS, then bought a working DOS from somebody else. The rest as they say is history) reply WalterBright 4 hours agoparentprev> Writing a compiler is not too difficult.Wait till you&#x27;re faced with the endless .h files with their inevitable use of nutburger undocumented C extensions. reply habibur 3 hours agorootparentDon&#x27;t write a compiler for C. Write compilers that convert your sources to C.You create the header files. reply userbinator 7 hours agoprevWe will store that intermediate value in the stack, and read it back after the right term is done computing. If we take care that the code we generate for the right term doesn&#x27;t write into the same stack slot, then we can be sure that the value will be preserved.There are push and pop instructions which are perfectly suited to this nested value use. In the past, lamenting how many compilers don&#x27;t seem to realise that (and the fact that push&#x2F;pop are specially optimised on x86 via hardware known as the stack engine), I wrote a piece of a code generator with similar capabilities to the one in this article as a proof-of-concept, and with the addition of some trivial (rotating FIFO-like) register allocation, was able to generate surprisingly compact and fast code that looks like it could&#x27;ve been written by a human Asm programmer.I believe Crenshaw&#x27;s famous compiler tutorial also makes the same simplification, and it&#x27;s also a powerful generalisation since it means that arbitrarily deep nested expressions can be compiled, as long as there is sufficient stack space. reply kragen 5 hours agoparentcrenshaw mostly just emits pushes and pops; he recommends a simpler version of that rotating fifo technique (just spilling deeply nested values onto the stack so you get a performance cliff, instead of pushing old values out of the fifo) but doesn&#x27;t actually show itin ur-scheme i just pushed and popped, getting performance much less terrible than i expected, but still probably a third of the performance the rotating fifo register allocator would give reply pklausler 10 hours agoprevWriting a toy compiler for one sane input language and one target platform is indeed surprisingly easy, and very educational. I had to do this back in the 90&#x27;s for C when the O&#x2F;S SW group I worked for needed to start work on a UNIX port to a new proprietary architecture (simulator) and the company&#x27;s compiler group wasn&#x27;t getting anything started any time soon. It took maybe 3-4 KLOC to get a boring old recursive descent parser and simple code generator working well enough to compile a minimal kernel configuration and pass a compiler self-replication test. The most interesting bit was actually the preprocessor. reply mr_toad 8 hours agoparentWriting a compiler was part of the undergraduate compsci curriculum back where I did it. I still have vague memories of ancient tools like Flex and Bison (and I’m puzzled that the author seems to be hand-rolling code rather than use existing tooling). reply badsectoracula 8 hours agorootparentAFAIK nowadays it is more common to write a recursive descent parser to build whatever structure you want to work with (if not use the parsing directly) than rely on Flex&#x2F;Bison.Personally i&#x27;ve written so many parsers over the years that the code for writing one \"flows\" naturally and i feel like Flex&#x2F;Bison would introduce complexity and dependencies for no gain. reply vidarh 2 hours agorootparentI keep writing parser generators because I hate writing parsers manually, but keep returning to writing parsers manually because making a parser generator survive the first few meetings with reality without the pretty grammar turning into a hairy beast (when e.g. adding error recovery or trying to wrangle it into producing the trees you&#x27;d prefer rather than what fits the structure of the grammar) remains elusive.Ironically I think the sheer number of parser generators reflects our collective failure to make a good one more so than their amazing utility (sure, some projects so actually use some).I&#x27;m knee deep in her another parser generator these days, and I&#x27;m mildly hopeful (then that&#x27;s always the case at the outset) of taking an augmented BNF variant and producing something DFA like that retains links from each state to higher level rules to retain enough information to backtrack to a reasonable place to both report errors from and&#x2F;or resume parsing after an error.I doubt the overall approach is novel in any way, and I suspect I&#x27;ll be back to hand rolling parsers soon enough, but who knows, I might end up with some worthwhile reusable components from it... reply CalChris 4 hours agorootparentprevThere is also the ANTLR parser generator which generates a top-down parser. It&#x27;s nice to write in a grammar. Still, almost all production lexers and parsers are hand written.https:&#x2F;&#x2F;www.antlr.org reply kragen 5 hours agorootparentprevit introduces knowing where the ambiguities are in your grammar and eliminates large classes of parsing bugsit&#x27;s also dramatically easier for other people to understand reply lifthrasiir 4 hours agorootparentUnfortunately `%expect` is so easy to reach even in yacc. reply ww520 8 hours agorootparentprevUndergrad was when I learned about the subject. It was done with tools like Lex and Yacc, along with the Dragon book. These tools are fine but only work in C. Yacc&#x2F;Bison generate LALR bottom up parsers, which can be difficult to debug and use. Also it&#x27;s difficult to implement error recovery. If you want to do it in another language or want to have more control, hand rolling the lexer and parser is not too bad. reply rossant 1 hour agoprev\"Writing a Compiler is Surprisingly Easy (part 1&#x2F;72)\"Joke aside, great work up! Thank you. reply RagnarD 8 hours agoprevPlaying chess is easy. Playing good chess - not so much. Playing world class chess - good luck. reply blt 6 hours agoparentBut a lot of programmers think compilers are magic. Maybe because they read about stuff like parser generators, register allocators, optimizations, etc., that are not strictly necessary. It&#x27;s empowering to remind people that a seemingly hard task is within their reach. reply lawn 3 hours agorootparentPeople always think that what they dont understand is magic, and when they do understand it they think its simple.For example: React, Operating Systems, AI, CSS and assembly. reply RagnarD 5 hours agoparentprevTo elaborate, I&#x27;ve written a number of compilers in years past. I highly recommend it as an exercise in learning about parsing, code emission, etc. Anything that gets a developer closer to understanding that process, rather than a mystery black box, is a very good thing. So I&#x27;m not trying to be a downer, just noting that it can rapidly become an extremely complex task to make an excellent compiler which includes end user expected code optimizations, informative error messages, syntax error recovery, etc. reply khazhoux 2 hours agorootparentI&#x27;m not sure anyone would think otherwise, though. reply atan2 6 hours agoparentprevSometimes people just want to learn how to play chess, and that&#x27;s ok. reply tester756 9 hours agoprevYet it is more and more time consuming the closer you want to get to the real world compilers reply armchairhacker 9 hours agoparentIt gets harder when you try to deviate from the norm of “40 years of research and experience, and this has survived 40 years for a reason” reply bachmeier 7 hours agoparentprevThe nice thing about real world compilers is that they already exist. You can write your own compiler for situations where you need to do other things. If you need performance, compile to a language with a high-performance compiler. reply Animats 2 hours agoprevWirth&#x27;s classic recursive descent Pascal compiler in his 1976 book Algorithms + Data Structures = Programs is a basic compiler for a somewhat useful language. That&#x27;s kind of dated. What&#x27;s a modern equivalent? reply bartekpacia 2 hours agoparentCrafting Interpreters? reply ramon156 1 hour agorootparentI&#x27;d argue that crafting interpreters is becoming dated as well. There are modern alternatives that could make the process a lot more streamline. Would love a rewrite! reply GuestHNUser 1 hour agorootparentCould you expand on what alternatives you prefer? I&#x27;m not sure what is dated about Crafting Interpreters (but I&#x27;m also not following the latest developments in the compiler space).Thorston Ball&#x27;s Compiler and Interpreter book series is the only other book on the subject I find widely recommend and modern. reply codr7 24 minutes agorootparentIf you don&#x27;t mind interpreters and&#x2F;or swift, I&#x27;m working on a tutorial here:https:&#x2F;&#x2F;github.com&#x2F;codr7&#x2F;swift-interpreter replysebastianmestre 5 hours agoprevWow! My blog made the HN front page!I&#x27;ve been lurking for a while but only now made an account :^) reply kragen 5 hours agoparentthanks for writing it! i look forward to seeing future installments reply 7373737373 2 hours agoprevOne thing I haven&#x27;t seen yet is how a compiler would keep track of types and emit the corresponding assembly reply duped 6 hours agoprevI wish there were a standard cross platform assembler library in C for x86, ARM, and WASM. Because frankly writing an asm text generator and shelling out to GCC or NASM is really annoying, and it feels like something so foundational should just exist.I get there&#x27;s yasm, and libnasm, and asmjit, and libgccjit, and llvm, etc but they&#x27;re all varying degrees of \"bad\" for the purposes of a simple code generator for someone that doesn&#x27;t want to dig through ARM and Intel&#x27;s developer docs. reply lelanthran 6 hours agoparent> I wish there were a standard cross platform assembler library in C for x86, ARM, and WASM. Because frankly writing an asm text generator and shelling out to GCC or NASM is really annoying, and it feels like something so foundational should just exist.It does, it&#x27;s called C :-)> I get there&#x27;s yasm, and libnasm, and asmjit, and libgccjit, and llvm, etc but they&#x27;re all varying degrees of \"bad\" for the purposes of a simple code generator for someone that doesn&#x27;t want to dig through ARM and Intel&#x27;s developer docs.This is only for language developers who aren&#x27;t writing in C, right? Because if you&#x27;re writing in C, what would you use this assembler for?Anything a cross-platform assembler emits is going to be portable, so it&#x27;s only going to be as performant as C is, so why not just emit C?Having a C library that emits C might be a nice thing to have - then all the other languages can emit \"code\" that is cross-platform. reply duped 5 hours agorootparentC is not assembler nor is it close to assembler nor is it desirable to have a C compiler in your toolchain to compile something that needs assemblerFor example, C has a calling convention. It has a notion of a stack and heap. Certain things like arbitrary control flow, threading, and process spawning cannot be expressed in C. It has a memory model that you must adhere to.If you actually want to implement a programming language, C is not sufficient as a transpilation target except for mostly trivial designs. reply lelanthran 4 hours agorootparent> For example, C has a calling convention. It has a notion of a stack and heap. Certain things like arbitrary control flow, threading, and process spawning cannot be expressed in C. It has a memory model that you must adhere to.Yes, all trivially bypassed or worked-around if you&#x27;re emitting C. Considering the initial constraint was \"cross-platform\":1. Calling convention - what would be the point of a calling convention different to the rest of the system? You wouldn&#x27;t be able to do system calls, for one. And if you need a different calling convention within the language itself C will let you push elements onto a stack and jump to a different piece of code[1], optionally saving and restoring registers.2. The notion of a stack and heap - what&#x27;s the alternative you have in mind when using assembler? Assemblers also have a notion of a stack and non-stack addresses, after all.3. Arbitrary control flow - you can emit goto&#x27;s to your hearts content (see [1] below).4. Threading - this is platform-specific by nature, but if you&#x27;re emitting C you can emit calls to the platform&#x27;s thread primitives (CreateThreadEx, pthread_create, etc) the same way you&#x27;d have to do if you were using an assembler. Nothing stops you from proving a wrapper for threads that your emitted C code calls (so that it works on multiple platforms).5. Process-spawning - once again, this is platform-specific, so even in assembler you&#x27;re going to have to make a call to the platform&#x27;s CreateProcess&#x2F;posix_spawn&#x2F;exec functions. If you&#x27;re going to call a platform function from assembly, you may as well call it from C.6. Memory model - I&#x27;ll give you this point, even though the memory model is not that much different from assembler. If you&#x27;re emitting C, you&#x27;re still free to allocate&#x2F;define a large array and use that memory in whatever way you wish.> If you actually want to implement a programming language, C is not sufficient as a transpilation target except for mostly trivial designs.Actually, many languages with non-trivial and advanced features, such as Common Lisp, already have implementations that transpile to C. They implement the entire Common Lisp standard, and don&#x27;t seem to be missing any features even though they are emitting C and not assembler.Anonymous functions? Done with emitted C.Closures, continuations? Done with emitted C.Garbage collection? Same.What feature do you have in mind that cannot be implemented by emitting C[2], but can be implemented by emitting assembler[3]?[1] Some constraints on the jumping exist, but emitting GCC-specific C let&#x27;s you do calculated expressions for the jump target - you don&#x27;t need to `goto` a constant address.[2] I initially thought that something like Goroutines or async functions might be a candidate, but off the top of my head, I can think of at least one way to implement async functions and&#x2F;or go routines by emitting C. There&#x27;s probably more.[3] I&#x27;m not being contentious, I&#x27;d really rather like to know - my own toy language (everyone has one) currently in the phase of \"I&#x27;m thinking really hard about what it should look like\" is going to be emitting C. I couldn&#x27;t find any feature for the language that can&#x27;t be done by emitting C, so I really want to know what you have in mind. reply vidarh 2 hours agorootparentPlenty of languages have language-internal calling conventions nothing like C, and usually for good reasons.Some try to stay close to make passing the boundary easy, some are so different they need an expensive conversion step anyway and then there&#x27;s little point.Sure, you can always map your requirement onto the standard calling convention somehow, but if you can&#x27;t directly call out or in anyway it&#x27;s a constraint it&#x27;s totally reasonable to not want to be forced into.EDIT: Note that there&#x27;s nothing wrong with emitting C if you don&#x27;t have any compelling reasons not to. When we don&#x27;t it&#x27;s often for reasons such as wanting a simpler toolchain, wanting the environment to be self-hosted etc. that are tradeoffs that sometimes are frankly ideological (take that as you want - I don&#x27;t mean anything inherently negative with that other than when the authors ideology differs from mine ;) I like that there&#x27;s choice and that some deviates from the norms ), sometimes based on requirements that doesn&#x27;t really have to do with the language itself. I do agree with you that you can fit all languages onto C, and most languages neatly onto C.One example where it has traditionally been painful without compiler extensions, though, is tail call elimination. You can still do it. Other fun times involve closures, but you can do that too (been there, done that, wrote a blog post years ago) even though it quickly gets ugly.Often you end up wanting to demand a specific set of extensions.Overall nothing stops you, but at some point it also doesn&#x27;t necessarily buy you all that much - you still need to do most of the hard bits. reply lelanthran 2 hours agorootparent> Sure, you can always map your requirement onto the standard calling convention somehow, but if you can&#x27;t directly call out or in anyway it&#x27;s a constraint it&#x27;s totally reasonable to not want to be forced into.I get that, but what I don&#x27;t get is what about C makes it harder to define your own calling convention than defining it in an assembler language.In the context of this thread, OP wants a portable assembler. Implementing a custom calling convention by emitting any assembly language is bound to be more work than implementing a custom calling convention by emitting C.Maybe the situation regarding floating point registers when passing floating point values? That&#x27;s about the only thing I can think of that makes it harder to emit C code that implements a custom calling convention than doing it in assembler, but even for that I can think of workarounds, just so that other high-level constructs can be used. reply vidarh 21 minutes agorootparent> I get that, but what I don&#x27;t get is what about C makes it harder to define your own calling convention than defining it in an assembler language.You don&#x27;t get to control which registers are caller or callee saved, or which registers are free to use.If your desired calling convention fits within those constraints, you can use it via C all you want. If it doesn&#x27;t, you usually will need to either resort to compiler extensions or give up on using C. Whether it&#x27;s wise to change that for your given use case can be a worthwhile question to ask, but that is another issue.Ironically sometimes this choice is about making C interop easier. E.g. I have a prototype Ruby compiler. It can call out to C from a low level \"escape\". The same exact code is used to generate calls to Ruby methods and to C. But the Ruby code needs the arity of the code that&#x27;s being called to be passed along. Putting it in a register that&#x27;s not used for arguments in the standard calling convention means that when calling out to e.g. glibc the C code just won&#x27;t be able to access those values.Now, in my case, if I&#x27;d been on the fence about using C as the target, then I&#x27;d have handled that in a different way instead, so that didn&#x27;t really influence my choice to emit assembler. But I can&#x27;t define that calling convention in ISO C.> Implementing a custom calling convention by emitting any assembly language is bound to be more work than implementing a custom calling convention by emitting C.Generally, your calling convention simply involves what goes into registers and what goes on the stack in which order. Storing to a register vs. outputting to an argument list only marginally different in effort. In the compiler mentioned above, preparing arguments is literally: arges.each_with_index { a,i| @e.save_to_stack( compile_eval_arg(scope, a), i) }If I was emitting to a C argument list instead, the only thing that&#x27;d change is the `@e.save_to_stack` bit. `save_to_stack` is a one-line method.There is plenty of complexity of dealing with assembler directly, and you certainly ought to have a reason for doing so over outputting to a higher-level target, but the complexity cost of assembler is not there.> OP wants a portable assemblerAnd as they pointed out, C is not a portable assembler. It is sometimes close enough, but it imposes plenty of restrictions that you can&#x27;t get around in ISO C. That can be perfectly fine, but it&#x27;s a tradeoff. Sometimes you can find a halfway house of requiring a specific compiler, but that also removes at least some of the advantage. reply kragen 5 hours agorootparentprevworks pretty well most of the time; chicken scheme even compiles call&#x2F;cc to c reply userbinator 5 hours agoparentprevYou can generate the opcodes directly if you want to avoid having a separate assembler.AFAIK MSVC does that unless you tell it to generate Asm output, whereas GCC always goes through the separate assembler route. reply wg0 4 hours agoparentprevOne way would be to target and generate LLVM IR.You get multiple platforms for free if I&#x27;m not wrong. reply kragen 11 hours agopreva problem that a lot of these series run into is that the author runs out of steam before they finish writing them. crenshaw&#x27;s otherwise excellent series suffers from this, for exampleso far the author of this one has only written the first chapteri&#x27;ve written a few didactic compilers that are complete enough to compile themselves, though not complete enough to compile anything else; these may be of more interest to someone who&#x27;s looking for how to make writing a compiler surprisingly easy, though they do lack the extensive explanatory text in the linked blog post- http:&#x2F;&#x2F;canonical.org&#x2F;~kragen&#x2F;sw&#x2F;urscheme (from a subset of scheme to at&t-syntax i386 assembly, 1553 lines of code)- https:&#x2F;&#x2F;github.com&#x2F;kragen&#x2F;stoneknifeforth (from a forth-like language to an i386 linux elf executable, 132 lines of code)- https:&#x2F;&#x2F;github.com&#x2F;kragen&#x2F;peg-bootstrap&#x2F;blob&#x2F;master&#x2F;peg.md (from a peg grammar with semantic actions to javascript, 66 lines of code)- https:&#x2F;&#x2F;github.com&#x2F;kragen&#x2F;peg-bootstrap&#x2F;blob&#x2F;master&#x2F;handaxew... (tangles a literate program in virtually any plain-text format, such as markdown, html, restructuredtext, or tex, into virtually any plain-text programming language, 208 lines of code; used to tangle both itself and the peg compiler compiler above)- http:&#x2F;&#x2F;canonical.org&#x2F;~kragen&#x2F;sw&#x2F;dev3&#x2F;meta5ix.m5 (from meta5ix, a language for writing parsers derived from val schorre&#x27;s meta-ii, to meta5ix assembly, 18 lines of code; it is a top-down parsing language with limited backtracking, like pegs, but less expressive and implementable without heap allocation or the ability to backtrack past the beginning of a line; see http:&#x2F;&#x2F;canonical.org&#x2F;~kragen&#x2F;sw&#x2F;dev3&#x2F;meta5ixrun.py for an m5asm interpreter)- http:&#x2F;&#x2F;canonical.org&#x2F;~kragen&#x2F;sw&#x2F;dev3&#x2F;meta5ix2c2.m5 (from a slightly different variation of meta5ix to c, 133 lines of code)most of these do take the same ast-free approach as the linked blog post and crenshaw, just emitting code as they finish parsing a production (or, in the case of stoneknifeforth, a token), but ur-scheme in particular does not; it uses scheme s-expressions as its syntax tree, because some kind of syntax tree is necessary to be able to allocate some local variables on the stack while also supporting closures. peg-bootstrap can certainly handle code that builds an ast with its semantic actions, but its implementation of itself just glues together snippets of javascript textalso worth mentioning in this connection:- darius bacon&#x27;s work, especially parson (for example, https:&#x2F;&#x2F;github.com&#x2F;darius&#x2F;parson&#x2F;blob&#x2F;master&#x2F;eg_calc_compile...)- the oberon compiler in wirth and gutknecht&#x27;s oberon book- the later chapters of sicp reply musicale 9 hours agoparent> the author runs out of steam before they finishOne approach is to finish the whole compiler first and then to split it up for presentation, but I imagine most writers don&#x27;t want to do that. reply whitten 5 hours agoparentprevThank you for your hard work. reply kragen 5 hours agorootparenti hope you enjoy it reply musicale 11 hours agoprevI like this approach, but why not take it one step further toward Turbo Pascal and generate the opcodes? ;-) reply jojobas 4 hours agoprevThe 2014 (doesn&#x27;t time fly) edition of the ICFP Programming Contest had participants make a Pacman brain, deliverable in SECD machine assembly, and ghost brains, deliverable in a simple microcontroller assembly.Most teams, ours included, wrote 2 (probably rather crappy) compilers in 3 days.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ICFP_Programming_Contesthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SECD_machine reply gigel82 10 hours agoprevThat&#x27;s... not a compiler. It&#x27;s a small part of a compiler backend (code generator). reply t14n 12 hours agoprevI like the sentiment of the title, even if it gets people riled up. I&#x27;m fondly reminded of the introduction from Bob Nystrom&#x27;s _Crafting Interpreter_ [1]> This last reason is hard for me to admit, because it’s so close to my heart. Ever since I learned to program as a kid, I felt there was something magical about languages. When I first tapped out BASIC programs one key at a time I couldn’t conceive how BASIC itself was made.> Later, the mixture of awe and terror on my college friends’ faces when talking about their compilers class was enough to convince me language hackers were a different breed of human—some sort of wizards granted privileged access to arcane arts.> It’s a charming image, but it has a darker side. I didn’t feel like a wizard, so I was left thinking I lacked some inborn quality necessary to join the cabal. Though I’ve been fascinated by languages ever since I doodled made-up keywords in my school notebook, it took me decades to muster the courage to try to really learn them. That “magical” quality, that sense of exclusivity, excluded me.> And its practitioners don’t hesitate to play up this image. Two of the seminal texts on programming languages feature a dragon and a wizard on their covers.> When I did finally start cobbling together my own little interpreters, I quickly learned that, of course, there is no magic at all. It’s just code, and the people who hack on languages are just people.> There are a few techniques you don’t often encounter outside of languages, and some parts are a little difficult. But not more difficult than other obstacles you’ve overcome. My hope is that if you’ve felt intimidated by languages and this book helps you overcome that fear, maybe I’ll leave you just a tiny bit braver than you were before.1: https:&#x2F;&#x2F;craftinginterpreters.com&#x2F; reply JohnMakin 11 hours agoprevWho needs a lexer, a parser, and an AST when you can just explicitly feed the tokens into a switch statement that completely falls through if it runs into something it doesn&#x27;t recognize? This is super easy!Sorry, I am by no means a compiler expert, but spent enough years in study of them and taken enough stabs at writing my own that this take is hopelessly naive, and I really hope the author realizes it. reply mianos 11 hours agoparentI have written multiple compilers, from C-like interpreters to protobuffer like compilers over the years, all in production, some still.Not doing a finite state machine for any stream interpretation is a huge mistake, just as much as it is outside of the compiler tokenisation, such as protocol decoders and even just parsing config files.edit: There is a well known book with a dragon on it, but I first learnt from The Unix Programming Environment, by Brian W. Kernighan and Rob Pike. In just a few pages they clearly explain how to write an basic calculator like this, that generates intermediate code to run on a stack based interpreter. I started with this and expanded it to emit assembly for an arcane DG machine. I know that code generated ran for at least 20 years. Kinda surreal as nothing lasts that long usually. reply musicale 11 hours agorootparentCould you elaborate on what you mean by that? To me this looks like a code generation library, an approach I like because of its concreteness and adaptability (for example, if we changed it to emit opcodes then it could be used for dynamic code generation, which has many fun and interesting applications.)Also this post is aimed at the author&#x27;s imagined teenage self. Does that change anything? reply mianos 10 hours agorootparentWhen writing a compiler you want to first look at what you expect and when you get that, what to expect next. If that does not come, where do you go?We call this a graph, but there is no need to confuse things with advanced terms. reply musicale 9 hours agorootparentI don&#x27;t see any parsing in TFA - I think they are taking a bottom-up approach by starting with a code generation library before even thinking about parsing.I like this approach because it produces something that generates usable code without worrying about things like parsing or high level language syntax, and you&#x27;ve basically written a DSL&#x2F;intermediate format which can be compiled by an existing C compiler. reply globalnode 8 hours agorootparentprevthanks for the edit, i will endeavor to have a look at that source reply elcritch 11 hours agoparentprevVery true. Writing a compiler that works on correct code is often trivial. It’s not much harder than a minimal lisp or forth.However, figuring out errors, adding type checking, etc now that’s hard. reply mati365 12 hours agoprev [–] * compiler without optimization phase reply mamcx 11 hours agoparentAka: a compiler.A compiler is just `source -> generate -> target`. All the other fancy things are optional. IMPORTANT things, but don&#x27;t detract from calling it a \"compiler\".---This is similar to anything else: A single `.html` served on `:80` is a website. A 2d, grayscale `pacman` is a videogame. `print(\"hello world\")` is a program, etc. reply aatd86 10 hours agorootparentAka a function tongue-in-cheek :p reply phtrivier 12 hours agoparentprevIf I read the article correctly, it&#x27;s actually \"a compiler for a language that only supports basic arithmetic, without a lexer, a parser, symbols, nor an optimization phase\".Which _is_ surprisingly easy to write. But it might be a stretch to call it \"a compiler\" :D reply ozim 11 hours agorootparentYes draw two circles and then the rest of the owl kind of thing. reply eichin 11 hours agorootparentprevEh, a college friend put together a C compiler in 100 lines of yacc (not particularly golfed, either, C just isn&#x27;t that sophisticated.) Great for playing with \"what if C + this one feature\" kind of things in a concrete way. So from my perspective, not a stretch at all... reply cmrdporcupine 12 hours agorootparentprevYeah, I&#x27;ve written stuff like this many times -- mostly producing AST then bytecode, etc. I never really wanted to call it a &#x27;compiler&#x27; per se though that&#x27;s what it is. Because I generally stand in awe of serious optimizing compiler engineers, they have deep domain expertise that is admirable. reply mattgreenrocks 12 hours agorootparentTrue, but no need to self-gatekeep the terminology here just to appease a rando commenter. :) reply mepian 11 hours agoparentprevAs opposed to a tree-walking interpreter, which is usually presented as the only viable way to write your first programming language implementation. reply acchow 12 hours agoparentprev* compiler without good error messages reply musicale 11 hours agorootparentClang may have better static checking, but Apple&#x27;s MPW C compiler still had better error messages.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37283375 reply acchow 11 hours agorootparentCute and whimsical, but I was thinking along the lines of context for answering \"why?\"\"..because it was defined at [....] and used [....] and [...] as a int32 type (thus coerced to int64), but passed in [...] as a\" reply zem 12 hours agoparentprevif you use the nanopass approach you can add optimisation phases relatively easily reply agumonkey 12 hours agorootparentbut since he hardcodes the register allocation, i wonder how he can control anything here reply zem 11 hours agorootparentyou can refactor over time to add a register allocator. the key point is it&#x27;s usually easier to do these things within the context of an end-to-end working compiler than with a big design up front. reply agumonkey 11 hours agorootparentyeah, fair enough reply TheChaplain 12 hours agoparentprev [–] Probably adheres to the principle; \"Make it work, then make it fast\" reply kevindamm 11 hours agorootparent [–] It&#x27;s actually three steps: make it, make it work, make it work faster.this may actually be somewhere between step one and two. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The blog post simplifies the process of writing a compiler, targeting the translation of high-level language into x86-64 machine code, with a focus on integer literals, variables, negation, and addition.",
      "The author demonstrates how to represent and compile integer literals, variables, compile negations utilizing different x86-64 instructions, and the importance of register usage in this process.",
      "Addition commands are compiled using the stack and a simple counter to prevent slot reuse, culminating in the compilation of arithmetic expressions. Future posts plan to guide on compiling control flow constructs and function calls and pointers."
    ],
    "commentSummary": [
      "The blog post author describes that writing a compiler, while initially seeming complex, can be simplistically achieved over a few weekends with certain assumptions.",
      "Conceptual emphasis is given on translating the high-level language to x86-64 machine code using variables, negation, and addition which are further translated to x86-64 assembly code via a pre-existing assembler.",
      "Using x86-64 instructions, the post provides examples on compiling integer literals, variables, negations and addition, concluding with the compilation of arithmetic expressions. Future posts promise to tackle compiling control flow constructs and function calls."
    ],
    "points": 208,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1699389403
  },
  {
    "id": 38176062,
    "title": "Introducing SectorC: World's Smallest C Compiler in x86 Machine's Boot Sector",
    "originLink": "https://github.com/xorvoid/sectorc",
    "originBody": "SectorC SectorC is a C compiler written in x86-16 assembly that fits within the 512 byte boot sector of an x86 machine. It supports a subset of C that is large enough to write real and interesting programs. It is quite likely the smallest C compiler ever written. In a base64 encoding, it looks like this: 6gUAwAdoADAfaAAgBzH/6DABPfQYdQXoJQHr8+gjAVOJP+gSALDDqluB+9lQdeAG/zdoAEAfy+gI AegFAYnYg/hNdFuE9nQNsOiqiwcp+IPoAqvr4j3/FXUG6OUAquvXPVgYdQXoJgDrGj0C2nUGV+gb AOsF6CgA68Ow6apYKfiD6AKrifgp8CaJRP7rrOg4ALiFwKu4D4Srq1fonP9ewz2N/HUV6JoA6BkA ieu4iQRQuIs26IAAWKvD6AcAieu4iQbrc4nd6HkA6HYA6DgAHg4fvq8Bra052HQGhcB19h/DrVCw UKroWQDoGwC4WZGrW4D/wHUMuDnIq7i4AKu4AA+ridirH8M9jfx1COgzALiLBOucg/j4dQXorf/r JIP49nUI6BwAuI0G6wyE0nQFsLiq6wa4iwarAduJ2KvrA+gAAOhLADwgfvkx2zHJPDkPnsI8IH4S weEIiMFr2wqD6DABw+gqAOvqicg9Ly90Dj0qL3QSPSkoD5TGidjD6BAAPAp1+eu86Ln/g/jDdfjr slIx9osEMQQ8O3QUuAACMdLNFIDkgHX0PDt1BIkEMcBaw/v/A8H9/yvB+v/34fb/I8FMAAvBLgAz wYQA0+CaANP4jwCUwHf/lcAMAJzADgCfwIUAnsCZAJ3AAAAAAAAAAAAAAAAAAAAAAAAAAAAAVao= Supported language A fairly large subset is supported: global variables, functions, if statements, while statements, lots of operators, pointer dereference, inline machine-code, comments, etc. All of these features make it quite capable. For example, the following program animates a moving sine-wave: int y; int x; int x_0; void sin_positive_approx() { y = ( x_0 * ( 157 - x_0 ) ) >> 7; } void sin() { x_0 = x; while( x_0 > 314 ){ x_0 = x_0 - 314; } if( x_0157 ){ x_0 = x_0 - 157; sin_positive_approx(); y = 0 - y; } y = 100 + y; } int offset; int x_end; void draw_sine_wave() { x = offset; x_end = x + 314; while( x = 314 ){ // mod the value to avoid 2^16 integer overflow offset = offset - 314; } } } Screenshot Provided Example Code A few examples are provided that leverage the unique hardware aspects of the x86-16 IBM PC: examples/hello.c: Print a text greeting on the screen writing to memory at 0xB8000 examples/sinwave.c: Draw a moving sine wave animation with VGA Mode 0x13 using an appropriately bad approximation of sin(x) examples/twinkle.c: Play “Twinkle Twinkle Little Star” through the PC Speaker (Warning: LOUD) Grammar The following grammar is accepted and compiled by sectorc: program = (var_declfunc_decl)+ var_decl = \"int\" identifier \";\" func_decl = \"void\" func_name \"{\" statement* \"}\" func_name =statement = \"if(\" expr \"){\" statement* \"}\"\"while(\" expr \"){\" statement* \"}\"\"asm\" integer \";\"func_name \";\"assign_expr \";\" assign_expr = deref? identifier \"=\" expr deref = \"*(int*)\" expr = unary (op unary)? unary = deref identifier\"&\" identifier\"(\" expr \")\"indentifierinteger op = \"+\"\"-\"\"&\"\"|\"\"^\"\">\"\"==\"\"!=\"\"\"\"=\" In addition, both // comment and /* multi-line comment */ styles are supported. (NOTE: This grammar is 704 bytes in ascii, 38% larger than it's implementation!) How? See blog post: SectorC: A C Compiler in 512 bytes Why? In 2020, cesarblum wrote a Forth that fits in a bootsector: (sectorforth) In 2021, jart et. al. wrote a Lisp that fits in the bootsector: (sectorlisp) Naturally, C always needs to come and crash (literally) every low-level systems party regaurdless of whether it was even invited. Running Dependencies: nasm for assembling (I used v2.16.01) qemu-system-i386 for emulating x86-16 (I used v8.0.0) Build: ./build.sh Run: ./run.sh your_source.c NOTE: Tested only on a MacBook M1 What is this useful for? Probably Nothing. Or at least that's what I thought when starting out. But, I didn't think I'd get such a feature set. Now, I'd say that it might be useful for someone that wants to explore x86-16 bios functions and machine model w/o having to learn lots of x86 assembly first. But, then again, you should just use a proper C compiler and write a tiny bootloader to execute it.",
    "commentLink": "https://news.ycombinator.com/item?id=38176062",
    "commentBody": "A C Compiler that fits in the 512 byte boot sector of an x86 machineHacker Newspastlogin [dupe] A C Compiler that fits in the 512 byte boot sector of an x86 machine (github.com/xorvoid) 203 points by doener 21 hours ago| hidepastfavorite58 comments userbinator 19 hours agoPreviously discussed on HN: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36064971 reply dang 15 hours agoparentYes, it&#x27;s a great topic but since it had significant attention in the last year, it counts as a dupe for now. This is in the FAQ: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsfaq.html. reply baq 20 hours agoprevHow large would a compiler which can build tcc and can be built by this be?tccboot https:&#x2F;&#x2F;bellard.org&#x2F;tcc&#x2F;tccboot.html clocks in at a ginormous 138kB by comparison.&#x27;Can we boot to linux from source in 512b&#x27; is the wrong question to ask ;) reply mati365 17 hours agoprevSlightly different idea but currently I&#x27;m working on C + Assembler Compiler to prototype and run such 512B games &#x2F; apps for retro CPUs.https:&#x2F;&#x2F;github.com&#x2F;Mati365&#x2F;ts-c-compiler reply andai 17 hours agoprevBlog post with more details: https:&#x2F;&#x2F;xorvoid.com&#x2F;sectorc.html reply distcs 18 hours agoprevWhen we talk about these sector$LANG implementations, I am guessing we are talking about the boot sector that BIOS recognizes, right?Does the 512 byte limit for a boot sector exist in UEFI too? I don&#x27;t know much about UEFI so if someone could educate me about how the boot sector and its size limit differs in UEFI, I&#x27;d love to know. reply sspiff 18 hours agoparentNo, UEFI loads PE executables from a special partition called the EFI System Partition or ESP. There&#x27;s no real size restriction there as far as I know.Before the ESP is accessed, there is no standardized way to customize the boot process. You could put these kinds of sectorX toys into the firmware directly, which would come with more constraints, but it would be vendor-specific.There is a platform-independent VM running a special EFI byte code that is part of the EFI specification, which allows you to extend the UEFI system with things like additional drivers, but those are also loaded from the ESP. reply distcs 18 hours agorootparentThanks for the answer! I&#x27;ve got some more questions now. Sorry, but if anyone is willing to take a stab at these questions, it&#x27;d be helpful to me.1. IIUC PE executables are Windows executables. So a Linux system that targets UEFI ends up writing a PE executable to the EFI System Partition?2. I know that some UEFIs (or is it all?) support BIOS boot sector as backward compatibility feature? How does that work? If I write a \"hello world\" program in pure machine code in the 1st sector of the boot disk, would UEFI read that and execute that? How would it even know whether what&#x27;s in the first sector is valid code or garbage? By checking the magic 0x55 0xaa at the end of the boot sector? reply rft 17 hours agorootparent> 1. IIUC PE executables are Windows executables. So a Linux system that targets UEFI ends up writing a PE executable to the EFI System Partition?Short answer: Yes.Longer answer: Yes, but it is not exactly a classic Windows desktop application. A PE file itself is at its core just a way to store data in a somewhat structured way. It has metadata (like imports&#x2F;exports and the target architecture) and actual contents (like data and code). I think it is a good idea to reuse an already existing, common executable file format for this use case. That the choice was PE instead of ELF or Mach-O is, IMO, the result of Microsoft being in the UEFI consortium. They are a big player and likely pushed for this. Whether or not ELF would have been a better choice, I can not say, but at this point I don&#x27;t think it matters.More info on that topic at OSDev Wiki: https:&#x2F;&#x2F;wiki.osdev.org&#x2F;UEFI#Binary_FormatFile output on my GRUB install: &#x2F;boot&#x2F;EFI&#x2F;GRUB&#x2F;grubx64.efi: PE32+ executable (EFI application) x86-64 (stripped to external PDB), for MS Windows, 4 sections reply Brian_K_White 17 hours agorootparent\"I think it is a good idea to reuse an already existing, common executable file format for this use case.\"Similarly how many file formats are actually just pkzip files with standardzied names and contents. reply oynqr 18 hours agorootparentprevSince FAT32 is the only FS that must be supported, I&#x27;d guess one potential limit is 4 gigs. reply danbruc 16 hours agoparentprevA classical PC master boot record does not actually have 512 byte for code as it also contains the partition table and a signature, you have 446 bytes for code. Not sure what exactly the BIOS validates, you might be able to get away with an invalid partition table. In general there is not really any limit unless you want to be compatible with something existing, you can define whatever disk layout you like. At worst you will have to load additional sectors yourself because the BIOS has no clue where you put them. I no longer remember what a floppy boot sector looks like, how much room you have there. reply distcs 18 hours agoprevIt&#x27;s been a long time since I&#x27;ve done ASM but do I understand it right that this implementation compiles each function and then executes it immediately? Or does it really compile the whole source code and then execute the binary generated?And where is the compiled binary saved? Is it kept temporarily in memory itself for immediate execution? Or is the compiled binary saved back to the disk?If someone could point me to the right sections of the code that answer these questions, it&#x27;d be of great help! Thanks! reply bluetomcat 17 hours agoparentLooks like a recursive-descent parser that emits instructions in memory as it parses. Then it executes them immediately (sectorc.s): ;; done compiling, execute the binary execute: push es ; push the codegen segment push word [bx] ; push the offset to \"_start()\" push 0x4000 ; load new segment for variable data pop ds retf ; jump into it via \"retf\" reply userbinator 13 hours agorootparentDoesn&#x27;t even have room for recursive descent or any sort of operator precedence. reply rowanG077 19 hours agoprevI&#x27;m getting pretty tired of this false advertisement. This is not a C compiler. It doesn&#x27;t have many crucial features required to compile most larger C programs. I do have to say it&#x27;s impressive what they have squeezed into 512 byte. reply distcs 18 hours agoparent> This is not a C compiler.This is technically true! What is posted here is not a C compiler. It is an implementation of a subset of C.I&#x27;d prefer that the title honestly mentions that like: A compiler for a subset of C that fits in the 512 byte boot sector.It is still a remarkable feat. But honestly, when I read the original title I was in complete disbelief that someone could implement a whole C compiler in 512 bytes.But with the new context that it is a subset of C (not the whole C), the initial great surprise is gone. It is still very impressive though. reply Brian_K_White 16 hours agorootparentOr even, interpreter. It compiles and executes on the fly, in ram, function by function. It doesn&#x27;t even compile the whole input but just a bit and immediately executes that bit before moving to the next bit, and doesn&#x27;t save the compilation result anywhere. To me, that&#x27;s an interpreter.So it&#x27;s a c subset interpreter.And a very cool thing. This is not a denegration or critique at all, just terminology.I think it&#x27;s perfectly fine for a bootstrapper to be a drastic subset. They all already are drastically limited in countless other ways anyways like not knowing how to use any of the crazy hardware, networking, etc. A forth bootloader is a full turing language that can eventually do anything, but it itself can do almost nothing initially besides use bios-provided features and start interpreting code which then provides more functionality. reply jcul 18 hours agoparentprevTo be fair, the first sentence states that it supports a subset of C.>SectorC is a C compiler written in x86-16 assembly that fits within the 512 byte boot sector of an x86 machine. It supports a subset of C that is large enough to write real and interesting programs.The post title could include this, but perhaps it&#x27;s a little verbose.In any case, agreed it&#x27;s impressive to fit it in 512 bytes! reply tomjakubowski 17 hours agorootparenti&#x27;m sorry to nitpick but it&#x27;s the second sentence which mentions it only supports a subset, not the first sentence. and the first sentence calls it a \"C compiler\" without qualification reply jcul 4 hours agorootparentAh yes you&#x27;re correct, I should have said first paragraph. reply humanrebar 19 hours agoparentprevAgreed. It&#x27;s a cool project, but it&#x27;s a compiler for a DSL that is a subset of C. reply userbinator 13 hours agoparentprevIt&#x27;s closer to B than C. reply jjtheblunt 19 hours agoparentprevI wonder how long until some LLM filters fraudulent titles wrt the article contents reply doener 18 hours agoprevI found this in a Golem article (German): https:&#x2F;&#x2F;www.golem.de&#x2F;news&#x2F;milliforth-eine-programmiersprache... reply PumpkinSpice 16 hours agoprevFolks here are probably reading too much into the \"boot sector\" angle. This project, like many others on HN, is best understood as \"doing something in a constrained way because it&#x27;s a fun challenge.\" As to why 512 bytes, the honest answer is \"because it&#x27;s a round number with some vague retro connotations.\"There was never a constraint on x86 that you had to fit any real functionality into a single disk sector. All the bootsector code ever did was setting up the registers and calling BIOS to load more data from disk - and the only reason you had this done in stages was so that BIOS wouldn&#x27;t have to know the particulars of your OS, such as where to find the kernel or what address to put it at.For what it&#x27;s worth, the pre-boot BIOS environment was always quite featured, offering text and VGA graphics, disk and keyboard handling, and so forth. In fact, when you look at something like MS-DOS, it was actually the BIOS-side code that was doing a lot of the heavy lifting. MS-DOS was halfway between a shell and a \"real\" OS as it is understood today.Nowadays, with UEFI, we essentially decided to make the initial code executed by the CPU an operating system in itself, with filesystem support and so forth - and the notion of a 512 byte first-stage bootloader is largely gone. reply xorvoid 15 hours agoparentSomebody with a fine taste in fall beverages gets it! Lol reply userbinator 13 hours agoparentprevUEFI is almost like protected-mode DOS, with its support for things like filesystems and networking. reply codedokode 15 hours agoprevI loved reading about hacks and tricks used to implement this (like they did in 80s). reply amelius 20 hours agoprevNo pointer support? reply benj111 20 hours agoparentWell theres pointer dereferencing.I&#x27;m not sure if the int type actually does anything. It may just be Typeless, and there&#x27;s no difference between an int and a pointer, if you want to treat an int as a pointer, you just dereference it.That&#x27;s how it works in assembly. reply devit 19 hours agorootparentThe code just ignores variable declarations. All variables are 16-bit words.It just hashes the variable name and uses twice the hash value as the address of the variable in memoryFor functions instead it uses twice the hash to store and lookup the function address at compile time, dedicating the whole compiler data segment except it seems for ds:0 to that table.Note that in segmented x86-16, the code (plus constants) and stack are in dedicated segments, and string functions used to write the generated code write to yet another segment selected by es.This seems to be the best strategy for compiler code size, although obviously it&#x27;s vulnerable to hash collisions and only supports global non-array variables. reply TedDoesntTalk 20 hours agoparentprevIt says:> pointer dereference reply varispeed 20 hours agoprevLove it! reply rollcat 20 hours agoprevFrom readme:> What is this useful for?Hard disagree with \"nothing\"! This could be a stage 1 compiler for running an entire OS from source. Tcc already demonstrated this running Linux, but it takes significantly more than 512 bytes.Also: https:&#x2F;&#x2F;malleable.systems&#x2F; reply bell-cot 18 hours agoparent>> What is this useful for?Other than \"look at really cool thing I made\", I&#x27;m thinking it might have some nice Chain-of-Trust use cases. A 512-byte binary isn&#x27;t hard to verify by hand. Vs. nobody can hope to verify that a modern multi-MB `cc` binary doesn&#x27;t contain a back-door-maker for someone less trustworthy than Ken Thompson. reply CamperBob2 17 hours agorootparentIntel: \"LOL get your own microcode.\" reply Brian_K_White 17 hours agorootparentrisc-v: \"workin&#x27;n on it\" reply rollcat 16 hours agorootparentHow does an instruction set solve supply chain trust?I suggest you reconsider [1] & [2], but apply the thought process in the context of a physical CPU. The problem is not source access or patents, the problem is you don&#x27;t have an electron microscope to look at these nanometers-wide elements; even if you did, it&#x27;s still an insanely difficult process.[1]: https:&#x2F;&#x2F;www.cs.cmu.edu&#x2F;~rdriley&#x2F;487&#x2F;papers&#x2F;Thompson_1984_Ref...[2]: https:&#x2F;&#x2F;research.swtch.com&#x2F;nih reply Brian_K_White 16 hours agorootparentVery simply, by not requiring Intel or AMD to produce the hardware to implement the isa.It&#x27;s true, but irrelevant, that you can&#x27;t trust a risc-v cpu from Intel any more than an x86 cpu from Intel.But I think the bulk of x86 and amd64 patents have expired since the 90&#x27;s already, so I think you could have other suppliers designing and fabricating x86_64 royalty-free and open-source today just as well, and risc-v is particularly interesting at least as much for the simpler start-over design as for the pure unencumbered ip. reply lloeki 14 hours agorootparentprevMaybe that was not the intent but I read it as a reference to Intel ME. replyColonelPhantom 19 hours agoparentprevYou&#x27;d also need to load the source code from disk. At the point where you&#x27;re doing that, the 512-byte limit isn&#x27;t really relevant anymore, and adding \"loading code from disk\" within the 512 bytes isn&#x27;t exactly realistic. reply londons_explore 19 hours agorootparentBIOS systems can load a page from disk in just a couple of bytes (since you are calling into the BIOS to do the actual work for you).Obviously, if you want to read from a file, you have all the overhead of understanding a filesystem. reply WaitWaitWha 16 hours agorootparent> you have all the overhead of understanding a filesystem.No need. Read & write cluster&#x2F;sector or block&#x2F;page directly; BIOS already does that. reply DougN7 16 hours agorootparentDon’t you need to read a directory structure to know where the file’s sectors are, how many there are, etc, and thus need to understand the file system? reply EvanAnderson 16 hours agorootparentYou could do something really quick-and-dirty. Write the code into sequential sectors, put a sentinel value in the last sector to indicate the code ends. It wouldn&#x27;t be at all good for in-place editing but it would be easy to load and parse the code. reply masklinn 16 hours agorootparentprevYou’d put the file contents at a static offset, or a location pointed to by the MBR or something. reply benj111 19 hours agorootparentprevMovsb can move the data in one instruction so I don&#x27;t see why it&#x27;s &#x27;unrealistic&#x27;I don&#x27;t really get your objection. 512bytes is rather arbitrary, yes. But I don&#x27;t see why it becomes less relevant when it&#x27;s ram. reply 6581 20 hours agoparentprevWith builder-hex0, 512 bytes are more than enough. https:&#x2F;&#x2F;github.com&#x2F;ironmeld&#x2F;builder-hex0 reply dale_glass 20 hours agoparentprevI wonder how long it&#x27;s going to take for Gentoo to adopt this. reply f1shy 15 hours agoparentprevThat is the concept behind GNU MES [1][1] https:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;mes&#x2F; reply tromp 17 hours agoparentprevIt would be far more useful if it supported function arguments. I wonder how much of the other features they&#x27;d have to give up to support those within 512 bytes. reply Waterluvian 20 hours agoparentprev“If you want to boot your OS from scratch…” reply linuxrebe1 17 hours agoprev [–] This is scary. It hides in boot sector and can compile tiny C apps to bootstrap malware. Wipe system, rebuild, blackhat is soon back in, rinse and repeat. Th end solution ... destroy the box. reply tomjakubowski 16 hours agoparentI don&#x27;t see what makes a compiler in the boot sector scarier in malware terms than any other program… would you elaborate?Like, how does the malware benefit shipping its own source code and a tiny compiler at boot time, over just booting directly into the compiled malware? reply JohnFen 16 hours agoparentprevThat sort of attack has been around for a very, very long time.> Th end solution ... destroy the box.Or reformat the disk, or even just write over the boot sector with something else (proper boot code, zeros, or even garbage). reply wvh 15 hours agorootparentSome viruses intercept the interrupt handler, detect if you&#x27;re trying to write to the boot sector, then either fake a write or change the sector. I believe some forms of ParityBoot (B?) did this. So you need to be sure you&#x27;re booting from a clean medium, which in the case of some of these boot viruses might not be that easy since a lot of your disks and floppies might have been infected already.Some viruses also used extra space at the end of the partition table or the end of the disk to store themselves so they wouldn&#x27;t be limited to the 512 byte limit (minus the metadata in the boot sector). reply sitzkrieg 16 hours agoparentprev [–] spooky code running code! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SectorC, a C compiler written in x86-16 assembly, potentially holds the title for being the smallest C compiler due to its capability to fit within the boot sector of an x86 machine.",
      "Supporting a substantial subset of C language, SectorC enables the crafting of complex programs, such as those involving animation of a moving sine-wave, despite its compact size.",
      "Although suggested to have a niche use-case, SectorC can be a helpful tool for individuals keen on understanding x86-16 bios functions and machine model without needing substantial knowledge of x86 assembly."
    ],
    "commentSummary": [
      "SectorC is a C compiler, said to be one of the smallest ever developed, written in x86-16 assembly. The compiler is unique as it can fit within the boot sector of an x86 machine.",
      "Despite its compact size, SectorC supports a notable subset of the C language, including functions, if statements, while statements, and other features. This allows for the creation of complex programs like a moving sine-wave animation.",
      "It seems developed with a focus on people who want to understand x86-16 bios functions and the machine model, providing them a bridge to explore without needing to learn extensive x86 assembly."
    ],
    "points": 203,
    "commentCount": 58,
    "retryCount": 0,
    "time": 1699360435
  },
  {
    "id": 38178592,
    "title": "Advancing Async Rust: A Comprehensive Four-Year Development Plan",
    "originLink": "https://without.boats/blog/a-four-year-plan/",
    "originBody": "A four year plan for async Rust Nov 7, 2023 Four years ago today, the Rust async/await feature was released in version 1.39.0. The announcement post says that “this work has been a long time in development – the key ideas for zero-cost futures, for example, were first proposed by Aaron Turon and Alex Crichton in 2016”. It’s now been longer since the release of async/await than the time between the first design work that underlies async/await. Despite this, and despite the fact that async/await syntax was explicitly shipped as a “minimum viable product,” the Rust project has shipped almost no extensions to async/await in the four years since the MVP was released. This fact has been noticed, and I contend it is the primary controllable reason that async Rust has developed a negative reputation (other reasons, like its essential complexity, are not in the project’s control). It’s encouraging to see project leaders like Niko Matsakis recognize the problem as well. I want to outline the features that I think async Rust needs to continue to improve its user experience. I’ve organized these features into features that I think the project could ship in the short term (say, in the next 18 months), to those that will take longer (up to three years), and finally a section on a potential change to the language that I think would take years to plan and prepare for. Near-term features These features are all features that I believe the Rust project would be able to ship within the next year or two. They all require relatively small changes to the compiler, because they depend on abstractive capabilities that are already implemented, and they involve relatively small changes to the surface syntax, largely new syntax implied already by the existing syntax. I think these are the things the project should focus its attention on, because they should be easier to ship and easier to build a consensus around. AsyncIterator and async generators I’ve harped on the importance of generators to Rust repeatedly in the past, so I won’t devote a lot of attention here. I’ve also highlighted before that the original plan for iterators included shipping generator syntax. Briefly, my opinion is that the absence of generators has left Rust in a confused state, in which the relationship between asynchrony and iteration is unclear (I elaborate more in my linked blog post). I want to focus specifically on async iterators and async generators, and the features that are needed to complete these. An async generator is a natural transformation from a generator: just like functions, generators can be marked async, and now you can use the await operator inside of them. Using my preferred syntax, this would look something like this: async gen fn sum_pairs(rx: Receiver) yields i32 { loop { let left = rx.next().await; let right = rx.next().await; yield left + right; } } The composition of these features falls out naturally from these syntaxes. Unlike a generator, an async generator compiles to an AsyncIterator. There is one other piece of syntax that is needed: for await loops. These can be called from within any async context, and consume items from the AsyncIterator, yielding control when the AsyncIterator yields pending: for await item in async_iter { println!(\"{}\", item); } When I was working on async Rust, this syntax was held up on two different design tangents. On the one hand, Taylor Cramer thought that the feature was a poor choice because users should instead be using for_each_concurrent, to get some concurrency. I do not agree with that: it’s not always the case that users want to use for_each_concurrent, adding more internal concurrency to your async function is a decision that needs to be considered with care, and there should be an obvious syntax for when you don’t want that, which for await is. On the other hand, there was some speculation about making “await patterns” that destructure futures and then somehow making that work here; I think this would imprudent and leaving await as an expression, and for await as a special expression for handling AsyncIterator, is the most sensible choice. Revisiting the table from my previous blog post, you could add this column for async iteration:Asynchronous Iteration Context async gen Effect (iteration) yield Forward (asynchrony) await Complete (iteration) for await The biggest thing blocking this is an issue on the library side: how should the AsyncIterator interface be expressed. I’ve already written about my preference for stabilizing AsyncIterator as-is, with the poll_next method. This remains a subject of some controversy, so I will return to it, but not in this post. For now I’ll just say that I think the failure to stabilize AsyncIterator over the past 4 years (which was absolutely not our intention when we planned the async MVP) has been harmful to async Rust, because APIs based on async iteration have been relegated to unstable features and side-libraries, leaving users confused and poorly supported when they need to deal with repetitious asynchronous events, a very common pattern. The single best thing the Rust project could do for users is stabilize AsyncIterator so the ecosystem can build on it, and it could do that tomorrow. The good news is that work is already underway on reserving the gen keyword in the next edition, so that generators could be implemented. This feature is using the same state machine transform that async functions already use, and by analogy should be feasible to implement without big changes to the compiler. The only big unresolved questions with generators (and which doesn’t apply to async generators, if AsyncIterator is stabilized as is) is how to make them self-referential. I’ll return to that question later in this post. Coroutine methods Orthogonal to the introduction of these additional kinds of coroutines is their integration into the trait system. Right now, you cannot define an async trait method in stable Rust. The good news is that this is changing, and in a soon-to-be-released version of Rust, it will be possible to write an async trait method. As other coroutines, generators and async generators should not require any special support to use them in traits that wasn’t already implemented for async functions. So when generators and async generators are implemented and stabilized, they should be supported as methods out of the box. The only thing that remains to be implemented for coroutine methods is the concept of “Return Type Notation” (or RTN). The problem is that adding a coroutine method to a trait adds an anonymous associated type to that trait, which is the return type of that method. Sometimes (most importantly: when spawning that method in a task on a work-stealing executor or otherwise moving it to another thread) users need to add additional bounds to that anonymous associated type. So Rust needs some syntax for declaring that. This is RTN. For example: trait Foo { async fn foo(&self); } // later: where F: Foo + Send, F::foo(): Send In my opinion, it is important to ship RTN because of a design principle I call the “Can you fix it?” principle. If an upstream dependency of yours has an async method, and you need to add a Send bound to the return type, can you fix it, or do you need to fork the library? Without the ability to add RTN bounds to where clauses, you cannot express the bounds that you require without changing the upstream code, even if your code is all perfectly valid (i.e. even if the async method you want to call is Send). It’s very frustrating for users to encounter a problem in which their code should compile fine, but the only way to satisfy the compiler is to fork a dependency. Fortunately, the project is already focusing on this feature, and I expect it to be shipped in the next year. There seems to be some discussion around the exact syntax for this feature: I would encourage contributors not to be too obstinate over syntax differences that don’t substantially change the feature. Coroutine closures Another aspect of Rust’s language design in which coroutines are currently not well-supported is closures. Niko Matsakis has explored this issue in two recent blog posts, focusing only on async closures and not on generative or asynchronously generative closures. In the first, he proposed treating async closures as a new hierarchy of function traits (i.e. adding AsyncFn, AsyncFnMut, and AsyncFnOnce). In the second, he instead explores the idea of modeling async closures as closures returning impl Future (e.g. F: Fn() -> impl Future). I prefer the second approach, because it does not result in a proliferation of more traits. This becomes especially apparent when you consider generative closures and asynchronously generative closures: if the function trait for each of these things were distinct, instead of 3 function traits, Rust would have 12. In contrast, by modeling coroutine closures as closures returning an impl Trait, no new traits are needed. It has the additional benefit that it involves modeling them in the exact way that Rust already desugars normal async functions. As Niko highlights in his blog post, this would require adapting the Fn traits to allow their return type to capture input lifetimes. There are a few things that Niko calls out in his post that require changing Rust’s syntax, possibly across an edition boundary: Adding a lifetime to the Output parameter of the Fn traits Desugaring -> impl Trait to a bound on the associated type projection instead of a new variable Because these may require an edition change, the project should work through the specifics of these changes immediately. But they do not seem like extremely thorny problems to work out. There is one other thing I would add to this feature, though. Once you have Fn() -> impl Future and so on, it would be natural to extend the syntax to have a kind of “async sugar” (and “gen sugar”) just like functions do. That is to say, special syntax sugar should be added to the Fn traits that makes it possible to write closure bounds like this: where F: async FnOnce() -> T // equivalent to: where F: FnOnce() -> impl Future where F: gen FnOnce() yields T // equivalent to: where F: FnOnce() -> impl Iterator where F: async gen FnOnce() yields T // equivalent to where F: FnOnce() -> impl AsyncIterator What’s nice about this is that it isn’t some new general-purpose abstractive concept like “trait transformers” or “effect generics:” it’s just a little bit of sugar that is a natural extension of sugar that already exists from one place (function declarations) to another (function trait bounds). And these function traits already have special syntax, because they use parens and arrows for their parameters and return type. This wouldn’t require a lot of implementation work or consensus on a controversial new feature. Medium-term features The features in the previous section were all features that I believe could be shipped without a huge amount of implementation effort, and which don’t have many thorny open questions in their design. The features in this section, on the other hand, are more difficult. It’s good that people are already investigating them now, but they don’t seem very close to shipping and I wouldn’t expect them in the next year or two. Object-safe coroutine methods Though async trait methods will soon be a stable feature, they will not initially be object-safe. I think this was the right decision, but it would be ideal if someday they could be. The problem with object-safety is this: each coroutine method implies an anonymous associated type, which would have a different size and layout in each implementation. In order to erase the static type of the trait object, you also need to erase the type of that method’s anonymous return type: in other words, it also needs to somehow be a trait object. For our examples, we’ll consider this trait: trait Foo { async fn foo(&self); } If I want to make a trait object of Foo, I need to specify the return type of Foo::foo. Thankfully, RTN starts to unravel this problem by allowing us this syntax: Box> But what is Something? It can’t be a specific type, or else that limits the trait object to implementations that return that type: in practice, this means limiting it to a single specific type, and now it isn’t even a meaningful trait object at all. That’s why it needs to be a trait object itself. For example, that might be Box>>>>. Of course, that is incredibly verbose. There are basically two problems at play which shape the design space: There needs to be some kind of transformer that takes your implementation of Foo, and includes the glue to allocate the future in the heap. Some members of the project leadership have the very strongly held view that heap allocations should be “explicit,” where explicit means there should be more syntax required to do it. As a result, the project has considered a new wrapper type that would be required, which would “explicitly” indicate (by virtue of being a different type) that the future type will be heap allocated. My understanding is that something like what I’ve written above would be Box>, or maybe just Boxed (it’s not clear to me from the material I have available). My own opinion is different. I think its reasonable to make the default behavior of a heap allocated trait object (i.e. Box, Rc and Arc) to allocate the state machine with the same allocator as that type. For non-owned trait objects, like &mut dyn Foo, I would also be fine making the default behavior allocating them with the global allocator, though here I see the point more (especially because this wouldn’ be possible in no_std contexts). Regardless, I agree it would be important to allow users to override this behavior with some alternative glue mechanism. This requires an interface for writing your own glue code, which might do something else (like use alloca to allocate a dynamically sized type on the stack). I just think that there should be a reasonable default behavior, which for heap allocated trait objects is probably heap allocating that state. In my opinion, this is not “implicit” any more than requiring all users to use an adapter is “implicit,” it just involves setting a reasonable default. Still, resolving this controversy to everyone’s satisfaction would be a blocker on this feature, as well as developing the interface for the glue code. I want to make one other note in this section: previous discussions of this issue treat the unstable dyn* feature as a prerequisite for object-safe coroutine methods. I do not believe this is the case. What dyn* does is create an existential type that all of the different trait object pointer types would implement, by virtualizing also their destructor code; if you can accept that trait objects using different allocation strategies for their virtual coroutine methods are different types, there’s no dependence on dyn* at all. I personally think the dyn* feature is a questionable direction for the Rust project to pursue. Async destructors Another very thorny issue is the problem of async destructors. Sometimes, a destructor might need to perform some kind of IO operation or otherwise block the current thread; it is desirable to support non-blocking destructors which instead yield control, so that other tasks can run concurrently. Unfortunately, there are several problems with this. The first problem is that running the async destructor is best effort, even more-so than running any destructor. This is because if you drop a type with an async destructor in a non-async context, there’s no possibility of running the destructor because this is not in an async context. There have been a couple of different ideas about how to solve this, such as using let async bindings to indicate variables that can’t be moved into a non-async context, or just accepting it and treating the async destructor as only an optimization over the non-async destructor. The second problem is actually very similar to the problem with trait objects: if the async destructor needs to use some sort of state, where do you store it? One option is to disallow async destructors from having state, using a poll method. This is simple, but it is problematic for things like data structures: a Vec for example has no way of storing which items it has polled already, and has to keep polling their destructors in a loop. This would be pretty unacceptable, probably. But then dealing with the state raises the same issues as trait objects. The third problem with async destructors is how to handle their interaction with unwinding. In particular, if you are unwinding through an async destructor, which returns Pending, what happens? There would need to be some kind of asynchronous version of catch_unwind that the pending calls can jump to, so that other tasks can run. This problem I think is easier to solve than the other two, but it needs to be specced out. I go back and forth between thinking that the difficulty with async destructors is one of the worst things about async Rust and thinking that maybe async destructors aren’t that useful anyway. Regardless of where you land, there is a lot of design work needed for this feature to be shippable, and I don’t think it will come soon. Long-term features In contrast to the near-term and medium-term features, there are certain larger problems with the design of Rust that I think should be considered carefully, such that they could not be addressed in the next few years. Still, the work of considering them must begin at some point, so that they can eventually be closed. I’m talking about “changing” the rules of Rust. As of right now, there are a few valuable kinds of types that Rust cannot really support: Immoveable types: types which can’t be moved once their address has been witnessed. Unforgetable types: types which can’t go out of scope without running their destructor or destructuring them. Undroppable types: types which can’t be dropped or forgotten but must be destructured. (The latter two are usually grouped together as “linear types” when people talk about them, but there are very important differences.) I think evidence has shown that there is a strong motivation for at least the first two categories. To support self-referential coroutines and intrusive data structures, Rust needs some support for types that are known never to move again. Because Rust doesn’t support immovable types, we added this functionality using the Pin API. But the Pin API has a few big flaws: one is that the API is clunky and difficult to work with. More important, though, is that it requires an interface to explicitly opt in to supporting immovable types; traits that existed before Pin can’t gain the ability to work with immovable types. There are two specific traits for which this is a big problem: Iterator: because iterator doesn’t support immovable types, the project is at an impasse about how to support immovable generators. Drop: because drop doesn’t support immovable types, an arcane implication is that you need crates like pin-project to access fields of pinned types. This is all very baroque and confusing, and wouldn’t be necessary if Drop supported immovable types. On the other hand, if Rust had the Move trait, these problems would go away. Self-referential generators would just not implement Move, and work naturally. The Pin type could be completely deprecated, and a reference to a type that doesn’t implement Move would have the same semantics as a pinned reference to a type that doesn’t implement Unpin. Of course, this would require pretty major edition-crossing changes. The scoped task trilemma presents a strong argument for types which cannot be forgotten. Stackless coroutines cannot use the destructor-based concurrent borrow trick: the only way to make it work is to use a closure-passing “internal” style, which is what Rust opted against when it went for stackless coroutines. This incompatibility between these two desirable aspects of Rust’s design makes a strong case that the decision not to support unforgettable types was the wrong decision. I titled this post “a four year plan” for a reason: if Rust were to adopt these fundamental changes, it would have to be done across an edition boundary, and I strongly doubt that it could be done as part of the 2024 edition. This leaves the 2027 edition, four years from now, as the target for such a change. But the project should commit to a decision about this change sometime soon, in the next two years, and that should include a temporary solution for generators, such as requiring them to be pinned before they can be used as iterators. I’ve been exploring what would be required to do this change on my blog this year because I think it is something the Rust project should seriously consider changing. I intend to continue to focus on this issue next year, because I think the implications of all of the different options needs to be fully understood. I’m trying to find ways to make this a collaborative process, but my options are limited. My goal isn’t really even to make a particular recommendation (though I will surely have opinions), but just to understand the full space of options for resolving these issues. What are the exact trade offs between different options to handle the problem of self-referential generators? What different requirements would there be to support “unforgettable” types as opposed to “undroppable” types? If Move were to be added, how could Pin be removed across an edition boundary? These are the kinds of questions I want to answer. However, I recognize that adding support for these kinds of types would be the biggest change to Rust since it was stabilized in 2015, and that making this change would bring with it enormous costs for both the project and the community. I also recognize that there are valid arguments why supporting these kinds of types isn’t really worth it (like the painful interaction with trait objects). For these reasons, the Rust project should build into its consideration of this idea the possibility that not doing anything may ultimately be the right outcome. In general, my instinct is to doubt big changes to Rust at this point in its design process. What I think Rust needs is to finish integrating the features it has already committed to - features like external iterators, stackless coroutines, monomorphized generics, and unsized trait object types. I specifically feel changing the rules around moveability and linear types is justified because of the implications for the integration of these existing features. Closing remarks This post has once again gotten very long. I decided to focus this post on changes to the language; in another post to come I will focus my attention on the standard library and the async library ecosystem, as well as devote a specific post to the AsyncIterator interface. I want to make one other remark, which I tried to find a place for in this post and the previous one, but couldn’t. It concerns the controversy around the final syntax for the await operator which played out in 2019. For those who don’t know, there was a big debate whether the await operator in Rust should be a prefix operator (as it is in other languages) or a postfix operator (as it ultimately was). This attracted an inordinate amount of attention - over 1000 comments. The way it played out was that almost everyone on the language team had reached a consensus that the operator should be postfix, but I was the lone hold out. At this point, it was clear that no new argument was going to appear, and no one was going to change their mind. I allowed this state of affairs to linger for several months. I regret this decision of mine. It was clear that there was no way to ship except for me to yield to the majority, and yet I didn’t for some time. In doing so, I allowed the situation to spiral with more and more “community feedback” reiterating the same points that had already been made, burning everyone out but especially me. The lesson I learned from this experience is to distinguish between factors that are truly critical and factors that don’t matter. If you’re going to be obstinate about some issue, you’d better be able to articulate a deep reason why it is important, and it had better be something more pressing than the slight differences in affordances and aesthetics between syntax options. I’ve tried to take this to heart in how I engage in technical questions since then. I worry that the Rust project took the wrong lesson from this experience. The project continues in its norm (as Graydon mentioned here) that with enough ideation and brainstorming, eventually a win-win solution to every controversy can be discovered. Rather than accepting that sometimes a hard decision has to be made, the project’s solution to the burnout of that comes from allowing these controversies to hang open indefinitely has been to turn inward. Design decisions are now documented primarily in unindexed formats like Zulip threads and HackMD documents. To the extent that there is a public expression of the design, it is one of a half dozen different blogs belonging to different contributors. As an outsider, it is nearly impossible to understand what the project considers a priority, and what the current state of any of these things are. I’ve never seen the project’s relationship with its community be in a worse state. But that community contains invaluable expertise; closing yourselves off is not the solution. I want to see the relationships of mutual trust and respect rebuilt between project members and community members, instead of the present situation of hostility and dissatisfaction. To this, I want to thank those from the project who have reached out and engaged with me on design issues over the last few months. rust async futures",
    "commentLink": "https://news.ycombinator.com/item?id=38178592",
    "commentBody": "A four year plan for async RustHacker NewspastloginA four year plan for async Rust (without.boats) 201 points by steveklabnik 17 hours ago| hidepastfavorite220 comments mplanchard 16 hours agoThis is a really interesting post, and it&#x27;s predictable if disappointing the degree to which the comments are rehashing all of the same tired arguments about async rust.I for one am pretty satisfied with async rust, and I&#x27;m excited for the stabilization of async-trait. I&#x27;d love to see some of the improvements discussed in this post come to fruition. Generators in particular are something I&#x27;ve found myself wanting on multiple occasions, because writing custom Iterators is relatively complex.The point about return-type notation is really interesting. Once async-trait is stabilized, we&#x27;ll probably go through and rip out as much usage of the `async-trait` macro as possible, so I&#x27;ll be curious to see how often we run into the issue described there. I also really like the idea highlighted in the blog post of adding async sugar to function closure types as part of expanding the support for async closures, e.g.: where F: async FnOnce() -> T &#x2F;&#x2F; rather than where F: FnOnce() -> impl FuturePersonally, the lack of good support for async in closures remains one of my only issues with async, just because we often write code in a more \"functional\" style, and whenever we&#x27;re dealing with complex async stuff we often wind up having to drop out of that. reply munificent 16 hours agoprev> AsyncIterator and async generatorsFor what it&#x27;s worth, Dart has had synchronous and asynchronous generators (including `await for` statements) for as long as its had async&#x2F;await. They are neat features. I&#x27;ve definitely written code using synchronous generators that would be hard to manually transform into a custom Iterable implementation.But they add a large amount of complexity to the language implementations and it turns out are very rarely used in practice. Here&#x27;s a quick scrape I did of the most recently published 2,000 packages on our package manager: -- Style (64317 total) -- 59409 ( 92.369%): normal ================================================= 4842 ( 7.528%): async ==== 42 ( 0.065%): async* = 24 ( 0.037%): sync* =Async&#x2F;await is clearly pretty useful with there being one for roughly every ten normal functions. But generators and async generators are barely used at all.Rust might be a in a different situation because efficient concurrency may be much more important in a systems language, but it&#x27;s not clear to me that those same features carry their weight in Dart. reply capableweb 16 hours agoparentI&#x27;m not sure \"percentage of usage\" is a metric you can use to fully decide how \"useful\" something is. Take macros in Clojure for example, usually you just have a few of those, but the ones you have are really useful, they give a lot of functionality and practicality to the language. Maybe the same thing is happening with sync&#x2F;async generators? reply insanitybit 16 hours agorootparentMacros are a really good example. A world without the equivalent of `#[derive(Serialize, Deserialize)]` would suck, but it&#x27;s just a few characters and I almost never write macros personally. reply munificent 15 hours agorootparentprevThat&#x27;s a good observation about a lot of language features, yes. Macros are a particularly good example.But for a feature like generators which is, I think, essentially user-facing syntactic sugar, I do think a count of usages is a pretty good measure of usefulness.It&#x27;s probably also worth noting that my data here is from published packages, which tends to skew towards reusable libraries and away from application code. So, if anything, I would expect this to be an over-count of their use if they primarily made libraries&#x2F;frameworks useful on behalf of application developers. reply steveklabnik 15 hours agorootparent> I think, essentially user-facing syntactic sugar,One thing to remember is that Rust is a bit weird here; often times, features like this are \"sugar\" in a sense, but that sugar lets you write safe code, whereas the non-sugar version would force you to write unsafe. This means this kind of thing is a larger win in Rust than it would be in other languages. reply munificent 15 hours agorootparentYeah, that&#x27;s a good point. reply withoutboats3 16 hours agoparentprevA big difference between Rust and other languages like Dart is that our async&#x2F;await is based on the same sort of coroutine transform as generators would be, rather than continuations, so its a lot less additional complexity to add generators compared to another language that has both async&#x2F;await based on continuations and generators based on coroutines. reply vorticalbox 16 hours agoparentprevI&#x27;ve just used an async generator when upgrading to aws-sdk v3, the function lists all the items in a s3 bucket, if its truncated then it yeilds a recursive generator.Stops when it&#x27;s got all the keys.First time in 5 years writing typescript I&#x27;ve actually used a generator. reply no_wizard 15 hours agorootparentGenerators (either variety) in JavaScript are flawed in their implementation in that they only went halfway with it. They also needed to make all primitive objects iterable as well, and&#x2F;or they should have introduced iterable helpers for all data structures. The fact that you can&#x27;t use an object in a `for` loop without implementing Symbol method(s) is a glaring hole in their every day utility. It makes it non-obvious to reach for in many casesThe other to me is some of the semantics of generators are not well thought out, for instance, you have to call `.next()` _twice_ in order to get the first `yield` value, and how arguments to `.next()` should be used correctly is opaque. This combined with the fact `yield` doesn&#x27;t follow the same lexcial scope as `this` does (IE, you can&#x27;t have an arrow function yield if it was enclosed by a generator, unlike `this` which can be used inside an arrow function as reference to its enclosing scope. This would make generators far more useful IMO).Combine all this with the fact that most frameworks don&#x27;t support generators natively for things like components (but they are starting to accept Promises &#x2F; async functions) you end up with a relatively niche feature reply MajimasEyepatch 16 hours agorootparentprevGenerators are one of those things that pop up more often in library code than in application code, I&#x27;ve found. reply brabel 16 hours agoparentprevFor what it&#x27;s worth: thanks to Dart&#x27;s async&#x2F;await and async* and sync* , I find it incredibly easy to write performant, clean concurrent code in Dart. I&#x27;ve implemented an application (very IO heavy, highly concurrent) that is half Dart, half Java (for reasons) and the async code in Java is atrocious, while the Dart code is just beautiful. reply ryansouza 15 hours agoparentprevI do wish discussions like the linked blog were more clear on specific use cases features would enable. Async summation shows off the syntax sure, but I don’t know any real world problems that are currently hard that this would make easy. Not to say there aren’t, just I don’t know them and would love to understand! reply insanitybit 16 hours agoprevTBH I think that, for the most part, I will only benefit from a few of these - mostly in terms of sugar. I routinely have positive experiences with Async rust and basically never have negative experiences&#x2F; issues that crop up because of it. In 3 years of writing Rust full time I had one async problem one time - I accidentally was causing an infinite select! loop in a tonic server, so the server would hang. Not really a big deal for 3 years of async work. I could have done the same thing in sync code just as easily tbh.I also don’t think that async-drop as quite as necessary or desirable as it may seem. I really wanted it at one point and then I realized that it’s just too tricky. It reminds me of how File calls sync_all on drop but ignores the error - ultimately, “drop” is just a really tricky place for anything complex. I’d rather see a linear type, like: struct LinearFile { fn close(self) -> Result { self.sync_all(); File { inner: self.inner } } }Where Linear can’t be implicitly drop’d, you have to .close() it, get a File, and File can be dropped. Hand wavy and not necessarily a good implementation but hopefully this is getting the point across. This would be preferable to shoving more into a drop impl when drop is such a constrained interface.Or maybe add a try_drop(&mut self) that will run implicity but also ? implicity. I don’t know.I guess the point is that I’m not sure an async drop can ever be worth it.TBH I feel like ~30% of people&#x27;s complaints about async are solved by:a) Encouraging a sync + async API in librariesb) Adding `block_on` to the stdlib, which will help with (a)People mostly seem to care (and imo this is stupid but whatever) about using async in sync contexts when they don&#x27;t want to, and they don&#x27;t seem to know that you can just block. reply mplanchard 15 hours agoparentI wish that some of these folks complaining about how rust libraries force you to use async would go out and write some equivalent libraries with synchronous APIs. Rust&#x27;s philosophy has always been to let library authors explore a problem space before (if ever) pulling stuff into the stdlib, and I think it is generally only beneficial for the ecosystem to have multiple ways of solving a problem. reply insanitybit 15 hours agorootparentI think it goes to show that the vast majority of Rust devs don&#x27;t actually care about this problem, otherwise they&#x27;d be doing that already. Like, providing a sync API over an async API is almost always as simple as: struct SyncThing { async_version: AsyncThing } impl SyncThing { pub fn sync_api(&self) { block_on(self.async_version.sync_api) } }If this were really such a huge problem I think we&#x27;d see more PRs. I get that there&#x27;s some survivorship bias here, but still... reply ReactiveJelly 15 hours agoparentprevIs that the same as the \"Unforgetable types\" mentioned in the blog?I never thought about it but, my only problem with C&#x27;s manual destructors is that the compiler doesn&#x27;t check that you remember to call them. If we accept a language like Rust that does sophisticated static analysis, it doesn&#x27;t need to delete things for you, it only needs to be sure you have a plan to delete everything.That&#x27;s interesting. reply insanitybit 15 hours agorootparent> Is that the same as the \"Unforgetable types\" mentioned in the blog?Pretty much, yes.> I never thought about it but, my only problem with C&#x27;s manual destructors is that the compiler doesn&#x27;t check that you remember to call them.Right, so in this case the compiler would force you to consume the value somehow. This is \"linear\" typing. reply sargun 16 hours agoprevI was a huge opponent of Rust, but finally decided to give it a try in anger once again.I began writing a large application, and noticed that many of my libraries only offered async versions, and the promise was quite appealing -- not having to worry about threads or concurrency as long as I followed certain rules. What I ended up with was an incredibly slow application because of the limitations of Rust async, and the runtime. All of my I&#x2F;O got pushed through one thread (with tokio), and that, plus scheduling overhead became my bottleneck. Debugging this was a nightmare in writing my own tracing tools.20&#x2F;20 hindsight, I would not write my code to be async, and would just prefer threads. I&#x27;m really not sure how &#x2F; why async took off the way it did. reply ReactiveJelly 15 hours agoparent> All of my I&#x2F;O got pushed through one thread (with tokio)In all my use of Tokio in the last few years, I never heard of such a thing.In tokio::fs::File [1] it calls spawn_mandatory_blocking to do file writes, I assume this is similar to spawn_blocking [2] which sends a task to Tokio&#x27;s blocking thread pool. That thread pool is supposed to max out at 512 blocking threads [3], unrelated to CPU core count.Tokio&#x27;s TcpStream appears to be built on mio&#x27;s TcpStream. I didn&#x27;t dig deep into the code for this, but it doesn&#x27;t just call spawn_blocking, and I&#x27;m assuming on Unix it ultimately registers the socket with epoll or equivalent, so it never blocks a thread to do socket reads or writes.Could you share more about your application?[1] https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;src&#x2F;tokio&#x2F;fs&#x2F;file.rs.html#682[2] https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;task&#x2F;fn.spawn_blocking.ht...[3] https:&#x2F;&#x2F;docs.rs&#x2F;tokio&#x2F;latest&#x2F;tokio&#x2F;runtime&#x2F;struct.Builder.ht... reply sargun 6 hours agorootparentSo, it wasn&#x27;t actually synchonrizing all of the I&#x2F;Os onto one thread, but I wasn&#x27;t getting any parallelism due to the amount of time required to dispatch I&#x2F;Os. Essentially, my program was highly concurrent, but I wasn&#x27;t able to get any I&#x2F;O parallelism because each syscall was pretty cheap, and the cost of dispatching each I&#x2F;O was too expensive. reply gnulinux 16 hours agoparentprevIn these debates I find myself very confused. I feel very comfortable with async ergonomics in Rust. It seems like the argument against it is that it has poor ergonomic... but how? It&#x27;s rather straightforward to go from sync to async and async to sync you just have to code the strategy in. If you&#x27;re in sync and need to run async, you need to run it in some executor (either in threads or in single-thread concurrency or something else). I&#x27;ve been writing async code in Python for years I&#x27;m truly missing what&#x27;s so bad -- or even different -- about Rust async. What am I missing? I&#x27;ll continue to write async code because it&#x27;s pretty nice.EDIT: People talk about swapping executors etc but it seems like 99.999% of the programming applications you don&#x27;t need anything like this, nor does something like Python supports this anyway and we&#x27;re all fine with it. reply mplanchard 16 hours agorootparentJust noting for the sake of countering this narrative that async rust is fundamentally broken that I feel the same way as you, having been working with async rust professionally for 2.5 years. reply rstuart4133 13 hours agorootparentprev> It seems like the argument against it is that it has poor ergonomic... but how?It depends on what you&#x27;re comparing it against. If you are comparing Rust async against other languages, then the major difference is Rusts borrow checker. In every implementation of async, you effectively move whatever state is needed off the stack and into a separately allocated memory area. In Rust that separate area is a closure.This interacts badly with Rusts borrow checker. The borrow checker needs to know the lifetime of any object you deal with. It has two \"base truths\", by which I mean life times it already knows about that you can derive other life times from: static and the stack. If they don&#x27;t suffice you have to handle life time management yourself and at run time using Rc or Arc or something. Being forced to do that complicates your types and slows the code down. The root cause is async in Rust removes one of those two base truths: the stack. So now you are forced to write that ugly manual life time management code far more often.This is unique to Rust. Every other language I know of that implements async has garbage collection, so while it remains true they also move stuff off the stack it doesn&#x27;t change anything. You still use the same types, and apart from sprinkling async&#x27;s and await&#x27;s here and there and indenting your closures, your code remains the same.This is also why I think green threads are a much better fit for Rust than async. Under the hood green threads and async are very similar: they are both ways of doing event driven I&#x2F;O. Their performance characteristics are near identical. The main difference is while async forces you to move your state to a different area, green threads you do it as before and store it on the stack, just like normal code. In fact green thread code looks identical to normal code. The only change you have to make to convert some code to green threads is change the name of the I&#x2F;O calls to use non-blocking versions (which is something you also have to do with async, of course). But since the stack is still available all those fights with the borrow checker async creates go away, as does all the extra syntax async requires.It doesn&#x27;t come for free of course, so the run time performance of green threads and async is not absolutely identical. In async every task shares the one stack, whereas in green threads they each get a new one. This creates some extra memory overhead, chews up considerable address space (which normally isn&#x27;t backed by memory) in order to protect against stack overflow, and it costs a bit more to set up a stack. But once a task is setup green threads are going to be bit faster you aren&#x27;t moving stuff and and off the stack and you don&#x27;t get hit with those additional run time life time checks you were forced to introduce for async. Mitigating green threads overheads somewhat, a process that is handling 1000&#x27;s of concurrently connections is unlikely to be running one a machine that is memory constrained, so the extra memory probably doesn&#x27;t matter. (In reality a Raspberry Pi with 4GB of memory can handle 1000&#x27;s of stacks.) And it&#x27;s likely to be a 64 bit machine where address space is nearly free, so the \"considerable extra address\" space also doesn&#x27;t matter.Still, I can think of once place it does matter. You can have two styles of generators: ones take the async approach and ones that take the green thread approach (ie, allocate an extra stack to each generator). Rust nightly does have generators and they currently take the green thread approach(!). But, generators tend to be short lived. You tend to use them to iterate over an array, rather than serving a web request (the typical use a task is put to). That means the overhead of creating the stack for a green thread isn&#x27;t a small proportion of the time a long running task takes, but could well dominate the time it takes to iterate over a small array. Thus async is a much better fit for iterators.Currently Rust has this arse about: it has async for long running tasks, and green threads for generators in nightly. With this announcement it looks like this will be 1&#x2F;2 fixed. Great! reply wahern 9 hours agorootparent> But, generators tend to be short lived. You tend to use them to iterate over an array, rather than serving a web request (the typical use a task is put to). That means the overhead of creating the stack for a green thread isn&#x27;t a small proportion of the time a long running task takes, but could well dominate the time it takes to iterate over a small array. Thus async is a much better fit for iterators.The current async approach requires the compiler to statically calculate a fixed size for each invocation context. Except when it can&#x27;t, in which case you have to dynamically allocate space for each invocation. That same logic could be used to transparently optimize stack creation, opportunistically avoiding both a pessimistically large stack and the costly guard pages. The compiler could even choose to instantiate the generator stack on the caller&#x27;s stack, just as today.async Rust optimizes the common case but completely neglects the hard case. In theory Rust users should be able to have their cake and eat it too, especially given that the difficult static analysis work already exists to support the current async model.(I&#x27;ve made this point before and feel like I may have forgotten some counterpoints. I apologize in advance if that&#x27;s so.) reply steveklabnik 12 hours agorootparentprevWithout commenting on the rest of this post:> Every other language I know of that implements async has garbage collection,Small note: C++ also has it these days, and does not have GC. You are (as far as I know) left to your own with object lifetimes, as with non-async&#x2F;await. reply mplanchard 10 hours agorootparentprevRust had green threads prior to 1.0, and they were ripped out for performance and other reasons. Probably worth revisiting those discussions to see where this has been thought through by the Rust team reply rstuart4133 9 hours agorootparent> Probably worth revisiting those discussions to see where this has been thought through by the Rust teamThe issue generated a lot of hot air at the time, far more than I have time to read, but I think I have the gist of it.The performance issues were due to an implementation choice. All green thread implementations I&#x27;m aware of hide the code colouring event driven I&#x2F;O introduces, and Rust did the same. The hiding has to be done at run time. That translates to every I&#x2F;O call has at some point chose the blocking or non-blocking implementation. This is typically done using vtables (dyn in Rust), but whatever mechanism is used, it introduces runtime overhead. Worse, it slows down everything - including code that doesn&#x27;t use green threads. It gets radically worse if you try to hide C calls blocking.Async has the same issue, some solves it by making coloured code the programmers problem. If they had of made the same design decision for green threads the performance issues go away. We don&#x27;t have to speculate about that. There is a green thread crate out there called \"may\", then has independent benchmarks covering it, async Rust implementations, and other languages. \"may\" beat everything at one point, but it&#x27;s a very noisy benchmark so the only conclusion I would draw from it is that \"may\" looks to run at the same speed as async.As for the rest of the issues: they revolve around needing a separate stack. I tried to cover the trade-offs above. Summarising: green threads lead to simpler code that&#x27;s easier to write and theoretically could run faster than async, but have larger setup overhead and use more memory. reply mplanchard 9 hours agorootparentThat’s part of it, but it is also important that rust be an embeddable language. Ideally you should be able to replace a small component of a larger C or C++ program with Rust. Having a big fat runtime you’ve got to include before running any rust code makes that pretty much a non-starter. reply rstuart4133 7 hours agorootparent> Having a big fat runtime you’ve got to include before running any rust code makes that pretty much a non-starter.Just reasoning aloud here. That looks to be another similarity with green threads and async. Async also requires a big fat runtime that isn&#x27;t part of the language. Instead you have to pick an async colour - such as tokio. That&#x27;s pretty much what happens with green threads now. You have to pick a runtime such as the \"may\" crate, which forces the programmer to choose yet another colour.So many colours, yet they are all just event loops underneath. Colours cause fragmentation, fragmentation is the mortal enemy of reuse.It seems like the very least the language could do is provide a set of trait&#x27;s for event driven I&#x2F;O that mirror the existing I&#x2F;O library in std. Then the library writers wouldn&#x27;t have to colour their code by using a particular event loop implementation. I suspect it&#x27;s easy enough for green threads or async, but accommodating both styles of event loop would be hard. replyandrewstuart 16 hours agoparentprevIn the words of Steve Jobs, “you’re holding it wrong”.I’m guessing your code is blocking. You absolutely cannot do blocking code in async in any language, unless the blocking is super quick. No blocking io.async code should yield great performance if you are doing everything the right way. Yes it is single threaded but either run multiple threads in rust or run multiple instances of your program with systemd.That applies same to rust, Python, javascript, any async language.I wrote a prototype message queue in Rust with Actix and got 7 million messages per second via http. reply bad_user 16 hours agorootparentJava, C#, probably Go and others, are able to do async I&#x2F;O on multiple threads. It doesn&#x27;t help with the actual async I&#x2F;O being performed, but it does help with parallelising CPU work, or with the fact that not all I&#x2F;O can be async and the runtime is faking it, such as local file I&#x2F;O, which is going to be blocking system threads.Async I&#x2F;O is all about multiplexing work on few CPU cores efficiently, and multi-threading is still required. Python or JavaScript are seriously limiting environments and should not be given as an example when we&#x27;re talking about a language that does 1:1 scheduling. reply mplanchard 16 hours agorootparentTokio&#x27;s default scheduler is multi-threaded, and Rust does this very well. You just have to be explicit when you want to run some non-async blocking code in a way that won&#x27;t block a thread. reply andrewstuart 16 hours agorootparentprevI don’t really get your point.You cannot, (should not), do blocking IO in async in any language.The language provides libraries to do non blocking IO.What is unclear about that?Multi threading has nothing to do with async, except as a way to run certain things in an executor thread to avoid blocking.Also I don’t really know what you mean by async IO…. even in the languages you reference I would guess IO operations are all run in a single thread. reply bad_user 15 hours agorootparent> You cannot, (should not), do blocking IO in async in any language.On platforms with 1:1 scheduling, of course you can. Blocking I&#x2F;O executed on another thread, with a callback to execute when done, becomes async I&#x2F;O (from the user&#x27;s PoV).Ofc, when we talk about async I&#x2F;O, we also refer to the kernel APIs being used, such as select&#x2F;poll&#x2F;epoll&#x2F;io_uring. Say, working with Epoll is usually done via a single-threaded \"event loop\", but that only listens for the operations possible for an open file&#x2F;socket. The read&#x2F;write operations are still potentially blocking, so for efficiency you need multiple threads. The dirty secret is that async I&#x2F;O, as implemented by Linux, isn&#x27;t actually fully async. reply BatmanAoD 13 hours agorootparentThat&#x27;s...not...how threads or async work...?> Blocking I&#x2F;O executed on another thread, with a callback to execute when done, becomes async I&#x2F;O (from the user&#x27;s PoV).That&#x27;s not what we&#x27;re talking about when we discuss languages with async I&#x2F;O, though. That&#x27;s just bog-standard synchronous I&#x2F;O with multithreading.> The read&#x2F;write operations are still potentially blocking, so for efficiency you need multiple threads.That doesn&#x27;t actually follow. The entire point of language-level async I&#x2F;O is to be able to continue doing other work while waiting for the kernel to finish an I&#x2F;O operation, without spawning a new OS thread just for this purpose. reply sargun 6 hours agorootparentprevRight, I think async is bad. We have threads, and operating system level isolation with processes. For the most part, these primitives work fine.My code wasn&#x27;t blocking, but it did a very small amount of computation, locked on what was typically a highly contended (async) lock, and then dispatched a bunch of blocking I&#x2F;O operations. Each of these turned into a context switch under the hood.There were parts of my code that were computer intensive, but determining that without being able to use my normal tools was a pain, and I had to come up with heuristics of whether or not to dispatch with spawn_blocking, since the call had significant overhead.An abstraction that was meant to simplify program resulted in me spending a lot more time staring at it.I think one difference with Python is that the async implementation doesn&#x27;t try to hide or abstract I&#x2F;O away from you. If you&#x27;re doing I&#x2F;O, you know you&#x27;re going to block, and thus you&#x27;re forced to acknowledge it by spawning it on another thread. reply nextaccountic 16 hours agoparentprevWhy didn&#x27;t you use the multithreaded executor from Tokio? reply tuetuopay 16 hours agorootparentTokio does sync I&#x2F;O in the background with dedicated I&#x2F;O threads if memory serves. (it is sync in the sense it does syscalls, which are pushed to a dedicated thread). reply ReactiveJelly 15 hours agorootparentEven then I&#x27;m pretty sure it&#x27;s not _a_ dedicated thread, but a thread pool that defaults to a maximum of 512 blocking threads. There&#x27;s no reason it would bottleneck unrelated writes on unrelated Files through the same thread. I tried to dig into the code here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38180860 reply 0x457 15 hours agorootparentprevTokio has a thread pool for blocking operations. It&#x27;s not automatic, though, you have to explicitly use it.I don&#x27;t understand why some people think async is difficult to write. It&#x27;s difficult if language doesn&#x27;t have good support for it, but rust does. I remember async ruby was pretty weird to write initially. reply dymk 16 hours agorootparentprevDepends on the type of I&#x2F;O (network, file, etc), and the async abstractions that the target operating system supplies. reply littlestymaar 16 hours agorootparentprevOnly for file access, which wasn&#x27;t supported by async on Linux until io-uring. reply insanitybit 16 hours agoparentprevIO shouldn&#x27;t be going to one thread, as far as I know. Blocking IO would go to a threadpool.But you can just `block_on` your futures if you want and not think about it at all. reply cmollis 16 hours agorootparent+1 reply jackhalford 16 hours agoparentprevasync took off when multicore processors came out and C had no first class way of running in parallel, so we bolted on threading libraries that are second class. Take a look at zig’s approach to concurrency, it’s so first class you can write your own event loop without an OS, i.e you could use the language’s async to write an OS. reply Sharlin 14 hours agorootparentAsync doesn’t really have much to do with multicore. Indeed the most used async environment on the planet (JavaScript) is (used to be) strictly single-threaded. Async is all about keeping the CPU busy even though the stuff it does involves latencies thousands or millions of times longer than CPU timescales – and about abstractions that allow you to pretend you’re writing normal synchronous code when the reality is anything but. This mostly just involves chopping up the code and turning it into a state machine.Async is almost useless when you’re not incredibly I&#x2F;O bound. But many people these days are because the web ate the world.C did and does have a poor almost-anything story but it doesn’t and didn’t really matter because C hasn’t been relevant on the web since 1995 or so. reply jackhalford 1 hour agorootparent> async doesn’t have much to do with mumticoreIt does, once you have async you can multiplex n coroutines on m cpu cores, meaning you can throw libthread out of the window.> C hasn’t been relevant on the web since 1995Do you know nginx, a core web technology is written in C? Linux is also C. Don’t forget that at the end ov every web request are syscalls and hardware. reply jcranmer 14 hours agorootparentprev> Async is almost useless when you’re not incredibly I&#x2F;O bound.I&#x27;m not sure that&#x27;s true. The async&#x2F;await model is about representing a state machine in imperative code. Not all state machines can be written imperatively, but when they can be, it is often clearer than writing the state machine manually. I&#x2F;O is the most common scenario for such state machines, but I can see a few other OS scenarios where you might want to use async&#x2F;await instead (e.g., process management is probably better represented with async&#x2F;await). reply pornel 9 hours agoparentprevCloudflare pipes a large fraction of the Web through tokio. The runtime has a very low overhead, and can scale to over a hundred cores. reply sapiogram 16 hours agoparentprevCould you be more specific about your bottlenecks? Were you not able use the multithreaded scheduler for some reason, or did it not work properly? reply jokethrowaway 16 hours agoparentprevThat doesn&#x27;t sound right. In which way was your application slow? Conceptually, async is not necessarily giving you parallelism but concurrency. Tokio (multithreaded) or async-std spawn N threads though and schedule your work for you.It would be interesting to see the code or know which libraries you used (or even just what type of application you were building).I built a heavy app using async-std and then rewrote it to threads just to better control what was each thread doing. Without my additional scheduling rules (which brought a lot of other benefits and helped performance in other ways), the performance between async and not async was close, with threads being marginally faster. reply speed_spread 12 hours agoparentprevRust Async has very real constraints but it&#x27;s definitely _not_ supposed to make your app slow. Most will agree that it is often best avoided unless demonstrated to be required by performance requirements. IMO this advice also applies to other lang&#x27;s async, but even moreso in Rust. The complexity is real. reply lucasyvas 16 hours agoprevI think std needs a default runtime, and we might as well make it tokio, but maybe make the single-threaded executor the default instead and tweak the API where appropriate to align with this change.Swapping the executors out should absolutely be a feature, and the traits should be portable, but a way to start fixing the situation beyond the great suggestions in this proposal is to acknowledge that std and no-std users are different, and std users are often developing applications and prefer sane defaults. reply steveklabnik 16 hours agoparent> I think std needs a default runtime, and we might as well make it tokioRegardless of the quality of this idea, it isn&#x27;t going to happen: neither the Rust Project nor Tokio (in my understanding, to be clear I am not involved in either) want this to happen.> Swapping the executors out should absolutely be a feature, and the traits should be portableI am not fully aware of all of the details here but there are significant problems when it comes to actually getting this done; I don&#x27;t think anyone is ideologically opposed, but there&#x27;s a lot of practical considerations that make this difficult, in my understanding. reply alilleybrinker 16 hours agorootparentTo pick out one example of what makes it challenging: not all executors place the same type system constraints on tasks they execute. Tokio, for example, is a work-stealing executor which requires tasks to implement the `Send` trait so they can be sent between threads, while other executors may never move tasks between threads and therefore don&#x27;t require the `Send` bound. reply lucasyvas 16 hours agorootparentYes, this is a major difference. But at this point, let&#x27;s be honest - why has most stuff converged on Tokio? IMO it&#x27;s not for reasons wholly of merit - it additionally won a popularity contest as one of the first movers. Why the popularity contest? Because people want an async executor, but they just want it to work. These people largely don&#x27;t care about the benefits between different executors.I think they&#x27;d like the choice to use a different one, but they&#x27;d rather just having something available with async traits that trend toward opinionated. The executor issue is a huge problem, because the ideology of \"zero opinion\" on executor coupled with \"ease of adoption\" are completely at odds. I don&#x27;t think the current trajectory will ever resolve nicely. reply pornel 9 hours agorootparentThere’s definitely a network effect that makes everyone converge on tokio.However, I don’t think the situation can be improved by putting an executor in std. That will even more strongly make everyone stick to the standard one.The problem isn’t that it’s hard to pick an executor (you can pick tokio without thinking). The problem is that when someone has a legit reason to use a different executor, it’s hard to avoid dependencies using tokio, and it would be even harder to avoid dependencies using a built-in executor. reply mplanchard 16 hours agorootparentprevWe experimented with both tokio and async-std and picked tokio on the merits. This was ~2 years ago, so things may have changed a bit, but tokio provided a lot more out-of-the-box, and we also wanted a multi-threaded executor so its defaults worked well for us. reply cmrdporcupine 14 hours agorootparentprevI actually think we have a cultural problem due to the fact that many of the people coming into Rust recently are coming from a \"full-stack\" webdev background, where \"frameworks\" are huge, and feels like nobody worries about being coupled to one framework or another, just picking the right one. Which is in large part due to the history of JavaScript and so on. This is an influx of people who sense that tokio is the \"right\" way to do things -- tutorials, blog posts, example applications, and 3rd party libs all start with tokio... and they&#x27;re not philosophically against being tied to it.Whereas my own sense of the Rust philosophy is supposed to be one of zero-cost abstractions (when possible), and for the language to provide nuts and bolts that I can assemble myself. My interest is in systems eng. I don&#x27;t want to be tied specifically into the systems-eng choices that Tokio happens to have already made, even if they might be good ones. I want the ability to choose. It&#x27;s not healthy, in my opinion, for one entity to dominate choices like this.If this can&#x27;t be resolved, my sense is that people who have the same impulses as me will choose to either not use async at all, or move on from Rust. reply lucasyvas 13 hours agorootparentI agree with you 100%, but members of the Rust project have stated in the past that async, in not insignificant ways, is a play to deliberately target the higher level web&#x2F;service based crowd. So, the cultural issue is partially self-inflicted.I&#x27;m not even sure what I want in Rust. All I know is that people have a legitimate gripe being sold on Rust async for high level work, having it ergonomically fall much flatter than it should. It&#x27;s very hard to satisfy everyone, which they are learning day by day.I do wish for the async story to mature a bit more so the implementors have a chance to show the community how good it can be. But the project needs to consider its messaging to the users it has courted over. reply steveklabnik 12 hours agorootparent> the higher level web&#x2F;service based crowd.Not everyone that writes network services is \"higher level\" or \"web\". reply cmrdporcupine 12 hours agorootparentThat is entirely fair. But back to the topic -- some of us building network services etc would like options, and not to be tied to a specific async runtime. E.g. I was looking at what it would take to move my code over to monoio. Or anything else. Not going to happen, because too many 3rd party deps mandate tokio.That&#x27;s not a good situ. I&#x27;d as soon rip out async, and optimize the concurrent multithreaded situation myself than be tied down that way.FWIW my day job is on embedded Linux, small systems that sit in tractors. We don&#x27;t do async Rust. It&#x27;s all actor-style communicating components. And it works pretty much fine. reply steveklabnik 12 hours agorootparentI hear you, options would be nice for sure. We&#x27;ll see if making things more generic is in the cards or not, I guess. replybryanlarsen 16 hours agoparentprevI believe that without.boats (or somebody of similar prominence) proposed that pollster (https:&#x2F;&#x2F;docs.rs&#x2F;pollster&#x2F;latest&#x2F;pollster&#x2F;) or a similar async executor be pulled into std.I think it&#x27;s a great idea. By blessing something that&#x27;s not tokio you give a good incentive for library authors to test against more than one executor. And by being so far from fully featured pollster is never going to \"win\" so blessing it doesn&#x27;t appoint a winner. And it gives an obvious solution for what people who don&#x27;t want to use async in their code but do want to pull in an async library should do.edit: it was without.boats in this post: https:&#x2F;&#x2F;without.boats&#x2F;blog&#x2F;why-async-rust&#x2F; reply tuetuopay 16 hours agoparentprevI would not think it would be that good. Having multiple runtimes is great for specific use cases. I would also fear that having \"one standard endorsed runtime\" would lead to either the death of the alternative ones, or to the freeze of it once it&#x27;s in the stdlib and fall to oblivion (like many packages in the python standard library).What the stdlib actually needs is the proper set of traits&#x2F;facades&#x2F;whatever to interact with the current runtime. Just like they did with the Future trait. And add the handful of traits that go with them that tokio, futures, smol, etc have: AsyncRead, AsyncWrite, Stream, Sink, et al reply jcranmer 15 hours agorootparentThere&#x27;s two sets of missing things here.The first is interfaces to represent async versions of existing core sync traits (that&#x27;s the AsyncRead&#x2F;AsyncWrite&#x2F;Stream&#x2F;Sink&#x2F;etc. you refer to). What makes this somewhat awkward is you&#x27;re providing these traits without an implementation of them in the standard lib.The other thing that&#x27;s missing is something like GlobalAlloc. You need a generic executor runtime interface to handle some of the executor things you need like \"schedule new task\".In general, I think there&#x27;s a class of features where you need to have just one global (really, process-wide, not just library-wide) provider of some service, and it may be worth having language features to provide this functionality. Memory allocation is one specific area; async executors is another topical area. But you can also throw in stuff like signal handlers or logging or service providers or error handling or tracing features, etc. reply mplanchard 15 hours agorootparentprevAgree on both points. While I don&#x27;t find async rust hard to use as a library consumer, trying to write a runtime-agnostic library is (IMO) more difficult than it needs to be. I would like to see most of `futures` either be incorporated into the stdlib or used more consistently throughout the various runtimes. reply cmrdporcupine 15 hours agorootparentI think we&#x27;d need, at least, runtime agnostic locks, channels, and a &#x27;spawn&#x27; function (trickier). And ideally some I&#x2F;O primitives somehow not tied to the runtime? reply cmrdporcupine 15 hours agorootparentprevIn reality there aren&#x27;t multiple runtimes in a real, pluggable, generic sense. There&#x27;s tokio and then some niche things that are hard to build on top of because they&#x27;re not tokio (despite being possibly technically superior in some way).Every async-focused dependency that is relevant effectively mandates Tokio. And I&#x27;ve been ridiculed in public and private forums for suggesting that there should be a way to write libraries generically so that they don&#x27;t have a runtime dependency. (Right now, services as basic as locking and task spawning are coupled to tokio, at least, and people use them all over.). Major new things are being made, all coupled to tokio.And I think this is a shitty situation for a whole bunch of reasons. And others (looks like you, too) agree, but it feels like there&#x27;s just no way this is going to get fixed.Like, this article here, it doesn&#x27;t even mention this as a concern? In the context of a big picture discussion of async over the next 4 years.So I don&#x27;t foresee any progress on this front, and it makes me want to just rip async out of my code entirely. reply lambdaone 16 hours agoprevWhat makes Rust great is that its design drew upon decades of understanding of programming language theory and practice, and the designers took bold decisions based on that understanding to avoid the mistakes of other programming languages.The problem with async Rust is that the async idiom is new, and its interactions with the rest of the software ecosystem not particularly well understood. This makes async support glaringly different from the rest of the language.I&#x27;m glad the designers seem to be taking a step back and reconsidering how everything fits together. reply Rusky 9 hours agoparent> I&#x27;m glad the designers seem to be taking a step back and reconsidering how everything fits together.This is simply not what is happening here. The post is clear that this is about filling out and finishing up the plans that were laid down when async was initially designed, not changing how things fit together. reply pornel 9 hours agoparentprevAsync isn’t new in programming language theory. It’s a syntax sugar for state machines and continuations. I think it could be argued that PLT was already way ahead of async&#x2F;await – monads are more general than futures, and Rust’s async wasn’t generalized to be an effect system.Also it’s simply not true that async wasn’t fully understood or carefully evaluated. It took years to design, and then bikeshed every detail, to the point people involved were burned out. It had multiple prototypes, and an early callback-based implementation used by hundreds of libraries, in production, for over a year. It’s probably the most thoroughly designed and tested feature in Rust’s history. reply vlovich123 17 hours agoprevAdding Move and deprecating pin&#x2F;unpin would be a huge ergonomic improvement I think. I also think the Rust project should consider “out-of-band” editions if they can deliver big features like that sooner rather than waiting until 2027. reply alilleybrinker 16 hours agoparentNote that in general, the Rust project has chosen a time-based, not feature-based, release model. New Rust versions come out every 6 weeks, and new Rust editions have a consistent cadence of every 3 years. There are advantages and disadvantages to debate between time-based and feature-based release models, but Rust pretty clearly has chosen their preference. reply zozbot234 16 hours agorootparentThen they&#x27;ll just add a new #[from future import Move] syntax. reply pornel 9 hours agorootparentprevThe important aspect of the 6-week releases is that they’re frequent, so nobody feels a need to rush a feature to cram into the next big release.Editions happening every 3 years unfortunately undo this, and there is a pressure to land changes before the upcoming edition. reply mplanchard 15 hours agoparentprevI agree that Pin is super confusing, and a Move trait would be much better. I&#x27;m willing to wait though :) reply qaq 16 hours agoprevI kindah lost track what is the current status of async in traits ? Still relies on the macro? reply withoutboats3 16 hours agoparentThe feature is shipping before the end of the year. reply andrewstuart 17 hours agoprevI thought async and await were kind of logical builds on top of generators but this is saying rust has no generators.That’s how it works in javascript and as a commenter mentions in Python too, right? reply Sprocklem 17 hours agoparentThey are in some languages, but Rust instead implemented them with a pollable Future trait. The async keyword, then, causes the block to desugar into a new type that implements Future. In order to emulate a coroutine, the generated poll function includes a state machine that tracks the await point where the function was suspended. reply __s 17 hours agoparentprevThey&#x27;re intertwined, but generators have yet to stabilize https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;beta&#x2F;unstable-book&#x2F;language-featur... reply kmeisthax 16 hours agoparentprevIt&#x27;s also how it works in Rust. Stable Rust isn&#x27;t allowed to use generators, but the code that desugars `async fn` is, because it&#x27;s part of the compiler. reply potatochup 17 hours agoparentprevThat&#x27;s true for implementations like python async, but rust operates a bit differently (mostly to avoid allocations across await points). The author of this article has some other very good posts about it. reply bobbylarrybobby 17 hours agoparentprevThey are logical builds on top of coroutines, as are generators. There is a generator initiative in the works, but it does seem odd that async exists and generators don’t given that the “pausable state machine” nature of them is so similar. reply infogulch 16 hours agoprevHey boats, I found this sentence confusing to read (emphasis mine); an editing mishap perhaps?> On the other hand, there was some speculation about making “await patterns” that destructure futures and then somehow making that work here; I think this would imprudent and leaving await as an expression, and for await as a special expression for handling AsyncIterator, is the most sensible choice. reply explodingwaffle 16 hours agoprevTangential to some comments here: Why does the standard library not have block_on? reply steveklabnik 16 hours agoparentAs far as I know, the proposal to add one was determined to need an RFC: https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rust&#x2F;pull&#x2F;65875 reply devit 16 hours agorootparentAnother instance of a trivial and obvious feature that can only really be designed one way that is not implemented 4 years after initial proposal. reply steveklabnik 15 hours agorootparentI am not fully sure I agree with the first part of your assessment, but I share the frustration that a feature like this, which would be useful and is not particularly large, is basically ignored by the working group, while larger, more controversial, and less useful features, like keyword generics, are pursued while the more useful things languish. reply ironhaven 14 hours agoparentprevblock_on is a executor that polls a future until it returns ready. If the future is not ready then the executor wait until it is woken up. If you poll a future that relies on a specific runtime (I.g. A async library that uses Tokio) to wake up the executor, with a simple block_on you will get stuck.A generic block_on in std would be a footgun for new programmers I believe. reply bryanlarsen 12 hours agorootparentThe proposals to add block_on generally include an executor like pollster. reply gaganyaan 12 hours agoprevHas there been any progress with the effects system WG? That seems quite relevant to the proposed \"async gen\" syntax. reply laerus 14 hours agoprevWhy yield is not a suffix operator like await? reply Georgelemental 14 hours agoparent`.await` being postfix makes it easy to chain with further method calls (eg `foo().await.bar().await`). `yield expr` returns `()`, so there is no use in chaining it. reply laerus 13 hours agorootparentThanks for the explanation. I was thinking of Python&#x27;s yield were it evaluates to what is .send() back in the generator. reply inamberclad 17 hours agoprevAsync is a huge wart and I try and avoid it wherever possible. It&#x27;s simply not useful in a lot of cases that I encounter. However, if a library uses async, you have little choice but to make your whole project async. This adds to its horrible reputation. reply lucasyvas 17 hours agoparentThis is consistent with the author&#x27;s assessment - the incomplete implementation of async makes it very challenging to advocate for, despite the fact that it was the only logical choice given Rust&#x27;s design goals.I will say that the notion that you must make your whole project async is largely true (except that you can block on futures with all runtimes), but this is more symptomatic of the fact that Rust has hitched its horse to two wagons that don&#x27;t have clean overlap. It is effectively two languages trying to converge in the middle.It&#x27;s equally desired at \"web server and above\" and \"operating system and below\", which probably makes it one of the hardest languages on the planet to design (lets not forget it deliberately has no runtime, which makes things even more difficult). Whether or not this is a good idea remains to be seen over time, but they are in largely uncharted territory so I&#x27;m prepared to give them some slack on it while they figure it out.That said, holy has it taken such a long time to round out the async story to make it feel better. I don&#x27;t blame users not wanting to wait it out because it has felt like an eternity. reply Verdex 16 hours agorootparent> It&#x27;s equally desired at \"web server and above\" and \"operating system and below\", which probably makes it one of the hardest languages on the planet to design.My theory as to why C++ has become as a problematic language as it has is because it is able to do it all. And \"all\" doesn&#x27;t fit nicely into a single package or paradigm.I don&#x27;t like async (in any language), so your post immediately piqued my interest. I&#x27;m not that interested in &#x27;webserver and above&#x27; so of course that would be where people find async useful.It is possible that there is no way to unify these two domains into a single language (at least without becoming c++). Although, then again, it might be that if you think about it long enough then the unification mechanism becomes apparent. reply samus 16 hours agorootparentThe problem with C++ is that every feature- attempts to solve too many problems,- has significant papercuts that have to be considered,- has significant runtime cost,- interacts poorly with other features, or at least leaves significant edge cases open,- has non-uniform compiler support (although in OSS land only GCC and LLVM matter), and- creates arcane error messages that are anything but fun to analyze. Especially when templates are involved.Above everything the fundamental problem that the unsafe parts of C are everywhere, and to master C++ you have to become really proficient at diagnosing problems with them because you will run into them. Only then can you start thinking about fun things like software architecture. Always use a linter&#x2F;static analyzer. reply Kranar 15 hours agorootparentDon&#x27;t forget that C++ features are also often rolled out before anyone even really understands them, and then after they are rolled out people find all kinds of footguns and issues with them.The C++ committee basically evaluates features almost entirely in the abstract, writing papers and discussing privately among a small group of people about things instead of working on proof of concept implementations, getting actual real world feedback on it, or having something along the lines of Rust&#x27;s nightly where experimental features can be tried out. reply jcranmer 15 hours agorootparent> The C++ committee basically evaluates features almost entirely in the abstract, writing papers and discussing privately among a small group of people about things instead of working on proof of concept implementations, getting actual real world feedback on it, or having something along the lines of Rust&#x27;s nightly where experimental features can be tried out.Sitting on the C++ committee, we actually demand a lot of proof-of-concept implementation of proposals before they&#x27;ll be accepted. reply kroltan 16 hours agorootparentprevThat list of bullet points (except the compiler one) is also applicable to the whole async ecosystem in Rust :) reply mplanchard 15 hours agorootparentAgree on papercuts and interaction with other features to some degree. Absolutely disagree on runtime cost. The design of async has as minimal a runtime cost as seems theoretically possible, and avoids a lot of the runtime cost of async in other languages. It&#x27;s really an impressive engineering feat given the constraints and I think there&#x27;s a real case for it being a \"zero-cost\" abstraction (i.e. you couldn&#x27;t implement a faster version by hand).IME the bad compiler messages tend to come more often from the `async-trait` macro than from anything fundamental to asyc itself. Hoping the stabilization of async-trait helps with that. Backtraces with async are definitely a bit nasty though. reply samus 16 hours agorootparentprevI for sure hope that Rust gets at least the safety aspect right :) I could endure a lot of suffering if I knew that concern to be taken care of. reply munificent 16 hours agorootparentprevAgreed. The classic claim about C++ is that everyone wants to remove half of its features, but no one can agree on which half. reply zozbot234 16 hours agorootparentprevC++ is problematic in that it&#x27;s a memory-unsafe language with a lot of cruft dating back to the 1980s. Its generality has made it more not less successful, since that makes it a lot easier to reuse library and support code across domains. reply kllrnohj 15 hours agorootparentprevI think async is still in the more just trendy camp than being a proven asset. After all, thread per connection is perfectly viable for the vast majority of servers. Most people aren&#x27;t re-writing NGINX, after all (hopefully...).It&#x27;s a shame Rust let itself be distracted by it instead of focusing on refining its strengths and developer experience reply riku_iki 9 hours agorootparent> Most people aren&#x27;t re-writing NGINX, after all (hopefully...).those people probably may use another language (java, go, c#) if absolute performance is not critical for them. reply dymk 17 hours agoparentprev> However, if a library uses async, you have little choice but to make your whole project async.This isn&#x27;t true. I&#x27;m writing an application right now that is mostly sync, but has a small amount of async code in it. It&#x27;s easy to spin up a tokio runtime which can run inline on the current thread. Then use it to evaluate a Future. tokio::runtime::Builder::new_current_thread().enable_all().build().unwrap().block_on(async { println!(\"I&#x27;m async!\"); }); reply killercup 17 hours agorootparentBecause this code block looks quite complex, I want to add that it can also be just smol::block_on(async { println!(\"I&#x27;m async!\"); });(I thought tokio had a helper like this too but could only find `tokio::runtime::Runtime::new().unwrap().block_on(async { println!(\"I&#x27;m async!\"); });`.) reply cedws 16 hours agorootparentNeeding a helper library for something as simple as async so you don&#x27;t go mental is really not good enough. I see the same thing with error handling - every Rust project I see imports a helper because it&#x27;s too clunky otherwise. reply mplanchard 16 hours agorootparentIf you don&#x27;t want to pull in a helper library to run async code in a sync context, then why pull in an async library at all?Rust is not a batteries-included language like Python. There are lots of libraries that are very commonly used in most projects (serde, thiserror, and itertools are in almost all of mine), but this is a conscious choice. They say in Python that the stdlib is where projects go to die. I&#x27;d rather have the flexiblity of choosing my dependencies, even for stuff I have to use in every project. reply Elinvynia 15 hours agorootparentThe problem is that a large number of popular libraries has converted to async, 95+% of them to Tokio.So you are stuck with smaller, less battle tested products if you&#x27;d rather not pull in 100+ crates of dependencies that are doing nothing but inflating the build times and file sizes (for your particular usecase).Example: reqwest vs ureq reply insanitybit 15 hours agorootparentOK, but like, can we just be honest then that the problem here is that your build times go up? People act like it&#x27;s an insurmountable problem rather than just a trivial trade-off where, yes, your build times will go up because of some extra dependencies on an async runtime.Increased build times are not great but holy shit the way people talk you&#x27;d never know that that&#x27;s the actual trade-off here, an extra 3 seconds on a clean build. reply qup 11 hours agorootparentAdding dependencies is not easy in some organizations. You have to trust them, in addition to waiting 3 seconds to compile them. reply insanitybit 11 hours agorootparentOK, in some niche scenarios I can see the cost being larger, but I think this is totally overstated. replybryanlarsen 16 hours agorootparentprevUsually you&#x27;re reaching for block_on because a library you want to use is async. Almost certainly the library you&#x27;re using will have already be depending on an async library, so by pulling it in yourself you&#x27;re not adding additional dependencies. reply dymk 16 hours agorootparentprevThen use the code I posted if you don&#x27;t want a helper library. Or just wrap it in your own function if it&#x27;s too complex for your tastes. reply kingofthehill98 16 hours agorootparentprevEvery day we stray further from god. reply gnulinux 12 hours agorootparentThis is the kind of thing you write once to abstract out async things in a function and call it a day. It really isn&#x27;t that bad. Besides you can just use: smol::block_on(async { println!(\"I&#x27;m async!\"); });if smol is an option. reply wavemode 16 hours agorootparentprevThe complexity of this code snippet almost seems satirical (though I do get the point you&#x27;re making, and agree with you). reply dymk 16 hours agorootparentOn one hand, I agree that on the surface, this looks complex, if you don&#x27;t read it.But on the other hand, just read the code. It&#x27;s not complex.You drill down into a tokio namespace. You make a builder object. You unwrap it. This is idiomatic Rust. It&#x27;s verbose, but explicit is better than vague. There&#x27;s no conditional logic. There&#x27;s no weird type-fu. No macros. There&#x27;s not even any parameters to supply, other than the Future to block on.It&#x27;s trivial to write a wrapper to go from chained methods a helper call. reply mplanchard 16 hours agorootparentprevJust noting for other readers that, while killercup posted another option using `smol`, this seems to me to be in line with Rust&#x27;s philosophy of explicitness, which is something I really appreciate about the language:- create a builder- run on the current thread only- enable all drivers- create the instance- ignore errors- then call some blocking async codeWould look nicer if split out onto multiple lines I imagine: use tokio::runtime::Builder; let runtime = Builder::new_current_thread() .enable_all() .build()?; runtime.block_on(async { println!(\"I&#x27;m async!\"); }); reply no_wizard 16 hours agoparentprevI will forever argue that things like goroutines and the Java Loom Project are proving that it is long term more successful than making an explicit async keyword &#x2F; operation that has its own semantics when invoked, because it won&#x27;t dictate your code and cause the color function problem to exist.I&#x27;d love to see this in Rust, and I know that it initially had something like this, perhaps its not a bad idea for someone to take a second look at this now that more time has passed.EDIT: to be clear, that is not me saying we need goroutines or we need a Java Loom equivalent in Rust, simply, the DX of these two examples are far superior to the DX of async Rust today, in my opinion reply withoutboats3 16 hours agorootparentThis was the subject of my previous post: https:&#x2F;&#x2F;without.boats&#x2F;blog&#x2F;why-async-rust&#x2F; reply insanitybit 16 hours agorootparentprevHow can you argue that? Loom is extremely early, it&#x27;s not proving anything.And Java&#x2F;Goroutines don&#x27;t have a keyword because they do things implicitly, they have heavy preemptive runtimes. reply no_wizard 16 hours agorootparentThats red herring IMO. Sure, they&#x27;re GC&#x27;d languages, but that does not preclude the fact that both of these approaches from a DX perspective are easier to work with, and that matters in language design.I didn&#x27;t say we need goroutines or we need Loom style asynchronous primitives I am however pointing out, that they did a really good job of making async approachable and feel like you&#x27;re writing the same code as you would in a traditional synchronous model. Thats the real win.Its not an easy problem to solve, to be absolutely clear, but its a worthy goal, and if that means it adds marginal overhead initially I think its worth the tradeoff (esp. if you can do something similar to how you can use Rust in a `no-std` build, you could do one without a `async runtime` build, spitballing off the top of my head)Another problem is that generally speaking, async is de facto used a 3rd party lib, and it really should be a first party primitive that everyone feels comfortable using.To me, this is what matters reply insanitybit 16 hours agorootparent> I didn&#x27;t say we need goroutines or we need Loom style asynchronous primitives I am however pointing out, that they did a really good job of making async approachable and feel like you&#x27;re writing the same code as you would in a traditional synchronous model.You created a dichotomy - languages with a native construct for async versus languages that provide this as libraries. But that dichotomy does not exist - both language have native concurrency support through their runtime. That was what I was pushing back against.> async is de facto used a 3rd party lib, and it really should be a first party primitive that everyone feels comfortable using.I think this really remains to be seen. Rust has always had a \"just pull in a crate\" mentality and a \"be very conservative about what&#x27;s in std\" approach, and I think the community is overwhelmingly in favor of that. Any major stdlib changes should be taken pretty seriously. reply no_wizard 16 hours agorootparentI agree, it should be taken really seriously.I think 4 years worth of a feature being out in the wild and in use is enough time to start having conversations about what went well and what didn&#x27;t and how to address that. Its very clear to me, at least, that async in Rust is becoming more and more dependent on tokio. Most of the major async supporting crates support tokio and&#x2F;or only leverage tokio. Just a cursory glance at the crates registry supports this much.I&#x27;m not against a \"pull in a crate\" mentality mind you (though, careful what you wish for here, see: NPM &#x2F; Node ecosystem) however, it is worth identifying when something is becoming &#x2F; has become &#x2F; is considered to be such a core feature of the ecosystem that it would benefit greatly from stdlib support, and I think this fits that definition based on the evidence I&#x27;ve seen, at least. Though I realize others may not share this sentiment, I think its a viewpoint that has evidentiary backing (see all the talk about async Rust in the communicate, issues etc surrounding it. Its already a pretty big buzz topic relative to other things surrounding the language)All this is to say, maybe its time to seriously start thinking about what first party support will look if we bring in a first party async &#x2F; non-blocking I&#x2F;O platform into the stdlib reply insanitybit 16 hours agorootparent> careful what you wish for here, see: NPM &#x2F; Node ecosystem)Just to be clear, I think the NPM ecosystem is generally great and a massive success. People totally overblow the issues, and none of them are actually because of a small std library or due to the ease of install&#x2F;publish.> however, it is worth identifying when something is becoming &#x2F; has become &#x2F; is considered to be such a core feature of the ecosystem that it would benefit greatly from stdlib support,I agree, and I think that there are a few places with regards to async that could work well here. Maybe some kind of Executor trait (hard, but maybe possible?), probably `std::block_on`.> see all the talk about async Rust in the communicate,FWIW I think the majority of people are just happily doing async work in Rust and don&#x27;t get too involved in the discussions. I&#x27;m one of those people, except I&#x27;m also an internet addict on extended PTO so here I am.> All this is to say, maybe its time to seriously start thinking about what first party support will look if we bring in a first party async &#x2F; non-blocking I&#x2F;O platform into the stdlibI agree, I think some of this is best done in the language but some should be in std. No question. reply steveklabnik 16 hours agorootparentprev> both of these approaches from a DX perspective are easier to work with, and that matters in language design.While you are right that DX matters, DX is not the only thing that exists. Design is about balancing constraints and tradeoffs. Rust has other design commitments that preclude using this design, before you even get to DX questions.(Furthermore not everyone agrees that these things are clearly better from a DX perspective, as DX is a subjective topic.) reply no_wizard 16 hours agorootparentI agree, there&#x27;s questions that need to be answered, and I don&#x27;t know that I even have answers to give to them.I will say, that its clear, to me and a good portion of Rust users, that async in Rust needs DX improvements. Its one of the top features of the language that is used alot and people struggle with often[0][0]: To be fair, async in any language trips up developers pretty often, though I think Rust can give someone a particularly bad time. Granted, I have not compared it to C &#x2F; C++ as I don&#x27;t do any development in either language currently reply steveklabnik 16 hours agorootparent> I don&#x27;t know that I even have answers to give to them.To be honest, this is why this discussion always gets frustrating: people demand change that is impossible, and then when pushed for how to accomplish the impossible, they throw up their hands. I do not think you or anyone else is doing it maliciously, but for some reason, on this specific topic, it happens endlessly. reply no_wizard 15 hours agorootparentMy best shot at this is something akin to a runtime built-in to the stdlib that can be opted out, similar to how you can build something with `no-std` so there is no reliance on `libstd`. Perhaps this is a great place where you drop into more \"raw\" async programming using the async &#x2F; await primitives. You lose DX sugar but slim out the runtime for embedded work.Ideally, the runtime could handle anything written using lower level primitives as to not completely kneecap libraries that need to work with `no-async-runtime` (or whatever you want to call it).This would at least alleviate a common concern I hear around this, which is runtime bloat.That seems like a step in the right direction to integrate a unified async runtime with an alternative &#x2F; better syntax[0][0]: I want to note, that C# is the only language I ever worked in that supported async in two constructs. There is the traditional async &#x2F; await, which is by far the most common. Before that though, there was event driven async programming (with support for background workers and other async features) and that is also still supported, and they can interop with each other (with some caveats) reply steveklabnik 15 hours agorootparentThe only thing this would change is not needing to \"cargo add smol\" which already exists as a smaller runtime if you need it. That wouldn&#x27;t solve the fact that a large part of the ecosystem would still need the features of Tokio, and would still use them. So you still have interoperability problems, until figuring out how to make runtimes swappable, and that is open-ended work. (and also assumes that smol&#x27;s particular choices are correct for this, and that everyone maintaining the stdlib agrees that they are, and that the folks on the libs team are willing to step up and start maintaining an entire async runtime, etc etc etc) replyjayd16 16 hours agorootparentprevAsync handles thread contexts better. Maybe I&#x27;m out of the loop but implicit blocking patterns haven&#x27;t taken over gui programming just yet. reply samus 16 hours agorootparentLoom is very new, and Java on the desktop is almost dead. Even though virtual threads could be useful for GUI programming, I don&#x27;t expect significant innovation in that area. But the upcoming Structured Concurrency[0] and Scoped Values[1] JEPs make things hopefully easier.[0]: https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;462[1]: https:&#x2F;&#x2F;openjdk.org&#x2F;jeps&#x2F;446 reply jayd16 16 hours agorootparentStructured concurrency looks good but is it really better than async syntax? reply samus 16 hours agorootparentI have to admit that async syntax has a certain charm, as it has deep connections to iterators. (I have to program with Unity for my master thesis). But Structured Concurrency leverages well-known blocking syntax that doesn&#x27;t require further explanation. It&#x27;s not even specific to virtual threads. reply zozbot234 16 hours agorootparentprevGoroutines and the Java Loom are just fibers. They&#x27;re like a super clunky mix of async-like and thread-like features, though sometimes there are reasons to use them. (For example, stackful fibers might enable cleaner interactions with OS facilities or outside library code.) Rust makes it real easy to just use threads if that&#x27;s what you prefer. reply untitaker_ 16 hours agoparentprevThis is a popular sentiment that I share to some degree, but I really wish we could just move on from this discussion. It happens in every post that is even just vaguely about Rust or async. It&#x27;s like reading complaints about the GIL on a post that is loosely connected to Python! At some point it just gets boring.\"I will forever argue that [...]\" -- Why are you forever arguing?\"I feel like I am alone with [...]\" -- No, I read it every day on here. reply no_wizard 16 hours agorootparentto be honest, HN is one of the few venues where I think someone who is core to a project might actually see what is said about a language. I&#x27;ve tried getting involved in mailing lists and stuff, but they aren&#x27;t often as welcoming to this discussion as one might assume.My hope is that by raising these things on HN, someone will take notice in a different way and at least start considering &#x2F; revisiting alternatives reply untitaker_ 16 hours agorootparentAll of this would be correct in an alternative reality where everybody in the Rust community, including every person ever involved in the language&#x27;s evolvement isn&#x27;t aware of these complaints. reply Kranar 15 hours agorootparentYour comment is self defeating. The reason people are aware of these complaints is because they keep being brought up, over and over.This is a serious wart on language design and while I can agree that it&#x27;s likely too late to fix it for Rust, there is a kind of race among new languages to be a successor to C++ in many of the domains C++ is used in, and while I think Rust does hold a lead in that race, the race is not over.A language that can provide an ergonomic solution to concurrency would absolutely provide a huge boost to any such language, and so to people in that space, listen to these complaints. Async&#x2F;await is not a good solution to this problem.You almost always hear people complaining about async&#x2F;await in every language it&#x27;s a part of but you rarely hear people complain about how Go manages concurrency. reply withoutboats3 17 hours agoparentprevWhat Rust libraries use async that you think should not? I can think of one, but otherwise every library I&#x27;ve encountered uses async because its intended for the kind of networking service that benefits from using non-blocking IO. reply couchand 17 hours agorootparentJust because it&#x27;s a network request doesn&#x27;t mean it benefits from using async.EDIT: to add a specific example, postgres. I understand from sfackler&#x27;s perspective why it makes sense to maintain just an async library and a sync wrapper around it. But from the user&#x27;s perspective there&#x27;a absolutely no reason that all of tokio should be required to talk to their db. reply withoutboats3 17 hours agorootparentAs a user who has maintained network services that communicate with Postgres, I&#x27;m very glad that sfackler&#x27;s postgres library doesn&#x27;t perform blocking IO calls, as that would make it unfit for purpose for me. reply couchand 16 hours agorootparentMaybe you misunderstand me. I&#x27;m not saying there shouldn&#x27;t be a non-blocking version. I&#x27;m saying async is not a silver bullet. Some programs&#x2F;teams&#x2F;environments have different constraints than you.Would you also advocate for the kernel to deprecate blocking i&#x2F;o? reply withoutboats3 15 hours agorootparentObviously, it&#x27;d be better for someone who wants to talk to postgres and doesn&#x27;t need non-blocking IO if a version based on blocking IO existed. But what is your grand point? It&#x27;s not some conspiracy that libraries for network services use async&#x2F;await: they most often do it because their maintainers need to use async&#x2F;await in the work that pays for them to provide this open source library free of charge to you.And all you need to do to not deal with async is wrap it in one of the many different block_on implementations. Yes, that&#x27;s less ideal than not having to pull in these dependencies; if avoiding those dependencies is mission critical for you, maybe yours could be the enterprise that pays for the blocking IO postgres library. reply chlorion 15 hours agorootparentprev\"async\" and threads are not the only options for concurrent IO.I&#x27;ve never saw anyone discuss using poll(2) style concurrency here which is interesting but also kind of sad.With the mio crate for example, it uses the operating systems \"select&#x2F;poll\" interface. On Linix this is epoll(7), but other OSes have their own interface.\"poll\" style concurrency is a lot less complicated for me. The general idea is to register IO handles such as sockets into a data structure and pass it into the kernel. The kernel will emit events whenever a handle is ready to do something. There is the option to go to sleep and block until one of the handles are ready but it&#x27;s not required.\"async\" is an abstraction on top of this. The async runtime is handling the event loop and other stuff for you which is very useful but also a little bit complicated.I am not in any way against \"async\" style concurrency but I think a lot of libraries could avoid pulling in a runtime and still be concurrent. reply insanitybit 15 hours agorootparent\"mio\" was the game in town for years and it was definitely not ideal at all, it was promising but very low level and most people didn&#x27;t use it if they could help it. People wanted async&#x2F;await. reply bryanlarsen 14 hours agorootparentprevSeveral of my rust programs use tokio&#x27;s select! macro as their main loop. I really like that pattern. reply mplanchard 16 hours agorootparentprevNothing is stopping anyone from writing DB drivers that don&#x27;t require async. If there&#x27;s as much of a market for it as threads like this suggest, it seems like it would be a fairly popular project. reply geodel 15 hours agorootparentHuh, thats rather odd argument. It is like saying no one is stopping anyone to write new low level, memory-safe programing language, that won&#x27;t have Rust style async system. If there is real market demand it could fairly popular project.DB drivers, http servers, runtimes and so many other complex components are preferences of high skilled developers and not some objective market choices. Once its developed most application developers have to use it however user unfriendly it maybe. reply mplanchard 10 hours agorootparentOne thing about Rust is that it&#x27;s a fairly young language. We&#x27;ve had to implement a number of things ourselves that we wouldn&#x27;t have had to implement in other languages.If there&#x27;s not enough community interest for there to already exist a solution for your problem, you really only have three options: write it yourself (including opening a PR to add it to an existing implementation), pay someone to write it, or switch languages. If none of these are options, you&#x27;re just out of luck, and complaining about it is unlikely to do any good. I&#x27;m not saying you can&#x27;t complain of course, but I am saying that you&#x27;re more likely to get what you want via another path.But regardless, I don&#x27;t think it&#x27;s an odd argument. Indeed, no one is stopping anyone from writing a new, low-level, memory-safe programming language! That&#x27;s why Rust exists! Turns out the market was huge! Writing a new one now would be easier because of all the great ideas that Rust helped to prove work at scale. We&#x27;re seeing this already with the success of languages like Zig, which makes different tradeoffs than Rust did and seems to be finding success in slightly different niches.And sort of disproving your point, we use postgres, and I can think of three different implementations of postgres drivers offhand (sqlx, tokio-postgres, and diesel). I&#x27;ll also note that the author of tokio-postgres also publishes https:&#x2F;&#x2F;docs.rs&#x2F;postgres&#x2F;latest&#x2F;postgres&#x2F;, which is not async! It&#x27;s impressive how many options we have for such a complex thing in such a young ecosystem. reply couchand 7 hours agorootparentpostgres is a wrapper around block-on(tokio-postgres). replysapiogram 16 hours agorootparentprevI had an absolutely awful experience when I tried using Sqlite through the sqlx crate. The work was mostly cpu-bound, but I didn&#x27;t mind blocking the event loop for a few seconds here and there, so I thought I would just run it on Tokio&#x27;s worker threads. Big mistake, I ended up getting extremely low CPU utilization due to a quirk (Or less charitably, a bug) in Tokio&#x27;s scheduler.I eventually rewrote the whole thing with rusqlite, but apart from being non-async, I found the API much less ergonomic to work with. But at least Rayon worked exactly as I expected. reply dpc_01234 15 hours agorootparentprevExample from the recent past: I wanted a quick Rust code to stream s3 object, uncompress with zstd and untar the content to a directory. aws-sdk-s3 supports only async (tokio), tar crate only blocking, async-tar only async-std, async-compression only tokio. Hard to paper over it with `block_on` because of the streaming part. I don&#x27;t remember what I actually did, but it doesn&#x27;t matter - having to come up with a magic working combination is exactly the pain.I just wish everything would at least still support blocking IO as a common denominator, so there&#x27;s at least a baseline that is known to be possible. 99% of percent of the time I do not need benefits of async, because I write small software for relatively small, but still real use-cases. And using Rust ecosystem was easier just a few years ago than it is now for these use-cases, as blocking Rust was not yet relegated to be a second class citizen, replaced by an immature and fractured async. reply insanitybit 15 hours agorootparent> And using Rust ecosystem was easier just a few years ago than it is now for these use-casesI used to write Rust web services (professionally) before async and it was definitely not easier for me. It was way harder. I&#x27;d end up with accidental hanging because some socket didn&#x27;t have a timeout set on it properly, it was extremely leaky (why the hell am I talking to raw socket APIs just so that I can read from S3?), and it sucked compared to async. We&#x27;ve had radically different experiences, somehow. reply dpc_01234 11 hours agorootparent> why the hell am I talking to raw socket APIs just so that I can read from S3I don&#x27;t know. https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;net&#x2F;struct.TcpStream.html#meth... etc. were there for a while. Though I think that deadline-based timeouts would be way better to have. https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;rust&#x2F;comments&#x2F;8b5krv&#x2F;the_case_for_d... . Probably could be built around existing primitives. These things were never built&#x2F;popularized because the community just jumped on async like some silver bullet.I agree that building heavy duty networked services got easier with async, but at an expense of fracturing the ecosystem and dragging everything else into an MVP feature, which made things worse (at least in some respect) for other things. I personally don&#x27;t do much web servers, and when I do I can just spawn lots of threads, terminate TLS with nginx anyway.Again, I don&#x27;t mind async on its own. I think it&#x27;s great for what it is, and is useful when it&#x27;s useful. But for decades tons of the web was built in Java, Python, RoR without async IO and it worked just fine. And I didn&#x27;t have to play IO-type sudoku, and could expect that the most basic, native blocking IO is well supported, and not just an afterthought&#x2F;wrapper. reply the__alchemist 17 hours agorootparentprev> the kind of ... service that benefits from using non-blocking IO.Async, in the sense from the article, and non-blocking aren&#x27;t synonyms. Not using Async doesn&#x27;t imply blocking. reply withoutboats3 17 hours agorootparentWhat Rust libraries use non-blocking IO without using async syntax? I don&#x27;t know of any. This interpretation of the request is new to me: I&#x27;ve exclusively heard complaints about libraries using async from people who want to use blocking IO.(Also, in case it isn&#x27;t obvious: I wrote the article in question.) reply the__alchemist 17 hours agorootparentI usually do non-blocking ops with hardware interrupts, DMA, distributed computing (over CAN etc), and multiple cores. For GPOS&#x2F;Desktop PCs, threads, SIMD (GPU or CPU etc) are effective.More generally than the concurrency operations I described, are any sort of event-loop or state machine, of which Async is one example. reply starcraft2wol 17 hours agoparentprevThe entire unix operating system is designed so that you can write sequential code. It abstracts concurrency away. It’s incredible. reply gwbas1c 14 hours agorootparentThe point of async is to move concurrency from the OS into the process.The specific issue is the context switch. The compiler, with async is able to be much more performant than the context switch that the OS provides.Depending on the kind of application you&#x27;re writing, this is either splitting hairs or very, very important. Applications that handle many (hundreds, 1000s,) of concurrent IO will have a noticeable performance improvement using async versus the OS&#x27;s context switching.But, there&#x27;s a more important thing to consider: \"async\" in a programming language communicates that a method can block. It allows the caller to start the call and do something while it&#x27;s waiting for the result, without needing to get into the weeds of threading. Purely relying on the OS for context switching means that it&#x27;s hard to know what methods block. reply returningfory2 14 hours agorootparentJust a note that it seems many people think the main problem isn&#x27;t the context switch. Rather, Linux by default allocates a very large stack to every thread, and thus many threads lead to high memory usage. Async makes this better.See e.g. this recent clip from one of the engineers on Project Loom in which they argue that the context switch is relatively low overhead: https:&#x2F;&#x2F;youtu.be&#x2F;07V08SB1l8c?si=i0v9w90Kb_M0I4gP&t=966 reply gwbas1c 13 hours agorootparentAt least on Windows I&#x27;ve reconfigured the stack space. (I had to run an experiment that required a lot of threads.)Is this something that&#x27;s hard to do on Linux? reply steveklabnik 12 hours agorootparentIt&#x27;s the same, but this issue gets to one of the hearts here:Both of these APIs are set by you, the user. You can choose how big to set your stack size, it&#x27;s true. However, what value do you actually set? Too high, and you&#x27;re still using too much memory, though admittedly less. Too low, and you either need to accept death by stack overflow, or runtime detect this case and fix things up.With async&#x2F;await in Rust, the compiler can statically see how large the stack size needs to be. Each \"thread\" will have a perfectly sized stack. No user intervention required, no fiddling with settings. reply 10000truths 6 hours agorootparent> Both of these APIs are set by you, the user. You can choose how big to set your stack size, it&#x27;s true. However, what value do you actually set? Too high, and you&#x27;re still using too much memory, though admittedly less. Too low, and you either need to accept death by stack overflow, or runtime detect this case and fix things up.This is a solved problem - it&#x27;s \"just\" the longest path in a call graph where each node is weighted by its function&#x27;s stack frame size.> With async&#x2F;await in Rust, the compiler can statically see how large the stack size needs to be. Each \"thread\" will have a perfectly sized stack. No user intervention required, no fiddling with settings.There is nothing stopping a compiler from doing the exact same analysis for a sync function at compile time (barring exceptions like varargs or deliberate recursion). They just... haven&#x27;t, for some reason. It&#x27;s a shame that it took until Zig for it to be addressed. reply MrBuddyCasino 12 hours agorootparentprevThe stack memory won’t actually be physically allocated upfront - like all user space memory it is virtual. reply starcraft2wol 14 hours agorootparentprevI agree with most of this.> without needing to get into the weeds of threadingA thread is the exact concept needed to describe that and preserve “if else then” sequential code.> 1000s of threadsLinux handles thousands of threads just fine. If you’re using a scripting language like python, context switching is the least of your performance concerns. reply gwbas1c 13 hours agorootparent> A thread is the exact concept needed to describe that and preserve “if else then” sequential code.I suggest looking at C# and Javascript that implement async very, very well.The difference is that with conventional threading semantics, when you join a thread, it doesn&#x27;t return a result. You still need to write some kind of \"thing\" to get your result from the subthread to whatever&#x27;s waiting on it. (C# also provides a less-well-known BeginInvoke mechanism which is somewhat cleaner than join.)In contrast, the promise (Javascript) or task (C#) has a result. Instead of joining a thread, the await keyword gets the result, just like calling a method.> Linux handles thousands of threads just fine.Yes... And no...It doesn&#x27;t matter what OS you&#x27;re on, each thread needs its own allocated stack space and has the overhead of context switching. \"async\" optimizes that by putting data that would normally go into many different stack spaces into the heap and jumping around among concurrent operations without the context switch.Again, depending on what you&#x27;re doing, that&#x27;s either splitting hairs, or really making a tangible improvement. But you can&#x27;t argue that more allocated stacks, and more context switches, is faster than doing it in process. At that point you&#x27;re arguing with fact. reply starcraft2wol 8 hours agorootparent> C#&#x2F;JavaScriptI am familiar with how these are implemented. My opinion is the same. Yes you can implement slightly lighter weight threads in a language itself.> It doesn&#x27;t matter what OS you&#x27;re on, each thread needs its own allocated stack space and has the overhead of context switchingThis is a quantitative question. I know what it does, the question is how much slower it is than whatever async construct you want to use. reply gwbas1c 11 hours agorootparentprevToo late to edit: I should also point out that Rust has the same issue with joining a thread: It doesn&#x27;t give you the result of the function; unlike awaiting on a promise.(I really struggled with async rust, so I&#x27;ll admit that I don&#x27;t remember the name of the type that represents the promise.) replythe__alchemist 17 hours agoparentprevI&#x27;m with you. I feel like an outcast in the Rust OSS embedded circles when I bring this up. They are heavily into async&#x2F;embassy. reply dgacmu 17 hours agorootparentI&#x27;m curious why you don&#x27;t like it for embedded - embassy has been an absolute delight for me thus far, and my primary complaint about it is just that it doesn&#x27;t have the breadth of hardware support (yet?). It&#x27;s been the thing that has redeemed Rust async for me, as otherwise, I tend to find the tension the author notes frustrating as well. reply steveklabnik 16 hours agorootparentI am pro async Rust, but we don&#x27;t use async in our embedded projects at Oxide. This is because of specific design constraints and goals: https:&#x2F;&#x2F;hubris.oxide.computer&#x2F;reference&#x2F;#_why_synchronousThat being said, I am also a fan of embassy when you have different design constraints and goals, and consider the fact that is is able to exist and be successful is a massive testament to the design of async Rust.(We also use async Rust heavily further up the stack, and have some issues with it, but they tend to be disjoint from the way that this is talked about online.) reply dgacmu 16 hours agorootparentOddly, I agree with you - but I think I may be approaching it differently. I use async as a mechanism to be able to have clearly-defined \"tasks\" in an embedded context, where tasks have straight-line code that handles something. I have most of the interaction between tasks be synchronous; in the case of embassy, the thing it brings is that it manages that otherwise-spaghetti-feeling mix of state machines in an easy-to-read kind of way.Example from a current side project, since it&#x27;s not work-encumbered: A wifi-enabled clock light for my 5yo. It has a task that sits there and every hour pings an SNTP server, updating a (mutex-protected) global with the time state. It has another task that listens for a telnet session for various control signals - which also updates a mutex-protected global config state. And it has a task that spins doing LED effects.With embassy&#x2F;async, I can write each of those as a separate task, without paying much attention to what gets invoked by interrupt handlers.(This particular one is an rp2040, but I use it on stm-based systems as well).I feel like this is kind of analogous to the discussion of threads-vs-events as a mechanism for structuring code vs. threads as a mechanism for achieving parallelism. :-)Edited to add: Or, perhaps an alternative view of what I&#x27;m doing is that I&#x27;m using the embassy runtime as a really lightweight alternative to an RTOS, since I mostly haven&#x27;t met an RTOS I don&#x27;t want to throw across the room. An argument against what I&#x27;m saying here is, \"well, use Hubris as your embedded OS and then you can have tasks and they can be synchronous\" - which seems entirely fair. reply steveklabnik 16 hours agorootparent> I use async as a mechanism to be able to have clearly-defined \"tasks\" in an embedded contextThis is also a good design! The primary designer of Hubris also has a project that works like this: https:&#x2F;&#x2F;github.com&#x2F;cbiffle&#x2F;lilos reply the__alchemist 16 hours agorootparentprevWhat I like about Embassy is the Metapac, and less reliance on generics and typestates than predecessors.My complaint is I don&#x27;t find the async ergonomics intuitive; it feels like a layer of misdirection. And, the viral character. reply empath-nirvana 16 hours agoparentprevI genuinely don&#x27;t understand the problems people have with async code... at least for anything involving http&#x2F;api requests it&#x27;s largely just a matter of decorating stuff with &#x27;async&#x2F;await&#x27;. It makes a few things difficult (iterators with futures, ugh), but mostly it&#x27;s easy. reply galangalalgol 15 hours agorootparentBecause rust is a systems language, it is common for people to use it for things that don&#x27;t involve http or even networking in general. Alternatively, people often use it for wasm. Before async and specifically tokio, a much larger percentage of crates were usable by those people. This feels like something nice has been taken away or that our use case has been marginalized. The answer is to spend the time to create tokio and&#x2F;or async free alternatives to these crates, but that was not expected to be necessary, so it also is added work. All of that is irritating, and the constant stream of \"just accept it and get with the program. Stop complaining!\" Is really quite infuriating. The fair answer is that rust should be what the majority of its users want&#x2F;need it to be. But people who just need a back end language have a dozen or more good ones to choose from. People who need a systems language have far fewer choices, especially if you want memory safety, so having the aims of the language diverted from that end is irritating to say the least. I do suspect a fork to occur someday for those reasons, probably centered around the use in linux android or windows. reply orcy 17 hours agoparentprevI am in doubts about async too. For better understanding I have implemented my own executor and io library (even with some tricky async destruction) and I am not quite happy with it. The problem is that in rust there are no other good methods to write safe async code, are there? My impression that borrow checker forbids lots of patterns I know from other language. reply nextaccountic 16 hours agoparentprevdoesn&#x27;t block_on work for you? reply jokethrowaway 16 hours agoparentprevWell, you can block on it if you wantThat said, I disagree on the usefulness of async: in my experience it does the job and it&#x27;s my default setup.There&#x27;s a complex project where I ended up just using threads because I needed to squeeze performance out but overall async is great for tasks, sequence of async operations.Still, it had some rough edges: (it&#x27;s been a while but) using Async Closures wasn&#x27;t pleasant and I re architected my app to not use them as a result. There&#x27;s an argument to be made for this change making my application easier to reason about - but overall it&#x27;s poor language flexibility. reply littlestymaar 17 hours agoparentprev> However, if a library uses async, you have little choice but to make your whole project async. This adds to its horrible reputation.No.This is how yo do: you look what executor your dependency is using (most likely tokio) you add it to your cargo.toml (at zero cost, since it&#x27;s already there in your dep) and then you wrap the async library calls in `block_on` and call it a day. You don&#x27;t need to change a single other line in your project. reply couchand 17 hours agorootparentYou breeze over the dependency weight by abusing \"zero cost\" to mean \"sunk cost\". They&#x27;re not the same! reply littlestymaar 16 hours agorootparentThey are. If you&#x27;re using a dependency you&#x27;re using your dependency dependencies, there&#x27;s no way around it.If it matters to you, you don&#x27;t have the same priority as your dependency&#x27;s author anyway and probably shouldn&#x27;t be using it in the first place, and it has nothing to do with async. reply pm215 17 hours agorootparentprevThis was not my experience. I had a working program that used the reqwest crate for a very basic synchronous-is-fine \"just give me the contents o",
    "originSummary": [
      "The author advocates for new features in async Rust, such as AsyncIterator, async generators, and \"Return Type Notation\", along with treating async closures as closures returning 'impl Future'.",
      "They touch upon complex concepts such as object-safe coroutine methods and async destructors, and discuss the integration of advanced types like Immoveable, Unforgettable, and Undroppable.",
      "The author critiques the Rust project's decision-making and communication process, urging for more understanding and open dialogue between the project team and the community."
    ],
    "commentSummary": [
      "The author articulates future enhancements for asynchronous Rust programming, focusing on the introduction of new features including AsyncIterator, async generators and a novel \"Return Type Notation\".",
      "The post suggests treating asynchronous closures as closures returning an 'impl Future', and delves into intricate concepts like object-safe coroutine methods and asynchronous destructors.",
      "The author critiques the decision-making and communication practices of the Rust project and appeals for better comprehension and communication between the project developers and the community."
    ],
    "points": 201,
    "commentCount": 220,
    "retryCount": 0,
    "time": 1699373577
  },
  {
    "id": 38177250,
    "title": "Mass Resignation at The Escapist Following Termination of Editor-in-Chief Nick Calandra",
    "originLink": "https://www.gamesindustry.biz/the-escapist-staff-resign-following-termination-of-editor-in-chief-nick-calandra",
    "originBody": "Home News The Escapist staff resign following termination of editor-in-chief Nick Calandra Zero Punctuation's Ben \"Yahtzee\" Croshaw is one of many to leave the site News by Sophie McEvoy Staff Writer Published on Nov. 7, 2023 Follow The Escapist Journalists from The Escapist have resigned in response to the termination of its editor-in-chief Nick Calandra. On Monday, Calandra announced on X that he was fired for \"not achieving goals\" reportedly set by the Gamurs Group, which acquired The Escapist last year. \"I was let go for 'not achieving goals' that were never properly set for us, and a lack of understanding of our audience and the team that built that audience,\" Calandra wrote. \"I've watched many colleagues let go for the same reasons, and today was my day.\" GamesIndustry.biz has reached out to Calandra and the Gamurs Group for more clarification. Calandra shared more information on Discord, revealing that the \"entire video team\" has resigned in response. This includes Ben \"Yahtzee\" Croshaw, who created the video review series Zero Punctuation. \"Today, I formally resigned from The Escapist and Gamurs,\" Croshaw wrote today on X. \"I don't have the rights to Zero Punctuation, but whatever happens you'll be hearing from my voice again soon, in a new place.\" Contributors such as Amy Campbell, Parkes Harman, Darren Mooney, Matt Laughlin, and Design Delve's JM8 have also left the site in response to Calandra's termination. Sign up for the GI Daily here to get the biggest news straight to your inbox",
    "commentLink": "https://news.ycombinator.com/item?id=38177250",
    "commentBody": "The Escapist staff resign following termination of editor-in-chief Nick CalandraHacker NewspastloginThe Escapist staff resign following termination of editor-in-chief Nick Calandra (gamesindustry.biz) 189 points by falcor84 19 hours ago| hidepastfavorite101 comments loganfrederick 17 hours agoAs I posted in the Aftermath&#x2F;Kotaku thread[1], I worked as a contract writer for The Escapist from 2005-2009, and it was literally my first job ever. Yahtzee resigning is what I consider the end of the publication, as he&#x27;s been the most consistent contributor for nearly two decades and most likely the primary revenue generator. It&#x27;s very sad to see a huge part of my past coming to a close.[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38176053 reply martincmartin 15 hours agoparentEdit: I misread, sorry. reply bentley 17 hours agoprevIt’s not too surprising that Nick got fired given The Escapist’s desperate attempts at monetization of late. Zero Punctuation videos typically start with a short 30‐second ad for some other Escapist property, read by Yahtzee himself. But recently blatant 1‐minute ads (preceding a 5‐minute review) from external sponsors have been showing up in the high‐profile review videos such as Tears of the Kingdom and Baldur’s Gate 3. A review just two months ago even had an advertisement within the video. Notably, Yahtzee did not deign to perform these ad spots for external sponsors himself, a sign of how much pull he had within the company.Another sign of how much of a moneymaker ZP is for The Escapist is how in the last few years it’s rebranded to use the distinctive “limbless white figure” art style, an invention of ZP, throughout Escapist’s other blogs and podcasts.Ticking off Yahtzee by firing Nick has taken out what’s almost certainly The Escapist’s biggest source of revenue. reply wsinks 16 hours agoparentI remember that video with the sponsor in the middle of it, and if I remember correctly showed Yahtzee&#x27;s active disdain for it because he alluded to it before the sponsor bit, showing that he knew that it would interrupt the content that he was powerless to change it.I&#x27;ll have to follow Yahtzee and Frost wherever they go. reply colechristensen 6 hours agorootparentSeems like they’re all balding together and starting something new called Second Wind.>@everyone I&#x27;m very excited to announce that name of our new adventure, Second Wind.The ENTIRE Escapist video team is coming with. and I will be live on the channel tomorrow at 11 AM CT to discuss our plans, talk about what happened, where to support and when our first videos will drop.All the links you need:https:&#x2F;&#x2F;twitter.com&#x2F;SecondWindGroup https:&#x2F;&#x2F;www.twitch.tv&#x2F;secondwindgroup https:&#x2F;&#x2F;www.youtube.com&#x2F;@SecondWindGroup reply colechristensen 14 hours agoparentprevThe escapist was just purchased a few months ago and the new corporate overlords were trying new things to monetize. reply m-p-3 14 hours agorootparentLooks like they&#x27;ve made a significant miscalculation. reply raffraffraff 5 hours agorootparentMay the old team thrive and may the brand fail reply tinus_hn 9 hours agoparentprevWithout external ads and with only promotion for their own properties, how were they supposed to make any money?Is making money ‘blatant’? reply bentley 8 hours agorootparent> Without external ads and with only promotion for their own properties, how were they supposed to make any money?Among other things, they advertised direct moneymakers like paid subscriptions.> Is making money ‘blatant’?There’s making money and then there’s making money. As a somewhat regular browser of Escapist content for over a decade, my characterization of Nick’s tenure would be that its non‐ZP output stood out for being rather thoughtful games industry commentary, as opposed to chasing clickbait and other industry trends. By Nick’s account, this was enough for them to see successful, healthy growth—it just wasn’t enough growth to please the higher‐ups.Now consider the “blatant” sponsored advertisements, which I neglected to mention were for such products as gacha games and crypto miners. Tonally inconsistent with the surrounding aesthetic; unpopular with the talent, as visible in Yahtzee’s obvious disdain. Worrying indicators of executive meddling that seem to have been confirmed by this week’s events.So yes, decisions in the name of “making money” can be blatant, if by chasing it you lose all that distinguishes you from the bland, reader‐hostile content mill that is the rest of the gaming news industry. reply ivraatiems 17 hours agoprevWhy is it never good enough to just have an ongoing business that works?Unless The Escapist was really losing money or about to go bankrupt, I don&#x27;t know why it needed to be messed with. It&#x27;s not a \"growth\" project, it&#x27;s a journalistic outlet. Who cares if it \"grows\"? reply jeffwask 16 hours agoparentIt&#x27;s the VC wheel. You buy a successful outfit. Saddle it with the acquisition debt. It&#x27;s no longer profitable because of debt service. You need more revenue in a thin margin business. You start alienating users and dumping unrealistic expectations on employees. Company goes boom or dies like a wet fart.I mean it was purchased by a company that unironically calls itself Gamurs Group. reply StressedDev 12 hours agorootparentVenture Capitalists do not buy existing profitable companies. They fund startups. You are thinking of private equity or leveraged buyout companies. In private equity, private equity companies buy a company (typically on credit). The private equity company hopes to make a return on its investment.I also doubt there are a lot of deals where a previously profitable company is unprofitable after the deal. There are two reasons for this. One, it&#x27;s bad business. Two, very few people are going to lend money for this type of acquisition. If it does happen, it was either probably a mistake or an error. reply Beldin 2 hours agorootparent> I also doubt there are a lot of deals where a previously profitable company is unprofitable after the deal. Perhaps - but the fact that a trick has become well-known where companies are acquired only to be burdened with debt from the acquisition is rather telling. And that is not helping profitability.As someone who&#x27;s less into business &#x2F; financial news than eg. curling news, I know of a ridiculous amount of companies where this happened. So I really do not doubt this is a common strategy. reply lvspiff 16 hours agoparentprevWithout growth you would need to increase price to continue to pay for workers who want a COLA increase. Increase price and you hemorrhage customers without a growth path. Even if you kept your staff at the same level paying someone the same amount yearly would still lead to decreasing revenue due to the cost of taxes, benefits, etc increasing.In the long run the only way to run a business is to increase growth or increase cost to consumers. Since the escapist mostly ran off ad revenue (although they did have subscriptions that im guessing helps) unless they increased viewership they likely they weren&#x27;t hitting the metrics they wanted.by no means does this means let go of the guy leading the team who is your likely biggest draw -- thats just stupid reply didibus 15 hours agorootparentHow do small businesses manage this? Restaurants, coffee shops, local bookstores, small gift shops, local specialty clothes store, etc. ? reply araes 12 hours agorootparentA lot of small businesses push the price increases onward. Food distributor says all your burger patties are +10%, all your burgers are +10%, unless you think its very temporary.One benefit of local \"anything\" is that the prices are often way better. Ex: Live in a small town, the land rent can regularly be $1-2&#x2F;sq. ft.&#x2F;month ($10-20&#x2F;yr) while a quick on Sydney (where Gamurs is located) runs $8-10&#x2F;sq. ft.&#x2F;month ($90-$100&#x2F;yr).Frankly, Sydney&#x27;s mostly already subdivided into work shares from what I&#x27;ve seen, and its difficult to even find a spot that&#x27;s not just $500-1000 &#x2F; worker &#x2F; month rates (or \"contact for price\"). Its part of the reason Sydney&#x27;s childcare is ridiculous, cause the space to even have a facility cost so much (and you have to have a min reg space per child). reply astrange 6 hours agorootparentprevIt might be a lifestyle business (or a way to keep a rich person&#x27;s spouse busy) in which case you can live on only employing family.Also, there just wasn&#x27;t inflation in some places for a few decades, so they just haven&#x27;t had to deal with it. (Which also means there hasn&#x27;t been wage growth.) reply VHRanger 14 hours agorootparentprevYou might notice a lot of small businesses fail. Of the ones that don&#x27;t, they don&#x27;t generate excessive profits for the owners.It&#x27;s only a small sliver of the small business space that ends up being economically succesful. reply AussieWog93 13 hours agorootparentI run a small business, know plenty of small business owners and this isn&#x27;t really the full story.Small businesses do frequently fail, but it&#x27;s more to do with the fact that anyone can start one than the fact that they are small. If you allowed random people with no experience to start billion dollar megacorps, they&#x27;d fail too.And there are plenty that generate pretty serious profits, triple or more what you could earn in a traditional job. reply jay_kyburz 14 hours agorootparentprevI went to a restaurant on the weekend where somebody had crossed out $16 and had hand written $18 next to all the mains. reply didibus 14 hours agorootparentRight, so I think people understand inflation. But apart from that? At least I didn&#x27;t understand OP as meaning that growth is meant to keep lowering prices and raising wages even in the presence of inflation. reply Exoristos 16 hours agorootparentprevThis seems pretty disingenuous. Keeping up with costs is just part of stable profitability and in no way implies growth at the rate modern investors demand. reply pixl97 15 hours agorootparentThe problem here is you&#x27;re looking at the system as individual parts instead of the entire system.Lets imagine an entire economic system that was steady state. Why would profitability have to increase?Instead we have a system that profit must increase, and profit must increase in every component of the system constantly due to inflationary practices. reply astrange 6 hours agorootparentProfit only has to increase in nominal terms, not real terms.You don&#x27;t have to grow in real terms as long as you don&#x27;t promise equity investors you&#x27;ll try to grow.If you don&#x27;t even grow nominally, you won&#x27;t outrun debt and wage growth. reply johnbellone 14 hours agorootparentprevYou&#x27;re talking about \"profits\" when you should really be talking about \"costs\".At a macro level, in a large company&#x2F;business, your employees expect raises for a variety of reasons (inflation, quality of life, promos, etc). A new product or feature may require hiring additional employees. If an employee exits, you may need to spend more money to hire a replacement. In addition to all of that, there are contractual obligations with vendors, your customers may be trying to eliminate product (or leave entirely), etc.All of that raise the cost to run the business. If you want to keep your margin you need to raise your prices, cut expenses, or both. reply thereddaikon 14 hours agorootparentprevThat&#x27;s not how that works. Raising profits is not the same as raising prices to match inflation. reply pixl97 14 hours agorootparentRaising profits can cause inflation.https:&#x2F;&#x2F;www.npr.org&#x2F;2023&#x2F;05&#x2F;19&#x2F;1177180972&#x2F;economists-are-rec...>He found that in 2021, corporate profits could account for about double that, nearly 60% of inflation, meaning it was not costs driving inflation. It was corporate profits. Now, some economists hear this and think this is proof that companies were just using inflation as an excuse to gouge customers. reply vkou 14 hours agorootparentprev> Without growth you would need to increase price to continue to pay for workers who want a COLA increase.A business that raises prices to match inflation is not growing by any definition. reply dathinab 15 hours agoparentprevThe problem is if companies are bought by credit.Companies bind a lot of money (in assets but also less concrete goods like people and expertise).If you buy a company you need to pay for all of that even including _\"potential\"_ even if realizing that potential also would likely destroy the company.So if you pay for it with liquidity that would \"just\" bind liquidity.But if you pay for it with credit you now have to _pay of the credit_ or at least pay the interests.So if the company made 100x€ profit every month but you have to pay 200x€ in interests every month to pay it of after 20 years then the investor loses 100x€ every month. Now that is the investor not the company and after 20 years they would make 100x€ profit, but for most investors that would be a major losing deal (I mean ignoring interests on interest, inflation etc. that would be 40€ until crossing even!).In such situation the investor has a few choices, one paying of the additional 100€ with profit from a different company bought before where any interests are payed of. But humans only life so long, which brings us to the other solution:Forcefully raise the profit from 100x to 200x to pay of interests squeezing out the company, then either resell a \"now more profitable company\" for more money or if the value of the company falls have some shenanigans ready to tax write of the loss in value....Worse similar to a mortgage you can take on a house you can (at least in the US) make a contract where you get a credit you have to use to buy a company (or more like the lender directly pays a part of the cost) and the insurance for the credit is the company itself leading to a situation where the company basically now has to itself pay the 200x interests instead of the buyer. (example Twitter).Now I&#x27;m gross oversimplifying things, but basically our financial system is so messed up that if a sustainable company gets bought there is a good chance it gets fucked up soon afterwards in one way or another. This in turn is not sustainable for the industry as a whole.Now you might argue what has that to do with this case as not a person but another journalistic outlet bought them, well that other outlet is for profit and is likely to act as much as described above as a person. Buy, squeeze, resell or buy gut-out and write of is as much a case there then if a unrelated 3rd party would have bought it, and gut-out works much better if the buyer is from the same industry branch. reply k1ns 17 hours agoparentprevWhy maintain a perfectly good and profitable business when you could suck every possible resource dry and be the CEO that boosted profits by 3%? &#x2F;sSilicon Valley, VC culture, American industry in general, has all jaded my view of \"business\" people. reply Drakim 17 hours agoparentprevSomebody in the new management probably needed to stir things up and show that they have a vision and direction that will take the company to new heights, which includes drastic measures like firing those holding the company back, or who were unwilling to be reduced in compensation and scope. reply runeofdoom 16 hours agorootparentThis. Over two decades, I have yet to see new senior management who didn&#x27;t feel compelled to &#x27;make their mark&#x27; on their new territory by changing something significant. Occassionally, they&#x27;ll actually do something useful, but usually they take something that worked and break it. reply jstarfish 12 hours agorootparentI don&#x27;t think it&#x27;s incompetence or egomania anymore; I think it&#x27;s outright sadism. Some of these corporate sociopaths (Shkreli) don&#x27;t even try to conceal their intentions because nothing ever happens to any of them anyway. It wasn&#x27;t the hijinks with the Epi-pen pricing that sent Shkreli to prison.Find something sentimental to someone, and smash it while they watch. People can&#x27;t coordinate resistance against you when they&#x27;re emotional. Hurt them deep enough and they give up. Then you can replace them with sycophants. reply cool_dude85 17 hours agoparentprev>Who cares if it \"grows\"?Investors who want to make money and do not particularly care how. reply johnbellone 14 hours agoparentprev> Who cares if it \"grows\"?I understand what you&#x27;re trying to say here, but it&#x27;s extremely naive. For one, the employees definitely care, because they want their pay to keep up with cost of living. The owners want the business to be successful so they get a return on their investment.> Why is it never good enough to just have an ongoing business that works?Unfortunately, as soon as you employee people it is never good enough to make sure the business operates without growth. Unless, of course, you&#x27;re wealthy enough to fund the business through the hard times. reply ivraatiems 11 hours agorootparentWe&#x27;re not talking about \"grow a few percent a year, combined with price increases, to combat inflation.\" We&#x27;re talking about \"grow massively in a way that makes the founders of the company rich.\"That&#x27;s what I am unconcerned about. Being so concerned about attaining wealth that you sacrifice the value of what you already have in a misguided attempt to do so is the naive thing. reply ska 16 hours agoparentprev> Who cares if it \"grows\"?Did they raise any money? reply hnthrowaway0315 16 hours agoparentprevBecause why not experiment if others get shit when it goes bad? I&#x27;d do it too... reply monero-xmr 17 hours agoparentprevPlenty of journalists have joined Substack, started podcasts, etc. They quickly realize that’s a business as well, and there’s no escaping the hustle and grind. reply M2Ys4U 17 hours agorootparentThere&#x27;s a difference between running a profitable business and running a business that has continuous growth. reply ketzo 16 hours agorootparentEvery business’s highest cost - labor - will tend to grow every year. So will the cost of most other inputs.If you stop pursuing some amount of continuous growth or price increase, you stop making money. reply ip26 16 hours agorootparent3% higher expenses and 3% higher revenues to compensate is not what people mean by “a growth company”. reply ketzo 9 hours agorootparentNo, but it is the dictionary definition of “continuously pursuing growth.” replypaxys 17 hours agoprevI like video games as much as anyone, but the entire video games industry is such a hot mess. Terrible working conditions, nasty politics, racism, sexism, toxic fans, zero quality control, monopolies, manipulated reviews, endless push of gambling, microtransactions and other addictive behavior...the list is endless. What is it about the space that brings out the absolute worst in everyone? reply erulabs 17 hours agoparentI think it&#x27;s any industry which is a very common childhood dream that doesn&#x27;t have a high barrier to entry. I wanted to be a game developer - I was briefly too - but I&#x27;m not anymore. It&#x27;s the perfect environment to get 20 year olds to work 80 hour weeks for close to no pay - because it&#x27;s so cool we&#x27;re making video games!. reply CM30 15 hours agorootparentYeah, this is very accurate. Which in turn is why games journalism is such a broken industry in of itself, because it mixes all the problems of the games industry as a whole (people accepting miserable wages for a &#x27;dream job&#x27;, fairly low barrier to entry, toxic conditions) with those of the media industry (people accepting low&#x2F;miserable wages, low barrier to entry, toxic conditions and almost no way to make a decent amount of revenue).Hence you get situations like the focus of this discussion; the people who actually do the work and draw in the visitors getting treated terribly by out of touch execs, and many sites cratering as a result of similar poor decision making. reply depereo 14 hours agorootparentprevLots of industries with low barrier to entry have their &#x27;rock stars&#x27; who people aspire to be and will work hard towards, at least for a while. Carmack or Bowie or Ramsay.But they&#x27;re the 0.1% of the 0.1%. reply bena 15 hours agorootparentprevI did it on the hobbyist scene for a bit and then my place of work tried to spin up an indie shop. It can be fun. It can be interesting. However, it is not as lucrative as just writing YACS (Yet Another CRUD Site).Now, I would like to get back to hobbyist development, just for giggles, but I&#x27;ve wound up with so many obligations, it&#x27;s hard to find time. reply Tistel 16 hours agoparentprevI worked in it for 13 years (worked on one of the biggest non shooter games in the world). (this was ten years ago). I moved to new city to work and did so much overtime that when I go back to the same city now it feels strange to me. no familiarity whatsoever. The main problems I experienced were insane hours, low pay (base salary sounds good till you do the back of the envelop calc of pay over time and realize its less than minimum wage. lol.) and business people (who don&#x27;t play or like games) making decisions that overrode the decisions of people who actually like games. Yahtzee is the only game reporter&#x2F;reviewer whose name I still remember. I far as I can tell, he was the channel. you could tell he liked games. He will be fine, he has talent. reply huytersd 15 hours agoparentprevIt’s shut in culture. Whether you agree with me or not, a large part of the user base is depressed men that spend their time playing video games in a closed room. The edge and toxicity is the only way for them to spice up their lives. reply ip26 16 hours agoparentprevMy guess? Money to be made, but winner-take-all dynamics. Dark horses are able to emerge relatively frequently, but it’s hard to predict winners beforehand. A workforce willing to be exploited (kid dreams of working in gaming).All this comes together to create an environment where everyone is working furiously for the payout, but most will lose, and you have few friends on a sinking ship.Contrast to a more stable market with clear lynchpins that is slow to change. That kind of environment is less equitable and meritocratic, but managers at a tiny company with 0.01% market share will struggle to whip their employees into repeated 80 hour weeks. reply PedroBatista 15 hours agoparentprevIMO it&#x27;s the same&#x2F;same-ish dynamic of Hollywood. It attracts a certain type of people, plus the environment is cut to \"good people turn bad\" plus all the pressure and money ( a carrot most of the time for most of the people )\"Creative\" industries always will suffer from this, it&#x27;s just a matter of how bad someone let&#x27;s things go. Because of the flip side corporate environments give us Call of Duty 44, that in reality they offshore most of the work to \"3rd World\" countries where little to no oversight happens. reply Zigurd 17 hours agoparentprev...and that&#x27;s the good part. reply sickofparadox 17 hours agoprevHopefully Yahtzee will get his own youtube channel or at least one that shares the spotlight with other creators of his caliber, I only watched ZP sparingly because subscribing to the Escapist would have meant regularly getting MovieBob in my feed. reply F2hP18Foam 17 hours agoparentAccording to Yahtzee he doesn&#x27;t own the rights to ZP, so I hope he doesn&#x27;t have too much trouble starting something new. reply entropicdrifter 16 hours agorootparent... sure, but it&#x27;s not like ZP owns the format of fast-paced, 5 minute video game reviews full of dick jokes reply kridsdale3 13 hours agorootparentprevHe&#x27;s talented enough to make something new. His novels are original IP and dang good fun. reply jabroni_salad 16 hours agoparentprevCold Take has been such an excellent foil for ZP. I hope they continue to do business together. reply wsinks 16 hours agorootparentWhen did Cold Take start? I only just found it through recommendations in the last few months and absolutely love the whole vibe that Frost has captured. reply jabroni_salad 15 hours agorootparentIt will have been exactly 1 year tomorrow. reply jhbadger 16 hours agoparentprevMoviebob hasn&#x27;t been associated with the Escapist for years. Although I don&#x27;t know why you&#x27;d want to avoid him -- he&#x27;s one of the best Youtube movie critics out there. reply camdenlock 15 hours agorootparentHe may not adequately conform to the Dogma. replyMDGeist 18 hours agoprevDamn I&#x27;ve been watching zero punctuation since my college days. I suppose it is remarkable that it went on unchanged as long as it did. reply misnome 18 hours agoparentAt one point it was the literal only thing keeping the site afloat! reply VHRanger 17 hours agorootparentArguably that point extended up to yesterday reply trostaft 16 hours agoprevBoth Yahtzee (ZP) and Sebastian (Cold Take), who both ran my favorite two Escapist publications, have resigned along with him. I sincerely hope that the new management at the Escapist actually have a plan here, for the sake of the remaining employees (naive hope). Wonder where these two will end up, their work is great reply adamzochowski 18 hours agoprevZero Punctuation is youtube reviews of games done in a funny fast way. As if the read text had no pauses, commans, periods. Hence zero punctuation. Some people said it made them think Charlie Booker was making game reviews. reply oakesm9 17 hours agoparentCharlie Booker did do game reviews https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Charlie_Brooker%27s_Gameswipe reply s_dev 16 hours agorootparentYeah, I&#x27;d say Charlie Brooker&#x27;s stint at PC Zone was more notable. That was the best gaming magazine ever and the world is shitter without it. Dave Woods, Jamie Sefton, Will Porter, Rihanna Pratchett. I&#x27;m genuinely amazed PCGamer beat it in the market and continues to this day. reply waveBidder 16 hours agoparentprevone of a few YouTube channels I have to watch at normal rather than 2x reply irrational 18 hours agoprevThe article doesn’t have any context about what the Escapist is, or who or what anything else mentioned is (zero punctuation?). Anyone have an ELI5? reply willk 17 hours agoparentThe Escapist is an online magazine covering games and the gaming industry. Zero Punctuation was a weekly series by reviewer Yahtzee Croshaw. ZP is a video essay given in the format of no punctuation. It has been around for a long time and probably was the only thing keeping The Escapist afloat for a while. reply distortedsignal 17 hours agorootparentTo give context for \"a long time\" - I believe it was started in 07&#x2F;08. I remember when it was still \"Fully Ramblomatic Reviews\".To give context for \"only thing keeping The Escapist afloat\" - this isn&#x27;t the first time The Escapist has imploded. Around 2013&#x2F;2014(?) there was a big blowup, I think The Escapist was bought out, and the new owners terminated a bunch of people and only (really) kept on ZP. The owners basically bought The Escapist for ZP. They ran as a skeleton for quite a few years, and recently (2021?) they started doing more stuff. Their 3 Minute Reviews have been pretty good, and the Cold Take series has been great.This is disappointing for me. I thought they were going in a good direction. It&#x27;s too bad that management decided that they didn&#x27;t want to keep funding interesting, well considered voices. reply loganfrederick 17 hours agorootparentIt was officially started in 2005 with a format much closer to traditional magazines. It was a phase when people were making \"e-zines\", high quality PDFs distributed monthly: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;The_Escapist_(magazine)*Edit: I&#x27;m referring to the whole publication, parent comment might&#x27;ve strictly meant the Zero Punctuation show. reply WorldMaker 15 hours agorootparentThat PDF-based \"The Escapist\" had some really great content some issues. Well researched, highly intellectual, and sometimes fascinatingly deep. That was the era I most followed The Escapist. Somewhere after that was when it fell out of my RSS feeds for being too shallow, I might have even blamed Zero Punctuation a bit for that at the time. That was always a weird dichotomy to me of well researched magazine on the one side and shallow, fast-paced, rambling video reviews on the other. I enjoyed some of the ZP takes at the time and I appreciate Yahtzee&#x27;s ability to deliver interesting points sometimes, but it was always something I felt was of the vanguard of \"shallow clickbait\" that every game site had to be soon after that.Anyway, I thought The Escapist died a long time ago, it&#x27;s fun to reminisce about the one that I liked the most and to hear from everyone else about this later The Escapist that has died even to the point of angering the golden calf of ZP itself. reply distortedsignal 14 hours agorootparentprevYeah - sorry - I was referring to ZP exclusively. I had an indefinite reference (entirely my fault, I’m having a tough week), but I appreciate the history on The Escapist! Good info! reply quchen 17 hours agoparentprevIt’s a computer game thing most commonly known for Zero Punctuation, a review format. It sets itself apart by no punctuation and no pictures of the game being reviewed. Here’s Elden Ring: https:&#x2F;&#x2F;youtu.be&#x2F;BW_h1zD2luY reply schrijver 16 hours agorootparentThanks! I feel cheated though, there’s plenty of punctuation! If you switch on the subtitles, it features periods commas and question marks more or less where I hear them. It’s just someone talking annoyingly fast. reply delecti 17 hours agoparentprevThe website is \"games industry biz\", and the first word of the article is \"journalists\". If you aren&#x27;t familiar with Yahtzee, Zero Punctuation, or the Escapist, then that&#x27;s really all the background you need. reply mvdtnz 16 hours agoprevI hope Croshaw takes this as an opportunity to expand his horizons. He&#x27;s a funny, clever guy who has been beating the same drum for years. Zero Punctuation got old a decade ago but he kept wheeling it out week after week like a comfort blanket. reply PumpkinSpice 15 hours agoparentI think this is a weird take. He found his groove, had a strong popular following, and enriched the lives of two generations of gamers. This is more of a positive legacy than most of us can hope for cranking out JavaScript for advertising companies throughout our prime years.And as others note, he has hobbies and moderately successful side projects outside this envelope. reply dtech 16 hours agoparentprevHe&#x27;s been doing game dev off and on and is currently working on Starstruck Vagabond [1], so he might spend more time on that. He&#x27;s also written quite a few books.edit: He and some other former Escapist crew are doing something, and their Patreon leaked [2][1] https:&#x2F;&#x2F;yzcroshaw.itch.io&#x2F;starstruck [2] https:&#x2F;&#x2F;www.patreon.com&#x2F;SecondWindGroup reply averageRoyalty 12 hours agorootparentHe also used to run two nerd bars in Australia, and has been involved in countless other endeavours. reply mvdtnz 16 hours agorootparentprevThat&#x27;s cool, I wasn&#x27;t aware of his books. I am more talking about his video content, I would love to see him do some funny videos that don&#x27;t follow the mould of ZP. reply VHRanger 14 hours agorootparentHis audiobooks are his best content, no joke. They&#x27;re fast paced, funny, clever and action packed. Both his main book series are worth getting into.He&#x27;s a better writer than many famous authors, and narrates his own books as well. reply kridsdale3 13 hours agorootparentSeconded. The first Star Pilot audiobook is excellent. And of course read by him and he has a lot of experience in delivering entertaining spoken content. reply niam 16 hours agoparentprevI thought he was pretty solid in \"Extra Punctuation\". It was a nice change of pace to hear him gush about Undertale or muse about narrative in games instead of his usual routine. reply swarnie 16 hours agoparentprevI&#x27;m not sure what else you want the guy to do.He has multiple video series, a live stream and about six novels i can name. reply fullshark 16 hours agoparentprevMeh tired of that mentality, we need more people who get good at their job and keep doing it well. reply AlexandrB 16 hours agorootparentGetting good at your job and doing it well doesn&#x27;t mean doing the exact same thing for 20 years. Many of the best musicians had multiple \"eras\" where their styles changed dramatically. reply VikingCoder 15 hours agoparentprevGive him a segment on Last Week Tonight. reply AdamJacobMuller 14 hours agoprev> \"I don&#x27;t have the rights to Zero Punctuation\"Thats sad. Nothing gamurs does with it will be successful. Yahtzee, both in his voice and in the video content itself, is far too linked to Zero Punctuation.I&#x27;m sure whatever Yahtzee does next will be successful but it will be lesser without the ZP name attached. reply Hamuko 14 hours agoparentI hope it&#x27;s just the name \"Zero Punctuation\" that he doesn&#x27;t have the rights to, since he started making what was essentially Zero Punctuation but without the name \"Zero Punctuation\" before he was hired by The Escapist.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eWS9_nrKOPA reply slg 14 hours agoprevReminiscent of what happened at Deadspin a few years ago[1]. The EIC was fired for some weird management BS and the entire staff resigned and eventually started Defector as a worker owned business which has been consistently profitable[2]. Hopefully some of the Escapist folks follow that route.[1] - https:&#x2F;&#x2F;www.nytimes.com&#x2F;2020&#x2F;07&#x2F;28&#x2F;business&#x2F;media&#x2F;deadspin-s...[2] - https:&#x2F;&#x2F;defector.com&#x2F;three-years-of-defector reply phendrenad2 14 hours agoprevThis is good. This is like a prey animal developing a bitter taste so predators will cough it up if they try to eat it. Or the villagers banding together to expel a rich businessman who wants to strip mine the local ecology. reply atleastoptimal 15 hours agoprevDoes anyone still read web publications that hail back to the golden era of Vice? I feel that they were in their heyday in the late 2000s and since have suffered a gradual, painful decline into irrelevance. reply karaterobot 14 hours agoparentI think at a certain point many of them just changed to primarily or exclusively video and streaming content. It&#x27;s easier to monetize, and it&#x27;s where most of the attention of gamers is focused. A lot of it is cheap and terrible, but some of it is really good. reply kalupa 10 hours agoprevI see that \"private equity\" buyout by Gamurs is going exceedingly well reply xvector 16 hours agoprev [–] The execs who make these decisions ought to be named and shamed. reply ncr100 9 hours agoparent [–] I don&#x27;t know that would help anything.https:&#x2F;&#x2F;gamurs.group&#x2F;aboutLooking deeper than names, several roles in the executive level changed over the last 12 months (&#x27;22 and one in &#x27;23). The CEO has been there forever.So perhaps it&#x27;s reasonable to guess they are in an acquisition phase, and are squeezing their portfolio to meet their new higher financial goals.What do you think? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Escapist, a gaming website, has experienced a wave of resignations, including Ben \"Yahtzee\" Croshaw from Zero Punctuation, following the termination of the editor-in-chief, Nick Calandra.",
      "Calandra was reportedly dismissed for \"not meeting goals\" by the Gamurs Group, which acquired The Escapist last year, citing unclear objectives and a lack of understanding of the platform's readership as ongoing issues.",
      "Other notable departures include contributors Amy Campbell, Parkes Harman, Darren Mooney, Matt Laughlin, and JM8 from Design Delve, suggesting a staff-wide unity and response to Calandra's termination."
    ],
    "commentSummary": [
      "Several staff members from The Escapist, including Ben \"Yahtzee\" Croshaw, known from Zero Punctuation, resigned following the firing of the site's editor-in-chief, Nick Calandra.",
      "The Gamurs Group, who bought The Escapist last year, reportedly terminated Calandra for \"not achieving goals,\" although he pointed to goal ambiguity and lack of understanding of their audience as ongoing issues.",
      "This mass resignation is an act of solidarity with Calandra, and is a response to his termination with notable exits including Amy Campbell, Parkes Harman, Darren Mooney, Matt Laughlin, and Design Delve's JM8."
    ],
    "points": 189,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1699368025
  }
]
